{"home.repos.pwc.inspect_result.machanic_MetaAdvDet.toolkit.img_transform.get_preprocessor": [[4, 24], ["torchvision.transforms.transforms.Normalize", "torchvision.transforms.transforms.Compose", "torchvision.transforms.transforms.Compose", "torchvision.transforms.transforms.Resize", "torchvision.transforms.transforms.ToTensor", "torchvision.transforms.transforms.ToTensor"], "function", ["None"], ["def", "get_preprocessor", "(", "input_channels", "=", "3", ",", "input_size", "=", "None", ")", ":", "\n", "    ", "if", "input_channels", "==", "3", ":", "\n", "        ", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "", "else", ":", "\n", "        ", "mean", "=", "[", "0.456", "]", "\n", "std", "=", "[", "0.224", "]", "\n", "", "normalizer", "=", "transforms", ".", "Normalize", "(", "mean", "=", "mean", ",", "std", "=", "std", ")", "\n", "if", "input_size", "is", "not", "None", ":", "\n", "        ", "preprocess_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "size", "=", "input_size", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalizer", "\n", "]", ")", "\n", "", "else", ":", "\n", "        ", "preprocess_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalizer", "\n", "]", ")", "\n", "", "return", "preprocess_transform", "\n", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.iterative_FGSM.IterativeFastGradientSignUntargeted.__init__": [[19, 26], ["iterative_FGSM.IterativeFastGradientSignUntargeted.model.eval"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model", ",", "alpha", "=", "0.01", ",", "max_iters", "=", "10", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "# Movement multiplier per iteration", "\n", "self", ".", "alpha", "=", "alpha", "\n", "# Create the folder to export images if not exists", "\n", "self", ".", "max_iters", "=", "max_iters", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.iterative_FGSM.IterativeFastGradientSignUntargeted.generate": [[27, 65], ["torch.nn.CrossEntropyLoss", "x.detach().cuda", "range", "processed_image.detach.detach.detach", "iterative_FGSM.IterativeFastGradientSignUntargeted.model.zero_grad", "iterative_FGSM.IterativeFastGradientSignUntargeted.model", "torch.nn.CrossEntropyLoss.", "nn.CrossEntropyLoss.backward", "x.detach", "torch.sign"], "methods", ["None"], ["", "def", "generate", "(", "self", ",", "x", ",", "orig_class", ",", "target", ")", ":", "\n", "# Define loss functions", "\n", "        ", "ce_loss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "# Process image", "\n", "processed_image", "=", "x", ".", "detach", "(", ")", ".", "cuda", "(", ")", "\n", "# Start iteration", "\n", "for", "i", "in", "range", "(", "self", ".", "max_iters", ")", ":", "\n", "# zero_gradients(x)", "\n", "# Zero out previous gradients", "\n", "# Can also use zero_gradients(x)", "\n", "            ", "last_proceed_img", "=", "processed_image", "\n", "processed_image", "=", "processed_image", ".", "detach", "(", ")", "\n", "del", "last_proceed_img", "\n", "processed_image", ".", "requires_grad", "=", "True", "\n", "processed_image", ".", "grad", "=", "None", "\n", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "# Forward pass", "\n", "out", "=", "self", ".", "model", "(", "processed_image", ")", "\n", "# Calculate CE loss", "\n", "pred_loss", "=", "ce_loss", "(", "out", ",", "orig_class", ")", "\n", "# Do backward pass", "\n", "pred_loss", ".", "backward", "(", ")", "\n", "# Create Noise", "\n", "# Here, processed_image.grad.data is also the same thing is the backward gradient from", "\n", "# the first layer, can use that with hooks as well", "\n", "adv_noise", "=", "self", ".", "alpha", "*", "torch", ".", "sign", "(", "processed_image", ".", "grad", ")", "\n", "# Add Noise to processed image", "\n", "processed_image", "=", "processed_image", "+", "adv_noise", "\n", "\n", "# Confirming if the image is indeed adversarial with added noise", "\n", "# This is necessary (for some cases) because when we recreate image", "\n", "# the values become integers between 1 and 255 and sometimes the adversariality", "\n", "# is lost in the recreation process", "\n", "# if gen_correct:", "\n", "#     break", "\n", "del", "out", "\n", "del", "pred_loss", "\n", "", "return", "processed_image", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.iterative_FGSM.IterativeFastGradientSignTargeted.__init__": [[74, 80], ["iterative_FGSM.IterativeFastGradientSignTargeted.model.eval"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model", ",", "alpha", ",", "max_iters", "=", "10", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "max_iters", "=", "max_iters", "\n", "# Movement multiplier per iteration", "\n", "self", ".", "alpha", "=", "alpha", "\n", "# Create the folder to export images if not exists", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.iterative_FGSM.IterativeFastGradientSignTargeted.generate": [[82, 121], ["torch.nn.CrossEntropyLoss", "x.detach().cuda", "range", "processed_image.detach.detach.detach", "iterative_FGSM.IterativeFastGradientSignTargeted.model.zero_grad", "iterative_FGSM.IterativeFastGradientSignTargeted.model", "torch.nn.CrossEntropyLoss.", "nn.CrossEntropyLoss.backward", "x.detach", "torch.sign"], "methods", ["None"], ["", "def", "generate", "(", "self", ",", "x", ",", "orig_class", ",", "target", ")", ":", "\n", "# I honestly dont know a better way to create a variable with specific value", "\n", "# Targeting the specific class", "\n", "# Define loss functions", "\n", "        ", "ce_loss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "# Process image", "\n", "processed_image", "=", "x", ".", "detach", "(", ")", ".", "cuda", "(", ")", "\n", "# Start iteration", "\n", "gen_correct", "=", "False", "\n", "for", "i", "in", "range", "(", "self", ".", "max_iters", ")", ":", "\n", "# zero_gradients(x)", "\n", "# Zero out previous gradients", "\n", "# Can also use zero_gradients(x)", "\n", "            ", "last_proceed_img", "=", "processed_image", "\n", "processed_image", "=", "processed_image", ".", "detach", "(", ")", "\n", "del", "last_proceed_img", "\n", "processed_image", ".", "requires_grad", "=", "True", "\n", "processed_image", ".", "grad", "=", "None", "\n", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "# Forward pass", "\n", "out", "=", "self", ".", "model", "(", "processed_image", ")", "\n", "# Calculate CE loss", "\n", "pred_loss", "=", "ce_loss", "(", "out", ",", "target", ")", "\n", "# Do backward pass", "\n", "pred_loss", ".", "backward", "(", ")", "\n", "# Create Noise", "\n", "# Here, processed_image.grad.data is also the same thing is the backward gradient from", "\n", "# the first layer, can use that with hooks as well", "\n", "adv_noise", "=", "self", ".", "alpha", "*", "torch", ".", "sign", "(", "processed_image", ".", "grad", ")", "\n", "# Add noise to processed image", "\n", "processed_image", "=", "processed_image", "-", "adv_noise", "\n", "\n", "# Confirming if the image is indeed adversarial with added noise", "\n", "# This is necessary (for some cases) because when we recreate image", "\n", "# the values become integers between 1 and 255 and sometimes the adversariality", "\n", "# is lost in the recreation process", "\n", "del", "out", "\n", "del", "pred_loss", "\n", "", "return", "processed_image", "\n", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2.CarliniWagnerL2.__init__": [[232, 320], ["copy.deepcopy", "float", "tuple", "len", "TypeError", "ValueError", "float", "float", "map"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model", "=", "None", ",", "targeted", "=", "True", ",", "confidence", "=", "0.0", ",", "c_range", "=", "(", "1e-3", ",", "1e10", ")", ",", "\n", "search_steps", "=", "5", ",", "max_steps", "=", "1000", ",", "abort_early", "=", "True", ",", "\n", "optimizer_lr", "=", "1e-2", ",", "init_rand", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param model: nn.Module the model network we want to attack\n        :param targeted: ``True`` to perform targeted attack in ``self.run``\n               method\n        :type targeted: bool\n        :param confidence: the confidence constant, i.e. the $\\\\kappa$ in paper\n        :type confidence: float\n        :param c_range: the search range of the constant :math:`c`; should be a\n               tuple of form (lower_bound, upper_bound)\n        :type c_range: Tuple[float, float]\n        :param search_steps: the number of steps to perform binary search of\n               the constant :math:`c` over ``c_range``\n        :type search_steps: int\n        :param max_steps: the maximum number of optimization steps for each\n               constant :math:`c`\n        :type max_steps: int\n        :param abort_early: ``True`` to abort early in process of searching for\n               :math:`c` when the loss virtually stops increasing\n        :type abort_early: bool\n        :param learning_rate: the base learning rate of the Adam optimizer used\n               over the adversarial perturbation in clipped space\n        :type learning_rate: float\n        :param init_rand: ``True`` to initialize perturbation to small Gaussian;\n               False is consistent with the original paper, where the\n               perturbation is initialized to zero\n        :type init_rand: bool\n        :rtype: None\n\n        Why to make ``box`` default to (-1., 1.) rather than (0., 1.)? TL;DR the\n        domain of the problem in pytorch is [-1, 1] instead of [0, 1].\n        According to Xiang Xu (samxucmu@gmail.com)::\n\n        > The reason is that in pytorch a transformation is applied first\n        > before getting the input from the data loader. So image in range [0,1]\n        > will subtract some mean and divide by std. The normalized input image\n        > will now be in range [-1,1]. For this implementation, clipping is\n        > actually performed on the image after normalization, not on the\n        > original image.\n\n        Why to ``optimizer_lr`` default to 1e-2? The optimizer used in Carlini's\n        code adopts 1e-2. In another pytorch implementation\n        (https://github.com/rwightman/pytorch-nips2017-attack-example.git),\n        though, the learning rate is set to 5e-4.\n        \"\"\"", "\n", "# mean = [0.485, 0.456, 0.406]", "\n", "# std = [0.229, 0.224, 0.225]", "\n", "# box = (min((0 - m) / s for m, s in zip(mean, std)),", "\n", "#               max((1 - m) / s for m, s in zip(mean, std)))", "\n", "box", "=", "(", "-", "2.4", ",", "2.7", ")", "\n", "if", "len", "(", "c_range", ")", "!=", "2", ":", "\n", "            ", "raise", "TypeError", "(", "'c_range ({}) should be of form '", "\n", "'tuple([lower_bound, upper_bound])'", "\n", ".", "format", "(", "c_range", ")", ")", "\n", "", "if", "c_range", "[", "0", "]", ">=", "c_range", "[", "1", "]", ":", "\n", "            ", "raise", "ValueError", "(", "'c_range lower bound ({}) is expected to be less '", "\n", "'than c_range upper bound ({})'", ".", "format", "(", "*", "c_range", ")", ")", "\n", "# if len(box) != 2:", "\n", "#     raise TypeError('box ({}) should be of form '", "\n", "#                     'tuple([lower_bound, upper_bound])'", "\n", "#                     .format(box))", "\n", "# if box[0] >= box[1]:", "\n", "#     raise ValueError('box lower bound ({}) is expected to be less than '", "\n", "#                      'box upper bound ({})'.format(*box))", "\n", "", "self", ".", "model", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "self", ".", "targeted", "=", "targeted", "\n", "self", ".", "confidence", "=", "float", "(", "confidence", ")", "\n", "self", ".", "c_range", "=", "(", "float", "(", "c_range", "[", "0", "]", ")", ",", "float", "(", "c_range", "[", "1", "]", ")", ")", "\n", "self", ".", "binary_search_steps", "=", "search_steps", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "abort_early", "=", "abort_early", "\n", "self", ".", "ae_tol", "=", "1e-4", "# tolerance of early abort", "\n", "self", ".", "box", "=", "tuple", "(", "map", "(", "float", ",", "box", ")", ")", "# type: Tuple[float, float]", "\n", "self", ".", "optimizer_lr", "=", "optimizer_lr", "\n", "\n", "# `self.init_rand` is not in Carlini's code, it's an attempt in the", "\n", "# referencing pytorch implementation to improve the quality of attacks.", "\n", "self", ".", "init_rand", "=", "init_rand", "\n", "\n", "# Since the larger the `scale_const` is, the more likely a successful", "\n", "# attack can be found, `self.repeat` guarantees at least attempt the", "\n", "# largest scale_const once. Moreover, since the optimal criterion is the", "\n", "# L2 norm of the attack, and the larger `scale_const` is, the larger", "\n", "# the L2 norm is, thus less optimal, the last attempt at the largest", "\n", "# `scale_const` won't ruin the optimum ever found.", "\n", "self", ".", "repeat", "=", "(", "self", ".", "binary_search_steps", ">=", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2.CarliniWagnerL2.generate": [[321, 479], ["x.cuda().detach", "x.cuda().detach.size", "numpy.zeros", "x.cuda().detach.cpu().detach().numpy", "carlini_wagner_L2.CarliniWagnerL2._to_tanh_space", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda.scatter_", "torch.zeros().cuda.scatter_", "torch.zeros().cuda.scatter_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.Adam", "torch.Adam", "torch.Adam", "range", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "len", "len", "target.clone().cpu().numpy", "orig_class.clone().cpu().numpy", "carlini_wagner_L2.make_cuda_consistent", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "carlini_wagner_L2.CarliniWagnerL2.model().size", "numpy.ones", "numpy.ones", "numpy.ones", "numpy.ones", "carlini_wagner_L2.make_cuda_consistent", "target.unsqueeze", "torch.init.normal", "torch.init.normal", "torch.init.normal", "carlini_wagner_L2.make_cuda_consistent", "torch.from_numpy().cuda().float", "torch.from_numpy().cuda().float", "torch.from_numpy().cuda().float", "torch.from_numpy().cuda().float", "torch.from_numpy().cuda().float", "torch.from_numpy().cuda().float", "torch.from_numpy().cuda().float", "torch.from_numpy().cuda().float", "torch.from_numpy().cuda().float", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "range", "range", "x.cuda", "x.cuda().detach.size", "target.size", "carlini_wagner_L2.make_cuda_consistent", "carlini_wagner_L2.make_cuda_consistent", "x.cuda().detach.cpu().detach", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "carlini_wagner_L2.make_cuda_consistent", "numpy.ones", "numpy.ones", "carlini_wagner_L2.CarliniWagnerL2._optimize", "numpy.argmax", "numpy.argmax", "range", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "target.clone().cpu", "orig_class.clone().cpu", "carlini_wagner_L2.CarliniWagnerL2.model", "x.cuda().detach.size", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "carlini_wagner_L2.CarliniWagnerL2._compensate_confidence", "carlini_wagner_L2.CarliniWagnerL2._attack_successful", "carlini_wagner_L2.CarliniWagnerL2._attack_successful", "carlini_wagner_L2.CarliniWagnerL2._attack_successful", "x.cuda().detach.cpu", "target.size", "target.clone", "orig_class.clone", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.copy"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._to_tanh_space", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.make_cuda_consistent", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.make_cuda_consistent", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.make_cuda_consistent", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.make_cuda_consistent", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.make_cuda_consistent", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.make_cuda_consistent", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._optimize", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._compensate_confidence", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._attack_successful", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._attack_successful", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._attack_successful"], ["", "def", "generate", "(", "self", ",", "x", ",", "orig_class", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        Produce adversarial examples for ``inputs``.\n\n        :param x: the processed images tensor, of dimension [B x C x H x W].\n               ``x`` can be on either CPU or GPU, but it will eventually be\n               moved to the same device as the one the parameters of ``model``\n               reside\n        :type inputs: torch.FloatTensor\n        :param target: the original image labels, or the attack targets, of\n               dimension [B]. If ``self.targeted`` is ``True``, then ``targets``\n               is treated as the attack targets, otherwise the labels.\n               ``targets`` can be on either CPU or GPU, but it will eventually\n               be moved to the same device as the one the parameters of\n               ``model`` reside\n        :type target: torch.LongTensor\n        :param to_numpy: True to return an `np.ndarray`, otherwise,\n               `torch.FloatTensor`\n        :type to_numpy: bool\n        :return: the adversarial examples on CPU, of dimension [B x C x H x W]\n        \"\"\"", "\n", "# sanity check", "\n", "# inputs = torch.from_numpy(orig_img).unsqueeze(0).float().cuda()  # B,H,W,C", "\n", "# inputs = inputs.permute(0,3,1,2)", "\n", "inputs", "=", "x", ".", "cuda", "(", ")", ".", "detach", "(", ")", "\n", "assert", "len", "(", "inputs", ".", "size", "(", ")", ")", "==", "4", "\n", "assert", "len", "(", "target", ".", "size", "(", ")", ")", "==", "1", "\n", "\n", "# get a copy of targets in numpy before moving to GPU, used when doing", "\n", "# the binary search on `scale_const`", "\n", "if", "self", ".", "targeted", ":", "\n", "            ", "targets_np", "=", "target", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "# type: np.ndarray", "\n", "target", "=", "make_cuda_consistent", "(", "self", ".", "model", ",", "target", ")", "[", "0", "]", "# type: torch.FloatTensor", "\n", "", "else", ":", "\n", "            ", "targets_np", "=", "orig_class", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "# type: np.ndarray", "\n", "target", "=", "make_cuda_consistent", "(", "self", ".", "model", ",", "orig_class", ")", "[", "0", "]", "# type: torch.FloatTensor", "\n", "# the type annotations here are used only for type hinting and do", "\n", "# not indicate the actual type (cuda or cpu); same applies to all codes", "\n", "# below", "\n", "", "inputs", "=", "make_cuda_consistent", "(", "self", ".", "model", ",", "inputs", ")", "[", "0", "]", "# type: torch.FloatTensor", "\n", "# run the model a little bit to get the `num_classes`", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "num_classes", "=", "self", ".", "model", "(", "inputs", ")", ".", "size", "(", "1", ")", "# type: int", "\n", "", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", "# type: int", "\n", "\n", "# `lower_bounds_np`, `upper_bounds_np` and `scale_consts_np` are used", "\n", "# for binary search of each `scale_const` in the batch. The element-wise", "\n", "# inquality holds: lower_bounds_np < scale_consts_np <= upper_bounds_np", "\n", "lower_bounds_np", "=", "np", ".", "zeros", "(", "batch_size", ")", "\n", "upper_bounds_np", "=", "np", ".", "ones", "(", "batch_size", ")", "*", "self", ".", "c_range", "[", "1", "]", "\n", "scale_consts_np", "=", "np", ".", "ones", "(", "batch_size", ")", "*", "self", ".", "c_range", "[", "0", "]", "\n", "\n", "# Optimal attack to be found.", "\n", "# The three \"placeholders\" are defined as:", "\n", "# - `o_best_l2`: the least L2 norms", "\n", "# - `o_best_l2_ppred`: the perturbed predictions made by the adversarial", "\n", "#    perturbations with the least L2 norms", "\n", "# - `o_best_advx`: the underlying adversarial example of", "\n", "#   `o_best_l2_ppred`", "\n", "o_best_l2", "=", "np", ".", "ones", "(", "batch_size", ")", "*", "np", ".", "inf", "\n", "o_best_l2_ppred", "=", "-", "np", ".", "ones", "(", "batch_size", ")", "# type: np.ndarray", "\n", "o_best_advx", "=", "inputs", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "# type: np.ndarray", "\n", "\n", "# convert `inputs` to tanh-space", "\n", "inputs_tanh", "=", "self", ".", "_to_tanh_space", "(", "inputs", ")", "# type: torch.FloatTensor", "\n", "inputs_tanh_var", "=", "Variable", "(", "inputs_tanh", ",", "requires_grad", "=", "False", ")", "\n", "\n", "# the one-hot encoding of `targets`", "\n", "targets_oh", "=", "torch", ".", "zeros", "(", "target", ".", "size", "(", ")", "+", "(", "num_classes", ",", ")", ")", ".", "cuda", "(", ")", "# type: torch.FloatTensor", "\n", "targets_oh", "=", "make_cuda_consistent", "(", "self", ".", "model", ",", "targets_oh", ")", "[", "0", "]", "\n", "targets_oh", ".", "scatter_", "(", "1", ",", "target", ".", "unsqueeze", "(", "1", ")", ",", "1.0", ")", "\n", "\n", "targets_oh_var", "=", "Variable", "(", "targets_oh", ",", "requires_grad", "=", "False", ")", "\n", "\n", "# the perturbation variable to optimize.", "\n", "# `pert_tanh` is essentially the adversarial perturbation in tanh-space.", "\n", "# In Carlini's code it's denoted as `modifier`", "\n", "pert_tanh", "=", "torch", ".", "zeros", "(", "inputs", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", "# type: torch.FloatTensor", "\n", "if", "self", ".", "init_rand", ":", "\n", "            ", "nn", ".", "init", ".", "normal", "(", "pert_tanh", ",", "mean", "=", "0", ",", "std", "=", "1e-3", ")", "\n", "", "pert_tanh", "=", "make_cuda_consistent", "(", "self", ".", "model", ",", "pert_tanh", ")", "[", "0", "]", "\n", "pert_tanh_var", "=", "Variable", "(", "pert_tanh", ",", "requires_grad", "=", "True", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "[", "pert_tanh_var", "]", ",", "lr", "=", "self", ".", "optimizer_lr", ")", "\n", "for", "sstep", "in", "range", "(", "self", ".", "binary_search_steps", ")", ":", "\n", "            ", "if", "self", ".", "repeat", "and", "sstep", "==", "self", ".", "binary_search_steps", "-", "1", ":", "\n", "                ", "scale_consts_np", "=", "upper_bounds_np", "\n", "", "scale_consts", "=", "torch", ".", "from_numpy", "(", "np", ".", "copy", "(", "scale_consts_np", ")", ")", ".", "cuda", "(", ")", ".", "float", "(", ")", "# type: torch.FloatTensor", "\n", "scale_consts", "=", "make_cuda_consistent", "(", "self", ".", "model", ",", "scale_consts", ")", "[", "0", "]", "\n", "scale_consts_var", "=", "Variable", "(", "scale_consts", ",", "requires_grad", "=", "False", ")", "\n", "\n", "# the minimum L2 norms of perturbations found during optimization", "\n", "best_l2", "=", "np", ".", "ones", "(", "batch_size", ")", "*", "np", ".", "inf", "\n", "# the perturbed predictions corresponding to `best_l2`, to be used", "\n", "# in binary search of `scale_const`", "\n", "best_l2_ppred", "=", "-", "np", ".", "ones", "(", "batch_size", ")", "# type: np.ndarray", "\n", "# previous (summed) batch loss, to be used in early stopping policy", "\n", "prev_batch_loss", "=", "np", ".", "inf", "# type: float", "\n", "for", "optim_step", "in", "range", "(", "self", ".", "max_steps", ")", ":", "\n", "                ", "batch_loss", ",", "pert_norms_np", ",", "pert_outputs_np", ",", "advxs_np", "=", "self", ".", "_optimize", "(", "self", ".", "model", ",", "optimizer", ",", "inputs_tanh_var", ",", "\n", "pert_tanh_var", ",", "targets_oh_var", ",", "\n", "scale_consts_var", ")", "\n", "\n", "if", "self", ".", "abort_early", "and", "not", "optim_step", "%", "(", "self", ".", "max_steps", "//", "10", ")", ":", "\n", "                    ", "if", "batch_loss", ">", "prev_batch_loss", "*", "(", "1", "-", "self", ".", "ae_tol", ")", ":", "\n", "                        ", "break", "\n", "", "prev_batch_loss", "=", "batch_loss", "\n", "\n", "# update best attack found during optimization", "\n", "", "pert_predictions_np", "=", "np", ".", "argmax", "(", "pert_outputs_np", ",", "axis", "=", "1", ")", "\n", "comp_pert_predictions_np", "=", "np", ".", "argmax", "(", "\n", "self", ".", "_compensate_confidence", "(", "pert_outputs_np", ",", "\n", "targets_np", ")", ",", "\n", "axis", "=", "1", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "l2", "=", "pert_norms_np", "[", "i", "]", "\n", "cppred", "=", "comp_pert_predictions_np", "[", "i", "]", "\n", "ppred", "=", "pert_predictions_np", "[", "i", "]", "\n", "tlabel", "=", "targets_np", "[", "i", "]", "\n", "ax", "=", "advxs_np", "[", "i", "]", "\n", "if", "self", ".", "_attack_successful", "(", "cppred", ",", "tlabel", ")", ":", "\n", "                        ", "assert", "cppred", "==", "ppred", "\n", "if", "l2", "<", "best_l2", "[", "i", "]", ":", "\n", "                            ", "best_l2", "[", "i", "]", "=", "l2", "\n", "best_l2_ppred", "[", "i", "]", "=", "ppred", "\n", "", "if", "l2", "<", "o_best_l2", "[", "i", "]", ":", "\n", "                            ", "o_best_l2", "[", "i", "]", "=", "l2", "\n", "o_best_l2_ppred", "[", "i", "]", "=", "ppred", "\n", "o_best_advx", "[", "i", "]", "=", "ax", "\n", "\n", "# binary search of `scale_const`", "\n", "", "", "", "", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "tlabel", "=", "targets_np", "[", "i", "]", "\n", "assert", "best_l2_ppred", "[", "i", "]", "==", "-", "1", "or", "self", ".", "_attack_successful", "(", "best_l2_ppred", "[", "i", "]", ",", "tlabel", ")", "\n", "assert", "o_best_l2_ppred", "[", "i", "]", "==", "-", "1", "or", "self", ".", "_attack_successful", "(", "o_best_l2_ppred", "[", "i", "]", ",", "tlabel", ")", "\n", "if", "best_l2_ppred", "[", "i", "]", "!=", "-", "1", ":", "\n", "# successful; attempt to lower `scale_const` by halving it", "\n", "                    ", "if", "scale_consts_np", "[", "i", "]", "<", "upper_bounds_np", "[", "i", "]", ":", "\n", "                        ", "upper_bounds_np", "[", "i", "]", "=", "scale_consts_np", "[", "i", "]", "\n", "# `upper_bounds_np[i] == c_range[1]` implies no solution", "\n", "# found, i.e. upper_bounds_np[i] has never been updated by", "\n", "# scale_consts_np[i] until", "\n", "# `scale_consts_np[i] > 0.1 * c_range[1]`", "\n", "", "if", "upper_bounds_np", "[", "i", "]", "<", "self", ".", "c_range", "[", "1", "]", "*", "0.1", ":", "\n", "                        ", "scale_consts_np", "[", "i", "]", "=", "(", "lower_bounds_np", "[", "i", "]", "+", "upper_bounds_np", "[", "i", "]", ")", "/", "2", "\n", "", "", "else", ":", "\n", "# failure; multiply `scale_const` by ten if no solution", "\n", "# found; otherwise do binary search", "\n", "                    ", "if", "scale_consts_np", "[", "i", "]", ">", "lower_bounds_np", "[", "i", "]", ":", "\n", "                        ", "lower_bounds_np", "[", "i", "]", "=", "scale_consts_np", "[", "i", "]", "\n", "", "if", "upper_bounds_np", "[", "i", "]", "<", "self", ".", "c_range", "[", "1", "]", "*", "0.1", ":", "\n", "                        ", "scale_consts_np", "[", "i", "]", "=", "(", "lower_bounds_np", "[", "i", "]", "+", "upper_bounds_np", "[", "i", "]", ")", "/", "2", "\n", "", "else", ":", "\n", "                        ", "scale_consts_np", "[", "i", "]", "*=", "10", "\n", "", "", "", "", "o_best_advx", "=", "torch", ".", "from_numpy", "(", "o_best_advx", ")", ".", "float", "(", ")", "\n", "return", "o_best_advx", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2.CarliniWagnerL2._optimize": [[481, 574], ["carlini_wagner_L2.CarliniWagnerL2._from_tanh_space", "model", "carlini_wagner_L2.CarliniWagnerL2._from_tanh_space", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "optimizer.zero_grad", "torch.sum.backward", "torch.sum.backward", "torch.sum.backward", "optimizer.step", "torch.sum.item", "torch.sum.item", "torch.sum.item", "carlini_wagner_L2._var2numpy", "carlini_wagner_L2._var2numpy", "carlini_wagner_L2._var2numpy", "torch.sum.view", "torch.sum.view", "torch.sum.view", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.sum.size", "torch.sum.size", "torch.sum.size", "model.max"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._from_tanh_space", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._from_tanh_space", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint._var2numpy", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint._var2numpy", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint._var2numpy"], ["", "def", "_optimize", "(", "self", ",", "model", ",", "optimizer", ",", "inputs_tanh_var", ",", "pert_tanh_var", ",", "\n", "targets_oh_var", ",", "c_var", ")", ":", "\n", "        ", "\"\"\"\n        Optimize for one step.\n\n        :param model: the model to attack\n        :type model: nn.Module\n        :param optimizer: the Adam optimizer to optimize ``modifier_var``\n        :type optimizer: optim.Adam\n        :param inputs_tanh_var: the input images in tanh-space\n        :type inputs_tanh_var: torch.FloatTensor\n        :param pert_tanh_var: the perturbation to optimize in tanh-space,\n               ``pert_tanh_var.requires_grad`` flag must be set to True\n        :type pert_tanh_var: torch.FloatTensor\n        :param targets_oh_var: the one-hot encoded target tensor (the attack\n               targets if self.targeted else image labels)\n        :type targets_oh_var: torch.FloatTensor\n        :param c_var: the constant :math:`c` for each perturbation of a batch,\n               a FloatTensor of dimension [B]\n        :type c_var: torch.FloatTensor\n        :return: the batch loss, squared L2-norm of adversarial perturbations\n                 (of dimension [B]), the perturbed activations (of dimension\n                 [B]), the adversarial examples (of dimension [B x C x H x W])\n        \"\"\"", "\n", "# the adversarial examples in the image space", "\n", "# of dimension [B x C x H x W]", "\n", "advxs_var", "=", "self", ".", "_from_tanh_space", "(", "inputs_tanh_var", "+", "pert_tanh_var", ")", "\n", "# the perturbed activation before softmax", "\n", "pert_outputs_var", "=", "model", "(", "advxs_var", ")", "\n", "# the original inputs", "\n", "inputs_var", "=", "self", ".", "_from_tanh_space", "(", "inputs_tanh_var", ")", "\n", "\n", "perts_norm_var", "=", "torch", ".", "pow", "(", "advxs_var", "-", "inputs_var", ",", "2", ")", "\n", "perts_norm_var", "=", "torch", ".", "sum", "(", "perts_norm_var", ".", "view", "(", "\n", "perts_norm_var", ".", "size", "(", "0", ")", ",", "-", "1", ")", ",", "1", ")", "\n", "\n", "# In Carlini's code, `target_activ_var` is called `real`.", "\n", "# It should be a Variable of tensor of dimension [B], such that the", "\n", "# `target_activ_var[i]` is the final activation (right before softmax)", "\n", "# of the $t$th class, where $t$ is the attack target or the image label", "\n", "#", "\n", "# noinspection PyArgumentList", "\n", "target_activ_var", "=", "torch", ".", "sum", "(", "targets_oh_var", "*", "pert_outputs_var", ",", "1", ")", "\n", "inf", "=", "1e4", "# sadly pytorch does not work with np.inf;", "\n", "# 1e4 is also used in Carlini's code", "\n", "# In Carlini's code, `maxother_activ_var` is called `other`.", "\n", "# It should be a Variable of tensor of dimension [B], such that the", "\n", "# `maxother_activ_var[i]` is the maximum final activation of all classes", "\n", "# other than class $t$, where $t$ is the attack target or the image", "\n", "# label.", "\n", "#", "\n", "# The assertion here ensures (sufficiently yet not necessarily) the", "\n", "# assumption behind the trick to get `maxother_activ_var` holds, that", "\n", "# $\\max_{i \\ne t}{o_i} \\ge -\\text{_inf}$, where $t$ is the target and", "\n", "# $o_i$ the $i$th element along axis=1 of `pert_outputs_var`.", "\n", "#", "\n", "# noinspection PyArgumentList", "\n", "assert", "(", "pert_outputs_var", ".", "max", "(", "1", ")", "[", "0", "]", ">=", "-", "inf", ")", ".", "all", "(", ")", ",", "'assumption failed'", "\n", "# noinspection PyArgumentList", "\n", "maxother_activ_var", "=", "torch", ".", "max", "(", "(", "(", "1", "-", "targets_oh_var", ")", "*", "pert_outputs_var", "\n", "-", "targets_oh_var", "*", "inf", ")", ",", "1", ")", "[", "0", "]", "\n", "\n", "# Compute $f(x')$, where $x'$ is the adversarial example in image space.", "\n", "# The result `f_var` should be of dimension [B]", "\n", "if", "self", ".", "targeted", ":", "\n", "# if targeted, optimize to make `target_activ_var` larger than", "\n", "# `maxother_activ_var` by `self.confidence`", "\n", "#", "\n", "# noinspection PyArgumentList", "\n", "            ", "f_var", "=", "torch", ".", "clamp", "(", "maxother_activ_var", "-", "target_activ_var", "\n", "+", "self", ".", "confidence", ",", "min", "=", "0.0", ")", "\n", "", "else", ":", "\n", "# if not targeted, optimize to make `maxother_activ_var` larger than", "\n", "# `target_activ_var` (the ground truth image labels) by", "\n", "# `self.confidence`", "\n", "#", "\n", "# noinspection PyArgumentList", "\n", "            ", "f_var", "=", "torch", ".", "clamp", "(", "target_activ_var", "-", "maxother_activ_var", "\n", "+", "self", ".", "confidence", ",", "min", "=", "0.0", ")", "\n", "# the total loss of current batch, should be of dimension [1]", "\n", "", "batch_loss_var", "=", "torch", ".", "sum", "(", "perts_norm_var", "+", "c_var", "*", "f_var", ")", "# type: torch.Tensor", "\n", "\n", "# Do optimization for one step", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "batch_loss_var", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Make some records in python/numpy on CPU", "\n", "batch_loss", "=", "batch_loss_var", ".", "item", "(", ")", "\n", "pert_norms_np", "=", "_var2numpy", "(", "perts_norm_var", ")", "\n", "pert_outputs_np", "=", "_var2numpy", "(", "pert_outputs_var", ")", "\n", "advxs_np", "=", "_var2numpy", "(", "advxs_var", ")", "\n", "return", "batch_loss", ",", "pert_norms_np", ",", "pert_outputs_np", ",", "advxs_np", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2.CarliniWagnerL2._attack_successful": [[575, 590], ["None"], "methods", ["None"], ["", "def", "_attack_successful", "(", "self", ",", "prediction", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        See whether the underlying attack is successful.\n\n        :param prediction: the prediction of the model on an input\n        :type prediction: int\n        :param target: either the attack target or the ground-truth image label\n        :type target: int\n        :return: ``True`` if the attack is successful\n        :rtype: bool\n        \"\"\"", "\n", "if", "self", ".", "targeted", ":", "\n", "            ", "return", "prediction", "==", "target", "\n", "", "else", ":", "\n", "            ", "return", "prediction", "!=", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2.CarliniWagnerL2._compensate_confidence": [[592, 620], ["numpy.copy", "numpy.arange"], "methods", ["None"], ["", "", "def", "_compensate_confidence", "(", "self", ",", "outputs", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Compensate for ``self.confidence`` and returns a new weighted sum\n        vector.\n\n        :param outputs: the weighted sum right before the last layer softmax\n               normalization, of dimension [B x M]\n        :type outputs: np.ndarray\n        :param targets: either the attack targets or the real image labels,\n               depending on whether or not ``self.targeted``, of dimension [B]\n        :type targets: np.ndarray\n        :return: the compensated weighted sum of dimension [B x M]\n        :rtype: np.ndarray\n        \"\"\"", "\n", "outputs_comp", "=", "np", ".", "copy", "(", "outputs", ")", "\n", "rng", "=", "np", ".", "arange", "(", "targets", ".", "shape", "[", "0", "]", ")", "\n", "if", "self", ".", "targeted", ":", "\n", "# for each image $i$:", "\n", "# if targeted, `outputs[i, target_onehot]` should be larger than", "\n", "# `max(outputs[i, ~target_onehot])` by `self.confidence`", "\n", "            ", "outputs_comp", "[", "rng", ",", "targets", "]", "-=", "self", ".", "confidence", "\n", "", "else", ":", "\n", "# for each image $i$:", "\n", "# if not targeted, `max(outputs[i, ~target_onehot]` should be larger", "\n", "# than `outputs[i, target_onehot]` (the ground truth image labels)", "\n", "# by `self.confidence`", "\n", "            ", "outputs_comp", "[", "rng", ",", "targets", "]", "+=", "self", ".", "confidence", "\n", "", "return", "outputs_comp", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2.CarliniWagnerL2._to_tanh_space": [[621, 629], ["carlini_wagner_L2.to_tanh_space"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.to_tanh_space"], ["", "def", "_to_tanh_space", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Convert a batch of tensors to tanh-space.\n\n        :param x: the batch of tensors, of dimension [B x C x H x W]\n        :return: the batch of tensors in tanh-space, of the same dimension\n        \"\"\"", "\n", "return", "to_tanh_space", "(", "x", ",", "self", ".", "box", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2.CarliniWagnerL2._from_tanh_space": [[630, 639], ["carlini_wagner_L2.from_tanh_space"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.from_tanh_space"], ["", "def", "_from_tanh_space", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Convert a batch of tensors from tanh-space to input space.\n\n        :param x: the batch of tensors, of dimension [B x C x H x W]\n        :return: the batch of tensors in tanh-space, of the same dimension;\n                 the returned tensor is on the same device as ``x``\n        \"\"\"", "\n", "return", "from_tanh_space", "(", "x", ",", "self", ".", "box", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2.get_cuda_state": [[22, 39], ["isinstance", "hasattr", "TypeError", "next", "obj.parameters", "type"], "function", ["None"], ["def", "get_cuda_state", "(", "obj", ")", ":", "\n", "    ", "\"\"\"\n    Get cuda state of any object.\n    :param obj: an object (a tensor or an `torch.nn.Module`)\n    :raise TypeError:\n    :return: True if the object or the parameter set of the object\n             is on GPU\n    \"\"\"", "\n", "if", "isinstance", "(", "obj", ",", "nn", ".", "Module", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "next", "(", "obj", ".", "parameters", "(", ")", ")", ".", "is_cuda", "\n", "", "except", "StopIteration", ":", "\n", "            ", "return", "None", "\n", "", "", "elif", "hasattr", "(", "obj", ",", "'is_cuda'", ")", ":", "\n", "        ", "return", "obj", ".", "is_cuda", "\n", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "'unrecognized type ({}) in args'", ".", "format", "(", "type", "(", "obj", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2.is_cuda_consistent": [[41, 63], ["dict", "carlini_wagner_L2.get_cuda_state", "dict.get"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.get_cuda_state"], ["", "", "def", "is_cuda_consistent", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    See if the cuda states are consistent among variables (of type either\n    tensors or torch.autograd.Variable). For example,\n        import torch\n        from torch.autograd import Variable\n        import torch.nn as nn\n        net = nn.Linear(512, 10)\n        tensor = torch.rand(10, 10).cuda()\n        assert not is_cuda_consistent(net=net, tensor=tensor)\n    :param args: the variables to test\n    :return: True if len(args) == 0 or the cuda states of all elements in args\n             are consistent; False otherwise\n    \"\"\"", "\n", "result", "=", "dict", "(", ")", "\n", "for", "v", "in", "args", ":", "\n", "        ", "cur_cuda_state", "=", "get_cuda_state", "(", "v", ")", "\n", "cuda_state", "=", "result", ".", "get", "(", "'cuda'", ",", "cur_cuda_state", ")", "\n", "if", "cur_cuda_state", "is", "not", "cuda_state", ":", "\n", "            ", "return", "False", "\n", "", "result", "[", "'cuda'", "]", "=", "cur_cuda_state", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2.make_cuda_consistent": [[64, 95], ["operator.methodcaller", "list", "tuple", "carlini_wagner_L2.get_cuda_state", "ValueError", "carlini_wagner_L2.get_cuda_state", "list.append", "type", "isinstance", "ValueError", "isinstance", "operator.methodcaller.", "operator.methodcaller."], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.get_cuda_state", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.get_cuda_state"], ["", "def", "make_cuda_consistent", "(", "refobj", ",", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    Attempt to make the cuda states of args consistent with that of ``refobj``.\n    If any element of args is a Variable and the cuda state of the element is\n    inconsistent with ``refobj``, raise ValueError, since changing the cuda state\n    of a Variable involves rewrapping it in a new Variable, which changes the\n    semantics of the code.\n    :param refobj: either the referential object or the cuda state of the\n           referential object\n    :param args: the variables to test\n    :return: tuple of the same data as ``args`` but on the same device as\n             ``refobj``\n    \"\"\"", "\n", "ref_cuda_state", "=", "refobj", "if", "type", "(", "refobj", ")", "is", "bool", "else", "get_cuda_state", "(", "refobj", ")", "\n", "if", "ref_cuda_state", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "'cannot determine the cuda state of `refobj` ({})'", "\n", ".", "format", "(", "refobj", ")", ")", "\n", "", "move_to_device", "=", "methodcaller", "(", "'cuda'", "if", "ref_cuda_state", "else", "'cpu'", ")", "\n", "\n", "result_args", "=", "list", "(", ")", "\n", "for", "v", "in", "args", ":", "\n", "        ", "cuda_state", "=", "get_cuda_state", "(", "v", ")", "\n", "if", "cuda_state", "!=", "ref_cuda_state", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "Variable", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'cannot change cuda state of a Variable'", ")", "\n", "", "elif", "isinstance", "(", "v", ",", "nn", ".", "Module", ")", ":", "\n", "                ", "move_to_device", "(", "v", ")", "\n", "", "else", ":", "\n", "                ", "v", "=", "move_to_device", "(", "v", ")", "\n", "", "", "result_args", ".", "append", "(", "v", ")", "\n", "", "return", "tuple", "(", "result_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2.predict": [[96, 109], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "model", "carlini_wagner_L2.make_cuda_consistent", "torch.max", "torch.max", "torch.max"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.make_cuda_consistent"], ["", "def", "predict", "(", "model", ",", "inputs", ")", ":", "\n", "    ", "\"\"\"\n    Predict labels. The cuda state of `net` decides that of the returned\n    prediction tensor.\n    :param model: the network\n    :param inputs: the input tensor (non Variable), of dimension [B x C x W x H]\n    :return: prediction tensor (LongTensor), of dimension [B]\n    \"\"\"", "\n", "inputs", "=", "make_cuda_consistent", "(", "model", ",", "inputs", ")", "[", "0", "]", "\n", "inputs_var", "=", "torch", ".", "Tensor", "(", "inputs", ")", "\n", "outputs_var", "=", "model", "(", "inputs_var", ")", "\n", "predictions", "=", "torch", ".", "max", "(", "outputs_var", ".", "data", ",", "dim", "=", "1", ")", "[", "1", "]", "\n", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2._var2numpy": [[111, 121], ["var.detach().cpu().numpy", "var.detach().cpu", "var.detach"], "function", ["None"], ["", "def", "_var2numpy", "(", "var", ")", ":", "\n", "    ", "\"\"\"\n    Make Variable to numpy array. No transposition will be made.\n\n    :param var: Variable instance on whatever device\n    :type var: Variable\n    :return: the corresponding numpy array\n    :rtype: np.ndarray\n    \"\"\"", "\n", "return", "var", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2.atanh": [[123, 133], ["torch.log", "torch.log", "torch.log"], "function", ["None"], ["", "def", "atanh", "(", "x", ",", "eps", "=", "1e-6", ")", ":", "\n", "    ", "\"\"\"\n    The inverse hyperbolic tangent function, missing in pytorch.\n\n    :param x: a tensor or a Variable\n    :param eps: used to enhance numeric stability\n    :return: :math:`\\\\tanh^{-1}{x}`, of the same type as ``x``\n    \"\"\"", "\n", "x", "=", "x", "*", "(", "1", "-", "eps", ")", "\n", "return", "0.5", "*", "torch", ".", "log", "(", "(", "1.0", "+", "x", ")", "/", "(", "1.0", "-", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2.to_tanh_space": [[134, 148], ["carlini_wagner_L2.atanh"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.atanh"], ["", "def", "to_tanh_space", "(", "x", ",", "box", ")", ":", "\n", "# type: (Union[Variable, torch.FloatTensor], Tuple[float, float]) -> Union[Variable, torch.FloatTensor]", "\n", "    ", "\"\"\"\n    Convert a batch of tensors to tanh-space. This method complements the\n    implementation of the change-of-variable trick in terms of tanh.\n\n    :param x: the batch of tensors, of dimension [B x C x H x W]\n    :param box: a tuple of lower bound and upper bound of the box constraint\n    :return: the batch of tensors in tanh-space, of the same dimension;\n             the returned tensor is on the same device as ``x``\n    \"\"\"", "\n", "_box_mul", "=", "(", "box", "[", "1", "]", "-", "box", "[", "0", "]", ")", "*", "0.5", "\n", "_box_plus", "=", "(", "box", "[", "1", "]", "+", "box", "[", "0", "]", ")", "*", "0.5", "\n", "return", "atanh", "(", "(", "x", "-", "_box_plus", ")", "/", "_box_mul", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2.from_tanh_space": [[149, 164], ["torch.tanh", "torch.tanh", "torch.tanh"], "function", ["None"], ["", "def", "from_tanh_space", "(", "x", ",", "box", ")", ":", "\n", "# type: (Union[Variable, torch.FloatTensor], Tuple[float, float]) -> Union[Variable, torch.FloatTensor]", "\n", "    ", "\"\"\"\n    Convert a batch of tensors from tanh-space to oridinary image space.\n    This method complements the implementation of the change-of-variable trick\n    in terms of tanh.\n\n    :param x: the batch of tensors, of dimension [B x C x H x W]\n    :param box: a tuple of lower bound and upper bound of the box constraint\n    :return: the batch of tensors in ordinary image space, of the same\n             dimension; the returned tensor is on the same device as ``x``\n    \"\"\"", "\n", "_box_mul", "=", "(", "box", "[", "1", "]", "-", "box", "[", "0", "]", ")", "*", "0.5", "\n", "_box_plus", "=", "(", "box", "[", "1", "]", "+", "box", "[", "0", "]", ")", "*", "0.5", "\n", "return", "torch", ".", "tanh", "(", "x", ")", "*", "_box_mul", "+", "_box_plus", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.iterative_FGSM_neural_fingerprint.IterativeFastGradientSignUntargeted.__init__": [[19, 27], ["iterative_FGSM_neural_fingerprint.IterativeFastGradientSignUntargeted.model.eval"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model", ",", "alpha", "=", "0.01", ",", "max_iters", "=", "10", ",", "lambd", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "# Movement multiplier per iteration", "\n", "self", ".", "alpha", "=", "alpha", "\n", "# Create the folder to export images if not exists", "\n", "self", ".", "max_iters", "=", "max_iters", "\n", "self", ".", "lambd", "=", "lambd", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.iterative_FGSM_neural_fingerprint.IterativeFastGradientSignUntargeted.generate": [[28, 68], ["torch.nn.CrossEntropyLoss", "x.detach().cuda", "range", "processed_image.detach.detach.detach", "iterative_FGSM_neural_fingerprint.IterativeFastGradientSignUntargeted.model.zero_grad", "iterative_FGSM_neural_fingerprint.IterativeFastGradientSignUntargeted.model", "torch.nn.CrossEntropyLoss.", "nn.CrossEntropyLoss.backward", "x.detach", "torch.sign"], "methods", ["None"], ["", "def", "generate", "(", "self", ",", "x", ",", "orig_class", ",", "target", ",", "addition_loss", "=", "None", ")", ":", "\n", "# Define loss functions", "\n", "        ", "ce_loss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "# Process image", "\n", "processed_image", "=", "x", ".", "detach", "(", ")", ".", "cuda", "(", ")", "\n", "# Start iteration", "\n", "for", "i", "in", "range", "(", "self", ".", "max_iters", ")", ":", "\n", "# zero_gradients(x)", "\n", "# Zero out previous gradients", "\n", "# Can also use zero_gradients(x)", "\n", "            ", "last_proceed_img", "=", "processed_image", "\n", "processed_image", "=", "processed_image", ".", "detach", "(", ")", "\n", "del", "last_proceed_img", "\n", "processed_image", ".", "requires_grad", "=", "True", "\n", "processed_image", ".", "grad", "=", "None", "\n", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "# Forward pass", "\n", "out", "=", "self", ".", "model", "(", "processed_image", ")", "\n", "# Calculate CE loss", "\n", "pred_loss", "=", "ce_loss", "(", "out", ",", "orig_class", ")", "\n", "if", "addition_loss", "is", "not", "None", ":", "\n", "                ", "pred_loss", "+=", "self", ".", "lambd", "*", "addition_loss", "\n", "# Do backward pass", "\n", "", "pred_loss", ".", "backward", "(", ")", "\n", "# Create Noise", "\n", "# Here, processed_image.grad.data is also the same thing is the backward gradient from", "\n", "# the first layer, can use that with hooks as well", "\n", "adv_noise", "=", "self", ".", "alpha", "*", "torch", ".", "sign", "(", "processed_image", ".", "grad", ")", "\n", "# Add Noise to processed image", "\n", "processed_image", "=", "processed_image", "+", "adv_noise", "\n", "\n", "# Confirming if the image is indeed adversarial with added noise", "\n", "# This is necessary (for some cases) because when we recreate image", "\n", "# the values become integers between 1 and 255 and sometimes the adversariality", "\n", "# is lost in the recreation process", "\n", "# if gen_correct:", "\n", "#     break", "\n", "del", "out", "\n", "del", "pred_loss", "\n", "", "return", "processed_image", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.iterative_FGSM_neural_fingerprint.IterativeFastGradientSignTargetedFingerprint.__init__": [[77, 85], ["iterative_FGSM_neural_fingerprint.IterativeFastGradientSignTargetedFingerprint.model.eval"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model", ",", "alpha", ",", "max_iters", "=", "10", ",", "neural_fp", "=", "None", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "max_iters", "=", "max_iters", "\n", "# Movement multiplier per iteration", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "lambd", "=", "1.0", "\n", "self", ".", "neural_fp", "=", "neural_fp", "\n", "# Create the folder to export images if not exists", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.iterative_FGSM_neural_fingerprint.IterativeFastGradientSignTargetedFingerprint.generate": [[87, 128], ["torch.nn.CrossEntropyLoss", "x.detach().cuda", "range", "processed_image.detach.detach.detach", "iterative_FGSM_neural_fingerprint.IterativeFastGradientSignTargetedFingerprint.model.zero_grad", "iterative_FGSM_neural_fingerprint.IterativeFastGradientSignTargetedFingerprint.model", "torch.nn.CrossEntropyLoss.", "iterative_FGSM_neural_fingerprint.IterativeFastGradientSignTargetedFingerprint.neural_fp.get_all_loss", "nn.CrossEntropyLoss.backward", "x.detach", "torch.sign"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.get_all_loss"], ["", "def", "generate", "(", "self", ",", "x", ",", "orig_class", ",", "target", ")", ":", "\n", "# I honestly dont know a better way to create a variable with specific value", "\n", "# Targeting the specific class", "\n", "# Define loss functions", "\n", "        ", "ce_loss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "# Process image", "\n", "processed_image", "=", "x", ".", "detach", "(", ")", ".", "cuda", "(", ")", "\n", "# Start iteration", "\n", "gen_correct", "=", "False", "\n", "for", "i", "in", "range", "(", "self", ".", "max_iters", ")", ":", "\n", "# zero_gradients(x)", "\n", "# Zero out previous gradients", "\n", "# Can also use zero_gradients(x)", "\n", "            ", "last_proceed_img", "=", "processed_image", "\n", "processed_image", "=", "processed_image", ".", "detach", "(", ")", "\n", "del", "last_proceed_img", "\n", "processed_image", ".", "requires_grad", "=", "True", "\n", "processed_image", ".", "grad", "=", "None", "\n", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "# Forward pass", "\n", "out", "=", "self", ".", "model", "(", "processed_image", ")", "\n", "# Calculate CE loss", "\n", "pred_loss", "=", "ce_loss", "(", "out", ",", "target", ")", "\n", "_", ",", "_", ",", "_", ",", "loss_fingerprint_dy", "=", "self", ".", "neural_fp", ".", "get_all_loss", "(", "self", ".", "neural_fp", ".", "model", ",", "processed_image", ",", "orig_class", ",", "epoch", "=", "3", ")", "\n", "pred_loss", "+=", "self", ".", "lambd", "*", "loss_fingerprint_dy", "\n", "# Do backward pass", "\n", "pred_loss", ".", "backward", "(", ")", "\n", "# Create Noise", "\n", "# Here, processed_image.grad.data is also the same thing is the backward gradient from", "\n", "# the first layer, can use that with hooks as well", "\n", "adv_noise", "=", "self", ".", "alpha", "*", "torch", ".", "sign", "(", "processed_image", ".", "grad", ")", "\n", "# Add noise to processed image", "\n", "processed_image", "=", "processed_image", "-", "adv_noise", "\n", "\n", "# Confirming if the image is indeed adversarial with added noise", "\n", "# This is necessary (for some cases) because when we recreate image", "\n", "# the values become integers between 1 and 255 and sometimes the adversariality", "\n", "# is lost in the recreation process", "\n", "del", "out", "\n", "del", "pred_loss", "\n", "", "return", "processed_image", "\n", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.generate_white_box_attack.build_meta_adv_detector": [[53, 64], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "print", "networks.conv3.Conv3", "networks.conv3.Conv3.load_state_dict", "networks.conv3.Conv3.cuda"], "function", ["None"], ["def", "build_meta_adv_detector", "(", "dataset", ",", "arch", ",", "adv_arch", ",", "shot", ",", "protocol", ")", ":", "\n", "# extract_pattern = re.compile(", "\n", "#     \".*/MAML@(.*?)_(.*?)@model_(.*?)@data.*?@epoch_(\\d+)@meta_batch_size_(\\d+)@way_(\\d+)@shot_(\\d+)@num_query_(\\d+)@num_updates_(\\d+)@lr_(.*?)@inner_lr_(.*?)@fixed_way_(.*?)@rotate_(.*?)\\.pth.tar\")", "\n", "# str2bool = lambda v: v.lower() in (\"yes\", \"true\", \"t\", \"1\")", "\n", "    ", "model_path", "=", "\"{}/train_pytorch_model/white_box_model/MAML@{}_{}@model_{}@data_{}@epoch_4@meta_batch_size_30@way_2@shot_{}@num_query_35@num_updates_12@lr_0.0001@inner_lr_0.001@fixed_way_True@rotate_False.pth.tar\"", ".", "format", "(", "PY_ROOT", ",", "dataset", ",", "protocol", ",", "arch", ",", "adv_arch", ",", "shot", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "print", "(", "\"load {} to detector\"", ".", "format", "(", "model_path", ")", ")", "\n", "network", "=", "Conv3", "(", "IN_CHANNELS", "[", "dataset", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", ",", "2", ")", "\n", "network", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ",", "strict", "=", "True", ")", "\n", "network", ".", "cuda", "(", ")", "\n", "return", "network", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.generate_white_box_attack.build_DNN_detector": [[66, 74], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "print", "networks.conv3.Conv3", "networks.conv3.Conv3.load_state_dict", "networks.conv3.Conv3.cuda"], "function", ["None"], ["", "def", "build_DNN_detector", "(", "dataset", ",", "arch", ",", "adv_arch", ",", "protocol", ")", ":", "\n", "    ", "model_path", "=", "\"{}/train_pytorch_model/white_box_model/DL_DET@{}_{}@model_{}@data_{}@epoch_40@class_2@lr_0.0001@balance_True.pth.tar\"", ".", "format", "(", "PY_ROOT", ",", "dataset", ",", "protocol", ",", "arch", ",", "adv_arch", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "print", "(", "\"load {} to detector\"", ".", "format", "(", "model_path", ")", ")", "\n", "network", "=", "Conv3", "(", "IN_CHANNELS", "[", "dataset", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", ",", "2", ")", "\n", "network", ".", "load_state_dict", "(", "checkpoint", "[", "\"state_dict\"", "]", ",", "strict", "=", "True", ")", "\n", "network", ".", "cuda", "(", ")", "\n", "return", "network", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.generate_white_box_attack.build_rotate_detector": [[76, 88], ["networks.conv3.Conv3", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "print", "image_rotate_detector.image_rotate.ImageTransformTorch", "image_rotate_detector.rotate_detector.Detector", "image_rotate_detector.rotate_detector.Detector.load_state_dict", "image_rotate_detector.rotate_detector.Detector.cuda"], "function", ["None"], ["", "def", "build_rotate_detector", "(", "dataset", ",", "arch", ",", "adv_arch", ",", "protocol", ")", ":", "\n", "    ", "img_classifier_network", "=", "Conv3", "(", "IN_CHANNELS", "[", "dataset", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", ",", "\n", "CLASS_NUM", "[", "dataset", "]", ")", "\n", "model_path", "=", "\"{}/train_pytorch_model/white_box_model/IMG_ROTATE_DET@{}_{}@model_{}@data_{}@epoch_10@lr_0.0001@batch_100@no_fix_cnn_params.pth.tar\"", ".", "format", "(", "PY_ROOT", ",", "dataset", ",", "protocol", ",", "arch", ",", "adv_arch", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "print", "(", "\"load {} to detector\"", ".", "format", "(", "model_path", ")", ")", "\n", "image_transform", "=", "ImageTransformTorch", "(", "dataset", ",", "[", "5", ",", "15", "]", ")", "\n", "layer_number", "=", "3", "if", "dataset", "in", "[", "\"CIFAR-10\"", ",", "\"CIFAR-100\"", ",", "\"SVHN\"", "]", "else", "2", "\n", "detector", "=", "Detector", "(", "dataset", ",", "img_classifier_network", ",", "CLASS_NUM", "[", "dataset", "]", ",", "image_transform", ",", "layer_number", ")", "\n", "detector", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ",", "strict", "=", "True", ")", "\n", "detector", ".", "cuda", "(", ")", "\n", "return", "detector", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.generate_white_box_attack.confirm_attack_untarget_success": [[89, 108], ["model.max", "model.max", "adv_pred.detach().cpu().numpy.detach().cpu().numpy", "orig_pred.detach().cpu().numpy.detach().cpu().numpy", "gt_label.detach().cpu().numpy.detach().cpu().numpy", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model", "model", "numpy.where", "adv_pred.detach().cpu().numpy.detach().cpu", "orig_pred.detach().cpu().numpy.detach().cpu", "gt_label.detach().cpu().numpy.detach().cpu", "adv_pred.detach().cpu().numpy.detach", "orig_pred.detach().cpu().numpy.detach", "gt_label.detach().cpu().numpy.detach"], "function", ["None"], ["", "def", "confirm_attack_untarget_success", "(", "adv_x", ",", "x", ",", "model", ",", "gt_label", ")", ":", "\n", "# Generate confirmation image", "\n", "# Process confirmation image", "\n", "# Forward pass", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "adv_out", "=", "model", "(", "adv_x", ")", "\n", "orig_out", "=", "model", "(", "x", ")", "\n", "# Get prediction", "\n", "", "_", ",", "adv_pred", "=", "adv_out", ".", "max", "(", "1", ")", "\n", "_", ",", "orig_pred", "=", "orig_out", ".", "max", "(", "1", ")", "\n", "# Convert tensor to int", "\n", "adv_pred", "=", "adv_pred", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "orig_pred", "=", "orig_pred", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "gt_label", "=", "gt_label", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "indexes", "=", "np", ".", "where", "(", "gt_label", "==", "orig_pred", ")", "[", "0", "]", "\n", "# Check if the prediction is different than the original", "\n", "gen_correct", "=", "(", "adv_pred", "!=", "gt_label", ")", "\n", "return", "gen_correct", ",", "adv_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.generate_white_box_attack.build_neural_fingerprint_detector": [[112, 124], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "print", "networks.conv3.Conv3", "networks.conv3.Conv3.load_state_dict", "networks.conv3.Conv3.cuda", "neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector", "glob.glob"], "function", ["None"], ["", "def", "build_neural_fingerprint_detector", "(", "dataset", ",", "arch", ",", "eps", "=", "0.1", ",", "num_dx", "=", "5", ")", ":", "\n", "    ", "output_dx_dy_dir", "=", "\"{}/NF_dx_dy\"", ".", "format", "(", "PY_ROOT", ")", "\n", "model_path", "=", "\"{}/train_pytorch_model/white_box_model/NF_Det@{}@{}*.pth.tar\"", ".", "format", "(", "PY_ROOT", ",", "dataset", ",", "arch", ")", "\n", "model_path", "=", "glob", ".", "glob", "(", "model_path", ")", "[", "0", "]", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "print", "(", "\"load {} to detector\"", ".", "format", "(", "model_path", ")", ")", "\n", "network", "=", "Conv3", "(", "IN_CHANNELS", "[", "dataset", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", ",", "CLASS_NUM", "[", "dataset", "]", ")", "\n", "network", ".", "load_state_dict", "(", "checkpoint", "[", "\"state_dict\"", "]", ")", "\n", "network", ".", "cuda", "(", ")", "\n", "detector", "=", "NeuralFingerprintDetector", "(", "dataset", ",", "network", ",", "num_dx", ",", "CLASS_NUM", "[", "dataset", "]", ",", "eps", "=", "eps", ",", "\n", "out_fp_dxdy_dir", "=", "output_dx_dy_dir", ")", "\n", "return", "detector", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.generate_white_box_attack.main": [[126, 195], ["parser.parse_args", "str", "toolkit.img_transform.get_preprocessor", "print", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "networks.conv3.Conv3.load_state_dict", "print", "networks.conv3.Conv3.eval", "networks.conv3.Conv3.cuda", "generate_white_box_attack.generate", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "networks.resnet.resnet10", "generate_white_box_attack.build_meta_adv_detector", "build_neural_fingerprint_detector.eval", "white_box_attack.combined_model.CombinedModel", "white_box_attack.combined_model.CombinedModel.cuda", "white_box_attack.combined_model.CombinedModel.eval", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "networks.resnet.resnet18", "generate_white_box_attack.build_DNN_detector", "white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint", "white_box_attack.carlini_wagner_L2.CarliniWagnerL2", "torchvision.datasets.FashionMNIST", "torchvision.datasets.FashionMNIST", "networks.conv3.Conv3", "generate_white_box_attack.build_rotate_detector", "white_box_attack.iterative_FGSM_neural_fingerprint.IterativeFastGradientSignTargetedFingerprint", "white_box_attack.iterative_FGSM.IterativeFastGradientSignTargeted", "dataset.SVHN_dataset.SVHN", "dataset.SVHN_dataset.SVHN", "generate_white_box_attack.build_neural_fingerprint_detector"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.train_fingerprint.parse_args", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.toolkit.img_transform.get_preprocessor", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint.generate", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet10", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.generate_white_box_attack.build_meta_adv_detector", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet18", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.generate_white_box_attack.build_DNN_detector", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.generate_white_box_attack.build_rotate_detector", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.generate_white_box_attack.build_neural_fingerprint_detector"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "os", ".", "environ", "[", "\"CUDA_DEVICE_ORDER\"", "]", "=", "\"PCI_BUS_ID\"", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "str", "(", "args", ".", "gpu", ")", "\n", "preprocessor", "=", "get_preprocessor", "(", "input_channels", "=", "IN_CHANNELS", "[", "args", ".", "dataset", "]", ")", "\n", "\n", "if", "args", ".", "dataset", "==", "\"CIFAR-10\"", ":", "\n", "        ", "train_dataset", "=", "datasets", ".", "CIFAR10", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "dataset", "]", ",", "train", "=", "True", ",", "transform", "=", "preprocessor", ")", "\n", "val_dataset", "=", "datasets", ".", "CIFAR10", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "dataset", "]", ",", "train", "=", "False", ",", "transform", "=", "preprocessor", ")", "\n", "", "elif", "args", ".", "dataset", "==", "\"MNIST\"", ":", "\n", "        ", "train_dataset", "=", "datasets", ".", "MNIST", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "dataset", "]", ",", "train", "=", "True", ",", "transform", "=", "preprocessor", ",", "download", "=", "True", ")", "\n", "val_dataset", "=", "datasets", ".", "MNIST", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "dataset", "]", ",", "train", "=", "False", ",", "transform", "=", "preprocessor", ",", "download", "=", "True", ")", "\n", "", "elif", "args", ".", "dataset", "==", "\"F-MNIST\"", ":", "\n", "        ", "train_dataset", "=", "datasets", ".", "FashionMNIST", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "dataset", "]", ",", "train", "=", "True", ",", "transform", "=", "preprocessor", ",", "download", "=", "True", ")", "\n", "val_dataset", "=", "datasets", ".", "FashionMNIST", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "dataset", "]", ",", "train", "=", "False", ",", "transform", "=", "preprocessor", ",", "download", "=", "True", ")", "\n", "", "elif", "args", ".", "dataset", "==", "\"SVHN\"", ":", "\n", "        ", "train_dataset", "=", "SVHN", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "dataset", "]", ",", "train", "=", "True", ",", "transform", "=", "preprocessor", ")", "\n", "val_dataset", "=", "SVHN", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "dataset", "]", ",", "train", "=", "False", ",", "transform", "=", "preprocessor", ")", "\n", "\n", "# load image classifier model", "\n", "", "img_classifier_model_path", "=", "\"{}/train_pytorch_model/DL_IMAGE_CLASSIFIER_{}@{}@epoch_40@lr_0.0001@batch_500.pth.tar\"", ".", "format", "(", "PY_ROOT", ",", "\n", "args", ".", "dataset", ",", "args", ".", "adv_arch", ")", "\n", "if", "args", ".", "adv_arch", "==", "\"resnet10\"", ":", "\n", "        ", "img_classifier_network", "=", "resnet10", "(", "num_classes", "=", "CLASS_NUM", "[", "args", ".", "dataset", "]", ",", "in_channels", "=", "IN_CHANNELS", "[", "args", ".", "dataset", "]", ")", "\n", "", "elif", "args", ".", "adv_arch", "==", "\"resnet18\"", ":", "\n", "        ", "img_classifier_network", "=", "resnet18", "(", "num_classes", "=", "CLASS_NUM", "[", "args", ".", "dataset", "]", ",", "in_channels", "=", "IN_CHANNELS", "[", "args", ".", "dataset", "]", ")", "\n", "", "elif", "args", ".", "adv_arch", "==", "\"conv3\"", ":", "\n", "        ", "img_classifier_network", "=", "Conv3", "(", "IN_CHANNELS", "[", "args", ".", "dataset", "]", ",", "IMAGE_SIZE", "[", "args", ".", "dataset", "]", ",", "CLASS_NUM", "[", "args", ".", "dataset", "]", ")", "\n", "\n", "\n", "", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "img_classifier_model_path", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "img_classifier_model_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "img_classifier_network", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {}) for img classifier\"", "\n", ".", "format", "(", "img_classifier_model_path", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "img_classifier_network", ".", "eval", "(", ")", "\n", "img_classifier_network", "=", "img_classifier_network", ".", "cuda", "(", ")", "\n", "\n", "# load detector model", "\n", "if", "args", ".", "detector", "==", "\"MetaAdvDet\"", ":", "\n", "# \u5982\u679c\u653b\u51fbfinetune\u540e\u7684model\uff0c\u5219\u9700\u8981\u52a8\u6001\u751f\u6210\u566a\u97f3\uff0c\u6bcf\u6b21support\u4e0afinetune\u4e4b\u540e\uff0c\u8fc5\u901f\u8fdb\u884c\u653b\u51fb\u751f\u6210\u65b0\u7684\u5bf9\u6297\u6837\u672c", "\n", "        ", "detector_net", "=", "build_meta_adv_detector", "(", "args", ".", "dataset", ",", "args", ".", "det_arch", ",", "args", ".", "adv_arch", ",", "args", ".", "shot", ",", "args", ".", "protocol", ")", "# \u9700\u8981\u5728support\u4e0afine-tune\u540e\u8fdb\u884c\u68c0\u6d4b\uff0c\u5230\u5e95\u653b\u51fbfinetune\u540e\u7684\u8fd8\u662ffinetune\u524d\u7684", "\n", "", "elif", "args", ".", "detector", "==", "\"DNN\"", ":", "\n", "        ", "detector_net", "=", "build_DNN_detector", "(", "args", ".", "dataset", ",", "args", ".", "det_arch", ",", "args", ".", "adv_arch", ",", "args", ".", "protocol", ")", "\n", "", "elif", "args", ".", "detector", "==", "\"RotateDet\"", ":", "\n", "        ", "detector_net", "=", "build_rotate_detector", "(", "args", ".", "dataset", ",", "args", ".", "det_arch", ",", "args", ".", "adv_arch", ",", "args", ".", "protocol", ")", "\n", "", "elif", "args", ".", "detector", "==", "\"NeuralFP\"", ":", "\n", "        ", "detector_net", "=", "build_neural_fingerprint_detector", "(", "args", ".", "dataset", ",", "args", ".", "det_arch", ")", "\n", "\n", "", "if", "args", ".", "detector", "==", "\"NeuralFP\"", ":", "\n", "        ", "if", "args", ".", "attack", "==", "\"CW_L2\"", ":", "\n", "            ", "attack", "=", "CarliniWagnerL2Fingerprint", "(", "img_classifier_network", ",", "targeted", "=", "True", ",", "confidence", "=", "0.3", ",", "search_steps", "=", "30", ",", "\n", "max_steps", "=", "args", ".", "atk_max_iter", ",", "optimizer_lr", "=", "0.01", ",", "neural_fp", "=", "detector_net", ")", "\n", "", "elif", "args", ".", "attack", "==", "\"FGSM\"", ":", "\n", "            ", "attack", "=", "IterativeFastGradientSignTargetedFingerprint", "(", "img_classifier_network", ",", "alpha", "=", "0.01", ",", "\n", "max_iters", "=", "args", ".", "atk_max_iter", ",", "neural_fp", "=", "detector_net", ")", "\n", "", "", "else", ":", "\n", "        ", "detector_net", ".", "eval", "(", ")", "\n", "combined_model", "=", "CombinedModel", "(", "img_classifier_network", ",", "detector_net", ")", "\n", "combined_model", ".", "cuda", "(", ")", "\n", "combined_model", ".", "eval", "(", ")", "\n", "if", "args", ".", "attack", "==", "\"CW_L2\"", ":", "\n", "            ", "attack", "=", "CarliniWagnerL2", "(", "combined_model", ",", "True", ",", "confidence", "=", "0.3", ",", "search_steps", "=", "30", ",", "max_steps", "=", "args", ".", "atk_max_iter", ",", "optimizer_lr", "=", "0.01", ")", "\n", "", "elif", "args", ".", "attack", "==", "\"FGSM\"", ":", "\n", "            ", "attack", "=", "IterativeFastGradientSignTargeted", "(", "combined_model", ",", "alpha", "=", "0.01", ",", "max_iters", "=", "args", ".", "atk_max_iter", ")", "\n", "\n", "", "", "generate", "(", "attack", ",", "args", ".", "attack", ",", "args", ".", "dataset", ",", "args", ".", "detector", ",", "val_dataset", ",", "\n", "output_dir", "=", "\"{}/adversarial_images/white_box@data_{}@det_{}\"", ".", "format", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "dataset", "]", ",", "\n", "args", ".", "adv_arch", ",", "args", ".", "detector", ")", ",", "args", "=", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.generate_white_box_attack.generate": [[196, 257], ["os.makedirs", "torch.utils.data.DataLoader", "numpy.array", "numpy.array", "numpy.array", "numpy.savez", "numpy.savez", "print", "x.cuda.detach().cpu().numpy", "np.array.extend", "range", "np.array.extend", "x.cuda.cuda", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "adv_target_label.cuda.cuda", "attacker.generate", "numpy.where", "numpy.where", "len", "np.array.append", "label.detach().cpu().numpy", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "attacker.model", "attacker.model.max", "orig_pred.detach().cpu().numpy.detach().cpu().numpy", "enumerate", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "adv_x.detach().cpu().numpy.cuda", "attacker.model", "attacker.model.max", "adv_pred.detach().cpu().numpy.detach().cpu().numpy", "label.detach().cpu().numpy", "adv_x.detach().cpu().numpy.detach().cpu().numpy", "enumerate", "numpy.ones", "numpy.zeros", "x.cuda.detach().cpu", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "random.choice", "label.detach().cpu", "x.cuda.size", "orig_pred.detach().cpu().numpy.detach().cpu", "list", "list", "adv_pred.detach().cpu().numpy.detach().cpu", "label.detach().cpu", "adv_x.detach().cpu().numpy.detach().cpu", "np.array.append", "np.array.append", "np.array.append", "x.cuda.detach", "range", "range", "label.detach", "orig_pred.detach().cpu().numpy.detach", "adv_pred.detach().cpu().numpy.detach", "label.detach", "adv_x.detach().cpu().numpy.detach"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint.generate"], ["", "def", "generate", "(", "attacker", ",", "attack_name", ",", "dataset", ",", "detector_name", ",", "val_dataset", ",", "output_dir", ",", "args", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "# generate one by one", "\n", "batch_size", "=", "100", "\n", "val_loader", "=", "DataLoader", "(", "val_dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ",", "num_workers", "=", "0", ",", "pin_memory", "=", "True", ")", "\n", "\n", "all_x_list", "=", "[", "]", "\n", "labels_list", "=", "[", "]", "\n", "all_gt_labels", "=", "[", "]", "\n", "for", "x", ",", "label", "in", "val_loader", ":", "# label\u5c31\u662f\u539f\u59cb\u56fe\u50cf\u7684\u5206\u7c7blabel", "\n", "        ", "real_x", "=", "x", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "all_x_list", ".", "extend", "(", "real_x", ")", "\n", "for", "_", "in", "range", "(", "len", "(", "real_x", ")", ")", ":", "\n", "            ", "labels_list", ".", "append", "(", "1", ")", "\n", "", "all_gt_labels", ".", "extend", "(", "label", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "# \u653b\u51fb\u6210label=10\uff0c\u5219\u8ba4\u4e3a\u662f\u767d\u76d2\u653b\u51fb\u6210\u529f\uff0c\u5bf9\u6297\u6837\u672c", "\n", "x", "=", "x", ".", "cuda", "(", ")", "\n", "adv_target_label", "=", "torch", ".", "zeros", "(", "x", ".", "size", "(", "0", ")", ")", ".", "long", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "orig_out", "=", "attacker", ".", "model", "(", "x", ")", "\n", "_", ",", "orig_pred", "=", "orig_out", ".", "max", "(", "1", ")", "\n", "orig_pred", "=", "orig_pred", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "idx", ",", "orig_label", "in", "enumerate", "(", "orig_pred", ")", ":", "\n", "                ", "r", "=", "list", "(", "range", "(", "0", ",", "orig_label", ")", ")", "+", "list", "(", "range", "(", "orig_label", "+", "1", ",", "CLASS_NUM", "[", "dataset", "]", ")", ")", "\n", "adv_target_label", "[", "idx", "]", "=", "random", ".", "choice", "(", "r", ")", "\n", "", "", "adv_target_label", "=", "adv_target_label", ".", "cuda", "(", ")", "# ! \u653b\u51fb\u76ee\u6807\uff0c\u65e2\u8981\u8ba9\u539f\u59cb\u6a21\u578b\u9519\u8bef\u5206\u7c7b\uff0c\u4e5f\u8981\u8ba9detector\u8ba4\u4e3a\u8fd8\u662f\u4e2a\u5e72\u51c0\u5f97\u56fe\u7247", "\n", "\n", "adv_x", "=", "attacker", ".", "generate", "(", "x", ",", "label", ",", "adv_target_label", ")", "# \u4e00\u5f8b\u653b\u51fb\u51fa\u4e00\u4e2alabel = 10\u7684\uff0c\u8868\u793a\u662f\u5bf9\u6297\u6837\u672c", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "adv_x", "=", "adv_x", ".", "cuda", "(", ")", "\n", "adv_out", "=", "attacker", ".", "model", "(", "adv_x", ")", "\n", "_", ",", "adv_pred", "=", "adv_out", ".", "max", "(", "1", ")", "\n", "adv_pred", "=", "adv_pred", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "gt_labels", "=", "label", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "adv_x", "=", "adv_x", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "idx", ",", "adv_label", "in", "enumerate", "(", "adv_pred", ")", ":", "\n", "                ", "orig_label", "=", "orig_pred", "[", "idx", "]", "\n", "if", "adv_label", "!=", "orig_label", "and", "adv_label", "!=", "gt_labels", "[", "idx", "]", "and", "adv_label", "!=", "CLASS_NUM", "[", "dataset", "]", ":", "\n", "                    ", "labels_list", ".", "append", "(", "0", ")", "\n", "all_x_list", ".", "append", "(", "adv_x", "[", "idx", "]", ")", "\n", "all_gt_labels", ".", "append", "(", "gt_labels", "[", "idx", "]", ")", "\n", "", "", "", "", "all_x_list", "=", "np", ".", "array", "(", "all_x_list", ")", "\n", "labels_list", "=", "np", ".", "array", "(", "labels_list", ")", "\n", "all_gt_labels", "=", "np", ".", "array", "(", "all_gt_labels", ")", "\n", "clean_index", "=", "np", ".", "where", "(", "labels_list", "==", "1", ")", "[", "0", "]", "\n", "adv_index", "=", "np", ".", "where", "(", "labels_list", "==", "0", ")", "[", "0", "]", "\n", "\n", "clean_imgs", "=", "all_x_list", "[", "clean_index", "]", "\n", "gt_clean", "=", "all_gt_labels", "[", "clean_index", "]", "\n", "\n", "adv_imgs", "=", "all_x_list", "[", "adv_index", "]", "\n", "gt_adv", "=", "all_gt_labels", "[", "adv_index", "]", "\n", "\n", "clean_file_name", "=", "output_dir", "+", "\"/clean_{}@det_{}@protocol_{}@shot_{}@white_box.npz\"", ".", "format", "(", "dataset", ",", "detector_name", ",", "args", ".", "protocol", ",", "args", ".", "shot", ")", "\n", "adv_file_name", "=", "output_dir", "+", "\"/{}_{}@det_{}@protocol_{}@shot_{}@white_box.npz\"", ".", "format", "(", "attack_name", ",", "dataset", ",", "detector_name", ",", "args", ".", "protocol", ",", "args", ".", "shot", ")", "\n", "np", ".", "savez", "(", "clean_file_name", ",", "adv_images", "=", "clean_imgs", ",", "adv_label", "=", "np", ".", "ones", "(", "shape", "=", "clean_imgs", ".", "shape", "[", "0", "]", ")", ",", "gt_label", "=", "gt_clean", ")", "\n", "np", ".", "savez", "(", "adv_file_name", ",", "adv_images", "=", "adv_imgs", ",", "adv_label", "=", "np", ".", "zeros", "(", "shape", "=", "adv_imgs", ".", "shape", "[", "0", "]", ")", ",", "gt_label", "=", "gt_adv", ")", "\n", "\n", "print", "(", "\"done, save to {} and {}\"", ".", "format", "(", "clean_file_name", ",", "adv_file_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.adversary_dataset.CleanImgDataset.__init__": [[8, 27], ["glob.glob", "numpy.load", "numpy.arange", "print", "adversary_dataset.CleanImgDataset.img_label_list.append"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root_path", ",", "train", ",", "protocol", ")", ":", "\n", "        ", "self", ".", "root_path", "=", "root_path", "\n", "filter_str", "=", "\"train\"", "\n", "if", "not", "train", ":", "\n", "            ", "filter_str", "=", "\"test\"", "\n", "", "self", ".", "cache", "=", "{", "}", "\n", "self", ".", "img_label_list", "=", "[", "]", "\n", "for", "npz_path", "in", "glob", ".", "glob", "(", "root_path", "+", "\"/*{}.npz\"", ".", "format", "(", "filter_str", ")", ")", ":", "\n", "            ", "if", "\"clean\"", "not", "in", "npz_path", ":", "\n", "                ", "continue", "\n", "", "data", "=", "np", ".", "load", "(", "npz_path", ")", "\n", "gt_label", "=", "data", "[", "\"gt_label\"", "]", "\n", "adv_images", "=", "data", "[", "\"adv_images\"", "]", "\n", "self", ".", "cache", "[", "npz_path", "]", "=", "adv_images", "\n", "indexes", "=", "np", ".", "arange", "(", "adv_images", ".", "shape", "[", "0", "]", ")", "\n", "for", "index", "in", "indexes", ":", "\n", "                ", "label", "=", "gt_label", "[", "index", "]", "\n", "self", ".", "img_label_list", ".", "append", "(", "(", "npz_path", ",", "index", ",", "label", ")", ")", "\n", "", "print", "(", "\"{} done\"", ".", "format", "(", "npz_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.adversary_dataset.CleanImgDataset.__len__": [[29, 31], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "img_label_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.adversary_dataset.CleanImgDataset.__getitem__": [[33, 46], ["numpy.transpose", "numpy.load"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "npz_path", ",", "index", ",", "label", "=", "self", ".", "img_label_list", "[", "item", "]", "\n", "if", "npz_path", "in", "self", ".", "cache", ":", "\n", "            ", "adv_images", "=", "self", ".", "cache", "[", "npz_path", "]", "\n", "", "else", ":", "\n", "            ", "data", "=", "np", ".", "load", "(", "npz_path", ")", "\n", "adv_images", "=", "data", "[", "\"adv_images\"", "]", "# 10000,32,32,3", "\n", "self", ".", "cache", "[", "npz_path", "]", "=", "adv_images", "\n", "\n", "", "adv_image", "=", "adv_images", "[", "index", "]", "\n", "adv_image", "=", "np", ".", "transpose", "(", "adv_image", ",", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "\n", "return", "adv_image", ",", "label", "\n", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.adaptive_attack.adaptive_fgsm": [[5, 27], ["pickle.load", "pickle.load", "model", "np.shape", "open", "open", "model.max", "os.path.join", "os.path.join"], "function", ["None"], ["def", "adaptive_fgsm", "(", "model", ",", "x", ",", "fingerprint_dir", ",", "eps", ",", "clip_min", "=", "None", ",", "clip_max", "=", "None", ",", "\n", "target", "=", "None", ",", "model_logits", "=", "None", ",", "alpha", "=", "None", ",", "dataset", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n        Computes symbolic TF tensor for the adversarial samples. This must\n        be evaluated with a session.run call.\n        :param x: the input placeholder\n        :param eps: the epsilon (input variation parameter)\n        :param clip_min: optional parameter that can be used to set a minimum\n                        value for components of the example returned\n        :param clip_max: optional parameter that can be used to set a maximum\n                        value for components of the example returned\n        :param y: the output placeholder. Use None (the default) to avoid the\n                label leaking effect.\n        :return: a tensor for the adversarial example\n        \"\"\"", "\n", "fixed_dxs", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "fingerprint_dir", ",", "\"fp_inputs_dx.pkl\"", ")", ",", "\"rb\"", ")", ")", "\n", "fixed_dys", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "fingerprint_dir", ",", "\"fp_outputs.pkl\"", ")", ",", "\"rb\"", ")", ")", "\n", "y", "=", "model", "(", "x", ")", "\n", "pred_class", "=", "y", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "loss_fp", "=", "0", "\n", "[", "a", ",", "b", ",", "c", "]", "=", "np", ".", "shape", "(", "fixed_dys", ")", "\n", "num_dx", "=", "b", "\n", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint.__init__": [[232, 322], ["copy.deepcopy", "float", "tuple", "len", "TypeError", "ValueError", "float", "float", "map"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model", "=", "None", ",", "targeted", "=", "True", ",", "confidence", "=", "0.0", ",", "c_range", "=", "(", "1e-3", ",", "1e10", ")", ",", "\n", "search_steps", "=", "5", ",", "max_steps", "=", "1000", ",", "abort_early", "=", "True", ",", "\n", "optimizer_lr", "=", "1e-2", ",", "init_rand", "=", "False", ",", "neural_fp", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param model: nn.Module the model network we want to attack\n        :param targeted: ``True`` to perform targeted attack in ``self.run``\n               method\n        :type targeted: bool\n        :param confidence: the confidence constant, i.e. the $\\\\kappa$ in paper\n        :type confidence: float\n        :param c_range: the search range of the constant :math:`c`; should be a\n               tuple of form (lower_bound, upper_bound)\n        :type c_range: Tuple[float, float]\n        :param search_steps: the number of steps to perform binary search of\n               the constant :math:`c` over ``c_range``\n        :type search_steps: int\n        :param max_steps: the maximum number of optimization steps for each\n               constant :math:`c`\n        :type max_steps: int\n        :param abort_early: ``True`` to abort early in process of searching for\n               :math:`c` when the loss virtually stops increasing\n        :type abort_early: bool\n        :param learning_rate: the base learning rate of the Adam optimizer used\n               over the adversarial perturbation in clipped space\n        :type learning_rate: float\n        :param init_rand: ``True`` to initialize perturbation to small Gaussian;\n               False is consistent with the original paper, where the\n               perturbation is initialized to zero\n        :type init_rand: bool\n        :rtype: None\n\n        Why to make ``box`` default to (-1., 1.) rather than (0., 1.)? TL;DR the\n        domain of the problem in pytorch is [-1, 1] instead of [0, 1].\n        According to Xiang Xu (samxucmu@gmail.com)::\n\n        > The reason is that in pytorch a transformation is applied first\n        > before getting the input from the data loader. So image in range [0,1]\n        > will subtract some mean and divide by std. The normalized input image\n        > will now be in range [-1,1]. For this implementation, clipping is\n        > actually performed on the image after normalization, not on the\n        > original image.\n\n        Why to ``optimizer_lr`` default to 1e-2? The optimizer used in Carlini's\n        code adopts 1e-2. In another pytorch implementation\n        (https://github.com/rwightman/pytorch-nips2017-attack-example.git),\n        though, the learning rate is set to 5e-4.\n        \"\"\"", "\n", "# mean = [0.485, 0.456, 0.406]", "\n", "# std = [0.229, 0.224, 0.225]", "\n", "# box = (min((0 - m) / s for m, s in zip(mean, std)),", "\n", "#               max((1 - m) / s for m, s in zip(mean, std)))", "\n", "box", "=", "(", "-", "2.4", ",", "2.7", ")", "\n", "if", "len", "(", "c_range", ")", "!=", "2", ":", "\n", "            ", "raise", "TypeError", "(", "'c_range ({}) should be of form '", "\n", "'tuple([lower_bound, upper_bound])'", "\n", ".", "format", "(", "c_range", ")", ")", "\n", "", "if", "c_range", "[", "0", "]", ">=", "c_range", "[", "1", "]", ":", "\n", "            ", "raise", "ValueError", "(", "'c_range lower bound ({}) is expected to be less '", "\n", "'than c_range upper bound ({})'", ".", "format", "(", "*", "c_range", ")", ")", "\n", "# if len(box) != 2:", "\n", "#     raise TypeError('box ({}) should be of form '", "\n", "#                     'tuple([lower_bound, upper_bound])'", "\n", "#                     .format(box))", "\n", "# if box[0] >= box[1]:", "\n", "#     raise ValueError('box lower bound ({}) is expected to be less than '", "\n", "#                      'box upper bound ({})'.format(*box))", "\n", "", "self", ".", "model", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "self", ".", "targeted", "=", "targeted", "\n", "self", ".", "confidence", "=", "float", "(", "confidence", ")", "\n", "self", ".", "c_range", "=", "(", "float", "(", "c_range", "[", "0", "]", ")", ",", "float", "(", "c_range", "[", "1", "]", ")", ")", "\n", "self", ".", "binary_search_steps", "=", "search_steps", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "abort_early", "=", "abort_early", "\n", "self", ".", "ae_tol", "=", "1e-4", "# tolerance of early abort", "\n", "self", ".", "box", "=", "tuple", "(", "map", "(", "float", ",", "box", ")", ")", "# type: Tuple[float, float]", "\n", "self", ".", "optimizer_lr", "=", "optimizer_lr", "\n", "\n", "# `self.init_rand` is not in Carlini's code, it's an attempt in the", "\n", "# referencing pytorch implementation to improve the quality of attacks.", "\n", "self", ".", "init_rand", "=", "init_rand", "\n", "\n", "# Since the larger the `scale_const` is, the more likely a successful", "\n", "# attack can be found, `self.repeat` guarantees at least attempt the", "\n", "# largest scale_const once. Moreover, since the optimal criterion is the", "\n", "# L2 norm of the attack, and the larger `scale_const` is, the larger", "\n", "# the L2 norm is, thus less optimal, the last attempt at the largest", "\n", "# `scale_const` won't ruin the optimum ever found.", "\n", "self", ".", "repeat", "=", "(", "self", ".", "binary_search_steps", ">=", "10", ")", "\n", "self", ".", "lambd", "=", "1.0", "\n", "self", ".", "neural_fp", "=", "neural_fp", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint.generate": [[323, 482], ["x.cuda().detach", "x.cuda().detach.size", "numpy.zeros", "x.cuda().detach.cpu().detach().numpy", "carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._to_tanh_space", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda.scatter_", "torch.zeros().cuda.scatter_", "torch.zeros().cuda.scatter_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.Adam", "torch.Adam", "torch.Adam", "range", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "len", "len", "target.clone().cpu().numpy", "orig_class.clone().cpu().numpy", "carlini_wagner_L2_neural_fingerprint.make_cuda_consistent", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint.model().size", "numpy.ones", "numpy.ones", "numpy.ones", "numpy.ones", "carlini_wagner_L2_neural_fingerprint.make_cuda_consistent", "target.unsqueeze", "torch.init.normal", "torch.init.normal", "torch.init.normal", "carlini_wagner_L2_neural_fingerprint.make_cuda_consistent", "torch.from_numpy().cuda().float", "torch.from_numpy().cuda().float", "torch.from_numpy().cuda().float", "torch.from_numpy().cuda().float", "torch.from_numpy().cuda().float", "torch.from_numpy().cuda().float", "torch.from_numpy().cuda().float", "torch.from_numpy().cuda().float", "torch.from_numpy().cuda().float", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "range", "range", "x.cuda", "x.cuda().detach.size", "target.size", "carlini_wagner_L2_neural_fingerprint.make_cuda_consistent", "carlini_wagner_L2_neural_fingerprint.make_cuda_consistent", "x.cuda().detach.cpu().detach", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "carlini_wagner_L2_neural_fingerprint.make_cuda_consistent", "numpy.ones", "numpy.ones", "carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._optimize", "numpy.argmax", "numpy.argmax", "range", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "target.clone().cpu", "orig_class.clone().cpu", "carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint.model", "x.cuda().detach.size", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._compensate_confidence", "carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._attack_successful", "carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._attack_successful", "carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._attack_successful", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "x.cuda().detach.cpu", "target.size", "target.clone", "orig_class.clone", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.copy"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._to_tanh_space", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.make_cuda_consistent", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.make_cuda_consistent", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.make_cuda_consistent", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.make_cuda_consistent", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.make_cuda_consistent", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.make_cuda_consistent", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._optimize", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._compensate_confidence", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._attack_successful", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._attack_successful", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._attack_successful"], ["", "def", "generate", "(", "self", ",", "x", ",", "orig_class", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        Produce adversarial examples for ``inputs``.\n\n        :param x: the processed images tensor, of dimension [B x C x H x W].\n               ``x`` can be on either CPU or GPU, but it will eventually be\n               moved to the same device as the one the parameters of ``model``\n               reside\n        :type inputs: torch.FloatTensor\n        :param target: the original image labels, or the attack targets, of\n               dimension [B]. If ``self.targeted`` is ``True``, then ``targets``\n               is treated as the attack targets, otherwise the labels.\n               ``targets`` can be on either CPU or GPU, but it will eventually\n               be moved to the same device as the one the parameters of\n               ``model`` reside\n        :type target: torch.LongTensor\n        :param to_numpy: True to return an `np.ndarray`, otherwise,\n               `torch.FloatTensor`\n        :type to_numpy: bool\n        :return: the adversarial examples on CPU, of dimension [B x C x H x W]\n        \"\"\"", "\n", "# sanity check", "\n", "# inputs = torch.from_numpy(orig_img).unsqueeze(0).float().cuda()  # B,H,W,C", "\n", "# inputs = inputs.permute(0,3,1,2)", "\n", "inputs", "=", "x", ".", "cuda", "(", ")", ".", "detach", "(", ")", "\n", "assert", "len", "(", "inputs", ".", "size", "(", ")", ")", "==", "4", "\n", "assert", "len", "(", "target", ".", "size", "(", ")", ")", "==", "1", "\n", "\n", "# get a copy of targets in numpy before moving to GPU, used when doing", "\n", "# the binary search on `scale_const`", "\n", "if", "self", ".", "targeted", ":", "\n", "            ", "targets_np", "=", "target", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "# type: np.ndarray", "\n", "target", "=", "make_cuda_consistent", "(", "self", ".", "model", ",", "target", ")", "[", "0", "]", "# type: torch.FloatTensor", "\n", "", "else", ":", "\n", "            ", "targets_np", "=", "orig_class", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "# type: np.ndarray", "\n", "target", "=", "make_cuda_consistent", "(", "self", ".", "model", ",", "orig_class", ")", "[", "0", "]", "# type: torch.FloatTensor", "\n", "# the type annotations here are used only for type hinting and do", "\n", "# not indicate the actual type (cuda or cpu); same applies to all codes", "\n", "# below", "\n", "", "inputs", "=", "make_cuda_consistent", "(", "self", ".", "model", ",", "inputs", ")", "[", "0", "]", "# type: torch.FloatTensor", "\n", "# run the model a little bit to get the `num_classes`", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "num_classes", "=", "self", ".", "model", "(", "Variable", "(", "inputs", "[", "0", "]", "[", "None", ",", ":", "]", ",", "requires_grad", "=", "False", ")", ")", ".", "size", "(", "1", ")", "# type: int", "\n", "", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", "# type: int", "\n", "\n", "# `lower_bounds_np`, `upper_bounds_np` and `scale_consts_np` are used", "\n", "# for binary search of each `scale_const` in the batch. The element-wise", "\n", "# inquality holds: lower_bounds_np < scale_consts_np <= upper_bounds_np", "\n", "lower_bounds_np", "=", "np", ".", "zeros", "(", "batch_size", ")", "\n", "upper_bounds_np", "=", "np", ".", "ones", "(", "batch_size", ")", "*", "self", ".", "c_range", "[", "1", "]", "\n", "scale_consts_np", "=", "np", ".", "ones", "(", "batch_size", ")", "*", "self", ".", "c_range", "[", "0", "]", "\n", "\n", "# Optimal attack to be found.", "\n", "# The three \"placeholders\" are defined as:", "\n", "# - `o_best_l2`: the least L2 norms", "\n", "# - `o_best_l2_ppred`: the perturbed predictions made by the adversarial", "\n", "#    perturbations with the least L2 norms", "\n", "# - `o_best_advx`: the underlying adversarial example of", "\n", "#   `o_best_l2_ppred`", "\n", "o_best_l2", "=", "np", ".", "ones", "(", "batch_size", ")", "*", "np", ".", "inf", "\n", "o_best_l2_ppred", "=", "-", "np", ".", "ones", "(", "batch_size", ")", "# type: np.ndarray", "\n", "o_best_advx", "=", "inputs", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "# type: np.ndarray", "\n", "\n", "# convert `inputs` to tanh-space", "\n", "inputs_tanh", "=", "self", ".", "_to_tanh_space", "(", "inputs", ")", "# type: torch.FloatTensor", "\n", "inputs_tanh_var", "=", "Variable", "(", "inputs_tanh", ",", "requires_grad", "=", "False", ")", "\n", "\n", "# the one-hot encoding of `targets`", "\n", "targets_oh", "=", "torch", ".", "zeros", "(", "target", ".", "size", "(", ")", "+", "(", "num_classes", ",", ")", ")", ".", "cuda", "(", ")", "# type: torch.FloatTensor", "\n", "targets_oh", "=", "make_cuda_consistent", "(", "self", ".", "model", ",", "targets_oh", ")", "[", "0", "]", "\n", "targets_oh", ".", "scatter_", "(", "1", ",", "target", ".", "unsqueeze", "(", "1", ")", ",", "1.0", ")", "\n", "\n", "targets_oh_var", "=", "Variable", "(", "targets_oh", ",", "requires_grad", "=", "False", ")", "\n", "\n", "# the perturbation variable to optimize.", "\n", "# `pert_tanh` is essentially the adversarial perturbation in tanh-space.", "\n", "# In Carlini's code it's denoted as `modifier`", "\n", "pert_tanh", "=", "torch", ".", "zeros", "(", "inputs", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", "# type: torch.FloatTensor", "\n", "if", "self", ".", "init_rand", ":", "\n", "            ", "nn", ".", "init", ".", "normal", "(", "pert_tanh", ",", "mean", "=", "0", ",", "std", "=", "1e-3", ")", "\n", "", "pert_tanh", "=", "make_cuda_consistent", "(", "self", ".", "model", ",", "pert_tanh", ")", "[", "0", "]", "\n", "pert_tanh_var", "=", "Variable", "(", "pert_tanh", ",", "requires_grad", "=", "True", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "[", "pert_tanh_var", "]", ",", "lr", "=", "self", ".", "optimizer_lr", ")", "\n", "for", "sstep", "in", "range", "(", "self", ".", "binary_search_steps", ")", ":", "\n", "            ", "if", "self", ".", "repeat", "and", "sstep", "==", "self", ".", "binary_search_steps", "-", "1", ":", "\n", "                ", "scale_consts_np", "=", "upper_bounds_np", "\n", "", "scale_consts", "=", "torch", ".", "from_numpy", "(", "np", ".", "copy", "(", "scale_consts_np", ")", ")", ".", "cuda", "(", ")", ".", "float", "(", ")", "# type: torch.FloatTensor", "\n", "scale_consts", "=", "make_cuda_consistent", "(", "self", ".", "model", ",", "scale_consts", ")", "[", "0", "]", "\n", "scale_consts_var", "=", "Variable", "(", "scale_consts", ",", "requires_grad", "=", "False", ")", "\n", "\n", "# the minimum L2 norms of perturbations found during optimization", "\n", "best_l2", "=", "np", ".", "ones", "(", "batch_size", ")", "*", "np", ".", "inf", "\n", "# the perturbed predictions corresponding to `best_l2`, to be used", "\n", "# in binary search of `scale_const`", "\n", "best_l2_ppred", "=", "-", "np", ".", "ones", "(", "batch_size", ")", "# type: np.ndarray", "\n", "# previous (summed) batch loss, to be used in early stopping policy", "\n", "prev_batch_loss", "=", "np", ".", "inf", "# type: float", "\n", "for", "optim_step", "in", "range", "(", "self", ".", "max_steps", ")", ":", "\n", "                ", "batch_loss", ",", "pert_norms_np", ",", "pert_outputs_np", ",", "advxs_np", "=", "self", ".", "_optimize", "(", "self", ".", "model", ",", "optimizer", ",", "inputs_tanh_var", ",", "\n", "pert_tanh_var", ",", "targets_oh_var", ",", "\n", "scale_consts_var", ",", "orig_class", ")", "\n", "\n", "\n", "if", "self", ".", "abort_early", "and", "not", "optim_step", "%", "(", "self", ".", "max_steps", "//", "10", ")", ":", "\n", "                    ", "if", "batch_loss", ">", "prev_batch_loss", "*", "(", "1", "-", "self", ".", "ae_tol", ")", ":", "\n", "                        ", "break", "\n", "", "prev_batch_loss", "=", "batch_loss", "\n", "\n", "# update best attack found during optimization", "\n", "", "pert_predictions_np", "=", "np", ".", "argmax", "(", "pert_outputs_np", ",", "axis", "=", "1", ")", "\n", "comp_pert_predictions_np", "=", "np", ".", "argmax", "(", "\n", "self", ".", "_compensate_confidence", "(", "pert_outputs_np", ",", "\n", "targets_np", ")", ",", "\n", "axis", "=", "1", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "l2", "=", "pert_norms_np", "[", "i", "]", "\n", "cppred", "=", "comp_pert_predictions_np", "[", "i", "]", "\n", "ppred", "=", "pert_predictions_np", "[", "i", "]", "\n", "tlabel", "=", "targets_np", "[", "i", "]", "\n", "ax", "=", "advxs_np", "[", "i", "]", "\n", "if", "self", ".", "_attack_successful", "(", "cppred", ",", "tlabel", ")", ":", "\n", "                        ", "assert", "cppred", "==", "ppred", "\n", "if", "l2", "<", "best_l2", "[", "i", "]", ":", "\n", "                            ", "best_l2", "[", "i", "]", "=", "l2", "\n", "best_l2_ppred", "[", "i", "]", "=", "ppred", "\n", "", "if", "l2", "<", "o_best_l2", "[", "i", "]", ":", "\n", "                            ", "o_best_l2", "[", "i", "]", "=", "l2", "\n", "o_best_l2_ppred", "[", "i", "]", "=", "ppred", "\n", "o_best_advx", "[", "i", "]", "=", "ax", "\n", "\n", "# binary search of `scale_const`", "\n", "", "", "", "", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "tlabel", "=", "targets_np", "[", "i", "]", "\n", "assert", "best_l2_ppred", "[", "i", "]", "==", "-", "1", "or", "self", ".", "_attack_successful", "(", "best_l2_ppred", "[", "i", "]", ",", "tlabel", ")", "\n", "assert", "o_best_l2_ppred", "[", "i", "]", "==", "-", "1", "or", "self", ".", "_attack_successful", "(", "o_best_l2_ppred", "[", "i", "]", ",", "tlabel", ")", "\n", "if", "best_l2_ppred", "[", "i", "]", "!=", "-", "1", ":", "\n", "# successful; attempt to lower `scale_const` by halving it", "\n", "                    ", "if", "scale_consts_np", "[", "i", "]", "<", "upper_bounds_np", "[", "i", "]", ":", "\n", "                        ", "upper_bounds_np", "[", "i", "]", "=", "scale_consts_np", "[", "i", "]", "\n", "# `upper_bounds_np[i] == c_range[1]` implies no solution", "\n", "# found, i.e. upper_bounds_np[i] has never been updated by", "\n", "# scale_consts_np[i] until", "\n", "# `scale_consts_np[i] > 0.1 * c_range[1]`", "\n", "", "if", "upper_bounds_np", "[", "i", "]", "<", "self", ".", "c_range", "[", "1", "]", "*", "0.1", ":", "\n", "                        ", "scale_consts_np", "[", "i", "]", "=", "(", "lower_bounds_np", "[", "i", "]", "+", "upper_bounds_np", "[", "i", "]", ")", "/", "2", "\n", "", "", "else", ":", "\n", "# failure; multiply `scale_const` by ten if no solution", "\n", "# found; otherwise do binary search", "\n", "                    ", "if", "scale_consts_np", "[", "i", "]", ">", "lower_bounds_np", "[", "i", "]", ":", "\n", "                        ", "lower_bounds_np", "[", "i", "]", "=", "scale_consts_np", "[", "i", "]", "\n", "", "if", "upper_bounds_np", "[", "i", "]", "<", "self", ".", "c_range", "[", "1", "]", "*", "0.1", ":", "\n", "                        ", "scale_consts_np", "[", "i", "]", "=", "(", "lower_bounds_np", "[", "i", "]", "+", "upper_bounds_np", "[", "i", "]", ")", "/", "2", "\n", "", "else", ":", "\n", "                        ", "scale_consts_np", "[", "i", "]", "*=", "10", "\n", "", "", "", "", "o_best_advx", "=", "torch", ".", "from_numpy", "(", "o_best_advx", ")", ".", "float", "(", ")", "\n", "return", "o_best_advx", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._optimize": [[484, 578], ["carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._from_tanh_space", "model", "carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._from_tanh_space", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint.neural_fp.get_all_loss", "optimizer.zero_grad", "torch.sum.backward", "torch.sum.backward", "torch.sum.backward", "optimizer.step", "torch.sum.item", "torch.sum.item", "torch.sum.item", "carlini_wagner_L2_neural_fingerprint._var2numpy", "carlini_wagner_L2_neural_fingerprint._var2numpy", "carlini_wagner_L2_neural_fingerprint._var2numpy", "torch.sum.view", "torch.sum.view", "torch.sum.view", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.sum.size", "torch.sum.size", "torch.sum.size", "model.max"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._from_tanh_space", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._from_tanh_space", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.get_all_loss", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint._var2numpy", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint._var2numpy", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint._var2numpy"], ["", "def", "_optimize", "(", "self", ",", "model", ",", "optimizer", ",", "inputs_tanh_var", ",", "pert_tanh_var", ",", "\n", "targets_oh_var", ",", "c_var", ",", "img_gt", ")", ":", "\n", "        ", "\"\"\"\n        Optimize for one step.\n\n        :param model: the model to attack\n        :type model: nn.Module\n        :param optimizer: the Adam optimizer to optimize ``modifier_var``\n        :type optimizer: optim.Adam\n        :param inputs_tanh_var: the input images in tanh-space\n        :type inputs_tanh_var: torch.FloatTensor\n        :param pert_tanh_var: the perturbation to optimize in tanh-space,\n               ``pert_tanh_var.requires_grad`` flag must be set to True\n        :type pert_tanh_var: torch.FloatTensor\n        :param targets_oh_var: the one-hot encoded target tensor (the attack\n               targets if self.targeted else image labels)\n        :type targets_oh_var: torch.FloatTensor\n        :param c_var: the constant :math:`c` for each perturbation of a batch,\n               a FloatTensor of dimension [B]\n        :type c_var: torch.FloatTensor\n        :return: the batch loss, squared L2-norm of adversarial perturbations\n                 (of dimension [B]), the perturbed activations (of dimension\n                 [B]), the adversarial examples (of dimension [B x C x H x W])\n        \"\"\"", "\n", "# the adversarial examples in the image space", "\n", "# of dimension [B x C x H x W]", "\n", "advxs_var", "=", "self", ".", "_from_tanh_space", "(", "inputs_tanh_var", "+", "pert_tanh_var", ")", "\n", "# the perturbed activation before softmax", "\n", "pert_outputs_var", "=", "model", "(", "advxs_var", ")", "\n", "# the original inputs", "\n", "inputs_var", "=", "self", ".", "_from_tanh_space", "(", "inputs_tanh_var", ")", "\n", "\n", "perts_norm_var", "=", "torch", ".", "pow", "(", "advxs_var", "-", "inputs_var", ",", "2", ")", "\n", "perts_norm_var", "=", "torch", ".", "sum", "(", "perts_norm_var", ".", "view", "(", "\n", "perts_norm_var", ".", "size", "(", "0", ")", ",", "-", "1", ")", ",", "1", ")", "\n", "\n", "# In Carlini's code, `target_activ_var` is called `real`.", "\n", "# It should be a Variable of tensor of dimension [B], such that the", "\n", "# `target_activ_var[i]` is the final activation (right before softmax)", "\n", "# of the $t$th class, where $t$ is the attack target or the image label", "\n", "#", "\n", "# noinspection PyArgumentList", "\n", "target_activ_var", "=", "torch", ".", "sum", "(", "targets_oh_var", "*", "pert_outputs_var", ",", "1", ")", "\n", "inf", "=", "1e4", "# sadly pytorch does not work with np.inf;", "\n", "# 1e4 is also used in Carlini's code", "\n", "# In Carlini's code, `maxother_activ_var` is called `other`.", "\n", "# It should be a Variable of tensor of dimension [B], such that the", "\n", "# `maxother_activ_var[i]` is the maximum final activation of all classes", "\n", "# other than class $t$, where $t$ is the attack target or the image", "\n", "# label.", "\n", "#", "\n", "# The assertion here ensures (sufficiently yet not necessarily) the", "\n", "# assumption behind the trick to get `maxother_activ_var` holds, that", "\n", "# $\\max_{i \\ne t}{o_i} \\ge -\\text{_inf}$, where $t$ is the target and", "\n", "# $o_i$ the $i$th element along axis=1 of `pert_outputs_var`.", "\n", "#", "\n", "# noinspection PyArgumentList", "\n", "assert", "(", "pert_outputs_var", ".", "max", "(", "1", ")", "[", "0", "]", ">=", "-", "inf", ")", ".", "all", "(", ")", ",", "'assumption failed'", "\n", "# noinspection PyArgumentList", "\n", "maxother_activ_var", "=", "torch", ".", "max", "(", "(", "(", "1", "-", "targets_oh_var", ")", "*", "pert_outputs_var", "\n", "-", "targets_oh_var", "*", "inf", ")", ",", "1", ")", "[", "0", "]", "\n", "\n", "# Compute $f(x')$, where $x'$ is the adversarial example in image space.", "\n", "# The result `f_var` should be of dimension [B]", "\n", "if", "self", ".", "targeted", ":", "\n", "# if targeted, optimize to make `target_activ_var` larger than", "\n", "# `maxother_activ_var` by `self.confidence`", "\n", "#", "\n", "# noinspection PyArgumentList", "\n", "            ", "f_var", "=", "torch", ".", "clamp", "(", "maxother_activ_var", "-", "target_activ_var", "\n", "+", "self", ".", "confidence", ",", "min", "=", "0.0", ")", "\n", "", "else", ":", "\n", "# if not targeted, optimize to make `maxother_activ_var` larger than", "\n", "# `target_activ_var` (the ground truth image labels) by", "\n", "# `self.confidence`", "\n", "#", "\n", "# noinspection PyArgumentList", "\n", "            ", "f_var", "=", "torch", ".", "clamp", "(", "target_activ_var", "-", "maxother_activ_var", "\n", "+", "self", ".", "confidence", ",", "min", "=", "0.0", ")", "\n", "# the total loss of current batch, should be of dimension [1]", "\n", "", "batch_loss_var", "=", "torch", ".", "sum", "(", "perts_norm_var", "+", "c_var", "*", "f_var", ")", "# type: torch.Tensor", "\n", "_", ",", "_", ",", "_", ",", "loss_fingerprint_dy", "=", "self", ".", "neural_fp", ".", "get_all_loss", "(", "self", ".", "neural_fp", ".", "model", ",", "advxs_var", ",", "img_gt", ",", "epoch", "=", "3", ")", "\n", "batch_loss_var", "+=", "self", ".", "lambd", "*", "loss_fingerprint_dy", "\n", "# Do optimization for one step", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "batch_loss_var", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Make some records in python/numpy on CPU", "\n", "batch_loss", "=", "batch_loss_var", ".", "item", "(", ")", "\n", "pert_norms_np", "=", "_var2numpy", "(", "perts_norm_var", ")", "\n", "pert_outputs_np", "=", "_var2numpy", "(", "pert_outputs_var", ")", "\n", "advxs_np", "=", "_var2numpy", "(", "advxs_var", ")", "\n", "return", "batch_loss", ",", "pert_norms_np", ",", "pert_outputs_np", ",", "advxs_np", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._attack_successful": [[579, 594], ["None"], "methods", ["None"], ["", "def", "_attack_successful", "(", "self", ",", "prediction", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        See whether the underlying attack is successful.\n\n        :param prediction: the prediction of the model on an input\n        :type prediction: int\n        :param target: either the attack target or the ground-truth image label\n        :type target: int\n        :return: ``True`` if the attack is successful\n        :rtype: bool\n        \"\"\"", "\n", "if", "self", ".", "targeted", ":", "\n", "            ", "return", "prediction", "==", "target", "\n", "", "else", ":", "\n", "            ", "return", "prediction", "!=", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._compensate_confidence": [[596, 624], ["numpy.copy", "numpy.arange"], "methods", ["None"], ["", "", "def", "_compensate_confidence", "(", "self", ",", "outputs", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Compensate for ``self.confidence`` and returns a new weighted sum\n        vector.\n\n        :param outputs: the weighted sum right before the last layer softmax\n               normalization, of dimension [B x M]\n        :type outputs: np.ndarray\n        :param targets: either the attack targets or the real image labels,\n               depending on whether or not ``self.targeted``, of dimension [B]\n        :type targets: np.ndarray\n        :return: the compensated weighted sum of dimension [B x M]\n        :rtype: np.ndarray\n        \"\"\"", "\n", "outputs_comp", "=", "np", ".", "copy", "(", "outputs", ")", "\n", "rng", "=", "np", ".", "arange", "(", "targets", ".", "shape", "[", "0", "]", ")", "\n", "if", "self", ".", "targeted", ":", "\n", "# for each image $i$:", "\n", "# if targeted, `outputs[i, target_onehot]` should be larger than", "\n", "# `max(outputs[i, ~target_onehot])` by `self.confidence`", "\n", "            ", "outputs_comp", "[", "rng", ",", "targets", "]", "-=", "self", ".", "confidence", "\n", "", "else", ":", "\n", "# for each image $i$:", "\n", "# if not targeted, `max(outputs[i, ~target_onehot]` should be larger", "\n", "# than `outputs[i, target_onehot]` (the ground truth image labels)", "\n", "# by `self.confidence`", "\n", "            ", "outputs_comp", "[", "rng", ",", "targets", "]", "+=", "self", ".", "confidence", "\n", "", "return", "outputs_comp", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._to_tanh_space": [[625, 633], ["carlini_wagner_L2_neural_fingerprint.to_tanh_space"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.to_tanh_space"], ["", "def", "_to_tanh_space", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Convert a batch of tensors to tanh-space.\n\n        :param x: the batch of tensors, of dimension [B x C x H x W]\n        :return: the batch of tensors in tanh-space, of the same dimension\n        \"\"\"", "\n", "return", "to_tanh_space", "(", "x", ",", "self", ".", "box", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint._from_tanh_space": [[634, 643], ["carlini_wagner_L2_neural_fingerprint.from_tanh_space"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.from_tanh_space"], ["", "def", "_from_tanh_space", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Convert a batch of tensors from tanh-space to input space.\n\n        :param x: the batch of tensors, of dimension [B x C x H x W]\n        :return: the batch of tensors in tanh-space, of the same dimension;\n                 the returned tensor is on the same device as ``x``\n        \"\"\"", "\n", "return", "from_tanh_space", "(", "x", ",", "self", ".", "box", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.get_cuda_state": [[22, 39], ["isinstance", "hasattr", "TypeError", "next", "obj.parameters", "type"], "function", ["None"], ["def", "get_cuda_state", "(", "obj", ")", ":", "\n", "    ", "\"\"\"\n    Get cuda state of any object.\n    :param obj: an object (a tensor or an `torch.nn.Module`)\n    :raise TypeError:\n    :return: True if the object or the parameter set of the object\n             is on GPU\n    \"\"\"", "\n", "if", "isinstance", "(", "obj", ",", "nn", ".", "Module", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "next", "(", "obj", ".", "parameters", "(", ")", ")", ".", "is_cuda", "\n", "", "except", "StopIteration", ":", "\n", "            ", "return", "None", "\n", "", "", "elif", "hasattr", "(", "obj", ",", "'is_cuda'", ")", ":", "\n", "        ", "return", "obj", ".", "is_cuda", "\n", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "'unrecognized type ({}) in args'", ".", "format", "(", "type", "(", "obj", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.is_cuda_consistent": [[41, 63], ["dict", "carlini_wagner_L2_neural_fingerprint.get_cuda_state", "dict.get"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.get_cuda_state"], ["", "", "def", "is_cuda_consistent", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    See if the cuda states are consistent among variables (of type either\n    tensors or torch.autograd.Variable). For example,\n        import torch\n        from torch.autograd import Variable\n        import torch.nn as nn\n        net = nn.Linear(512, 10)\n        tensor = torch.rand(10, 10).cuda()\n        assert not is_cuda_consistent(net=net, tensor=tensor)\n    :param args: the variables to test\n    :return: True if len(args) == 0 or the cuda states of all elements in args\n             are consistent; False otherwise\n    \"\"\"", "\n", "result", "=", "dict", "(", ")", "\n", "for", "v", "in", "args", ":", "\n", "        ", "cur_cuda_state", "=", "get_cuda_state", "(", "v", ")", "\n", "cuda_state", "=", "result", ".", "get", "(", "'cuda'", ",", "cur_cuda_state", ")", "\n", "if", "cur_cuda_state", "is", "not", "cuda_state", ":", "\n", "            ", "return", "False", "\n", "", "result", "[", "'cuda'", "]", "=", "cur_cuda_state", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.make_cuda_consistent": [[64, 95], ["operator.methodcaller", "list", "tuple", "carlini_wagner_L2_neural_fingerprint.get_cuda_state", "ValueError", "carlini_wagner_L2_neural_fingerprint.get_cuda_state", "list.append", "type", "isinstance", "ValueError", "isinstance", "operator.methodcaller.", "operator.methodcaller."], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.get_cuda_state", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.get_cuda_state"], ["", "def", "make_cuda_consistent", "(", "refobj", ",", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    Attempt to make the cuda states of args consistent with that of ``refobj``.\n    If any element of args is a Variable and the cuda state of the element is\n    inconsistent with ``refobj``, raise ValueError, since changing the cuda state\n    of a Variable involves rewrapping it in a new Variable, which changes the\n    semantics of the code.\n    :param refobj: either the referential object or the cuda state of the\n           referential object\n    :param args: the variables to test\n    :return: tuple of the same data as ``args`` but on the same device as\n             ``refobj``\n    \"\"\"", "\n", "ref_cuda_state", "=", "refobj", "if", "type", "(", "refobj", ")", "is", "bool", "else", "get_cuda_state", "(", "refobj", ")", "\n", "if", "ref_cuda_state", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "'cannot determine the cuda state of `refobj` ({})'", "\n", ".", "format", "(", "refobj", ")", ")", "\n", "", "move_to_device", "=", "methodcaller", "(", "'cuda'", "if", "ref_cuda_state", "else", "'cpu'", ")", "\n", "\n", "result_args", "=", "list", "(", ")", "\n", "for", "v", "in", "args", ":", "\n", "        ", "cuda_state", "=", "get_cuda_state", "(", "v", ")", "\n", "if", "cuda_state", "!=", "ref_cuda_state", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "Variable", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'cannot change cuda state of a Variable'", ")", "\n", "", "elif", "isinstance", "(", "v", ",", "nn", ".", "Module", ")", ":", "\n", "                ", "move_to_device", "(", "v", ")", "\n", "", "else", ":", "\n", "                ", "v", "=", "move_to_device", "(", "v", ")", "\n", "", "", "result_args", ".", "append", "(", "v", ")", "\n", "", "return", "tuple", "(", "result_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.predict": [[96, 109], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "model", "carlini_wagner_L2_neural_fingerprint.make_cuda_consistent", "torch.max", "torch.max", "torch.max"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.make_cuda_consistent"], ["", "def", "predict", "(", "model", ",", "inputs", ")", ":", "\n", "    ", "\"\"\"\n    Predict labels. The cuda state of `net` decides that of the returned\n    prediction tensor.\n    :param model: the network\n    :param inputs: the input tensor (non Variable), of dimension [B x C x W x H]\n    :return: prediction tensor (LongTensor), of dimension [B]\n    \"\"\"", "\n", "inputs", "=", "make_cuda_consistent", "(", "model", ",", "inputs", ")", "[", "0", "]", "\n", "inputs_var", "=", "torch", ".", "Tensor", "(", "inputs", ")", "\n", "outputs_var", "=", "model", "(", "inputs_var", ")", "\n", "predictions", "=", "torch", ".", "max", "(", "outputs_var", ".", "data", ",", "dim", "=", "1", ")", "[", "1", "]", "\n", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint._var2numpy": [[111, 121], ["var.detach().cpu().numpy", "var.detach().cpu", "var.detach"], "function", ["None"], ["", "def", "_var2numpy", "(", "var", ")", ":", "\n", "    ", "\"\"\"\n    Make Variable to numpy array. No transposition will be made.\n\n    :param var: Variable instance on whatever device\n    :type var: Variable\n    :return: the corresponding numpy array\n    :rtype: np.ndarray\n    \"\"\"", "\n", "return", "var", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.atanh": [[123, 133], ["torch.log", "torch.log", "torch.log"], "function", ["None"], ["", "def", "atanh", "(", "x", ",", "eps", "=", "1e-6", ")", ":", "\n", "    ", "\"\"\"\n    The inverse hyperbolic tangent function, missing in pytorch.\n\n    :param x: a tensor or a Variable\n    :param eps: used to enhance numeric stability\n    :return: :math:`\\\\tanh^{-1}{x}`, of the same type as ``x``\n    \"\"\"", "\n", "x", "=", "x", "*", "(", "1", "-", "eps", ")", "\n", "return", "0.5", "*", "torch", ".", "log", "(", "(", "1.0", "+", "x", ")", "/", "(", "1.0", "-", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.to_tanh_space": [[134, 148], ["carlini_wagner_L2_neural_fingerprint.atanh"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.atanh"], ["", "def", "to_tanh_space", "(", "x", ",", "box", ")", ":", "\n", "# type: (Union[Variable, torch.FloatTensor], Tuple[float, float]) -> Union[Variable, torch.FloatTensor]", "\n", "    ", "\"\"\"\n    Convert a batch of tensors to tanh-space. This method complements the\n    implementation of the change-of-variable trick in terms of tanh.\n\n    :param x: the batch of tensors, of dimension [B x C x H x W]\n    :param box: a tuple of lower bound and upper bound of the box constraint\n    :return: the batch of tensors in tanh-space, of the same dimension;\n             the returned tensor is on the same device as ``x``\n    \"\"\"", "\n", "_box_mul", "=", "(", "box", "[", "1", "]", "-", "box", "[", "0", "]", ")", "*", "0.5", "\n", "_box_plus", "=", "(", "box", "[", "1", "]", "+", "box", "[", "0", "]", ")", "*", "0.5", "\n", "return", "atanh", "(", "(", "x", "-", "_box_plus", ")", "/", "_box_mul", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.from_tanh_space": [[149, 164], ["torch.tanh", "torch.tanh", "torch.tanh"], "function", ["None"], ["", "def", "from_tanh_space", "(", "x", ",", "box", ")", ":", "\n", "# type: (Union[Variable, torch.FloatTensor], Tuple[float, float]) -> Union[Variable, torch.FloatTensor]", "\n", "    ", "\"\"\"\n    Convert a batch of tensors from tanh-space to oridinary image space.\n    This method complements the implementation of the change-of-variable trick\n    in terms of tanh.\n\n    :param x: the batch of tensors, of dimension [B x C x H x W]\n    :param box: a tuple of lower bound and upper bound of the box constraint\n    :return: the batch of tensors in ordinary image space, of the same\n             dimension; the returned tensor is on the same device as ``x``\n    \"\"\"", "\n", "_box_mul", "=", "(", "box", "[", "1", "]", "-", "box", "[", "0", "]", ")", "*", "0.5", "\n", "_box_plus", "=", "(", "box", "[", "1", "]", "+", "box", "[", "0", "]", ")", "*", "0.5", "\n", "return", "torch", ".", "tanh", "(", "x", ")", "*", "_box_mul", "+", "_box_plus", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.combined_model.CombinedModel.__init__": [[7, 12], ["torch.nn.Module.__init__", "torch.nn.Softmax"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "img_classifier", ",", "detector_network", ")", ":", "\n", "        ", "super", "(", "CombinedModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "img_classifier", "=", "img_classifier", "# pretrained_model  \u5982\u679c\u653b\u51fb\u7b97\u6cd5", "\n", "self", ".", "detector", "=", "detector_network", "# pretrained_model", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.combined_model.CombinedModel.forward": [[14, 24], ["combined_model.CombinedModel.img_classifier", "combined_model.CombinedModel.detector", "combined_model.CombinedModel.softmax", "Z_D.unsqueeze.unsqueeze.unsqueeze", "torch.cat", "torch.max"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.softmax"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "logits_img_class", "=", "self", ".", "img_classifier", "(", "x", ")", "# output num class", "\n", "logits_det", "=", "self", ".", "detector", "(", "x", ")", "# \u8f93\u51faN,2 \uff0c\u5982\u679c\u662f\u6b63\u5e38\u6837\u672c\u5219index=1\u5927,\u5426\u5219index=0\u5927", "\n", "soft_det", "=", "self", ".", "softmax", "(", "logits_det", ")", "# \u6bcf\u4e2alogit\u7684\u503c\u90fd\u662f0 -- 1\u4e4b\u95f4", "\n", "Z_D", "=", "soft_det", "[", ":", ",", "0", "]", "# N index=0\u662f\u8868\u793a\u88ab\u8bc6\u522b\u4e3a\u566a\u97f3\u7684\u6982\u7387\uff0c\u5982\u679c>0.5\u5219\u8868\u793a\u662f\u566a\u97f3", "\n", "Z_G", "=", "logits_img_class", "\n", "Z_D", "=", "Z_D", "*", "2", "*", "torch", ".", "max", "(", "Z_G", ",", "dim", "=", "1", ",", "keepdim", "=", "False", ")", "[", "0", "]", "# shape = (N,),\u5982\u679c", "\n", "Z_D", "=", "Z_D", ".", "unsqueeze", "(", "1", ")", "# shape = (N,1)", "\n", "Z_G", "=", "torch", ".", "cat", "(", "[", "Z_G", ",", "Z_D", "]", ",", "dim", "=", "1", ")", "# N, class + 1", "\n", "return", "Z_G", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.combined_model.CombinedModelForNeuralFingerprint.__init__": [[27, 32], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "img_classifier", ",", "detector_network", ",", "attacker", ")", ":", "\n", "        ", "super", "(", "CombinedModelForNeuralFingerprint", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "img_classifier", "=", "img_classifier", "# pretrained_model  \u5982\u679c\u653b\u51fb\u7b97\u6cd5", "\n", "self", ".", "detector", "=", "detector_network", "# pretrained_model", "\n", "self", ".", "attacker", "=", "attacker", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.combined_model.CombinedModelForNeuralFingerprint.forward": [[33, 36], ["combined_model.CombinedModelForNeuralFingerprint.detector.get_all_loss", "combined_model.CombinedModelForNeuralFingerprint.attacker.generate"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.get_all_loss", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.white_box_attack.carlini_wagner_L2_neural_fingerprint.CarliniWagnerL2Fingerprint.generate"], ["", "def", "forward", "(", "self", ",", "x", ",", "img_gt", ",", "target", ")", ":", "\n", "        ", "_", ",", "_", ",", "_", ",", "loss_fingerprint_dy", "=", "self", ".", "detector", ".", "get_all_loss", "(", "self", ".", "detector", ".", "model", ",", "x", ",", "img_gt", ",", "epoch", "=", "3", ")", "\n", "self", ".", "attacker", ".", "generate", "(", "x", ",", "img_gt", ",", "target", ",", "loss_fingerprint_dy", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.deep_learning_adv_detector.gen_train_val_list.genList": [[5, 24], ["open", "open", "open.flush", "open.close", "line.strip.strip", "line.strip.split", "range", "os.path.join", "open", "int", "int", "open.write", "os.path.dirname", "file_obj.read", "arylines[].split", "str"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.close"], ["def", "genList", "(", "fileListPath", ",", "writePath", ",", "split_type", "=", "\"I\"", ",", "type", "=", "\"train\"", ")", ":", "\n", "    ", "fid", "=", "open", "(", "fileListPath", ",", "\"r\"", ")", "\n", "wid", "=", "open", "(", "writePath", ",", "\"w\"", ")", "\n", "root_dir", "=", "\"/home1/machen/dataset/CIFAR-10/split_data_mem\"", "\n", "for", "line", "in", "fid", ":", "\n", "        ", "if", "type", "not", "in", "line", "or", "split_type", "not", "in", "line", ":", "\n", "            ", "continue", "\n", "", "line", "=", "line", ".", "strip", "(", ")", "\n", "count_file_path", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "os", ".", "path", ".", "dirname", "(", "line", ")", ")", "+", "'/count.txt'", "\n", "with", "open", "(", "count_file_path", ",", "\"r\"", ")", "as", "file_obj", ":", "\n", "            ", "count", "=", "int", "(", "file_obj", ".", "read", "(", ")", ")", "\n", "", "arylines", "=", "line", ".", "split", "(", "\"/\"", ")", "\n", "label", "=", "int", "(", "arylines", "[", "2", "]", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", ")", "-", "1", "\n", "if", "label", "!=", "0", ":", "\n", "            ", "label", "=", "1", "\n", "", "for", "i", "in", "range", "(", "count", ")", ":", "\n", "            ", "wid", ".", "write", "(", "line", "+", "\"#{}\"", ".", "format", "(", "i", ")", "+", "\" \"", "+", "str", "(", "label", ")", "+", "\"\\n\"", ")", "\n", "", "", "wid", ".", "flush", "(", ")", "\n", "wid", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.deep_learning_adv_detector.gen_train_val_list.genTaskList": [[26, 42], ["open", "open", "re.compile", "open.flush", "open.close", "line.strip.strip", "re.compile.match", "int", "open.write", "line.strip.split", "pattern.match.group"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.close"], ["", "def", "genTaskList", "(", "fileListPath", ",", "writePath", ",", "split_type", "=", "\"I\"", ",", "type", "=", "\"train\"", ")", ":", "\n", "    ", "fid", "=", "open", "(", "fileListPath", ",", "\"r\"", ")", "\n", "wid", "=", "open", "(", "writePath", ",", "\"w\"", ")", "\n", "pattern", "=", "re", ".", "compile", "(", "\".*?/\\d+_(\\d+)/.*\"", ")", "\n", "for", "line", "in", "fid", ":", "\n", "        ", "if", "type", "not", "in", "line", "or", "split_type", "not", "in", "line", ":", "\n", "            ", "continue", "\n", "", "line", "=", "line", ".", "strip", "(", ")", "\n", "npy_path", "=", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "ma", "=", "pattern", ".", "match", "(", "npy_path", ")", "\n", "label", "=", "int", "(", "ma", ".", "group", "(", "1", ")", ")", "\n", "if", "label", "!=", "1", ":", "# clean is labeled as 1", "\n", "            ", "label", "=", "0", "\n", "", "wid", ".", "write", "(", "\"{0} {1}\\n\"", ".", "format", "(", "npy_path", ",", "label", ")", ")", "\n", "", "wid", ".", "flush", "(", ")", "\n", "wid", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.deep_learning_adv_detector.gen_train_val_list.hasPositiveSampleKey": [[44, 49], ["key.split"], "function", ["None"], ["", "def", "hasPositiveSampleKey", "(", "keys", ")", ":", "\n", "    ", "for", "key", "in", "keys", ":", "\n", "        ", "if", "key", ".", "split", "(", "\"_\"", ")", "[", "2", "]", "==", "\"1\"", ":", "\n", "            ", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.deep_learning_adv_detector.gen_train_val_list.genLists": [[51, 90], ["open", "range", "os.path.exists", "os.mkdir", "line.strip.strip", "line.strip.split", "open", "random.sample", "open.close", "labelMap[].append", "labelMap[].append", "labelMap.keys", "range", "gen_train_val_list.hasPositiveSampleKey", "random.sample", "open.write", "str", "labelMap.keys", "len", "random.randint", "label.split", "len"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.close", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.deep_learning_adv_detector.gen_train_val_list.hasPositiveSampleKey"], ["", "def", "genLists", "(", "fileListPath", ",", "writePath", ",", "type", ",", "numSamples", ",", "numList", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "writePath", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "writePath", ")", "\n", "\n", "", "fid", "=", "open", "(", "fileListPath", ")", "\n", "labelMap", "=", "{", "}", "\n", "for", "line", "in", "fid", ":", "\n", "        ", "if", "type", "not", "in", "line", ":", "\n", "            ", "continue", "\n", "", "line", "=", "line", ".", "strip", "(", ")", "\n", "arylines", "=", "line", ".", "split", "(", "\"/\"", ")", "\n", "label", "=", "arylines", "[", "1", "]", "\n", "if", "label", "not", "in", "labelMap", ":", "\n", "            ", "labelMap", "[", "label", "]", "=", "[", "]", "\n", "labelMap", "[", "label", "]", ".", "append", "(", "line", ")", "\n", "", "else", ":", "\n", "            ", "labelMap", "[", "label", "]", ".", "append", "(", "line", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "numList", ")", ":", "\n", "        ", "wid", "=", "open", "(", "writePath", "+", "\"/\"", "+", "writePath", "+", "str", "(", "i", ")", "+", "\".txt\"", ",", "\"w\"", ")", "\n", "labelMapSampled", "=", "random", ".", "sample", "(", "labelMap", ".", "keys", "(", ")", ",", "5", ")", "\n", "while", "True", ":", "\n", "            ", "if", "hasPositiveSampleKey", "(", "labelMapSampled", ")", "==", "True", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "labelMapSampled", "=", "random", ".", "sample", "(", "labelMap", ".", "keys", "(", ")", ",", "5", ")", "\n", "\n", "", "", "for", "label", "in", "labelMapSampled", ":", "\n", "            ", "tempList", "=", "labelMap", "[", "label", "]", "\n", "for", "j", "in", "range", "(", "numSamples", ")", ":", "\n", "                ", "imagePath", "=", "labelMap", "[", "label", "]", "[", "j", "]", "\n", "if", "numSamples", "!=", "len", "(", "tempList", ")", ":", "\n", "                    ", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "tempList", ")", "-", "1", ")", "\n", "imagePath", "=", "labelMap", "[", "label", "]", "[", "index", "]", "\n", "", "labelStr", "=", "\"0\"", "\n", "if", "label", ".", "split", "(", "\"_\"", ")", "[", "2", "]", "!=", "\"1\"", ":", "\n", "                    ", "labelStr", "=", "\"1\"", "\n", "", "wid", ".", "write", "(", "imagePath", "+", "\" \"", "+", "labelStr", "+", "\"\\n\"", ")", "\n", "", "", "wid", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.deep_learning_adv_detector.gen_train_val_list.genLists2": [[92, 149], ["open", "range", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "line.strip.strip", "line.strip.split", "open", "open", "random.sample", "open.close", "open.close", "labelMap[].append", "labelMap_query[].append", "labelMap.keys", "range", "range", "gen_train_val_list.hasPositiveSampleKey", "random.sample", "open.write", "open.write", "str", "str", "labelMap.keys", "len", "random.randint", "len", "random.randint", "label.split", "label.split", "len", "len"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.close", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.close", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.deep_learning_adv_detector.gen_train_val_list.hasPositiveSampleKey"], ["", "", "def", "genLists2", "(", "fileListPath", ",", "support_writePath", ",", "query_writePath", ",", "support_numSamples", ",", "query_numSamples", ",", "numList", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "support_writePath", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "support_writePath", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "query_writePath", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "query_writePath", ")", "\n", "\n", "", "fid", "=", "open", "(", "fileListPath", ")", "\n", "labelMap", "=", "{", "}", "\n", "labelMap_query", "=", "{", "}", "\n", "for", "line", "in", "fid", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "arylines", "=", "line", ".", "split", "(", "\"/\"", ")", "\n", "label", "=", "arylines", "[", "1", "]", "\n", "if", "\"Support\"", "in", "line", ":", "\n", "            ", "if", "label", "not", "in", "labelMap", ":", "\n", "                ", "labelMap", "[", "label", "]", "=", "[", "]", "\n", "", "labelMap", "[", "label", "]", ".", "append", "(", "line", ")", "\n", "", "else", ":", "\n", "            ", "if", "label", "not", "in", "labelMap_query", ":", "\n", "                ", "labelMap_query", "[", "label", "]", "=", "[", "]", "\n", "", "labelMap_query", "[", "label", "]", ".", "append", "(", "line", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "numList", ")", ":", "\n", "        ", "wid", "=", "open", "(", "support_writePath", "+", "\"/\"", "+", "support_writePath", "+", "str", "(", "i", ")", "+", "\".txt\"", ",", "\"w\"", ")", "\n", "wid2", "=", "open", "(", "query_writePath", "+", "\"/\"", "+", "query_writePath", "+", "str", "(", "i", ")", "+", "\".txt\"", ",", "\"w\"", ")", "\n", "labelMapSampled", "=", "random", ".", "sample", "(", "labelMap", ".", "keys", "(", ")", ",", "5", ")", "\n", "while", "True", ":", "\n", "            ", "if", "hasPositiveSampleKey", "(", "labelMapSampled", ")", "==", "True", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "labelMapSampled", "=", "random", ".", "sample", "(", "labelMap", ".", "keys", "(", ")", ",", "5", ")", "\n", "\n", "", "", "for", "label", "in", "labelMapSampled", ":", "\n", "            ", "tempList", "=", "labelMap", "[", "label", "]", "\n", "for", "j", "in", "range", "(", "support_numSamples", ")", ":", "\n", "                ", "imagePath", "=", "labelMap", "[", "label", "]", "[", "j", "]", "\n", "if", "support_numSamples", "!=", "len", "(", "tempList", ")", ":", "\n", "                    ", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "tempList", ")", "-", "1", ")", "\n", "imagePath", "=", "labelMap", "[", "label", "]", "[", "index", "]", "\n", "", "labelStr", "=", "\"0\"", "\n", "if", "label", ".", "split", "(", "\"_\"", ")", "[", "2", "]", "!=", "\"1\"", ":", "\n", "                    ", "labelStr", "=", "\"1\"", "\n", "", "wid", ".", "write", "(", "imagePath", "+", "\" \"", "+", "labelStr", "+", "\"\\n\"", ")", "\n", "", "", "wid", ".", "close", "(", ")", "\n", "\n", "for", "label", "in", "labelMapSampled", ":", "\n", "            ", "tempList", "=", "labelMap_query", "[", "label", "]", "\n", "for", "j", "in", "range", "(", "query_numSamples", ")", ":", "\n", "                ", "imagePath", "=", "labelMap_query", "[", "label", "]", "[", "j", "]", "\n", "if", "query_numSamples", "!=", "len", "(", "tempList", ")", ":", "\n", "                    ", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "tempList", ")", "-", "1", ")", "\n", "imagePath", "=", "labelMap_query", "[", "label", "]", "[", "index", "]", "\n", "", "labelStr", "=", "\"0\"", "\n", "if", "label", ".", "split", "(", "\"_\"", ")", "[", "2", "]", "!=", "\"1\"", ":", "\n", "                    ", "labelStr", "=", "\"1\"", "\n", "", "wid2", ".", "write", "(", "imagePath", "+", "\" \"", "+", "labelStr", "+", "\"\\n\"", ")", "\n", "", "", "wid2", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.deep_learning_adv_detector.npy_dataset.NpzDataset.__init__": [[7, 19], ["open", "line.split", "int", "os.path.join.split", "int", "os.path.join", "npy_dataset.NpzDataset.npy_file_list.append"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_folder", ",", "image_label_txt_path", ")", ":", "\n", "\n", "        ", "self", ".", "data_folder", "=", "data_folder", "\n", "self", ".", "npy_file_list", "=", "[", "]", "\n", "with", "open", "(", "image_label_txt_path", ",", "\"r\"", ")", "as", "file_obj", ":", "\n", "            ", "for", "line", "in", "file_obj", ":", "\n", "                ", "npy_path", ",", "label", "=", "line", ".", "split", "(", "\" \"", ")", "\n", "label", "=", "int", "(", "label", ")", "\n", "npy_path", ",", "data_index", "=", "npy_path", ".", "split", "(", "\"#\"", ")", "\n", "data_index", "=", "int", "(", "data_index", ")", "\n", "npy_path", "=", "os", ".", "path", ".", "join", "(", "data_folder", ",", "npy_path", ")", "\n", "self", ".", "npy_file_list", ".", "append", "(", "{", "\"npy_path\"", ":", "npy_path", ",", "\"index\"", ":", "data_index", ",", "\"label\"", ":", "label", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.deep_learning_adv_detector.npy_dataset.NpzDataset.__len__": [[20, 22], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "npy_file_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.deep_learning_adv_detector.npy_dataset.NpzDataset.__getitem__": [[23, 33], ["numpy.memmap", "numpy.transpose.reshape", "numpy.transpose", "torch.from_numpy"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "data_json", "=", "self", ".", "npy_file_list", "[", "item", "]", "\n", "npy_path", "=", "data_json", "[", "\"npy_path\"", "]", "\n", "npy_index", "=", "data_json", "[", "\"index\"", "]", "\n", "im", "=", "np", ".", "memmap", "(", "npy_path", ",", "dtype", "=", "'float32'", ",", "mode", "=", "'r'", ",", "shape", "=", "(", "1", ",", "32", ",", "32", ",", "3", ")", ",", "\n", "offset", "=", "npy_index", "*", "32", "*", "32", "*", "3", "*", "32", "//", "8", ")", "\n", "im", "=", "im", ".", "reshape", "(", "32", ",", "32", ",", "3", ")", "\n", "im", "=", "np", ".", "transpose", "(", "im", ",", "axes", "=", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "label", "=", "data_json", "[", "\"label\"", "]", "\n", "return", "torch", ".", "from_numpy", "(", "im", ")", ",", "label", "", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.deep_learning_adv_detector.train.AverageMeter.__init__": [[315, 317], ["train.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.deep_learning_adv_detector.train.AverageMeter.reset": [[318, 323], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.deep_learning_adv_detector.train.AverageMeter.update": [[324, 329], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.deep_learning_adv_detector.train.main": [[89, 168], ["parser.parse_args", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "warnings.warn", "os.makedirs", "train.main_train_worker", "print", "str", "glob.glob", "os.path.dirname", "deep_learning_adv_detector.evaluation.cross_domain_and_arch_evaluation.evaluate_cross_domain", "open", "file_obj.write", "file_obj.flush", "str", "deep_learning_adv_detector.evaluation.finetune_evaluation.evaluate_finetune", "json.dumps", "deep_learning_adv_detector.evaluation.shots_evaluation.evaluate_shots", "deep_learning_adv_detector.evaluation.cross_domain_and_arch_evaluation.evaluate_cross_arch", "deep_learning_adv_detector.evaluation.zero_shot_evaluation.evaluate_zero_shot", "deep_learning_adv_detector.evaluation.speed_evaluation.evaluate_speed", "collections.defaultdict", "deep_learning_adv_detector.evaluation.white_box_evaluation.evaluate_whitebox"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.train_fingerprint.parse_args", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.main_train_worker", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.cross_domain_evaluation.evaluate_cross_domain", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.finetune_evaluation.evaluate_finetune", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.shots_evaluation.evaluate_shots", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.cross_arch_evaluation.evaluate_cross_arch", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.zero_shot_evaluation.evaluate_zero_shot", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.speed_evaluation.evaluate_speed", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.white_box_evaluation.evaluate_whitebox"], ["def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "args", ".", "seed", "is", "not", "None", ":", "\n", "        ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "cudnn", ".", "deterministic", "=", "True", "\n", "warnings", ".", "warn", "(", "'You have chosen to seed training. '", "\n", "'This will turn on the CUDNN deterministic setting, '", "\n", "'which can slow down your training considerably! '", "\n", "'You may see unexpected behavior when restarting '", "\n", "'from checkpoints.'", ")", "\n", "", "if", "not", "args", ".", "evaluate", ":", "# not evaluate_accuracy", "\n", "\n", "        ", "model_path", "=", "'{}/train_pytorch_model/DL_DET/DL_DET@{}_{}@model_{}@data_{}@epoch_{}@class_{}@lr_{}@balance_{}.pth.tar'", ".", "format", "(", "\n", "PY_ROOT", ",", "args", ".", "dataset", ",", "args", ".", "protocol", ",", "args", ".", "arch", ",", "args", ".", "adv_arch", ",", "\n", "args", ".", "epochs", ",", "\n", "2", ",", "args", ".", "lr", ",", "args", ".", "balance", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "model_path", ")", ",", "exist_ok", "=", "True", ")", "\n", "main_train_worker", "(", "args", ",", "model_path", ",", "gpu", "=", "str", "(", "args", ".", "gpu", ")", ")", "\n", "\n", "", "else", ":", "# finetune evaluate_accuracy", "\n", "# DL_DET@CIFAR-10_TRAIN_II_TEST_I@conv3@epoch_40@class_2@lr_0.0001.pth.tar", "\n", "        ", "print", "(", "\"Use GPU: {} for training\"", ".", "format", "(", "args", ".", "gpu", ")", ")", "\n", "os", ".", "environ", "[", "\"CUDA_DEVICE_ORDER\"", "]", "=", "\"PCI_BUS_ID\"", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "str", "(", "args", ".", "gpu", ")", "\n", "model_file_list", "=", "glob", ".", "glob", "(", "\"{}/train_pytorch_model/DL_DET/DL_DET@*\"", ".", "format", "(", "PY_ROOT", ")", ")", "\n", "if", "args", ".", "study_subject", "==", "\"cross_domain\"", ":", "\n", "            ", "result", "=", "evaluate_cross_domain", "(", "model_file_list", ",", "args", ".", "num_updates", ",", "args", ".", "lr", ",", "args", ".", "protocol", ",", "\n", "args", ".", "cross_domain_source", ",", "args", ".", "cross_domain_target", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "'finetune_eval'", ":", "\n", "            ", "result", "=", "evaluate_finetune", "(", "model_file_list", ",", "args", ".", "lr", ",", "args", ".", "protocol", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"shots_eval\"", ":", "\n", "            ", "result", "=", "evaluate_shots", "(", "model_file_list", ",", "args", ".", "num_updates", ",", "args", ".", "lr", ",", "args", ".", "protocol", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"cross_arch\"", ":", "\n", "            ", "updateBN", "=", "False", "\n", "result", "=", "evaluate_cross_arch", "(", "model_file_list", ",", "args", ".", "num_updates", ",", "args", ".", "lr", ",", "args", ".", "protocol", ",", "args", ".", "cross_arch_source", ",", "\n", "args", ".", "cross_arch_target", ",", "updateBN", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"zero_shot\"", ":", "\n", "            ", "result", "=", "evaluate_zero_shot", "(", "model_file_list", ",", "args", ".", "lr", ",", "args", ".", "protocol", ",", "args", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"speed_test\"", ":", "\n", "            ", "result", "=", "evaluate_speed", "(", "model_file_list", ",", "args", ".", "num_updates", ",", "args", ".", "lr", ",", "args", ".", "protocol", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"white_box\"", ":", "\n", "            ", "result", "=", "defaultdict", "(", "dict", ")", "\n", "attacks", "=", "[", "\"FGSM\"", ",", "\"CW_L2\"", "]", "\n", "for", "attack_name", "in", "attacks", ":", "\n", "                ", "evaluate_whitebox", "(", "args", ".", "dataset", ",", "\"conv3\"", ",", "\"conv3\"", ",", "\"DNN\"", ",", "attack_name", ",", "args", ".", "num_updates", ",", "args", ".", "lr", ",", "\n", "args", ".", "protocol", ",", "LOAD_TASK_MODE", ".", "NO_LOAD", ",", "result", ")", "\n", "", "", "file_name", "=", "'{}/train_pytorch_model/DL_DET/cross_adv_group_{}_using_{}_protocol.json'", ".", "format", "(", "PY_ROOT", ",", "args", ".", "study_subject", ",", "args", ".", "protocol", ")", "\n", "if", "args", ".", "study_subject", "==", "\"cross_domain\"", ":", "\n", "            ", "file_name", "=", "'{}/train_pytorch_model/DL_DET/evaluate_{}_{}--{}_using_{}_protocol.json'", ".", "format", "(", "PY_ROOT", ",", "\n", "args", ".", "study_subject", ",", "args", ".", "cross_domain_source", ",", "args", ".", "cross_domain_target", ",", "\n", "args", ".", "protocol", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"cross_arch\"", ":", "\n", "            ", "file_name", "=", "'{}/train_pytorch_model/DL_DET/evaluate_{}_{}--{}_using_{}_protocol_updateBN_{}.json'", ".", "format", "(", "PY_ROOT", ",", "\n", "args", ".", "study_subject", ",", "\n", "args", ".", "cross_arch_source", ",", "\n", "args", ".", "cross_arch_target", ",", "\n", "args", ".", "protocol", ",", "updateBN", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"white_box\"", ":", "\n", "            ", "file_name", "=", "'{}/train_pytorch_model/white_box_model/white_box_UPDATEBN_DNN_{}_using_{}_protocol.json'", ".", "format", "(", "PY_ROOT", ",", "\n", "args", ".", "dataset", ",", "\n", "args", ".", "protocol", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"speed_test\"", ":", "\n", "            ", "file_name", "=", "'{}/train_pytorch_model/DL_DET/speed_test_of_DNN.json'", ".", "format", "(", "PY_ROOT", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"zero_shot\"", ":", "\n", "            ", "if", "args", ".", "cross_domain_source", ":", "\n", "                ", "file_name", "=", "'{}/train_pytorch_model/DL_DET/evaluate_{}_{}--{}_using_{}_protocol.json'", ".", "format", "(", "PY_ROOT", ",", "\n", "args", ".", "study_subject", ",", "\n", "args", ".", "cross_domain_source", ",", "\n", "args", ".", "cross_domain_target", ",", "\n", "args", ".", "protocol", ")", "\n", "", "else", ":", "\n", "                ", "file_name", "=", "'{}/train_pytorch_model/DL_DET/evaluate_{}_using_{}_protocol.json'", ".", "format", "(", "PY_ROOT", ",", "\n", "args", ".", "study_subject", ",", "\n", "args", ".", "protocol", ")", "\n", "\n", "", "", "with", "open", "(", "file_name", ",", "\"w\"", ")", "as", "file_obj", ":", "\n", "            ", "file_obj", ".", "write", "(", "json", ".", "dumps", "(", "result", ")", ")", "\n", "file_obj", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.deep_learning_adv_detector.train.main_train_worker": [[170, 248], ["print", "print", "networks.resnet.resnet18.cuda", "torch.CrossEntropyLoss().cuda", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "os.path.exists", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "meta_adv_detector.tensorboard_helper.TensorBoardWriter", "range", "networks.conv3.Conv3", "dataset.DNN_adversary_random_access_npy_dataset.AdversaryRandomAccessNpyDataset", "dataset.DNN_adversary_dataset.AdversaryDataset", "networks.resnet.resnet18.parameters", "print", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "networks.resnet.resnet18.load_state_dict", "torch.optim.SGD.load_state_dict", "print", "print", "train.adjust_learning_rate", "train.train", "train.save_checkpoint", "networks.resnet.resnet10", "torch.CrossEntropyLoss", "dataset.DNN_adversary_dataset.AdversaryDataset.img_label_list.clear", "dataset.DNN_adversary_dataset.AdversaryDataset.img_label_list.extend", "dataset.DNN_adversary_dataset.AdversaryDataset.img_label_list.extend", "networks.resnet.resnet18", "random.sample", "networks.resnet.resnet18.state_dict", "torch.optim.SGD.state_dict", "len"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.adjust_learning_rate", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.save_checkpoint", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet10", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet18"], ["", "", "", "def", "main_train_worker", "(", "args", ",", "model_path", ",", "META_ATTACKER_PART_I", "=", "None", ",", "META_ATTACKER_PART_II", "=", "None", ",", "gpu", "=", "\"0\"", ")", ":", "\n", "    ", "if", "META_ATTACKER_PART_I", "is", "None", ":", "\n", "        ", "META_ATTACKER_PART_I", "=", "config", ".", "META_ATTACKER_PART_I", "\n", "", "if", "META_ATTACKER_PART_II", "is", "None", ":", "\n", "        ", "META_ATTACKER_PART_II", "=", "config", ".", "META_ATTACKER_PART_II", "\n", "", "print", "(", "\"Use GPU: {} for training\"", ".", "format", "(", "gpu", ")", ")", "\n", "os", ".", "environ", "[", "\"CUDA_DEVICE_ORDER\"", "]", "=", "\"PCI_BUS_ID\"", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "gpu", "\n", "print", "(", "\"will save to {}\"", ".", "format", "(", "model_path", ")", ")", "\n", "global", "best_acc1", "\n", "if", "args", ".", "arch", "==", "\"conv3\"", ":", "\n", "        ", "model", "=", "Conv3", "(", "IN_CHANNELS", "[", "args", ".", "dataset", "]", ",", "IMAGE_SIZE", "[", "args", ".", "dataset", "]", ",", "2", ")", "\n", "", "elif", "args", ".", "arch", "==", "\"resnet10\"", ":", "\n", "        ", "model", "=", "resnet10", "(", "2", ",", "in_channels", "=", "IN_CHANNELS", "[", "args", ".", "dataset", "]", ",", "pretrained", "=", "False", ")", "\n", "", "elif", "args", ".", "arch", "==", "\"resnet18\"", ":", "\n", "        ", "model", "=", "resnet18", "(", "2", ",", "in_channels", "=", "IN_CHANNELS", "[", "args", ".", "dataset", "]", ",", "pretrained", "=", "False", ")", "\n", "", "model", "=", "model", ".", "cuda", "(", ")", "\n", "if", "args", ".", "dataset", "==", "\"ImageNet\"", ":", "\n", "        ", "train_dataset", "=", "AdversaryRandomAccessNpyDataset", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "dataset", "]", "+", "\"/adversarial_images/{}\"", ".", "format", "(", "args", ".", "adv_arch", ")", ",", "\n", "True", ",", "args", ".", "protocol", ",", "META_ATTACKER_PART_I", ",", "META_ATTACKER_PART_II", ",", "\n", "args", ".", "balance", ",", "args", ".", "dataset", ")", "\n", "", "else", ":", "\n", "        ", "train_dataset", "=", "AdversaryDataset", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "dataset", "]", "+", "\"/adversarial_images/{}\"", ".", "format", "(", "args", ".", "adv_arch", ")", ",", "\n", "True", ",", "args", ".", "protocol", ",", "META_ATTACKER_PART_I", ",", "META_ATTACKER_PART_II", ",", "args", ".", "balance", ")", "\n", "\n", "# val_dataset = MetaTaskDataset(20000, 2, 1, 15,", "\n", "#                                     args.dataset, is_train=False, pkl_task_dump_path=args.test_pkl_path,", "\n", "#                                     load_mode=LOAD_TASK_MODE.LOAD,", "\n", "#                                     protocol=args.protocol, no_random_way=True)", "\n", "\n", "# define loss function (criterion) and optimizer", "\n", "", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "cuda", "(", "args", ".", "gpu", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "lr", ",", "\n", "momentum", "=", "args", ".", "momentum", ",", "\n", "weight_decay", "=", "args", ".", "weight_decay", ")", "\n", "\n", "# optionally resume from a checkpoint", "\n", "if", "os", ".", "path", ".", "exists", "(", "model_path", ")", ":", "\n", "        ", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "model_path", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "args", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "model_path", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"=> no checkpoint found at '{}'\"", ".", "format", "(", "model_path", ")", ")", "\n", "\n", "", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# Data loading code", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "train_dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "\n", "# val_loader = torch.utils.data.DataLoader(", "\n", "#     val_dataset,", "\n", "#     batch_size=100, shuffle=False,", "\n", "#     num_workers=0, pin_memory=True)", "\n", "tensorboard", "=", "TensorBoardWriter", "(", "\"{0}/pytorch_DeepLearning_tensorboard\"", ".", "format", "(", "PY_ROOT", ")", ",", "\"DeepLearning\"", ")", "\n", "for", "epoch", "in", "range", "(", "args", ".", "start_epoch", ",", "args", ".", "epochs", ")", ":", "\n", "        ", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ",", "args", ")", "\n", "# train for one epoch", "\n", "train", "(", "train_loader", ",", "None", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "tensorboard", ",", "args", ")", "\n", "if", "args", ".", "balance", ":", "\n", "            ", "train_dataset", ".", "img_label_list", ".", "clear", "(", ")", "\n", "train_dataset", ".", "img_label_list", ".", "extend", "(", "train_dataset", ".", "img_label_dict", "[", "1", "]", ")", "\n", "train_dataset", ".", "img_label_list", ".", "extend", "(", "random", ".", "sample", "(", "train_dataset", ".", "img_label_dict", "[", "0", "]", ",", "len", "(", "train_dataset", ".", "img_label_dict", "[", "1", "]", ")", ")", ")", "\n", "# evaluate_accuracy on validation set", "\n", "\n", "# acc1 = validate(val_loader, model, criterion, args)", "\n", "# remember best acc@1 and save checkpoint", "\n", "", "save_checkpoint", "(", "{", "\n", "'epoch'", ":", "epoch", "+", "1", ",", "\n", "'arch'", ":", "args", ".", "arch", ",", "\n", "'state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "filename", "=", "model_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.deep_learning_adv_detector.train.train": [[251, 293], ["train.AverageMeter", "train.AverageMeter", "train.AverageMeter", "train.AverageMeter", "model.train", "time.time", "enumerate", "train.AverageMeter.update", "input.cuda.cuda", "target.cuda.cuda", "model", "criterion", "train.accuracy", "train.AverageMeter.update", "train.AverageMeter.update", "optimizer.zero_grad", "criterion.backward", "optimizer.step", "train.AverageMeter.update", "time.time", "criterion.item", "input.cuda.size", "input.cuda.size", "print", "time.time", "time.time", "len"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.accuracy", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update"], ["", "", "def", "train", "(", "train_loader", ",", "val_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "tensorboard", ",", "args", ")", ":", "\n", "    ", "batch_time", "=", "AverageMeter", "(", ")", "\n", "data_time", "=", "AverageMeter", "(", ")", "\n", "losses", "=", "AverageMeter", "(", ")", "\n", "top1", "=", "AverageMeter", "(", ")", "\n", "# top5 = AverageMeter()", "\n", "\n", "# switch to train mode", "\n", "model", ".", "train", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "input", ",", "target", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "# measure data loading time", "\n", "        ", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "input", "=", "input", ".", "cuda", "(", ")", "\n", "target", "=", "target", ".", "cuda", "(", ")", "\n", "\n", "# compute output", "\n", "output", "=", "model", "(", "input", ")", "\n", "loss", "=", "criterion", "(", "output", ",", "target", ")", "\n", "# measure accuracy and record loss", "\n", "acc1", ",", "=", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", "\n", "losses", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "top1", ".", "update", "(", "acc1", "[", "0", "]", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "# top5.update(acc5[0], input.size(0))", "\n", "\n", "# compute gradient and do SGD step", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "i", "%", "args", ".", "print_freq", "==", "0", ":", "\n", "            ", "print", "(", "'Epoch: [{0}][{1}/{2}]\\t'", "\n", "'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'", "\n", "'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'", "\n", "'Acc@1 {top1.val:.3f} ({top1.avg:.3f})'", ".", "format", "(", "\n", "epoch", ",", "i", ",", "len", "(", "train_loader", ")", ",", "batch_time", "=", "batch_time", ",", "\n", "loss", "=", "losses", ",", "top1", "=", "top1", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.deep_learning_adv_detector.train.save_checkpoint": [[308, 310], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save"], "function", ["None"], ["", "", "", "def", "save_checkpoint", "(", "state", ",", "filename", "=", "'traditional_dl.pth.tar'", ")", ":", "\n", "    ", "torch", ".", "save", "(", "state", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.deep_learning_adv_detector.train.adjust_learning_rate": [[331, 336], ["None"], "function", ["None"], ["", "", "def", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ",", "args", ")", ":", "\n", "    ", "\"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"", "\n", "lr", "=", "args", ".", "lr", "*", "(", "0.1", "**", "(", "epoch", "//", "30", ")", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.deep_learning_adv_detector.train.accuracy": [[338, 352], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["", "", "def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "            ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.speed_evaluation.speed_test": [[20, 61], ["copy.deepcopy", "enumerate", "numpy.mean", "numpy.var", "support_labels.cuda.cuda", "query_labels.cuda.cuda", "range", "support_images.size", "copy.deepcopy", "copy.deepcopy.cuda", "torch.optim.SGD", "copy.deepcopy.train", "time.time", "range", "copy.deepcopy.eval", "meta_adv_detector.meta_adv_det.evaluate_two_way", "all_times.append", "copy.deepcopy.eval", "copy.deepcopy.parameters", "copy.deepcopy.modules", "meta_adv_detector.meta_adv_det.forward_pass", "torch.optim.SGD.zero_grad", "loss.backward", "torch.optim.SGD.step", "time.time", "isinstance", "m.eval"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.evaluate_two_way", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward_pass"], ["# test_net = copy.deepcopy(network)", "\n", "# Select ten tasks randomly from the test set to evaluate_accuracy on", "\n", "    ", "test_net", "=", "copy", ".", "deepcopy", "(", "network", ")", "\n", "all_times", "=", "[", "]", "\n", "# support_images,support_gt_labels, support_binary_labels, query_images, query_gt_labels, query_binary_labels", "\n", "for", "val_idx", ",", "(", "support_images", ",", "_", ",", "support_labels", ",", "query_images", ",", "_", ",", "query_labels", ",", "positive_labels", ")", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "# print(\"process task {}  task_batch={}\".format(val_idx, len(support_images)))", "\n", "        ", "support_labels", "=", "support_labels", ".", "cuda", "(", ")", "\n", "query_labels", "=", "query_labels", ".", "cuda", "(", ")", "\n", "for", "task_idx", "in", "range", "(", "support_images", ".", "size", "(", "0", ")", ")", ":", "\n", "# Make a test net with same parameters as our current net", "\n", "            ", "test_net", "=", "copy", ".", "deepcopy", "(", "network", ")", "\n", "test_net", ".", "cuda", "(", ")", "\n", "test_opt", "=", "SGD", "(", "test_net", ".", "parameters", "(", ")", ",", "lr", "=", "inner_lr", ")", "\n", "support_task", ",", "support_target", "=", "support_images", "[", "task_idx", "]", ",", "support_labels", "[", "task_idx", "]", "\n", "test_net", ".", "train", "(", ")", "\n", "\n", "before_time", "=", "time", ".", "time", "(", ")", "\n", "if", "not", "update_BN", ":", "\n", "                ", "for", "m", "in", "test_net", ".", "modules", "(", ")", ":", "\n", "                    ", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                        ", "m", ".", "eval", "(", ")", "\n", "", "", "", "for", "i", "in", "range", "(", "num_updates", ")", ":", "# \u5148fine_tune", "\n", "                ", "loss", ",", "out", "=", "forward_pass", "(", "test_net", ",", "support_task", ",", "support_target", ")", "\n", "test_opt", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "test_opt", ".", "step", "(", ")", "\n", "", "test_net", ".", "eval", "(", ")", "\n", "query_acc", ",", "query_F1_score", "=", "evaluate_two_way", "(", "test_net", ",", "query_images", "[", "task_idx", "]", ",", "query_labels", "[", "task_idx", "]", ")", "\n", "pass_time", "=", "time", ".", "time", "(", ")", "-", "before_time", "\n", "all_times", ".", "append", "(", "pass_time", ")", "\n", "test_net", ".", "eval", "(", ")", "\n", "# Evaluate the trained model on train and val examples", "\n", "\n", "", "", "mean_time_elapse", "=", "np", ".", "mean", "(", "all_times", ")", "\n", "std_var_time_elapse", "=", "np", ".", "var", "(", "all_times", ")", "\n", "result_json", "=", "{", "\"mean_time\"", ":", "mean_time_elapse", ",", "\"var_time\"", ":", "std_var_time_elapse", "}", "\n", "\n", "del", "test_net", "\n", "return", "result_json", "\n", "\n", "", "def", "evaluate_speed", "(", "model_path_list", ",", "num_update", ",", "lr", ",", "protocol", ")", ":", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.speed_evaluation.evaluate_speed": [[14, 62], ["re.compile", "collections.defaultdict", "glob.glob", "re.compile.match", "extract_pattern.match.group", "extract_pattern.match.group", "int", "int", "float", "networks.conv3.Conv3", "networks.conv3.Conv3.load_state_dict", "networks.conv3.Conv3.cuda", "print", "neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector", "open", "file_obj.write", "file_obj.flush", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "dataset.meta_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.test_speed", "print", "json.dumps", "range", "torch.load"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.test_speed"], ["from", "dataset", ".", "protocol_enum", "import", "SPLIT_DATA_PROTOCOL", ",", "LOAD_TASK_MODE", "\n", "from", "meta_adv_detector", ".", "score", "import", "forward_pass", ",", "evaluate_two_way", "\n", "import", "numpy", "as", "np", "\n", "import", "time", "\n", "\n", "def", "speed_test", "(", "network", ",", "val_loader", ",", "inner_lr", ",", "num_updates", ",", "update_BN", "=", "True", ")", ":", "\n", "# test_net = copy.deepcopy(network)", "\n", "# Select ten tasks randomly from the test set to evaluate_accuracy on", "\n", "    ", "test_net", "=", "copy", ".", "deepcopy", "(", "network", ")", "\n", "all_times", "=", "[", "]", "\n", "# support_images,support_gt_labels, support_binary_labels, query_images, query_gt_labels, query_binary_labels", "\n", "for", "val_idx", ",", "(", "support_images", ",", "_", ",", "support_labels", ",", "query_images", ",", "_", ",", "query_labels", ",", "positive_labels", ")", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "# print(\"process task {}  task_batch={}\".format(val_idx, len(support_images)))", "\n", "        ", "support_labels", "=", "support_labels", ".", "cuda", "(", ")", "\n", "query_labels", "=", "query_labels", ".", "cuda", "(", ")", "\n", "for", "task_idx", "in", "range", "(", "support_images", ".", "size", "(", "0", ")", ")", ":", "\n", "# Make a test net with same parameters as our current net", "\n", "            ", "test_net", "=", "copy", ".", "deepcopy", "(", "network", ")", "\n", "test_net", ".", "cuda", "(", ")", "\n", "test_opt", "=", "SGD", "(", "test_net", ".", "parameters", "(", ")", ",", "lr", "=", "inner_lr", ")", "\n", "support_task", ",", "support_target", "=", "support_images", "[", "task_idx", "]", ",", "support_labels", "[", "task_idx", "]", "\n", "test_net", ".", "train", "(", ")", "\n", "\n", "before_time", "=", "time", ".", "time", "(", ")", "\n", "if", "not", "update_BN", ":", "\n", "                ", "for", "m", "in", "test_net", ".", "modules", "(", ")", ":", "\n", "                    ", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                        ", "m", ".", "eval", "(", ")", "\n", "", "", "", "for", "i", "in", "range", "(", "num_updates", ")", ":", "# \u5148fine_tune", "\n", "                ", "loss", ",", "out", "=", "forward_pass", "(", "test_net", ",", "support_task", ",", "support_target", ")", "\n", "test_opt", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "test_opt", ".", "step", "(", ")", "\n", "", "test_net", ".", "eval", "(", ")", "\n", "query_acc", ",", "query_F1_score", "=", "evaluate_two_way", "(", "test_net", ",", "query_images", "[", "task_idx", "]", ",", "query_labels", "[", "task_idx", "]", ")", "\n", "pass_time", "=", "time", ".", "time", "(", ")", "-", "before_time", "\n", "all_times", ".", "append", "(", "pass_time", ")", "\n", "test_net", ".", "eval", "(", ")", "\n", "# Evaluate the trained model on train and val examples", "\n", "\n", "", "", "mean_time_elapse", "=", "np", ".", "mean", "(", "all_times", ")", "\n", "std_var_time_elapse", "=", "np", ".", "var", "(", "all_times", ")", "\n", "result_json", "=", "{", "\"mean_time\"", ":", "mean_time_elapse", ",", "\"var_time\"", ":", "std_var_time_elapse", "}", "\n", "\n", "del", "test_net", "\n", "return", "result_json", "\n", "\n", "", "def", "evaluate_speed", "(", "model_path_list", ",", "num_update", ",", "lr", ",", "protocol", ")", ":", "\n", "# deep learning\u8bad\u7ec3\u662f\u5728all_in\u6216\u8005sampled all in\u4e0b\u8bad\u7ec3\u7684\uff0c\u4f46\u662f\u6d4b\u8bd5\u9700\u8981\u5728task\u7248\u672c\u7684dataset\u4e0a\u505a", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.zero_shot_evaluation.evaluate_zero_shot": [[19, 80], ["str", "re.compile", "collections.defaultdict", "glob.glob", "re.compile.match", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "int", "float", "int", "print", "dataset.meta_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "networks.conv3.Conv3", "image_rotate_detector.image_rotate.ImageTransformCV2", "image_rotate_detector.rotate_detector.Detector", "torch.load", "image_rotate_detector.rotate_detector.Detector.load_state_dict", "image_rotate_detector.rotate_detector.Detector.cuda", "print", "evaluation_toolkit.evaluation.finetune_eval_task_accuracy", "open", "file_obj.write", "file_obj.flush", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "json.dumps", "extract_pattern_detail.match.group", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation_toolkit.evaluation.finetune_eval_task_accuracy"], ["query", "=", "15", "\n", "result", "=", "defaultdict", "(", "dict", ")", "\n", "for", "model_path", "in", "model_path_list", ":", "\n", "        ", "ma", "=", "extract_pattern_detail", ".", "match", "(", "model_path", ")", "\n", "dataset", "=", "ma", ".", "group", "(", "1", ")", "\n", "file_protocol", "=", "ma", ".", "group", "(", "2", ")", "\n", "if", "str", "(", "protocol", ")", "!=", "file_protocol", ":", "\n", "            ", "continue", "\n", "", "balance", "=", "ma", ".", "group", "(", "8", ")", "\n", "if", "balance", "==", "\"True\"", ":", "\n", "            ", "balance", "=", "\"balance\"", "\n", "", "else", ":", "\n", "            ", "balance", "=", "\"no_balance\"", "\n", "\n", "", "key", "=", "\"{}@{}__{}\"", ".", "format", "(", "dataset", ",", "balance", ",", "protocol", ")", "\n", "if", "args", ".", "cross_domain_source", "is", "not", "None", ":", "\n", "            ", "if", "dataset", "!=", "args", ".", "cross_domain_source", ":", "\n", "                ", "continue", "\n", "", "dataset", "=", "args", ".", "cross_domain_target", "\n", "key", "=", "\"{}@{}-->{}__{}\"", ".", "format", "(", "args", ".", "cross_domain_source", ",", "balance", ",", "dataset", ",", "protocol", ")", "\n", "\n", "", "print", "(", "\"evaluate_accuracy model :{}\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "model_path", ")", ")", ")", "\n", "arch", "=", "ma", ".", "group", "(", "3", ")", "\n", "adv_arch", "=", "ma", ".", "group", "(", "4", ")", "\n", "model", "=", "Conv3", "(", "IN_CHANNELS", "[", "dataset", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", ",", "2", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "model_path", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "shot", "=", "1", "\n", "num_update", "=", "0", "\n", "meta_task_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "way", ",", "shot", ",", "query", ",", "\n", "dataset", ",", "is_train", "=", "False", ",", "\n", "load_mode", "=", "LOAD_TASK_MODE", ".", "LOAD", ",", "\n", "protocol", "=", "protocol", ",", "no_random_way", "=", "True", ",", "adv_arch", "=", "adv_arch", ")", "\n", "data_loader", "=", "DataLoader", "(", "meta_task_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "pin_memory", "=", "True", ")", "\n", "evaluate_result", "=", "finetune_eval_task_accuracy", "(", "model", ",", "data_loader", ",", "lr", ",", "num_update", ",", "update_BN", "=", "False", ")", "\n", "result", "[", "key", "]", "[", "0", "]", "=", "evaluate_result", "\n", "", "return", "result", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.finetune_evaluation.evaluate_finetune": [[20, 68], ["str", "re.compile", "collections.defaultdict", "glob.glob", "re.compile.match", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "int", "float", "int", "print", "dataset.meta_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "networks.conv3.Conv3", "image_rotate_detector.image_rotate.ImageTransformCV2", "image_rotate_detector.rotate_detector.Detector", "torch.load", "image_rotate_detector.rotate_detector.Detector.load_state_dict", "image_rotate_detector.rotate_detector.Detector.cuda", "print", "range", "open", "file_obj.write", "file_obj.flush", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "evaluation_toolkit.evaluation.finetune_eval_task_accuracy", "json.dumps", "extract_pattern_detail.match.group", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation_toolkit.evaluation.finetune_eval_task_accuracy"], ["result", "=", "defaultdict", "(", "dict", ")", "\n", "assert", "protocol", "==", "SPLIT_DATA_PROTOCOL", ".", "TRAIN_I_TEST_II", ",", "\"protocol {} is not TRAIN_I_TEST_II!\"", ".", "format", "(", "protocol", ")", "\n", "for", "model_path", "in", "model_path_list", ":", "\n", "        ", "ma", "=", "extract_pattern_detail", ".", "match", "(", "model_path", ")", "\n", "dataset", "=", "ma", ".", "group", "(", "1", ")", "\n", "if", "dataset", "!=", "\"CIFAR-10\"", ":", "\n", "            ", "continue", "\n", "", "file_protocol", "=", "ma", ".", "group", "(", "2", ")", "\n", "if", "str", "(", "protocol", ")", "!=", "file_protocol", ":", "\n", "            ", "continue", "\n", "", "adv_arch", "=", "ma", ".", "group", "(", "4", ")", "\n", "balance", "=", "ma", ".", "group", "(", "8", ")", "\n", "if", "balance", "==", "\"True\"", ":", "\n", "            ", "balance", "=", "\"balance\"", "\n", "", "else", ":", "\n", "            ", "balance", "=", "\"no_balance\"", "\n", "", "print", "(", "\"evaluate_accuracy model :{}\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "model_path", ")", ")", ")", "\n", "arch", "=", "ma", ".", "group", "(", "3", ")", "\n", "model", "=", "Conv3", "(", "IN_CHANNELS", "[", "dataset", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", ",", "2", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "import", "torch", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "model_path", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "shot", "=", "1", "\n", "meta_task_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "way", ",", "shot", ",", "query", ",", "\n", "dataset", ",", "is_train", "=", "False", ",", "\n", "load_mode", "=", "LOAD_TASK_MODE", ".", "LOAD", ",", "\n", "protocol", "=", "protocol", ",", "no_random_way", "=", "True", ",", "adv_arch", "=", "adv_arch", ")", "\n", "data_loader", "=", "DataLoader", "(", "meta_task_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "pin_memory", "=", "True", ")", "\n", "for", "num_update", "in", "range", "(", "0", ",", "51", ")", ":", "\n", "            ", "evaluate_result", "=", "finetune_eval_task_accuracy", "(", "model", ",", "data_loader", ",", "lr", ",", "num_update", ",", "update_BN", "=", "False", ")", "\n", "if", "num_update", "==", "0", ":", "\n", "                ", "shot", "=", "0", "\n", "", "else", ":", "\n", "                ", "shot", "=", "1", "\n", "", "evaluate_result", "[", "\"shot\"", "]", "=", "shot", "\n", "result", "[", "\"{}_{}\"", ".", "format", "(", "dataset", ",", "balance", ")", "]", "[", "num_update", "]", "=", "evaluate_result", "\n", "", "", "return", "result", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.cross_domain_and_arch_evaluation.evaluate_cross_arch": [[16, 63], ["re.compile", "collections.defaultdict", "re.compile.match", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "print", "networks.conv3.Conv3", "model.cuda.cuda", "torch.load", "model.cuda.load_state_dict", "print", "str", "dataset.meta_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "evaluation_toolkit.evaluation.finetune_eval_task_accuracy", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation_toolkit.evaluation.finetune_eval_task_accuracy"], ["def", "evaluate_cross_arch", "(", "model_path_list", ",", "num_update", ",", "lr", ",", "protocol", ",", "src_arch", ",", "target_arch", ",", "updateBN", ")", ":", "\n", "    ", "extract_pattern_detail", "=", "re", ".", "compile", "(", "\n", "\".*?DL_DET@(.*?)_(TRAIN_.*?)@model_(.*?)@data_(.*?)@epoch_(\\d+)@class_(\\d+)@lr_(.*?)@balance_(.*?)\\.pth\\.tar\"", ")", "\n", "tot_num_tasks", "=", "20000", "\n", "way", "=", "2", "\n", "query", "=", "15", "\n", "result", "=", "defaultdict", "(", "dict", ")", "\n", "for", "model_path", "in", "model_path_list", ":", "\n", "        ", "ma", "=", "extract_pattern_detail", ".", "match", "(", "model_path", ")", "\n", "dataset", "=", "ma", ".", "group", "(", "1", ")", "\n", "file_protocol", "=", "ma", ".", "group", "(", "2", ")", "\n", "if", "str", "(", "protocol", ")", "!=", "file_protocol", ":", "\n", "            ", "continue", "\n", "\n", "", "arch", "=", "ma", ".", "group", "(", "3", ")", "\n", "adv_arch", "=", "ma", ".", "group", "(", "4", ")", "\n", "if", "adv_arch", "!=", "src_arch", ":", "\n", "            ", "continue", "\n", "", "balance", "=", "ma", ".", "group", "(", "8", ")", "\n", "if", "balance", "==", "\"True\"", ":", "\n", "            ", "balance", "=", "\"balance\"", "\n", "", "else", ":", "\n", "            ", "balance", "=", "\"no_balance\"", "\n", "", "print", "(", "\"evaluate_accuracy model :{}\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "model_path", ")", ")", ")", "\n", "model", "=", "Conv3", "(", "IN_CHANNELS", "[", "dataset", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", ",", "2", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "model_path", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "old_num_update", "=", "num_update", "\n", "for", "shot", "in", "[", "0", ",", "1", ",", "5", "]", ":", "\n", "            ", "if", "shot", "==", "0", ":", "\n", "                ", "shot", "=", "1", "\n", "num_update", "=", "0", "\n", "", "else", ":", "\n", "                ", "num_update", "=", "old_num_update", "\n", "", "meta_task_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "way", ",", "shot", ",", "query", ",", "\n", "dataset", ",", "is_train", "=", "False", ",", "\n", "load_mode", "=", "LOAD_TASK_MODE", ".", "LOAD", ",", "\n", "protocol", "=", "protocol", ",", "no_random_way", "=", "True", ",", "adv_arch", "=", "target_arch", ",", "fetch_attack_name", "=", "False", ")", "\n", "data_loader", "=", "DataLoader", "(", "meta_task_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "pin_memory", "=", "True", ")", "\n", "evaluate_result", "=", "finetune_eval_task_accuracy", "(", "model", ",", "data_loader", ",", "lr", ",", "num_update", ",", "update_BN", "=", "updateBN", ")", "\n", "if", "num_update", "==", "0", ":", "\n", "                ", "shot", "=", "0", "\n", "", "result", "[", "\"{}-->{}@{}_{}\"", ".", "format", "(", "src_arch", ",", "target_arch", ",", "dataset", ",", "balance", ")", "]", "[", "shot", "]", "=", "evaluate_result", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.cross_domain_and_arch_evaluation.evaluate_cross_domain": [[64, 113], ["re.compile", "collections.defaultdict", "re.compile.match", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "print", "networks.conv3.Conv3", "model.cuda.cuda", "torch.load", "model.cuda.load_state_dict", "print", "str", "dataset.meta_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "evaluation_toolkit.evaluation.finetune_eval_task_accuracy", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation_toolkit.evaluation.finetune_eval_task_accuracy"], ["", "def", "evaluate_cross_domain", "(", "model_path_list", ",", "num_update", ",", "lr", ",", "protocol", ",", "src_dataset", ",", "target_dataset", ")", ":", "\n", "# deep learning\u8bad\u7ec3\u662f\u5728all_in\u6216\u8005sampled all in\u4e0b\u8bad\u7ec3\u7684\uff0c\u4f46\u662f\u6d4b\u8bd5\u9700\u8981\u5728task\u7248\u672c\u7684dataset\u4e0a\u505a", "\n", "    ", "extract_pattern_detail", "=", "re", ".", "compile", "(", "\".*?DL_DET@(.*?)_(TRAIN_.*?)@model_(.*?)@data_(.*?)@epoch_(\\d+)@class_(\\d+)@lr_(.*?)@balance_(.*?)\\.pth\\.tar\"", ")", "\n", "tot_num_tasks", "=", "20000", "\n", "way", "=", "2", "\n", "query", "=", "15", "\n", "result", "=", "defaultdict", "(", "dict", ")", "\n", "for", "model_path", "in", "model_path_list", ":", "\n", "        ", "ma", "=", "extract_pattern_detail", ".", "match", "(", "model_path", ")", "\n", "dataset", "=", "ma", ".", "group", "(", "1", ")", "\n", "if", "dataset", "==", "\"ImageNet\"", ":", "\n", "            ", "continue", "\n", "", "file_protocol", "=", "ma", ".", "group", "(", "2", ")", "\n", "if", "str", "(", "protocol", ")", "!=", "file_protocol", ":", "\n", "            ", "continue", "\n", "", "if", "dataset", "!=", "src_dataset", ":", "\n", "            ", "continue", "\n", "", "dataset", "=", "target_dataset", "\n", "arch", "=", "ma", ".", "group", "(", "3", ")", "\n", "adv_arch", "=", "ma", ".", "group", "(", "4", ")", "\n", "balance", "=", "ma", ".", "group", "(", "8", ")", "\n", "if", "balance", "==", "\"True\"", ":", "\n", "            ", "balance", "=", "\"balance\"", "\n", "", "else", ":", "\n", "            ", "balance", "=", "\"no_balance\"", "\n", "", "print", "(", "\"evaluate_accuracy model :{}\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "model_path", ")", ")", ")", "\n", "model", "=", "Conv3", "(", "IN_CHANNELS", "[", "dataset", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", ",", "2", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "model_path", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "old_num_update", "=", "num_update", "\n", "for", "shot", "in", "[", "0", ",", "1", ",", "5", "]", ":", "\n", "            ", "if", "shot", "==", "0", ":", "\n", "                ", "shot", "=", "1", "\n", "num_update", "=", "0", "\n", "", "else", ":", "\n", "                ", "num_update", "=", "old_num_update", "\n", "", "meta_task_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "way", ",", "shot", ",", "query", ",", "\n", "dataset", ",", "is_train", "=", "False", ",", "\n", "load_mode", "=", "LOAD_TASK_MODE", ".", "LOAD", ",", "\n", "protocol", "=", "protocol", ",", "no_random_way", "=", "True", ",", "adv_arch", "=", "adv_arch", ",", "fetch_attack_name", "=", "False", ")", "\n", "data_loader", "=", "DataLoader", "(", "meta_task_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "pin_memory", "=", "True", ")", "\n", "evaluate_result", "=", "finetune_eval_task_accuracy", "(", "model", ",", "data_loader", ",", "lr", ",", "num_update", ",", "update_BN", "=", "True", ")", "\n", "if", "num_update", "==", "0", ":", "\n", "                ", "shot", "=", "0", "\n", "", "result", "[", "\"{}-->{}@{}@{}\"", ".", "format", "(", "src_dataset", ",", "target_dataset", ",", "balance", ",", "adv_arch", ")", "]", "[", "shot", "]", "=", "evaluate_result", "\n", "", "", "return", "result", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.white_box_evaluation.evaluate_whitebox": [[14, 59], ["re.compile", "os.path.exists", "re.compile.match", "extract_pattern_detail.match.group", "print", "extract_pattern_detail.match.group", "networks.conv3.Conv3", "model.cuda.cuda", "torch.load", "model.cuda.load_state_dict", "print", "dataset.white_box_attack_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "evaluation_toolkit.evaluation.finetune_eval_task_accuracy", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation_toolkit.evaluation.finetune_eval_task_accuracy"], ["def", "evaluate_whitebox", "(", "dataset", ",", "arch", ",", "adv_arch", ",", "detector", ",", "attack_name", ",", "num_update", ",", "lr", ",", "protocol", ",", "load_mode", ",", "result", ")", ":", "\n", "# deep learning\u8bad\u7ec3\u662f\u5728all_in\u6216\u8005sampled all in\u4e0b\u8bad\u7ec3\u7684\uff0c\u4f46\u662f\u6d4b\u8bd5\u9700\u8981\u5728task\u7248\u672c\u7684dataset\u4e0a\u505a", "\n", "    ", "extract_pattern_detail", "=", "re", ".", "compile", "(", "\".*?DL_DET@(.*?)_(TRAIN_.*?)@model_(.*?)@data_(.*?)@epoch_(\\d+)@class_(\\d+)@lr_(.*?)@balance_(.*?)\\.pth\\.tar\"", ")", "\n", "tot_num_tasks", "=", "20000", "\n", "way", "=", "2", "\n", "query", "=", "15", "\n", "\n", "model_path", "=", "\"{}/train_pytorch_model/white_box_model/DL_DET@{}_{}@model_{}@data_{}@epoch_40@class_2@lr_0.0001@balance_True.pth.tar\"", ".", "format", "(", "\n", "PY_ROOT", ",", "dataset", ",", "protocol", ",", "arch", ",", "adv_arch", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "model_path", ")", ",", "\"{} is not exists\"", ".", "format", "(", "model_path", ")", "\n", "root_folder", "=", "IMAGE_DATA_ROOT", "[", "dataset", "]", "+", "\"/adversarial_images/white_box@data_{}@det_{}/{}/\"", ".", "format", "(", "adv_arch", ",", "detector", ",", "attack_name", ")", "\n", "ma", "=", "extract_pattern_detail", ".", "match", "(", "model_path", ")", "\n", "balance", "=", "ma", ".", "group", "(", "8", ")", "\n", "if", "balance", "==", "\"True\"", ":", "\n", "        ", "balance", "=", "\"balance\"", "\n", "", "else", ":", "\n", "        ", "balance", "=", "\"no_balance\"", "\n", "", "print", "(", "\"evaluate_accuracy model :{}\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "model_path", ")", ")", ")", "\n", "arch", "=", "ma", ".", "group", "(", "3", ")", "\n", "model", "=", "Conv3", "(", "IN_CHANNELS", "[", "dataset", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", ",", "2", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "model_path", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "\n", "old_num_update", "=", "num_update", "\n", "# for shot in range(16):", "\n", "for", "shot", "in", "[", "0", ",", "1", ",", "5", "]", ":", "\n", "        ", "if", "shot", "==", "0", ":", "\n", "            ", "shot", "=", "1", "\n", "num_update", "=", "0", "\n", "", "else", ":", "\n", "            ", "num_update", "=", "old_num_update", "\n", "\n", "", "meta_task_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "way", ",", "shot", ",", "query", ",", "\n", "dataset", ",", "\n", "load_mode", "=", "load_mode", ",", "detector", "=", "detector", ",", "attack_name", "=", "attack_name", ",", "root_folder", "=", "root_folder", ")", "\n", "data_loader", "=", "DataLoader", "(", "meta_task_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "pin_memory", "=", "True", ")", "\n", "evaluate_result", "=", "finetune_eval_task_accuracy", "(", "model", ",", "data_loader", ",", "lr", ",", "num_update", ",", "update_BN", "=", "True", ")", "\n", "if", "num_update", "==", "0", ":", "\n", "            ", "shot", "=", "0", "\n", "", "result", "[", "\"{}_{}_{}_{}\"", ".", "format", "(", "dataset", ",", "attack_name", ",", "detector", ",", "adv_arch", ")", "]", "[", "shot", "]", "=", "evaluate_result", "\n", "\n", "", "return", "result", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.shots_evaluation.evaluate_shots": [[21, 87], ["str", "re.compile", "collections.defaultdict", "glob.glob", "re.compile.match", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "float", "print", "open", "file_obj.write", "file_obj.flush", "extract_pattern_detail.match.group", "dataset.meta_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "image_rotate_detector.image_rotate.ImageTransformCV2", "image_rotate_detector.rotate_detector.Detector", "torch.load", "image_rotate_detector.rotate_detector.Detector.load_state_dict", "image_rotate_detector.rotate_detector.Detector.cuda", "print", "evaluation_toolkit.evaluation.finetune_eval_task_accuracy", "json.dumps", "extract_pattern_detail.match.group", "os.path.basename", "networks.resnet.resnet10", "networks.resnet.resnet18", "networks.conv3.Conv3"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation_toolkit.evaluation.finetune_eval_task_accuracy", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet10", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet18"], ["result", "=", "defaultdict", "(", "dict", ")", "\n", "assert", "protocol", "==", "SPLIT_DATA_PROTOCOL", ".", "TRAIN_I_TEST_II", ",", "\"protocol {} is not TRAIN_I_TEST_II!\"", ".", "format", "(", "protocol", ")", "\n", "for", "model_path", "in", "model_path_list", ":", "\n", "        ", "ma", "=", "extract_pattern_detail", ".", "match", "(", "model_path", ")", "\n", "dataset", "=", "ma", ".", "group", "(", "1", ")", "\n", "if", "dataset", "==", "\"ImageNet\"", ":", "\n", "            ", "continue", "\n", "", "file_protocol", "=", "ma", ".", "group", "(", "2", ")", "\n", "if", "str", "(", "protocol", ")", "!=", "file_protocol", ":", "\n", "            ", "continue", "\n", "", "balance", "=", "ma", ".", "group", "(", "8", ")", "\n", "if", "balance", "==", "\"True\"", ":", "\n", "            ", "balance", "=", "\"balance\"", "\n", "", "else", ":", "\n", "            ", "balance", "=", "\"no_balance\"", "\n", "\n", "\n", "", "print", "(", "\"evaluate_accuracy model :{}\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "model_path", ")", ")", ")", "\n", "arch", "=", "ma", ".", "group", "(", "3", ")", "\n", "adv_arch", "=", "ma", ".", "group", "(", "4", ")", "\n", "\n", "if", "arch", "==", "\"conv3\"", ":", "\n", "            ", "model", "=", "Conv3", "(", "IN_CHANNELS", "[", "dataset", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", ",", "2", ")", "\n", "", "elif", "arch", "==", "\"resnet10\"", ":", "\n", "            ", "model", "=", "resnet10", "(", "2", ",", "in_channels", "=", "IN_CHANNELS", "[", "dataset", "]", ",", "pretrained", "=", "False", ")", "\n", "", "elif", "arch", "==", "\"resnet18\"", ":", "\n", "            ", "model", "=", "resnet18", "(", "2", ",", "in_channels", "=", "IN_CHANNELS", "[", "dataset", "]", ",", "pretrained", "=", "False", ")", "\n", "", "model", "=", "model", ".", "cuda", "(", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "model_path", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "old_num_update", "=", "num_update", "\n", "# for shot in range(16):", "\n", "for", "shot", "in", "[", "0", ",", "1", ",", "5", "]", ":", "\n", "            ", "if", "shot", "==", "0", ":", "\n", "                ", "shot", "=", "1", "\n", "num_update", "=", "0", "\n", "", "else", ":", "\n", "                ", "num_update", "=", "old_num_update", "\n", "", "meta_task_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "way", ",", "shot", ",", "query", ",", "\n", "dataset", ",", "is_train", "=", "False", ",", "\n", "load_mode", "=", "LOAD_TASK_MODE", ".", "NO_LOAD", ",", "\n", "protocol", "=", "protocol", ",", "no_random_way", "=", "True", ",", "adv_arch", "=", "adv_arch", ")", "\n", "data_loader", "=", "DataLoader", "(", "meta_task_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "pin_memory", "=", "True", ")", "\n", "evaluate_result", "=", "finetune_eval_task_accuracy", "(", "model", ",", "data_loader", ",", "lr", ",", "num_update", ",", "update_BN", "=", "False", ")", "\n", "if", "num_update", "==", "0", ":", "\n", "                ", "shot", "=", "0", "\n", "", "result", "[", "\"{}@{}@{}\"", ".", "format", "(", "dataset", ",", "balance", ",", "adv_arch", ")", "]", "[", "shot", "]", "=", "evaluate_result", "\n", "", "", "return", "result", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.cross_domain_evaluation.evaluate_cross_domain": [[20, 76], ["str", "re.compile", "collections.defaultdict", "glob.glob", "re.compile.match", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "int", "float", "int", "print", "open", "file_obj.write", "file_obj.flush", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "dataset.meta_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "networks.conv3.Conv3", "image_rotate_detector.image_rotate.ImageTransformCV2", "image_rotate_detector.rotate_detector.Detector", "torch.load", "image_rotate_detector.rotate_detector.Detector.load_state_dict", "image_rotate_detector.rotate_detector.Detector.cuda", "print", "evaluation_toolkit.evaluation.finetune_eval_task_accuracy", "json.dumps", "extract_pattern_detail.match.group", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation_toolkit.evaluation.finetune_eval_task_accuracy"], ["def", "evaluate_cross_domain", "(", "args", ")", ":", "\n", "# 0-shot\u7684\u65f6\u5019\u8bf7\u4f20\u9012args.num_updates = 0", "\n", "    ", "os", ".", "environ", "[", "\"CUDA_DEVICE_ORDER\"", "]", "=", "\"PCI_BUS_ID\"", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "str", "(", "args", ".", "gpus", "[", "0", "]", "[", "0", "]", ")", "\n", "# IMG_ROTATE_DET@CIFAR-10_TRAIN_II_TEST_I@model_conv3@data_conv4@epoch_20@lr_0.001@batch_100@no_fix_cnn_params.pth.tar", "\n", "extract_pattern_detail", "=", "re", ".", "compile", "(", "\n", "\".*?IMG_ROTATE_DET@(.*?)_(.*?)@model_(.*?)@data_(.*?)@epoch_(\\d+)@lr_(.*?)@batch_(\\d+)\\.pth.tar\"", ")", "\n", "result", "=", "defaultdict", "(", "dict", ")", "\n", "# IMG_ROTATE_DET@CIFAR-10_TRAIN_I_TEST_II@conv3@epoch_20@lr_0.001@batch_100@no_fix_cnn_params.pth.tar", "\n", "for", "model_path", "in", "glob", ".", "glob", "(", "\"{}/train_pytorch_model/ROTATE_DET/cv2_rotate_model/IMG_ROTATE_DET*\"", ".", "format", "(", "PY_ROOT", ")", ")", ":", "\n", "        ", "ma", "=", "extract_pattern_detail", ".", "match", "(", "model_path", ")", "\n", "dataset", "=", "ma", ".", "group", "(", "1", ")", "\n", "split_protocol", "=", "SPLIT_DATA_PROTOCOL", "[", "ma", ".", "group", "(", "2", ")", "]", "\n", "if", "split_protocol", "!=", "args", ".", "protocol", ":", "\n", "            ", "continue", "\n", "", "if", "dataset", "!=", "args", ".", "cross_domain_source", ":", "\n", "            ", "continue", "\n", "", "dataset", "=", "args", ".", "cross_domain_target", "\n", "arch", "=", "ma", ".", "group", "(", "3", ")", "\n", "adv_data_arch", "=", "ma", ".", "group", "(", "4", ")", "\n", "epoch", "=", "int", "(", "ma", ".", "group", "(", "5", ")", ")", "\n", "lr", "=", "float", "(", "ma", ".", "group", "(", "6", ")", ")", "\n", "batch_size", "=", "int", "(", "ma", ".", "group", "(", "7", ")", ")", "\n", "print", "(", "\"evaluate_accuracy model :{}\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "model_path", ")", ")", ")", "\n", "tot_num_tasks", "=", "20000", "\n", "num_classes", "=", "2", "\n", "\n", "num_query", "=", "15", "\n", "old_num_update", "=", "args", ".", "num_updates", "\n", "for", "shot", "in", "[", "0", ",", "1", ",", "5", "]", ":", "\n", "            ", "if", "shot", "==", "0", ":", "\n", "                ", "shot", "=", "1", "\n", "num_update", "=", "0", "\n", "", "else", ":", "\n", "                ", "num_update", "=", "old_num_update", "\n", "", "meta_task_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "num_classes", ",", "shot", ",", "num_query", ",", "\n", "dataset", ",", "is_train", "=", "False", ",", "load_mode", "=", "args", ".", "load_mode", ",", "\n", "protocol", "=", "split_protocol", ",", "no_random_way", "=", "True", ",", "adv_arch", "=", "adv_data_arch", ",", "fetch_attack_name", "=", "False", ")", "# FIXME adv arch\u8fd8\u6ca1\u505a\u5176\u4ed6architecture\u7684\u4ee3\u7801", "\n", "data_loader", "=", "DataLoader", "(", "meta_task_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "pin_memory", "=", "True", ")", "\n", "img_classifier_network", "=", "Conv3", "(", "IN_CHANNELS", "[", "dataset", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", ",", "\n", "CLASS_NUM", "[", "dataset", "]", ")", "\n", "image_transform", "=", "ImageTransformCV2", "(", "dataset", ",", "[", "1", ",", "2", "]", ")", "\n", "layer_number", "=", "3", "if", "args", ".", "cross_domain_source", "in", "[", "\"CIFAR-10\"", ",", "\"CIFAR-100\"", ",", "\"SVHN\"", "]", "else", "2", "\n", "model", "=", "Detector", "(", "dataset", ",", "img_classifier_network", ",", "CLASS_NUM", "[", "dataset", "]", ",", "image_transform", ",", "layer_number", ",", "num_classes", "=", "2", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "model_path", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "evaluate_result", "=", "finetune_eval_task_accuracy", "(", "model", ",", "data_loader", ",", "lr", ",", "num_update", ",", "update_BN", "=", "False", ")", "\n", "if", "num_update", "==", "0", ":", "\n", "                ", "shot", "=", "0", "\n", "", "result", "[", "\"{}-->{}@data_arch_{}\"", ".", "format", "(", "args", ".", "cross_domain_source", ",", "args", ".", "cross_domain_target", ",", "adv_data_arch", ")", "]", "[", "shot", "]", "=", "evaluate_result", "\n", "", "", "with", "open", "(", "\"{}/train_pytorch_model/ROTATE_DET/cv2_rotate_model/cross_domain_{}--{}_result.json\"", ".", "format", "(", "PY_ROOT", ",", "args", ".", "cross_domain_source", ",", "args", ".", "cross_domain_target", ")", ",", "\"w\"", ")", "as", "file_obj", ":", "\n", "        ", "file_obj", ".", "write", "(", "json", ".", "dumps", "(", "result", ")", ")", "\n", "file_obj", ".", "flush", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.white_box_evaluation.evaluate_whitebox_attack": [[18, 82], ["str", "re.compile", "collections.defaultdict", "os.path.exists", "re.compile.match", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "int", "float", "int", "print", "torch.load", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "open", "file_obj.write", "file_obj.flush", "extract_pattern_detail.match.group", "os.path.basename", "dataset.white_box_attack_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "networks.conv3.Conv3", "image_rotate_detector.image_rotate.ImageTransformTorch", "image_rotate_detector.rotate_detector.Detector", "image_rotate_detector.rotate_detector.Detector.load_state_dict", "image_rotate_detector.rotate_detector.Detector.cuda", "print", "evaluation_toolkit.evaluation.finetune_eval_task_rotate", "json.dumps"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation_toolkit.evaluation.finetune_eval_task_rotate"], ["way", "=", "2", "\n", "query", "=", "15", "\n", "\n", "model_path", "=", "\"{}/train_pytorch_model/white_box_model/DL_DET@{}_{}@model_{}@data_{}@epoch_40@class_2@lr_0.0001@balance_True.pth.tar\"", ".", "format", "(", "\n", "PY_ROOT", ",", "dataset", ",", "protocol", ",", "arch", ",", "adv_arch", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "model_path", ")", ",", "\"{} is not exists\"", ".", "format", "(", "model_path", ")", "\n", "root_folder", "=", "IMAGE_DATA_ROOT", "[", "dataset", "]", "+", "\"/adversarial_images/white_box@data_{}@det_{}/{}/\"", ".", "format", "(", "adv_arch", ",", "detector", ",", "attack_name", ")", "\n", "ma", "=", "extract_pattern_detail", ".", "match", "(", "model_path", ")", "\n", "balance", "=", "ma", ".", "group", "(", "8", ")", "\n", "if", "balance", "==", "\"True\"", ":", "\n", "        ", "balance", "=", "\"balance\"", "\n", "", "else", ":", "\n", "        ", "balance", "=", "\"no_balance\"", "\n", "", "print", "(", "\"evaluate_accuracy model :{}\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "model_path", ")", ")", ")", "\n", "arch", "=", "ma", ".", "group", "(", "3", ")", "\n", "model", "=", "Conv3", "(", "IN_CHANNELS", "[", "dataset", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", ",", "2", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "model_path", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "\n", "old_num_update", "=", "num_update", "\n", "# for shot in range(16):", "\n", "for", "shot", "in", "[", "0", ",", "1", ",", "5", "]", ":", "\n", "        ", "if", "shot", "==", "0", ":", "\n", "            ", "shot", "=", "1", "\n", "num_update", "=", "0", "\n", "", "else", ":", "\n", "            ", "num_update", "=", "old_num_update", "\n", "\n", "", "meta_task_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "way", ",", "shot", ",", "query", ",", "\n", "dataset", ",", "\n", "load_mode", "=", "load_mode", ",", "detector", "=", "detector", ",", "attack_name", "=", "attack_name", ",", "root_folder", "=", "root_folder", ")", "\n", "data_loader", "=", "DataLoader", "(", "meta_task_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "pin_memory", "=", "True", ")", "\n", "evaluate_result", "=", "finetune_eval_task_accuracy", "(", "model", ",", "data_loader", ",", "lr", ",", "num_update", ",", "update_BN", "=", "True", ")", "\n", "if", "num_update", "==", "0", ":", "\n", "            ", "shot", "=", "0", "\n", "", "result", "[", "\"{}_{}_{}_{}\"", ".", "format", "(", "dataset", ",", "attack_name", ",", "detector", ",", "adv_arch", ")", "]", "[", "shot", "]", "=", "evaluate_result", "\n", "\n", "", "return", "result", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.cross_arch_evaluation.evaluate_cross_arch": [[20, 76], ["str", "re.compile", "collections.defaultdict", "glob.glob", "re.compile.match", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "int", "float", "int", "print", "open", "file_obj.write", "file_obj.flush", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "dataset.meta_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "networks.conv3.Conv3", "image_rotate_detector.image_rotate.ImageTransformCV2", "image_rotate_detector.rotate_detector.Detector", "torch.load", "image_rotate_detector.rotate_detector.Detector.load_state_dict", "image_rotate_detector.rotate_detector.Detector.cuda", "print", "evaluation_toolkit.evaluation.finetune_eval_task_accuracy", "json.dumps", "extract_pattern_detail.match.group", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation_toolkit.evaluation.finetune_eval_task_accuracy"], ["def", "evaluate_cross_arch", "(", "args", ")", ":", "\n", "# 0-shot\u7684\u65f6\u5019\u8bf7\u4f20\u9012args.num_updates = 0", "\n", "    ", "os", ".", "environ", "[", "\"CUDA_DEVICE_ORDER\"", "]", "=", "\"PCI_BUS_ID\"", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "str", "(", "args", ".", "gpus", "[", "0", "]", "[", "0", "]", ")", "\n", "# IMG_ROTATE_DET@CIFAR-10_TRAIN_ALL_TEST_ALL@model_conv3@data_conv3@epoch_10@lr_0.0001@batch_100@no_fix_cnn_params.pth.tar", "\n", "extract_pattern_detail", "=", "re", ".", "compile", "(", "\n", "\".*?IMG_ROTATE_DET@(.*?)_(.*?)@model_(.*?)@data_(.*?)@epoch_(\\d+)@lr_(.*?)@batch_(\\d+)\\.pth.tar\"", ")", "\n", "result", "=", "defaultdict", "(", "dict", ")", "\n", "update_BN", "=", "False", "\n", "for", "model_path", "in", "glob", ".", "glob", "(", "\"{}/train_pytorch_model/ROTATE_DET/cv2_rotate_model/IMG_ROTATE_DET*\"", ".", "format", "(", "PY_ROOT", ")", ")", ":", "\n", "        ", "ma", "=", "extract_pattern_detail", ".", "match", "(", "model_path", ")", "\n", "dataset", "=", "ma", ".", "group", "(", "1", ")", "\n", "split_protocol", "=", "SPLIT_DATA_PROTOCOL", "[", "ma", ".", "group", "(", "2", ")", "]", "\n", "if", "split_protocol", "!=", "args", ".", "protocol", ":", "\n", "            ", "continue", "\n", "", "arch", "=", "ma", ".", "group", "(", "3", ")", "\n", "adv_arch", "=", "ma", ".", "group", "(", "4", ")", "\n", "if", "adv_arch", "!=", "args", ".", "cross_arch_source", ":", "\n", "            ", "continue", "\n", "\n", "", "epoch", "=", "int", "(", "ma", ".", "group", "(", "5", ")", ")", "\n", "lr", "=", "float", "(", "ma", ".", "group", "(", "6", ")", ")", "\n", "batch_size", "=", "int", "(", "ma", ".", "group", "(", "7", ")", ")", "\n", "print", "(", "\"evaluate_accuracy model :{}\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "model_path", ")", ")", ")", "\n", "tot_num_tasks", "=", "20000", "\n", "num_classes", "=", "2", "\n", "num_query", "=", "15", "\n", "old_num_update", "=", "args", ".", "num_updates", "\n", "for", "shot", "in", "[", "0", ",", "1", ",", "5", "]", ":", "\n", "            ", "if", "shot", "==", "0", ":", "\n", "                ", "shot", "=", "1", "\n", "num_update", "=", "0", "\n", "", "else", ":", "\n", "                ", "num_update", "=", "old_num_update", "\n", "", "meta_task_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "num_classes", ",", "shot", ",", "num_query", ",", "\n", "dataset", ",", "is_train", "=", "False", ",", "load_mode", "=", "args", ".", "load_mode", ",", "\n", "protocol", "=", "split_protocol", ",", "no_random_way", "=", "True", ",", "adv_arch", "=", "args", ".", "cross_arch_target", ",", "fetch_attack_name", "=", "False", ")", "\n", "data_loader", "=", "DataLoader", "(", "meta_task_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "pin_memory", "=", "True", ")", "\n", "img_classifier_network", "=", "Conv3", "(", "IN_CHANNELS", "[", "dataset", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", ",", "\n", "CLASS_NUM", "[", "dataset", "]", ")", "\n", "image_transform", "=", "ImageTransformCV2", "(", "dataset", ",", "[", "1", ",", "2", "]", ")", "\n", "layer_number", "=", "3", "if", "dataset", "in", "[", "\"CIFAR-10\"", ",", "\"CIFAR-100\"", ",", "\"SVHN\"", "]", "else", "2", "\n", "model", "=", "Detector", "(", "dataset", ",", "img_classifier_network", ",", "CLASS_NUM", "[", "dataset", "]", ",", "image_transform", ",", "layer_number", ",", "num_classes", "=", "2", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "model_path", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "evaluate_result", "=", "finetune_eval_task_accuracy", "(", "model", ",", "data_loader", ",", "lr", ",", "num_update", ",", "update_BN", "=", "update_BN", ")", "# FIXME update_BN=False\u4f1a\u5f88\u9ad8", "\n", "if", "num_update", "==", "0", ":", "\n", "                ", "shot", "=", "0", "\n", "", "result", "[", "\"{}@{}-->{}\"", ".", "format", "(", "dataset", ",", "args", ".", "cross_arch_source", ",", "args", ".", "cross_arch_target", ")", "]", "[", "shot", "]", "=", "evaluate_result", "\n", "", "", "with", "open", "(", "\"{}/train_pytorch_model/ROTATE_DET/cv2_rotate_model/cross_arch_{}--{}_using_{}_result_updateBN_{}.json\"", ".", "format", "(", "PY_ROOT", ",", "args", ".", "cross_arch_source", ",", "\n", "args", ".", "cross_arch_target", ",", "args", ".", "protocol", ",", "update_BN", ")", ",", "\"w\"", ")", "as", "file_obj", ":", "\n", "        ", "file_obj", ".", "write", "(", "json", ".", "dumps", "(", "result", ")", ")", "\n", "file_obj", ".", "flush", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.zero_shot_evaluation.meta_zero_shot_evaluate": [[14, 67], ["re.compile", "re.compile", "collections.defaultdict", "glob.glob", "re.compile.match", "extract_param_prefix.match.group", "re.compile.match", "extract_pattern.match.group", "extract_pattern.match.group", "int", "int", "int", "int", "int", "int", "float", "float", "str2bool", "str2bool", "torch.load", "meta_adv_detector.meta_adv_det.MetaLearner", "meta_adv_detector.meta_adv_det.MetaLearner.network.load_state_dict", "evaluation_toolkit.evaluation.finetune_eval_task_accuracy", "open", "file_obj.write", "file_obj.flush", "v.lower", "str", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "json.dumps", "extract_pattern.match.group"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation_toolkit.evaluation.finetune_eval_task_accuracy"], ["def", "evaluate_zero_shot", "(", "model_path_list", ",", "lr", ",", "protocol", ",", "args", ")", ":", "\n", "# deep learning\u8bad\u7ec3\u662f\u5728all_in\u6216\u8005sampled all in\u4e0b\u8bad\u7ec3\u7684\uff0c\u4f46\u662f\u6d4b\u8bd5\u9700\u8981\u5728task\u7248\u672c\u7684dataset\u4e0a\u505a", "\n", "    ", "extract_pattern_detail", "=", "re", ".", "compile", "(", "\".*?DL_DET@(.*?)_(TRAIN_.*?)@model_(.*?)@data_(.*?)@epoch_(\\d+)@class_(\\d+)@lr_(.*?)@balance_(.*?)\\.pth\\.tar\"", ")", "\n", "tot_num_tasks", "=", "20000", "\n", "way", "=", "2", "\n", "query", "=", "15", "\n", "result", "=", "defaultdict", "(", "dict", ")", "\n", "for", "model_path", "in", "model_path_list", ":", "\n", "        ", "ma", "=", "extract_pattern_detail", ".", "match", "(", "model_path", ")", "\n", "dataset", "=", "ma", ".", "group", "(", "1", ")", "\n", "file_protocol", "=", "ma", ".", "group", "(", "2", ")", "\n", "if", "str", "(", "protocol", ")", "!=", "file_protocol", ":", "\n", "            ", "continue", "\n", "", "balance", "=", "ma", ".", "group", "(", "8", ")", "\n", "if", "balance", "==", "\"True\"", ":", "\n", "            ", "balance", "=", "\"balance\"", "\n", "", "else", ":", "\n", "            ", "balance", "=", "\"no_balance\"", "\n", "\n", "", "key", "=", "\"{}@{}__{}\"", ".", "format", "(", "dataset", ",", "balance", ",", "protocol", ")", "\n", "if", "args", ".", "cross_domain_source", "is", "not", "None", ":", "\n", "            ", "if", "dataset", "!=", "args", ".", "cross_domain_source", ":", "\n", "                ", "continue", "\n", "", "dataset", "=", "args", ".", "cross_domain_target", "\n", "key", "=", "\"{}@{}-->{}__{}\"", ".", "format", "(", "args", ".", "cross_domain_source", ",", "balance", ",", "dataset", ",", "protocol", ")", "\n", "\n", "", "print", "(", "\"evaluate_accuracy model :{}\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "model_path", ")", ")", ")", "\n", "arch", "=", "ma", ".", "group", "(", "3", ")", "\n", "adv_arch", "=", "ma", ".", "group", "(", "4", ")", "\n", "model", "=", "Conv3", "(", "IN_CHANNELS", "[", "dataset", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", ",", "2", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "model_path", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "shot", "=", "1", "\n", "num_update", "=", "0", "\n", "meta_task_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "way", ",", "shot", ",", "query", ",", "\n", "dataset", ",", "is_train", "=", "False", ",", "\n", "load_mode", "=", "LOAD_TASK_MODE", ".", "LOAD", ",", "\n", "protocol", "=", "protocol", ",", "no_random_way", "=", "True", ",", "adv_arch", "=", "adv_arch", ")", "\n", "data_loader", "=", "DataLoader", "(", "meta_task_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "pin_memory", "=", "True", ")", "\n", "evaluate_result", "=", "finetune_eval_task_accuracy", "(", "model", ",", "data_loader", ",", "lr", ",", "num_update", ",", "update_BN", "=", "False", ")", "\n", "result", "[", "key", "]", "[", "0", "]", "=", "evaluate_result", "\n", "", "return", "result", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.cross_domain_evaluation.meta_cross_domain_evaluate": [[15, 65], ["re.compile", "re.compile", "collections.defaultdict", "glob.glob", "open", "file_obj.write", "file_obj.flush", "v.lower", "re.compile.match", "extract_param_prefix.match.group", "re.compile.match", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "int", "int", "int", "int", "float", "float", "str2bool", "print", "torch.load", "meta_adv_detector.meta_adv_det.MetaLearner", "meta_adv_detector.meta_adv_det.MetaLearner.network.load_state_dict", "evaluation_toolkit.evaluation.finetune_eval_task_accuracy", "json.dumps", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation_toolkit.evaluation.finetune_eval_task_accuracy"], ["from", "image_rotate_detector", ".", "image_rotate", "import", "ImageTransformCV2", "\n", "from", "image_rotate_detector", ".", "rotate_detector", "import", "Detector", "\n", "from", "networks", ".", "conv3", "import", "Conv3", "\n", "\n", "\n", "def", "evaluate_cross_domain", "(", "args", ")", ":", "\n", "# 0-shot\u7684\u65f6\u5019\u8bf7\u4f20\u9012args.num_updates = 0", "\n", "    ", "os", ".", "environ", "[", "\"CUDA_DEVICE_ORDER\"", "]", "=", "\"PCI_BUS_ID\"", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "str", "(", "args", ".", "gpus", "[", "0", "]", "[", "0", "]", ")", "\n", "# IMG_ROTATE_DET@CIFAR-10_TRAIN_II_TEST_I@model_conv3@data_conv4@epoch_20@lr_0.001@batch_100@no_fix_cnn_params.pth.tar", "\n", "extract_pattern_detail", "=", "re", ".", "compile", "(", "\n", "\".*?IMG_ROTATE_DET@(.*?)_(.*?)@model_(.*?)@data_(.*?)@epoch_(\\d+)@lr_(.*?)@batch_(\\d+)\\.pth.tar\"", ")", "\n", "result", "=", "defaultdict", "(", "dict", ")", "\n", "# IMG_ROTATE_DET@CIFAR-10_TRAIN_I_TEST_II@conv3@epoch_20@lr_0.001@batch_100@no_fix_cnn_params.pth.tar", "\n", "for", "model_path", "in", "glob", ".", "glob", "(", "\"{}/train_pytorch_model/ROTATE_DET/cv2_rotate_model/IMG_ROTATE_DET*\"", ".", "format", "(", "PY_ROOT", ")", ")", ":", "\n", "        ", "ma", "=", "extract_pattern_detail", ".", "match", "(", "model_path", ")", "\n", "dataset", "=", "ma", ".", "group", "(", "1", ")", "\n", "split_protocol", "=", "SPLIT_DATA_PROTOCOL", "[", "ma", ".", "group", "(", "2", ")", "]", "\n", "if", "split_protocol", "!=", "args", ".", "protocol", ":", "\n", "            ", "continue", "\n", "", "if", "dataset", "!=", "args", ".", "cross_domain_source", ":", "\n", "            ", "continue", "\n", "", "dataset", "=", "args", ".", "cross_domain_target", "\n", "arch", "=", "ma", ".", "group", "(", "3", ")", "\n", "adv_data_arch", "=", "ma", ".", "group", "(", "4", ")", "\n", "epoch", "=", "int", "(", "ma", ".", "group", "(", "5", ")", ")", "\n", "lr", "=", "float", "(", "ma", ".", "group", "(", "6", ")", ")", "\n", "batch_size", "=", "int", "(", "ma", ".", "group", "(", "7", ")", ")", "\n", "print", "(", "\"evaluate_accuracy model :{}\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "model_path", ")", ")", ")", "\n", "tot_num_tasks", "=", "20000", "\n", "num_classes", "=", "2", "\n", "\n", "num_query", "=", "15", "\n", "old_num_update", "=", "args", ".", "num_updates", "\n", "for", "shot", "in", "[", "0", ",", "1", ",", "5", "]", ":", "\n", "            ", "if", "shot", "==", "0", ":", "\n", "                ", "shot", "=", "1", "\n", "num_update", "=", "0", "\n", "", "else", ":", "\n", "                ", "num_update", "=", "old_num_update", "\n", "", "meta_task_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "num_classes", ",", "shot", ",", "num_query", ",", "\n", "dataset", ",", "is_train", "=", "False", ",", "load_mode", "=", "args", ".", "load_mode", ",", "\n", "protocol", "=", "split_protocol", ",", "no_random_way", "=", "True", ",", "adv_arch", "=", "adv_data_arch", ",", "fetch_attack_name", "=", "False", ")", "# FIXME adv arch\u8fd8\u6ca1\u505a\u5176\u4ed6architecture\u7684\u4ee3\u7801", "\n", "data_loader", "=", "DataLoader", "(", "meta_task_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "pin_memory", "=", "True", ")", "\n", "img_classifier_network", "=", "Conv3", "(", "IN_CHANNELS", "[", "dataset", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", ",", "\n", "CLASS_NUM", "[", "dataset", "]", ")", "\n", "image_transform", "=", "ImageTransformCV2", "(", "dataset", ",", "[", "1", ",", "2", "]", ")", "\n", "layer_number", "=", "3", "if", "args", ".", "cross_domain_source", "in", "[", "\"CIFAR-10\"", ",", "\"CIFAR-100\"", ",", "\"SVHN\"", "]", "else", "2", "\n", "model", "=", "Detector", "(", "dataset", ",", "img_classifier_network", ",", "CLASS_NUM", "[", "dataset", "]", ",", "image_transform", ",", "layer_number", ",", "num_classes", "=", "2", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.white_box_evaluation.meta_white_box_attack_evaluate": [[10, 50], ["collections.defaultdict", "re.compile", "os.path.exists", "re.compile.match", "extract_pattern.match.group", "int", "int", "int", "float", "float", "print", "torch.load", "open", "file_obj.write", "file_obj.flush", "v.lower", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "print", "meta_adv_detector.white_box_meta_adv_det.MetaLearner", "meta_adv_detector.white_box_meta_adv_det.MetaLearner.network.load_state_dict", "meta_adv_detector.white_box_meta_adv_det.MetaLearner.test_task_F1", "json.dumps"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.ablation_study.meta_adv_det_task_net.MetaLearnerTasknetOnly.test_task_F1"], ["from", "dataset", ".", "white_box_attack_task_dataset", "import", "MetaTaskDataset", "\n", "from", "dataset", ".", "protocol_enum", "import", "SPLIT_DATA_PROTOCOL", ",", "LOAD_TASK_MODE", "\n", "\n", "\n", "def", "evaluate_whitebox", "(", "dataset", ",", "arch", ",", "adv_arch", ",", "detector", ",", "attack_name", ",", "num_update", ",", "lr", ",", "protocol", ",", "load_mode", ",", "result", ")", ":", "\n", "# deep learning\u8bad\u7ec3\u662f\u5728all_in\u6216\u8005sampled all in\u4e0b\u8bad\u7ec3\u7684\uff0c\u4f46\u662f\u6d4b\u8bd5\u9700\u8981\u5728task\u7248\u672c\u7684dataset\u4e0a\u505a", "\n", "    ", "extract_pattern_detail", "=", "re", ".", "compile", "(", "\".*?DL_DET@(.*?)_(TRAIN_.*?)@model_(.*?)@data_(.*?)@epoch_(\\d+)@class_(\\d+)@lr_(.*?)@balance_(.*?)\\.pth\\.tar\"", ")", "\n", "tot_num_tasks", "=", "20000", "\n", "way", "=", "2", "\n", "query", "=", "15", "\n", "\n", "model_path", "=", "\"{}/train_pytorch_model/white_box_model/DL_DET@{}_{}@model_{}@data_{}@epoch_40@class_2@lr_0.0001@balance_True.pth.tar\"", ".", "format", "(", "\n", "PY_ROOT", ",", "dataset", ",", "protocol", ",", "arch", ",", "adv_arch", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "model_path", ")", ",", "\"{} is not exists\"", ".", "format", "(", "model_path", ")", "\n", "root_folder", "=", "IMAGE_DATA_ROOT", "[", "dataset", "]", "+", "\"/adversarial_images/white_box@data_{}@det_{}/{}/\"", ".", "format", "(", "adv_arch", ",", "detector", ",", "attack_name", ")", "\n", "ma", "=", "extract_pattern_detail", ".", "match", "(", "model_path", ")", "\n", "balance", "=", "ma", ".", "group", "(", "8", ")", "\n", "if", "balance", "==", "\"True\"", ":", "\n", "        ", "balance", "=", "\"balance\"", "\n", "", "else", ":", "\n", "        ", "balance", "=", "\"no_balance\"", "\n", "", "print", "(", "\"evaluate_accuracy model :{}\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "model_path", ")", ")", ")", "\n", "arch", "=", "ma", ".", "group", "(", "3", ")", "\n", "model", "=", "Conv3", "(", "IN_CHANNELS", "[", "dataset", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", ",", "2", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "model_path", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "\n", "old_num_update", "=", "num_update", "\n", "# for shot in range(16):", "\n", "for", "shot", "in", "[", "0", ",", "1", ",", "5", "]", ":", "\n", "        ", "if", "shot", "==", "0", ":", "\n", "            ", "shot", "=", "1", "\n", "num_update", "=", "0", "\n", "", "else", ":", "\n", "            ", "num_update", "=", "old_num_update", "\n", "\n", "", "meta_task_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "way", ",", "shot", ",", "query", ",", "\n", "dataset", ",", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.ablation_study_evaluation.meta_ablation_study_evaluate": [[15, 103], ["re.compile", "re.compile", "collections.defaultdict", "glob.glob", "re.compile.match", "extract_param_prefix.match.group", "re.compile.match", "extract_pattern.match.group", "extract_pattern.match.group", "int", "int", "int", "int", "int", "int", "float", "float", "str2bool", "str2bool", "print", "torch.load", "open", "file_obj.write", "file_obj.flush", "v.lower", "str", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "meta_adv_detector.meta_adv_det.MetaLearner", "meta_adv_detector.meta_adv_det.MetaLearner.network.load_state_dict", "range", "json.dumps", "extract_pattern.match.group", "evaluation_toolkit.evaluation.finetune_eval_task_accuracy", "meta_adv_detector.meta_adv_det.MetaLearner", "meta_adv_detector.meta_adv_det.MetaLearner.network.load_state_dict", "meta_adv_detector.meta_adv_det.MetaLearner.test_zero_shot_with_finetune_trainset", "meta_adv_detector.meta_adv_det.MetaLearner", "meta_adv_detector.meta_adv_det.MetaLearner.network.load_state_dict", "evaluation_toolkit.evaluation.finetune_eval_task_accuracy"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation_toolkit.evaluation.finetune_eval_task_accuracy", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.meta_adv_det.MetaLearner.test_zero_shot_with_finetune_trainset", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation_toolkit.evaluation.finetune_eval_task_accuracy"], ["def", "meta_ablation_study_evaluate", "(", "args", ")", ":", "\n", "    ", "extract_pattern", "=", "re", ".", "compile", "(", "\n", "\".*/MAML@(.*?)_(.*?)@model_(.*?)@data.*?@epoch_(\\d+)@meta_batch_size_(\\d+)@way_(\\d+)@shot_(\\d+)@num_query_(\\d+)@num_updates_(\\d+)@lr_(.*?)@inner_lr_(.*?)@fixed_way_(.*?)@rotate_(.*?)\\.pth.tar\"", ")", "\n", "extract_param_prefix", "=", "re", ".", "compile", "(", "\".*/MAML@(.*?)\\.pth.tar\"", ")", "\n", "report_result", "=", "defaultdict", "(", "dict", ")", "\n", "str2bool", "=", "lambda", "v", ":", "v", ".", "lower", "(", ")", "in", "(", "\"yes\"", ",", "\"true\"", ",", "\"t\"", ",", "\"1\"", ")", "\n", "for", "model_path", "in", "glob", ".", "glob", "(", "\"{}/train_pytorch_model/{}/MAML@*\"", ".", "format", "(", "PY_ROOT", ",", "args", ".", "study_subject", ")", ")", ":", "\n", "        ", "if", "str", "(", "args", ".", "split_protocol", ")", "not", "in", "model_path", ":", "\n", "            ", "continue", "\n", "", "ma_prefix", "=", "extract_param_prefix", ".", "match", "(", "model_path", ")", "\n", "param_prefix", "=", "ma_prefix", ".", "group", "(", "1", ")", "\n", "ma", "=", "extract_pattern", ".", "match", "(", "model_path", ")", "\n", "orig_ma", "=", "ma", "\n", "dataset", "=", "ma", ".", "group", "(", "1", ")", "\n", "if", "dataset", "==", "\"ImageNet\"", ":", "\n", "            ", "continue", "\n", "", "split_protocol", "=", "SPLIT_DATA_PROTOCOL", "[", "ma", ".", "group", "(", "2", ")", "]", "\n", "arch", "=", "ma", ".", "group", "(", "3", ")", "\n", "epoch", "=", "int", "(", "ma", ".", "group", "(", "4", ")", ")", "\n", "meta_batch_size", "=", "int", "(", "ma", ".", "group", "(", "5", ")", ")", "\n", "num_classes", "=", "int", "(", "ma", ".", "group", "(", "6", ")", ")", "\n", "num_support", "=", "int", "(", "ma", ".", "group", "(", "7", ")", ")", "\n", "num_query", "=", "int", "(", "ma", ".", "group", "(", "8", ")", ")", "# \u7528\u8fd9\u4e2anum_query\u6765\u505a", "\n", "num_updates", "=", "int", "(", "ma", ".", "group", "(", "9", ")", ")", "\n", "meta_lr", "=", "float", "(", "ma", ".", "group", "(", "10", ")", ")", "\n", "inner_lr", "=", "float", "(", "ma", ".", "group", "(", "11", ")", ")", "\n", "fixe_way", "=", "str2bool", "(", "ma", ".", "group", "(", "12", ")", ")", "\n", "rotate", "=", "str2bool", "(", "ma", ".", "group", "(", "13", ")", ")", "\n", "extract_key", "=", "param_prefix", "\n", "if", "args", ".", "study_subject", "==", "\"inner_update_ablation_study\"", ":", "\n", "            ", "extract_key", "=", "num_updates", "\n", "", "elif", "args", ".", "study_subject", "==", "\"shots_ablation_study\"", ":", "\n", "            ", "extract_key", "=", "num_support", "\n", "", "elif", "args", ".", "study_subject", "==", "\"cross_adv_group\"", ":", "\n", "            ", "extract_key", "=", "num_support", "\n", "", "elif", "args", ".", "study_subject", "==", "\"tasks_ablation_study\"", ":", "\n", "            ", "extract_key", "=", "meta_batch_size", "\n", "", "elif", "args", ".", "study_subject", "==", "\"ways_ablation_study\"", ":", "\n", "            ", "extract_key", "=", "num_classes", "\n", "", "elif", "args", ".", "study_subject", "==", "\"random_vs_fix_way\"", ":", "\n", "            ", "extract_key", "=", "\"shots_{}_fixed_way_{}\"", ".", "format", "(", "num_support", ",", "fixe_way", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"query_size_ablation_study\"", ":", "\n", "            ", "extract_key", "=", "num_query", "\n", "", "elif", "args", ".", "study_subject", "==", "\"vs_deep_MAX\"", ":", "\n", "            ", "extract_key", "=", "num_support", "\n", "", "elif", "args", ".", "study_subject", "==", "\"zero_shot\"", ":", "\n", "            ", "extract_key", "=", "\"0-shot\"", "\n", "", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "model_path", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "\n", "if", "args", ".", "study_subject", "==", "\"fine_tune_update_ablation_study\"", ":", "# \u8fd9\u4e2a\u5b9e\u9a8c\u91cd\u505a", "\n", "            ", "learner", "=", "MetaLearner", "(", "dataset", ",", "num_classes", ",", "meta_batch_size", ",", "meta_lr", ",", "inner_lr", ",", "args", ".", "lr_decay_itr", ",", "\n", "epoch", ",", "\n", "num_updates", ",", "\n", "args", ".", "load_task_mode", ",", "\n", "split_protocol", ",", "arch", ",", "args", ".", "tot_num_tasks", ",", "num_support", ",", "15", ",", "\n", "True", ",", "param_prefix", ",", "train", "=", "False", ",", "adv_arch", "=", "args", ".", "adv_arch", ",", "need_val", "=", "True", ")", "\n", "learner", ".", "network", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ",", "strict", "=", "True", ")", "\n", "for", "test_num_updates", "in", "range", "(", "1", ",", "51", ")", ":", "\n", "                ", "result_json", "=", "finetune_eval_task_accuracy", "(", "learner", ".", "network", ",", "learner", ".", "val_loader", ",", "inner_lr", ",", "test_num_updates", ",", "update_BN", "=", "True", ")", "\n", "report_result", "[", "dataset", "]", "[", "test_num_updates", "]", "=", "result_json", "\n", "", "", "elif", "args", ".", "study_subject", "==", "\"zero_shot\"", ":", "\n", "            ", "learner", "=", "MetaLearner", "(", "dataset", ",", "num_classes", ",", "meta_batch_size", ",", "meta_lr", ",", "inner_lr", ",", "args", ".", "lr_decay_itr", ",", "epoch", ",", "\n", "args", ".", "test_num_updates", ",", "\n", "args", ".", "load_task_mode", ",", "\n", "split_protocol", ",", "arch", ",", "args", ".", "tot_num_tasks", ",", "num_support", ",", "num_query", ",", "# \u8fd9\u4e2anum_query\u7edf\u4e00\u752815", "\n", "no_random_way", "=", "True", ",", "\n", "tensorboard_data_prefix", "=", "param_prefix", ",", "train", "=", "True", ",", "adv_arch", "=", "args", ".", "adv_arch", ",", "need_val", "=", "True", ")", "\n", "learner", ".", "network", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ",", "strict", "=", "True", ")", "\n", "result_json", "=", "learner", ".", "test_zero_shot_with_finetune_trainset", "(", ")", "\n", "report_result", "[", "dataset", "]", "[", "extract_key", "]", "=", "result_json", "\n", "", "else", ":", "\n", "            ", "load_mode", "=", "args", ".", "load_task_mode", "\n", "learner", "=", "MetaLearner", "(", "dataset", ",", "num_classes", ",", "meta_batch_size", ",", "meta_lr", ",", "inner_lr", ",", "args", ".", "lr_decay_itr", ",", "epoch", ",", "\n", "args", ".", "test_num_updates", ",", "\n", "load_mode", ",", "\n", "split_protocol", ",", "arch", ",", "args", ".", "tot_num_tasks", ",", "num_support", ",", "15", ",", "# \u8fd9\u4e2anum_query\u7edf\u4e00\u752815", "\n", "True", ",", "param_prefix", ",", "train", "=", "False", ",", "adv_arch", "=", "args", ".", "adv_arch", ",", "need_val", "=", "True", ")", "\n", "learner", ".", "network", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ",", "strict", "=", "True", ")", "\n", "result_json", "=", "finetune_eval_task_accuracy", "(", "learner", ".", "network", ",", "learner", ".", "val_loader", ",", "inner_lr", ",", "args", ".", "test_num_updates", ",", "update_BN", "=", "True", ")", "\n", "report_result", "[", "dataset", "]", "[", "extract_key", "]", "=", "result_json", "\n", "\n", "", "", "file_name", "=", "\"{}/train_pytorch_model/{}/{}_result.json\"", ".", "format", "(", "PY_ROOT", ",", "args", ".", "study_subject", ",", "args", ".", "study_subject", ")", "\n", "if", "args", ".", "study_subject", "==", "\"cross_domain\"", ":", "\n", "        ", "file_name", "=", "\"{}/train_pytorch_model/{}/{}--{}_result.json\"", ".", "format", "(", "PY_ROOT", ",", "args", ".", "study_subject", ",", "args", ".", "cross_domain_source", ",", "args", ".", "cross_domain_target", ")", "\n", "", "with", "open", "(", "file_name", ",", "\"w\"", ")", "as", "file_obj", ":", "\n", "        ", "file_obj", ".", "write", "(", "json", ".", "dumps", "(", "report_result", ")", ")", "\n", "file_obj", ".", "flush", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.cross_arch_evaluation.meta_cross_arch_evaluate": [[13, 65], ["re.compile", "re.compile", "collections.defaultdict", "glob.glob", "open", "file_obj.write", "file_obj.flush", "v.lower", "re.compile.match", "extract_param_prefix.match.group", "re.compile.match", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "int", "int", "int", "int", "float", "float", "str2bool", "print", "torch.load", "meta_adv_detector.meta_adv_det.MetaLearner", "meta_adv_detector.meta_adv_det.MetaLearner.network.load_state_dict", "evaluation_toolkit.evaluation.finetune_eval_task_accuracy", "json.dumps", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation_toolkit.evaluation.finetune_eval_task_accuracy"], ["from", "dataset", ".", "protocol_enum", "import", "SPLIT_DATA_PROTOCOL", "\n", "\n", "from", "image_rotate_detector", ".", "image_rotate", "import", "ImageTransformCV2", "\n", "from", "image_rotate_detector", ".", "rotate_detector", "import", "Detector", "\n", "from", "networks", ".", "conv3", "import", "Conv3", "\n", "\n", "\n", "def", "evaluate_cross_arch", "(", "args", ")", ":", "\n", "# 0-shot\u7684\u65f6\u5019\u8bf7\u4f20\u9012args.num_updates = 0", "\n", "    ", "os", ".", "environ", "[", "\"CUDA_DEVICE_ORDER\"", "]", "=", "\"PCI_BUS_ID\"", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "str", "(", "args", ".", "gpus", "[", "0", "]", "[", "0", "]", ")", "\n", "# IMG_ROTATE_DET@CIFAR-10_TRAIN_ALL_TEST_ALL@model_conv3@data_conv3@epoch_10@lr_0.0001@batch_100@no_fix_cnn_params.pth.tar", "\n", "extract_pattern_detail", "=", "re", ".", "compile", "(", "\n", "\".*?IMG_ROTATE_DET@(.*?)_(.*?)@model_(.*?)@data_(.*?)@epoch_(\\d+)@lr_(.*?)@batch_(\\d+)\\.pth.tar\"", ")", "\n", "result", "=", "defaultdict", "(", "dict", ")", "\n", "update_BN", "=", "False", "\n", "for", "model_path", "in", "glob", ".", "glob", "(", "\"{}/train_pytorch_model/ROTATE_DET/cv2_rotate_model/IMG_ROTATE_DET*\"", ".", "format", "(", "PY_ROOT", ")", ")", ":", "\n", "        ", "ma", "=", "extract_pattern_detail", ".", "match", "(", "model_path", ")", "\n", "dataset", "=", "ma", ".", "group", "(", "1", ")", "\n", "split_protocol", "=", "SPLIT_DATA_PROTOCOL", "[", "ma", ".", "group", "(", "2", ")", "]", "\n", "if", "split_protocol", "!=", "args", ".", "protocol", ":", "\n", "            ", "continue", "\n", "", "arch", "=", "ma", ".", "group", "(", "3", ")", "\n", "adv_arch", "=", "ma", ".", "group", "(", "4", ")", "\n", "if", "adv_arch", "!=", "args", ".", "cross_arch_source", ":", "\n", "            ", "continue", "\n", "\n", "", "epoch", "=", "int", "(", "ma", ".", "group", "(", "5", ")", ")", "\n", "lr", "=", "float", "(", "ma", ".", "group", "(", "6", ")", ")", "\n", "batch_size", "=", "int", "(", "ma", ".", "group", "(", "7", ")", ")", "\n", "print", "(", "\"evaluate_accuracy model :{}\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "model_path", ")", ")", ")", "\n", "tot_num_tasks", "=", "20000", "\n", "num_classes", "=", "2", "\n", "num_query", "=", "15", "\n", "old_num_update", "=", "args", ".", "num_updates", "\n", "for", "shot", "in", "[", "0", ",", "1", ",", "5", "]", ":", "\n", "            ", "if", "shot", "==", "0", ":", "\n", "                ", "shot", "=", "1", "\n", "num_update", "=", "0", "\n", "", "else", ":", "\n", "                ", "num_update", "=", "old_num_update", "\n", "", "meta_task_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "num_classes", ",", "shot", ",", "num_query", ",", "\n", "dataset", ",", "is_train", "=", "False", ",", "load_mode", "=", "args", ".", "load_mode", ",", "\n", "protocol", "=", "split_protocol", ",", "no_random_way", "=", "True", ",", "adv_arch", "=", "args", ".", "cross_arch_target", ",", "fetch_attack_name", "=", "False", ")", "\n", "data_loader", "=", "DataLoader", "(", "meta_task_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "pin_memory", "=", "True", ")", "\n", "img_classifier_network", "=", "Conv3", "(", "IN_CHANNELS", "[", "dataset", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", ",", "\n", "CLASS_NUM", "[", "dataset", "]", ")", "\n", "image_transform", "=", "ImageTransformCV2", "(", "dataset", ",", "[", "1", ",", "2", "]", ")", "\n", "layer_number", "=", "3", "if", "dataset", "in", "[", "\"CIFAR-10\"", ",", "\"CIFAR-100\"", ",", "\"SVHN\"", "]", "else", "2", "\n", "model", "=", "Detector", "(", "dataset", ",", "img_classifier_network", ",", "CLASS_NUM", "[", "dataset", "]", ",", "image_transform", ",", "layer_number", ",", "num_classes", "=", "2", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "model", ".", "cuda", "(", ")", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.__init__": [[82, 97], ["feature_squeeze_detector.FeatureSqueezingDetector.model.eval", "feature_squeeze_detector.parse_params", "params[].split", "feature_squeeze_detector.FeatureSqueezingDetector.set_config", "float", "float"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.parse_params", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.set_config"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "param_str", "=", "\"squeezers=bit_depth_4,median_filter_3_3&distance_measure=l2&fpr=0.05\"", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "params", "=", "parse_params", "(", "param_str", ")", "\n", "\n", "normalizer", "=", "'none'", "\n", "metric", "=", "params", "[", "'distance_measure'", "]", "\n", "squeezers_name", "=", "params", "[", "'squeezers'", "]", ".", "split", "(", "','", ")", "\n", "self", ".", "set_config", "(", "normalizer", ",", "metric", ",", "squeezers_name", ")", "\n", "\n", "if", "'threshold'", "in", "params", ":", "\n", "            ", "self", ".", "threshold", "=", "float", "(", "params", "[", "'threshold'", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "threshold", "=", "None", "\n", "self", ".", "train_fpr", "=", "float", "(", "params", "[", "'fpr'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.get_squeezer_by_name": [[98, 100], ["feature_squeeze.squeeze.get_squeezer_by_name"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.get_squeezer_by_name"], ["", "", "def", "get_squeezer_by_name", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "get_squeezer_by_name", "(", "name", ",", "'python'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.get_normalizer_by_name": [[101, 104], ["None"], "methods", ["None"], ["", "def", "get_normalizer_by_name", "(", "self", ",", "name", ")", ":", "\n", "        ", "d", "=", "{", "'unit_norm'", ":", "unit_norm", ",", "'softmax'", ":", "softmax", ",", "'none'", ":", "lambda", "x", ":", "x", "}", "\n", "return", "d", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.get_metric_by_name": [[105, 108], ["feature_squeeze_detector.kl", "feature_squeeze_detector.kl"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.kl", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.kl"], ["", "def", "get_metric_by_name", "(", "self", ",", "name", ")", ":", "\n", "        ", "d", "=", "{", "'kl_f'", ":", "lambda", "x1", ",", "x2", ":", "kl", "(", "x1", ",", "x2", ")", ",", "'kl_b'", ":", "lambda", "x1", ",", "x2", ":", "kl", "(", "x2", ",", "x1", ")", ",", "'l1'", ":", "l1_dist", ",", "'l2'", ":", "l2_dist", "}", "\n", "return", "d", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.set_config": [[109, 113], ["None"], "methods", ["None"], ["", "def", "set_config", "(", "self", ",", "normalizer_name", ",", "metric_name", ",", "squeezers_name", ")", ":", "\n", "        ", "self", ".", "normalizer_name", "=", "normalizer_name", "\n", "self", ".", "metric_name", "=", "metric_name", "\n", "self", ".", "squeezers_name", "=", "squeezers_name", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.get_config": [[114, 116], ["None"], "methods", ["None"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "normalizer_name", ",", "self", ".", "metric_name", ",", "self", ".", "squeezers_name", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.calculate_distance_max": [[117, 127], ["feature_squeeze_detector.FeatureSqueezingDetector.get_metric_by_name", "numpy.array", "numpy.max", "feature_squeeze_detector.FeatureSqueezingDetector.", "numpy.array.append"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.get_metric_by_name"], ["", "def", "calculate_distance_max", "(", "self", ",", "val_orig", ",", "vals_squeezed", ",", "metric_name", ")", ":", "\n", "        ", "distance_func", "=", "self", ".", "get_metric_by_name", "(", "metric_name", ")", "\n", "\n", "dist_array", "=", "[", "]", "\n", "for", "val_squeezed", "in", "vals_squeezed", ":", "\n", "            ", "dist", "=", "distance_func", "(", "val_orig", ",", "val_squeezed", ")", "# 50000\u4e2a\u6837\u672cpair\u7684distance", "\n", "dist_array", ".", "append", "(", "dist", ")", "\n", "\n", "", "dist_array", "=", "np", ".", "array", "(", "dist_array", ")", "# shape = SQUEEZER_NUM, 50000\u4e2a\u6837\u672c", "\n", "return", "np", ".", "max", "(", "dist_array", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.get_distance": [[128, 157], ["isinstance", "isinstance", "feature_squeeze_detector.FeatureSqueezingDetector.get_config", "feature_squeeze_detector.FeatureSqueezingDetector.get_normalizer_by_name", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "feature_squeeze_detector.FeatureSqueezingDetector.", "torch.no_grad", "input_to_normalized_output", "torch.cuda.empty_cache", "reshape_2d().cpu().numpy", "feature_squeeze_detector.FeatureSqueezingDetector.calculate_distance_max", "input_to_normalized_output", "torch.cuda.empty_cache", "feature_squeeze_detector.FeatureSqueezingDetector.get_metric_by_name", "feature_squeeze_detector.FeatureSqueezingDetector.", "torch.from_numpy", "torch.from_numpy", "feature_squeeze_detector.FeatureSqueezingDetector.get_squeezer_by_name", "input_to_normalized_output", "torch.cuda.empty_cache", "vals_squeezed.append", "reshape_2d().cpu", "torch.from_numpy().float().cuda", "feature_squeeze_detector.reshape_2d", "torch.from_numpy().float", "feature_squeeze_detector.FeatureSqueezingDetector.eval_layer_output", "torch.from_numpy", "feature_squeeze_detector.FeatureSqueezingDetector.", "torch.from_numpy().cuda.detach().cpu().numpy", "torch.from_numpy().cuda.detach().cpu", "torch.from_numpy().cuda.detach"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.get_config", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.get_normalizer_by_name", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.calculate_distance_max", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.get_metric_by_name", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.get_squeezer_by_name", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.reshape_2d", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.eval_layer_output"], ["", "def", "get_distance", "(", "self", ",", "X1", ",", "X2", "=", "None", ")", ":", "\n", "        ", "if", "isinstance", "(", "X1", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "X1", "=", "torch", ".", "from_numpy", "(", "X1", ")", ".", "cuda", "(", ")", "\n", "", "if", "isinstance", "(", "X2", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "X2", "=", "torch", ".", "from_numpy", "(", "X2", ")", ".", "cuda", "(", ")", "\n", "", "normalizer_name", ",", "metric_name", ",", "squeezers_name", "=", "self", ".", "get_config", "(", ")", "\n", "normalize_func", "=", "self", ".", "get_normalizer_by_name", "(", "normalizer_name", ")", "\n", "# return numpy array", "\n", "input_to_normalized_output", "=", "lambda", "x", ":", "normalize_func", "(", "reshape_2d", "(", "self", ".", "eval_layer_output", "(", "x", ")", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "val_orig_norm", "=", "input_to_normalized_output", "(", "X1", ")", "# normalize\u540e\u7684\u6a21\u578b\u8f93\u51fa", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "if", "X2", "is", "None", ":", "\n", "                ", "vals_squeezed", "=", "[", "]", "\n", "for", "squeezer_name", "in", "squeezers_name", ":", "\n", "                    ", "squeeze_func", "=", "self", ".", "get_squeezer_by_name", "(", "squeezer_name", ")", "\n", "val_squeezed_norm", "=", "input_to_normalized_output", "(", "torch", ".", "from_numpy", "(", "squeeze_func", "(", "X1", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", ")", "# squeeze\u540e\u518d\u7ecf\u8fc7\u6a21\u578b\u8f93\u51fa\uff0c\u518d\u5f97\u5230squeezed_norm", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "vals_squeezed", ".", "append", "(", "val_squeezed_norm", ")", "\n", "", "distance", "=", "self", ".", "calculate_distance_max", "(", "val_orig_norm", ",", "vals_squeezed", ",", "metric_name", ")", "\n", "", "else", ":", "\n", "                ", "val_1_norm", "=", "val_orig_norm", "\n", "val_2_norm", "=", "input_to_normalized_output", "(", "X2", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "distance_func", "=", "self", ".", "get_metric_by_name", "(", "metric_name", ")", "\n", "distance", "=", "distance_func", "(", "val_1_norm", ",", "val_2_norm", ")", "\n", "\n", "", "", "return", "distance", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.eval_layer_output": [[158, 162], ["feature_squeeze_detector.FeatureSqueezingDetector.model", "torch.nn.Softmax"], "methods", ["None"], ["", "def", "eval_layer_output", "(", "self", ",", "X", ")", ":", "\n", "\n", "        ", "layer_output", "=", "self", ".", "model", "(", "X", ")", "\n", "return", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "(", "layer_output", ")", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.output_distance_csv": [[164, 180], ["range", "feature_squeeze_detector.FeatureSqueezingDetector.get_distance", "distances_list.append", "len", "enumerate", "to_csv.append", "len"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.get_distance"], ["", "def", "output_distance_csv", "(", "self", ",", "X_list", ",", "field_name_list", ",", "csv_fpath", ")", ":", "\n", "        ", "distances_list", "=", "[", "]", "\n", "for", "X", "in", "X_list", ":", "\n", "            ", "distances", "=", "self", ".", "get_distance", "(", "X", ")", "\n", "distances_list", ".", "append", "(", "distances", ")", "\n", "\n", "", "to_csv", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "X_list", "[", "0", "]", ")", ")", ":", "\n", "            ", "record", "=", "{", "}", "\n", "for", "j", ",", "field_name", "in", "enumerate", "(", "field_name_list", ")", ":", "\n", "                ", "if", "len", "(", "distances_list", "[", "j", "]", ")", ">", "i", ":", "\n", "                    ", "record", "[", "field_name", "]", "=", "distances_list", "[", "j", "]", "[", "i", "]", "\n", "", "else", ":", "\n", "                    ", "record", "[", "field_name", "]", "=", "None", "\n", "", "", "to_csv", ".", "append", "(", "record", ")", "\n", "", "return", "to_csv", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.train": [[182, 202], ["print", "feature_squeeze_detector.FeatureSqueezingDetector.get_distance", "int", "print", "numpy.where", "numpy.ceil", "sorted", "len"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.get_distance"], ["", "def", "train", "(", "self", ",", "X", ",", "Y", ")", ":", "\n", "        ", "\"\"\"\n        \u6240\u8c13\u7684train\u5c31\u662f\u9009\u4e00\u4e2a\u9608\u503c,\u8fd9\u4e2a\u9608\u503c\u80fd\u5206\u5272\u5f00\u6b63\u8d1f\u6837\u672c\uff0c\u4f7f\u5176false positive rate\n        Calculating distance depends on:\n            normalizer\n            distance metric\n            feature squeezer(s)\n        \"\"\"", "\n", "\n", "if", "self", ".", "threshold", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"Loaded a pre-defined threshold value %f\"", "%", "self", ".", "threshold", ")", "\n", "", "else", ":", "\n", "            ", "pos_idx", "=", "np", ".", "where", "(", "Y", "==", "1", ")", "[", "0", "]", "\n", "X_pos", "=", "X", "[", "pos_idx", "]", "# \u6b63\u6837\u672c", "\n", "distances", "=", "self", ".", "get_distance", "(", "X_pos", ")", "# \u8ba1\u7b97\u6b63\u6837\u672c\u53ca\u5176squeeze feature\u8f93\u5165\u5230\u6a21\u578b\uff0c\u8f93\u51fa\u7684\u6700\u5927\u5dee\u8ddd", "\n", "selected_distance_idx", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "X_pos", ")", "*", "(", "1", "-", "self", ".", "train_fpr", ")", ")", ")", "#", "\n", "threshold", "=", "sorted", "(", "distances", ")", "[", "selected_distance_idx", "-", "1", "]", "# \u6309\u7167\u8ddd\u79bb\u4ece\u5c0f\u5230\u5927\u6392\u5e8f\uff0c\u53d6\u51fa\u7b2c\u53d6\u51fa95%d\u7684\u4f4d\u7f6e\uff0c\u5c0f\u4e8e\u6b64\u4f4d\u7f6e\u5168\u7b97\u6b63\u6837\u672c", "\n", "self", ".", "threshold", "=", "threshold", "\n", "print", "(", "\"Selected %f as the threshold value.\"", "%", "self", ".", "threshold", ")", "\n", "", "return", "self", ".", "threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.test": [[203, 208], ["feature_squeeze_detector.FeatureSqueezingDetector.get_distance"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector.get_distance"], ["", "def", "test", "(", "self", ",", "X", ")", ":", "\n", "        ", "distances", "=", "self", ".", "get_distance", "(", "X", ")", "\n", "threshold", "=", "self", ".", "threshold", "\n", "Y_pred", "=", "(", "distances", "<", "threshold", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "return", "Y_pred", ",", "distances", "", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.parse_params": [[17, 34], ["urllib.parse.parse_qs", "dict", "dict.items", "int", "dict.items", "v.lower", "len", "feature_squeeze.squeeze.isfloat", "float"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.isfloat"], ["def", "parse_params", "(", "params_str", ")", ":", "\n", "    ", "params", "=", "urlparse", ".", "parse_qs", "(", "params_str", ")", "\n", "params", "=", "dict", "(", "(", "k", ",", "v", ".", "lower", "(", ")", "if", "len", "(", "v", ")", ">", "1", "else", "v", "[", "0", "]", ")", "for", "k", ",", "v", "in", "params", ".", "items", "(", ")", ")", "\n", "# Data type conversion.", "\n", "integer_parameter_names", "=", "[", "'batch_size'", ",", "'max_iterations'", ",", "'num_classes'", ",", "'max_iter'", ",", "'nb_iter'", ",", "'max_iter_df'", "]", "\n", "for", "k", ",", "v", "in", "params", ".", "items", "(", ")", ":", "\n", "        ", "if", "k", "in", "integer_parameter_names", ":", "\n", "            ", "params", "[", "k", "]", "=", "int", "(", "v", ")", "\n", "", "elif", "v", "==", "'true'", ":", "\n", "            ", "params", "[", "k", "]", "=", "True", "\n", "", "elif", "v", "==", "'false'", ":", "\n", "            ", "params", "[", "k", "]", "=", "False", "\n", "", "elif", "v", "==", "'inf'", ":", "\n", "            ", "params", "[", "k", "]", "=", "np", ".", "inf", "\n", "", "elif", "isfloat", "(", "v", ")", ":", "\n", "            ", "params", "[", "k", "]", "=", "float", "(", "v", ")", "\n", "", "", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.reshape_2d": [[35, 38], ["x.view.view", "x.view.size"], "function", ["None"], ["", "def", "reshape_2d", "(", "x", ")", ":", "\n", "    ", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.softmax": [[43, 51], ["numpy.max", "numpy.exp", "numpy.sum", "len"], "function", ["None"], ["", "def", "softmax", "(", "z", ")", ":", "\n", "    ", "assert", "len", "(", "z", ".", "shape", ")", "==", "2", "\n", "s", "=", "np", ".", "max", "(", "z", ",", "axis", "=", "1", ")", "\n", "s", "=", "s", "[", ":", ",", "np", ".", "newaxis", "]", "# necessary step to do broadcasting", "\n", "e_x", "=", "np", ".", "exp", "(", "z", "-", "s", ")", "\n", "div", "=", "np", ".", "sum", "(", "e_x", ",", "axis", "=", "1", ")", "\n", "div", "=", "div", "[", ":", ",", "np", ".", "newaxis", "]", "# dito", "\n", "return", "e_x", "/", "div", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.unit_norm": [[52, 57], ["sklearn.preprocessing.normalize"], "function", ["None"], ["", "def", "unit_norm", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    x: a 2D array: (batch_size, vector_length)\n    \"\"\"", "\n", "return", "normalize", "(", "x", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.kl": [[65, 76], ["x1.transpose", "x2.transpose", "scipy.stats.entropy", "numpy.where"], "function", ["None"], ["def", "kl", "(", "x1", ",", "x2", ")", ":", "\n", "    ", "assert", "x1", ".", "shape", "==", "x2", ".", "shape", "\n", "# x1_2d, x2_2d = reshape_2d(x1), reshape_2d(x2)", "\n", "# Transpose to [?, #num_examples]", "\n", "x1_2d_t", "=", "x1", ".", "transpose", "(", ")", "\n", "x2_2d_t", "=", "x2", ".", "transpose", "(", ")", "\n", "\n", "# pdb.set_trace()", "\n", "e", "=", "entropy", "(", "x1_2d_t", ",", "x2_2d_t", ")", "\n", "e", "[", "np", ".", "where", "(", "e", "==", "np", ".", "inf", ")", "]", "=", "2", "\n", "return", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.main.get_train_data": [[36, 44], ["range", "len", "img.detach().cpu().numpy.detach().cpu().numpy", "all_data_list.append", "img.detach().cpu().numpy.detach().cpu", "img.detach().cpu().numpy.detach"], "function", ["None"], ["def", "get_train_data", "(", "train_dataset", ")", ":", "\n", "    ", "all_data_list", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "train_dataset", ")", ")", ":", "\n", "        ", "img", ",", "label", "=", "train_dataset", "[", "idx", "]", "\n", "img", "=", "img", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "# C,H,W", "\n", "all_data_list", ".", "append", "(", "img", ")", "\n", "\n", "", "return", "all_data_list", "# N,C,H,W", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.main.main": [[45, 106], ["parser.parse_args", "str", "re.compile", "re.compile", "glob.glob", "re.compile.match", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "int", "float", "int", "torch.load", "networks.resnet.resnet18.load_state_dict", "networks.resnet.resnet18.cuda", "print", "feature_squeeze.detection_evaluator.DetectionEvaluator", "glob.glob", "open", "file_obj.write", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "extract_pattern_detail.match.group", "networks.shallow_convs.FourConvs", "clean_image_classifier.train.get_preprocessor", "re.compile.match", "int", "int", "int", "int", "dataset.meta_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "feature_squeeze.detection_evaluator.DetectionEvaluator.evaluate_detections", "os.path.basename", "os.path.basename", "json.dumps", "networks.resnet.resnet10", "torchvision.datasets.CIFAR10", "extract_dataset_pattern.match.group", "extract_dataset_pattern.match.group", "extract_dataset_pattern.match.group", "extract_dataset_pattern.match.group", "networks.resnet.resnet18", "torchvision.datasets.MNIST", "os.path.basename.rindex", "os.path.basename.rindex", "torchvision.datasets.FashionMNIST", "dataset.SVHN_dataset.SVHN"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.train_fingerprint.parse_args", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.toolkit.img_transform.get_preprocessor", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.detection_evaluator.DetectionEvaluator.evaluate_detections", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet10", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet18"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "os", ".", "environ", "[", "\"CUDA_DEVICE_ORDER\"", "]", "=", "\"PCI_BUS_ID\"", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "str", "(", "args", ".", "gpu", ")", "\n", "\n", "# DL_IMAGE_CLASSIFIER_CIFAR-10@conv4@epoch_40@lr_0.0001@batch_500.pth.tar", "\n", "extract_pattern_detail", "=", "re", ".", "compile", "(", "\n", "\".*?DL_IMAGE_CLASSIFIER_(.*?)@(.*?)@epoch_(\\d+)@lr_(.*?)@batch_(\\d+)\\.pth\\.tar\"", ")", "\n", "# test_CIFAR-10_tot_num_tasks_20000_metabatch_10_way_5_shot_5_query_15.txt", "\n", "extract_dataset_pattern", "=", "re", ".", "compile", "(", "\".*?tot_num_tasks_(\\d+)_metabatch_(\\d+)_way_(\\d+)_shot_(\\d+)_query_(\\d+).*\"", ")", "\n", "result", "=", "{", "}", "\n", "for", "model_path", "in", "glob", ".", "glob", "(", "\"{}/train_pytorch_model/DL_IMAGE_CLASSIFIER*\"", ".", "format", "(", "PY_ROOT", ")", ")", ":", "\n", "        ", "ma", "=", "extract_pattern_detail", ".", "match", "(", "model_path", ")", "\n", "dataset", "=", "ma", ".", "group", "(", "1", ")", "\n", "arch", "=", "ma", ".", "group", "(", "2", ")", "\n", "epoch", "=", "int", "(", "ma", ".", "group", "(", "3", ")", ")", "\n", "lr", "=", "float", "(", "ma", ".", "group", "(", "4", ")", ")", "\n", "batch", "=", "int", "(", "ma", ".", "group", "(", "5", ")", ")", "\n", "if", "arch", "==", "\"conv4\"", ":", "\n", "            ", "model", "=", "FourConvs", "(", "IN_CHANNELS", "[", "dataset", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", ",", "CLASS_NUM", "[", "dataset", "]", ")", "\n", "", "elif", "arch", "==", "\"resnet10\"", ":", "\n", "            ", "model", "=", "resnet10", "(", "CLASS_NUM", "[", "dataset", "]", ",", "IN_CHANNELS", "[", "dataset", "]", ")", "\n", "", "elif", "arch", "==", "\"resnet18\"", ":", "\n", "            ", "model", "=", "resnet18", "(", "CLASS_NUM", "[", "dataset", "]", ",", "IN_CHANNELS", "[", "dataset", "]", ")", "\n", "", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"state_dict\"", "]", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "print", "(", "\"loading {}\"", ".", "format", "(", "model_path", ")", ")", "\n", "detector", "=", "DetectionEvaluator", "(", "model", ",", "dataset", ")", "\n", "for", "pkl_task_file_name", "in", "glob", ".", "glob", "(", "\"{}/task/{}/test_{}*.pkl\"", ".", "format", "(", "PY_ROOT", ",", "args", ".", "split_data_protocol", ",", "dataset", ")", ")", ":", "\n", "            ", "preprocessor", "=", "get_preprocessor", "(", "input_size", "=", "IMAGE_SIZE", "[", "dataset", "]", ",", "input_channels", "=", "IN_CHANNELS", "[", "dataset", "]", ")", "\n", "if", "dataset", "==", "\"CIFAR-10\"", ":", "\n", "                ", "train_dataset", "=", "CIFAR10", "(", "IMAGE_DATA_ROOT", "[", "dataset", "]", ",", "train", "=", "True", ",", "transform", "=", "preprocessor", ")", "\n", "", "elif", "dataset", "==", "\"MNIST\"", ":", "\n", "                ", "train_dataset", "=", "MNIST", "(", "IMAGE_DATA_ROOT", "[", "dataset", "]", ",", "train", "=", "True", ",", "transform", "=", "preprocessor", ",", "download", "=", "True", ")", "\n", "", "elif", "dataset", "==", "\"F-MNIST\"", ":", "\n", "                ", "train_dataset", "=", "FashionMNIST", "(", "IMAGE_DATA_ROOT", "[", "dataset", "]", ",", "train", "=", "True", ",", "transform", "=", "preprocessor", ",", "\n", "download", "=", "True", ")", "\n", "", "elif", "dataset", "==", "\"SVHN\"", ":", "\n", "                ", "train_dataset", "=", "SVHN", "(", "IMAGE_DATA_ROOT", "[", "dataset", "]", ",", "train", "=", "True", ",", "transform", "=", "preprocessor", ")", "\n", "", "ma_d", "=", "extract_dataset_pattern", ".", "match", "(", "pkl_task_file_name", ")", "\n", "tot_num_tasks", "=", "int", "(", "ma_d", ".", "group", "(", "1", ")", ")", "\n", "num_classes", "=", "int", "(", "ma_d", ".", "group", "(", "3", ")", ")", "\n", "num_support", "=", "int", "(", "ma_d", ".", "group", "(", "4", ")", ")", "\n", "num_query", "=", "int", "(", "ma_d", ".", "group", "(", "5", ")", ")", "\n", "meta_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "num_classes", ",", "num_support", ",", "num_query", ",", "\n", "dataset", ",", "is_train", "=", "False", ",", "load_mode", "=", "LOAD_TASK_MODE", ".", "LOAD", ",", "\n", "pkl_task_dump_path", "=", "pkl_task_file_name", ",", "\n", "protocol", "=", "args", ".", "split_data_protocol", ")", "\n", "val_loader", "=", "DataLoader", "(", "meta_dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n", "# train_imgs = get_train_data(train_dataset)", "\n", "train_imgs", "=", "[", "]", "\n", "accuracy", "=", "detector", ".", "evaluate_detections", "(", "train_imgs", ",", "val_loader", ")", "\n", "key1", "=", "os", ".", "path", ".", "basename", "(", "model_path", ")", "\n", "key1", "=", "key1", "[", ":", "key1", ".", "rindex", "(", "\".\"", ")", "]", "\n", "key", "=", "os", ".", "path", ".", "basename", "(", "pkl_task_file_name", ")", "\n", "key", "=", "key", "[", ":", "key", ".", "rindex", "(", "\".\"", ")", "]", "\n", "result", "[", "\"{}|{}\"", ".", "format", "(", "key1", ",", "key", ")", "]", "=", "accuracy", "\n", "", "", "with", "open", "(", "args", ".", "output_path", ",", "\"w\"", ")", "as", "file_obj", ":", "\n", "        ", "file_obj", ".", "write", "(", "json", ".", "dumps", "(", "result", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.detection_evaluator.DetectionEvaluator.__init__": [[46, 51], ["detection_evaluator.DetectionEvaluator.get_detector"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.detection_evaluator.DetectionEvaluator.get_detector"], ["def", "__init__", "(", "self", ",", "model", ",", "dataset_name", ")", ":", "\n", "# set_base_model()", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "dataset_name", "=", "dataset_name", "\n", "self", ".", "detector", "=", "self", ".", "get_detector", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.detection_evaluator.DetectionEvaluator.get_detector": [[53, 56], ["feature_squeeze.feature_squeeze_detector.FeatureSqueezingDetector"], "methods", ["None"], ["", "def", "get_detector", "(", "self", ",", "model", ")", ":", "\n", "        ", "detector", "=", "FeatureSqueezingDetector", "(", "model", ")", "\n", "return", "detector", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.detection_evaluator.DetectionEvaluator.evaluate_detections": [[58, 90], ["numpy.mean", "print", "positive_labels.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "query_labels.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "query_images.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "support_labels.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "support_images.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "range", "enumerate", "detection_evaluator.DetectionEvaluator.detector.train", "X_test.reshape.reshape.reshape", "detection_evaluator.DetectionEvaluator.detector.test", "sklearn.metrics.accuracy_score", "accuracy_list.append", "positive_labels.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "query_labels.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "query_images.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "support_labels.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "support_images.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "numpy.stack", "numpy.ones", "train_imgs.append", "len", "positive_labels.detach().cpu().numpy.detach().cpu().numpy.detach", "query_labels.detach().cpu().numpy.detach().cpu().numpy.detach", "query_images.detach().cpu().numpy.detach().cpu().numpy.detach", "support_labels.detach().cpu().numpy.detach().cpu().numpy.detach", "support_images.detach().cpu().numpy.detach().cpu().numpy.detach", "[].reshape"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.test"], ["", "def", "evaluate_detections", "(", "self", ",", "train_imgs", ",", "val_loader", ")", ":", "\n", "        ", "accuracy_list", "=", "[", "]", "\n", "\n", "for", "support_images", ",", "support_labels", ",", "query_images", ",", "query_labels", ",", "positive_labels", "in", "val_loader", ":", "\n", "            ", "assert", "support_images", ".", "shape", "[", "0", "]", "==", "query_images", ".", "shape", "[", "0", "]", "\n", "positive_labels", "=", "positive_labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "query_labels", "=", "query_labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "query_labels", "=", "(", "query_labels", "==", "positive_labels", ")", ".", "astype", "(", "np", ".", "int64", ")", "\n", "query_images", "=", "query_images", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "support_labels", "=", "support_labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "support_labels", "=", "(", "support_labels", "==", "positive_labels", ")", ".", "astype", "(", "np", ".", "int64", ")", "\n", "support_images", "=", "support_images", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "for", "task_idx", "in", "range", "(", "query_images", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "for", "idx", ",", "label_", "in", "enumerate", "(", "query_labels", "[", "task_idx", "]", ")", ":", "\n", "                    ", "if", "label_", "==", "1", ":", "\n", "                        ", "train_imgs", ".", "append", "(", "\n", "query_images", "[", "task_idx", "]", "[", "idx", "]", ".", "reshape", "(", "IN_CHANNELS", "[", "self", ".", "dataset_name", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset_name", "]", "[", "0", "]", ",", "\n", "IMAGE_SIZE", "[", "self", ".", "dataset_name", "]", "[", "1", "]", ")", ")", "\n", "\n", "", "", "self", ".", "detector", ".", "train", "(", "np", ".", "stack", "(", "train_imgs", ")", ",", "np", ".", "ones", "(", "len", "(", "train_imgs", ")", ")", ")", "\n", "X_test", ",", "Y_test", "=", "query_images", "[", "task_idx", "]", ",", "query_labels", "[", "task_idx", "]", "\n", "X_test", "=", "X_test", ".", "reshape", "(", "-", "1", ",", "IN_CHANNELS", "[", "self", ".", "dataset_name", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset_name", "]", "[", "0", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset_name", "]", "[", "1", "]", ")", "\n", "# Example: --detection \"FeatureSqueezing?distance_measure=l1&squeezers=median_smoothing_2,bit_depth_4;", "\n", "Y_test_pred", ",", "Y_test_pred_score", "=", "self", ".", "detector", ".", "test", "(", "X_test", ")", "\n", "# accuracy, tpr, fpr, tp, ap = evalulate_detection_test(Y_test, Y_test_pred)", "\n", "accuracy", "=", "accuracy_score", "(", "Y_test", ",", "Y_test_pred", ")", "\n", "accuracy_list", ".", "append", "(", "accuracy", ")", "\n", "\n", "", "", "accuracy", "=", "np", ".", "mean", "(", "accuracy_list", ")", "\n", "print", "(", "accuracy", ")", "\n", "return", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.detection_evaluator.get_tpr_fpr": [[13, 24], ["numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.logical_and", "numpy.logical_and"], "function", ["None"], ["def", "get_tpr_fpr", "(", "true_labels", ",", "pred_labels", ")", ":", "\n", "    ", "TP", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "pred_labels", "==", "1", ",", "true_labels", "==", "1", ")", ")", "\n", "FP", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "pred_labels", "==", "1", ",", "true_labels", "==", "0", ")", ")", "\n", "\n", "AP", "=", "np", ".", "sum", "(", "true_labels", ")", "\n", "AN", "=", "np", ".", "sum", "(", "1", "-", "true_labels", ")", "\n", "\n", "tpr", "=", "TP", "/", "AP", "if", "AP", ">", "0", "else", "np", ".", "nan", "\n", "fpr", "=", "FP", "/", "AN", "if", "AN", ">", "0", "else", "np", ".", "nan", "\n", "\n", "return", "tpr", ",", "fpr", ",", "TP", ",", "AP", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.detection_evaluator.evalulate_detection_test": [[26, 30], ["sklearn.metrics.accuracy_score", "detection_evaluator.get_tpr_fpr"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.detection_evaluator.get_tpr_fpr"], ["", "def", "evalulate_detection_test", "(", "Y_detect_test", ",", "Y_detect_pred", ")", ":", "\n", "    ", "accuracy", "=", "sklearn", ".", "metrics", ".", "accuracy_score", "(", "Y_detect_test", ",", "Y_detect_pred", ",", "normalize", "=", "True", ",", "sample_weight", "=", "None", ")", "\n", "tpr", ",", "fpr", ",", "tp", ",", "ap", "=", "get_tpr_fpr", "(", "Y_detect_test", ",", "Y_detect_pred", ")", "\n", "return", "accuracy", ",", "tpr", ",", "fpr", ",", "tp", ",", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.utils.restore_or_calculate_object": [[7, 16], ["os.path.isfile", "print", "func", "pickle.dump", "pickle.load", "print", "open", "open"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.dump"], ["def", "restore_or_calculate_object", "(", "fpath", ",", "func", ",", "args", ",", "obj_name", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "isfile", "(", "fpath", ")", ":", "\n", "        ", "print", "(", "\"===Calculating %s...\"", "%", "obj_name", ")", "\n", "obj", "=", "func", "(", "*", "args", ")", "\n", "pickle", ".", "dump", "(", "obj", ",", "open", "(", "fpath", ",", "'wb'", ")", ")", "\n", "", "else", ":", "\n", "        ", "obj", "=", "pickle", ".", "load", "(", "open", "(", "fpath", ")", ")", "\n", "print", "(", "\"===Loaded %s.\"", "%", "obj_name", ")", "\n", "", "return", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.utils.model_eval_distance": [[19, 33], ["torch.sqrt", "torch.max", "torch.sum", "torch.sum", "torch.abs", "torch.abs", "torch.mul"], "function", ["None"], ["", "def", "model_eval_distance", "(", "orig_prediction", ",", "squeeze_prediction", ")", ":", "\n", "    ", "\"\"\"\n    Compute the L1 distance between prediction of original and squeezed data.\n    :param orig_prediction: model output original predictions\n    :param squeeze_prediction: model output squeezed predictions\n    :return: a float vector with the distance value\n    \"\"\"", "\n", "# Define sympbolic for accuracy", "\n", "# acc_value = keras.metrics.categorical_accuracy(y, model)", "\n", "\n", "l2_diff", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "orig_prediction", "-", "squeeze_prediction", ",", "orig_prediction", "-", "squeeze_prediction", ")", ",", "dim", "=", "1", ")", ")", "\n", "l_inf_diff", "=", "torch", ".", "max", "(", "torch", ".", "abs", "(", "orig_prediction", "-", "squeeze_prediction", ")", ",", "dim", "=", "1", ")", "\n", "l1_diff", "=", "torch", ".", "sum", "(", "torch", ".", "abs", "(", "orig_prediction", "-", "squeeze_prediction", ")", ",", "dim", "=", "1", ")", "\n", "return", "l1_diff", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.utils.model_eval_distance_dual_input": [[34, 37], ["torch.sum", "torch.abs"], "function", ["None"], ["", "def", "model_eval_distance_dual_input", "(", "prediction_x_test1", ",", "prediction_x_test2", ")", ":", "\n", "    ", "l1_dist_vec", "=", "torch", ".", "sum", "(", "torch", ".", "abs", "(", "prediction_x_test1", "-", "prediction_x_test2", ")", ",", "dim", "=", "1", ")", "\n", "return", "l1_dist_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.utils.model_eval_dist_tri_input": [[38, 47], ["torch.sum", "torch.sum", "torch.sum", "torch.abs", "torch.abs", "torch.abs", "torch.max", "torch.stack", "torch.mean", "torch.stack"], "function", ["None"], ["", "def", "model_eval_dist_tri_input", "(", "prediction_x_test1", ",", "prediction_x_test2", ",", "prediction_x_test3", ",", "mode", "=", "\"max\"", ")", ":", "\n", "    ", "l11", "=", "torch", ".", "sum", "(", "torch", ".", "abs", "(", "prediction_x_test1", "-", "prediction_x_test2", ")", ",", "dim", "=", "1", ")", "\n", "l12", "=", "torch", ".", "sum", "(", "torch", ".", "abs", "(", "prediction_x_test1", "-", "prediction_x_test3", ")", ",", "dim", "=", "1", ")", "\n", "l13", "=", "torch", ".", "sum", "(", "torch", ".", "abs", "(", "prediction_x_test2", "-", "prediction_x_test3", ")", ",", "dim", "=", "1", ")", "\n", "if", "mode", "==", "\"max\"", ":", "\n", "        ", "l1_dist_vec", "=", "torch", ".", "max", "(", "torch", ".", "stack", "(", "[", "l11", ",", "l12", ",", "l13", "]", ")", ",", "dim", "=", "0", ")", "\n", "", "elif", "mode", "==", "\"mean\"", ":", "\n", "        ", "l1_dist_vec", "=", "torch", ".", "mean", "(", "torch", ".", "stack", "(", "[", "l11", ",", "l12", ",", "l13", "]", ")", ",", "dim", "=", "0", ")", "\n", "", "return", "l1_dist_vec", "\n", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.recreate_image": [[7, 33], ["copy.copy", "numpy.rint", "numpy.transpose", "range"], "function", ["None"], ["def", "recreate_image", "(", "x", ",", "npp_int", ")", ":", "\n", "    ", "\"\"\"\n        Recreates images from a torch Tensor, sort of reverse preprocessing\n\n    Args:\n        x (np.array): C,H,W format Image to recreate\n\n    returns:\n        recreated_im (numpy arr): H,W,C format Recreated image in array\n    \"\"\"", "\n", "reverse_mean", "=", "[", "-", "0.485", ",", "-", "0.456", ",", "-", "0.406", "]", "\n", "reverse_std", "=", "[", "1", "/", "0.229", ",", "1", "/", "0.224", ",", "1", "/", "0.225", "]", "\n", "in_channel", "=", "x", ".", "shape", "[", "0", "]", "\n", "recreated_im", "=", "copy", ".", "copy", "(", "x", ")", "# C, H, W", "\n", "if", "in_channel", "==", "3", ":", "\n", "        ", "for", "c", "in", "range", "(", "in_channel", ")", ":", "\n", "            ", "recreated_im", "[", "c", "]", "/=", "reverse_std", "[", "c", "]", "\n", "recreated_im", "[", "c", "]", "-=", "reverse_mean", "[", "c", "]", "\n", "", "", "elif", "in_channel", "==", "1", ":", "\n", "        ", "recreated_im", "[", "0", "]", "/=", "reverse_std", "[", "1", "]", "\n", "recreated_im", "[", "0", "]", "-=", "reverse_mean", "[", "1", "]", "\n", "", "recreated_im", "[", "recreated_im", ">", "1", "]", "=", "1", "\n", "recreated_im", "[", "recreated_im", "<", "0", "]", "=", "0", "\n", "recreated_im", "=", "np", ".", "rint", "(", "recreated_im", "*", "npp_int", ")", "\n", "recreated_im", "=", "np", ".", "transpose", "(", "recreated_im", ",", "axes", "=", "(", "1", ",", "2", ",", "0", ")", ")", "# H, W, C", "\n", "return", "recreated_im", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.normalized_process": [[34, 52], ["copy.copy", "numpy.transpose", "processed_x.astype.astype", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.array", "numpy.array", "numpy.expand_dims", "numpy.expand_dims", "numpy.array", "numpy.array"], "function", ["None"], ["", "def", "normalized_process", "(", "x", ",", "npp_int", ")", ":", "\n", "    ", "\"\"\"\n    :param x: H,W,C format\n    :return:  C,H,W format\n    \"\"\"", "\n", "in_channel", "=", "x", ".", "shape", "[", "-", "1", "]", "\n", "if", "in_channel", "==", "3", ":", "\n", "        ", "mean", "=", "np", ".", "expand_dims", "(", "np", ".", "expand_dims", "(", "np", ".", "array", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ")", ",", "1", ")", ",", "1", ")", "# 3,1,1", "\n", "std", "=", "np", ".", "expand_dims", "(", "np", ".", "expand_dims", "(", "np", ".", "array", "(", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ",", "1", ")", ",", "1", ")", "# 3,1,1", "\n", "", "elif", "in_channel", "==", "1", ":", "\n", "        ", "mean", "=", "np", ".", "expand_dims", "(", "np", ".", "expand_dims", "(", "np", ".", "array", "(", "[", "0.456", "]", ")", ",", "1", ")", ",", "1", ")", "# 1,1,1", "\n", "std", "=", "np", ".", "expand_dims", "(", "np", ".", "expand_dims", "(", "np", ".", "array", "(", "[", "0.224", "]", ")", ",", "1", ")", ",", "1", ")", "# 1,1,1", "\n", "", "processed_x", "=", "copy", ".", "copy", "(", "x", ")", "# H,W,C", "\n", "processed_x", "=", "np", ".", "transpose", "(", "processed_x", ",", "(", "2", ",", "0", ",", "1", ")", ")", "# C,H,W", "\n", "processed_x", "=", "processed_x", ".", "astype", "(", "np", ".", "float32", ")", "\n", "processed_x", "=", "processed_x", "/", "npp_int", "# normalize", "\n", "processed_x", "=", "(", "processed_x", "-", "mean", ")", "/", "std", "\n", "return", "processed_x", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.reduce_precision_py": [[53, 69], ["numpy.stack", "squeeze.recreate_image", "squeeze.normalized_process", "new_x.append"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.recreate_image", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.normalized_process"], ["", "def", "reduce_precision_py", "(", "x", ",", "npp", ")", ":", "\n", "    ", "\"\"\"\n    Reduce the precision of image, the numpy version.\n    :param x: a float tensor, which has been scaled to [0, 1].\n    :param npp: number of possible values per pixel. E.g. it's 256 for 8-bit gray-scale image, and 2 for binarized image.\n    :return: a tensor representing image(s) with lower precision.\n    \"\"\"", "\n", "# Note: 0 is a possible value too.", "\n", "npp_int", "=", "npp", "-", "1", "\n", "assert", "x", ".", "ndim", "==", "4", ",", "x", ".", "ndim", "\n", "new_x", "=", "[", "]", "\n", "for", "x_", "in", "x", ":", "\n", "        ", "x_int", "=", "recreate_image", "(", "x_", ",", "npp_int", ")", "# H,W,C", "\n", "x_float", "=", "normalized_process", "(", "x_int", ",", "npp_int", ")", "# C,H,W", "\n", "new_x", ".", "append", "(", "x_float", ")", "\n", "", "return", "np", ".", "stack", "(", "new_x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.bit_depth_py": [[71, 74], ["squeeze.reduce_precision_py"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.reduce_precision_py"], ["", "def", "bit_depth_py", "(", "x", ",", "bits", ")", ":", "\n", "    ", "precisions", "=", "2", "**", "bits", "\n", "return", "reduce_precision_py", "(", "x", ",", "precisions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.bit_depth_random_py": [[76, 83], ["numpy.add", "squeeze.bit_depth_py", "numpy.zeros", "numpy.random.normal"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.bit_depth_py"], ["", "def", "bit_depth_random_py", "(", "x", ",", "bits", ",", "stddev", ")", ":", "\n", "    ", "if", "stddev", "==", "0.", ":", "\n", "        ", "rand_array", "=", "np", ".", "zeros", "(", "x", ".", "shape", ")", "\n", "", "else", ":", "\n", "        ", "rand_array", "=", "np", ".", "random", ".", "normal", "(", "loc", "=", "0.", ",", "scale", "=", "stddev", ",", "size", "=", "x", ".", "shape", ")", "\n", "", "x_random", "=", "np", ".", "add", "(", "x", ",", "rand_array", ")", "\n", "return", "bit_depth_py", "(", "x_random", ",", "bits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.binary_filter_py": [[84, 90], ["numpy.maximum", "numpy.sign"], "function", ["None"], ["", "def", "binary_filter_py", "(", "x", ",", "threshold", ")", ":", "\n", "    ", "\"\"\"\n    An efficient implementation of reduce_precision_py(x, 2). \u7070\u5ea6\u4e8c\u503c\u5316\n    \"\"\"", "\n", "x_bin", "=", "np", ".", "maximum", "(", "np", ".", "sign", "(", "x", "-", "threshold", ")", ",", "0", ")", "\n", "return", "x_bin", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.binary_random_filter_py": [[92, 99], ["numpy.maximum().astype", "numpy.zeros", "numpy.random.normal", "numpy.maximum", "numpy.sign", "numpy.add"], "function", ["None"], ["", "def", "binary_random_filter_py", "(", "x", ",", "threshold", ",", "stddev", "=", "0.125", ")", ":", "\n", "    ", "if", "stddev", "==", "0.", ":", "\n", "        ", "rand_array", "=", "np", ".", "zeros", "(", "x", ".", "shape", ")", "\n", "", "else", ":", "\n", "        ", "rand_array", "=", "np", ".", "random", ".", "normal", "(", "loc", "=", "0.", ",", "scale", "=", "stddev", ",", "size", "=", "x", ".", "shape", ")", "\n", "", "x_bin", "=", "np", ".", "maximum", "(", "np", ".", "sign", "(", "np", ".", "add", "(", "x", ",", "rand_array", ")", "-", "threshold", ")", ",", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "return", "x_bin", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.median_filter_py": [[101, 112], ["scipy.ndimage.filters.median_filter"], "function", ["None"], ["", "def", "median_filter_py", "(", "x", ",", "width", ",", "height", "=", "-", "1", ")", ":", "\n", "    ", "\"\"\"\n    Median smoothing by Scipy.\n    :param x: a tensor of image(s)\n    :param width: the width of the sliding window (number of pixels)\n    :param height: the height of the window. The same as width by default.\n    :return: a modified tensor with the same shape as x.\n    \"\"\"", "\n", "if", "height", "==", "-", "1", ":", "\n", "        ", "height", "=", "width", "\n", "", "return", "ndimage", ".", "filters", ".", "median_filter", "(", "x", ",", "size", "=", "(", "1", ",", "1", ",", "width", ",", "height", ")", ",", "mode", "=", "'reflect'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.opencv_wrapper": [[115, 134], ["numpy.stack", "squeeze.recreate_image", "numpy.clip().astype", "opencv_func", "normalized_process().astype", "np.stack.append", "numpy.squeeze", "type", "numpy.expand_dims", "numpy.clip", "squeeze.normalized_process"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.recreate_image", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.normalized_process"], ["", "def", "opencv_wrapper", "(", "imgs", ",", "opencv_func", ",", "argv", ")", ":", "\n", "# imgs is N,C,H,W format", "\n", "    ", "ret_imgs", "=", "[", "]", "\n", "imgs_copy", "=", "imgs", "\n", "\n", "for", "img", "in", "imgs_copy", ":", "# each is C,H,W", "\n", "        ", "img", "=", "recreate_image", "(", "img", ")", "# H, W, C", "\n", "if", "img", ".", "shape", "[", "-", "1", "]", "==", "1", ":", "\n", "            ", "img", "=", "np", ".", "squeeze", "(", "img", ")", "# grey image convert to H,W", "\n", "", "img_uint8", "=", "np", ".", "clip", "(", "img", ",", "0", ",", "255", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "ret_img", "=", "opencv_func", "(", "*", "[", "img_uint8", "]", "+", "argv", ")", "# H,W,C", "\n", "if", "type", "(", "ret_img", ")", "==", "tuple", ":", "\n", "            ", "ret_img", "=", "ret_img", "[", "1", "]", "\n", "", "if", "ret_img", ".", "shape", "[", "-", "1", "]", "==", "1", ":", "\n", "            ", "ret_img", "=", "np", ".", "expand_dims", "(", "ret_img", ",", "-", "1", ")", "# H, W, 1", "\n", "", "ret_img", "=", "normalized_process", "(", "ret_img", ",", "255", ")", ".", "astype", "(", "np", ".", "float32", ")", "# C,H,W", "\n", "ret_imgs", ".", "append", "(", "ret_img", ")", "\n", "", "ret_imgs", "=", "np", ".", "stack", "(", "ret_imgs", ")", "# N, C,H ,W", "\n", "return", "ret_imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.otsu_binarize_py": [[135, 141], ["squeeze.opencv_wrapper"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.opencv_wrapper"], ["", "def", "otsu_binarize_py", "(", "x", ")", ":", "\n", "# func = lambda img: cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]", "\n", "# return opencv_binarize(x, func)", "\n", "    ", "import", "cv2", "\n", "ret_imgs", "=", "opencv_wrapper", "(", "x", ",", "cv2", ".", "threshold", ",", "[", "0", ",", "255", ",", "cv2", ".", "THRESH_BINARY", "+", "cv2", ".", "THRESH_OTSU", "]", ")", "\n", "return", "ret_imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.adaptive_binarize_py": [[143, 150], ["squeeze.opencv_wrapper"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.opencv_wrapper"], ["", "def", "adaptive_binarize_py", "(", "x", ",", "block_size", "=", "5", ",", "C", "=", "33.8", ")", ":", "\n", "    ", "\"Works like an edge detector.\"", "\n", "# ADAPTIVE_THRESH_GAUSSIAN_C, ADAPTIVE_THRESH_MEAN_C", "\n", "# THRESH_BINARY, THRESH_BINARY_INV", "\n", "import", "cv2", "\n", "ret_imgs", "=", "opencv_wrapper", "(", "x", ",", "cv2", ".", "adaptiveThreshold", ",", "[", "255", ",", "cv2", ".", "ADAPTIVE_THRESH_GAUSSIAN_C", ",", "cv2", ".", "THRESH_BINARY_INV", ",", "block_size", ",", "C", "]", ")", "\n", "return", "ret_imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.non_local_means_color_py": [[152, 156], ["squeeze.opencv_wrapper"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.opencv_wrapper"], ["", "def", "non_local_means_color_py", "(", "imgs", ",", "search_window", ",", "block_size", ",", "photo_render", ")", ":", "\n", "    ", "import", "cv2", "\n", "ret_imgs", "=", "opencv_wrapper", "(", "imgs", ",", "cv2", ".", "fastNlMeansDenoisingColored", ",", "[", "None", ",", "photo_render", ",", "photo_render", ",", "block_size", ",", "search_window", "]", ")", "\n", "return", "ret_imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.non_local_means_color_torch": [[157, 162], ["isinstance", "torch.from_numpy", "torch.from_numpy", "imgs.detach().cpu().numpy.detach().cpu().numpy", "squeeze.non_local_means_color_py", "imgs.detach().cpu().numpy.detach().cpu", "imgs.detach().cpu().numpy.detach"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.non_local_means_color_py"], ["", "def", "non_local_means_color_torch", "(", "imgs", ",", "search_window", ",", "block_size", ",", "photo_render", ")", ":", "\n", "    ", "if", "isinstance", "(", "imgs", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "imgs", "=", "imgs", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "ret", "=", "torch", ".", "from_numpy", "(", "non_local_means_color_py", "(", "imgs", ",", "search_window", ",", "block_size", ",", "photo_render", ")", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.non_local_means_bw_py": [[163, 167], ["squeeze.opencv_wrapper"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.opencv_wrapper"], ["", "def", "non_local_means_bw_py", "(", "imgs", ",", "search_window", ",", "block_size", ",", "photo_render", ")", ":", "\n", "    ", "import", "cv2", "\n", "ret_imgs", "=", "opencv_wrapper", "(", "imgs", ",", "cv2", ".", "fastNlMeansDenoising", ",", "[", "None", ",", "photo_render", ",", "block_size", ",", "search_window", "]", ")", "\n", "return", "ret_imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.non_local_means_bw_torch": [[168, 173], ["isinstance", "torch.from_numpy", "torch.from_numpy", "imgs.detach().cpu().numpy.detach().cpu().numpy", "squeeze.non_local_means_bw_py", "imgs.detach().cpu().numpy.detach().cpu", "imgs.detach().cpu().numpy.detach"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.non_local_means_bw_py"], ["", "def", "non_local_means_bw_torch", "(", "imgs", ",", "search_window", ",", "block_size", ",", "photo_render", ")", ":", "\n", "    ", "if", "isinstance", "(", "imgs", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "imgs", "=", "imgs", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "ret", "=", "torch", ".", "from_numpy", "(", "non_local_means_bw_py", "(", "imgs", ",", "search_window", ",", "block_size", ",", "photo_render", ")", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.bilateral_filter_py": [[174, 187], ["squeeze.opencv_wrapper"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.opencv_wrapper"], ["", "def", "bilateral_filter_py", "(", "imgs", ",", "d", ",", "sigmaSpace", ",", "sigmaColor", ")", ":", "\n", "    ", "\"\"\"\n    :param d: Diameter of each pixel neighborhood that is used during filtering.\n        If it is non-positive, it is computed from sigmaSpace.\n    :param sigmaSpace: Filter sigma in the coordinate space.\n        A larger value of the parameter means that farther pixels will influence each other as long as their colors are close enough (see sigmaColor ).\n        When d>0, it specifies the neighborhood size regardless of sigmaSpace.\n        Otherwise, d is proportional to sigmaSpace.\n    :param sigmaColor: Filter sigma in the color space.\n        A larger value of the parameter means that farther colors within the pixel neighborhood (see sigmaSpace) will be mixed together, resulting in larger areas of semi-equal color.\n    \"\"\"", "\n", "import", "cv2", "\n", "return", "opencv_wrapper", "(", "imgs", ",", "cv2", ".", "bilateralFilter", ",", "[", "d", ",", "sigmaColor", ",", "sigmaSpace", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.adaptive_bilateral_filter_py": [[188, 191], ["squeeze.opencv_wrapper"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.opencv_wrapper"], ["", "def", "adaptive_bilateral_filter_py", "(", "imgs", ",", "ksize", ",", "sigmaSpace", ",", "maxSigmaColor", "=", "20.0", ")", ":", "\n", "    ", "import", "cv2", "\n", "return", "opencv_wrapper", "(", "imgs", ",", "cv2", ".", "adaptiveBilateralFilter", ",", "[", "(", "ksize", ",", "ksize", ")", ",", "sigmaSpace", ",", "maxSigmaColor", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.isfloat": [[194, 200], ["float"], "function", ["None"], ["", "def", "isfloat", "(", "value", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "float", "(", "value", ")", "\n", "return", "True", "\n", "", "except", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.parse_params": [[201, 213], ["params_str.split", "float.strip", "float.isdigit", "params.append", "int", "squeeze.isfloat", "float"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.isfloat"], ["", "", "def", "parse_params", "(", "params_str", ")", ":", "\n", "    ", "params", "=", "[", "]", "\n", "for", "param", "in", "params_str", ".", "split", "(", "'_'", ")", ":", "\n", "        ", "param", "=", "param", ".", "strip", "(", ")", "\n", "if", "param", ".", "isdigit", "(", ")", ":", "\n", "            ", "param", "=", "int", "(", "param", ")", "\n", "", "elif", "isfloat", "(", "param", ")", ":", "\n", "            ", "param", "=", "float", "(", "param", ")", "\n", "", "else", ":", "\n", "            ", "continue", "\n", "", "params", ".", "append", "(", "param", ")", "\n", "", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.get_squeezer_by_name": [[214, 242], ["Exception", "name.startswith", "squeeze.parse_params", "len", "globals"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.parse_params"], ["", "def", "get_squeezer_by_name", "(", "name", ",", "func_type", ")", ":", "\n", "    ", "squeezer_list", "=", "[", "'none'", ",", "\n", "'bit_depth_random'", ",", "\n", "'bit_depth'", ",", "\n", "'binary_filter'", ",", "\n", "'reduce_precision'", ",", "\n", "'binary_random_filter'", ",", "\n", "'adaptive_binarize'", ",", "\n", "'otsu_binarize'", ",", "\n", "'median_filter'", ",", "\n", "'median_random_filter'", ",", "\n", "'median_random_size_filter'", ",", "\n", "'non_local_means_bw'", ",", "\n", "'non_local_means_color'", ",", "\n", "'adaptive_bilateral_filter'", ",", "\n", "'bilateral_filter'", ",", "\n", "]", "\n", "\n", "for", "squeezer_name", "in", "squeezer_list", ":", "\n", "        ", "if", "name", ".", "startswith", "(", "squeezer_name", ")", ":", "\n", "            ", "params_str", "=", "name", "[", "len", "(", "squeezer_name", ")", ":", "]", "\n", "func_name", "=", "\"%s_py\"", "%", "squeezer_name", "if", "func_type", "==", "'python'", "else", "\"%s_tf\"", "%", "squeezer_name", "\n", "# Return a list", "\n", "args", "=", "parse_params", "(", "params_str", ")", "\n", "# print (\"params_str: %s, args: %s\" % (params_str, args))", "\n", "return", "lambda", "x", ":", "globals", "(", ")", "[", "func_name", "]", "(", "*", "(", "[", "x", "]", "+", "args", ")", ")", "\n", "\n", "", "", "raise", "Exception", "(", "'Unknown squeezer name: {} squeezer_name:{}'", ".", "format", "(", "name", ",", "squeezer_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.get_sequential_squeezers_by_name": [[243, 254], ["squeezers_name.split", "squeeze.get_squeezer_by_name", "get_squeezer_by_name.", "get_squeezer_by_name.", "old_func"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.squeeze.get_squeezer_by_name"], ["", "def", "get_sequential_squeezers_by_name", "(", "squeezers_name", ")", ":", "\n", "# example_squeezers_name = \"binary_filter_0.5,median_filter_2_2\"", "\n", "    ", "squeeze_func", "=", "None", "\n", "for", "squeezer_name", "in", "squeezers_name", ".", "split", "(", "','", ")", ":", "\n", "        ", "squeezer", "=", "get_squeezer_by_name", "(", "squeezer_name", ",", "'python'", ")", "\n", "if", "squeeze_func", "==", "None", ":", "\n", "            ", "squeeze_func", "=", "lambda", "x", ":", "squeezer", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "old_func", "=", "squeeze_func", "\n", "squeeze_func", "=", "lambda", "x", ":", "squeezer", "(", "old_func", "(", "x", ")", ")", "\n", "", "", "return", "squeeze_func", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.imagenet_real_dataset.ImageNetRealDataset.__init__": [[8, 26], ["sorted", "os.listdir", "os.listdir", "os.listdir", "sorted.index", "os.listdir", "sorted.index", "os.listdir", "imagenet_real_dataset.ImageNetRealDataset.files.append", "imagenet_real_dataset.ImageNetRealDataset.files.append"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root_path", ",", "train", ",", "transform", ")", ":", "\n", "        ", "self", ".", "root_path", "=", "root_path", "\n", "self", ".", "train_folder", "=", "root_path", "+", "\"/train\"", "\n", "self", ".", "test_folder", "=", "root_path", "+", "\"/test\"", "\n", "self", ".", "transform", "=", "transform", "\n", "MiniImageNet_All_Category", "=", "sorted", "(", "os", ".", "listdir", "(", "self", ".", "train_folder", ")", ")", "\n", "self", ".", "is_train", "=", "train", "\n", "self", ".", "files", "=", "[", "]", "\n", "if", "train", ":", "\n", "            ", "for", "cat_folder", "in", "os", ".", "listdir", "(", "self", ".", "train_folder", ")", ":", "\n", "                ", "class_id", "=", "MiniImageNet_All_Category", ".", "index", "(", "cat_folder", ")", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "self", ".", "train_folder", "+", "'/'", "+", "cat_folder", ")", ":", "\n", "                    ", "self", ".", "files", ".", "append", "(", "(", "self", ".", "train_folder", "+", "'/'", "+", "cat_folder", "+", "\"/\"", "+", "filename", ",", "class_id", ")", ")", "\n", "", "", "", "else", ":", "\n", "            ", "for", "cat_folder", "in", "os", ".", "listdir", "(", "self", ".", "test_folder", ")", ":", "\n", "                ", "class_id", "=", "MiniImageNet_All_Category", ".", "index", "(", "cat_folder", ")", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "self", ".", "test_folder", "+", "'/'", "+", "cat_folder", ")", ":", "\n", "                    ", "self", ".", "files", ".", "append", "(", "(", "self", ".", "test_folder", "+", "'/'", "+", "cat_folder", "+", "\"/\"", "+", "filename", ",", "class_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.imagenet_real_dataset.ImageNetRealDataset.__len__": [[27, 29], ["len"], "methods", ["None"], ["", "", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "files", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.imagenet_real_dataset.ImageNetRealDataset.pil_loader": [[30, 34], ["open", "PIL.Image.open", "img.convert"], "methods", ["None"], ["", "def", "pil_loader", "(", "self", ",", "path", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "with", "Image", ".", "open", "(", "f", ")", "as", "img", ":", "\n", "                ", "return", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.imagenet_real_dataset.ImageNetRealDataset.__getitem__": [[35, 41], ["imagenet_real_dataset.ImageNetRealDataset.pil_loader", "imagenet_real_dataset.ImageNetRealDataset.transform"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.imagenet_real_dataset.ImageNetRealDataset.pil_loader"], ["", "", "", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "file_path", ",", "label", "=", "self", ".", "files", "[", "item", "]", "\n", "img", "=", "self", ".", "pil_loader", "(", "file_path", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "return", "img", ",", "label", "", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.white_box_attack_task_dataset.MetaTaskDataset.__init__": [[27, 67], ["glob.glob", "os.makedirs", "white_box_attack_task_dataset.MetaTaskDataset.store_data_per_task", "numpy.prod", "os.listdir", "os.path.dirname", "os.path.isdir", "folder.endswith", "os.path.join", "metaval_folders.append", "folder.endswith", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_dataset.MetaTaskDataset.store_data_per_task"], ["def", "__init__", "(", "self", ",", "num_tot_tasks", ",", "num_classes", ",", "num_support", ",", "num_query", ",", "\n", "dataset", ",", "load_mode", ",", "detector", ",", "attack_name", ",", "root_folder", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            num_samples_per_class: num samples to generate \"per class\" in one batch\n            batch_size: size of meta batch size (e.g. number of functions)\n        \"\"\"", "\n", "self", ".", "num_samples_per_class", "=", "num_support", "+", "num_query", "\n", "self", ".", "num_classes", "=", "num_classes", "# e.g. 5-way", "\n", "self", ".", "img_size", "=", "IMAGE_SIZE", "[", "dataset", "]", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "dim_input", "=", "np", ".", "prod", "(", "self", ".", "img_size", ")", "*", "IN_CHANNELS", "[", "dataset", "]", "\n", "self", ".", "dim_output", "=", "self", ".", "num_classes", "\n", "self", ".", "no_random_way", "=", "True", "\n", "self", ".", "num_support", "=", "num_support", "\n", "self", ".", "num_query", "=", "num_query", "\n", "\n", "metaval_folder", "=", "root_folder", "+", "\"/II\"", "\n", "metaval_folders", "=", "[", "]", "\n", "\n", "for", "each_folder", "in", "glob", ".", "glob", "(", "metaval_folder", ")", ":", "\n", "            ", "for", "label", "in", "os", ".", "listdir", "(", "each_folder", ")", ":", "\n", "                ", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "each_folder", ",", "label", ")", ")", ":", "\n", "                    ", "metaval_folders", ".", "append", "(", "os", ".", "path", ".", "join", "(", "each_folder", ",", "label", ")", ")", "\n", "# get the positive and negative folder if num_classes is 2", "\n", "", "", "", "self", ".", "metaval_folders_p", "=", "[", "folder", "for", "folder", "in", "metaval_folders", "if", "folder", ".", "endswith", "(", "'_1'", ")", "]", "# \u771f\u5b9e\u56fe\u7247", "\n", "self", ".", "metaval_folders_n", "=", "[", "folder", "for", "folder", "in", "metaval_folders", "if", "not", "folder", ".", "endswith", "(", "'_1'", ")", "]", "\n", "\n", "self", ".", "metaval_folders", "=", "metaval_folders", "\n", "\n", "self", ".", "num_tot_trn_tasks", "=", "num_tot_tasks", "\n", "self", ".", "num_tot_val_batches", "=", "1000", "\n", "# white_box@data_conv3@det_DNN/CW_L2", "\n", "self", ".", "task_dump_path", "=", "\"{}/task/white_box@{}_{}_{}/test_{}_{}_{}_tot_num_tasks_{}_way_{}_shot_{}_query_{}.pkl\"", ".", "format", "(", "PY_ROOT", ",", "\n", "dataset", ",", "attack_name", ",", "detector", ",", "\n", "dataset", ",", "attack_name", ",", "detector", ",", "self", ".", "num_tot_val_batches", ",", "\n", "num_classes", ",", "\n", "num_support", ",", "num_query", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "self", ".", "task_dump_path", ")", ",", "exist_ok", "=", "True", ")", "\n", "self", ".", "store_data_per_task", "(", "load_mode", ",", "self", ".", "task_dump_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.white_box_attack_task_dataset.MetaTaskDataset.store_data_per_task": [[69, 116], ["collections.defaultdict", "range", "white_box_attack_task_dataset.MetaTaskDataset.dump_task", "os.path.exists", "os.path.exists", "random.sample", "random.sample", "random.shuffle", "open", "pickle.load", "print", "white_box_attack_task_dataset.MetaTaskDataset.get_image_paths", "white_box_attack_task_dataset.MetaTaskDataset.all_tasks[].append", "white_box_attack_task_dataset.MetaTaskDataset.all_tasks[].append", "random.sample", "random.sample", "random.shuffle", "white_box_attack_task_dataset.MetaTaskDataset.get_image_paths"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_dataset.MetaTaskDataset.dump_task", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_dataset.MetaTaskDataset.get_image_paths", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_dataset.MetaTaskDataset.get_image_paths"], ["", "def", "store_data_per_task", "(", "self", ",", "load_mode", ",", "task_dump_path", ")", ":", "\n", "        ", "if", "load_mode", "==", "LOAD_TASK_MODE", ".", "LOAD", ":", "\n", "            ", "assert", "os", ".", "path", ".", "exists", "(", "task_dump_path", ")", ",", "\"LOAD_TASK_MODE but do not exits task path: {} for load\"", ".", "format", "(", "task_dump_path", ")", "\n", "", "self", ".", "all_tasks", "=", "defaultdict", "(", "list", ")", "\n", "if", "load_mode", "==", "LOAD_TASK_MODE", ".", "LOAD", "and", "os", ".", "path", ".", "exists", "(", "task_dump_path", ")", ":", "\n", "            ", "with", "open", "(", "task_dump_path", ",", "\"rb\"", ")", "as", "file_obj", ":", "\n", "                ", "self", ".", "all_tasks", "=", "pickle", ".", "load", "(", "file_obj", ")", "\n", "", "return", "\n", "\n", "", "folder_p", "=", "self", ".", "metaval_folders_p", "\n", "folder_n", "=", "self", ".", "metaval_folders_n", "\n", "num_total_batches", "=", "self", ".", "num_tot_val_batches", "\n", "\n", "for", "i", "in", "range", "(", "num_total_batches", ")", ":", "# \u603b\u5171\u7684\u8bad\u7ec3\u4efb\u52a1\u4e2a\u6570\uff0c\u6bcf\u6b21\u8fed\u4ee3\u90fd\u4ece\u8fd9\u4e9b\u4efb\u52a1\u53bb\u53d6", "\n", "            ", "if", "i", "%", "100", "==", "0", ":", "\n", "                ", "print", "(", "\"store {} tasks\"", ".", "format", "(", "i", ")", ")", "\n", "", "p_folder", "=", "random", ".", "sample", "(", "folder_p", ",", "1", ")", "# \u53ea\u6709\u4e00\u4e2away\u662f\u6b63\u6837\u672c", "\n", "n_folder", "=", "random", ".", "sample", "(", "folder_n", ",", "self", ".", "num_classes", "-", "1", ")", "# \u5269\u4f59\u76844-way\u90fd\u662f\u8d1f\u6837\u672c", "\n", "task_folders", "=", "p_folder", "+", "n_folder", "# \u51715\u4e2a\u6587\u4ef6\u5939\u8868\u793a5-way", "\n", "\n", "random", ".", "shuffle", "(", "task_folders", ")", "# \u4ece\u8fd9\u4e00\u53e5\u53ef\u4ee5\u770b\u51fa, \u6bcf\u4e2atask\u4e3atask_folders\u968f\u673a\u5b89\u6392\u7684class id\u6beb\u65e0\u89c4\u5f8b\u53ef\u8a00. \u6240\u4ee5no_random_way\u4e5f\u662f\u4f5c\u7528\u5728\u8fd9\u91cc", "\n", "# \u4e3a\u6bcf\u4e00\u7c7bsample\u51faself.num_samples_per_class\u4e2a\u6837\u672c", "\n", "# nb_samples = self.num_samples_per_class = support num + query num", "\n", "try", ":", "\n", "                ", "supp_lbs_and_img_paths", ",", "query_lbs_and_img_paths", ",", "positive_label", "=", "self", ".", "get_image_paths", "(", "task_folders", ",", "\n", "self", ".", "num_support", ",", "self", ".", "num_query", ",", "is_test", "=", "True", ")", "# task_folders\u5305\u542b\u6b63\u8d1f\u6837\u672c\u7684\u5206\u5e03\uff0c\u4f46\u662f\u5177\u4f53support\u53d6\u51e0\u4e2a\uff0cquery\u53d6\u51e0\u4e2a", "\n", "", "except", "IOError", ":", "# \u91cd\u6765\u4e00\u904d sample, \u8fd9\u4e2away\u653e\u5f03", "\n", "                ", "p_folder", "=", "random", ".", "sample", "(", "folder_p", ",", "1", ")", "\n", "n_folder", "=", "random", ".", "sample", "(", "folder_n", ",", "self", ".", "num_classes", "-", "1", ")", "\n", "task_folders", "=", "p_folder", "+", "n_folder", "\n", "random", ".", "shuffle", "(", "task_folders", ")", "\n", "supp_lbs_and_img_paths", ",", "query_lbs_and_img_paths", ",", "positive_label", "=", "self", ".", "get_image_paths", "(", "task_folders", ",", "\n", "self", ".", "num_support", ",", "\n", "self", ".", "num_query", ",", "\n", "is_test", "=", "True", ")", "\n", "\n", "", "for", "supp_img_gt_label", ",", "supp_way_label", ",", "supp_adv_label", ",", "supp_path", "in", "supp_lbs_and_img_paths", ":", "\n", "                ", "self", ".", "all_tasks", "[", "i", "]", ".", "append", "(", "{", "\"task_idx\"", ":", "i", ",", "\"pos_label\"", ":", "positive_label", ",", "\"img_path\"", ":", "supp_path", ",", "\n", "\"img_gt_label\"", ":", "supp_img_gt_label", ",", "\"way_label\"", ":", "supp_way_label", ",", "\n", "\"adv_label\"", ":", "supp_adv_label", ",", "\"type\"", ":", "\"support\"", "}", ")", "\n", "\n", "", "for", "query_img_gt_label", ",", "query_way_label", ",", "query_adv_label", ",", "query_path", "in", "query_lbs_and_img_paths", ":", "\n", "                ", "self", ".", "all_tasks", "[", "i", "]", ".", "append", "(", "{", "\"task_idx\"", ":", "i", ",", "\"pos_label\"", ":", "positive_label", ",", "\"img_path\"", ":", "query_path", ",", "\n", "\"img_gt_label\"", ":", "query_img_gt_label", ",", "\"way_label\"", ":", "query_way_label", ",", "\n", "\"adv_label\"", ":", "query_adv_label", ",", "\"type\"", ":", "\"query\"", "}", ")", "\n", "\n", "", "", "self", ".", "dump_task", "(", "self", ".", "all_tasks", ",", "task_dump_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.white_box_attack_task_dataset.MetaTaskDataset.dump_task": [[117, 121], ["os.makedirs", "os.path.dirname", "open", "pickle.dump"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.dump"], ["", "def", "dump_task", "(", "self", ",", "all_tasks", ",", "task_dump_txt_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "task_dump_txt_path", ")", ",", "exist_ok", "=", "True", ")", "\n", "with", "open", "(", "task_dump_txt_path", ",", "\"wb\"", ")", "as", "file_obj", ":", "\n", "            ", "pickle", ".", "dump", "(", "all_tasks", ",", "file_obj", ",", "protocol", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.white_box_attack_task_dataset.MetaTaskDataset.chunk": [[123, 134], ["list", "random.shuffle", "range", "len", "leftovers.pop"], "methods", ["None"], ["", "", "def", "chunk", "(", "self", ",", "xs", ",", "n", ")", ":", "\n", "        ", "ys", "=", "list", "(", "xs", ")", "\n", "random", ".", "shuffle", "(", "ys", ")", "\n", "size", "=", "len", "(", "ys", ")", "//", "n", "\n", "leftovers", "=", "ys", "[", "size", "*", "n", ":", "]", "\n", "for", "c", "in", "range", "(", "n", ")", ":", "\n", "            ", "if", "leftovers", ":", "\n", "                ", "extra", "=", "[", "leftovers", ".", "pop", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "extra", "=", "[", "]", "\n", "", "yield", "ys", "[", "c", "*", "size", ":", "(", "c", "+", "1", ")", "*", "size", "]", "+", "extra", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.white_box_attack_task_dataset.MetaTaskDataset.get_image_paths": [[135, 203], ["re.compile", "enumerate", "orig_path.endswith", "numpy.arange().tolist", "random.sample", "open", "int", "set", "set", "random.sample", "re.compile.match", "int", "int", "support_images.append", "re.compile.match", "int", "int", "query_images.append", "random.sample", "file_obj.read().strip", "numpy.arange", "print", "re.compile.match.group", "re.compile.match.group", "re.compile.match.group", "re.compile.match.group", "open", "int", "IOError", "IOError", "numpy.arange().tolist", "re.compile.match", "int", "int", "label_images.append", "file_obj.read().strip", "re.compile.match.group", "re.compile.match.group", "file_obj.read", "numpy.arange", "file_obj.read"], "methods", ["None"], ["", "", "def", "get_image_paths", "(", "self", ",", "paths", ",", "num_support", ",", "num_query", ",", "is_test", ")", ":", "\n", "        ", "support_images", "=", "[", "]", "\n", "query_images", "=", "[", "]", "\n", "extract_gt_label_pattern", "=", "re", ".", "compile", "(", "\".*(\\d+)_(\\d+).*\"", ")", "\n", "for", "i", ",", "orig_path", "in", "enumerate", "(", "paths", ")", ":", "# for\u5faa\u73af\u4e00\u4e2apath\u5c31\u8868\u793a\u4e00\u4e2away", "\n", "            ", "if", "orig_path", ".", "endswith", "(", "\"_1\"", ")", ":", "\n", "                ", "positive_label", "=", "i", "\n", "", "if", "not", "is_test", ":", "\n", "                ", "path", "=", "orig_path", "\n", "# \u5982\u679c\u4e0d\u662f", "\n", "npy_path", "=", "orig_path", "+", "\"/train.npy\"", "\n", "with", "open", "(", "path", "+", "\"/\"", "+", "\"count.txt\"", ",", "\"r\"", ")", "as", "file_obj", ":", "\n", "                    ", "N", "=", "int", "(", "file_obj", ".", "read", "(", ")", ".", "strip", "(", ")", ")", "\n", "", "all_index", "=", "np", ".", "arange", "(", "N", ")", ".", "tolist", "(", ")", "\n", "support_idx", "=", "random", ".", "sample", "(", "all_index", ",", "num_support", ")", "\n", "rest_idx", "=", "set", "(", "all_index", ")", "-", "set", "(", "support_idx", ")", "\n", "try", ":", "\n", "                    ", "query_idx", "=", "random", ".", "sample", "(", "rest_idx", ",", "num_query", ")", "\n", "", "except", "ValueError", ":", "\n", "                    ", "print", "(", "\"error in sample from {} N = {} sampling {}\"", ".", "format", "(", "path", ",", "N", ",", "num_query", ")", ")", "\n", "raise", "\n", "", "for", "idx", "in", "support_idx", ":", "\n", "                    ", "whole_path", "=", "\"{}#{}\"", ".", "format", "(", "npy_path", ",", "idx", ")", "\n", "ma", "=", "extract_gt_label_pattern", ".", "match", "(", "whole_path", ")", "\n", "img_gt_label", "=", "int", "(", "ma", ".", "group", "(", "1", ")", ")", "\n", "adv_label", "=", "int", "(", "ma", ".", "group", "(", "2", ")", ")", "\n", "if", "adv_label", "!=", "1", ":", "\n", "                        ", "adv_label", "=", "0", "\n", "", "way_label", "=", "i", "\n", "support_images", ".", "append", "(", "(", "img_gt_label", ",", "way_label", ",", "adv_label", ",", "whole_path", ")", ")", "\n", "", "for", "idx", "in", "query_idx", ":", "\n", "                    ", "whole_path", "=", "\"{}#{}\"", ".", "format", "(", "npy_path", ",", "idx", ")", "\n", "ma", "=", "extract_gt_label_pattern", ".", "match", "(", "whole_path", ")", "\n", "img_gt_label", "=", "int", "(", "ma", ".", "group", "(", "1", ")", ")", "\n", "adv_label", "=", "int", "(", "ma", ".", "group", "(", "2", ")", ")", "\n", "if", "adv_label", "!=", "1", ":", "\n", "                        ", "adv_label", "=", "0", "\n", "", "way_label", "=", "i", "\n", "query_images", ".", "append", "(", "(", "img_gt_label", ",", "way_label", ",", "adv_label", ",", "whole_path", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "sq", "in", "[", "\"support\"", ",", "\"query\"", "]", ":", "\n", "                    ", "path", "=", "orig_path", "+", "\"/{}\"", ".", "format", "(", "sq", ")", "\n", "with", "open", "(", "path", "+", "\"/\"", "+", "\"count.txt\"", ",", "\"r\"", ")", "as", "file_obj", ":", "\n", "                        ", "N", "=", "int", "(", "file_obj", ".", "read", "(", ")", ".", "strip", "(", ")", ")", "\n", "", "if", "sq", "==", "\"support\"", "and", "N", "<", "num_support", ":", "\n", "                        ", "raise", "IOError", "(", "'please check that whether each class contains enough images for the support set,'", "\n", "'the class path is :  '", "+", "path", ")", "\n", "", "if", "sq", "==", "\"query\"", "and", "N", "<", "num_query", ":", "\n", "                        ", "raise", "IOError", "(", "'please check that whether each class contains enough images for the query set,'", "\n", "'the class path is :  '", "+", "path", ")", "\n", "", "if", "sq", "==", "\"support\"", ":", "\n", "                        ", "num", "=", "num_support", "\n", "label_images", "=", "support_images", "\n", "", "elif", "sq", "==", "\"query\"", ":", "\n", "                        ", "num", "=", "num_query", "\n", "label_images", "=", "query_images", "\n", "", "sampled_images", "=", "random", ".", "sample", "(", "np", ".", "arange", "(", "N", ")", ".", "tolist", "(", ")", ",", "num", ")", "# support\u548cquery\u4e0d\u80fd\u6709\u4ea4\u96c6", "\n", "for", "idx", "in", "sampled_images", ":", "\n", "                        ", "whole_path", "=", "\"{}/{}.npy#{}\"", ".", "format", "(", "path", ",", "sq", ",", "idx", ")", "\n", "ma", "=", "extract_gt_label_pattern", ".", "match", "(", "whole_path", ")", "\n", "img_gt_label", "=", "int", "(", "ma", ".", "group", "(", "1", ")", ")", "\n", "adv_label", "=", "int", "(", "ma", ".", "group", "(", "2", ")", ")", "\n", "if", "adv_label", "!=", "1", ":", "\n", "                            ", "adv_label", "=", "0", "# real image == 1, adv image == 0", "\n", "", "way_label", "=", "i", "\n", "label_images", ".", "append", "(", "(", "img_gt_label", ",", "way_label", ",", "adv_label", ",", "whole_path", ")", ")", "\n", "\n", "", "", "", "", "return", "support_images", ",", "query_images", ",", "positive_label", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.white_box_attack_task_dataset.MetaTaskDataset.__getitem__": [[204, 282], ["random.shuffle", "random.shuffle", "numpy.concatenate", "numpy.array", "numpy.array", "numpy.concatenate", "numpy.array", "numpy.array", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.Tensor().long().view", "int", "open", "numpy.memmap().copy", "open.close", "numpy.transpose.reshape", "numpy.transpose", "numpy.transpose.reshape", "image_list.append", "adv_label_list.append", "img_gt_label_list.append", "int", "open", "numpy.memmap().copy", "open.close", "numpy.transpose.reshape", "numpy.transpose", "numpy.transpose.reshape", "image_list.append", "adv_label_list.append", "img_gt_label_list.append", "print", "int", "int", "int", "int", "int", "int", "torch.Tensor().long", "image_path.rindex", "numpy.memmap", "image_path.rindex", "numpy.memmap", "torch.Tensor", "image_path.rindex", "image_path.rindex"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.close", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.close"], ["", "def", "__getitem__", "(", "self", ",", "task_index", ")", ":", "\n", "        ", "task_data_list", "=", "self", ".", "all_tasks", "[", "task_index", "]", "#\u53d6\u51fa\u8be5task\u76845-way\u7684\u6240\u6709\u6570\u636e", "\n", "\n", "train_files", "=", "[", "data_json", "for", "data_json", "in", "task_data_list", "if", "data_json", "[", "\"type\"", "]", "==", "\"support\"", "]", "\n", "test_files", "=", "[", "data_json", "for", "data_json", "in", "task_data_list", "if", "data_json", "[", "\"type\"", "]", "==", "\"query\"", "]", "\n", "try", ":", "\n", "            ", "task_positive_label", "=", "train_files", "[", "0", "]", "[", "\"pos_label\"", "]", "\n", "", "except", "IndexError", ":", "\n", "            ", "print", "(", "\"task :{}\"", ".", "format", "(", "task_index", ")", ")", "\n", "raise", "\n", "", "random", ".", "shuffle", "(", "train_files", ")", "\n", "random", ".", "shuffle", "(", "test_files", ")", "\n", "image_list", "=", "[", "]", "\n", "adv_label_list", "=", "[", "]", "\n", "img_gt_label_list", "=", "[", "]", "\n", "for", "data_json", "in", "train_files", ":", "# adv_type_label, img_gt_label, whole_path", "\n", "            ", "img_gt_label", ",", "image_path", "=", "int", "(", "data_json", "[", "\"img_gt_label\"", "]", ")", ",", "data_json", "[", "\"img_path\"", "]", "\n", "if", "self", ".", "no_random_way", ":", "\n", "                ", "adv_label", "=", "int", "(", "data_json", "[", "\"adv_label\"", "]", ")", "\n", "", "else", ":", "\n", "                ", "adv_label", "=", "int", "(", "data_json", "[", "\"way_label\"", "]", ")", "\n", "\n", "", "image_idx", "=", "int", "(", "image_path", "[", "image_path", ".", "rindex", "(", "\"#\"", ")", "+", "1", ":", "]", ")", "\n", "image_path", "=", "image_path", "[", ":", "image_path", ".", "rindex", "(", "\"#\"", ")", "]", "\n", "fobj", "=", "open", "(", "image_path", ",", "\"rb\"", ")", "\n", "im", "=", "np", ".", "memmap", "(", "fobj", ",", "dtype", "=", "'float32'", ",", "mode", "=", "'r'", ",", "shape", "=", "(", "\n", "1", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "0", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "1", "]", ",", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ")", ",", "\n", "offset", "=", "image_idx", "*", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "0", "]", "*", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "1", "]", "*", "IN_CHANNELS", "[", "\n", "self", ".", "dataset", "]", "*", "32", "//", "8", ")", ".", "copy", "(", ")", "\n", "fobj", ".", "close", "(", ")", "\n", "im", "=", "im", ".", "reshape", "(", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "0", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "1", "]", ",", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ")", "\n", "\n", "im", "=", "np", ".", "transpose", "(", "im", ",", "axes", "=", "(", "2", ",", "0", ",", "1", ")", ")", "# C,H,W", "\n", "im2", "=", "im", ".", "reshape", "(", "self", ".", "dim_input", ")", "\n", "image_list", ".", "append", "(", "im2", "[", "np", ".", "newaxis", ",", ":", "]", ")", "# \u52a0\u4e00\u4e2a\u65b0\u7684\u7ef4\u5ea6", "\n", "adv_label_list", ".", "append", "(", "adv_label", ")", "\n", "img_gt_label_list", ".", "append", "(", "img_gt_label", ")", "\n", "\n", "", "task_train_ims", "=", "np", ".", "concatenate", "(", "image_list", ",", "axis", "=", "0", ")", "# N, 3072", "\n", "train_adv_labels", "=", "np", ".", "array", "(", "adv_label_list", ")", "\n", "train_img_gt_labels", "=", "np", ".", "array", "(", "img_gt_label_list", ")", "\n", "image_list", "=", "[", "]", "\n", "adv_label_list", "=", "[", "]", "\n", "img_gt_label_list", "=", "[", "]", "\n", "for", "data_json", "in", "test_files", ":", "# adv_type_label, img_gt_label, whole_path", "\n", "            ", "img_gt_label", ",", "image_path", "=", "int", "(", "data_json", "[", "\"img_gt_label\"", "]", ")", ",", "data_json", "[", "\"img_path\"", "]", "\n", "if", "self", ".", "no_random_way", ":", "\n", "                ", "adv_label", "=", "int", "(", "data_json", "[", "\"adv_label\"", "]", ")", "\n", "", "else", ":", "\n", "                ", "adv_label", "=", "int", "(", "data_json", "[", "\"way_label\"", "]", ")", "\n", "\n", "", "image_idx", "=", "int", "(", "image_path", "[", "image_path", ".", "rindex", "(", "\"#\"", ")", "+", "1", ":", "]", ")", "\n", "image_path", "=", "image_path", "[", ":", "image_path", ".", "rindex", "(", "\"#\"", ")", "]", "\n", "fobj", "=", "open", "(", "image_path", ",", "\"rb\"", ")", "\n", "im", "=", "np", ".", "memmap", "(", "fobj", ",", "dtype", "=", "'float32'", ",", "mode", "=", "'r'", ",", "shape", "=", "(", "\n", "1", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "0", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "1", "]", ",", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ")", ",", "\n", "offset", "=", "image_idx", "*", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "0", "]", "*", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "1", "]", "*", "IN_CHANNELS", "[", "\n", "self", ".", "dataset", "]", "*", "32", "//", "8", ")", ".", "copy", "(", ")", "\n", "fobj", ".", "close", "(", ")", "\n", "im", "=", "im", ".", "reshape", "(", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "0", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "1", "]", ",", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ")", "\n", "im", "=", "np", ".", "transpose", "(", "im", ",", "axes", "=", "(", "2", ",", "0", ",", "1", ")", ")", "# C,H,W", "\n", "im2", "=", "im", ".", "reshape", "(", "self", ".", "dim_input", ")", "\n", "image_list", ".", "append", "(", "im2", "[", "np", ".", "newaxis", ",", ":", "]", ")", "# \u52a0\u4e00\u4e2a\u65b0\u7684\u7ef4\u5ea6", "\n", "adv_label_list", ".", "append", "(", "adv_label", ")", "\n", "img_gt_label_list", ".", "append", "(", "img_gt_label", ")", "\n", "", "task_test_ims", "=", "np", ".", "concatenate", "(", "image_list", ",", "axis", "=", "0", ")", "# N C H W", "\n", "test_adv_labels", "=", "np", ".", "array", "(", "adv_label_list", ")", "\n", "test_img_gt_labels", "=", "np", ".", "array", "(", "img_gt_label_list", ")", "\n", "\n", "task_train_ims", "=", "torch", ".", "from_numpy", "(", "task_train_ims", ")", "\n", "train_adv_labels", "=", "torch", ".", "from_numpy", "(", "train_adv_labels", ")", "\n", "train_img_gt_labels", "=", "torch", ".", "from_numpy", "(", "train_img_gt_labels", ")", "\n", "task_test_ims", "=", "torch", ".", "from_numpy", "(", "task_test_ims", ")", "\n", "test_adv_labels", "=", "torch", ".", "from_numpy", "(", "test_adv_labels", ")", "\n", "test_img_gt_labels", "=", "torch", ".", "from_numpy", "(", "test_img_gt_labels", ")", "# \u6682\u65f6\u4e0d\u7528\u8fd9\u4e2a", "\n", "task_positive_label", "=", "torch", ".", "Tensor", "(", "[", "task_positive_label", "]", ")", ".", "long", "(", ")", ".", "view", "(", "1", ",", ")", "\n", "# support_images,support_gt_labels, support_binary_labels, query_images, query_gt_labels, query_binary_labels", "\n", "return", "task_train_ims", ",", "train_img_gt_labels", ",", "train_adv_labels", ",", "task_test_ims", ",", "test_img_gt_labels", ",", "test_adv_labels", ",", "task_positive_label", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.white_box_attack_task_dataset.MetaTaskDataset.__len__": [[283, 285], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "all_tasks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_only_support_dataset.MetaTaskDatasetOnlySupport.__init__": [[27, 92], ["glob.glob", "glob.glob", "meta_task_only_support_dataset.MetaTaskDatasetOnlySupport.store_data_per_task", "numpy.prod", "os.listdir", "os.listdir", "os.path.isdir", "os.path.isdir", "folder.endswith", "folder.endswith", "os.path.join", "metatrain_folders.append", "os.path.join", "metaval_folders.append", "folder.endswith", "folder.endswith", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_dataset.MetaTaskDataset.store_data_per_task"], ["def", "__init__", "(", "self", ",", "num_tot_tasks", ",", "num_classes", ",", "num_support", ",", "num_query", ",", "\n", "dataset", ",", "is_train", ",", "load_mode", ",", "protocol", ",", "no_random_way", ",", "adv_arch", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            num_samples_per_class: num samples to generate \"per class\" in one batch\n            batch_size: size of meta batch size (e.g. number of functions)\n        \"\"\"", "\n", "self", ".", "num_samples_per_class", "=", "num_support", "+", "num_query", "\n", "self", ".", "num_classes", "=", "num_classes", "# e.g. 5-way", "\n", "self", ".", "img_size", "=", "IMAGE_SIZE", "[", "dataset", "]", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "dim_input", "=", "np", ".", "prod", "(", "self", ".", "img_size", ")", "*", "IN_CHANNELS", "[", "dataset", "]", "\n", "self", ".", "dim_output", "=", "self", ".", "num_classes", "\n", "self", ".", "train", "=", "is_train", "# \u533a\u5206\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6", "\n", "self", ".", "no_random_way", "=", "no_random_way", "\n", "self", ".", "num_support", "=", "num_support", "\n", "self", ".", "num_query", "=", "num_query", "\n", "if", "not", "self", ".", "train", ":", "\n", "            ", "assert", "no_random_way", ",", "\"In test mode, we must specify the fixed way setting!\"", "\n", "", "if", "protocol", "==", "SPLIT_DATA_PROTOCOL", ".", "TRAIN_I_TEST_II", ":", "\n", "            ", "train_sub_folder", "=", "\"I\"", "\n", "test_sub_folder", "=", "\"II\"", "\n", "", "elif", "protocol", "==", "SPLIT_DATA_PROTOCOL", ".", "TRAIN_II_TEST_I", ":", "\n", "            ", "train_sub_folder", "=", "\"II\"", "\n", "test_sub_folder", "=", "\"I\"", "\n", "", "elif", "protocol", "==", "SPLIT_DATA_PROTOCOL", ".", "TRAIN_ALL_TEST_ALL", ":", "\n", "            ", "train_sub_folder", "=", "\"*\"", "\n", "test_sub_folder", "=", "\"*\"", "\n", "\n", "", "root_folder", "=", "TASK_DATA_ROOT", "[", "dataset", "]", "[", "adv_arch", "]", "\n", "metatrain_folder", "=", "root_folder", "+", "'/train/'", "+", "train_sub_folder", "\n", "metaval_folder", "=", "root_folder", "+", "\"/test/\"", "+", "test_sub_folder", "\n", "\n", "metatrain_folders", "=", "[", "]", "\n", "metaval_folders", "=", "[", "]", "\n", "for", "root_folder", "in", "glob", ".", "glob", "(", "metatrain_folder", ")", ":", "\n", "            ", "for", "label", "in", "os", ".", "listdir", "(", "root_folder", ")", ":", "\n", "                ", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "label", ")", ")", ":", "\n", "                    ", "metatrain_folders", ".", "append", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "label", ")", ")", "\n", "", "", "", "for", "root_folder", "in", "glob", ".", "glob", "(", "metaval_folder", ")", ":", "\n", "            ", "for", "label", "in", "os", ".", "listdir", "(", "root_folder", ")", ":", "\n", "                ", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "label", ")", ")", ":", "\n", "                    ", "metaval_folders", ".", "append", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "label", ")", ")", "\n", "# get the positive and negative folder if num_classes is 2", "\n", "", "", "", "self", ".", "metatrain_folders_p", "=", "[", "folder", "for", "folder", "in", "metatrain_folders", "if", "folder", ".", "endswith", "(", "'_1'", ")", "]", "# 1 \u8868\u793a\u5e72\u51c0\u771f\u5b9e\u56fe\u7247", "\n", "self", ".", "metatrain_folders_n", "=", "[", "folder", "for", "folder", "in", "metatrain_folders", "if", "not", "folder", ".", "endswith", "(", "'_1'", ")", "]", "\n", "self", ".", "metaval_folders_p", "=", "[", "folder", "for", "folder", "in", "metaval_folders", "if", "folder", ".", "endswith", "(", "'_1'", ")", "]", "# \u771f\u5b9e\u56fe\u7247", "\n", "self", ".", "metaval_folders_n", "=", "[", "folder", "for", "folder", "in", "metaval_folders", "if", "not", "folder", ".", "endswith", "(", "'_1'", ")", "]", "\n", "\n", "self", ".", "metatrain_folders", "=", "metatrain_folders", "\n", "self", ".", "metaval_folders", "=", "metaval_folders", "\n", "\n", "self", ".", "num_tot_trn_tasks", "=", "num_tot_tasks", "\n", "self", ".", "num_tot_val_batches", "=", "1000", "\n", "num_tot_tasks", "=", "self", ".", "num_tot_trn_tasks", "\n", "trn_or_test_str", "=", "\"train\"", "\n", "if", "not", "is_train", ":", "\n", "            ", "trn_or_test_str", "=", "\"test\"", "\n", "num_tot_tasks", "=", "self", ".", "num_tot_val_batches", "\n", "\n", "", "self", ".", "task_dump_txt_path", "=", "\"{}/task/only_sup_{}_{}/{}/{}_{}_tot_num_tasks_{}_way_{}_shot_{}_query_{}.pkl\"", ".", "format", "(", "PY_ROOT", ",", "protocol", ",", "\n", "dataset", ",", "adv_arch", ",", "trn_or_test_str", ",", "\n", "dataset", ",", "num_tot_tasks", ",", "num_classes", ",", "\n", "num_support", ",", "num_query", ")", "\n", "self", ".", "store_data_per_task", "(", "load_mode", ",", "self", ".", "task_dump_txt_path", ",", "train", "=", "is_train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_only_support_dataset.MetaTaskDatasetOnlySupport.store_data_per_task": [[94, 142], ["collections.defaultdict", "range", "meta_task_only_support_dataset.MetaTaskDatasetOnlySupport.dump_task", "os.path.exists", "os.path.exists", "random.sample", "random.sample", "random.shuffle", "open", "pickle.load", "print", "meta_task_only_support_dataset.MetaTaskDatasetOnlySupport.get_image_paths", "meta_task_only_support_dataset.MetaTaskDatasetOnlySupport.all_tasks[].append", "random.sample", "random.sample", "random.shuffle", "meta_task_only_support_dataset.MetaTaskDatasetOnlySupport.get_image_paths"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_dataset.MetaTaskDataset.dump_task", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_dataset.MetaTaskDataset.get_image_paths", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_dataset.MetaTaskDataset.get_image_paths"], ["", "def", "store_data_per_task", "(", "self", ",", "load_mode", ",", "task_dump_txt_path", ",", "train", "=", "True", ")", ":", "\n", "        ", "if", "load_mode", "==", "LOAD_TASK_MODE", ".", "LOAD", ":", "\n", "            ", "assert", "os", ".", "path", ".", "exists", "(", "task_dump_txt_path", ")", ",", "\"LOAD_TASK_MODE but do not exits task path: {} for load\"", ".", "format", "(", "task_dump_txt_path", ")", "\n", "", "self", ".", "all_tasks", "=", "defaultdict", "(", "list", ")", "\n", "if", "load_mode", "==", "LOAD_TASK_MODE", ".", "LOAD", "and", "os", ".", "path", ".", "exists", "(", "task_dump_txt_path", ")", ":", "\n", "            ", "with", "open", "(", "task_dump_txt_path", ",", "\"rb\"", ")", "as", "file_obj", ":", "\n", "                ", "self", ".", "all_tasks", "=", "pickle", ".", "load", "(", "file_obj", ")", "\n", "", "return", "\n", "\n", "", "if", "train", ":", "\n", "            ", "folder_p", "=", "self", ".", "metatrain_folders_p", "\n", "folder_n", "=", "self", ".", "metatrain_folders_n", "\n", "num_total_batches", "=", "self", ".", "num_tot_trn_tasks", "\n", "", "else", ":", "\n", "            ", "folder_p", "=", "self", ".", "metaval_folders_p", "\n", "folder_n", "=", "self", ".", "metaval_folders_n", "\n", "num_total_batches", "=", "self", ".", "num_tot_val_batches", "\n", "\n", "", "for", "i", "in", "range", "(", "num_total_batches", ")", ":", "# \u603b\u5171\u7684\u8bad\u7ec3\u4efb\u52a1\u4e2a\u6570\uff0c\u6bcf\u6b21\u8fed\u4ee3\u90fd\u4ece\u8fd9\u4e9b\u4efb\u52a1\u53bb\u53d6", "\n", "            ", "if", "i", "%", "100", "==", "0", ":", "\n", "                ", "print", "(", "\"store {} tasks\"", ".", "format", "(", "i", ")", ")", "\n", "", "p_folder", "=", "random", ".", "sample", "(", "folder_p", ",", "1", ")", "# \u53ea\u6709\u4e00\u4e2away\u662f\u6b63\u6837\u672c", "\n", "n_folder", "=", "random", ".", "sample", "(", "folder_n", ",", "self", ".", "num_classes", "-", "1", ")", "# \u5269\u4f59\u76844-way\u90fd\u662f\u8d1f\u6837\u672c", "\n", "task_folders", "=", "p_folder", "+", "n_folder", "# \u51715\u4e2a\u6587\u4ef6\u5939\u8868\u793a5-way", "\n", "\n", "random", ".", "shuffle", "(", "task_folders", ")", "# \u4ece\u8fd9\u4e00\u53e5\u53ef\u4ee5\u770b\u51fa, \u6bcf\u4e2atask\u4e3atask_folders\u968f\u673a\u5b89\u6392\u7684class id\u6beb\u65e0\u89c4\u5f8b\u53ef\u8a00. \u6240\u4ee5no_random_way\u4e5f\u662f\u4f5c\u7528\u5728\u8fd9\u91cc", "\n", "# \u4e3a\u6bcf\u4e00\u7c7bsample\u51faself.num_samples_per_class\u4e2a\u6837\u672c", "\n", "# nb_samples = self.num_samples_per_class = support num + query num", "\n", "try", ":", "\n", "                ", "supp_lbs_and_img_paths", ",", "query_lbs_and_img_paths", ",", "positive_label", "=", "self", ".", "get_image_paths", "(", "task_folders", ",", "\n", "self", ".", "num_support", ",", "self", ".", "num_query", ",", "is_test", "=", "not", "train", ")", "# task_folders\u5305\u542b\u6b63\u8d1f\u6837\u672c\u7684\u5206\u5e03\uff0c\u4f46\u662f\u5177\u4f53support\u53d6\u51e0\u4e2a\uff0cquery\u53d6\u51e0\u4e2a", "\n", "", "except", "IOError", ":", "# \u91cd\u6765\u4e00\u904d sample, \u8fd9\u4e2away\u653e\u5f03", "\n", "                ", "p_folder", "=", "random", ".", "sample", "(", "folder_p", ",", "1", ")", "\n", "n_folder", "=", "random", ".", "sample", "(", "folder_n", ",", "self", ".", "num_classes", "-", "1", ")", "\n", "task_folders", "=", "p_folder", "+", "n_folder", "\n", "random", ".", "shuffle", "(", "task_folders", ")", "\n", "supp_lbs_and_img_paths", ",", "query_lbs_and_img_paths", ",", "positive_label", "=", "self", ".", "get_image_paths", "(", "task_folders", ",", "\n", "self", ".", "num_support", ",", "\n", "self", ".", "num_query", ",", "\n", "is_test", "=", "not", "train", ")", "\n", "\n", "", "for", "supp_img_gt_label", ",", "supp_way_label", ",", "supp_adv_label", ",", "supp_path", "in", "supp_lbs_and_img_paths", ":", "\n", "                ", "self", ".", "all_tasks", "[", "i", "]", ".", "append", "(", "{", "\"task_idx\"", ":", "i", ",", "\"pos_label\"", ":", "positive_label", ",", "\"img_path\"", ":", "supp_path", ",", "\n", "\"img_gt_label\"", ":", "supp_img_gt_label", ",", "\"way_label\"", ":", "supp_way_label", ",", "\n", "\"adv_label\"", ":", "supp_adv_label", ",", "\"type\"", ":", "\"support\"", "}", ")", "\n", "\n", "\n", "", "", "self", ".", "dump_task", "(", "self", ".", "all_tasks", ",", "task_dump_txt_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_only_support_dataset.MetaTaskDatasetOnlySupport.dump_task": [[143, 147], ["os.makedirs", "os.path.dirname", "open", "pickle.dump"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.dump"], ["", "def", "dump_task", "(", "self", ",", "all_tasks", ",", "task_dump_txt_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "task_dump_txt_path", ")", ",", "exist_ok", "=", "True", ")", "\n", "with", "open", "(", "task_dump_txt_path", ",", "\"wb\"", ")", "as", "file_obj", ":", "\n", "            ", "pickle", ".", "dump", "(", "all_tasks", ",", "file_obj", ",", "protocol", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_only_support_dataset.MetaTaskDatasetOnlySupport.chunk": [[149, 160], ["list", "random.shuffle", "range", "len", "leftovers.pop"], "methods", ["None"], ["", "", "def", "chunk", "(", "self", ",", "xs", ",", "n", ")", ":", "\n", "        ", "ys", "=", "list", "(", "xs", ")", "\n", "random", ".", "shuffle", "(", "ys", ")", "\n", "size", "=", "len", "(", "ys", ")", "//", "n", "\n", "leftovers", "=", "ys", "[", "size", "*", "n", ":", "]", "\n", "for", "c", "in", "range", "(", "n", ")", ":", "\n", "            ", "if", "leftovers", ":", "\n", "                ", "extra", "=", "[", "leftovers", ".", "pop", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "extra", "=", "[", "]", "\n", "", "yield", "ys", "[", "c", "*", "size", ":", "(", "c", "+", "1", ")", "*", "size", "]", "+", "extra", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_only_support_dataset.MetaTaskDatasetOnlySupport.get_image_paths": [[161, 229], ["re.compile", "enumerate", "orig_path.endswith", "numpy.arange().tolist", "random.sample", "open", "int", "set", "set", "random.sample", "re.compile.match", "int", "int", "support_images.append", "re.compile.match", "int", "int", "query_images.append", "random.sample", "file_obj.read().strip", "numpy.arange", "print", "re.compile.match.group", "re.compile.match.group", "re.compile.match.group", "re.compile.match.group", "open", "int", "IOError", "IOError", "numpy.arange().tolist", "re.compile.match", "int", "int", "label_images.append", "file_obj.read().strip", "re.compile.match.group", "re.compile.match.group", "file_obj.read", "numpy.arange", "file_obj.read"], "methods", ["None"], ["", "", "def", "get_image_paths", "(", "self", ",", "paths", ",", "num_support", ",", "num_query", ",", "is_test", ")", ":", "\n", "        ", "support_images", "=", "[", "]", "\n", "query_images", "=", "[", "]", "\n", "extract_gt_label_pattern", "=", "re", ".", "compile", "(", "\".*(\\d+)_(\\d+).*\"", ")", "\n", "for", "i", ",", "orig_path", "in", "enumerate", "(", "paths", ")", ":", "# for\u5faa\u73af\u4e00\u4e2apath\u5c31\u8868\u793a\u4e00\u4e2away", "\n", "            ", "if", "orig_path", ".", "endswith", "(", "\"_1\"", ")", ":", "\n", "                ", "positive_label", "=", "i", "\n", "", "if", "not", "is_test", ":", "\n", "                ", "path", "=", "orig_path", "\n", "# \u5982\u679c\u4e0d\u662f", "\n", "npy_path", "=", "orig_path", "+", "\"/train.npy\"", "\n", "with", "open", "(", "path", "+", "\"/\"", "+", "\"count.txt\"", ",", "\"r\"", ")", "as", "file_obj", ":", "\n", "                    ", "N", "=", "int", "(", "file_obj", ".", "read", "(", ")", ".", "strip", "(", ")", ")", "\n", "", "all_index", "=", "np", ".", "arange", "(", "N", ")", ".", "tolist", "(", ")", "\n", "support_idx", "=", "random", ".", "sample", "(", "all_index", ",", "num_support", ")", "\n", "rest_idx", "=", "set", "(", "all_index", ")", "-", "set", "(", "support_idx", ")", "\n", "try", ":", "\n", "                    ", "query_idx", "=", "random", ".", "sample", "(", "rest_idx", ",", "num_query", ")", "\n", "", "except", "ValueError", ":", "\n", "                    ", "print", "(", "\"error in sample from {} N = {} sampling {}\"", ".", "format", "(", "path", ",", "N", ",", "num_query", ")", ")", "\n", "raise", "\n", "", "for", "idx", "in", "support_idx", ":", "\n", "                    ", "whole_path", "=", "\"{}#{}\"", ".", "format", "(", "npy_path", ",", "idx", ")", "\n", "ma", "=", "extract_gt_label_pattern", ".", "match", "(", "whole_path", ")", "\n", "img_gt_label", "=", "int", "(", "ma", ".", "group", "(", "1", ")", ")", "\n", "adv_label", "=", "int", "(", "ma", ".", "group", "(", "2", ")", ")", "\n", "if", "adv_label", "!=", "1", ":", "\n", "                        ", "adv_label", "=", "0", "\n", "", "way_label", "=", "i", "\n", "support_images", ".", "append", "(", "(", "img_gt_label", ",", "way_label", ",", "adv_label", ",", "whole_path", ")", ")", "\n", "", "for", "idx", "in", "query_idx", ":", "\n", "                    ", "whole_path", "=", "\"{}#{}\"", ".", "format", "(", "npy_path", ",", "idx", ")", "\n", "ma", "=", "extract_gt_label_pattern", ".", "match", "(", "whole_path", ")", "\n", "img_gt_label", "=", "int", "(", "ma", ".", "group", "(", "1", ")", ")", "\n", "adv_label", "=", "int", "(", "ma", ".", "group", "(", "2", ")", ")", "\n", "if", "adv_label", "!=", "1", ":", "\n", "                        ", "adv_label", "=", "0", "\n", "", "way_label", "=", "i", "\n", "query_images", ".", "append", "(", "(", "img_gt_label", ",", "way_label", ",", "adv_label", ",", "whole_path", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "sq", "in", "[", "\"support\"", ",", "\"query\"", "]", ":", "\n", "                    ", "path", "=", "orig_path", "+", "\"/{}\"", ".", "format", "(", "sq", ")", "\n", "with", "open", "(", "path", "+", "\"/\"", "+", "\"count.txt\"", ",", "\"r\"", ")", "as", "file_obj", ":", "\n", "                        ", "N", "=", "int", "(", "file_obj", ".", "read", "(", ")", ".", "strip", "(", ")", ")", "\n", "", "if", "sq", "==", "\"support\"", "and", "N", "<", "num_support", ":", "\n", "                        ", "raise", "IOError", "(", "'please check that whether each class contains enough images for the support set,'", "\n", "'the class path is :  '", "+", "path", ")", "\n", "", "if", "sq", "==", "\"query\"", "and", "N", "<", "num_query", ":", "\n", "                        ", "raise", "IOError", "(", "'please check that whether each class contains enough images for the query set,'", "\n", "'the class path is :  '", "+", "path", ")", "\n", "", "if", "sq", "==", "\"support\"", ":", "\n", "                        ", "num", "=", "num_support", "\n", "label_images", "=", "support_images", "\n", "", "elif", "sq", "==", "\"query\"", ":", "\n", "                        ", "num", "=", "num_query", "\n", "label_images", "=", "query_images", "\n", "", "sampled_images", "=", "random", ".", "sample", "(", "np", ".", "arange", "(", "N", ")", ".", "tolist", "(", ")", ",", "num", ")", "# support\u548cquery\u4e0d\u80fd\u6709\u4ea4\u96c6", "\n", "for", "idx", "in", "sampled_images", ":", "\n", "                        ", "whole_path", "=", "\"{}/{}.npy#{}\"", ".", "format", "(", "path", ",", "sq", ",", "idx", ")", "\n", "ma", "=", "extract_gt_label_pattern", ".", "match", "(", "whole_path", ")", "\n", "img_gt_label", "=", "int", "(", "ma", ".", "group", "(", "1", ")", ")", "\n", "adv_label", "=", "int", "(", "ma", ".", "group", "(", "2", ")", ")", "\n", "if", "adv_label", "!=", "1", ":", "\n", "                            ", "adv_label", "=", "0", "# real image == 1, adv image == 0", "\n", "", "way_label", "=", "i", "\n", "label_images", ".", "append", "(", "(", "img_gt_label", ",", "way_label", ",", "adv_label", ",", "whole_path", ")", ")", "\n", "\n", "", "", "", "", "return", "support_images", ",", "query_images", ",", "positive_label", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_only_support_dataset.MetaTaskDatasetOnlySupport.__getitem__": [[230, 275], ["random.shuffle", "numpy.concatenate", "numpy.array", "numpy.array", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.Tensor().long().view", "int", "open", "numpy.memmap().copy", "open.close", "numpy.transpose.reshape", "numpy.transpose", "numpy.transpose.reshape", "image_list.append", "adv_label_list.append", "img_gt_label_list.append", "print", "int", "int", "int", "torch.Tensor().long", "image_path.rindex", "numpy.memmap", "torch.Tensor", "image_path.rindex"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.close"], ["", "def", "__getitem__", "(", "self", ",", "task_index", ")", ":", "\n", "        ", "task_data_list", "=", "self", ".", "all_tasks", "[", "task_index", "]", "#\u53d6\u51fa\u8be5task\u76845-way\u7684\u6240\u6709\u6570\u636e", "\n", "\n", "train_files", "=", "[", "data_json", "for", "data_json", "in", "task_data_list", "if", "data_json", "[", "\"type\"", "]", "==", "\"support\"", "]", "\n", "try", ":", "\n", "            ", "task_positive_label", "=", "train_files", "[", "0", "]", "[", "\"pos_label\"", "]", "\n", "", "except", "IndexError", ":", "\n", "            ", "print", "(", "\"task :{}\"", ".", "format", "(", "task_index", ")", ")", "\n", "raise", "\n", "", "random", ".", "shuffle", "(", "train_files", ")", "\n", "image_list", "=", "[", "]", "\n", "adv_label_list", "=", "[", "]", "\n", "img_gt_label_list", "=", "[", "]", "\n", "for", "data_json", "in", "train_files", ":", "# adv_type_label, img_gt_label, whole_path", "\n", "            ", "img_gt_label", ",", "image_path", "=", "int", "(", "data_json", "[", "\"img_gt_label\"", "]", ")", ",", "data_json", "[", "\"img_path\"", "]", "\n", "if", "self", ".", "no_random_way", ":", "\n", "                ", "adv_label", "=", "int", "(", "data_json", "[", "\"adv_label\"", "]", ")", "\n", "", "else", ":", "\n", "                ", "adv_label", "=", "int", "(", "data_json", "[", "\"way_label\"", "]", ")", "\n", "\n", "", "image_idx", "=", "int", "(", "image_path", "[", "image_path", ".", "rindex", "(", "\"#\"", ")", "+", "1", ":", "]", ")", "\n", "image_path", "=", "image_path", "[", ":", "image_path", ".", "rindex", "(", "\"#\"", ")", "]", "\n", "fobj", "=", "open", "(", "image_path", ",", "\"rb\"", ")", "\n", "im", "=", "np", ".", "memmap", "(", "fobj", ",", "dtype", "=", "'float32'", ",", "mode", "=", "'r'", ",", "shape", "=", "(", "\n", "1", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "0", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "1", "]", ",", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ")", ",", "\n", "offset", "=", "image_idx", "*", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "0", "]", "*", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "1", "]", "*", "IN_CHANNELS", "[", "\n", "self", ".", "dataset", "]", "*", "32", "//", "8", ")", ".", "copy", "(", ")", "\n", "fobj", ".", "close", "(", ")", "\n", "im", "=", "im", ".", "reshape", "(", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "0", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "1", "]", ",", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ")", "\n", "im", "=", "np", ".", "transpose", "(", "im", ",", "axes", "=", "(", "2", ",", "0", ",", "1", ")", ")", "# C,H,W", "\n", "im2", "=", "im", ".", "reshape", "(", "self", ".", "dim_input", ")", "\n", "image_list", ".", "append", "(", "im2", "[", "np", ".", "newaxis", ",", ":", "]", ")", "# \u52a0\u4e00\u4e2a\u65b0\u7684\u7ef4\u5ea6", "\n", "adv_label_list", ".", "append", "(", "adv_label", ")", "\n", "img_gt_label_list", ".", "append", "(", "img_gt_label", ")", "\n", "\n", "", "task_train_ims", "=", "np", ".", "concatenate", "(", "image_list", ",", "axis", "=", "0", ")", "# N, 3072", "\n", "train_adv_labels", "=", "np", ".", "array", "(", "adv_label_list", ")", "\n", "train_img_gt_labels", "=", "np", ".", "array", "(", "img_gt_label_list", ")", "\n", "\n", "task_train_ims", "=", "torch", ".", "from_numpy", "(", "task_train_ims", ")", "\n", "train_adv_labels", "=", "torch", ".", "from_numpy", "(", "train_adv_labels", ")", "\n", "train_img_gt_labels", "=", "torch", ".", "from_numpy", "(", "train_img_gt_labels", ")", "\n", "task_positive_label", "=", "torch", ".", "Tensor", "(", "[", "task_positive_label", "]", ")", ".", "long", "(", ")", ".", "view", "(", "1", ",", ")", "\n", "# support_images,support_gt_labels, support_binary_labels, query_images, query_gt_labels, query_binary_labels", "\n", "return", "task_train_ims", ",", "train_img_gt_labels", ",", "train_adv_labels", ",", "task_positive_label", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_only_support_dataset.MetaTaskDatasetOnlySupport.__len__": [[276, 278], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "all_tasks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.DNN_adversary_dataset.AdversaryDataset.__init__": [[14, 62], ["re.compile", "lru.LRU", "collections.defaultdict", "glob.glob", "DNN_adversary_dataset.AdversaryDataset.img_label_list.extend", "re.compile.match", "re.compile.match.group", "numpy.load", "print", "DNN_adversary_dataset.AdversaryDataset.img_label_list.extend", "DNN_adversary_dataset.AdversaryDataset.img_label_list.extend", "os.path.basename", "numpy.arange", "DNN_adversary_dataset.AdversaryDataset.img_label_dict[].append", "random.sample", "numpy.where", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root_path", ",", "train", ",", "protocol", ",", "META_ATTACKER_PART_I", ",", "META_ATTACKER_PART_II", ",", "balance", ",", "use_cache", "=", "True", ")", ":", "\n", "        ", "self", ".", "root_path", "=", "root_path", "\n", "self", ".", "use_cache", "=", "use_cache", "\n", "filter_str", "=", "\"train\"", "\n", "if", "not", "train", ":", "\n", "            ", "filter_str", "=", "\"test\"", "\n", "", "extract_pattern", "=", "re", ".", "compile", "(", "\"(.*?)_untargeted.*\"", ")", "\n", "self", ".", "cache", "=", "LRU", "(", "16", ")", "\n", "self", ".", "img_label_list", "=", "[", "]", "\n", "self", ".", "img_label_dict", "=", "defaultdict", "(", "list", ")", "\n", "for", "npz_path", "in", "glob", ".", "glob", "(", "root_path", "+", "\"/*{}.npz\"", ".", "format", "(", "filter_str", ")", ")", ":", "\n", "\n", "            ", "ma", "=", "extract_pattern", ".", "match", "(", "os", ".", "path", ".", "basename", "(", "npz_path", ")", ")", "\n", "adv_name", "=", "ma", ".", "group", "(", "1", ")", "\n", "if", "protocol", "==", "SPLIT_DATA_PROTOCOL", ".", "TRAIN_I_TEST_II", "and", "train", ":", "\n", "                ", "if", "adv_name", "not", "in", "META_ATTACKER_PART_I", ":", "\n", "                    ", "continue", "\n", "", "", "elif", "protocol", "==", "SPLIT_DATA_PROTOCOL", ".", "TRAIN_II_TEST_I", "and", "train", ":", "\n", "                ", "if", "adv_name", "not", "in", "META_ATTACKER_PART_II", ":", "\n", "                    ", "continue", "\n", "", "", "elif", "protocol", "==", "SPLIT_DATA_PROTOCOL", ".", "TRAIN_II_TEST_I", "and", "not", "train", ":", "\n", "                ", "if", "adv_name", "not", "in", "META_ATTACKER_PART_I", ":", "\n", "                    ", "continue", "\n", "", "", "elif", "protocol", "==", "SPLIT_DATA_PROTOCOL", ".", "TRAIN_I_TEST_II", "and", "not", "train", ":", "\n", "                ", "if", "adv_name", "not", "in", "META_ATTACKER_PART_II", ":", "\n", "                    ", "continue", "\n", "\n", "", "", "data", "=", "np", ".", "load", "(", "npz_path", ")", "\n", "adv_pred", "=", "data", "[", "\"adv_pred\"", "]", "\n", "gt_label", "=", "data", "[", "\"gt_label\"", "]", "\n", "\n", "if", "adv_name", "==", "\"clean\"", ":", "\n", "                ", "adv_label", "=", "1", "\n", "adv_images", "=", "data", "[", "\"adv_images\"", "]", "\n", "if", "self", ".", "use_cache", ":", "\n", "                    ", "self", ".", "cache", "[", "npz_path", "]", "=", "adv_images", "\n", "", "indexes", "=", "np", ".", "arange", "(", "adv_images", ".", "shape", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                ", "adv_label", "=", "0", "\n", "indexes", "=", "np", ".", "where", "(", "adv_pred", "!=", "gt_label", ")", "[", "0", "]", "\n", "", "for", "index", "in", "indexes", ":", "\n", "                ", "self", ".", "img_label_dict", "[", "adv_label", "]", ".", "append", "(", "(", "npz_path", ",", "index", ",", "adv_label", ")", ")", "\n", "", "print", "(", "\"{} done\"", ".", "format", "(", "npz_path", ")", ")", "\n", "", "self", ".", "img_label_list", ".", "extend", "(", "self", ".", "img_label_dict", "[", "1", "]", ")", "\n", "if", "balance", ":", "\n", "            ", "self", ".", "img_label_list", ".", "extend", "(", "random", ".", "sample", "(", "self", ".", "img_label_dict", "[", "0", "]", ",", "len", "(", "self", ".", "img_label_dict", "[", "1", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "img_label_list", ".", "extend", "(", "self", ".", "img_label_dict", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.DNN_adversary_dataset.AdversaryDataset.__len__": [[63, 65], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "img_label_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.DNN_adversary_dataset.AdversaryDataset.__getitem__": [[67, 81], ["numpy.transpose", "numpy.load"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "npz_path", ",", "index", ",", "label", "=", "self", ".", "img_label_list", "[", "item", "]", "\n", "if", "self", ".", "use_cache", "and", "npz_path", "in", "self", ".", "cache", ":", "\n", "            ", "adv_images", "=", "self", ".", "cache", "[", "npz_path", "]", "\n", "", "else", ":", "\n", "            ", "data", "=", "np", ".", "load", "(", "npz_path", ")", "\n", "adv_images", "=", "data", "[", "\"adv_images\"", "]", "# 10000,32,32,3", "\n", "if", "self", ".", "use_cache", ":", "\n", "                ", "self", ".", "cache", "[", "npz_path", "]", "=", "adv_images", "\n", "\n", "", "", "adv_image", "=", "adv_images", "[", "index", "]", "\n", "adv_image", "=", "np", ".", "transpose", "(", "adv_image", ",", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "\n", "return", "adv_image", ",", "label", "\n", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_dataset.MetaTaskDataset.__init__": [[22, 96], ["glob.glob", "glob.glob", "meta_task_dataset.MetaTaskDataset.store_data_per_task", "numpy.prod", "os.listdir", "os.listdir", "os.path.isdir", "os.path.isdir", "folder.endswith", "folder.endswith", "os.path.join", "metatrain_folders.append", "os.path.join", "metaval_folders.append", "folder.endswith", "folder.endswith", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_dataset.MetaTaskDataset.store_data_per_task"], ["def", "__init__", "(", "self", ",", "num_tot_tasks", ",", "num_classes", ",", "num_support", ",", "num_query", ",", "\n", "dataset", ",", "is_train", ",", "load_mode", ",", "protocol", ",", "no_random_way", ",", "adv_arch", ",", "fetch_attack_name", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            num_samples_per_class: num samples to generate \"per class\" in one batch\n            batch_size: size of meta batch size (e.g. number of functions)\n        \"\"\"", "\n", "self", ".", "num_samples_per_class", "=", "num_support", "+", "num_query", "\n", "self", ".", "num_classes", "=", "num_classes", "# e.g. 5-way", "\n", "self", ".", "img_size", "=", "IMAGE_SIZE", "[", "dataset", "]", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "dim_input", "=", "np", ".", "prod", "(", "self", ".", "img_size", ")", "*", "IN_CHANNELS", "[", "dataset", "]", "\n", "self", ".", "dim_output", "=", "self", ".", "num_classes", "\n", "self", ".", "train", "=", "is_train", "# \u533a\u5206\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6", "\n", "self", ".", "no_random_way", "=", "no_random_way", "\n", "self", ".", "num_support", "=", "num_support", "\n", "self", ".", "num_query", "=", "num_query", "\n", "self", ".", "fetch_attack_name", "=", "fetch_attack_name", "\n", "if", "not", "self", ".", "train", ":", "\n", "            ", "assert", "no_random_way", ",", "\"In test mode, we must specify the fixed way setting!\"", "\n", "", "if", "protocol", "==", "SPLIT_DATA_PROTOCOL", ".", "TRAIN_I_TEST_II", ":", "\n", "            ", "train_sub_folder", "=", "\"I\"", "\n", "test_sub_folder", "=", "\"II\"", "\n", "", "elif", "protocol", "==", "SPLIT_DATA_PROTOCOL", ".", "TRAIN_II_TEST_I", ":", "\n", "            ", "train_sub_folder", "=", "\"II\"", "\n", "test_sub_folder", "=", "\"I\"", "\n", "", "elif", "protocol", "==", "SPLIT_DATA_PROTOCOL", ".", "TRAIN_ALL_TEST_ALL", ":", "\n", "            ", "train_sub_folder", "=", "\"*\"", "\n", "test_sub_folder", "=", "\"*\"", "\n", "\n", "", "root_folder", "=", "TASK_DATA_ROOT", "[", "dataset", "]", "[", "adv_arch", "]", "\n", "metatrain_folder", "=", "root_folder", "+", "'/train/'", "+", "train_sub_folder", "\n", "metaval_folder", "=", "root_folder", "+", "\"/test/\"", "+", "test_sub_folder", "\n", "\n", "metatrain_folders", "=", "[", "]", "\n", "metaval_folders", "=", "[", "]", "\n", "for", "root_folder", "in", "glob", ".", "glob", "(", "metatrain_folder", ")", ":", "\n", "            ", "for", "label", "in", "os", ".", "listdir", "(", "root_folder", ")", ":", "# label = ClassID_attackIDX", "\n", "                ", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "label", ")", ")", ":", "\n", "                    ", "metatrain_folders", ".", "append", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "label", ")", ")", "\n", "", "", "", "for", "root_folder", "in", "glob", ".", "glob", "(", "metaval_folder", ")", ":", "\n", "            ", "for", "label", "in", "os", ".", "listdir", "(", "root_folder", ")", ":", "\n", "                ", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "label", ")", ")", ":", "\n", "                    ", "metaval_folders", ".", "append", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "label", ")", ")", "\n", "# get the positive and negative folder if num_classes is 2", "\n", "", "", "", "self", ".", "metatrain_folders_p", "=", "[", "folder", "for", "folder", "in", "metatrain_folders", "if", "folder", ".", "endswith", "(", "'_1'", ")", "]", "# 1 \u8868\u793a\u5e72\u51c0\u771f\u5b9e\u56fe\u7247", "\n", "self", ".", "metatrain_folders_n", "=", "[", "folder", "for", "folder", "in", "metatrain_folders", "if", "not", "folder", ".", "endswith", "(", "'_1'", ")", "]", "\n", "self", ".", "metaval_folders_p", "=", "[", "folder", "for", "folder", "in", "metaval_folders", "if", "folder", ".", "endswith", "(", "'_1'", ")", "]", "# \u771f\u5b9e\u56fe\u7247", "\n", "self", ".", "metaval_folders_n", "=", "[", "folder", "for", "folder", "in", "metaval_folders", "if", "not", "folder", ".", "endswith", "(", "'_1'", ")", "]", "\n", "\n", "self", ".", "metatrain_folders", "=", "metatrain_folders", "\n", "self", ".", "metaval_folders", "=", "metaval_folders", "\n", "\n", "self", ".", "num_tot_trn_tasks", "=", "num_tot_tasks", "\n", "self", ".", "num_tot_val_batches", "=", "1000", "\n", "num_tot_tasks", "=", "self", ".", "num_tot_trn_tasks", "\n", "trn_or_test_str", "=", "\"train\"", "\n", "if", "not", "is_train", ":", "\n", "            ", "trn_or_test_str", "=", "\"test\"", "\n", "num_tot_tasks", "=", "self", ".", "num_tot_val_batches", "\n", "\n", "", "if", "self", ".", "fetch_attack_name", ":", "# \u7531\u4e8e\u5ba1\u7a3f\u4eba\u8981\u6c42\u52a0\u4e00\u4e2a\u6bcf\u4e2a\u653b\u51fb\u65b9\u6cd5\u5206\u522b\u7edf\u8ba1", "\n", "            ", "self", ".", "task_dump_txt_path", "=", "\"{}/task/{}_{}/{}/{}_{}_tot_num_tasks_{}_way_{}_shot_{}_query_{}.pkl\"", ".", "format", "(", "PY_ROOT", ",", "protocol", ",", "\n", "dataset", ",", "adv_arch", ",", "trn_or_test_str", ",", "\n", "dataset", ",", "num_tot_tasks", ",", "num_classes", ",", "\n", "num_support", ",", "num_query", ")", "\n", "", "else", ":", "# # \u7531\u4e8e\u5ba1\u7a3f\u4eba\u8981\u6c42\u52a0\u4e00\u4e2a\u6bcf\u4e2a\u653b\u51fb\u65b9\u6cd5\u5206\u522b\u7edf\u8ba1,\u4f46\u4ee5\u524d\u505a\u597d\u7684task\u5b58\u653e\u5728\u8fd9\u4e2a\u8def\u5f84\u4e0d\u8981\u5220\u6389", "\n", "            ", "self", ".", "task_dump_txt_path", "=", "\"{}/task/no_attack_name_stats/{}_{}/{}/{}_{}_tot_num_tasks_{}_way_{}_shot_{}_query_{}.pkl\"", ".", "format", "(", "\n", "PY_ROOT", ",", "protocol", ",", "\n", "dataset", ",", "adv_arch", ",", "trn_or_test_str", ",", "\n", "dataset", ",", "num_tot_tasks", ",", "num_classes", ",", "\n", "num_support", ",", "num_query", ")", "\n", "\n", "", "self", ".", "store_data_per_task", "(", "load_mode", ",", "self", ".", "task_dump_txt_path", ",", "train", "=", "is_train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_dataset.MetaTaskDataset.store_data_per_task": [[98, 151], ["collections.defaultdict", "range", "meta_task_dataset.MetaTaskDataset.dump_task", "os.path.exists", "random.sample", "random.sample", "random.shuffle", "open", "pickle.load", "print", "meta_task_dataset.MetaTaskDataset.get_image_paths", "meta_task_dataset.MetaTaskDataset.all_tasks[].append", "meta_task_dataset.MetaTaskDataset.all_tasks[].append", "random.sample", "random.sample", "random.shuffle", "meta_task_dataset.MetaTaskDataset.get_image_paths"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_dataset.MetaTaskDataset.dump_task", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_dataset.MetaTaskDataset.get_image_paths", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_dataset.MetaTaskDataset.get_image_paths"], ["", "def", "store_data_per_task", "(", "self", ",", "load_mode", ",", "task_dump_txt_path", ",", "train", "=", "True", ")", ":", "\n", "# if load_mode == LOAD_TASK_MODE.LOAD:", "\n", "#     assert os.path.exists(task_dump_txt_path), \"LOAD_TASK_MODE but do not exits task path: {} for load\".format(task_dump_txt_path)", "\n", "        ", "self", ".", "all_tasks", "=", "defaultdict", "(", "list", ")", "\n", "if", "load_mode", "==", "LOAD_TASK_MODE", ".", "LOAD", "and", "os", ".", "path", ".", "exists", "(", "task_dump_txt_path", ")", ":", "\n", "# if os.path.exists(task_dump_txt_path):", "\n", "            ", "with", "open", "(", "task_dump_txt_path", ",", "\"rb\"", ")", "as", "file_obj", ":", "\n", "                ", "self", ".", "all_tasks", "=", "pickle", ".", "load", "(", "file_obj", ")", "\n", "", "return", "\n", "\n", "", "if", "train", ":", "\n", "            ", "folder_p", "=", "self", ".", "metatrain_folders_p", "\n", "folder_n", "=", "self", ".", "metatrain_folders_n", "\n", "num_total_batches", "=", "self", ".", "num_tot_trn_tasks", "\n", "", "else", ":", "\n", "            ", "folder_p", "=", "self", ".", "metaval_folders_p", "\n", "folder_n", "=", "self", ".", "metaval_folders_n", "\n", "num_total_batches", "=", "self", ".", "num_tot_val_batches", "\n", "\n", "", "for", "i", "in", "range", "(", "num_total_batches", ")", ":", "# \u603b\u5171\u7684\u8bad\u7ec3\u4efb\u52a1\u4e2a\u6570\uff0c\u6bcf\u6b21\u8fed\u4ee3\u90fd\u4ece\u8fd9\u4e9b\u4efb\u52a1\u53bb\u53d6", "\n", "            ", "if", "i", "%", "100", "==", "0", ":", "\n", "                ", "print", "(", "\"store {} tasks\"", ".", "format", "(", "i", ")", ")", "\n", "", "p_folder", "=", "random", ".", "sample", "(", "folder_p", ",", "1", ")", "# \u53ea\u6709\u4e00\u4e2away\u662f\u6b63\u6837\u672c", "\n", "n_folder", "=", "random", ".", "sample", "(", "folder_n", ",", "self", ".", "num_classes", "-", "1", ")", "# \u5269\u4f59\u76841-way\u90fd\u662f\u8d1f\u6837\u672c", "\n", "task_folders", "=", "p_folder", "+", "n_folder", "# \u51715\u4e2a\u6587\u4ef6\u5939\u8868\u793a5-way", "\n", "\n", "random", ".", "shuffle", "(", "task_folders", ")", "# \u4ece\u8fd9\u4e00\u53e5\u53ef\u4ee5\u770b\u51fa, \u6bcf\u4e2atask\u4e3atask_folders\u968f\u673a\u5b89\u6392\u7684class id\u6beb\u65e0\u89c4\u5f8b\u53ef\u8a00. \u6240\u4ee5no_random_way\u4e5f\u662f\u4f5c\u7528\u5728\u8fd9\u91cc", "\n", "# \u4e3a\u6bcf\u4e00\u7c7bsample\u51faself.num_samples_per_class\u4e2a\u6837\u672c", "\n", "# nb_samples = self.num_samples_per_class = support num + query num", "\n", "try", ":", "\n", "                ", "supp_lbs_and_img_paths", ",", "query_lbs_and_img_paths", ",", "positive_label", "=", "self", ".", "get_image_paths", "(", "task_folders", ",", "\n", "self", ".", "num_support", ",", "self", ".", "num_query", ",", "is_test", "=", "not", "train", ")", "# task_folders\u5305\u542b\u6b63\u8d1f\u6837\u672c\u7684\u5206\u5e03\uff0c\u4f46\u662f\u5177\u4f53support\u53d6\u51e0\u4e2a\uff0cquery\u53d6\u51e0\u4e2a", "\n", "", "except", "IOError", ":", "# \u91cd\u6765\u4e00\u904d sample, \u8fd9\u4e2away\u653e\u5f03", "\n", "                ", "p_folder", "=", "random", ".", "sample", "(", "folder_p", ",", "1", ")", "\n", "n_folder", "=", "random", ".", "sample", "(", "folder_n", ",", "self", ".", "num_classes", "-", "1", ")", "\n", "task_folders", "=", "p_folder", "+", "n_folder", "\n", "random", ".", "shuffle", "(", "task_folders", ")", "\n", "supp_lbs_and_img_paths", ",", "query_lbs_and_img_paths", ",", "positive_label", "=", "self", ".", "get_image_paths", "(", "task_folders", ",", "\n", "self", ".", "num_support", ",", "\n", "self", ".", "num_query", ",", "\n", "is_test", "=", "not", "train", ")", "\n", "\n", "", "for", "supp_img_gt_label", ",", "supp_way_label", ",", "supp_adv_label", ",", "adversary", ",", "supp_path", "in", "supp_lbs_and_img_paths", ":", "\n", "                ", "self", ".", "all_tasks", "[", "i", "]", ".", "append", "(", "{", "\"task_idx\"", ":", "i", ",", "\"pos_label\"", ":", "positive_label", ",", "\"img_path\"", ":", "supp_path", ",", "\n", "\"img_gt_label\"", ":", "supp_img_gt_label", ",", "\"way_label\"", ":", "supp_way_label", ",", "\n", "\"adv_label\"", ":", "supp_adv_label", ",", "\"adversary\"", ":", "adversary", ",", "\"type\"", ":", "\"support\"", "}", ")", "\n", "\n", "", "for", "query_img_gt_label", ",", "query_way_label", ",", "query_adv_label", ",", "adversary", ",", "query_path", "in", "query_lbs_and_img_paths", ":", "\n", "                ", "self", ".", "all_tasks", "[", "i", "]", ".", "append", "(", "{", "\"task_idx\"", ":", "i", ",", "\"pos_label\"", ":", "positive_label", ",", "\"img_path\"", ":", "query_path", ",", "\n", "\"img_gt_label\"", ":", "query_img_gt_label", ",", "\"way_label\"", ":", "query_way_label", ",", "\n", "\"adv_label\"", ":", "query_adv_label", ",", "\"adversary\"", ":", "adversary", ",", "\"type\"", ":", "\"query\"", "}", ")", "\n", "\n", "", "", "self", ".", "dump_task", "(", "self", ".", "all_tasks", ",", "task_dump_txt_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_dataset.MetaTaskDataset.dump_task": [[152, 156], ["os.makedirs", "os.path.dirname", "open", "pickle.dump"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.dump"], ["", "def", "dump_task", "(", "self", ",", "all_tasks", ",", "task_dump_txt_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "task_dump_txt_path", ")", ",", "exist_ok", "=", "True", ")", "\n", "with", "open", "(", "task_dump_txt_path", ",", "\"wb\"", ")", "as", "file_obj", ":", "\n", "            ", "pickle", ".", "dump", "(", "all_tasks", ",", "file_obj", ",", "protocol", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_dataset.MetaTaskDataset.chunk": [[158, 169], ["list", "random.shuffle", "range", "len", "leftovers.pop"], "methods", ["None"], ["", "", "def", "chunk", "(", "self", ",", "xs", ",", "n", ")", ":", "\n", "        ", "ys", "=", "list", "(", "xs", ")", "\n", "random", ".", "shuffle", "(", "ys", ")", "\n", "size", "=", "len", "(", "ys", ")", "//", "n", "\n", "leftovers", "=", "ys", "[", "size", "*", "n", ":", "]", "\n", "for", "c", "in", "range", "(", "n", ")", ":", "\n", "            ", "if", "leftovers", ":", "\n", "                ", "extra", "=", "[", "leftovers", ".", "pop", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "extra", "=", "[", "]", "\n", "", "yield", "ys", "[", "c", "*", "size", ":", "(", "c", "+", "1", ")", "*", "size", "]", "+", "extra", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_dataset.MetaTaskDataset.get_image_paths": [[170, 240], ["re.compile", "enumerate", "orig_path.endswith", "numpy.arange().tolist", "random.sample", "open", "int", "set", "set", "random.sample", "re.compile.match", "int", "int", "support_images.append", "re.compile.match", "int", "int", "query_images.append", "random.sample", "file_obj.read().strip", "numpy.arange", "print", "re.compile.match.group", "re.compile.match.group", "re.compile.match.group", "re.compile.match.group", "open", "int", "IOError", "IOError", "numpy.arange().tolist", "re.compile.match", "int", "int", "label_images.append", "file_obj.read().strip", "re.compile.match.group", "re.compile.match.group", "file_obj.read", "numpy.arange", "file_obj.read"], "methods", ["None"], ["", "", "def", "get_image_paths", "(", "self", ",", "paths", ",", "num_support", ",", "num_query", ",", "is_test", ")", ":", "\n", "        ", "support_images", "=", "[", "]", "\n", "query_images", "=", "[", "]", "\n", "extract_gt_label_pattern", "=", "re", ".", "compile", "(", "\".*(\\d+)_(\\d+).*\"", ")", "\n", "for", "i", ",", "orig_path", "in", "enumerate", "(", "paths", ")", ":", "# for\u5faa\u73af\u4e00\u4e2apath\u5c31\u8868\u793a\u4e00\u4e2away", "\n", "            ", "if", "orig_path", ".", "endswith", "(", "\"_1\"", ")", ":", "\n", "                ", "positive_label", "=", "i", "\n", "", "if", "not", "is_test", ":", "\n", "                ", "path", "=", "orig_path", "\n", "npy_path", "=", "orig_path", "+", "\"/train.npy\"", "\n", "with", "open", "(", "path", "+", "\"/\"", "+", "\"count.txt\"", ",", "\"r\"", ")", "as", "file_obj", ":", "\n", "                    ", "N", "=", "int", "(", "file_obj", ".", "read", "(", ")", ".", "strip", "(", ")", ")", "\n", "", "all_index", "=", "np", ".", "arange", "(", "N", ")", ".", "tolist", "(", ")", "\n", "support_idx", "=", "random", ".", "sample", "(", "all_index", ",", "num_support", ")", "\n", "rest_idx", "=", "set", "(", "all_index", ")", "-", "set", "(", "support_idx", ")", "\n", "try", ":", "\n", "                    ", "query_idx", "=", "random", ".", "sample", "(", "rest_idx", ",", "num_query", ")", "\n", "", "except", "ValueError", ":", "\n", "                    ", "print", "(", "\"error in sample from {} N = {} sampling {}\"", ".", "format", "(", "path", ",", "N", ",", "num_query", ")", ")", "\n", "raise", "\n", "", "for", "idx", "in", "support_idx", ":", "\n", "                    ", "whole_path", "=", "\"{}#{}\"", ".", "format", "(", "npy_path", ",", "idx", ")", "\n", "ma", "=", "extract_gt_label_pattern", ".", "match", "(", "whole_path", ")", "\n", "img_gt_label", "=", "int", "(", "ma", ".", "group", "(", "1", ")", ")", "\n", "adv_label", "=", "int", "(", "ma", ".", "group", "(", "2", ")", ")", "\n", "adversary", "=", "META_ATTACKER_INDEX", "[", "adv_label", "-", "1", "]", "\n", "if", "adv_label", "!=", "1", ":", "\n", "                        ", "adv_label", "=", "0", "\n", "", "way_label", "=", "i", "\n", "support_images", ".", "append", "(", "(", "img_gt_label", ",", "way_label", ",", "adv_label", ",", "adversary", ",", "whole_path", ")", ")", "\n", "", "for", "idx", "in", "query_idx", ":", "\n", "                    ", "whole_path", "=", "\"{}#{}\"", ".", "format", "(", "npy_path", ",", "idx", ")", "\n", "ma", "=", "extract_gt_label_pattern", ".", "match", "(", "whole_path", ")", "\n", "img_gt_label", "=", "int", "(", "ma", ".", "group", "(", "1", ")", ")", "\n", "adv_label", "=", "int", "(", "ma", ".", "group", "(", "2", ")", ")", "\n", "adversary", "=", "META_ATTACKER_INDEX", "[", "adv_label", "-", "1", "]", "\n", "if", "adv_label", "!=", "1", ":", "\n", "                        ", "adv_label", "=", "0", "\n", "", "way_label", "=", "i", "\n", "query_images", ".", "append", "(", "(", "img_gt_label", ",", "way_label", ",", "adv_label", ",", "adversary", ",", "whole_path", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "sq", "in", "[", "\"support\"", ",", "\"query\"", "]", ":", "\n", "                    ", "path", "=", "orig_path", "+", "\"/{}\"", ".", "format", "(", "sq", ")", "\n", "with", "open", "(", "path", "+", "\"/\"", "+", "\"count.txt\"", ",", "\"r\"", ")", "as", "file_obj", ":", "\n", "                        ", "N", "=", "int", "(", "file_obj", ".", "read", "(", ")", ".", "strip", "(", ")", ")", "\n", "", "if", "sq", "==", "\"support\"", "and", "N", "<", "num_support", ":", "\n", "                        ", "raise", "IOError", "(", "'please check that whether each class contains enough images for the support set,'", "\n", "'the class path is :  '", "+", "path", ")", "\n", "", "if", "sq", "==", "\"query\"", "and", "N", "<", "num_query", ":", "\n", "                        ", "raise", "IOError", "(", "'please check that whether each class contains enough images for the query set,'", "\n", "'the class path is :  '", "+", "path", ")", "\n", "", "if", "sq", "==", "\"support\"", ":", "\n", "                        ", "num", "=", "num_support", "\n", "label_images", "=", "support_images", "\n", "", "elif", "sq", "==", "\"query\"", ":", "\n", "                        ", "num", "=", "num_query", "\n", "label_images", "=", "query_images", "\n", "", "sampled_images", "=", "random", ".", "sample", "(", "np", ".", "arange", "(", "N", ")", ".", "tolist", "(", ")", ",", "num", ")", "# support\u548cquery\u4e0d\u80fd\u6709\u4ea4\u96c6", "\n", "for", "idx", "in", "sampled_images", ":", "\n", "                        ", "whole_path", "=", "\"{}/{}.npy#{}\"", ".", "format", "(", "path", ",", "sq", ",", "idx", ")", "\n", "ma", "=", "extract_gt_label_pattern", ".", "match", "(", "whole_path", ")", "\n", "img_gt_label", "=", "int", "(", "ma", ".", "group", "(", "1", ")", ")", "\n", "adv_label", "=", "int", "(", "ma", ".", "group", "(", "2", ")", ")", "\n", "adversary", "=", "META_ATTACKER_INDEX", "[", "adv_label", "-", "1", "]", "# clean = 1,\u6240\u4ee5\u4ece1 \u5f00\u59cb -1\uff0c\u5219\u4ece0\u5f00\u59cb", "\n", "if", "adv_label", "!=", "1", ":", "\n", "                            ", "adv_label", "=", "0", "# real image == 1, adv image == 0", "\n", "", "way_label", "=", "i", "\n", "label_images", ".", "append", "(", "(", "img_gt_label", ",", "way_label", ",", "adv_label", ",", "adversary", ",", "whole_path", ")", ")", "\n", "\n", "", "", "", "", "return", "support_images", ",", "query_images", ",", "positive_label", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_dataset.MetaTaskDataset.__getitem__": [[241, 333], ["random.shuffle", "random.shuffle", "numpy.concatenate", "numpy.array", "numpy.array", "numpy.concatenate", "numpy.array", "numpy.array", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.Tensor().long().view", "list", "set", "len", "config.META_ATTACKER_INDEX.index", "int", "open", "numpy.memmap().copy", "open.close", "numpy.transpose.reshape", "numpy.transpose", "numpy.transpose.reshape", "image_list.append", "adv_label_list.append", "img_gt_label_list.append", "int", "open", "numpy.memmap().copy", "open.close", "numpy.transpose.reshape", "numpy.transpose", "numpy.transpose.reshape", "image_list.append", "adv_label_list.append", "img_gt_label_list.append", "filter", "len", "print", "int", "int", "int", "int", "int", "int", "torch.Tensor().long", "list", "image_path.rindex", "numpy.memmap", "image_path.rindex", "numpy.memmap", "torch.Tensor", "image_path.rindex", "image_path.rindex"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.close", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.close"], ["", "def", "__getitem__", "(", "self", ",", "task_index", ")", ":", "\n", "        ", "task_data_list", "=", "self", ".", "all_tasks", "[", "task_index", "]", "#\u53d6\u51fa\u8be5task\u76842-way\u7684\u6240\u6709\u6570\u636e", "\n", "\n", "train_files", "=", "[", "data_json", "for", "data_json", "in", "task_data_list", "if", "data_json", "[", "\"type\"", "]", "==", "\"support\"", "]", "# 2-way, N-shot", "\n", "test_files", "=", "[", "data_json", "for", "data_json", "in", "task_data_list", "if", "data_json", "[", "\"type\"", "]", "==", "\"query\"", "]", "\n", "\n", "if", "self", ".", "fetch_attack_name", ":", "\n", "            ", "adversary_list", "=", "list", "(", "filter", "(", "lambda", "data_json", ":", "data_json", "[", "\"adv_label\"", "]", "==", "0", ",", "task_data_list", ")", ")", "# adv_label = 0\u8868\u793a\u662f\u5bf9\u6297\u6837\u672c", "\n", "adversary_set", "=", "set", "(", "e", "[", "\"adversary\"", "]", "for", "e", "in", "adversary_list", ")", "# adversary\u5b58\u50a8\u7684\u662f\u5b57\u7b26\u4e32", "\n", "assert", "len", "(", "adversary_set", ")", "==", "1", ",", "len", "(", "adversary_set", ")", "\n", "adversary_index", "=", "META_ATTACKER_INDEX", ".", "index", "(", "list", "(", "adversary_set", ")", "[", "0", "]", ")", "\n", "\n", "", "try", ":", "\n", "            ", "task_positive_label", "=", "train_files", "[", "0", "]", "[", "\"pos_label\"", "]", "\n", "", "except", "IndexError", ":", "\n", "            ", "print", "(", "\"task :{}\"", ".", "format", "(", "task_index", ")", ")", "\n", "raise", "\n", "", "random", ".", "shuffle", "(", "train_files", ")", "\n", "random", ".", "shuffle", "(", "test_files", ")", "\n", "image_list", "=", "[", "]", "\n", "adv_label_list", "=", "[", "]", "\n", "img_gt_label_list", "=", "[", "]", "\n", "for", "data_json", "in", "train_files", ":", "# adv_type_label, img_gt_label, whole_path", "\n", "            ", "img_gt_label", ",", "image_path", "=", "int", "(", "data_json", "[", "\"img_gt_label\"", "]", ")", ",", "data_json", "[", "\"img_path\"", "]", "\n", "if", "self", ".", "no_random_way", ":", "\n", "                ", "adv_label", "=", "int", "(", "data_json", "[", "\"adv_label\"", "]", ")", "\n", "", "else", ":", "\n", "                ", "adv_label", "=", "int", "(", "data_json", "[", "\"way_label\"", "]", ")", "\n", "\n", "", "image_idx", "=", "int", "(", "image_path", "[", "image_path", ".", "rindex", "(", "\"#\"", ")", "+", "1", ":", "]", ")", "\n", "image_path", "=", "image_path", "[", ":", "image_path", ".", "rindex", "(", "\"#\"", ")", "]", "\n", "fobj", "=", "open", "(", "image_path", ",", "\"rb\"", ")", "\n", "im", "=", "np", ".", "memmap", "(", "fobj", ",", "dtype", "=", "'float32'", ",", "mode", "=", "'r'", ",", "shape", "=", "(", "\n", "1", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "0", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "1", "]", ",", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ")", ",", "\n", "offset", "=", "image_idx", "*", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "0", "]", "*", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "1", "]", "*", "IN_CHANNELS", "[", "\n", "self", ".", "dataset", "]", "*", "32", "//", "8", ")", ".", "copy", "(", ")", "\n", "fobj", ".", "close", "(", ")", "\n", "im", "=", "im", ".", "reshape", "(", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "0", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "1", "]", ",", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ")", "\n", "\n", "im", "=", "np", ".", "transpose", "(", "im", ",", "axes", "=", "(", "2", ",", "0", ",", "1", ")", ")", "# C,H,W", "\n", "im2", "=", "im", ".", "reshape", "(", "self", ".", "dim_input", ")", "\n", "image_list", ".", "append", "(", "im2", "[", "np", ".", "newaxis", ",", ":", "]", ")", "# \u52a0\u4e00\u4e2a\u65b0\u7684\u7ef4\u5ea6", "\n", "adv_label_list", ".", "append", "(", "adv_label", ")", "\n", "img_gt_label_list", ".", "append", "(", "img_gt_label", ")", "\n", "\n", "", "task_train_ims", "=", "np", ".", "concatenate", "(", "image_list", ",", "axis", "=", "0", ")", "# N, 3072", "\n", "train_adv_labels", "=", "np", ".", "array", "(", "adv_label_list", ")", "\n", "train_img_gt_labels", "=", "np", ".", "array", "(", "img_gt_label_list", ")", "\n", "\n", "image_list", "=", "[", "]", "\n", "adv_label_list", "=", "[", "]", "\n", "img_gt_label_list", "=", "[", "]", "\n", "for", "data_json", "in", "test_files", ":", "# adv_type_label, img_gt_label, whole_path", "\n", "            ", "img_gt_label", ",", "image_path", "=", "int", "(", "data_json", "[", "\"img_gt_label\"", "]", ")", ",", "data_json", "[", "\"img_path\"", "]", "\n", "if", "self", ".", "no_random_way", ":", "\n", "                ", "adv_label", "=", "int", "(", "data_json", "[", "\"adv_label\"", "]", ")", "\n", "", "else", ":", "\n", "                ", "adv_label", "=", "int", "(", "data_json", "[", "\"way_label\"", "]", ")", "\n", "\n", "", "image_idx", "=", "int", "(", "image_path", "[", "image_path", ".", "rindex", "(", "\"#\"", ")", "+", "1", ":", "]", ")", "\n", "image_path", "=", "image_path", "[", ":", "image_path", ".", "rindex", "(", "\"#\"", ")", "]", "\n", "fobj", "=", "open", "(", "image_path", ",", "\"rb\"", ")", "\n", "im", "=", "np", ".", "memmap", "(", "fobj", ",", "dtype", "=", "'float32'", ",", "mode", "=", "'r'", ",", "shape", "=", "(", "\n", "1", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "0", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "1", "]", ",", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ")", ",", "\n", "offset", "=", "image_idx", "*", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "0", "]", "*", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "1", "]", "*", "IN_CHANNELS", "[", "\n", "self", ".", "dataset", "]", "*", "32", "//", "8", ")", ".", "copy", "(", ")", "\n", "fobj", ".", "close", "(", ")", "\n", "im", "=", "im", ".", "reshape", "(", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "0", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "1", "]", ",", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ")", "\n", "\n", "im", "=", "np", ".", "transpose", "(", "im", ",", "axes", "=", "(", "2", ",", "0", ",", "1", ")", ")", "# C,H,W", "\n", "im2", "=", "im", ".", "reshape", "(", "self", ".", "dim_input", ")", "\n", "image_list", ".", "append", "(", "im2", "[", "np", ".", "newaxis", ",", ":", "]", ")", "# \u52a0\u4e00\u4e2a\u65b0\u7684\u7ef4\u5ea6", "\n", "adv_label_list", ".", "append", "(", "adv_label", ")", "\n", "img_gt_label_list", ".", "append", "(", "img_gt_label", ")", "\n", "\n", "", "task_test_ims", "=", "np", ".", "concatenate", "(", "image_list", ",", "axis", "=", "0", ")", "# N C H W", "\n", "test_adv_labels", "=", "np", ".", "array", "(", "adv_label_list", ")", "\n", "test_img_gt_labels", "=", "np", ".", "array", "(", "img_gt_label_list", ")", "\n", "task_train_ims", "=", "torch", ".", "from_numpy", "(", "task_train_ims", ")", "\n", "train_adv_labels", "=", "torch", ".", "from_numpy", "(", "train_adv_labels", ")", "\n", "train_img_gt_labels", "=", "torch", ".", "from_numpy", "(", "train_img_gt_labels", ")", "\n", "task_test_ims", "=", "torch", ".", "from_numpy", "(", "task_test_ims", ")", "\n", "test_adv_labels", "=", "torch", ".", "from_numpy", "(", "test_adv_labels", ")", "\n", "test_img_gt_labels", "=", "torch", ".", "from_numpy", "(", "test_img_gt_labels", ")", "# \u6682\u65f6\u4e0d\u7528\u8fd9\u4e2a", "\n", "task_positive_label", "=", "torch", ".", "Tensor", "(", "[", "task_positive_label", "]", ")", ".", "long", "(", ")", ".", "view", "(", "1", ",", ")", "\n", "# support_images,support_gt_labels, support_binary_labels, query_images, query_gt_labels, query_binary_labels", "\n", "if", "self", ".", "fetch_attack_name", ":", "\n", "            ", "return", "task_train_ims", ",", "train_img_gt_labels", ",", "train_adv_labels", ",", "task_test_ims", ",", "test_img_gt_labels", ",", "test_adv_labels", ",", "adversary_index", ",", "task_positive_label", "\n", "", "else", ":", "\n", "            ", "return", "task_train_ims", ",", "train_img_gt_labels", ",", "train_adv_labels", ",", "task_test_ims", ",", "test_img_gt_labels", ",", "test_adv_labels", ",", "task_positive_label", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.meta_task_dataset.MetaTaskDataset.__len__": [[334, 336], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "all_tasks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.SVHN_dataset.SVHN.__init__": [[6, 20], ["scipy.io.loadmat", "scipy.io.loadmat"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root_path", ",", "train", ",", "transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "root_path", "=", "root_path", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "train_file_path", "=", "root_path", "+", "'/train_32x32.mat'", "\n", "self", ".", "test_file_path", "=", "root_path", "+", "\"/test_32x32.mat\"", "\n", "self", ".", "is_train", "=", "train", "\n", "if", "train", ":", "\n", "            ", "train_data_and_label", "=", "scipy", ".", "io", ".", "loadmat", "(", "self", ".", "train_file_path", ")", "\n", "self", ".", "train_data", "=", "train_data_and_label", "[", "\"X\"", "]", "\n", "self", ".", "train_label", "=", "train_data_and_label", "[", "\"y\"", "]", "\n", "", "else", ":", "\n", "            ", "test_data_and_label", "=", "scipy", ".", "io", ".", "loadmat", "(", "self", ".", "test_file_path", ")", "\n", "self", ".", "test_data", "=", "test_data_and_label", "[", "\"X\"", "]", "\n", "self", ".", "test_label", "=", "test_data_and_label", "[", "\"y\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.SVHN_dataset.SVHN.__len__": [[21, 25], ["len", "len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "is_train", ":", "\n", "            ", "return", "len", "(", "self", ".", "train_label", ")", "\n", "", "return", "len", "(", "self", ".", "test_label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.SVHN_dataset.SVHN.__getitem__": [[26, 36], ["SVHN_dataset.SVHN.transform", "PIL.Image.fromarray", "int"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "if", "self", ".", "is_train", ":", "\n", "            ", "data", "=", "self", ".", "train_data", "[", ":", ",", ":", ",", ":", ",", "item", "]", "\n", "label", "=", "self", ".", "train_label", "[", "item", ",", "0", "]", "\n", "", "else", ":", "\n", "            ", "data", "=", "self", ".", "test_data", "[", ":", ",", ":", ",", ":", ",", "item", "]", "\n", "label", "=", "self", ".", "test_label", "[", "item", ",", "0", "]", "\n", "", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "data", "=", "self", ".", "transform", "(", "Image", ".", "fromarray", "(", "data", ")", ")", "\n", "", "return", "data", ",", "int", "(", "label", ")", "-", "1", "", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.presampled_task_dataset.TaskDatasetForDetector.__init__": [[12, 28], ["re.compile", "open", "json.loads", "image_path_position.split", "re.compile.match", "int", "presampled_task_dataset.TaskDatasetForDetector.data_list.append", "re.compile.match.group", "int"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "img_size", ",", "in_channel", ",", "txt_task_path", ",", "posneg_binary_label", "=", "True", ")", ":", "\n", "        ", "self", ".", "posneg_binary_label", "=", "posneg_binary_label", "# False: each noise type is considered as an independent category, True: 1/0 True False", "\n", "noise_label_pattern", "=", "re", ".", "compile", "(", "\".*?(\\d+)_(\\d+)/.*\"", ")", "\n", "self", ".", "data_list", "=", "[", "]", "\n", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "channel", "=", "in_channel", "\n", "with", "open", "(", "txt_task_path", ",", "\"r\"", ")", "as", "file_obj", ":", "\n", "            ", "for", "line", "in", "file_obj", ":", "\n", "                ", "json_data", "=", "json", ".", "loads", "(", "line", ")", "\n", "task_idx", ",", "image_path_position", "=", "json_data", "[", "\"task_idx\"", "]", ",", "json_data", "[", "\"img_path\"", "]", "\n", "npy_path", ",", "position", "=", "image_path_position", ".", "split", "(", "\"#\"", ")", "\n", "ma", "=", "noise_label_pattern", ".", "match", "(", "npy_path", ")", "\n", "noise_label", "=", "int", "(", "ma", ".", "group", "(", "2", ")", ")", "\n", "if", "self", ".", "posneg_binary_label", "and", "noise_label", "!=", "1", ":", "# 1 == clean image, 0 == noise image", "\n", "                    ", "noise_label", "=", "0", "\n", "", "self", ".", "data_list", ".", "append", "(", "(", "npy_path", ",", "int", "(", "position", ")", ",", "noise_label", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.presampled_task_dataset.TaskDatasetForDetector.__len__": [[30, 32], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.presampled_task_dataset.TaskDatasetForDetector.__getitem__": [[33, 42], ["open", "numpy.memmap().copy", "open.close", "numpy.transpose.reshape", "numpy.transpose", "torch.from_numpy", "numpy.memmap"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.close"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "npy_path", ",", "position", ",", "label", "=", "self", ".", "data_list", "[", "item", "]", "\n", "fobj", "=", "open", "(", "npy_path", ",", "\"rb\"", ")", "\n", "im", "=", "np", ".", "memmap", "(", "fobj", ",", "dtype", "=", "'float32'", ",", "mode", "=", "'r'", ",", "shape", "=", "(", "1", ",", "32", ",", "32", ",", "3", ")", ",", "\n", "offset", "=", "position", "*", "self", ".", "img_size", "[", "0", "]", "*", "self", ".", "img_size", "[", "1", "]", "*", "self", ".", "channel", "*", "32", "//", "8", ")", ".", "copy", "(", ")", "\n", "fobj", ".", "close", "(", ")", "\n", "im", "=", "im", ".", "reshape", "(", "self", ".", "img_size", "[", "0", "]", ",", "self", ".", "img_size", "[", "1", "]", ",", "self", ".", "channel", ")", "\n", "im", "=", "np", ".", "transpose", "(", "im", ",", "axes", "=", "(", "2", ",", "0", ",", "1", ")", ")", "# C,H,W", "\n", "return", "torch", ".", "from_numpy", "(", "im", ")", ",", "label", "", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.DNN_adversary_random_access_npy_dataset.AdversaryRandomAccessNpyDataset.__init__": [[16, 60], ["re.compile", "collections.defaultdict", "glob.glob", "DNN_adversary_random_access_npy_dataset.AdversaryRandomAccessNpyDataset.img_label_list.extend", "re.compile.match", "re.compile.match.group", "numpy.load", "npz_path.replace", "print", "DNN_adversary_random_access_npy_dataset.AdversaryRandomAccessNpyDataset.img_label_list.extend", "DNN_adversary_random_access_npy_dataset.AdversaryRandomAccessNpyDataset.img_label_list.extend", "os.path.basename", "numpy.arange", "DNN_adversary_random_access_npy_dataset.AdversaryRandomAccessNpyDataset.img_label_dict[].append", "random.sample", "len", "numpy.where", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root_path", ",", "train", ",", "protocol", ",", "META_ATTACKER_PART_I", ",", "META_ATTACKER_PART_II", ",", "balance", ",", "dataset", "=", "\"ImageNet\"", ")", ":", "\n", "        ", "self", ".", "root_path", "=", "root_path", "\n", "self", ".", "dataset", "=", "dataset", "\n", "filter_str", "=", "\"train\"", "\n", "if", "not", "train", ":", "\n", "            ", "filter_str", "=", "\"test\"", "\n", "", "extract_pattern", "=", "re", ".", "compile", "(", "\"(.*?)_untargeted.*\"", ")", "\n", "self", ".", "img_label_list", "=", "[", "]", "\n", "self", ".", "img_label_dict", "=", "defaultdict", "(", "list", ")", "\n", "for", "npz_path", "in", "glob", ".", "glob", "(", "root_path", "+", "\"/*{}.npz\"", ".", "format", "(", "filter_str", ")", ")", ":", "\n", "\n", "            ", "ma", "=", "extract_pattern", ".", "match", "(", "os", ".", "path", ".", "basename", "(", "npz_path", ")", ")", "\n", "adv_name", "=", "ma", ".", "group", "(", "1", ")", "\n", "if", "protocol", "==", "SPLIT_DATA_PROTOCOL", ".", "TRAIN_I_TEST_II", "and", "train", ":", "\n", "                ", "if", "adv_name", "not", "in", "META_ATTACKER_PART_I", ":", "\n", "                    ", "continue", "\n", "", "", "elif", "protocol", "==", "SPLIT_DATA_PROTOCOL", ".", "TRAIN_II_TEST_I", "and", "train", ":", "\n", "                ", "if", "adv_name", "not", "in", "META_ATTACKER_PART_II", ":", "\n", "                    ", "continue", "\n", "", "", "elif", "protocol", "==", "SPLIT_DATA_PROTOCOL", ".", "TRAIN_II_TEST_I", "and", "not", "train", ":", "\n", "                ", "if", "adv_name", "not", "in", "META_ATTACKER_PART_I", ":", "\n", "                    ", "continue", "\n", "", "", "elif", "protocol", "==", "SPLIT_DATA_PROTOCOL", ".", "TRAIN_I_TEST_II", "and", "not", "train", ":", "\n", "                ", "if", "adv_name", "not", "in", "META_ATTACKER_PART_II", ":", "\n", "                    ", "continue", "\n", "\n", "", "", "data", "=", "np", ".", "load", "(", "npz_path", ")", "\n", "adv_pred", "=", "data", "[", "\"adv_pred\"", "]", "\n", "gt_label", "=", "data", "[", "\"gt_label\"", "]", "\n", "if", "adv_name", "==", "\"clean\"", ":", "\n", "                ", "adv_label", "=", "1", "\n", "indexes", "=", "np", ".", "arange", "(", "len", "(", "gt_label", ")", ")", "\n", "", "else", ":", "\n", "                ", "adv_label", "=", "0", "\n", "indexes", "=", "np", ".", "where", "(", "adv_pred", "!=", "gt_label", ")", "[", "0", "]", "\n", "", "adv_data_npy_path", "=", "npz_path", ".", "replace", "(", "\".npz\"", ",", "\".npy\"", ")", "\n", "for", "index", "in", "indexes", ":", "\n", "                ", "self", ".", "img_label_dict", "[", "adv_label", "]", ".", "append", "(", "(", "adv_data_npy_path", ",", "index", ",", "adv_label", ")", ")", "\n", "", "print", "(", "\"{} done\"", ".", "format", "(", "npz_path", ")", ")", "\n", "", "self", ".", "img_label_list", ".", "extend", "(", "self", ".", "img_label_dict", "[", "1", "]", ")", "\n", "if", "balance", ":", "\n", "            ", "self", ".", "img_label_list", ".", "extend", "(", "random", ".", "sample", "(", "self", ".", "img_label_dict", "[", "0", "]", ",", "len", "(", "self", ".", "img_label_dict", "[", "1", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "img_label_list", ".", "extend", "(", "self", ".", "img_label_dict", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.DNN_adversary_random_access_npy_dataset.AdversaryRandomAccessNpyDataset.__len__": [[61, 63], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "img_label_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.DNN_adversary_random_access_npy_dataset.AdversaryRandomAccessNpyDataset.__getitem__": [[65, 76], ["open", "numpy.memmap().copy", "open.close", "torch.from_numpy.reshape", "torch.from_numpy", "numpy.transpose", "numpy.memmap"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.close"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "adv_data_npy_path", ",", "index", ",", "label", "=", "self", ".", "img_label_list", "[", "item", "]", "\n", "fobj", "=", "open", "(", "adv_data_npy_path", ",", "\"rb\"", ")", "\n", "adv_image", "=", "np", ".", "memmap", "(", "fobj", ",", "dtype", "=", "'float32'", ",", "mode", "=", "'r'", ",", "shape", "=", "(", "\n", "1", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "0", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "1", "]", ",", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ")", ",", "\n", "offset", "=", "index", "*", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "0", "]", "*", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "1", "]", "*", "IN_CHANNELS", "[", "\n", "self", ".", "dataset", "]", "*", "32", "//", "8", ")", ".", "copy", "(", ")", "\n", "fobj", ".", "close", "(", ")", "\n", "adv_image", "=", "adv_image", ".", "reshape", "(", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "0", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", "[", "1", "]", ",", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ")", "\n", "adv_image", "=", "torch", ".", "from_numpy", "(", "np", ".", "transpose", "(", "adv_image", ",", "(", "2", ",", "0", ",", "1", ")", ")", ")", "\n", "return", "adv_image", ",", "label", "\n", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.dataset.protocol_enum.SPLIT_DATA_PROTOCOL.__str__": [[11, 13], ["None"], "methods", ["None"], ["def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.gen_txt_for_train_and_test.genTaskList": [[4, 20], ["open", "open", "re.compile", "open.flush", "open.close", "line.strip.strip", "re.compile.match", "int", "open.write", "line.strip.split", "pattern.match.group"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.close"], ["def", "genTaskList", "(", "fileListPath", ",", "writePath", ",", "split_type", "=", "\"I\"", ",", "type", "=", "\"train\"", ")", ":", "\n", "    ", "fid", "=", "open", "(", "fileListPath", ",", "\"r\"", ")", "\n", "wid", "=", "open", "(", "writePath", ",", "\"w\"", ")", "\n", "pattern", "=", "re", ".", "compile", "(", "\".*?/\\d+_(\\d+)/.*\"", ")", "\n", "for", "line", "in", "fid", ":", "\n", "        ", "if", "type", "not", "in", "line", "or", "split_type", "not", "in", "line", ":", "\n", "            ", "continue", "\n", "", "line", "=", "line", ".", "strip", "(", ")", "\n", "npy_path", "=", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "ma", "=", "pattern", ".", "match", "(", "npy_path", ")", "\n", "label", "=", "int", "(", "ma", ".", "group", "(", "1", ")", ")", "\n", "if", "label", "!=", "1", ":", "# clean is labeled as 1", "\n", "            ", "label", "=", "0", "\n", "", "wid", ".", "write", "(", "\"{0} {1}\\n\"", ".", "format", "(", "npy_path", ",", "label", ")", ")", "\n", "", "wid", ".", "flush", "(", ")", "\n", "wid", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.image_rotate.ImageTransformCV2.__init__": [[23, 31], ["isinstance", "image_rotate.ImageTransformCV2.pixels_shift_dict[].append", "copy.copy"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "shift_pixels_one_direction", ")", ":", "\n", "        ", "assert", "isinstance", "(", "shift_pixels_one_direction", ",", "list", ")", "\n", "self", ".", "pixels_shift_dict", "=", "{", "}", "\n", "for", "direction", "in", "Direction", ":", "\n", "            ", "self", ".", "pixels_shift_dict", "[", "direction", "]", "=", "copy", ".", "copy", "(", "shift_pixels_one_direction", ")", "\n", "", "self", ".", "pixels_shift_dict", "[", "Direction", ".", "right", "]", ".", "append", "(", "0", ")", "\n", "self", ".", "rotate_angles", "=", "IMAGE_ROTATE_DETECTOR_ANGLES", "[", "dataset", "]", "\n", "self", ".", "process_chain", "=", "[", "self", ".", "shift_pixel_cv2", ",", "self", ".", "rotate", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.image_rotate.ImageTransformCV2.rotate": [[32, 40], ["numpy.stack", "cv2.getRotationMatrix2D", "cv2.warpAffine", "new_xs.append"], "methods", ["None"], ["", "def", "rotate", "(", "self", ",", "xs", ")", ":", "\n", "        ", "new_xs", "=", "[", "]", "\n", "for", "x", "in", "xs", ":", "\n", "            ", "for", "rotate_angle", "in", "self", ".", "rotate_angles", ":", "\n", "                ", "M", "=", "cv2", ".", "getRotationMatrix2D", "(", "(", "x", ".", "shape", "[", "0", "]", "//", "2", ",", "x", ".", "shape", "[", "1", "]", "/", "2", ")", ",", "rotate_angle", ",", "1", ")", "\n", "rotate_x", "=", "cv2", ".", "warpAffine", "(", "x", ",", "M", ",", "(", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "0", "]", ")", ")", "\n", "new_xs", ".", "append", "(", "rotate_x", ")", "\n", "", "", "return", "np", ".", "stack", "(", "new_xs", ")", "# B,", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.image_rotate.ImageTransformCV2.shift_pixel_cv2": [[42, 64], ["numpy.stack", "image_rotate.ImageTransformCV2.pixels_shift_dict.items", "numpy.float32", "cv2.warpAffine", "new_xs.append"], "methods", ["None"], ["", "def", "shift_pixel_cv2", "(", "self", ",", "xs", ")", ":", "\n", "        ", "new_xs", "=", "[", "]", "\n", "for", "x", "in", "xs", ":", "# xs shape = (N,H,W,C)", "\n", "            ", "for", "direction", ",", "shift_pixels", "in", "self", ".", "pixels_shift_dict", ".", "items", "(", ")", ":", "\n", "                ", "for", "shift_pixel", "in", "shift_pixels", ":", "\n", "                    ", "if", "direction", "==", "Direction", ".", "left", ":", "\n", "                        ", "tx", "=", "-", "shift_pixel", "\n", "ty", "=", "0", "\n", "", "elif", "direction", "==", "Direction", ".", "right", ":", "\n", "                        ", "tx", "=", "shift_pixel", "\n", "ty", "=", "0", "\n", "", "elif", "direction", "==", "Direction", ".", "up", ":", "\n", "                        ", "tx", "=", "0", "\n", "ty", "=", "-", "shift_pixel", "\n", "", "elif", "direction", "==", "Direction", ".", "down", ":", "\n", "                        ", "tx", "=", "0", "\n", "ty", "=", "shift_pixel", "\n", "\n", "", "M", "=", "np", ".", "float32", "(", "[", "[", "1", ",", "0", ",", "tx", "]", ",", "[", "0", ",", "1", ",", "ty", "]", "]", ")", "\n", "shift_x", "=", "cv2", ".", "warpAffine", "(", "x", ",", "M", ",", "(", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "0", "]", ")", ")", "\n", "new_xs", ".", "append", "(", "shift_x", ")", "\n", "", "", "", "return", "np", ".", "stack", "(", "new_xs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.image_rotate.ImageTransformCV2.shift_pixel_numpy": [[66, 84], ["numpy.stack", "image_rotate.ImageTransformCV2.pixels_shift_dict.items", "numpy.zeros_like", "numpy.stack.append"], "methods", ["None"], ["", "def", "shift_pixel_numpy", "(", "self", ",", "xs", ")", ":", "# B, 224,224,3", "\n", "        ", "new_xs", "=", "[", "]", "\n", "\n", "for", "x", "in", "xs", ":", "\n", "            ", "for", "direction", ",", "shift_pixels", "in", "self", ".", "pixels_shift_dict", ".", "items", "(", ")", ":", "\n", "                ", "for", "shift_pixel", "in", "shift_pixels", ":", "\n", "                    ", "shift_x", "=", "np", ".", "zeros_like", "(", "x", ")", "\n", "if", "direction", "==", "Direction", ".", "left", ":", "\n", "                        ", "shift_x", "[", ":", ",", "0", ":", "shift_x", ".", "shape", "[", "1", "]", "-", "shift_pixel", ",", ":", "]", "=", "x", "[", ":", ",", "shift_pixel", ":", ",", ":", "]", "\n", "", "elif", "direction", "==", "Direction", ".", "right", ":", "\n", "                        ", "shift_x", "[", ":", ",", "shift_pixel", ":", ",", ":", "]", "=", "x", "[", ":", ",", "0", ":", "x", ".", "shape", "[", "1", "]", "-", "shift_pixel", ",", ":", "]", "\n", "", "elif", "direction", "==", "Direction", ".", "up", ":", "\n", "                        ", "shift_x", "[", ":", "shift_pixel", ".", "shape", "[", "0", "]", "-", "shift_pixel", ",", ":", ",", ":", "]", "=", "x", "[", "shift_pixel", ":", ",", ":", ",", ":", "]", "\n", "", "elif", "direction", "==", "Direction", ".", "down", ":", "\n", "                        ", "shift_x", "[", "shift_pixel", ":", ",", ":", ",", ":", "]", "=", "x", "[", "0", ":", "x", ".", "shape", "[", "0", "]", "-", "shift_pixel", ",", ":", ",", ":", "]", "\n", "", "new_xs", ".", "append", "(", "shift_x", ")", "\n", "", "", "", "new_xs", "=", "np", ".", "stack", "(", "new_xs", ")", "\n", "return", "new_xs", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.image_rotate.ImageTransformCV2.__call__": [[85, 104], ["process_func.detach().cpu().numpy", "process_func.reshape", "numpy.transpose", "torch.from_numpy().cuda", "numpy.squeeze", "process_func", "random.randint", "process_func.detach().cpu", "torch.from_numpy", "range", "len", "process_func.detach"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "xs", ",", "random_rotate", "=", "False", ")", ":", "\n", "        ", "'''\n        :param x:  224, 224, 3\n        :return:\n        '''", "\n", "if", "random_rotate", ":", "\n", "            ", "self", ".", "rotate_angles", "=", "[", "random", ".", "randint", "(", "-", "180", ",", "180", ")", "for", "_", "in", "range", "(", "len", "(", "self", ".", "rotate_angles", ")", ")", "]", "\n", "", "xs", "=", "xs", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "batch_size", "=", "xs", ".", "shape", "[", "0", "]", "\n", "height", ",", "width", ",", "channel", "=", "xs", ".", "shape", "[", "1", "]", ",", "xs", ".", "shape", "[", "2", "]", ",", "xs", ".", "shape", "[", "3", "]", "\n", "if", "channel", "==", "1", ":", "\n", "            ", "xs", "=", "np", ".", "squeeze", "(", "xs", ",", "-", "1", ")", "\n", "\n", "", "for", "process_func", "in", "self", ".", "process_chain", ":", "\n", "            ", "xs", "=", "process_func", "(", "xs", ")", "# B, H, W, C", "\n", "", "xs", "=", "xs", ".", "reshape", "(", "batch_size", ",", "-", "1", ",", "height", ",", "width", ",", "channel", ")", "# B, TRANS_NUM,H,W,C", "\n", "xs", "=", "np", ".", "transpose", "(", "xs", ",", "axes", "=", "(", "1", ",", "0", ",", "2", ",", "3", ",", "4", ")", ")", "\n", "xs", "=", "torch", ".", "from_numpy", "(", "xs", ")", ".", "cuda", "(", ")", "# TRANS_NUM,B, H,W,C", "\n", "return", "xs", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.image_rotate.ImageTransformTorch.__init__": [[109, 119], ["torch.nn.Module.__init__", "isinstance", "image_rotate.ImageTransformTorch.pixels_shift_dict[].append", "copy.copy"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "shift_pixels_one_direction", ")", ":", "\n", "        ", "super", "(", "ImageTransformTorch", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "shift_pixels_one_direction", ",", "list", ")", "\n", "self", ".", "pixels_shift_dict", "=", "{", "}", "\n", "for", "direction", "in", "Direction", ":", "\n", "            ", "self", ".", "pixels_shift_dict", "[", "direction", "]", "=", "copy", ".", "copy", "(", "shift_pixels_one_direction", ")", "\n", "", "self", ".", "pixels_shift_dict", "[", "Direction", ".", "right", "]", ".", "append", "(", "0", ")", "\n", "self", ".", "rotate_angles", "=", "IMAGE_ROTATE_DETECTOR_ANGLES", "[", "dataset", "]", "\n", "self", ".", "process_chain", "=", "[", "self", ".", "shift_pixel", ",", "self", ".", "rotate", "]", "\n", "self", ".", "M_cache", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.image_rotate.ImageTransformTorch.rotate": [[120, 145], ["torch.stack().contiguous", "all_rotate_xs.view().contiguous.view().contiguous.view().contiguous", "torch.nn.functional.affine_grid", "torch.nn.functional.grid_sample", "all_rotate_xs.view().contiguous.view().contiguous.append", "all_rotate_xs.view().contiguous.view().contiguous.size", "all_rotate_xs.view().contiguous.view().contiguous.size", "xs.size", "torch.Tensor().float().cuda", "M.unsqueeze().repeat().float.unsqueeze().repeat().float.unsqueeze().repeat().float", "xs.size", "torch.stack", "all_rotate_xs.view().contiguous.view().contiguous.view", "all_rotate_xs.view().contiguous.view().contiguous.size", "all_rotate_xs.view().contiguous.view().contiguous.size", "all_rotate_xs.view().contiguous.view().contiguous.size", "torch.Tensor().float", "M.unsqueeze().repeat().float.unsqueeze().repeat().float.unsqueeze().repeat", "xs.size", "torch.Tensor", "M.unsqueeze().repeat().float.unsqueeze().repeat().float.unsqueeze", "math.cos", "math.sin", "math.cos", "math.sin"], "methods", ["None"], ["", "def", "rotate", "(", "self", ",", "xs", ")", ":", "\n", "        ", "all_rotate_xs", "=", "[", "]", "\n", "for", "rotate_angle", "in", "self", ".", "rotate_angles", ":", "\n", "# height = xs.size(2)", "\n", "# width = xs.size(3)", "\n", "# M = cv2.getRotationMatrix2D((width / 2, height / 2), rotate_angle, 1)  # 2,3", "\n", "# M[0, -1] /= (-float(width - 1))", "\n", "# M[1, -1] /= (-float(height - 1))", "\n", "            ", "key", "=", "\"rotate_{}_batchsize_{}\"", ".", "format", "(", "rotate_angle", ",", "xs", ".", "size", "(", "0", ")", ")", "\n", "if", "key", "in", "self", ".", "M_cache", ":", "\n", "                ", "M", "=", "self", ".", "M_cache", "[", "key", "]", "\n", "", "else", ":", "\n", "                ", "M", "=", "torch", ".", "Tensor", "(", "[", "\n", "[", "cos", "(", "rotate_angle", ")", ",", "sin", "(", "rotate_angle", ")", ",", "0", "]", ",", "\n", "[", "-", "sin", "(", "rotate_angle", ")", ",", "cos", "(", "rotate_angle", ")", ",", "0", "]", ",", "\n", "]", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "M", "=", "M", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "xs", ".", "size", "(", "0", ")", ",", "1", ",", "1", ")", ".", "float", "(", ")", "\n", "self", ".", "M_cache", "[", "key", "]", "=", "M", "\n", "", "grid", "=", "F", ".", "affine_grid", "(", "M", ",", "xs", ".", "size", "(", ")", ")", "# Trans * N,C,H,W", "\n", "rotate_xs", "=", "F", ".", "grid_sample", "(", "xs", ",", "grid", ")", "\n", "all_rotate_xs", ".", "append", "(", "rotate_xs", ")", "# each is Trans * N , C , H , W", "\n", "", "all_rotate_xs", "=", "torch", ".", "stack", "(", "all_rotate_xs", ")", ".", "contiguous", "(", ")", "# R,Trans * N ,C,H,W", "\n", "R", ",", "B", "=", "all_rotate_xs", ".", "size", "(", "0", ")", ",", "all_rotate_xs", ".", "size", "(", "1", ")", "\n", "all_rotate_xs", "=", "all_rotate_xs", ".", "view", "(", "B", "*", "R", ",", "all_rotate_xs", ".", "size", "(", "2", ")", ",", "all_rotate_xs", ".", "size", "(", "3", ")", ",", "all_rotate_xs", ".", "size", "(", "4", ")", ")", ".", "contiguous", "(", ")", "# R * Trans * N ,C,H,W", "\n", "return", "all_rotate_xs", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.image_rotate.ImageTransformTorch.shift_pixel": [[147, 179], ["image_rotate.ImageTransformTorch.pixels_shift_dict.items", "torch.cat", "x_torch.size", "x_torch.size", "torch.nn.functional.affine_grid", "torch.nn.functional.grid_sample", "new_xs.append", "numpy.array().astype", "torch.from_numpy().cuda", "torch.from_numpy().cuda.unsqueeze", "x_torch.unsqueeze().size", "x_torch.unsqueeze", "numpy.array", "torch.from_numpy", "x_torch.unsqueeze", "float", "float"], "methods", ["None"], ["", "def", "shift_pixel", "(", "self", ",", "xs", ")", ":", "\n", "        ", "new_xs", "=", "[", "]", "\n", "\n", "for", "direction", ",", "shift_pixels", "in", "self", ".", "pixels_shift_dict", ".", "items", "(", ")", ":", "\n", "            ", "for", "shift_pixel", "in", "shift_pixels", ":", "\n", "                ", "key", "=", "\"{}_{}\"", ".", "format", "(", "direction", ",", "shift_pixel", ")", "\n", "for", "x_torch", "in", "xs", ":", "\n", "                    ", "if", "direction", "==", "Direction", ".", "left", ":", "\n", "                        ", "tx", "=", "shift_pixel", "\n", "ty", "=", "0", "\n", "", "elif", "direction", "==", "Direction", ".", "right", ":", "\n", "                        ", "tx", "=", "-", "shift_pixel", "\n", "ty", "=", "0", "\n", "", "elif", "direction", "==", "Direction", ".", "up", ":", "\n", "                        ", "tx", "=", "0", "\n", "ty", "=", "shift_pixel", "\n", "", "elif", "direction", "==", "Direction", ".", "down", ":", "\n", "                        ", "tx", "=", "0", "\n", "ty", "=", "-", "shift_pixel", "\n", "", "width", "=", "x_torch", ".", "size", "(", "2", ")", "\n", "height", "=", "x_torch", ".", "size", "(", "1", ")", "\n", "if", "key", "in", "self", ".", "M_cache", ":", "\n", "                        ", "M", "=", "self", ".", "M_cache", "[", "key", "]", "\n", "", "else", ":", "\n", "                        ", "M", "=", "np", ".", "array", "(", "[", "[", "1", ",", "0", ",", "tx", "/", "float", "(", "width", "-", "1", ")", "]", ",", "[", "0", ",", "1", ",", "ty", "/", "float", "(", "height", "-", "1", ")", "]", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "# M = np.array([[1, 0, 0], [0, 1, -0.0031]]).astype(np.float32)  # \u5411\u53f3\u79fb\u52a820%, \u5411\u4e0b\u79fb\u52a840%", "\n", "M", "=", "torch", ".", "from_numpy", "(", "M", ")", ".", "cuda", "(", ")", "\n", "self", ".", "M_cache", "[", "key", "]", "=", "M", "\n", "", "grid", "=", "F", ".", "affine_grid", "(", "M", ".", "unsqueeze", "(", "0", ")", ",", "x_torch", ".", "unsqueeze", "(", "0", ")", ".", "size", "(", ")", ")", "\n", "shift_x", "=", "F", ".", "grid_sample", "(", "x_torch", ".", "unsqueeze", "(", "0", ")", ",", "grid", ",", "mode", "=", "'bilinear'", ")", "\n", "new_xs", ".", "append", "(", "shift_x", ")", "\n", "", "", "", "return", "torch", ".", "cat", "(", "new_xs", ",", "dim", "=", "0", ")", "# R * B, C,H,W", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.image_rotate.ImageTransformTorch.forward": [[183, 200], ["process_func.permute", "process_func.size", "process_func.permute().contiguous", "process_func.view", "process_func.size", "process_func.size", "process_func.size", "process_func", "random.randint", "process_func.permute", "range", "len"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "xs", ",", "random_rotate", "=", "False", ")", ":", "\n", "        ", "'''\n        :param x:  224, 224, 3\n        :return:\n        '''", "\n", "if", "random_rotate", ":", "\n", "            ", "self", ".", "rotate_angles", "=", "[", "random", ".", "randint", "(", "-", "180", ",", "180", ")", "for", "_", "in", "range", "(", "len", "(", "self", ".", "rotate_angles", ")", ")", "]", "\n", "\n", "", "xs", "=", "xs", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "# N,H,W,C -> N,C,H,W", "\n", "batch_size", "=", "xs", ".", "size", "(", "0", ")", "\n", "channel", ",", "height", ",", "width", "=", "xs", ".", "size", "(", "1", ")", ",", "xs", ".", "size", "(", "2", ")", ",", "xs", ".", "size", "(", "3", ")", "\n", "for", "process_func", "in", "self", ".", "process_chain", ":", "\n", "            ", "xs", "=", "process_func", "(", "xs", ")", "\n", "", "xs", "=", "xs", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", "# B,H,W,C", "\n", "xs", "=", "xs", ".", "view", "(", "-", "1", ",", "batch_size", ",", "height", ",", "width", ",", "channel", ")", "# Transform, N,  H, W,C", "\n", "\n", "return", "xs", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.npy_dataset.NpzDataset.__init__": [[7, 19], ["open", "line.split", "int", "os.path.join.split", "int", "os.path.join", "npy_dataset.NpzDataset.npy_file_list.append"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_folder", ",", "image_label_txt_path", ")", ":", "\n", "\n", "        ", "self", ".", "data_folder", "=", "data_folder", "\n", "self", ".", "npy_file_list", "=", "[", "]", "\n", "with", "open", "(", "image_label_txt_path", ",", "\"r\"", ")", "as", "file_obj", ":", "\n", "            ", "for", "line", "in", "file_obj", ":", "\n", "                ", "npy_path", ",", "label", "=", "line", ".", "split", "(", "\" \"", ")", "\n", "label", "=", "int", "(", "label", ")", "\n", "npy_path", ",", "data_index", "=", "npy_path", ".", "split", "(", "\"#\"", ")", "\n", "data_index", "=", "int", "(", "data_index", ")", "\n", "npy_path", "=", "os", ".", "path", ".", "join", "(", "data_folder", ",", "npy_path", ")", "\n", "self", ".", "npy_file_list", ".", "append", "(", "{", "\"npy_path\"", ":", "npy_path", ",", "\"index\"", ":", "data_index", ",", "\"label\"", ":", "label", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.npy_dataset.NpzDataset.__len__": [[20, 22], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "npy_file_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.npy_dataset.NpzDataset.__getitem__": [[23, 33], ["numpy.memmap", "numpy.transpose.reshape", "numpy.transpose", "torch.from_numpy"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "data_json", "=", "self", ".", "npy_file_list", "[", "item", "]", "\n", "npy_path", "=", "data_json", "[", "\"npy_path\"", "]", "\n", "npy_index", "=", "data_json", "[", "\"index\"", "]", "\n", "im", "=", "np", ".", "memmap", "(", "npy_path", ",", "dtype", "=", "'float32'", ",", "mode", "=", "'r'", ",", "shape", "=", "(", "1", ",", "32", ",", "32", ",", "3", ")", ",", "\n", "offset", "=", "npy_index", "*", "32", "*", "32", "*", "3", "*", "32", "//", "8", ")", "\n", "im", "=", "im", ".", "reshape", "(", "32", ",", "32", ",", "3", ")", "\n", "im", "=", "np", ".", "transpose", "(", "im", ",", "axes", "=", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "label", "=", "data_json", "[", "\"label\"", "]", "\n", "return", "torch", ".", "from_numpy", "(", "im", ")", ",", "label", "", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.rotate_detector.Detector.__init__": [[11, 27], ["networks.meta_network.MetaNetwork.__init__", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset_name", ",", "network", ",", "image_class_number", ",", "image_transform", ",", "layer_number", ",", "num_classes", "=", "2", ")", ":", "\n", "        ", "super", "(", "self", ".", "__class__", ",", "self", ")", ".", "__init__", "(", "network", ",", "IN_CHANNELS", "[", "dataset_name", "]", ",", "IMAGE_SIZE", "[", "dataset_name", "]", ")", "\n", "self", ".", "image_transform", "=", "image_transform", "\n", "self", ".", "network", "=", "network", "\n", "self", ".", "layer_number", "=", "layer_number", "\n", "self", ".", "image_class_number", "=", "image_class_number", "\n", "if", "layer_number", "==", "2", ":", "\n", "            ", "self", ".", "network", ".", "detector_chain", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "45", "*", "image_class_number", ",", "128", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "128", ",", "num_classes", ")", ")", "\n", "", "elif", "layer_number", "==", "3", ":", "\n", "            ", "self", ".", "network", ".", "detector_chain", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "45", "*", "image_class_number", ",", "128", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "128", ",", "32", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "32", ",", "num_classes", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.rotate_detector.Detector.feature_forward": [[28, 39], ["x.permute.permute.permute", "rotate_detector.Detector.image_transform", "transformed_x.view.view.permute", "transformed_x.view.view.view", "rotate_detector.Detector.network", "logits.view.view.view().transpose().contiguous", "logits.view.view.view", "transformed_x.view.view.size", "transformed_x.view.view.size", "transformed_x.view.view.size", "transformed_x.view.view.size", "transformed_x.view.view.size", "logits.view.view.view().transpose", "logits.view.view.view"], "methods", ["None"], ["", "", "def", "feature_forward", "(", "self", ",", "x", ",", "random_rotate", "=", "False", ")", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "# N, C, H ,W -> N, H, W, C", "\n", "transformed_x", "=", "self", ".", "image_transform", "(", "x", ",", "random_rotate", ")", "# Transform, N,  H, W, C", "\n", "transformed_x", "=", "transformed_x", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "3", ")", "\n", "transform_num", ",", "batch_size", "=", "transformed_x", ".", "size", "(", "0", ")", ",", "transformed_x", ".", "size", "(", "1", ")", "\n", "# TRANS_NUM * N, C, H, W", "\n", "transformed_x", "=", "transformed_x", ".", "view", "(", "transform_num", "*", "batch_size", ",", "transformed_x", ".", "size", "(", "2", ")", ",", "transformed_x", ".", "size", "(", "3", ")", ",", "transformed_x", ".", "size", "(", "4", ")", ")", "\n", "logits", "=", "self", ".", "network", "(", "transformed_x", ")", "# TRANS_NUM * N, 10", "\n", "logits", "=", "logits", ".", "view", "(", "transform_num", ",", "batch_size", ",", "-", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "# N,TRANS_NUM, 10", "\n", "logits", "=", "logits", ".", "view", "(", "batch_size", ",", "-", "1", ")", "# N, TRANS_NUM*10  (TRANS_NUM=45)", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.rotate_detector.Detector.forward": [[42, 46], ["rotate_detector.Detector.feature_forward", "rotate_detector.Detector.network.detector_chain"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.rotate_detector.Detector.feature_forward"], ["", "def", "forward", "(", "self", ",", "x", ",", "random_rotate", "=", "False", ")", ":", "\n", "        ", "logits", "=", "self", ".", "feature_forward", "(", "x", ",", "random_rotate", ")", "# N,TRANS_NUM, 10", "\n", "prediction", "=", "self", ".", "network", ".", "detector_chain", "(", "logits", ")", "\n", "return", "prediction", "", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.train.AverageMeter.__init__": [[330, 332], ["train.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.reset"], ["\n", "", "", "def", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ",", "args", ")", ":", "\n", "    ", "\"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.train.AverageMeter.reset": [[333, 338], ["None"], "methods", ["None"], ["lr", "=", "args", ".", "lr", "*", "(", "0.1", "**", "(", "epoch", "//", "30", ")", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n", "\n", "", "", "def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.train.AverageMeter.update": [[339, 344], ["None"], "methods", ["None"], ["    ", "\"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.train.main": [[94, 122], ["parser.parse_args", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "warnings.warn", "train.main_train_worker", "image_rotate_detector.evaluation.shots_evaluation.evaluate_shots", "image_rotate_detector.evaluation.cross_domain_evaluation.evaluate_cross_domain", "image_rotate_detector.evaluation.finetune_evaluation.evaluate_finetune", "image_rotate_detector.evaluation.cross_arch_evaluation.evaluate_cross_arch", "image_rotate_detector.evaluation.white_box_evaluation.evaluate_whitebox_attack", "image_rotate_detector.evaluation.zero_shot_evaluation.evaluate_zero_shot", "image_rotate_detector.evaluation.speed_evaluation.evaluate_speed"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.train_fingerprint.parse_args", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.main_train_worker", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.shots_evaluation.evaluate_shots", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.cross_domain_evaluation.evaluate_cross_domain", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.finetune_evaluation.evaluate_finetune", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.cross_arch_evaluation.evaluate_cross_arch", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.white_box_evaluation.evaluate_whitebox_attack", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.zero_shot_evaluation.evaluate_zero_shot", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.speed_evaluation.evaluate_speed"], ["cudnn", ".", "deterministic", "=", "True", "\n", "warnings", ".", "warn", "(", "'You have chosen to seed training. '", "\n", "'This will turn on the CUDNN deterministic setting, '", "\n", "'which can slow down your training considerably! '", "\n", "'You may see unexpected behavior when restarting '", "\n", "'from checkpoints.'", ")", "\n", "", "if", "not", "args", ".", "evaluate", ":", "# not evaluate_accuracy", "\n", "\n", "        ", "model_path", "=", "'{}/train_pytorch_model/DL_DET/DL_DET@{}_{}@model_{}@data_{}@epoch_{}@class_{}@lr_{}@balance_{}.pth.tar'", ".", "format", "(", "\n", "PY_ROOT", ",", "args", ".", "dataset", ",", "args", ".", "protocol", ",", "args", ".", "arch", ",", "args", ".", "adv_arch", ",", "\n", "args", ".", "epochs", ",", "\n", "2", ",", "args", ".", "lr", ",", "args", ".", "balance", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "model_path", ")", ",", "exist_ok", "=", "True", ")", "\n", "main_train_worker", "(", "args", ",", "model_path", ",", "gpu", "=", "str", "(", "args", ".", "gpu", ")", ")", "\n", "\n", "", "else", ":", "# finetune evaluate_accuracy", "\n", "# DL_DET@CIFAR-10_TRAIN_II_TEST_I@conv3@epoch_40@class_2@lr_0.0001.pth.tar", "\n", "        ", "print", "(", "\"Use GPU: {} for training\"", ".", "format", "(", "args", ".", "gpu", ")", ")", "\n", "os", ".", "environ", "[", "\"CUDA_DEVICE_ORDER\"", "]", "=", "\"PCI_BUS_ID\"", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "str", "(", "args", ".", "gpu", ")", "\n", "model_file_list", "=", "glob", ".", "glob", "(", "\"{}/train_pytorch_model/DL_DET/DL_DET@*\"", ".", "format", "(", "PY_ROOT", ")", ")", "\n", "if", "args", ".", "study_subject", "==", "\"cross_domain\"", ":", "\n", "            ", "result", "=", "evaluate_cross_domain", "(", "model_file_list", ",", "args", ".", "num_updates", ",", "args", ".", "lr", ",", "args", ".", "protocol", ",", "\n", "args", ".", "cross_domain_source", ",", "args", ".", "cross_domain_target", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "'finetune_eval'", ":", "\n", "            ", "result", "=", "evaluate_finetune", "(", "model_file_list", ",", "args", ".", "lr", ",", "args", ".", "protocol", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"shots_eval\"", ":", "\n", "            ", "result", "=", "evaluate_shots", "(", "model_file_list", ",", "args", ".", "num_updates", ",", "args", ".", "lr", ",", "args", ".", "protocol", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"cross_arch\"", ":", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.train.evaluate_accuracy": [[123, 132], ["in_.cuda.cuda", "meta_adv_detector.score.forward_pass", "l.item", "numpy.argmax().reshape", "sklearn.metrics.accuracy_score", "target_positive.detach().cpu().numpy().reshape", "in_.cuda.detach().cpu().numpy", "numpy.argmax", "float", "in_.cuda.size", "out.detach().cpu().numpy", "target_positive.detach().cpu().numpy", "in_.cuda.detach().cpu", "out.detach().cpu", "target_positive.detach().cpu", "in_.cuda.detach", "out.detach", "target_positive.detach"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward_pass"], ["            ", "updateBN", "=", "False", "\n", "result", "=", "evaluate_cross_arch", "(", "model_file_list", ",", "args", ".", "num_updates", ",", "args", ".", "lr", ",", "args", ".", "protocol", ",", "args", ".", "cross_arch_source", ",", "\n", "args", ".", "cross_arch_target", ",", "updateBN", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"zero_shot\"", ":", "\n", "            ", "result", "=", "evaluate_zero_shot", "(", "model_file_list", ",", "args", ".", "lr", ",", "args", ".", "protocol", ",", "args", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"speed_test\"", ":", "\n", "            ", "result", "=", "evaluate_speed", "(", "model_file_list", ",", "args", ".", "num_updates", ",", "args", ".", "lr", ",", "args", ".", "protocol", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"white_box\"", ":", "\n", "            ", "result", "=", "defaultdict", "(", "dict", ")", "\n", "attacks", "=", "[", "\"FGSM\"", ",", "\"CW_L2\"", "]", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.train.build_network": [[134, 156], ["os.path.exists", "print", "print", "print", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "networks.conv3.Conv3.load_state_dict", "print", "networks.resnet.resnet10", "networks.resnet.resnet18", "networks.conv3.Conv3"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet10", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet18"], ["                ", "evaluate_whitebox", "(", "args", ".", "dataset", ",", "\"conv3\"", ",", "\"conv3\"", ",", "\"DNN\"", ",", "attack_name", ",", "args", ".", "num_updates", ",", "args", ".", "lr", ",", "\n", "args", ".", "protocol", ",", "LOAD_TASK_MODE", ".", "NO_LOAD", ",", "result", ")", "\n", "", "", "file_name", "=", "'{}/train_pytorch_model/DL_DET/cross_adv_group_{}_using_{}_protocol.json'", ".", "format", "(", "PY_ROOT", ",", "args", ".", "study_subject", ",", "args", ".", "protocol", ")", "\n", "if", "args", ".", "study_subject", "==", "\"cross_domain\"", ":", "\n", "            ", "file_name", "=", "'{}/train_pytorch_model/DL_DET/evaluate_{}_{}--{}_using_{}_protocol.json'", ".", "format", "(", "PY_ROOT", ",", "\n", "args", ".", "study_subject", ",", "args", ".", "cross_domain_source", ",", "args", ".", "cross_domain_target", ",", "\n", "args", ".", "protocol", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"cross_arch\"", ":", "\n", "            ", "file_name", "=", "'{}/train_pytorch_model/DL_DET/evaluate_{}_{}--{}_using_{}_protocol_updateBN_{}.json'", ".", "format", "(", "PY_ROOT", ",", "\n", "args", ".", "study_subject", ",", "\n", "args", ".", "cross_arch_source", ",", "\n", "args", ".", "cross_arch_target", ",", "\n", "args", ".", "protocol", ",", "updateBN", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"white_box\"", ":", "\n", "            ", "file_name", "=", "'{}/train_pytorch_model/white_box_model/white_box_UPDATEBN_DNN_{}_using_{}_protocol.json'", ".", "format", "(", "PY_ROOT", ",", "\n", "args", ".", "dataset", ",", "\n", "args", ".", "protocol", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"speed_test\"", ":", "\n", "            ", "file_name", "=", "'{}/train_pytorch_model/DL_DET/speed_test_of_DNN.json'", ".", "format", "(", "PY_ROOT", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"zero_shot\"", ":", "\n", "            ", "if", "args", ".", "cross_domain_source", ":", "\n", "                ", "file_name", "=", "'{}/train_pytorch_model/DL_DET/evaluate_{}_{}--{}_using_{}_protocol.json'", ".", "format", "(", "PY_ROOT", ",", "\n", "args", ".", "study_subject", ",", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.train.main_train_worker": [[157, 172], ["re.compile", "re.compile.match", "extract_info_pattern.match.group", "train.train_detector", "len"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.train.train_detector"], ["args", ".", "cross_domain_source", ",", "\n", "args", ".", "cross_domain_target", ",", "\n", "args", ".", "protocol", ")", "\n", "", "else", ":", "\n", "                ", "file_name", "=", "'{}/train_pytorch_model/DL_DET/evaluate_{}_using_{}_protocol.json'", ".", "format", "(", "PY_ROOT", ",", "\n", "args", ".", "study_subject", ",", "\n", "args", ".", "protocol", ")", "\n", "\n", "", "", "with", "open", "(", "file_name", ",", "\"w\"", ")", "as", "file_obj", ":", "\n", "            ", "file_obj", ".", "write", "(", "json", ".", "dumps", "(", "result", ")", ")", "\n", "file_obj", ".", "flush", "(", ")", "\n", "\n", "\n", "", "", "", "def", "main_train_worker", "(", "args", ",", "model_path", ",", "META_ATTACKER_PART_I", "=", "None", ",", "META_ATTACKER_PART_II", "=", "None", ",", "gpu", "=", "\"0\"", ")", ":", "\n", "    ", "if", "META_ATTACKER_PART_I", "is", "None", ":", "\n", "        ", "META_ATTACKER_PART_I", "=", "config", ".", "META_ATTACKER_PART_I", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.train.train_detector": [[174, 217], ["print", "str", "train.build_network", "image_rotate_detector.rotate_detector.Detector", "image_rotate_detector.rotate_detector.Detector.cuda", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "train.train_epochs", "image_rotate_detector.image_rotate.ImageTransformCV2", "os.makedirs", "image_rotate_detector.image_rotate.ImageTransformTorch", "os.makedirs", "image_rotate_detector.rotate_detector.Detector.parameters", "dataset.DNN_adversary_random_access_npy_dataset.AdversaryRandomAccessNpyDataset", "dataset.DNN_adversary_dataset.AdversaryDataset", "os.path.dirname", "os.path.dirname"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.train.build_network", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.train.train_epochs"], ["        ", "META_ATTACKER_PART_II", "=", "config", ".", "META_ATTACKER_PART_II", "\n", "", "print", "(", "\"Use GPU: {} for training\"", ".", "format", "(", "gpu", ")", ")", "\n", "os", ".", "environ", "[", "\"CUDA_DEVICE_ORDER\"", "]", "=", "\"PCI_BUS_ID\"", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "gpu", "\n", "print", "(", "\"will save to {}\"", ".", "format", "(", "model_path", ")", ")", "\n", "global", "best_acc1", "\n", "if", "args", ".", "arch", "==", "\"conv3\"", ":", "\n", "        ", "model", "=", "Conv3", "(", "IN_CHANNELS", "[", "args", ".", "dataset", "]", ",", "IMAGE_SIZE", "[", "args", ".", "dataset", "]", ",", "2", ")", "\n", "", "elif", "args", ".", "arch", "==", "\"resnet10\"", ":", "\n", "        ", "model", "=", "resnet10", "(", "2", ",", "in_channels", "=", "IN_CHANNELS", "[", "args", ".", "dataset", "]", ",", "pretrained", "=", "False", ")", "\n", "", "elif", "args", ".", "arch", "==", "\"resnet18\"", ":", "\n", "        ", "model", "=", "resnet18", "(", "2", ",", "in_channels", "=", "IN_CHANNELS", "[", "args", ".", "dataset", "]", ",", "pretrained", "=", "False", ")", "\n", "", "model", "=", "model", ".", "cuda", "(", ")", "\n", "if", "args", ".", "dataset", "==", "\"ImageNet\"", ":", "\n", "        ", "train_dataset", "=", "AdversaryRandomAccessNpyDataset", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "dataset", "]", "+", "\"/adversarial_images/{}\"", ".", "format", "(", "args", ".", "adv_arch", ")", ",", "\n", "True", ",", "args", ".", "protocol", ",", "META_ATTACKER_PART_I", ",", "META_ATTACKER_PART_II", ",", "\n", "args", ".", "balance", ",", "args", ".", "dataset", ")", "\n", "", "else", ":", "\n", "        ", "train_dataset", "=", "AdversaryDataset", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "dataset", "]", "+", "\"/adversarial_images/{}\"", ".", "format", "(", "args", ".", "adv_arch", ")", ",", "\n", "True", ",", "args", ".", "protocol", ",", "META_ATTACKER_PART_I", ",", "META_ATTACKER_PART_II", ",", "args", ".", "balance", ")", "\n", "\n", "# val_dataset = MetaTaskDataset(20000, 2, 1, 15,", "\n", "#                                     args.dataset, is_train=False, pkl_task_dump_path=args.test_pkl_path,", "\n", "#                                     load_mode=LOAD_TASK_MODE.LOAD,", "\n", "#                                     protocol=args.protocol, no_random_way=True)", "\n", "\n", "# define loss function (criterion) and optimizer", "\n", "", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "cuda", "(", "args", ".", "gpu", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "lr", ",", "\n", "momentum", "=", "args", ".", "momentum", ",", "\n", "weight_decay", "=", "args", ".", "weight_decay", ")", "\n", "\n", "# optionally resume from a checkpoint", "\n", "if", "os", ".", "path", ".", "exists", "(", "model_path", ")", ":", "\n", "        ", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "model_path", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "args", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "model_path", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"=> no checkpoint found at '{}'\"", ".", "format", "(", "model_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.train.train_epochs": [[218, 226], ["str", "torch.CrossEntropyLoss().cuda", "detector.cuda", "range", "train.adjust_learning_rate", "train.train", "torch.CrossEntropyLoss"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.adjust_learning_rate", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train"], ["", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# Data loading code", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "train_dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "\n", "# val_loader = torch.utils.data.DataLoader(", "\n", "#     val_dataset,", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.train.train": [[228, 284], ["train.AverageMeter", "train.AverageMeter", "train.AverageMeter", "train.AverageMeter", "model.train", "time.time", "enumerate", "train.save_checkpoint", "train.AverageMeter.update", "input.cuda.cuda", "target.cuda.cuda", "model", "criterion", "train.accuracy", "train.AverageMeter.update", "train.AverageMeter.update", "optimizer.zero_grad", "criterion.backward", "optimizer.step", "train.AverageMeter.update", "time.time", "train_loader.dataset.img_label_list.clear", "train_loader.dataset.img_label_list.extend", "train_loader.dataset.img_label_list.extend", "criterion.item", "input.cuda.size", "input.cuda.size", "print", "model.state_dict", "optimizer.state_dict", "random.sample", "time.time", "time.time", "len", "len"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.save_checkpoint", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.accuracy", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update"], ["#     num_workers=0, pin_memory=True)", "\n", "tensorboard", "=", "TensorBoardWriter", "(", "\"{0}/pytorch_DeepLearning_tensorboard\"", ".", "format", "(", "PY_ROOT", ")", ",", "\"DeepLearning\"", ")", "\n", "for", "epoch", "in", "range", "(", "args", ".", "start_epoch", ",", "args", ".", "epochs", ")", ":", "\n", "        ", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ",", "args", ")", "\n", "# train for one epoch", "\n", "train", "(", "train_loader", ",", "None", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "tensorboard", ",", "args", ")", "\n", "if", "args", ".", "balance", ":", "\n", "            ", "train_dataset", ".", "img_label_list", ".", "clear", "(", ")", "\n", "train_dataset", ".", "img_label_list", ".", "extend", "(", "train_dataset", ".", "img_label_dict", "[", "1", "]", ")", "\n", "train_dataset", ".", "img_label_list", ".", "extend", "(", "random", ".", "sample", "(", "train_dataset", ".", "img_label_dict", "[", "0", "]", ",", "len", "(", "train_dataset", ".", "img_label_dict", "[", "1", "]", ")", ")", ")", "\n", "# evaluate_accuracy on validation set", "\n", "\n", "# acc1 = validate(val_loader, model, criterion, args)", "\n", "# remember best acc@1 and save checkpoint", "\n", "", "save_checkpoint", "(", "{", "\n", "'epoch'", ":", "epoch", "+", "1", ",", "\n", "'arch'", ":", "args", ".", "arch", ",", "\n", "'state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "filename", "=", "model_path", ")", "\n", "\n", "\n", "\n", "", "", "def", "train", "(", "train_loader", ",", "val_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "tensorboard", ",", "args", ")", ":", "\n", "    ", "batch_time", "=", "AverageMeter", "(", ")", "\n", "data_time", "=", "AverageMeter", "(", ")", "\n", "losses", "=", "AverageMeter", "(", ")", "\n", "top1", "=", "AverageMeter", "(", ")", "\n", "# top5 = AverageMeter()", "\n", "\n", "# switch to train mode", "\n", "model", ".", "train", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "input", ",", "target", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "# measure data loading time", "\n", "        ", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "input", "=", "input", ".", "cuda", "(", ")", "\n", "target", "=", "target", ".", "cuda", "(", ")", "\n", "\n", "# compute output", "\n", "output", "=", "model", "(", "input", ")", "\n", "loss", "=", "criterion", "(", "output", ",", "target", ")", "\n", "# measure accuracy and record loss", "\n", "acc1", ",", "=", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", "\n", "losses", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "top1", ".", "update", "(", "acc1", "[", "0", "]", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "# top5.update(acc5[0], input.size(0))", "\n", "\n", "# compute gradient and do SGD step", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.train.validate": [[285, 323], ["train.AverageMeter", "train.AverageMeter", "train.AverageMeter", "model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "time.time", "enumerate", "print", "input.cuda.cuda", "target.cuda.cuda", "model", "criterion", "train.accuracy", "train.AverageMeter.update", "train.AverageMeter.update", "train.AverageMeter.update", "time.time", "criterion.item", "input.cuda.size", "input.cuda.size", "print", "time.time", "len"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.accuracy", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update"], ["\n", "if", "i", "%", "args", ".", "print_freq", "==", "0", ":", "\n", "            ", "print", "(", "'Epoch: [{0}][{1}/{2}]\\t'", "\n", "'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'", "\n", "'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'", "\n", "'Acc@1 {top1.val:.3f} ({top1.avg:.3f})'", ".", "format", "(", "\n", "epoch", ",", "i", ",", "len", "(", "train_loader", ")", ",", "batch_time", "=", "batch_time", ",", "\n", "loss", "=", "losses", ",", "top1", "=", "top1", ",", ")", ")", "\n", "\n", "# iter = epoch * len(train_loader) + i", "\n", "# evaluate_result = speed_test(model, val_loader, 0, 0, 1000)", "\n", "# query_F1_tensor = torch.Tensor(1)", "\n", "# query_F1_tensor.fill_(evaluate_result[\"query_F1\"])", "\n", "# tensorboard.record_val_query_F1(query_F1_tensor, iter)", "\n", "# print('Epoch: [{0}][{1}/{2}]\\t'", "\n", "#       'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'", "\n", "#       'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'", "\n", "#       'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\tValQueryF1 {query_F1:.3f}'.format(", "\n", "#     epoch, i, len(train_loader), batch_time=batch_time,", "\n", "#     loss=losses, top1=top1, query_F1=evaluate_result[\"query_F1\"]))", "\n", "\n", "\n", "\n", "", "", "", "def", "save_checkpoint", "(", "state", ",", "filename", "=", "'traditional_dl.pth.tar'", ")", ":", "\n", "    ", "torch", ".", "save", "(", "state", ",", "filename", ")", "\n", "\n", "\n", "", "class", "AverageMeter", "(", "object", ")", ":", "\n", "    ", "\"\"\"Computes and stores the average and current value\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.train.save_checkpoint": [[324, 326], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save"], "function", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.train.adjust_learning_rate": [[346, 351], ["None"], "function", ["None"], ["\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "            ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.image_rotate_detector.train.accuracy": [[353, 368], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["\n", "", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "main", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.__init__": [[5, 10], ["os.makedirs", "tensorboardX.SummaryWriter"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "folder", ",", "data_prefix", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "folder", ",", "exist_ok", "=", "True", ")", "\n", "self", ".", "writer", "=", "SummaryWriter", "(", "folder", ")", "\n", "self", ".", "export_json_path", "=", "folder", "+", "\"/all_scalars.json\"", "\n", "self", ".", "data_prefix", "=", "data_prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.record_trn_support_loss": [[11, 13], ["tensorboard_helper.TensorBoardWriter.writer.add_scalar"], "methods", ["None"], ["", "def", "record_trn_support_loss", "(", "self", ",", "tensor", ",", "iter", ":", "int", ")", ":", "\n", "        ", "self", ".", "writer", ".", "add_scalar", "(", "\"{}/trn_support_loss\"", ".", "format", "(", "self", ".", "data_prefix", ")", ",", "tensor", ",", "iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.record_trn_support_acc": [[14, 16], ["tensorboard_helper.TensorBoardWriter.writer.add_scalar"], "methods", ["None"], ["", "def", "record_trn_support_acc", "(", "self", ",", "tensor", ",", "iter", ":", "int", ")", ":", "\n", "        ", "self", ".", "writer", ".", "add_scalar", "(", "\"{}/trn_support_acc\"", ".", "format", "(", "self", ".", "data_prefix", ")", ",", "tensor", ",", "iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.record_trn_query_acc": [[17, 19], ["tensorboard_helper.TensorBoardWriter.writer.add_scalar"], "methods", ["None"], ["", "def", "record_trn_query_acc", "(", "self", ",", "tensor", ",", "iter", ":", "int", ")", ":", "\n", "        ", "self", ".", "writer", ".", "add_scalar", "(", "\"{}/trn_query_acc\"", ".", "format", "(", "self", ".", "data_prefix", ")", ",", "tensor", ",", "iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.record_trn_query_loss": [[20, 22], ["tensorboard_helper.TensorBoardWriter.writer.add_scalar"], "methods", ["None"], ["", "def", "record_trn_query_loss", "(", "self", ",", "tensor", ",", "iter", ":", "int", ")", ":", "\n", "        ", "self", ".", "writer", ".", "add_scalar", "(", "\"{}/trn_query_loss\"", ".", "format", "(", "self", ".", "data_prefix", ")", ",", "tensor", ",", "iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.record_val_support_loss": [[23, 25], ["tensorboard_helper.TensorBoardWriter.writer.add_scalar"], "methods", ["None"], ["", "def", "record_val_support_loss", "(", "self", ",", "tensor", ",", "iter", ":", "int", ")", ":", "\n", "        ", "self", ".", "writer", ".", "add_scalar", "(", "\"{}/val_support_loss\"", ".", "format", "(", "self", ".", "data_prefix", ")", ",", "tensor", ",", "iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.record_val_query_loss": [[26, 28], ["tensorboard_helper.TensorBoardWriter.writer.add_scalar"], "methods", ["None"], ["", "def", "record_val_query_loss", "(", "self", ",", "tensor", ",", "iter", ":", "int", ")", ":", "\n", "        ", "self", ".", "writer", ".", "add_scalar", "(", "\"{}/val_query_loss\"", ".", "format", "(", "self", ".", "data_prefix", ")", ",", "tensor", ",", "iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.record_val_support_acc": [[29, 31], ["tensorboard_helper.TensorBoardWriter.writer.add_scalar"], "methods", ["None"], ["", "def", "record_val_support_acc", "(", "self", ",", "tensor", ",", "iter", ":", "int", ")", ":", "\n", "        ", "self", ".", "writer", ".", "add_scalar", "(", "\"{}/val_support_acc\"", ".", "format", "(", "self", ".", "data_prefix", ")", ",", "tensor", ",", "iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.record_val_query_F1": [[32, 34], ["tensorboard_helper.TensorBoardWriter.writer.add_scalar"], "methods", ["None"], ["", "def", "record_val_query_F1", "(", "self", ",", "tensor", ",", "iter", ":", "int", ")", ":", "\n", "        ", "self", ".", "writer", ".", "add_scalar", "(", "\"{}/val_query_F1\"", ".", "format", "(", "self", ".", "data_prefix", ")", ",", "tensor", ",", "iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.record_val_support_twoway_acc": [[35, 37], ["tensorboard_helper.TensorBoardWriter.writer.add_scalar"], "methods", ["None"], ["", "def", "record_val_support_twoway_acc", "(", "self", ",", "tensor", ",", "iter", ":", "int", ")", ":", "\n", "        ", "self", ".", "writer", ".", "add_scalar", "(", "\"{}/val_support_2way_acc\"", ".", "format", "(", "self", ".", "data_prefix", ")", ",", "tensor", ",", "iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.record_val_query_twoway_acc": [[38, 40], ["tensorboard_helper.TensorBoardWriter.writer.add_scalar"], "methods", ["None"], ["", "def", "record_val_query_twoway_acc", "(", "self", ",", "tensor", ",", "iter", ":", "int", ")", ":", "\n", "        ", "self", ".", "writer", ".", "add_scalar", "(", "\"{}/val_query_2way_acc\"", ".", "format", "(", "self", ".", "data_prefix", ")", ",", "tensor", ",", "iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.record_trn_support_twoway_acc": [[41, 43], ["tensorboard_helper.TensorBoardWriter.writer.add_scalar"], "methods", ["None"], ["", "def", "record_trn_support_twoway_acc", "(", "self", ",", "tensor", ",", "iter", ":", "int", ")", ":", "\n", "        ", "self", ".", "writer", ".", "add_scalar", "(", "\"{}/trn_support_2way_acc\"", ".", "format", "(", "self", ".", "data_prefix", ")", ",", "tensor", ",", "iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.record_trn_query_twoway_acc": [[44, 46], ["tensorboard_helper.TensorBoardWriter.writer.add_scalar"], "methods", ["None"], ["", "def", "record_trn_query_twoway_acc", "(", "self", ",", "tensor", ",", "iter", ":", "int", ")", ":", "\n", "        ", "self", ".", "writer", ".", "add_scalar", "(", "\"{}/trn_query_2way_acc\"", ".", "format", "(", "self", ".", "data_prefix", ")", ",", "tensor", ",", "iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.export_json": [[47, 49], ["tensorboard_helper.TensorBoardWriter.writer.export_scalars_to_json"], "methods", ["None"], ["", "def", "export_json", "(", "self", ")", ":", "\n", "        ", "self", ".", "writer", ".", "export_scalars_to_json", "(", "self", ".", "export_json_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.close": [[50, 52], ["tensorboard_helper.TensorBoardWriter.writer.close"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "writer", ".", "close", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.train.parse_args": [[18, 57], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "str", "print", "list", "list"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.train_fingerprint.parse_args"], ["import", "torch", ".", "nn", "as", "nn", "\n", "import", "torch", ".", "nn", ".", "parallel", "\n", "import", "torch", ".", "backends", ".", "cudnn", "as", "cudnn", "\n", "import", "torch", ".", "optim", "\n", "import", "torch", ".", "utils", ".", "data", "\n", "import", "torch", ".", "utils", ".", "data", ".", "distributed", "\n", "import", "torchvision", ".", "models", "as", "models", "\n", "from", "config", "import", "IMAGE_SIZE", ",", "IMAGE_DATA_ROOT", "\n", "import", "config", "\n", "from", "networks", ".", "resnet", "import", "resnet10", ",", "resnet18", "\n", "import", "json", "\n", "from", "config", "import", "IN_CHANNELS", ",", "PY_ROOT", "\n", "from", "dataset", ".", "protocol_enum", "import", "SPLIT_DATA_PROTOCOL", ",", "LOAD_TASK_MODE", "\n", "\n", "from", "deep_learning_adv_detector", ".", "evaluation", ".", "zero_shot_evaluation", "import", "evaluate_zero_shot", "\n", "from", "deep_learning_adv_detector", ".", "evaluation", ".", "white_box_evaluation", "import", "evaluate_whitebox", "\n", "import", "glob", "\n", "from", "deep_learning_adv_detector", ".", "evaluation", ".", "speed_evaluation", "import", "evaluate_speed", "\n", "\n", "model_names", "=", "sorted", "(", "name", "for", "name", "in", "models", ".", "__dict__", "\n", "if", "name", ".", "islower", "(", ")", "and", "not", "name", ".", "startswith", "(", "\"__\"", ")", "\n", "and", "callable", "(", "models", ".", "__dict__", "[", "name", "]", ")", ")", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'PyTorch ImageNet Training'", ")", "\n", "parser", ".", "add_argument", "(", "'-a'", ",", "'--arch'", ",", "type", "=", "str", ",", "default", "=", "\"conv3\"", ",", "choices", "=", "[", "\"resnet10\"", ",", "\"conv3\"", ",", "\"resnet18\"", "]", ")", "\n", "parser", ".", "add_argument", "(", "'-j'", ",", "'--workers'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'number of data loading workers (default: 4)'", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "default", "=", "40", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'number of total epochs to run'", ")", "\n", "parser", ".", "add_argument", "(", "'--start-epoch'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'manual epoch number (useful on restarts)'", ")", "\n", "parser", ".", "add_argument", "(", "'-b'", ",", "'--batch-size'", ",", "default", "=", "500", ",", "type", "=", "int", ",", "\n", "metavar", "=", "'N'", ",", "\n", "help", "=", "'mini-batch size (default: 256), this is the total '", "\n", "'batch size of all GPUs on the current node when '", "\n", "'using Data Parallel or Distributed Data Parallel'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "'--learning-rate'", ",", "default", "=", "0.0001", ",", "type", "=", "float", ",", "\n", "metavar", "=", "'LR'", ",", "help", "=", "'initial learning rate'", ",", "dest", "=", "'lr'", ")", "\n", "parser", ".", "add_argument", "(", "'--momentum'", ",", "default", "=", "0.9", ",", "type", "=", "float", ",", "metavar", "=", "'M'", ",", "\n", "help", "=", "'momentum'", ")", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.train.main": [[58, 111], ["train.parse_args", "random.seed", "numpy.random.seed", "print", "str", "os.makedirs", "meta_adv_detector.meta_adv_det.MetaLearner", "os.path.exists", "print", "meta_adv_detector.meta_adv_det.MetaLearner.train", "os.path.dirname", "print", "torch.load", "meta_adv_detector.meta_adv_det.MetaLearner.network.load_state_dict", "meta_adv_detector.meta_adv_det.MetaLearner.opt.load_state_dict", "print", "meta_adv_detector.evaluation.meta_cross_domain_evaluate", "meta_adv_detector.evaluation.meta_cross_arch_evaluate", "meta_adv_detector.evaluation.meta_white_box_attack_evaluate", "meta_adv_detector.evaluation.meta_zero_shot_evaluate", "meta_adv_detector.evaluation.speed_evaluation.evaluate_speed", "meta_adv_detector.evaluation.meta_ablation_study_evaluate"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.train_fingerprint.parse_args", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.cross_domain_evaluation.meta_cross_domain_evaluate", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.cross_arch_evaluation.meta_cross_arch_evaluate", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.white_box_evaluation.meta_white_box_attack_evaluate", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.zero_shot_evaluation.meta_zero_shot_evaluate", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.speed_evaluation.evaluate_speed", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.ablation_study_evaluation.meta_ablation_study_evaluate"], ["parser", ".", "add_argument", "(", "'--wd'", ",", "'--weight-decay'", ",", "default", "=", "1e-4", ",", "type", "=", "float", ",", "\n", "metavar", "=", "'W'", ",", "help", "=", "'weight decay (default: 1e-4)'", ",", "\n", "dest", "=", "'weight_decay'", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "type", "=", "str", ",", "default", "=", "\"CIFAR-10\"", ")", "\n", "parser", ".", "add_argument", "(", "'-p'", ",", "'--print-freq'", ",", "default", "=", "100", ",", "type", "=", "int", ",", "\n", "metavar", "=", "'N'", ",", "help", "=", "'print frequency (default: 10)'", ")", "\n", "parser", ".", "add_argument", "(", "'--resume'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "'path to latest checkpoint (default: none)'", ")", "\n", "parser", ".", "add_argument", "(", "'-e'", ",", "'--evaluate'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'evaluate_accuracy model on validation set'", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrained'", ",", "dest", "=", "'pretrained'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use pre-trained model'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "default", "=", "None", ",", "type", "=", "int", ",", "\n", "help", "=", "'seed for initializing training. '", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "'GPU id to use.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--protocol\"", ",", "type", "=", "SPLIT_DATA_PROTOCOL", ",", "choices", "=", "list", "(", "SPLIT_DATA_PROTOCOL", ")", ",", "help", "=", "\"split protocol of data\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cross_domain_target\"", ",", "type", "=", "str", ",", "help", "=", "\"the target domain to evaluate_accuracy\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cross_domain_source\"", ",", "type", "=", "str", ",", "help", "=", "\"the target domain to evaluate_accuracy\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--cross_arch_target\"", ",", "type", "=", "str", ",", "help", "=", "\"the target domain to evaluate_accuracy\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cross_arch_source\"", ",", "type", "=", "str", ",", "help", "=", "\"the target domain to evaluate_accuracy\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--num_updates\"", ",", "type", "=", "int", ",", "default", "=", "20", ",", "help", "=", "\"the number of inner updates\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_pkl_path\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"the train task txt file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--study_subject\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--balance\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv_arch\"", ",", "type", "=", "str", ",", "default", "=", "\"conv3\"", ",", "choices", "=", "[", "\"conv3\"", ",", "\"resnet10\"", ",", "\"resnet18\"", "]", ")", "\n", "best_acc1", "=", "0", "\n", "\n", "\n", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "args", ".", "seed", "is", "not", "None", ":", "\n", "        ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "cudnn", ".", "deterministic", "=", "True", "\n", "warnings", ".", "warn", "(", "'You have chosen to seed training. '", "\n", "'This will turn on the CUDNN deterministic setting, '", "\n", "'which can slow down your training considerably! '", "\n", "'You may see unexpected behavior when restarting '", "\n", "'from checkpoints.'", ")", "\n", "", "if", "not", "args", ".", "evaluate", ":", "# not evaluate_accuracy", "\n", "\n", "        ", "model_path", "=", "'{}/train_pytorch_model/DL_DET/DL_DET@{}_{}@model_{}@data_{}@epoch_{}@class_{}@lr_{}@balance_{}.pth.tar'", ".", "format", "(", "\n", "PY_ROOT", ",", "args", ".", "dataset", ",", "args", ".", "protocol", ",", "args", ".", "arch", ",", "args", ".", "adv_arch", ",", "\n", "args", ".", "epochs", ",", "\n", "2", ",", "args", ".", "lr", ",", "args", ".", "balance", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "model_path", ")", ",", "exist_ok", "=", "True", ")", "\n", "main_train_worker", "(", "args", ",", "model_path", ",", "gpu", "=", "str", "(", "args", ".", "gpu", ")", ")", "\n", "\n", "", "else", ":", "# finetune evaluate_accuracy", "\n", "# DL_DET@CIFAR-10_TRAIN_II_TEST_I@conv3@epoch_40@class_2@lr_0.0001.pth.tar", "\n", "        ", "print", "(", "\"Use GPU: {} for training\"", ".", "format", "(", "args", ".", "gpu", ")", ")", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.zeroshot_meta_adv_det.AttributeNetwork.__init__": [[22, 26], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "AttributeNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.zeroshot_meta_adv_det.AttributeNetwork.copy_weights": [[27, 34], ["zip", "net.modules", "zeroshot_meta_adv_det.AttributeNetwork.modules", "isinstance", "isinstance", "isinstance", "m_from.weight.data.clone", "m_from.bias.data.clone"], "methods", ["None"], ["", "def", "copy_weights", "(", "self", ",", "net", ")", ":", "\n", "        ", "''' Set this module's weights to be the same as those of 'net' '''", "\n", "for", "m_from", ",", "m_to", "in", "zip", "(", "net", ".", "modules", "(", ")", ",", "self", ".", "modules", "(", ")", ")", ":", "\n", "            ", "if", "isinstance", "(", "m_to", ",", "nn", ".", "Linear", ")", "or", "isinstance", "(", "m_to", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "m_to", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m_to", ".", "weight", ".", "data", "=", "m_from", ".", "weight", ".", "data", ".", "clone", "(", ")", "\n", "if", "m_to", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "m_to", ".", "bias", ".", "data", "=", "m_from", ".", "bias", ".", "data", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.zeroshot_meta_adv_det.AttributeNetwork.forward": [[36, 42], ["torch.nn.functional.relu", "torch.nn.functional.relu", "zeroshot_meta_adv_det.AttributeNetwork.fc1", "zeroshot_meta_adv_det.AttributeNetwork.fc2"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu"], ["", "", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.zeroshot_meta_adv_det.RelationNetwork.__init__": [[47, 53], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.MSELoss"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "class_num", ")", ":", "\n", "        ", "super", "(", "RelationNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "1", ")", "\n", "self", ".", "loss", "=", "nn", ".", "MSELoss", "(", ")", "\n", "self", ".", "class_num", "=", "class_num", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.zeroshot_meta_adv_det.RelationNetwork.copy_weights": [[54, 61], ["zip", "net.modules", "zeroshot_meta_adv_det.RelationNetwork.modules", "isinstance", "isinstance", "isinstance", "m_from.weight.data.clone", "m_from.bias.data.clone"], "methods", ["None"], ["", "def", "copy_weights", "(", "self", ",", "net", ")", ":", "\n", "        ", "''' Set this module's weights to be the same as those of 'net' '''", "\n", "for", "m_from", ",", "m_to", "in", "zip", "(", "net", ".", "modules", "(", ")", ",", "self", ".", "modules", "(", ")", ")", ":", "\n", "            ", "if", "isinstance", "(", "m_to", ",", "nn", ".", "Linear", ")", "or", "isinstance", "(", "m_to", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "m_to", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m_to", ".", "weight", ".", "data", "=", "m_from", ".", "weight", ".", "data", ".", "clone", "(", ")", "\n", "if", "m_to", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "m_to", ".", "bias", ".", "data", "=", "m_from", ".", "bias", ".", "data", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.zeroshot_meta_adv_det.RelationNetwork.forward": [[62, 67], ["torch.nn.functional.relu", "torch.nn.functional.sigmoid().view", "zeroshot_meta_adv_det.RelationNetwork.loss", "zeroshot_meta_adv_det.RelationNetwork.fc1", "torch.nn.functional.sigmoid", "zeroshot_meta_adv_det.RelationNetwork.fc2"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu"], ["", "", "", "", "def", "forward", "(", "self", ",", "x", ",", "one_hot_label", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "sigmoid", "(", "self", ".", "fc2", "(", "x", ")", ")", ".", "view", "(", "-", "1", ",", "self", ".", "class_num", ")", "\n", "loss", "=", "self", ".", "loss", "(", "x", ",", "one_hot_label", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.zeroshot_meta_adv_det.ZeroShotMetaLearner.__init__": [[72, 125], ["object.__init__", "zeroshot_meta_adv_det.AttributeNetwork", "zeroshot_meta_adv_det.RelationNetwork", "networks.conv3.Conv3", "zeroshot_meta_adv_det.ZeroShotMetaLearner.attr_network.cuda", "zeroshot_meta_adv_det.ZeroShotMetaLearner.relation_network.cuda", "copy.deepcopy", "copy.deepcopy", "torch.optim.Adam", "torch.optim.lr_scheduler.StepLR", "MetaTaskDataset", "torch.utils.data.DataLoader", "meta_adv_detector.tensorboard_helper.TensorBoardWriter", "os.makedirs", "MetaTaskDataset", "torch.utils.data.DataLoader", "zeroshot_meta_adv_det.ZeroShotMetaLearner.attr_network.parameters", "zeroshot_meta_adv_det.ZeroShotMetaLearner.img_feature_extract_network.parameters", "zeroshot_meta_adv_det.ZeroShotMetaLearner.relation_network.parameters"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "dataset", ",", "\n", "num_classes", ",", "\n", "meta_batch_size", ",", "\n", "meta_step_size", ",", "\n", "inner_step_size", ",", "lr_decay_itr", ",", "\n", "epoch", ",", "\n", "num_inner_updates", ",", "load_task_mode", ",", "protocol", ",", "\n", "tot_num_tasks", ",", "num_support", ",", "num_query", ",", "no_random_way", ",", "\n", "tensorboard_data_prefix", ",", "train", "=", "True", ",", "adv_arch", "=", "\"conv3\"", ",", "rotate", "=", "False", ",", "need_val", "=", "False", ")", ":", "\n", "        ", "super", "(", "self", ".", "__class__", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "meta_batch_size", "=", "meta_batch_size", "# task number per batch", "\n", "self", ".", "meta_step_size", "=", "meta_step_size", "\n", "self", ".", "inner_step_size", "=", "inner_step_size", "\n", "self", ".", "lr_decay_itr", "=", "lr_decay_itr", "\n", "self", ".", "epoch", "=", "epoch", "\n", "self", ".", "num_inner_updates", "=", "num_inner_updates", "\n", "self", ".", "test_finetune_updates", "=", "num_inner_updates", "\n", "# Make the nets", "\n", "\n", "if", "train", ":", "\n", "# \u9700\u8981\u4e00\u79cd\u7279\u6b8a\u7684MetaTaskDataset,\u8bad\u7ec3\u9636\u6bb5support set\u5c31\u7ed9\u4e24\u4e2away\u7684class attribute", "\n", "            ", "trn_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "num_classes", ",", "num_support", ",", "num_query", ",", "\n", "dataset", ",", "is_train", "=", "True", ",", "load_mode", "=", "load_task_mode", ",", "\n", "protocol", "=", "protocol", ",", "\n", "no_random_way", "=", "no_random_way", ",", "adv_arch", "=", "adv_arch", ",", "rotate", "=", "rotate", ")", "\n", "self", ".", "train_loader", "=", "DataLoader", "(", "trn_dataset", ",", "batch_size", "=", "meta_batch_size", ",", "shuffle", "=", "True", ",", "num_workers", "=", "0", ",", "pin_memory", "=", "True", ")", "\n", "self", ".", "tensorboard", "=", "TensorBoardWriter", "(", "\"{0}/zeroshot_tensorboard\"", ".", "format", "(", "PY_ROOT", ")", ",", "\n", "tensorboard_data_prefix", ")", "\n", "os", ".", "makedirs", "(", "\"{0}/zeroshot_tensorboard\"", ".", "format", "(", "PY_ROOT", ")", ",", "exist_ok", "=", "True", ")", "\n", "", "if", "need_val", ":", "\n", "            ", "val_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "num_classes", ",", "num_support", ",", "15", ",", "\n", "dataset", ",", "is_train", "=", "False", ",", "load_mode", "=", "load_task_mode", ",", "\n", "protocol", "=", "protocol", ",", "\n", "no_random_way", "=", "True", ",", "adv_arch", "=", "adv_arch", ",", "rotate", "=", "rotate", ")", "\n", "self", ".", "val_loader", "=", "DataLoader", "(", "val_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "num_workers", "=", "0", ",", "pin_memory", "=", "True", ")", "# \u56fa\u5b9a100\u4e2atask\uff0c\u5206\u522b\u6d4b\u6bcf\u4e2atask\u7684\u51c6\u786e\u7387", "\n", "\n", "", "self", ".", "hidden_feature_size", "=", "2048", "\n", "self", ".", "attr_network", "=", "AttributeNetwork", "(", "312", ",", "1200", ",", "self", ".", "hidden_feature_size", ")", "# output 2048", "\n", "self", ".", "relation_network", "=", "RelationNetwork", "(", "2", "*", "self", ".", "hidden_feature_size", ",", "1200", ",", "2", ")", "\n", "self", ".", "img_feature_extract_network", "=", "Conv3", "(", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", ",", "self", ".", "hidden_feature_size", ")", "\n", "self", ".", "attr_network", ".", "cuda", "(", ")", "\n", "self", ".", "relation_network", ".", "cuda", "(", ")", "\n", "\n", "self", ".", "inner_attr_network", "=", "copy", ".", "deepcopy", "(", "self", ".", "attr_network", ")", "# deal with each task", "\n", "self", ".", "inner_relation_network", "=", "copy", ".", "deepcopy", "(", "self", ".", "relation_network", ")", "# deal with each task", "\n", "\n", "# \u6ca1\u6709\u5185\u90e8\u66f4\u65b0\uff0c\u53ea\u6709\u5916\u90e8\u66f4\u65b0\uff0coptimizer\u62e5\u6709\u4e24\u4e2a\u7f51\u7edc\u7684\u53c2\u6570", "\n", "self", ".", "opt_attr_net", "=", "Adam", "(", "self", ".", "img_feature_extract_network", ".", "parameters", "(", ")", "+", "self", ".", "relation_network", ".", "parameters", "(", ")", "+", "self", ".", "attr_network", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "meta_step_size", ")", "\n", "self", ".", "sched", "=", "StepLR", "(", "self", ".", "opt_attr_net", ",", "step_size", "=", "30000", ",", "gamma", "=", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.zeroshot_meta_adv_det.ZeroShotMetaLearner.meta_update": [[126, 150], ["forward_pass", "zeroshot_meta_adv_det.ZeroShotMetaLearner.network.named_parameters", "zeroshot_meta_adv_det.ZeroShotMetaLearner.opt.zero_grad", "loss.backward", "zeroshot_meta_adv_det.ZeroShotMetaLearner.opt.step", "sum", "hooks.append", "h.remove", "grads[].keys", "v.register_hook", "len", "zeroshot_meta_adv_det.ZeroShotMetaLearner.meta_update.get_closure"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward_pass"], ["", "def", "meta_update", "(", "self", ",", "grads", ",", "query_images", ",", "query_labels", ")", ":", "\n", "        ", "in_", ",", "target", "=", "query_images", "[", "0", "]", ",", "query_labels", "[", "0", "]", "\n", "# We use a dummy forward / backward pass to get the correct grads into self.net", "\n", "loss", ",", "out", "=", "forward_pass", "(", "self", ".", "network", ",", "in_", ",", "target", ")", "# \u5176\u5b9e\u4f20\u8c01\u65e0\u6240\u8c13\uff0c\u56e0\u4e3aloss.backward\u8c03\u7528\u7684\u65f6\u5019\uff0c\u4f1a\u7528\u5916\u90e8\u66f4\u65b0\u7684\u68af\u5ea6\u7684\u6c42\u548c\u6765\u66ff\u6362\u6389loss.backward\u81ea\u5df1\u7b97\u51fa\u6765\u7684\u68af\u5ea6\u503c", "\n", "# Unpack the list of grad dicts", "\n", "gradients", "=", "{", "k", "[", "len", "(", "\"network.\"", ")", ":", "]", ":", "sum", "(", "d", "[", "k", "]", "for", "d", "in", "grads", ")", "for", "k", "in", "grads", "[", "0", "]", ".", "keys", "(", ")", "}", "# \u628aN\u4e2atask\u7684grad\u52a0\u8d77\u6765", "\n", "# Register a hook on each parameter in the net that replaces the current dummy grad", "\n", "# with our grads accumulated across the meta-batch", "\n", "hooks", "=", "[", "]", "\n", "for", "(", "k", ",", "v", ")", "in", "self", ".", "network", ".", "named_parameters", "(", ")", ":", "\n", "            ", "def", "get_closure", "(", ")", ":", "\n", "                ", "key", "=", "k", "\n", "def", "replace_grad", "(", "grad", ")", ":", "\n", "                    ", "return", "gradients", "[", "key", "]", "\n", "", "return", "replace_grad", "\n", "", "hooks", ".", "append", "(", "v", ".", "register_hook", "(", "get_closure", "(", ")", ")", ")", "\n", "# Compute grads for current step, replace with summed gradients as defined by hook", "\n", "", "self", ".", "opt", ".", "zero_grad", "(", ")", "# \u6e05\u7a7a\u68af\u5ea6", "\n", "loss", ".", "backward", "(", ")", "# \u5f53\u8fd9\u53e5\u8bdd\u8c03\u7528\u7684\u65f6\u5019\uff0chook\u6267\u884c", "\n", "# Update the net parameters with the accumulated gradient according to optimizer", "\n", "self", ".", "opt", ".", "step", "(", ")", "\n", "# Remove the hooks before next training phase", "\n", "for", "h", "in", "hooks", ":", "\n", "            ", "h", ".", "remove", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.zeroshot_meta_adv_det.ZeroShotMetaLearner.train": [[152, 193], ["range", "enumerate", "torch.save", "zeroshot_meta_adv_det.ZeroShotMetaLearner.adjust_learning_rate", "zeroshot_meta_adv_det.ZeroShotMetaLearner.img_feature_extract_network", "all_query_feature.view.view.view", "range", "zeroshot_meta_adv_det.ZeroShotMetaLearner.meta_update", "grads.clear", "support_attribute_feature.cuda", "support_labels.cuda", "query_images.cuda", "query_labels.cuda", "support_attribute_feature.size", "support_attribute_feature.size", "zeroshot_meta_adv_det.ZeroShotMetaLearner.inner_attr_network.copy_weights", "zeroshot_meta_adv_det.ZeroShotMetaLearner.inner_relation_network.copy_weights", "zeroshot_meta_adv_det.ZeroShotMetaLearner.inner_attr_network", "torch.cat().view", "zeroshot_meta_adv_det.ZeroShotMetaLearner.relation_network", "torch.autograd.grad", "torch.autograd.grad", "meta_grads.update", "grads.append", "zeroshot_meta_adv_det.ZeroShotMetaLearner.test_task_F1", "zeroshot_meta_adv_det.ZeroShotMetaLearner.network.state_dict", "zeroshot_meta_adv_det.ZeroShotMetaLearner.opt.state_dict", "len", "zeroshot_meta_adv_det.ZeroShotMetaLearner.inner_attr_network.parameters", "zeroshot_meta_adv_det.ZeroShotMetaLearner.inner_relation_network.parameters", "torch.cat", "zip", "zip", "zeroshot_meta_adv_det.ZeroShotMetaLearner.inner_attr_network.named_parameters", "zeroshot_meta_adv_det.ZeroShotMetaLearner.inner_relation_network.named_parameters"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.adjust_learning_rate", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.meta_adv_det.MetaLearner.meta_update", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.ResNet.copy_weights", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.ResNet.copy_weights", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.ablation_study.meta_adv_det_task_net.MetaLearnerTasknetOnly.test_task_F1"], ["", "", "def", "train", "(", "self", ",", "model_path", ",", "resume_epoch", "=", "0", ",", "need_val", "=", "False", ")", ":", "\n", "# mtr_loss, mtr_acc, mval_loss, mval_acc = [], [], [], []", "\n", "        ", "PRINT_INTERVAL", "=", "100", "\n", "\n", "for", "epoch", "in", "range", "(", "resume_epoch", ",", "self", ".", "epoch", ")", ":", "\n", "# Evaluate on test tasks", "\n", "# Collect a meta batch update", "\n", "# Save a model snapshot every now and then", "\n", "\n", "            ", "for", "i", ",", "(", "support_attribute_feature", ",", "_", ",", "support_labels", ",", "query_images", ",", "_", ",", "query_labels", ",", "_", ")", "in", "enumerate", "(", "self", ".", "train_loader", ")", ":", "\n", "                ", "itr", "=", "epoch", "*", "len", "(", "self", ".", "train_loader", ")", "+", "i", "\n", "self", ".", "adjust_learning_rate", "(", "itr", ",", "self", ".", "meta_step_size", ",", "self", ".", "lr_decay_itr", ")", "\n", "grads", "=", "[", "]", "\n", "support_attribute_feature", ",", "support_labels", ",", "query_images", ",", "query_labels", "=", "support_attribute_feature", ".", "cuda", "(", ")", ",", "support_labels", ".", "cuda", "(", ")", ",", "query_images", ".", "cuda", "(", ")", ",", "query_labels", ".", "cuda", "(", ")", "\n", "all_query_feature", "=", "self", ".", "img_feature_extract_network", "(", "query_images", ")", "\n", "all_query_feature", "=", "all_query_feature", ".", "view", "(", "support_attribute_feature", ".", "size", "(", "0", ")", ",", "-", "1", ",", "self", ".", "hidden_feature_size", ")", "\n", "for", "task_idx", "in", "range", "(", "support_attribute_feature", ".", "size", "(", "0", ")", ")", ":", "# shape = (task_num, num, feature_dim)", "\n", "                    ", "self", ".", "inner_attr_network", ".", "copy_weights", "(", "self", ".", "attr_network", ")", "\n", "self", ".", "inner_relation_network", ".", "copy_weights", "(", "self", ".", "relation_network", ")", "\n", "attr_feature", "=", "self", ".", "inner_attr_network", "(", "support_attribute_feature", "[", "task_idx", "]", ")", "\n", "img_feature", "=", "all_query_feature", "[", "task_idx", "]", "\n", "relation_pairs", "=", "torch", ".", "cat", "(", "(", "attr_feature", ",", "img_feature", ")", ",", "1", ")", ".", "view", "(", "-", "1", ",", "4096", ")", "\n", "loss", "=", "self", ".", "relation_network", "(", "relation_pairs", ")", "\n", "grad_1", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "self", ".", "inner_attr_network", ".", "parameters", "(", ")", ")", "\n", "grad_2", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "self", ".", "inner_relation_network", ".", "parameters", "(", ")", ")", "\n", "meta_grads", "=", "{", "name", ":", "g", "for", "(", "(", "name", ",", "_", ")", ",", "g", ")", "in", "zip", "(", "self", ".", "inner_attr_network", ".", "named_parameters", "(", ")", ",", "grad_1", ")", "}", "\n", "meta_grads_2", "=", "{", "name", ":", "g", "for", "(", "(", "name", ",", "_", ")", ",", "g", ")", "in", "zip", "(", "self", ".", "inner_relation_network", ".", "named_parameters", "(", ")", ",", "grad_2", ")", "}", "\n", "meta_grads", ".", "update", "(", "meta_grads_2", ")", "\n", "grads", ".", "append", "(", "meta_grads", ")", "\n", "\n", "# Perform the meta update", "\n", "# print('Meta update', itr)", "\n", "", "self", ".", "meta_update", "(", "grads", ",", "query_images", ",", "query_labels", ")", "\n", "grads", ".", "clear", "(", ")", "\n", "if", "itr", "%", "100", "==", "0", "and", "need_val", ":", "\n", "                    ", "self", ".", "test_task_F1", "(", "itr", ",", "limit", "=", "200", ")", "\n", "", "", "torch", ".", "save", "(", "{", "\n", "'epoch'", ":", "epoch", "+", "1", ",", "\n", "'state_dict'", ":", "self", ".", "network", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "self", ".", "opt", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "model_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.zeroshot_meta_adv_det.ZeroShotMetaLearner.adjust_learning_rate": [[195, 203], ["int", "int"], "methods", ["None"], ["", "", "def", "adjust_learning_rate", "(", "self", ",", "itr", ",", "meta_lr", ",", "lr_decay_itr", ")", ":", "\n", "        ", "\"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"", "\n", "if", "lr_decay_itr", ">", "0", ":", "\n", "            ", "if", "int", "(", "itr", "%", "lr_decay_itr", ")", "==", "0", "and", "itr", ">", "0", ":", "\n", "                ", "meta_lr", "=", "meta_lr", "/", "(", "10", "**", "int", "(", "itr", "/", "lr_decay_itr", ")", ")", "\n", "self", ".", "fast_net", ".", "step_size", "=", "self", ".", "fast_net", ".", "step_size", "/", "10", "\n", "for", "param_group", "in", "self", ".", "opt", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "'lr'", "]", "=", "meta_lr", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.meta_adv_det.MetaLearner.__init__": [[23, 76], ["object.__init__", "meta_adv_det.MetaLearner.network.cuda", "meta_adv_detector.inner_loop.InnerLoop", "meta_adv_det.MetaLearner.fast_net.cuda", "torch.optim.Adam", "networks.conv3.Conv3", "dataset.meta_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "meta_adv_detector.tensorboard_helper.TensorBoardWriter", "os.makedirs", "dataset.meta_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "meta_adv_det.MetaLearner.network.parameters", "networks.meta_network.MetaNetwork", "networks.resnet.resnet10", "networks.meta_network.MetaNetwork", "networks.resnet.resnet18"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet10", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet18"], ["    ", "def", "__init__", "(", "self", ",", "\n", "dataset", ",", "\n", "num_classes", ",", "\n", "meta_batch_size", ",", "\n", "meta_step_size", ",", "\n", "inner_step_size", ",", "lr_decay_itr", ",", "\n", "epoch", ",", "\n", "num_inner_updates", ",", "load_task_mode", ",", "protocol", ",", "arch", ",", "\n", "tot_num_tasks", ",", "num_support", ",", "num_query", ",", "no_random_way", ",", "\n", "tensorboard_data_prefix", ",", "train", "=", "True", ",", "adv_arch", "=", "\"conv4\"", ",", "need_val", "=", "False", ")", ":", "\n", "        ", "super", "(", "self", ".", "__class__", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "meta_batch_size", "=", "meta_batch_size", "# task number per batch", "\n", "self", ".", "meta_step_size", "=", "meta_step_size", "\n", "self", ".", "inner_step_size", "=", "inner_step_size", "\n", "self", ".", "lr_decay_itr", "=", "lr_decay_itr", "\n", "self", ".", "epoch", "=", "epoch", "\n", "self", ".", "num_inner_updates", "=", "num_inner_updates", "\n", "self", ".", "test_finetune_updates", "=", "num_inner_updates", "\n", "# Make the nets", "\n", "if", "arch", "==", "\"conv3\"", ":", "\n", "# network = FourConvs(IN_CHANNELS[self.dataset_name], IMAGE_SIZE[self.dataset_name], num_classes)", "\n", "            ", "network", "=", "Conv3", "(", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", ",", "num_classes", ")", "\n", "", "elif", "arch", "==", "\"resnet10\"", ":", "\n", "            ", "network", "=", "MetaNetwork", "(", "resnet10", "(", "num_classes", ",", "in_channels", "=", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ",", "pretrained", "=", "False", ")", ",", "\n", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", ")", "\n", "", "elif", "arch", "==", "\"resnet18\"", ":", "\n", "            ", "network", "=", "MetaNetwork", "(", "resnet18", "(", "num_classes", ",", "in_channels", "=", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ",", "pretrained", "=", "False", ")", ",", "\n", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", ")", "\n", "\n", "", "self", ".", "network", "=", "network", "\n", "self", ".", "network", ".", "cuda", "(", ")", "\n", "if", "train", ":", "\n", "            ", "trn_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "num_classes", ",", "num_support", ",", "num_query", ",", "\n", "dataset", ",", "is_train", "=", "True", ",", "load_mode", "=", "load_task_mode", ",", "\n", "protocol", "=", "protocol", ",", "\n", "no_random_way", "=", "no_random_way", ",", "adv_arch", "=", "adv_arch", ",", "fetch_attack_name", "=", "False", ")", "\n", "# task number per mini-batch is controlled by DataLoader", "\n", "self", ".", "train_loader", "=", "DataLoader", "(", "trn_dataset", ",", "batch_size", "=", "meta_batch_size", ",", "shuffle", "=", "True", ",", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "\n", "self", ".", "tensorboard", "=", "TensorBoardWriter", "(", "\"{0}/pytorch_MAML_tensorboard\"", ".", "format", "(", "PY_ROOT", ")", ",", "\n", "tensorboard_data_prefix", ")", "\n", "os", ".", "makedirs", "(", "\"{0}/pytorch_MAML_tensorboard\"", ".", "format", "(", "PY_ROOT", ")", ",", "exist_ok", "=", "True", ")", "\n", "", "if", "need_val", ":", "\n", "            ", "val_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "num_classes", ",", "num_support", ",", "15", ",", "\n", "dataset", ",", "is_train", "=", "False", ",", "load_mode", "=", "load_task_mode", ",", "\n", "protocol", "=", "protocol", ",", "\n", "no_random_way", "=", "True", ",", "adv_arch", "=", "adv_arch", ",", "fetch_attack_name", "=", "False", ")", "\n", "self", ".", "val_loader", "=", "DataLoader", "(", "val_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "# \u56fa\u5b9a100\u4e2atask\uff0c\u5206\u522b\u6d4b\u6bcf\u4e2atask\u7684\u51c6\u786e\u7387", "\n", "", "self", ".", "fast_net", "=", "InnerLoop", "(", "self", ".", "network", ",", "self", ".", "num_inner_updates", ",", "\n", "self", ".", "inner_step_size", ",", "self", ".", "meta_batch_size", ")", "# \u5e76\u884c\u6267\u884c\u6bcf\u4e2atask", "\n", "self", ".", "fast_net", ".", "cuda", "(", ")", "\n", "self", ".", "opt", "=", "Adam", "(", "self", ".", "network", ".", "parameters", "(", ")", ",", "lr", "=", "meta_step_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.meta_adv_det.MetaLearner.meta_update": [[79, 103], ["forward_pass", "meta_adv_det.MetaLearner.network.named_parameters", "meta_adv_det.MetaLearner.opt.zero_grad", "loss.backward", "meta_adv_det.MetaLearner.opt.step", "sum", "hooks.append", "h.remove", "grads[].keys", "v.register_hook", "len", "meta_adv_det.MetaLearner.meta_update.get_closure"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward_pass"], ["", "def", "meta_update", "(", "self", ",", "grads", ",", "query_images", ",", "query_labels", ")", ":", "\n", "        ", "in_", ",", "target", "=", "query_images", "[", "0", "]", ",", "query_labels", "[", "0", "]", "\n", "# We use a dummy forward / backward pass to get the correct grads into self.net", "\n", "loss", ",", "out", "=", "forward_pass", "(", "self", ".", "network", ",", "in_", ",", "target", ")", "# \u5176\u5b9e\u4f20\u8c01\u65e0\u6240\u8c13\uff0c\u56e0\u4e3aloss.backward\u8c03\u7528\u7684\u65f6\u5019\uff0c\u4f1a\u7528\u5916\u90e8\u66f4\u65b0\u7684\u68af\u5ea6\u7684\u6c42\u548c\u6765\u66ff\u6362\u6389loss.backward\u81ea\u5df1\u7b97\u51fa\u6765\u7684\u68af\u5ea6\u503c", "\n", "# Unpack the list of grad dicts", "\n", "gradients", "=", "{", "k", "[", "len", "(", "\"network.\"", ")", ":", "]", ":", "sum", "(", "d", "[", "k", "]", "for", "d", "in", "grads", ")", "for", "k", "in", "grads", "[", "0", "]", ".", "keys", "(", ")", "}", "# \u628aN\u4e2atask\u7684grad\u52a0\u8d77\u6765", "\n", "# Register a hook on each parameter in the net that replaces the current dummy grad", "\n", "# with our grads accumulated across the meta-batch", "\n", "hooks", "=", "[", "]", "\n", "for", "(", "k", ",", "v", ")", "in", "self", ".", "network", ".", "named_parameters", "(", ")", ":", "\n", "            ", "def", "get_closure", "(", ")", ":", "\n", "                ", "key", "=", "k", "\n", "def", "replace_grad", "(", "grad", ")", ":", "\n", "                    ", "return", "gradients", "[", "key", "]", "\n", "", "return", "replace_grad", "\n", "", "hooks", ".", "append", "(", "v", ".", "register_hook", "(", "get_closure", "(", ")", ")", ")", "\n", "# Compute grads for current step, replace with summed gradients as defined by hook", "\n", "", "self", ".", "opt", ".", "zero_grad", "(", ")", "# \u6e05\u7a7a\u68af\u5ea6", "\n", "loss", ".", "backward", "(", ")", "# \u5f53\u8fd9\u53e5\u8bdd\u8c03\u7528\u7684\u65f6\u5019\uff0chook\u6267\u884c", "\n", "# Update the net parameters with the accumulated gradient according to optimizer", "\n", "self", ".", "opt", ".", "step", "(", ")", "\n", "# Remove the hooks before next training phase", "\n", "for", "h", "in", "hooks", ":", "\n", "            ", "h", ".", "remove", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.meta_adv_det.MetaLearner.test_zero_shot_with_finetune_trainset": [[105, 152], ["copy.deepcopy", "np.mean", "print", "range", "query_images.size", "copy.deepcopy.copy_weights", "copy.deepcopy.cuda", "copy.deepcopy.train", "copy.deepcopy.modules", "torch.optim.SGD", "copy.deepcopy.eval", "evaluate_two_way", "query_F1_list.append", "isinstance", "copy.deepcopy.parameters", "task_test_img.cuda.cuda.cuda", "test_adv_labels.cuda.cuda.cuda", "range", "m.eval", "task_test_img.cuda.cuda.size", "finetune_target.size", "range", "forward_pass", "torch.optim.SGD.zero_grad", "loss.backward", "torch.optim.SGD.step"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.ResNet.copy_weights", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.evaluate_two_way", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward_pass"], ["", "", "def", "test_zero_shot_with_finetune_trainset", "(", "self", ")", ":", "\n", "        ", "test_net", "=", "copy", ".", "deepcopy", "(", "self", ".", "network", ")", "\n", "# Select ten tasks randomly from the test set to evaluate_accuracy on", "\n", "query_F1_list", "=", "[", "]", "\n", "finetune_img_count", "=", "200", "# \u627e100\u5f20\u56fe\u8fdb\u884cfinetune", "\n", "\n", "for", "_", ",", "_", ",", "_", ",", "query_images", ",", "_", ",", "query_labels", ",", "_", "in", "self", ".", "val_loader", ":", "\n", "            ", "for", "task_idx", "in", "range", "(", "query_images", ".", "size", "(", "0", ")", ")", ":", "# \u9009\u62e9100\u4e2atask", "\n", "# Make a test net with same parameters as our current net", "\n", "                ", "test_net", ".", "copy_weights", "(", "self", ".", "network", ")", "\n", "test_net", ".", "cuda", "(", ")", "\n", "test_net", ".", "train", "(", ")", "\n", "current_fine_tune_idx", "=", "0", "\n", "for", "m", "in", "test_net", ".", "modules", "(", ")", ":", "\n", "                    ", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                        ", "m", ".", "eval", "(", ")", "\n", "", "", "test_opt", "=", "SGD", "(", "test_net", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "inner_step_size", ")", "\n", "for", "_", ",", "_", ",", "_", ",", "task_test_img", ",", "_", ",", "test_adv_labels", ",", "_", "in", "self", ".", "train_loader", ":", "\n", "                    ", "task_test_img", "=", "task_test_img", ".", "cuda", "(", ")", "\n", "test_adv_labels", "=", "test_adv_labels", ".", "cuda", "(", ")", "\n", "for", "inner_idx", "in", "range", "(", "task_test_img", ".", "size", "(", "0", ")", ")", ":", "\n", "                        ", "finetune_img", "=", "task_test_img", "[", "inner_idx", "]", "\n", "finetune_target", "=", "test_adv_labels", "[", "inner_idx", "]", "\n", "# finetune_target = (finetune_target == task_positive_label).astype(np.int32)", "\n", "current_fine_tune_idx", "+=", "finetune_target", ".", "size", "(", "0", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_inner_updates", ")", ":", "# \u5148fine_tune", "\n", "                            ", "loss", ",", "_", "=", "forward_pass", "(", "test_net", ",", "finetune_img", ",", "finetune_target", ")", "\n", "# print(loss.item())", "\n", "test_opt", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "test_opt", ".", "step", "(", ")", "\n", "", "if", "current_fine_tune_idx", ">", "finetune_img_count", ":", "\n", "                            ", "break", "\n", "", "", "if", "current_fine_tune_idx", ">", "finetune_img_count", ":", "\n", "                        ", "break", "# \u4e00\u76f4break\u5230\u5916\u5c42", "\n", "\n", "", "", "test_net", ".", "eval", "(", ")", "\n", "# Evaluate the trained model on train and val examples", "\n", "query_accuracy", ",", "query_F1", "=", "evaluate_two_way", "(", "test_net", ",", "query_images", "[", "task_idx", "]", ",", "query_labels", "[", "task_idx", "]", ")", "\n", "query_F1_list", ".", "append", "(", "query_F1", ")", "\n", "\n", "", "", "query_F1", "=", "np", ".", "mean", "(", "query_F1_list", ")", "\n", "result_json", "=", "{", "\"query_F1\"", ":", "query_F1", ",", "\n", "\"num_updates\"", ":", "self", ".", "num_inner_updates", "}", "\n", "print", "(", "'Validation Set Query F1: {}'", ".", "format", "(", "query_F1", ")", ")", "\n", "del", "test_net", "\n", "return", "result_json", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.meta_adv_det.MetaLearner.train": [[154, 189], ["range", "enumerate", "torch.save", "meta_adv_det.MetaLearner.adjust_learning_rate", "range", "meta_adv_det.MetaLearner.meta_update", "grads.clear", "support_images.cuda", "support_labels.cuda", "query_images.cuda", "query_labels.cuda", "support_images.size", "meta_adv_det.MetaLearner.fast_net.copy_weights", "meta_adv_det.MetaLearner.fast_net.forward", "grads.append", "evaluation_toolkit.evaluation.finetune_eval_task_accuracy", "torch.Tensor", "torch.Tensor.fill_", "meta_adv_det.MetaLearner.tensorboard.record_val_query_F1", "meta_adv_det.MetaLearner.network.state_dict", "meta_adv_det.MetaLearner.opt.state_dict", "len"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.adjust_learning_rate", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.meta_adv_det.MetaLearner.meta_update", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.ResNet.copy_weights", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.Identity.forward", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation_toolkit.evaluation.finetune_eval_task_accuracy", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.record_val_query_F1"], ["", "def", "train", "(", "self", ",", "model_path", ",", "resume_epoch", "=", "0", ",", "need_val", "=", "False", ")", ":", "\n", "# mtr_loss, mtr_acc, mval_loss, mval_acc = [], [], [], []", "\n", "\n", "        ", "for", "epoch", "in", "range", "(", "resume_epoch", ",", "self", ".", "epoch", ")", ":", "\n", "# Evaluate on test tasks", "\n", "# Collect a meta batch update", "\n", "# Save a model snapshot every now and then", "\n", "\n", "            ", "for", "i", ",", "(", "support_images", ",", "_", ",", "support_labels", ",", "query_images", ",", "_", ",", "query_labels", ",", "*", "_", ")", "in", "enumerate", "(", "self", ".", "train_loader", ")", ":", "\n", "                ", "itr", "=", "epoch", "*", "len", "(", "self", ".", "train_loader", ")", "+", "i", "\n", "self", ".", "adjust_learning_rate", "(", "itr", ",", "self", ".", "meta_step_size", ",", "self", ".", "lr_decay_itr", ")", "\n", "grads", "=", "[", "]", "\n", "support_images", ",", "support_labels", ",", "query_images", ",", "query_labels", "=", "support_images", ".", "cuda", "(", ")", ",", "support_labels", ".", "cuda", "(", ")", ",", "query_images", ".", "cuda", "(", ")", ",", "query_labels", ".", "cuda", "(", ")", "\n", "for", "task_idx", "in", "range", "(", "support_images", ".", "size", "(", "0", ")", ")", ":", "\n", "                    ", "self", ".", "fast_net", ".", "copy_weights", "(", "self", ".", "network", ")", "\n", "# fast_net only forward one task's data", "\n", "g", "=", "self", ".", "fast_net", ".", "forward", "(", "support_images", "[", "task_idx", "]", ",", "query_images", "[", "task_idx", "]", ",", "support_labels", "[", "task_idx", "]", ",", "query_labels", "[", "task_idx", "]", ")", "\n", "# (trl, tra, vall, vala) = metrics", "\n", "grads", ".", "append", "(", "g", ")", "\n", "\n", "# Perform the meta update", "\n", "# print('Meta update', itr)", "\n", "", "self", ".", "meta_update", "(", "grads", ",", "query_images", ",", "query_labels", ")", "\n", "grads", ".", "clear", "(", ")", "\n", "if", "itr", "%", "1000", "==", "0", "and", "need_val", ":", "\n", "                    ", "result_json", "=", "finetune_eval_task_accuracy", "(", "self", ".", "network", ",", "self", ".", "val_loader", ",", "self", ".", "inner_step_size", ",", "\n", "self", ".", "test_finetune_updates", ",", "update_BN", "=", "True", ")", "\n", "query_F1_tensor", "=", "torch", ".", "Tensor", "(", "1", ")", "\n", "query_F1_tensor", ".", "fill_", "(", "result_json", "[", "\"query_F1\"", "]", ")", "\n", "self", ".", "tensorboard", ".", "record_val_query_F1", "(", "query_F1_tensor", ",", "itr", ")", "\n", "", "", "torch", ".", "save", "(", "{", "\n", "'epoch'", ":", "epoch", "+", "1", ",", "\n", "'state_dict'", ":", "self", ".", "network", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "self", ".", "opt", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "model_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.meta_adv_det.MetaLearner.adjust_learning_rate": [[191, 199], ["int", "int"], "methods", ["None"], ["", "", "def", "adjust_learning_rate", "(", "self", ",", "itr", ",", "meta_lr", ",", "lr_decay_itr", ")", ":", "\n", "        ", "\"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"", "\n", "if", "lr_decay_itr", ">", "0", ":", "\n", "            ", "if", "int", "(", "itr", "%", "lr_decay_itr", ")", "==", "0", "and", "itr", ">", "0", ":", "\n", "                ", "meta_lr", "=", "meta_lr", "/", "(", "10", "**", "int", "(", "itr", "/", "lr_decay_itr", ")", ")", "\n", "self", ".", "fast_net", ".", "step_size", "=", "self", ".", "fast_net", ".", "step_size", "/", "10", "\n", "for", "param_group", "in", "self", ".", "opt", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "'lr'", "]", "=", "meta_lr", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.inner_loop.InnerLoop.__init__": [[15, 25], ["torch.nn.Module.__init__", "copy.deepcopy", "torch.nn.CrossEntropyLoss"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__"], ["def", "__init__", "(", "self", ",", "network", ",", "num_updates", ",", "step_size", ",", "meta_batch_size", ")", ":", "\n", "        ", "super", "(", "InnerLoop", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "network", "=", "copy", ".", "deepcopy", "(", "network", ")", "\n", "# Number of updates to be taken", "\n", "self", ".", "num_updates", "=", "num_updates", "\n", "# Step size for the updates", "\n", "self", ".", "step_size", "=", "step_size", "\n", "self", ".", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "# for loss normalization ", "\n", "self", ".", "meta_batch_size", "=", "meta_batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.inner_loop.InnerLoop.copy_weights": [[26, 29], ["inner_loop.InnerLoop.network.copy_weights"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.ResNet.copy_weights"], ["", "def", "copy_weights", "(", "self", ",", "net", ")", ":", "\n", "        ", "''' Set this module's weights to be the same as those of 'net' '''", "\n", "self", ".", "network", ".", "copy_weights", "(", "net", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.inner_loop.InnerLoop.net_forward": [[30, 32], ["inner_loop.InnerLoop.network.net_forward"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.mlp_detector.MLP.net_forward"], ["", "def", "net_forward", "(", "self", ",", "x", ",", "weights", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "network", ".", "net_forward", "(", "x", ",", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.inner_loop.InnerLoop.forward_pass": [[33, 41], ["in_.cuda", "target.cuda", "inner_loop.InnerLoop.net_forward", "inner_loop.InnerLoop.loss_fn"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.mlp_detector.MLP.net_forward"], ["", "def", "forward_pass", "(", "self", ",", "in_", ",", "target", ",", "weights", "=", "None", ")", ":", "\n", "        ", "''' Run data through net, return loss and output '''", "\n", "input_var", "=", "in_", ".", "cuda", "(", ")", "\n", "target_var", "=", "target", ".", "cuda", "(", ")", "\n", "# Run the batch through the net, compute loss", "\n", "out", "=", "self", ".", "net_forward", "(", "input_var", ",", "weights", ")", "\n", "loss", "=", "self", ".", "loss_fn", "(", "out", ",", "target_var", ")", "\n", "return", "loss", ",", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.inner_loop.InnerLoop.forward": [[42, 63], ["collections.OrderedDict", "range", "inner_loop.InnerLoop.forward_pass", "torch.autograd.grad", "in_support.detach", "in_query.detach", "target_support.detach", "target_query.detach", "collections.OrderedDict", "inner_loop.InnerLoop.parameters", "inner_loop.InnerLoop.forward_pass", "torch.autograd.grad", "inner_loop.InnerLoop.forward_pass", "torch.autograd.grad", "zip", "inner_loop.InnerLoop.network.named_parameters", "inner_loop.InnerLoop.parameters", "collections.OrderedDict.values", "inner_loop.InnerLoop.named_parameters", "zip", "collections.OrderedDict.items"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward_pass", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward_pass", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward_pass"], ["", "def", "forward", "(", "self", ",", "in_support", ",", "in_query", ",", "target_support", ",", "target_query", ")", ":", "\n", "        ", "in_support", ",", "in_query", ",", "target_support", ",", "target_query", "=", "in_support", ".", "detach", "(", ")", ",", "in_query", ".", "detach", "(", ")", ",", "target_support", ".", "detach", "(", ")", ",", "target_query", ".", "detach", "(", ")", "\n", "##### Test net before training, should be random accuracy ####", "\n", "fast_weights", "=", "OrderedDict", "(", "(", "name", ",", "param", ")", "for", "(", "name", ",", "param", ")", "in", "self", ".", "network", ".", "named_parameters", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_updates", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "loss", ",", "_", "=", "self", ".", "forward_pass", "(", "in_support", ",", "target_support", ")", "\n", "grads", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "self", ".", "parameters", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss", ",", "_", "=", "self", ".", "forward_pass", "(", "in_support", ",", "target_support", ",", "fast_weights", ")", "\n", "grads", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "fast_weights", ".", "values", "(", ")", ")", "\n", "", "fast_weights", "=", "OrderedDict", "(", "(", "name", ",", "param", "-", "self", ".", "step_size", "*", "grad", ")", "for", "(", "(", "name", ",", "param", ")", ",", "grad", ")", "in", "zip", "(", "fast_weights", ".", "items", "(", ")", ",", "grads", ")", ")", "\n", "##### Test net after training, should be better than random ####", "\n", "# tr_post_loss, tr_post_acc, tr_post_two_acc = evaluate_accuracy(self, in_support, target_support,positive_label, weights=fast_weights)", "\n", "# val_post_loss, val_post_acc, val_post_two_acc = evaluate_accuracy(self, in_query, target_query,positive_label, weights=fast_weights)", "\n", "# Compute the meta gradient and return it", "\n", "", "loss", ",", "_", "=", "self", ".", "forward_pass", "(", "in_query", ",", "target_query", ",", "fast_weights", ")", "#", "\n", "loss", "=", "loss", "/", "self", ".", "meta_batch_size", "# normalize loss", "\n", "grads", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "self", ".", "parameters", "(", ")", ")", "\n", "meta_grads", "=", "{", "name", ":", "g", "for", "(", "(", "name", ",", "_", ")", ",", "g", ")", "in", "zip", "(", "self", ".", "named_parameters", "(", ")", ",", "grads", ")", "}", "\n", "return", "meta_grads", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.Nway_2way": [[10, 17], ["sklearn.metrics.accuracy_score", "sklearn.metrics.f1_score"], "function", ["None"], ["def", "Nway_2way", "(", "predicts", ",", "Nway_labels", ",", "twoway_label", ")", ":", "\n", "# convert to two way", "\n", "    ", "predicts", "=", "(", "predicts", "==", "twoway_label", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "two_way_labels", "=", "(", "Nway_labels", "==", "twoway_label", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "accuracy", "=", "accuracy_score", "(", "two_way_labels", ",", "predicts", ")", "\n", "F1_score", "=", "f1_score", "(", "two_way_labels", ",", "predicts", ")", "\n", "return", "accuracy", ",", "F1_score", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.count_correct": [[20, 24], ["sum", "int", "zip"], "function", ["None"], ["", "def", "count_correct", "(", "pred", ",", "target", ")", ":", "\n", "    ", "''' count number of correct classification predictions in a batch '''", "\n", "pairs", "=", "[", "int", "(", "x", "==", "y", ")", "for", "(", "x", ",", "y", ")", "in", "zip", "(", "pred", ",", "target", ")", "]", "\n", "return", "sum", "(", "pairs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.forward_pass": [[25, 32], ["in_.cuda", "target.cuda", "net.net_forward", "net.loss_fn"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.mlp_detector.MLP.net_forward"], ["", "def", "forward_pass", "(", "net", ",", "in_", ",", "target", ",", "weights", "=", "None", ")", ":", "\n", "    ", "''' forward in_ through the net, return loss and output '''", "\n", "input_var", "=", "in_", ".", "cuda", "(", ")", "\n", "target_var", "=", "target", ".", "cuda", "(", ")", "\n", "out", "=", "net", ".", "net_forward", "(", "input_var", ",", "weights", ")", "\n", "loss", "=", "net", ".", "loss_fn", "(", "out", ",", "target_var", ")", "\n", "return", "loss", ",", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.forward_pass_rotate_random_angle": [[33, 40], ["in_.cuda", "target.cuda", "net.net_forward", "net.loss_fn"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.mlp_detector.MLP.net_forward"], ["", "def", "forward_pass_rotate_random_angle", "(", "net", ",", "in_", ",", "target", ")", ":", "\n", "    ", "''' forward in_ through the net, return loss and output '''", "\n", "input_var", "=", "in_", ".", "cuda", "(", ")", "\n", "target_var", "=", "target", ".", "cuda", "(", ")", "\n", "out", "=", "net", ".", "net_forward", "(", "input_var", ",", "True", ")", "\n", "loss", "=", "net", ".", "loss_fn", "(", "out", ",", "target_var", ")", "\n", "return", "loss", ",", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.evaluate_two_way_random_angle": [[41, 51], ["x.cuda.cuda", "target.detach().cpu().numpy.cuda", "numpy.argmax", "target.detach().cpu().numpy.detach().cpu().numpy", "sklearn.metrics.f1_score", "sklearn.metrics.accuracy_score", "torch.no_grad", "score.forward_pass_rotate_random_angle", "out.detach().cpu().numpy", "target.detach().cpu().numpy.detach().cpu", "out.detach().cpu", "target.detach().cpu().numpy.detach", "out.detach"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.forward_pass_rotate_random_angle"], ["", "def", "evaluate_two_way_random_angle", "(", "net", ",", "x", ",", "target", ")", ":", "\n", "    ", "x", "=", "x", ".", "cuda", "(", ")", "\n", "target", "=", "target", ".", "cuda", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "_", ",", "out", "=", "forward_pass_rotate_random_angle", "(", "net", ",", "x", ",", "target", ")", "\n", "", "predict", "=", "np", ".", "argmax", "(", "out", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "1", ")", "\n", "target", "=", "target", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "F1", "=", "f1_score", "(", "target", ",", "predict", ")", "\n", "accuracy", "=", "accuracy_score", "(", "target", ",", "predict", ")", "\n", "return", "accuracy", ",", "F1", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.evaluate_two_way": [[52, 66], ["x.cuda.cuda", "target.detach().cpu().numpy.cuda", "numpy.argmax", "target.detach().cpu().numpy.detach().cpu().numpy", "sklearn.metrics.f1_score", "sklearn.metrics.accuracy_score", "torch.no_grad", "score.forward_pass", "out.detach().cpu().numpy", "target.detach().cpu().numpy.detach().cpu", "out.detach().cpu", "target.detach().cpu().numpy.detach", "out.detach"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward_pass"], ["", "def", "evaluate_two_way", "(", "net", ",", "x", ",", "target", ")", ":", "\n", "    ", "x", "=", "x", ".", "cuda", "(", ")", "\n", "target", "=", "target", ".", "cuda", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "loss", ",", "out", "=", "forward_pass", "(", "net", ",", "x", ",", "target", ")", "\n", "", "predict", "=", "np", ".", "argmax", "(", "out", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "1", ")", "\n", "target", "=", "target", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "F1", "=", "f1_score", "(", "target", ",", "predict", ")", "\n", "accuracy", "=", "accuracy_score", "(", "target", ",", "predict", ")", "\n", "del", "loss", "\n", "del", "out", "\n", "del", "x", "\n", "# torch.cuda.empty_cache()", "\n", "return", "accuracy", ",", "F1", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.evaluate": [[67, 79], ["in_.cuda.cuda", "target_Nway.cuda.cuda", "score.forward_pass", "numpy.argmax", "target_Nway.cuda.detach().cpu().numpy", "out.detach().cpu().numpy", "score.Nway_2way", "target_Nway.cuda.detach().cpu", "sklearn.metrics.accuracy_score", "sklearn.metrics.f1_score", "out.detach().cpu", "target_positive.detach().cpu().numpy", "target_Nway.cuda.detach", "out.detach", "target_positive.detach().cpu", "target_positive.detach"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward_pass", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.Nway_2way"], ["", "def", "evaluate", "(", "net", ",", "in_", ",", "target_Nway", ",", "target_positive", ",", "weights", "=", "None", ",", "use_positive_position", "=", "True", ")", ":", "\n", "# in_ is one task's 5-way k-shot data, in_ is either support data or query data", "\n", "    ", "in_", "=", "in_", ".", "cuda", "(", ")", "\n", "target_Nway", "=", "target_Nway", ".", "cuda", "(", ")", "\n", "l", ",", "out", "=", "forward_pass", "(", "net", ",", "in_", ",", "target_Nway", ",", "weights", ")", "\n", "predict", "=", "np", ".", "argmax", "(", "out", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "1", ")", "\n", "Nway_labels", "=", "target_Nway", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "use_positive_position", ":", "\n", "        ", "two_way_accuracy", ",", "F1", "=", "Nway_2way", "(", "predict", ",", "Nway_labels", ",", "target_positive", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "        ", "two_way_accuracy", ",", "F1", "=", "accuracy_score", "(", "Nway_labels", ",", "predict", ")", ",", "f1_score", "(", "Nway_labels", ",", "predict", ")", "\n", "", "return", "two_way_accuracy", ",", "F1", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.get_net_predict": [[80, 86], ["input.cuda.cuda", "torch.no_grad", "net.net_forward", "numpy.argmax", "net.net_forward.detach().cpu().numpy", "net.net_forward.detach().cpu", "net.net_forward.detach"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.mlp_detector.MLP.net_forward"], ["", "def", "get_net_predict", "(", "net", ",", "input", ")", ":", "\n", "    ", "input", "=", "input", ".", "cuda", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "out", "=", "net", ".", "net_forward", "(", "input", ")", "\n", "predict", "=", "np", ".", "argmax", "(", "out", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "1", ")", "\n", "", "return", "predict", "\n", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.task.OmniglotTask.__init__": [[16, 44], ["os.listdir", "random.shuffle", "numpy.array", "dict", "dict", "range", "zip", "random.sample", "os.path.join", "len", "os.path.join", "len", "os.listdir", "os.listdir", "task.OmniglotTask.get_class", "task.OmniglotTask.get_class", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.task.OmniglotTask.get_class", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.task.OmniglotTask.get_class"], ["def", "__init__", "(", "self", ",", "root", ",", "num_cls", ",", "num_inst", ",", "split", "=", "'train'", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "'omniglot'", "\n", "self", ".", "root", "=", "'{}/images_background'", ".", "format", "(", "root", ")", "if", "split", "==", "'train'", "else", "'{}/images_evaluation'", ".", "format", "(", "root", ")", "\n", "self", ".", "num_cl", "=", "num_cls", "\n", "self", ".", "num_inst", "=", "num_inst", "\n", "# Sample num_cls characters and num_inst instances of each", "\n", "languages", "=", "os", ".", "listdir", "(", "self", ".", "root", ")", "\n", "chars", "=", "[", "]", "\n", "for", "l", "in", "languages", ":", "\n", "            ", "chars", "+=", "[", "os", ".", "path", ".", "join", "(", "l", ",", "x", ")", "for", "x", "in", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "l", ")", ")", "]", "\n", "", "random", ".", "shuffle", "(", "chars", ")", "\n", "classes", "=", "chars", "[", ":", "num_cls", "]", "\n", "labels", "=", "np", ".", "array", "(", "range", "(", "len", "(", "classes", ")", ")", ")", "\n", "labels", "=", "dict", "(", "zip", "(", "classes", ",", "labels", ")", ")", "\n", "instances", "=", "dict", "(", ")", "\n", "# Now sample from the chosen classes to create class-balanced train and val sets", "\n", "self", ".", "train_ids", "=", "[", "]", "\n", "self", ".", "val_ids", "=", "[", "]", "\n", "for", "c", "in", "classes", ":", "\n", "# First get all isntances of that class", "\n", "            ", "temp", "=", "[", "os", ".", "path", ".", "join", "(", "c", ",", "x", ")", "for", "x", "in", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "c", ")", ")", "]", "\n", "instances", "[", "c", "]", "=", "random", ".", "sample", "(", "temp", ",", "len", "(", "temp", ")", ")", "\n", "# Sample num_inst instances randomly each for train and val", "\n", "self", ".", "train_ids", "+=", "instances", "[", "c", "]", "[", ":", "num_inst", "]", "\n", "self", ".", "val_ids", "+=", "instances", "[", "c", "]", "[", "num_inst", ":", "num_inst", "*", "2", "]", "\n", "# Keep instances separated by class for class-balanced mini-batches", "\n", "", "self", ".", "train_labels", "=", "[", "labels", "[", "self", ".", "get_class", "(", "x", ")", "]", "for", "x", "in", "self", ".", "train_ids", "]", "\n", "self", ".", "val_labels", "=", "[", "labels", "[", "self", ".", "get_class", "(", "x", ")", "]", "for", "x", "in", "self", ".", "val_ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.task.OmniglotTask.get_class": [[46, 48], ["os.path.join", "instance.split"], "methods", ["None"], ["", "def", "get_class", "(", "self", ",", "instance", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "*", "instance", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.task.MNISTTask.__init__": [[59, 81], ["range", "dict", "range", "os.path.join", "os.listdir", "all_ids.append", "zip", "list", "task.MNISTTask.relabel", "task.MNISTTask.relabel", "str", "range", "numpy.random.permutation", "numpy.array", "numpy.random.permutation", "range", "numpy.array", "str", "range", "len"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.task.MNISTTask.relabel", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.task.MNISTTask.relabel"], ["def", "__init__", "(", "self", ",", "root", ",", "num_cls", ",", "num_inst", ",", "split", "=", "'train'", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "'mnist'", "\n", "self", ".", "root", "=", "root", "+", "'/'", "+", "split", "\n", "self", ".", "split", "=", "split", "\n", "all_ids", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "            ", "d", "=", "os", ".", "path", ".", "join", "(", "root", ",", "self", ".", "split", ",", "str", "(", "i", ")", ")", "\n", "files", "=", "os", ".", "listdir", "(", "d", ")", "\n", "all_ids", ".", "append", "(", "[", "str", "(", "i", ")", "+", "'/'", "+", "f", "[", ":", "-", "4", "]", "for", "f", "in", "files", "]", ")", "\n", "\n", "# To create a task, we randomly shuffle the labels", "\n", "", "self", ".", "label_map", "=", "dict", "(", "zip", "(", "range", "(", "10", ")", ",", "np", ".", "random", ".", "permutation", "(", "np", ".", "array", "(", "range", "(", "10", ")", ")", ")", ")", ")", "\n", "\n", "# Choose num_inst ids from each of 10 classes", "\n", "self", ".", "train_ids", "=", "[", "]", "\n", "self", ".", "val_ids", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "            ", "permutation", "=", "list", "(", "np", ".", "random", ".", "permutation", "(", "np", ".", "array", "(", "range", "(", "len", "(", "all_ids", "[", "i", "]", ")", ")", ")", ")", "[", ":", "num_inst", "*", "2", "]", ")", "\n", "self", ".", "train_ids", "+=", "[", "all_ids", "[", "i", "]", "[", "j", "]", "for", "j", "in", "permutation", "[", ":", "num_inst", "]", "]", "\n", "self", ".", "train_labels", "=", "self", ".", "relabel", "(", "self", ".", "train_ids", ")", "\n", "self", ".", "val_ids", "+=", "[", "all_ids", "[", "i", "]", "[", "j", "]", "for", "j", "in", "permutation", "[", "num_inst", ":", "]", "]", "\n", "self", ".", "val_labels", "=", "self", ".", "relabel", "(", "self", ".", "val_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.task.MNISTTask.relabel": [[82, 86], ["int"], "methods", ["None"], ["", "", "def", "relabel", "(", "self", ",", "img_ids", ")", ":", "\n", "        ", "''' Remap labels to new label map for this task '''", "\n", "orig_labels", "=", "[", "int", "(", "x", "[", "0", "]", ")", "for", "x", "in", "img_ids", "]", "\n", "return", "[", "self", ".", "label_map", "[", "x", "]", "for", "x", "in", "orig_labels", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.white_box_meta_adv_det.MetaLearner.__init__": [[17, 51], ["object.__init__", "white_box_meta_adv_det.MetaLearner.network.cuda", "dataset.white_box_attack_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "networks.conv3.Conv3", "networks.resnet.resnet10", "networks.resnet.resnet18"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet10", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet18"], ["    ", "def", "__init__", "(", "self", ",", "\n", "dataset", ",", "\n", "num_classes", ",", "\n", "meta_batch_size", ",", "\n", "meta_step_size", ",", "\n", "inner_step_size", ",", "lr_decay_itr", ",", "\n", "epoch", ",", "\n", "num_inner_updates", ",", "load_task_mode", ",", "arch", ",", "\n", "tot_num_tasks", ",", "num_support", ",", "detector", ",", "attack_name", ",", "\n", "root_folder", ")", ":", "\n", "        ", "super", "(", "self", ".", "__class__", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "meta_batch_size", "=", "meta_batch_size", "# task number per batch", "\n", "self", ".", "meta_step_size", "=", "meta_step_size", "\n", "self", ".", "inner_step_size", "=", "inner_step_size", "\n", "self", ".", "lr_decay_itr", "=", "lr_decay_itr", "\n", "self", ".", "epoch", "=", "epoch", "\n", "self", ".", "num_inner_updates", "=", "num_inner_updates", "\n", "self", ".", "test_finetune_updates", "=", "num_inner_updates", "\n", "# Make the nets", "\n", "if", "arch", "==", "\"conv3\"", ":", "\n", "# network = FourConvs(IN_CHANNELS[self.dataset_name], IMAGE_SIZE[self.dataset_name], num_classes)", "\n", "            ", "network", "=", "Conv3", "(", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", ",", "num_classes", ")", "\n", "", "elif", "arch", "==", "\"resnet10\"", ":", "\n", "            ", "network", "=", "resnet10", "(", "num_classes", ",", "pretrained", "=", "False", ")", "\n", "", "elif", "arch", "==", "\"resnet18\"", ":", "\n", "            ", "network", "=", "resnet18", "(", "num_classes", ",", "pretrained", "=", "False", ")", "\n", "", "self", ".", "network", "=", "network", "\n", "self", ".", "network", ".", "cuda", "(", ")", "\n", "\n", "val_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "num_classes", ",", "num_support", ",", "15", ",", "\n", "dataset", ",", "load_task_mode", ",", "detector", ",", "attack_name", ",", "root_folder", ")", "\n", "self", ".", "val_loader", "=", "DataLoader", "(", "val_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "num_workers", "=", "0", ",", "pin_memory", "=", "True", ")", "# \u56fa\u5b9a100\u4e2atask\uff0c\u5206\u522b\u6d4b\u6bcf\u4e2atask\u7684\u51c6\u786e\u7387", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.white_box_meta_adv_det.MetaLearner.test_task_F1": [[53, 89], ["copy.deepcopy", "np.mean", "np.mean", "print", "range", "support_images.size", "copy.deepcopy", "copy.deepcopy.cuda", "copy.deepcopy.train", "torch.optim.SGD", "range", "copy.deepcopy.eval", "evaluate_two_way", "evaluate_two_way", "support_F1_list.append", "query_F1_list.append", "copy.deepcopy.parameters", "support_images[].cuda", "support_labels[].cuda", "forward_pass", "torch.optim.SGD.zero_grad", "loss.backward", "torch.optim.SGD.step"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.evaluate_two_way", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.evaluate_two_way", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward_pass"], ["", "def", "test_task_F1", "(", "self", ")", ":", "\n", "# Select ten tasks randomly from the test set to evaluate_accuracy on", "\n", "        ", "test_net", "=", "copy", ".", "deepcopy", "(", "self", ".", "network", ")", "\n", "support_F1_list", ",", "query_F1_list", "=", "[", "]", ",", "[", "]", "\n", "for", "support_images", ",", "_", ",", "support_labels", ",", "query_images", ",", "_", ",", "query_labels", ",", "positive_position", "in", "self", ".", "val_loader", ":", "\n", "            ", "for", "task_idx", "in", "range", "(", "support_images", ".", "size", "(", "0", ")", ")", ":", "# \u9009\u62e9100\u4e2atask", "\n", "# Make a test net with same parameters as our current net", "\n", "                ", "test_net", "=", "copy", ".", "deepcopy", "(", "self", ".", "network", ")", "\n", "# test_net.copy_weights(self.network)", "\n", "test_net", ".", "cuda", "(", ")", "\n", "test_net", ".", "train", "(", ")", "\n", "test_opt", "=", "SGD", "(", "test_net", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "inner_step_size", ")", "\n", "# for m in test_net.modules():", "\n", "#     if isinstance(m, torch.nn.BatchNorm2d):", "\n", "#         m.eval()", "\n", "finetune_img", ",", "finetune_target", "=", "support_images", "[", "task_idx", "]", ".", "cuda", "(", ")", ",", "support_labels", "[", "task_idx", "]", ".", "cuda", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "test_finetune_updates", ")", ":", "# \u5148fine_tune", "\n", "                    ", "loss", ",", "_", "=", "forward_pass", "(", "test_net", ",", "finetune_img", ",", "finetune_target", ")", "\n", "# print(loss.item())", "\n", "test_opt", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "test_opt", ".", "step", "(", ")", "\n", "", "test_net", ".", "eval", "(", ")", "\n", "# Evaluate the trained model on train and val examples", "\n", "support_accuracy", ",", "support_F1", "=", "evaluate_two_way", "(", "test_net", ",", "finetune_img", ",", "finetune_target", ")", "\n", "query_accuracy", ",", "query_F1", "=", "evaluate_two_way", "(", "test_net", ",", "query_images", "[", "task_idx", "]", ",", "query_labels", "[", "task_idx", "]", ")", "\n", "support_F1_list", ".", "append", "(", "support_F1", ")", "\n", "query_F1_list", ".", "append", "(", "query_F1", ")", "\n", "", "", "support_F1", "=", "np", ".", "mean", "(", "support_F1_list", ")", "\n", "query_F1", "=", "np", ".", "mean", "(", "query_F1_list", ")", "\n", "result_json", "=", "{", "\"query_F1\"", ":", "query_F1", ",", "\n", "\"num_updates\"", ":", "self", ".", "num_inner_updates", "}", "\n", "\n", "print", "(", "'Validation Set Support F1: {} Query F1: {}'", ".", "format", "(", "support_F1", ",", "query_F1", ")", ")", "\n", "del", "test_net", "\n", "return", "result_json", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.ablation_study.train_ablation_study.parse_args": [[19, 59], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "str", "print", "list", "list"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.train_fingerprint.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'PyTorch Meta_SGD Training'", ")", "\n", "# Training options", "\n", "parser", ".", "add_argument", "(", "'--gpu'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"GPU ID to train\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num_classes'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "'number of classes(ways) used in classification (e.g. 5-way classification).'", ")", "\n", "parser", ".", "add_argument", "(", "\"--epoch\"", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "\"number of epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--meta_batch_size'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "help", "=", "'number of tasks sampled per meta-update'", ")", "# \u6ce8\u610f\u662ftask\u6570\u91cf", "\n", "parser", ".", "add_argument", "(", "'--meta_lr'", ",", "type", "=", "float", ",", "default", "=", "1e-4", ",", "help", "=", "'the base learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--inner_lr'", ",", "type", "=", "float", ",", "default", "=", "1e-3", ",", "help", "=", "\"lr for inner update\"", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_decay_itr'", ",", "type", "=", "int", ",", "default", "=", "7000", ",", "help", "=", "\"* 1/10. the number of iteration that the meta lr should decay\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num_support'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'number/shots of examples used for inner gradient update (K for K-shot learning) in one way.'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_query'", ",", "type", "=", "int", ",", "default", "=", "35", ",", "\n", "help", "=", "'number of examples of each class in query set in one way.'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_updates'", ",", "type", "=", "int", ",", "default", "=", "12", ",", "help", "=", "'number of inner gradient updates(on support set) during training.'", ")", "\n", "parser", ".", "add_argument", "(", "'--tot_num_tasks'", ",", "type", "=", "int", ",", "default", "=", "20000", ",", "help", "=", "'the maximum number of tasks in total, which is repeatly processed in training.'", ")", "\n", "parser", ".", "add_argument", "(", "'--arch'", ",", "type", "=", "str", ",", "default", "=", "'conv3'", ",", "choices", "=", "[", "\"resnet10\"", ",", "\"resnet18\"", ",", "\"densenet121\"", ",", "\"conv3\"", ",", "\"vgg11\"", ",", "\"vgg11_bn\"", ",", "\"vgg13\"", ",", "\"vgg13_bn\"", ",", "\"vgg16\"", ",", "\"vgg16_bn\"", "]", ",", "help", "=", "'network name'", ")", "#10 \u5c42", "\n", "parser", ".", "add_argument", "(", "'--test_num_updates'", ",", "type", "=", "int", ",", "default", "=", "20", ",", "help", "=", "'number of inner gradient updates during testing'", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "type", "=", "str", ",", "default", "=", "\"CIFAR-10\"", ",", "help", "=", "\"the dataset to train\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--split_protocol\"", ",", "type", "=", "SPLIT_DATA_PROTOCOL", ",", "choices", "=", "list", "(", "SPLIT_DATA_PROTOCOL", ")", ",", "help", "=", "\"split protocol of data\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--load_task_mode\"", ",", "default", "=", "LOAD_TASK_MODE", ".", "LOAD", ",", "type", "=", "LOAD_TASK_MODE", ",", "choices", "=", "list", "(", "LOAD_TASK_MODE", ")", ",", "help", "=", "\"load task mode\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_random_way\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"whether to randomize the way\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--rotate\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"randomly rotate image before training\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_accuracy\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"to evaluate_accuracy the pretrained model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--study_subject\"", ",", "type", "=", "str", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv_arch\"", ",", "type", "=", "str", ",", "default", "=", "\"conv3\"", ",", "choices", "=", "[", "\"conv3\"", ",", "\"resnet10\"", ",", "\"resnet18\"", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--cross_domain_target\"", ",", "type", "=", "str", ",", "help", "=", "\"the target domain to evaluate_accuracy\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cross_domain_source\"", ",", "type", "=", "str", ",", "help", "=", "\"the target domain to evaluate_accuracy\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cross_arch_source\"", ",", "type", "=", "str", ",", "help", "=", "\"the source arch to evaluate_accuracy\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cross_arch_target\"", ",", "type", "=", "str", ",", "help", "=", "\"the target arch to evaluate_accuracy\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--ony_support_data\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--task_net_only\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "## Logging, saving, and testing options", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "os", ".", "environ", "[", "\"CUDA_DEVICE_ORDER\"", "]", "=", "\"PCI_BUS_ID\"", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "str", "(", "args", ".", "gpu", ")", "\n", "print", "(", "\"using GPU :{}\"", ".", "format", "(", "args", ".", "gpu", ")", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.ablation_study.train_ablation_study.main": [[60, 113], ["train_ablation_study.parse_args", "random.seed", "numpy.random.seed", "print", "str", "os.makedirs", "meta_adv_detector.ablation_study.meta_adv_det_task_net.MetaLearnerTasknetOnly", "os.path.exists", "meta_adv_detector.ablation_study.meta_adv_det_task_net.MetaLearnerTasknetOnly.train", "os.path.dirname", "print", "torch.load", "meta_adv_detector.ablation_study.meta_adv_det_task_net.MetaLearnerTasknetOnly.network.load_state_dict", "meta_adv_detector.ablation_study.meta_adv_det_task_net.MetaLearnerTasknetOnly.opt.load_state_dict", "print", "meta_adv_detector.evaluation.meta_cross_domain_evaluate", "meta_adv_detector.evaluation.meta_cross_arch_evaluate", "meta_adv_detector.evaluation.meta_white_box_attack_evaluate", "meta_adv_detector.evaluation.meta_zero_shot_evaluate", "meta_adv_detector.evaluation.speed_evaluation.evaluate_speed", "meta_adv_detector.evaluation.meta_ablation_study_evaluate"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.train_fingerprint.parse_args", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.cross_domain_evaluation.meta_cross_domain_evaluate", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.cross_arch_evaluation.meta_cross_arch_evaluate", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.white_box_evaluation.meta_white_box_attack_evaluate", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.zero_shot_evaluation.meta_zero_shot_evaluate", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.speed_evaluation.evaluate_speed", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.ablation_study_evaluation.meta_ablation_study_evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "random", ".", "seed", "(", "1337", ")", "\n", "np", ".", "random", ".", "seed", "(", "1337", ")", "\n", "# make output dir", "\n", "# Set the gpu", "\n", "print", "(", "'Setting GPU to'", ",", "str", "(", "args", ".", "gpu", ")", ")", "\n", "\n", "if", "not", "args", ".", "evaluate", ":", "\n", "        ", "param_prefix", "=", "\"{}_{}@model_{}@data_{}@epoch_{}@meta_batch_size_{}@way_{}@shot_{}@num_query_{}@num_updates_{}@lr_{}@inner_lr_{}@fixed_way_{}@rotate_{}\"", ".", "format", "(", "\n", "args", ".", "dataset", ",", "\n", "args", ".", "split_protocol", ",", "args", ".", "arch", ",", "args", ".", "adv_arch", ",", "args", ".", "epoch", ",", "args", ".", "meta_batch_size", ",", "args", ".", "num_classes", ",", "args", ".", "num_support", ",", "\n", "args", ".", "num_query", ",", "args", ".", "num_updates", ",", "args", ".", "meta_lr", ",", "args", ".", "inner_lr", ",", "args", ".", "no_random_way", ",", "args", ".", "rotate", ")", "\n", "model_path", "=", "'{}/train_pytorch_model/{}/MAML@{}.pth.tar'", ".", "format", "(", "\n", "PY_ROOT", ",", "\n", "args", ".", "study_subject", ",", "\n", "param_prefix", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "model_path", ")", ",", "exist_ok", "=", "True", ")", "\n", "class_number", "=", "args", ".", "num_classes", "\n", "if", "args", ".", "no_random_way", ":", "\n", "            ", "class_number", "=", "2", "\n", "", "learner", "=", "MetaLearnerTasknetOnly", "(", "args", ".", "dataset", ",", "class_number", ",", "args", ".", "meta_batch_size", ",", "args", ".", "meta_lr", ",", "args", ".", "inner_lr", ",", "args", ".", "lr_decay_itr", ",", "\n", "args", ".", "epoch", ",", "args", ".", "num_updates", ",", "args", ".", "load_task_mode", ",", "\n", "args", ".", "split_protocol", ",", "args", ".", "arch", ",", "args", ".", "tot_num_tasks", ",", "args", ".", "num_support", ",", "args", ".", "num_query", ",", "\n", "args", ".", "no_random_way", ",", "\n", "param_prefix", ",", "train", "=", "True", ",", "adv_arch", "=", "args", ".", "adv_arch", ",", "rotate", "=", "args", ".", "rotate", ")", "\n", "# epoch 5-way  k-shot num_updates num_support num_query meta_lr inner_lr", "\n", "\n", "resume_epoch", "=", "0", "\n", "if", "os", ".", "path", ".", "exists", "(", "model_path", ")", ":", "\n", "            ", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "model_path", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "resume_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "learner", ".", "network", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ",", "strict", "=", "True", ")", "\n", "learner", ".", "opt", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "model_path", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "\n", "", "learner", ".", "train", "(", "model_path", ",", "resume_epoch", ",", "need_val", "=", "False", ")", "\n", "", "else", ":", "# \u6d4b\u8bd5\u6a21\u5f0f", "\n", "# MAML@CIFAR-10_TRAIN_I_TEST_II@conv4@epoch_40@meta_batch_size_10@way_2@shot_1@num_query_15@num_updates_2@lr_0.001@inner_lr_0.01.pth.tar", "\n", "        ", "if", "args", ".", "study_subject", "==", "\"cross_domain\"", ":", "\n", "            ", "meta_cross_domain_evaluate", "(", "args", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"cross_arch\"", ":", "\n", "            ", "meta_cross_arch_evaluate", "(", "args", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"white_box\"", ":", "\n", "            ", "meta_white_box_attack_evaluate", "(", "\"conv3\"", ",", "args", ".", "adv_arch", ",", "args", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"zero_shot\"", ":", "\n", "            ", "meta_zero_shot_evaluate", "(", "args", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"speed_test\"", ":", "\n", "            ", "evaluate_speed", "(", "args", ")", "\n", "", "else", ":", "\n", "            ", "meta_ablation_study_evaluate", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.ablation_study.meta_adv_det_task_net.MetaLearnerTasknetOnly.__init__": [[21, 68], ["object.__init__", "meta_adv_det_task_net.MetaLearnerTasknetOnly.network.cuda", "torch.optim.Adam", "networks.conv3.Conv3", "dataset.meta_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "meta_adv_detector.tensorboard_helper.TensorBoardWriter", "os.makedirs", "dataset.meta_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "meta_adv_det_task_net.MetaLearnerTasknetOnly.network.parameters", "networks.resnet.resnet10", "networks.resnet.resnet18"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet10", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet18"], ["    ", "def", "__init__", "(", "self", ",", "\n", "dataset", ",", "\n", "num_classes", ",", "\n", "meta_batch_size", ",", "\n", "meta_step_size", ",", "\n", "inner_step_size", ",", "lr_decay_itr", ",", "\n", "epoch", ",", "\n", "num_inner_updates", ",", "load_task_mode", ",", "protocol", ",", "arch", ",", "\n", "tot_num_tasks", ",", "num_support", ",", "num_query", ",", "no_random_way", ",", "\n", "tensorboard_data_prefix", ",", "train", "=", "True", ",", "adv_arch", "=", "\"conv3\"", ",", "need_val", "=", "False", ")", ":", "\n", "        ", "super", "(", "self", ".", "__class__", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "meta_batch_size", "=", "meta_batch_size", "# task number per batch", "\n", "self", ".", "meta_step_size", "=", "meta_step_size", "\n", "self", ".", "inner_step_size", "=", "inner_step_size", "\n", "self", ".", "lr_decay_itr", "=", "lr_decay_itr", "\n", "self", ".", "epoch", "=", "epoch", "\n", "self", ".", "num_inner_updates", "=", "num_inner_updates", "\n", "self", ".", "test_finetune_updates", "=", "num_inner_updates", "\n", "# Make the nets", "\n", "if", "arch", "==", "\"conv3\"", ":", "\n", "# network = FourConvs(IN_CHANNELS[self.dataset_name], IMAGE_SIZE[self.dataset_name], num_classes)", "\n", "            ", "network", "=", "Conv3", "(", "IN_CHANNELS", "[", "self", ".", "dataset", "]", ",", "IMAGE_SIZE", "[", "self", ".", "dataset", "]", ",", "num_classes", ")", "\n", "", "elif", "arch", "==", "\"resnet10\"", ":", "\n", "            ", "network", "=", "resnet10", "(", "num_classes", ",", "pretrained", "=", "False", ")", "\n", "", "elif", "arch", "==", "\"resnet18\"", ":", "\n", "            ", "network", "=", "resnet18", "(", "num_classes", ",", "pretrained", "=", "False", ")", "\n", "", "self", ".", "network", "=", "network", "\n", "self", ".", "network", ".", "cuda", "(", ")", "\n", "if", "train", ":", "\n", "            ", "trn_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "num_classes", ",", "num_support", ",", "num_query", ",", "\n", "dataset", ",", "is_train", "=", "True", ",", "load_mode", "=", "load_task_mode", ",", "\n", "protocol", "=", "protocol", ",", "\n", "no_random_way", "=", "no_random_way", ",", "adv_arch", "=", "adv_arch", ")", "\n", "self", ".", "train_loader", "=", "DataLoader", "(", "trn_dataset", ",", "batch_size", "=", "meta_batch_size", ",", "shuffle", "=", "True", ",", "num_workers", "=", "0", ",", "pin_memory", "=", "True", ")", "\n", "self", ".", "tensorboard", "=", "TensorBoardWriter", "(", "\"{0}/MAML_task_net_tensorboard\"", ".", "format", "(", "PY_ROOT", ")", ",", "\n", "tensorboard_data_prefix", ")", "\n", "os", ".", "makedirs", "(", "\"{0}/MAML_task_net_tensorboard\"", ".", "format", "(", "PY_ROOT", ")", ",", "exist_ok", "=", "True", ")", "\n", "", "if", "need_val", ":", "\n", "            ", "val_dataset", "=", "MetaTaskDataset", "(", "tot_num_tasks", ",", "num_classes", ",", "num_support", ",", "15", ",", "\n", "dataset", ",", "is_train", "=", "False", ",", "load_mode", "=", "load_task_mode", ",", "\n", "protocol", "=", "protocol", ",", "\n", "no_random_way", "=", "True", ",", "adv_arch", "=", "adv_arch", ")", "\n", "self", ".", "val_loader", "=", "DataLoader", "(", "val_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "num_workers", "=", "0", ",", "pin_memory", "=", "True", ")", "# \u56fa\u5b9a100\u4e2atask\uff0c\u5206\u522b\u6d4b\u6bcf\u4e2atask\u7684\u51c6\u786e\u7387", "\n", "\n", "", "self", ".", "opt", "=", "Adam", "(", "self", ".", "network", ".", "parameters", "(", ")", ",", "lr", "=", "meta_step_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.ablation_study.meta_adv_det_task_net.MetaLearnerTasknetOnly.test_task_F1": [[72, 116], ["copy.deepcopy", "np.mean", "np.mean", "print", "range", "torch.Tensor", "torch.Tensor.fill_", "meta_adv_det_task_net.MetaLearnerTasknetOnly.tensorboard.record_val_query_F1", "support_images.size", "copy.deepcopy.copy_weights", "copy.deepcopy.cuda", "copy.deepcopy.train", "torch.optim.SGD", "range", "copy.deepcopy.eval", "evaluate_two_way", "evaluate_two_way", "support_F1_list.append", "query_F1_list.append", "copy.deepcopy.parameters", "support_images[].cuda", "support_labels[].cuda", "forward_pass", "torch.optim.SGD.zero_grad", "loss.backward", "torch.optim.SGD.step"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.record_val_query_F1", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.ResNet.copy_weights", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.evaluate_two_way", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.evaluate_two_way", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward_pass"], ["", "def", "test_task_F1", "(", "self", ",", "iter", "=", "0", ",", "limit", "=", "100", ")", ":", "\n", "        ", "test_net", "=", "copy", ".", "deepcopy", "(", "self", ".", "network", ")", "\n", "# Select ten tasks randomly from the test set to evaluate_accuracy on", "\n", "support_F1_list", ",", "query_F1_list", "=", "[", "]", ",", "[", "]", "\n", "all_c", "=", "0", "\n", "for", "support_images", ",", "_", ",", "support_labels", ",", "query_images", ",", "_", ",", "query_labels", ",", "positive_position", "in", "self", ".", "val_loader", ":", "\n", "            ", "for", "task_idx", "in", "range", "(", "support_images", ".", "size", "(", "0", ")", ")", ":", "# \u9009\u62e9100\u4e2atask", "\n", "# Make a test net with same parameters as our current net", "\n", "                ", "test_net", ".", "copy_weights", "(", "self", ".", "network", ")", "\n", "test_net", ".", "cuda", "(", ")", "\n", "test_net", ".", "train", "(", ")", "\n", "test_opt", "=", "SGD", "(", "test_net", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "inner_step_size", ")", "\n", "# for m in test_net.modules():", "\n", "#     if isinstance(m, torch.nn.BatchNorm2d):", "\n", "#         m.eval()", "\n", "finetune_img", ",", "finetune_target", "=", "support_images", "[", "task_idx", "]", ".", "cuda", "(", ")", ",", "support_labels", "[", "task_idx", "]", ".", "cuda", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "test_finetune_updates", ")", ":", "# \u5148fine_tune", "\n", "                    ", "loss", ",", "_", "=", "forward_pass", "(", "test_net", ",", "finetune_img", ",", "finetune_target", ")", "\n", "# print(loss.item())", "\n", "test_opt", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "test_opt", ".", "step", "(", ")", "\n", "# print(\"---------\")", "\n", "", "test_net", ".", "eval", "(", ")", "\n", "# Evaluate the trained model on train and val examples", "\n", "support_accuracy", ",", "support_F1", "=", "evaluate_two_way", "(", "test_net", ",", "finetune_img", ",", "finetune_target", ")", "\n", "query_accuracy", ",", "query_F1", "=", "evaluate_two_way", "(", "test_net", ",", "query_images", "[", "task_idx", "]", ",", "query_labels", "[", "task_idx", "]", ")", "\n", "support_F1_list", ".", "append", "(", "support_F1", ")", "\n", "query_F1_list", ".", "append", "(", "query_F1", ")", "\n", "all_c", "+=", "1", "\n", "if", "limit", ">", "0", "and", "all_c", ">", "limit", ":", "\n", "                    ", "break", "\n", "", "", "", "support_F1", "=", "np", ".", "mean", "(", "support_F1_list", ")", "\n", "query_F1", "=", "np", ".", "mean", "(", "query_F1_list", ")", "\n", "result_json", "=", "{", "\"support_F1\"", ":", "support_F1", ",", "\n", "\"query_F1\"", ":", "query_F1", ",", "\n", "\"num_updates\"", ":", "self", ".", "num_inner_updates", "}", "\n", "if", "iter", ">=", "0", ":", "\n", "            ", "query_F1_tensor", "=", "torch", ".", "Tensor", "(", "1", ")", "\n", "query_F1_tensor", ".", "fill_", "(", "query_F1", ")", "\n", "self", ".", "tensorboard", ".", "record_val_query_F1", "(", "query_F1_tensor", ",", "iter", ")", "\n", "", "print", "(", "'Validation Set iteration:{} Support F1: {} Query F1: {}'", ".", "format", "(", "iter", ",", "support_F1", ",", "query_F1", ")", ")", "\n", "del", "test_net", "\n", "return", "result_json", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.ablation_study.meta_adv_det_task_net.MetaLearnerTasknetOnly.train": [[118, 157], ["range", "enumerate", "torch.save", "meta_adv_det_task_net.MetaLearnerTasknetOnly.adjust_learning_rate", "range", "support_images.cuda", "support_labels.cuda", "query_images.cuda", "query_labels.cuda", "support_images.size", "collections.OrderedDict", "range", "meta_adv_det_task_net.MetaLearnerTasknetOnly.network.forward_pass", "meta_adv_det_task_net.MetaLearnerTasknetOnly.opt.zero_grad", "loss.backward", "meta_adv_det_task_net.MetaLearnerTasknetOnly.opt.step", "meta_adv_det_task_net.MetaLearnerTasknetOnly.test_task_F1", "meta_adv_det_task_net.MetaLearnerTasknetOnly.network.state_dict", "meta_adv_det_task_net.MetaLearnerTasknetOnly.opt.state_dict", "len", "collections.OrderedDict", "meta_adv_det_task_net.MetaLearnerTasknetOnly.network.forward_pass", "torch.autograd.grad", "meta_adv_det_task_net.MetaLearnerTasknetOnly.network.forward_pass", "torch.autograd.grad", "meta_adv_det_task_net.MetaLearnerTasknetOnly.network.named_parameters", "meta_adv_det_task_net.MetaLearnerTasknetOnly.network.parameters", "collections.OrderedDict.values", "zip", "collections.OrderedDict.items"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.adjust_learning_rate", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward_pass", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.ablation_study.meta_adv_det_task_net.MetaLearnerTasknetOnly.test_task_F1", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward_pass", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward_pass"], ["", "def", "train", "(", "self", ",", "model_path", ",", "resume_epoch", "=", "0", ",", "need_val", "=", "False", ")", ":", "\n", "        ", "for", "epoch", "in", "range", "(", "resume_epoch", ",", "self", ".", "epoch", ")", ":", "\n", "# Evaluate on test tasks", "\n", "# Collect a meta batch update", "\n", "# Save a model snapshot every now and then", "\n", "\n", "            ", "for", "i", ",", "(", "support_images", ",", "_", ",", "support_labels", ",", "query_images", ",", "_", ",", "query_labels", ",", "_", ")", "in", "enumerate", "(", "self", ".", "train_loader", ")", ":", "\n", "                ", "itr", "=", "epoch", "*", "len", "(", "self", ".", "train_loader", ")", "+", "i", "\n", "self", ".", "adjust_learning_rate", "(", "itr", ",", "self", ".", "meta_step_size", ",", "self", ".", "lr_decay_itr", ")", "\n", "support_images", ",", "support_labels", ",", "query_images", ",", "query_labels", "=", "support_images", ".", "cuda", "(", ")", ",", "support_labels", ".", "cuda", "(", ")", ",", "query_images", ".", "cuda", "(", ")", ",", "query_labels", ".", "cuda", "(", ")", "\n", "for", "task_idx", "in", "range", "(", "support_images", ".", "size", "(", "0", ")", ")", ":", "# \u5728\u6bcf\u4e00\u4e2atask\u4f9d\u6b21\u66f4\u65b0\u5373\u53ef\uff0c\u6240\u4ee5\u65e0\u97002\u4e2a\u7f51\u7edc", "\n", "                    ", "in_support", ",", "in_query", ",", "target_support", ",", "target_query", "=", "support_images", "[", "task_idx", "]", ",", "query_images", "[", "task_idx", "]", ",", "support_labels", "[", "task_idx", "]", ",", "query_labels", "[", "task_idx", "]", "\n", "fast_weights", "=", "OrderedDict", "(", "(", "name", ",", "param", ")", "for", "(", "name", ",", "param", ")", "in", "self", ".", "network", ".", "named_parameters", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_inner_updates", ")", ":", "\n", "                        ", "if", "i", "==", "0", ":", "\n", "                            ", "loss", ",", "_", "=", "self", ".", "network", ".", "forward_pass", "(", "in_support", ",", "target_support", ")", "\n", "grads", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "self", ".", "network", ".", "parameters", "(", ")", ")", "\n", "", "else", ":", "\n", "                            ", "loss", ",", "_", "=", "self", ".", "network", ".", "forward_pass", "(", "in_support", ",", "target_support", ",", "fast_weights", ")", "\n", "grads", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "fast_weights", ".", "values", "(", ")", ")", "\n", "", "fast_weights", "=", "OrderedDict", "(", "(", "name", ",", "param", "-", "self", ".", "inner_step_size", "*", "grad", ")", "for", "(", "(", "name", ",", "param", ")", ",", "grad", ")", "in", "\n", "zip", "(", "fast_weights", ".", "items", "(", ")", ",", "grads", ")", ")", "\n", "# fast_net only forward one task's data", "\n", "", "loss", ",", "_", "=", "self", ".", "network", ".", "forward_pass", "(", "in_query", ",", "target_query", ",", "fast_weights", ")", "\n", "loss", "=", "loss", "/", "self", ".", "meta_batch_size", "# normalize loss", "\n", "self", ".", "opt", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "opt", ".", "step", "(", ")", "\n", "# Perform the meta update", "\n", "# print('Meta update', itr)", "\n", "\n", "", "if", "itr", "%", "100", "==", "0", "and", "need_val", ":", "\n", "                    ", "self", ".", "test_task_F1", "(", "itr", ",", "limit", "=", "200", ")", "\n", "", "", "torch", ".", "save", "(", "{", "\n", "'epoch'", ":", "epoch", "+", "1", ",", "\n", "'state_dict'", ":", "self", ".", "network", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "self", ".", "opt", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "model_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.ablation_study.meta_adv_det_task_net.MetaLearnerTasknetOnly.adjust_learning_rate": [[159, 166], ["int", "int"], "methods", ["None"], ["", "", "def", "adjust_learning_rate", "(", "self", ",", "itr", ",", "meta_lr", ",", "lr_decay_itr", ")", ":", "\n", "        ", "\"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"", "\n", "if", "lr_decay_itr", ">", "0", ":", "\n", "            ", "if", "int", "(", "itr", "%", "lr_decay_itr", ")", "==", "0", "and", "itr", ">", "0", ":", "\n", "                ", "meta_lr", "=", "meta_lr", "/", "(", "10", "**", "int", "(", "itr", "/", "lr_decay_itr", ")", ")", "\n", "for", "param_group", "in", "self", ".", "opt", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "'lr'", "]", "=", "meta_lr", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.shallow_convs.FourConvs.__init__": [[20, 45], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "shallow_convs.FourConvs.add_module", "shallow_convs.conv_block", "shallow_convs.conv_block", "shallow_convs.conv_block", "shallow_convs.conv_block", "torch.Linear", "torch.Linear", "torch.Linear", "len", "len"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.shallow_convs.conv_block", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.shallow_convs.conv_block", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.shallow_convs.conv_block", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.shallow_convs.conv_block"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "img_size", ",", "num_classes", ")", ":", "\n", "        ", "\"\"\"\n        self.net returns:\n            [N, 64, 1, 1] for Omniglot (28x28)\n            [N, 64, 5, 5] for miniImageNet (84x84)\n        self.fc returns:\n            [N, num_classes]\n\n        Args:\n            in_channels: number of input channels feeding into first conv_block\n            num_classes: number of classes for the task\n            dataset: for the measure of input units for self.fc, caused by\n                     difference of input size of 'Omniglot' and 'ImageNet'\n        \"\"\"", "\n", "super", "(", "FourConvs", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "\n", "conv_block", "(", "0", ",", "in_channels", ",", "padding", "=", "1", ",", "pooling", "=", "True", ")", ",", "\n", "conv_block", "(", "1", ",", "N_FILTERS", ",", "padding", "=", "1", ",", "pooling", "=", "True", ")", ",", "\n", "conv_block", "(", "2", ",", "N_FILTERS", ",", "padding", "=", "1", ",", "pooling", "=", "True", ")", ",", "\n", "conv_block", "(", "3", ",", "N_FILTERS", ",", "padding", "=", "1", ",", "pooling", "=", "True", ")", ")", "\n", "self", ".", "add_module", "(", "'fc'", ",", "\n", "nn", ".", "Linear", "(", "64", "*", "(", "self", ".", "img_size", "[", "0", "]", "//", "2", "**", "len", "(", "self", ".", "features", ")", ")", "*", "(", "self", ".", "img_size", "[", "1", "]", "//", "2", "**", "len", "(", "self", ".", "features", ")", ")", ",", "\n", "num_classes", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.shallow_convs.FourConvs.copy_weights": [[46, 53], ["zip", "net.modules", "shallow_convs.FourConvs.modules", "isinstance", "isinstance", "isinstance", "m_from.weight.data.clone", "m_from.bias.data.clone"], "methods", ["None"], ["", "def", "copy_weights", "(", "self", ",", "net", ")", ":", "\n", "        ", "''' Set this module's weights to be the same as those of 'net' '''", "\n", "for", "m_from", ",", "m_to", "in", "zip", "(", "net", ".", "modules", "(", ")", ",", "self", ".", "modules", "(", ")", ")", ":", "\n", "            ", "if", "isinstance", "(", "m_to", ",", "nn", ".", "Linear", ")", "or", "isinstance", "(", "m_to", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "m_to", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m_to", ".", "weight", ".", "data", "=", "m_from", ".", "weight", ".", "data", ".", "clone", "(", ")", "\n", "if", "m_to", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "m_to", ".", "bias", ".", "data", "=", "m_from", ".", "bias", ".", "data", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.shallow_convs.FourConvs.forward": [[55, 68], ["X.view.view.view", "shallow_convs.FourConvs.features", "shallow_convs.FourConvs.view", "shallow_convs.FourConvs.fc", "shallow_convs.FourConvs.size"], "methods", ["None"], ["", "", "", "", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            X: [N, in_channels, W, H]\n            params: a state_dict()\n        Returns:\n            out: [N, num_classes] unnormalized score for each class\n        \"\"\"", "\n", "X", "=", "X", ".", "view", "(", "-", "1", ",", "self", ".", "in_channels", ",", "self", ".", "img_size", "[", "0", "]", ",", "self", ".", "img_size", "[", "1", "]", ")", "\n", "out", "=", "self", ".", "features", "(", "X", ")", "\n", "out", "=", "out", ".", "view", "(", "out", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "out", "=", "self", ".", "fc", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.shallow_convs.conv_block": [[70, 103], ["torch.Sequential", "torch.Sequential", "collections.OrderedDict", "collections.OrderedDict", "torch.Conv2d", "torch.BatchNorm2d", "torch.ReLU", "torch.MaxPool2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.ReLU", "str", "str", "str", "str", "str", "str", "str"], "function", ["None"], ["", "", "def", "conv_block", "(", "index", ",", "\n", "in_channels", ",", "\n", "out_channels", "=", "N_FILTERS", ",", "\n", "padding", "=", "0", ",", "\n", "pooling", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    The unit architecture (Convolutional Block; CB) used in the modules.\n    The CB consists of following modules in the order:\n        3x3 conv, 64 filters\n        batch normalization\n        ReLU\n        MaxPool\n    \"\"\"", "\n", "if", "pooling", ":", "\n", "        ", "conv", "=", "nn", ".", "Sequential", "(", "\n", "OrderedDict", "(", "[", "\n", "(", "'conv'", "+", "str", "(", "index", ")", ",", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "K_SIZE", ",", "padding", "=", "padding", ")", ")", ",", "\n", "(", "'bn'", "+", "str", "(", "index", ")", ",", "nn", ".", "BatchNorm2d", "(", "out_channels", ",", "momentum", "=", "1", ",", "affine", "=", "True", ")", ")", ",", "\n", "(", "'relu'", "+", "str", "(", "index", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", ",", "\n", "(", "'pool'", "+", "str", "(", "index", ")", ",", "nn", ".", "MaxPool2d", "(", "MP_SIZE", ")", ")", "\n", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "conv", "=", "nn", ".", "Sequential", "(", "\n", "OrderedDict", "(", "[", "\n", "(", "'conv'", "+", "str", "(", "index", ")", ",", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "K_SIZE", ",", "padding", "=", "padding", ")", ")", ",", "\n", "(", "'bn'", "+", "str", "(", "index", ")", ",", "nn", ".", "BatchNorm2d", "(", "out_channels", ",", "momentum", "=", "1", ",", "affine", "=", "True", ")", ")", ",", "\n", "(", "'relu'", "+", "str", "(", "index", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "]", ")", ")", "\n", "", "return", "conv", "\n", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.conv3.Conv3.__init__": [[14, 39], ["torch.nn.Module.__init__", "torch.nn.Sequential", "conv3.Conv3.add_module", "torch.nn.CrossEntropyLoss", "conv3.Conv3._init_weights", "collections.OrderedDict", "torch.nn.Linear", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU", "torch.nn.MaxPool2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU", "torch.nn.MaxPool2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU", "torch.nn.MaxPool2d"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork._init_weights"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "img_size", ",", "num_classes", ")", ":", "\n", "        ", "super", "(", "Conv3", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "img_size", "=", "img_size", "\n", "# Define the network", "\n", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'conv1'", ",", "nn", ".", "Conv2d", "(", "in_channels", ",", "64", ",", "3", ")", ")", ",", "\n", "(", "'bn1'", ",", "nn", ".", "BatchNorm2d", "(", "64", ",", "momentum", "=", "1", ",", "affine", "=", "True", ")", ")", ",", "\n", "(", "'relu1'", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", ",", "\n", "(", "'pool1'", ",", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", ")", ",", "\n", "(", "'conv2'", ",", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "3", ")", ")", ",", "\n", "(", "'bn2'", ",", "nn", ".", "BatchNorm2d", "(", "64", ",", "momentum", "=", "1", ",", "affine", "=", "True", ")", ")", ",", "\n", "(", "'relu2'", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", ",", "\n", "(", "'pool2'", ",", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", ")", ",", "\n", "(", "'conv3'", ",", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "3", ")", ")", ",", "\n", "(", "'bn3'", ",", "nn", ".", "BatchNorm2d", "(", "64", ",", "momentum", "=", "1", ",", "affine", "=", "True", ")", ")", ",", "\n", "(", "'relu3'", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", ",", "\n", "(", "'pool3'", ",", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", ")", "\n", "]", ")", ")", "\n", "self", ".", "add_module", "(", "'fc'", ",", "nn", ".", "Linear", "(", "64", "*", "(", "self", ".", "img_size", "[", "0", "]", "//", "2", "**", "4", ")", "*", "(", "self", ".", "img_size", "[", "1", "]", "//", "2", "**", "4", ")", ",", "num_classes", ")", ")", "\n", "\n", "# Define loss function", "\n", "self", ".", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "channels", "=", "in_channels", "\n", "# Initialize weights", "\n", "self", ".", "_init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.conv3.Conv3.forward": [[40, 63], ["linear.view", "conv3.Conv3.features", "linear.view", "conv3.Conv3.fc", "conv2d", "batchnorm", "relu", "maxpool", "conv2d", "batchnorm", "relu", "maxpool", "conv2d", "batchnorm", "relu", "maxpool", "linear.view", "linear", "linear.size", "linear.size"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.conv2d", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.batchnorm", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.maxpool", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.conv2d", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.batchnorm", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.maxpool", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.conv2d", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.batchnorm", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.maxpool", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.linear"], ["", "def", "forward", "(", "self", ",", "x", ",", "weights", "=", "None", ")", ":", "\n", "        ", "''' Define what happens to data in the net '''", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "channels", ",", "self", ".", "img_size", "[", "0", "]", ",", "self", ".", "img_size", "[", "1", "]", ")", "\n", "if", "weights", "is", "None", ":", "\n", "            ", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "conv2d", "(", "x", ",", "weights", "[", "'features.conv1.weight'", "]", ",", "weights", "[", "'features.conv1.bias'", "]", ")", "\n", "x", "=", "batchnorm", "(", "x", ",", "weight", "=", "weights", "[", "'features.bn1.weight'", "]", ",", "bias", "=", "weights", "[", "'features.bn1.bias'", "]", ",", "momentum", "=", "1", ")", "\n", "x", "=", "relu", "(", "x", ")", "\n", "x", "=", "maxpool", "(", "x", ",", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", "\n", "x", "=", "conv2d", "(", "x", ",", "weights", "[", "'features.conv2.weight'", "]", ",", "weights", "[", "'features.conv2.bias'", "]", ")", "\n", "x", "=", "batchnorm", "(", "x", ",", "weight", "=", "weights", "[", "'features.bn2.weight'", "]", ",", "bias", "=", "weights", "[", "'features.bn2.bias'", "]", ",", "momentum", "=", "1", ")", "\n", "x", "=", "relu", "(", "x", ")", "\n", "x", "=", "maxpool", "(", "x", ",", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", "\n", "x", "=", "conv2d", "(", "x", ",", "weights", "[", "'features.conv3.weight'", "]", ",", "weights", "[", "'features.conv3.bias'", "]", ")", "\n", "x", "=", "batchnorm", "(", "x", ",", "weight", "=", "weights", "[", "'features.bn3.weight'", "]", ",", "bias", "=", "weights", "[", "'features.bn3.bias'", "]", ",", "momentum", "=", "1", ")", "\n", "x", "=", "relu", "(", "x", ")", "\n", "x", "=", "maxpool", "(", "x", ",", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "linear", "(", "x", ",", "weights", "[", "'fc.weight'", "]", ",", "weights", "[", "'fc.bias'", "]", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.conv3.Conv3.net_forward": [[64, 66], ["conv3.Conv3.forward"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.Identity.forward"], ["", "def", "net_forward", "(", "self", ",", "x", ",", "weights", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "forward", "(", "x", ",", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.conv3.Conv3._init_weights": [[67, 86], ["torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "conv3.Conv3.modules", "isinstance", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.bias.data.zero_", "m.weight.data.fill_", "m.bias.data.zero_", "isinstance", "m.weight.size", "m.weight.data.normal_", "torch.ones", "m.bias.data.size"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ")", ":", "\n", "        ", "''' Set weights to Gaussian, biases to zero '''", "\n", "torch", ".", "manual_seed", "(", "1337", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "1337", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "1337", ")", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.", "/", "n", ")", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "n", "=", "m", ".", "weight", ".", "size", "(", "1", ")", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.01", ")", "\n", "# m.bias.data.zero_() + 1", "\n", "m", ".", "bias", ".", "data", "=", "torch", ".", "ones", "(", "m", ".", "bias", ".", "data", ".", "size", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.conv3.Conv3.copy_weights": [[87, 96], ["zip", "net.modules", "conv3.Conv3.modules", "isinstance", "isinstance", "isinstance", "m_from.weight.data.clone", "m_from.bias.data.clone"], "methods", ["None"], ["", "", "", "def", "copy_weights", "(", "self", ",", "net", ")", ":", "\n", "        ", "''' Set this module's weights to be the same as those of 'net' '''", "\n", "# TODO: breaks if nets are not identical", "\n", "# TODO: won't copy buffers, e.g. for batch norm", "\n", "for", "m_from", ",", "m_to", "in", "zip", "(", "net", ".", "modules", "(", ")", ",", "self", ".", "modules", "(", ")", ")", ":", "\n", "            ", "if", "isinstance", "(", "m_to", ",", "nn", ".", "Linear", ")", "or", "isinstance", "(", "m_to", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "m_to", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m_to", ".", "weight", ".", "data", "=", "m_from", ".", "weight", ".", "data", ".", "clone", "(", ")", "\n", "if", "m_to", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "m_to", ".", "bias", ".", "data", "=", "m_from", ".", "bias", ".", "data", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.conv3.Conv3.forward_pass": [[97, 105], ["in_.cuda", "target.cuda", "conv3.Conv3.net_forward", "conv3.Conv3.loss_fn"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.mlp_detector.MLP.net_forward"], ["", "", "", "", "def", "forward_pass", "(", "self", ",", "in_", ",", "target", ",", "weights", "=", "None", ")", ":", "\n", "        ", "''' Run data through net, return loss and output '''", "\n", "input_var", "=", "in_", ".", "cuda", "(", ")", "\n", "target_var", "=", "target", ".", "cuda", "(", ")", "\n", "# Run the batch through the net, compute loss", "\n", "out", "=", "self", ".", "net_forward", "(", "input_var", ",", "weights", ")", "\n", "loss", "=", "self", ".", "loss_fn", "(", "out", ",", "target_var", ")", "\n", "return", "loss", ",", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.__init__": [[51, 59], ["torch.nn.Module.__init__", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "meta_network.MetaNetwork.construct_module_name_dict", "meta_network.MetaNetwork._init_weights"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.construct_module_name_dict", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork._init_weights"], ["    ", "def", "__init__", "(", "self", ",", "network", ",", "in_channels", ",", "img_size", ")", ":", "\n", "        ", "super", "(", "MetaNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "channels", "=", "in_channels", "\n", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "network", "=", "network", "\n", "self", ".", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "conv_fc_module_to_name", "=", "self", ".", "construct_module_name_dict", "(", ")", "\n", "self", ".", "_init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork._init_weights": [[60, 79], ["torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "meta_network.MetaNetwork.modules", "isinstance", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.bias.data.zero_", "m.weight.data.fill_", "m.bias.data.zero_", "isinstance", "m.weight.size", "m.weight.data.normal_", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "m.bias.data.size"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ")", ":", "\n", "        ", "''' Set weights to Gaussian, biases to zero '''", "\n", "torch", ".", "manual_seed", "(", "1337", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "1337", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "1337", ")", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.", "/", "n", ")", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "n", "=", "m", ".", "weight", ".", "size", "(", "1", ")", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.01", ")", "\n", "# m.bias.data.zero_() + 1", "\n", "m", ".", "bias", ".", "data", "=", "torch", ".", "ones", "(", "m", ".", "bias", ".", "data", ".", "size", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.construct_module_name_dict": [[80, 88], ["collections.defaultdict", "meta_network.MetaNetwork.network.named_modules", "isinstance", "isinstance", "isinstance"], "methods", ["None"], ["", "", "", "def", "construct_module_name_dict", "(", "self", ")", ":", "\n", "        ", "module_to_name", "=", "defaultdict", "(", "dict", ")", "\n", "for", "name", ",", "module", "in", "self", ".", "network", ".", "named_modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "or", "isinstance", "(", "module", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "module_to_name", "[", "module", "]", "[", "\"weight\"", "]", "=", "\"network.{}.weight\"", ".", "format", "(", "name", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "module_to_name", "[", "module", "]", "[", "\"bias\"", "]", "=", "\"network.{}.bias\"", ".", "format", "(", "name", ")", "\n", "", "", "", "return", "module_to_name", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.backup_orig_forward": [[89, 98], ["isinstance", "isinstance", "isinstance", "hasattr", "types.FunctionType", "functools.update_wrapper", "types.MethodType"], "methods", ["None"], ["", "def", "backup_orig_forward", "(", "self", ",", "module", ")", ":", "\n", "        ", "if", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "or", "isinstance", "(", "module", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "            ", "if", "not", "hasattr", "(", "module", ",", "\"orig_forward\"", ")", ":", "\n", "                ", "f", "=", "module", ".", "forward", "\n", "g", "=", "types", ".", "FunctionType", "(", "f", ".", "__code__", ",", "f", ".", "__globals__", ",", "name", "=", "f", ".", "__name__", ",", "\n", "argdefs", "=", "f", ".", "__defaults__", ",", "\n", "closure", "=", "f", ".", "__closure__", ")", "\n", "g", "=", "update_wrapper", "(", "g", ",", "f", ")", "\n", "module", ".", "orig_forward", "=", "types", ".", "MethodType", "(", "g", ",", "module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.recover_orig_forward": [[99, 102], ["isinstance", "isinstance", "isinstance"], "methods", ["None"], ["", "", "", "def", "recover_orig_forward", "(", "self", ",", "module", ")", ":", "\n", "        ", "if", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "or", "isinstance", "(", "module", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "            ", "module", ".", "forward", "=", "module", ".", "orig_forward", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.replace_forward": [[104, 114], ["isinstance", "functools.partial", "isinstance", "types.MethodType", "functools.partial", "isinstance", "types.MethodType", "functools.partial", "types.MethodType"], "methods", ["None"], ["", "", "def", "replace_forward", "(", "self", ",", "module", ",", "weight", ")", ":", "\n", "        ", "if", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", ":", "\n", "            ", "module", ".", "forward", "=", "partial", "(", "types", ".", "MethodType", "(", "conv_weight_forward", ",", "module", ")", ",", "conv_fc_module_to_name", "=", "self", ".", "conv_fc_module_to_name", ",", "\n", "param_dict", "=", "weight", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "module", ".", "forward", "=", "partial", "(", "types", ".", "MethodType", "(", "fc_weight_forward", ",", "module", ")", ",", "conv_fc_module_to_name", "=", "self", ".", "conv_fc_module_to_name", ",", "\n", "param_dict", "=", "weight", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "            ", "module", ".", "forward", "=", "partial", "(", "types", ".", "MethodType", "(", "bn_forward", ",", "module", ")", ",", "conv_fc_module_to_name", "=", "self", ".", "conv_fc_module_to_name", ",", "\n", "param_dict", "=", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward": [[115, 117], ["meta_network.MetaNetwork.network"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "network", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.copy_weights": [[118, 125], ["zip", "net.modules", "meta_network.MetaNetwork.modules", "isinstance", "isinstance", "isinstance", "m_from.weight.data.clone", "m_from.bias.data.clone"], "methods", ["None"], ["", "def", "copy_weights", "(", "self", ",", "net", ")", ":", "\n", "        ", "''' Set this module's weights to be the same as those of 'net' '''", "\n", "for", "m_from", ",", "m_to", "in", "zip", "(", "net", ".", "modules", "(", ")", ",", "self", ".", "modules", "(", ")", ")", ":", "\n", "            ", "if", "isinstance", "(", "m_to", ",", "nn", ".", "Linear", ")", "or", "isinstance", "(", "m_to", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "m_to", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m_to", ".", "weight", ".", "data", "=", "m_from", ".", "weight", ".", "data", ".", "clone", "(", ")", "\n", "if", "m_to", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "m_to", ".", "bias", ".", "data", "=", "m_from", ".", "bias", ".", "data", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.net_forward": [[126, 134], ["meta_network.MetaNetwork.network.apply", "x.view.view.view", "meta_network.MetaNetwork.forward", "meta_network.MetaNetwork.network.apply", "meta_network.MetaNetwork.network.apply", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.Identity.forward"], ["", "", "", "", "def", "net_forward", "(", "self", ",", "x", ",", "weight", "=", "None", ")", ":", "\n", "        ", "self", ".", "network", ".", "apply", "(", "self", ".", "backup_orig_forward", ")", "# \u5907\u4efd\u539f\u672c\u7684forward\u51fd\u6570", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "channels", ",", "self", ".", "img_size", "[", "0", "]", ",", "self", ".", "img_size", "[", "1", "]", ")", "\n", "if", "weight", "is", "not", "None", ":", "\n", "            ", "self", ".", "network", ".", "apply", "(", "partial", "(", "self", ".", "replace_forward", ",", "weight", "=", "weight", ")", ")", "\n", "", "output", "=", "self", ".", "forward", "(", "x", ")", "\n", "self", ".", "network", ".", "apply", "(", "self", ".", "recover_orig_forward", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward_pass": [[135, 141], ["in_.cuda", "target.cuda", "meta_network.MetaNetwork.net_forward", "meta_network.MetaNetwork.loss_fn"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.mlp_detector.MLP.net_forward"], ["", "def", "forward_pass", "(", "self", ",", "in_", ",", "target", ",", "weight", "=", "None", ")", ":", "\n", "        ", "input_var", "=", "in_", ".", "cuda", "(", ")", "\n", "target_var", "=", "target", ".", "cuda", "(", ")", "\n", "out", "=", "self", ".", "net_forward", "(", "input_var", ",", "weight", ")", "\n", "loss", "=", "self", ".", "loss_fn", "(", "out", ",", "target_var", ")", "\n", "return", "loss", ",", "out", "", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.conv_weight_forward": [[9, 19], ["torch.conv2d"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.conv2d"], ["def", "conv_weight_forward", "(", "self", ",", "x", ",", "conv_fc_module_to_name", ",", "param_dict", ")", ":", "\n", "    ", "module_weight_name", "=", "conv_fc_module_to_name", "[", "self", "]", "[", "\"weight\"", "]", "\n", "conv_weight", "=", "param_dict", "[", "module_weight_name", "]", "\n", "conv_bias", "=", "self", ".", "bias", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "        ", "module_bias_name", "=", "conv_fc_module_to_name", "[", "self", "]", "[", "\"bias\"", "]", "\n", "conv_bias", "=", "param_dict", "[", "module_bias_name", "]", "\n", "", "out", "=", "F", ".", "conv2d", "(", "x", ",", "conv_weight", ",", "conv_bias", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "# B, C, H, W", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.fc_weight_forward": [[20, 28], ["torch.linear"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.linear"], ["", "def", "fc_weight_forward", "(", "self", ",", "x", ",", "conv_fc_module_to_name", ",", "param_dict", ")", ":", "\n", "    ", "module_weight_name", "=", "conv_fc_module_to_name", "[", "self", "]", "[", "\"weight\"", "]", "\n", "fc_weight", "=", "param_dict", "[", "module_weight_name", "]", "\n", "fc_bias", "=", "self", ".", "bias", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "        ", "module_bias_name", "=", "conv_fc_module_to_name", "[", "self", "]", "[", "\"bias\"", "]", "\n", "fc_bias", "=", "param_dict", "[", "module_bias_name", "]", "\n", "", "return", "F", ".", "linear", "(", "x", ",", "fc_weight", ",", "fc_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.bn_forward": [[29, 48], ["torch.batch_norm", "meta_network..num_batches_tracked.item"], "function", ["None"], ["", "def", "bn_forward", "(", "self", ",", "x", ",", "conv_fc_module_to_name", ",", "param_dict", ")", ":", "\n", "    ", "exponential_average_factor", "=", "0.0", "\n", "if", "self", ".", "training", "and", "self", ".", "track_running_stats", ":", "\n", "        ", "self", ".", "num_batches_tracked", "+=", "1", "\n", "if", "self", ".", "momentum", "is", "None", ":", "# use cumulative moving average", "\n", "            ", "exponential_average_factor", "=", "1.0", "/", "self", ".", "num_batches_tracked", ".", "item", "(", ")", "\n", "", "else", ":", "# use exponential moving average", "\n", "            ", "exponential_average_factor", "=", "self", ".", "momentum", "\n", "", "", "module_weight_name", "=", "conv_fc_module_to_name", "[", "self", "]", "[", "\"weight\"", "]", "\n", "weight", "=", "param_dict", "[", "module_weight_name", "]", "\n", "bias", "=", "self", ".", "bias", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "        ", "module_bias_name", "=", "conv_fc_module_to_name", "[", "self", "]", "[", "\"bias\"", "]", "\n", "bias", "=", "param_dict", "[", "module_bias_name", "]", "\n", "\n", "", "return", "F", ".", "batch_norm", "(", "\n", "x", ",", "self", ".", "running_mean", ",", "self", ".", "running_var", ",", "weight", ",", "bias", ",", "\n", "self", ".", "training", "or", "not", "self", ".", "track_running_stats", ",", "\n", "exponential_average_factor", ",", "self", ".", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.linear": [[12, 17], ["torch.nn.functional.linear", "torch.nn.functional.linear", "weight.cuda", "weight.cuda", "bias.cuda"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.linear", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.linear"], ["def", "linear", "(", "input", ",", "weight", ",", "bias", "=", "None", ")", ":", "\n", "    ", "if", "bias", "is", "None", ":", "\n", "        ", "return", "F", ".", "linear", "(", "input", ",", "weight", ".", "cuda", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "F", ".", "linear", "(", "input", ",", "weight", ".", "cuda", "(", ")", ",", "bias", ".", "cuda", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.conv2d": [[18, 20], ["torch.nn.functional.conv2d", "weight.cuda", "bias.cuda"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.conv2d"], ["", "", "def", "conv2d", "(", "input", ",", "weight", ",", "bias", "=", "None", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ")", ":", "\n", "    ", "return", "F", ".", "conv2d", "(", "input", ",", "weight", ".", "cuda", "(", ")", ",", "bias", ".", "cuda", "(", ")", ",", "stride", ",", "padding", ",", "dilation", ",", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu": [[21, 23], ["torch.nn.functional.threshold"], "function", ["None"], ["", "def", "relu", "(", "input", ")", ":", "\n", "    ", "return", "F", ".", "threshold", "(", "input", ",", "0", ",", "0", ",", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.maxpool": [[24, 26], ["torch.nn.functional.max_pool2d"], "function", ["None"], ["", "def", "maxpool", "(", "input", ",", "kernel_size", ",", "stride", "=", "None", ")", ":", "\n", "    ", "return", "F", ".", "max_pool2d", "(", "input", ",", "kernel_size", ",", "stride", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.batchnorm": [[27, 34], ["torch.zeros().cuda", "torch.ones().cuda", "torch.nn.functional.batch_norm", "torch.zeros", "torch.ones", "numpy.prod", "numpy.prod", "numpy.array", "numpy.array", "input.data.size", "input.data.size"], "function", ["None"], ["", "def", "batchnorm", "(", "input", ",", "weight", "=", "None", ",", "bias", "=", "None", ",", "running_mean", "=", "None", ",", "running_var", "=", "None", ",", "training", "=", "True", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ")", ":", "\n", "    ", "''' momentum = 1 restricts stats to the current mini-batch '''", "\n", "# This hack only works when momentum is 1 and avoids needing to track running stats", "\n", "# by substuting dummy variables", "\n", "running_mean", "=", "torch", ".", "zeros", "(", "np", ".", "prod", "(", "np", ".", "array", "(", "input", ".", "data", ".", "size", "(", ")", "[", "1", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "running_var", "=", "torch", ".", "ones", "(", "np", ".", "prod", "(", "np", ".", "array", "(", "input", ".", "data", ".", "size", "(", ")", "[", "1", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "return", "F", ".", "batch_norm", "(", "input", ",", "running_mean", ",", "running_var", ",", "weight", ",", "bias", ",", "training", ",", "momentum", ",", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.bilinear_upsample": [[35, 37], ["torch.nn.functional.upsample"], "function", ["None"], ["", "def", "bilinear_upsample", "(", "in_", ",", "factor", ")", ":", "\n", "    ", "return", "F", ".", "upsample", "(", "in_", ",", "None", ",", "factor", ",", "'bilinear'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.log_softmax": [[38, 40], ["torch.nn.functional.log_softmax"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.log_softmax"], ["", "def", "log_softmax", "(", "input", ")", ":", "\n", "    ", "return", "F", ".", "log_softmax", "(", "input", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.BasicBlock.__init__": [[27, 36], ["torch.Module.__init__", "resnet.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "resnet.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.conv3x3", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.BasicBlock.forward": [[37, 54], ["resnet.BasicBlock.conv1", "resnet.BasicBlock.bn1", "resnet.BasicBlock.relu", "resnet.BasicBlock.conv2", "resnet.BasicBlock.bn2", "resnet.BasicBlock.relu", "resnet.BasicBlock.downsample"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.Bottleneck.__init__": [[59, 70], ["torch.Module.__init__", "resnet.conv1x1", "torch.BatchNorm2d", "torch.BatchNorm2d", "resnet.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "resnet.conv1x1", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.conv1x1", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.conv3x3", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.conv1x1"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv1x1", "(", "inplanes", ",", "planes", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "conv1x1", "(", "planes", ",", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.Bottleneck.forward": [[71, 92], ["resnet.Bottleneck.conv1", "resnet.Bottleneck.bn1", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv2", "resnet.Bottleneck.bn2", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv3", "resnet.Bottleneck.bn3", "resnet.Bottleneck.relu", "resnet.Bottleneck.downsample"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.ResNet.__init__": [[96, 132], ["torch.Module.__init__", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Linear", "torch.Linear", "resnet.ResNet.modules", "len", "resnet.ResNet._make_layer", "isinstance", "resnet.ResNet.modules", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "isinstance", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "in_channels", "=", "3", ",", "num_classes", "=", "15", ",", "zero_init_residual", "=", "False", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "inplanes", "=", "64", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "64", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "if", "len", "(", "layers", ")", ">", "3", ":", "\n", "            ", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "\n", "", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "# self.fc = nn.Linear(512 * block.expansion, num_classes)", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n", "# Zero-initialize the last BN in each residual branch,", "\n", "# so that the residual branch starts with zeros, and each residual block behaves like an identity.", "\n", "# This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677", "\n", "", "", "if", "zero_init_residual", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "Bottleneck", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn3", ".", "weight", ",", "0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "BasicBlock", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn2", ".", "weight", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.ResNet.copy_weights": [[133, 140], ["zip", "net.modules", "resnet.ResNet.modules", "isinstance", "isinstance", "isinstance", "m_from.weight.data.clone", "m_from.bias.data.clone"], "methods", ["None"], ["", "", "", "", "def", "copy_weights", "(", "self", ",", "net", ")", ":", "\n", "        ", "''' Set this module's weights to be the same as those of 'net' '''", "\n", "for", "m_from", ",", "m_to", "in", "zip", "(", "net", ".", "modules", "(", ")", ",", "self", ".", "modules", "(", ")", ")", ":", "\n", "            ", "if", "isinstance", "(", "m_to", ",", "nn", ".", "Linear", ")", "or", "isinstance", "(", "m_to", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "m_to", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m_to", ".", "weight", ".", "data", "=", "m_from", ".", "weight", ".", "data", ".", "clone", "(", ")", "\n", "if", "m_to", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "m_to", ".", "bias", ".", "data", "=", "m_from", ".", "bias", ".", "data", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.ResNet._make_layer": [[141, 156], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "resnet.conv1x1", "torch.BatchNorm2d", "torch.BatchNorm2d", "block"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.conv1x1"], ["", "", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "filters", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "filters", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "conv1x1", "(", "self", ".", "inplanes", ",", "filters", "*", "block", ".", "expansion", ",", "stride", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "filters", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "filters", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "filters", "*", "block", ".", "expansion", "\n", "for", "_", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "filters", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.ResNet.forward": [[157, 174], ["resnet.ResNet.conv1", "resnet.ResNet.bn1", "resnet.ResNet.relu", "resnet.ResNet.maxpool", "resnet.ResNet.layer1", "resnet.ResNet.layer2", "resnet.ResNet.layer3", "hasattr", "resnet.ResNet.avgpool", "resnet.ResNet.view", "resnet.ResNet.fc", "resnet.ResNet.layer4", "resnet.ResNet.size"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.maxpool"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "if", "hasattr", "(", "self", ",", "\"layer4\"", ")", ":", "\n", "            ", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.ResNet.net_forward": [[175, 178], ["x.view.view.view", "resnet.ResNet.forward"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.Identity.forward"], ["", "def", "net_forward", "(", "self", ",", "x", ",", "weights", "=", "None", ")", ":", "\n", "        ", "x", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "in_channels", ",", "224", ",", "224", ")", "# FIXME!!", "\n", "return", "self", ".", "forward", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.conv3x3": [[13, 17], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.conv1x1": [[19, 22], ["torch.Conv2d"], "function", ["None"], ["", "def", "conv1x1", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"1x1 convolution\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet8": [[179, 182], ["resnet.ResNet"], "function", ["None"], ["", "", "def", "resnet8", "(", "num_classes", ",", "**", "kwards", ")", ":", "\n", "    ", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "1", ",", "1", ",", "1", "]", ",", "num_classes", "=", "num_classes", ",", "**", "kwards", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet18": [[183, 192], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet18", "(", "num_classes", ",", "in_channels", "=", "3", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "in_channels", "=", "in_channels", ",", "num_classes", "=", "num_classes", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet18'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet10": [[195, 203], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet10", "(", "num_classes", ",", "in_channels", "=", "3", ",", "**", "kwards", ")", ":", "\n", "    ", "\"\"\"\n    Construct a ResNet-10 model\n    :param kwards:\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "num_classes", "=", "num_classes", ",", "in_channels", "=", "in_channels", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet50": [[207, 216], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet50'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet101": [[218, 227], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet101", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet101'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet152": [[229, 238], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet152", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-152 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet152'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.mlp_detector.MLP.__init__": [[4, 13], ["torch.nn.Module.__init__", "torch.nn.CrossEntropyLoss", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "output_dim", ")", ":", "\n", "        ", "super", "(", "MLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "seq", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "input_dim", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "128", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "128", ",", "output_dim", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.mlp_detector.MLP.forward": [[14, 16], ["mlp_detector.MLP.seq"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "feature", ")", ":", "\n", "        ", "return", "self", ".", "seq", "(", "feature", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.mlp_detector.MLP.net_forward": [[17, 19], ["mlp_detector.MLP.forward"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.Identity.forward"], ["", "def", "net_forward", "(", "self", ",", "feature", ")", ":", "\n", "        ", "return", "self", ".", "forward", "(", "feature", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation_toolkit.evaluation.accuracy": [[14, 28], ["torch.no_grad", "max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "            ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation_toolkit.evaluation.finetune_eval_task_rotate": [[31, 75], ["copy.deepcopy", "enumerate", "numpy.mean", "numpy.mean", "print", "print", "print", "print", "support_labels.cuda.cuda", "query_labels.cuda.cuda", "range", "numpy.array", "numpy.array", "support_images.size", "copy.deepcopy", "copy.deepcopy.cuda", "torch.optim.SGD", "copy.deepcopy.train", "range", "copy.deepcopy.eval", "meta_adv_detector.score.evaluate_two_way", "meta_adv_detector.score.evaluate_two_way", "support_F1_list.append", "query_F1_list.append", "copy.deepcopy.parameters", "copy.deepcopy.modules", "meta_adv_detector.score.forward_pass", "torch.optim.SGD.zero_grad", "loss.backward", "torch.optim.SGD.step", "isinstance", "len", "m.eval"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.evaluate_two_way", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.evaluate_two_way", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward_pass"], ["", "", "def", "finetune_eval_task_rotate", "(", "network", ",", "val_loader", ",", "inner_lr", ",", "num_updates", ",", "update_BN", "=", "True", ",", "limit", "=", "-", "1", ")", ":", "\n", "# test_net = copy.deepcopy(network)", "\n", "# Select ten tasks randomly from the test set to evaluate_accuracy on", "\n", "    ", "support_F1_list", ",", "query_F1_list", "=", "[", "]", ",", "[", "]", "\n", "test_net", "=", "copy", ".", "deepcopy", "(", "network", ")", "\n", "# support_images,support_gt_labels, support_binary_labels, query_images, query_gt_labels, query_binary_labels", "\n", "for", "val_idx", ",", "(", "support_images", ",", "_", ",", "support_labels", ",", "query_images", ",", "_", ",", "query_labels", ",", "positive_labels", ")", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "# print(\"process task {}  task_batch={}\".format(val_idx, len(support_images)))", "\n", "        ", "support_labels", "=", "support_labels", ".", "cuda", "(", ")", "\n", "query_labels", "=", "query_labels", ".", "cuda", "(", ")", "\n", "for", "task_idx", "in", "range", "(", "support_images", ".", "size", "(", "0", ")", ")", ":", "\n", "# Make a test net with same parameters as our current net", "\n", "            ", "test_net", "=", "copy", ".", "deepcopy", "(", "network", ")", "\n", "test_net", ".", "cuda", "(", ")", "\n", "test_opt", "=", "SGD", "(", "test_net", ".", "parameters", "(", ")", ",", "lr", "=", "inner_lr", ")", "\n", "support_task", ",", "support_target", "=", "support_images", "[", "task_idx", "]", ",", "support_labels", "[", "task_idx", "]", "\n", "test_net", ".", "train", "(", ")", "\n", "if", "not", "update_BN", ":", "\n", "                ", "for", "m", "in", "test_net", ".", "modules", "(", ")", ":", "\n", "                    ", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                        ", "m", ".", "eval", "(", ")", "\n", "", "", "", "for", "i", "in", "range", "(", "num_updates", ")", ":", "# \u5148fine_tune", "\n", "                ", "loss", ",", "out", "=", "forward_pass", "(", "test_net", ",", "support_task", ",", "support_target", ")", "\n", "test_opt", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "test_opt", ".", "step", "(", ")", "\n", "", "test_net", ".", "eval", "(", ")", "\n", "# Evaluate the trained model on train and val examples", "\n", "support_acc", ",", "support_F1_score", "=", "evaluate_two_way", "(", "test_net", ",", "support_task", ",", "support_target", ")", "\n", "query_acc", ",", "query_F1_score", "=", "evaluate_two_way", "(", "test_net", ",", "query_images", "[", "task_idx", "]", ",", "query_labels", "[", "task_idx", "]", ")", "\n", "support_F1_list", ".", "append", "(", "support_F1_score", ")", "\n", "query_F1_list", ".", "append", "(", "query_F1_score", ")", "\n", "if", "limit", ">", "0", "and", "len", "(", "query_F1_list", ")", ">=", "limit", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "support_F1", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "support_F1_list", ")", ")", "\n", "query_F1", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "query_F1_list", ")", ")", "\n", "result_json", "=", "{", "\"query_F1\"", ":", "query_F1", ",", "\"num_updates\"", ":", "num_updates", "}", "\n", "print", "(", "'-------------------------'", ")", "\n", "print", "(", "'Support F1: {}'", ".", "format", "(", "support_F1", ")", ")", "\n", "print", "(", "'Query F1: {}'", ".", "format", "(", "query_F1", ")", ")", "\n", "print", "(", "'-------------------------'", ")", "\n", "del", "test_net", "\n", "return", "result_json", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation_toolkit.evaluation.finetune_eval_task_accuracy": [[77, 137], ["copy.deepcopy", "collections.defaultdict", "enumerate", "numpy.mean", "numpy.mean", "collections.defaultdict.items", "print", "print", "print", "print", "support_labels.cuda.cuda", "query_labels.cuda.cuda", "range", "numpy.array", "numpy.array", "numpy.mean", "support_images.size", "time.time", "copy.deepcopy", "copy.deepcopy.cuda", "torch.optim.SGD", "copy.deepcopy.train", "range", "copy.deepcopy.eval", "meta_adv_detector.score.evaluate_two_way", "meta_adv_detector.score.evaluate_two_way", "torch.cuda.empty_cache", "support_F1_list.append", "query_F1_list.append", "copy.deepcopy.parameters", "copy.deepcopy.modules", "meta_adv_detector.score.forward_pass", "torch.optim.SGD.zero_grad", "loss.backward", "torch.optim.SGD.step", "attack_stats[].append", "isinstance", "len", "m.eval", "adversary_indexes[].item"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.evaluate_two_way", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.score.evaluate_two_way", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward_pass"], ["", "def", "finetune_eval_task_accuracy", "(", "network", ",", "val_loader", ",", "inner_lr", ",", "num_updates", ",", "update_BN", "=", "True", ",", "limit", "=", "-", "1", ")", ":", "\n", "# Select ten tasks randomly from the test set to evaluate_accuracy on", "\n", "    ", "test_net", "=", "copy", ".", "deepcopy", "(", "network", ")", "\n", "support_F1_list", ",", "query_F1_list", "=", "[", "]", ",", "[", "]", "\n", "# support_images,support_gt_labels, support_binary_labels, query_images, query_gt_labels, query_binary_labels", "\n", "each_attack_stats", "=", "val_loader", ".", "dataset", ".", "fetch_attack_name", "\n", "attack_stats", "=", "defaultdict", "(", "list", ")", "\n", "for", "idx", ",", "pack", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "        ", "if", "each_attack_stats", ":", "\n", "            ", "support_images", ",", "_", ",", "support_labels", ",", "query_images", ",", "_", ",", "query_labels", ",", "adversary_indexes", ",", "positive_labels", "=", "pack", "\n", "", "else", ":", "\n", "            ", "support_images", ",", "_", ",", "support_labels", ",", "query_images", ",", "_", ",", "query_labels", ",", "positive_labels", "=", "pack", "\n", "# print(\"process task {}  task_batch={}\".format(val_idx, len(support_images)))", "\n", "", "support_labels", "=", "support_labels", ".", "cuda", "(", ")", "\n", "query_labels", "=", "query_labels", ".", "cuda", "(", ")", "\n", "for", "task_idx", "in", "range", "(", "support_images", ".", "size", "(", "0", ")", ")", ":", "\n", "# Make a test net with same parameters as our current net", "\n", "            ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "test_net", "=", "copy", ".", "deepcopy", "(", "network", ")", "\n", "test_net", ".", "cuda", "(", ")", "\n", "test_opt", "=", "SGD", "(", "test_net", ".", "parameters", "(", ")", ",", "lr", "=", "inner_lr", ")", "\n", "support_task", ",", "support_target", "=", "support_images", "[", "task_idx", "]", ",", "support_labels", "[", "task_idx", "]", "\n", "\n", "test_net", ".", "train", "(", ")", "\n", "if", "not", "update_BN", ":", "\n", "                ", "for", "m", "in", "test_net", ".", "modules", "(", ")", ":", "\n", "                    ", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                        ", "m", ".", "eval", "(", ")", "\n", "", "", "", "for", "i", "in", "range", "(", "num_updates", ")", ":", "# \u5148fine_tune", "\n", "                ", "loss", ",", "out", "=", "forward_pass", "(", "test_net", ",", "support_task", ",", "support_target", ")", "\n", "test_opt", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "test_opt", ".", "step", "(", ")", "\n", "", "test_net", ".", "eval", "(", ")", "\n", "# Evaluate the trained model on train and val examples", "\n", "support_acc", ",", "support_F1_score", "=", "evaluate_two_way", "(", "test_net", ",", "support_task", ",", "support_target", ")", "\n", "query_acc", ",", "query_F1_score", "=", "evaluate_two_way", "(", "test_net", ",", "query_images", "[", "task_idx", "]", ",", "query_labels", "[", "task_idx", "]", ")", "\n", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "if", "each_attack_stats", ":", "\n", "                ", "adversary", "=", "META_ATTACKER_INDEX", "[", "adversary_indexes", "[", "task_idx", "]", ".", "item", "(", ")", "]", "\n", "attack_stats", "[", "adversary", "]", ".", "append", "(", "query_F1_score", ")", "\n", "", "support_F1_list", ".", "append", "(", "support_F1_score", ")", "\n", "query_F1_list", ".", "append", "(", "query_F1_score", ")", "\n", "if", "limit", ">", "0", "and", "len", "(", "query_F1_list", ")", ">=", "limit", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "support_F1", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "support_F1_list", ")", ")", "\n", "query_F1", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "query_F1_list", ")", ")", "\n", "for", "adversary", ",", "query_F1_score_list", "in", "attack_stats", ".", "items", "(", ")", ":", "\n", "        ", "attack_stats", "[", "adversary", "]", "=", "np", ".", "mean", "(", "query_F1_score_list", ")", "\n", "", "if", "each_attack_stats", ":", "\n", "        ", "result_json", "=", "{", "\"query_F1\"", ":", "query_F1", ",", "\"num_updates\"", ":", "num_updates", ",", "\"attack_stats\"", ":", "attack_stats", "}", "\n", "", "else", ":", "\n", "        ", "result_json", "=", "{", "\"query_F1\"", ":", "query_F1", ",", "\"num_updates\"", ":", "num_updates", "}", "\n", "", "print", "(", "'-------------------------'", ")", "\n", "print", "(", "'Support F1: {}'", ".", "format", "(", "support_F1", ")", ")", "\n", "print", "(", "'Query F1: {}'", ".", "format", "(", "query_F1", ")", ")", "\n", "print", "(", "'-------------------------'", ")", "\n", "return", "result_json", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.train_fingerprint.parse_args": [[35, 80], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "str", "list", "list"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.train_fingerprint.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "# Training settings", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'PyTorch train_fingerprint Example'", ")", "\n", "parser", ".", "add_argument", "(", "'--ds_name'", ",", "type", "=", "str", ",", "default", "=", "'CIFAR-10'", ",", "\n", "help", "=", "'Dataset -- mnist, cifar, miniimagenet'", ")", "\n", "parser", ".", "add_argument", "(", "\"--arch\"", ",", "type", "=", "str", ",", "default", "=", "\"conv3\"", ",", "choices", "=", "[", "\"conv3\"", ",", "\"resnet10\"", ",", "\"resnet18\"", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'input batch size for training (default: 64)'", ")", "\n", "parser", ".", "add_argument", "(", "'--test-batch-size'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'input batch size for testing (default: 1000)'", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "80", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'number of epochs to train (default: 80)'", ")", "# CIFAR-10:80, MNIST:1", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "metavar", "=", "'LR'", ",", "\n", "help", "=", "'learning rate (default: 0.001)'", ")", "# MNIST\u5e94\u8be5\u7528\u66f4\u4f4e\u7684\u503c", "\n", "parser", ".", "add_argument", "(", "'--gpu'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'the GPU for train'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "metavar", "=", "'S'", ",", "\n", "help", "=", "'random seed (default: 1)'", ")", "\n", "parser", ".", "add_argument", "(", "'--log-interval'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'how many batches to wait before logging training status'", ")", "\n", "parser", ".", "add_argument", "(", "'-j'", ",", "'--workers'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'number of data loading workers (default: 4)'", ")", "\n", "parser", ".", "add_argument", "(", "'--eps'", ",", "type", "=", "float", ",", "default", "=", "0.003", ")", "# 0.003 0.006 0.01 \u90fd\u8bd5\u8bd5", "\n", "parser", ".", "add_argument", "(", "'--num-dx'", ",", "type", "=", "int", ",", "default", "=", "30", ")", "# 5 10 30  \u90fd\u8bd5\u8bd5", "\n", "parser", ".", "add_argument", "(", "\"--output_dx_dy_dir\"", ",", "type", "=", "str", ",", "default", "=", "\"/home1/machen/adv_detection_meta_learning/NF_dx_dy\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"eval with fingerprint\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--protocol\"", ",", "\n", "type", "=", "SPLIT_DATA_PROTOCOL", ",", "choices", "=", "list", "(", "SPLIT_DATA_PROTOCOL", ")", ",", "help", "=", "\"split data protocol\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--load_task_mode\"", ",", "default", "=", "LOAD_TASK_MODE", ".", "LOAD", ",", "type", "=", "LOAD_TASK_MODE", ",", "choices", "=", "list", "(", "LOAD_TASK_MODE", ")", ",", "help", "=", "\"load task mode\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_updates\"", ",", "type", "=", "int", ",", "default", "=", "20", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_way\"", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_support\"", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_query\"", ",", "type", "=", "int", ",", "default", "=", "15", ")", "\n", "parser", ".", "add_argument", "(", "\"--log-dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--profile\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"use profile to stats evaluation speed\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--study_subject\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv_arch\"", ",", "type", "=", "str", ",", "default", "=", "\"conv4\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cross_domain_source\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--best_tau\"", ",", "type", "=", "float", ",", "default", "=", "1.475234", ")", "\n", "parser", ".", "add_argument", "(", "\"--cross_domain_target\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--cross_arch_target\"", ",", "type", "=", "str", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "os", ".", "environ", "[", "\"CUDA_DEVICE_ORDER\"", "]", "=", "\"PCI_BUS_ID\"", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "str", "(", "args", ".", "gpu", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.train_fingerprint.main": [[84, 308], ["train_fingerprint.parse_args", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "toolkit.img_transform.get_preprocessor", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "networks.resnet.resnet18.cuda", "os.path.join", "os.makedirs", "neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector", "torch.SGD", "print", "os.path.exists", "range", "re.compile", "collections.defaultdict", "glob.glob", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "networks.conv3.Conv3", "os.path.dirname", "networks.resnet.resnet18.parameters", "torch.load", "torch.load", "optim.SGD.load_state_dict", "networks.resnet.resnet18.load_state_dict", "neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.train", "print", "torch.save", "torch.save", "neural_fingerprint.evaluation.speed_evaluation.evaluate_speed", "re.compile.match", "extract_pattern.match.group", "extract_pattern.match.group", "int", "int", "float", "networks.resnet.resnet18.load_state_dict", "networks.resnet.resnet18.cuda", "print", "neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector", "torchvision.datasets.FashionMNIST", "torchvision.datasets.FashionMNIST", "networks.resnet.resnet10", "neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.test", "extract_pattern.match.group", "extract_pattern.match.group", "extract_pattern.match.group", "networks.conv3.Conv3", "open", "file_obj.write", "file_obj.flush", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "networks.resnet.resnet18", "networks.resnet.resnet18.state_dict", "optim.SGD.state_dict", "networks.resnet.resnet10", "range", "torch.load", "torch.load", "dataset.meta_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.eval_with_fingerprints_finetune", "print", "json.dumps", "dataset.SVHN_dataset.SVHN", "dataset.SVHN_dataset.SVHN", "networks.resnet.resnet18", "dataset.meta_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.eval_with_fingerprints_finetune", "dataset.imagenet_real_dataset.ImageNetRealDataset", "dataset.imagenet_real_dataset.ImageNetRealDataset", "len", "dataset.meta_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.eval_with_fingerprints_finetune", "dataset.meta_task_dataset.MetaTaskDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.eval_with_fingerprints_finetune", "print"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.train_fingerprint.parse_args", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.toolkit.img_transform.get_preprocessor", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.evaluation.speed_evaluation.evaluate_speed", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet10", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.test", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet18", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet10", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.eval_with_fingerprints_finetune", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet18", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.eval_with_fingerprints_finetune", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.eval_with_fingerprints_finetune", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.eval_with_fingerprints_finetune"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "transform", "=", "get_preprocessor", "(", "IN_CHANNELS", "[", "args", ".", "ds_name", "]", ",", "IMAGE_SIZE", "[", "args", ".", "ds_name", "]", ")", "# NeuralFP\u7684MNIST\u548cF-MNIST\u5b9e\u9a8c\u9700\u8981\u91cd\u505a\uff0c\u56e0\u4e3a\u53d1\u73b0\u5355\u901a\u9053bug", "\n", "kwargs", "=", "{", "'pin_memory'", ":", "True", "}", "\n", "if", "not", "args", ".", "evaluate", ":", "# \u8bad\u7ec3\u6a21\u5f0f", "\n", "        ", "if", "args", ".", "ds_name", "==", "\"MNIST\"", ":", "\n", "            ", "trn_dataset", "=", "datasets", ".", "MNIST", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "ds_name", "]", ",", "train", "=", "True", ",", "download", "=", "False", ",", "transform", "=", "transform", ")", "\n", "val_dataset", "=", "datasets", ".", "MNIST", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "ds_name", "]", ",", "train", "=", "False", ",", "download", "=", "False", ",", "\n", "transform", "=", "transform", ")", "\n", "", "elif", "args", ".", "ds_name", "==", "\"F-MNIST\"", ":", "\n", "            ", "trn_dataset", "=", "datasets", ".", "FashionMNIST", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "ds_name", "]", ",", "train", "=", "True", ",", "download", "=", "False", ",", "\n", "transform", "=", "transform", ")", "\n", "val_dataset", "=", "datasets", ".", "FashionMNIST", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "ds_name", "]", ",", "train", "=", "False", ",", "download", "=", "False", ",", "\n", "transform", "=", "transform", ")", "\n", "", "elif", "args", ".", "ds_name", "==", "\"CIFAR-10\"", ":", "\n", "            ", "trn_dataset", "=", "datasets", ".", "CIFAR10", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "ds_name", "]", ",", "train", "=", "True", ",", "download", "=", "False", ",", "\n", "transform", "=", "transform", ")", "\n", "val_dataset", "=", "datasets", ".", "CIFAR10", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "ds_name", "]", ",", "train", "=", "False", ",", "download", "=", "False", ",", "\n", "transform", "=", "transform", ")", "\n", "", "elif", "args", ".", "ds_name", "==", "\"SVHN\"", ":", "\n", "            ", "trn_dataset", "=", "SVHN", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "ds_name", "]", ",", "train", "=", "True", ",", "transform", "=", "transform", ")", "\n", "val_dataset", "=", "SVHN", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "ds_name", "]", ",", "train", "=", "False", ",", "transform", "=", "transform", ")", "\n", "", "elif", "args", ".", "ds_name", "==", "\"ImageNet\"", ":", "\n", "            ", "trn_dataset", "=", "ImageNetRealDataset", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "ds_name", "]", "+", "\"/new2\"", ",", "train", "=", "True", ",", "transform", "=", "transform", ")", "\n", "val_dataset", "=", "ImageNetRealDataset", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "ds_name", "]", "+", "\"/new2\"", ",", "train", "=", "False", ",", "transform", "=", "transform", ")", "\n", "\n", "", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "trn_dataset", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "num_workers", "=", "args", ".", "workers", ",", "**", "kwargs", ")", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "val_dataset", ",", "\n", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "num_workers", "=", "0", ",", "**", "kwargs", ")", "\n", "\n", "if", "args", ".", "arch", "==", "\"conv3\"", ":", "\n", "            ", "network", "=", "Conv3", "(", "IN_CHANNELS", "[", "args", ".", "ds_name", "]", ",", "IMAGE_SIZE", "[", "args", ".", "ds_name", "]", ",", "CLASS_NUM", "[", "args", ".", "ds_name", "]", ")", "\n", "", "elif", "args", ".", "arch", "==", "\"resnet10\"", ":", "\n", "            ", "network", "=", "resnet10", "(", "in_channels", "=", "IN_CHANNELS", "[", "args", ".", "ds_name", "]", ",", "num_classes", "=", "CLASS_NUM", "[", "args", ".", "ds_name", "]", ")", "\n", "", "elif", "args", ".", "arch", "==", "\"resnet18\"", ":", "\n", "            ", "network", "=", "resnet18", "(", "in_channels", "=", "IN_CHANNELS", "[", "args", ".", "ds_name", "]", ",", "num_classes", "=", "CLASS_NUM", "[", "args", ".", "ds_name", "]", ")", "\n", "", "network", ".", "cuda", "(", ")", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "PY_ROOT", ",", "\"train_pytorch_model/NF_Det\"", ",", "\n", "\"NF_Det@{}@{}@epoch_{}@lr_{}@eps_{}@num_dx_{}@num_class_{}.pth.tar\"", ".", "format", "(", "\n", "args", ".", "ds_name", ",", "\n", "args", ".", "arch", ",", "args", ".", "epochs", ",", "\n", "args", ".", "lr", ",", "args", ".", "eps", ",", "\n", "args", ".", "num_dx", ",", "\n", "CLASS_NUM", "[", "args", ".", "ds_name", "]", ")", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "model_path", ")", ",", "exist_ok", "=", "True", ")", "\n", "detector", "=", "NeuralFingerprintDetector", "(", "args", ".", "ds_name", ",", "network", ",", "args", ".", "num_dx", ",", "CLASS_NUM", "[", "args", ".", "ds_name", "]", ",", "eps", "=", "args", ".", "eps", ",", "\n", "out_fp_dxdy_dir", "=", "args", ".", "output_dx_dy_dir", ")", "\n", "\n", "optimizer", "=", "optim", ".", "SGD", "(", "network", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ",", "weight_decay", "=", "1e-6", ",", "momentum", "=", "0.9", ")", "\n", "resume_epoch", "=", "0", "\n", "print", "(", "\"{}\"", ".", "format", "(", "model_path", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "model_path", ")", ":", "\n", "            ", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "\"optimizer\"", "]", ")", "\n", "resume_epoch", "=", "checkpoint", "[", "\"epoch\"", "]", "\n", "network", ".", "load_state_dict", "(", "checkpoint", "[", "\"state_dict\"", "]", ")", "\n", "\n", "", "for", "epoch", "in", "range", "(", "resume_epoch", ",", "args", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "if", "(", "epoch", "==", "1", ")", ":", "\n", "                ", "detector", ".", "test", "(", "epoch", ",", "test_loader", ",", "test_length", "=", "0.1", "*", "len", "(", "val_dataset", ")", ")", "\n", "", "detector", ".", "train", "(", "epoch", ",", "optimizer", ",", "train_loader", ")", "\n", "\n", "print", "(", "\"Epoch{}, Saving model in {}\"", ".", "format", "(", "epoch", ",", "model_path", ")", ")", "\n", "torch", ".", "save", "(", "{", "\n", "'epoch'", ":", "epoch", "+", "1", ",", "\n", "'arch'", ":", "args", ".", "arch", ",", "\n", "'state_dict'", ":", "network", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "model_path", ")", "\n", "", "", "else", ":", "# \u6d4b\u8bd5\u6a21\u5f0f", "\n", "\n", "        ", "if", "args", ".", "study_subject", "==", "\"speed_test\"", ":", "\n", "            ", "evaluate_speed", "(", "args", ")", "\n", "return", "\n", "\n", "", "extract_pattern", "=", "re", ".", "compile", "(", "\".*NF_Det@(.*?)@(.*?)@epoch_(\\d+)@lr_(.*?)@eps_(.*?)@num_dx_(\\d+)@num_class_(\\d+).pth.tar\"", ")", "\n", "results", "=", "defaultdict", "(", "dict", ")", "\n", "for", "model_path", "in", "glob", ".", "glob", "(", "\"{}/train_pytorch_model/NF_Det/NF_Det@*\"", ".", "format", "(", "PY_ROOT", ")", ")", ":", "\n", "            ", "ma", "=", "extract_pattern", ".", "match", "(", "model_path", ")", "\n", "ds_name", "=", "ma", ".", "group", "(", "1", ")", "\n", "# if ds_name == \"ImageNet\": # FIXME", "\n", "#     continue", "\n", "# if ds_name != \"CIFAR-10\": # FIXME", "\n", "#     continue", "\n", "\n", "arch", "=", "ma", ".", "group", "(", "2", ")", "\n", "epoch", "=", "int", "(", "ma", ".", "group", "(", "3", ")", ")", "\n", "num_dx", "=", "int", "(", "ma", ".", "group", "(", "6", ")", ")", "\n", "eps", "=", "float", "(", "ma", ".", "group", "(", "5", ")", ")", "\n", "if", "arch", "==", "\"conv3\"", ":", "\n", "                ", "network", "=", "Conv3", "(", "IN_CHANNELS", "[", "ds_name", "]", ",", "IMAGE_SIZE", "[", "ds_name", "]", ",", "CLASS_NUM", "[", "ds_name", "]", ")", "\n", "", "elif", "arch", "==", "\"resnet10\"", ":", "\n", "                ", "network", "=", "resnet10", "(", "in_channels", "=", "IN_CHANNELS", "[", "ds_name", "]", ",", "num_classes", "=", "CLASS_NUM", "[", "ds_name", "]", ")", "\n", "", "elif", "arch", "==", "\"resnet18\"", ":", "\n", "                ", "network", "=", "resnet18", "(", "in_channels", "=", "IN_CHANNELS", "[", "ds_name", "]", ",", "num_classes", "=", "CLASS_NUM", "[", "ds_name", "]", ")", "\n", "", "reject_thresholds", "=", "[", "0.", "+", "0.001", "*", "i", "for", "i", "in", "range", "(", "2050", ")", "]", "\n", "network", ".", "load_state_dict", "(", "torch", ".", "load", "(", "model_path", ",", "lambda", "storage", ",", "location", ":", "storage", ")", "[", "\"state_dict\"", "]", ")", "\n", "network", ".", "cuda", "(", ")", "\n", "print", "(", "\"load {} over\"", ".", "format", "(", "model_path", ")", ")", "\n", "detector", "=", "NeuralFingerprintDetector", "(", "ds_name", ",", "network", ",", "num_dx", ",", "CLASS_NUM", "[", "ds_name", "]", ",", "eps", "=", "eps", ",", "\n", "out_fp_dxdy_dir", "=", "args", ".", "output_dx_dy_dir", ")", "\n", "# \u4e0d\u5b58\u5728cross arch\u7684\u6982\u5ff5", "\n", "if", "args", ".", "study_subject", "==", "\"shots\"", ":", "\n", "                ", "all_shots", "=", "[", "0", ",", "1", ",", "5", "]", "\n", "# threhold_dict = {0:0.885896, 1:1.23128099999,5:1.33487699}", "\n", "old_updates", "=", "args", ".", "num_updates", "\n", "# threhold_dict = {0:0.885896, 1:1.23128099999,5:1.33487699}", "\n", "for", "shot", "in", "all_shots", ":", "\n", "                    ", "report_shot", "=", "shot", "\n", "if", "shot", "==", "0", ":", "\n", "                        ", "shot", "=", "1", "\n", "args", ".", "num_updates", "=", "0", "\n", "", "else", ":", "\n", "                        ", "args", ".", "num_updates", "=", "old_updates", "\n", "", "num_way", "=", "2", "\n", "num_query", "=", "15", "\n", "val_dataset", "=", "MetaTaskDataset", "(", "20000", ",", "num_way", ",", "shot", ",", "num_query", ",", "ds_name", ",", "is_train", "=", "False", ",", "load_mode", "=", "args", ".", "load_task_mode", ",", "\n", "protocol", "=", "args", ".", "protocol", ",", "no_random_way", "=", "True", ",", "adv_arch", "=", "args", ".", "adv_arch", ",", "fetch_attack_name", "=", "True", ")", "\n", "adv_val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "val_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "# if args.profile:", "\n", "#     cProfile.runctx(\"detector.eval_with_fingerprints_finetune(adv_val_loader, ds_name, reject_thresholds, args.num_updates, args.lr)\", globals(), locals(), \"Profile.prof\")", "\n", "#     s = pstats.Stats(\"Profile.prof\")", "\n", "#     s.strip_dirs().sort_stats(\"time\").print_stats()", "\n", "# else:", "\n", "F1", ",", "tau", ",", "attacker_stats", "=", "detector", ".", "eval_with_fingerprints_finetune", "(", "adv_val_loader", ",", "ds_name", ",", "\n", "reject_thresholds", ",", "args", ".", "num_updates", ",", "args", ".", "lr", ")", "\n", "results", "[", "ds_name", "]", "[", "report_shot", "]", "=", "{", "\"F1\"", ":", "F1", ",", "\"best_tau\"", ":", "tau", ",", "\"eps\"", ":", "eps", ",", "\"num_dx\"", ":", "num_dx", ",", "\n", "\"num_updates\"", ":", "args", ".", "num_updates", ",", "\"attack_stats\"", ":", "attacker_stats", "}", "\n", "print", "(", "\"shot {} done\"", ".", "format", "(", "shot", ")", ")", "\n", "\n", "", "", "elif", "args", ".", "study_subject", "==", "\"cross_domain\"", ":", "\n", "                ", "source_dataset", ",", "target_dataset", "=", "args", ".", "cross_domain_source", ",", "args", ".", "cross_domain_target", "\n", "if", "ds_name", "!=", "source_dataset", ":", "\n", "                    ", "continue", "\n", "# threhold_dict = {0: 0.885896, 1: 1.23128099999, 5: 1.33487699}", "\n", "", "old_num_update", "=", "args", ".", "num_updates", "\n", "# threhold_dict = {0: 0.885896, 1: 1.23128099999, 5: 1.33487699}", "\n", "for", "shot", "in", "[", "0", ",", "1", ",", "5", "]", ":", "\n", "                    ", "report_shot", "=", "shot", "\n", "if", "shot", "==", "0", ":", "\n", "                        ", "shot", "=", "1", "\n", "args", ".", "num_updates", "=", "0", "\n", "", "else", ":", "\n", "                        ", "args", ".", "num_updates", "=", "old_num_update", "\n", "", "num_way", "=", "2", "\n", "num_query", "=", "15", "\n", "val_dataset", "=", "MetaTaskDataset", "(", "20000", ",", "num_way", ",", "shot", ",", "num_query", ",", "target_dataset", ",", "is_train", "=", "False", ",", "\n", "load_mode", "=", "args", ".", "load_task_mode", ",", "\n", "protocol", "=", "args", ".", "protocol", ",", "no_random_way", "=", "True", ",", "adv_arch", "=", "args", ".", "adv_arch", ",", "fetch_attack_name", "=", "False", ")", "\n", "adv_val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "val_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "F1", ",", "tau", ",", "attacker_stats", "=", "detector", ".", "eval_with_fingerprints_finetune", "(", "adv_val_loader", ",", "target_dataset", ",", "\n", "reject_thresholds", ",", "args", ".", "num_updates", ",", "args", ".", "lr", ")", "\n", "results", "[", "\"{}--{}@data_adv_arch_{}\"", ".", "format", "(", "source_dataset", ",", "target_dataset", ",", "args", ".", "adv_arch", ")", "]", "[", "report_shot", "]", "=", "{", "\"F1\"", ":", "F1", ",", "\"best_tau\"", ":", "tau", ",", "\n", "\"eps\"", ":", "eps", ",", "\"num_dx\"", ":", "num_dx", ",", "\n", "\"num_updates\"", ":", "args", ".", "num_updates", ",", "\"attack_stats\"", ":", "attacker_stats", "}", "\n", "", "", "elif", "args", ".", "study_subject", "==", "\"cross_arch\"", ":", "\n", "                ", "target_arch", "=", "args", ".", "cross_arch_target", "\n", "old_num_update", "=", "args", ".", "num_updates", "\n", "for", "shot", "in", "[", "0", ",", "1", ",", "5", "]", ":", "\n", "                    ", "report_shot", "=", "shot", "\n", "if", "shot", "==", "0", ":", "\n", "                        ", "shot", "=", "1", "\n", "args", ".", "num_updates", "=", "0", "\n", "", "else", ":", "\n", "                        ", "args", ".", "num_updates", "=", "old_num_update", "\n", "", "num_way", "=", "2", "\n", "num_query", "=", "15", "\n", "val_dataset", "=", "MetaTaskDataset", "(", "20000", ",", "num_way", ",", "shot", ",", "num_query", ",", "ds_name", ",", "is_train", "=", "False", ",", "\n", "load_mode", "=", "args", ".", "load_task_mode", ",", "\n", "protocol", "=", "args", ".", "protocol", ",", "no_random_way", "=", "True", ",", "adv_arch", "=", "target_arch", ",", "fetch_attack_name", "=", "False", ")", "\n", "adv_val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "val_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "F1", ",", "tau", ",", "attacker_stats", "=", "detector", ".", "eval_with_fingerprints_finetune", "(", "adv_val_loader", ",", "ds_name", ",", "\n", "reject_thresholds", ",", "args", ".", "num_updates", ",", "args", ".", "lr", ")", "\n", "results", "[", "\"{}_target_arch_{}\"", ".", "format", "(", "ds_name", ",", "target_arch", ")", "]", "[", "report_shot", "]", "=", "{", "\"F1\"", ":", "F1", ",", "\"best_tau\"", ":", "tau", ",", "\n", "\"eps\"", ":", "eps", ",", "\n", "\"num_dx\"", ":", "num_dx", ",", "\n", "\"num_updates\"", ":", "args", ".", "num_updates", ",", "\n", "\"attack_stats\"", ":", "attacker_stats", "}", "\n", "\n", "", "", "elif", "args", ".", "study_subject", "==", "\"finetune_eval\"", ":", "\n", "                ", "shot", "=", "1", "\n", "query_count", "=", "15", "\n", "old_updates", "=", "args", ".", "num_updates", "\n", "num_way", "=", "2", "\n", "num_query", "=", "15", "\n", "# threhold_dict = {0: 0.885896, 1: 1.23128099999, 5: 1.33487699}", "\n", "if", "ds_name", "!=", "args", ".", "ds_name", ":", "\n", "                    ", "continue", "\n", "", "val_dataset", "=", "MetaTaskDataset", "(", "20000", ",", "num_way", ",", "shot", ",", "num_query", ",", "ds_name", ",", "is_train", "=", "False", ",", "\n", "load_mode", "=", "args", ".", "load_task_mode", ",", "\n", "protocol", "=", "args", ".", "protocol", ",", "no_random_way", "=", "True", ",", "adv_arch", "=", "args", ".", "adv_arch", ")", "\n", "adv_val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "val_dataset", ",", "batch_size", "=", "100", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "args", ".", "num_updates", "=", "50", "\n", "for", "num_update", "in", "range", "(", "0", ",", "51", ")", ":", "\n", "# if args.profile:", "\n", "#     cProfile.runctx(\"detector.eval_with_fingerprints_finetune(adv_val_loader, ds_name, reject_thresholds, args.num_updates, args.lr)\", globals(), locals(), \"Profile.prof\")", "\n", "#     s = pstats.Stats(\"Profile.prof\")", "\n", "#     s.strip_dirs().sort_stats(\"time\").print_stats()", "\n", "# else:", "\n", "                    ", "F1", ",", "tau", ",", "attacker_stats", "=", "detector", ".", "eval_with_fingerprints_finetune", "(", "adv_val_loader", ",", "ds_name", ",", "\n", "reject_thresholds", ",", "num_update", ",", "args", ".", "lr", ")", "\n", "results", "[", "ds_name", "]", "[", "num_update", "]", "=", "{", "\"F1\"", ":", "F1", ",", "\"best_tau\"", ":", "tau", ",", "\"eps\"", ":", "eps", ",", "\"num_dx\"", ":", "num_dx", ",", "\n", "\"num_updates\"", ":", "num_update", ",", "\"attack_stats\"", ":", "attacker_stats", "}", "\n", "print", "(", "\"finetune {} done\"", ".", "format", "(", "shot", ")", ")", "\n", "\n", "\n", "\n", "", "", "", "if", "not", "args", ".", "profile", ":", "\n", "            ", "if", "args", ".", "study_subject", "==", "\"cross_domain\"", ":", "\n", "                ", "filename", "=", "\"{}/train_pytorch_model/NF_Det/cross_domain_{}--{}@adv_arch_{}.json\"", ".", "format", "(", "PY_ROOT", ",", "args", ".", "cross_domain_source", ",", "\n", "args", ".", "cross_domain_target", ",", "args", ".", "adv_arch", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"cross_arch\"", ":", "\n", "                ", "filename", "=", "\"{}/train_pytorch_model/NF_Det/cross_arch_target_{}.json\"", ".", "format", "(", "PY_ROOT", ",", "\n", "args", ".", "cross_arch_target", ")", "\n", "", "else", ":", "\n", "                ", "filename", "=", "\"{}/train_pytorch_model/NF_Det/{}@data_{}@protocol_{}@lr_{}@finetune_{}.json\"", ".", "format", "(", "PY_ROOT", ",", "args", ".", "study_subject", ",", "args", ".", "adv_arch", ",", "args", ".", "protocol", ",", "args", ".", "lr", ",", "args", ".", "num_updates", ")", "\n", "", "with", "open", "(", "filename", ",", "\"w\"", ")", "as", "file_obj", ":", "\n", "                ", "file_obj", ".", "write", "(", "json", ".", "dumps", "(", "results", ")", ")", "\n", "file_obj", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.pgd_cw_whitebox.LinfPGDAttack.__init__": [[16, 85], ["tensorflow.gradients", "tensorflow.one_hot", "tensorflow.reduce_sum", "tensorflow.reduce_max", "tensorflow.nn.relu", "pickle.load", "pickle.load", "enumerate", "tensorflow.one_hot", "tensorflow.reduce_sum", "tensorflow.reduce_max", "tensorflow.argmax", "tensorflow.one_hot", "tensorflow.tensordot", "open", "open", "tensorflow.convert_to_tensor", "tensorflow.reshape", "model.model", "numpy.zeros", "tensorflow.matmul", "tensorflow.cast", "tensorflow.nn.relu", "os.path.join", "os.path.join", "tensorflow.reshape", "tensorflow.cast", "tensorflow.losses.mean_squared_error", "numpy.array", "tensorflow.norm", "tensorflow.norm", "range"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "epsilon", ",", "k", ",", "a", ",", "random_start", ",", "loss_func", ",", "log_dir", ")", ":", "\n", "        ", "\"\"\"Attack parameter initialization. The attack performs k steps of\n           size a, while always staying within epsilon from the initial\n           point.\"\"\"", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "a", "=", "a", "\n", "self", ".", "rand", "=", "random_start", "\n", "if", "loss_func", "==", "'xent'", ":", "\n", "            ", "loss", "=", "model", ".", "xent", "\n", "\n", "", "elif", "loss_func", "==", "'cw'", ":", "\n", "            ", "label_mask", "=", "tf", ".", "one_hot", "(", "model", ".", "y_input", ",", "\n", "10", ",", "\n", "on_value", "=", "1.0", ",", "\n", "off_value", "=", "0.0", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "correct_logit", "=", "tf", ".", "reduce_sum", "(", "label_mask", "*", "model", ".", "logits", ",", "axis", "=", "1", ")", "\n", "wrong_logit", "=", "tf", ".", "reduce_max", "(", "(", "1", "-", "label_mask", ")", "*", "model", ".", "logits", ",", "axis", "=", "1", ")", "\n", "loss", "=", "-", "tf", ".", "nn", ".", "relu", "(", "correct_logit", "-", "wrong_logit", "+", "50", ")", "\n", "\n", "", "elif", "(", "loss_func", "==", "'cw_custom'", "or", "loss_func", "==", "'xent_custom'", ")", ":", "\n", "# fix this later", "\n", "            ", "if", "(", "1", ">", "0", ")", ":", "\n", "                ", "label_mask", "=", "tf", ".", "one_hot", "(", "model", ".", "y_input", ",", "\n", "10", ",", "\n", "on_value", "=", "1.0", ",", "\n", "off_value", "=", "0.0", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "correct_logit", "=", "tf", ".", "reduce_sum", "(", "label_mask", "*", "model", ".", "logits", ",", "axis", "=", "1", ")", "\n", "wrong_logit", "=", "tf", ".", "reduce_max", "(", "(", "1", "-", "label_mask", ")", "*", "model", ".", "logits", ",", "axis", "=", "1", ")", "\n", "wrong_logit_arg", "=", "tf", ".", "argmax", "(", "(", "(", "1", "-", "label_mask", ")", "*", "model", ".", "logits", ")", ",", "axis", "=", "1", ")", "\n", "\n", "\"\"\"\n                 Unnecessary, but tensorflow seems to break if we call\n                 fixed_dys[wrong_logit_arg,item,:] later\n                \"\"\"", "\n", "wrong_logit_label_mask", "=", "tf", ".", "one_hot", "(", "wrong_logit_arg", ",", "\n", "10", ",", "\n", "on_value", "=", "1.0", ",", "\n", "off_value", "=", "0.0", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "wrong_index", "=", "tf", ".", "tensordot", "(", "tf", ".", "cast", "(", "wrong_logit_label_mask", ",", "dtype", "=", "tf", ".", "float64", ")", ",", "\n", "1.0", "*", "np", ".", "array", "(", "range", "(", "10", ")", ")", ",", "1", ")", "\n", "", "if", "(", "loss_func", "==", "'cw_custom'", ")", ":", "\n", "                ", "loss", "=", "-", "tf", ".", "nn", ".", "relu", "(", "correct_logit", "-", "wrong_logit", "+", "50", ")", "\n", "", "if", "(", "loss_func", "==", "'xent_custom'", ")", ":", "\n", "                ", "loss", "=", "model", ".", "xent", "\n", "\n", "# Add loss that makes it align fingerprints also to the wrong class", "\n", "", "fixed_dxs", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"fp_inputs_dx.pkl\"", ")", ",", "\"rb\"", ")", ")", "\n", "fixed_dys", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"fp_outputs.pkl\"", ")", ",", "\"rb\"", ")", ")", "\n", "for", "item", ",", "perturbs", "in", "enumerate", "(", "fixed_dxs", ")", ":", "\n", "                ", "perturbs", "=", "tf", ".", "convert_to_tensor", "(", "perturbs", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "perturbs", "=", "tf", ".", "reshape", "(", "model", ".", "x_input", ",", "[", "-", "1", ",", "1", ",", "28", ",", "28", "]", ")", "+", "perturbs", "\n", "perturbs", "=", "tf", ".", "reshape", "(", "perturbs", ",", "[", "-", "1", ",", "1", ",", "28", ",", "28", "]", ")", "\n", "# perturbs = tf.reshape(perturbs,[1,-1])", "\n", "logits_p", "=", "model", ".", "model", "(", "perturbs", ")", "\n", "logits", "=", "model", ".", "logits", "\n", "dy", "=", "logits_p", "/", "tf", ".", "norm", "(", "logits_p", ")", "-", "logits", "/", "tf", ".", "norm", "(", "logits", ")", "\n", "dy_ref", "=", "np", ".", "zeros", "(", "(", "1", ",", "10", ")", ")", "\n", "dy_ref", "=", "tf", ".", "matmul", "(", "wrong_logit_label_mask", ",", "\n", "tf", ".", "cast", "(", "fixed_dys", "[", ":", ",", "item", ",", ":", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "loss_perturb", "=", "1.0", "*", "(", "tf", ".", "losses", ".", "mean_squared_error", "(", "dy", ",", "\n", "dy_ref", ")", ")", "\n", "loss", "=", "loss", "-", "loss_perturb", "\n", "", "", "self", ".", "grad", "=", "tf", ".", "gradients", "(", "loss", ",", "model", ".", "x_input", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.pgd_cw_whitebox.LinfPGDAttack.perturb": [[86, 104], ["range", "numpy.copy", "sess.run", "numpy.clip", "numpy.clip", "numpy.random.uniform", "numpy.sign"], "methods", ["None"], ["", "def", "perturb", "(", "self", ",", "x_nat", ",", "y", ",", "sess", ")", ":", "\n", "        ", "\"\"\"Given a set of examples (x_nat, y), returns a set of adversarial\n           examples within epsilon of x_nat in l_infinity norm.\"\"\"", "\n", "if", "self", ".", "rand", ":", "\n", "            ", "x", "=", "x_nat", "+", "np", ".", "random", ".", "uniform", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ",", "x_nat", ".", "shape", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "np", ".", "copy", "(", "x_nat", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "k", ")", ":", "\n", "            ", "grad", "=", "sess", ".", "run", "(", "self", ".", "grad", ",", "feed_dict", "=", "{", "self", ".", "model", ".", "x_input", ":", "x", ",", "\n", "self", ".", "model", ".", "y_input", ":", "y", "}", ")", "\n", "\n", "x", "+=", "self", ".", "a", "*", "np", ".", "sign", "(", "grad", ")", "\n", "\n", "x", "=", "np", ".", "clip", "(", "x", ",", "x_nat", "-", "self", ".", "epsilon", ",", "x_nat", "+", "self", ".", "epsilon", ")", "\n", "x", "=", "np", ".", "clip", "(", "x", ",", "0", ",", "1", ")", "# ensure valid pixel range", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.model.Net.__init__": [[12, 19], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "1", ",", "10", ",", "kernel_size", "=", "5", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "10", ",", "20", ",", "kernel_size", "=", "5", ")", "\n", "self", ".", "conv2_drop", "=", "nn", ".", "Dropout2d", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "320", ",", "50", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "50", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.model.Net.forward": [[20, 28], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.Net.view", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "model.Net.fc2", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "model.Net.fc1", "model.Net.conv1", "model.Net.conv2_drop", "model.Net.conv2"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.log_softmax", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.log_softmax", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.log_softmax", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.log_softmax"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "F", ".", "max_pool2d", "(", "self", ".", "conv1", "(", "x", ")", ",", "2", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "F", ".", "max_pool2d", "(", "self", ".", "conv2_drop", "(", "self", ".", "conv2", "(", "x", ")", ")", ",", "2", ")", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "320", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "return", "F", ".", "log_softmax", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.model.CW_Net.__init__": [[30, 45], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "CW_Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "1", ",", "32", ",", "3", ")", "\n", "self", ".", "bnm1", "=", "nn", ".", "BatchNorm2d", "(", "32", ",", "momentum", "=", "0.1", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "32", ",", "32", ",", "3", ")", "\n", "self", ".", "bnm2", "=", "nn", ".", "BatchNorm2d", "(", "32", ",", "momentum", "=", "0.1", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "3", ")", "\n", "self", ".", "bnm3", "=", "nn", ".", "BatchNorm2d", "(", "64", ",", "momentum", "=", "0.1", ")", "\n", "self", ".", "conv4", "=", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "3", ")", "\n", "self", ".", "bnm4", "=", "nn", ".", "BatchNorm2d", "(", "64", ",", "momentum", "=", "0.1", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "1024", ",", "200", ")", "\n", "self", ".", "bnm5", "=", "nn", ".", "BatchNorm1d", "(", "200", ",", "momentum", "=", "0.1", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "200", ",", "200", ")", "\n", "self", ".", "bnm6", "=", "nn", ".", "BatchNorm1d", "(", "200", ",", "momentum", "=", "0.1", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "200", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.model.CW_Net.forward": [[46, 64], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.CW_Net.bnm1", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.CW_Net.bnm2", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.CW_Net.bnm3", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.CW_Net.bnm4", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "model.CW_Net.view", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.CW_Net.bnm5", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.CW_Net.bnm6", "model.CW_Net.fc3", "model.CW_Net.conv1", "model.CW_Net.conv2", "model.CW_Net.conv3", "model.CW_Net.conv4", "model.CW_Net.size", "model.CW_Net.fc1", "model.CW_Net.fc2"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", "\n", "out", "=", "self", ".", "bnm1", "(", "out", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "conv2", "(", "out", ")", ")", "\n", "out", "=", "self", ".", "bnm2", "(", "out", ")", "\n", "out", "=", "F", ".", "max_pool2d", "(", "out", ",", "2", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "conv3", "(", "out", ")", ")", "\n", "out", "=", "self", ".", "bnm3", "(", "out", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "conv4", "(", "out", ")", ")", "\n", "out", "=", "self", ".", "bnm4", "(", "out", ")", "\n", "out", "=", "F", ".", "max_pool2d", "(", "out", ",", "2", ")", "\n", "out", "=", "out", ".", "view", "(", "out", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "out", ")", ")", "\n", "out", "=", "self", ".", "bnm5", "(", "out", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "fc2", "(", "out", ")", ")", "\n", "out", "=", "self", ".", "bnm6", "(", "out", ")", "\n", "out", "=", "self", ".", "fc3", "(", "out", ")", "\n", "return", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.model.LeNet.__init__": [[66, 77], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "LeNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "1", ",", "32", ",", "5", ")", "\n", "self", ".", "bnm1", "=", "nn", ".", "BatchNorm2d", "(", "32", ",", "momentum", "=", "0.1", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "5", ")", "\n", "self", ".", "bnm2", "=", "nn", ".", "BatchNorm2d", "(", "64", ",", "momentum", "=", "0.1", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "1024", ",", "200", ")", "\n", "self", ".", "bnm3", "=", "nn", ".", "BatchNorm2d", "(", "200", ",", "momentum", "=", "0.1", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "200", ",", "84", ")", "\n", "self", ".", "bnm4", "=", "nn", ".", "BatchNorm2d", "(", "84", ",", "momentum", "=", "0.1", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "84", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.model.LeNet.forward": [[78, 92], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.LeNet.bnm1", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.LeNet.bnm2", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "model.LeNet.view", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.LeNet.bnm3", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.LeNet.bnm4", "model.LeNet.fc3", "model.LeNet.conv1", "model.LeNet.conv2", "model.LeNet.size", "model.LeNet.fc1", "model.LeNet.fc2"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", "\n", "out", "=", "self", ".", "bnm1", "(", "out", ")", "\n", "out", "=", "F", ".", "max_pool2d", "(", "out", ",", "2", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "conv2", "(", "out", ")", ")", "\n", "out", "=", "self", ".", "bnm2", "(", "out", ")", "\n", "out", "=", "F", ".", "max_pool2d", "(", "out", ",", "2", ")", "\n", "out", "=", "out", ".", "view", "(", "out", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "out", ")", ")", "\n", "out", "=", "self", ".", "bnm3", "(", "out", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "fc2", "(", "out", ")", ")", "\n", "out", "=", "self", ".", "bnm4", "(", "out", ")", "\n", "out", "=", "self", ".", "fc3", "(", "out", ")", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.gen_whitebox_adv.evaluate_checkpoint": [[76, 111], ["int", "range", "dill.dump", "open.close", "math.ceil", "min", "attack.perturb", "open", "numpy.concatenate", "numpy.concatenate", "os.path.join", "os.path.join", "open", "open", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.dump", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.meta_adv_detector.tensorboard_helper.TensorBoardWriter.close", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.pgd_cw_whitebox.LinfPGDAttack.perturb"], ["def", "evaluate_checkpoint", "(", "sess", ",", "model", ")", ":", "\n", "    ", "dataset", "=", "'mnist'", "\n", "\n", "#with tf.Session() as sess:", "\n", "# Iterate over the samples batch-by-batch", "\n", "num_batches", "=", "int", "(", "math", ".", "ceil", "(", "num_eval_examples", "/", "eval_batch_size", ")", ")", "\n", "adv_x_samples", "=", "[", "]", "\n", "adv_y_samples", "=", "[", "]", "\n", "for", "ibatch", "in", "range", "(", "num_batches", ")", ":", "\n", "      ", "bstart", "=", "ibatch", "*", "eval_batch_size", "\n", "bend", "=", "min", "(", "bstart", "+", "eval_batch_size", ",", "num_eval_examples", ")", "\n", "\n", "x_batch", "=", "mnist", ".", "test", ".", "images", "[", "bstart", ":", "bend", ",", ":", "]", "\n", "y_batch", "=", "mnist", ".", "test", ".", "labels", "[", "bstart", ":", "bend", "]", "\n", "\n", "dict_nat", "=", "{", "model", ".", "x_input", ":", "x_batch", ",", "\n", "model", ".", "y_input", ":", "y_batch", "}", "\n", "\n", "x_batch_adv", "=", "attack", ".", "perturb", "(", "x_batch", ",", "y_batch", ",", "sess", ")", "\n", "if", "(", "ibatch", "==", "0", ")", ":", "\n", "          ", "adv_x_samples", "=", "x_batch_adv", "\n", "adv_y_samples", "=", "y_batch", "\n", "", "else", ":", "\n", "          ", "adv_x_samples", "=", "np", ".", "concatenate", "(", "(", "adv_x_samples", ",", "x_batch_adv", ")", ",", "axis", "=", "0", ")", "\n", "adv_y_samples", "=", "np", ".", "concatenate", "(", "(", "adv_y_samples", ",", "y_batch", ")", ",", "axis", "=", "0", ")", "\n", "", "", "if", "(", "args", ".", "attack", "==", "'xent'", ")", ":", "\n", "      ", "atck", "=", "'pgd'", "\n", "f", "=", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "log_dir", ",", "'Adv_%s_%s.p'", "%", "(", "dataset", ",", "atck", ")", ")", ",", "\"w\"", ")", "\n", "", "elif", "(", "args", ".", "attack", "==", "'cw_pgd'", ")", ":", "\n", "      ", "atck", "=", "'cw_pgd'", "\n", "f", "=", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "log_dir", ",", "'Adv_%s_%s.p'", "%", "(", "dataset", ",", "atck", ")", ")", ",", "\"w\"", ")", "\n", "", "else", ":", "\n", "      ", "f", "=", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "log_dir", ",", "\"custom.p\"", ")", ",", "\"w\"", ")", "\n", "", "pickle", ".", "dump", "(", "{", "\"adv_input\"", ":", "adv_x_samples", ",", "\"adv_labels\"", ":", "adv_y_samples", "}", ",", "f", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Fingerprints.__init__": [[6, 10], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "dx", "=", "None", "\n", "self", ".", "y", "=", "None", "\n", "self", ".", "dy", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Example.__init__": [[12, 24], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "x", ",", "yhat", ",", "y_class", ")", ":", "\n", "        ", "self", ".", "id", "=", "None", "\n", "\n", "self", ".", "x", "=", "x", "\n", "self", ".", "yhat", "=", "yhat", "\n", "self", ".", "y_class", "=", "y_class", "\n", "self", ".", "is_legal", "=", "None", "\n", "self", ".", "dxs", "=", "None", "\n", "self", ".", "yhat_p", "=", "None", "\n", "self", ".", "diff", "=", "None", "\n", "self", ".", "diff_norm", "=", "None", "\n", "self", ".", "y_class_with_fp", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.__init__": [[26, 55], ["set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "list", "list", "set", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tau", "=", "0", ",", "name", "=", "\"\"", ",", "ds_name", "=", "\"\"", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "ds_name", "=", "ds_name", "\n", "self", ".", "tau", "=", "tau", "\n", "\n", "self", ".", "ids", "=", "set", "(", ")", "\n", "self", ".", "ids_correct", "=", "set", "(", ")", "\n", "self", ".", "ids_correct_fp", "=", "set", "(", ")", "\n", "self", ".", "ids_agree", "=", "set", "(", ")", "\n", "\n", "self", ".", "TP", "=", "set", "(", ")", "\n", "self", ".", "P", "=", "set", "(", ")", "\n", "self", ".", "N", "=", "set", "(", ")", "\n", "self", ".", "FP", "=", "set", "(", ")", "\n", "self", ".", "FN", "=", "set", "(", ")", "\n", "self", ".", "TN", "=", "set", "(", ")", "\n", "self", ".", "predition_list", "=", "list", "(", ")", "\n", "self", ".", "ground_truth_list", "=", "list", "(", ")", "\n", "# Legal = there is a fingerprint match below threshold tau", "\n", "self", ".", "ids_legal", "=", "set", "(", ")", "\n", "\n", "self", ".", "counts", "=", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "self", ".", "counts_legal", "=", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "self", ".", "counts_correct", "=", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "\n", "\n", "\n", "# Total number of examples", "\n", "self", ".", "i", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.compute_counts": [[56, 96], ["set.intersection", "sklearn.metrics.f1_score", "set.intersection", "set.intersection", "set.intersection", "set.intersection", "set.intersection", "set.intersection", "set.intersection", "set.intersection", "float", "len", "len", "len", "len", "len", "len", "len", "len", "float", "len", "float", "len", "len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "compute_counts", "(", "self", ",", "ids_correct", "=", "None", ")", ":", "\n", "        ", "i", "=", "self", ".", "ids", "\n", "c", "=", "self", ".", "ids_correct", "\n", "c_fp", "=", "self", ".", "ids_correct_fp", "\n", "l", "=", "self", ".", "ids_legal", "\n", "a", "=", "self", ".", "ids_agree", "\n", "aa", "=", "set", ".", "intersection", "(", "\n", "self", ".", "ids_correct", ",", "self", ".", "ids_correct_fp", ")", "\n", "TP", "=", "self", ".", "TP", "\n", "FP", "=", "self", ".", "FP", "\n", "if", "ids_correct", ":", "# use to only look at examples in ids_correct, i.e. the ones where f(x) was correct for test x.", "\n", "            ", "i", "=", "set", ".", "intersection", "(", "i", ",", "ids_correct", ")", "# ids_correct\u8868\u793a\u539f\u59cbmodel f(x)\u5c31\u80fd\u9884\u6d4b\u6b63\u786e\u7684", "\n", "c", "=", "set", ".", "intersection", "(", "c", ",", "ids_correct", ")", "\n", "c_fp", "=", "set", ".", "intersection", "(", "c_fp", ",", "ids_correct", ")", "\n", "l", "=", "set", ".", "intersection", "(", "l", ",", "ids_correct", ")", "# \u5408\u6cd5\u7684", "\n", "a", "=", "set", ".", "intersection", "(", "a", ",", "ids_correct", ")", "\n", "aa", "=", "set", ".", "intersection", "(", "aa", ",", "ids_correct", ")", "\n", "TP", "=", "set", ".", "intersection", "(", "TP", ",", "ids_correct", ")", "\n", "FP", "=", "set", ".", "intersection", "(", "FP", ",", "ids_correct", ")", "\n", "", "precision", "=", "0.0", "\n", "if", "float", "(", "len", "(", "TP", ")", "+", "len", "(", "FP", ")", ")", ">", "0.0", ":", "\n", "            ", "precision", "=", "len", "(", "TP", ")", "/", "float", "(", "len", "(", "TP", ")", "+", "len", "(", "FP", ")", ")", "\n", "", "recall", "=", "0.0", "\n", "if", "len", "(", "self", ".", "P", ")", ">", "0", ":", "\n", "            ", "recall", "=", "len", "(", "TP", ")", "/", "float", "(", "len", "(", "self", ".", "P", ")", ")", "\n", "# F1 = 0.0", "\n", "# if precision + recall > 0.0:", "\n", "#     F1 = 2 * precision * recall / (precision + recall)", "\n", "\n", "", "F1", "=", "f1_score", "(", "self", ".", "ground_truth_list", ",", "self", ".", "predition_list", ")", "\n", "# Reject if not legal: model output does not match any fingerprint at threshold tau.", "\n", "# when does argmax f(x) == argmax f(x+dx)", "\n", "# when does y* == argmax f(x) == argmax f(x+dx)", "\n", "return", "{", "\"num\"", ":", "len", "(", "i", ")", ",", "\n", "\"num_correct\"", ":", "len", "(", "c", ")", ",", "\n", "\"num_correct_fp\"", ":", "len", "(", "c_fp", ")", ",", "\n", "\"num_legal\"", ":", "len", "(", "l", ")", ",", "\n", "\"num_reject\"", ":", "len", "(", "i", ")", "-", "len", "(", "l", ")", ",", "\n", "\"num_agree\"", ":", "len", "(", "a", ")", ",", "\"F1\"", ":", "F1", ",", "\n", "\"num_all_agree\"", ":", "len", "(", "aa", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.show": [[97, 104], ["d.items", "print", "print"], "methods", ["None"], ["", "def", "show", "(", "self", ",", "d", ")", ":", "\n", "        ", "n", "=", "d", "[", "\"num\"", "]", "\n", "if", "n", "<=", "0", ":", "\n", "            ", "print", "(", "\"Empty set!\"", ")", "\n", "return", "\n", "", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", ":", "\n", "            ", "print", "(", "\"{:<20}: {:3.2f}% ({} / {})\"", ".", "format", "(", "k", ",", "v", "/", "n", "*", "100", ",", "v", ",", "n", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.write_dict": [[105, 109], ["os.path.join", "print", "pickle.dump", "open"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.dump"], ["", "", "def", "write_dict", "(", "self", ",", "d", ",", "fn", ",", "log_dir", ",", "name", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"{}-{}-{}-tau_{:.4f}.pkl\"", ".", "format", "(", "name", ",", "self", ".", "ds_name", ",", "fn", ",", "self", ".", "tau", ")", ")", "\n", "print", "(", "\"Saving stats in\"", ",", "path", ")", "\n", "pickle", ".", "dump", "(", "d", ",", "open", "(", "path", ",", "\"wb\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.dump": [[110, 117], ["zip", "fingerprint.Stats.write_dict"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.write_dict"], ["", "def", "dump", "(", "self", ",", "log_dir", ",", "name", ")", ":", "\n", "\n", "        ", "dicts", "=", "[", "self", ".", "counts", ",", "self", ".", "counts_legal", ",", "self", ".", "counts_correct", "]", "\n", "fns", "=", "[", "\"args\"", ",", "\"counts\"", ",", "\"counts_legal\"", ",", "\"counts_correct\"", "]", "\n", "\n", "for", "result", ",", "fn", "in", "zip", "(", "dicts", ",", "fns", ")", ":", "\n", "            ", "self", ".", "write_dict", "(", "result", ",", "fn", ",", "log_dir", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.__init__": [[17, 47], ["torch.from_numpy().cuda().float", "torch.from_numpy().cuda().float", "torch.from_numpy().cuda().float", "torch.from_numpy().cuda().float", "neural_fingerprint.fingerprint.Fingerprints", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "os.path.exists", "os.path.exists", "print", "range", "fingerprint_detector.NeuralFingerprintDetector.dump_dx_dy", "open", "pickle.load", "open", "pickle.load", "numpy.ones", "range", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "range", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.random.rand"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.dump_dx_dy"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "model", ",", "num_dx", ",", "num_class", ",", "eps", ",", "out_fp_dxdy_dir", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "num_class", "=", "num_class", "\n", "self", ".", "dx_path", "=", "out_fp_dxdy_dir", "+", "'/fp_inputs_dx@num_dx_{}_eps_{}@{}.pkl'", ".", "format", "(", "num_dx", ",", "eps", ",", "dataset", ")", "\n", "self", ".", "dy_path", "=", "out_fp_dxdy_dir", "+", "'/fp_outputs_dy@num_dx_{}_num_class_{}@{}.pkl'", ".", "format", "(", "num_dx", ",", "num_class", ",", "dataset", ")", "\n", "self", ".", "num_dx", "=", "num_dx", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "dx_path", ")", "and", "os", ".", "path", ".", "exists", "(", "self", ".", "dy_path", ")", ":", "\n", "            ", "print", "(", "\"loading dx and dy from {} and {}\"", ".", "format", "(", "self", ".", "dx_path", ",", "self", ".", "dy_path", ")", ")", "\n", "with", "open", "(", "self", ".", "dx_path", ",", "\"rb\"", ")", "as", "file_obj", ":", "\n", "                ", "self", ".", "fp_dx", "=", "pickle", ".", "load", "(", "file_obj", ")", "\n", "", "with", "open", "(", "self", ".", "dy_path", ",", "\"rb\"", ")", "as", "file_obj", ":", "\n", "                ", "self", ".", "fp_target", "=", "pickle", ".", "load", "(", "file_obj", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "fp_dx", "=", "[", "(", "np", ".", "random", ".", "rand", "(", "1", ",", "IN_CHANNELS", "[", "dataset", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", "[", "0", "]", ",", "IMAGE_SIZE", "[", "dataset", "]", "[", "1", "]", ")", "-", "0.5", ")", "*", "2", "*", "eps", "for", "i", "in", "range", "(", "num_dx", ")", "]", "\n", "self", ".", "fp_target", "=", "0.254", "*", "np", ".", "ones", "(", "(", "num_class", ",", "num_dx", ",", "num_class", ")", ")", "\n", "for", "j", "in", "range", "(", "num_dx", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "num_class", ")", ":", "\n", "                    ", "self", ".", "fp_target", "[", "i", ",", "j", ",", "i", "]", "=", "-", "0.7", "\n", "", "", "self", ".", "fp_target", "=", "1.5", "*", "self", ".", "fp_target", "\n", "self", ".", "dump_dx_dy", "(", ")", "\n", "", "self", ".", "fp_target", "=", "torch", ".", "from_numpy", "(", "self", ".", "fp_target", ")", ".", "cuda", "(", ")", ".", "float", "(", ")", "\n", "\n", "self", ".", "fp", "=", "Fingerprints", "(", ")", "\n", "self", ".", "fp", ".", "dx", "=", "self", ".", "fp_dx", "\n", "self", ".", "fp", ".", "dy", "=", "self", ".", "fp_target", "\n", "\n", "self", ".", "loss_func", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "loss_n", "=", "nn", ".", "MSELoss", "(", ")", "\n", "self", ".", "verbose", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.dump_dx_dy": [[48, 54], ["print", "open", "pickle.dump", "open", "pickle.dump"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.dump", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.dump"], ["", "def", "dump_dx_dy", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "dx_path", ",", "'wb'", ")", "as", "file_obj", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "fp_dx", ",", "file_obj", ")", "\n", "", "with", "open", "(", "self", ".", "dy_path", ",", "\"wb\"", ")", "as", "file_obj", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "fp_target", ",", "file_obj", ")", "\n", "", "print", "(", "\"dump to {} and {} over\"", ".", "format", "(", "self", ".", "dx_path", ",", "self", ".", "dy_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.get_all_loss": [[56, 94], ["y.size", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "range", "model", "torch.log_softmax", "torch.log_softmax", "fingerprint_detector.NeuralFingerprintDetector.loss_func", "range", "x.cuda", "y.cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.norm().reciprocal().expand", "torch.norm().reciprocal().expand", "torch.norm().reciprocal().expand", "torch.norm().reciprocal().expand", "fingerprint_detector.NeuralFingerprintDetector.loss_n", "fingerprint_detector.NeuralFingerprintDetector.loss_n", "torch.norm().reciprocal().expand", "torch.norm().reciprocal().expand", "torch.norm().reciprocal().expand", "torch.norm().reciprocal().expand", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.norm().reciprocal", "torch.norm().reciprocal", "torch.norm().reciprocal", "torch.norm().reciprocal", "torch.norm().reciprocal", "torch.norm().reciprocal", "torch.norm().reciprocal", "torch.norm().reciprocal", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.log_softmax", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.log_softmax"], ["", "def", "get_all_loss", "(", "self", ",", "model", ",", "x", ",", "y", ",", "epoch", ")", ":", "\n", "        ", "x", ",", "y", "=", "x", ".", "cuda", "(", ")", ",", "y", ".", "cuda", "(", ")", "\n", "\n", "real_bs", "=", "y", ".", "size", "(", "0", ")", "\n", "fp_target_var", "=", "torch", ".", "index_select", "(", "self", ".", "fp_target", ",", "0", ",", "y", ")", "\n", "x_net", "=", "x", "\n", "for", "i", "in", "range", "(", "self", ".", "num_dx", ")", ":", "\n", "            ", "dx", "=", "self", ".", "fp_dx", "[", "i", "]", "\n", "dx", "=", "torch", ".", "from_numpy", "(", "dx", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "x_net", "=", "torch", ".", "cat", "(", "(", "x_net", ",", "x", "+", "dx", ")", ")", "\n", "", "logits_net", "=", "model", "(", "x_net", ")", "\n", "output_net", "=", "F", ".", "log_softmax", "(", "logits_net", ",", "dim", "=", "1", ")", "\n", "yhat", "=", "output_net", "[", ":", "real_bs", "]", "\n", "logits", "=", "logits_net", "[", ":", "real_bs", "]", "\n", "# \u9664\u4ee5\u6a21\u957f\uff0c\u5f52\u4e00\u5316", "\n", "logits_norm", "=", "logits", "*", "torch", ".", "norm", "(", "logits", ",", "2", ",", "1", ",", "keepdim", "=", "True", ")", ".", "reciprocal", "(", ")", ".", "expand", "(", "real_bs", ",", "self", ".", "num_class", ")", "\n", "loss_fingerprint_y", "=", "0", "\n", "loss_fingerprint_dy", "=", "0", "\n", "loss_vanilla", "=", "self", ".", "loss_func", "(", "yhat", ",", "y", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_dx", ")", ":", "\n", "            ", "fp_target_var_i", "=", "fp_target_var", "[", ":", ",", "i", ",", ":", "]", "\n", "logits_p", "=", "logits_net", "[", "(", "i", "+", "1", ")", "*", "real_bs", ":", "(", "i", "+", "2", ")", "*", "real_bs", "]", "\n", "logits_p_norm", "=", "logits_p", "*", "torch", ".", "norm", "(", "logits_p", ",", "2", ",", "1", ",", "keepdim", "=", "True", ")", ".", "reciprocal", "(", ")", ".", "expand", "(", "real_bs", ",", "\n", "self", ".", "num_class", ")", "\n", "diff_logits_p", "=", "logits_p_norm", "-", "logits_norm", "+", "0.00001", "\n", "loss_fingerprint_y", "+=", "self", ".", "loss_n", "(", "logits_p_norm", ",", "fp_target_var_i", ")", "\n", "loss_fingerprint_dy", "+=", "self", ".", "loss_n", "(", "diff_logits_p", ",", "fp_target_var_i", ")", "\n", "", "if", "self", ".", "dataset", "==", "\"MNIST\"", "or", "self", ".", "dataset", "==", "\"F-MNIST\"", ":", "\n", "            ", "if", "epoch", ">=", "1", ":", "\n", "                ", "loss", "=", "loss_vanilla", "+", "1.0", "*", "loss_fingerprint_dy", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_vanilla", "\n", "", "", "else", ":", "\n", "            ", "if", "epoch", ">=", "1", ":", "\n", "                ", "loss", "=", "loss_vanilla", "+", "(", "1.0", "+", "50.0", "/", "self", ".", "num_dx", ")", "*", "loss_fingerprint_dy", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_vanilla", "\n", "", "", "return", "loss", ",", "loss_vanilla", ",", "loss_fingerprint_y", ",", "loss_fingerprint_dy", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.train_one_image": [[95, 101], ["fingerprint_detector.NeuralFingerprintDetector.get_all_loss", "optimizer.zero_grad", "loss.backward", "optimizer.step"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.get_all_loss"], ["", "def", "train_one_image", "(", "self", ",", "model", ",", "x", ",", "y", ",", "optimizer", ",", "epoch", "=", "1", ")", ":", "\n", "        ", "loss", ",", "loss_vanilla", ",", "loss_fingerprint_y", ",", "loss_fingerprint_dy", "=", "self", ".", "get_all_loss", "(", "model", ",", "x", ",", "y", ",", "epoch", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "return", "loss", ",", "loss_vanilla", ",", "loss_fingerprint_y", ",", "loss_fingerprint_dy", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.train": [[103, 117], ["fingerprint_detector.NeuralFingerprintDetector.model.train", "enumerate", "fingerprint_detector.NeuralFingerprintDetector.train_one_image", "x.cuda", "y.cuda", "print", "len", "loss_vanilla.item", "loss_fingerprint_y.item", "loss_fingerprint_dy.item", "loss.item", "len", "len"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.train_one_image"], ["", "def", "train", "(", "self", ",", "epoch", ",", "optimizer", ",", "data_loader", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "batch_idx", ",", "(", "x", ",", "y", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "            ", "x", ",", "y", "=", "x", ".", "cuda", "(", ")", ",", "y", ".", "cuda", "(", ")", "\n", "loss", ",", "loss_vanilla", ",", "loss_fingerprint_y", ",", "loss_fingerprint_dy", "=", "self", ".", "train_one_image", "(", "self", ".", "model", ",", "x", ",", "y", ",", "optimizer", ",", "epoch", ")", "\n", "if", "batch_idx", "%", "100", "==", "0", ":", "\n", "                ", "print", "(", "\n", "'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss vanilla: {:.3f} fp-y: {:.3f} fp-dy: {:.3f} Total Loss: {:.3f}'", ".", "format", "(", "\n", "epoch", ",", "batch_idx", "*", "len", "(", "x", ")", ",", "len", "(", "data_loader", ".", "dataset", ")", ",", "\n", "100.", "*", "batch_idx", "/", "len", "(", "data_loader", ")", ",", "\n", "loss_vanilla", ".", "item", "(", ")", ",", "\n", "loss_fingerprint_y", ".", "item", "(", ")", ",", "\n", "loss_fingerprint_dy", ".", "item", "(", ")", ",", "\n", "loss", ".", "item", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.test": [[118, 175], ["fingerprint_detector.NeuralFingerprintDetector.model.eval", "print", "print", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "len", "loss_y.item", "loss_dy.item", "data.detach().cpu().numpy", "fingerprint_detector.NeuralFingerprintDetector.model", "torch.log_softmax", "torch.log_softmax", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "range", "torch.nll_loss().item", "torch.nll_loss().item", "pred.eq().detach().cpu().sum", "loss_y.item", "loss_dy.item", "data.cuda", "target.cuda", "torch.norm().reciprocal().expand", "torch.norm().reciprocal().expand", "torch.norm().reciprocal().expand", "torch.norm().reciprocal().expand", "fingerprint_detector.NeuralFingerprintDetector.model", "fingerprint_detector.NeuralFingerprintDetector.loss_n", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.log_softmax.max", "len", "data.detach().cpu", "torch.norm().reciprocal().expand", "torch.norm().reciprocal().expand", "torch.norm().reciprocal().expand", "torch.norm().reciprocal().expand", "diff.max", "fp_target_var_i.max", "fingerprint_detector.NeuralFingerprintDetector.loss_n", "torch.nll_loss", "torch.nll_loss", "pred.eq().detach().cpu", "torch.norm().reciprocal", "torch.norm().reciprocal", "torch.norm().reciprocal", "torch.norm().reciprocal", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "data.detach", "torch.norm().reciprocal", "torch.norm().reciprocal", "torch.norm().reciprocal", "torch.norm().reciprocal", "pred.eq().detach", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "pred.eq", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "target.view_as"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.log_softmax", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.layers.log_softmax"], ["", "", "", "def", "test", "(", "self", ",", "epoch", ",", "data_loader", ",", "test_length", "=", "None", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "test_loss", "=", "0", "\n", "correct", "=", "0", "\n", "correct_fp", "=", "0", "\n", "fingerprint_accuracy", "=", "[", "]", "\n", "loss_y", "=", "0", "\n", "loss_dy", "=", "0", "\n", "num_same_argmax", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "e", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "                ", "data", ",", "target", "=", "data", ".", "cuda", "(", ")", ",", "target", ".", "cuda", "(", ")", "\n", "data", ".", "requires_grad", "=", "False", "\n", "data_np", "=", "data", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "real_bs", "=", "data_np", ".", "shape", "[", "0", "]", "\n", "logits", "=", "self", ".", "model", "(", "data", ")", "\n", "output", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "logits_norm", "=", "logits", "*", "torch", ".", "norm", "(", "logits", ",", "2", ",", "1", ",", "keepdim", "=", "True", ")", ".", "reciprocal", "(", ")", ".", "expand", "(", "real_bs", ",", "self", ".", "num_class", ")", "\n", "fp_target_var", "=", "torch", ".", "index_select", "(", "self", ".", "fp_target", ",", "0", ",", "target", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_dx", ")", ":", "\n", "                    ", "dx", "=", "self", ".", "fp_dx", "[", "i", "]", "\n", "fp_target_var_i", "=", "fp_target_var", "[", ":", ",", "i", ",", ":", "]", "\n", "logits_p", "=", "self", ".", "model", "(", "data", "+", "torch", ".", "from_numpy", "(", "dx", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", ")", "\n", "logits_p_norm", "=", "logits_p", "*", "torch", ".", "norm", "(", "logits_p", ",", "2", ",", "1", ",", "keepdim", "=", "True", ")", ".", "reciprocal", "(", ")", ".", "expand", "(", "real_bs", ",", "\n", "self", ".", "num_class", ")", "\n", "diff", "=", "logits_p_norm", "-", "logits_norm", "\n", "diff_class", "=", "diff", ".", "max", "(", "1", ",", "keepdim", "=", "True", ")", "[", "1", "]", "\n", "fp_target_class", "=", "fp_target_var_i", ".", "max", "(", "1", ",", "keepdim", "=", "True", ")", "[", "1", "]", "\n", "loss_y", "+=", "self", ".", "loss_n", "(", "logits_p_norm", ",", "fp_target_var_i", ")", "\n", "loss_dy", "+=", "10.0", "*", "self", ".", "loss_n", "(", "diff", ",", "fp_target_var_i", ")", "\n", "num_same_argmax", "+=", "torch", ".", "sum", "(", "diff_class", "==", "fp_target_class", ")", "\n", "", "test_loss", "+=", "F", ".", "nll_loss", "(", "output", ",", "target", ",", "size_average", "=", "False", ")", ".", "item", "(", ")", "# sum up batch loss", "\n", "pred", "=", "output", ".", "max", "(", "1", ",", "keepdim", "=", "True", ")", "[", "1", "]", "# get the index of the max log-probability", "\n", "correct", "+=", "pred", ".", "eq", "(", "target", ".", "view_as", "(", "pred", ")", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "sum", "(", ")", "\n", "", "", "if", "test_length", "is", "None", ":", "\n", "            ", "test_length", "=", "len", "(", "data_loader", ".", "dataset", ")", "\n", "", "test_loss", "/=", "test_length", "\n", "loss_y", "/=", "test_length", "\n", "loss_dy", "/=", "test_length", "\n", "argmax_acc", "=", "num_same_argmax", "*", "1.0", "/", "(", "test_length", "*", "self", ".", "num_dx", ")", "\n", "print", "(", "'Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'", ".", "format", "(", "\n", "test_loss", ",", "correct", ",", "test_length", ",", "\n", "100.", "*", "correct", "/", "test_length", ")", ")", "\n", "print", "(", "'Fingerprints (on test): L(fp, y) loss: {:.4f}, L(fp, dy) loss: {:.4f}, argmax y = argmax f(x+dx) Accuracy: {}/{} ({:.0f}%)'", ".", "format", "(", "\n", "loss_y", ".", "item", "(", ")", ",", "loss_dy", ".", "item", "(", ")", ",", "num_same_argmax", ",", "\n", "len", "(", "data_loader", ".", "dataset", ")", "*", "self", ".", "num_dx", ",", "\n", "100.", "*", "argmax_acc", ")", ")", "\n", "result", "=", "{", "\"epoch\"", ":", "epoch", ",", "\n", "\"test-loss\"", ":", "test_loss", ",", "\n", "\"test-correct\"", ":", "correct", ",", "\n", "\"test-N\"", ":", "test_length", ",", "\n", "\"test-acc\"", ":", "correct", "/", "test_length", ",", "\n", "\"fingerprint-loss (y)\"", ":", "loss_y", ".", "item", "(", ")", ",", "\n", "\"fingerprint-loss (dy)\"", ":", "loss_dy", ".", "item", "(", ")", ",", "\n", "\"fingerprint-loss (argmax)\"", ":", "argmax_acc", ",", "\n", "}", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.model_with_fingerprint": [[177, 229], ["model", "torch.softmax", "torch.softmax", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "fingerprint_detector.NeuralFingerprintDetector.model", "torch.softmax", "torch.softmax", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "neural_fingerprint.fingerprint.Example", "torch.mean.detach().cpu().numpy", "torch.mean.detach().cpu().numpy", "torch.softmax.data.max", "y_class.detach().cpu().numpy", "torch.norm().reciprocal().expand", "torch.norm().reciprocal().expand", "torch.norm().reciprocal().expand", "torch.norm().reciprocal().expand", "torch.norm().reciprocal().expand", "torch.norm().reciprocal().expand", "torch.norm().reciprocal().expand", "torch.norm().reciprocal().expand", "torch.mean.min", "torch.mean.min", "y_class_with_fp.detach().cpu().numpy", "x.size", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.mean.detach().cpu", "torch.mean.detach().cpu", "y_class.detach().cpu", "torch.norm().reciprocal", "torch.norm().reciprocal", "torch.norm().reciprocal", "torch.norm().reciprocal", "torch.norm().reciprocal", "torch.norm().reciprocal", "torch.norm().reciprocal", "torch.norm().reciprocal", "y_class_with_fp.detach().cpu", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.mean.detach", "torch.mean.detach", "y_class.detach", "numpy.concatenate", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "y_class_with_fp.detach"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.softmax", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.softmax", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.softmax", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.feature_squeeze.feature_squeeze_detector.softmax"], ["", "def", "model_with_fingerprint", "(", "self", ",", "model", ",", "x", ",", "fp", ")", ":", "\n", "# x : B x C x W x H with B = 1", "\n", "# Check y' = f(x+dx) for all dx", "\n", "\n", "        ", "assert", "x", ".", "size", "(", ")", "[", "0", "]", "==", "1", "# batch", "\n", "\n", "# Get perturbations for predicted class", "\n", "\n", "logits", "=", "model", "(", "x", ")", "\n", "\n", "yhat", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "y_class", "=", "yhat", ".", "data", ".", "max", "(", "1", ",", "keepdim", "=", "True", ")", "[", "1", "]", "\n", "y_class", "=", "y_class", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", ",", "0", "]", "\n", "\n", "# fixed_dxs : num_perturb x C x W x H", "\n", "fixed_dxs", "=", "torch", ".", "from_numpy", "(", "np", ".", "concatenate", "(", "fp", ".", "dx", ",", "axis", "=", "0", ")", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "# cmopute x + dx : broadcast! num_perturb x C x W x H", "\n", "xp", "=", "x", "+", "fixed_dxs", "\n", "\n", "# if args.debug: print(\"xp\", xp.size(), \"x\", x.size(), \"fixed_dxs\", fixed_dxs.size())", "\n", "\n", "logits_p", "=", "self", ".", "model", "(", "xp", ")", "\n", "yhat_p", "=", "F", ".", "softmax", "(", "logits_p", ",", "dim", "=", "1", ")", "\n", "\n", "# compute f(x + dx) : num_perturb x num_class", "\n", "\n", "# print(\"get fixed_dys : num_target_class x num_perturb x num_class: for each target class, a set of perturbations and desired outputs (num_class).\")", "\n", "fixed_dys", "=", "fp", ".", "dy", "\n", "logits_norm", "=", "logits", "*", "torch", ".", "norm", "(", "logits", ",", "2", ",", "1", ",", "keepdim", "=", "True", ")", ".", "reciprocal", "(", ")", ".", "expand", "(", "1", ",", "self", ".", "num_class", ")", "\n", "logits_p_norm", "=", "logits_p", "*", "torch", ".", "norm", "(", "logits_p", ",", "2", ",", "1", ",", "keepdim", "=", "True", ")", ".", "reciprocal", "(", ")", ".", "expand", "(", "self", ".", "num_dx", ",", "\n", "self", ".", "num_class", ")", "\n", "diff_logits_p", "=", "logits_p_norm", "-", "logits_norm", "\n", "# diff_logits_p = diff_logits_p * torch.norm(diff_logits_p, 2, 1, keepdim=True).reciprocal().expand(args.num_dx, args.num_class)", "\n", "\n", "diff", "=", "fixed_dys", "-", "diff_logits_p", "# \u8bba\u6587\u516c\u5f0f9", "\n", "\n", "diff_norm", "=", "torch", ".", "norm", "(", "diff", ",", "2", ",", "dim", "=", "2", ")", "\n", "\n", "diff_norm", "=", "torch", ".", "mean", "(", "diff_norm", ",", "dim", "=", "1", ")", "#\u8bba\u6587\u516c\u5f0f9\u6c42\u5747\u503c", "\n", "\n", "y_class_with_fp", "=", "diff_norm", ".", "min", "(", "0", ",", "keepdim", "=", "True", ")", "[", "1", "]", "#\u5dee\u8ddd\u6700\u5c0f\u7684\u90a3\u4e2alogit\u7684\u4f4d\u7f6e", "\n", "y_class_with_fp", "=", "y_class_with_fp", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", "]", "\n", "\n", "ex", "=", "Example", "(", "x", ",", "yhat", ",", "y_class", ")", "\n", "ex", ".", "dxs", "=", "fixed_dxs", "\n", "ex", ".", "yhat_p", "=", "yhat_p", "\n", "ex", ".", "diff", "=", "diff", "\n", "ex", ".", "diff_norm", "=", "diff_norm", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "ex", ".", "y_class_with_fp", "=", "y_class_with_fp", "\n", "\n", "return", "ex", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.detect_with_fingerprints": [[230, 272], ["stats_per_tau.items", "stats.ids.add", "below_threshold.astype.astype.astype", "stats.ids_correct.add", "stats.ids_correct_fp.add", "stats.ids_agree.add", "stats.P.add", "stats.ground_truth_list.append", "stats.N.add", "stats.ground_truth_list.append", "stats.predition_list.append", "stats.predition_list.append", "stats.TP.add", "stats.FP.add", "stats.ids_legal.add"], "methods", ["None"], ["", "def", "detect_with_fingerprints", "(", "self", ",", "ex", ",", "stats_per_tau", ")", ":", "\n", "        ", "diff_norm", "=", "ex", ".", "diff_norm", "\n", "y_class_with_fp", "=", "ex", ".", "y_class_with_fp", "\n", "\n", "for", "reject_threshold", ",", "stats", "in", "stats_per_tau", ".", "items", "(", ")", ":", "\n", "\n", "            ", "stats", ".", "ids", ".", "add", "(", "ex", ".", "id", ")", "\n", "# Check legal: ? D({f(x+dx)}, {y^k}) < tau for all classes k.", "\n", "below_threshold", "=", "diff_norm", "<", "reject_threshold", "\n", "below_threshold", "=", "below_threshold", ".", "astype", "(", "np", ".", "int32", ")", "\n", "below_threshold_t", "=", "below_threshold", "[", "y_class_with_fp", "]", "\n", "\n", "is_legal", "=", "below_threshold_t", ">", "0", "\n", "ex", ".", "is_legal", "=", "is_legal", "\n", "\n", "if", "ex", ".", "y", "==", "ex", ".", "y_class", ":", "# y\u662fgt label  y_class\u6a21\u578bf(x)\u8f93\u51fa", "\n", "                ", "stats", ".", "ids_correct", ".", "add", "(", "ex", ".", "id", ")", "\n", "\n", "", "if", "ex", ".", "y", "==", "ex", ".", "y_class_with_fp", ":", "\n", "                ", "stats", ".", "ids_correct_fp", ".", "add", "(", "ex", ".", "id", ")", "\n", "\n", "", "if", "ex", ".", "y_class", "==", "ex", ".", "y_class_with_fp", ":", "\n", "                ", "stats", ".", "ids_agree", ".", "add", "(", "ex", ".", "id", ")", "\n", "\n", "", "if", "ex", ".", "binary_y", "==", "1", ":", "\n", "                ", "stats", ".", "P", ".", "add", "(", "ex", ".", "id", ")", "\n", "stats", ".", "ground_truth_list", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "stats", ".", "N", ".", "add", "(", "ex", ".", "id", ")", "\n", "stats", ".", "ground_truth_list", ".", "append", "(", "0", ")", "\n", "", "if", "is_legal", ":", "\n", "                ", "stats", ".", "predition_list", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "stats", ".", "predition_list", ".", "append", "(", "0", ")", "\n", "", "if", "is_legal", "and", "ex", ".", "binary_y", "==", "1", ":", "\n", "                ", "stats", ".", "TP", ".", "add", "(", "ex", ".", "id", ")", "\n", "", "if", "is_legal", "and", "ex", ".", "binary_y", "==", "0", ":", "\n", "                ", "stats", ".", "FP", ".", "add", "(", "ex", ".", "id", ")", "\n", "", "if", "ex", ".", "is_legal", ":", "\n", "                ", "stats", ".", "ids_legal", ".", "add", "(", "ex", ".", "id", ")", "\n", "\n", "", "", "return", "ex", ",", "stats_per_tau", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.eval_with_fingerprints": [[274, 318], ["fingerprint_detector.NeuralFingerprintDetector.model.eval", "enumerate", "collections.defaultdict", "collections.defaultdict", "stats_per_tau.items", "neural_fingerprint.fingerprint.Stats", "x.detach().cpu().numpy", "range", "stats.compute_counts", "stats.compute_counts", "fingerprint_detector.NeuralFingerprintDetector.model_with_fingerprint", "fingerprint_detector.NeuralFingerprintDetector.detect_with_fingerprints", "print", "print", "stats.show", "print", "stats.show", "x.detach().cpu", "print", "print", "print", "print", "x[].size", "y[].size", "hash", "x.detach", "fingerprint_detector.NeuralFingerprintDetector.diff_norm.detach().cpu().numpy", "fingerprint_detector.NeuralFingerprintDetector.diff_norm.detach().cpu", "fingerprint_detector.NeuralFingerprintDetector.diff_norm.detach"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.compute_counts", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.compute_counts", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.model_with_fingerprint", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.detect_with_fingerprints", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.show", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.show"], ["", "def", "eval_with_fingerprints", "(", "self", ",", "data_loader", ",", "ds_name", ",", "reject_thresholds", ",", "test_results_by_tau", ",", "name", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "stats_per_tau", "=", "{", "i", ":", "Stats", "(", "tau", "=", "i", ",", "name", "=", "name", ",", "ds_name", "=", "ds_name", ")", "for", "i", "in", "reject_thresholds", "}", "\n", "i", "=", "0", "\n", "for", "e", ",", "(", "x", ",", "y", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "            ", "data_np", "=", "x", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "real_bs", "=", "data_np", ".", "shape", "[", "0", "]", "\n", "for", "b", "in", "range", "(", "real_bs", ")", ":", "\n", "                ", "ex", "=", "self", ".", "model_with_fingerprint", "(", "self", ".", "model", ",", "x", "[", "b", ":", "b", "+", "1", "]", ",", "self", ".", "fp", ")", "\n", "# Careful! Needs Dataloader with shuffle=False", "\n", "ex", ".", "id", "=", "i", "\n", "ex", ".", "y", "=", "y", "[", "b", "]", "\n", "\n", "ex", ",", "stats_per_tau", "=", "self", ".", "detect_with_fingerprints", "(", "ex", ",", "stats_per_tau", ")", "\n", "i", "+=", "1", "\n", "if", "self", ".", "verbose", ":", "\n", "                    ", "print", "(", "\"\\nx\"", ",", "x", "[", "b", ":", "b", "+", "1", "]", ".", "size", "(", ")", ",", "\"y\"", ",", "y", "[", "b", ":", "b", "+", "1", "]", ",", "y", "[", "b", ":", "b", "+", "1", "]", ".", "size", "(", ")", ")", "\n", "print", "(", "\"Fingerprinting image (hash:\"", ",", "hash", "(", "x", "[", "b", ":", "b", "+", "1", "]", ")", ",", "\") class\"", ",", "y", "[", "b", "]", ")", "\n", "print", "(", "\"Model    class prediction: [\"", ",", "ex", ".", "y_class", ",", "\"] from logits:\"", ",", "ex", ".", "yhat", ")", "\n", "print", "(", "\"Model+fp class prediction: [{}] from diff_norm: {}\"", ".", "format", "(", "ex", ".", "y_class_with_fp", ",", "\n", "ex", ".", "diff_norm", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "", "", "if", "e", "%", "10", "==", "0", ":", "\n", "                ", "print", "(", "\"Ex: {} batch {} of size {}\"", ".", "format", "(", "i", ",", "e", ",", "real_bs", ")", ")", "\n", "\n", "", "", "results", "=", "defaultdict", "(", "lambda", ":", "None", ")", "\n", "stats_results", "=", "defaultdict", "(", "lambda", ":", "None", ")", "\n", "\n", "for", "tau", ",", "stats", "in", "stats_per_tau", ".", "items", "(", ")", ":", "\n", "            ", "stats", ".", "counts", "=", "stats", ".", "compute_counts", "(", ")", "# \u8fd9\u4e2a\u5b57\u5178\u91cc\u7684num_correct_fp\u5c31\u662f\u9884\u6d4b\u6b63\u786e\u7684\u4e2a\u6570", "\n", "# use test x for which f(x) was correct. If the current dataset is not test, we need an external set of ids.", "\n", "if", "test_results_by_tau", ":", "\n", "                ", "ids_correct", "=", "test_results_by_tau", "[", "tau", "]", ".", "ids_correct", "\n", "", "else", ":", "\n", "                ", "continue", "\n", "", "stats", ".", "counts_correct", "=", "stats", ".", "compute_counts", "(", "ids_correct", "=", "ids_correct", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "\"Stats raw (tau {})\"", ".", "format", "(", "tau", ")", ")", "\n", "stats", ".", "show", "(", "stats", ".", "counts", ")", "\n", "print", "(", "\"Stats cond_correct (tau {})\"", ".", "format", "(", "tau", ")", ")", "\n", "stats", ".", "show", "(", "stats", ".", "counts_correct", ")", "\n", "", "results", "[", "tau", "]", "=", "[", "stats", ".", "counts", ",", "stats", ".", "counts_correct", "]", "\n", "stats_results", "[", "tau", "]", "=", "stats", "\n", "", "return", "results", ",", "stats_results", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.eval_with_fingerprints_finetune": [[321, 408], ["copy.deepcopy", "collections.defaultdict", "numpy.mean", "numpy.mean", "collections.defaultdict.items", "print", "neural_fingerprint.fingerprint.Stats", "support_binary_labels.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "support_gt_labels.cuda.cuda.cuda", "support_images.cuda.cuda.cuda", "query_images.cuda.cuda.cuda", "range", "numpy.mean", "support_images.cuda.cuda.size", "copy.deepcopy.copy_weights", "torch.optim.SGD", "torch.optim.SGD", "clean_imgs.view.view.size", "clean_imgs.view.view.view", "copy.deepcopy.train", "copy.deepcopy.modules", "range", "copy.deepcopy.eval", "y.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "binary_y.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "x.view.view.size", "x.view.view.view", "x.view.view.detach().cpu().numpy", "range", "stats_per_tau.items", "max", "all_F1_scores.append", "all_tau.append", "stats_per_tau.clear", "print", "support_binary_labels.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "numpy.where", "copy.deepcopy.parameters", "isinstance", "fingerprint_detector.NeuralFingerprintDetector.train_one_image", "fingerprint_detector.NeuralFingerprintDetector.model_with_fingerprint", "fingerprint_detector.NeuralFingerprintDetector.detect_with_fingerprints", "stats.compute_counts", "list", "max", "attacker_stats[].append", "neural_fingerprint.fingerprint.Stats", "m.eval", "y.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "binary_y.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "x.view.view.detach().cpu", "stats.compute_counts", "result.values", "list", "support_binary_labels.detach().cpu().numpy.detach().cpu().numpy.detach", "result.items", "adversary_indexes[].item", "y.detach().cpu().numpy.detach().cpu().numpy.detach", "binary_y.detach().cpu().numpy.detach().cpu().numpy.detach", "x.view.view.detach"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.ResNet.copy_weights", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.train_one_image", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.model_with_fingerprint", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.detect_with_fingerprints", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.compute_counts", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.compute_counts"], ["", "def", "eval_with_fingerprints_finetune", "(", "self", ",", "val_loader", ",", "ds_name", ",", "reject_thresholds", ",", "num_updates", ",", "lr", ")", ":", "\n", "        ", "test_net", "=", "copy", ".", "deepcopy", "(", "self", ".", "model", ")", "\n", "stats_per_tau", "=", "{", "thresh", ":", "Stats", "(", "tau", "=", "thresh", ",", "name", "=", "ds_name", ",", "ds_name", "=", "ds_name", ")", "for", "thresh", "in", "reject_thresholds", "}", "\n", "i", "=", "0", "\n", "all_F1_scores", "=", "[", "]", "\n", "all_tau", "=", "[", "]", "\n", "# \u6ce8\u610f\u8fd9\u4e2aval_loader\u8981\u7279\u522b\u5b9a\u5236\u5316", "\n", "each_attack_stats", "=", "val_loader", ".", "dataset", ".", "fetch_attack_name", "\n", "attacker_stats", "=", "defaultdict", "(", "list", ")", "\n", "for", "pack", "in", "val_loader", ":", "\n", "            ", "if", "each_attack_stats", ":", "\n", "                ", "support_images", ",", "support_gt_labels", ",", "support_binary_labels", ",", "query_images", ",", "query_gt_labels", ",", "query_binary_labels", ",", "adversary_indexes", ",", "_", "=", "pack", "\n", "", "else", ":", "\n", "                ", "support_images", ",", "support_gt_labels", ",", "support_binary_labels", ",", "query_images", ",", "query_gt_labels", ",", "query_binary_labels", ",", "_", "=", "pack", "\n", "", "support_binary_labels", "=", "support_binary_labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "support_gt_labels", "=", "support_gt_labels", ".", "cuda", "(", ")", "\n", "support_images", "=", "support_images", ".", "cuda", "(", ")", "\n", "query_images", "=", "query_images", ".", "cuda", "(", ")", "\n", "for", "task_idx", "in", "range", "(", "support_images", ".", "size", "(", "0", ")", ")", ":", "\n", "\n", "                ", "clean_support_index", "=", "np", ".", "where", "(", "support_binary_labels", "[", "task_idx", "]", "==", "1", ")", "[", "0", "]", "\n", "clean_imgs", "=", "support_images", "[", "task_idx", "]", "[", "clean_support_index", "]", "\n", "clean_labels", "=", "support_gt_labels", "[", "task_idx", "]", "[", "clean_support_index", "]", "# support label \u9700\u8981\u4f20\u5165\u5e72\u51c0\u56fe \u7684\u771f\u6b63label\uff0c\u800c\u4e0d\u662f0/1", "\n", "test_net", ".", "copy_weights", "(", "self", ".", "model", ")", "\n", "\n", "optimizer", "=", "optim", ".", "SGD", "(", "test_net", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "batch_size", "=", "clean_imgs", ".", "size", "(", "0", ")", "\n", "clean_imgs", "=", "clean_imgs", ".", "view", "(", "batch_size", ",", "IN_CHANNELS", "[", "ds_name", "]", ",", "IMAGE_SIZE", "[", "ds_name", "]", "[", "0", "]", ",", "IMAGE_SIZE", "[", "ds_name", "]", "[", "1", "]", ")", "\n", "test_net", ".", "train", "(", ")", "\n", "for", "m", "in", "test_net", ".", "modules", "(", ")", ":", "\n", "                    ", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                        ", "m", ".", "eval", "(", ")", "# BN\u5c42\u4f1a\u51fa\u95ee\u9898\uff0c\u4e0d\u8981\u8bad\u7ec3", "\n", "", "", "for", "_", "in", "range", "(", "num_updates", ")", ":", "# \u5148fine_tune", "\n", "                    ", "self", ".", "train_one_image", "(", "test_net", ",", "clean_imgs", ",", "clean_labels", ",", "optimizer", ",", "1", ")", "\n", "\n", "", "test_net", ".", "eval", "(", ")", "\n", "x", ",", "y", "=", "query_images", "[", "task_idx", "]", ",", "query_gt_labels", "[", "task_idx", "]", "# \u6ce8\u610f\u8fd9\u4e2a\u5206\u7c7b\u4fe1\u606f\u662fimg gt label", "\n", "binary_y", "=", "query_binary_labels", "[", "task_idx", "]", "\n", "y", "=", "y", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "binary_y", "=", "binary_y", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "batch_size", "=", "x", ".", "size", "(", "0", ")", "\n", "x", "=", "x", ".", "view", "(", "batch_size", ",", "IN_CHANNELS", "[", "ds_name", "]", ",", "IMAGE_SIZE", "[", "ds_name", "]", "[", "0", "]", ",", "IMAGE_SIZE", "[", "ds_name", "]", "[", "1", "]", ")", "\n", "\n", "data_np", "=", "x", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "real_bs", "=", "data_np", ".", "shape", "[", "0", "]", "\n", "\n", "for", "b", "in", "range", "(", "real_bs", ")", ":", "\n", "                    ", "ex", "=", "self", ".", "model_with_fingerprint", "(", "test_net", ",", "x", "[", "b", ":", "b", "+", "1", "]", ",", "self", ".", "fp", ")", "\n", "# Careful! Needs Dataloader with shuffle=False", "\n", "ex", ".", "id", "=", "i", "\n", "ex", ".", "y", "=", "y", "[", "b", "]", "# ground truth of real image : 1 , adversarial image 0", "\n", "ex", ".", "binary_y", "=", "binary_y", "[", "b", "]", "\n", "ex", ",", "stats_per_tau", "=", "self", ".", "detect_with_fingerprints", "(", "ex", ",", "stats_per_tau", ")", "\n", "i", "+=", "1", "\n", "\n", "# results = defaultdict(lambda: None)", "\n", "# stats_results = defaultdict(lambda: None)", "\n", "\n", "", "result", "=", "{", "}", "\n", "for", "tau", ",", "stats", "in", "stats_per_tau", ".", "items", "(", ")", ":", "\n", "                    ", "stats", ".", "counts", "=", "stats", ".", "compute_counts", "(", ")", "\n", "ids_correct", "=", "stats", ".", "ids_correct", "\n", "F1", "=", "stats", ".", "compute_counts", "(", "ids_correct", "=", "ids_correct", ")", "[", "\"F1\"", "]", "\n", "result", "[", "tau", "]", "=", "F1", "\n", "# best_F1 = result[min(result.keys(), key=lambda k: abs(k-threshold))]", "\n", "", "best_F1", "=", "max", "(", "list", "(", "result", ".", "values", "(", ")", ")", ")", "\n", "# best_tau = threshold", "\n", "best_tau", "=", "max", "(", "list", "(", "result", ".", "items", "(", ")", ")", ",", "key", "=", "lambda", "e", ":", "e", "[", "1", "]", ")", "[", "0", "]", "\n", "if", "each_attack_stats", ":", "\n", "                    ", "adversary", "=", "META_ATTACKER_INDEX", "[", "adversary_indexes", "[", "task_idx", "]", ".", "item", "(", ")", "]", "\n", "attacker_stats", "[", "adversary", "]", ".", "append", "(", "best_F1", ")", "\n", "\n", "", "all_F1_scores", ".", "append", "(", "best_F1", ")", "\n", "all_tau", ".", "append", "(", "best_tau", ")", "\n", "stats_per_tau", ".", "clear", "(", ")", "\n", "for", "thresh", "in", "reject_thresholds", ":", "\n", "                    ", "stats_per_tau", "[", "thresh", "]", "=", "Stats", "(", "tau", "=", "thresh", ",", "name", "=", "ds_name", ",", "ds_name", "=", "ds_name", ")", "\n", "", "print", "(", "\"evaluate_accuracy task {}, F1:{}\"", ".", "format", "(", "task_idx", ",", "best_F1", ")", ")", "\n", "", "", "F1", "=", "np", ".", "mean", "(", "all_F1_scores", ")", "\n", "tau", "=", "np", ".", "mean", "(", "all_tau", ")", "\n", "for", "adversary", ",", "query_F1_score_list", "in", "attacker_stats", ".", "items", "(", ")", ":", "\n", "            ", "attacker_stats", "[", "adversary", "]", "=", "np", ".", "mean", "(", "query_F1_score_list", ")", "\n", "\n", "\n", "", "del", "test_net", "\n", "print", "(", "\"final   F1: {}  tau:{}\"", ".", "format", "(", "F1", ",", "tau", ")", ")", "\n", "return", "F1", ",", "tau", ",", "attacker_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.test_speed": [[411, 483], ["copy.deepcopy", "numpy.mean", "numpy.var", "neural_fingerprint.fingerprint.Stats", "support_binary_labels.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "support_gt_labels.cuda.cuda.cuda", "support_images.cuda.cuda.cuda", "query_images.cuda.cuda.cuda", "range", "support_images.cuda.cuda.size", "print", "copy.deepcopy.copy_weights", "torch.optim.SGD", "torch.optim.SGD", "clean_imgs.view.view.size", "clean_imgs.view.view.view", "copy.deepcopy.train", "time.time", "copy.deepcopy.modules", "range", "copy.deepcopy.eval", "y.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "binary_y.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "x.view.view.size", "x.view.view.view", "x.view.view.detach().cpu().numpy", "range", "stats_per_tau.items", "max", "all_times.append", "stats_per_tau.clear", "support_binary_labels.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "numpy.where", "copy.deepcopy.parameters", "isinstance", "fingerprint_detector.NeuralFingerprintDetector.train_one_image", "fingerprint_detector.NeuralFingerprintDetector.model_with_fingerprint", "fingerprint_detector.NeuralFingerprintDetector.detect_with_fingerprints", "stats.compute_counts", "list", "time.time", "max", "neural_fingerprint.fingerprint.Stats", "m.eval", "y.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "binary_y.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "x.view.view.detach().cpu", "stats.compute_counts", "result.values", "list", "support_binary_labels.detach().cpu().numpy.detach().cpu().numpy.detach", "result.items", "y.detach().cpu().numpy.detach().cpu().numpy.detach", "binary_y.detach().cpu().numpy.detach().cpu().numpy.detach", "x.view.view.detach"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.ResNet.copy_weights", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.train_one_image", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.model_with_fingerprint", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint_detector.NeuralFingerprintDetector.detect_with_fingerprints", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.compute_counts", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.fingerprint.Stats.compute_counts"], ["", "def", "test_speed", "(", "self", ",", "val_loader", ",", "ds_name", ",", "reject_thresholds", ",", "num_updates", ",", "lr", ")", ":", "\n", "        ", "test_net", "=", "copy", ".", "deepcopy", "(", "self", ".", "model", ")", "\n", "stats_per_tau", "=", "{", "thresh", ":", "Stats", "(", "tau", "=", "thresh", ",", "name", "=", "ds_name", ",", "ds_name", "=", "ds_name", ")", "for", "thresh", "in", "reject_thresholds", "}", "\n", "i", "=", "0", "\n", "all_times", "=", "[", "]", "\n", "# \u6ce8\u610f\u8fd9\u4e2aval_loader\u8981\u7279\u522b\u5b9a\u5236\u5316", "\n", "for", "support_images", ",", "support_gt_labels", ",", "support_binary_labels", ",", "query_images", ",", "query_gt_labels", ",", "query_binary_labels", ",", "_", "in", "val_loader", ":", "\n", "            ", "support_binary_labels", "=", "support_binary_labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "support_gt_labels", "=", "support_gt_labels", ".", "cuda", "(", ")", "\n", "support_images", "=", "support_images", ".", "cuda", "(", ")", "\n", "query_images", "=", "query_images", ".", "cuda", "(", ")", "\n", "for", "task_idx", "in", "range", "(", "support_images", ".", "size", "(", "0", ")", ")", ":", "\n", "                ", "print", "(", "\"evaluate_accuracy task {}\"", ".", "format", "(", "task_idx", ")", ")", "\n", "clean_support_index", "=", "np", ".", "where", "(", "support_binary_labels", "[", "task_idx", "]", "==", "1", ")", "[", "0", "]", "\n", "clean_imgs", "=", "support_images", "[", "task_idx", "]", "[", "clean_support_index", "]", "\n", "clean_labels", "=", "support_gt_labels", "[", "task_idx", "]", "[", "clean_support_index", "]", "# support label \u9700\u8981\u4f20\u5165\u5e72\u51c0\u56fe \u7684\u771f\u6b63label\uff0c\u800c\u4e0d\u662f0/1", "\n", "test_net", ".", "copy_weights", "(", "self", ".", "model", ")", "\n", "\n", "optimizer", "=", "optim", ".", "SGD", "(", "test_net", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "batch_size", "=", "clean_imgs", ".", "size", "(", "0", ")", "\n", "clean_imgs", "=", "clean_imgs", ".", "view", "(", "batch_size", ",", "IN_CHANNELS", "[", "ds_name", "]", ",", "IMAGE_SIZE", "[", "ds_name", "]", "[", "0", "]", ",", "IMAGE_SIZE", "[", "ds_name", "]", "[", "1", "]", ")", "\n", "test_net", ".", "train", "(", ")", "\n", "before_time", "=", "time", ".", "time", "(", ")", "\n", "for", "m", "in", "test_net", ".", "modules", "(", ")", ":", "\n", "                    ", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                        ", "m", ".", "eval", "(", ")", "# BN\u5c42\u4f1a\u51fa\u95ee\u9898\uff0c\u4e0d\u8981\u8bad\u7ec3", "\n", "", "", "for", "_", "in", "range", "(", "num_updates", ")", ":", "# \u5148fine_tune", "\n", "                    ", "self", ".", "train_one_image", "(", "test_net", ",", "clean_imgs", ",", "clean_labels", ",", "optimizer", ",", "1", ")", "\n", "\n", "", "test_net", ".", "eval", "(", ")", "\n", "x", ",", "y", "=", "query_images", "[", "task_idx", "]", ",", "query_gt_labels", "[", "task_idx", "]", "# \u6ce8\u610f\u8fd9\u4e2a\u5206\u7c7b\u4fe1\u606f\u662fimg gt label", "\n", "binary_y", "=", "query_binary_labels", "[", "task_idx", "]", "\n", "y", "=", "y", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "binary_y", "=", "binary_y", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "batch_size", "=", "x", ".", "size", "(", "0", ")", "\n", "x", "=", "x", ".", "view", "(", "batch_size", ",", "IN_CHANNELS", "[", "ds_name", "]", ",", "IMAGE_SIZE", "[", "ds_name", "]", "[", "0", "]", ",", "IMAGE_SIZE", "[", "ds_name", "]", "[", "1", "]", ")", "\n", "\n", "data_np", "=", "x", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "real_bs", "=", "data_np", ".", "shape", "[", "0", "]", "\n", "\n", "for", "b", "in", "range", "(", "real_bs", ")", ":", "\n", "                    ", "ex", "=", "self", ".", "model_with_fingerprint", "(", "test_net", ",", "x", "[", "b", ":", "b", "+", "1", "]", ",", "self", ".", "fp", ")", "\n", "# Careful! Needs Dataloader with shuffle=False", "\n", "ex", ".", "id", "=", "i", "\n", "ex", ".", "y", "=", "y", "[", "b", "]", "# ground truth of real image : 1 , adversarial image 0", "\n", "ex", ".", "binary_y", "=", "binary_y", "[", "b", "]", "\n", "ex", ",", "stats_per_tau", "=", "self", ".", "detect_with_fingerprints", "(", "ex", ",", "stats_per_tau", ")", "\n", "i", "+=", "1", "\n", "\n", "# results = defaultdict(lambda: None)", "\n", "# stats_results = defaultdict(lambda: None)", "\n", "\n", "", "result", "=", "{", "}", "\n", "for", "tau", ",", "stats", "in", "stats_per_tau", ".", "items", "(", ")", ":", "\n", "                    ", "stats", ".", "counts", "=", "stats", ".", "compute_counts", "(", ")", "\n", "ids_correct", "=", "stats", ".", "ids_correct", "\n", "F1", "=", "stats", ".", "compute_counts", "(", "ids_correct", "=", "ids_correct", ")", "[", "\"F1\"", "]", "\n", "result", "[", "tau", "]", "=", "F1", "\n", "# best_F1 = result[min(result.keys(), key=lambda k: abs(k-threshold))]", "\n", "", "best_F1", "=", "max", "(", "list", "(", "result", ".", "values", "(", ")", ")", ")", "\n", "# best_tau = threshold", "\n", "time_elapse", "=", "time", ".", "time", "(", ")", "-", "before_time", "\n", "best_tau", "=", "max", "(", "list", "(", "result", ".", "items", "(", ")", ")", ",", "key", "=", "lambda", "e", ":", "e", "[", "1", "]", ")", "[", "0", "]", "\n", "\n", "all_times", ".", "append", "(", "time_elapse", ")", "\n", "stats_per_tau", ".", "clear", "(", ")", "\n", "for", "thresh", "in", "reject_thresholds", ":", "\n", "                    ", "stats_per_tau", "[", "thresh", "]", "=", "Stats", "(", "tau", "=", "thresh", ",", "name", "=", "ds_name", ",", "ds_name", "=", "ds_name", ")", "\n", "", "", "", "mean_time", "=", "np", ".", "mean", "(", "all_times", ")", "\n", "var_time", "=", "np", ".", "var", "(", "all_times", ")", "\n", "del", "test_net", "\n", "return", "mean_time", ",", "var_time", "", "", "", ""]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.Identity.__init__": [[32, 34], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__"], ["from", "deep_learning_adv_detector", ".", "evaluation", ".", "zero_shot_evaluation", "import", "evaluate_zero_shot", "\n", "from", "deep_learning_adv_detector", ".", "evaluation", ".", "white_box_evaluation", "import", "evaluate_whitebox", "\n", "import", "glob", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.Identity.forward": [[34, 36], ["None"], "methods", ["None"], ["import", "glob", "\n", "from", "deep_learning_adv_detector", ".", "evaluation", ".", "speed_evaluation", "import", "evaluate_speed", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.__init__": [[291, 293], ["train.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.reset"], ["epoch", ",", "i", ",", "len", "(", "train_loader", ")", ",", "batch_time", "=", "batch_time", ",", "\n", "loss", "=", "losses", ",", "top1", "=", "top1", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.reset": [[294, 299], ["None"], "methods", ["None"], ["# iter = epoch * len(train_loader) + i", "\n", "# evaluate_result = speed_test(model, val_loader, 0, 0, 1000)", "\n", "# query_F1_tensor = torch.Tensor(1)", "\n", "# query_F1_tensor.fill_(evaluate_result[\"query_F1\"])", "\n", "# tensorboard.record_val_query_F1(query_F1_tensor, iter)", "\n", "# print('Epoch: [{0}][{1}/{2}]\\t'", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update": [[300, 305], ["None"], "methods", ["None"], ["#       'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'", "\n", "#       'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'", "\n", "#       'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\tValQueryF1 {query_F1:.3f}'.format(", "\n", "#     epoch, i, len(train_loader), batch_time=batch_time,", "\n", "#     loss=losses, top1=top1, query_F1=evaluate_result[\"query_F1\"]))", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.main": [[78, 97], ["parser.parse_args", "str", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "warnings.warn", "train.main_train_worker"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.neural_fingerprint.train_fingerprint.parse_args", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.main_train_worker"], ["parser", ".", "add_argument", "(", "\"--cross_arch_target\"", ",", "type", "=", "str", ",", "help", "=", "\"the target domain to evaluate_accuracy\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cross_arch_source\"", ",", "type", "=", "str", ",", "help", "=", "\"the target domain to evaluate_accuracy\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--num_updates\"", ",", "type", "=", "int", ",", "default", "=", "20", ",", "help", "=", "\"the number of inner updates\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_pkl_path\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"the train task txt file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--study_subject\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--balance\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv_arch\"", ",", "type", "=", "str", ",", "default", "=", "\"conv3\"", ",", "choices", "=", "[", "\"conv3\"", ",", "\"resnet10\"", ",", "\"resnet18\"", "]", ")", "\n", "best_acc1", "=", "0", "\n", "\n", "\n", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "args", ".", "seed", "is", "not", "None", ":", "\n", "        ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "cudnn", ".", "deterministic", "=", "True", "\n", "warnings", ".", "warn", "(", "'You have chosen to seed training. '", "\n", "'This will turn on the CUDNN deterministic setting, '", "\n", "'which can slow down your training considerably! '", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.evaluate": [[98, 107], ["in_.cuda.cuda", "meta_adv_detector.score.forward_pass", "l.item", "numpy.argmax().reshape", "sklearn.metrics.accuracy_score", "target_positive.detach().cpu().numpy().reshape", "in_.cuda.detach().cpu().numpy", "numpy.argmax", "float", "in_.cuda.size", "out.detach().cpu().numpy", "target_positive.detach().cpu().numpy", "in_.cuda.detach().cpu", "out.detach().cpu", "target_positive.detach().cpu", "in_.cuda.detach", "out.detach", "target_positive.detach"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.meta_network.MetaNetwork.forward_pass"], ["'You may see unexpected behavior when restarting '", "\n", "'from checkpoints.'", ")", "\n", "", "if", "not", "args", ".", "evaluate", ":", "# not evaluate_accuracy", "\n", "\n", "        ", "model_path", "=", "'{}/train_pytorch_model/DL_DET/DL_DET@{}_{}@model_{}@data_{}@epoch_{}@class_{}@lr_{}@balance_{}.pth.tar'", ".", "format", "(", "\n", "PY_ROOT", ",", "args", ".", "dataset", ",", "args", ".", "protocol", ",", "args", ".", "arch", ",", "args", ".", "adv_arch", ",", "\n", "args", ".", "epochs", ",", "\n", "2", ",", "args", ".", "lr", ",", "args", ".", "balance", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "model_path", ")", ",", "exist_ok", "=", "True", ")", "\n", "main_train_worker", "(", "args", ",", "model_path", ",", "gpu", "=", "str", "(", "args", ".", "gpu", ")", ")", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.main_train_worker": [[108, 197], ["args.arch.startswith", "os.makedirs", "toolkit.img_transform.get_preprocessor", "networks.conv3.Conv3.cuda", "torch.CrossEntropyLoss().cuda", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "print", "print", "print", "train.Identity", "torch.Linear", "args.arch.startswith", "os.path.dirname", "networks.conv3.Conv3.parameters", "os.path.isfile", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "train.adjust_learning_rate", "train.train", "train.validate", "print", "train.save_checkpoint", "networks.resnet.resnet10", "torch.Linear", "torch.CrossEntropyLoss", "print", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "networks.conv3.Conv3.load_state_dict", "print", "print", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "networks.resnet.resnet18", "torchvision.datasets.FashionMNIST", "torchvision.datasets.FashionMNIST", "networks.conv3.Conv3.state_dict", "torch.optim.Adam.state_dict", "networks.conv3.Conv3", "dataset.SVHN_dataset.SVHN", "dataset.SVHN_dataset.SVHN"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.toolkit.img_transform.get_preprocessor", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.adjust_learning_rate", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.validate", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.save_checkpoint", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet10", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.networks.resnet.resnet18"], ["\n", "", "else", ":", "# finetune evaluate_accuracy", "\n", "# DL_DET@CIFAR-10_TRAIN_II_TEST_I@conv3@epoch_40@class_2@lr_0.0001.pth.tar", "\n", "        ", "print", "(", "\"Use GPU: {} for training\"", ".", "format", "(", "args", ".", "gpu", ")", ")", "\n", "os", ".", "environ", "[", "\"CUDA_DEVICE_ORDER\"", "]", "=", "\"PCI_BUS_ID\"", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "str", "(", "args", ".", "gpu", ")", "\n", "model_file_list", "=", "glob", ".", "glob", "(", "\"{}/train_pytorch_model/DL_DET/DL_DET@*\"", ".", "format", "(", "PY_ROOT", ")", ")", "\n", "if", "args", ".", "study_subject", "==", "\"cross_domain\"", ":", "\n", "            ", "result", "=", "evaluate_cross_domain", "(", "model_file_list", ",", "args", ".", "num_updates", ",", "args", ".", "lr", ",", "args", ".", "protocol", ",", "\n", "args", ".", "cross_domain_source", ",", "args", ".", "cross_domain_target", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "'finetune_eval'", ":", "\n", "            ", "result", "=", "evaluate_finetune", "(", "model_file_list", ",", "args", ".", "lr", ",", "args", ".", "protocol", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"shots_eval\"", ":", "\n", "            ", "result", "=", "evaluate_shots", "(", "model_file_list", ",", "args", ".", "num_updates", ",", "args", ".", "lr", ",", "args", ".", "protocol", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"cross_arch\"", ":", "\n", "            ", "updateBN", "=", "False", "\n", "result", "=", "evaluate_cross_arch", "(", "model_file_list", ",", "args", ".", "num_updates", ",", "args", ".", "lr", ",", "args", ".", "protocol", ",", "args", ".", "cross_arch_source", ",", "\n", "args", ".", "cross_arch_target", ",", "updateBN", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"zero_shot\"", ":", "\n", "            ", "result", "=", "evaluate_zero_shot", "(", "model_file_list", ",", "args", ".", "lr", ",", "args", ".", "protocol", ",", "args", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"speed_test\"", ":", "\n", "            ", "result", "=", "evaluate_speed", "(", "model_file_list", ",", "args", ".", "num_updates", ",", "args", ".", "lr", ",", "args", ".", "protocol", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"white_box\"", ":", "\n", "            ", "result", "=", "defaultdict", "(", "dict", ")", "\n", "attacks", "=", "[", "\"FGSM\"", ",", "\"CW_L2\"", "]", "\n", "for", "attack_name", "in", "attacks", ":", "\n", "                ", "evaluate_whitebox", "(", "args", ".", "dataset", ",", "\"conv3\"", ",", "\"conv3\"", ",", "\"DNN\"", ",", "attack_name", ",", "args", ".", "num_updates", ",", "args", ".", "lr", ",", "\n", "args", ".", "protocol", ",", "LOAD_TASK_MODE", ".", "NO_LOAD", ",", "result", ")", "\n", "", "", "file_name", "=", "'{}/train_pytorch_model/DL_DET/cross_adv_group_{}_using_{}_protocol.json'", ".", "format", "(", "PY_ROOT", ",", "args", ".", "study_subject", ",", "args", ".", "protocol", ")", "\n", "if", "args", ".", "study_subject", "==", "\"cross_domain\"", ":", "\n", "            ", "file_name", "=", "'{}/train_pytorch_model/DL_DET/evaluate_{}_{}--{}_using_{}_protocol.json'", ".", "format", "(", "PY_ROOT", ",", "\n", "args", ".", "study_subject", ",", "args", ".", "cross_domain_source", ",", "args", ".", "cross_domain_target", ",", "\n", "args", ".", "protocol", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"cross_arch\"", ":", "\n", "            ", "file_name", "=", "'{}/train_pytorch_model/DL_DET/evaluate_{}_{}--{}_using_{}_protocol_updateBN_{}.json'", ".", "format", "(", "PY_ROOT", ",", "\n", "args", ".", "study_subject", ",", "\n", "args", ".", "cross_arch_source", ",", "\n", "args", ".", "cross_arch_target", ",", "\n", "args", ".", "protocol", ",", "updateBN", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"white_box\"", ":", "\n", "            ", "file_name", "=", "'{}/train_pytorch_model/white_box_model/white_box_UPDATEBN_DNN_{}_using_{}_protocol.json'", ".", "format", "(", "PY_ROOT", ",", "\n", "args", ".", "dataset", ",", "\n", "args", ".", "protocol", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"speed_test\"", ":", "\n", "            ", "file_name", "=", "'{}/train_pytorch_model/DL_DET/speed_test_of_DNN.json'", ".", "format", "(", "PY_ROOT", ")", "\n", "", "elif", "args", ".", "study_subject", "==", "\"zero_shot\"", ":", "\n", "            ", "if", "args", ".", "cross_domain_source", ":", "\n", "                ", "file_name", "=", "'{}/train_pytorch_model/DL_DET/evaluate_{}_{}--{}_using_{}_protocol.json'", ".", "format", "(", "PY_ROOT", ",", "\n", "args", ".", "study_subject", ",", "\n", "args", ".", "cross_domain_source", ",", "\n", "args", ".", "cross_domain_target", ",", "\n", "args", ".", "protocol", ")", "\n", "", "else", ":", "\n", "                ", "file_name", "=", "'{}/train_pytorch_model/DL_DET/evaluate_{}_using_{}_protocol.json'", ".", "format", "(", "PY_ROOT", ",", "\n", "args", ".", "study_subject", ",", "\n", "args", ".", "protocol", ")", "\n", "\n", "", "", "with", "open", "(", "file_name", ",", "\"w\"", ")", "as", "file_obj", ":", "\n", "            ", "file_obj", ".", "write", "(", "json", ".", "dumps", "(", "result", ")", ")", "\n", "file_obj", ".", "flush", "(", ")", "\n", "\n", "\n", "", "", "", "def", "main_train_worker", "(", "args", ",", "model_path", ",", "META_ATTACKER_PART_I", "=", "None", ",", "META_ATTACKER_PART_II", "=", "None", ",", "gpu", "=", "\"0\"", ")", ":", "\n", "    ", "if", "META_ATTACKER_PART_I", "is", "None", ":", "\n", "        ", "META_ATTACKER_PART_I", "=", "config", ".", "META_ATTACKER_PART_I", "\n", "", "if", "META_ATTACKER_PART_II", "is", "None", ":", "\n", "        ", "META_ATTACKER_PART_II", "=", "config", ".", "META_ATTACKER_PART_II", "\n", "", "print", "(", "\"Use GPU: {} for training\"", ".", "format", "(", "gpu", ")", ")", "\n", "os", ".", "environ", "[", "\"CUDA_DEVICE_ORDER\"", "]", "=", "\"PCI_BUS_ID\"", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "gpu", "\n", "print", "(", "\"will save to {}\"", ".", "format", "(", "model_path", ")", ")", "\n", "global", "best_acc1", "\n", "if", "args", ".", "arch", "==", "\"conv3\"", ":", "\n", "        ", "model", "=", "Conv3", "(", "IN_CHANNELS", "[", "args", ".", "dataset", "]", ",", "IMAGE_SIZE", "[", "args", ".", "dataset", "]", ",", "2", ")", "\n", "", "elif", "args", ".", "arch", "==", "\"resnet10\"", ":", "\n", "        ", "model", "=", "resnet10", "(", "2", ",", "in_channels", "=", "IN_CHANNELS", "[", "args", ".", "dataset", "]", ",", "pretrained", "=", "False", ")", "\n", "", "elif", "args", ".", "arch", "==", "\"resnet18\"", ":", "\n", "        ", "model", "=", "resnet18", "(", "2", ",", "in_channels", "=", "IN_CHANNELS", "[", "args", ".", "dataset", "]", ",", "pretrained", "=", "False", ")", "\n", "", "model", "=", "model", ".", "cuda", "(", ")", "\n", "if", "args", ".", "dataset", "==", "\"ImageNet\"", ":", "\n", "        ", "train_dataset", "=", "AdversaryRandomAccessNpyDataset", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "dataset", "]", "+", "\"/adversarial_images/{}\"", ".", "format", "(", "args", ".", "adv_arch", ")", ",", "\n", "True", ",", "args", ".", "protocol", ",", "META_ATTACKER_PART_I", ",", "META_ATTACKER_PART_II", ",", "\n", "args", ".", "balance", ",", "args", ".", "dataset", ")", "\n", "", "else", ":", "\n", "        ", "train_dataset", "=", "AdversaryDataset", "(", "IMAGE_DATA_ROOT", "[", "args", ".", "dataset", "]", "+", "\"/adversarial_images/{}\"", ".", "format", "(", "args", ".", "adv_arch", ")", ",", "\n", "True", ",", "args", ".", "protocol", ",", "META_ATTACKER_PART_I", ",", "META_ATTACKER_PART_II", ",", "args", ".", "balance", ")", "\n", "\n", "# val_dataset = MetaTaskDataset(20000, 2, 1, 15,", "\n", "#                                     args.dataset, is_train=False, pkl_task_dump_path=args.test_pkl_path,", "\n", "#                                     load_mode=LOAD_TASK_MODE.LOAD,", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train": [[200, 245], ["train.AverageMeter", "train.AverageMeter", "train.AverageMeter", "train.AverageMeter", "model.train", "time.time", "enumerate", "train.AverageMeter.update", "input.cuda.cuda", "target.cuda.cuda", "model", "criterion", "train.accuracy", "train.AverageMeter.update", "train.AverageMeter.update", "optimizer.zero_grad", "criterion.backward", "optimizer.step", "train.AverageMeter.update", "time.time", "criterion.item", "input.cuda.size", "input.cuda.size", "print", "time.time", "time.time", "len"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.train", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.accuracy", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update"], ["# define loss function (criterion) and optimizer", "\n", "", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "cuda", "(", "args", ".", "gpu", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "lr", ",", "\n", "momentum", "=", "args", ".", "momentum", ",", "\n", "weight_decay", "=", "args", ".", "weight_decay", ")", "\n", "\n", "# optionally resume from a checkpoint", "\n", "if", "os", ".", "path", ".", "exists", "(", "model_path", ")", ":", "\n", "        ", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "model_path", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "args", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "model_path", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"=> no checkpoint found at '{}'\"", ".", "format", "(", "model_path", ")", ")", "\n", "\n", "", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# Data loading code", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "train_dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "\n", "# val_loader = torch.utils.data.DataLoader(", "\n", "#     val_dataset,", "\n", "#     batch_size=100, shuffle=False,", "\n", "#     num_workers=0, pin_memory=True)", "\n", "tensorboard", "=", "TensorBoardWriter", "(", "\"{0}/pytorch_DeepLearning_tensorboard\"", ".", "format", "(", "PY_ROOT", ")", ",", "\"DeepLearning\"", ")", "\n", "for", "epoch", "in", "range", "(", "args", ".", "start_epoch", ",", "args", ".", "epochs", ")", ":", "\n", "        ", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ",", "args", ")", "\n", "# train for one epoch", "\n", "train", "(", "train_loader", ",", "None", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "tensorboard", ",", "args", ")", "\n", "if", "args", ".", "balance", ":", "\n", "            ", "train_dataset", ".", "img_label_list", ".", "clear", "(", ")", "\n", "train_dataset", ".", "img_label_list", ".", "extend", "(", "train_dataset", ".", "img_label_dict", "[", "1", "]", ")", "\n", "train_dataset", ".", "img_label_list", ".", "extend", "(", "random", ".", "sample", "(", "train_dataset", ".", "img_label_dict", "[", "0", "]", ",", "len", "(", "train_dataset", ".", "img_label_dict", "[", "1", "]", ")", ")", ")", "\n", "# evaluate_accuracy on validation set", "\n", "\n", "# acc1 = validate(val_loader, model, criterion, args)", "\n", "# remember best acc@1 and save checkpoint", "\n", "", "save_checkpoint", "(", "{", "\n", "'epoch'", ":", "epoch", "+", "1", ",", "\n", "'arch'", ":", "args", ".", "arch", ",", "\n", "'state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.validate": [[247, 284], ["train.AverageMeter", "train.AverageMeter", "train.AverageMeter", "model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "time.time", "enumerate", "print", "input.cuda.cuda", "target.cuda.cuda", "model", "criterion", "train.accuracy", "train.AverageMeter.update", "train.AverageMeter.update", "train.AverageMeter.update", "time.time", "criterion.item", "input.cuda.size", "input.cuda.size", "print", "time.time", "len"], "function", ["home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.accuracy", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update", "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.AverageMeter.update"], ["}", ",", "filename", "=", "model_path", ")", "\n", "\n", "\n", "\n", "", "", "def", "train", "(", "train_loader", ",", "val_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "tensorboard", ",", "args", ")", ":", "\n", "    ", "batch_time", "=", "AverageMeter", "(", ")", "\n", "data_time", "=", "AverageMeter", "(", ")", "\n", "losses", "=", "AverageMeter", "(", ")", "\n", "top1", "=", "AverageMeter", "(", ")", "\n", "# top5 = AverageMeter()", "\n", "\n", "# switch to train mode", "\n", "model", ".", "train", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "input", ",", "target", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "# measure data loading time", "\n", "        ", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "input", "=", "input", ".", "cuda", "(", ")", "\n", "target", "=", "target", ".", "cuda", "(", ")", "\n", "\n", "# compute output", "\n", "output", "=", "model", "(", "input", ")", "\n", "loss", "=", "criterion", "(", "output", ",", "target", ")", "\n", "# measure accuracy and record loss", "\n", "acc1", ",", "=", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", "\n", "losses", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "top1", ".", "update", "(", "acc1", "[", "0", "]", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "# top5.update(acc5[0], input.size(0))", "\n", "\n", "# compute gradient and do SGD step", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.save_checkpoint": [[285, 287], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save"], "function", ["None"], ["\n", "if", "i", "%", "args", ".", "print_freq", "==", "0", ":", "\n", "            ", "print", "(", "'Epoch: [{0}][{1}/{2}]\\t'", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.adjust_learning_rate": [[307, 312], ["None"], "function", ["None"], ["\n", "", "", "", "def", "save_checkpoint", "(", "state", ",", "filename", "=", "'traditional_dl.pth.tar'", ")", ":", "\n", "    ", "torch", ".", "save", "(", "state", ",", "filename", ")", "\n", "\n", "\n", "", "class", "AverageMeter", "(", "object", ")", ":", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.clean_image_classifier.train.accuracy": [[314, 329], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["\n", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n", "", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.draw_figure.line_curve.read_json_data": [[8, 17], ["open", "sorted", "numpy.array", "json.load", "data.items", "x.append", "y.append", "numpy.array", "int", "int"], "function", ["None"], ["def", "read_json_data", "(", "json_path", ")", ":", "\n", "    ", "x", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "with", "open", "(", "json_path", ",", "\"r\"", ")", "as", "file_obj", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "file_obj", ")", "[", "\"CIFAR-10\"", "]", "\n", "for", "key", ",", "val_json", "in", "sorted", "(", "data", ".", "items", "(", ")", ",", "key", "=", "lambda", "e", ":", "int", "(", "e", "[", "0", "]", ")", ")", ":", "\n", "            ", "x", ".", "append", "(", "int", "(", "key", ")", ")", "\n", "y", ".", "append", "(", "val_json", "[", "\"query_F1\"", "]", ")", "\n", "", "", "return", "np", ".", "array", "(", "x", ")", ",", "np", ".", "array", "(", "y", ")", "*", "100", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.draw_figure.line_curve.read_deep_learning_shots_data": [[19, 37], ["open", "sorted", "open", "sorted", "numpy.array", "numpy.array", "json.load", "data.items", "x_no_balance.append", "y_no_balance.append", "json.load", "data.items", "x_balance.append", "y_balance.append", "numpy.array", "numpy.array", "int", "int", "int", "int"], "function", ["None"], ["", "def", "read_deep_learning_shots_data", "(", "json_path", ")", ":", "\n", "    ", "x_no_balance", "=", "[", "]", "\n", "y_no_balance", "=", "[", "]", "\n", "x_balance", "=", "[", "]", "\n", "y_balance", "=", "[", "]", "\n", "with", "open", "(", "json_path", ",", "\"r\"", ")", "as", "file_obj", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "file_obj", ")", "[", "\"CIFAR-10_no_balance\"", "]", "\n", "for", "key", ",", "val_json", "in", "sorted", "(", "data", ".", "items", "(", ")", ",", "key", "=", "lambda", "e", ":", "int", "(", "e", "[", "0", "]", ")", ")", ":", "\n", "            ", "x_no_balance", ".", "append", "(", "int", "(", "key", ")", ")", "\n", "y_no_balance", ".", "append", "(", "val_json", "[", "\"query_F1\"", "]", ")", "\n", "\n", "", "", "with", "open", "(", "json_path", ",", "\"r\"", ")", "as", "file_obj", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "file_obj", ")", "[", "\"CIFAR-10_balance\"", "]", "\n", "for", "key", ",", "val_json", "in", "sorted", "(", "data", ".", "items", "(", ")", ",", "key", "=", "lambda", "e", ":", "int", "(", "e", "[", "0", "]", ")", ")", ":", "\n", "            ", "x_balance", ".", "append", "(", "int", "(", "key", ")", ")", "\n", "y_balance", ".", "append", "(", "val_json", "[", "\"query_F1\"", "]", ")", "\n", "\n", "", "", "return", "np", ".", "array", "(", "x_no_balance", ")", ",", "np", ".", "array", "(", "y_no_balance", ")", "*", "100", ",", "np", ".", "array", "(", "x_balance", ")", ",", "np", ".", "array", "(", "y_balance", ")", "*", "100", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.draw_figure.line_curve.read_deep_learning_finetune_data": [[39, 56], ["open", "sorted", "open", "sorted", "numpy.array", "numpy.array", "json.load", "data.items", "x_no_balance.append", "y_no_balance.append", "json.load", "data.items", "x_balance.append", "y_balance.append", "numpy.array", "numpy.array", "int", "int", "int", "int"], "function", ["None"], ["", "def", "read_deep_learning_finetune_data", "(", "json_path", ")", ":", "\n", "    ", "x_balance", "=", "[", "]", "\n", "y_balance", "=", "[", "]", "\n", "x_no_balance", "=", "[", "]", "\n", "y_no_balance", "=", "[", "]", "\n", "with", "open", "(", "json_path", ",", "\"r\"", ")", "as", "file_obj", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "file_obj", ")", "[", "\"CIFAR-10_no_balance\"", "]", "\n", "for", "key", ",", "val_json", "in", "sorted", "(", "data", ".", "items", "(", ")", ",", "key", "=", "lambda", "e", ":", "int", "(", "e", "[", "0", "]", ")", ")", ":", "\n", "            ", "x_no_balance", ".", "append", "(", "int", "(", "key", ")", ")", "\n", "y_no_balance", ".", "append", "(", "val_json", "[", "\"query_F1\"", "]", ")", "\n", "", "", "with", "open", "(", "json_path", ",", "\"r\"", ")", "as", "file_obj", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "file_obj", ")", "[", "\"CIFAR-10_balance\"", "]", "\n", "for", "key", ",", "val_json", "in", "sorted", "(", "data", ".", "items", "(", ")", ",", "key", "=", "lambda", "e", ":", "int", "(", "e", "[", "0", "]", ")", ")", ":", "\n", "            ", "x_balance", ".", "append", "(", "int", "(", "key", ")", ")", "\n", "y_balance", ".", "append", "(", "val_json", "[", "\"query_F1\"", "]", ")", "\n", "\n", "", "", "return", "np", ".", "array", "(", "x_no_balance", ")", ",", "np", ".", "array", "(", "y_no_balance", ")", "*", "100", ",", "np", ".", "array", "(", "x_balance", ")", ",", "np", ".", "array", "(", "y_balance", ")", "*", "100", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.draw_figure.line_curve.draw_shots_line_curve": [[58, 79], ["matplotlib.style.use", "matplotlib.figure", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.gcf().subplots_adjust", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.legend", "matplotlib.savefig", "matplotlib.gcf"], "function", ["None"], ["", "def", "draw_shots_line_curve", "(", "x_list", ",", "y_list", ",", "save_fig_name", ")", ":", "\n", "    ", "plt", ".", "style", ".", "use", "(", "'seaborn-whitegrid'", ")", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "8", ",", "6", ")", ")", "\n", "x_meta", "=", "x_list", "[", "0", "]", "\n", "x_deep_nobalance", "=", "x_list", "[", "1", "]", "\n", "x_deep_balance", "=", "x_list", "[", "2", "]", "\n", "y_meta", "=", "y_list", "[", "0", "]", "\n", "y_deep_nobalance", "=", "y_list", "[", "1", "]", "\n", "y_deep_balance", "=", "y_list", "[", "2", "]", "\n", "line", ",", "=", "plt", ".", "plot", "(", "x_meta", ",", "y_meta", ",", "marker", "=", "'.'", ",", "color", "=", "\"r\"", ",", "label", "=", "\"AdvMetaDet (ours)\"", ")", "\n", "line", ",", "=", "plt", ".", "plot", "(", "x_deep_nobalance", ",", "y_deep_nobalance", ",", "marker", "=", "'.'", ",", "color", "=", "\"b\"", ",", "label", "=", "\"DNN\"", ")", "\n", "line", ",", "=", "plt", ".", "plot", "(", "x_deep_balance", ",", "y_deep_balance", ",", "marker", "=", "'.'", ",", "color", "=", "'y'", ",", "label", "=", "\"DNN(balanced)\"", ")", "\n", "plt", ".", "xlim", "(", "0", ",", "16", ")", "\n", "plt", ".", "ylim", "(", "50", ",", "90", ")", "\n", "plt", ".", "gcf", "(", ")", ".", "subplots_adjust", "(", "bottom", "=", "0.15", ")", "\n", "plt", ".", "xticks", "(", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", ",", "11", ",", "12", ",", "13", ",", "14", ",", "15", "]", ",", "fontsize", "=", "15", ")", "\n", "plt", ".", "yticks", "(", "[", "50", ",", "55", ",", "60", ",", "65", ",", "70", ",", "75", ",", "80", ",", "85", ",", "90", "]", ",", "fontsize", "=", "15", ")", "\n", "plt", ".", "xlabel", "(", "\"shots\"", ",", "fontsize", "=", "18", ")", "\n", "plt", ".", "ylabel", "(", "\"F1 score of query set(%)\"", ",", "fontsize", "=", "18", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'upper left'", ",", "prop", "=", "{", "'size'", ":", "17", "}", ")", "\n", "plt", ".", "savefig", "(", "save_fig_name", ",", "dpi", "=", "200", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.draw_figure.line_curve.draw_tasks_line_curve": [[81, 94], ["matplotlib.style.use", "matplotlib.figure", "matplotlib.plot", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.gcf().subplots_adjust", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.legend", "matplotlib.savefig", "matplotlib.gcf"], "function", ["None"], ["", "def", "draw_tasks_line_curve", "(", "x", ",", "y", ",", "save_fig_name", ")", ":", "\n", "    ", "plt", ".", "style", ".", "use", "(", "'seaborn-whitegrid'", ")", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "8", ",", "6", ")", ")", "\n", "line", ",", "=", "plt", ".", "plot", "(", "x", ",", "y", ",", "marker", "=", "'.'", ",", "color", "=", "\"r\"", ")", "\n", "plt", ".", "xlim", "(", "4", ",", "x", "[", "-", "1", "]", "+", "1", ")", "\n", "plt", ".", "ylim", "(", "55", ",", "65", ")", "\n", "plt", ".", "gcf", "(", ")", ".", "subplots_adjust", "(", "bottom", "=", "0.15", ")", "\n", "plt", ".", "xticks", "(", "x", ",", "fontsize", "=", "15", ")", "\n", "plt", ".", "yticks", "(", "[", "55", ",", "58", ",", "60", ",", "62", ",", "65", "]", ",", "fontsize", "=", "15", ")", "\n", "plt", ".", "xlabel", "(", "\"task number\"", ",", "fontsize", "=", "18", ")", "\n", "plt", ".", "ylabel", "(", "\"F1 score of query set(%)\"", ",", "fontsize", "=", "18", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'upper right'", ",", "prop", "=", "{", "'size'", ":", "17", "}", ")", "\n", "plt", ".", "savefig", "(", "save_fig_name", ",", "dpi", "=", "200", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.draw_figure.line_curve.draw_inner_update_line_curve": [[95, 108], ["matplotlib.style.use", "matplotlib.figure", "matplotlib.plot", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.gcf().subplots_adjust", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.legend", "matplotlib.savefig", "matplotlib.gcf"], "function", ["None"], ["", "def", "draw_inner_update_line_curve", "(", "x_meta", ",", "y_meta", ",", "save_fig_name", ")", ":", "\n", "    ", "plt", ".", "style", ".", "use", "(", "'seaborn-whitegrid'", ")", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "8", ",", "6", ")", ")", "\n", "line", ",", "=", "plt", ".", "plot", "(", "x_meta", ",", "y_meta", ",", "marker", "=", "'.'", ",", "color", "=", "\"r\"", ",", ")", "\n", "plt", ".", "xlim", "(", "4", ",", "x_meta", "[", "-", "1", "]", "+", "1", ")", "\n", "plt", ".", "ylim", "(", "60", ",", "64", ")", "\n", "plt", ".", "gcf", "(", ")", ".", "subplots_adjust", "(", "bottom", "=", "0.15", ")", "\n", "plt", ".", "xticks", "(", "x_meta", ",", "fontsize", "=", "15", ")", "\n", "plt", ".", "yticks", "(", "[", "60", ",", "61", ",", "62", ",", "63", ",", "64", ",", "65", "]", ",", "fontsize", "=", "15", ")", "\n", "plt", ".", "xlabel", "(", "\"inner update times\"", ",", "fontsize", "=", "18", ")", "\n", "plt", ".", "ylabel", "(", "\"F1 score of query set(%)\"", ",", "fontsize", "=", "18", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'upper right'", ",", "prop", "=", "{", "'size'", ":", "17", "}", ")", "\n", "plt", ".", "savefig", "(", "save_fig_name", ",", "dpi", "=", "200", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.draw_figure.line_curve.draw_finetune_line_curve": [[109, 131], ["matplotlib.style.use", "matplotlib.figure", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.gcf().subplots_adjust", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.legend", "matplotlib.savefig", "matplotlib.gcf"], "function", ["None"], ["", "def", "draw_finetune_line_curve", "(", "x_list", ",", "y_list", ",", "save_fig_name", ")", ":", "\n", "    ", "plt", ".", "style", ".", "use", "(", "'seaborn-whitegrid'", ")", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "8", ",", "6", ")", ")", "\n", "x_meta", "=", "x_list", "[", "0", "]", "\n", "x_deep_nobalance", "=", "x_list", "[", "1", "]", "\n", "x_deep_balance", "=", "x_list", "[", "2", "]", "\n", "y_meta", "=", "y_list", "[", "0", "]", "\n", "y_deep_nobalance", "=", "y_list", "[", "1", "]", "\n", "y_deep_balance", "=", "y_list", "[", "2", "]", "\n", "line", ",", "=", "plt", ".", "plot", "(", "x_meta", ",", "y_meta", ",", "marker", "=", "'.'", ",", "color", "=", "\"r\"", ",", "label", "=", "\"AdvMetaDet (ours)\"", ")", "\n", "line", ",", "=", "plt", ".", "plot", "(", "x_deep_nobalance", ",", "y_deep_nobalance", ",", "marker", "=", "'.'", ",", "color", "=", "\"b\"", ",", "label", "=", "\"DNN\"", ")", "\n", "line", ",", "=", "plt", ".", "plot", "(", "x_deep_balance", ",", "y_deep_balance", ",", "marker", "=", "'.'", ",", "color", "=", "'y'", ",", "\n", "label", "=", "\"DNN(balanced)\"", ")", "\n", "plt", ".", "xlim", "(", "0", ",", "x_meta", "[", "-", "1", "]", "+", "1", ")", "\n", "plt", ".", "ylim", "(", "30", ",", "65", ")", "\n", "plt", ".", "gcf", "(", ")", ".", "subplots_adjust", "(", "bottom", "=", "0.15", ")", "\n", "plt", ".", "xticks", "(", "[", "1", ",", "5", ",", "10", ",", "15", ",", "20", ",", "25", ",", "30", ",", "35", ",", "40", ",", "45", ",", "50", "]", ",", "fontsize", "=", "15", ")", "\n", "plt", ".", "yticks", "(", "[", "30", ",", "35", ",", "40", ",", "45", ",", "50", ",", "55", ",", "60", ",", "65", "]", ",", "fontsize", "=", "15", ")", "\n", "plt", ".", "xlabel", "(", "\"fine-tune iterations\"", ",", "fontsize", "=", "18", ")", "\n", "plt", ".", "ylabel", "(", "\"F1 score of query set(%)\"", ",", "fontsize", "=", "18", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'lower right'", ",", "prop", "=", "{", "'size'", ":", "17", "}", ")", "\n", "plt", ".", "savefig", "(", "save_fig_name", ",", "dpi", "=", "200", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.draw_figure.line_curve.draw_ways_line_curve": [[132, 145], ["matplotlib.style.use", "matplotlib.figure", "matplotlib.plot", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.gcf().subplots_adjust", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.legend", "matplotlib.savefig", "matplotlib.gcf"], "function", ["None"], ["", "def", "draw_ways_line_curve", "(", "x", ",", "y", ",", "save_fig_name", ")", ":", "\n", "    ", "plt", ".", "style", ".", "use", "(", "'seaborn-whitegrid'", ")", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "8", ",", "6", ")", ")", "\n", "line", ",", "=", "plt", ".", "plot", "(", "x", ",", "y", ",", "marker", "=", "'.'", ",", "color", "=", "\"r\"", ")", "\n", "plt", ".", "xlim", "(", "4", ",", "x", "[", "-", "1", "]", "+", "1", ")", "\n", "plt", ".", "ylim", "(", "5", ",", "75", ")", "\n", "plt", ".", "gcf", "(", ")", ".", "subplots_adjust", "(", "bottom", "=", "0.15", ")", "\n", "plt", ".", "xticks", "(", "x", ",", "fontsize", "=", "15", ")", "\n", "plt", ".", "yticks", "(", "[", "5", ",", "10", ",", "15", ",", "20", ",", "25", ",", "30", ",", "35", ",", "40", ",", "45", ",", "50", ",", "55", ",", "60", ",", "65", ",", "70", ",", "75", "]", ",", "fontsize", "=", "15", ")", "\n", "plt", ".", "xlabel", "(", "\"the number of way in each task\"", ",", "fontsize", "=", "18", ")", "\n", "plt", ".", "ylabel", "(", "\"F1 score of query set(%)\"", ",", "fontsize", "=", "18", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'upper right'", ",", "prop", "=", "{", "'size'", ":", "17", "}", ")", "\n", "plt", ".", "savefig", "(", "save_fig_name", ",", "dpi", "=", "200", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.machanic_MetaAdvDet.draw_figure.line_curve.draw_query_size_line_curve": [[147, 160], ["matplotlib.style.use", "matplotlib.figure", "matplotlib.plot", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.gcf().subplots_adjust", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.legend", "matplotlib.savefig", "matplotlib.gcf"], "function", ["None"], ["", "def", "draw_query_size_line_curve", "(", "x", ",", "y", ",", "save_fig_name", ")", ":", "\n", "    ", "plt", ".", "style", ".", "use", "(", "'seaborn-whitegrid'", ")", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "8", ",", "6", ")", ")", "\n", "line", ",", "=", "plt", ".", "plot", "(", "x", ",", "y", ",", "marker", "=", "'.'", ",", "color", "=", "\"r\"", ")", "\n", "plt", ".", "xlim", "(", "4", ",", "x", "[", "-", "1", "]", "+", "1", ")", "\n", "plt", ".", "ylim", "(", "59", ",", "64", ")", "\n", "plt", ".", "gcf", "(", ")", ".", "subplots_adjust", "(", "bottom", "=", "0.15", ")", "\n", "plt", ".", "xticks", "(", "x", ",", "fontsize", "=", "15", ")", "\n", "plt", ".", "yticks", "(", "[", "59", ",", "60", ",", "61", ",", "62", ",", "63", ",", "64", "]", ",", "fontsize", "=", "15", ")", "\n", "plt", ".", "xlabel", "(", "\"query set size of each way during training\"", ",", "fontsize", "=", "18", ")", "\n", "plt", ".", "ylabel", "(", "\"F1 score of query set(%)\"", ",", "fontsize", "=", "18", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'upper right'", ",", "prop", "=", "{", "'size'", ":", "17", "}", ")", "\n", "plt", ".", "savefig", "(", "save_fig_name", ",", "dpi", "=", "200", ")", "\n", "\n"]]}