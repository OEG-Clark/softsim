{"home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.paraphrase.get_paraphrases": [[18, 58], ["translators.translators.Anamorphism", "translators.translators.Anamorphism", "print", "translators.translators.Anamorphism.forward", "translators.translators.Anamorphism.empty_cache", "print", "translators.translators.Anamorphism.forward", "translators.translators.Anamorphism.forward", "print", "py_translator.Translator().translate", "utils.helper_functions.display", "nltk.word_tokenize", "nltk.word_tokenize", "nltk.word_tokenize", "nltk.word_tokenize", "utils.helper_functions.byte_pair_decoding", "utils.helper_functions.byte_pair_decoding", "utils.helper_functions.byte_pair_decoding", "utils.helper_functions.byte_pair_decoding", "py_translator.Translator"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.forward", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.empty_cache", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.forward", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.forward", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.display", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.byte_pair_decoding", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.byte_pair_decoding", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.byte_pair_decoding", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.byte_pair_decoding"], ["def", "get_paraphrases", "(", "\n", "sentence", ",", "\n", "rightward_model", ",", "\n", "leftward_model", ",", "\n", ")", ":", "\n", "\n", "\t", "unfolded_rightward_model", "=", "Anamorphism", "(", "underlying_model", "=", "rightward_model", ",", "beam_width", "=", "1", ")", "\n", "unfolded_leftward_model", "=", "Anamorphism", "(", "underlying_model", "=", "leftward_model", ",", "beam_width", "=", "2", ")", "\n", "\n", "# sentence = byte_pair_encoding(sentence=sentence.lower(),code_path=unfolded_rightward_model.bpe_code_path)", "\n", "\n", "# _ , target_sents = unfolded_rightward_model.forward(sequence=[],source_sentence=sentence)", "\n", "# target_sent = target_sents[0].lower()", "\n", "\n", "target_sent", "=", "Translator", "(", ")", ".", "translate", "(", "text", "=", "sentence", ",", "src", "=", "'en'", ",", "dest", "=", "'fr'", ")", ".", "text", "\n", "\n", "# target_sent = \"Der mann lacht.\"", "\n", "\n", "# input_target_sent = byte_pair_encoding(sentence=target_sent,code_path=leftward_code_path)", "\n", "print", "(", "\"target sentence:\"", ",", "target_sent", ")", "\n", "# print(\"INPUT TARGET SENTENCE\",input_target_sent)", "\n", "probs", ",", "paraphrases", "=", "unfolded_leftward_model", ".", "forward", "(", "sequence", "=", "[", "]", ",", "source_sentence", "=", "target_sent", ")", "\n", "unfolded_leftward_model", ".", "empty_cache", "(", ")", "\n", "print", "(", "\"ALL PARAPHRASES\"", ",", "display", "(", "probs", "=", "probs", ",", "support", "=", "paraphrases", ")", ")", "\n", "# print(\"paraphrases\",paraphrases)", "\n", "# raise Exception", "\n", "\n", "paraphrase1", "=", "paraphrases", "[", "0", "]", "\n", "paraphrase2", "=", "paraphrases", "[", "1", "]", "\n", "\n", "_", ",", "backtrans1", "=", "unfolded_rightward_model", ".", "forward", "(", "sequence", "=", "[", "]", ",", "source_sentence", "=", "paraphrase1", ")", "\n", "_", ",", "backtrans2", "=", "unfolded_rightward_model", ".", "forward", "(", "sequence", "=", "[", "]", ",", "source_sentence", "=", "paraphrase2", ")", "\n", "backtrans1", "=", "backtrans1", "[", "0", "]", "\n", "backtrans2", "=", "backtrans2", "[", "0", "]", "\n", "\n", "print", "(", "\"tok\"", ",", "nltk", ".", "word_tokenize", "(", "byte_pair_decoding", "(", "backtrans1", ")", ")", ",", "nltk", ".", "word_tokenize", "(", "byte_pair_decoding", "(", "backtrans2", ")", ")", ")", "\n", "condition1", "=", "nltk", ".", "word_tokenize", "(", "byte_pair_decoding", "(", "backtrans1", ")", ")", "==", "nltk", ".", "word_tokenize", "(", "byte_pair_decoding", "(", "backtrans2", ")", ")", "\n", "if", "condition1", ":", "\n", "\n", "\t\t", "return", "[", "paraphrase1", ",", "paraphrase2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.find_pairs.cap_to_words": [[11, 13], ["charpragcap.utils.image_and_text_utils.devectorize_caption", "re.sub().split", "nltk.corpus.stopwords.words", "re.sub", "charpragcap.utils.image_and_text_utils.devectorize_caption"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.devectorize_caption", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.devectorize_caption"], ["def", "cap_to_words", "(", "cap", ")", ":", "\n", "\t", "return", "[", "word", "for", "word", "in", "re", ".", "sub", "(", "'[^a-z ]'", ",", "\"\"", ",", "devectorize_caption", "(", "cap", ")", ")", ".", "split", "(", ")", "if", "word", "not", "in", "stopwords", ".", "words", "(", "'english'", ")", "]", ",", "devectorize_caption", "(", "cap", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.find_pairs.find_pairs": [[18, 31], ["set", "item.split", "t.split", "sorted", "find_pairs.cap_to_words", "find_pairs.cap_to_words", "l.append", "len", "set().intersection", "set"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.generate_clusters.cap_to_words", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.generate_clusters.cap_to_words"], ["", "def", "find_pairs", "(", "item", ")", ":", "\n", "\n", "\t", "cap", "=", "set", "(", "cap_to_words", "(", "id_to_caption", "[", "item", "]", "[", "0", "]", "[", "0", "]", ")", "[", "0", "]", ")", "\n", "fst_half_id", ",", "snd_half_id", "=", "item", ".", "split", "(", "'_'", ")", "\n", "l", "=", "[", "]", "\n", "\n", "for", "t", "in", "test", ":", "\n", "\t\t", "fst_half_new_id", ",", "snd_half_new_id", "=", "t", ".", "split", "(", "'_'", ")", "\n", "if", "fst_half_id", "!=", "fst_half_new_id", ":", "\n", "\t\t\t", "new_cap", ",", "full_cap", "=", "cap_to_words", "(", "id_to_caption", "[", "t", "]", "[", "0", "]", "[", "0", "]", ")", "\n", "l", ".", "append", "(", "(", "len", "(", "set", "(", "new_cap", ")", ".", "intersection", "(", "cap", ")", ")", ",", "full_cap", ",", "t", ")", ")", "\n", "\n", "", "", "return", "(", "sorted", "(", "l", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "[", ":", "30", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.find_pairs.all_pairs": [[32, 45], ["enumerate", "sorted", "print", "find_pairs.find_pairs", "print", "out.append"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.find_pairs.find_pairs"], ["", "def", "all_pairs", "(", ")", ":", "\n", "\t", "out", "=", "[", "]", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "test", ")", ":", "\n", "\t\t", "print", "(", "i", ")", "\n", "pairs", "=", "find_pairs", "(", "t", ")", "\n", "# if pairs[1][0]>1:", "\n", "print", "(", "pairs", "[", ":", "3", "]", ")", "\n", "if", "pairs", "[", "2", "]", "[", "0", "]", ">", "1", ":", "\n", "\t\t\t", "out", ".", "append", "(", "pairs", "[", ":", "3", "]", ")", "\n", "", "if", "i", ">", "5000", ":", "\n", "\t\t\t", "break", "\n", "\n", "", "", "return", "sorted", "(", "out", ",", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ")", "\n", "# break", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.config.list_to_index_iso": [[27, 39], ["collections.defaultdict", "enumerate", "collections.defaultdict", "enumerate"], "function", ["None"], ["def", "list_to_index_iso", "(", "l", ")", ":", "\n", "\t", "rightward", "=", "defaultdict", "(", "int", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "l", ")", ":", "\n", "\t\t", "rightward", "[", "x", "]", "=", "i", "\n", "", "leftward", "=", "defaultdict", "(", "int", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "sym_set", ")", ":", "\n", "\t\t", "leftward", "[", "i", "]", "=", "x", "\n", "\n", "", "out", "=", "{", "}", "\n", "out", "[", "\"rightward\"", "]", "=", "rightward", "\n", "out", "[", "\"leftward\"", "]", "=", "leftward", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.compute_results.compute_results": [[24, 45], ["numpy.array", "model.ana_beam", "print", "pickle.dump", "open", "charpragcap.utils.image_and_text_utils.get_rep_from_img_id", "numpy.log", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.get_rep_from_img_id"], ["def", "compute_results", "(", "model", ",", "images", ")", ":", "\n", "\n", "\t", "s0_results", "=", "{", "}", "\n", "for", "img_id", "in", "images", ":", "\n", "\t\t", "model", ".", "images", "=", "np", ".", "array", "(", "[", "get_rep_from_img_id", "(", "img_id", ")", "]", ")", "\n", "# out = model.ana_greedy(speaker_rationality=1.0, listener_rationality=1.0, depth=0,start_from=\"\",img_prior=np.log(np.asarray([0.5])))", "\n", "out", "=", "model", ".", "ana_beam", "(", "\n", "speaker_rationality", "=", "1.0", ",", "\n", "listener_rationality", "=", "1.0", ",", "\n", "depth", "=", "0", ",", "start_from", "=", "\"\"", ",", "\n", "decay_rate", "=", "-", "1.0", ",", "\n", "img_prior", "=", "np", ".", "log", "(", "np", ".", "asarray", "(", "[", "0.5", "]", ")", ")", "\n", ")", "\n", "\n", "s0_results", "[", "img_id", "]", "=", "out", "\n", "print", "(", "\"RESULTS:\"", ",", "out", ")", "\n", "model", ".", "_speaker_cache", "=", "{", "}", "\n", "model", ".", "_listener_cache", "=", "{", "}", "\n", "\n", "\n", "pickle", ".", "dump", "(", "s0_results", ",", "open", "(", "\"charpragcap/resources/s0_results_beam\"", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.compute_results.compute_results_pragmatic": [[50, 72], ["pickle.load", "model.ana_beam", "open", "numpy.array", "print", "print", "pickle.dump", "numpy.log", "open", "numpy.asarray", "charpragcap.utils.image_and_text_utils.get_rep_from_img_id", "tuple"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.get_rep_from_img_id"], ["def", "compute_results_pragmatic", "(", "model", ",", "depth", ",", "name", ")", ":", "\n", "\t", "clusters", "=", "pickle", ".", "load", "(", "open", "(", "\"charpragcap/resources/clusters\"", ",", "'rb'", ")", ")", "\n", "s0_results", "=", "{", "}", "\n", "out", "=", "model", ".", "ana_beam", "(", "\n", "speaker_rationality", "=", "1.0", ",", "\n", "listener_rationality", "=", "1.0", ",", "\n", "depth", "=", "depth", ",", "start_from", "=", "\"\"", ",", "\n", "decay_rate", "=", "-", "1.0", ",", "\n", "img_prior", "=", "np", ".", "log", "(", "np", ".", "asarray", "(", "[", "1", "/", "2", ",", "1", "/", "2", "]", ")", ")", "\n", ")", "\n", "for", "items", "in", "clusters", "[", ":", "20", "]", ":", "\n", "\t\t", "model", ".", "images", "=", "np", ".", "array", "(", "[", "get_rep_from_img_id", "(", "item", "[", "1", "]", ")", "for", "item", "in", "items", "]", ")", "\n", "# out = model.ana_greedy(speaker_rationality=1.0, listener_rationality=1.0, depth=0,start_from=\"\",img_prior=np.log(np.asarray([0.5])))", "\n", "\n", "s0_results", "[", "tuple", "(", "[", "(", "item", "[", "1", "]", ",", "item", "[", "0", "]", ")", "for", "item", "in", "items", "]", ")", "]", "=", "out", "\n", "print", "(", "out", ")", "\n", "print", "(", "items", ")", "\n", "model", ".", "_speaker_cache", "=", "{", "}", "\n", "model", ".", "_listener_cache", "=", "{", "}", "\n", "\n", "\n", "pickle", ".", "dump", "(", "s0_results", ",", "open", "(", "\"charpragcap/resources/s0_results_\"", "+", "name", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_utils.get_rep_from_url": [[1, 12], ["requests.get", "open", "shutil.copyfileobj"], "function", ["None"], ["def", "get_rep_from_url", "(", "url", ")", ":", "\n", "\n", "    ", "import", "urllib", ".", "request", "\n", "from", "PIL", "import", "Image", "as", "PIL_Image", "\n", "import", "shutil", "\n", "import", "requests", "\n", "\n", "response", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "\n", "with", "open", "(", "'charpragcap/resources/img.jpg'", ",", "'wb'", ")", "as", "out_file", ":", "\n", "        ", "shutil", ".", "copyfileobj", "(", "response", ".", "raw", ",", "out_file", ")", "\n", "", "del", "response", "", "", ""]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.sample.to_var": [[13, 17], ["torch.cuda.is_available", "torch.autograd.Variable", "x.cuda.cuda"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator.cuda"], ["def", "to_var", "(", "x", ",", "volatile", "=", "False", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "x", "=", "x", ".", "cuda", "(", ")", "\n", "", "return", "Variable", "(", "x", ",", "volatile", "=", "volatile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.sample.load_image_from_path": [[22, 34], ["PIL.Image.open", "transform().unsqueeze.resize", "transform().unsqueeze", "transform"], "function", ["None"], ["", "def", "load_image_from_path", "(", "path", ",", "transform", "=", "None", ")", ":", "\n", "\n", "    ", "from", "PIL", "import", "Image", "as", "PIL_Image", "\n", "\n", "\n", "image", "=", "Image", ".", "open", "(", "path", ")", "\n", "image", "=", "image", ".", "resize", "(", "[", "224", ",", "224", "]", ",", "Image", ".", "LANCZOS", ")", "\n", "# image = image.crop([0,0,224,224])", "\n", "if", "transform", "is", "not", "None", ":", "\n", "        ", "image", "=", "transform", "(", "image", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.sample.load_image": [[35, 76], ["re.sub", "requests.get", "print", "PIL.Image.open", "transform().unsqueeze.resize", "open", "shutil.copyfileobj", "transform().unsqueeze", "transform"], "function", ["None"], ["", "def", "load_image", "(", "url", ",", "transform", "=", "None", ")", ":", "\n", "\n", "    ", "import", "urllib", ".", "request", "\n", "from", "PIL", "import", "Image", "as", "PIL_Image", "\n", "import", "shutil", "\n", "import", "requests", "\n", "\n", "hashed_url", "=", "re", ".", "sub", "(", "'/'", ",", "''", ",", "url", ")", "\n", "\n", "response", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "\n", "with", "open", "(", "'data/google_images/img'", "+", "hashed_url", "+", "'.jpg'", ",", "'wb'", ")", "as", "out_file", ":", "\n", "        ", "shutil", ".", "copyfileobj", "(", "response", ".", "raw", ",", "out_file", ")", "\n", "# del response", "\n", "", "print", "(", "url", ",", "response", ")", "\n", "# print(os.listdir())", "\n", "\n", "\n", "image", "=", "Image", ".", "open", "(", "'data/google_images/img'", "+", "hashed_url", "+", "'.jpg'", ")", "\n", "# print(\"image loaded (sample.py)\")", "\n", "image", "=", "image", ".", "resize", "(", "[", "224", ",", "224", "]", ",", "Image", ".", "LANCZOS", ")", "\n", "# width = image.size[0]", "\n", "# height = image.size[1]", "\n", "\n", "# if width>height:", "\n", "#     new_height=224", "\n", "#     new_width=224 * (width/height)", "\n", "# else:", "\n", "#     new_width=224", "\n", "#     new_height=224 * (height/width)", "\n", "\n", "# b = image.resize([int(new_width),int(new_height)],PIL_Image.LANCZOS)", "\n", "# # b = a.thumbnail([224, 224], PIL_Image.LANCZOS)", "\n", "# # c = b.crop([0,0,224,224])", "\n", "# image = b.crop([0,0,224,224])", "\n", "\n", "if", "transform", "is", "not", "None", ":", "\n", "        ", "image", "=", "transform", "(", "image", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "# image = transforms.ToTensor()(image).unsqueeze(0)", "\n", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.test_data.check_reps": [[7, 24], ["single_stream", "single_stream", "range", "next", "next", "print", "item_to_rep", "np.expand_dims", "print", "print", "print", "np.array_equal"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.data_stream.single_stream", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.data_stream.single_stream", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.item_to_rep"], ["def", "check_reps", "(", ")", ":", "\n", "\n", "\t", "repsandcaps", "=", "single_stream", "(", "train", ",", "X0_type", "=", "'rep'", ")", "\n", "idsandcaps", "=", "single_stream", "(", "train", ",", "X0_type", "=", "'id'", ")", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "\t\t", "repandcaps", "=", "next", "(", "repsandcaps", ")", "\n", "idandcaps", "=", "next", "(", "idsandcaps", ")", "\n", "img_id", "=", "idandcaps", "[", "0", "]", "\n", "img_rep", "=", "repandcaps", "[", "0", "]", "\n", "print", "(", "\"img id:\"", ",", "img_id", ")", "\n", "real_rep", "=", "item_to_rep", "(", "img_id", ")", "\n", "stored_rep", "=", "np", ".", "expand_dims", "(", "img_rep", ",", "0", ")", "\n", "\n", "print", "(", "\"real rep\"", ",", "real_rep", ")", "\n", "print", "(", "\"stored rep\"", ",", "stored_rep", ")", "\n", "print", "(", "real_rep", "==", "stored_rep", ")", "\n", "assert", "(", "np", ".", "array_equal", "(", "real_rep", ",", "stored_rep", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.test_data.view_data": [[25, 32], ["single_stream", "get_img_from_id", "display", "print", "print", "np.argmax"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.data_stream.single_stream", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.get_img_from_id", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.display"], ["", "", "def", "view_data", "(", ")", ":", "\n", "\t", "for", "full_id", ",", "cap_in", ",", "cap_out", "in", "single_stream", "(", "test", ",", "X0_type", "=", "'id'", ")", ":", "\n", "\t    ", "img", "=", "get_img_from_id", "(", "full_id", ",", "id_to_caption", ")", "\n", "display", "(", "img", ")", "\n", "print", "(", "\"\"", ".", "join", "(", "[", "index_to_char", "[", "x", "]", "for", "x", "in", "cap_in", "]", ")", ")", "\n", "print", "(", "''", ".", "join", "(", "[", "index_to_char", "[", "np", ".", "argmax", "(", "x", ")", "]", "for", "x", "in", "cap_out", "]", ")", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.data_stream.single_stream": [[16, 66], ["type", "tuple", "charpragcap.utils.image_and_text_utils.get_img_from_id", "numpy.expand_dims", "print", "fc_resnet.predict", "print", "charpragcap.utils.image_and_text_utils.get_img_from_id", "keras.preprocessing.image.img_to_array", "out.append", "keras.preprocessing.image.img_to_array", "fc_resnet.predict"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.get_img_from_id", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.get_img_from_id"], ["def", "single_stream", "(", "ids", ",", "X0_type", "=", "'rep'", ")", ":", "\n", "\n", "# TODO", "\n", "#find the other ids with same first part: hopefully can just look down the dict, if sorted right: check that", "\n", "#iterate through this list, taking each as a starting id, and returning the whole list of ids", "\n", "#use the lookup in a vectorized way (implemented in pandas) to get reps, if reps needed", "\n", "\n", "\t", "for", "full_id", "in", "ids", ":", "\n", "\t\t", "pairs", "=", "False", "\n", "if", "type", "(", "full_id", ")", "==", "tuple", ":", "pairs", "=", "True", "\n", "\n", "\n", "\n", "if", "pairs", ":", "\n", "\n", "\n", "\t\t\t", "fst_id", ",", "snd_id", "=", "full_id", "\n", "if", "X0_type", "==", "'rep'", ":", "\n", "\t\t\t\t", "try", ":", "\n", "\t\t\t\t\t", "fst_X0", ",", "snd_X0", "=", "reps", ".", "ix", "[", "fst_id", "]", ".", "values", ",", "reps", ".", "ix", "[", "snd_id", "]", ".", "values", "\n", "", "except", "Exception", ":", "\n", "\t\t\t\t\t", "out", "=", "[", "]", "\n", "for", "idx", "in", "[", "fst_id", ",", "snd_id", "]", ":", "\n", "\t\t\t\t\t\t", "img", "=", "get_img_from_id", "(", "idx", ",", "id_to_caption", ")", "\n", "img_vector", "=", "image", ".", "img_to_array", "(", "img", ")", "\n", "out", ".", "append", "(", "fc_resnet", ".", "predict", "(", "[", "img_vector", "]", ")", ")", "\n", "", "fst_X0", ",", "snd_X0", "=", "tuple", "(", "out", ")", "\n", "", "", "elif", "X0_type", "==", "'id'", ":", "\n", "\t\t\t\t", "fst_X0", ",", "snd_X0", "=", "fst_id", ",", "snd_id", "\n", "", "fst_X1", ",", "fst_Y", "=", "id_to_caption", "[", "fst_id", "]", "[", "caption", "]", "\n", "snd_X1", ",", "snd_Y", "=", "id_to_caption", "[", "snd_id", "]", "[", "caption", "]", "\n", "yield", "(", "fst_X0", ",", "fst_X1", ",", "fst_Y", ",", "snd_X0", ",", "snd_X1", ",", "snd_Y", ")", "\n", "\n", "", "else", ":", "\n", "\t\t\t", "if", "X0_type", "==", "'rep'", ":", "\n", "\t\t\t\t", "try", ":", "\n", "\t\t\t\t\t", "X0", "=", "reps", ".", "ix", "[", "full_id", "]", ".", "values", "\n", "", "except", "KeyError", ":", "\n", "\t\t\t\t\t", "img", "=", "get_img_from_id", "(", "full_id", ",", "id_to_caption", ")", "\n", "\n", "img_vector", "=", "np", ".", "expand_dims", "(", "image", ".", "img_to_array", "(", "img", ")", ",", "0", ")", "\n", "print", "(", "\"\\n\\n\\nshape\"", ",", "img_vector", ".", "shape", ")", "\n", "X0", "=", "fc_resnet", ".", "predict", "(", "img_vector", ")", "\n", "\n", "print", "(", "\"\\n\\n\\nGOT IMAGE\\n\\n\\n\"", ")", "\n", "\n", "\n", "", "", "elif", "X0_type", "==", "'id'", ":", "X0", "=", "full_id", "\n", "X1", ",", "Y", "=", "id_to_caption", "[", "full_id", "]", "[", "caption", "]", "\n", "yield", "(", "X0", ",", "X1", ",", "Y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.data_stream.chunked_stream": [[68, 74], ["more_itertools.chunked", "data_stream.single_stream", "list", "zip", "numpy.asarray", "numpy.asarray", "numpy.expand_dims", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.data_stream.single_stream"], ["", "", "", "def", "chunked_stream", "(", "ids", ")", ":", "\n", "\t", "chunks", "=", "more_itertools", ".", "chunked", "(", "single_stream", "(", "ids", ")", ",", "batch_size", ")", "\n", "\n", "for", "chunk", "in", "chunks", ":", "\n", "\t\t", "x1s", ",", "x2s", ",", "ys", "=", "list", "(", "zip", "(", "*", "chunk", ")", ")", "\n", "yield", "(", "[", "np", ".", "asarray", "(", "x1s", ")", ",", "np", ".", "expand_dims", "(", "np", ".", "asarray", "(", "x2s", ")", ",", "-", "1", ")", "]", ",", "np", ".", "asarray", "(", "ys", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.data_stream.data": [[76, 81], ["data_stream.chunked_stream"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.data_stream.chunked_stream"], ["", "", "def", "data", "(", "ids", ")", ":", "\n", "# if X0_type=='rep':", "\n", "# \treps = pickle.load(open(REP_DATA_PATH+'reps.pickle','rb'))", "\n", "\t", "while", "True", ":", "\n", "\t\t", "yield", "from", "chunked_stream", "(", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.overlap": [[13, 31], ["None"], "function", ["None"], ["def", "overlap", "(", "target_box", ",", "candidate_box", ")", ":", "\n", "\n", "    ", "saved_x1", "=", "target_box", "[", "0", "]", "\n", "saved_y1", "=", "target_box", "[", "1", "]", "\n", "saved_x2", "=", "target_box", "[", "2", "]", "\n", "saved_y2", "=", "target_box", "[", "3", "]", "\n", "\n", "x1", "=", "candidate_box", "[", "0", "]", "\n", "y1", "=", "candidate_box", "[", "1", "]", "\n", "x2", "=", "candidate_box", "[", "2", "]", "\n", "y2", "=", "candidate_box", "[", "3", "]", "\n", "\n", "cond1", "=", "saved_x1", "<", "x1", "and", "x1", "<", "saved_x2", "\n", "cond2", "=", "saved_y1", "<", "y1", "and", "y1", "<", "saved_y2", "\n", "cond3", "=", "saved_x1", "<", "x2", "and", "x2", "<", "saved_x2", "\n", "cond4", "=", "saved_y1", "<", "y2", "and", "y2", "<", "saved_y2", "\n", "\n", "return", "(", "cond1", "or", "cond2", "or", "cond3", "or", "cond4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.edit_region": [[32, 51], ["max", "max", "max", "max", "max", "max", "max", "max"], "function", ["None"], ["", "def", "edit_region", "(", "height", ",", "width", ",", "x_coordinate", ",", "y_coordinate", ")", ":", "\n", "    ", "if", "(", "width", ">", "height", ")", ":", "\n", "# check if image recentering causes box to go off the image up", "\n", "        ", "if", "(", "y_coordinate", "+", "(", "height", "/", "2", ")", "-", "(", "width", "/", "2", ")", "<", "0.0", ")", ":", "\n", "            ", "box", "=", "(", "x_coordinate", ",", "y_coordinate", ",", "x_coordinate", "+", "max", "(", "width", ",", "height", ")", ",", "y_coordinate", "+", "max", "(", "width", ",", "height", ")", ")", "\n", "", "else", ":", "\n", "            ", "box", "=", "(", "x_coordinate", ",", "y_coordinate", "+", "(", "height", "/", "2", ")", "-", "(", "width", "/", "2", ")", ",", "x_coordinate", "+", "max", "(", "width", ",", "height", ")", ",", "y_coordinate", "+", "(", "height", "/", "2", ")", "-", "(", "width", "/", "2", ")", "+", "max", "(", "width", ",", "height", ")", ")", "\n", "", "", "else", ":", "\n", "# check if image recentering causes box to go off the image to the left", "\n", "        ", "if", "(", "x_coordinate", "+", "(", "width", "/", "2", ")", "-", "(", "height", "/", "2", ")", "<", "0.0", ")", ":", "\n", "            ", "box", "=", "(", "x_coordinate", ",", "y_coordinate", ",", "x_coordinate", "+", "max", "(", "width", ",", "height", ")", ",", "y_coordinate", "+", "max", "(", "width", ",", "height", ")", ")", "\n", "", "else", ":", "\n", "            ", "box", "=", "(", "x_coordinate", "+", "(", "width", "/", "2", ")", "-", "(", "height", "/", "2", ")", ",", "y_coordinate", ",", "x_coordinate", "+", "(", "width", "/", "2", ")", "-", "(", "height", "/", "2", ")", "+", "max", "(", "width", ",", "height", ")", ",", "y_coordinate", "+", "max", "(", "width", ",", "height", ")", ")", "\n", "\n", "", "", "return", "box", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.valid_item": [[55, 63], ["float", "os.path.isfile", "all", "float", "float", "len", "max", "min", "str"], "function", ["None"], ["", "def", "valid_item", "(", "height", ",", "width", ",", "sentence", ",", "img_id", ")", ":", "\n", "\n", "    ", "ratio", "=", "(", "(", "float", "(", "max", "(", "height", ",", "width", ")", ")", ")", "/", "float", "(", "min", "(", "height", ",", "width", ")", ")", ")", "\n", "size", "=", "float", "(", "height", ")", "\n", "file_exists", "=", "os", ".", "path", ".", "isfile", "(", "IMG_DATA_PATH", "+", "\"VG_100K/\"", "+", "str", "(", "img_id", ")", "+", "\".jpg\"", ")", "\n", "good_length", "=", "len", "(", "sentence", ")", "<", "max_sentence_length", "\n", "no_punctuation", "=", "all", "(", "(", "char", "in", "sym_set", ")", "for", "char", "in", "sentence", ")", "\n", "return", "ratio", "<", "1.25", "and", "size", ">", "100.0", "and", "file_exists", "and", "good_length", "and", "no_punctuation", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.get_img_from_id": [[64, 82], ["item.split", "PIL_Image.open", "PIL_Image.open.crop", "img.crop.resize"], "function", ["None"], ["", "def", "get_img_from_id", "(", "item", ",", "id_to_caption", ")", ":", "\n", "\n", "\n", "    ", "from", "PIL", "import", "Image", "as", "PIL_Image", "\n", "\n", "img_id", ",", "region_id", "=", "item", ".", "split", "(", "'_'", ")", "\n", "path", "=", "IMG_DATA_PATH", "+", "'VG_100K/'", "+", "img_id", "+", "\".jpg\"", "\n", "img", "=", "PIL_Image", ".", "open", "(", "path", ")", "\n", "#crop region from img", "\n", "box", "=", "id_to_caption", "[", "item", "]", "[", "region", "]", "\n", "# print(\"box\",box)", "\n", "cropped_img", "=", "img", ".", "crop", "(", "box", ")", "\n", "# print(\"cropped_img\", image.img_to_array(cropped_img))", "\n", "#resize into square", "\n", "resized_img", "=", "cropped_img", ".", "resize", "(", "[", "224", ",", "224", "]", ",", "PIL_Image", ".", "LANCZOS", ")", "\n", "\n", "\n", "return", "resized_img", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.get_rep_from_id": [[83, 106], ["item.split", "PIL_Image.open", "resnet().predict.crop", "img.crop.resize", "display", "numpy.expand_dims", "resnet().predict", "keras.preprocessing.image.img_to_array", "resnet"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.display"], ["", "def", "get_rep_from_id", "(", "item", ",", "id_to_caption", ")", ":", "\n", "\n", "    ", "from", "PIL", "import", "Image", "as", "PIL_Image", "\n", "from", "charpragcap", ".", "resources", ".", "models", ".", "resnet", "import", "resnet", "\n", "from", "keras", ".", "preprocessing", "import", "image", "\n", "\n", "img_id", ",", "region_id", "=", "item", ".", "split", "(", "'_'", ")", "\n", "path", "=", "IMG_DATA_PATH", "+", "'VG_100K/'", "+", "img_id", "+", "\".jpg\"", "\n", "img", "=", "PIL_Image", ".", "open", "(", "path", ")", "\n", "#crop region from img", "\n", "box", "=", "id_to_caption", "[", "item", "]", "[", "region", "]", "\n", "# print(\"box\",box)", "\n", "cropped_img", "=", "img", ".", "crop", "(", "box", ")", "\n", "# print(\"cropped_img\", image.img_to_array(cropped_img))", "\n", "#resize into square", "\n", "resized_img", "=", "cropped_img", ".", "resize", "(", "[", "224", ",", "224", "]", ",", "PIL_Image", ".", "ANTIALIAS", ")", "\n", "\n", "display", "(", "resized_img", ")", "\n", "\n", "img", "=", "np", ".", "expand_dims", "(", "image", ".", "img_to_array", "(", "resized_img", ")", ",", "0", ")", "\n", "\n", "img", "=", "resnet", "(", "img_rep_layer", ")", ".", "predict", "(", "img", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.get_rep_from_img_id": [[110, 125], ["PIL_Image.open", "resnet().predict.resize", "numpy.expand_dims", "resnet().predict", "keras.preprocessing.image.img_to_array", "resnet"], "function", ["None"], ["", "def", "get_rep_from_img_id", "(", "img_id", ")", ":", "\n", "\n", "    ", "from", "PIL", "import", "Image", "as", "PIL_Image", "\n", "import", "urllib", ".", "request", "\n", "from", "charpragcap", ".", "resources", ".", "models", ".", "resnet", "import", "resnet", "\n", "from", "keras", ".", "preprocessing", "import", "image", "\n", "\n", "path", "=", "IMG_DATA_PATH", "+", "'VG_100K/'", "+", "img_id", "+", "\".jpg\"", "\n", "img", "=", "PIL_Image", ".", "open", "(", "path", ")", "\n", "resized_img", "=", "img", ".", "resize", "(", "[", "224", ",", "224", "]", ",", "PIL_Image", ".", "ANTIALIAS", ")", "\n", "\n", "img", "=", "np", ".", "expand_dims", "(", "image", ".", "img_to_array", "(", "resized_img", ")", ",", "0", ")", "\n", "\n", "img", "=", "resnet", "(", "img_rep_layer", ")", ".", "predict", "(", "img", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.get_img_from_url": [[128, 144], ["requests.get", "PIL_Image.open", "open", "shutil.copyfileobj"], "function", ["None"], ["", "def", "get_img_from_url", "(", "url", ")", ":", "\n", "    ", "import", "urllib", ".", "request", "\n", "from", "charpragcap", ".", "resources", ".", "models", ".", "resnet", "import", "resnet", "\n", "from", "PIL", "import", "Image", "as", "PIL_Image", "\n", "import", "shutil", "\n", "import", "requests", "\n", "from", "keras", ".", "preprocessing", "import", "image", "\n", "from", "PIL", "import", "Image", "as", "PIL_Image", "\n", "response", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "\n", "with", "open", "(", "'charpragcap/resources/img.jpg'", ",", "'wb'", ")", "as", "out_file", ":", "\n", "        ", "shutil", ".", "copyfileobj", "(", "response", ".", "raw", ",", "out_file", ")", "\n", "", "del", "response", "\n", "\n", "img", "=", "PIL_Image", ".", "open", "(", "'charpragcap/resources/img.jpg'", ")", "\n", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.get_rep_from_url": [[158, 184], ["requests.get", "PIL_Image.open", "np.expand_dims.resize", "numpy.expand_dims", "model.predict", "open", "shutil.copyfileobj", "keras.preprocessing.image.img_to_array"], "function", ["None"], ["", "def", "get_rep_from_url", "(", "url", ",", "model", ")", ":", "\n", "    ", "import", "urllib", ".", "request", "\n", "from", "keras", ".", "preprocessing", "import", "image", "\n", "from", "PIL", "import", "Image", "as", "PIL_Image", "\n", "import", "shutil", "\n", "import", "requests", "\n", "from", "keras", ".", "preprocessing", "import", "image", "\n", "from", "PIL", "import", "Image", "as", "PIL_Image", "\n", "response", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "\n", "with", "open", "(", "'charpragcap/resources/img.jpg'", ",", "'wb'", ")", "as", "out_file", ":", "\n", "        ", "shutil", ".", "copyfileobj", "(", "response", ".", "raw", ",", "out_file", ")", "\n", "", "del", "response", "\n", "\n", "img", "=", "PIL_Image", ".", "open", "(", "'charpragcap/resources/img.jpg'", ")", "\n", "\n", "\n", "# file_name = \"charpragcap/resources/local-filename.jpg\"", "\n", "# urllib.request.urlretrieve(url, file_name)", "\n", "# img = PIL_Image.open(file_name)", "\n", "\n", "img", "=", "img", ".", "resize", "(", "[", "224", ",", "224", "]", ",", "PIL_Image", ".", "ANTIALIAS", ")", "\n", "# display(img)", "\n", "img", "=", "np", ".", "expand_dims", "(", "image", ".", "img_to_array", "(", "img", ")", ",", "0", ")", "\n", "\n", "rep", "=", "model", ".", "predict", "(", "img", ")", "\n", "return", "rep", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.display_image": [[186, 202], ["pickle.load", "chosen_id.split", "PIL_Image.open", "display", "PIL_Image.open.crop", "region.resize.resize", "display", "open", "list", "str", "str"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.display", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.display"], ["", "def", "display_image", "(", "number", ")", ":", "\n", "\n", "    ", "import", "pickle", "\n", "from", "PIL", "import", "Image", "as", "PIL_Image", "\n", "\n", "id_to_caption", "=", "pickle", ".", "load", "(", "open", "(", "\"charpragcap/resources/id_to_caption\"", ",", "'rb'", ")", ")", "\n", "chosen_id", "=", "list", "(", "id_to_caption", ")", "[", "number", "]", "\n", "\n", "img_path", "=", "\"data/VG_100K/\"", "+", "str", "(", "chosen_id", ")", "+", "\".jpg\"", "\n", "box", "=", "id_to_caption", "[", "chosen_id", "]", "[", "1", "]", "\n", "img_id", ",", "region_id", "=", "chosen_id", ".", "split", "(", "\"_\"", ")", "\n", "img", "=", "PIL_Image", ".", "open", "(", "IMG_DATA_PATH", "+", "\"VG_100K/\"", "+", "str", "(", "img_id", ")", "+", "\".jpg\"", ")", "\n", "display", "(", "img", ")", "\n", "region", "=", "img", ".", "crop", "(", "box", ")", "\n", "region", "=", "region", ".", "resize", "(", "[", "224", ",", "224", "]", ",", "PIL_Image", ".", "ANTIALIAS", ")", "\n", "display", "(", "region", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.display_img_from_url": [[203, 215], ["requests.get", "PIL_Image.open", "img.resize.resize", "display", "open", "shutil.copyfileobj"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.display"], ["", "def", "display_img_from_url", "(", "url", ")", ":", "\n", "    ", "import", "shutil", "\n", "import", "requests", "\n", "from", "keras", ".", "preprocessing", "import", "image", "\n", "from", "PIL", "import", "Image", "as", "PIL_Image", "\n", "response", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "\n", "with", "open", "(", "'charpragcap/resources/img.jpg'", ",", "'wb'", ")", "as", "out_file", ":", "\n", "        ", "shutil", ".", "copyfileobj", "(", "response", ".", "raw", ",", "out_file", ")", "\n", "", "del", "response", "\n", "img", "=", "PIL_Image", ".", "open", "(", "'charpragcap/resources/img.jpg'", ")", "\n", "img", "=", "img", ".", "resize", "(", "[", "224", ",", "224", "]", ",", "PIL_Image", ".", "ANTIALIAS", ")", "\n", "display", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.get_img": [[216, 236], ["requests.get", "PIL_Image.open", "img.resize.resize", "display", "numpy.expand_dims", "resnet().predict", "open", "shutil.copyfileobj", "keras.preprocessing.image.img_to_array", "resnet"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.display"], ["", "def", "get_img", "(", "url", ")", ":", "\n", "    ", "import", "shutil", "\n", "import", "requests", "\n", "from", "keras", ".", "preprocessing", "import", "image", "\n", "from", "PIL", "import", "Image", "as", "PIL_Image", "\n", "from", "charpragcap", ".", "resources", ".", "models", ".", "resnet", "import", "resnet", "\n", "from", "charpragcap", ".", "utils", ".", "config", "import", "img_rep_layer", "\n", "\n", "\n", "response", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "\n", "with", "open", "(", "'charpragcap/resources/img.jpg'", ",", "'wb'", ")", "as", "out_file", ":", "\n", "        ", "shutil", ".", "copyfileobj", "(", "response", ".", "raw", ",", "out_file", ")", "\n", "", "del", "response", "\n", "img", "=", "PIL_Image", ".", "open", "(", "'charpragcap/resources/img.jpg'", ")", "\n", "img", "=", "img", ".", "resize", "(", "[", "224", ",", "224", "]", ",", "PIL_Image", ".", "ANTIALIAS", ")", "\n", "display", "(", "img", ")", "\n", "rep", "=", "np", ".", "expand_dims", "(", "image", ".", "img_to_array", "(", "img", ")", ",", "0", ")", "\n", "\n", "rep", "=", "resnet", "(", "img_rep_layer", ")", ".", "predict", "(", "img", ")", "\n", "return", "rep", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.item_to_rep": [[237, 246], ["image_and_text_utils.get_img_from_id", "numpy.expand_dims", "resnet().predict", "keras.preprocessing.image.img_to_array", "resnet"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.get_img_from_id"], ["", "def", "item_to_rep", "(", "item", ",", "id_to_caption", ")", ":", "\n", "    ", "import", "numpy", "as", "np", "\n", "from", "charpragcap", ".", "resources", ".", "models", ".", "resnet", "import", "resnet", "\n", "from", "keras", ".", "preprocessing", "import", "image", "\n", "\n", "original_image", "=", "get_img_from_id", "(", "item", ",", "id_to_caption", ")", "\n", "original_image_vector", "=", "np", ".", "expand_dims", "(", "image", ".", "img_to_array", "(", "original_image", ")", ",", "axis", "=", "0", ")", "\n", "input_image", "=", "resnet", "(", "img_rep_layer", ")", ".", "predict", "(", "original_image_vector", ")", "\n", "return", "input_image", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.vectorize_caption": [[250, 266], ["list", "numpy.asarray", "numpy.expand_dims", "numpy.zeros", "len", "list.append", "numpy.asarray", "len", "list", "len", "numpy.arange"], "function", ["None"], ["", "def", "vectorize_caption", "(", "sentence", ")", ":", "\n", "    ", "if", "len", "(", "sentence", ")", ">", "0", "and", "sentence", "[", "-", "1", "]", "in", "list", "(", "\"!?.\"", ")", ":", "\n", "        ", "sentence", "=", "sentence", "[", ":", "-", "1", "]", "\n", "", "sentence", "=", "start_token", "[", "\"char\"", "]", "+", "sentence", "+", "stop_token", "[", "\"char\"", "]", "\n", "sentence", "=", "list", "(", "sentence", ")", "\n", "while", "len", "(", "sentence", ")", "<", "max_sentence_length", "+", "2", ":", "\n", "        ", "sentence", ".", "append", "(", "pad_token", ")", "\n", "\n", "", "caption_in", "=", "sentence", "[", ":", "-", "1", "]", "\n", "caption_out", "=", "sentence", "[", "1", ":", "]", "\n", "caption_in", "=", "np", ".", "asarray", "(", "[", "char_to_index", "[", "x", "]", "for", "x", "in", "caption_in", "]", ")", "\n", "caption_out", "=", "np", ".", "expand_dims", "(", "np", ".", "asarray", "(", "[", "char_to_index", "[", "x", "]", "for", "x", "in", "caption_out", "]", ")", ",", "0", ")", "\n", "one_hot", "=", "np", ".", "zeros", "(", "(", "caption_out", ".", "shape", "[", "1", "]", ",", "len", "(", "sym_set", ")", ")", ")", "\n", "one_hot", "[", "np", ".", "arange", "(", "caption_out", ".", "shape", "[", "1", "]", ")", ",", "caption_out", "]", "=", "1", "\n", "caption_out", "=", "one_hot", "\n", "return", "caption_in", ",", "caption_out", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.devectorize_caption": [[268, 271], ["numpy.squeeze"], "function", ["None"], ["", "def", "devectorize_caption", "(", "ary", ")", ":", "\n", "# print(\"ARY\",ary.shape,ary)", "\n", "    ", "return", "\"\"", ".", "join", "(", "[", "index_to_char", "[", "idx", "]", "for", "idx", "in", "np", ".", "squeeze", "(", "ary", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.sentence_likelihood": [[274, 279], ["text_to_vecs", "s_zero.predict", "enumerate"], "function", ["None"], ["", "def", "sentence_likelihood", "(", "img", ",", "sent", ")", ":", "\n", "    ", "sentence", "=", "text_to_vecs", "(", "sent", ",", "words", "=", "True", ")", "\n", "# print(sentence.shape,img.shape)", "\n", "probs", "=", "s_zero", ".", "predict", "(", "[", "img", ",", "sentence", "]", ")", "\n", "probs", "=", "[", "x", "[", "word_to_index", "[", "sent", "[", "i", "+", "1", "]", "]", "]", "for", "i", ",", "x", "in", "enumerate", "(", "probs", "[", "0", "]", "[", ":", "-", "1", "]", ")", "]", "\n", "# print(np.sum(np.log(probs)))", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.largest_indices": [[281, 286], ["ary.flatten", "numpy.unravel_index", "numpy.argpartition", "numpy.argsort"], "function", ["None"], ["", "def", "largest_indices", "(", "self", ",", "ary", ",", "n", ")", ":", "\n", "    ", "flat", "=", "ary", ".", "flatten", "(", ")", "\n", "indices", "=", "np", ".", "argpartition", "(", "flat", ",", "-", "n", ")", "[", "-", "n", ":", "]", "\n", "indices", "=", "indices", "[", "np", ".", "argsort", "(", "-", "flat", "[", "indices", "]", ")", "]", "\n", "return", "np", ".", "unravel_index", "(", "indices", ",", "ary", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.split_dataset": [[290, 305], ["pickle.load", "sorted", "len", "int", "open", "list", "int", "int"], "function", ["None"], ["", "def", "split_dataset", "(", "trains", "=", "train_size", ",", "vals", "=", "val_size", ",", "tests", "=", "test_size", ")", ":", "\n", "\n", "    ", "import", "pickle", "\n", "id_to_caption", "=", "pickle", ".", "load", "(", "open", "(", "\"charpragcap/resources/id_to_caption\"", ",", "'rb'", ")", ")", "\n", "\n", "ids", "=", "sorted", "(", "list", "(", "id_to_caption", ")", ")", "\n", "num_ids", "=", "(", "len", "(", "ids", ")", ")", "\n", "assert", "trains", "+", "vals", "+", "tests", "==", "1.0", "\n", "\n", "num_train", "=", "int", "(", "num_ids", "*", "trains", ")", "\n", "num_val", "=", "num_train", "+", "int", "(", "num_ids", "*", "vals", ")", "\n", "num_test", "=", "num_val", "+", "int", "(", "num_ids", "*", "tests", ")", "\n", "\n", "trains", ",", "vals", ",", "tests", "=", "ids", "[", "0", ":", "num_train", "]", ",", "ids", "[", "num_train", ":", "num_val", "]", ",", "ids", "[", "num_val", ":", "num_test", "]", "\n", "return", "trains", ",", "vals", ",", "tests", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.generate_clusters.cap_to_words": [[8, 10], ["re.sub().split", "nltk.corpus.stopwords.words", "re.sub", "charpragcap.utils.image_and_text_utils.devectorize_caption"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.image_and_text_utils.devectorize_caption"], ["def", "cap_to_words", "(", "cap", ")", ":", "\n", "\t", "return", "[", "word", "for", "word", "in", "re", ".", "sub", "(", "'[^a-z ]'", ",", "\"\"", ",", "devectorize_caption", "(", "cap", ")", ")", ".", "split", "(", ")", "if", "word", "not", "in", "stopwords", ".", "words", "(", "'english'", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.build_vocab.Vocabulary.__init__": [[10, 14], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "word2idx", "=", "{", "}", "\n", "self", ".", "idx2word", "=", "{", "}", "\n", "self", ".", "idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.build_vocab.Vocabulary.add_word": [[15, 20], ["None"], "methods", ["None"], ["", "def", "add_word", "(", "self", ",", "word", ")", ":", "\n", "        ", "if", "not", "word", "in", "self", ".", "word2idx", ":", "\n", "            ", "self", ".", "word2idx", "[", "word", "]", "=", "self", ".", "idx", "\n", "self", ".", "idx2word", "[", "self", ".", "idx", "]", "=", "word", "\n", "self", ".", "idx", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.build_vocab.Vocabulary.__call__": [[21, 25], ["None"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "word", ")", ":", "\n", "        ", "if", "not", "word", "in", "self", ".", "word2idx", ":", "\n", "            ", "return", "self", ".", "word2idx", "[", "'<unk>'", "]", "\n", "", "return", "self", ".", "word2idx", "[", "word", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.build_vocab.Vocabulary.__len__": [[26, 28], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "word2idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.build_vocab.build_vocab": [[29, 56], ["COCO", "collections.Counter", "COCO.anns.keys", "enumerate", "build_vocab.Vocabulary", "build_vocab.Vocabulary.add_word", "build_vocab.Vocabulary.add_word", "build_vocab.Vocabulary.add_word", "build_vocab.Vocabulary.add_word", "enumerate", "str", "nltk.tokenize.word_tokenize", "collections.Counter.update", "build_vocab.Vocabulary.add_word", "str.lower", "print", "collections.Counter.items", "len"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.build_vocab.Vocabulary.add_word", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.build_vocab.Vocabulary.add_word", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.build_vocab.Vocabulary.add_word", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.build_vocab.Vocabulary.add_word", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.build_vocab.Vocabulary.add_word"], ["", "", "def", "build_vocab", "(", "json", ",", "threshold", ")", ":", "\n", "    ", "\"\"\"Build a simple vocabulary wrapper.\"\"\"", "\n", "coco", "=", "COCO", "(", "json", ")", "\n", "counter", "=", "Counter", "(", ")", "\n", "ids", "=", "coco", ".", "anns", ".", "keys", "(", ")", "\n", "for", "i", ",", "id", "in", "enumerate", "(", "ids", ")", ":", "\n", "        ", "caption", "=", "str", "(", "coco", ".", "anns", "[", "id", "]", "[", "'caption'", "]", ")", "\n", "tokens", "=", "nltk", ".", "tokenize", ".", "word_tokenize", "(", "caption", ".", "lower", "(", ")", ")", "\n", "counter", ".", "update", "(", "tokens", ")", "\n", "\n", "if", "i", "%", "1000", "==", "0", ":", "\n", "            ", "print", "(", "\"[%d/%d] Tokenized the captions.\"", "%", "(", "i", ",", "len", "(", "ids", ")", ")", ")", "\n", "\n", "# If the word frequency is less than 'threshold', then the word is discarded.", "\n", "", "", "words", "=", "[", "word", "for", "word", ",", "cnt", "in", "counter", ".", "items", "(", ")", "if", "cnt", ">=", "threshold", "]", "\n", "\n", "# Creates a vocab wrapper and add some special tokens.", "\n", "vocab", "=", "Vocabulary", "(", ")", "\n", "vocab", ".", "add_word", "(", "'<pad>'", ")", "\n", "vocab", ".", "add_word", "(", "'<start>'", ")", "\n", "vocab", ".", "add_word", "(", "'<end>'", ")", "\n", "vocab", ".", "add_word", "(", "'<unk>'", ")", "\n", "\n", "# Adds the words to the vocabulary.", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "        ", "vocab", ".", "add_word", "(", "word", ")", "\n", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.build_vocab.main": [[57, 65], ["build_vocab.build_vocab", "print", "print", "open", "pickle.dump", "len"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.build_vocab.build_vocab"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "vocab", "=", "build_vocab", "(", "json", "=", "args", ".", "caption_path", ",", "\n", "threshold", "=", "args", ".", "threshold", ")", "\n", "vocab_path", "=", "args", ".", "vocab_path", "\n", "with", "open", "(", "vocab_path", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "vocab", ",", "f", ")", "\n", "", "print", "(", "\"Total vocabulary size: %d\"", "%", "len", "(", "vocab", ")", ")", "\n", "print", "(", "\"Saved the vocabulary wrapper to '%s'\"", "%", "vocab_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.imagenet_utils.preprocess_input": [[12, 30], ["keras.backend.image_dim_ordering"], "function", ["None"], ["def", "preprocess_input", "(", "x", ",", "dim_ordering", "=", "'default'", ")", ":", "\n", "    ", "if", "dim_ordering", "==", "'default'", ":", "\n", "        ", "dim_ordering", "=", "K", ".", "image_dim_ordering", "(", ")", "\n", "", "assert", "dim_ordering", "in", "{", "'tf'", ",", "'th'", "}", "\n", "\n", "if", "dim_ordering", "==", "'th'", ":", "\n", "        ", "x", "[", ":", ",", "0", ",", ":", ",", ":", "]", "-=", "103.939", "\n", "x", "[", ":", ",", "1", ",", ":", ",", ":", "]", "-=", "116.779", "\n", "x", "[", ":", ",", "2", ",", ":", ",", ":", "]", "-=", "123.68", "\n", "# 'RGB'->'BGR'", "\n", "x", "=", "x", "[", ":", ",", ":", ":", "-", "1", ",", ":", ",", ":", "]", "\n", "", "else", ":", "\n", "        ", "x", "[", ":", ",", ":", ",", ":", ",", "0", "]", "-=", "103.939", "\n", "x", "[", ":", ",", ":", ",", ":", ",", "1", "]", "-=", "116.779", "\n", "x", "[", ":", ",", ":", ",", ":", ",", "2", "]", "-=", "123.68", "\n", "# 'RGB'->'BGR'", "\n", "x", "=", "x", "[", ":", ",", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.imagenet_utils.decode_predictions": [[32, 50], ["ValueError", "keras.utils.data_utils.get_file", "json.load", "results.append", "len", "open", "str", "pred.argsort", "tuple", "str"], "function", ["None"], ["", "def", "decode_predictions", "(", "preds", ",", "top", "=", "5", ")", ":", "\n", "    ", "global", "CLASS_INDEX", "\n", "if", "len", "(", "preds", ".", "shape", ")", "!=", "2", "or", "preds", ".", "shape", "[", "1", "]", "!=", "1000", ":", "\n", "        ", "raise", "ValueError", "(", "'`decode_predictions` expects '", "\n", "'a batch of predictions '", "\n", "'(i.e. a 2D array of shape (samples, 1000)). '", "\n", "'Found array with shape: '", "+", "str", "(", "preds", ".", "shape", ")", ")", "\n", "", "if", "CLASS_INDEX", "is", "None", ":", "\n", "        ", "fpath", "=", "get_file", "(", "'imagenet_class_index.json'", ",", "\n", "CLASS_INDEX_PATH", ",", "\n", "cache_subdir", "=", "'models'", ")", "\n", "CLASS_INDEX", "=", "json", ".", "load", "(", "open", "(", "fpath", ")", ")", "\n", "", "results", "=", "[", "]", "\n", "for", "pred", "in", "preds", ":", "\n", "        ", "top_indices", "=", "pred", ".", "argsort", "(", ")", "[", "-", "top", ":", "]", "[", ":", ":", "-", "1", "]", "\n", "result", "=", "[", "tuple", "(", "CLASS_INDEX", "[", "str", "(", "i", ")", "]", ")", "+", "(", "pred", "[", "i", "]", ",", ")", "for", "i", "in", "top_indices", "]", "\n", "results", ".", "append", "(", "result", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator.__init__": [[17, 50], ["tgt_dict.pad", "tgt_dict.unk", "tgt_dict.eos", "len", "min", "min", "m.max_decoder_positions"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "models", ",", "tgt_dict", ",", "beam_size", "=", "1", ",", "minlen", "=", "1", ",", "maxlen", "=", "None", ",", "stop_early", "=", "True", ",", "\n", "normalize_scores", "=", "True", ",", "len_penalty", "=", "1", ",", "unk_penalty", "=", "0", ",", "retain_dropout", "=", "False", ",", "\n", "sampling", "=", "False", ",", "sampling_topk", "=", "-", "1", ",", "sampling_temperature", "=", "1", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Generates translations of a given source sentence.\n        Args:\n            min/maxlen: The length of the generated output will be bounded by\n                minlen and maxlen (not including the end-of-sentence marker).\n            stop_early: Stop generation immediately after we finalize beam_size\n                hypotheses, even though longer hypotheses might have better\n                normalized scores.\n            normalize_scores: Normalize scores by the length of the output.\n        \"\"\"", "\n", "self", ".", "models", "=", "models", "\n", "self", ".", "pad", "=", "tgt_dict", ".", "pad", "(", ")", "\n", "self", ".", "unk", "=", "tgt_dict", ".", "unk", "(", ")", "\n", "self", ".", "eos", "=", "tgt_dict", ".", "eos", "(", ")", "\n", "self", ".", "tgt_dict", "=", "tgt_dict", "\n", "self", ".", "vocab_size", "=", "len", "(", "tgt_dict", ")", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "self", ".", "minlen", "=", "minlen", "\n", "max_decoder_len", "=", "min", "(", "m", ".", "max_decoder_positions", "(", ")", "for", "m", "in", "self", ".", "models", ")", "\n", "max_decoder_len", "-=", "1", "# we define maxlen not including the EOS marker", "\n", "self", ".", "maxlen", "=", "max_decoder_len", "if", "maxlen", "is", "None", "else", "min", "(", "maxlen", ",", "max_decoder_len", ")", "\n", "self", ".", "stop_early", "=", "stop_early", "\n", "self", ".", "normalize_scores", "=", "normalize_scores", "\n", "self", ".", "len_penalty", "=", "len_penalty", "\n", "self", ".", "unk_penalty", "=", "unk_penalty", "\n", "self", ".", "retain_dropout", "=", "retain_dropout", "\n", "self", ".", "sampling", "=", "sampling", "\n", "self", ".", "sampling_topk", "=", "sampling_topk", "\n", "self", ".", "sampling_temperature", "=", "sampling_temperature", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator.cuda": [[51, 55], ["model.cuda"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator.cuda"], ["", "def", "cuda", "(", "self", ")", ":", "\n", "        ", "for", "model", "in", "self", ".", "models", ":", "\n", "            ", "model", ".", "cuda", "(", ")", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator.generate_batched_itr": [[56, 93], ["input[].size", "enumerate", "fairseq.utils.move_to_cuda", "timer.start", "torch.no_grad", "seqgen.SequenceGenerator.generate", "timer.stop", "fairseq.utils.strip_pad", "sum", "fairseq.utils.strip_pad", "int", "len"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator.generate"], ["", "def", "generate_batched_itr", "(", "\n", "self", ",", "data_itr", ",", "beam_size", "=", "None", ",", "maxlen_a", "=", "0.0", ",", "maxlen_b", "=", "None", ",", "\n", "cuda", "=", "False", ",", "timer", "=", "None", ",", "prefix_size", "=", "0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Iterate over a batched dataset and yield individual translations.\n        Args:\n            maxlen_a/b: generate sequences of maximum length ax + b,\n                where x is the source sentence length.\n            cuda: use GPU for generation\n            timer: StopwatchMeter for timing generations.\n        \"\"\"", "\n", "if", "maxlen_b", "is", "None", ":", "\n", "            ", "maxlen_b", "=", "self", ".", "maxlen", "\n", "\n", "", "for", "sample", "in", "data_itr", ":", "\n", "            ", "s", "=", "utils", ".", "move_to_cuda", "(", "sample", ")", "if", "cuda", "else", "sample", "\n", "if", "'net_input'", "not", "in", "s", ":", "\n", "                ", "continue", "\n", "", "input", "=", "s", "[", "'net_input'", "]", "\n", "srclen", "=", "input", "[", "'src_tokens'", "]", ".", "size", "(", "1", ")", "\n", "if", "timer", "is", "not", "None", ":", "\n", "                ", "timer", ".", "start", "(", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "hypos", "=", "self", ".", "generate", "(", "\n", "input", "[", "'src_tokens'", "]", ",", "\n", "input", "[", "'src_lengths'", "]", ",", "\n", "beam_size", "=", "beam_size", ",", "\n", "maxlen", "=", "int", "(", "maxlen_a", "*", "srclen", "+", "maxlen_b", ")", ",", "\n", "prefix_tokens", "=", "s", "[", "'target'", "]", "[", ":", ",", ":", "prefix_size", "]", "if", "prefix_size", ">", "0", "else", "None", ",", "\n", ")", "\n", "", "if", "timer", "is", "not", "None", ":", "\n", "                ", "timer", ".", "stop", "(", "sum", "(", "len", "(", "h", "[", "0", "]", "[", "'tokens'", "]", ")", "for", "h", "in", "hypos", ")", ")", "\n", "", "for", "i", ",", "id", "in", "enumerate", "(", "s", "[", "'id'", "]", ".", "data", ")", ":", "\n", "# remove padding", "\n", "                ", "src", "=", "utils", ".", "strip_pad", "(", "input", "[", "'src_tokens'", "]", ".", "data", "[", "i", ",", ":", "]", ",", "self", ".", "pad", ")", "\n", "ref", "=", "utils", ".", "strip_pad", "(", "s", "[", "'target'", "]", ".", "data", "[", "i", ",", ":", "]", ",", "self", ".", "pad", ")", "if", "s", "[", "'target'", "]", "is", "not", "None", "else", "None", "\n", "yield", "id", ",", "src", ",", "ref", ",", "hypos", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator.generate": [[94, 112], ["torch.no_grad", "seqgen.SequenceGenerator._generate_single_step", "torch.ones", "enumerate", "torch.ones.type", "len", "seqgen.SequenceGenerator.tgt_dict.index"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator._generate_single_step"], ["", "", "", "def", "generate", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "beam_size", "=", "None", ",", "maxlen", "=", "None", ",", "prefix_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\"Generate a batch of translations.\"\"\"", "\n", "# with torch.no_grad():", "\n", "#     print(self._generate(src_tokens, src_lengths, beam_size, maxlen, None))", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# foo = src_tokens.clone()", "\n", "# foo[:,:]=10", "\n", "# foo[:,0]=self.tgt_dict.index('</s>')", "\n", "# print(\"index\",self.tgt_dict.index('</s>'))", "\n", "# print(foo.type(torch.LongTensor))", "\n", "# print(\"src tokens\",src_tokens)", "\n", "            ", "bar", "=", "None", "\n", "if", "prefix_tokens", ":", "\n", "                ", "foo", "=", "torch", ".", "ones", "(", "1", ",", "len", "(", "prefix_tokens", ")", ")", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "prefix_tokens", ")", ":", "\n", "                    ", "foo", "[", ":", ",", "i", "]", "=", "self", ".", "tgt_dict", ".", "index", "(", "t", ")", "\n", "", "bar", "=", "foo", ".", "type", "(", "torch", ".", "LongTensor", ")", "\n", "", "return", "self", ".", "_generate_single_step", "(", "src_tokens", ",", "src_lengths", ",", "beam_size", ",", "maxlen", ",", "prefix_tokens", "=", "bar", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator._generate": [[120, 530], ["src_tokens.size", "min", "src_tokens.data.new().float().fill_", "[].view.clone", "src_tokens.data.new().fill_", "[].view.clone", "[].view.new", "[].view.new.clone", "torch.arange().type_as", "range", "range", "min", "isinstance", "model.encoder", "encoder_outs.append", "src_tokens.size", "[].view.index_select", "set", "enumerate", "seqgen.SequenceGenerator._decode", "seqgen.SequenceGenerator._generate.buffer"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator._decode"], ["", "", "def", "_generate", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "beam_size", "=", "None", ",", "maxlen", "=", "None", ",", "prefix_tokens", "=", "None", ")", ":", "\n", "        ", "bsz", ",", "srclen", "=", "src_tokens", ".", "size", "(", ")", "\n", "maxlen", "=", "min", "(", "maxlen", ",", "self", ".", "maxlen", ")", "if", "maxlen", "is", "not", "None", "else", "self", ".", "maxlen", "\n", "\n", "# the max beam size is the dictionary size - 1, since we never select pad", "\n", "beam_size", "=", "beam_size", "if", "beam_size", "is", "not", "None", "else", "self", ".", "beam_size", "\n", "beam_size", "=", "min", "(", "beam_size", ",", "self", ".", "vocab_size", "-", "1", ")", "\n", "\n", "encoder_outs", "=", "[", "]", "\n", "incremental_states", "=", "{", "}", "\n", "for", "model", "in", "self", ".", "models", ":", "\n", "            ", "if", "not", "self", ".", "retain_dropout", ":", "\n", "                ", "model", ".", "eval", "(", ")", "\n", "", "if", "isinstance", "(", "model", ".", "decoder", ",", "FairseqIncrementalDecoder", ")", ":", "\n", "                ", "incremental_states", "[", "model", "]", "=", "{", "}", "\n", "", "else", ":", "\n", "                ", "incremental_states", "[", "model", "]", "=", "None", "\n", "\n", "# compute the encoder output for each beam", "\n", "", "encoder_out", "=", "model", ".", "encoder", "(", "\n", "src_tokens", ".", "repeat", "(", "1", ",", "beam_size", ")", ".", "view", "(", "-", "1", ",", "srclen", ")", ",", "\n", "src_lengths", ".", "expand", "(", "beam_size", ",", "src_lengths", ".", "numel", "(", ")", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ",", "\n", ")", "\n", "encoder_outs", ".", "append", "(", "encoder_out", ")", "\n", "\n", "# initialize buffers", "\n", "", "scores", "=", "src_tokens", ".", "data", ".", "new", "(", "bsz", "*", "beam_size", ",", "maxlen", "+", "1", ")", ".", "float", "(", ")", ".", "fill_", "(", "0", ")", "\n", "scores_buf", "=", "scores", ".", "clone", "(", ")", "\n", "tokens", "=", "src_tokens", ".", "data", ".", "new", "(", "bsz", "*", "beam_size", ",", "maxlen", "+", "2", ")", ".", "fill_", "(", "self", ".", "pad", ")", "\n", "tokens_buf", "=", "tokens", ".", "clone", "(", ")", "\n", "tokens", "[", ":", ",", "0", "]", "=", "self", ".", "eos", "\n", "attn", "=", "scores", ".", "new", "(", "bsz", "*", "beam_size", ",", "src_tokens", ".", "size", "(", "1", ")", ",", "maxlen", "+", "2", ")", "\n", "attn_buf", "=", "attn", ".", "clone", "(", ")", "\n", "\n", "# list of completed sentences", "\n", "finalized", "=", "[", "[", "]", "for", "i", "in", "range", "(", "bsz", ")", "]", "\n", "finished", "=", "[", "False", "for", "i", "in", "range", "(", "bsz", ")", "]", "\n", "worst_finalized", "=", "[", "{", "'idx'", ":", "None", ",", "'score'", ":", "-", "math", ".", "inf", "}", "for", "i", "in", "range", "(", "bsz", ")", "]", "\n", "num_remaining_sent", "=", "bsz", "\n", "\n", "# number of candidate hypos per step", "\n", "cand_size", "=", "2", "*", "beam_size", "# 2 x beam size in case half are EOS", "\n", "\n", "# offset arrays for converting between different indexing schemes", "\n", "bbsz_offsets", "=", "(", "torch", ".", "arange", "(", "0", ",", "bsz", ")", "*", "beam_size", ")", ".", "unsqueeze", "(", "1", ")", ".", "type_as", "(", "tokens", ")", "\n", "cand_offsets", "=", "torch", ".", "arange", "(", "0", ",", "cand_size", ")", ".", "type_as", "(", "tokens", ")", "\n", "\n", "# helper function for allocating buffers on the fly", "\n", "buffers", "=", "{", "}", "\n", "\n", "def", "buffer", "(", "name", ",", "type_of", "=", "tokens", ")", ":", "# noqa", "\n", "            ", "if", "name", "not", "in", "buffers", ":", "\n", "                ", "buffers", "[", "name", "]", "=", "type_of", ".", "new", "(", ")", "\n", "", "return", "buffers", "[", "name", "]", "\n", "\n", "", "def", "is_finished", "(", "sent", ",", "step", ",", "unfinalized_scores", "=", "None", ")", ":", "\n", "            ", "\"\"\"\n            Check whether we've finished generation for a given sentence, by\n            comparing the worst score among finalized hypotheses to the best\n            possible score among unfinalized hypotheses.\n            \"\"\"", "\n", "assert", "len", "(", "finalized", "[", "sent", "]", ")", "<=", "beam_size", "\n", "if", "len", "(", "finalized", "[", "sent", "]", ")", "==", "beam_size", ":", "\n", "                ", "if", "self", ".", "stop_early", "or", "step", "==", "maxlen", "or", "unfinalized_scores", "is", "None", ":", "\n", "                    ", "return", "True", "\n", "# stop if the best unfinalized score is worse than the worst", "\n", "# finalized one", "\n", "", "best_unfinalized_score", "=", "unfinalized_scores", "[", "sent", "]", ".", "max", "(", ")", "\n", "if", "self", ".", "normalize_scores", ":", "\n", "                    ", "best_unfinalized_score", "/=", "maxlen", "**", "self", ".", "len_penalty", "\n", "", "if", "worst_finalized", "[", "sent", "]", "[", "'score'", "]", ">=", "best_unfinalized_score", ":", "\n", "                    ", "return", "True", "\n", "", "", "return", "False", "\n", "\n", "", "def", "finalize_hypos", "(", "step", ",", "bbsz_idx", ",", "eos_scores", ",", "unfinalized_scores", "=", "None", ")", ":", "\n", "            ", "\"\"\"\n            Finalize the given hypotheses at this step, while keeping the total\n            number of finalized hypotheses per sentence <= beam_size.\n            Note: the input must be in the desired finalization order, so that\n            hypotheses that appear earlier in the input are preferred to those\n            that appear later.\n            Args:\n                step: current time step\n                bbsz_idx: A vector of indices in the range [0, bsz*beam_size),\n                    indicating which hypotheses to finalize\n                eos_scores: A vector of the same size as bbsz_idx containing\n                    scores for each hypothesis\n                unfinalized_scores: A vector containing scores for all\n                    unfinalized hypotheses\n            \"\"\"", "\n", "assert", "bbsz_idx", ".", "numel", "(", ")", "==", "eos_scores", ".", "numel", "(", ")", "\n", "\n", "# clone relevant token and attention tensors", "\n", "tokens_clone", "=", "tokens", ".", "index_select", "(", "0", ",", "bbsz_idx", ")", "\n", "tokens_clone", "=", "tokens_clone", "[", ":", ",", "1", ":", "step", "+", "2", "]", "# skip the first index, which is EOS", "\n", "tokens_clone", "[", ":", ",", "step", "]", "=", "self", ".", "eos", "\n", "attn_clone", "=", "attn", ".", "index_select", "(", "0", ",", "bbsz_idx", ")", "[", ":", ",", ":", ",", "1", ":", "step", "+", "2", "]", "\n", "\n", "# compute scores per token position", "\n", "pos_scores", "=", "scores", ".", "index_select", "(", "0", ",", "bbsz_idx", ")", "[", ":", ",", ":", "step", "+", "1", "]", "\n", "pos_scores", "[", ":", ",", "step", "]", "=", "eos_scores", "\n", "# convert from cumulative to per-position scores", "\n", "pos_scores", "[", ":", ",", "1", ":", "]", "=", "pos_scores", "[", ":", ",", "1", ":", "]", "-", "pos_scores", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "# normalize sentence-level scores", "\n", "if", "self", ".", "normalize_scores", ":", "\n", "                ", "eos_scores", "/=", "(", "step", "+", "1", ")", "**", "self", ".", "len_penalty", "\n", "\n", "", "cum_unfin", "=", "[", "]", "\n", "prev", "=", "0", "\n", "for", "f", "in", "finished", ":", "\n", "                ", "if", "f", ":", "\n", "                    ", "prev", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "cum_unfin", ".", "append", "(", "prev", ")", "\n", "\n", "", "", "sents_seen", "=", "set", "(", ")", "\n", "for", "i", ",", "(", "idx", ",", "score", ")", "in", "enumerate", "(", "zip", "(", "bbsz_idx", ".", "tolist", "(", ")", ",", "eos_scores", ".", "tolist", "(", ")", ")", ")", ":", "\n", "                ", "unfin_idx", "=", "idx", "//", "beam_size", "\n", "sent", "=", "unfin_idx", "+", "cum_unfin", "[", "unfin_idx", "]", "\n", "\n", "sents_seen", ".", "add", "(", "(", "sent", ",", "unfin_idx", ")", ")", "\n", "\n", "def", "get_hypo", "(", ")", ":", "\n", "\n", "# remove padding tokens from attn scores", "\n", "                    ", "nonpad_idxs", "=", "src_tokens", "[", "sent", "]", ".", "ne", "(", "self", ".", "pad", ")", "\n", "hypo_attn", "=", "attn_clone", "[", "i", "]", "[", "nonpad_idxs", "]", "\n", "_", ",", "alignment", "=", "hypo_attn", ".", "max", "(", "dim", "=", "0", ")", "\n", "\n", "return", "{", "\n", "'tokens'", ":", "tokens_clone", "[", "i", "]", ",", "\n", "'score'", ":", "score", ",", "\n", "'attention'", ":", "hypo_attn", ",", "# src_len x tgt_len", "\n", "'alignment'", ":", "alignment", ",", "\n", "'positional_scores'", ":", "pos_scores", "[", "i", "]", ",", "\n", "}", "\n", "\n", "", "if", "len", "(", "finalized", "[", "sent", "]", ")", "<", "beam_size", ":", "\n", "                    ", "finalized", "[", "sent", "]", ".", "append", "(", "get_hypo", "(", ")", ")", "\n", "", "elif", "not", "self", ".", "stop_early", "and", "score", ">", "worst_finalized", "[", "sent", "]", "[", "'score'", "]", ":", "\n", "# replace worst hypo for this sentence with new/better one", "\n", "                    ", "worst_idx", "=", "worst_finalized", "[", "sent", "]", "[", "'idx'", "]", "\n", "if", "worst_idx", "is", "not", "None", ":", "\n", "                        ", "finalized", "[", "sent", "]", "[", "worst_idx", "]", "=", "get_hypo", "(", ")", "\n", "\n", "# find new worst finalized hypo for this sentence", "\n", "", "idx", ",", "s", "=", "min", "(", "enumerate", "(", "finalized", "[", "sent", "]", ")", ",", "key", "=", "lambda", "r", ":", "r", "[", "1", "]", "[", "'score'", "]", ")", "\n", "worst_finalized", "[", "sent", "]", "=", "{", "\n", "'score'", ":", "s", "[", "'score'", "]", ",", "\n", "'idx'", ":", "idx", ",", "\n", "}", "\n", "\n", "", "", "newly_finished", "=", "[", "]", "\n", "for", "sent", ",", "unfin_idx", "in", "sents_seen", ":", "\n", "# check termination conditions for this sentence", "\n", "                ", "if", "not", "finished", "[", "sent", "]", "and", "is_finished", "(", "sent", ",", "step", ",", "unfinalized_scores", ")", ":", "\n", "                    ", "finished", "[", "sent", "]", "=", "True", "\n", "newly_finished", ".", "append", "(", "unfin_idx", ")", "\n", "", "", "return", "newly_finished", "\n", "\n", "", "reorder_state", "=", "None", "\n", "batch_idxs", "=", "None", "\n", "for", "step", "in", "range", "(", "maxlen", "+", "1", ")", ":", "# one extra step for EOS marker", "\n", "# reorder decoder internal states based on the prev choice of beams", "\n", "            ", "if", "reorder_state", "is", "not", "None", ":", "\n", "                ", "if", "batch_idxs", "is", "not", "None", ":", "\n", "# update beam indices to take into account removed sentences", "\n", "                    ", "corr", "=", "batch_idxs", "-", "torch", ".", "arange", "(", "batch_idxs", ".", "numel", "(", ")", ")", ".", "type_as", "(", "batch_idxs", ")", "\n", "reorder_state", ".", "view", "(", "-", "1", ",", "beam_size", ")", ".", "add_", "(", "corr", ".", "unsqueeze", "(", "-", "1", ")", "*", "beam_size", ")", "\n", "", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "                    ", "if", "isinstance", "(", "model", ".", "decoder", ",", "FairseqIncrementalDecoder", ")", ":", "\n", "                        ", "model", ".", "decoder", ".", "reorder_incremental_state", "(", "incremental_states", "[", "model", "]", ",", "reorder_state", ")", "\n", "", "encoder_outs", "[", "i", "]", "=", "model", ".", "encoder", ".", "reorder_encoder_out", "(", "encoder_outs", "[", "i", "]", ",", "reorder_state", ")", "\n", "\n", "", "", "probs", ",", "avg_attn_scores", "=", "self", ".", "_decode", "(", "\n", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", ",", "encoder_outs", ",", "incremental_states", ")", "\n", "if", "step", "==", "0", ":", "\n", "# at the first step all hypotheses are equally likely, so use", "\n", "# only the first beam", "\n", "                ", "probs", "=", "probs", ".", "unfold", "(", "0", ",", "1", ",", "beam_size", ")", ".", "squeeze", "(", "2", ")", ".", "contiguous", "(", ")", "\n", "scores", "=", "scores", ".", "type_as", "(", "probs", ")", "\n", "scores_buf", "=", "scores_buf", ".", "type_as", "(", "probs", ")", "\n", "", "elif", "not", "self", ".", "sampling", ":", "\n", "# make probs contain cumulative scores for each hypothesis", "\n", "                ", "probs", ".", "add_", "(", "scores", "[", ":", ",", "step", "-", "1", "]", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "\n", "", "probs", "[", ":", ",", "self", ".", "pad", "]", "=", "-", "math", ".", "inf", "# never select pad", "\n", "probs", "[", ":", ",", "self", ".", "unk", "]", "-=", "self", ".", "unk_penalty", "# apply unk penalty", "\n", "\n", "# Record attention scores", "\n", "#            attn[:, :, step + 1].copy_(avg_attn_scores)", "\n", "if", "avg_attn_scores", "is", "not", "None", ":", "\n", "                ", "if", "attn", "is", "None", ":", "\n", "                    ", "attn", "=", "scores", ".", "new", "(", "bsz", "*", "beam_size", ",", "src_tokens", ".", "size", "(", "1", ")", ",", "maxlen", "+", "2", ")", "\n", "attn_buf", "=", "attn", ".", "clone", "(", ")", "\n", "nonpad_idxs", "=", "src_tokens", ".", "ne", "(", "self", ".", "pad", ")", "\n", "", "attn", "[", ":", ",", ":", ",", "step", "+", "1", "]", ".", "copy_", "(", "avg_attn_scores", ")", "\n", "\n", "", "cand_scores", "=", "buffer", "(", "'cand_scores'", ",", "type_of", "=", "scores", ")", "\n", "cand_indices", "=", "buffer", "(", "'cand_indices'", ")", "\n", "cand_beams", "=", "buffer", "(", "'cand_beams'", ")", "\n", "eos_bbsz_idx", "=", "buffer", "(", "'eos_bbsz_idx'", ")", "\n", "eos_scores", "=", "buffer", "(", "'eos_scores'", ",", "type_of", "=", "scores", ")", "\n", "if", "step", "<", "maxlen", ":", "\n", "                ", "if", "prefix_tokens", "is", "not", "None", "and", "step", "<", "prefix_tokens", ".", "size", "(", "1", ")", ":", "\n", "                    ", "probs_slice", "=", "probs", ".", "view", "(", "bsz", ",", "-", "1", ",", "probs", ".", "size", "(", "-", "1", ")", ")", "[", ":", ",", "0", ",", ":", "]", "\n", "cand_scores", "=", "torch", ".", "gather", "(", "\n", "probs_slice", ",", "dim", "=", "1", ",", "\n", "index", "=", "prefix_tokens", "[", ":", ",", "step", "]", ".", "view", "(", "-", "1", ",", "1", ")", ".", "data", "\n", ")", ".", "expand", "(", "-", "1", ",", "cand_size", ")", "\n", "cand_indices", "=", "prefix_tokens", "[", ":", ",", "step", "]", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand", "(", "bsz", ",", "cand_size", ")", ".", "data", "\n", "cand_beams", ".", "resize_as_", "(", "cand_indices", ")", ".", "fill_", "(", "0", ")", "\n", "", "elif", "self", ".", "sampling", ":", "\n", "                    ", "assert", "self", ".", "pad", "==", "1", ",", "'sampling assumes the first two symbols can be ignored'", "\n", "\n", "if", "self", ".", "sampling_topk", ">", "0", ":", "\n", "                        ", "values", ",", "indices", "=", "probs", "[", ":", ",", "2", ":", "]", ".", "topk", "(", "self", ".", "sampling_topk", ")", "\n", "exp_probs", "=", "values", ".", "div_", "(", "self", ".", "sampling_temperature", ")", ".", "exp", "(", ")", "\n", "if", "step", "==", "0", ":", "\n", "                            ", "torch", ".", "multinomial", "(", "exp_probs", ",", "beam_size", ",", "replacement", "=", "True", ",", "out", "=", "cand_indices", ")", "\n", "", "else", ":", "\n", "                            ", "torch", ".", "multinomial", "(", "exp_probs", ",", "1", ",", "replacement", "=", "True", ",", "out", "=", "cand_indices", ")", "\n", "", "torch", ".", "gather", "(", "exp_probs", ",", "dim", "=", "1", ",", "index", "=", "cand_indices", ",", "out", "=", "cand_scores", ")", "\n", "torch", ".", "gather", "(", "indices", ",", "dim", "=", "1", ",", "index", "=", "cand_indices", ",", "out", "=", "cand_indices", ")", "\n", "cand_indices", ".", "add_", "(", "2", ")", "\n", "", "else", ":", "\n", "                        ", "exp_probs", "=", "probs", ".", "div_", "(", "self", ".", "sampling_temperature", ")", ".", "exp_", "(", ")", ".", "view", "(", "-", "1", ",", "self", ".", "vocab_size", ")", "\n", "\n", "if", "step", "==", "0", ":", "\n", "# we exclude the first two vocab items, one of which is pad", "\n", "                            ", "torch", ".", "multinomial", "(", "exp_probs", "[", ":", ",", "2", ":", "]", ",", "beam_size", ",", "replacement", "=", "True", ",", "out", "=", "cand_indices", ")", "\n", "", "else", ":", "\n", "                            ", "torch", ".", "multinomial", "(", "exp_probs", "[", ":", ",", "2", ":", "]", ",", "1", ",", "replacement", "=", "True", ",", "out", "=", "cand_indices", ")", "\n", "\n", "", "cand_indices", ".", "add_", "(", "2", ")", "\n", "torch", ".", "gather", "(", "exp_probs", ",", "dim", "=", "1", ",", "index", "=", "cand_indices", ",", "out", "=", "cand_scores", ")", "\n", "\n", "", "cand_scores", ".", "log_", "(", ")", "\n", "cand_indices", "=", "cand_indices", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "repeat", "(", "1", ",", "2", ")", "\n", "cand_scores", "=", "cand_scores", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "repeat", "(", "1", ",", "2", ")", "\n", "if", "step", "==", "0", ":", "\n", "                        ", "cand_beams", "=", "torch", ".", "zeros", "(", "bsz", ",", "cand_size", ")", ".", "type_as", "(", "cand_indices", ")", "\n", "", "else", ":", "\n", "                        ", "cand_beams", "=", "torch", ".", "arange", "(", "0", ",", "beam_size", ")", ".", "repeat", "(", "bsz", ",", "2", ")", ".", "type_as", "(", "cand_indices", ")", "\n", "# make scores cumulative", "\n", "cand_scores", ".", "add_", "(", "\n", "torch", ".", "gather", "(", "\n", "scores", "[", ":", ",", "step", "-", "1", "]", ".", "view", "(", "bsz", ",", "beam_size", ")", ",", "dim", "=", "1", ",", "\n", "index", "=", "cand_beams", ",", "\n", ")", "\n", ")", "\n", "", "", "else", ":", "\n", "# take the best 2 x beam_size predictions. We'll choose the first", "\n", "# beam_size of these which don't predict eos to continue with.", "\n", "                    ", "torch", ".", "topk", "(", "\n", "probs", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "\n", "k", "=", "min", "(", "cand_size", ",", "probs", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "size", "(", "1", ")", "-", "1", ")", ",", "# -1 so we never select pad", "\n", "out", "=", "(", "cand_scores", ",", "cand_indices", ")", ",", "\n", ")", "\n", "torch", ".", "div", "(", "cand_indices", ",", "self", ".", "vocab_size", ",", "out", "=", "cand_beams", ")", "\n", "cand_indices", ".", "fmod_", "(", "self", ".", "vocab_size", ")", "\n", "", "", "else", ":", "\n", "# finalize all active hypotheses once we hit maxlen", "\n", "# pick the hypothesis with the highest prob of EOS right now", "\n", "                ", "torch", ".", "sort", "(", "\n", "probs", "[", ":", ",", "self", ".", "eos", "]", ",", "\n", "descending", "=", "True", ",", "\n", "out", "=", "(", "eos_scores", ",", "eos_bbsz_idx", ")", ",", "\n", ")", "\n", "num_remaining_sent", "-=", "len", "(", "finalize_hypos", "(", "\n", "step", ",", "eos_bbsz_idx", ",", "eos_scores", ")", ")", "\n", "assert", "num_remaining_sent", "==", "0", "\n", "break", "\n", "\n", "# cand_bbsz_idx contains beam indices for the top candidate", "\n", "# hypotheses, with a range of values: [0, bsz*beam_size),", "\n", "# and dimensions: [bsz, cand_size]", "\n", "", "cand_bbsz_idx", "=", "cand_beams", ".", "add", "(", "bbsz_offsets", ")", "\n", "\n", "# finalize hypotheses that end in eos", "\n", "eos_mask", "=", "cand_indices", ".", "eq", "(", "self", ".", "eos", ")", "\n", "\n", "finalized_sents", "=", "set", "(", ")", "\n", "if", "step", ">=", "self", ".", "minlen", ":", "\n", "# only consider eos when it's among the top beam_size indices", "\n", "                ", "torch", ".", "masked_select", "(", "\n", "cand_bbsz_idx", "[", ":", ",", ":", "beam_size", "]", ",", "\n", "mask", "=", "eos_mask", "[", ":", ",", ":", "beam_size", "]", ",", "\n", "out", "=", "eos_bbsz_idx", ",", "\n", ")", "\n", "if", "eos_bbsz_idx", ".", "numel", "(", ")", ">", "0", ":", "\n", "                    ", "torch", ".", "masked_select", "(", "\n", "cand_scores", "[", ":", ",", ":", "beam_size", "]", ",", "\n", "mask", "=", "eos_mask", "[", ":", ",", ":", "beam_size", "]", ",", "\n", "out", "=", "eos_scores", ",", "\n", ")", "\n", "finalized_sents", "=", "finalize_hypos", "(", "\n", "step", ",", "eos_bbsz_idx", ",", "eos_scores", ",", "cand_scores", ")", "\n", "num_remaining_sent", "-=", "len", "(", "finalized_sents", ")", "\n", "\n", "", "", "assert", "num_remaining_sent", ">=", "0", "\n", "if", "num_remaining_sent", "==", "0", ":", "\n", "                ", "break", "\n", "", "assert", "step", "<", "maxlen", "\n", "\n", "if", "len", "(", "finalized_sents", ")", ">", "0", ":", "\n", "                ", "new_bsz", "=", "bsz", "-", "len", "(", "finalized_sents", ")", "\n", "\n", "# construct batch_idxs which holds indices of batches to keep for the next pass", "\n", "batch_mask", "=", "torch", ".", "ones", "(", "bsz", ")", ".", "type_as", "(", "cand_indices", ")", "\n", "batch_mask", "[", "cand_indices", ".", "new", "(", "finalized_sents", ")", "]", "=", "0", "\n", "batch_idxs", "=", "batch_mask", ".", "nonzero", "(", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "eos_mask", "=", "eos_mask", "[", "batch_idxs", "]", "\n", "cand_beams", "=", "cand_beams", "[", "batch_idxs", "]", "\n", "bbsz_offsets", ".", "resize_", "(", "new_bsz", ",", "1", ")", "\n", "cand_bbsz_idx", "=", "cand_beams", ".", "add", "(", "bbsz_offsets", ")", "\n", "\n", "cand_scores", "=", "cand_scores", "[", "batch_idxs", "]", "\n", "cand_indices", "=", "cand_indices", "[", "batch_idxs", "]", "\n", "if", "prefix_tokens", "is", "not", "None", ":", "\n", "                    ", "prefix_tokens", "=", "prefix_tokens", "[", "batch_idxs", "]", "\n", "\n", "", "scores", "=", "scores", ".", "view", "(", "bsz", ",", "-", "1", ")", "[", "batch_idxs", "]", ".", "view", "(", "new_bsz", "*", "beam_size", ",", "-", "1", ")", "\n", "scores_buf", ".", "resize_as_", "(", "scores", ")", "\n", "tokens", "=", "tokens", ".", "view", "(", "bsz", ",", "-", "1", ")", "[", "batch_idxs", "]", ".", "view", "(", "new_bsz", "*", "beam_size", ",", "-", "1", ")", "\n", "tokens_buf", ".", "resize_as_", "(", "tokens", ")", "\n", "attn", "=", "attn", ".", "view", "(", "bsz", ",", "-", "1", ")", "[", "batch_idxs", "]", ".", "view", "(", "new_bsz", "*", "beam_size", ",", "attn", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "attn_buf", ".", "resize_as_", "(", "attn", ")", "\n", "bsz", "=", "new_bsz", "\n", "", "else", ":", "\n", "                ", "batch_idxs", "=", "None", "\n", "\n", "# set active_mask so that values > cand_size indicate eos hypos", "\n", "# and values < cand_size indicate candidate active hypos.", "\n", "# After, the min values per row are the top candidate active hypos", "\n", "", "active_mask", "=", "buffer", "(", "'active_mask'", ")", "\n", "torch", ".", "add", "(", "\n", "eos_mask", ".", "type_as", "(", "cand_offsets", ")", "*", "cand_size", ",", "\n", "cand_offsets", "[", ":", "eos_mask", ".", "size", "(", "1", ")", "]", ",", "\n", "out", "=", "active_mask", ",", "\n", ")", "\n", "\n", "# get the top beam_size active hypotheses, which are just the hypos", "\n", "# with the smallest values in active_mask", "\n", "active_hypos", ",", "_ignore", "=", "buffer", "(", "'active_hypos'", ")", ",", "buffer", "(", "'_ignore'", ")", "\n", "torch", ".", "topk", "(", "\n", "active_mask", ",", "k", "=", "beam_size", ",", "dim", "=", "1", ",", "largest", "=", "False", ",", "\n", "out", "=", "(", "_ignore", ",", "active_hypos", ")", "\n", ")", "\n", "active_bbsz_idx", "=", "buffer", "(", "'active_bbsz_idx'", ")", "\n", "torch", ".", "gather", "(", "\n", "cand_bbsz_idx", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", ",", "\n", "out", "=", "active_bbsz_idx", ",", "\n", ")", "\n", "active_scores", "=", "torch", ".", "gather", "(", "\n", "cand_scores", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", ",", "\n", "out", "=", "scores", "[", ":", ",", "step", "]", ".", "view", "(", "bsz", ",", "beam_size", ")", ",", "\n", ")", "\n", "\n", "active_bbsz_idx", "=", "active_bbsz_idx", ".", "view", "(", "-", "1", ")", "\n", "active_scores", "=", "active_scores", ".", "view", "(", "-", "1", ")", "\n", "\n", "# copy tokens and scores for active hypotheses", "\n", "torch", ".", "index_select", "(", "\n", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", ",", "dim", "=", "0", ",", "index", "=", "active_bbsz_idx", ",", "\n", "out", "=", "tokens_buf", "[", ":", ",", ":", "step", "+", "1", "]", ",", "\n", ")", "\n", "torch", ".", "gather", "(", "\n", "cand_indices", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", ",", "\n", "out", "=", "tokens_buf", ".", "view", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "[", ":", ",", ":", ",", "step", "+", "1", "]", ",", "\n", ")", "\n", "if", "step", ">", "0", ":", "\n", "                ", "torch", ".", "index_select", "(", "\n", "scores", "[", ":", ",", ":", "step", "]", ",", "dim", "=", "0", ",", "index", "=", "active_bbsz_idx", ",", "\n", "out", "=", "scores_buf", "[", ":", ",", ":", "step", "]", ",", "\n", ")", "\n", "", "torch", ".", "gather", "(", "\n", "cand_scores", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", ",", "\n", "out", "=", "scores_buf", ".", "view", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "[", ":", ",", ":", ",", "step", "]", ",", "\n", ")", "\n", "\n", "# copy attention for active hypotheses", "\n", "torch", ".", "index_select", "(", "\n", "attn", "[", ":", ",", ":", ",", ":", "step", "+", "2", "]", ",", "dim", "=", "0", ",", "index", "=", "active_bbsz_idx", ",", "\n", "out", "=", "attn_buf", "[", ":", ",", ":", ",", ":", "step", "+", "2", "]", ",", "\n", ")", "\n", "\n", "# swap buffers", "\n", "tokens", ",", "tokens_buf", "=", "tokens_buf", ",", "tokens", "\n", "scores", ",", "scores_buf", "=", "scores_buf", ",", "scores", "\n", "attn", ",", "attn_buf", "=", "attn_buf", ",", "attn", "\n", "\n", "# reorder incremental state in decoder", "\n", "reorder_state", "=", "active_bbsz_idx", "\n", "\n", "# print(\"step\")", "\n", "# print(scores[0])", "\n", "# print([self.tgt_dict.symbols[x] for x in tokens[0]][:5])", "\n", "# print([self.tgt_dict.symbols[x] for x in tokens[1]][:5])", "\n", "# print([self.tgt_dict.symbols[x] for x in tokens[2]][:5])", "\n", "# print(self.tgt_dict.symbols[1115],self.tgt_dict.symbols[5741])", "\n", "# ,scores,self.tgt_dict.string(tokens[0]),\"try\",self.tgt_dict.string([1,62,4]))", "\n", "\n", "# sort by score descending", "\n", "", "for", "sent", "in", "range", "(", "len", "(", "finalized", ")", ")", ":", "\n", "            ", "finalized", "[", "sent", "]", "=", "sorted", "(", "finalized", "[", "sent", "]", ",", "key", "=", "lambda", "r", ":", "r", "[", "'score'", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "", "return", "finalized", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator._generate_single_step": [[531, 972], ["src_tokens.size", "min", "src_tokens.data.new().float().fill_", "[].view.clone", "src_tokens.data.new().fill_", "[].view.clone", "[].view.new", "[].view.new.clone", "torch.arange().type_as", "range", "range", "min", "isinstance", "model.encoder", "encoder_outs.append", "src_tokens.size", "[].view.index_select", "set", "enumerate", "seqgen.SequenceGenerator._decode", "seqgen.SequenceGenerator._generate.buffer"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator._decode"], ["", "def", "_generate_single_step", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "beam_size", "=", "None", ",", "maxlen", "=", "None", ",", "prefix_tokens", "=", "None", ")", ":", "\n", "        ", "bsz", ",", "srclen", "=", "src_tokens", ".", "size", "(", ")", "\n", "maxlen", "=", "min", "(", "maxlen", ",", "self", ".", "maxlen", ")", "if", "maxlen", "is", "not", "None", "else", "self", ".", "maxlen", "\n", "\n", "# the max beam size is the dictionary size - 1, since we never select pad", "\n", "beam_size", "=", "beam_size", "if", "beam_size", "is", "not", "None", "else", "self", ".", "beam_size", "\n", "beam_size", "=", "min", "(", "beam_size", ",", "self", ".", "vocab_size", "-", "1", ")", "\n", "\n", "encoder_outs", "=", "[", "]", "\n", "incremental_states", "=", "{", "}", "\n", "for", "model", "in", "self", ".", "models", ":", "\n", "            ", "if", "not", "self", ".", "retain_dropout", ":", "\n", "                ", "model", ".", "eval", "(", ")", "\n", "", "if", "isinstance", "(", "model", ".", "decoder", ",", "FairseqIncrementalDecoder", ")", ":", "\n", "                ", "incremental_states", "[", "model", "]", "=", "{", "}", "\n", "", "else", ":", "\n", "                ", "incremental_states", "[", "model", "]", "=", "None", "\n", "\n", "# compute the encoder output for each beam", "\n", "", "encoder_out", "=", "model", ".", "encoder", "(", "\n", "src_tokens", ".", "repeat", "(", "1", ",", "beam_size", ")", ".", "view", "(", "-", "1", ",", "srclen", ")", ",", "\n", "src_lengths", ".", "expand", "(", "beam_size", ",", "src_lengths", ".", "numel", "(", ")", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ",", "\n", ")", "\n", "encoder_outs", ".", "append", "(", "encoder_out", ")", "\n", "\n", "# initialize buffers", "\n", "", "scores", "=", "src_tokens", ".", "data", ".", "new", "(", "bsz", "*", "beam_size", ",", "maxlen", "+", "1", ")", ".", "float", "(", ")", ".", "fill_", "(", "0", ")", "\n", "scores_buf", "=", "scores", ".", "clone", "(", ")", "\n", "tokens", "=", "src_tokens", ".", "data", ".", "new", "(", "bsz", "*", "beam_size", ",", "maxlen", "+", "2", ")", ".", "fill_", "(", "self", ".", "pad", ")", "\n", "tokens_buf", "=", "tokens", ".", "clone", "(", ")", "\n", "tokens", "[", ":", ",", "0", "]", "=", "self", ".", "eos", "\n", "attn", "=", "scores", ".", "new", "(", "bsz", "*", "beam_size", ",", "src_tokens", ".", "size", "(", "1", ")", ",", "maxlen", "+", "2", ")", "\n", "attn_buf", "=", "attn", ".", "clone", "(", ")", "\n", "\n", "# list of completed sentences", "\n", "finalized", "=", "[", "[", "]", "for", "i", "in", "range", "(", "bsz", ")", "]", "\n", "finished", "=", "[", "False", "for", "i", "in", "range", "(", "bsz", ")", "]", "\n", "worst_finalized", "=", "[", "{", "'idx'", ":", "None", ",", "'score'", ":", "-", "math", ".", "inf", "}", "for", "i", "in", "range", "(", "bsz", ")", "]", "\n", "num_remaining_sent", "=", "bsz", "\n", "\n", "# number of candidate hypos per step", "\n", "cand_size", "=", "2", "*", "beam_size", "# 2 x beam size in case half are EOS", "\n", "\n", "# offset arrays for converting between different indexing schemes", "\n", "bbsz_offsets", "=", "(", "torch", ".", "arange", "(", "0", ",", "bsz", ")", "*", "beam_size", ")", ".", "unsqueeze", "(", "1", ")", ".", "type_as", "(", "tokens", ")", "\n", "cand_offsets", "=", "torch", ".", "arange", "(", "0", ",", "cand_size", ")", ".", "type_as", "(", "tokens", ")", "\n", "\n", "# helper function for allocating buffers on the fly", "\n", "buffers", "=", "{", "}", "\n", "\n", "def", "buffer", "(", "name", ",", "type_of", "=", "tokens", ")", ":", "# noqa", "\n", "            ", "if", "name", "not", "in", "buffers", ":", "\n", "                ", "buffers", "[", "name", "]", "=", "type_of", ".", "new", "(", ")", "\n", "", "return", "buffers", "[", "name", "]", "\n", "\n", "", "def", "is_finished", "(", "sent", ",", "step", ",", "unfinalized_scores", "=", "None", ")", ":", "\n", "            ", "\"\"\"\n            Check whether we've finished generation for a given sentence, by\n            comparing the worst score among finalized hypotheses to the best\n            possible score among unfinalized hypotheses.\n            \"\"\"", "\n", "assert", "len", "(", "finalized", "[", "sent", "]", ")", "<=", "beam_size", "\n", "if", "len", "(", "finalized", "[", "sent", "]", ")", "==", "beam_size", ":", "\n", "                ", "if", "self", ".", "stop_early", "or", "step", "==", "maxlen", "or", "unfinalized_scores", "is", "None", ":", "\n", "                    ", "return", "True", "\n", "# stop if the best unfinalized score is worse than the worst", "\n", "# finalized one", "\n", "", "best_unfinalized_score", "=", "unfinalized_scores", "[", "sent", "]", ".", "max", "(", ")", "\n", "if", "self", ".", "normalize_scores", ":", "\n", "                    ", "best_unfinalized_score", "/=", "maxlen", "**", "self", ".", "len_penalty", "\n", "", "if", "worst_finalized", "[", "sent", "]", "[", "'score'", "]", ">=", "best_unfinalized_score", ":", "\n", "                    ", "return", "True", "\n", "", "", "return", "False", "\n", "\n", "", "def", "finalize_hypos", "(", "step", ",", "bbsz_idx", ",", "eos_scores", ",", "unfinalized_scores", "=", "None", ")", ":", "\n", "            ", "\"\"\"\n            Finalize the given hypotheses at this step, while keeping the total\n            number of finalized hypotheses per sentence <= beam_size.\n            Note: the input must be in the desired finalization order, so that\n            hypotheses that appear earlier in the input are preferred to those\n            that appear later.\n            Args:\n                step: current time step\n                bbsz_idx: A vector of indices in the range [0, bsz*beam_size),\n                    indicating which hypotheses to finalize\n                eos_scores: A vector of the same size as bbsz_idx containing\n                    scores for each hypothesis\n                unfinalized_scores: A vector containing scores for all\n                    unfinalized hypotheses\n            \"\"\"", "\n", "assert", "bbsz_idx", ".", "numel", "(", ")", "==", "eos_scores", ".", "numel", "(", ")", "\n", "\n", "# clone relevant token and attention tensors", "\n", "tokens_clone", "=", "tokens", ".", "index_select", "(", "0", ",", "bbsz_idx", ")", "\n", "tokens_clone", "=", "tokens_clone", "[", ":", ",", "1", ":", "step", "+", "2", "]", "# skip the first index, which is EOS", "\n", "tokens_clone", "[", ":", ",", "step", "]", "=", "self", ".", "eos", "\n", "attn_clone", "=", "attn", ".", "index_select", "(", "0", ",", "bbsz_idx", ")", "[", ":", ",", ":", ",", "1", ":", "step", "+", "2", "]", "\n", "\n", "# compute scores per token position", "\n", "pos_scores", "=", "scores", ".", "index_select", "(", "0", ",", "bbsz_idx", ")", "[", ":", ",", ":", "step", "+", "1", "]", "\n", "pos_scores", "[", ":", ",", "step", "]", "=", "eos_scores", "\n", "# convert from cumulative to per-position scores", "\n", "pos_scores", "[", ":", ",", "1", ":", "]", "=", "pos_scores", "[", ":", ",", "1", ":", "]", "-", "pos_scores", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "# normalize sentence-level scores", "\n", "if", "self", ".", "normalize_scores", ":", "\n", "                ", "eos_scores", "/=", "(", "step", "+", "1", ")", "**", "self", ".", "len_penalty", "\n", "\n", "", "cum_unfin", "=", "[", "]", "\n", "prev", "=", "0", "\n", "for", "f", "in", "finished", ":", "\n", "                ", "if", "f", ":", "\n", "                    ", "prev", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "cum_unfin", ".", "append", "(", "prev", ")", "\n", "\n", "", "", "sents_seen", "=", "set", "(", ")", "\n", "for", "i", ",", "(", "idx", ",", "score", ")", "in", "enumerate", "(", "zip", "(", "bbsz_idx", ".", "tolist", "(", ")", ",", "eos_scores", ".", "tolist", "(", ")", ")", ")", ":", "\n", "                ", "unfin_idx", "=", "idx", "//", "beam_size", "\n", "sent", "=", "unfin_idx", "+", "cum_unfin", "[", "unfin_idx", "]", "\n", "\n", "sents_seen", ".", "add", "(", "(", "sent", ",", "unfin_idx", ")", ")", "\n", "\n", "def", "get_hypo", "(", ")", ":", "\n", "\n", "# remove padding tokens from attn scores", "\n", "                    ", "nonpad_idxs", "=", "src_tokens", "[", "sent", "]", ".", "ne", "(", "self", ".", "pad", ")", "\n", "hypo_attn", "=", "attn_clone", "[", "i", "]", "[", "nonpad_idxs", "]", "\n", "_", ",", "alignment", "=", "hypo_attn", ".", "max", "(", "dim", "=", "0", ")", "\n", "\n", "return", "{", "\n", "'tokens'", ":", "tokens_clone", "[", "i", "]", ",", "\n", "'score'", ":", "score", ",", "\n", "'attention'", ":", "hypo_attn", ",", "# src_len x tgt_len", "\n", "'alignment'", ":", "alignment", ",", "\n", "'positional_scores'", ":", "pos_scores", "[", "i", "]", ",", "\n", "}", "\n", "\n", "", "if", "len", "(", "finalized", "[", "sent", "]", ")", "<", "beam_size", ":", "\n", "                    ", "finalized", "[", "sent", "]", ".", "append", "(", "get_hypo", "(", ")", ")", "\n", "", "elif", "not", "self", ".", "stop_early", "and", "score", ">", "worst_finalized", "[", "sent", "]", "[", "'score'", "]", ":", "\n", "# replace worst hypo for this sentence with new/better one", "\n", "                    ", "worst_idx", "=", "worst_finalized", "[", "sent", "]", "[", "'idx'", "]", "\n", "if", "worst_idx", "is", "not", "None", ":", "\n", "                        ", "finalized", "[", "sent", "]", "[", "worst_idx", "]", "=", "get_hypo", "(", ")", "\n", "\n", "# find new worst finalized hypo for this sentence", "\n", "", "idx", ",", "s", "=", "min", "(", "enumerate", "(", "finalized", "[", "sent", "]", ")", ",", "key", "=", "lambda", "r", ":", "r", "[", "1", "]", "[", "'score'", "]", ")", "\n", "worst_finalized", "[", "sent", "]", "=", "{", "\n", "'score'", ":", "s", "[", "'score'", "]", ",", "\n", "'idx'", ":", "idx", ",", "\n", "}", "\n", "\n", "", "", "newly_finished", "=", "[", "]", "\n", "for", "sent", ",", "unfin_idx", "in", "sents_seen", ":", "\n", "# check termination conditions for this sentence", "\n", "                ", "if", "not", "finished", "[", "sent", "]", "and", "is_finished", "(", "sent", ",", "step", ",", "unfinalized_scores", ")", ":", "\n", "                    ", "finished", "[", "sent", "]", "=", "True", "\n", "newly_finished", ".", "append", "(", "unfin_idx", ")", "\n", "", "", "return", "newly_finished", "\n", "\n", "", "reorder_state", "=", "None", "\n", "batch_idxs", "=", "None", "\n", "# print(\"SHAPE\", prefix_tokens.size()[1]+1)", "\n", "if", "prefix_tokens", "is", "not", "None", ":", "\n", "            ", "num_of_steps", "=", "prefix_tokens", ".", "size", "(", ")", "[", "1", "]", "+", "1", "\n", "# print(\"PREFIX TOKENS NOT NONE\")", "\n", "", "else", ":", "\n", "# print(\"PREFIX TOKENS NONE\")", "\n", "            ", "num_of_steps", "=", "1", "\n", "# print(\"NUM OF STEPS\",num_of_steps)", "\n", "", "for", "step", "in", "range", "(", "num_of_steps", ")", ":", "# one extra step for EOS marker", "\n", "# reorder decoder internal states based on the prev choice of beams", "\n", "            ", "if", "reorder_state", "is", "not", "None", ":", "\n", "                ", "if", "batch_idxs", "is", "not", "None", ":", "\n", "# update beam indices to take into account removed sentences", "\n", "                    ", "corr", "=", "batch_idxs", "-", "torch", ".", "arange", "(", "batch_idxs", ".", "numel", "(", ")", ")", ".", "type_as", "(", "batch_idxs", ")", "\n", "reorder_state", ".", "view", "(", "-", "1", ",", "beam_size", ")", ".", "add_", "(", "corr", ".", "unsqueeze", "(", "-", "1", ")", "*", "beam_size", ")", "\n", "", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "                    ", "if", "isinstance", "(", "model", ".", "decoder", ",", "FairseqIncrementalDecoder", ")", ":", "\n", "                        ", "model", ".", "decoder", ".", "reorder_incremental_state", "(", "incremental_states", "[", "model", "]", ",", "reorder_state", ")", "\n", "", "encoder_outs", "[", "i", "]", "=", "model", ".", "encoder", ".", "reorder_encoder_out", "(", "encoder_outs", "[", "i", "]", ",", "reorder_state", ")", "\n", "\n", "", "", "probs", ",", "avg_attn_scores", "=", "self", ".", "_decode", "(", "\n", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", ",", "encoder_outs", ",", "incremental_states", ")", "\n", "\n", "# print(probs,probs.size(),\"PROBS, SequenceGenerator\")", "\n", "# print(avg_attn_scores, avg_attn_scores.size(), \"avg_attn_scores SequenceGenerator\")", "\n", "\n", "# print(probs.numpy())", "\n", "# c = np.exp(probs.numpy()[:10])", "\n", "# a = (np.argsort(-probs.numpy()[0]))", "\n", "# b = [self.tgt_dict.symbols[x] for x in a[:10]]", "\n", "# d = (np.argmax(-probs.numpy()[0]))", "\n", "\n", "# print(b,step)", "\n", "if", "step", "==", "num_of_steps", "-", "1", ":", "\n", "# print(\"blah\")", "\n", "# raise Exception", "\n", "                ", "return", "probs", ".", "numpy", "(", ")", "[", "0", "]", "\n", "# print(d)", "\n", "# raise Exception", "\n", "\n", "", "if", "step", "==", "0", ":", "\n", "# at the first step all hypotheses are equally likely, so use", "\n", "# only the first beam", "\n", "                ", "probs", "=", "probs", ".", "unfold", "(", "0", ",", "1", ",", "beam_size", ")", ".", "squeeze", "(", "2", ")", ".", "contiguous", "(", ")", "\n", "scores", "=", "scores", ".", "type_as", "(", "probs", ")", "\n", "scores_buf", "=", "scores_buf", ".", "type_as", "(", "probs", ")", "\n", "", "elif", "not", "self", ".", "sampling", ":", "\n", "# make probs contain cumulative scores for each hypothesis", "\n", "                ", "probs", ".", "add_", "(", "scores", "[", ":", ",", "step", "-", "1", "]", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "\n", "", "probs", "[", ":", ",", "self", ".", "pad", "]", "=", "-", "math", ".", "inf", "# never select pad", "\n", "probs", "[", ":", ",", "self", ".", "unk", "]", "-=", "self", ".", "unk_penalty", "# apply unk penalty", "\n", "\n", "# Record attention scores", "\n", "#            attn[:, :, step + 1].copy_(avg_attn_scores)", "\n", "if", "avg_attn_scores", "is", "not", "None", ":", "\n", "                ", "if", "attn", "is", "None", ":", "\n", "                    ", "attn", "=", "scores", ".", "new", "(", "bsz", "*", "beam_size", ",", "src_tokens", ".", "size", "(", "1", ")", ",", "maxlen", "+", "2", ")", "\n", "attn_buf", "=", "attn", ".", "clone", "(", ")", "\n", "nonpad_idxs", "=", "src_tokens", ".", "ne", "(", "self", ".", "pad", ")", "\n", "", "attn", "[", ":", ",", ":", ",", "step", "+", "1", "]", ".", "copy_", "(", "avg_attn_scores", ")", "\n", "", "cand_scores", "=", "buffer", "(", "'cand_scores'", ",", "type_of", "=", "scores", ")", "\n", "cand_indices", "=", "buffer", "(", "'cand_indices'", ")", "\n", "cand_beams", "=", "buffer", "(", "'cand_beams'", ")", "\n", "eos_bbsz_idx", "=", "buffer", "(", "'eos_bbsz_idx'", ")", "\n", "eos_scores", "=", "buffer", "(", "'eos_scores'", ",", "type_of", "=", "scores", ")", "\n", "if", "step", "<", "maxlen", ":", "\n", "                ", "if", "prefix_tokens", "is", "not", "None", "and", "step", "<", "prefix_tokens", ".", "size", "(", "1", ")", ":", "\n", "                    ", "probs_slice", "=", "probs", ".", "view", "(", "bsz", ",", "-", "1", ",", "probs", ".", "size", "(", "-", "1", ")", ")", "[", ":", ",", "0", ",", ":", "]", "\n", "cand_scores", "=", "torch", ".", "gather", "(", "\n", "probs_slice", ",", "dim", "=", "1", ",", "\n", "index", "=", "prefix_tokens", "[", ":", ",", "step", "]", ".", "view", "(", "-", "1", ",", "1", ")", ".", "data", "\n", ")", ".", "expand", "(", "-", "1", ",", "cand_size", ")", "\n", "cand_indices", "=", "prefix_tokens", "[", ":", ",", "step", "]", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand", "(", "bsz", ",", "cand_size", ")", ".", "data", "\n", "cand_beams", ".", "resize_as_", "(", "cand_indices", ")", ".", "fill_", "(", "0", ")", "\n", "", "elif", "self", ".", "sampling", ":", "\n", "                    ", "assert", "self", ".", "pad", "==", "1", ",", "'sampling assumes the first two symbols can be ignored'", "\n", "\n", "if", "self", ".", "sampling_topk", ">", "0", ":", "\n", "                        ", "values", ",", "indices", "=", "probs", "[", ":", ",", "2", ":", "]", ".", "topk", "(", "self", ".", "sampling_topk", ")", "\n", "exp_probs", "=", "values", ".", "div_", "(", "self", ".", "sampling_temperature", ")", ".", "exp", "(", ")", "\n", "if", "step", "==", "0", ":", "\n", "                            ", "torch", ".", "multinomial", "(", "exp_probs", ",", "beam_size", ",", "replacement", "=", "True", ",", "out", "=", "cand_indices", ")", "\n", "", "else", ":", "\n", "                            ", "torch", ".", "multinomial", "(", "exp_probs", ",", "1", ",", "replacement", "=", "True", ",", "out", "=", "cand_indices", ")", "\n", "", "torch", ".", "gather", "(", "exp_probs", ",", "dim", "=", "1", ",", "index", "=", "cand_indices", ",", "out", "=", "cand_scores", ")", "\n", "torch", ".", "gather", "(", "indices", ",", "dim", "=", "1", ",", "index", "=", "cand_indices", ",", "out", "=", "cand_indices", ")", "\n", "cand_indices", ".", "add_", "(", "2", ")", "\n", "", "else", ":", "\n", "                        ", "exp_probs", "=", "probs", ".", "div_", "(", "self", ".", "sampling_temperature", ")", ".", "exp_", "(", ")", ".", "view", "(", "-", "1", ",", "self", ".", "vocab_size", ")", "\n", "\n", "if", "step", "==", "0", ":", "\n", "# we exclude the first two vocab items, one of which is pad", "\n", "                            ", "torch", ".", "multinomial", "(", "exp_probs", "[", ":", ",", "2", ":", "]", ",", "beam_size", ",", "replacement", "=", "True", ",", "out", "=", "cand_indices", ")", "\n", "", "else", ":", "\n", "                            ", "torch", ".", "multinomial", "(", "exp_probs", "[", ":", ",", "2", ":", "]", ",", "1", ",", "replacement", "=", "True", ",", "out", "=", "cand_indices", ")", "\n", "\n", "", "cand_indices", ".", "add_", "(", "2", ")", "\n", "torch", ".", "gather", "(", "exp_probs", ",", "dim", "=", "1", ",", "index", "=", "cand_indices", ",", "out", "=", "cand_scores", ")", "\n", "\n", "", "cand_scores", ".", "log_", "(", ")", "\n", "cand_indices", "=", "cand_indices", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "repeat", "(", "1", ",", "2", ")", "\n", "cand_scores", "=", "cand_scores", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "repeat", "(", "1", ",", "2", ")", "\n", "if", "step", "==", "0", ":", "\n", "                        ", "cand_beams", "=", "torch", ".", "zeros", "(", "bsz", ",", "cand_size", ")", ".", "type_as", "(", "cand_indices", ")", "\n", "", "else", ":", "\n", "                        ", "cand_beams", "=", "torch", ".", "arange", "(", "0", ",", "beam_size", ")", ".", "repeat", "(", "bsz", ",", "2", ")", ".", "type_as", "(", "cand_indices", ")", "\n", "# make scores cumulative", "\n", "cand_scores", ".", "add_", "(", "\n", "torch", ".", "gather", "(", "\n", "scores", "[", ":", ",", "step", "-", "1", "]", ".", "view", "(", "bsz", ",", "beam_size", ")", ",", "dim", "=", "1", ",", "\n", "index", "=", "cand_beams", ",", "\n", ")", "\n", ")", "\n", "", "", "else", ":", "\n", "# take the best 2 x beam_size predictions. We'll choose the first", "\n", "# beam_size of these which don't predict eos to continue with.", "\n", "                    ", "torch", ".", "topk", "(", "\n", "probs", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "\n", "k", "=", "min", "(", "cand_size", ",", "probs", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "size", "(", "1", ")", "-", "1", ")", ",", "# -1 so we never select pad", "\n", "out", "=", "(", "cand_scores", ",", "cand_indices", ")", ",", "\n", ")", "\n", "torch", ".", "div", "(", "cand_indices", ",", "self", ".", "vocab_size", ",", "out", "=", "cand_beams", ")", "\n", "cand_indices", ".", "fmod_", "(", "self", ".", "vocab_size", ")", "\n", "", "", "else", ":", "\n", "# finalize all active hypotheses once we hit maxlen", "\n", "# pick the hypothesis with the highest prob of EOS right now", "\n", "                ", "torch", ".", "sort", "(", "\n", "probs", "[", ":", ",", "self", ".", "eos", "]", ",", "\n", "descending", "=", "True", ",", "\n", "out", "=", "(", "eos_scores", ",", "eos_bbsz_idx", ")", ",", "\n", ")", "\n", "num_remaining_sent", "-=", "len", "(", "finalize_hypos", "(", "\n", "step", ",", "eos_bbsz_idx", ",", "eos_scores", ")", ")", "\n", "assert", "num_remaining_sent", "==", "0", "\n", "break", "\n", "\n", "# cand_bbsz_idx contains beam indices for the top candidate", "\n", "# hypotheses, with a range of values: [0, bsz*beam_size),", "\n", "# and dimensions: [bsz, cand_size]", "\n", "", "cand_bbsz_idx", "=", "cand_beams", ".", "add", "(", "bbsz_offsets", ")", "\n", "\n", "# finalize hypotheses that end in eos", "\n", "eos_mask", "=", "cand_indices", ".", "eq", "(", "self", ".", "eos", ")", "\n", "\n", "finalized_sents", "=", "set", "(", ")", "\n", "if", "step", ">=", "self", ".", "minlen", ":", "\n", "# only consider eos when it's among the top beam_size indices", "\n", "                ", "torch", ".", "masked_select", "(", "\n", "cand_bbsz_idx", "[", ":", ",", ":", "beam_size", "]", ",", "\n", "mask", "=", "eos_mask", "[", ":", ",", ":", "beam_size", "]", ",", "\n", "out", "=", "eos_bbsz_idx", ",", "\n", ")", "\n", "if", "eos_bbsz_idx", ".", "numel", "(", ")", ">", "0", ":", "\n", "                    ", "torch", ".", "masked_select", "(", "\n", "cand_scores", "[", ":", ",", ":", "beam_size", "]", ",", "\n", "mask", "=", "eos_mask", "[", ":", ",", ":", "beam_size", "]", ",", "\n", "out", "=", "eos_scores", ",", "\n", ")", "\n", "finalized_sents", "=", "finalize_hypos", "(", "\n", "step", ",", "eos_bbsz_idx", ",", "eos_scores", ",", "cand_scores", ")", "\n", "num_remaining_sent", "-=", "len", "(", "finalized_sents", ")", "\n", "\n", "", "", "assert", "num_remaining_sent", ">=", "0", "\n", "if", "num_remaining_sent", "==", "0", ":", "\n", "                ", "break", "\n", "", "assert", "step", "<", "maxlen", "\n", "\n", "if", "len", "(", "finalized_sents", ")", ">", "0", ":", "\n", "                ", "new_bsz", "=", "bsz", "-", "len", "(", "finalized_sents", ")", "\n", "\n", "# construct batch_idxs which holds indices of batches to keep for the next pass", "\n", "batch_mask", "=", "torch", ".", "ones", "(", "bsz", ")", ".", "type_as", "(", "cand_indices", ")", "\n", "batch_mask", "[", "cand_indices", ".", "new", "(", "finalized_sents", ")", "]", "=", "0", "\n", "batch_idxs", "=", "batch_mask", ".", "nonzero", "(", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "eos_mask", "=", "eos_mask", "[", "batch_idxs", "]", "\n", "cand_beams", "=", "cand_beams", "[", "batch_idxs", "]", "\n", "bbsz_offsets", ".", "resize_", "(", "new_bsz", ",", "1", ")", "\n", "cand_bbsz_idx", "=", "cand_beams", ".", "add", "(", "bbsz_offsets", ")", "\n", "\n", "cand_scores", "=", "cand_scores", "[", "batch_idxs", "]", "\n", "cand_indices", "=", "cand_indices", "[", "batch_idxs", "]", "\n", "if", "prefix_tokens", "is", "not", "None", ":", "\n", "                    ", "prefix_tokens", "=", "prefix_tokens", "[", "batch_idxs", "]", "\n", "\n", "", "scores", "=", "scores", ".", "view", "(", "bsz", ",", "-", "1", ")", "[", "batch_idxs", "]", ".", "view", "(", "new_bsz", "*", "beam_size", ",", "-", "1", ")", "\n", "scores_buf", ".", "resize_as_", "(", "scores", ")", "\n", "tokens", "=", "tokens", ".", "view", "(", "bsz", ",", "-", "1", ")", "[", "batch_idxs", "]", ".", "view", "(", "new_bsz", "*", "beam_size", ",", "-", "1", ")", "\n", "tokens_buf", ".", "resize_as_", "(", "tokens", ")", "\n", "attn", "=", "attn", ".", "view", "(", "bsz", ",", "-", "1", ")", "[", "batch_idxs", "]", ".", "view", "(", "new_bsz", "*", "beam_size", ",", "attn", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "attn_buf", ".", "resize_as_", "(", "attn", ")", "\n", "bsz", "=", "new_bsz", "\n", "", "else", ":", "\n", "                ", "batch_idxs", "=", "None", "\n", "\n", "# set active_mask so that values > cand_size indicate eos hypos", "\n", "# and values < cand_size indicate candidate active hypos.", "\n", "# After, the min values per row are the top candidate active hypos", "\n", "", "active_mask", "=", "buffer", "(", "'active_mask'", ")", "\n", "torch", ".", "add", "(", "\n", "eos_mask", ".", "type_as", "(", "cand_offsets", ")", "*", "cand_size", ",", "\n", "cand_offsets", "[", ":", "eos_mask", ".", "size", "(", "1", ")", "]", ",", "\n", "out", "=", "active_mask", ",", "\n", ")", "\n", "\n", "# get the top beam_size active hypotheses, which are just the hypos", "\n", "# with the smallest values in active_mask", "\n", "active_hypos", ",", "_ignore", "=", "buffer", "(", "'active_hypos'", ")", ",", "buffer", "(", "'_ignore'", ")", "\n", "torch", ".", "topk", "(", "\n", "active_mask", ",", "k", "=", "beam_size", ",", "dim", "=", "1", ",", "largest", "=", "False", ",", "\n", "out", "=", "(", "_ignore", ",", "active_hypos", ")", "\n", ")", "\n", "active_bbsz_idx", "=", "buffer", "(", "'active_bbsz_idx'", ")", "\n", "torch", ".", "gather", "(", "\n", "cand_bbsz_idx", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", ",", "\n", "out", "=", "active_bbsz_idx", ",", "\n", ")", "\n", "active_scores", "=", "torch", ".", "gather", "(", "\n", "cand_scores", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", ",", "\n", "out", "=", "scores", "[", ":", ",", "step", "]", ".", "view", "(", "bsz", ",", "beam_size", ")", ",", "\n", ")", "\n", "\n", "active_bbsz_idx", "=", "active_bbsz_idx", ".", "view", "(", "-", "1", ")", "\n", "active_scores", "=", "active_scores", ".", "view", "(", "-", "1", ")", "\n", "\n", "# copy tokens and scores for active hypotheses", "\n", "torch", ".", "index_select", "(", "\n", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", ",", "dim", "=", "0", ",", "index", "=", "active_bbsz_idx", ",", "\n", "out", "=", "tokens_buf", "[", ":", ",", ":", "step", "+", "1", "]", ",", "\n", ")", "\n", "torch", ".", "gather", "(", "\n", "cand_indices", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", ",", "\n", "out", "=", "tokens_buf", ".", "view", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "[", ":", ",", ":", ",", "step", "+", "1", "]", ",", "\n", ")", "\n", "if", "step", ">", "0", ":", "\n", "                ", "torch", ".", "index_select", "(", "\n", "scores", "[", ":", ",", ":", "step", "]", ",", "dim", "=", "0", ",", "index", "=", "active_bbsz_idx", ",", "\n", "out", "=", "scores_buf", "[", ":", ",", ":", "step", "]", ",", "\n", ")", "\n", "", "torch", ".", "gather", "(", "\n", "cand_scores", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", ",", "\n", "out", "=", "scores_buf", ".", "view", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "[", ":", ",", ":", ",", "step", "]", ",", "\n", ")", "\n", "\n", "# copy attention for active hypotheses", "\n", "torch", ".", "index_select", "(", "\n", "attn", "[", ":", ",", ":", ",", ":", "step", "+", "2", "]", ",", "dim", "=", "0", ",", "index", "=", "active_bbsz_idx", ",", "\n", "out", "=", "attn_buf", "[", ":", ",", ":", ",", ":", "step", "+", "2", "]", ",", "\n", ")", "\n", "\n", "# swap buffers", "\n", "tokens", ",", "tokens_buf", "=", "tokens_buf", ",", "tokens", "\n", "scores", ",", "scores_buf", "=", "scores_buf", ",", "scores", "\n", "attn", ",", "attn_buf", "=", "attn_buf", ",", "attn", "\n", "\n", "# reorder incremental state in decoder", "\n", "reorder_state", "=", "active_bbsz_idx", "\n", "\n", "# print(\"RESULT\")", "\n", "# print(scores[0])", "\n", "# print([self.tgt_dict.symbols[x] for x in tokens[0]][:5])", "\n", "# print([self.tgt_dict.symbols[x] for x in tokens[0]][:5])", "\n", "# print([self.tgt_dict.symbols[x] for x in tokens[1]][:5])", "\n", "# print([self.tgt_dict.symbols[x] for x in tokens[2]][:5])", "\n", "\n", "# print([x for x in tokens[0]][:5])", "\n", "# print([self.tgt_dict.symbols[x] for x in tokens[0]][:5])", "\n", "# print([x for x in tokens[1]][:5])", "\n", "# print([x for x in tokens[4]][:5])", "\n", "# print(self.tgt_dict.symbols[1115],self.tgt_dict.symbols[5741])", "\n", "# ,scores,self.tgt_dict.string(tokens[0]),\"try\",self.tgt_dict.string([1,62,4]))", "\n", "\n", "# sort by score descending", "\n", "", "for", "sent", "in", "range", "(", "len", "(", "finalized", ")", ")", ":", "\n", "            ", "finalized", "[", "sent", "]", "=", "sorted", "(", "finalized", "[", "sent", "]", ",", "key", "=", "lambda", "r", ":", "r", "[", "'score'", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "", "return", "finalized", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator._decode": [[974, 996], ["zip", "avg_probs.div_", "avg_probs.log_", "len", "seqgen.SequenceGenerator._decode_one", "seqgen.SequenceGenerator._decode_one", "len", "avg_attn.div_", "avg_probs.add_", "len", "avg_attn.add_"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator._decode_one", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator._decode_one"], ["", "def", "_decode", "(", "self", ",", "tokens", ",", "encoder_outs", ",", "incremental_states", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "models", ")", "==", "1", ":", "\n", "            ", "return", "self", ".", "_decode_one", "(", "tokens", ",", "self", ".", "models", "[", "0", "]", ",", "encoder_outs", "[", "0", "]", ",", "incremental_states", ",", "log_probs", "=", "True", ")", "\n", "\n", "", "avg_probs", "=", "None", "\n", "avg_attn", "=", "None", "\n", "for", "model", ",", "encoder_out", "in", "zip", "(", "self", ".", "models", ",", "encoder_outs", ")", ":", "\n", "            ", "probs", ",", "attn", "=", "self", ".", "_decode_one", "(", "tokens", ",", "model", ",", "encoder_out", ",", "incremental_states", ",", "log_probs", "=", "False", ")", "\n", "if", "avg_probs", "is", "None", ":", "\n", "                ", "avg_probs", "=", "probs", "\n", "", "else", ":", "\n", "                ", "avg_probs", ".", "add_", "(", "probs", ")", "\n", "", "if", "attn", "is", "not", "None", ":", "\n", "                ", "if", "avg_attn", "is", "None", ":", "\n", "                    ", "avg_attn", "=", "attn", "\n", "", "else", ":", "\n", "                    ", "avg_attn", ".", "add_", "(", "attn", ")", "\n", "", "", "", "avg_probs", ".", "div_", "(", "len", "(", "self", ".", "models", ")", ")", "\n", "avg_probs", ".", "log_", "(", ")", "\n", "if", "avg_attn", "is", "not", "None", ":", "\n", "            ", "avg_attn", ".", "div_", "(", "len", "(", "self", ".", "models", ")", ")", "\n", "", "return", "avg_probs", ",", "avg_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator._decode_one": [[997, 1009], ["model.get_normalized_probs", "torch.no_grad", "list", "list", "model.decoder", "model.decoder"], "methods", ["None"], ["", "def", "_decode_one", "(", "self", ",", "tokens", ",", "model", ",", "encoder_out", ",", "incremental_states", ",", "log_probs", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "incremental_states", "[", "model", "]", "is", "not", "None", ":", "\n", "                ", "decoder_out", "=", "list", "(", "model", ".", "decoder", "(", "tokens", ",", "encoder_out", ",", "incremental_states", "[", "model", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "decoder_out", "=", "list", "(", "model", ".", "decoder", "(", "tokens", ",", "encoder_out", ")", ")", "\n", "", "decoder_out", "[", "0", "]", "=", "decoder_out", "[", "0", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "attn", "=", "decoder_out", "[", "1", "]", "\n", "if", "attn", "is", "not", "None", ":", "\n", "                ", "attn", "=", "attn", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "", "", "probs", "=", "model", ".", "get_normalized_probs", "(", "decoder_out", ",", "log_probs", "=", "log_probs", ")", "\n", "return", "probs", ",", "attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.numpy_functions.softmax": [[3, 7], ["numpy.exp", "np.exp.sum", "numpy.max"], "function", ["None"], ["def", "softmax", "(", "x", ")", ":", "\n", "    ", "\"\"\"Compute softmax values for each sets of scores in x.\"\"\"", "\n", "e_x", "=", "np", ".", "exp", "(", "x", "-", "np", ".", "max", "(", "x", ")", ")", "\n", "return", "e_x", "/", "e_x", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.numpy_functions.uniform_vector": [[8, 10], ["numpy.ones"], "function", ["None"], ["", "def", "uniform_vector", "(", "length", ")", ":", "\n", "\t", "return", "np", ".", "ones", "(", "(", "length", ")", ")", "/", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.numpy_functions.make_initial_prior": [[11, 14], ["numpy.log", "numpy.multiply.outer", "numpy.multiply.outer"], "function", ["None"], ["", "def", "make_initial_prior", "(", "initial_image_prior", ",", "initial_rationality_prior", ",", "initial_speaker_prior", ")", ":", "\n", "\n", "\t", "return", "np", ".", "log", "(", "np", ".", "multiply", ".", "outer", "(", "initial_image_prior", ",", "np", ".", "multiply", ".", "outer", "(", "initial_rationality_prior", ",", "initial_speaker_prior", ")", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.softmax": [[7, 11], ["numpy.exp", "np.exp.sum", "numpy.max"], "function", ["None"], ["def", "softmax", "(", "x", ")", ":", "\n", "    ", "\"\"\"Compute softmax values for each sets of scores in x.\"\"\"", "\n", "e_x", "=", "np", ".", "exp", "(", "x", "-", "np", ".", "max", "(", "x", ")", ")", "\n", "return", "e_x", "/", "e_x", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.uniform_vector": [[12, 14], ["numpy.ones"], "function", ["None"], ["", "def", "uniform_vector", "(", "length", ")", ":", "\n", "\t", "return", "np", ".", "ones", "(", "(", "length", ")", ")", "/", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.make_initial_prior": [[15, 23], ["numpy.multiply.outer", "numpy.multiply.outer", "numpy.multiply.outer", "numpy.multiply.outer", "numpy.multiply.outer", "numpy.log"], "function", ["None"], ["", "def", "make_initial_prior", "(", "initial_image_prior", ",", "initial_rationality_prior", ",", "initial_speaker_prior", ",", "initial_hyperprior_prior", ",", "initial_langmod_prior", ",", "initial_qud_prior", ")", ":", "\n", "\n", "    ", "langmod_qud", "=", "np", ".", "multiply", ".", "outer", "(", "initial_langmod_prior", ",", "initial_qud_prior", ")", "\n", "hyperprior_langmod_qud", "=", "np", ".", "multiply", ".", "outer", "(", "initial_hyperprior_prior", ",", "langmod_qud", ")", "\n", "speaker_hyperprior_langmod_qud", "=", "np", ".", "multiply", ".", "outer", "(", "initial_speaker_prior", ",", "hyperprior_langmod_qud", ")", "\n", "rat_speaker_hyperprior_langmod_qud", "=", "np", ".", "multiply", ".", "outer", "(", "initial_rationality_prior", ",", "speaker_hyperprior_langmod_qud", ")", "\n", "image_rat_speaker_hyperprior_langmod_qud", "=", "np", ".", "multiply", ".", "outer", "(", "initial_image_prior", ",", "rat_speaker_hyperprior_langmod_qud", ")", "\n", "return", "np", ".", "log", "(", "image_rat_speaker_hyperprior_langmod_qud", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.display": [[24, 31], ["sorted", "list", "zip", "list", "list", "numpy.exp"], "function", ["None"], ["", "def", "display", "(", "probs", ",", "support", ")", ":", "\n", "# print(\"STUFFF\")", "\n", "# print(probs)", "\n", "# print(support)", "\n", "# print(list(zip(list(support),list(np.exp(probs)))))", "\n", "# print(sorted(list(zip(list(support),list(np.exp(probs)))),key=lambda x : x[1],reverse=True))", "\n", "    ", "return", "sorted", "(", "list", "(", "zip", "(", "list", "(", "support", ")", ",", "list", "(", "np", ".", "exp", "(", "probs", ")", ")", ")", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "[", ":", "10", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.kl": [[32, 43], ["numpy.asarray", "numpy.asarray", "numpy.sum", "numpy.where", "numpy.log"], "function", ["None"], ["", "def", "kl", "(", "p", ",", "q", ")", ":", "\n", "    ", "\"\"\"Kullback-Leibler divergence D(P || Q) for discrete distributions\n    Parameters\n    ----------\n    p, q : array-like, dtype=float, shape=n\n    Discrete probability distributions.\n    \"\"\"", "\n", "p", "=", "np", ".", "asarray", "(", "p", ",", "dtype", "=", "np", ".", "float", ")", "\n", "q", "=", "np", ".", "asarray", "(", "q", ",", "dtype", "=", "np", ".", "float", ")", "\n", "\n", "return", "np", ".", "sum", "(", "np", ".", "where", "(", "p", "!=", "0.0", ",", "p", "*", "np", ".", "log", "(", "p", "/", "q", ")", ",", "0.0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.marginalize_out": [[44, 46], ["numpy.sum", "numpy.sum", "numpy.exp"], "function", ["None"], ["", "def", "marginalize_out", "(", "dimension1", ",", "dimension2", ")", ":", "\n", "    ", "return", "np", ".", "sum", "(", "np", ".", "sum", "(", "np", ".", "exp", "(", "world_posterior", ")", ",", "axis", "=", "state", ".", "dim", "[", "dimension1", "]", "+", "1", ")", ",", "axis", "=", "state", ".", "dim", "[", "dimension2", "]", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.byte_pair_encoding": [[48, 59], ["re.sub", "codecs.open", "subword_nmt.apply_bpe.BPE().process_line", "list", "subword_nmt.apply_bpe.BPE"], "function", ["None"], ["", "def", "byte_pair_encoding", "(", "sentence", ",", "code_path", ")", ":", "\n", "    ", "sentence", "=", "re", ".", "sub", "(", "\"'\"", ",", "\"&apos;\"", ",", "sentence", ")", "\n", "if", "sentence", "[", "-", "1", "]", "in", "list", "(", "\".!?\"", ")", ":", "\n", "        ", "sentence", "=", "sentence", "[", ":", "-", "1", "]", "+", "\" \"", "+", "sentence", "[", "-", "1", "]", "+", "\" \"", "\n", "# sentence+=\" \"", "\n", "\n", "", "code", "=", "codecs", ".", "open", "(", "code_path", ",", "encoding", "=", "'utf-8'", ")", "\n", "out", "=", "BPE", "(", "code", ")", ".", "process_line", "(", "sentence", ")", "\n", "# print(\"ENCODED SENTENCE:\",out)", "\n", "# print(\"CODE PATH\",code_path)", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.byte_pair_decoding": [[60, 72], ["re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub"], "function", ["None"], ["", "def", "byte_pair_decoding", "(", "sentence", ")", ":", "\n", "# sentence = \" \".join(nltk.word_tokenize(sentence))+\" . \"", "\n", "# return re.sub(\"(\\.$)|(@@ )\",\"\",sentence)", "\n", "# sentence = re.sub(\"\\.\",\"\",sentence)", "\n", "    ", "sentence", "=", "re", ".", "sub", "(", "\"\\n\"", ",", "\"\"", ",", "sentence", ")", "\n", "sentence", "=", "re", ".", "sub", "(", "\"&apos;\"", ",", "\"'\"", ",", "sentence", ")", "\n", "sentence", "=", "re", ".", "sub", "(", "\"@@ \"", ",", "\"\"", ",", "sentence", ")", "\n", "sentence", "=", "re", ".", "sub", "(", "\" @-@ \"", ",", "\"\"", ",", "sentence", ")", "\n", "sentence", "=", "re", ".", "sub", "(", "\"@@@\"", ",", "\"\"", ",", "sentence", ")", "\n", "sentence", "=", "re", ".", "sub", "(", "\"\\&quot\"", ",", "\"\\\"\"", ",", "sentence", ")", "\n", "sentence", "=", "re", ".", "sub", "(", "\"&amp\"", ",", "\"&\"", ",", "sentence", ")", "\n", "return", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.helper_functions.unique_list": [[73, 81], ["new_l.append"], "function", ["None"], ["", "def", "unique_list", "(", "l", ")", ":", "\n", "\n", "    ", "new_l", "=", "[", "]", "\n", "for", "item", "in", "l", ":", "\n", "        ", "if", "item", "not", "in", "new_l", ":", "\n", "            ", "new_l", ".", "append", "(", "item", ")", "\n", "\n", "", "", "return", "new_l", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.__init__": [[71, 89], ["dict", "dict", "dict", "dict", "collections.defaultdict", "collections.defaultdict", "print", "time.time", "json.load", "print", "coco.COCO.createIndex", "open", "type", "type", "time.time"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.createIndex"], ["    ", "def", "__init__", "(", "self", ",", "annotation_file", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Constructor of Microsoft COCO helper class for reading and visualizing annotations.\n        :param annotation_file (str): location of annotation file\n        :param image_folder (str): location to the folder that hosts images.\n        :return:\n        \"\"\"", "\n", "# load dataset", "\n", "self", ".", "dataset", ",", "self", ".", "anns", ",", "self", ".", "cats", ",", "self", ".", "imgs", "=", "dict", "(", ")", ",", "dict", "(", ")", ",", "dict", "(", ")", ",", "dict", "(", ")", "\n", "self", ".", "imgToAnns", ",", "self", ".", "catToImgs", "=", "defaultdict", "(", "list", ")", ",", "defaultdict", "(", "list", ")", "\n", "if", "not", "annotation_file", "==", "None", ":", "\n", "            ", "print", "(", "'loading annotations into memory...'", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "dataset", "=", "json", ".", "load", "(", "open", "(", "annotation_file", ",", "'r'", ")", ")", "\n", "assert", "type", "(", "dataset", ")", "==", "dict", ",", "'annotation file format {} not supported'", ".", "format", "(", "type", "(", "dataset", ")", ")", "\n", "print", "(", "'Done (t={:0.2f}s)'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "createIndex", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.createIndex": [[90, 120], ["print", "print", "collections.defaultdict", "collections.defaultdict", "imgToAnns[].append", "catToImgs[].append"], "methods", ["None"], ["", "", "def", "createIndex", "(", "self", ")", ":", "\n", "# create index", "\n", "        ", "print", "(", "'creating index...'", ")", "\n", "anns", ",", "cats", ",", "imgs", "=", "{", "}", ",", "{", "}", ",", "{", "}", "\n", "imgToAnns", ",", "catToImgs", "=", "defaultdict", "(", "list", ")", ",", "defaultdict", "(", "list", ")", "\n", "if", "'annotations'", "in", "self", ".", "dataset", ":", "\n", "            ", "for", "ann", "in", "self", ".", "dataset", "[", "'annotations'", "]", ":", "\n", "                ", "imgToAnns", "[", "ann", "[", "'image_id'", "]", "]", ".", "append", "(", "ann", ")", "\n", "anns", "[", "ann", "[", "'id'", "]", "]", "=", "ann", "\n", "\n", "", "", "if", "'images'", "in", "self", ".", "dataset", ":", "\n", "            ", "for", "img", "in", "self", ".", "dataset", "[", "'images'", "]", ":", "\n", "                ", "imgs", "[", "img", "[", "'id'", "]", "]", "=", "img", "\n", "\n", "", "", "if", "'categories'", "in", "self", ".", "dataset", ":", "\n", "            ", "for", "cat", "in", "self", ".", "dataset", "[", "'categories'", "]", ":", "\n", "                ", "cats", "[", "cat", "[", "'id'", "]", "]", "=", "cat", "\n", "\n", "", "", "if", "'annotations'", "in", "self", ".", "dataset", "and", "'categories'", "in", "self", ".", "dataset", ":", "\n", "            ", "for", "ann", "in", "self", ".", "dataset", "[", "'annotations'", "]", ":", "\n", "                ", "catToImgs", "[", "ann", "[", "'category_id'", "]", "]", ".", "append", "(", "ann", "[", "'image_id'", "]", ")", "\n", "\n", "", "", "print", "(", "'index created!'", ")", "\n", "\n", "# create class members", "\n", "self", ".", "anns", "=", "anns", "\n", "self", ".", "imgToAnns", "=", "imgToAnns", "\n", "self", ".", "catToImgs", "=", "catToImgs", "\n", "self", ".", "imgs", "=", "imgs", "\n", "self", ".", "cats", "=", "cats", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.info": [[121, 128], ["coco.COCO.dataset[].items", "print"], "methods", ["None"], ["", "def", "info", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Print information about the annotation file.\n        :return:\n        \"\"\"", "\n", "for", "key", ",", "value", "in", "self", ".", "dataset", "[", "'info'", "]", ".", "items", "(", ")", ":", "\n", "            ", "print", "(", "'{}: {}'", ".", "format", "(", "key", ",", "value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.getAnnIds": [[129, 156], ["coco._isArrayLike", "coco._isArrayLike", "len", "len", "len", "list", "len", "itertools.chain.from_iterable", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco._isArrayLike", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco._isArrayLike"], ["", "", "def", "getAnnIds", "(", "self", ",", "imgIds", "=", "[", "]", ",", "catIds", "=", "[", "]", ",", "areaRng", "=", "[", "]", ",", "iscrowd", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Get ann ids that satisfy given filter conditions. default skips that filter\n        :param imgIds  (int array)     : get anns for given imgs\n               catIds  (int array)     : get anns for given cats\n               areaRng (float array)   : get anns for given area range (e.g. [0 inf])\n               iscrowd (boolean)       : get anns for given crowd label (False or True)\n        :return: ids (int array)       : integer array of ann ids\n        \"\"\"", "\n", "imgIds", "=", "imgIds", "if", "_isArrayLike", "(", "imgIds", ")", "else", "[", "imgIds", "]", "\n", "catIds", "=", "catIds", "if", "_isArrayLike", "(", "catIds", ")", "else", "[", "catIds", "]", "\n", "\n", "if", "len", "(", "imgIds", ")", "==", "len", "(", "catIds", ")", "==", "len", "(", "areaRng", ")", "==", "0", ":", "\n", "            ", "anns", "=", "self", ".", "dataset", "[", "'annotations'", "]", "\n", "", "else", ":", "\n", "            ", "if", "not", "len", "(", "imgIds", ")", "==", "0", ":", "\n", "                ", "lists", "=", "[", "self", ".", "imgToAnns", "[", "imgId", "]", "for", "imgId", "in", "imgIds", "if", "imgId", "in", "self", ".", "imgToAnns", "]", "\n", "anns", "=", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "lists", ")", ")", "\n", "", "else", ":", "\n", "                ", "anns", "=", "self", ".", "dataset", "[", "'annotations'", "]", "\n", "", "anns", "=", "anns", "if", "len", "(", "catIds", ")", "==", "0", "else", "[", "ann", "for", "ann", "in", "anns", "if", "ann", "[", "'category_id'", "]", "in", "catIds", "]", "\n", "anns", "=", "anns", "if", "len", "(", "areaRng", ")", "==", "0", "else", "[", "ann", "for", "ann", "in", "anns", "if", "ann", "[", "'area'", "]", ">", "areaRng", "[", "0", "]", "and", "ann", "[", "'area'", "]", "<", "areaRng", "[", "1", "]", "]", "\n", "", "if", "not", "iscrowd", "==", "None", ":", "\n", "            ", "ids", "=", "[", "ann", "[", "'id'", "]", "for", "ann", "in", "anns", "if", "ann", "[", "'iscrowd'", "]", "==", "iscrowd", "]", "\n", "", "else", ":", "\n", "            ", "ids", "=", "[", "ann", "[", "'id'", "]", "for", "ann", "in", "anns", "]", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.getCatIds": [[157, 178], ["coco._isArrayLike", "coco._isArrayLike", "coco._isArrayLike", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco._isArrayLike", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco._isArrayLike", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco._isArrayLike"], ["", "def", "getCatIds", "(", "self", ",", "catNms", "=", "[", "]", ",", "supNms", "=", "[", "]", ",", "catIds", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\"\n        filtering parameters. default skips that filter.\n        :param catNms (str array)  : get cats for given cat names\n        :param supNms (str array)  : get cats for given supercategory names\n        :param catIds (int array)  : get cats for given cat ids\n        :return: ids (int array)   : integer array of cat ids\n        \"\"\"", "\n", "catNms", "=", "catNms", "if", "_isArrayLike", "(", "catNms", ")", "else", "[", "catNms", "]", "\n", "supNms", "=", "supNms", "if", "_isArrayLike", "(", "supNms", ")", "else", "[", "supNms", "]", "\n", "catIds", "=", "catIds", "if", "_isArrayLike", "(", "catIds", ")", "else", "[", "catIds", "]", "\n", "\n", "if", "len", "(", "catNms", ")", "==", "len", "(", "supNms", ")", "==", "len", "(", "catIds", ")", "==", "0", ":", "\n", "            ", "cats", "=", "self", ".", "dataset", "[", "'categories'", "]", "\n", "", "else", ":", "\n", "            ", "cats", "=", "self", ".", "dataset", "[", "'categories'", "]", "\n", "cats", "=", "cats", "if", "len", "(", "catNms", ")", "==", "0", "else", "[", "cat", "for", "cat", "in", "cats", "if", "cat", "[", "'name'", "]", "in", "catNms", "]", "\n", "cats", "=", "cats", "if", "len", "(", "supNms", ")", "==", "0", "else", "[", "cat", "for", "cat", "in", "cats", "if", "cat", "[", "'supercategory'", "]", "in", "supNms", "]", "\n", "cats", "=", "cats", "if", "len", "(", "catIds", ")", "==", "0", "else", "[", "cat", "for", "cat", "in", "cats", "if", "cat", "[", "'id'", "]", "in", "catIds", "]", "\n", "", "ids", "=", "[", "cat", "[", "'id'", "]", "for", "cat", "in", "cats", "]", "\n", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.getImgIds": [[179, 199], ["list", "coco._isArrayLike", "coco._isArrayLike", "len", "len", "coco.COCO.imgs.keys", "set", "enumerate", "set", "set", "len"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco._isArrayLike", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco._isArrayLike"], ["", "def", "getImgIds", "(", "self", ",", "imgIds", "=", "[", "]", ",", "catIds", "=", "[", "]", ")", ":", "\n", "        ", "'''\n        Get img ids that satisfy given filter conditions.\n        :param imgIds (int array) : get imgs for given ids\n        :param catIds (int array) : get imgs with all given cats\n        :return: ids (int array)  : integer array of img ids\n        '''", "\n", "imgIds", "=", "imgIds", "if", "_isArrayLike", "(", "imgIds", ")", "else", "[", "imgIds", "]", "\n", "catIds", "=", "catIds", "if", "_isArrayLike", "(", "catIds", ")", "else", "[", "catIds", "]", "\n", "\n", "if", "len", "(", "imgIds", ")", "==", "len", "(", "catIds", ")", "==", "0", ":", "\n", "            ", "ids", "=", "self", ".", "imgs", ".", "keys", "(", ")", "\n", "", "else", ":", "\n", "            ", "ids", "=", "set", "(", "imgIds", ")", "\n", "for", "i", ",", "catId", "in", "enumerate", "(", "catIds", ")", ":", "\n", "                ", "if", "i", "==", "0", "and", "len", "(", "ids", ")", "==", "0", ":", "\n", "                    ", "ids", "=", "set", "(", "self", ".", "catToImgs", "[", "catId", "]", ")", "\n", "", "else", ":", "\n", "                    ", "ids", "&=", "set", "(", "self", ".", "catToImgs", "[", "catId", "]", ")", "\n", "", "", "", "return", "list", "(", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.loadAnns": [[200, 210], ["coco._isArrayLike", "type"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco._isArrayLike"], ["", "def", "loadAnns", "(", "self", ",", "ids", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\"\n        Load anns with the specified ids.\n        :param ids (int array)       : integer ids specifying anns\n        :return: anns (object array) : loaded ann objects\n        \"\"\"", "\n", "if", "_isArrayLike", "(", "ids", ")", ":", "\n", "            ", "return", "[", "self", ".", "anns", "[", "id", "]", "for", "id", "in", "ids", "]", "\n", "", "elif", "type", "(", "ids", ")", "==", "int", ":", "\n", "            ", "return", "[", "self", ".", "anns", "[", "ids", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.loadCats": [[211, 221], ["coco._isArrayLike", "type"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco._isArrayLike"], ["", "", "def", "loadCats", "(", "self", ",", "ids", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\"\n        Load cats with the specified ids.\n        :param ids (int array)       : integer ids specifying cats\n        :return: cats (object array) : loaded cat objects\n        \"\"\"", "\n", "if", "_isArrayLike", "(", "ids", ")", ":", "\n", "            ", "return", "[", "self", ".", "cats", "[", "id", "]", "for", "id", "in", "ids", "]", "\n", "", "elif", "type", "(", "ids", ")", "==", "int", ":", "\n", "            ", "return", "[", "self", ".", "cats", "[", "ids", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.loadImgs": [[222, 232], ["coco._isArrayLike", "type"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco._isArrayLike"], ["", "", "def", "loadImgs", "(", "self", ",", "ids", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\"\n        Load anns with the specified ids.\n        :param ids (int array)       : integer ids specifying img\n        :return: imgs (object array) : loaded img objects\n        \"\"\"", "\n", "if", "_isArrayLike", "(", "ids", ")", ":", "\n", "            ", "return", "[", "self", ".", "imgs", "[", "id", "]", "for", "id", "in", "ids", "]", "\n", "", "elif", "type", "(", "ids", ")", "==", "int", ":", "\n", "            ", "return", "[", "self", ".", "imgs", "[", "ids", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.showAnns": [[233, 296], ["len", "matplotlib.gca", "matplotlib.gca.set_autoscale_on", "matplotlib.collections.PatchCollection", "matplotlib.gca.add_collection", "matplotlib.collections.PatchCollection", "matplotlib.gca.add_collection", "Exception", "numpy.array", "matplotlib.plot", "matplotlib.plot", "print", "type", "maskUtils.decode", "numpy.ones", "range", "matplotlib.gca.imshow", "type", "numpy.array", "numpy.all", "numpy.array().reshape", "polygons.append", "color.append", "type", "maskUtils.frPyObjects", "numpy.dstack", "matplotlib.plot", "matplotlib.patches.Polygon", "numpy.array", "numpy.random.random().tolist", "numpy.random.random", "numpy.array", "int", "coco.COCO.loadCats", "numpy.random.random", "len"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.mask.decode", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.loadCats"], ["", "", "def", "showAnns", "(", "self", ",", "anns", ")", ":", "\n", "        ", "\"\"\"\n        Display the specified annotations.\n        :param anns (array of object): annotations to display\n        :return: None\n        \"\"\"", "\n", "if", "len", "(", "anns", ")", "==", "0", ":", "\n", "            ", "return", "0", "\n", "", "if", "'segmentation'", "in", "anns", "[", "0", "]", "or", "'keypoints'", "in", "anns", "[", "0", "]", ":", "\n", "            ", "datasetType", "=", "'instances'", "\n", "", "elif", "'caption'", "in", "anns", "[", "0", "]", ":", "\n", "            ", "datasetType", "=", "'captions'", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'datasetType not supported'", ")", "\n", "", "if", "datasetType", "==", "'instances'", ":", "\n", "            ", "ax", "=", "plt", ".", "gca", "(", ")", "\n", "ax", ".", "set_autoscale_on", "(", "False", ")", "\n", "polygons", "=", "[", "]", "\n", "color", "=", "[", "]", "\n", "for", "ann", "in", "anns", ":", "\n", "                ", "c", "=", "(", "np", ".", "random", ".", "random", "(", "(", "1", ",", "3", ")", ")", "*", "0.6", "+", "0.4", ")", ".", "tolist", "(", ")", "[", "0", "]", "\n", "if", "'segmentation'", "in", "ann", ":", "\n", "                    ", "if", "type", "(", "ann", "[", "'segmentation'", "]", ")", "==", "list", ":", "\n", "# polygon", "\n", "                        ", "for", "seg", "in", "ann", "[", "'segmentation'", "]", ":", "\n", "                            ", "poly", "=", "np", ".", "array", "(", "seg", ")", ".", "reshape", "(", "(", "int", "(", "len", "(", "seg", ")", "/", "2", ")", ",", "2", ")", ")", "\n", "polygons", ".", "append", "(", "Polygon", "(", "poly", ")", ")", "\n", "color", ".", "append", "(", "c", ")", "\n", "", "", "else", ":", "\n", "# mask", "\n", "                        ", "t", "=", "self", ".", "imgs", "[", "ann", "[", "'image_id'", "]", "]", "\n", "if", "type", "(", "ann", "[", "'segmentation'", "]", "[", "'counts'", "]", ")", "==", "list", ":", "\n", "                            ", "rle", "=", "maskUtils", ".", "frPyObjects", "(", "[", "ann", "[", "'segmentation'", "]", "]", ",", "t", "[", "'height'", "]", ",", "t", "[", "'width'", "]", ")", "\n", "", "else", ":", "\n", "                            ", "rle", "=", "[", "ann", "[", "'segmentation'", "]", "]", "\n", "", "m", "=", "maskUtils", ".", "decode", "(", "rle", ")", "\n", "img", "=", "np", ".", "ones", "(", "(", "m", ".", "shape", "[", "0", "]", ",", "m", ".", "shape", "[", "1", "]", ",", "3", ")", ")", "\n", "if", "ann", "[", "'iscrowd'", "]", "==", "1", ":", "\n", "                            ", "color_mask", "=", "np", ".", "array", "(", "[", "2.0", ",", "166.0", ",", "101.0", "]", ")", "/", "255", "\n", "", "if", "ann", "[", "'iscrowd'", "]", "==", "0", ":", "\n", "                            ", "color_mask", "=", "np", ".", "random", ".", "random", "(", "(", "1", ",", "3", ")", ")", ".", "tolist", "(", ")", "[", "0", "]", "\n", "", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "                            ", "img", "[", ":", ",", ":", ",", "i", "]", "=", "color_mask", "[", "i", "]", "\n", "", "ax", ".", "imshow", "(", "np", ".", "dstack", "(", "(", "img", ",", "m", "*", "0.5", ")", ")", ")", "\n", "", "", "if", "'keypoints'", "in", "ann", "and", "type", "(", "ann", "[", "'keypoints'", "]", ")", "==", "list", ":", "\n", "# turn skeleton into zero-based index", "\n", "                    ", "sks", "=", "np", ".", "array", "(", "self", ".", "loadCats", "(", "ann", "[", "'category_id'", "]", ")", "[", "0", "]", "[", "'skeleton'", "]", ")", "-", "1", "\n", "kp", "=", "np", ".", "array", "(", "ann", "[", "'keypoints'", "]", ")", "\n", "x", "=", "kp", "[", "0", ":", ":", "3", "]", "\n", "y", "=", "kp", "[", "1", ":", ":", "3", "]", "\n", "v", "=", "kp", "[", "2", ":", ":", "3", "]", "\n", "for", "sk", "in", "sks", ":", "\n", "                        ", "if", "np", ".", "all", "(", "v", "[", "sk", "]", ">", "0", ")", ":", "\n", "                            ", "plt", ".", "plot", "(", "x", "[", "sk", "]", ",", "y", "[", "sk", "]", ",", "linewidth", "=", "3", ",", "color", "=", "c", ")", "\n", "", "", "plt", ".", "plot", "(", "x", "[", "v", ">", "0", "]", ",", "y", "[", "v", ">", "0", "]", ",", "'o'", ",", "markersize", "=", "8", ",", "markerfacecolor", "=", "c", ",", "markeredgecolor", "=", "'k'", ",", "markeredgewidth", "=", "2", ")", "\n", "plt", ".", "plot", "(", "x", "[", "v", ">", "1", "]", ",", "y", "[", "v", ">", "1", "]", ",", "'o'", ",", "markersize", "=", "8", ",", "markerfacecolor", "=", "c", ",", "markeredgecolor", "=", "c", ",", "markeredgewidth", "=", "2", ")", "\n", "", "", "p", "=", "PatchCollection", "(", "polygons", ",", "facecolor", "=", "color", ",", "linewidths", "=", "0", ",", "alpha", "=", "0.4", ")", "\n", "ax", ".", "add_collection", "(", "p", ")", "\n", "p", "=", "PatchCollection", "(", "polygons", ",", "facecolor", "=", "'none'", ",", "edgecolors", "=", "color", ",", "linewidths", "=", "2", ")", "\n", "ax", ".", "add_collection", "(", "p", ")", "\n", "", "elif", "datasetType", "==", "'captions'", ":", "\n", "            ", "for", "ann", "in", "anns", ":", "\n", "                ", "print", "(", "ann", "[", "'caption'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.loadRes": [[297, 357], ["coco.COCO", "print", "time.time", "print", "coco.COCO.createIndex", "json.load", "type", "set", "enumerate", "type", "type", "open", "type", "coco.COCO.loadNumpyAnnotations", "set", "set", "set", "set", "copy.deepcopy", "enumerate", "coco.COCO.getImgIds", "copy.deepcopy", "enumerate", "time.time", "maskUtils.area", "copy.deepcopy", "enumerate", "maskUtils.toBbox", "numpy.min", "numpy.max", "numpy.min", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.createIndex", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.loadNumpyAnnotations", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.getImgIds", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.mask.area", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.mask.toBbox"], ["", "", "", "def", "loadRes", "(", "self", ",", "resFile", ")", ":", "\n", "        ", "\"\"\"\n        Load result file and return a result api object.\n        :param   resFile (str)     : file name of result file\n        :return: res (obj)         : result api object\n        \"\"\"", "\n", "res", "=", "COCO", "(", ")", "\n", "res", ".", "dataset", "[", "'images'", "]", "=", "[", "img", "for", "img", "in", "self", ".", "dataset", "[", "'images'", "]", "]", "\n", "\n", "print", "(", "'Loading and preparing results...'", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "if", "type", "(", "resFile", ")", "==", "str", "or", "type", "(", "resFile", ")", "==", "unicode", ":", "\n", "            ", "anns", "=", "json", ".", "load", "(", "open", "(", "resFile", ")", ")", "\n", "", "elif", "type", "(", "resFile", ")", "==", "np", ".", "ndarray", ":", "\n", "            ", "anns", "=", "self", ".", "loadNumpyAnnotations", "(", "resFile", ")", "\n", "", "else", ":", "\n", "            ", "anns", "=", "resFile", "\n", "", "assert", "type", "(", "anns", ")", "==", "list", ",", "'results in not an array of objects'", "\n", "annsImgIds", "=", "[", "ann", "[", "'image_id'", "]", "for", "ann", "in", "anns", "]", "\n", "assert", "set", "(", "annsImgIds", ")", "==", "(", "set", "(", "annsImgIds", ")", "&", "set", "(", "self", ".", "getImgIds", "(", ")", ")", ")", ",", "'Results do not correspond to current coco set'", "\n", "if", "'caption'", "in", "anns", "[", "0", "]", ":", "\n", "            ", "imgIds", "=", "set", "(", "[", "img", "[", "'id'", "]", "for", "img", "in", "res", ".", "dataset", "[", "'images'", "]", "]", ")", "&", "set", "(", "[", "ann", "[", "'image_id'", "]", "for", "ann", "in", "anns", "]", ")", "\n", "res", ".", "dataset", "[", "'images'", "]", "=", "[", "img", "for", "img", "in", "res", ".", "dataset", "[", "'images'", "]", "if", "img", "[", "'id'", "]", "in", "imgIds", "]", "\n", "for", "id", ",", "ann", "in", "enumerate", "(", "anns", ")", ":", "\n", "                ", "ann", "[", "'id'", "]", "=", "id", "+", "1", "\n", "", "", "elif", "'bbox'", "in", "anns", "[", "0", "]", "and", "not", "anns", "[", "0", "]", "[", "'bbox'", "]", "==", "[", "]", ":", "\n", "            ", "res", ".", "dataset", "[", "'categories'", "]", "=", "copy", ".", "deepcopy", "(", "self", ".", "dataset", "[", "'categories'", "]", ")", "\n", "for", "id", ",", "ann", "in", "enumerate", "(", "anns", ")", ":", "\n", "                ", "bb", "=", "ann", "[", "'bbox'", "]", "\n", "x1", ",", "x2", ",", "y1", ",", "y2", "=", "[", "bb", "[", "0", "]", ",", "bb", "[", "0", "]", "+", "bb", "[", "2", "]", ",", "bb", "[", "1", "]", ",", "bb", "[", "1", "]", "+", "bb", "[", "3", "]", "]", "\n", "if", "not", "'segmentation'", "in", "ann", ":", "\n", "                    ", "ann", "[", "'segmentation'", "]", "=", "[", "[", "x1", ",", "y1", ",", "x1", ",", "y2", ",", "x2", ",", "y2", ",", "x2", ",", "y1", "]", "]", "\n", "", "ann", "[", "'area'", "]", "=", "bb", "[", "2", "]", "*", "bb", "[", "3", "]", "\n", "ann", "[", "'id'", "]", "=", "id", "+", "1", "\n", "ann", "[", "'iscrowd'", "]", "=", "0", "\n", "", "", "elif", "'segmentation'", "in", "anns", "[", "0", "]", ":", "\n", "            ", "res", ".", "dataset", "[", "'categories'", "]", "=", "copy", ".", "deepcopy", "(", "self", ".", "dataset", "[", "'categories'", "]", ")", "\n", "for", "id", ",", "ann", "in", "enumerate", "(", "anns", ")", ":", "\n", "# now only support compressed RLE format as segmentation results", "\n", "                ", "ann", "[", "'area'", "]", "=", "maskUtils", ".", "area", "(", "ann", "[", "'segmentation'", "]", ")", "\n", "if", "not", "'bbox'", "in", "ann", ":", "\n", "                    ", "ann", "[", "'bbox'", "]", "=", "maskUtils", ".", "toBbox", "(", "ann", "[", "'segmentation'", "]", ")", "\n", "", "ann", "[", "'id'", "]", "=", "id", "+", "1", "\n", "ann", "[", "'iscrowd'", "]", "=", "0", "\n", "", "", "elif", "'keypoints'", "in", "anns", "[", "0", "]", ":", "\n", "            ", "res", ".", "dataset", "[", "'categories'", "]", "=", "copy", ".", "deepcopy", "(", "self", ".", "dataset", "[", "'categories'", "]", ")", "\n", "for", "id", ",", "ann", "in", "enumerate", "(", "anns", ")", ":", "\n", "                ", "s", "=", "ann", "[", "'keypoints'", "]", "\n", "x", "=", "s", "[", "0", ":", ":", "3", "]", "\n", "y", "=", "s", "[", "1", ":", ":", "3", "]", "\n", "x0", ",", "x1", ",", "y0", ",", "y1", "=", "np", ".", "min", "(", "x", ")", ",", "np", ".", "max", "(", "x", ")", ",", "np", ".", "min", "(", "y", ")", ",", "np", ".", "max", "(", "y", ")", "\n", "ann", "[", "'area'", "]", "=", "(", "x1", "-", "x0", ")", "*", "(", "y1", "-", "y0", ")", "\n", "ann", "[", "'id'", "]", "=", "id", "+", "1", "\n", "ann", "[", "'bbox'", "]", "=", "[", "x0", ",", "y0", ",", "x1", "-", "x0", ",", "y1", "-", "y0", "]", "\n", "", "", "print", "(", "'DONE (t={:0.2f}s)'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "\n", "res", ".", "dataset", "[", "'annotations'", "]", "=", "anns", "\n", "res", ".", "createIndex", "(", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.download": [[358, 381], ["len", "enumerate", "print", "len", "coco.COCO.imgs.values", "coco.COCO.loadImgs", "os.path.exists", "os.makedirs", "time.time", "os.path.join", "print", "os.path.exists", "urlretrieve", "time.time"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.loadImgs"], ["", "def", "download", "(", "self", ",", "tarDir", "=", "None", ",", "imgIds", "=", "[", "]", ")", ":", "\n", "        ", "'''\n        Download COCO images from mscoco.org server.\n        :param tarDir (str): COCO results directory name\n               imgIds (list): images to be downloaded\n        :return:\n        '''", "\n", "if", "tarDir", "is", "None", ":", "\n", "            ", "print", "(", "'Please specify target directory'", ")", "\n", "return", "-", "1", "\n", "", "if", "len", "(", "imgIds", ")", "==", "0", ":", "\n", "            ", "imgs", "=", "self", ".", "imgs", ".", "values", "(", ")", "\n", "", "else", ":", "\n", "            ", "imgs", "=", "self", ".", "loadImgs", "(", "imgIds", ")", "\n", "", "N", "=", "len", "(", "imgs", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "tarDir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "tarDir", ")", "\n", "", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "            ", "tic", "=", "time", ".", "time", "(", ")", "\n", "fname", "=", "os", ".", "path", ".", "join", "(", "tarDir", ",", "img", "[", "'file_name'", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "fname", ")", ":", "\n", "                ", "urlretrieve", "(", "img", "[", "'coco_url'", "]", ",", "fname", ")", "\n", "", "print", "(", "'downloaded {}/{} images (t={:0.1f}s)'", ".", "format", "(", "i", ",", "N", ",", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.loadNumpyAnnotations": [[382, 404], ["print", "print", "range", "type", "print", "int", "int"], "methods", ["None"], ["", "", "def", "loadNumpyAnnotations", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"\n        Convert result data from a numpy array [Nx7] where each row contains {imageID,x1,y1,w,h,score,class}\n        :param  data (numpy.ndarray)\n        :return: annotations (python nested list)\n        \"\"\"", "\n", "print", "(", "'Converting ndarray to lists...'", ")", "\n", "assert", "(", "type", "(", "data", ")", "==", "np", ".", "ndarray", ")", "\n", "print", "(", "data", ".", "shape", ")", "\n", "assert", "(", "data", ".", "shape", "[", "1", "]", "==", "7", ")", "\n", "N", "=", "data", ".", "shape", "[", "0", "]", "\n", "ann", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "            ", "if", "i", "%", "1000000", "==", "0", ":", "\n", "                ", "print", "(", "'{}/{}'", ".", "format", "(", "i", ",", "N", ")", ")", "\n", "", "ann", "+=", "[", "{", "\n", "'image_id'", ":", "int", "(", "data", "[", "i", ",", "0", "]", ")", ",", "\n", "'bbox'", ":", "[", "data", "[", "i", ",", "1", "]", ",", "data", "[", "i", ",", "2", "]", ",", "data", "[", "i", ",", "3", "]", ",", "data", "[", "i", ",", "4", "]", "]", ",", "\n", "'score'", ":", "data", "[", "i", ",", "5", "]", ",", "\n", "'category_id'", ":", "int", "(", "data", "[", "i", ",", "6", "]", ")", ",", "\n", "}", "]", "\n", "", "return", "ann", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.annToRLE": [[405, 425], ["type", "maskUtils.frPyObjects", "maskUtils.merge", "type", "maskUtils.frPyObjects"], "methods", ["None"], ["", "def", "annToRLE", "(", "self", ",", "ann", ")", ":", "\n", "        ", "\"\"\"\n        Convert annotation which can be polygons, uncompressed RLE to RLE.\n        :return: binary mask (numpy 2D array)\n        \"\"\"", "\n", "t", "=", "self", ".", "imgs", "[", "ann", "[", "'image_id'", "]", "]", "\n", "h", ",", "w", "=", "t", "[", "'height'", "]", ",", "t", "[", "'width'", "]", "\n", "segm", "=", "ann", "[", "'segmentation'", "]", "\n", "if", "type", "(", "segm", ")", "==", "list", ":", "\n", "# polygon -- a single object might consist of multiple parts", "\n", "# we merge all parts into one mask rle code", "\n", "            ", "rles", "=", "maskUtils", ".", "frPyObjects", "(", "segm", ",", "h", ",", "w", ")", "\n", "rle", "=", "maskUtils", ".", "merge", "(", "rles", ")", "\n", "", "elif", "type", "(", "segm", "[", "'counts'", "]", ")", "==", "list", ":", "\n", "# uncompressed RLE", "\n", "            ", "rle", "=", "maskUtils", ".", "frPyObjects", "(", "segm", ",", "h", ",", "w", ")", "\n", "", "else", ":", "\n", "# rle", "\n", "            ", "rle", "=", "ann", "[", "'segmentation'", "]", "\n", "", "return", "rle", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.annToMask": [[426, 434], ["coco.COCO.annToRLE", "maskUtils.decode"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.annToRLE", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.mask.decode"], ["", "def", "annToMask", "(", "self", ",", "ann", ")", ":", "\n", "        ", "\"\"\"\n        Convert annotation which can be polygons, uncompressed RLE, or RLE to binary mask.\n        :return: binary mask (numpy 2D array)\n        \"\"\"", "\n", "rle", "=", "self", ".", "annToRLE", "(", "ann", ")", "\n", "m", "=", "maskUtils", ".", "decode", "(", "rle", ")", "\n", "return", "m", "", "", "", ""]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco._isArrayLike": [[66, 68], ["hasattr", "hasattr"], "function", ["None"], ["", "def", "_isArrayLike", "(", "obj", ")", ":", "\n", "    ", "return", "hasattr", "(", "obj", ",", "'__iter__'", ")", "and", "hasattr", "(", "obj", ",", "'__len__'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.mask.encode": [[80, 86], ["len", "cocoapi.encode", "len", "cocoapi.encode", "bimask.reshape"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.mask.encode", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.mask.encode"], ["def", "encode", "(", "bimask", ")", ":", "\n", "    ", "if", "len", "(", "bimask", ".", "shape", ")", "==", "3", ":", "\n", "        ", "return", "_mask", ".", "encode", "(", "bimask", ")", "\n", "", "elif", "len", "(", "bimask", ".", "shape", ")", "==", "2", ":", "\n", "        ", "h", ",", "w", "=", "bimask", ".", "shape", "\n", "return", "_mask", ".", "encode", "(", "bimask", ".", "reshape", "(", "(", "h", ",", "w", ",", "1", ")", ",", "order", "=", "'F'", ")", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.mask.decode": [[87, 92], ["type", "cocoapi.decode", "cocoapi.decode"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.mask.decode", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.mask.decode"], ["", "", "def", "decode", "(", "rleObjs", ")", ":", "\n", "    ", "if", "type", "(", "rleObjs", ")", "==", "list", ":", "\n", "        ", "return", "_mask", ".", "decode", "(", "rleObjs", ")", "\n", "", "else", ":", "\n", "        ", "return", "_mask", ".", "decode", "(", "[", "rleObjs", "]", ")", "[", ":", ",", ":", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.mask.area": [[93, 98], ["type", "cocoapi.area", "cocoapi.area"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.mask.area", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.mask.area"], ["", "", "def", "area", "(", "rleObjs", ")", ":", "\n", "    ", "if", "type", "(", "rleObjs", ")", "==", "list", ":", "\n", "        ", "return", "_mask", ".", "area", "(", "rleObjs", ")", "\n", "", "else", ":", "\n", "        ", "return", "_mask", ".", "area", "(", "[", "rleObjs", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.mask.toBbox": [[99, 104], ["type", "cocoapi.toBbox", "cocoapi.toBbox"], "function", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.mask.toBbox", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.mask.toBbox"], ["", "", "def", "toBbox", "(", "rleObjs", ")", ":", "\n", "    ", "if", "type", "(", "rleObjs", ")", "==", "list", ":", "\n", "        ", "return", "_mask", ".", "toBbox", "(", "rleObjs", ")", "\n", "", "else", ":", "\n", "        ", "return", "_mask", ".", "toBbox", "(", "[", "rleObjs", "]", ")", "[", "0", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.cocoeval.COCOeval.__init__": [[60, 83], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "cocoeval.Params", "print", "sorted", "sorted", "cocoGt.getImgIds", "cocoGt.getCatIds"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.getImgIds", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.getCatIds"], ["    ", "def", "__init__", "(", "self", ",", "cocoGt", "=", "None", ",", "cocoDt", "=", "None", ",", "iouType", "=", "'segm'", ")", ":", "\n", "        ", "'''\n        Initialize CocoEval using coco APIs for gt and dt\n        :param cocoGt: coco object with ground truth annotations\n        :param cocoDt: coco object with detection results\n        :return: None\n        '''", "\n", "if", "not", "iouType", ":", "\n", "            ", "print", "(", "'iouType not specified. use default iouType segm'", ")", "\n", "", "self", ".", "cocoGt", "=", "cocoGt", "# ground truth COCO API", "\n", "self", ".", "cocoDt", "=", "cocoDt", "# detections COCO API", "\n", "self", ".", "params", "=", "{", "}", "# evaluation parameters", "\n", "self", ".", "evalImgs", "=", "defaultdict", "(", "list", ")", "# per-image per-category evaluation results [KxAxI] elements", "\n", "self", ".", "eval", "=", "{", "}", "# accumulated evaluation results", "\n", "self", ".", "_gts", "=", "defaultdict", "(", "list", ")", "# gt for evaluation", "\n", "self", ".", "_dts", "=", "defaultdict", "(", "list", ")", "# dt for evaluation", "\n", "self", ".", "params", "=", "Params", "(", "iouType", "=", "iouType", ")", "# parameters", "\n", "self", ".", "_paramsEval", "=", "{", "}", "# parameters for evaluation", "\n", "self", ".", "stats", "=", "[", "]", "# result summarization", "\n", "self", ".", "ious", "=", "{", "}", "# ious between all gts and dts", "\n", "if", "not", "cocoGt", "is", "None", ":", "\n", "            ", "self", ".", "params", ".", "imgIds", "=", "sorted", "(", "cocoGt", ".", "getImgIds", "(", ")", ")", "\n", "self", ".", "params", ".", "catIds", "=", "sorted", "(", "cocoGt", ".", "getCatIds", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.cocoeval.COCOeval._prepare": [[85, 121], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "cocoeval.COCOeval.cocoGt.loadAnns", "cocoeval.COCOeval.cocoDt.loadAnns", "cocoeval.COCOeval.cocoGt.loadAnns", "cocoeval.COCOeval.cocoDt.loadAnns", "cocoeval.COCOeval._prepare._toMask"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.loadAnns", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.loadAnns", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.loadAnns", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.coco.COCO.loadAnns"], ["", "", "def", "_prepare", "(", "self", ")", ":", "\n", "        ", "'''\n        Prepare ._gts and ._dts for evaluation based on params\n        :return: None\n        '''", "\n", "def", "_toMask", "(", "anns", ",", "coco", ")", ":", "\n", "# modify ann['segmentation'] by reference", "\n", "            ", "for", "ann", "in", "anns", ":", "\n", "                ", "rle", "=", "coco", ".", "annToRLE", "(", "ann", ")", "\n", "ann", "[", "'segmentation'", "]", "=", "rle", "\n", "", "", "p", "=", "self", ".", "params", "\n", "if", "p", ".", "useCats", ":", "\n", "            ", "gts", "=", "self", ".", "cocoGt", ".", "loadAnns", "(", "self", ".", "cocoGt", ".", "getAnnIds", "(", "imgIds", "=", "p", ".", "imgIds", ",", "catIds", "=", "p", ".", "catIds", ")", ")", "\n", "dts", "=", "self", ".", "cocoDt", ".", "loadAnns", "(", "self", ".", "cocoDt", ".", "getAnnIds", "(", "imgIds", "=", "p", ".", "imgIds", ",", "catIds", "=", "p", ".", "catIds", ")", ")", "\n", "", "else", ":", "\n", "            ", "gts", "=", "self", ".", "cocoGt", ".", "loadAnns", "(", "self", ".", "cocoGt", ".", "getAnnIds", "(", "imgIds", "=", "p", ".", "imgIds", ")", ")", "\n", "dts", "=", "self", ".", "cocoDt", ".", "loadAnns", "(", "self", ".", "cocoDt", ".", "getAnnIds", "(", "imgIds", "=", "p", ".", "imgIds", ")", ")", "\n", "\n", "# convert ground truth to mask if iouType == 'segm'", "\n", "", "if", "p", ".", "iouType", "==", "'segm'", ":", "\n", "            ", "_toMask", "(", "gts", ",", "self", ".", "cocoGt", ")", "\n", "_toMask", "(", "dts", ",", "self", ".", "cocoDt", ")", "\n", "# set ignore flag", "\n", "", "for", "gt", "in", "gts", ":", "\n", "            ", "gt", "[", "'ignore'", "]", "=", "gt", "[", "'ignore'", "]", "if", "'ignore'", "in", "gt", "else", "0", "\n", "gt", "[", "'ignore'", "]", "=", "'iscrowd'", "in", "gt", "and", "gt", "[", "'iscrowd'", "]", "\n", "if", "p", ".", "iouType", "==", "'keypoints'", ":", "\n", "                ", "gt", "[", "'ignore'", "]", "=", "(", "gt", "[", "'num_keypoints'", "]", "==", "0", ")", "or", "gt", "[", "'ignore'", "]", "\n", "", "", "self", ".", "_gts", "=", "defaultdict", "(", "list", ")", "# gt for evaluation", "\n", "self", ".", "_dts", "=", "defaultdict", "(", "list", ")", "# dt for evaluation", "\n", "for", "gt", "in", "gts", ":", "\n", "            ", "self", ".", "_gts", "[", "gt", "[", "'image_id'", "]", ",", "gt", "[", "'category_id'", "]", "]", ".", "append", "(", "gt", ")", "\n", "", "for", "dt", "in", "dts", ":", "\n", "            ", "self", ".", "_dts", "[", "dt", "[", "'image_id'", "]", ",", "dt", "[", "'category_id'", "]", "]", ".", "append", "(", "dt", ")", "\n", "", "self", ".", "evalImgs", "=", "defaultdict", "(", "list", ")", "# per-image per-category evaluation results", "\n", "self", ".", "eval", "=", "{", "}", "# accumulated evaluation results", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.cocoeval.COCOeval.evaluate": [[122, 163], ["time.time", "print", "print", "list", "sorted", "cocoeval.COCOeval._prepare", "copy.deepcopy", "time.time", "print", "print", "numpy.unique", "list", "cocoeval.COCOeval.computeIoU"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.cocoeval.COCOeval._prepare", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.cocoeval.COCOeval.computeIoU"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "'''\n        Run per image evaluation on given images and store results (a list of dict) in self.evalImgs\n        :return: None\n        '''", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'Running per image evaluation...'", ")", "\n", "p", "=", "self", ".", "params", "\n", "# add backward compatibility if useSegm is specified in params", "\n", "if", "not", "p", ".", "useSegm", "is", "None", ":", "\n", "            ", "p", ".", "iouType", "=", "'segm'", "if", "p", ".", "useSegm", "==", "1", "else", "'bbox'", "\n", "print", "(", "'useSegm (deprecated) is not None. Running {} evaluation'", ".", "format", "(", "p", ".", "iouType", ")", ")", "\n", "", "print", "(", "'Evaluate annotation type *{}*'", ".", "format", "(", "p", ".", "iouType", ")", ")", "\n", "p", ".", "imgIds", "=", "list", "(", "np", ".", "unique", "(", "p", ".", "imgIds", ")", ")", "\n", "if", "p", ".", "useCats", ":", "\n", "            ", "p", ".", "catIds", "=", "list", "(", "np", ".", "unique", "(", "p", ".", "catIds", ")", ")", "\n", "", "p", ".", "maxDets", "=", "sorted", "(", "p", ".", "maxDets", ")", "\n", "self", ".", "params", "=", "p", "\n", "\n", "self", ".", "_prepare", "(", ")", "\n", "# loop through images, area range, max detection number", "\n", "catIds", "=", "p", ".", "catIds", "if", "p", ".", "useCats", "else", "[", "-", "1", "]", "\n", "\n", "if", "p", ".", "iouType", "==", "'segm'", "or", "p", ".", "iouType", "==", "'bbox'", ":", "\n", "            ", "computeIoU", "=", "self", ".", "computeIoU", "\n", "", "elif", "p", ".", "iouType", "==", "'keypoints'", ":", "\n", "            ", "computeIoU", "=", "self", ".", "computeOks", "\n", "", "self", ".", "ious", "=", "{", "(", "imgId", ",", "catId", ")", ":", "computeIoU", "(", "imgId", ",", "catId", ")", "for", "imgId", "in", "p", ".", "imgIds", "\n", "for", "catId", "in", "catIds", "}", "\n", "\n", "evaluateImg", "=", "self", ".", "evaluateImg", "\n", "maxDet", "=", "p", ".", "maxDets", "[", "-", "1", "]", "\n", "self", ".", "evalImgs", "=", "[", "evaluateImg", "(", "imgId", ",", "catId", ",", "areaRng", ",", "maxDet", ")", "\n", "for", "catId", "in", "catIds", "\n", "for", "areaRng", "in", "p", ".", "areaRng", "\n", "for", "imgId", "in", "p", ".", "imgIds", "\n", "]", "\n", "self", ".", "_paramsEval", "=", "copy", ".", "deepcopy", "(", "self", ".", "params", ")", "\n", "toc", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'DONE (t={:0.2f}s).'", ".", "format", "(", "toc", "-", "tic", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.cocoeval.COCOeval.computeIoU": [[164, 192], ["numpy.argsort", "mask.iou", "len", "int", "len", "len", "Exception"], "methods", ["None"], ["", "def", "computeIoU", "(", "self", ",", "imgId", ",", "catId", ")", ":", "\n", "        ", "p", "=", "self", ".", "params", "\n", "if", "p", ".", "useCats", ":", "\n", "            ", "gt", "=", "self", ".", "_gts", "[", "imgId", ",", "catId", "]", "\n", "dt", "=", "self", ".", "_dts", "[", "imgId", ",", "catId", "]", "\n", "", "else", ":", "\n", "            ", "gt", "=", "[", "_", "for", "cId", "in", "p", ".", "catIds", "for", "_", "in", "self", ".", "_gts", "[", "imgId", ",", "cId", "]", "]", "\n", "dt", "=", "[", "_", "for", "cId", "in", "p", ".", "catIds", "for", "_", "in", "self", ".", "_dts", "[", "imgId", ",", "cId", "]", "]", "\n", "", "if", "len", "(", "gt", ")", "==", "0", "and", "len", "(", "dt", ")", "==", "0", ":", "\n", "            ", "return", "[", "]", "\n", "", "inds", "=", "np", ".", "argsort", "(", "[", "-", "d", "[", "'score'", "]", "for", "d", "in", "dt", "]", ",", "kind", "=", "'mergesort'", ")", "\n", "dt", "=", "[", "dt", "[", "i", "]", "for", "i", "in", "inds", "]", "\n", "if", "len", "(", "dt", ")", ">", "p", ".", "maxDets", "[", "-", "1", "]", ":", "\n", "            ", "dt", "=", "dt", "[", "0", ":", "p", ".", "maxDets", "[", "-", "1", "]", "]", "\n", "\n", "", "if", "p", ".", "iouType", "==", "'segm'", ":", "\n", "            ", "g", "=", "[", "g", "[", "'segmentation'", "]", "for", "g", "in", "gt", "]", "\n", "d", "=", "[", "d", "[", "'segmentation'", "]", "for", "d", "in", "dt", "]", "\n", "", "elif", "p", ".", "iouType", "==", "'bbox'", ":", "\n", "            ", "g", "=", "[", "g", "[", "'bbox'", "]", "for", "g", "in", "gt", "]", "\n", "d", "=", "[", "d", "[", "'bbox'", "]", "for", "d", "in", "dt", "]", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'unknown iouType for iou computation'", ")", "\n", "\n", "# compute iou between each dt and gt region", "\n", "", "iscrowd", "=", "[", "int", "(", "o", "[", "'iscrowd'", "]", ")", "for", "o", "in", "gt", "]", "\n", "ious", "=", "maskUtils", ".", "iou", "(", "d", ",", "g", ",", "iscrowd", ")", "\n", "return", "ious", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.cocoeval.COCOeval.computeOks": [[193, 235], ["numpy.argsort", "numpy.zeros", "len", "enumerate", "len", "numpy.array", "numpy.array", "numpy.count_nonzero", "enumerate", "len", "len", "len", "len", "numpy.array", "numpy.zeros", "numpy.sum", "numpy.max", "numpy.max", "numpy.max", "numpy.max", "numpy.exp", "numpy.spacing"], "methods", ["None"], ["", "def", "computeOks", "(", "self", ",", "imgId", ",", "catId", ")", ":", "\n", "        ", "p", "=", "self", ".", "params", "\n", "# dimention here should be Nxm", "\n", "gts", "=", "self", ".", "_gts", "[", "imgId", ",", "catId", "]", "\n", "dts", "=", "self", ".", "_dts", "[", "imgId", ",", "catId", "]", "\n", "inds", "=", "np", ".", "argsort", "(", "[", "-", "d", "[", "'score'", "]", "for", "d", "in", "dts", "]", ",", "kind", "=", "'mergesort'", ")", "\n", "dts", "=", "[", "dts", "[", "i", "]", "for", "i", "in", "inds", "]", "\n", "if", "len", "(", "dts", ")", ">", "p", ".", "maxDets", "[", "-", "1", "]", ":", "\n", "            ", "dts", "=", "dts", "[", "0", ":", "p", ".", "maxDets", "[", "-", "1", "]", "]", "\n", "# if len(gts) == 0 and len(dts) == 0:", "\n", "", "if", "len", "(", "gts", ")", "==", "0", "or", "len", "(", "dts", ")", "==", "0", ":", "\n", "            ", "return", "[", "]", "\n", "", "ious", "=", "np", ".", "zeros", "(", "(", "len", "(", "dts", ")", ",", "len", "(", "gts", ")", ")", ")", "\n", "sigmas", "=", "np", ".", "array", "(", "[", ".26", ",", ".25", ",", ".25", ",", ".35", ",", ".35", ",", ".79", ",", ".79", ",", ".72", ",", ".72", ",", ".62", ",", ".62", ",", "1.07", ",", "1.07", ",", ".87", ",", ".87", ",", ".89", ",", ".89", "]", ")", "/", "10.0", "\n", "vars", "=", "(", "sigmas", "*", "2", ")", "**", "2", "\n", "k", "=", "len", "(", "sigmas", ")", "\n", "# compute oks between each detection and ground truth object", "\n", "for", "j", ",", "gt", "in", "enumerate", "(", "gts", ")", ":", "\n", "# create bounds for ignore regions(double the gt bbox)", "\n", "            ", "g", "=", "np", ".", "array", "(", "gt", "[", "'keypoints'", "]", ")", "\n", "xg", "=", "g", "[", "0", ":", ":", "3", "]", ";", "yg", "=", "g", "[", "1", ":", ":", "3", "]", ";", "vg", "=", "g", "[", "2", ":", ":", "3", "]", "\n", "k1", "=", "np", ".", "count_nonzero", "(", "vg", ">", "0", ")", "\n", "bb", "=", "gt", "[", "'bbox'", "]", "\n", "x0", "=", "bb", "[", "0", "]", "-", "bb", "[", "2", "]", ";", "x1", "=", "bb", "[", "0", "]", "+", "bb", "[", "2", "]", "*", "2", "\n", "y0", "=", "bb", "[", "1", "]", "-", "bb", "[", "3", "]", ";", "y1", "=", "bb", "[", "1", "]", "+", "bb", "[", "3", "]", "*", "2", "\n", "for", "i", ",", "dt", "in", "enumerate", "(", "dts", ")", ":", "\n", "                ", "d", "=", "np", ".", "array", "(", "dt", "[", "'keypoints'", "]", ")", "\n", "xd", "=", "d", "[", "0", ":", ":", "3", "]", ";", "yd", "=", "d", "[", "1", ":", ":", "3", "]", "\n", "if", "k1", ">", "0", ":", "\n", "# measure the per-keypoint distance if keypoints visible", "\n", "                    ", "dx", "=", "xd", "-", "xg", "\n", "dy", "=", "yd", "-", "yg", "\n", "", "else", ":", "\n", "# measure minimum distance to keypoints in (x0,y0) & (x1,y1)", "\n", "                    ", "z", "=", "np", ".", "zeros", "(", "(", "k", ")", ")", "\n", "dx", "=", "np", ".", "max", "(", "(", "z", ",", "x0", "-", "xd", ")", ",", "axis", "=", "0", ")", "+", "np", ".", "max", "(", "(", "z", ",", "xd", "-", "x1", ")", ",", "axis", "=", "0", ")", "\n", "dy", "=", "np", ".", "max", "(", "(", "z", ",", "y0", "-", "yd", ")", ",", "axis", "=", "0", ")", "+", "np", ".", "max", "(", "(", "z", ",", "yd", "-", "y1", ")", ",", "axis", "=", "0", ")", "\n", "", "e", "=", "(", "dx", "**", "2", "+", "dy", "**", "2", ")", "/", "vars", "/", "(", "gt", "[", "'area'", "]", "+", "np", ".", "spacing", "(", "1", ")", ")", "/", "2", "\n", "if", "k1", ">", "0", ":", "\n", "                    ", "e", "=", "e", "[", "vg", ">", "0", "]", "\n", "", "ious", "[", "i", ",", "j", "]", "=", "np", ".", "sum", "(", "np", ".", "exp", "(", "-", "e", ")", ")", "/", "e", ".", "shape", "[", "0", "]", "\n", "", "", "return", "ious", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.cocoeval.COCOeval.evaluateImg": [[236, 314], ["numpy.argsort", "numpy.argsort", "len", "len", "len", "numpy.zeros", "numpy.zeros", "numpy.array", "numpy.zeros", "numpy.array().reshape", "numpy.logical_or", "int", "enumerate", "numpy.logical_and", "len", "len", "len", "len", "enumerate", "numpy.array", "len", "numpy.repeat", "min", "enumerate"], "methods", ["None"], ["", "def", "evaluateImg", "(", "self", ",", "imgId", ",", "catId", ",", "aRng", ",", "maxDet", ")", ":", "\n", "        ", "'''\n        perform evaluation for single category and image\n        :return: dict (single image results)\n        '''", "\n", "p", "=", "self", ".", "params", "\n", "if", "p", ".", "useCats", ":", "\n", "            ", "gt", "=", "self", ".", "_gts", "[", "imgId", ",", "catId", "]", "\n", "dt", "=", "self", ".", "_dts", "[", "imgId", ",", "catId", "]", "\n", "", "else", ":", "\n", "            ", "gt", "=", "[", "_", "for", "cId", "in", "p", ".", "catIds", "for", "_", "in", "self", ".", "_gts", "[", "imgId", ",", "cId", "]", "]", "\n", "dt", "=", "[", "_", "for", "cId", "in", "p", ".", "catIds", "for", "_", "in", "self", ".", "_dts", "[", "imgId", ",", "cId", "]", "]", "\n", "", "if", "len", "(", "gt", ")", "==", "0", "and", "len", "(", "dt", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "for", "g", "in", "gt", ":", "\n", "            ", "if", "g", "[", "'ignore'", "]", "or", "(", "g", "[", "'area'", "]", "<", "aRng", "[", "0", "]", "or", "g", "[", "'area'", "]", ">", "aRng", "[", "1", "]", ")", ":", "\n", "                ", "g", "[", "'_ignore'", "]", "=", "1", "\n", "", "else", ":", "\n", "                ", "g", "[", "'_ignore'", "]", "=", "0", "\n", "\n", "# sort dt highest score first, sort gt ignore last", "\n", "", "", "gtind", "=", "np", ".", "argsort", "(", "[", "g", "[", "'_ignore'", "]", "for", "g", "in", "gt", "]", ",", "kind", "=", "'mergesort'", ")", "\n", "gt", "=", "[", "gt", "[", "i", "]", "for", "i", "in", "gtind", "]", "\n", "dtind", "=", "np", ".", "argsort", "(", "[", "-", "d", "[", "'score'", "]", "for", "d", "in", "dt", "]", ",", "kind", "=", "'mergesort'", ")", "\n", "dt", "=", "[", "dt", "[", "i", "]", "for", "i", "in", "dtind", "[", "0", ":", "maxDet", "]", "]", "\n", "iscrowd", "=", "[", "int", "(", "o", "[", "'iscrowd'", "]", ")", "for", "o", "in", "gt", "]", "\n", "# load computed ious", "\n", "ious", "=", "self", ".", "ious", "[", "imgId", ",", "catId", "]", "[", ":", ",", "gtind", "]", "if", "len", "(", "self", ".", "ious", "[", "imgId", ",", "catId", "]", ")", ">", "0", "else", "self", ".", "ious", "[", "imgId", ",", "catId", "]", "\n", "\n", "T", "=", "len", "(", "p", ".", "iouThrs", ")", "\n", "G", "=", "len", "(", "gt", ")", "\n", "D", "=", "len", "(", "dt", ")", "\n", "gtm", "=", "np", ".", "zeros", "(", "(", "T", ",", "G", ")", ")", "\n", "dtm", "=", "np", ".", "zeros", "(", "(", "T", ",", "D", ")", ")", "\n", "gtIg", "=", "np", ".", "array", "(", "[", "g", "[", "'_ignore'", "]", "for", "g", "in", "gt", "]", ")", "\n", "dtIg", "=", "np", ".", "zeros", "(", "(", "T", ",", "D", ")", ")", "\n", "if", "not", "len", "(", "ious", ")", "==", "0", ":", "\n", "            ", "for", "tind", ",", "t", "in", "enumerate", "(", "p", ".", "iouThrs", ")", ":", "\n", "                ", "for", "dind", ",", "d", "in", "enumerate", "(", "dt", ")", ":", "\n", "# information about best match so far (m=-1 -> unmatched)", "\n", "                    ", "iou", "=", "min", "(", "[", "t", ",", "1", "-", "1e-10", "]", ")", "\n", "m", "=", "-", "1", "\n", "for", "gind", ",", "g", "in", "enumerate", "(", "gt", ")", ":", "\n", "# if this gt already matched, and not a crowd, continue", "\n", "                        ", "if", "gtm", "[", "tind", ",", "gind", "]", ">", "0", "and", "not", "iscrowd", "[", "gind", "]", ":", "\n", "                            ", "continue", "\n", "# if dt matched to reg gt, and on ignore gt, stop", "\n", "", "if", "m", ">", "-", "1", "and", "gtIg", "[", "m", "]", "==", "0", "and", "gtIg", "[", "gind", "]", "==", "1", ":", "\n", "                            ", "break", "\n", "# continue to next gt unless better match made", "\n", "", "if", "ious", "[", "dind", ",", "gind", "]", "<", "iou", ":", "\n", "                            ", "continue", "\n", "# if match successful and best so far, store appropriately", "\n", "", "iou", "=", "ious", "[", "dind", ",", "gind", "]", "\n", "m", "=", "gind", "\n", "# if match made store id of match for both dt and gt", "\n", "", "if", "m", "==", "-", "1", ":", "\n", "                        ", "continue", "\n", "", "dtIg", "[", "tind", ",", "dind", "]", "=", "gtIg", "[", "m", "]", "\n", "dtm", "[", "tind", ",", "dind", "]", "=", "gt", "[", "m", "]", "[", "'id'", "]", "\n", "gtm", "[", "tind", ",", "m", "]", "=", "d", "[", "'id'", "]", "\n", "# set unmatched detections outside of area range to ignore", "\n", "", "", "", "a", "=", "np", ".", "array", "(", "[", "d", "[", "'area'", "]", "<", "aRng", "[", "0", "]", "or", "d", "[", "'area'", "]", ">", "aRng", "[", "1", "]", "for", "d", "in", "dt", "]", ")", ".", "reshape", "(", "(", "1", ",", "len", "(", "dt", ")", ")", ")", "\n", "dtIg", "=", "np", ".", "logical_or", "(", "dtIg", ",", "np", ".", "logical_and", "(", "dtm", "==", "0", ",", "np", ".", "repeat", "(", "a", ",", "T", ",", "0", ")", ")", ")", "\n", "# store results for given image and category", "\n", "return", "{", "\n", "'image_id'", ":", "imgId", ",", "\n", "'category_id'", ":", "catId", ",", "\n", "'aRng'", ":", "aRng", ",", "\n", "'maxDet'", ":", "maxDet", ",", "\n", "'dtIds'", ":", "[", "d", "[", "'id'", "]", "for", "d", "in", "dt", "]", ",", "\n", "'gtIds'", ":", "[", "g", "[", "'id'", "]", "for", "g", "in", "gt", "]", ",", "\n", "'dtMatches'", ":", "dtm", ",", "\n", "'gtMatches'", ":", "gtm", ",", "\n", "'dtScores'", ":", "[", "d", "[", "'score'", "]", "for", "d", "in", "dt", "]", ",", "\n", "'gtIgnore'", ":", "gtIg", ",", "\n", "'dtIgnore'", ":", "dtIg", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.cocoeval.COCOeval.accumulate": [[316, 422], ["print", "time.time", "len", "len", "len", "len", "set", "set", "set", "set", "len", "len", "enumerate", "time.time", "print", "print", "len", "numpy.ones", "numpy.ones", "numpy.ones", "map", "enumerate", "datetime.datetime.now().strftime", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "map", "numpy.concatenate", "numpy.argsort", "numpy.concatenate", "numpy.count_nonzero", "numpy.logical_and", "numpy.logical_and", "numpy.cumsum().astype", "numpy.cumsum().astype", "enumerate", "datetime.datetime.now", "len", "numpy.concatenate", "numpy.concatenate", "numpy.logical_not", "numpy.logical_not", "numpy.logical_not", "zip", "numpy.array", "numpy.array", "len", "numpy.zeros", "numpy.zeros", "pr.tolist.tolist.tolist", "q.tolist.tolist.tolist", "range", "numpy.searchsorted", "numpy.array", "numpy.array", "tuple", "numpy.cumsum", "numpy.cumsum", "enumerate", "numpy.spacing"], "methods", ["None"], ["", "def", "accumulate", "(", "self", ",", "p", "=", "None", ")", ":", "\n", "        ", "'''\n        Accumulate per image evaluation results and store the result in self.eval\n        :param p: input params for evaluation\n        :return: None\n        '''", "\n", "print", "(", "'Accumulating evaluation results...'", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "if", "not", "self", ".", "evalImgs", ":", "\n", "            ", "print", "(", "'Please run evaluate() first'", ")", "\n", "# allows input customized parameters", "\n", "", "if", "p", "is", "None", ":", "\n", "            ", "p", "=", "self", ".", "params", "\n", "", "p", ".", "catIds", "=", "p", ".", "catIds", "if", "p", ".", "useCats", "==", "1", "else", "[", "-", "1", "]", "\n", "T", "=", "len", "(", "p", ".", "iouThrs", ")", "\n", "R", "=", "len", "(", "p", ".", "recThrs", ")", "\n", "K", "=", "len", "(", "p", ".", "catIds", ")", "if", "p", ".", "useCats", "else", "1", "\n", "A", "=", "len", "(", "p", ".", "areaRng", ")", "\n", "M", "=", "len", "(", "p", ".", "maxDets", ")", "\n", "precision", "=", "-", "np", ".", "ones", "(", "(", "T", ",", "R", ",", "K", ",", "A", ",", "M", ")", ")", "# -1 for the precision of absent categories", "\n", "recall", "=", "-", "np", ".", "ones", "(", "(", "T", ",", "K", ",", "A", ",", "M", ")", ")", "\n", "scores", "=", "-", "np", ".", "ones", "(", "(", "T", ",", "R", ",", "K", ",", "A", ",", "M", ")", ")", "\n", "\n", "# create dictionary for future indexing", "\n", "_pe", "=", "self", ".", "_paramsEval", "\n", "catIds", "=", "_pe", ".", "catIds", "if", "_pe", ".", "useCats", "else", "[", "-", "1", "]", "\n", "setK", "=", "set", "(", "catIds", ")", "\n", "setA", "=", "set", "(", "map", "(", "tuple", ",", "_pe", ".", "areaRng", ")", ")", "\n", "setM", "=", "set", "(", "_pe", ".", "maxDets", ")", "\n", "setI", "=", "set", "(", "_pe", ".", "imgIds", ")", "\n", "# get inds to evaluate", "\n", "k_list", "=", "[", "n", "for", "n", ",", "k", "in", "enumerate", "(", "p", ".", "catIds", ")", "if", "k", "in", "setK", "]", "\n", "m_list", "=", "[", "m", "for", "n", ",", "m", "in", "enumerate", "(", "p", ".", "maxDets", ")", "if", "m", "in", "setM", "]", "\n", "a_list", "=", "[", "n", "for", "n", ",", "a", "in", "enumerate", "(", "map", "(", "lambda", "x", ":", "tuple", "(", "x", ")", ",", "p", ".", "areaRng", ")", ")", "if", "a", "in", "setA", "]", "\n", "i_list", "=", "[", "n", "for", "n", ",", "i", "in", "enumerate", "(", "p", ".", "imgIds", ")", "if", "i", "in", "setI", "]", "\n", "I0", "=", "len", "(", "_pe", ".", "imgIds", ")", "\n", "A0", "=", "len", "(", "_pe", ".", "areaRng", ")", "\n", "# retrieve E at each category, area range, and max number of detections", "\n", "for", "k", ",", "k0", "in", "enumerate", "(", "k_list", ")", ":", "\n", "            ", "Nk", "=", "k0", "*", "A0", "*", "I0", "\n", "for", "a", ",", "a0", "in", "enumerate", "(", "a_list", ")", ":", "\n", "                ", "Na", "=", "a0", "*", "I0", "\n", "for", "m", ",", "maxDet", "in", "enumerate", "(", "m_list", ")", ":", "\n", "                    ", "E", "=", "[", "self", ".", "evalImgs", "[", "Nk", "+", "Na", "+", "i", "]", "for", "i", "in", "i_list", "]", "\n", "E", "=", "[", "e", "for", "e", "in", "E", "if", "not", "e", "is", "None", "]", "\n", "if", "len", "(", "E", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "dtScores", "=", "np", ".", "concatenate", "(", "[", "e", "[", "'dtScores'", "]", "[", "0", ":", "maxDet", "]", "for", "e", "in", "E", "]", ")", "\n", "\n", "# different sorting method generates slightly different results.", "\n", "# mergesort is used to be consistent as Matlab implementation.", "\n", "inds", "=", "np", ".", "argsort", "(", "-", "dtScores", ",", "kind", "=", "'mergesort'", ")", "\n", "dtScoresSorted", "=", "dtScores", "[", "inds", "]", "\n", "\n", "dtm", "=", "np", ".", "concatenate", "(", "[", "e", "[", "'dtMatches'", "]", "[", ":", ",", "0", ":", "maxDet", "]", "for", "e", "in", "E", "]", ",", "axis", "=", "1", ")", "[", ":", ",", "inds", "]", "\n", "dtIg", "=", "np", ".", "concatenate", "(", "[", "e", "[", "'dtIgnore'", "]", "[", ":", ",", "0", ":", "maxDet", "]", "for", "e", "in", "E", "]", ",", "axis", "=", "1", ")", "[", ":", ",", "inds", "]", "\n", "gtIg", "=", "np", ".", "concatenate", "(", "[", "e", "[", "'gtIgnore'", "]", "for", "e", "in", "E", "]", ")", "\n", "npig", "=", "np", ".", "count_nonzero", "(", "gtIg", "==", "0", ")", "\n", "if", "npig", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "tps", "=", "np", ".", "logical_and", "(", "dtm", ",", "np", ".", "logical_not", "(", "dtIg", ")", ")", "\n", "fps", "=", "np", ".", "logical_and", "(", "np", ".", "logical_not", "(", "dtm", ")", ",", "np", ".", "logical_not", "(", "dtIg", ")", ")", "\n", "\n", "tp_sum", "=", "np", ".", "cumsum", "(", "tps", ",", "axis", "=", "1", ")", ".", "astype", "(", "dtype", "=", "np", ".", "float", ")", "\n", "fp_sum", "=", "np", ".", "cumsum", "(", "fps", ",", "axis", "=", "1", ")", ".", "astype", "(", "dtype", "=", "np", ".", "float", ")", "\n", "for", "t", ",", "(", "tp", ",", "fp", ")", "in", "enumerate", "(", "zip", "(", "tp_sum", ",", "fp_sum", ")", ")", ":", "\n", "                        ", "tp", "=", "np", ".", "array", "(", "tp", ")", "\n", "fp", "=", "np", ".", "array", "(", "fp", ")", "\n", "nd", "=", "len", "(", "tp", ")", "\n", "rc", "=", "tp", "/", "npig", "\n", "pr", "=", "tp", "/", "(", "fp", "+", "tp", "+", "np", ".", "spacing", "(", "1", ")", ")", "\n", "q", "=", "np", ".", "zeros", "(", "(", "R", ",", ")", ")", "\n", "ss", "=", "np", ".", "zeros", "(", "(", "R", ",", ")", ")", "\n", "\n", "if", "nd", ":", "\n", "                            ", "recall", "[", "t", ",", "k", ",", "a", ",", "m", "]", "=", "rc", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                            ", "recall", "[", "t", ",", "k", ",", "a", ",", "m", "]", "=", "0", "\n", "\n", "# numpy is slow without cython optimization for accessing elements", "\n", "# use python array gets significant speed improvement", "\n", "", "pr", "=", "pr", ".", "tolist", "(", ")", ";", "q", "=", "q", ".", "tolist", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "nd", "-", "1", ",", "0", ",", "-", "1", ")", ":", "\n", "                            ", "if", "pr", "[", "i", "]", ">", "pr", "[", "i", "-", "1", "]", ":", "\n", "                                ", "pr", "[", "i", "-", "1", "]", "=", "pr", "[", "i", "]", "\n", "\n", "", "", "inds", "=", "np", ".", "searchsorted", "(", "rc", ",", "p", ".", "recThrs", ",", "side", "=", "'left'", ")", "\n", "try", ":", "\n", "                            ", "for", "ri", ",", "pi", "in", "enumerate", "(", "inds", ")", ":", "\n", "                                ", "q", "[", "ri", "]", "=", "pr", "[", "pi", "]", "\n", "ss", "[", "ri", "]", "=", "dtScoresSorted", "[", "pi", "]", "\n", "", "", "except", ":", "\n", "                            ", "pass", "\n", "", "precision", "[", "t", ",", ":", ",", "k", ",", "a", ",", "m", "]", "=", "np", ".", "array", "(", "q", ")", "\n", "scores", "[", "t", ",", ":", ",", "k", ",", "a", ",", "m", "]", "=", "np", ".", "array", "(", "ss", ")", "\n", "", "", "", "", "self", ".", "eval", "=", "{", "\n", "'params'", ":", "p", ",", "\n", "'counts'", ":", "[", "T", ",", "R", ",", "K", ",", "A", ",", "M", "]", ",", "\n", "'date'", ":", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ")", ",", "\n", "'precision'", ":", "precision", ",", "\n", "'recall'", ":", "recall", ",", "\n", "'scores'", ":", "scores", ",", "\n", "}", "\n", "toc", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'DONE (t={:0.2f}s).'", ".", "format", "(", "toc", "-", "tic", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.cocoeval.COCOeval.summarize": [[423, 495], ["cocoeval.COCOeval.summarize"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.cocoeval.COCOeval.summarize"], ["", "def", "summarize", "(", "self", ")", ":", "\n", "        ", "'''\n        Compute and display summary metrics for evaluation results.\n        Note this functin can *only* be applied on the default parameter setting\n        '''", "\n", "def", "_summarize", "(", "ap", "=", "1", ",", "iouThr", "=", "None", ",", "areaRng", "=", "'all'", ",", "maxDets", "=", "100", ")", ":", "\n", "            ", "p", "=", "self", ".", "params", "\n", "iStr", "=", "' {:<18} {} @[ IoU={:<9} | area={:>6s} | maxDets={:>3d} ] = {:0.3f}'", "\n", "titleStr", "=", "'Average Precision'", "if", "ap", "==", "1", "else", "'Average Recall'", "\n", "typeStr", "=", "'(AP)'", "if", "ap", "==", "1", "else", "'(AR)'", "\n", "iouStr", "=", "'{:0.2f}:{:0.2f}'", ".", "format", "(", "p", ".", "iouThrs", "[", "0", "]", ",", "p", ".", "iouThrs", "[", "-", "1", "]", ")", "if", "iouThr", "is", "None", "else", "'{:0.2f}'", ".", "format", "(", "iouThr", ")", "\n", "\n", "aind", "=", "[", "i", "for", "i", ",", "aRng", "in", "enumerate", "(", "p", ".", "areaRngLbl", ")", "if", "aRng", "==", "areaRng", "]", "\n", "mind", "=", "[", "i", "for", "i", ",", "mDet", "in", "enumerate", "(", "p", ".", "maxDets", ")", "if", "mDet", "==", "maxDets", "]", "\n", "if", "ap", "==", "1", ":", "\n", "# dimension of precision: [TxRxKxAxM]", "\n", "                ", "s", "=", "self", ".", "eval", "[", "'precision'", "]", "\n", "# IoU", "\n", "if", "iouThr", "is", "not", "None", ":", "\n", "                    ", "t", "=", "np", ".", "where", "(", "iouThr", "==", "p", ".", "iouThrs", ")", "[", "0", "]", "\n", "s", "=", "s", "[", "t", "]", "\n", "", "s", "=", "s", "[", ":", ",", ":", ",", ":", ",", "aind", ",", "mind", "]", "\n", "", "else", ":", "\n", "# dimension of recall: [TxKxAxM]", "\n", "                ", "s", "=", "self", ".", "eval", "[", "'recall'", "]", "\n", "if", "iouThr", "is", "not", "None", ":", "\n", "                    ", "t", "=", "np", ".", "where", "(", "iouThr", "==", "p", ".", "iouThrs", ")", "[", "0", "]", "\n", "s", "=", "s", "[", "t", "]", "\n", "", "s", "=", "s", "[", ":", ",", ":", ",", "aind", ",", "mind", "]", "\n", "", "if", "len", "(", "s", "[", "s", ">", "-", "1", "]", ")", "==", "0", ":", "\n", "                ", "mean_s", "=", "-", "1", "\n", "", "else", ":", "\n", "                ", "mean_s", "=", "np", ".", "mean", "(", "s", "[", "s", ">", "-", "1", "]", ")", "\n", "", "print", "(", "iStr", ".", "format", "(", "titleStr", ",", "typeStr", ",", "iouStr", ",", "areaRng", ",", "maxDets", ",", "mean_s", ")", ")", "\n", "return", "mean_s", "\n", "", "def", "_summarizeDets", "(", ")", ":", "\n", "            ", "stats", "=", "np", ".", "zeros", "(", "(", "12", ",", ")", ")", "\n", "stats", "[", "0", "]", "=", "_summarize", "(", "1", ")", "\n", "stats", "[", "1", "]", "=", "_summarize", "(", "1", ",", "iouThr", "=", ".5", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "2", "]", "=", "_summarize", "(", "1", ",", "iouThr", "=", ".75", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "3", "]", "=", "_summarize", "(", "1", ",", "areaRng", "=", "'small'", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "4", "]", "=", "_summarize", "(", "1", ",", "areaRng", "=", "'medium'", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "5", "]", "=", "_summarize", "(", "1", ",", "areaRng", "=", "'large'", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "6", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ")", "\n", "stats", "[", "7", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "1", "]", ")", "\n", "stats", "[", "8", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "9", "]", "=", "_summarize", "(", "0", ",", "areaRng", "=", "'small'", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "10", "]", "=", "_summarize", "(", "0", ",", "areaRng", "=", "'medium'", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "11", "]", "=", "_summarize", "(", "0", ",", "areaRng", "=", "'large'", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "return", "stats", "\n", "", "def", "_summarizeKps", "(", ")", ":", "\n", "            ", "stats", "=", "np", ".", "zeros", "(", "(", "10", ",", ")", ")", "\n", "stats", "[", "0", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "20", ")", "\n", "stats", "[", "1", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "20", ",", "iouThr", "=", ".5", ")", "\n", "stats", "[", "2", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "20", ",", "iouThr", "=", ".75", ")", "\n", "stats", "[", "3", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "20", ",", "areaRng", "=", "'medium'", ")", "\n", "stats", "[", "4", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "20", ",", "areaRng", "=", "'large'", ")", "\n", "stats", "[", "5", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "20", ")", "\n", "stats", "[", "6", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "20", ",", "iouThr", "=", ".5", ")", "\n", "stats", "[", "7", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "20", ",", "iouThr", "=", ".75", ")", "\n", "stats", "[", "8", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "20", ",", "areaRng", "=", "'medium'", ")", "\n", "stats", "[", "9", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "20", ",", "areaRng", "=", "'large'", ")", "\n", "return", "stats", "\n", "", "if", "not", "self", ".", "eval", ":", "\n", "            ", "raise", "Exception", "(", "'Please run accumulate() first'", ")", "\n", "", "iouType", "=", "self", ".", "params", ".", "iouType", "\n", "if", "iouType", "==", "'segm'", "or", "iouType", "==", "'bbox'", ":", "\n", "            ", "summarize", "=", "_summarizeDets", "\n", "", "elif", "iouType", "==", "'keypoints'", ":", "\n", "            ", "summarize", "=", "_summarizeKps", "\n", "", "self", ".", "stats", "=", "summarize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.cocoeval.COCOeval.__str__": [[496, 498], ["cocoeval.COCOeval.summarize"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.cocoeval.COCOeval.summarize"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "self", ".", "summarize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.cocoeval.Params.setDetParams": [[503, 513], ["numpy.linspace", "numpy.linspace", "numpy.round", "numpy.round"], "methods", ["None"], ["def", "setDetParams", "(", "self", ")", ":", "\n", "        ", "self", ".", "imgIds", "=", "[", "]", "\n", "self", ".", "catIds", "=", "[", "]", "\n", "# np.arange causes trouble.  the data point on arange is slightly larger than the true value", "\n", "self", ".", "iouThrs", "=", "np", ".", "linspace", "(", ".5", ",", "0.95", ",", "np", ".", "round", "(", "(", "0.95", "-", ".5", ")", "/", ".05", ")", "+", "1", ",", "endpoint", "=", "True", ")", "\n", "self", ".", "recThrs", "=", "np", ".", "linspace", "(", ".0", ",", "1.00", ",", "np", ".", "round", "(", "(", "1.00", "-", ".0", ")", "/", ".01", ")", "+", "1", ",", "endpoint", "=", "True", ")", "\n", "self", ".", "maxDets", "=", "[", "1", ",", "10", ",", "100", "]", "\n", "self", ".", "areaRng", "=", "[", "[", "0", "**", "2", ",", "1e5", "**", "2", "]", ",", "[", "0", "**", "2", ",", "32", "**", "2", "]", ",", "[", "32", "**", "2", ",", "96", "**", "2", "]", ",", "[", "96", "**", "2", ",", "1e5", "**", "2", "]", "]", "\n", "self", ".", "areaRngLbl", "=", "[", "'all'", ",", "'small'", ",", "'medium'", ",", "'large'", "]", "\n", "self", ".", "useCats", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.cocoeval.Params.setKpParams": [[514, 524], ["numpy.linspace", "numpy.linspace", "numpy.round", "numpy.round"], "methods", ["None"], ["", "def", "setKpParams", "(", "self", ")", ":", "\n", "        ", "self", ".", "imgIds", "=", "[", "]", "\n", "self", ".", "catIds", "=", "[", "]", "\n", "# np.arange causes trouble.  the data point on arange is slightly larger than the true value", "\n", "self", ".", "iouThrs", "=", "np", ".", "linspace", "(", ".5", ",", "0.95", ",", "np", ".", "round", "(", "(", "0.95", "-", ".5", ")", "/", ".05", ")", "+", "1", ",", "endpoint", "=", "True", ")", "\n", "self", ".", "recThrs", "=", "np", ".", "linspace", "(", ".0", ",", "1.00", ",", "np", ".", "round", "(", "(", "1.00", "-", ".0", ")", "/", ".01", ")", "+", "1", ",", "endpoint", "=", "True", ")", "\n", "self", ".", "maxDets", "=", "[", "20", "]", "\n", "self", ".", "areaRng", "=", "[", "[", "0", "**", "2", ",", "1e5", "**", "2", "]", ",", "[", "32", "**", "2", ",", "96", "**", "2", "]", ",", "[", "96", "**", "2", ",", "1e5", "**", "2", "]", "]", "\n", "self", ".", "areaRngLbl", "=", "[", "'all'", ",", "'medium'", ",", "'large'", "]", "\n", "self", ".", "useCats", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.cocoeval.Params.__init__": [[525, 535], ["cocoeval.Params.setDetParams", "cocoeval.Params.setKpParams", "Exception"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.cocoeval.Params.setDetParams", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.pycocotools.cocoeval.Params.setKpParams"], ["", "def", "__init__", "(", "self", ",", "iouType", "=", "'segm'", ")", ":", "\n", "        ", "if", "iouType", "==", "'segm'", "or", "iouType", "==", "'bbox'", ":", "\n", "            ", "self", ".", "setDetParams", "(", ")", "\n", "", "elif", "iouType", "==", "'keypoints'", ":", "\n", "            ", "self", ".", "setKpParams", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'iouType not supported'", ")", "\n", "", "self", ".", "iouType", "=", "iouType", "\n", "# useSegm is deprecated", "\n", "self", ".", "useSegm", "=", "None", "", "", "", ""]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.bayesian_agents.bayesian_pragmatics.Pragmatic.__init__": [[13, 40], ["translators.translators.Unfold", "translators.translators.Unfold"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "rightward_model", ",", "leftward_model", ",", "unfolded_leftward_model", "=", "None", ",", "width", "=", "2", ",", "rat", "=", "2.0", ",", "EXTEND", "=", "True", ",", ")", ":", "\n", "# assert (rightward_model.seg_type==leftward_model.seg_type)", "\n", "\n", "\t\t", "self", ".", "seg_type", "=", "rightward_model", ".", "seg_type", "\n", "# it's leftward because we want the bpe encoding that the leftward model would yield, since we're looking up from leftward model outputs", "\n", "\n", "try", ":", "self", ".", "bpe_code_path", "=", "leftward_model", ".", "bpe_code_path", "\n", "except", ":", "self", ".", "bpe_code_path", "=", "self", ".", "bpe_code_path", "=", "unfolded_leftward_model", ".", "bpe_code_path", "\n", "if", "rightward_model", ".", "seg_type", "==", "\"sentence\"", ":", "\n", "\t\t\t", "self", ".", "underlying_model", "=", "rightward_model", ".", "underlying_model", "\n", "# except: ", "\n", "# \tprint(\"RIGHTWARD MODEL HAS NO SEG TYPE\")", "\n", "# \tself.seg_type=leftward_model.seg.type", "\n", "# \tself.bpe_code_path=leftward_model.bpe_code_path", "\n", "\n", "", "self", ".", "rightward_model", "=", "rightward_model", "\n", "self", ".", "leftward_model", "=", "leftward_model", "\n", "\n", "if", "unfolded_leftward_model", "is", "None", ":", "\n", "\t\t\t", "unfolded_leftward_model", "=", "Unfold", "(", "underlying_model", "=", "self", ".", "leftward_model", ")", "\n", "# else: self.bpe_code_path = unfolded_leftward_model.underlying_model.bpe_code_path", "\n", "", "self", ".", "unfolded_leftward_model", "=", "unfolded_leftward_model", "\n", "self", ".", "unfolded_rightward_model", "=", "Unfold", "(", "underlying_model", "=", "self", ".", "rightward_model", ",", "stop_on", "=", "None", ")", "\n", "self", ".", "width", "=", "width", "\n", "self", ".", "rat", "=", "rat", "\n", "self", ".", "EXTEND", "=", "EXTEND", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.bayesian_agents.bayesian_pragmatics.Pragmatic.empty_cache": [[41, 45], ["bayesian_pragmatics.Pragmatic.unfolded_leftward_model.empty_cache", "bayesian_pragmatics.Pragmatic.unfolded_rightward_model.empty_cache"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.empty_cache", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.empty_cache"], ["", "def", "empty_cache", "(", "self", ")", ":", "\n", "\t\t", "self", ".", "cache", "=", "{", "}", "\n", "self", ".", "unfolded_leftward_model", ".", "empty_cache", "(", ")", "\n", "self", ".", "unfolded_rightward_model", ".", "empty_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.bayesian_agents.bayesian_pragmatics.Pragmatic.memoize_forward": [[46, 56], ["tuple", "tuple", "f"], "methods", ["None"], ["", "def", "memoize_forward", "(", "f", ")", ":", "\n", "\t\t", "def", "helper", "(", "self", ",", "sequence", ",", "source_sentence", ",", "debug", "=", "False", ")", ":", "\n", "\n", "# world_prior_list = np.ndarray.tolist(np.ndarray.flatten(state.world_priors))", "\n", "\t\t\t", "hashable_args", "=", "(", "tuple", "(", "sequence", ")", ",", "tuple", "(", "source_sentence", ")", ")", "\n", "if", "hashable_args", "not", "in", "self", ".", "cache", ":", "\n", "# print(\"MEM\\n\\n\")", "\n", "\t\t\t\t", "self", ".", "cache", "[", "hashable_args", "]", "=", "f", "(", "self", ",", "sequence", "=", "sequence", ",", "source_sentence", "=", "source_sentence", ",", "debug", "=", "debug", ")", "\n", "", "return", "self", ".", "cache", "[", "hashable_args", "]", "\n", "", "return", "helper", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.bayesian_agents.bayesian_pragmatics.Pragmatic.forward": [[57, 167], ["bayesian_pragmatics.Pragmatic.rightward_model.forward", "enumerate", "numpy.asarray", "l0_scores.append", "numpy.asarray", "scipy.special.logsumexp", "scipy.special.logsumexp", "scipy.special.logsumexp", "scipy.special.logsumexp", "bayesian_pragmatics.Pragmatic.unfolded_leftward_model.likelihood", "print", "print", "bayesian_pragmatics.Pragmatic.unfolded_rightward_model.forward", "bayesian_pragmatics.Pragmatic.unfolded_leftward_model.likelihood", "bayesian_pragmatics.Pragmatic.unfolded_leftward_model.likelihood", "print", "print", "print", "print", "print"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.forward", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.likelihood", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.forward", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.likelihood", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.likelihood"], ["", "@", "memoize_forward", "\n", "def", "forward", "(", "self", ",", "sequence", ",", "source_sentence", ",", "debug", "=", "False", ")", ":", "\n", "\n", "# print(\"Starting pragmatics\")", "\n", "\n", "\n", "# print(\"ENCODED SOurCE SENTENCE\",source_sentence,self.bpe_code_path)", "\n", "# left_coded_source_sentence = byte_pair_decoding(source_sentence)", "\n", "# left_coded_source_sentence = byte_pair_encoding(sentence=left_coded_source_sentence,code_path=self.bpe_code_path)", "\n", "\t\t", "left_coded_source_sentence", "=", "source_sentence", "\n", "EXTEND", "=", "self", ".", "EXTEND", "\n", "\n", "s0_probs", ",", "s0_support", "=", "self", ".", "rightward_model", ".", "forward", "(", "sequence", "=", "sequence", ",", "source_sentence", "=", "source_sentence", ")", "\n", "\n", "s0_probs", ",", "s0_support", "=", "np", ".", "asarray", "(", "s0_probs", "[", ":", "self", ".", "width", "]", ")", ",", "s0_support", "[", ":", "self", ".", "width", "]", "\n", "\n", "# print(\"S0 complete\")", "\n", "\n", "# if debug:", "\n", "# \tprint(\"s0\",display(probs=s0_probs,support=s0_support))", "\n", "# print(\"probs and support\",sym_set[np.argmax(s0_probs)])", "\n", "# print(\"EXTEND?\",EXTEND)", "\n", "# unrolled_sents = []", "\n", "l0_scores", "=", "[", "]", "\n", "for", "i", ",", "seg", "in", "enumerate", "(", "s0_support", ")", ":", "\n", "\n", "# if debug: print(\"SEG\",seg)", "\n", "\n", "\t\t\t", "if", "seg", "!=", "stop_token", "[", "self", ".", "seg_type", "]", ":", "\n", "# _, unrolled_sent = self.unfolded_rightward_model.forward(sequence=sequence+[seg],source_sentence=source_sentence,beam_width=1)", "\n", "# unrolled_sent = unrolled_sent[0]", "\n", "# if debug:", "\n", "# \tprint(\"\\nunrolled sent\\n\",unrolled_sent)", "\n", "# # unrolled_sents.append(unrolled_sent)", "\n", "\t\t\t\t", "if", "debug", ":", "\n", "\t\t\t\t\t", "print", "(", "\"SEG\"", ",", "seg", ")", "\n", "# \tprint(\"stuff\",unrolled_sent.lower(),source_sentence.split())", "\n", "# \tp,s = self.leftward_model.forward(sequence=[],source_sentence=unrolled_sent.lower())", "\n", "# \tprint(s[:200])", "\n", "\n", "", "if", "EXTEND", ":", "\n", "\n", "\t\t\t\t\t", "if", "debug", ":", "print", "(", "\"STARTING EXTENSION\"", ")", "\n", "_", ",", "unrolled_sent", "=", "self", ".", "unfolded_rightward_model", ".", "forward", "(", "sequence", "=", "sequence", "+", "[", "seg", "]", ",", "source_sentence", "=", "source_sentence", ",", "debug", "=", "debug", ")", "\n", "unrolled_sent", "=", "unrolled_sent", "[", "0", "]", "\n", "\n", "# if True:", "\n", "# print(\"EXTENSION COMPLETE\")", "\n", "# print(\"\\nunrolled sent\\n\",unrolled_sent)", "\n", "# unrolled_sents.append(unrolled_sent)", "\n", "# print(\"stuff\",unrolled_sent.lower(),source_sentence.split())", "\n", "# p,s = self.leftward_model.forward(sequence=[],source_sentence=unrolled_sent.lower())", "\n", "# print(s[:200])", "\n", "score", "=", "self", ".", "unfolded_leftward_model", ".", "likelihood", "(", "sequence", "=", "[", "]", ",", "source_sentence", "=", "unrolled_sent", ",", "target", "=", "left_coded_source_sentence", ")", "\n", "# if debug:", "\n", "# \tprint(\"score\",score)", "\n", "\n", "", "else", ":", "\n", "# print(\"SEQUENCE AND WORD\",sequence+[seg])", "\n", "\t\t\t\t\t", "if", "self", ".", "rightward_model", ".", "seg_type", "==", "'char'", ":", "new_seq", "=", "\"\"", ".", "join", "(", "sequence", "+", "[", "seg", "]", ")", "\n", "elif", "self", ".", "rightward_model", ".", "seg_type", "in", "[", "'word'", ",", "'sentence'", "]", ":", "\n", "\t\t\t\t\t\t", "new_seq", "=", "\" \"", ".", "join", "(", "sequence", "+", "[", "seg", "]", ")", "\n", "if", "debug", ":", "\n", "\t\t\t\t\t\t\t", "print", "(", "\"BP\"", ")", "\n", "print", "(", "\"source_sentence\"", ",", "new_seq", ")", "\n", "print", "(", "\"target\"", ",", "source_sentence", ")", "\n", "", "", "score", "=", "self", ".", "unfolded_leftward_model", ".", "likelihood", "(", "sequence", "=", "[", "]", ",", "source_sentence", "=", "new_seq", ",", "target", "=", "left_coded_source_sentence", ",", "debug", "=", "debug", ")", "\n", "\n", "# score = self.unfolded_leftward_model.likelihood(sequence=[],source_sentence=unrolled_sent.lower(),target=source_sentence.split())", "\n", "# score = self.unfolded_leftward_model.likelihood(sequence=source_sentence.split()[:len(sequence)],source_sentence=s,target=source_sentence.split()[len(sequence):])", "\n", "", "if", "debug", ":", "\n", "# print(s0_support[i])", "\n", "# print(\"source\",\" \".join(sequence+[seg]).lower())", "\n", "# print(\"target\",source_sentence.split())", "\n", "\t\t\t\t\t", "print", "(", "\"score\"", ",", "score", ")", "\n", "\n", "", "", "else", ":", "\n", "\t\t\t\t", "score", "=", "self", ".", "unfolded_leftward_model", ".", "likelihood", "(", "sequence", "=", "[", "]", ",", "source_sentence", "=", "\" \"", ".", "join", "(", "sequence", "+", "[", "seg", "]", ")", ",", "target", "=", "left_coded_source_sentence", ")", "\n", "# unrolled_sents.append(\" \".join(sequence+[seg]))", "\n", "\n", "", "if", "debug", ":", "\n", "\t\t\t\t", "print", "(", "\"SCORE, SEG\"", ",", "score", ",", "seg", ")", "\n", "", "l0_scores", ".", "append", "(", "score", ")", "\n", "\n", "\n", "# print(unrolled_sents, \"unrolled_sents\")", "\n", "\n", "# print(\"seq\",source_sentence.split()[:len(sequence)])", "\n", "# print(\"targ\",source_sentence.split()[len(sequence):])", "\n", "# for i,s in enumerate(unrolled_sents):", "\n", "# \tl0_scores.append(score)", "\n", "\n", "# print(\"rat\",self.rat)", "\n", "", "l0_scores", "=", "self", ".", "rat", "*", "np", ".", "asarray", "(", "l0_scores", ")", "\n", "\n", "# print(type(s0_probs),type(l0_scores))", "\n", "\n", "# if debug:print(\"l0 scores\",sym_set[np.argmax(l0_scores)])", "\n", "\n", "\n", "# l0_scores = [(unfolded_de_en_model.likelihood(sequence=[],source_sentence=s,target=sentence.split())) for s in unrolled_sents]", "\n", "# l0_scores = np.asarray(l0_scores)", "\n", "# print(np.exp(l0_scores))", "\n", "\n", "unnormed_probs", "=", "s0_probs", "+", "l0_scores", "\n", "normed_probs", "=", "unnormed_probs", "-", "scipy", ".", "special", ".", "logsumexp", "(", "unnormed_probs", ")", "\n", "\n", "# print(\"MAX\",sym_set[np.argmax(normed_probs)])", "\n", "\n", "return", "normed_probs", ",", "s0_support", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.bayesian_agents.bayesian_pragmatics.Pragmatic.likelihood": [[168, 177], ["bayesian_pragmatics.Pragmatic.forward", "print", "support.index"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.forward"], ["", "def", "likelihood", "(", "self", ",", "sequence", ",", "source_sentence", ",", "target", ",", "debug", "=", "False", ")", ":", "\n", "\t\t", "probs", ",", "support", "=", "self", ".", "forward", "(", "sequence", ",", "source_sentence", ")", "\n", "\n", "try", ":", "out", "=", "probs", "[", "support", ".", "index", "(", "target", ")", "]", "\n", "except", ":", "\n", "\t\t\t", "print", "(", "\"target failed:\"", ",", "target", ")", "\n", "# out = np.log(1.0)", "\n", "raise", "Exception", "\n", "", "return", "out", "", "", "", ""]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.BaseCase.__init__": [[44, 177], ["namedtuple", "namedtuple", "Args", "tasks.setup_task", "Args.path.split", "utils.load_ensemble_for_inference", "list_to_index_iso", "SequenceGenerator", "utils.load_align_dict", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "model.make_generation_fast_", "translator.cuda", "range", "model.half", "len"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.config.list_to_index_iso", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator.cuda"], ["\t", "def", "__init__", "(", "self", ",", "path", ",", "source", ",", "target", ",", "bpe_code_path", "=", "None", ")", ":", "\n", "\n", "# from interactive import Args", "\n", "\t\t", "from", "collections", "import", "namedtuple", "\n", "import", "numpy", "as", "np", "\n", "import", "sys", "\n", "import", "scipy", ".", "misc", "\n", "\n", "import", "torch", "\n", "from", "torch", ".", "autograd", "import", "Variable", "\n", "\n", "from", "fairseq", "import", "data", ",", "options", ",", "tasks", ",", "tokenizer", ",", "utils", "\n", "# from fairseq.sequence_generator import SequenceGenerator", "\n", "from", "utils", ".", "seqgen", "import", "SequenceGenerator", "\n", "\n", "Batch", "=", "namedtuple", "(", "'Batch'", ",", "'srcs tokens lengths'", ")", "\n", "Translation", "=", "namedtuple", "(", "'Translation'", ",", "'src_str hypos alignments'", ")", "\n", "\n", "self", ".", "bpe_code_path", "=", "path", "+", "bpe_code_path", "\n", "# print(\"bpe code 1\",self.bpe_code_path)", "\n", "\n", "class", "Args", ":", "\n", "\t\t\t", "def", "__init__", "(", "self", ")", ":", "\n", "\t\t\t\t", "pass", "\n", "\n", "", "", "args", "=", "Args", "(", ")", "\n", "args", ".", "sampling_topk", "=", "-", "1", "\n", "args", ".", "cpu", "=", "False", "\n", "args", ".", "gen_subset", "=", "'test'", "\n", "args", ".", "log_format", "=", "None", "\n", "args", ".", "log_interval", "=", "1000", "\n", "args", ".", "max_len_a", "=", "0", "\n", "args", ".", "max_len_b", "=", "200", "\n", "args", ".", "max_source_positions", "=", "1024", "\n", "args", ".", "max_target_positions", "=", "1024", "\n", "args", ".", "min_len", "=", "1", "\n", "args", ".", "model_overrides", "=", "{", "}", "\n", "args", ".", "no_progress_bar", "=", "False", "\n", "args", ".", "num_shards", "=", "1", "\n", "args", ".", "prefix_size", "=", "0", "\n", "args", ".", "quiet", "=", "False", "\n", "args", ".", "raw_text", "=", "False", "\n", "args", ".", "replace_unk", "=", "None", "\n", "args", ".", "sampling_temperature", "=", "1", "\n", "args", ".", "score_reference", "=", "False", "\n", "args", ".", "seed", "=", "1", "\n", "args", ".", "shard_id", "=", "0", "\n", "args", ".", "skip_invalid_size_inputs_valid_test", "=", "False", "\n", "args", ".", "lenpen", "=", "1", "\n", "args", ".", "unkpen", "=", "0", "\n", "args", ".", "unnormalized", "=", "False", "\n", "args", ".", "no_early_stop", "=", "False", "\n", "args", ".", "fp16", "=", "False", "\n", "args", ".", "no_beamable_mm", "=", "False", "\n", "args", ".", "data", "=", "path", "\n", "args", ".", "path", "=", "path", "+", "'/model.pt'", "\n", "args", ".", "target_lang", "=", "target", "\n", "args", ".", "source_lang", "=", "source", "\n", "\n", "args", ".", "beam", "=", "1", "\n", "args", ".", "buffer_size", "=", "0", "\n", "args", ".", "max_tokens", "=", "None", "\n", "args", ".", "max_sentences", "=", "None", "\n", "args", ".", "nbest", "=", "1", "\n", "args", ".", "sampling", "=", "False", "\n", "args", ".", "remove_bpe", "=", "True", "\n", "args", ".", "task", "=", "'translation'", "\n", "args", ".", "left_pad_source", "=", "True", "\n", "args", ".", "left_pad_target", "=", "False", "\n", "\n", "self", ".", "args", "=", "args", "\n", "\n", "# self.utterance_to_world=None", "\n", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n", "if", "args", ".", "buffer_size", "<", "1", ":", "\n", "\t\t\t", "args", ".", "buffer_size", "=", "1", "\n", "", "if", "args", ".", "max_tokens", "is", "None", "and", "args", ".", "max_sentences", "is", "None", ":", "\n", "\t\t\t", "args", ".", "max_sentences", "=", "1", "\n", "\n", "", "assert", "not", "args", ".", "sampling", "or", "args", ".", "nbest", "==", "args", ".", "beam", ",", "'--sampling requires --nbest to be equal to --beam'", "\n", "assert", "not", "args", ".", "max_sentences", "or", "args", ".", "max_sentences", "<=", "args", ".", "buffer_size", ",", "'--max-sentences/--batch-size cannot be larger than --buffer-size'", "\n", "\n", "# print(args)", "\n", "\n", "use_cuda", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "cpu", "\n", "\n", "# Setup task, e.g., translation", "\n", "task", "=", "tasks", ".", "setup_task", "(", "args", ")", "\n", "\n", "# Load ensemble", "\n", "# print('| loading model(s) from {}'.format(args.path))", "\n", "model_paths", "=", "args", ".", "path", ".", "split", "(", "':'", ")", "\n", "self", ".", "models", ",", "self", ".", "model_args", "=", "utils", ".", "load_ensemble_for_inference", "(", "model_paths", ",", "task", ")", "\n", "\n", "# Set dictionaries", "\n", "self", ".", "src_dict", "=", "task", ".", "source_dictionary", "\n", "self", ".", "tgt_dict", "=", "task", ".", "target_dictionary", "\n", "\n", "# print(tgt_dict)", "\n", "u_support", "=", "[", "self", ".", "tgt_dict", "[", "x", "]", "for", "x", "in", "range", "(", "len", "(", "self", ".", "tgt_dict", ")", ")", "]", "\n", "# list(self.tgt_dict.values())", "\n", "mappings", "=", "list_to_index_iso", "(", "u_support", ")", "\n", "self", ".", "idx2seg", "=", "mappings", "[", "\"leftward\"", "]", "\n", "self", ".", "seg2idx", "=", "mappings", "[", "\"rightward\"", "]", "\n", "\n", "self", ".", "path", "=", "path", "\n", "self", ".", "seg_type", "=", "'word'", "\n", "self", ".", "u_support", "=", "u_support", "\n", "\n", "# Optimize ensemble for generation", "\n", "for", "model", "in", "self", ".", "models", ":", "\n", "\t\t\t", "model", ".", "make_generation_fast_", "(", "beamable_mm_beam_size", "=", "None", "if", "args", ".", "no_beamable_mm", "else", "args", ".", "beam", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "\t\t\t\t", "model", ".", "half", "(", ")", "\n", "\n", "# Initialize generator", "\n", "", "", "self", ".", "translator", "=", "SequenceGenerator", "(", "\n", "self", ".", "models", ",", "self", ".", "tgt_dict", ",", "beam_size", "=", "args", ".", "beam", ",", "stop_early", "=", "(", "not", "args", ".", "no_early_stop", ")", ",", "\n", "normalize_scores", "=", "(", "not", "args", ".", "unnormalized", ")", ",", "len_penalty", "=", "args", ".", "lenpen", ",", "\n", "unk_penalty", "=", "args", ".", "unkpen", ",", "sampling", "=", "args", ".", "sampling", ",", "sampling_topk", "=", "args", ".", "sampling_topk", ",", "\n", "minlen", "=", "args", ".", "min_len", ",", "\n", ")", "\n", "\n", "if", "use_cuda", ":", "\n", "\t\t\t", "translator", ".", "cuda", "(", ")", "\n", "\n", "# Load alignment dictionary for unknown word replacement", "\n", "# (None if no unknown word replacement, empty if no path to align dictionary)", "\n", "", "self", ".", "align_dict", "=", "utils", ".", "load_align_dict", "(", "args", ".", "replace_unk", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.BaseCase.empty_cache": [[178, 180], ["None"], "methods", ["None"], ["", "def", "empty_cache", "(", "self", ")", ":", "\n", "\t\t", "self", ".", "cache", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.BaseCase.memoize_forward": [[181, 196], ["tuple", "tuple", "f"], "methods", ["None"], ["", "def", "memoize_forward", "(", "f", ")", ":", "\n", "\t\t", "def", "helper", "(", "self", ",", "sequence", ",", "source_sentence", ",", "debug", "=", "False", ")", ":", "\n", "\n", "\n", "# print(\"source sent\",source_sentence)", "\n", "# world_prior_list = np.ndarray.tolist(np.ndarray.flatten(state.world_priors))", "\n", "\t\t\t", "hashable_args", "=", "(", "tuple", "(", "sequence", ")", ",", "tuple", "(", "source_sentence", ")", ")", "\n", "if", "hashable_args", "not", "in", "self", ".", "cache", ":", "\n", "# print(\"MEM\\n\\n\")", "\n", "\t\t\t\t", "self", ".", "cache", "[", "hashable_args", "]", "=", "f", "(", "self", ",", "sequence", "=", "sequence", ",", "source_sentence", "=", "source_sentence", ",", "debug", "=", "debug", ")", "\n", "# else: ", "\n", "# \tprint(\"LOOKING UP\")", "\n", "# \tprint(\"cache keys\",list(self.cache))", "\n", "", "return", "self", ".", "cache", "[", "hashable_args", "]", "\n", "", "return", "helper", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.BaseCase.forward": [[197, 283], ["next", "translators.BaseCase.translator.generate", "list", "Translation", "translators.BaseCase.translator.generate", "make_batches", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "zip", "utils.post_process_prediction", "Translation.hypos.append", "Translation.alignments.append", "tokens.cuda.cuda.cuda", "lengths.cuda.cuda.cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "translators.BaseCase.forward.make_result"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator.generate", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator.generate", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.utils.seqgen.SequenceGenerator.cuda"], ["", "@", "memoize_forward", "\n", "def", "forward", "(", "self", ",", "sequence", ",", "source_sentence", ",", "debug", "=", "False", ")", ":", "\n", "\n", "# print(\"CALLING BaseCase\",source_sentence)", "\n", "# source_sentence = re.sub(\"@@ \",\"\",source_sentence).lower()", "\n", "# source_sentence = re.sub(\"@@@\",\"\",source_sentence).lower()", "\n", "\n", "\n", "\n", "# source_sentence = byte_pair_decoding(source_sentence)", "\n", "# source_sentence = byte_pair_encoding(sentence=source_sentence,code_path=self.bpe_code_path)", "\n", "\n", "\n", "\n", "\n", "# print(\"DECODED SENTENCE IN BaseCase\",source_sentence)", "\n", "# print(\"bpe path\",self.bpe_code_path)", "\n", "\n", "# print(\"ENCODED SENTENCE IN BaseCase\",source_sentence)", "\n", "\n", "\n", "\t\t", "from", "interactive", "import", "make_batches", ",", "buffered_read", "\n", "\n", "def", "make_result", "(", "src_str", ",", "hypos", ")", ":", "\n", "\t\t\t", "result", "=", "Translation", "(", "\n", "src_str", "=", "'O\\t{}'", ".", "format", "(", "src_str", ")", ",", "\n", "hypos", "=", "[", "]", ",", "\n", "alignments", "=", "[", "]", ",", "\n", ")", "\n", "\n", "# Process top predictions", "\n", "for", "hypo", "in", "hypos", "[", ":", "min", "(", "len", "(", "hypos", ")", ",", "self", ".", "args", ".", "nbest", ")", "]", ":", "\n", "\t\t\t\t", "hypo_tokens", ",", "hypo_str", ",", "alignment", "=", "utils", ".", "post_process_prediction", "(", "\n", "hypo_tokens", "=", "hypo", "[", "'tokens'", "]", ".", "int", "(", ")", ".", "cpu", "(", ")", ",", "\n", "src_str", "=", "src_str", ",", "\n", "alignment", "=", "hypo", "[", "'alignment'", "]", ".", "int", "(", ")", ".", "cpu", "(", ")", ",", "\n", "align_dict", "=", "selfalign_dict", ",", "\n", "tgt_dict", "=", "self", ".", "tgt_dict", ",", "\n", "remove_bpe", "=", "self", ".", "args", ".", "remove_bpe", ",", "\n", ")", "\n", "result", ".", "hypos", ".", "append", "(", "'H\\t{}\\t{}'", ".", "format", "(", "hypo", "[", "'score'", "]", ",", "hypo_str", ")", ")", "\n", "result", ".", "alignments", ".", "append", "(", "'A\\t{}'", ".", "format", "(", "' '", ".", "join", "(", "map", "(", "lambda", "x", ":", "str", "(", "utils", ".", "item", "(", "x", ")", ")", ",", "alignment", ")", ")", ")", ")", "\n", "", "return", "result", "\n", "\n", "", "def", "process_batch", "(", "batch", ")", ":", "\n", "\t\t\t", "tokens", "=", "batch", ".", "tokens", "\n", "lengths", "=", "batch", ".", "lengths", "\n", "\n", "if", "use_cuda", ":", "\n", "\t\t\t\t", "tokens", "=", "tokens", ".", "cuda", "(", ")", "\n", "lengths", "=", "lengths", ".", "cuda", "(", ")", "\n", "\n", "", "translations", "=", "self", ".", "translator", ".", "generate", "(", "\n", "Variable", "(", "tokens", ")", ",", "\n", "Variable", "(", "lengths", ")", ",", "\n", "maxlen", "=", "int", "(", "self", ".", "args", ".", "max_len_a", "*", "tokens", ".", "size", "(", "1", ")", "+", "self", ".", "args", ".", "max_len_b", ")", ",", "\n", ")", "\n", "\n", "# print(\"translations\",translations)", "\n", "# print(batch.srcs[0])", "\n", "\n", "return", "[", "make_result", "(", "batch", ".", "srcs", "[", "i", "]", ",", "t", ")", "for", "i", ",", "t", "in", "enumerate", "(", "translations", ")", "]", "\n", "\n", "# print(\"SENTENCES\",self.sentences)", "\n", "", "batch", ",", "batch_indices", "=", "next", "(", "make_batches", "(", "[", "source_sentence", "]", ",", "self", ".", "args", ",", "self", ".", "src_dict", ",", "self", ".", "models", "[", "0", "]", ".", "max_positions", "(", ")", ")", ")", "\n", "# print(\"batch shape\",len(batch),len(batch[0]))", "\n", "translations", "=", "self", ".", "translator", ".", "generate", "(", "\n", "Variable", "(", "batch", ".", "tokens", ")", ",", "\n", "Variable", "(", "batch", ".", "lengths", ")", ",", "\n", "maxlen", "=", "int", "(", "self", ".", "args", ".", "max_len_a", "*", "batch", ".", "tokens", ".", "size", "(", "1", ")", "+", "self", ".", "args", ".", "max_len_b", ")", ",", "\n", "prefix_tokens", "=", "sequence", ",", "\n", ")", "\n", "# print(\"translations\",translations)", "\n", "# print(translations[:5],\"translations\")", "\n", "probs", ",", "support", "=", "translations", ",", "[", "self", ".", "tgt_dict", "[", "x", "]", "for", "x", "in", "range", "(", "translations", ".", "shape", "[", "0", "]", ")", "]", "\n", "\n", "# probs = list(probs)", "\n", "# support = list(support)", "\n", "# for seg in source_sentence.split():", "\n", "# \tif seg in support:", "\n", "# \t\tind = support.index(seg)", "\n", "# \t\tdel support[ind]", "\n", "# \t\tdel probs[ind]", "\n", "probs", ",", "support", "=", "list", "(", "zip", "(", "*", "sorted", "(", "list", "(", "zip", "(", "probs", ",", "support", ")", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", ")", ")", "\n", "\n", "return", "probs", ",", "support", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.BaseCase.likelihood": [[284, 300], ["translators.BaseCase.forward", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "print", "print", "print", "print", "numpy.log", "numpy.log", "numpy.asarray.index", "sorted"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.forward"], ["", "def", "likelihood", "(", "self", ",", "sequence", ",", "source_sentence", ",", "target", ",", "debug", "=", "False", ")", ":", "\n", "\n", "\t\t", "probs", ",", "support", "=", "self", ".", "forward", "(", "sequence", "=", "sequence", ",", "source_sentence", "=", "source_sentence", ")", "\n", "probs", "=", "np", ".", "asarray", "(", "probs", ")", "\n", "# print(target,\"target word\")", "\n", "try", ":", "out", "=", "probs", "[", "support", ".", "index", "(", "target", ")", "]", "\n", "except", ":", "\n", "\t\t\t", "support", "=", "np", ".", "asarray", "(", "support", ")", "\n", "print", "(", "\"target word failed:\"", ",", "target", ")", "\n", "print", "(", "\"sequence:\"", ",", "sequence", ")", "\n", "print", "(", "\"source sentence:\"", ",", "source_sentence", ")", "\n", "# print(support[np.argsort(-probs)][:5])", "\n", "print", "(", "sorted", "(", "support", ")", "[", "5000", ":", "5500", "]", ")", "\n", "# raise Exception", "\n", "out", "=", "np", ".", "log", "(", "1.0", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Factor_To_Character.__init__": [[303, 308], ["None"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "word_model", ")", ":", "\n", "\t\t", "self", ".", "word_model", "=", "word_model", "\n", "self", ".", "seg_type", "=", "\"char\"", "\n", "self", ".", "cache", "=", "{", "}", "\n", "self", ".", "bpe_code_path", "=", "word_model", ".", "bpe_code_path", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Factor_To_Character.empty_cache": [[309, 312], ["translators.Factor_To_Character.word_model.empty_cache"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.empty_cache"], ["", "def", "empty_cache", "(", "self", ")", ":", "\n", "\t\t", "self", ".", "cache", "=", "{", "}", "\n", "self", ".", "word_model", ".", "empty_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Factor_To_Character.memoize_forward": [[313, 323], ["tuple", "tuple", "f"], "methods", ["None"], ["", "def", "memoize_forward", "(", "f", ")", ":", "\n", "\t\t", "def", "helper", "(", "self", ",", "sequence", ",", "source_sentence", ",", "debug", "=", "False", ")", ":", "\n", "\n", "# world_prior_list = np.ndarray.tolist(np.ndarray.flatten(state.world_priors))", "\n", "\t\t\t", "hashable_args", "=", "(", "tuple", "(", "sequence", ")", ",", "tuple", "(", "source_sentence", ")", ")", "\n", "if", "hashable_args", "not", "in", "self", ".", "cache", ":", "\n", "# print(\"MEM\\n\\n\")", "\n", "\t\t\t\t", "self", ".", "cache", "[", "hashable_args", "]", "=", "f", "(", "self", ",", "sequence", "=", "sequence", ",", "source_sentence", "=", "source_sentence", ")", "\n", "", "return", "self", ".", "cache", "[", "hashable_args", "]", "\n", "", "return", "helper", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Factor_To_Character.forward": [[324, 415], ["translators.Factor_To_Character.word_model.forward", "time.time", "dict", "numpy.zeros", "numpy.zeros", "len", "range", "time.time", "list", "len", "len", "numpy.log", "numpy.log", "scipy.special.logsumexp", "zip", "numpy.log", "numpy.log", "zip", "sorted", "numpy.exp", "numpy.exp", "len", "len", "list", "numpy.exp", "numpy.exp", "numpy.exp", "numpy.exp", "zip", "len", "numpy.exp", "numpy.exp", "set"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.forward"], ["", "@", "memoize_forward", "\n", "def", "forward", "(", "self", ",", "sequence", ",", "source_sentence", ",", "debug", "=", "False", ")", ":", "\n", "\t\t", "if", "sequence", "!=", "[", "]", ":", "\n", "\t\t\t", "ends_with_space", "=", "(", "sequence", "[", "-", "1", "]", "==", "' '", ")", "\n", "", "else", ":", "ends_with_space", "=", "False", "\n", "sequence", "=", "\"\"", ".", "join", "(", "sequence", ")", ".", "split", "(", ")", "\n", "word_sequence", "=", "sequence", "[", ":", "-", "1", "]", "\n", "if", "ends_with_space", ":", "word_sequence", "=", "sequence", "\n", "\n", "char_remainder", "=", "sequence", "[", "-", "1", ":", "]", "\n", "if", "char_remainder", "!=", "[", "]", ":", "char_remainder", "=", "char_remainder", "[", "0", "]", "\n", "else", ":", "char_remainder", "=", "\"\"", "\n", "# if ends_with_space: char_remainder = ' '", "\n", "\n", "# print(sequence,source_sentence)", "\n", "# raise Exception", "\n", "word_probs", ",", "word_support", "=", "self", ".", "word_model", ".", "forward", "(", "sequence", "=", "word_sequence", ",", "source_sentence", "=", "source_sentence", ")", "\n", "if", "ends_with_space", ":", "char_remainder", "=", "\"\"", "\n", "# print(\"char remainder\",char_remainder)", "\n", "# print(word_sequence,\"word_sequence\")", "\n", "# print(word_support[np.asarray(np.argmax(word_probs))])", "\n", "# print(\"ends_with_space\",ends_with_space,\"ends_with_space\")", "\n", "# ,len(char_remainder),[\"abc\"][:len(char_remainder)],[\"abc\"][:len(char_remainder)]==char_remainder)", "\n", "\n", "# print(word_probs)", "\n", "# print(word_sequence)", "\n", "\n", "# pairs = []", "\n", "# for x,y in zip(word_support,word_probs):", "\n", "# \tcond = (x[:len(char_remainder)]==char_remainder)", "\n", "# \tprint(\"x:\",x[:len(char_remainder)])", "\n", "# \tprint(\"char rem:\",char_remainder)", "\n", "# \tprint(cond)", "\n", "# \tif cond:", "\n", "# \t\tpairs.append((x,y))", "\n", "\n", "# word_dict = dict(pairs)", "\n", "toc", "=", "time", ".", "time", "(", ")", "\n", "word_dict", "=", "dict", "(", "[", "(", "x", ",", "y", ")", "for", "(", "x", ",", "y", ")", "in", "zip", "(", "word_support", ",", "word_probs", ")", "if", "(", "x", "[", ":", "len", "(", "char_remainder", ")", "]", "==", "char_remainder", ")", "]", ")", "\n", "# print(word_dict)", "\n", "# raise Exception", "\n", "# print(word_dict)", "\n", "\n", "char_dist", "=", "np", ".", "zeros", "(", "len", "(", "sym_set", ")", ")", "\n", "\n", "# how far along in the word to look", "\n", "index", "=", "len", "(", "char_remainder", ")", "\n", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "sym_set", ")", ")", ":", "\n", "\t\t\t", "for", "word", "in", "word_dict", ":", "\n", "# print(\"word\",word,word[0],sym_set[i])", "\n", "# if word==stop_token[\"word\"]:", "\n", "\n", "# print(\"BLAH BLAH\")", "\n", "\n", "\t\t\t\t", "if", "word", "==", "stop_token", "[", "\"word\"", "]", "or", "sym_set", "[", "i", "]", "==", "stop_token", ":", "\n", "\n", "\t\t\t\t\t", "if", "sym_set", "[", "i", "]", "==", "stop_token", "[", "\"char\"", "]", ":", "\n", "# print(\"TRUEEUEUE\\n\\n\\n\")", "\n", "# print(\"stop token is word\")", "\n", "\t\t\t\t\t\t", "char_dist", "[", "i", "]", "+=", "np", ".", "exp", "(", "word_dict", "[", "word", "]", ")", "\n", "\n", "", "", "elif", "len", "(", "word", ")", ">", "len", "(", "char_remainder", ")", ":", "\n", "\n", "\t\t\t\t\t", "if", "sym_set", "[", "i", "]", "==", "word", "[", "index", "]", ":", "\n", "\t\t\t\t\t\t", "char_dist", "[", "i", "]", "+=", "np", ".", "exp", "(", "word_dict", "[", "word", "]", ")", "\n", "\n", "\n", "", "elif", "(", "word", "[", "index", "]", "not", "in", "set", "(", "sym_set", ")", ")", "and", "sym_set", "[", "i", "]", "==", "'&'", ":", "\n", "\t\t\t\t\t\t", "char_dist", "[", "i", "]", "+=", "np", ".", "exp", "(", "word_dict", "[", "word", "]", ")", "\n", "\n", "", "", "else", ":", "\n", "\t\t\t\t\t", "if", "sym_set", "[", "i", "]", "==", "\" \"", ":", "\n", "\t\t\t\t\t\t", "char_dist", "[", "i", "]", "+=", "np", ".", "exp", "(", "word_dict", "[", "word", "]", ")", "\n", "\n", "", "else", ":", "continue", "\n", "\n", "\n", "\n", "# print(char_dist[i])", "\n", "# smooth", "\n", "# print(\"CHAR DIST UNNORMED UNSMOOTHED\",char_dist[sym_set.index('$')])", "\n", "", "", "", "tic", "=", "time", ".", "time", "(", ")", "\n", "# print(\"TIME (in factor to char):\",tic-toc)", "\n", "char_dist", "=", "char_dist", "+", "1e-10", "\n", "char_probs", "=", "np", ".", "log", "(", "char_dist", ")", "-", "scipy", ".", "special", ".", "logsumexp", "(", "np", ".", "log", "(", "char_dist", ")", ")", "\n", "char_probs", ",", "support", "=", "list", "(", "zip", "(", "*", "sorted", "(", "list", "(", "zip", "(", "char_probs", ",", "sym_set", ")", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", ")", ")", "\n", "# print(\"NORMED AND SMOOTHED\",char_probs[sym_set.index('$')])", "\n", "\n", "return", "char_probs", ",", "support", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Factor_To_Character.likelihood": [[416, 425], ["translators.Factor_To_Character.forward", "print", "support.index"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.forward"], ["", "def", "likelihood", "(", "self", ",", "sequence", ",", "source_sentence", ",", "target", ",", "debug", "=", "False", ")", ":", "\n", "\n", "\t\t", "probs", ",", "support", "=", "self", ".", "forward", "(", "sequence", "=", "sequence", ",", "source_sentence", "=", "source_sentence", ")", "\n", "# print(target,\"target word\")", "\n", "try", ":", "out", "=", "probs", "[", "support", ".", "index", "(", "target", ")", "]", "\n", "except", ":", "\n", "\t\t\t", "print", "(", "\"target word failed:\"", ",", "target", ")", "\n", "raise", "Exception", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Constant.__init__": [[431, 446], ["None"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "support", ",", "unfolded_model", ",", "prior_ps", "=", "None", ",", "change_direction", "=", "True", ")", ":", "\n", "\n", "\t\t", "self", ".", "seg_type", "=", "\"sentence\"", "\n", "# self.support = [byte_pair_encoding(sentence=s,code_path=unfolded_model.bpe_code_path) for s in support]", "\n", "\n", "self", ".", "support", "=", "support", "\n", "\n", "# support", "\n", "# if not prior_ps is None:", "\n", "self", ".", "prior_ps", "=", "prior_ps", "\n", "self", ".", "unfolded_model", "=", "unfolded_model", "\n", "self", ".", "change_direction", "=", "change_direction", "\n", "# self.max_sentence_length = max_sentence_length[self.underlying_model.seg_type]", "\n", "self", ".", "cache", "=", "{", "}", "\n", "self", ".", "bpe_code_path", "=", "unfolded_model", ".", "bpe_code_path", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Constant.empty_cache": [[447, 450], ["translators.Constant.unfolded_model.empty_cache"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.empty_cache"], ["", "def", "empty_cache", "(", "self", ")", ":", "\n", "\t\t", "self", ".", "cache", "=", "{", "}", "\n", "self", ".", "unfolded_model", ".", "empty_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Constant.memoize_forward": [[451, 461], ["tuple", "tuple", "f"], "methods", ["None"], ["", "def", "memoize_forward", "(", "f", ")", ":", "\n", "\t\t", "def", "helper", "(", "self", ",", "sequence", ",", "source_sentence", ",", "debug", "=", "False", ")", ":", "\n", "\n", "# world_prior_list = np.ndarray.tolist(np.ndarray.flatten(state.world_priors))", "\n", "\t\t\t", "hashable_args", "=", "(", "tuple", "(", "sequence", ")", ",", "tuple", "(", "source_sentence", ")", ")", "\n", "if", "hashable_args", "not", "in", "self", ".", "cache", ":", "\n", "# print(\"MEM\\n\\n\")", "\n", "\t\t\t\t", "self", ".", "cache", "[", "hashable_args", "]", "=", "f", "(", "self", ",", "sequence", "=", "sequence", ",", "source_sentence", "=", "source_sentence", ",", "debug", "=", "debug", ")", "\n", "", "return", "self", ".", "cache", "[", "hashable_args", "]", "\n", "", "return", "helper", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Constant.forward": [[462, 509], ["len", "numpy.zeros", "numpy.zeros", "enumerate", "scipy.special.logsumexp", "numpy.log", "numpy.log", "translators.Constant.unfolded_model.likelihood", "translators.Constant.unfolded_model.likelihood", "numpy.zeros", "numpy.zeros", "print", "print", "print", "print", "print", "len"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.likelihood", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.likelihood"], ["", "@", "memoize_forward", "\n", "def", "forward", "(", "self", ",", "source_sentence", ",", "sequence", ",", "debug", "=", "False", ")", ":", "\n", "\n", "\t\t", "support_size", "=", "len", "(", "self", ".", "support", ")", "\n", "\n", "if", "self", ".", "prior_ps", "is", "None", ":", "\n", "\t\t\t", "self", ".", "prior_ps", "=", "np", ".", "log", "(", "np", ".", "zeros", "(", "len", "(", "self", ".", "support", ")", ")", "+", "(", "1", "/", "support_size", ")", ")", "\n", "\n", "", "scores", "=", "np", ".", "zeros", "(", "support_size", ")", "\n", "\n", "# print(\"STARTING\")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "self", ".", "support", ")", ":", "\n", "\t\t\t", "if", "debug", ":", "\n", "\t\t\t\t", "pass", "\n", "# print(\"CONSTANT\")", "\n", "", "if", "not", "self", ".", "change_direction", ":", "\n", "\t\t\t\t", "if", "debug", ":", "\n", "\t\t\t\t\t", "pass", "\n", "# print(\"CONSTANT\")", "\n", "# print(\"source sentence\",source_sentence)", "\n", "# print(\"sequence\",sequence)", "\n", "# print(\"target\",sent)", "\n", "# print(\"source_sentence\",source_sentence)", "\n", "", "score", "=", "self", ".", "unfolded_model", ".", "likelihood", "(", "source_sentence", "=", "source_sentence", ",", "sequence", "=", "sequence", ",", "target", "=", "sent", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "if", "debug", ":", "\n", "\t\t\t\t\t", "pass", "\n", "print", "(", "\"CONSTANT\"", ")", "\n", "print", "(", "\"source sentence\"", ",", "sent", ")", "\n", "print", "(", "\"sequence\"", ",", "sequence", ")", "\n", "print", "(", "\"target\"", ",", "source_sentence", ")", "\n", "# print(\"THING\",source_sentence)", "\n", "", "score", "=", "self", ".", "unfolded_model", ".", "likelihood", "(", "source_sentence", "=", "sent", ",", "sequence", "=", "[", "]", ",", "target", "=", "source_sentence", ")", "\n", "if", "debug", ":", "print", "(", "\"score\"", ",", "score", ")", "\n", "# print(\"score\",source_sentence)", "\n", "# print(\"score\",score,sent,\"source sent:\",source_sentence)", "\n", "", "scores", "[", "i", "]", "=", "score", "\n", "# print(\"STOPPING\")", "\n", "\n", "# print(np.exp(scores)/np.sum(np.exp(scores)))", "\n", "", "unnormed_posterior_ps", "=", "scores", "+", "self", ".", "prior_ps", "\n", "# print(\"POST\",unnormed_posterior_ps, source_sentence,sequence)", "\n", "norm", "=", "scipy", ".", "special", ".", "logsumexp", "(", "unnormed_posterior_ps", ")", "\n", "normed_posterior_ps", "=", "unnormed_posterior_ps", "-", "norm", "\n", "# print(\"finished\")", "\n", "# print(\"results\\n\\n\",normed_posterior_ps)", "\n", "return", "normed_posterior_ps", ",", "self", ".", "support", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Constant.likelihood": [[510, 521], ["translators.Constant.forward", "print", "print", "support.index"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.forward"], ["", "def", "likelihood", "(", "self", ",", "sequence", ",", "source_sentence", ",", "target", ",", "debug", "=", "False", ")", ":", "\n", "\n", "\n", "\t\t", "probs", ",", "support", "=", "self", ".", "forward", "(", "sequence", "=", "sequence", ",", "source_sentence", "=", "source_sentence", ",", "debug", "=", "debug", ")", "\n", "try", ":", "out", "=", "probs", "[", "support", ".", "index", "(", "target", ")", "]", "\n", "except", ":", "\n", "\t\t\t", "print", "(", "\"target word failed:\"", ",", "target", ")", "\n", "print", "(", "support", "[", ":", "10", "]", ")", "\n", "raise", "Exception", "\n", "# out = np.log(1.0)", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Compose.__init__": [[526, 537], ["translators.Unfold"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "rightward_model", ",", "leftward_model", ",", "unfolded_rightward_model", "=", "None", ")", ":", "\n", "\n", "\t\t", "self", ".", "rightward_model", "=", "rightward_model", "\n", "if", "unfolded_rightward_model", "is", "None", ":", "\n", "\t\t\t", "unfolded_rightward_model", "=", "Unfold", "(", "underlying_model", "=", "self", ".", "rightward_model", ")", "\n", "", "self", ".", "unfolded_rightward_model", "=", "unfolded_rightward_model", "\n", "self", ".", "leftward_model", "=", "leftward_model", "\n", "self", ".", "seg_type", "=", "leftward_model", ".", "seg_type", "\n", "self", ".", "cache", "=", "{", "}", "\n", "try", ":", "self", ".", "bpe_code_path", "=", "rightward_model", ".", "bpe_code_path", "\n", "except", ":", "self", ".", "bpe_code_path", "=", "unfolded_rightward_model", ".", "underlying_model", ".", "bpe_code_path", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Compose.memoize_forward": [[538, 547], ["tuple", "tuple", "f"], "methods", ["None"], ["", "def", "memoize_forward", "(", "f", ")", ":", "\n", "\t\t", "def", "helper", "(", "self", ",", "sequence", ",", "source_sentence", ",", "debug", "=", "False", ",", ")", ":", "\n", "\n", "\t\t\t", "hashable_args", "=", "(", "tuple", "(", "sequence", ")", ",", "tuple", "(", "source_sentence", ")", ",", "debug", ")", "\n", "if", "hashable_args", "not", "in", "self", ".", "cache", ":", "\n", "# print(\"MEM\\n\\n\")", "\n", "\t\t\t\t", "self", ".", "cache", "[", "hashable_args", "]", "=", "f", "(", "self", ",", "sequence", "=", "sequence", ",", "source_sentence", "=", "source_sentence", ",", "debug", "=", "debug", ",", ")", "\n", "", "return", "self", ".", "cache", "[", "hashable_args", "]", "\n", "", "return", "helper", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Compose.forward": [[548, 594], ["translators.Compose.unfolded_rightward_model.forward", "re.sub", "translators.Compose.leftward_model.forward", "list", "zip", "sorted", "list", "zip"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.forward", "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.forward"], ["", "@", "memoize_forward", "\n", "def", "forward", "(", "self", ",", "source_sentence", ",", "sequence", ",", "debug", "=", "False", ",", ")", ":", "\n", "\n", "\n", "\t\t", "inter_probs", ",", "inter_support", "=", "self", ".", "unfolded_rightward_model", ".", "forward", "(", "source_sentence", "=", "source_sentence", ",", "sequence", "=", "[", "]", ",", "debug", "=", "debug", ")", "\n", "\n", "# print(\"PROBS SUPP\",list(zip(inter_probs,inter_support)))", "\n", "\n", "target_lang_input", "=", "list", "(", "zip", "(", "*", "(", "sorted", "(", "list", "(", "zip", "(", "inter_support", ",", "inter_probs", ")", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", ")", ")", ")", "[", "0", "]", "[", "0", "]", "\n", "target_lang_input", "=", "re", ".", "sub", "(", "\"@@ \"", ",", "\"\"", ",", "target_lang_input", ")", "\n", "target_lang_input", "+=", "\".\"", "\n", "# target_sent = re.sub(\"\\.\",\"\",target_sent)", "\n", "\n", "# target_lang_input = byte_pair_encoding(sentence=target_lang_input,code_path=self.leftward_model.bpe_code_path)", "\n", "\n", "\n", "# print(\"target_lang_input\",target_lang_input)", "\n", "\n", "final_probs", ",", "final_support", "=", "self", ".", "leftward_model", ".", "forward", "(", "source_sentence", "=", "target_lang_input", ",", "sequence", "=", "sequence", ",", "debug", "=", "debug", ")", "\n", "\n", "if", "debug", ":", "\n", "\t\t\t", "pass", "\n", "# print(\"target support\",final_support)", "\n", "\n", "# if many_to_one:", "\n", "\n", "# \tprint(\"support\", final_support)", "\n", "\n", "# \tnew_final_support = []", "\n", "# \tnew_final_probs = []", "\n", "\n", "# \tback_translations = [self.unfolded_rightward_model.forward(source_sentence=s,sequence=[]) for s in final_support]", "\n", "\n", "# \tfor i, s in enumerate(final_support):", "\n", "\n", "# \t\tp,bt = self.unfolded_rightward_model.forward(source_sentence=s,sequence=[]) for s in final_support", "\n", "\n", "# \t\tif bt==target_lang_input:", "\n", "\n", "# \t\t\tnew_final_support.append(final_support[i])", "\n", "# \t\t\tnew_final_probs.append(final_probs[i])", "\n", "\n", "# \treturn new_final_probs, new_final_support", "\n", "\n", "# print(\"final_support\",final_support[:2])", "\n", "", "return", "final_probs", ",", "final_support", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Compose.likelihood": [[595, 604], ["translators.Compose.forward", "print", "support.index"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.forward"], ["", "def", "likelihood", "(", "self", ",", "sequence", ",", "source_sentence", ",", "target", ",", "debug", "=", "False", ")", ":", "\n", "\n", "\n", "\t\t", "probs", ",", "support", "=", "self", ".", "forward", "(", "sequence", "=", "sequence", ",", "source_sentence", "=", "source_sentence", ")", "\n", "try", ":", "out", "=", "probs", "[", "support", ".", "index", "(", "target", ")", "]", "\n", "except", ":", "\n", "\t\t\t", "print", "(", "\"target word failed:\"", ",", "target", ")", "\n", "raise", "Exception", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.__init__": [[607, 617], ["None"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "underlying_model", ",", "beam_width", "=", "1", ",", "diverse", "=", "False", ",", "stop_on", "=", "None", ")", ":", "\n", "\n", "\t\t", "self", ".", "seg_type", "=", "\"sentence\"", "\n", "self", ".", "underlying_model", "=", "underlying_model", "\n", "self", ".", "max_sentence_length", "=", "max_sentence_length", "[", "self", ".", "underlying_model", ".", "seg_type", "]", "\n", "self", ".", "cache", "=", "{", "}", "\n", "self", ".", "beam_width", "=", "beam_width", "\n", "self", ".", "diverse", "=", "diverse", "\n", "self", ".", "bpe_code_path", "=", "underlying_model", ".", "bpe_code_path", "\n", "self", ".", "stop_on", "=", "stop_on", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.empty_cache": [[618, 621], ["translators.Unfold.underlying_model.empty_cache"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.empty_cache"], ["", "def", "empty_cache", "(", "self", ")", ":", "\n", "\t\t", "self", ".", "cache", "=", "{", "}", "\n", "self", ".", "underlying_model", ".", "empty_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.memoize_forward": [[622, 632], ["tuple", "tuple", "f"], "methods", ["None"], ["", "def", "memoize_forward", "(", "f", ")", ":", "\n", "\t\t", "def", "helper", "(", "self", ",", "sequence", ",", "source_sentence", ",", "debug", "=", "False", ")", ":", "\n", "\n", "\t\t\t", "hashable_args", "=", "(", "tuple", "(", "sequence", ")", ",", "tuple", "(", "source_sentence", ")", ",", "debug", ")", "\n", "if", "hashable_args", "not", "in", "self", ".", "cache", ":", "\n", "# print(\"MEM\\n\\n\")", "\n", "# print(self.cache)", "\n", "\t\t\t\t", "self", ".", "cache", "[", "hashable_args", "]", "=", "f", "(", "self", ",", "sequence", "=", "sequence", ",", "source_sentence", "=", "source_sentence", ",", "debug", "=", "debug", ")", "\n", "", "return", "self", ".", "cache", "[", "hashable_args", "]", "\n", "", "return", "helper", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.forward": [[633, 781], ["tqdm.tqdm.tqdm", "list", "numpy.array", "numpy.array", "list", "print", "range", "sorted", "numpy.array.append", "zip", "list", "translators.Unfold.underlying_model.forward", "enumerate", "list.append", "list.append", "scipy.misc.logsumexp", "numpy.squeeze", "numpy.squeeze", "print", "len", "sorted", "copy.deepcopy", "new_sent_prob.append", "list", "copy.deepcopy", "final_sentences.append", "copy.deepcopy", "new_sent_prob.append", "zip", "new_sent_prob.append", "penultimate_sequence.append", "set", "len", "math.pow"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.forward"], ["", "@", "memoize_forward", "\n", "def", "forward", "(", "self", ",", "source_sentence", ",", "sequence", ",", "debug", "=", "False", ")", ":", "\n", "# print(\"DEBUG?\",debug,\"STOP ON\",stop_on)", "\n", "\n", "# log = open('log','w')", "\n", "# source_words = byte_pair_encoding(sentence=byte_pair_decoding(source_sentence),code_path=self.bpe_code_path).split()", "\n", "# print(\"source words\",source_words)", "\n", "\n", "\t\t", "decay_rate", "=", "0", "\n", "cut_rate", "=", "1", "\n", "\n", "beam_width", "=", "self", ".", "beam_width", "\n", "# print(\"BEAM SEARCH\",beam_width)", "\n", "\n", "greedy", "=", "beam_width", "==", "1", "\n", "if", "greedy", "and", "debug", ":", "\n", "\t\t\t", "print", "(", "\"GREEDY SEARCH\"", ")", "\n", "\n", "", "sent_prob", "=", "[", "(", "sequence", ",", "0.0", ")", "]", "\n", "\n", "\n", "final_sentences", "=", "[", "]", "\n", "for", "step", "in", "tqdm", "(", "range", "(", "1", ",", "self", ".", "max_sentence_length", ")", ")", ":", "\n", "\n", "\n", "\t\t\t", "new_sent_prob", "=", "[", "]", "\n", "for", "sent", ",", "old_prob", "in", "sent_prob", ":", "\n", "\n", "\t\t\t\t", "sequence", "=", "sent", "\n", "# print(sequence,\"SEQ\")", "\n", "dist", ",", "support", "=", "self", ".", "underlying_model", ".", "forward", "(", "sequence", "=", "sequence", ",", "source_sentence", "=", "source_sentence", ",", "debug", "=", "debug", ")", "\n", "dist", ",", "support", "=", "dist", "[", ":", "]", ",", "support", "[", ":", "]", "\n", "# print(dist,support)", "\n", "# raise Exception", "\n", "# print(dist,support)", "\n", "# raise Exception", "\n", "for", "seg", ",", "prob", "in", "enumerate", "(", "np", ".", "squeeze", "(", "dist", ")", ")", ":", "\n", "\n", "# cond1 = support[seg] not in source_words", "\n", "# cond2 = support[seg][0]!=support[seg][0].lower()", "\n", "# cond3 = step>1", "\n", "# print(sent)", "\n", "# cond4 = len(sent)>0  and sent[-1][-1]=='@'", "\n", "\t\t\t\t\t", "if", "True", ":", "\n", "# if (cond2 and cond3) or (cond4 or cond1):", "\n", "# if (support[seg] not in source_words) or (support[seg][0]!=support[seg][0].lower() and step>1) :", "\n", "\t\t\t\t\t\t", "new_sentence", "=", "copy", ".", "deepcopy", "(", "sent", ")", "\n", "new_sentence", "+=", "[", "support", "[", "seg", "]", "]", "\n", "new_prob", "=", "(", "prob", "*", "(", "1", "/", "math", ".", "pow", "(", "step", ",", "decay_rate", ")", ")", ")", "+", "old_prob", "\n", "new_sent_prob", ".", "append", "(", "(", "new_sentence", ",", "new_prob", ")", ")", "\n", "# if seg=='The':", "\n", "# print(seg,source_words,seg in source_words)", "\n", "# raise Exception", "\n", "# print(\"tick\")", "\n", "\n", "", "if", "False", ":", "\n", "\t\t\t\t\t\t", "prior", "=", "1", "\n", "self", ".", "underlying_model", ".", "unfolded_leftward_model", ".", "support", "=", "prior", "\n", "\n", "", "", "", "sent_prob", "=", "sorted", "(", "new_sent_prob", ",", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "if", "(", "step", "-", "1", ")", "%", "cut_rate", "==", "0", ":", "\n", "# cut down to size", "\n", "# if False:", "\n", "\t\t\t\t", "if", "self", ".", "diverse", "and", "step", ">", "2", ":", "\n", "\n", "\t\t\t\t\t", "index", "=", "-", "2", "\n", "# if step==1: index = -1", "\n", "# elif step>1: index = -2", "\n", "\n", "# print(\"sent_prob\", sent_prob[-10:],len(sent_prob))", "\n", "new_sent_prob", "=", "[", "]", "\n", "penultimate_sequence", "=", "[", "]", "\n", "for", "sent", ",", "prob", "in", "sent_prob", ":", "\n", "\n", "\t\t\t\t\t\t", "if", "sent", "[", ":", "index", "+", "1", "]", "not", "in", "penultimate_sequence", ":", "\n", "\t\t\t\t\t\t\t", "new_sent_prob", ".", "append", "(", "(", "sent", ",", "prob", ")", ")", "\n", "\n", "penultimate_sequence", ".", "append", "(", "sent", "[", ":", "index", "+", "1", "]", ")", "\n", "\n", "# print(\"penultimate_sequence\",penultimate_sequence[:10])", "\n", "", "", "print", "(", "list", "(", "set", "(", "[", "sent", "[", "0", "]", "for", "(", "sent", ",", "prob", ")", "in", "sent_prob", "]", ")", ")", ")", "\n", "# raise Exception", "\n", "sent_prob", "=", "new_sent_prob", "\n", "# print(\"new sent_prob\",sent_prob[:10])", "\n", "\n", "#identify last word variants: remove all but max", "\n", "\n", "", "sent_prob", "=", "sent_prob", "[", ":", "beam_width", "]", "\n", "new_sent_prob", "=", "[", "]", "\n", "for", "sent", ",", "prob", "in", "sent_prob", ":", "\n", "# print(prob)", "\n", "\t\t\t\t\t", "st", "=", "stop_token", "[", "self", ".", "underlying_model", ".", "seg_type", "]", "\n", "# sent[-1] in ['.','?','!'] or", "\n", "if", "sent", "[", "-", "1", "]", "==", "st", "or", "(", "len", "(", "sent", ")", ">", "1", "and", "sent", "[", "-", "2", "]", "in", "[", "'.'", ",", "'?'", ",", "'!'", ",", "'<eos>'", "]", ")", "or", "sent", "[", "-", "1", "]", "==", "\"<Lua heritage>\"", "or", "sent", "[", "-", "1", "]", "==", "self", ".", "stop_on", "or", "sent", "[", "-", "1", "]", "==", "\"&\"", ":", "\n", "# if debug: print(\"\\n\\nENDING TOKEN\\n\\n\",sent[-1])", "\n", "\t\t\t\t\t\t", "final_sentence", "=", "copy", ".", "deepcopy", "(", "sent", ")", "\n", "final_sentences", ".", "append", "(", "(", "final_sentence", ",", "prob", ")", ")", "\n", "", "else", ":", "\n", "\t\t\t\t\t\t", "new_tuple", "=", "copy", ".", "deepcopy", "(", "(", "sent", ",", "prob", ")", ")", "\n", "new_sent_prob", ".", "append", "(", "new_tuple", ")", "\n", "\n", "\n", "", "", "sent_prob", "=", "new_sent_prob", "\n", "\n", "if", "len", "(", "final_sentences", ")", "==", "beam_width", ":", "\n", "# print(\"LEN FINAL SENTENCES = beam width\")", "\n", "\t\t\t\t\t", "break", "\n", "\n", "# if debug and sent_prob!=[]: print(sent_prob,\"SELECTION\")", "\n", "\n", "\n", "# try:", "\n", "# \tfor x in sent_prob:", "\n", "# \t\tprint(\"sentence\")", "\n", "# \t\tif self.underlying_model.seg_type=='word':", "\n", "# \t\t\tprint(\" \".join(x[0]),x[1][step],x[2])", "\n", "# \t\telse:print(\"\".join(x[0])[1:])", "\n", "# except: pass", "\n", "\n", "", "", "", "probs", "=", "[", "]", "\n", "support", "=", "[", "]", "\n", "\n", "\n", "if", "final_sentences", "==", "[", "]", ":", "final_sentences", "=", "sent_prob", "\n", "for", "sent", ",", "prob", "in", "final_sentences", ":", "\n", "\t\t\t", "probs", ".", "append", "(", "prob", ")", "\n", "if", "self", ".", "underlying_model", ".", "seg_type", "==", "'char'", ":", "\n", "\t\t\t\t", "support", ".", "append", "(", "\"\"", ".", "join", "(", "sent", "[", ":", "-", "1", "]", ")", ")", "\n", "# if support[-1][-1] not in ", "\n", "", "else", ":", "support", ".", "append", "(", "\" \"", ".", "join", "(", "sent", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "\n", "# probs = np.array(probs)", "\n", "# return probs,support", "\n", "# normed_probs = probs - scipy.misc.logsumexp(probs)", "\n", "\n", "# raise Exception", "\n", "", "probs", ",", "support", "=", "list", "(", "zip", "(", "*", "sorted", "(", "zip", "(", "probs", ",", "support", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", ")", ")", "\n", "probs", ",", "support", "=", "probs", "[", ":", "beam_width", "]", ",", "support", "[", ":", "beam_width", "]", "\n", "probs", "=", "np", ".", "array", "(", "list", "(", "probs", ")", ")", "\n", "support", "=", "list", "(", "support", ")", "\n", "# assert (probs.shape[0] == beam_width)", "\n", "# print(\"CHECKS\")", "\n", "# print(\"len probs\",probs)", "\n", "# print(\"len support\",support)", "\n", "# return probs,support", "\n", "return", "(", "probs", "-", "scipy", ".", "misc", ".", "logsumexp", "(", "probs", ")", ")", ",", "support", "\n", "\n"]], "home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.likelihood": [[782, 795], ["range", "numpy.sum", "numpy.sum", "target.split", "len", "translators.Unfold.underlying_model.likelihood", "likelihood.items"], "methods", ["home.repos.pwc.inspect_result.reubenharry_pragmatic-translation.translators.translators.Unfold.likelihood"], ["", "def", "likelihood", "(", "self", ",", "sequence", ",", "source_sentence", ",", "target", ",", "debug", "=", "False", ")", ":", "\n", "\t\t", "if", "self", ".", "underlying_model", ".", "seg_type", "==", "\"word\"", ":", "\n", "\t\t\t", "new_target", "=", "target", ".", "split", "(", ")", "\n", "", "else", ":", "new_target", "=", "target", "\n", "likelihood", "=", "{", "}", "\n", "new_sequence", "=", "sequence", "[", ":", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "new_target", ")", ")", ":", "\n", "\t\t\t", "seg", "=", "new_target", "[", "i", "]", "\n", "likelihood", "[", "i", "]", "=", "self", ".", "underlying_model", ".", "likelihood", "(", "sequence", "=", "new_sequence", ",", "source_sentence", "=", "source_sentence", ",", "target", "=", "seg", ",", "debug", "=", "debug", ")", "\n", "new_sequence", "+=", "[", "new_target", "[", "i", "]", "]", "\n", "\n", "\n", "", "return", "np", ".", "sum", "(", "[", "p", "for", "(", "l", ",", "p", ")", "in", "likelihood", ".", "items", "(", ")", "]", ")", "\n", "\n"]]}