{"home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.keras_wraper_ensemble.KerasModelWrapper.__init__": [[22, 35], ["cleverhans.model.Model.__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.datasets.Dataset.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "num_class", "=", "10", ")", ":", "\n", "        ", "\"\"\"\n        Create a wrapper for a Keras model\n        :param model: A Keras model\n        \"\"\"", "\n", "super", "(", "KerasModelWrapper", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "model", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "'model argument must be supplied.'", ")", "\n", "\n", "", "self", ".", "model", "=", "model", "\n", "self", ".", "keras_model", "=", "None", "\n", "self", ".", "num_classes", "=", "num_class", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.keras_wraper_ensemble.KerasModelWrapper._get_softmax_name": [[36, 47], ["Exception", "layer.get_config"], "methods", ["None"], ["", "def", "_get_softmax_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n    Looks for the name of the softmax layer.\n    :return: Softmax layer name\n    \"\"\"", "\n", "for", "layer", "in", "self", ".", "model", ".", "layers", ":", "\n", "            ", "cfg", "=", "layer", ".", "get_config", "(", ")", "\n", "if", "cfg", "[", "'name'", "]", "==", "'average_1'", ":", "\n", "                ", "return", "layer", ".", "name", "\n", "\n", "", "", "raise", "Exception", "(", "\"No softmax layers found\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.keras_wraper_ensemble.KerasModelWrapper._get_logits_name": [[48, 72], ["keras_wraper_ensemble.KerasModelWrapper._get_softmax_name", "keras_wraper_ensemble.KerasModelWrapper.model.get_layer", "hasattr", "isinstance", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.keras_wraper_ensemble.KerasModelWrapper._get_softmax_name", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.keras_wraper_ensemble.KerasModelWrapper.get_layer"], ["", "def", "_get_logits_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n    Looks for the name of the layer producing the logits.\n    :return: name of layer producing the logits\n    \"\"\"", "\n", "softmax_name", "=", "self", ".", "_get_softmax_name", "(", ")", "\n", "softmax_layer", "=", "self", ".", "model", ".", "get_layer", "(", "softmax_name", ")", "\n", "\n", "if", "not", "isinstance", "(", "softmax_layer", ",", "Activation", ")", ":", "\n", "# In this case, the activation is part of another layer", "\n", "            ", "return", "softmax_name", "\n", "\n", "", "if", "hasattr", "(", "softmax_layer", ",", "'inbound_nodes'", ")", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"Please update your version to keras >= 2.1.3; \"", "\n", "\"support for earlier keras versions will be dropped on \"", "\n", "\"2018-07-22\"", ")", "\n", "node", "=", "softmax_layer", ".", "inbound_nodes", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "node", "=", "softmax_layer", ".", "_inbound_nodes", "[", "0", "]", "\n", "\n", "", "logits_name", "=", "node", ".", "inbound_layers", "[", "0", "]", ".", "name", "\n", "\n", "return", "logits_name", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.keras_wraper_ensemble.KerasModelWrapper.get_logits": [[73, 92], ["keras_wraper_ensemble.KerasModelWrapper.get_probs", "tensorflow.log"], "methods", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.keras_wraper_ensemble.KerasModelWrapper.get_probs"], ["", "def", "get_logits", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n    :param x: A symbolic representation of the network input.\n    :return: A symbolic representation of the logits\n    \"\"\"", "\n", "# logits_name = self._get_logits_name()", "\n", "# logits_layer = self.get_layer(x, logits_name)", "\n", "\n", "# # Need to deal with the case where softmax is part of the", "\n", "# # logits layer", "\n", "# if logits_name == self._get_softmax_name():", "\n", "#   softmax_logit_layer = self.get_layer(x, logits_name)", "\n", "\n", "#   # The final op is the softmax. Return its input", "\n", "#   logits_layer = softmax_logit_layer._op.inputs[0]", "\n", "prob", "=", "self", ".", "get_probs", "(", "x", ")", "\n", "logits", "=", "tf", ".", "log", "(", "prob", ")", "\n", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.keras_wraper_ensemble.KerasModelWrapper.get_probs": [[93, 100], ["keras_wraper_ensemble.KerasModelWrapper.model"], "methods", ["None"], ["", "def", "get_probs", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n    :param x: A symbolic representation of the network input.\n    :return: A symbolic representation of the probs\n    \"\"\"", "\n", "\n", "return", "self", ".", "model", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.keras_wraper_ensemble.KerasModelWrapper.get_layer_names": [[101, 107], ["None"], "methods", ["None"], ["", "def", "get_layer_names", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n    :return: Names of all the layers kept by Keras\n    \"\"\"", "\n", "layer_names", "=", "[", "x", ".", "name", "for", "x", "in", "self", ".", "model", ".", "layers", "]", "\n", "return", "layer_names", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.keras_wraper_ensemble.KerasModelWrapper.fprop": [[108, 137], ["keras_wraper_ensemble.KerasModelWrapper.keras_model", "dict", "keras_wraper_ensemble.KerasModelWrapper.model.get_input_at", "KerasModel", "len", "zip", "keras_wraper_ensemble.KerasModelWrapper.get_layer_names"], "methods", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.keras_wraper_ensemble.KerasModelWrapper.get_layer_names"], ["", "def", "fprop", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n    Exposes all the layers of the model returned by get_layer_names.\n    :param x: A symbolic representation of the network input\n    :return: A dictionary mapping layer names to the symbolic\n             representation of their output.\n    \"\"\"", "\n", "from", "tf", ".", "keras", ".", "models", "import", "Model", "as", "KerasModel", "\n", "\n", "if", "self", ".", "keras_model", "is", "None", ":", "\n", "# Get the input layer", "\n", "            ", "new_input", "=", "self", ".", "model", ".", "get_input_at", "(", "0", ")", "\n", "\n", "# Make a new model that returns each of the layers as output", "\n", "out_layers", "=", "[", "x_layer", ".", "output", "for", "x_layer", "in", "self", ".", "model", ".", "layers", "]", "\n", "self", ".", "keras_model", "=", "KerasModel", "(", "new_input", ",", "out_layers", ")", "\n", "\n", "# and get the outputs for that model on the input x", "\n", "", "outputs", "=", "self", ".", "keras_model", "(", "x", ")", "\n", "\n", "# Keras only returns a list for outputs of length >= 1, if the model", "\n", "# is only one layer, wrap a list", "\n", "if", "len", "(", "self", ".", "model", ".", "layers", ")", "==", "1", ":", "\n", "            ", "outputs", "=", "[", "outputs", "]", "\n", "\n", "# compute the dict to return", "\n", "", "fprop_dict", "=", "dict", "(", "zip", "(", "self", ".", "get_layer_names", "(", ")", ",", "outputs", ")", ")", "\n", "\n", "return", "fprop_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.keras_wraper_ensemble.KerasModelWrapper.get_layer": [[138, 153], ["keras_wraper_ensemble.KerasModelWrapper.fprop", "cleverhans.model.NoSuchLayerError"], "methods", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.keras_wraper_ensemble.KerasModelWrapper.fprop"], ["", "def", "get_layer", "(", "self", ",", "x", ",", "layer", ")", ":", "\n", "        ", "\"\"\"\n    Expose the hidden features of a model given a layer name.\n    :param x: A symbolic representation of the network input\n    :param layer: The name of the hidden layer to return features at.\n    :return: A symbolic representation of the hidden features\n    :raise: NoSuchLayerError if `layer` is not in the model.\n    \"\"\"", "\n", "# Return the symbolic representation for this layer.", "\n", "output", "=", "self", ".", "fprop", "(", "x", ")", "\n", "try", ":", "\n", "            ", "requested", "=", "output", "[", "layer", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "raise", "NoSuchLayerError", "(", ")", "\n", "", "return", "requested", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.tf_shuffle": [[18, 20], ["tensorflow.gather", "tensorflow.random_shuffle", "tensorflow.range", "tensorflow.shape"], "function", ["None"], ["def", "tf_shuffle", "(", "x", ")", ":", "\n", "  ", "return", "tf", ".", "gather", "(", "x", ",", "tf", ".", "random_shuffle", "(", "tf", ".", "range", "(", "tf", ".", "shape", "(", "x", ")", "[", "0", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.tf_roll": [[21, 27], ["tensorflow.concat", "x.get_shape().as_list", "x.get_shape"], "function", ["None"], ["", "def", "tf_roll", "(", "x", ",", "shift", "=", "1", ",", "axis", "=", "0", ")", ":", "\n", "# return tf.roll(x, shift=shift, axis=axis)", "\n", "  ", "assert", "(", "axis", "==", "0", ")", "\n", "nb", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "y", "=", "tf", ".", "concat", "(", "[", "x", "[", "shift", ":", "]", ",", "x", "[", "0", ":", "shift", "]", "]", ",", "axis", "=", "axis", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.tf_repeat": [[28, 36], ["x.get_shape().as_list", "tensorflow.tile", "len", "x.get_shape"], "function", ["None"], ["", "def", "tf_repeat", "(", "x", ",", "n", ",", "axis", "=", "0", ")", ":", "\n", "  ", "x_shape", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "# [b, d1, d2]", "\n", "multiples", "=", "len", "(", "x_shape", ")", "*", "[", "1", "]", "\n", "if", "x_shape", "[", "axis", "]", "is", "not", "None", ":", "\n", "    ", "multiples", "[", "axis", "]", "=", "n", "\n", "\n", "", "x_r", "=", "tf", ".", "tile", "(", "x", ",", "multiples", "=", "multiples", ")", "\n", "return", "x_r", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.l2_batch_normalize": [[37, 52], ["tensorflow.name_scope", "tensorflow.shape", "tensorflow.contrib.layers.flatten", "tensorflow.reduce_sum", "tensorflow.rsqrt", "tensorflow.multiply", "tensorflow.reshape", "tensorflow.reduce_max", "tensorflow.square", "tensorflow.abs", "numpy.sqrt"], "function", ["None"], ["", "def", "l2_batch_normalize", "(", "x", ",", "epsilon", "=", "1e-12", ",", "scope", "=", "None", ",", "axis", "=", "None", ",", "keepdims", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n  Helper function to normalize a batch of vectors.\n  :param x: the input placeholder\n  :param epsilon: stabilizes division\n  :return: the batch of l2 normalized vector\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "scope", ",", "\"l2_batch_normalize\"", ")", "as", "name_scope", ":", "\n", "    ", "x_shape", "=", "tf", ".", "shape", "(", "x", ")", "\n", "x", "=", "tf", ".", "contrib", ".", "layers", ".", "flatten", "(", "x", ")", "\n", "x", "/=", "(", "epsilon", "+", "tf", ".", "reduce_max", "(", "tf", ".", "abs", "(", "x", ")", ",", "1", ",", "keepdims", "=", "True", ")", ")", "\n", "square_sum", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "x", ")", ",", "1", ",", "keepdims", "=", "True", ")", "\n", "x_inv_norm", "=", "tf", ".", "rsqrt", "(", "np", ".", "sqrt", "(", "epsilon", ")", "+", "square_sum", ")", "\n", "x_norm", "=", "tf", ".", "multiply", "(", "x", ",", "x_inv_norm", ")", "\n", "return", "tf", ".", "reshape", "(", "x_norm", ",", "x_shape", ",", "name_scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.kl_with_logits": [[53, 65], ["tensorflow.name_scope", "tensorflow.nn.softmax", "tensorflow.nn.log_softmax", "tensorflow.nn.log_softmax", "tensorflow.reduce_mean", "tensorflow.losses.add_loss", "tensorflow.reduce_sum"], "function", ["None"], ["", "", "def", "kl_with_logits", "(", "p_logits", ",", "q_logits", ",", "scope", "=", "None", ",", "\n", "loss_collection", "=", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ")", ":", "\n", "  ", "\"\"\"Helper function to compute kl-divergence KL(p || q)\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "scope", ",", "\"kl_divergence\"", ")", "as", "name", ":", "\n", "    ", "p", "=", "tf", ".", "nn", ".", "softmax", "(", "p_logits", ")", "\n", "p_log", "=", "tf", ".", "nn", ".", "log_softmax", "(", "p_logits", ")", "\n", "q_log", "=", "tf", ".", "nn", ".", "log_softmax", "(", "q_logits", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "p", "*", "(", "p_log", "-", "q_log", ")", ",", "axis", "=", "1", ")", ",", "\n", "name", "=", "name", ")", "\n", "tf", ".", "losses", ".", "add_loss", "(", "loss", ",", "loss_collection", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.add_eta": [[66, 74], ["utils_tf.random_lp_vector", "utils_tf.clip_eta", "x.get_shape().as_list", "utils_tf.clip_by_value", "x.get_shape"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.random_lp_vector", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.clip_eta", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.clip_by_value"], ["", "", "def", "add_eta", "(", "x", ",", "ord", ",", "eps", ",", "clip_value_min", "=", "None", ",", "clip_value_max", "=", "None", ",", "seed", "=", "None", ")", ":", "\n", "  ", "eta", "=", "random_lp_vector", "(", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "ord", "=", "ord", ",", "eps", "=", "eps", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "seed", "=", "seed", ")", "\n", "eta", "=", "clip_eta", "(", "eta", ",", "ord", ",", "eps", ")", "\n", "adv_x", "=", "x", "+", "eta", "\n", "if", "clip_value_min", "is", "not", "None", "or", "clip_value_max", "is", "not", "None", ":", "\n", "    ", "adv_x", "=", "clip_by_value", "(", "adv_x", ",", "clip_value_min", ",", "clip_value_max", ")", "\n", "", "return", "adv_x", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.add_eta_np": [[75, 81], ["utils_tf.clip_eta", "utils_tf.clip_by_value"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.clip_eta", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.clip_by_value"], ["", "def", "add_eta_np", "(", "x", ",", "eta", ",", "ord", ",", "eps", ",", "clip_value_min", "=", "None", ",", "clip_value_max", "=", "None", ",", "seed", "=", "None", ")", ":", "\n", "  ", "eta", "=", "clip_eta", "(", "eta", ",", "ord", ",", "eps", ")", "\n", "adv_x", "=", "x", "+", "eta", "\n", "if", "clip_value_min", "is", "not", "None", "or", "clip_value_max", "is", "not", "None", ":", "\n", "    ", "adv_x", "=", "clip_by_value", "(", "adv_x", ",", "clip_value_min", ",", "clip_value_max", ")", "\n", "", "return", "adv_x", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.clip_eta": [[83, 143], ["list", "ValueError", "six.moves.xrange", "utils_tf.clip_by_value", "len", "tensorflow.cast", "tensorflow.reduce_prod", "tensorflow.reshape", "tensorflow.abs", "tensorflow.cumsum", "tensorflow.cast", "tensorflow.cast", "tensorflow.argmax", "tensorflow.reduce_max", "tensorflow.divide", "tensorflow.sign", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.where", "tf.where.get_shape", "dir", "tensorflow.divide", "tensorflow.greater", "tensorflow.cast", "tensorflow.maximum", "tensorflow.shape", "tensorflow.abs", "tensorflow.greater", "tensorflow.sqrt", "tensorflow.minimum", "tensorflow.shape", "tensorflow.sort", "tensorflow.nn.top_k", "tensorflow.range", "tensorflow.maximum", "utils_tf.div", "tensorflow.reduce_sum", "tensorflow.square"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.clip_by_value", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.div"], ["", "def", "clip_eta", "(", "eta", ",", "ord", ",", "eps", ")", ":", "\n", "  ", "\"\"\"\n  Helper function to clip the perturbation to epsilon norm ball.\n  :param eta: A tensor with the current perturbation.\n  :param ord: Order of the norm (mimics Numpy).\n              Possible values: np.inf, 1 or 2.\n  :param eps: Epsilon, bound of the perturbation.\n  \"\"\"", "\n", "\n", "# Clipping perturbation eta to self.ord norm ball", "\n", "if", "ord", "not", "in", "[", "np", ".", "inf", ",", "1", ",", "2", "]", ":", "\n", "    ", "raise", "ValueError", "(", "'ord must be np.inf, 1, or 2.'", ")", "\n", "", "reduc_ind", "=", "list", "(", "xrange", "(", "1", ",", "len", "(", "eta", ".", "get_shape", "(", ")", ")", ")", ")", "\n", "avoid_zero_div", "=", "1e-12", "\n", "if", "ord", "==", "np", ".", "inf", ":", "\n", "    ", "eta", "=", "clip_by_value", "(", "eta", ",", "-", "eps", ",", "eps", ")", "\n", "", "elif", "ord", "==", "1", ":", "\n", "# Implements a projection algorithm onto the l1-ball from", "\n", "# (Duchi et al. 2008) that runs in time O(d*log(d)) where d is the", "\n", "# input dimension.", "\n", "# Paper link (Duchi et al. 2008): https://dl.acm.org/citation.cfm?id=1390191", "\n", "\n", "    ", "eps", "=", "tf", ".", "cast", "(", "eps", ",", "eta", ".", "dtype", ")", "\n", "\n", "dim", "=", "tf", ".", "reduce_prod", "(", "tf", ".", "shape", "(", "eta", ")", "[", "1", ":", "]", ")", "\n", "eta_flat", "=", "tf", ".", "reshape", "(", "eta", ",", "(", "-", "1", ",", "dim", ")", ")", "\n", "abs_eta", "=", "tf", ".", "abs", "(", "eta_flat", ")", "\n", "\n", "if", "'sort'", "in", "dir", "(", "tf", ")", ":", "\n", "      ", "mu", "=", "-", "tf", ".", "sort", "(", "-", "abs_eta", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "# `tf.sort` is only available in TF 1.13 onwards", "\n", "      ", "mu", "=", "tf", ".", "nn", ".", "top_k", "(", "abs_eta", ",", "k", "=", "dim", ",", "sorted", "=", "True", ")", "[", "0", "]", "\n", "", "cumsums", "=", "tf", ".", "cumsum", "(", "mu", ",", "axis", "=", "-", "1", ")", "\n", "js", "=", "tf", ".", "cast", "(", "tf", ".", "divide", "(", "1", ",", "tf", ".", "range", "(", "1", ",", "dim", "+", "1", ")", ")", ",", "eta", ".", "dtype", ")", "\n", "t", "=", "tf", ".", "cast", "(", "tf", ".", "greater", "(", "mu", "-", "js", "*", "(", "cumsums", "-", "eps", ")", ",", "0", ")", ",", "eta", ".", "dtype", ")", "\n", "\n", "rho", "=", "tf", ".", "argmax", "(", "t", "*", "cumsums", ",", "axis", "=", "-", "1", ")", "\n", "rho_val", "=", "tf", ".", "reduce_max", "(", "t", "*", "cumsums", ",", "axis", "=", "-", "1", ")", "\n", "theta", "=", "tf", ".", "divide", "(", "rho_val", "-", "eps", ",", "tf", ".", "cast", "(", "1", "+", "rho", ",", "eta", ".", "dtype", ")", ")", "\n", "\n", "eta_sgn", "=", "tf", ".", "sign", "(", "eta_flat", ")", "\n", "eta_proj", "=", "eta_sgn", "*", "tf", ".", "maximum", "(", "abs_eta", "-", "theta", "[", ":", ",", "tf", ".", "newaxis", "]", ",", "0", ")", "\n", "eta_proj", "=", "tf", ".", "reshape", "(", "eta_proj", ",", "tf", ".", "shape", "(", "eta", ")", ")", "\n", "\n", "norm", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "abs", "(", "eta", ")", ",", "reduc_ind", ")", "\n", "eta", "=", "tf", ".", "where", "(", "tf", ".", "greater", "(", "norm", ",", "eps", ")", ",", "eta_proj", ",", "eta", ")", "\n", "\n", "", "elif", "ord", "==", "2", ":", "\n", "# avoid_zero_div must go inside sqrt to avoid a divide by zero", "\n", "# in the gradient through this operation", "\n", "    ", "norm", "=", "tf", ".", "sqrt", "(", "tf", ".", "maximum", "(", "avoid_zero_div", ",", "\n", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "eta", ")", ",", "\n", "reduc_ind", ",", "\n", "keepdims", "=", "True", ")", ")", ")", "\n", "# We must *clip* to within the norm ball, not *normalize* onto the", "\n", "# surface of the ball", "\n", "factor", "=", "tf", ".", "minimum", "(", "1.", ",", "div", "(", "eps", ",", "norm", ")", ")", "\n", "eta", "=", "eta", "*", "factor", "\n", "", "return", "eta", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.zero_out_clipped_grads": [[145, 166], ["tensorflow.sign", "tensorflow.logical_and", "tensorflow.logical_and", "tensorflow.logical_or", "tensorflow.where", "tensorflow.less_equal", "tensorflow.less", "tensorflow.greater_equal", "tensorflow.greater", "utils_tf.mul", "tensorflow.cast", "tensorflow.cast"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.mul"], ["", "def", "zero_out_clipped_grads", "(", "grad", ",", "x", ",", "clip_min", ",", "clip_max", ")", ":", "\n", "  ", "\"\"\"\n  Helper function to erase entries in the gradient where the update would be\n  clipped.\n  :param grad: The gradient\n  :param x: The current input\n  :param clip_min: Minimum input component value\n  :param clip_max: Maximum input component value\n  \"\"\"", "\n", "signed_grad", "=", "tf", ".", "sign", "(", "grad", ")", "\n", "\n", "# Find input components that lie at the boundary of the input range, and", "\n", "# where the gradient points in the wrong direction.", "\n", "clip_low", "=", "tf", ".", "logical_and", "(", "tf", ".", "less_equal", "(", "x", ",", "tf", ".", "cast", "(", "clip_min", ",", "x", ".", "dtype", ")", ")", ",", "\n", "tf", ".", "less", "(", "signed_grad", ",", "0", ")", ")", "\n", "clip_high", "=", "tf", ".", "logical_and", "(", "tf", ".", "greater_equal", "(", "x", ",", "tf", ".", "cast", "(", "clip_max", ",", "x", ".", "dtype", ")", ")", ",", "\n", "tf", ".", "greater", "(", "signed_grad", ",", "0", ")", ")", "\n", "clip", "=", "tf", ".", "logical_or", "(", "clip_low", ",", "clip_high", ")", "\n", "grad", "=", "tf", ".", "where", "(", "clip", ",", "mul", "(", "grad", ",", "0", ")", ",", "grad", ")", "\n", "\n", "return", "grad", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.random_exponential": [[168, 174], ["tensorflow.random_gamma"], "function", ["None"], ["", "def", "random_exponential", "(", "shape", ",", "rate", "=", "1.0", ",", "dtype", "=", "tf", ".", "float32", ",", "seed", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n  Helper function to sample from the exponential distribution, which is not\n  included in core TensorFlow.\n  \"\"\"", "\n", "return", "tf", ".", "random_gamma", "(", "shape", ",", "alpha", "=", "1", ",", "beta", "=", "1.", "/", "rate", ",", "dtype", "=", "dtype", ",", "seed", "=", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.random_laplace": [[176, 184], ["utils_tf.random_exponential", "utils_tf.random_exponential"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.random_exponential", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.random_exponential"], ["", "def", "random_laplace", "(", "shape", ",", "loc", "=", "0.0", ",", "scale", "=", "1.0", ",", "dtype", "=", "tf", ".", "float32", ",", "seed", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n  Helper function to sample from the Laplace distribution, which is not\n  included in core TensorFlow.\n  \"\"\"", "\n", "z1", "=", "random_exponential", "(", "shape", ",", "loc", ",", "dtype", "=", "dtype", ",", "seed", "=", "seed", ")", "\n", "z2", "=", "random_exponential", "(", "shape", ",", "scale", ",", "dtype", "=", "dtype", ",", "seed", "=", "seed", ")", "\n", "return", "z1", "-", "z2", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.random_lp_vector": [[186, 231], ["ValueError", "tensorflow.random_uniform", "tensorflow.reduce_prod", "tensorflow.pow", "utils_tf.random_laplace", "tensorflow.reduce_sum", "tensorflow.random.uniform", "tensorflow.reshape", "tensorflow.abs", "tensorflow.random_normal", "tensorflow.sqrt", "ValueError", "tensorflow.cast", "tensorflow.reduce_sum", "tensorflow.square"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.random_laplace"], ["", "def", "random_lp_vector", "(", "shape", ",", "ord", ",", "eps", ",", "dtype", "=", "tf", ".", "float32", ",", "seed", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n  Helper function to generate uniformly random vectors from a norm ball of\n  radius epsilon.\n  :param shape: Output shape of the random sample. The shape is expected to be\n                of the form `(n, d1, d2, ..., dn)` where `n` is the number of\n                i.i.d. samples that will be drawn from a norm ball of dimension\n                `d1*d1*...*dn`.\n  :param ord: Order of the norm (mimics Numpy).\n              Possible values: np.inf, 1 or 2.\n  :param eps: Epsilon, radius of the norm ball.\n  \"\"\"", "\n", "if", "ord", "not", "in", "[", "np", ".", "inf", ",", "1", ",", "2", "]", ":", "\n", "    ", "raise", "ValueError", "(", "'ord must be np.inf, 1, or 2.'", ")", "\n", "\n", "", "if", "ord", "==", "np", ".", "inf", ":", "\n", "    ", "r", "=", "tf", ".", "random_uniform", "(", "shape", ",", "-", "eps", ",", "eps", ",", "dtype", "=", "dtype", ",", "seed", "=", "seed", ")", "\n", "", "else", ":", "\n", "\n", "# For ord=1 and ord=2, we use the generic technique from", "\n", "# (Calafiore et al. 1998) to sample uniformly from a norm ball.", "\n", "# Paper link (Calafiore et al. 1998):", "\n", "# https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=758215&tag=1", "\n", "# We first sample from the surface of the norm ball, and then scale by", "\n", "# a factor `w^(1/d)` where `w~U[0,1]` is a standard uniform random variable", "\n", "# and `d` is the dimension of the ball. In high dimensions, this is roughly", "\n", "# equivalent to sampling from the surface of the ball.", "\n", "\n", "    ", "dim", "=", "tf", ".", "reduce_prod", "(", "shape", "[", "1", ":", "]", ")", "\n", "\n", "if", "ord", "==", "1", ":", "\n", "      ", "x", "=", "random_laplace", "(", "(", "shape", "[", "0", "]", ",", "dim", ")", ",", "loc", "=", "1.0", ",", "scale", "=", "1.0", ",", "dtype", "=", "dtype", ",", "\n", "seed", "=", "seed", ")", "\n", "norm", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "abs", "(", "x", ")", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "", "elif", "ord", "==", "2", ":", "\n", "      ", "x", "=", "tf", ".", "random_normal", "(", "(", "shape", "[", "0", "]", ",", "dim", ")", ",", "dtype", "=", "dtype", ",", "seed", "=", "seed", ")", "\n", "norm", "=", "tf", ".", "sqrt", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "x", ")", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "'ord must be np.inf, 1, or 2.'", ")", "\n", "\n", "", "w", "=", "tf", ".", "pow", "(", "tf", ".", "random", ".", "uniform", "(", "(", "shape", "[", "0", "]", ",", "1", ")", ",", "dtype", "=", "dtype", ",", "seed", "=", "seed", ")", ",", "\n", "1.0", "/", "tf", ".", "cast", "(", "dim", ",", "dtype", ")", ")", "\n", "r", "=", "eps", "*", "tf", ".", "reshape", "(", "w", "*", "x", "/", "norm", ",", "shape", ")", "\n", "\n", "", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.random_lp_vector_np": [[232, 266], ["numpy.random.seed", "ValueError", "numpy.random.uniform", "numpy.prod", "numpy.power", "numpy.random.laplace", "numpy.sum", "numpy.random.uniform", "numpy.reshape", "numpy.abs", "numpy.random.normal", "numpy.sqrt", "ValueError", "numpy.sum", "numpy.square"], "function", ["None"], ["", "def", "random_lp_vector_np", "(", "shape", ",", "ord", ",", "eps", ",", "seed", "=", "None", ")", ":", "\n", "  ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "if", "ord", "not", "in", "[", "np", ".", "inf", ",", "1", ",", "2", "]", ":", "\n", "    ", "raise", "ValueError", "(", "'ord must be np.inf, 1, or 2.'", ")", "\n", "\n", "", "if", "ord", "==", "np", ".", "inf", ":", "\n", "    ", "r", "=", "np", ".", "random", ".", "uniform", "(", "size", "=", "shape", ",", "low", "=", "-", "eps", ",", "high", "=", "eps", ")", "\n", "", "else", ":", "\n", "\n", "# For ord=1 and ord=2, we use the generic technique from", "\n", "# (Calafiore et al. 1998) to sample uniformly from a norm ball.", "\n", "# Paper link (Calafiore et al. 1998):", "\n", "# https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=758215&tag=1", "\n", "# We first sample from the surface of the norm ball, and then scale by", "\n", "# a factor `w^(1/d)` where `w~U[0,1]` is a standard uniform random variable", "\n", "# and `d` is the dimension of the ball. In high dimensions, this is roughly", "\n", "# equivalent to sampling from the surface of the ball.", "\n", "\n", "    ", "dim", "=", "np", ".", "prod", "(", "shape", "[", "1", ":", "]", ")", "\n", "\n", "if", "ord", "==", "1", ":", "\n", "      ", "x", "=", "np", ".", "random", ".", "laplace", "(", "size", "=", "(", "shape", "[", "0", "]", ",", "dim", ")", ",", "loc", "=", "1.0", ",", "scale", "=", "1.0", ")", "\n", "norm", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "x", ")", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "", "elif", "ord", "==", "2", ":", "\n", "      ", "x", "=", "np", ".", "random", ".", "normal", "(", "size", "=", "(", "shape", "[", "0", "]", ",", "dim", ")", ")", "\n", "norm", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "x", ")", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "'ord must be np.inf, 1, or 2.'", ")", "\n", "\n", "", "w", "=", "np", ".", "power", "(", "np", ".", "random", ".", "uniform", "(", "size", "=", "(", "shape", "[", "0", "]", ",", "1", ")", ")", ",", "1.0", "/", "dim", ")", "\n", "r", "=", "eps", "*", "np", ".", "reshape", "(", "w", "*", "x", "/", "norm", ",", "shape", ")", "\n", "\n", "", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.clip_by_value": [[267, 287], ["utils_tf.clip_by_value.cast_clip"], "function", ["None"], ["", "def", "clip_by_value", "(", "t", ",", "clip_value_min", ",", "clip_value_max", ",", "name", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n  A wrapper for clip_by_value that casts the clipping range if needed.\n  \"\"\"", "\n", "def", "cast_clip", "(", "clip", ")", ":", "\n", "    ", "\"\"\"\n    Cast clipping range argument if needed.\n    \"\"\"", "\n", "if", "t", ".", "dtype", "in", "(", "tf", ".", "float32", ",", "tf", ".", "float64", ")", ":", "\n", "      ", "if", "hasattr", "(", "clip", ",", "'dtype'", ")", ":", "\n", "# Convert to tf dtype in case this is a numpy dtype", "\n", "        ", "clip_dtype", "=", "tf", ".", "as_dtype", "(", "clip", ".", "dtype", ")", "\n", "if", "clip_dtype", "!=", "t", ".", "dtype", ":", "\n", "          ", "return", "tf", ".", "cast", "(", "clip", ",", "t", ".", "dtype", ")", "\n", "", "", "", "return", "clip", "\n", "\n", "", "clip_value_min", "=", "cast_clip", "(", "clip_value_min", ")", "\n", "clip_value_max", "=", "cast_clip", "(", "clip_value_max", ")", "\n", "\n", "return", "tf", ".", "clip_by_value", "(", "t", ",", "clip_value_min", ",", "clip_value_max", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.mul": [[289, 298], ["utils_tf.op_with_scalar_cast"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.op_with_scalar_cast"], ["", "def", "mul", "(", "a", ",", "b", ")", ":", "\n", "  ", "\"\"\"\n  A wrapper around tf multiplication that does more automatic casting of\n  the input.\n  \"\"\"", "\n", "def", "multiply", "(", "a", ",", "b", ")", ":", "\n", "    ", "\"\"\"Multiplication\"\"\"", "\n", "return", "a", "*", "b", "\n", "", "return", "op_with_scalar_cast", "(", "a", ",", "b", ",", "multiply", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.div": [[299, 308], ["utils_tf.op_with_scalar_cast"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.op_with_scalar_cast"], ["", "def", "div", "(", "a", ",", "b", ")", ":", "\n", "  ", "\"\"\"\n  A wrapper around tf division that does more automatic casting of\n  the input.\n  \"\"\"", "\n", "def", "divide", "(", "a", ",", "b", ")", ":", "\n", "    ", "\"\"\"Division\"\"\"", "\n", "return", "a", "/", "b", "\n", "", "return", "op_with_scalar_cast", "(", "a", ",", "b", ",", "divide", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.op_with_scalar_cast": [[309, 347], ["utils_tf.op_with_scalar_cast.is_scalar"], "function", ["None"], ["", "def", "op_with_scalar_cast", "(", "a", ",", "b", ",", "f", ")", ":", "\n", "  ", "\"\"\"\n  Builds the graph to compute f(a, b).\n  If only one of the two arguments is a scalar and the operation would\n  cause a type error without casting, casts the scalar to match the\n  tensor.\n  :param a: a tf-compatible array or scalar\n  :param b: a tf-compatible array or scalar\n  \"\"\"", "\n", "\n", "try", ":", "\n", "    ", "return", "f", "(", "a", ",", "b", ")", "\n", "", "except", "(", "TypeError", ",", "ValueError", ")", ":", "\n", "    ", "pass", "\n", "\n", "", "def", "is_scalar", "(", "x", ")", ":", "\n", "    ", "\"\"\"Return True if `x` is a scalar\"\"\"", "\n", "if", "hasattr", "(", "x", ",", "\"get_shape\"", ")", ":", "\n", "      ", "shape", "=", "x", ".", "get_shape", "(", ")", "\n", "return", "shape", ".", "ndims", "==", "0", "\n", "", "if", "hasattr", "(", "x", ",", "\"ndim\"", ")", ":", "\n", "      ", "return", "x", ".", "ndim", "==", "0", "\n", "", "assert", "isinstance", "(", "x", ",", "(", "int", ",", "float", ")", ")", "\n", "return", "True", "\n", "\n", "", "a_scalar", "=", "is_scalar", "(", "a", ")", "\n", "b_scalar", "=", "is_scalar", "(", "b", ")", "\n", "\n", "if", "a_scalar", "and", "b_scalar", ":", "\n", "    ", "raise", "TypeError", "(", "\"Trying to apply \"", "+", "str", "(", "f", ")", "+", "\" with mixed types\"", ")", "\n", "\n", "", "if", "a_scalar", "and", "not", "b_scalar", ":", "\n", "    ", "a", "=", "tf", ".", "cast", "(", "a", ",", "b", ".", "dtype", ")", "\n", "\n", "", "if", "b_scalar", "and", "not", "a_scalar", ":", "\n", "    ", "b", "=", "tf", ".", "cast", "(", "b", ",", "a", ".", "dtype", ")", "\n", "\n", "", "return", "f", "(", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.assert_less_equal": [[348, 356], ["tensorflow.device", "tensorflow.assert_less_equal"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.assert_less_equal"], ["", "def", "assert_less_equal", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "  ", "\"\"\"\n  Wrapper for tf.assert_less_equal\n  Overrides tf.device so that the assert always goes on CPU.\n  The unwrapped version raises an exception if used with tf.device(\"/GPU:x\").\n  \"\"\"", "\n", "with", "tf", ".", "device", "(", "\"/CPU:0\"", ")", ":", "\n", "    ", "return", "tf", ".", "assert_less_equal", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.assert_greater_equal": [[357, 365], ["tensorflow.device", "tensorflow.assert_greater_equal"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.assert_greater_equal"], ["", "", "def", "assert_greater_equal", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "  ", "\"\"\"\n  Wrapper for tf.assert_greater_equal.\n  Overrides tf.device so that the assert always goes on CPU.\n  The unwrapped version raises an exception if used with tf.device(\"/GPU:x\").\n  \"\"\"", "\n", "with", "tf", ".", "device", "(", "\"/CPU:0\"", ")", ":", "\n", "    ", "return", "tf", ".", "assert_greater_equal", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.assert_equal": [[366, 374], ["tensorflow.device", "tensorflow.assert_equal"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_tf.assert_equal"], ["", "", "def", "assert_equal", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "  ", "\"\"\"\n  Wrapper for tf.assert_equal.\n  Overrides tf.device so that the assert always goes on CPU.\n  The unwrapped version raises an exception if used with tf.device(\"/GPU:x\").\n  \"\"\"", "\n", "with", "tf", ".", "device", "(", "\"/CPU:0\"", ")", ":", "\n", "    ", "return", "tf", ".", "assert_equal", "(", "*", "args", ",", "**", "kwargs", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_cm.mkdir_p": [[6, 9], ["os.path.exists", "os.makedirs"], "function", ["None"], ["def", "mkdir_p", "(", "path", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_cm.copyfile": [[10, 14], ["os.path.dirname", "utils_cm.mkdir_p", "shutil.copyfile"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_cm.mkdir_p", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_cm.copyfile"], ["", "", "def", "copyfile", "(", "src", ",", "dst", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "dirname", "(", "dst", ")", "\n", "mkdir_p", "(", "path", ")", "\n", "shutil", ".", "copyfile", "(", "src", ",", "dst", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_cm.chdir_p": [[15, 19], ["os.chdir", "print", "os.path.dirname", "os.path.realpath"], "function", ["None"], ["", "def", "chdir_p", "(", "path", "=", "'/content/drive/My Drive/Workspace/OT/myOT/'", ")", ":", "\n", "    ", "os", ".", "chdir", "(", "path", ")", "\n", "WP", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "'__file__'", ")", ")", "+", "'/'", "\n", "print", "(", "'CHANGING WORKING PATH: '", ",", "WP", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_cm.writelog": [[20, 27], ["open", "open.write", "open.flush", "open.close", "print"], "function", ["None"], ["", "def", "writelog", "(", "data", "=", "None", ",", "logfile", "=", "None", ",", "printlog", "=", "True", ")", ":", "\n", "    ", "fid", "=", "open", "(", "logfile", ",", "'a'", ")", "\n", "fid", ".", "write", "(", "'%s\\n'", "%", "(", "data", ")", ")", "\n", "fid", ".", "flush", "(", ")", "\n", "fid", ".", "close", "(", ")", "\n", "if", "printlog", ":", "\n", "        ", "print", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_cm.dict2str": [[28, 35], ["d.keys"], "function", ["None"], ["", "", "def", "dict2str", "(", "d", ")", ":", "\n", "# assert(type(d)==dict)", "\n", "    ", "res", "=", "''", "\n", "for", "k", "in", "d", ".", "keys", "(", ")", ":", "\n", "        ", "v", "=", "d", "[", "k", "]", "\n", "res", "=", "res", "+", "'{}:{},'", ".", "format", "(", "k", ",", "v", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_cm.list2str": [[36, 42], ["None"], "function", ["None"], ["", "def", "list2str", "(", "l", ")", ":", "\n", "# assert(type(l)==list)", "\n", "    ", "res", "=", "''", "\n", "for", "i", "in", "l", ":", "\n", "        ", "res", "=", "res", "+", "' {}'", ".", "format", "(", "i", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_cm.str2bool": [[43, 53], ["isinstance", "v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["", "def", "str2bool", "(", "v", ")", ":", "\n", "# https://stackoverflow.com/questions/15008758/parsing-boolean-values-with-argparse", "\n", "    ", "if", "isinstance", "(", "v", ",", "bool", ")", ":", "\n", "       ", "return", "v", "\n", "", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_cm.delete_existing": [[54, 64], ["os.path.exists", "os.path.exists", "shutil.rmtree"], "function", ["None"], ["", "", "def", "delete_existing", "(", "path", ",", "overwrite", "=", "True", ")", ":", "\n", "    ", "\"\"\"Delete directory if it exists\n\n    Used for automatically rewrites existing log directories\n    \"\"\"", "\n", "if", "not", "overwrite", ":", "\n", "        ", "assert", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ",", "\"Cannot overwrite {:s}\"", ".", "format", "(", "path", ")", "\n", "", "else", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_cm.backup": [[65, 70], ["glob.iglob", "os.path.join", "os.path.isfile", "shutil.copy2"], "function", ["None"], ["", "", "", "def", "backup", "(", "source_dir", ",", "dest_dir", ")", ":", "\n", "    ", "files", "=", "glob", ".", "iglob", "(", "os", ".", "path", ".", "join", "(", "source_dir", ",", "\"*.py\"", ")", ")", "\n", "for", "file", "in", "files", ":", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "file", ")", ":", "\n", "            ", "shutil", ".", "copy2", "(", "file", ",", "dest_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_cm.list_dir": [[72, 78], ["sorted", "sorted", "glob.glob", "glob.glob"], "function", ["None"], ["", "", "", "def", "list_dir", "(", "folder_dir", ",", "filetype", "=", "'.png'", ")", ":", "\n", "    ", "if", "'.'", "in", "filetype", ":", "\n", "        ", "all_dir", "=", "sorted", "(", "glob", ".", "glob", "(", "folder_dir", "+", "\"*\"", "+", "filetype", ")", ",", "key", "=", "os", ".", "path", ".", "getmtime", ")", "\n", "", "else", ":", "\n", "        ", "all_dir", "=", "sorted", "(", "glob", ".", "glob", "(", "folder_dir", "+", "\"*.\"", "+", "filetype", ")", ",", "key", "=", "os", ".", "path", ".", "getmtime", ")", "\n", "", "return", "all_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_cm.split_dict": [[79, 103], ["d.keys", "range", "type", "dict", "d.keys", "all_dicts.append", "numpy.maximum", "utils_cm.split_dict._get"], "function", ["None"], ["", "def", "split_dict", "(", "d", ")", ":", "\n", "    ", "assert", "(", "type", "(", "d", ")", "is", "dict", ")", "\n", "all_dicts", "=", "[", "]", "\n", "nb_d", "=", "1", "\n", "for", "k", "in", "d", ".", "keys", "(", ")", ":", "\n", "        ", "if", "type", "(", "d", "[", "k", "]", ")", "is", "list", "or", "type", "(", "d", "[", "k", "]", ")", "is", "tuple", ":", "\n", "            ", "nb_d", "=", "np", ".", "maximum", "(", "nb_d", ",", "len", "(", "d", "[", "k", "]", ")", ")", "\n", "\n", "", "", "def", "_get", "(", "d", ",", "k", ",", "i", ")", ":", "\n", "        ", "v", "=", "d", "[", "k", "]", "\n", "if", "type", "(", "v", ")", "is", "list", "or", "type", "(", "v", ")", "is", "tuple", ":", "\n", "            ", "if", "i", "<=", "len", "(", "v", ")", ":", "\n", "                ", "return", "v", "[", "i", "]", "\n", "", "else", ":", "\n", "                ", "return", "v", "[", "-", "1", "]", "\n", "", "", "else", ":", "\n", "            ", "return", "v", "\n", "\n", "", "", "for", "i", "in", "range", "(", "nb_d", ")", ":", "\n", "        ", "new_dict", "=", "dict", "(", ")", "\n", "for", "k", "in", "d", ".", "keys", "(", ")", ":", "\n", "            ", "new_dict", "[", "k", "]", "=", "_get", "(", "d", ",", "k", ",", "i", ")", "\n", "", "all_dicts", ".", "append", "(", "new_dict", ")", "\n", "", "return", "all_dicts", "", "", ""]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.main_train.adv_acc_metric": [[189, 196], ["tensorflow.split", "tensorflow.split", "range", "tensorflow.keras.metrics.categorical_accuracy"], "function", ["None"], ["def", "adv_acc_metric", "(", "y_true", ",", "y_pred", ",", "num_models", "=", "FLAGS", ".", "num_models", ")", ":", "\n", "    ", "y_p", "=", "tf", ".", "split", "(", "adv_pred_concat", ",", "num_models", ",", "axis", "=", "-", "1", ")", "\n", "y_t", "=", "tf", ".", "split", "(", "y_true", ",", "num_models", ",", "axis", "=", "-", "1", ")", "\n", "acc", "=", "0", "\n", "for", "i", "in", "range", "(", "num_models", ")", ":", "\n", "        ", "acc", "+=", "tf", ".", "keras", ".", "metrics", ".", "categorical_accuracy", "(", "y_t", "[", "i", "]", ",", "y_p", "[", "i", "]", ")", "\n", "", "return", "acc", "/", "num_models", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.lib_method.get_loss": [[8, 20], ["lib_method.adv_NONE", "lib_method.adv_ADP", "lib_method.adv_EN", "lib_method.adv_EN", "lib_method.adv_CCE"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.lib_method.adv_NONE", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.lib_method.adv_ADP", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.lib_method.adv_EN", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.lib_method.adv_EN", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.lib_method.adv_CCE"], ["def", "get_loss", "(", "method", ",", "adv_pred_concat", ",", "nor_pred_concat", ",", "adv_pred", ",", "nor_pred", ")", ":", "\n", "    ", "if", "method", "==", "'none'", ":", "\n", "        ", "return", "adv_NONE", "(", "nor_pred_concat", ")", "\n", "", "elif", "method", "==", "'adp'", ":", "\n", "        ", "return", "adv_ADP", "(", "adv_pred_concat", ",", "nor_pred_concat", ")", "\n", "", "elif", "method", "==", "'adv'", ":", "\n", "        ", "assert", "(", "FLAGS", ".", "num_models", "==", "1", ")", "\n", "return", "adv_EN", "(", "adv_pred_concat", ",", "nor_pred_concat", ")", "\n", "", "elif", "method", "==", "'adv_en'", ":", "\n", "        ", "return", "adv_EN", "(", "adv_pred_concat", ",", "nor_pred_concat", ")", "\n", "", "elif", "method", "==", "'cce'", ":", "\n", "        ", "return", "adv_CCE", "(", "adv_pred", ",", "nor_pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.lib_method.adv_ADP": [[22, 44], ["tensorflow.split", "tensorflow.split", "range", "utils.Ensemble_Entropy", "utils.log_det", "lib_method.adv_ADP._Loss_withEE_DPP"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils.Ensemble_Entropy", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils.log_det"], ["", "", "def", "adv_ADP", "(", "adv_pred_concat", ",", "nor_pred_concat", ")", ":", "\n", "    ", "def", "adv_EEDPP", "(", "_y_true", ",", "_y_pred", ")", ":", "\n", "        ", "return", "_Loss_withEE_DPP", "(", "_y_true", ",", "adv_pred_concat", ")", "+", "_Loss_withEE_DPP", "(", "_y_true", ",", "nor_pred_concat", ")", "\n", "\n", "", "def", "_Loss_withEE_DPP", "(", "y_true", ",", "\n", "y_pred", ",", "\n", "num_models", "=", "FLAGS", ".", "num_models", ",", "\n", "label_smooth", "=", "FLAGS", ".", "label_smooth", ")", ":", "\n", "\n", "        ", "scale", "=", "(", "1", "-", "label_smooth", ")", "/", "(", "num_classes", "*", "label_smooth", "-", "1", ")", "\n", "y_t_ls", "=", "scale", "*", "tf", ".", "ones_like", "(", "y_true", ")", "+", "y_true", "\n", "y_t_ls", "=", "(", "num_models", "*", "y_t_ls", ")", "/", "tf", ".", "reduce_sum", "(", "y_t_ls", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "y_p", "=", "tf", ".", "split", "(", "y_pred", ",", "num_models", ",", "axis", "=", "-", "1", ")", "\n", "y_t", "=", "tf", ".", "split", "(", "y_t_ls", ",", "num_models", ",", "axis", "=", "-", "1", ")", "\n", "CE_all", "=", "0", "\n", "for", "i", "in", "range", "(", "num_models", ")", ":", "\n", "            ", "CE_all", "+=", "keras", ".", "losses", ".", "categorical_crossentropy", "(", "y_t", "[", "i", "]", ",", "y_p", "[", "i", "]", ")", "\n", "", "EE", "=", "Ensemble_Entropy", "(", "y_true", ",", "y_pred", ",", "num_models", ")", "\n", "log_dets", "=", "log_det", "(", "y_true", ",", "y_pred", ",", "num_models", ")", "\n", "return", "CE_all", "-", "FLAGS", ".", "lamda", "*", "EE", "-", "FLAGS", ".", "log_det_lamda", "*", "log_dets", "\n", "\n", "", "return", "adv_EEDPP", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.lib_method.adv_EN": [[45, 59], ["tensorflow.split", "tensorflow.split", "range", "lib_method.adv_EN._Loss_CE"], "function", ["None"], ["", "def", "adv_EN", "(", "adv_pred_concat", ",", "nor_pred_concat", ")", ":", "\n", "    ", "def", "adv_CE", "(", "_y_true", ",", "_y_pred", ")", ":", "\n", "        ", "return", "_Loss_CE", "(", "_y_true", ",", "adv_pred_concat", ")", "+", "_Loss_CE", "(", "_y_true", ",", "nor_pred_concat", ")", "\n", "\n", "", "def", "_Loss_CE", "(", "y_true", ",", "y_pred", ",", "num_models", "=", "FLAGS", ".", "num_models", ")", ":", "\n", "        ", "y_p", "=", "tf", ".", "split", "(", "y_pred", ",", "num_models", ",", "axis", "=", "-", "1", ")", "\n", "y_t", "=", "tf", ".", "split", "(", "y_true", ",", "num_models", ",", "axis", "=", "-", "1", ")", "\n", "CE_all", "=", "0", "\n", "for", "i", "in", "range", "(", "num_models", ")", ":", "\n", "            ", "CE_all", "+=", "keras", ".", "losses", ".", "categorical_crossentropy", "(", "y_t", "[", "i", "]", ",", "y_p", "[", "i", "]", ")", "\n", "\n", "", "return", "CE_all", "\n", "\n", "", "return", "adv_CE", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.lib_method.adv_NONE": [[60, 74], ["lib_method.adv_EN._Loss_CE"], "function", ["None"], ["", "def", "adv_NONE", "(", "nor_pred_concat", ")", ":", "\n", "    ", "def", "adv_CE", "(", "_y_true", ",", "_y_pred", ")", ":", "\n", "        ", "return", "_Loss_CE", "(", "_y_true", ",", "nor_pred_concat", ")", "\n", "\n", "", "def", "_Loss_CE", "(", "y_true", ",", "y_pred", ",", "num_models", "=", "FLAGS", ".", "num_models", ")", ":", "\n", "        ", "y_p", "=", "tf", ".", "split", "(", "y_pred", ",", "num_models", ",", "axis", "=", "-", "1", ")", "\n", "y_t", "=", "tf", ".", "split", "(", "y_true", ",", "num_models", ",", "axis", "=", "-", "1", ")", "\n", "CE_all", "=", "0", "\n", "for", "i", "in", "range", "(", "num_models", ")", ":", "\n", "            ", "CE_all", "+=", "keras", ".", "losses", ".", "categorical_crossentropy", "(", "y_t", "[", "i", "]", ",", "y_p", "[", "i", "]", ")", "\n", "\n", "", "return", "CE_all", "\n", "\n", "", "return", "adv_CE", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.lib_method.adv_CCE": [[75, 120], ["tensorflow.split", "dict", "range", "range", "tensorflow.multiply", "tensorflow.reduce_sum", "tensorflow.keras.losses.categorical_crossentropy", "tensorflow.keras.losses.categorical_crossentropy", "range", "lib_method.adv_CCE._fil_pred"], "function", ["None"], ["", "def", "adv_CCE", "(", "adv_pred", ",", "nor_pred", ",", "num_models", "=", "FLAGS", ".", "num_models", ",", "wce", "=", "FLAGS", ".", "wce", ",", "wdm", "=", "FLAGS", ".", "wdm", ",", "wpm", "=", "FLAGS", ".", "wpm", ")", ":", "\n", "    ", "\"\"\"\n    crossing collaborative ensemble algorithm \n        using predicted label to decide a next action: \n            if argmax(_y_pred) == argmax(_y_true):\n                promoting model_i with adversarial example x_j\n            else: \n                demoting model_i with adversarial example x_j\n    \"\"\"", "\n", "def", "cceloss", "(", "_y_true", ",", "_y_pred", ",", "return_loss_i", "=", "False", ")", ":", "\n", "        ", "true_y", "=", "tf", ".", "split", "(", "_y_true", ",", "num_models", ",", "axis", "=", "-", "1", ")", "\n", "loss_i", "=", "dict", "(", ")", "\n", "for", "i", "in", "range", "(", "num_models", ")", ":", "\n", "            ", "CE_nor_i", "=", "tf", ".", "keras", ".", "losses", ".", "categorical_crossentropy", "(", "true_y", "[", "i", "]", ",", "nor_pred", "[", "i", "]", ")", "\n", "CE_adv_i", "=", "tf", ".", "keras", ".", "losses", ".", "categorical_crossentropy", "(", "true_y", "[", "i", "]", ",", "adv_pred", "[", "'m'", "+", "str", "(", "i", ")", "]", "[", "'x'", "+", "str", "(", "i", ")", "]", ")", "\n", "loss_i", "[", "i", "]", "=", "CE_nor_i", "+", "wce", "*", "CE_adv_i", "\n", "for", "j", "in", "range", "(", "num_models", ")", ":", "\n", "                ", "if", "j", "!=", "i", ":", "\n", "                    ", "w", "=", "_fil_pred", "(", "true_y", ",", "adv_pred", "[", "'m'", "+", "str", "(", "i", ")", "]", "[", "'x'", "+", "str", "(", "j", ")", "]", ")", "# [batch_size, ]", "\n", "cce", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "adv_pred", "[", "'m'", "+", "str", "(", "i", ")", "]", "[", "'x'", "+", "str", "(", "j", ")", "]", ",", "\n", "adv_pred", "[", "'m'", "+", "str", "(", "i", ")", "]", "[", "'x'", "+", "str", "(", "j", ")", "]", ")", "# [batch_size, ]", "\n", "\n", "ce", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "true_y", "[", "i", "]", ",", "\n", "adv_pred", "[", "'m'", "+", "str", "(", "i", ")", "]", "[", "'x'", "+", "str", "(", "j", ")", "]", ")", "# [batch_size, ]", "\n", "\n", "if", "wdm", "!=", "0", ":", "\n", "                        ", "loss_i", "[", "i", "]", "-=", "wdm", "/", "(", "num_models", "-", "1", ")", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "multiply", "(", "cce", ",", "1.0000001", "-", "w", ")", ",", "axis", "=", "0", ")", "\n", "", "if", "wpm", "!=", "0", ":", "\n", "                        ", "loss_i", "[", "i", "]", "+=", "wpm", "/", "(", "num_models", "-", "1", ")", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "multiply", "(", "ce", ",", "w", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "", "", "loss_a", "=", "0", "\n", "for", "i", "in", "range", "(", "num_models", ")", ":", "\n", "            ", "loss_a", "+=", "loss_i", "[", "i", "]", "\n", "\n", "", "if", "return_loss_i", ":", "\n", "            ", "return", "loss_a", ",", "loss_i", "\n", "", "else", ":", "\n", "            ", "return", "loss_a", "\n", "\n", "", "", "def", "_fil_pred", "(", "y_true", ",", "y_pred", ")", ":", "\n", "# return the probability of the true index ", "\n", "        ", "t", "=", "tf", ".", "multiply", "(", "y_true", ",", "y_pred", ")", "\n", "return", "tf", ".", "reduce_sum", "(", "t", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "return", "cceloss", "", "", ""]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.main_eval_bbattack.init_attack.__init__": [[137, 139], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "attack", ")", ":", "\n", "        ", "self", ".", "attack", "=", "attack", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.main_eval_bbattack.init_attack.run": [[140, 142], ["main_eval_bbattack.init_attack.attack"], "methods", ["None"], ["", "def", "run", "(", "self", ",", "model", ",", "originals", ",", "criterion_", ")", ":", "\n", "        ", "return", "self", ".", "attack", "(", "model", ",", "images", ",", "criterion", "=", "criterion_", ",", "epsilons", "=", "0.3", ")", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_model.get_lr_schedule": [[13, 20], ["utils_model.lr_schedule_cifar10", "utils_model.lr_schedule_mnist", "utils_model.lr_schedule_cifar100"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_model.lr_schedule_cifar10", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_model.lr_schedule_mnist", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_model.lr_schedule_cifar100"], ["def", "get_lr_schedule", "(", "epoch", ",", "dataset", "=", "FLAGS", ".", "dataset", ")", ":", "\n", "    ", "if", "dataset", "==", "'cifar10'", ":", "\n", "        ", "return", "lr_schedule_cifar10", "(", "epoch", ")", "\n", "", "elif", "dataset", "==", "'mnist'", ":", "\n", "        ", "return", "lr_schedule_mnist", "(", "epoch", ")", "\n", "", "elif", "dataset", "==", "'cifar100'", ":", "\n", "        ", "return", "lr_schedule_cifar100", "(", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_model.lr_schedule_cifar10": [[23, 41], ["print"], "function", ["None"], ["def", "lr_schedule_cifar10", "(", "epoch", ")", ":", "\n", "    ", "\"\"\"Learning Rate Schedule\n    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n    Called automatically every epoch as part of callbacks during training.\n    # Arguments\n        epoch (int): The number of epochs\n    # Returns\n        lr (float32): learning rate\n    \"\"\"", "\n", "lr", "=", "1e-3", "\n", "if", "epoch", ">", "160", ":", "\n", "        ", "lr", "*=", "1e-3", "\n", "", "elif", "epoch", ">", "120", ":", "\n", "        ", "lr", "*=", "1e-2", "\n", "", "elif", "epoch", ">", "80", ":", "\n", "        ", "lr", "*=", "1e-1", "\n", "", "print", "(", "'Learning rate: '", ",", "lr", ")", "\n", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_model.lr_schedule_cifar100": [[42, 60], ["print"], "function", ["None"], ["", "def", "lr_schedule_cifar100", "(", "epoch", ")", ":", "\n", "    ", "\"\"\"Learning Rate Schedule\n    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n    Called automatically every epoch as part of callbacks during training.\n    # Arguments\n        epoch (int): The number of epochs\n    # Returns\n        lr (float32): learning rate\n    \"\"\"", "\n", "lr", "=", "1e-3", "\n", "if", "epoch", ">", "160", ":", "\n", "        ", "lr", "*=", "1e-3", "\n", "", "elif", "epoch", ">", "120", ":", "\n", "        ", "lr", "*=", "1e-2", "\n", "", "elif", "epoch", ">", "80", ":", "\n", "        ", "lr", "*=", "1e-1", "\n", "", "print", "(", "'Learning rate: '", ",", "lr", ")", "\n", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_model.lr_schedule_mnist": [[61, 77], ["print"], "function", ["None"], ["", "def", "lr_schedule_mnist", "(", "epoch", ")", ":", "\n", "    ", "\"\"\"Learning Rate Schedule\n    Learning rate is scheduled to be reduced after 15, 30 epochs.\n    Called automatically every epoch as part of callbacks during training.\n    # Arguments\n        epoch (int): The number of epochs\n    # Returns\n        lr (float32): learning rate\n    \"\"\"", "\n", "lr", "=", "1e-3", "\n", "if", "epoch", ">", "30", ":", "\n", "        ", "lr", "*=", "1e-2", "\n", "", "elif", "epoch", ">", "15", ":", "\n", "        ", "lr", "*=", "1e-1", "\n", "", "print", "(", "'Learning rate: '", ",", "lr", ")", "\n", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_model.get_final_checkpoint": [[78, 92], ["os.path.join", "print", "utils_cm.list_dir"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_cm.list_dir"], ["", "def", "get_final_checkpoint", "(", "save_dir", ",", "selected_epoch", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Args: \n        save_dir \n        selected_epoch\n    Returns: \n        selected_epoch if selected_epoch <= 0 else return final_epoch in folder save_dir \n    \"\"\"", "\n", "if", "selected_epoch", ">", "0", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'model.{:03d}.h5'", ".", "format", "(", "selected_epoch", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'search checkpoints in folder: '", ",", "save_dir", "+", "'/'", ")", "\n", "all_dir", "=", "list_dir", "(", "save_dir", "+", "'/'", ",", "filetype", "=", "'.h5'", ")", "\n", "return", "all_dir", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_model.get_statistic": [[93, 104], ["utils_model.get_statistic._entropy"], "function", ["None"], ["", "", "def", "get_statistic", "(", "pred", ")", ":", "\n", "  ", "def", "_entropy", "(", "pred", ")", ":", "\n", "    ", "log_y", "=", "np", ".", "log", "(", "pred", "+", "1e-12", ")", "\n", "temp", "=", "-", "np", ".", "multiply", "(", "pred", ",", "log_y", ")", "\n", "return", "np", ".", "sum", "(", "temp", ",", "axis", "=", "1", ")", "\n", "\n", "", "en", "=", "_entropy", "(", "pred", ")", "\n", "# h = _hist(en)", "\n", "m", "=", "np", ".", "mean", "(", "en", ")", "\n", "s", "=", "np", ".", "std", "(", "en", ")", "\n", "return", "en", ",", "m", ",", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_model.get_model_eval": [[105, 169], ["tensorflow.equal", "ValueError", "tensorflow.argmax", "tensorflow.argmax", "sess.as_default", "int", "numpy.zeros", "numpy.zeros", "range", "len", "numpy.concatenate", "math.ceil", "len", "min", "tf.equal.eval", "predictions.eval", "cur_corr_preds[].sum", "np.concatenate.append", "len", "len", "float", "len"], "function", ["None"], ["", "def", "get_model_eval", "(", "sess", ",", "x", ",", "y", ",", "predictions", ",", "X_test", "=", "None", ",", "Y_test", "=", "None", ",", "batch_size", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n  Compute the accuracy of a TF model on some data\n  :param sess: TF session to use\n  :param x: input placeholder\n  :param y: output placeholder (for labels)\n  :param predictions: model output predictions\n  :param X_test: numpy array with training inputs\n  :param Y_test: numpy array with training outputs\n  :param feed: An optional dictionary that is appended to the feeding\n           dictionary before the session runs. Can be used to feed\n           the learning phase of a Keras model for instance.\n  :return: a float with the accuracy value and predictions \n  \"\"\"", "\n", "if", "X_test", "is", "None", "or", "Y_test", "is", "None", ":", "\n", "    ", "raise", "ValueError", "(", "\"X_test argument and Y_test argument \"", "\n", "\"must be supplied.\"", ")", "\n", "\n", "# Define accuracy symbolically", "\n", "", "correct_preds", "=", "tf", ".", "equal", "(", "tf", ".", "argmax", "(", "y", ",", "axis", "=", "-", "1", ")", ",", "\n", "tf", ".", "argmax", "(", "predictions", ",", "axis", "=", "-", "1", ")", ")", "\n", "\n", "\n", "# Init result var", "\n", "accuracy", "=", "0.0", "\n", "preds", "=", "[", "]", "\n", "\n", "with", "sess", ".", "as_default", "(", ")", ":", "\n", "# Compute number of batches", "\n", "    ", "nb_batches", "=", "int", "(", "math", ".", "ceil", "(", "float", "(", "len", "(", "X_test", ")", ")", "/", "batch_size", ")", ")", "\n", "assert", "nb_batches", "*", "batch_size", ">=", "len", "(", "X_test", ")", "\n", "\n", "X_cur", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", ")", "+", "X_test", ".", "shape", "[", "1", ":", "]", ",", "\n", "dtype", "=", "X_test", ".", "dtype", ")", "\n", "Y_cur", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", ")", "+", "Y_test", ".", "shape", "[", "1", ":", "]", ",", "\n", "dtype", "=", "Y_test", ".", "dtype", ")", "\n", "for", "batch", "in", "range", "(", "nb_batches", ")", ":", "\n", "\n", "# Must not use the `batch_indices` function here, because it", "\n", "# repeats some examples.", "\n", "# It's acceptable to repeat during training, but not eval.", "\n", "      ", "start", "=", "batch", "*", "batch_size", "\n", "end", "=", "min", "(", "len", "(", "X_test", ")", ",", "start", "+", "batch_size", ")", "\n", "\n", "# The last batch may be smaller than all others. This should not", "\n", "# affect the accuarcy disproportionately.", "\n", "cur_batch_size", "=", "end", "-", "start", "\n", "X_cur", "[", ":", "cur_batch_size", "]", "=", "X_test", "[", "start", ":", "end", "]", "\n", "Y_cur", "[", ":", "cur_batch_size", "]", "=", "Y_test", "[", "start", ":", "end", "]", "\n", "feed_dict", "=", "{", "x", ":", "X_cur", ",", "y", ":", "Y_cur", "}", "\n", "\n", "cur_corr_preds", "=", "correct_preds", ".", "eval", "(", "feed_dict", "=", "feed_dict", ")", "\n", "cur_preds", "=", "predictions", ".", "eval", "(", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "accuracy", "+=", "cur_corr_preds", "[", ":", "cur_batch_size", "]", ".", "sum", "(", ")", "\n", "preds", ".", "append", "(", "cur_preds", ")", "\n", "\n", "", "assert", "end", ">=", "len", "(", "X_test", ")", "\n", "\n", "# Divide by number of examples to get final value", "\n", "accuracy", "/=", "len", "(", "X_test", ")", "\n", "preds", "=", "np", ".", "concatenate", "(", "preds", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "accuracy", ",", "preds", "", "", ""]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.model.get_model": [[22, 44], ["model.cnn_cifar10", "model.resnet_v1", "model.cnn_cifar100", "model.cnn_mnist"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.model.cnn_cifar10", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.model.resnet_v1", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.model.cnn_cifar100", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.model.cnn_mnist"], ["def", "get_model", "(", "inputs", ",", "model", ",", "dataset", ")", ":", "\n", "    ", "\"\"\"\n    Retrieve model using \n    Args: \n        model: cnn or resnet20 \n        dataset: cifar10, mnist, or cifar100 \n    Returns: \n        probability: softmax output \n\n    \"\"\"", "\n", "if", "model", "==", "'cnn'", ":", "\n", "        ", "if", "dataset", "==", "'cifar10'", ":", "\n", "            ", "return", "cnn_cifar10", "(", "inputs", ")", "[", "0", "]", "\n", "", "elif", "dataset", "==", "'cifar100'", ":", "\n", "            ", "return", "cnn_cifar100", "(", "inputs", ")", "[", "0", "]", "\n", "", "elif", "dataset", "==", "'mnist'", ":", "\n", "            ", "return", "cnn_mnist", "(", "inputs", ")", "[", "0", "]", "\n", "", "", "elif", "model", "==", "'resnet20'", ":", "\n", "        ", "num_classes", "=", "100", "if", "dataset", "==", "'cifar100'", "else", "10", "\n", "return", "resnet_v1", "(", "input", "=", "inputs", ",", "depth", "=", "20", ",", "num_classes", "=", "num_classes", ",", "dataset", "=", "dataset", ")", "[", "2", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.model.resnet_layer": [[46, 88], ["Conv2D", "Conv2D.", "Conv2D.", "l2", "BatchNormalization", "Activation", "BatchNormalization", "Activation"], "function", ["None"], ["", "", "def", "resnet_layer", "(", "inputs", ",", "\n", "num_filters", "=", "16", ",", "\n", "kernel_size", "=", "3", ",", "\n", "strides", "=", "1", ",", "\n", "activation", "=", "'relu'", ",", "\n", "batch_normalization", "=", "True", ",", "\n", "conv_first", "=", "True", ")", ":", "\n", "    ", "\"\"\"2D Convolution-Batch Normalization-Activation stack builder\n    # Arguments\n        inputs (tensor): input tensor from input image or previous layer\n        num_filters (int): Conv2D number of filters\n        kernel_size (int): Conv2D square kernel dimensions\n        strides (int): Conv2D square stride dimensions\n        activation (string): activation name\n        batch_normalization (bool): whether to include batch normalization\n        conv_first (bool): conv-bn-activation (True) or\n            bn-activation-conv (False)\n    # Returns\n        x (tensor): tensor as input to the next layer\n    \"\"\"", "\n", "conv", "=", "Conv2D", "(", "\n", "num_filters", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "strides", "=", "strides", ",", "\n", "padding", "=", "'same'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "l2", "(", "1e-4", ")", ")", "\n", "\n", "x", "=", "inputs", "\n", "if", "conv_first", ":", "\n", "        ", "x", "=", "conv", "(", "x", ")", "\n", "if", "batch_normalization", ":", "\n", "            ", "x", "=", "BatchNormalization", "(", ")", "(", "x", ")", "\n", "", "if", "activation", "is", "not", "None", ":", "\n", "            ", "x", "=", "Activation", "(", "activation", ")", "(", "x", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "batch_normalization", ":", "\n", "            ", "x", "=", "BatchNormalization", "(", ")", "(", "x", ")", "\n", "", "if", "activation", "is", "not", "None", ":", "\n", "            ", "x", "=", "Activation", "(", "activation", ")", "(", "x", ")", "\n", "", "x", "=", "conv", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.model.resnet_v1": [[90, 160], ["int", "model.resnet_layer", "range", "Model", "ValueError", "range", "AveragePooling2D", "Flatten", "Dense", "Activation", "model.resnet_layer", "model.resnet_layer", "add", "model.resnet_layer", "Activation"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.model.resnet_layer", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.model.resnet_layer", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.model.resnet_layer", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.model.resnet_layer"], ["", "def", "resnet_v1", "(", "input", ",", "depth", ",", "num_classes", "=", "10", ",", "dataset", "=", "'cifar10'", ")", ":", "\n", "    ", "\"\"\"ResNet Version 1 Model builder [a]\n    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n    Last ReLU is after the shortcut connection.\n    At the beginning of each stage, the feature map size is halved (downsampled)\n    by a convolutional layer with strides=2, while the number of filters is\n    doubled. Within each stage, the layers have the same number filters and the\n    same number of filters.\n    Features maps sizes:\n    stage 0: 32x32, 16\n    stage 1: 16x16, 32\n    stage 2:  8x8,  64\n    The Number of parameters is approx the same as Table 6 of [a]:\n    ResNet20 0.27M\n    ResNet32 0.46M\n    ResNet44 0.66M\n    ResNet56 0.85M\n    ResNet110 1.7M\n    # Arguments\n        input_shape (tensor): shape of input image tensor\n        depth (int): number of core convolutional layers\n        num_classes (int): number of classes (CIFAR10 has 10)\n    # Returns\n        model (Model): Keras model instance\n    \"\"\"", "\n", "if", "(", "depth", "-", "2", ")", "%", "6", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "'depth should be 6n+2 (eg 20, 32, 44 in [a])'", ")", "\n", "# Start model definition.", "\n", "", "num_filters", "=", "16", "\n", "num_res_blocks", "=", "int", "(", "(", "depth", "-", "2", ")", "/", "6", ")", "\n", "\n", "inputs", "=", "input", "\n", "x", "=", "resnet_layer", "(", "inputs", "=", "inputs", ")", "\n", "# Instantiate the stack of residual units", "\n", "for", "stack", "in", "range", "(", "3", ")", ":", "\n", "        ", "for", "res_block", "in", "range", "(", "num_res_blocks", ")", ":", "\n", "            ", "strides", "=", "1", "\n", "if", "stack", ">", "0", "and", "res_block", "==", "0", ":", "# first layer but not first stack", "\n", "                ", "strides", "=", "2", "# downsample", "\n", "", "y", "=", "resnet_layer", "(", "inputs", "=", "x", ",", "num_filters", "=", "num_filters", ",", "strides", "=", "strides", ")", "\n", "y", "=", "resnet_layer", "(", "inputs", "=", "y", ",", "num_filters", "=", "num_filters", ",", "activation", "=", "None", ")", "\n", "if", "stack", ">", "0", "and", "res_block", "==", "0", ":", "# first layer but not first stack", "\n", "# linear projection residual shortcut connection to match", "\n", "# changed dims", "\n", "                ", "x", "=", "resnet_layer", "(", "\n", "inputs", "=", "x", ",", "\n", "num_filters", "=", "num_filters", ",", "\n", "kernel_size", "=", "1", ",", "\n", "strides", "=", "strides", ",", "\n", "activation", "=", "None", ",", "\n", "batch_normalization", "=", "False", ")", "\n", "", "x", "=", "add", "(", "[", "x", ",", "y", "]", ")", "\n", "x", "=", "Activation", "(", "'relu'", ")", "(", "x", ")", "\n", "", "num_filters", "*=", "2", "\n", "\n", "# Add classifier on top.", "\n", "# v1 does not use BN after last shortcut connection-ReLU", "\n", "", "if", "dataset", "==", "'mnist'", ":", "\n", "        ", "poolsize", "=", "7", "\n", "", "else", ":", "\n", "        ", "poolsize", "=", "8", "\n", "", "x", "=", "AveragePooling2D", "(", "pool_size", "=", "poolsize", ")", "(", "x", ")", "\n", "final_features", "=", "Flatten", "(", ")", "(", "x", ")", "\n", "logits", "=", "Dense", "(", "\n", "num_classes", ",", "kernel_initializer", "=", "'he_normal'", ")", "(", "final_features", ")", "\n", "outputs", "=", "Activation", "(", "'softmax'", ")", "(", "logits", ")", "\n", "\n", "# Instantiate model.", "\n", "model", "=", "Model", "(", "inputs", "=", "inputs", ",", "outputs", "=", "outputs", ")", "\n", "return", "model", ",", "inputs", ",", "outputs", ",", "logits", ",", "final_features", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.model.cnn_cifar10": [[161, 184], ["functools.partial", "functools.partial.", "functools.partial.", "MaxPooling2D", "functools.partial.", "functools.partial.", "MaxPooling2D", "Flatten", "Dense", "Dense", "Dense", "Activation", "l2"], "function", ["None"], ["", "def", "cnn_cifar10", "(", "inputs", ")", ":", "\n", "    ", "\"\"\"\n    Standard CNN architecture \n    Ref: C&W 2016 \n    \"\"\"", "\n", "conv", "=", "partial", "(", "Conv2D", ",", "kernel_size", "=", "3", ",", "strides", "=", "1", ",", "padding", "=", "'same'", ",", "\n", "activation", "=", "'relu'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "l2", "(", "1e-4", ")", ")", "\n", "\n", "h", "=", "conv", "(", "filters", "=", "64", ")", "(", "inputs", ")", "\n", "h", "=", "conv", "(", "filters", "=", "64", ")", "(", "h", ")", "\n", "h", "=", "MaxPooling2D", "(", ")", "(", "h", ")", "\n", "h", "=", "conv", "(", "filters", "=", "128", ")", "(", "h", ")", "\n", "h", "=", "conv", "(", "filters", "=", "128", ")", "(", "h", ")", "\n", "h", "=", "MaxPooling2D", "(", ")", "(", "h", ")", "\n", "h", "=", "Flatten", "(", ")", "(", "h", ")", "\n", "h", "=", "Dense", "(", "256", ",", "activation", "=", "'relu'", ",", "kernel_initializer", "=", "'he_normal'", ")", "(", "h", ")", "\n", "h", "=", "Dense", "(", "256", ",", "activation", "=", "'relu'", ",", "kernel_initializer", "=", "'he_normal'", ")", "(", "h", ")", "\n", "logits", "=", "Dense", "(", "10", ",", "kernel_initializer", "=", "'he_normal'", ")", "(", "h", ")", "\n", "probs", "=", "Activation", "(", "'softmax'", ")", "(", "logits", ")", "\n", "\n", "return", "probs", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.model.cnn_mnist": [[186, 209], ["functools.partial", "functools.partial.", "functools.partial.", "MaxPooling2D", "functools.partial.", "functools.partial.", "MaxPooling2D", "Flatten", "Dense", "Dense", "Dense", "Activation", "l2"], "function", ["None"], ["", "def", "cnn_mnist", "(", "inputs", ")", ":", "\n", "    ", "\"\"\"\n    Standard CNN architecture \n    Ref: C&W 2016 \n    \"\"\"", "\n", "conv", "=", "partial", "(", "Conv2D", ",", "kernel_size", "=", "3", ",", "strides", "=", "1", ",", "padding", "=", "'same'", ",", "\n", "activation", "=", "'relu'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "l2", "(", "1e-4", ")", ")", "\n", "\n", "h", "=", "conv", "(", "filters", "=", "32", ")", "(", "inputs", ")", "\n", "h", "=", "conv", "(", "filters", "=", "32", ")", "(", "h", ")", "\n", "h", "=", "MaxPooling2D", "(", ")", "(", "h", ")", "\n", "h", "=", "conv", "(", "filters", "=", "64", ")", "(", "h", ")", "\n", "h", "=", "conv", "(", "filters", "=", "64", ")", "(", "h", ")", "\n", "h", "=", "MaxPooling2D", "(", ")", "(", "h", ")", "\n", "h", "=", "Flatten", "(", ")", "(", "h", ")", "\n", "h", "=", "Dense", "(", "200", ",", "activation", "=", "'relu'", ",", "kernel_initializer", "=", "'he_normal'", ")", "(", "h", ")", "\n", "h", "=", "Dense", "(", "200", ",", "activation", "=", "'relu'", ",", "kernel_initializer", "=", "'he_normal'", ")", "(", "h", ")", "\n", "logits", "=", "Dense", "(", "10", ",", "kernel_initializer", "=", "'he_normal'", ")", "(", "h", ")", "\n", "probs", "=", "Activation", "(", "'softmax'", ")", "(", "logits", ")", "\n", "\n", "return", "probs", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.model.cnn_cifar100": [[210, 236], ["functools.partial", "functools.partial.", "functools.partial.", "functools.partial.", "MaxPooling2D", "functools.partial.", "functools.partial.", "functools.partial.", "MaxPooling2D", "Flatten", "Dense", "Dense", "Dense", "Dense", "Activation", "l2"], "function", ["None"], ["", "def", "cnn_cifar100", "(", "inputs", ")", ":", "\n", "    ", "\"\"\"\n    Standard CNN architecture \n    Ref: C&W 2016 \n    \"\"\"", "\n", "conv", "=", "partial", "(", "Conv2D", ",", "kernel_size", "=", "3", ",", "strides", "=", "1", ",", "padding", "=", "'same'", ",", "\n", "activation", "=", "'relu'", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "l2", "(", "1e-4", ")", ")", "\n", "\n", "h", "=", "conv", "(", "filters", "=", "64", ")", "(", "inputs", ")", "\n", "h", "=", "conv", "(", "filters", "=", "64", ")", "(", "h", ")", "\n", "h", "=", "conv", "(", "filters", "=", "64", ")", "(", "h", ")", "\n", "h", "=", "MaxPooling2D", "(", ")", "(", "h", ")", "\n", "h", "=", "conv", "(", "filters", "=", "128", ")", "(", "h", ")", "\n", "h", "=", "conv", "(", "filters", "=", "128", ")", "(", "h", ")", "\n", "h", "=", "conv", "(", "filters", "=", "128", ")", "(", "h", ")", "\n", "h", "=", "MaxPooling2D", "(", ")", "(", "h", ")", "\n", "h", "=", "Flatten", "(", ")", "(", "h", ")", "\n", "h", "=", "Dense", "(", "256", ",", "activation", "=", "'relu'", ",", "kernel_initializer", "=", "'he_normal'", ")", "(", "h", ")", "\n", "h", "=", "Dense", "(", "256", ",", "activation", "=", "'relu'", ",", "kernel_initializer", "=", "'he_normal'", ")", "(", "h", ")", "\n", "h", "=", "Dense", "(", "256", ",", "activation", "=", "'relu'", ",", "kernel_initializer", "=", "'he_normal'", ")", "(", "h", ")", "\n", "logits", "=", "Dense", "(", "100", ",", "kernel_initializer", "=", "'he_normal'", ")", "(", "h", ")", "\n", "probs", "=", "Activation", "(", "'softmax'", ")", "(", "logits", ")", "\n", "\n", "return", "probs", ",", "logits", "", "", ""]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_im.plot_prediction": [[7, 39], ["matplotlib.figure", "plt.figure.add_subplot", "fig.add_subplot.imshow", "fig.add_subplot.grid", "fig.add_subplot.axis", "fig.add_subplot.set_title", "plt.figure.add_subplot", "fig.add_subplot.imshow", "fig.add_subplot.grid", "fig.add_subplot.axis", "fig.add_subplot.set_title", "zip", "matplotlib.tight_layout", "matplotlib.savefig", "matplotlib.close", "plt.figure.add_subplot", "fig.add_subplot.bar", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "fig.add_subplot.set_title", "fig.add_subplot.tick_params", "numpy.arange", "len", "numpy.argmax"], "function", ["None"], ["def", "plot_prediction", "(", "figname", ",", "image", ",", "adv", ",", "pred_nor", ",", "pred_adv", ")", ":", "\n", "    ", "nb", "=", "2", "\n", "size", "=", "5", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "size", "*", "nb", ",", "2", "*", "size", ")", ")", "\n", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "2", ",", "nb", ",", "1", ")", "\n", "ax", ".", "imshow", "(", "image", ")", "\n", "ax", ".", "grid", "(", "False", ")", "\n", "ax", ".", "axis", "(", "'off'", ")", "\n", "ax", ".", "set_title", "(", "'Input image'", ",", "fontsize", "=", "FONT_SIZE", ")", "\n", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "2", ",", "nb", ",", "1", "+", "nb", ")", "\n", "ax", ".", "imshow", "(", "adv", ")", "\n", "ax", ".", "grid", "(", "False", ")", "\n", "ax", ".", "axis", "(", "'off'", ")", "\n", "ax", ".", "set_title", "(", "'Adversarial image'", ",", "fontsize", "=", "FONT_SIZE", ")", "\n", "\n", "values", "=", "[", "pred_nor", ",", "pred_adv", "]", "\n", "titles", "=", "[", "'Model Ensemble'", ",", "'Model Ensemble'", "]", "\n", "indexes", "=", "[", "2", ",", "4", "]", "\n", "\n", "for", "val", ",", "title", ",", "idx", "in", "zip", "(", "values", ",", "titles", ",", "indexes", ")", ":", "\n", "        ", "ax", "=", "fig", ".", "add_subplot", "(", "2", ",", "nb", ",", "idx", ")", "\n", "ax", ".", "bar", "(", "np", ".", "arange", "(", "len", "(", "val", ")", ")", ",", "val", ")", "\n", "ax", ".", "set_xlabel", "(", "'Classes'", ",", "fontsize", "=", "FONT_SIZE", ")", "\n", "ax", ".", "set_ylabel", "(", "'Pred'", ",", "fontsize", "=", "FONT_SIZE", ")", "\n", "ax", ".", "set_title", "(", "title", "+", "'; max index={}'", ".", "format", "(", "np", ".", "argmax", "(", "val", ")", ")", ",", "fontsize", "=", "FONT_SIZE", ")", "\n", "ax", ".", "tick_params", "(", "labelsize", "=", "STICK_SIZE", ")", "\n", "\n", "", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "figname", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_im.plot_images": [[40, 64], ["matplotlib.figure", "range", "matplotlib.tight_layout", "matplotlib.savefig", "matplotlib.close", "range", "matplotlib.subplot", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.grid", "matplotlib.imshow", "matplotlib.xlabel", "numpy.shape"], "function", ["None"], ["", "def", "plot_images", "(", "savepath", ",", "x", ",", "y", ",", "x_adv", ",", "y_adv", ")", ":", "\n", "\t", "class_names", "=", "[", "'airplane'", ",", "'automobile'", ",", "'bird'", ",", "'cat'", ",", "'deer'", ",", "'dog'", ",", "'frog'", ",", "'horse'", ",", "'ship'", ",", "'truck'", "]", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "8", ",", "8", ")", ")", "\n", "nbrow", "=", "4", "\n", "nbcol", "=", "np", ".", "shape", "(", "x", ")", "[", "0", "]", "//", "nbrow", "*", "2", "\n", "\n", "for", "r", "in", "range", "(", "nbrow", ")", ":", "\n", "\t\t", "_x", "=", "x", "if", "r", "%", "2", "==", "0", "else", "x_adv", "\n", "_y", "=", "y", "if", "r", "%", "2", "==", "0", "else", "y_adv", "\n", "\n", "for", "c", "in", "range", "(", "nbcol", ")", ":", "\n", "\t\t\t", "plt", ".", "subplot", "(", "nbrow", ",", "nbcol", ",", "r", "*", "nbrow", "+", "c", "+", "1", ")", "\n", "plt", ".", "xticks", "(", "[", "]", ")", "\n", "plt", ".", "yticks", "(", "[", "]", ")", "\n", "plt", ".", "grid", "(", "False", ")", "\n", "plt", ".", "imshow", "(", "_x", "[", "r", "//", "2", "+", "c", "]", ",", "cmap", "=", "plt", ".", "cm", ".", "binary", ")", "\n", "# The CIFAR labels happen to be arrays, ", "\n", "# which is why you need the extra index", "\n", "plt", ".", "xlabel", "(", "class_names", "[", "_y", "[", "r", "//", "2", "+", "c", "]", "]", ")", "\n", "\n", "", "", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "savepath", ",", "dpi", "=", "300", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils_im.plot_historgram": [[65, 75], ["matplotlib.figure", "matplotlib.hist", "matplotlib.hist", "matplotlib.legend", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.title", "matplotlib.savefig", "matplotlib.close"], "function", ["None"], ["", "def", "plot_historgram", "(", "figname", ",", "h_nat", ",", "h_adv", ",", "title", ")", ":", "\n", "    ", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "hist", "(", "h_nat", ",", "bins", "=", "50", ",", "color", "=", "'blue'", ",", "label", "=", "'normal'", ")", "\n", "plt", ".", "hist", "(", "h_adv", ",", "bins", "=", "50", ",", "color", "=", "'red'", ",", "label", "=", "'adv'", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "xlabel", "(", "'entropy H(f(x))'", ")", "\n", "plt", ".", "ylabel", "(", "'count'", ")", "\n", "plt", ".", "title", "(", "title", ")", "\n", "plt", ".", "savefig", "(", "figname", ",", "dpi", "=", "300", ")", "\n", "plt", ".", "close", "(", ")", "", "", ""]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.lib_attack.gen_adv": [[4, 41], ["print", "att_params.keys", "tensorflow.stop_gradient", "cleverhans.MadryEtAl", "print", "attacks.FastGradientMethod.generate", "cleverhans.MomentumIterativeMethod", "cleverhans.FastGradientMethod"], "function", ["None"], ["def", "gen_adv", "(", "wrap_model", ",", "model_input", ",", "attack_method", ",", "eps", ",", "eta", ",", "def_iter", ",", "\n", "clip_min", "=", "0.", ",", "clip_max", "=", "1.", ")", ":", "\n", "\n", "    ", "\"\"\"\n    Generate adversarial examples using keras wrapper \n    \"\"\"", "\n", "\n", "if", "attack_method", "==", "'MadryEtAl'", ":", "\n", "        ", "att", "=", "attacks", ".", "MadryEtAl", "(", "wrap_model", ")", "\n", "att_params", "=", "{", "\n", "'eps'", ":", "eps", ",", "\n", "'eps_iter'", ":", "eta", ",", "\n", "'clip_min'", ":", "clip_min", ",", "\n", "'clip_max'", ":", "clip_max", ",", "\n", "'nb_iter'", ":", "def_iter", "\n", "}", "\n", "", "elif", "attack_method", "==", "'MomentumIterativeMethod'", ":", "\n", "        ", "att", "=", "attacks", ".", "MomentumIterativeMethod", "(", "wrap_model", ")", "\n", "att_params", "=", "{", "\n", "'eps'", ":", "eps", ",", "\n", "'eps_iter'", ":", "eta", ",", "\n", "'clip_min'", ":", "clip_min", ",", "\n", "'clip_max'", ":", "clip_max", ",", "\n", "'nb_iter'", ":", "def_iter", "\n", "}", "\n", "", "elif", "attack_method", "==", "'FastGradientMethod'", ":", "\n", "        ", "att", "=", "attacks", ".", "FastGradientMethod", "(", "wrap_model", ")", "\n", "att_params", "=", "{", "'eps'", ":", "eps", ",", "\n", "'clip_min'", ":", "clip_min", ",", "\n", "'clip_max'", ":", "clip_max", "}", "\n", "\n", "", "print", "(", "'attack_method: {}'", ".", "format", "(", "attack_method", ")", ")", "\n", "for", "k", "in", "att_params", ".", "keys", "(", ")", ":", "\n", "    \t", "print", "(", "'{}:{}'", ".", "format", "(", "k", ",", "att_params", "[", "k", "]", ")", ")", "\n", "", "adv_x", "=", "tf", ".", "stop_gradient", "(", "att", ".", "generate", "(", "model_input", ",", "**", "att_params", ")", ")", "\n", "\n", "return", "adv_x", "", "", ""]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils.Entropy": [[20, 23], ["tensorflow.reduce_sum", "tensorflow.multiply", "tensorflow.log"], "function", ["None"], ["def", "Entropy", "(", "input", ")", ":", "\n", "#input shape is batch_size X num_class", "\n", "    ", "return", "tf", ".", "reduce_sum", "(", "-", "tf", ".", "multiply", "(", "input", ",", "tf", ".", "log", "(", "input", "+", "log_offset", ")", ")", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils.Ensemble_Entropy": [[24, 31], ["tensorflow.split", "range", "utils.Entropy"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils.Entropy"], ["", "def", "Ensemble_Entropy", "(", "y_true", ",", "y_pred", ",", "num_model", "=", "FLAGS", ".", "num_models", ")", ":", "\n", "    ", "y_p", "=", "tf", ".", "split", "(", "y_pred", ",", "num_model", ",", "axis", "=", "-", "1", ")", "\n", "y_p_all", "=", "0", "\n", "for", "i", "in", "range", "(", "num_model", ")", ":", "\n", "        ", "y_p_all", "+=", "y_p", "[", "i", "]", "\n", "", "Ensemble", "=", "Entropy", "(", "y_p_all", "/", "num_model", ")", "\n", "return", "Ensemble", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils.log_det": [[32, 40], ["tensorflow.not_equal", "tensorflow.boolean_mask", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.linalg.logdet", "tensorflow.norm", "tensorflow.transpose", "tensorflow.ones_like", "tensorflow.expand_dims", "tensorflow.eye"], "function", ["None"], ["", "def", "log_det", "(", "y_true", ",", "y_pred", ",", "num_model", "=", "FLAGS", ".", "num_models", ")", ":", "\n", "    ", "bool_R_y_true", "=", "tf", ".", "not_equal", "(", "tf", ".", "ones_like", "(", "y_true", ")", "-", "y_true", ",", "zero", ")", "# batch_size X (num_class X num_models), 2-D", "\n", "mask_non_y_pred", "=", "tf", ".", "boolean_mask", "(", "y_pred", ",", "bool_R_y_true", ")", "# batch_size X (num_class-1) X num_models, 1-D", "\n", "mask_non_y_pred", "=", "tf", ".", "reshape", "(", "mask_non_y_pred", ",", "[", "-", "1", ",", "num_model", ",", "num_classes", "-", "1", "]", ")", "# batch_size X num_model X (num_class-1), 3-D", "\n", "mask_non_y_pred", "=", "mask_non_y_pred", "/", "tf", ".", "norm", "(", "mask_non_y_pred", ",", "axis", "=", "2", ",", "keepdims", "=", "True", ")", "# batch_size X num_model X (num_class-1), 3-D", "\n", "matrix", "=", "tf", ".", "matmul", "(", "mask_non_y_pred", ",", "tf", ".", "transpose", "(", "mask_non_y_pred", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", ")", "# batch_size X num_model X num_model, 3-D", "\n", "all_log_det", "=", "tf", ".", "linalg", ".", "logdet", "(", "matrix", "+", "det_offset", "*", "tf", ".", "expand_dims", "(", "tf", ".", "eye", "(", "num_model", ")", ",", "0", ")", ")", "# batch_size X 1, 1-D", "\n", "return", "all_log_det", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils.Ensemble_Entropy_metric": [[43, 46], ["utils.Ensemble_Entropy", "keras.backend.mean"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils.Ensemble_Entropy"], ["", "def", "Ensemble_Entropy_metric", "(", "y_true", ",", "y_pred", ",", "num_model", "=", "FLAGS", ".", "num_models", ")", ":", "\n", "    ", "EE", "=", "Ensemble_Entropy", "(", "y_true", ",", "y_pred", ",", "num_model", "=", "num_model", ")", "\n", "return", "K", ".", "mean", "(", "EE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils.log_det_metric": [[47, 50], ["utils.log_det", "keras.backend.mean"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils.log_det"], ["", "def", "log_det_metric", "(", "y_true", ",", "y_pred", ",", "num_model", "=", "FLAGS", ".", "num_models", ")", ":", "\n", "    ", "log_dets", "=", "log_det", "(", "y_true", ",", "y_pred", ",", "num_model", "=", "num_model", ")", "\n", "return", "K", ".", "mean", "(", "log_dets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils.acc_metric": [[61, 66], ["tensorflow.split", "tensorflow.split", "tensorflow.reduce_mean", "keras.metrics.categorical_accuracy"], "function", ["None"], ["", "def", "acc_metric", "(", "y_true", ",", "y_pred", ",", "num_model", "=", "FLAGS", ".", "num_models", ")", ":", "\n", "    ", "y_p", "=", "tf", ".", "split", "(", "y_pred", ",", "num_model", ",", "axis", "=", "-", "1", ")", "\n", "y_t", "=", "tf", ".", "split", "(", "y_true", ",", "num_model", ",", "axis", "=", "-", "1", ")", "\n", "ens_p", "=", "tf", ".", "reduce_mean", "(", "y_p", ",", "axis", "=", "0", ")", "\n", "return", "keras", ".", "metrics", ".", "categorical_accuracy", "(", "y_t", "[", "0", "]", ",", "ens_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils.Loss_withEE_DPP": [[68, 82], ["tensorflow.split", "tensorflow.split", "range", "tensorflow.reduce_sum", "keras.losses.categorical_crossentropy", "print", "utils.Ensemble_Entropy", "utils.log_det"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils.Ensemble_Entropy", "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils.log_det"], ["", "def", "Loss_withEE_DPP", "(", "y_true", ",", "y_pred", ",", "num_model", "=", "FLAGS", ".", "num_models", ")", ":", "\n", "    ", "y_true", "=", "(", "num_model", "*", "y_true", ")", "/", "tf", ".", "reduce_sum", "(", "y_true", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "y_p", "=", "tf", ".", "split", "(", "y_pred", ",", "num_model", ",", "axis", "=", "-", "1", ")", "\n", "y_t", "=", "tf", ".", "split", "(", "y_true", ",", "num_model", ",", "axis", "=", "-", "1", ")", "\n", "CE_all", "=", "0", "\n", "for", "i", "in", "range", "(", "num_model", ")", ":", "\n", "        ", "CE_all", "+=", "keras", ".", "losses", ".", "categorical_crossentropy", "(", "y_t", "[", "i", "]", ",", "y_p", "[", "i", "]", ")", "\n", "", "if", "FLAGS", ".", "lamda", "==", "0", "and", "FLAGS", ".", "log_det_lamda", "==", "0", ":", "\n", "        ", "print", "(", "'This is original ECE!'", ")", "\n", "return", "CE_all", "\n", "", "else", ":", "\n", "        ", "EE", "=", "Ensemble_Entropy", "(", "y_true", ",", "y_pred", ",", "num_model", ")", "\n", "log_dets", "=", "log_det", "(", "y_true", ",", "y_pred", ",", "num_model", ")", "\n", "return", "CE_all", "-", "FLAGS", ".", "lamda", "*", "EE", "-", "FLAGS", ".", "log_det_lamda", "*", "log_dets", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils.ensemble_diversity": [[85, 93], ["tensorflow.not_equal", "tensorflow.boolean_mask", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.linalg.logdet", "tensorflow.norm", "tensorflow.transpose", "tensorflow.ones_like", "tensorflow.expand_dims", "tensorflow.eye"], "function", ["None"], ["", "", "def", "ensemble_diversity", "(", "y_true", ",", "y_pred", ",", "num_model", ")", ":", "\n", "    ", "bool_R_y_true", "=", "tf", ".", "not_equal", "(", "tf", ".", "ones_like", "(", "y_true", ")", "-", "y_true", ",", "zero", ")", "# batch_size X (num_class X num_models), 2-D", "\n", "mask_non_y_pred", "=", "tf", ".", "boolean_mask", "(", "y_pred", ",", "bool_R_y_true", ")", "# batch_size X (num_class-1) X num_models, 1-D", "\n", "mask_non_y_pred", "=", "tf", ".", "reshape", "(", "mask_non_y_pred", ",", "[", "-", "1", ",", "num_model", ",", "num_classes", "-", "1", "]", ")", "# batch_size X num_model X (num_class-1), 3-D", "\n", "mask_non_y_pred", "=", "mask_non_y_pred", "/", "tf", ".", "norm", "(", "mask_non_y_pred", ",", "axis", "=", "2", ",", "keepdims", "=", "True", ")", "# batch_size X num_model X (num_class-1), 3-D", "\n", "matrix", "=", "tf", ".", "matmul", "(", "mask_non_y_pred", ",", "tf", ".", "transpose", "(", "mask_non_y_pred", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", ")", "# batch_size X num_model X num_model, 3-D", "\n", "all_log_det", "=", "tf", ".", "linalg", ".", "logdet", "(", "matrix", "+", "det_offset", "*", "tf", ".", "expand_dims", "(", "tf", ".", "eye", "(", "num_model", ")", ",", "0", ")", ")", "# batch_size X 1, 1-D", "\n", "return", "all_log_det", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils.model_eval_targetacc": [[94, 170], ["cleverhans.utils._ArgsWrapper", "ValueError", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "tensorflow.equal", "tensorflow.equal", "sess.as_default", "int", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "len", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.argmax", "math.ceil", "len", "min", "tf.equal.eval", "cur_corr_preds[].sum", "len", "_logger.debug", "len", "feed_dict.update", "float", "tensorflow.rank", "tensorflow.rank", "len", "str"], "function", ["None"], ["", "def", "model_eval_targetacc", "(", "sess", ",", "x", ",", "y", ",", "y_target", ",", "predictions", ",", "X_test", "=", "None", ",", "Y_test", "=", "None", ",", "Y_test_target", "=", "None", ",", "\n", "feed", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n  Compute the accuracy of a TF model on some data\n  :param sess: TF session to use\n  :param x: input placeholder\n  :param y: output placeholder (for labels)\n  :param predictions: model output predictions\n  :param X_test: numpy array with training inputs\n  :param Y_test: numpy array with training outputs\n  :param feed: An optional dictionary that is appended to the feeding\n           dictionary before the session runs. Can be used to feed\n           the learning phase of a Keras model for instance.\n  :param args: dict or argparse `Namespace` object.\n               Should contain `batch_size`\n  :return: a float with the accuracy value\n  \"\"\"", "\n", "args", "=", "_ArgsWrapper", "(", "args", "or", "{", "}", ")", "\n", "\n", "assert", "args", ".", "batch_size", ",", "\"Batch size was not given in args dict\"", "\n", "if", "X_test", "is", "None", "or", "Y_test_target", "is", "None", "or", "Y_test", "is", "None", ":", "\n", "    ", "raise", "ValueError", "(", "\"X_test argument and Y_test argument and Y_test_target argument\"", "\n", "\"must be supplied.\"", ")", "\n", "\n", "# Define accuracy symbolically", "\n", "", "if", "LooseVersion", "(", "tf", ".", "__version__", ")", ">=", "LooseVersion", "(", "'1.0.0'", ")", ":", "\n", "    ", "correct_preds", "=", "tf", ".", "equal", "(", "tf", ".", "argmax", "(", "y", ",", "axis", "=", "-", "1", ")", ",", "\n", "tf", ".", "argmax", "(", "predictions", ",", "axis", "=", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "    ", "correct_preds", "=", "tf", ".", "equal", "(", "tf", ".", "argmax", "(", "y", ",", "axis", "=", "tf", ".", "rank", "(", "y", ")", "-", "1", ")", ",", "\n", "tf", ".", "argmax", "(", "predictions", ",", "\n", "axis", "=", "tf", ".", "rank", "(", "predictions", ")", "-", "1", ")", ")", "\n", "\n", "# Init result var", "\n", "", "accuracy", "=", "0.0", "\n", "\n", "with", "sess", ".", "as_default", "(", ")", ":", "\n", "# Compute number of batches", "\n", "    ", "nb_batches", "=", "int", "(", "math", ".", "ceil", "(", "float", "(", "len", "(", "X_test", ")", ")", "/", "args", ".", "batch_size", ")", ")", "\n", "assert", "nb_batches", "*", "args", ".", "batch_size", ">=", "len", "(", "X_test", ")", "\n", "\n", "X_cur", "=", "np", ".", "zeros", "(", "(", "args", ".", "batch_size", ",", ")", "+", "X_test", ".", "shape", "[", "1", ":", "]", ",", "\n", "dtype", "=", "X_test", ".", "dtype", ")", "\n", "Y_cur", "=", "np", ".", "zeros", "(", "(", "args", ".", "batch_size", ",", ")", "+", "Y_test", ".", "shape", "[", "1", ":", "]", ",", "\n", "dtype", "=", "Y_test", ".", "dtype", ")", "\n", "Y_cur_target", "=", "np", ".", "zeros", "(", "(", "args", ".", "batch_size", ",", ")", "+", "Y_test_target", ".", "shape", "[", "1", ":", "]", ",", "\n", "dtype", "=", "Y_test_target", ".", "dtype", ")", "\n", "for", "batch", "in", "range", "(", "nb_batches", ")", ":", "\n", "      ", "if", "batch", "%", "100", "==", "0", "and", "batch", ">", "0", ":", "\n", "        ", "_logger", ".", "debug", "(", "\"Batch \"", "+", "str", "(", "batch", ")", ")", "\n", "\n", "# Must not use the `batch_indices` function here, because it", "\n", "# repeats some examples.", "\n", "# It's acceptable to repeat during training, but not eval.", "\n", "", "start", "=", "batch", "*", "args", ".", "batch_size", "\n", "end", "=", "min", "(", "len", "(", "X_test", ")", ",", "start", "+", "args", ".", "batch_size", ")", "\n", "\n", "# The last batch may be smaller than all others. This should not", "\n", "# affect the accuarcy disproportionately.", "\n", "cur_batch_size", "=", "end", "-", "start", "\n", "X_cur", "[", ":", "cur_batch_size", "]", "=", "X_test", "[", "start", ":", "end", "]", "\n", "Y_cur", "[", ":", "cur_batch_size", "]", "=", "Y_test", "[", "start", ":", "end", "]", "\n", "Y_cur_target", "[", ":", "cur_batch_size", "]", "=", "Y_test_target", "[", "start", ":", "end", "]", "\n", "feed_dict", "=", "{", "x", ":", "X_cur", ",", "y", ":", "Y_cur", ",", "y_target", ":", "Y_cur_target", "}", "\n", "if", "feed", "is", "not", "None", ":", "\n", "        ", "feed_dict", ".", "update", "(", "feed", ")", "\n", "", "cur_corr_preds", "=", "correct_preds", ".", "eval", "(", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "accuracy", "+=", "cur_corr_preds", "[", ":", "cur_batch_size", "]", ".", "sum", "(", ")", "\n", "\n", "", "assert", "end", ">=", "len", "(", "X_test", ")", "\n", "\n", "# Divide by number of examples to get final value", "\n", "accuracy", "/=", "len", "(", "X_test", ")", "\n", "\n", "", "return", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils.get_ensemble_diversity_values": [[172, 232], ["cleverhans.utils._ArgsWrapper", "numpy.array", "utils.ensemble_diversity", "ValueError", "sess.as_default", "int", "numpy.zeros", "numpy.zeros", "range", "math.ceil", "len", "min", "ensemble_diversity.eval", "numpy.concatenate", "len", "_logger.debug", "len", "feed_dict.update", "float", "len", "str"], "function", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.utils.ensemble_diversity"], ["", "def", "get_ensemble_diversity_values", "(", "sess", ",", "x", ",", "y", ",", "predictions", ",", "number_model", ",", "X_test", "=", "None", ",", "Y_test", "=", "None", ",", "\n", "feed", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n  Compute the accuracy of a TF model on some data\n  :param sess: TF session to use\n  :param x: input placeholder\n  :param y: output placeholder (for labels)\n  :param predictions: model output predictions\n  :param X_test: numpy array with training inputs\n  :param Y_test: numpy array with training outputs\n  :param feed: An optional dictionary that is appended to the feeding\n           dictionary before the session runs. Can be used to feed\n           the learning phase of a Keras model for instance.\n  :param args: dict or argparse `Namespace` object.\n               Should contain `batch_size`\n  :return: a float with the accuracy value\n  \"\"\"", "\n", "args", "=", "_ArgsWrapper", "(", "args", "or", "{", "}", ")", "\n", "\n", "assert", "args", ".", "batch_size", ",", "\"Batch size was not given in args dict\"", "\n", "if", "X_test", "is", "None", "or", "Y_test", "is", "None", ":", "\n", "    ", "raise", "ValueError", "(", "\"X_test argument and Y_test argument\"", "\n", "\"must be supplied.\"", ")", "\n", "\n", "", "ensemble_diversity_records", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "get_batch_ensemble_diversity", "=", "ensemble_diversity", "(", "y", ",", "predictions", ",", "number_model", ")", "\n", "with", "sess", ".", "as_default", "(", ")", ":", "\n", "# Compute number of batches", "\n", "    ", "nb_batches", "=", "int", "(", "math", ".", "ceil", "(", "float", "(", "len", "(", "X_test", ")", ")", "/", "args", ".", "batch_size", ")", ")", "\n", "assert", "nb_batches", "*", "args", ".", "batch_size", ">=", "len", "(", "X_test", ")", "\n", "\n", "X_cur", "=", "np", ".", "zeros", "(", "(", "args", ".", "batch_size", ",", ")", "+", "X_test", ".", "shape", "[", "1", ":", "]", ",", "\n", "dtype", "=", "X_test", ".", "dtype", ")", "\n", "Y_cur", "=", "np", ".", "zeros", "(", "(", "args", ".", "batch_size", ",", ")", "+", "Y_test", ".", "shape", "[", "1", ":", "]", ",", "\n", "dtype", "=", "Y_test", ".", "dtype", ")", "\n", "for", "batch", "in", "range", "(", "nb_batches", ")", ":", "\n", "      ", "if", "batch", "%", "100", "==", "0", "and", "batch", ">", "0", ":", "\n", "        ", "_logger", ".", "debug", "(", "\"Batch \"", "+", "str", "(", "batch", ")", ")", "\n", "\n", "# Must not use the `batch_indices` function here, because it", "\n", "# repeats some examples.", "\n", "# It's acceptable to repeat during training, but not eval.", "\n", "", "start", "=", "batch", "*", "args", ".", "batch_size", "\n", "end", "=", "min", "(", "len", "(", "X_test", ")", ",", "start", "+", "args", ".", "batch_size", ")", "\n", "\n", "# The last batch may be smaller than all others. This should not", "\n", "# affect the accuarcy disproportionately.", "\n", "cur_batch_size", "=", "end", "-", "start", "\n", "X_cur", "[", ":", "cur_batch_size", "]", "=", "X_test", "[", "start", ":", "end", "]", "\n", "Y_cur", "[", ":", "cur_batch_size", "]", "=", "Y_test", "[", "start", ":", "end", "]", "\n", "feed_dict", "=", "{", "x", ":", "X_cur", ",", "y", ":", "Y_cur", "}", "\n", "if", "feed", "is", "not", "None", ":", "\n", "        ", "feed_dict", ".", "update", "(", "feed", ")", "\n", "", "ensemble_diversity_records_batch", "=", "get_batch_ensemble_diversity", ".", "eval", "(", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "ensemble_diversity_records", "=", "np", ".", "concatenate", "(", "(", "ensemble_diversity_records", ",", "ensemble_diversity_records_batch", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "assert", "end", ">=", "len", "(", "X_test", ")", "\n", "\n", "", "return", "ensemble_diversity_records", "#len(X_test) X 1", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.datasets.Dataset.__init__": [[9, 124], ["object.__init__", "keras.utils.to_categorical", "keras.utils.to_categorical", "keras.preprocessing.image.ImageDataGenerator", "datasets.Dataset.datagen.fit", "print", "keras.datasets.mnist.load_data", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims.astype", "numpy.expand_dims.astype", "numpy.mean", "float", "float", "range", "numpy.concatenate", "numpy.concatenate", "keras.datasets.cifar10.load_data", "numpy.concatenate.append", "numpy.concatenate.append", "keras.datasets.cifar100.load_data", "keras.datasets.fashion_mnist.load_data", "numpy.expand_dims", "numpy.expand_dims"], "methods", ["home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.datasets.Dataset.__init__"], ["\t", "def", "__init__", "(", "self", ",", "ds", ",", "num_models", "=", "1", ",", "\n", "subtract_pixel_mean", "=", "True", ",", "\n", "clip_min", "=", "0.", ",", "\n", "clip_max", "=", "1.", ")", ":", "\n", "\n", "\t\t", "super", "(", "Dataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "clip_min", "=", "clip_min", "\n", "self", ".", "clip_max", "=", "clip_max", "\n", "\n", "if", "ds", "==", "'mnist'", ":", "\n", "\t\t\t", "(", "x_train", ",", "y_train", ")", ",", "(", "x_test", ",", "y_test", ")", "=", "mnist", ".", "load_data", "(", ")", "\n", "x_train", "=", "np", ".", "expand_dims", "(", "x_train", ",", "axis", "=", "3", ")", "\n", "x_test", "=", "np", ".", "expand_dims", "(", "x_test", ",", "axis", "=", "3", ")", "\n", "nb_class", "=", "10", "\n", "", "elif", "ds", "==", "'cifar10'", ":", "\n", "\t\t\t", "(", "x_train", ",", "y_train", ")", ",", "(", "x_test", ",", "y_test", ")", "=", "cifar10", ".", "load_data", "(", ")", "\n", "nb_class", "=", "10", "\n", "", "elif", "ds", "==", "'cifar100'", ":", "\n", "\t\t\t", "(", "x_train", ",", "y_train", ")", ",", "(", "x_test", ",", "y_test", ")", "=", "cifar100", ".", "load_data", "(", ")", "\n", "nb_class", "=", "100", "\n", "", "elif", "ds", "==", "'fashion'", ":", "\n", "\t\t\t", "(", "x_train", ",", "y_train", ")", ",", "(", "x_test", ",", "y_test", ")", "=", "fashion_mnist", ".", "load_data", "(", ")", "\n", "x_train", "=", "np", ".", "expand_dims", "(", "x_train", ",", "axis", "=", "3", ")", "\n", "x_test", "=", "np", ".", "expand_dims", "(", "x_test", ",", "axis", "=", "3", ")", "\n", "nb_class", "=", "10", "\n", "\n", "# Normalize data.", "\n", "", "self", ".", "x_train", "=", "x_train", ".", "astype", "(", "'float32'", ")", "/", "255", "\n", "self", ".", "x_test", "=", "x_test", ".", "astype", "(", "'float32'", ")", "/", "255", "\n", "\n", "self", ".", "y_train", "=", "keras", ".", "utils", ".", "to_categorical", "(", "y_train", ",", "nb_class", ")", "\n", "self", ".", "y_test", "=", "keras", ".", "utils", ".", "to_categorical", "(", "y_test", ",", "nb_class", ")", "\n", "\n", "# get infor ", "\n", "self", ".", "x_shape", "=", "x_train", ".", "shape", "[", "1", ":", "]", "\n", "\n", "\n", "# ", "\n", "if", "subtract_pixel_mean", ":", "\n", "# x_train_mean = np.mean(x_train, axis=0)", "\n", "\t\t\t", "self", ".", "x_train_mean", "=", "np", ".", "mean", "(", "self", ".", "x_train", ")", "\n", "self", ".", "x_train", "-=", "self", ".", "x_train_mean", "\n", "self", ".", "x_test", "-=", "self", ".", "x_train_mean", "\n", "self", ".", "clip_min", "-=", "self", ".", "x_train_mean", "\n", "self", ".", "clip_max", "-=", "self", ".", "x_train_mean", "\n", "self", ".", "clip_min", "=", "float", "(", "self", ".", "clip_min", ")", "\n", "self", ".", "clip_max", "=", "float", "(", "self", ".", "clip_max", ")", "\n", "\n", "", "else", ":", "\n", "\t\t\t", "self", ".", "x_train_mean", "=", "0.", "\n", "\n", "", "if", "num_models", ">", "1", ":", "\n", "\t\t\t", "\"\"\"\n\t\t\tif num_models > 1, need duplicate the true labels by #num_models times.\n\t\t\tfor example:  y1 = model_1(x); y2 = model_2(x); y = [y1, y2]\n\t\t\t\"\"\"", "\n", "y_train_2", "=", "[", "]", "\n", "y_test_2", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "num_models", ")", ":", "\n", "\t\t\t\t", "y_train_2", ".", "append", "(", "self", ".", "y_train", ")", "\n", "y_test_2", ".", "append", "(", "self", ".", "y_test", ")", "\n", "", "y_train_2", "=", "np", ".", "concatenate", "(", "y_train_2", ",", "axis", "=", "-", "1", ")", "\n", "y_test_2", "=", "np", ".", "concatenate", "(", "y_test_2", ",", "axis", "=", "-", "1", ")", "\n", "\n", "self", ".", "y_train", "=", "y_train_2", "\n", "self", ".", "y_test", "=", "y_test_2", "\n", "\n", "", "self", ".", "datagen", "=", "ImageDataGenerator", "(", "\n", "# set input mean to 0 over the dataset", "\n", "featurewise_center", "=", "False", ",", "\n", "# set each sample mean to 0", "\n", "samplewise_center", "=", "False", ",", "\n", "# divide inputs by std of dataset", "\n", "featurewise_std_normalization", "=", "False", ",", "\n", "# divide each input by its std", "\n", "samplewise_std_normalization", "=", "False", ",", "\n", "# apply ZCA whitening", "\n", "zca_whitening", "=", "False", ",", "\n", "# epsilon for ZCA whitening", "\n", "zca_epsilon", "=", "1e-06", ",", "\n", "# randomly rotate images in the range (deg 0 to 180)", "\n", "rotation_range", "=", "0", ",", "\n", "# randomly shift images horizontally", "\n", "width_shift_range", "=", "0.1", ",", "\n", "# randomly shift images vertically", "\n", "height_shift_range", "=", "0.1", ",", "\n", "# set range for random shear", "\n", "shear_range", "=", "0.", ",", "\n", "# set range for random zoom", "\n", "zoom_range", "=", "0.", ",", "\n", "# set range for random channel shifts", "\n", "channel_shift_range", "=", "0.", ",", "\n", "# set mode for filling points outside the input boundaries", "\n", "fill_mode", "=", "'nearest'", ",", "\n", "# value used for fill_mode = \"constant\"", "\n", "cval", "=", "0.", ",", "\n", "# randomly flip images", "\n", "horizontal_flip", "=", "True", ",", "\n", "# randomly flip images", "\n", "vertical_flip", "=", "False", ",", "\n", "# set rescaling factor (applied before any other transformation)", "\n", "rescale", "=", "None", ",", "\n", "# set function that will be applied on each input", "\n", "preprocessing_function", "=", "None", ",", "\n", "# image data format, either \"channels_first\" or \"channels_last\"", "\n", "data_format", "=", "None", ",", "\n", "# fraction of images reserved for validation (strictly between 0 and 1)", "\n", "validation_split", "=", "0.0", ")", "\n", "\n", "# Compute quantities required for featurewise normalization", "\n", "# (std, mean, and principal components if ZCA whitening is applied).", "\n", "self", ".", "datagen", ".", "fit", "(", "self", ".", "x_train", ")", "\n", "\n", "print", "(", "'Finish data processing'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tuananhbui89_Crossing-Collaborative-Ensemble.None.datasets.Dataset.next_batch": [[125, 127], ["datasets.Dataset.datagen.flow"], "methods", ["None"], ["", "def", "next_batch", "(", "self", ",", "bs", ")", ":", "\n", "\t\t", "return", "self", ".", "datagen", ".", "flow", "(", "self", ".", "x_train", ",", "self", ".", "y_train", ",", "batch_size", "=", "bs", ")", "\n", "\n"]]}