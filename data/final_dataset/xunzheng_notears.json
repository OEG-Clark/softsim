{"home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsMLP.__init__": [[11, 27], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "nonlinear.NotearsMLP._bounds", "nonlinear.NotearsMLP._bounds", "range", "torch.ModuleList", "torch.ModuleList", "len", "layers.append", "len", "notears.locally_connected.LocallyConnected"], "methods", ["home.repos.pwc.inspect_result.xunzheng_notears.notears.lbfgsb_scipy.LBFGSBScipy.__init__", "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsSobolev._bounds", "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsSobolev._bounds"], ["    ", "def", "__init__", "(", "self", ",", "dims", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "NotearsMLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "len", "(", "dims", ")", ">=", "2", "\n", "assert", "dims", "[", "-", "1", "]", "==", "1", "\n", "d", "=", "dims", "[", "0", "]", "\n", "self", ".", "dims", "=", "dims", "\n", "# fc1: variable splitting for l1", "\n", "self", ".", "fc1_pos", "=", "nn", ".", "Linear", "(", "d", ",", "d", "*", "dims", "[", "1", "]", ",", "bias", "=", "bias", ")", "\n", "self", ".", "fc1_neg", "=", "nn", ".", "Linear", "(", "d", ",", "d", "*", "dims", "[", "1", "]", ",", "bias", "=", "bias", ")", "\n", "self", ".", "fc1_pos", ".", "weight", ".", "bounds", "=", "self", ".", "_bounds", "(", ")", "\n", "self", ".", "fc1_neg", ".", "weight", ".", "bounds", "=", "self", ".", "_bounds", "(", ")", "\n", "# fc2: local linear layers", "\n", "layers", "=", "[", "]", "\n", "for", "l", "in", "range", "(", "len", "(", "dims", ")", "-", "2", ")", ":", "\n", "            ", "layers", ".", "append", "(", "LocallyConnected", "(", "d", ",", "dims", "[", "l", "+", "1", "]", ",", "dims", "[", "l", "+", "2", "]", ",", "bias", "=", "bias", ")", ")", "\n", "", "self", ".", "fc2", "=", "nn", ".", "ModuleList", "(", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsMLP._bounds": [[28, 40], ["range", "range", "range", "bounds.append"], "methods", ["None"], ["", "def", "_bounds", "(", "self", ")", ":", "\n", "        ", "d", "=", "self", ".", "dims", "[", "0", "]", "\n", "bounds", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "d", ")", ":", "\n", "            ", "for", "m", "in", "range", "(", "self", ".", "dims", "[", "1", "]", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "d", ")", ":", "\n", "                    ", "if", "i", "==", "j", ":", "\n", "                        ", "bound", "=", "(", "0", ",", "0", ")", "\n", "", "else", ":", "\n", "                        ", "bound", "=", "(", "0", ",", "None", ")", "\n", "", "bounds", ".", "append", "(", "bound", ")", "\n", "", "", "", "return", "bounds", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsMLP.forward": [[41, 49], ["fc.view", "fc.squeeze", "nonlinear.NotearsMLP.fc1_pos", "nonlinear.NotearsMLP.fc1_neg", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "# [n, d] -> [n, d]", "\n", "        ", "x", "=", "self", ".", "fc1_pos", "(", "x", ")", "-", "self", ".", "fc1_neg", "(", "x", ")", "# [n, d * m1]", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "dims", "[", "0", "]", ",", "self", ".", "dims", "[", "1", "]", ")", "# [n, d, m1]", "\n", "for", "fc", "in", "self", ".", "fc2", ":", "\n", "            ", "x", "=", "torch", ".", "sigmoid", "(", "x", ")", "# [n, d, m1]", "\n", "x", "=", "fc", "(", "x", ")", "# [n, d, m2]", "\n", "", "x", "=", "x", ".", "squeeze", "(", "dim", "=", "2", ")", "# [n, d]", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsMLP.h_func": [[50, 62], ["fc1_weight.view.view.view", "torch.sum().t", "torch.sum().t", "torch.sum().t", "torch.sum().t", "notears.trace_expm.trace_expm", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "h_func", "(", "self", ")", ":", "\n", "        ", "\"\"\"Constrain 2-norm-squared of fc1 weights along m1 dim to be a DAG\"\"\"", "\n", "d", "=", "self", ".", "dims", "[", "0", "]", "\n", "fc1_weight", "=", "self", ".", "fc1_pos", ".", "weight", "-", "self", ".", "fc1_neg", ".", "weight", "# [j * m1, i]", "\n", "fc1_weight", "=", "fc1_weight", ".", "view", "(", "d", ",", "-", "1", ",", "d", ")", "# [j, m1, i]", "\n", "A", "=", "torch", ".", "sum", "(", "fc1_weight", "*", "fc1_weight", ",", "dim", "=", "1", ")", ".", "t", "(", ")", "# [i, j]", "\n", "h", "=", "trace_expm", "(", "A", ")", "-", "d", "# (Zheng et al. 2018)", "\n", "# A different formulation, slightly faster at the cost of numerical stability", "\n", "# M = torch.eye(d) + A / d  # (Yu et al. 2019)", "\n", "# E = torch.matrix_power(M, d - 1)", "\n", "# h = (E.t() * M).sum() - d", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsMLP.l2_reg": [[63, 71], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "l2_reg", "(", "self", ")", ":", "\n", "        ", "\"\"\"Take 2-norm-squared of all parameters\"\"\"", "\n", "reg", "=", "0.", "\n", "fc1_weight", "=", "self", ".", "fc1_pos", ".", "weight", "-", "self", ".", "fc1_neg", ".", "weight", "# [j * m1, i]", "\n", "reg", "+=", "torch", ".", "sum", "(", "fc1_weight", "**", "2", ")", "\n", "for", "fc", "in", "self", ".", "fc2", ":", "\n", "            ", "reg", "+=", "torch", ".", "sum", "(", "fc", ".", "weight", "**", "2", ")", "\n", "", "return", "reg", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsMLP.fc1_l1_reg": [[72, 76], ["torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "fc1_l1_reg", "(", "self", ")", ":", "\n", "        ", "\"\"\"Take l1 norm of fc1 weight\"\"\"", "\n", "reg", "=", "torch", ".", "sum", "(", "self", ".", "fc1_pos", ".", "weight", "+", "self", ".", "fc1_neg", ".", "weight", ")", "\n", "return", "reg", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsMLP.fc1_to_adj": [[77, 87], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "fc1_weight.view.view.view", "torch.sum().t", "torch.sum().t", "torch.sum().t", "torch.sum().t", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "W.cpu().detach().numpy.cpu().detach().numpy.cpu().detach().numpy", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "W.cpu().detach().numpy.cpu().detach().numpy.cpu().detach", "W.cpu().detach().numpy.cpu().detach().numpy.cpu"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "fc1_to_adj", "(", "self", ")", "->", "np", ".", "ndarray", ":", "# [j * m1, i] -> [i, j]", "\n", "        ", "\"\"\"Get W from fc1 weights, take 2-norm over m1 dim\"\"\"", "\n", "d", "=", "self", ".", "dims", "[", "0", "]", "\n", "fc1_weight", "=", "self", ".", "fc1_pos", ".", "weight", "-", "self", ".", "fc1_neg", ".", "weight", "# [j * m1, i]", "\n", "fc1_weight", "=", "fc1_weight", ".", "view", "(", "d", ",", "-", "1", ",", "d", ")", "# [j, m1, i]", "\n", "A", "=", "torch", ".", "sum", "(", "fc1_weight", "*", "fc1_weight", ",", "dim", "=", "1", ")", ".", "t", "(", ")", "# [i, j]", "\n", "W", "=", "torch", ".", "sqrt", "(", "A", ")", "# [i, j]", "\n", "W", "=", "W", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "# [i, j]", "\n", "return", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsSobolev.__init__": [[90, 101], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "nonlinear.NotearsSobolev._bounds", "nonlinear.NotearsSobolev._bounds", "torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_"], "methods", ["home.repos.pwc.inspect_result.xunzheng_notears.notears.lbfgsb_scipy.LBFGSBScipy.__init__", "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsSobolev._bounds", "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsSobolev._bounds"], ["    ", "def", "__init__", "(", "self", ",", "d", ",", "k", ")", ":", "\n", "        ", "\"\"\"d: num variables k: num expansion of each variable\"\"\"", "\n", "super", "(", "NotearsSobolev", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "d", ",", "self", ".", "k", "=", "d", ",", "k", "\n", "self", ".", "fc1_pos", "=", "nn", ".", "Linear", "(", "d", "*", "k", ",", "d", ",", "bias", "=", "False", ")", "# ik -> j", "\n", "self", ".", "fc1_neg", "=", "nn", ".", "Linear", "(", "d", "*", "k", ",", "d", ",", "bias", "=", "False", ")", "\n", "self", ".", "fc1_pos", ".", "weight", ".", "bounds", "=", "self", ".", "_bounds", "(", ")", "\n", "self", ".", "fc1_neg", ".", "weight", ".", "bounds", "=", "self", ".", "_bounds", "(", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "fc1_pos", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "fc1_neg", ".", "weight", ")", "\n", "self", ".", "l2_reg_store", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsSobolev._bounds": [[102, 114], ["range", "range", "range", "bounds.append"], "methods", ["None"], ["", "def", "_bounds", "(", "self", ")", ":", "\n", "# weight shape [j, ik]", "\n", "        ", "bounds", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "d", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "d", ")", ":", "\n", "                ", "for", "_", "in", "range", "(", "self", ".", "k", ")", ":", "\n", "                    ", "if", "i", "==", "j", ":", "\n", "                        ", "bound", "=", "(", "0", ",", "0", ")", "\n", "", "else", ":", "\n", "                        ", "bound", "=", "(", "0", ",", "None", ")", "\n", "", "bounds", ".", "append", "(", "bound", ")", "\n", "", "", "", "return", "bounds", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsSobolev.sobolev_basis": [[115, 124], ["range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "bases.view.view.view", "seq.append", "torch.sin", "torch.sin", "torch.sin", "torch.sin"], "methods", ["None"], ["", "def", "sobolev_basis", "(", "self", ",", "x", ")", ":", "# [n, d] -> [n, dk]", "\n", "        ", "seq", "=", "[", "]", "\n", "for", "kk", "in", "range", "(", "self", ".", "k", ")", ":", "\n", "            ", "mu", "=", "2.0", "/", "(", "2", "*", "kk", "+", "1", ")", "/", "math", ".", "pi", "# sobolev basis", "\n", "psi", "=", "mu", "*", "torch", ".", "sin", "(", "x", "/", "mu", ")", "\n", "seq", ".", "append", "(", "psi", ")", "# [n, d] * k", "\n", "", "bases", "=", "torch", ".", "stack", "(", "seq", ",", "dim", "=", "2", ")", "# [n, d, k]", "\n", "bases", "=", "bases", ".", "view", "(", "-", "1", ",", "self", ".", "d", "*", "self", ".", "k", ")", "# [n, dk]", "\n", "return", "bases", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsSobolev.forward": [[125, 130], ["nonlinear.NotearsSobolev.sobolev_basis", "nonlinear.NotearsSobolev.fc1_pos", "nonlinear.NotearsSobolev.fc1_neg", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsSobolev.sobolev_basis"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "# [n, d] -> [n, d]", "\n", "        ", "bases", "=", "self", ".", "sobolev_basis", "(", "x", ")", "# [n, dk]", "\n", "x", "=", "self", ".", "fc1_pos", "(", "bases", ")", "-", "self", ".", "fc1_neg", "(", "bases", ")", "# [n, d]", "\n", "self", ".", "l2_reg_store", "=", "torch", ".", "sum", "(", "x", "**", "2", ")", "/", "x", ".", "shape", "[", "0", "]", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsSobolev.h_func": [[131, 141], ["fc1_weight.view.view.view", "torch.sum().t", "torch.sum().t", "torch.sum().t", "torch.sum().t", "notears.trace_expm.trace_expm", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "h_func", "(", "self", ")", ":", "\n", "        ", "fc1_weight", "=", "self", ".", "fc1_pos", ".", "weight", "-", "self", ".", "fc1_neg", ".", "weight", "# [j, ik]", "\n", "fc1_weight", "=", "fc1_weight", ".", "view", "(", "self", ".", "d", ",", "self", ".", "d", ",", "self", ".", "k", ")", "# [j, i, k]", "\n", "A", "=", "torch", ".", "sum", "(", "fc1_weight", "*", "fc1_weight", ",", "dim", "=", "2", ")", ".", "t", "(", ")", "# [i, j]", "\n", "h", "=", "trace_expm", "(", "A", ")", "-", "d", "# (Zheng et al. 2018)", "\n", "# A different formulation, slightly faster at the cost of numerical stability", "\n", "# M = torch.eye(self.d) + A / self.d  # (Yu et al. 2019)", "\n", "# E = torch.matrix_power(M, self.d - 1)", "\n", "# h = (E.t() * M).sum() - self.d", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsSobolev.l2_reg": [[142, 145], ["None"], "methods", ["None"], ["", "def", "l2_reg", "(", "self", ")", ":", "\n", "        ", "reg", "=", "self", ".", "l2_reg_store", "\n", "return", "reg", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsSobolev.fc1_l1_reg": [[146, 149], ["torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "fc1_l1_reg", "(", "self", ")", ":", "\n", "        ", "reg", "=", "torch", ".", "sum", "(", "self", ".", "fc1_pos", ".", "weight", "+", "self", ".", "fc1_neg", ".", "weight", ")", "\n", "return", "reg", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsSobolev.fc1_to_adj": [[150, 158], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "fc1_weight.view.view.view", "torch.sum().t", "torch.sum().t", "torch.sum().t", "torch.sum().t", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "W.cpu().detach().numpy.cpu().detach().numpy.cpu().detach().numpy", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "W.cpu().detach().numpy.cpu().detach().numpy.cpu().detach", "W.cpu().detach().numpy.cpu().detach().numpy.cpu"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "fc1_to_adj", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "fc1_weight", "=", "self", ".", "fc1_pos", ".", "weight", "-", "self", ".", "fc1_neg", ".", "weight", "# [j, ik]", "\n", "fc1_weight", "=", "fc1_weight", ".", "view", "(", "self", ".", "d", ",", "self", ".", "d", ",", "self", ".", "k", ")", "# [j, i, k]", "\n", "A", "=", "torch", ".", "sum", "(", "fc1_weight", "*", "fc1_weight", ",", "dim", "=", "2", ")", ".", "t", "(", ")", "# [i, j]", "\n", "W", "=", "torch", ".", "sqrt", "(", "A", ")", "# [i, j]", "\n", "W", "=", "W", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "# [i, j]", "\n", "return", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.squared_loss": [[160, 164], ["torch.sum", "torch.sum"], "function", ["None"], ["", "", "def", "squared_loss", "(", "output", ",", "target", ")", ":", "\n", "    ", "n", "=", "target", ".", "shape", "[", "0", "]", "\n", "loss", "=", "0.5", "/", "n", "*", "torch", ".", "sum", "(", "(", "output", "-", "target", ")", "**", "2", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.dual_ascent_step": [[166, 192], ["notears.lbfgsb_scipy.LBFGSBScipy", "torch.from_numpy", "torch.from_numpy", "model.parameters", "notears.lbfgsb_scipy.LBFGSBScipy.step", "notears.lbfgsb_scipy.LBFGSBScipy.zero_grad", "model", "nonlinear.squared_loss", "model.h_func", "primal_obj.backward", "torch.no_grad", "torch.no_grad", "model.h_func().item", "model.l2_reg", "model.fc1_l1_reg", "model.h_func"], "function", ["home.repos.pwc.inspect_result.xunzheng_notears.notears.lbfgsb_scipy.LBFGSBScipy.step", "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.squared_loss", "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsSobolev.h_func", "home.repos.pwc.inspect_result.xunzheng_notears.notears.trace_expm.TraceExpm.backward", "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsSobolev.l2_reg", "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsSobolev.fc1_l1_reg", "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsSobolev.h_func"], ["", "def", "dual_ascent_step", "(", "model", ",", "X", ",", "lambda1", ",", "lambda2", ",", "rho", ",", "alpha", ",", "h", ",", "rho_max", ")", ":", "\n", "    ", "\"\"\"Perform one step of dual ascent in augmented Lagrangian.\"\"\"", "\n", "h_new", "=", "None", "\n", "optimizer", "=", "LBFGSBScipy", "(", "model", ".", "parameters", "(", ")", ")", "\n", "X_torch", "=", "torch", ".", "from_numpy", "(", "X", ")", "\n", "while", "rho", "<", "rho_max", ":", "\n", "        ", "def", "closure", "(", ")", ":", "\n", "            ", "optimizer", ".", "zero_grad", "(", ")", "\n", "X_hat", "=", "model", "(", "X_torch", ")", "\n", "loss", "=", "squared_loss", "(", "X_hat", ",", "X_torch", ")", "\n", "h_val", "=", "model", ".", "h_func", "(", ")", "\n", "penalty", "=", "0.5", "*", "rho", "*", "h_val", "*", "h_val", "+", "alpha", "*", "h_val", "\n", "l2_reg", "=", "0.5", "*", "lambda2", "*", "model", ".", "l2_reg", "(", ")", "\n", "l1_reg", "=", "lambda1", "*", "model", ".", "fc1_l1_reg", "(", ")", "\n", "primal_obj", "=", "loss", "+", "penalty", "+", "l2_reg", "+", "l1_reg", "\n", "primal_obj", ".", "backward", "(", ")", "\n", "return", "primal_obj", "\n", "", "optimizer", ".", "step", "(", "closure", ")", "# NOTE: updates model in-place", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "h_new", "=", "model", ".", "h_func", "(", ")", ".", "item", "(", ")", "\n", "", "if", "h_new", ">", "0.25", "*", "h", ":", "\n", "            ", "rho", "*=", "10", "\n", "", "else", ":", "\n", "            ", "break", "\n", "", "", "alpha", "+=", "rho", "*", "h_new", "\n", "return", "rho", ",", "alpha", ",", "h_new", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.notears_nonlinear": [[194, 211], ["range", "model.fc1_to_adj", "nonlinear.dual_ascent_step", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.NotearsSobolev.fc1_to_adj", "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.dual_ascent_step"], ["", "def", "notears_nonlinear", "(", "model", ":", "nn", ".", "Module", ",", "\n", "X", ":", "np", ".", "ndarray", ",", "\n", "lambda1", ":", "float", "=", "0.", ",", "\n", "lambda2", ":", "float", "=", "0.", ",", "\n", "max_iter", ":", "int", "=", "100", ",", "\n", "h_tol", ":", "float", "=", "1e-8", ",", "\n", "rho_max", ":", "float", "=", "1e+16", ",", "\n", "w_threshold", ":", "float", "=", "0.3", ")", ":", "\n", "    ", "rho", ",", "alpha", ",", "h", "=", "1.0", ",", "0.0", ",", "np", ".", "inf", "\n", "for", "_", "in", "range", "(", "max_iter", ")", ":", "\n", "        ", "rho", ",", "alpha", ",", "h", "=", "dual_ascent_step", "(", "model", ",", "X", ",", "lambda1", ",", "lambda2", ",", "\n", "rho", ",", "alpha", ",", "h", ",", "rho_max", ")", "\n", "if", "h", "<=", "h_tol", "or", "rho", ">=", "rho_max", ":", "\n", "            ", "break", "\n", "", "", "W_est", "=", "model", ".", "fc1_to_adj", "(", ")", "\n", "W_est", "[", "np", ".", "abs", "(", "W_est", ")", "<", "w_threshold", "]", "=", "0", "\n", "return", "W_est", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.main": [[213, 233], ["torch.set_default_dtype", "torch.set_default_dtype", "numpy.set_printoptions", "ut.set_random_seed", "ut.simulate_dag", "numpy.savetxt", "ut.simulate_nonlinear_sem", "numpy.savetxt", "nonlinear.NotearsMLP", "nonlinear.notears_nonlinear", "ut.is_dag", "numpy.savetxt", "ut.count_accuracy", "print"], "function", ["home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.set_random_seed", "home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.simulate_dag", "home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.simulate_nonlinear_sem", "home.repos.pwc.inspect_result.xunzheng_notears.notears.nonlinear.notears_nonlinear", "home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.is_dag", "home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.count_accuracy"], ["", "def", "main", "(", ")", ":", "\n", "    ", "torch", ".", "set_default_dtype", "(", "torch", ".", "double", ")", "\n", "np", ".", "set_printoptions", "(", "precision", "=", "3", ")", "\n", "\n", "import", "notears", ".", "utils", "as", "ut", "\n", "ut", ".", "set_random_seed", "(", "123", ")", "\n", "\n", "n", ",", "d", ",", "s0", ",", "graph_type", ",", "sem_type", "=", "200", ",", "5", ",", "9", ",", "'ER'", ",", "'mim'", "\n", "B_true", "=", "ut", ".", "simulate_dag", "(", "d", ",", "s0", ",", "graph_type", ")", "\n", "np", ".", "savetxt", "(", "'W_true.csv'", ",", "B_true", ",", "delimiter", "=", "','", ")", "\n", "\n", "X", "=", "ut", ".", "simulate_nonlinear_sem", "(", "B_true", ",", "n", ",", "sem_type", ")", "\n", "np", ".", "savetxt", "(", "'X.csv'", ",", "X", ",", "delimiter", "=", "','", ")", "\n", "\n", "model", "=", "NotearsMLP", "(", "dims", "=", "[", "d", ",", "10", ",", "1", "]", ",", "bias", "=", "True", ")", "\n", "W_est", "=", "notears_nonlinear", "(", "model", ",", "X", ",", "lambda1", "=", "0.01", ",", "lambda2", "=", "0.01", ")", "\n", "assert", "ut", ".", "is_dag", "(", "W_est", ")", "\n", "np", ".", "savetxt", "(", "'W_est.csv'", ",", "W_est", ",", "delimiter", "=", "','", ")", "\n", "acc", "=", "ut", ".", "count_accuracy", "(", "B_true", ",", "W_est", "!=", "0", ")", "\n", "print", "(", "acc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.trace_expm.TraceExpm.forward": [[7, 15], ["scipy.expm", "numpy.trace", "torch.from_numpy", "ctx.save_for_backward", "torch.as_tensor", "input.detach().numpy", "input.detach"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ")", ":", "\n", "# detach so we can cast to NumPy", "\n", "        ", "E", "=", "slin", ".", "expm", "(", "input", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "f", "=", "np", ".", "trace", "(", "E", ")", "\n", "E", "=", "torch", ".", "from_numpy", "(", "E", ")", "\n", "ctx", ".", "save_for_backward", "(", "E", ")", "\n", "return", "torch", ".", "as_tensor", "(", "f", ",", "dtype", "=", "input", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.trace_expm.TraceExpm.backward": [[16, 21], ["E.t"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "E", ",", "=", "ctx", ".", "saved_tensors", "\n", "grad_input", "=", "grad_output", "*", "E", ".", "t", "(", ")", "\n", "return", "grad_input", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.trace_expm.main": [[26, 36], ["torch.randn", "torch.autograd.gradcheck", "torch.tensor", "trace_expm", "print", "f.backward", "print", "f.item"], "function", ["home.repos.pwc.inspect_result.xunzheng_notears.notears.trace_expm.TraceExpm.backward"], ["def", "main", "(", ")", ":", "\n", "    ", "input", "=", "torch", ".", "randn", "(", "20", ",", "20", ",", "dtype", "=", "torch", ".", "double", ",", "requires_grad", "=", "True", ")", "\n", "assert", "torch", ".", "autograd", ".", "gradcheck", "(", "trace_expm", ",", "input", ")", "\n", "\n", "input", "=", "torch", ".", "tensor", "(", "[", "[", "1", ",", "2", "]", ",", "[", "3", ",", "4.", "]", "]", ",", "requires_grad", "=", "True", ")", "\n", "tre", "=", "trace_expm", "(", "input", ")", "\n", "f", "=", "0.5", "*", "tre", "*", "tre", "\n", "print", "(", "'f\\n'", ",", "f", ".", "item", "(", ")", ")", "\n", "f", ".", "backward", "(", ")", "\n", "print", "(", "'grad\\n'", ",", "input", ".", "grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.locally_connected.LocallyConnected.__init__": [[24, 41], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "locally_connected.LocallyConnected.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Parameter", "torch.Parameter", "locally_connected.LocallyConnected.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.xunzheng_notears.notears.lbfgsb_scipy.LBFGSBScipy.__init__", "home.repos.pwc.inspect_result.xunzheng_notears.notears.locally_connected.LocallyConnected.reset_parameters"], ["def", "__init__", "(", "self", ",", "num_linear", ",", "input_features", ",", "output_features", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "LocallyConnected", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_linear", "=", "num_linear", "\n", "self", ".", "input_features", "=", "input_features", "\n", "self", ".", "output_features", "=", "output_features", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_linear", ",", "\n", "input_features", ",", "\n", "output_features", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_linear", ",", "output_features", ")", ")", "\n", "", "else", ":", "\n", "# You should always register all possible parameters, but the", "\n", "# optional ones can be None if you want.", "\n", "            ", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.locally_connected.LocallyConnected.reset_parameters": [[42, 49], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "math.sqrt", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "k", "=", "1.0", "/", "self", ".", "input_features", "\n", "bound", "=", "math", ".", "sqrt", "(", "k", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "weight", ",", "-", "bound", ",", "bound", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "bias", ",", "-", "bound", ",", "bound", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.locally_connected.LocallyConnected.forward": [[50, 58], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "out.squeeze.squeeze.squeeze", "input.unsqueeze", "locally_connected.LocallyConnected.weight.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", ":", "\n", "# [n, d, 1, m2] = [n, d, 1, m1] @ [1, d, m1, m2]", "\n", "        ", "out", "=", "torch", ".", "matmul", "(", "input", ".", "unsqueeze", "(", "dim", "=", "2", ")", ",", "self", ".", "weight", ".", "unsqueeze", "(", "dim", "=", "0", ")", ")", "\n", "out", "=", "out", ".", "squeeze", "(", "dim", "=", "2", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "# [n, d, m2] += [d, m2]", "\n", "            ", "out", "+=", "self", ".", "bias", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.locally_connected.LocallyConnected.extra_repr": [[59, 65], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "# (Optional)Set the extra information about this module. You can test", "\n", "# it by printing an object of this class.", "\n", "        ", "return", "'num_linear={}, in_features={}, out_features={}, bias={}'", ".", "format", "(", "\n", "self", ".", "num_linear", ",", "self", ".", "in_features", ",", "self", ".", "out_features", ",", "\n", "self", ".", "bias", "is", "not", "None", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.locally_connected.main": [[68, 89], ["np.random.randn", "np.random.randn", "np.zeros", "range", "torch.set_default_dtype", "torch.set_default_dtype", "torch.from_numpy", "torch.from_numpy", "locally_connected.LocallyConnected", "torch.from_numpy", "torch.from_numpy", "LocallyConnected.", "print", "torch.allclose", "torch.allclose", "torch.from_numpy", "torch.from_numpy"], "function", ["None"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "n", ",", "d", ",", "m1", ",", "m2", "=", "2", ",", "3", ",", "5", ",", "7", "\n", "\n", "# numpy", "\n", "import", "numpy", "as", "np", "\n", "input_numpy", "=", "np", ".", "random", ".", "randn", "(", "n", ",", "d", ",", "m1", ")", "\n", "weight", "=", "np", ".", "random", ".", "randn", "(", "d", ",", "m1", ",", "m2", ")", "\n", "output_numpy", "=", "np", ".", "zeros", "(", "[", "n", ",", "d", ",", "m2", "]", ")", "\n", "for", "j", "in", "range", "(", "d", ")", ":", "\n", "# [n, m2] = [n, m1] @ [m1, m2]", "\n", "        ", "output_numpy", "[", ":", ",", "j", ",", ":", "]", "=", "input_numpy", "[", ":", ",", "j", ",", ":", "]", "@", "weight", "[", "j", ",", ":", ",", ":", "]", "\n", "\n", "# torch", "\n", "", "torch", ".", "set_default_dtype", "(", "torch", ".", "double", ")", "\n", "input_torch", "=", "torch", ".", "from_numpy", "(", "input_numpy", ")", "\n", "locally_connected", "=", "LocallyConnected", "(", "d", ",", "m1", ",", "m2", ",", "bias", "=", "False", ")", "\n", "locally_connected", ".", "weight", ".", "data", "[", ":", "]", "=", "torch", ".", "from_numpy", "(", "weight", ")", "\n", "output_torch", "=", "locally_connected", "(", "input_torch", ")", "\n", "\n", "# compare", "\n", "print", "(", "torch", ".", "allclose", "(", "output_torch", ",", "torch", ".", "from_numpy", "(", "output_numpy", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.lbfgsb_scipy.LBFGSBScipy.__init__": [[12, 22], ["dict", "super().__init__", "sum", "len", "ValueError", "p.numel"], "methods", ["home.repos.pwc.inspect_result.xunzheng_notears.notears.lbfgsb_scipy.LBFGSBScipy.__init__"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "defaults", "=", "dict", "(", ")", "\n", "super", "(", "LBFGSBScipy", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n", "if", "len", "(", "self", ".", "param_groups", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"LBFGSBScipy doesn't support per-parameter options\"", "\n", "\" (parameter groups)\"", ")", "\n", "\n", "", "self", ".", "_params", "=", "self", ".", "param_groups", "[", "0", "]", "[", "'params'", "]", "\n", "self", ".", "_numel", "=", "sum", "(", "[", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "_params", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.lbfgsb_scipy.LBFGSBScipy._gather_flat_grad": [[23, 34], ["torch.cat", "views.append", "p.data.new().zero_", "p.grad.data.to_dense().view", "p.grad.data.view", "p.data.new", "p.data.numel", "p.grad.data.to_dense"], "methods", ["None"], ["", "def", "_gather_flat_grad", "(", "self", ")", ":", "\n", "        ", "views", "=", "[", "]", "\n", "for", "p", "in", "self", ".", "_params", ":", "\n", "            ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                ", "view", "=", "p", ".", "data", ".", "new", "(", "p", ".", "data", ".", "numel", "(", ")", ")", ".", "zero_", "(", ")", "\n", "", "elif", "p", ".", "grad", ".", "data", ".", "is_sparse", ":", "\n", "                ", "view", "=", "p", ".", "grad", ".", "data", ".", "to_dense", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "view", "=", "p", ".", "grad", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "views", ".", "append", "(", "view", ")", "\n", "", "return", "torch", ".", "cat", "(", "views", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.lbfgsb_scipy.LBFGSBScipy._gather_flat_bounds": [[35, 44], ["hasattr", "p.numel"], "methods", ["None"], ["", "def", "_gather_flat_bounds", "(", "self", ")", ":", "\n", "        ", "bounds", "=", "[", "]", "\n", "for", "p", "in", "self", ".", "_params", ":", "\n", "            ", "if", "hasattr", "(", "p", ",", "'bounds'", ")", ":", "\n", "                ", "b", "=", "p", ".", "bounds", "\n", "", "else", ":", "\n", "                ", "b", "=", "[", "(", "None", ",", "None", ")", "]", "*", "p", ".", "numel", "(", ")", "\n", "", "bounds", "+=", "b", "\n", "", "return", "bounds", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.lbfgsb_scipy.LBFGSBScipy._gather_flat_params": [[45, 54], ["torch.cat", "views.append", "p.data.to_dense().view", "p.data.view", "p.data.to_dense"], "methods", ["None"], ["", "def", "_gather_flat_params", "(", "self", ")", ":", "\n", "        ", "views", "=", "[", "]", "\n", "for", "p", "in", "self", ".", "_params", ":", "\n", "            ", "if", "p", ".", "data", ".", "is_sparse", ":", "\n", "                ", "view", "=", "p", ".", "data", ".", "to_dense", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "view", "=", "p", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "views", ".", "append", "(", "view", ")", "\n", "", "return", "torch", ".", "cat", "(", "views", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.lbfgsb_scipy.LBFGSBScipy._distribute_flat_params": [[55, 63], ["p.numel", "params[].view_as"], "methods", ["None"], ["", "def", "_distribute_flat_params", "(", "self", ",", "params", ")", ":", "\n", "        ", "offset", "=", "0", "\n", "for", "p", "in", "self", ".", "_params", ":", "\n", "            ", "numel", "=", "p", ".", "numel", "(", ")", "\n", "# view as to avoid deprecated pointwise semantics", "\n", "p", ".", "data", "=", "params", "[", "offset", ":", "offset", "+", "numel", "]", ".", "view_as", "(", "p", ".", "data", ")", "\n", "offset", "+=", "numel", "\n", "", "assert", "offset", "==", "self", ".", "_numel", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.lbfgsb_scipy.LBFGSBScipy.step": [[64, 98], ["lbfgsb_scipy.LBFGSBScipy._gather_flat_params", "initial_params.cpu().detach().numpy.cpu().detach().numpy.cpu().detach().numpy", "lbfgsb_scipy.LBFGSBScipy._gather_flat_bounds", "scipy.minimize", "torch.from_numpy", "final_params.to.to.to", "lbfgsb_scipy.LBFGSBScipy._distribute_flat_params", "len", "torch.from_numpy", "flat_params.to.to.to", "lbfgsb_scipy.LBFGSBScipy._distribute_flat_params", "closure", "loss.item.item.item", "lbfgsb_scipy.LBFGSBScipy._gather_flat_grad().cpu().detach().numpy", "torch.get_default_dtype", "torch.get_default_dtype", "lbfgsb_scipy.LBFGSBScipy.astype", "initial_params.cpu().detach().numpy.cpu().detach().numpy.cpu().detach", "lbfgsb_scipy.LBFGSBScipy._gather_flat_grad().cpu().detach", "initial_params.cpu().detach().numpy.cpu().detach().numpy.cpu", "lbfgsb_scipy.LBFGSBScipy._gather_flat_grad().cpu", "lbfgsb_scipy.LBFGSBScipy._gather_flat_grad"], "methods", ["home.repos.pwc.inspect_result.xunzheng_notears.notears.lbfgsb_scipy.LBFGSBScipy._gather_flat_params", "home.repos.pwc.inspect_result.xunzheng_notears.notears.lbfgsb_scipy.LBFGSBScipy._gather_flat_bounds", "home.repos.pwc.inspect_result.xunzheng_notears.notears.lbfgsb_scipy.LBFGSBScipy._distribute_flat_params", "home.repos.pwc.inspect_result.xunzheng_notears.notears.lbfgsb_scipy.LBFGSBScipy._distribute_flat_params", "home.repos.pwc.inspect_result.xunzheng_notears.notears.lbfgsb_scipy.LBFGSBScipy._gather_flat_grad"], ["", "def", "step", "(", "self", ",", "closure", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "assert", "len", "(", "self", ".", "param_groups", ")", "==", "1", "\n", "\n", "def", "wrapped_closure", "(", "flat_params", ")", ":", "\n", "            ", "\"\"\"closure must call zero_grad() and backward()\"\"\"", "\n", "flat_params", "=", "torch", ".", "from_numpy", "(", "flat_params", ")", "\n", "flat_params", "=", "flat_params", ".", "to", "(", "torch", ".", "get_default_dtype", "(", ")", ")", "\n", "self", ".", "_distribute_flat_params", "(", "flat_params", ")", "\n", "loss", "=", "closure", "(", ")", "\n", "loss", "=", "loss", ".", "item", "(", ")", "\n", "flat_grad", "=", "self", ".", "_gather_flat_grad", "(", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "return", "loss", ",", "flat_grad", ".", "astype", "(", "'float64'", ")", "\n", "\n", "", "initial_params", "=", "self", ".", "_gather_flat_params", "(", ")", "\n", "initial_params", "=", "initial_params", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "bounds", "=", "self", ".", "_gather_flat_bounds", "(", ")", "\n", "\n", "# Magic", "\n", "sol", "=", "sopt", ".", "minimize", "(", "wrapped_closure", ",", "\n", "initial_params", ",", "\n", "method", "=", "'L-BFGS-B'", ",", "\n", "jac", "=", "True", ",", "\n", "bounds", "=", "bounds", ")", "\n", "\n", "final_params", "=", "torch", ".", "from_numpy", "(", "sol", ".", "x", ")", "\n", "final_params", "=", "final_params", ".", "to", "(", "torch", ".", "get_default_dtype", "(", ")", ")", "\n", "self", ".", "_distribute_flat_params", "(", "final_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.lbfgsb_scipy.main": [[100, 127], ["torch.randn", "torch.rand", "torch.matmul", "nn.Linear", "range", "nn.MSELoss", "lbfgsb_scipy.LBFGSBScipy", "print", "lbfgsb_scipy.LBFGSBScipy.step", "print", "print", "nn.Linear.parameters", "list", "LBFGSBScipy.zero_grad", "nn.Linear.", "nn.MSELoss.", "print", "criterion.backward", "list", "torch.rand.t", "nn.Linear.parameters", "criterion.item", "nn.Linear.parameters"], "function", ["home.repos.pwc.inspect_result.xunzheng_notears.notears.lbfgsb_scipy.LBFGSBScipy.step", "home.repos.pwc.inspect_result.xunzheng_notears.notears.trace_expm.TraceExpm.backward"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "import", "torch", ".", "nn", "as", "nn", "\n", "# torch.set_default_dtype(torch.double)", "\n", "\n", "n", ",", "d", ",", "out", ",", "j", "=", "10000", ",", "3000", ",", "10", ",", "0", "\n", "input", "=", "torch", ".", "randn", "(", "n", ",", "d", ")", "\n", "w_true", "=", "torch", ".", "rand", "(", "d", ",", "out", ")", "\n", "w_true", "[", "j", ",", ":", "]", "=", "0", "\n", "target", "=", "torch", ".", "matmul", "(", "input", ",", "w_true", ")", "\n", "linear", "=", "nn", ".", "Linear", "(", "d", ",", "out", ")", "\n", "linear", ".", "weight", ".", "bounds", "=", "[", "(", "0", ",", "None", ")", "]", "*", "d", "*", "out", "# hack", "\n", "for", "m", "in", "range", "(", "out", ")", ":", "\n", "        ", "linear", ".", "weight", ".", "bounds", "[", "m", "*", "d", "+", "j", "]", "=", "(", "0", ",", "0", ")", "\n", "", "criterion", "=", "nn", ".", "MSELoss", "(", ")", "\n", "optimizer", "=", "LBFGSBScipy", "(", "linear", ".", "parameters", "(", ")", ")", "\n", "print", "(", "list", "(", "linear", ".", "parameters", "(", ")", ")", ")", "\n", "\n", "def", "closure", "(", ")", ":", "\n", "        ", "optimizer", ".", "zero_grad", "(", ")", "\n", "output", "=", "linear", "(", "input", ")", "\n", "loss", "=", "criterion", "(", "output", ",", "target", ")", "\n", "print", "(", "'loss:'", ",", "loss", ".", "item", "(", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "return", "loss", "\n", "", "optimizer", ".", "step", "(", "closure", ")", "\n", "print", "(", "list", "(", "linear", ".", "parameters", "(", ")", ")", ")", "\n", "print", "(", "w_true", ".", "t", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.linear.notears_linear": [[7, 87], ["range", "linear.notears_linear._adj"], "function", ["None"], ["def", "notears_linear", "(", "X", ",", "lambda1", ",", "loss_type", ",", "max_iter", "=", "100", ",", "h_tol", "=", "1e-8", ",", "rho_max", "=", "1e+16", ",", "w_threshold", "=", "0.3", ")", ":", "\n", "    ", "\"\"\"Solve min_W L(W; X) + lambda1 \u2016W\u2016_1 s.t. h(W) = 0 using augmented Lagrangian.\n\n    Args:\n        X (np.ndarray): [n, d] sample matrix\n        lambda1 (float): l1 penalty parameter\n        loss_type (str): l2, logistic, poisson\n        max_iter (int): max num of dual ascent steps\n        h_tol (float): exit if |h(w_est)| <= htol\n        rho_max (float): exit if rho >= rho_max\n        w_threshold (float): drop edge if |weight| < threshold\n\n    Returns:\n        W_est (np.ndarray): [d, d] estimated DAG\n    \"\"\"", "\n", "def", "_loss", "(", "W", ")", ":", "\n", "        ", "\"\"\"Evaluate value and gradient of loss.\"\"\"", "\n", "M", "=", "X", "@", "W", "\n", "if", "loss_type", "==", "'l2'", ":", "\n", "            ", "R", "=", "X", "-", "M", "\n", "loss", "=", "0.5", "/", "X", ".", "shape", "[", "0", "]", "*", "(", "R", "**", "2", ")", ".", "sum", "(", ")", "\n", "G_loss", "=", "-", "1.0", "/", "X", ".", "shape", "[", "0", "]", "*", "X", ".", "T", "@", "R", "\n", "", "elif", "loss_type", "==", "'logistic'", ":", "\n", "            ", "loss", "=", "1.0", "/", "X", ".", "shape", "[", "0", "]", "*", "(", "np", ".", "logaddexp", "(", "0", ",", "M", ")", "-", "X", "*", "M", ")", ".", "sum", "(", ")", "\n", "G_loss", "=", "1.0", "/", "X", ".", "shape", "[", "0", "]", "*", "X", ".", "T", "@", "(", "sigmoid", "(", "M", ")", "-", "X", ")", "\n", "", "elif", "loss_type", "==", "'poisson'", ":", "\n", "            ", "S", "=", "np", ".", "exp", "(", "M", ")", "\n", "loss", "=", "1.0", "/", "X", ".", "shape", "[", "0", "]", "*", "(", "S", "-", "X", "*", "M", ")", ".", "sum", "(", ")", "\n", "G_loss", "=", "1.0", "/", "X", ".", "shape", "[", "0", "]", "*", "X", ".", "T", "@", "(", "S", "-", "X", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'unknown loss type'", ")", "\n", "", "return", "loss", ",", "G_loss", "\n", "\n", "", "def", "_h", "(", "W", ")", ":", "\n", "        ", "\"\"\"Evaluate value and gradient of acyclicity constraint.\"\"\"", "\n", "E", "=", "slin", ".", "expm", "(", "W", "*", "W", ")", "# (Zheng et al. 2018)", "\n", "h", "=", "np", ".", "trace", "(", "E", ")", "-", "d", "\n", "#     # A different formulation, slightly faster at the cost of numerical stability", "\n", "#     M = np.eye(d) + W * W / d  # (Yu et al. 2019)", "\n", "#     E = np.linalg.matrix_power(M, d - 1)", "\n", "#     h = (E.T * M).sum() - d", "\n", "G_h", "=", "E", ".", "T", "*", "W", "*", "2", "\n", "return", "h", ",", "G_h", "\n", "\n", "", "def", "_adj", "(", "w", ")", ":", "\n", "        ", "\"\"\"Convert doubled variables ([2 d^2] array) back to original variables ([d, d] matrix).\"\"\"", "\n", "return", "(", "w", "[", ":", "d", "*", "d", "]", "-", "w", "[", "d", "*", "d", ":", "]", ")", ".", "reshape", "(", "[", "d", ",", "d", "]", ")", "\n", "\n", "", "def", "_func", "(", "w", ")", ":", "\n", "        ", "\"\"\"Evaluate value and gradient of augmented Lagrangian for doubled variables ([2 d^2] array).\"\"\"", "\n", "W", "=", "_adj", "(", "w", ")", "\n", "loss", ",", "G_loss", "=", "_loss", "(", "W", ")", "\n", "h", ",", "G_h", "=", "_h", "(", "W", ")", "\n", "obj", "=", "loss", "+", "0.5", "*", "rho", "*", "h", "*", "h", "+", "alpha", "*", "h", "+", "lambda1", "*", "w", ".", "sum", "(", ")", "\n", "G_smooth", "=", "G_loss", "+", "(", "rho", "*", "h", "+", "alpha", ")", "*", "G_h", "\n", "g_obj", "=", "np", ".", "concatenate", "(", "(", "G_smooth", "+", "lambda1", ",", "-", "G_smooth", "+", "lambda1", ")", ",", "axis", "=", "None", ")", "\n", "return", "obj", ",", "g_obj", "\n", "\n", "", "n", ",", "d", "=", "X", ".", "shape", "\n", "w_est", ",", "rho", ",", "alpha", ",", "h", "=", "np", ".", "zeros", "(", "2", "*", "d", "*", "d", ")", ",", "1.0", ",", "0.0", ",", "np", ".", "inf", "# double w_est into (w_pos, w_neg)", "\n", "bnds", "=", "[", "(", "0", ",", "0", ")", "if", "i", "==", "j", "else", "(", "0", ",", "None", ")", "for", "_", "in", "range", "(", "2", ")", "for", "i", "in", "range", "(", "d", ")", "for", "j", "in", "range", "(", "d", ")", "]", "\n", "if", "loss_type", "==", "'l2'", ":", "\n", "        ", "X", "=", "X", "-", "np", ".", "mean", "(", "X", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "", "for", "_", "in", "range", "(", "max_iter", ")", ":", "\n", "        ", "w_new", ",", "h_new", "=", "None", ",", "None", "\n", "while", "rho", "<", "rho_max", ":", "\n", "            ", "sol", "=", "sopt", ".", "minimize", "(", "_func", ",", "w_est", ",", "method", "=", "'L-BFGS-B'", ",", "jac", "=", "True", ",", "bounds", "=", "bnds", ")", "\n", "w_new", "=", "sol", ".", "x", "\n", "h_new", ",", "_", "=", "_h", "(", "_adj", "(", "w_new", ")", ")", "\n", "if", "h_new", ">", "0.25", "*", "h", ":", "\n", "                ", "rho", "*=", "10", "\n", "", "else", ":", "\n", "                ", "break", "\n", "", "", "w_est", ",", "h", "=", "w_new", ",", "h_new", "\n", "alpha", "+=", "rho", "*", "h", "\n", "if", "h", "<=", "h_tol", "or", "rho", ">=", "rho_max", ":", "\n", "            ", "break", "\n", "", "", "W_est", "=", "_adj", "(", "w_est", ")", "\n", "W_est", "[", "np", ".", "abs", "(", "W_est", ")", "<", "w_threshold", "]", "=", "0", "\n", "return", "W_est", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.set_random_seed": [[7, 10], ["random.seed", "numpy.random.seed"], "function", ["None"], ["def", "set_random_seed", "(", "seed", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.is_dag": [[12, 15], ["igraph.Graph.Weighted_Adjacency", "ig.Graph.Weighted_Adjacency.is_dag", "W.tolist"], "function", ["home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.is_dag"], ["", "def", "is_dag", "(", "W", ")", ":", "\n", "    ", "G", "=", "ig", ".", "Graph", ".", "Weighted_Adjacency", "(", "W", ".", "tolist", "(", ")", ")", "\n", "return", "G", ".", "is_dag", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.simulate_dag": [[17, 58], ["utils.simulate_dag._random_permutation"], "function", ["None"], ["", "def", "simulate_dag", "(", "d", ",", "s0", ",", "graph_type", ")", ":", "\n", "    ", "\"\"\"Simulate random DAG with some expected number of edges.\n\n    Args:\n        d (int): num of nodes\n        s0 (int): expected num of edges\n        graph_type (str): ER, SF, BP\n\n    Returns:\n        B (np.ndarray): [d, d] binary adj matrix of DAG\n    \"\"\"", "\n", "def", "_random_permutation", "(", "M", ")", ":", "\n", "# np.random.permutation permutes first axis only", "\n", "        ", "P", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "eye", "(", "M", ".", "shape", "[", "0", "]", ")", ")", "\n", "return", "P", ".", "T", "@", "M", "@", "P", "\n", "\n", "", "def", "_random_acyclic_orientation", "(", "B_und", ")", ":", "\n", "        ", "return", "np", ".", "tril", "(", "_random_permutation", "(", "B_und", ")", ",", "k", "=", "-", "1", ")", "\n", "\n", "", "def", "_graph_to_adjmat", "(", "G", ")", ":", "\n", "        ", "return", "np", ".", "array", "(", "G", ".", "get_adjacency", "(", ")", ".", "data", ")", "\n", "\n", "", "if", "graph_type", "==", "'ER'", ":", "\n", "# Erdos-Renyi", "\n", "        ", "G_und", "=", "ig", ".", "Graph", ".", "Erdos_Renyi", "(", "n", "=", "d", ",", "m", "=", "s0", ")", "\n", "B_und", "=", "_graph_to_adjmat", "(", "G_und", ")", "\n", "B", "=", "_random_acyclic_orientation", "(", "B_und", ")", "\n", "", "elif", "graph_type", "==", "'SF'", ":", "\n", "# Scale-free, Barabasi-Albert", "\n", "        ", "G", "=", "ig", ".", "Graph", ".", "Barabasi", "(", "n", "=", "d", ",", "m", "=", "int", "(", "round", "(", "s0", "/", "d", ")", ")", ",", "directed", "=", "True", ")", "\n", "B", "=", "_graph_to_adjmat", "(", "G", ")", "\n", "", "elif", "graph_type", "==", "'BP'", ":", "\n", "# Bipartite, Sec 4.1 of (Gu, Fu, Zhou, 2018)", "\n", "        ", "top", "=", "int", "(", "0.2", "*", "d", ")", "\n", "G", "=", "ig", ".", "Graph", ".", "Random_Bipartite", "(", "top", ",", "d", "-", "top", ",", "m", "=", "s0", ",", "directed", "=", "True", ",", "neimode", "=", "ig", ".", "OUT", ")", "\n", "B", "=", "_graph_to_adjmat", "(", "G", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'unknown graph type'", ")", "\n", "", "B_perm", "=", "_random_permutation", "(", "B", ")", "\n", "assert", "ig", ".", "Graph", ".", "Adjacency", "(", "B_perm", ".", "tolist", "(", ")", ")", ".", "is_dag", "(", ")", "\n", "return", "B_perm", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.simulate_parameter": [[60, 76], ["numpy.zeros", "numpy.random.randint", "enumerate", "len", "numpy.random.uniform"], "function", ["None"], ["", "def", "simulate_parameter", "(", "B", ",", "w_ranges", "=", "(", "(", "-", "2.0", ",", "-", "0.5", ")", ",", "(", "0.5", ",", "2.0", ")", ")", ")", ":", "\n", "    ", "\"\"\"Simulate SEM parameters for a DAG.\n\n    Args:\n        B (np.ndarray): [d, d] binary adj matrix of DAG\n        w_ranges (tuple): disjoint weight ranges\n\n    Returns:\n        W (np.ndarray): [d, d] weighted adj matrix of DAG\n    \"\"\"", "\n", "W", "=", "np", ".", "zeros", "(", "B", ".", "shape", ")", "\n", "S", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "w_ranges", ")", ",", "size", "=", "B", ".", "shape", ")", "# which range", "\n", "for", "i", ",", "(", "low", ",", "high", ")", "in", "enumerate", "(", "w_ranges", ")", ":", "\n", "        ", "U", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "low", ",", "high", "=", "high", ",", "size", "=", "B", ".", "shape", ")", "\n", "W", "+=", "B", "*", "(", "S", "==", "i", ")", "*", "U", "\n", "", "return", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.simulate_linear_sem": [[78, 141], ["numpy.isinf", "igraph.Graph.Weighted_Adjacency", "ig.Graph.Weighted_Adjacency.topological_sorting", "numpy.zeros", "numpy.ones", "numpy.isscalar", "utils.is_dag", "ValueError", "W.tolist", "len", "ig.Graph.Weighted_Adjacency.neighbors", "utils.simulate_linear_sem._simulate_single_equation"], "function", ["home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.is_dag"], ["", "def", "simulate_linear_sem", "(", "W", ",", "n", ",", "sem_type", ",", "noise_scale", "=", "None", ")", ":", "\n", "    ", "\"\"\"Simulate samples from linear SEM with specified type of noise.\n\n    For uniform, noise z ~ uniform(-a, a), where a = noise_scale.\n\n    Args:\n        W (np.ndarray): [d, d] weighted adj matrix of DAG\n        n (int): num of samples, n=inf mimics population risk\n        sem_type (str): gauss, exp, gumbel, uniform, logistic, poisson\n        noise_scale (np.ndarray): scale parameter of additive noise, default all ones\n\n    Returns:\n        X (np.ndarray): [n, d] sample matrix, [d, d] if n=inf\n    \"\"\"", "\n", "def", "_simulate_single_equation", "(", "X", ",", "w", ",", "scale", ")", ":", "\n", "        ", "\"\"\"X: [n, num of parents], w: [num of parents], x: [n]\"\"\"", "\n", "if", "sem_type", "==", "'gauss'", ":", "\n", "            ", "z", "=", "np", ".", "random", ".", "normal", "(", "scale", "=", "scale", ",", "size", "=", "n", ")", "\n", "x", "=", "X", "@", "w", "+", "z", "\n", "", "elif", "sem_type", "==", "'exp'", ":", "\n", "            ", "z", "=", "np", ".", "random", ".", "exponential", "(", "scale", "=", "scale", ",", "size", "=", "n", ")", "\n", "x", "=", "X", "@", "w", "+", "z", "\n", "", "elif", "sem_type", "==", "'gumbel'", ":", "\n", "            ", "z", "=", "np", ".", "random", ".", "gumbel", "(", "scale", "=", "scale", ",", "size", "=", "n", ")", "\n", "x", "=", "X", "@", "w", "+", "z", "\n", "", "elif", "sem_type", "==", "'uniform'", ":", "\n", "            ", "z", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "scale", ",", "high", "=", "scale", ",", "size", "=", "n", ")", "\n", "x", "=", "X", "@", "w", "+", "z", "\n", "", "elif", "sem_type", "==", "'logistic'", ":", "\n", "            ", "x", "=", "np", ".", "random", ".", "binomial", "(", "1", ",", "sigmoid", "(", "X", "@", "w", ")", ")", "*", "1.0", "\n", "", "elif", "sem_type", "==", "'poisson'", ":", "\n", "            ", "x", "=", "np", ".", "random", ".", "poisson", "(", "np", ".", "exp", "(", "X", "@", "w", ")", ")", "*", "1.0", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'unknown sem type'", ")", "\n", "", "return", "x", "\n", "\n", "", "d", "=", "W", ".", "shape", "[", "0", "]", "\n", "if", "noise_scale", "is", "None", ":", "\n", "        ", "scale_vec", "=", "np", ".", "ones", "(", "d", ")", "\n", "", "elif", "np", ".", "isscalar", "(", "noise_scale", ")", ":", "\n", "        ", "scale_vec", "=", "noise_scale", "*", "np", ".", "ones", "(", "d", ")", "\n", "", "else", ":", "\n", "        ", "if", "len", "(", "noise_scale", ")", "!=", "d", ":", "\n", "            ", "raise", "ValueError", "(", "'noise scale must be a scalar or has length d'", ")", "\n", "", "scale_vec", "=", "noise_scale", "\n", "", "if", "not", "is_dag", "(", "W", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'W must be a DAG'", ")", "\n", "", "if", "np", ".", "isinf", "(", "n", ")", ":", "# population risk for linear gauss SEM", "\n", "        ", "if", "sem_type", "==", "'gauss'", ":", "\n", "# make 1/d X'X = true cov", "\n", "            ", "X", "=", "np", ".", "sqrt", "(", "d", ")", "*", "np", ".", "diag", "(", "scale_vec", ")", "@", "np", ".", "linalg", ".", "inv", "(", "np", ".", "eye", "(", "d", ")", "-", "W", ")", "\n", "return", "X", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'population risk not available'", ")", "\n", "# empirical risk", "\n", "", "", "G", "=", "ig", ".", "Graph", ".", "Weighted_Adjacency", "(", "W", ".", "tolist", "(", ")", ")", "\n", "ordered_vertices", "=", "G", ".", "topological_sorting", "(", ")", "\n", "assert", "len", "(", "ordered_vertices", ")", "==", "d", "\n", "X", "=", "np", ".", "zeros", "(", "[", "n", ",", "d", "]", ")", "\n", "for", "j", "in", "ordered_vertices", ":", "\n", "        ", "parents", "=", "G", ".", "neighbors", "(", "j", ",", "mode", "=", "ig", ".", "IN", ")", "\n", "X", "[", ":", ",", "j", "]", "=", "_simulate_single_equation", "(", "X", "[", ":", ",", "parents", "]", ",", "W", "[", "parents", ",", "j", "]", ",", "scale_vec", "[", "j", "]", ")", "\n", "", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.simulate_nonlinear_sem": [[143, 199], ["numpy.zeros", "igraph.Graph.Adjacency", "ig.Graph.Adjacency.topological_sorting", "numpy.random.normal", "numpy.ones", "B.tolist", "len", "ig.Graph.Adjacency.neighbors", "utils.simulate_linear_sem._simulate_single_equation"], "function", ["None"], ["", "def", "simulate_nonlinear_sem", "(", "B", ",", "n", ",", "sem_type", ",", "noise_scale", "=", "None", ")", ":", "\n", "    ", "\"\"\"Simulate samples from nonlinear SEM.\n\n    Args:\n        B (np.ndarray): [d, d] binary adj matrix of DAG\n        n (int): num of samples\n        sem_type (str): mlp, mim, gp, gp-add\n        noise_scale (np.ndarray): scale parameter of additive noise, default all ones\n\n    Returns:\n        X (np.ndarray): [n, d] sample matrix\n    \"\"\"", "\n", "def", "_simulate_single_equation", "(", "X", ",", "scale", ")", ":", "\n", "        ", "\"\"\"X: [n, num of parents], x: [n]\"\"\"", "\n", "z", "=", "np", ".", "random", ".", "normal", "(", "scale", "=", "scale", ",", "size", "=", "n", ")", "\n", "pa_size", "=", "X", ".", "shape", "[", "1", "]", "\n", "if", "pa_size", "==", "0", ":", "\n", "            ", "return", "z", "\n", "", "if", "sem_type", "==", "'mlp'", ":", "\n", "            ", "hidden", "=", "100", "\n", "W1", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.5", ",", "high", "=", "2.0", ",", "size", "=", "[", "pa_size", ",", "hidden", "]", ")", "\n", "W1", "[", "np", ".", "random", ".", "rand", "(", "*", "W1", ".", "shape", ")", "<", "0.5", "]", "*=", "-", "1", "\n", "W2", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.5", ",", "high", "=", "2.0", ",", "size", "=", "hidden", ")", "\n", "W2", "[", "np", ".", "random", ".", "rand", "(", "hidden", ")", "<", "0.5", "]", "*=", "-", "1", "\n", "x", "=", "sigmoid", "(", "X", "@", "W1", ")", "@", "W2", "+", "z", "\n", "", "elif", "sem_type", "==", "'mim'", ":", "\n", "            ", "w1", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.5", ",", "high", "=", "2.0", ",", "size", "=", "pa_size", ")", "\n", "w1", "[", "np", ".", "random", ".", "rand", "(", "pa_size", ")", "<", "0.5", "]", "*=", "-", "1", "\n", "w2", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.5", ",", "high", "=", "2.0", ",", "size", "=", "pa_size", ")", "\n", "w2", "[", "np", ".", "random", ".", "rand", "(", "pa_size", ")", "<", "0.5", "]", "*=", "-", "1", "\n", "w3", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.5", ",", "high", "=", "2.0", ",", "size", "=", "pa_size", ")", "\n", "w3", "[", "np", ".", "random", ".", "rand", "(", "pa_size", ")", "<", "0.5", "]", "*=", "-", "1", "\n", "x", "=", "np", ".", "tanh", "(", "X", "@", "w1", ")", "+", "np", ".", "cos", "(", "X", "@", "w2", ")", "+", "np", ".", "sin", "(", "X", "@", "w3", ")", "+", "z", "\n", "", "elif", "sem_type", "==", "'gp'", ":", "\n", "            ", "from", "sklearn", ".", "gaussian_process", "import", "GaussianProcessRegressor", "\n", "gp", "=", "GaussianProcessRegressor", "(", ")", "\n", "x", "=", "gp", ".", "sample_y", "(", "X", ",", "random_state", "=", "None", ")", ".", "flatten", "(", ")", "+", "z", "\n", "", "elif", "sem_type", "==", "'gp-add'", ":", "\n", "            ", "from", "sklearn", ".", "gaussian_process", "import", "GaussianProcessRegressor", "\n", "gp", "=", "GaussianProcessRegressor", "(", ")", "\n", "x", "=", "sum", "(", "[", "gp", ".", "sample_y", "(", "X", "[", ":", ",", "i", ",", "None", "]", ",", "random_state", "=", "None", ")", ".", "flatten", "(", ")", "\n", "for", "i", "in", "range", "(", "X", ".", "shape", "[", "1", "]", ")", "]", ")", "+", "z", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'unknown sem type'", ")", "\n", "", "return", "x", "\n", "\n", "", "d", "=", "B", ".", "shape", "[", "0", "]", "\n", "scale_vec", "=", "noise_scale", "if", "noise_scale", "else", "np", ".", "ones", "(", "d", ")", "\n", "X", "=", "np", ".", "zeros", "(", "[", "n", ",", "d", "]", ")", "\n", "G", "=", "ig", ".", "Graph", ".", "Adjacency", "(", "B", ".", "tolist", "(", ")", ")", "\n", "ordered_vertices", "=", "G", ".", "topological_sorting", "(", ")", "\n", "assert", "len", "(", "ordered_vertices", ")", "==", "d", "\n", "for", "j", "in", "ordered_vertices", ":", "\n", "        ", "parents", "=", "G", ".", "neighbors", "(", "j", ",", "mode", "=", "ig", ".", "IN", ")", "\n", "X", "[", ":", ",", "j", "]", "=", "_simulate_single_equation", "(", "X", "[", ":", ",", "parents", "]", ",", "scale_vec", "[", "j", "]", ")", "\n", "", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.count_accuracy": [[201, 261], ["numpy.flatnonzero", "numpy.flatnonzero", "numpy.flatnonzero", "numpy.flatnonzero", "numpy.concatenate", "numpy.intersect1d", "numpy.intersect1d", "numpy.concatenate", "numpy.setdiff1d", "numpy.setdiff1d", "numpy.concatenate", "numpy.setdiff1d", "numpy.intersect1d", "numpy.flatnonzero", "numpy.flatnonzero", "numpy.setdiff1d", "numpy.setdiff1d", "len", "len", "len", "float", "max", "float", "max", "float", "max", "numpy.tril", "numpy.tril", "len", "ValueError", "ValueError", "ValueError", "utils.is_dag", "ValueError", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.is_dag"], ["", "def", "count_accuracy", "(", "B_true", ",", "B_est", ")", ":", "\n", "    ", "\"\"\"Compute various accuracy metrics for B_est.\n\n    true positive = predicted association exists in condition in correct direction\n    reverse = predicted association exists in condition in opposite direction\n    false positive = predicted association does not exist in condition\n\n    Args:\n        B_true (np.ndarray): [d, d] ground truth graph, {0, 1}\n        B_est (np.ndarray): [d, d] estimate, {0, 1, -1}, -1 is undirected edge in CPDAG\n\n    Returns:\n        fdr: (reverse + false positive) / prediction positive\n        tpr: (true positive) / condition positive\n        fpr: (reverse + false positive) / condition negative\n        shd: undirected extra + undirected missing + reverse\n        nnz: prediction positive\n    \"\"\"", "\n", "if", "(", "B_est", "==", "-", "1", ")", ".", "any", "(", ")", ":", "# cpdag", "\n", "        ", "if", "not", "(", "(", "B_est", "==", "0", ")", "|", "(", "B_est", "==", "1", ")", "|", "(", "B_est", "==", "-", "1", ")", ")", ".", "all", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'B_est should take value in {0,1,-1}'", ")", "\n", "", "if", "(", "(", "B_est", "==", "-", "1", ")", "&", "(", "B_est", ".", "T", "==", "-", "1", ")", ")", ".", "any", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'undirected edge should only appear once'", ")", "\n", "", "", "else", ":", "# dag", "\n", "        ", "if", "not", "(", "(", "B_est", "==", "0", ")", "|", "(", "B_est", "==", "1", ")", ")", ".", "all", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'B_est should take value in {0,1}'", ")", "\n", "", "if", "not", "is_dag", "(", "B_est", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'B_est should be a DAG'", ")", "\n", "", "", "d", "=", "B_true", ".", "shape", "[", "0", "]", "\n", "# linear index of nonzeros", "\n", "pred_und", "=", "np", ".", "flatnonzero", "(", "B_est", "==", "-", "1", ")", "\n", "pred", "=", "np", ".", "flatnonzero", "(", "B_est", "==", "1", ")", "\n", "cond", "=", "np", ".", "flatnonzero", "(", "B_true", ")", "\n", "cond_reversed", "=", "np", ".", "flatnonzero", "(", "B_true", ".", "T", ")", "\n", "cond_skeleton", "=", "np", ".", "concatenate", "(", "[", "cond", ",", "cond_reversed", "]", ")", "\n", "# true pos", "\n", "true_pos", "=", "np", ".", "intersect1d", "(", "pred", ",", "cond", ",", "assume_unique", "=", "True", ")", "\n", "# treat undirected edge favorably", "\n", "true_pos_und", "=", "np", ".", "intersect1d", "(", "pred_und", ",", "cond_skeleton", ",", "assume_unique", "=", "True", ")", "\n", "true_pos", "=", "np", ".", "concatenate", "(", "[", "true_pos", ",", "true_pos_und", "]", ")", "\n", "# false pos", "\n", "false_pos", "=", "np", ".", "setdiff1d", "(", "pred", ",", "cond_skeleton", ",", "assume_unique", "=", "True", ")", "\n", "false_pos_und", "=", "np", ".", "setdiff1d", "(", "pred_und", ",", "cond_skeleton", ",", "assume_unique", "=", "True", ")", "\n", "false_pos", "=", "np", ".", "concatenate", "(", "[", "false_pos", ",", "false_pos_und", "]", ")", "\n", "# reverse", "\n", "extra", "=", "np", ".", "setdiff1d", "(", "pred", ",", "cond", ",", "assume_unique", "=", "True", ")", "\n", "reverse", "=", "np", ".", "intersect1d", "(", "extra", ",", "cond_reversed", ",", "assume_unique", "=", "True", ")", "\n", "# compute ratio", "\n", "pred_size", "=", "len", "(", "pred", ")", "+", "len", "(", "pred_und", ")", "\n", "cond_neg_size", "=", "0.5", "*", "d", "*", "(", "d", "-", "1", ")", "-", "len", "(", "cond", ")", "\n", "fdr", "=", "float", "(", "len", "(", "reverse", ")", "+", "len", "(", "false_pos", ")", ")", "/", "max", "(", "pred_size", ",", "1", ")", "\n", "tpr", "=", "float", "(", "len", "(", "true_pos", ")", ")", "/", "max", "(", "len", "(", "cond", ")", ",", "1", ")", "\n", "fpr", "=", "float", "(", "len", "(", "reverse", ")", "+", "len", "(", "false_pos", ")", ")", "/", "max", "(", "cond_neg_size", ",", "1", ")", "\n", "# structural hamming distance", "\n", "pred_lower", "=", "np", ".", "flatnonzero", "(", "np", ".", "tril", "(", "B_est", "+", "B_est", ".", "T", ")", ")", "\n", "cond_lower", "=", "np", ".", "flatnonzero", "(", "np", ".", "tril", "(", "B_true", "+", "B_true", ".", "T", ")", ")", "\n", "extra_lower", "=", "np", ".", "setdiff1d", "(", "pred_lower", ",", "cond_lower", ",", "assume_unique", "=", "True", ")", "\n", "missing_lower", "=", "np", ".", "setdiff1d", "(", "cond_lower", ",", "pred_lower", ",", "assume_unique", "=", "True", ")", "\n", "shd", "=", "len", "(", "extra_lower", ")", "+", "len", "(", "missing_lower", ")", "+", "len", "(", "reverse", ")", "\n", "return", "{", "'fdr'", ":", "fdr", ",", "'tpr'", ":", "tpr", ",", "'fpr'", ":", "fpr", ",", "'shd'", ":", "shd", ",", "'nnz'", ":", "pred_size", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.experiments.expt_twovars.main": [[9, 34], ["notears.utils.set_random_seed", "expt_twovars.run_expt", "expt_twovars.run_expt", "expt_twovars.run_expt"], "function", ["home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.set_random_seed", "home.repos.pwc.inspect_result.xunzheng_notears.experiments.expt_twovars.run_expt", "home.repos.pwc.inspect_result.xunzheng_notears.experiments.expt_twovars.run_expt", "home.repos.pwc.inspect_result.xunzheng_notears.experiments.expt_twovars.run_expt"], ["def", "main", "(", ")", ":", "\n", "    ", "utils", ".", "set_random_seed", "(", "123", ")", "\n", "\n", "num_graph", "=", "1000", "\n", "num_data_per_graph", "=", "1", "\n", "\n", "n", ",", "d", ",", "s0", ",", "graph_type", ",", "sem_type", "=", "np", ".", "inf", ",", "2", ",", "1", ",", "'ER'", ",", "'gauss'", "\n", "\n", "# equal variance", "\n", "w_ranges", "=", "(", "(", "-", "2.0", ",", "-", "0.5", ")", ",", "(", "0.5", ",", "2.0", ")", ")", "\n", "noise_scale", "=", "[", "1.", ",", "1.", "]", "\n", "expt_name", "=", "'equal_var'", "\n", "run_expt", "(", "num_graph", ",", "num_data_per_graph", ",", "n", ",", "d", ",", "s0", ",", "graph_type", ",", "sem_type", ",", "w_ranges", ",", "noise_scale", ",", "expt_name", ")", "\n", "\n", "# large a", "\n", "w_ranges", "=", "(", "(", "-", "2.0", ",", "-", "1.1", ")", ",", "(", "1.1", ",", "2.0", ")", ")", "\n", "noise_scale", "=", "[", "1.", ",", "0.15", "]", "\n", "expt_name", "=", "'large_a'", "\n", "run_expt", "(", "num_graph", ",", "num_data_per_graph", ",", "n", ",", "d", ",", "s0", ",", "graph_type", ",", "sem_type", ",", "w_ranges", ",", "noise_scale", ",", "expt_name", ")", "\n", "\n", "# small a", "\n", "w_ranges", "=", "(", "(", "-", "0.9", ",", "-", "0.5", ")", ",", "(", "0.5", ",", "0.9", ")", ")", "\n", "noise_scale", "=", "[", "1", ",", "0.15", "]", "\n", "expt_name", "=", "'small_a'", "\n", "run_expt", "(", "num_graph", ",", "num_data_per_graph", ",", "n", ",", "d", ",", "s0", ",", "graph_type", ",", "sem_type", ",", "w_ranges", ",", "noise_scale", ",", "expt_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xunzheng_notears.experiments.expt_twovars.run_expt": [[36, 63], ["os.mkdir", "os.chmod", "collections.defaultdict", "tqdm.tqdm", "print", "range", "notears.utils.simulate_dag", "notears.utils.simulate_parameter", "os.path.join", "numpy.savetxt", "range", "print", "notears.utils.simulate_linear_sem", "os.path.join", "numpy.savetxt", "notears.notears.notears_linear_l1", "notears.utils.is_dag", "os.path.join", "numpy.savetxt", "notears.utils.count_accuracy", "perf[].append", "numpy.mean", "numpy.std"], "function", ["home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.simulate_dag", "home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.simulate_parameter", "home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.simulate_linear_sem", "home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.is_dag", "home.repos.pwc.inspect_result.xunzheng_notears.notears.utils.count_accuracy"], ["", "def", "run_expt", "(", "num_graph", ",", "num_data_per_graph", ",", "n", ",", "d", ",", "s0", ",", "graph_type", ",", "sem_type", ",", "w_ranges", ",", "noise_scale", ",", "expt_name", ")", ":", "\n", "    ", "os", ".", "mkdir", "(", "expt_name", ")", "\n", "os", ".", "chmod", "(", "expt_name", ",", "0o777", ")", "\n", "perf", "=", "defaultdict", "(", "list", ")", "\n", "for", "ii", "in", "tqdm", "(", "range", "(", "num_graph", ")", ")", ":", "\n", "        ", "B_true", "=", "utils", ".", "simulate_dag", "(", "d", ",", "s0", ",", "graph_type", ")", "\n", "W_true", "=", "utils", ".", "simulate_parameter", "(", "B_true", ",", "w_ranges", "=", "w_ranges", ")", "\n", "W_true_fn", "=", "os", ".", "path", ".", "join", "(", "expt_name", ",", "f'graph{ii:05}_W_true.csv'", ")", "\n", "np", ".", "savetxt", "(", "W_true_fn", ",", "W_true", ",", "delimiter", "=", "','", ")", "\n", "for", "jj", "in", "range", "(", "num_data_per_graph", ")", ":", "\n", "            ", "X", "=", "utils", ".", "simulate_linear_sem", "(", "W_true", ",", "n", ",", "sem_type", ",", "noise_scale", "=", "noise_scale", ")", "\n", "X_fn", "=", "os", ".", "path", ".", "join", "(", "expt_name", ",", "f'graph{ii:05}_data{jj:05}_X.csv'", ")", "\n", "np", ".", "savetxt", "(", "X_fn", ",", "X", ",", "delimiter", "=", "','", ")", "\n", "# notears", "\n", "W_notears", "=", "notears", ".", "notears_linear_l1", "(", "X", ",", "lambda1", "=", "0", ",", "loss_type", "=", "'l2'", ")", "\n", "assert", "utils", ".", "is_dag", "(", "W_notears", ")", "\n", "W_notears_fn", "=", "os", ".", "path", ".", "join", "(", "expt_name", ",", "f'graph{ii:05}_data{jj:05}_W_notears.csv'", ")", "\n", "np", ".", "savetxt", "(", "W_notears_fn", ",", "W_notears", ",", "delimiter", "=", "','", ")", "\n", "# eval", "\n", "B_notears", "=", "(", "W_notears", "!=", "0", ")", "\n", "acc", "=", "utils", ".", "count_accuracy", "(", "B_true", ",", "B_notears", ")", "\n", "for", "metric", "in", "acc", ":", "\n", "                ", "perf", "[", "metric", "]", ".", "append", "(", "acc", "[", "metric", "]", ")", "\n", "# print stats", "\n", "", "", "", "print", "(", "expt_name", ")", "\n", "for", "metric", "in", "perf", ":", "\n", "        ", "print", "(", "metric", ",", "f'{np.mean(perf[metric]):.4f}'", ",", "'+/-'", ",", "f'{np.std(perf[metric]):.4f}'", ")", "\n", "\n"]]}