{"home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.common.DataFromListOfDict.__init__": [[12, 17], ["len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "lst", ",", "keys", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "self", ".", "_lst", "=", "lst", "\n", "self", ".", "_keys", "=", "keys", "\n", "self", ".", "_shuffle", "=", "shuffle", "\n", "self", ".", "_size", "=", "len", "(", "lst", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.common.DataFromListOfDict.__len__": [[18, 20], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.common.DataFromListOfDict.__iter__": [[21, 27], ["common.DataFromListOfDict.rng.shuffle"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_shuffle", ":", "\n", "            ", "self", ".", "rng", ".", "shuffle", "(", "self", ".", "_lst", ")", "\n", "", "for", "dic", "in", "self", ".", "_lst", ":", "\n", "            ", "dp", "=", "[", "dic", "[", "k", "]", "for", "k", "in", "self", ".", "_keys", "]", "\n", "yield", "dp", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.common.CustomResize.__init__": [[35, 46], ["tensorpack.dataflow.imgaug.ImageAugmentor.__init__", "isinstance", "common.CustomResize._init", "locals"], "methods", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.test.TextRecognition.__init__"], ["def", "__init__", "(", "self", ",", "short_edge_length", ",", "max_size", ",", "interp", "=", "cv2", ".", "INTER_LINEAR", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            short_edge_length ([int, int]): a [min, max] interval from which to sample the\n                shortest edge length.\n            max_size (int): maximum allowed longest edge length.\n        \"\"\"", "\n", "super", "(", "CustomResize", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "short_edge_length", ",", "int", ")", ":", "\n", "            ", "short_edge_length", "=", "(", "short_edge_length", ",", "short_edge_length", ")", "\n", "", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.common.CustomResize.get_transform": [[47, 63], ["common.CustomResize.rng.randint", "int", "int", "tensorpack.dataflow.imgaug.ResizeTransform", "min", "max", "max"], "methods", ["None"], ["", "def", "get_transform", "(", "self", ",", "img", ")", ":", "\n", "        ", "h", ",", "w", "=", "img", ".", "shape", "[", ":", "2", "]", "\n", "size", "=", "self", ".", "rng", ".", "randint", "(", "\n", "self", ".", "short_edge_length", "[", "0", "]", ",", "self", ".", "short_edge_length", "[", "1", "]", "+", "1", ")", "\n", "scale", "=", "size", "*", "1.0", "/", "min", "(", "h", ",", "w", ")", "\n", "if", "h", "<", "w", ":", "\n", "            ", "newh", ",", "neww", "=", "size", ",", "scale", "*", "w", "\n", "", "else", ":", "\n", "            ", "newh", ",", "neww", "=", "scale", "*", "h", ",", "size", "\n", "", "if", "max", "(", "newh", ",", "neww", ")", ">", "self", ".", "max_size", ":", "\n", "            ", "scale", "=", "self", ".", "max_size", "*", "1.0", "/", "max", "(", "newh", ",", "neww", ")", "\n", "newh", "=", "newh", "*", "scale", "\n", "neww", "=", "neww", "*", "scale", "\n", "", "neww", "=", "int", "(", "neww", "+", "0.5", ")", "\n", "newh", "=", "int", "(", "newh", "+", "0.5", ")", "\n", "return", "ResizeTransform", "(", "h", ",", "w", ",", "newh", ",", "neww", ",", "self", ".", "interp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.common.box_to_point8": [[65, 76], ["b.reshape.reshape"], "function", ["None"], ["", "", "def", "box_to_point8", "(", "boxes", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        boxes: nx4\n\n    Returns:\n        (nx4)x2\n    \"\"\"", "\n", "b", "=", "boxes", "[", ":", ",", "[", "0", ",", "1", ",", "2", ",", "3", ",", "0", ",", "3", ",", "2", ",", "1", "]", "]", "\n", "b", "=", "b", ".", "reshape", "(", "(", "-", "1", ",", "2", ")", ")", "\n", "return", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.common.point8_to_box": [[78, 89], ["points.reshape", "points.reshape.min", "points.reshape.max", "numpy.concatenate"], "function", ["None"], ["", "def", "point8_to_box", "(", "points", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        points: (nx4)x2\n    Returns:\n        nx4 boxes (x1y1x2y2)\n    \"\"\"", "\n", "p", "=", "points", ".", "reshape", "(", "(", "-", "1", ",", "4", ",", "2", ")", ")", "\n", "minxy", "=", "p", ".", "min", "(", "axis", "=", "1", ")", "# nx2", "\n", "maxxy", "=", "p", ".", "max", "(", "axis", "=", "1", ")", "# nx2", "\n", "return", "np", ".", "concatenate", "(", "(", "minxy", ",", "maxxy", ")", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.common.polygons_to_mask": [[91, 108], ["cocomask.frPyObjects", "cocomask.merge", "cocomask.decode", "p.flatten().tolist", "len", "p.flatten"], "function", ["None"], ["", "def", "polygons_to_mask", "(", "polys", ",", "height", ",", "width", ")", ":", "\n", "    ", "\"\"\"\n    Convert polygons to binary masks.\n\n    Args:\n        polys: a list of nx2 float array. Each array contains many (x, y) coordinates.\n\n    Returns:\n        a binary matrix of (height, width)\n    \"\"\"", "\n", "polys", "=", "[", "p", ".", "flatten", "(", ")", ".", "tolist", "(", ")", "for", "p", "in", "polys", "]", "\n", "assert", "len", "(", "polys", ")", ">", "0", ",", "\"Polygons are empty!\"", "\n", "\n", "import", "pycocotools", ".", "mask", "as", "cocomask", "\n", "rles", "=", "cocomask", ".", "frPyObjects", "(", "polys", ",", "height", ",", "width", ")", "\n", "rle", "=", "cocomask", ".", "merge", "(", "rles", ")", "\n", "return", "cocomask", ".", "decode", "(", "rle", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.common.clip_boxes": [[110, 123], ["boxes.reshape.reshape", "numpy.maximum", "numpy.minimum", "numpy.minimum", "boxes.reshape.reshape"], "function", ["None"], ["", "def", "clip_boxes", "(", "boxes", ",", "shape", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        boxes: (...)x4, float\n        shape: h, w\n    \"\"\"", "\n", "orig_shape", "=", "boxes", ".", "shape", "\n", "boxes", "=", "boxes", ".", "reshape", "(", "[", "-", "1", ",", "4", "]", ")", "\n", "h", ",", "w", "=", "shape", "\n", "boxes", "[", ":", ",", "[", "0", ",", "1", "]", "]", "=", "np", ".", "maximum", "(", "boxes", "[", ":", ",", "[", "0", ",", "1", "]", "]", ",", "0", ")", "\n", "boxes", "[", ":", ",", "2", "]", "=", "np", ".", "minimum", "(", "boxes", "[", ":", ",", "2", "]", ",", "w", ")", "\n", "boxes", "[", ":", ",", "3", "]", "=", "np", ".", "minimum", "(", "boxes", "[", ":", ",", "3", "]", ",", "h", ")", "\n", "return", "boxes", ".", "reshape", "(", "orig_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.common.filter_boxes_inside_shape": [[125, 144], ["len", "numpy.where"], "function", ["None"], ["", "def", "filter_boxes_inside_shape", "(", "boxes", ",", "shape", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        boxes: (nx4), float\n        shape: (h, w)\n\n    Returns:\n        indices: (k, )\n        selection: (kx4)\n    \"\"\"", "\n", "assert", "boxes", ".", "ndim", "==", "2", ",", "boxes", ".", "shape", "\n", "assert", "len", "(", "shape", ")", "==", "2", ",", "shape", "\n", "h", ",", "w", "=", "shape", "\n", "indices", "=", "np", ".", "where", "(", "\n", "(", "boxes", "[", ":", ",", "0", "]", ">=", "0", ")", "&", "\n", "(", "boxes", "[", ":", ",", "1", "]", ">=", "0", ")", "&", "\n", "(", "boxes", "[", ":", ",", "2", "]", "<=", "w", ")", "&", "\n", "(", "boxes", "[", ":", ",", "3", "]", "<=", "h", ")", ")", "[", "0", "]", "\n", "return", "indices", ",", "boxes", "[", "indices", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.eval.cal_sim": [[21, 47], ["numpy.zeros", "range", "range", "range", "len", "len", "range", "max", "max", "min", "min"], "function", ["None"], ["def", "cal_sim", "(", "str1", ",", "str2", ")", ":", "\n", "    ", "\"\"\"\n    Normalized Edit Distance metric (1-N.E.D specifically)\n    \"\"\"", "\n", "m", "=", "len", "(", "str1", ")", "+", "1", "\n", "n", "=", "len", "(", "str2", ")", "+", "1", "\n", "matrix", "=", "np", ".", "zeros", "(", "(", "m", ",", "n", ")", ")", "\n", "for", "i", "in", "range", "(", "m", ")", ":", "\n", "        ", "matrix", "[", "i", "]", "[", "0", "]", "=", "i", "\n", "\n", "", "for", "j", "in", "range", "(", "n", ")", ":", "\n", "        ", "matrix", "[", "0", "]", "[", "j", "]", "=", "j", "\n", "\n", "", "for", "i", "in", "range", "(", "1", ",", "m", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "1", ",", "n", ")", ":", "\n", "            ", "if", "str1", "[", "i", "-", "1", "]", "==", "str2", "[", "j", "-", "1", "]", ":", "\n", "                ", "matrix", "[", "i", "]", "[", "j", "]", "=", "matrix", "[", "i", "-", "1", "]", "[", "j", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "matrix", "[", "i", "]", "[", "j", "]", "=", "min", "(", "matrix", "[", "i", "-", "1", "]", "[", "j", "-", "1", "]", ",", "min", "(", "matrix", "[", "i", "]", "[", "j", "-", "1", "]", ",", "matrix", "[", "i", "-", "1", "]", "[", "j", "]", ")", ")", "+", "1", "\n", "\n", "", "", "", "lev", "=", "matrix", "[", "m", "-", "1", "]", "[", "n", "-", "1", "]", "\n", "if", "(", "max", "(", "m", "-", "1", ",", "n", "-", "1", ")", ")", "==", "0", ":", "\n", "        ", "sim", "=", "1.0", "\n", "", "else", ":", "\n", "        ", "sim", "=", "1.0", "-", "lev", "/", "(", "max", "(", "m", "-", "1", ",", "n", "-", "1", ")", ")", "\n", "", "return", "sim", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.eval.preprocess": [[49, 80], ["common.polygons_to_mask", "cv2.boundingRect", "numpy.expand_dims", "cv2.resize", "cv2.copyMakeBorder", "numpy.float32", "numpy.asarray", "int", "int", "config.cfg.image_size"], "function", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.common.polygons_to_mask"], ["", "def", "preprocess", "(", "image", ",", "points", ",", "size", "=", "cfg", ".", "image_size", ")", ":", "\n", "    ", "\"\"\"\n    Preprocess for test.\n    Args:\n        image: test image\n        points: text polygon\n        size: test image size\n    \"\"\"", "\n", "height", ",", "width", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "mask", "=", "polygons_to_mask", "(", "[", "np", ".", "asarray", "(", "points", ",", "np", ".", "float32", ")", "]", ",", "height", ",", "width", ")", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "cv2", ".", "boundingRect", "(", "mask", ")", "\n", "mask", "=", "np", ".", "expand_dims", "(", "np", ".", "float32", "(", "mask", ")", ",", "axis", "=", "-", "1", ")", "\n", "image", "=", "image", "*", "mask", "\n", "image", "=", "image", "[", "y", ":", "y", "+", "h", ",", "x", ":", "x", "+", "w", ",", ":", "]", "\n", "\n", "new_height", ",", "new_width", "=", "(", "size", ",", "int", "(", "w", "*", "size", "/", "h", ")", ")", "if", "h", ">", "w", "else", "(", "int", "(", "h", "*", "size", "/", "w", ")", ",", "size", ")", "\n", "image", "=", "cv2", ".", "resize", "(", "image", ",", "(", "new_width", ",", "new_height", ")", ")", "\n", "\n", "if", "new_height", ">", "new_width", ":", "\n", "        ", "padding_top", ",", "padding_down", "=", "0", ",", "0", "\n", "padding_left", "=", "(", "size", "-", "new_width", ")", "//", "2", "\n", "padding_right", "=", "size", "-", "padding_left", "-", "new_width", "\n", "", "else", ":", "\n", "        ", "padding_left", ",", "padding_right", "=", "0", ",", "0", "\n", "padding_top", "=", "(", "size", "-", "new_height", ")", "//", "2", "\n", "padding_down", "=", "size", "-", "padding_top", "-", "new_height", "\n", "\n", "", "image", "=", "cv2", ".", "copyMakeBorder", "(", "image", ",", "padding_top", ",", "padding_down", ",", "padding_left", ",", "padding_right", ",", "borderType", "=", "cv2", ".", "BORDER_CONSTANT", ",", "value", "=", "[", "0", ",", "0", ",", "0", "]", ")", "\n", "\n", "image", "=", "image", "/", "255.", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.eval.label2str": [[82, 94], ["results.append", "min", "len"], "function", ["None"], ["", "def", "label2str", "(", "preds", ",", "probs", ",", "label_dict", ",", "eos", "=", "'EOS'", ")", ":", "\n", "    ", "\"\"\"\n    Predicted sequence to string. \n    \"\"\"", "\n", "results", "=", "[", "]", "\n", "for", "idx", "in", "preds", ":", "\n", "        ", "if", "label_dict", "[", "idx", "]", "==", "eos", ":", "\n", "            ", "break", "\n", "", "results", ".", "append", "(", "label_dict", "[", "idx", "]", ")", "\n", "\n", "", "probabilities", "=", "probs", "[", ":", "min", "(", "len", "(", "results", ")", "+", "1", ",", "cfg", ".", "seq_len", "+", "1", ")", "]", "\n", "return", "''", ".", "join", "(", "results", ")", ",", "probabilities", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.eval.eval": [[95, 129], ["model.tensorpack_model.AttentionOCR", "tensorpack.predict.PredictConfig", "tensorpack.predict.OfflinePredictor", "zip", "print", "cv2.imread", "cv2.cvtColor", "eval.preprocess", "time.time", "tensorpack.predict.OfflinePredictor.", "time.time", "eval.label2str", "print", "print", "eval.cal_sim", "tensorpack.tfutils.SmartInit", "numpy.expand_dims", "numpy.ones", "model.tensorpack_model.AttentionOCR.get_inferene_tensor_names", "model.tensorpack_model.AttentionOCR.get_inferene_tensor_names"], "function", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.test.preprocess", "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.eval.label2str", "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.eval.cal_sim", "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.tensorpack_model.AttentionOCR.get_inferene_tensor_names", "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.tensorpack_model.AttentionOCR.get_inferene_tensor_names"], ["", "def", "eval", "(", "args", ",", "filenames", ",", "polygons", ",", "labels", ",", "label_dict", "=", "cfg", ".", "label_dict", ")", ":", "\n", "    ", "Normalized_ED", "=", "0.", "\n", "total_num", "=", "0", "\n", "total_time", "=", "0", "\n", "\n", "model", "=", "AttentionOCR", "(", ")", "\n", "predcfg", "=", "PredictConfig", "(", "\n", "model", "=", "model", ",", "\n", "session_init", "=", "SmartInit", "(", "args", ".", "checkpoint_path", ")", ",", "\n", "input_names", "=", "model", ".", "get_inferene_tensor_names", "(", ")", "[", "0", "]", ",", "\n", "output_names", "=", "model", ".", "get_inferene_tensor_names", "(", ")", "[", "1", "]", ")", "\n", "\n", "predictor", "=", "OfflinePredictor", "(", "predcfg", ")", "\n", "\n", "for", "filename", ",", "points", ",", "label", "in", "zip", "(", "filenames", ",", "polygons", ",", "labels", ")", ":", "\n", "        ", "image", "=", "cv2", ".", "imread", "(", "filename", ")", "\n", "image", "=", "cv2", ".", "cvtColor", "(", "image", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "image", "=", "preprocess", "(", "image", ",", "points", ",", "cfg", ".", "image_size", ")", "\n", "\n", "before", "=", "time", ".", "time", "(", ")", "\n", "preds", ",", "probs", "=", "predictor", "(", "np", ".", "expand_dims", "(", "image", ",", "axis", "=", "0", ")", ",", "np", ".", "ones", "(", "[", "1", ",", "cfg", ".", "seq_len", "+", "1", "]", ",", "np", ".", "int32", ")", ",", "False", ",", "1.", ")", "\n", "after", "=", "time", ".", "time", "(", ")", "\n", "\n", "total_time", "+=", "after", "-", "before", "\n", "preds", ",", "probs", "=", "label2str", "(", "preds", "[", "0", "]", ",", "probs", "[", "0", "]", ",", "label_dict", ")", "\n", "print", "(", "label", ")", "\n", "print", "(", "preds", ",", "probs", ")", "\n", "\n", "sim", "=", "cal_sim", "(", "preds", ",", "label", ")", "\n", "\n", "total_num", "+=", "1", "\n", "Normalized_ED", "+=", "sim", "\n", "\n", "", "print", "(", "\"total_num: %d, 1-N.E.D: %.4f, average time: %.4f\"", "%", "(", "total_num", ",", "Normalized_ED", "/", "total_num", ",", "total_time", "/", "total_num", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.train.train": [[21, 70], ["text_dataflow.get_roidb", "text_dataflow.get_batch_train_dataflow", "logger.set_logger_dir", "model.tensorpack_model.AttentionOCR", "TrainConfig", "SyncMultiGPUTrainerReplicated", "launch_train_with_config", "PeriodicCallback", "ScheduledHyperParamSetter", "GPUMemoryTracker", "HostMemoryTracker", "ThroughputTracker", "EstimatedTimeLeft", "SessionRunTimeout", "GPUUtilizationTracker", "SmartInit", "SaverRestoreRelaxed", "ModelSaver", "QueueInput"], "function", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.get_roidb", "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.get_batch_train_dataflow"], ["def", "train", "(", ")", ":", "\n", "    ", "roidb", "=", "get_roidb", "(", "cfg", ".", "dataset_name", ")", "\n", "train_dataflow", "=", "get_batch_train_dataflow", "(", "roidb", ",", "cfg", ".", "batch_size", ")", "\n", "\n", "logger", ".", "set_logger_dir", "(", "cfg", ".", "summary_path", ",", "'d'", ")", "\n", "\n", "# Compute the training schedule from the number of GPUs ...", "\n", "warmup_schedule", "=", "[", "(", "0", ",", "cfg", ".", "learning_rate", "/", "100", ")", ",", "(", "cfg", ".", "warmup_steps", ",", "cfg", ".", "learning_rate", ")", "]", "\n", "# lr_schedule = [(int(cfg.warmup_steps/cfg.steps_per_epoch+0.5), cfg.learning_rate),(cfg.num_epochs-150, cfg.learning_rate/10),(cfg.num_epochs-50, cfg.learning_rate/100)]", "\n", "\n", "# Create callbacks ...", "\n", "callbacks", "=", "[", "\n", "PeriodicCallback", "(", "\n", "ModelSaver", "(", "max_to_keep", "=", "20", ",", "keep_checkpoint_every_n_hours", "=", "1", ")", ",", "\n", "every_k_epochs", "=", "20", ")", ",", "\n", "# linear warmup", "\n", "ScheduledHyperParamSetter", "(", "\n", "'learning_rate'", ",", "warmup_schedule", ",", "interp", "=", "'linear'", ",", "step_based", "=", "True", ")", ",", "\n", "# ScheduledHyperParamSetter('learning_rate', lr_schedule),", "\n", "GPUMemoryTracker", "(", ")", ",", "\n", "HostMemoryTracker", "(", ")", ",", "\n", "ThroughputTracker", "(", "samples_per_step", "=", "cfg", ".", "num_gpus", ")", ",", "\n", "EstimatedTimeLeft", "(", "median", "=", "True", ")", ",", "\n", "SessionRunTimeout", "(", "60000", ")", ",", "# 1 minute timeout", "\n", "GPUUtilizationTracker", "(", ")", "\n", "]", "\n", "\n", "\n", "# session_init = SmartInit(cfg.pretrain_path, ignore_mismatch=True)", "\n", "if", "cfg", ".", "restore_path", ":", "\n", "        ", "session_init", "=", "SmartInit", "(", "cfg", ".", "restore_path", ",", "ignore_mismatch", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "session_init", "=", "SaverRestoreRelaxed", "(", "cfg", ".", "pretrain_path", ",", "ignore", "=", "[", "'global_step:0'", "]", ")", "# if cfg.pretrain_path else SmartInit(cfg.restore_path, ignore_mismatch=True)", "\n", "\n", "", "model", "=", "AttentionOCR", "(", ")", "\n", "\n", "traincfg", "=", "TrainConfig", "(", "\n", "model", "=", "model", ",", "\n", "data", "=", "QueueInput", "(", "train_dataflow", ")", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "steps_per_epoch", "=", "cfg", ".", "steps_per_epoch", ",", "\n", "max_epoch", "=", "cfg", ".", "num_epochs", ",", "\n", "session_init", "=", "session_init", ",", "\n", "starting_epoch", "=", "cfg", ".", "starting_epoch", "\n", ")", "\n", "\n", "trainer", "=", "SyncMultiGPUTrainerReplicated", "(", "cfg", ".", "num_gpus", ",", "average", "=", "False", ",", "mode", "=", "'nccl'", ")", "\n", "\n", "launch_train_with_config", "(", "traincfg", ",", "trainer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.dataset.Dataset.__init__": [[73, 84], ["print"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "name", "=", "'base'", ",", "max_len", "=", "max_len", ",", "base_dir", "=", "base_dir", ",", "label_dict", "=", "cfg", ".", "reverse_label_dict", ")", ":", "# label_dict  label_dict_with_rects 5434+1", "\n", "        ", "self", ".", "data_path", "=", "dataset_path", "[", "name", "]", "\n", "print", "(", "self", ".", "data_path", ")", "\n", "self", ".", "label_dict", "=", "label_dict", "\n", "self", ".", "max_len", "=", "max_len", "\n", "self", ".", "base_dir", "=", "base_dir", "\n", "self", ".", "filenames", "=", "[", "]", "\n", "self", ".", "labels", "=", "[", "]", "\n", "self", ".", "masks", "=", "[", "]", "\n", "self", ".", "bboxes", "=", "[", "]", "\n", "self", ".", "points", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.dataset.ReCTS.__init__": [[91, 93], ["dataset.Dataset.__init__"], "methods", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.test.TextRecognition.__init__"], ["def", "__init__", "(", "self", ",", "name", "=", "'rects'", ")", ":", "\n", "        ", "super", "(", "ReCTS", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.dataset.ReCTS.load_data": [[94, 159], ["os.path.join", "os.listdir", "os.path.join", "open", "json.load", "zip", "os.path.join", "dataset.preprocess", "seq_label.append", "len", "numpy.array", "numpy.reshape", "dataset.ReCTS.filenames.append", "dataset.ReCTS.labels.append", "dataset.ReCTS.masks.append", "dataset.ReCTS.bboxes.append", "dataset.ReCTS.points.append", "len", "print", "seq_label.append", "numpy.amin", "numpy.amin", "numpy.amax", "numpy.amax", "int", "dataset.ReCTS.label_dict.keys"], "methods", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.test.preprocess"], ["", "def", "load_data", "(", "self", ")", ":", "\n", "        ", "label_folder", "=", "os", ".", "path", ".", "join", "(", "self", ".", "base_dir", ",", "'rects/gt_unicode/'", ")", "#gt_unicode gt", "\n", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "label_folder", ")", ":", "\n", "            ", "img_name", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "filename", "[", ":", "-", "5", "]", "+", "'.jpg'", ")", "\n", "# image = cv2.imread(img_name)", "\n", "# print(img_name)", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "label_folder", ",", "filename", ")", ")", "as", "f", ":", "\n", "                ", "json_data", "=", "json", ".", "load", "(", "f", ")", "\n", "anno_data", "=", "json_data", "[", "'lines'", "]", "\n", "points", "=", "[", "anno", "[", "'points'", "]", "for", "anno", "in", "anno_data", "]", "\n", "transcripts", "=", "[", "anno", "[", "'transcription'", "]", "for", "anno", "in", "anno_data", "]", "\n", "ignores", "=", "[", "anno", "[", "'ignore'", "]", "for", "anno", "in", "anno_data", "]", "\n", "for", "polygon", ",", "transcript", ",", "ignore", "in", "zip", "(", "points", ",", "transcripts", ",", "ignores", ")", ":", "\n", "                    ", "if", "ignore", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "len", "(", "transcript", ")", ">", "self", ".", "max_len", "-", "1", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "transcript", "==", "'###'", ":", "\n", "                        ", "continue", "\n", "\n", "", "transcript", "=", "preprocess", "(", "transcript", ")", "\n", "\n", "skip", "=", "False", "\n", "for", "char", "in", "transcript", ":", "\n", "                        ", "if", "char", "not", "in", "self", ".", "label_dict", ".", "keys", "(", ")", ":", "\n", "                            ", "skip", "=", "True", "\n", "\n", "", "", "if", "skip", ":", "\n", "                        ", "print", "(", "transcript", ")", "\n", "continue", "\n", "\n", "", "seq_label", "=", "[", "]", "\n", "for", "char", "in", "transcript", ":", "\n", "                        ", "seq_label", ".", "append", "(", "self", ".", "label_dict", "[", "char", "]", ")", "#.decode('utf-8')", "\n", "", "seq_label", ".", "append", "(", "self", ".", "label_dict", "[", "'EOS'", "]", ")", "\n", "\n", "non_zero_count", "=", "len", "(", "seq_label", ")", "\n", "seq_label", "=", "seq_label", "+", "[", "self", ".", "label_dict", "[", "'EOS'", "]", "]", "*", "(", "self", ".", "max_len", "-", "non_zero_count", ")", "\n", "mask", "=", "[", "1", "]", "*", "(", "non_zero_count", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_len", "-", "non_zero_count", ")", "\n", "\n", "polygon", "=", "np", ".", "array", "(", "polygon", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "polygon", "=", "np", ".", "reshape", "(", "polygon", ",", "(", "-", "1", ",", "2", ")", ")", "\n", "\n", "points_x", "=", "[", "point", "[", "0", "]", "for", "point", "in", "polygon", "]", "\n", "points_y", "=", "[", "point", "[", "1", "]", "for", "point", "in", "polygon", "]", "\n", "bbox", "=", "[", "np", ".", "amin", "(", "points_y", ")", ",", "np", ".", "amin", "(", "points_x", ")", ",", "np", ".", "amax", "(", "points_y", ")", ",", "np", ".", "amax", "(", "points_x", ")", "]", "# ymin, xmin, ymax, xmax", "\n", "bbox", "=", "[", "int", "(", "item", ")", "for", "item", "in", "bbox", "]", "\n", "\n", "bbox_w", ",", "bbox_h", "=", "bbox", "[", "3", "]", "-", "bbox", "[", "1", "]", ",", "bbox", "[", "2", "]", "-", "bbox", "[", "0", "]", "\n", "if", "bbox_w", "<", "8", "or", "bbox_h", "<", "8", ":", "\n", "                        ", "continue", "\n", "\n", "# print(transcript, seq_label, mask, polygon)", "\n", "# img = visualization(img_name, polygon, transcript)", "\n", "# plt.imshow(img)", "\n", "# plt.show()", "\n", "\n", "", "self", ".", "filenames", ".", "append", "(", "img_name", ")", "\n", "self", ".", "labels", ".", "append", "(", "seq_label", ")", "\n", "self", ".", "masks", ".", "append", "(", "mask", ")", "\n", "self", ".", "bboxes", ".", "append", "(", "bbox", ")", "\n", "self", ".", "points", ".", "append", "(", "polygon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.dataset.ART.__init__": [[166, 168], ["dataset.Dataset.__init__"], "methods", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.test.TextRecognition.__init__"], ["def", "__init__", "(", "self", ",", "name", "=", "'art'", ")", ":", "\n", "        ", "super", "(", "ART", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.dataset.ART.load_data": [[169, 238], ["open", "json.load", "os.listdir", "os.path.join", "dataset.preprocess", "seq_label.append", "len", "dataset.ART.filenames.append", "dataset.ART.labels.append", "dataset.ART.masks.append", "dataset.ART.bboxes.append", "dataset.ART.points.append", "len", "seq_label.append", "numpy.amin", "numpy.amin", "numpy.amax", "numpy.amax", "int", "dataset.ART.label_dict.keys"], "methods", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.test.preprocess"], ["", "def", "load_data", "(", "self", ",", "annotation_file", "=", "art_annotation", ")", ":", "\n", "        ", "count", "=", "0", "\n", "with", "open", "(", "annotation_file", ")", "as", "f", ":", "\n", "            ", "json_data", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "self", ".", "data_path", ")", ":", "\n", "                ", "img_name", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "filename", ")", "\n", "#image = cv2.imread(img_name)", "\n", "#image_height, image_width = image.shape[:2]", "\n", "\n", "anno_data", "=", "json_data", "[", "filename", "[", ":", "-", "4", "]", "]", "[", "0", "]", "\n", "# print(len(json_data[filename[:-4]]))", "\n", "illegibility", "=", "anno_data", "[", "'illegibility'", "]", "\n", "\n", "if", "illegibility", ":", "\n", "                    ", "continue", "\n", "\n", "", "polygon", "=", "anno_data", "[", "'points'", "]", "\n", "transcripts", "=", "anno_data", "[", "'transcription'", "]", "\n", "languages", "=", "anno_data", "[", "'language'", "]", "\n", "\n", "if", "len", "(", "transcripts", ")", ">", "self", ".", "max_len", "-", "1", ":", "\n", "# print(transcripts)", "\n", "# count = count + 1", "\n", "                    ", "continue", "\n", "\n", "", "transcripts", "=", "preprocess", "(", "transcripts", ")", "\n", "\n", "skip", "=", "False", "\n", "for", "char", "in", "transcripts", ":", "\n", "                    ", "if", "char", "not", "in", "self", ".", "label_dict", ".", "keys", "(", ")", ":", "\n", "                        ", "skip", "=", "True", "\n", "\n", "", "", "if", "skip", ":", "\n", "# print(transcripts)", "\n", "                    ", "count", "=", "count", "+", "1", "\n", "continue", "\n", "\n", "# print(polygon, transcripts)", "\n", "\n", "", "seq_label", "=", "[", "]", "\n", "for", "char", "in", "transcripts", ":", "\n", "                    ", "seq_label", ".", "append", "(", "self", ".", "label_dict", "[", "char", "]", ")", "#.decode('utf-8')", "\n", "", "seq_label", ".", "append", "(", "self", ".", "label_dict", "[", "'EOS'", "]", ")", "\n", "\n", "non_zero_count", "=", "len", "(", "seq_label", ")", "\n", "seq_label", "=", "seq_label", "+", "[", "self", ".", "label_dict", "[", "'EOS'", "]", "]", "*", "(", "self", ".", "max_len", "-", "non_zero_count", ")", "\n", "mask", "=", "[", "1", "]", "*", "(", "non_zero_count", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_len", "-", "non_zero_count", ")", "\n", "\n", "points_x", "=", "[", "point", "[", "0", "]", "for", "point", "in", "polygon", "]", "\n", "points_y", "=", "[", "point", "[", "1", "]", "for", "point", "in", "polygon", "]", "\n", "bbox", "=", "[", "np", ".", "amin", "(", "points_y", ")", ",", "np", ".", "amin", "(", "points_x", ")", ",", "np", ".", "amax", "(", "points_y", ")", ",", "np", ".", "amax", "(", "points_x", ")", "]", "# ymin, xmin, ymax, xmax", "\n", "bbox", "=", "[", "int", "(", "item", ")", "for", "item", "in", "bbox", "]", "\n", "\n", "bbox_w", ",", "bbox_h", "=", "bbox", "[", "3", "]", "-", "bbox", "[", "1", "]", ",", "bbox", "[", "2", "]", "-", "bbox", "[", "0", "]", "\n", "\n", "if", "bbox_w", "<", "8", "or", "bbox_h", "<", "8", ":", "\n", "                    ", "continue", "\n", "\n", "# print(transcripts, seq_label, mask, polygon)", "\n", "# img = visualization(img_name, polygon, transcripts)", "\n", "# plt.imshow(img)", "\n", "# plt.show()  ", "\n", "\n", "", "self", ".", "filenames", ".", "append", "(", "img_name", ")", "\n", "self", ".", "labels", ".", "append", "(", "seq_label", ")", "\n", "self", ".", "masks", ".", "append", "(", "mask", ")", "\n", "self", ".", "bboxes", ".", "append", "(", "bbox", ")", "\n", "self", ".", "points", ".", "append", "(", "polygon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.dataset.LSVT.__init__": [[245, 247], ["dataset.Dataset.__init__"], "methods", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.test.TextRecognition.__init__"], ["def", "__init__", "(", "self", ",", "name", "=", "'lsvt'", ")", ":", "\n", "        ", "super", "(", "LSVT", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.dataset.LSVT.load_data": [[248, 314], ["open", "json.load", "os.listdir", "os.path.join", "zip", "dataset.preprocess", "seq_label.append", "len", "dataset.LSVT.filenames.append", "dataset.LSVT.labels.append", "dataset.LSVT.masks.append", "dataset.LSVT.bboxes.append", "dataset.LSVT.points.append", "preprocess.strip", "len", "seq_label.append", "numpy.amin", "numpy.amin", "numpy.amax", "numpy.amax", "int", "dataset.LSVT.label_dict.keys"], "methods", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.test.preprocess"], ["", "def", "load_data", "(", "self", ",", "annotation_file", "=", "lsvt_annotation", ")", ":", "\n", "        ", "with", "open", "(", "annotation_file", ")", "as", "f", ":", "\n", "            ", "json_data", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "self", ".", "data_path", ")", ":", "\n", "                ", "img_name", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "filename", ")", "\n", "#image = cv2.imread(img_name)", "\n", "#image_height, image_width = image.shape[:2]", "\n", "\n", "anno_data", "=", "json_data", "[", "filename", "[", ":", "-", "4", "]", "]", "\n", "# print(len(json_data[filename[:-4]]))", "\n", "# print(anno_data)", "\n", "points", "=", "[", "anno", "[", "'points'", "]", "for", "anno", "in", "anno_data", "]", "\n", "transcripts", "=", "[", "anno", "[", "'transcription'", "]", "for", "anno", "in", "anno_data", "]", "\n", "illegibilities", "=", "[", "anno", "[", "'illegibility'", "]", "for", "anno", "in", "anno_data", "]", "\n", "\n", "for", "polygon", ",", "transcript", ",", "illegibility", "in", "zip", "(", "points", ",", "transcripts", ",", "illegibilities", ")", ":", "\n", "                    ", "if", "transcript", "==", "'###'", ":", "\n", "                        ", "continue", "\n", "\n", "", "transcript", "=", "preprocess", "(", "transcript", ".", "strip", "(", ")", ")", "\n", "\n", "\n", "if", "len", "(", "transcript", ")", ">", "self", ".", "max_len", "-", "1", ":", "\n", "# print(transcripts)", "\n", "# count = count + 1", "\n", "                        ", "continue", "\n", "\n", "", "skip", "=", "False", "\n", "for", "char", "in", "transcript", ":", "\n", "                        ", "if", "char", "not", "in", "self", ".", "label_dict", ".", "keys", "(", ")", ":", "\n", "                            ", "skip", "=", "True", "\n", "\n", "", "", "if", "skip", ":", "\n", "                        ", "continue", "\n", "\n", "# print(polygon, transcripts)", "\n", "\n", "", "seq_label", "=", "[", "]", "\n", "for", "char", "in", "transcript", ":", "\n", "                        ", "seq_label", ".", "append", "(", "self", ".", "label_dict", "[", "char", "]", ")", "#.decode('utf-8')", "\n", "", "seq_label", ".", "append", "(", "self", ".", "label_dict", "[", "'EOS'", "]", ")", "\n", "\n", "non_zero_count", "=", "len", "(", "seq_label", ")", "\n", "seq_label", "=", "seq_label", "+", "[", "self", ".", "label_dict", "[", "'EOS'", "]", "]", "*", "(", "self", ".", "max_len", "-", "non_zero_count", ")", "\n", "mask", "=", "[", "1", "]", "*", "(", "non_zero_count", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_len", "-", "non_zero_count", ")", "\n", "\n", "points_x", "=", "[", "point", "[", "0", "]", "for", "point", "in", "polygon", "]", "\n", "points_y", "=", "[", "point", "[", "1", "]", "for", "point", "in", "polygon", "]", "\n", "bbox", "=", "[", "np", ".", "amin", "(", "points_y", ")", ",", "np", ".", "amin", "(", "points_x", ")", ",", "np", ".", "amax", "(", "points_y", ")", ",", "np", ".", "amax", "(", "points_x", ")", "]", "# ymin, xmin, ymax, xmax", "\n", "bbox", "=", "[", "int", "(", "item", ")", "for", "item", "in", "bbox", "]", "\n", "\n", "bbox_w", ",", "bbox_h", "=", "bbox", "[", "3", "]", "-", "bbox", "[", "1", "]", ",", "bbox", "[", "2", "]", "-", "bbox", "[", "0", "]", "\n", "\n", "if", "bbox_w", "<", "8", "or", "bbox_h", "<", "8", ":", "\n", "                        ", "continue", "\n", "\n", "# print(transcript, seq_label, mask, polygon)", "\n", "# img = visualization(img_name, polygon, transcript)", "\n", "# plt.imshow(img)", "\n", "# plt.show()  ", "\n", "", "self", ".", "filenames", ".", "append", "(", "img_name", ")", "\n", "self", ".", "labels", ".", "append", "(", "seq_label", ")", "\n", "self", ".", "masks", ".", "append", "(", "mask", ")", "\n", "self", ".", "bboxes", ".", "append", "(", "bbox", ")", "\n", "self", ".", "points", ".", "append", "(", "polygon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.dataset.ICDAR2017RCTW.__init__": [[320, 323], ["dataset.Dataset.__init__"], "methods", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.test.TextRecognition.__init__"], ["def", "__init__", "(", "self", ",", "name", "=", "'icdar2017rctw'", ")", ":", "\n", "        ", "super", "(", "ICDAR2017RCTW", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "transcripts", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.dataset.ICDAR2017RCTW.load_data": [[324, 383], ["os.listdir", "filename.endswith", "os.path.join", "codecs.open", "f.readlines", "os.path.join", "line.split", "dataset.preprocess", "seq_label.append", "len", "dataset.ICDAR2017RCTW.filenames.append", "dataset.ICDAR2017RCTW.labels.append", "dataset.ICDAR2017RCTW.masks.append", "dataset.ICDAR2017RCTW.bboxes.append", "dataset.ICDAR2017RCTW.points.append", "dataset.ICDAR2017RCTW.transcripts.append", "len", "seq_label.append", "numpy.amin", "numpy.amin", "numpy.amax", "numpy.amax", "dataset.ICDAR2017RCTW.label_dict.keys", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.test.preprocess"], ["", "def", "load_data", "(", "self", ")", ":", "\n", "        ", "for", "filename", "in", "os", ".", "listdir", "(", "self", ".", "data_path", ")", ":", "\n", "            ", "if", "filename", ".", "endswith", "(", "\".jpg\"", ")", ":", "\n", "                ", "img_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "filename", ")", "\n", "with", "codecs", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "filename", "[", ":", "-", "4", "]", "+", "'.txt'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "                    ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "                        ", "res", "=", "line", ".", "split", "(", "\",\"", ",", "10", ")", "\n", "label", "=", "res", "[", "9", "]", "[", "1", ":", "-", "2", "]", "#.decode('utf-8')", "\n", "\n", "if", "label", "==", "'###'", ":", "\n", "                            ", "continue", "\n", "\n", "", "if", "len", "(", "label", ")", ">", "self", ".", "max_len", "-", "1", ":", "\n", "                            ", "continue", "\n", "\n", "", "label", "=", "preprocess", "(", "label", ")", "\n", "\n", "skip", "=", "False", "\n", "for", "char", "in", "label", ":", "\n", "                            ", "if", "char", "not", "in", "self", ".", "label_dict", ".", "keys", "(", ")", ":", "\n", "                                ", "skip", "=", "True", "\n", "#if label[0] not in label_dict.keys():", "\n", "", "", "if", "skip", ":", "\n", "                            ", "continue", "\n", "\n", "", "seq_label", "=", "[", "]", "\n", "for", "char", "in", "label", ":", "\n", "                            ", "seq_label", ".", "append", "(", "self", ".", "label_dict", "[", "char", "]", ")", "#.decode('utf-8')", "\n", "", "seq_label", ".", "append", "(", "self", ".", "label_dict", "[", "'EOS'", "]", ")", "\n", "\n", "non_zero_count", "=", "len", "(", "seq_label", ")", "\n", "seq_label", "=", "seq_label", "+", "[", "self", ".", "label_dict", "[", "'EOS'", "]", "]", "*", "(", "self", ".", "max_len", "-", "non_zero_count", ")", "\n", "mask", "=", "[", "1", "]", "*", "(", "non_zero_count", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_len", "-", "non_zero_count", ")", "\n", "try", ":", "\n", "                            ", "vertex_row_coords", "=", "[", "int", "(", "res", "[", "1", "]", ")", ",", "int", "(", "res", "[", "3", "]", ")", ",", "int", "(", "res", "[", "5", "]", ")", ",", "int", "(", "res", "[", "7", "]", ")", "]", "\n", "vertex_col_coords", "=", "[", "int", "(", "res", "[", "0", "]", ")", ",", "int", "(", "res", "[", "2", "]", ")", ",", "int", "(", "res", "[", "4", "]", ")", ",", "int", "(", "res", "[", "6", "]", ")", "]", "\n", "", "except", ":", "\n", "                            ", "continue", "\n", "\n", "", "bbox", "=", "[", "np", ".", "amin", "(", "vertex_row_coords", ")", ",", "np", ".", "amin", "(", "vertex_col_coords", ")", ",", "np", ".", "amax", "(", "vertex_row_coords", ")", ",", "np", ".", "amax", "(", "vertex_col_coords", ")", "]", "\n", "polygon", "=", "[", "[", "int", "(", "res", "[", "0", "]", ")", ",", "int", "(", "res", "[", "1", "]", ")", "]", ",", "[", "int", "(", "res", "[", "2", "]", ")", ",", "int", "(", "res", "[", "3", "]", ")", "]", ",", "[", "int", "(", "res", "[", "4", "]", ")", ",", "int", "(", "res", "[", "5", "]", ")", "]", ",", "[", "int", "(", "res", "[", "6", "]", ")", ",", "int", "(", "res", "[", "7", "]", ")", "]", "]", "\n", "\n", "#print(bbox[2]-bbox[0], bbox[3]-bbox[1])", "\n", "bbox_w", ",", "bbox_h", "=", "bbox", "[", "3", "]", "-", "bbox", "[", "1", "]", ",", "bbox", "[", "2", "]", "-", "bbox", "[", "0", "]", "\n", "if", "bbox_w", "<", "8", "or", "bbox_h", "<", "8", ":", "\n", "                            ", "continue", "\n", "\n", "# print(polygon, label, seq_label, mask)", "\n", "# image = visualization(img_path, polygon, label)", "\n", "# plt.imshow(image)", "\n", "# plt.show()", "\n", "\n", "", "self", ".", "filenames", ".", "append", "(", "img_path", ")", "\n", "self", ".", "labels", ".", "append", "(", "seq_label", ")", "\n", "self", ".", "masks", ".", "append", "(", "mask", ")", "\n", "self", ".", "bboxes", ".", "append", "(", "bbox", ")", "\n", "self", ".", "points", ".", "append", "(", "polygon", ")", "\n", "self", ".", "transcripts", ".", "append", "(", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.dataset.visualization": [[34, 48], ["numpy.asarray", "numpy.reshape", "cv2.imread", "cv2.polylines", "PIL.Image.fromarray", "PIL.ImageFont.truetype", "PIL.ImageDraw.Draw", "ImageDraw.Draw.text", "numpy.array"], "function", ["None"], ["def", "visualization", "(", "image_path", ",", "points", ",", "label", ",", "vis_color", "=", "(", "255", ",", "255", ",", "255", ")", ")", ":", "\n", "    ", "\"\"\"\n    Visualize groundtruth label to image.\n    \"\"\"", "\n", "points", "=", "np", ".", "asarray", "(", "points", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "points", "=", "np", ".", "reshape", "(", "points", ",", "[", "-", "1", ",", "2", "]", ")", "\n", "image", "=", "cv2", ".", "imread", "(", "image_path", ")", "\n", "cv2", ".", "polylines", "(", "image", ",", "[", "points", "]", ",", "1", ",", "(", "0", ",", "255", ",", "0", ")", ",", "2", ")", "\n", "image", "=", "Image", ".", "fromarray", "(", "image", ")", "\n", "FONT", "=", "ImageFont", ".", "truetype", "(", "font_path", ",", "20", ",", "encoding", "=", "'utf-8'", ")", "\n", "DRAW", "=", "ImageDraw", ".", "Draw", "(", "image", ")", "\n", "\n", "DRAW", ".", "text", "(", "points", "[", "0", "]", ",", "label", ",", "vis_color", ",", "font", "=", "FONT", ")", "\n", "return", "np", ".", "array", "(", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.dataset.strQ2B": [[49, 59], ["ord", "chr"], "function", ["None"], ["", "def", "strQ2B", "(", "uchar", ")", ":", "\n", "    ", "\"\"\"\n    Convert full-width character to half-width character.\n    \"\"\"", "\n", "inside_code", "=", "ord", "(", "uchar", ")", "\n", "if", "inside_code", "==", "12288", ":", "\n", "        ", "inside_code", "=", "32", "\n", "", "elif", "(", "inside_code", ">=", "65281", "and", "inside_code", "<=", "65374", ")", ":", "\n", "        ", "inside_code", "-=", "65248", "\n", "", "return", "chr", "(", "inside_code", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.dataset.preprocess": [[60, 67], ["None"], "function", ["None"], ["", "def", "preprocess", "(", "string", ")", ":", "\n", "    ", "\"\"\"\n    Groundtruth label preprocess function.\n    \"\"\"", "\n", "# string = [strQ2B(ch) for ch in string.strip()]", "\n", "# return ''.join(string)  ", "\n", "return", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.parse_dict.get_dict": [[12, 36], ["os.path.join", "dict", "open", "f.readlines", "re.match", "int", "re.match.group", "re.match.group"], "function", ["None"], ["def", "get_dict", "(", "path", "=", "os", ".", "path", ".", "join", "(", "currentdir", ",", "'label_dict/icdar_labels.txt'", ")", ",", "add_space", "=", "False", ",", "add_eos", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Load text label dict from preprocessed text file.\n    Args:\n        path: label dict text file path.\n        add_space: whether add additional space charater to label dict.\n        add_eos: whether add EOS which represents end of sequence to label dict.\n    Returns:\n        label_dict: text label dict.\n    \"\"\"", "\n", "label_dict", "=", "dict", "(", ")", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "m", "=", "re", ".", "match", "(", "r'(\\d+) (.*)'", ",", "line", ")", "\n", "idx", ",", "label", "=", "int", "(", "m", ".", "group", "(", "1", ")", ")", ",", "m", ".", "group", "(", "2", ")", "\n", "label_dict", "[", "idx", "]", "=", "label", "\n", "", "if", "add_space", ":", "\n", "            ", "idx", "=", "idx", "+", "1", "\n", "label_dict", "[", "idx", "]", "=", "' '", "\n", "", "if", "add_eos", ":", "\n", "            ", "idx", "=", "idx", "+", "1", "\n", "label_dict", "[", "idx", "]", "=", "'EOS'", "\n", "", "", "return", "label_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.TextDataPreprocessor.__init__": [[119, 121], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "self", ".", "cfg", "=", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.TextDataPreprocessor.__call__": [[122, 144], ["cv2.imread", "cv2.cvtColor", "text_dataflow.affine_transform", "numpy.random.randint", "text_dataflow.aspect_preserving_resize", "text_dataflow.padding_image", "aspect_preserving_resize.astype"], "methods", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.affine_transform", "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.aspect_preserving_resize", "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.padding_image"], ["", "def", "__call__", "(", "self", ",", "roidb", ")", ":", "\n", "        ", "filename", ",", "label", ",", "mask", ",", "bbox", ",", "polygon", "=", "roidb", "[", "'filename'", "]", ",", "roidb", "[", "'label'", "]", ",", "roidb", "[", "'mask'", "]", ",", "roidb", "[", "'bbox'", "]", ",", "roidb", "[", "'polygon'", "]", ",", "\n", "img", "=", "cv2", ".", "imread", "(", "filename", ")", "\n", "img", "=", "cv2", ".", "cvtColor", "(", "img", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "\n", "image", "=", "affine_transform", "(", "img", ",", "polygon", ")", "\n", "# img = img[bbox[0]:bbox[2], bbox[1]:bbox[3], :] if image.shape[0]<cfg.stride/2 or image.shape[1]<cfg.stride/2 else image", "\n", "img", "=", "img", "if", "image", ".", "shape", "[", "0", "]", "<", "cfg", ".", "stride", "/", "2", "or", "image", ".", "shape", "[", "1", "]", "<", "cfg", ".", "stride", "/", "2", "else", "image", "\n", "\n", "largest_side", "=", "np", ".", "random", ".", "randint", "(", "cfg", ".", "crop_min_size", ",", "cfg", ".", "image_size", ")", "\n", "img", "=", "aspect_preserving_resize", "(", "img", ",", "largest_side", ")", "\n", "\n", "img", ",", "crop_bbox", "=", "padding_image", "(", "img", ",", "cfg", ".", "image_size", ")", "\n", "\n", "normalized_bbox", "=", "[", "coord", "/", "cfg", ".", "image_size", "for", "coord", "in", "crop_bbox", "]", "\n", "\n", "img", "=", "img", ".", "astype", "(", "\"float32\"", ")", "/", "255.", "\n", "\n", "\n", "ret", "=", "{", "\"image\"", ":", "img", ",", "\"label\"", ":", "label", ",", "\"mask\"", ":", "mask", ",", "\"normalized_bbox\"", ":", "normalized_bbox", ",", "\"is_training\"", ":", "True", ",", "\"dropout_keep_prob\"", ":", "0.5", "}", "\n", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.largest_size_at_most": [[26, 35], ["min"], "function", ["None"], ["def", "largest_size_at_most", "(", "height", ",", "width", ",", "largest_side", ",", "max_scale", ")", ":", "\n", "    ", "\"\"\"\n    Compute resized image size with limited max scale. \n    \"\"\"", "\n", "scale", "=", "largest_side", "/", "height", "if", "height", ">", "width", "else", "largest_side", "/", "width", "\n", "scale", "=", "min", "(", "scale", ",", "max_scale", ")", "\n", "\n", "new_height", ",", "new_width", "=", "height", "*", "scale", ",", "width", "*", "scale", "\n", "return", "new_height", ",", "new_width", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.aspect_preserving_resize": [[36, 48], ["text_dataflow.largest_size_at_most", "max", "max", "cv2.resize", "int", "int"], "function", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.largest_size_at_most"], ["", "def", "aspect_preserving_resize", "(", "image", ",", "largest_side", ",", "max_scale", "=", "4.", ")", ":", "\n", "    ", "\"\"\"\n    Resize image with perserved aspect and limited max scale.\n    \"\"\"", "\n", "height", ",", "width", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "new_height", ",", "new_width", "=", "largest_size_at_most", "(", "height", ",", "width", ",", "largest_side", ",", "max_scale", ")", "\n", "\n", "new_height", "=", "max", "(", "new_height", ",", "cfg", ".", "stride", ")", "\n", "new_width", "=", "max", "(", "new_width", ",", "cfg", ".", "stride", ")", "\n", "resized_image", "=", "cv2", ".", "resize", "(", "image", ",", "(", "int", "(", "new_width", ")", ",", "int", "(", "new_height", ")", ")", ")", "\n", "\n", "return", "resized_image", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.padding_image": [[49, 64], ["numpy.random.randint", "numpy.random.randint", "cv2.copyMakeBorder", "config.cfg.image_size", "config.cfg.image_size"], "function", ["None"], ["", "def", "padding_image", "(", "image", ",", "padding_size", ")", ":", "\n", "    ", "\"\"\"\n    Padding arbitrary-shaped text image to square for tensorflow batch training.\n    \"\"\"", "\n", "height", ",", "width", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "padding_h", "=", "padding_size", "-", "height", "\n", "padding_w", "=", "padding_size", "-", "width", "\n", "\n", "padding_top", "=", "np", ".", "random", ".", "randint", "(", "padding_h", ")", "\n", "padding_left", "=", "np", ".", "random", ".", "randint", "(", "padding_w", ")", "\n", "padding_down", "=", "padding_h", "-", "padding_top", "\n", "padding_right", "=", "padding_w", "-", "padding_left", "\n", "\n", "padding_img", "=", "cv2", ".", "copyMakeBorder", "(", "image", ",", "padding_top", ",", "padding_down", ",", "padding_left", ",", "padding_right", ",", "borderType", "=", "cv2", ".", "BORDER_CONSTANT", ",", "value", "=", "[", "0", ",", "0", ",", "0", "]", ")", "\n", "return", "padding_img", ",", "(", "padding_top", ",", "padding_left", ",", "height", ",", "width", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.rotatedPoint": [[66, 73], ["int", "int"], "function", ["None"], ["", "def", "rotatedPoint", "(", "R", ",", "point", ")", ":", "\n", "    ", "\"\"\"\n    Transform polygon with affine transform matrix.\n    \"\"\"", "\n", "x", "=", "R", "[", "0", ",", "0", "]", "*", "point", "[", "0", "]", "+", "R", "[", "0", ",", "1", "]", "*", "point", "[", "1", "]", "+", "R", "[", "0", ",", "2", "]", "\n", "y", "=", "R", "[", "1", ",", "0", "]", "*", "point", "[", "0", "]", "+", "R", "[", "1", ",", "1", "]", "*", "point", "[", "1", "]", "+", "R", "[", "1", ",", "2", "]", "\n", "return", "[", "int", "(", "x", ")", ",", "int", "(", "y", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.affine_transform": [[75, 113], ["math.radians", "numpy.abs", "numpy.abs", "int", "int", "numpy.array", "cv2.warpAffine", "common.polygons_to_mask", "cv2.boundingRect", "numpy.expand_dims", "numpy.random.uniform", "math.sin", "math.cos", "abs", "abs", "text_dataflow.rotatedPoint", "numpy.float32", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform", "numpy.array"], "function", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.common.polygons_to_mask", "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.rotatedPoint"], ["", "def", "affine_transform", "(", "image", ",", "polygon", ")", ":", "\n", "    ", "\"\"\"\n    Conduct same affine transform for both image and polygon for data augmentation.\n    \"\"\"", "\n", "height", ",", "width", ",", "_", "=", "image", ".", "shape", "\n", "center_x", ",", "center_y", "=", "width", "/", "2", ",", "height", "/", "2", "\n", "\n", "angle", "=", "0", "if", "np", ".", "random", ".", "uniform", "(", ")", ">", "0.5", "else", "np", ".", "random", ".", "uniform", "(", "-", "20.", ",", "20.", ")", "\n", "shear_x", ",", "shear_y", "=", "(", "0", ",", "0", ")", "if", "np", ".", "random", ".", "uniform", "(", ")", ">", "0.5", "else", "(", "np", ".", "random", ".", "uniform", "(", "-", "0.2", ",", "0.2", ")", ",", "np", ".", "random", ".", "uniform", "(", "-", "0.2", ",", "0.2", ")", ")", "\n", "\n", "rad", "=", "math", ".", "radians", "(", "angle", ")", "\n", "sin", ",", "cos", "=", "math", ".", "sin", "(", "rad", ")", ",", "math", ".", "cos", "(", "rad", ")", "# x, y", "\n", "abs_sin", ",", "abs_cos", "=", "abs", "(", "sin", ")", ",", "abs", "(", "cos", ")", "\n", "\n", "new_width", "=", "(", "(", "height", "*", "abs_sin", ")", "+", "(", "width", "*", "abs_cos", ")", ")", "\n", "new_height", "=", "(", "(", "height", "*", "abs_cos", ")", "+", "(", "width", "*", "abs_sin", ")", ")", "\n", "\n", "new_width", "+=", "np", ".", "abs", "(", "shear_y", "*", "new_height", ")", "\n", "new_height", "+=", "np", ".", "abs", "(", "shear_x", "*", "new_width", ")", "\n", "\n", "new_width", "=", "int", "(", "new_width", ")", "\n", "new_height", "=", "int", "(", "new_height", ")", "\n", "\n", "M", "=", "np", ".", "array", "(", "[", "[", "cos", ",", "sin", "+", "shear_y", ",", "new_width", "/", "2", "-", "center_x", "+", "(", "1", "-", "cos", ")", "*", "center_x", "-", "(", "sin", "+", "shear_y", ")", "*", "center_y", "]", ",", "\n", "[", "-", "sin", "+", "shear_x", ",", "cos", ",", "new_height", "/", "2", "-", "center_y", "+", "(", "sin", "-", "shear_x", ")", "*", "center_x", "+", "(", "1", "-", "cos", ")", "*", "center_y", "]", "]", ")", "\n", "\n", "rotatedImage", "=", "cv2", ".", "warpAffine", "(", "image", ",", "M", ",", "(", "new_width", ",", "new_height", ")", ",", "flags", "=", "cv2", ".", "INTER_CUBIC", ",", "borderMode", "=", "cv2", ".", "BORDER_CONSTANT", ",", "borderValue", "=", "(", "0", ",", "0", ",", "0", ")", ")", "\n", "\n", "height", ",", "width", "=", "rotatedImage", ".", "shape", "[", ":", "2", "]", "\n", "rotatedPoints", "=", "[", "rotatedPoint", "(", "M", ",", "point", ")", "for", "point", "in", "polygon", "]", "\n", "mask", "=", "polygons_to_mask", "(", "[", "np", ".", "array", "(", "rotatedPoints", ",", "np", ".", "float32", ")", "]", ",", "new_height", ",", "new_width", ")", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "cv2", ".", "boundingRect", "(", "mask", ")", "\n", "mask", "=", "np", ".", "expand_dims", "(", "np", ".", "float32", "(", "mask", ")", ",", "axis", "=", "-", "1", ")", "\n", "rotatedImage", "=", "rotatedImage", "*", "mask", "\n", "\n", "cropImage", "=", "rotatedImage", "[", "y", ":", "y", "+", "h", ",", "x", ":", "x", "+", "w", ",", ":", "]", "\n", "\n", "return", "cropImage", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.get_train_dataflow": [[145, 160], ["tensorpack.dataflow.DataFromList", "text_dataflow.TextDataPreprocessor", "tensorpack.dataflow.MultiThreadMapData", "tensorpack.dataflow.PrefetchData", "multiprocessing.cpu_count"], "function", ["None"], ["", "", "def", "get_train_dataflow", "(", "roidb", ")", ":", "\n", "    ", "\"\"\"\n    Tensorpack text dataflow.\n    \"\"\"", "\n", "ds", "=", "DataFromList", "(", "roidb", ",", "shuffle", "=", "True", ")", "\n", "preprocess", "=", "TextDataPreprocessor", "(", "cfg", ")", "\n", "\n", "buffer_size", "=", "cfg", ".", "num_threads", "*", "10", "\n", "ds", "=", "MultiThreadMapData", "(", "ds", ",", "cfg", ".", "num_threads", ",", "preprocess", ",", "buffer_size", "=", "buffer_size", ")", "\n", "# ds = MultiProcessMapData(ds, cfg.num_workers, preprocess, buffer_size=buffer_size)", "\n", "ds", "=", "PrefetchData", "(", "ds", ",", "100", ",", "multiprocessing", ".", "cpu_count", "(", ")", "//", "4", ")", "\n", "\n", "#ds = BatchData(ds, cfg.batch_size, remainder=True)", "\n", "\n", "return", "ds", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.get_roidb": [[161, 173], ["zip", "numpy.load", "roidb.append"], "function", ["None"], ["", "def", "get_roidb", "(", "dataset_name", ")", ":", "\n", "    ", "\"\"\"\n    Load generated numpy dataset for tensorpack dataflow.\n    \"\"\"", "\n", "dataset", "=", "np", ".", "load", "(", "dataset_name", ")", "[", "(", ")", "]", "\n", "filenames", ",", "labels", ",", "masks", ",", "bboxes", ",", "points", "=", "dataset", "[", "\"filenames\"", "]", ",", "dataset", "[", "\"labels\"", "]", ",", "dataset", "[", "\"masks\"", "]", ",", "dataset", "[", "\"bboxes\"", "]", ",", "dataset", "[", "\"points\"", "]", "\n", "\n", "roidb", "=", "[", "]", "\n", "for", "filename", ",", "label", ",", "mask", ",", "bbox", ",", "polygon", "in", "zip", "(", "filenames", ",", "labels", ",", "masks", ",", "bboxes", ",", "points", ")", ":", "\n", "        ", "item", "=", "{", "\"filename\"", ":", "filename", ",", "\"label\"", ":", "label", ",", "\"mask\"", ":", "mask", ",", "\"bbox\"", ":", "bbox", ",", "\"polygon\"", ":", "polygon", "}", "\n", "roidb", ".", "append", "(", "item", ")", "\n", "", "return", "roidb", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.get_batch_train_dataflow": [[176, 226], ["enumerate", "tensorpack.dataflow.DataFromList", "tensorpack.dataflow.MultiThreadMapData", "batch.append", "cv2.imread", "cv2.cvtColor", "text_dataflow.affine_transform", "numpy.random.randint", "text_dataflow.aspect_preserving_resize", "text_dataflow.padding_image", "datapoint_list.append", "numpy.stack", "len", "batched_roidbs.append", "aspect_preserving_resize.astype"], "function", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.affine_transform", "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.aspect_preserving_resize", "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.text_dataflow.padding_image"], ["", "def", "get_batch_train_dataflow", "(", "roidbs", ",", "batch_size", ")", ":", "\n", "    ", "\"\"\"\n    Tensorpack batch text dataflow.\n    \"\"\"", "\n", "batched_roidbs", "=", "[", "]", "\n", "\n", "batch", "=", "[", "]", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "roidbs", ")", ":", "\n", "        ", "if", "i", "%", "batch_size", "==", "0", ":", "\n", "            ", "if", "len", "(", "batch", ")", "==", "batch_size", ":", "\n", "                ", "batched_roidbs", ".", "append", "(", "batch", ")", "\n", "", "batch", "=", "[", "]", "\n", "", "batch", ".", "append", "(", "d", ")", "\n", "\n", "", "def", "preprocess", "(", "roidb_batch", ")", ":", "\n", "        ", "\"\"\"\n        Tensorpack batch text data preprocess function.\n        \"\"\"", "\n", "datapoint_list", "=", "[", "]", "\n", "for", "roidb", "in", "roidb_batch", ":", "\n", "            ", "filename", ",", "label", ",", "mask", ",", "bbox", ",", "polygon", "=", "roidb", "[", "'filename'", "]", ",", "roidb", "[", "'label'", "]", ",", "roidb", "[", "'mask'", "]", ",", "roidb", "[", "'bbox'", "]", ",", "roidb", "[", "'polygon'", "]", "\n", "img", "=", "cv2", ".", "imread", "(", "filename", ")", "\n", "img", "=", "cv2", ".", "cvtColor", "(", "img", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "\n", "\n", "image", "=", "affine_transform", "(", "img", ",", "polygon", ")", "\n", "# img = img[bbox[0]:bbox[2], bbox[1]:bbox[3], :] if image.shape[0]<cfg.stride/2 or image.shape[1]<cfg.stride/2 else image", "\n", "img", "=", "img", "if", "image", ".", "shape", "[", "0", "]", "<", "cfg", ".", "stride", "/", "2", "or", "image", ".", "shape", "[", "1", "]", "<", "cfg", ".", "stride", "/", "2", "else", "image", "\n", "\n", "largest_side", "=", "np", ".", "random", ".", "randint", "(", "cfg", ".", "crop_min_size", ",", "cfg", ".", "image_size", ")", "\n", "img", "=", "aspect_preserving_resize", "(", "img", ",", "largest_side", ")", "\n", "\n", "img", ",", "crop_bbox", "=", "padding_image", "(", "img", ",", "cfg", ".", "image_size", ")", "\n", "\n", "normalized_bbox", "=", "[", "coord", "/", "cfg", ".", "image_size", "for", "coord", "in", "crop_bbox", "]", "\n", "\n", "img", "=", "img", ".", "astype", "(", "\"float32\"", ")", "/", "255.", "\n", "\n", "ret", "=", "{", "\"image\"", ":", "img", ",", "\"label\"", ":", "label", ",", "\"mask\"", ":", "mask", ",", "\"normalized_bbox\"", ":", "normalized_bbox", "}", "\n", "datapoint_list", ".", "append", "(", "ret", ")", "\n", "\n", "", "batched_datapoint", "=", "{", "\"is_training\"", ":", "True", ",", "\"dropout_keep_prob\"", ":", "0.5", "}", "\n", "for", "stackable_field", "in", "[", "\"image\"", ",", "\"label\"", ",", "\"mask\"", ",", "\"normalized_bbox\"", "]", ":", "\n", "            ", "batched_datapoint", "[", "stackable_field", "]", "=", "np", ".", "stack", "(", "[", "d", "[", "stackable_field", "]", "for", "d", "in", "datapoint_list", "]", ")", "\n", "", "return", "batched_datapoint", "\n", "\n", "", "ds", "=", "DataFromList", "(", "batched_roidbs", ",", "shuffle", "=", "True", ")", "\n", "ds", "=", "MultiThreadMapData", "(", "ds", ",", "cfg", ".", "num_threads", ",", "preprocess", ")", "\n", "# ds = PrefetchData(ds, 100, multiprocessing.cpu_count() // 4)", "\n", "return", "ds", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.export.export": [[13, 22], ["model.tensorpack_model.AttentionOCR", "tensorpack.predict.PredictConfig", "tensorpack.tfutils.export.ModelExporter().export_compact", "tensorpack.tfutils.SmartInit", "tensorpack.tfutils.export.ModelExporter", "model.tensorpack_model.AttentionOCR.get_inferene_tensor_names", "model.tensorpack_model.AttentionOCR.get_inferene_tensor_names"], "function", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.tensorpack_model.AttentionOCR.get_inferene_tensor_names", "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.tensorpack_model.AttentionOCR.get_inferene_tensor_names"], ["def", "export", "(", "args", ")", ":", "\n", "    ", "model", "=", "AttentionOCR", "(", ")", "\n", "predcfg", "=", "PredictConfig", "(", "\n", "model", "=", "model", ",", "\n", "session_init", "=", "SmartInit", "(", "args", ".", "checkpoint_path", ")", ",", "\n", "input_names", "=", "model", ".", "get_inferene_tensor_names", "(", ")", "[", "0", "]", ",", "\n", "output_names", "=", "model", ".", "get_inferene_tensor_names", "(", ")", "[", "1", "]", ")", "\n", "\n", "ModelExporter", "(", "predcfg", ")", ".", "export_compact", "(", "args", ".", "pb_path", ",", "optimize", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.test.TextRecognition.__init__": [[20, 24], ["test.TextRecognition.init_model"], "methods", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.test.TextRecognition.init_model"], ["def", "__init__", "(", "self", ",", "pb_file", ",", "seq_len", ")", ":", "\n", "        ", "self", ".", "pb_file", "=", "pb_file", "\n", "self", ".", "seq_len", "=", "seq_len", "\n", "self", ".", "init_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.test.TextRecognition.init_model": [[25, 42], ["tensorflow.Graph", "tensorflow.Session", "test.TextRecognition.sess.graph.get_tensor_by_name", "test.TextRecognition.sess.graph.get_tensor_by_name", "test.TextRecognition.sess.graph.get_tensor_by_name", "test.TextRecognition.sess.graph.get_tensor_by_name", "test.TextRecognition.sess.graph.get_tensor_by_name", "test.TextRecognition.sess.graph.get_tensor_by_name", "test.TextRecognition.graph.as_default", "tensorflow.gfile.FastGFile", "tensorflow.GraphDef", "tensorflow.GraphDef.ParseFromString", "tensorflow.import_graph_def", "f.read"], "methods", ["None"], ["", "def", "init_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "graph", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "            ", "with", "tf", ".", "gfile", ".", "FastGFile", "(", "self", ".", "pb_file", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "graph_def", "=", "tf", ".", "GraphDef", "(", ")", "\n", "graph_def", ".", "ParseFromString", "(", "f", ".", "read", "(", ")", ")", "\n", "_", "=", "tf", ".", "import_graph_def", "(", "graph_def", ",", "name", "=", "''", ")", "\n", "\n", "\n", "", "", "self", ".", "sess", "=", "tf", ".", "Session", "(", "graph", "=", "self", ".", "graph", ")", "\n", "\n", "self", ".", "img_ph", "=", "self", ".", "sess", ".", "graph", ".", "get_tensor_by_name", "(", "'image:0'", ")", "\n", "self", ".", "label_ph", "=", "self", ".", "sess", ".", "graph", ".", "get_tensor_by_name", "(", "'label:0'", ")", "\n", "self", ".", "is_training", "=", "self", ".", "sess", ".", "graph", ".", "get_tensor_by_name", "(", "'is_training:0'", ")", "\n", "self", ".", "dropout", "=", "self", ".", "sess", ".", "graph", ".", "get_tensor_by_name", "(", "'dropout_keep_prob:0'", ")", "\n", "self", ".", "preds", "=", "self", ".", "sess", ".", "graph", ".", "get_tensor_by_name", "(", "'sequence_preds:0'", ")", "\n", "self", ".", "probs", "=", "self", ".", "sess", ".", "graph", ".", "get_tensor_by_name", "(", "'sequence_probs:0'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.test.TextRecognition.predict": [[43, 57], ["test.TextRecognition.sess.run", "results.append", "min", "numpy.ones", "len", "config.cfg.label_dict"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "image", ",", "label_dict", ",", "EOS", "=", "'EOS'", ")", ":", "\n", "        ", "results", "=", "[", "]", "\n", "probabilities", "=", "[", "]", "\n", "\n", "pred_sentences", ",", "pred_probs", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "preds", ",", "self", ".", "probs", "]", ",", "feed_dict", "=", "{", "self", ".", "is_training", ":", "False", ",", "self", ".", "dropout", ":", "1.0", ",", "self", ".", "img_ph", ":", "image", ",", "self", ".", "label_ph", ":", "np", ".", "ones", "(", "(", "1", ",", "self", ".", "seq_len", ")", ",", "np", ".", "int32", ")", "}", ")", "\n", "\n", "for", "char", "in", "pred_sentences", "[", "0", "]", ":", "\n", "            ", "if", "label_dict", "[", "char", "]", "==", "EOS", ":", "\n", "                ", "break", "\n", "", "results", ".", "append", "(", "label_dict", "[", "char", "]", ")", "\n", "", "probabilities", "=", "pred_probs", "[", "0", "]", "[", ":", "min", "(", "len", "(", "results", ")", "+", "1", ",", "self", ".", "seq_len", ")", "]", "\n", "\n", "return", "results", ",", "probabilities", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.test.preprocess": [[58, 89], ["common.polygons_to_mask", "cv2.boundingRect", "numpy.expand_dims", "cv2.resize", "cv2.copyMakeBorder", "numpy.float32", "numpy.asarray", "int", "int", "config.cfg.image_size"], "function", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.common.polygons_to_mask"], ["", "", "def", "preprocess", "(", "image", ",", "points", ",", "size", "=", "cfg", ".", "image_size", ")", ":", "\n", "    ", "\"\"\"\n    Preprocess for test.\n    Args:\n        image: test image\n        points: text polygon\n        size: test image size\n    \"\"\"", "\n", "height", ",", "width", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "mask", "=", "polygons_to_mask", "(", "[", "np", ".", "asarray", "(", "points", ",", "np", ".", "float32", ")", "]", ",", "height", ",", "width", ")", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "cv2", ".", "boundingRect", "(", "mask", ")", "\n", "mask", "=", "np", ".", "expand_dims", "(", "np", ".", "float32", "(", "mask", ")", ",", "axis", "=", "-", "1", ")", "\n", "image", "=", "image", "*", "mask", "\n", "image", "=", "image", "[", "y", ":", "y", "+", "h", ",", "x", ":", "x", "+", "w", ",", ":", "]", "\n", "\n", "new_height", ",", "new_width", "=", "(", "size", ",", "int", "(", "w", "*", "size", "/", "h", ")", ")", "if", "h", ">", "w", "else", "(", "int", "(", "h", "*", "size", "/", "w", ")", ",", "size", ")", "\n", "image", "=", "cv2", ".", "resize", "(", "image", ",", "(", "new_width", ",", "new_height", ")", ")", "\n", "\n", "if", "new_height", ">", "new_width", ":", "\n", "        ", "padding_top", ",", "padding_down", "=", "0", ",", "0", "\n", "padding_left", "=", "(", "size", "-", "new_width", ")", "//", "2", "\n", "padding_right", "=", "size", "-", "padding_left", "-", "new_width", "\n", "", "else", ":", "\n", "        ", "padding_left", ",", "padding_right", "=", "0", ",", "0", "\n", "padding_top", "=", "(", "size", "-", "new_height", ")", "//", "2", "\n", "padding_down", "=", "size", "-", "padding_top", "-", "new_height", "\n", "\n", "", "image", "=", "cv2", ".", "copyMakeBorder", "(", "image", ",", "padding_top", ",", "padding_down", ",", "padding_left", ",", "padding_right", ",", "borderType", "=", "cv2", ".", "BORDER_CONSTANT", ",", "value", "=", "[", "0", ",", "0", ",", "0", "]", ")", "\n", "\n", "image", "=", "image", "/", "255.", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.test.test": [[90, 112], ["test.TextRecognition", "os.listdir", "os.path.join", "cv2.imread", "cv2.cvtColor", "test.preprocess", "numpy.expand_dims", "time.time", "test.TextRecognition.predict", "time.time", "print", "matplotlib.pyplot.imshow", "matplotlib.pyplot.show"], "function", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.test.preprocess", "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.None.test.TextRecognition.predict"], ["", "def", "test", "(", "args", ")", ":", "\n", "    ", "model", "=", "TextRecognition", "(", "args", ".", "pb_path", ",", "cfg", ".", "seq_len", "+", "1", ")", "\n", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "args", ".", "img_folder", ")", ":", "\n", "        ", "img_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "img_folder", ",", "filename", ")", "\n", "image", "=", "cv2", ".", "imread", "(", "img_path", ")", "\n", "image", "=", "cv2", ".", "cvtColor", "(", "image", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "height", ",", "width", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "\n", "points", "=", "[", "[", "0", ",", "0", "]", ",", "[", "width", "-", "1", ",", "0", "]", ",", "[", "width", "-", "1", ",", "height", "-", "1", "]", ",", "[", "0", ",", "height", "-", "1", "]", "]", "\n", "\n", "image", "=", "preprocess", "(", "image", ",", "points", ",", "cfg", ".", "image_size", ")", "\n", "image", "=", "np", ".", "expand_dims", "(", "image", ",", "0", ")", "\n", "\n", "before", "=", "time", ".", "time", "(", ")", "\n", "preds", ",", "probs", "=", "model", ".", "predict", "(", "image", ",", "cfg", ".", "label_dict", ")", "\n", "after", "=", "time", ".", "time", "(", ")", "\n", "\n", "print", "(", "preds", ",", "probs", ")", "\n", "\n", "plt", ".", "imshow", "(", "image", "[", "0", ",", ":", ",", ":", ",", ":", "]", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.inception_v4.inception_arg_scope": [[15, 66], ["slim.arg_scope", "slim.arg_scope", "slim.l2_regularizer", "slim.variance_scaling_initializer"], "function", ["None"], ["def", "inception_arg_scope", "(", "weight_decay", "=", "0.00004", ",", "\n", "use_batch_norm", "=", "True", ",", "\n", "batch_norm_decay", "=", "0.9997", ",", "\n", "batch_norm_epsilon", "=", "0.001", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "batch_norm_updates_collections", "=", "tf", ".", "compat", ".", "v1", ".", "GraphKeys", ".", "UPDATE_OPS", ",", "\n", "batch_norm_scale", "=", "False", ")", ":", "\n", "    ", "\"\"\"Defines the default arg scope for inception models.\n\n    Args:\n      weight_decay: The weight decay to use for regularizing the model.\n      use_batch_norm: \"If `True`, batch_norm is applied after each convolution.\n      batch_norm_decay: Decay for batch norm moving average.\n      batch_norm_epsilon: Small float added to variance to avoid dividing by zero\n        in batch norm.\n      activation_fn: Activation function for conv2d.\n      batch_norm_updates_collections: Collection for the update ops for\n        batch norm.\n      batch_norm_scale: If True, uses an explicit `gamma` multiplier to scale the\n        activations in the batch normalization layer.\n\n    Returns:\n      An `arg_scope` to use for the inception models.\n    \"\"\"", "\n", "batch_norm_params", "=", "{", "\n", "# Decay for the moving averages.", "\n", "'decay'", ":", "batch_norm_decay", ",", "\n", "# epsilon to prevent 0s in variance.", "\n", "'epsilon'", ":", "batch_norm_epsilon", ",", "\n", "# collection containing update_ops.", "\n", "'updates_collections'", ":", "batch_norm_updates_collections", ",", "\n", "# use fused batch norm if possible.", "\n", "'fused'", ":", "None", ",", "\n", "'scale'", ":", "batch_norm_scale", ",", "\n", "}", "\n", "if", "use_batch_norm", ":", "\n", "        ", "normalizer_fn", "=", "slim", ".", "batch_norm", "\n", "normalizer_params", "=", "batch_norm_params", "\n", "", "else", ":", "\n", "        ", "normalizer_fn", "=", "None", "\n", "normalizer_params", "=", "{", "}", "\n", "# Set weight_decay for weights in Conv and FC layers.", "\n", "", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", "]", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "weight_decay", ")", ")", ":", "\n", "        ", "with", "slim", ".", "arg_scope", "(", "\n", "[", "slim", ".", "conv2d", "]", ",", "\n", "weights_initializer", "=", "slim", ".", "variance_scaling_initializer", "(", ")", ",", "\n", "activation_fn", "=", "activation_fn", ",", "\n", "normalizer_fn", "=", "normalizer_fn", ",", "\n", "normalizer_params", "=", "normalizer_params", ")", "as", "sc", ":", "\n", "            ", "return", "sc", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.inception_v4.block_inception_a": [[68, 87], ["slim.arg_scope", "tensorflow.compat.v1.variable_scope", "tensorflow.concat", "tensorflow.compat.v1.variable_scope", "slim.conv2d", "tensorflow.compat.v1.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.compat.v1.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.compat.v1.variable_scope", "slim.avg_pool2d", "slim.conv2d"], "function", ["None"], ["", "", "", "def", "block_inception_a", "(", "inputs", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "\"\"\"Builds Inception-A block for Inception v4 network.\"\"\"", "\n", "# By default use stride=1 and SAME padding", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "avg_pool2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "scope", ",", "'BlockInceptionA'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "                ", "branch_0", "=", "slim", ".", "conv2d", "(", "inputs", ",", "96", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "                ", "branch_1", "=", "slim", ".", "conv2d", "(", "inputs", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "96", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "                ", "branch_2", "=", "slim", ".", "conv2d", "(", "inputs", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "96", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "96", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0c_3x3'", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "                ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "inputs", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "96", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "return", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.inception_v4.block_reduction_a": [[89, 107], ["slim.arg_scope", "tensorflow.compat.v1.variable_scope", "tensorflow.concat", "tensorflow.compat.v1.variable_scope", "slim.conv2d", "tensorflow.compat.v1.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.compat.v1.variable_scope", "slim.max_pool2d"], "function", ["None"], ["", "", "", "def", "block_reduction_a", "(", "inputs", ",", "stride", "=", "2", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "\"\"\"Builds Reduction-A block for Inception v4 network.\"\"\"", "\n", "# By default use stride=1 and SAME padding", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "avg_pool2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "scope", ",", "'BlockReductionA'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "                ", "branch_0", "=", "slim", ".", "conv2d", "(", "inputs", ",", "384", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "stride", ",", "padding", "=", "'SAME'", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "                ", "branch_1", "=", "slim", ".", "conv2d", "(", "inputs", ",", "192", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "224", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "256", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "'SAME'", ",", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "                ", "branch_2", "=", "slim", ".", "max_pool2d", "(", "inputs", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "stride", ",", "padding", "=", "'SAME'", ",", "\n", "scope", "=", "'MaxPool_1a_3x3'", ")", "\n", "", "return", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.inception_v4.block_inception_b": [[109, 131], ["slim.arg_scope", "tensorflow.compat.v1.variable_scope", "tensorflow.concat", "tensorflow.compat.v1.variable_scope", "slim.conv2d", "tensorflow.compat.v1.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.compat.v1.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.compat.v1.variable_scope", "slim.avg_pool2d", "slim.conv2d"], "function", ["None"], ["", "", "", "def", "block_inception_b", "(", "inputs", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "\"\"\"Builds Inception-B block for Inception v4 network.\"\"\"", "\n", "# By default use stride=1 and SAME padding", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "avg_pool2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "scope", ",", "'BlockInceptionB'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "                ", "branch_0", "=", "slim", ".", "conv2d", "(", "inputs", ",", "384", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "                ", "branch_1", "=", "slim", ".", "conv2d", "(", "inputs", ",", "192", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "224", ",", "[", "1", ",", "7", "]", ",", "scope", "=", "'Conv2d_0b_1x7'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "256", ",", "[", "7", ",", "1", "]", ",", "scope", "=", "'Conv2d_0c_7x1'", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "                ", "branch_2", "=", "slim", ".", "conv2d", "(", "inputs", ",", "192", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "192", ",", "[", "7", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_7x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "224", ",", "[", "1", ",", "7", "]", ",", "scope", "=", "'Conv2d_0c_1x7'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "224", ",", "[", "7", ",", "1", "]", ",", "scope", "=", "'Conv2d_0d_7x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "256", ",", "[", "1", ",", "7", "]", ",", "scope", "=", "'Conv2d_0e_1x7'", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "                ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "inputs", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "128", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "return", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.inception_v4.block_reduction_b": [[133, 153], ["slim.arg_scope", "tensorflow.compat.v1.variable_scope", "tensorflow.concat", "tensorflow.compat.v1.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.compat.v1.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.compat.v1.variable_scope", "slim.max_pool2d"], "function", ["None"], ["", "", "", "def", "block_reduction_b", "(", "inputs", ",", "stride", "=", "2", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "\"\"\"Builds Reduction-B block for Inception v4 network.\"\"\"", "\n", "# By default use stride=1 and SAME padding", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "avg_pool2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "scope", ",", "'BlockReductionB'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "                ", "branch_0", "=", "slim", ".", "conv2d", "(", "inputs", ",", "192", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_0", "=", "slim", ".", "conv2d", "(", "branch_0", ",", "192", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "'SAME'", ",", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "                ", "branch_1", "=", "slim", ".", "conv2d", "(", "inputs", ",", "256", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "256", ",", "[", "1", ",", "7", "]", ",", "scope", "=", "'Conv2d_0b_1x7'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "320", ",", "[", "7", ",", "1", "]", ",", "scope", "=", "'Conv2d_0c_7x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "320", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "'SAME'", ",", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "                ", "branch_2", "=", "slim", ".", "max_pool2d", "(", "inputs", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "stride", ",", "padding", "=", "'SAME'", ",", "\n", "scope", "=", "'MaxPool_1a_3x3'", ")", "\n", "", "return", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.inception_v4.block_inception_c": [[155, 179], ["slim.arg_scope", "tensorflow.compat.v1.variable_scope", "tensorflow.concat", "tensorflow.compat.v1.variable_scope", "slim.conv2d", "tensorflow.compat.v1.variable_scope", "slim.conv2d", "tensorflow.concat", "tensorflow.compat.v1.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.concat", "tensorflow.compat.v1.variable_scope", "slim.avg_pool2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d"], "function", ["None"], ["", "", "", "def", "block_inception_c", "(", "inputs", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "\"\"\"Builds Inception-C block for Inception v4 network.\"\"\"", "\n", "# By default use stride=1 and SAME padding", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "avg_pool2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "scope", ",", "'BlockInceptionC'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "                ", "branch_0", "=", "slim", ".", "conv2d", "(", "inputs", ",", "256", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "                ", "branch_1", "=", "slim", ".", "conv2d", "(", "inputs", ",", "384", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "\n", "slim", ".", "conv2d", "(", "branch_1", ",", "256", ",", "[", "1", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_1x3'", ")", ",", "\n", "slim", ".", "conv2d", "(", "branch_1", ",", "256", ",", "[", "3", ",", "1", "]", ",", "scope", "=", "'Conv2d_0c_3x1'", ")", "]", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "                ", "branch_2", "=", "slim", ".", "conv2d", "(", "inputs", ",", "384", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "448", ",", "[", "3", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_3x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "512", ",", "[", "1", ",", "3", "]", ",", "scope", "=", "'Conv2d_0c_1x3'", ")", "\n", "branch_2", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "\n", "slim", ".", "conv2d", "(", "branch_2", ",", "256", ",", "[", "1", ",", "3", "]", ",", "scope", "=", "'Conv2d_0d_1x3'", ")", ",", "\n", "slim", ".", "conv2d", "(", "branch_2", ",", "256", ",", "[", "3", ",", "1", "]", ",", "scope", "=", "'Conv2d_0e_3x1'", ")", "]", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "                ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "inputs", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "256", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "return", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.inception_v4.inception_v4_base": [[181, 289], ["ValueError", "tensorflow.compat.v1.variable_scope", "range", "inception_v4.block_reduction_a", "inception_v4.inception_v4_base.add_and_check_final"], "function", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.inception_v4.block_reduction_a"], ["", "", "", "def", "inception_v4_base", "(", "inputs", ",", "final_endpoint", "=", "'Mixed_7d'", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates the Inception V4 network up to the given final endpoint.\n\n    Args:\n      inputs: a 4-D tensor of size [batch_size, height, width, 3].\n      final_endpoint: specifies the endpoint to construct the network up to.\n        It can be one of [ 'Conv2d_1a_3x3', 'Conv2d_2a_3x3', 'Conv2d_2b_3x3',\n        'Mixed_3a', 'Mixed_4a', 'Mixed_5a', 'Mixed_5b', 'Mixed_5c', 'Mixed_5d',\n        'Mixed_5e', 'Mixed_6a', 'Mixed_6b', 'Mixed_6c', 'Mixed_6d', 'Mixed_6e',\n        'Mixed_6f', 'Mixed_6g', 'Mixed_6h', 'Mixed_7a', 'Mixed_7b', 'Mixed_7c',\n        'Mixed_7d']\n      scope: Optional variable_scope.\n\n    Returns:\n      logits: the logits outputs of the model.\n      end_points: the set of end_points from the inception model.\n\n    Raises:\n      ValueError: if final_endpoint is not set to one of the predefined values,\n    \"\"\"", "\n", "end_points", "=", "{", "}", "\n", "\n", "def", "add_and_check_final", "(", "name", ",", "net", ")", ":", "\n", "        ", "end_points", "[", "name", "]", "=", "net", "\n", "return", "name", "==", "final_endpoint", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "scope", ",", "'InceptionV4'", ",", "[", "inputs", "]", ")", ":", "\n", "        ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "max_pool2d", ",", "slim", ".", "avg_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "# 299 x 299 x 3", "\n", "            ", "net", "=", "slim", ".", "conv2d", "(", "inputs", ",", "32", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "\n", "padding", "=", "'SAME'", ",", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "if", "add_and_check_final", "(", "'Conv2d_1a_3x3'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "# 149 x 149 x 32", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "32", ",", "[", "3", ",", "3", "]", ",", "padding", "=", "'SAME'", ",", "\n", "scope", "=", "'Conv2d_2a_3x3'", ")", "\n", "if", "add_and_check_final", "(", "'Conv2d_2a_3x3'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "# 147 x 147 x 32", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "64", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_2b_3x3'", ")", "\n", "if", "add_and_check_final", "(", "'Conv2d_2b_3x3'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "# 147 x 147 x 64", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Mixed_3a'", ")", ":", "\n", "                ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "                    ", "branch_0", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'SAME'", ",", "\n", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "                    ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "96", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'SAME'", ",", "\n", "scope", "=", "'Conv2d_0a_3x3'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", "]", ")", "\n", "if", "add_and_check_final", "(", "'Mixed_3a'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 73 x 73 x 160", "\n", "", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Mixed_4a'", ")", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "                ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_0", "=", "slim", ".", "conv2d", "(", "branch_0", ",", "96", ",", "[", "3", ",", "3", "]", ",", "padding", "=", "'SAME'", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "                ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "64", ",", "[", "1", ",", "7", "]", ",", "scope", "=", "'Conv2d_0b_1x7'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "64", ",", "[", "7", ",", "1", "]", ",", "scope", "=", "'Conv2d_0c_7x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "96", ",", "[", "3", ",", "3", "]", ",", "padding", "=", "'SAME'", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", "]", ")", "\n", "if", "add_and_check_final", "(", "'Mixed_4a'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 71 x 71 x 192", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Mixed_5a'", ")", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "                ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "192", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'SAME'", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "                ", "branch_1", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'SAME'", ",", "\n", "scope", "=", "'MaxPool_1a_3x3'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", "]", ")", "\n", "if", "add_and_check_final", "(", "'Mixed_5a'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 35 x 35 x 384", "\n", "# 4 x Inception-A blocks", "\n", "", "for", "idx", "in", "range", "(", "4", ")", ":", "\n", "            ", "block_scope", "=", "'Mixed_5'", "+", "chr", "(", "ord", "(", "'b'", ")", "+", "idx", ")", "\n", "net", "=", "block_inception_a", "(", "net", ",", "block_scope", ")", "\n", "if", "add_and_check_final", "(", "block_scope", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 35 x 35 x 384", "\n", "# Reduction-A block", "\n", "", "net", "=", "block_reduction_a", "(", "net", ",", "1", ",", "'Mixed_6a'", ")", "\n", "if", "add_and_check_final", "(", "'Mixed_6a'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 17 x 17 x 1024", "\n", "# 7 x Inception-B blocks", "\n", "for", "idx", "in", "range", "(", "7", ")", ":", "\n", "            ", "block_scope", "=", "'Mixed_6'", "+", "chr", "(", "ord", "(", "'b'", ")", "+", "idx", ")", "\n", "net", "=", "block_inception_b", "(", "net", ",", "block_scope", ")", "\n", "if", "add_and_check_final", "(", "block_scope", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 17 x 17 x 1024", "\n", "# Reduction-B block", "\n", "", "net", "=", "block_reduction_b", "(", "net", ",", "1", ",", "'Mixed_7a'", ")", "\n", "if", "add_and_check_final", "(", "'Mixed_7a'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 8 x 8 x 1536", "\n", "# 3 x Inception-C blocks", "\n", "for", "idx", "in", "range", "(", "3", ")", ":", "\n", "            ", "block_scope", "=", "'Mixed_7'", "+", "chr", "(", "ord", "(", "'b'", ")", "+", "idx", ")", "\n", "net", "=", "block_inception_c", "(", "net", ",", "block_scope", ")", "\n", "if", "add_and_check_final", "(", "block_scope", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "", "", "raise", "ValueError", "(", "'Unknown final endpoint %s'", "%", "final_endpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.inception_v4.inception_v4": [[291, 368], ["tensorflow.compat.v1.variable_scope", "slim.arg_scope", "inception_v4.inception_v4_base", "slim.arg_scope", "tensorflow.compat.v1.variable_scope", "kernel_size.is_fully_defined", "slim.dropout", "slim.flatten", "slim.fully_connected", "tensorflow.nn.softmax", "tensorflow.compat.v1.variable_scope", "slim.avg_pool2d", "slim.conv2d", "slim.conv2d", "slim.flatten", "slim.fully_connected", "tf.reduce_mean.get_shape", "slim.avg_pool2d", "tensorflow.reduce_mean", "slim.fully_connected.get_shape"], "function", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.inception_v4.inception_v4_base"], ["", "def", "inception_v4", "(", "inputs", ",", "num_classes", "=", "1001", ",", "is_training", "=", "True", ",", "\n", "dropout_keep_prob", "=", "0.8", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "'InceptionV4'", ",", "\n", "create_aux_logits", "=", "True", ")", ":", "\n", "    ", "\"\"\"Creates the Inception V4 model.\n\n    Args:\n      inputs: a 4-D tensor of size [batch_size, height, width, 3].\n      num_classes: number of predicted classes. If 0 or None, the logits layer\n        is omitted and the input features to the logits layer (before dropout)\n        are returned instead.\n      is_training: whether is training or not.\n      dropout_keep_prob: float, the fraction to keep before final layer.\n      reuse: whether or not the network and its variables should be reused. To be\n        able to reuse 'scope' must be given.\n      scope: Optional variable_scope.\n      create_aux_logits: Whether to include the auxiliary logits.\n\n    Returns:\n      net: a Tensor with the logits (pre-softmax activations) if num_classes\n        is a non-zero integer, or the non-dropped input to the logits layer\n        if num_classes is 0 or None.\n      end_points: the set of end_points from the inception model.\n    \"\"\"", "\n", "end_points", "=", "{", "}", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "scope", ",", "'InceptionV4'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", "as", "scope", ":", "\n", "        ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", ",", "slim", ".", "dropout", "]", ",", "\n", "is_training", "=", "is_training", ")", ":", "\n", "            ", "net", ",", "end_points", "=", "inception_v4_base", "(", "inputs", ",", "scope", "=", "scope", ")", "\n", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "max_pool2d", ",", "slim", ".", "avg_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "# Auxiliary Head logits", "\n", "                ", "if", "create_aux_logits", "and", "num_classes", ":", "\n", "                    ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'AuxLogits'", ")", ":", "\n", "# 17 x 17 x 1024", "\n", "                      ", "aux_logits", "=", "end_points", "[", "'Mixed_6h'", "]", "\n", "aux_logits", "=", "slim", ".", "avg_pool2d", "(", "aux_logits", ",", "[", "5", ",", "5", "]", ",", "stride", "=", "3", ",", "\n", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'AvgPool_1a_5x5'", ")", "\n", "aux_logits", "=", "slim", ".", "conv2d", "(", "aux_logits", ",", "128", ",", "[", "1", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_1b_1x1'", ")", "\n", "aux_logits", "=", "slim", ".", "conv2d", "(", "aux_logits", ",", "768", ",", "\n", "aux_logits", ".", "get_shape", "(", ")", "[", "1", ":", "3", "]", ",", "\n", "padding", "=", "'VALID'", ",", "scope", "=", "'Conv2d_2a'", ")", "\n", "aux_logits", "=", "slim", ".", "flatten", "(", "aux_logits", ")", "\n", "aux_logits", "=", "slim", ".", "fully_connected", "(", "aux_logits", ",", "num_classes", ",", "\n", "activation_fn", "=", "None", ",", "\n", "scope", "=", "'Aux_logits'", ")", "\n", "end_points", "[", "'AuxLogits'", "]", "=", "aux_logits", "\n", "\n", "# Final pooling and prediction", "\n", "# TODO(sguada,arnoegw): Consider adding a parameter global_pool which", "\n", "# can be set to False to disable pooling here (as in resnet_*()).", "\n", "", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'Logits'", ")", ":", "\n", "# 8 x 8 x 1536", "\n", "                    ", "kernel_size", "=", "net", ".", "get_shape", "(", ")", "[", "1", ":", "3", "]", "\n", "if", "kernel_size", ".", "is_fully_defined", "(", ")", ":", "\n", "                        ", "net", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "kernel_size", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'AvgPool_1a'", ")", "\n", "", "else", ":", "\n", "                        ", "net", "=", "tf", ".", "reduce_mean", "(", "net", ",", "[", "1", ",", "2", "]", ",", "keep_dims", "=", "True", ",", "\n", "name", "=", "'global_pool'", ")", "\n", "", "end_points", "[", "'global_pool'", "]", "=", "net", "\n", "if", "not", "num_classes", ":", "\n", "                        ", "return", "net", ",", "end_points", "\n", "# 1 x 1 x 1536", "\n", "", "net", "=", "slim", ".", "dropout", "(", "net", ",", "dropout_keep_prob", ",", "scope", "=", "'Dropout_1b'", ")", "\n", "net", "=", "slim", ".", "flatten", "(", "net", ",", "scope", "=", "'PreLogitsFlatten'", ")", "\n", "end_points", "[", "'PreLogitsFlatten'", "]", "=", "net", "\n", "# 1536", "\n", "logits", "=", "slim", ".", "fully_connected", "(", "net", ",", "num_classes", ",", "activation_fn", "=", "None", ",", "\n", "scope", "=", "'Logits'", ")", "\n", "end_points", "[", "'Logits'", "]", "=", "logits", "\n", "end_points", "[", "'Predictions'", "]", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ",", "name", "=", "'Predictions'", ")", "\n", "", "", "", "return", "logits", ",", "end_points", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.tensorpack_model.AttentionOCR.inputs": [[32, 39], ["tensorflow.TensorSpec", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "tensorflow.TensorSpec"], "methods", ["None"], ["def", "inputs", "(", "self", ")", ":", "\n", "        ", "return", "[", "tf", ".", "TensorSpec", "(", "[", "None", ",", "cfg", ".", "image_size", ",", "cfg", ".", "image_size", ",", "3", "]", ",", "tf", ".", "float32", ",", "'image'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "None", ",", "cfg", ".", "seq_len", "+", "1", "]", ",", "tf", ".", "int32", ",", "'label'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "None", ",", "cfg", ".", "seq_len", "+", "1", "]", ",", "tf", ".", "float32", ",", "'mask'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "None", ",", "4", "]", ",", "tf", ".", "float32", ",", "'normalized_bbox'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "bool", ",", "'is_training'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "float32", ",", "'dropout_keep_prob'", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.tensorpack_model.AttentionOCR.optimizer": [[40, 49], ["tensorflow.train.get_or_create_global_step", "tensorflow.get_variable", "tensorflow.train.cosine_decay", "tensorflow.compat.v1.summary.scalar", "tensorflow.train.AdamOptimizer"], "methods", ["None"], ["", "def", "optimizer", "(", "self", ")", ":", "\n", "        ", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "lr", "=", "tf", ".", "get_variable", "(", "'learning_rate'", ",", "initializer", "=", "cfg", ".", "learning_rate", "/", "100", ",", "trainable", "=", "False", ")", "\n", "lr", "=", "tf", ".", "train", ".", "cosine_decay", "(", "lr", ",", "global_step", ",", "cfg", ".", "num_epochs", "*", "cfg", ".", "steps_per_epoch", ",", "alpha", "=", "cfg", ".", "min_lr", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "lr", ")", "\n", "# add_moving_summary(lr)", "\n", "# opt = tf.train.MomentumOptimizer(lr, 0.9)", "\n", "opt", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "lr", ",", "0.9", ",", "0.999", ")", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.tensorpack_model.AttentionOCR.get_inferene_tensor_names": [[50, 57], ["None"], "methods", ["None"], ["", "def", "get_inferene_tensor_names", "(", "self", ")", ":", "\n", "        ", "inputs", ",", "outputs", "=", "[", "]", ",", "[", "]", "\n", "if", "cfg", ".", "model_name", "==", "'ocr'", ":", "\n", "            ", "inputs", ",", "outputs", "=", "[", "'image'", ",", "'label'", ",", "'is_training'", ",", "'dropout_keep_prob'", "]", ",", "[", "'sequence_preds'", ",", "'sequence_probs'", "]", "\n", "", "elif", "cfg", ".", "model_name", "==", "'ocr_with_normalized_bbox'", ":", "\n", "            ", "inputs", ",", "outputs", "=", "[", "'image'", ",", "'label'", ",", "'normalized_bbox'", ",", "'is_training'", ",", "'dropout_keep_prob'", "]", ",", "[", "'sequence_preds'", ",", "'sequence_probs'", "]", "\n", "", "return", "inputs", ",", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.tensorpack_model.AttentionOCR.build_graph": [[58, 114], ["tensorflow.while_loop", "tensorflow.add_n", "tensorflow.compat.v1.summary.image", "range", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.tensor_summary", "tensorflow.compat.v1.summary.text", "tensorflow.compat.v1.summary.tensor_summary", "tensorflow.compat.v1.summary.text", "tensorflow.nn.softmax", "tensorflow.argmax", "tensorflow.reduce_max", "tensorflow.compat.v1.summary.tensor_summary", "tensorflow.compat.v1.summary.text", "tensorflow.compat.v1.summary.tensor_summary", "tensorflow.compat.v1.summary.text", "tensorpack.tfutils.summary.add_param_summary", "inception_padding_model", "tensorpack_model.label_smoothing", "tensorflow.nn.softmax_cross_entropy_with_logits", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.compat.v1.get_collection", "tensorflow.compat.v1.summary.image", "tensorflow.as_string", "tensorflow.as_string", "tensorflow.as_string", "tensorflow.as_string", "inception_model", "tensorflow.one_hot", "tensorflow.constant", "tensorflow.constant", "np.zeros"], "methods", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.model.inception_padding_model", "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.tensorpack_model.label_smoothing", "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.model.inception_model"], ["", "def", "build_graph", "(", "self", ",", "image", ",", "label", ",", "mask", ",", "normalized_bbox", ",", "is_training", ",", "dropout_keep_prob", ")", ":", "\n", "        ", "if", "cfg", ".", "model_name", "==", "'ocr'", ":", "\n", "            ", "outputs", ",", "attentions", "=", "inception_padding_model", "(", "image", ",", "label", ",", "wemb_size", "=", "cfg", ".", "wemb_size", ",", "seq_len", "=", "cfg", ".", "seq_len", "+", "1", ",", "num_classes", "=", "cfg", ".", "num_classes", ",", "lstm_size", "=", "cfg", ".", "lstm_size", ",", "is_training", "=", "is_training", ",", "dropout_keep_prob", "=", "dropout_keep_prob", ",", "weight_decay", "=", "cfg", ".", "weight_decay", ",", "name", "=", "cfg", ".", "name_scope", ",", "reuse", "=", "None", ")", "\n", "\n", "", "elif", "cfg", ".", "model_name", "==", "'ocr_with_normalized_bbox'", ":", "\n", "            ", "outputs", ",", "attentions", "=", "inception_model", "(", "image", ",", "label", ",", "normalized_bbox", ",", "wemb_size", "=", "cfg", ".", "wemb_size", ",", "seq_len", "=", "cfg", ".", "seq_len", "+", "1", ",", "num_classes", "=", "cfg", ".", "num_classes", ",", "lstm_size", "=", "cfg", ".", "lstm_size", ",", "is_training", "=", "is_training", ",", "dropout_keep_prob", "=", "dropout_keep_prob", ",", "weight_decay", "=", "cfg", ".", "weight_decay", ",", "name", "=", "cfg", ".", "name_scope", ",", "reuse", "=", "None", ")", "\n", "\n", "", "def", "_step_loss", "(", "k", ",", "total_xen_loss", ")", ":", "\n", "# cross_entropy_loss = tf.compat.v1.losses.sparse_softmax_cross_entropy(label[:,k], outputs[:,k,:])", "\n", "            ", "label_smoothed", "=", "label_smoothing", "(", "tf", ".", "one_hot", "(", "label", "[", ":", ",", "k", "]", ",", "cfg", ".", "num_classes", ",", "axis", "=", "-", "1", ")", ")", "\n", "cross_entropy_loss", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits", "(", "logits", "=", "outputs", "[", ":", ",", "k", ",", ":", "]", ",", "labels", "=", "label_smoothed", ")", "\n", "cross_entropy_loss", "*=", "mask", "[", ":", ",", "k", "]", "\n", "return", "k", "+", "1", ",", "total_xen_loss", "+", "cross_entropy_loss", "\n", "\n", "", "_", ",", "cross_entropy_loss", "=", "tf", ".", "while_loop", "(", "\n", "cond", "=", "lambda", "k", ",", "*", "_", ":", "k", "<", "cfg", ".", "seq_len", "+", "1", ",", "\n", "body", "=", "_step_loss", ",", "\n", "loop_vars", "=", "(", "tf", ".", "constant", "(", "0", ",", "tf", ".", "int32", ")", ",", "tf", ".", "constant", "(", "np", ".", "zeros", "(", "cfg", ".", "batch_size", ")", ",", "tf", ".", "float32", ")", ")", "\n", ")", "\n", "\n", "cross_entropy_loss", "=", "tf", ".", "reduce_sum", "(", "cross_entropy_loss", ")", "/", "tf", ".", "reduce_sum", "(", "mask", ")", "\n", "reg_loss", "=", "tf", ".", "add_n", "(", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "tf", ".", "compat", ".", "v1", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ")", ")", "\n", "\n", "total_loss", "=", "reg_loss", "+", "cross_entropy_loss", "\n", "\n", "# tensorboard summary", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "image", "(", "'input_image'", ",", "image", "[", "0", ":", "1", ",", ":", ",", ":", ",", ":", "]", ")", "\n", "for", "a", "in", "range", "(", "cfg", ".", "seq_len", "+", "1", ")", ":", "\n", "            ", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "image", "(", "'attention_%d'", "%", "a", ",", "attentions", "[", "0", ":", "1", ",", ":", ",", ":", ",", "a", ":", "a", "+", "1", "]", ")", "\n", "", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'cross_entropy_loss'", ",", "cross_entropy_loss", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'reg_loss'", ",", "reg_loss", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'total_loss'", ",", "total_loss", ")", "\n", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "tensor_summary", "(", "'mask'", ",", "mask", "[", "0", ",", ":", "]", ",", "summary_description", "=", "'mask'", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "text", "(", "'mask'", ",", "tf", ".", "as_string", "(", "mask", "[", "0", ",", ":", "]", ")", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "tensor_summary", "(", "'label'", ",", "label", "[", "0", ",", ":", "]", ",", "summary_description", "=", "'label'", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "text", "(", "'label'", ",", "tf", ".", "as_string", "(", "label", "[", "0", ",", ":", "]", ")", ")", "\n", "\n", "logits", "=", "tf", ".", "nn", ".", "softmax", "(", "outputs", ",", "name", "=", "'logits'", ")", "\n", "preds", "=", "tf", ".", "argmax", "(", "logits", ",", "axis", "=", "-", "1", ",", "name", "=", "'sequence_preds'", ")", "\n", "probs", "=", "tf", ".", "reduce_max", "(", "logits", ",", "axis", "=", "-", "1", ",", "name", "=", "'sequence_probs'", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "tensor_summary", "(", "'pred'", ",", "preds", "[", "0", ",", ":", "]", ",", "summary_description", "=", "'preds'", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "text", "(", "'pred'", ",", "tf", ".", "as_string", "(", "preds", "[", "0", ",", ":", "]", ")", ")", "\n", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "tensor_summary", "(", "'prob'", ",", "probs", "[", "0", ",", ":", "]", ",", "summary_description", "=", "'probs'", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "text", "(", "'prob'", ",", "tf", ".", "as_string", "(", "probs", "[", "0", ",", ":", "]", ")", ")", "\n", "\n", "add_param_summary", "(", "(", "'.*'", ",", "[", "'histogram'", "]", ")", ")", "# monitor W  .*/W", "\n", "\n", "return", "total_loss", "", "", "", ""]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.tensorpack_model.label_smoothing": [[18, 26], ["inputs.get_shape().as_list", "inputs.get_shape"], "function", ["None"], ["def", "label_smoothing", "(", "inputs", ",", "epsilon", "=", "0.05", ")", ":", "\n", "    ", "'''Applies label smoothing. See https://arxiv.org/abs/1512.00567.\n    Args:\n      inputs: A 2d tensor with shape of [N, V], where V is the number of vocabulary.\n      epsilon: Smoothing rate.\n    '''", "\n", "K", "=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "# number of channels", "\n", "return", "(", "(", "1", "-", "epsilon", ")", "*", "inputs", ")", "+", "(", "epsilon", "/", "K", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.model.conv": [[15, 17], ["tensorflow.contrib.slim.conv2d"], "function", ["None"], ["def", "conv", "(", "x", ",", "channels", ",", "kernel_size", ",", "stride", ",", "scope", ",", "normalizer_fn", "=", "slim", ".", "batch_norm", ",", "activation_fn", "=", "relu", ")", ":", "\n", "    ", "return", "slim", ".", "conv2d", "(", "x", ",", "channels", ",", "kernel_size", ",", "stride", ",", "scope", "=", "scope", ",", "normalizer_fn", "=", "normalizer_fn", ",", "activation_fn", "=", "activation_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.model.inception_padding_model": [[18, 175], ["tensorflow.compat.v1.variable_scope", "tensorflow.contrib.slim.l2_regularizer", "tensorflow.contrib.slim.arg_scope", "inception_v4_arg_scope", "tensorflow.contrib.slim.arg_scope", "inception_v4_base", "tensorflow.TensorArray", "cnn_feature.get_shape().as_list", "tensorflow.TensorArray", "tensorflow.reduce_mean", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.zeros", "tensorflow.while_loop", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.compat.v1.variable_scope", "tensorflow.add_n", "tensorflow.nn.bias_add", "tensorflow.split", "tensorflow.sigmoid", "tensorflow.sigmoid", "tensorflow.sigmoid", "tensorflow.tanh", "tensorflow.add", "tensorflow.multiply", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.tanh", "tensorflow.reshape", "tensorflow.add", "tensorflow.reshape", "tensorflow.nn.softmax", "attention_array.write.write", "tensorflow.reduce_sum", "model.inception_padding_model._LSTMCell"], "function", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.inception_v4.inception_v4_base"], ["", "def", "inception_padding_model", "(", "images", ",", "labels", ",", "wemb_size", ",", "seq_len", ",", "num_classes", ",", "lstm_size", ",", "is_training", "=", "True", ",", "\n", "dropout_keep_prob", "=", "0.5", ",", "weight_decay", "=", "0.00004", ",", "final_endpoint", "=", "'Mixed_6h'", ",", "name", "=", "'InceptionV4'", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Core default tensorflow model for text recognition.\n    Args:\n        images: input images\n        labels: input groundtruth labels \n        wemb_size: word embedding size\n        seq_len: max sequence length for lstm with end of sequence\n        num_classes: text label classes\n        lstm_size: lstm size\n        is_training: tensorflow placeholder\n        dropout_keep_prob: tensorflow placeholder for dropout\n        weight_decay: tensorflow model weight decay factor\n        final_endpoint: final endpoint for CNN(InceptionV4)\n        name: name scope\n        reuse: reuse parameter\n\n    Returns:\n        output_array: (batch, seq_len, num_classes) logits\n        attention_array: (batch, h, w, seq_len) attention feature map\n    \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ",", "reuse", "=", "reuse", ")", "as", "scope", ":", "\n", "        ", "regularizer", "=", "slim", ".", "l2_regularizer", "(", "weight_decay", ")", "\n", "with", "slim", ".", "arg_scope", "(", "inception_v4_arg_scope", "(", ")", ")", ":", "\n", "            ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", ",", "slim", ".", "dropout", "]", ",", "is_training", "=", "is_training", ")", ":", "\n", "                ", "net", ",", "end_points", "=", "inception_v4_base", "(", "images", ",", "final_endpoint", "=", "final_endpoint", ",", "scope", "=", "scope", ")", "# Mixed_6h Mixed_7d", "\n", "# print(net.get_shape().as_list())", "\n", "cnn_feature", "=", "net", "\n", "\n", "output_array", "=", "tf", ".", "TensorArray", "(", "dtype", "=", "tf", ".", "float32", ",", "size", "=", "seq_len", ")", "\n", "batch", ",", "height", ",", "width", ",", "channel", "=", "cnn_feature", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "attention_array", "=", "tf", ".", "TensorArray", "(", "dtype", "=", "tf", ".", "float32", ",", "size", "=", "seq_len", ")", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"attention_lstm\"", ")", ":", "\n", "                    ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'word_embedding'", ")", ":", "\n", "                        ", "W_wemb", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'W_wemb'", ",", "[", "num_classes", ",", "wemb_size", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ")", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"feature_map_attention\"", ")", ":", "\n", "                        ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"init_mean\"", ")", ":", "\n", "                            ", "W_init_c", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'W_init_c'", ",", "[", "channel", ",", "lstm_size", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "W_init_h", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'W_init_h'", ",", "[", "channel", ",", "lstm_size", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"attention_x\"", ")", ":", "\n", "                            ", "W", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'W'", ",", "[", "channel", ",", "channel", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"attention_h\"", ")", ":", "\n", "                            ", "W_h", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'W_h'", ",", "[", "lstm_size", ",", "channel", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ",", "regularizer", "=", "regularizer", ")", "#tf.truncated_normal_initializer(stddev=0.1)", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"att\"", ")", ":", "\n", "                            ", "W_att", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'W_att'", ",", "[", "channel", ",", "1", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "b_att", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'b_att'", ",", "[", "1", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ")", "\n", "\n", "", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"softmax\"", ")", ":", "\n", "                        ", "softmax_w", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'softmax_w'", ",", "[", "wemb_size", ",", "num_classes", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "softmax_b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'softmax_b'", ",", "[", "num_classes", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ")", "#tf.constant_initializer(biivector)", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"attention_to_embedding\"", ")", ":", "\n", "                        ", "W_attention_wemb", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'W_attention_wemb'", ",", "[", "channel", ",", "wemb_size", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "W_hidden_wemd", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'W_hidden_wemd'", ",", "[", "lstm_size", ",", "wemb_size", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'lstm_cell'", ")", ":", "#orthogonal_initializer  xavier_initializer()", "\n", "                        ", "lstm_W", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'lstm_W'", ",", "[", "wemb_size", ",", "lstm_size", "*", "4", "]", ",", "initializer", "=", "tf", ".", "initializers", ".", "orthogonal", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "lstm_U", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'lstm_U'", ",", "[", "lstm_size", ",", "lstm_size", "*", "4", "]", ",", "initializer", "=", "tf", ".", "initializers", ".", "orthogonal", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "lstm_Z", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'lstm_Z'", ",", "[", "channel", ",", "lstm_size", "*", "4", "]", ",", "initializer", "=", "tf", ".", "initializers", ".", "orthogonal", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "lstm_b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'lstm_b'", ",", "[", "lstm_size", "*", "4", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ")", "\n", "\n", "\n", "", "", "def", "_LSTMCell", "(", "wemb_prev", ",", "h_prev", ",", "attention_feature", ",", "c_prev", ",", "forget_bias", "=", "1.", ",", "keep_prob", "=", "1.", ")", ":", "\n", "                    ", "\"\"\"\n                    Image Caption Attention Mechanism LSTM, refer to https://arxiv.org/abs/1502.03044.\n                    wemb_prev  :                   (batch, wemb_size)\n                    h_prev  :                      (batch, lstm_size)\n                    attention_feature  :           (batch, channel)\n                    c_prev  :                      (batch, lstm_size)\n                    \"\"\"", "\n", "pack", "=", "tf", ".", "add_n", "(", "[", "tf", ".", "matmul", "(", "wemb_prev", ",", "lstm_W", ")", ",", "tf", ".", "matmul", "(", "h_prev", ",", "lstm_U", ")", ",", "tf", ".", "matmul", "(", "attention_feature", ",", "lstm_Z", ")", "]", ")", "\n", "pack_with_bias", "=", "tf", ".", "nn", ".", "bias_add", "(", "pack", ",", "lstm_b", ")", "# (bsize, hid_dim * 4)", "\n", "i", ",", "f", ",", "o", ",", "g", "=", "tf", ".", "split", "(", "pack_with_bias", ",", "num_or_size_splits", "=", "4", ",", "axis", "=", "1", ")", "# (bsize, hid_dim)", "\n", "i", "=", "tf", ".", "sigmoid", "(", "i", ")", "\n", "f", "=", "tf", ".", "sigmoid", "(", "f", ")", "# (f + forget_bias)", "\n", "o", "=", "tf", ".", "sigmoid", "(", "o", ")", "\n", "g", "=", "tf", ".", "tanh", "(", "g", ")", "\n", "c", "=", "tf", ".", "add", "(", "tf", ".", "multiply", "(", "f", ",", "c_prev", ")", ",", "tf", ".", "multiply", "(", "i", ",", "g", ")", ")", "\n", "h", "=", "tf", ".", "multiply", "(", "o", ",", "tf", ".", "tanh", "(", "c", ")", ")", "\n", "\n", "h", "=", "tf", ".", "nn", ".", "dropout", "(", "h", ",", "rate", "=", "1", "-", "keep_prob", ")", "\n", "c", "=", "tf", ".", "nn", ".", "dropout", "(", "c", ",", "rate", "=", "1", "-", "keep_prob", ")", "\n", "return", "h", ",", "c", "\n", "\n", "", "mean_inputs", "=", "tf", ".", "reduce_mean", "(", "cnn_feature", ",", "[", "1", ",", "2", "]", ")", "\n", "init_h", "=", "tf", ".", "tanh", "(", "tf", ".", "matmul", "(", "mean_inputs", ",", "W_init_h", ")", ")", "\n", "init_c", "=", "tf", ".", "tanh", "(", "tf", ".", "matmul", "(", "mean_inputs", ",", "W_init_c", ")", ")", "\n", "init_wemb", "=", "tf", ".", "zeros", "(", "[", "tf", ".", "shape", "(", "mean_inputs", ")", "[", "0", "]", ",", "wemb_size", "]", ")", "\n", "\n", "def", "attention_lstm", "(", "i", ",", "cnn_feature", ",", "wemb_prev", ",", "hidden_state", ",", "cell_state", ",", "output_array", ",", "attention_array", ")", ":", "\n", "                    ", "\"\"\"\n                    Loop body for AttentionOCR.\n                    Args:\n                        i: loop count\n                        cnn_feature: cnn feature map with shape (batch, height, width, channel)\n                        bboxes: groundtruth boxes for crop text region\n                        wemb_prev: previous word embedding\n                        hidden_state: prev lstm hidden state\n                        cell_state: prev lstm cell state\n                        output_array: softmax logit TensorArray at time step i \n                        attention_array: attention feature map TensorArray at time step i \n                    \"\"\"", "\n", "# Bahdanau/Additive Attention Mechanism, refer to https://arxiv.org/pdf/1409.0473.pdf.", "\n", "attention_x", "=", "tf", ".", "reshape", "(", "cnn_feature", ",", "[", "-", "1", ",", "channel", "]", ")", "\n", "attention_x", "=", "tf", ".", "matmul", "(", "attention_x", ",", "W", ")", "\n", "attention_x", "=", "tf", ".", "reshape", "(", "attention_x", ",", "[", "-", "1", ",", "height", "*", "width", ",", "channel", "]", ")", "#(batch, h*w, channel)", "\n", "\n", "# rnn hidden state transform  (batch, lstm_size) -> attention feature h (batch, channel) ", "\n", "attention_h", "=", "tf", ".", "matmul", "(", "hidden_state", ",", "W_h", ")", "#(batch, channel)", "\n", "\n", "# Score function for Attention Mechanism", "\n", "att", "=", "tf", ".", "tanh", "(", "attention_x", "+", "tf", ".", "expand_dims", "(", "attention_h", ",", "axis", "=", "1", ")", ")", "#(batch, h*w, channel)", "\n", "\n", "# Align function for Attention Mechanism  (batch, h*w, channel) -> (batch, h*w)", "\n", "att", "=", "tf", ".", "reshape", "(", "att", ",", "[", "-", "1", ",", "channel", "]", ")", "\n", "att", "=", "tf", ".", "add", "(", "tf", ".", "matmul", "(", "att", ",", "W_att", ")", ",", "b_att", ")", "\n", "att", "=", "tf", ".", "reshape", "(", "att", ",", "[", "-", "1", ",", "height", "*", "width", "]", ")", "\n", "alpha", "=", "tf", ".", "nn", ".", "softmax", "(", "att", ")", "#(batch, h*w)", "\n", "\n", "# store attention", "\n", "attention_array", "=", "attention_array", ".", "write", "(", "i", ",", "alpha", ")", "\n", "\n", "# attention context feature for lstm input", "\n", "x", "=", "attention_x", "*", "tf", ".", "expand_dims", "(", "alpha", ",", "axis", "=", "2", ")", "#(batch, h*w, channel)", "\n", "attention_feature", "=", "tf", ".", "reduce_sum", "(", "x", ",", "axis", "=", "1", ")", "# (batch, channel)", "\n", "\n", "# compute new state by previous word embedding, attention feature and state", "\n", "hidden_state", ",", "cell_state", "=", "_LSTMCell", "(", "wemb_prev", ",", "hidden_state", ",", "attention_feature", ",", "cell_state", ",", "keep_prob", "=", "dropout_keep_prob", ")", "\n", "\n", "# compute output feature for softmax by wemb_prev and transformed hidden state, attention feature", "\n", "attention_wemb", "=", "tf", ".", "matmul", "(", "attention_feature", ",", "W_attention_wemb", ")", "\n", "hidden_wemd", "=", "tf", ".", "matmul", "(", "hidden_state", ",", "W_hidden_wemd", ")", "\n", "\n", "#output = tf.add_n([attention_wemb, hidden_wemd])", "\n", "output", "=", "tf", ".", "add_n", "(", "[", "attention_wemb", ",", "hidden_wemd", ",", "wemb_prev", "]", ")", "\n", "\n", "output", "=", "tf", ".", "matmul", "(", "output", ",", "softmax_w", ")", "+", "softmax_b", "\n", "\n", "# compute word embedding in different behaviours between train(by groundtruth) and test(by max_prob_word)", "\n", "wemb_prev", "=", "tf", ".", "cond", "(", "is_training", ",", "lambda", ":", "tf", ".", "nn", ".", "embedding_lookup", "(", "W_wemb", ",", "labels", "[", ":", ",", "i", "]", ")", ",", "lambda", ":", "tf", ".", "nn", ".", "embedding_lookup", "(", "W_wemb", ",", "tf", ".", "argmax", "(", "tf", ".", "nn", ".", "softmax", "(", "output", ")", ",", "1", ")", ")", ")", "\n", "\n", "output_array", "=", "output_array", ".", "write", "(", "i", ",", "output", ")", "\n", "\n", "return", "i", "+", "1", ",", "cnn_feature", ",", "wemb_prev", ",", "hidden_state", ",", "cell_state", ",", "output_array", ",", "attention_array", "\n", "\n", "", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "output_array", ",", "attention_array", "=", "tf", ".", "while_loop", "(", "cond", "=", "lambda", "i", ",", "*", "_", ":", "i", "<", "seq_len", ",", "body", "=", "attention_lstm", ",", "loop_vars", "=", "(", "tf", ".", "constant", "(", "0", ",", "tf", ".", "int32", ")", ",", "cnn_feature", ",", "init_wemb", ",", "init_h", ",", "init_c", ",", "output_array", ",", "attention_array", ")", ")", "#, shape_invariants=", "\n", "\n", "output_array", "=", "tf", ".", "transpose", "(", "output_array", ".", "stack", "(", ")", ",", "[", "1", ",", "0", ",", "2", "]", ")", "# (batch, seq_len, num_classes)", "\n", "attention_array", "=", "tf", ".", "transpose", "(", "attention_array", ".", "stack", "(", ")", ",", "[", "1", ",", "2", ",", "0", "]", ")", "# (batch, seq_len, h*w)", "\n", "attention_array", "=", "tf", ".", "reshape", "(", "attention_array", ",", "[", "-", "1", ",", "height", ",", "width", ",", "seq_len", "]", ")", "\n", "\n", "", "return", "output_array", ",", "attention_array", "\n", "\n"]], "home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.model.inception_model": [[177, 349], ["tensorflow.compat.v1.variable_scope", "tensorflow.contrib.slim.l2_regularizer", "tensorflow.contrib.slim.arg_scope", "inception_v4_arg_scope", "tensorflow.contrib.slim.arg_scope", "inception_v4_base", "tensorflow.TensorArray", "cnn_feature.get_shape().as_list", "tensorflow.TensorArray", "tensorflow.reduce_mean", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.zeros", "tensorflow.while_loop", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.compat.v1.variable_scope", "tensorflow.add_n", "tensorflow.nn.bias_add", "tensorflow.split", "tensorflow.sigmoid", "tensorflow.sigmoid", "tensorflow.sigmoid", "tensorflow.tanh", "tensorflow.add", "tensorflow.multiply", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.map_fn", "attention_array.write.write", "model.inception_padding_model._LSTMCell"], "function", ["home.repos.pwc.inspect_result.zhang0jhon_AttentionOCR.model.inception_v4.inception_v4_base"], ["", "", "", "def", "inception_model", "(", "images", ",", "labels", ",", "bboxes", ",", "wemb_size", ",", "seq_len", ",", "num_classes", ",", "lstm_size", ",", "is_training", "=", "True", ",", "\n", "dropout_keep_prob", "=", "0.5", ",", "weight_decay", "=", "0.00004", ",", "final_endpoint", "=", "'Mixed_6h'", ",", "name", "=", "'InceptionV4'", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Core tensorflow model for text recognition.\n    Args:\n        images: input images\n        labels: input groundtruth labels \n        bboxes: input groundtruth boxes for text region extract due to preprocess image padding\n        wemb_size: word embedding size\n        seq_len: max sequence length for lstm with end of sequence\n        num_classes: text label classes\n        lstm_size: lstm size\n        is_training: tensorflow placeholder\n        dropout_keep_prob: tensorflow placeholder for dropout\n        weight_decay: tensorflow model weight decay factor\n        final_endpoint: final endpoint for CNN(InceptionV4)\n        name: name scope\n        reuse: reuse parameter\n\n    Returns:\n        output_array: (batch, seq_len, num_classes) logits\n        attention_array: (batch, h, w, seq_len) attention feature map\n    \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ",", "reuse", "=", "reuse", ")", "as", "scope", ":", "\n", "        ", "regularizer", "=", "slim", ".", "l2_regularizer", "(", "weight_decay", ")", "\n", "with", "slim", ".", "arg_scope", "(", "inception_v4_arg_scope", "(", ")", ")", ":", "\n", "            ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", ",", "slim", ".", "dropout", "]", ",", "is_training", "=", "is_training", ")", ":", "\n", "                ", "net", ",", "end_points", "=", "inception_v4_base", "(", "images", ",", "final_endpoint", "=", "final_endpoint", ",", "scope", "=", "scope", ")", "# Mixed_6h Mixed_7d", "\n", "# 299 -> 149 -> 147 -> 73 -> 71 -> 35 -> 17 -> 8    8X+19   16X+27   32X+43", "\n", "# print(net.get_shape().as_list())", "\n", "cnn_feature", "=", "net", "\n", "\n", "output_array", "=", "tf", ".", "TensorArray", "(", "dtype", "=", "tf", ".", "float32", ",", "size", "=", "seq_len", ")", "\n", "batch", ",", "height", ",", "width", ",", "channel", "=", "cnn_feature", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "attention_array", "=", "tf", ".", "TensorArray", "(", "dtype", "=", "tf", ".", "float32", ",", "size", "=", "seq_len", ")", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"attention_lstm\"", ")", ":", "\n", "                    ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'word_embedding'", ")", ":", "\n", "                        ", "W_wemb", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'W_wemb'", ",", "[", "num_classes", ",", "wemb_size", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ")", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"feature_map_attention\"", ")", ":", "\n", "                        ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"init_mean\"", ")", ":", "\n", "                            ", "W_init_c", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'W_init_c'", ",", "[", "channel", ",", "lstm_size", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "W_init_h", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'W_init_h'", ",", "[", "channel", ",", "lstm_size", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"attention_x\"", ")", ":", "\n", "                            ", "W", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'W'", ",", "[", "channel", ",", "channel", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"attention_h\"", ")", ":", "\n", "                            ", "W_h", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'W_h'", ",", "[", "lstm_size", ",", "channel", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ",", "regularizer", "=", "regularizer", ")", "#tf.truncated_normal_initializer(stddev=0.1)", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"att\"", ")", ":", "\n", "                            ", "W_att", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'W_att'", ",", "[", "channel", ",", "1", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "b_att", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'b_att'", ",", "[", "1", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ")", "\n", "\n", "", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"softmax\"", ")", ":", "\n", "                        ", "softmax_w", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'softmax_w'", ",", "[", "wemb_size", ",", "num_classes", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "softmax_b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'softmax_b'", ",", "[", "num_classes", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ")", "#tf.constant_initializer(biivector)", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"attention_to_embedding\"", ")", ":", "\n", "                        ", "W_attention_wemb", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'W_attention_wemb'", ",", "[", "channel", ",", "wemb_size", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "W_hidden_wemd", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'W_hidden_wemd'", ",", "[", "lstm_size", ",", "wemb_size", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'lstm_cell'", ")", ":", "#orthogonal_initializer  xavier_initializer()", "\n", "                        ", "lstm_W", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'lstm_W'", ",", "[", "wemb_size", ",", "lstm_size", "*", "4", "]", ",", "initializer", "=", "tf", ".", "initializers", ".", "orthogonal", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "lstm_U", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'lstm_U'", ",", "[", "lstm_size", ",", "lstm_size", "*", "4", "]", ",", "initializer", "=", "tf", ".", "initializers", ".", "orthogonal", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "lstm_Z", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'lstm_Z'", ",", "[", "channel", ",", "lstm_size", "*", "4", "]", ",", "initializer", "=", "tf", ".", "initializers", ".", "orthogonal", "(", ")", ",", "regularizer", "=", "regularizer", ")", "\n", "lstm_b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'lstm_b'", ",", "[", "lstm_size", "*", "4", "]", ",", "initializer", "=", "xavier_initializer", "(", ")", ")", "\n", "\n", "\n", "", "", "def", "_LSTMCell", "(", "wemb_prev", ",", "h_prev", ",", "attention_feature", ",", "c_prev", ",", "forget_bias", "=", "1.", ",", "keep_prob", "=", "1.", ")", ":", "\n", "                    ", "\"\"\"\n                    wemb_prev  :                   (batch, wemb_size)\n                    h_prev  :                      (batch, lstm_size)\n                    attention_feature  :           (batch, channel)\n                    c_prev  :                      (batch, lstm_size)\n                    \"\"\"", "\n", "pack", "=", "tf", ".", "add_n", "(", "[", "tf", ".", "matmul", "(", "wemb_prev", ",", "lstm_W", ")", ",", "tf", ".", "matmul", "(", "h_prev", ",", "lstm_U", ")", ",", "tf", ".", "matmul", "(", "attention_feature", ",", "lstm_Z", ")", "]", ")", "\n", "pack_with_bias", "=", "tf", ".", "nn", ".", "bias_add", "(", "pack", ",", "lstm_b", ")", "# (bsize, hid_dim * 4)", "\n", "i", ",", "f", ",", "o", ",", "g", "=", "tf", ".", "split", "(", "pack_with_bias", ",", "num_or_size_splits", "=", "4", ",", "axis", "=", "1", ")", "# (bsize, hid_dim)", "\n", "i", "=", "tf", ".", "sigmoid", "(", "i", ")", "\n", "f", "=", "tf", ".", "sigmoid", "(", "f", ")", "# (f + forget_bias)", "\n", "o", "=", "tf", ".", "sigmoid", "(", "o", ")", "\n", "g", "=", "tf", ".", "tanh", "(", "g", ")", "\n", "c", "=", "tf", ".", "add", "(", "tf", ".", "multiply", "(", "f", ",", "c_prev", ")", ",", "tf", ".", "multiply", "(", "i", ",", "g", ")", ")", "\n", "h", "=", "tf", ".", "multiply", "(", "o", ",", "tf", ".", "tanh", "(", "c", ")", ")", "\n", "\n", "h", "=", "tf", ".", "nn", ".", "dropout", "(", "h", ",", "rate", "=", "1", "-", "keep_prob", ")", "\n", "c", "=", "tf", ".", "nn", ".", "dropout", "(", "c", ",", "rate", "=", "1", "-", "keep_prob", ")", "\n", "return", "h", ",", "c", "\n", "\n", "", "mean_inputs", "=", "tf", ".", "reduce_mean", "(", "cnn_feature", ",", "[", "1", ",", "2", "]", ")", "\n", "init_h", "=", "tf", ".", "tanh", "(", "tf", ".", "matmul", "(", "mean_inputs", ",", "W_init_h", ")", ")", "\n", "init_c", "=", "tf", ".", "tanh", "(", "tf", ".", "matmul", "(", "mean_inputs", ",", "W_init_c", ")", ")", "\n", "init_y", "=", "tf", ".", "zeros", "(", "[", "tf", ".", "shape", "(", "mean_inputs", ")", "[", "0", "]", ",", "wemb_size", "]", ")", "\n", "\n", "def", "attention_lstm", "(", "i", ",", "cnn_feature", ",", "bboxes", ",", "wemb_prev", ",", "hidden_state", ",", "cell_state", ",", "output_array", ",", "attention_array", ")", ":", "\n", "                    ", "\"\"\"\n                    Loop body for AttentionOCR.\n                    Args:\n                        i: loop count\n                        cnn_feature: cnn feature map with shape (batch, height, width, channel)\n                        bboxes: groundtruth boxes for crop text region\n                        wemb_prev: previous word embedding\n                        hidden_state: prev lstm hidden state\n                        cell_state: prev lstm cell state\n                        output_array: softmax logit TensorArray at time step i \n                        attention_array: attention feature map TensorArray at time step i \n                    \"\"\"", "\n", "def", "map_fn_for_attention", "(", "image", ",", "bbox", ",", "attention_h", ")", ":", "\n", "                        ", "\"\"\"\n                        attention mechanism for each image\n                        \"\"\"", "\n", "offset_height", ",", "offset_width", ",", "target_height", ",", "target_width", "=", "tf", ".", "cast", "(", "bbox", "[", "0", "]", "*", "height", ",", "tf", ".", "int32", ")", ",", "tf", ".", "cast", "(", "bbox", "[", "1", "]", "*", "width", ",", "tf", ".", "int32", ")", ",", "tf", ".", "cast", "(", "bbox", "[", "2", "]", "*", "height", ",", "tf", ".", "int32", ")", ",", "tf", ".", "cast", "(", "bbox", "[", "3", "]", "*", "width", ",", "tf", ".", "int32", ")", "\n", "image", "=", "tf", ".", "compat", ".", "v1", ".", "image", ".", "crop_to_bounding_box", "(", "image", ",", "offset_height", ",", "offset_width", ",", "target_height", ",", "target_width", ")", "\n", "\n", "# score function for context similarity", "\n", "attention_x", "=", "tf", ".", "reshape", "(", "image", ",", "[", "-", "1", ",", "channel", "]", ")", "#(h*w, c)", "\n", "attention_x", "=", "tf", ".", "matmul", "(", "attention_x", ",", "W", ")", "\n", "\n", "att", "=", "tf", ".", "tanh", "(", "attention_x", "+", "tf", ".", "expand_dims", "(", "attention_h", ",", "axis", "=", "0", ")", ")", "#(h*w, c)", "\n", "\n", "# attention weight", "\n", "att", "=", "tf", ".", "add", "(", "tf", ".", "matmul", "(", "att", ",", "W_att", ")", ",", "b_att", ")", "#(h*w, 1)", "\n", "alpha", "=", "tf", ".", "nn", ".", "softmax", "(", "att", ",", "axis", "=", "0", ")", "\n", "\n", "x", "=", "attention_x", "*", "alpha", "#(h*w, c)", "\n", "attention_feature", "=", "tf", ".", "reduce_sum", "(", "x", ",", "axis", "=", "0", ")", "# (c)", "\n", "\n", "alpha", "=", "tf", ".", "reshape", "(", "alpha", ",", "[", "target_height", ",", "target_width", "]", ")", "\n", "paddings", "=", "[", "[", "offset_height", ",", "height", "-", "target_height", "-", "offset_height", "]", ",", "[", "offset_width", ",", "width", "-", "offset_width", "-", "target_width", "]", "]", "\n", "alpha", "=", "tf", ".", "pad", "(", "alpha", ",", "paddings", ",", "'CONSTANT'", ")", "\n", "\n", "return", "attention_feature", ",", "alpha", "\n", "\n", "\n", "# rnn hidden state transform  (batch, lstm_size) -> attention feature h (batch, channel) ", "\n", "", "attention_h", "=", "tf", ".", "matmul", "(", "hidden_state", ",", "W_h", ")", "#(batch, channel)   attention feature in channel dimension", "\n", "\n", "attention_feature", ",", "alpha", "=", "tf", ".", "map_fn", "(", "lambda", "x", ":", "map_fn_for_attention", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ",", "x", "[", "2", "]", ")", ",", "(", "cnn_feature", ",", "bboxes", ",", "attention_h", ")", ",", "(", "tf", ".", "float32", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "# store attention", "\n", "attention_array", "=", "attention_array", ".", "write", "(", "i", ",", "tf", ".", "reshape", "(", "alpha", ",", "[", "-", "1", ",", "height", "*", "width", "]", ")", ")", "\n", "\n", "\n", "# compute new state by previous word embedding, attention feature and state", "\n", "hidden_state", ",", "cell_state", "=", "_LSTMCell", "(", "wemb_prev", ",", "hidden_state", ",", "attention_feature", ",", "cell_state", ",", "keep_prob", "=", "dropout_keep_prob", ")", "\n", "\n", "# compute output feature for softmax by wemb_prev and transformed hidden state, attention feature", "\n", "attention_wemb", "=", "tf", ".", "matmul", "(", "attention_feature", ",", "W_attention_wemb", ")", "\n", "hidden_wemd", "=", "tf", ".", "matmul", "(", "hidden_state", ",", "W_hidden_wemd", ")", "\n", "\n", "#output = tf.add_n([attention_wemb, hidden_wemd])", "\n", "output", "=", "tf", ".", "add_n", "(", "[", "attention_wemb", ",", "hidden_wemd", ",", "wemb_prev", "]", ")", "\n", "\n", "output", "=", "tf", ".", "matmul", "(", "output", ",", "softmax_w", ")", "+", "softmax_b", "\n", "\n", "# compute word embedding in different behaviours between train(by groundtruth) and test(by max_prob_word)", "\n", "wemb_prev", "=", "tf", ".", "cond", "(", "is_training", ",", "lambda", ":", "tf", ".", "nn", ".", "embedding_lookup", "(", "W_wemb", ",", "labels", "[", ":", ",", "i", "]", ")", ",", "lambda", ":", "tf", ".", "nn", ".", "embedding_lookup", "(", "W_wemb", ",", "tf", ".", "argmax", "(", "tf", ".", "nn", ".", "softmax", "(", "output", ")", ",", "1", ")", ")", ")", "\n", "\n", "output_array", "=", "output_array", ".", "write", "(", "i", ",", "output", ")", "\n", "\n", "return", "i", "+", "1", ",", "cnn_feature", ",", "bboxes", ",", "wemb_prev", ",", "hidden_state", ",", "cell_state", ",", "output_array", ",", "attention_array", "\n", "\n", "", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "output_array", ",", "attention_array", "=", "tf", ".", "while_loop", "(", "cond", "=", "lambda", "i", ",", "*", "_", ":", "i", "<", "seq_len", ",", "body", "=", "attention_lstm", ",", "loop_vars", "=", "(", "tf", ".", "constant", "(", "0", ",", "tf", ".", "int32", ")", ",", "cnn_feature", ",", "bboxes", ",", "init_y", ",", "init_h", ",", "init_c", ",", "output_array", ",", "attention_array", ")", ")", "#, shape_invariants=", "\n", "\n", "output_array", "=", "tf", ".", "transpose", "(", "output_array", ".", "stack", "(", ")", ",", "[", "1", ",", "0", ",", "2", "]", ")", "# (batch, seq_len, num_classes)", "\n", "attention_array", "=", "tf", ".", "transpose", "(", "attention_array", ".", "stack", "(", ")", ",", "[", "1", ",", "2", ",", "0", "]", ")", "# (batch, seq_len, h*w)", "\n", "attention_array", "=", "tf", ".", "reshape", "(", "attention_array", ",", "[", "-", "1", ",", "height", ",", "width", ",", "seq_len", "]", ")", "\n", "\n", "", "return", "output_array", ",", "attention_array", "\n", "\n"]]}