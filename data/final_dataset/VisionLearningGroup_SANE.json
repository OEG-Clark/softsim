{"home.repos.pwc.inspect_result.VisionLearningGroup_SANE.datasets.data_loader.DataLoader.__init__": [[10, 46], ["os.path.join", "os.path.exists", "os.makedirs", "os.path.join", "set", "list", "dict", "os.path.exists", "os.makedirs", "open", "zip", "os.path.join", "line.strip().split", "int", "set.update", "data_loader.DataLoader.pairs.append", "range", "len", "line.strip"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.update"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "split", ",", "transform", "=", "None", ",", "loader", "=", "default_image_loader", ")", ":", "\n", "        ", "typedir", "=", "'var'", "\n", "if", "args", ".", "fixed_ref", ":", "\n", "            ", "typedir", "=", "'fixed'", "\n", "\n", "", "self", ".", "cache_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "datadir", ",", "'cache'", ",", "args", ".", "dataset", ",", "typedir", ",", "args", ".", "method", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "cache_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "cache_dir", ")", "\n", "\n", "", "if", "split", "==", "'train'", ":", "\n", "            ", "self", ".", "resized_cache_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "datadir", ",", "'cache'", ",", "args", ".", "dataset", ",", "'resized'", ",", "typedir", ",", "args", ".", "method", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "resized_cache_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "self", ".", "resized_cache_dir", ")", "\n", "\n", "", "", "self", ".", "transform", "=", "transform", "\n", "self", ".", "is_train", "=", "split", "==", "'train'", "\n", "self", ".", "loader", "=", "loader", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "pairs", "=", "[", "]", "\n", "if", "split", "!=", "'train'", ":", "\n", "            ", "images", "=", "set", "(", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "'pairs'", ",", "split", ",", "args", ".", "dataset", "+", "'_pairs.txt'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "f", ":", "\n", "                    ", "img1", ",", "img2", ",", "label", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "label", "=", "int", "(", "label", ")", "\n", "images", ".", "update", "(", "[", "img1", ",", "img2", "]", ")", "\n", "self", ".", "pairs", ".", "append", "(", "(", "img1", ",", "img2", ",", "label", ")", ")", "\n", "\n", "", "", "self", ".", "images", "=", "list", "(", "images", ")", "\n", "self", ".", "image2index", "=", "dict", "(", "zip", "(", "self", ".", "images", ",", "range", "(", "len", "(", "self", ".", "images", ")", ")", ")", ")", "\n", "\n", "", "self", ".", "method", "=", "args", ".", "method", "\n", "self", ".", "dataset", "=", "args", ".", "dataset", "\n", "self", ".", "fixed_ref", "=", "args", ".", "fixed_ref", "\n", "self", ".", "cuda", "=", "args", ".", "cuda", "\n", "self", ".", "mask_size", "=", "args", ".", "mask_size", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.datasets.data_loader.DataLoader.get_typespace": [[47, 49], ["None"], "methods", ["None"], ["", "def", "get_typespace", "(", "self", ",", "anchor", ",", "pair", ")", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.datasets.data_loader.DataLoader.get_heatmap_cachefn": [[50, 55], ["os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "get_heatmap_cachefn", "(", "self", ",", "img1", ",", "img2", "=", "None", ")", ":", "\n", "        ", "if", "img2", "is", "None", ":", "\n", "            ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "resized_cache_dir", ",", "img1", "+", "'.npy'", ")", "\n", "", "else", ":", "\n", "            ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "cache_dir", ",", "img1", "+", "'+'", "+", "img2", "+", "'.npy'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.datasets.data_loader.DataLoader.process_heatmap": [[56, 58], ["None"], "methods", ["None"], ["", "", "def", "process_heatmap", "(", "self", ",", "heatmap", ")", ":", "\n", "        ", "return", "heatmap", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.datasets.data_loader.DataLoader.load_heatmap": [[59, 73], ["data_loader.DataLoader.process_heatmap", "torch.rand", "data_loader.DataLoader.get_heatmap_cachefn", "os.path.exists", "heatmap.cuda.cuda.cuda", "torch.from_numpy", "numpy.load", "heatmap.cuda.cuda.cuda"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.attributes.data_loader.AttributeDataLoader.process_heatmap", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.attributes.awa.AwALoader.get_heatmap_cachefn"], ["", "def", "load_heatmap", "(", "self", ",", "img1", ",", "img2", "=", "None", ",", "model", "=", "None", ",", "embeddings", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "method", "==", "'random'", ":", "\n", "            ", "heatmap", "=", "torch", ".", "rand", "(", "112", ",", "112", ")", "\n", "if", "self", ".", "cuda", ":", "\n", "                ", "heatmap", "=", "heatmap", ".", "cuda", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "outfn", "=", "self", ".", "get_heatmap_cachefn", "(", "img1", ",", "img2", ")", "\n", "heatmap", "=", "None", "\n", "if", "os", ".", "path", ".", "exists", "(", "outfn", ")", ":", "\n", "                ", "heatmap", "=", "torch", ".", "from_numpy", "(", "np", ".", "load", "(", "outfn", ")", ")", "\n", "if", "self", ".", "cuda", ":", "\n", "                    ", "heatmap", "=", "heatmap", ".", "cuda", "(", ")", "\n", "\n", "", "", "", "return", "self", ".", "process_heatmap", "(", "heatmap", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.datasets.data_loader.DataLoader.__getitem__": [[74, 81], ["os.path.join", "data_loader.DataLoader.loader", "data_loader.DataLoader.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "imfn", "=", "os", ".", "path", ".", "join", "(", "self", ".", "impath", ",", "self", ".", "images", "[", "index", "]", "+", "'.jpg'", ")", "\n", "img", "=", "self", ".", "loader", "(", "imfn", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.datasets.data_loader.DataLoader.__len__": [[82, 84], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "images", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.datasets.data_loader.default_image_loader": [[6, 8], ["PIL.Image.open().convert", "PIL.Image.open"], "function", ["None"], ["def", "default_image_loader", "(", "path", ")", ":", "\n", "    ", "return", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.awa.AwALoader.__init__": [[6, 52], ["datasets.saliency.data_loader.SaliencyDataLoader.__init__", "os.path.join", "os.path.join", "dict", "range", "enumerate", "numpy.random.shuffle", "os.path.join", "zip", "len", "os.path.join", "os.path.join", "open", "open", "open", "enumerate", "os.listdir", "range", "os.path.join", "line.strip.strip.strip", "os.path.join", "line.strip.strip.strip", "os.path.join", "line.strip.strip.strip", "os.path.join", "os.path.join", "image_id.split", "len", "os.path.join.split", "os.path.join.split", "classes.append", "predicates.append", "splitclasses.append", "im.split", "image_id.split", "line.strip.strip.split", "line.strip.strip.split"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "split", ",", "transform", "=", "None", ")", ":", "\n", "        ", "super", "(", "AwALoader", ",", "self", ")", ".", "__init__", "(", "args", ",", "split", ",", "transform", ")", "\n", "awa_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "datadir", ",", "'Animals_with_Attributes2'", ")", "\n", "self", ".", "impath", "=", "os", ".", "path", ".", "join", "(", "awa_dir", ",", "'JPEGImages'", ")", "\n", "if", "split", "==", "'train'", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "awa_dir", ",", "'classes.txt'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "classes", "=", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "                    ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", ":", "\n", "                        ", "classes", ".", "append", "(", "line", ".", "split", "(", ")", "[", "1", "]", ")", "\n", "\n", "", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "awa_dir", ",", "'predicates.txt'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "predicates", "=", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "                    ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", ":", "\n", "                        ", "predicates", ".", "append", "(", "line", ".", "split", "(", ")", "[", "1", "]", ")", "\n", "\n", "", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "awa_dir", ",", "split", "+", "'classes.txt'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "splitclasses", "=", "[", "]", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                    ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", ":", "\n", "                        ", "splitclasses", ".", "append", "(", "line", ")", "\n", "\n", "", "", "", "images", "=", "[", "]", "\n", "cls2ims", "=", "{", "}", "\n", "for", "i", ",", "cls", "in", "enumerate", "(", "splitclasses", ")", ":", "\n", "                ", "imlist", "=", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "impath", ",", "cls", ")", ")", "\n", "imlist", "=", "[", "im", ".", "split", "(", "'.'", ")", "[", "0", "]", "for", "im", "in", "imlist", "]", "\n", "cls2ims", "[", "cls", "]", "=", "[", "os", ".", "path", ".", "join", "(", "image_id", ".", "split", "(", "'_'", ")", "[", "0", "]", ",", "image_id", ")", "for", "image_id", "in", "imlist", "]", "\n", "images", "+=", "imlist", "\n", "\n", "", "np", ".", "random", ".", "shuffle", "(", "images", ")", "\n", "self", ".", "cls2ims", "=", "cls2ims", "\n", "self", ".", "images", "=", "images", "\n", "\n", "", "self", ".", "images", "=", "[", "os", ".", "path", ".", "join", "(", "image_id", ".", "split", "(", "'_'", ")", "[", "0", "]", ",", "image_id", ")", "for", "image_id", "in", "self", ".", "images", "]", "\n", "self", ".", "image2index", "=", "dict", "(", "zip", "(", "self", ".", "images", ",", "range", "(", "len", "(", "self", ".", "images", ")", ")", ")", ")", "\n", "self", ".", "_background_pixel_value", "=", "(", "127", ",", "127", ",", "127", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "pairs", ")", ")", ":", "\n", "            ", "img1", ",", "img2", ",", "label", "=", "self", ".", "pairs", "[", "i", "]", "\n", "img1", "=", "os", ".", "path", ".", "join", "(", "img1", ".", "split", "(", "'_'", ")", "[", "0", "]", ",", "img1", ")", "\n", "img2", "=", "os", ".", "path", ".", "join", "(", "img2", ".", "split", "(", "'_'", ")", "[", "0", "]", ",", "img2", ")", "\n", "self", ".", "pairs", "[", "i", "]", "=", "(", "img1", ",", "img2", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.awa.AwALoader.get_heatmap_cachefn": [[53, 59], ["super().get_heatmap_cachefn", "img1.split", "img2.split"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.attributes.awa.AwALoader.get_heatmap_cachefn"], ["", "", "def", "get_heatmap_cachefn", "(", "self", ",", "img1", ",", "img2", "=", "None", ")", ":", "\n", "        ", "img1", "=", "img1", ".", "split", "(", "os", ".", "path", ".", "sep", ")", "[", "1", "]", "\n", "if", "img2", "is", "not", "None", ":", "\n", "            ", "img2", "=", "img2", ".", "split", "(", "os", ".", "path", ".", "sep", ")", "[", "1", "]", "\n", "\n", "", "return", "super", "(", "AwALoader", ",", "self", ")", ".", "get_heatmap_cachefn", "(", "img1", ",", "img2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.awa.AwALoader.sample_positive_pairs": [[60, 69], ["list", "numpy.random.choice.remove", "awa.AwALoader.images[].split", "len", "numpy.random.choice"], "methods", ["None"], ["", "def", "sample_positive_pairs", "(", "self", ",", "index", ")", ":", "\n", "        ", "cls", "=", "self", ".", "images", "[", "index", "]", ".", "split", "(", "os", ".", "path", ".", "sep", ")", "[", "0", "]", "\n", "candidates", "=", "list", "(", "self", ".", "cls2ims", "[", "cls", "]", ")", "\n", "candidates", ".", "remove", "(", "self", ".", "images", "[", "index", "]", ")", "\n", "if", "len", "(", "candidates", ")", ">", "self", ".", "max_num_heatmaps", ":", "\n", "            ", "candidates", "=", "np", ".", "random", ".", "choice", "(", "candidates", ",", "self", ".", "max_num_heatmaps", ",", "replace", "=", "False", ")", "\n", "\n", "", "inds", "=", "[", "self", ".", "image2index", "[", "c", "]", "for", "c", "in", "candidates", "]", "\n", "return", "inds", ",", "candidates", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.__init__": [[15, 71], ["datasets.data_loader.DataLoader.__init__", "numpy.arange", "torch.autograd.Variable", "torch.from_numpy", "data_loader.SaliencyDataLoader._masks.cuda", "numpy.zeros", "range", "torch.autograd.Variable", "generate_masks().astype", "range", "torch.from_numpy().float", "data_loader.SaliencyDataLoader._sliding_masks.cuda", "numpy.zeros", "range", "torch.autograd.Variable", "torchvision.transforms.Compose", "lime.lime_image.LimeImageExplainer", "numpy.ones", "range", "torch.from_numpy().float", "data_loader.SaliencyDataLoader._reference_sliding_masks.cuda", "torch.stack", "batch.cuda.cuda.cuda", "numpy.expand_dims.detach().cpu().numpy", "numpy.expand_dims", "generate_masks", "torch.from_numpy", "numpy.ones", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "tuple", "model.run_on_batch", "torch.from_numpy", "numpy.expand_dims.detach().cpu", "data_loader.SaliencyDataLoader._preprocess_transform", "numpy.expand_dims.detach"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.__init__", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.generate_masks", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.SaliencyModel.run_on_batch"], ["", "self", ".", "cache_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "datadir", ",", "'cache'", ",", "args", ".", "dataset", ",", "typedir", ",", "args", ".", "method", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "cache_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "cache_dir", ")", "\n", "\n", "", "if", "split", "==", "'train'", ":", "\n", "            ", "self", ".", "resized_cache_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "datadir", ",", "'cache'", ",", "args", ".", "dataset", ",", "'resized'", ",", "typedir", ",", "args", ".", "method", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "resized_cache_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "self", ".", "resized_cache_dir", ")", "\n", "\n", "", "", "self", ".", "transform", "=", "transform", "\n", "self", ".", "is_train", "=", "split", "==", "'train'", "\n", "self", ".", "loader", "=", "loader", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "pairs", "=", "[", "]", "\n", "if", "split", "!=", "'train'", ":", "\n", "            ", "images", "=", "set", "(", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "'pairs'", ",", "split", ",", "args", ".", "dataset", "+", "'_pairs.txt'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "f", ":", "\n", "                    ", "img1", ",", "img2", ",", "label", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "label", "=", "int", "(", "label", ")", "\n", "images", ".", "update", "(", "[", "img1", ",", "img2", "]", ")", "\n", "self", ".", "pairs", ".", "append", "(", "(", "img1", ",", "img2", ",", "label", ")", ")", "\n", "\n", "", "", "self", ".", "images", "=", "list", "(", "images", ")", "\n", "self", ".", "image2index", "=", "dict", "(", "zip", "(", "self", ".", "images", ",", "range", "(", "len", "(", "self", ".", "images", ")", ")", ")", ")", "\n", "\n", "", "self", ".", "method", "=", "args", ".", "method", "\n", "self", ".", "dataset", "=", "args", ".", "dataset", "\n", "self", ".", "fixed_ref", "=", "args", ".", "fixed_ref", "\n", "self", ".", "cuda", "=", "args", ".", "cuda", "\n", "self", ".", "mask_size", "=", "args", ".", "mask_size", "\n", "\n", "", "def", "get_typespace", "(", "self", ",", "anchor", ",", "pair", ")", ":", "\n", "        ", "return", "None", "\n", "\n", "", "def", "get_heatmap_cachefn", "(", "self", ",", "img1", ",", "img2", "=", "None", ")", ":", "\n", "        ", "if", "img2", "is", "None", ":", "\n", "            ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "resized_cache_dir", ",", "img1", "+", "'.npy'", ")", "\n", "", "else", ":", "\n", "            ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "cache_dir", ",", "img1", "+", "'+'", "+", "img2", "+", "'.npy'", ")", "\n", "\n", "", "", "def", "process_heatmap", "(", "self", ",", "heatmap", ")", ":", "\n", "        ", "return", "heatmap", "\n", "\n", "", "def", "load_heatmap", "(", "self", ",", "img1", ",", "img2", "=", "None", ",", "model", "=", "None", ",", "embeddings", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "method", "==", "'random'", ":", "\n", "            ", "heatmap", "=", "torch", ".", "rand", "(", "112", ",", "112", ")", "\n", "if", "self", ".", "cuda", ":", "\n", "                ", "heatmap", "=", "heatmap", ".", "cuda", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "outfn", "=", "self", ".", "get_heatmap_cachefn", "(", "img1", ",", "img2", ")", "\n", "heatmap", "=", "None", "\n", "if", "os", ".", "path", ".", "exists", "(", "outfn", ")", ":", "\n", "                ", "heatmap", "=", "torch", ".", "from_numpy", "(", "np", ".", "load", "(", "outfn", ")", ")", "\n", "if", "self", ".", "cuda", ":", "\n", "                    ", "heatmap", "=", "heatmap", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.load_image_data": [[73, 111], ["data_loader.SaliencyDataLoader.loader", "torch.autograd.Variable", "os.path.join", "[].copy", "cv2.medianBlur", "PIL.Image.fromarray", "data_loader.SaliencyDataLoader.transform", "img1.cuda.cuda.cuda", "torch.unsqueeze", "torch.autograd.Variable", "torch.autograd.Variable", "cv2.cvtColor", "PIL.Image.new", "data_loader.SaliencyDataLoader.transform", "data_loader.SaliencyDataLoader.transform", "img1_blur.cuda.cuda.cuda", "torch.unsqueeze", "background.cuda.cuda.cuda", "background.cuda.cuda.unsqueeze", "numpy.array"], "methods", ["None"], ["\n", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "imfn", "=", "os", ".", "path", ".", "join", "(", "self", ".", "impath", ",", "self", ".", "images", "[", "index", "]", "+", "'.jpg'", ")", "\n", "img", "=", "self", ".", "loader", "(", "imfn", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "return", "img", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "images", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.sample_positive_pairs": [[112, 114], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.compute_train_saliency_maps": [[115, 145], ["tqdm.tqdm.tqdm", "enumerate", "data_loader.SaliencyDataLoader.get_heatmap_cachefn", "os.path.exists", "data_loader.SaliencyDataLoader.sample_positive_pairs", "int", "range", "numpy.concatenate", "numpy.save", "len", "numpy.ceil", "torch.stack", "torch.autograd.Variable", "torch.stack().unsqueeze", "torch.nn.functional.interpolate().squeeze().cpu().numpy", "all_heatmaps.append", "reference_images.cuda.cuda.cuda", "model.embeddingnet", "len", "data_loader.SaliencyDataLoader.__getitem__", "torch.stack", "torch.nn.functional.interpolate().squeeze().cpu", "data_loader.SaliencyDataLoader.compute_heatmap", "torch.nn.functional.interpolate().squeeze", "zip", "torch.nn.functional.interpolate"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.attributes.awa.AwALoader.get_heatmap_cachefn", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.polyvore_outfits.OutfitsLoader.sample_positive_pairs", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.type_specific_network.ListModule.__getitem__", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.compute_heatmap"], []], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.compute_heatmap": [[146, 183], ["data_loader.SaliencyDataLoader.get_typespace", "data_loader.SaliencyDataLoader.load_image_data", "reference_embedding.unsqueeze.unsqueeze.unsqueeze", "data_loader.SaliencyDataLoader.load_image_data", "mask_explain", "mask_explain_var", "rise_explain", "rise_explain_var", "slide_explain", "slide_explain_var", "lime_explain", "ValueError", "NotImplementedError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.polyvore_outfits.OutfitsLoader.get_typespace", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.load_image_data", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.load_image_data", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.mask_explain", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.mask_explain_var", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.rise_explain", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.rise_explain_var", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.slide_explain", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.slide_explain_var", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.lime_explain"], []], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.process_heatmap": [[184, 194], ["torch.nn.functional.interpolate.view", "torch.nn.functional.interpolate.view", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate.size"], "methods", ["None"], []], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.load_heatmap": [[195, 208], ["super().load_heatmap", "data_loader.SaliencyDataLoader.compute_heatmap", "numpy.save", "data_loader.SaliencyDataLoader.process_heatmap", "numpy.save", "data_loader.SaliencyDataLoader.get_heatmap_cachefn", "data_loader.SaliencyDataLoader.cpu().numpy", "data_loader.SaliencyDataLoader.get_heatmap_cachefn", "heatmap2.cpu().numpy", "data_loader.SaliencyDataLoader.cpu", "heatmap2.cpu"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.load_heatmap", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.compute_heatmap", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.attributes.data_loader.AttributeDataLoader.process_heatmap", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.attributes.awa.AwALoader.get_heatmap_cachefn", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.attributes.awa.AwALoader.get_heatmap_cachefn"], []], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.get_masked_embeddings": [[209, 242], ["torch.stack().squeeze", "max", "torch.autograd.Variable", "int", "torch.autograd.Variable", "all_img1[].append", "torch.stack", "model.embeddingnet", "torch.from_numpy", "condition.cuda.cuda.cuda", "model.embeddingnet", "round", "torch.topk", "torch.zeros", "torch.topk", "torch.ones", "new_heatmap.cuda.cuda.cuda", "new_heatmap.cuda.cuda.view", "heatmap.size", "heatmap.size", "new_heatmap.cuda.cuda.expand_as", "numpy.ones", "heatmap.size", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.test": [[243, 277], ["len", "numpy.zeros", "numpy.zeros_like", "tqdm.tqdm.tqdm", "sklearn.auc", "sklearn.auc", "enumerate", "data_loader.SaliencyDataLoader.load_heatmap", "data_loader.SaliencyDataLoader.load_image_data", "data_loader.SaliencyDataLoader.load_image_data", "data_loader.SaliencyDataLoader.get_typespace", "data_loader.SaliencyDataLoader.get_masked_embeddings", "embed2.unsqueeze.unsqueeze.unsqueeze", "torch.nn.functional.cosine_similarity().cpu().numpy", "min", "min", "numpy.mean", "numpy.mean", "len", "len", "max", "max", "torch.nn.functional.cosine_similarity().cpu", "torch.nn.functional.cosine_similarity", "embed2.unsqueeze.unsqueeze.expand_as"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.load_heatmap", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.load_image_data", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.load_image_data", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.polyvore_outfits.OutfitsLoader.get_typespace", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.get_masked_embeddings"], []], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.polyvore_outfits.OutfitsLoader.__init__": [[26, 65], ["datasets.saliency.data_loader.SaliencyDataLoader.__init__", "os.path.join", "os.path.join", "os.path.join", "json.load", "set", "id2im.items", "polyvore_outfits.load_typespaces", "list", "dict", "open", "list", "zip", "set.add", "range", "set", "id2im[].add", "len"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.__init__", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.polyvore_outfits.load_typespaces"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "split", ",", "meta_data", ",", "transform", "=", "None", ")", ":", "\n", "        ", "super", "(", "OutfitsLoader", ",", "self", ")", ".", "__init__", "(", "args", ",", "split", ",", "transform", ")", "\n", "rootdir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "datadir", ",", "'polyvore_outfits'", ",", "args", ".", "polyvore_split", ")", "\n", "self", ".", "impath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "datadir", ",", "'polyvore_outfits'", ",", "'images'", ")", "\n", "\n", "data_json", "=", "os", ".", "path", ".", "join", "(", "rootdir", ",", "'%s.json'", "%", "split", ")", "\n", "outfit_data", "=", "json", ".", "load", "(", "open", "(", "data_json", ",", "'r'", ")", ")", "\n", "\n", "# get list of images and make a mapping used to quickly organize the data", "\n", "im2type", "=", "{", "}", "\n", "category2ims", "=", "{", "}", "\n", "imnames", "=", "set", "(", ")", "\n", "id2im", "=", "{", "}", "\n", "for", "outfit", "in", "outfit_data", ":", "\n", "            ", "outfit_id", "=", "outfit", "[", "'set_id'", "]", "\n", "for", "item", "in", "outfit", "[", "'items'", "]", ":", "\n", "                ", "im", "=", "item", "[", "'item_id'", "]", "\n", "imnames", ".", "add", "(", "im", ")", "\n", "category", "=", "meta_data", "[", "im", "]", "[", "'semantic_category'", "]", "\n", "im2type", "[", "im", "]", "=", "category", "\n", "if", "im", "not", "in", "id2im", ":", "\n", "                    ", "id2im", "[", "im", "]", "=", "set", "(", ")", "\n", "\n", "", "for", "item2", "in", "outfit", "[", "'items'", "]", ":", "\n", "                    ", "im2", "=", "item2", "[", "'item_id'", "]", "\n", "if", "im", "==", "im2", ":", "\n", "                        ", "continue", "\n", "\n", "", "id2im", "[", "im", "]", ".", "add", "(", "im2", ")", "\n", "\n", "", "", "", "pairs", "=", "[", "]", "\n", "for", "imid", ",", "outfit", "in", "id2im", ".", "items", "(", ")", ":", "\n", "            ", "id2im", "[", "imid", "]", "=", "list", "(", "outfit", ")", "\n", "\n", "", "self", ".", "im2outfit", "=", "id2im", "\n", "self", ".", "im2type", "=", "im2type", "\n", "self", ".", "typespaces", "=", "load_typespaces", "(", "rootdir", ")", "\n", "self", ".", "images", "=", "list", "(", "imnames", ")", "\n", "self", ".", "image2index", "=", "dict", "(", "zip", "(", "self", ".", "images", ",", "range", "(", "len", "(", "self", ".", "images", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.polyvore_outfits.OutfitsLoader.sample_positive_pairs": [[66, 73], ["len", "numpy.random.choice"], "methods", ["None"], ["", "def", "sample_positive_pairs", "(", "self", ",", "index", ")", ":", "\n", "        ", "candidates", "=", "self", ".", "im2outfit", "[", "self", ".", "images", "[", "index", "]", "]", "\n", "if", "len", "(", "candidates", ")", ">", "self", ".", "max_num_heatmaps", ":", "\n", "            ", "candidates", "=", "np", ".", "random", ".", "choice", "(", "candidates", ",", "self", ".", "max_num_heatmaps", ",", "replace", "=", "False", ")", "\n", "\n", "", "inds", "=", "[", "self", ".", "image2index", "[", "c", "]", "for", "c", "in", "candidates", "]", "\n", "return", "inds", ",", "candidates", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.polyvore_outfits.OutfitsLoader.get_typespace": [[74, 84], ["None"], "methods", ["None"], ["", "def", "get_typespace", "(", "self", ",", "im1", ",", "im2", ")", ":", "\n", "        ", "\"\"\" Returns the index of the type specific embedding\n        for the pair of item types provided as input\n        \"\"\"", "\n", "anchor", ",", "pair", "=", "self", ".", "im2type", "[", "im1", "]", ",", "self", ".", "im2type", "[", "im2", "]", "\n", "query", "=", "(", "anchor", ",", "pair", ")", "\n", "if", "query", "not", "in", "self", ".", "typespaces", ":", "\n", "            ", "query", "=", "(", "pair", ",", "anchor", ")", "\n", "\n", "", "return", "self", ".", "typespaces", "[", "query", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.polyvore_outfits.load_typespaces": [[7, 24], ["os.path.join", "pickle.load", "enumerate", "open"], "function", ["None"], ["def", "load_typespaces", "(", "rootdir", ")", ":", "\n", "    ", "\"\"\" loads a mapping of pairs of types to the embedding used to\n        compare them\n\n        rand_typespaces: Boolean indicator of randomly assigning type\n                         specific spaces to their embedding\n        num_rand_embed: number of embeddings to use when\n                        rand_typespaces is true\n    \"\"\"", "\n", "typespace_fn", "=", "os", ".", "path", ".", "join", "(", "rootdir", ",", "'typespaces.p'", ")", "\n", "typespaces", "=", "pickle", ".", "load", "(", "open", "(", "typespace_fn", ",", "'rb'", ")", ")", "\n", "ts", "=", "{", "}", "\n", "for", "index", ",", "t", "in", "enumerate", "(", "typespaces", ")", ":", "\n", "        ", "ts", "[", "t", "]", "=", "index", "\n", "\n", "", "typespaces", "=", "ts", "\n", "return", "typespaces", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.attributes.awa.AwALoader.__init__": [[6, 72], ["datasets.attributes.data_loader.AttributeDataLoader.__init__", "os.path.join", "os.path.join", "len", "enumerate", "dict", "range", "open", "open", "open", "open", "enumerate", "os.listdir", "os.path.join", "zip", "len", "os.path.join", "os.path.join", "os.path.join", "line.strip.strip.strip", "os.path.join", "line.strip.strip.strip", "os.path.join", "line.strip.strip.strip", "os.path.join", "line.strip.strip.strip", "os.path.join", "range", "classes2attr.append", "classes.append", "predicates.append", "splitclasses.append", "classes.index", "image_id.split", "image_id.split", "len", "os.path.join.split", "os.path.join.split", "im.split", "numpy.nonzero", "line.strip.strip.split", "line.strip.strip.split", "int", "line.strip.strip.split"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "split", ",", "transform", "=", "None", ")", ":", "\n", "        ", "super", "(", "AwALoader", ",", "self", ")", ".", "__init__", "(", "args", ",", "split", ",", "transform", ")", "\n", "awa_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "datadir", ",", "'Animals_with_Attributes2'", ")", "\n", "self", ".", "impath", "=", "os", ".", "path", ".", "join", "(", "awa_dir", ",", "'JPEGImages'", ")", "\n", "if", "split", "==", "'train'", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "awa_dir", ",", "'classes.txt'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "classes", "=", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "                    ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", ":", "\n", "                        ", "classes", ".", "append", "(", "line", ".", "split", "(", ")", "[", "1", "]", ")", "\n", "\n", "", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "awa_dir", ",", "'predicates.txt'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "predicates", "=", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "                    ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", ":", "\n", "                        ", "predicates", ".", "append", "(", "line", ".", "split", "(", ")", "[", "1", "]", ")", "\n", "\n", "", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "awa_dir", ",", "split", "+", "'classes.txt'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "splitclasses", "=", "[", "]", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                    ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", ":", "\n", "                        ", "splitclasses", ".", "append", "(", "line", ")", "\n", "\n", "", "", "", "images", "=", "[", "]", "\n", "cls2ims", "=", "{", "}", "\n", "for", "i", ",", "cls", "in", "enumerate", "(", "splitclasses", ")", ":", "\n", "                ", "imlist", "=", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "impath", ",", "cls", ")", ")", "\n", "imlist", "=", "[", "im", ".", "split", "(", "'.'", ")", "[", "0", "]", "for", "im", "in", "imlist", "]", "\n", "cls2ims", "[", "cls", "]", "=", "[", "os", ".", "path", ".", "join", "(", "image_id", ".", "split", "(", "'_'", ")", "[", "0", "]", ",", "image_id", ")", "for", "image_id", "in", "imlist", "]", "\n", "images", "+=", "imlist", "\n", "\n", "", "np", ".", "random", ".", "shuffle", "(", "images", ")", "\n", "self", ".", "cls2ims", "=", "cls2ims", "\n", "self", ".", "images", "=", "images", "\n", "\n", "", "self", ".", "images", "=", "[", "os", ".", "path", ".", "join", "(", "image_id", ".", "split", "(", "'_'", ")", "[", "0", "]", ",", "image_id", ")", "for", "image_id", "in", "self", ".", "images", "]", "\n", "self", ".", "image2index", "=", "dict", "(", "zip", "(", "self", ".", "images", ",", "range", "(", "len", "(", "self", ".", "images", ")", ")", ")", ")", "\n", "self", ".", "_background_pixel_value", "=", "(", "127", ",", "127", ",", "127", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "pairs", ")", ")", ":", "\n", "            ", "img1", ",", "img2", ",", "label", "=", "self", ".", "pairs", "[", "i", "]", "\n", "img1", "=", "os", ".", "path", ".", "join", "(", "img1", ".", "split", "(", "'_'", ")", "[", "0", "]", ",", "img1", ")", "\n", "img2", "=", "os", ".", "path", ".", "join", "(", "img2", ".", "split", "(", "'_'", ")", "[", "0", "]", ",", "img2", ")", "\n", "self", ".", "pairs", "[", "i", "]", "=", "(", "img1", ",", "img2", ",", "label", ")", "\n", "\n", "", "", "def", "get_heatmap_cachefn", "(", "self", ",", "img1", ",", "img2", "=", "None", ")", ":", "\n", "        ", "img1", "=", "img1", ".", "split", "(", "os", ".", "path", ".", "sep", ")", "[", "1", "]", "\n", "if", "img2", "is", "not", "None", ":", "\n", "            ", "img2", "=", "img2", ".", "split", "(", "os", ".", "path", ".", "sep", ")", "[", "1", "]", "\n", "\n", "", "return", "super", "(", "AwALoader", ",", "self", ")", ".", "get_heatmap_cachefn", "(", "img1", ",", "img2", ")", "\n", "\n", "", "def", "sample_positive_pairs", "(", "self", ",", "index", ")", ":", "\n", "        ", "cls", "=", "self", ".", "images", "[", "index", "]", ".", "split", "(", "os", ".", "path", ".", "sep", ")", "[", "0", "]", "\n", "candidates", "=", "list", "(", "self", ".", "cls2ims", "[", "cls", "]", ")", "\n", "candidates", ".", "remove", "(", "self", ".", "images", "[", "index", "]", ")", "\n", "if", "len", "(", "candidates", ")", ">", "self", ".", "max_num_heatmaps", ":", "\n", "            ", "candidates", "=", "np", ".", "random", ".", "choice", "(", "candidates", ",", "self", ".", "max_num_heatmaps", ",", "replace", "=", "False", ")", "\n", "\n", "", "inds", "=", "[", "self", ".", "image2index", "[", "c", "]", "for", "c", "in", "candidates", "]", "\n", "return", "inds", ",", "candidates", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.attributes.awa.AwALoader.get_heatmap_cachefn": [[73, 79], ["super().get_heatmap_cachefn", "img1.split", "img2.split"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.attributes.awa.AwALoader.get_heatmap_cachefn"], []], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.attributes.data_loader.AttributeDataLoader.__init__": [[20, 31], ["datasets.data_loader.DataLoader.__init__"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.__init__"], ["            ", "self", ".", "resized_cache_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "datadir", ",", "'cache'", ",", "args", ".", "dataset", ",", "'resized'", ",", "typedir", ",", "args", ".", "method", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "resized_cache_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "self", ".", "resized_cache_dir", ")", "\n", "\n", "", "", "self", ".", "transform", "=", "transform", "\n", "self", ".", "is_train", "=", "split", "==", "'train'", "\n", "self", ".", "loader", "=", "loader", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "pairs", "=", "[", "]", "\n", "if", "split", "!=", "'train'", ":", "\n", "            ", "images", "=", "set", "(", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "'pairs'", ",", "split", ",", "args", ".", "dataset", "+", "'_pairs.txt'", ")", ",", "'r'", ")", "as", "f", ":", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.attributes.data_loader.AttributeDataLoader.process_heatmap": [[32, 45], ["heatmap.view.view.view", "torch.nn.functional.interpolate", "heatmap.view.view.size", "heatmap.view.view.view", "heatmap.view.view.view"], "methods", ["None"], ["                ", "for", "line", "in", "f", ":", "\n", "                    ", "img1", ",", "img2", ",", "label", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "label", "=", "int", "(", "label", ")", "\n", "images", ".", "update", "(", "[", "img1", ",", "img2", "]", ")", "\n", "self", ".", "pairs", ".", "append", "(", "(", "img1", ",", "img2", ",", "label", ")", ")", "\n", "\n", "", "", "self", ".", "images", "=", "list", "(", "images", ")", "\n", "self", ".", "image2index", "=", "dict", "(", "zip", "(", "self", ".", "images", ",", "range", "(", "len", "(", "self", ".", "images", ")", ")", ")", ")", "\n", "\n", "", "self", ".", "method", "=", "args", ".", "method", "\n", "self", ".", "dataset", "=", "args", ".", "dataset", "\n", "self", ".", "fixed_ref", "=", "args", ".", "fixed_ref", "\n", "self", ".", "cuda", "=", "args", ".", "cuda", "\n", "self", ".", "mask_size", "=", "args", ".", "mask_size", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.attributes.data_loader.AttributeDataLoader.test": [[46, 56], ["attribute_scores.cpu().numpy.cpu().numpy.cpu().numpy", "range", "numpy.mean", "attribute_scores.cpu().numpy.cpu().numpy.cpu", "numpy.sum", "ap.append", "sklearn.average_precision_score"], "methods", ["None"], ["\n", "", "def", "get_typespace", "(", "self", ",", "anchor", ",", "pair", ")", ":", "\n", "        ", "return", "None", "\n", "\n", "", "def", "get_heatmap_cachefn", "(", "self", ",", "img1", ",", "img2", "=", "None", ")", ":", "\n", "        ", "if", "img2", "is", "None", ":", "\n", "            ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "resized_cache_dir", ",", "img1", "+", "'.npy'", ")", "\n", "", "else", ":", "\n", "            ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "cache_dir", ",", "img1", "+", "'+'", "+", "img2", "+", "'.npy'", ")", "\n", "\n", "", "", "def", "process_heatmap", "(", "self", ",", "heatmap", ")", ":", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.attributes.data_loader.AttributeDataLoader.__getitem__": [[57, 79], ["data_loader.AttributeDataLoader.loader", "numpy.zeros", "len", "os.path.join", "data_loader.AttributeDataLoader.transform", "numpy.zeros", "data_loader.AttributeDataLoader.load_heatmap", "min", "numpy.zeros", "len"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.load_heatmap"], ["        ", "return", "heatmap", "\n", "\n", "", "def", "load_heatmap", "(", "self", ",", "img1", ",", "img2", "=", "None", ",", "model", "=", "None", ",", "embeddings", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "method", "==", "'random'", ":", "\n", "            ", "heatmap", "=", "torch", ".", "rand", "(", "112", ",", "112", ")", "\n", "if", "self", ".", "cuda", ":", "\n", "                ", "heatmap", "=", "heatmap", ".", "cuda", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "outfn", "=", "self", ".", "get_heatmap_cachefn", "(", "img1", ",", "img2", ")", "\n", "heatmap", "=", "None", "\n", "if", "os", ".", "path", ".", "exists", "(", "outfn", ")", ":", "\n", "                ", "heatmap", "=", "torch", ".", "from_numpy", "(", "np", ".", "load", "(", "outfn", ")", ")", "\n", "if", "self", ".", "cuda", ":", "\n", "                    ", "heatmap", "=", "heatmap", ".", "cuda", "(", ")", "\n", "\n", "", "", "", "return", "self", ".", "process_heatmap", "(", "heatmap", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "imfn", "=", "os", ".", "path", ".", "join", "(", "self", ".", "impath", ",", "self", ".", "images", "[", "index", "]", "+", "'.jpg'", ")", "\n", "img", "=", "self", ".", "loader", "(", "imfn", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.attributes.polyvore_outfits.OutfitsLoader.__init__": [[7, 32], ["datasets.attributes.data_loader.AttributeDataLoader.__init__", "os.path.join", "os.path.join", "os.path.join", "json.load", "os.path.join", "json.load", "len", "os.path.join", "os.path.join", "json.load", "set", "list", "dict", "open", "open", "line.strip", "open", "zip", "open().readlines", "range", "set.add", "len", "open", "len"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.__init__"], ["def", "load_typespaces", "(", "rootdir", ")", ":", "\n", "    ", "\"\"\" loads a mapping of pairs of types to the embedding used to\n        compare them\n\n        rand_typespaces: Boolean indicator of randomly assigning type\n                         specific spaces to their embedding\n        num_rand_embed: number of embeddings to use when\n                        rand_typespaces is true\n    \"\"\"", "\n", "typespace_fn", "=", "os", ".", "path", ".", "join", "(", "rootdir", ",", "'typespaces.p'", ")", "\n", "typespaces", "=", "pickle", ".", "load", "(", "open", "(", "typespace_fn", ",", "'rb'", ")", ")", "\n", "ts", "=", "{", "}", "\n", "for", "index", ",", "t", "in", "enumerate", "(", "typespaces", ")", ":", "\n", "        ", "ts", "[", "t", "]", "=", "index", "\n", "\n", "", "typespaces", "=", "ts", "\n", "return", "typespaces", "\n", "\n", "", "class", "OutfitsLoader", "(", "SaliencyDataLoader", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "args", ",", "split", ",", "meta_data", ",", "transform", "=", "None", ")", ":", "\n", "        ", "super", "(", "OutfitsLoader", ",", "self", ")", ".", "__init__", "(", "args", ",", "split", ",", "transform", ")", "\n", "rootdir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "datadir", ",", "'polyvore_outfits'", ",", "args", ".", "polyvore_split", ")", "\n", "self", ".", "impath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "datadir", ",", "'polyvore_outfits'", ",", "'images'", ")", "\n", "\n", "data_json", "=", "os", ".", "path", ".", "join", "(", "rootdir", ",", "'%s.json'", "%", "split", ")", "\n", "outfit_data", "=", "json", ".", "load", "(", "open", "(", "data_json", ",", "'r'", ")", ")", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.SaliencyModel.__init__": [[10, 13], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ")", ":", "\n", "        ", "self", ".", "embeddingnet", "=", "model", "\n", "self", ".", "input_size", "=", "(", "112", ",", "112", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.SaliencyModel.run_on_batch": [[14, 27], ["torch.nn.functional.cosine_similarity().squeeze", "saliency_maps.SaliencyModel.embeddingnet", "isinstance", "saliency_maps.SaliencyModel.embeddingnet", "torch.autograd.Variable", "torch.nn.functional.cosine_similarity", "torch.from_numpy", "condition.cuda.cuda.cuda", "e.expand_as", "numpy.ones", "len"], "methods", ["None"], ["", "def", "run_on_batch", "(", "self", ",", "x", ",", "e", ",", "condition", ")", ":", "\n", "        ", "if", "condition", "is", "None", ":", "\n", "            ", "m", "=", "self", ".", "embeddingnet", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "if", "isinstance", "(", "condition", ",", "int", ")", ":", "\n", "                ", "condition", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "np", ".", "ones", "(", "len", "(", "x", ")", ",", "np", ".", "int64", ")", "*", "condition", ")", ")", "\n", "if", "x", ".", "is_cuda", ":", "\n", "                    ", "condition", "=", "condition", ".", "cuda", "(", ")", "\n", "\n", "", "", "m", "=", "self", ".", "embeddingnet", "(", "x", ",", "condition", ")", "\n", "\n", "", "sim", "=", "torch", ".", "nn", ".", "functional", ".", "cosine_similarity", "(", "m", ".", "data", ",", "e", ".", "expand_as", "(", "m", ")", ")", ".", "squeeze", "(", ")", "\n", "return", "sim", "#[1:] - sim[0]", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.tv_norm": [[28, 33], ["torch.mean", "torch.mean", "torch.abs().pow", "torch.abs().pow", "torch.abs", "torch.abs"], "function", ["None"], ["", "", "def", "tv_norm", "(", "input", ",", "tv_beta", ")", ":", "\n", "    ", "img", "=", "input", "[", "0", ",", "0", ",", ":", "]", "\n", "row_grad", "=", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "(", "img", "[", ":", "-", "1", ",", ":", "]", "-", "img", "[", "1", ":", ",", ":", "]", ")", ")", ".", "pow", "(", "tv_beta", ")", ")", "\n", "col_grad", "=", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "(", "img", "[", ":", ",", ":", "-", "1", "]", "-", "img", "[", ":", ",", "1", ":", "]", ")", ")", ".", "pow", "(", "tv_beta", ")", ")", "\n", "return", "row_grad", "+", "col_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.mask_inference": [[34, 54], ["upsampled_mask.expand.expand", "numpy.zeros", "cv2.randn", "torch.autograd.Variable", "upsampled_mask.expand.size", "upsampled_mask.expand.size", "img.mul", "img1_blur.mul", "torch.from_numpy().cuda", "model.embeddingnet().squeeze().unsqueeze", "model.embeddingnet().squeeze().unsqueeze", "torch.from_numpy", "model.embeddingnet().squeeze", "model.embeddingnet().squeeze", "model.embeddingnet", "model.embeddingnet"], "function", ["None"], ["", "def", "mask_inference", "(", "upsampled_mask", ",", "img", ",", "img1_blur", ",", "model", ",", "condition", ")", ":", "\n", "# The single channel mask is used with an RGB image,", "\n", "# so the mask is duplicated to have 3 channel,", "\n", "    ", "upsampled_mask", "=", "upsampled_mask", ".", "expand", "(", "1", ",", "3", ",", "upsampled_mask", ".", "size", "(", "2", ")", ",", "\n", "upsampled_mask", ".", "size", "(", "3", ")", ")", "\n", "\n", "# Use the mask to perturbated the input image.", "\n", "perturbated_input", "=", "img", ".", "mul", "(", "upsampled_mask", ")", "+", "img1_blur", ".", "mul", "(", "1", "-", "upsampled_mask", ")", "\n", "\n", "noise", "=", "np", ".", "zeros", "(", "(", "1", ",", "3", ",", "112", ",", "112", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "cv2", ".", "randn", "(", "noise", ",", "0", ",", "0.2", ")", "\n", "noise", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "noise", ")", ".", "cuda", "(", ")", ")", "\n", "perturbated_input", "=", "perturbated_input", "+", "noise", "\n", "if", "condition", "is", "None", ":", "\n", "        ", "e", "=", "model", ".", "embeddingnet", "(", "perturbated_input", ")", ".", "squeeze", "(", ")", ".", "unsqueeze", "(", "0", ")", "\n", "", "else", ":", "\n", "        ", "e", "=", "model", ".", "embeddingnet", "(", "perturbated_input", ",", "condition", ")", ".", "squeeze", "(", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "return", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.mask_explain_var": [[55, 89], ["numpy.ones", "torch.from_numpy", "torch.autograd.Variable", "torch.optim.Adam", "range", "mask_init.cuda.cuda", "torch.autograd.Variable", "torch.nn.functional.interpolate", "saliency_maps.mask_inference", "saliency_maps.mask_inference", "torch.nn.functional.cosine_similarity().squeeze", "torch.optim.Adam.zero_grad", "loss.backward", "torch.optim.Adam.step", "torch.autograd.Variable.data.clamp_", "torch.from_numpy", "condition.cuda.cuda", "numpy.array", "torch.nn.functional.cosine_similarity", "torch.mean", "saliency_maps.tv_norm", "torch.abs"], "function", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.mask_inference", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.mask_inference", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.tv_norm"], ["", "def", "mask_explain_var", "(", "model", ",", "img", ",", "img1_blur", ",", "img2", ",", "img2_blur", ",", "mask_size", ",", "condition", ")", ":", "\n", "    ", "tv_beta", "=", "3", "\n", "learning_rate", "=", "0.1", "\n", "max_iterations", "=", "500", "\n", "l1_coeff", "=", "0.01", "\n", "tv_coeff", "=", "0.2", "\n", "mask_init", "=", "np", ".", "ones", "(", "(", "1", ",", "1", ",", "mask_size", ",", "mask_size", "*", "2", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "mask_init", "=", "torch", ".", "from_numpy", "(", "mask_init", ")", "\n", "if", "img", ".", "is_cuda", ":", "\n", "        ", "mask_init", "=", "mask_init", ".", "cuda", "(", ")", "\n", "\n", "", "mask", "=", "Variable", "(", "mask_init", ",", "requires_grad", "=", "True", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "[", "mask", "]", ",", "lr", "=", "learning_rate", ")", "\n", "if", "condition", "is", "not", "None", ":", "\n", "        ", "condition", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "[", "condition", "]", ",", "np", ".", "int64", ")", ")", ")", "\n", "if", "img", ".", "is_cuda", ":", "\n", "            ", "condition", "=", "condition", ".", "cuda", "(", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "max_iterations", ")", ":", "\n", "        ", "upsampled_mask", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "mask", ",", "size", "=", "(", "112", ",", "112", "*", "2", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "e", "=", "mask_inference", "(", "upsampled_mask", "[", ":", ",", ":", ",", ":", ",", ":", "112", "]", ",", "img", ",", "img1_blur", ",", "model", ",", "condition", ")", "\n", "embed1", "=", "mask_inference", "(", "upsampled_mask", "[", ":", ",", ":", ",", ":", ",", "112", ":", "]", ",", "img2", ",", "img2_blur", ",", "model", ",", "condition", ")", "\n", "outputs", "=", "torch", ".", "nn", ".", "functional", ".", "cosine_similarity", "(", "embed1", ",", "e", ")", ".", "squeeze", "(", ")", "\n", "loss", "=", "l1_coeff", "*", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "1", "-", "mask", ")", ")", "+", "tv_coeff", "*", "tv_norm", "(", "mask", ",", "tv_beta", ")", "+", "outputs", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Optional: clamping seems to give better results", "\n", "mask", ".", "data", ".", "clamp_", "(", "0", ",", "1", ")", "\n", "\n", "", "return", "1", "-", "mask", ".", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.mask_explain": [[90, 125], ["numpy.ones", "torch.from_numpy", "torch.autograd.Variable", "torch.optim.Adam", "range", "mask_init.cuda.cuda", "torch.autograd.Variable", "torch.nn.functional.interpolate", "saliency_maps.mask_inference", "torch.nn.functional.cosine_similarity().squeeze", "torch.optim.Adam.zero_grad", "loss.backward", "torch.optim.Adam.step", "torch.autograd.Variable.data.clamp_", "torch.from_numpy", "condition.cuda.cuda", "numpy.array", "torch.nn.functional.cosine_similarity", "torch.mean", "saliency_maps.tv_norm", "torch.abs"], "function", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.mask_inference", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.tv_norm"], ["", "def", "mask_explain", "(", "model", ",", "img", ",", "img1_blur", ",", "embed1", ",", "mask_size", ",", "condition", ")", ":", "\n", "    ", "tv_beta", "=", "3", "\n", "learning_rate", "=", "0.1", "\n", "max_iterations", "=", "500", "\n", "l1_coeff", "=", "0.01", "\n", "tv_coeff", "=", "0.2", "\n", "mask_init", "=", "np", ".", "ones", "(", "(", "1", ",", "1", ",", "mask_size", ",", "mask_size", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "mask_init", "=", "torch", ".", "from_numpy", "(", "mask_init", ")", "\n", "if", "img", ".", "is_cuda", ":", "\n", "        ", "mask_init", "=", "mask_init", ".", "cuda", "(", ")", "\n", "\n", "", "mask", "=", "Variable", "(", "mask_init", ",", "requires_grad", "=", "True", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "[", "mask", "]", ",", "lr", "=", "learning_rate", ")", "\n", "if", "condition", "is", "not", "None", ":", "\n", "        ", "condition", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "[", "condition", "]", ",", "np", ".", "int64", ")", ")", ")", "\n", "if", "img", ".", "is_cuda", ":", "\n", "            ", "condition", "=", "condition", ".", "cuda", "(", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "max_iterations", ")", ":", "\n", "        ", "upsampled_mask", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "mask", ",", "size", "=", "(", "112", ",", "112", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "# The single channel mask is used with an RGB image,", "\n", "# so the mask is duplicated to have 3 channel,", "\n", "e", "=", "mask_inference", "(", "upsampled_mask", ",", "img", ",", "img1_blur", ",", "model", ",", "condition", ")", "\n", "outputs", "=", "torch", ".", "nn", ".", "functional", ".", "cosine_similarity", "(", "embed1", ",", "e", ")", ".", "squeeze", "(", ")", "\n", "loss", "=", "l1_coeff", "*", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "1", "-", "mask", ")", ")", "+", "tv_coeff", "*", "tv_norm", "(", "mask", ",", "tv_beta", ")", "+", "outputs", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Optional: clamping seems to give better results", "\n", "mask", ".", "data", ".", "clamp_", "(", "0", ",", "1", ")", "\n", "\n", "", "return", "1", "-", "mask", ".", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.generate_masks": [[126, 145], ["numpy.ceil", "grid.astype.astype", "numpy.empty", "tqdm.tqdm", "masks.reshape.reshape", "numpy.random.rand", "range", "numpy.random.randint", "numpy.random.randint", "numpy.array", "skimage.transform.resize"], "function", ["None"], ["", "def", "generate_masks", "(", "N", ",", "s", ",", "p1", ")", ":", "\n", "    ", "input_size", "=", "(", "112", ",", "112", ")", "\n", "cell_size", "=", "np", ".", "ceil", "(", "np", ".", "array", "(", "input_size", ")", "/", "s", ")", "\n", "up_size", "=", "(", "s", "+", "1", ")", "*", "cell_size", "\n", "\n", "grid", "=", "np", ".", "random", ".", "rand", "(", "N", ",", "s", ",", "s", ")", "<", "p1", "\n", "grid", "=", "grid", ".", "astype", "(", "'float32'", ")", "\n", "\n", "masks", "=", "np", ".", "empty", "(", "(", "N", ",", "112", ",", "112", ")", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "N", ")", ",", "desc", "=", "'Generating masks'", ")", ":", "\n", "# Random shifts", "\n", "        ", "x", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "cell_size", "[", "0", "]", ")", "\n", "y", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "cell_size", "[", "1", "]", ")", "\n", "# Linear upsampling and cropping", "\n", "masks", "[", "i", ",", ":", ",", ":", "]", "=", "resize", "(", "grid", "[", "i", "]", ",", "up_size", ",", "order", "=", "1", ",", "mode", "=", "'reflect'", ",", "\n", "anti_aliasing", "=", "False", ")", "[", "x", ":", "x", "+", "input_size", "[", "0", "]", ",", "y", ":", "y", "+", "input_size", "[", "1", "]", "]", "\n", "\n", "", "masks", "=", "masks", ".", "reshape", "(", "-", "1", ",", "1", ",", "112", ",", "112", ")", "\n", "return", "masks", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.rise_explain": [[146, 163], ["im.repeat", "range", "torch.cat().view", "torch.sum().reshape", "masks.squeeze().mean", "masks.expand_as", "torch.cat", "torch.cat().view.append", "torch.cat", "torch.sum", "masks.squeeze", "model.run_on_batch", "masks.reshape", "min", "min"], "function", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.SaliencyModel.run_on_batch"], ["", "def", "rise_explain", "(", "model", ",", "im", ",", "embed1", ",", "masks", ",", "N", ",", "p1", ",", "condition", ")", ":", "\n", "    ", "preds", "=", "[", "]", "\n", "# Make sure multiplication is being done for correct axes", "\n", "batch_size", "=", "500", "\n", "inp", "=", "im", ".", "repeat", "(", "N", ",", "1", ",", "1", ",", "1", ")", "\n", "masked", "=", "inp", "*", "masks", ".", "expand_as", "(", "inp", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "N", ",", "batch_size", ")", ":", "\n", "        ", "masked_input", "=", "torch", ".", "cat", "(", "(", "im", ",", "masked", "[", "i", ":", "min", "(", "i", "+", "batch_size", ",", "N", ")", "]", ")", ",", "0", ")", "\n", "#preds.append(model.run_on_batch(masked_input, embed1, condition).data)", "\n", "preds", ".", "append", "(", "model", ".", "run_on_batch", "(", "masked", "[", "i", ":", "min", "(", "i", "+", "batch_size", ",", "N", ")", "]", ",", "embed1", ",", "condition", ")", ".", "data", ")", "\n", "\n", "", "preds", "=", "torch", ".", "cat", "(", "preds", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "sal", "=", "torch", ".", "sum", "(", "preds", "*", "masks", ".", "reshape", "(", "N", ",", "-", "1", ")", ",", "dim", "=", "0", ")", ".", "reshape", "(", "112", ",", "112", ")", "\n", "times_location_sampled", "=", "masks", ".", "squeeze", "(", ")", ".", "mean", "(", "0", ")", "\n", "sal", "/=", "times_location_sampled", "\n", "#sal = sal / N / p1", "\n", "return", "sal", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.lime_explain": [[164, 175], ["functools.partial", "lime_explainer.explain_instance", "sorted", "numpy.vectorize", "np.vectorize.", "torch.Tensor"], "function", ["None"], ["", "def", "lime_explain", "(", "model", ",", "img_t", ",", "embed1", ",", "condition", ",", "lime_explainer", ",", "score_fn", ",", "preprocess_transform", ",", "N_lime", "=", "1000", ")", ":", "\n", "# Denormalize image", "\n", "    ", "cur_img", "=", "(", "(", "img_t", "[", "0", "]", "+", "1", ")", "/", "2", "*", "255.", ")", ".", "clamp", "(", "0", ",", "255", ")", ".", "byte", "(", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "batch_predict", "=", "partial", "(", "score_fn", ",", "model", ",", "embed1", ",", "condition", ")", "\n", "explanation", "=", "lime_explainer", ".", "explain_instance", "(", "cur_img", ",", "batch_predict", ",", "top_labels", "=", "1", ",", "\n", "hide_color", "=", "0", ",", "num_samples", "=", "N_lime", ")", "\n", "le", "=", "sorted", "(", "explanation", ".", "local_exp", "[", "0", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "# Sort (region_id, region_saliency) by id", "\n", "assign_saliency", "=", "np", ".", "vectorize", "(", "lambda", "x", ":", "le", "[", "x", "]", "[", "1", "]", ")", "# Function that returns region saliency given id", "\n", "sal", "=", "assign_saliency", "(", "explanation", ".", "segments", ")", "# Assign saliency to each pixel", "\n", "sal", "=", "torch", ".", "Tensor", "(", "sal", ")", "\n", "return", "sal", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.slide_explain": [[176, 190], ["len", "int", "im.repeat", "range", "masks.expand_as", "torch.cat", "preds.append", "torch.cat().view", "model.run_on_batch", "torch.cat", "min"], "function", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.SaliencyModel.run_on_batch"], ["", "def", "slide_explain", "(", "model", ",", "im", ",", "embed1", ",", "masks", ",", "condition", ")", ":", "\n", "    ", "preds", "=", "[", "]", "\n", "# Make sure multiplication is being done for correct axes", "\n", "batch_size", "=", "500", "\n", "N", "=", "len", "(", "masks", ")", "\n", "side", "=", "int", "(", "N", "**", "0.5", ")", "\n", "assert", "N", "==", "side", "**", "2", "\n", "inp", "=", "im", ".", "repeat", "(", "N", ",", "1", ",", "1", ",", "1", ")", "\n", "masked", "=", "inp", "*", "masks", ".", "expand_as", "(", "inp", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "N", ",", "batch_size", ")", ":", "\n", "        ", "masked_input", "=", "torch", ".", "cat", "(", "(", "im", ",", "masked", "[", "i", ":", "min", "(", "i", "+", "batch_size", ",", "N", ")", "]", ")", ",", "0", ")", "\n", "preds", ".", "append", "(", "model", ".", "run_on_batch", "(", "masked_input", ",", "embed1", ",", "condition", ")", ".", "data", ")", "\n", "", "sal", "=", "1", "-", "torch", ".", "cat", "(", "preds", ")", ".", "view", "(", "side", ",", "side", ")", "\n", "return", "sal", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.rise_explain_var": [[192, 232], ["im2.repeat", "im.repeat", "masks.squeeze().mean", "enumerate", "torch.stack().mean", "len", "torch.from_numpy", "torch.from_numpy", "masks[].expand_as", "masks.expand_as", "embed1.unsqueeze.unsqueeze", "range", "torch.cat().view", "torch.sum().reshape", "torch.stack().mean.append", "torch.autograd.Variable", "torch.autograd.Variable", "model.embeddingnet", "model.embeddingnet", "masks.squeeze", "torch.cat().view.append", "torch.stack", "numpy.ones", "numpy.ones", "torch.from_numpy.cuda", "torch.from_numpy.cuda", "torch.cat", "torch.sum", "model.run_on_batch", "masks.reshape", "min"], "function", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.SaliencyModel.run_on_batch"], ["", "def", "rise_explain_var", "(", "model", ",", "im", ",", "im2", ",", "masks", ",", "N", ",", "p1", ",", "condition", ")", ":", "\n", "# Make sure multiplication is being done for correct axes", "\n", "    ", "batch_size", "=", "500", "\n", "\n", "# typically K < batch_size", "\n", "K", "=", "len", "(", "masks", ")", "-", "N", "\n", "query_condition", "=", "None", "\n", "if", "condition", "is", "not", "None", ":", "\n", "        ", "reference_condition", "=", "torch", ".", "from_numpy", "(", "np", ".", "ones", "(", "K", ",", "np", ".", "int64", ")", "*", "condition", ")", "\n", "query_condition", "=", "torch", ".", "from_numpy", "(", "np", ".", "ones", "(", "batch_size", ",", "np", ".", "int64", ")", "*", "condition", ")", "\n", "if", "im", ".", "is_cuda", ":", "\n", "            ", "reference_condition", ",", "query_condition", "=", "reference_condition", ".", "cuda", "(", ")", ",", "query_condition", ".", "cuda", "(", ")", "\n", "", "reference_condition", ",", "query_condition", "=", "Variable", "(", "reference_condition", ")", ",", "Variable", "(", "query_condition", ")", "\n", "\n", "", "im2_ref", "=", "im2", ".", "repeat", "(", "K", ",", "1", ",", "1", ",", "1", ")", "\n", "im2_masked", "=", "im2_ref", "*", "masks", "[", ":", "K", "]", ".", "expand_as", "(", "im2_ref", ")", "\n", "if", "condition", "is", "None", ":", "\n", "        ", "all_embed", "=", "model", ".", "embeddingnet", "(", "im2_masked", ")", ".", "data", "\n", "", "else", ":", "\n", "        ", "all_embed", "=", "model", ".", "embeddingnet", "(", "im2_masked", ",", "reference_condition", ")", ".", "data", "\n", "\n", "", "masks", "=", "masks", "[", "K", ":", "]", "\n", "inp", "=", "im", ".", "repeat", "(", "N", ",", "1", ",", "1", ",", "1", ")", "\n", "masked", "=", "inp", "*", "masks", ".", "expand_as", "(", "inp", ")", "\n", "all_sal", "=", "[", "]", "\n", "times_location_sampled", "=", "masks", ".", "squeeze", "(", ")", ".", "mean", "(", "0", ")", "\n", "for", "j", ",", "embed1", "in", "enumerate", "(", "all_embed", ")", ":", "\n", "        ", "embed1", "=", "embed1", ".", "unsqueeze", "(", "0", ")", "\n", "preds", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "N", ",", "batch_size", ")", ":", "\n", "            ", "preds", ".", "append", "(", "model", ".", "run_on_batch", "(", "masked", "[", "i", ":", "min", "(", "i", "+", "batch_size", ",", "N", ")", "]", ",", "embed1", ",", "query_condition", ")", ".", "data", ")", "\n", "\n", "", "preds", "=", "torch", ".", "cat", "(", "preds", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "sal", "=", "torch", ".", "sum", "(", "preds", "*", "masks", ".", "reshape", "(", "N", ",", "-", "1", ")", ",", "dim", "=", "0", ")", ".", "reshape", "(", "112", ",", "112", ")", "\n", "sal", "/=", "times_location_sampled", "\n", "#sal = sal / N / p1", "\n", "all_sal", ".", "append", "(", "sal", ")", "\n", "\n", "", "all_sal", "=", "torch", ".", "stack", "(", "all_sal", ")", ".", "mean", "(", "0", ")", "\n", "return", "all_sal", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.slide_explain_var": [[233, 270], ["len", "int", "im.repeat", "len", "im2.repeat", "enumerate", "torch.stack().mean", "torch.from_numpy", "torch.from_numpy", "ref_masks.expand_as", "masks.expand_as", "embed1.unsqueeze.unsqueeze", "range", "torch.stack().mean.append", "torch.autograd.Variable", "torch.autograd.Variable", "model.embeddingnet", "model.embeddingnet", "min", "preds.append", "torch.cat().view", "torch.stack", "numpy.ones", "numpy.ones", "torch.from_numpy.cuda", "torch.from_numpy.cuda", "model.run_on_batch", "torch.cat"], "function", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.misc.saliency_maps.SaliencyModel.run_on_batch"], ["", "def", "slide_explain_var", "(", "model", ",", "im", ",", "im2", ",", "masks", ",", "ref_masks", ",", "condition", ")", ":", "\n", "# Make sure multiplication is being done for correct axes", "\n", "    ", "batch_size", "=", "500", "\n", "N", "=", "len", "(", "masks", ")", "\n", "side", "=", "int", "(", "N", "**", "0.5", ")", "\n", "assert", "N", "==", "side", "**", "2", "\n", "inp", "=", "im", ".", "repeat", "(", "N", ",", "1", ",", "1", ",", "1", ")", "\n", "K", "=", "len", "(", "ref_masks", ")", "\n", "if", "condition", "is", "not", "None", ":", "\n", "        ", "reference_condition", "=", "torch", ".", "from_numpy", "(", "np", ".", "ones", "(", "K", ",", "np", ".", "int64", ")", "*", "condition", ")", "\n", "query_condition", "=", "torch", ".", "from_numpy", "(", "np", ".", "ones", "(", "batch_size", ",", "np", ".", "int64", ")", "*", "condition", ")", "\n", "if", "im", ".", "is_cuda", ":", "\n", "            ", "reference_condition", ",", "query_condition", "=", "reference_condition", ".", "cuda", "(", ")", ",", "query_condition", ".", "cuda", "(", ")", "\n", "", "reference_condition", ",", "query_condition", "=", "Variable", "(", "reference_condition", ")", ",", "Variable", "(", "query_condition", ")", "\n", "\n", "", "im2_ref", "=", "im2", ".", "repeat", "(", "K", ",", "1", ",", "1", ",", "1", ")", "\n", "im2_masked", "=", "im2_ref", "*", "ref_masks", ".", "expand_as", "(", "im2_ref", ")", "\n", "if", "condition", "is", "None", ":", "\n", "        ", "all_embed", "=", "model", ".", "embeddingnet", "(", "im2_masked", ")", ".", "data", "\n", "", "else", ":", "\n", "        ", "all_embed", "=", "model", ".", "embeddingnet", "(", "im2_masked", ",", "reference_condition", ")", ".", "data", "\n", "", "all_sal", "=", "[", "]", "\n", "masked", "=", "inp", "*", "masks", ".", "expand_as", "(", "inp", ")", "\n", "for", "j", ",", "embed1", "in", "enumerate", "(", "all_embed", ")", ":", "\n", "        ", "embed1", "=", "embed1", ".", "unsqueeze", "(", "0", ")", "\n", "preds", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "N", ",", "batch_size", ")", ":", "\n", "            ", "A", "=", "min", "(", "i", "+", "batch_size", ",", "N", ")", "\n", "batch_condition", "=", "None", "\n", "if", "condition", "is", "not", "None", ":", "\n", "                ", "batch_condition", "=", "query_condition", "[", ":", "(", "A", "-", "i", ")", "]", "\n", "", "preds", ".", "append", "(", "model", ".", "run_on_batch", "(", "masked", "[", "i", ":", "A", "]", ",", "embed1", ",", "batch_condition", ")", ".", "data", ")", "\n", "", "sal", "=", "1", "-", "torch", ".", "cat", "(", "preds", ")", ".", "view", "(", "side", ",", "side", ")", "\n", "all_sal", ".", "append", "(", "sal", ")", "\n", "\n", "", "all_sal", "=", "torch", ".", "stack", "(", "all_sal", ")", ".", "mean", "(", "0", ")", "\n", "return", "all_sal", "\n", "", ""]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.attribute_predictor.AttributePredictor.__init__": [[6, 23], ["torch.Module.__init__", "torchvision.resnet50", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "list", "torchvision.resnet50.children"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_classes", ")", ":", "\n", "        ", "\"\"\" args: Input arguments from the main script\n            embeddingnet: The network that projects the inputs into an embedding of embedding_size\n            embedding_size: Number of dimensions of the embedding output from the embeddingnet\n            n_conditions: Integer defining number of different similarity notions\n        \"\"\"", "\n", "super", "(", "AttributePredictor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "embeddingnet", "=", "models", ".", "resnet50", "(", "pretrained", "=", "True", ")", "\n", "\n", "# pulling off last fully connected layer", "\n", "layers", "=", "list", "(", "embeddingnet", ".", "children", "(", ")", ")", "[", ":", "-", "1", "]", "\n", "self", ".", "embeddingnet", "=", "nn", ".", "Sequential", "(", "*", "layers", "[", ":", "-", "1", "]", ")", "\n", "\n", "# this is just an average pooling layer", "\n", "self", ".", "cls_net", "=", "layers", "[", "-", "1", "]", "\n", "\n", "self", ".", "heatmap_net", "=", "nn", ".", "Conv2d", "(", "2048", ",", "num_classes", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "(", "1", ",", "1", ")", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.attribute_predictor.AttributePredictor.forward": [[24, 35], ["attribute_predictor.AttributePredictor.embeddingnet", "attribute_predictor.AttributePredictor.heatmap_net", "attribute_predictor.AttributePredictor.cls_net().squeeze", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax.size", "torch.nn.functional.softmax.size", "torch.nn.functional.softmax.view", "torch.nn.functional.softmax.view", "attribute_predictor.AttributePredictor.cls_net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\" x: input image data\n            c: type specific embedding to compute for the images, returns all embeddings\n               when None including the general embedding concatenated onto the end\n        \"\"\"", "\n", "embedding", "=", "self", ".", "embeddingnet", "(", "x", ")", "\n", "heatmap", "=", "self", ".", "heatmap_net", "(", "embedding", ")", "\n", "cls_score", "=", "self", ".", "cls_net", "(", "heatmap", ")", ".", "squeeze", "(", ")", "\n", "num_batch", ",", "num_attr", "=", "heatmap", ".", "size", "(", ")", "[", ":", "2", "]", "\n", "heatmap", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "heatmap", ".", "view", "(", "num_batch", ",", "num_attr", ",", "-", "1", ")", ",", "2", ")", "\n", "return", "cls_score", ",", "heatmap", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.tripletnet.EmbedBranch.__init__": [[12, 16], ["torch.Module.__init__", "tripletnet.make_fc_1d", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.__init__", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.tripletnet.make_fc_1d"], ["    ", "def", "__init__", "(", "self", ",", "feat_dim", ",", "embedding_dim", ")", ":", "\n", "        ", "super", "(", "EmbedBranch", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "make_fc_1d", "(", "feat_dim", ",", "embedding_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "embedding_dim", ",", "embedding_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.tripletnet.EmbedBranch.forward": [[17, 24], ["tripletnet.EmbedBranch.fc1", "tripletnet.EmbedBranch.fc2", "torch.functional.normalize"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "\n", "# L2 normalize each feature vector", "\n", "x", "=", "nn", ".", "functional", ".", "normalize", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.tripletnet.Tripletnet.__init__": [[26, 31], ["torch.Module.__init__", "tripletnet.EmbedBranch"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "embeddingnet", ",", "text_dim", ")", ":", "\n", "        ", "super", "(", "Tripletnet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embeddingnet", "=", "embeddingnet", "\n", "self", ".", "text_branch", "=", "EmbedBranch", "(", "text_dim", ",", "args", ".", "dim_embed", ")", "\n", "self", ".", "metric_branch", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.tripletnet.make_fc_1d": [[6, 10], ["torch.Sequential", "torch.Linear", "torch.BatchNorm1d", "torch.ReLU"], "function", ["None"], ["def", "make_fc_1d", "(", "f_in", ",", "f_out", ")", ":", "\n", "    ", "return", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "f_in", ",", "f_out", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "f_out", ",", "eps", "=", "0.001", ",", "momentum", "=", "0.01", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.type_specific_network.ListModule.__init__": [[7, 13], ["torch.Module.__init__", "type_specific_network.ListModule.add_module", "str"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "super", "(", "ListModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "idx", "=", "0", "\n", "for", "module", "in", "args", ":", "\n", "            ", "self", ".", "add_module", "(", "str", "(", "idx", ")", ",", "module", ")", "\n", "idx", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.type_specific_network.ListModule.__getitem__": [[14, 21], ["iter", "range", "next", "IndexError", "type_specific_network.ListModule._modules.values", "next", "len"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "idx", "<", "0", "or", "idx", ">=", "len", "(", "self", ".", "_modules", ")", ":", "\n", "            ", "raise", "IndexError", "(", "'index {} is out of range'", ".", "format", "(", "idx", ")", ")", "\n", "", "it", "=", "iter", "(", "self", ".", "_modules", ".", "values", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "idx", ")", ":", "\n", "            ", "next", "(", "it", ")", "\n", "", "return", "next", "(", "it", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.type_specific_network.ListModule.__iter__": [[22, 24], ["iter", "type_specific_network.ListModule._modules.values"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "_modules", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.type_specific_network.ListModule.__len__": [[25, 27], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.type_specific_network.TypeSpecificNet.__init__": [[29, 42], ["torch.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "type_specific_network.TypeSpecificNet.masks.weight.data.normal_"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "embeddingnet", ",", "n_conditions", ")", ":", "\n", "        ", "\"\"\" args: Input arguments from the main script\n            embeddingnet: The network that projects the inputs into an embedding of embedding_size\n            embedding_size: Number of dimensions of the embedding output from the embeddingnet\n            n_conditions: Integer defining number of different similarity notions\n        \"\"\"", "\n", "super", "(", "TypeSpecificNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embeddingnet", "=", "embeddingnet", "\n", "\n", "# define masks with gradients", "\n", "self", ".", "masks", "=", "torch", ".", "nn", ".", "Embedding", "(", "n_conditions", ",", "args", ".", "dim_embed", ")", "\n", "# initialize weights", "\n", "self", ".", "masks", ".", "weight", ".", "data", ".", "normal_", "(", "0.9", ",", "0.7", ")", "# 0.1, 0.005", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.type_specific_network.TypeSpecificNet.forward": [[44, 67], ["type_specific_network.TypeSpecificNet.embeddingnet", "type_specific_network.TypeSpecificNet.masks", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.autograd.Variable", "torch.autograd.Variable", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "masks.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "embedded_x.unsqueeze.unsqueeze.unsqueeze", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "embedded_x.unsqueeze.unsqueeze.size", "embedded_x.unsqueeze.unsqueeze.expand_as", "masks.unsqueeze().repeat.unsqueeze().repeat.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "c", "=", "None", ")", ":", "\n", "        ", "\"\"\" x: input image data\n            c: type specific embedding to compute for the images, returns all embeddings\n               when None including the general embedding concatenated onto the end\n        \"\"\"", "\n", "embedded_x", "=", "self", ".", "embeddingnet", "(", "x", ")", "\n", "if", "c", "is", "None", ":", "\n", "# used during testing, wants all type specific embeddings returned for an image", "\n", "            ", "masks", "=", "Variable", "(", "self", ".", "masks", ".", "weight", ".", "data", ")", "\n", "masks", "=", "torch", ".", "nn", ".", "functional", ".", "relu", "(", "masks", ")", "\n", "\n", "masks", "=", "masks", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "embedded_x", ".", "size", "(", "0", ")", ",", "1", ",", "1", ")", "\n", "embedded_x", "=", "embedded_x", ".", "unsqueeze", "(", "1", ")", "\n", "masked_embedding", "=", "embedded_x", ".", "expand_as", "(", "masks", ")", "*", "masks", "\n", "masked_embedding", "=", "torch", ".", "nn", ".", "functional", ".", "normalize", "(", "masked_embedding", ")", "\n", "return", "torch", ".", "cat", "(", "(", "masked_embedding", ",", "embedded_x", ")", ",", "1", ")", "\n", "\n", "", "self", ".", "mask", "=", "self", ".", "masks", "(", "c", ")", "\n", "self", ".", "mask", "=", "torch", ".", "nn", ".", "functional", ".", "relu", "(", "self", ".", "mask", ")", "\n", "\n", "masked_embedding", "=", "embedded_x", "*", "self", ".", "mask", "\n", "masked_embedding", "=", "torch", ".", "nn", ".", "functional", ".", "normalize", "(", "masked_embedding", ")", "\n", "return", "masked_embedding", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.awa_net_wrapper.AwAWrapper.__init__": [[4, 7], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embeddingnet", ")", ":", "\n", "        ", "super", "(", "AwAWrapper", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embeddingnet", "=", "embeddingnet", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.Resnet_18.BasicBlock.__init__": [[23, 32], ["torch.Module.__init__", "Resnet_18.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "Resnet_18.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.__init__", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.Resnet_18.conv3x3", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.Resnet_18.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.Resnet_18.BasicBlock.forward": [[33, 50], ["Resnet_18.BasicBlock.conv1", "Resnet_18.BasicBlock.bn1", "Resnet_18.BasicBlock.relu", "Resnet_18.BasicBlock.conv2", "Resnet_18.BasicBlock.bn2", "Resnet_18.BasicBlock.relu", "Resnet_18.BasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.Resnet_18.ResNet.__init__": [[53, 77], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "Resnet_18.ResNet._make_layer", "Resnet_18.ResNet._make_layer", "Resnet_18.ResNet._make_layer", "Resnet_18.ResNet.modules", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Linear", "torch.Linear", "isinstance", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.__init__", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.Resnet_18.ResNet._make_layer", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.Resnet_18.ResNet._make_layer", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.Resnet_18.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "embedding_size", "=", "64", ",", "norm_output", "=", "False", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "64", "\n", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm_output", "=", "norm_output", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "avgpool", "=", "None", "\n", "if", "embedding_size", "is", "not", "None", ":", "\n", "            ", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "7", ")", "\n", "self", ".", "fc_embed", "=", "nn", ".", "Linear", "(", "256", "*", "block", ".", "expansion", ",", "embedding_size", ")", "\n", "\n", "", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.", "/", "n", ")", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.Resnet_18.ResNet._make_layer": [[78, 94], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "block"], "methods", ["None"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.Resnet_18.ResNet.forward": [[95, 113], ["Resnet_18.ResNet.conv1", "Resnet_18.ResNet.bn1", "Resnet_18.ResNet.relu", "Resnet_18.ResNet.maxpool", "Resnet_18.ResNet.layer1", "Resnet_18.ResNet.layer2", "Resnet_18.ResNet.layer3", "Resnet_18.ResNet.avgpool", "torch.functional.normalize.view", "Resnet_18.ResNet.fc_embed", "torch.functional.normalize.size", "torch.functional.normalize", "torch.functional.normalize"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "\n", "if", "self", ".", "avgpool", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc_embed", "(", "x", ")", "\n", "if", "self", ".", "norm_output", ":", "\n", "                ", "x", "=", "nn", ".", "functional", ".", "normalize", "(", "x", ")", "\n", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.Resnet_18.conv3x3": [[14, 18], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"3x3 convolution with padding\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.Resnet_18.resnet18": [[115, 130], ["Resnet_18.ResNet", "ResNet.state_dict", "torch.load_url", "ResNet.load_state_dict"], "function", ["None"], ["", "", "def", "resnet18", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "state", "=", "model", ".", "state_dict", "(", ")", "\n", "loaded_state_dict", "=", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet18'", "]", ")", "\n", "for", "k", "in", "loaded_state_dict", ":", "\n", "            ", "if", "k", "in", "state", ":", "\n", "                ", "state", "[", "k", "]", "=", "loaded_state_dict", "[", "k", "]", "\n", "", "", "model", ".", "load_state_dict", "(", "state", ")", "\n", "", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.saliency.pdist": [[59, 67], ["torch.mm", "torch.mm", "x2.transpose"], "function", ["None"], ["def", "pdist", "(", "x1", ",", "x2", ")", ":", "\n", "    ", "\"\"\"\n        x1: Tensor of shape (h1, w)\n        x2: Tensor of shape (h2, w)\n        Return pairwise distance for each row vector in x1, x2 as\n        a Tensor of shape (h1, h2)\n    \"\"\"", "\n", "return", "torch", ".", "mm", "(", "x1", ",", "x2", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.saliency.evaluate_saliency": [[68, 91], ["os.path.join", "os.path.isfile", "test_loader.dataset.test", "print", "torch.load", "torch.load", "tqdm.tqdm", "torch.cat", "torch.cat", "torch.save", "torch.save", "embeddings.cuda.cuda", "torch.autograd.Variable", "embeddings.cuda.append", "round", "round", "len", "images.cuda.cuda", "model.embeddingnet"], "function", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.sane_eval.test"], ["", "def", "evaluate_saliency", "(", "model", ",", "test_loader", ")", ":", "\n", "    ", "cached_embedding_fn", "=", "os", ".", "path", ".", "join", "(", "args", ".", "datadir", ",", "'cache'", ",", "args", ".", "dataset", ",", "'embeddings.pkl'", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "cached_embedding_fn", ")", ":", "\n", "        ", "embeddings", "=", "torch", ".", "load", "(", "cached_embedding_fn", ")", "\n", "if", "args", ".", "cuda", ":", "\n", "            ", "embeddings", "=", "embeddings", ".", "cuda", "(", ")", "\n", "", "", "else", ":", "\n", "        ", "embeddings", "=", "[", "]", "\n", "for", "images", "in", "tqdm", "(", "test_loader", ",", "\n", "desc", "=", "'caching fixed embeddings'", ",", "\n", "total", "=", "len", "(", "test_loader", ")", ")", ":", "\n", "            ", "if", "args", ".", "cuda", ":", "\n", "                ", "images", "=", "images", ".", "cuda", "(", ")", "\n", "", "images", "=", "Variable", "(", "images", ")", "\n", "embeddings", ".", "append", "(", "model", ".", "embeddingnet", "(", "images", ")", ".", "data", ")", "\n", "\n", "", "embeddings", "=", "torch", ".", "cat", "(", "embeddings", ")", "\n", "torch", ".", "save", "(", "embeddings", ",", "cached_embedding_fn", ")", "\n", "\n", "", "insert_auc", ",", "delete_auc", "=", "test_loader", ".", "dataset", ".", "test", "(", "model", ",", "embeddings", ")", "\n", "print", "(", "'\\n{} set for {} using {}: Insert AUC: {:.1f}\\t Delete AUC: {:.1f}\\n'", ".", "format", "(", "\n", "test_loader", ".", "dataset", ".", "split", ",", "args", ".", "dataset", ",", "args", ".", "method", ",", "\n", "round", "(", "insert_auc", "*", "100", ",", "1", ")", ",", "round", "(", "delete_auc", "*", "100", ",", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.saliency.main": [[92, 150], ["parser.parse_args", "torch.manual_seed", "torch.manual_seed", "torchvision.transforms.Normalize", "torchvision.transforms.Compose", "os.path.join", "print", "torch.load", "torch.load", "nets.tripletnet.Tripletnet.load_state_dict", "print", "nets.tripletnet.Tripletnet.eval", "misc.saliency_maps.SaliencyModel", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "os.path.join", "json.load", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "nets.Resnet_18.resnet18", "nets.type_specific_network.TypeSpecificNet", "nets.tripletnet.Tripletnet", "nets.tripletnet.Tripletnet.cuda", "torch.utils.data.DataLoader.dataset.compute_train_saliency_maps", "saliency.evaluate_saliency", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "open", "datasets.saliency.polyvore_outfits.OutfitsLoader", "len", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "nets.Resnet_18.resnet18", "nets.tripletnet.Tripletnet", "ValueError", "datasets.saliency.awa.AwALoader", "nets.awa_net_wrapper.AwAWrapper"], "function", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.Resnet_18.resnet18", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.saliency.data_loader.SaliencyDataLoader.compute_train_saliency_maps", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.saliency.evaluate_saliency", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.nets.Resnet_18.resnet18"], ["", "def", "main", "(", ")", ":", "\n", "    ", "global", "args", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "assert", "(", "args", ".", "method", "in", "[", "'slide'", ",", "'rise'", ",", "'mask'", ",", "'lime'", ",", "'random'", "]", ")", "\n", "args", ".", "cuda", "=", "not", "args", ".", "no_cuda", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "cuda", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "\n", "", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "112", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "112", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", ")", "\n", "\n", "text_feat_dim", "=", "6000", "\n", "kwargs", "=", "{", "'num_workers'", ":", "8", ",", "'pin_memory'", ":", "True", "}", "if", "args", ".", "cuda", "else", "{", "}", "\n", "if", "args", ".", "dataset", "==", "'polyvore_outfits'", ":", "\n", "        ", "fn", "=", "os", ".", "path", ".", "join", "(", "args", ".", "datadir", ",", "args", ".", "dataset", ",", "'polyvore_item_metadata.json'", ")", "\n", "meta_data", "=", "json", ".", "load", "(", "open", "(", "fn", ",", "'r'", ")", ")", "\n", "data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "OutfitsLoader", "(", "args", ",", "args", ".", "split", ",", "meta_data", ",", "transform", "=", "transform", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "\n", "feat_cnn", "=", "nets", ".", "Resnet_18", ".", "resnet18", "(", "pretrained", "=", "True", ",", "embedding_size", "=", "args", ".", "dim_embed", ")", "\n", "tsn", "=", "TypeSpecificNet", "(", "args", ",", "feat_cnn", ",", "len", "(", "data_loader", ".", "dataset", ".", "typespaces", ")", ")", "\n", "embeddingnet", "=", "Tripletnet", "(", "args", ",", "tsn", ",", "text_feat_dim", ")", "\n", "", "elif", "args", ".", "dataset", "==", "'awa'", ":", "\n", "        ", "data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "AwALoader", "(", "args", ",", "args", ".", "split", ",", "transform", "=", "transform", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "\n", "tsn", "=", "nets", ".", "Resnet_18", ".", "resnet18", "(", "pretrained", "=", "True", ",", "embedding_size", "=", "args", ".", "dim_embed", ",", "norm_output", "=", "True", ")", "\n", "embeddingnet", "=", "Tripletnet", "(", "args", ",", "AwAWrapper", "(", "tsn", ")", ",", "text_feat_dim", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unrecognized dataset: '", "+", "args", ".", "dataset", ")", "\n", "\n", "", "if", "args", ".", "cuda", ":", "\n", "        ", "embeddingnet", ".", "cuda", "(", ")", "\n", "\n", "", "resume", "=", "os", ".", "path", ".", "join", "(", "'image_similarity_models'", ",", "args", ".", "dataset", "+", "'_model.pth.tar'", ")", "\n", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "resume", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "resume", ",", "encoding", "=", "'latin1'", ")", "\n", "embeddingnet", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", ".", "format", "(", "resume", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "\n", "# switch to evaluation mode", "\n", "embeddingnet", ".", "eval", "(", ")", "\n", "model", "=", "SaliencyModel", "(", "tsn", ")", "\n", "\n", "if", "args", ".", "split", "==", "'train'", ":", "\n", "        ", "data_loader", ".", "dataset", ".", "compute_train_saliency_maps", "(", "model", ")", "\n", "", "else", ":", "\n", "        ", "evaluate_saliency", "(", "model", ",", "data_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.__init__": [[256, 258], ["train_attribute_classifier.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.reset": [[259, 264], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.update": [[265, 270], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.main": [[66, 167], ["parser.parse_args", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torchvision.transforms.Normalize", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "nets.attribute_predictor.AttributePredictor", "filter", "torch.Adam", "sum", "print", "range", "torch.load", "torch.load", "torch.load", "nets.attribute_predictor.AttributePredictor.load_state_dict", "train_attribute_classifier.test", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "dataset_class", "dataset_class", "dataset_class", "nets.attribute_predictor.AttributePredictor.cuda", "os.path.isfile", "train_attribute_classifier.test", "sys.exit", "nets.attribute_predictor.AttributePredictor.parameters", "train_attribute_classifier.adjust_learning_rate", "train_attribute_classifier.train", "train_attribute_classifier.test", "max", "train_attribute_classifier.save_checkpoint", "os.path.join", "ValueError", "print", "torch.load", "torch.load", "torch.load", "nets.attribute_predictor.AttributePredictor.load_state_dict", "print", "print", "p.data.nelement", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "nets.attribute_predictor.AttributePredictor.parameters", "nets.attribute_predictor.AttributePredictor.state_dict", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor"], "function", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.sane_eval.test", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.sane_eval.test", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.adjust_learning_rate", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.train", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.sane_eval.test", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.save_checkpoint"], ["def", "main", "(", ")", ":", "\n", "    ", "global", "args", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "args", ".", "cuda", "=", "not", "args", ".", "no_cuda", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "cuda", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "\n", "", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "\n", "kwargs", "=", "{", "'num_workers'", ":", "8", ",", "'pin_memory'", ":", "True", "}", "if", "args", ".", "cuda", "else", "{", "}", "\n", "if", "args", ".", "dataset", "==", "'polyvore_outfits'", ":", "\n", "        ", "dataset_class", "=", "OutfitsLoader", "\n", "image_size", "=", "112", "\n", "crop_size", "=", "112", "\n", "", "elif", "args", ".", "dataset", "==", "'awa'", ":", "\n", "        ", "dataset_class", "=", "AwALoader", "\n", "image_size", "=", "112", "\n", "crop_size", "=", "112", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unrecognized dataset: '", "+", "args", ".", "dataset", ")", "\n", "\n", "\n", "", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset_class", "(", "args", ",", "'test'", ",", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "image_size", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "crop_size", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", "//", "2", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset_class", "(", "args", ",", "'train'", ",", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "image_size", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "crop_size", ")", ",", "\n", "#transforms.RandomHorizontalFlip(),", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset_class", "(", "args", ",", "'valid'", ",", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "image_size", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "crop_size", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", "//", "2", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "\n", "model", "=", "AttributePredictor", "(", "test_loader", ".", "dataset", ".", "num_attr", ")", "\n", "if", "args", ".", "cuda", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "", "best_acc", "=", "0", "\n", "# optionally resume from a checkpoint", "\n", "if", "args", ".", "resume", ":", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "args", ".", "resume", ")", ":", "\n", "            ", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "args", ".", "resume", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "resume", ")", "\n", "args", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "best_acc", "=", "checkpoint", "[", "'best_prec1'", "]", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "args", ".", "resume", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"=> no checkpoint found at '{}'\"", ".", "format", "(", "args", ".", "resume", ")", ")", "\n", "\n", "", "", "cudnn", ".", "benchmark", "=", "True", "\n", "if", "args", ".", "test", ":", "\n", "        ", "test_acc", "=", "test", "(", "test_loader", ",", "model", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "", "parameters", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "parameters", ",", "lr", "=", "args", ".", "lr", ")", "\n", "n_parameters", "=", "sum", "(", "[", "p", ".", "data", ".", "nelement", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ")", "\n", "print", "(", "'  + Number of params: {}'", ".", "format", "(", "n_parameters", ")", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "args", ".", "start_epoch", ",", "args", ".", "epochs", "+", "1", ")", ":", "\n", "# update learning rate", "\n", "        ", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ")", "\n", "# train for one epoch", "\n", "train", "(", "train_loader", ",", "model", ",", "optimizer", ",", "epoch", ")", "\n", "# evaluate on validation set", "\n", "acc", "=", "test", "(", "val_loader", ",", "model", ")", "\n", "\n", "# remember best acc and save checkpoint", "\n", "is_best", "=", "acc", ">", "best_acc", "\n", "best_acc", "=", "max", "(", "acc", ",", "best_acc", ")", "\n", "save_checkpoint", "(", "{", "\n", "'epoch'", ":", "epoch", "+", "1", ",", "\n", "'state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'best_prec1'", ":", "best_acc", ",", "\n", "}", ",", "is_best", ")", "\n", "\n", "", "checkpoint", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "'runs'", ",", "args", ".", "dataset", ",", "args", ".", "name", ",", "'model_best.pth.tar'", ")", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "test_acc", "=", "test", "(", "test_loader", ",", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.train": [[168, 216], ["train_attribute_classifier.AverageMeter", "train_attribute_classifier.AverageMeter", "torch.nn.SmoothL1Loss", "torch.nn.SmoothL1Loss", "torch.nn.SmoothL1Loss", "model.train", "enumerate", "model", "torch.nn.SmoothL1Loss.", "len", "train_attribute_classifier.AverageMeter.update", "torch.nn.functional.softmax().unsqueeze", "torch.nn.functional.softmax().unsqueeze", "torch.nn.functional.softmax().unsqueeze", "supp.unsqueeze().expand", "heatmap_mask.sum", "train_attribute_classifier.AverageMeter.update", "optimizer.zero_grad", "loss.backward", "optimizer.step", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "criterion.item", "torch.nn.functional.softmax().unsqueeze.expand_as", "diff.view().norm", "heat_loss.item", "heatmap_mask.sum.int", "print", "images.cuda", "labels.cuda", "torch.nn.functional.softmax().unsqueeze.cuda", "heatmap_mask.cuda", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "supp.unsqueeze", "diff.view", "labels.unsqueeze", "len"], "function", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.train", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.update", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.update"], ["", "def", "train", "(", "train_loader", ",", "model", ",", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "losses", "=", "AverageMeter", "(", ")", "\n", "losses_heat", "=", "AverageMeter", "(", ")", "\n", "criterion", "=", "torch", ".", "nn", ".", "SmoothL1Loss", "(", ")", "\n", "\n", "# switch to train mode", "\n", "model", ".", "train", "(", ")", "\n", "for", "batch_idx", ",", "(", "images", ",", "labels", ",", "gt_heatmap", ",", "heatmap_mask", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "        ", "if", "args", ".", "cuda", ":", "\n", "            ", "images", ",", "labels", ",", "gt_heatmap", ",", "heatmap_mask", "=", "images", ".", "cuda", "(", ")", ",", "labels", ".", "cuda", "(", ")", ",", "gt_heatmap", ".", "cuda", "(", ")", ",", "heatmap_mask", ".", "cuda", "(", ")", "\n", "", "images", ",", "labels", ",", "gt_heatmap", ",", "heatmap_mask", "=", "Variable", "(", "images", ")", ",", "Variable", "(", "labels", ")", ",", "Variable", "(", "gt_heatmap", ")", ",", "Variable", "(", "heatmap_mask", ")", "\n", "scores", ",", "supp", "=", "model", "(", "images", ")", "\n", "\n", "cls_loss", "=", "criterion", "(", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "scores", ",", "1", ")", ",", "labels", ")", "\n", "\n", "num_items", "=", "len", "(", "images", ")", "\n", "losses", ".", "update", "(", "cls_loss", ".", "item", "(", ")", ",", "num_items", ")", "\n", "gt_heatmap", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "gt_heatmap", ",", "2", ")", ".", "unsqueeze", "(", "2", ")", "\n", "heatmap", "=", "supp", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "num_items", ",", "\n", "train_loader", ".", "dataset", ".", "max_num_heatmaps", ",", "\n", "train_loader", ".", "dataset", ".", "num_attr", ",", "\n", "args", ".", "mask_size", "*", "args", ".", "mask_size", ")", "\n", "\n", "diff", "=", "heatmap", "-", "gt_heatmap", ".", "expand_as", "(", "heatmap", ")", "\n", "norms", "=", "1", "-", "diff", ".", "view", "(", "num_items", ",", "train_loader", ".", "dataset", ".", "max_num_heatmaps", ",", "\n", "train_loader", ".", "dataset", ".", "num_attr", ",", "-", "1", ")", ".", "norm", "(", "2", ",", "3", ")", "\n", "\n", "labels", "=", "(", "labels", ".", "unsqueeze", "(", "1", ")", ">", "0", ")", ".", "float", "(", ")", "\n", "norms", ",", "_", "=", "(", "norms", "*", "labels", ")", ".", "max", "(", "2", ")", "\n", "num_heatmap_items", "=", "heatmap_mask", ".", "sum", "(", ")", "\n", "heat_loss", "=", "(", "(", "1", "-", "norms", ")", "*", "heatmap_mask", ")", ".", "sum", "(", ")", "/", "num_heatmap_items", "\n", "losses_heat", ".", "update", "(", "heat_loss", ".", "item", "(", ")", ",", "num_heatmap_items", ".", "int", "(", ")", ")", "\n", "\n", "loss", "=", "cls_loss", "+", "heat_loss", "*", "args", ".", "heat_loss", "\n", "\n", "# compute gradient and do optimizer step", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "batch_idx", "%", "args", ".", "log_interval", "==", "0", ":", "\n", "            ", "print", "(", "'Train Epoch: {} [{}/{}]\\t'", "\n", "'Loss: {:.4f} ({:.4f})\\t'", "\n", "'heatmap: {:.4f} ({:.4f})'", ".", "format", "(", "\n", "epoch", ",", "batch_idx", "*", "num_items", ",", "len", "(", "train_loader", ".", "dataset", ")", ",", "\n", "losses", ".", "val", "*", "100", ",", "losses", ".", "avg", "*", "100", ",", "\n", "losses_heat", ".", "val", ",", "losses_heat", ".", "avg", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.test": [[217, 243], ["model.eval", "tqdm.tqdm", "torch.cat().t().numpy", "torch.cat().t().numpy", "torch.cat().t().numpy", "zip", "numpy.mean", "print", "enumerate", "torch.autograd.Variable", "labels.append", "model", "torch.cat().t().numpy.append", "torch.cat().t().numpy", "torch.cat().t().numpy", "torch.cat().t().numpy", "len", "images.cuda.cuda", "pred.data.cpu", "torch.cat().t", "torch.cat().t", "torch.cat().t", "numpy.sum", "ap.append", "round", "torch.cat().t", "torch.cat().t", "torch.cat().t", "sklearn.average_precision_score", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "function", ["None"], ["", "", "", "def", "test", "(", "test_loader", ",", "model", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "scores", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "# for test/val data we get images only from the data loader", "\n", "for", "batch_idx", ",", "(", "images", ",", "im_labels", ")", "in", "tqdm", "(", "enumerate", "(", "test_loader", ")", ",", "desc", "=", "'testing...'", ",", "total", "=", "len", "(", "test_loader", ")", ")", ":", "\n", "        ", "if", "args", ".", "cuda", ":", "\n", "            ", "images", "=", "images", ".", "cuda", "(", ")", "\n", "", "images", "=", "Variable", "(", "images", ")", "\n", "labels", ".", "append", "(", "im_labels", ")", "\n", "pred", ",", "_", "=", "model", "(", "images", ")", "\n", "\n", "scores", ".", "append", "(", "pred", ".", "data", ".", "cpu", "(", ")", ")", "\n", "\n", "", "labels", "=", "torch", ".", "cat", "(", "labels", ")", ".", "t", "(", ")", ".", "numpy", "(", ")", ">", "0", "\n", "scores", "=", "torch", ".", "cat", "(", "scores", ")", ".", "t", "(", ")", ".", "numpy", "(", ")", "\n", "ap", "=", "[", "]", "\n", "for", "im_labels", ",", "im_scores", "in", "zip", "(", "labels", ",", "scores", ")", ":", "\n", "        ", "if", "np", ".", "sum", "(", "im_labels", ")", ">", "0", ":", "\n", "            ", "ap", ".", "append", "(", "skm", ".", "average_precision_score", "(", "im_labels", ",", "im_scores", ")", ")", "\n", "\n", "", "", "mAP", "=", "np", ".", "mean", "(", "ap", ")", "\n", "\n", "print", "(", "'\\n{} set: mAP {:.1f}\\n'", ".", "format", "(", "\n", "test_loader", ".", "dataset", ".", "split", ",", "round", "(", "mAP", "*", "100", ",", "1", ")", ")", ")", "\n", "return", "mAP", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.save_checkpoint": [[244, 253], ["os.path.join", "os.path.join", "torch.save", "torch.save", "torch.save", "os.path.exists", "os.makedirs", "shutil.copyfile", "os.path.join"], "function", ["None"], ["", "def", "save_checkpoint", "(", "state", ",", "is_best", ",", "filename", "=", "'checkpoint.pth.tar'", ")", ":", "\n", "    ", "\"\"\"Saves checkpoint to disk\"\"\"", "\n", "directory", "=", "os", ".", "path", ".", "join", "(", "\"runs\"", ",", "args", ".", "dataset", ",", "args", ".", "name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "directory", ")", "\n", "", "filename", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "filename", ")", "\n", "torch", ".", "save", "(", "state", ",", "filename", ")", "\n", "if", "is_best", ":", "\n", "        ", "shutil", ".", "copyfile", "(", "filename", ",", "os", ".", "path", ".", "join", "(", "directory", ",", "'model_best.pth.tar'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.adjust_learning_rate": [[271, 276], ["None"], "function", ["None"], ["", "", "def", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "\"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"", "\n", "lr", "=", "args", ".", "lr", "*", "(", "(", "1", "-", "0.015", ")", "**", "epoch", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools._init_paths.add_path": [[4, 7], ["sys.path.insert"], "function", ["None"], ["def", "add_path", "(", "path", ")", ":", "\n", "    ", "if", "path", "not", "in", "sys", ".", "path", ":", "\n", "        ", "sys", ".", "path", ".", "insert", "(", "0", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.sane_eval.main": [[80, 189], ["parser.parse_args", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torchvision.transforms.Normalize", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "AttributePredictor", "os.path.exists", "sane_eval.test", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "dataset_class", "AttributePredictor.cuda", "os.path.isfile", "pickle.load", "numpy.zeros", "set", "enumerate", "list", "dict", "numpy.zeros", "enumerate", "tqdm.tqdm", "torch.stack", "torch.stack", "torch.stack", "AttributePredictor.eval", "int", "tqdm.tqdm", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "tqdm.tqdm", "pickle.dump", "ValueError", "print", "torch.load", "torch.load", "torch.load", "AttributePredictor.load_state_dict", "print", "print", "open", "list.update", "zip", "torch.utils.data.DataLoader.dataset.loader", "torch.stack.append", "numpy.ceil", "range", "AttributePredictor.", "torch.cat().numpy.append", "enumerate", "pickle.load.append", "open", "torchvision.transforms.Compose", "range", "attr2im[].append", "attr2im[].append", "range", "len", "len", "len", "os.path.join", "torch.utils.data.DataLoader.dataset.transform", "len", "torch.autograd.Variable", "batch_scores.data.cpu", "torch.cat", "torch.cat", "torch.cat", "len", "numpy.median", "len", "attr2im[].append", "len", "len", "float", "images[].cuda", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "numpy.where"], "function", ["home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.sane_eval.test", "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.train_attribute_classifier.AverageMeter.update"], ["def", "main", "(", ")", ":", "\n", "    ", "global", "args", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "args", ".", "cuda", "=", "not", "args", ".", "no_cuda", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "assert", "(", "args", ".", "attr_weight", "<=", "1", "and", "args", ".", "attr_weight", ">=", "0", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "cuda", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "\n", "", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "\n", "kwargs", "=", "{", "'num_workers'", ":", "8", ",", "'pin_memory'", ":", "True", "}", "if", "args", ".", "cuda", "else", "{", "}", "\n", "if", "args", ".", "dataset", "==", "'polyvore_outfits'", ":", "\n", "        ", "dataset_class", "=", "AttributePOutfitsLoader", "\n", "", "elif", "args", ".", "dataset", "==", "'awa'", ":", "\n", "        ", "dataset_class", "=", "AttributeAwALoader", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unrecognized dataset: '", "+", "args", ".", "dataset", ")", "\n", "\n", "", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset_class", "(", "args", ",", "'test'", ",", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "112", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "112", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", "//", "2", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "\n", "model", "=", "AttributePredictor", "(", "test_loader", ".", "dataset", ".", "num_attr", ")", "\n", "if", "args", ".", "cuda", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "", "best_acc", "=", "0", "\n", "# optionally resume from a checkpoint", "\n", "if", "args", ".", "resume", ":", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "args", ".", "resume", ")", ":", "\n", "            ", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "args", ".", "resume", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "resume", ")", "\n", "args", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "best_acc", "=", "checkpoint", "[", "'best_prec1'", "]", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "args", ".", "resume", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"=> no checkpoint found at '{}'\"", ".", "format", "(", "args", ".", "resume", ")", ")", "\n", "\n", "", "", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "calibration_params", "=", "'data/%s_calibration_sigmoid.pkl'", "%", "args", ".", "dataset", "\n", "if", "os", ".", "path", ".", "exists", "(", "calibration_params", ")", ":", "\n", "        ", "calibration", "=", "pickle", ".", "load", "(", "open", "(", "calibration_params", ",", "'rb'", ")", ")", "\n", "", "else", ":", "\n", "        ", "assert", "(", "False", ")", "\n", "attr2im", "=", "[", "[", "]", "for", "_", "in", "range", "(", "test_loader", ".", "dataset", ".", "num_attr", ")", "]", "\n", "finished", "=", "np", ".", "zeros", "(", "test_loader", ".", "dataset", ".", "num_attr", ",", "np", ".", "int32", ")", "\n", "num_items", "=", "200", "\n", "for", "imfn", "in", "test_loader", ".", "dataset", ".", "images", ":", "\n", "            ", "for", "attr_id", "in", "test_loader", ".", "dataset", ".", "attribute_data", "[", "imfn", "]", ":", "\n", "                ", "attr2im", "[", "attr_id", "]", ".", "append", "(", "imfn", ")", "\n", "\n", "", "", "for", "imfn", "in", "val_loader", ".", "dataset", ".", "images", ":", "\n", "            ", "for", "attr_id", "in", "val_loader", ".", "dataset", ".", "attribute_data", "[", "imfn", "]", ":", "\n", "                ", "attr2im", "[", "attr_id", "]", ".", "append", "(", "imfn", ")", "\n", "\n", "", "", "for", "imfn", "in", "train_loader", ".", "dataset", ".", "images", ":", "\n", "            ", "for", "attr_id", "in", "train_loader", ".", "dataset", ".", "attribute_data", "[", "imfn", "]", ":", "\n", "                ", "if", "len", "(", "attr2im", "[", "attr_id", "]", ")", "<", "num_items", ":", "\n", "                    ", "attr2im", "[", "attr_id", "]", ".", "append", "(", "imfn", ")", "\n", "\n", "", "", "", "all_imfns", "=", "set", "(", ")", "\n", "for", "attr_id", ",", "imfns", "in", "enumerate", "(", "attr2im", ")", ":", "\n", "#attr2im[attr_id] = set(imfns[:num_items])", "\n", "            ", "all_imfns", ".", "update", "(", "attr2im", "[", "attr_id", "]", ")", "\n", "\n", "", "all_imfns", "=", "list", "(", "all_imfns", ")", "\n", "im2idx", "=", "dict", "(", "zip", "(", "all_imfns", ",", "range", "(", "len", "(", "all_imfns", ")", ")", ")", ")", "\n", "labels", "=", "np", ".", "zeros", "(", "(", "len", "(", "all_imfns", ")", ",", "len", "(", "attr2im", ")", ")", ",", "np", ".", "float32", ")", "\n", "for", "attr_id", ",", "imfns", "in", "enumerate", "(", "attr2im", ")", ":", "\n", "            ", "for", "imfn", "in", "imfns", ":", "\n", "                ", "labels", "[", "im2idx", "[", "imfn", "]", ",", "attr_id", "]", "=", "1", "\n", "\n", "", "", "images", "=", "[", "]", "\n", "for", "imfn", "in", "tqdm", "(", "all_imfns", ",", "desc", "=", "'converting images'", ",", "total", "=", "len", "(", "all_imfns", ")", ")", ":", "\n", "            ", "img", "=", "test_loader", ".", "dataset", ".", "loader", "(", "os", ".", "path", ".", "join", "(", "test_loader", ".", "dataset", ".", "impath", ",", "imfn", "+", "'.jpg'", ")", ")", "\n", "if", "test_loader", ".", "dataset", ".", "transform", "is", "not", "None", ":", "\n", "                ", "img", "=", "test_loader", ".", "dataset", ".", "transform", "(", "img", ")", "\n", "\n", "", "images", ".", "append", "(", "img", ")", "\n", "\n", "", "images", "=", "torch", ".", "stack", "(", "images", ")", "\n", "model", ".", "eval", "(", ")", "\n", "scores", "=", "[", "]", "\n", "num_batches", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "images", ")", "/", "float", "(", "args", ".", "batch_size", ")", ")", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "images", ")", ",", "args", ".", "batch_size", ")", ",", "desc", "=", "'scoring'", ",", "total", "=", "num_batches", ")", ":", "\n", "            ", "batch_scores", ",", "_", "=", "model", "(", "Variable", "(", "images", "[", "i", ":", "i", "+", "args", ".", "batch_size", "]", ".", "cuda", "(", ")", ")", ")", "\n", "scores", ".", "append", "(", "batch_scores", ".", "data", ".", "cpu", "(", ")", ")", "\n", "\n", "", "scores", "=", "torch", ".", "cat", "(", "scores", ",", "0", ")", ".", "numpy", "(", ")", "\n", "calibration", "=", "[", "]", "\n", "neg_mult", "=", "5", "\n", "for", "attr_id", ",", "imfns", "in", "tqdm", "(", "enumerate", "(", "attr2im", ")", ",", "desc", "=", "'calibrating'", ",", "total", "=", "len", "(", "attr2im", ")", ")", ":", "\n", "            ", "pos_scores", "=", "scores", "[", "np", ".", "where", "(", "labels", "[", ":", ",", "attr_id", "]", ">", "0", ")", "[", "0", "]", ",", "attr_id", "]", "\n", "calibration", ".", "append", "(", "np", ".", "median", "(", "pos_scores", ")", ")", "\n", "\n", "", "pickle", ".", "dump", "(", "calibration", ",", "open", "(", "calibration_params", ",", "'wb'", ")", ")", "\n", "\n", "", "test_acc", "=", "test", "(", "test_loader", ",", "model", ",", "calibration", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VisionLearningGroup_SANE.tools.sane_eval.test": [[190, 251], ["os.path.exists", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "test_loader.dataset.set_labels_scores", "tqdm.tqdm", "numpy.vstack", "print", "numpy.save", "pickle.load", "pickle.load", "model.eval", "enumerate", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().view", "torch.cat().view", "torch.cat().view", "pickle.dump", "enumerate", "enumerate", "np.vstack.append", "open", "open", "torch.autograd.Variable", "torch.cat().numpy.append", "print", "torch.cat().cpu().numpy.append", "len", "open", "len", "images.cuda.cuda", "model", "torch.cat().view.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat", "torch.cat", "torch.cat", "torch.cat().view.cpu().numpy", "model", "model", "torch.cat", "torch.cat", "torch.cat", "torch.cat().view.cpu"], "function", ["None"], ["", "def", "test", "(", "test_loader", ",", "model", ",", "calibration", ")", ":", "\n", "    ", "attr_fn", "=", "'data/val_%s_attr_scores_sigmoid.pkl'", "%", "args", ".", "dataset", "\n", "if", "os", ".", "path", ".", "exists", "(", "attr_fn", ")", ":", "\n", "        ", "data", "=", "pickle", ".", "load", "(", "open", "(", "attr_fn", ",", "'rb'", ")", ")", "\n", "scores", ",", "heatmaps", ",", "labels", "=", "data", "[", "'scores'", "]", ",", "data", "[", "'heatmaps'", "]", ",", "data", "[", "'labels'", "]", "\n", "", "else", ":", "\n", "        ", "attr_fn", "=", "'data/%s_attr_scores_sigmoid.pkl'", "%", "args", ".", "dataset", "\n", "data", "=", "pickle", ".", "load", "(", "open", "(", "attr_fn", ",", "'rb'", ")", ")", "\n", "scores", ",", "heatmaps", ",", "labels", "=", "data", "[", "'scores'", "]", ",", "data", "[", "'heatmaps'", "]", ",", "data", "[", "'labels'", "]", "\n", "\n", "# switch to evaluation mode", "\n", "model", ".", "eval", "(", ")", "\n", "#scores = []", "\n", "heatmaps", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "# for test/val data we get images only from the data loader", "\n", "for", "batch_idx", ",", "(", "images", ",", "im_labels", ",", "_", ",", "_", ")", "in", "enumerate", "(", "test_loader", ")", ":", "\n", "            ", "if", "args", ".", "cuda", ":", "\n", "                ", "images", "=", "images", ".", "cuda", "(", ")", "\n", "\n", "", "images", "=", "Variable", "(", "images", ")", "\n", "labels", ".", "append", "(", "im_labels", ")", "\n", "if", "args", ".", "attr_model", "==", "'classifier'", ":", "\n", "                ", "pred", "=", "model", "(", "images", ")", "\n", "", "else", ":", "\n", "                ", "if", "args", ".", "attr_model", "==", "'latent'", ":", "\n", "                    ", "pred", ",", "heatmap", ",", "_", "=", "model", "(", "images", ")", "\n", "", "else", ":", "\n", "                    ", "pred", ",", "heatmap", "=", "model", "(", "images", ")", "\n", "\n", "", "heatmaps", ".", "append", "(", "heatmap", ".", "data", ")", "\n", "\n", "", "print", "(", "pred", ".", "data", ")", "\n", "assert", "False", "\n", "scores", ".", "append", "(", "pred", ".", "data", ")", "\n", "\n", "", "labels", "=", "torch", ".", "cat", "(", "labels", ")", ".", "numpy", "(", ")", "\n", "scores", "=", "torch", ".", "cat", "(", "scores", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "heatmaps", "=", "torch", ".", "cat", "(", "heatmaps", ")", ".", "view", "(", "len", "(", "scores", ")", ",", "scores", ".", "shape", "[", "1", "]", ",", "-", "1", ")", "\n", "pickle", ".", "dump", "(", "{", "'scores'", ":", "scores", ",", "\n", "'heatmaps'", ":", "heatmaps", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "'labels'", ":", "labels", "}", ",", "open", "(", "attr_fn", ",", "'wb'", ")", ")", "\n", "\n", "", "if", "args", ".", "dataset", "==", "'polyvore_outfits'", ":", "\n", "        ", "for", "i", ",", "thresh", "in", "enumerate", "(", "calibration", ")", ":", "\n", "            ", "labels", "[", ":", ",", "i", "]", "=", "(", "(", "scores", "[", ":", ",", "i", "]", ">", "thresh", ")", "+", "labels", "[", ":", ",", "i", "]", ")", ">", "0", "\n", "", "", "else", ":", "\n", "        ", "labels", "=", "labels", ">", "0", "\n", "\n", "", "scores", "=", "torch", ".", "from_numpy", "(", "scores", ")", "\n", "test_loader", ".", "dataset", ".", "set_labels_scores", "(", "labels", ",", "scores", ")", "\n", "removal_scores", "=", "[", "]", "\n", "for", "i", ",", "(", "removes", ")", "in", "tqdm", "(", "enumerate", "(", "test_loader", ")", ",", "\n", "desc", "=", "'%s attribute caching'", "%", "args", ".", "dataset", ",", "\n", "total", "=", "len", "(", "test_loader", ")", ")", ":", "\n", "        ", "removal_scores", ".", "append", "(", "removes", ")", "\n", "\n", "", "removal_scores", "=", "np", ".", "vstack", "(", "removal_scores", ")", "\n", "print", "(", "removal_scores", ".", "shape", ")", "\n", "\n", "np", ".", "save", "(", "'data/%s_orcale_removal_sigmoid.npy'", "%", "args", ".", "dataset", ",", "removal_scores", ")", "\n", "\n"]]}