{"home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.eval_PCKh.get_PCKh_penn": [[12, 84], ["numpy.zeros", "numpy.zeros", "range", "numpy.divide", "numpy.mean", "print", "print", "nFrames[].int", "torch.zeros", "torch.zeros", "range", "numpy.sum", "numpy.multiply", "numpy.sum", "numpy.sum", "numpy.sum", "len", "len", "len", "len", "torch.norm", "vis.numpy", "vis.numpy", "str", "torch.norm", "torch.max", "torch.ones", "torch.zeros.numpy", "torch.zeros.numpy", "torch.norm", "len"], "function", ["None"], ["def", "get_PCKh_penn", "(", "Test_gt", ",", "Test_out", ",", "Visbility", ",", "Bbox", ",", "nFrames", ",", "normTorso", ")", ":", "\n", "# adopted code from : https://github.com/lawy623/LSTM_Pose_Machines/blob/master/testing/src/run_benchmark_GPU_PENN.m", "\n", "# Penn Action Official Joints Info, Menglong", "\n", "# 0.  head", "\n", "# 1.  left_shoulder  2.  right_shoulder", "\n", "# 3.  left_elbow     4.  right_elbow", "\n", "# 5.  left_wrist     6.  right_wrist", "\n", "# 7.  left_hip       8.  right_hip", "\n", "# 9.  left_knee      10. right_knee", "\n", "# 11. left_ankle     12. right_ankle", "\n", "\n", "# orderToPENN = [0 2 5 4 7 5 8 9 12 10 13 11 14];", "\n", "    ", "gtJointOrder", "=", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", ",", "11", ",", "12", "]", "\n", "thresh", "=", "0.2", "\n", "\n", "\n", "# torso_norm = 1 # 1: Torso / 0:bbx; default as 0 -> 0.2*max(h,w)", "\n", "sample_num", "=", "Test_gt", ".", "shape", "[", "0", "]", "\n", "\n", "HitPoint", "=", "np", ".", "zeros", "(", "(", "sample_num", ",", "len", "(", "gtJointOrder", ")", ")", ")", "\n", "visible_joint", "=", "np", ".", "zeros", "(", "(", "sample_num", ",", "len", "(", "gtJointOrder", ")", ")", ")", "\n", "\n", "for", "sample", "in", "range", "(", "0", ",", "sample_num", ")", ":", "\n", "# print('test sample:', sample)", "\n", "        ", "test_gt", "=", "Test_gt", "[", "sample", "]", "\n", "test_out", "=", "Test_out", "[", "sample", "]", "\n", "visibility", "=", "Visbility", "[", "sample", "]", "\n", "bbox", "=", "Bbox", "[", "sample", "]", "\n", "nframes", "=", "nFrames", "[", "sample", "]", ".", "int", "(", ")", "\n", "\n", "if", "nframes", ">=", "test_gt", ".", "shape", "[", "0", "]", ":", "\n", "            ", "nfr", "=", "test_gt", ".", "shape", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "nfr", "=", "nframes", "\n", "\n", "# num_frame = test_gt.shape[0]", "\n", "", "seqError", "=", "torch", ".", "zeros", "(", "nfr", ",", "len", "(", "gtJointOrder", ")", ")", "\n", "\n", "seqThresh", "=", "torch", ".", "zeros", "(", "nfr", ",", "len", "(", "gtJointOrder", ")", ")", "\n", "for", "frame", "in", "range", "(", "0", ",", "nfr", ")", ":", "\n", "            ", "gt", "=", "test_gt", "[", "frame", "]", "# 13x2", "\n", "pred", "=", "test_out", "[", "frame", "]", "# 13x2", "\n", "# vis = visibility[frame] # 1x13", "\n", "\n", "if", "normTorso", ":", "\n", "                ", "bodysize", "=", "torch", ".", "norm", "(", "gt", "[", "2", "]", "-", "gt", "[", "7", "]", ")", "\n", "if", "bodysize", "<", "1", ":", "\n", "                    ", "bodysize", "=", "torch", ".", "norm", "(", "pred", "[", "2", "]", "-", "pred", "[", "7", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "bodysize", "=", "torch", ".", "max", "(", "bbox", "[", "frame", ",", "2", "]", "-", "bbox", "[", "frame", ",", "0", "]", ",", "bbox", "[", "frame", ",", "3", "]", "-", "bbox", "[", "frame", ",", "1", "]", ")", "\n", "\n", "\n", "", "error_dis", "=", "torch", ".", "norm", "(", "gt", "-", "pred", ",", "p", "=", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "False", ")", "\n", "\n", "seqError", "[", "frame", "]", "=", "error_dis", "\n", "seqThresh", "[", "frame", "]", "=", "(", "bodysize", "*", "thresh", ")", "*", "torch", ".", "ones", "(", "len", "(", "gtJointOrder", ")", ")", "\n", "\n", "", "vis", "=", "visibility", "[", "0", ":", "nfr", "]", "\n", "visible_joint", "[", "sample", "]", "=", "np", ".", "sum", "(", "vis", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "less_than_thresh", "=", "np", ".", "multiply", "(", "seqError", ".", "numpy", "(", ")", "<=", "seqThresh", ".", "numpy", "(", ")", ",", "vis", ".", "numpy", "(", ")", ")", "\n", "# visibleJoint = np.sum(visibility.numpy(), axis=0)", "\n", "HitPoint", "[", "sample", "]", "=", "np", ".", "sum", "(", "less_than_thresh", ",", "axis", "=", "0", ")", "\n", "\n", "# finalPCK = np.divide(np.sum(HitPoint, axis=0), np.sum(np.sum(Visbility.numpy(), axis=1), axis=0))", "\n", "", "finalPCK", "=", "np", ".", "divide", "(", "np", ".", "sum", "(", "HitPoint", ",", "axis", "=", "0", ")", ",", "np", ".", "sum", "(", "visible_joint", ",", "axis", "=", "0", ")", ")", "\n", "finalMean", "=", "np", ".", "mean", "(", "finalPCK", ")", "\n", "print", "(", "'normTorso,    Head,      Shoulder,   Elbow,    Wrist,     Hip,     Knee,    Ankle,  Mean'", ")", "\n", "print", "(", "'{:5s}        {:.4f}      {:.4f}     {:.4f}     {:.4f}      {:.4f}    {:.4f}    {:.4f}   {:.4f}'", ".", "format", "(", "str", "(", "normTorso", ")", ",", "\n", "finalPCK", "[", "0", "]", ",", "0.5", "*", "(", "finalPCK", "[", "1", "]", "+", "finalPCK", "[", "2", "]", ")", ",", "0.5", "*", "(", "finalPCK", "[", "3", "]", "+", "finalPCK", "[", "4", "]", ")", ",", "0.5", "*", "(", "finalPCK", "[", "5", "]", "+", "finalPCK", "[", "6", "]", ")", ",", "\n", "0.5", "*", "(", "finalPCK", "[", "7", "]", "+", "finalPCK", "[", "8", "]", ")", ",", "0.5", "*", "(", "finalPCK", "[", "9", "]", "+", "finalPCK", "[", "10", "]", ")", ",", "0.5", "*", "(", "finalPCK", "[", "11", "]", "+", "finalPCK", "[", "12", "]", ")", ",", "finalMean", ")", ")", "\n", "\n", "return", "finalMean", ",", "finalPCK", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.eval_PCKh.get_PCKh_jhmdb": [[86, 166], ["numpy.zeros", "numpy.ones", "numpy.ones", "range", "numpy.divide", "numpy.mean", "print", "print", "torch.zeros", "torch.zeros", "range", "numpy.sum", "numpy.sum", "numpy.divide", "numpy.mean", "numpy.sum", "numpy.sum", "len", "len", "len", "nframes.int", "len", "len", "torch.norm", "torch.FloatTensor", "torch.zeros.numpy", "torch.zeros.numpy", "numpy.sum", "numpy.sum", "str", "torch.norm", "torch.max", "torch.ones", "torch.norm", "len"], "function", ["None"], ["", "def", "get_PCKh_jhmdb", "(", "Test_gt", ",", "Test_out", ",", "Bbox", ",", "nFrames", ",", "imgPath", ",", "normTorso", ")", ":", "\n", "\n", "# 0: neck    1:belly   2: face", "\n", "# 3: right shoulder  4: left shoulder", "\n", "# 5: right hip       6: left hip", "\n", "# 7: right elbow     8: left elbow", "\n", "# 9: right knee      10: left knee", "\n", "# 11: right wrist    12: left wrist", "\n", "# 13: right ankle    14: left ankle", "\n", "\n", "    ", "orderJHMDB", "=", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", ",", "11", ",", "12", ",", "13", ",", "14", "]", "\n", "thresh", "=", "0.2", "\n", "N", "=", "Test_out", ".", "shape", "[", "1", "]", "\n", "if", "normTorso", ":", "\n", "        ", "torso_norm", "=", "1", "# 1: Torso / 0:bbx; default as 0 -> 0.2*max(h,w)", "\n", "", "else", ":", "\n", "        ", "torso_norm", "=", "0", "\n", "", "sample_num", "=", "Test_gt", ".", "shape", "[", "0", "]", "\n", "\n", "HitPoint", "=", "np", ".", "zeros", "(", "(", "sample_num", ",", "len", "(", "orderJHMDB", ")", ")", ")", "\n", "allPoint", "=", "np", ".", "ones", "(", "(", "sample_num", ",", "N", ",", "len", "(", "orderJHMDB", ")", ")", ")", "\n", "Point_to_use", "=", "np", ".", "ones", "(", "(", "sample_num", ",", "len", "(", "orderJHMDB", ")", ")", ")", "\n", "\n", "\n", "for", "sample", "in", "range", "(", "0", ",", "sample_num", ")", ":", "\n", "# print('test sample:', sample)", "\n", "        ", "test_gt", "=", "Test_gt", "[", "sample", "]", "\n", "test_out", "=", "Test_out", "[", "sample", "]", "\n", "nframes", "=", "nFrames", "[", "sample", "]", "\n", "img_path", "=", "imgPath", "[", "sample", "]", "\n", "bbox", "=", "Bbox", "[", "sample", "]", "\n", "\n", "# num_frame = test_gt.shape[0]", "\n", "if", "nframes", ">=", "test_gt", ".", "shape", "[", "0", "]", ":", "\n", "            ", "nfr", "=", "test_gt", ".", "shape", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "nfr", "=", "nframes", ".", "int", "(", ")", "\n", "\n", "", "seqError", "=", "torch", ".", "zeros", "(", "nfr", ",", "len", "(", "orderJHMDB", ")", ")", "\n", "seqThresh", "=", "torch", ".", "zeros", "(", "nfr", ",", "len", "(", "orderJHMDB", ")", ")", "\n", "\n", "for", "frame", "in", "range", "(", "0", ",", "nfr", ")", ":", "\n", "            ", "gt", "=", "test_gt", "[", "frame", "]", "# 13x2", "\n", "pred", "=", "test_out", "[", "frame", "]", "# 13x2", "\n", "# vis = visibility[frame] # 1x13", "\n", "\n", "if", "torso_norm", "==", "1", ":", "\n", "                ", "bodysize", "=", "torch", ".", "norm", "(", "gt", "[", "4", "]", "-", "gt", "[", "5", "]", ")", "\n", "if", "bodysize", "<", "1", ":", "\n", "                    ", "bodysize", "=", "torch", ".", "norm", "(", "pred", "[", "4", "]", "-", "pred", "[", "5", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "bodysize", "=", "torch", ".", "max", "(", "bbox", "[", "frame", ",", "2", "]", "-", "bbox", "[", "frame", ",", "0", "]", ",", "bbox", "[", "frame", ",", "3", "]", "-", "bbox", "[", "frame", ",", "1", "]", ")", "\n", "\n", "", "error_dis", "=", "torch", ".", "norm", "(", "gt", "-", "pred", ",", "p", "=", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "False", ")", "\n", "\n", "seqError", "[", "frame", "]", "=", "torch", ".", "FloatTensor", "(", "error_dis", ")", "\n", "# seqThresh[frame] = (bodysize * thresh) * torch.ones(partJHMDB)", "\n", "seqThresh", "[", "frame", "]", "=", "(", "bodysize", "*", "thresh", ")", "*", "torch", ".", "ones", "(", "len", "(", "orderJHMDB", ")", ")", "\n", "\n", "", "pts", "=", "allPoint", "[", "sample", ",", "0", ":", "nfr", "]", "\n", "Point_to_use", "[", "sample", "]", "=", "np", ".", "sum", "(", "pts", ",", "axis", "=", "0", ")", "\n", "\n", "less_than_thresh", "=", "seqError", ".", "numpy", "(", ")", "<=", "seqThresh", ".", "numpy", "(", ")", "\n", "HitPoint", "[", "sample", "]", "=", "np", ".", "sum", "(", "less_than_thresh", ",", "axis", "=", "0", ")", "\n", "eachPCK", "=", "np", ".", "divide", "(", "np", ".", "sum", "(", "HitPoint", "[", "sample", "]", ",", "axis", "=", "0", ")", ",", "np", ".", "sum", "(", "Point_to_use", "[", "sample", "]", ",", "axis", "=", "0", ")", ")", "\n", "eachMean", "=", "np", ".", "mean", "(", "eachPCK", ")", "\n", "\n", "# print('sample num:', sample, 'imgpath:', img_path, 'eachMean:', eachMean)", "\n", "\n", "\n", "", "finalPCK", "=", "np", ".", "divide", "(", "np", ".", "sum", "(", "HitPoint", ",", "axis", "=", "0", ")", ",", "np", ".", "sum", "(", "Point_to_use", ",", "axis", "=", "0", ")", ")", "\n", "\n", "finalMean", "=", "np", ".", "mean", "(", "finalPCK", ")", "\n", "print", "(", "'normTorso,     Head,     Shoulder,     Elbow,     Wrist,     Hip,      Knee,     Ankle,    Mean'", ")", "\n", "\n", "print", "(", "'{:5s}          {:.4f}      {:.4f}      {:.4f}     {:.4f}     {:.4f}    {:.4f}    {:.4f}   {:.4f}'", ".", "format", "(", "str", "(", "normTorso", ")", ",", "finalPCK", "[", "2", "]", ",", "\n", "0.5", "*", "(", "finalPCK", "[", "3", "]", "+", "finalPCK", "[", "4", "]", ")", ",", "0.5", "*", "(", "finalPCK", "[", "7", "]", "+", "finalPCK", "[", "8", "]", ")", ",", "0.5", "*", "(", "finalPCK", "[", "11", "]", "+", "finalPCK", "[", "12", "]", ")", ",", "\n", "0.5", "*", "(", "finalPCK", "[", "5", "]", "+", "finalPCK", "[", "6", "]", ")", ",", "0.5", "*", "(", "finalPCK", "[", "9", "]", "+", "finalPCK", "[", "10", "]", ")", ",", "0.5", "*", "(", "finalPCK", "[", "13", "]", "+", "finalPCK", "[", "14", "]", ")", ",", "finalMean", ")", ")", "\n", "\n", "return", "finalMean", ",", "finalPCK", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.eval_PCKh.eval_PCKh": [[167, 232], ["numpy.transpose", "numpy.linalg.norm", "numpy.linalg.norm", "numpy.multiply", "numpy.divide", "numpy.multiply", "numpy.sum", "numpy.multiply", "numpy.divide", "numpy.arange", "numpy.zeros", "range", "numpy.ma.array", "print", "print", "numpy.ones", "len", "numpy.multiply", "numpy.divide", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.sum", "len", "numpy.mean", "len", "numpy.sum"], "function", ["None"], ["", "def", "eval_PCKh", "(", "dict", ",", "preds", ",", "model_name", ",", "idx", ")", ":", "\n", "    ", "threshold", "=", "0.5", "\n", "SC_BIAS", "=", "0.6", "\n", "pa", "=", "[", "2", ",", "3", ",", "7", ",", "7", ",", "4", ",", "5", ",", "8", ",", "9", ",", "10", ",", "0", ",", "12", ",", "13", ",", "8", ",", "8", ",", "14", ",", "15", "]", "\n", "\n", "dataset_joints", "=", "dict", "[", "'dataset_joints'", "]", "\n", "jnt_missing", "=", "dict", "[", "'jnt_missing'", "]", "[", ":", ",", "idx", "]", "\n", "# pos_pred_src = dict['pos_pred_src']", "\n", "pos_gt_src", "=", "dict", "[", "'pos_gt_src'", "]", "[", ":", ",", ":", ",", "idx", "]", "\n", "headboxes_src", "=", "dict", "[", "'headboxes_src'", "]", "[", ":", ",", ":", ",", "idx", "]", "\n", "\n", "\n", "\n", "#predictions", "\n", "# model_name = 'hg'", "\n", "# predfile = sys.argv[1]", "\n", "# preds = loadmat(predfile)['preds']", "\n", "\n", "pos_pred_src", "=", "transpose", "(", "preds", ",", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "\n", "head", "=", "np", ".", "where", "(", "dataset_joints", "==", "'head'", ")", "[", "1", "]", "[", "0", "]", "\n", "lsho", "=", "np", ".", "where", "(", "dataset_joints", "==", "'lsho'", ")", "[", "1", "]", "[", "0", "]", "\n", "lelb", "=", "np", ".", "where", "(", "dataset_joints", "==", "'lelb'", ")", "[", "1", "]", "[", "0", "]", "\n", "lwri", "=", "np", ".", "where", "(", "dataset_joints", "==", "'lwri'", ")", "[", "1", "]", "[", "0", "]", "\n", "lhip", "=", "np", ".", "where", "(", "dataset_joints", "==", "'lhip'", ")", "[", "1", "]", "[", "0", "]", "\n", "lkne", "=", "np", ".", "where", "(", "dataset_joints", "==", "'lkne'", ")", "[", "1", "]", "[", "0", "]", "\n", "lank", "=", "np", ".", "where", "(", "dataset_joints", "==", "'lank'", ")", "[", "1", "]", "[", "0", "]", "\n", "\n", "rsho", "=", "np", ".", "where", "(", "dataset_joints", "==", "'rsho'", ")", "[", "1", "]", "[", "0", "]", "\n", "relb", "=", "np", ".", "where", "(", "dataset_joints", "==", "'relb'", ")", "[", "1", "]", "[", "0", "]", "\n", "rwri", "=", "np", ".", "where", "(", "dataset_joints", "==", "'rwri'", ")", "[", "1", "]", "[", "0", "]", "\n", "rkne", "=", "np", ".", "where", "(", "dataset_joints", "==", "'rkne'", ")", "[", "1", "]", "[", "0", "]", "\n", "rank", "=", "np", ".", "where", "(", "dataset_joints", "==", "'rank'", ")", "[", "1", "]", "[", "0", "]", "\n", "rhip", "=", "np", ".", "where", "(", "dataset_joints", "==", "'rhip'", ")", "[", "1", "]", "[", "0", "]", "\n", "\n", "jnt_visible", "=", "1", "-", "jnt_missing", "\n", "uv_error", "=", "pos_pred_src", "-", "pos_gt_src", "\n", "uv_err", "=", "np", ".", "linalg", ".", "norm", "(", "uv_error", ",", "axis", "=", "1", ")", "\n", "headsizes", "=", "headboxes_src", "[", "1", ",", ":", ",", ":", "]", "-", "headboxes_src", "[", "0", ",", ":", ",", ":", "]", "\n", "headsizes", "=", "np", ".", "linalg", ".", "norm", "(", "headsizes", ",", "axis", "=", "0", ")", "\n", "headsizes", "*=", "SC_BIAS", "\n", "scale", "=", "np", ".", "multiply", "(", "headsizes", ",", "np", ".", "ones", "(", "(", "len", "(", "uv_err", ")", ",", "1", ")", ")", ")", "\n", "scaled_uv_err", "=", "np", ".", "divide", "(", "uv_err", ",", "scale", ")", "\n", "scaled_uv_err", "=", "np", ".", "multiply", "(", "scaled_uv_err", ",", "jnt_visible", ")", "\n", "jnt_count", "=", "np", ".", "sum", "(", "jnt_visible", ",", "axis", "=", "1", ")", "\n", "less_than_threshold", "=", "np", ".", "multiply", "(", "(", "scaled_uv_err", "<", "threshold", ")", ",", "jnt_visible", ")", "\n", "PCKh", "=", "np", ".", "divide", "(", "100.", "*", "np", ".", "sum", "(", "less_than_threshold", ",", "axis", "=", "1", ")", ",", "jnt_count", ")", "\n", "\n", "\n", "# save", "\n", "rng", "=", "np", ".", "arange", "(", "0", ",", "0.5", ",", "0.01", ")", "\n", "pckAll", "=", "np", ".", "zeros", "(", "(", "len", "(", "rng", ")", ",", "16", ")", ")", "\n", "\n", "for", "r", "in", "range", "(", "len", "(", "rng", ")", ")", ":", "\n", "        ", "threshold", "=", "rng", "[", "r", "]", "\n", "less_than_threshold", "=", "np", ".", "multiply", "(", "scaled_uv_err", "<", "threshold", ",", "jnt_visible", ")", "\n", "pckAll", "[", "r", ",", ":", "]", "=", "np", ".", "divide", "(", "100.", "*", "np", ".", "sum", "(", "less_than_threshold", ",", "axis", "=", "1", ")", ",", "jnt_count", ")", "\n", "\n", "# name = predfile.split(os.sep)[-1]", "\n", "", "PCKh", "=", "np", ".", "ma", ".", "array", "(", "PCKh", ",", "mask", "=", "False", ")", "\n", "PCKh", ".", "mask", "[", "6", ":", "8", "]", "=", "True", "\n", "print", "(", "\"Model,  Head,   Shoulder, Elbow,  Wrist,   Hip,     Knee,    Ankle,  Mean\"", ")", "\n", "print", "(", "'{:5s}   {:.2f}   {:.2f}     {:.2f}   {:.2f}    {:.2f}    {:.2f}    {:.2f}   {:.2f}'", ".", "format", "(", "model_name", ",", "PCKh", "[", "head", "]", ",", "0.5", "*", "(", "PCKh", "[", "lsho", "]", "+", "PCKh", "[", "rsho", "]", ")", ",", "0.5", "*", "(", "PCKh", "[", "lelb", "]", "+", "PCKh", "[", "relb", "]", ")", ",", "0.5", "*", "(", "PCKh", "[", "lwri", "]", "+", "PCKh", "[", "rwri", "]", ")", ",", "0.5", "*", "(", "PCKh", "[", "lhip", "]", "+", "PCKh", "[", "rhip", "]", ")", ",", "0.5", "*", "(", "PCKh", "[", "lkne", "]", "+", "PCKh", "[", "rkne", "]", ")", ",", "0.5", "*", "(", "PCKh", "[", "lank", "]", "+", "PCKh", "[", "rank", "]", ")", ",", "np", ".", "mean", "(", "PCKh", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.PENN_dloader.pennDataset.__init__": [[63, 99], ["len", "six.moves.xrange", "numpy.concatenate", "numpy.concatenate", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std", "len", "annot[].astype", "annot[].astype", "numpy.concatenate.append", "numpy.concatenate.append", "len", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "trainAnnot", ",", "testAnnot", ",", "T", ",", "split", ")", ":", "\n", "# self.dataRoot = data_root", "\n", "\n", "        ", "self", ".", "trainSet", "=", "trainAnnot", "[", "0", ":", "1000", "]", "\n", "self", ".", "testSet", "=", "testAnnot", "\n", "self", ".", "valSet", "=", "trainAnnot", "[", "1000", ":", "]", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "inputLen", "=", "T", "\n", "self", ".", "numJoint", "=", "13", "\n", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "self", ".", "dataLen", "=", "len", "(", "self", ".", "trainSet", ")", "\n", "", "elif", "self", ".", "split", "==", "'val'", ":", "\n", "            ", "self", ".", "dataLen", "=", "len", "(", "self", ".", "valSet", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dataLen", "=", "len", "(", "self", ".", "testSet", ")", "\n", "\n", "\n", "", "numData", "=", "len", "(", "self", ".", "trainSet", ")", "\n", "\n", "X", "=", "[", "]", "\n", "Y", "=", "[", "]", "\n", "for", "i", "in", "xrange", "(", "numData", ")", ":", "\n", "            ", "annot", "=", "self", ".", "trainSet", "[", "i", "]", "[", "'annot'", "]", "\n", "x", "=", "annot", "[", "'x'", "]", ".", "astype", "(", "float", ")", "\n", "y", "=", "annot", "[", "'y'", "]", ".", "astype", "(", "float", ")", "\n", "X", ".", "append", "(", "x", ")", "\n", "Y", ".", "append", "(", "y", ")", "\n", "\n", "# X[i] = x", "\n", "# Y[i] = y", "\n", "", "X", "=", "np", ".", "concatenate", "(", "(", "X", ")", ",", "axis", "=", "0", ")", "\n", "Y", "=", "np", ".", "concatenate", "(", "(", "Y", ")", ",", "axis", "=", "0", ")", "\n", "self", ".", "meanX", "=", "np", ".", "mean", "(", "X", ",", "axis", "=", "0", ")", "\n", "self", ".", "stdX", "=", "np", ".", "std", "(", "X", ",", "axis", "=", "0", ")", "\n", "self", ".", "meanY", "=", "np", ".", "mean", "(", "Y", ",", "axis", "=", "0", ")", "\n", "self", ".", "stdY", "=", "np", ".", "std", "(", "Y", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.PENN_dloader.pennDataset.__len__": [[101, 103], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dataLen", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.PENN_dloader.pennDataset.read_annot": [[106, 124], ["[].astype", "[].astype", "numpy.concatenate().astype", "[].astype", "[].astype", "numpy.concatenate().astype", "numpy.double", "numpy.concatenate", "numpy.concatenate", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims"], "methods", ["None"], ["", "def", "read_annot", "(", "self", ",", "annotSet", ")", ":", "\n", "        ", "imgFolderPath", "=", "annotSet", "[", "'imgFolderPath'", "]", "\n", "x", "=", "annotSet", "[", "'annot'", "]", "[", "'x'", "]", ".", "astype", "(", "float", ")", "\n", "y", "=", "annotSet", "[", "'annot'", "]", "[", "'y'", "]", ".", "astype", "(", "float", ")", "\n", "\n", "skeleton", "=", "np", ".", "concatenate", "(", "(", "np", ".", "expand_dims", "(", "x", ",", "2", ")", ",", "np", ".", "expand_dims", "(", "y", ",", "2", ")", ")", ",", "axis", "=", "2", ")", ".", "astype", "(", "float", ")", "# T x 13 x 2", "\n", "\n", "visibility", "=", "annotSet", "[", "'annot'", "]", "[", "'visibility'", "]", ".", "astype", "(", "float", ")", "\n", "nframes", "=", "annotSet", "[", "'annot'", "]", "[", "'nframes'", "]", "\n", "bbox", "=", "annotSet", "[", "'annot'", "]", "[", "'bbox'", "]", ".", "astype", "(", "float", ")", "\n", "# self.numJoint = skeleton.shape[1]", "\n", "\n", "xnorm", "=", "(", "x", "-", "self", ".", "meanX", ")", "/", "self", ".", "stdX", "\n", "ynorm", "=", "(", "y", "-", "self", ".", "meanY", ")", "/", "self", ".", "stdY", "\n", "\n", "skeleton_norm", "=", "np", ".", "concatenate", "(", "(", "np", ".", "expand_dims", "(", "xnorm", ",", "2", ")", ",", "np", ".", "expand_dims", "(", "ynorm", ",", "2", ")", ")", ",", "axis", "=", "2", ")", ".", "astype", "(", "float", ")", "\n", "\n", "return", "imgFolderPath", ",", "skeleton", ",", "skeleton_norm", ",", "visibility", ",", "np", ".", "double", "(", "nframes", ")", ",", "bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.PENN_dloader.pennDataset.unnormData": [[125, 137], ["numpy.expand_dims().repeat().transpose", "numpy.expand_dims().repeat().transpose", "numpy.expand_dims().repeat().transpose", "numpy.expand_dims().repeat().transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.DoubleTensor", "torch.DoubleTensor", "torch.DoubleTensor", "torch.DoubleTensor", "torch.DoubleTensor", "torch.DoubleTensor", "torch.DoubleTensor", "torch.DoubleTensor", "numpy.expand_dims().repeat", "numpy.expand_dims().repeat", "numpy.expand_dims().repeat", "numpy.expand_dims().repeat", "skeletonNorm[].double", "torch.DoubleTensor", "torch.DoubleTensor", "torch.DoubleTensor", "torch.DoubleTensor", "numpy.expand_dims", "skeletonNorm[].double", "torch.DoubleTensor", "torch.DoubleTensor", "torch.DoubleTensor", "torch.DoubleTensor", "numpy.expand_dims", "unnorm_X.unsqueeze", "unnorm_Y.unsqueeze", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims"], "methods", ["None"], ["", "def", "unnormData", "(", "self", ",", "skeletonNorm", ")", ":", "\n", "        ", "meanX_mat", "=", "np", ".", "expand_dims", "(", "self", ".", "meanX", ",", "1", ")", ".", "repeat", "(", "self", ".", "inputLen", ",", "1", ")", ".", "transpose", "(", "1", ",", "0", ")", "# T x 13", "\n", "meanY_mat", "=", "np", ".", "expand_dims", "(", "self", ".", "meanY", ",", "1", ")", ".", "repeat", "(", "self", ".", "inputLen", ",", "1", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "stdX_mat", "=", "np", ".", "expand_dims", "(", "self", ".", "stdX", ",", "1", ")", ".", "repeat", "(", "self", ".", "inputLen", ",", "1", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "stdY_mat", "=", "np", ".", "expand_dims", "(", "self", ".", "stdY", ",", "1", ")", ".", "repeat", "(", "self", ".", "inputLen", ",", "1", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "\n", "unnorm_X", "=", "skeletonNorm", "[", ":", ",", ":", ",", ":", ",", "0", "]", ".", "double", "(", ")", "*", "torch", ".", "DoubleTensor", "(", "np", ".", "expand_dims", "(", "stdX_mat", ",", "0", ")", ")", "+", "torch", ".", "DoubleTensor", "(", "np", ".", "expand_dims", "(", "meanX_mat", ",", "0", ")", ")", "\n", "unnorm_Y", "=", "skeletonNorm", "[", ":", ",", ":", ",", ":", ",", "1", "]", ".", "double", "(", ")", "*", "torch", ".", "DoubleTensor", "(", "np", ".", "expand_dims", "(", "stdY_mat", ",", "0", ")", ")", "+", "torch", ".", "DoubleTensor", "(", "np", ".", "expand_dims", "(", "meanY_mat", ",", "0", ")", ")", "\n", "\n", "skeleton_unnorm", "=", "torch", ".", "cat", "(", "(", "unnorm_X", ".", "unsqueeze", "(", "3", ")", ",", "unnorm_Y", ".", "unsqueeze", "(", "3", ")", ")", ",", "3", ")", "\n", "\n", "return", "skeleton_unnorm", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.PENN_dloader.pennDataset.preProcessImage": [[138, 157], ["os.listdir", "os.listdir.sort", "six.moves.xrange", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "os.path.join", "PIL.Image.open", "torchvision.transforms.Compose", "torchvision.transforms.Compose.", "torch.cat.append", "torch.cat.append", "transforms.Compose.unsqueeze", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["None"], ["", "def", "preProcessImage", "(", "self", ",", "imgFolderPath", ")", ":", "\n", "        ", "imgList", "=", "os", ".", "listdir", "(", "imgFolderPath", ")", "\n", "imgList", ".", "sort", "(", ")", "# list image in a descent order", "\n", "imgSequence", "=", "[", "]", "\n", "for", "i", "in", "xrange", "(", "len", "(", "imgList", ")", ")", ":", "\n", "            ", "imgPath", "=", "os", ".", "path", ".", "join", "(", "imgFolderPath", ",", "imgList", "[", "i", "]", ")", "\n", "input_image", "=", "Image", ".", "open", "(", "imgPath", ")", "\n", "preprocess", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "256", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "224", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ",", "\n", "]", ")", "\n", "img_tensor", "=", "preprocess", "(", "input_image", ")", "\n", "imgSequence", ".", "append", "(", "img_tensor", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "imgSequence", "=", "torch", ".", "cat", "(", "(", "imgSequence", ")", ",", "0", ")", "\n", "\n", "return", "imgSequence", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.PENN_dloader.pennDataset.data_to_use": [[158, 260], ["random.seed", "skeleton.squeeze.squeeze.squeeze", "visibility.squeeze.squeeze.squeeze", "bbox.squeeze.squeeze.squeeze", "len", "int.int", "int", "random.randint", "range", "numpy.concatenate().astype", "numpy.concatenate().astype", "numpy.concatenate().astype", "torch.cat().type", "torch.cat().type", "torch.cat().type", "torch.cat().type", "numpy.ones", "len", "len", "torch.cat.append", "torch.cat.append", "numpy.concatenate.append", "numpy.concatenate.append", "numpy.concatenate.append", "random.randint", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.ones", "six.moves.xrange", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "numpy.concatenate", "numpy.concatenate().astype", "numpy.concatenate().astype", "numpy.concatenate().astype", "torch.cat().type", "torch.cat().type", "torch.cat().type", "torch.cat().type", "numpy.ones", "numpy.concatenate().astype", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat.append", "torch.cat.append", "numpy.concatenate.append", "numpy.concatenate.append", "numpy.concatenate.append", "m_idx.append", "torch.zeros.unsqueeze", "torch.zeros.unsqueeze", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "numpy.concatenate"], "methods", ["None"], ["", "def", "data_to_use", "(", "self", ",", "nframes", ",", "skeleton", ",", "visibility", ",", "bbox", ",", "imgSequence", ",", "shiftTimes", ")", ":", "\n", "        ", "\"\"\"\"\"\n        'shift times: we used T=40 for each training or testing sequence, if given video is more than 40, for training, we randomly pick \n         concecutive 40 frames; for testing, we shifted sequence until the getting the last frame. \n         \n         'if the sequence is less than 40, we added dummy frames behind'\n        \"\"\"", "\"\"", "\n", "random", ".", "seed", "(", "1234567890", ")", "\n", "useLen", "=", "self", ".", "inputLen", "\n", "stepSize", "=", "10", "\n", "if", "len", "(", "skeleton", ".", "shape", ")", "==", "4", "and", "len", "(", "visibility", ".", "shape", ")", "==", "3", ":", "\n", "            ", "skeleton", "=", "skeleton", ".", "squeeze", "(", "0", ")", "\n", "visibility", "=", "visibility", ".", "squeeze", "(", "0", ")", "\n", "bbox", "=", "bbox", ".", "squeeze", "(", "0", ")", "\n", "\n", "", "if", "len", "(", "nframes", ".", "shape", ")", "==", "1", ":", "# if nframes is a tensor", "\n", "            ", "nframes", "=", "nframes", ".", "int", "(", ")", "\n", "", "else", ":", "\n", "            ", "nframes", "=", "int", "(", "nframes", ")", "\n", "\n", "", "if", "nframes", ">", "useLen", "+", "stepSize", "*", "shiftTimes", ":", "\n", "\n", "            ", "idx", "=", "random", ".", "randint", "(", "0", ",", "nframes", "-", "self", ".", "inputLen", "-", "10", "*", "shiftTimes", ")", "\n", "sequence", "=", "[", "]", "\n", "vis", "=", "[", "]", "\n", "bbx", "=", "[", "]", "\n", "sequence_img", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "shiftTimes", ")", ":", "\n", "                ", "data_sel", "=", "skeleton", "[", "idx", "+", "i", "*", "stepSize", ":", "idx", "+", "i", "*", "stepSize", "+", "self", ".", "inputLen", "]", "\n", "vis_sel", "=", "visibility", "[", "idx", "+", "i", "*", "stepSize", ":", "idx", "+", "i", "*", "stepSize", "+", "self", ".", "inputLen", "]", "\n", "bbx_sel", "=", "bbox", "[", "idx", "+", "i", "*", "stepSize", ":", "idx", "+", "i", "*", "stepSize", "+", "self", ".", "inputLen", "]", "\n", "img_sel", "=", "imgSequence", "[", "idx", "+", "i", "*", "stepSize", ":", "idx", "+", "i", "*", "stepSize", "+", "self", ".", "inputLen", "]", "# tensor", "\n", "\n", "\n", "sequence_img", ".", "append", "(", "img_sel", ")", "\n", "sequence", ".", "append", "(", "np", ".", "expand_dims", "(", "data_sel", ",", "0", ")", ")", "\n", "vis", ".", "append", "(", "np", ".", "expand_dims", "(", "vis_sel", ",", "0", ")", ")", "\n", "bbx", ".", "append", "(", "np", ".", "expand_dims", "(", "bbx_sel", ",", "0", ")", ")", "\n", "\n", "", "sequence_to_use", "=", "np", ".", "concatenate", "(", "sequence", ",", "axis", "=", "0", ")", ".", "astype", "(", "float", ")", "\n", "vis_to_use", "=", "np", ".", "concatenate", "(", "vis", ",", "axis", "=", "0", ")", ".", "astype", "(", "float", ")", "\n", "bbox_to_use", "=", "np", ".", "concatenate", "(", "bbx", ",", "axis", "=", "0", ")", ".", "astype", "(", "float", ")", "\n", "imgSequence_to_use", "=", "torch", ".", "cat", "(", "(", "sequence_img", ")", ",", "0", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "\n", "mask_idx", "=", "np", ".", "ones", "(", "(", "sequence_to_use", ".", "shape", ")", ")", "\n", "\n", "", "elif", "useLen", "<=", "nframes", "<=", "useLen", "+", "10", "*", "shiftTimes", ":", "\n", "            ", "idx", "=", "random", ".", "randint", "(", "0", ",", "nframes", "-", "useLen", ")", "\n", "\n", "data_sel", "=", "np", ".", "expand_dims", "(", "skeleton", "[", "idx", ":", "idx", "+", "useLen", "]", ",", "0", ")", "\n", "vis_sel", "=", "np", ".", "expand_dims", "(", "visibility", "[", "idx", ":", "idx", "+", "useLen", "]", ",", "0", ")", "\n", "bbx_sel", "=", "np", ".", "expand_dims", "(", "bbox", "[", "idx", ":", "idx", "+", "useLen", "]", ",", "0", ")", "\n", "img_sel", "=", "imgSequence", "[", "idx", ":", "idx", "+", "useLen", "]", "\n", "\n", "sequence_to_use", "=", "data_sel", "\n", "vis_to_use", "=", "vis_sel", "\n", "bbox_to_use", "=", "bbx_sel", "\n", "imgSequence_to_use", "=", "img_sel", "\n", "\n", "mask_idx", "=", "np", ".", "ones", "(", "(", "sequence_to_use", ".", "shape", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "seqLeft", "=", "useLen", "-", "nframes", "\n", "sequence", "=", "[", "]", "\n", "vis", "=", "[", "]", "\n", "bbx", "=", "[", "]", "\n", "sequence_img", "=", "[", "]", "\n", "m_idx", "=", "[", "]", "\n", "idx", "=", "0", "\n", "for", "i", "in", "xrange", "(", "seqLeft", ")", ":", "\n", "\n", "                ", "'padding 0'", "\n", "\n", "mask_sel", "=", "np", ".", "zeros", "(", "(", "self", ".", "numJoint", ",", "2", ")", ")", "\n", "data_sel", "=", "np", ".", "zeros", "(", "(", "self", ".", "numJoint", ",", "2", ")", ")", "\n", "vis_sel", "=", "np", ".", "zeros", "(", "(", "self", ".", "numJoint", ")", ")", "\n", "bbx_sel", "=", "np", ".", "zeros", "(", "(", "4", ")", ")", "\n", "img_sel", "=", "torch", ".", "zeros", "(", "3", ",", "224", ",", "224", ")", "\n", "\n", "sequence_img", ".", "append", "(", "img_sel", ".", "unsqueeze", "(", "0", ")", ")", "\n", "sequence", ".", "append", "(", "np", ".", "expand_dims", "(", "data_sel", ",", "0", ")", ")", "\n", "vis", ".", "append", "(", "np", ".", "expand_dims", "(", "vis_sel", ",", "0", ")", ")", "\n", "bbx", ".", "append", "(", "np", ".", "expand_dims", "(", "bbx_sel", ",", "0", ")", ")", "\n", "m_idx", ".", "append", "(", "np", ".", "expand_dims", "(", "mask_sel", ",", "0", ")", ")", "\n", "\n", "", "sequence", "=", "np", ".", "concatenate", "(", "sequence", ",", "axis", "=", "0", ")", "\n", "vis", "=", "np", ".", "concatenate", "(", "vis", ",", "axis", "=", "0", ")", "\n", "bbx", "=", "np", ".", "concatenate", "(", "bbx", ",", "axis", "=", "0", ")", "\n", "sequence_img", "=", "torch", ".", "cat", "(", "(", "sequence_img", ")", ",", "0", ")", "\n", "ma_idx", "=", "np", ".", "concatenate", "(", "m_idx", ",", "axis", "=", "0", ")", "\n", "\n", "sequence_to_use", "=", "np", ".", "concatenate", "(", "(", "skeleton", ",", "sequence", ")", ",", "axis", "=", "0", ")", ".", "astype", "(", "float", ")", "\n", "vis_to_use", "=", "np", ".", "concatenate", "(", "(", "visibility", ",", "vis", ")", ",", "axis", "=", "0", ")", ".", "astype", "(", "float", ")", "\n", "bbox_to_use", "=", "np", ".", "concatenate", "(", "(", "bbox", ",", "bbx", ")", ",", "axis", "=", "0", ")", ".", "astype", "(", "float", ")", "\n", "imgSequence_to_use", "=", "torch", ".", "cat", "(", "(", "imgSequence", ",", "sequence_img", ")", ",", "0", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "# T x 3 x 224 x 224", "\n", "\n", "\n", "mask_part1", "=", "np", ".", "ones", "(", "(", "skeleton", ".", "shape", ")", ")", "\n", "mask_idx", "=", "np", ".", "concatenate", "(", "(", "mask_part1", ",", "ma_idx", ")", ",", "axis", "=", "0", ")", ".", "astype", "(", "float", ")", "\n", "\n", "\n", "", "return", "sequence_to_use", ",", "vis_to_use", ",", "bbox_to_use", ",", "imgSequence_to_use", ",", "mask_idx", ",", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.PENN_dloader.pennDataset.__getitem__": [[263, 282], ["PENN_dloader.pennDataset.read_annot", "PENN_dloader.pennDataset.preProcessImage", "PENN_dloader.pennDataset.data_to_use"], "methods", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.read_annot", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.preProcessImage", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.data_to_use"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "annotSet", "=", "self", ".", "trainSet", "[", "idx", "]", "\n", "", "else", ":", "\n", "            ", "annotSet", "=", "self", ".", "testSet", "[", "idx", "]", "\n", "\n", "", "imgFolderPath", ",", "skeleton", ",", "skeleton_norm", ",", "visibility", ",", "nframes", ",", "bbox", "=", "self", ".", "read_annot", "(", "annotSet", ")", "\n", "imgSequence", "=", "self", ".", "preProcessImage", "(", "imgFolderPath", ")", "\n", "\n", "skeleton_to_use", ",", "vis_to_use", ",", "bbox_to_use", ",", "imgSequence_to_use", ",", "mask_idx", ",", "idx", "=", "self", ".", "data_to_use", "(", "nframes", ",", "skeleton_norm", ",", "\n", "visibility", ",", "bbox", ",", "\n", "imgSequence", ",", "shiftTimes", "=", "1", ")", "\n", "\n", "\n", "\n", "dict", "=", "{", "'skeleton_to_use'", ":", "skeleton_to_use", ",", "'vis_to_use'", ":", "vis_to_use", ",", "'bbox_to_use'", ":", "bbox_to_use", ",", "\n", "'imgSequence_to_use'", ":", "imgSequence_to_use", ",", "'mask_idx'", ":", "mask_idx", ",", "'nframes'", ":", "nframes", ",", "'randIdx'", ":", "idx", ",", "\n", "'imgPath'", ":", "imgFolderPath", "}", "\n", "return", "dict", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.PENN_dloader.get_train_test_annot": [[32, 61], ["os.path.join", "os.listdir", "os.listdir.sort", "range", "os.path.join", "len", "scipy.io.loadmat", "os.path.join", "os.path.join", "trainAnnot.append", "testAnnot.append"], "function", ["None"], ["def", "get_train_test_annot", "(", "data_root", ")", ":", "\n", "    ", "imgPath", "=", "os", ".", "path", ".", "join", "(", "data_root", ",", "'frames'", ")", "\n", "use_baseline", "=", "False", "\n", "\n", "if", "use_baseline", ":", "\n", "        ", "'dataPath = your baseline path'", "\n", "'make your baseline as the same format as labels'", "\n", "", "else", ":", "\n", "\n", "        ", "dataPath", "=", "os", ".", "path", ".", "join", "(", "data_root", ",", "'labels'", ")", "\n", "\n", "", "skeletonPath", "=", "dataPath", "\n", "\n", "dataList", "=", "os", ".", "listdir", "(", "imgPath", ")", "\n", "dataList", ".", "sort", "(", ")", "\n", "trainAnnot", "=", "[", "]", "\n", "testAnnot", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "dataList", ")", ")", ":", "\n", "        ", "mat_name", "=", "dataList", "[", "i", "]", "+", "'.mat'", "\n", "annot", "=", "scipy", ".", "io", ".", "loadmat", "(", "os", ".", "path", ".", "join", "(", "skeletonPath", ",", "mat_name", ")", ")", "\n", "imgFolderPath", "=", "os", ".", "path", ".", "join", "(", "imgPath", ",", "dataList", "[", "i", "]", ")", "\n", "dict", "=", "{", "'imgFolderPath'", ":", "imgFolderPath", ",", "'annot'", ":", "annot", "}", "\n", "if", "annot", "[", "'train'", "]", "==", "1", ":", "\n", "            ", "trainAnnot", ".", "append", "(", "dict", ")", "\n", "", "else", ":", "\n", "            ", "testAnnot", ".", "append", "(", "dict", ")", "\n", "# print(len(trainAnnot), len(testAnnot))", "\n", "", "", "return", "trainAnnot", ",", "testAnnot", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.test_penn.test_val": [[14, 148], ["torch.no_grad", "testloader.__len__", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "enumerate", "np.asarray", "eval_PCKh.get_PCKh_penn", "print", "print", "print", "imgPath.append", "randIdx.append", "imgSequence_to_use.squeeze", "imgSequence_to_use.squeeze.cuda", "time.time", "net.forward", "net.forward2", "list", "np.asarray.append", "skeleton_to_use[].type().cuda", "skeleton_to_use[].type().cuda.reshape", "Time.append", "skeletonData.reshape.reshape().cpu", "utils.get_recover_fista.reshape().cpu", "dataset_test.unnormData", "dataset_test.unnormData", "np.max", "np.min", "np.std", "np.median", "key_ind.cpu().numpy", "len", "len", "torch.zeros", "utils.get_recover_fista", "time.time", "input.reshape().cpu.unsqueeze", "y_hat.reshape().cpu.unsqueeze", "skeleton_to_use[].type", "Dict_pose_use.cuda", "skeletonData.reshape.reshape", "utils.get_recover_fista.reshape", "key_ind.cpu"], "function", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.__len__", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.eval_PCKh.get_PCKh_penn", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet.forward", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.networks.keyframeProposalNet.forward2", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.PENN_dloader.pennDataset.unnormData", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.PENN_dloader.pennDataset.unnormData", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.utils.get_recover_fista"], ["def", "test_val", "(", "net", ",", "testloader", ",", "alpha", ",", "thresh", ",", "Dict_pose_use", ",", "dataset_test", ",", "gpu_id", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "T", "=", "Dict_pose_use", ".", "shape", "[", "0", "]", "\n", "keyFrames", "=", "[", "]", "\n", "imgPath", "=", "[", "]", "\n", "numKey", "=", "0", "\n", "Time", "=", "[", "]", "\n", "# sample_num = len(testAnnot)", "\n", "sample_num", "=", "testloader", ".", "__len__", "(", ")", "\n", "gtData", "=", "torch", ".", "zeros", "(", "sample_num", ",", "T", ",", "13", ",", "2", ")", "\n", "testData", "=", "torch", ".", "zeros", "(", "sample_num", ",", "T", ",", "13", ",", "2", ")", "\n", "testUniform", "=", "torch", ".", "zeros", "(", "sample_num", ",", "T", ",", "13", ",", "2", ")", "\n", "\n", "\n", "Y_rs_min", "=", "torch", ".", "zeros", "(", "sample_num", ",", "T", ",", "13", ",", "2", ")", "\n", "# Y_rs_mean = torch.zeros(sample_num, T, 13, 2)", "\n", "\n", "\n", "\n", "VIS", "=", "torch", ".", "zeros", "(", "sample_num", ",", "T", ",", "13", ")", "\n", "BBOX", "=", "torch", ".", "zeros", "(", "sample_num", ",", "T", ",", "4", ")", "\n", "nFrames", "=", "torch", ".", "zeros", "(", "sample_num", ")", "\n", "randIdx", "=", "[", "]", "\n", "Error_all", "=", "[", "]", "\n", "# finalMean_mean = []", "\n", "for", "i", ",", "sample", "in", "enumerate", "(", "testloader", ")", ":", "\n", "\n", "            ", "print", "(", "'starting to test sample:'", ",", "i", ")", "\n", "skeleton_to_use", "=", "sample", "[", "'skeleton_to_use'", "]", "\n", "vis_to_use", "=", "sample", "[", "'vis_to_use'", "]", "\n", "bbox_to_use", "=", "sample", "[", "'bbox_to_use'", "]", "\n", "imgSequence_to_use", "=", "sample", "[", "'imgSequence_to_use'", "]", "\n", "nframes", "=", "sample", "[", "'nframes'", "]", "\n", "idx", "=", "sample", "[", "'randIdx'", "]", "\n", "imgFolderPath", "=", "sample", "[", "'imgPath'", "]", "\n", "imgPath", ".", "append", "(", "imgFolderPath", "[", "0", "]", ")", "\n", "randIdx", ".", "append", "(", "idx", ")", "\n", "\n", "img_data", "=", "imgSequence_to_use", ".", "squeeze", "(", "0", ")", "\n", "inputData", "=", "img_data", ".", "cuda", "(", "gpu_id", ")", "\n", "\n", "t0", "=", "time", ".", "time", "(", ")", "\n", "feature", ",", "Dictionary", ",", "_", "=", "net", ".", "forward", "(", "inputData", ")", "\n", "out", "=", "net", ".", "forward2", "(", "feature", ",", "alpha", ")", "\n", "# endtime = time.time() - t0", "\n", "# print('time:', endtime)", "\n", "\n", "s", "=", "out", "[", "0", ",", ":", "]", "\n", "key_ind", "=", "(", "s", ">=", "thresh", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", "1", ")", "\n", "key_list", "=", "list", "(", "key_ind", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "# print('sample:', i, 'keyframes:', key_list)", "\n", "keyFrames", ".", "append", "(", "len", "(", "key_list", ")", ")", "\n", "numKey", "=", "numKey", "+", "len", "(", "key_list", ")", "\n", "\n", "skeletonData", "=", "skeleton_to_use", "[", "0", "]", ".", "type", "(", "torch", ".", "FloatTensor", ")", ".", "cuda", "(", "gpu_id", ")", "\n", "\n", "input", "=", "skeletonData", ".", "reshape", "(", "1", ",", "T", ",", "13", "*", "2", ")", "# Tx26", "\n", "\n", "if", "key_list", "==", "[", "]", ":", "\n", "                ", "y_hat", "=", "torch", ".", "zeros", "(", "input", ".", "shape", ")", "\n", "", "else", ":", "\n", "                ", "y_hat", "=", "get_recover_fista", "(", "Dict_pose_use", ".", "cuda", "(", "gpu_id", ")", ",", "input", ",", "key_list", ",", "0.01", ",", "gpu_id", ")", "\n", "", "endtime", "=", "time", ".", "time", "(", ")", "-", "t0", "\n", "# print('time:', endtime)", "\n", "Time", ".", "append", "(", "endtime", ")", "\n", "\n", "\n", "\n", "test_gt", "=", "input", ".", "reshape", "(", "T", ",", "-", "1", ",", "2", ")", ".", "cpu", "(", ")", "# T x 13 x 2", "\n", "test_yhat", "=", "y_hat", ".", "reshape", "(", "T", ",", "-", "1", ",", "2", ")", ".", "cpu", "(", ")", "# T x 13 x 2", "\n", "test_gt_unnorm", "=", "dataset_test", ".", "unnormData", "(", "test_gt", ".", "unsqueeze", "(", "0", ")", ")", "\n", "test_out_unnorm", "=", "dataset_test", ".", "unnormData", "(", "test_yhat", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "\n", "\"\"\"\"\"\n            'uniform sampling'\n            idx = np.round(T / len(key_list))\n            n = int(T / idx)\n            key_uniform = idx * np.linspace(0, n-1, n, dtype=np.int16)\n            # print('uni keylist:', key_uniform)\n            y_hat_uniform = get_recover_fista(Dict_pose_use.cuda(gpu_id), input, list(key_uniform), gpu_id)\n\n            test_uniform = dataset_test.unnormData(y_hat_uniform.reshape(T, -1, 2).cpu().unsqueeze(0))\n            testUniform[i] = test_uniform\n\n\n            'Random selection'\n\n            Y_hat_rs, Error, _,_ = random_select(key_list, input, Dict_pose_use, gpu_id)\n\n            Error_all.append(np.min(np.asarray(Error)))\n            minIndex = np.where(np.min(np.asarray(Error)))[0]\n            Y_hat_min = Y_hat_rs[minIndex].cpu().reshape(T, -1, 2)\n            Y_hat_min_unnorm = dataset_test.unnormData(Y_hat_min.unsqueeze(0)) # recovery corresponding with the minimum error\n            Y_rs_min[i] = Y_hat_min_unnorm\n\n            \"\"\"", "\"\"", "\n", "gtData", "[", "i", "]", "=", "test_gt_unnorm", "\n", "testData", "[", "i", "]", "=", "test_out_unnorm", "\n", "\n", "VIS", "[", "i", "]", "=", "vis_to_use", "\n", "BBOX", "[", "i", "]", "=", "bbox_to_use", "\n", "nFrames", "[", "i", "]", "=", "nframes", "\n", "#", "\n", "# with torch.cuda.device(gpu_id):", "\n", "#     flops, params = get_model_complexity_info(net, (3, 244, 244), as_strings=True, print_per_layer_stat=True)", "\n", "#     print('Flops:' + flops)", "\n", "#     print('Params:' + params)", "\n", "# print('time:', endtime)", "\n", "\n", "", "'min error of random selection'", "\n", "# minError = np.mean(np.asarray(Error_all))", "\n", "# print(minError)", "\n", "\n", "meanNumKey", "=", "numKey", "/", "sample_num", "\n", "\n", "'totalTime = numKey * (baseline time per video / T) + statistics.mean(Time) * sample_num '", "\n", "# print('time/fr ms:', 1000 * (totalTime / (T * sample_num)))", "\n", "\n", "\n", "keyFrames", "=", "np", ".", "asarray", "(", "keyFrames", ")", "\n", "\n", "finalMean_kfpn", ",", "_", "=", "get_PCKh_penn", "(", "gtData", ",", "testData", ",", "VIS", ",", "BBOX", ",", "nFrames", ",", "normTorso", "=", "False", ")", "\n", "\n", "# finalMean_uniform , _ = get_PCKh_penn(gtData, testUniform, VIS, BBOX, nFrames, normTorso=False)", "\n", "\n", "# finalMean_min, _ = get_PCKh_penn(gtData, Y_rs_min, VIS, BBOX, nFrames, normTorso=False)", "\n", "\n", "print", "(", "'mean_keyframe:'", ",", "meanNumKey", ",", "'max_keyframe:'", ",", "np", ".", "max", "(", "keyFrames", ")", ",", "'min_keyframe:'", ",", "np", ".", "min", "(", "keyFrames", ")", ",", "'std_keyframe:'", ",", "np", ".", "std", "(", "keyFrames", ")", ",", "\n", "'median_keyframe:'", ",", "np", ".", "median", "(", "keyFrames", ")", ")", "\n", "# print('mean kfpn:', finalMean_kfpn,'mean min', finalMean_min, 'mean uniform:', finalMean_uniform)", "\n", "\n", "\n", "print", "(", "'done'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.test_penn.random_select": [[150, 173], ["torch.zeros", "len", "range", "np.random.choice", "np.random.choice.sort", "utils.get_recover_fista", "utils.get_recover_fista.squeeze", "torch.norm", "Error.append", "Dictionary_pose.cuda", "torch.norm.data.item"], "function", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.utils.get_recover_fista"], ["", "", "def", "random_select", "(", "keyframes", ",", "testSkeleton", ",", "Dictionary_pose", ",", "gpu_id", ")", ":", "\n", "    ", "'testSkeleton is baseline skeleton'", "\n", "maxtIter", "=", "100", "\n", "# Y_hat = torch.zeros(maxtIter, T, 13, 2)", "\n", "Y_hat", "=", "torch", ".", "zeros", "(", "maxtIter", ",", "T", ",", "26", ")", "\n", "# L = len(testSkeleton)", "\n", "L", "=", "testSkeleton", ".", "shape", "[", "1", "]", "# T = 40", "\n", "k", "=", "len", "(", "keyframes", ")", "\n", "Error", "=", "[", "]", "\n", "PCK", "=", "[", "]", "\n", "KEYS", "=", "[", "]", "\n", "for", "iter", "in", "range", "(", "0", ",", "maxtIter", ")", ":", "\n", "        ", "keys", "=", "np", ".", "random", ".", "choice", "(", "L", ",", "k", ")", "\n", "keys", ".", "sort", "(", ")", "\n", "\n", "\n", "y_hat", "=", "get_recover_fista", "(", "Dictionary_pose", ".", "cuda", "(", "gpu_id", ")", ",", "testSkeleton", ",", "keys", ",", "gpu_id", ")", "\n", "\n", "Y_hat", "[", "iter", "]", "=", "y_hat", ".", "squeeze", "(", "0", ")", "\n", "error", "=", "torch", ".", "norm", "(", "testSkeleton", "-", "y_hat", ")", "\n", "Error", ".", "append", "(", "error", ".", "data", ".", "item", "(", ")", ")", "\n", "\n", "", "return", "Y_hat", ",", "Error", ",", "KEYS", ",", "PCK", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.test_jhmdb.test_val": [[18, 111], ["torch.no_grad", "testloader.__len__", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "enumerate", "print", "eval_PCKh.get_PCKh_jhmdb", "print", "print", "img_data[].cuda", "imPath.append", "time.time", "net.forward", "net.forward2", "list", "keyFrames.append", "sequence_to_use[].type().cuda", "sequence_to_use[].type().cuda.reshape", "Time.append", "skeletonData.reshape.squeeze().reshape().cpu", "utils.get_recover_fista.squeeze().reshape().cpu", "dataset_test.get_unNormalized_data", "dataset_test.get_unNormalized_data", "np.max", "np.min", "np.std", "np.median", "len", "inputData.squeeze.squeeze", "key_ind.cpu().numpy", "len", "len", "torch.zeros", "utils.get_recover_fista", "time.time", "statistics.mean", "sequence_to_use[].type", "Dictionary_pose.cuda", "skeletonData.reshape.squeeze().reshape", "utils.get_recover_fista.squeeze().reshape", "key_ind.cpu", "skeletonData.reshape.squeeze", "utils.get_recover_fista.squeeze"], "function", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.__len__", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.eval_PCKh.get_PCKh_jhmdb", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet.forward", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.networks.keyframeProposalNet.forward2", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.get_unNormalized_data", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.get_unNormalized_data", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.utils.get_recover_fista"], ["def", "test_val", "(", "net", ",", "testloader", ",", "alpha", ",", "thresh", ",", "Dictionary_pose", ",", "dataset_test", ",", "gpu_id", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "T", "=", "Dictionary_pose", ".", "shape", "[", "0", "]", "\n", "keyFrames", "=", "[", "]", "\n", "numKey", "=", "0", "\n", "numJoint", "=", "15", "\n", "\n", "sample_num", "=", "testloader", ".", "__len__", "(", ")", "\n", "gtData", "=", "torch", ".", "zeros", "(", "sample_num", ",", "T", ",", "numJoint", ",", "2", ")", "\n", "testData", "=", "torch", ".", "zeros", "(", "sample_num", ",", "T", ",", "numJoint", ",", "2", ")", "\n", "\n", "\n", "imPath", "=", "[", "]", "\n", "\n", "Time", "=", "[", "]", "\n", "BBOX", "=", "torch", ".", "zeros", "(", "sample_num", ",", "T", ",", "4", ")", "\n", "nFrames", "=", "torch", ".", "zeros", "(", "sample_num", ")", "\n", "# t0 = time.time()", "\n", "for", "i", ",", "sample", "in", "enumerate", "(", "testloader", ")", ":", "\n", "            ", "print", "(", "'testing sample:'", ",", "i", ")", "\n", "\n", "sequence_to_use", "=", "sample", "[", "'sequence_to_use'", "]", "# already normalized", "\n", "img_data", "=", "sample", "[", "'imgSequence_to_use'", "]", "\n", "bbox", "=", "sample", "[", "'Bbox_to_use'", "]", "\n", "nframes", "=", "sample", "[", "'nframes'", "]", "\n", "# baseline_to_use = sample['baseline_to_use']", "\n", "\n", "inputData", "=", "img_data", "[", "0", "]", ".", "cuda", "(", "gpu_id", ")", "\n", "imagePath", "=", "sample", "[", "'imgPath'", "]", "\n", "imPath", ".", "append", "(", "imagePath", ")", "\n", "\n", "if", "len", "(", "inputData", ".", "shape", ")", "==", "5", ":", "\n", "                ", "inputData", "=", "inputData", ".", "squeeze", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "inputData", "=", "inputData", "\n", "\n", "", "t0", "=", "time", ".", "time", "(", ")", "\n", "\n", "# print('input shape:',inputData.shape)", "\n", "feature", ",", "Dictionary", ",", "_", "=", "net", ".", "forward", "(", "inputData", ")", "\n", "out", "=", "net", ".", "forward2", "(", "feature", ",", "alpha", ")", "\n", "\n", "s", "=", "out", "[", "0", ",", ":", "]", "\n", "key_ind", "=", "(", "s", ">", "thresh", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", "1", ")", "\n", "key_list", "=", "list", "(", "key_ind", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "# print('imgpath:', imagePath, 'keyframes:', len(key_list))", "\n", "keyFrames", ".", "append", "(", "len", "(", "key_list", ")", ")", "\n", "numKey", "=", "numKey", "+", "len", "(", "key_list", ")", "\n", "\n", "skeletonData", "=", "sequence_to_use", "[", "0", "]", ".", "type", "(", "torch", ".", "FloatTensor", ")", ".", "cuda", "(", "gpu_id", ")", "\n", "# baselineData = baseline_to_use[0].type(torch.FloatTensor).cuda(gpu_id)", "\n", "\n", "dim", "=", "numJoint", "*", "2", "\n", "GT", "=", "skeletonData", ".", "reshape", "(", "1", ",", "T", ",", "dim", ")", "# Tx30", "\n", "# baseline = baselineData.reshape(1, T, dim)", "\n", "\n", "if", "key_list", "==", "[", "]", ":", "\n", "                ", "y_hat_gt", "=", "torch", ".", "zeros", "(", "GT", ".", "shape", ")", "\n", "# y_hat_gt = torch.zeros(baseline.shape)", "\n", "\n", "", "else", ":", "\n", "                ", "y_hat_gt", "=", "get_recover_fista", "(", "Dictionary_pose", ".", "cuda", "(", "gpu_id", ")", ",", "GT", ",", "key_list", ",", "0.1", ",", "gpu_id", ")", "# for validation", "\n", "# y_hat_gt = get_recover_fista(Dictionary_pose.cuda(gpu_id), baseline, key_list, gpu_id) # for testing", "\n", "\n", "", "endtime", "=", "time", ".", "time", "(", ")", "-", "t0", "\n", "Time", ".", "append", "(", "endtime", ")", "\n", "# print('time:', endtime)", "\n", "# endtime = time.time() - t0", "\n", "# print('time:', endtime)", "\n", "# get mpjpe", "\n", "test_gt", "=", "GT", ".", "squeeze", "(", "0", ")", ".", "reshape", "(", "T", ",", "-", "1", ",", "2", ")", ".", "cpu", "(", ")", "# T x 15 x 2", "\n", "test_yhat_gt", "=", "y_hat_gt", ".", "squeeze", "(", "0", ")", ".", "reshape", "(", "T", ",", "-", "1", ",", "2", ")", ".", "cpu", "(", ")", "# T x 15 x 2", "\n", "\n", "test_out_unnorm", "=", "dataset_test", ".", "get_unNormalized_data", "(", "test_yhat_gt", ")", "\n", "test_gt_unnorm", "=", "dataset_test", ".", "get_unNormalized_data", "(", "test_gt", ")", "\n", "\n", "\n", "gtData", "[", "i", "]", "=", "test_gt_unnorm", "\n", "testData", "[", "i", "]", "=", "test_out_unnorm", "\n", "BBOX", "[", "i", "]", "=", "bbox", "\n", "nFrames", "[", "i", "]", "=", "nframes", "\n", "# endtime = time.time() - t0", "\n", "# print('time:',endtime)", "\n", "\n", "", "totalTime", "=", "numKey", "*", "(", "0.4", "/", "40", ")", "+", "statistics", ".", "mean", "(", "Time", ")", "*", "sample_num", "# for GeForce 1080i, roughly, Time(baseline) = 0.4 for each video;'", "\n", "print", "(", "'time/fr ms:'", ",", "1000", "*", "(", "totalTime", "/", "(", "T", "*", "sample_num", ")", ")", ")", "\n", "\n", "meanNumKey", "=", "numKey", "/", "sample_num", "\n", "\n", "get_PCKh_jhmdb", "(", "gtData", ",", "testData", ",", "BBOX", ",", "nFrames", ",", "imPath", ",", "normTorso", "=", "False", ")", "\n", "\n", "print", "(", "'mean_keyframe:'", ",", "meanNumKey", ",", "'max_keyframe:'", ",", "np", ".", "max", "(", "keyFrames", ")", ",", "'min_keyframe:'", ",", "\n", "np", ".", "min", "(", "keyFrames", ")", ",", "'std_keyframe:'", ",", "np", ".", "std", "(", "keyFrames", ")", ",", "'median_keyframe:'", ",", "np", ".", "median", "(", "keyFrames", ")", ")", "\n", "# with torch.cuda.device(gpu_id):", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.test_jhmdb.random_select": [[116, 130], ["torch.zeros", "len", "len", "range", "np.random.choice", "utils.get_recover_fista", "Dictionary_pose.cuda"], "function", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.utils.get_recover_fista"], ["", "", "def", "random_select", "(", "keyframes", ",", "testSkeleton", ",", "Dictionary_pose", ",", "gpu_id", ")", ":", "\n", "    ", "'testSkeleton is baseline skeleton'", "\n", "maxtIter", "=", "100", "\n", "Y_hat", "=", "torch", ".", "zeros", "(", "maxtIter", ",", "T", ",", "15", ",", "2", ")", "\n", "L", "=", "len", "(", "testSkeleton", ")", "\n", "k", "=", "len", "(", "keyframes", ")", "\n", "\n", "for", "iter", "in", "range", "(", "0", ",", "maxtIter", ")", ":", "\n", "        ", "keys", "=", "np", ".", "random", ".", "choice", "(", "L", ",", "k", ")", "\n", "\n", "y_hat", "=", "get_recover_fista", "(", "Dictionary_pose", ".", "cuda", "(", "gpu_id", ")", ",", "testSkeleton", ",", "keys", ",", "gpu_id", ")", "\n", "Y_hat", "[", "iter", "]", "=", "y_hat", "\n", "\n", "", "return", "Y_hat", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.keyframePred_test.test_val_online": [[12, 138], ["torch.no_grad", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "print", "eval_PCKh.get_PCKh_jhmdb", "print", "eval_PCKh.get_PCKh_jhmdb", "print", "np.asarray", "print", "img_data[].cuda", "imgPath.append", "np.max", "np.min", "np.std", "np.median", "print", "imPath.append", "net.get_keylist", "sequence_to_use[].type().cuda", "skeletonData[].reshape", "keyFrame_in.append", "np.asarray.append", "skeletonData[].reshape.squeeze().reshape().cpu", "utils.get_recover_fista.squeeze().reshape().cpu", "utils.get_recover_fista.squeeze().reshape().cpu", "dataset_test.get_unNormalized_data", "dataset_test.get_unNormalized_data", "dataset_test.get_unNormalized_data", "print", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "nFrames.append", "len", "inputData.squeeze.squeeze", "torch.zeros().cuda", "torch.zeros().cuda", "utils.get_recover_fista", "utils.get_recover_fista", "len", "len", "len", "len", "len", "dataset_test.get_unNormalized_data.unsqueeze", "dataset_test.get_unNormalized_data.unsqueeze", "dataset_test.get_unNormalized_data.unsqueeze", "bbox.type", "sequence_to_use[].type", "Dict_pose_use[].cuda", "Dict_pose_use[].cuda", "skeletonData[].reshape.squeeze().reshape", "utils.get_recover_fista.squeeze().reshape", "utils.get_recover_fista.squeeze().reshape", "torch.zeros", "torch.zeros", "skeletonData[].reshape.squeeze", "utils.get_recover_fista.squeeze", "utils.get_recover_fista.squeeze"], "function", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.eval_PCKh.get_PCKh_jhmdb", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.eval_PCKh.get_PCKh_jhmdb", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.networks.onlineUpdate.get_keylist", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.get_unNormalized_data", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.get_unNormalized_data", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.get_unNormalized_data", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.utils.get_recover_fista", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.utils.get_recover_fista"], ["def", "test_val_online", "(", "net", ",", "testloader", ",", "alpha", ",", "FRA", ",", "PRE", ",", "Dict_pose_use", ",", "dataset_test", ",", "gpu_id", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "T", "=", "Dict_pose_use", ".", "shape", "[", "0", "]", "\n", "# predLen = T - FRA", "\n", "numJoint", "=", "15", "\n", "dim", "=", "numJoint", "*", "2", "\n", "\n", "imPath", "=", "[", "]", "\n", "\n", "gtData", "=", "[", "]", "\n", "testBase", "=", "[", "]", "\n", "testBase_wo", "=", "[", "]", "\n", "\n", "BBOX", "=", "[", "]", "\n", "nFrames", "=", "[", "]", "\n", "\n", "\n", "numKey_in", "=", "0", "\n", "numKey_pred", "=", "0", "\n", "sampleNum", "=", "0", "\n", "keyFrame_in", "=", "[", "]", "\n", "keyFrame_up", "=", "[", "]", "\n", "imgPath", "=", "[", "]", "\n", "for", "i", ",", "sample", "in", "enumerate", "(", "testloader", ")", ":", "\n", "\n", "            ", "sequence_to_use", "=", "sample", "[", "'sequence_to_use'", "]", "# already normalized", "\n", "img_data", "=", "sample", "[", "'imgSequence_to_use'", "]", "\n", "bbox", "=", "sample", "[", "'Bbox_to_use'", "]", "\n", "nframes", "=", "sample", "[", "'nframes'", "]", "\n", "inputData", "=", "img_data", "[", "0", "]", ".", "cuda", "(", "gpu_id", ")", "\n", "imagePath", "=", "sample", "[", "'imgPath'", "]", "[", "0", "]", "\n", "imgPath", ".", "append", "(", "imagePath", ")", "\n", "# baseline = sample['baseline']", "\n", "if", "nframes", ">=", "0", ":", "\n", "                ", "print", "(", "'testing sample:'", ",", "i", ",", "'impath:'", ",", "imagePath", ")", "\n", "sampleNum", "+=", "1", "\n", "imPath", ".", "append", "(", "imagePath", ")", "\n", "if", "len", "(", "inputData", ".", "shape", ")", "==", "5", ":", "\n", "                    ", "inputData", "=", "inputData", ".", "squeeze", "(", "0", ")", "\n", "", "else", ":", "\n", "                    ", "inputData", "=", "inputData", "\n", "\n", "", "sparseCode_key", ",", "Dictionary", ",", "keylist_to_pred", ",", "keylist_FRA", ",", "key_list", ",", "imgFeature", "=", "net", ".", "get_keylist", "(", "inputData", ",", "alpha", ")", "\n", "predKeylist", "=", "[", "]", "\n", "\n", "\n", "\n", "skeletonData", "=", "sequence_to_use", "[", "0", "]", ".", "type", "(", "torch", ".", "FloatTensor", ")", ".", "cuda", "(", "gpu_id", ")", "\n", "GT", "=", "skeletonData", "[", "0", ":", "FRA", "+", "PRE", "]", ".", "reshape", "(", "1", ",", "FRA", "+", "PRE", ",", "dim", ")", "\n", "\n", "\n", "if", "predKeylist", "==", "[", "]", ":", "\n", "                    ", "keyList_full", "=", "keylist_FRA", "\n", "", "else", ":", "\n", "                    ", "keyList_full", "=", "keylist_FRA", "+", "predKeylist", "\n", "\n", "# print('gt key:',key_list ,'pred key:', keyList_full)", "\n", "\n", "", "if", "keyList_full", "==", "[", "]", ":", "\n", "# y_hat_gt = torch.zeros(GT.shape)", "\n", "                    ", "y_hat_base", "=", "torch", ".", "zeros", "(", "GT", ".", "shape", ")", ".", "cuda", "(", "gpu_id", ")", "\n", "y_hat_base_wo", "=", "torch", ".", "zeros", "(", "GT", ".", "shape", ")", ".", "cuda", "(", "gpu_id", ")", "\n", "", "else", ":", "\n", "\n", "                    ", "y_hat_base", "=", "get_recover_fista", "(", "Dict_pose_use", "[", "0", ":", "FRA", "+", "PRE", "]", ".", "cuda", "(", "gpu_id", ")", ",", "GT", ",", "keyList_full", ",", "0.1", ",", "gpu_id", ")", "\n", "y_hat_base_wo", "=", "get_recover_fista", "(", "Dict_pose_use", "[", "0", ":", "FRA", "+", "PRE", "]", ".", "cuda", "(", "gpu_id", ")", ",", "GT", ",", "key_list", ",", "0.1", ",", "gpu_id", ")", "\n", "\n", "\n", "", "numKey_pred", "=", "numKey_pred", "+", "len", "(", "keyList_full", ")", "\n", "numKey_in", "=", "numKey_in", "+", "len", "(", "key_list", ")", "\n", "\n", "keyFrame_in", ".", "append", "(", "key_list", ")", "\n", "# keyFrame_up.append(keyList_full)", "\n", "keyFrame_up", ".", "append", "(", "len", "(", "keyList_full", ")", ")", "\n", "\n", "\n", "test_gt", "=", "GT", ".", "squeeze", "(", "0", ")", ".", "reshape", "(", "FRA", "+", "PRE", ",", "-", "1", ",", "2", ")", ".", "cpu", "(", ")", "# T x 15 x 2", "\n", "test_yhat_base", "=", "y_hat_base", ".", "squeeze", "(", "0", ")", ".", "reshape", "(", "FRA", "+", "PRE", ",", "-", "1", ",", "2", ")", ".", "cpu", "(", ")", "\n", "test_yhat_base_wo", "=", "y_hat_base_wo", ".", "squeeze", "(", "0", ")", ".", "reshape", "(", "FRA", "+", "PRE", ",", "-", "1", ",", "2", ")", ".", "cpu", "(", ")", "\n", "\n", "test_gt_unnorm", "=", "dataset_test", ".", "get_unNormalized_data", "(", "test_gt", ")", "\n", "test_base_unnorm", "=", "dataset_test", ".", "get_unNormalized_data", "(", "test_yhat_base", ")", "\n", "test_base_unnorm_wo", "=", "dataset_test", ".", "get_unNormalized_data", "(", "test_yhat_base_wo", ")", "\n", "\n", "\n", "'only consider prediction '", "\n", "# gtData[i] = test_gt_unnorm[FRA:T]", "\n", "# testBase[i] = test_base_unnorm[FRA:T]", "\n", "# BBOX[i] = bbox", "\n", "\n", "# gtData.append(test_gt_unnorm[FRA:T].unsqueeze(0))", "\n", "# testBase.append(test_base_unnorm[FRA:T].unsqueeze(0))", "\n", "# testBase_wo.append(test_base_unnorm_wo[FRA:T].unsqueeze(0))", "\n", "# BBOX.append(bbox[:, FRA:T].type(torch.FloatTensor))", "\n", "# nFrames.append(nframes - FRA)", "\n", "\n", "print", "(", "'update list:'", ",", "len", "(", "keyList_full", ")", ",", "'all keylist:'", ",", "len", "(", "key_list", ")", ")", "\n", "gtData", ".", "append", "(", "test_gt_unnorm", ".", "unsqueeze", "(", "0", ")", ")", "\n", "testBase", ".", "append", "(", "test_base_unnorm", ".", "unsqueeze", "(", "0", ")", ")", "\n", "testBase_wo", ".", "append", "(", "test_base_unnorm_wo", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "BBOX", ".", "append", "(", "bbox", ".", "type", "(", "torch", ".", "FloatTensor", ")", ")", "\n", "nFrames", ".", "append", "(", "nframes", ")", "\n", "", "else", ":", "\n", "                ", "continue", "\n", "\n", "\n", "", "", "meanNumKey_in", "=", "numKey_in", "/", "sampleNum", "\n", "meanNumKey_pred", "=", "numKey_pred", "/", "sampleNum", "\n", "\n", "gtData", "=", "torch", ".", "cat", "(", "(", "gtData", ")", ")", "\n", "testBase", "=", "torch", ".", "cat", "(", "(", "testBase", ")", ")", "\n", "BBOX", "=", "torch", ".", "cat", "(", "(", "BBOX", ")", ")", "\n", "testBase_wo", "=", "torch", ".", "cat", "(", "(", "testBase_wo", ")", ")", "\n", "\n", "print", "(", "'update with keyframes'", ")", "\n", "get_PCKh_jhmdb", "(", "gtData", ",", "testBase", ",", "BBOX", ",", "nFrames", ",", "imPath", ",", "normTorso", "=", "False", ")", "\n", "\n", "print", "(", "'non-updating keyframes'", ")", "\n", "get_PCKh_jhmdb", "(", "gtData", ",", "testBase_wo", ",", "BBOX", ",", "nFrames", ",", "imPath", ",", "normTorso", "=", "False", ")", "\n", "\n", "print", "(", "'mean_keyframe pred:'", ",", "meanNumKey_pred", ",", "'mean_keyframe in'", ",", "meanNumKey_in", ")", "\n", "\n", "keyFrame_up", "=", "np", ".", "asarray", "(", "keyFrame_up", ")", "\n", "print", "(", "'for online mode:'", ",", "'max_keyframe:'", ",", "np", ".", "max", "(", "keyFrame_up", ")", ",", "'min_keyframe:'", ",", "\n", "np", ".", "min", "(", "keyFrame_up", ")", ",", "'std_keyframe:'", ",", "np", ".", "std", "(", "keyFrame_up", ")", ",", "'median_keyframe:'", ",", "np", ".", "median", "(", "keyFrame_up", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.lossFunction.minInverse_loss": [[5, 65], ["torch.matmul", "torch.diag", "torch.eye().cuda", "torch.inverse", "torch.sum", "torch.norm", "torch.sum", "Dictionary.t", "input.t.permute().squeeze", "torch.matmul", "torch.pow", "len", "len", "input.t.t", "print", "torch.eye", "input.t.permute", "len", "len", "input.t.reshape", "m.squeeze.squeeze", "torch.matmul", "torch.pow", "len", "len", "input.t.view", "m.squeeze.squeeze", "len", "len", "input.t.squeeze().reshape", "m.squeeze.squeeze", "input.t.t", "m.squeeze.squeeze", "len", "len", "input.t.squeeze"], "function", ["None"], ["def", "minInverse_loss", "(", "m", ",", "Dictionary", ",", "input", ",", "T", ",", "lamd", ",", "gpu_id", ",", "config", ")", ":", "\n", "    ", "ddt", "=", "torch", ".", "matmul", "(", "Dictionary", ",", "Dictionary", ".", "t", "(", ")", ")", "\n", "if", "len", "(", "m", ".", "shape", ")", "==", "3", "and", "len", "(", "input", ".", "shape", ")", "==", "3", ":", "\n", "        ", "input", "=", "input", ".", "permute", "(", "2", ",", "0", ",", "1", ")", ".", "squeeze", "(", "2", ")", "\n", "m", "=", "m", "[", "0", ",", "0", ",", ":", "]", "\n", "", "elif", "len", "(", "m", ".", "shape", ")", "==", "3", "and", "len", "(", "input", ".", "shape", ")", "==", "2", ":", "\n", "        ", "input", "=", "input", ".", "t", "(", ")", "\n", "# m = m.squeeze(0)", "\n", "m", "=", "m", "[", "0", ",", "0", ",", ":", "]", "\n", "", "elif", "len", "(", "m", ".", "shape", ")", "==", "2", "and", "len", "(", "input", ".", "shape", ")", "==", "3", ":", "\n", "# input = input.permute(2, 0, 1).squeeze(2)", "\n", "        ", "dim", "=", "input", ".", "shape", "[", "1", "]", "*", "input", ".", "shape", "[", "2", "]", "\n", "input", "=", "input", ".", "reshape", "(", "T", ",", "dim", ")", "\n", "m", "=", "m", ".", "squeeze", "(", "0", ")", "\n", "\n", "", "elif", "len", "(", "m", ".", "shape", ")", "==", "2", "and", "len", "(", "input", ".", "shape", ")", "==", "4", ":", "\n", "# dim = input.shape[1] * input.shape[3]", "\n", "# input = input.squeeze(0).permute(1, 2, 0).reshape(T, dim)", "\n", "        ", "input", "=", "input", ".", "view", "(", "T", ",", "-", "1", ")", "\n", "m", "=", "m", ".", "squeeze", "(", "0", ")", "\n", "", "elif", "len", "(", "m", ".", "shape", ")", "==", "2", "and", "len", "(", "input", ".", "shape", ")", "==", "5", ":", "\n", "        ", "dim", "=", "input", ".", "shape", "[", "2", "]", "*", "input", ".", "shape", "[", "3", "]", "*", "input", ".", "shape", "[", "4", "]", "\n", "input", "=", "input", ".", "squeeze", "(", "0", ")", ".", "reshape", "(", "T", ",", "dim", ")", "\n", "m", "=", "m", ".", "squeeze", "(", "0", ")", "\n", "\n", "\n", "", "else", ":", "\n", "        ", "input", "=", "input", ".", "t", "(", ")", "\n", "m", "=", "m", ".", "squeeze", "(", "0", ")", "\n", "\n", "", "sigma", "=", "0.1", "#0.01", "\n", "if", "config", "==", "'penn'", ":", "\n", "# lam1 = 1", "\n", "# lam2 = 5", "\n", "        ", "lam1", "=", "lamd", "[", "0", "]", "\n", "lam2", "=", "lamd", "[", "1", "]", "\n", "\n", "", "elif", "config", "==", "'jhmdb'", ":", "\n", "# lam1 = 2", "\n", "# lam2 = 4", "\n", "        ", "lam1", "=", "lamd", "[", "0", "]", "\n", "lam2", "=", "lamd", "[", "1", "]", "\n", "", "else", ":", "\n", "        ", "print", "(", "'error model'", ")", "\n", "\n", "\n", "\n", "", "lam3", "=", "0", "\n", "M", "=", "torch", ".", "diag", "(", "m", ")", "\n", "# M = m.t() * m", "\n", "I", "=", "torch", ".", "eye", "(", "T", ")", ".", "cuda", "(", "gpu_id", ")", "\n", "A", "=", "torch", ".", "inverse", "(", "I", "+", "(", "1", "/", "sigma", ")", "*", "(", "torch", ".", "matmul", "(", "ddt", ",", "M", ")", ")", ")", "\n", "\n", "l1", "=", "torch", ".", "sum", "(", "m", ")", "\n", "l2", "=", "torch", ".", "norm", "(", "torch", ".", "matmul", "(", "A", ",", "input", ")", ",", "p", "=", "'fro'", ")", "\n", "l3", "=", "torch", ".", "sum", "(", "torch", ".", "pow", "(", "torch", ".", "pow", "(", "m", ",", "2", ")", "-", "m", ",", "2", ")", ")", "\n", "\n", "total_loss", "=", "lam1", "*", "l1", "+", "lam2", "*", "l2", "+", "lam3", "*", "l3", "\n", "\n", "return", "total_loss", ",", "l1", ",", "l2", ",", "l3", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.utils.gridRing": [[12, 36], ["int", "utils.generateGridPoles", "len", "random.sample", "numpy.concatenate", "range", "numpy.conjugate", "numpy.conjugate"], "function", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.utils.generateGridPoles"], ["def", "gridRing", "(", "N", ")", ":", "\n", "# epsilon_low = 0.25", "\n", "# epsilon_high = 0.15", "\n", "# rmin = (1 - epsilon_low)", "\n", "# rmax = (1 + epsilon_high)", "\n", "\n", "    ", "epsilon_low", "=", "0.25", "\n", "epsilon_high", "=", "0.15", "\n", "rmin", "=", "(", "1", "-", "epsilon_low", ")", "\n", "rmax", "=", "(", "1", "+", "epsilon_high", ")", "\n", "\n", "thetaMin", "=", "0.001", "\n", "thetaMax", "=", "np", ".", "pi", "/", "2", "-", "0.001", "\n", "delta", "=", "0.001", "\n", "# Npole = int(N / 4)", "\n", "Npole", "=", "int", "(", "N", "/", "2", ")", "\n", "Pool", "=", "generateGridPoles", "(", "delta", ",", "rmin", ",", "rmax", ",", "thetaMin", ",", "thetaMax", ")", "\n", "M", "=", "len", "(", "Pool", ")", "\n", "\n", "idx", "=", "random", ".", "sample", "(", "range", "(", "0", ",", "M", ")", ",", "Npole", ")", "\n", "P", "=", "Pool", "[", "idx", "]", "\n", "Pall", "=", "np", ".", "concatenate", "(", "(", "P", ",", "-", "P", ",", "np", ".", "conjugate", "(", "P", ")", ",", "np", ".", "conjugate", "(", "-", "P", ")", ")", ",", "axis", "=", "0", ")", "\n", "\n", "return", "P", ",", "Pall", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.utils.generateGridPoles": [[39, 51], ["pow", "pow", "numpy.arange", "numpy.meshgrid", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "numpy.angle", "numpy.angle"], "function", ["None"], ["", "def", "generateGridPoles", "(", "delta", ",", "rmin", ",", "rmax", ",", "thetaMin", ",", "thetaMax", ")", ":", "\n", "    ", "rmin2", "=", "pow", "(", "rmin", ",", "2", ")", "\n", "rmax2", "=", "pow", "(", "rmax", ",", "2", ")", "\n", "xv", "=", "np", ".", "arange", "(", "-", "rmax", ",", "rmax", ",", "delta", ")", "\n", "x", ",", "y", "=", "np", ".", "meshgrid", "(", "xv", ",", "xv", ",", "sparse", "=", "False", ")", "\n", "mask", "=", "np", ".", "logical_and", "(", "np", ".", "logical_and", "(", "x", "**", "2", "+", "y", "**", "2", ">=", "rmin2", ",", "x", "**", "2", "+", "y", "**", "2", "<=", "rmax2", ")", ",", "\n", "np", ".", "logical_and", "(", "np", ".", "angle", "(", "x", "+", "1j", "*", "y", ")", ">=", "thetaMin", ",", "np", ".", "angle", "(", "x", "+", "1j", "*", "y", ")", "<=", "thetaMax", ")", ")", "\n", "px", "=", "x", "[", "mask", "]", "\n", "py", "=", "y", "[", "mask", "]", "\n", "P", "=", "px", "+", "1j", "*", "py", "\n", "\n", "return", "P", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.utils.getRowSparsity": [[52, 64], ["range", "inputDict[].unsqueeze", "len", "round", "inputDict[].unsqueeze.nonzero"], "function", ["None"], ["", "def", "getRowSparsity", "(", "inputDict", ")", ":", "\n", "    ", "rowNum", "=", "inputDict", ".", "shape", "[", "0", "]", "\n", "L", "=", "inputDict", ".", "shape", "[", "1", "]", "\n", "count", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "rowNum", ")", ":", "\n", "        ", "dictRow", "=", "inputDict", "[", "i", ",", ":", "]", ".", "unsqueeze", "(", "0", ")", "\n", "if", "len", "(", "dictRow", ".", "nonzero", "(", ")", ")", "<=", "round", "(", "0.6", "*", "L", ")", ":", "\n", "            ", "count", "+=", "1", "\n", "", "else", ":", "\n", "            ", "continue", "\n", "", "", "rowSparsity", "=", "count", "\n", "return", "rowSparsity", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.utils.get_recover_fista": [[66, 85], ["type", "torch.Tensor", "torch.Tensor", "len", "modelZoo.DyanOF.fista", "torch.matmul", "torch.matmul", "modelZoo.DyanOF.fista", "torch.matmul", "torch.matmul", "D_r.cuda", "torch.Tensor.cuda"], "function", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.DyanOF.fista", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.DyanOF.fista"], ["", "def", "get_recover_fista", "(", "D", ",", "y", ",", "key_set", ",", "param", ",", "gpu_id", ")", ":", "\n", "    ", "if", "type", "(", "D", ")", "is", "np", ".", "ndarray", ":", "\n", "        ", "D", "=", "torch", ".", "Tensor", "(", "D", ")", "\n", "\n", "", "D_r", "=", "D", "[", "key_set", "]", "\n", "\n", "if", "len", "(", "y", ".", "shape", ")", "==", "3", ":", "\n", "        ", "y_r", "=", "y", "[", ":", ",", "key_set", "]", "\n", "", "else", ":", "\n", "        ", "y_r", "=", "y", "[", "key_set", "]", "\n", "\n", "", "if", "D", ".", "is_cuda", ":", "\n", "        ", "c_r", "=", "fista", "(", "D_r", ",", "y_r", ",", "param", ",", "100", ",", "gpu_id", ")", "\n", "y_hat", "=", "torch", ".", "matmul", "(", "D", ",", "c_r", ")", "\n", "", "else", ":", "\n", "        ", "c_r", "=", "fista", "(", "D_r", ".", "cuda", "(", "gpu_id", ")", ",", "y_r", ",", "param", ",", "100", ",", "gpu_id", ")", "\n", "y_hat", "=", "torch", ".", "matmul", "(", "D", ".", "cuda", "(", "gpu_id", ")", ",", "c_r", ")", "\n", "\n", "", "return", "y_hat", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.__init__": [[77, 105], ["len", "range", "numpy.concatenate", "numpy.concatenate", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "len", "numpy.concatenate.append", "len", "len", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.std", "numpy.std", "numpy.std", "numpy.std"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "trainAnnot", ",", "testAnnot", ",", "T", ",", "split", ",", "if_occ", ")", ":", "\n", "# if_occ: occlusion ratio for robust comparison experiment", "\n", "\n", "        ", "self", ".", "trainSet", "=", "trainAnnot", "[", "0", ":", "600", "]", "\n", "self", ".", "testSet", "=", "testAnnot", "\n", "self", ".", "valSet", "=", "trainAnnot", "[", "600", ":", "]", "\n", "self", ".", "inputLen", "=", "T", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "numJoint", "=", "15", "\n", "self", ".", "if_occ", "=", "if_occ", "\n", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "self", ".", "dataLen", "=", "len", "(", "self", ".", "trainSet", ")", "\n", "", "elif", "self", ".", "split", "==", "'val'", ":", "\n", "            ", "self", ".", "dataLen", "=", "len", "(", "self", ".", "valSet", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dataLen", "=", "len", "(", "self", ".", "testSet", ")", "\n", "\n", "", "numData", "=", "len", "(", "self", ".", "trainSet", ")", "\n", "allSkeleton", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "numData", ")", ":", "\n", "            ", "skeleton", "=", "self", ".", "trainSet", "[", "i", "]", "[", "'annot'", "]", "[", "'pos_img'", "]", "\n", "allSkeleton", ".", "append", "(", "skeleton", ")", "\n", "\n", "", "allSkeleton", "=", "np", ".", "concatenate", "(", "(", "allSkeleton", ")", ",", "2", ")", "\n", "self", ".", "meanX", "=", "np", ".", "expand_dims", "(", "np", ".", "mean", "(", "allSkeleton", ",", "axis", "=", "2", ")", "[", "0", "]", ",", "0", ")", "# 1 x num_joint", "\n", "self", ".", "meanY", "=", "np", ".", "expand_dims", "(", "np", ".", "mean", "(", "allSkeleton", ",", "axis", "=", "2", ")", "[", "1", "]", ",", "0", ")", "\n", "self", ".", "stdX", "=", "np", ".", "expand_dims", "(", "np", ".", "std", "(", "allSkeleton", ",", "axis", "=", "2", ")", "[", "0", "]", ",", "0", ")", "\n", "self", ".", "stdY", "=", "np", ".", "expand_dims", "(", "np", ".", "std", "(", "allSkeleton", ",", "axis", "=", "2", ")", "[", "1", "]", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.__len__": [[106, 108], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dataLen", "\n", "# return 10               # TO DEBUG", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.read_annot": [[110, 124], ["[].transpose", "numpy.zeros", "numpy.zeros"], "methods", ["None"], ["", "def", "read_annot", "(", "self", ",", "annotSet", ")", ":", "\n", "        ", "imgPath", "=", "annotSet", "[", "'imgPath'", "]", "\n", "Bbox", "=", "annotSet", "[", "'Bbox'", "]", "\n", "skeleton", "=", "annotSet", "[", "'annot'", "]", "[", "'pos_img'", "]", ".", "transpose", "(", "2", ",", "1", ",", "0", ")", "# 2 x 15 x T ---> T x 15 x 2", "\n", "img_mask", "=", "annotSet", "[", "'mask'", "]", "\n", "\n", "if", "annotSet", "[", "'baseline'", "]", "is", "None", ":", "\n", "            ", "baseline", "=", "np", ".", "zeros", "(", "skeleton", ".", "shape", ")", "\n", "", "else", ":", "\n", "            ", "baseline", "=", "annotSet", "[", "'baseline'", "]", "\n", "\n", "\n", "\n", "", "return", "imgPath", ",", "Bbox", ",", "skeleton", ",", "baseline", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.preProcessImage": [[125, 174], ["fnmatch.filter", "fnmatch.filter.sort", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "os.listdir", "JHMDB_dloader.jhmdbDataset.get_occlusion_idx", "JHMDB_dloader.jhmdbDataset.get_occlusion_idx", "len", "os.path.join", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.concatenate", "numpy.concatenate", "PIL.Image.open", "imgSize.append", "torchvision.transforms.Compose", "torchvision.transforms.Compose.", "torch.cat.append", "torch.cat.append", "len", "len", "JHMDB_dloader.jhmdbDataset.manuallyOcclusion", "transforms.Compose.unsqueeze", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.get_occlusion_idx", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.get_occlusion_idx", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.manuallyOcclusion"], ["", "def", "preProcessImage", "(", "self", ",", "imgPath", ",", "Bbox", ")", ":", "\n", "        ", "imgList", "=", "fnmatch", ".", "filter", "(", "os", ".", "listdir", "(", "imgPath", ")", ",", "'*.png'", ")", "\n", "imgList", ".", "sort", "(", ")", "\n", "\n", "# imgList.remove('.')", "\n", "if", "self", ".", "if_occ", ":", "\n", "            ", "frame_occ_idx", "=", "self", ".", "get_occlusion_idx", "(", "len", "(", "imgList", ")", ",", "occRatio", "=", "0.1", ")", "\n", "", "else", ":", "\n", "            ", "frame_occ_idx", "=", "self", ".", "get_occlusion_idx", "(", "len", "(", "imgList", ")", ",", "occRatio", "=", "0.0", ")", "\n", "", "imgSequence", "=", "[", "]", "\n", "imgSize", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "imgList", ")", ")", ":", "\n", "            ", "img_path", "=", "os", ".", "path", ".", "join", "(", "imgPath", ",", "imgList", "[", "i", "]", ")", "\n", "h", "=", "Bbox", "[", "i", ",", "2", "]", "-", "Bbox", "[", "i", ",", "0", "]", "\n", "w", "=", "Bbox", "[", "i", ",", "3", "]", "-", "Bbox", "[", "i", ",", "1", "]", "\n", "c1", "=", "np", ".", "expand_dims", "(", "Bbox", "[", "i", ",", "0", "]", "+", "0.5", "*", "h", ",", "0", ")", "\n", "c2", "=", "np", ".", "expand_dims", "(", "Bbox", "[", "i", ",", "1", "]", "+", "0.5", "*", "w", ",", "0", ")", "\n", "center", "=", "np", ".", "concatenate", "(", "(", "c1", ",", "c2", ")", ",", "0", ")", "\n", "\n", "input_image", "=", "Image", ".", "open", "(", "img_path", ")", "\n", "imgSize", ".", "append", "(", "input_image", ".", "size", ")", "\n", "\n", "if", "i", "in", "frame_occ_idx", ":", "\n", "\n", "                ", "input_image", "=", "self", ".", "manuallyOcclusion", "(", "input_image", ",", "center", ")", "\n", "# input_image2 = self.get_blurImage(input_image)", "\n", "# input_image3 = self.change_Brightness(input_image)", "\n", "# print('check')", "\n", "\n", "", "else", ":", "\n", "                ", "input_image", "=", "input_image", "\n", "\n", "# bbx = Bbox[i]", "\n", "# cropedwithBbox = input_image.crop(bbx)", "\n", "\n", "", "preprocess", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "256", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "224", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ",", "\n", "]", ")", "\n", "\n", "\n", "img_tensor", "=", "preprocess", "(", "input_image", ")", "\n", "\n", "imgSequence", ".", "append", "(", "img_tensor", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "imgSequence", "=", "torch", ".", "cat", "(", "(", "imgSequence", ")", ",", "0", ")", "\n", "return", "imgSequence", ",", "imgSize", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.get_random_crop": [[175, 188], ["numpy.asarray", "numpy.asarray", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "PIL.Image.fromarray"], "methods", ["None"], ["", "def", "get_random_crop", "(", "self", ",", "input_image", ",", "crop_height", ",", "crop_width", ")", ":", "\n", "\n", "        ", "input_image", "=", "np", ".", "asarray", "(", "input_image", ")", "\n", "max_x", "=", "input_image", ".", "shape", "[", "1", "]", "-", "crop_width", "\n", "max_y", "=", "input_image", ".", "shape", "[", "0", "]", "-", "crop_height", "\n", "\n", "x", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "max_x", ")", "\n", "y", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "max_y", ")", "\n", "\n", "cropImg", "=", "input_image", "[", "y", ":", "y", "+", "crop_height", ",", "x", ":", "x", "+", "crop_width", "]", "\n", "cropImg", "=", "Image", ".", "fromarray", "(", "cropImg", ")", "\n", "\n", "return", "cropImg", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.get_occlusion_idx": [[189, 200], ["random.seed", "int", "list", "numpy.linspace", "numpy.linspace", "random.sample"], "methods", ["None"], ["", "def", "get_occlusion_idx", "(", "self", ",", "T", ",", "occRatio", ")", ":", "\n", "        ", "random", ".", "seed", "(", "1234567890", ")", "\n", "n", "=", "int", "(", "T", "*", "occRatio", ")", "\n", "# print('occluded frame number:', n, 'frame num:', T)", "\n", "frameIdx", "=", "list", "(", "np", ".", "linspace", "(", "0", ",", "T", "-", "1", ",", "T", "-", "1", ",", "dtype", "=", "np", ".", "int", ")", ")", "\n", "if", "occRatio", "<", "1.0", ":", "\n", "            ", "frame_occ_idx", "=", "random", ".", "sample", "(", "frameIdx", ",", "k", "=", "n", ")", "\n", "", "else", ":", "\n", "            ", "frame_occ_idx", "=", "frameIdx", "\n", "\n", "", "return", "frame_occ_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.manuallyOcclusion": [[201, 213], ["random.seed", "numpy.array", "numpy.array", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "PIL.Image.fromarray", "int", "int", "int", "int"], "methods", ["None"], ["", "def", "manuallyOcclusion", "(", "self", ",", "input_image", ",", "center", ")", ":", "\n", "        ", "'manually occlusion'", "\n", "random", ".", "seed", "(", "1234567890", ")", "\n", "\n", "input_image", "=", "np", ".", "array", "(", "input_image", ")", "\n", "psize", "=", "80", "\n", "x", "=", "np", ".", "random", ".", "randint", "(", "center", "[", "0", "]", "-", "5", ",", "center", "[", "0", "]", "+", "5", ")", "\n", "y", "=", "np", ".", "random", ".", "randint", "(", "center", "[", "1", "]", "-", "5", ",", "center", "[", "1", "]", "+", "5", ")", "\n", "\n", "input_image", "[", "y", "-", "int", "(", "psize", "/", "2", ")", ":", "y", "+", "int", "(", "psize", "/", "2", ")", ",", "x", "-", "int", "(", "psize", "/", "2", ")", ":", "x", "+", "int", "(", "psize", "/", "2", ")", "]", "=", "0", "\n", "input_image", "=", "Image", ".", "fromarray", "(", "input_image", ")", "\n", "return", "input_image", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.get_blurImage": [[214, 218], ["input_image.filter", "PIL.ImageFilter.GaussianBlur"], "methods", ["None"], ["", "def", "get_blurImage", "(", "self", ",", "input_image", ")", ":", "\n", "        ", "blurImage", "=", "input_image", ".", "filter", "(", "ImageFilter", ".", "GaussianBlur", "(", "radius", "=", "4", ")", ")", "\n", "\n", "return", "blurImage", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.change_Brightness": [[219, 229], ["random.seed", "random.choice", "random.choice", "random.choice", "PIL.ImageEnhance.Brightness", "PIL.ImageEnhance.Brightness.enhance"], "methods", ["None"], ["", "def", "change_Brightness", "(", "self", ",", "input_image", ")", ":", "\n", "        ", "random", ".", "seed", "(", "1234567890", ")", "\n", "x", "=", "random", ".", "choice", "(", "[", "2", ",", "3", ",", "4", ",", "5", "]", ")", "\n", "y", "=", "random", ".", "choice", "(", "[", "0.1", ",", "0.2", ",", "0.3", ",", "0.4", "]", ")", "\n", "n", "=", "random", ".", "choice", "(", "[", "x", ",", "y", "]", ")", "# either brighter or darker", "\n", "\n", "enhancer", "=", "ImageEnhance", ".", "Brightness", "(", "input_image", ")", "\n", "enhancedImage", "=", "enhancer", ".", "enhance", "(", "n", ")", "\n", "\n", "return", "enhancedImage", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.data_to_use": [[231, 309], ["random.seed", "len", "skeleton.squeeze.squeeze.squeeze", "bbox.squeeze.squeeze.squeeze", "imgSequence.squeeze.squeeze.squeeze", "random.randint", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.ones", "numpy.ones", "numpy.ones", "numpy.ones", "six.moves.xrange", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate().astype", "numpy.concatenate().astype", "numpy.ones", "numpy.ones", "numpy.concatenate().astype", "numpy.concatenate().astype", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "numpy.concatenate.append", "numpy.concatenate.append", "img_sequence.append", "m_idx.append", "numpy.concatenate().astype", "numpy.concatenate().astype", "torch.cat().type", "torch.cat().type", "torch.cat().type", "torch.cat().type", "numpy.concatenate().astype", "numpy.concatenate().astype", "torch.cat().type", "torch.cat().type", "torch.cat().type", "torch.cat().type", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "torch.zeros.unsqueeze", "torch.zeros.unsqueeze", "numpy.expand_dims", "numpy.expand_dims", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "numpy.concatenate", "numpy.concatenate", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "data_to_use", "(", "self", ",", "skeleton", ",", "bbox", ",", "imgSequence", ")", ":", "\n", "        ", "nframes", "=", "imgSequence", ".", "shape", "[", "0", "]", "\n", "# print('number of frames:', nframes)", "\n", "random", ".", "seed", "(", "1234567890", ")", "\n", "useLen", "=", "self", ".", "inputLen", "\n", "\n", "if", "len", "(", "skeleton", ".", "shape", ")", "==", "4", ":", "\n", "            ", "skeleton", "=", "skeleton", ".", "squeeze", "(", "0", ")", "# inputLen x 15 x 2", "\n", "bbox", "=", "bbox", ".", "squeeze", "(", "0", ")", "# T x 4", "\n", "imgSequence", "=", "imgSequence", ".", "squeeze", "(", "0", ")", "\n", "\n", "\n", "", "if", "nframes", ">", "useLen", ":", "\n", "            ", "idx", "=", "random", ".", "randint", "(", "0", ",", "nframes", "-", "useLen", ")", "\n", "\n", "data_sel", "=", "np", ".", "expand_dims", "(", "skeleton", "[", "idx", ":", "idx", "+", "useLen", "]", ",", "0", ")", "\n", "bbx_sel", "=", "np", ".", "expand_dims", "(", "bbox", "[", "idx", ":", "idx", "+", "useLen", "]", ",", "0", ")", "\n", "img_sel", "=", "np", ".", "expand_dims", "(", "imgSequence", "[", "idx", ":", "idx", "+", "useLen", "]", ",", "0", ")", "\n", "\n", "sequence_to_use", "=", "data_sel", "\n", "bbox_to_use", "=", "bbx_sel", "\n", "imgSequence_to_use", "=", "img_sel", "\n", "mask_idx", "=", "np", ".", "ones", "(", "(", "sequence_to_use", ".", "shape", ")", ")", "\n", "\n", "\n", "", "elif", "nframes", "==", "useLen", ":", "\n", "            ", "idx", "=", "0", "\n", "sequence_to_use", "=", "skeleton", "\n", "\n", "mask_idx", "=", "np", ".", "ones", "(", "(", "sequence_to_use", ".", "shape", ")", ")", "\n", "if", "bbox", ".", "shape", "[", "0", "]", "==", "nframes", ":", "\n", "                ", "bbox_to_use", "=", "bbox", "\n", "imgSequence_to_use", "=", "imgSequence", "\n", "\n", "", "else", ":", "\n", "                ", "bbox_to_use", "=", "bbox", "[", "0", ":", "nframes", "]", "# need to check'", "\n", "imgSequence_to_use", "=", "imgSequence", "[", "0", ":", "nframes", "]", "\n", "\n", "\n", "", "", "elif", "nframes", "<", "useLen", ":", "\n", "            ", "seqLeft", "=", "useLen", "-", "nframes", "\n", "sequence", "=", "[", "]", "\n", "\n", "img_sequence", "=", "[", "]", "\n", "bbx", "=", "[", "]", "\n", "m_idx", "=", "[", "]", "\n", "idx", "=", "0", "# start from first frame", "\n", "for", "i", "in", "xrange", "(", "seqLeft", ")", ":", "\n", "\n", "                ", "mask_sel", "=", "np", ".", "zeros", "(", "(", "self", ".", "numJoint", ",", "2", ")", ")", "\n", "data_sel", "=", "np", ".", "zeros", "(", "(", "self", ".", "numJoint", ",", "2", ")", ")", "\n", "\n", "bbx_sel", "=", "np", ".", "zeros", "(", "(", "4", ")", ")", "\n", "img_sel", "=", "torch", ".", "zeros", "(", "3", ",", "224", ",", "224", ")", "\n", "\n", "sequence", ".", "append", "(", "np", ".", "expand_dims", "(", "data_sel", ",", "0", ")", ")", "\n", "\n", "bbx", ".", "append", "(", "np", ".", "expand_dims", "(", "bbx_sel", ",", "0", ")", ")", "\n", "img_sequence", ".", "append", "(", "img_sel", ".", "unsqueeze", "(", "0", ")", ")", "\n", "m_idx", ".", "append", "(", "np", ".", "expand_dims", "(", "mask_sel", ",", "0", ")", ")", "\n", "\n", "", "sequence", "=", "np", ".", "concatenate", "(", "sequence", ",", "axis", "=", "0", ")", "# seqLeft x 15 x 2", "\n", "bbx", "=", "np", ".", "concatenate", "(", "bbx", ",", "axis", "=", "0", ")", "# seqLeft x 4", "\n", "sequence_img", "=", "torch", ".", "cat", "(", "(", "img_sequence", ")", ",", "0", ")", "\n", "ma_idx", "=", "np", ".", "concatenate", "(", "m_idx", ",", "axis", "=", "0", ")", "\n", "\n", "sequence_to_use", "=", "np", ".", "concatenate", "(", "(", "skeleton", ",", "sequence", ")", ",", "axis", "=", "0", ")", ".", "astype", "(", "float", ")", "\n", "\n", "mask_part1", "=", "np", ".", "ones", "(", "(", "skeleton", ".", "shape", ")", ")", "\n", "mask_idx", "=", "np", ".", "concatenate", "(", "(", "mask_part1", ",", "ma_idx", ")", ",", "axis", "=", "0", ")", ".", "astype", "(", "float", ")", "\n", "if", "bbox", ".", "shape", "[", "0", "]", "==", "nframes", ":", "\n", "                ", "bbox_to_use", "=", "np", ".", "concatenate", "(", "(", "bbox", ",", "bbx", ")", ",", "axis", "=", "0", ")", ".", "astype", "(", "float", ")", "\n", "imgSequence_to_use", "=", "torch", ".", "cat", "(", "(", "imgSequence", ",", "sequence_img", ")", ",", "0", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "", "else", ":", "\n", "                ", "bbox_to_use", "=", "np", ".", "concatenate", "(", "(", "bbox", "[", "0", ":", "nframes", "]", ",", "bbx", ")", ",", "axis", "=", "0", ")", ".", "astype", "(", "float", ")", "\n", "imgSequence_to_use", "=", "torch", ".", "cat", "(", "(", "imgSequence", "[", "0", ":", "nframes", "]", ",", "sequence_img", ")", ",", "0", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "\n", "", "", "return", "sequence_to_use", ",", "bbox_to_use", ",", "imgSequence_to_use", ",", "mask_idx", ",", "nframes", ",", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.get_normalized_data": [[310, 323], ["numpy.concatenate().astype", "numpy.concatenate().astype", "numpy.concatenate", "numpy.concatenate", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims"], "methods", ["None"], ["", "def", "get_normalized_data", "(", "self", ",", "skeleton", ")", ":", "\n", "        ", "'skeleton : 15 x 2 x T'", "\n", "\n", "X", "=", "skeleton", "[", ":", ",", ":", ",", "0", "]", "\n", "Y", "=", "skeleton", "[", ":", ",", ":", ",", "1", "]", "\n", "\n", "\n", "normX", "=", "(", "X", "-", "self", ".", "meanX", ")", "/", "self", ".", "stdX", "\n", "normY", "=", "(", "Y", "-", "self", ".", "meanY", ")", "/", "self", ".", "stdY", "\n", "\n", "normSkeleton", "=", "np", ".", "concatenate", "(", "(", "np", ".", "expand_dims", "(", "normX", ",", "2", ")", ",", "np", ".", "expand_dims", "(", "normY", ",", "2", ")", ")", ",", "2", ")", ".", "astype", "(", "float", ")", "# inputLen x 15 x 2", "\n", "\n", "return", "normSkeleton", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.get_normalized_data_openpose": [[324, 332], ["numpy.zeros", "numpy.zeros", "range"], "methods", ["None"], ["", "def", "get_normalized_data_openpose", "(", "self", ",", "skeleton", ",", "imageSize", ")", ":", "\n", "        ", "normSkeleton", "=", "np", ".", "zeros", "(", "(", "skeleton", ".", "shape", ")", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "skeleton", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "normSkeleton", "[", "i", ",", ":", ",", "0", "]", "=", "skeleton", "[", "i", ",", ":", ",", "0", "]", "/", "imageSize", "[", "i", "]", "[", "0", "]", "\n", "normSkeleton", "[", "i", ",", ":", ",", "1", "]", "=", "skeleton", "[", "i", ",", ":", ",", "1", "]", "/", "imageSize", "[", "i", "]", "[", "1", "]", "\n", "normSkeleton", "[", "i", ",", ":", ",", "2", "]", "=", "skeleton", "[", "i", ",", ":", ",", "2", "]", "\n", "\n", "", "return", "normSkeleton", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.get_unNormalized_data": [[333, 357], ["isinstance", "torch.FloatTensor().repeat", "torch.FloatTensor().repeat", "torch.FloatTensor().repeat", "torch.FloatTensor().repeat", "torch.FloatTensor().repeat", "torch.FloatTensor().repeat", "torch.FloatTensor().repeat", "torch.FloatTensor().repeat", "torch.FloatTensor().repeat", "torch.FloatTensor().repeat", "torch.FloatTensor().repeat", "torch.FloatTensor().repeat", "torch.FloatTensor().repeat", "torch.FloatTensor().repeat", "torch.FloatTensor().repeat", "torch.FloatTensor().repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "torch.Tensor().float.squeeze", "torch.Tensor().float.squeeze", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "unNormX.unsqueeze", "unNormY.unsqueeze", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "def", "get_unNormalized_data", "(", "self", ",", "normSkeleton", ")", ":", "\n", "        ", "'for inference part, normSkeleton : N x useLen x 15 x 2'", "\n", "\n", "if", "len", "(", "normSkeleton", ".", "shape", ")", "==", "4", ":", "\n", "            ", "normSkeleton", "=", "normSkeleton", ".", "squeeze", "(", "0", ")", "\n", "\n", "", "if", "isinstance", "(", "normSkeleton", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "normSkeleton", "=", "torch", ".", "Tensor", "(", "normSkeleton", ")", ".", "float", "(", ")", "\n", "\n", "", "framNum", "=", "normSkeleton", ".", "shape", "[", "0", "]", "\n", "meanX_mat", "=", "torch", ".", "FloatTensor", "(", "self", ".", "meanX", ")", ".", "repeat", "(", "framNum", ",", "1", ")", "# inputLen x 15", "\n", "meanY_mat", "=", "torch", ".", "FloatTensor", "(", "self", ".", "meanY", ")", ".", "repeat", "(", "framNum", ",", "1", ")", "\n", "stdX_mat", "=", "torch", ".", "FloatTensor", "(", "self", ".", "stdX", ")", ".", "repeat", "(", "framNum", ",", "1", ")", "\n", "stdY_mat", "=", "torch", ".", "FloatTensor", "(", "self", ".", "stdY", ")", ".", "repeat", "(", "framNum", ",", "1", ")", "\n", "\n", "X", "=", "normSkeleton", "[", ":", ",", ":", ",", "0", "]", "# inputLen x 15", "\n", "Y", "=", "normSkeleton", "[", ":", ",", ":", ",", "1", "]", "# inputLen x 15", "\n", "\n", "unNormX", "=", "X", "*", "stdX_mat", "+", "meanX_mat", "\n", "unNormY", "=", "Y", "*", "stdY_mat", "+", "meanY_mat", "\n", "\n", "unNormSkeleton", "=", "torch", ".", "cat", "(", "(", "unNormX", ".", "unsqueeze", "(", "2", ")", ",", "unNormY", ".", "unsqueeze", "(", "2", ")", ")", ",", "2", ")", "\n", "\n", "return", "unNormSkeleton", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.__getitem__": [[358, 388], ["JHMDB_dloader.jhmdbDataset.read_annot", "JHMDB_dloader.jhmdbDataset.get_normalized_data", "JHMDB_dloader.jhmdbDataset.preProcessImage", "JHMDB_dloader.jhmdbDataset.data_to_use", "JHMDB_dloader.jhmdbDataset.get_normalized_data"], "methods", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.read_annot", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.get_normalized_data", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.preProcessImage", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.data_to_use", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.jhmdbDataset.get_normalized_data"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "annotSet", "=", "self", ".", "trainSet", "[", "idx", "]", "\n", "\n", "", "elif", "self", ".", "split", "==", "'val'", ":", "\n", "            ", "annotSet", "=", "self", ".", "valSet", "[", "idx", "]", "\n", "", "else", ":", "\n", "            ", "annotSet", "=", "self", ".", "testSet", "[", "idx", "]", "\n", "\n", "", "imgPath", ",", "Bbox", ",", "gtSkeleton", ",", "baseline", "=", "self", ".", "read_annot", "(", "annotSet", ")", "\n", "normSkeleton", "=", "self", ".", "get_normalized_data", "(", "gtSkeleton", ")", "\n", "\n", "if", "self", ".", "split", "==", "'test'", ":", "\n", "\n", "            ", "baseline_to_use", "=", "self", ".", "get_normalized_data", "(", "baseline", ")", "\n", "", "else", ":", "\n", "            ", "baseline_to_use", "=", "None", "\n", "\n", "\n", "", "imgSequence", ",", "imageSize", "=", "self", ".", "preProcessImage", "(", "imgPath", ",", "Bbox", ")", "\n", "\n", "\n", "sequence_to_use", ",", "Bbox_to_use", ",", "imgSequence_to_use", ",", "mask_idx", ",", "nframes", ",", "idx", "=", "self", ".", "data_to_use", "(", "normSkeleton", ",", "Bbox", ",", "imgSequence", ")", "\n", "\n", "\n", "dicts", "=", "{", "'imgSequence_to_use'", ":", "imgSequence_to_use", ",", "'Bbox_to_use'", ":", "Bbox_to_use", ",", "\n", "'sequence_to_use'", ":", "sequence_to_use", ",", "'mask_idx'", ":", "mask_idx", ",", "'nframes'", ":", "nframes", ",", "\n", "'randomInd:'", ":", "idx", ",", "'baseline_to_use'", ":", "baseline_to_use", ",", "'imgPath'", ":", "imgPath", "}", "\n", "\n", "return", "dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.None.JHMDB_dloader.get_train_test_annotation": [[29, 74], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.listdir", "range", "len", "os.path.join", "range", "totTXTlist[].split", "open", "f.readlines", "len", "os.path.join", "os.path.join", "os.path.join", "scipy.io.loadmat", "[].split", "[].split", "os.path.join", "scipy.io.loadmat", "scipy.io.loadmat", "int", "trainAnnot.append", "numpy.zeros", "testAnnot.append", "os.path.join", "os.path.join", "content[].split", "content[].split"], "function", ["None"], ["def", "get_train_test_annotation", "(", "dataRoot", ")", ":", "\n", "\n", "    ", "subFolder", "=", "os", ".", "path", ".", "join", "(", "dataRoot", ",", "'sub_splits'", ")", "\n", "imageFolder", "=", "os", ".", "path", ".", "join", "(", "dataRoot", ",", "'Rename_Images'", ")", "\n", "maskFolder", "=", "os", ".", "path", ".", "join", "(", "dataRoot", ",", "'puppet_mask'", ")", "\n", "poseFolder", "=", "os", ".", "path", ".", "join", "(", "dataRoot", ",", "'joint_positions'", ")", "\n", "\n", "# baselineFolder = os.path.join(dataRoot, 'your baseline folder')", "\n", "\n", "totTXTlist", "=", "os", ".", "listdir", "(", "subFolder", ")", "\n", "\n", "trainAnnot", "=", "[", "]", "\n", "testAnnot", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "totTXTlist", ")", ")", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "join", "(", "subFolder", ",", "totTXTlist", "[", "i", "]", ")", "\n", "action", "=", "totTXTlist", "[", "i", "]", ".", "split", "(", "'_test_'", ")", "[", "0", "]", "\n", "\n", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "            ", "content", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "for", "t", "in", "range", "(", "0", ",", "len", "(", "content", ")", ")", ":", "\n", "\n", "            ", "folder_to_use", "=", "content", "[", "t", "]", ".", "split", "(", "'\\n'", ")", "[", "0", "]", ".", "split", "(", "'.avi'", ")", "[", "0", "]", "\n", "traintest", "=", "content", "[", "t", "]", ".", "split", "(", "'\\n'", ")", "[", "0", "]", ".", "split", "(", "'.avi'", ")", "[", "1", "]", "# 1: train; 2: test", "\n", "\n", "imgPath", "=", "os", ".", "path", ".", "join", "(", "imageFolder", ",", "action", ",", "folder_to_use", ")", "\n", "posePath", "=", "os", ".", "path", ".", "join", "(", "poseFolder", ",", "action", ",", "folder_to_use", ")", "\n", "maskPath", "=", "os", ".", "path", ".", "join", "(", "maskFolder", ",", "action", ",", "folder_to_use", ")", "\n", "\n", "\n", "annot", "=", "scipy", ".", "io", ".", "loadmat", "(", "os", ".", "path", ".", "join", "(", "posePath", ",", "'joint_positions'", ")", ")", "\n", "bbox", "=", "scipy", ".", "io", ".", "loadmat", "(", "os", ".", "path", ".", "join", "(", "maskPath", ",", "'Bbox.mat'", ")", ")", "[", "'Bbox'", "]", "\n", "mask", "=", "scipy", ".", "io", ".", "loadmat", "(", "os", ".", "path", ".", "join", "(", "maskPath", ",", "'puppet_mask.mat'", ")", ")", "[", "'part_mask'", "]", "\n", "\n", "if", "int", "(", "traintest", ")", "==", "1", ":", "\n", "                ", "dicts", "=", "{", "'imgPath'", ":", "imgPath", ",", "'annot'", ":", "annot", ",", "'Bbox'", ":", "bbox", ",", "'mask'", ":", "mask", ",", "'baseline'", ":", "None", "}", "\n", "trainAnnot", ".", "append", "(", "dicts", ")", "\n", "", "else", ":", "\n", "# baselinePath = os.path.join(baselineFolder, folder_to_use)", "\n", "# baseline = scipy.io.loadmat(os.path.join(baselinePath, 'preds.mat'))['preds']", "\n", "                ", "baseline", "=", "np", ".", "zeros", "(", "(", "40", ",", "15", ",", "2", ")", ")", "# only for debug", "\n", "dicts", "=", "{", "'imgPath'", ":", "imgPath", ",", "'annot'", ":", "annot", ",", "'Bbox'", ":", "bbox", ",", "'mask'", ":", "mask", ",", "'baseline'", ":", "baseline", "}", "\n", "testAnnot", ".", "append", "(", "dicts", ")", "\n", "\n", "", "", "", "return", "trainAnnot", ",", "testAnnot", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.DyanOF.Encoder.__init__": [[71, 77], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter"], "methods", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "Drr", ",", "Dtheta", ",", "T", ",", "gpu_id", ")", ":", "\n", "        ", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rr", "=", "nn", ".", "Parameter", "(", "Drr", ")", "\n", "self", ".", "theta", "=", "nn", ".", "Parameter", "(", "Dtheta", ")", "\n", "self", ".", "T", "=", "T", "\n", "self", ".", "gid", "=", "gpu_id", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.DyanOF.Encoder.forward": [[78, 86], ["DyanOF.creatRealDictionary", "DyanOF.fista", "torch.autograd.Variable", "torch.autograd.Variable"], "methods", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.DyanOF.creatRealDictionary", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.DyanOF.fista"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "dic_en", "=", "creatRealDictionary", "(", "self", ".", "T", ",", "self", ".", "rr", ",", "self", ".", "theta", ",", "self", ".", "gid", ")", "\n", "# print(dic_en.shape)", "\n", "sparsecode", "=", "fista", "(", "dic_en", ",", "x", ",", "0.01", ",", "100", ",", "self", ".", "gid", ")", "\n", "# print(sparsecode.shape)", "\n", "# return Variable(sparsecode)", "\n", "#     # , dic_en", "\n", "return", "Variable", "(", "sparsecode", ")", ",", "dic_en", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.DyanOF.Decoder.__init__": [[90, 97], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "rr", ",", "theta", ",", "T", ",", "gpu_id", ")", ":", "\n", "        ", "super", "(", "Decoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rr", "=", "rr", "\n", "self", ".", "theta", "=", "theta", "\n", "self", ".", "T", "=", "T", "\n", "# self.PRE = PRE", "\n", "self", ".", "gid", "=", "gpu_id", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.DyanOF.Decoder.forward": [[98, 105], ["DyanOF.creatRealDictionary", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "methods", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.DyanOF.creatRealDictionary"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# dic_de = creatRealDictionary(self.T + self.PRE, self.rr, self.theta, self.gid)", "\n", "        ", "dic_de", "=", "creatRealDictionary", "(", "self", ".", "T", ",", "self", ".", "rr", ",", "self", ".", "theta", ",", "self", ".", "gid", ")", "\n", "# print(dic_de.shape)", "\n", "# print(x)", "\n", "result", "=", "torch", ".", "matmul", "(", "dic_de", ",", "x", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.DyanOF.OFModel.__init__": [[109, 114], ["torch.Module.__init__", "DyanOF.Encoder", "DyanOF.Decoder"], "methods", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "Drr", ",", "Dtheta", ",", "T", ",", "gpu_id", ")", ":", "\n", "        ", "super", "(", "OFModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "l1", "=", "Encoder", "(", "Drr", ",", "Dtheta", ",", "T", ",", "gpu_id", ")", "\n", "# self.l2 = Decoder(self.l1.rr, self.l1.theta, T, PRE, gpu_id)", "\n", "self", ".", "l2", "=", "Decoder", "(", "self", ".", "l1", ".", "rr", ",", "self", ".", "l1", ".", "theta", ",", "T", ",", "gpu_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.DyanOF.OFModel.forward": [[115, 118], ["DyanOF.OFModel.l1", "DyanOF.OFModel.l2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "coeff", ",", "dict", "=", "self", ".", "l1", "(", "x", ")", "\n", "return", "self", ".", "l2", "(", "coeff", ")", "\n", "# return self.l2(self.l1(x))", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.DyanOF.OFModel.forward2": [[120, 122], ["DyanOF.OFModel.l1"], "methods", ["None"], ["", "def", "forward2", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "l1", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.DyanOF.creatRealDictionary": [[11, 32], ["torch.ones().cuda", "torch.ones().cuda", "torch.autograd.Variable", "range", "torch.cat", "torch.cat", "torch.norm", "torch.norm", "torch.norm.clone", "numpy.sqrt", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.cat", "torch.cat", "WVar.append", "torch.ones", "torch.ones", "torch.pow", "torch.pow", "torch.cos", "torch.cos", "torch.pow", "torch.pow", "torch.cos", "torch.cos", "torch.pow", "torch.pow", "torch.sin", "torch.sin", "torch.pow", "torch.pow", "torch.sin", "torch.sin", "torch.cat.view"], "function", ["None"], ["def", "creatRealDictionary", "(", "T", ",", "Drr", ",", "Dtheta", ",", "gpu_id", ")", ":", "\n", "    ", "WVar", "=", "[", "]", "\n", "Wones", "=", "torch", ".", "ones", "(", "1", ")", ".", "cuda", "(", "gpu_id", ")", "\n", "Wones", "=", "Variable", "(", "Wones", ",", "requires_grad", "=", "False", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "T", ")", ":", "\n", "        ", "W1", "=", "torch", ".", "mul", "(", "torch", ".", "pow", "(", "Drr", ",", "i", ")", ",", "torch", ".", "cos", "(", "i", "*", "Dtheta", ")", ")", "\n", "W2", "=", "torch", ".", "mul", "(", "torch", ".", "pow", "(", "-", "Drr", ",", "i", ")", ",", "torch", ".", "cos", "(", "i", "*", "Dtheta", ")", ")", "\n", "W3", "=", "torch", ".", "mul", "(", "torch", ".", "pow", "(", "Drr", ",", "i", ")", ",", "torch", ".", "sin", "(", "i", "*", "Dtheta", ")", ")", "\n", "W4", "=", "torch", ".", "mul", "(", "torch", ".", "pow", "(", "-", "Drr", ",", "i", ")", ",", "torch", ".", "sin", "(", "i", "*", "Dtheta", ")", ")", "\n", "W", "=", "torch", ".", "cat", "(", "(", "Wones", ",", "W1", ",", "W2", ",", "W3", ",", "W4", ")", ",", "0", ")", "\n", "WVar", ".", "append", "(", "W", ".", "view", "(", "1", ",", "-", "1", ")", ")", "\n", "", "dic", "=", "torch", ".", "cat", "(", "(", "WVar", ")", ",", "0", ")", "\n", "G", "=", "torch", ".", "norm", "(", "dic", ",", "p", "=", "2", ",", "dim", "=", "0", ")", "\n", "idx", "=", "(", "G", "==", "0", ")", ".", "nonzero", "(", ")", "\n", "nG", "=", "G", ".", "clone", "(", ")", "\n", "nG", "[", "idx", "]", "=", "np", ".", "sqrt", "(", "T", ")", "\n", "G", "=", "nG", "\n", "\n", "dic", "=", "dic", "/", "G", "\n", "\n", "return", "dic", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.DyanOF.fista": [[34, 68], ["torch.matmul", "torch.matmul", "torch.norm", "torch.norm", "torch.matmul", "torch.matmul", "torch.autograd.Variable", "torch.mul", "torch.mul", "torch.Softshrink", "torch.t", "torch.t", "torch.t", "torch.t", "torch.zeros().cuda", "torch.zeros().cuda", "linv.data.cpu().numpy", "torch.autograd.Variable", "torch.mul", "torch.mul", "torch.no_grad", "torch.no_grad", "range", "torch.eye().cuda", "torch.eye().cuda", "torch.matmul", "torch.matmul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.zeros", "torch.zeros", "linv.data.cpu", "torch.enable_grad", "torch.enable_grad", "nn.Softshrink.", "torch.eye", "torch.eye", "numpy.sqrt", "torch.norm", "torch.norm"], "function", ["None"], ["", "def", "fista", "(", "D", ",", "Y", ",", "lambd", ",", "maxIter", ",", "gpu_id", ")", ":", "\n", "    ", "DtD", "=", "torch", ".", "matmul", "(", "torch", ".", "t", "(", "D", ")", ",", "D", ")", "\n", "L", "=", "torch", ".", "norm", "(", "DtD", ",", "2", ")", "\n", "linv", "=", "1", "/", "L", "\n", "DtY", "=", "torch", ".", "matmul", "(", "torch", ".", "t", "(", "D", ")", ",", "Y", ")", "\n", "x_old", "=", "Variable", "(", "torch", ".", "zeros", "(", "DtD", ".", "shape", "[", "1", "]", ",", "DtY", ".", "shape", "[", "2", "]", ")", ".", "cuda", "(", "gpu_id", ")", ",", "requires_grad", "=", "True", ")", "# batch-wised", "\n", "# x_old = Variable(torch.zeros(DtD.shape[0], DtY.shape[1]).cuda(gpu_id), requires_grad=True)", "\n", "# x_old = torch.zeros(DtD.shape[0], DtY.shape[1]).cuda(gpu_id)", "\n", "t", "=", "1", "\n", "y_old", "=", "x_old", "\n", "lambd", "=", "lambd", "*", "(", "linv", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "# A = Variable(torch.eye(DtD.shape[0]).cuda(gpu_id), requires_grad=True) - torch.mul(DtD, linv)", "\n", "A", "=", "Variable", "(", "torch", ".", "eye", "(", "DtD", ".", "shape", "[", "1", "]", ")", ".", "cuda", "(", "gpu_id", ")", ",", "requires_grad", "=", "True", ")", "-", "torch", ".", "mul", "(", "DtD", ",", "linv", ")", "\n", "# A = torch.eye(DtD.shape[1]).cuda(gpu_id) - torch.mul(DtD, linv)", "\n", "DtY", "=", "torch", ".", "mul", "(", "DtY", ",", "linv", ")", "\n", "\n", "Softshrink", "=", "nn", ".", "Softshrink", "(", "lambd", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "ii", "in", "range", "(", "maxIter", ")", ":", "\n", "            ", "Ay", "=", "torch", ".", "matmul", "(", "A", ",", "y_old", ")", "\n", "del", "y_old", "\n", "with", "torch", ".", "enable_grad", "(", ")", ":", "\n", "                ", "x_new", "=", "Softshrink", "(", "(", "Ay", "+", "DtY", ")", ")", "\n", "", "t_new", "=", "(", "1", "+", "np", ".", "sqrt", "(", "1", "+", "4", "*", "t", "**", "2", ")", ")", "/", "2.", "\n", "tt", "=", "(", "t", "-", "1", ")", "/", "t_new", "\n", "y_old", "=", "torch", ".", "mul", "(", "x_new", ",", "(", "1", "+", "tt", ")", ")", "\n", "y_old", "-=", "torch", ".", "mul", "(", "x_old", ",", "tt", ")", "\n", "if", "torch", ".", "norm", "(", "(", "x_old", "-", "x_new", ")", ",", "p", "=", "2", ")", "/", "x_old", ".", "shape", "[", "1", "]", "<", "1e-4", ":", "\n", "                ", "x_old", "=", "x_new", "\n", "break", "\n", "", "t", "=", "t_new", "\n", "x_old", "=", "x_new", "\n", "del", "x_new", "\n", "", "", "return", "x_old", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.networks.keyframeProposalNet.__init__": [[30, 94], ["torch.Module.__init__", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Sigmoid", "torch.Sigmoid", "modelZoo.resNet.ResNet", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Linear", "torch.Linear", "torch.Conv2d", "torch.Conv2d", "torch.Linear", "torch.Linear", "modelZoo.resNet.ResNet", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "modelZoo.resNet.ResNet", "modelZoo.resNet.ResNet"], "methods", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "numFrame", ",", "Drr", ",", "Dtheta", ",", "gpu_id", ",", "backbone", ",", "config", ")", ":", "\n", "        ", "super", "(", "keyframeProposalNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_frame", "=", "numFrame", "\n", "self", ".", "gpu_id", "=", "gpu_id", "\n", "self", ".", "backbone", "=", "backbone", "\n", "self", ".", "config", "=", "config", "\n", "if", "self", ".", "backbone", "==", "'Resnet101'", ":", "\n", "            ", "self", ".", "modifiedResnet", "=", "ResNet", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "zero_init_residual", "=", "False", ",", "\n", "groups", "=", "1", ",", "width_per_group", "=", "64", ",", "replace_stride_with_dilation", "=", "None", ",", "\n", "norm_layer", "=", "None", ")", "# ResNet-101", "\n", "self", ".", "Conv2d", "=", "nn", ".", "Conv2d", "(", "2048", ",", "512", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "groups", "=", "1", ",", "bias", "=", "False", ",", "dilation", "=", "1", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "512", ",", "eps", "=", "1e-05", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", "\n", "\n", "", "elif", "self", ".", "backbone", "==", "'Resnet50'", ":", "\n", "            ", "self", ".", "modifiedResnet", "=", "ResNet", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "zero_init_residual", "=", "False", ",", "\n", "groups", "=", "1", ",", "width_per_group", "=", "64", ",", "replace_stride_with_dilation", "=", "None", ",", "\n", "norm_layer", "=", "None", ")", "# ResNet-50", "\n", "self", ".", "Conv2d", "=", "nn", ".", "Conv2d", "(", "2048", ",", "512", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "groups", "=", "1", ",", "bias", "=", "False", ",", "dilation", "=", "1", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "512", ",", "eps", "=", "1e-05", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", "\n", "\n", "\n", "", "elif", "self", ".", "backbone", "==", "'Resnet34'", ":", "\n", "            ", "self", ".", "modifiedResnet", "=", "ResNet", "(", "block", "=", "BasicBlock", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "zero_init_residual", "=", "False", ",", "\n", "groups", "=", "1", ",", "width_per_group", "=", "64", ",", "replace_stride_with_dilation", "=", "None", ",", "\n", "norm_layer", "=", "None", ")", "# ResNet-34", "\n", "# self.layer2 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=0, groups=1, bias=False, dilation=1)", "\n", "\n", "", "elif", "self", ".", "backbone", "==", "'Resnet18'", ":", "\n", "            ", "self", ".", "modifiedResnet", "=", "ResNet", "(", "block", "=", "BasicBlock", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "zero_init_residual", "=", "False", ",", "\n", "groups", "=", "1", ",", "width_per_group", "=", "64", ",", "replace_stride_with_dilation", "=", "None", ",", "\n", "norm_layer", "=", "None", ")", "# Resent-18", "\n", "\n", "", "self", ".", "relu", "=", "nn", ".", "LeakyReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "'downsample feature map'", "\n", "self", ".", "layer2", "=", "nn", ".", "Conv2d", "(", "512", ",", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "groups", "=", "1", ",", "bias", "=", "False", ",", "dilation", "=", "1", ")", "\n", "self", ".", "bn_l2", "=", "nn", ".", "BatchNorm2d", "(", "256", ",", "eps", "=", "1e-05", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", "\n", "self", ".", "layer3", "=", "nn", ".", "Conv2d", "(", "256", ",", "128", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "groups", "=", "1", ",", "bias", "=", "False", ",", "dilation", "=", "1", ")", "\n", "self", ".", "bn_l3", "=", "nn", ".", "BatchNorm2d", "(", "128", ",", "eps", "=", "1e-05", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", "\n", "self", ".", "layer4", "=", "nn", ".", "Conv2d", "(", "128", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "groups", "=", "1", ",", "bias", "=", "False", ",", "dilation", "=", "1", ")", "\n", "self", ".", "bn_l4", "=", "nn", ".", "BatchNorm2d", "(", "64", ",", "eps", "=", "1e-05", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", "\n", "\n", "\n", "self", ".", "Drr", "=", "nn", ".", "Parameter", "(", "Drr", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "Dtheta", "=", "nn", ".", "Parameter", "(", "Dtheta", ",", "requires_grad", "=", "True", ")", "\n", "\n", "'embeded infomation along time space'", "\n", "if", "self", ".", "config", "==", "'Penn'", ":", "\n", "            ", "self", ".", "fcn1", "=", "nn", ".", "Conv2d", "(", "self", ".", "num_frame", ",", "25", ",", "kernel_size", "=", "1", ",", "stride", "=", "2", ",", "padding", "=", "0", ",", "groups", "=", "1", ",", "bias", "=", "False", ",", "dilation", "=", "1", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "2560", ",", "self", ".", "num_frame", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "fcn1", "=", "nn", ".", "Conv2d", "(", "self", ".", "num_frame", ",", "25", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "groups", "=", "1", ",", "bias", "=", "False", ",", "\n", "dilation", "=", "1", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "5760", ",", "self", ".", "num_frame", ")", "\n", "\n", "", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "25", ",", "eps", "=", "1e-05", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", "\n", "self", ".", "fcn2", "=", "nn", ".", "Conv2d", "(", "25", ",", "10", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "groups", "=", "1", ",", "bias", "=", "False", ",", "dilation", "=", "1", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "10", ",", "eps", "=", "1e-05", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", "\n", "\n", "self", ".", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "\n", "\n", "self", ".", "sig", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.networks.keyframeProposalNet.forward": [[96, 123], ["modelZoo.DyanOF.creatRealDictionary", "networks.keyframeProposalNet.modifiedResnet", "networks.keyframeProposalNet.layer2", "networks.keyframeProposalNet.bn_l2", "networks.keyframeProposalNet.relu", "networks.keyframeProposalNet.layer3", "networks.keyframeProposalNet.bn_l3", "networks.keyframeProposalNet.relu", "networks.keyframeProposalNet.layer4", "networks.keyframeProposalNet.bn_l4", "networks.keyframeProposalNet.relu", "networks.keyframeProposalNet.Conv2d", "networks.keyframeProposalNet.bn1", "networks.keyframeProposalNet.relu"], "methods", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.DyanOF.creatRealDictionary"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "Dictionary", "=", "creatRealDictionary", "(", "self", ".", "num_frame", ",", "self", ".", "Drr", ",", "self", ".", "Dtheta", ",", "self", ".", "gpu_id", ")", "\n", "imageFeature", "=", "self", ".", "modifiedResnet", "(", "x", ")", "# T X 512 X 7 X 7", "\n", "\n", "if", "self", ".", "backbone", "==", "'Resnet34'", "or", "'Resnet18'", ":", "\n", "            ", "convx", "=", "imageFeature", "\n", "\n", "", "else", ":", "\n", "            ", "convx", "=", "self", ".", "Conv2d", "(", "imageFeature", ")", "\n", "convx", "=", "self", ".", "bn1", "(", "convx", ")", "\n", "convx", "=", "self", ".", "relu", "(", "convx", ")", "\n", "\n", "", "x2", "=", "self", ".", "layer2", "(", "convx", ")", "\n", "x2", "=", "self", ".", "bn_l2", "(", "x2", ")", "\n", "x2", "=", "self", ".", "relu", "(", "x2", ")", "\n", "\n", "x3", "=", "self", ".", "layer3", "(", "x2", ")", "\n", "x3", "=", "self", ".", "bn_l3", "(", "x3", ")", "\n", "\n", "x3", "=", "self", ".", "relu", "(", "x3", ")", "\n", "\n", "x4", "=", "self", ".", "layer4", "(", "x3", ")", "\n", "x4", "=", "self", ".", "bn_l4", "(", "x4", ")", "\n", "feature", "=", "self", ".", "relu", "(", "x4", ")", "\n", "\n", "\n", "return", "feature", ",", "Dictionary", ",", "imageFeature", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.networks.keyframeProposalNet.forward2": [[125, 139], ["feature.permute", "networks.keyframeProposalNet.fcn1", "networks.keyframeProposalNet.bn2", "networks.keyframeProposalNet.relu", "networks.keyframeProposalNet.fcn2", "networks.keyframeProposalNet.bn3", "networks.keyframeProposalNet.relu", "networks.keyframeProposalNet.view", "networks.keyframeProposalNet.fc", "networks.keyframeProposalNet.sig"], "methods", ["None"], ["", "def", "forward2", "(", "self", ",", "feature", ",", "alpha", ")", ":", "\n", "\n", "        ", "x", "=", "feature", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "x", "=", "self", ".", "fcn1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn2", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "fcn2", "(", "x", ")", "\n", "x", "=", "self", ".", "bn3", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "\n", "x", "=", "x", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "out", "=", "self", ".", "sig", "(", "alpha", "*", "x", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.networks.onlineUpdate.__init__": [[142, 169], ["torch.Module.__init__", "networks.keyframeProposalNet", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "FRA", ",", "PRE", ",", "T", ",", "Drr", ",", "Dtheta", ",", "gpu_id", ")", ":", "\n", "        ", "super", "(", "onlineUpdate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "gpu_id", "=", "gpu_id", "\n", "self", ".", "Drr", "=", "Drr", "\n", "self", ".", "Dtheta", "=", "Dtheta", "\n", "self", ".", "numFrame", "=", "T", "\n", "self", ".", "K_FPN", "=", "keyframeProposalNet", "(", "numFrame", "=", "self", ".", "numFrame", ",", "Drr", "=", "self", ".", "Drr", ",", "Dtheta", "=", "self", ".", "Dtheta", ",", "gpu_id", "=", "gpu_id", ",", "\n", "backbone", "=", "'Resnet18'", ",", "config", "=", "'jhmdb'", ")", "\n", "self", ".", "FRA", "=", "FRA", "\n", "self", ".", "PRE", "=", "PRE", "\n", "\n", "\n", "self", ".", "relu", "=", "nn", ".", "LeakyReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "layer0", "=", "nn", ".", "Conv2d", "(", "512", "*", "2", ",", "512", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "groups", "=", "1", ",", "bias", "=", "False", ",", "dilation", "=", "1", ")", "\n", "self", ".", "bn_l0", "=", "nn", ".", "BatchNorm2d", "(", "512", ",", "eps", "=", "1e-05", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", "\n", "\n", "self", ".", "layer1", "=", "nn", ".", "Conv2d", "(", "512", ",", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "groups", "=", "1", ",", "bias", "=", "False", ",", "dilation", "=", "1", ")", "\n", "self", ".", "bn_l1", "=", "nn", ".", "BatchNorm2d", "(", "256", ",", "eps", "=", "1e-05", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", "\n", "\n", "self", ".", "layer2", "=", "nn", ".", "Conv2d", "(", "256", ",", "128", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "groups", "=", "1", ",", "bias", "=", "False", ",", "dilation", "=", "1", ")", "\n", "self", ".", "bn_l2", "=", "nn", ".", "BatchNorm2d", "(", "128", ",", "eps", "=", "1e-05", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", "\n", "\n", "self", ".", "layer3", "=", "nn", ".", "Conv2d", "(", "128", ",", "64", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "groups", "=", "1", ",", "bias", "=", "False", ",", "dilation", "=", "1", ")", "\n", "self", ".", "bn_l3", "=", "nn", ".", "BatchNorm2d", "(", "64", ",", "eps", "=", "1e-05", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", "\n", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "1", "*", "64", "*", "3", "*", "3", ",", "2", ")", "\n", "", "def", "get_keylist", "(", "self", ",", "x", ",", "alpha", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.networks.onlineUpdate.get_keylist": [[169, 190], ["networks.onlineUpdate.K_FPN.forward", "networks.onlineUpdate.K_FPN.forward2", "key_ind.cpu().numpy", "list", "list", "list", "feat_key.reshape.reshape.reshape", "utils.fista", "key_ind.cpu", "set", "set", "numpy.where", "numpy.where"], "methods", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet.forward", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.networks.keyframeProposalNet.forward2", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.DyanOF.fista"], ["", "def", "get_keylist", "(", "self", ",", "x", ",", "alpha", ")", ":", "\n", "        ", "feature", ",", "Dictionary", ",", "imgFeature", "=", "self", ".", "K_FPN", ".", "forward", "(", "x", ")", "\n", "indicator", "=", "self", ".", "K_FPN", ".", "forward2", "(", "feature", ",", "alpha", ")", "\n", "s", "=", "indicator", "[", "0", ",", ":", "]", "\n", "key_ind", "=", "(", "s", ">", "0.995", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", "1", ")", "\n", "key_list_tot", "=", "key_ind", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "key_list_FRA", "=", "list", "(", "key_list_tot", "[", "np", ".", "where", "(", "key_list_tot", "<", "self", ".", "FRA", ")", "[", "0", "]", "]", ")", "# input key list", "\n", "key_list", "=", "list", "(", "key_list_tot", "[", "np", ".", "where", "(", "key_list_tot", "<", "self", ".", "PRE", "+", "self", ".", "FRA", ")", "[", "0", "]", "]", ")", "\n", "keylist_to_pred", "=", "list", "(", "set", "(", "key_list", ")", "-", "set", "(", "key_list_FRA", ")", ")", "\n", "\n", "\n", "Dict_key", "=", "Dictionary", "[", "key_list_FRA", ",", ":", "]", "\n", "feat_key", "=", "imgFeature", "[", "key_list_FRA", ",", ":", "]", "\n", "\n", "\n", "t", ",", "c", ",", "w", ",", "h", "=", "feat_key", ".", "shape", "\n", "feat_key", "=", "feat_key", ".", "reshape", "(", "1", ",", "t", ",", "c", "*", "w", "*", "h", ")", "\n", "sparseCode_key", "=", "fista", "(", "Dict_key", ",", "feat_key", ",", "0.01", ",", "100", ",", "self", ".", "gpu_id", ")", "\n", "\n", "return", "sparseCode_key", ",", "Dictionary", ",", "keylist_to_pred", ",", "key_list_FRA", ",", "key_list", ",", "imgFeature", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.networks.onlineUpdate.forward": [[191, 218], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.matmul().reshape", "torch.matmul().reshape", "torch.matmul().reshape", "torch.matmul().reshape", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "networks.onlineUpdate.layer0", "networks.onlineUpdate.bn_l0", "networks.onlineUpdate.relu", "networks.onlineUpdate.layer1", "networks.onlineUpdate.bn_l1", "networks.onlineUpdate.relu", "networks.onlineUpdate.layer2", "networks.onlineUpdate.bn_l2", "networks.onlineUpdate.relu", "networks.onlineUpdate.layer3", "networks.onlineUpdate.bn_l3", "networks.onlineUpdate.relu", "x.view.view.view", "networks.onlineUpdate.fc", "Dictionary[].unsqueeze", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "imgFeature", ",", "sparseCode_key", ",", "Dictionary", ",", "fraNum", ")", ":", "\n", "        ", "gtImgFeature", "=", "imgFeature", "[", "fraNum", "]", "\n", "c", ",", "w", ",", "h", "=", "gtImgFeature", ".", "shape", "\n", "newDictionary", "=", "torch", ".", "cat", "(", "(", "Dictionary", "[", "0", ":", "self", ".", "FRA", "]", ",", "Dictionary", "[", "fraNum", "]", ".", "unsqueeze", "(", "0", ")", ")", ")", "\n", "newImgFeature", "=", "torch", ".", "matmul", "(", "newDictionary", ",", "sparseCode_key", ")", ".", "reshape", "(", "newDictionary", ".", "shape", "[", "0", "]", ",", "c", ",", "w", ",", "h", ")", "\n", "\n", "predImgFeature", "=", "newImgFeature", "[", "-", "1", "]", "\n", "combineFeature", "=", "torch", ".", "cat", "(", "(", "gtImgFeature", ",", "predImgFeature", ")", ")", ".", "unsqueeze", "(", "0", ")", "\n", "x", "=", "self", ".", "layer0", "(", "combineFeature", ")", "\n", "x", "=", "self", ".", "bn_l0", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn_l1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "bn_l2", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "bn_l3", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "\n", "x", "=", "x", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "out", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.networks.load_preTrained_model": [[9, 27], ["pretrained.state_dict", "newModel.state_dict", "newModel.state_dict.update", "newModel.load_state_dict", "newModel.parameters", "pretrained.state_dict.items"], "function", ["None"], ["def", "load_preTrained_model", "(", "pretrained", ",", "newModel", ")", ":", "\n", "    ", "'load pretrained resnet-X to self defined model '", "\n", "'modified resnet has no last two layers, only return feature map'", "\n", "\n", "pre_dict", "=", "pretrained", ".", "state_dict", "(", ")", "\n", "\n", "new_dict", "=", "newModel", ".", "state_dict", "(", ")", "\n", "\n", "pre_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "pre_dict", ".", "items", "(", ")", "if", "k", "in", "new_dict", "}", "\n", "\n", "new_dict", ".", "update", "(", "pre_dict", ")", "\n", "\n", "newModel", ".", "load_state_dict", "(", "new_dict", ")", "\n", "\n", "for", "param", "in", "newModel", ".", "parameters", "(", ")", ":", "\n", "        ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "return", "newModel", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.BasicBlock.__init__": [[40, 57], ["torch.Module.__init__", "resNet.conv3x3", "norm_layer", "torch.ReLU", "torch.ReLU", "resNet.conv3x3", "norm_layer", "ValueError", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet.__init__", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.conv3x3", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "groups", "=", "1", ",", "\n", "base_width", "=", "64", ",", "dilation", "=", "1", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "if", "groups", "!=", "1", "or", "base_width", "!=", "64", ":", "\n", "            ", "raise", "ValueError", "(", "'BasicBlock only supports groups=1 and base_width=64'", ")", "\n", "", "if", "dilation", ">", "1", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Dilation > 1 not supported in BasicBlock\"", ")", "\n", "# Both self.conv1 and self.downsample layers downsample the input when stride != 1", "\n", "", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "norm_layer", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.BasicBlock.forward": [[58, 75], ["resNet.BasicBlock.conv1", "resNet.BasicBlock.bn1", "resNet.BasicBlock.relu", "resNet.BasicBlock.conv2", "resNet.BasicBlock.bn2", "resNet.BasicBlock.relu", "resNet.BasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.Bottleneck.__init__": [[81, 97], ["torch.Module.__init__", "resNet.conv1x1", "norm_layer", "resNet.conv3x3", "norm_layer", "resNet.conv1x1", "norm_layer", "torch.ReLU", "torch.ReLU", "int"], "methods", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet.__init__", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.conv1x1", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.conv3x3", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.conv1x1"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "groups", "=", "1", ",", "\n", "base_width", "=", "64", ",", "dilation", "=", "1", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "width", "=", "int", "(", "planes", "*", "(", "base_width", "/", "64.", ")", ")", "*", "groups", "\n", "# Both self.conv2 and self.downsample layers downsample the input when stride != 1", "\n", "self", ".", "conv1", "=", "conv1x1", "(", "inplanes", ",", "width", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "width", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "width", ",", "width", ",", "stride", ",", "groups", ",", "dilation", ")", "\n", "self", ".", "bn2", "=", "norm_layer", "(", "width", ")", "\n", "self", ".", "conv3", "=", "conv1x1", "(", "width", ",", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "bn3", "=", "norm_layer", "(", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.Bottleneck.forward": [[98, 119], ["resNet.Bottleneck.conv1", "resNet.Bottleneck.bn1", "resNet.Bottleneck.relu", "resNet.Bottleneck.conv2", "resNet.Bottleneck.bn2", "resNet.Bottleneck.relu", "resNet.Bottleneck.conv3", "resNet.Bottleneck.bn3", "resNet.Bottleneck.relu", "resNet.Bottleneck.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.ResNet.__init__": [[126, 180], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "resNet.ResNet._make_layer", "resNet.ResNet._make_layer", "resNet.ResNet._make_layer", "resNet.ResNet._make_layer", "len", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet.__init__", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet._make_layer", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet._make_layer", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet._make_layer", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "zero_init_residual", "=", "False", ",", "\n", "groups", "=", "1", ",", "width_per_group", "=", "64", ",", "replace_stride_with_dilation", "=", "None", ",", "\n", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "self", ".", "_norm_layer", "=", "norm_layer", "\n", "\n", "self", ".", "inplanes", "=", "64", "\n", "self", ".", "dilation", "=", "1", "\n", "if", "replace_stride_with_dilation", "is", "None", ":", "\n", "# each element in the tuple indicates if we should replace", "\n", "# the 2x2 stride with a dilated convolution instead", "\n", "            ", "replace_stride_with_dilation", "=", "[", "False", ",", "False", ",", "False", "]", "\n", "", "if", "len", "(", "replace_stride_with_dilation", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"replace_stride_with_dilation should be None \"", "\n", "\"or a 3-element tuple, got {}\"", ".", "format", "(", "replace_stride_with_dilation", ")", ")", "\n", "", "self", ".", "groups", "=", "groups", "\n", "self", ".", "base_width", "=", "width_per_group", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "self", ".", "inplanes", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "self", ".", "inplanes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ",", "\n", "dilate", "=", "replace_stride_with_dilation", "[", "0", "]", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ",", "\n", "dilate", "=", "replace_stride_with_dilation", "[", "1", "]", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ",", "\n", "dilate", "=", "replace_stride_with_dilation", "[", "2", "]", ")", "\n", "\n", "\"\"\"\"\"\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n        \n        \n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n        # Zero-initialize the last BN in each residual branch,\n        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n        if zero_init_residual:\n            for m in self.modules():\n                if isinstance(m, Bottleneck):\n                    nn.init.constant_(m.bn3.weight, 0)\n                elif isinstance(m, BasicBlock):\n                    nn.init.constant_(m.bn2.weight, 0)\n        \"\"\"", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.ResNet._make_layer": [[181, 204], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "resNet.conv1x1", "norm_layer", "block"], "methods", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.conv1x1"], ["", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ",", "dilate", "=", "False", ")", ":", "\n", "        ", "norm_layer", "=", "self", ".", "_norm_layer", "\n", "downsample", "=", "None", "\n", "previous_dilation", "=", "self", ".", "dilation", "\n", "if", "dilate", ":", "\n", "            ", "self", ".", "dilation", "*=", "stride", "\n", "stride", "=", "1", "\n", "", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "conv1x1", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "stride", ")", ",", "\n", "norm_layer", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ",", "self", ".", "groups", ",", "\n", "self", ".", "base_width", ",", "previous_dilation", ",", "norm_layer", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "_", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "groups", "=", "self", ".", "groups", ",", "\n", "base_width", "=", "self", ".", "base_width", ",", "dilation", "=", "self", ".", "dilation", ",", "\n", "norm_layer", "=", "norm_layer", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.ResNet._forward": [[205, 222], ["resNet.ResNet.conv1", "resNet.ResNet.bn1", "resNet.ResNet.relu", "resNet.ResNet.maxpool", "resNet.ResNet.layer1", "resNet.ResNet.layer2", "resNet.ResNet.layer3", "resNet.ResNet.layer4"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "# N x 2048 x 7 x 7", "\n", "\n", "\"\"\"\"\"\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        \"\"\"", "\"\"", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.conv3x3": [[25, 29], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ",", "groups", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "dilation", ",", "groups", "=", "groups", ",", "bias", "=", "False", ",", "dilation", "=", "dilation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.conv1x1": [[31, 34], ["torch.Conv2d"], "function", ["None"], ["", "def", "conv1x1", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"1x1 convolution\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet._resnet": [[227, 234], ["resNet.ResNet", "torch.utils.model_zoo.load_url", "ResNet.load_state_dict"], "function", ["None"], ["", "def", "_resnet", "(", "arch", ",", "block", ",", "layers", ",", "pretrained", ",", "progress", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "ResNet", "(", "block", ",", "layers", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "state_dict", "=", "load_state_dict_from_url", "(", "model_urls", "[", "arch", "]", ",", "\n", "progress", "=", "progress", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.resnet18": [[236, 245], ["resNet._resnet"], "function", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet._resnet"], ["", "def", "resnet18", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-18 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet18'", ",", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.resnet34": [[247, 256], ["resNet._resnet"], "function", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet._resnet"], ["", "def", "resnet34", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-34 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet34'", ",", "BasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.resnet50": [[258, 267], ["resNet._resnet"], "function", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet._resnet"], ["", "def", "resnet50", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-50 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet50'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.resnet101": [[269, 278], ["resNet._resnet"], "function", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet._resnet"], ["", "def", "resnet101", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-101 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet101'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.resnet152": [[280, 289], ["resNet._resnet"], "function", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet._resnet"], ["", "def", "resnet152", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-152 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet152'", ",", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.resnext50_32x4d": [[291, 302], ["resNet._resnet"], "function", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet._resnet"], ["", "def", "resnext50_32x4d", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNeXt-50 32x4d model from\n    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'groups'", "]", "=", "32", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "4", "\n", "return", "_resnet", "(", "'resnext50_32x4d'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.resnext101_32x8d": [[304, 315], ["resNet._resnet"], "function", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet._resnet"], ["", "def", "resnext101_32x8d", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNeXt-101 32x8d model from\n    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'groups'", "]", "=", "32", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "8", "\n", "return", "_resnet", "(", "'resnext101_32x8d'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.wide_resnet50_2": [[317, 331], ["resNet._resnet"], "function", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet._resnet"], ["", "def", "wide_resnet50_2", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"Wide ResNet-50-2 model from\n    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n    The model is the same as ResNet except for the bottleneck number of channels\n    which is twice larger in every block. The number of channels in outer 1x1\n    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "64", "*", "2", "\n", "return", "_resnet", "(", "'wide_resnet50_2'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet.wide_resnet101_2": [[333, 347], ["resNet._resnet"], "function", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet._resnet"], ["", "def", "wide_resnet101_2", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"Wide ResNet-101-2 model from\n    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n    The model is the same as ResNet except for the bottleneck number of channels\n    which is twice larger in every block. The number of channels in outer 1x1\n    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "64", "*", "2", "\n", "return", "_resnet", "(", "'wide_resnet101_2'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.BasicBlock.__init__": [[15, 27], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet.__init__"], ["def", "__init__", "(", "self", ",", "in_planes", ",", "planes", ",", "stride", "=", "1", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "\n", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", ")", "\n", "if", "stride", "!=", "1", "or", "in_planes", "!=", "self", ".", "expansion", "*", "planes", ":", "\n", "            ", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_planes", ",", "self", ".", "expansion", "*", "planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.BasicBlock.forward": [[29, 35], ["torch.relu", "torch.relu", "torch.relu", "resNet_101.BasicBlock.bn2", "resNet_101.BasicBlock.shortcut", "torch.relu", "torch.relu", "torch.relu", "resNet_101.BasicBlock.bn1", "resNet_101.BasicBlock.conv2", "resNet_101.BasicBlock.conv1"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", "\n", "out", "+=", "self", ".", "shortcut", "(", "x", ")", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.Bottleneck.__init__": [[40, 54], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet.__init__"], ["def", "__init__", "(", "self", ",", "in_planes", ",", "planes", ",", "stride", "=", "1", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_planes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "self", ".", "expansion", "*", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", "\n", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", ")", "\n", "if", "stride", "!=", "1", "or", "in_planes", "!=", "self", ".", "expansion", "*", "planes", ":", "\n", "            ", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_planes", ",", "self", ".", "expansion", "*", "planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.Bottleneck.forward": [[56, 63], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "resNet_101.Bottleneck.bn3", "resNet_101.Bottleneck.shortcut", "torch.relu", "torch.relu", "torch.relu", "resNet_101.Bottleneck.bn1", "resNet_101.Bottleneck.bn2", "resNet_101.Bottleneck.conv3", "resNet_101.Bottleneck.conv1", "resNet_101.Bottleneck.conv2"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", ")", "\n", "out", "=", "self", ".", "bn3", "(", "self", ".", "conv3", "(", "out", ")", ")", "\n", "out", "+=", "self", ".", "shortcut", "(", "x", ")", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet.__init__": [[66, 77], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "resNet_101.ResNet._make_layer", "resNet_101.ResNet._make_layer", "resNet_101.ResNet._make_layer", "resNet_101.ResNet._make_layer", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet.__init__", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet._make_layer", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet._make_layer", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet._make_layer", "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "num_blocks", ",", "num_classes", "=", "128", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_planes", "=", "64", "\n", "self", ".", "block_exp", "=", "block", ".", "expansion", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "num_blocks", "[", "0", "]", ",", "stride", "=", "1", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "num_blocks", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "num_blocks", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "num_blocks", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "512", "*", "self", ".", "block_exp", ",", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet._make_layer": [[78, 85], ["torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.append", "block"], "methods", ["None"], ["", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "num_blocks", ",", "stride", ")", ":", "\n", "        ", "strides", "=", "[", "stride", "]", "+", "[", "1", "]", "*", "(", "num_blocks", "-", "1", ")", "\n", "layers", "=", "[", "]", "\n", "for", "stride", "in", "strides", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "in_planes", ",", "planes", ",", "stride", ")", ")", "\n", "self", ".", "in_planes", "=", "planes", "*", "block", ".", "expansion", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet.forward": [[86, 99], ["torch.relu", "torch.relu", "torch.relu", "resNet_101.ResNet.layer1", "resNet_101.ResNet.layer2", "resNet_101.ResNet.layer3", "resNet_101.ResNet.layer4", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "resNet_101.ResNet.view", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear.", "resNet_101.ResNet.linear", "resNet_101.ResNet.bn1", "resNet_101.ResNet.size", "resNet_101.ResNet.conv1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "out", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "out", ")", ")", ")", "\n", "out", "=", "self", ".", "layer1", "(", "out", ")", "\n", "out", "=", "self", ".", "layer2", "(", "out", ")", "\n", "out", "=", "self", ".", "layer3", "(", "out", ")", "\n", "out", "=", "self", ".", "layer4", "(", "out", ")", "\n", "out", "=", "F", ".", "avg_pool2d", "(", "out", ",", "4", ")", "\n", "\n", "out", "=", "out", ".", "view", "(", "out", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "fc", "=", "nn", ".", "Linear", "(", "out", ".", "shape", "[", "0", "]", "*", "out", ".", "shape", "[", "1", "]", ",", "512", "*", "self", ".", "block_exp", ")", "\n", "out", "=", "fc", "(", "out", ")", "\n", "out", "=", "self", ".", "linear", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet18": [[101, 103], ["resNet_101.ResNet"], "function", ["None"], ["", "", "def", "ResNet18", "(", ")", ":", "\n", "    ", "return", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet34": [[104, 106], ["resNet_101.ResNet"], "function", ["None"], ["", "def", "ResNet34", "(", ")", ":", "\n", "    ", "return", "ResNet", "(", "BasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet50": [[107, 109], ["resNet_101.ResNet"], "function", ["None"], ["", "def", "ResNet50", "(", ")", ":", "\n", "    ", "return", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet101": [[110, 112], ["resNet_101.ResNet"], "function", ["None"], ["", "def", "ResNet101", "(", ")", ":", "\n", "    ", "return", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Yuexiaoxi10_Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos.modelZoo.resNet_101.ResNet152": [[113, 115], ["resNet_101.ResNet"], "function", ["None"], ["", "def", "ResNet152", "(", ")", ":", "\n", "    ", "return", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ")", "\n", "\n"]]}