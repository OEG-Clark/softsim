{"home.repos.pwc.inspect_result.amirhk_mace.None.generateMOExplanations.findClosestObservableSample": [[15, 47], ["observable_samples.items", "dataset_obj.getInputAttributeNames", "normalizedDistance.getDistanceBetweenSamples"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.normalizedDistance.getDistanceBetweenSamples"], ["def", "findClosestObservableSample", "(", "observable_samples", ",", "dataset_obj", ",", "factual_sample", ",", "norm_type", ")", ":", "\n", "\n", "  ", "closest_observable_sample", "=", "{", "'sample'", ":", "{", "}", ",", "'distance'", ":", "np", ".", "infty", ",", "'norm_type'", ":", "None", "}", "# in case no observables are found.", "\n", "\n", "for", "observable_sample_index", ",", "observable_sample", "in", "observable_samples", ".", "items", "(", ")", ":", "\n", "\n", "# observable_sample['y'] = True", "\n", "\n", "    ", "if", "observable_sample", "[", "'y'", "]", "==", "factual_sample", "[", "'y'", "]", ":", "# make sure the cf flips the prediction", "\n", "      ", "continue", "\n", "\n", "# Only compare against those observable samples that DO NOT differ with the", "\n", "# factual sample in non-actionable features!", "\n", "", "violating_actionable_attributes", "=", "False", "\n", "for", "attr_name_kurz", "in", "dataset_obj", ".", "getInputAttributeNames", "(", "'kurz'", ")", ":", "\n", "      ", "attr_obj", "=", "dataset_obj", ".", "attributes_kurz", "[", "attr_name_kurz", "]", "\n", "if", "attr_obj", ".", "actionability", "==", "'none'", "and", "factual_sample", "[", "attr_name_kurz", "]", "!=", "observable_sample", "[", "attr_name_kurz", "]", ":", "\n", "        ", "violating_actionable_attributes", "=", "True", "\n", "", "elif", "attr_obj", ".", "actionability", "==", "'same-or-increase'", "and", "factual_sample", "[", "attr_name_kurz", "]", ">", "observable_sample", "[", "attr_name_kurz", "]", ":", "\n", "        ", "violating_actionable_attributes", "=", "True", "\n", "", "elif", "attr_obj", ".", "actionability", "==", "'same-or-decrease'", "and", "factual_sample", "[", "attr_name_kurz", "]", "<", "observable_sample", "[", "attr_name_kurz", "]", ":", "\n", "        ", "violating_actionable_attributes", "=", "True", "\n", "\n", "", "", "observable_distance", "=", "normalizedDistance", ".", "getDistanceBetweenSamples", "(", "factual_sample", ",", "observable_sample", ",", "norm_type", ",", "dataset_obj", ")", "\n", "\n", "if", "violating_actionable_attributes", ":", "\n", "      ", "continue", "\n", "\n", "", "if", "observable_distance", "<", "closest_observable_sample", "[", "'distance'", "]", ":", "\n", "      ", "closest_observable_sample", "=", "{", "'sample'", ":", "observable_sample", ",", "'distance'", ":", "observable_distance", ",", "'norm_type'", ":", "norm_type", "}", "\n", "\n", "", "", "return", "closest_observable_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.generateMOExplanations.getPrettyStringForSampleDictionary": [[49, 74], ["sample.items", "sorted", "all_key_value_pairs.append", "len", "len", "key_value_pairs_with_x_in_key.items", "all_key_value_pairs.append", "sample.keys", "dataset_obj.getInputAttributeNames", "key_value_pairs_with_y_in_key.keys", "len", "dataset_obj.getOutputAttributeNames", "Exception", "key_value_pairs_with_y_in_key.keys", "int", "[].split"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getOutputAttributeNames"], ["", "def", "getPrettyStringForSampleDictionary", "(", "sample", ",", "dataset_obj", ")", ":", "\n", "\n", "  ", "if", "len", "(", "sample", ".", "keys", "(", ")", ")", "==", "0", ":", "\n", "    ", "return", "'No sample found.'", "\n", "\n", "", "key_value_pairs_with_x_in_key", "=", "{", "}", "\n", "key_value_pairs_with_y_in_key", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "sample", ".", "items", "(", ")", ":", "\n", "    ", "if", "key", "in", "dataset_obj", ".", "getInputAttributeNames", "(", "'kurz'", ")", ":", "\n", "      ", "key_value_pairs_with_x_in_key", "[", "key", "]", "=", "value", "\n", "", "elif", "key", "in", "dataset_obj", ".", "getOutputAttributeNames", "(", "'kurz'", ")", ":", "\n", "      ", "key_value_pairs_with_y_in_key", "[", "key", "]", "=", "value", "\n", "", "else", ":", "\n", "      ", "raise", "Exception", "(", "'Sample keys may only be `x` or `y`.'", ")", "\n", "\n", "", "", "assert", "len", "(", "key_value_pairs_with_y_in_key", ".", "keys", "(", ")", ")", "==", "1", ",", "f'expecting only 1 output variables, got {len(key_value_pairs_with_y_in_key.keys())}'", "\n", "\n", "all_key_value_pairs", "=", "[", "]", "\n", "for", "key", ",", "value", "in", "sorted", "(", "key_value_pairs_with_x_in_key", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", "[", "0", "]", "[", "1", ":", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", ")", ":", "\n", "    ", "all_key_value_pairs", ".", "append", "(", "f'{key} : {value}'", ")", "\n", "", "all_key_value_pairs", ".", "append", "(", "f\"{'y'}: {key_value_pairs_with_y_in_key['y']}\"", ")", "\n", "\n", "return", "f\"{{{', '.join(all_key_value_pairs)}}}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.generateMOExplanations.genExp": [[76, 111], ["time.time", "open", "generateMOExplanations.findClosestObservableSample", "print", "print", "print", "print", "print", "time.time", "generateMOExplanations.getPrettyStringForSampleDictionary", "generateMOExplanations.getPrettyStringForSampleDictionary"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.generateMOExplanations.findClosestObservableSample", "home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.getPrettyStringForSampleDictionary", "home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.getPrettyStringForSampleDictionary"], ["", "def", "genExp", "(", "\n", "explanation_file_name", ",", "\n", "dataset_obj", ",", "\n", "factual_sample", ",", "\n", "observable_samples", ",", "\n", "norm_type", ")", ":", "\n", "\n", "  ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "log_file", "=", "open", "(", "explanation_file_name", ",", "'w'", ")", "\n", "\n", "# factual_sample['y'] = False", "\n", "\n", "closest_observable_sample", "=", "findClosestObservableSample", "(", "\n", "observable_samples", ",", "\n", "dataset_obj", ",", "\n", "factual_sample", ",", "\n", "norm_type", "\n", ")", "\n", "\n", "print", "(", "'\\n'", ",", "file", "=", "log_file", ")", "\n", "print", "(", "f\"Factual sample: \\t\\t {getPrettyStringForSampleDictionary(factual_sample, dataset_obj)}\"", ",", "file", "=", "log_file", ")", "\n", "print", "(", "f\"Best observable sample: \\t {getPrettyStringForSampleDictionary(closest_observable_sample['sample'], dataset_obj)} (verified)\"", ",", "file", "=", "log_file", ")", "\n", "print", "(", "''", ",", "file", "=", "log_file", ")", "\n", "print", "(", "f\"Minimum observable distance (by searching the dataset):\\t {closest_observable_sample['distance']:.6f}\"", ",", "file", "=", "log_file", ")", "\n", "\n", "end_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "return", "{", "\n", "'factual_sample'", ":", "factual_sample", ",", "\n", "'cfe_sample'", ":", "closest_observable_sample", "[", "'sample'", "]", ",", "\n", "'cfe_found'", ":", "True", ",", "\n", "'cfe_plausible'", ":", "True", ",", "\n", "'cfe_distance'", ":", "closest_observable_sample", "[", "'distance'", "]", ",", "\n", "'cfe_time'", ":", "end_time", "-", "start_time", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.__init__": [[88, 143], ["dict", "copy.deepcopy", "loadData.Dataset.getAllAttributeNames", "numpy.setdiff1d", "loadData.Dataset.assertSiblingsShareAttributes", "loadData.Dataset.assertSiblingsShareAttributes", "len", "loadData.Dataset.getInputAttributeNames", "loadData.Dataset.getRealBasedAttributeNames", "numpy.unique", "numpy.setdiff1d", "data_frame_long[].to_numpy", "attributes_long.items", "numpy.array", "numpy.floor", "loadData.Dataset.getAllAttributeNames", "numpy.array_equal", "numpy.array_equal", "numpy.array_equal", "debug.ipsh"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getAllAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.assertSiblingsShareAttributes", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.assertSiblingsShareAttributes", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getRealBasedAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getAllAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.debug.ipsh"], ["  ", "def", "__init__", "(", "self", ",", "data_frame", ",", "attributes", ",", "is_one_hot", ",", "dataset_name", ")", ":", "\n", "\n", "    ", "self", ".", "dataset_name", "=", "dataset_name", "\n", "\n", "self", ".", "is_one_hot", "=", "is_one_hot", "\n", "\n", "attributes_long", "=", "attributes", "\n", "data_frame_long", "=", "data_frame", "\n", "self", ".", "data_frame_long", "=", "data_frame_long", "# i.e., data_frame is indexed by attr_name_long", "\n", "self", ".", "attributes_long", "=", "attributes_long", "# i.e., attributes is indexed by attr_name_long", "\n", "\n", "attributes_kurz", "=", "dict", "(", "(", "attributes", "[", "key", "]", ".", "attr_name_kurz", ",", "value", ")", "for", "(", "key", ",", "value", ")", "in", "attributes_long", ".", "items", "(", ")", ")", "\n", "data_frame_kurz", "=", "copy", ".", "deepcopy", "(", "data_frame_long", ")", "\n", "data_frame_kurz", ".", "columns", "=", "self", ".", "getAllAttributeNames", "(", "'kurz'", ")", "\n", "self", ".", "data_frame_kurz", "=", "data_frame_kurz", "# i.e., data_frame is indexed by attr_name_kurz", "\n", "self", ".", "attributes_kurz", "=", "attributes_kurz", "# i.e., attributes is indexed by attr_name_kurz", "\n", "\n", "# assert that data_frame and attributes match on variable names (long)", "\n", "assert", "len", "(", "np", ".", "setdiff1d", "(", "\n", "data_frame", ".", "columns", ".", "values", ",", "\n", "np", ".", "array", "(", "self", ".", "getAllAttributeNames", "(", "'long'", ")", ")", "\n", ")", ")", "==", "0", "\n", "\n", "# assert attribute type matches what is in the data frame", "\n", "for", "attr_name", "in", "np", ".", "setdiff1d", "(", "\n", "self", ".", "getInputAttributeNames", "(", "'long'", ")", ",", "\n", "self", ".", "getRealBasedAttributeNames", "(", "'long'", ")", ",", "\n", ")", ":", "\n", "      ", "unique_values", "=", "np", ".", "unique", "(", "data_frame_long", "[", "attr_name", "]", ".", "to_numpy", "(", ")", ")", "\n", "# all non-numerical-real values should be integer or {0,1}", "\n", "for", "value", "in", "unique_values", ":", "\n", "        ", "assert", "value", "==", "np", ".", "floor", "(", "value", ")", "\n", "", "if", "is_one_hot", "and", "attributes_long", "[", "attr_name", "]", ".", "attr_type", "!=", "'numeric-int'", ":", "# binary, sub-categorical, sub-ordinal", "\n", "        ", "try", ":", "\n", "          ", "assert", "np", ".", "array_equal", "(", "unique_values", ",", "[", "0", ",", "1", "]", ")", "or", "np", ".", "array_equal", "(", "unique_values", ",", "[", "1", ",", "2", "]", ")", "or", "np", ".", "array_equal", "(", "unique_values", ",", "[", "1", "]", ")", "# the first sub-ordinal attribute is always 1", "\n", "# race (binary) in compass is encoded as {1,2}", "\n", "", "except", ":", "\n", "          ", "ipsh", "(", ")", "\n", "\n", "# # assert attributes and is_one_hot agree on one-hot-ness (i.e., if is_one_hot,", "\n", "# # then at least one attribute should be encoded as one-hot (w/ parent reference))", "\n", "# tmp_is_one_hot = False", "\n", "# for attr_name in attributes.keys():", "\n", "#   attr_obj = attributes[attr_name]", "\n", "#   # this simply checks to make sure that at least one elem is one-hot encoded", "\n", "#   if attr_obj.parent_name_long != -1 or attr_obj.parent_name_kurz != -1:", "\n", "#     tmp_is_one_hot = True", "\n", "# # TODO: assert only if there is a cat/ord variable!", "\n", "# assert is_one_hot == tmp_is_one_hot, \"Dataset object and actual attributes don't agree on one-hot\"", "\n", "\n", "", "", "", "self", ".", "assertSiblingsShareAttributes", "(", "'long'", ")", "\n", "self", ".", "assertSiblingsShareAttributes", "(", "'kurz'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getAttributeNames": [[144, 158], ["loadData.Dataset.attributes_long.keys", "numpy.array", "names.append", "names.append", "Exception"], "methods", ["None"], ["", "def", "getAttributeNames", "(", "self", ",", "allowed_node_types", ",", "long_or_kurz", "=", "'kurz'", ")", ":", "\n", "    ", "names", "=", "[", "]", "\n", "# We must loop through all attributes and check attr_name", "\n", "for", "attr_name", "in", "self", ".", "attributes_long", ".", "keys", "(", ")", ":", "\n", "      ", "attr_obj", "=", "self", ".", "attributes_long", "[", "attr_name", "]", "\n", "if", "attr_obj", ".", "node_type", "not", "in", "allowed_node_types", ":", "\n", "        ", "continue", "\n", "", "if", "long_or_kurz", "==", "'long'", ":", "\n", "        ", "names", ".", "append", "(", "attr_obj", ".", "attr_name_long", ")", "\n", "", "elif", "long_or_kurz", "==", "'kurz'", ":", "\n", "        ", "names", ".", "append", "(", "attr_obj", ".", "attr_name_kurz", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "f'{long_or_kurz} not recognized as a valid `long_or_kurz`.'", ")", "\n", "", "", "return", "np", ".", "array", "(", "names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getAllAttributeNames": [[159, 161], ["loadData.Dataset.getAttributeNames"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getAttributeNames"], ["", "def", "getAllAttributeNames", "(", "self", ",", "long_or_kurz", "=", "'kurz'", ")", ":", "\n", "    ", "return", "self", ".", "getAttributeNames", "(", "{", "'meta'", ",", "'input'", ",", "'output'", "}", ",", "long_or_kurz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputOutputAttributeNames": [[162, 164], ["loadData.Dataset.getAttributeNames"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getAttributeNames"], ["", "def", "getInputOutputAttributeNames", "(", "self", ",", "long_or_kurz", "=", "'kurz'", ")", ":", "\n", "    ", "return", "self", ".", "getAttributeNames", "(", "{", "'input'", ",", "'output'", "}", ",", "long_or_kurz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getMetaInputAttributeNames": [[165, 167], ["loadData.Dataset.getAttributeNames"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getAttributeNames"], ["", "def", "getMetaInputAttributeNames", "(", "self", ",", "long_or_kurz", "=", "'kurz'", ")", ":", "\n", "    ", "return", "self", ".", "getAttributeNames", "(", "{", "'meta'", ",", "'input'", "}", ",", "long_or_kurz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getMetaAttributeNames": [[168, 170], ["loadData.Dataset.getAttributeNames"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getAttributeNames"], ["", "def", "getMetaAttributeNames", "(", "self", ",", "long_or_kurz", "=", "'kurz'", ")", ":", "\n", "    ", "return", "self", ".", "getAttributeNames", "(", "{", "'meta'", "}", ",", "long_or_kurz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames": [[171, 173], ["loadData.Dataset.getAttributeNames"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getAttributeNames"], ["", "def", "getInputAttributeNames", "(", "self", ",", "long_or_kurz", "=", "'kurz'", ")", ":", "\n", "    ", "return", "self", ".", "getAttributeNames", "(", "{", "'input'", "}", ",", "long_or_kurz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getOutputAttributeNames": [[174, 176], ["loadData.Dataset.getAttributeNames"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getAttributeNames"], ["", "def", "getOutputAttributeNames", "(", "self", ",", "long_or_kurz", "=", "'kurz'", ")", ":", "\n", "    ", "return", "self", ".", "getAttributeNames", "(", "{", "'output'", "}", ",", "long_or_kurz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getBinaryAttributeNames": [[177, 190], ["loadData.Dataset.getInputAttributeNames", "numpy.array", "names.append", "names.append", "Exception"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames"], ["", "def", "getBinaryAttributeNames", "(", "self", ",", "long_or_kurz", "=", "'kurz'", ")", ":", "\n", "    ", "names", "=", "[", "]", "\n", "# We must loop through all attributes and check binary", "\n", "for", "attr_name_long", "in", "self", ".", "getInputAttributeNames", "(", "'long'", ")", ":", "\n", "      ", "attr_obj", "=", "self", ".", "attributes_long", "[", "attr_name_long", "]", "\n", "if", "attr_obj", ".", "node_type", "==", "'input'", "and", "attr_obj", ".", "attr_type", "==", "'binary'", ":", "\n", "        ", "if", "long_or_kurz", "==", "'long'", ":", "\n", "          ", "names", ".", "append", "(", "attr_obj", ".", "attr_name_long", ")", "\n", "", "elif", "long_or_kurz", "==", "'kurz'", ":", "\n", "          ", "names", ".", "append", "(", "attr_obj", ".", "attr_name_kurz", ")", "\n", "", "else", ":", "\n", "          ", "raise", "Exception", "(", "f'{long_or_kurz} not recognized as a valid `long_or_kurz`.'", ")", "\n", "", "", "", "return", "np", ".", "array", "(", "names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getActionableAttributeNames": [[191, 204], ["loadData.Dataset.getInputAttributeNames", "numpy.array", "names.append", "names.append", "Exception"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames"], ["", "def", "getActionableAttributeNames", "(", "self", ",", "long_or_kurz", "=", "'kurz'", ")", ":", "\n", "    ", "names", "=", "[", "]", "\n", "# We must loop through all attributes and check actionability", "\n", "for", "attr_name_long", "in", "self", ".", "getInputAttributeNames", "(", "'long'", ")", ":", "\n", "      ", "attr_obj", "=", "self", ".", "attributes_long", "[", "attr_name_long", "]", "\n", "if", "attr_obj", ".", "node_type", "==", "'input'", "and", "attr_obj", ".", "actionability", "!=", "'none'", ":", "\n", "        ", "if", "long_or_kurz", "==", "'long'", ":", "\n", "          ", "names", ".", "append", "(", "attr_obj", ".", "attr_name_long", ")", "\n", "", "elif", "long_or_kurz", "==", "'kurz'", ":", "\n", "          ", "names", ".", "append", "(", "attr_obj", ".", "attr_name_kurz", ")", "\n", "", "else", ":", "\n", "          ", "raise", "Exception", "(", "f'{long_or_kurz} not recognized as a valid `long_or_kurz`.'", ")", "\n", "", "", "", "return", "np", ".", "array", "(", "names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getNonActionableAttributeNames": [[205, 209], ["loadData.Dataset.getInputAttributeNames", "loadData.Dataset.getActionableAttributeNames", "numpy.setdiff1d"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getActionableAttributeNames"], ["", "def", "getNonActionableAttributeNames", "(", "self", ",", "long_or_kurz", "=", "'kurz'", ")", ":", "\n", "    ", "a", "=", "self", ".", "getInputAttributeNames", "(", "long_or_kurz", ")", "\n", "b", "=", "self", ".", "getActionableAttributeNames", "(", "long_or_kurz", ")", "\n", "return", "np", ".", "setdiff1d", "(", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getMutableAttributeNames": [[210, 223], ["loadData.Dataset.getInputAttributeNames", "numpy.array", "names.append", "names.append", "Exception"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames"], ["", "def", "getMutableAttributeNames", "(", "self", ",", "long_or_kurz", "=", "'kurz'", ")", ":", "\n", "    ", "names", "=", "[", "]", "\n", "# We must loop through all attributes and check mutability", "\n", "for", "attr_name_long", "in", "self", ".", "getInputAttributeNames", "(", "'long'", ")", ":", "\n", "      ", "attr_obj", "=", "self", ".", "attributes_long", "[", "attr_name_long", "]", "\n", "if", "attr_obj", ".", "node_type", "==", "'input'", "and", "attr_obj", ".", "mutability", "!=", "False", ":", "\n", "        ", "if", "long_or_kurz", "==", "'long'", ":", "\n", "          ", "names", ".", "append", "(", "attr_obj", ".", "attr_name_long", ")", "\n", "", "elif", "long_or_kurz", "==", "'kurz'", ":", "\n", "          ", "names", ".", "append", "(", "attr_obj", ".", "attr_name_kurz", ")", "\n", "", "else", ":", "\n", "          ", "raise", "Exception", "(", "f'{long_or_kurz} not recognized as a valid `long_or_kurz`.'", ")", "\n", "", "", "", "return", "np", ".", "array", "(", "names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getNonMutableAttributeNames": [[224, 228], ["loadData.Dataset.getInputAttributeNames", "loadData.Dataset.getMutableAttributeNames", "numpy.setdiff1d"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getMutableAttributeNames"], ["", "def", "getNonMutableAttributeNames", "(", "self", ",", "long_or_kurz", "=", "'kurz'", ")", ":", "\n", "    ", "a", "=", "self", ".", "getInputAttributeNames", "(", "long_or_kurz", ")", "\n", "b", "=", "self", ".", "getMutableAttributeNames", "(", "long_or_kurz", ")", "\n", "return", "np", ".", "setdiff1d", "(", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getIntegerBasedAttributeNames": [[229, 242], ["loadData.Dataset.getInputAttributeNames", "numpy.array", "names.append", "names.append", "Exception"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames"], ["", "def", "getIntegerBasedAttributeNames", "(", "self", ",", "long_or_kurz", "=", "'kurz'", ")", ":", "\n", "    ", "names", "=", "[", "]", "\n", "# We must loop through all attributes and check attr_type", "\n", "for", "attr_name_long", "in", "self", ".", "getInputAttributeNames", "(", "'long'", ")", ":", "\n", "      ", "attr_obj", "=", "self", ".", "attributes_long", "[", "attr_name_long", "]", "\n", "if", "attr_obj", ".", "attr_type", "==", "'numeric-int'", ":", "\n", "        ", "if", "long_or_kurz", "==", "'long'", ":", "\n", "          ", "names", ".", "append", "(", "attr_obj", ".", "attr_name_long", ")", "\n", "", "elif", "long_or_kurz", "==", "'kurz'", ":", "\n", "          ", "names", ".", "append", "(", "attr_obj", ".", "attr_name_kurz", ")", "\n", "", "else", ":", "\n", "          ", "raise", "Exception", "(", "f'{long_or_kurz} not recognized as a valid `long_or_kurz`.'", ")", "\n", "", "", "", "return", "np", ".", "array", "(", "names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getRealBasedAttributeNames": [[243, 256], ["loadData.Dataset.getInputAttributeNames", "numpy.array", "names.append", "names.append", "Exception"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames"], ["", "def", "getRealBasedAttributeNames", "(", "self", ",", "long_or_kurz", "=", "'kurz'", ")", ":", "\n", "    ", "names", "=", "[", "]", "\n", "# We must loop through all attributes and check attr_type", "\n", "for", "attr_name_long", "in", "self", ".", "getInputAttributeNames", "(", "'long'", ")", ":", "\n", "      ", "attr_obj", "=", "self", ".", "attributes_long", "[", "attr_name_long", "]", "\n", "if", "attr_obj", ".", "attr_type", "==", "'numeric-real'", ":", "\n", "        ", "if", "long_or_kurz", "==", "'long'", ":", "\n", "          ", "names", ".", "append", "(", "attr_obj", ".", "attr_name_long", ")", "\n", "", "elif", "long_or_kurz", "==", "'kurz'", ":", "\n", "          ", "names", ".", "append", "(", "attr_obj", ".", "attr_name_kurz", ")", "\n", "", "else", ":", "\n", "          ", "raise", "Exception", "(", "f'{long_or_kurz} not recognized as a valid `long_or_kurz`.'", ")", "\n", "", "", "", "return", "np", ".", "array", "(", "names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.assertSiblingsShareAttributes": [[257, 280], ["loadData.Dataset.getDictOfSiblings", "dict_of_siblings[].keys", "len", "Exception"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getDictOfSiblings"], ["", "def", "assertSiblingsShareAttributes", "(", "self", ",", "long_or_kurz", "=", "'kurz'", ")", ":", "\n", "# assert elems of dictOfSiblings share attr_type, node_type, parent, actionability, and mutability", "\n", "    ", "dict_of_siblings", "=", "self", ".", "getDictOfSiblings", "(", "long_or_kurz", ")", "\n", "for", "parent_name", "in", "dict_of_siblings", "[", "'cat'", "]", ".", "keys", "(", ")", ":", "\n", "      ", "siblings", "=", "dict_of_siblings", "[", "'cat'", "]", "[", "parent_name", "]", "\n", "assert", "len", "(", "siblings", ")", ">", "1", "\n", "for", "sibling", "in", "siblings", ":", "\n", "        ", "if", "long_or_kurz", "==", "'long'", ":", "\n", "          ", "self", ".", "attributes_long", "[", "sibling", "]", ".", "attr_type", "=", "self", ".", "attributes_long", "[", "siblings", "[", "0", "]", "]", ".", "attr_type", "\n", "self", ".", "attributes_long", "[", "sibling", "]", ".", "node_type", "=", "self", ".", "attributes_long", "[", "siblings", "[", "0", "]", "]", ".", "node_type", "\n", "self", ".", "attributes_long", "[", "sibling", "]", ".", "actionability", "=", "self", ".", "attributes_long", "[", "siblings", "[", "0", "]", "]", ".", "actionability", "\n", "self", ".", "attributes_long", "[", "sibling", "]", ".", "mutability", "=", "self", ".", "attributes_long", "[", "siblings", "[", "0", "]", "]", ".", "mutability", "\n", "self", ".", "attributes_long", "[", "sibling", "]", ".", "parent_name_long", "=", "self", ".", "attributes_long", "[", "siblings", "[", "0", "]", "]", ".", "parent_name_long", "\n", "self", ".", "attributes_long", "[", "sibling", "]", ".", "parent_name_kurz", "=", "self", ".", "attributes_long", "[", "siblings", "[", "0", "]", "]", ".", "parent_name_kurz", "\n", "", "elif", "long_or_kurz", "==", "'kurz'", ":", "\n", "          ", "self", ".", "attributes_kurz", "[", "sibling", "]", ".", "attr_type", "=", "self", ".", "attributes_kurz", "[", "siblings", "[", "0", "]", "]", ".", "attr_type", "\n", "self", ".", "attributes_kurz", "[", "sibling", "]", ".", "node_type", "=", "self", ".", "attributes_kurz", "[", "siblings", "[", "0", "]", "]", ".", "node_type", "\n", "self", ".", "attributes_kurz", "[", "sibling", "]", ".", "actionability", "=", "self", ".", "attributes_kurz", "[", "siblings", "[", "0", "]", "]", ".", "actionability", "\n", "self", ".", "attributes_kurz", "[", "sibling", "]", ".", "mutability", "=", "self", ".", "attributes_kurz", "[", "siblings", "[", "0", "]", "]", ".", "mutability", "\n", "self", ".", "attributes_kurz", "[", "sibling", "]", ".", "parent_name_long", "=", "self", ".", "attributes_kurz", "[", "siblings", "[", "0", "]", "]", ".", "parent_name_long", "\n", "self", ".", "attributes_kurz", "[", "sibling", "]", ".", "parent_name_kurz", "=", "self", ".", "attributes_kurz", "[", "siblings", "[", "0", "]", "]", ".", "parent_name_kurz", "\n", "", "else", ":", "\n", "          ", "raise", "Exception", "(", "f'{long_or_kurz} not recognized as a valid `long_or_kurz`.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getSiblingsFor": [[281, 311], ["loadData.Dataset.getInputOutputAttributeNames", "loadData.Dataset.getDictOfSiblings", "loadData.Dataset.getInputOutputAttributeNames", "loadData.Dataset.getDictOfSiblings", "Exception"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputOutputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getDictOfSiblings", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputOutputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getDictOfSiblings"], ["", "", "", "", "def", "getSiblingsFor", "(", "self", ",", "attr_name_long_or_kurz", ")", ":", "\n", "# If attr_name_long is given, we will return siblings_long (the same length)", "\n", "# but not siblings_kurz. Same for the opposite direction.", "\n", "    ", "assert", "'cat'", "in", "attr_name_long_or_kurz", "or", "'ord'", "in", "attr_name_long_or_kurz", ",", "'attr_name must include either `cat` or `ord`.'", "\n", "if", "attr_name_long_or_kurz", "in", "self", ".", "getInputOutputAttributeNames", "(", "'long'", ")", ":", "\n", "      ", "attr_name_long", "=", "attr_name_long_or_kurz", "\n", "dict_of_siblings_long", "=", "self", ".", "getDictOfSiblings", "(", "'long'", ")", "\n", "for", "parent_name_long", "in", "dict_of_siblings_long", "[", "'cat'", "]", ":", "\n", "        ", "siblings_long", "=", "dict_of_siblings_long", "[", "'cat'", "]", "[", "parent_name_long", "]", "\n", "if", "attr_name_long_or_kurz", "in", "siblings_long", ":", "\n", "          ", "return", "siblings_long", "\n", "", "", "for", "parent_name_long", "in", "dict_of_siblings_long", "[", "'ord'", "]", ":", "\n", "        ", "siblings_long", "=", "dict_of_siblings_long", "[", "'ord'", "]", "[", "parent_name_long", "]", "\n", "if", "attr_name_long_or_kurz", "in", "siblings_long", ":", "\n", "          ", "return", "siblings_long", "\n", "", "", "", "elif", "attr_name_long_or_kurz", "in", "self", ".", "getInputOutputAttributeNames", "(", "'kurz'", ")", ":", "\n", "      ", "attr_name_kurz", "=", "attr_name_long_or_kurz", "\n", "dict_of_siblings_kurz", "=", "self", ".", "getDictOfSiblings", "(", "'kurz'", ")", "\n", "for", "parent_name_kurz", "in", "dict_of_siblings_kurz", "[", "'cat'", "]", ":", "\n", "        ", "siblings_kurz", "=", "dict_of_siblings_kurz", "[", "'cat'", "]", "[", "parent_name_kurz", "]", "\n", "if", "attr_name_long_or_kurz", "in", "siblings_kurz", ":", "\n", "          ", "return", "siblings_kurz", "\n", "", "", "for", "parent_name_kurz", "in", "dict_of_siblings_kurz", "[", "'ord'", "]", ":", "\n", "        ", "siblings_kurz", "=", "dict_of_siblings_kurz", "[", "'ord'", "]", "[", "parent_name_kurz", "]", "\n", "if", "attr_name_long_or_kurz", "in", "siblings_kurz", ":", "\n", "          ", "return", "siblings_kurz", "\n", "", "", "", "else", ":", "\n", "      ", "raise", "Exception", "(", "f'{attr_name_long_or_kurz} not recognized as a valid `attr_name_long_or_kurz`.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getDictOfSiblings": [[312, 368], ["loadData.Dataset.getInputAttributeNames", "dict_of_siblings_long[].keys", "dict_of_siblings_long[].keys", "sorted", "sorted", "loadData.Dataset.getInputAttributeNames", "dict_of_siblings_kurz[].keys", "dict_of_siblings_kurz[].keys", "Exception", "[].append", "sorted", "sorted", "dict_of_siblings_long[].keys", "[].append", "[].append", "dict_of_siblings_long[].keys", "int", "int", "dict_of_siblings_kurz[].keys", "[].append", "dict_of_siblings_kurz[].keys", "int", "int", "x.split", "x.split", "x.split", "x.split"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames"], ["", "", "def", "getDictOfSiblings", "(", "self", ",", "long_or_kurz", "=", "'kurz'", ")", ":", "\n", "    ", "if", "long_or_kurz", "==", "'long'", ":", "\n", "\n", "      ", "dict_of_siblings_long", "=", "{", "}", "\n", "dict_of_siblings_long", "[", "'cat'", "]", "=", "{", "}", "\n", "dict_of_siblings_long", "[", "'ord'", "]", "=", "{", "}", "\n", "\n", "for", "attr_name_long", "in", "self", ".", "getInputAttributeNames", "(", "'long'", ")", ":", "\n", "        ", "attr_obj", "=", "self", ".", "attributes_long", "[", "attr_name_long", "]", "\n", "if", "attr_obj", ".", "attr_type", "==", "'sub-categorical'", ":", "\n", "          ", "if", "attr_obj", ".", "parent_name_long", "not", "in", "dict_of_siblings_long", "[", "'cat'", "]", ".", "keys", "(", ")", ":", "\n", "            ", "dict_of_siblings_long", "[", "'cat'", "]", "[", "attr_obj", ".", "parent_name_long", "]", "=", "[", "]", "# initiate key-value pair", "\n", "", "dict_of_siblings_long", "[", "'cat'", "]", "[", "attr_obj", ".", "parent_name_long", "]", ".", "append", "(", "attr_obj", ".", "attr_name_long", ")", "\n", "", "elif", "attr_obj", ".", "attr_type", "==", "'sub-ordinal'", ":", "\n", "          ", "if", "attr_obj", ".", "parent_name_long", "not", "in", "dict_of_siblings_long", "[", "'ord'", "]", ".", "keys", "(", ")", ":", "\n", "            ", "dict_of_siblings_long", "[", "'ord'", "]", "[", "attr_obj", ".", "parent_name_long", "]", "=", "[", "]", "# initiate key-value pair", "\n", "", "dict_of_siblings_long", "[", "'ord'", "]", "[", "attr_obj", ".", "parent_name_long", "]", ".", "append", "(", "attr_obj", ".", "attr_name_long", ")", "\n", "\n", "# sort sub-arrays", "\n", "", "", "for", "key", "in", "dict_of_siblings_long", "[", "'cat'", "]", ".", "keys", "(", ")", ":", "\n", "        ", "dict_of_siblings_long", "[", "'cat'", "]", "[", "key", "]", "=", "sorted", "(", "dict_of_siblings_long", "[", "'cat'", "]", "[", "key", "]", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", ")", "\n", "\n", "", "for", "key", "in", "dict_of_siblings_long", "[", "'ord'", "]", ".", "keys", "(", ")", ":", "\n", "        ", "dict_of_siblings_long", "[", "'ord'", "]", "[", "key", "]", "=", "sorted", "(", "dict_of_siblings_long", "[", "'ord'", "]", "[", "key", "]", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", ")", "\n", "\n", "", "return", "dict_of_siblings_long", "\n", "\n", "", "elif", "long_or_kurz", "==", "'kurz'", ":", "\n", "\n", "      ", "dict_of_siblings_kurz", "=", "{", "}", "\n", "dict_of_siblings_kurz", "[", "'cat'", "]", "=", "{", "}", "\n", "dict_of_siblings_kurz", "[", "'ord'", "]", "=", "{", "}", "\n", "\n", "for", "attr_name_kurz", "in", "self", ".", "getInputAttributeNames", "(", "'kurz'", ")", ":", "\n", "        ", "attr_obj", "=", "self", ".", "attributes_kurz", "[", "attr_name_kurz", "]", "\n", "if", "attr_obj", ".", "attr_type", "==", "'sub-categorical'", ":", "\n", "          ", "if", "attr_obj", ".", "parent_name_kurz", "not", "in", "dict_of_siblings_kurz", "[", "'cat'", "]", ".", "keys", "(", ")", ":", "\n", "            ", "dict_of_siblings_kurz", "[", "'cat'", "]", "[", "attr_obj", ".", "parent_name_kurz", "]", "=", "[", "]", "# initiate key-value pair", "\n", "", "dict_of_siblings_kurz", "[", "'cat'", "]", "[", "attr_obj", ".", "parent_name_kurz", "]", ".", "append", "(", "attr_obj", ".", "attr_name_kurz", ")", "\n", "", "elif", "attr_obj", ".", "attr_type", "==", "'sub-ordinal'", ":", "\n", "          ", "if", "attr_obj", ".", "parent_name_kurz", "not", "in", "dict_of_siblings_kurz", "[", "'ord'", "]", ".", "keys", "(", ")", ":", "\n", "            ", "dict_of_siblings_kurz", "[", "'ord'", "]", "[", "attr_obj", ".", "parent_name_kurz", "]", "=", "[", "]", "# initiate key-value pair", "\n", "", "dict_of_siblings_kurz", "[", "'ord'", "]", "[", "attr_obj", ".", "parent_name_kurz", "]", ".", "append", "(", "attr_obj", ".", "attr_name_kurz", ")", "\n", "\n", "# sort sub-arrays", "\n", "", "", "for", "key", "in", "dict_of_siblings_kurz", "[", "'cat'", "]", ".", "keys", "(", ")", ":", "\n", "        ", "dict_of_siblings_kurz", "[", "'cat'", "]", "[", "key", "]", "=", "sorted", "(", "dict_of_siblings_kurz", "[", "'cat'", "]", "[", "key", "]", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", ")", "\n", "\n", "", "for", "key", "in", "dict_of_siblings_kurz", "[", "'ord'", "]", ".", "keys", "(", ")", ":", "\n", "        ", "dict_of_siblings_kurz", "[", "'ord'", "]", "[", "key", "]", "=", "sorted", "(", "dict_of_siblings_kurz", "[", "'ord'", "]", "[", "key", "]", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", ")", "\n", "\n", "", "return", "dict_of_siblings_kurz", "\n", "\n", "", "else", ":", "\n", "\n", "      ", "raise", "Exception", "(", "f'{long_or_kurz} not recognized as a valid `long_or_kurz`.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getOneHotAttributesNames": [[369, 376], ["loadData.Dataset.getDictOfSiblings", "loadData.Dataset.keys", "numpy.array", "tmp[].keys", "names.extend"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getDictOfSiblings"], ["", "", "def", "getOneHotAttributesNames", "(", "self", ",", "long_or_kurz", "=", "'kurz'", ")", ":", "\n", "    ", "tmp", "=", "self", ".", "getDictOfSiblings", "(", "long_or_kurz", ")", "\n", "names", "=", "[", "]", "\n", "for", "key1", "in", "tmp", ".", "keys", "(", ")", ":", "\n", "      ", "for", "key2", "in", "tmp", "[", "key1", "]", ".", "keys", "(", ")", ":", "\n", "        ", "names", ".", "extend", "(", "tmp", "[", "key1", "]", "[", "key2", "]", ")", "\n", "", "", "return", "np", ".", "array", "(", "names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getNonHotAttributesNames": [[377, 381], ["loadData.Dataset.getInputAttributeNames", "loadData.Dataset.getOneHotAttributesNames", "numpy.setdiff1d"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getOneHotAttributesNames"], ["", "def", "getNonHotAttributesNames", "(", "self", ",", "long_or_kurz", "=", "'kurz'", ")", ":", "\n", "    ", "a", "=", "self", ".", "getInputAttributeNames", "(", "long_or_kurz", ")", "\n", "b", "=", "self", ".", "getOneHotAttributesNames", "(", "long_or_kurz", ")", "\n", "return", "np", ".", "setdiff1d", "(", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getVariableRanges": [[382, 389], ["dict", "zip", "loadData.Dataset.getInputAttributeNames", "loadData.Dataset.getInputAttributeNames"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames"], ["", "def", "getVariableRanges", "(", "self", ")", ":", "\n", "    ", "return", "dict", "(", "zip", "(", "\n", "self", ".", "getInputAttributeNames", "(", "'kurz'", ")", ",", "\n", "[", "\n", "self", ".", "attributes_kurz", "[", "attr_name_kurz", "]", ".", "upper_bound", "-", "\n", "self", ".", "attributes_kurz", "[", "attr_name_kurz", "]", ".", "lower_bound", "\n", "for", "attr_name_kurz", "in", "self", ".", "getInputAttributeNames", "(", "'kurz'", ")", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.printDataset": [[392, 401], ["print", "Exception", "print"], "methods", ["None"], ["", "def", "printDataset", "(", "self", ",", "long_or_kurz", "=", "'kurz'", ")", ":", "\n", "    ", "if", "long_or_kurz", "==", "'long'", ":", "\n", "      ", "for", "attr_name_long", "in", "self", ".", "attributes_long", ":", "\n", "        ", "print", "(", "self", ".", "attributes_long", "[", "attr_name_long", "]", ".", "__dict__", ")", "\n", "", "", "elif", "long_or_kurz", "==", "'kurz'", ":", "\n", "      ", "for", "attr_name_kurz", "in", "self", ".", "attributes_kurz", ":", "\n", "        ", "print", "(", "self", ".", "attributes_kurz", "[", "attr_name_kurz", "]", ".", "__dict__", ")", "\n", "", "", "else", ":", "\n", "      ", "raise", "Exception", "(", "f'{long_or_kurz} not recognized as a valid `long_or_kurz`.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getBalancedDataFrame": [[402, 428], ["copy.deepcopy", "loadData.Dataset.getMetaAttributeNames", "loadData.Dataset.getInputAttributeNames", "numpy.array_equal", "balanced_data_frame[].value_counts", "pandas.concat().sample", "loadData.Dataset.getOutputAttributeNames", "numpy.unique", "numpy.array", "balanced_data_frame[].value_counts.min", "pandas.concat", "balanced_data_frame[].sample", "balanced_data_frame[].sample"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getMetaAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getOutputAttributeNames"], ["", "", "def", "getBalancedDataFrame", "(", "self", ")", ":", "\n", "    ", "balanced_data_frame", "=", "copy", ".", "deepcopy", "(", "self", ".", "data_frame_kurz", ")", "\n", "\n", "meta_cols", "=", "self", ".", "getMetaAttributeNames", "(", ")", "\n", "input_cols", "=", "self", ".", "getInputAttributeNames", "(", ")", "\n", "output_col", "=", "self", ".", "getOutputAttributeNames", "(", ")", "[", "0", "]", "\n", "\n", "# assert only two classes in label (maybe relax later??)", "\n", "assert", "np", ".", "array_equal", "(", "\n", "np", ".", "unique", "(", "balanced_data_frame", "[", "output_col", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "0", ",", "1", "]", ")", "# only allowing {0, 1} labels", "\n", ")", "\n", "\n", "# get balanced dataframe (take minimum of the count, then round down to nearest 250)", "\n", "unique_values_and_count", "=", "balanced_data_frame", "[", "output_col", "]", ".", "value_counts", "(", ")", "\n", "number_of_subsamples_in_each_class", "=", "unique_values_and_count", ".", "min", "(", ")", "//", "250", "*", "250", "\n", "balanced_data_frame", "=", "pd", ".", "concat", "(", "[", "\n", "balanced_data_frame", "[", "balanced_data_frame", ".", "loc", "[", ":", ",", "output_col", "]", "==", "0", "]", ".", "sample", "(", "number_of_subsamples_in_each_class", ",", "random_state", "=", "RANDOM_SEED", ")", ",", "\n", "balanced_data_frame", "[", "balanced_data_frame", ".", "loc", "[", ":", ",", "output_col", "]", "==", "1", "]", ".", "sample", "(", "number_of_subsamples_in_each_class", ",", "random_state", "=", "RANDOM_SEED", ")", ",", "\n", "]", ")", ".", "sample", "(", "frac", "=", "1", ",", "random_state", "=", "RANDOM_SEED", ")", "\n", "# balanced_data_frame = pd.concat([", "\n", "#     balanced_data_frame[balanced_data_frame.loc[:,output_col] == 0],", "\n", "#     balanced_data_frame[balanced_data_frame.loc[:,output_col] == 1],", "\n", "# ]).sample(frac = 1, random_state = RANDOM_SEED)", "\n", "\n", "return", "balanced_data_frame", ",", "meta_cols", ",", "input_cols", ",", "output_col", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getTrainTestSplit": [[432, 513], ["loadData.Dataset.getBalancedDataFrame", "loadData.Dataset.getNonHotAttributesNames", "loadData.Dataset.getNonHotAttributesNames", "loadData.Dataset.getTrainTestSplit.setBoundsToZeroOne"], "methods", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getBalancedDataFrame", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getNonHotAttributesNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getNonHotAttributesNames"], ["", "def", "getTrainTestSplit", "(", "self", ",", "preprocessing", "=", "None", ",", "with_meta", "=", "False", ")", ":", "\n", "\n", "# When working only with normalized data in [0, 1], data ranges must change to [0, 1] as well", "\n", "# otherwise, in computing normalized distance we will normalize with intial ranges again!", "\n", "# pseudonym (2020.05.17) does this work with cat/ord and sub-cat/sub-ord data???", "\n", "    ", "def", "setBoundsToZeroOne", "(", ")", ":", "\n", "      ", "for", "attr_name_kurz", "in", "self", ".", "getNonHotAttributesNames", "(", "'kurz'", ")", ":", "\n", "        ", "attr_obj", "=", "self", ".", "attributes_kurz", "[", "attr_name_kurz", "]", "\n", "attr_obj", ".", "lower_bound", "=", "0.0", "\n", "attr_obj", ".", "upper_bound", "=", "1.0", "\n", "\n", "attr_obj", "=", "self", ".", "attributes_long", "[", "attr_obj", ".", "attr_name_long", "]", "\n", "attr_obj", ".", "lower_bound", "=", "0.0", "\n", "attr_obj", ".", "upper_bound", "=", "1.0", "\n", "\n", "# Normalize data: bring everything to [0, 1] - implemented for when feeding the model to DiCE", "\n", "", "", "def", "normalizeData", "(", "X_train", ",", "X_test", ")", ":", "\n", "      ", "for", "attr_name_kurz", "in", "self", ".", "getNonHotAttributesNames", "(", "'kurz'", ")", ":", "\n", "        ", "attr_obj", "=", "self", ".", "attributes_kurz", "[", "attr_name_kurz", "]", "\n", "lower_bound", "=", "attr_obj", ".", "lower_bound", "\n", "upper_bound", "=", "attr_obj", ".", "upper_bound", "\n", "X_train", "[", "attr_name_kurz", "]", "=", "(", "X_train", "[", "attr_name_kurz", "]", "-", "lower_bound", ")", "/", "(", "upper_bound", "-", "lower_bound", ")", "\n", "X_test", "[", "attr_name_kurz", "]", "=", "(", "X_test", "[", "attr_name_kurz", "]", "-", "lower_bound", ")", "/", "(", "upper_bound", "-", "lower_bound", ")", "\n", "\n", "", "setBoundsToZeroOne", "(", ")", "\n", "\n", "return", "X_train", ",", "X_test", "\n", "\n", "# TODO: This should be used with caution... it messes things up in MACE as ranges", "\n", "# will differ between factual and counterfactual domains", "\n", "", "def", "standardizeData", "(", "X_train", ",", "X_test", ")", ":", "\n", "      ", "x_mean", "=", "X_train", ".", "mean", "(", ")", "\n", "x_std", "=", "X_train", ".", "std", "(", ")", "\n", "for", "index", "in", "x_std", ".", "index", ":", "\n", "        ", "if", "'_ord_'", "in", "index", "or", "'_cat_'", "in", "index", ":", "\n", "          ", "x_mean", "[", "index", "]", "=", "0", "\n", "x_std", "[", "index", "]", "=", "1", "\n", "", "", "X_train", "=", "(", "X_train", "-", "x_mean", ")", "/", "x_std", "\n", "X_test", "=", "(", "X_test", "-", "x_mean", ")", "/", "x_std", "\n", "return", "X_train", ",", "X_test", "\n", "\n", "", "balanced_data_frame", ",", "meta_cols", ",", "input_cols", ",", "output_col", "=", "self", ".", "getBalancedDataFrame", "(", ")", "\n", "\n", "if", "with_meta", ":", "\n", "      ", "all_data", "=", "balanced_data_frame", ".", "loc", "[", ":", ",", "np", ".", "array", "(", "(", "input_cols", ",", "meta_cols", ")", ")", ".", "flatten", "(", ")", "]", "\n", "all_true_labels", "=", "balanced_data_frame", ".", "loc", "[", ":", ",", "output_col", "]", "\n", "if", "preprocessing", "is", "not", "None", ":", "\n", "        ", "assert", "with_meta", "==", "False", ",", "'This feature is not built yet...'", "\n", "\n", "", "X_train", ",", "X_test", ",", "y_train", ",", "y_test", "=", "train_test_split", "(", "\n", "all_data", ",", "\n", "all_true_labels", ",", "\n", "train_size", "=", ".7", ",", "\n", "random_state", "=", "RANDOM_SEED", ")", "\n", "\n", "# ordering of next two lines matters (shouldn't overwrite input_cols); silly code... :|", "\n", "U_train", "=", "X_train", "[", "self", ".", "getMetaAttributeNames", "(", ")", "]", "\n", "U_test", "=", "X_test", "[", "self", ".", "getMetaAttributeNames", "(", ")", "]", "\n", "X_train", "=", "X_train", "[", "self", ".", "getInputAttributeNames", "(", ")", "]", "\n", "X_test", "=", "X_test", "[", "self", ".", "getInputAttributeNames", "(", ")", "]", "\n", "y_train", "=", "y_train", "# noop", "\n", "y_test", "=", "y_test", "# noop", "\n", "\n", "return", "X_train", ",", "X_test", ",", "U_train", ",", "U_test", ",", "y_train", ",", "y_test", "\n", "", "else", ":", "\n", "      ", "all_data", "=", "balanced_data_frame", ".", "loc", "[", ":", ",", "input_cols", "]", "\n", "all_true_labels", "=", "balanced_data_frame", ".", "loc", "[", ":", ",", "output_col", "]", "\n", "\n", "X_train", ",", "X_test", ",", "y_train", ",", "y_test", "=", "train_test_split", "(", "\n", "all_data", ",", "\n", "all_true_labels", ",", "\n", "train_size", "=", ".7", ",", "\n", "random_state", "=", "RANDOM_SEED", ")", "\n", "\n", "# TODO (2020.05.18): this should be updated so as NOT to update meta variables", "\n", "if", "preprocessing", "==", "'standardize'", ":", "\n", "        ", "X_train", ",", "X_test", "=", "standardizeData", "(", "X_train", ",", "X_test", ")", "\n", "", "elif", "preprocessing", "==", "'normalize'", ":", "\n", "        ", "X_train", ",", "X_test", "=", "normalizeData", "(", "X_train", ",", "X_test", ")", "\n", "\n", "", "return", "X_train", ",", "X_test", ",", "y_train", ",", "y_test", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.DatasetAttribute.__init__": [[517, 593], ["Exception", "Exception", "Exception", "Exception", "Exception"], "methods", ["None"], ["  ", "def", "__init__", "(", "\n", "self", ",", "\n", "attr_name_long", ",", "\n", "attr_name_kurz", ",", "\n", "attr_type", ",", "\n", "node_type", ",", "\n", "actionability", ",", "\n", "mutability", ",", "\n", "parent_name_long", ",", "\n", "parent_name_kurz", ",", "\n", "lower_bound", ",", "\n", "upper_bound", ")", ":", "\n", "\n", "    ", "if", "attr_type", "not", "in", "VALID_ATTRIBUTE_DATA_TYPES", ":", "\n", "      ", "raise", "Exception", "(", "\"`attr_type` must be one of %r.\"", "%", "VALID_ATTRIBUTE_DATA_TYPES", ")", "\n", "\n", "", "if", "node_type", "not", "in", "VALID_ATTRIBUTE_NODE_TYPES", ":", "\n", "      ", "raise", "Exception", "(", "\"`node_type` must be one of %r.\"", "%", "VALID_ATTRIBUTE_NODE_TYPES", ")", "\n", "\n", "", "if", "actionability", "not", "in", "VALID_ACTIONABILITY_TYPES", ":", "\n", "      ", "raise", "Exception", "(", "\"`actionability` must be one of %r.\"", "%", "VALID_ACTIONABILITY_TYPES", ")", "\n", "\n", "", "if", "mutability", "not", "in", "VALID_MUTABILITY_TYPES", ":", "\n", "      ", "raise", "Exception", "(", "\"`mutability` must be one of %r.\"", "%", "VALID_MUTABILITY_TYPES", ")", "\n", "\n", "", "if", "lower_bound", ">", "upper_bound", ":", "\n", "      ", "raise", "Exception", "(", "\"`lower_bound` must be <= `upper_bound`\"", ")", "\n", "\n", "", "if", "attr_type", "in", "{", "'sub-categorical'", ",", "'sub-ordinal'", "}", ":", "\n", "      ", "assert", "parent_name_long", "!=", "-", "1", ",", "'Parent ID set for non-hot attribute.'", "\n", "assert", "parent_name_kurz", "!=", "-", "1", ",", "'Parent ID set for non-hot attribute.'", "\n", "if", "attr_type", "==", "'sub-categorical'", ":", "\n", "        ", "assert", "lower_bound", "==", "0", "\n", "assert", "upper_bound", "==", "1", "\n", "", "if", "attr_type", "==", "'sub-ordinal'", ":", "\n", "# the first elem in thermometer is always on, but the rest may be on or off", "\n", "        ", "assert", "lower_bound", "==", "0", "or", "lower_bound", "==", "1", "\n", "assert", "upper_bound", "==", "1", "\n", "", "", "else", ":", "\n", "      ", "assert", "parent_name_long", "==", "-", "1", ",", "'Parent ID set for non-hot attribute.'", "\n", "assert", "parent_name_kurz", "==", "-", "1", ",", "'Parent ID set for non-hot attribute.'", "\n", "\n", "", "if", "attr_type", "in", "{", "'categorical'", ",", "'ordinal'", "}", ":", "\n", "      ", "assert", "lower_bound", "==", "1", "# setOneHotValue & setThermoValue assume this in their logic", "\n", "\n", "", "if", "attr_type", "in", "{", "'binary'", ",", "'categorical'", ",", "'sub-categorical'", "}", ":", "# not 'ordinal' or 'sub-ordinal'", "\n", "# IMPORTANT: surprisingly, it is OK if all sub-ordinal variables share actionability", "\n", "#            think about it, if each sub- variable is same-or-increase, along with", "\n", "#            the constraints that x0_ord_1 >= x0_ord_2, all variables can only stay", "\n", "#            the same or increase. It works :)", "\n", "      ", "assert", "actionability", "in", "{", "'none'", ",", "'any'", "}", ",", "f\"{attr_type}'s actionability can only be in {'none', 'any'}, not `{actionability}`.\"", "\n", "\n", "", "if", "node_type", "!=", "'input'", ":", "\n", "      ", "assert", "actionability", "==", "'none'", ",", "f'{node_type} attribute is not actionable.'", "\n", "assert", "mutability", "==", "False", ",", "f'{node_type} attribute is not mutable.'", "\n", "\n", "# We have introduced 3 types of variables: (actionable and mutable, non-actionable but mutable, immutable and non-actionable)", "\n", "", "if", "actionability", "!=", "'none'", ":", "\n", "      ", "assert", "mutability", "==", "True", "\n", "# TODO: above/below seem contradictory... (2020.04.14)", "\n", "", "if", "mutability", "==", "False", ":", "\n", "      ", "assert", "actionability", "==", "'none'", "\n", "\n", "", "if", "parent_name_long", "==", "-", "1", "or", "parent_name_kurz", "==", "-", "1", ":", "\n", "      ", "assert", "parent_name_long", "==", "parent_name_kurz", "==", "-", "1", "\n", "\n", "", "self", ".", "attr_name_long", "=", "attr_name_long", "\n", "self", ".", "attr_name_kurz", "=", "attr_name_kurz", "\n", "self", ".", "attr_type", "=", "attr_type", "\n", "self", ".", "node_type", "=", "node_type", "\n", "self", ".", "actionability", "=", "actionability", "\n", "self", ".", "mutability", "=", "mutability", "\n", "self", ".", "parent_name_long", "=", "parent_name_long", "\n", "self", ".", "parent_name_kurz", "=", "parent_name_kurz", "\n", "self", ".", "lower_bound", "=", "lower_bound", "\n", "self", ".", "upper_bound", "=", "upper_bound", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.loadDataset": [[595, 1128], ["os.path.join", "loadData.Dataset", "pickle.dump", "os.path.dirname", "load_adult_data_new", "data_frame_non_hot.reset_index.reset_index", "loadData.loadDataset.getInputOutputColumns"], "function", ["home.repos.pwc.inspect_result.amirhk_mace._data_main.fair_adult_data.load_adult_data_new"], ["", "", "def", "loadDataset", "(", "dataset_name", ",", "return_one_hot", ",", "load_from_cache", "=", "False", ",", "debug_flag", "=", "True", ",", "meta_param", "=", "None", ")", ":", "\n", "\n", "  ", "def", "getInputOutputColumns", "(", "data_frame", ")", ":", "\n", "    ", "all_data_frame_cols", "=", "data_frame", ".", "columns", ".", "values", "\n", "input_cols", "=", "[", "x", "for", "x", "in", "all_data_frame_cols", "if", "'label'", "not", "in", "x", ".", "lower", "(", ")", "]", "\n", "output_cols", "=", "[", "x", "for", "x", "in", "all_data_frame_cols", "if", "'label'", "in", "x", ".", "lower", "(", ")", "]", "\n", "assert", "len", "(", "output_cols", ")", "==", "1", "\n", "return", "input_cols", ",", "output_cols", "[", "0", "]", "\n", "\n", "", "one_hot_string", "=", "'one_hot'", "if", "return_one_hot", "else", "'non_hot'", "\n", "\n", "save_file_path", "=", "os", ".", "path", ".", "join", "(", "\n", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "\n", "f'_data_main/_cached/{dataset_name}_{one_hot_string}'", "\n", ")", "\n", "\n", "if", "load_from_cache", ":", "\n", "    ", "if", "debug_flag", ":", "print", "(", "f'[INFO] Attempting to load saved dataset (`{dataset_name}`) from cache...\\t'", ",", "end", "=", "''", ")", "\n", "try", ":", "\n", "      ", "tmp", "=", "pickle", ".", "load", "(", "open", "(", "save_file_path", ",", "'rb'", ")", ")", "\n", "if", "debug_flag", ":", "print", "(", "'done.'", ")", "\n", "return", "tmp", "\n", "", "except", ":", "\n", "      ", "if", "debug_flag", ":", "print", "(", "'failed. Re-creating dataset...'", ")", "\n", "\n", "", "", "if", "dataset_name", "==", "'adult'", ":", "\n", "\n", "    ", "data_frame_non_hot", "=", "load_adult_data_new", "(", ")", "\n", "data_frame_non_hot", "=", "data_frame_non_hot", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "attributes_non_hot", "=", "{", "}", "\n", "\n", "input_cols", ",", "output_col", "=", "getInputOutputColumns", "(", "data_frame_non_hot", ")", "\n", "\n", "col_name", "=", "output_col", "\n", "attributes_non_hot", "[", "col_name", "]", "=", "DatasetAttribute", "(", "\n", "attr_name_long", "=", "col_name", ",", "\n", "attr_name_kurz", "=", "'y'", ",", "\n", "attr_type", "=", "'binary'", ",", "\n", "node_type", "=", "'output'", ",", "\n", "actionability", "=", "'none'", ",", "\n", "mutability", "=", "False", ",", "\n", "parent_name_long", "=", "-", "1", ",", "\n", "parent_name_kurz", "=", "-", "1", ",", "\n", "lower_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "min", "(", ")", ",", "\n", "upper_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "max", "(", ")", ")", "\n", "\n", "for", "col_idx", ",", "col_name", "in", "enumerate", "(", "input_cols", ")", ":", "\n", "\n", "      ", "if", "col_name", "==", "'Sex'", ":", "\n", "        ", "attr_type", "=", "'binary'", "\n", "actionability", "=", "'any'", "# 'none'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'Age'", ":", "\n", "        ", "attr_type", "=", "'numeric-int'", "\n", "actionability", "=", "'any'", "# 'none'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'NativeCountry'", ":", "#~ RACE", "\n", "        ", "attr_type", "=", "'binary'", "\n", "actionability", "=", "'any'", "# 'none'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'WorkClass'", ":", "\n", "        ", "attr_type", "=", "'categorical'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'EducationNumber'", ":", "\n", "        ", "attr_type", "=", "'numeric-int'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'EducationLevel'", ":", "\n", "        ", "attr_type", "=", "'ordinal'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'MaritalStatus'", ":", "\n", "        ", "attr_type", "=", "'categorical'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'Occupation'", ":", "\n", "        ", "attr_type", "=", "'categorical'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'Relationship'", ":", "\n", "        ", "attr_type", "=", "'categorical'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'CapitalGain'", ":", "\n", "        ", "attr_type", "=", "'numeric-real'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'CapitalLoss'", ":", "\n", "        ", "attr_type", "=", "'numeric-real'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'HoursPerWeek'", ":", "\n", "        ", "attr_type", "=", "'numeric-int'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "\n", "", "attributes_non_hot", "[", "col_name", "]", "=", "DatasetAttribute", "(", "\n", "attr_name_long", "=", "col_name", ",", "\n", "attr_name_kurz", "=", "f'x{col_idx}'", ",", "\n", "attr_type", "=", "attr_type", ",", "\n", "node_type", "=", "'input'", ",", "\n", "actionability", "=", "actionability", ",", "\n", "mutability", "=", "mutability", ",", "\n", "parent_name_long", "=", "-", "1", ",", "\n", "parent_name_kurz", "=", "-", "1", ",", "\n", "lower_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "min", "(", ")", ",", "\n", "upper_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "max", "(", ")", ")", "\n", "\n", "", "", "elif", "dataset_name", "==", "'german'", ":", "\n", "\n", "    ", "data_frame_non_hot", "=", "load_german_data", "(", ")", "\n", "data_frame_non_hot", "=", "data_frame_non_hot", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "attributes_non_hot", "=", "{", "}", "\n", "\n", "input_cols", ",", "output_col", "=", "getInputOutputColumns", "(", "data_frame_non_hot", ")", "\n", "\n", "col_name", "=", "output_col", "\n", "attributes_non_hot", "[", "col_name", "]", "=", "DatasetAttribute", "(", "\n", "attr_name_long", "=", "col_name", ",", "\n", "attr_name_kurz", "=", "'y'", ",", "\n", "attr_type", "=", "'binary'", ",", "\n", "node_type", "=", "'output'", ",", "\n", "actionability", "=", "'none'", ",", "\n", "mutability", "=", "False", ",", "\n", "parent_name_long", "=", "-", "1", ",", "\n", "parent_name_kurz", "=", "-", "1", ",", "\n", "lower_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "min", "(", ")", ",", "\n", "upper_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "max", "(", ")", ")", "\n", "\n", "for", "col_idx", ",", "col_name", "in", "enumerate", "(", "input_cols", ")", ":", "\n", "\n", "      ", "if", "col_name", "==", "'Sex'", ":", "# TODO: make sex and race immutable in all datasets!", "\n", "        ", "attr_type", "=", "'binary'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'Age'", ":", "\n", "        ", "attr_type", "=", "'numeric-int'", "# 'numeric-real'", "\n", "actionability", "=", "'same-or-increase'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'Credit'", ":", "\n", "        ", "attr_type", "=", "'numeric-real'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'LoanDuration'", ":", "\n", "        ", "attr_type", "=", "'numeric-int'", "\n", "actionability", "=", "'none'", "\n", "mutability", "=", "True", "\n", "# elif col_name == 'CheckingAccountBalance':", "\n", "#   attr_type = 'ordinal' # 'numeric-real'", "\n", "#   actionability = 'any'", "\n", "#   mutability = True", "\n", "# elif col_name == 'SavingsAccountBalance':", "\n", "#   attr_type = 'ordinal'", "\n", "#   actionability = 'any'", "\n", "#   mutability = True", "\n", "# elif col_name == 'HousingStatus':", "\n", "#   attr_type = 'ordinal'", "\n", "#   actionability = 'any'", "\n", "#   mutability = True", "\n", "\n", "", "attributes_non_hot", "[", "col_name", "]", "=", "DatasetAttribute", "(", "\n", "attr_name_long", "=", "col_name", ",", "\n", "attr_name_kurz", "=", "f'x{col_idx}'", ",", "\n", "attr_type", "=", "attr_type", ",", "\n", "node_type", "=", "'input'", ",", "\n", "actionability", "=", "actionability", ",", "\n", "mutability", "=", "mutability", ",", "\n", "parent_name_long", "=", "-", "1", ",", "\n", "parent_name_kurz", "=", "-", "1", ",", "\n", "lower_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "min", "(", ")", ",", "\n", "upper_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "max", "(", ")", ")", "\n", "\n", "", "", "elif", "dataset_name", "==", "'credit'", ":", "\n", "\n", "    ", "data_frame_non_hot", "=", "load_credit_data", "(", ")", "\n", "data_frame_non_hot", "=", "data_frame_non_hot", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "attributes_non_hot", "=", "{", "}", "\n", "\n", "input_cols", ",", "output_col", "=", "getInputOutputColumns", "(", "data_frame_non_hot", ")", "\n", "\n", "col_name", "=", "output_col", "\n", "attributes_non_hot", "[", "col_name", "]", "=", "DatasetAttribute", "(", "\n", "attr_name_long", "=", "col_name", ",", "\n", "attr_name_kurz", "=", "'y'", ",", "\n", "attr_type", "=", "'binary'", ",", "\n", "node_type", "=", "'output'", ",", "\n", "actionability", "=", "'none'", ",", "\n", "mutability", "=", "False", ",", "\n", "parent_name_long", "=", "-", "1", ",", "\n", "parent_name_kurz", "=", "-", "1", ",", "\n", "lower_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "min", "(", ")", ",", "\n", "upper_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "max", "(", ")", ")", "\n", "\n", "for", "col_idx", ",", "col_name", "in", "enumerate", "(", "input_cols", ")", ":", "\n", "\n", "      ", "if", "col_name", "==", "'isMale'", ":", "\n", "        ", "attr_type", "=", "'binary'", "\n", "actionability", "=", "'any'", "# 'none'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'isMarried'", ":", "\n", "        ", "attr_type", "=", "'binary'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'AgeGroup'", ":", "\n", "        ", "attr_type", "=", "'ordinal'", "\n", "actionability", "=", "'any'", "# 'none'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'EducationLevel'", ":", "\n", "        ", "attr_type", "=", "'ordinal'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'MaxBillAmountOverLast6Months'", ":", "\n", "        ", "attr_type", "=", "'numeric-real'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'MaxPaymentAmountOverLast6Months'", ":", "\n", "        ", "attr_type", "=", "'numeric-real'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'MonthsWithZeroBalanceOverLast6Months'", ":", "\n", "        ", "attr_type", "=", "'numeric-int'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'MonthsWithLowSpendingOverLast6Months'", ":", "\n", "        ", "attr_type", "=", "'numeric-int'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'MonthsWithHighSpendingOverLast6Months'", ":", "\n", "        ", "attr_type", "=", "'numeric-int'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'MostRecentBillAmount'", ":", "\n", "        ", "attr_type", "=", "'numeric-real'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'MostRecentPaymentAmount'", ":", "\n", "        ", "attr_type", "=", "'numeric-real'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'TotalOverdueCounts'", ":", "\n", "        ", "attr_type", "=", "'numeric-int'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'TotalMonthsOverdue'", ":", "\n", "        ", "attr_type", "=", "'numeric-int'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'HasHistoryOfOverduePayments'", ":", "\n", "        ", "attr_type", "=", "'binary'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "\n", "", "attributes_non_hot", "[", "col_name", "]", "=", "DatasetAttribute", "(", "\n", "attr_name_long", "=", "col_name", ",", "\n", "attr_name_kurz", "=", "f'x{col_idx}'", ",", "\n", "attr_type", "=", "attr_type", ",", "\n", "node_type", "=", "'input'", ",", "\n", "actionability", "=", "actionability", ",", "\n", "mutability", "=", "mutability", ",", "\n", "parent_name_long", "=", "-", "1", ",", "\n", "parent_name_kurz", "=", "-", "1", ",", "\n", "lower_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "min", "(", ")", ",", "\n", "upper_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "max", "(", ")", ")", "\n", "\n", "", "", "elif", "dataset_name", "==", "'compass'", ":", "\n", "\n", "    ", "data_frame_non_hot", "=", "load_compas_data_new", "(", ")", "\n", "data_frame_non_hot", "=", "data_frame_non_hot", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "attributes_non_hot", "=", "{", "}", "\n", "\n", "input_cols", ",", "output_col", "=", "getInputOutputColumns", "(", "data_frame_non_hot", ")", "\n", "\n", "col_name", "=", "output_col", "\n", "attributes_non_hot", "[", "col_name", "]", "=", "DatasetAttribute", "(", "\n", "attr_name_long", "=", "col_name", ",", "\n", "attr_name_kurz", "=", "'y'", ",", "\n", "attr_type", "=", "'binary'", ",", "\n", "node_type", "=", "'output'", ",", "\n", "actionability", "=", "'none'", ",", "\n", "mutability", "=", "False", ",", "\n", "parent_name_long", "=", "-", "1", ",", "\n", "parent_name_kurz", "=", "-", "1", ",", "\n", "lower_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "min", "(", ")", ",", "\n", "upper_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "max", "(", ")", ")", "\n", "\n", "for", "col_idx", ",", "col_name", "in", "enumerate", "(", "input_cols", ")", ":", "\n", "\n", "      ", "if", "col_name", "==", "'AgeGroup'", ":", "\n", "        ", "attr_type", "=", "'ordinal'", "\n", "actionability", "=", "'any'", "# 'none'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'Race'", ":", "\n", "        ", "attr_type", "=", "'binary'", "\n", "actionability", "=", "'any'", "# 'none'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'Sex'", ":", "\n", "        ", "attr_type", "=", "'binary'", "\n", "actionability", "=", "'any'", "# 'none'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'PriorsCount'", ":", "\n", "        ", "attr_type", "=", "'numeric-int'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'ChargeDegree'", ":", "\n", "        ", "attr_type", "=", "'binary'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "\n", "", "attributes_non_hot", "[", "col_name", "]", "=", "DatasetAttribute", "(", "\n", "attr_name_long", "=", "col_name", ",", "\n", "attr_name_kurz", "=", "f'x{col_idx}'", ",", "\n", "attr_type", "=", "attr_type", ",", "\n", "node_type", "=", "'input'", ",", "\n", "actionability", "=", "actionability", ",", "\n", "mutability", "=", "mutability", ",", "\n", "parent_name_long", "=", "-", "1", ",", "\n", "parent_name_kurz", "=", "-", "1", ",", "\n", "lower_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "min", "(", ")", ",", "\n", "upper_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "max", "(", ")", ")", "\n", "\n", "", "", "elif", "dataset_name", "==", "'synthetic'", ":", "\n", "\n", "    ", "variable_type", "=", "'real'", "\n", "# variable_type = 'integer'", "\n", "\n", "scm_class", "=", "meta_param", "\n", "\n", "data_frame_non_hot", "=", "load_synthetic_data", "(", "scm_class", ",", "variable_type", ")", "\n", "data_frame_non_hot", "=", "data_frame_non_hot", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "attributes_non_hot", "=", "{", "}", "\n", "\n", "input_cols", ",", "output_col", "=", "getInputOutputColumns", "(", "data_frame_non_hot", ")", "\n", "# ordering of next two lines matters (shouldn't overwrite input_cols); silly code... :|", "\n", "meta_cols", "=", "[", "col_name", "for", "col_name", "in", "input_cols", "if", "'u'", "in", "col_name", "]", "\n", "input_cols", "=", "[", "col_name", "for", "col_name", "in", "input_cols", "if", "'x'", "in", "col_name", "]", "\n", "\n", "col_name", "=", "output_col", "\n", "attributes_non_hot", "[", "col_name", "]", "=", "DatasetAttribute", "(", "\n", "attr_name_long", "=", "col_name", ",", "\n", "attr_name_kurz", "=", "'y'", ",", "\n", "attr_type", "=", "'binary'", ",", "\n", "node_type", "=", "'output'", ",", "\n", "actionability", "=", "'none'", ",", "\n", "mutability", "=", "False", ",", "\n", "parent_name_long", "=", "-", "1", ",", "\n", "parent_name_kurz", "=", "-", "1", ",", "\n", "lower_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "min", "(", ")", ",", "\n", "upper_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "max", "(", ")", ")", "\n", "\n", "for", "col_idx", ",", "col_name", "in", "enumerate", "(", "input_cols", ")", ":", "\n", "\n", "      ", "attr_type", "=", "'numeric-real'", "if", "variable_type", "==", "'real'", "else", "'numeric-int'", "\n", "node_type", "=", "'input'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "\n", "attributes_non_hot", "[", "col_name", "]", "=", "DatasetAttribute", "(", "\n", "attr_name_long", "=", "col_name", ",", "\n", "attr_name_kurz", "=", "col_name", ",", "\n", "attr_type", "=", "attr_type", ",", "\n", "node_type", "=", "node_type", ",", "\n", "actionability", "=", "actionability", ",", "\n", "mutability", "=", "mutability", ",", "\n", "parent_name_long", "=", "-", "1", ",", "\n", "parent_name_kurz", "=", "-", "1", ",", "\n", "lower_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "min", "(", ")", ",", "\n", "upper_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "max", "(", ")", ")", "\n", "\n", "", "for", "col_idx", ",", "col_name", "in", "enumerate", "(", "meta_cols", ")", ":", "\n", "\n", "      ", "attr_type", "=", "'numeric-real'", "\n", "node_type", "=", "'meta'", "\n", "actionability", "=", "'none'", "\n", "mutability", "=", "False", "\n", "\n", "attributes_non_hot", "[", "col_name", "]", "=", "DatasetAttribute", "(", "\n", "attr_name_long", "=", "col_name", ",", "\n", "attr_name_kurz", "=", "col_name", ",", "\n", "attr_type", "=", "attr_type", ",", "\n", "node_type", "=", "node_type", ",", "\n", "actionability", "=", "actionability", ",", "\n", "mutability", "=", "mutability", ",", "\n", "parent_name_long", "=", "-", "1", ",", "\n", "parent_name_kurz", "=", "-", "1", ",", "\n", "lower_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "min", "(", ")", ",", "\n", "upper_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "max", "(", ")", ")", "\n", "\n", "", "", "elif", "dataset_name", "==", "'mortgage'", ":", "\n", "\n", "    ", "data_frame_non_hot", "=", "load_mortgage_data", "(", ")", "\n", "data_frame_non_hot", "=", "data_frame_non_hot", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "attributes_non_hot", "=", "{", "}", "\n", "\n", "input_cols", ",", "output_col", "=", "getInputOutputColumns", "(", "data_frame_non_hot", ")", "\n", "\n", "col_name", "=", "output_col", "\n", "attributes_non_hot", "[", "col_name", "]", "=", "DatasetAttribute", "(", "\n", "attr_name_long", "=", "col_name", ",", "\n", "attr_name_kurz", "=", "'y'", ",", "\n", "attr_type", "=", "'binary'", ",", "\n", "node_type", "=", "'output'", ",", "\n", "actionability", "=", "'none'", ",", "\n", "mutability", "=", "False", ",", "\n", "parent_name_long", "=", "-", "1", ",", "\n", "parent_name_kurz", "=", "-", "1", ",", "\n", "lower_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "min", "(", ")", ",", "\n", "upper_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "max", "(", ")", ")", "\n", "\n", "for", "col_idx", ",", "col_name", "in", "enumerate", "(", "input_cols", ")", ":", "\n", "\n", "      ", "if", "col_name", "==", "'x0'", ":", "\n", "        ", "attr_type", "=", "'numeric-real'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'x1'", ":", "\n", "        ", "attr_type", "=", "'numeric-real'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "\n", "", "attributes_non_hot", "[", "col_name", "]", "=", "DatasetAttribute", "(", "\n", "attr_name_long", "=", "col_name", ",", "\n", "attr_name_kurz", "=", "f'x{col_idx}'", ",", "\n", "attr_type", "=", "attr_type", ",", "\n", "node_type", "=", "'input'", ",", "\n", "actionability", "=", "actionability", ",", "\n", "mutability", "=", "mutability", ",", "\n", "parent_name_long", "=", "-", "1", ",", "\n", "parent_name_kurz", "=", "-", "1", ",", "\n", "lower_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "min", "(", ")", ",", "\n", "upper_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "max", "(", ")", ")", "\n", "\n", "", "", "elif", "dataset_name", "==", "'twomoon'", ":", "\n", "\n", "    ", "variable_type", "=", "'real'", "\n", "# variable_type = 'integer'", "\n", "\n", "data_frame_non_hot", "=", "load_twomoon_data", "(", "variable_type", ")", "\n", "data_frame_non_hot", "=", "data_frame_non_hot", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "attributes_non_hot", "=", "{", "}", "\n", "\n", "input_cols", ",", "output_col", "=", "getInputOutputColumns", "(", "data_frame_non_hot", ")", "\n", "\n", "col_name", "=", "output_col", "\n", "attributes_non_hot", "[", "col_name", "]", "=", "DatasetAttribute", "(", "\n", "attr_name_long", "=", "col_name", ",", "\n", "attr_name_kurz", "=", "'y'", ",", "\n", "attr_type", "=", "'binary'", ",", "\n", "node_type", "=", "'output'", ",", "\n", "actionability", "=", "'none'", ",", "\n", "mutability", "=", "False", ",", "\n", "parent_name_long", "=", "-", "1", ",", "\n", "parent_name_kurz", "=", "-", "1", ",", "\n", "lower_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "min", "(", ")", ",", "\n", "upper_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "max", "(", ")", ")", "\n", "\n", "for", "col_idx", ",", "col_name", "in", "enumerate", "(", "input_cols", ")", ":", "\n", "\n", "      ", "if", "col_name", "==", "'x0'", ":", "\n", "        ", "attr_type", "=", "'numeric-real'", "if", "variable_type", "==", "'real'", "else", "'numeric-int'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "", "elif", "col_name", "==", "'x1'", ":", "\n", "        ", "attr_type", "=", "'numeric-real'", "if", "variable_type", "==", "'real'", "else", "'numeric-int'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "\n", "", "attributes_non_hot", "[", "col_name", "]", "=", "DatasetAttribute", "(", "\n", "attr_name_long", "=", "col_name", ",", "\n", "attr_name_kurz", "=", "f'x{col_idx}'", ",", "\n", "attr_type", "=", "attr_type", ",", "\n", "node_type", "=", "'input'", ",", "\n", "actionability", "=", "actionability", ",", "\n", "mutability", "=", "mutability", ",", "\n", "parent_name_long", "=", "-", "1", ",", "\n", "parent_name_kurz", "=", "-", "1", ",", "\n", "lower_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "min", "(", ")", ",", "\n", "upper_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "max", "(", ")", ")", "\n", "\n", "", "", "elif", "dataset_name", "==", "'test'", ":", "\n", "\n", "    ", "data_frame_non_hot", "=", "load_test_data", "(", ")", "\n", "data_frame_non_hot", "=", "data_frame_non_hot", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "attributes_non_hot", "=", "{", "}", "\n", "\n", "input_cols", ",", "output_col", "=", "getInputOutputColumns", "(", "data_frame_non_hot", ")", "\n", "\n", "col_name", "=", "output_col", "\n", "attributes_non_hot", "[", "col_name", "]", "=", "DatasetAttribute", "(", "\n", "attr_name_long", "=", "col_name", ",", "\n", "attr_name_kurz", "=", "'y'", ",", "\n", "attr_type", "=", "'binary'", ",", "\n", "node_type", "=", "'output'", ",", "\n", "actionability", "=", "'none'", ",", "\n", "mutability", "=", "False", ",", "\n", "parent_name_long", "=", "-", "1", ",", "\n", "parent_name_kurz", "=", "-", "1", ",", "\n", "lower_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "min", "(", ")", ",", "\n", "upper_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "max", "(", ")", ")", "\n", "\n", "for", "col_idx", ",", "col_name", "in", "enumerate", "(", "input_cols", ")", ":", "\n", "\n", "      ", "if", "col_name", "==", "'x0'", ":", "\n", "        ", "attr_type", "=", "'categorical'", "\n", "actionability", "=", "'any'", "\n", "mutability", "=", "True", "\n", "\n", "", "attributes_non_hot", "[", "col_name", "]", "=", "DatasetAttribute", "(", "\n", "attr_name_long", "=", "col_name", ",", "\n", "attr_name_kurz", "=", "f'x{col_idx}'", ",", "\n", "attr_type", "=", "attr_type", ",", "\n", "node_type", "=", "'input'", ",", "\n", "actionability", "=", "actionability", ",", "\n", "mutability", "=", "mutability", ",", "\n", "parent_name_long", "=", "-", "1", ",", "\n", "parent_name_kurz", "=", "-", "1", ",", "\n", "lower_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "min", "(", ")", ",", "\n", "upper_bound", "=", "data_frame_non_hot", "[", "col_name", "]", ".", "max", "(", ")", ")", "\n", "\n", "", "", "else", ":", "\n", "\n", "    ", "raise", "Exception", "(", "f'{dataset_name} not recognized as a valid dataset.'", ")", "\n", "\n", "", "if", "return_one_hot", ":", "\n", "    ", "data_frame", ",", "attributes", "=", "getOneHotEquivalent", "(", "data_frame_non_hot", ",", "attributes_non_hot", ")", "\n", "", "else", ":", "\n", "    ", "data_frame", ",", "attributes", "=", "data_frame_non_hot", ",", "attributes_non_hot", "\n", "\n", "# save then return", "\n", "", "dataset_obj", "=", "Dataset", "(", "data_frame", ",", "attributes", ",", "return_one_hot", ",", "dataset_name", ")", "\n", "# if not loading from cache, we always overwrite the cache", "\n", "pickle", ".", "dump", "(", "dataset_obj", ",", "open", "(", "save_file_path", ",", "'wb'", ")", ")", "\n", "return", "dataset_obj", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.getOneHotEquivalent": [[1131, 1218], ["copy.deepcopy", "copy.deepcopy", "numpy.append", "numpy.append", "int", "pandas.concat", "range", "numpy.append", "numpy.zeros", "numpy.ones", "numpy.zeros", "print", "numpy.array", "pandas.DataFrame", "len", "loadData.DatasetAttribute", "numpy.zeros", "numpy.ones", "list", "print", "numpy.array", "pandas.DataFrame", "pd.concat.drop", "range", "range", "map", "list", "data_frame[].min", "data_frame[].max", "list", "range", "range", "map", "list", "data_frame[].astype", "data_frame[].astype"], "function", ["None"], ["", "def", "getOneHotEquivalent", "(", "data_frame_non_hot", ",", "attributes_non_hot", ")", ":", "\n", "\n", "# TODO: see how we can switch between feature_names = col names for kurz and long (also maybe ordered)", "\n", "\n", "  ", "data_frame", "=", "copy", ".", "deepcopy", "(", "data_frame_non_hot", ")", "\n", "attributes", "=", "copy", ".", "deepcopy", "(", "attributes_non_hot", ")", "\n", "\n", "def", "setOneHotValue", "(", "val", ")", ":", "\n", "    ", "return", "np", ".", "append", "(", "np", ".", "append", "(", "\n", "np", ".", "zeros", "(", "val", "-", "1", ")", ",", "\n", "np", ".", "ones", "(", "1", ")", ")", ",", "\n", "np", ".", "zeros", "(", "num_unique_values", "-", "val", ")", "\n", ")", "\n", "\n", "", "def", "setThermoValue", "(", "val", ")", ":", "\n", "    ", "return", "np", ".", "append", "(", "\n", "np", ".", "ones", "(", "val", ")", ",", "\n", "np", ".", "zeros", "(", "num_unique_values", "-", "val", ")", "\n", ")", "\n", "\n", "", "for", "col_name", "in", "data_frame", ".", "columns", ".", "values", ":", "\n", "\n", "    ", "if", "attributes", "[", "col_name", "]", ".", "attr_type", "not", "in", "{", "'categorical'", ",", "'ordinal'", "}", ":", "\n", "      ", "continue", "\n", "\n", "", "old_col_name_long", "=", "col_name", "\n", "new_col_names_long", "=", "[", "]", "\n", "new_col_names_kurz", "=", "[", "]", "\n", "\n", "old_attr_name_long", "=", "attributes", "[", "old_col_name_long", "]", ".", "attr_name_long", "\n", "old_attr_name_kurz", "=", "attributes", "[", "old_col_name_long", "]", ".", "attr_name_kurz", "\n", "old_attr_type", "=", "attributes", "[", "old_col_name_long", "]", ".", "attr_type", "\n", "old_node_type", "=", "attributes", "[", "old_col_name_long", "]", ".", "node_type", "\n", "old_actionability", "=", "attributes", "[", "old_col_name_long", "]", ".", "actionability", "\n", "old_mutability", "=", "attributes", "[", "old_col_name_long", "]", ".", "mutability", "\n", "old_lower_bound", "=", "attributes", "[", "old_col_name_long", "]", ".", "lower_bound", "\n", "old_upper_bound", "=", "attributes", "[", "old_col_name_long", "]", ".", "upper_bound", "\n", "\n", "num_unique_values", "=", "int", "(", "old_upper_bound", "-", "old_lower_bound", "+", "1", ")", "\n", "\n", "assert", "old_col_name_long", "==", "old_attr_name_long", "\n", "\n", "new_attr_type", "=", "'sub-'", "+", "old_attr_type", "\n", "new_node_type", "=", "old_node_type", "\n", "new_actionability", "=", "old_actionability", "\n", "new_mutability", "=", "old_mutability", "\n", "new_parent_name_long", "=", "old_attr_name_long", "\n", "new_parent_name_kurz", "=", "old_attr_name_kurz", "\n", "\n", "\n", "if", "attributes", "[", "col_name", "]", ".", "attr_type", "==", "'categorical'", ":", "# do not do this for 'binary'!", "\n", "\n", "      ", "new_col_names_long", "=", "[", "f'{old_attr_name_long}_cat_{i}'", "for", "i", "in", "range", "(", "num_unique_values", ")", "]", "\n", "new_col_names_kurz", "=", "[", "f'{old_attr_name_kurz}_cat_{i}'", "for", "i", "in", "range", "(", "num_unique_values", ")", "]", "\n", "print", "(", "f'Replacing column {col_name} with {{{\", \".join(new_col_names_long)}}}'", ")", "\n", "tmp", "=", "np", ".", "array", "(", "list", "(", "map", "(", "setOneHotValue", ",", "list", "(", "data_frame", "[", "col_name", "]", ".", "astype", "(", "int", ")", ".", "values", ")", ")", ")", ")", "\n", "data_frame_dummies", "=", "pd", ".", "DataFrame", "(", "data", "=", "tmp", ",", "columns", "=", "new_col_names_long", ")", "\n", "\n", "", "elif", "attributes", "[", "col_name", "]", ".", "attr_type", "==", "'ordinal'", ":", "\n", "\n", "      ", "new_col_names_long", "=", "[", "f'{old_attr_name_long}_ord_{i}'", "for", "i", "in", "range", "(", "num_unique_values", ")", "]", "\n", "new_col_names_kurz", "=", "[", "f'{old_attr_name_kurz}_ord_{i}'", "for", "i", "in", "range", "(", "num_unique_values", ")", "]", "\n", "print", "(", "f'Replacing column {col_name} with {{{\", \".join(new_col_names_long)}}}'", ")", "\n", "tmp", "=", "np", ".", "array", "(", "list", "(", "map", "(", "setThermoValue", ",", "list", "(", "data_frame", "[", "col_name", "]", ".", "astype", "(", "int", ")", ".", "values", ")", ")", ")", ")", "\n", "data_frame_dummies", "=", "pd", ".", "DataFrame", "(", "data", "=", "tmp", ",", "columns", "=", "new_col_names_long", ")", "\n", "\n", "# Update data_frame", "\n", "", "data_frame", "=", "pd", ".", "concat", "(", "[", "data_frame", ".", "drop", "(", "columns", "=", "old_col_name_long", ")", ",", "data_frame_dummies", "]", ",", "axis", "=", "1", ")", "\n", "\n", "# Update attributes", "\n", "del", "attributes", "[", "old_col_name_long", "]", "\n", "for", "col_idx", "in", "range", "(", "len", "(", "new_col_names_long", ")", ")", ":", "\n", "      ", "new_col_name_long", "=", "new_col_names_long", "[", "col_idx", "]", "\n", "new_col_name_kurz", "=", "new_col_names_kurz", "[", "col_idx", "]", "\n", "attributes", "[", "new_col_name_long", "]", "=", "DatasetAttribute", "(", "\n", "attr_name_long", "=", "new_col_name_long", ",", "\n", "attr_name_kurz", "=", "new_col_name_kurz", ",", "\n", "attr_type", "=", "new_attr_type", ",", "\n", "node_type", "=", "new_node_type", ",", "\n", "actionability", "=", "new_actionability", ",", "\n", "mutability", "=", "new_mutability", ",", "\n", "parent_name_long", "=", "new_parent_name_long", ",", "\n", "parent_name_kurz", "=", "new_parent_name_kurz", ",", "\n", "lower_bound", "=", "data_frame", "[", "new_col_name_long", "]", ".", "min", "(", ")", ",", "\n", "upper_bound", "=", "data_frame", "[", "new_col_name_long", "]", ".", "max", "(", ")", ")", "\n", "\n", "", "", "return", "data_frame", ",", "attributes", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.analyzeResults.gatherAndSaveDistances": [[45, 273], ["pandas.DataFrame", "print", "print", "print", "pickle.dump", "os.listdir", "all_child_folders.extend", "len", "open", "os.path.join", "len", "len", "len", "pickle.load.keys", "os.path.join", "os.path.isfile", "print", "pickle.load", "print", "df_all_distances.append.append", "len", "print", "open", "print", "list", "list", "len", "map", "map", "len", "x.split", "x.split", "x.split", "x.split", "matching_child_folder.split", "pickle.load.keys"], "function", ["None"], ["def", "gatherAndSaveDistances", "(", ")", ":", "\n", "\n", "# parent_folders = [", "\n", "#   '/Volumes/amir/dev/mace/_experiments/__2019.07.30__merged_unconstrained_MO_PFT_AR',", "\n", "#   '/Volumes/amir/dev/mace/_experiments/__2019.07.30__merged_unconstrained_MACE_eps_1e-1',", "\n", "#   '/Volumes/amir/dev/mace/_experiments/__2019.09.19__merged_unconstrained_MACE_eps_1e-3',", "\n", "#   '/Volumes/amir/dev/mace/_experiments/__2019.09.19__merged_unconstrained_MACE_eps_1e-5'", "\n", "# ]", "\n", "\n", "# parent_folders = [", "\n", "#   '/Volumes/amir/dev/mace/_experiments/__2019.07.30__merged_unconstrained_MO_PFT_AR',", "\n", "#   '/Volumes/amir/dev/mace/_experiments/__2019.09.29__merged_unconstrained_MACE_eps_1e-2__tree_forest_lr',", "\n", "#   '/Volumes/amir/dev/mace/_experiments/__2019.09.29__merged_unconstrained_MACE_eps_1e-3__tree_forest_lr',", "\n", "#   '/Volumes/amir/dev/mace/_experiments/__2019.09.29__merged_unconstrained_MACE_eps_1e-5__tree_forest_lr'", "\n", "# ]", "\n", "\n", "# parent_folders = [", "\n", "#   '/Volumes/amir/dev/mace/_experiments/__2019.07.30__merged_constrained_MO_AR__lr',", "\n", "#   '/Volumes/amir/dev/mace/_experiments/__2019.09.20__merged_constrained_MACE_eps_1e-3__tree_forest_lr'", "\n", "# ]", "\n", "# year = '2019'", "\n", "\n", "  ", "parent_folders", "=", "[", "\n", "'/Users/a6karimi/dev/mace/_experiments'", "\n", "# '/Users/a6karimi/dev/mace/_experiments/__merged_german-lr-one_norm-MACE_eps_1e-3'", "\n", "]", "\n", "year", "=", "'2020'", "\n", "\n", "all_child_folders", "=", "[", "]", "\n", "for", "parent_folder", "in", "parent_folders", ":", "\n", "    ", "child_folders", "=", "os", ".", "listdir", "(", "parent_folder", ")", "\n", "child_folders", "=", "[", "x", "for", "x", "in", "child_folders", "if", "year", "in", "x", "and", "x", "[", "0", "]", "!=", "'.'", "]", "# remove .DS_Store, etc.", "\n", "child_folders", "=", "[", "os", ".", "path", ".", "join", "(", "parent_folder", ",", "x", ")", "for", "x", "in", "child_folders", "]", "\n", "all_child_folders", ".", "extend", "(", "child_folders", ")", "# happens in place", "\n", "\n", "# DATASET_VALUES = ['adult', 'credit', 'compass']", "\n", "# MODEL_CLASS_VALUES = ['tree', 'forest', 'lr'] # , 'mlp']", "\n", "# NORM_VALUES = ['zero_norm', 'one_norm', 'infty_norm']", "\n", "# APPROACHES_VALUES = ['MACE_eps_1e-2', 'MACE_eps_1e-3', 'MACE_eps_1e-5', 'MO', 'PFT', 'AR']", "\n", "\n", "", "DATASET_VALUES", "=", "[", "'german'", "]", "\n", "MODEL_CLASS_VALUES", "=", "[", "'tree'", "]", "#,'lr']", "\n", "NORM_VALUES", "=", "[", "'one_norm'", "]", "\n", "APPROACHES_VALUES", "=", "[", "'MACE_eps_1e-3'", "]", "\n", "\n", "# all_counter = 72 + 18 + 6 # (without the unneccessary FT folders for LR and MLP)", "\n", "# assert len(all_child_folders) == all_counter, 'missing, or too many experiment folders'", "\n", "all_counter", "=", "len", "(", "DATASET_VALUES", ")", "*", "len", "(", "MODEL_CLASS_VALUES", ")", "*", "len", "(", "NORM_VALUES", ")", "*", "len", "(", "APPROACHES_VALUES", ")", "\n", "\n", "df_all_distances", "=", "pd", ".", "DataFrame", "(", "{", "'dataset'", ":", "[", "]", ",", "'model'", ":", "[", "]", ",", "'norm'", ":", "[", "]", ",", "'approach'", ":", "[", "]", ",", "# 'approach_param': [], \\", "\n", "'factual sample index'", ":", "[", "]", ",", "'counterfactual found'", ":", "[", "]", ",", "'counterfactual plausible'", ":", "[", "]", ",", "'counterfactual distance'", ":", "[", "]", ",", "'counterfactual time'", ":", "[", "]", ",", "'all counterfactual distances'", ":", "[", "]", ",", "'all counterfactual times'", ":", "[", "]", ",", "'changed age'", ":", "[", "]", ",", "'changed gender'", ":", "[", "]", ",", "'changed race'", ":", "[", "]", ",", "# 'changed attributes': [], \\", "\n", "'age constant'", ":", "[", "]", ",", "'age increased'", ":", "[", "]", ",", "'age decreased'", ":", "[", "]", ",", "'interventional distance'", ":", "[", "]", ",", "}", ")", "\n", "\n", "print", "(", "'Loading and merging all distance files.'", ")", "\n", "\n", "counter", "=", "0", "\n", "\n", "for", "dataset_string", "in", "DATASET_VALUES", ":", "\n", "\n", "    ", "for", "model_class_string", "in", "MODEL_CLASS_VALUES", ":", "\n", "\n", "      ", "for", "norm_type_string", "in", "NORM_VALUES", ":", "\n", "\n", "        ", "for", "approach_string", "in", "APPROACHES_VALUES", ":", "\n", "\n", "          ", "if", "approach_string", "==", "'PFT'", ":", "\n", "            ", "if", "model_class_string", "!=", "'tree'", "and", "model_class_string", "!=", "'forest'", ":", "\n", "              ", "continue", "\n", "", "", "elif", "approach_string", "==", "'AR'", ":", "\n", "            ", "if", "model_class_string", "!=", "'lr'", ":", "\n", "              ", "continue", "\n", "\n", "", "", "counter", "=", "counter", "+", "1", "\n", "\n", "matching_child_folders", "=", "[", "\n", "x", "for", "x", "in", "all_child_folders", "if", "\n", "f'__{dataset_string}__'", "in", "x", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "and", "\n", "f'__{model_class_string}__'", "in", "x", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "and", "\n", "f'__{norm_type_string}__'", "in", "x", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "and", "\n", "f'__{approach_string}'", "in", "x", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "]", "\n", "\n", "# if approach_string == 'MACE_eps_1e-5':", "\n", "#   tmp_index = minimum_distance_file_path.find('eps')", "\n", "#   epsilon_string = minimum_distance_file_path[tmp_index + 4 : tmp_index + 8]", "\n", "#   approach_param = float(epsilon_string)", "\n", "# else:", "\n", "#   approach_param = -1", "\n", "\n", "# Find results folder", "\n", "try", ":", "\n", "            ", "assert", "len", "(", "matching_child_folders", ")", "==", "1", ",", "f'Expecting only 1 folder, but we found {len(matching_child_folders)}.'", "\n", "matching_child_folder", "=", "matching_child_folders", "[", "0", "]", "\n", "minimum_distance_file_path", "=", "os", ".", "path", ".", "join", "(", "matching_child_folder", ",", "'_minimum_distances'", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "f'\\t[{counter} / (max {all_counter})] Cannot find folder for {dataset_string}-{model_class_string}-{norm_type_string}-{approach_string}'", ")", "\n", "continue", "\n", "\n", "# Find results file", "\n", "", "try", ":", "\n", "            ", "assert", "os", ".", "path", ".", "isfile", "(", "minimum_distance_file_path", ")", "\n", "print", "(", "f'\\t[{counter} / (max {all_counter})] Successfully found folder {matching_child_folder.split(\"/\")[-1]}, found min dist file, '", ",", "end", "=", "''", ")", "\n", "minimum_distance_file", "=", "pickle", ".", "load", "(", "open", "(", "minimum_distance_file_path", ",", "'rb'", ")", ")", "\n", "print", "(", "f'adding {len(minimum_distance_file.keys())} distances.'", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "f'Cannot find file {minimum_distance_file_path}'", ")", "\n", "continue", "\n", "\n", "# Add results to global results data frame", "\n", "# try:", "\n", "", "for", "key", "in", "minimum_distance_file", ".", "keys", "(", ")", ":", "\n", "            ", "factual_sample", "=", "minimum_distance_file", "[", "key", "]", "[", "'factual_sample'", "]", "\n", "counterfactual_sample", "=", "minimum_distance_file", "[", "key", "]", "[", "'counterfactual_sample'", "]", "\n", "changed_age", "=", "False", "\n", "changed_gender", "=", "False", "\n", "changed_race", "=", "False", "\n", "# if dataset_string == 'adult':", "\n", "#   if not np.isclose(factual_sample['x0'], counterfactual_sample['x0']):", "\n", "#     changed_gender = True", "\n", "#   if not np.isclose(factual_sample['x1'], counterfactual_sample['x1']):", "\n", "#     changed_age = True", "\n", "\n", "# elif dataset_string == 'credit':", "\n", "#   if not np.isclose(factual_sample['x0'], counterfactual_sample['x0']):", "\n", "#     changed_gender = True", "\n", "#   if model_class_string == 'tree' or model_class_string == 'forest': # non-hot", "\n", "#     if not np.isclose(factual_sample['x2'], counterfactual_sample['x2']):", "\n", "#       changed_age = True", "\n", "#   else: # one-hot", "\n", "#     if not np.isclose(factual_sample['x2_ord_0'], counterfactual_sample['x2_ord_0']) or \\", "\n", "#        not np.isclose(factual_sample['x2_ord_1'], counterfactual_sample['x2_ord_1']) or \\", "\n", "#        not np.isclose(factual_sample['x2_ord_2'], counterfactual_sample['x2_ord_2']) or \\", "\n", "#        not np.isclose(factual_sample['x2_ord_3'], counterfactual_sample['x2_ord_3']):", "\n", "#       changed_age = True", "\n", "# elif dataset_string == 'compass':", "\n", "#   if model_class_string == 'tree' or model_class_string == 'forest': # non-hot", "\n", "#     if not np.isclose(factual_sample['x0'], counterfactual_sample['x0']):", "\n", "#       changed_age = True", "\n", "#   else: # one-hot", "\n", "#     if not np.isclose(factual_sample['x0_ord_0'], counterfactual_sample['x0_ord_0']) or \\", "\n", "#        not np.isclose(factual_sample['x0_ord_1'], counterfactual_sample['x0_ord_1']) or \\", "\n", "#        not np.isclose(factual_sample['x0_ord_2'], counterfactual_sample['x0_ord_2']):", "\n", "#       changed_age = True", "\n", "#   if not np.isclose(factual_sample['x1'], counterfactual_sample['x1']):", "\n", "#     changed_race = True", "\n", "#   if not np.isclose(factual_sample['x2'], counterfactual_sample['x2']):", "\n", "#     changed_gender = True", "\n", "\n", "# changed_attributes = []", "\n", "# for attr in factual_sample.keys():", "\n", "#   if not isinstance(factual_sample[attr], float):", "\n", "#     print(attr)", "\n", "#     print(f'factual_sample[attr]: {factual_sample}')", "\n", "#     print(f'counterfactual_sample[attr]: {counterfactual_sample}')", "\n", "#   if not np.isclose(factual_sample[attr], counterfactual_sample[attr]):", "\n", "#     changed_attributes.append(attr)", "\n", "\n", "age_constant", "=", "False", "\n", "age_increased", "=", "False", "\n", "age_decreased", "=", "False", "\n", "# if dataset_string == 'adult':", "\n", "#   if factual_sample['x1'] < counterfactual_sample['x1']:", "\n", "#     age_increased = True", "\n", "#   elif factual_sample['x1'] == counterfactual_sample['x1']:", "\n", "#     age_constant = True", "\n", "#   elif factual_sample['x1'] > counterfactual_sample['x1']:", "\n", "#     age_decreased = True", "\n", "\n", "# append rows", "\n", "\n", "if", "'MACE'", "in", "approach_string", ":", "\n", "              ", "all_counterfactual_distances", "=", "list", "(", "map", "(", "lambda", "x", ":", "x", "[", "'counterfactual_distance'", "]", ",", "minimum_distance_file", "[", "key", "]", "[", "'all_counterfactuals'", "]", ")", ")", "\n", "all_counterfactual_times", "=", "list", "(", "map", "(", "lambda", "x", ":", "x", "[", "'time'", "]", ",", "minimum_distance_file", "[", "key", "]", "[", "'all_counterfactuals'", "]", ")", ")", "\n", "", "else", ":", "\n", "              ", "all_counterfactual_distances", "=", "[", "]", "\n", "all_counterfactual_times", "=", "[", "]", "\n", "\n", "", "df_all_distances", "=", "df_all_distances", ".", "append", "(", "{", "\n", "'dataset'", ":", "dataset_string", ",", "\n", "'model'", ":", "model_class_string", ",", "\n", "'norm'", ":", "norm_type_string", ",", "\n", "'approach'", ":", "approach_string", ",", "\n", "# 'approach_param': approach_param,", "\n", "'factual sample index'", ":", "key", ",", "\n", "'counterfactual found'", ":", "minimum_distance_file", "[", "key", "]", "[", "'counterfactual_found'", "]", ",", "\n", "'counterfactual plausible'", ":", "minimum_distance_file", "[", "key", "]", "[", "'counterfactual_plausible'", "]", ",", "\n", "'counterfactual distance'", ":", "minimum_distance_file", "[", "key", "]", "[", "'counterfactual_distance'", "]", ",", "\n", "'counterfactual time'", ":", "minimum_distance_file", "[", "key", "]", "[", "'counterfactual_time'", "]", ",", "\n", "'all counterfactual distances'", ":", "all_counterfactual_distances", ",", "\n", "'all counterfactual times'", ":", "all_counterfactual_times", ",", "\n", "'changed age'", ":", "changed_age", ",", "\n", "'changed gender'", ":", "changed_gender", ",", "\n", "'changed race'", ":", "changed_race", ",", "\n", "# 'changed attributes': changed_attributes,", "\n", "'age constant'", ":", "age_constant", ",", "\n", "'age increased'", ":", "age_increased", ",", "\n", "'age decreased'", ":", "age_decreased", ",", "\n", "'interventional distance'", ":", "minimum_distance_file", "[", "key", "]", "[", "'interventional_distance'", "]", ",", "\n", "}", ",", "ignore_index", "=", "True", ")", "\n", "# ipsh()", "\n", "# except:", "\n", "#   print(f'Problem with adding row in data frame.')", "\n", "\n", "\n", "", "", "", "", "", "print", "(", "'Processing merged distance files.'", ")", "\n", "\n", "print", "(", "'Saving merged distance files.'", ")", "\n", "\n", "pickle", ".", "dump", "(", "df_all_distances", ",", "open", "(", "f'_results/df_all_distances'", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.analyzeResults.gatherAndSaveDistanceTimeTradeoffData": [[275, 377], ["pickle.load", "df_all_distances.where().dropna.where().dropna", "pandas.DataFrame", "pickle.dump", "open", "len", "open", "df_all_distances.where().dropna.where", "len", "len", "len", "df_all_distances.where().dropna.where().dropna", "print", "df_all_distances.where().dropna.where", "max", "df_all_distances.where().dropna.iterrows", "df_all_distances.where().dropna.iterrows", "list", "numpy.cumsum", "range", "range", "map", "len", "len", "len", "tmp_df.append.append", "tmp_df.append.append", "len", "int", "int"], "function", ["None"], ["", "def", "gatherAndSaveDistanceTimeTradeoffData", "(", ")", ":", "\n", "\n", "# unconstrained", "\n", "  ", "DATASET_VALUES", "=", "[", "'adult'", ",", "'credit'", ",", "'compass'", "]", "\n", "MODEL_CLASS_VALUES", "=", "[", "'tree'", ",", "'forest'", ",", "'lr'", "]", "# , 'mlp']", "\n", "NORM_VALUES", "=", "[", "'one_norm'", "]", "\n", "APPROACHES_VALUES", "=", "[", "'MO'", ",", "'PFT'", ",", "'AR'", ",", "'MACE_eps_1e-2'", ",", "'MACE_eps_1e-3'", ",", "'MACE_eps_1e-5'", "]", "\n", "\n", "# Remove FeatureTweaking / ActionableRecourse distances that were unsuccessful or non-plausible", "\n", "df_all_distances", "=", "pickle", ".", "load", "(", "open", "(", "f'_results/df_all_distances'", ",", "'rb'", ")", ")", "\n", "df_all_distances", "=", "df_all_distances", ".", "where", "(", "\n", "(", "df_all_distances", "[", "'counterfactual found'", "]", "==", "True", ")", "&", "\n", "(", "df_all_distances", "[", "'counterfactual plausible'", "]", "==", "True", ")", "\n", ")", ".", "dropna", "(", ")", "\n", "\n", "tmp_df", "=", "pd", ".", "DataFrame", "(", "{", "'factual_sample_index'", ":", "[", "]", ",", "'dataset'", ":", "[", "]", ",", "'model'", ":", "[", "]", ",", "'norm'", ":", "[", "]", ",", "'approach'", ":", "[", "]", ",", "'iteration'", ":", "[", "]", ",", "'distance'", ":", "[", "]", ",", "'time'", ":", "[", "]", ",", "}", ")", "\n", "\n", "counter", "=", "1", "\n", "total_counter", "=", "len", "(", "DATASET_VALUES", ")", "*", "len", "(", "MODEL_CLASS_VALUES", ")", "*", "len", "(", "NORM_VALUES", ")", "*", "len", "(", "APPROACHES_VALUES", ")", "\n", "for", "model_class_string", "in", "MODEL_CLASS_VALUES", ":", "\n", "\n", "    ", "for", "norm_type_string", "in", "NORM_VALUES", ":", "\n", "\n", "      ", "for", "dataset_string", "in", "DATASET_VALUES", ":", "\n", "\n", "        ", "for", "approach_string", "in", "APPROACHES_VALUES", ":", "\n", "\n", "          ", "df", "=", "df_all_distances", ".", "where", "(", "\n", "(", "df_all_distances", "[", "'dataset'", "]", "==", "dataset_string", ")", "&", "\n", "(", "df_all_distances", "[", "'model'", "]", "==", "model_class_string", ")", "&", "\n", "(", "df_all_distances", "[", "'norm'", "]", "==", "norm_type_string", ")", "&", "\n", "(", "df_all_distances", "[", "'approach'", "]", "==", "approach_string", ")", ",", "\n", ")", ".", "dropna", "(", ")", "\n", "\n", "print", "(", "f'[INFO] (#{counter} / {total_counter}) Processing {dataset_string}-{model_class_string}-{norm_type_string}-{approach_string}...'", ")", "\n", "counter", "=", "counter", "+", "1", "\n", "\n", "if", "df", ".", "shape", "[", "0", "]", ":", "# if any tests exist for this setup", "\n", "\n", "            ", "if", "'MACE'", "in", "approach_string", ":", "\n", "\n", "# max_iterations_over_all_factual_samples", "\n", "              ", "max_iterations", "=", "max", "(", "list", "(", "map", "(", "lambda", "x", ":", "len", "(", "x", ")", ",", "df_all_distances", "[", "'all counterfactual times'", "]", ")", ")", ")", "\n", "# print(f'max_iterations: {max_iterations}')", "\n", "\n", "for", "index", ",", "row", "in", "df", ".", "iterrows", "(", ")", ":", "\n", "\n", "                ", "all_counterfactual_distances", "=", "row", "[", "'all counterfactual distances'", "]", "[", "1", ":", "]", "# remove the first elem (np.infty)", "\n", "all_counterfactual_times", "=", "row", "[", "'all counterfactual times'", "]", "[", "1", ":", "]", "# remove the first elem (np.infty)", "\n", "assert", "len", "(", "all_counterfactual_distances", ")", "==", "len", "(", "all_counterfactual_times", ")", "\n", "# IMPORTANT: keep repeating last elem of array so that all factual", "\n", "# samples have the same number of iterations (this is important", "\n", "# for later when we take the average for any iteration; we do not", "\n", "# want the plot to come down-to-the-right, then go up last minute", "\n", "# Importantly, the repeating of last element should be done prior", "\n", "# to cumsum. max_iterations - len(array) - 1 (-1 because we remove", "\n", "# the first elem (np.infty))", "\n", "# all_counterfactual_distances.extend([all_counterfactual_distances[-1]] * (max_iterations - len(all_counterfactual_distances) - 1))", "\n", "# all_counterfactual_times.extend([all_counterfactual_times[-1]] * (max_iterations - len(all_counterfactual_times) - 1))", "\n", "# Now (and only after the 2 lines above), perform cumulation sum", "\n", "cum_counterfactual_times", "=", "np", ".", "cumsum", "(", "all_counterfactual_times", ")", "\n", "\n", "for", "iteration_counter", "in", "range", "(", "len", "(", "all_counterfactual_distances", ")", ")", ":", "\n", "\n", "                  ", "tmp_df", "=", "tmp_df", ".", "append", "(", "{", "\n", "'factual_sample_index'", ":", "row", "[", "'factual sample index'", "]", ",", "\n", "'dataset'", ":", "dataset_string", ",", "\n", "'model'", ":", "model_class_string", ",", "\n", "'norm'", ":", "norm_type_string", ",", "\n", "'approach'", ":", "approach_string", ",", "\n", "'iteration'", ":", "int", "(", "iteration_counter", ")", "+", "1", ",", "\n", "'distance'", ":", "all_counterfactual_distances", "[", "iteration_counter", "]", ",", "\n", "'time'", ":", "cum_counterfactual_times", "[", "iteration_counter", "]", ",", "\n", "}", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "", "", "else", ":", "\n", "\n", "              ", "for", "index", ",", "row", "in", "df", ".", "iterrows", "(", ")", ":", "\n", "\n", "                ", "for", "iteration_counter", "in", "range", "(", "15", ")", ":", "\n", "\n", "                  ", "tmp_df", "=", "tmp_df", ".", "append", "(", "{", "\n", "'factual_sample_index'", ":", "row", "[", "'factual sample index'", "]", ",", "\n", "'dataset'", ":", "dataset_string", ",", "\n", "'model'", ":", "model_class_string", ",", "\n", "'norm'", ":", "norm_type_string", ",", "\n", "'approach'", ":", "approach_string", ",", "\n", "'iteration'", ":", "int", "(", "iteration_counter", ")", "+", "1", ",", "\n", "'distance'", ":", "row", "[", "'counterfactual distance'", "]", ",", "\n", "'time'", ":", "row", "[", "'counterfactual time'", "]", ",", "\n", "}", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "", "", "", "", "", "", "", "pickle", ".", "dump", "(", "tmp_df", ",", "open", "(", "f'_results/df_all_distance_vs_time'", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.analyzeResults.latexify": [[379, 435], ["matplotlib.rcParams.update", "matplotlib.rcParams.update", "matplotlib.rcParams.update", "print", "numpy.sqrt"], "function", ["None"], ["", "def", "latexify", "(", "fig_width", "=", "None", ",", "fig_height", "=", "None", ",", "columns", "=", "1", ",", "largeFonts", "=", "False", ",", "font_scale", "=", "1", ")", ":", "\n", "  ", "\"\"\"Set up matplotlib's RC params for LaTeX plotting.\n  Call this before plotting a figure.\n\n  Parameters\n  ----------\n  fig_width : float, optional, inches\n  fig_height : float,  optional, inches\n  columns : {1, 2}\n  \"\"\"", "\n", "\n", "# code adapted from http://www.scipy.org/Cookbook/Matplotlib/LaTeX_Examples", "\n", "\n", "# Width and max height in inches for IEEE journals taken from", "\n", "# computer.org/cms/Computer.org/Journal%20templates/transactions_art_guide.pdf", "\n", "\n", "assert", "(", "columns", "in", "[", "1", ",", "2", "]", ")", "\n", "\n", "if", "fig_width", "is", "None", ":", "\n", "      ", "fig_width", "=", "3.39", "if", "columns", "==", "1", "else", "6.9", "# width in inches", "\n", "\n", "", "if", "fig_height", "is", "None", ":", "\n", "      ", "golden_mean", "=", "(", "np", ".", "sqrt", "(", "5", ")", "-", "1.0", ")", "/", "2.0", "# Aesthetic ratio", "\n", "fig_height", "=", "fig_width", "*", "golden_mean", "# height in inches", "\n", "\n", "", "MAX_HEIGHT_INCHES", "=", "8.0", "\n", "if", "fig_height", ">", "MAX_HEIGHT_INCHES", ":", "\n", "      ", "print", "(", "\"WARNING: fig_height too large:\"", "+", "fig_height", "+", "\n", "\"so will reduce to\"", "+", "MAX_HEIGHT_INCHES", "+", "\"inches.\"", ")", "\n", "fig_height", "=", "MAX_HEIGHT_INCHES", "\n", "\n", "", "params", "=", "{", "'backend'", ":", "'ps'", ",", "\n", "'text.latex.preamble'", ":", "[", "'\\\\usepackage{gensymb}'", "]", ",", "\n", "# fontsize for x and y labels (was 10)", "\n", "'axes.labelsize'", ":", "font_scale", "*", "10", "if", "largeFonts", "else", "font_scale", "*", "7", ",", "\n", "'axes.titlesize'", ":", "font_scale", "*", "10", "if", "largeFonts", "else", "font_scale", "*", "7", ",", "\n", "'font.size'", ":", "font_scale", "*", "10", "if", "largeFonts", "else", "font_scale", "*", "7", ",", "# was 10", "\n", "'legend.fontsize'", ":", "font_scale", "*", "10", "if", "largeFonts", "else", "font_scale", "*", "7", ",", "# was 10", "\n", "'xtick.labelsize'", ":", "font_scale", "*", "10", "if", "largeFonts", "else", "font_scale", "*", "7", ",", "\n", "'ytick.labelsize'", ":", "font_scale", "*", "10", "if", "largeFonts", "else", "font_scale", "*", "7", ",", "\n", "'text.usetex'", ":", "True", ",", "\n", "'figure.figsize'", ":", "[", "fig_width", ",", "fig_height", "]", ",", "\n", "'font.family'", ":", "'serif'", ",", "\n", "'xtick.minor.size'", ":", "0.5", ",", "\n", "'xtick.major.pad'", ":", "1.5", ",", "\n", "'xtick.major.size'", ":", "1", ",", "\n", "'ytick.minor.size'", ":", "0.5", ",", "\n", "'ytick.major.pad'", ":", "1.5", ",", "\n", "'ytick.major.size'", ":", "1", ",", "\n", "'lines.linewidth'", ":", "1.5", ",", "\n", "'lines.markersize'", ":", "0.1", ",", "\n", "'hatch.linewidth'", ":", "0.5", "\n", "}", "\n", "\n", "matplotlib", ".", "rcParams", ".", "update", "(", "params", ")", "\n", "plt", ".", "rcParams", ".", "update", "(", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.analyzeResults.analyzeRelativeDistances": [[437, 543], ["pickle.load", "df_all_distances.where().dropna.where().dropna", "print", "open", "df_all_distances.where().dropna.where", "df_all_distances.where().dropna.where().dropna", "dict", "list", "df_all_distances.where().dropna.where", "numpy.unique", "numpy.setdiff1d", "numpy.intersect1d", "print", "numpy.array", "numpy.array", "len", "df_all_distances.where().dropna.where().dropna().T.to_dict", "df_all_distances.where().dropna.where().dropna().T.to_dict", "distance_reduction_list.append", "numpy.mean", "numpy.std", "df_all_distances.where().dropna.where().dropna", "dict.items", "list", "len", "len", "numpy.array", "numpy.array", "len", "factual_sample_index_per_approach.keys", "df.where().dropna().T.to_dict.keys", "df.where().dropna().T.to_dict.keys", "len", "df_all_distances.where().dropna.where", "df_all_distances.where().dropna.where().dropna", "df_all_distances.where().dropna.where().dropna", "list", "list", "df_all_distances.where().dropna.where", "df_all_distances.where().dropna.where", "df.where().dropna().T.to_dict.keys", "df.where().dropna().T.to_dict.keys"], "function", ["None"], ["", "def", "analyzeRelativeDistances", "(", ")", ":", "\n", "  ", "DATASET_VALUES", "=", "[", "'adult'", ",", "'credit'", ",", "'compass'", "]", "\n", "MODEL_CLASS_VALUES", "=", "[", "'tree'", ",", "'forest'", ",", "'lr'", ",", "'mlp'", "]", "\n", "NORM_VALUES", "=", "[", "'zero_norm'", ",", "'one_norm'", ",", "'infty_norm'", "]", "\n", "# APPROACHES_VALUES = ['MACE_eps_1e-1', 'MACE_eps_1e-3', 'MACE_eps_1e-5', 'MO', 'PFT', 'AR']", "\n", "# APPROACHES_VALUES = ['MACE_eps_1e-3', 'MACE_eps_1e-5', 'MO', 'PFT', 'AR']", "\n", "# APPROACHES_VALUES = ['MACE_eps_1e-5', 'MO', 'PFT', 'AR']", "\n", "APPROACHES_VALUES", "=", "[", "'MACE_eps_1e-2'", ",", "'MO'", ",", "'PFT'", ",", "'AR'", "]", "\n", "# mace_baseline = 'MACE_eps_1e-5'", "\n", "mace_baseline", "=", "'MACE_eps_1e-2'", "\n", "\n", "# Remove FeatureTweaking / ActionableRecourse distances that were unsuccessful or non-plausible", "\n", "df_all_distances", "=", "pickle", ".", "load", "(", "open", "(", "f'_results/df_all_distances'", ",", "'rb'", ")", ")", "\n", "df_all_distances", "=", "df_all_distances", ".", "where", "(", "\n", "(", "df_all_distances", "[", "'counterfactual found'", "]", "==", "True", ")", "&", "\n", "(", "df_all_distances", "[", "'counterfactual plausible'", "]", "==", "True", ")", "\n", ")", ".", "dropna", "(", ")", "\n", "\n", "print", "(", "'Analyzing merged distance files.'", ")", "\n", "\n", "df", "=", "df_all_distances", "\n", "\n", "MIN_SAMPLES_REQUIRED", "=", "0", "\n", "\n", "for", "model_class_string", "in", "MODEL_CLASS_VALUES", ":", "\n", "    ", "for", "dataset_string", "in", "DATASET_VALUES", ":", "\n", "      ", "for", "norm_type_string", "in", "NORM_VALUES", ":", "\n", "\n", "# speficic dataset, speficic model, speficic norm, all approaches", "\n", "        ", "df", "=", "df_all_distances", ".", "where", "(", "\n", "(", "df_all_distances", "[", "'dataset'", "]", "==", "dataset_string", ")", "&", "\n", "(", "df_all_distances", "[", "'model'", "]", "==", "model_class_string", ")", "&", "\n", "(", "df_all_distances", "[", "'norm'", "]", "==", "norm_type_string", ")", ",", "\n", "# inplace = True", "\n", ")", ".", "dropna", "(", ")", "\n", "\n", "if", "df", ".", "shape", "[", "0", "]", ":", "# if any tests exist for this setup", "\n", "\n", "          ", "tmp_string", "=", "f'{dataset_string}-{model_class_string}-{norm_type_string}'", "\n", "\n", "# for each approach, get the index of factual samples for which counterfactuals were computed", "\n", "factual_sample_index_per_approach", "=", "{", "}", "\n", "for", "approach_string", "in", "APPROACHES_VALUES", ":", "\n", "            ", "factual_sample_index_per_approach", "[", "approach_string", "]", "=", "np", ".", "unique", "(", "df", ".", "where", "(", "df", "[", "'approach'", "]", "==", "approach_string", ")", ".", "dropna", "(", ")", "[", "'factual sample index'", "]", ")", "\n", "\n", "# # MACE works in all scenarios", "\n", "# assert \\", "\n", "#   len(factual_sample_index_per_approach['MACE_eps_1e-5']) >= MIN_SAMPLES_REQUIRED, \\", "\n", "#   f'Expecting at least {MIN_SAMPLES_REQUIRED} samples for MACE, got {len(factual_sample_index_per_approach[\"MACE\"])} ({tmp_string})'", "\n", "\n", "# # MO works in all scenarios", "\n", "# assert \\", "\n", "#   len(factual_sample_index_per_approach['MO']) >= MIN_SAMPLES_REQUIRED, \\", "\n", "#   f'Expecting at least {MIN_SAMPLES_REQUIRED} samples for MO, got {len(factual_sample_index_per_approach[\"MO\"])} ({tmp_string})'", "\n", "\n", "# # TODO: FT works in all scenarios, except for adult tree??????", "\n", "# if model_class_string == 'tree' or model_class_string == 'forest':", "\n", "#   assert \\", "\n", "#     len(factual_sample_index_per_approach['PFT']) >= MIN_SAMPLES_REQUIRED, \\", "\n", "#     f'Expecting at least {MIN_SAMPLES_REQUIRED} samples for PFT, got {len(factual_sample_index_per_approach[\"PFT\"])} ({tmp_string})'", "\n", "\n", "# # AR works in all scenarios, except for zero-norm", "\n", "# if model_class_string == 'lr':", "\n", "#   if norm_type_string != 'zero_norm':", "\n", "#     assert \\", "\n", "#       len(factual_sample_index_per_approach['AR']) >= MIN_SAMPLES_REQUIRED, \\", "\n", "#       f'Expecting at least {MIN_SAMPLES_REQUIRED} samples for AR, got {len(factual_sample_index_per_approach[\"AR\"])} ({tmp_string})'", "\n", "\n", "# remove keys that don't have any factual sample indices", "\n", "", "tmp", "=", "factual_sample_index_per_approach", "\n", "tmp", "=", "dict", "(", "(", "key", ",", "value", ")", "for", "(", "key", ",", "value", ")", "in", "tmp", ".", "items", "(", ")", "if", "len", "(", "tmp", "[", "key", "]", ")", ">", "0", ")", "\n", "factual_sample_index_per_approach", "=", "tmp", "\n", "# for key in factual_sample_index_per_approach.keys():", "\n", "#   print(f'key: {key}, num factual samples: {len(factual_sample_index_per_approach[key])}')", "\n", "\n", "# compute 1 - d_MACE / d_{MO, FT, ...}", "\n", "all_but_mace_approaches", "=", "list", "(", "np", ".", "setdiff1d", "(", "\n", "np", ".", "array", "(", "list", "(", "factual_sample_index_per_approach", ".", "keys", "(", ")", ")", ")", ",", "\n", "np", ".", "array", "(", "mace_baseline", ")", "\n", ")", ")", "\n", "factual_sample_index_intersect", "=", "[", "]", "\n", "for", "approach_string", "in", "all_but_mace_approaches", ":", "\n", "            ", "factual_sample_index_intersect", "=", "np", ".", "intersect1d", "(", "\n", "factual_sample_index_per_approach", "[", "mace_baseline", "]", ",", "\n", "factual_sample_index_per_approach", "[", "approach_string", "]", "\n", ")", "\n", "assert", "len", "(", "factual_sample_index_intersect", ")", ">=", "MIN_SAMPLES_REQUIRED", ",", "f'Expecting at least {MIN_SAMPLES_REQUIRED} intersecting samples between MACE and {approach_string}'", "\n", "distance_reduction_list", "=", "[", "]", "\n", "for", "factual_sample_index", "in", "factual_sample_index_intersect", ":", "\n", "              ", "sample_mace", "=", "df", ".", "where", "(", "\n", "(", "df", "[", "'approach'", "]", "==", "mace_baseline", ")", "&", "\n", "(", "df", "[", "'factual sample index'", "]", "==", "factual_sample_index", ")", "\n", ")", ".", "dropna", "(", ")", ".", "T", ".", "to_dict", "(", ")", "\n", "assert", "len", "(", "sample_mace", ".", "keys", "(", ")", ")", "==", "1", ",", "f'Expecting only 1 sample with index {factual_sample_index} for approach {approach_string}'", "\n", "sample_other", "=", "df", ".", "where", "(", "\n", "(", "df", "[", "'approach'", "]", "==", "approach_string", ")", "&", "\n", "(", "df", "[", "'factual sample index'", "]", "==", "factual_sample_index", ")", "\n", ")", ".", "dropna", "(", ")", ".", "T", ".", "to_dict", "(", ")", "\n", "assert", "len", "(", "sample_other", ".", "keys", "(", ")", ")", "==", "1", ",", "f'Expecting only 1 sample with index {factual_sample_index} for approach {approach_string}'", "\n", "minimum_distance_mace", "=", "sample_mace", "[", "list", "(", "sample_mace", ".", "keys", "(", ")", ")", "[", "0", "]", "]", "[", "'counterfactual distance'", "]", "\n", "minimum_distance_other", "=", "sample_other", "[", "list", "(", "sample_other", ".", "keys", "(", ")", ")", "[", "0", "]", "]", "[", "'counterfactual distance'", "]", "\n", "distance_reduction_list", ".", "append", "(", "1", "-", "minimum_distance_mace", "/", "minimum_distance_other", ")", "\n", "", "tmp_mean", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "distance_reduction_list", ")", ")", "*", "100", "\n", "tmp_std", "=", "np", ".", "std", "(", "np", ".", "array", "(", "distance_reduction_list", ")", ")", "*", "100", "\n", "print", "(", "f'\\t Distance reduction for {dataset_string} {model_class_string} {norm_type_string} (1 - d_MACE / d_{approach_string}) = \\t {tmp_mean:.2f} +/- {tmp_std:.2f} \\t (N = {len(distance_reduction_list)})'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.analyzeResults.analyzeAverageDistanceRunTimeCoverage": [[545, 596], ["pickle.load", "open", "pickle.load.where().dropna", "df_all_distances.where().dropna.where", "df_all_distances.where().dropna.where", "df_all_distances.where().dropna.where", "found_and_plausible[].mean", "found_and_plausible[].std", "found_and_plausible[].mean", "found_and_plausible[].std", "print", "print", "print", "print", "pickle.load.where", "df.where.dropna", "df.where.dropna", "df.where.dropna"], "function", ["None"], ["", "", "", "", "", "", "def", "analyzeAverageDistanceRunTimeCoverage", "(", ")", ":", "\n", "  ", "DATASET_VALUES", "=", "[", "'adult'", ",", "'credit'", ",", "'compass'", "]", "\n", "MODEL_CLASS_VALUES", "=", "[", "'tree'", ",", "'forest'", ",", "'lr'", "]", "# , 'mlp']", "\n", "NORM_VALUES", "=", "[", "'zero_norm'", ",", "'one_norm'", ",", "'infty_norm'", "]", "\n", "# APPROACHES_VALUES = ['MACE_eps_1e-3', 'MACE_eps_1e-5', 'MO', 'PFT', 'AR']", "\n", "APPROACHES_VALUES", "=", "[", "'MACE_eps_1e-2'", ",", "'MACE_eps_1e-3'", ",", "'MACE_eps_1e-5'", "]", "\n", "\n", "# DATASET_VALUES = ['adult', 'credit', 'compass']", "\n", "# MODEL_CLASS_VALUES = ['mlp']", "\n", "# NORM_VALUES = ['zero_norm', 'one_norm', 'infty_norm']", "\n", "# APPROACHES_VALUES = ['MACE_eps_1e-3', 'MACE_eps_1e-5']", "\n", "\n", "# APPROACHES_VALUES = ['MACE_eps_1e-3', 'MACE_eps_1e-5', 'MO'] # COVERAGE = %100 ALWAYS", "\n", "# APPROACHES_VALUES = ['PFT', 'AR']", "\n", "# Remove FeatureTweaking / ActionableRecourse distances that were unsuccessful or non-plausible", "\n", "df_all_distances", "=", "pickle", ".", "load", "(", "open", "(", "f'_results/df_all_distances'", ",", "'rb'", ")", ")", "\n", "# DO NOT INCLUDE THE LINES BELOW!!!!!!!!!!!!!!!!!!!! WHY??? B/c we want to count statistics below", "\n", "# df_all_distances = df_all_distances.where(", "\n", "#   (df_all_distances['counterfactual found'] == True) &", "\n", "#   (df_all_distances['counterfactual plausible'] == True)", "\n", "# ).dropna()", "\n", "for", "model_class_string", "in", "MODEL_CLASS_VALUES", ":", "\n", "    ", "for", "approach_string", "in", "APPROACHES_VALUES", ":", "\n", "      ", "for", "dataset_string", "in", "DATASET_VALUES", ":", "\n", "        ", "for", "norm_type_string", "in", "NORM_VALUES", ":", "\n", "          ", "df", "=", "df_all_distances", ".", "where", "(", "\n", "(", "df_all_distances", "[", "'dataset'", "]", "==", "dataset_string", ")", "&", "\n", "(", "df_all_distances", "[", "'model'", "]", "==", "model_class_string", ")", "&", "\n", "(", "df_all_distances", "[", "'norm'", "]", "==", "norm_type_string", ")", "&", "\n", "(", "df_all_distances", "[", "'approach'", "]", "==", "approach_string", ")", ",", "\n", ")", ".", "dropna", "(", ")", "\n", "if", "df", ".", "shape", "[", "0", "]", ":", "# if any tests exist for this setup", "\n", "            ", "found_and_plausible", "=", "df", ".", "where", "(", "(", "df", "[", "'counterfactual found'", "]", "==", "True", ")", "&", "(", "df", "[", "'counterfactual plausible'", "]", "==", "True", ")", ")", "\n", "found_and_not_plausible", "=", "df", ".", "where", "(", "(", "df", "[", "'counterfactual found'", "]", "==", "True", ")", "&", "(", "df", "[", "'counterfactual plausible'", "]", "==", "False", ")", ")", "\n", "not_found", "=", "df", ".", "where", "(", "df", "[", "'counterfactual found'", "]", "==", "False", ")", "\n", "count_found_and_plausible", "=", "found_and_plausible", ".", "dropna", "(", ")", ".", "shape", "[", "0", "]", "\n", "count_found_and_not_plausible", "=", "found_and_not_plausible", ".", "dropna", "(", ")", ".", "shape", "[", "0", "]", "\n", "count_not_found", "=", "not_found", ".", "dropna", "(", ")", ".", "shape", "[", "0", "]", "\n", "assert", "df", ".", "shape", "[", "0", "]", "==", "count_found_and_plausible", "+", "count_found_and_not_plausible", "+", "count_not_found", "\n", "average_distance", "=", "found_and_plausible", "[", "'counterfactual distance'", "]", ".", "mean", "(", ")", "# this is NOT a good way to compare methods! see analyzeRelativeDistances() instead, as it compares ratio of distances for the same samples!", "\n", "std_distance", "=", "found_and_plausible", "[", "'counterfactual distance'", "]", ".", "std", "(", ")", "\n", "average_run_time", "=", "found_and_plausible", "[", "'counterfactual time'", "]", ".", "mean", "(", ")", "\n", "std_run_time", "=", "found_and_plausible", "[", "'counterfactual time'", "]", ".", "std", "(", ")", "\n", "coverage", "=", "count_found_and_plausible", "/", "df", ".", "shape", "[", "0", "]", "*", "100", "\n", "print", "(", "f'{model_class_string}-{approach_string}-{dataset_string}-{norm_type_string} ({count_found_and_plausible} plausible samples found):'", ")", "\n", "print", "(", "f'\\tAvg distance: {average_distance:.2f} +/- {std_distance:.2f}'", ")", "\n", "print", "(", "f'\\tAvg run-time: {average_run_time:.2f} +/- {std_run_time:.2f} seconds'", ")", "\n", "print", "(", "f'\\tCoverage: %{coverage}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.analyzeResults.plotAllDistancesAppendix": [[670, 755], ["pickle.load", "df_all_distances.where().dropna.where().dropna", "df_all_distances[].map", "df_all_distances[].map", "df_all_distances[].map", "print", "open", "df_all_distances.where().dropna.where().dropna", "analyzeResults.latexify", "seaborn.set_style", "seaborn.catplot", "[].legend().remove", "[].legend", "sns.catplot.set", "sns.catplot.set_axis_labels", "sns.catplot.set_titles", "sns.catplot.set_xlabels", "sns.catplot.savefig", "df_all_distances.where().dropna.where", "hue_order.extend", "df_all_distances.where().dropna.where", "hue_order.extend", "seaborn.color_palette", "[].legend", "hue_order.extend", "sns.catplot.fig.get_axes", "sns.catplot.fig.get_axes"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.analyzeResults.latexify"], ["", "", "", "", "", "", "def", "plotAllDistancesAppendix", "(", ")", ":", "\n", "  ", "MODEL_CLASS_VALUES", "=", "[", "'tree'", ",", "'forest'", ",", "'lr'", ",", "'mlp'", "]", "\n", "# MODEL_CLASS_VALUES = ['lr']", "\n", "\n", "# tmp_constrained = 'constrained'", "\n", "tmp_constrained", "=", "'unconstrained'", "\n", "# Remove FeatureTweaking / ActionableRecourse distances that were unsuccessful or non-plausible", "\n", "df_all_distances", "=", "pickle", ".", "load", "(", "open", "(", "f'_results/_bu_df_all_distances_{tmp_constrained}_old'", ",", "'rb'", ")", ")", "\n", "\n", "# Remove FeatureTweaking / ActionableRecourse distances that were unsuccessful or non-plausible", "\n", "df_all_distances", "=", "df_all_distances", ".", "where", "(", "\n", "(", "df_all_distances", "[", "'counterfactual found'", "]", "==", "True", ")", "&", "\n", "(", "df_all_distances", "[", "'counterfactual plausible'", "]", "==", "True", ")", "\n", ")", ".", "dropna", "(", ")", "\n", "\n", "# change norms for plotting??????", "\n", "# df_all_distances = df_all_distances.where(df_all_distances['norm'] != 'zero_norm').dropna()", "\n", "\n", "df_all_distances", "[", "'norm'", "]", "=", "df_all_distances", "[", "'norm'", "]", ".", "map", "(", "{", "\n", "'zero_norm'", ":", "r'$\\ell_0$'", ",", "\n", "'one_norm'", ":", "r'$\\ell_1$'", ",", "\n", "'infty_norm'", ":", "r'$\\ell_\\infty$'", ",", "\n", "}", ")", "\n", "\n", "df_all_distances", "[", "'dataset'", "]", "=", "df_all_distances", "[", "'dataset'", "]", ".", "map", "(", "{", "\n", "'adult'", ":", "'Adult'", ",", "\n", "'credit'", ":", "'Credit'", ",", "\n", "'compass'", ":", "'COMPAS'", ",", "\n", "}", ")", "\n", "\n", "df_all_distances", "[", "'approach'", "]", "=", "df_all_distances", "[", "'approach'", "]", ".", "map", "(", "{", "\n", "# 'MACE_eps_1e-1': r'MACE ($\\epsilon = 10^{-1}$)',", "\n", "# 'MACE_eps_1e-2': r'MACE ($\\epsilon = 10^{-2}$)',", "\n", "'MACE_eps_1e-3'", ":", "r'MACE ($\\epsilon = 10^{-3}$)'", ",", "\n", "'MACE_eps_1e-5'", ":", "r'MACE ($\\epsilon = 10^{-5}$)'", ",", "\n", "'MO'", ":", "'MO'", ",", "\n", "'PFT'", ":", "'PFT'", ",", "\n", "'AR'", ":", "'AR'", ",", "\n", "}", ")", "\n", "\n", "print", "(", "'Plotting merged distance files.'", ")", "\n", "\n", "for", "model_string", "in", "MODEL_CLASS_VALUES", ":", "\n", "\n", "    ", "model_specific_df", "=", "df_all_distances", ".", "where", "(", "df_all_distances", "[", "'model'", "]", "==", "model_string", ")", ".", "dropna", "(", ")", "\n", "\n", "# hue_order = [r'MACE ($\\epsilon = 10^{-1}$)', r'MACE ($\\epsilon = 10^{-3}$)', r'MACE ($\\epsilon = 10^{-5}$)']", "\n", "# hue_order = [r'MACE ($\\epsilon = 10^{-2}$)', r'MACE ($\\epsilon = 10^{-3}$)', r'MACE ($\\epsilon = 10^{-5}$)']", "\n", "hue_order", "=", "[", "r'MACE ($\\epsilon = 10^{-3}$)'", ",", "r'MACE ($\\epsilon = 10^{-5}$)'", "]", "\n", "# hue_order = [r'MACE ($\\epsilon = 10^{-3}$)']", "\n", "if", "model_string", "==", "'tree'", "or", "model_string", "==", "'forest'", ":", "\n", "      ", "hue_order", ".", "extend", "(", "[", "'MO'", ",", "'PFT'", "]", ")", "\n", "", "elif", "model_string", "==", "'lr'", ":", "\n", "      ", "hue_order", ".", "extend", "(", "[", "'MO'", ",", "'AR'", "]", ")", "\n", "", "elif", "model_string", "==", "'mlp'", ":", "\n", "      ", "hue_order", ".", "extend", "(", "[", "'MO'", "]", ")", "\n", "\n", "", "latexify", "(", "1.5", "*", "6", ",", "6", ",", "font_scale", "=", "1.2", ")", "\n", "sns", ".", "set_style", "(", "\"whitegrid\"", ")", "\n", "ax", "=", "sns", ".", "catplot", "(", "\n", "x", "=", "'dataset'", ",", "\n", "y", "=", "'counterfactual distance'", ",", "\n", "hue", "=", "'approach'", ",", "\n", "hue_order", "=", "hue_order", ",", "\n", "col", "=", "'norm'", ",", "\n", "data", "=", "model_specific_df", ",", "\n", "kind", "=", "'box'", ",", "\n", "# kind = 'violin',", "\n", "# kind = 'swarm',", "\n", "height", "=", "3.5", ",", "\n", "aspect", "=", ".9", ",", "\n", "palette", "=", "sns", ".", "color_palette", "(", "\"muted\"", ",", "5", ")", ",", "\n", "sharey", "=", "False", ",", "\n", "whis", "=", "np", ".", "inf", ",", "\n", "legend_out", "=", "False", ",", "\n", ")", "\n", "# ax.legend(loc = 'lower left', ncol = 1, fancybox = True, shadow = True, fontsize = 'small')", "\n", "# ax.fig.get_children()[-1].set_bbox_to_anchor((1.1, 0.5, 0, 0))", "\n", "ax", ".", "fig", ".", "get_axes", "(", ")", "[", "0", "]", ".", "legend", "(", ")", ".", "remove", "(", ")", "\n", "ax", ".", "fig", ".", "get_axes", "(", ")", "[", "2", "]", ".", "legend", "(", "loc", "=", "'upper left'", ",", "fancybox", "=", "True", ",", "shadow", "=", "True", ",", "fontsize", "=", "'small'", ")", "\n", "ax", ".", "set", "(", "ylim", "=", "(", "0", ",", "None", ")", ")", "\n", "ax", ".", "set_axis_labels", "(", "\"\"", ",", "r\"Distance $\\delta$ to\"", "+", "\"\\nNearest Counterfactual\"", ")", "\n", "ax", ".", "set_titles", "(", "'{col_name}'", ")", "\n", "ax", ".", "set_xlabels", "(", ")", "# remove \"dataset\" on the x-axis", "\n", "ax", ".", "savefig", "(", "f'_results/{tmp_constrained}__all_distances_appendix__{model_string}.png'", ",", "dpi", "=", "400", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.analyzeResults.plotAvgDistanceRunTimeCoverageTradeoffAgainstIterations": [[757, 903], ["pickle.load", "pickle.load", "pickle.load.apply", "df_all_distances[].map", "df_all_distance_vs_time[].map", "df_all_distances[].map", "df_all_distance_vs_time[].map", "open", "open", "approach_order.extend", "print", "pickle.load.where().dropna", "pickle.load.where().dropna", "seaborn.set_style", "matplotlib.subplots", "ax1.set", "ax2.set", "seaborn.lineplot", "seaborn.lineplot", "ax2.legend", "ax1.set_xlabel", "ax1.set_ylabel", "ax2.set_xlabel", "ax2.set_ylabel", "fig.tight_layout", "fig.savefig", "approach_order.extend", "approach_order.extend", "pickle.load.where", "pickle.load.where"], "function", ["None"], ["", "", "def", "plotAvgDistanceRunTimeCoverageTradeoffAgainstIterations", "(", ")", ":", "\n", "\n", "  ", "MODEL_CLASS_VALUES", "=", "[", "'tree'", ",", "'forest'", ",", "'lr'", ",", "'mlp'", "]", "\n", "NORM_VALUES", "=", "[", "'one_norm'", "]", "\n", "\n", "# tmp_constrained = 'constrained'", "\n", "tmp_constrained", "=", "'unconstrained'", "\n", "# Remove FeatureTweaking / ActionableRecourse distances that were unsuccessful or non-plausible", "\n", "df_all_distances", "=", "pickle", ".", "load", "(", "open", "(", "f'_results/_bu_df_all_distances_{tmp_constrained}_old'", ",", "'rb'", ")", ")", "\n", "df_all_distance_vs_time", "=", "pickle", ".", "load", "(", "open", "(", "f'_results/_bu_df_all_distance_vs_time_{tmp_constrained}_old'", ",", "'rb'", ")", ")", "\n", "\n", "# df_all_distance_vs_time = df_all_distance_vs_time.where(df_all_distance_vs_time['iteration'] <= 10).dropna()", "\n", "\n", "\n", "df_all_distances", "[", "'counterfactual found and plausible'", "]", "=", "df_all_distances", ".", "apply", "(", "\n", "lambda", "row", ":", "row", "[", "'counterfactual found'", "]", "and", "row", "[", "'counterfactual plausible'", "]", ",", "\n", "axis", "=", "1", "\n", ")", "\n", "\n", "# df_all_distance_vs_time['norm'] = df_all_distance_vs_time['norm'].map({", "\n", "#   'zero_norm': r'$\\ell_0$',", "\n", "#   'one_norm': r'$\\ell_1$',", "\n", "#   'infty_norm': r'$\\ell_\\infty$',", "\n", "# })", "\n", "\n", "df_all_distances", "[", "'dataset'", "]", "=", "df_all_distances", "[", "'dataset'", "]", ".", "map", "(", "{", "\n", "'adult'", ":", "'Adult'", ",", "\n", "'credit'", ":", "'Credit'", ",", "\n", "'compass'", ":", "'COMPAS'", ",", "\n", "}", ")", "\n", "\n", "df_all_distance_vs_time", "[", "'dataset'", "]", "=", "df_all_distance_vs_time", "[", "'dataset'", "]", ".", "map", "(", "{", "\n", "'adult'", ":", "'Adult'", ",", "\n", "'credit'", ":", "'Credit'", ",", "\n", "'compass'", ":", "'COMPAS'", ",", "\n", "}", ")", "\n", "\n", "df_all_distances", "[", "'approach'", "]", "=", "df_all_distances", "[", "'approach'", "]", ".", "map", "(", "{", "\n", "# 'MACE_eps_1e-1': r'MACE ($\\epsilon = 10^{-1}$)',", "\n", "'MACE_eps_1e-2'", ":", "r'MACE ($\\epsilon = 10^{-2}$)'", ",", "\n", "'MACE_eps_1e-3'", ":", "r'MACE ($\\epsilon = 10^{-3}$)'", ",", "\n", "'MACE_eps_1e-5'", ":", "r'MACE ($\\epsilon = 10^{-5}$)'", ",", "\n", "'MO'", ":", "'MO'", ",", "\n", "'PFT'", ":", "'PFT'", ",", "\n", "'AR'", ":", "'AR'", ",", "\n", "}", ")", "\n", "\n", "df_all_distance_vs_time", "[", "'approach'", "]", "=", "df_all_distance_vs_time", "[", "'approach'", "]", ".", "map", "(", "{", "\n", "# 'MACE_eps_1e-1': r'MACE ($\\epsilon = 10^{-1}$)',", "\n", "'MACE_eps_1e-2'", ":", "r'MACE ($\\epsilon = 10^{-2}$)'", ",", "\n", "'MACE_eps_1e-3'", ":", "r'MACE ($\\epsilon = 10^{-3}$)'", ",", "\n", "'MACE_eps_1e-5'", ":", "r'MACE ($\\epsilon = 10^{-5}$)'", ",", "\n", "'MO'", ":", "'MO'", ",", "\n", "'PFT'", ":", "'PFT'", ",", "\n", "'AR'", ":", "'AR'", ",", "\n", "}", ")", "\n", "\n", "for", "model_class_string", "in", "MODEL_CLASS_VALUES", ":", "\n", "\n", "    ", "dataset_order", "=", "[", "'Adult'", ",", "'Credit'", ",", "'COMPAS'", "]", "\n", "\n", "approach_order", "=", "[", "r'MACE ($\\epsilon = 10^{-2}$)'", ",", "r'MACE ($\\epsilon = 10^{-3}$)'", ",", "r'MACE ($\\epsilon = 10^{-5}$)'", "]", "\n", "# approach_order = [r'MACE ($\\epsilon = 10^{-3}$)', r'MACE ($\\epsilon = 10^{-5}$)']", "\n", "# approach_order = [r'MACE ($\\epsilon = 10^{-3}$)']", "\n", "if", "model_class_string", "==", "'tree'", "or", "model_class_string", "==", "'forest'", ":", "\n", "      ", "approach_order", ".", "extend", "(", "[", "'MO'", ",", "'PFT'", "]", ")", "\n", "", "elif", "model_class_string", "==", "'lr'", ":", "\n", "      ", "approach_order", ".", "extend", "(", "[", "'MO'", ",", "'AR'", "]", ")", "\n", "", "elif", "model_class_string", "==", "'mlp'", ":", "\n", "      ", "approach_order", ".", "extend", "(", "[", "'MO'", "]", ")", "\n", "\n", "", "for", "norm_type_string", "in", "NORM_VALUES", ":", "\n", "\n", "      ", "print", "(", "f'[INFO] Processing {model_class_string}-{norm_type_string}...'", ")", "\n", "\n", "tmp_df", "=", "df_all_distance_vs_time", ".", "where", "(", "\n", "# (df_all_distance_vs_time['dataset'] == 'credit') &", "\n", "(", "df_all_distance_vs_time", "[", "'model'", "]", "==", "model_class_string", ")", "&", "\n", "# (df_all_distance_vs_time['approach'] == 'AR') &", "\n", "(", "df_all_distance_vs_time", "[", "'norm'", "]", "==", "norm_type_string", ")", ",", "# &", "\n", ")", ".", "dropna", "(", ")", "\n", "\n", "tmp_df_2", "=", "df_all_distances", ".", "where", "(", "\n", "# (df_all_distances['dataset'] == 'credit') &", "\n", "(", "df_all_distances", "[", "'model'", "]", "==", "model_class_string", ")", "&", "\n", "# (df_all_distances['approach'] == 'AR') &", "\n", "(", "df_all_distances", "[", "'norm'", "]", "==", "norm_type_string", ")", ",", "# &", "\n", ")", ".", "dropna", "(", ")", "\n", "\n", "# fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 6))", "\n", "sns", ".", "set_style", "(", "\"whitegrid\"", ")", "\n", "fig", ",", "(", "ax1", ",", "ax2", ")", "=", "plt", ".", "subplots", "(", "1", ",", "2", ",", "figsize", "=", "(", "14", ",", "4", ")", ")", "\n", "\n", "ax1", ".", "set", "(", "yscale", "=", "\"log\"", ")", "\n", "ax2", ".", "set", "(", "yscale", "=", "\"log\"", ")", "\n", "sns", ".", "lineplot", "(", "\n", "x", "=", "\"iteration\"", ",", "\n", "y", "=", "\"time\"", ",", "\n", "style", "=", "'dataset'", ",", "\n", "style_order", "=", "dataset_order", ",", "\n", "hue", "=", "\"approach\"", ",", "\n", "hue_order", "=", "approach_order", ",", "\n", "markers", "=", "False", ",", "\n", "dashes", "=", "True", ",", "\n", "data", "=", "tmp_df", ",", "\n", "legend", "=", "False", ",", "\n", "ax", "=", "ax1", ")", "\n", "sns", ".", "lineplot", "(", "\n", "x", "=", "\"iteration\"", ",", "\n", "y", "=", "\"distance\"", ",", "\n", "style", "=", "'dataset'", ",", "\n", "style_order", "=", "dataset_order", ",", "\n", "hue", "=", "\"approach\"", ",", "\n", "hue_order", "=", "approach_order", ",", "\n", "markers", "=", "False", ",", "\n", "dashes", "=", "True", ",", "\n", "data", "=", "tmp_df", ",", "\n", "legend", "=", "'full'", ",", "\n", "ax", "=", "ax2", ")", "\n", "# sns.barplot(", "\n", "#   x = 'dataset',", "\n", "#   y = 'counterfactual found and plausible',", "\n", "#   hue = 'approach',", "\n", "#   hue_order = approach_order,", "\n", "#   data = tmp_df_2,", "\n", "#   ax = ax3)", "\n", "\n", "# ax1.set(ylim = (0, 60))", "\n", "# ax2.set(ylim = (0, 0.5))", "\n", "# ax2.legend(loc = 'upper center', bbox_to_anchor = (-.1, 1.15), ncol = 5, fancybox = True, shadow = True)", "\n", "# ax2.legend(loc = 'center left', bbox_to_anchor = (1, 0.5))", "\n", "# ax1.legend(loc = 'lower right', ncol = 2, fancybox = True, shadow = True, fontsize = 'small')", "\n", "# ax2.legend(loc = 'upper right', ncol = 2, fancybox = True, shadow = True, fontsize = 'small')", "\n", "ax2", ".", "legend", "(", "loc", "=", "'lower left'", ",", "ncol", "=", "2", ",", "fancybox", "=", "True", ",", "shadow", "=", "True", ",", "fontsize", "=", "'small'", ")", "\n", "# ax3.legend(loc = 'lower center', ncol = 1, fancybox = True, shadow = True, fontsize = 'small')", "\n", "\n", "\n", "ax1", ".", "set_xlabel", "(", "r\"# Calls to SAT Solver - $O(\\log(1 / \\epsilon))$\"", ")", "\n", "ax1", ".", "set_ylabel", "(", "r\"Time $\\tau$ to compute\"", "+", "\"\\nNearest Counterfactual\"", ")", "\n", "ax2", ".", "set_xlabel", "(", "r\"# Calls to SAT Solver - $O(\\log(1 / \\epsilon))$\"", ")", "\n", "ax2", ".", "set_ylabel", "(", "r\"Distance $\\delta$ to\"", "+", "\"\\nNearest Counterfactual\"", ")", "\n", "# ax3.set_xlabel('') # remove \"dataset\" on the x-axis", "\n", "# ax3.set_ylabel(r\"Coverage $\\Omega$\")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "f'_results/{tmp_constrained}__avg_tradeoff__{model_class_string}_{norm_type_string}.png'", ",", "dpi", "=", "300", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.analyzeResults.compareMACEandMINT": [[958, 970], ["pickle.load", "numpy.array", "numpy.array", "numpy.mean", "numpy.std", "print", "open"], "function", ["None"], ["", "", "", "def", "compareMACEandMINT", "(", ")", ":", "\n", "  ", "df_all_distances", "=", "pickle", ".", "load", "(", "open", "(", "f'_results/df_all_distances'", ",", "'rb'", ")", ")", "\n", "df", "=", "df_all_distances", "\n", "counterfactual_distances", "=", "np", ".", "array", "(", "df", "[", "'counterfactual distance'", "]", ")", "\n", "counterfactual_distances", "[", "counterfactual_distances", ">", "1", "]", "=", "1", "\n", "counterfactual_distances", "=", "counterfactual_distances", "[", "counterfactual_distances", "!=", "0", "]", "\n", "interventional_distances", "=", "np", ".", "array", "(", "df", "[", "'interventional distance'", "]", ")", "\n", "interventional_distances", "[", "interventional_distances", ">", "1", "]", "=", "1", "\n", "interventional_distances", "=", "interventional_distances", "[", "interventional_distances", "!=", "0", "]", "\n", "mean_distance_ratio", "=", "np", ".", "mean", "(", "counterfactual_distances", "/", "interventional_distances", ")", "\n", "std_distance_ratio", "=", "np", ".", "std", "(", "counterfactual_distances", "/", "interventional_distances", ")", "\n", "print", "(", "f'MACE / MINT distances: {mean_distance_ratio:.4f} +/- {std_distance_ratio:.4f}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.getModelFormula": [[32, 45], ["isinstance", "model2formula", "isinstance", "modelConversion.tree2formula", "isinstance", "modelConversion.lr2formula", "isinstance", "modelConversion.forest2formula", "modelConversion.mlp2formula"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.modelConversion.tree2formula", "home.repos.pwc.inspect_result.amirhk_mace.None.modelConversion.lr2formula", "home.repos.pwc.inspect_result.amirhk_mace.None.modelConversion.forest2formula", "home.repos.pwc.inspect_result.amirhk_mace.None.modelConversion.mlp2formula"], ["def", "getModelFormula", "(", "model_symbols", ",", "model_trained", ")", ":", "\n", "  ", "if", "isinstance", "(", "model_trained", ",", "DecisionTreeClassifier", ")", ":", "\n", "    ", "model2formula", "=", "lambda", "a", ",", "b", ":", "tree2formula", "(", "a", ",", "b", ")", "\n", "", "elif", "isinstance", "(", "model_trained", ",", "LogisticRegression", ")", ":", "\n", "    ", "model2formula", "=", "lambda", "a", ",", "b", ":", "lr2formula", "(", "a", ",", "b", ")", "\n", "", "elif", "isinstance", "(", "model_trained", ",", "RandomForestClassifier", ")", ":", "\n", "    ", "model2formula", "=", "lambda", "a", ",", "b", ":", "forest2formula", "(", "a", ",", "b", ")", "\n", "", "elif", "isinstance", "(", "model_trained", ",", "MLPClassifier", ")", ":", "\n", "    ", "model2formula", "=", "lambda", "a", ",", "b", ":", "mlp2formula", "(", "a", ",", "b", ")", "\n", "\n", "", "return", "model2formula", "(", "\n", "model_trained", ",", "\n", "model_symbols", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.getCounterfactualFormula": [[47, 51], ["EqualsOrIff", "Not"], "function", ["None"], ["", "def", "getCounterfactualFormula", "(", "model_symbols", ",", "factual_sample", ")", ":", "\n", "  ", "return", "EqualsOrIff", "(", "\n", "model_symbols", "[", "'output'", "]", "[", "'y'", "]", "[", "'symbol'", "]", ",", "\n", "Not", "(", "factual_sample", "[", "'y'", "]", ")", "\n", ")", "# meaning we want the decision to be flipped.", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.getDistanceFormula": [[54, 283], ["dataset_obj.getMutableAttributeNames", "dataset_obj.getOneHotAttributesNames", "dataset_obj.getNonHotAttributesNames", "numpy.intersect1d", "numpy.intersect1d", "Ite", "normalized_absolute_distances.append", "normalized_squared_distances.append", "LE", "GE", "Minus", "Minus", "Div", "Pow", "dataset_obj.getSiblingsFor", "already_considered.extend", "Times", "Real", "LE", "Minus", "Real", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal", "Div", "Real", "normalized_absolute_distances.append", "normalized_squared_distances.append", "Real", "Plus", "Times", "Real", "LE", "ToReal", "ToReal", "generateSATExplanations.getDistanceFormula.getAbsoluteDifference"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getMutableAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getOneHotAttributesNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getNonHotAttributesNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getSiblingsFor"], ["", "def", "getDistanceFormula", "(", "model_symbols", ",", "dataset_obj", ",", "factual_sample", ",", "norm_type", ",", "approach_string", ",", "norm_threshold", ")", ":", "\n", "\n", "  ", "if", "'mace'", "in", "approach_string", ":", "\n", "    ", "variable_to_compute_distance_on", "=", "'counterfactual'", "\n", "", "elif", "'mint'", "in", "approach_string", ":", "\n", "    ", "variable_to_compute_distance_on", "=", "'interventional'", "\n", "\n", "\n", "", "def", "getAbsoluteDifference", "(", "symbol_1", ",", "symbol_2", ")", ":", "\n", "    ", "return", "Ite", "(", "\n", "GE", "(", "Minus", "(", "ToReal", "(", "symbol_1", ")", ",", "ToReal", "(", "symbol_2", ")", ")", ",", "Real", "(", "0", ")", ")", ",", "\n", "Minus", "(", "ToReal", "(", "symbol_1", ")", ",", "ToReal", "(", "symbol_2", ")", ")", ",", "\n", "Minus", "(", "ToReal", "(", "symbol_2", ")", ",", "ToReal", "(", "symbol_1", ")", ")", "\n", ")", "\n", "\n", "# normalize this feature's distance by dividing the absolute difference by the", "\n", "# range of the variable (only applies for non-hot variables)", "\n", "", "normalized_absolute_distances", "=", "[", "]", "\n", "normalized_squared_distances", "=", "[", "]", "\n", "\n", "# IMPORTANT CHANGE IN CODE (Feb 04, 2020): prior to today, actionable/mutable", "\n", "# features overlapped. Now that we have introduced 3 types of variables", "\n", "# (actionable and mutable, non-actionable but mutable, immutable and non-actionable),", "\n", "# we must re-write the distance function to depent on all mutable features only,", "\n", "# while before we wrote distance as a function over actionable/mutable features.", "\n", "\n", "mutable_attributes", "=", "dataset_obj", ".", "getMutableAttributeNames", "(", "'kurz'", ")", "\n", "one_hot_attributes", "=", "dataset_obj", ".", "getOneHotAttributesNames", "(", "'kurz'", ")", "\n", "non_hot_attributes", "=", "dataset_obj", ".", "getNonHotAttributesNames", "(", "'kurz'", ")", "\n", "\n", "# 1. mutable & non-hot", "\n", "for", "attr_name_kurz", "in", "np", ".", "intersect1d", "(", "mutable_attributes", ",", "non_hot_attributes", ")", ":", "\n", "    ", "normalized_absolute_distances", ".", "append", "(", "\n", "Div", "(", "\n", "ToReal", "(", "\n", "getAbsoluteDifference", "(", "\n", "model_symbols", "[", "variable_to_compute_distance_on", "]", "[", "attr_name_kurz", "]", "[", "'symbol'", "]", ",", "\n", "factual_sample", "[", "attr_name_kurz", "]", "\n", ")", "\n", ")", ",", "\n", "# Real(1)", "\n", "ToReal", "(", "\n", "model_symbols", "[", "variable_to_compute_distance_on", "]", "[", "attr_name_kurz", "]", "[", "'upper_bound'", "]", "-", "\n", "model_symbols", "[", "variable_to_compute_distance_on", "]", "[", "attr_name_kurz", "]", "[", "'lower_bound'", "]", "\n", ")", "\n", ")", "\n", ")", "\n", "normalized_squared_distances", ".", "append", "(", "\n", "Pow", "(", "\n", "Div", "(", "\n", "ToReal", "(", "\n", "Minus", "(", "\n", "model_symbols", "[", "variable_to_compute_distance_on", "]", "[", "attr_name_kurz", "]", "[", "'symbol'", "]", ",", "\n", "factual_sample", "[", "attr_name_kurz", "]", "\n", ")", "\n", ")", ",", "\n", "# Real(1)", "\n", "ToReal", "(", "\n", "model_symbols", "[", "variable_to_compute_distance_on", "]", "[", "attr_name_kurz", "]", "[", "'upper_bound'", "]", "-", "\n", "model_symbols", "[", "variable_to_compute_distance_on", "]", "[", "attr_name_kurz", "]", "[", "'lower_bound'", "]", "\n", ")", "\n", ")", ",", "\n", "Real", "(", "2", ")", "\n", ")", "\n", ")", "\n", "\n", "# 2. mutable & integer-based & one-hot", "\n", "", "already_considered", "=", "[", "]", "\n", "for", "attr_name_kurz", "in", "np", ".", "intersect1d", "(", "mutable_attributes", ",", "one_hot_attributes", ")", ":", "\n", "    ", "if", "attr_name_kurz", "not", "in", "already_considered", ":", "\n", "      ", "siblings_kurz", "=", "dataset_obj", ".", "getSiblingsFor", "(", "attr_name_kurz", ")", "\n", "if", "'cat'", "in", "dataset_obj", ".", "attributes_kurz", "[", "attr_name_kurz", "]", ".", "attr_type", ":", "\n", "# this can also be implemented as the abs value of sum of a difference", "\n", "# in each attribute, divided by 2", "\n", "        ", "normalized_absolute_distances", ".", "append", "(", "\n", "Ite", "(", "\n", "And", "(", "[", "\n", "EqualsOrIff", "(", "\n", "model_symbols", "[", "variable_to_compute_distance_on", "]", "[", "attr_name_kurz", "]", "[", "'symbol'", "]", ",", "\n", "factual_sample", "[", "attr_name_kurz", "]", "\n", ")", "\n", "for", "attr_name_kurz", "in", "siblings_kurz", "\n", "]", ")", ",", "\n", "Real", "(", "0", ")", ",", "\n", "Real", "(", "1", ")", "\n", ")", "\n", ")", "\n", "# TODO: What about this? might be cheaper than Ite.", "\n", "# normalized_absolute_distances.append(", "\n", "#   Minus(", "\n", "#     Real(1),", "\n", "#     ToReal(And([", "\n", "#       EqualsOrIff(", "\n", "#         model_symbols[variable_to_compute_distance_on][attr_name_kurz]['symbol'],", "\n", "#         factual_sample[attr_name_kurz]", "\n", "#       )", "\n", "#       for attr_name_kurz in siblings_kurz", "\n", "#     ]))", "\n", "#   )", "\n", "# )", "\n", "\n", "# As the distance is 0 or 1 in this case, the 2nd power is same as itself", "\n", "normalized_squared_distances", ".", "append", "(", "normalized_absolute_distances", "[", "-", "1", "]", ")", "\n", "\n", "", "elif", "'ord'", "in", "dataset_obj", ".", "attributes_kurz", "[", "attr_name_kurz", "]", ".", "attr_type", ":", "\n", "        ", "normalized_absolute_distances", ".", "append", "(", "\n", "Div", "(", "\n", "ToReal", "(", "\n", "getAbsoluteDifference", "(", "\n", "Plus", "(", "[", "\n", "model_symbols", "[", "variable_to_compute_distance_on", "]", "[", "attr_name_kurz", "]", "[", "'symbol'", "]", "\n", "for", "attr_name_kurz", "in", "siblings_kurz", "\n", "]", ")", ",", "\n", "Plus", "(", "[", "\n", "factual_sample", "[", "attr_name_kurz", "]", "\n", "for", "attr_name_kurz", "in", "siblings_kurz", "\n", "]", ")", ",", "\n", ")", "\n", ")", ",", "\n", "Real", "(", "len", "(", "siblings_kurz", ")", ")", "\n", ")", "\n", ")", "\n", "# this can also be implemented as below:", "\n", "# normalized_absolute_distances.append(", "\n", "#   Div(", "\n", "#     ToReal(", "\n", "#       Plus([", "\n", "#         Ite(", "\n", "#           EqualsOrIff(", "\n", "#             model_symbols[variable_to_compute_distance_on][attr_name_kurz]['symbol'],", "\n", "#             factual_sample[attr_name_kurz]", "\n", "#           ),", "\n", "#           Real(0),", "\n", "#           Real(1)", "\n", "#         )", "\n", "#         for attr_name_kurz in siblings_kurz", "\n", "#       ])", "\n", "#     ),", "\n", "#     Real(len(siblings_kurz))", "\n", "#   )", "\n", "# )", "\n", "normalized_squared_distances", ".", "append", "(", "\n", "Pow", "(", "\n", "Div", "(", "\n", "ToReal", "(", "\n", "Minus", "(", "\n", "Plus", "(", "[", "\n", "model_symbols", "[", "variable_to_compute_distance_on", "]", "[", "attr_name_kurz", "]", "[", "'symbol'", "]", "\n", "for", "attr_name_kurz", "in", "siblings_kurz", "\n", "]", ")", ",", "\n", "Plus", "(", "[", "\n", "factual_sample", "[", "attr_name_kurz", "]", "\n", "for", "attr_name_kurz", "in", "siblings_kurz", "\n", "]", ")", ",", "\n", ")", "\n", ")", ",", "\n", "Real", "(", "len", "(", "siblings_kurz", ")", ")", "\n", ")", ",", "\n", "Real", "(", "2", ")", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "f'{attr_name_kurz} must include either `cat` or `ord`.'", ")", "\n", "", "already_considered", ".", "extend", "(", "siblings_kurz", ")", "\n", "\n", "# # 3. compute normalized squared distances", "\n", "# # pysmt.exceptions.SolverReturnedUnknownResultError", "\n", "# normalized_squared_distances = [", "\n", "#   # Times(distance, distance)", "\n", "#   Pow(distance, Int(2))", "\n", "#   for distance in normalized_absolute_distances", "\n", "# ]", "\n", "# # TODO: deprecate?", "\n", "# # def getSquaredifference(symbol_1, symbol_2):", "\n", "# #   return Times(", "\n", "# #     ToReal(Minus(ToReal(symbol_1), ToReal(symbol_2))),", "\n", "# #     ToReal(Minus(ToReal(symbol_2), ToReal(symbol_1)))", "\n", "# #   )", "\n", "\n", "\n", "# 4. sum up over everything allowed...", "\n", "# We use 1 / len(normalized_absolute_distances) below because we only consider", "\n", "# those attributes that are mutable, and for each sibling-group (ord, cat)", "\n", "# we only consider 1 entry in the normalized_absolute_distances", "\n", "", "", "if", "norm_type", "==", "'zero_norm'", ":", "\n", "    ", "distance_formula", "=", "LE", "(", "\n", "Times", "(", "\n", "Real", "(", "1", "/", "len", "(", "normalized_absolute_distances", ")", ")", ",", "\n", "Plus", "(", "[", "\n", "Ite", "(", "\n", "Equals", "(", "elem", ",", "Real", "(", "0", ")", ")", ",", "\n", "Real", "(", "0", ")", ",", "\n", "Real", "(", "1", ")", "\n", ")", "for", "elem", "in", "normalized_absolute_distances", "\n", "]", ")", "\n", ")", ",", "\n", "Real", "(", "norm_threshold", ")", "\n", ")", "\n", "", "elif", "norm_type", "==", "'one_norm'", ":", "\n", "    ", "distance_formula", "=", "LE", "(", "\n", "Times", "(", "\n", "Real", "(", "1", "/", "len", "(", "normalized_absolute_distances", ")", ")", ",", "\n", "ToReal", "(", "Plus", "(", "normalized_absolute_distances", ")", ")", "\n", ")", ",", "\n", "Real", "(", "norm_threshold", ")", "\n", ")", "\n", "", "elif", "norm_type", "==", "'two_norm'", ":", "\n", "    ", "distance_formula", "=", "LE", "(", "\n", "Times", "(", "\n", "Real", "(", "1", "/", "len", "(", "normalized_squared_distances", ")", ")", ",", "\n", "ToReal", "(", "Plus", "(", "normalized_squared_distances", ")", ")", "\n", ")", ",", "\n", "Pow", "(", "\n", "Real", "(", "norm_threshold", ")", ",", "\n", "Real", "(", "2", ")", "\n", ")", "\n", ")", "\n", "", "elif", "norm_type", "==", "'infty_norm'", ":", "\n", "    ", "distance_formula", "=", "LE", "(", "\n", "Times", "(", "\n", "Real", "(", "1", "/", "len", "(", "normalized_absolute_distances", ")", ")", ",", "\n", "ToReal", "(", "Max", "(", "normalized_absolute_distances", ")", ")", "\n", ")", ",", "\n", "Real", "(", "norm_threshold", ")", "\n", ")", "\n", "", "else", ":", "\n", "    ", "raise", "Exception", "(", "f'{norm_type} not recognized as a valid `norm_type`.'", ")", "\n", "\n", "", "return", "distance_formula", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.getCausalConsistencyConstraints": [[285, 296], ["getGermanCausalConsistencyConstraints", "getRandomCausalConsistencyConstraints", "getMortgageCausalConsistencyConstraints", "getTwoMoonCausalConsistencyConstraints", "getTestCausalConsistencyConstraints"], "function", ["home.repos.pwc.inspect_result.amirhk_mace._data_main.loadCausalConstraints.getGermanCausalConsistencyConstraints", "home.repos.pwc.inspect_result.amirhk_mace._data_main.loadCausalConstraints.getRandomCausalConsistencyConstraints", "home.repos.pwc.inspect_result.amirhk_mace._data_main.loadCausalConstraints.getMortgageCausalConsistencyConstraints", "home.repos.pwc.inspect_result.amirhk_mace._data_main.loadCausalConstraints.getTwoMoonCausalConsistencyConstraints", "home.repos.pwc.inspect_result.amirhk_mace._data_main.loadCausalConstraints.getTestCausalConsistencyConstraints"], ["", "def", "getCausalConsistencyConstraints", "(", "model_symbols", ",", "dataset_obj", ",", "factual_sample", ")", ":", "\n", "  ", "if", "dataset_obj", ".", "dataset_name", "==", "'german'", ":", "\n", "    ", "return", "getGermanCausalConsistencyConstraints", "(", "model_symbols", ",", "factual_sample", ")", "\n", "", "elif", "dataset_obj", ".", "dataset_name", "==", "'random'", ":", "\n", "    ", "return", "getRandomCausalConsistencyConstraints", "(", "model_symbols", ",", "factual_sample", ")", "\n", "", "elif", "dataset_obj", ".", "dataset_name", "==", "'mortgage'", ":", "\n", "    ", "return", "getMortgageCausalConsistencyConstraints", "(", "model_symbols", ",", "factual_sample", ")", "\n", "", "elif", "dataset_obj", ".", "dataset_name", "==", "'twomoon'", ":", "\n", "    ", "return", "getTwoMoonCausalConsistencyConstraints", "(", "model_symbols", ",", "factual_sample", ")", "\n", "", "elif", "dataset_obj", ".", "dataset_name", "==", "'test'", ":", "\n", "    ", "return", "getTestCausalConsistencyConstraints", "(", "model_symbols", ",", "factual_sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.getPlausibilityFormula": [[298, 497], ["And", "And", "And", "TRUE", "TRUE", "dataset_obj.getInputAttributeNames", "And", "And", "dataset_obj.getDictOfSiblings", "dict_of_siblings_kurz[].keys", "dict_of_siblings_kurz[].keys", "TRUE", "And", "And", "And", "And", "generateSATExplanations.getCausalConsistencyConstraints", "GE", "LE", "dataset_obj.getInputAttributeNames", "GE", "LE", "dataset_obj.getInputAttributeNames", "And", "And", "And", "And", "And.append", "And.append", "And.append", "And.append", "EqualsOrIff", "EqualsOrIff", "GE", "GE", "And.append", "And.append", "And.append", "EqualsOrIff", "EqualsOrIff", "Plus", "Int", "Plus", "Int", "GE", "GE", "LE", "LE", "EqualsOrIff", "And.append", "ToReal", "ToReal", "range", "ToReal", "ToReal", "range", "EqualsOrIff", "len", "len"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getDictOfSiblings", "home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.getCausalConsistencyConstraints", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames"], ["", "", "def", "getPlausibilityFormula", "(", "model_symbols", ",", "dataset_obj", ",", "factual_sample", ",", "approach_string", ")", ":", "\n", "# here is where the user specifies the following:", "\n", "#  1. data range plausibility", "\n", "#  2. data type plausibility", "\n", "#  3. actionability + mutability", "\n", "#  4. causal consistency", "\n", "\n", "##############################################################################", "\n", "## 1. data range plausibility", "\n", "##############################################################################", "\n", "  ", "range_plausibility_counterfactual", "=", "And", "(", "[", "\n", "And", "(", "\n", "GE", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "attr_name_kurz", "]", "[", "'symbol'", "]", ",", "model_symbols", "[", "'counterfactual'", "]", "[", "attr_name_kurz", "]", "[", "'lower_bound'", "]", ")", ",", "\n", "LE", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "attr_name_kurz", "]", "[", "'symbol'", "]", ",", "model_symbols", "[", "'counterfactual'", "]", "[", "attr_name_kurz", "]", "[", "'upper_bound'", "]", ")", "\n", ")", "\n", "for", "attr_name_kurz", "in", "dataset_obj", ".", "getInputAttributeNames", "(", "'kurz'", ")", "\n", "]", ")", "\n", "range_plausibility_interventional", "=", "And", "(", "[", "\n", "And", "(", "\n", "GE", "(", "model_symbols", "[", "'interventional'", "]", "[", "attr_name_kurz", "]", "[", "'symbol'", "]", ",", "model_symbols", "[", "'interventional'", "]", "[", "attr_name_kurz", "]", "[", "'lower_bound'", "]", ")", ",", "\n", "LE", "(", "model_symbols", "[", "'interventional'", "]", "[", "attr_name_kurz", "]", "[", "'symbol'", "]", ",", "model_symbols", "[", "'interventional'", "]", "[", "attr_name_kurz", "]", "[", "'upper_bound'", "]", ")", "\n", ")", "\n", "for", "attr_name_kurz", "in", "dataset_obj", ".", "getInputAttributeNames", "(", "'kurz'", ")", "\n", "]", ")", "\n", "\n", "# IMPORTANT: a weird behavior of print(get_model(formula)) is that if there is", "\n", "#            a variable that is defined as a symbol, but is not constrained in", "\n", "#            the formula, then print(.) will not print the \"verifying\" value of", "\n", "#            that variable (as it can be anything). Therefore, we always use", "\n", "#            range plausibility constraints on ALL variables (including the", "\n", "#            interventional variables, even though they are only used for MINT", "\n", "#            and not MACE). TODO: find alternative method to print(model).", "\n", "range_plausibility", "=", "And", "(", "[", "range_plausibility_counterfactual", ",", "range_plausibility_interventional", "]", ")", "\n", "\n", "\n", "##############################################################################", "\n", "## 2. data type plausibility", "\n", "##############################################################################", "\n", "onehot_categorical_plausibility", "=", "TRUE", "(", ")", "# plausibility of categorical (sum = 1)", "\n", "onehot_ordinal_plausibility", "=", "TRUE", "(", ")", "# plausibility ordinal (x3 >= x2 & x2 >= x1)", "\n", "\n", "if", "dataset_obj", ".", "is_one_hot", ":", "\n", "\n", "    ", "dict_of_siblings_kurz", "=", "dataset_obj", ".", "getDictOfSiblings", "(", "'kurz'", ")", "\n", "\n", "for", "parent_name_kurz", "in", "dict_of_siblings_kurz", "[", "'cat'", "]", ".", "keys", "(", ")", ":", "\n", "\n", "      ", "onehot_categorical_plausibility", "=", "And", "(", "\n", "onehot_categorical_plausibility", ",", "\n", "And", "(", "\n", "EqualsOrIff", "(", "\n", "Plus", "(", "[", "\n", "model_symbols", "[", "'counterfactual'", "]", "[", "attr_name_kurz", "]", "[", "'symbol'", "]", "\n", "for", "attr_name_kurz", "in", "dict_of_siblings_kurz", "[", "'cat'", "]", "[", "parent_name_kurz", "]", "\n", "]", ")", ",", "\n", "Int", "(", "1", ")", "\n", ")", "\n", ")", ",", "\n", "And", "(", "\n", "EqualsOrIff", "(", "\n", "Plus", "(", "[", "\n", "model_symbols", "[", "'interventional'", "]", "[", "attr_name_kurz", "]", "[", "'symbol'", "]", "\n", "for", "attr_name_kurz", "in", "dict_of_siblings_kurz", "[", "'cat'", "]", "[", "parent_name_kurz", "]", "\n", "]", ")", ",", "\n", "Int", "(", "1", ")", "\n", ")", "\n", ")", "\n", ")", "\n", "\n", "", "for", "parent_name_kurz", "in", "dict_of_siblings_kurz", "[", "'ord'", "]", ".", "keys", "(", ")", ":", "\n", "\n", "      ", "onehot_ordinal_plausibility", "=", "And", "(", "\n", "onehot_ordinal_plausibility", ",", "\n", "And", "(", "[", "\n", "GE", "(", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "dict_of_siblings_kurz", "[", "'ord'", "]", "[", "parent_name_kurz", "]", "[", "symbol_idx", "]", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "dict_of_siblings_kurz", "[", "'ord'", "]", "[", "parent_name_kurz", "]", "[", "symbol_idx", "+", "1", "]", "]", "[", "'symbol'", "]", ")", "\n", ")", "\n", "for", "symbol_idx", "in", "range", "(", "len", "(", "dict_of_siblings_kurz", "[", "'ord'", "]", "[", "parent_name_kurz", "]", ")", "-", "1", ")", "# already sorted", "\n", "]", ")", ",", "\n", "And", "(", "[", "\n", "GE", "(", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "dict_of_siblings_kurz", "[", "'ord'", "]", "[", "parent_name_kurz", "]", "[", "symbol_idx", "]", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "dict_of_siblings_kurz", "[", "'ord'", "]", "[", "parent_name_kurz", "]", "[", "symbol_idx", "+", "1", "]", "]", "[", "'symbol'", "]", ")", "\n", ")", "\n", "for", "symbol_idx", "in", "range", "(", "len", "(", "dict_of_siblings_kurz", "[", "'ord'", "]", "[", "parent_name_kurz", "]", ")", "-", "1", ")", "# already sorted", "\n", "]", ")", "\n", ")", "\n", "\n", "# # Also implemented as the following logic, stating that", "\n", "# # if x_j == 1, all x_i == 1 for i < j", "\n", "# # Friendly reminder that for ordinal variables, x_0 is always 1", "\n", "# onehot_ordinal_plausibility = And([", "\n", "#   Ite(", "\n", "#     EqualsOrIff(", "\n", "#       ToReal(model_symbols['counterfactual'][dict_of_siblings_kurz['ord'][parent_name_kurz][symbol_idx_ahead]]['symbol']),", "\n", "#       Real(1)", "\n", "#     ),", "\n", "#     And([", "\n", "#       EqualsOrIff(", "\n", "#         ToReal(model_symbols['counterfactual'][dict_of_siblings_kurz['ord'][parent_name_kurz][symbol_idx_behind]]['symbol']),", "\n", "#         Real(1)", "\n", "#       )", "\n", "#       for symbol_idx_behind in range(symbol_idx_ahead)", "\n", "#     ]),", "\n", "#     TRUE()", "\n", "#   )", "\n", "#   for symbol_idx_ahead in range(1, len(dict_of_siblings_kurz['ord'][parent_name_kurz])) # already sorted", "\n", "# ])", "\n", "\n", "\n", "##############################################################################", "\n", "## 3. actionability + mutability", "\n", "#    a) actionable and mutable: both interventional and counterfactual value can change", "\n", "#    b) non-actionable but mutable: interventional value cannot change, but counterfactual value can", "\n", "#    c) immutable and non-actionable: neither interventional nor counterfactual value can change", "\n", "##############################################################################", "\n", "", "", "actionability_mutability_plausibility", "=", "[", "]", "\n", "for", "attr_name_kurz", "in", "dataset_obj", ".", "getInputAttributeNames", "(", "'kurz'", ")", ":", "\n", "    ", "attr_obj", "=", "dataset_obj", ".", "attributes_kurz", "[", "attr_name_kurz", "]", "\n", "\n", "# a) actionable and mutable: both interventional and counterfactual value can change", "\n", "if", "attr_obj", ".", "mutability", "==", "True", "and", "attr_obj", ".", "actionability", "!=", "'none'", ":", "\n", "\n", "      ", "if", "attr_obj", ".", "actionability", "==", "'same-or-increase'", ":", "\n", "        ", "actionability_mutability_plausibility", ".", "append", "(", "GE", "(", "\n", "model_symbols", "[", "'counterfactual'", "]", "[", "attr_name_kurz", "]", "[", "'symbol'", "]", ",", "\n", "factual_sample", "[", "attr_name_kurz", "]", "\n", ")", ")", "\n", "actionability_mutability_plausibility", ".", "append", "(", "GE", "(", "\n", "model_symbols", "[", "'interventional'", "]", "[", "attr_name_kurz", "]", "[", "'symbol'", "]", ",", "\n", "factual_sample", "[", "attr_name_kurz", "]", "\n", ")", ")", "\n", "", "elif", "attr_obj", ".", "actionability", "==", "'same-or-decrease'", ":", "\n", "        ", "actionability_mutability_plausibility", ".", "append", "(", "LE", "(", "\n", "model_symbols", "[", "'counterfactual'", "]", "[", "attr_name_kurz", "]", "[", "'symbol'", "]", ",", "\n", "factual_sample", "[", "attr_name_kurz", "]", "\n", ")", ")", "\n", "actionability_mutability_plausibility", ".", "append", "(", "LE", "(", "\n", "model_symbols", "[", "'interventional'", "]", "[", "attr_name_kurz", "]", "[", "'symbol'", "]", ",", "\n", "factual_sample", "[", "attr_name_kurz", "]", "\n", ")", ")", "\n", "", "elif", "attr_obj", ".", "actionability", "==", "'any'", ":", "\n", "        ", "continue", "\n", "\n", "# b) mutable but non-actionable: interventional value cannot change, but counterfactual value can", "\n", "", "", "elif", "attr_obj", ".", "mutability", "==", "True", "and", "attr_obj", ".", "actionability", "==", "'none'", ":", "\n", "\n", "# IMPORTANT: when we are optimizing for nearest CFE, we completely ignore", "\n", "#            the interventional symbols, even though they are defined. In", "\n", "#            such a world, we also don't have any assumptions about the", "\n", "#            causal structure, and therefore, causal_consistency = TRUE()", "\n", "#            later in the code. Therefore, a `mutable but actionable` var", "\n", "#            (i.e., a variable that can change due to it's ancerstors) does", "\n", "#            not even exist. Thus, non-actionable variables are supported", "\n", "#            by restricing the counterfactual symbols.", "\n", "# TODO: perhaps a better way to structure this code is to completely get", "\n", "#       rid of interventional symbols when calling genSATExp.py with MACE.", "\n", "      ", "if", "'mace'", "in", "approach_string", ":", "\n", "        ", "actionability_mutability_plausibility", ".", "append", "(", "EqualsOrIff", "(", "\n", "model_symbols", "[", "'counterfactual'", "]", "[", "attr_name_kurz", "]", "[", "'symbol'", "]", ",", "\n", "factual_sample", "[", "attr_name_kurz", "]", "\n", ")", ")", "\n", "", "elif", "'mint'", "in", "approach_string", ":", "\n", "        ", "actionability_mutability_plausibility", ".", "append", "(", "EqualsOrIff", "(", "\n", "model_symbols", "[", "'interventional'", "]", "[", "attr_name_kurz", "]", "[", "'symbol'", "]", ",", "\n", "factual_sample", "[", "attr_name_kurz", "]", "\n", ")", ")", "\n", "\n", "# c) immutable and non-actionable: neither interventional nor counterfactual value can change", "\n", "", "", "else", ":", "\n", "\n", "      ", "actionability_mutability_plausibility", ".", "append", "(", "EqualsOrIff", "(", "\n", "model_symbols", "[", "'counterfactual'", "]", "[", "attr_name_kurz", "]", "[", "'symbol'", "]", ",", "\n", "factual_sample", "[", "attr_name_kurz", "]", "\n", ")", ")", "\n", "actionability_mutability_plausibility", ".", "append", "(", "EqualsOrIff", "(", "\n", "model_symbols", "[", "'interventional'", "]", "[", "attr_name_kurz", "]", "[", "'symbol'", "]", ",", "\n", "factual_sample", "[", "attr_name_kurz", "]", "\n", ")", ")", "\n", "\n", "", "", "actionability_mutability_plausibility", "=", "And", "(", "actionability_mutability_plausibility", ")", "\n", "\n", "\n", "##############################################################################", "\n", "## 4. causal consistency", "\n", "##############################################################################", "\n", "if", "'mace'", "in", "approach_string", ":", "\n", "    ", "causal_consistency", "=", "TRUE", "(", ")", "\n", "", "elif", "'mint'", "in", "approach_string", ":", "\n", "    ", "causal_consistency", "=", "getCausalConsistencyConstraints", "(", "model_symbols", ",", "dataset_obj", ",", "factual_sample", ")", "\n", "\n", "\n", "", "return", "And", "(", "\n", "range_plausibility", ",", "\n", "onehot_categorical_plausibility", ",", "\n", "onehot_ordinal_plausibility", ",", "\n", "actionability_mutability_plausibility", ",", "\n", "causal_consistency", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.getDiversityFormulaUpdate": [[500, 508], ["Not", "And", "EqualsOrIff"], "function", ["None"], ["", "def", "getDiversityFormulaUpdate", "(", "model", ")", ":", "\n", "  ", "return", "Not", "(", "\n", "And", "(", "[", "\n", "EqualsOrIff", "(", "\n", "symbol_key", ",", "\n", "symbol_value", "\n", ")", "\n", "for", "(", "symbol_key", ",", "symbol_value", ")", "in", "model", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.findClosestCounterfactualSample": [[512, 680], ["generateSATExplanations.getPySMTSampleFromDictSample", "generateSATExplanations.findClosestCounterfactualSample.getCenterNormThresholdInRange"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.getPySMTSampleFromDictSample"], ["", "def", "findClosestCounterfactualSample", "(", "model_trained", ",", "model_symbols", ",", "dataset_obj", ",", "factual_sample", ",", "norm_type", ",", "approach_string", ",", "epsilon", ",", "log_file", ")", ":", "\n", "\n", "  ", "def", "getCenterNormThresholdInRange", "(", "lower_bound", ",", "upper_bound", ")", ":", "\n", "    ", "return", "(", "lower_bound", "+", "upper_bound", ")", "/", "2", "\n", "\n", "", "def", "assertPrediction", "(", "dict_sample", ",", "model_trained", ",", "dataset_obj", ")", ":", "\n", "    ", "vectorized_sample", "=", "[", "]", "\n", "for", "attr_name_kurz", "in", "dataset_obj", ".", "getInputAttributeNames", "(", "'kurz'", ")", ":", "\n", "      ", "vectorized_sample", ".", "append", "(", "dict_sample", "[", "attr_name_kurz", "]", ")", "\n", "\n", "", "sklearn_prediction", "=", "int", "(", "model_trained", ".", "predict", "(", "[", "vectorized_sample", "]", ")", "[", "0", "]", ")", "\n", "pysmt_prediction", "=", "int", "(", "dict_sample", "[", "'y'", "]", ")", "\n", "factual_prediction", "=", "int", "(", "factual_sample", "[", "'y'", "]", ")", "\n", "\n", "# IMPORTANT: sometimes, MACE does such a good job, that the counterfactual", "\n", "#            ends up super close to (if not on) the decision boundary; here", "\n", "#            the label is underfined which causes inconsistency errors", "\n", "#            between pysmt and sklearn. We skip the assert at such points.", "\n", "class_predict_proba", "=", "model_trained", ".", "predict_proba", "(", "[", "vectorized_sample", "]", ")", "[", "0", "]", "\n", "if", "np", ".", "abs", "(", "class_predict_proba", "[", "0", "]", "-", "class_predict_proba", "[", "1", "]", ")", "<", "1e-10", ":", "\n", "      ", "return", "\n", "\n", "", "assert", "sklearn_prediction", "==", "pysmt_prediction", ",", "'Pysmt prediction does not match sklearn prediction.'", "\n", "assert", "sklearn_prediction", "!=", "factual_prediction", ",", "'Counterfactual and factual samples have the same prediction.'", "\n", "\n", "# Convert to pysmt_sample so factual symbols can be used in formulae", "\n", "", "factual_pysmt_sample", "=", "getPySMTSampleFromDictSample", "(", "factual_sample", ",", "dataset_obj", ")", "\n", "\n", "norm_lower_bound", "=", "0", "\n", "norm_upper_bound", "=", "1", "\n", "curr_norm_threshold", "=", "getCenterNormThresholdInRange", "(", "norm_lower_bound", ",", "norm_upper_bound", ")", "\n", "\n", "# Get and merge all constraints", "\n", "print", "(", "'Constructing initial formulas: model, counterfactual, distance, plausibility, diversity\\t\\t'", ",", "end", "=", "''", ",", "file", "=", "log_file", ")", "\n", "model_formula", "=", "getModelFormula", "(", "model_symbols", ",", "model_trained", ")", "\n", "counterfactual_formula", "=", "getCounterfactualFormula", "(", "model_symbols", ",", "factual_pysmt_sample", ")", "\n", "plausibility_formula", "=", "getPlausibilityFormula", "(", "model_symbols", ",", "dataset_obj", ",", "factual_pysmt_sample", ",", "approach_string", ")", "\n", "distance_formula", "=", "getDistanceFormula", "(", "model_symbols", ",", "dataset_obj", ",", "factual_pysmt_sample", ",", "norm_type", ",", "approach_string", ",", "curr_norm_threshold", ")", "\n", "diversity_formula", "=", "TRUE", "(", ")", "# simply initialize and modify later as new counterfactuals come in", "\n", "print", "(", "'done.'", ",", "file", "=", "log_file", ")", "\n", "\n", "iters", "=", "1", "\n", "max_iters", "=", "100", "\n", "counterfactuals", "=", "[", "]", "# list of tuples (samples, distances)", "\n", "# In case no counterfactuals are found (this could happen for a variety of", "\n", "# reasons, perhaps due to non-plausibility), return a template counterfactual", "\n", "counterfactuals", ".", "append", "(", "{", "\n", "'counterfactual_sample'", ":", "{", "}", ",", "\n", "'counterfactual_distance'", ":", "np", ".", "infty", ",", "\n", "'interventional_sample'", ":", "{", "}", ",", "\n", "'interventional_distance'", ":", "np", ".", "infty", ",", "\n", "'time'", ":", "np", ".", "infty", ",", "\n", "'norm_type'", ":", "norm_type", "}", ")", "\n", "\n", "print", "(", "'Solving (not searching) for closest counterfactual using various distance thresholds...'", ",", "file", "=", "log_file", ")", "\n", "\n", "while", "iters", "<", "max_iters", "and", "norm_upper_bound", "-", "norm_lower_bound", ">=", "epsilon", ":", "\n", "\n", "    ", "print", "(", "f'\\tIteration #{iters:03d}: testing norm threshold {curr_norm_threshold:.6f} in range [{norm_lower_bound:.6f}, {norm_upper_bound:.6f}]...\\t'", ",", "end", "=", "''", ",", "file", "=", "log_file", ")", "\n", "iters", "=", "iters", "+", "1", "\n", "\n", "formula", "=", "And", "(", "# works for both initial iteration and all subsequent iterations", "\n", "model_formula", ",", "\n", "counterfactual_formula", ",", "\n", "plausibility_formula", ",", "\n", "distance_formula", ",", "\n", "diversity_formula", ",", "\n", ")", "\n", "\n", "solver_name", "=", "\"z3\"", "\n", "with", "Solver", "(", "name", "=", "solver_name", ")", "as", "solver", ":", "\n", "      ", "solver", ".", "add_assertion", "(", "formula", ")", "\n", "\n", "iteration_start_time", "=", "time", ".", "time", "(", ")", "\n", "solved", "=", "solver", ".", "solve", "(", ")", "\n", "iteration_end_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "solved", ":", "# joint formula is satisfiable", "\n", "        ", "model", "=", "solver", ".", "get_model", "(", ")", "\n", "print", "(", "'solution exists & found.'", ",", "file", "=", "log_file", ")", "\n", "counterfactual_pysmt_sample", "=", "{", "}", "\n", "interventional_pysmt_sample", "=", "{", "}", "\n", "for", "(", "symbol_key", ",", "symbol_value", ")", "in", "model", ":", "\n", "# symbol_key may be 'x#', {'p0#', 'p1#'}, 'w#', or 'y'", "\n", "          ", "tmp", "=", "str", "(", "symbol_key", ")", "\n", "if", "'counterfactual'", "in", "str", "(", "symbol_key", ")", ":", "\n", "            ", "tmp", "=", "tmp", "[", ":", "-", "15", "]", "\n", "if", "tmp", "in", "dataset_obj", ".", "getInputOutputAttributeNames", "(", "'kurz'", ")", ":", "\n", "              ", "counterfactual_pysmt_sample", "[", "tmp", "]", "=", "symbol_value", "\n", "", "", "elif", "'interventional'", "in", "str", "(", "symbol_key", ")", ":", "\n", "            ", "tmp", "=", "tmp", "[", ":", "-", "15", "]", "\n", "if", "tmp", "in", "dataset_obj", ".", "getInputOutputAttributeNames", "(", "'kurz'", ")", ":", "\n", "              ", "interventional_pysmt_sample", "[", "tmp", "]", "=", "symbol_value", "\n", "", "", "elif", "tmp", "in", "dataset_obj", ".", "getInputOutputAttributeNames", "(", "'kurz'", ")", ":", "# for y variable", "\n", "            ", "counterfactual_pysmt_sample", "[", "tmp", "]", "=", "symbol_value", "\n", "interventional_pysmt_sample", "[", "tmp", "]", "=", "symbol_value", "\n", "\n", "# Convert back from pysmt_sample to dict_sample to compute distance and save", "\n", "", "", "counterfactual_sample", "=", "getDictSampleFromPySMTSample", "(", "\n", "counterfactual_pysmt_sample", ",", "\n", "dataset_obj", ")", "\n", "interventional_sample", "=", "getDictSampleFromPySMTSample", "(", "\n", "interventional_pysmt_sample", ",", "\n", "dataset_obj", ")", "\n", "\n", "# Assert samples have correct prediction label according to sklearn model", "\n", "assertPrediction", "(", "counterfactual_sample", ",", "model_trained", ",", "dataset_obj", ")", "\n", "# of course, there is no need to assertPrediction on the interventional_sample", "\n", "\n", "counterfactual_distance", "=", "normalizedDistance", ".", "getDistanceBetweenSamples", "(", "\n", "factual_sample", ",", "\n", "counterfactual_sample", ",", "\n", "norm_type", ",", "\n", "dataset_obj", ")", "\n", "interventional_distance", "=", "normalizedDistance", ".", "getDistanceBetweenSamples", "(", "\n", "factual_sample", ",", "\n", "interventional_sample", ",", "\n", "norm_type", ",", "\n", "dataset_obj", ")", "\n", "counterfactual_time", "=", "iteration_end_time", "-", "iteration_start_time", "\n", "counterfactuals", ".", "append", "(", "{", "\n", "'counterfactual_sample'", ":", "counterfactual_sample", ",", "\n", "'counterfactual_distance'", ":", "counterfactual_distance", ",", "\n", "'interventional_sample'", ":", "interventional_sample", ",", "\n", "'interventional_distance'", ":", "interventional_distance", ",", "\n", "'time'", ":", "counterfactual_time", ",", "\n", "'norm_type'", ":", "norm_type", "}", ")", "\n", "\n", "# Update diversity and distance formulas now that we have found a solution", "\n", "# TODO: I think the line below should be removed, because in successive", "\n", "#       reductions of delta, we should be able to re-use previous CFs", "\n", "# diversity_formula = And(diversity_formula, getDiversityFormulaUpdate(model))", "\n", "\n", "# IMPORTANT: something odd happens somtimes if use vanilla binary search;", "\n", "#            On the first iteration, with [0, 1] bounds, we may see a CF at", "\n", "#            d = 0.22. When we update the bounds to [0, 0.5] bounds,  we", "\n", "#            sometimes surprisingly see a new CF at distance 0.24. We optimize", "\n", "#            the binary search to solve this.", "\n", "norm_lower_bound", "=", "norm_lower_bound", "\n", "# norm_upper_bound = curr_norm_threshold", "\n", "if", "'mace'", "in", "approach_string", ":", "\n", "          ", "norm_upper_bound", "=", "float", "(", "counterfactual_distance", "+", "epsilon", "/", "100", ")", "# not float64", "\n", "", "elif", "'mint'", "in", "approach_string", ":", "\n", "          ", "norm_upper_bound", "=", "float", "(", "interventional_distance", "+", "epsilon", "/", "100", ")", "# not float64", "\n", "", "curr_norm_threshold", "=", "getCenterNormThresholdInRange", "(", "norm_lower_bound", ",", "norm_upper_bound", ")", "\n", "distance_formula", "=", "getDistanceFormula", "(", "model_symbols", ",", "dataset_obj", ",", "factual_pysmt_sample", ",", "norm_type", ",", "approach_string", ",", "curr_norm_threshold", ")", "\n", "\n", "", "else", ":", "# no solution found in the assigned norm range --> update range and try again", "\n", "        ", "with", "Solver", "(", "name", "=", "solver_name", ")", "as", "neg_solver", ":", "\n", "          ", "neg_formula", "=", "Not", "(", "formula", ")", "\n", "neg_solver", ".", "add_assertion", "(", "neg_formula", ")", "\n", "neg_solved", "=", "neg_solver", ".", "solve", "(", ")", "\n", "if", "neg_solved", ":", "\n", "            ", "print", "(", "'no solution exists.'", ",", "file", "=", "log_file", ")", "\n", "norm_lower_bound", "=", "curr_norm_threshold", "\n", "norm_upper_bound", "=", "norm_upper_bound", "\n", "curr_norm_threshold", "=", "getCenterNormThresholdInRange", "(", "norm_lower_bound", ",", "norm_upper_bound", ")", "\n", "distance_formula", "=", "getDistanceFormula", "(", "model_symbols", ",", "dataset_obj", ",", "factual_pysmt_sample", ",", "norm_type", ",", "approach_string", ",", "curr_norm_threshold", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'no solution found (SMT issue).'", ",", "file", "=", "log_file", ")", "\n", "quit", "(", ")", "\n", "break", "\n", "\n", "# IMPORTANT: there may be many more at this same distance! OR NONE! (what?? 2020.02.19)", "\n", "", "", "", "", "", "closest_counterfactual_sample", "=", "sorted", "(", "counterfactuals", ",", "key", "=", "lambda", "x", ":", "x", "[", "'counterfactual_distance'", "]", ")", "[", "0", "]", "\n", "closest_interventional_sample", "=", "sorted", "(", "counterfactuals", ",", "key", "=", "lambda", "x", ":", "x", "[", "'interventional_distance'", "]", ")", "[", "0", "]", "\n", "\n", "return", "counterfactuals", ",", "closest_counterfactual_sample", ",", "closest_interventional_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.getPrettyStringForSampleDictionary": [[682, 707], ["sample.items", "sorted", "all_key_value_pairs.append", "len", "len", "key_value_pairs_with_x_in_key.items", "all_key_value_pairs.append", "sample.keys", "dataset_obj.getInputAttributeNames", "key_value_pairs_with_y_in_key.keys", "len", "dataset_obj.getOutputAttributeNames", "Exception", "key_value_pairs_with_y_in_key.keys", "int", "[].split"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getOutputAttributeNames"], ["", "def", "getPrettyStringForSampleDictionary", "(", "sample", ",", "dataset_obj", ")", ":", "\n", "\n", "  ", "if", "len", "(", "sample", ".", "keys", "(", ")", ")", "==", "0", ":", "\n", "    ", "return", "'No sample found.'", "\n", "\n", "", "key_value_pairs_with_x_in_key", "=", "{", "}", "\n", "key_value_pairs_with_y_in_key", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "sample", ".", "items", "(", ")", ":", "\n", "    ", "if", "key", "in", "dataset_obj", ".", "getInputAttributeNames", "(", "'kurz'", ")", ":", "\n", "      ", "key_value_pairs_with_x_in_key", "[", "key", "]", "=", "value", "\n", "", "elif", "key", "in", "dataset_obj", ".", "getOutputAttributeNames", "(", "'kurz'", ")", ":", "\n", "      ", "key_value_pairs_with_y_in_key", "[", "key", "]", "=", "value", "\n", "", "else", ":", "\n", "      ", "raise", "Exception", "(", "'Sample keys may only be `x` or `y`.'", ")", "\n", "\n", "", "", "assert", "len", "(", "key_value_pairs_with_y_in_key", ".", "keys", "(", ")", ")", "==", "1", ",", "f'expecting only 1 output variables, got {len(key_value_pairs_with_y_in_key.keys())}'", "\n", "\n", "all_key_value_pairs", "=", "[", "]", "\n", "for", "key", ",", "value", "in", "sorted", "(", "key_value_pairs_with_x_in_key", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", "[", "0", "]", "[", "1", ":", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", ")", ":", "\n", "    ", "all_key_value_pairs", ".", "append", "(", "f'{key} : {value}'", ")", "\n", "", "all_key_value_pairs", ".", "append", "(", "f\"{'y'}: {key_value_pairs_with_y_in_key['y']}\"", ")", "\n", "\n", "return", "f\"{{{', '.join(all_key_value_pairs)}}}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.getPySMTSampleFromDictSample": [[709, 720], ["dataset_obj.getInputOutputAttributeNames", "dataset_obj.getInputAttributeNames", "Bool", "Real", "Int", "float", "int"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputOutputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames"], ["", "def", "getPySMTSampleFromDictSample", "(", "dict_sample", ",", "dataset_obj", ")", ":", "\n", "  ", "pysmt_sample", "=", "{", "}", "\n", "for", "attr_name_kurz", "in", "dataset_obj", ".", "getInputOutputAttributeNames", "(", "'kurz'", ")", ":", "\n", "    ", "attr_obj", "=", "dataset_obj", ".", "attributes_kurz", "[", "attr_name_kurz", "]", "\n", "if", "attr_name_kurz", "not", "in", "dataset_obj", ".", "getInputAttributeNames", "(", "'kurz'", ")", ":", "\n", "      ", "pysmt_sample", "[", "attr_name_kurz", "]", "=", "Bool", "(", "dict_sample", "[", "attr_name_kurz", "]", ")", "\n", "", "elif", "attr_obj", ".", "attr_type", "==", "'numeric-real'", ":", "\n", "      ", "pysmt_sample", "[", "attr_name_kurz", "]", "=", "Real", "(", "float", "(", "dict_sample", "[", "attr_name_kurz", "]", ")", ")", "\n", "", "else", ":", "# refer to loadData.VALID_ATTRIBUTE_TYPES", "\n", "      ", "pysmt_sample", "[", "attr_name_kurz", "]", "=", "Int", "(", "int", "(", "dict_sample", "[", "attr_name_kurz", "]", ")", ")", "\n", "", "", "return", "pysmt_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.getDictSampleFromPySMTSample": [[722, 736], ["dataset_obj.getInputOutputAttributeNames", "dataset_obj.getInputAttributeNames", "bool", "Exception", "float", "int", "str", "eval", "str", "str"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputOutputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames"], ["", "def", "getDictSampleFromPySMTSample", "(", "pysmt_sample", ",", "dataset_obj", ")", ":", "\n", "  ", "dict_sample", "=", "{", "}", "\n", "for", "attr_name_kurz", "in", "dataset_obj", ".", "getInputOutputAttributeNames", "(", "'kurz'", ")", ":", "\n", "    ", "attr_obj", "=", "dataset_obj", ".", "attributes_kurz", "[", "attr_name_kurz", "]", "\n", "try", ":", "\n", "      ", "if", "attr_name_kurz", "not", "in", "dataset_obj", ".", "getInputAttributeNames", "(", "'kurz'", ")", ":", "\n", "        ", "dict_sample", "[", "attr_name_kurz", "]", "=", "bool", "(", "str", "(", "pysmt_sample", "[", "attr_name_kurz", "]", ")", "==", "'True'", ")", "\n", "", "elif", "attr_obj", ".", "attr_type", "==", "'numeric-real'", ":", "\n", "        ", "dict_sample", "[", "attr_name_kurz", "]", "=", "float", "(", "eval", "(", "str", "(", "pysmt_sample", "[", "attr_name_kurz", "]", ")", ")", ")", "\n", "", "else", ":", "# refer to loadData.VALID_ATTRIBUTE_TYPES", "\n", "        ", "dict_sample", "[", "attr_name_kurz", "]", "=", "int", "(", "str", "(", "pysmt_sample", "[", "attr_name_kurz", "]", ")", ")", "\n", "", "", "except", ":", "\n", "      ", "raise", "Exception", "(", "f'Failed to read value from pysmt sample. Debug me manually.'", ")", "\n", "", "", "return", "dict_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.genExp": [[738, 856], ["time.time", "dataset_obj.getInputAttributeNames", "print", "print", "pprint.pprint", "generateSATExplanations.findClosestCounterfactualSample", "print", "print", "time.time", "Exception", "open", "print", "print", "dataset_obj.getInputAttributeNames", "print", "print", "print", "print", "dataset_obj.getInputAttributeNames", "Symbol", "Symbol", "Real", "Real", "Symbol", "Real", "Real", "Symbol", "Int", "Int", "Symbol", "Int", "Int", "generateSATExplanations.getPrettyStringForSampleDictionary", "float", "float", "float", "float", "int", "int", "int", "int", "generateSATExplanations.getPrettyStringForSampleDictionary", "generateSATExplanations.getPrettyStringForSampleDictionary", "generateSATExplanations.getPrettyStringForSampleDictionary"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.findClosestCounterfactualSample", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.getPrettyStringForSampleDictionary", "home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.getPrettyStringForSampleDictionary", "home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.getPrettyStringForSampleDictionary", "home.repos.pwc.inspect_result.amirhk_mace.None.generateSATExplanations.getPrettyStringForSampleDictionary"], ["", "def", "genExp", "(", "\n", "explanation_file_name", ",", "\n", "model_trained", ",", "\n", "dataset_obj", ",", "\n", "factual_sample", ",", "\n", "norm_type", ",", "\n", "approach_string", ",", "\n", "epsilon", ")", ":", "\n", "\n", "# # ONLY TO BE USED FOR TEST PURPOSES ON MORTGAGE DATASET", "\n", "# factual_sample = {'x0': 75000, 'x1': 25000, 'y': False}", "\n", "\n", "  ", "if", "'mace'", "not", "in", "approach_string", "and", "'mint'", "not", "in", "approach_string", ":", "\n", "    ", "raise", "Exception", "(", "f'`{approach_string}` not recognized as valid approach string; expected `mint` or `mace`.'", ")", "\n", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "DEBUG_FLAG", ":", "\n", "    ", "log_file", "=", "sys", ".", "stdout", "\n", "", "else", ":", "\n", "    ", "log_file", "=", "open", "(", "explanation_file_name", ",", "'w'", ")", "\n", "\n", "# Initial params", "\n", "", "model_symbols", "=", "{", "\n", "'counterfactual'", ":", "{", "}", ",", "\n", "'interventional'", ":", "{", "}", ",", "\n", "'output'", ":", "{", "'y'", ":", "{", "'symbol'", ":", "Symbol", "(", "'y'", ",", "BOOL", ")", "}", "}", "\n", "}", "\n", "\n", "# Populate model_symbols['counterfactual'/'interventional'] using the", "\n", "# parameters saved during training", "\n", "for", "attr_name_kurz", "in", "dataset_obj", ".", "getInputAttributeNames", "(", "'kurz'", ")", ":", "\n", "    ", "attr_obj", "=", "dataset_obj", ".", "attributes_kurz", "[", "attr_name_kurz", "]", "\n", "lower_bound", "=", "attr_obj", ".", "lower_bound", "\n", "upper_bound", "=", "attr_obj", ".", "upper_bound", "\n", "# print(f'\\n attr_name_kurz: {attr_name_kurz} \\t\\t lower_bound: {lower_bound} \\t upper_bound: {upper_bound}', file = log_file)", "\n", "if", "attr_name_kurz", "not", "in", "dataset_obj", ".", "getInputAttributeNames", "(", "'kurz'", ")", ":", "\n", "      ", "continue", "# do not overwrite the output", "\n", "", "if", "attr_obj", ".", "attr_type", "==", "'numeric-real'", ":", "\n", "      ", "model_symbols", "[", "'counterfactual'", "]", "[", "attr_name_kurz", "]", "=", "{", "\n", "'symbol'", ":", "Symbol", "(", "attr_name_kurz", "+", "'_counterfactual'", ",", "REAL", ")", ",", "\n", "'lower_bound'", ":", "Real", "(", "float", "(", "lower_bound", ")", ")", ",", "\n", "'upper_bound'", ":", "Real", "(", "float", "(", "upper_bound", ")", ")", "\n", "}", "\n", "model_symbols", "[", "'interventional'", "]", "[", "attr_name_kurz", "]", "=", "{", "\n", "'symbol'", ":", "Symbol", "(", "attr_name_kurz", "+", "'_interventional'", ",", "REAL", ")", ",", "\n", "'lower_bound'", ":", "Real", "(", "float", "(", "lower_bound", ")", ")", ",", "\n", "'upper_bound'", ":", "Real", "(", "float", "(", "upper_bound", ")", ")", "\n", "}", "\n", "", "else", ":", "# refer to loadData.VALID_ATTRIBUTE_TYPES", "\n", "      ", "model_symbols", "[", "'counterfactual'", "]", "[", "attr_name_kurz", "]", "=", "{", "\n", "'symbol'", ":", "Symbol", "(", "attr_name_kurz", "+", "'_counterfactual'", ",", "INT", ")", ",", "\n", "'lower_bound'", ":", "Int", "(", "int", "(", "lower_bound", ")", ")", ",", "\n", "'upper_bound'", ":", "Int", "(", "int", "(", "upper_bound", ")", ")", "\n", "}", "\n", "model_symbols", "[", "'interventional'", "]", "[", "attr_name_kurz", "]", "=", "{", "\n", "'symbol'", ":", "Symbol", "(", "attr_name_kurz", "+", "'_interventional'", ",", "INT", ")", ",", "\n", "'lower_bound'", ":", "Int", "(", "int", "(", "lower_bound", ")", ")", ",", "\n", "'upper_bound'", ":", "Int", "(", "int", "(", "upper_bound", ")", ")", "\n", "}", "\n", "", "", "print", "(", "'\\n\\n==============================================\\n\\n'", ",", "file", "=", "log_file", ")", "\n", "print", "(", "'Model Symbols:'", ",", "file", "=", "log_file", ")", "\n", "pprint", "(", "model_symbols", ",", "log_file", ")", "\n", "\n", "# factual_sample['y'] = False", "\n", "\n", "# find closest counterfactual sample from this negative sample", "\n", "all_counterfactuals", ",", "closest_counterfactual_sample", ",", "closest_interventional_sample", "=", "findClosestCounterfactualSample", "(", "\n", "model_trained", ",", "\n", "model_symbols", ",", "\n", "dataset_obj", ",", "\n", "factual_sample", ",", "\n", "norm_type", ",", "\n", "approach_string", ",", "\n", "epsilon", ",", "\n", "log_file", "\n", ")", "\n", "\n", "print", "(", "'\\n'", ",", "file", "=", "log_file", ")", "\n", "print", "(", "f\"Factual sample: \\t\\t {getPrettyStringForSampleDictionary(factual_sample, dataset_obj)}\"", ",", "file", "=", "log_file", ")", "\n", "if", "'mace'", "in", "approach_string", ":", "\n", "    ", "print", "(", "f\"Nearest counterfactual sample:\\t {getPrettyStringForSampleDictionary(closest_counterfactual_sample['counterfactual_sample'], dataset_obj)} (verified)\"", ",", "file", "=", "log_file", ")", "\n", "print", "(", "f\"Minimum counterfactual distance: {closest_counterfactual_sample['counterfactual_distance']:.6f}\"", ",", "file", "=", "log_file", ")", "\n", "", "elif", "'mint'", "in", "approach_string", ":", "\n", "    ", "print", "(", "f\"Nearest interventional sample:\\t {getPrettyStringForSampleDictionary(closest_interventional_sample['interventional_sample'], dataset_obj)}\"", ",", "file", "=", "log_file", ")", "\n", "print", "(", "f\"Nearest resulting CF sample:\\t {getPrettyStringForSampleDictionary(closest_interventional_sample['counterfactual_sample'], dataset_obj)} (verified)\"", ",", "file", "=", "log_file", ")", "\n", "print", "(", "f\"Minimum interventional distance: {closest_interventional_sample['interventional_distance']:.6f}\"", ",", "file", "=", "log_file", ")", "\n", "print", "(", "f\"Minimum resulting CF distance:\\t {closest_interventional_sample['counterfactual_distance']:.6f}\"", ",", "file", "=", "log_file", ")", "\n", "\n", "", "end_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "'mace'", "in", "approach_string", ":", "\n", "    ", "return", "{", "\n", "'fac_sample'", ":", "factual_sample", ",", "\n", "'cfe_found'", ":", "True", ",", "\n", "'cfe_plausible'", ":", "True", ",", "\n", "'cfe_time'", ":", "end_time", "-", "start_time", ",", "\n", "'cfe_sample'", ":", "closest_counterfactual_sample", "[", "'counterfactual_sample'", "]", ",", "\n", "'cfe_distance'", ":", "closest_counterfactual_sample", "[", "'counterfactual_distance'", "]", ",", "\n", "# 'all_counterfactuals': all_counterfactuals", "\n", "}", "\n", "", "elif", "'mint'", "in", "approach_string", ":", "\n", "    ", "action_set", "=", "{", "}", "\n", "for", "attr_name_kurz", "in", "dataset_obj", ".", "getInputAttributeNames", "(", "'kurz'", ")", ":", "\n", "      ", "if", "factual_sample", "[", "attr_name_kurz", "]", "!=", "closest_interventional_sample", "[", "'interventional_sample'", "]", "[", "attr_name_kurz", "]", ":", "\n", "        ", "action_set", "[", "attr_name_kurz", "]", "=", "closest_interventional_sample", "[", "'interventional_sample'", "]", "[", "attr_name_kurz", "]", "\n", "", "", "return", "{", "\n", "'fac_sample'", ":", "factual_sample", ",", "\n", "'scf_found'", ":", "True", ",", "\n", "'scf_plausible'", ":", "True", ",", "\n", "'scf_time'", ":", "end_time", "-", "start_time", ",", "\n", "'scf_sample'", ":", "closest_interventional_sample", "[", "'counterfactual_sample'", "]", ",", "\n", "'scf_distance'", ":", "closest_interventional_sample", "[", "'counterfactual_distance'", "]", ",", "\n", "# 'int_sample': closest_interventional_sample['interventional_sample'],", "\n", "# 'int_distance': closest_interventional_sample['interventional_distance'],", "\n", "# 'action_set': action_set,", "\n", "'int_set'", ":", "action_set", ",", "\n", "'int_cost'", ":", "closest_interventional_sample", "[", "'interventional_distance'", "]", ",", "\n", "# 'all_counterfactuals': all_counterfactuals", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.debug.ipsh": [[33, 40], ["IPython.terminal.embed.InteractiveShellEmbed", "IPython.terminal.embed.InteractiveShellEmbed.", "inspect.currentframe"], "function", ["None"], ["def", "ipsh", "(", ")", ":", "\n", "    ", "ipshell", "=", "InteractiveShellEmbed", "(", "config", "=", "cfg", ",", "banner1", "=", "banner_msg", ",", "exit_msg", "=", "exit_msg", ")", "\n", "frame", "=", "inspect", ".", "currentframe", "(", ")", ".", "f_back", "\n", "msg", "=", "'Stopped at {0.f_code.co_filename} at line {0.f_lineno}'", ".", "format", "(", "frame", ")", "\n", "# Go back one level!", "\n", "# This is needed because the call to ipshell is inside the function ipsh()", "\n", "ipshell", "(", "msg", ",", "stack_depth", "=", "2", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.amirhk_mace.None.normalizedDistance.getDistanceBetweenSamples": [[12, 85], ["dataset_obj.getMutableAttributeNames", "dataset_obj.getOneHotAttributesNames", "dataset_obj.getNonHotAttributesNames", "numpy.intersect1d", "numpy.intersect1d", "numpy.sqrt", "sample_1.keys", "sample_2.keys", "sorted", "sorted", "normalized_absolute_distances.append", "numpy.count_nonzero", "sum", "max", "sample_1.keys", "dataset_obj.getInputOutputAttributeNames", "dataset_obj.getSiblingsFor", "already_considered.extend", "len", "len", "sum", "len", "abs", "normalized_absolute_distances.append", "len", "normalized_absolute_distances.append", "Exception", "Exception", "int", "numpy.array_equal", "numpy.sum", "len", "numpy.abs", "numpy.subtract"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getMutableAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getOneHotAttributesNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getNonHotAttributesNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputOutputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getSiblingsFor"], ["def", "getDistanceBetweenSamples", "(", "sample_1", ",", "sample_2", ",", "norm_type", ",", "dataset_obj", ")", ":", "\n", "\n", "# IMPORTANT: sample1 and sample2 are dict_samples, not pysmt_samples", "\n", "# (of course, this is by design, otherwise it would break abstraction)", "\n", "  ", "assert", "(", "sample_1", ".", "keys", "(", ")", "==", "sample_2", ".", "keys", "(", ")", ")", "\n", "assert", "(", "sorted", "(", "sample_1", ".", "keys", "(", ")", ")", "==", "sorted", "(", "dataset_obj", ".", "getInputOutputAttributeNames", "(", "'kurz'", ")", ")", ")", "\n", "\n", "# normalize this feature's distance by dividing the absolute difference by the", "\n", "# range of the variable (only applies for non-hot variables)", "\n", "normalized_absolute_distances", "=", "[", "]", "\n", "\n", "mutable_attributes", "=", "dataset_obj", ".", "getMutableAttributeNames", "(", "'kurz'", ")", "\n", "one_hot_attributes", "=", "dataset_obj", ".", "getOneHotAttributesNames", "(", "'kurz'", ")", "\n", "non_hot_attributes", "=", "dataset_obj", ".", "getNonHotAttributesNames", "(", "'kurz'", ")", "\n", "\n", "# 1. mutable & non-hot", "\n", "for", "attr_name_kurz", "in", "np", ".", "intersect1d", "(", "mutable_attributes", ",", "non_hot_attributes", ")", ":", "\n", "    ", "normalized_absolute_distances", ".", "append", "(", "\n", "# note: float() works for both integer-based and real-based attributes, no", "\n", "# need to separate them out", "\n", "abs", "(", "\n", "sample_1", "[", "attr_name_kurz", "]", "-", "\n", "sample_2", "[", "attr_name_kurz", "]", "\n", ")", "/", "\n", "(", "\n", "dataset_obj", ".", "attributes_kurz", "[", "attr_name_kurz", "]", ".", "upper_bound", "-", "\n", "dataset_obj", ".", "attributes_kurz", "[", "attr_name_kurz", "]", ".", "lower_bound", "\n", ")", "\n", ")", "\n", "\n", "# 2. mutable & one-hot", "\n", "", "already_considered", "=", "[", "]", "\n", "for", "attr_name_kurz", "in", "np", ".", "intersect1d", "(", "mutable_attributes", ",", "one_hot_attributes", ")", ":", "\n", "    ", "if", "attr_name_kurz", "not", "in", "already_considered", ":", "\n", "      ", "siblings_kurz", "=", "dataset_obj", ".", "getSiblingsFor", "(", "attr_name_kurz", ")", "\n", "if", "'cat'", "in", "dataset_obj", ".", "attributes_kurz", "[", "attr_name_kurz", "]", ".", "attr_type", ":", "\n", "        ", "sub_sample_1", "=", "[", "sample_1", "[", "x", "]", "for", "x", "in", "siblings_kurz", "]", "\n", "sub_sample_2", "=", "[", "sample_2", "[", "x", "]", "for", "x", "in", "siblings_kurz", "]", "\n", "normalized_absolute_distances", ".", "append", "(", "\n", "1", "-", "int", "(", "np", ".", "array_equal", "(", "sub_sample_1", ",", "sub_sample_2", ")", ")", "\n", ")", "\n", "", "elif", "'ord'", "in", "dataset_obj", ".", "attributes_kurz", "[", "attr_name_kurz", "]", ".", "attr_type", ":", "\n", "        ", "sub_sample_1", "=", "[", "sample_1", "[", "x", "]", "for", "x", "in", "siblings_kurz", "]", "\n", "sub_sample_2", "=", "[", "sample_2", "[", "x", "]", "for", "x", "in", "siblings_kurz", "]", "\n", "normalized_absolute_distances", ".", "append", "(", "\n", "np", ".", "sum", "(", "np", ".", "abs", "(", "np", ".", "subtract", "(", "sub_sample_1", ",", "sub_sample_2", ")", ")", ")", "/", "len", "(", "sub_sample_1", ")", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "f'{attr_name_kurz} must include either `cat` or `ord`.'", ")", "\n", "", "already_considered", ".", "extend", "(", "siblings_kurz", ")", "\n", "\n", "# 3. compute normalized squared distances", "\n", "", "", "normalized_squared_distances", "=", "[", "\n", "distance", "**", "2", "\n", "for", "distance", "in", "normalized_absolute_distances", "\n", "]", "\n", "\n", "# 4. sum up over everything allowed...", "\n", "zero_norm_distance", "=", "1", "/", "len", "(", "normalized_absolute_distances", ")", "*", "np", ".", "count_nonzero", "(", "normalized_absolute_distances", ")", "\n", "one_norm_distance", "=", "1", "/", "len", "(", "normalized_absolute_distances", ")", "*", "sum", "(", "normalized_absolute_distances", ")", "\n", "two_norm_distance", "=", "np", ".", "sqrt", "(", "1", "/", "len", "(", "normalized_squared_distances", ")", "*", "sum", "(", "normalized_squared_distances", ")", ")", "# note the sqrt(1/len) guarantees dist \\in [0,1]", "\n", "infty_norm_distance", "=", "1", "/", "len", "(", "normalized_absolute_distances", ")", "*", "max", "(", "normalized_absolute_distances", ")", "\n", "\n", "if", "norm_type", "==", "'zero_norm'", ":", "\n", "    ", "return", "zero_norm_distance", "\n", "", "elif", "norm_type", "==", "'one_norm'", ":", "\n", "    ", "return", "one_norm_distance", "\n", "", "elif", "norm_type", "==", "'two_norm'", ":", "\n", "    ", "return", "two_norm_distance", "\n", "", "elif", "norm_type", "==", "'infty_norm'", ":", "\n", "    ", "return", "infty_norm_distance", "\n", "", "else", ":", "\n", "    ", "raise", "Exception", "(", "f'{norm_type} not recognized as a valid `norm_type`.'", ")", "\n", "# TODO: implement combinations of distances", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadModel.warn": [[1, 3], ["None"], "function", ["None"], ["def", "warn", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadModel.loadModelForDataset": [[38, 109], ["loadData.loadDataset", "loadData.loadDataset.getTrainTestSplit", "pandas.concat", "pandas.concat", "loadData.loadDataset.getInputAttributeNames", "print", "print", "sklearn.neural_network.MLPClassifier.fit", "print", "print", "print", "print", "print", "print", "loadModel.visualizeDatasetAndFixedModel", "open", "Exception", "Exception", "sklearn.tree.DecisionTreeClassifier", "sklearn.metrics.accuracy_score", "pickle.dump", "Exception", "sum", "len", "sklearn.ensemble.RandomForestClassifier", "model_pretrain.fit.predict", "print", "treeUtils.simplifyDecisionTree", "print", "range", "open", "sklearn.linear_model.LogisticRegression", "len", "sklearn.neural_network.MLPClassifier", "sklearn.metrics.accuracy_score", "sklearn.metrics.accuracy_score", "sklearn.metrics.accuracy_score", "sklearn.metrics.accuracy_score", "print", "treeUtils.simplifyDecisionTree", "print", "model_pretrain.fit.predict", "model_pretrain.fit.predict", "model_pretrain.fit.predict", "model_pretrain.fit.predict", "len"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.loadDataset", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getTrainTestSplit", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadModel.visualizeDatasetAndFixedModel", "home.repos.pwc.inspect_result.amirhk_mace.None.treeUtils.simplifyDecisionTree", "home.repos.pwc.inspect_result.amirhk_mace.None.treeUtils.simplifyDecisionTree"], ["@", "utils", ".", "Memoize", "\n", "def", "loadModelForDataset", "(", "model_class", ",", "dataset_string", ",", "scm_class", "=", "None", ",", "experiment_folder_name", "=", "None", ")", ":", "\n", "\n", "  ", "log_file", "=", "sys", ".", "stdout", "if", "experiment_folder_name", "==", "None", "else", "open", "(", "f'{experiment_folder_name}/log_training.txt'", ",", "'w'", ")", "\n", "\n", "if", "not", "(", "model_class", "in", "{", "'lr'", ",", "'mlp'", ",", "'tree'", ",", "'forest'", "}", ")", ":", "\n", "    ", "raise", "Exception", "(", "f'{model_class} not supported.'", ")", "\n", "\n", "", "if", "not", "(", "dataset_string", "in", "{", "'synthetic'", ",", "'mortgage'", ",", "'twomoon'", ",", "'german'", ",", "'credit'", ",", "'compass'", ",", "'adult'", ",", "'test'", "}", ")", ":", "\n", "    ", "raise", "Exception", "(", "f'{dataset_string} not supported.'", ")", "\n", "\n", "", "if", "model_class", "in", "{", "'tree'", ",", "'forest'", "}", ":", "\n", "    ", "one_hot", "=", "False", "\n", "", "elif", "model_class", "in", "{", "'lr'", ",", "'mlp'", "}", ":", "\n", "    ", "one_hot", "=", "True", "\n", "", "else", ":", "\n", "    ", "raise", "Exception", "(", "f'{model_class} not recognized as a valid `model_class`.'", ")", "\n", "\n", "", "dataset_obj", "=", "loadData", ".", "loadDataset", "(", "dataset_string", ",", "return_one_hot", "=", "one_hot", ",", "load_from_cache", "=", "False", ",", "meta_param", "=", "scm_class", ")", "\n", "X_train", ",", "X_test", ",", "y_train", ",", "y_test", "=", "dataset_obj", ".", "getTrainTestSplit", "(", ")", "\n", "X_all", "=", "pd", ".", "concat", "(", "[", "X_train", ",", "X_test", "]", ",", "axis", "=", "0", ")", "\n", "y_all", "=", "pd", ".", "concat", "(", "[", "y_train", ",", "y_test", "]", ",", "axis", "=", "0", ")", "\n", "assert", "sum", "(", "y_all", ")", "/", "len", "(", "y_all", ")", "==", "0.5", ",", "'Expected class balance should be 50/50%.'", "\n", "feature_names", "=", "dataset_obj", ".", "getInputAttributeNames", "(", "'kurz'", ")", "# easier to read (nothing to do with one-hot vs non-hit!)", "\n", "\n", "if", "model_class", "==", "'tree'", ":", "\n", "    ", "model_pretrain", "=", "DecisionTreeClassifier", "(", ")", "\n", "", "elif", "model_class", "==", "'forest'", ":", "\n", "    ", "model_pretrain", "=", "RandomForestClassifier", "(", ")", "\n", "", "elif", "model_class", "==", "'lr'", ":", "\n", "# IMPORTANT: The default solver changed from \u2018liblinear\u2019 to \u2018lbfgs\u2019 in 0.22;", "\n", "#            therefore, results may differ slightly from paper.", "\n", "    ", "model_pretrain", "=", "LogisticRegression", "(", ")", "# default penalty='l2', i.e., ridge", "\n", "", "elif", "model_class", "==", "'mlp'", ":", "\n", "    ", "model_pretrain", "=", "MLPClassifier", "(", "hidden_layer_sizes", "=", "(", "10", ",", "10", ")", ")", "\n", "\n", "", "tmp_text", "=", "f'[INFO] Training `{model_class}` on {X_train.shape[0]:,} samples '", "+", "f'(%{100 * X_train.shape[0] / (X_train.shape[0] + X_test.shape[0]):.2f} '", "+", "f'of {X_train.shape[0] + X_test.shape[0]:,} samples)...'", "\n", "print", "(", "tmp_text", ")", "\n", "print", "(", "tmp_text", ",", "file", "=", "log_file", ")", "\n", "model_trained", "=", "model_pretrain", ".", "fit", "(", "X_train", ",", "y_train", ")", "\n", "print", "(", "f'\\tTraining accuracy: %{accuracy_score(y_train, model_trained.predict(X_train)) * 100:.2f}'", ",", "file", "=", "log_file", ")", "\n", "print", "(", "f'\\tTesting accuracy: %{accuracy_score(y_test, model_trained.predict(X_test)) * 100:.2f}'", ",", "file", "=", "log_file", ")", "\n", "print", "(", "f'\\tTraining accuracy: %{accuracy_score(y_train, model_trained.predict(X_train)) * 100:.2f}'", ")", "\n", "print", "(", "f'\\tTesting accuracy: %{accuracy_score(y_test, model_trained.predict(X_test)) * 100:.2f}'", ")", "\n", "print", "(", "'[INFO] done.\\n'", ",", "file", "=", "log_file", ")", "\n", "print", "(", "'[INFO] done.\\n'", ")", "\n", "assert", "accuracy_score", "(", "y_train", ",", "model_trained", ".", "predict", "(", "X_train", ")", ")", ">", "0.70", "\n", "\n", "classifier_obj", "=", "model_trained", "\n", "visualizeDatasetAndFixedModel", "(", "dataset_obj", ",", "classifier_obj", ",", "experiment_folder_name", ")", "\n", "\n", "if", "model_class", "==", "'tree'", ":", "\n", "    ", "if", "SIMPLIFY_TREES", ":", "\n", "      ", "print", "(", "'[INFO] Simplifying decision tree...'", ",", "end", "=", "''", ",", "file", "=", "log_file", ")", "\n", "model_trained", ".", "tree_", "=", "treeUtils", ".", "simplifyDecisionTree", "(", "model_trained", ",", "False", ")", "\n", "print", "(", "'\\tdone.'", ",", "file", "=", "log_file", ")", "\n", "# treeUtils.saveTreeVisualization(model_trained, model_class, '', X_test, feature_names, experiment_folder_name)", "\n", "", "", "elif", "model_class", "==", "'forest'", ":", "\n", "    ", "for", "tree_idx", "in", "range", "(", "len", "(", "model_trained", ".", "estimators_", ")", ")", ":", "\n", "      ", "if", "SIMPLIFY_TREES", ":", "\n", "        ", "print", "(", "f'[INFO] Simplifying decision tree (#{tree_idx + 1}/{len(model_trained.estimators_)})...'", ",", "end", "=", "''", ",", "file", "=", "log_file", ")", "\n", "model_trained", ".", "estimators_", "[", "tree_idx", "]", ".", "tree_", "=", "treeUtils", ".", "simplifyDecisionTree", "(", "model_trained", ".", "estimators_", "[", "tree_idx", "]", ",", "False", ")", "\n", "print", "(", "'\\tdone.'", ",", "file", "=", "log_file", ")", "\n", "# treeUtils.saveTreeVisualization(model_trained.estimators_[tree_idx], model_class, f'tree{tree_idx}', X_test, feature_names, experiment_folder_name)", "\n", "\n", "", "", "", "if", "experiment_folder_name", ":", "\n", "    ", "pickle", ".", "dump", "(", "model_trained", ",", "open", "(", "f'{experiment_folder_name}/_model_trained'", ",", "'wb'", ")", ")", "\n", "\n", "", "return", "model_trained", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadModel.scatterDataset": [[111, 128], ["dataset_obj.getTrainTestSplit", "X_train.to_numpy", "X_test.to_numpy", "y_train.to_numpy.to_numpy", "y_test.to_numpy.to_numpy", "min", "range", "len", "dataset_obj.getInputAttributeNames", "ax.scatter", "ax.scatter", "ax.scatter", "ax.scatter"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getTrainTestSplit", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames"], ["", "def", "scatterDataset", "(", "dataset_obj", ",", "classifier_obj", ",", "ax", ")", ":", "\n", "  ", "assert", "len", "(", "dataset_obj", ".", "getInputAttributeNames", "(", ")", ")", "<=", "3", "\n", "X_train", ",", "X_test", ",", "y_train", ",", "y_test", "=", "dataset_obj", ".", "getTrainTestSplit", "(", ")", "\n", "X_train_numpy", "=", "X_train", ".", "to_numpy", "(", ")", "\n", "X_test_numpy", "=", "X_test", ".", "to_numpy", "(", ")", "\n", "y_train", "=", "y_train", ".", "to_numpy", "(", ")", "\n", "y_test", "=", "y_test", ".", "to_numpy", "(", ")", "\n", "number_of_samples_to_plot", "=", "min", "(", "200", ",", "X_train_numpy", ".", "shape", "[", "0", "]", ",", "X_test_numpy", ".", "shape", "[", "0", "]", ")", "\n", "for", "idx", "in", "range", "(", "number_of_samples_to_plot", ")", ":", "\n", "    ", "color_train", "=", "'black'", "if", "y_train", "[", "idx", "]", "==", "1", "else", "'magenta'", "\n", "color_test", "=", "'black'", "if", "y_test", "[", "idx", "]", "==", "1", "else", "'magenta'", "\n", "if", "X_train", ".", "shape", "[", "1", "]", "==", "2", ":", "\n", "      ", "ax", ".", "scatter", "(", "X_train_numpy", "[", "idx", ",", "0", "]", ",", "X_train_numpy", "[", "idx", ",", "1", "]", ",", "marker", "=", "'s'", ",", "color", "=", "color_train", ",", "alpha", "=", "0.2", ",", "s", "=", "10", ")", "\n", "ax", ".", "scatter", "(", "X_test_numpy", "[", "idx", ",", "0", "]", ",", "X_test_numpy", "[", "idx", ",", "1", "]", ",", "marker", "=", "'o'", ",", "color", "=", "color_test", ",", "alpha", "=", "0.2", ",", "s", "=", "15", ")", "\n", "", "elif", "X_train", ".", "shape", "[", "1", "]", "==", "3", ":", "\n", "      ", "ax", ".", "scatter", "(", "X_train_numpy", "[", "idx", ",", "0", "]", ",", "X_train_numpy", "[", "idx", ",", "1", "]", ",", "X_train_numpy", "[", "idx", ",", "2", "]", ",", "marker", "=", "'s'", ",", "color", "=", "color_train", ",", "alpha", "=", "0.2", ",", "s", "=", "10", ")", "\n", "ax", ".", "scatter", "(", "X_test_numpy", "[", "idx", ",", "0", "]", ",", "X_test_numpy", "[", "idx", ",", "1", "]", ",", "X_test_numpy", "[", "idx", ",", "2", "]", ",", "marker", "=", "'o'", ",", "color", "=", "color_test", ",", "alpha", "=", "0.2", ",", "s", "=", "15", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadModel.scatterDecisionBoundary": [[130, 169], ["len", "numpy.linspace", "numpy.linspace", "numpy.meshgrid", "np.linspace.ravel", "np.linspace.ravel", "classifier_obj.predict", "classifier_obj.predict.reshape", "matplotlib.pyplot.get_cmap", "ax.contourf", "dataset_obj.getInputAttributeNames", "len", "numpy.linspace", "numpy.linspace", "numpy.meshgrid", "ax.plot_wireframe", "ax.get_xlim", "ax.get_xlim", "ax.get_ylim", "ax.get_ylim", "dataset_obj.getInputAttributeNames", "ax.get_xlim", "ax.get_xlim", "ax.get_ylim", "ax.get_ylim", "ax.get_xlim", "ax.get_xlim", "ax.get_ylim", "ax.get_ylim", "ax.get_xlim", "ax.get_xlim", "ax.get_ylim", "ax.get_ylim"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames"], ["", "", "", "def", "scatterDecisionBoundary", "(", "dataset_obj", ",", "classifier_obj", ",", "ax", ")", ":", "\n", "\n", "  ", "if", "len", "(", "dataset_obj", ".", "getInputAttributeNames", "(", ")", ")", "==", "2", ":", "\n", "\n", "    ", "x_range", "=", "ax", ".", "get_xlim", "(", ")", "[", "1", "]", "-", "ax", ".", "get_xlim", "(", ")", "[", "0", "]", "\n", "y_range", "=", "ax", ".", "get_ylim", "(", ")", "[", "1", "]", "-", "ax", ".", "get_ylim", "(", ")", "[", "0", "]", "\n", "X", "=", "np", ".", "linspace", "(", "ax", ".", "get_xlim", "(", ")", "[", "0", "]", "-", "x_range", "/", "10", ",", "ax", ".", "get_xlim", "(", ")", "[", "1", "]", "+", "x_range", "/", "10", ",", "1000", ")", "\n", "Y", "=", "np", ".", "linspace", "(", "ax", ".", "get_ylim", "(", ")", "[", "0", "]", "-", "y_range", "/", "10", ",", "ax", ".", "get_ylim", "(", ")", "[", "1", "]", "+", "y_range", "/", "10", ",", "1000", ")", "\n", "X", ",", "Y", "=", "np", ".", "meshgrid", "(", "X", ",", "Y", ")", "\n", "Xp", "=", "X", ".", "ravel", "(", ")", "\n", "Yp", "=", "Y", ".", "ravel", "(", ")", "\n", "\n", "# if normalized_fixed_model is False:", "\n", "#   labels = classifier_obj.predict(np.c_[Xp, Yp])", "\n", "# else:", "\n", "#   Xp = (Xp - dataset_obj.attributes_kurz['x0'].lower_bound) / \\", "\n", "#        (dataset_obj.attributes_kurz['x0'].upper_bound - dataset_obj.attributes_kurz['x0'].lower_bound)", "\n", "#   Yp = (Yp - dataset_obj.attributes_kurz['x1'].lower_bound) / \\", "\n", "#        (dataset_obj.attributes_kurz['x1'].upper_bound - dataset_obj.attributes_kurz['x1'].lower_bound)", "\n", "#   labels = classifier_obj.predict(np.c_[Xp, Yp])", "\n", "labels", "=", "classifier_obj", ".", "predict", "(", "np", ".", "c_", "[", "Xp", ",", "Yp", "]", ")", "\n", "Z", "=", "labels", ".", "reshape", "(", "X", ".", "shape", ")", "\n", "\n", "cmap", "=", "plt", ".", "get_cmap", "(", "'Paired'", ")", "\n", "ax", ".", "contourf", "(", "X", ",", "Y", ",", "Z", ",", "cmap", "=", "cmap", ",", "alpha", "=", "0.5", ")", "\n", "\n", "", "elif", "len", "(", "dataset_obj", ".", "getInputAttributeNames", "(", ")", ")", "==", "3", ":", "\n", "\n", "    ", "fixed_model_w", "=", "classifier_obj", ".", "coef_", "\n", "fixed_model_b", "=", "classifier_obj", ".", "intercept_", "\n", "\n", "x_range", "=", "ax", ".", "get_xlim", "(", ")", "[", "1", "]", "-", "ax", ".", "get_xlim", "(", ")", "[", "0", "]", "\n", "y_range", "=", "ax", ".", "get_ylim", "(", ")", "[", "1", "]", "-", "ax", ".", "get_ylim", "(", ")", "[", "0", "]", "\n", "X", "=", "np", ".", "linspace", "(", "ax", ".", "get_xlim", "(", ")", "[", "0", "]", "-", "x_range", "/", "10", ",", "ax", ".", "get_xlim", "(", ")", "[", "1", "]", "+", "x_range", "/", "10", ",", "10", ")", "\n", "Y", "=", "np", ".", "linspace", "(", "ax", ".", "get_ylim", "(", ")", "[", "0", "]", "-", "y_range", "/", "10", ",", "ax", ".", "get_ylim", "(", ")", "[", "1", "]", "+", "y_range", "/", "10", ",", "10", ")", "\n", "X", ",", "Y", "=", "np", ".", "meshgrid", "(", "X", ",", "Y", ")", "\n", "Z", "=", "-", "(", "fixed_model_w", "[", "0", "]", "[", "0", "]", "*", "X", "+", "fixed_model_w", "[", "0", "]", "[", "1", "]", "*", "Y", "+", "fixed_model_b", ")", "/", "fixed_model_w", "[", "0", "]", "[", "2", "]", "\n", "\n", "surf", "=", "ax", ".", "plot_wireframe", "(", "X", ",", "Y", ",", "Z", ",", "alpha", "=", "0.3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.loadModel.visualizeDatasetAndFixedModel": [[172, 199], ["matplotlib.pyplot.figure", "loadModel.scatterDataset", "loadModel.scatterDecisionBoundary", "plt.subplot.set_title", "plt.subplot.grid", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "len", "matplotlib.pyplot.subplot", "plt.subplot.set_xlabel", "plt.subplot.set_ylabel", "plt.subplot.grid", "len", "dataset_obj.getInputAttributeNames", "len", "matplotlib.pyplot.subplot", "plt.subplot.set_xlabel", "plt.subplot.set_ylabel", "plt.subplot.set_zlabel", "plt.subplot.view_init", "dataset_obj.getInputAttributeNames", "dataset_obj.getInputAttributeNames"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadModel.scatterDataset", "home.repos.pwc.inspect_result.amirhk_mace.None.loadModel.scatterDecisionBoundary", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames"], ["", "", "def", "visualizeDatasetAndFixedModel", "(", "dataset_obj", ",", "classifier_obj", ",", "experiment_folder_name", ")", ":", "\n", "\n", "  ", "if", "not", "len", "(", "dataset_obj", ".", "getInputAttributeNames", "(", ")", ")", "<=", "3", ":", "\n", "    ", "return", "\n", "\n", "", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "if", "len", "(", "dataset_obj", ".", "getInputAttributeNames", "(", ")", ")", "==", "2", ":", "\n", "    ", "ax", "=", "plt", ".", "subplot", "(", ")", "\n", "ax", ".", "set_xlabel", "(", "'x1'", ")", "\n", "ax", ".", "set_ylabel", "(", "'x2'", ")", "\n", "ax", ".", "grid", "(", ")", "\n", "", "elif", "len", "(", "dataset_obj", ".", "getInputAttributeNames", "(", ")", ")", "==", "3", ":", "\n", "    ", "ax", "=", "plt", ".", "subplot", "(", "1", ",", "1", ",", "1", ",", "projection", "=", "'3d'", ")", "\n", "ax", ".", "set_xlabel", "(", "'x1'", ")", "\n", "ax", ".", "set_ylabel", "(", "'x2'", ")", "\n", "ax", ".", "set_zlabel", "(", "'x3'", ")", "\n", "ax", ".", "view_init", "(", "elev", "=", "10", ",", "azim", "=", "-", "20", ")", "\n", "\n", "", "scatterDataset", "(", "dataset_obj", ",", "classifier_obj", ",", "ax", ")", "\n", "scatterDecisionBoundary", "(", "dataset_obj", ",", "classifier_obj", ",", "ax", ")", "\n", "\n", "ax", ".", "set_title", "(", "f'{dataset_obj.dataset_name}'", ")", "\n", "ax", ".", "grid", "(", "True", ")", "\n", "\n", "# plt.show()", "\n", "plt", ".", "savefig", "(", "f'{experiment_folder_name}/_dataset_and_model.pdf'", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None._depAnalyzeResults.measureSensitiveAttributeChange": [[2, 48], ["pickle.load", "df_all_distances.where().dropna.where().dropna", "open", "df_all_distances.where().dropna.where", "df_all_distances.where().dropna.where().dropna", "df_all_distances.where().dropna.where().dropna", "df_all_distances.where().dropna.where().dropna", "df_all_distances.where().dropna.where().dropna", "df_all_distances.where().dropna.where().dropna", "df_all_distances.where().dropna.where().dropna", "df_all_distances.where().dropna.where().dropna", "df_all_distances.where().dropna.where().dropna", "df_all_distances.where().dropna.where().dropna", "print", "print", "print", "print", "df_all_distances.where().dropna.where", "print", "df_all_distances.where().dropna.where", "df_all_distances.where().dropna.where", "df_all_distances.where().dropna.where", "df_all_distances.where().dropna.where", "df_all_distances.where().dropna.where", "df_all_distances.where().dropna.where", "df_all_distances.where().dropna.where", "df_all_distances.where().dropna.where"], "function", ["None"], ["def", "measureSensitiveAttributeChange", "(", ")", ":", "\n", "  ", "df_all_distances", "=", "pickle", ".", "load", "(", "open", "(", "f'_results/df_all_distances'", ",", "'rb'", ")", ")", "\n", "df_all_distances", "=", "df_all_distances", ".", "where", "(", "\n", "(", "df_all_distances", "[", "'counterfactual found'", "]", "==", "True", ")", "&", "\n", "(", "df_all_distances", "[", "'counterfactual plausible'", "]", "==", "True", ")", "\n", ")", ".", "dropna", "(", ")", "\n", "for", "model_class_string", "in", "MODEL_CLASS_VALUES", ":", "\n", "    ", "for", "approach_string", "in", "APPROACHES_VALUES", ":", "\n", "      ", "for", "dataset_string", "in", "DATASET_VALUES", ":", "\n", "        ", "for", "norm_type_string", "in", "NORM_VALUES", ":", "\n", "          ", "df", "=", "df_all_distances", ".", "where", "(", "\n", "(", "df_all_distances", "[", "'dataset'", "]", "==", "dataset_string", ")", "&", "\n", "(", "df_all_distances", "[", "'model'", "]", "==", "model_class_string", ")", "&", "\n", "(", "df_all_distances", "[", "'norm'", "]", "==", "norm_type_string", ")", "&", "\n", "(", "df_all_distances", "[", "'approach'", "]", "==", "approach_string", ")", ",", "\n", ")", ".", "dropna", "(", ")", "\n", "if", "df", ".", "shape", "[", "0", "]", ":", "# if any tests exist for this setup", "\n", "            ", "age_changed", "=", "df", ".", "where", "(", "df", "[", "'changed age'", "]", "==", "True", ")", ".", "dropna", "(", ")", "\n", "age_not_changed", "=", "df", ".", "where", "(", "df", "[", "'changed age'", "]", "==", "False", ")", ".", "dropna", "(", ")", "\n", "gender_changed", "=", "df", ".", "where", "(", "df", "[", "'changed gender'", "]", "==", "True", ")", ".", "dropna", "(", ")", "\n", "gender_not_changed", "=", "df", ".", "where", "(", "df", "[", "'changed gender'", "]", "==", "False", ")", ".", "dropna", "(", ")", "\n", "race_changed", "=", "df", ".", "where", "(", "df", "[", "'changed race'", "]", "==", "True", ")", ".", "dropna", "(", ")", "\n", "race_not_changed", "=", "df", ".", "where", "(", "df", "[", "'changed race'", "]", "==", "False", ")", ".", "dropna", "(", ")", "\n", "\n", "sensitive_changed", "=", "df", ".", "where", "(", "\n", "(", "df", "[", "'changed age'", "]", "==", "True", ")", "|", "\n", "(", "df", "[", "'changed gender'", "]", "==", "True", ")", "|", "\n", "(", "df", "[", "'changed race'", "]", "==", "True", ")", "\n", ")", ".", "dropna", "(", ")", "\n", "sensitive_not_changed", "=", "df", ".", "where", "(", "\n", "(", "df", "[", "'changed age'", "]", "==", "False", ")", "&", "\n", "(", "df", "[", "'changed gender'", "]", "==", "False", ")", "&", "\n", "(", "df", "[", "'changed race'", "]", "==", "False", ")", "\n", ")", ".", "dropna", "(", ")", "\n", "\n", "assert", "df", ".", "shape", "[", "0", "]", "==", "age_changed", ".", "shape", "[", "0", "]", "+", "age_not_changed", ".", "shape", "[", "0", "]", "\n", "assert", "df", ".", "shape", "[", "0", "]", "==", "gender_changed", ".", "shape", "[", "0", "]", "+", "gender_not_changed", ".", "shape", "[", "0", "]", "\n", "assert", "df", ".", "shape", "[", "0", "]", "==", "race_changed", ".", "shape", "[", "0", "]", "+", "race_not_changed", ".", "shape", "[", "0", "]", "\n", "assert", "df", ".", "shape", "[", "0", "]", "==", "sensitive_changed", ".", "shape", "[", "0", "]", "+", "sensitive_not_changed", ".", "shape", "[", "0", "]", "\n", "\n", "print", "(", "f'{dataset_string}-{model_class_string}-{norm_type_string}-{approach_string}:'", ".", "ljust", "(", "40", ")", ",", "end", "=", "''", ")", "\n", "print", "(", "f'\\t\\tpercent age change: % {100 * age_changed.shape[0] / df.shape[0]:.2f}'", ",", "end", "=", "''", ")", "\n", "print", "(", "f'\\t\\tpercent gender change: % {100 * gender_changed.shape[0] / df.shape[0]:.2f}'", ",", "end", "=", "''", ")", "\n", "if", "dataset_string", "==", "'compass'", ":", "\n", "              ", "print", "(", "f'\\t\\tpercent race change: % {100 * race_changed.shape[0] / df.shape[0]:.2f}'", ",", "end", "=", "''", ")", "\n", "", "print", "(", "f'\\t\\tsensitive_changed: {sensitive_changed.shape[0]}, \\t sensitive_not_changed: {sensitive_not_changed.shape[0]}, \\t percent: % {100 * sensitive_changed.shape[0] / df.shape[0]:.2f}'", ",", "end", "=", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None._depAnalyzeResults.measureEffectOfAgeCompass": [[50, 101], ["pickle.load", "df_all_distances.where().dropna.where().dropna", "open", "df_all_distances.where().dropna.where().dropna", "df_all_distances.where().dropna.where", "df_all_distances.where().dropna.where().dropna", "df_all_distances.where().dropna.where().dropna", "print", "print", "np.unique", "print", "np.unique", "print", "df_all_distances.where().dropna.where", "df.where().dropna.where().dropna", "print", "df.where().dropna.where().dropna", "print", "df_all_distances.where().dropna.where", "df_all_distances.where().dropna.where", "df.where().dropna.where", "df.where().dropna.where"], "function", ["None"], ["", "", "", "", "", "", "def", "measureEffectOfAgeCompass", "(", ")", ":", "\n", "  ", "df_all_distances", "=", "pickle", ".", "load", "(", "open", "(", "f'_results/df_all_distances'", ",", "'rb'", ")", ")", "\n", "df_all_distances", "=", "df_all_distances", ".", "where", "(", "\n", "(", "df_all_distances", "[", "'counterfactual found'", "]", "==", "True", ")", "&", "\n", "(", "df_all_distances", "[", "'counterfactual plausible'", "]", "==", "True", ")", "\n", ")", ".", "dropna", "(", ")", "\n", "model_class_string", "=", "'lr'", "\n", "dataset_string", "=", "'compass'", "\n", "norm_type_string", "=", "'zero_norm'", "\n", "for", "approach_string", "in", "[", "'MACE_eps_1e-5'", ",", "'MO'", "]", ":", "\n", "\n", "    ", "df", "=", "df_all_distances", ".", "where", "(", "\n", "(", "df_all_distances", "[", "'dataset'", "]", "==", "dataset_string", ")", "&", "\n", "(", "df_all_distances", "[", "'model'", "]", "==", "model_class_string", ")", "&", "\n", "(", "df_all_distances", "[", "'norm'", "]", "==", "norm_type_string", ")", "&", "\n", "(", "df_all_distances", "[", "'approach'", "]", "==", "approach_string", ")", ",", "\n", ")", ".", "dropna", "(", ")", "\n", "if", "df", ".", "shape", "[", "0", "]", ":", "# if any tests exist for this setup", "\n", "      ", "age_changed", "=", "df", ".", "where", "(", "df", "[", "'changed age'", "]", "==", "True", ")", ".", "dropna", "(", ")", "\n", "age_not_changed", "=", "df", ".", "where", "(", "df", "[", "'changed age'", "]", "==", "False", ")", ".", "dropna", "(", ")", "\n", "assert", "df", ".", "shape", "[", "0", "]", "==", "age_changed", ".", "shape", "[", "0", "]", "+", "age_not_changed", ".", "shape", "[", "0", "]", "\n", "\n", "print", "(", "f'\\n\\n{dataset_string}-{model_class_string}-{norm_type_string}-{approach_string}:'", ".", "ljust", "(", "40", ")", ")", "\n", "\n", "# print(f'\\tage_changed: {age_changed.shape[0]} samples')", "\n", "# uniques, counts = np.unique(age_changed[\"counterfactual distance\"], return_counts = True)", "\n", "# for idx, elem in enumerate(uniques):", "\n", "#   print(f'\\t\\t{counts[idx]} samples at distance {uniques[idx]}')", "\n", "\n", "# print(f'\\tage_not_changed: {age_not_changed.shape[0]} samples')", "\n", "# uniques, counts = np.unique(age_not_changed[\"counterfactual distance\"], return_counts = True)", "\n", "# for idx, elem in enumerate(uniques):", "\n", "#   print(f'\\t\\t{counts[idx]} samples at distance {uniques[idx]}')", "\n", "\n", "print", "(", "f'\\tage_changed: {age_changed.shape[0]} samples'", ")", "\n", "for", "unique_distance", "in", "np", ".", "unique", "(", "age_changed", "[", "\"counterfactual distance\"", "]", ")", ":", "\n", "        ", "unique_distance_df", "=", "age_changed", ".", "where", "(", "age_changed", "[", "'counterfactual distance'", "]", "==", "unique_distance", ")", ".", "dropna", "(", ")", "\n", "print", "(", "f'\\t\\t{unique_distance_df.shape[0]} samples at distance {unique_distance}'", ")", "\n", "# unique_attr_changes, counts = np.unique(unique_distance_df[\"changed attributes\"], return_counts = True)", "\n", "# for idx, unique_attr_change in enumerate(unique_attr_changes):", "\n", "#   print(f'\\t\\t\\t{counts[idx]} samples changing attributes {unique_attr_change}')", "\n", "\n", "", "print", "(", "f'\\tage_not_changed: {age_not_changed.shape[0]} samples'", ")", "\n", "for", "unique_distance", "in", "np", ".", "unique", "(", "age_not_changed", "[", "\"counterfactual distance\"", "]", ")", ":", "\n", "        ", "unique_distance_df", "=", "age_not_changed", ".", "where", "(", "age_not_changed", "[", "'counterfactual distance'", "]", "==", "unique_distance", ")", ".", "dropna", "(", ")", "\n", "print", "(", "f'\\t\\t{unique_distance_df.shape[0]} samples at distance {unique_distance}'", ")", "\n", "# unique_attr_changes, counts = np.unique(unique_distance_df[\"changed attributes\"], return_counts = True)", "\n", "# for idx, unique_attr_change in enumerate(unique_attr_changes):", "\n", "#   print(f'\\t\\t\\t{counts[idx]} samples changing attributes {unique_attr_change}')", "\n", "\n", "", "print", "(", "f'\\tpercent: % {100 * age_changed.shape[0] / df.shape[0]:.2f}'", ",", "end", "=", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None._depAnalyzeResults.measureEffectOfRaceCompass": [[103, 143], ["print", "pickle.load", "pickle.load", "pickle.load.keys", "print", "print", "print", "print", "open", "open", "np.isclose", "increase_in_distance.append", "unrestricted_distances.append", "restricted_distances.append", "np.mean", "np.mean", "np.mean", "np.isclose", "print"], "function", ["None"], ["", "", "", "def", "measureEffectOfRaceCompass", "(", ")", ":", "\n", "  ", "pairs", "=", "[", "\n", "(", "\n", "'compass-lr-one_norm-AR'", ",", "\n", "'/Users/a6karimi/dev/mace/_experiments/2019.05.23_14.10.06__compass__lr__one_norm__AR__batch0__samples500/_minimum_distances'", ",", "\n", "'/Users/a6karimi/dev/mace/_experiments/2019.05.23_14.10.40__compass__lr__one_norm__AR__batch0__samples500/_minimum_distances'", ",", "\n", ")", ",", "# ('compass-lr-infty_norm-AR', ), \\", "\n", "]", "\n", "print", "(", "'\\n\\n<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\\n\\n'", ")", "\n", "for", "pair", "in", "pairs", ":", "\n", "    ", "unrestricted_file", "=", "pickle", ".", "load", "(", "open", "(", "pair", "[", "1", "]", ",", "'rb'", ")", ")", "\n", "restricted_file", "=", "pickle", ".", "load", "(", "open", "(", "pair", "[", "2", "]", ",", "'rb'", ")", ")", "\n", "increase_in_distance", "=", "[", "]", "\n", "unrestricted_distances", "=", "[", "]", "\n", "restricted_distances", "=", "[", "]", "\n", "for", "factual_sample_index", "in", "unrestricted_file", ".", "keys", "(", ")", ":", "\n", "\n", "      ", "restricted_factual_sample", "=", "restricted_file", "[", "factual_sample_index", "]", "[", "'factual_sample'", "]", "\n", "unrestricted_factual_sample", "=", "unrestricted_file", "[", "factual_sample_index", "]", "[", "'factual_sample'", "]", "\n", "restricted_counterfactual_sample", "=", "restricted_file", "[", "factual_sample_index", "]", "[", "'counterfactual_sample'", "]", "\n", "unrestricted_counterfactual_sample", "=", "unrestricted_file", "[", "factual_sample_index", "]", "[", "'counterfactual_sample'", "]", "\n", "assert", "restricted_factual_sample", "==", "unrestricted_factual_sample", "\n", "\n", "# if it changes race", "\n", "if", "not", "np", ".", "isclose", "(", "unrestricted_factual_sample", "[", "'x3'", "]", ",", "unrestricted_counterfactual_sample", "[", "'x3'", "]", ")", ":", "\n", "        ", "unrestricted_distance", "=", "unrestricted_counterfactual_sample", "[", "'counterfactual_distance'", "]", "\n", "restricted_distance", "=", "restricted_counterfactual_sample", "[", "'counterfactual_distance'", "]", "\n", "try", ":", "\n", "          ", "assert", "(", "restricted_distance", ">=", "unrestricted_distance", ")", "or", "np", ".", "isclose", "(", "restricted_distance", ",", "unrestricted_distance", ",", "1e-3", ",", "1e-3", ")", "\n", "", "except", ":", "\n", "          ", "print", "(", "f'\\t Unexpected: \\t\\t restricted_distance - unrestricted_distance = {restricted_distance - unrestricted_distance}'", ")", "\n", "", "increase_in_distance", ".", "append", "(", "restricted_distance", "/", "unrestricted_distance", ")", "\n", "unrestricted_distances", ".", "append", "(", "unrestricted_distance", ")", "\n", "restricted_distances", ".", "append", "(", "restricted_distance", ")", "\n", "\n", "", "", "print", "(", "f'{pair[0]}:'", ")", "\n", "print", "(", "f'\\t\\tMean unrestricted distance = {np.mean(unrestricted_distances):.4f}'", ")", "\n", "print", "(", "f'\\t\\tMean restricted distance = {np.mean(restricted_distances):.4f}'", ")", "\n", "print", "(", "f'\\t\\tMean increase in distance (restricted / unrestricted) = {np.mean(increase_in_distance):.4f}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None._depAnalyzeResults.measureEffectOfAgeAdultPart1": [[161, 216], ["pickle.load", "df_all_distances.where().dropna.where().dropna", "open", "df_all_distances.where().dropna.where", "df_all_distances.where().dropna.where().dropna", "df_all_distances.where().dropna.where().dropna", "df_all_distances.where().dropna.where().dropna", "df_all_distances.where().dropna.where().dropna", "print", "print", "print", "print", "pickle.dump", "pickle.dump", "df_all_distances.where().dropna.where", "open", "open", "df_all_distances.where().dropna.where", "df_all_distances.where().dropna.where", "df_all_distances.where().dropna.where", "np.mean", "np.mean", "np.mean"], "function", ["None"], ["", "", "def", "measureEffectOfAgeAdultPart1", "(", ")", ":", "\n", "  ", "df_all_distances", "=", "pickle", ".", "load", "(", "open", "(", "f'_results/df_all_distances'", ",", "'rb'", ")", ")", "\n", "df_all_distances", "=", "df_all_distances", ".", "where", "(", "\n", "(", "df_all_distances", "[", "'counterfactual found'", "]", "==", "True", ")", "&", "\n", "(", "df_all_distances", "[", "'counterfactual plausible'", "]", "==", "True", ")", "\n", ")", ".", "dropna", "(", ")", "\n", "\n", "model_class_string", "=", "'forest'", "\n", "dataset_string", "=", "'adult'", "\n", "for", "approach_string", "in", "[", "'MACE_eps_1e-5'", ",", "'MO'", ",", "'PFT'", "]", ":", "\n", "    ", "for", "norm_type_string", "in", "[", "'zero_norm'", ",", "'one_norm'", ",", "'infty_norm'", "]", ":", "\n", "\n", "      ", "df", "=", "df_all_distances", ".", "where", "(", "\n", "(", "df_all_distances", "[", "'dataset'", "]", "==", "dataset_string", ")", "&", "\n", "(", "df_all_distances", "[", "'model'", "]", "==", "model_class_string", ")", "&", "\n", "(", "df_all_distances", "[", "'norm'", "]", "==", "norm_type_string", ")", "&", "\n", "(", "df_all_distances", "[", "'approach'", "]", "==", "approach_string", ")", ",", "\n", ")", ".", "dropna", "(", ")", "\n", "if", "df", ".", "shape", "[", "0", "]", ":", "# if any tests exist for this setup", "\n", "\n", "        ", "age_constant", "=", "df", ".", "where", "(", "df", "[", "'age constant'", "]", "==", "True", ")", ".", "dropna", "(", ")", "\n", "age_increased", "=", "df", ".", "where", "(", "df", "[", "'age increased'", "]", "==", "True", ")", ".", "dropna", "(", ")", "\n", "age_decreased", "=", "df", ".", "where", "(", "df", "[", "'age decreased'", "]", "==", "True", ")", ".", "dropna", "(", ")", "\n", "assert", "df", ".", "shape", "[", "0", "]", "==", "age_constant", ".", "shape", "[", "0", "]", "+", "age_increased", ".", "shape", "[", "0", "]", "+", "age_decreased", ".", "shape", "[", "0", "]", "\n", "\n", "test_name", "=", "f'{dataset_string}-{model_class_string}-{norm_type_string}-{approach_string}'", "\n", "\n", "print", "(", "f'\\n\\n{test_name}:'", ".", "ljust", "(", "40", ")", ")", "\n", "\n", "print", "(", "f'\\tage_increased: {age_increased.shape[0]} samples \\t % {100 * age_increased.shape[0] / df.shape[0]} \\t average cost: {np.mean(age_increased[\"counterfactual distance\"]):.4f}'", ")", "\n", "# for unique_distance in np.unique(age_increased[\"counterfactual distance\"]):", "\n", "#   unique_distance_df = age_increased.where(age_increased['counterfactual distance'] == unique_distance).dropna()", "\n", "#   print(f'\\t\\t{unique_distance_df.shape[0]} samples at distance {unique_distance}')", "\n", "# unique_attr_changes, counts = np.unique(unique_distance_df[\"changed attributes\"], return_counts = True)", "\n", "# for idx, unique_attr_change in enumerate(unique_attr_changes):", "\n", "#   print(f'\\t\\t\\t{counts[idx]} samples changing attributes {unique_attr_change}')", "\n", "\n", "print", "(", "f'\\tage_constant: {age_constant.shape[0]} samples \\t % {100 * age_constant.shape[0] / df.shape[0]} \\t average cost: {np.mean(age_constant[\"counterfactual distance\"]):.4f}'", ")", "\n", "# for unique_distance in np.unique(age_constant[\"counterfactual distance\"]):", "\n", "#   unique_distance_df = age_constant.where(age_constant['counterfactual distance'] == unique_distance).dropna()", "\n", "#   print(f'\\t\\t{unique_distance_df.shape[0]} samples at distance {unique_distance}')", "\n", "# unique_attr_changes, counts = np.unique(unique_distance_df[\"changed attributes\"], return_counts = True)", "\n", "# for idx, unique_attr_change in enumerate(unique_attr_changes):", "\n", "#   print(f'\\t\\t\\t{counts[idx]} samples changing attributes {unique_attr_change}')", "\n", "\n", "print", "(", "f'\\tage_decreased: {age_decreased.shape[0]} samples \\t % {100 * age_decreased.shape[0] / df.shape[0]} \\t average cost: {np.mean(age_decreased[\"counterfactual distance\"]):.4f}'", ")", "\n", "# for unique_distance in np.unique(age_decreased[\"counterfactual distance\"]):", "\n", "#   unique_distance_df = age_decreased.where(age_decreased['counterfactual distance'] == unique_distance).dropna()", "\n", "#   print(f'\\t\\t{unique_distance_df.shape[0]} samples at distance {unique_distance}')", "\n", "# unique_attr_changes, counts = np.unique(unique_distance_df[\"changed attributes\"], return_counts = True)", "\n", "# for idx, unique_attr_change in enumerate(unique_attr_changes):", "\n", "#   print(f'\\t\\t\\t{counts[idx]} samples changing attributes {unique_attr_change}')", "\n", "\n", "pickle", ".", "dump", "(", "age_increased", ",", "open", "(", "f'_results/{test_name}_age_increased_df'", ",", "'wb'", ")", ")", "\n", "pickle", ".", "dump", "(", "age_decreased", ",", "open", "(", "f'_results/{test_name}_age_decreased_df'", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None._depAnalyzeResults.measureEffectOfAgeAdultPart2": [[218, 258], ["print", "pickle.load", "pickle.load", "pickle.load.iterrows", "print", "print", "print", "print", "open", "open", "increase_in_distance.append", "unrestricted_distances.append", "restricted_distances.append", "np.isclose", "print", "np.mean", "np.mean", "np.mean"], "function", ["None"], ["", "", "", "", "def", "measureEffectOfAgeAdultPart2", "(", ")", ":", "\n", "\n", "# pairs = [", "\n", "#   ('adult-forest-zero_norm-SAT', '_results/adult-forest-zero_norm-SAT_age_decreased_df', '/Volumes/amir/dev/mace/_experiments/_may_21_restricted_results_no_age_reduction/2019.05.21_17.17.39__adult__forest__zero_norm__SAT/_minimum_distances'), \\", "\n", "#   ('adult-forest-one_norm-SAT', '_results/adult-forest-one_norm-SAT_age_decreased_df', '/Volumes/amir/dev/mace/_experiments/_may_21_restricted_results_no_age_reduction/2019.05.21_17.37.32__adult__forest__one_norm__SAT/_minimum_distances'), \\", "\n", "#   ('adult-forest-infty_norm-SAT', '_results/adult-forest-infty_norm-SAT_age_decreased_df', '/Volumes/amir/dev/mace/_experiments/_may_21_restricted_results_no_age_reduction/2019.05.21_17.46.25__adult__forest__infty_norm__SAT/_minimum_distances'), \\", "\n", "#   ('adult-forest-zero_norm-MO', '_results/adult-forest-zero_norm-MO_age_decreased_df', '/Volumes/amir/dev/mace/_experiments/_may_21_restricted_results_no_age_reduction/2019.05.21_17.19.16__adult__forest__zero_norm__MO/_minimum_distances'), \\", "\n", "#   ('adult-forest-one_norm-MO', '_results/adult-forest-one_norm-MO_age_decreased_df', '/Volumes/amir/dev/mace/_experiments/_may_21_restricted_results_no_age_reduction/2019.05.21_17.37.35__adult__forest__one_norm__MO/_minimum_distances'), \\", "\n", "#   ('adult-forest-infty_norm-MO', '_results/adult-forest-infty_norm-MO_age_decreased_df', '/Volumes/amir/dev/mace/_experiments/_may_21_restricted_results_no_age_reduction/2019.05.21_17.54.09__adult__forest__infty_norm__MO/_minimum_distances'), \\", "\n", "# ]", "\n", "  ", "pairs", "=", "[", "\n", "(", "'adult-forest-zero_norm-SAT'", ",", "'_results/adult-forest-zero_norm-SAT_age_decreased_df'", ",", "'/Volumes/amir/dev/mace/_experiments/_may_22_restricted_results_no_age_change/2019.05.22_17.42.00__adult__forest__zero_norm__SAT/_minimum_distances'", ")", ",", "(", "'adult-forest-one_norm-SAT'", ",", "'_results/adult-forest-one_norm-SAT_age_decreased_df'", ",", "'/Volumes/amir/dev/mace/_experiments/_may_22_restricted_results_no_age_change/2019.05.22_18.17.48__adult__forest__one_norm__SAT/_minimum_distances'", ")", ",", "(", "'adult-forest-infty_norm-SAT'", ",", "'_results/adult-forest-infty_norm-SAT_age_decreased_df'", ",", "'/Volumes/amir/dev/mace/_experiments/_may_22_restricted_results_no_age_change/2019.05.22_18.36.35__adult__forest__infty_norm__SAT/_minimum_distances'", ")", ",", "(", "'adult-forest-zero_norm-MO'", ",", "'_results/adult-forest-zero_norm-MO_age_decreased_df'", ",", "'/Volumes/amir/dev/mace/_experiments/_may_22_restricted_results_no_age_change/2019.05.22_18.00.02__adult__forest__zero_norm__MO/_minimum_distances'", ")", ",", "(", "'adult-forest-one_norm-MO'", ",", "'_results/adult-forest-one_norm-MO_age_decreased_df'", ",", "'/Volumes/amir/dev/mace/_experiments/_may_22_restricted_results_no_age_change/2019.05.22_18.20.50__adult__forest__one_norm__MO/_minimum_distances'", ")", ",", "(", "'adult-forest-infty_norm-MO'", ",", "'_results/adult-forest-infty_norm-MO_age_decreased_df'", ",", "'/Volumes/amir/dev/mace/_experiments/_may_22_restricted_results_no_age_change/2019.05.22_18.32.33__adult__forest__infty_norm__MO/_minimum_distances'", ")", ",", "]", "\n", "print", "(", "'\\n\\n<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\\n\\n'", ")", "\n", "for", "pair", "in", "pairs", ":", "\n", "    ", "unrestricted_df", "=", "pickle", ".", "load", "(", "open", "(", "pair", "[", "1", "]", ",", "'rb'", ")", ")", "\n", "restricted_file", "=", "pickle", ".", "load", "(", "open", "(", "pair", "[", "2", "]", ",", "'rb'", ")", ")", "\n", "increase_in_distance", "=", "[", "]", "\n", "unrestricted_distances", "=", "[", "]", "\n", "restricted_distances", "=", "[", "]", "\n", "for", "index", ",", "row", "in", "unrestricted_df", ".", "iterrows", "(", ")", ":", "\n", "      ", "factual_sample_index", "=", "row", ".", "loc", "[", "'factual sample index'", "]", "\n", "unrestricted_distance", "=", "row", ".", "loc", "[", "'counterfactual distance'", "]", "\n", "restricted_distance", "=", "restricted_file", "[", "factual_sample_index", "]", "[", "'counterfactual_distance'", "]", "\n", "try", ":", "\n", "        ", "assert", "(", "restricted_distance", ">=", "unrestricted_distance", ")", "or", "np", ".", "isclose", "(", "restricted_distance", ",", "unrestricted_distance", ",", "1e-3", ",", "1e-3", ")", "\n", "", "except", ":", "\n", "        ", "print", "(", "f'\\t Unexpected: \\t\\t restricted_distance - unrestricted_distance = {restricted_distance - unrestricted_distance}'", ")", "\n", "", "increase_in_distance", ".", "append", "(", "restricted_distance", "/", "unrestricted_distance", ")", "\n", "unrestricted_distances", ".", "append", "(", "unrestricted_distance", ")", "\n", "restricted_distances", ".", "append", "(", "restricted_distance", ")", "\n", "", "print", "(", "f'{pair[0]}:'", ")", "\n", "print", "(", "f'\\t\\tMean unrestricted distance = {np.mean(unrestricted_distances):.4f}'", ")", "\n", "print", "(", "f'\\t\\tMean restricted distance = {np.mean(restricted_distances):.4f}'", ")", "\n", "print", "(", "f'\\t\\tMean increase in distance (restricted / unrestricted) = {np.mean(increase_in_distance):.4f}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None._depAnalyzeResults.measureEffectOfAgeAdultPart3": [[260, 306], ["print", "pickle.load", "pickle.load", "pickle.load.append", "pickle.load", "pickle.load", "unrestricted_df1.append.iterrows", "open", "open", "open", "open", "factual_sample.keys", "print", "print", "print", "np.isclose", "restricted_changed_attributes.append", "np.isclose", "unrestricted_changed_attributes.append"], "function", ["None"], ["", "", "def", "measureEffectOfAgeAdultPart3", "(", ")", ":", "\n", "\n", "  ", "pairs", "=", "[", "(", "\n", "'adult-forest-zero_norm-SAT'", ",", "\n", "'_results/adult-forest-zero_norm-SAT_age_decreased_df'", ",", "\n", "'_results/adult-forest-zero_norm-SAT_age_increased_df'", ",", "\n", "'/Volumes/amir/dev/mace/_experiments/_may_20_all_results/2019.05.20_17.44.50__adult__forest__zero_norm__SAT/_minimum_distances'", ",", "\n", "'/Volumes/amir/dev/mace/_experiments/_may_22_restricted_results_no_age_change/2019.05.22_17.42.00__adult__forest__zero_norm__SAT/_minimum_distances'", "\n", ")", "]", "\n", "print", "(", "'\\n\\n<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\\n\\n'", ")", "\n", "for", "pair", "in", "pairs", ":", "\n", "    ", "unrestricted_df1", "=", "pickle", ".", "load", "(", "open", "(", "pair", "[", "1", "]", ",", "'rb'", ")", ")", "\n", "unrestricted_df2", "=", "pickle", ".", "load", "(", "open", "(", "pair", "[", "2", "]", ",", "'rb'", ")", ")", "\n", "unrestricted_df", "=", "unrestricted_df1", ".", "append", "(", "unrestricted_df2", ",", "ignore_index", "=", "True", ")", "\n", "unrestricted_file", "=", "pickle", ".", "load", "(", "open", "(", "pair", "[", "3", "]", ",", "'rb'", ")", ")", "\n", "restricted_file", "=", "pickle", ".", "load", "(", "open", "(", "pair", "[", "4", "]", ",", "'rb'", ")", ")", "\n", "# assert unrestricted_df.shape[0] == 18 # %3.6 x 500", "\n", "for", "index", ",", "row", "in", "unrestricted_df", ".", "iterrows", "(", ")", ":", "\n", "\n", "      ", "factual_sample_index", "=", "row", ".", "loc", "[", "'factual sample index'", "]", "\n", "\n", "# unrestricted_distance = row.loc['counterfactual distance']", "\n", "# restricted_distance = restricted_file[factual_sample_index]['counterfactual_distance']", "\n", "# assert unrestricted_distance == restricted_distance", "\n", "\n", "restricted_factual_sample", "=", "restricted_file", "[", "factual_sample_index", "]", "[", "'factual_sample'", "]", "\n", "unrestricted_factual_sample", "=", "unrestricted_file", "[", "factual_sample_index", "]", "[", "'factual_sample'", "]", "\n", "restricted_counterfactual_sample", "=", "restricted_file", "[", "factual_sample_index", "]", "[", "'counterfactual_sample'", "]", "\n", "unrestricted_counterfactual_sample", "=", "unrestricted_file", "[", "factual_sample_index", "]", "[", "'counterfactual_sample'", "]", "\n", "assert", "restricted_factual_sample", "==", "unrestricted_factual_sample", "\n", "\n", "factual_sample", "=", "restricted_factual_sample", "# or unrestricted_factual_sample", "\n", "restricted_changed_attributes", "=", "[", "]", "\n", "unrestricted_changed_attributes", "=", "[", "]", "\n", "for", "attr", "in", "factual_sample", ".", "keys", "(", ")", ":", "\n", "        ", "if", "not", "np", ".", "isclose", "(", "factual_sample", "[", "attr", "]", ",", "restricted_counterfactual_sample", "[", "attr", "]", ")", ":", "\n", "          ", "restricted_changed_attributes", ".", "append", "(", "(", "attr", ",", "factual_sample", "[", "attr", "]", ",", "restricted_counterfactual_sample", "[", "attr", "]", ")", ")", "\n", "", "if", "not", "np", ".", "isclose", "(", "factual_sample", "[", "attr", "]", ",", "unrestricted_counterfactual_sample", "[", "attr", "]", ")", ":", "\n", "          ", "unrestricted_changed_attributes", ".", "append", "(", "(", "attr", ",", "factual_sample", "[", "attr", "]", ",", "unrestricted_counterfactual_sample", "[", "attr", "]", ")", ")", "\n", "\n", "# restricted_changed_attributes.pop('y')", "\n", "# unrestricted_changed_attributes.pop('y')", "\n", "\n", "", "", "print", "(", "f'Sample: {factual_sample_index}'", ")", "\n", "print", "(", "f'\\trestricted_changed_attributes: {restricted_changed_attributes}'", ")", "\n", "print", "(", "f'\\tunrestricted_changed_attributes: {unrestricted_changed_attributes}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.generateARExplanations.genExp": [[11, 189], ["time.time", "tmp_df.append.loc[].to_dict", "dataset_obj.getOneHotAttributesNames", "tmp_df.append.append", "recourse.builder.ActionSet", "dataset_obj.getInputAttributeNames", "numpy.union1d", "list", "recourse.builder.RecourseBuilder", "recourse.builder.RecourseBuilder.fit", "numpy.add", "dict", "numpy.union1d", "dataset_obj.getOneHotAttributesNames", "normalizedDistance.getDistanceBetweenSamples", "time.time", "pandas.Series", "dataset_obj.getIntegerBasedAttributeNames", "dataset_obj.getBinaryAttributeNames", "factual_sample.values", "zip", "dataset_obj.getOneHotAttributesNames", "dataset_obj.getBinaryAttributeNames", "numpy.union1d", "ValueError", "factual_sample.keys", "numpy.isclose", "numpy.round", "dataset_obj.getSiblingsFor", "numpy.sum", "already_considered.extend", "dataset_obj.getOneHotAttributesNames", "dataset_obj.getBinaryAttributeNames", "ValueError", "numpy.round", "range", "Exception", "int"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getOneHotAttributesNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getOneHotAttributesNames", "home.repos.pwc.inspect_result.amirhk_mace.None.normalizedDistance.getDistanceBetweenSamples", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getIntegerBasedAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getBinaryAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getOneHotAttributesNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getBinaryAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getSiblingsFor", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getOneHotAttributesNames", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getBinaryAttributeNames"], ["def", "genExp", "(", "model_trained", ",", "factual_sample", ",", "norm_type", ",", "dataset_obj", ")", ":", "\n", "\n", "  ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# SIMPLE HACK!!", "\n", "# ActionSet() construction demands that all variables have a range to them. In", "\n", "# the case of one-hot ordinal variables (e.g., x2_ord_0, x2_ord_1, x2_ord_2)),", "\n", "# the first sub-category (i.e., x2_ord_0) will always have range(1,1), failing", "\n", "# the requirements of ActionSet(). Therefore, we add a DUMMY ROW to the data-", "\n", "# frame, which is a copy of another row (so not to throw off the range of other", "\n", "# attributes), but setting a 0 value to all _ord_ variables. (might as well do", "\n", "# this for all _cat_ variables as well).", "\n", "tmp_df", "=", "dataset_obj", ".", "data_frame_kurz", "\n", "sample_row", "=", "tmp_df", ".", "loc", "[", "0", "]", ".", "to_dict", "(", ")", "\n", "for", "attr_name_kurz", "in", "dataset_obj", ".", "getOneHotAttributesNames", "(", "'kurz'", ")", ":", "\n", "    ", "sample_row", "[", "attr_name_kurz", "]", "=", "0", "\n", "", "tmp_df", "=", "tmp_df", ".", "append", "(", "pd", ".", "Series", "(", "sample_row", ")", ",", "ignore_index", "=", "True", ")", "\n", "\n", "df", "=", "tmp_df", "\n", "X", "=", "df", ".", "loc", "[", ":", ",", "df", ".", "columns", "!=", "'y'", "]", "\n", "\n", "# Enforce binary, categorical (including ordinal) variables only take on 2 values", "\n", "custom_bounds", "=", "{", "attr_name_kurz", ":", "(", "0", ",", "100", ",", "'p'", ")", "for", "attr_name_kurz", "in", "np", ".", "union1d", "(", "\n", "dataset_obj", ".", "getOneHotAttributesNames", "(", "'kurz'", ")", ",", "\n", "dataset_obj", ".", "getBinaryAttributeNames", "(", "'kurz'", ")", "\n", ")", "}", "\n", "action_set", "=", "ActionSet", "(", "X", "=", "X", ",", "custom_bounds", "=", "custom_bounds", ")", "\n", "# action_set['x1'].mutable = False # x1 = 'Race'", "\n", "# In the current implementation, we only supports any/none actionability", "\n", "for", "attr_name_kurz", "in", "dataset_obj", ".", "getInputAttributeNames", "(", "'kurz'", ")", ":", "\n", "    ", "attr_obj", "=", "dataset_obj", ".", "attributes_kurz", "[", "attr_name_kurz", "]", "\n", "if", "attr_obj", ".", "actionability", "==", "'none'", ":", "\n", "      ", "action_set", "[", "attr_name_kurz", "]", ".", "mutable", "=", "False", "\n", "", "elif", "attr_obj", ".", "actionability", "==", "'any'", ":", "\n", "      ", "continue", "# do nothing", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "f'Actionable Recourse does not support actionability type {attr_obj.actionability}'", ")", "\n", "\n", "# Enforce search over integer-based grid for integer-based variables", "\n", "", "", "for", "attr_name_kurz", "in", "np", ".", "union1d", "(", "\n", "dataset_obj", ".", "getIntegerBasedAttributeNames", "(", "'kurz'", ")", ",", "\n", "dataset_obj", ".", "getBinaryAttributeNames", "(", "'kurz'", ")", ",", "\n", ")", ":", "\n", "    ", "action_set", "[", "attr_name_kurz", "]", ".", "step_type", "=", "\"absolute\"", "\n", "action_set", "[", "attr_name_kurz", "]", ".", "step_size", "=", "1", "\n", "\n", "", "coefficients", "=", "model_trained", ".", "coef_", "[", "0", "]", "\n", "intercept", "=", "model_trained", ".", "intercept_", "[", "0", "]", "\n", "\n", "if", "norm_type", "==", "'one_norm'", ":", "\n", "    ", "mip_cost_type", "=", "'total'", "\n", "", "elif", "norm_type", "==", "'infty_norm'", ":", "\n", "    ", "mip_cost_type", "=", "'max'", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "f'Actionable Recourse does not support norm_type {norm_type}'", ")", "\n", "\n", "", "factual_sample_values", "=", "list", "(", "factual_sample", ".", "values", "(", ")", ")", "\n", "# p = .8", "\n", "rb", "=", "RecourseBuilder", "(", "\n", "optimizer", "=", "\"cplex\"", ",", "\n", "coefficients", "=", "coefficients", ",", "\n", "intercept", "=", "intercept", ",", "# - (np.log(p / (1. - p))),", "\n", "action_set", "=", "action_set", ",", "\n", "x", "=", "factual_sample_values", ",", "\n", "mip_cost_type", "=", "mip_cost_type", "\n", ")", "\n", "\n", "output", "=", "rb", ".", "fit", "(", ")", "\n", "counterfactual_sample_values", "=", "np", ".", "add", "(", "factual_sample_values", ",", "output", "[", "'actions'", "]", ")", "\n", "counterfactual_sample", "=", "dict", "(", "zip", "(", "factual_sample", ".", "keys", "(", ")", ",", "counterfactual_sample_values", ")", ")", "\n", "\n", "# factual_sample['y'] = False", "\n", "# counterfactual_sample['y'] = True", "\n", "counterfactual_sample", "[", "'y'", "]", "=", "not", "factual_sample", "[", "'y'", "]", "\n", "counterfactual_plausible", "=", "True", "\n", "\n", "# IMPORTANT: no need to check for integer-based / binary-based plausibility,", "\n", "# because those were set above when we said step_type = absolute! Just round!", "\n", "for", "attr_name_kurz", "in", "np", ".", "union1d", "(", "\n", "dataset_obj", ".", "getOneHotAttributesNames", "(", "'kurz'", ")", ",", "\n", "dataset_obj", ".", "getBinaryAttributeNames", "(", "'kurz'", ")", "\n", ")", ":", "\n", "    ", "try", ":", "\n", "      ", "assert", "np", ".", "isclose", "(", "\n", "counterfactual_sample", "[", "attr_name_kurz", "]", ",", "\n", "np", ".", "round", "(", "counterfactual_sample", "[", "attr_name_kurz", "]", ")", "\n", ")", "\n", "counterfactual_sample", "[", "attr_name_kurz", "]", "=", "np", ".", "round", "(", "counterfactual_sample", "[", "attr_name_kurz", "]", ")", "\n", "", "except", ":", "\n", "      ", "distance", "=", "-", "1", "\n", "counterfactual_plausible", "=", "False", "\n", "# return counterfactual_sample, distance", "\n", "\n", "# Perform plausibility-data-type check! Remember, all ordinal variables", "\n", "# have already been converted to categorical variables. It is important now", "\n", "# to check that 1 (and only 1) sub-category is activated in the resulting", "\n", "# counterfactual sample.", "\n", "", "", "already_considered", "=", "[", "]", "\n", "for", "attr_name_kurz", "in", "dataset_obj", ".", "getOneHotAttributesNames", "(", "'kurz'", ")", ":", "\n", "    ", "if", "attr_name_kurz", "not", "in", "already_considered", ":", "\n", "      ", "siblings_kurz", "=", "dataset_obj", ".", "getSiblingsFor", "(", "attr_name_kurz", ")", "\n", "activations_for_category", "=", "[", "\n", "counterfactual_sample", "[", "attr_name_kurz", "]", "for", "attr_name_kurz", "in", "siblings_kurz", "\n", "]", "\n", "sum_activations_for_category", "=", "np", ".", "sum", "(", "activations_for_category", ")", "\n", "if", "'cat'", "in", "dataset_obj", ".", "attributes_kurz", "[", "attr_name_kurz", "]", ".", "attr_type", ":", "\n", "        ", "if", "sum_activations_for_category", "==", "1", ":", "\n", "          ", "continue", "\n", "", "else", ":", "\n", "# print('not plausible, fixing..', end='')", "\n", "# TODO: don't actually return early! Instead see the actual distance,", "\n", "# fingers crossed that we can say that not only is their method giving", "\n", "# counterfactuals are larger distances, but in a lot of cases they are", "\n", "# not data-type plausible", "\n", "# INSTEAD, do below:", "\n", "# Convert to correct categorical/ordinal activations so we can", "\n", "# compute the distance using already written function.", "\n", "#     Turns out we need to do nothing, because the distance between", "\n", "#     [0,1,0] and anything other than itself, (e.g., [1,1,0] or [1,0,1])", "\n", "#     is always 1 :)", "\n", "# continue", "\n", "          ", "distance", "=", "-", "1", "\n", "counterfactual_plausible", "=", "False", "\n", "# return counterfactual_sample, distance", "\n", "", "", "elif", "'ord'", "in", "dataset_obj", ".", "attributes_kurz", "[", "attr_name_kurz", "]", ".", "attr_type", ":", "\n", "# TODO: assert activations are in order...", "\n", "# if not, repeat as above...", "\n", "        ", "for", "idx", "in", "range", "(", "int", "(", "sum_activations_for_category", ")", ")", ":", "\n", "          ", "if", "activations_for_category", "[", "idx", "]", "!=", "1", ":", "\n", "# Convert to correct categorical/ordinal activations so we can", "\n", "# compute the distance using already written function.", "\n", "# Find the max index of 1 in the array, and set everything before that to 1", "\n", "# print('not plausible, fixing..', end='')", "\n", "# max_index_of_1 = np.where(np.array(activations_for_category) == 1)[0][-1]", "\n", "# for idx2 in range(max_index_of_1 + 1):", "\n", "#   counterfactual_sample[siblings_kurz[idx2]] = 1", "\n", "# break", "\n", "            ", "distance", "=", "-", "1", "\n", "counterfactual_plausible", "=", "False", "\n", "# return counterfactual_sample, distance", "\n", "", "", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "f'{attr_name_kurz} must include either `cat` or `ord`.'", ")", "\n", "", "already_considered", ".", "extend", "(", "siblings_kurz", ")", "\n", "\n", "# TODO: convert to correct categorical/ordinal activations so we can compute", "\n", "\n", "# distance = output['cost'] # TODO: this must change / be verified!???", "\n", "", "", "distance", "=", "normalizedDistance", ".", "getDistanceBetweenSamples", "(", "\n", "factual_sample", ",", "\n", "counterfactual_sample", ",", "\n", "norm_type", ",", "\n", "dataset_obj", "\n", ")", "\n", "\n", "\n", "# # TODO: post-feasibible needed???? NO", "\n", "# # make plausible by rounding all non-numeric-real attributes to", "\n", "# # nearest value in range", "\n", "# for idx, elem in enumerate(es_instance):", "\n", "#     attr_name_kurz = dataset_obj.getInputAttributeNames('kurz')[idx]", "\n", "#     attr_obj = dataset_obj.attributes_kurz[attr_name_kurz]", "\n", "#     if attr_obj.attr_type != 'numeric-real':", "\n", "#         # round() might give a value that is NOT in plausible.", "\n", "#         # instead find the nearest plausible value", "\n", "#         es_instance[idx] = min(", "\n", "#             list(range(int(attr_obj.lower_bound), int(attr_obj.upper_bound) + 1)),", "\n", "#             key = lambda x : abs(x - es_instance[idx])", "\n", "#         )", "\n", "\n", "end_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "return", "{", "\n", "'factual_sample'", ":", "factual_sample", ",", "\n", "'cfe_sample'", ":", "counterfactual_sample", ",", "\n", "'cfe_found'", ":", "True", ",", "# TODO?", "\n", "'cfe_plausible'", ":", "counterfactual_plausible", ",", "\n", "'cfe_distance'", ":", "distance", ",", "\n", "'cfe_time'", ":", "end_time", "-", "start_time", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.generateFTExplanations.search_path": [[12, 82], ["estimator.tree_.value[].reshape", "numpy.where", "len", "len", "range", "parents_left.append", "parents_right.append", "len", "numpy.where", "node_ids.append", "inequality_symbols.append", "thresholds.append", "features.append", "node_ids.append", "inequality_symbols.append", "thresholds.append", "features.append", "numpy.where", "numpy.where", "numpy.where", "numpy.where"], "function", ["None"], ["def", "search_path", "(", "estimator", ",", "class_labels", ",", "counterfactual_label", ")", ":", "\n", "    ", "\"\"\"\n    return path index list containing [{leaf node id, inequality symbol, threshold, feature index}].\n    estimator: decision tree\n    maxj: the number of selected leaf nodes\n    \"\"\"", "\n", "\"\"\" select leaf nodes whose outcome is counterfactual_label \"\"\"", "\n", "children_left", "=", "estimator", ".", "tree_", ".", "children_left", "# information of left child node", "\n", "children_right", "=", "estimator", ".", "tree_", ".", "children_right", "\n", "feature", "=", "estimator", ".", "tree_", ".", "feature", "\n", "threshold", "=", "estimator", ".", "tree_", ".", "threshold", "\n", "# leaf nodes ID", "\n", "leaf_nodes", "=", "np", ".", "where", "(", "children_left", "==", "-", "1", ")", "[", "0", "]", "\n", "# outcomes of leaf nodes", "\n", "leaf_values", "=", "estimator", ".", "tree_", ".", "value", "[", "leaf_nodes", "]", ".", "reshape", "(", "len", "(", "leaf_nodes", ")", ",", "len", "(", "class_labels", ")", ")", "\n", "# select the leaf nodes whose outcome is counterfactual_label", "\n", "# (select index of leaf node in tree, not in the previous leaf_node array!)", "\n", "leaf_nodes", "=", "leaf_nodes", "[", "np", ".", "where", "(", "leaf_values", "[", ":", ",", "counterfactual_label", "]", "!=", "0", ")", "[", "0", "]", "]", "\n", "\"\"\" search the path to the selected leaf node \"\"\"", "\n", "paths", "=", "{", "}", "\n", "for", "leaf_node", "in", "leaf_nodes", ":", "\n", "        ", "\"\"\" correspond leaf node to left and right parents \"\"\"", "\n", "child_node", "=", "leaf_node", "\n", "parent_node", "=", "-", "100", "# initialize", "\n", "parents_left", "=", "[", "]", "\n", "parents_right", "=", "[", "]", "\n", "while", "(", "parent_node", "!=", "0", ")", ":", "\n", "            ", "if", "(", "np", ".", "where", "(", "children_left", "==", "child_node", ")", "[", "0", "]", ".", "shape", "==", "(", "0", ",", ")", ")", ":", "\n", "                ", "parent_left", "=", "-", "1", "\n", "parent_right", "=", "np", ".", "where", "(", "children_right", "==", "child_node", ")", "[", "0", "]", "[", "0", "]", "\n", "parent_node", "=", "parent_right", "\n", "", "elif", "(", "np", ".", "where", "(", "children_right", "==", "child_node", ")", "[", "0", "]", ".", "shape", "==", "(", "0", ",", ")", ")", ":", "\n", "                ", "parent_right", "=", "-", "1", "\n", "parent_left", "=", "np", ".", "where", "(", "children_left", "==", "child_node", ")", "[", "0", "]", "[", "0", "]", "\n", "parent_node", "=", "parent_left", "\n", "", "parents_left", ".", "append", "(", "parent_left", ")", "\n", "parents_right", ".", "append", "(", "parent_right", ")", "\n", "\"\"\" for next step \"\"\"", "\n", "child_node", "=", "parent_node", "\n", "# nodes dictionary containing left parents and right parents", "\n", "", "paths", "[", "leaf_node", "]", "=", "(", "parents_left", ",", "parents_right", ")", "\n", "\n", "", "path_info", "=", "{", "}", "\n", "for", "i", "in", "paths", ":", "\n", "        ", "node_ids", "=", "[", "]", "# node ids used in the current node", "\n", "# inequality symbols used in the current node", "\n", "inequality_symbols", "=", "[", "]", "\n", "thresholds", "=", "[", "]", "# thretholds used in the current node", "\n", "features", "=", "[", "]", "# features used in the current node", "\n", "parents_left", ",", "parents_right", "=", "paths", "[", "i", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "parents_left", ")", ")", ":", "\n", "            ", "if", "(", "parents_left", "[", "idx", "]", "!=", "-", "1", ")", ":", "\n", "                ", "\"\"\" the child node is the left child of the parent \"\"\"", "\n", "node_id", "=", "parents_left", "[", "idx", "]", "# node id", "\n", "node_ids", ".", "append", "(", "node_id", ")", "\n", "inequality_symbols", ".", "append", "(", "0", ")", "\n", "thresholds", ".", "append", "(", "threshold", "[", "node_id", "]", ")", "\n", "features", ".", "append", "(", "feature", "[", "node_id", "]", ")", "\n", "", "elif", "(", "parents_right", "[", "idx", "]", "!=", "-", "1", ")", ":", "\n", "                ", "\"\"\" the child node is the right child of the parent \"\"\"", "\n", "node_id", "=", "parents_right", "[", "idx", "]", "\n", "node_ids", ".", "append", "(", "node_id", ")", "\n", "inequality_symbols", ".", "append", "(", "1", ")", "\n", "thresholds", ".", "append", "(", "threshold", "[", "node_id", "]", ")", "\n", "features", ".", "append", "(", "feature", "[", "node_id", "]", ")", "\n", "", "path_info", "[", "i", "]", "=", "{", "'node_id'", ":", "node_ids", ",", "\n", "'inequality_symbol'", ":", "inequality_symbols", ",", "\n", "'threshold'", ":", "thresholds", ",", "\n", "'feature'", ":", "features", "}", "\n", "", "", "return", "path_info", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.generateFTExplanations.esatisfactory_instance": [[83, 104], ["copy.deepcopy", "range", "len", "print"], "function", ["None"], ["", "def", "esatisfactory_instance", "(", "x", ",", "epsilon", ",", "path_info", ",", "standard_deviations", ")", ":", "\n", "    ", "\"\"\"\n    return the epsilon satisfactory instance of x.\n    \"\"\"", "\n", "esatisfactory", "=", "copy", ".", "deepcopy", "(", "x", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "path_info", "[", "'feature'", "]", ")", ")", ":", "\n", "# feature index", "\n", "        ", "feature_idx", "=", "path_info", "[", "'feature'", "]", "[", "i", "]", "\n", "# threshold used in the current node", "\n", "threshold_value", "=", "path_info", "[", "'threshold'", "]", "[", "i", "]", "\n", "# inequality symbol", "\n", "inequality_symbol", "=", "path_info", "[", "'inequality_symbol'", "]", "[", "i", "]", "\n", "if", "inequality_symbol", "==", "0", ":", "\n", "# esatisfactory[feature_idx] = threshold_value - epsilon", "\n", "            ", "esatisfactory", "[", "feature_idx", "]", "=", "threshold_value", "-", "epsilon", "*", "standard_deviations", "[", "feature_idx", "]", "\n", "", "elif", "inequality_symbol", "==", "1", ":", "\n", "# esatisfactory[feature_idx] = threshold_value + epsilon", "\n", "            ", "esatisfactory", "[", "feature_idx", "]", "=", "threshold_value", "+", "epsilon", "*", "standard_deviations", "[", "feature_idx", "]", "\n", "", "else", ":", "\n", "            ", "print", "(", "'something wrong'", ")", "\n", "", "", "return", "esatisfactory", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.generateFTExplanations.genExp": [[105, 237], ["time.time", "factual_sample.copy", "numpy.array", "dict", "isinstance", "dataset_obj.getInputOutputAttributeNames", "time.time", "list", "zip", "isinstance", "np.array.values", "factual_sample.keys", "estimator.predict", "generateFTExplanations.search_path", "np.array.reshape", "generateFTExplanations.esatisfactory_instance", "numpy.isclose", "numpy.round", "factual_sample.values", "enumerate", "estimator.predict", "dict", "normalizedDistance.getDistanceBetweenSamples", "estimator.predict", "generateFTExplanations.search_path", "numpy.round", "esatisfactory_instance.reshape", "zip", "ensemble_classifier.predict", "estimator.predict", "generateFTExplanations.esatisfactory_instance", "dataset_obj.getInputAttributeNames", "min", "factual_sample.keys", "np.array.reshape", "np.array.reshape", "np.array.reshape", "enumerate", "ensemble_classifier.predict", "dict", "normalizedDistance.getDistanceBetweenSamples", "list", "esatisfactory_instance.reshape", "zip", "range", "dataset_obj.getInputAttributeNames", "min", "factual_sample.keys", "int", "abs", "list", "int", "range", "int", "abs", "int"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputOutputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.generateFTExplanations.search_path", "home.repos.pwc.inspect_result.amirhk_mace.None.generateFTExplanations.esatisfactory_instance", "home.repos.pwc.inspect_result.amirhk_mace.None.normalizedDistance.getDistanceBetweenSamples", "home.repos.pwc.inspect_result.amirhk_mace.None.generateFTExplanations.search_path", "home.repos.pwc.inspect_result.amirhk_mace.None.generateFTExplanations.esatisfactory_instance", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames", "home.repos.pwc.inspect_result.amirhk_mace.None.normalizedDistance.getDistanceBetweenSamples", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getInputAttributeNames"], ["", "def", "genExp", "(", "model_trained", ",", "factual_sample", ",", "class_labels", ",", "epsilon", ",", "norm_type", ",", "dataset_obj", ",", "standard_deviations", ",", "perform_while_plausibility", ")", ":", "\n", "    ", "\"\"\"\n    This function return the active feature tweaking vector.\n    x: feature vector\n    class_labels: list containing the all class labels\n    counterfactual_label: the label which we want to transform the label of x to\n    \"\"\"", "\n", "\n", "\"\"\" initialize \"\"\"", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "x", "=", "factual_sample", ".", "copy", "(", ")", "\n", "del", "x", "[", "'y'", "]", "\n", "x", "=", "np", ".", "array", "(", "list", "(", "x", ".", "values", "(", ")", ")", ")", "\n", "# factual_sample['y'] = False", "\n", "counterfactual_label", "=", "not", "factual_sample", "[", "'y'", "]", "\n", "\n", "# initialize output in case no solution is found", "\n", "closest_counterfactual_sample", "=", "dict", "(", "zip", "(", "factual_sample", ".", "keys", "(", ")", ",", "[", "-", "1", "for", "elem", "in", "factual_sample", ".", "values", "(", ")", "]", ")", ")", "\n", "closest_counterfactual_sample", "[", "'y'", "]", "=", "counterfactual_label", "\n", "counterfactual_found", "=", "False", "\n", "closest_distance", "=", "1000", "# initialize cost (if no solution is found, this is returned)", "\n", "\n", "# We want to support forest and tree, and we keep in mind that a trained", "\n", "# tree does NOT perform the same as a trained forest with 1 tree!", "\n", "if", "isinstance", "(", "model_trained", ",", "DecisionTreeClassifier", ")", ":", "\n", "# ensemble_classifier will in fact not be an ensemble, but only be a tree", "\n", "        ", "estimator", "=", "model_trained", "\n", "if", "estimator", ".", "predict", "(", "x", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "!=", "counterfactual_label", ":", "\n", "            ", "paths_info", "=", "search_path", "(", "estimator", ",", "class_labels", ",", "counterfactual_label", ")", "\n", "for", "key", "in", "paths_info", ":", "\n", "                ", "\"\"\" generate epsilon-satisfactory instance \"\"\"", "\n", "path_info", "=", "paths_info", "[", "key", "]", "\n", "es_instance", "=", "esatisfactory_instance", "(", "x", ",", "epsilon", ",", "path_info", ",", "standard_deviations", ")", "\n", "\n", "if", "perform_while_plausibility", ":", "\n", "# make plausible by rounding all non-numeric-real attributes to", "\n", "# nearest value in range", "\n", "                    ", "for", "idx", ",", "elem", "in", "enumerate", "(", "es_instance", ")", ":", "\n", "                        ", "attr_name_kurz", "=", "dataset_obj", ".", "getInputAttributeNames", "(", "'kurz'", ")", "[", "idx", "]", "\n", "attr_obj", "=", "dataset_obj", ".", "attributes_kurz", "[", "attr_name_kurz", "]", "\n", "if", "attr_obj", ".", "attr_type", "!=", "'numeric-real'", ":", "\n", "# round() might give a value that is NOT in plausible.", "\n", "# instead find the nearest plausible value", "\n", "                            ", "es_instance", "[", "idx", "]", "=", "min", "(", "\n", "list", "(", "range", "(", "int", "(", "attr_obj", ".", "lower_bound", ")", ",", "int", "(", "attr_obj", ".", "upper_bound", ")", "+", "1", ")", ")", ",", "\n", "key", "=", "lambda", "x", ":", "abs", "(", "x", "-", "es_instance", "[", "idx", "]", ")", "\n", ")", "\n", "\n", "", "", "", "if", "estimator", ".", "predict", "(", "es_instance", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "==", "counterfactual_label", ":", "\n", "                    ", "counterfactual_sample", "=", "dict", "(", "zip", "(", "factual_sample", ".", "keys", "(", ")", ",", "es_instance", ")", ")", "\n", "counterfactual_sample", "[", "'y'", "]", "=", "counterfactual_label", "\n", "distance", "=", "normalizedDistance", ".", "getDistanceBetweenSamples", "(", "\n", "factual_sample", ",", "\n", "counterfactual_sample", ",", "\n", "norm_type", ",", "\n", "dataset_obj", "\n", ")", "\n", "if", "distance", "<", "closest_distance", ":", "\n", "                        ", "closest_counterfactual_sample", "=", "counterfactual_sample", "\n", "counterfactual_found", "=", "True", "\n", "closest_distance", "=", "distance", "\n", "\n", "", "", "", "", "", "elif", "isinstance", "(", "model_trained", ",", "RandomForestClassifier", ")", ":", "\n", "        ", "ensemble_classifier", "=", "model_trained", "\n", "for", "estimator", "in", "ensemble_classifier", ":", "\n", "            ", "if", "(", "ensemble_classifier", ".", "predict", "(", "x", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "==", "estimator", ".", "predict", "(", "x", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "\n", "and", "estimator", ".", "predict", "(", "x", ".", "reshape", "(", "1", ",", "-", "1", ")", "!=", "counterfactual_label", ")", ")", ":", "\n", "                ", "paths_info", "=", "search_path", "(", "estimator", ",", "class_labels", ",", "counterfactual_label", ")", "\n", "for", "key", "in", "paths_info", ":", "\n", "                    ", "\"\"\" generate epsilon-satisfactory instance \"\"\"", "\n", "path_info", "=", "paths_info", "[", "key", "]", "\n", "es_instance", "=", "esatisfactory_instance", "(", "x", ",", "epsilon", ",", "path_info", ",", "standard_deviations", ")", "\n", "\n", "if", "perform_while_plausibility", ":", "\n", "# make plausible by rounding all non-numeric-real attributes to", "\n", "# nearest value in range", "\n", "                        ", "for", "idx", ",", "elem", "in", "enumerate", "(", "es_instance", ")", ":", "\n", "                            ", "attr_name_kurz", "=", "dataset_obj", ".", "getInputAttributeNames", "(", "'kurz'", ")", "[", "idx", "]", "\n", "attr_obj", "=", "dataset_obj", ".", "attributes_kurz", "[", "attr_name_kurz", "]", "\n", "if", "attr_obj", ".", "attr_type", "!=", "'numeric-real'", ":", "\n", "# round() might give a value that is NOT in plausible.", "\n", "# instead find the nearest plausible value", "\n", "                                ", "es_instance", "[", "idx", "]", "=", "min", "(", "\n", "list", "(", "range", "(", "int", "(", "attr_obj", ".", "lower_bound", ")", ",", "int", "(", "attr_obj", ".", "upper_bound", ")", "+", "1", ")", ")", ",", "\n", "key", "=", "lambda", "x", ":", "abs", "(", "x", "-", "es_instance", "[", "idx", "]", ")", "\n", ")", "\n", "\n", "", "", "", "if", "ensemble_classifier", ".", "predict", "(", "es_instance", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "==", "counterfactual_label", ":", "\n", "                        ", "counterfactual_sample", "=", "dict", "(", "zip", "(", "factual_sample", ".", "keys", "(", ")", ",", "es_instance", ")", ")", "\n", "counterfactual_sample", "[", "'y'", "]", "=", "counterfactual_label", "\n", "distance", "=", "normalizedDistance", ".", "getDistanceBetweenSamples", "(", "\n", "factual_sample", ",", "\n", "counterfactual_sample", ",", "\n", "norm_type", ",", "\n", "dataset_obj", "\n", ")", "\n", "if", "distance", "<", "closest_distance", ":", "\n", "                            ", "closest_counterfactual_sample", "=", "counterfactual_sample", "\n", "counterfactual_found", "=", "True", "\n", "closest_distance", "=", "distance", "\n", "\n", "# better naming", "\n", "", "", "", "", "", "", "counterfactual_sample", "=", "closest_counterfactual_sample", "\n", "distance", "=", "closest_distance", "\n", "\n", "# Perform plausibility check on the nearest counterfactual found", "\n", "counterfactual_plausible", "=", "True", "\n", "for", "attr_name_kurz", "in", "dataset_obj", ".", "getInputOutputAttributeNames", "(", "'kurz'", ")", ":", "\n", "        ", "attr_obj", "=", "dataset_obj", ".", "attributes_kurz", "[", "attr_name_kurz", "]", "\n", "if", "attr_obj", ".", "attr_type", "!=", "'numeric-real'", ":", "\n", "            ", "try", ":", "\n", "                ", "assert", "np", ".", "isclose", "(", "\n", "counterfactual_sample", "[", "attr_name_kurz", "]", ",", "\n", "np", ".", "round", "(", "counterfactual_sample", "[", "attr_name_kurz", "]", ")", "\n", ")", ",", "'not satisfying plausibility (data-type)'", "\n", "counterfactual_sample", "[", "attr_name_kurz", "]", "=", "np", ".", "round", "(", "counterfactual_sample", "[", "attr_name_kurz", "]", ")", "\n", "assert", "counterfactual_sample", "[", "attr_name_kurz", "]", ">=", "attr_obj", ".", "lower_bound", ",", "'not satisfying plausibility (data-range)'", "\n", "assert", "counterfactual_sample", "[", "attr_name_kurz", "]", "<=", "attr_obj", ".", "upper_bound", ",", "'not satisfying plausibility (data-range)'", "\n", "", "except", ":", "\n", "                ", "counterfactual_plausible", "=", "False", "\n", "# distance = 1000", "\n", "# return factual_sample, counterfactual_sample, distance", "\n", "\n", "", "", "", "end_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "return", "{", "\n", "'factual_sample'", ":", "factual_sample", ",", "\n", "'cfe_sample'", ":", "counterfactual_sample", ",", "\n", "'cfe_found'", ":", "counterfactual_found", ",", "\n", "'cfe_plausible'", ":", "counterfactual_plausible", ",", "\n", "'cfe_distance'", ":", "distance", ",", "\n", "'cfe_time'", ":", "end_time", "-", "start_time", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.treeUtils.simplifyDecisionTree": [[11, 53], ["treeUtils.mergeConditionHoldsTrue", "print", "treeUtils.mergeConditionHoldsTrue", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.treeUtils.mergeConditionHoldsTrue", "home.repos.pwc.inspect_result.amirhk_mace.None.treeUtils.mergeConditionHoldsTrue"], ["def", "simplifyDecisionTree", "(", "tree", ",", "debug_flag", ")", ":", "\n", "    ", "tree_", "=", "tree", ".", "tree_", "\n", "\n", "# while there exists a node whose left & right children", "\n", "#   1. are leaves", "\n", "#   2. share the same classification results", "\n", "# merge together into parent, making their parent a leaf", "\n", "parent_idx", ",", "left_child_idx", ",", "right_child_idx", ",", "children_class", "=", "mergeConditionHoldsTrue", "(", "tree_", ")", "\n", "\n", "if", "debug_flag", ">", "0", ":", "\n", "        ", "print", "(", "'[INFO] Simplifying decision tree...'", ")", "\n", "\n", "", "while", "parent_idx", ">", "-", "1", ":", "\n", "\n", "        ", "if", "debug_flag", ">", "1", ":", "\n", "            ", "print", "(", "'\\t[INFO] Merging children at index {} (left) and {} (right) into index {} (parent)...'", ".", "format", "(", "left_child_idx", ",", "right_child_idx", ",", "parent_idx", ")", ",", "end", "=", "''", ")", "\n", "\n", "", "tree_", ".", "feature", "[", "parent_idx", "]", "=", "-", "2", "\n", "tree_", ".", "threshold", "[", "parent_idx", "]", "=", "-", "2", "\n", "tree_", ".", "children_left", "[", "parent_idx", "]", "=", "-", "1", "\n", "tree_", ".", "children_right", "[", "parent_idx", "]", "=", "-", "1", "\n", "\n", "# Note, unfortunately we cannot update the attributes of tree_ (even if", "\n", "# we were to deep-copy it), and so all pruned nodes will remain. Instead", "\n", "# we will introduce another value (-3) to represent pruned nodes.", "\n", "tree_", ".", "feature", "[", "left_child_idx", "]", "=", "-", "3", "\n", "tree_", ".", "feature", "[", "right_child_idx", "]", "=", "-", "3", "\n", "tree_", ".", "threshold", "[", "left_child_idx", "]", "=", "-", "3", "\n", "tree_", ".", "threshold", "[", "right_child_idx", "]", "=", "-", "3", "\n", "tree_", ".", "children_left", "[", "left_child_idx", "]", "=", "-", "3", "\n", "tree_", ".", "children_left", "[", "right_child_idx", "]", "=", "-", "3", "\n", "tree_", ".", "children_right", "[", "left_child_idx", "]", "=", "-", "3", "\n", "tree_", ".", "children_right", "[", "right_child_idx", "]", "=", "-", "3", "\n", "\n", "parent_idx", ",", "left_child_idx", ",", "right_child_idx", ",", "children_class", "=", "mergeConditionHoldsTrue", "(", "tree_", ")", "\n", "\n", "if", "debug_flag", ">", "1", ":", "\n", "            ", "print", "(", "'done.'", ")", "\n", "\n", "", "", "if", "debug_flag", ">", "0", ":", "\n", "        ", "print", "(", "'[INFO] done.\\n'", ")", "\n", "", "return", "tree_", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.treeUtils.mergeConditionHoldsTrue": [[55, 69], ["treeUtils.getParentLeftRightTuples", "list().index", "list().index", "max", "max", "list", "list", "list", "list"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.treeUtils.getParentLeftRightTuples"], ["", "def", "mergeConditionHoldsTrue", "(", "tree_", ")", ":", "\n", "# Find pairs of leaves", "\n", "# Assert they share a parent", "\n", "# Assert they share a classification result", "\n", "    ", "for", "elem", "in", "getParentLeftRightTuples", "(", "tree_", ")", ":", "\n", "        ", "parent_idx", "=", "elem", "[", "0", "]", "\n", "left_child_idx", "=", "elem", "[", "1", "]", "\n", "right_child_idx", "=", "elem", "[", "2", "]", "\n", "left_child_class", "=", "list", "(", "tree_", ".", "value", "[", "left_child_idx", "]", "[", "0", "]", ")", ".", "index", "(", "max", "(", "list", "(", "tree_", ".", "value", "[", "left_child_idx", "]", "[", "0", "]", ")", ")", ")", "\n", "right_child_class", "=", "list", "(", "tree_", ".", "value", "[", "right_child_idx", "]", "[", "0", "]", ")", ".", "index", "(", "max", "(", "list", "(", "tree_", ".", "value", "[", "right_child_idx", "]", "[", "0", "]", ")", ")", ")", "\n", "if", "left_child_class", "==", "right_child_class", ":", "\n", "            ", "children_class", "=", "left_child_class", "\n", "return", "parent_idx", ",", "left_child_idx", ",", "right_child_idx", ",", "children_class", "\n", "", "", "return", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.treeUtils.getParentLeftRightTuples": [[71, 92], ["list", "range", "len", "range", "len", "treeUtils.isValidParentIdx", "tuples_list.append"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.treeUtils.isValidParentIdx"], ["", "def", "getParentLeftRightTuples", "(", "tree_", ")", ":", "\n", "    ", "features_list", "=", "list", "(", "tree_", ".", "feature", ")", "\n", "tuples_list", "=", "[", "]", "\n", "# Because we cannot delete pruned nodes, we must check for sequences", "\n", "# of [-2, m x -3, -2] within the main list, where m >= 0", "\n", "for", "i", "in", "range", "(", "len", "(", "features_list", ")", ")", ":", "\n", "        ", "if", "features_list", "[", "i", "]", "==", "-", "2", ":", "\n", "            ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "len", "(", "features_list", ")", ")", ":", "\n", "                ", "if", "features_list", "[", "j", "]", "==", "-", "2", ":", "\n", "                    ", "parent_idx", "=", "i", "-", "1", "\n", "left_child_idx", "=", "i", "\n", "right_child_idx", "=", "j", "\n", "# print((parent_idx, left_child_idx, right_child_idx))", "\n", "if", "isValidParentIdx", "(", "tree_", ",", "parent_idx", ",", "left_child_idx", ",", "right_child_idx", ")", ":", "\n", "                        ", "tuples_list", ".", "append", "(", "(", "parent_idx", ",", "left_child_idx", ",", "right_child_idx", ")", ")", "\n", "", "break", "\n", "", "elif", "features_list", "[", "j", "]", "==", "-", "3", ":", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "", "", "", "", "return", "tuples_list", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.treeUtils.getAllSubIdx": [[94, 101], ["range", "len", "len", "sub_indices.append"], "function", ["None"], ["", "def", "getAllSubIdx", "(", "x", ",", "y", ")", ":", "\n", "    ", "sub_indices", "=", "[", "]", "\n", "l1", ",", "l2", "=", "len", "(", "x", ")", ",", "len", "(", "y", ")", "\n", "for", "i", "in", "range", "(", "l1", ")", ":", "\n", "        ", "if", "x", "[", "i", ":", "i", "+", "l2", "]", "==", "y", ":", "\n", "            ", "sub_indices", ".", "append", "(", "i", ")", "\n", "", "", "return", "sub_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.treeUtils.isValidParentIdx": [[103, 107], ["None"], "function", ["None"], ["", "def", "isValidParentIdx", "(", "tree_", ",", "parent_idx", ",", "left_child_idx", ",", "right_child_idx", ")", ":", "\n", "    ", "return", "tree_", ".", "children_left", "[", "parent_idx", "]", "==", "left_child_idx", "and", "tree_", ".", "children_right", "[", "parent_idx", "]", "==", "right_child_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.treeUtils.saveTreeVisualization": [[109, 120], ["sklearn.tree.export_graphviz", "graphviz.Source", "graphviz.Source.render", "os.remove"], "function", ["None"], ["", "def", "saveTreeVisualization", "(", "model", ",", "model_class", ",", "sub_model_name", ",", "X_test", ",", "feature_names", ",", "save_folder_name", ")", ":", "\n", "    ", "save_path", "=", "f'{save_folder_name}/{model_class}_{sub_model_name}_{X_test.shape[1]}_features'", "\n", "dot_data", "=", "export_graphviz", "(", "model", ",", "out_file", "=", "None", ",", "\n", "feature_names", "=", "feature_names", ",", "\n", "class_names", "=", "[", "'0'", ",", "'1'", "]", ",", "\n", "filled", "=", "True", ",", "\n", "rounded", "=", "True", ",", "\n", "special_characters", "=", "True", ")", "\n", "graph", "=", "graphviz", ".", "Source", "(", "dot_data", ")", "\n", "graph", ".", "render", "(", "save_path", ")", "\n", "os", ".", "remove", "(", "save_path", ")", "# two files are outputted, one is extra", "\n", "", ""]], "home.repos.pwc.inspect_result.amirhk_mace.None.utils.Memoize.__init__": [[7, 11], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "fn", ")", ":", "\n", "\n", "    ", "self", ".", "fn", "=", "fn", "\n", "self", ".", "memo", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.utils.Memoize.__call__": [[12, 37], ["inspect.signature", "inspect.signature.bind", "inspect.signature.parameters.values", "tuple", "utils.Memoize.fn", "kwargs.keys", "isinstance", "str"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "\n", "\n", "    ", "sig", "=", "inspect", ".", "signature", "(", "self", ".", "fn", ")", "\n", "ba", "=", "sig", ".", "bind", "(", "*", "args", ")", "\n", "for", "param", "in", "sig", ".", "parameters", ".", "values", "(", ")", ":", "\n", "# to support default args: https://docs.python.org/3.3/library/inspect.html", "\n", "      ", "if", "param", ".", "name", "not", "in", "ba", ".", "arguments", ":", "\n", "        ", "ba", ".", "arguments", "[", "param", ".", "name", "]", "=", "param", ".", "default", "\n", "# For some reason, when we pass in something like tmp(a,b=1) to the function", "\n", "# def tmp(a,b=0), the args will remain (a,0) but not (a,1). Therefore, we", "\n", "# should update `ba` according to the k,v pairs in kwargs", "\n", "", "if", "param", ".", "name", "in", "kwargs", ".", "keys", "(", ")", ":", "\n", "        ", "ba", ".", "arguments", "[", "param", ".", "name", "]", "=", "kwargs", "[", "param", ".", "name", "]", "\n", "", "", "args", "=", "ba", ".", "args", "\n", "\n", "# convert lists and numpy array into tuples so that they can be used as keys", "\n", "hashable_args", "=", "tuple", "(", "[", "\n", "arg", "if", "isinstance", "(", "arg", ",", "collections", ".", "Hashable", ")", "else", "str", "(", "arg", ")", "\n", "for", "arg", "in", "args", "\n", "]", ")", "\n", "\n", "if", "hashable_args", "not", "in", "self", ".", "memo", ":", "\n", "      ", "self", ".", "memo", "[", "hashable_args", "]", "=", "self", ".", "fn", "(", "*", "args", ")", "\n", "", "return", "self", ".", "memo", "[", "hashable_args", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.amirhk_mace.None.batchTest.getEpsilonInString": [[34, 38], ["approach_string.find", "float"], "function", ["None"], ["def", "getEpsilonInString", "(", "approach_string", ")", ":", "\n", "  ", "tmp_index", "=", "approach_string", ".", "find", "(", "'eps'", ")", "\n", "epsilon_string", "=", "approach_string", "[", "tmp_index", "+", "4", ":", "tmp_index", "+", "8", "]", "\n", "return", "float", "(", "epsilon_string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.batchTest.generateExplanations": [[40, 128], ["generateSATExplanations.genExp", "batchTest.getEpsilonInString", "generateSATExplanations.genExp", "batchTest.getEpsilonInString", "generateMOExplanations.genExp", "generateFTExplanations.genExp", "generateFTExplanations.genExp", "generateARExplanations.genExp", "Exception"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.generateFTExplanations.genExp", "home.repos.pwc.inspect_result.amirhk_mace.None.batchTest.getEpsilonInString", "home.repos.pwc.inspect_result.amirhk_mace.None.generateFTExplanations.genExp", "home.repos.pwc.inspect_result.amirhk_mace.None.batchTest.getEpsilonInString", "home.repos.pwc.inspect_result.amirhk_mace.None.generateFTExplanations.genExp", "home.repos.pwc.inspect_result.amirhk_mace.None.generateFTExplanations.genExp", "home.repos.pwc.inspect_result.amirhk_mace.None.generateFTExplanations.genExp", "home.repos.pwc.inspect_result.amirhk_mace.None.generateFTExplanations.genExp"], ["", "def", "generateExplanations", "(", "\n", "approach_string", ",", "\n", "explanation_file_name", ",", "\n", "model_trained", ",", "\n", "dataset_obj", ",", "\n", "factual_sample", ",", "\n", "norm_type_string", ",", "\n", "observable_data_dict", ",", "\n", "standard_deviations", ")", ":", "\n", "\n", "  ", "if", "'MACE'", "in", "approach_string", ":", "# 'MACE_counterfactual':", "\n", "\n", "    ", "return", "generateSATExplanations", ".", "genExp", "(", "\n", "explanation_file_name", ",", "\n", "model_trained", ",", "\n", "dataset_obj", ",", "\n", "factual_sample", ",", "\n", "norm_type_string", ",", "\n", "'mace'", ",", "\n", "getEpsilonInString", "(", "approach_string", ")", "\n", ")", "\n", "\n", "", "elif", "'MINT'", "in", "approach_string", ":", "# 'MINT_counterfactual':", "\n", "\n", "    ", "return", "generateSATExplanations", ".", "genExp", "(", "\n", "explanation_file_name", ",", "\n", "model_trained", ",", "\n", "dataset_obj", ",", "\n", "factual_sample", ",", "\n", "norm_type_string", ",", "\n", "'mint'", ",", "\n", "getEpsilonInString", "(", "approach_string", ")", "\n", ")", "\n", "\n", "", "elif", "approach_string", "==", "'MO'", ":", "# 'minimum_observable':", "\n", "\n", "    ", "return", "generateMOExplanations", ".", "genExp", "(", "\n", "explanation_file_name", ",", "\n", "dataset_obj", ",", "\n", "factual_sample", ",", "\n", "observable_data_dict", ",", "\n", "norm_type_string", "\n", ")", "\n", "\n", "", "elif", "approach_string", "==", "'FT'", ":", "# 'feature_tweaking':", "\n", "\n", "    ", "possible_labels", "=", "[", "0", ",", "1", "]", "\n", "epsilon", "=", ".5", "\n", "perform_while_plausibility", "=", "False", "\n", "return", "generateFTExplanations", ".", "genExp", "(", "\n", "model_trained", ",", "\n", "factual_sample", ",", "\n", "possible_labels", ",", "\n", "epsilon", ",", "\n", "norm_type_string", ",", "\n", "dataset_obj", ",", "\n", "standard_deviations", ",", "\n", "perform_while_plausibility", "\n", ")", "\n", "\n", "", "elif", "approach_string", "==", "'PFT'", ":", "# 'plausible_feature_tweaking':", "\n", "\n", "    ", "possible_labels", "=", "[", "0", ",", "1", "]", "\n", "epsilon", "=", ".5", "\n", "perform_while_plausibility", "=", "True", "\n", "return", "generateFTExplanations", ".", "genExp", "(", "\n", "model_trained", ",", "\n", "factual_sample", ",", "\n", "possible_labels", ",", "\n", "epsilon", ",", "\n", "norm_type_string", ",", "\n", "dataset_obj", ",", "\n", "standard_deviations", ",", "\n", "perform_while_plausibility", "\n", ")", "\n", "\n", "", "elif", "approach_string", "==", "'AR'", ":", "# 'actionable_recourse':", "\n", "\n", "    ", "return", "generateARExplanations", ".", "genExp", "(", "\n", "model_trained", ",", "\n", "factual_sample", ",", "\n", "norm_type_string", ",", "\n", "dataset_obj", "\n", ")", "\n", "\n", "", "else", ":", "\n", "\n", "    ", "raise", "Exception", "(", "f'{approach_string} not recognized as a valid `approach_string`.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.batchTest.runExperiments": [[130, 267], ["print", "print", "print", "print", "os.mkdir", "os.mkdir", "os.mkdir", "open", "loadData.loadDataset", "pickle.dump", "loadData.loadDataset.getTrainTestSplit", "list", "loadModel.loadModelForDataset", "loadModel.loadModelForDataset.predict", "all_pred_data_df.where().dropna", "all_pred_data_df.where().dropna", "iterate_over_data_df.T.to_dict", "observable_data_df.T.to_dict", "iterate_over_data_df.T.to_dict.items", "pickle.dump", "pprint.pprint", "open", "X_train.std", "bool", "print", "batchTest.generateExplanations", "open", "open", "Exception", "datetime.datetime.now().strftime", "all_pred_data_df.where", "all_pred_data_df.where", "print", "print", "Exception", "datetime.datetime.now", "len", "iterate_over_data_df.T.to_dict.keys"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.loadData.loadDataset", "home.repos.pwc.inspect_result.amirhk_mace.None.loadData.Dataset.getTrainTestSplit", "home.repos.pwc.inspect_result.amirhk_mace.None.loadModel.loadModelForDataset", "home.repos.pwc.inspect_result.amirhk_mace.None.batchTest.generateExplanations"], ["", "", "def", "runExperiments", "(", "dataset_values", ",", "model_class_values", ",", "norm_values", ",", "approaches_values", ",", "batch_number", ",", "sample_count", ",", "gen_cf_for", ",", "process_id", ")", ":", "\n", "\n", "  ", "for", "dataset_string", "in", "dataset_values", ":", "\n", "\n", "    ", "print", "(", "f'\\n\\nExperimenting with dataset_string = `{dataset_string}`'", ")", "\n", "\n", "for", "model_class_string", "in", "model_class_values", ":", "\n", "\n", "      ", "print", "(", "f'\\tExperimenting with model_class_string = `{model_class_string}`'", ")", "\n", "\n", "for", "norm_type_string", "in", "norm_values", ":", "\n", "\n", "        ", "print", "(", "f'\\t\\tExperimenting with norm_type_string = `{norm_type_string}`'", ")", "\n", "\n", "for", "approach_string", "in", "approaches_values", ":", "\n", "\n", "          ", "print", "(", "f'\\t\\t\\tExperimenting with approach_string = `{approach_string}`'", ")", "\n", "\n", "# if norm_type_string == 'two_norm':", "\n", "#   raise Exception(f'{norm_type_string} not supported.')", "\n", "\n", "if", "model_class_string", "in", "{", "'tree'", ",", "'forest'", "}", ":", "\n", "            ", "one_hot", "=", "False", "\n", "", "elif", "model_class_string", "in", "{", "'lr'", ",", "'mlp'", "}", ":", "\n", "            ", "one_hot", "=", "True", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f'{model_class_string} not recognized as a valid `model_class_string`.'", ")", "\n", "\n", "# prepare experiment folder", "\n", "", "experiment_name", "=", "f'{dataset_string}__{model_class_string}__{norm_type_string}__{approach_string}__batch{batch_number}__samples{sample_count}__pid{process_id}'", "\n", "experiment_folder_name", "=", "f\"_experiments/{datetime.now().strftime('%Y.%m.%d_%H.%M.%S')}__{experiment_name}\"", "\n", "explanation_folder_name", "=", "f'{experiment_folder_name}/__explanation_log'", "\n", "minimum_distance_folder_name", "=", "f'{experiment_folder_name}/__minimum_distances'", "\n", "os", ".", "mkdir", "(", "f'{experiment_folder_name}'", ")", "\n", "os", ".", "mkdir", "(", "f'{explanation_folder_name}'", ")", "\n", "os", ".", "mkdir", "(", "f'{minimum_distance_folder_name}'", ")", "\n", "log_file", "=", "open", "(", "f'{experiment_folder_name}/log_experiment.txt'", ",", "'w'", ")", "\n", "\n", "# save some files", "\n", "dataset_obj", "=", "loadData", ".", "loadDataset", "(", "dataset_string", ",", "return_one_hot", "=", "one_hot", ",", "load_from_cache", "=", "False", ",", "debug_flag", "=", "False", ")", "\n", "pickle", ".", "dump", "(", "dataset_obj", ",", "open", "(", "f'{experiment_folder_name}/_dataset_obj'", ",", "'wb'", ")", ")", "\n", "#     training portion used to train models", "\n", "#     testing portion used to compute counterfactuals", "\n", "X_train", ",", "X_test", ",", "y_train", ",", "y_test", "=", "dataset_obj", ".", "getTrainTestSplit", "(", ")", "\n", "\n", "standard_deviations", "=", "list", "(", "X_train", ".", "std", "(", ")", ")", "\n", "\n", "# train the model", "\n", "# model_trained = modelTraining.trainAndSaveModels(", "\n", "#   model_class_string,", "\n", "#   dataset_string,", "\n", "#   experiment_folder_name,", "\n", "# )", "\n", "model_trained", "=", "loadModel", ".", "loadModelForDataset", "(", "\n", "model_class_string", ",", "\n", "dataset_string", ",", "\n", "experiment_folder_name", "=", "experiment_folder_name", ")", "\n", "\n", "# get the predicted labels (only test set)", "\n", "# X_test = pd.concat([X_train, X_test]) # ONLY ACTIVATE THIS WHEN TEST SET IS NOT LARGE ENOUGH TO GEN' MODEL RECON DATASET", "\n", "X_test_pred_labels", "=", "model_trained", ".", "predict", "(", "X_test", ")", "\n", "\n", "all_pred_data_df", "=", "X_test", "\n", "# IMPORTANT: note that 'y' is actually 'pred_y', not 'true_y'", "\n", "all_pred_data_df", "[", "'y'", "]", "=", "X_test_pred_labels", "\n", "neg_pred_data_df", "=", "all_pred_data_df", ".", "where", "(", "all_pred_data_df", "[", "'y'", "]", "==", "0", ")", ".", "dropna", "(", ")", "\n", "pos_pred_data_df", "=", "all_pred_data_df", ".", "where", "(", "all_pred_data_df", "[", "'y'", "]", "==", "1", ")", ".", "dropna", "(", ")", "\n", "\n", "batch_start_index", "=", "batch_number", "*", "sample_count", "\n", "batch_end_index", "=", "(", "batch_number", "+", "1", ")", "*", "sample_count", "\n", "\n", "# generate counterfactuals for {only negative, negative & positive} samples", "\n", "if", "gen_cf_for", "==", "'neg_only'", ":", "\n", "            ", "iterate_over_data_df", "=", "neg_pred_data_df", "[", "batch_start_index", ":", "batch_end_index", "]", "# choose only a subset to compare", "\n", "observable_data_df", "=", "pos_pred_data_df", "\n", "", "elif", "gen_cf_for", "==", "'pos_only'", ":", "\n", "            ", "iterate_over_data_df", "=", "pos_pred_data_df", "[", "batch_start_index", ":", "batch_end_index", "]", "# choose only a subset to compare", "\n", "observable_data_df", "=", "neg_pred_data_df", "\n", "", "elif", "gen_cf_for", "==", "'neg_and_pos'", ":", "\n", "            ", "iterate_over_data_df", "=", "all_pred_data_df", "[", "batch_start_index", ":", "batch_end_index", "]", "# choose only a subset to compare", "\n", "observable_data_df", "=", "all_pred_data_df", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f'{gen_cf_for} not recognized as a valid `gen_cf_for`.'", ")", "\n", "\n", "# convert to dictionary for easier enumeration (iteration)", "\n", "", "iterate_over_data_dict", "=", "iterate_over_data_df", ".", "T", ".", "to_dict", "(", ")", "\n", "observable_data_dict", "=", "observable_data_df", ".", "T", ".", "to_dict", "(", ")", "\n", "\n", "# loop through samples for which we desire a counterfactual,", "\n", "# (to be saved as part of the same file of minimum distances)", "\n", "explanation_counter", "=", "1", "\n", "all_minimum_distances", "=", "{", "}", "\n", "for", "factual_sample_index", ",", "factual_sample", "in", "iterate_over_data_dict", ".", "items", "(", ")", ":", "\n", "\n", "            ", "factual_sample", "[", "'y'", "]", "=", "bool", "(", "factual_sample", "[", "'y'", "]", ")", "\n", "\n", "print", "(", "\n", "'\\t\\t\\t\\t'", "\n", "f'Generating explanation for\\t'", "\n", "f'batch #{batch_number}\\t'", "\n", "f'sample #{explanation_counter}/{len(iterate_over_data_dict.keys())}\\t'", "\n", "f'(sample index {factual_sample_index}): '", ",", "end", "=", "''", ")", "# , file=log_file)", "\n", "explanation_counter", "=", "explanation_counter", "+", "1", "\n", "explanation_file_name", "=", "f'{explanation_folder_name}/sample_{factual_sample_index}.txt'", "\n", "\n", "explanation_object", "=", "generateExplanations", "(", "\n", "approach_string", ",", "\n", "explanation_file_name", ",", "\n", "model_trained", ",", "\n", "dataset_obj", ",", "\n", "factual_sample", ",", "\n", "norm_type_string", ",", "\n", "observable_data_dict", ",", "# used solely for minimum_observable method", "\n", "standard_deviations", ",", "# used solely for feature_tweaking method", "\n", ")", "\n", "\n", "if", "'MINT'", "in", "approach_string", ":", "\n", "              ", "print", "(", "\n", "f'\\t- scf_found: {explanation_object[\"scf_found\"]} -'", "\n", "f'\\t- scf_plaus: {explanation_object[\"scf_plausible\"]} -'", "\n", "f'\\t- scf_time: {explanation_object[\"scf_time\"]:.4f} -'", "\n", "f'\\t- int_cost: {explanation_object[\"int_cost\"]:.4f} -'", "\n", "f'\\t- scf_dist: {explanation_object[\"scf_distance\"]:.4f} -'", "\n", ")", "# , file=log_file)", "\n", "", "else", ":", "# 'MACE' or other..", "\n", "              ", "print", "(", "\n", "f'\\t- cfe_found: {explanation_object[\"cfe_found\"]} -'", "\n", "f'\\t- cfe_plaus: {explanation_object[\"cfe_plausible\"]} -'", "\n", "f'\\t- cfe_time: {explanation_object[\"cfe_time\"]:.4f} -'", "\n", "f'\\t- int_cost: N/A -'", "\n", "f'\\t- cfe_dist: {explanation_object[\"cfe_distance\"]:.4f} -'", "\n", ")", "# , file=log_file)", "\n", "\n", "", "all_minimum_distances", "[", "f'sample_{factual_sample_index}'", "]", "=", "explanation_object", "\n", "\n", "", "pickle", ".", "dump", "(", "all_minimum_distances", ",", "open", "(", "f'{experiment_folder_name}/_minimum_distances'", ",", "'wb'", ")", ")", "\n", "pprint", "(", "all_minimum_distances", ",", "open", "(", "f'{experiment_folder_name}/minimum_distances.txt'", ",", "'w'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.modelConversion.tree2py": [[16, 49], ["list", "list.append", "modelConversion.tree2py.recurse"], "function", ["None"], ["def", "tree2py", "(", "tree", ",", "feature_names", ",", "return_value", "=", "'class_idx_max'", ",", "tree_idx", "=", "''", ")", ":", "\n", "    ", "tree_", "=", "tree", ".", "tree_", "\n", "feature_name", "=", "[", "\n", "feature_names", "[", "i", "]", "if", "i", "!=", "_tree", ".", "TREE_UNDEFINED", "else", "'undefined!'", "\n", "for", "i", "in", "tree_", ".", "feature", "\n", "]", "\n", "lines", "=", "list", "(", ")", "\n", "lines", ".", "append", "(", "'def predict_tree{}({}):'", ".", "format", "(", "tree_idx", ",", "', '", ".", "join", "(", "feature_names", ")", ")", ")", "\n", "#", "\n", "def", "recurse", "(", "node", ",", "depth", ")", ":", "\n", "        ", "indent", "=", "'\\t'", "*", "depth", "\n", "if", "tree_", ".", "feature", "[", "node", "]", "!=", "_tree", ".", "TREE_UNDEFINED", ":", "\n", "            ", "name", "=", "feature_name", "[", "node", "]", "\n", "threshold", "=", "tree_", ".", "threshold", "[", "node", "]", "\n", "lines", ".", "append", "(", "'{}if {} <= {}:'", ".", "format", "(", "indent", ",", "name", ",", "threshold", ")", ")", "\n", "recurse", "(", "tree_", ".", "children_left", "[", "node", "]", ",", "depth", "+", "1", ")", "\n", "lines", ".", "append", "(", "'{}else:'", ".", "format", "(", "indent", ")", ")", "\n", "# lines.append('{}else: # if {} > {}'.format(indent, name, threshold))", "\n", "recurse", "(", "tree_", ".", "children_right", "[", "node", "]", ",", "depth", "+", "1", ")", "\n", "", "else", ":", "\n", "            ", "if", "return_value", "==", "'class_idx_max'", ":", "\n", "                ", "values", "=", "list", "(", "tree_", ".", "value", "[", "node", "]", "[", "0", "]", ")", "\n", "output", "=", "values", ".", "index", "(", "max", "(", "values", ")", ")", "\n", "lines", ".", "append", "(", "'{}output = {}'", ".", "format", "(", "indent", ",", "output", ")", ")", "\n", "", "elif", "return_value", "==", "'class_prob_array'", ":", "\n", "                ", "prob_array", "=", "list", "(", "np", ".", "divide", "(", "tree_", ".", "value", "[", "node", "]", "[", "0", "]", ",", "np", ".", "sum", "(", "tree_", ".", "value", "[", "node", "]", "[", "0", "]", ")", ")", ")", "\n", "lines", ".", "append", "(", "'{}output = {}'", ".", "format", "(", "indent", ",", "prob_array", ")", ")", "\n", "#", "\n", "", "", "", "recurse", "(", "0", ",", "1", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'\\treturn output;'", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "return", "'\\n'", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.modelConversion.tree2c": [[51, 89], ["list", "list.append", "list.append", "list.append", "list.append", "modelConversion.tree2py.recurse"], "function", ["None"], ["", "def", "tree2c", "(", "tree", ",", "feature_names", ",", "return_value", "=", "'class_idx_max'", ",", "tree_idx", "=", "''", ")", ":", "\n", "    ", "tree_", "=", "tree", ".", "tree_", "\n", "feature_name", "=", "[", "\n", "feature_names", "[", "i", "]", "if", "i", "!=", "_tree", ".", "TREE_UNDEFINED", "else", "'undefined!'", "\n", "for", "i", "in", "tree_", ".", "feature", "\n", "]", "\n", "lines", "=", "list", "(", ")", "\n", "lines", ".", "append", "(", "'proc predict_tree{}({} : int) : int = {{'", ".", "format", "(", "tree_idx", ",", "' : int, '", ".", "join", "(", "feature_names", ")", ")", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'\\tvar output : int;'", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "#", "\n", "def", "recurse", "(", "node", ",", "depth", ")", ":", "\n", "        ", "indent", "=", "'\\t'", "*", "depth", "\n", "if", "tree_", ".", "feature", "[", "node", "]", "!=", "_tree", ".", "TREE_UNDEFINED", ":", "\n", "            ", "name", "=", "feature_name", "[", "node", "]", "\n", "threshold", "=", "tree_", ".", "threshold", "[", "node", "]", "\n", "lines", ".", "append", "(", "'{}if ( {} <= {} ) then {{ '", ".", "format", "(", "indent", ",", "name", ",", "threshold", ")", ")", "\n", "recurse", "(", "tree_", ".", "children_left", "[", "node", "]", ",", "depth", "+", "1", ")", "\n", "lines", ".", "append", "(", "'{}}} else {{ '", ".", "format", "(", "indent", ")", ")", "\n", "recurse", "(", "tree_", ".", "children_right", "[", "node", "]", ",", "depth", "+", "1", ")", "\n", "lines", ".", "append", "(", "'{}}}'", ".", "format", "(", "indent", ",", "name", ",", "threshold", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "return_value", "==", "'class_idx_max'", ":", "\n", "                ", "values", "=", "list", "(", "tree_", ".", "value", "[", "node", "]", "[", "0", "]", ")", "\n", "output", "=", "values", ".", "index", "(", "max", "(", "values", ")", ")", "\n", "lines", ".", "append", "(", "'{}output = {};'", ".", "format", "(", "indent", ",", "output", ")", ")", "\n", "", "elif", "return_value", "==", "'class_prob_array'", ":", "\n", "                ", "prob_array", "=", "list", "(", "np", ".", "divide", "(", "tree_", ".", "value", "[", "node", "]", "[", "0", "]", ",", "np", ".", "sum", "(", "tree_", ".", "value", "[", "node", "]", "[", "0", "]", ")", ")", ")", "\n", "lines", ".", "append", "(", "'{}output = {};'", ".", "format", "(", "indent", ",", "prob_array", ")", ")", "\n", "#", "\n", "", "", "", "recurse", "(", "0", ",", "1", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'\\treturn output;'", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'}'", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "return", "'\\n'", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.modelConversion.tree2formula": [[91, 126], ["list", "modelConversion.tree2py.recurse"], "function", ["None"], ["", "def", "tree2formula", "(", "tree", ",", "model_symbols", ",", "return_value", "=", "'class_idx_max'", ",", "tree_idx", "=", "''", ")", ":", "\n", "    ", "tree_", "=", "tree", ".", "tree_", "\n", "feature_names", "=", "list", "(", "model_symbols", "[", "'counterfactual'", "]", ".", "keys", "(", ")", ")", "\n", "feature_name", "=", "[", "\n", "feature_names", "[", "i", "]", "if", "i", "!=", "_tree", ".", "TREE_UNDEFINED", "else", "'undefined!'", "\n", "for", "i", "in", "tree_", ".", "feature", "\n", "]", "\n", "\n", "def", "recurse", "(", "node", ")", ":", "\n", "        ", "if", "tree_", ".", "feature", "[", "node", "]", "!=", "_tree", ".", "TREE_UNDEFINED", ":", "\n", "            ", "name", "=", "feature_name", "[", "node", "]", "\n", "threshold", "=", "float", "(", "tree_", ".", "threshold", "[", "node", "]", ")", "\n", "return", "Or", "(", "\n", "And", "(", "\n", "LE", "(", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "name", "]", "[", "'symbol'", "]", ")", ",", "Real", "(", "threshold", ")", ")", ",", "\n", "recurse", "(", "tree_", ".", "children_left", "[", "node", "]", ")", "\n", ")", ",", "\n", "And", "(", "\n", "Not", "(", "LE", "(", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "name", "]", "[", "'symbol'", "]", ")", ",", "Real", "(", "threshold", ")", ")", ")", ",", "\n", "recurse", "(", "tree_", ".", "children_right", "[", "node", "]", ")", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "if", "return_value", "==", "'class_idx_max'", ":", "\n", "                ", "values", "=", "list", "(", "tree_", ".", "value", "[", "node", "]", "[", "0", "]", ")", "\n", "output", "=", "bool", "(", "values", ".", "index", "(", "max", "(", "values", ")", ")", ")", "\n", "return", "EqualsOrIff", "(", "model_symbols", "[", "'output'", "]", "[", "'y'", "]", "[", "'symbol'", "]", ",", "Bool", "(", "output", ")", ")", "\n", "", "elif", "return_value", "==", "'class_prob_array'", ":", "\n", "                ", "prob_array", "=", "list", "(", "np", ".", "divide", "(", "tree_", ".", "value", "[", "node", "]", "[", "0", "]", ",", "np", ".", "sum", "(", "tree_", ".", "value", "[", "node", "]", "[", "0", "]", ")", ")", ")", "\n", "return", "And", "(", "\n", "EqualsOrIff", "(", "model_symbols", "[", "'aux'", "]", "[", "f'p0{tree_idx}'", "]", "[", "'symbol'", "]", ",", "Real", "(", "float", "(", "prob_array", "[", "0", "]", ")", ")", ")", ",", "\n", "EqualsOrIff", "(", "model_symbols", "[", "'aux'", "]", "[", "f'p1{tree_idx}'", "]", "[", "'symbol'", "]", ",", "Real", "(", "float", "(", "prob_array", "[", "1", "]", ")", ")", ")", "\n", ")", "\n", "\n", "", "", "", "return", "recurse", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.modelConversion.forest2py": [[132, 156], ["range", "lines.append", "lines.append", "lines.append", "range", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "len", "lines.append", "lines.append", "lines.append", "len", "lines.append", "lines.append", "lines.append", "modelConversion.tree2py"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.modelConversion.tree2py"], ["", "def", "forest2py", "(", "forest", ",", "feature_names", ")", ":", "\n", "    ", "lines", "=", "[", "]", "\n", "for", "tree_idx", "in", "range", "(", "len", "(", "forest", ".", "estimators_", ")", ")", ":", "\n", "        ", "tree", "=", "forest", ".", "estimators_", "[", "tree_idx", "]", "\n", "lines", ".", "append", "(", "tree2py", "(", "tree", ",", "feature_names", ",", "return_value", "=", "'class_prob_array'", ",", "tree_idx", "=", "tree_idx", ")", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "", "lines", ".", "append", "(", "'def predict_forest({}):'", ".", "format", "(", "', '", ".", "join", "(", "feature_names", ")", ")", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'\\tsum_prob = [0, 0]'", ")", "\n", "for", "tree_idx", "in", "range", "(", "len", "(", "forest", ".", "estimators_", ")", ")", ":", "\n", "        ", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'\\tsum_prob[0] = sum_prob[0] + predict_tree{}({})[0]'", ".", "format", "(", "tree_idx", ",", "', '", ".", "join", "(", "feature_names", ")", ")", ")", "\n", "lines", ".", "append", "(", "'\\tsum_prob[1] = sum_prob[1] + predict_tree{}({})[1]'", ".", "format", "(", "tree_idx", ",", "', '", ".", "join", "(", "feature_names", ")", ")", ")", "\n", "", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'\\tif sum_prob[0] >= sum_prob[1]:'", ")", "\n", "lines", ".", "append", "(", "'\\t\\toutput = 0'", ")", "\n", "lines", ".", "append", "(", "'\\telse:'", ")", "\n", "lines", ".", "append", "(", "'\\t\\toutput = 1'", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'\\treturn output'", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "return", "'\\n'", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.modelConversion.forest2c": [[158, 184], ["range", "lines.append", "lines.append", "lines.append", "range", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "len", "lines.append", "lines.append", "lines.append", "len", "lines.append", "lines.append", "lines.append", "modelConversion.tree2c"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.modelConversion.tree2c"], ["", "def", "forest2c", "(", "forest", ",", "feature_names", ")", ":", "\n", "    ", "lines", "=", "[", "]", "\n", "for", "tree_idx", "in", "range", "(", "len", "(", "forest", ".", "estimators_", ")", ")", ":", "\n", "        ", "tree", "=", "forest", ".", "estimators_", "[", "tree_idx", "]", "\n", "lines", ".", "append", "(", "tree2c", "(", "tree", ",", "feature_names", ",", "return_value", "=", "'class_prob_array'", ",", "tree_idx", "=", "tree_idx", ")", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "", "lines", ".", "append", "(", "'proc predict_forest({} : int) : int = {{'", ".", "format", "(", "', '", ".", "join", "(", "feature_names", ")", ")", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'\\tsum_prob = [0, 0] : int;'", ")", "\n", "for", "tree_idx", "in", "range", "(", "len", "(", "forest", ".", "estimators_", ")", ")", ":", "\n", "        ", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'\\tsum_prob[0] = sum_prob[0] + predict_tree{}({})[0];'", ".", "format", "(", "tree_idx", ",", "', '", ".", "join", "(", "feature_names", ")", ")", ")", "\n", "lines", ".", "append", "(", "'\\tsum_prob[1] = sum_prob[1] + predict_tree{}({})[1];'", ".", "format", "(", "tree_idx", ",", "', '", ".", "join", "(", "feature_names", ")", ")", ")", "\n", "", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'\\tif sum_prob[0] >= sum_prob[1] {{'", ")", "\n", "lines", ".", "append", "(", "'\\t\\toutput = 0;'", ")", "\n", "lines", ".", "append", "(", "'\\t} else {'", ")", "\n", "lines", ".", "append", "(", "'\\t\\toutput = 1;'", ")", "\n", "lines", ".", "append", "(", "'\\t}'", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'\\treturn output;'", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'}'", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "return", "'\\n'", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.modelConversion.forest2formula": [[186, 208], ["range", "And", "Ite", "And", "len", "GE", "EqualsOrIff", "EqualsOrIff", "Symbol", "Symbol", "modelConversion.tree2formula", "Plus", "Plus", "FALSE", "TRUE", "range", "len", "range", "range", "len", "len"], "function", ["home.repos.pwc.inspect_result.amirhk_mace.None.modelConversion.tree2formula"], ["", "def", "forest2formula", "(", "forest", ",", "model_symbols", ")", ":", "\n", "    ", "model_symbols", "[", "'aux'", "]", "=", "{", "}", "\n", "for", "tree_idx", "in", "range", "(", "len", "(", "forest", ".", "estimators_", ")", ")", ":", "\n", "        ", "model_symbols", "[", "'aux'", "]", "[", "f'p0{tree_idx}'", "]", "=", "{", "'symbol'", ":", "Symbol", "(", "f'p0{tree_idx}'", ",", "REAL", ")", "}", "\n", "model_symbols", "[", "'aux'", "]", "[", "f'p1{tree_idx}'", "]", "=", "{", "'symbol'", ":", "Symbol", "(", "f'p1{tree_idx}'", ",", "REAL", ")", "}", "\n", "\n", "", "tree_formulas", "=", "And", "(", "[", "\n", "tree2formula", "(", "forest", ".", "estimators_", "[", "tree_idx", "]", ",", "model_symbols", ",", "return_value", "=", "'class_prob_array'", ",", "tree_idx", "=", "tree_idx", ")", "\n", "for", "tree_idx", "in", "range", "(", "len", "(", "forest", ".", "estimators_", ")", ")", "\n", "]", ")", "\n", "output_formula", "=", "Ite", "(", "\n", "GE", "(", "\n", "Plus", "(", "[", "model_symbols", "[", "'aux'", "]", "[", "f'p0{tree_idx}'", "]", "[", "'symbol'", "]", "for", "tree_idx", "in", "range", "(", "len", "(", "forest", ".", "estimators_", ")", ")", "]", ")", ",", "\n", "Plus", "(", "[", "model_symbols", "[", "'aux'", "]", "[", "f'p1{tree_idx}'", "]", "[", "'symbol'", "]", "for", "tree_idx", "in", "range", "(", "len", "(", "forest", ".", "estimators_", ")", ")", "]", ")", "\n", ")", ",", "\n", "EqualsOrIff", "(", "model_symbols", "[", "'output'", "]", "[", "'y'", "]", "[", "'symbol'", "]", ",", "FALSE", "(", ")", ")", ",", "\n", "EqualsOrIff", "(", "model_symbols", "[", "'output'", "]", "[", "'y'", "]", "[", "'symbol'", "]", ",", "TRUE", "(", ")", ")", ",", "\n", ")", "\n", "\n", "return", "And", "(", "\n", "tree_formulas", ",", "\n", "output_formula", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.modelConversion.lr2py": [[215, 226], ["list", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append"], "function", ["None"], ["", "def", "lr2py", "(", "model", ",", "feature_names", ")", ":", "\n", "    ", "lines", "=", "list", "(", ")", "\n", "lines", ".", "append", "(", "'def predict_lr(x):'", ")", "\n", "lines", ".", "append", "(", "'\\tw = [{}]'", ".", "format", "(", "', '", ".", "join", "(", "[", "'{}'", ".", "format", "(", "w", ")", "for", "w", "in", "model", ".", "coef_", "[", "0", "]", "]", ")", ")", ")", "\n", "lines", ".", "append", "(", "'\\tscore = {}'", ".", "format", "(", "model", ".", "intercept_", "[", "0", "]", ")", ")", "\n", "lines", ".", "append", "(", "'\\tfor i in range({}):'", ".", "format", "(", "model", ".", "coef_", ".", "shape", "[", "1", "]", ")", ")", "\n", "lines", ".", "append", "(", "'\\t\\tscore += x[i] * w[i]'", ")", "\n", "lines", ".", "append", "(", "'\\tif score > 0:'", ")", "\n", "lines", ".", "append", "(", "'\\t\\treturn 1'", ")", "\n", "lines", ".", "append", "(", "'\\treturn 0'", ")", "\n", "return", "'\\n'", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.modelConversion.lr2c": [[228, 253], ["list", "list.append", "list.append", "list.append", "list.append", "list.append", "range", "list.append", "list.append", "range", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "len", "list.append", "len", "list.append", "str", "range", "len"], "function", ["None"], ["", "def", "lr2c", "(", "model", ",", "feature_names", ")", ":", "\n", "    ", "lines", "=", "list", "(", ")", "\n", "lines", ".", "append", "(", "'proc predict_lr({} : int) : int = {{'", ".", "format", "(", "' : int, '", ".", "join", "(", "feature_names", ")", ")", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'\\tvar {}, score : int;'", ".", "format", "(", "', '", ".", "join", "(", "[", "'w'", "+", "str", "(", "i", ")", "for", "i", "in", "range", "(", "len", "(", "feature_names", ")", ")", "]", ")", ")", ")", "\n", "lines", ".", "append", "(", "'\\tvar output : int;'", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "feature_names", ")", ")", ":", "\n", "        ", "lines", ".", "append", "(", "'\\tw{} = {};'", ".", "format", "(", "i", ",", "model", ".", "coef_", "[", "0", "]", "[", "i", "]", ")", ")", "\n", "", "lines", ".", "append", "(", "'\\tscore0 = {};'", ".", "format", "(", "model", ".", "intercept_", "[", "0", "]", ")", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "feature_names", ")", ")", ":", "\n", "        ", "lines", ".", "append", "(", "'\\tscore{} = score{} + ({} * w{});'", ".", "format", "(", "i", "+", "1", ",", "i", ",", "feature_names", "[", "i", "]", ",", "i", ")", ")", "\n", "", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'\\tif (score{} > 0) {{'", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "lines", ".", "append", "(", "'\\t\\toutput = 1;'", ")", "\n", "lines", ".", "append", "(", "'\\t} else {'", ")", "\n", "lines", ".", "append", "(", "'\\t\\toutput = 0;'", ")", "\n", "lines", ".", "append", "(", "'\\t}'", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'\\treturn output;'", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'}'", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "return", "'\\n'", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.modelConversion.lr2formula": [[255, 282], ["Ite", "GT", "EqualsOrIff", "EqualsOrIff", "Plus", "Real", "TRUE", "FALSE", "Real", "Plus", "float", "Times", "ToReal", "Real", "enumerate", "float", "model_symbols[].keys"], "function", ["None"], ["", "def", "lr2formula", "(", "model", ",", "model_symbols", ")", ":", "\n", "    ", "return", "Ite", "(", "\n", "# it turns out that sklearn's model.predict() classifies the following", "\n", "# as class -1, not +1: np.dot(coef_, sample) + intercept_ = 0", "\n", "# Therefore, below we should use GT, and not GE. We didn't encounter", "\n", "# this bug before, becuase of another bug in genMACEExplanations where", "\n", "# numeric-real variables were not being set to REAL. Therefore, it never", "\n", "# happened that np.dot(coef_, sample) + intercept_ would be exactly 0 lol!", "\n", "# UPDATE (2020.02.28 & 2020.06.24): turns out that:", "\n", "#                        for factual_sample['y'] = 1 for which we seek a negative CF --> GE works, GT fails", "\n", "#                        for factual_sample['y'] = 0 for which we seek a positive CF --> GT works, GE fails", "\n", "# ... which is due to 2e-16 values... therefore, I reluctantly added a", "\n", "# condition to assertPrediction in genSATExplanations.py. Resolved.", "\n", "GT", "(", "\n", "Plus", "(", "\n", "Real", "(", "float", "(", "model", ".", "intercept_", "[", "0", "]", ")", ")", ",", "\n", "Plus", "(", "[", "\n", "Times", "(", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "symbol_key", "]", "[", "'symbol'", "]", ")", ",", "\n", "Real", "(", "float", "(", "model", ".", "coef_", "[", "0", "]", "[", "idx", "]", ")", ")", "\n", ")", "\n", "for", "idx", ",", "symbol_key", "in", "enumerate", "(", "model_symbols", "[", "'counterfactual'", "]", ".", "keys", "(", ")", ")", "\n", "]", ")", "\n", ")", ",", "\n", "Real", "(", "0", ")", ")", ",", "\n", "EqualsOrIff", "(", "model_symbols", "[", "'output'", "]", "[", "'y'", "]", "[", "'symbol'", "]", ",", "TRUE", "(", ")", ")", ",", "\n", "EqualsOrIff", "(", "model_symbols", "[", "'output'", "]", "[", "'y'", "]", "[", "'symbol'", "]", ",", "FALSE", "(", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.modelConversion.mlp2py": [[289, 317], ["list", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append"], "function", ["None"], ["", "def", "mlp2py", "(", "model", ")", ":", "\n", "    ", "lines", "=", "list", "(", ")", "\n", "lines", ".", "append", "(", "'def predict_mlp(model, x):'", ")", "\n", "lines", ".", "append", "(", "'\\tlayer_output = x'", ")", "\n", "lines", ".", "append", "(", "'\\tfor layer_idx in range(len(model.coefs_)):'", ")", "\n", "lines", ".", "append", "(", "'\\t\\t#'", ")", "\n", "lines", ".", "append", "(", "'\\t\\tlayer_input_size = len(model.coefs_[layer_idx])'", ")", "\n", "lines", ".", "append", "(", "'\\t\\tif layer_idx != len(model.coefs_) - 1:'", ")", "\n", "lines", ".", "append", "(", "'\\t\\t\\tlayer_output_size = len(model.coefs_[layer_idx + 1])'", ")", "\n", "lines", ".", "append", "(", "'\\t\\telse:'", ")", "\n", "lines", ".", "append", "(", "'\\t\\t\\tlayer_output_size = model.n_outputs_'", ")", "\n", "lines", ".", "append", "(", "'\\t\\t#'", ")", "\n", "lines", ".", "append", "(", "'\\t\\tlayer_input = layer_output'", ")", "\n", "lines", ".", "append", "(", "'\\t\\tlayer_output = [0 for j in range(layer_output_size)]'", ")", "\n", "lines", ".", "append", "(", "'\\t\\t# i: indices of nodes in layer L'", ")", "\n", "lines", ".", "append", "(", "'\\t\\t# j: indices of nodes in layer L + 1'", ")", "\n", "lines", ".", "append", "(", "'\\t\\tfor j in range(layer_output_size):'", ")", "\n", "lines", ".", "append", "(", "'\\t\\t\\tscore = model.intercepts_[layer_idx][j]'", ")", "\n", "lines", ".", "append", "(", "'\\t\\t\\tfor i in range(layer_input_size):'", ")", "\n", "lines", ".", "append", "(", "'\\t\\t\\t\\tscore += layer_input[i] * model.coefs_[layer_idx][i][j]'", ")", "\n", "lines", ".", "append", "(", "'\\t\\t\\tif score > 0: # relu operator'", ")", "\n", "lines", ".", "append", "(", "'\\t\\t\\t\\tlayer_output[j] = score'", ")", "\n", "lines", ".", "append", "(", "'\\t\\t\\telse:'", ")", "\n", "lines", ".", "append", "(", "'\\t\\t\\t\\tlayer_output[j] = 0'", ")", "\n", "lines", ".", "append", "(", "'\\tif layer_output[0] > 0:'", ")", "\n", "lines", ".", "append", "(", "'\\t\\treturn 1'", ")", "\n", "lines", ".", "append", "(", "'\\treturn 0'", ")", "\n", "return", "'\\n'", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.modelConversion.mlp2c": [[319, 405], ["layer_widths.append", "layer_widths.extend", "layer_widths.append", "range", "range", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "range", "lines.append", "lines.append", "range", "lines.append", "range", "lines.append", "range", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "len", "len", "len", "range", "len", "range", "len", "range", "lines.append", "len", "range", "len", "lines.append", "lines.append", "range", "range", "all_feature_variables.append", "range", "lines.append", "range", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "all_weight_variables.append", "lines.append", "tmp_strings.append"], "function", ["None"], ["", "def", "mlp2c", "(", "model", ",", "feature_names", ")", ":", "\n", "\n", "    ", "num_layers", "=", "2", "+", "len", "(", "model", ".", "hidden_layer_sizes", ")", "\n", "layer_widths", "=", "[", "]", "\n", "layer_widths", ".", "append", "(", "len", "(", "feature_names", ")", ")", "\n", "layer_widths", ".", "extend", "(", "model", ".", "hidden_layer_sizes", ")", "\n", "layer_widths", ".", "append", "(", "model", ".", "n_outputs_", ")", "\n", "\n", "all_weight_variables", "=", "[", "]", "\n", "for", "interlayer_idx", "in", "range", "(", "len", "(", "model", ".", "coefs_", ")", ")", ":", "\n", "        ", "interlayer_weight_matrix", "=", "model", ".", "coefs_", "[", "interlayer_idx", "]", "\n", "for", "prev_layer_feature_idx", "in", "range", "(", "interlayer_weight_matrix", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "for", "curr_layer_feature_idx", "in", "range", "(", "interlayer_weight_matrix", ".", "shape", "[", "1", "]", ")", ":", "\n", "                ", "all_weight_variables", ".", "append", "(", "'w_{}_{}_{}'", ".", "format", "(", "interlayer_idx", ",", "prev_layer_feature_idx", ",", "curr_layer_feature_idx", ")", ")", "\n", "\n", "", "", "", "all_feature_variables", "=", "[", "]", "\n", "for", "layer_idx", "in", "range", "(", "len", "(", "layer_widths", ")", ")", ":", "\n", "        ", "for", "feature_idx", "in", "range", "(", "layer_widths", "[", "layer_idx", "]", ")", ":", "\n", "            ", "all_feature_variables", ".", "append", "(", "'f_{}_{}'", ".", "format", "(", "layer_idx", ",", "feature_idx", ")", ")", "\n", "\n", "", "", "lines", "=", "[", "]", "\n", "lines", ".", "append", "(", "'proc predict_mlp({} : int) : int = {{'", ".", "format", "(", "' : int, '", ".", "join", "(", "feature_names", ")", ")", ")", "\n", "\n", "lines", ".", "append", "(", "''", ")", "\n", "\n", "# lines.append('\\tvar num_layers : int;')", "\n", "# lines.append('\\tvar layer_widths : int list;')", "\n", "lines", ".", "append", "(", "'\\tvar {} : int;'", ".", "format", "(", "', '", ".", "join", "(", "all_weight_variables", ")", ")", ")", "\n", "lines", ".", "append", "(", "'\\tvar {} : int;'", ".", "format", "(", "', '", ".", "join", "(", "all_feature_variables", ")", ")", ")", "\n", "lines", ".", "append", "(", "'\\tvar output : int;'", ")", "\n", "\n", "lines", ".", "append", "(", "''", ")", "\n", "\n", "# lines.append('\\tnum_layers = {};'.format(num_layers))", "\n", "# for i in range(len(layer_widths)):", "\n", "#     lines.append('\\tlayer_widths = layer_widths ++ [{}]'.format(layer_widths[i]))", "\n", "\n", "for", "interlayer_idx", "in", "range", "(", "len", "(", "model", ".", "coefs_", ")", ")", ":", "\n", "        ", "interlayer_weight_matrix", "=", "model", ".", "coefs_", "[", "interlayer_idx", "]", "\n", "for", "prev_layer_feature_idx", "in", "range", "(", "interlayer_weight_matrix", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "for", "curr_layer_feature_idx", "in", "range", "(", "interlayer_weight_matrix", ".", "shape", "[", "1", "]", ")", ":", "\n", "                ", "lines", ".", "append", "(", "'\\tw_{}_{}_{} = {};'", ".", "format", "(", "interlayer_idx", ",", "prev_layer_feature_idx", ",", "curr_layer_feature_idx", ",", "interlayer_weight_matrix", "[", "prev_layer_feature_idx", ",", "curr_layer_feature_idx", "]", ")", ")", "\n", "# TODO... why don't lines below work??", "\n", "# for layer_idx in range(len(layer_widths) - 1):", "\n", "#     for prev_layer_feature_idx in range(layer_widths[layer_idx]):", "\n", "#         for curr_layer_feature_idx in range(layer_widths[layer_idx] + 1):", "\n", "#             lines.append('\\tw_{}_{}_{} = {};'.format(layer_idx, prev_layer_feature_idx, curr_layer_feature_idx, model.coefs_[layer_idx][prev_layer_feature_idx, curr_layer_feature_idx]))", "\n", "", "", "", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'\\t%% value set to input to MLP'", ")", "\n", "for", "feature_idx", "in", "range", "(", "layer_widths", "[", "0", "]", ")", ":", "\n", "        ", "lines", ".", "append", "(", "'\\tf_{}_{} = {};'", ".", "format", "(", "0", ",", "feature_idx", ",", "feature_names", "[", "feature_idx", "]", ")", ")", "\n", "", "lines", ".", "append", "(", "'\\t%% initial value set to node bias'", ")", "\n", "for", "layer_idx", "in", "range", "(", "1", ",", "len", "(", "layer_widths", ")", ")", ":", "\n", "        ", "for", "feature_idx", "in", "range", "(", "layer_widths", "[", "layer_idx", "]", ")", ":", "\n", "            ", "lines", ".", "append", "(", "'\\tf_{}_{} = {};'", ".", "format", "(", "layer_idx", ",", "feature_idx", ",", "model", ".", "intercepts_", "[", "layer_idx", "-", "1", "]", "[", "feature_idx", "]", ")", ")", "\n", "\n", "", "", "lines", ".", "append", "(", "''", ")", "\n", "\n", "# TODO: s/int/float", "\n", "for", "layer_idx", "in", "range", "(", "1", ",", "len", "(", "layer_widths", ")", ")", ":", "\n", "        ", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'\\t%% Layer {}'", ".", "format", "(", "layer_idx", ")", ")", "\n", "for", "curr_layer_feature_idx", "in", "range", "(", "layer_widths", "[", "layer_idx", "]", ")", ":", "\n", "            ", "curr_layer_feature", "=", "'f_{}_{}'", ".", "format", "(", "layer_idx", ",", "curr_layer_feature_idx", ")", "\n", "tmp_strings", "=", "[", "]", "\n", "for", "prev_layer_feature_idx", "in", "range", "(", "layer_widths", "[", "layer_idx", "-", "1", "]", ")", ":", "\n", "                ", "prev_layer_feature", "=", "'f_{}_{}'", ".", "format", "(", "layer_idx", "-", "1", ",", "prev_layer_feature_idx", ")", "\n", "tmp_strings", ".", "append", "(", "'({} * w_{}_{}_{})'", ".", "format", "(", "prev_layer_feature", ",", "layer_idx", "-", "1", ",", "prev_layer_feature_idx", ",", "curr_layer_feature_idx", ")", ")", "\n", "", "lines", ".", "append", "(", "'\\t{} = {} + {};'", ".", "format", "(", "curr_layer_feature", ",", "curr_layer_feature", ",", "' + '", ".", "join", "(", "tmp_strings", ")", ")", ")", "\n", "#", "\n", "lines", ".", "append", "(", "'\\tif ({} > 0) {{'", ".", "format", "(", "curr_layer_feature", ")", ")", "\n", "lines", ".", "append", "(", "'\\t\\t{} = {};'", ".", "format", "(", "curr_layer_feature", ",", "curr_layer_feature", ")", ")", "\n", "lines", ".", "append", "(", "'\\t} else {'", ")", "\n", "lines", ".", "append", "(", "'\\t\\t{} = 0;'", ".", "format", "(", "curr_layer_feature", ")", ")", "\n", "lines", ".", "append", "(", "'\\t}'", ")", "\n", "#", "\n", "# lines.append('\\t{} = ({} > 0) ? {} : 0'.format(curr_layer_feature, curr_layer_feature, curr_layer_feature))", "\n", "\n", "# using the final value set to curr_layer_feature (remember it's only 1 value because binary classification)", "\n", "", "", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'\\toutput = {};'", ".", "format", "(", "curr_layer_feature", ")", ")", "# TODO: if > 1, return TRUE, else FALSE", "\n", "lines", ".", "append", "(", "'\\treturn output;'", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "lines", ".", "append", "(", "'}'", ")", "\n", "lines", ".", "append", "(", "''", ")", "\n", "return", "'\\n'", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace.None.modelConversion.mlp2formula": [[407, 495], ["range", "layer_widths.append", "range", "range", "Ite", "tmp.append", "And", "len", "layer_widths.append", "len", "range", "len", "range", "GT", "EqualsOrIff", "EqualsOrIff", "tmp.append", "inputs_to_curr_layer_feature.append", "range", "formula_assign_feature_values.append", "formula_assign_feature_values.append", "Real", "TRUE", "FALSE", "Symbol", "Symbol", "Real", "EqualsOrIff", "EqualsOrIff", "len", "float", "inputs_to_curr_layer_feature.append", "inputs_to_curr_layer_feature.append", "Plus", "Ite", "list", "Times", "Times", "GE", "Real", "model_symbols[].keys", "ToReal", "Real", "Real", "Real", "float", "float"], "function", ["None"], ["", "def", "mlp2formula", "(", "model", ",", "model_symbols", ")", ":", "\n", "\n", "    ", "model_symbols", "[", "'aux'", "]", "=", "{", "}", "\n", "layer_widths", "=", "[", "]", "\n", "for", "interlayer_idx", "in", "range", "(", "len", "(", "model", ".", "coefs_", ")", ")", ":", "\n", "        ", "layer_widths", ".", "append", "(", "model", ".", "coefs_", "[", "interlayer_idx", "]", ".", "shape", "[", "0", "]", ")", "\n", "", "layer_widths", ".", "append", "(", "model", ".", "coefs_", "[", "-", "1", "]", ".", "shape", "[", "1", "]", ")", "\n", "\n", "\n", "for", "layer_idx", "in", "range", "(", "1", ",", "len", "(", "layer_widths", ")", ")", ":", "\n", "        ", "for", "feature_idx", "in", "range", "(", "layer_widths", "[", "layer_idx", "]", ")", ":", "\n", "            ", "feature_string_1", "=", "'f_{}_{}_pre_nonlin'", ".", "format", "(", "layer_idx", ",", "feature_idx", ")", "\n", "feature_string_2", "=", "'f_{}_{}_post_nonlin'", ".", "format", "(", "layer_idx", ",", "feature_idx", ")", "\n", "model_symbols", "[", "'aux'", "]", "[", "feature_string_1", "]", "=", "{", "'symbol'", ":", "Symbol", "(", "feature_string_1", ",", "REAL", ")", "}", "\n", "model_symbols", "[", "'aux'", "]", "[", "feature_string_2", "]", "=", "{", "'symbol'", ":", "Symbol", "(", "feature_string_2", ",", "REAL", ")", "}", "\n", "\n", "\n", "", "", "formula_assign_feature_values", "=", "[", "]", "\n", "for", "layer_idx", "in", "range", "(", "1", ",", "len", "(", "layer_widths", ")", ")", ":", "\n", "\n", "        ", "interlayer_weight_matrix", "=", "model", ".", "coefs_", "[", "layer_idx", "-", "1", "]", "\n", "\n", "for", "curr_layer_feature_idx", "in", "range", "(", "layer_widths", "[", "layer_idx", "]", ")", ":", "\n", "\n", "            ", "curr_layer_feature_string_1", "=", "'f_{}_{}_pre_nonlin'", ".", "format", "(", "layer_idx", ",", "curr_layer_feature_idx", ")", "\n", "curr_layer_feature_string_2", "=", "'f_{}_{}_post_nonlin'", ".", "format", "(", "layer_idx", ",", "curr_layer_feature_idx", ")", "\n", "bias_string", "=", "'b_{}_{}'", ".", "format", "(", "layer_idx", ",", "curr_layer_feature_idx", ")", "\n", "\n", "inputs_to_curr_layer_feature", "=", "[", "]", "\n", "inputs_to_curr_layer_feature", ".", "append", "(", "Real", "(", "float", "(", "model", ".", "intercepts_", "[", "layer_idx", "-", "1", "]", "[", "curr_layer_feature_idx", "]", ")", ")", ")", "\n", "\n", "for", "prev_layer_feature_idx", "in", "range", "(", "layer_widths", "[", "layer_idx", "-", "1", "]", ")", ":", "\n", "\n", "                ", "if", "layer_idx", "==", "1", ":", "\n", "                    ", "input_layer_feature_string", "=", "list", "(", "model_symbols", "[", "'counterfactual'", "]", ".", "keys", "(", ")", ")", "[", "prev_layer_feature_idx", "]", "\n", "weight_string", "=", "'w_{}_{}_{}'", ".", "format", "(", "layer_idx", "-", "1", ",", "prev_layer_feature_idx", ",", "curr_layer_feature_idx", ")", "\n", "inputs_to_curr_layer_feature", ".", "append", "(", "\n", "Times", "(", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "input_layer_feature_string", "]", "[", "'symbol'", "]", ")", ",", "\n", "Real", "(", "float", "(", "interlayer_weight_matrix", "[", "prev_layer_feature_idx", ",", "curr_layer_feature_idx", "]", ")", ")", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "prev_layer_feature_string_2", "=", "'f_{}_{}_post_nonlin'", ".", "format", "(", "layer_idx", "-", "1", ",", "prev_layer_feature_idx", ")", "\n", "weight_string", "=", "'w_{}_{}_{}'", ".", "format", "(", "layer_idx", "-", "1", ",", "prev_layer_feature_idx", ",", "curr_layer_feature_idx", ")", "\n", "inputs_to_curr_layer_feature", ".", "append", "(", "\n", "Times", "(", "\n", "model_symbols", "[", "'aux'", "]", "[", "prev_layer_feature_string_2", "]", "[", "'symbol'", "]", ",", "\n", "Real", "(", "float", "(", "interlayer_weight_matrix", "[", "prev_layer_feature_idx", ",", "curr_layer_feature_idx", "]", ")", ")", "\n", ")", "\n", ")", "\n", "\n", "", "", "formula_assign_feature_values", ".", "append", "(", "\n", "EqualsOrIff", "(", "\n", "model_symbols", "[", "'aux'", "]", "[", "curr_layer_feature_string_1", "]", "[", "'symbol'", "]", ",", "\n", "Plus", "(", "inputs_to_curr_layer_feature", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "formula_assign_feature_values", ".", "append", "(", "\n", "EqualsOrIff", "(", "\n", "model_symbols", "[", "'aux'", "]", "[", "curr_layer_feature_string_2", "]", "[", "'symbol'", "]", ",", "\n", "Ite", "(", "\n", "GE", "(", "model_symbols", "[", "'aux'", "]", "[", "curr_layer_feature_string_1", "]", "[", "'symbol'", "]", ",", "Real", "(", "0", ")", ")", ",", "\n", "model_symbols", "[", "'aux'", "]", "[", "curr_layer_feature_string_1", "]", "[", "'symbol'", "]", ",", "\n", "Real", "(", "0", ")", "\n", ")", "\n", ")", "\n", "\n", ")", "\n", "\n", "", "", "final_layer_binary_feature_string", "=", "f'f_{len(layer_widths) - 1}_0_post_nonlin'", "\n", "output_formula", "=", "Ite", "(", "\n", "GT", "(", "\n", "model_symbols", "[", "'aux'", "]", "[", "final_layer_binary_feature_string", "]", "[", "'symbol'", "]", ",", "\n", "Real", "(", "0", ")", ",", "\n", ")", ",", "\n", "EqualsOrIff", "(", "model_symbols", "[", "'output'", "]", "[", "'y'", "]", "[", "'symbol'", "]", ",", "TRUE", "(", ")", ")", ",", "\n", "EqualsOrIff", "(", "model_symbols", "[", "'output'", "]", "[", "'y'", "]", "[", "'symbol'", "]", ",", "FALSE", "(", ")", ")", ",", "\n", ")", "\n", "\n", "# Flatten before And() to get a & b & c, not (a & b) & c... maybe easier for solver.", "\n", "tmp", "=", "[", "]", "\n", "for", "elem", "in", "formula_assign_feature_values", ":", "\n", "        ", "tmp", ".", "append", "(", "elem", ")", "\n", "", "tmp", ".", "append", "(", "output_formula", ")", "\n", "\n", "return", "And", "(", "tmp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace._hooks.checkDistanceOptimality.get_all_new_minimum_distances": [[18, 51], ["glob.glob", "experiment_folder.split", "os.path.join", "experiment_details[].split", "os.path.isfile", "pickle.load", "open"], "function", ["None"], ["def", "get_all_new_minimum_distances", "(", "experiments_start_time", ")", ":", "\n", "# create a dictionary with regards to the setup", "\n", "    ", "all_new_minimum_distances", "=", "{", "}", "\n", "for", "dataset_string", "in", "DATASET_VALUES", ":", "\n", "        ", "all_new_minimum_distances", "[", "dataset_string", "]", "=", "{", "}", "\n", "for", "model_class_string", "in", "MODEL_CLASS_VALUES", ":", "\n", "            ", "all_new_minimum_distances", "[", "dataset_string", "]", "[", "model_class_string", "]", "=", "{", "}", "\n", "for", "norm_type_string", "in", "NORM_VALUES", ":", "\n", "                ", "all_new_minimum_distances", "[", "dataset_string", "]", "[", "model_class_string", "]", "[", "norm_type_string", "]", "=", "{", "}", "\n", "for", "approach_string", "in", "APPROACHES_VALUES", ":", "\n", "                    ", "all_new_minimum_distances", "[", "dataset_string", "]", "[", "model_class_string", "]", "[", "norm_type_string", "]", "[", "approach_string", "]", "=", "{", "}", "\n", "\n", "# take the minimum distances from each experiment folder created after experiments_start_time", "\n", "", "", "", "", "for", "experiment_folder", "in", "glob", ".", "glob", "(", "f'{experiments_folder_path}*'", ")", ":", "\n", "\n", "        ", "experiment_details", "=", "experiment_folder", ".", "split", "(", "'__'", ")", "\n", "\n", "if", "experiment_details", "[", "0", "]", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ">=", "experiments_start_time", ":", "\n", "            ", "dataset_string", "=", "experiment_details", "[", "1", "]", "\n", "model_class_string", "=", "experiment_details", "[", "2", "]", "\n", "norm_type_string", "=", "experiment_details", "[", "3", "]", "\n", "approach_string", "=", "experiment_details", "[", "4", "]", "\n", "\n", "minimum_distances_path", "=", "os", ".", "path", ".", "join", "(", "experiment_folder", ",", "'_minimum_distances'", ")", "\n", "\n", "try", ":", "\n", "                ", "assert", "os", ".", "path", ".", "isfile", "(", "minimum_distances_path", ")", "\n", "minimum_distances", "=", "pickle", ".", "load", "(", "open", "(", "minimum_distances_path", ",", "'rb'", ")", ")", "\n", "all_new_minimum_distances", "[", "dataset_string", "]", "[", "model_class_string", "]", "[", "norm_type_string", "]", "[", "approach_string", "]", "=", "minimum_distances", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "\n", "", "", "", "return", "all_new_minimum_distances", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace._data_main.process_credit_data.load_credit_data": [[7, 118], ["os.path.join", "os.path.join", "pandas.read_csv", "pandas.DataFrame", "list", "raw_df[].applymap().round().astype", "numpy.maximum", "numpy.maximum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.maximum", "numpy.maximum", "raw_df.rename.rename", "raw_df[].replace", "numpy.logical_not", "numpy.repeat", "numpy.sum", "range", "overdue_counts.astype.astype", "raw_df[].sum", "processed_df.dropna.reset_index", "processed_df.dropna.dropna", "processed_df.dropna.to_csv", "processed_df.dropna.astype", "os.path.dirname", "os.path.dirname", "filter", "raw_df[].max", "raw_df[].max", "numpy.greater", "raw_df[].to_numpy", "numpy.concatenate", "numpy.abs", "[].reshape", "len", "len", "raw_df[].sum", "raw_df[].applymap().round", "raw_df[].div", "raw_df[].div", "range", "numpy.diff", "process_credit_data.load_credit_data.count_zero_streaks"], "function", ["None"], ["def", "load_credit_data", "(", ")", ":", "\n", "\n", "# input vars", "\n", "  ", "data_name", "=", "'credit'", "\n", "raw_data_file", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "'credit_raw.csv'", ")", "\n", "processed_file", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "'credit_processed.csv'", ")", "\n", "\n", "##### Credit Data Processing", "\n", "raw_df", "=", "pd", ".", "read_csv", "(", "raw_data_file", ",", "index_col", "=", "0", ")", "\n", "processed_df", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n", "# convert NTD to USD using spot rate in 09-2005", "\n", "NTD_to_USD", "=", "32.75", "# see https://www.poundsterlinglive.com/bank-of-england-spot/historical-spot-exchange-rates/usd/USD-to-TWD-2005", "\n", "monetary_features", "=", "list", "(", "filter", "(", "lambda", "x", ":", "(", "'BILL_AMT'", "in", "x", ")", "or", "(", "'PAY_AMT'", "in", "x", ")", "or", "(", "'LIMIT_BAL'", "in", "x", ")", ",", "raw_df", ".", "columns", ")", ")", "\n", "raw_df", "[", "monetary_features", "]", "=", "raw_df", "[", "monetary_features", "]", ".", "applymap", "(", "lambda", "x", ":", "x", "/", "NTD_to_USD", ")", ".", "round", "(", "-", "1", ")", ".", "astype", "(", "int", ")", "\n", "\n", "# outcome variable in first column", "\n", "processed_df", "[", "'NoDefaultNextMonth (label)'", "]", "=", "1", "-", "raw_df", "[", "'default payment next month (label)'", "]", "\n", "\n", "# Gender (old; male = 1, female = 2) --> (new; male = 0, female = 1)", "\n", "# <Removed by Berk> processed_df['Female'] = raw_df['SEX'] == 2", "\n", "processed_df", ".", "loc", "[", "raw_df", "[", "'SEX'", "]", "==", "1", ",", "'isMale'", "]", "=", "True", "\n", "processed_df", ".", "loc", "[", "raw_df", "[", "'SEX'", "]", "==", "2", ",", "'isMale'", "]", "=", "False", "\n", "\n", "# Married (old; married = 1; single = 2; other = 3) --> (new; married = 1; single = 2; other = 3)", "\n", "# <Removed by Amir> processed_df['Married'] = raw_df['MARRIAGE'] == 1", "\n", "# <Removed by Amir> processed_df['Single'] = raw_df['MARRIAGE'] == 2", "\n", "processed_df", ".", "loc", "[", "raw_df", ".", "MARRIAGE", "==", "1", ",", "'isMarried'", "]", "=", "True", "# married (use T/F, but not 1/0, so that some values become NAN and can be dropped later!)", "\n", "processed_df", ".", "loc", "[", "raw_df", ".", "MARRIAGE", "==", "2", ",", "'isMarried'", "]", "=", "False", "# single (use T/F, but not 1/0, so that some values become NAN and can be dropped later!)", "\n", "# <Set to NAN by Amir> processed_df.loc[raw_df.MARRIAGE == 0, 'isMarried'] = 3 # other", "\n", "# <Set to NAN by Amir> processed_df.loc[raw_df.MARRIAGE == 3, 'isMarried'] = 3 # other", "\n", "\n", "# Age", "\n", "# <Removed by Amir> processed_df['Age_lt_25'] = raw_df['AGE'] < 25", "\n", "# <Removed by Amir> processed_df['Age_in_25_to_40'] = raw_df['AGE'].between(25, 40, inclusive = True)", "\n", "# <Removed by Amir> processed_df['Age_in_40_to_59'] = raw_df['AGE'].between(40, 59, inclusive = True)", "\n", "# <Removed by Amir> processed_df['Age_geq_60'] = raw_df['AGE'] >= 60", "\n", "processed_df", ".", "loc", "[", "raw_df", "[", "'AGE'", "]", "<", "25", ",", "'AgeGroup'", "]", "=", "1", "\n", "processed_df", ".", "loc", "[", "raw_df", "[", "'AGE'", "]", ".", "between", "(", "25", ",", "40", ",", "inclusive", "=", "True", ")", ",", "'AgeGroup'", "]", "=", "2", "\n", "processed_df", ".", "loc", "[", "raw_df", "[", "'AGE'", "]", ".", "between", "(", "40", ",", "59", ",", "inclusive", "=", "True", ")", ",", "'AgeGroup'", "]", "=", "3", "\n", "processed_df", ".", "loc", "[", "raw_df", "[", "'AGE'", "]", ">=", "60", ",", "'AgeGroup'", "]", "=", "4", "\n", "\n", "# EducationLevel (currently, 1 = graduate school; 2 = university; 3 = high school; 4 = others)", "\n", "processed_df", "[", "'EducationLevel'", "]", "=", "1", "\n", "processed_df", "[", "'EducationLevel'", "]", "[", "raw_df", "[", "'EDUCATION'", "]", "==", "3", "]", "=", "2", "# HS", "\n", "processed_df", "[", "'EducationLevel'", "]", "[", "raw_df", "[", "'EDUCATION'", "]", "==", "2", "]", "=", "3", "# University", "\n", "processed_df", "[", "'EducationLevel'", "]", "[", "raw_df", "[", "'EDUCATION'", "]", "==", "1", "]", "=", "4", "# Graduate", "\n", "\n", "\n", "# Process Bill Related Variables", "\n", "pay_columns", "=", "[", "'PAY_AMT1'", ",", "'PAY_AMT2'", ",", "'PAY_AMT3'", ",", "'PAY_AMT4'", ",", "'PAY_AMT5'", ",", "'PAY_AMT6'", "]", "\n", "bill_columns", "=", "[", "'BILL_AMT1'", ",", "'BILL_AMT2'", ",", "'BILL_AMT3'", ",", "'BILL_AMT4'", ",", "'BILL_AMT5'", ",", "'BILL_AMT6'", "]", "\n", "\n", "#processed_df['LastBillAmount'] = np.maximum(raw_df['BILL_AMT1'], 0)", "\n", "processed_df", "[", "'MaxBillAmountOverLast6Months'", "]", "=", "np", ".", "maximum", "(", "raw_df", "[", "bill_columns", "]", ".", "max", "(", "axis", "=", "1", ")", ",", "0", ")", "\n", "processed_df", "[", "'MaxPaymentAmountOverLast6Months'", "]", "=", "np", ".", "maximum", "(", "raw_df", "[", "pay_columns", "]", ".", "max", "(", "axis", "=", "1", ")", ",", "0", ")", "\n", "processed_df", "[", "'MonthsWithZeroBalanceOverLast6Months'", "]", "=", "np", ".", "sum", "(", "np", ".", "greater", "(", "raw_df", "[", "pay_columns", "]", ".", "values", ",", "raw_df", "[", "bill_columns", "]", ".", "values", ")", ",", "axis", "=", "1", ")", "\n", "processed_df", "[", "'MonthsWithLowSpendingOverLast6Months'", "]", "=", "np", ".", "sum", "(", "raw_df", "[", "bill_columns", "]", ".", "div", "(", "raw_df", "[", "'LIMIT_BAL'", "]", ",", "axis", "=", "0", ")", "<", "0.20", ",", "axis", "=", "1", ")", "\n", "processed_df", "[", "'MonthsWithHighSpendingOverLast6Months'", "]", "=", "np", ".", "sum", "(", "raw_df", "[", "bill_columns", "]", ".", "div", "(", "raw_df", "[", "'LIMIT_BAL'", "]", ",", "axis", "=", "0", ")", ">", "0.80", ",", "axis", "=", "1", ")", "\n", "processed_df", "[", "'MostRecentBillAmount'", "]", "=", "np", ".", "maximum", "(", "raw_df", "[", "bill_columns", "[", "0", "]", "]", ",", "0", ")", "\n", "processed_df", "[", "'MostRecentPaymentAmount'", "]", "=", "np", ".", "maximum", "(", "raw_df", "[", "pay_columns", "[", "0", "]", "]", ",", "0", ")", "\n", "\n", "# Credit History", "\n", "# PAY_M' = months since last payment (as recorded last month)", "\n", "# PAY_6 =  months since last payment (as recorded 6 months ago)", "\n", "# PAY_M = -1 if paid duly in month M", "\n", "# PAY_M = -2 if customer was issued refund M", "\n", "raw_df", "=", "raw_df", ".", "rename", "(", "columns", "=", "{", "'PAY_0'", ":", "'MonthsOverdue_1'", ",", "\n", "'PAY_2'", ":", "'MonthsOverdue_2'", ",", "\n", "'PAY_3'", ":", "'MonthsOverdue_3'", ",", "\n", "'PAY_4'", ":", "'MonthsOverdue_4'", ",", "\n", "'PAY_5'", ":", "'MonthsOverdue_5'", ",", "\n", "'PAY_6'", ":", "'MonthsOverdue_6'", "}", ")", "\n", "\n", "overdue", "=", "[", "'MonthsOverdue_%d'", "%", "j", "for", "j", "in", "range", "(", "1", ",", "7", ")", "]", "\n", "raw_df", "[", "overdue", "]", "=", "raw_df", "[", "overdue", "]", ".", "replace", "(", "to_replace", "=", "[", "-", "2", ",", "-", "1", "]", ",", "value", "=", "[", "0", ",", "0", "]", ")", "\n", "overdue_history", "=", "raw_df", "[", "overdue", "]", ".", "to_numpy", "(", ")", ">", "0", "\n", "payment_history", "=", "np", ".", "logical_not", "(", "overdue_history", ")", "\n", "\n", "def", "count_zero_streaks", "(", "a", ")", ":", "\n", "#adapted from zero_runs function of https://stackoverflow.com/a/24892274/568249", "\n", "      ", "iszero", "=", "np", ".", "concatenate", "(", "(", "[", "0", "]", ",", "np", ".", "equal", "(", "a", ",", "0", ")", ".", "view", "(", "np", ".", "int8", ")", ",", "[", "0", "]", ")", ")", "\n", "absdiff", "=", "np", ".", "abs", "(", "np", ".", "diff", "(", "iszero", ")", ")", "\n", "runs", "=", "np", ".", "where", "(", "absdiff", "==", "1", ")", "[", "0", "]", ".", "reshape", "(", "-", "1", ",", "2", ")", "\n", "n_streaks", "=", "runs", ".", "shape", "[", "0", "]", "\n", "#streak_lengths = np.sum(runs[:,1] - runs[:,0])", "\n", "return", "n_streaks", "\n", "\n", "\n", "", "overdue_counts", "=", "np", ".", "repeat", "(", "np", ".", "nan", ",", "len", "(", "raw_df", ")", ")", "\n", "n_overdue_months", "=", "np", ".", "sum", "(", "overdue_history", ">", "0", ",", "axis", "=", "1", ")", "\n", "overdue_counts", "[", "n_overdue_months", "==", "0", "]", "=", "0", "# count_zero_streaks doesn't work for edge cases", "\n", "overdue_counts", "[", "n_overdue_months", "==", "6", "]", "=", "1", "\n", "for", "k", "in", "range", "(", "1", ",", "len", "(", "overdue", ")", ")", ":", "\n", "      ", "idx", "=", "n_overdue_months", "==", "k", "\n", "overdue_counts", "[", "idx", "]", "=", "[", "count_zero_streaks", "(", "a", ")", "for", "a", "in", "payment_history", "[", "idx", ",", ":", "]", "]", "\n", "\n", "", "overdue_counts", "=", "overdue_counts", ".", "astype", "(", "np", ".", "int_", ")", "\n", "processed_df", "[", "'TotalOverdueCounts'", "]", "=", "overdue_counts", "\n", "processed_df", "[", "'TotalMonthsOverdue'", "]", "=", "raw_df", "[", "overdue", "]", ".", "sum", "(", "axis", "=", "1", ")", "\n", "processed_df", "[", "'HasHistoryOfOverduePayments'", "]", "=", "raw_df", "[", "overdue", "]", ".", "sum", "(", "axis", "=", "1", ")", ">", "0", "\n", "\n", "\n", "# Save to CSV", "\n", "processed_df", "=", "processed_df", "+", "0", "# convert boolean values to numeric", "\n", "processed_df", "=", "processed_df", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "processed_df", "=", "processed_df", ".", "dropna", "(", ")", "# drop all rows that include NAN (some exist in isMarried column, possibly elsewhere as well)", "\n", "processed_df", ".", "to_csv", "(", "processed_file", ",", "header", "=", "True", ",", "index", "=", "False", ")", "\n", "assert", "(", "processed_df", ".", "shape", "[", "0", "]", "==", "29623", ")", "\n", "\n", "return", "processed_df", ".", "astype", "(", "'float64'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.amirhk_mace._data_main.loadCausalConstraints.getGermanCausalConsistencyConstraints": [[11, 119], ["Ite", "Ite", "Ite", "Ite", "And", "Not", "EqualsOrIff", "EqualsOrIff", "Not", "EqualsOrIff", "EqualsOrIff", "Not", "EqualsOrIff", "EqualsOrIff", "Not", "EqualsOrIff", "EqualsOrIff", "EqualsOrIff", "ToReal", "ToReal", "ToReal", "ToReal", "EqualsOrIff", "ToReal", "ToReal", "ToReal", "ToReal", "EqualsOrIff", "ToReal", "ToReal", "ToReal", "Plus", "EqualsOrIff", "ToReal", "ToReal", "ToReal", "Plus", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal", "Times", "Times", "ToReal", "Times", "Minus", "Real", "Minus", "Real", "Minus", "Real", "ToReal", "ToReal", "float", "ToReal", "ToReal", "float", "ToReal", "ToReal", "float"], "function", ["None"], ["def", "getGermanCausalConsistencyConstraints", "(", "model_symbols", ",", "factual_sample", ")", ":", "\n", "# Gender (no parents)", "\n", "  ", "g", "=", "Ite", "(", "\n", "Not", "(", "# if YES intervened", "\n", "EqualsOrIff", "(", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x0'", "]", ")", ",", "\n", ")", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# set value of X^CF to the intervened value", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# else, set value of X^CF to (8) from paper", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x0'", "]", ")", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "# Age (no parents)", "\n", "a", "=", "Ite", "(", "\n", "Not", "(", "# if YES intervened", "\n", "EqualsOrIff", "(", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x1'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x1'", "]", ")", ",", "\n", ")", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# set value of X^CF to the intervened value", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x1'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x1'", "]", "[", "'symbol'", "]", ")", ",", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# else, set value of X^CF to (8) from paper", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x1'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x1'", "]", ")", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "# Credit (parents: age, sex)", "\n", "c", "=", "Ite", "(", "\n", "Not", "(", "# if YES intervened", "\n", "EqualsOrIff", "(", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x2'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x2'", "]", ")", ",", "\n", ")", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# set value of X^CF to the intervened value", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x2'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x2'", "]", "[", "'symbol'", "]", ")", ",", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# else, set value of X^CF to (8) from paper", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x2'", "]", "[", "'symbol'", "]", ")", ",", "\n", "Plus", "(", "[", "\n", "ToReal", "(", "factual_sample", "[", "'x2'", "]", ")", ",", "\n", "Times", "(", "\n", "Minus", "(", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x0'", "]", ")", ",", "\n", ")", ",", "\n", "# If you want to support numeric-int children, then you should round", "\n", "# these structural equation weights.", "\n", "# Real(float(552.43925387))", "\n", "Real", "(", "float", "(", "550", ")", ")", "\n", ")", ",", "\n", "Times", "(", "\n", "Minus", "(", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x1'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x1'", "]", ")", ",", "\n", ")", ",", "\n", "# If you want to support numeric-int children, then you should round", "\n", "# these structural equation weights.", "\n", "# Real(float(4.4847736))", "\n", "Real", "(", "float", "(", "4.5", ")", ")", "\n", ")", ",", "\n", "]", ")", "\n", ")", ",", "\n", ")", "\n", "\n", "# Repayment duration (parents: credit)", "\n", "r", "=", "Ite", "(", "\n", "Not", "(", "# if YES intervened", "\n", "EqualsOrIff", "(", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x3'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x3'", "]", ")", ",", "\n", ")", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# set value of X^CF to the intervened value", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x3'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x3'", "]", "[", "'symbol'", "]", ")", ",", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# else, set value of X^CF to (8) from paper", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x3'", "]", "[", "'symbol'", "]", ")", ",", "\n", "Plus", "(", "[", "\n", "ToReal", "(", "factual_sample", "[", "'x3'", "]", ")", ",", "\n", "Times", "(", "\n", "Minus", "(", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x2'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x2'", "]", ")", ",", "\n", ")", ",", "\n", "# If you want to support numeric-int children, then you should round", "\n", "# these structural equation weights.", "\n", "# Real(float(0.00266995))", "\n", "Real", "(", "float", "(", "0.0025", ")", ")", "\n", ")", ",", "\n", "]", ")", "\n", ")", ",", "\n", ")", "\n", "\n", "return", "And", "(", "[", "g", ",", "a", ",", "c", ",", "r", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace._data_main.loadCausalConstraints.getRandomCausalConsistencyConstraints": [[122, 208], ["Ite", "Ite", "Ite", "And", "Not", "EqualsOrIff", "EqualsOrIff", "Not", "EqualsOrIff", "EqualsOrIff", "Not", "EqualsOrIff", "EqualsOrIff", "EqualsOrIff", "ToReal", "ToReal", "ToReal", "ToReal", "EqualsOrIff", "ToReal", "ToReal", "ToReal", "Plus", "EqualsOrIff", "ToReal", "ToReal", "ToReal", "Plus", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal", "Times", "ToReal", "ToReal", "Minus", "Real", "ToReal", "Times", "ToReal", "ToReal", "Minus", "Real", "Times", "Times", "float", "ToReal", "Pow", "ToReal", "Pow", "numpy.sqrt", "ToReal", "Real", "ToReal", "Real"], "function", ["None"], ["", "def", "getRandomCausalConsistencyConstraints", "(", "model_symbols", ",", "factual_sample", ")", ":", "\n", "# x0 (root node; no parents)", "\n", "  ", "x0", "=", "Ite", "(", "\n", "Not", "(", "# if YES intervened", "\n", "EqualsOrIff", "(", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x0'", "]", ")", ",", "\n", ")", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# set value of X^CF to the intervened value", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# else, set value of X^CF to (8) from paper", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x0'", "]", ")", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "# x1 (parents = {x0})", "\n", "x1", "=", "Ite", "(", "\n", "Not", "(", "# if YES intervened", "\n", "EqualsOrIff", "(", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x1'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x1'", "]", ")", ",", "\n", ")", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# set value of X^CF to the intervened value", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x1'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x1'", "]", "[", "'symbol'", "]", ")", ",", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# else, set value of X^CF to (8) from paper", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x1'", "]", "[", "'symbol'", "]", ")", ",", "\n", "Plus", "(", "\n", "ToReal", "(", "factual_sample", "[", "'x1'", "]", ")", ",", "\n", "Times", "(", "\n", "Minus", "(", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x0'", "]", ")", ",", "\n", ")", ",", "\n", "Real", "(", "1", ")", "\n", ")", "\n", ")", "\n", ")", ",", "\n", ")", "\n", "\n", "# x2 (parents = {x0, x1})", "\n", "x2", "=", "Ite", "(", "\n", "Not", "(", "# if YES intervened", "\n", "EqualsOrIff", "(", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x2'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x2'", "]", ")", ",", "\n", ")", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# set value of X^CF to the intervened value", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x2'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x2'", "]", "[", "'symbol'", "]", ")", ",", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# else, set value of X^CF to (8) from paper", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x2'", "]", "[", "'symbol'", "]", ")", ",", "\n", "Plus", "(", "[", "\n", "ToReal", "(", "factual_sample", "[", "'x2'", "]", ")", ",", "\n", "Times", "(", "\n", "Minus", "(", "\n", "Times", "(", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", "Pow", "(", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x1'", "]", "[", "'symbol'", "]", ")", ",", "\n", "Real", "(", "2", ")", "\n", ")", ",", "\n", ")", ",", "\n", "Times", "(", "\n", "ToReal", "(", "factual_sample", "[", "'x0'", "]", ")", ",", "\n", "Pow", "(", "\n", "ToReal", "(", "factual_sample", "[", "'x1'", "]", ")", ",", "\n", "Real", "(", "2", ")", "\n", ")", ",", "\n", ")", ",", "\n", ")", ",", "\n", "Real", "(", "float", "(", "np", ".", "sqrt", "(", "3", ")", ")", ")", "\n", ")", ",", "\n", "]", ")", "\n", ")", ",", "\n", ")", "\n", "\n", "return", "And", "(", "[", "x0", ",", "x1", ",", "x2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace._data_main.loadCausalConstraints.getMortgageCausalConsistencyConstraints": [[298, 343], ["Ite", "Ite", "And", "Not", "EqualsOrIff", "EqualsOrIff", "Not", "EqualsOrIff", "EqualsOrIff", "EqualsOrIff", "ToReal", "ToReal", "ToReal", "ToReal", "EqualsOrIff", "ToReal", "ToReal", "ToReal", "Plus", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal", "Times", "Minus", "Real", "ToReal", "ToReal"], "function", ["None"], ["", "def", "getMortgageCausalConsistencyConstraints", "(", "model_symbols", ",", "factual_sample", ")", ":", "\n", "  ", "a", "=", "Ite", "(", "\n", "Not", "(", "# if YES intervened", "\n", "EqualsOrIff", "(", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x0'", "]", ")", ",", "\n", ")", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# set value of X^CF to the intervened value", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# else, set value of X^CF to (8) from paper", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x0'", "]", ")", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "b", "=", "Ite", "(", "\n", "Not", "(", "# if YES intervened", "\n", "EqualsOrIff", "(", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x1'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x1'", "]", ")", ",", "\n", ")", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# set value of X^CF to the intervened value", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x1'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x1'", "]", "[", "'symbol'", "]", ")", ",", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# else, set value of X^CF to (8) from paper", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x1'", "]", "[", "'symbol'", "]", ")", ",", "\n", "Plus", "(", "\n", "ToReal", "(", "factual_sample", "[", "'x1'", "]", ")", ",", "\n", "Times", "(", "\n", "Minus", "(", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x0'", "]", ")", ",", "\n", ")", ",", "\n", "Real", "(", "0.3", ")", "\n", ")", ",", "\n", ")", "\n", ")", ",", "\n", ")", "\n", "\n", "return", "And", "(", "[", "a", ",", "b", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace._data_main.loadCausalConstraints.getTwoMoonCausalConsistencyConstraints": [[345, 381], ["Ite", "Ite", "And", "Not", "EqualsOrIff", "EqualsOrIff", "Not", "EqualsOrIff", "EqualsOrIff", "EqualsOrIff", "ToReal", "ToReal", "ToReal", "ToReal", "EqualsOrIff", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal"], "function", ["None"], ["", "def", "getTwoMoonCausalConsistencyConstraints", "(", "model_symbols", ",", "factual_sample", ")", ":", "\n", "  ", "a", "=", "Ite", "(", "\n", "Not", "(", "# if YES intervened", "\n", "EqualsOrIff", "(", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x0'", "]", ")", ",", "\n", ")", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# set value of X^CF to the intervened value", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# else, set value of X^CF to (8) from paper", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x0'", "]", ")", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "b", "=", "Ite", "(", "\n", "Not", "(", "# if YES intervened", "\n", "EqualsOrIff", "(", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x1'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x1'", "]", ")", ",", "\n", ")", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# set value of X^CF to the intervened value", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x1'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x1'", "]", "[", "'symbol'", "]", ")", ",", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# else, set value of X^CF to (8) from paper", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x1'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x1'", "]", ")", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "return", "And", "(", "[", "a", ",", "b", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace._data_main.loadCausalConstraints.getTestCausalConsistencyConstraints": [[383, 453], ["Ite", "Ite", "Ite", "Ite", "And", "Not", "EqualsOrIff", "EqualsOrIff", "Not", "EqualsOrIff", "EqualsOrIff", "Not", "EqualsOrIff", "EqualsOrIff", "Not", "EqualsOrIff", "EqualsOrIff", "EqualsOrIff", "ToReal", "ToReal", "ToReal", "ToReal", "EqualsOrIff", "ToReal", "ToReal", "ToReal", "ToReal", "EqualsOrIff", "ToReal", "ToReal", "ToReal", "ToReal", "EqualsOrIff", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal", "ToReal"], "function", ["None"], ["", "def", "getTestCausalConsistencyConstraints", "(", "model_symbols", ",", "factual_sample", ")", ":", "\n", "  ", "a", "=", "Ite", "(", "\n", "Not", "(", "# if YES intervened", "\n", "EqualsOrIff", "(", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x0_ord_0'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x0_ord_0'", "]", ")", ",", "\n", ")", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# set value of X^CF to the intervened value", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0_ord_0'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x0_ord_0'", "]", "[", "'symbol'", "]", ")", ",", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# else, set value of X^CF to (8) from paper", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0_ord_0'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x0_ord_0'", "]", ")", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "b", "=", "Ite", "(", "\n", "Not", "(", "# if YES intervened", "\n", "EqualsOrIff", "(", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x0_ord_1'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x0_ord_1'", "]", ")", ",", "\n", ")", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# set value of X^CF to the intervened value", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0_ord_1'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x0_ord_1'", "]", "[", "'symbol'", "]", ")", ",", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# else, set value of X^CF to (8) from paper", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0_ord_1'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x0_ord_1'", "]", ")", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "c", "=", "Ite", "(", "\n", "Not", "(", "# if YES intervened", "\n", "EqualsOrIff", "(", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x0_ord_2'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x0_ord_2'", "]", ")", ",", "\n", ")", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# set value of X^CF to the intervened value", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0_ord_2'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x0_ord_2'", "]", "[", "'symbol'", "]", ")", ",", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# else, set value of X^CF to (8) from paper", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0_ord_2'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x0_ord_2'", "]", ")", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "d", "=", "Ite", "(", "\n", "Not", "(", "# if YES intervened", "\n", "EqualsOrIff", "(", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x0_ord_3'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x0_ord_3'", "]", ")", ",", "\n", ")", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# set value of X^CF to the intervened value", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0_ord_3'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "model_symbols", "[", "'interventional'", "]", "[", "'x0_ord_3'", "]", "[", "'symbol'", "]", ")", ",", "\n", ")", ",", "\n", "EqualsOrIff", "(", "# else, set value of X^CF to (8) from paper", "\n", "ToReal", "(", "model_symbols", "[", "'counterfactual'", "]", "[", "'x0_ord_3'", "]", "[", "'symbol'", "]", ")", ",", "\n", "ToReal", "(", "factual_sample", "[", "'x0_ord_3'", "]", ")", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "return", "And", "(", "[", "a", ",", "b", ",", "c", ",", "d", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.amirhk_mace._data_main.process_german_data.load_german_data": [[12, 54], ["os.path.join", "os.path.join", "pandas.read_csv", "pandas.DataFrame", "processed_df.dropna.reset_index", "processed_df.dropna.dropna", "processed_df.dropna.to_csv", "processed_df.dropna.astype", "os.path.dirname", "os.path.dirname"], "function", ["None"], ["def", "load_german_data", "(", ")", ":", "\n", "\n", "# input vars", "\n", "  ", "data_name", "=", "'german'", "\n", "raw_data_file", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "'german_raw.csv'", ")", "\n", "processed_file", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "'german_processed.csv'", ")", "\n", "\n", "##### German Data Processing", "\n", "raw_df", "=", "pd", ".", "read_csv", "(", "raw_data_file", ")", "# , index_col = 0)", "\n", "processed_df", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n", "processed_df", "[", "'GoodCustomer (label)'", "]", "=", "raw_df", "[", "'GoodCustomer'", "]", "\n", "processed_df", "[", "'GoodCustomer (label)'", "]", "=", "(", "processed_df", "[", "'GoodCustomer (label)'", "]", "+", "1", ")", "/", "2", "\n", "processed_df", ".", "loc", "[", "raw_df", "[", "'Gender'", "]", "==", "'Male'", ",", "'Sex'", "]", "=", "1", "\n", "processed_df", ".", "loc", "[", "raw_df", "[", "'Gender'", "]", "==", "'Female'", ",", "'Sex'", "]", "=", "0", "\n", "processed_df", "[", "'Age'", "]", "=", "raw_df", "[", "'Age'", "]", "\n", "processed_df", "[", "'Credit'", "]", "=", "raw_df", "[", "'Credit'", "]", "\n", "processed_df", "[", "'LoanDuration'", "]", "=", "raw_df", "[", "'LoanDuration'", "]", "\n", "\n", "# # order important, more balance can overwrite less balance!", "\n", "# processed_df.loc[raw_df['CheckingAccountBalance_geq_0'] == 1, 'CheckingAccountBalance'] = 2", "\n", "# processed_df.loc[raw_df['CheckingAccountBalance_geq_200'] == 1, 'CheckingAccountBalance'] = 3", "\n", "# processed_df = processed_df.fillna(1) # all other categories...", "\n", "\n", "# # order important, more balance can overwrite less balance!", "\n", "# processed_df.loc[raw_df['SavingsAccountBalance_geq_100'] == 1, 'SavingsAccountBalance'] = 2", "\n", "# processed_df.loc[raw_df['SavingsAccountBalance_geq_500'] == 1, 'SavingsAccountBalance'] = 3", "\n", "# processed_df = processed_df.fillna(1) # all other categories...", "\n", "\n", "# # 2: owns house, 1: rents house, 0: neither", "\n", "# processed_df.loc[raw_df['OwnsHouse'] == 1, 'HousingStatus'] = 3", "\n", "# processed_df.loc[raw_df['RentsHouse'] == 1, 'HousingStatus'] = 2", "\n", "# processed_df = processed_df.fillna(1) # all other categories...", "\n", "\n", "# Save to CSV", "\n", "processed_df", "=", "processed_df", "+", "0", "# convert boolean values to numeric", "\n", "processed_df", "=", "processed_df", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "processed_df", "=", "processed_df", ".", "dropna", "(", ")", "# drop all rows that include NAN (some exist in isMarried column, possibly elsewhere as well)", "\n", "processed_df", ".", "to_csv", "(", "processed_file", ",", "header", "=", "True", ",", "index", "=", "False", ")", "\n", "assert", "(", "processed_df", ".", "shape", "[", "0", "]", "==", "1000", ")", "\n", "\n", "return", "processed_df", ".", "astype", "(", "'float64'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace._data_main.fair_compas_data.check_data_file": [[22, 41], ["os.path.dirname", "os.listdir", "print", "os.path.realpath", "os.path.join", "print", "urllib.request.urlopen", "urllib.request.urlopen.read", "open", "open.write", "open.close", "print", "print"], "function", ["None"], ["def", "check_data_file", "(", "file_name", ")", ":", "\n", "\n", "    ", "this_files_directory", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", "\n", "files", "=", "os", ".", "listdir", "(", "this_files_directory", ")", "# get the current directory listing", "\n", "\n", "print", "(", "f'Looking for file {file_name} in the {this_files_directory} directory..'", ")", "\n", "\n", "if", "file_name", "not", "in", "files", ":", "\n", "        ", "full_file_name", "=", "os", ".", "path", ".", "join", "(", "this_files_directory", ",", "file_name", ")", "\n", "print", "(", "\"'%s' not found! Downloading from GitHub...\"", "%", "file_name", ")", "\n", "addr", "=", "\"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"", "\n", "response", "=", "urllib", ".", "request", ".", "urlopen", "(", "addr", ")", "\n", "data", "=", "response", ".", "read", "(", ")", "\n", "fileOut", "=", "open", "(", "full_file_name", ",", "\"wb\"", ")", "\n", "fileOut", ".", "write", "(", "data", ")", "\n", "fileOut", ".", "close", "(", ")", "\n", "print", "(", "\"'%s' download and saved locally..\"", "%", "full_file_name", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"File found in current directory..\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace._data_main.fair_compas_data.load_compas_data": [[43, 152], ["fair_compas_data.check_data_file", "pandas.read_csv", "df.dropna.dropna", "df.dropna.to_dict", "df.to_dict.keys", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "df.to_dict.keys", "print", "print", "print", "numpy.array().reshape", "collections.defaultdict", "dict", "dict.keys", "list", "random.shuffle", "dict.keys", "fair_utils_data.add_intercept", "print", "numpy.array", "numpy.logical_or", "pandas.Series().value_counts", "len", "numpy.hstack", "numpy.array().flatten", "range", "len", "numpy.array", "sklearn.preprocessing.scale", "numpy.reshape", "sklearn.preprocessing.LabelBinarizer", "preprocessing.LabelBinarizer.fit", "preprocessing.LabelBinarizer.transform", "feature_names.append", "pandas.Series", "float", "feature_names.append", "numpy.array", "len", "feature_names.append", "str"], "function", ["home.repos.pwc.inspect_result.amirhk_mace._data_main.fair_adult_data.check_data_file", "home.repos.pwc.inspect_result.amirhk_mace._data_main.fair_utils_data.add_intercept"], ["", "", "def", "load_compas_data", "(", ")", ":", "\n", "\n", "  ", "FEATURES_CLASSIFICATION", "=", "[", "\"age_cat\"", ",", "\"race\"", ",", "\"sex\"", ",", "\"priors_count\"", ",", "\"c_charge_degree\"", "]", "# features to be used for classification", "\n", "CONT_VARIABLES", "=", "[", "\"priors_count\"", "]", "# continuous features, will need to be handled separately from categorical features, categorical features will be encoded using one-hot", "\n", "CLASS_FEATURE", "=", "\"two_year_recid\"", "# the decision variable", "\n", "SENSITIVE_ATTRS", "=", "[", "\"race\"", "]", "\n", "\n", "COMPAS_INPUT_FILE", "=", "\"compas-scores-two-years.csv\"", "\n", "check_data_file", "(", "COMPAS_INPUT_FILE", ")", "\n", "\n", "# load the data and get some stats", "\n", "df", "=", "pd", ".", "read_csv", "(", "COMPAS_INPUT_FILE", ")", "\n", "df", "=", "df", ".", "dropna", "(", "subset", "=", "[", "\"days_b_screening_arrest\"", "]", ")", "# dropping missing vals", "\n", "\n", "# convert to np array", "\n", "data", "=", "df", ".", "to_dict", "(", "'list'", ")", "\n", "for", "k", "in", "data", ".", "keys", "(", ")", ":", "\n", "    ", "data", "[", "k", "]", "=", "np", ".", "array", "(", "data", "[", "k", "]", ")", "\n", "\n", "\n", "", "\"\"\" Filtering the data \"\"\"", "\n", "\n", "# These filters are the same as propublica (refer to https://github.com/propublica/compas-analysis)", "\n", "# If the charge date of a defendants Compas scored crime was not within 30 days from when the person was arrested, we assume that because of data quality reasons, that we do not have the right offense.", "\n", "idx", "=", "np", ".", "logical_and", "(", "data", "[", "\"days_b_screening_arrest\"", "]", "<=", "30", ",", "data", "[", "\"days_b_screening_arrest\"", "]", ">=", "-", "30", ")", "\n", "\n", "# We coded the recidivist flag -- is_recid -- to be -1 if we could not find a compas case at all.", "\n", "idx", "=", "np", ".", "logical_and", "(", "idx", ",", "data", "[", "\"is_recid\"", "]", "!=", "-", "1", ")", "\n", "\n", "# In a similar vein, ordinary traffic offenses -- those with a c_charge_degree of 'O' -- will not result in Jail time are removed (only two of them).", "\n", "idx", "=", "np", ".", "logical_and", "(", "idx", ",", "data", "[", "\"c_charge_degree\"", "]", "!=", "\"O\"", ")", "# F: felony, M: misconduct", "\n", "\n", "# We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility.", "\n", "idx", "=", "np", ".", "logical_and", "(", "idx", ",", "data", "[", "\"score_text\"", "]", "!=", "\"NA\"", ")", "\n", "\n", "# we will only consider blacks and whites for this analysis", "\n", "idx", "=", "np", ".", "logical_and", "(", "idx", ",", "np", ".", "logical_or", "(", "data", "[", "\"race\"", "]", "==", "\"African-American\"", ",", "data", "[", "\"race\"", "]", "==", "\"Caucasian\"", ")", ")", "\n", "\n", "# select the examples that satisfy this criteria", "\n", "for", "k", "in", "data", ".", "keys", "(", ")", ":", "\n", "    ", "data", "[", "k", "]", "=", "data", "[", "k", "]", "[", "idx", "]", "\n", "\n", "\n", "", "\"\"\" Feature normalization and one hot encoding \"\"\"", "\n", "\n", "# convert class label 0 to -1", "\n", "y", "=", "data", "[", "CLASS_FEATURE", "]", "\n", "y", "[", "y", "==", "0", "]", "=", "-", "1", "\n", "\n", "print", "(", "\"\\nNumber of people recidivating within two years\"", ")", "\n", "print", "(", "pd", ".", "Series", "(", "y", ")", ".", "value_counts", "(", ")", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "\n", "X", "=", "np", ".", "array", "(", "[", "]", ")", ".", "reshape", "(", "len", "(", "y", ")", ",", "0", ")", "# empty array with num rows same as num examples, will hstack the features to it", "\n", "x_control", "=", "defaultdict", "(", "list", ")", "\n", "\n", "feature_names", "=", "[", "]", "\n", "for", "attr", "in", "FEATURES_CLASSIFICATION", ":", "\n", "    ", "vals", "=", "data", "[", "attr", "]", "\n", "if", "attr", "in", "CONT_VARIABLES", ":", "\n", "      ", "vals", "=", "[", "float", "(", "v", ")", "for", "v", "in", "vals", "]", "\n", "vals", "=", "preprocessing", ".", "scale", "(", "vals", ")", "# 0 mean and 1 variance", "\n", "vals", "=", "np", ".", "reshape", "(", "vals", ",", "(", "len", "(", "y", ")", ",", "-", "1", ")", ")", "# convert from 1-d arr to a 2-d arr with one col", "\n", "\n", "", "else", ":", "# for binary categorical variables, the label binarizer uses just one var instead of two", "\n", "      ", "lb", "=", "preprocessing", ".", "LabelBinarizer", "(", ")", "\n", "lb", ".", "fit", "(", "vals", ")", "\n", "vals", "=", "lb", ".", "transform", "(", "vals", ")", "\n", "\n", "# add to sensitive features dict", "\n", "", "if", "attr", "in", "SENSITIVE_ATTRS", ":", "\n", "      ", "x_control", "[", "attr", "]", "=", "vals", "\n", "\n", "# add to learnable features", "\n", "", "X", "=", "np", ".", "hstack", "(", "(", "X", ",", "vals", ")", ")", "\n", "\n", "if", "attr", "in", "CONT_VARIABLES", ":", "# continuous feature, just append the name", "\n", "      ", "feature_names", ".", "append", "(", "attr", ")", "\n", "", "else", ":", "# categorical features", "\n", "      ", "if", "vals", ".", "shape", "[", "1", "]", "==", "1", ":", "# binary features that passed through lib binarizer", "\n", "        ", "feature_names", ".", "append", "(", "attr", ")", "\n", "", "else", ":", "\n", "        ", "for", "k", "in", "lb", ".", "classes_", ":", "# non-binary categorical features, need to add the names for each cat", "\n", "          ", "feature_names", ".", "append", "(", "attr", "+", "\"_\"", "+", "str", "(", "k", ")", ")", "\n", "\n", "# convert the sensitive feature to 1-d array", "\n", "", "", "", "", "x_control", "=", "dict", "(", "x_control", ")", "\n", "for", "k", "in", "x_control", ".", "keys", "(", ")", ":", "\n", "    ", "assert", "(", "x_control", "[", "k", "]", ".", "shape", "[", "1", "]", "==", "1", ")", "# make sure that the sensitive feature is binary after one hot encoding", "\n", "x_control", "[", "k", "]", "=", "np", ".", "array", "(", "x_control", "[", "k", "]", ")", ".", "flatten", "(", ")", "\n", "\n", "# sys.exit(1)", "\n", "\n", "\n", "", "\"\"\"permute the date randomly\"\"\"", "\n", "perm", "=", "list", "(", "range", "(", "0", ",", "X", ".", "shape", "[", "0", "]", ")", ")", "\n", "shuffle", "(", "perm", ")", "\n", "X", "=", "X", "[", "perm", "]", "\n", "y", "=", "y", "[", "perm", "]", "\n", "for", "k", "in", "x_control", ".", "keys", "(", ")", ":", "\n", "    ", "x_control", "[", "k", "]", "=", "x_control", "[", "k", "]", "[", "perm", "]", "\n", "\n", "", "X", "=", "ut", ".", "add_intercept", "(", "X", ")", "\n", "\n", "feature_names", "=", "[", "\"intercept\"", "]", "+", "feature_names", "\n", "assert", "(", "len", "(", "feature_names", ")", "==", "X", ".", "shape", "[", "1", "]", ")", "\n", "print", "(", "\"Features we will be using for classification are:\"", ",", "feature_names", ",", "\"\\n\"", ")", "\n", "\n", "return", "X", ",", "y", ",", "x_control", ",", "feature_names", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace._data_main.fair_compas_data.load_compas_data_new": [[155, 212], ["os.path.dirname", "os.path.join", "fair_compas_data.check_data_file", "pandas.read_csv", "pd.concat.dropna", "pandas.concat", "pandas.DataFrame", "pd.DataFrame.astype", "os.path.realpath"], "function", ["home.repos.pwc.inspect_result.amirhk_mace._data_main.fair_adult_data.check_data_file"], ["", "def", "load_compas_data_new", "(", ")", ":", "\n", "\n", "    ", "FEATURES_CLASSIFICATION", "=", "[", "\"age_cat\"", ",", "\"race\"", ",", "\"sex\"", ",", "\"priors_count\"", ",", "\"c_charge_degree\"", "]", "# features to be used for classification", "\n", "CONT_VARIABLES", "=", "[", "\"priors_count\"", "]", "# continuous features, will need to be handled separately from categorical features, categorical features will be encoded using one-hot", "\n", "CLASS_FEATURE", "=", "\"two_year_recid\"", "# the decision variable", "\n", "SENSITIVE_ATTRS", "=", "[", "\"race\"", "]", "\n", "\n", "file_name", "=", "\"compas-scores-two-years.csv\"", "\n", "this_files_directory", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", "\n", "full_file_name", "=", "os", ".", "path", ".", "join", "(", "this_files_directory", ",", "file_name", ")", "\n", "check_data_file", "(", "file_name", ")", "\n", "\n", "# load the data and get some stats", "\n", "df", "=", "pd", ".", "read_csv", "(", "full_file_name", ")", "\n", "df", "=", "df", ".", "dropna", "(", "subset", "=", "[", "\"days_b_screening_arrest\"", "]", ")", "# dropping missing vals", "\n", "\n", "# \"\"\" Filtering the data \"\"\"", "\n", "\n", "# These filters are the same as propublica (refer to https://github.com/propublica/compas-analysis)", "\n", "# If the charge date of a defendants Compas scored crime was not within 30 days from when the person was arrested, we assume that because of data quality reasons, that we do not have the right offense.", "\n", "# We coded the recidivist flag -- is_recid -- to be -1 if we could not find a compas case at all.", "\n", "# In a similar vein, ordinary traffic offenses -- those with a c_charge_degree of 'O' -- will not result in Jail time are removed (only two of them).", "\n", "# We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility.", "\n", "# we will only consider blacks and whites for this analysis", "\n", "tmp", "=", "(", "(", "df", "[", "\"days_b_screening_arrest\"", "]", "<=", "30", ")", "&", "(", "df", "[", "\"days_b_screening_arrest\"", "]", ">=", "-", "30", ")", ")", "&", "(", "df", "[", "\"is_recid\"", "]", "!=", "-", "1", ")", "&", "(", "df", "[", "\"c_charge_degree\"", "]", "!=", "\"O\"", ")", "&", "(", "df", "[", "\"score_text\"", "]", "!=", "\"NA\"", ")", "&", "(", "(", "df", "[", "\"race\"", "]", "==", "\"African-American\"", ")", "|", "(", "df", "[", "\"race\"", "]", "==", "\"Caucasian\"", ")", ")", "\n", "\n", "df", "=", "df", "[", "tmp", "==", "True", "]", "\n", "df", "=", "pd", ".", "concat", "(", "[", "\n", "df", "[", "FEATURES_CLASSIFICATION", "]", ",", "\n", "df", "[", "CLASS_FEATURE", "]", ",", "\n", "]", ",", "axis", "=", "1", ")", "\n", "\n", "processed_df", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n", "processed_df", "[", "'TwoYearRecid (label)'", "]", "=", "df", "[", "'two_year_recid'", "]", "\n", "\n", "processed_df", ".", "loc", "[", "df", "[", "'age_cat'", "]", "==", "'Less than 25'", ",", "'AgeGroup'", "]", "=", "1", "\n", "processed_df", ".", "loc", "[", "df", "[", "'age_cat'", "]", "==", "'25 - 45'", ",", "'AgeGroup'", "]", "=", "2", "\n", "processed_df", ".", "loc", "[", "df", "[", "'age_cat'", "]", "==", "'Greater than 45'", ",", "'AgeGroup'", "]", "=", "3", "\n", "\n", "processed_df", ".", "loc", "[", "df", "[", "'race'", "]", "==", "'African-American'", ",", "'Race'", "]", "=", "1", "\n", "processed_df", ".", "loc", "[", "df", "[", "'race'", "]", "==", "'Caucasian'", ",", "'Race'", "]", "=", "2", "\n", "\n", "processed_df", ".", "loc", "[", "df", "[", "'sex'", "]", "==", "'Male'", ",", "'Sex'", "]", "=", "1", "\n", "processed_df", ".", "loc", "[", "df", "[", "'sex'", "]", "==", "'Female'", ",", "'Sex'", "]", "=", "2", "\n", "\n", "processed_df", "[", "'PriorsCount'", "]", "=", "df", "[", "'priors_count'", "]", "\n", "\n", "processed_df", ".", "loc", "[", "df", "[", "'c_charge_degree'", "]", "==", "'M'", ",", "'ChargeDegree'", "]", "=", "1", "\n", "processed_df", ".", "loc", "[", "df", "[", "'c_charge_degree'", "]", "==", "'F'", ",", "'ChargeDegree'", "]", "=", "2", "\n", "\n", "return", "processed_df", ".", "astype", "(", "'float64'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.amirhk_mace._data_main.process_test_data.load_test_data": [[15, 40], ["numpy.random.randint", "numpy.array", "X.reshape.reshape", "y.reshape.reshape", "pandas.DataFrame", "pd.DataFrame.astype", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate"], "function", ["None"], ["def", "load_test_data", "(", "variable_type", "=", "'real'", ")", ":", "\n", "\n", "  ", "X", "=", "np", ".", "random", ".", "randint", "(", "1", ",", "5", ",", "n_samples", ")", "\n", "y", "=", "np", ".", "array", "(", "[", "1", "if", "x", "%", "2", "else", "0", "for", "x", "in", "X", "]", ")", "# y = 1 for even values, y = 0 for odd values", "\n", "\n", "# make 2D", "\n", "X", "=", "X", ".", "reshape", "(", "X", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "y", "=", "y", ".", "reshape", "(", "y", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "X_train", "=", "X", "[", ":", "n_samples", "//", "2", "]", "\n", "X_test", "=", "X", "[", "n_samples", "//", "2", ":", "]", "\n", "y_train", "=", "y", "[", ":", "n_samples", "//", "2", "]", "\n", "y_test", "=", "y", "[", "n_samples", "//", "2", ":", "]", "\n", "\n", "\n", "data_frame_non_hot", "=", "pd", ".", "DataFrame", "(", "\n", "np", ".", "concatenate", "(", "(", "\n", "np", ".", "concatenate", "(", "(", "y_train", ",", "X_train", ")", ",", "axis", "=", "1", ")", ",", "# importantly, labels have to go first, else Dataset.__init__ messes up kurz column names", "\n", "np", ".", "concatenate", "(", "(", "y_test", ",", "X_test", ")", ",", "axis", "=", "1", ")", ",", "# importantly, labels have to go first, else Dataset.__init__ messes up kurz column names", "\n", ")", ",", "\n", "axis", "=", "0", ",", "\n", ")", ",", "\n", "columns", "=", "[", "'label'", ",", "'x0'", "]", "\n", ")", "\n", "return", "data_frame_non_hot", ".", "astype", "(", "'float64'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace._data_main.fair_adult_data.check_data_file": [[17, 38], ["os.path.dirname", "os.listdir", "print", "print", "os.path.realpath", "os.path.join", "print", "urllib.request.urlopen", "urllib.request.urlopen.read", "open", "open.write", "open.close", "print", "print"], "function", ["None"], ["def", "check_data_file", "(", "file_name", ")", ":", "\n", "    ", "this_files_directory", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", "\n", "files_in_directory", "=", "os", ".", "listdir", "(", "this_files_directory", ")", "# get the current directory listing", "\n", "\n", "print", "(", "f'Looking for file {file_name} in the {this_files_directory} directory..'", ")", "\n", "\n", "if", "file_name", "not", "in", "files_in_directory", ":", "\n", "        ", "full_file_name", "=", "os", ".", "path", ".", "join", "(", "this_files_directory", ",", "file_name", ")", "\n", "print", "(", "\"'%s' not found! Downloading from UCI Archive...\"", "%", "file_name", ")", "\n", "addr", "=", "\"http://archive.ics.uci.edu/ml/machine-learning-databases/adult/%s\"", "%", "file_name", "\n", "response", "=", "urllib", ".", "request", ".", "urlopen", "(", "addr", ")", "\n", "data", "=", "response", ".", "read", "(", ")", "\n", "fileOut", "=", "open", "(", "full_file_name", ",", "\"wb\"", ")", "\n", "fileOut", ".", "write", "(", "data", ")", "\n", "fileOut", ".", "close", "(", ")", "\n", "print", "(", "\"'%s' download and saved locally..\"", "%", "full_file_name", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"File found in current directory..\"", ")", "\n", "\n", "", "print", "(", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace._data_main.fair_adult_data.load_adult_data": [[40, 168], ["fair_adult_data.load_adult_data.convert_attrs_to_ints"], "function", ["None"], ["", "def", "load_adult_data", "(", "load_data_size", "=", "None", ")", ":", "\n", "\n", "    ", "\"\"\"\n        if load_data_size is set to None (or if no argument is provided), then we load and return the whole data\n        if it is a number, say 10000, then we will return randomly selected 10K examples\n    \"\"\"", "\n", "\n", "attrs", "=", "[", "'age'", ",", "'workclass'", ",", "'fnlwgt'", ",", "'education'", ",", "'education_num'", ",", "'marital_status'", ",", "'occupation'", ",", "'relationship'", ",", "'race'", ",", "'sex'", ",", "'capital_gain'", ",", "'capital_loss'", ",", "'hours_per_week'", ",", "'native_country'", "]", "# all attributes", "\n", "int_attrs", "=", "[", "'age'", ",", "'fnlwgt'", ",", "'education_num'", ",", "'capital_gain'", ",", "'capital_loss'", ",", "'hours_per_week'", "]", "# attributes with integer values -- the rest are categorical", "\n", "sensitive_attrs", "=", "[", "'sex'", "]", "# the fairness constraints will be used for this feature", "\n", "attrs_to_ignore", "=", "[", "'sex'", ",", "'race'", ",", "'fnlwgt'", "]", "# sex and race are sensitive feature so we will not use them in classification, we will not consider fnlwght for classification since its computed externally and it highly predictive for the class (for details, see documentation of the adult data)", "\n", "attrs_for_classification", "=", "set", "(", "attrs", ")", "-", "set", "(", "attrs_to_ignore", ")", "\n", "\n", "# adult data comes in two different files, one for training and one for testing, however, we will combine data from both the files", "\n", "data_files", "=", "[", "\"adult.data\"", ",", "\"adult.test\"", "]", "\n", "\n", "\n", "X", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "x_control", "=", "{", "}", "\n", "\n", "attrs_to_vals", "=", "{", "}", "# will store the values for each attribute for all users", "\n", "for", "k", "in", "attrs", ":", "\n", "        ", "if", "k", "in", "sensitive_attrs", ":", "\n", "            ", "x_control", "[", "k", "]", "=", "[", "]", "\n", "", "elif", "k", "in", "attrs_to_ignore", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "attrs_to_vals", "[", "k", "]", "=", "[", "]", "\n", "\n", "", "", "for", "f", "in", "data_files", ":", "\n", "        ", "check_data_file", "(", "f", ")", "\n", "\n", "for", "line", "in", "open", "(", "f", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "==", "\"\"", ":", "continue", "# skip empty lines", "\n", "line", "=", "line", ".", "split", "(", "\", \"", ")", "\n", "if", "len", "(", "line", ")", "!=", "15", "or", "\"?\"", "in", "line", ":", "# if a line has missing attributes, ignore it", "\n", "                ", "continue", "\n", "\n", "", "class_label", "=", "line", "[", "-", "1", "]", "\n", "if", "class_label", "in", "[", "\"<=50K.\"", ",", "\"<=50K\"", "]", ":", "\n", "                ", "class_label", "=", "-", "1", "\n", "", "elif", "class_label", "in", "[", "\">50K.\"", ",", "\">50K\"", "]", ":", "\n", "                ", "class_label", "=", "+", "1", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"Invalid class label value\"", ")", "\n", "\n", "", "y", ".", "append", "(", "class_label", ")", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "line", ")", "-", "1", ")", ":", "\n", "                ", "attr_name", "=", "attrs", "[", "i", "]", "\n", "attr_val", "=", "line", "[", "i", "]", "\n", "# reducing dimensionality of some very sparse features", "\n", "if", "attr_name", "==", "\"native_country\"", ":", "\n", "                    ", "if", "attr_val", "!=", "\"United-States\"", ":", "\n", "                        ", "attr_val", "=", "\"Non-United-Stated\"", "\n", "", "", "elif", "attr_name", "==", "\"education\"", ":", "\n", "                    ", "if", "attr_val", "in", "[", "\"Preschool\"", ",", "\"1st-4th\"", ",", "\"5th-6th\"", ",", "\"7th-8th\"", "]", ":", "\n", "                        ", "attr_val", "=", "\"prim-middle-school\"", "\n", "", "elif", "attr_val", "in", "[", "\"9th\"", ",", "\"10th\"", ",", "\"11th\"", ",", "\"12th\"", "]", ":", "\n", "                        ", "attr_val", "=", "\"high-school\"", "\n", "\n", "", "", "if", "attr_name", "in", "sensitive_attrs", ":", "\n", "                    ", "x_control", "[", "attr_name", "]", ".", "append", "(", "attr_val", ")", "\n", "", "elif", "attr_name", "in", "attrs_to_ignore", ":", "\n", "                    ", "pass", "\n", "", "else", ":", "\n", "                    ", "attrs_to_vals", "[", "attr_name", "]", ".", "append", "(", "attr_val", ")", "\n", "\n", "\n", "", "", "", "", "def", "convert_attrs_to_ints", "(", "d", ")", ":", "# discretize the string attributes", "\n", "        ", "for", "attr_name", ",", "attr_vals", "in", "d", ".", "items", "(", ")", ":", "\n", "            ", "if", "attr_name", "in", "int_attrs", ":", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "uniq_vals", "=", "sorted", "(", "list", "(", "set", "(", "attr_vals", ")", ")", ")", "# get unique values", "\n", "\n", "# compute integer codes for the unique values", "\n", "val_dict", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "uniq_vals", ")", ")", ":", "\n", "                    ", "val_dict", "[", "uniq_vals", "[", "i", "]", "]", "=", "i", "\n", "\n", "# replace the values with their integer encoding", "\n", "", "for", "i", "in", "range", "(", "0", ",", "len", "(", "attr_vals", ")", ")", ":", "\n", "                    ", "attr_vals", "[", "i", "]", "=", "val_dict", "[", "attr_vals", "[", "i", "]", "]", "\n", "", "d", "[", "attr_name", "]", "=", "attr_vals", "\n", "\n", "\n", "# convert the discrete values to their integer representations", "\n", "", "", "", "convert_attrs_to_ints", "(", "x_control", ")", "\n", "convert_attrs_to_ints", "(", "attrs_to_vals", ")", "\n", "\n", "\n", "# if the integer vals are not binary, we need to get one-hot encoding for them", "\n", "for", "attr_name", "in", "attrs_for_classification", ":", "\n", "        ", "attr_vals", "=", "attrs_to_vals", "[", "attr_name", "]", "\n", "if", "attr_name", "in", "int_attrs", "or", "attr_name", "==", "\"native_country\"", ":", "# the way we encoded native country, its binary now so no need to apply one hot encoding on it", "\n", "            ", "X", ".", "append", "(", "attr_vals", ")", "\n", "\n", "", "else", ":", "\n", "            ", "attr_vals", ",", "index_dict", "=", "ut", ".", "get_one_hot_encoding", "(", "attr_vals", ")", "\n", "for", "inner_col", "in", "attr_vals", ".", "T", ":", "\n", "                ", "X", ".", "append", "(", "inner_col", ")", "\n", "\n", "\n", "# convert to numpy arrays for easy handline", "\n", "", "", "", "X", "=", "np", ".", "array", "(", "X", ",", "dtype", "=", "float", ")", ".", "T", "\n", "y", "=", "np", ".", "array", "(", "y", ",", "dtype", "=", "float", ")", "\n", "for", "k", ",", "v", "in", "x_control", ".", "items", "(", ")", ":", "x_control", "[", "k", "]", "=", "np", ".", "array", "(", "v", ",", "dtype", "=", "float", ")", "\n", "\n", "# shuffle the data", "\n", "perm", "=", "list", "(", "range", "(", "0", ",", "len", "(", "y", ")", ")", ")", "# shuffle the data before creating each fold", "\n", "shuffle", "(", "perm", ")", "\n", "X", "=", "X", "[", "perm", "]", "\n", "y", "=", "y", "[", "perm", "]", "\n", "for", "k", "in", "x_control", ".", "keys", "(", ")", ":", "\n", "        ", "x_control", "[", "k", "]", "=", "x_control", "[", "k", "]", "[", "perm", "]", "\n", "\n", "# see if we need to subsample the data", "\n", "", "if", "load_data_size", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"Loading only %d examples from the data\"", "%", "load_data_size", ")", "\n", "X", "=", "X", "[", ":", "load_data_size", "]", "\n", "y", "=", "y", "[", ":", "load_data_size", "]", "\n", "for", "k", "in", "x_control", ".", "keys", "(", ")", ":", "\n", "            ", "x_control", "[", "k", "]", "=", "x_control", "[", "k", "]", "[", ":", "load_data_size", "]", "\n", "\n", "", "", "return", "X", ",", "y", ",", "x_control", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace._data_main.fair_adult_data.load_adult_data_new": [[170, 318], ["os.path.dirname", "all_attrs_to_vals.keys", "pandas.DataFrame.from_dict", "pandas.DataFrame", "pd.DataFrame.astype", "set", "set", "os.path.realpath", "fair_adult_data.check_data_file", "os.path.join", "print", "open", "list", "line.split.strip", "line.split.split", "y.append", "range", "all_attrs_to_vals.keys", "len", "len", "len", "Exception", "len", "x_control[].append", "attrs_to_vals[].append"], "function", ["home.repos.pwc.inspect_result.amirhk_mace._data_main.fair_adult_data.check_data_file"], ["", "def", "load_adult_data_new", "(", ")", ":", "\n", "\n", "    ", "attrs", "=", "[", "'age'", ",", "'workclass'", ",", "'fnlwgt'", ",", "'education'", ",", "'education_num'", ",", "'marital_status'", ",", "'occupation'", ",", "'relationship'", ",", "'race'", ",", "'sex'", ",", "'capital_gain'", ",", "'capital_loss'", ",", "'hours_per_week'", ",", "'native_country'", "]", "# all attributes", "\n", "int_attrs", "=", "[", "'age'", ",", "'fnlwgt'", ",", "'education_num'", ",", "'capital_gain'", ",", "'capital_loss'", ",", "'hours_per_week'", "]", "# attributes with integer values -- the rest are categorical", "\n", "sensitive_attrs", "=", "[", "'sex'", "]", "# the fairness constraints will be used for this feature", "\n", "attrs_to_ignore", "=", "[", "'sex'", ",", "'race'", ",", "'fnlwgt'", "]", "# sex and race are sensitive feature so we will not use them in classification, we will not consider fnlwght for classification since its computed externally and it highly predictive for the class (for details, see documentation of the adult data)", "\n", "attrs_for_classification", "=", "set", "(", "attrs", ")", "-", "set", "(", "attrs_to_ignore", ")", "\n", "\n", "# adult data comes in two different files, one for training and one for testing, however, we will combine data from both the files", "\n", "this_files_directory", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", "\n", "data_files", "=", "[", "\"adult.data\"", ",", "\"adult.test\"", "]", "\n", "\n", "X", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "x_control", "=", "{", "}", "\n", "\n", "attrs_to_vals", "=", "{", "}", "# will store the values for each attribute for all users", "\n", "for", "k", "in", "attrs", ":", "\n", "        ", "if", "k", "in", "sensitive_attrs", ":", "\n", "            ", "x_control", "[", "k", "]", "=", "[", "]", "\n", "", "elif", "k", "in", "attrs_to_ignore", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "attrs_to_vals", "[", "k", "]", "=", "[", "]", "\n", "\n", "", "", "for", "file_name", "in", "data_files", ":", "\n", "\n", "        ", "check_data_file", "(", "file_name", ")", "\n", "full_file_name", "=", "os", ".", "path", ".", "join", "(", "this_files_directory", ",", "file_name", ")", "\n", "print", "(", "full_file_name", ")", "\n", "\n", "for", "line", "in", "open", "(", "full_file_name", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "==", "\"\"", ":", "continue", "# skip empty lines", "\n", "line", "=", "line", ".", "split", "(", "\", \"", ")", "\n", "if", "len", "(", "line", ")", "!=", "15", "or", "\"?\"", "in", "line", ":", "# if a line has missing attributes, ignore it", "\n", "                ", "continue", "\n", "\n", "", "class_label", "=", "line", "[", "-", "1", "]", "\n", "if", "class_label", "in", "[", "\"<=50K.\"", ",", "\"<=50K\"", "]", ":", "\n", "                ", "class_label", "=", "0", "\n", "", "elif", "class_label", "in", "[", "\">50K.\"", ",", "\">50K\"", "]", ":", "\n", "                ", "class_label", "=", "+", "1", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"Invalid class label value\"", ")", "\n", "\n", "", "y", ".", "append", "(", "class_label", ")", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "line", ")", "-", "1", ")", ":", "\n", "                ", "attr_name", "=", "attrs", "[", "i", "]", "\n", "attr_val", "=", "line", "[", "i", "]", "\n", "# reducing dimensionality of some very sparse features", "\n", "if", "attr_name", "==", "\"native_country\"", ":", "\n", "                    ", "if", "attr_val", "!=", "\"United-States\"", ":", "\n", "                        ", "attr_val", "=", "\"Non-United-Stated\"", "\n", "", "", "elif", "attr_name", "==", "\"education\"", ":", "\n", "                    ", "if", "attr_val", "in", "[", "\"Preschool\"", ",", "\"1st-4th\"", ",", "\"5th-6th\"", ",", "\"7th-8th\"", "]", ":", "\n", "                        ", "attr_val", "=", "\"prim-middle-school\"", "\n", "", "elif", "attr_val", "in", "[", "\"9th\"", ",", "\"10th\"", ",", "\"11th\"", ",", "\"12th\"", "]", ":", "\n", "                        ", "attr_val", "=", "\"high-school\"", "\n", "\n", "", "", "if", "attr_name", "in", "sensitive_attrs", ":", "\n", "                    ", "x_control", "[", "attr_name", "]", ".", "append", "(", "attr_val", ")", "\n", "", "elif", "attr_name", "in", "attrs_to_ignore", ":", "\n", "                    ", "pass", "\n", "", "else", ":", "\n", "                    ", "attrs_to_vals", "[", "attr_name", "]", ".", "append", "(", "attr_val", ")", "\n", "\n", "\n", "", "", "", "", "all_attrs_to_vals", "=", "attrs_to_vals", "\n", "all_attrs_to_vals", "[", "'sex'", "]", "=", "x_control", "[", "'sex'", "]", "\n", "all_attrs_to_vals", "[", "'label'", "]", "=", "y", "\n", "\n", "first_key", "=", "list", "(", "all_attrs_to_vals", ".", "keys", "(", ")", ")", "[", "0", "]", "\n", "for", "key", "in", "all_attrs_to_vals", ".", "keys", "(", ")", ":", "\n", "      ", "assert", "(", "len", "(", "all_attrs_to_vals", "[", "key", "]", ")", "==", "len", "(", "all_attrs_to_vals", "[", "first_key", "]", ")", ")", "\n", "\n", "", "df", "=", "pd", ".", "DataFrame", ".", "from_dict", "(", "all_attrs_to_vals", ")", "\n", "\n", "processed_df", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n", "processed_df", "[", "'Label'", "]", "=", "df", "[", "'label'", "]", "\n", "\n", "processed_df", ".", "loc", "[", "df", "[", "'sex'", "]", "==", "'Male'", ",", "'Sex'", "]", "=", "1", "\n", "processed_df", ".", "loc", "[", "df", "[", "'sex'", "]", "==", "'Female'", ",", "'Sex'", "]", "=", "2", "\n", "\n", "processed_df", "[", "'Age'", "]", "=", "df", "[", "'age'", "]", "\n", "\n", "processed_df", ".", "loc", "[", "df", "[", "'native_country'", "]", "==", "'United-States'", ",", "'NativeCountry'", "]", "=", "1", "\n", "processed_df", ".", "loc", "[", "df", "[", "'native_country'", "]", "==", "'Non-United-Stated'", ",", "'NativeCountry'", "]", "=", "2", "\n", "\n", "processed_df", ".", "loc", "[", "df", "[", "'workclass'", "]", "==", "'Federal-gov'", ",", "'WorkClass'", "]", "=", "1", "\n", "processed_df", ".", "loc", "[", "df", "[", "'workclass'", "]", "==", "'Local-gov'", ",", "'WorkClass'", "]", "=", "2", "\n", "processed_df", ".", "loc", "[", "df", "[", "'workclass'", "]", "==", "'Private'", ",", "'WorkClass'", "]", "=", "3", "\n", "processed_df", ".", "loc", "[", "df", "[", "'workclass'", "]", "==", "'Self-emp-inc'", ",", "'WorkClass'", "]", "=", "4", "\n", "processed_df", ".", "loc", "[", "df", "[", "'workclass'", "]", "==", "'Self-emp-not-inc'", ",", "'WorkClass'", "]", "=", "5", "\n", "processed_df", ".", "loc", "[", "df", "[", "'workclass'", "]", "==", "'State-gov'", ",", "'WorkClass'", "]", "=", "6", "\n", "processed_df", ".", "loc", "[", "df", "[", "'workclass'", "]", "==", "'Without-pay'", ",", "'WorkClass'", "]", "=", "7", "\n", "\n", "processed_df", "[", "'EducationNumber'", "]", "=", "df", "[", "'education_num'", "]", "\n", "\n", "processed_df", ".", "loc", "[", "df", "[", "'education'", "]", "==", "'prim-middle-school'", ",", "'EducationLevel'", "]", "=", "1", "\n", "processed_df", ".", "loc", "[", "df", "[", "'education'", "]", "==", "'high-school'", ",", "'EducationLevel'", "]", "=", "2", "\n", "processed_df", ".", "loc", "[", "df", "[", "'education'", "]", "==", "'HS-grad'", ",", "'EducationLevel'", "]", "=", "3", "\n", "processed_df", ".", "loc", "[", "df", "[", "'education'", "]", "==", "'Some-college'", ",", "'EducationLevel'", "]", "=", "4", "\n", "processed_df", ".", "loc", "[", "df", "[", "'education'", "]", "==", "'Bachelors'", ",", "'EducationLevel'", "]", "=", "5", "\n", "processed_df", ".", "loc", "[", "df", "[", "'education'", "]", "==", "'Masters'", ",", "'EducationLevel'", "]", "=", "6", "\n", "processed_df", ".", "loc", "[", "df", "[", "'education'", "]", "==", "'Doctorate'", ",", "'EducationLevel'", "]", "=", "7", "\n", "processed_df", ".", "loc", "[", "df", "[", "'education'", "]", "==", "'Assoc-voc'", ",", "'EducationLevel'", "]", "=", "8", "\n", "processed_df", ".", "loc", "[", "df", "[", "'education'", "]", "==", "'Assoc-acdm'", ",", "'EducationLevel'", "]", "=", "9", "\n", "processed_df", ".", "loc", "[", "df", "[", "'education'", "]", "==", "'Prof-school'", ",", "'EducationLevel'", "]", "=", "10", "\n", "\n", "processed_df", ".", "loc", "[", "df", "[", "'marital_status'", "]", "==", "'Divorced'", ",", "'MaritalStatus'", "]", "=", "1", "\n", "processed_df", ".", "loc", "[", "df", "[", "'marital_status'", "]", "==", "'Married-AF-spouse'", ",", "'MaritalStatus'", "]", "=", "2", "\n", "processed_df", ".", "loc", "[", "df", "[", "'marital_status'", "]", "==", "'Married-civ-spouse'", ",", "'MaritalStatus'", "]", "=", "3", "\n", "processed_df", ".", "loc", "[", "df", "[", "'marital_status'", "]", "==", "'Married-spouse-absent'", ",", "'MaritalStatus'", "]", "=", "4", "\n", "processed_df", ".", "loc", "[", "df", "[", "'marital_status'", "]", "==", "'Never-married'", ",", "'MaritalStatus'", "]", "=", "5", "\n", "processed_df", ".", "loc", "[", "df", "[", "'marital_status'", "]", "==", "'Separated'", ",", "'MaritalStatus'", "]", "=", "6", "\n", "processed_df", ".", "loc", "[", "df", "[", "'marital_status'", "]", "==", "'Widowed'", ",", "'MaritalStatus'", "]", "=", "7", "\n", "\n", "processed_df", ".", "loc", "[", "df", "[", "'occupation'", "]", "==", "'Adm-clerical'", ",", "'Occupation'", "]", "=", "1", "\n", "processed_df", ".", "loc", "[", "df", "[", "'occupation'", "]", "==", "'Armed-Forces'", ",", "'Occupation'", "]", "=", "2", "\n", "processed_df", ".", "loc", "[", "df", "[", "'occupation'", "]", "==", "'Craft-repair'", ",", "'Occupation'", "]", "=", "3", "\n", "processed_df", ".", "loc", "[", "df", "[", "'occupation'", "]", "==", "'Exec-managerial'", ",", "'Occupation'", "]", "=", "4", "\n", "processed_df", ".", "loc", "[", "df", "[", "'occupation'", "]", "==", "'Farming-fishing'", ",", "'Occupation'", "]", "=", "5", "\n", "processed_df", ".", "loc", "[", "df", "[", "'occupation'", "]", "==", "'Handlers-cleaners'", ",", "'Occupation'", "]", "=", "6", "\n", "processed_df", ".", "loc", "[", "df", "[", "'occupation'", "]", "==", "'Machine-op-inspct'", ",", "'Occupation'", "]", "=", "7", "\n", "processed_df", ".", "loc", "[", "df", "[", "'occupation'", "]", "==", "'Other-service'", ",", "'Occupation'", "]", "=", "8", "\n", "processed_df", ".", "loc", "[", "df", "[", "'occupation'", "]", "==", "'Priv-house-serv'", ",", "'Occupation'", "]", "=", "9", "\n", "processed_df", ".", "loc", "[", "df", "[", "'occupation'", "]", "==", "'Prof-specialty'", ",", "'Occupation'", "]", "=", "10", "\n", "processed_df", ".", "loc", "[", "df", "[", "'occupation'", "]", "==", "'Protective-serv'", ",", "'Occupation'", "]", "=", "11", "\n", "processed_df", ".", "loc", "[", "df", "[", "'occupation'", "]", "==", "'Sales'", ",", "'Occupation'", "]", "=", "12", "\n", "processed_df", ".", "loc", "[", "df", "[", "'occupation'", "]", "==", "'Tech-support'", ",", "'Occupation'", "]", "=", "13", "\n", "processed_df", ".", "loc", "[", "df", "[", "'occupation'", "]", "==", "'Transport-moving'", ",", "'Occupation'", "]", "=", "14", "\n", "\n", "processed_df", ".", "loc", "[", "df", "[", "'relationship'", "]", "==", "'Husband'", ",", "'Relationship'", "]", "=", "1", "\n", "processed_df", ".", "loc", "[", "df", "[", "'relationship'", "]", "==", "'Not-in-family'", ",", "'Relationship'", "]", "=", "2", "\n", "processed_df", ".", "loc", "[", "df", "[", "'relationship'", "]", "==", "'Other-relative'", ",", "'Relationship'", "]", "=", "3", "\n", "processed_df", ".", "loc", "[", "df", "[", "'relationship'", "]", "==", "'Own-child'", ",", "'Relationship'", "]", "=", "4", "\n", "processed_df", ".", "loc", "[", "df", "[", "'relationship'", "]", "==", "'Unmarried'", ",", "'Relationship'", "]", "=", "5", "\n", "processed_df", ".", "loc", "[", "df", "[", "'relationship'", "]", "==", "'Wife'", ",", "'Relationship'", "]", "=", "6", "\n", "\n", "processed_df", "[", "'CapitalGain'", "]", "=", "df", "[", "'capital_gain'", "]", "\n", "processed_df", "[", "'CapitalLoss'", "]", "=", "df", "[", "'capital_loss'", "]", "\n", "processed_df", "[", "'HoursPerWeek'", "]", "=", "df", "[", "'hours_per_week'", "]", "\n", "\n", "\n", "return", "processed_df", ".", "astype", "(", "'float64'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.amirhk_mace._data_main.process_twomoon_data.load_twomoon_data": [[15, 40], ["sklearn.datasets.make_moons", "y.reshape.reshape", "pandas.DataFrame", "pd.DataFrame.astype", "numpy.round", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate"], "function", ["None"], ["def", "load_twomoon_data", "(", "variable_type", "=", "'real'", ")", ":", "\n", "\n", "# https://rohitmidha23.github.io/Neural-Network-Decision-Boundary/", "\n", "  ", "X", ",", "y", "=", "datasets", ".", "make_moons", "(", "n_samples", "=", "n_samples", ",", "noise", "=", "0.1", ",", "random_state", "=", "0", ")", "\n", "if", "variable_type", "==", "'integer'", ":", "\n", "    ", "X", "=", "np", ".", "round", "(", "4", "*", "X", ")", "\n", "", "y", "=", "y", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "# X = processDataAccordingToGraph(X) # TODO...", "\n", "\n", "X_train", "=", "X", "[", ":", "n_samples", "//", "2", ",", ":", "]", "\n", "X_test", "=", "X", "[", "n_samples", "//", "2", ":", ",", ":", "]", "\n", "y_train", "=", "y", "[", ":", "n_samples", "//", "2", ",", ":", "]", "\n", "y_test", "=", "y", "[", "n_samples", "//", "2", ":", ",", ":", "]", "\n", "\n", "\n", "data_frame_non_hot", "=", "pd", ".", "DataFrame", "(", "\n", "np", ".", "concatenate", "(", "(", "\n", "np", ".", "concatenate", "(", "(", "y_train", ",", "X_train", ")", ",", "axis", "=", "1", ")", ",", "# importantly, labels have to go first, else Dataset.__init__ messes up kurz column names", "\n", "np", ".", "concatenate", "(", "(", "y_test", ",", "X_test", ")", ",", "axis", "=", "1", ")", ",", "# importantly, labels have to go first, else Dataset.__init__ messes up kurz column names", "\n", ")", ",", "\n", "axis", "=", "0", ",", "\n", ")", ",", "\n", "columns", "=", "[", "'label'", ",", "'x0'", ",", "'x1'", "]", "\n", ")", "\n", "return", "data_frame_non_hot", ".", "astype", "(", "'float64'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace._data_main.process_mortgage_data.load_mortgage_data": [[20, 50], ["numpy.concatenate().astype", "process_mortgage_data.processDataAccordingToGraph", "numpy.random.shuffle", "numpy.array", "pandas.DataFrame", "pd.DataFrame.astype", "numpy.random.normal", "numpy.round", "numpy.concatenate", "numpy.random.poisson", "numpy.random.normal", "numpy.concatenate", "numpy.sign", "numpy.concatenate", "numpy.concatenate", "numpy.sign", "numpy.dot"], "function", ["home.repos.pwc.inspect_result.amirhk_mace._data_main.process_mortgage_data.processDataAccordingToGraph"], ["def", "load_mortgage_data", "(", ")", ":", "\n", "\n", "  ", "U_0", "=", "(", "np", ".", "random", ".", "poisson", "(", "salary_lambda", ",", "(", "n", ",", "1", ")", ")", "+", "np", ".", "random", ".", "normal", "(", "0", ",", "1", ",", "(", "n", ",", "1", ")", ")", ")", "*", "salary_multiplier", "\n", "U_1", "=", "np", ".", "random", ".", "normal", "(", "0", ",", "1", ",", "(", "n", ",", "1", ")", ")", "*", "balance_multiplier", "\n", "U_1", "=", "500", "*", "np", ".", "round", "(", "U_1", "/", "500", ")", "\n", "X", "=", "np", ".", "concatenate", "(", "(", "U_0", ",", "U_1", ")", ",", "axis", "=", "1", ")", ".", "astype", "(", "float", ")", "\n", "X", "=", "processDataAccordingToGraph", "(", "X", ")", "\n", "# Shuffle just in case the random generator from Poisson", "\n", "# distributions gets skewed as more samples are generated", "\n", "np", ".", "random", ".", "shuffle", "(", "X", ")", "# must happen before we assign labels", "\n", "y", "=", "(", "np", ".", "sign", "(", "np", ".", "sign", "(", "np", ".", "dot", "(", "X", ",", "w", ")", "+", "b", ")", "+", "1e-6", ")", "+", "1", ")", "/", "2", "# add 1e-3 to prevent label 0.5", "\n", "\n", "X_train", "=", "X", "[", ":", "n", "//", "2", ",", ":", "]", "\n", "X_test", "=", "X", "[", "n", "//", "2", ":", ",", ":", "]", "\n", "y_train", "=", "y", "[", ":", "n", "//", "2", ",", ":", "]", "\n", "y_test", "=", "y", "[", "n", "//", "2", ":", ",", ":", "]", "\n", "\n", "X_test", "[", "0", ",", ":", "]", "=", "np", ".", "array", "(", "[", "[", "75000", ",", "25000", "]", "]", ")", "\n", "\n", "# return w, b, X_train, y_train, X_test, y_test", "\n", "data_frame_non_hot", "=", "pd", ".", "DataFrame", "(", "\n", "np", ".", "concatenate", "(", "(", "\n", "np", ".", "concatenate", "(", "(", "y_train", ",", "X_train", ")", ",", "axis", "=", "1", ")", ",", "# importantly, labels have to go first, else Dataset.__init__ messes up kurz column names", "\n", "np", ".", "concatenate", "(", "(", "y_test", ",", "X_test", ")", ",", "axis", "=", "1", ")", ",", "# importantly, labels have to go first, else Dataset.__init__ messes up kurz column names", "\n", ")", ",", "\n", "axis", "=", "0", ",", "\n", ")", ",", "\n", "columns", "=", "[", "'label'", ",", "'x0'", ",", "'x1'", "]", "\n", ")", "\n", "return", "data_frame_non_hot", ".", "astype", "(", "'float64'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace._data_main.process_mortgage_data.processDataAccordingToGraph": [[52, 62], ["None"], "function", ["None"], ["", "def", "processDataAccordingToGraph", "(", "data", ")", ":", "\n", "# We assume the model below", "\n", "# X_0 := U_0 \\\\ annual salary", "\n", "# X_1 := X_0 / 5 +  U_1 \\\\", "\n", "# U_0 ~ Poisson(salary_lambda) * salary_multiplier", "\n", "# U_1 ~ Poisson(balance_lambda) * balance_multiplier", "\n", "# data = copy.deepcopy(data)", "\n", "  ", "data", "[", ":", ",", "0", "]", "=", "data", "[", ":", ",", "0", "]", "\n", "data", "[", ":", ",", "1", "]", "=", "data", "[", ":", ",", "1", "]", "+", "data", "[", ":", ",", "0", "]", "*", "3", "/", "10.", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace._data_main.fair_utils_data.add_intercept": [[9, 15], ["numpy.ones().reshape", "numpy.concatenate", "numpy.ones"], "function", ["None"], ["def", "add_intercept", "(", "x", ")", ":", "\n", "\n", "    ", "\"\"\" Add intercept to the data before linear classification \"\"\"", "\n", "m", ",", "n", "=", "x", ".", "shape", "\n", "intercept", "=", "np", ".", "ones", "(", "m", ")", ".", "reshape", "(", "m", ",", "1", ")", "# the constant b", "\n", "return", "np", ".", "concatenate", "(", "(", "intercept", ",", "x", ")", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirhk_mace._data_main.fair_utils_data.get_one_hot_encoding": [[17, 52], ["numpy.array", "sorted", "len", "range", "range", "len", "list", "len", "len", "numpy.zeros", "out_arr.append", "numpy.array", "print", "print", "set", "str", "type", "type", "str", "type", "type"], "function", ["None"], ["", "def", "get_one_hot_encoding", "(", "in_arr", ")", ":", "\n", "    ", "\"\"\"\n        input: 1-D arr with int vals -- if not int vals, will raise an error\n        output: m (ndarray): one-hot encoded matrix\n                d (dict): also returns a dictionary original_val -> column in encoded matrix\n    \"\"\"", "\n", "\n", "for", "k", "in", "in_arr", ":", "\n", "        ", "if", "str", "(", "type", "(", "k", ")", ")", "!=", "\"<type 'numpy.float64'>\"", "and", "type", "(", "k", ")", "!=", "int", "and", "type", "(", "k", ")", "!=", "np", ".", "int64", ":", "\n", "            ", "print", "(", "str", "(", "type", "(", "k", ")", ")", ")", "\n", "print", "(", "\"************* ERROR: Input arr does not have integer types\"", ")", "\n", "return", "None", "\n", "\n", "", "", "in_arr", "=", "np", ".", "array", "(", "in_arr", ",", "dtype", "=", "int", ")", "\n", "assert", "(", "len", "(", "in_arr", ".", "shape", ")", "==", "1", ")", "# no column, means it was a 1-D arr", "\n", "attr_vals_uniq_sorted", "=", "sorted", "(", "list", "(", "set", "(", "in_arr", ")", ")", ")", "\n", "num_uniq_vals", "=", "len", "(", "attr_vals_uniq_sorted", ")", "\n", "if", "(", "num_uniq_vals", "==", "2", ")", "and", "(", "attr_vals_uniq_sorted", "[", "0", "]", "==", "0", "and", "attr_vals_uniq_sorted", "[", "1", "]", "==", "1", ")", ":", "\n", "        ", "return", "in_arr", ",", "None", "\n", "\n", "\n", "", "index_dict", "=", "{", "}", "# value to the column number", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "attr_vals_uniq_sorted", ")", ")", ":", "\n", "        ", "val", "=", "attr_vals_uniq_sorted", "[", "i", "]", "\n", "index_dict", "[", "val", "]", "=", "i", "\n", "\n", "", "out_arr", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "in_arr", ")", ")", ":", "\n", "        ", "tup", "=", "np", ".", "zeros", "(", "num_uniq_vals", ")", "\n", "val", "=", "in_arr", "[", "i", "]", "\n", "ind", "=", "index_dict", "[", "val", "]", "\n", "tup", "[", "ind", "]", "=", "1", "# set that value of tuple to 1", "\n", "out_arr", ".", "append", "(", "tup", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "out_arr", ")", ",", "index_dict", "\n", "\n"]]}