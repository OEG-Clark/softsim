{"home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.aggregate_results.aggregate_results_to_json": [[27, 40], ["absl.logging.info", "aggregate_results._get", "absl.logging.info", "tensorflow.compat.v1.gfile.Open", "_get.to_json"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.aggregate_results._get"], ["def", "aggregate_results_to_json", "(", "result_file_pattern", ",", "output_path", ")", ":", "\n", "  ", "\"\"\"Aggregates all the results files in the pattern into a single JSON file.\n\n  Args:\n    result_file_pattern: String with glob pattern to all the result files that\n      should be aggregated (e.g. /tmp/*/results/aggregate/evaluation.json).\n    output_path: String with path to output json file (e.g. /tmp/results.json).\n  \"\"\"", "\n", "logging", ".", "info", "(", "\"Loading the results.\"", ")", "\n", "model_results", "=", "_get", "(", "result_file_pattern", ")", "\n", "logging", ".", "info", "(", "\"Saving the aggregated results.\"", ")", "\n", "with", "gfile", ".", "Open", "(", "output_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "    ", "model_results", ".", "to_json", "(", "path_or_buf", "=", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.aggregate_results.load_aggregated_json_results": [[42, 54], ["absl.logging.info", "pandas.read_json"], "function", ["None"], ["", "", "def", "load_aggregated_json_results", "(", "source_path", ")", ":", "\n", "  ", "\"\"\"Convenience function to load aggregated results from JSON file.\n\n  Args:\n    source_path: String with path to aggregated json file (e.g.\n      /tmp/results.json).\n\n  Returns:\n    pd.DataFrame with aggregated results.\n  \"\"\"", "\n", "logging", ".", "info", "(", "\"Loading the aggregated results.\"", ")", "\n", "return", "pd", ".", "read_json", "(", "path_or_buf", "=", "source_path", ",", "orient", "=", "\"columns\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.aggregate_results._load": [[56, 61], ["tensorflow.compat.v1.gfile.GFile", "simplejson.load"], "function", ["None"], ["", "def", "_load", "(", "path", ")", ":", "\n", "  ", "with", "gfile", ".", "GFile", "(", "path", ")", "as", "f", ":", "\n", "    ", "result", "=", "json", ".", "load", "(", "f", ")", "\n", "", "result", "[", "\"path\"", "]", "=", "path", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.aggregate_results._get": [[63, 68], ["tensorflow.compat.v1.gfile.Glob", "multiprocessing.Pool", "multiprocessing.Pool.map", "pandas.DataFrame"], "function", ["None"], ["", "def", "_get", "(", "pattern", ")", ":", "\n", "  ", "files", "=", "gfile", ".", "Glob", "(", "pattern", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", ")", "\n", "all_results", "=", "pool", ".", "map", "(", "_load", ",", "files", ")", "\n", "return", "pd", ".", "DataFrame", "(", "all_results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file": [[23, 27], ["resource_filename"], "function", ["None"], ["def", "get_file", "(", "path", ")", ":", "\n", "  ", "\"\"\"Returns path relative to file.\"\"\"", "\n", "from", "pkg_resources", "import", "resource_filename", "# pylint: disable=g-bad-import-order, g-import-not-at-top", "\n", "return", "resource_filename", "(", "\"disentanglement_lib\"", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_files_in_folder": [[29, 35], ["pkg_resources.resource_listdir", "pkg_resources.resource_isdir", "pkg_resources.resource_filename"], "function", ["None"], ["", "def", "get_files_in_folder", "(", "path", ")", ":", "\n", "  ", "import", "pkg_resources", "# pylint: disable=g-bad-import-order, g-import-not-at-top", "\n", "for", "name", "in", "pkg_resources", ".", "resource_listdir", "(", "\"disentanglement_lib\"", ",", "path", ")", ":", "\n", "    ", "new_path", "=", "path", "+", "\"/\"", "+", "name", "\n", "if", "not", "pkg_resources", ".", "resource_isdir", "(", "\"disentanglement_lib\"", ",", "new_path", ")", ":", "\n", "      ", "yield", "pkg_resources", ".", "resource_filename", "(", "\"disentanglement_lib\"", ",", "new_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results_test.ResultsTest.test_namespaced_dict": [[33, 43], ["disentanglement_lib.utils.results.namespaced_dict", "results_test.ResultsTest.assertDictEqual"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.namespaced_dict"], ["  ", "def", "test_namespaced_dict", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests namespacing functionality.\"\"\"", "\n", "base_dict", "=", "{", "\"!\"", ":", "\"!!\"", "}", "\n", "numbers", "=", "{", "\"1\"", ":", "\"one\"", "}", "\n", "chars", "=", "{", "\"a\"", ":", "\"A\"", "}", "\n", "new_dict", "=", "results", ".", "namespaced_dict", "(", "base_dict", ",", "numbers", "=", "numbers", ",", "chars", "=", "chars", ")", "\n", "self", ".", "assertDictEqual", "(", "new_dict", ",", "{", "\n", "\"!\"", ":", "\"!!\"", ",", "\n", "\"numbers.1\"", ":", "\"one\"", ",", "\n", "\"chars.a\"", ":", "\"A\"", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results_test.ResultsTest.test_dict_to_txt": [[45, 50], ["os.path.join", "disentanglement_lib.utils.results.save_dict", "results_test.ResultsTest.get_temp_dir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.save_dict"], ["", "def", "test_dict_to_txt", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests saving functionality to txt file.\"\"\"", "\n", "output_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "get_temp_dir", "(", ")", ",", "\"export.csv\"", ")", "\n", "output_dict", "=", "{", "\"1\"", ":", "\"one\"", "}", "\n", "results", ".", "save_dict", "(", "output_path", ",", "output_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results_test.ResultsTest.test_gin_dict_live": [[51, 57], ["gin.bind_parameter", "results_test.test_fn", "results_test.ResultsTest.assertDictEqual", "disentanglement_lib.utils.results.gin_dict"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results_test.test_fn", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.gin_dict"], ["", "def", "test_gin_dict_live", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests namespacing functionality based on live gin config.\"\"\"", "\n", "parameter_name", "=", "\"test.value\"", "\n", "gin", ".", "bind_parameter", "(", "parameter_name", ",", "1", ")", "\n", "_", "=", "test_fn", "(", ")", "\n", "self", ".", "assertDictEqual", "(", "results", ".", "gin_dict", "(", ")", ",", "{", "parameter_name", ":", "\"1\"", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results_test.ResultsTest.test_gin_dict_dir": [[58, 68], ["gin.bind_parameter", "results_test.test_fn", "os.path.join", "results_test.ResultsTest.assertDictEqual", "results_test.ResultsTest.get_temp_dir", "tensorflow.gfile.GFile", "f.write", "f.close", "disentanglement_lib.utils.results.gin_dict", "gin.operative_config_str"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results_test.test_fn", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.gin_dict"], ["", "def", "test_gin_dict_dir", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests namespacing functionality based on saved gin config.\"\"\"", "\n", "parameter_name", "=", "\"test.value\"", "\n", "gin", ".", "bind_parameter", "(", "parameter_name", ",", "1", ")", "\n", "_", "=", "test_fn", "(", ")", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "get_temp_dir", "(", ")", ",", "\"config.gin\"", ")", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "config_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "      ", "f", ".", "write", "(", "gin", ".", "operative_config_str", "(", ")", ")", "\n", "f", ".", "close", "(", ")", "\n", "", "self", ".", "assertDictEqual", "(", "results", ".", "gin_dict", "(", "config_path", ")", ",", "{", "parameter_name", ":", "\"1\"", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results_test.ResultsTest.test_aggregate_json_results": [[69, 82], ["results_test.ResultsTest.get_temp_dir", "os.path.join", "disentanglement_lib.utils.results.save_dict", "os.path.join", "disentanglement_lib.utils.results.save_dict", "disentanglement_lib.utils.results.aggregate_json_results", "results_test.ResultsTest.assertDictEqual"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.save_dict", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.save_dict", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.aggregate_json_results"], ["", "def", "test_aggregate_json_results", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests aggregation functionality.\"\"\"", "\n", "tmp_dir", "=", "self", ".", "get_temp_dir", "(", ")", "\n", "output_path1", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "\"export_one.json\"", ")", "\n", "output_dict1", "=", "{", "\"1\"", ":", "\"one\"", "}", "\n", "results", ".", "save_dict", "(", "output_path1", ",", "output_dict1", ")", "\n", "output_path2", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "\"export_two.json\"", ")", "\n", "output_dict2", "=", "{", "\"2\"", ":", "\"two\"", "}", "\n", "results", ".", "save_dict", "(", "output_path2", ",", "output_dict2", ")", "\n", "result_dict", "=", "results", ".", "aggregate_json_results", "(", "tmp_dir", ")", "\n", "self", ".", "assertDictEqual", "(", "result_dict", ",", "{", "\n", "\"export_one.1\"", ":", "\"one\"", ",", "\n", "\"export_two.2\"", ":", "\"two\"", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results_test.test_fn": [[26, 29], ["gin.configurable"], "function", ["None"], ["@", "gin", ".", "configurable", "(", "\"test\"", ")", "\n", "def", "test_fn", "(", "value", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "  ", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.convolute_hub_test.ConvoluteHubTest.test_convolute": [[29, 71], ["numpy.random.RandomState", "numpy.random.RandomState.normal", "numpy.random.RandomState.normal", "numpy.random.RandomState.normal", "os.path.join", "disentanglement_lib.utils.convolute_hub.save_numpy_arrays_to_checkpoint", "os.path.join", "tensorflow_hub.create_module_spec", "tensorflow_hub.create_module_spec.export", "os.path.join", "disentanglement_lib.utils.convolute_hub.convolute_and_save", "np.random.RandomState.normal.dot().dot", "convolute_hub_test.ConvoluteHubTest.assertAllClose", "convolute_hub_test.ConvoluteHubTest.get_temp_dir", "convolute_hub_test.ConvoluteHubTest.get_temp_dir", "tensorflow.placeholder", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow_hub.add_signature", "tensorflow.get_variable", "dict", "convolute_hub_test.ConvoluteHubTest.get_temp_dir", "tensorflow_hub.eval_function_for_module", "f", "dict", "np.random.RandomState.normal.dot", "tensorflow.matmul"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.convolute_hub.save_numpy_arrays_to_checkpoint", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.convolute_hub.convolute_and_save"], ["  ", "def", "test_convolute", "(", "self", ")", ":", "\n", "\n", "# Create variables to use.", "\n", "    ", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "data", "=", "random_state", ".", "normal", "(", "size", "=", "(", "5", ",", "10", ")", ")", "\n", "variable1", "=", "random_state", ".", "normal", "(", "size", "=", "(", "10", ",", "6", ")", ")", "\n", "variable2", "=", "random_state", ".", "normal", "(", "size", "=", "(", "6", ",", "2", ")", ")", "\n", "\n", "# Save variables to checkpoint.", "\n", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "get_temp_dir", "(", ")", ",", "\"checkpoint.ckpt\"", ")", "\n", "convolute_hub", ".", "save_numpy_arrays_to_checkpoint", "(", "\n", "checkpoint_path", ",", "variable1", "=", "variable1", ",", "variable2", "=", "variable2", ")", "\n", "\n", "# Save a TFHub module that we will convolute.", "\n", "module_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "get_temp_dir", "(", ")", ",", "\"module_path\"", ")", "\n", "def", "module_fn", "(", ")", ":", "\n", "      ", "tensor", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "shape", "=", "(", "None", ",", "10", ")", ")", "\n", "variable1", "=", "tf", ".", "get_variable", "(", "\"variable1\"", ",", "shape", "=", "(", "10", ",", "6", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "output", "=", "tf", ".", "matmul", "(", "tensor", ",", "variable1", ")", "\n", "hub", ".", "add_signature", "(", "\n", "name", "=", "\"multiplication1\"", ",", "\n", "inputs", "=", "{", "\"tensor\"", ":", "tensor", "}", ",", "\n", "outputs", "=", "{", "\"tensor\"", ":", "output", "}", ")", "\n", "", "spec", "=", "hub", ".", "create_module_spec", "(", "module_fn", ")", "\n", "spec", ".", "export", "(", "module_path", ",", "checkpoint_path", "=", "checkpoint_path", ")", "\n", "\n", "# Function used for the convolution.", "\n", "def", "_operation2", "(", "tensor", ")", ":", "\n", "      ", "variable2", "=", "tf", ".", "get_variable", "(", "\"variable2\"", ",", "shape", "=", "(", "6", ",", "2", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "return", "dict", "(", "tensor", "=", "tf", ".", "matmul", "(", "tensor", ",", "variable2", ")", ")", "\n", "\n", "# Save the convolution as a new TFHub module", "\n", "", "module_path_new", "=", "os", ".", "path", ".", "join", "(", "self", ".", "get_temp_dir", "(", ")", ",", "\"module_path_new\"", ")", "\n", "convolute_hub", ".", "convolute_and_save", "(", "module_path", ",", "\"multiplication1\"", ",", "\n", "module_path_new", ",", "_operation2", ",", "\n", "checkpoint_path", ",", "\"convoluted\"", ")", "\n", "\n", "# Check the first signature.", "\n", "with", "hub", ".", "eval_function_for_module", "(", "module_path_new", ")", "as", "f", ":", "\n", "      ", "module_result", "=", "f", "(", "dict", "(", "tensor", "=", "data", ")", ",", "signature", "=", "\"convoluted\"", ",", "as_dict", "=", "True", ")", "\n", "", "real_result", "=", "data", ".", "dot", "(", "variable1", ")", ".", "dot", "(", "variable2", ")", "\n", "self", ".", "assertAllClose", "(", "real_result", ",", "module_result", "[", "\"tensor\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.Encoder.default": [[122, 132], ["isinstance", "simplejson.JSONEncoder.default", "float", "isinstance", "int", "isinstance", "obj.tolist.tolist.tolist"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.Encoder.default"], ["def", "default", "(", "self", ",", "obj", ")", ":", "\n", "    ", "if", "isinstance", "(", "obj", ",", "(", "np", ".", "float_", ",", "np", ".", "float32", ",", "np", ".", "float16", ",", "np", ".", "float64", ")", ")", ":", "\n", "      ", "return", "float", "(", "obj", ")", "\n", "", "elif", "isinstance", "(", "obj", ",", "\n", "(", "np", ".", "intc", ",", "np", ".", "intp", ",", "np", ".", "int_", ",", "np", ".", "int8", ",", "np", ".", "int16", ",", "np", ".", "int32", ",", "\n", "np", ".", "int64", ",", "np", ".", "uint8", ",", "np", ".", "uint16", ",", "np", ".", "uint32", ",", "np", ".", "uint64", ")", ")", ":", "\n", "      ", "return", "int", "(", "obj", ")", "\n", "", "elif", "isinstance", "(", "obj", ",", "np", ".", "ndarray", ")", ":", "\n", "      ", "obj", "=", "obj", ".", "tolist", "(", ")", "\n", "", "return", "json", ".", "JSONEncoder", ".", "default", "(", "self", ",", "obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.update_result_directory": [[32, 85], ["os.path.join", "str", "os.path.join", "results.save_gin", "os.path.join", "results.save_dict", "os.path.join", "results.save_dict", "results.aggregate_json_results", "os.path.join", "results.save_dict", "results.copydir", "uuid.uuid4", "results.gin_dict", "tensorflow.gfile.IsDirectory", "tensorflow.gfile.MakeDirs"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.save_gin", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.save_dict", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.save_dict", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.aggregate_json_results", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.save_dict", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.copydir", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.gin_dict"], ["def", "update_result_directory", "(", "result_directory", ",", "\n", "step_name", ",", "\n", "results_dict", ",", "\n", "old_result_directory", "=", "None", ")", ":", "\n", "  ", "\"\"\"One stop solution for updating the result directory.\n\n  1. Copies old_result_directory to result_directory if not None.\n  2. Adds a unique id to the result_dict.\n  3. Saves the gin config to the gin/{step_name}.gin file.\n  4. Saves the gin config dict to json/config_{step_name}.json file.\n  5. Saves the results_dict to the json/results_{step_name}.json file.\n  6. Aggregates all dicts in json/*.json into a new\n     aggregate/aggregate_results_{step_name}.json file.\n\n  Args:\n    result_directory: String with path to result directory to update.\n    step_name: String with the step name. This will be used as a name space.\n    results_dict: Dictionary with results to be persisted.\n    old_result_directory: String with path to old directory from which to copy\n      results from (if not set to None).\n  \"\"\"", "\n", "json_dir", "=", "os", ".", "path", ".", "join", "(", "result_directory", ",", "\"json\"", ")", "\n", "\n", "# Copy the old output directory to the new one if required.", "\n", "if", "old_result_directory", "is", "not", "None", ":", "\n", "    ", "copydir", "(", "old_result_directory", ",", "result_directory", ")", "\n", "", "else", ":", "\n", "# Creates the output directory if necessary.", "\n", "    ", "if", "not", "tf", ".", "gfile", ".", "IsDirectory", "(", "result_directory", ")", ":", "\n", "      ", "tf", ".", "gfile", ".", "MakeDirs", "(", "result_directory", ")", "\n", "\n", "# Add unique id to the result dict (useful for obtaining unique runs).", "\n", "", "", "results_dict", "[", "\"uuid\"", "]", "=", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", "\n", "\n", "# Save the gin config in the gin format.", "\n", "gin_config_path", "=", "os", ".", "path", ".", "join", "(", "result_directory", ",", "\"gin\"", ",", "\n", "\"{}.gin\"", ".", "format", "(", "step_name", ")", ")", "\n", "save_gin", "(", "gin_config_path", ")", "\n", "\n", "# Save gin config in JSON file for aggregation.", "\n", "gin_json_path", "=", "os", ".", "path", ".", "join", "(", "json_dir", ",", "\"{}_config.json\"", ".", "format", "(", "step_name", ")", ")", "\n", "save_dict", "(", "gin_json_path", ",", "gin_dict", "(", "gin_config_path", ")", ")", "\n", "\n", "# Save the results as a dictionary in JSON.", "\n", "results_json_path", "=", "os", ".", "path", ".", "join", "(", "json_dir", ",", "\n", "\"{}_results.json\"", ".", "format", "(", "step_name", ")", ")", "\n", "save_dict", "(", "results_json_path", ",", "results_dict", ")", "\n", "\n", "# Aggregate all the results present in the result_dir so far.", "\n", "aggregate_dict", "=", "aggregate_json_results", "(", "json_dir", ")", "\n", "aggregate_json_path", "=", "results_json_path", "=", "os", ".", "path", ".", "join", "(", "\n", "result_directory", ",", "\"aggregate\"", ",", "\"{}.json\"", ".", "format", "(", "step_name", ")", ")", "\n", "save_dict", "(", "aggregate_json_path", ",", "aggregate_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results._copy_recursively": [[87, 89], ["distutils.dir_util.copy_tree"], "function", ["None"], ["", "def", "_copy_recursively", "(", "path_to_old_dir", ",", "path_to_new_dir", ")", ":", "\n", "  ", "return", "dir_util", ".", "copy_tree", "(", "path_to_old_dir", ",", "path_to_new_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.copydir": [[91, 102], ["os.path.dirname", "results._copy_recursively", "tensorflow.gfile.IsDirectory", "tensorflow.gfile.MakeDirs"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results._copy_recursively"], ["", "def", "copydir", "(", "path_to_old_dir", ",", "path_to_new_dir", ")", ":", "\n", "  ", "\"\"\"Copies a directory to a new path which is created if necessary.\n\n  Args:\n    path_to_old_dir: String with old directory path.\n    path_to_new_dir: String with new directory path.\n  \"\"\"", "\n", "directory", "=", "os", ".", "path", ".", "dirname", "(", "path_to_new_dir", ")", "\n", "if", "not", "tf", ".", "gfile", ".", "IsDirectory", "(", "directory", ")", ":", "\n", "    ", "tf", ".", "gfile", ".", "MakeDirs", "(", "directory", ")", "\n", "", "_copy_recursively", "(", "path_to_old_dir", ",", "path_to_new_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.save_gin": [[104, 117], ["os.path.dirname", "tensorflow.gfile.IsDirectory", "tensorflow.gfile.MakeDirs", "tensorflow.gfile.GFile", "f.write", "gin.operative_config_str"], "function", ["None"], ["", "def", "save_gin", "(", "config_path", ")", ":", "\n", "  ", "\"\"\"Saves the operative gin config to a gin config file.\n\n  Args:\n    config_path: String with path where to save the gin config.\n  \"\"\"", "\n", "# Ensure that the folder exists.", "\n", "directory", "=", "os", ".", "path", ".", "dirname", "(", "config_path", ")", "\n", "if", "not", "tf", ".", "gfile", ".", "IsDirectory", "(", "directory", ")", ":", "\n", "    ", "tf", ".", "gfile", ".", "MakeDirs", "(", "directory", ")", "\n", "# Save the actual config.", "\n", "", "with", "tf", ".", "gfile", ".", "GFile", "(", "config_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "    ", "f", ".", "write", "(", "gin", ".", "operative_config_str", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.save_dict": [[134, 148], ["os.path.dirname", "tensorflow.gfile.IsDirectory", "tensorflow.gfile.MakeDirs", "tensorflow.gfile.GFile", "simplejson.dump"], "function", ["None"], ["", "", "def", "save_dict", "(", "config_path", ",", "dict_with_info", ")", ":", "\n", "  ", "\"\"\"Saves a dict to a JSON file.\n\n  Args:\n    config_path: String with path where to save the gin config.\n    dict_with_info: Dictionary with keys and values which are safed as strings.\n  \"\"\"", "\n", "# Ensure that the folder exists.", "\n", "directory", "=", "os", ".", "path", ".", "dirname", "(", "config_path", ")", "\n", "if", "not", "tf", ".", "gfile", ".", "IsDirectory", "(", "directory", ")", ":", "\n", "    ", "tf", ".", "gfile", ".", "MakeDirs", "(", "directory", ")", "\n", "# Save the actual config.", "\n", "", "with", "tf", ".", "gfile", ".", "GFile", "(", "config_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "    ", "json", ".", "dump", "(", "dict_with_info", ",", "f", ",", "cls", "=", "Encoder", ",", "indent", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.gin_dict": [[150, 175], ["f.read.split", "gin.operative_config_str", "tensorflow.gfile.GFile", "f.read", "line.split", "line.startswith"], "function", ["None"], ["", "", "def", "gin_dict", "(", "config_path", "=", "None", ")", ":", "\n", "  ", "\"\"\"Returns dict with gin configs based on active config or config file.\n\n  Args:\n    config_path: Path to gin config file. If set to None (default), currently\n      active bindings using gin.operative_config_str() are used.\n\n  Returns:\n    Dictionary with gin bindings as string keys and string values.\n  \"\"\"", "\n", "result", "=", "{", "}", "\n", "# Gin does not allow to directly retrieve a dictionary but it allows to", "\n", "# obtain a string with all active configs in human readable format.", "\n", "if", "config_path", "is", "None", ":", "\n", "    ", "operative_str", "=", "gin", ".", "operative_config_str", "(", ")", "\n", "", "else", ":", "\n", "    ", "with", "tf", ".", "gfile", ".", "GFile", "(", "config_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "      ", "operative_str", "=", "f", ".", "read", "(", ")", "\n", "", "", "for", "line", "in", "operative_str", ".", "split", "(", "\"\\n\"", ")", ":", "\n", "# We need to filter out the auto-generated comments and make sure the line", "\n", "# contains a valid assignment.", "\n", "    ", "if", "not", "line", ".", "startswith", "(", "\"#\"", ")", "and", "\" = \"", "in", "line", ":", "\n", "      ", "key", ",", "value", "=", "line", ".", "split", "(", "\" = \"", ",", "2", ")", "\n", "result", "[", "key", "]", "=", "value", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.namespaced_dict": [[177, 202], ["named_dicts.items", "copy.deepcopy", "inner_dict.items"], "function", ["None"], ["", "def", "namespaced_dict", "(", "base_dict", "=", "None", ",", "**", "named_dicts", ")", ":", "\n", "  ", "\"\"\"Fuses several named dictionaries into one dict by namespacing the keys.\n\n  Example:\n  >> base_dict = {\"!\": \"!!\"}\n  >> numbers = {\"1\": \"one\"}\n  >> chars = {\"a\": \"A\"}\n  >> new_dict = namespaced_dict(base_dict, numbers=numbers, chars=chars)\n  >> # new_dict = {\"!\": \"!!\", \"numbers.1\": \"one\", \"chars.a\": \"A\"}\n\n  Args:\n    base_dict: Base dictionary of which a deepcopy will be use to fuse the named\n      dicts into. If set to None, an empty dict will be used.\n    **named_dicts: Named dictionary of dictionaries that will be namespaced and\n      fused into base_dict. All keys should be string as the new key of any\n      value will be outer key + \".\" + inner key.\n\n  Returns:\n    Dictionary with aggregated items.\n  \"\"\"", "\n", "result", "=", "{", "}", "if", "base_dict", "is", "None", "else", "copy", ".", "deepcopy", "(", "base_dict", ")", "\n", "for", "outer_key", ",", "inner_dict", "in", "named_dicts", ".", "items", "(", ")", ":", "\n", "    ", "for", "inner_key", ",", "value", "in", "inner_dict", ".", "items", "(", ")", ":", "\n", "      ", "result", "[", "\"{}.{}\"", ".", "format", "(", "outer_key", ",", "inner_key", ")", "]", "=", "value", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.aggregate_json_results": [[204, 223], ["re.compile", "tensorflow.compat.v1.gfile.ListDirectory", "results.namespaced_dict", "re.compile.match", "os.path.join", "tensorflow.gfile.GFile", "simplejson.load", "compiled_pattern.match.group"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.namespaced_dict"], ["", "def", "aggregate_json_results", "(", "base_path", ")", ":", "\n", "  ", "\"\"\"Aggregates all the result files in a directory into a namespaced dict.\n\n  Args:\n    base_path: String with the directory containing JSON files that only contain\n      dictionaries.\n\n  Returns:\n    Namespaced dictionary with the results.\n  \"\"\"", "\n", "result", "=", "{", "}", "\n", "compiled_pattern", "=", "re", ".", "compile", "(", "r\"(.*)\\.json\"", ")", "\n", "for", "filename", "in", "gfile", ".", "ListDirectory", "(", "base_path", ")", ":", "\n", "    ", "match", "=", "compiled_pattern", ".", "match", "(", "filename", ")", "\n", "if", "match", ":", "\n", "      ", "path", "=", "os", ".", "path", ".", "join", "(", "base_path", ",", "filename", ")", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "result", "[", "match", ".", "group", "(", "1", ")", "]", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "", "return", "namespaced_dict", "(", "**", "result", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.convolute_hub.convolute_and_save": [[25, 81], ["tensorflow_hub.Module", "convolute_hub._placeholders_from_module", "hub.Module.", "tensorflow_hub.add_signature", "tensorflow.Graph().as_default", "tensorflow_hub.create_module_spec", "tensorflow_hub.Module", "tensorflow.variable_scope", "transform_fn", "tensorflow.contrib.framework.assign_from_checkpoint_fn", "tensorflow.Session", "sess.run", "hub.Module.export", "tensorflow.Graph", "hub.Module.variable_map.items", "k.startswith", "tensorflow.global_variables_initializer", "contrib_framework.assign_from_checkpoint_fn.", "len"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.convolute_hub._placeholders_from_module"], ["def", "convolute_and_save", "(", "module_path", ",", "signature", ",", "export_path", ",", "transform_fn", ",", "\n", "transform_checkpoint_path", ",", "new_signature", "=", "None", ")", ":", "\n", "  ", "\"\"\"Loads TFHub module, convolutes it with transform_fn and saves it again.\n\n  Args:\n    module_path: String with path from which the module is constructed.\n    signature: String with name of signature to use for loaded module.\n    export_path: String with path where to save the final TFHub module.\n    transform_fn: Function that creates the graph to be appended to the loaded\n      TFHub module. The function should take as keyword arguments the tensors\n      returned by the loaded TFHub module. The function should return a\n      dictionary of tensor that will be the output of the new TFHub module.\n    transform_checkpoint_path: Path to checkpoint from which the transformer_fn\n      variables will be read.\n    new_signature: String with new name of signature to use for saved module. If\n      None, `signature` is used instead.\n  \"\"\"", "\n", "if", "new_signature", "is", "None", ":", "\n", "    ", "new_signature", "=", "signature", "\n", "\n", "# We create a module_fn that creates the new TFHub module.", "\n", "", "def", "module_fn", "(", ")", ":", "\n", "    ", "module", "=", "hub", ".", "Module", "(", "module_path", ")", "\n", "inputs", "=", "_placeholders_from_module", "(", "module", ",", "signature", "=", "signature", ")", "\n", "intermediate_tensor", "=", "module", "(", "inputs", ",", "signature", "=", "signature", ",", "as_dict", "=", "True", ")", "\n", "# We need to scope the variables that are created when the transform_fn is", "\n", "# applied.", "\n", "with", "tf", ".", "variable_scope", "(", "\"transform\"", ")", ":", "\n", "      ", "outputs", "=", "transform_fn", "(", "**", "intermediate_tensor", ")", "\n", "", "hub", ".", "add_signature", "(", "name", "=", "new_signature", ",", "inputs", "=", "inputs", ",", "outputs", "=", "outputs", ")", "\n", "\n", "# We create a new graph where we will build the module for export.", "\n", "", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "# Create the module_spec for the export.", "\n", "    ", "spec", "=", "hub", ".", "create_module_spec", "(", "module_fn", ")", "\n", "m", "=", "hub", ".", "Module", "(", "spec", ",", "trainable", "=", "True", ")", "\n", "# We need to recover the scoped variables and remove the scope when loading", "\n", "# from the checkpoint.", "\n", "prefix", "=", "\"transform/\"", "\n", "transform_variables", "=", "{", "\n", "k", "[", "len", "(", "prefix", ")", ":", "]", ":", "v", "\n", "for", "k", ",", "v", "in", "m", ".", "variable_map", ".", "items", "(", ")", "\n", "if", "k", ".", "startswith", "(", "prefix", ")", "\n", "}", "\n", "if", "transform_variables", ":", "\n", "      ", "init_fn", "=", "contrib_framework", ".", "assign_from_checkpoint_fn", "(", "\n", "transform_checkpoint_path", ",", "transform_variables", ")", "\n", "\n", "", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "# Initialize all variables, this also loads the TFHub parameters.", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "# Load the transformer variables from the checkpoint.", "\n", "if", "transform_variables", ":", "\n", "        ", "init_fn", "(", "sess", ")", "\n", "# Export the new TFHub module.", "\n", "", "m", ".", "export", "(", "export_path", ",", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.convolute_hub.save_numpy_arrays_to_checkpoint": [[83, 113], ["tensorflow.Graph().as_default", "dict_with_arrays.items", "tensorflow.train.Saver", "tensorflow.as_dtype", "tensorflow.get_variable", "nodes_to_save.append", "tensorflow.placeholder", "assign_ops.append", "tensorflow.Session", "sess.run", "sess.run", "tf.train.Saver.save", "tensorflow.Graph", "tensorflow.assign", "tensorflow.global_variables_initializer"], "function", ["None"], ["", "", "", "def", "save_numpy_arrays_to_checkpoint", "(", "checkpoint_path", ",", "**", "dict_with_arrays", ")", ":", "\n", "  ", "\"\"\"Saves several NumpyArrays to variables in a TF checkpoint.\n\n  Args:\n    checkpoint_path: String with the path to the checkpoint file.\n    **dict_with_arrays: Dictionary with keys that signify variable names and\n      values that are the corresponding Numpy arrays to be saved.\n  \"\"\"", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "    ", "feed_dict", "=", "{", "}", "\n", "assign_ops", "=", "[", "]", "\n", "nodes_to_save", "=", "[", "]", "\n", "for", "array_name", ",", "array", "in", "dict_with_arrays", ".", "items", "(", ")", ":", "\n", "# We will save the numpy array with the corresponding dtype.", "\n", "      ", "tf_dtype", "=", "tf", ".", "as_dtype", "(", "array", ".", "dtype", ")", "\n", "# We create a variable which we would like to persist in the checkpoint.", "\n", "node", "=", "tf", ".", "get_variable", "(", "array_name", ",", "shape", "=", "array", ".", "shape", ",", "dtype", "=", "tf_dtype", ")", "\n", "nodes_to_save", ".", "append", "(", "node", ")", "\n", "# We feed the numpy arrays into the graph via placeholder which avoids", "\n", "# adding the numpy arrays to the graph as constants.", "\n", "placeholder", "=", "tf", ".", "placeholder", "(", "tf_dtype", ",", "shape", "=", "array", ".", "shape", ")", "\n", "feed_dict", "[", "placeholder", "]", "=", "array", "\n", "# We use the placeholder to assign the variable the intended value.", "\n", "assign_ops", ".", "append", "(", "tf", ".", "assign", "(", "node", ",", "placeholder", ")", ")", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "nodes_to_save", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "assign_ops", ",", "feed_dict", "=", "feed_dict", ")", "\n", "saver", ".", "save", "(", "sess", ",", "checkpoint_path", ")", "\n", "", "", "assert", "saver", ".", "last_checkpoints", "[", "0", "]", "==", "checkpoint_path", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.convolute_hub._placeholders_from_module": [[115, 122], ["tfhub_module.get_input_info_dict", "tfhub_module.get_input_info_dict.items", "tensorflow.placeholder", "value.get_shape"], "function", ["None"], ["", "def", "_placeholders_from_module", "(", "tfhub_module", ",", "signature", ")", ":", "\n", "  ", "\"\"\"Returns a dictionary with placeholder nodes for a given TFHub module.\"\"\"", "\n", "info_dict", "=", "tfhub_module", ".", "get_input_info_dict", "(", "signature", "=", "signature", ")", "\n", "result", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "info_dict", ".", "items", "(", ")", ":", "\n", "    ", "result", "[", "key", "]", "=", "tf", ".", "placeholder", "(", "value", ".", "dtype", ",", "shape", "=", "value", ".", "get_shape", "(", ")", ",", "name", "=", "key", ")", "\n", "", "return", "result", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep": [[25, 28], ["None"], "function", ["None"], ["def", "sweep", "(", "name", ",", "values", ")", ":", "\n", "  ", "\"\"\"Sweeps the hyperparameter across different values.\"\"\"", "\n", "return", "[", "{", "name", ":", "value", "}", "for", "value", "in", "values", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.categorical": [[30, 33], ["None"], "function", ["None"], ["", "def", "categorical", "(", "items", ")", ":", "\n", "  ", "\"\"\"Defines sweep over categorical variable.\"\"\"", "\n", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete": [[35, 38], ["None"], "function", ["None"], ["", "def", "discrete", "(", "items", ")", ":", "\n", "  ", "\"\"\"Sweeps over discrete variable.\"\"\"", "\n", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed": [[40, 43], ["six.moves.range"], "function", ["None"], ["", "def", "fixed", "(", "name", ",", "value", ",", "length", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates fixed hyperparameter setting.\"\"\"", "\n", "return", "[", "{", "name", ":", "value", "}", "for", "_", "in", "range", "(", "length", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit": [[45, 66], ["hyperparams.zipit", "six.moves.zip", "len", "len", "len", "new_dict.update", "new_dict.update", "result.append", "len", "len", "len", "len", "ValueError"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit"], ["", "def", "zipit", "(", "list_of_items", ")", ":", "\n", "  ", "\"\"\"Zips different hyperparameter settings.\"\"\"", "\n", "if", "len", "(", "list_of_items", ")", "==", "1", ":", "\n", "    ", "return", "list_of_items", "[", "0", "]", "\n", "", "main_items", "=", "list_of_items", "[", "0", "]", "\n", "other_items", "=", "zipit", "(", "list_of_items", "[", "1", ":", "]", ")", "\n", "if", "len", "(", "main_items", ")", "!=", "len", "(", "other_items", ")", ":", "\n", "    ", "if", "len", "(", "main_items", ")", "==", "1", ":", "\n", "      ", "main_items", "*=", "len", "(", "other_items", ")", "\n", "", "elif", "len", "(", "other_items", ")", "==", "1", ":", "\n", "      ", "other_items", "*=", "len", "(", "main_items", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"Cannot zip lists of different lengths.\"", ")", "\n", "\n", "", "", "result", "=", "[", "]", "\n", "for", "main_dict", ",", "other_dict", "in", "zip", "(", "main_items", ",", "other_items", ")", ":", "\n", "    ", "new_dict", "=", "{", "}", "\n", "new_dict", ".", "update", "(", "main_dict", ")", "\n", "new_dict", ".", "update", "(", "other_dict", ")", "\n", "result", ".", "append", "(", "new_dict", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.chainit": [[68, 74], ["result.extend"], "function", ["None"], ["", "def", "chainit", "(", "list_of_items", ")", ":", "\n", "  ", "\"\"\"Chains different hyperparameter settings.\"\"\"", "\n", "result", "=", "[", "]", "\n", "for", "items", "in", "list_of_items", ":", "\n", "    ", "result", ".", "extend", "(", "items", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.product": [[76, 89], ["hyperparams.product", "len", "new_dict.update", "new_dict.update", "result.append"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.product"], ["", "def", "product", "(", "list_of_items", ")", ":", "\n", "  ", "\"\"\"Creates outer product of hyperparameter settings.\"\"\"", "\n", "if", "len", "(", "list_of_items", ")", "==", "1", ":", "\n", "    ", "return", "list_of_items", "[", "0", "]", "\n", "", "result", "=", "[", "]", "\n", "other_items", "=", "product", "(", "list_of_items", "[", "1", ":", "]", ")", "\n", "for", "first_dict", "in", "list_of_items", "[", "0", "]", ":", "\n", "    ", "for", "second_dict", "in", "other_items", ":", "\n", "      ", "new_dict", "=", "{", "}", "\n", "new_dict", ".", "update", "(", "first_dict", ")", "\n", "new_dict", ".", "update", "(", "second_dict", ")", "\n", "result", ".", "append", "(", "new_dict", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.to_bindings": [[91, 95], ["hyperparams._escape_value", "items.items"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams._escape_value"], ["", "def", "to_bindings", "(", "items", ")", ":", "\n", "  ", "return", "[", "\n", "\"{} = {}\"", ".", "format", "(", "key", ",", "_escape_value", "(", "value", ")", ")", "\n", "for", "key", ",", "value", "in", "items", ".", "items", "(", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams._escape_value": [[98, 102], ["str", "isinstance", "value.startswith"], "function", ["None"], ["", "def", "_escape_value", "(", "value", ")", ":", "\n", "  ", "if", "isinstance", "(", "value", ",", "(", "str", ",", "six", ".", "text_type", ")", ")", "and", "not", "value", ".", "startswith", "(", "\"@\"", ")", ":", "\n", "    ", "return", "\"'{}'\"", ".", "format", "(", "value", ")", "\n", "", "return", "str", "(", "value", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.postprocessing.methods.mean_representation": [[29, 61], ["gin.configurable"], "function", ["None"], ["@", "gin", ".", "configurable", "(", "\n", "\"mean_representation\"", ",", "\n", "blacklist", "=", "[", "\"ground_truth_data\"", ",", "\"gaussian_encoder\"", ",", "\"random_state\"", "]", ")", "\n", "def", "mean_representation", "(", "\n", "ground_truth_data", ",", "\n", "gaussian_encoder", ",", "\n", "random_state", ",", "\n", "save_path", ",", "\n", ")", ":", "\n", "  ", "\"\"\"Extracts the mean representation from a Gaussian encoder.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    gaussian_encoder: Function that takes observations as input and outputs a\n      dictionary with mean and log variances of the encodings in the keys \"mean\"\n      and \"logvar\" respectively.\n    random_state: Numpy random state used for randomness.\n    save_path: String with path where results can be saved.\n\n  Returns:\n    transform_fn: Function that takes as keyword arguments the \"mean\" and\n      \"logvar\" tensors and returns a tensor with the representation.\n    None as no variables are saved.\n\n  \"\"\"", "\n", "del", "ground_truth_data", ",", "gaussian_encoder", ",", "random_state", ",", "save_path", "\n", "\n", "def", "transform_fn", "(", "mean", ",", "logvar", ")", ":", "\n", "    ", "del", "logvar", "\n", "return", "mean", "\n", "\n", "", "return", "transform_fn", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.postprocessing.methods.sampled_representation": [[63, 90], ["gin.configurable", "tensorflow.add", "tensorflow.exp", "tensorflow.random_normal", "tensorflow.shape"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"sampled_representation\"", ",", "\n", "blacklist", "=", "[", "\"ground_truth_data\"", ",", "\"gaussian_encoder\"", ",", "\"random_state\"", "]", ")", "\n", "def", "sampled_representation", "(", "ground_truth_data", ",", "gaussian_encoder", ",", "random_state", ",", "\n", "save_path", ")", ":", "\n", "  ", "\"\"\"Extracts the random representation from a Gaussian encoder.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    gaussian_encoder: Function that takes observations as input and outputs a\n      dictionary with mean and log variances of the encodings in the keys \"mean\"\n      and \"logvar\" respectively.\n    random_state: Numpy random state used for randomness.\n    save_path: String with path where results can be saved.\n\n  Returns:\n    transform_fn: Function that takes as keyword arguments the \"mean\" and\n      \"logvar\" tensors and returns a tensor with the representation.\n    None as no variables are saved.\n  \"\"\"", "\n", "del", "ground_truth_data", ",", "gaussian_encoder", ",", "random_state", ",", "save_path", "\n", "\n", "def", "transform_fn", "(", "mean", ",", "logvar", ")", ":", "\n", "    ", "return", "tf", ".", "add", "(", "mean", ",", "\n", "tf", ".", "exp", "(", "logvar", "/", "2", ")", "*", "tf", ".", "random_normal", "(", "tf", ".", "shape", "(", "mean", ")", ",", "0", ",", "1", ")", ")", "\n", "\n", "", "return", "transform_fn", ",", "None", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.postprocessing.postprocess_test.PostprocessTest.setUp": [[30, 37], ["super().setUp", "disentanglement_lib.methods.unsupervised.train.train_with_gin", "postprocess_test.PostprocessTest.create_tempdir", "disentanglement_lib.utils.resources.get_file"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.validation.validation_test.ValidateTest.setUp", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train_with_gin", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file"], ["  ", "def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "PostprocessTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "self", ".", "model_dir", "=", "self", ".", "create_tempdir", "(", "\n", "\"model\"", ",", "cleanup", "=", "absltest", ".", "TempFileCleanup", ".", "OFF", ")", ".", "full_path", "\n", "train", ".", "train_with_gin", "(", "self", ".", "model_dir", ",", "True", ",", "[", "\n", "resources", ".", "get_file", "(", "\"config/tests/methods/unsupervised/train_test.gin\"", ")", "\n", "]", ",", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.postprocessing.postprocess_test.PostprocessTest.test_postprocess": [[38, 49], ["absl.testing.parameterized.parameters", "gin.clear_config", "disentanglement_lib.postprocessing.postprocess.postprocess_with_gin", "list", "disentanglement_lib.utils.resources.get_files_in_folder", "postprocess_test.PostprocessTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.postprocessing.postprocess.postprocess_with_gin", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_files_in_folder"], ["", "@", "parameterized", ".", "parameters", "(", "\n", "list", "(", "\n", "resources", ".", "get_files_in_folder", "(", "\n", "\"config/tests/postprocessing/postprocess_test_configs\"", ")", ")", ")", "\n", "def", "test_postprocess", "(", "self", ",", "gin_config", ")", ":", "\n", "# We clear the gin config before running. Otherwise, if a prior test fails,", "\n", "# the gin config is locked and the current test fails.", "\n", "    ", "gin", ".", "clear_config", "(", ")", "\n", "postprocess", ".", "postprocess_with_gin", "(", "self", ".", "model_dir", ",", "\n", "self", ".", "create_tempdir", "(", ")", ".", "full_path", ",", "True", ",", "\n", "[", "gin_config", "]", ",", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.postprocessing.postprocess.postprocess_with_gin": [[33, 58], ["gin.parse_config_files_and_bindings", "postprocess.postprocess", "gin.clear_config"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.postprocessing.postprocess.postprocess"], ["def", "postprocess_with_gin", "(", "model_dir", ",", "\n", "output_dir", ",", "\n", "overwrite", "=", "False", ",", "\n", "gin_config_files", "=", "None", ",", "\n", "gin_bindings", "=", "None", ")", ":", "\n", "  ", "\"\"\"Postprocess a trained model based on the provided gin configuration.\n\n  This function will set the provided gin bindings, call the postprocess()\n  function and clear the gin config. Please see the postprocess() for required\n  gin bindings.\n\n  Args:\n    model_dir: String with path to directory where the model is saved.\n    output_dir: String with the path where the representation should be saved.\n    overwrite: Boolean indicating whether to overwrite output directory.\n    gin_config_files: List of gin config files to load.\n    gin_bindings: List of gin bindings to use.\n  \"\"\"", "\n", "if", "gin_config_files", "is", "None", ":", "\n", "    ", "gin_config_files", "=", "[", "]", "\n", "", "if", "gin_bindings", "is", "None", ":", "\n", "    ", "gin_bindings", "=", "[", "]", "\n", "", "gin", ".", "parse_config_files_and_bindings", "(", "gin_config_files", ",", "gin_bindings", ")", "\n", "postprocess", "(", "model_dir", ",", "output_dir", ",", "overwrite", ")", "\n", "gin", ".", "clear_config", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.postprocessing.postprocess.postprocess": [[60, 139], ["gin.configurable", "tensorflow.gfile.IsDirectory", "time.time", "disentanglement_lib.data.ground_truth.named_data.get_named_ground_truth_data", "os.path.join", "os.path.join", "os.path.join", "dict", "disentanglement_lib.utils.results.update_result_directory", "gin.query_parameter", "os.path.join", "disentanglement_lib.utils.results.gin_dict", "tensorflow_hub.eval_function_for_module", "postprocess_fn", "os.path.join", "disentanglement_lib.utils.convolute_hub.convolute_and_save", "tensorflow.gfile.DeleteRecursively", "ValueError", "gin.unlock_config", "gin.bind_parameter", "f", "numpy.random.RandomState", "gin_dict[].replace", "dict", "numpy.array", "time.time", "f.items"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.named_data.get_named_ground_truth_data", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.update_result_directory", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.gin_dict", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.convolute_hub.convolute_and_save"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"postprocess\"", ",", "blacklist", "=", "[", "\"model_dir\"", ",", "\"output_dir\"", ",", "\"overwrite\"", "]", ")", "\n", "def", "postprocess", "(", "model_dir", ",", "\n", "output_dir", ",", "\n", "overwrite", "=", "False", ",", "\n", "postprocess_fn", "=", "gin", ".", "REQUIRED", ",", "\n", "random_seed", "=", "gin", ".", "REQUIRED", ",", "\n", "name", "=", "\"\"", ")", ":", "\n", "  ", "\"\"\"Loads a trained Gaussian encoder and extracts representation.\n\n  Args:\n    model_dir: String with path to directory where the model is saved.\n    output_dir: String with the path where the representation should be saved.\n    overwrite: Boolean indicating whether to overwrite output directory.\n    postprocess_fn: Function used to extract the representation (see methods.py\n      for examples).\n    random_seed: Integer with random seed used for postprocessing (may be\n      unused).\n    name: Optional string with name of the representation (can be used to name\n      representations).\n  \"\"\"", "\n", "# We do not use the variable 'name'. Instead, it can be used to name", "\n", "# representations as it will be part of the saved gin config.", "\n", "del", "name", "\n", "\n", "# Delete the output directory if it already exists.", "\n", "if", "tf", ".", "gfile", ".", "IsDirectory", "(", "output_dir", ")", ":", "\n", "    ", "if", "overwrite", ":", "\n", "      ", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "output_dir", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"Directory already exists and overwrite is False.\"", ")", "\n", "\n", "# Set up timer to keep track of elapsed time in results.", "\n", "", "", "experiment_timer", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Automatically set the proper data set if necessary. We replace the active", "\n", "# gin config as this will lead to a valid gin config file where the data set", "\n", "# is present.", "\n", "if", "gin", ".", "query_parameter", "(", "\"dataset.name\"", ")", "==", "\"auto\"", ":", "\n", "# Obtain the dataset name from the gin config of the previous step.", "\n", "    ", "gin_config_file", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"results\"", ",", "\"gin\"", ",", "\"train.gin\"", ")", "\n", "gin_dict", "=", "results", ".", "gin_dict", "(", "gin_config_file", ")", "\n", "with", "gin", ".", "unlock_config", "(", ")", ":", "\n", "      ", "gin", ".", "bind_parameter", "(", "\"dataset.name\"", ",", "gin_dict", "[", "\"dataset.name\"", "]", ".", "replace", "(", "\n", "\"'\"", ",", "\"\"", ")", ")", "\n", "", "", "dataset", "=", "named_data", ".", "get_named_ground_truth_data", "(", ")", "\n", "\n", "# Path to TFHub module of previously trained model.", "\n", "module_path", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"tfhub\"", ")", "\n", "with", "hub", ".", "eval_function_for_module", "(", "module_path", ")", "as", "f", ":", "\n", "\n", "    ", "def", "_gaussian_encoder", "(", "x", ")", ":", "\n", "      ", "\"\"\"Encodes images using trained model.\"\"\"", "\n", "# Push images through the TFHub module.", "\n", "output", "=", "f", "(", "dict", "(", "images", "=", "x", ")", ",", "signature", "=", "\"gaussian_encoder\"", ",", "as_dict", "=", "True", ")", "\n", "# Convert to numpy arrays and return.", "\n", "return", "{", "key", ":", "np", ".", "array", "(", "values", ")", "for", "key", ",", "values", "in", "output", ".", "items", "(", ")", "}", "\n", "\n", "# Run the postprocessing function which returns a transformation function", "\n", "# that can be used to create the representation from the mean and log", "\n", "# variance of the Gaussian distribution given by the encoder. Also returns", "\n", "# path to a checkpoint if the transformation requires variables.", "\n", "", "transform_fn", ",", "transform_checkpoint_path", "=", "postprocess_fn", "(", "\n", "dataset", ",", "_gaussian_encoder", ",", "np", ".", "random", ".", "RandomState", "(", "random_seed", ")", ",", "\n", "output_dir", ")", "\n", "\n", "# Takes the \"gaussian_encoder\" signature, extracts the representation and", "\n", "# then saves under the signature \"representation\".", "\n", "tfhub_module_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"tfhub\"", ")", "\n", "convolute_hub", ".", "convolute_and_save", "(", "\n", "module_path", ",", "\"gaussian_encoder\"", ",", "tfhub_module_dir", ",", "transform_fn", ",", "\n", "transform_checkpoint_path", ",", "\"representation\"", ")", "\n", "\n", "# We first copy over all the prior results and configs.", "\n", "", "original_results_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"results\"", ")", "\n", "results_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"results\"", ")", "\n", "results_dict", "=", "dict", "(", "elapsed_time", "=", "time", ".", "time", "(", ")", "-", "experiment_timer", ")", "\n", "results", ".", "update_result_directory", "(", "results_dir", ",", "\"postprocess\"", ",", "results_dict", ",", "\n", "original_results_dir", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_dataset.visualize_dataset": [[28, 72], ["disentanglement_lib.data.ground_truth.named_data.get_named_ground_truth_data", "numpy.random.RandomState", "os.path.join", "six.moves.range", "six.moves.range", "tensorflow.compat.v1.gfile.IsDirectory", "tensorflow.compat.v1.gfile.MakeDirs", "named_data.get_named_ground_truth_data.sample_factors", "named_data.get_named_ground_truth_data.sample_observations_from_factors", "disentanglement_lib.visualize.visualize_util.grid_save_images", "named_data.get_named_ground_truth_data.sample_factors", "enumerate", "disentanglement_lib.visualize.visualize_util.save_animation", "os.path.join", "numpy.repeat", "disentanglement_lib.visualize.visualize_util.cycle_factor", "data.sample_observations_from_factors.append", "numpy.array", "os.path.join", "six.moves.range", "named_data.get_named_ground_truth_data.sample_observations_from_factors"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.named_data.get_named_ground_truth_data", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.grid_save_images", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.save_animation", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.repeat", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.cycle_factor", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors"], ["def", "visualize_dataset", "(", "dataset_name", ",", "output_path", ",", "num_animations", "=", "5", ",", "\n", "num_frames", "=", "20", ",", "fps", "=", "10", ")", ":", "\n", "  ", "\"\"\"Visualizes the data set by saving images to output_path.\n\n  For each latent factor, outputs 16 images where only that latent factor is\n  varied while all others are kept constant.\n\n  Args:\n    dataset_name: String with name of dataset as defined in named_data.py.\n    output_path: String with path in which to create the visualizations.\n    num_animations: Integer with number of distinct animations to create.\n    num_frames: Integer with number of frames in each animation.\n    fps: Integer with frame rate for the animation.\n  \"\"\"", "\n", "data", "=", "named_data", ".", "get_named_ground_truth_data", "(", "dataset_name", ")", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "\n", "# Create output folder if necessary.", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "output_path", ",", "dataset_name", ")", "\n", "if", "not", "gfile", ".", "IsDirectory", "(", "path", ")", ":", "\n", "    ", "gfile", ".", "MakeDirs", "(", "path", ")", "\n", "\n", "# Create still images.", "\n", "", "for", "i", "in", "range", "(", "data", ".", "num_factors", ")", ":", "\n", "    ", "factors", "=", "data", ".", "sample_factors", "(", "16", ",", "random_state", ")", "\n", "indices", "=", "[", "j", "for", "j", "in", "range", "(", "data", ".", "num_factors", ")", "if", "i", "!=", "j", "]", "\n", "factors", "[", ":", ",", "indices", "]", "=", "factors", "[", "0", ",", "indices", "]", "\n", "images", "=", "data", ".", "sample_observations_from_factors", "(", "factors", ",", "random_state", ")", "\n", "visualize_util", ".", "grid_save_images", "(", "\n", "images", ",", "os", ".", "path", ".", "join", "(", "path", ",", "\"variations_of_factor%s.png\"", "%", "i", ")", ")", "\n", "\n", "# Create animations.", "\n", "", "for", "i", "in", "range", "(", "num_animations", ")", ":", "\n", "    ", "base_factor", "=", "data", ".", "sample_factors", "(", "1", ",", "random_state", ")", "\n", "images", "=", "[", "]", "\n", "for", "j", ",", "num_atoms", "in", "enumerate", "(", "data", ".", "factors_num_values", ")", ":", "\n", "      ", "factors", "=", "np", ".", "repeat", "(", "base_factor", ",", "num_frames", ",", "axis", "=", "0", ")", "\n", "factors", "[", ":", ",", "j", "]", "=", "visualize_util", ".", "cycle_factor", "(", "base_factor", "[", "0", ",", "j", "]", ",", "num_atoms", ",", "\n", "num_frames", ")", "\n", "images", ".", "append", "(", "data", ".", "sample_observations_from_factors", "(", "factors", ",", "\n", "random_state", ")", ")", "\n", "", "visualize_util", ".", "save_animation", "(", "np", ".", "array", "(", "images", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "\"animation%d.gif\"", "%", "i", ")", ",", "\n", "fps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util_test.VisualizeUtilTest.test_save_image": [[28, 32], ["numpy.zeros", "os.path.join", "disentanglement_lib.visualize.visualize_util.save_image", "visualize_util_test.VisualizeUtilTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.save_image"], ["  ", "def", "test_save_image", "(", "self", ")", ":", "\n", "    ", "image", "=", "np", ".", "zeros", "(", "(", "128", ",", "256", ",", "3", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "create_tempdir", "(", ")", ".", "full_path", ",", "\"save_image.png\"", ")", "\n", "visualize_util", ".", "save_image", "(", "image", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util_test.VisualizeUtilTest.test_save_image_grayscale": [[33, 38], ["numpy.ones", "os.path.join", "disentanglement_lib.visualize.visualize_util.save_image", "visualize_util_test.VisualizeUtilTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.save_image"], ["", "def", "test_save_image_grayscale", "(", "self", ")", ":", "\n", "    ", "image", "=", "np", ".", "ones", "(", "(", "128", ",", "256", ",", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "create_tempdir", "(", ")", ".", "full_path", ",", "\n", "\"save_image_grayscale.png\"", ")", "\n", "visualize_util", ".", "save_image", "(", "image", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util_test.VisualizeUtilTest.test_grid_save_images": [[39, 43], ["numpy.zeros", "os.path.join", "disentanglement_lib.visualize.visualize_util.grid_save_images", "visualize_util_test.VisualizeUtilTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.grid_save_images"], ["", "def", "test_grid_save_images", "(", "self", ")", ":", "\n", "    ", "images", "=", "np", ".", "zeros", "(", "(", "18", ",", "128", ",", "256", ",", "3", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "create_tempdir", "(", ")", ".", "full_path", ",", "\"grid_save_images.png\"", ")", "\n", "visualize_util", ".", "grid_save_images", "(", "images", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util_test.VisualizeUtilTest.test_save_animation": [[44, 48], ["os.path.join", "numpy.ones", "disentanglement_lib.visualize.visualize_util.save_animation", "visualize_util_test.VisualizeUtilTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.save_animation"], ["", "def", "test_save_animation", "(", "self", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "create_tempdir", "(", ")", ".", "full_path", ",", "\"animation.gif\"", ")", "\n", "images", "=", "np", ".", "ones", "(", "(", "18", ",", "128", ",", "256", ",", "3", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "visualize_util", ".", "save_animation", "(", "[", "images", ",", "images", "]", ",", "path", ",", "fps", "=", "18", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util_test.VisualizeUtilTest.cycle_factor": [[49, 53], ["list", "visualize_util_test.VisualizeUtilTest.assertAllEqual", "disentanglement_lib.visualize.visualize_util.cycle_factor"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.cycle_factor"], ["", "def", "cycle_factor", "(", "self", ")", ":", "\n", "    ", "result", "=", "list", "(", "visualize_util", ".", "cycle_factor", "(", "1", ",", "3", ",", "4", ")", ")", "\n", "shouldbe", "=", "[", "1", ",", "2", ",", "2", ",", "1", ",", "0", ",", "0", "]", "\n", "self", ".", "assertAllEqual", "(", "result", ",", "shouldbe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores.heat_square": [[33, 86], ["seaborn.set_context", "seaborn.set_style", "matplotlib.subplots", "matplotlib.GridSpec", "matplotlib.subplot", "seaborn.color_palette", "visualize_scores.plot_matrix_squares", "matplotlib.xticks", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.subplot", "visualize_scores.plot_bar_palette", "os.path.join", "numpy.max", "range", "matplotlib.yticks", "matplotlib.yticks", "tensorflow.gfile.IsDirectory", "tensorflow.gfile.MakeDirs", "tensorflow.gfile.Open", "fig.savefig", "numpy.max", "ValueError", "range", "range", "fig.get_dpi", "fig.get_size_inches", "plt.subplot.get_position", "plt.subplot.get_position"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores.plot_matrix_squares", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores.plot_bar_palette"], ["def", "heat_square", "(", "matrix", ",", "output_dir", ",", "name", ",", "xlabel", ",", "ylabel", ",", "max_val", "=", "None", ",", "\n", "factor_names", "=", "None", ")", ":", "\n", "  ", "\"\"\"Plot values of a matrix.\n\n  Each entry is represented as a square of increasing size and different color.\n\n  Args:\n    matrix: Matrix of values to plot. Values should be in range [0, max_val].\n    output_dir: Where to save the image.\n    name: File name.\n    xlabel: Name of the x axis of the matrix.\n    ylabel: Name of the y axis of the matrix.\n    max_val: Maximum value acceptable in the matrix. If None, the max_val will\n      be set as the maximum value in the matrix.\n    factor_names: Names of the factors of variation.\n  \"\"\"", "\n", "sns", ".", "set_context", "(", "\"notebook\"", ",", "font_scale", "=", "1.5", ",", "rc", "=", "{", "\"lines.linewidth\"", ":", "2", "}", ")", "\n", "sns", ".", "set_style", "(", "\"whitegrid\"", ")", "\n", "fig", ",", "_", "=", "plt", ".", "subplots", "(", ")", "\n", "plot_grid", "=", "plt", ".", "GridSpec", "(", "1", ",", "15", ",", "hspace", "=", "0.2", ",", "wspace", "=", "1.2", ")", "\n", "ax", "=", "plt", ".", "subplot", "(", "plot_grid", "[", ":", ",", ":", "-", "1", "]", ")", "\n", "if", "max_val", "is", "None", ":", "\n", "    ", "max_val", "=", "np", ".", "max", "(", "matrix", ")", "\n", "if", "max_val", "==", "0", ":", "\n", "      ", "max_val", "=", "1.", "\n", "", "", "else", ":", "\n", "    ", "if", "max_val", "<", "np", ".", "max", "(", "matrix", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"The matrix has maximum value larger than max_val\"", ")", "\n", "", "", "palette", "=", "sns", ".", "color_palette", "(", "\"Blues\"", ",", "256", ")", "\n", "# Estimates the area of the squares: the length of the edge is", "\n", "# roughly: length of the grid in inches * how many points per inch - space for", "\n", "# the axis names times * 14/15 as the last 1/15 part of the figure is occupied", "\n", "# by the colorbar legend.", "\n", "size_scale", "=", "(", "(", "(", "(", "ax", ".", "get_position", "(", ")", ".", "xmax", "-", "ax", ".", "get_position", "(", ")", ".", "xmin", ")", "*", "\n", "fig", ".", "get_size_inches", "(", ")", "[", "0", "]", "*", "fig", ".", "get_dpi", "(", ")", "-", "40", ")", "*", "14", "/", "15", "*", "0.8", ")", "/", "\n", "(", "matrix", ".", "shape", "[", "0", "]", ")", ")", "**", "2", "\n", "plot_matrix_squares", "(", "matrix", ",", "max_val", ",", "palette", ",", "size_scale", ",", "ax", ")", "\n", "plt", ".", "xticks", "(", "range", "(", "matrix", ".", "shape", "[", "0", "]", ")", ")", "\n", "if", "factor_names", "is", "not", "None", ":", "\n", "    ", "plt", ".", "yticks", "(", "range", "(", "matrix", ".", "shape", "[", "1", "]", ")", ",", "factor_names", ")", "\n", "", "else", ":", "\n", "    ", "plt", ".", "yticks", "(", "range", "(", "matrix", ".", "shape", "[", "1", "]", ")", ")", "\n", "", "plt", ".", "xlabel", "(", "xlabel", ")", "\n", "plt", ".", "ylabel", "(", "ylabel", ")", "\n", "# Add color legend on the right side of the plot.", "\n", "ax", "=", "plt", ".", "subplot", "(", "plot_grid", "[", ":", ",", "-", "1", "]", ")", "\n", "plot_bar_palette", "(", "palette", ",", "max_val", ",", "ax", ")", "\n", "\n", "if", "not", "tf", ".", "gfile", ".", "IsDirectory", "(", "output_dir", ")", ":", "\n", "    ", "tf", ".", "gfile", ".", "MakeDirs", "(", "output_dir", ")", "\n", "", "output_path", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"{}.png\"", ".", "format", "(", "name", ")", ")", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "output_path", ",", "\"wb\"", ")", "as", "path", ":", "\n", "    ", "fig", ".", "savefig", "(", "path", ",", "bbox_inches", "=", "\"tight\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores.plot_matrix_squares": [[88, 115], ["pandas.melt", "ax.scatter", "ax.set_xticks", "ax.set_yticks", "ax.grid", "ax.grid", "ax.set_xlim", "ax.set_ylim", "ax.tick_params", "ax.set_aspect", "pandas.DataFrame().reset_index", "int", "tmp[].apply", "pandas.DataFrame", "range", "range"], "function", ["None"], ["", "", "def", "plot_matrix_squares", "(", "matrix", ",", "max_val", ",", "palette", ",", "size_scale", ",", "ax", ")", ":", "\n", "  ", "\"\"\"Grid of squares where the size is proportional to the matrix values.\n\n  Args:\n    matrix: Matrix of values to plot.\n    max_val: Maximum value that is allowed in the matrix.\n    palette: Color palette.\n    size_scale: Maximum size of the squares.\n    ax: Axis of the subplot.\n  \"\"\"", "\n", "tmp", "=", "pd", ".", "melt", "(", "pd", ".", "DataFrame", "(", "matrix", ")", ".", "reset_index", "(", ")", ",", "id_vars", "=", "\"index\"", ")", "\n", "# The columns of the dataframe are: index, variable and value.", "\n", "def", "to_color", "(", "val", ")", ":", "\n", "    ", "ind", "=", "int", "(", "val", "/", "max_val", "*", "255", ")", "\n", "return", "palette", "[", "ind", "]", "\n", "", "ax", ".", "scatter", "(", "x", "=", "tmp", "[", "\"index\"", "]", ",", "y", "=", "tmp", "[", "\"variable\"", "]", ",", "\n", "s", "=", "size_scale", "*", "tmp", "[", "\"value\"", "]", "/", "max_val", ",", "marker", "=", "\"s\"", ",", "\n", "c", "=", "tmp", "[", "\"value\"", "]", ".", "apply", "(", "to_color", ")", ")", "\n", "ax", ".", "set_xticks", "(", "[", "v", "+", "0.5", "for", "v", "in", "range", "(", "matrix", ".", "shape", "[", "0", "]", ")", "]", ",", "minor", "=", "True", ")", "\n", "ax", ".", "set_yticks", "(", "[", "v", "+", "0.5", "for", "v", "in", "range", "(", "matrix", ".", "shape", "[", "1", "]", ")", "]", ",", "minor", "=", "True", ")", "\n", "\n", "ax", ".", "grid", "(", "False", ",", "\"major\"", ")", "\n", "ax", ".", "grid", "(", "True", ",", "\"minor\"", ")", "\n", "ax", ".", "set_xlim", "(", "[", "-", "0.5", ",", "matrix", ".", "shape", "[", "0", "]", "-", "0.5", "]", ")", "\n", "ax", ".", "set_ylim", "(", "[", "-", "0.5", ",", "matrix", ".", "shape", "[", "1", "]", "-", "0.5", "]", ")", "\n", "ax", ".", "tick_params", "(", "right", "=", "False", ",", "top", "=", "False", ",", "left", "=", "False", ",", "bottom", "=", "False", ")", "\n", "ax", ".", "set_aspect", "(", "aspect", "=", "1.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores.plot_bar_palette": [[117, 132], ["numpy.linspace", "ax.barh", "ax.set_xlim", "ax.set_ylim", "ax.grid", "ax.set_xticks", "ax.set_yticks", "ax.yaxis.tick_right", "len", "numpy.array", "numpy.linspace", "len"], "function", ["None"], ["", "def", "plot_bar_palette", "(", "palette", ",", "max_val", ",", "ax", ")", ":", "\n", "  ", "\"\"\"Plot color bar legend.\"\"\"", "\n", "col_x", "=", "[", "0", "]", "*", "len", "(", "palette", ")", "\n", "bar_y", "=", "np", ".", "linspace", "(", "0", ",", "max_val", ",", "256", ",", "ax", ")", "\n", "\n", "bar_height", "=", "bar_y", "[", "1", "]", "-", "bar_y", "[", "0", "]", "\n", "ax", ".", "barh", "(", "bar_y", ",", "np", ".", "array", "(", "[", "5", "]", "*", "len", "(", "palette", ")", ")", ",", "height", "=", "bar_height", ",", "left", "=", "col_x", ",", "\n", "align", "=", "\"center\"", ",", "color", "=", "palette", ",", "linewidth", "=", "0", ")", "\n", "\n", "ax", ".", "set_xlim", "(", "1", ",", "2", ")", "\n", "ax", ".", "set_ylim", "(", "0", ",", "max_val", ")", "\n", "ax", ".", "grid", "(", "False", ")", "\n", "ax", ".", "set_xticks", "(", "[", "]", ")", "\n", "ax", ".", "set_yticks", "(", "np", ".", "linspace", "(", "0", ",", "max_val", ",", "3", ")", ")", "\n", "ax", ".", "yaxis", ".", "tick_right", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores.plot_recovery_vs_independent": [[134, 173], ["seaborn.set_context", "seaborn.set_style", "matplotlib.subplots", "seaborn.color_palette", "matplotlib.plot", "matplotlib.plot", "range", "matplotlib.xticks", "ax.set_ylim", "ax.tick_params", "ax.set_yticks", "matplotlib.legend", "matplotlib.xlabel", "matplotlib.ylabel", "os.path.join", "numpy.sort", "visualize_scores.precision", "visualize_scores.recall", "range", "range", "numpy.around", "numpy.linspace", "tensorflow.gfile.IsDirectory", "tensorflow.gfile.MakeDirs", "tensorflow.gfile.Open", "fig.savefig", "matrix.flatten"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores.precision", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores.recall"], ["", "def", "plot_recovery_vs_independent", "(", "matrix", ",", "output_dir", ",", "name", ")", ":", "\n", "  ", "\"\"\"Plot how many factors are recovered and in how many independent groups.\n\n  Plot how many factors of variation are independently captured in a\n  representation at different thresholds. It takes as input a matrix\n  relating factors of variation and latent dimensions, sort the elements and\n  then plot for each threshold (1) how many factors are discovered and (2)\n  how many factors are encoded independently in the representation.\n\n  Args:\n    matrix: Contains statistical relations between factors of variation and\n      latent codes.\n    output_dir: Output directory where to save the plot.\n    name: Filename of the plot.\n  \"\"\"", "\n", "thresholds", "=", "np", ".", "sort", "(", "matrix", ".", "flatten", "(", ")", ")", "[", ":", ":", "-", "1", "]", "\n", "precisions", "=", "[", "precision", "(", "matrix", ",", "x", ")", "for", "x", "in", "thresholds", "]", "\n", "recalls", "=", "[", "recall", "(", "matrix", ",", "x", ")", "for", "x", "in", "thresholds", "]", "\n", "sns", ".", "set_context", "(", "\"notebook\"", ",", "font_scale", "=", "1.5", ",", "rc", "=", "{", "\"lines.linewidth\"", ":", "2", "}", ")", "\n", "sns", ".", "set_style", "(", "\"whitegrid\"", ")", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "palette", "=", "sns", ".", "color_palette", "(", ")", "\n", "plt", ".", "plot", "(", "range", "(", "thresholds", ".", "shape", "[", "0", "]", ")", ",", "precisions", ",", "label", "=", "\"Independent groups\"", ",", "\n", "color", "=", "palette", "[", "0", "]", ",", "linewidth", "=", "3", ")", "\n", "plt", ".", "plot", "(", "range", "(", "thresholds", ".", "shape", "[", "0", "]", ")", ",", "recalls", ",", "\"--\"", ",", "label", "=", "\"Discovered\"", ",", "\n", "color", "=", "palette", "[", "1", "]", ",", "linewidth", "=", "3", ")", "\n", "thresholds_ids", "=", "range", "(", "0", ",", "thresholds", ".", "shape", "[", "0", "]", ",", "10", ")", "\n", "plt", ".", "xticks", "(", "thresholds_ids", ",", "np", ".", "around", "(", "thresholds", "[", "thresholds_ids", "]", ",", "2", ")", ")", "\n", "ax", ".", "set_ylim", "(", "[", "0", ",", "matrix", ".", "shape", "[", "0", "]", "*", "1.1", "]", ")", "\n", "ax", ".", "tick_params", "(", "right", "=", "False", ",", "top", "=", "False", ",", "left", "=", "False", ",", "bottom", "=", "False", ")", "\n", "ax", ".", "set_yticks", "(", "np", ".", "linspace", "(", "0", ",", "matrix", ".", "shape", "[", "0", "]", ",", "matrix", ".", "shape", "[", "0", "]", "+", "1", ")", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "\"upper center\"", ",", "bbox_to_anchor", "=", "(", "0.5", ",", "1.25", ")", ",", "ncol", "=", "2", ")", "\n", "plt", ".", "xlabel", "(", "\"Threshold\"", ")", "\n", "plt", ".", "ylabel", "(", "\"Number of Factors\"", ")", "\n", "if", "not", "tf", ".", "gfile", ".", "IsDirectory", "(", "output_dir", ")", ":", "\n", "    ", "tf", ".", "gfile", ".", "MakeDirs", "(", "output_dir", ")", "\n", "", "output_path", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "name", "+", "\".png\"", ")", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "output_path", ",", "\"wb\"", ")", "as", "path", ":", "\n", "    ", "fig", ".", "savefig", "(", "path", ",", "bbox_inches", "=", "\"tight\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores.precision": [[175, 199], ["matrix.copy", "numpy.zeros", "numpy.zeros", "range", "len", "visualize_scores.bfs"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores.bfs"], ["", "", "def", "precision", "(", "matrix", ",", "th", ")", ":", "\n", "  ", "\"\"\"How many independent components are discovered for a given threshold.\n\n  Args:\n    matrix: Adjacency matrix  of shape (num_codes, num_factors) encoding the\n      statistical relations between factors and codes.\n    th: Eliminate all edges smaller than this threshold.\n\n  Returns:\n    Number of connected components.\n  \"\"\"", "\n", "tmp", "=", "matrix", ".", "copy", "(", ")", "\n", "tmp", "[", "tmp", "<", "th", "]", "=", "0", "\n", "factors", "=", "np", ".", "zeros", "(", "tmp", ".", "shape", "[", "0", "]", ")", "\n", "codes", "=", "np", ".", "zeros", "(", "tmp", ".", "shape", "[", "1", "]", ")", "\n", "cc", "=", "0", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "factors", ")", ")", ":", "\n", "    ", "if", "factors", "[", "i", "]", "==", "0", ":", "\n", "      ", "to_visit", "=", "[", "(", "i", ",", "0", ")", "]", "\n", "factors", ",", "codes", ",", "size", "=", "bfs", "(", "tmp", ",", "to_visit", ",", "factors", ",", "codes", ",", "1", ")", "\n", "if", "size", ">", "1", ":", "\n", "        ", "cc", "+=", "1", "\n", "", "", "", "return", "cc", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores.recall": [[201, 218], ["matrix.copy", "numpy.sum", "numpy.sum"], "function", ["None"], ["", "def", "recall", "(", "matrix", ",", "th", ")", ":", "\n", "  ", "\"\"\"How many factors are discovered for a given threshold.\n\n  Counts as many factors of variation are captured in the representation.\n  First, we remove all edges in the adjacency matrix with weight smaller than\n  the threshold. Then, we count how many factors are connected to some codes.\n\n  Args:\n    matrix: Adjacency matrix for the graph.\n    th: Eliminate all edges smaller than this threshold.\n\n  Returns:\n    Number of discovered factors of variation for the given threshold.\n  \"\"\"", "\n", "tmp", "=", "matrix", ".", "copy", "(", ")", "\n", "tmp", "[", "tmp", "<", "th", "]", "=", "0", "\n", "return", "np", ".", "sum", "(", "np", ".", "sum", "(", "tmp", ",", "axis", "=", "1", ")", "!=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores.bfs": [[220, 265], ["to_visit.pop", "range", "range", "len", "len", "to_visit.append", "visualize_scores.bfs", "to_visit.append", "visualize_scores.bfs"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores.bfs", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores.bfs"], ["", "def", "bfs", "(", "matrix", ",", "to_visit", ",", "factors", ",", "codes", ",", "size", ")", ":", "\n", "  ", "\"\"\"Traverse the matrix across connected components.\n\n  Implements breadth first search on an adjacency matrix. In our case, the\n  adjacency matrix encodes the statistical relations between factors of\n  variation and codes. This is used to traverse the adjacency matrix and\n  discover whether a factor is captured in multiple codes and whether there is a\n  path in the graph connecting two factors.\n\n  Args:\n    matrix: Adjacency matrix for the graph.\n    to_visit: Queue with the nodes to visit. We index the factors and codes in\n      the adjacency matrix and implement the queue with an array containing the\n      nodes that need to  be visited.\n    factors: Array of shape (num_factors, ) with flags marking whether factors\n      of variation are visited.\n    codes: Array of shape (num_codes, ) with flags marking whether codes are\n      visited.\n    size: Count how many node are in the same connected component.\n\n  Returns:\n    factors: Array of shape (num_factors, ) with flags marking whether factors\n      of variation are visited.\n    codes: Array of shape (num_codes, ) with flags marking whether codes are\n      visited.\n    size: How many nodes were visited.\n  \"\"\"", "\n", "(", "current_node", ",", "flag", ")", "=", "to_visit", ".", "pop", "(", ")", "\n", "if", "flag", "==", "0", ":", "\n", "    ", "factors", "[", "current_node", "]", "=", "1", "\n", "for", "i", "in", "range", "(", "len", "(", "matrix", "[", "current_node", ",", ":", "]", ")", ")", ":", "\n", "      ", "if", "matrix", "[", "current_node", ",", "i", "]", "!=", "0", ":", "\n", "        ", "if", "codes", "[", "i", "]", "==", "0", ":", "\n", "          ", "to_visit", ".", "append", "(", "(", "i", ",", "1", ")", ")", "\n", "size", "+=", "1", "\n", "factors", ",", "codes", ",", "size", "=", "bfs", "(", "matrix", ",", "to_visit", ",", "factors", ",", "codes", ",", "size", ")", "\n", "", "", "", "", "else", ":", "\n", "    ", "codes", "[", "current_node", "]", "=", "1", "\n", "for", "i", "in", "range", "(", "len", "(", "matrix", "[", ":", ",", "current_node", "]", ")", ")", ":", "\n", "      ", "if", "matrix", "[", "i", ",", "current_node", "]", "!=", "0", ":", "\n", "        ", "if", "factors", "[", "i", "]", "==", "0", ":", "\n", "          ", "to_visit", ".", "append", "(", "(", "i", ",", "0", ")", ")", "\n", "size", "+=", "1", "\n", "factors", ",", "codes", ",", "size", "=", "bfs", "(", "matrix", ",", "to_visit", ",", "factors", ",", "codes", ",", "size", ")", "\n", "", "", "", "", "return", "factors", ",", "codes", ",", "size", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores_test.VisualizeScoresTest.plot_recovery_vs_independent": [[29, 35], ["absl.testing.parameterized.parameters", "disentanglement_lib.visualize.visualize_scores.plot_recovery_vs_independent", "numpy.zeros", "numpy.zeros", "numpy.zeros", "visualize_scores_test.VisualizeScoresTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores_test.VisualizeScoresTest.plot_recovery_vs_independent"], ["  ", "@", "parameterized", ".", "parameters", "(", "(", "np", ".", "zeros", "(", "(", "5", ",", "10", ")", ",", "dtype", "=", "np", ".", "float32", ")", ",", "\n", "np", ".", "zeros", "(", "(", "2", ",", "10", ")", ",", "dtype", "=", "np", ".", "float32", ")", ",", "\n", "np", ".", "zeros", "(", "(", "10", ",", "10", ")", ",", "dtype", "=", "np", ".", "float32", ")", ")", ")", "\n", "def", "plot_recovery_vs_independent", "(", "self", ",", "matrix", ")", ":", "\n", "    ", "visualize_scores", ".", "plot_recovery_vs_independent", "(", "\n", "matrix", ",", "self", ".", "create_tempdir", "(", ")", ".", "full_path", ",", "\"save_image.png\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores_test.ComputeMatrixStatsTest.test_bfs": [[39, 66], ["absl.testing.parameterized.parameters", "numpy.zeros", "numpy.zeros", "disentanglement_lib.visualize.visualize_scores.bfs", "visualize_scores_test.ComputeMatrixStatsTest.assertEqual", "visualize_scores_test.ComputeMatrixStatsTest.assertEqual", "visualize_scores_test.ComputeMatrixStatsTest.assertEqual", "numpy.eye", "numpy.triu", "numpy.ones", "numpy.array", "numpy.array", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores.bfs"], ["  ", "@", "parameterized", ".", "parameters", "(", "\n", "(", "np", ".", "eye", "(", "5", ")", ",", "[", "(", "0", ",", "0", ")", "]", ",", "[", "1", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "[", "1", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "2", ")", ",", "\n", "(", "np", ".", "triu", "(", "np", ".", "ones", "(", "5", ")", ")", ",", "[", "(", "0", ",", "0", ")", "]", ",", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ",", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ",", "10", ")", ",", "\n", "(", "np", ".", "ones", "(", "(", "5", ",", "5", ")", ")", ",", "[", "(", "0", ",", "0", ")", "]", ",", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ",", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ",", "10", ")", ",", "\n", "(", "np", ".", "array", "(", "[", "[", "1", ",", "1", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "1", ",", "1", "]", "]", ")", ",", "\n", "[", "(", "0", ",", "0", ")", "]", ",", "[", "1", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "[", "1", ",", "1", ",", "0", ",", "0", ",", "0", "]", ",", "3", ")", ",", "\n", "(", "np", ".", "array", "(", "[", "[", "1", ",", "1", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "1", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "1", ",", "1", "]", "]", ")", ",", "\n", "[", "(", "0", ",", "0", ")", "]", ",", "[", "1", ",", "0", ",", "0", ",", "1", ",", "0", "]", ",", "[", "1", ",", "1", ",", "0", ",", "0", ",", "0", "]", ",", "4", ")", "\n", ")", "\n", "def", "test_bfs", "(", "self", ",", "matrix", ",", "to_visit", ",", "visited_factors", ",", "visited_codes", ",", "\n", "visited_size", ")", ":", "\n", "    ", "factors", "=", "np", ".", "zeros", "(", "matrix", ".", "shape", "[", "0", "]", ")", "\n", "codes", "=", "np", ".", "zeros", "(", "matrix", ".", "shape", "[", "1", "]", ")", "\n", "factors", ",", "codes", ",", "size", "=", "visualize_scores", ".", "bfs", "(", "\n", "matrix", ",", "to_visit", ",", "factors", ",", "codes", ",", "1", ")", "\n", "\n", "self", ".", "assertEqual", "(", "(", "factors", "==", "visited_factors", ")", ".", "all", "(", ")", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "(", "codes", "==", "visited_codes", ")", ".", "all", "(", ")", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "size", ",", "visited_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores_test.ComputeMatrixStatsTest.test_precision": [[67, 76], ["absl.testing.parameterized.parameters", "disentanglement_lib.visualize.visualize_scores.precision", "visualize_scores_test.ComputeMatrixStatsTest.assertEqual", "numpy.zeros", "numpy.eye", "numpy.triu", "numpy.ones", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores.precision"], ["", "@", "parameterized", ".", "parameters", "(", "\n", "(", "np", ".", "zeros", "(", "(", "5", ",", "5", ")", ")", ",", "0", ")", ",", "\n", "(", "np", ".", "eye", "(", "5", ")", ",", "5", ")", ",", "\n", "(", "np", ".", "triu", "(", "np", ".", "ones", "(", "5", ")", ")", ",", "1", ")", ",", "\n", "(", "np", ".", "ones", "(", "(", "5", ",", "5", ")", ")", ",", "1", ")", "\n", ")", "\n", "def", "test_precision", "(", "self", ",", "matrix", ",", "cc", ")", ":", "\n", "    ", "cc_count", "=", "visualize_scores", ".", "precision", "(", "matrix", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "cc", ",", "cc_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores_test.ComputeMatrixStatsTest.test_recall": [[77, 86], ["absl.testing.parameterized.parameters", "disentanglement_lib.visualize.visualize_scores.recall", "visualize_scores_test.ComputeMatrixStatsTest.assertEqual", "numpy.zeros", "numpy.eye", "numpy.triu", "numpy.ones", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores.recall"], ["", "@", "parameterized", ".", "parameters", "(", "\n", "(", "np", ".", "zeros", "(", "(", "5", ",", "5", ")", ")", ",", "0", ")", ",", "\n", "(", "np", ".", "eye", "(", "5", ")", ",", "5", ")", ",", "\n", "(", "np", ".", "triu", "(", "np", ".", "ones", "(", "5", ")", ")", ",", "5", ")", ",", "\n", "(", "np", ".", "ones", "(", "(", "5", ",", "5", ")", ")", ",", "5", ")", "\n", ")", "\n", "def", "test_recall", "(", "self", ",", "matrix", ",", "cc", ")", ":", "\n", "    ", "cc_count", "=", "visualize_scores", ".", "recall", "(", "matrix", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "cc", ",", "cc_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.dendrogram.dendrogram_plot": [[31, 122], ["pandas.melt", "tmp.to_numpy.to_numpy", "range", "numpy.zeros", "list", "enumerate", "matplotlib.subplots", "scipy.cluster.hierarchy.dendrogram", "zip", "scipy.cluster.hierarchy._plot_dendrogram", "matplotlib.xlabel", "matplotlib.ylabel", "range", "matplotlib.xticks", "dendrogram.report_merges", "pandas.DataFrame().reset_index", "range", "dendrogram._union", "len", "numpy.array", "numpy.around", "tensorflow.gfile.Open", "fig.savefig", "max", "pandas.DataFrame", "tmp[].argsort", "numpy.array"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.dendrogram.report_merges", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.dendrogram._union"], ["def", "dendrogram_plot", "(", "matrix", ",", "output_dir", ",", "factor_names", ")", ":", "\n", "  ", "\"\"\"Make dendrogram plot recording at which threshold factors and codes merge.\n\n  This plotting function produce a dendrogram plot recording at which factors of\n  variation and latent codes are most related by running the union-find\n  algorithm https://en.wikipedia.org/wiki/Disjoint-set_data_structure on the\n  matrix relating factors of variation and latent codes.\n\n  Args:\n    matrix: Input matrix of shape [num_factors, num_codes] encoding the\n      statistical relation between factors and codes.\n    output_dir: Directory to save the plot in.\n    factor_names: Lables for the factors of variation to be used in the plot.\n\n  Returns:\n    Dictionary containing the threshold ID of each merging events and which\n    factors were merged.\n  \"\"\"", "\n", "tmp", "=", "pd", ".", "melt", "(", "pd", ".", "DataFrame", "(", "matrix", ")", ".", "reset_index", "(", ")", ",", "id_vars", "=", "\"index\"", ")", "\n", "# The columns of the dataframe are: index, variable and value.", "\n", "tmp", "=", "tmp", ".", "to_numpy", "(", ")", "\n", "# Sort the matrix by threshold", "\n", "tmp", "=", "tmp", "[", "tmp", "[", ":", ",", "-", "1", "]", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "]", "\n", "# The codes have index code + num_factors.", "\n", "tmp", "[", ":", ",", "1", "]", "+=", "matrix", ".", "shape", "[", "0", "]", "\n", "\n", "# Initialize dictionaries for cluster IDs and size.", "\n", "size", "=", "{", "}", "\n", "cluster_id", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "matrix", ".", "shape", "[", "0", "]", ")", ":", "\n", "    ", "size", "[", "i", "]", "=", "1", "\n", "cluster_id", "[", "i", "]", "=", "i", "\n", "# Initialize dendrogram matrix. Each row is an event, each event is composed", "\n", "# by [cluster_id_1, cluster_id_2, threshold, size of the new cluster]", "\n", "", "z", "=", "np", ".", "zeros", "(", "[", "matrix", ".", "shape", "[", "0", "]", "-", "1", ",", "4", "]", ")", "\n", "# Each factor of variation is in its own tree. So the maximum cluster ID we", "\n", "# have is matrix.shape[0]-1.", "\n", "n_clusters", "=", "matrix", ".", "shape", "[", "0", "]", "-", "1", "\n", "nodes", "=", "list", "(", "range", "(", "matrix", ".", "shape", "[", "0", "]", "+", "matrix", ".", "shape", "[", "1", "]", ")", ")", "\n", "idx_found", "=", "0", "\n", "discovered", "=", "{", "}", "\n", "# Run the Union-Find Algorithm", "\n", "for", "id_i", ",", "i", "in", "enumerate", "(", "tmp", ")", ":", "\n", "# Record if we just discovered a new factor of variation.", "\n", "    ", "if", "i", "[", "0", "]", "not", "in", "discovered", ":", "\n", "      ", "discovered", "[", "i", "[", "0", "]", "]", "=", "id_i", "\n", "# Merge trees.", "\n", "", "z", ",", "cluster_id", ",", "size", ",", "n_clusters", ",", "idx_found", "=", "_union", "(", "\n", "nodes", ",", "i", "[", "0", "]", ",", "i", "[", "1", "]", ",", "id_i", ",", "z", ",", "cluster_id", ",", "size", ",", "matrix", ",", "n_clusters", ",", "\n", "idx_found", ")", "\n", "# Obtain the dendrogram plot data structure from the matrix z", "\n", "", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "dn", "=", "hierarchy", ".", "dendrogram", "(", "z", ",", "ax", "=", "ax", ",", "orientation", "=", "\"left\"", ",", "no_plot", "=", "True", ")", "\n", "# Create a dictionary to map the location on the plot to the leaf", "\n", "id_to_leaf", "=", "{", "}", "\n", "id_conv", "=", "5", "\n", "for", "l", "in", "dn", "[", "\"leaves\"", "]", ":", "\n", "    ", "id_to_leaf", "[", "id_conv", "]", "=", "l", "\n", "id_conv", "+=", "10", "\n", "# Update the dcoord to when the cluster was actually discovered.", "\n", "", "for", "d", ",", "i", "in", "zip", "(", "dn", "[", "\"dcoord\"", "]", ",", "dn", "[", "\"icoord\"", "]", ")", ":", "\n", "    ", "if", "d", "[", "0", "]", "==", "0", ":", "\n", "      ", "idx", "=", "id_to_leaf", "[", "i", "[", "0", "]", "]", "\n", "d", "[", "0", "]", "=", "discovered", "[", "idx", "]", "\n", "", "if", "d", "[", "-", "1", "]", "==", "0", ":", "\n", "      ", "idx", "=", "id_to_leaf", "[", "i", "[", "-", "1", "]", "]", "\n", "d", "[", "-", "1", "]", "=", "discovered", "[", "idx", "]", "\n", "# Set colors to be all the same.", "\n", "", "", "dn", "[", "\"color_list\"", "]", "=", "[", "\"b\"", "]", "*", "len", "(", "dn", "[", "\"color_list\"", "]", ")", "\n", "dn", "[", "\"ivl\"", "]", "=", "np", ".", "array", "(", "factor_names", ")", "[", "dn", "[", "\"leaves\"", "]", "]", "\n", "\n", "hierarchy", ".", "_plot_dendrogram", "(", "dn", "[", "\"icoord\"", "]", ",", "dn", "[", "\"dcoord\"", "]", ",", "dn", "[", "\"ivl\"", "]", ",", "p", "=", "30", ",", "# pylint: disable=protected-access", "\n", "n", "=", "z", ".", "shape", "[", "0", "]", "+", "1", ",", "mh", "=", "max", "(", "z", "[", ":", ",", "2", "]", ")", ",", "\n", "orientation", "=", "\"right\"", ",", "no_labels", "=", "False", ",", "\n", "color_list", "=", "dn", "[", "\"color_list\"", "]", ",", "\n", "leaf_font_size", "=", "None", ",", "\n", "leaf_rotation", "=", "None", ",", "\n", "contraction_marks", "=", "None", ",", "\n", "ax", "=", "ax", ",", "\n", "above_threshold_color", "=", "\"b\"", ")", "\n", "plt", ".", "xlabel", "(", "\"Threshold\"", ")", "\n", "plt", ".", "ylabel", "(", "\"Factor\"", ")", "\n", "thresholds", "=", "tmp", "[", ":", ",", "2", "]", "\n", "thresholds_ids", "=", "range", "(", "0", ",", "thresholds", ".", "shape", "[", "0", "]", ",", "10", ")", "\n", "plt", ".", "xticks", "(", "\n", "thresholds_ids", ",", "\n", "np", ".", "around", "(", "np", ".", "array", "(", "thresholds", ",", "dtype", "=", "\"float32\"", ")", "[", "thresholds_ids", "]", ",", "2", ")", ")", "\n", "output_path", "=", "output_dir", "+", "\".png\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "output_path", ",", "\"wb\"", ")", "as", "path", ":", "\n", "    ", "fig", ".", "savefig", "(", "path", ",", "bbox_inches", "=", "\"tight\"", ")", "\n", "", "return", "report_merges", "(", "z", ",", "matrix", ".", "shape", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.dendrogram.report_merges": [[124, 159], ["range", "range"], "function", ["None"], ["", "def", "report_merges", "(", "z", ",", "num_factors", ")", ":", "\n", "  ", "\"\"\"Saves which factors of variations are merged and at which threshold.\n\n  Args:\n    z: Dendrogram matrix. Each row is an event, each event is composed by\n      [cluster_id_1, cluster_id_2, threshold, size of the new cluster].\n    num_factors: Number of factors of Variations.\n\n  Returns:\n    Dictionary containing the threshold ID of each merging events and which\n    factors were merged.\n  \"\"\"", "\n", "scores", "=", "{", "}", "\n", "id_to_node_list", "=", "{", "}", "\n", "n_clusters", "=", "num_factors", "-", "1", "\n", "for", "i", "in", "range", "(", "num_factors", ")", ":", "\n", "    ", "id_to_node_list", "[", "i", "]", "=", "[", "i", ",", "]", "\n", "", "for", "i", "in", "range", "(", "z", ".", "shape", "[", "0", "]", ")", ":", "\n", "    ", "cluster_id_1", "=", "z", "[", "i", ",", "0", "]", "\n", "cluster_id_2", "=", "z", "[", "i", ",", "1", "]", "\n", "threshold_id", "=", "z", "[", "i", ",", "2", "]", "\n", "list_nodes_1", "=", "id_to_node_list", "[", "cluster_id_1", "]", "\n", "list_nodes_2", "=", "id_to_node_list", "[", "cluster_id_2", "]", "\n", "\n", "for", "node_1", "in", "list_nodes_1", ":", "\n", "      ", "for", "node_2", "in", "list_nodes_2", ":", "\n", "        ", "scores", "[", "\"merge_{}_{}\"", ".", "format", "(", "node_1", ",", "node_2", ")", "]", "=", "threshold_id", "\n", "\n", "", "", "del", "id_to_node_list", "[", "cluster_id_1", "]", "\n", "del", "id_to_node_list", "[", "cluster_id_2", "]", "\n", "n_clusters", "+=", "1", "\n", "\n", "id_to_node_list", "[", "n_clusters", "]", "=", "list_nodes_1", "+", "list_nodes_2", "\n", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.dendrogram._find": [[161, 166], ["dendrogram._find"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.dendrogram._find"], ["", "def", "_find", "(", "nodes", ",", "i", ")", ":", "\n", "  ", "\"\"\"Find function for the Union-Find algorithm.\"\"\"", "\n", "if", "nodes", "[", "i", "]", "!=", "i", ":", "\n", "    ", "nodes", "[", "i", "]", "=", "_find", "(", "nodes", ",", "nodes", "[", "i", "]", ")", "\n", "", "return", "nodes", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.dendrogram._union": [[168, 223], ["dendrogram._find", "dendrogram._find"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.dendrogram._find", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.dendrogram._find"], ["", "def", "_union", "(", "nodes", ",", "idx", ",", "idy", ",", "val", ",", "z", ",", "cluster_id", ",", "size", ",", "matrix", ",", "n_clusters", ",", "\n", "idx_found", ")", ":", "\n", "  ", "\"\"\"Implements the a modification to the union of the Union-Find algorithm.\n\n  In this function we first perform the standard union of the Union-Find\n  algorithm. We mantain the root of the trees with more than 1 element to\n  factors of variation. If two trees rooted at factors of variation gets merged\n  we record the event in the dendrogram matrix.\n\n  Args:\n    nodes: Array with the nodes of the graph. The first num_factors nodes\n      correspond to factors of variation. The rest to codes.\n    idx: First node to eventually merge.\n    idy: Second node to eventually merge.\n    val: Threshold value of the considered edge.\n    z: Dendrogram matrix. Each row is an event, each event is composed by\n      [cluster_id_1, cluster_id_2, threshold, size of the new cluster].\n    cluster_id: Dictionary mapping factors of variation to cluster IDs.\n    size: Dictionary mapping cluster ID to its size.\n    matrix: Matrix of shape  [num_factors, num_codes] on which we compute the\n      dendrogram.\n    n_clusters: How many clusters have been discovered.\n    idx_found: How many evenys have been found.\n\n  Returns:\n    z, cluster_id, size, n_clusters, idx_found\n  \"\"\"", "\n", "parent_idx", "=", "_find", "(", "nodes", ",", "idx", ")", "\n", "parent_idy", "=", "_find", "(", "nodes", ",", "idy", ")", "\n", "# Set the parent node the one with smalles id. This ensures that the trees", "\n", "# roots are on the factors of variations as they have smaller ID. The two", "\n", "# nodes cause a merge if they are not already in the same tree.", "\n", "if", "parent_idx", "!=", "parent_idy", ":", "\n", "    ", "if", "parent_idy", ">", "parent_idx", ":", "\n", "      ", "nodes", "[", "parent_idy", "]", "=", "parent_idx", "\n", "", "else", ":", "\n", "      ", "nodes", "[", "parent_idx", "]", "=", "parent_idy", "\n", "\n", "", "if", "parent_idx", "<", "matrix", ".", "shape", "[", "0", "]", "and", "parent_idy", "<", "matrix", ".", "shape", "[", "0", "]", ":", "\n", "# There is a merge happening on two trees rooted at a factor of variation.", "\n", "# These are the events we need to record. First, we get the cluster id of", "\n", "# the trees:", "\n", "      ", "cc_idx", "=", "cluster_id", "[", "parent_idx", "]", "\n", "cc_idy", "=", "cluster_id", "[", "parent_idy", "]", "\n", "# Now we create a new cluster by merging the two trees. The size will be", "\n", "# the sum of the two subtrees as they are disjoint.", "\n", "n_clusters", "+=", "1", "\n", "size", "[", "n_clusters", "]", "=", "size", "[", "cc_idx", "]", "+", "size", "[", "cc_idy", "]", "\n", "# Update the dendrogram matrix with the new event.", "\n", "z", "[", "idx_found", ",", ":", "]", "=", "[", "cc_idx", ",", "cc_idy", ",", "val", ",", "size", "[", "n_clusters", "]", "]", "\n", "idx_found", "+=", "1", "\n", "# Set the new cluster ID for the parent nodes.", "\n", "cluster_id", "[", "parent_idy", "]", "=", "n_clusters", "\n", "cluster_id", "[", "parent_idx", "]", "=", "n_clusters", "\n", "", "", "return", "z", ",", "cluster_id", ",", "size", ",", "n_clusters", ",", "idx_found", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_irs.vis_all_interventional_effects": [[30, 63], ["disentanglement_lib.evaluation.metrics.irs.scalable_disentanglement_score", "matplotlib.subplots", "range", "fig.tight_layout", "os.path.join", "range", "tensorflow.gfile.IsDirectory", "tensorflow.gfile.MakeDirs", "tensorflow.gfile.Open", "fig.savefig", "visualize_irs._visualize_interventional_effect", "ax.set_title", "visualize_irs._visualize_interventional_effect", "ax.set_title"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.irs.scalable_disentanglement_score", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_irs._visualize_interventional_effect", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_irs._visualize_interventional_effect"], ["def", "vis_all_interventional_effects", "(", "gen_factors", ",", "latents", ",", "output_dir", ")", ":", "\n", "  ", "\"\"\"Compute Matrix of all interventional effects.\"\"\"", "\n", "res", "=", "scalable_disentanglement_score", "(", "gen_factors", ",", "latents", ")", "\n", "parents", "=", "res", "[", "\"parents\"", "]", "\n", "scores", "=", "res", "[", "\"disentanglement_scores\"", "]", "\n", "\n", "fig_width_inches", "=", "3.0", "*", "gen_factors", ".", "shape", "[", "1", "]", "\n", "fig_height_inches", "=", "3.0", "*", "latents", ".", "shape", "[", "1", "]", "\n", "fig", ",", "axes", "=", "plt", ".", "subplots", "(", "\n", "latents", ".", "shape", "[", "1", "]", ",", "\n", "gen_factors", ".", "shape", "[", "1", "]", ",", "\n", "figsize", "=", "(", "fig_width_inches", ",", "fig_height_inches", ")", ",", "\n", "sharex", "=", "\"col\"", ",", "\n", "sharey", "=", "\"row\"", ")", "\n", "\n", "for", "j", "in", "range", "(", "gen_factors", ".", "shape", "[", "1", "]", ")", ":", "# Iterate over generative factors.", "\n", "    ", "for", "l", "in", "range", "(", "latents", ".", "shape", "[", "1", "]", ")", ":", "\n", "      ", "ax", "=", "axes", "[", "l", ",", "j", "]", "\n", "if", "parents", "[", "l", "]", "!=", "j", ":", "\n", "        ", "_visualize_interventional_effect", "(", "\n", "gen_factors", ",", "latents", ",", "l", ",", "parents", "[", "l", "]", ",", "j", ",", "ax", "=", "ax", ",", "plot_legend", "=", "False", ")", "\n", "ax", ".", "set_title", "(", "\"\"", ")", "\n", "", "else", ":", "\n", "        ", "_visualize_interventional_effect", "(", "\n", "gen_factors", ",", "latents", ",", "l", ",", "parents", "[", "l", "]", ",", "j", ",", "no_conditioning", "=", "True", ",", "ax", "=", "ax", ")", "\n", "ax", ".", "set_title", "(", "\"Parent={}, IRS = {:1.2}\"", ".", "format", "(", "parents", "[", "l", "]", ",", "scores", "[", "l", "]", ")", ")", "\n", "\n", "", "", "", "fig", ".", "tight_layout", "(", ")", "\n", "if", "not", "tf", ".", "gfile", ".", "IsDirectory", "(", "output_dir", ")", ":", "\n", "    ", "tf", ".", "gfile", ".", "MakeDirs", "(", "output_dir", ")", "\n", "", "output_path", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"interventional_effect.png\"", ")", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "output_path", ",", "\"wb\"", ")", "as", "path", ":", "\n", "    ", "fig", ".", "savefig", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_irs._visualize_interventional_effect": [[65, 147], ["numpy.unique", "numpy.unique", "numpy.empty", "range", "matplotlib.figure", "matplotlib.axes", "plt.axes.scatter", "numpy.empty", "numpy.empty", "numpy.empty", "range", "plt.axes.plot", "plt.axes.plot", "plt.axes.plot", "plt.axes.plot", "plt.axes.set_ylabel", "plt.axes.set_xlabel", "plt.axes.legend", "numpy.empty", "range", "plt.axes.set_xlabel", "plt.axes.set_ylabel", "plt.axes.set_title", "numpy.mean", "numpy.median", "numpy.std", "range", "plt.axes.plot", "plt.axes.legend", "numpy.mean", "len", "len"], "function", ["None"], ["", "", "def", "_visualize_interventional_effect", "(", "gen_factors", ",", "\n", "latents", ",", "\n", "latent_dim", ",", "\n", "const_factor_idx", ",", "\n", "intervened_factor_idx", ",", "\n", "no_conditioning", "=", "False", ",", "\n", "ax", "=", "None", ",", "\n", "plot_legend", "=", "True", ",", "\n", "plot_scatter", "=", "False", ")", ":", "\n", "  ", "\"\"\"Visualize single cell of interventional effects.\n\n  Args:\n    gen_factors: Ground truth generative factors.\n    latents: Latent factors.\n    latent_dim: Latent dimension under consideration.\n    const_factor_idx: Generative factor which is being kept constant.\n    intervened_factor_idx: Generative factor on which we intervene.\n    no_conditioning: Whether or not we should condition on const_factor_idx.\n    ax: Matplotlib axis to use.\n    plot_legend: Whether to plot a legend.\n    plot_scatter: Whether to plot all points in a scatter plot.\n  \"\"\"", "\n", "if", "ax", "is", "None", ":", "\n", "    ", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "7", ")", ")", "\n", "ax", "=", "plt", ".", "axes", "(", ")", "\n", "\n", "", "g_is", "=", "np", ".", "unique", "(", "gen_factors", "[", ":", ",", "const_factor_idx", "]", ",", "axis", "=", "0", ")", "\n", "g_js", "=", "np", ".", "unique", "(", "gen_factors", "[", ":", ",", "intervened_factor_idx", "]", ",", "axis", "=", "0", ")", "\n", "\n", "colors", "=", "[", "\"b\"", ",", "\"y\"", ",", "\"g\"", ",", "\"r\"", ",", "\"c\"", ",", "\"m\"", ",", "\"k\"", "]", "\n", "cols_idx", "=", "np", ".", "empty", "(", "[", "gen_factors", ".", "shape", "[", "0", "]", "]", ",", "dtype", "=", "int", ")", "\n", "for", "i_idx", "in", "range", "(", "g_is", ".", "shape", "[", "0", "]", ")", ":", "\n", "    ", "match", "=", "(", "gen_factors", "[", ":", ",", "[", "const_factor_idx", "]", "]", "==", "[", "g_is", "[", "i_idx", "]", "]", ")", ".", "all", "(", "axis", "=", "1", ")", "\n", "cols_idx", "[", "match", "]", "=", "i_idx", "\n", "", "cols", "=", "[", "colors", "[", "col", "%", "len", "(", "colors", ")", "]", "for", "col", "in", "cols_idx", "]", "\n", "\n", "# Plot all points, color indicates constant factor.", "\n", "if", "plot_scatter", ":", "\n", "    ", "ax", ".", "scatter", "(", "\n", "gen_factors", "[", ":", ",", "intervened_factor_idx", "]", ",", "latents", "[", ":", ",", "latent_dim", "]", ",", "c", "=", "cols", ")", "\n", "\n", "# Compute possible g_i and g_j.", "\n", "", "if", "no_conditioning", ":", "\n", "    ", "e_for_j", "=", "np", ".", "empty", "(", "[", "g_js", ".", "shape", "[", "0", "]", "]", ")", "\n", "median_for_j", "=", "np", ".", "empty", "(", "[", "g_js", ".", "shape", "[", "0", "]", "]", ")", "\n", "stdev_for_j", "=", "np", ".", "empty", "(", "[", "g_js", ".", "shape", "[", "0", "]", "]", ")", "\n", "for", "j_idx", "in", "range", "(", "g_js", ".", "shape", "[", "0", "]", ")", ":", "\n", "      ", "match", "=", "(", "gen_factors", "[", ":", ",", "intervened_factor_idx", "]", "==", "g_js", "[", "j_idx", "]", ")", "\n", "e_for_j", "[", "j_idx", "]", "=", "np", ".", "mean", "(", "latents", "[", "match", ",", "latent_dim", "]", ")", "\n", "median_for_j", "[", "j_idx", "]", "=", "np", ".", "median", "(", "latents", "[", "match", ",", "latent_dim", "]", ")", "\n", "stdev_for_j", "[", "j_idx", "]", "=", "np", ".", "std", "(", "latents", "[", "match", ",", "latent_dim", "]", ")", "\n", "", "ax", ".", "plot", "(", "g_js", ",", "e_for_j", ",", "linewidth", "=", "2", ",", "markersize", "=", "12", ",", "label", "=", "\"mean\"", ")", "\n", "ax", ".", "plot", "(", "g_js", ",", "median_for_j", ",", "linewidth", "=", "2", ",", "markersize", "=", "12", ",", "label", "=", "\"median\"", ")", "\n", "ax", ".", "plot", "(", "g_js", ",", "e_for_j", "+", "stdev_for_j", ",", "linestyle", "=", "\"--\"", ",", "c", "=", "\"b\"", ",", "linewidth", "=", "1", ")", "\n", "ax", ".", "plot", "(", "g_js", ",", "e_for_j", "-", "stdev_for_j", ",", "linestyle", "=", "\"--\"", ",", "c", "=", "\"b\"", ",", "linewidth", "=", "1", ")", "\n", "ax", ".", "set_ylabel", "(", "\"E[z_{}|g_{}]\"", ".", "format", "(", "latent_dim", ",", "intervened_factor_idx", ")", ")", "\n", "ax", ".", "set_xlabel", "(", "\"g_{}\"", ".", "format", "(", "intervened_factor_idx", ")", ")", "\n", "ax", ".", "legend", "(", ")", "\n", "", "else", ":", "\n", "# Compute E[Z_l | g_i, g_j] as a function of g_j for each g_i.", "\n", "    ", "e_given_i_for_j", "=", "np", ".", "empty", "(", "[", "g_is", ".", "shape", "[", "0", "]", ",", "g_js", ".", "shape", "[", "0", "]", "]", ")", "\n", "for", "i_idx", "in", "range", "(", "g_is", ".", "shape", "[", "0", "]", ")", ":", "\n", "      ", "for", "j_idx", "in", "range", "(", "g_js", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "match", "=", "(", "gen_factors", "[", ":", ",", "[", "const_factor_idx", ",", "intervened_factor_idx", "]", "]", "==", "[", "\n", "g_is", "[", "i_idx", "]", ",", "g_js", "[", "j_idx", "]", "\n", "]", ")", ".", "all", "(", "axis", "=", "1", ")", "\n", "e_given_i_for_j", "[", "i_idx", ",", "j_idx", "]", "=", "np", ".", "mean", "(", "latents", "[", "match", ",", "latent_dim", "]", ")", "\n", "", "ax", ".", "plot", "(", "\n", "g_js", ",", "\n", "e_given_i_for_j", "[", "i_idx", ",", ":", "]", ",", "\n", "\"go--\"", ",", "\n", "c", "=", "colors", "[", "i_idx", "%", "len", "(", "colors", ")", "]", ",", "\n", "label", "=", "\"g_{}=={}\"", ".", "format", "(", "const_factor_idx", ",", "g_is", "[", "i_idx", "]", ")", ",", "\n", "linewidth", "=", "1.5", ",", "\n", "markersize", "=", "3", ")", "\n", "\n", "", "ax", ".", "set_xlabel", "(", "\"int. g_{}\"", ".", "format", "(", "intervened_factor_idx", ")", ")", "\n", "ax", ".", "set_ylabel", "(", "\"E[z_{}|g_{}, g_{}]\"", ".", "format", "(", "latent_dim", ",", "const_factor_idx", ",", "\n", "intervened_factor_idx", ")", ")", "\n", "ax", ".", "set_title", "(", "\"Interventional Effect (keeping parent fixed)\"", ")", "\n", "if", "plot_legend", ":", "\n", "      ", "ax", ".", "legend", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.dendrogram_test.DendrogramTest.test_dendrogram_plot": [[29, 33], ["absl.testing.parameterized.parameters", "disentanglement_lib.visualize.dendrogram.dendrogram_plot", "numpy.zeros", "dendrogram_test.DendrogramTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.dendrogram.dendrogram_plot"], ["  ", "@", "parameterized", ".", "parameters", "(", "(", "np", ".", "zeros", "(", "(", "5", ",", "10", ")", ",", "dtype", "=", "np", ".", "float32", ")", ",", ")", ")", "\n", "def", "test_dendrogram_plot", "(", "self", ",", "matrix", ")", ":", "\n", "    ", "dendrogram", ".", "dendrogram_plot", "(", "\n", "matrix", ",", "self", ".", "create_tempdir", "(", ")", ".", "full_path", ",", "[", "\"Factor\"", "]", "*", "matrix", ".", "shape", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.dendrogram_test.DendrogramTest.test_union": [[34, 125], ["absl.testing.parameterized.parameters", "disentanglement_lib.visualize.dendrogram._union", "dendrogram_test.DendrogramTest.assertEqual", "dendrogram_test.DendrogramTest.assertEqual", "dendrogram_test.DendrogramTest.assertEqual", "dendrogram_test.DendrogramTest.assertEqual", "dendrogram_test.DendrogramTest.assertEqual", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.dendrogram._union"], ["", "@", "parameterized", ".", "parameters", "(", "\n", "(", "\n", "# Step by step simulation of the union-find algorithm on the event", "\n", "# matrix [[1, 3, 4], [1, 2, 3], [0, 3, 2], [0, 2, 1]], we're now", "\n", "# considering the first step.", "\n", "np", ".", "array", "(", "[", "0", ",", "1", ",", "2", ",", "3", "]", ")", ",", "# Roots for nodes in the graph.", "\n", "1", ",", "# Merge node 1 ...", "\n", "3", ",", "# With node 3", "\n", "0", ",", "# Threshold value of the considered edge: this is the first edge.", "\n", "np", ".", "array", "(", "[", "[", "0.", ",", "0.", ",", "0.", ",", "0.", "]", "]", ")", ",", "# Current dendrogram matrix.", "\n", "{", "0", ":", "0", ",", "1", ":", "1", "}", ",", "# Dictionary factors of variation to cluster IDs.", "\n", "{", "0", ":", "1", ",", "1", ":", "1", "}", ",", "# Size of each cluster.", "\n", "np", ".", "array", "(", "[", "[", "1", ",", "2", "]", ",", "[", "3", ",", "4", "]", "]", ")", ",", "# Original edge-weight matrix.", "\n", "1", ",", "# Max cluster ID we have so far.", "\n", "0", ",", "# How many events have been found.", "\n", "np", ".", "array", "(", "[", "[", "0.", ",", "0.", ",", "0.", ",", "0.", "]", "]", ")", ",", "# A factor and a code are merged.", "\n", "{", "0", ":", "0", ",", "1", ":", "1", "}", ",", "\n", "{", "0", ":", "1", ",", "1", ":", "1", "}", ",", "\n", "1", ",", "0.", "\n", ")", ",", "\n", "(", "\n", "# We're now considering the second step. Node 1 and 3 were merged in", "\n", "# the previous step.", "\n", "np", ".", "array", "(", "[", "0", ",", "1", ",", "2", ",", "1", "]", ")", ",", "# Roots for nodes in the graph.", "\n", "1", ",", "# Merge node 1 ...", "\n", "2", ",", "# With node 2", "\n", "1", ",", "# Threshold value of the considered edge: this is the first edge.", "\n", "np", ".", "array", "(", "[", "[", "0.", ",", "0.", ",", "0.", ",", "0.", "]", "]", ")", ",", "# Current dendrogram matrix.", "\n", "{", "0", ":", "0", ",", "1", ":", "1", "}", ",", "# Dictionary factors of variation to cluster IDs.", "\n", "{", "0", ":", "1", ",", "1", ":", "1", "}", ",", "# Size of each cluster.", "\n", "np", ".", "array", "(", "[", "[", "1", ",", "2", "]", ",", "[", "3", ",", "4", "]", "]", ")", ",", "# Original edge-weight matrix.", "\n", "1", ",", "# Max cluster ID we have so far.", "\n", "0", ",", "# How many events have been found.", "\n", "np", ".", "array", "(", "[", "[", "0.", ",", "0.", ",", "0.", ",", "0.", "]", "]", ")", ",", "# A factor and a code are merged.", "\n", "{", "0", ":", "0", ",", "1", ":", "1", "}", ",", "\n", "{", "0", ":", "1", ",", "1", ":", "1", "}", ",", "\n", "1", ",", "0.", "\n", ")", ",", "\n", "(", "\n", "# We're now considering the third step. Cluster 1 and node 2 were", "\n", "# merged in the previous step. Cluster 0 and 1 merged into cluster 2", "\n", "# which has now size of 2.", "\n", "np", ".", "array", "(", "[", "0", ",", "1", ",", "1", ",", "1", "]", ")", ",", "# Nodes in the graph.", "\n", "0", ",", "# Merge node 0 ...", "\n", "3", ",", "# With node 3", "\n", "2", ",", "# Threshold value of the considered edge: this is the second edge.", "\n", "np", ".", "array", "(", "[", "[", "0.", ",", "0.", ",", "0.", ",", "0.", "]", "]", ")", ",", "# Current dendrogram matrix.", "\n", "{", "0", ":", "0", ",", "1", ":", "1", "}", ",", "# Dictionary factors of variation to cluster IDs.", "\n", "{", "0", ":", "1", ",", "1", ":", "1", "}", ",", "# Size of each cluster.", "\n", "np", ".", "array", "(", "[", "[", "1", ",", "2", "]", ",", "[", "3", ",", "4", "]", "]", ")", ",", "# Original edge-weight matrix.", "\n", "1", ",", "# Max cluster ID we have so far.", "\n", "0", ",", "# How many events have been found.", "\n", "np", ".", "array", "(", "[", "[", "0.", ",", "1.", ",", "2.", ",", "2.", "]", "]", ")", ",", "# Two clusters merged.", "\n", "{", "0", ":", "2", ",", "1", ":", "2", "}", ",", "# Both factors are now mapped to the new cluster 2.", "\n", "{", "0", ":", "1", ",", "1", ":", "1", ",", "2", ":", "2", "}", ",", "# Size of the new cluster is added.", "\n", "2", ",", "# Our new max cluster id is 2.", "\n", "1", "# We have had our first cluster merge.", "\n", ")", ",", "\n", "(", "\n", "# We're now considering the last step. The last code gets merged into", "\n", "# the now only cluster. Since cluster 0 and 1 were merged, 0 is the", "\n", "# root of cluster 2.", "\n", "np", ".", "array", "(", "[", "0", ",", "0", ",", "1", ",", "1", "]", ")", ",", "# Nodes in the graph. Smallest node is root.", "\n", "0", ",", "# Merge node 0 ...", "\n", "2", ",", "# With node 2", "\n", "3", ",", "# Threshold value of the considered edge: this is the first edge.", "\n", "np", ".", "array", "(", "[", "[", "0.", ",", "1.", ",", "2.", ",", "2.", "]", "]", ")", ",", "# Current dendrogram matrix.", "\n", "{", "0", ":", "2", ",", "1", ":", "2", "}", ",", "# Dictionary factors of variation to cluster IDs.", "\n", "{", "0", ":", "1", ",", "1", ":", "1", ",", "2", ":", "2", "}", ",", "# Size of each cluster.", "\n", "np", ".", "array", "(", "[", "[", "1", ",", "2", "]", ",", "[", "3", ",", "4", "]", "]", ")", ",", "# Original edge-weight matrix.", "\n", "2", ",", "# Max cluster ID we have so far.", "\n", "1", ",", "# How many events have been found.", "\n", "np", ".", "array", "(", "[", "[", "0.", ",", "1.", ",", "2.", ",", "2.", "]", "]", ")", ",", "# A code is merged into a cluster.", "\n", "{", "0", ":", "2", ",", "1", ":", "2", "}", ",", "# Both factors are now mapped to the new cluster 2.", "\n", "{", "0", ":", "1", ",", "1", ":", "1", ",", "2", ":", "2", "}", ",", "# Size of the new cluster is added.", "\n", "2", ",", "# Our new max cluster id is 2.", "\n", "1", "# We have had one cluster merge.", "\n", ")", ")", "\n", "def", "test_union", "(", "\n", "self", ",", "nodes", ",", "idx", ",", "idy", ",", "val", ",", "z", ",", "cluster_id", ",", "size", ",", "matrix", ",", "n_clusters", ",", "\n", "idx_found", ",", "z_target", ",", "cluster_id_target", ",", "size_target", ",", "n_clusters_target", ",", "\n", "idx_found_target", ")", ":", "\n", "\n", "    ", "z", ",", "cluster_id", ",", "size", ",", "n_clusters", ",", "idx_found", "=", "dendrogram", ".", "_union", "(", "\n", "nodes", ",", "idx", ",", "idy", ",", "val", ",", "z", ",", "cluster_id", ",", "size", ",", "matrix", ",", "n_clusters", ",", "\n", "idx_found", ")", "\n", "self", ".", "assertEqual", "(", "(", "z_target", "==", "z", ")", ".", "all", "(", ")", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "(", "cluster_id_target", "==", "cluster_id", ")", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "(", "size_target", "==", "size", ")", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "(", "n_clusters_target", "==", "n_clusters", ")", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "(", "idx_found_target", "==", "idx_found", ")", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_model.visualize": [[35, 209], ["numpy.random.RandomState", "tensorflow.gfile.IsDirectory", "os.path.join", "disentanglement_lib.utils.results.gin_dict", "gin.bind_parameter", "disentanglement_lib.data.ground_truth.named_data.get_named_ground_truth_data", "os.path.join", "gin.clear_config", "gin_dict[].replace", "tensorflow_hub.eval_function_for_module", "named_data.get_named_ground_truth_data.sample_observations", "activation", "numpy.concatenate", "os.path.join", "disentanglement_lib.visualize.visualize_util.grid_save_images", "int", "np.random.RandomState.normal", "activation", "os.path.join", "disentanglement_lib.visualize.visualize_util.grid_save_images", "f", "os.path.join", "six.moves.range", "os.path.join", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "named_data.get_named_ground_truth_data.sample_factors", "named_data.get_named_ground_truth_data.sample_observations_from_factors", "os.path.join", "disentanglement_lib.visualize.visualize_irs.vis_all_interventional_effects", "tensorflow.gfile.DeleteRecursively", "ValueError", "ValueError", "f", "tensorflow.compat.v1.gfile.IsDirectory", "tensorflow.compat.v1.gfile.MakeDirs", "os.path.join", "visualize_model.visualize._decoder"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.gin_dict", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.named_data.get_named_ground_truth_data", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.ground_truth_data.GroundTruthData.sample_observations", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.grid_save_images", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.grid_save_images", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_irs.vis_all_interventional_effects"], ["def", "visualize", "(", "model_dir", ",", "\n", "output_dir", ",", "\n", "overwrite", "=", "False", ",", "\n", "num_animations", "=", "5", ",", "\n", "num_frames", "=", "20", ",", "\n", "fps", "=", "10", ",", "\n", "num_points_irs", "=", "10000", ")", ":", "\n", "  ", "\"\"\"Takes trained model from model_dir and visualizes it in output_dir.\n\n  Args:\n    model_dir: Path to directory where the trained model is saved.\n    output_dir: Path to output directory.\n    overwrite: Boolean indicating whether to overwrite output directory.\n    num_animations: Integer with number of distinct animations to create.\n    num_frames: Integer with number of frames in each animation.\n    fps: Integer with frame rate for the animation.\n    num_points_irs: Number of points to be used for the IRS plots.\n  \"\"\"", "\n", "# Fix the random seed for reproducibility.", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "\n", "# Create the output directory if necessary.", "\n", "if", "tf", ".", "gfile", ".", "IsDirectory", "(", "output_dir", ")", ":", "\n", "    ", "if", "overwrite", ":", "\n", "      ", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "output_dir", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"Directory already exists and overwrite is False.\"", ")", "\n", "\n", "# Automatically set the proper data set if necessary. We replace the active", "\n", "# gin config as this will lead to a valid gin config file where the data set", "\n", "# is present.", "\n", "# Obtain the dataset name from the gin config of the previous step.", "\n", "", "", "gin_config_file", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"results\"", ",", "\"gin\"", ",", "\"train.gin\"", ")", "\n", "gin_dict", "=", "results", ".", "gin_dict", "(", "gin_config_file", ")", "\n", "gin", ".", "bind_parameter", "(", "\"dataset.name\"", ",", "gin_dict", "[", "\"dataset.name\"", "]", ".", "replace", "(", "\n", "\"'\"", ",", "\"\"", ")", ")", "\n", "\n", "# Automatically infer the activation function from gin config.", "\n", "activation_str", "=", "gin_dict", "[", "\"reconstruction_loss.activation\"", "]", "\n", "if", "activation_str", "==", "\"'logits'\"", ":", "\n", "    ", "activation", "=", "sigmoid", "\n", "", "elif", "activation_str", "==", "\"'tanh'\"", ":", "\n", "    ", "activation", "=", "tanh", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "\"Activation function  could not be infered from gin config.\"", ")", "\n", "\n", "", "dataset", "=", "named_data", ".", "get_named_ground_truth_data", "(", ")", "\n", "num_pics", "=", "64", "\n", "module_path", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"tfhub\"", ")", "\n", "\n", "with", "hub", ".", "eval_function_for_module", "(", "module_path", ")", "as", "f", ":", "\n", "# Save reconstructions.", "\n", "    ", "real_pics", "=", "dataset", ".", "sample_observations", "(", "num_pics", ",", "random_state", ")", "\n", "raw_pics", "=", "f", "(", "\n", "dict", "(", "images", "=", "real_pics", ")", ",", "signature", "=", "\"reconstructions\"", ",", "\n", "as_dict", "=", "True", ")", "[", "\"images\"", "]", "\n", "pics", "=", "activation", "(", "raw_pics", ")", "\n", "paired_pics", "=", "np", ".", "concatenate", "(", "(", "real_pics", ",", "pics", ")", ",", "axis", "=", "2", ")", "\n", "paired_pics", "=", "[", "paired_pics", "[", "i", ",", ":", ",", ":", ",", ":", "]", "for", "i", "in", "range", "(", "paired_pics", ".", "shape", "[", "0", "]", ")", "]", "\n", "results_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"reconstructions\"", ")", "\n", "if", "not", "gfile", ".", "IsDirectory", "(", "results_dir", ")", ":", "\n", "      ", "gfile", ".", "MakeDirs", "(", "results_dir", ")", "\n", "", "visualize_util", ".", "grid_save_images", "(", "\n", "paired_pics", ",", "os", ".", "path", ".", "join", "(", "results_dir", ",", "\"reconstructions.jpg\"", ")", ")", "\n", "\n", "# Save samples.", "\n", "def", "_decoder", "(", "latent_vectors", ")", ":", "\n", "      ", "return", "f", "(", "\n", "dict", "(", "latent_vectors", "=", "latent_vectors", ")", ",", "\n", "signature", "=", "\"decoder\"", ",", "\n", "as_dict", "=", "True", ")", "[", "\"images\"", "]", "\n", "\n", "", "num_latent", "=", "int", "(", "gin_dict", "[", "\"encoder.num_latent\"", "]", ")", "\n", "num_pics", "=", "64", "\n", "random_codes", "=", "random_state", ".", "normal", "(", "0", ",", "1", ",", "[", "num_pics", ",", "num_latent", "]", ")", "\n", "pics", "=", "activation", "(", "_decoder", "(", "random_codes", ")", ")", "\n", "results_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"sampled\"", ")", "\n", "if", "not", "gfile", ".", "IsDirectory", "(", "results_dir", ")", ":", "\n", "      ", "gfile", ".", "MakeDirs", "(", "results_dir", ")", "\n", "", "visualize_util", ".", "grid_save_images", "(", "pics", ",", "\n", "os", ".", "path", ".", "join", "(", "results_dir", ",", "\"samples.jpg\"", ")", ")", "\n", "\n", "# Save latent traversals.", "\n", "result", "=", "f", "(", "\n", "dict", "(", "images", "=", "dataset", ".", "sample_observations", "(", "num_pics", ",", "random_state", ")", ")", ",", "\n", "signature", "=", "\"gaussian_encoder\"", ",", "\n", "as_dict", "=", "True", ")", "\n", "means", "=", "result", "[", "\"mean\"", "]", "\n", "logvars", "=", "result", "[", "\"logvar\"", "]", "\n", "results_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"traversals\"", ")", "\n", "if", "not", "gfile", ".", "IsDirectory", "(", "results_dir", ")", ":", "\n", "      ", "gfile", ".", "MakeDirs", "(", "results_dir", ")", "\n", "", "for", "i", "in", "range", "(", "means", ".", "shape", "[", "1", "]", ")", ":", "\n", "      ", "pics", "=", "activation", "(", "\n", "latent_traversal_1d_multi_dim", "(", "_decoder", ",", "means", "[", "i", ",", ":", "]", ",", "None", ")", ")", "\n", "file_name", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "\"traversals{}.jpg\"", ".", "format", "(", "i", ")", ")", "\n", "visualize_util", ".", "grid_save_images", "(", "[", "pics", "]", ",", "file_name", ")", "\n", "\n", "# Save the latent traversal animations.", "\n", "", "results_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"animated_traversals\"", ")", "\n", "if", "not", "gfile", ".", "IsDirectory", "(", "results_dir", ")", ":", "\n", "      ", "gfile", ".", "MakeDirs", "(", "results_dir", ")", "\n", "\n", "# Cycle through quantiles of a standard Gaussian.", "\n", "", "for", "i", ",", "base_code", "in", "enumerate", "(", "means", "[", ":", "num_animations", "]", ")", ":", "\n", "      ", "images", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "base_code", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "code", "=", "np", ".", "repeat", "(", "np", ".", "expand_dims", "(", "base_code", ",", "0", ")", ",", "num_frames", ",", "axis", "=", "0", ")", "\n", "code", "[", ":", ",", "j", "]", "=", "visualize_util", ".", "cycle_gaussian", "(", "base_code", "[", "j", "]", ",", "num_frames", ")", "\n", "images", ".", "append", "(", "np", ".", "array", "(", "activation", "(", "_decoder", "(", "code", ")", ")", ")", ")", "\n", "", "filename", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "\"std_gaussian_cycle%d.gif\"", "%", "i", ")", "\n", "visualize_util", ".", "save_animation", "(", "np", ".", "array", "(", "images", ")", ",", "filename", ",", "fps", ")", "\n", "\n", "# Cycle through quantiles of a fitted Gaussian.", "\n", "", "for", "i", ",", "base_code", "in", "enumerate", "(", "means", "[", ":", "num_animations", "]", ")", ":", "\n", "      ", "images", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "base_code", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "code", "=", "np", ".", "repeat", "(", "np", ".", "expand_dims", "(", "base_code", ",", "0", ")", ",", "num_frames", ",", "axis", "=", "0", ")", "\n", "loc", "=", "np", ".", "mean", "(", "means", "[", ":", ",", "j", "]", ")", "\n", "total_variance", "=", "np", ".", "mean", "(", "np", ".", "exp", "(", "logvars", "[", ":", ",", "j", "]", ")", ")", "+", "np", ".", "var", "(", "means", "[", ":", ",", "j", "]", ")", "\n", "code", "[", ":", ",", "j", "]", "=", "visualize_util", ".", "cycle_gaussian", "(", "\n", "base_code", "[", "j", "]", ",", "num_frames", ",", "loc", "=", "loc", ",", "scale", "=", "np", ".", "sqrt", "(", "total_variance", ")", ")", "\n", "images", ".", "append", "(", "np", ".", "array", "(", "activation", "(", "_decoder", "(", "code", ")", ")", ")", ")", "\n", "", "filename", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "\"fitted_gaussian_cycle%d.gif\"", "%", "i", ")", "\n", "visualize_util", ".", "save_animation", "(", "np", ".", "array", "(", "images", ")", ",", "filename", ",", "fps", ")", "\n", "\n", "# Cycle through [-2, 2] interval.", "\n", "", "for", "i", ",", "base_code", "in", "enumerate", "(", "means", "[", ":", "num_animations", "]", ")", ":", "\n", "      ", "images", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "base_code", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "code", "=", "np", ".", "repeat", "(", "np", ".", "expand_dims", "(", "base_code", ",", "0", ")", ",", "num_frames", ",", "axis", "=", "0", ")", "\n", "code", "[", ":", ",", "j", "]", "=", "visualize_util", ".", "cycle_interval", "(", "base_code", "[", "j", "]", ",", "num_frames", ",", "\n", "-", "2.", ",", "2.", ")", "\n", "images", ".", "append", "(", "np", ".", "array", "(", "activation", "(", "_decoder", "(", "code", ")", ")", ")", ")", "\n", "", "filename", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "\"fixed_interval_cycle%d.gif\"", "%", "i", ")", "\n", "visualize_util", ".", "save_animation", "(", "np", ".", "array", "(", "images", ")", ",", "filename", ",", "fps", ")", "\n", "\n", "# Cycle linearly through +-2 std dev of a fitted Gaussian.", "\n", "", "for", "i", ",", "base_code", "in", "enumerate", "(", "means", "[", ":", "num_animations", "]", ")", ":", "\n", "      ", "images", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "base_code", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "code", "=", "np", ".", "repeat", "(", "np", ".", "expand_dims", "(", "base_code", ",", "0", ")", ",", "num_frames", ",", "axis", "=", "0", ")", "\n", "loc", "=", "np", ".", "mean", "(", "means", "[", ":", ",", "j", "]", ")", "\n", "total_variance", "=", "np", ".", "mean", "(", "np", ".", "exp", "(", "logvars", "[", ":", ",", "j", "]", ")", ")", "+", "np", ".", "var", "(", "means", "[", ":", ",", "j", "]", ")", "\n", "scale", "=", "np", ".", "sqrt", "(", "total_variance", ")", "\n", "code", "[", ":", ",", "j", "]", "=", "visualize_util", ".", "cycle_interval", "(", "base_code", "[", "j", "]", ",", "num_frames", ",", "\n", "loc", "-", "2.", "*", "scale", ",", "loc", "+", "2.", "*", "scale", ")", "\n", "images", ".", "append", "(", "np", ".", "array", "(", "activation", "(", "_decoder", "(", "code", ")", ")", ")", ")", "\n", "", "filename", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "\"conf_interval_cycle%d.gif\"", "%", "i", ")", "\n", "visualize_util", ".", "save_animation", "(", "np", ".", "array", "(", "images", ")", ",", "filename", ",", "fps", ")", "\n", "\n", "# Cycle linearly through minmax of a fitted Gaussian.", "\n", "", "for", "i", ",", "base_code", "in", "enumerate", "(", "means", "[", ":", "num_animations", "]", ")", ":", "\n", "      ", "images", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "base_code", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "code", "=", "np", ".", "repeat", "(", "np", ".", "expand_dims", "(", "base_code", ",", "0", ")", ",", "num_frames", ",", "axis", "=", "0", ")", "\n", "code", "[", ":", ",", "j", "]", "=", "visualize_util", ".", "cycle_interval", "(", "base_code", "[", "j", "]", ",", "num_frames", ",", "\n", "np", ".", "min", "(", "means", "[", ":", ",", "j", "]", ")", ",", "\n", "np", ".", "max", "(", "means", "[", ":", ",", "j", "]", ")", ")", "\n", "images", ".", "append", "(", "np", ".", "array", "(", "activation", "(", "_decoder", "(", "code", ")", ")", ")", ")", "\n", "", "filename", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "\"minmax_interval_cycle%d.gif\"", "%", "i", ")", "\n", "visualize_util", ".", "save_animation", "(", "np", ".", "array", "(", "images", ")", ",", "filename", ",", "fps", ")", "\n", "\n", "# Interventional effects visualization.", "\n", "", "factors", "=", "dataset", ".", "sample_factors", "(", "num_points_irs", ",", "random_state", ")", "\n", "obs", "=", "dataset", ".", "sample_observations_from_factors", "(", "factors", ",", "random_state", ")", "\n", "latents", "=", "f", "(", "\n", "dict", "(", "images", "=", "obs", ")", ",", "signature", "=", "\"gaussian_encoder\"", ",", "as_dict", "=", "True", ")", "[", "\"mean\"", "]", "\n", "results_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"interventional_effects\"", ")", "\n", "vis_all_interventional_effects", "(", "factors", ",", "latents", ",", "results_dir", ")", "\n", "\n", "# Finally, we clear the gin config that we have set.", "\n", "", "gin", ".", "clear_config", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_model.latent_traversal_1d_multi_dim": [[211, 287], ["len", "numpy.concatenate", "ValueError", "numpy.arange", "isinstance", "ValueError", "numpy.linspace", "isinstance", "ValueError", "numpy.tile", "generator_fn", "row_or_columns.append", "numpy.arange", "numpy.linspace", "numpy.concatenate", "ValueError", "ValueError", "ValueError"], "function", ["None"], ["", "def", "latent_traversal_1d_multi_dim", "(", "generator_fn", ",", "\n", "latent_vector", ",", "\n", "dimensions", "=", "None", ",", "\n", "values", "=", "None", ",", "\n", "transpose", "=", "False", ")", ":", "\n", "  ", "\"\"\"Creates latent traversals for a latent vector along multiple dimensions.\n\n  Creates a 2d grid image where each grid image is generated by passing a\n  modified version of latent_vector to the generator_fn. In each column, a\n  fixed dimension of latent_vector is modified. In each row, the value in the\n  modified dimension is replaced by a fixed value.\n\n  Args:\n    generator_fn: Function that computes (fixed size) images from latent\n      representation. It should accept a single Numpy array argument of the same\n      shape as latent_vector and return a Numpy array of images where the first\n      dimension corresponds to the different vectors in latent_vectors.\n    latent_vector: 1d Numpy array with the base latent vector to be used.\n    dimensions: 1d Numpy array with the indices of the dimensions that should be\n      modified. If an integer is passed, the dimensions 0, 1, ...,\n      (dimensions - 1) are modified. If None is passed, all dimensions of\n      latent_vector are modified.\n    values: 1d Numpy array with the latent space values that should be used for\n      modifications. If an integer is passed, a linear grid between -1 and 1\n      with that many points is constructed. If None is passed, a default grid is\n      used (whose specific design is not guaranteed).\n    transpose: Boolean which indicates whether rows and columns of the 2d grid\n      should be transposed.\n\n  Returns:\n    Numpy array with image.\n  \"\"\"", "\n", "if", "latent_vector", ".", "ndim", "!=", "1", ":", "\n", "    ", "raise", "ValueError", "(", "\"Latent vector needs to be 1-dimensional.\"", ")", "\n", "\n", "", "if", "dimensions", "is", "None", ":", "\n", "# Default case, use all available dimensions.", "\n", "    ", "dimensions", "=", "np", ".", "arange", "(", "latent_vector", ".", "shape", "[", "0", "]", ")", "\n", "", "elif", "isinstance", "(", "dimensions", ",", "numbers", ".", "Integral", ")", ":", "\n", "# Check that there are enough dimensions in latent_vector.", "\n", "    ", "if", "dimensions", ">", "latent_vector", ".", "shape", "[", "0", "]", ":", "\n", "      ", "raise", "ValueError", "(", "\"The number of dimensions of latent_vector is less than\"", "\n", "\" the number of dimensions requested in the arguments.\"", ")", "\n", "", "if", "dimensions", "<", "1", ":", "\n", "      ", "raise", "ValueError", "(", "\"The number of dimensions has to be at least 1.\"", ")", "\n", "", "dimensions", "=", "np", ".", "arange", "(", "dimensions", ")", "\n", "", "if", "dimensions", ".", "ndim", "!=", "1", ":", "\n", "    ", "raise", "ValueError", "(", "\"Dimensions vector needs to be 1-dimensional.\"", ")", "\n", "\n", "", "if", "values", "is", "None", ":", "\n", "# Default grid of values.", "\n", "    ", "values", "=", "np", ".", "linspace", "(", "-", "1.", ",", "1.", ",", "num", "=", "11", ")", "\n", "", "elif", "isinstance", "(", "values", ",", "numbers", ".", "Integral", ")", ":", "\n", "    ", "if", "values", "<=", "1", ":", "\n", "      ", "raise", "ValueError", "(", "\"If an int is passed for values, it has to be >1.\"", ")", "\n", "", "values", "=", "np", ".", "linspace", "(", "-", "1.", ",", "1.", ",", "num", "=", "values", ")", "\n", "", "if", "values", ".", "ndim", "!=", "1", ":", "\n", "    ", "raise", "ValueError", "(", "\"Values vector needs to be 1-dimensional.\"", ")", "\n", "\n", "# We iteratively generate the rows/columns for each dimension as different", "\n", "# Numpy arrays. We do not preallocate a single final Numpy array as this code", "\n", "# is not performance critical and as it reduces code complexity.", "\n", "", "num_values", "=", "len", "(", "values", ")", "\n", "row_or_columns", "=", "[", "]", "\n", "for", "dimension", "in", "dimensions", ":", "\n", "# Creates num_values copy of the latent_vector along the first axis.", "\n", "    ", "latent_traversal_vectors", "=", "np", ".", "tile", "(", "latent_vector", ",", "[", "num_values", ",", "1", "]", ")", "\n", "# Intervenes in the latent space.", "\n", "latent_traversal_vectors", "[", ":", ",", "dimension", "]", "=", "values", "\n", "# Generate the batch of images", "\n", "images", "=", "generator_fn", "(", "latent_traversal_vectors", ")", "\n", "# Adds images as a row or column depending whether transpose is True.", "\n", "axis", "=", "(", "1", "if", "transpose", "else", "0", ")", "\n", "row_or_columns", ".", "append", "(", "np", ".", "concatenate", "(", "images", ",", "axis", ")", ")", "\n", "", "axis", "=", "(", "0", "if", "transpose", "else", "1", ")", "\n", "return", "np", ".", "concatenate", "(", "row_or_columns", ",", "axis", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_model.sigmoid": [[289, 291], ["scipy.stats.logistic.cdf"], "function", ["None"], ["", "def", "sigmoid", "(", "x", ")", ":", "\n", "  ", "return", "stats", ".", "logistic", ".", "cdf", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_model.tanh": [[293, 295], ["numpy.tanh"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_model.tanh"], ["", "def", "tanh", "(", "x", ")", ":", "\n", "  ", "return", "np", ".", "tanh", "(", "x", ")", "/", "2.", "+", ".5", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.save_image": [[30, 46], ["numpy.ascontiguousarray", "np.repeat.astype", "numpy.repeat", "tensorflow.gfile.Open", "PIL.Image.fromarray", "Image.fromarray.save"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.repeat"], ["def", "save_image", "(", "image", ",", "image_path", ")", ":", "\n", "  ", "\"\"\"Saves an image in the [0,1]-valued Numpy array to image_path.\n\n  Args:\n    image: Numpy array of shape (height, width, {1,3}) with values in [0, 1].\n    image_path: String with path to output image.\n  \"\"\"", "\n", "# Copy the single channel if we are provided a grayscale image.", "\n", "if", "image", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "    ", "image", "=", "np", ".", "repeat", "(", "image", ",", "3", ",", "axis", "=", "2", ")", "\n", "", "image", "=", "np", ".", "ascontiguousarray", "(", "image", ")", "\n", "image", "*=", "255.", "\n", "image", "=", "image", ".", "astype", "(", "\"uint8\"", ")", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "image_path", ",", "\"wb\"", ")", "as", "path", ":", "\n", "    ", "img", "=", "Image", ".", "fromarray", "(", "image", ",", "mode", "=", "\"RGB\"", ")", "\n", "img", ".", "save", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.grid_save_images": [[48, 64], ["int", "numpy.concatenate", "visualize_util.save_image", "math.floor", "numpy.concatenate", "math.sqrt", "six.moves.range", "len"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.save_image"], ["", "", "def", "grid_save_images", "(", "images", ",", "image_path", ")", ":", "\n", "  ", "\"\"\"Saves images in list of [0,1]-valued np.arrays on a grid.\n\n  Args:\n    images: List of Numpy arrays of shape (height, width, {1,3}) with values in\n      [0, 1].\n    image_path: String with path to output image.\n  \"\"\"", "\n", "side_length", "=", "int", "(", "math", ".", "floor", "(", "math", ".", "sqrt", "(", "len", "(", "images", ")", ")", ")", ")", "\n", "image_rows", "=", "[", "\n", "np", ".", "concatenate", "(", "\n", "images", "[", "side_length", "*", "i", ":", "side_length", "*", "i", "+", "side_length", "]", ",", "axis", "=", "0", ")", "\n", "for", "i", "in", "range", "(", "side_length", ")", "\n", "]", "\n", "tiled_image", "=", "np", ".", "concatenate", "(", "image_rows", ",", "axis", "=", "1", ")", "\n", "save_image", "(", "tiled_image", ",", "image_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.padded_grid": [[66, 83], ["len", "int", "visualize_util.padded_stack", "visualize_util.best_num_rows", "numpy.ceil", "visualize_util.padded_stack", "six.moves.range", "float", "numpy.ones_like"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.padded_stack", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.best_num_rows", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.padded_stack"], ["", "def", "padded_grid", "(", "images", ",", "num_rows", "=", "None", ",", "padding_px", "=", "10", ",", "value", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates a grid with padding in between images.\"\"\"", "\n", "num_images", "=", "len", "(", "images", ")", "\n", "if", "num_rows", "is", "None", ":", "\n", "    ", "num_rows", "=", "best_num_rows", "(", "num_images", ")", "\n", "\n", "# Computes how many empty images we need to add.", "\n", "", "num_cols", "=", "int", "(", "np", ".", "ceil", "(", "float", "(", "num_images", ")", "/", "num_rows", ")", ")", "\n", "num_missing", "=", "num_rows", "*", "num_cols", "-", "num_images", "\n", "\n", "# Add the empty images at the end.", "\n", "all_images", "=", "images", "+", "[", "np", ".", "ones_like", "(", "images", "[", "0", "]", ")", "]", "*", "num_missing", "\n", "\n", "# Create the final grid.", "\n", "rows", "=", "[", "padded_stack", "(", "all_images", "[", "i", "*", "num_cols", ":", "(", "i", "+", "1", ")", "*", "num_cols", "]", ",", "padding_px", ",", "\n", "1", ",", "value", "=", "value", ")", "for", "i", "in", "range", "(", "num_rows", ")", "]", "\n", "return", "padded_stack", "(", "rows", ",", "padding_px", ",", "axis", "=", "0", ",", "value", "=", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.padded_stack": [[85, 93], ["visualize_util.padding_array", "numpy.concatenate", "new_images.append", "new_images.append"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.padding_array"], ["", "def", "padded_stack", "(", "images", ",", "padding_px", "=", "10", ",", "axis", "=", "0", ",", "value", "=", "None", ")", ":", "\n", "  ", "\"\"\"Stacks images along axis with padding in between images.\"\"\"", "\n", "padding_arr", "=", "padding_array", "(", "images", "[", "0", "]", ",", "padding_px", ",", "axis", ",", "value", "=", "value", ")", "\n", "new_images", "=", "[", "images", "[", "0", "]", "]", "\n", "for", "image", "in", "images", "[", "1", ":", "]", ":", "\n", "    ", "new_images", ".", "append", "(", "padding_arr", ")", "\n", "new_images", ".", "append", "(", "image", ")", "\n", "", "return", "np", ".", "concatenate", "(", "new_images", ",", "axis", "=", "axis", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.padding_array": [[95, 105], ["list", "numpy.ones", "numpy.tile", "len"], "function", ["None"], ["", "def", "padding_array", "(", "image", ",", "padding_px", ",", "axis", ",", "value", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates padding image of proper shape to pad image along the axis.\"\"\"", "\n", "shape", "=", "list", "(", "image", ".", "shape", ")", "\n", "shape", "[", "axis", "]", "=", "padding_px", "\n", "if", "value", "is", "None", ":", "\n", "    ", "return", "np", ".", "ones", "(", "shape", ",", "dtype", "=", "image", ".", "dtype", ")", "\n", "", "else", ":", "\n", "    ", "assert", "len", "(", "value", ")", "==", "shape", "[", "-", "1", "]", "\n", "shape", "[", "-", "1", "]", "=", "1", "\n", "return", "np", ".", "tile", "(", "value", ",", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.best_num_rows": [[107, 122], ["int", "numpy.sqrt"], "function", ["None"], ["", "", "def", "best_num_rows", "(", "num_elements", ",", "max_ratio", "=", "4", ")", ":", "\n", "  ", "\"\"\"Automatically selects a smart number of rows.\"\"\"", "\n", "best_remainder", "=", "num_elements", "\n", "best_i", "=", "None", "\n", "i", "=", "int", "(", "np", ".", "sqrt", "(", "num_elements", ")", ")", "\n", "while", "True", ":", "\n", "    ", "if", "num_elements", ">", "max_ratio", "*", "i", "*", "i", ":", "\n", "      ", "return", "best_i", "\n", "", "remainder", "=", "(", "i", "-", "num_elements", "%", "i", ")", "%", "i", "\n", "if", "remainder", "==", "0", ":", "\n", "      ", "return", "i", "\n", "", "if", "remainder", "<", "best_remainder", ":", "\n", "      ", "best_remainder", "=", "remainder", "\n", "best_i", "=", "i", "\n", "", "i", "-=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.pad_around": [[124, 132], ["visualize_util.padding_array", "numpy.concatenate", "visualize_util.pad_around"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.padding_array", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.pad_around"], ["", "", "def", "pad_around", "(", "image", ",", "padding_px", "=", "10", ",", "axis", "=", "None", ",", "value", "=", "None", ")", ":", "\n", "  ", "\"\"\"Adds a padding around each image.\"\"\"", "\n", "# If axis is None, pad both the first and the second axis.", "\n", "if", "axis", "is", "None", ":", "\n", "    ", "image", "=", "pad_around", "(", "image", ",", "padding_px", ",", "axis", "=", "0", ",", "value", "=", "value", ")", "\n", "axis", "=", "1", "\n", "", "padding_arr", "=", "padding_array", "(", "image", ",", "padding_px", ",", "axis", ",", "value", "=", "value", ")", "\n", "return", "np", ".", "concatenate", "(", "[", "padding_arr", ",", "image", ",", "padding_arr", "]", ",", "axis", "=", "axis", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.add_below": [[134, 151], ["visualize_util.padded_stack", "len", "numpy.expand_dims", "numpy.repeat", "ValueError", "tensorflow.gfile.Open", "visualize_util.padding_array", "numpy.concatenate", "disentanglement_lib.utils.resources.get_file", "numpy.array", "PIL.Image.open().convert", "PIL.Image.open"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.padded_stack", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.repeat", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.padding_array", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file"], ["", "def", "add_below", "(", "image", ",", "padding_px", "=", "10", ",", "value", "=", "None", ")", ":", "\n", "  ", "\"\"\"Adds a footer below.\"\"\"", "\n", "if", "len", "(", "image", ".", "shape", ")", "==", "2", ":", "\n", "    ", "image", "=", "np", ".", "expand_dims", "(", "image", ",", "-", "1", ")", "\n", "", "if", "image", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "    ", "image", "=", "np", ".", "repeat", "(", "image", ",", "3", ",", "2", ")", "\n", "", "if", "image", ".", "shape", "[", "2", "]", "!=", "3", ":", "\n", "    ", "raise", "ValueError", "(", "\"Could not convert image to have three channels.\"", ")", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "resources", ".", "get_file", "(", "\"disentanglement_lib.png\"", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "    ", "footer", "=", "np", ".", "array", "(", "Image", ".", "open", "(", "f", ")", ".", "convert", "(", "\"RGB\"", ")", ")", "*", "1.0", "/", "255.", "\n", "", "missing_px", "=", "image", ".", "shape", "[", "1", "]", "-", "footer", ".", "shape", "[", "1", "]", "\n", "if", "missing_px", "<", "0", ":", "\n", "    ", "return", "image", "\n", "", "if", "missing_px", ">", "0", ":", "\n", "    ", "padding_arr", "=", "padding_array", "(", "footer", ",", "missing_px", ",", "axis", "=", "1", ",", "value", "=", "value", ")", "\n", "footer", "=", "np", ".", "concatenate", "(", "[", "padding_arr", ",", "footer", "]", ",", "axis", "=", "1", ")", "\n", "", "return", "padded_stack", "(", "[", "image", ",", "footer", "]", ",", "padding_px", ",", "axis", "=", "0", ",", "value", "=", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.save_animation": [[153, 159], ["zip", "imageio.mimwrite", "full_size_images.append", "visualize_util.pad_around", "visualize_util.add_below", "visualize_util.padded_grid", "list"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.pad_around", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.add_below", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.padded_grid"], ["", "def", "save_animation", "(", "list_of_animated_images", ",", "image_path", ",", "fps", ")", ":", "\n", "  ", "full_size_images", "=", "[", "]", "\n", "for", "single_images", "in", "zip", "(", "*", "list_of_animated_images", ")", ":", "\n", "    ", "full_size_images", ".", "append", "(", "\n", "pad_around", "(", "add_below", "(", "padded_grid", "(", "list", "(", "single_images", ")", ")", ")", ")", ")", "\n", "", "imageio", ".", "mimwrite", "(", "image_path", ",", "full_size_images", ",", "fps", "=", "fps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.cycle_factor": [[161, 169], ["numpy.linspace", "numpy.array", "numpy.maximum", "numpy.maximum", "numpy.ceil"], "function", ["None"], ["", "def", "cycle_factor", "(", "starting_index", ",", "num_indices", ",", "num_frames", ")", ":", "\n", "  ", "\"\"\"Cycles through the state space in a single cycle.\"\"\"", "\n", "grid", "=", "np", ".", "linspace", "(", "starting_index", ",", "starting_index", "+", "2", "*", "num_indices", ",", "\n", "num", "=", "num_frames", ",", "endpoint", "=", "False", ")", "\n", "grid", "=", "np", ".", "array", "(", "np", ".", "ceil", "(", "grid", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "grid", "-=", "np", ".", "maximum", "(", "0", ",", "2", "*", "grid", "-", "2", "*", "num_indices", "+", "1", ")", "\n", "grid", "+=", "np", ".", "maximum", "(", "0", ",", "-", "2", "*", "grid", "-", "1", ")", "\n", "return", "grid", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.cycle_gaussian": [[171, 181], ["scipy.stats.norm.cdf", "numpy.linspace", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.maximum", "numpy.array", "scipy.stats.norm.ppf"], "function", ["None"], ["", "def", "cycle_gaussian", "(", "starting_value", ",", "num_frames", ",", "loc", "=", "0.", ",", "scale", "=", "1.", ")", ":", "\n", "  ", "\"\"\"Cycles through the quantiles of a Gaussian in a single cycle.\"\"\"", "\n", "starting_prob", "=", "scipy", ".", "stats", ".", "norm", ".", "cdf", "(", "starting_value", ",", "loc", "=", "loc", ",", "scale", "=", "scale", ")", "\n", "grid", "=", "np", ".", "linspace", "(", "starting_prob", ",", "starting_prob", "+", "2.", ",", "\n", "num", "=", "num_frames", ",", "endpoint", "=", "False", ")", "\n", "grid", "-=", "np", ".", "maximum", "(", "0", ",", "2", "*", "grid", "-", "2", ")", "\n", "grid", "+=", "np", ".", "maximum", "(", "0", ",", "-", "2", "*", "grid", ")", "\n", "grid", "=", "np", ".", "minimum", "(", "grid", ",", "0.999", ")", "\n", "grid", "=", "np", ".", "maximum", "(", "grid", ",", "0.001", ")", "\n", "return", "np", ".", "array", "(", "[", "scipy", ".", "stats", ".", "norm", ".", "ppf", "(", "i", ",", "loc", "=", "loc", ",", "scale", "=", "scale", ")", "for", "i", "in", "grid", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.cycle_interval": [[183, 191], ["numpy.linspace", "numpy.maximum", "numpy.maximum"], "function", ["None"], ["", "def", "cycle_interval", "(", "starting_value", ",", "num_frames", ",", "min_val", ",", "max_val", ")", ":", "\n", "  ", "\"\"\"Cycles through the state space in a single cycle.\"\"\"", "\n", "starting_in_01", "=", "(", "starting_value", "-", "min_val", ")", "/", "(", "max_val", "-", "min_val", ")", "\n", "grid", "=", "np", ".", "linspace", "(", "starting_in_01", ",", "starting_in_01", "+", "2.", ",", "\n", "num", "=", "num_frames", ",", "endpoint", "=", "False", ")", "\n", "grid", "-=", "np", ".", "maximum", "(", "0", ",", "2", "*", "grid", "-", "2", ")", "\n", "grid", "+=", "np", ".", "maximum", "(", "0", ",", "-", "2", "*", "grid", ")", "\n", "return", "grid", "*", "(", "max_val", "-", "min_val", ")", "+", "min_val", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_model_test.VisualizeTest.test_visualize_sigmoid": [[31, 51], ["absl.testing.parameterized.parameters", "disentanglement_lib.methods.unsupervised.train.train_with_gin", "disentanglement_lib.visualize.visualize_model.visualize", "visualize_model_test.VisualizeTest.create_tempdir", "disentanglement_lib.utils.resources.get_file", "visualize_model_test.VisualizeTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train_with_gin", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_model.visualize", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file"], ["  ", "@", "parameterized", ".", "parameters", "(", "\n", "(", "\"logits\"", ")", ",", "\n", "(", "\"tanh\"", ")", ",", "\n", ")", "\n", "def", "test_visualize_sigmoid", "(", "self", ",", "activation", ")", ":", "\n", "    ", "activation_binding", "=", "(", "\n", "\"reconstruction_loss.activation = '{}'\"", ".", "format", "(", "activation", ")", ")", "\n", "self", ".", "model_dir", "=", "self", ".", "create_tempdir", "(", "\n", "\"model_{}\"", ".", "format", "(", "activation", ")", ",", "\n", "cleanup", "=", "absltest", ".", "TempFileCleanup", ".", "OFF", ")", ".", "full_path", "\n", "train", ".", "train_with_gin", "(", "self", ".", "model_dir", ",", "True", ",", "[", "\n", "resources", ".", "get_file", "(", "\"config/tests/methods/unsupervised/train_test.gin\"", ")", "\n", "]", ",", "[", "activation_binding", "]", ")", "\n", "visualize_model", ".", "visualize", "(", "\n", "self", ".", "model_dir", ",", "\n", "self", ".", "create_tempdir", "(", "\"visualization_{}\"", ".", "format", "(", "activation", ")", ")", ".", "full_path", ",", "\n", "True", ",", "\n", "num_animations", "=", "1", ",", "\n", "num_frames", "=", "4", ",", "\n", "num_points_irs", "=", "100", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_dataset_test.VisualizeDatasetTest.test_visualize": [[26, 29], ["disentanglement_lib.visualize.visualize_dataset.visualize_dataset", "visualize_dataset_test.VisualizeDatasetTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_dataset.visualize_dataset"], ["  ", "def", "test_visualize", "(", "self", ")", ":", "\n", "    ", "visualize_dataset", ".", "visualize_dataset", "(", "\"dummy_data\"", ",", "\n", "self", ".", "create_tempdir", "(", ")", ".", "full_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.config.study.Study.get_model_config": [[26, 29], ["NotImplementedError"], "methods", ["None"], ["def", "get_model_config", "(", "self", ",", "model_num", "=", "0", ")", ":", "\n", "    ", "\"\"\"Returns model bindings and config file.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.config.study.Study.print_model_config": [[30, 41], ["study.Study.get_model_config", "print", "print", "print", "print", "print", "print", "print"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.tests.sweep.TestStudy.get_model_config"], ["", "def", "print_model_config", "(", "self", ",", "model_num", "=", "0", ")", ":", "\n", "    ", "\"\"\"Prints model bindings and config file.\"\"\"", "\n", "model_bindings", ",", "model_config_file", "=", "self", ".", "get_model_config", "(", "model_num", ")", "\n", "print", "(", "\"Gin base config for model training:\"", ")", "\n", "print", "(", "\"--\"", ")", "\n", "print", "(", "model_config_file", ")", "\n", "print", "(", ")", "\n", "print", "(", "\"Gin bindings for model training:\"", ")", "\n", "print", "(", "\"--\"", ")", "\n", "for", "binding", "in", "model_bindings", ":", "\n", "      ", "print", "(", "binding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.config.study.Study.get_postprocess_config_files": [[42, 45], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "get_postprocess_config_files", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns postprocessing config files.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.config.study.Study.print_postprocess_config": [[46, 53], ["print", "print", "study.Study.get_postprocess_config_files", "print"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.tests.sweep.TestStudy.get_postprocess_config_files"], ["", "def", "print_postprocess_config", "(", "self", ")", ":", "\n", "    ", "\"\"\"Prints postprocessing config files.\"\"\"", "\n", "print", "(", "\"Gin config files for postprocessing (random seeds may be set \"", "\n", "\"later):\"", ")", "\n", "print", "(", "\"--\"", ")", "\n", "for", "path", "in", "self", ".", "get_postprocess_config_files", "(", ")", ":", "\n", "      ", "print", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.config.study.Study.get_eval_config_files": [[54, 57], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "get_eval_config_files", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns evaluation config files.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.config.study.Study.print_eval_config": [[58, 64], ["print", "print", "study.Study.get_eval_config_files", "print"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.tests.sweep.TestStudy.get_eval_config_files"], ["", "def", "print_eval_config", "(", "self", ")", ":", "\n", "    ", "\"\"\"Prints evaluation config files.\"\"\"", "\n", "print", "(", "\"Gin config files for evaluation (random seeds may be set later):\"", ")", "\n", "print", "(", "\"--\"", ")", "\n", "for", "path", "in", "self", ".", "get_eval_config_files", "(", ")", ":", "\n", "      ", "print", "(", "path", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.stage1.sweep.AbstractReasoningStudyV1.get_model_config": [[123, 130], ["disentanglement_lib.to_bindings", "disentanglement_lib.utils.resources.get_file", "sweep.get_config"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.to_bindings", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.get_config"], ["def", "get_model_config", "(", "self", ",", "model_num", "=", "0", ")", ":", "\n", "    ", "\"\"\"Returns model bindings and config file.\"\"\"", "\n", "config", "=", "get_config", "(", ")", "[", "model_num", "]", "\n", "model_bindings", "=", "h", ".", "to_bindings", "(", "config", ")", "\n", "model_config_file", "=", "resources", ".", "get_file", "(", "\n", "\"config/abstract_reasoning_study_v1/stage1/model_configs/shared.gin\"", ")", "\n", "return", "model_bindings", ",", "model_config_file", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.stage1.sweep.AbstractReasoningStudyV1.get_postprocess_config_files": [[131, 136], ["list", "disentanglement_lib.utils.resources.get_files_in_folder"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_files_in_folder"], ["", "def", "get_postprocess_config_files", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns postprocessing config files.\"\"\"", "\n", "return", "list", "(", "\n", "resources", ".", "get_files_in_folder", "(", "\n", "\"config/abstract_reasoning_study_v1/stage1/postprocess_configs/\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.stage1.sweep.AbstractReasoningStudyV1.get_eval_config_files": [[137, 142], ["list", "disentanglement_lib.utils.resources.get_files_in_folder"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_files_in_folder"], ["", "def", "get_eval_config_files", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns evaluation config files.\"\"\"", "\n", "return", "list", "(", "\n", "resources", ".", "get_files_in_folder", "(", "\n", "\"config/abstract_reasoning_study_v1/stage1/metric_configs/\"", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.stage1.sweep.get_datasets": [[33, 38], ["disentanglement_lib.sweep", "disentanglement_lib.categorical"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.categorical"], ["def", "get_datasets", "(", ")", ":", "\n", "  ", "\"\"\"Returns all the data sets.\"\"\"", "\n", "return", "h", ".", "sweep", "(", "\n", "\"dataset.name\"", ",", "\n", "h", ".", "categorical", "(", "[", "\"shapes3d\"", ",", "\"abstract_dsprites\"", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.stage1.sweep.get_num_latent": [[40, 42], ["disentanglement_lib.sweep", "disentanglement_lib.discrete"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete"], ["", "def", "get_num_latent", "(", "sweep", ")", ":", "\n", "  ", "return", "h", ".", "sweep", "(", "\"encoder.num_latent\"", ",", "h", ".", "discrete", "(", "sweep", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.stage1.sweep.get_seeds": [[44, 47], ["disentanglement_lib.sweep", "disentanglement_lib.categorical", "list", "six.moves.range"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.categorical"], ["", "def", "get_seeds", "(", "num", ")", ":", "\n", "  ", "\"\"\"Returns random seeds.\"\"\"", "\n", "return", "h", ".", "sweep", "(", "\"model.random_seed\"", ",", "h", ".", "categorical", "(", "list", "(", "range", "(", "num", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.stage1.sweep.get_default_models": [[49, 105], ["disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.sweep", "disentanglement_lib.zipit", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.sweep", "disentanglement_lib.fixed", "disentanglement_lib.zipit", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.sweep", "disentanglement_lib.zipit", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.sweep", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.zipit", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.sweep", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.zipit", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.sweep", "disentanglement_lib.zipit", "disentanglement_lib.chainit", "disentanglement_lib.discrete", "disentanglement_lib.discrete", "disentanglement_lib.discrete", "disentanglement_lib.discrete", "disentanglement_lib.discrete", "disentanglement_lib.discrete"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.chainit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete"], ["", "def", "get_default_models", "(", ")", ":", "\n", "  ", "\"\"\"Our default set of models (6 model * 6 hyperparameters=36 models).\"\"\"", "\n", "# BetaVAE config.", "\n", "model_name", "=", "h", ".", "fixed", "(", "\"model.name\"", ",", "\"beta_vae\"", ")", "\n", "model_fn", "=", "h", ".", "fixed", "(", "\"model.model\"", ",", "\"@vae()\"", ")", "\n", "betas", "=", "h", ".", "sweep", "(", "\"vae.beta\"", ",", "h", ".", "discrete", "(", "[", "1.", ",", "2.", ",", "4.", ",", "6.", ",", "8.", ",", "16.", "]", ")", ")", "\n", "config_beta_vae", "=", "h", ".", "zipit", "(", "[", "model_name", ",", "betas", ",", "model_fn", "]", ")", "\n", "\n", "# AnnealedVAE config.", "\n", "model_name", "=", "h", ".", "fixed", "(", "\"model.name\"", ",", "\"annealed_vae\"", ")", "\n", "model_fn", "=", "h", ".", "fixed", "(", "\"model.model\"", ",", "\"@annealed_vae()\"", ")", "\n", "iteration_threshold", "=", "h", ".", "fixed", "(", "\"annealed_vae.iteration_threshold\"", ",", "100000", ")", "\n", "c", "=", "h", ".", "sweep", "(", "\"annealed_vae.c_max\"", ",", "h", ".", "discrete", "(", "[", "5.", ",", "10.", ",", "25.", ",", "50.", ",", "75.", ",", "100.", "]", ")", ")", "\n", "gamma", "=", "h", ".", "fixed", "(", "\"annealed_vae.gamma\"", ",", "1000", ")", "\n", "config_annealed_beta_vae", "=", "h", ".", "zipit", "(", "\n", "[", "model_name", ",", "c", ",", "iteration_threshold", ",", "gamma", ",", "model_fn", "]", ")", "\n", "\n", "# FactorVAE config.", "\n", "model_name", "=", "h", ".", "fixed", "(", "\"model.name\"", ",", "\"factor_vae\"", ")", "\n", "model_fn", "=", "h", ".", "fixed", "(", "\"model.model\"", ",", "\"@factor_vae()\"", ")", "\n", "discr_fn", "=", "h", ".", "fixed", "(", "\"discriminator.discriminator_fn\"", ",", "\"@fc_discriminator\"", ")", "\n", "\n", "gammas", "=", "h", ".", "sweep", "(", "\"factor_vae.gamma\"", ",", "\n", "h", ".", "discrete", "(", "[", "10.", ",", "20.", ",", "30.", ",", "40.", ",", "50.", ",", "100.", "]", ")", ")", "\n", "config_factor_vae", "=", "h", ".", "zipit", "(", "[", "model_name", ",", "gammas", ",", "model_fn", ",", "discr_fn", "]", ")", "\n", "\n", "# DIP-VAE-I config.", "\n", "model_name", "=", "h", ".", "fixed", "(", "\"model.name\"", ",", "\"dip_vae_i\"", ")", "\n", "model_fn", "=", "h", ".", "fixed", "(", "\"model.model\"", ",", "\"@dip_vae()\"", ")", "\n", "lambda_od", "=", "h", ".", "sweep", "(", "\"dip_vae.lambda_od\"", ",", "\n", "h", ".", "discrete", "(", "[", "1.", ",", "2.", ",", "5.", ",", "10.", ",", "20.", ",", "50.", "]", ")", ")", "\n", "lambda_d_factor", "=", "h", ".", "fixed", "(", "\"dip_vae.lambda_d_factor\"", ",", "10.", ")", "\n", "dip_type", "=", "h", ".", "fixed", "(", "\"dip_vae.dip_type\"", ",", "\"i\"", ")", "\n", "config_dip_vae_i", "=", "h", ".", "zipit", "(", "\n", "[", "model_name", ",", "model_fn", ",", "lambda_od", ",", "lambda_d_factor", ",", "dip_type", "]", ")", "\n", "\n", "# DIP-VAE-II config.", "\n", "model_name", "=", "h", ".", "fixed", "(", "\"model.name\"", ",", "\"dip_vae_ii\"", ")", "\n", "model_fn", "=", "h", ".", "fixed", "(", "\"model.model\"", ",", "\"@dip_vae()\"", ")", "\n", "lambda_od", "=", "h", ".", "sweep", "(", "\"dip_vae.lambda_od\"", ",", "\n", "h", ".", "discrete", "(", "[", "1.", ",", "2.", ",", "5.", ",", "10.", ",", "20.", ",", "50.", "]", ")", ")", "\n", "lambda_d_factor", "=", "h", ".", "fixed", "(", "\"dip_vae.lambda_d_factor\"", ",", "1.", ")", "\n", "dip_type", "=", "h", ".", "fixed", "(", "\"dip_vae.dip_type\"", ",", "\"ii\"", ")", "\n", "config_dip_vae_ii", "=", "h", ".", "zipit", "(", "\n", "[", "model_name", ",", "model_fn", ",", "lambda_od", ",", "lambda_d_factor", ",", "dip_type", "]", ")", "\n", "\n", "# BetaTCVAE config.", "\n", "model_name", "=", "h", ".", "fixed", "(", "\"model.name\"", ",", "\"beta_tc_vae\"", ")", "\n", "model_fn", "=", "h", ".", "fixed", "(", "\"model.model\"", ",", "\"@beta_tc_vae()\"", ")", "\n", "betas", "=", "h", ".", "sweep", "(", "\"beta_tc_vae.beta\"", ",", "h", ".", "discrete", "(", "[", "1.", ",", "2.", ",", "4.", ",", "6.", ",", "8.", ",", "10.", "]", ")", ")", "\n", "config_beta_tc_vae", "=", "h", ".", "zipit", "(", "[", "model_name", ",", "model_fn", ",", "betas", "]", ")", "\n", "all_models", "=", "h", ".", "chainit", "(", "[", "\n", "config_beta_vae", ",", "config_factor_vae", ",", "config_dip_vae_i", ",", "config_dip_vae_ii", ",", "\n", "config_beta_tc_vae", ",", "config_annealed_beta_vae", "\n", "]", ")", "\n", "return", "all_models", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.stage1.sweep.get_config": [[107, 117], ["disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.zipit", "disentanglement_lib.product", "sweep.get_datasets", "sweep.get_default_models", "sweep.get_seeds"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.product", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.get_datasets", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.get_default_models", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.get_seeds"], ["", "def", "get_config", "(", ")", ":", "\n", "  ", "\"\"\"Returns the hyperparameter configs for different experiments.\"\"\"", "\n", "arch_enc", "=", "h", ".", "fixed", "(", "\"encoder.encoder_fn\"", ",", "\"@conv_encoder\"", ",", "length", "=", "1", ")", "\n", "arch_dec", "=", "h", ".", "fixed", "(", "\"decoder.decoder_fn\"", ",", "\"@deconv_decoder\"", ",", "length", "=", "1", ")", "\n", "architecture", "=", "h", ".", "zipit", "(", "[", "arch_enc", ",", "arch_dec", "]", ")", "\n", "return", "h", ".", "product", "(", "[", "\n", "get_datasets", "(", ")", ",", "\n", "architecture", ",", "\n", "get_default_models", "(", ")", ",", "\n", "get_seeds", "(", "5", ")", ",", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.fairness_study_v1.sweep.FairnessStudyV1.get_model_config": [[126, 133], ["disentanglement_lib.to_bindings", "disentanglement_lib.utils.resources.get_file", "sweep.get_config"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.to_bindings", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.get_config"], ["model_bindings", "=", "h", ".", "to_bindings", "(", "config", ")", "\n", "model_config_file", "=", "resources", ".", "get_file", "(", "\n", "\"config/abstract_reasoning_study_v1/stage1/model_configs/shared.gin\"", ")", "\n", "return", "model_bindings", ",", "model_config_file", "\n", "\n", "", "def", "get_postprocess_config_files", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns postprocessing config files.\"\"\"", "\n", "return", "list", "(", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.fairness_study_v1.sweep.FairnessStudyV1.get_postprocess_config_files": [[134, 139], ["list", "disentanglement_lib.utils.resources.get_files_in_folder"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_files_in_folder"], ["resources", ".", "get_files_in_folder", "(", "\n", "\"config/abstract_reasoning_study_v1/stage1/postprocess_configs/\"", ")", ")", "\n", "\n", "", "def", "get_eval_config_files", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns evaluation config files.\"\"\"", "\n", "return", "list", "(", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.fairness_study_v1.sweep.FairnessStudyV1.get_eval_config_files": [[140, 145], ["list", "disentanglement_lib.utils.resources.get_files_in_folder"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_files_in_folder"], ["resources", ".", "get_files_in_folder", "(", "\n", "\"config/abstract_reasoning_study_v1/stage1/metric_configs/\"", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.fairness_study_v1.sweep.get_datasets": [[33, 40], ["disentanglement_lib.sweep", "disentanglement_lib.categorical"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.categorical"], ["def", "get_datasets", "(", ")", ":", "\n", "  ", "\"\"\"Returns all the data sets.\"\"\"", "\n", "return", "h", ".", "sweep", "(", "\n", "\"dataset.name\"", ",", "\n", "h", ".", "categorical", "(", "[", "\"shapes3d\"", ",", "\"abstract_dsprites\"", "]", ")", ")", "\n", "\n", "\n", "", "def", "get_num_latent", "(", "sweep", ")", ":", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.fairness_study_v1.sweep.get_num_latent": [[43, 45], ["disentanglement_lib.sweep", "disentanglement_lib.discrete"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete"], ["\n", "", "def", "get_seeds", "(", "num", ")", ":", "\n", "  ", "\"\"\"Returns random seeds.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.fairness_study_v1.sweep.get_seeds": [[47, 50], ["disentanglement_lib.sweep", "disentanglement_lib.categorical", "list", "six.moves.range"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.categorical"], ["\n", "\n", "", "def", "get_default_models", "(", ")", ":", "\n", "  ", "\"\"\"Our default set of models (6 model * 6 hyperparameters=36 models).\"\"\"", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.fairness_study_v1.sweep.get_default_models": [[52, 108], ["disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.sweep", "disentanglement_lib.zipit", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.sweep", "disentanglement_lib.fixed", "disentanglement_lib.zipit", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.sweep", "disentanglement_lib.zipit", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.sweep", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.zipit", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.sweep", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.zipit", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.sweep", "disentanglement_lib.zipit", "disentanglement_lib.chainit", "disentanglement_lib.discrete", "disentanglement_lib.discrete", "disentanglement_lib.discrete", "disentanglement_lib.discrete", "disentanglement_lib.discrete", "disentanglement_lib.discrete"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.chainit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete"], ["model_name", "=", "h", ".", "fixed", "(", "\"model.name\"", ",", "\"beta_vae\"", ")", "\n", "model_fn", "=", "h", ".", "fixed", "(", "\"model.model\"", ",", "\"@vae()\"", ")", "\n", "betas", "=", "h", ".", "sweep", "(", "\"vae.beta\"", ",", "h", ".", "discrete", "(", "[", "1.", ",", "2.", ",", "4.", ",", "6.", ",", "8.", ",", "16.", "]", ")", ")", "\n", "config_beta_vae", "=", "h", ".", "zipit", "(", "[", "model_name", ",", "betas", ",", "model_fn", "]", ")", "\n", "\n", "# AnnealedVAE config.", "\n", "model_name", "=", "h", ".", "fixed", "(", "\"model.name\"", ",", "\"annealed_vae\"", ")", "\n", "model_fn", "=", "h", ".", "fixed", "(", "\"model.model\"", ",", "\"@annealed_vae()\"", ")", "\n", "iteration_threshold", "=", "h", ".", "fixed", "(", "\"annealed_vae.iteration_threshold\"", ",", "100000", ")", "\n", "c", "=", "h", ".", "sweep", "(", "\"annealed_vae.c_max\"", ",", "h", ".", "discrete", "(", "[", "5.", ",", "10.", ",", "25.", ",", "50.", ",", "75.", ",", "100.", "]", ")", ")", "\n", "gamma", "=", "h", ".", "fixed", "(", "\"annealed_vae.gamma\"", ",", "1000", ")", "\n", "config_annealed_beta_vae", "=", "h", ".", "zipit", "(", "\n", "[", "model_name", ",", "c", ",", "iteration_threshold", ",", "gamma", ",", "model_fn", "]", ")", "\n", "\n", "# FactorVAE config.", "\n", "model_name", "=", "h", ".", "fixed", "(", "\"model.name\"", ",", "\"factor_vae\"", ")", "\n", "model_fn", "=", "h", ".", "fixed", "(", "\"model.model\"", ",", "\"@factor_vae()\"", ")", "\n", "discr_fn", "=", "h", ".", "fixed", "(", "\"discriminator.discriminator_fn\"", ",", "\"@fc_discriminator\"", ")", "\n", "\n", "gammas", "=", "h", ".", "sweep", "(", "\"factor_vae.gamma\"", ",", "\n", "h", ".", "discrete", "(", "[", "10.", ",", "20.", ",", "30.", ",", "40.", ",", "50.", ",", "100.", "]", ")", ")", "\n", "config_factor_vae", "=", "h", ".", "zipit", "(", "[", "model_name", ",", "gammas", ",", "model_fn", ",", "discr_fn", "]", ")", "\n", "\n", "# DIP-VAE-I config.", "\n", "model_name", "=", "h", ".", "fixed", "(", "\"model.name\"", ",", "\"dip_vae_i\"", ")", "\n", "model_fn", "=", "h", ".", "fixed", "(", "\"model.model\"", ",", "\"@dip_vae()\"", ")", "\n", "lambda_od", "=", "h", ".", "sweep", "(", "\"dip_vae.lambda_od\"", ",", "\n", "h", ".", "discrete", "(", "[", "1.", ",", "2.", ",", "5.", ",", "10.", ",", "20.", ",", "50.", "]", ")", ")", "\n", "lambda_d_factor", "=", "h", ".", "fixed", "(", "\"dip_vae.lambda_d_factor\"", ",", "10.", ")", "\n", "dip_type", "=", "h", ".", "fixed", "(", "\"dip_vae.dip_type\"", ",", "\"i\"", ")", "\n", "config_dip_vae_i", "=", "h", ".", "zipit", "(", "\n", "[", "model_name", ",", "model_fn", ",", "lambda_od", ",", "lambda_d_factor", ",", "dip_type", "]", ")", "\n", "\n", "# DIP-VAE-II config.", "\n", "model_name", "=", "h", ".", "fixed", "(", "\"model.name\"", ",", "\"dip_vae_ii\"", ")", "\n", "model_fn", "=", "h", ".", "fixed", "(", "\"model.model\"", ",", "\"@dip_vae()\"", ")", "\n", "lambda_od", "=", "h", ".", "sweep", "(", "\"dip_vae.lambda_od\"", ",", "\n", "h", ".", "discrete", "(", "[", "1.", ",", "2.", ",", "5.", ",", "10.", ",", "20.", ",", "50.", "]", ")", ")", "\n", "lambda_d_factor", "=", "h", ".", "fixed", "(", "\"dip_vae.lambda_d_factor\"", ",", "1.", ")", "\n", "dip_type", "=", "h", ".", "fixed", "(", "\"dip_vae.dip_type\"", ",", "\"ii\"", ")", "\n", "config_dip_vae_ii", "=", "h", ".", "zipit", "(", "\n", "[", "model_name", ",", "model_fn", ",", "lambda_od", ",", "lambda_d_factor", ",", "dip_type", "]", ")", "\n", "\n", "# BetaTCVAE config.", "\n", "model_name", "=", "h", ".", "fixed", "(", "\"model.name\"", ",", "\"beta_tc_vae\"", ")", "\n", "model_fn", "=", "h", ".", "fixed", "(", "\"model.model\"", ",", "\"@beta_tc_vae()\"", ")", "\n", "betas", "=", "h", ".", "sweep", "(", "\"beta_tc_vae.beta\"", ",", "h", ".", "discrete", "(", "[", "1.", ",", "2.", ",", "4.", ",", "6.", ",", "8.", ",", "10.", "]", ")", ")", "\n", "config_beta_tc_vae", "=", "h", ".", "zipit", "(", "[", "model_name", ",", "model_fn", ",", "betas", "]", ")", "\n", "all_models", "=", "h", ".", "chainit", "(", "[", "\n", "config_beta_vae", ",", "config_factor_vae", ",", "config_dip_vae_i", ",", "config_dip_vae_ii", ",", "\n", "config_beta_tc_vae", ",", "config_annealed_beta_vae", "\n", "]", ")", "\n", "return", "all_models", "\n", "\n", "\n", "", "def", "get_config", "(", ")", ":", "\n", "  ", "\"\"\"Returns the hyperparameter configs for different experiments.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.fairness_study_v1.sweep.get_config": [[110, 120], ["disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.zipit", "disentanglement_lib.product", "sweep.get_datasets", "sweep.get_default_models", "sweep.get_seeds"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.product", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.get_datasets", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.get_default_models", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.get_seeds"], ["arch_dec", "=", "h", ".", "fixed", "(", "\"decoder.decoder_fn\"", ",", "\"@deconv_decoder\"", ",", "length", "=", "1", ")", "\n", "architecture", "=", "h", ".", "zipit", "(", "[", "arch_enc", ",", "arch_dec", "]", ")", "\n", "return", "h", ".", "product", "(", "[", "\n", "get_datasets", "(", ")", ",", "\n", "architecture", ",", "\n", "get_default_models", "(", ")", ",", "\n", "get_seeds", "(", "5", ")", ",", "\n", "]", ")", "\n", "\n", "\n", "", "class", "AbstractReasoningStudyV1", "(", "study", ".", "Study", ")", ":", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.UnsupervisedStudyV1.get_model_config": [[126, 133], ["disentanglement_lib.to_bindings", "disentanglement_lib.utils.resources.get_file", "sweep.get_config"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.to_bindings", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.get_config"], ["model_bindings", "=", "h", ".", "to_bindings", "(", "config", ")", "\n", "model_config_file", "=", "resources", ".", "get_file", "(", "\n", "\"config/abstract_reasoning_study_v1/stage1/model_configs/shared.gin\"", ")", "\n", "return", "model_bindings", ",", "model_config_file", "\n", "\n", "", "def", "get_postprocess_config_files", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns postprocessing config files.\"\"\"", "\n", "return", "list", "(", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.UnsupervisedStudyV1.get_postprocess_config_files": [[134, 139], ["list", "disentanglement_lib.utils.resources.get_files_in_folder"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_files_in_folder"], ["resources", ".", "get_files_in_folder", "(", "\n", "\"config/abstract_reasoning_study_v1/stage1/postprocess_configs/\"", ")", ")", "\n", "\n", "", "def", "get_eval_config_files", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns evaluation config files.\"\"\"", "\n", "return", "list", "(", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.UnsupervisedStudyV1.get_eval_config_files": [[140, 145], ["list", "disentanglement_lib.utils.resources.get_files_in_folder"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_files_in_folder"], ["resources", ".", "get_files_in_folder", "(", "\n", "\"config/abstract_reasoning_study_v1/stage1/metric_configs/\"", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.get_datasets": [[33, 40], ["disentanglement_lib.sweep", "disentanglement_lib.categorical"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.categorical"], ["def", "get_datasets", "(", ")", ":", "\n", "  ", "\"\"\"Returns all the data sets.\"\"\"", "\n", "return", "h", ".", "sweep", "(", "\n", "\"dataset.name\"", ",", "\n", "h", ".", "categorical", "(", "[", "\"shapes3d\"", ",", "\"abstract_dsprites\"", "]", ")", ")", "\n", "\n", "\n", "", "def", "get_num_latent", "(", "sweep", ")", ":", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.get_num_latent": [[43, 45], ["disentanglement_lib.sweep", "disentanglement_lib.discrete"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete"], ["\n", "", "def", "get_seeds", "(", "num", ")", ":", "\n", "  ", "\"\"\"Returns random seeds.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.get_seeds": [[47, 50], ["disentanglement_lib.sweep", "disentanglement_lib.categorical", "list", "six.moves.range"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.categorical"], ["\n", "\n", "", "def", "get_default_models", "(", ")", ":", "\n", "  ", "\"\"\"Our default set of models (6 model * 6 hyperparameters=36 models).\"\"\"", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.get_default_models": [[52, 108], ["disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.sweep", "disentanglement_lib.zipit", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.sweep", "disentanglement_lib.fixed", "disentanglement_lib.zipit", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.sweep", "disentanglement_lib.zipit", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.sweep", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.zipit", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.sweep", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.zipit", "disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.sweep", "disentanglement_lib.zipit", "disentanglement_lib.chainit", "disentanglement_lib.discrete", "disentanglement_lib.discrete", "disentanglement_lib.discrete", "disentanglement_lib.discrete", "disentanglement_lib.discrete", "disentanglement_lib.discrete"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.sweep", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.chainit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.discrete"], ["model_name", "=", "h", ".", "fixed", "(", "\"model.name\"", ",", "\"beta_vae\"", ")", "\n", "model_fn", "=", "h", ".", "fixed", "(", "\"model.model\"", ",", "\"@vae()\"", ")", "\n", "betas", "=", "h", ".", "sweep", "(", "\"vae.beta\"", ",", "h", ".", "discrete", "(", "[", "1.", ",", "2.", ",", "4.", ",", "6.", ",", "8.", ",", "16.", "]", ")", ")", "\n", "config_beta_vae", "=", "h", ".", "zipit", "(", "[", "model_name", ",", "betas", ",", "model_fn", "]", ")", "\n", "\n", "# AnnealedVAE config.", "\n", "model_name", "=", "h", ".", "fixed", "(", "\"model.name\"", ",", "\"annealed_vae\"", ")", "\n", "model_fn", "=", "h", ".", "fixed", "(", "\"model.model\"", ",", "\"@annealed_vae()\"", ")", "\n", "iteration_threshold", "=", "h", ".", "fixed", "(", "\"annealed_vae.iteration_threshold\"", ",", "100000", ")", "\n", "c", "=", "h", ".", "sweep", "(", "\"annealed_vae.c_max\"", ",", "h", ".", "discrete", "(", "[", "5.", ",", "10.", ",", "25.", ",", "50.", ",", "75.", ",", "100.", "]", ")", ")", "\n", "gamma", "=", "h", ".", "fixed", "(", "\"annealed_vae.gamma\"", ",", "1000", ")", "\n", "config_annealed_beta_vae", "=", "h", ".", "zipit", "(", "\n", "[", "model_name", ",", "c", ",", "iteration_threshold", ",", "gamma", ",", "model_fn", "]", ")", "\n", "\n", "# FactorVAE config.", "\n", "model_name", "=", "h", ".", "fixed", "(", "\"model.name\"", ",", "\"factor_vae\"", ")", "\n", "model_fn", "=", "h", ".", "fixed", "(", "\"model.model\"", ",", "\"@factor_vae()\"", ")", "\n", "discr_fn", "=", "h", ".", "fixed", "(", "\"discriminator.discriminator_fn\"", ",", "\"@fc_discriminator\"", ")", "\n", "\n", "gammas", "=", "h", ".", "sweep", "(", "\"factor_vae.gamma\"", ",", "\n", "h", ".", "discrete", "(", "[", "10.", ",", "20.", ",", "30.", ",", "40.", ",", "50.", ",", "100.", "]", ")", ")", "\n", "config_factor_vae", "=", "h", ".", "zipit", "(", "[", "model_name", ",", "gammas", ",", "model_fn", ",", "discr_fn", "]", ")", "\n", "\n", "# DIP-VAE-I config.", "\n", "model_name", "=", "h", ".", "fixed", "(", "\"model.name\"", ",", "\"dip_vae_i\"", ")", "\n", "model_fn", "=", "h", ".", "fixed", "(", "\"model.model\"", ",", "\"@dip_vae()\"", ")", "\n", "lambda_od", "=", "h", ".", "sweep", "(", "\"dip_vae.lambda_od\"", ",", "\n", "h", ".", "discrete", "(", "[", "1.", ",", "2.", ",", "5.", ",", "10.", ",", "20.", ",", "50.", "]", ")", ")", "\n", "lambda_d_factor", "=", "h", ".", "fixed", "(", "\"dip_vae.lambda_d_factor\"", ",", "10.", ")", "\n", "dip_type", "=", "h", ".", "fixed", "(", "\"dip_vae.dip_type\"", ",", "\"i\"", ")", "\n", "config_dip_vae_i", "=", "h", ".", "zipit", "(", "\n", "[", "model_name", ",", "model_fn", ",", "lambda_od", ",", "lambda_d_factor", ",", "dip_type", "]", ")", "\n", "\n", "# DIP-VAE-II config.", "\n", "model_name", "=", "h", ".", "fixed", "(", "\"model.name\"", ",", "\"dip_vae_ii\"", ")", "\n", "model_fn", "=", "h", ".", "fixed", "(", "\"model.model\"", ",", "\"@dip_vae()\"", ")", "\n", "lambda_od", "=", "h", ".", "sweep", "(", "\"dip_vae.lambda_od\"", ",", "\n", "h", ".", "discrete", "(", "[", "1.", ",", "2.", ",", "5.", ",", "10.", ",", "20.", ",", "50.", "]", ")", ")", "\n", "lambda_d_factor", "=", "h", ".", "fixed", "(", "\"dip_vae.lambda_d_factor\"", ",", "1.", ")", "\n", "dip_type", "=", "h", ".", "fixed", "(", "\"dip_vae.dip_type\"", ",", "\"ii\"", ")", "\n", "config_dip_vae_ii", "=", "h", ".", "zipit", "(", "\n", "[", "model_name", ",", "model_fn", ",", "lambda_od", ",", "lambda_d_factor", ",", "dip_type", "]", ")", "\n", "\n", "# BetaTCVAE config.", "\n", "model_name", "=", "h", ".", "fixed", "(", "\"model.name\"", ",", "\"beta_tc_vae\"", ")", "\n", "model_fn", "=", "h", ".", "fixed", "(", "\"model.model\"", ",", "\"@beta_tc_vae()\"", ")", "\n", "betas", "=", "h", ".", "sweep", "(", "\"beta_tc_vae.beta\"", ",", "h", ".", "discrete", "(", "[", "1.", ",", "2.", ",", "4.", ",", "6.", ",", "8.", ",", "10.", "]", ")", ")", "\n", "config_beta_tc_vae", "=", "h", ".", "zipit", "(", "[", "model_name", ",", "model_fn", ",", "betas", "]", ")", "\n", "all_models", "=", "h", ".", "chainit", "(", "[", "\n", "config_beta_vae", ",", "config_factor_vae", ",", "config_dip_vae_i", ",", "config_dip_vae_ii", ",", "\n", "config_beta_tc_vae", ",", "config_annealed_beta_vae", "\n", "]", ")", "\n", "return", "all_models", "\n", "\n", "\n", "", "def", "get_config", "(", ")", ":", "\n", "  ", "\"\"\"Returns the hyperparameter configs for different experiments.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.get_config": [[110, 120], ["disentanglement_lib.fixed", "disentanglement_lib.fixed", "disentanglement_lib.zipit", "disentanglement_lib.product", "sweep.get_datasets", "sweep.get_default_models", "sweep.get_seeds"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.fixed", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.zipit", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.hyperparams.product", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.get_datasets", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.get_default_models", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised_study_v1.sweep.get_seeds"], ["arch_dec", "=", "h", ".", "fixed", "(", "\"decoder.decoder_fn\"", ",", "\"@deconv_decoder\"", ",", "length", "=", "1", ")", "\n", "architecture", "=", "h", ".", "zipit", "(", "[", "arch_enc", ",", "arch_dec", "]", ")", "\n", "return", "h", ".", "product", "(", "[", "\n", "get_datasets", "(", ")", ",", "\n", "architecture", ",", "\n", "get_default_models", "(", ")", ",", "\n", "get_seeds", "(", "5", ")", ",", "\n", "]", ")", "\n", "\n", "\n", "", "class", "AbstractReasoningStudyV1", "(", "study", ".", "Study", ")", ":", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.tests.sweep.TestStudy.get_model_config": [[27, 31], ["disentanglement_lib.utils.resources.get_file"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file"], ["from", "disentanglement_lib", ".", "config", "import", "study", "\n", "from", "disentanglement_lib", ".", "utils", "import", "resources", "\n", "import", "disentanglement_lib", ".", "utils", ".", "hyperparams", "as", "h", "\n", "from", "six", ".", "moves", "import", "range", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.tests.sweep.TestStudy.get_postprocess_config_files": [[32, 37], ["list", "disentanglement_lib.utils.resources.get_files_in_folder"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_files_in_folder"], ["\n", "def", "get_datasets", "(", ")", ":", "\n", "  ", "\"\"\"Returns all the data sets.\"\"\"", "\n", "return", "h", ".", "sweep", "(", "\n", "\"dataset.name\"", ",", "\n", "h", ".", "categorical", "(", "[", "\"shapes3d\"", ",", "\"abstract_dsprites\"", "]", ")", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.tests.sweep.TestStudy.get_eval_config_files": [[38, 43], ["list", "disentanglement_lib.utils.resources.get_files_in_folder"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_files_in_folder"], ["\n", "\n", "", "def", "get_num_latent", "(", "sweep", ")", ":", "\n", "  ", "return", "h", ".", "sweep", "(", "\"encoder.num_latent\"", ",", "h", ".", "discrete", "(", "sweep", ")", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.cars3d.Cars3D.__init__": [[49, 60], ["sklearn.utils.extmath.cartesian", "disentanglement_lib.data.ground_truth.util.StateSpaceAtomIndex", "disentanglement_lib.data.ground_truth.util.SplitDiscreteStateSpace", "cars3d.Cars3D._load_data", "numpy.array", "list", "six.moves.range"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.cars3d.Cars3D._load_data"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "self", ".", "factor_sizes", "=", "[", "4", ",", "24", ",", "183", "]", "\n", "features", "=", "extmath", ".", "cartesian", "(", "\n", "[", "np", ".", "array", "(", "list", "(", "range", "(", "i", ")", ")", ")", "for", "i", "in", "self", ".", "factor_sizes", "]", ")", "\n", "self", ".", "latent_factor_indices", "=", "[", "0", ",", "1", ",", "2", "]", "\n", "self", ".", "num_total_factors", "=", "features", ".", "shape", "[", "1", "]", "\n", "self", ".", "index", "=", "util", ".", "StateSpaceAtomIndex", "(", "self", ".", "factor_sizes", ",", "features", ")", "\n", "self", ".", "state_space", "=", "util", ".", "SplitDiscreteStateSpace", "(", "self", ".", "factor_sizes", ",", "\n", "self", ".", "latent_factor_indices", ")", "\n", "self", ".", "data_shape", "=", "[", "64", ",", "64", ",", "3", "]", "\n", "self", ".", "images", "=", "self", ".", "_load_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.cars3d.Cars3D.num_factors": [[61, 64], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_factors", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "state_space", ".", "num_latent_factors", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.cars3d.Cars3D.factors_num_values": [[65, 68], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "factors_num_values", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "factor_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.cars3d.Cars3D.observation_shape": [[70, 73], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "observation_shape", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "data_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.cars3d.Cars3D.sample_factors": [[74, 77], ["cars3d.Cars3D.state_space.sample_latent_factors"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.SplitDiscreteStateSpace.sample_latent_factors"], ["", "def", "sample_factors", "(", "self", ",", "num", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a batch of factors Y.\"\"\"", "\n", "return", "self", ".", "state_space", ".", "sample_latent_factors", "(", "num", ",", "random_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.cars3d.Cars3D.sample_observations_from_factors": [[78, 83], ["cars3d.Cars3D.state_space.sample_all_factors", "cars3d.Cars3D.index.features_to_index", "cars3d.Cars3D.images[].astype"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.SplitDiscreteStateSpace.sample_all_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.StateSpaceAtomIndex.features_to_index"], ["", "def", "sample_observations_from_factors", "(", "self", ",", "factors", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a batch of observations X given a batch of factors Y.\"\"\"", "\n", "all_factors", "=", "self", ".", "state_space", ".", "sample_all_factors", "(", "factors", ",", "random_state", ")", "\n", "indices", "=", "self", ".", "index", ".", "features_to_index", "(", "all_factors", ")", "\n", "return", "self", ".", "images", "[", "indices", "]", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.cars3d.Cars3D._load_data": [[84, 100], ["numpy.zeros", "enumerate", "cars3d._load_mesh", "numpy.array", "numpy.array", "numpy.transpose", "cars3d.Cars3D.index.features_to_index", "tensorflow.compat.v1.gfile.ListDirectory", "list", "list", "six.moves.range", "six.moves.range", "numpy.tile", "numpy.repeat", "numpy.tile", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.cars3d._load_mesh", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.StateSpaceAtomIndex.features_to_index", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.repeat"], ["", "def", "_load_data", "(", "self", ")", ":", "\n", "    ", "dataset", "=", "np", ".", "zeros", "(", "(", "24", "*", "4", "*", "183", ",", "64", ",", "64", ",", "3", ")", ")", "\n", "all_files", "=", "[", "x", "for", "x", "in", "gfile", ".", "ListDirectory", "(", "CARS3D_PATH", ")", "if", "\".mat\"", "in", "x", "]", "\n", "for", "i", ",", "filename", "in", "enumerate", "(", "all_files", ")", ":", "\n", "      ", "data_mesh", "=", "_load_mesh", "(", "filename", ")", "\n", "factor1", "=", "np", ".", "array", "(", "list", "(", "range", "(", "4", ")", ")", ")", "\n", "factor2", "=", "np", ".", "array", "(", "list", "(", "range", "(", "24", ")", ")", ")", "\n", "all_factors", "=", "np", ".", "transpose", "(", "[", "\n", "np", ".", "tile", "(", "factor1", ",", "len", "(", "factor2", ")", ")", ",", "\n", "np", ".", "repeat", "(", "factor2", ",", "len", "(", "factor1", ")", ")", ",", "\n", "np", ".", "tile", "(", "i", ",", "\n", "len", "(", "factor1", ")", "*", "len", "(", "factor2", ")", ")", "\n", "]", ")", "\n", "indexes", "=", "self", ".", "index", ".", "features_to_index", "(", "all_factors", ")", "\n", "dataset", "[", "indexes", "]", "=", "data_mesh", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.cars3d._load_mesh": [[102, 113], ["np.einsum.reshape", "numpy.zeros", "six.moves.range", "tensorflow.compat.v1.gfile.Open", "numpy.einsum", "PIL.Image.fromarray", "PIL.Image.fromarray.thumbnail", "numpy.array", "os.path.join", "scipy.loadmat"], "function", ["None"], ["", "", "def", "_load_mesh", "(", "filename", ")", ":", "\n", "  ", "\"\"\"Parses a single source file and rescales contained images.\"\"\"", "\n", "with", "gfile", ".", "Open", "(", "os", ".", "path", ".", "join", "(", "CARS3D_PATH", ",", "filename", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "    ", "mesh", "=", "np", ".", "einsum", "(", "\"abcde->deabc\"", ",", "sio", ".", "loadmat", "(", "f", ")", "[", "\"im\"", "]", ")", "\n", "", "flattened_mesh", "=", "mesh", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "mesh", ".", "shape", "[", "2", ":", "]", ")", "\n", "rescaled_mesh", "=", "np", ".", "zeros", "(", "(", "flattened_mesh", ".", "shape", "[", "0", "]", ",", "64", ",", "64", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "flattened_mesh", ".", "shape", "[", "0", "]", ")", ":", "\n", "    ", "pic", "=", "PIL", ".", "Image", ".", "fromarray", "(", "flattened_mesh", "[", "i", ",", ":", ",", ":", ",", ":", "]", ")", "\n", "pic", ".", "thumbnail", "(", "(", "64", ",", "64", ",", "3", ")", ",", "PIL", ".", "Image", ".", "ANTIALIAS", ")", "\n", "rescaled_mesh", "[", "i", ",", ":", ",", ":", ",", ":", "]", "=", "np", ".", "array", "(", "pic", ")", "\n", "", "return", "rescaled_mesh", "*", "1.", "/", "255", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.norb.SmallNORB.__init__": [[55, 65], ["norb._load_small_norb_chunks", "disentanglement_lib.data.ground_truth.util.StateSpaceAtomIndex", "disentanglement_lib.data.ground_truth.util.SplitDiscreteStateSpace"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.norb._load_small_norb_chunks"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "self", ".", "images", ",", "features", "=", "_load_small_norb_chunks", "(", "SMALLNORB_TEMPLATE", ",", "\n", "SMALLNORB_CHUNKS", ")", "\n", "self", ".", "factor_sizes", "=", "[", "5", ",", "10", ",", "9", ",", "18", ",", "6", "]", "\n", "# Instances are not part of the latent space.", "\n", "self", ".", "latent_factor_indices", "=", "[", "0", ",", "2", ",", "3", ",", "4", "]", "\n", "self", ".", "num_total_factors", "=", "features", ".", "shape", "[", "1", "]", "\n", "self", ".", "index", "=", "util", ".", "StateSpaceAtomIndex", "(", "self", ".", "factor_sizes", ",", "features", ")", "\n", "self", ".", "state_space", "=", "util", ".", "SplitDiscreteStateSpace", "(", "self", ".", "factor_sizes", ",", "\n", "self", ".", "latent_factor_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.norb.SmallNORB.num_factors": [[66, 69], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_factors", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "state_space", ".", "num_latent_factors", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.norb.SmallNORB.factors_num_values": [[70, 73], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "factors_num_values", "(", "self", ")", ":", "\n", "    ", "return", "[", "self", ".", "factor_sizes", "[", "i", "]", "for", "i", "in", "self", ".", "latent_factor_indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.norb.SmallNORB.observation_shape": [[74, 77], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "observation_shape", "(", "self", ")", ":", "\n", "    ", "return", "[", "64", ",", "64", ",", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.norb.SmallNORB.sample_factors": [[79, 82], ["norb.SmallNORB.state_space.sample_latent_factors"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.SplitDiscreteStateSpace.sample_latent_factors"], ["", "def", "sample_factors", "(", "self", ",", "num", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a batch of factors Y.\"\"\"", "\n", "return", "self", ".", "state_space", ".", "sample_latent_factors", "(", "num", ",", "random_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.norb.SmallNORB.sample_observations_from_factors": [[83, 87], ["norb.SmallNORB.state_space.sample_all_factors", "norb.SmallNORB.index.features_to_index", "numpy.expand_dims", "norb.SmallNORB.images[].astype"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.SplitDiscreteStateSpace.sample_all_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.StateSpaceAtomIndex.features_to_index"], ["", "def", "sample_observations_from_factors", "(", "self", ",", "factors", ",", "random_state", ")", ":", "\n", "    ", "all_factors", "=", "self", ".", "state_space", ".", "sample_all_factors", "(", "factors", ",", "random_state", ")", "\n", "indices", "=", "self", ".", "index", ".", "features_to_index", "(", "all_factors", ")", "\n", "return", "np", ".", "expand_dims", "(", "self", ".", "images", "[", "indices", "]", ".", "astype", "(", "np", ".", "float32", ")", ",", "axis", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.norb._load_small_norb_chunks": [[89, 95], ["norb._load_chunks", "numpy.concatenate", "numpy.concatenate"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.norb._load_chunks"], ["", "", "def", "_load_small_norb_chunks", "(", "path_template", ",", "chunk_names", ")", ":", "\n", "  ", "\"\"\"Loads several chunks of the small norb data set for final use.\"\"\"", "\n", "list_of_images", ",", "list_of_features", "=", "_load_chunks", "(", "path_template", ",", "chunk_names", ")", "\n", "features", "=", "np", ".", "concatenate", "(", "list_of_features", ",", "axis", "=", "0", ")", "\n", "features", "[", ":", ",", "3", "]", "=", "features", "[", ":", ",", "3", "]", "/", "2", "# azimuth values are 0, 2, 4, ..., 24", "\n", "return", "np", ".", "concatenate", "(", "list_of_images", ",", "axis", "=", "0", ")", ",", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.norb._load_chunks": [[99, 110], ["norb._read_binary_matrix", "list_of_images.append", "norb._read_binary_matrix", "norb._read_binary_matrix", "list_of_features.append", "path_template.format", "norb._resize_images", "path_template.format", "path_template.format", "numpy.column_stack"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.norb._read_binary_matrix", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.norb._read_binary_matrix", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.norb._read_binary_matrix", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.norb._resize_images"], ["", "def", "_load_chunks", "(", "path_template", ",", "chunk_names", ")", ":", "\n", "  ", "\"\"\"Loads several chunks of the small norb data set into lists.\"\"\"", "\n", "list_of_images", "=", "[", "]", "\n", "list_of_features", "=", "[", "]", "\n", "for", "chunk_name", "in", "chunk_names", ":", "\n", "    ", "norb", "=", "_read_binary_matrix", "(", "path_template", ".", "format", "(", "chunk_name", ",", "\"dat\"", ")", ")", "\n", "list_of_images", ".", "append", "(", "_resize_images", "(", "norb", "[", ":", ",", "0", "]", ")", ")", "\n", "norb_class", "=", "_read_binary_matrix", "(", "path_template", ".", "format", "(", "chunk_name", ",", "\"cat\"", ")", ")", "\n", "norb_info", "=", "_read_binary_matrix", "(", "path_template", ".", "format", "(", "chunk_name", ",", "\"info\"", ")", ")", "\n", "list_of_features", ".", "append", "(", "np", ".", "column_stack", "(", "(", "norb_class", ",", "norb_info", ")", ")", ")", "\n", "", "return", "list_of_images", ",", "list_of_features", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.norb._read_binary_matrix": [[112, 133], ["np.frombuffer.reshape", "tensorflow.gfile.GFile", "f.read", "int", "int", "max", "numpy.frombuffer", "six.moves.range", "numpy.frombuffer", "tuple", "numpy.frombuffer", "numpy.frombuffer", "dims.append"], "function", ["None"], ["", "def", "_read_binary_matrix", "(", "filename", ")", ":", "\n", "  ", "\"\"\"Reads and returns binary formatted matrix stored in filename.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "filename", ",", "\"rb\"", ")", "as", "f", ":", "\n", "    ", "s", "=", "f", ".", "read", "(", ")", "\n", "magic", "=", "int", "(", "np", ".", "frombuffer", "(", "s", ",", "\"int32\"", ",", "1", ")", ")", "\n", "ndim", "=", "int", "(", "np", ".", "frombuffer", "(", "s", ",", "\"int32\"", ",", "1", ",", "4", ")", ")", "\n", "eff_dim", "=", "max", "(", "3", ",", "ndim", ")", "\n", "raw_dims", "=", "np", ".", "frombuffer", "(", "s", ",", "\"int32\"", ",", "eff_dim", ",", "8", ")", "\n", "dims", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "ndim", ")", ":", "\n", "      ", "dims", ".", "append", "(", "raw_dims", "[", "i", "]", ")", "\n", "\n", "", "dtype_map", "=", "{", "\n", "507333717", ":", "\"int8\"", ",", "\n", "507333716", ":", "\"int32\"", ",", "\n", "507333713", ":", "\"float\"", ",", "\n", "507333715", ":", "\"double\"", "\n", "}", "\n", "data", "=", "np", ".", "frombuffer", "(", "s", ",", "dtype_map", "[", "magic", "]", ",", "offset", "=", "8", "+", "eff_dim", "*", "4", ")", "\n", "", "data", "=", "data", ".", "reshape", "(", "tuple", "(", "dims", ")", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.norb._resize_images": [[135, 142], ["numpy.zeros", "six.moves.range", "PIL.Image.fromarray", "image.resize.resize"], "function", ["None"], ["", "def", "_resize_images", "(", "integer_images", ")", ":", "\n", "  ", "resized_images", "=", "np", ".", "zeros", "(", "(", "integer_images", ".", "shape", "[", "0", "]", ",", "64", ",", "64", ")", ")", "\n", "for", "i", "in", "range", "(", "integer_images", ".", "shape", "[", "0", "]", ")", ":", "\n", "    ", "image", "=", "PIL", ".", "Image", ".", "fromarray", "(", "integer_images", "[", "i", ",", ":", ",", ":", "]", ")", "\n", "image", "=", "image", ".", "resize", "(", "(", "64", ",", "64", ")", ",", "PIL", ".", "Image", ".", "ANTIALIAS", ")", "\n", "resized_images", "[", "i", ",", ":", ",", ":", "]", "=", "image", "\n", "", "return", "resized_images", "/", "255.", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.DSprites.__init__": [[51, 70], ["disentanglement_lib.data.ground_truth.util.SplitDiscreteStateSpace", "list", "tensorflow.compat.v1.gfile.Open", "numpy.load", "numpy.array", "numpy.array", "numpy.prod", "numpy.cumprod", "six.moves.range"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "latent_factor_indices", "=", "None", ")", ":", "\n", "# By default, all factors (including shape) are considered ground truth", "\n", "# factors.", "\n", "    ", "if", "latent_factor_indices", "is", "None", ":", "\n", "      ", "latent_factor_indices", "=", "list", "(", "range", "(", "6", ")", ")", "\n", "", "self", ".", "latent_factor_indices", "=", "latent_factor_indices", "\n", "self", ".", "data_shape", "=", "[", "64", ",", "64", ",", "1", "]", "\n", "# Load the data so that we can sample from it.", "\n", "with", "gfile", ".", "Open", "(", "DSPRITES_PATH", ",", "\"rb\"", ")", "as", "data_file", ":", "\n", "# Data was saved originally using python2, so we need to set the encoding.", "\n", "      ", "data", "=", "np", ".", "load", "(", "data_file", ",", "encoding", "=", "\"latin1\"", ",", "allow_pickle", "=", "True", ")", "\n", "self", ".", "images", "=", "np", ".", "array", "(", "data", "[", "\"imgs\"", "]", ")", "\n", "self", ".", "factor_sizes", "=", "np", ".", "array", "(", "\n", "data", "[", "\"metadata\"", "]", "[", "(", ")", "]", "[", "\"latents_sizes\"", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "", "self", ".", "full_factor_sizes", "=", "[", "1", ",", "3", ",", "6", ",", "40", ",", "32", ",", "32", "]", "\n", "self", ".", "factor_bases", "=", "np", ".", "prod", "(", "self", ".", "factor_sizes", ")", "/", "np", ".", "cumprod", "(", "\n", "self", ".", "factor_sizes", ")", "\n", "self", ".", "state_space", "=", "util", ".", "SplitDiscreteStateSpace", "(", "self", ".", "factor_sizes", ",", "\n", "self", ".", "latent_factor_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.DSprites.num_factors": [[71, 74], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_factors", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "state_space", ".", "num_latent_factors", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.DSprites.factors_num_values": [[75, 78], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "factors_num_values", "(", "self", ")", ":", "\n", "    ", "return", "[", "self", ".", "full_factor_sizes", "[", "i", "]", "for", "i", "in", "self", ".", "latent_factor_indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.DSprites.observation_shape": [[79, 82], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "observation_shape", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "data_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.DSprites.sample_factors": [[84, 87], ["dsprites.DSprites.state_space.sample_latent_factors"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.SplitDiscreteStateSpace.sample_latent_factors"], ["", "def", "sample_factors", "(", "self", ",", "num", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a batch of factors Y.\"\"\"", "\n", "return", "self", ".", "state_space", ".", "sample_latent_factors", "(", "num", ",", "random_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.DSprites.sample_observations_from_factors": [[88, 90], ["dsprites.DSprites.sample_observations_from_factors_no_color"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.DSprites.sample_observations_from_factors_no_color"], ["", "def", "sample_observations_from_factors", "(", "self", ",", "factors", ",", "random_state", ")", ":", "\n", "    ", "return", "self", ".", "sample_observations_from_factors_no_color", "(", "factors", ",", "random_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.DSprites.sample_observations_from_factors_no_color": [[91, 96], ["dsprites.DSprites.state_space.sample_all_factors", "numpy.array", "numpy.expand_dims", "numpy.dot", "dsprites.DSprites.images[].astype"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.SplitDiscreteStateSpace.sample_all_factors"], ["", "def", "sample_observations_from_factors_no_color", "(", "self", ",", "factors", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a batch of observations X given a batch of factors Y.\"\"\"", "\n", "all_factors", "=", "self", ".", "state_space", ".", "sample_all_factors", "(", "factors", ",", "random_state", ")", "\n", "indices", "=", "np", ".", "array", "(", "np", ".", "dot", "(", "all_factors", ",", "self", ".", "factor_bases", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "return", "np", ".", "expand_dims", "(", "self", ".", "images", "[", "indices", "]", ".", "astype", "(", "np", ".", "float32", ")", ",", "axis", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.DSprites._sample_factor": [[97, 99], ["random_state.randint"], "methods", ["None"], ["", "def", "_sample_factor", "(", "self", ",", "i", ",", "num", ",", "random_state", ")", ":", "\n", "    ", "return", "random_state", ".", "randint", "(", "self", ".", "factor_sizes", "[", "i", "]", ",", "size", "=", "num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.ColorDSprites.__init__": [[116, 119], ["dsprites.DSprites.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.__init__"], ["def", "__init__", "(", "self", ",", "latent_factor_indices", "=", "None", ")", ":", "\n", "    ", "DSprites", ".", "__init__", "(", "self", ",", "latent_factor_indices", ")", "\n", "self", ".", "data_shape", "=", "[", "64", ",", "64", ",", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.ColorDSprites.sample_observations_from_factors": [[120, 132], ["dsprites.ColorDSprites.sample_observations_from_factors_no_color", "numpy.repeat", "numpy.repeat", "numpy.repeat", "random_state.uniform"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.DSprites.sample_observations_from_factors_no_color", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.repeat", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.repeat", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.repeat"], ["", "def", "sample_observations_from_factors", "(", "self", ",", "factors", ",", "random_state", ")", ":", "\n", "    ", "no_color_observations", "=", "self", ".", "sample_observations_from_factors_no_color", "(", "\n", "factors", ",", "random_state", ")", "\n", "observations", "=", "np", ".", "repeat", "(", "no_color_observations", ",", "3", ",", "axis", "=", "3", ")", "\n", "color", "=", "np", ".", "repeat", "(", "\n", "np", ".", "repeat", "(", "\n", "random_state", ".", "uniform", "(", "0.5", ",", "1", ",", "[", "observations", ".", "shape", "[", "0", "]", ",", "1", ",", "1", ",", "3", "]", ")", ",", "\n", "observations", ".", "shape", "[", "1", "]", ",", "\n", "axis", "=", "1", ")", ",", "\n", "observations", ".", "shape", "[", "2", "]", ",", "\n", "axis", "=", "2", ")", "\n", "return", "observations", "*", "color", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.NoisyDSprites.__init__": [[149, 152], ["dsprites.DSprites.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.__init__"], ["def", "__init__", "(", "self", ",", "latent_factor_indices", "=", "None", ")", ":", "\n", "    ", "DSprites", ".", "__init__", "(", "self", ",", "latent_factor_indices", ")", "\n", "self", ".", "data_shape", "=", "[", "64", ",", "64", ",", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.NoisyDSprites.sample_observations_from_factors": [[153, 159], ["dsprites.NoisyDSprites.sample_observations_from_factors_no_color", "numpy.repeat", "random_state.uniform", "numpy.minimum"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.DSprites.sample_observations_from_factors_no_color", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.repeat"], ["", "def", "sample_observations_from_factors", "(", "self", ",", "factors", ",", "random_state", ")", ":", "\n", "    ", "no_color_observations", "=", "self", ".", "sample_observations_from_factors_no_color", "(", "\n", "factors", ",", "random_state", ")", "\n", "observations", "=", "np", ".", "repeat", "(", "no_color_observations", ",", "3", ",", "axis", "=", "3", ")", "\n", "color", "=", "random_state", ".", "uniform", "(", "0", ",", "1", ",", "[", "observations", ".", "shape", "[", "0", "]", ",", "64", ",", "64", ",", "3", "]", ")", "\n", "return", "np", ".", "minimum", "(", "observations", "+", "color", ",", "1.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.ScreamDSprites.__init__": [[177, 184], ["dsprites.DSprites.__init__", "tensorflow.compat.v1.gfile.Open", "PIL.Image.open", "PIL.Image.open.thumbnail", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.__init__"], ["def", "__init__", "(", "self", ",", "latent_factor_indices", "=", "None", ")", ":", "\n", "    ", "DSprites", ".", "__init__", "(", "self", ",", "latent_factor_indices", ")", "\n", "self", ".", "data_shape", "=", "[", "64", ",", "64", ",", "3", "]", "\n", "with", "gfile", ".", "Open", "(", "SCREAM_PATH", ",", "\"rb\"", ")", "as", "f", ":", "\n", "      ", "scream", "=", "PIL", ".", "Image", ".", "open", "(", "f", ")", "\n", "scream", ".", "thumbnail", "(", "(", "350", ",", "274", ",", "3", ")", ")", "\n", "self", ".", "scream", "=", "np", ".", "array", "(", "scream", ")", "*", "1.", "/", "255.", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.ScreamDSprites.sample_observations_from_factors": [[185, 199], ["dsprites.ScreamDSprites.sample_observations_from_factors_no_color", "numpy.repeat", "six.moves.range", "random_state.randint", "random_state.randint", "random_state.uniform"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.DSprites.sample_observations_from_factors_no_color", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.repeat"], ["", "", "def", "sample_observations_from_factors", "(", "self", ",", "factors", ",", "random_state", ")", ":", "\n", "    ", "no_color_observations", "=", "self", ".", "sample_observations_from_factors_no_color", "(", "\n", "factors", ",", "random_state", ")", "\n", "observations", "=", "np", ".", "repeat", "(", "no_color_observations", ",", "3", ",", "axis", "=", "3", ")", "\n", "\n", "for", "i", "in", "range", "(", "observations", ".", "shape", "[", "0", "]", ")", ":", "\n", "      ", "x_crop", "=", "random_state", ".", "randint", "(", "0", ",", "self", ".", "scream", ".", "shape", "[", "0", "]", "-", "64", ")", "\n", "y_crop", "=", "random_state", ".", "randint", "(", "0", ",", "self", ".", "scream", ".", "shape", "[", "1", "]", "-", "64", ")", "\n", "background", "=", "(", "self", ".", "scream", "[", "x_crop", ":", "x_crop", "+", "64", ",", "y_crop", ":", "y_crop", "+", "64", "]", "+", "\n", "random_state", ".", "uniform", "(", "0", ",", "1", ",", "size", "=", "3", ")", ")", "/", "2.", "\n", "mask", "=", "(", "observations", "[", "i", "]", "==", "1", ")", "\n", "background", "[", "mask", "]", "=", "1", "-", "background", "[", "mask", "]", "\n", "observations", "[", "i", "]", "=", "background", "\n", "", "return", "observations", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.AbstractDSprites.__init__": [[235, 239], ["dsprites.DSprites.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "# We retain all original factors except shape.", "\n", "    ", "DSprites", ".", "__init__", "(", "self", ",", "[", "1", ",", "2", ",", "4", ",", "5", "]", ")", "\n", "self", ".", "data_shape", "=", "[", "64", ",", "64", ",", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.AbstractDSprites.num_factors": [[240, 243], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_factors", "(", "self", ")", ":", "\n", "    ", "return", "2", "+", "self", ".", "state_space", ".", "num_latent_factors", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.AbstractDSprites.factors_num_values": [[244, 248], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "factors_num_values", "(", "self", ")", ":", "\n", "    ", "return", "(", "[", "BACKGROUND_COLORS", ".", "shape", "[", "0", "]", ",", "OBJECT_COLORS", ".", "shape", "[", "0", "]", "]", "+", "\n", "[", "self", ".", "full_factor_sizes", "[", "i", "]", "for", "i", "in", "self", ".", "latent_factor_indices", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.AbstractDSprites.sample_factors": [[249, 256], ["numpy.zeros", "random_state.randint", "random_state.randint", "dsprites.AbstractDSprites.state_space.sample_latent_factors", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.SplitDiscreteStateSpace.sample_latent_factors"], ["", "def", "sample_factors", "(", "self", ",", "num", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a batch of factors Y.\"\"\"", "\n", "colors", "=", "np", ".", "zeros", "(", "(", "num", ",", "2", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "colors", "[", ":", ",", "0", "]", "=", "random_state", ".", "randint", "(", "BACKGROUND_COLORS", ".", "shape", "[", "0", "]", ",", "size", "=", "num", ")", "\n", "colors", "[", ":", ",", "1", "]", "=", "random_state", ".", "randint", "(", "OBJECT_COLORS", ".", "shape", "[", "0", "]", ",", "size", "=", "num", ")", "\n", "other_factors", "=", "self", ".", "state_space", ".", "sample_latent_factors", "(", "num", ",", "random_state", ")", "\n", "return", "np", ".", "concatenate", "(", "[", "colors", ",", "other_factors", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.AbstractDSprites.sample_observations_from_factors": [[257, 269], ["dsprites.AbstractDSprites.sample_observations_from_factors_no_color", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dsprites.DSprites.sample_observations_from_factors_no_color"], ["", "def", "sample_observations_from_factors", "(", "self", ",", "factors", ",", "random_state", ")", ":", "\n", "    ", "mask", "=", "self", ".", "sample_observations_from_factors_no_color", "(", "\n", "factors", "[", ":", ",", "2", ":", "]", ",", "random_state", ")", "\n", "\n", "background_color", "=", "BACKGROUND_COLORS", "[", "factors", "[", ":", ",", "0", "]", "]", "\n", "object_color", "=", "OBJECT_COLORS", "[", "factors", "[", ":", ",", "1", "]", "]", "\n", "\n", "# Add axis for height and width.", "\n", "background_color", "=", "np", ".", "expand_dims", "(", "np", ".", "expand_dims", "(", "background_color", ",", "1", ")", ",", "1", ")", "\n", "object_color", "=", "np", ".", "expand_dims", "(", "np", ".", "expand_dims", "(", "object_color", ",", "1", ")", ",", "1", ")", "\n", "\n", "return", "mask", "*", "object_color", "+", "(", "1.", "-", "mask", ")", "*", "background_color", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util_test.UtilTest.test_tfdata": [[31, 39], ["disentanglement_lib.data.ground_truth.dummy_data.DummyData", "disentanglement_lib.data.ground_truth.util.tf_data_set_from_ground_truth_data", "disentanglement_lib.data.ground_truth.util.tf_data_set_from_ground_truth_data.make_one_shot_iterator", "util.tf_data_set_from_ground_truth_data.make_one_shot_iterator.get_next", "util_test.UtilTest.test_session", "six.moves.range", "sess.run"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.tf_data_set_from_ground_truth_data"], ["  ", "def", "test_tfdata", "(", "self", ")", ":", "\n", "    ", "ground_truth_data", "=", "dummy_data", ".", "DummyData", "(", ")", "\n", "dataset", "=", "util", ".", "tf_data_set_from_ground_truth_data", "(", "ground_truth_data", ",", "0", ")", "\n", "one_shot_iterator", "=", "dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "next_element", "=", "one_shot_iterator", ".", "get_next", "(", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "        ", "sess", ".", "run", "(", "next_element", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util_test.StateSpaceAtomIndexTest.test": [[43, 48], ["numpy.array", "disentanglement_lib.data.ground_truth.util.StateSpaceAtomIndex", "util_test.StateSpaceAtomIndexTest.assertAllEqual", "disentanglement_lib.data.ground_truth.util.StateSpaceAtomIndex.features_to_index", "list", "six.moves.range"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.StateSpaceAtomIndex.features_to_index"], ["  ", "def", "test", "(", "self", ")", ":", "\n", "    ", "features", "=", "np", ".", "array", "(", "[", "[", "0", ",", "1", "]", ",", "[", "1", ",", "0", "]", ",", "[", "1", ",", "1", "]", ",", "[", "0", ",", "0", "]", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "state_space_atom_index", "=", "util", ".", "StateSpaceAtomIndex", "(", "[", "2", ",", "2", "]", ",", "features", ")", "\n", "self", ".", "assertAllEqual", "(", "\n", "state_space_atom_index", ".", "features_to_index", "(", "features", ")", ",", "list", "(", "range", "(", "4", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.named_data.get_named_ground_truth_data": [[29, 66], ["gin.configurable", "disentanglement_lib.data.ground_truth.dsprites.DSprites", "disentanglement_lib.data.ground_truth.dsprites.DSprites", "disentanglement_lib.data.ground_truth.dsprites.ColorDSprites", "disentanglement_lib.data.ground_truth.dsprites.NoisyDSprites", "disentanglement_lib.data.ground_truth.dsprites.ScreamDSprites", "disentanglement_lib.data.ground_truth.norb.SmallNORB", "disentanglement_lib.data.ground_truth.cars3d.Cars3D", "disentanglement_lib.data.ground_truth.mpi3d.MPI3D", "disentanglement_lib.data.ground_truth.mpi3d.MPI3D", "disentanglement_lib.data.ground_truth.mpi3d.MPI3D", "disentanglement_lib.data.ground_truth.shapes3d.Shapes3D", "disentanglement_lib.data.ground_truth.dummy_data.DummyData", "ValueError"], "function", ["None"], ["@", "gin", ".", "configurable", "(", "\"dataset\"", ")", "\n", "def", "get_named_ground_truth_data", "(", "name", ")", ":", "\n", "  ", "\"\"\"Returns ground truth data set based on name.\n\n  Args:\n    name: String with the name of the dataset.\n\n  Raises:\n    ValueError: if an invalid data set name is provided.\n  \"\"\"", "\n", "\n", "if", "name", "==", "\"dsprites_full\"", ":", "\n", "    ", "return", "dsprites", ".", "DSprites", "(", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", ")", "\n", "", "elif", "name", "==", "\"dsprites_noshape\"", ":", "\n", "    ", "return", "dsprites", ".", "DSprites", "(", "[", "2", ",", "3", ",", "4", ",", "5", "]", ")", "\n", "", "elif", "name", "==", "\"color_dsprites\"", ":", "\n", "    ", "return", "dsprites", ".", "ColorDSprites", "(", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", ")", "\n", "", "elif", "name", "==", "\"noisy_dsprites\"", ":", "\n", "    ", "return", "dsprites", ".", "NoisyDSprites", "(", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", ")", "\n", "", "elif", "name", "==", "\"scream_dsprites\"", ":", "\n", "    ", "return", "dsprites", ".", "ScreamDSprites", "(", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", ")", "\n", "", "elif", "name", "==", "\"smallnorb\"", ":", "\n", "    ", "return", "norb", ".", "SmallNORB", "(", ")", "\n", "", "elif", "name", "==", "\"cars3d\"", ":", "\n", "    ", "return", "cars3d", ".", "Cars3D", "(", ")", "\n", "", "elif", "name", "==", "\"mpi3d_toy\"", ":", "\n", "    ", "return", "mpi3d", ".", "MPI3D", "(", "mode", "=", "\"mpi3d_toy\"", ")", "\n", "", "elif", "name", "==", "\"mpi3d_realistic\"", ":", "\n", "    ", "return", "mpi3d", ".", "MPI3D", "(", "mode", "=", "\"mpi3d_realistic\"", ")", "\n", "", "elif", "name", "==", "\"mpi3d_real\"", ":", "\n", "    ", "return", "mpi3d", ".", "MPI3D", "(", "mode", "=", "\"mpi3d_real\"", ")", "\n", "", "elif", "name", "==", "\"shapes3d\"", ":", "\n", "    ", "return", "shapes3d", ".", "Shapes3D", "(", ")", "\n", "", "elif", "name", "==", "\"dummy_data\"", ":", "\n", "    ", "return", "dummy_data", ".", "DummyData", "(", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"Invalid data set name.\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dummy_data.IdentityObservationsData.num_factors": [[26, 29], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "num_factors", "(", "self", ")", ":", "\n", "    ", "return", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dummy_data.IdentityObservationsData.observation_shape": [[30, 33], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "observation_shape", "(", "self", ")", ":", "\n", "    ", "return", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dummy_data.IdentityObservationsData.factors_num_values": [[34, 37], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "factors_num_values", "(", "self", ")", ":", "\n", "    ", "return", "[", "1", "]", "*", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dummy_data.IdentityObservationsData.sample_factors": [[38, 41], ["random_state.random_integers"], "methods", ["None"], ["", "def", "sample_factors", "(", "self", ",", "num", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a batch of factors Y.\"\"\"", "\n", "return", "random_state", ".", "random_integers", "(", "10", ",", "size", "=", "(", "num", ",", "self", ".", "num_factors", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dummy_data.IdentityObservationsData.sample_observations_from_factors": [[42, 45], ["None"], "methods", ["None"], ["", "def", "sample_observations_from_factors", "(", "self", ",", "factors", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a batch of observations X given a batch of factors Y.\"\"\"", "\n", "return", "factors", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dummy_data.IdentityObservationsData.factor_names": [[46, 49], ["range"], "methods", ["None"], ["", "@", "property", "\n", "def", "factor_names", "(", "self", ")", ":", "\n", "    ", "return", "[", "\"Factor {}\"", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "self", ".", "num_factors", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dummy_data.DummyData.num_factors": [[54, 57], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "num_factors", "(", "self", ")", ":", "\n", "    ", "return", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dummy_data.DummyData.factors_num_values": [[58, 61], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "factors_num_values", "(", "self", ")", ":", "\n", "    ", "return", "[", "5", "]", "*", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dummy_data.DummyData.observation_shape": [[62, 65], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "observation_shape", "(", "self", ")", ":", "\n", "    ", "return", "[", "64", ",", "64", ",", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dummy_data.DummyData.sample_factors": [[66, 69], ["random_state.randint"], "methods", ["None"], ["", "def", "sample_factors", "(", "self", ",", "num", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a batch of factors Y.\"\"\"", "\n", "return", "random_state", ".", "randint", "(", "5", ",", "size", "=", "(", "num", ",", "self", ".", "num_factors", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.dummy_data.DummyData.sample_observations_from_factors": [[70, 73], ["random_state.random_sample"], "methods", ["None"], ["", "def", "sample_observations_from_factors", "(", "self", ",", "factors", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a batch of observations X given a batch of factors Y.\"\"\"", "\n", "return", "random_state", ".", "random_sample", "(", "size", "=", "(", "factors", ".", "shape", "[", "0", "]", ",", "64", ",", "64", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.ground_truth_data.GroundTruthData.num_factors": [[25, 28], ["NotImplementedError"], "methods", ["None"], ["@", "property", "\n", "def", "num_factors", "(", "self", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.ground_truth_data.GroundTruthData.factors_num_values": [[29, 32], ["NotImplementedError"], "methods", ["None"], ["", "@", "property", "\n", "def", "factors_num_values", "(", "self", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.ground_truth_data.GroundTruthData.observation_shape": [[33, 36], ["NotImplementedError"], "methods", ["None"], ["", "@", "property", "\n", "def", "observation_shape", "(", "self", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.ground_truth_data.GroundTruthData.sample_factors": [[37, 40], ["NotImplementedError"], "methods", ["None"], ["", "def", "sample_factors", "(", "self", ",", "num", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a batch of factors Y.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.ground_truth_data.GroundTruthData.sample_observations_from_factors": [[41, 44], ["NotImplementedError"], "methods", ["None"], ["", "def", "sample_observations_from_factors", "(", "self", ",", "factors", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a batch of observations X given a batch of factors Y.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.ground_truth_data.GroundTruthData.sample": [[45, 49], ["ground_truth_data.GroundTruthData.sample_factors", "ground_truth_data.GroundTruthData.sample_observations_from_factors"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors"], ["", "def", "sample", "(", "self", ",", "num", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a batch of factors Y and observations X.\"\"\"", "\n", "factors", "=", "self", ".", "sample_factors", "(", "num", ",", "random_state", ")", "\n", "return", "factors", ",", "self", ".", "sample_observations_from_factors", "(", "factors", ",", "random_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.ground_truth_data.GroundTruthData.sample_observations": [[50, 53], ["ground_truth_data.GroundTruthData.sample"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.NonActiveRelation.sample"], ["", "def", "sample_observations", "(", "self", ",", "num", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a batch of observations X.\"\"\"", "\n", "return", "self", ".", "sample", "(", "num", ",", "random_state", ")", "[", "1", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.SplitDiscreteStateSpace.__init__": [[41, 48], ["len", "six.moves.range"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "factor_sizes", ",", "latent_factor_indices", ")", ":", "\n", "    ", "self", ".", "factor_sizes", "=", "factor_sizes", "\n", "self", ".", "num_factors", "=", "len", "(", "self", ".", "factor_sizes", ")", "\n", "self", ".", "latent_factor_indices", "=", "latent_factor_indices", "\n", "self", ".", "observation_factor_indices", "=", "[", "\n", "i", "for", "i", "in", "range", "(", "self", ".", "num_factors", ")", "\n", "if", "i", "not", "in", "self", ".", "latent_factor_indices", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.SplitDiscreteStateSpace.num_latent_factors": [[50, 53], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_latent_factors", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "self", ".", "latent_factor_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.SplitDiscreteStateSpace.sample_latent_factors": [[54, 61], ["numpy.zeros", "enumerate", "util.SplitDiscreteStateSpace._sample_factor", "len"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer._sample_factor"], ["", "def", "sample_latent_factors", "(", "self", ",", "num", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a batch of the latent factors.\"\"\"", "\n", "factors", "=", "np", ".", "zeros", "(", "\n", "shape", "=", "(", "num", ",", "len", "(", "self", ".", "latent_factor_indices", ")", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "for", "pos", ",", "i", "in", "enumerate", "(", "self", ".", "latent_factor_indices", ")", ":", "\n", "      ", "factors", "[", ":", ",", "pos", "]", "=", "self", ".", "_sample_factor", "(", "i", ",", "num", ",", "random_state", ")", "\n", "", "return", "factors", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.SplitDiscreteStateSpace.sample_all_factors": [[62, 72], ["numpy.zeros", "util.SplitDiscreteStateSpace._sample_factor"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer._sample_factor"], ["", "def", "sample_all_factors", "(", "self", ",", "latent_factors", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Samples the remaining factors based on the latent factors.\"\"\"", "\n", "num_samples", "=", "latent_factors", ".", "shape", "[", "0", "]", "\n", "all_factors", "=", "np", ".", "zeros", "(", "\n", "shape", "=", "(", "num_samples", ",", "self", ".", "num_factors", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "all_factors", "[", ":", ",", "self", ".", "latent_factor_indices", "]", "=", "latent_factors", "\n", "# Complete all the other factors", "\n", "for", "i", "in", "self", ".", "observation_factor_indices", ":", "\n", "      ", "all_factors", "[", ":", ",", "i", "]", "=", "self", ".", "_sample_factor", "(", "i", ",", "num_samples", ",", "random_state", ")", "\n", "", "return", "all_factors", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.SplitDiscreteStateSpace._sample_factor": [[73, 75], ["random_state.randint"], "methods", ["None"], ["", "def", "_sample_factor", "(", "self", ",", "i", ",", "num", ",", "random_state", ")", ":", "\n", "    ", "return", "random_state", ".", "randint", "(", "self", ".", "factor_sizes", "[", "i", "]", ",", "size", "=", "num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.StateSpaceAtomIndex.__init__": [[80, 98], ["numpy.prod", "util.StateSpaceAtomIndex._features_to_state_space_index", "numpy.zeros", "numpy.arange", "numpy.cumprod", "ValueError", "numpy.unique"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.StateSpaceAtomIndex._features_to_state_space_index"], ["def", "__init__", "(", "self", ",", "factor_sizes", ",", "features", ")", ":", "\n", "    ", "\"\"\"Creates the StateSpaceAtomIndex.\n\n    Args:\n      factor_sizes: List of integers with the number of distinct values for each\n        of the factors.\n      features: Numpy matrix where each row contains a different factor\n        configuration. The matrix needs to cover the whole state space.\n    \"\"\"", "\n", "self", ".", "factor_sizes", "=", "factor_sizes", "\n", "num_total_atoms", "=", "np", ".", "prod", "(", "self", ".", "factor_sizes", ")", "\n", "self", ".", "factor_bases", "=", "num_total_atoms", "/", "np", ".", "cumprod", "(", "self", ".", "factor_sizes", ")", "\n", "feature_state_space_index", "=", "self", ".", "_features_to_state_space_index", "(", "features", ")", "\n", "if", "np", ".", "unique", "(", "feature_state_space_index", ")", ".", "size", "!=", "num_total_atoms", ":", "\n", "      ", "raise", "ValueError", "(", "\"Features matrix does not cover the whole state space.\"", ")", "\n", "", "lookup_table", "=", "np", ".", "zeros", "(", "num_total_atoms", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "lookup_table", "[", "feature_state_space_index", "]", "=", "np", ".", "arange", "(", "num_total_atoms", ")", "\n", "self", ".", "state_space_to_save_space_index", "=", "lookup_table", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.StateSpaceAtomIndex.features_to_index": [[99, 109], ["util.StateSpaceAtomIndex._features_to_state_space_index"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.StateSpaceAtomIndex._features_to_state_space_index"], ["", "def", "features_to_index", "(", "self", ",", "features", ")", ":", "\n", "    ", "\"\"\"Returns the indices in the input space for given factor configurations.\n\n    Args:\n      features: Numpy matrix where each row contains a different factor\n        configuration for which the indices in the input space should be\n        returned.\n    \"\"\"", "\n", "state_space_index", "=", "self", ".", "_features_to_state_space_index", "(", "features", ")", "\n", "return", "self", ".", "state_space_to_save_space_index", "[", "state_space_index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.StateSpaceAtomIndex._features_to_state_space_index": [[110, 122], ["numpy.array", "numpy.any", "numpy.any", "ValueError", "numpy.dot", "numpy.expand_dims"], "methods", ["None"], ["", "def", "_features_to_state_space_index", "(", "self", ",", "features", ")", ":", "\n", "    ", "\"\"\"Returns the indices in the atom space for given factor configurations.\n\n    Args:\n      features: Numpy matrix where each row contains a different factor\n        configuration for which the indices in the atom space should be\n        returned.\n    \"\"\"", "\n", "if", "(", "np", ".", "any", "(", "features", ">", "np", ".", "expand_dims", "(", "self", ".", "factor_sizes", ",", "0", ")", ")", "or", "\n", "np", ".", "any", "(", "features", "<", "0", ")", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"Feature indices have to be within [0, factor_size-1]!\"", ")", "\n", "", "return", "np", ".", "array", "(", "np", ".", "dot", "(", "features", ",", "self", ".", "factor_bases", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.tf_data_set_from_ground_truth_data": [[25, 36], ["tensorflow.data.Dataset.from_generator", "numpy.random.RandomState", "ground_truth_data.sample_observations"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.ground_truth_data.GroundTruthData.sample_observations"], ["def", "tf_data_set_from_ground_truth_data", "(", "ground_truth_data", ",", "random_seed", ")", ":", "\n", "  ", "\"\"\"Generate a tf.data.DataSet from ground_truth data.\"\"\"", "\n", "\n", "def", "generator", "(", ")", ":", "\n", "# We need to hard code the random seed so that the data set can be reset.", "\n", "    ", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "random_seed", ")", "\n", "while", "True", ":", "\n", "      ", "yield", "ground_truth_data", ".", "sample_observations", "(", "1", ",", "random_state", ")", "[", "0", "]", "\n", "\n", "", "", "return", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "\n", "generator", ",", "tf", ".", "float32", ",", "output_shapes", "=", "ground_truth_data", ".", "observation_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.shapes3d.Shapes3D.__init__": [[50, 67], ["numpy.prod", "labels.reshape", "list", "disentanglement_lib.data.ground_truth.util.SplitDiscreteStateSpace", "tensorflow.gfile.GFile", "numpy.load", "images.reshape().astype", "six.moves.range", "numpy.prod", "numpy.cumprod", "images.reshape"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "with", "tf", ".", "gfile", ".", "GFile", "(", "SHAPES3D_PATH", ",", "\"rb\"", ")", "as", "f", ":", "\n", "# Data was saved originally using python2, so we need to set the encoding.", "\n", "      ", "data", "=", "np", ".", "load", "(", "f", ",", "encoding", "=", "\"latin1\"", ")", "\n", "", "images", "=", "data", "[", "\"images\"", "]", "\n", "labels", "=", "data", "[", "\"labels\"", "]", "\n", "n_samples", "=", "np", ".", "prod", "(", "images", ".", "shape", "[", "0", ":", "6", "]", ")", "\n", "self", ".", "images", "=", "(", "\n", "images", ".", "reshape", "(", "[", "n_samples", ",", "64", ",", "64", ",", "3", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "/", "255.", ")", "\n", "features", "=", "labels", ".", "reshape", "(", "[", "n_samples", ",", "6", "]", ")", "\n", "self", ".", "factor_sizes", "=", "[", "10", ",", "10", ",", "10", ",", "8", ",", "4", ",", "15", "]", "\n", "self", ".", "latent_factor_indices", "=", "list", "(", "range", "(", "6", ")", ")", "\n", "self", ".", "num_total_factors", "=", "features", ".", "shape", "[", "1", "]", "\n", "self", ".", "state_space", "=", "util", ".", "SplitDiscreteStateSpace", "(", "self", ".", "factor_sizes", ",", "\n", "self", ".", "latent_factor_indices", ")", "\n", "self", ".", "factor_bases", "=", "np", ".", "prod", "(", "self", ".", "factor_sizes", ")", "/", "np", ".", "cumprod", "(", "\n", "self", ".", "factor_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.shapes3d.Shapes3D.num_factors": [[68, 71], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_factors", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "state_space", ".", "num_latent_factors", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.shapes3d.Shapes3D.factors_num_values": [[72, 75], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "factors_num_values", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "factor_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.shapes3d.Shapes3D.observation_shape": [[76, 79], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "observation_shape", "(", "self", ")", ":", "\n", "    ", "return", "[", "64", ",", "64", ",", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.shapes3d.Shapes3D.sample_factors": [[81, 84], ["shapes3d.Shapes3D.state_space.sample_latent_factors"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.SplitDiscreteStateSpace.sample_latent_factors"], ["", "def", "sample_factors", "(", "self", ",", "num", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a batch of factors Y.\"\"\"", "\n", "return", "self", ".", "state_space", ".", "sample_latent_factors", "(", "num", ",", "random_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.shapes3d.Shapes3D.sample_observations_from_factors": [[85, 89], ["shapes3d.Shapes3D.state_space.sample_all_factors", "numpy.array", "numpy.dot"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.SplitDiscreteStateSpace.sample_all_factors"], ["", "def", "sample_observations_from_factors", "(", "self", ",", "factors", ",", "random_state", ")", ":", "\n", "    ", "all_factors", "=", "self", ".", "state_space", ".", "sample_all_factors", "(", "factors", ",", "random_state", ")", "\n", "indices", "=", "np", ".", "array", "(", "np", ".", "dot", "(", "all_factors", ",", "self", ".", "factor_bases", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "return", "self", ".", "images", "[", "indices", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.mpi3d.MPI3D.__init__": [[57, 104], ["disentanglement_lib.data.ground_truth.util.SplitDiscreteStateSpace", "os.path.join", "numpy.prod", "numpy.cumprod", "os.environ.get", "tensorflow.io.gfile.exists", "ValueError", "os.path.join", "tensorflow.io.gfile.GFile", "numpy.load", "os.environ.get", "tensorflow.io.gfile.exists", "ValueError", "os.path.join", "ValueError", "tensorflow.io.gfile.GFile", "numpy.load", "os.environ.get", "tensorflow.io.gfile.exists", "ValueError", "tensorflow.io.gfile.GFile", "numpy.load"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mode", "=", "\"mpi3d_toy\"", ")", ":", "\n", "    ", "if", "mode", "==", "\"mpi3d_toy\"", ":", "\n", "      ", "mpi3d_path", "=", "os", ".", "path", ".", "join", "(", "\n", "os", ".", "environ", ".", "get", "(", "\"DISENTANGLEMENT_LIB_DATA\"", ",", "\".\"", ")", ",", "\"mpi3d_toy\"", ",", "\n", "\"mpi3d_toy.npz\"", ")", "\n", "if", "not", "tf", ".", "io", ".", "gfile", ".", "exists", "(", "mpi3d_path", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Dataset '{}' not found. Make sure the dataset is publicly available and downloaded correctly.\"", "\n", ".", "format", "(", "mode", ")", ")", "\n", "", "else", ":", "\n", "        ", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "mpi3d_path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "          ", "data", "=", "np", ".", "load", "(", "f", ")", "\n", "", "", "self", ".", "factor_sizes", "=", "[", "4", ",", "4", ",", "2", ",", "3", ",", "3", ",", "40", ",", "40", "]", "\n", "", "elif", "mode", "==", "\"mpi3d_realistic\"", ":", "\n", "      ", "mpi3d_path", "=", "os", ".", "path", ".", "join", "(", "\n", "os", ".", "environ", ".", "get", "(", "\"DISENTANGLEMENT_LIB_DATA\"", ",", "\".\"", ")", ",", "\"mpi3d_realistic\"", ",", "\n", "\"mpi3d_realistic.npz\"", ")", "\n", "if", "not", "tf", ".", "io", ".", "gfile", ".", "exists", "(", "mpi3d_path", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Dataset '{}' not found. Make sure the dataset is publicly available and downloaded correctly.\"", "\n", ".", "format", "(", "mode", ")", ")", "\n", "", "else", ":", "\n", "        ", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "mpi3d_path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "          ", "data", "=", "np", ".", "load", "(", "f", ")", "\n", "", "", "self", ".", "factor_sizes", "=", "[", "4", ",", "4", ",", "2", ",", "3", ",", "3", ",", "40", ",", "40", "]", "\n", "", "elif", "mode", "==", "\"mpi3d_real\"", ":", "\n", "      ", "mpi3d_path", "=", "os", ".", "path", ".", "join", "(", "\n", "os", ".", "environ", ".", "get", "(", "\"DISENTANGLEMENT_LIB_DATA\"", ",", "\".\"", ")", ",", "\"mpi3d_real\"", ",", "\n", "\"mpi3d_real.npz\"", ")", "\n", "if", "not", "tf", ".", "io", ".", "gfile", ".", "exists", "(", "mpi3d_path", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Dataset '{}' not found. Make sure the dataset is publicly available and downloaded correctly.\"", "\n", ".", "format", "(", "mode", ")", ")", "\n", "", "else", ":", "\n", "        ", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "mpi3d_path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "          ", "data", "=", "np", ".", "load", "(", "f", ")", "\n", "", "", "self", ".", "factor_sizes", "=", "[", "6", ",", "6", ",", "2", ",", "3", ",", "3", ",", "40", ",", "40", "]", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"Unknown mode provided.\"", ")", "\n", "\n", "", "self", ".", "images", "=", "data", "[", "\"images\"", "]", "\n", "self", ".", "latent_factor_indices", "=", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", "]", "\n", "self", ".", "num_total_factors", "=", "7", "\n", "self", ".", "state_space", "=", "util", ".", "SplitDiscreteStateSpace", "(", "self", ".", "factor_sizes", ",", "\n", "self", ".", "latent_factor_indices", ")", "\n", "self", ".", "factor_bases", "=", "np", ".", "prod", "(", "self", ".", "factor_sizes", ")", "/", "np", ".", "cumprod", "(", "\n", "self", ".", "factor_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.mpi3d.MPI3D.num_factors": [[105, 108], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_factors", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "state_space", ".", "num_latent_factors", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.mpi3d.MPI3D.factors_num_values": [[109, 112], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "factors_num_values", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "factor_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.mpi3d.MPI3D.observation_shape": [[113, 116], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "observation_shape", "(", "self", ")", ":", "\n", "    ", "return", "[", "64", ",", "64", ",", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.mpi3d.MPI3D.sample_factors": [[118, 121], ["mpi3d.MPI3D.state_space.sample_latent_factors"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.SplitDiscreteStateSpace.sample_latent_factors"], ["", "def", "sample_factors", "(", "self", ",", "num", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a batch of factors Y.\"\"\"", "\n", "return", "self", ".", "state_space", ".", "sample_latent_factors", "(", "num", ",", "random_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.mpi3d.MPI3D.sample_observations_from_factors": [[122, 126], ["mpi3d.MPI3D.state_space.sample_all_factors", "numpy.array", "numpy.dot"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.SplitDiscreteStateSpace.sample_all_factors"], ["", "def", "sample_observations_from_factors", "(", "self", ",", "factors", ",", "random_state", ")", ":", "\n", "    ", "all_factors", "=", "self", ".", "state_space", ".", "sample_all_factors", "(", "factors", ",", "random_state", ")", "\n", "indices", "=", "np", ".", "array", "(", "np", ".", "dot", "(", "all_factors", ",", "self", ".", "factor_bases", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "return", "self", ".", "images", "[", "indices", "]", "/", "255.", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.evaluation.evaluate_test.EvaluateTest.setUp": [[31, 44], ["super().setUp", "disentanglement_lib.utils.resources.get_file", "disentanglement_lib.methods.unsupervised.train.train_with_gin", "disentanglement_lib.utils.resources.get_file", "disentanglement_lib.postprocessing.postprocess.postprocess_with_gin", "evaluate_test.EvaluateTest.create_tempdir", "evaluate_test.EvaluateTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.validation.validation_test.ValidateTest.setUp", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train_with_gin", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.postprocessing.postprocess.postprocess_with_gin"], ["  ", "def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "EvaluateTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "self", ".", "model_dir", "=", "self", ".", "create_tempdir", "(", "\n", "\"model\"", ",", "cleanup", "=", "absltest", ".", "TempFileCleanup", ".", "OFF", ")", ".", "full_path", "\n", "model_config", "=", "resources", ".", "get_file", "(", "\n", "\"config/tests/methods/unsupervised/train_test.gin\"", ")", "\n", "train", ".", "train_with_gin", "(", "self", ".", "model_dir", ",", "True", ",", "[", "model_config", "]", ")", "\n", "self", ".", "output_dir", "=", "self", ".", "create_tempdir", "(", "\n", "\"output\"", ",", "cleanup", "=", "absltest", ".", "TempFileCleanup", ".", "OFF", ")", ".", "full_path", "\n", "postprocess_config", "=", "resources", ".", "get_file", "(", "\n", "\"config/tests/postprocessing/postprocess_test_configs/mean.gin\"", ")", "\n", "postprocess", ".", "postprocess_with_gin", "(", "self", ".", "model_dir", ",", "self", ".", "output_dir", ",", "True", ",", "\n", "[", "postprocess_config", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.evaluation.evaluate_test.EvaluateTest.test_evaluate": [[45, 56], ["absl.testing.parameterized.parameters", "gin.clear_config", "disentanglement_lib.evaluation.evaluate.evaluate_with_gin", "list", "disentanglement_lib.utils.resources.get_files_in_folder", "evaluate_test.EvaluateTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.evaluation.evaluate.evaluate_with_gin", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_files_in_folder"], ["", "@", "parameterized", ".", "parameters", "(", "\n", "list", "(", "\n", "resources", ".", "get_files_in_folder", "(", "\n", "\"config/tests/evaluation/evaluate_test_configs\"", ")", ")", ")", "\n", "def", "test_evaluate", "(", "self", ",", "gin_config", ")", ":", "\n", "# We clear the gin config before running. Otherwise, if a prior test fails,", "\n", "# the gin config is locked and the current test fails.", "\n", "    ", "gin", ".", "clear_config", "(", ")", "\n", "evaluate", ".", "evaluate_with_gin", "(", "self", ".", "output_dir", ",", "\n", "self", ".", "create_tempdir", "(", ")", ".", "full_path", ",", "True", ",", "\n", "[", "gin_config", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.evaluation.evaluate.evaluate_with_gin": [[48, 73], ["gin.parse_config_files_and_bindings", "evaluate.evaluate", "gin.clear_config"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate.evaluate"], ["def", "evaluate_with_gin", "(", "model_dir", ",", "\n", "output_dir", ",", "\n", "overwrite", "=", "False", ",", "\n", "gin_config_files", "=", "None", ",", "\n", "gin_bindings", "=", "None", ")", ":", "\n", "  ", "\"\"\"Evaluate a representation based on the provided gin configuration.\n\n  This function will set the provided gin bindings, call the evaluate()\n  function and clear the gin config. Please see the evaluate() for required\n  gin bindings.\n\n  Args:\n    model_dir: String with path to directory where the representation is saved.\n    output_dir: String with the path where the evaluation should be saved.\n    overwrite: Boolean indicating whether to overwrite output directory.\n    gin_config_files: List of gin config files to load.\n    gin_bindings: List of gin bindings to use.\n  \"\"\"", "\n", "if", "gin_config_files", "is", "None", ":", "\n", "    ", "gin_config_files", "=", "[", "]", "\n", "", "if", "gin_bindings", "is", "None", ":", "\n", "    ", "gin_bindings", "=", "[", "]", "\n", "", "gin", ".", "parse_config_files_and_bindings", "(", "gin_config_files", ",", "gin_bindings", ")", "\n", "evaluate", "(", "model_dir", ",", "output_dir", ",", "overwrite", ")", "\n", "gin", ".", "clear_config", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.evaluation.evaluate.evaluate": [[75, 152], ["gin.configurable", "tensorflow.gfile.IsDirectory", "time.time", "disentanglement_lib.data.ground_truth.named_data.get_named_ground_truth_data", "os.path.join", "os.path.join", "os.path.join", "disentanglement_lib.utils.results.update_result_directory", "gin.query_parameter", "os.path.join", "disentanglement_lib.utils.results.gin_dict", "tensorflow_hub.eval_function_for_module", "evaluate._has_kwarg_or_kwargs", "time.time", "tensorflow.gfile.DeleteRecursively", "ValueError", "gin.unlock_config", "gin.bind_parameter", "f", "numpy.array", "os.path.join", "evaluation_fn", "warnings.warn", "evaluation_fn", "gin_dict[].replace", "dict", "numpy.random.RandomState", "numpy.random.RandomState"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.named_data.get_named_ground_truth_data", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.update_result_directory", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.gin_dict", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.evaluation.evaluate._has_kwarg_or_kwargs"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"evaluation\"", ",", "blacklist", "=", "[", "\"model_dir\"", ",", "\"output_dir\"", ",", "\"overwrite\"", "]", ")", "\n", "def", "evaluate", "(", "model_dir", ",", "\n", "output_dir", ",", "\n", "overwrite", "=", "False", ",", "\n", "evaluation_fn", "=", "gin", ".", "REQUIRED", ",", "\n", "random_seed", "=", "gin", ".", "REQUIRED", ",", "\n", "name", "=", "\"\"", ")", ":", "\n", "  ", "\"\"\"Loads a representation TFHub module and computes disentanglement metrics.\n\n  Args:\n    model_dir: String with path to directory where the representation function\n      is saved.\n    output_dir: String with the path where the results should be saved.\n    overwrite: Boolean indicating whether to overwrite output directory.\n    evaluation_fn: Function used to evaluate the representation (see metrics/\n      for examples).\n    random_seed: Integer with random seed used for training.\n    name: Optional string with name of the metric (can be used to name metrics).\n  \"\"\"", "\n", "# Delete the output directory if it already exists.", "\n", "if", "tf", ".", "gfile", ".", "IsDirectory", "(", "output_dir", ")", ":", "\n", "    ", "if", "overwrite", ":", "\n", "      ", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "output_dir", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"Directory already exists and overwrite is False.\"", ")", "\n", "\n", "# Set up time to keep track of elapsed time in results.", "\n", "", "", "experiment_timer", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Automatically set the proper data set if necessary. We replace the active", "\n", "# gin config as this will lead to a valid gin config file where the data set", "\n", "# is present.", "\n", "if", "gin", ".", "query_parameter", "(", "\"dataset.name\"", ")", "==", "\"auto\"", ":", "\n", "# Obtain the dataset name from the gin config of the previous step.", "\n", "    ", "gin_config_file", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"results\"", ",", "\"gin\"", ",", "\n", "\"postprocess.gin\"", ")", "\n", "gin_dict", "=", "results", ".", "gin_dict", "(", "gin_config_file", ")", "\n", "with", "gin", ".", "unlock_config", "(", ")", ":", "\n", "      ", "gin", ".", "bind_parameter", "(", "\"dataset.name\"", ",", "gin_dict", "[", "\"dataset.name\"", "]", ".", "replace", "(", "\n", "\"'\"", ",", "\"\"", ")", ")", "\n", "", "", "dataset", "=", "named_data", ".", "get_named_ground_truth_data", "(", ")", "\n", "\n", "# Path to TFHub module of previously trained representation.", "\n", "module_path", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"tfhub\"", ")", "\n", "with", "hub", ".", "eval_function_for_module", "(", "module_path", ")", "as", "f", ":", "\n", "\n", "    ", "def", "_representation_function", "(", "x", ")", ":", "\n", "      ", "\"\"\"Computes representation vector for input images.\"\"\"", "\n", "output", "=", "f", "(", "dict", "(", "images", "=", "x", ")", ",", "signature", "=", "\"representation\"", ",", "as_dict", "=", "True", ")", "\n", "return", "np", ".", "array", "(", "output", "[", "\"default\"", "]", ")", "\n", "\n", "# Computes scores of the representation based on the evaluation_fn.", "\n", "", "if", "_has_kwarg_or_kwargs", "(", "evaluation_fn", ",", "\"artifact_dir\"", ")", ":", "\n", "      ", "artifact_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"artifacts\"", ",", "name", ")", "\n", "results_dict", "=", "evaluation_fn", "(", "\n", "dataset", ",", "\n", "_representation_function", ",", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "random_seed", ")", ",", "\n", "artifact_dir", "=", "artifact_dir", ")", "\n", "", "else", ":", "\n", "# Legacy code path to allow for old evaluation metrics.", "\n", "      ", "warnings", ".", "warn", "(", "\n", "\"Evaluation function does not appear to accept an\"", "\n", "\" `artifact_dir` argument. This may not be compatible with \"", "\n", "\"future versions.\"", ",", "DeprecationWarning", ")", "\n", "results_dict", "=", "evaluation_fn", "(", "\n", "dataset", ",", "\n", "_representation_function", ",", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "random_seed", ")", ")", "\n", "\n", "# Save the results (and all previous results in the pipeline) on disk.", "\n", "", "", "original_results_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"results\"", ")", "\n", "results_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"results\"", ")", "\n", "results_dict", "[", "\"elapsed_time\"", "]", "=", "time", ".", "time", "(", ")", "-", "experiment_timer", "\n", "results", ".", "update_result_directory", "(", "results_dir", ",", "\"evaluation\"", ",", "results_dict", ",", "\n", "original_results_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.evaluation.evaluate._has_kwarg_or_kwargs": [[154, 163], ["hasattr", "inspect.getfullargspec"], "function", ["None"], ["", "def", "_has_kwarg_or_kwargs", "(", "f", ",", "kwarg", ")", ":", "\n", "  ", "\"\"\"Checks if the function has the provided kwarg or **kwargs.\"\"\"", "\n", "# For gin wrapped functions, we need to consider the wrapped function.", "\n", "if", "hasattr", "(", "f", ",", "\"__wrapped__\"", ")", ":", "\n", "    ", "f", "=", "f", ".", "__wrapped__", "\n", "", "(", "args", ",", "_", ",", "kwargs", ",", "_", ",", "_", ",", "_", ",", "_", ")", "=", "inspect", ".", "getfullargspec", "(", "f", ")", "\n", "if", "kwarg", "in", "args", "or", "kwargs", "is", "not", "None", ":", "\n", "    ", "return", "True", "\n", "", "return", "False", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.TwoStageModel.__init__": [[43, 65], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "embedding_model_class", "=", "gin", ".", "REQUIRED", ",", "\n", "reasoning_model_class", "=", "gin", ".", "REQUIRED", ",", "\n", "optimizer_fn", "=", "None", ")", ":", "\n", "    ", "\"\"\"Constructs a TwoStageModel.\n\n    Args:\n      embedding_model_class: Either `values`, `onehot`, or a class that has a\n        __call__ function that takes as input a two-tuple of\n        (batch_size, num_nodes, heigh, width, num_channels) tensors and returns\n        two (batch_size, num_nodes, num_embedding_dims) tensors for both the\n        context panels and the answer panels.\n      reasoning_model_class: Class that has a __call__ function that takes as\n        input a two-tuple of (batch_size, num_nodes, num_embedding_dims) tensors\n        and returns the solution in a (batch_size,) tensor.\n      optimizer_fn: Function that creates a tf.train optimizer.\n    \"\"\"", "\n", "if", "optimizer_fn", "is", "None", ":", "\n", "      ", "optimizer_fn", "=", "tf", ".", "train", ".", "AdamOptimizer", "\n", "", "self", ".", "optimizer_fn", "=", "optimizer_fn", "\n", "self", ".", "embedding_model_class", "=", "embedding_model_class", "\n", "self", ".", "reasoning_model_class", "=", "reasoning_model_class", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.TwoStageModel.model_fn": [[66, 125], ["models.TwoStageModel.reasoning_model_class", "models.TwoStageModel.", "models.TwoStageModel.summary", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "NotImplementedError", "tensorflow.contrib.tpu.TPUEstimatorSpec", "tensorflow.contrib.tpu.TPUEstimatorSpec", "models.TwoStageModel.embedding_model_class", "models.TwoStageModel.", "models.TwoStageModel.summary", "tensorflow.argmax", "tensorflow.control_dependencies", "models.TwoStageModel.optimizer_fn", "models.TwoStageModel.minimize", "tensorflow.metrics.accuracy", "tensorflow.train.get_global_step"], "methods", ["None"], ["", "def", "model_fn", "(", "self", ",", "features", ",", "labels", ",", "mode", ",", "params", ")", ":", "\n", "    ", "\"\"\"TPUEstimator compatible model_fn.\"\"\"", "\n", "del", "params", "\n", "is_training", "=", "(", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", "\n", "update_ops", "=", "[", "]", "\n", "\n", "# First, embed the context and answer panels.", "\n", "if", "self", ".", "embedding_model_class", "==", "\"values\"", ":", "\n", "# Use the integer values of the ground-truth factors.", "\n", "      ", "context_embeddings", "=", "features", "[", "\"context_factor_values\"", "]", "\n", "answer_embeddings", "=", "features", "[", "\"answers_factor_values\"", "]", "\n", "", "elif", "self", ".", "embedding_model_class", "==", "\"onehot\"", ":", "\n", "# Use one-hot embeddings of the ground-truth factors.", "\n", "      ", "context_embeddings", "=", "features", "[", "\"context_factors_onehot\"", "]", "\n", "answer_embeddings", "=", "features", "[", "\"answers_factors_onehot\"", "]", "\n", "", "else", ":", "\n", "      ", "embedding_model", "=", "self", ".", "embedding_model_class", "(", ")", "\n", "context_embeddings", ",", "answer_embeddings", "=", "embedding_model", "(", "\n", "[", "\n", "features", "[", "\"context\"", "]", ",", "\n", "features", "[", "\"answers\"", "]", ",", "\n", "]", ",", "\n", "training", "=", "is_training", ",", "\n", ")", "\n", "embedding_model", ".", "summary", "(", "print_fn", "=", "tf", ".", "logging", ".", "info", ")", "\n", "update_ops", "+=", "embedding_model", ".", "updates", "\n", "\n", "# Apply the reasoning model.", "\n", "", "reasoning_model", "=", "self", ".", "reasoning_model_class", "(", ")", "\n", "logits", "=", "reasoning_model", "(", "[", "context_embeddings", ",", "answer_embeddings", "]", ",", "\n", "training", "=", "is_training", ")", "\n", "reasoning_model", ".", "summary", "(", "print_fn", "=", "tf", ".", "logging", ".", "info", ")", "\n", "update_ops", "+=", "reasoning_model", ".", "updates", "\n", "\n", "loss_vec", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "labels", "=", "labels", ",", "logits", "=", "logits", ")", "\n", "loss_mean", "=", "tf", ".", "reduce_mean", "(", "loss_vec", ")", "\n", "\n", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ":", "\n", "\n", "      ", "def", "metric_fn", "(", "labels", ",", "logits", ")", ":", "\n", "        ", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "return", "{", "\n", "\"accuracy\"", ":", "\n", "tf", ".", "metrics", ".", "accuracy", "(", "labels", "=", "labels", ",", "predictions", "=", "predictions", ")", ",", "\n", "}", "\n", "\n", "", "return", "contrib_tpu", ".", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "loss", "=", "loss_mean", ",", "eval_metrics", "=", "(", "metric_fn", ",", "[", "labels", ",", "logits", "]", ")", ")", "\n", "\n", "", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ":", "\n", "# In case we use batch norm, the following is required.", "\n", "      ", "with", "tf", ".", "control_dependencies", "(", "update_ops", ")", ":", "\n", "        ", "optimizer", "=", "self", ".", "optimizer_fn", "(", ")", "\n", "train_op", "=", "optimizer", ".", "minimize", "(", "\n", "loss", "=", "loss_mean", ",", "global_step", "=", "tf", ".", "train", ".", "get_global_step", "(", ")", ")", "\n", "", "return", "contrib_tpu", ".", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "loss", "=", "loss_mean", ",", "train_op", "=", "train_op", ")", "\n", "", "raise", "NotImplementedError", "(", "\"Unsupported mode.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.BaselineCNNEmbedder.__init__": [[131, 172], ["super().__init__", "disentanglement_lib.evaluation.abstract_reasoning.relational_layers.MultiDimBatchApply", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Flatten", "tensorflow.keras.models.Sequential", "models.get_activation", "models.get_kernel_initializer", "models.get_activation", "models.get_kernel_initializer", "models.get_activation", "models.get_kernel_initializer", "models.get_activation", "models.get_kernel_initializer"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.__init__", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.get_activation", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.get_kernel_initializer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.get_activation", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.get_kernel_initializer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.get_activation", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.get_kernel_initializer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.get_activation", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.get_kernel_initializer"], ["def", "__init__", "(", "self", ",", "\n", "num_latent", "=", "gin", ".", "REQUIRED", ",", "\n", "name", "=", "\"BaselineCNNEmbedder\"", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a BaselineCNNEmbedder.\n\n    Args:\n      num_latent: Integer with the number of latent dimensions.\n      name: String with the name of the model.\n      **kwargs: Other keyword arguments passed to tf.keras.Model.\n    \"\"\"", "\n", "super", "(", "BaselineCNNEmbedder", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "embedding_layers", "=", "[", "\n", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "32", ",", "(", "4", ",", "4", ")", ",", "\n", "2", ",", "\n", "activation", "=", "get_activation", "(", ")", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "kernel_initializer", "=", "get_kernel_initializer", "(", ")", ")", ",", "\n", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "32", ",", "(", "4", ",", "4", ")", ",", "\n", "2", ",", "\n", "activation", "=", "get_activation", "(", ")", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "kernel_initializer", "=", "get_kernel_initializer", "(", ")", ")", ",", "\n", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "64", ",", "(", "4", ",", "4", ")", ",", "\n", "2", ",", "\n", "activation", "=", "get_activation", "(", ")", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "kernel_initializer", "=", "get_kernel_initializer", "(", ")", ")", ",", "\n", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "64", ",", "(", "4", ",", "4", ")", ",", "\n", "2", ",", "\n", "activation", "=", "get_activation", "(", ")", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "kernel_initializer", "=", "get_kernel_initializer", "(", ")", ")", ",", "\n", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", ",", "\n", "]", "\n", "self", ".", "embedding_layer", "=", "relational_layers", ".", "MultiDimBatchApply", "(", "\n", "tf", ".", "keras", ".", "models", ".", "Sequential", "(", "embedding_layers", ",", "\"embedding_cnn\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.BaselineCNNEmbedder.call": [[173, 178], ["models.BaselineCNNEmbedder.embedding_layer", "models.BaselineCNNEmbedder.embedding_layer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "    ", "context", ",", "answers", "=", "inputs", "\n", "context_embedding", "=", "self", ".", "embedding_layer", "(", "context", ",", "**", "kwargs", ")", "\n", "answers_embedding", "=", "self", ".", "embedding_layer", "(", "answers", ",", "**", "kwargs", ")", "\n", "return", "context_embedding", ",", "answers_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.HubEmbedding.__init__": [[187, 203], ["super().__init__", "disentanglement_lib.evaluation.abstract_reasoning.relational_layers.MultiDimBatchApply", "tensorflow_hub.Module", "tensorflow_hub.Module.", "tensorflow.keras.layers.Lambda", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.__init__"], ["def", "__init__", "(", "self", ",", "hub_path", "=", "gin", ".", "REQUIRED", ",", "name", "=", "\"HubEmbedding\"", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a HubEmbedding.\n\n    Args:\n      hub_path: Path to the TFHub module.\n      name: String with the name of the model.\n      **kwargs: Other keyword arguments passed to tf.keras.Model.\n    \"\"\"", "\n", "super", "(", "HubEmbedding", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "\n", "def", "_embedder", "(", "x", ")", ":", "\n", "      ", "embedder_module", "=", "hub", ".", "Module", "(", "hub_path", ")", "\n", "return", "embedder_module", "(", "dict", "(", "images", "=", "x", ")", ",", "signature", "=", "\"representation\"", ")", "\n", "\n", "", "self", ".", "embedding_layer", "=", "relational_layers", ".", "MultiDimBatchApply", "(", "\n", "tf", ".", "keras", ".", "layers", ".", "Lambda", "(", "_embedder", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.HubEmbedding.call": [[204, 209], ["models.HubEmbedding.embedding_layer", "models.HubEmbedding.embedding_layer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "    ", "context", ",", "answers", "=", "inputs", "\n", "context_embedding", "=", "self", ".", "embedding_layer", "(", "context", ",", "**", "kwargs", ")", "\n", "answers_embedding", "=", "self", ".", "embedding_layer", "(", "answers", ",", "**", "kwargs", ")", "\n", "return", "context_embedding", ",", "answers_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.OptimizedWildRelNet.__init__": [[218, 282], ["super().__init__", "tensorflow.keras.models.Sequential", "tensorflow.keras.models.Sequential", "disentanglement_lib.evaluation.abstract_reasoning.relational_layers.StackAnswers", "tensorflow.keras.models.Sequential", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "disentanglement_lib.evaluation.abstract_reasoning.relational_layers.AddPositionalEncoding", "disentanglement_lib.evaluation.abstract_reasoning.relational_layers.RelationalLayer", "tensorflow.keras.layers.Lambda", "tensorflow.keras.layers.Lambda", "models.get_kernel_initializer", "tensorflow.keras.layers.Lambda", "models.get_activation", "models.get_kernel_initializer", "models.get_activation", "models.get_kernel_initializer", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.__init__", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.get_kernel_initializer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.get_activation", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.get_kernel_initializer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.get_activation", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.get_kernel_initializer"], ["def", "__init__", "(", "self", ",", "\n", "edge_mlp", "=", "gin", ".", "REQUIRED", ",", "\n", "graph_mlp", "=", "gin", ".", "REQUIRED", ",", "\n", "dropout_in_last_graph_layer", "=", "gin", ".", "REQUIRED", ",", "\n", "name", "=", "\"OptimizedWildRelNet\"", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a OptimizedWildRelNet.\n\n    Args:\n      edge_mlp: List with number of latent nodes in different layers of the edge\n        MLP.\n      graph_mlp: List with number of latent nodes in different layers of the\n        graph MLP.\n      dropout_in_last_graph_layer: Dropout fraction to be applied in the last\n        layer of the graph MLP.\n      name: String with the name of the model.\n      **kwargs: Other keyword arguments passed to tf.keras.Model.\n    \"\"\"", "\n", "super", "(", "OptimizedWildRelNet", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "\n", "# Create the EdgeMLP.", "\n", "edge_layers", "=", "[", "]", "\n", "for", "num_units", "in", "edge_mlp", ":", "\n", "      ", "edge_layers", "+=", "[", "\n", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "num_units", ",", "\n", "activation", "=", "get_activation", "(", ")", ",", "\n", "kernel_initializer", "=", "get_kernel_initializer", "(", ")", ")", "\n", "]", "\n", "", "self", ".", "edge_layer", "=", "tf", ".", "keras", ".", "models", ".", "Sequential", "(", "edge_layers", ",", "\"edge_mlp\"", ")", "\n", "\n", "# Create the GraphMLP.", "\n", "graph_layers", "=", "[", "]", "\n", "for", "num_units", "in", "graph_mlp", ":", "\n", "      ", "graph_layers", "+=", "[", "\n", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "num_units", ",", "\n", "activation", "=", "get_activation", "(", ")", ",", "\n", "kernel_initializer", "=", "get_kernel_initializer", "(", ")", ")", "\n", "]", "\n", "", "if", "dropout_in_last_graph_layer", ":", "\n", "      ", "graph_layers", "+=", "[", "\n", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "\n", "1.", "-", "dropout_in_last_graph_layer", ",", "\n", "noise_shape", "=", "[", "1", ",", "1", ",", "graph_mlp", "[", "-", "1", "]", "]", ")", "\n", "]", "\n", "", "graph_layers", "+=", "[", "\n", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "1", ",", "kernel_initializer", "=", "get_kernel_initializer", "(", ")", ")", "\n", "]", "\n", "\n", "# Create the auxiliary layers.", "\n", "self", ".", "graph_layer", "=", "tf", ".", "keras", ".", "models", ".", "Sequential", "(", "graph_layers", ",", "\"graph_mlp\"", ")", "\n", "self", ".", "stacking_layer", "=", "relational_layers", ".", "StackAnswers", "(", ")", "\n", "\n", "# Create the WildRelationNet.", "\n", "self", ".", "wildrelnet", "=", "tf", ".", "keras", ".", "models", ".", "Sequential", "(", "[", "\n", "relational_layers", ".", "AddPositionalEncoding", "(", ")", ",", "\n", "relational_layers", ".", "RelationalLayer", "(", "\n", "self", ".", "edge_layer", ",", "\n", "tf", ".", "keras", ".", "layers", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "reduce_sum", "(", "x", ",", "axis", "=", "-", "2", ")", ")", ")", ",", "\n", "tf", ".", "keras", ".", "layers", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "reduce_sum", "(", "x", ",", "axis", "=", "-", "2", ")", ")", ",", "\n", "self", ".", "graph_layer", ",", "\n", "tf", ".", "keras", ".", "layers", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "reduce_sum", "(", "x", ",", "axis", "=", "-", "1", ")", ")", ",", "\n", "]", ",", "\"wildrelnet\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.OptimizedWildRelNet.call": [[283, 291], ["models.OptimizedWildRelNet.stacking_layer", "models.OptimizedWildRelNet.wildrelnet"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "    ", "context_embeddings", ",", "answer_embeddings", "=", "inputs", "\n", "# The stacking layer `stacks` each answer panel embedding onto the context", "\n", "# panels separately.", "\n", "stacked_answers", "=", "self", ".", "stacking_layer", "(", "\n", "[", "context_embeddings", ",", "answer_embeddings", "]", ")", "\n", "# Apply the relational neural network.", "\n", "return", "self", ".", "wildrelnet", "(", "stacked_answers", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.get_activation": [[293, 298], ["gin.configurable", "tensorflow.keras.activations.relu"], "function", ["None"], ["", "", "@", "gin", ".", "configurable", "(", "\"activation\"", ")", "\n", "def", "get_activation", "(", "activation", "=", "tf", ".", "keras", ".", "activations", ".", "relu", ")", ":", "\n", "  ", "if", "activation", "==", "\"lrelu\"", ":", "\n", "    ", "return", "lambda", "x", ":", "tf", ".", "keras", ".", "activations", ".", "relu", "(", "x", ",", "alpha", "=", "0.2", ")", "\n", "", "return", "activation", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.models.get_kernel_initializer": [[300, 303], ["gin.configurable"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"kernel_initializer\"", ")", "\n", "def", "get_kernel_initializer", "(", "kernel_initializer", "=", "\"lecun_normal\"", ")", ":", "\n", "  ", "return", "kernel_initializer", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.reason_test.ReasonTestRepresentation.setUp": [[31, 44], ["super().setUp", "disentanglement_lib.utils.resources.get_file", "disentanglement_lib.methods.unsupervised.train.train_with_gin", "disentanglement_lib.utils.resources.get_file", "disentanglement_lib.postprocessing.postprocess.postprocess_with_gin", "reason_test.ReasonTestRepresentation.create_tempdir", "reason_test.ReasonTestRepresentation.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.validation.validation_test.ValidateTest.setUp", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train_with_gin", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.postprocessing.postprocess.postprocess_with_gin"], ["  ", "def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "ReasonTestRepresentation", ",", "self", ")", ".", "setUp", "(", ")", "\n", "self", ".", "model_dir", "=", "self", ".", "create_tempdir", "(", "\n", "\"model\"", ",", "cleanup", "=", "absltest", ".", "TempFileCleanup", ".", "OFF", ")", ".", "full_path", "\n", "model_config", "=", "resources", ".", "get_file", "(", "\n", "\"config/tests/methods/unsupervised/train_test.gin\"", ")", "\n", "train", ".", "train_with_gin", "(", "self", ".", "model_dir", ",", "True", ",", "[", "model_config", "]", ")", "\n", "self", ".", "output_dir", "=", "self", ".", "create_tempdir", "(", "\n", "\"output\"", ",", "cleanup", "=", "absltest", ".", "TempFileCleanup", ".", "OFF", ")", ".", "full_path", "\n", "postprocess_config", "=", "resources", ".", "get_file", "(", "\n", "\"config/tests/postprocessing/postprocess_test_configs/mean.gin\"", ")", "\n", "postprocess", ".", "postprocess_with_gin", "(", "self", ".", "model_dir", ",", "self", ".", "output_dir", ",", "True", ",", "\n", "[", "postprocess_config", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.reason_test.ReasonTestRepresentation.test_reason_from_representation": [[45, 55], ["absl.testing.parameterized.parameters", "gin.clear_config", "disentanglement_lib.evaluation.abstract_reasoning.reason.reason_with_gin", "list", "disentanglement_lib.utils.resources.get_files_in_folder", "reason_test.ReasonTestRepresentation.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.reason.reason_with_gin", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_files_in_folder"], ["", "@", "parameterized", ".", "parameters", "(", "\n", "list", "(", "\n", "resources", ".", "get_files_in_folder", "(", "\n", "\"config/tests/abstract_reasoning/representation\"", ")", ")", ")", "\n", "def", "test_reason_from_representation", "(", "self", ",", "gin_config", ")", ":", "\n", "# We clear the gin config before running. Otherwise, if a prior test fails,", "\n", "# the gin config is locked and the current test fails.", "\n", "    ", "gin", ".", "clear_config", "(", ")", "\n", "reason", ".", "reason_with_gin", "(", "self", ".", "output_dir", ",", "\n", "self", ".", "create_tempdir", "(", ")", ".", "full_path", ",", "True", ",", "[", "gin_config", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.reason_test.ReasonTestFromScratch.test_reason_from_scratch": [[59, 69], ["absl.testing.parameterized.parameters", "gin.clear_config", "disentanglement_lib.evaluation.abstract_reasoning.reason.reason_with_gin", "list", "disentanglement_lib.utils.resources.get_files_in_folder", "reason_test.ReasonTestFromScratch.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.reason.reason_with_gin", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_files_in_folder"], ["  ", "@", "parameterized", ".", "parameters", "(", "\n", "list", "(", "\n", "resources", ".", "get_files_in_folder", "(", "\n", "\"config/tests/abstract_reasoning/from_scratch\"", ")", ")", ")", "\n", "def", "test_reason_from_scratch", "(", "self", ",", "gin_config", ")", ":", "\n", "# We clear the gin config before running. Otherwise, if a prior test fails,", "\n", "# the gin config is locked and the current test fails.", "\n", "    ", "gin", ".", "clear_config", "(", ")", "\n", "reason", ".", "reason_with_gin", "(", "None", ",", "\n", "self", ".", "create_tempdir", "(", ")", ".", "full_path", ",", "True", ",", "[", "gin_config", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.RelationalLayer.__init__": [[34, 52], ["relational_layers.PairwiseEdgeEmbeddings", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.__init__"], ["def", "__init__", "(", "self", ",", "edge_layer", ",", "reduce_layer", ")", ":", "\n", "    ", "\"\"\"Constructs a RelationalLayer.\n\n    Args:\n      edge_layer: tf.keras.layers.Layer that is applied to the edge embeddings.\n        Should accept a (batch_size, num_nodes, num_nodes, 2*num_dims)-sized\n        tensor (where the node embeddings are stacked along the last axis)\n        and should return a (batch_size, num_nodes, num_nodes, num_dims)-sized\n        tensor.\n      reduce_layer: tf.keras.layers.Layer that is used to reduce the edge\n        embeddings back to node embeddings. Should accept a\n        (batch_size, num_nodes, num_nodes, num_dims)-sized tensor and return a\n        (batch_size, num_nodes, num_dims)-sized tensor.\n    \"\"\"", "\n", "self", ".", "_pairwise_edge_embeddings_layer", "=", "PairwiseEdgeEmbeddings", "(", ")", "\n", "self", ".", "edge_layer", "=", "edge_layer", "\n", "self", ".", "reduce_layer", "=", "reduce_layer", "\n", "super", "(", "RelationalLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.RelationalLayer.call": [[53, 61], ["relational_layers.RelationalLayer._pairwise_edge_embeddings_layer", "relational_layers.RelationalLayer.edge_layer", "relational_layers.RelationalLayer.reduce_layer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "# Create edge embedding by concatenating the node embeddings.", "\n", "    ", "x", "=", "self", ".", "_pairwise_edge_embeddings_layer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "# Update edge embeddings using edge layer.", "\n", "x", "=", "self", ".", "edge_layer", "(", "x", ",", "**", "kwargs", ")", "\n", "# Reduce back to node embeddings.", "\n", "outputs", "=", "self", ".", "reduce_layer", "(", "x", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.PairwiseEdgeEmbeddings.call": [[66, 72], ["tensorflow.concat", "inputs.get_shape().as_list", "relational_layers.repeat", "relational_layers.repeat", "inputs.get_shape", "tensorflow.expand_dims", "tensorflow.expand_dims"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.repeat", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.repeat"], ["def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "    ", "num_nodes", "=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "2", "]", "\n", "return", "tf", ".", "concat", "(", "\n", "(", "repeat", "(", "tf", ".", "expand_dims", "(", "inputs", ",", "-", "2", ")", ",", "num_nodes", ",", "-", "2", ")", ",", "\n", "repeat", "(", "tf", ".", "expand_dims", "(", "inputs", ",", "-", "3", ")", ",", "num_nodes", ",", "-", "3", ")", ")", ",", "\n", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.AddPositionalEncoding.__init__": [[135, 139], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.__init__"], ["def", "__init__", "(", "self", ",", "positional_encoding_axis", "=", "-", "2", ",", "embedding_axis", "=", "-", "1", ")", ":", "\n", "    ", "self", ".", "positional_encoding_axis", "=", "positional_encoding_axis", "\n", "self", ".", "embedding_axis", "=", "embedding_axis", "\n", "super", "(", "AddPositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.AddPositionalEncoding.call": [[140, 146], ["relational_layers.positional_encoding_like", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.positional_encoding_like"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "    ", "onehot_embedding", "=", "positional_encoding_like", "(", "\n", "inputs", ",", "\n", "positional_encoding_axis", "=", "self", ".", "positional_encoding_axis", ",", "\n", "value_axis", "=", "self", ".", "embedding_axis", ")", "\n", "return", "tf", ".", "concat", "(", "[", "inputs", ",", "onehot_embedding", "]", ",", "axis", "=", "self", ".", "embedding_axis", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.StackAnswers.__init__": [[151, 155], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.__init__"], ["def", "__init__", "(", "self", ",", "answer_axis", "=", "-", "2", ",", "stack_axis", "=", "-", "3", ")", ":", "\n", "    ", "super", "(", "StackAnswers", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "answer_axis", "=", "answer_axis", "\n", "self", ".", "stack_axis", "=", "stack_axis", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.StackAnswers.call": [[156, 165], ["range", "tensorflow.stack", "answers.get_shape().as_list", "tensorflow.gather", "tensorflow.concat", "answer_blocks.append", "answers.get_shape"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "    ", "context", ",", "answers", "=", "inputs", "\n", "num_answers", "=", "answers", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "self", ".", "answer_axis", "]", "\n", "answer_blocks", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_answers", ")", ":", "\n", "      ", "ith_answer", "=", "tf", ".", "gather", "(", "answers", ",", "[", "i", "]", ",", "axis", "=", "self", ".", "answer_axis", ")", "\n", "ith_answer_block", "=", "tf", ".", "concat", "(", "[", "context", ",", "ith_answer", "]", ",", "axis", "=", "self", ".", "answer_axis", ")", "\n", "answer_blocks", ".", "append", "(", "ith_answer_block", ")", "\n", "", "return", "tf", ".", "stack", "(", "answer_blocks", ",", "axis", "=", "self", ".", "stack_axis", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.MultiDimBatchApply.__init__": [[170, 183], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.__init__"], ["def", "__init__", "(", "self", ",", "layer", ",", "num_dims_to_keep", "=", "3", ")", ":", "\n", "    ", "\"\"\"Constructs a MultiDimBatchApply.\n\n    Args:\n      layer: tf.keras.layers.Layer to apply.\n      num_dims_to_keep: Integer with number of dimensions to provide to the\n        layer. The dimensions 0:-num_dims_to_keep correspond to the multi\n          dimensional mini batch, i.e., the layer is applied independently for\n          each of these elements.\n    \"\"\"", "\n", "self", ".", "layer", "=", "layer", "\n", "self", ".", "num_dims_to_keep", "=", "num_dims_to_keep", "\n", "super", "(", "MultiDimBatchApply", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.MultiDimBatchApply.call": [[184, 193], ["tensorflow.reshape.get_shape().as_list", "tensorflow.reshape", "relational_layers.MultiDimBatchApply.layer", "tensorflow.reshape", "relational_layers.MultiDimBatchApply.get_shape().as_list", "tensorflow.reshape.get_shape", "relational_layers.MultiDimBatchApply.get_shape"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "    ", "shape", "=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "collapsed_shape", "=", "[", "-", "1", "]", "+", "shape", "[", "-", "self", ".", "num_dims_to_keep", ":", "]", "\n", "inputs", "=", "tf", ".", "reshape", "(", "inputs", ",", "collapsed_shape", ")", "\n", "# Apply the layer.", "\n", "output", "=", "self", ".", "layer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "active_shape", "=", "output", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "output_shape", "=", "[", "-", "1", "]", "+", "shape", "[", "1", ":", "-", "self", ".", "num_dims_to_keep", "]", "+", "active_shape", "\n", "return", "tf", ".", "reshape", "(", "output", ",", "output_shape", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.repeat": [[74, 79], ["tensorflow.tile", "tensor.get_shape"], "function", ["None"], ["", "", "def", "repeat", "(", "tensor", ",", "num", ",", "axis", ")", ":", "\n", "  ", "\"\"\"Repeats tensor num times along the specified axis.\"\"\"", "\n", "multiples", "=", "[", "1", "]", "*", "tensor", ".", "get_shape", "(", ")", ".", "ndims", "\n", "multiples", "[", "axis", "]", "=", "num", "\n", "return", "tf", ".", "tile", "(", "tensor", ",", "multiples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.positional_encoding_like": [[81, 122], ["tensor.get_shape", "tensorflow.eye", "tensorflow.reshape", "tensor.get_shape.as_list", "tensorflow.tile", "tensor.get_shape.as_list", "tensor.get_shape.is_fully_defined", "tensorflow.unstack", "tensorflow.shape", "enumerate"], "function", ["None"], ["", "def", "positional_encoding_like", "(", "tensor", ",", "positional_encoding_axis", "=", "-", "2", ",", "\n", "value_axis", "=", "-", "1", ")", ":", "\n", "  ", "\"\"\"Creates positional encoding matching the provided tensor.\n\n  Let each slice along the last axis of the tensor be a row. This function\n  computes the index of each row with respect to the specified\n  positional_encoding_axis and returns this index using a one-hot embedding.\n\n  The resulting tensor has the same shape as the provided tensor except for the\n  value_axis dimension. That dimension contains a one-hot encoding of the\n  positional_encoding_axis, i.e., each slice along value_axis and the\n  positional_encoding_axis corresponds to the identity matrix.\n\n  Args:\n    tensor: Input tensor.\n    positional_encoding_axis: Integer with the axis to encode.\n    value_axis: Integer with axis where to one-hot encode the\n      positional_encoding_axis.\n\n  Returns:\n    Positional encoding tensor of the same dtype as tensor.\n  \"\"\"", "\n", "# First, create identity matrix for one-hot embedding.", "\n", "shape", "=", "tensor", ".", "get_shape", "(", ")", "\n", "num_values", "=", "shape", ".", "as_list", "(", ")", "[", "positional_encoding_axis", "]", "\n", "result", "=", "tf", ".", "eye", "(", "num_values", ",", "dtype", "=", "tensor", ".", "dtype", ")", "\n", "# Second, reshape to proper dimensionality.", "\n", "new_shape", "=", "[", "1", "]", "*", "shape", ".", "ndims", "\n", "new_shape", "[", "positional_encoding_axis", "]", "=", "num_values", "\n", "new_shape", "[", "value_axis", "]", "=", "num_values", "\n", "result", "=", "tf", ".", "reshape", "(", "result", ",", "new_shape", ")", "\n", "# Third, broadcast to final shape.", "\n", "multiplier", "=", "shape", ".", "as_list", "(", ")", "\n", "multiplier", "[", "positional_encoding_axis", "]", "=", "1", "\n", "multiplier", "[", "value_axis", "]", "=", "1", "\n", "if", "not", "shape", ".", "is_fully_defined", "(", ")", ":", "\n", "    ", "dynamic_shape", "=", "tf", ".", "unstack", "(", "tf", ".", "shape", "(", "tensor", ")", ")", "\n", "multiplier", "=", "[", "\n", "(", "dynamic_shape", "[", "i", "]", "if", "n", "is", "None", "else", "n", ")", "for", "i", ",", "n", "in", "enumerate", "(", "multiplier", ")", "\n", "]", "\n", "", "return", "tf", ".", "tile", "(", "result", ",", "multiplier", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.reason.reason_with_gin": [[39, 63], ["gin.parse_config_files_and_bindings", "gin.parse_config_files_and_bindings", "reason.reason", "gin.clear_config", "gin.clear_config"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.reason.reason"], ["def", "reason_with_gin", "(", "input_dir", ",", "\n", "output_dir", ",", "\n", "overwrite", "=", "False", ",", "\n", "gin_config_files", "=", "None", ",", "\n", "gin_bindings", "=", "None", ")", ":", "\n", "  ", "\"\"\"Trains a model based on the provided gin configuration.\n\n  This function will set the provided gin bindings, call the reason() function\n  and clear the gin config. Please see reason() for required gin bindings.\n\n  Args:\n    input_dir: String with path to directory where the representation is saved.\n    output_dir: String with the path where the evaluation should be saved.\n    overwrite: Boolean indicating whether to overwrite output directory.\n    gin_config_files: List of gin config files to load.\n    gin_bindings: List of gin bindings to use.\n  \"\"\"", "\n", "if", "gin_config_files", "is", "None", ":", "\n", "    ", "gin_config_files", "=", "[", "]", "\n", "", "if", "gin_bindings", "is", "None", ":", "\n", "    ", "gin_bindings", "=", "[", "]", "\n", "", "gin", ".", "parse_config_files_and_bindings", "(", "gin_config_files", ",", "gin_bindings", ")", "\n", "reason", "(", "input_dir", ",", "output_dir", ",", "overwrite", ")", "\n", "gin", ".", "clear_config", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.reason.reason": [[65, 201], ["gin.configurable", "gin.configurable", "tensorflow.gfile.IsDirectory", "numpy.random.RandomState", "disentanglement_lib.evaluation.abstract_reasoning.pgm_data.get_pgm_dataset", "tensorflow.contrib.tpu.RunConfig", "tensorflow.contrib.tpu.TPUEstimator", "time.time", "range", "numpy.argmax", "disentanglement_lib.utils.results.namespaced_dict", "os.path.join", "disentanglement_lib.utils.results.update_result_directory", "gin.query_parameter", "gin.query_parameter", "os.path.join", "disentanglement_lib.utils.results.gin_dict", "os.path.join", "tensorflow.logging.info", "contrib_tpu.TPUEstimator.train", "contrib_tpu.TPUEstimator.evaluate", "validation_scores.append", "tensorflow.logging.info", "contrib_tpu.TPUEstimator.evaluate", "disentanglement_lib.utils.results.namespaced_dict", "all_dicts.append", "os.path.join", "time.time", "tensorflow.gfile.DeleteRecursively", "ValueError", "ValueError", "gin.unlock_config", "gin.unlock_config", "gin.bind_parameter", "gin.bind_parameter", "gin.unlock_config", "gin.unlock_config", "gin.bind_parameter", "gin.bind_parameter", "tensorflow.contrib.tpu.TPUConfig", "os.path.join", "gin_dict[].replace", "pgm_data.get_pgm_dataset.make_input_fn", "pgm_data.get_pgm_dataset.make_input_fn", "pgm_data.get_pgm_dataset.make_input_fn", "np.random.RandomState.randint", "np.random.RandomState.randint", "np.random.RandomState.randint"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.get_pgm_dataset", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.namespaced_dict", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.update_result_directory", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.gin_dict", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate.evaluate", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate.evaluate", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.namespaced_dict", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMDataset.make_input_fn", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMDataset.make_input_fn", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMDataset.make_input_fn"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"abstract_reasoning\"", ",", "blacklist", "=", "[", "\"input_dir\"", ",", "\"output_dir\"", ",", "\"overwrite\"", "]", ")", "\n", "def", "reason", "(", "\n", "input_dir", ",", "\n", "output_dir", ",", "\n", "overwrite", "=", "False", ",", "\n", "model", "=", "gin", ".", "REQUIRED", ",", "\n", "num_iterations", "=", "gin", ".", "REQUIRED", ",", "\n", "training_steps_per_iteration", "=", "gin", ".", "REQUIRED", ",", "\n", "eval_steps_per_iteration", "=", "gin", ".", "REQUIRED", ",", "\n", "random_seed", "=", "gin", ".", "REQUIRED", ",", "\n", "batch_size", "=", "gin", ".", "REQUIRED", ",", "\n", "name", "=", "\"\"", ",", "\n", ")", ":", "\n", "  ", "\"\"\"Trains the estimator and exports the snapshot and the gin config.\n\n  The use of this function requires the gin binding 'dataset.name' to be\n  specified if a model is trained from scratch as that determines the data set\n  used for training.\n\n  Args:\n    input_dir: String with path to directory where the representation function\n      is saved.\n    output_dir: String with the path where the results should be saved.\n    overwrite: Boolean indicating whether to overwrite output directory.\n    model: GaussianEncoderModel that should be trained and exported.\n    num_iterations: Integer with number of training steps.\n    training_steps_per_iteration: Integer with number of training steps per\n      iteration.\n    eval_steps_per_iteration: Integer with number of validationand test steps\n      per iteration.\n    random_seed: Integer with random seed used for training.\n    batch_size: Integer with the batch size.\n    name: Optional string with name of the model (can be used to name models).\n  \"\"\"", "\n", "# We do not use the variable 'name'. Instead, it can be used to name results", "\n", "# as it will be part of the saved gin config.", "\n", "del", "name", "\n", "\n", "# Delete the output directory if it already exists.", "\n", "if", "tf", ".", "gfile", ".", "IsDirectory", "(", "output_dir", ")", ":", "\n", "    ", "if", "overwrite", ":", "\n", "      ", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "output_dir", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"Directory already exists and overwrite is False.\"", ")", "\n", "\n", "# Create a numpy random state. We will sample the random seeds for training", "\n", "# and evaluation from this.", "\n", "", "", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "random_seed", ")", "\n", "\n", "# Automatically set the proper data set if necessary. We replace the active", "\n", "# gin config as this will lead to a valid gin config file where the data set", "\n", "# is present.", "\n", "if", "gin", ".", "query_parameter", "(", "\"dataset.name\"", ")", "==", "\"auto\"", ":", "\n", "    ", "if", "input_dir", "is", "None", ":", "\n", "      ", "raise", "ValueError", "(", "\"Cannot automatically infer data set for methods with\"", "\n", "\" no prior model directory.\"", ")", "\n", "# Obtain the dataset name from the gin config of the previous step.", "\n", "", "gin_config_file", "=", "os", ".", "path", ".", "join", "(", "input_dir", ",", "\"results\"", ",", "\"gin\"", ",", "\n", "\"postprocess.gin\"", ")", "\n", "gin_dict", "=", "results", ".", "gin_dict", "(", "gin_config_file", ")", "\n", "with", "gin", ".", "unlock_config", "(", ")", ":", "\n", "      ", "gin", ".", "bind_parameter", "(", "\"dataset.name\"", ",", "\n", "gin_dict", "[", "\"dataset.name\"", "]", ".", "replace", "(", "\"'\"", ",", "\"\"", ")", ")", "\n", "", "", "dataset", "=", "pgm_data", ".", "get_pgm_dataset", "(", ")", "\n", "\n", "# Set the path to the TFHub embedding if we are training based on a", "\n", "# pre-trained embedding..", "\n", "if", "input_dir", "is", "not", "None", ":", "\n", "    ", "tfhub_dir", "=", "os", ".", "path", ".", "join", "(", "input_dir", ",", "\"tfhub\"", ")", "\n", "with", "gin", ".", "unlock_config", "(", ")", ":", "\n", "      ", "gin", ".", "bind_parameter", "(", "\"HubEmbedding.hub_path\"", ",", "tfhub_dir", ")", "\n", "\n", "# We create a TPUEstimator based on the provided model. This is primarily so", "\n", "# that we could switch to TPU training in the future. For now, we train", "\n", "# locally on GPUs.", "\n", "", "", "run_config", "=", "contrib_tpu", ".", "RunConfig", "(", "\n", "tf_random_seed", "=", "random_seed", ",", "\n", "keep_checkpoint_max", "=", "1", ",", "\n", "tpu_config", "=", "contrib_tpu", ".", "TPUConfig", "(", "iterations_per_loop", "=", "500", ")", ")", "\n", "tpu_estimator", "=", "contrib_tpu", ".", "TPUEstimator", "(", "\n", "use_tpu", "=", "False", ",", "\n", "model_fn", "=", "model", ".", "model_fn", ",", "\n", "model_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"tf_checkpoint\"", ")", ",", "\n", "train_batch_size", "=", "batch_size", ",", "\n", "eval_batch_size", "=", "batch_size", ",", "\n", "config", "=", "run_config", ")", "\n", "\n", "# Set up time to keep track of elapsed time in results.", "\n", "experiment_timer", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Create a dictionary to keep track of all relevant information.", "\n", "results_dict_of_dicts", "=", "{", "}", "\n", "validation_scores", "=", "[", "]", "\n", "all_dicts", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_iterations", ")", ":", "\n", "    ", "steps_so_far", "=", "i", "*", "training_steps_per_iteration", "\n", "tf", ".", "logging", ".", "info", "(", "\"Training to %d steps.\"", ",", "steps_so_far", ")", "\n", "# Train the model for the specified steps.", "\n", "tpu_estimator", ".", "train", "(", "\n", "input_fn", "=", "dataset", ".", "make_input_fn", "(", "random_state", ".", "randint", "(", "2", "**", "32", ")", ")", ",", "\n", "steps", "=", "training_steps_per_iteration", ")", "\n", "# Compute validation scores used for model selection.", "\n", "validation_results", "=", "tpu_estimator", ".", "evaluate", "(", "\n", "input_fn", "=", "dataset", ".", "make_input_fn", "(", "\n", "random_state", ".", "randint", "(", "2", "**", "32", ")", ",", "num_batches", "=", "eval_steps_per_iteration", ")", ")", "\n", "validation_scores", ".", "append", "(", "validation_results", "[", "\"accuracy\"", "]", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"Validation results %s\"", ",", "validation_results", ")", "\n", "# Compute test scores for final results.", "\n", "test_results", "=", "tpu_estimator", ".", "evaluate", "(", "\n", "input_fn", "=", "dataset", ".", "make_input_fn", "(", "\n", "random_state", ".", "randint", "(", "2", "**", "32", ")", ",", "num_batches", "=", "eval_steps_per_iteration", ")", ",", "\n", "name", "=", "\"test\"", ")", "\n", "dict_at_iteration", "=", "results", ".", "namespaced_dict", "(", "\n", "val", "=", "validation_results", ",", "test", "=", "test_results", ")", "\n", "results_dict_of_dicts", "[", "\"step{}\"", ".", "format", "(", "steps_so_far", ")", "]", "=", "dict_at_iteration", "\n", "all_dicts", ".", "append", "(", "dict_at_iteration", ")", "\n", "\n", "# Select the best number of steps based on the validation scores and add it as", "\n", "# as a special key to the dictionary.", "\n", "", "best_index", "=", "np", ".", "argmax", "(", "validation_scores", ")", "\n", "results_dict_of_dicts", "[", "\"best\"", "]", "=", "all_dicts", "[", "best_index", "]", "\n", "\n", "# Save the results. The result dir will contain all the results and config", "\n", "# files that we copied along, as we progress in the pipeline. The idea is that", "\n", "# these files will be available for analysis at the end.", "\n", "if", "input_dir", "is", "not", "None", ":", "\n", "    ", "original_results_dir", "=", "os", ".", "path", ".", "join", "(", "input_dir", ",", "\"results\"", ")", "\n", "", "else", ":", "\n", "    ", "original_results_dir", "=", "None", "\n", "", "results_dict", "=", "results", ".", "namespaced_dict", "(", "**", "results_dict_of_dicts", ")", "\n", "results_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"results\"", ")", "\n", "results_dict", "[", "\"elapsed_time\"", "]", "=", "time", ".", "time", "(", ")", "-", "experiment_timer", "\n", "results", ".", "update_result_directory", "(", "results_dir", ",", "\"abstract_reasoning\"", ",", "\n", "results_dict", ",", "original_results_dir", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers_test.RelationalLayersTest.test_repeat_for_tensor": [[38, 43], ["numpy.arange().reshape", "numpy.concatenate", "relational_layers_test.RelationalLayersTest.evaluate", "relational_layers_test.RelationalLayersTest.assertAllClose", "disentanglement_lib.evaluation.abstract_reasoning.relational_layers.repeat", "numpy.arange", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate.evaluate", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.repeat"], ["  ", "def", "test_repeat_for_tensor", "(", "self", ")", ":", "\n", "    ", "a", "=", "np", ".", "arange", "(", "24", ")", ".", "reshape", "(", "(", "1", ",", "4", ",", "3", ",", "2", ")", ")", "\n", "shouldbe", "=", "np", ".", "concatenate", "(", "[", "a", "]", "*", "3", ",", "axis", "=", "-", "2", ")", "\n", "result", "=", "self", ".", "evaluate", "(", "relational_layers", ".", "repeat", "(", "tf", ".", "constant", "(", "a", ")", ",", "3", ",", "axis", "=", "-", "2", ")", ")", "\n", "self", ".", "assertAllClose", "(", "shouldbe", ",", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers_test.RelationalLayersTest.test_pairwise_edge_embeddings_for_tensor": [[44, 50], ["numpy.array", "numpy.array", "disentanglement_lib.evaluation.abstract_reasoning.relational_layers.PairwiseEdgeEmbeddings", "relational_layers_test.RelationalLayersTest.evaluate", "relational_layers_test.RelationalLayersTest.assertAllClose", "disentanglement_lib.evaluation.abstract_reasoning.relational_layers.PairwiseEdgeEmbeddings.", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate.evaluate"], ["", "def", "test_pairwise_edge_embeddings_for_tensor", "(", "self", ")", ":", "\n", "    ", "a", "=", "np", ".", "array", "(", "[", "[", "[", "1", "]", ",", "[", "2", "]", "]", "]", ")", "\n", "shouldbe", "=", "np", ".", "array", "(", "[", "[", "[", "[", "1", ",", "1", "]", ",", "[", "1", ",", "2", "]", "]", ",", "[", "[", "2", ",", "1", "]", ",", "[", "2", ",", "2", "]", "]", "]", "]", ")", "\n", "layer", "=", "relational_layers", ".", "PairwiseEdgeEmbeddings", "(", ")", "\n", "result", "=", "self", ".", "evaluate", "(", "layer", "(", "tf", ".", "constant", "(", "a", ")", ")", ")", "\n", "self", ".", "assertAllClose", "(", "shouldbe", ",", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers_test.RelationalLayersTest.test_relational_layer_for_tensor": [[51, 59], ["numpy.array", "numpy.array", "disentanglement_lib.evaluation.abstract_reasoning.relational_layers.RelationalLayer", "relational_layers_test.RelationalLayersTest.evaluate", "relational_layers_test.RelationalLayersTest.assertAllClose", "tensorflow.keras.layers.Lambda", "tensorflow.keras.layers.Lambda", "disentanglement_lib.evaluation.abstract_reasoning.relational_layers.RelationalLayer.", "tensorflow.constant", "tensorflow.reduce_sum"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate.evaluate"], ["", "def", "test_relational_layer_for_tensor", "(", "self", ")", ":", "\n", "    ", "a", "=", "np", ".", "array", "(", "[", "[", "[", "1", "]", ",", "[", "2", "]", "]", "]", ")", "\n", "shouldbe", "=", "np", ".", "array", "(", "[", "[", "[", "2", ",", "3", "]", ",", "[", "4", ",", "3", "]", "]", "]", ")", "\n", "layer", "=", "relational_layers", ".", "RelationalLayer", "(", "\n", "tf", ".", "keras", ".", "layers", ".", "Lambda", "(", "lambda", "x", ":", "x", ")", ",", "\n", "tf", ".", "keras", ".", "layers", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "reduce_sum", "(", "x", ",", "axis", "=", "-", "2", ")", ")", ")", "\n", "result", "=", "self", ".", "evaluate", "(", "layer", "(", "tf", ".", "constant", "(", "a", ")", ")", ")", "\n", "self", ".", "assertAllClose", "(", "shouldbe", ",", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers_test.RelationalLayersTest.test_positional_encoding_like_for_static_shape_tensor": [[60, 67], ["relational_layers_test._create_positional_encoding_matrices", "tensorflow.constant", "disentanglement_lib.evaluation.abstract_reasoning.relational_layers.positional_encoding_like", "relational_layers_test.RelationalLayersTest.evaluate", "relational_layers_test.RelationalLayersTest.assertEqual", "relational_layers_test.RelationalLayersTest.assertAllClose"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers_test._create_positional_encoding_matrices", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.positional_encoding_like", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate.evaluate"], ["", "def", "test_positional_encoding_like_for_static_shape_tensor", "(", "self", ")", ":", "\n", "    ", "value", ",", "shouldbe", "=", "_create_positional_encoding_matrices", "(", ")", "\n", "a", "=", "tf", ".", "constant", "(", "value", ")", "\n", "output_tensor", "=", "relational_layers", ".", "positional_encoding_like", "(", "a", ",", "-", "3", ",", "-", "2", ")", "\n", "result", "=", "self", ".", "evaluate", "(", "output_tensor", ")", "\n", "self", ".", "assertEqual", "(", "(", "1", ",", "4", ",", "4", ",", "2", ")", ",", "result", ".", "shape", ")", "\n", "self", ".", "assertAllClose", "(", "shouldbe", ",", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers_test.RelationalLayersTest.test_positional_encoding_like_for_dynamic_shape_tensor": [[68, 78], ["relational_layers_test._create_positional_encoding_matrices", "tensorflow.placeholder", "disentanglement_lib.evaluation.abstract_reasoning.relational_layers.positional_encoding_like", "relational_layers_test.RelationalLayersTest.assertEqual", "relational_layers_test.RelationalLayersTest.assertAllClose", "disentanglement_lib.evaluation.abstract_reasoning.relational_layers.positional_encoding_like.get_shape().as_list", "relational_layers_test.RelationalLayersTest.session", "sess.run", "disentanglement_lib.evaluation.abstract_reasoning.relational_layers.positional_encoding_like.get_shape"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers_test._create_positional_encoding_matrices", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.positional_encoding_like"], ["", "def", "test_positional_encoding_like_for_dynamic_shape_tensor", "(", "self", ")", ":", "\n", "    ", "value", ",", "shouldbe", "=", "_create_positional_encoding_matrices", "(", ")", "\n", "a", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "4", ",", "3", ",", "2", ")", ")", "\n", "output_tensor", "=", "relational_layers", ".", "positional_encoding_like", "(", "a", ",", "-", "3", ",", "-", "2", ")", "\n", "# Check the static shape.", "\n", "self", ".", "assertEqual", "(", "[", "None", ",", "4", ",", "4", ",", "2", "]", ",", "output_tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "# Check the solution.", "\n", "with", "self", ".", "session", "(", ")", "as", "sess", ":", "\n", "      ", "result", "=", "sess", ".", "run", "(", "output_tensor", ",", "feed_dict", "=", "{", "a", ":", "value", "}", ")", "\n", "", "self", ".", "assertAllClose", "(", "shouldbe", ",", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers_test.RelationalLayersTest.test_add_positional_encoding_layer_for_tensor": [[79, 86], ["relational_layers_test._create_positional_encoding_matrices", "numpy.concatenate", "tensorflow.constant", "relational_layers_test.RelationalLayersTest.evaluate", "relational_layers_test.RelationalLayersTest.assertAllClose", "disentanglement_lib.evaluation.abstract_reasoning.relational_layers.AddPositionalEncoding"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers_test._create_positional_encoding_matrices", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate.evaluate"], ["", "def", "test_add_positional_encoding_layer_for_tensor", "(", "self", ")", ":", "\n", "    ", "value", ",", "shouldbe_positional", "=", "_create_positional_encoding_matrices", "(", ")", "\n", "shouldbe", "=", "np", ".", "concatenate", "(", "[", "value", ",", "shouldbe_positional", "]", ",", "axis", "=", "-", "2", ")", "\n", "a", "=", "tf", ".", "constant", "(", "value", ")", "\n", "output_tensor", "=", "relational_layers", ".", "AddPositionalEncoding", "(", "-", "3", ",", "-", "2", ")", "(", "a", ")", "\n", "result", "=", "self", ".", "evaluate", "(", "output_tensor", ")", "\n", "self", ".", "assertAllClose", "(", "shouldbe", ",", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers_test.RelationalLayersTest.test_stack_answers_for_tensors": [[87, 102], ["numpy.arange().reshape", "numpy.arange().reshape", "range", "numpy.stack", "disentanglement_lib.evaluation.abstract_reasoning.relational_layers.StackAnswers", "relational_layers_test.RelationalLayersTest.evaluate", "relational_layers_test.RelationalLayersTest.assertAllClose", "results.append", "disentanglement_lib.evaluation.abstract_reasoning.relational_layers.StackAnswers.", "numpy.arange", "numpy.arange", "numpy.concatenate", "tensorflow.constant", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate.evaluate"], ["", "def", "test_stack_answers_for_tensors", "(", "self", ")", ":", "\n", "# Tensors used for testing.", "\n", "    ", "context", "=", "np", ".", "arange", "(", "24", ")", ".", "reshape", "(", "(", "2", ",", "3", ",", "4", ")", ")", "\n", "answers", "=", "np", ".", "arange", "(", "24", ",", "48", ")", ".", "reshape", "(", "(", "2", ",", "3", ",", "4", ")", ")", "\n", "# Compute the correct solutions.", "\n", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "answers", ".", "shape", "[", "-", "1", "]", ")", ":", "\n", "      ", "results", ".", "append", "(", "\n", "np", ".", "concatenate", "(", "[", "context", ",", "answers", "[", ":", ",", ":", ",", "i", ":", "(", "i", "+", "1", ")", "]", "]", ",", "axis", "=", "-", "1", ")", ")", "\n", "", "shouldbe", "=", "np", ".", "stack", "(", "results", ",", "axis", "=", "-", "2", ")", "\n", "# Compute the solution based on the layer.", "\n", "layer", "=", "relational_layers", ".", "StackAnswers", "(", "answer_axis", "=", "-", "1", ",", "stack_axis", "=", "-", "2", ")", "\n", "result", "=", "self", ".", "evaluate", "(", "layer", "(", "[", "tf", ".", "constant", "(", "context", ")", ",", "tf", ".", "constant", "(", "answers", ")", "]", ")", ")", "\n", "# Check that they are the same.", "\n", "self", ".", "assertAllClose", "(", "shouldbe", ",", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers_test.RelationalLayersTest.test_multi_dim_batch_apply_for_tensors": [[103, 116], ["numpy.arange().reshape", "numpy.arange().reshape", "numpy.matmul", "disentanglement_lib.evaluation.abstract_reasoning.relational_layers.MultiDimBatchApply", "relational_layers_test.RelationalLayersTest.evaluate", "relational_layers_test.RelationalLayersTest.assertAllClose", "tensorflow.keras.layers.Lambda", "disentanglement_lib.evaluation.abstract_reasoning.relational_layers.MultiDimBatchApply.", "numpy.arange", "numpy.arange", "tensorflow.constant", "tensorflow.matmul", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate.evaluate"], ["", "def", "test_multi_dim_batch_apply_for_tensors", "(", "self", ")", ":", "\n", "# Tensors used for testing.", "\n", "    ", "input_tensor", "=", "np", ".", "arange", "(", "24", ")", ".", "reshape", "(", "(", "2", ",", "3", ",", "4", ")", ")", "\n", "kernel", "=", "np", ".", "arange", "(", "24", ",", "36", ")", ".", "reshape", "(", "(", "4", ",", "3", ")", ")", "\n", "# Compute the correct solutions.", "\n", "shouldbe", "=", "np", ".", "matmul", "(", "input_tensor", ",", "kernel", ")", "\n", "# Compute the solution based on the layer.", "\n", "layer", "=", "relational_layers", ".", "MultiDimBatchApply", "(", "\n", "tf", ".", "keras", ".", "layers", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "matmul", "(", "x", ",", "tf", ".", "constant", "(", "kernel", ")", ")", ")", ",", "\n", "num_dims_to_keep", "=", "1", ")", "\n", "result", "=", "self", ".", "evaluate", "(", "layer", "(", "tf", ".", "constant", "(", "input_tensor", ")", ")", ")", "\n", "# Check that they are the same.", "\n", "self", ".", "assertAllClose", "(", "shouldbe", ",", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers_test._create_positional_encoding_matrices": [[27, 34], ["numpy.arange().reshape", "numpy.eye", "numpy.repeat", "numpy.expand_dims", "numpy.expand_dims", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.repeat"], ["def", "_create_positional_encoding_matrices", "(", ")", ":", "\n", "  ", "\"\"\"Shared input/output pair for the positional encoding tests.\"\"\"", "\n", "input_array", "=", "np", ".", "arange", "(", "24", ",", "dtype", "=", "np", ".", "float64", ")", ".", "reshape", "(", "(", "1", ",", "4", ",", "3", ",", "2", ")", ")", "\n", "output_array", "=", "np", ".", "eye", "(", "4", ")", "\n", "output_array", "=", "np", ".", "repeat", "(", "np", ".", "expand_dims", "(", "output_array", ",", "-", "1", ")", ",", "2", ",", "axis", "=", "-", "1", ")", "\n", "output_array", "=", "np", ".", "expand_dims", "(", "output_array", ",", "0", ")", "\n", "return", "input_array", ",", "output_array", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMDataset.__init__": [[93, 108], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "ground_truth_data", ",", "sampling_strategy", ",", "relations_dist", ")", ":", "\n", "    ", "\"\"\"Creates a PGMDataset.\n\n    Args:\n      ground_truth_data: GroundTruthData data set used to generate images.\n      sampling_strategy: Either `easy` or `hard`. For `easy`, alternative\n        answers are random other solutions that do not satisfy the constraints\n        in the given PGM. For `hard`, alternative answers are unique random\n        modifications of the correct solution which makes the task  harder.\n      relations_dist: List with probabilites where the i-th element contains the\n        probability that i relations are enforced.\n    \"\"\"", "\n", "self", ".", "ground_truth_data", "=", "ground_truth_data", "\n", "self", ".", "relations_dist", "=", "relations_dist", "\n", "self", ".", "sampling_strategy", "=", "sampling_strategy", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMDataset.sample": [[109, 139], ["disentanglement_lib.evaluation.abstract_reasoning.pgm_utils.PGM", "pgm_data.PGMDataset.ground_truth_data.sample_observations_from_factors", "random_state.choice", "pgm_data.PGMInstance", "random_state.choice", "solution.append", "numpy.array", "len", "pgm_data.PGMDataset.ground_truth_data.sample_observations_from_factors"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors"], ["", "def", "sample", "(", "self", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Returns a random PGMInstance.\"\"\"", "\n", "\n", "# Sample the number of relations.", "\n", "num_relations", "=", "1", "+", "random_state", ".", "choice", "(", "\n", "len", "(", "self", ".", "relations_dist", ")", ",", "p", "=", "self", ".", "relations_dist", ")", "\n", "\n", "# Construct the PGM solution in the space of ground-truth factors.", "\n", "pgm", "=", "pgm_utils", ".", "PGM", "(", "\n", "random_state", ",", "\n", "num_relations", ",", "\n", "self", ".", "ground_truth_data", ".", "factors_num_values", ",", "\n", ")", "\n", "\n", "# Sample instances of the images for the solutions and alternative answers.", "\n", "solution", "=", "[", "]", "\n", "for", "row", "in", "pgm", ".", "matrix", ":", "\n", "      ", "solution", ".", "append", "(", "\n", "self", ".", "ground_truth_data", ".", "sample_observations_from_factors", "(", "\n", "row", ",", "random_state", ")", ")", "\n", "\n", "", "alternatives", "=", "self", ".", "ground_truth_data", ".", "sample_observations_from_factors", "(", "\n", "pgm", ".", "other_solutions", ",", "random_state", ")", "\n", "\n", "# Sample the position of the correct answer.", "\n", "position", "=", "random_state", ".", "choice", "(", "alternatives", ".", "shape", "[", "0", "]", "+", "1", ")", "\n", "# Return the instance.", "\n", "return", "PGMInstance", "(", "\n", "np", ".", "array", "(", "solution", ")", ",", "alternatives", ",", "position", ",", "pgm", ".", "matrix", ",", "\n", "pgm", ".", "other_solutions", ",", "self", ".", "ground_truth_data", ".", "factors_num_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMDataset.tf_data_set": [[140, 166], ["pgm_data.PGMDataset.sample().training_sample", "tensorflow.data.Dataset.from_generator", "numpy.random.RandomState", "tensorflow.TensorShape", "pgm_data.PGMDataset.sample", "pgm_data.PGMDataset.sample", "features.items", "features.items", "pgm_data.PGMDataset.training_sample", "numpy.random.RandomState"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.training_sample", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.NonActiveRelation.sample", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.NonActiveRelation.sample", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.training_sample"], ["", "def", "tf_data_set", "(", "self", ",", "seed", ")", ":", "\n", "    ", "\"\"\"Returns a tf.data.Dataset.\n\n    Args:\n      seed: Integer with the random seed used to initialize the data set.\n\n    Returns.\n      tf.data.Dataset of the data set.\n    \"\"\"", "\n", "\n", "def", "generator", "(", ")", ":", "\n", "# We need to hard code the random seed so that the data set can be reset.", "\n", "      ", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "seed", ")", "\n", "while", "True", ":", "\n", "        ", "instance", "=", "self", ".", "sample", "(", "random_state", ")", "\n", "yield", "instance", ".", "training_sample", "(", ")", "\n", "\n", "# We sample a single example to obtain the actual shapes and dtypes.", "\n", "", "", "features", ",", "_", "=", "self", ".", "sample", "(", "np", ".", "random", ".", "RandomState", "(", "0", ")", ")", ".", "training_sample", "(", ")", "\n", "features_shapes", "=", "{", "k", ":", "v", ".", "shape", "for", "k", ",", "v", "in", "features", ".", "items", "(", ")", "}", "\n", "features_types", "=", "{", "k", ":", "v", ".", "dtype", "for", "k", ",", "v", "in", "features", ".", "items", "(", ")", "}", "\n", "output_shapes", "=", "(", "features_shapes", ",", "tf", ".", "TensorShape", "(", "[", "]", ")", ")", "\n", "output_types", "=", "(", "features_types", ",", "tf", ".", "int64", ")", "\n", "\n", "return", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "\n", "generator", ",", "output_types", "=", "output_types", ",", "output_shapes", "=", "output_shapes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMDataset.make_input_fn": [[167, 182], ["pgm_data.PGMDataset.tf_data_set", "dataset.take.take.batch", "dataset.take.take.make_one_shot_iterator().get_next", "dataset.take.take.take", "dataset.take.take.make_one_shot_iterator"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMDataset.tf_data_set"], ["", "def", "make_input_fn", "(", "self", ",", "seed", ",", "num_batches", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates an input function for the TPU Estimator.\"\"\"", "\n", "\n", "def", "input_fn", "(", "params", ")", ":", "\n", "      ", "\"\"\"TPUEstimator compatible input fuction.\"\"\"", "\n", "dataset", "=", "self", ".", "tf_data_set", "(", "seed", ")", "\n", "batch_size", "=", "params", "[", "\"batch_size\"", "]", "\n", "# We need to drop the remainder as otherwise we lose the batch size in the", "\n", "# tensor shape. This has no effect as our data set is infinite.", "\n", "dataset", "=", "dataset", ".", "batch", "(", "batch_size", ",", "drop_remainder", "=", "True", ")", "\n", "if", "num_batches", "is", "not", "None", ":", "\n", "        ", "dataset", "=", "dataset", ".", "take", "(", "num_batches", ")", "\n", "", "return", "dataset", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "\n", "", "return", "input_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.__init__": [[187, 214], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "solution", ",", "\n", "alternatives", ",", "\n", "position", ",", "\n", "solution_factors", "=", "None", ",", "\n", "alternatives_factors", "=", "None", ",", "\n", "num_factor_values", "=", "None", ")", ":", "\n", "    ", "\"\"\"Constructs a PGMInstance.\n\n    Args:\n      solution: Numpy array of shape (num_rows, num_cols, width, height,\n        channels) with the images of the PGM solution.\n      alternatives: Numpy array of shape (num_alternatives, width, height,\n        channels) with the images of the alternatives.\n      position: Integer with position where solution should be inserted.\n      solution_factors: Numpy array of shape (num_rows, num_cols, num_factors)\n        with the factors of the PGM solution.\n      alternatives_factors: Numpy array of shape (num_alternatives, num_factors)\n        with the images of the alternatives.\n      num_factor_values: List with the number of values for each factor.\n    \"\"\"", "\n", "self", ".", "solution", "=", "solution", "\n", "self", ".", "alternatives", "=", "alternatives", "\n", "self", ".", "position", "=", "position", "\n", "self", ".", "solution_factors", "=", "solution_factors", "\n", "self", ".", "alternatives_factors", "=", "alternatives_factors", "\n", "self", ".", "num_factor_values", "=", "num_factor_values", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.get_context": [[215, 225], ["numpy.array", "list"], "methods", ["None"], ["", "def", "get_context", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns the context.\n\n    Returns:\n      Numpy array of shape (num_rows*num_cols - 1, width, height, channels).\n    \"\"\"", "\n", "context", "=", "[", "]", "\n", "for", "row", "in", "self", ".", "solution", ":", "\n", "      ", "context", "+=", "list", "(", "row", ")", "\n", "", "return", "np", ".", "array", "(", "context", "[", ":", "-", "1", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.get_answers": [[226, 235], ["list", "list.insert", "numpy.array"], "methods", ["None"], ["", "def", "get_answers", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns the answers.\n\n    Returns:\n      Numpy array of shape (num_alternatives + 1, width, height, channels).\n    \"\"\"", "\n", "result", "=", "list", "(", "self", ".", "alternatives", ")", "\n", "result", ".", "insert", "(", "self", ".", "position", ",", "self", ".", "solution", "[", "-", "1", ",", "-", "1", "]", ")", "\n", "return", "np", ".", "array", "(", "result", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.get_context_factor_values": [[236, 246], ["numpy.array", "list"], "methods", ["None"], ["", "def", "get_context_factor_values", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns the context ground truth factos as integer values.\n\n    Returns:\n      Numpy array of shape (num_rows*num_cols - 1, len(num_factor_values).\n    \"\"\"", "\n", "context", "=", "[", "]", "\n", "for", "row", "in", "self", ".", "solution_factors", ":", "\n", "      ", "context", "+=", "list", "(", "row", ")", "\n", "", "return", "np", ".", "array", "(", "context", "[", ":", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.get_answers_factor_values": [[247, 256], ["list", "list.insert", "numpy.array"], "methods", ["None"], ["", "def", "get_answers_factor_values", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns the answers ground truth factos as integer values.\n\n    Returns:\n      Numpy array of shape (num_alternatives + 1, len(num_factor_values).\n    \"\"\"", "\n", "result", "=", "list", "(", "self", ".", "alternatives_factors", ")", "\n", "result", ".", "insert", "(", "self", ".", "position", ",", "self", ".", "solution_factors", "[", "-", "1", ",", "-", "1", "]", ")", "\n", "return", "np", ".", "array", "(", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.range_embed_factors": [[257, 270], ["numpy.array", "numpy.expand_dims", "numpy.array"], "methods", ["None"], ["", "def", "range_embed_factors", "(", "self", ",", "factors", ")", ":", "\n", "    ", "\"\"\"Embeds the factors linearly in [-0.5, 0.5] based on integer values.\n\n    Args:\n      factors: Numpy array of shape (:, len(num_factor_values) with factors.\n\n    Returns:\n      Numpy array of shape (:, len(num_factor_values) with floats.\n    \"\"\"", "\n", "result", "=", "np", ".", "array", "(", "factors", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "max_vals", "=", "np", ".", "array", "(", "self", ".", "num_factor_values", ",", "dtype", "=", "np", ".", "float32", ")", "-", "1.", "\n", "result", "/=", "np", ".", "expand_dims", "(", "max_vals", ",", "0", ")", "\n", "return", "result", "-", ".5", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.onehot_embed_factors": [[271, 284], ["enumerate", "numpy.array", "result.append", "numpy.concatenate", "pgm_data.onehot"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.onehot"], ["", "def", "onehot_embed_factors", "(", "self", ",", "factors", ")", ":", "\n", "    ", "\"\"\"Embeds the factors as one-hot vectors.\n\n    Args:\n      factors: Numpy array of shape (:, len(num_factor_values) with factors.\n\n    Returns:\n      Numpy array of shape (:, sum(num_factor_values) with floats.\n    \"\"\"", "\n", "result", "=", "[", "]", "\n", "for", "i", ",", "num", "in", "enumerate", "(", "self", ".", "num_factor_values", ")", ":", "\n", "      ", "result", ".", "append", "(", "onehot", "(", "factors", "[", ":", ",", "i", "]", ",", "num", ")", ")", "\n", "", "return", "np", ".", "array", "(", "np", ".", "concatenate", "(", "result", ",", "axis", "=", "-", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.training_sample": [[285, 303], ["pgm_data.PGMInstance.get_context", "pgm_data.PGMInstance.get_answers", "pgm_data.PGMInstance.get_context_factor_values", "pgm_data.PGMInstance.get_answers_factor_values", "pgm_data.PGMInstance.range_embed_factors", "pgm_data.PGMInstance.range_embed_factors", "pgm_data.PGMInstance.onehot_embed_factors", "pgm_data.PGMInstance.onehot_embed_factors"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.get_context", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.get_answers", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.get_context_factor_values", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.get_answers_factor_values", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.range_embed_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.range_embed_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.onehot_embed_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.onehot_embed_factors"], ["", "def", "training_sample", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns a single training example.\"\"\"", "\n", "sample", "=", "{", "}", "\n", "sample", "[", "\"context\"", "]", "=", "self", ".", "get_context", "(", ")", "\n", "sample", "[", "\"answers\"", "]", "=", "self", ".", "get_answers", "(", ")", "\n", "if", "self", ".", "solution_factors", "is", "not", "None", ":", "\n", "      ", "context_factors", "=", "self", ".", "get_context_factor_values", "(", ")", "\n", "answers_factors", "=", "self", ".", "get_answers_factor_values", "(", ")", "\n", "\n", "sample", "[", "\"context_factor_values\"", "]", "=", "self", ".", "range_embed_factors", "(", "\n", "context_factors", ")", "\n", "sample", "[", "\"answers_factor_values\"", "]", "=", "self", ".", "range_embed_factors", "(", "\n", "answers_factors", ")", "\n", "sample", "[", "\"context_factors_onehot\"", "]", "=", "self", ".", "onehot_embed_factors", "(", "\n", "context_factors", ")", "\n", "sample", "[", "\"answers_factors_onehot\"", "]", "=", "self", ".", "onehot_embed_factors", "(", "\n", "answers_factors", ")", "\n", "", "return", "sample", ",", "self", ".", "position", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.make_image": [[304, 348], ["numpy.copy", "range", "disentanglement_lib.visualize.visualize_util.padded_stack", "numpy.zeros", "pgm_data.PGMInstance.get_answers", "enumerate", "disentanglement_lib.visualize.visualize_util.padded_grid", "disentanglement_lib.visualize.visualize_util.padded_stack", "disentanglement_lib.visualize.visualize_util.pad_around", "numpy.repeat", "pgm_data.question_mark", "range", "rows.append", "numpy.repeat", "numpy.array", "answers_with_border.append", "disentanglement_lib.visualize.visualize_util.add_below", "numpy.array", "row.append", "disentanglement_lib.visualize.visualize_util.padded_stack", "disentanglement_lib.visualize.visualize_util.pad_around", "disentanglement_lib.visualize.visualize_util.pad_around"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.padded_stack", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.PGMInstance.get_answers", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.padded_grid", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.padded_stack", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.pad_around", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.repeat", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.question_mark", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.repeat", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.add_below", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.padded_stack", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.pad_around", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.pad_around"], ["", "def", "make_image", "(", "self", ",", "answer", "=", "False", ",", "padding_px", "=", "8", ",", "border_px", "=", "4", ")", ":", "\n", "    ", "\"\"\"Creates an image of the PGMInstance.\"\"\"", "\n", "# Create the question side that contains the progression matrix.", "\n", "question", "=", "np", ".", "copy", "(", "self", ".", "solution", ")", "\n", "if", "question", ".", "shape", "[", "-", "1", "]", "==", "1", ":", "\n", "      ", "question", "=", "np", ".", "repeat", "(", "question", ",", "3", ",", "-", "1", ")", "\n", "", "if", "not", "answer", ":", "\n", "      ", "question", "[", "-", "1", ",", "-", "1", "]", "=", "question_mark", "(", ")", "\n", "\n", "# Build up the image on the context side.", "\n", "", "rows", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "question", ".", "shape", "[", "0", "]", ")", ":", "\n", "      ", "row", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "question", ".", "shape", "[", "1", "]", ")", ":", "\n", "# Do the border around the image.", "\n", "        ", "color", "=", "np", ".", "array", "(", "[", "1.", ",", "1.", ",", "1.", "]", ")", "\n", "if", "answer", "and", "i", "==", "(", "question", ".", "shape", "[", "0", "]", "-", "1", ")", "and", "j", "==", "(", "question", ".", "shape", "[", "1", "]", "-", "\n", "1", ")", ":", "\n", "          ", "color", "=", "COLORS", "[", "\"green\"", "]", "\n", "", "row", ".", "append", "(", "\n", "visualize_util", ".", "pad_around", "(", "question", "[", "i", ",", "j", "]", ",", "border_px", ",", "value", "=", "color", ")", ")", "\n", "", "rows", ".", "append", "(", "visualize_util", ".", "padded_stack", "(", "row", ",", "padding_px", ",", "axis", "=", "1", ")", ")", "\n", "", "question_image", "=", "visualize_util", ".", "padded_stack", "(", "rows", ",", "padding_px", ")", "\n", "\n", "separator", "=", "np", ".", "zeros", "(", "(", "question_image", ".", "shape", "[", "0", "]", ",", "2", ",", "question_image", ".", "shape", "[", "2", "]", ")", ")", "\n", "\n", "# Create the answer side.", "\n", "answers", "=", "self", ".", "get_answers", "(", ")", "\n", "if", "answers", ".", "shape", "[", "-", "1", "]", "==", "1", ":", "\n", "      ", "answers", "=", "np", ".", "repeat", "(", "answers", ",", "3", ",", "-", "1", ")", "\n", "", "answers_with_border", "=", "[", "]", "\n", "for", "i", ",", "image", "in", "enumerate", "(", "answers", ")", ":", "\n", "      ", "color", "=", "np", ".", "array", "(", "[", "1.", ",", "1.", ",", "1.", "]", ")", "\n", "if", "answer", ":", "\n", "        ", "color", "=", "COLORS", "[", "\"green\"", "]", "if", "i", "==", "self", ".", "position", "else", "COLORS", "[", "\"red\"", "]", "\n", "", "answers_with_border", ".", "append", "(", "\n", "visualize_util", ".", "pad_around", "(", "image", ",", "border_px", ",", "value", "=", "color", ")", ")", "\n", "\n", "", "answer_image", "=", "visualize_util", ".", "padded_grid", "(", "answers_with_border", ",", "\n", "question", ".", "shape", "[", "0", "]", ",", "padding_px", ")", "\n", "center_crop", "=", "visualize_util", ".", "padded_stack", "(", "\n", "[", "question_image", ",", "separator", ",", "answer_image", "]", ",", "padding_px", ",", "axis", "=", "1", ")", "\n", "return", "visualize_util", ".", "pad_around", "(", "\n", "visualize_util", ".", "add_below", "(", "center_crop", ",", "padding_px", ")", ",", "padding_px", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.__init__": [[353, 363], ["list", "numpy.minimum"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "wrapped_ground_truth_data", ",", "max_factors", ")", ":", "\n", "    ", "\"\"\"Constructs a Quantizer.\n\n    Args:\n      wrapped_ground_truth_data: GroundTruthData that should be quantized.\n      max_factors: integer with the maximal number of factors.\n    \"\"\"", "\n", "self", ".", "wrapped_ground_truth_data", "=", "wrapped_ground_truth_data", "\n", "self", ".", "true_num_factors", "=", "wrapped_ground_truth_data", ".", "factors_num_values", "\n", "self", ".", "fake_num_factors", "=", "list", "(", "np", ".", "minimum", "(", "self", ".", "true_num_factors", ",", "max_factors", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.num_factors": [[364, 367], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_factors", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "wrapped_ground_truth_data", ".", "num_factors", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.factors_num_values": [[368, 371], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "factors_num_values", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "fake_num_factors", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.observation_shape": [[372, 375], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "observation_shape", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "wrapped_ground_truth_data", ".", "observation_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_factors": [[376, 382], ["numpy.zeros", "range", "pgm_data.Quantizer._sample_factor"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer._sample_factor"], ["", "def", "sample_factors", "(", "self", ",", "num", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a batch of factors Y.\"\"\"", "\n", "factors", "=", "np", ".", "zeros", "(", "shape", "=", "(", "num", ",", "self", ".", "num_factors", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_factors", ")", ":", "\n", "      ", "factors", "[", ":", ",", "i", "]", "=", "self", ".", "_sample_factor", "(", "i", ",", "num", ",", "random_state", ")", "\n", "", "return", "factors", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer._sample_factor": [[383, 385], ["random_state.randint"], "methods", ["None"], ["", "def", "_sample_factor", "(", "self", ",", "i", ",", "num", ",", "random_state", ")", ":", "\n", "    ", "return", "random_state", ".", "randint", "(", "self", ".", "factor_sizes", "[", "i", "]", ",", "size", "=", "num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors": [[386, 396], ["numpy.copy", "range", "pgm_data.Quantizer.wrapped_ground_truth_data.sample_observations_from_factors", "numpy.floor", "float", "float"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors"], ["", "def", "sample_observations_from_factors", "(", "self", ",", "factors", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a batch of observations X given a batch of factors Y.\"\"\"", "\n", "translated_factors", "=", "np", ".", "copy", "(", "factors", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_factors", ")", ":", "\n", "      ", "if", "self", ".", "true_num_factors", "[", "i", "]", "!=", "self", ".", "fake_num_factors", "[", "i", "]", ":", "\n", "        ", "ratio", "=", "float", "(", "self", ".", "true_num_factors", "[", "i", "]", ")", "/", "float", "(", "\n", "self", ".", "fake_num_factors", "[", "i", "]", ")", "\n", "translated_factors", "[", ":", ",", "i", "]", "=", "np", ".", "floor", "(", "factors", "[", ":", ",", "i", "]", "*", "ratio", ")", "\n", "", "", "return", "self", ".", "wrapped_ground_truth_data", ".", "sample_observations_from_factors", "(", "\n", "translated_factors", ",", "random_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.get_pgm_dataset": [[38, 88], ["gin.configurable", "disentanglement_lib.data.ground_truth.named_data.get_named_ground_truth_data", "isinstance", "pgm_type.startswith", "pgm_type.endswith", "pgm_data.PGMDataset", "pgm_data.Quantizer", "isinstance", "pgm_type.startswith", "pgm_type.endswith", "pgm_data.Quantizer", "isinstance", "ValueError", "pgm_type.endswith", "ValueError", "pgm_type.endswith", "ValueError"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.named_data.get_named_ground_truth_data"], ["@", "gin", ".", "configurable", "(", "\"pgm\"", ")", "\n", "def", "get_pgm_dataset", "(", "pgm_type", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "  ", "\"\"\"Returns a named PGM data set.\"\"\"", "\n", "ground_truth_data", "=", "named_data", ".", "get_named_ground_truth_data", "(", ")", "\n", "\n", "# Quantization for specific data sets (as described in", "\n", "# https://arxiv.org/abs/1905.12506).", "\n", "if", "isinstance", "(", "ground_truth_data", ",", "dsprites", ".", "AbstractDSprites", ")", ":", "\n", "    ", "wrapped_data_set", "=", "Quantizer", "(", "ground_truth_data", ",", "[", "5", ",", "6", ",", "3", ",", "3", ",", "4", ",", "4", "]", ")", "\n", "", "elif", "isinstance", "(", "ground_truth_data", ",", "shapes3d", ".", "Shapes3D", ")", ":", "\n", "    ", "wrapped_data_set", "=", "Quantizer", "(", "ground_truth_data", ",", "[", "10", ",", "10", ",", "10", ",", "4", ",", "4", ",", "4", "]", ")", "\n", "", "elif", "isinstance", "(", "ground_truth_data", ",", "dummy_data", ".", "DummyData", ")", ":", "\n", "    ", "wrapped_data_set", "=", "ground_truth_data", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"Invalid data set.\"", ")", "\n", "\n", "# We support different ways to generate PGMs for each of the data set (e.g.,", "\n", "# `easy_1`, `hard_3`, `easy_mixes`). `easy` and `hard` refers to the way the", "\n", "# alternative solutions of the PGMs are generated:", "\n", "#   - `easy`: Alternative answers are random other solutions that do not", "\n", "#             satisfy the constraints in the given PGM.", "\n", "#   - `hard`: Alternative answers are unique random modifications of the", "\n", "#             correct solution which makes the task substantially harder.", "\n", "", "if", "pgm_type", ".", "startswith", "(", "\"easy\"", ")", ":", "\n", "    ", "sampling", "=", "\"easy\"", "\n", "", "elif", "pgm_type", ".", "startswith", "(", "\"hard\"", ")", ":", "\n", "    ", "sampling", "=", "\"hard\"", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"Invalid sampling strategy.\"", ")", "\n", "\n", "# The suffix determines how many relations there are:", "\n", "#   - 1-3: Specifies whether always 1, 2, or 3 relations are constant in each", "\n", "#          row.", "\n", "#   - `mixed`: With probability 1/3 each, 1, 2, or 3 relations are constant", "\n", "#               in each row.", "\n", "", "if", "pgm_type", ".", "endswith", "(", "\"1\"", ")", ":", "\n", "    ", "relations_dist", "=", "[", "1.", ",", "0.", ",", "0.", "]", "\n", "", "elif", "pgm_type", ".", "endswith", "(", "\"2\"", ")", ":", "\n", "    ", "relations_dist", "=", "[", "0.", ",", "1.", ",", "0.", "]", "\n", "", "elif", "pgm_type", ".", "endswith", "(", "\"3\"", ")", ":", "\n", "    ", "relations_dist", "=", "[", "0.", ",", "0.", ",", "1.", "]", "\n", "", "elif", "pgm_type", ".", "endswith", "(", "\"mixed\"", ")", ":", "\n", "    ", "relations_dist", "=", "[", "1.", "/", "3.", ",", "1.", "/", "3.", ",", "1.", "/", "3.", "]", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"Invalid number of relations.\"", ")", "\n", "\n", "", "return", "PGMDataset", "(", "\n", "wrapped_data_set", ",", "\n", "sampling_strategy", "=", "sampling", ",", "\n", "relations_dist", "=", "relations_dist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.question_mark": [[409, 418], ["tensorflow.gfile.Open", "disentanglement_lib.utils.resources.get_file", "numpy.array", "PIL.Image.open().convert", "PIL.Image.open"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file"], ["def", "question_mark", "(", ")", ":", "\n", "  ", "\"\"\"Returns an image of the question mark.\"\"\"", "\n", "# Cache the image so it is not always reloaded.", "\n", "if", "QUESTION_MARK", "[", "0", "]", "is", "None", ":", "\n", "    ", "with", "tf", ".", "gfile", ".", "Open", "(", "\n", "resources", ".", "get_file", "(", "\"google/abstract_reasoning/data/question_mark.png\"", ")", ",", "\n", "\"rb\"", ")", "as", "f", ":", "\n", "      ", "QUESTION_MARK", "[", "0", "]", "=", "np", ".", "array", "(", "Image", ".", "open", "(", "f", ")", ".", "convert", "(", "\"RGB\"", ")", ")", "*", "1.0", "/", "255.", "\n", "", "", "return", "QUESTION_MARK", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.onehot": [[420, 423], ["numpy.eye"], "function", ["None"], ["", "def", "onehot", "(", "indices", ",", "num_atoms", ")", ":", "\n", "  ", "\"\"\"Embeds the indices as one hot vectors.\"\"\"", "\n", "return", "np", ".", "eye", "(", "num_atoms", ")", "[", "indices", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.PGM.__init__": [[28, 69], ["pgm_utils.PGMDesign", "pgm_utils.PGM.design.sample", "range", "numpy.array", "pgm_utils.PGM.other_solutions.append", "ValueError", "sampling_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.NonActiveRelation.sample"], ["def", "__init__", "(", "self", ",", "\n", "random_state", ",", "\n", "num_relations", ",", "\n", "atom_counts", ",", "\n", "sampling_strategy", "=", "\"easy\"", ",", "\n", "num_rows", "=", "3", ",", "\n", "num_cols", "=", "3", ",", "\n", "num_solutions", "=", "6", ")", ":", "\n", "    ", "\"\"\"Creates a PGM.\n\n    Args:\n      random_state: np.random.RandomState used to sample the PGM.\n      num_relations: Number of relations to enforce for each row in the PGM.\n      atom_counts: List that contains the number of atoms for each of the\n        ground-truth factors.\n      sampling_strategy: Either `easy` or `hard`. For `easy`, alternative\n        answers are random other solutions that do not satisfy the constraints\n        in the given PGM. For `hard`, alternative answers are unique random\n        modifications of the correct solution which makes the task  harder.\n      num_rows: Integer with number of rows.\n      num_cols: Integer with number of columns.\n      num_solutions: Integer with number of solutions in the PGM.\n    \"\"\"", "\n", "if", "sampling_strategy", "==", "\"easy\"", ":", "\n", "      ", "sampling_fn", "=", "sample_easy_alternative", "\n", "", "elif", "sampling_strategy", "==", "\"hard\"", ":", "\n", "      ", "sampling_fn", "=", "sample_hard_alternative", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"Only easy and hard sampling are currently supported.\"", ")", "\n", "\n", "# Create a factory for this PGM and sample a random solution to it.", "\n", "", "self", ".", "design", "=", "PGMDesign", "(", "random_state", ",", "num_relations", ",", "atom_counts", ",", "num_rows", ",", "\n", "num_cols", ")", "\n", "self", ".", "matrix", "=", "self", ".", "design", ".", "sample", "(", ")", "\n", "\n", "# Use the sample strategy to create additional wrong solutions.", "\n", "self", ".", "other_solutions", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "num_solutions", "-", "1", ")", ":", "\n", "      ", "self", ".", "other_solutions", ".", "append", "(", "\n", "sampling_fn", "(", "self", ".", "design", ",", "self", ".", "matrix", ",", "self", ".", "other_solutions", ")", ")", "\n", "", "self", ".", "other_solutions", "=", "np", ".", "array", "(", "self", ".", "other_solutions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.PGM.print_pgm": [[70, 80], ["range", "print", "print", "print", "print", "print", "print", "print"], "methods", ["None"], ["", "def", "print_pgm", "(", "self", ")", ":", "\n", "    ", "\"\"\"Prints the PGM to stdout.\"\"\"", "\n", "for", "i", "in", "range", "(", "self", ".", "matrix", ".", "shape", "[", "2", "]", ")", ":", "\n", "      ", "print", "(", "\"---\"", ")", "\n", "print", "(", "\"Factor %d\"", "%", "i", ")", "\n", "print", "(", "\"---\"", ")", "\n", "print", "(", "\"Solution:\"", ")", "\n", "print", "(", "self", ".", "matrix", "[", ":", ",", ":", ",", "i", "]", ")", "\n", "print", "(", "\"Alternatives:\"", ")", "\n", "print", "(", "self", ".", "other_solutions", "[", ":", ",", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.PGMDesign.__init__": [[85, 125], ["len", "list", "range", "enumerate", "ValueError", "range", "list.pop", "pgm_utils.PGMDesign.active_relations.append", "random_state.choice", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "random_state", ",", "\n", "num_relations", ",", "\n", "atom_counts", ",", "\n", "num_rows", "=", "3", ",", "\n", "num_cols", "=", "3", ")", ":", "\n", "    ", "\"\"\"Creates a PGMDesign.\n\n    Args:\n      random_state: np.random.RandomState used to sample the PGM.\n      num_relations: Number of relations to enforce for each row in the PGM.\n      atom_counts: List that contains the number of atoms for each of the\n        ground-truth factors.\n      num_rows: Integer with number of rows.\n      num_cols: Integer with number of columns.\n    \"\"\"", "\n", "self", ".", "random_state", "=", "random_state", "\n", "self", ".", "num_relations", "=", "num_relations", "\n", "self", ".", "atom_counts", "=", "atom_counts", "\n", "self", ".", "num_rows", "=", "num_rows", "\n", "self", ".", "num_cols", "=", "num_cols", "\n", "\n", "# Setup list to keep the relations for each of the factors. By default,", "\n", "# each factor has no active relation.", "\n", "self", ".", "relations", "=", "[", "NonActiveRelation", "for", "_", "in", "atom_counts", "]", "\n", "\n", "# Randomly sample factors where all factors will be the same across rows.", "\n", "self", ".", "num_factors", "=", "len", "(", "atom_counts", ")", "\n", "if", "self", ".", "num_factors", "<", "num_relations", ":", "\n", "      ", "raise", "ValueError", "(", "\"Cannot have less factors than relations.\"", ")", "\n", "", "indices", "=", "list", "(", "range", "(", "self", ".", "num_factors", ")", ")", "\n", "self", ".", "active_relations", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "num_relations", ")", ":", "\n", "      ", "selected_index", "=", "indices", ".", "pop", "(", "random_state", ".", "choice", "(", "len", "(", "indices", ")", ")", ")", "\n", "self", ".", "active_relations", ".", "append", "(", "selected_index", ")", "\n", "self", ".", "relations", "[", "selected_index", "]", "=", "ConstantRelation", "\n", "\n", "# Create the actual relations.", "\n", "", "for", "i", ",", "num_atoms", "in", "enumerate", "(", "atom_counts", ")", ":", "\n", "      ", "self", ".", "relations", "[", "i", "]", "=", "self", ".", "relations", "[", "i", "]", "(", "num_atoms", ",", "num_rows", ",", "num_cols", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.PGMDesign.sample": [[126, 138], ["numpy.zeros", "enumerate", "relation.sample"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.NonActiveRelation.sample"], ["", "", "def", "sample", "(", "self", ")", ":", "\n", "    ", "\"\"\"Sample the actual values of a PGM.\n\n    Returns:\n      Numpy array of type np.int64 and shape (num_rows, num_cols, num_factors)\n        with the ground-truth factor values of the PGM.\n    \"\"\"", "\n", "matrix", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_rows", ",", "self", ".", "num_cols", ",", "self", ".", "num_factors", ")", ",", "\n", "dtype", "=", "np", ".", "int64", ")", "\n", "for", "i", ",", "relation", "in", "enumerate", "(", "self", ".", "relations", ")", ":", "\n", "      ", "matrix", "[", ":", ",", ":", ",", "i", "]", "=", "relation", ".", "sample", "(", "self", ".", "random_state", ")", "\n", "", "return", "matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.PGMDesign.randomly_modify_solution": [[139, 160], ["numpy.copy", "pgm_utils.PGMDesign.random_state.choice", "pgm_utils.PGMDesign.random_state.choice", "enumerate", "pgm_utils.PGMDesign.random_state.choice"], "methods", ["None"], ["", "def", "randomly_modify_solution", "(", "self", ",", "initial_solution", ")", ":", "\n", "    ", "\"\"\"Randomly modifies solution to generate hard alternatives.\n\n    Args:\n      initial_solution: Numpy array with shape (num_rows, num_cols, num_factors)\n        with the ground-truth factor values of the original PGM.\n\n    Returns:\n      Numpy array of type np.int64 and shape (num_rows, num_cols, num_factors)\n        with the ground-truth factor values of a randomly modified PGM.\n    \"\"\"", "\n", "solution", "=", "np", ".", "copy", "(", "initial_solution", ")", "\n", "# Resample a random factor uniformly where a relation is active.", "\n", "i", "=", "self", ".", "random_state", ".", "choice", "(", "self", ".", "active_relations", ")", "\n", "relation", "=", "self", ".", "relations", "[", "i", "]", "\n", "solution", "[", "i", "]", "=", "self", ".", "random_state", ".", "choice", "(", "relation", ".", "num_atoms", ")", "\n", "# Change all the non-active relations to random values.", "\n", "for", "i", ",", "relation", "in", "enumerate", "(", "self", ".", "relations", ")", ":", "\n", "      ", "if", "i", "not", "in", "self", ".", "active_relations", ":", "\n", "        ", "solution", "[", "i", "]", "=", "self", ".", "random_state", ".", "choice", "(", "relation", ".", "num_atoms", ")", "\n", "", "", "return", "solution", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.PGMDesign.is_consistent": [[161, 167], ["enumerate", "relation.is_consistent"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.NonActiveRelation.is_consistent"], ["", "def", "is_consistent", "(", "self", ",", "matrix", ")", ":", "\n", "    ", "\"\"\"Check whether the matrix is consistent with the PGM Design.\"\"\"", "\n", "for", "i", ",", "relation", "in", "enumerate", "(", "self", ".", "relations", ")", ":", "\n", "      ", "if", "not", "relation", ".", "is_consistent", "(", "matrix", "[", ":", ",", ":", ",", "i", "]", ")", ":", "\n", "        ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.PGMDesign.resample_design": [[168, 178], ["pgm_utils.PGMDesign"], "methods", ["None"], ["", "def", "resample_design", "(", "self", ")", ":", "\n", "    ", "\"\"\"Generates an alternative design of the PGM.\n\n    This will generate a different set of active/non-active relations.\n\n    Returns:\n      PGMDesign instance with the new design.\n    \"\"\"", "\n", "return", "PGMDesign", "(", "self", ".", "random_state", ",", "self", ".", "num_relations", ",", "self", ".", "atom_counts", ",", "\n", "self", ".", "num_rows", ",", "self", ".", "num_cols", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.Relation.__init__": [[216, 224], ["ValueError", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_atoms", ",", "num_rows", "=", "3", ",", "num_cols", "=", "3", ")", ":", "\n", "    ", "if", "num_atoms", "<", "num_cols", ":", "\n", "      ", "raise", "ValueError", "(", "\"Cannot have less atoms than columns.\"", ")", "\n", "", "if", "num_atoms", "==", "1", ":", "\n", "      ", "raise", "ValueError", "(", "\"Need more than one atom.\"", ")", "\n", "", "self", ".", "num_atoms", "=", "num_atoms", "\n", "self", ".", "num_rows", "=", "num_rows", "\n", "self", ".", "num_cols", "=", "num_cols", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.Relation.is_consistent": [[225, 229], ["NotImplementedError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "is_consistent", "(", "matrix", ")", ":", "\n", "    ", "\"\"\"Checks whether the matrix satisfies the relation.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.Relation.sample": [[230, 233], ["NotImplementedError"], "methods", ["None"], ["", "def", "sample", "(", "self", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Samples a matrix consistent with the relation.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.ConstantRelation.is_consistent": [[242, 249], ["pgm_utils.is_constant_row"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.is_constant_row"], ["@", "staticmethod", "\n", "def", "is_consistent", "(", "matrix", ")", ":", "\n", "    ", "\"\"\"Checks whether the matrix satisfies the relation.\"\"\"", "\n", "for", "row", "in", "matrix", ":", "\n", "      ", "if", "not", "is_constant_row", "(", "row", ")", ":", "\n", "        ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.ConstantRelation.sample": [[250, 257], ["range", "numpy.array", "random_state.choice", "rows.append"], "methods", ["None"], ["", "def", "sample", "(", "self", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Samples a matrix consistent with the relation.\"\"\"", "\n", "rows", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "num_rows", ")", ":", "\n", "      ", "sampled_atom", "=", "random_state", ".", "choice", "(", "self", ".", "num_atoms", ")", "\n", "rows", ".", "append", "(", "[", "sampled_atom", "]", "*", "self", ".", "num_cols", ")", "\n", "", "return", "np", ".", "array", "(", "rows", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.DistinctRelation.is_consistent": [[266, 273], ["pgm_utils.is_distinct_row"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.is_distinct_row"], ["@", "staticmethod", "\n", "def", "is_consistent", "(", "matrix", ")", ":", "\n", "    ", "\"\"\"Checks whether the matrix satisfies the relation.\"\"\"", "\n", "for", "row", "in", "matrix", ":", "\n", "      ", "if", "not", "is_distinct_row", "(", "row", ")", ":", "\n", "        ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.DistinctRelation.sample": [[274, 281], ["range", "numpy.array", "random_state.permutation", "rows.append"], "methods", ["None"], ["", "def", "sample", "(", "self", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Samples a matrix consistent with the relation.\"\"\"", "\n", "rows", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "num_rows", ")", ":", "\n", "      ", "random_permutation", "=", "random_state", ".", "permutation", "(", "self", ".", "num_atoms", ")", "\n", "rows", ".", "append", "(", "random_permutation", "[", ":", "self", ".", "num_cols", "]", ")", "\n", "", "return", "np", ".", "array", "(", "rows", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.NonActiveRelation.is_consistent": [[286, 296], ["relation.is_consistent"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.NonActiveRelation.is_consistent"], ["@", "staticmethod", "\n", "def", "is_consistent", "(", "matrix", ")", ":", "\n", "    ", "\"\"\"Checks whether the matrix satisfies the relation.\"\"\"", "\n", "# We need to make sure there are no consistent relations in the rows except", "\n", "# the last ones.", "\n", "relevant_matrix", "=", "matrix", "[", ":", "-", "1", ",", ":", "]", "\n", "for", "relation", "in", "[", "ConstantRelation", ",", "DistinctRelation", "]", ":", "\n", "      ", "if", "relation", ".", "is_consistent", "(", "relevant_matrix", ")", ":", "\n", "        ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.NonActiveRelation._sample": [[297, 301], ["random_state.choice"], "methods", ["None"], ["", "def", "_sample", "(", "self", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Sample a random matrix.\"\"\"", "\n", "return", "random_state", ".", "choice", "(", "\n", "self", ".", "num_atoms", ",", "size", "=", "(", "self", ".", "num_rows", ",", "self", ".", "num_cols", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.NonActiveRelation.sample": [[302, 309], ["range", "ValueError", "pgm_utils.NonActiveRelation._sample", "pgm_utils.NonActiveRelation.is_consistent"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.NonActiveRelation._sample", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.NonActiveRelation.is_consistent"], ["", "def", "sample", "(", "self", ",", "random_state", ")", ":", "\n", "    ", "\"\"\"Samples a matrix consistent with the relation.\"\"\"", "\n", "for", "_", "in", "range", "(", "1000", ")", ":", "\n", "      ", "matrix", "=", "self", ".", "_sample", "(", "random_state", ")", "\n", "if", "self", ".", "is_consistent", "(", "matrix", ")", ":", "\n", "        ", "return", "matrix", "\n", "", "", "raise", "ValueError", "(", "\"Could not sample non-relational matrix.\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.sample_easy_alternative": [[180, 194], ["range", "ValueError", "design.resample_design().sample", "numpy.copy", "design.is_consistent", "numpy.allclose", "design.resample_design"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.NonActiveRelation.sample", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.NonActiveRelation.is_consistent", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.PGMDesign.resample_design"], ["", "", "def", "sample_easy_alternative", "(", "design", ",", "matrix", ",", "already_sampled_alternatives", ")", ":", "\n", "  ", "\"\"\"Samples easy alternative based on sampling a new PGM.\"\"\"", "\n", "for", "_", "in", "range", "(", "100", ")", ":", "\n", "    ", "alternative_pgm", "=", "design", ".", "resample_design", "(", ")", ".", "sample", "(", ")", "\n", "# Combine the solutions.", "\n", "alternative_solution", "=", "np", ".", "copy", "(", "matrix", ")", "\n", "alternative_solution", "[", "-", "1", ",", "-", "1", ",", ":", "]", "=", "alternative_pgm", "[", "-", "1", ",", "-", "1", ",", ":", "]", "\n", "if", "design", ".", "is_consistent", "(", "alternative_solution", ")", ":", "\n", "      ", "continue", "\n", "", "for", "already_sampled_alternative", "in", "already_sampled_alternatives", ":", "\n", "      ", "if", "np", ".", "allclose", "(", "already_sampled_alternative", ",", "alternative_pgm", "[", "-", "1", ",", "-", "1", ",", ":", "]", ")", ":", "\n", "        ", "continue", "\n", "", "", "return", "alternative_pgm", "[", "-", "1", ",", "-", "1", ",", ":", "]", "\n", "", "raise", "ValueError", "(", "\"Could not sample alternative solutions.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.sample_hard_alternative": [[196, 211], ["range", "ValueError", "design.randomly_modify_solution", "numpy.copy", "design.is_consistent", "numpy.allclose"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.PGMDesign.randomly_modify_solution", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.NonActiveRelation.is_consistent"], ["", "def", "sample_hard_alternative", "(", "design", ",", "matrix", ",", "already_sampled_alternatives", ")", ":", "\n", "  ", "\"\"\"Samples hard alternative based on sampling a new PGM.\"\"\"", "\n", "solution_so_far", "=", "matrix", "[", "-", "1", ",", "-", "1", "]", "\n", "for", "_", "in", "range", "(", "100", ")", ":", "\n", "    ", "solution_so_far", "=", "design", ".", "randomly_modify_solution", "(", "solution_so_far", ")", "\n", "# Combine the solutions.", "\n", "alternative_solution", "=", "np", ".", "copy", "(", "matrix", ")", "\n", "alternative_solution", "[", "-", "1", ",", "-", "1", ",", ":", "]", "=", "solution_so_far", "\n", "if", "design", ".", "is_consistent", "(", "alternative_solution", ")", ":", "\n", "      ", "continue", "\n", "", "for", "already_sampled_alternative", "in", "already_sampled_alternatives", ":", "\n", "      ", "if", "np", ".", "allclose", "(", "already_sampled_alternative", ",", "solution_so_far", ")", ":", "\n", "        ", "continue", "\n", "", "", "return", "solution_so_far", "\n", "", "raise", "ValueError", "(", "\"Could not sample hard alternative solutions.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.is_constant_row": [[235, 237], ["len", "numpy.unique"], "function", ["None"], ["", "", "def", "is_constant_row", "(", "row", ")", ":", "\n", "  ", "return", "len", "(", "np", ".", "unique", "(", "row", ")", ")", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.is_distinct_row": [[259, 261], ["len", "len", "numpy.unique"], "function", ["None"], ["", "", "def", "is_distinct_row", "(", "row", ")", ":", "\n", "  ", "return", "len", "(", "np", ".", "unique", "(", "row", ")", ")", "==", "len", "(", "row", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.factor_vae_test.FactorVaeTest.test_metric": [[28, 37], ["disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.factor_vae.compute_factor_vae", "factor_vae_test.FactorVaeTest.assertBetween", "factor_vae_test.FactorVaeTest.assertBetween"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.factor_vae.compute_factor_vae"], ["  ", "def", "test_metric", "(", "self", ")", ":", "\n", "    ", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "representation_function", "=", "lambda", "x", ":", "x", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "factor_vae", ".", "compute_factor_vae", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "5", ",", "3000", ",", "\n", "2000", ",", "2500", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"train_accuracy\"", "]", ",", "0.9", ",", "1.0", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"eval_accuracy\"", "]", ",", "0.9", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.factor_vae_test.FactorVaeTest.test_bad_metric": [[38, 47], ["disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.factor_vae.compute_factor_vae", "factor_vae_test.FactorVaeTest.assertBetween", "factor_vae_test.FactorVaeTest.assertBetween"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.factor_vae.compute_factor_vae"], ["", "def", "test_bad_metric", "(", "self", ")", ":", "\n", "    ", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "representation_function", "=", "np", ".", "zeros_like", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "factor_vae", ".", "compute_factor_vae", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "5", ",", "3000", ",", "\n", "2000", ",", "2500", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"train_accuracy\"", "]", ",", "0.0", ",", "0.2", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"eval_accuracy\"", "]", ",", "0.0", ",", "0.2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unsupervised_metrics_test.UnsupervisedMetricsTest.test_gaussian_total_correlation_zero": [[28, 32], ["disentanglement_lib.evaluation.metrics.unsupervised_metrics.gaussian_total_correlation", "unsupervised_metrics_test.UnsupervisedMetricsTest.assertBetween", "numpy.diag", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unsupervised_metrics.gaussian_total_correlation"], ["  ", "def", "test_gaussian_total_correlation_zero", "(", "self", ")", ":", "\n", "    ", "score", "=", "unsupervised_metrics", ".", "gaussian_total_correlation", "(", "\n", "np", ".", "diag", "(", "np", ".", "ones", "(", "5", ",", "dtype", "=", "np", ".", "float64", ")", ")", ")", "\n", "self", ".", "assertBetween", "(", "score", ",", "-", "0.01", ",", "0.01", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unsupervised_metrics_test.UnsupervisedMetricsTest.test_gaussian_total_correlation_same": [[33, 42], ["numpy.array", "numpy.array", "numpy.diag", "disentanglement_lib.evaluation.metrics.unsupervised_metrics.kl_gaussians_numerically_unstable", "disentanglement_lib.evaluation.metrics.unsupervised_metrics.gaussian_total_correlation", "unsupervised_metrics_test.UnsupervisedMetricsTest.assertBetween", "numpy.diag"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unsupervised_metrics.kl_gaussians_numerically_unstable", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unsupervised_metrics.gaussian_total_correlation"], ["", "def", "test_gaussian_total_correlation_same", "(", "self", ")", ":", "\n", "    ", "\"\"\"Check that the results of the both functions are the same.\"\"\"", "\n", "cov", "=", "np", ".", "array", "(", "[", "[", "1", ",", "0.9", "]", ",", "[", "0.9", ",", "1.0", "]", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "means", "=", "np", ".", "array", "(", "[", "0.0", ",", "0.0", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "cov_central", "=", "np", ".", "diag", "(", "np", ".", "diag", "(", "cov", ")", ")", "\n", "shouldbe", "=", "unsupervised_metrics", ".", "kl_gaussians_numerically_unstable", "(", "\n", "means", ",", "cov", ",", "means", ",", "cov_central", ",", "2", ")", "\n", "score", "=", "unsupervised_metrics", ".", "gaussian_total_correlation", "(", "cov", ")", "\n", "self", ".", "assertBetween", "(", "score", ",", "shouldbe", "-", "0.01", ",", "shouldbe", "+", "0.01", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unsupervised_metrics_test.UnsupervisedMetricsTest.test_gaussian_wasserstein_correlation_zero": [[43, 47], ["disentanglement_lib.evaluation.metrics.unsupervised_metrics.gaussian_wasserstein_correlation", "unsupervised_metrics_test.UnsupervisedMetricsTest.assertBetween", "numpy.diag", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unsupervised_metrics.gaussian_wasserstein_correlation"], ["", "def", "test_gaussian_wasserstein_correlation_zero", "(", "self", ")", ":", "\n", "    ", "score", "=", "unsupervised_metrics", ".", "gaussian_wasserstein_correlation", "(", "\n", "np", ".", "diag", "(", "np", ".", "ones", "(", "5", ",", "dtype", "=", "np", ".", "float64", ")", ")", ")", "\n", "self", ".", "assertBetween", "(", "score", ",", "-", "0.01", ",", "0.01", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unsupervised_metrics_test.UnsupervisedMetricsTest.test_gaussian_wasserstein_correlation_same": [[48, 55], ["numpy.array", "disentanglement_lib.evaluation.metrics.unsupervised_metrics.gaussian_wasserstein_correlation", "numpy.diag", "scipy.linalg.sqrtm", "numpy.trace", "unsupervised_metrics_test.UnsupervisedMetricsTest.assertBetween", "numpy.diag", "numpy.matmul"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unsupervised_metrics.gaussian_wasserstein_correlation"], ["", "def", "test_gaussian_wasserstein_correlation_same", "(", "self", ")", ":", "\n", "    ", "cov", "=", "np", ".", "array", "(", "[", "[", "1", ",", "0.9", "]", ",", "[", "0.9", ",", "1.0", "]", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "score", "=", "unsupervised_metrics", ".", "gaussian_wasserstein_correlation", "(", "cov", ")", "\n", "cov_only_diagonal", "=", "np", ".", "diag", "(", "np", ".", "diag", "(", "cov", ")", ")", "\n", "sqrtm", "=", "scipy", ".", "linalg", ".", "sqrtm", "(", "np", ".", "matmul", "(", "cov", ",", "cov_only_diagonal", ")", ")", "\n", "shouldbe", "=", "np", ".", "trace", "(", "cov", "+", "cov_only_diagonal", "-", "2", "*", "sqrtm", ")", "\n", "self", ".", "assertBetween", "(", "score", ",", "shouldbe", "-", "0.01", ",", "shouldbe", "+", "0.01", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.sap_score.compute_sap": [[32, 70], ["gin.configurable", "absl.logging.info", "disentanglement_lib.evaluation.metrics.utils.generate_batch_factor_code", "disentanglement_lib.evaluation.metrics.utils.generate_batch_factor_code", "absl.logging.info", "sap_score._compute_sap"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.generate_batch_factor_code", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.generate_batch_factor_code", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.sap_score._compute_sap"], ["@", "gin", ".", "configurable", "(", "\n", "\"sap_score\"", ",", "\n", "blacklist", "=", "[", "\"ground_truth_data\"", ",", "\"representation_function\"", ",", "\"random_state\"", ",", "\n", "\"artifact_dir\"", "]", ")", "\n", "def", "compute_sap", "(", "ground_truth_data", ",", "\n", "representation_function", ",", "\n", "random_state", ",", "\n", "artifact_dir", "=", "None", ",", "\n", "num_train", "=", "gin", ".", "REQUIRED", ",", "\n", "num_test", "=", "gin", ".", "REQUIRED", ",", "\n", "batch_size", "=", "16", ",", "\n", "continuous_factors", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "  ", "\"\"\"Computes the SAP score.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    random_state: Numpy random state used for randomness.\n    artifact_dir: Optional path to directory where artifacts can be saved.\n    num_train: Number of points used for training.\n    num_test: Number of points used for testing discrete variables.\n    batch_size: Batch size for sampling.\n    continuous_factors: Factors are continuous variable (True) or not (False).\n\n  Returns:\n    Dictionary with SAP score.\n  \"\"\"", "\n", "del", "artifact_dir", "\n", "logging", ".", "info", "(", "\"Generating training set.\"", ")", "\n", "mus", ",", "ys", "=", "utils", ".", "generate_batch_factor_code", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "num_train", ",", "\n", "random_state", ",", "batch_size", ")", "\n", "mus_test", ",", "ys_test", "=", "utils", ".", "generate_batch_factor_code", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "num_test", ",", "\n", "random_state", ",", "batch_size", ")", "\n", "logging", ".", "info", "(", "\"Computing score matrix.\"", ")", "\n", "return", "_compute_sap", "(", "mus", ",", "ys", ",", "mus_test", ",", "ys_test", ",", "continuous_factors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.sap_score._compute_sap": [[72, 84], ["sap_score.compute_score_matrix", "sap_score.compute_avg_diff_top_two", "absl.logging.info"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.sap_score.compute_score_matrix", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.sap_score.compute_avg_diff_top_two"], ["", "def", "_compute_sap", "(", "mus", ",", "ys", ",", "mus_test", ",", "ys_test", ",", "continuous_factors", ")", ":", "\n", "  ", "\"\"\"Computes score based on both training and testing codes and factors.\"\"\"", "\n", "score_matrix", "=", "compute_score_matrix", "(", "mus", ",", "ys", ",", "mus_test", ",", "\n", "ys_test", ",", "continuous_factors", ")", "\n", "# Score matrix should have shape [num_latents, num_factors].", "\n", "assert", "score_matrix", ".", "shape", "[", "0", "]", "==", "mus", ".", "shape", "[", "0", "]", "\n", "assert", "score_matrix", ".", "shape", "[", "1", "]", "==", "ys", ".", "shape", "[", "0", "]", "\n", "scores_dict", "=", "{", "}", "\n", "scores_dict", "[", "\"SAP_score\"", "]", "=", "compute_avg_diff_top_two", "(", "score_matrix", ")", "\n", "logging", ".", "info", "(", "\"SAP score: %.2g\"", ",", "scores_dict", "[", "\"SAP_score\"", "]", ")", "\n", "\n", "return", "scores_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.sap_score.compute_sap_on_fixed_data": [[86, 121], ["gin.configurable", "disentanglement_lib.evaluation.metrics.utils.obtain_representation", "disentanglement_lib.evaluation.metrics.utils.split_train_test", "disentanglement_lib.evaluation.metrics.utils.split_train_test", "sap_score._compute_sap"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.obtain_representation", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.split_train_test", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.split_train_test", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.sap_score._compute_sap"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"sap_score_validation\"", ",", "\n", "blacklist", "=", "[", "\"observations\"", ",", "\"labels\"", ",", "\"representation_function\"", "]", ")", "\n", "def", "compute_sap_on_fixed_data", "(", "observations", ",", "labels", ",", "representation_function", ",", "\n", "train_percentage", "=", "gin", ".", "REQUIRED", ",", "\n", "continuous_factors", "=", "gin", ".", "REQUIRED", ",", "\n", "batch_size", "=", "100", ")", ":", "\n", "  ", "\"\"\"Computes the SAP score on the fixed set of observations and labels.\n\n  Args:\n    observations: Observations on which to compute the score. Observations have\n      shape (num_observations, 64, 64, num_channels).\n    labels: Observed factors of variations.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    train_percentage: Percentage of observations used for training.\n    continuous_factors: Whether factors should be considered continuous or\n      discrete.\n    batch_size: Batch size used to compute the representation.\n\n  Returns:\n    SAP computed on the provided observations and labels.\n  \"\"\"", "\n", "mus", "=", "utils", ".", "obtain_representation", "(", "observations", ",", "representation_function", ",", "\n", "batch_size", ")", "\n", "assert", "labels", ".", "shape", "[", "1", "]", "==", "observations", ".", "shape", "[", "0", "]", ",", "\"Wrong labels shape.\"", "\n", "assert", "mus", ".", "shape", "[", "1", "]", "==", "observations", ".", "shape", "[", "0", "]", ",", "\"Wrong representation shape.\"", "\n", "mus_train", ",", "mus_test", "=", "utils", ".", "split_train_test", "(", "\n", "mus", ",", "\n", "train_percentage", ")", "\n", "ys_train", ",", "ys_test", "=", "utils", ".", "split_train_test", "(", "\n", "labels", ",", "\n", "train_percentage", ")", "\n", "return", "_compute_sap", "(", "mus_train", ",", "ys_train", ",", "mus_test", ",", "ys_test", ",", "\n", "continuous_factors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.sap_score.compute_score_matrix": [[123, 151], ["numpy.zeros", "six.moves.range", "six.moves.range", "numpy.cov", "sklearn.svm.LinearSVC", "svm.LinearSVC.fit", "svm.LinearSVC.predict", "numpy.mean"], "function", ["None"], ["", "def", "compute_score_matrix", "(", "mus", ",", "ys", ",", "mus_test", ",", "ys_test", ",", "continuous_factors", ")", ":", "\n", "  ", "\"\"\"Compute score matrix as described in Section 3.\"\"\"", "\n", "num_latents", "=", "mus", ".", "shape", "[", "0", "]", "\n", "num_factors", "=", "ys", ".", "shape", "[", "0", "]", "\n", "score_matrix", "=", "np", ".", "zeros", "(", "[", "num_latents", ",", "num_factors", "]", ")", "\n", "for", "i", "in", "range", "(", "num_latents", ")", ":", "\n", "    ", "for", "j", "in", "range", "(", "num_factors", ")", ":", "\n", "      ", "mu_i", "=", "mus", "[", "i", ",", ":", "]", "\n", "y_j", "=", "ys", "[", "j", ",", ":", "]", "\n", "if", "continuous_factors", ":", "\n", "# Attribute is considered continuous.", "\n", "        ", "cov_mu_i_y_j", "=", "np", ".", "cov", "(", "mu_i", ",", "y_j", ",", "ddof", "=", "1", ")", "\n", "cov_mu_y", "=", "cov_mu_i_y_j", "[", "0", ",", "1", "]", "**", "2", "\n", "var_mu", "=", "cov_mu_i_y_j", "[", "0", ",", "0", "]", "\n", "var_y", "=", "cov_mu_i_y_j", "[", "1", ",", "1", "]", "\n", "if", "var_mu", ">", "1e-12", ":", "\n", "          ", "score_matrix", "[", "i", ",", "j", "]", "=", "cov_mu_y", "*", "1.", "/", "(", "var_mu", "*", "var_y", ")", "\n", "", "else", ":", "\n", "          ", "score_matrix", "[", "i", ",", "j", "]", "=", "0.", "\n", "", "", "else", ":", "\n", "# Attribute is considered discrete.", "\n", "        ", "mu_i_test", "=", "mus_test", "[", "i", ",", ":", "]", "\n", "y_j_test", "=", "ys_test", "[", "j", ",", ":", "]", "\n", "classifier", "=", "svm", ".", "LinearSVC", "(", "C", "=", "0.01", ",", "class_weight", "=", "\"balanced\"", ")", "\n", "classifier", ".", "fit", "(", "mu_i", "[", ":", ",", "np", ".", "newaxis", "]", ",", "y_j", ")", "\n", "pred", "=", "classifier", ".", "predict", "(", "mu_i_test", "[", ":", ",", "np", ".", "newaxis", "]", ")", "\n", "score_matrix", "[", "i", ",", "j", "]", "=", "np", ".", "mean", "(", "pred", "==", "y_j_test", ")", "\n", "", "", "", "return", "score_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.sap_score.compute_avg_diff_top_two": [[153, 156], ["numpy.sort", "numpy.mean"], "function", ["None"], ["", "def", "compute_avg_diff_top_two", "(", "matrix", ")", ":", "\n", "  ", "sorted_matrix", "=", "np", ".", "sort", "(", "matrix", ",", "axis", "=", "0", ")", "\n", "return", "np", ".", "mean", "(", "sorted_matrix", "[", "-", "1", ",", ":", "]", "-", "sorted_matrix", "[", "-", "2", ",", ":", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.compute_dci": [[33, 72], ["gin.configurable", "absl.logging.info", "disentanglement_lib.evaluation.metrics.utils.generate_batch_factor_code", "disentanglement_lib.evaluation.metrics.utils.generate_batch_factor_code", "dci._compute_dci"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.generate_batch_factor_code", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.generate_batch_factor_code", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci._compute_dci"], ["@", "gin", ".", "configurable", "(", "\n", "\"dci\"", ",", "\n", "blacklist", "=", "[", "\"ground_truth_data\"", ",", "\"representation_function\"", ",", "\"random_state\"", ",", "\n", "\"artifact_dir\"", "]", ")", "\n", "def", "compute_dci", "(", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "\n", "artifact_dir", "=", "None", ",", "\n", "num_train", "=", "gin", ".", "REQUIRED", ",", "\n", "num_test", "=", "gin", ".", "REQUIRED", ",", "\n", "batch_size", "=", "16", ")", ":", "\n", "  ", "\"\"\"Computes the DCI scores according to Sec 2.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    random_state: Numpy random state used for randomness.\n    artifact_dir: Optional path to directory where artifacts can be saved.\n    num_train: Number of points used for training.\n    num_test: Number of points used for testing.\n    batch_size: Batch size for sampling.\n\n  Returns:\n    Dictionary with average disentanglement score, completeness and\n      informativeness (train and test).\n  \"\"\"", "\n", "del", "artifact_dir", "\n", "logging", ".", "info", "(", "\"Generating training set.\"", ")", "\n", "# mus_train are of shape [num_codes, num_train], while ys_train are of shape", "\n", "# [num_factors, num_train].", "\n", "mus_train", ",", "ys_train", "=", "utils", ".", "generate_batch_factor_code", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "num_train", ",", "\n", "random_state", ",", "batch_size", ")", "\n", "assert", "mus_train", ".", "shape", "[", "1", "]", "==", "num_train", "\n", "assert", "ys_train", ".", "shape", "[", "1", "]", "==", "num_train", "\n", "mus_test", ",", "ys_test", "=", "utils", ".", "generate_batch_factor_code", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "num_test", ",", "\n", "random_state", ",", "batch_size", ")", "\n", "scores", "=", "_compute_dci", "(", "mus_train", ",", "ys_train", ",", "mus_test", ",", "ys_test", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci._compute_dci": [[74, 86], ["dci.compute_importance_gbt", "dci.disentanglement", "dci.completeness"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.compute_importance_gbt", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.disentanglement", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.completeness"], ["", "def", "_compute_dci", "(", "mus_train", ",", "ys_train", ",", "mus_test", ",", "ys_test", ")", ":", "\n", "  ", "\"\"\"Computes score based on both training and testing codes and factors.\"\"\"", "\n", "scores", "=", "{", "}", "\n", "importance_matrix", ",", "train_err", ",", "test_err", "=", "compute_importance_gbt", "(", "\n", "mus_train", ",", "ys_train", ",", "mus_test", ",", "ys_test", ")", "\n", "assert", "importance_matrix", ".", "shape", "[", "0", "]", "==", "mus_train", ".", "shape", "[", "0", "]", "\n", "assert", "importance_matrix", ".", "shape", "[", "1", "]", "==", "ys_train", ".", "shape", "[", "0", "]", "\n", "scores", "[", "\"informativeness_train\"", "]", "=", "train_err", "\n", "scores", "[", "\"informativeness_test\"", "]", "=", "test_err", "\n", "scores", "[", "\"disentanglement\"", "]", "=", "disentanglement", "(", "importance_matrix", ")", "\n", "scores", "[", "\"completeness\"", "]", "=", "completeness", "(", "importance_matrix", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.compute_dci_on_fixed_data": [[88, 118], ["gin.configurable", "disentanglement_lib.evaluation.metrics.utils.obtain_representation", "disentanglement_lib.evaluation.metrics.utils.split_train_test", "disentanglement_lib.evaluation.metrics.utils.split_train_test", "dci._compute_dci"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.obtain_representation", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.split_train_test", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.split_train_test", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci._compute_dci"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"dci_validation\"", ",", "\n", "blacklist", "=", "[", "\"observations\"", ",", "\"labels\"", ",", "\"representation_function\"", "]", ")", "\n", "def", "compute_dci_on_fixed_data", "(", "observations", ",", "labels", ",", "representation_function", ",", "\n", "train_percentage", "=", "gin", ".", "REQUIRED", ",", "batch_size", "=", "100", ")", ":", "\n", "  ", "\"\"\"Computes the DCI scores on the fixed set of observations and labels.\n\n  Args:\n    observations: Observations on which to compute the score. Observations have\n      shape (num_observations, 64, 64, num_channels).\n    labels: Observed factors of variations.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    train_percentage: Percentage of observations used for training.\n    batch_size: Batch size used to compute the representation.\n\n  Returns:\n    DCI score.\n  \"\"\"", "\n", "mus", "=", "utils", ".", "obtain_representation", "(", "observations", ",", "representation_function", ",", "\n", "batch_size", ")", "\n", "assert", "labels", ".", "shape", "[", "1", "]", "==", "observations", ".", "shape", "[", "0", "]", ",", "\"Wrong labels shape.\"", "\n", "assert", "mus", ".", "shape", "[", "1", "]", "==", "observations", ".", "shape", "[", "0", "]", ",", "\"Wrong representation shape.\"", "\n", "mus_train", ",", "mus_test", "=", "utils", ".", "split_train_test", "(", "\n", "mus", ",", "\n", "train_percentage", ")", "\n", "ys_train", ",", "ys_test", "=", "utils", ".", "split_train_test", "(", "\n", "labels", ",", "\n", "train_percentage", ")", "\n", "return", "_compute_dci", "(", "mus_train", ",", "ys_train", ",", "mus_test", ",", "ys_test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.compute_importance_gbt": [[120, 135], ["numpy.zeros", "six.moves.range", "sklearn.ensemble.GradientBoostingClassifier", "ensemble.GradientBoostingClassifier.fit", "numpy.abs", "train_loss.append", "test_loss.append", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "ensemble.GradientBoostingClassifier.predict", "ensemble.GradientBoostingClassifier.predict"], "function", ["None"], ["", "def", "compute_importance_gbt", "(", "x_train", ",", "y_train", ",", "x_test", ",", "y_test", ")", ":", "\n", "  ", "\"\"\"Compute importance based on gradient boosted trees.\"\"\"", "\n", "num_factors", "=", "y_train", ".", "shape", "[", "0", "]", "\n", "num_codes", "=", "x_train", ".", "shape", "[", "0", "]", "\n", "importance_matrix", "=", "np", ".", "zeros", "(", "shape", "=", "[", "num_codes", ",", "num_factors", "]", ",", "\n", "dtype", "=", "np", ".", "float64", ")", "\n", "train_loss", "=", "[", "]", "\n", "test_loss", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_factors", ")", ":", "\n", "    ", "model", "=", "ensemble", ".", "GradientBoostingClassifier", "(", ")", "\n", "model", ".", "fit", "(", "x_train", ".", "T", ",", "y_train", "[", "i", ",", ":", "]", ")", "\n", "importance_matrix", "[", ":", ",", "i", "]", "=", "np", ".", "abs", "(", "model", ".", "feature_importances_", ")", "\n", "train_loss", ".", "append", "(", "np", ".", "mean", "(", "model", ".", "predict", "(", "x_train", ".", "T", ")", "==", "y_train", "[", "i", ",", ":", "]", ")", ")", "\n", "test_loss", ".", "append", "(", "np", ".", "mean", "(", "model", ".", "predict", "(", "x_test", ".", "T", ")", "==", "y_test", "[", "i", ",", ":", "]", ")", ")", "\n", "", "return", "importance_matrix", ",", "np", ".", "mean", "(", "train_loss", ")", ",", "np", ".", "mean", "(", "test_loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.disentanglement_per_code": [[137, 142], ["scipy.stats.entropy"], "function", ["None"], ["", "def", "disentanglement_per_code", "(", "importance_matrix", ")", ":", "\n", "  ", "\"\"\"Compute disentanglement score of each code.\"\"\"", "\n", "# importance_matrix is of shape [num_codes, num_factors].", "\n", "return", "1.", "-", "scipy", ".", "stats", ".", "entropy", "(", "importance_matrix", ".", "T", "+", "1e-11", ",", "\n", "base", "=", "importance_matrix", ".", "shape", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.disentanglement": [[144, 152], ["dci.disentanglement_per_code", "numpy.sum", "np.ones_like.sum", "numpy.ones_like", "np.ones_like.sum", "np.ones_like.sum"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.disentanglement_per_code"], ["", "def", "disentanglement", "(", "importance_matrix", ")", ":", "\n", "  ", "\"\"\"Compute the disentanglement score of the representation.\"\"\"", "\n", "per_code", "=", "disentanglement_per_code", "(", "importance_matrix", ")", "\n", "if", "importance_matrix", ".", "sum", "(", ")", "==", "0.", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "ones_like", "(", "importance_matrix", ")", "\n", "", "code_importance", "=", "importance_matrix", ".", "sum", "(", "axis", "=", "1", ")", "/", "importance_matrix", ".", "sum", "(", ")", "\n", "\n", "return", "np", ".", "sum", "(", "per_code", "*", "code_importance", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.completeness_per_factor": [[154, 159], ["scipy.stats.entropy"], "function", ["None"], ["", "def", "completeness_per_factor", "(", "importance_matrix", ")", ":", "\n", "  ", "\"\"\"Compute completeness of each factor.\"\"\"", "\n", "# importance_matrix is of shape [num_codes, num_factors].", "\n", "return", "1.", "-", "scipy", ".", "stats", ".", "entropy", "(", "importance_matrix", "+", "1e-11", ",", "\n", "base", "=", "importance_matrix", ".", "shape", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.completeness": [[161, 168], ["dci.completeness_per_factor", "numpy.sum", "np.ones_like.sum", "numpy.ones_like", "np.ones_like.sum", "np.ones_like.sum"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.completeness_per_factor"], ["", "def", "completeness", "(", "importance_matrix", ")", ":", "\n", "  ", "\"\"\"\"Compute completeness of the representation.\"\"\"", "\n", "per_factor", "=", "completeness_per_factor", "(", "importance_matrix", ")", "\n", "if", "importance_matrix", ".", "sum", "(", ")", "==", "0.", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "ones_like", "(", "importance_matrix", ")", "\n", "", "factor_importance", "=", "importance_matrix", ".", "sum", "(", "axis", "=", "0", ")", "/", "importance_matrix", ".", "sum", "(", ")", "\n", "return", "np", ".", "sum", "(", "per_factor", "*", "factor_importance", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness_test.ModularityTest.test_diagonal": [[35, 39], ["numpy.diag", "disentanglement_lib.evaluation.metrics.modularity_explicitness.modularity", "numpy.testing.assert_allclose", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness.modularity"], ["  ", "def", "test_diagonal", "(", "self", ")", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "diag", "(", "5.", "*", "np", ".", "ones", "(", "5", ")", ")", "\n", "result", "=", "modularity_explicitness", ".", "modularity", "(", "importance_matrix", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness_test.ModularityTest.test_diagonal_empty_codes": [[40, 44], ["numpy.array", "disentanglement_lib.evaluation.metrics.modularity_explicitness.modularity", "numpy.testing.assert_allclose"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness.modularity"], ["", "def", "test_diagonal_empty_codes", "(", "self", ")", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "array", "(", "[", "[", "1.", ",", "0.", ",", "]", ",", "[", "0.", ",", "1.", "]", ",", "[", "0.", ",", "0.", "]", "]", ")", "\n", "result", "=", "modularity_explicitness", ".", "modularity", "(", "importance_matrix", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", "2.", "/", "3.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness_test.ModularityTest.test_zero": [[45, 49], ["numpy.zeros", "disentanglement_lib.evaluation.metrics.modularity_explicitness.modularity", "numpy.testing.assert_allclose"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness.modularity"], ["", "def", "test_zero", "(", "self", ")", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "zeros", "(", "shape", "=", "[", "10", ",", "10", "]", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "result", "=", "modularity_explicitness", ".", "modularity", "(", "importance_matrix", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", ".0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness_test.ModularityTest.test_redundant_codes": [[50, 55], ["numpy.diag", "numpy.vstack", "disentanglement_lib.evaluation.metrics.modularity_explicitness.modularity", "numpy.testing.assert_allclose", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness.modularity"], ["", "def", "test_redundant_codes", "(", "self", ")", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "diag", "(", "5.", "*", "np", ".", "ones", "(", "5", ")", ")", "\n", "importance_matrix", "=", "np", ".", "vstack", "(", "[", "importance_matrix", ",", "importance_matrix", "]", ")", "\n", "result", "=", "modularity_explicitness", ".", "modularity", "(", "importance_matrix", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", "1.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness_test.ModularityTest.test_missed_factors": [[56, 60], ["numpy.diag", "disentanglement_lib.evaluation.metrics.modularity_explicitness.modularity", "numpy.testing.assert_allclose", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness.modularity"], ["", "def", "test_missed_factors", "(", "self", ")", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "diag", "(", "5.", "*", "np", ".", "ones", "(", "5", ")", ")", "\n", "result", "=", "modularity_explicitness", ".", "modularity", "(", "importance_matrix", "[", ":", "2", ",", ":", "]", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness_test.ModularityTest.test_one_code_two_factors": [[61, 66], ["numpy.diag", "numpy.hstack", "disentanglement_lib.evaluation.metrics.modularity_explicitness.modularity", "numpy.testing.assert_allclose", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness.modularity"], ["", "def", "test_one_code_two_factors", "(", "self", ")", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "diag", "(", "5.", "*", "np", ".", "ones", "(", "5", ")", ")", "\n", "importance_matrix", "=", "np", ".", "hstack", "(", "[", "importance_matrix", ",", "importance_matrix", "]", ")", "\n", "result", "=", "modularity_explicitness", ".", "modularity", "(", "importance_matrix", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", "1.", "-", "1.", "/", "9", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness_test.ModularityExplicitnessTest.test_metric": [[70, 80], ["gin.bind_parameter", "gin.bind_parameter", "disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.modularity_explicitness.compute_modularity_explicitness", "modularity_explicitness_test.ModularityExplicitnessTest.assertBetween", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness.compute_modularity_explicitness"], ["  ", "def", "test_metric", "(", "self", ")", ":", "\n", "    ", "gin", ".", "bind_parameter", "(", "\"discretizer.discretizer_fn\"", ",", "_identity_discretizer", ")", "\n", "gin", ".", "bind_parameter", "(", "\"discretizer.num_bins\"", ",", "10", ")", "\n", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "representation_function", "=", "lambda", "x", ":", "np", ".", "array", "(", "x", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "modularity_explicitness", ".", "compute_modularity_explicitness", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "3000", ",", "\n", "3000", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"modularity_score\"", "]", ",", "0.9", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness_test.ModularityExplicitnessTest.test_bad_metric": [[81, 98], ["gin.bind_parameter", "gin.bind_parameter", "disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.modularity_explicitness.compute_modularity_explicitness", "modularity_explicitness_test.ModularityExplicitnessTest.assertBetween", "numpy.array", "six.moves.range", "numpy.random.RandomState.permutation"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness.compute_modularity_explicitness"], ["", "def", "test_bad_metric", "(", "self", ")", ":", "\n", "    ", "gin", ".", "bind_parameter", "(", "\"discretizer.discretizer_fn\"", ",", "_identity_discretizer", ")", "\n", "gin", ".", "bind_parameter", "(", "\"discretizer.num_bins\"", ",", "10", ")", "\n", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "random_state_rep", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "# The representation which randomly permutes the factors, should have equal", "\n", "# non-zero MI which should give a low modularity score.", "\n", "def", "representation_function", "(", "x", ")", ":", "\n", "      ", "code", "=", "np", ".", "array", "(", "x", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "for", "i", "in", "range", "(", "code", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "code", "[", "i", ",", ":", "]", "=", "random_state_rep", ".", "permutation", "(", "code", "[", "i", ",", ":", "]", ")", "\n", "", "return", "code", "\n", "", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "modularity_explicitness", ".", "compute_modularity_explicitness", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "20000", ",", "\n", "20000", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"modularity_score\"", "]", ",", "0.0", ",", "0.2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness_test.ModularityExplicitnessTest.test_duplicated_latent_space": [[99, 111], ["gin.bind_parameter", "gin.bind_parameter", "disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.modularity_explicitness.compute_modularity_explicitness", "modularity_explicitness_test.ModularityExplicitnessTest.assertBetween", "numpy.array", "numpy.hstack"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness.compute_modularity_explicitness"], ["", "def", "test_duplicated_latent_space", "(", "self", ")", ":", "\n", "    ", "gin", ".", "bind_parameter", "(", "\"discretizer.discretizer_fn\"", ",", "_identity_discretizer", ")", "\n", "gin", ".", "bind_parameter", "(", "\"discretizer.num_bins\"", ",", "10", ")", "\n", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "def", "representation_function", "(", "x", ")", ":", "\n", "      ", "x", "=", "np", ".", "array", "(", "x", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "return", "np", ".", "hstack", "(", "[", "x", ",", "x", "]", ")", "\n", "", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "modularity_explicitness", ".", "compute_modularity_explicitness", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "3000", ",", "\n", "3000", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"modularity_score\"", "]", ",", "0.9", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness_test._identity_discretizer": [[28, 31], ["None"], "function", ["None"], ["def", "_identity_discretizer", "(", "target", ",", "num_bins", ")", ":", "\n", "  ", "del", "num_bins", "\n", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.sap_score_test.SapScoreTest.test_metric": [[28, 36], ["disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.sap_score.compute_sap", "sap_score_test.SapScoreTest.assertBetween", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.sap_score.compute_sap"], ["  ", "def", "test_metric", "(", "self", ")", ":", "\n", "    ", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "representation_function", "=", "lambda", "x", ":", "np", ".", "array", "(", "x", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "sap_score", ".", "compute_sap", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "3000", ",", "\n", "3000", ",", "continuous_factors", "=", "True", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"SAP_score\"", "]", ",", "0.9", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.sap_score_test.SapScoreTest.test_bad_metric": [[37, 45], ["disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.sap_score.compute_sap", "sap_score_test.SapScoreTest.assertBetween", "numpy.zeros_like"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.sap_score.compute_sap"], ["", "def", "test_bad_metric", "(", "self", ")", ":", "\n", "    ", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "representation_function", "=", "lambda", "x", ":", "np", ".", "zeros_like", "(", "x", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "sap_score", ".", "compute_sap", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "3000", ",", "\n", "3000", ",", "continuous_factors", "=", "True", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"SAP_score\"", "]", ",", "0.0", ",", "0.2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.sap_score_test.SapScoreTest.test_duplicated_latent_space": [[46, 56], ["disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.sap_score.compute_sap", "sap_score_test.SapScoreTest.assertBetween", "numpy.array", "numpy.hstack"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.sap_score.compute_sap"], ["", "def", "test_duplicated_latent_space", "(", "self", ")", ":", "\n", "    ", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "def", "representation_function", "(", "x", ")", ":", "\n", "      ", "x", "=", "np", ".", "array", "(", "x", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "return", "np", ".", "hstack", "(", "[", "x", ",", "x", "]", ")", "\n", "", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "sap_score", ".", "compute_sap", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "3000", ",", "\n", "3000", ",", "continuous_factors", "=", "True", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"SAP_score\"", "]", ",", "0.0", ",", "0.2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.beta_vae_test.BetaVaeTest.test_metric": [[30, 39], ["disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.beta_vae.compute_beta_vae_sklearn", "beta_vae_test.BetaVaeTest.assertBetween", "beta_vae_test.BetaVaeTest.assertBetween"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.beta_vae.compute_beta_vae_sklearn"], ["  ", "def", "test_metric", "(", "self", ")", ":", "\n", "    ", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "representation_function", "=", "lambda", "x", ":", "x", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "beta_vae", ".", "compute_beta_vae_sklearn", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "5", ",", "\n", "2000", ",", "2000", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"train_accuracy\"", "]", ",", "0.9", ",", "1.0", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"eval_accuracy\"", "]", ",", "0.9", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness.compute_modularity_explicitness": [[33, 85], ["gin.configurable", "disentanglement_lib.evaluation.metrics.utils.generate_batch_factor_code", "disentanglement_lib.evaluation.metrics.utils.generate_batch_factor_code", "disentanglement_lib.evaluation.metrics.utils.make_discretizer", "disentanglement_lib.evaluation.metrics.utils.discrete_mutual_info", "modularity_explicitness.modularity", "numpy.zeros", "numpy.zeros", "disentanglement_lib.evaluation.metrics.utils.normalize_data", "disentanglement_lib.evaluation.metrics.utils.normalize_data", "six.moves.range", "numpy.mean", "numpy.mean", "modularity_explicitness.explicitness_per_factor"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.generate_batch_factor_code", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.generate_batch_factor_code", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.make_discretizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.discrete_mutual_info", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness.modularity", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.normalize_data", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.normalize_data", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness.explicitness_per_factor"], ["@", "gin", ".", "configurable", "(", "\n", "\"modularity_explicitness\"", ",", "\n", "blacklist", "=", "[", "\"ground_truth_data\"", ",", "\"representation_function\"", ",", "\"random_state\"", ",", "\n", "\"artifact_dir\"", "]", ")", "\n", "def", "compute_modularity_explicitness", "(", "ground_truth_data", ",", "\n", "representation_function", ",", "\n", "random_state", ",", "\n", "artifact_dir", "=", "None", ",", "\n", "num_train", "=", "gin", ".", "REQUIRED", ",", "\n", "num_test", "=", "gin", ".", "REQUIRED", ",", "\n", "batch_size", "=", "16", ")", ":", "\n", "  ", "\"\"\"Computes the modularity metric according to Sec 3.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    random_state: Numpy random state used for randomness.\n    artifact_dir: Optional path to directory where artifacts can be saved.\n    num_train: Number of points used for training.\n    num_test: Number of points used for testing.\n    batch_size: Batch size for sampling.\n\n  Returns:\n    Dictionary with average modularity score and average explicitness\n      (train and test).\n  \"\"\"", "\n", "del", "artifact_dir", "\n", "scores", "=", "{", "}", "\n", "mus_train", ",", "ys_train", "=", "utils", ".", "generate_batch_factor_code", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "num_train", ",", "\n", "random_state", ",", "batch_size", ")", "\n", "mus_test", ",", "ys_test", "=", "utils", ".", "generate_batch_factor_code", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "num_test", ",", "\n", "random_state", ",", "batch_size", ")", "\n", "discretized_mus", "=", "utils", ".", "make_discretizer", "(", "mus_train", ")", "\n", "mutual_information", "=", "utils", ".", "discrete_mutual_info", "(", "discretized_mus", ",", "ys_train", ")", "\n", "# Mutual information should have shape [num_codes, num_factors].", "\n", "assert", "mutual_information", ".", "shape", "[", "0", "]", "==", "mus_train", ".", "shape", "[", "0", "]", "\n", "assert", "mutual_information", ".", "shape", "[", "1", "]", "==", "ys_train", ".", "shape", "[", "0", "]", "\n", "scores", "[", "\"modularity_score\"", "]", "=", "modularity", "(", "mutual_information", ")", "\n", "explicitness_score_train", "=", "np", ".", "zeros", "(", "[", "ys_train", ".", "shape", "[", "0", "]", ",", "1", "]", ")", "\n", "explicitness_score_test", "=", "np", ".", "zeros", "(", "[", "ys_test", ".", "shape", "[", "0", "]", ",", "1", "]", ")", "\n", "mus_train_norm", ",", "mean_mus", ",", "stddev_mus", "=", "utils", ".", "normalize_data", "(", "mus_train", ")", "\n", "mus_test_norm", ",", "_", ",", "_", "=", "utils", ".", "normalize_data", "(", "mus_test", ",", "mean_mus", ",", "stddev_mus", ")", "\n", "for", "i", "in", "range", "(", "ys_train", ".", "shape", "[", "0", "]", ")", ":", "\n", "    ", "explicitness_score_train", "[", "i", "]", ",", "explicitness_score_test", "[", "i", "]", "=", "explicitness_per_factor", "(", "mus_train_norm", ",", "ys_train", "[", "i", ",", ":", "]", ",", "\n", "mus_test_norm", ",", "ys_test", "[", "i", ",", ":", "]", ")", "\n", "", "scores", "[", "\"explicitness_score_train\"", "]", "=", "np", ".", "mean", "(", "explicitness_score_train", ")", "\n", "scores", "[", "\"explicitness_score_test\"", "]", "=", "np", ".", "mean", "(", "explicitness_score_test", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness.explicitness_per_factor": [[87, 113], ["numpy.transpose", "numpy.transpose", "sklearn.linear_model.LogisticRegression().fit", "linear_model.LogisticRegression().fit.predict_proba", "linear_model.LogisticRegression().fit.predict_proba", "sklearn.preprocessing.MultiLabelBinarizer", "sklearn.metrics.roc_auc_score", "sklearn.metrics.roc_auc_score", "preprocessing.MultiLabelBinarizer.fit_transform", "preprocessing.MultiLabelBinarizer.fit_transform", "sklearn.linear_model.LogisticRegression", "numpy.expand_dims", "numpy.expand_dims"], "function", ["None"], ["", "def", "explicitness_per_factor", "(", "mus_train", ",", "y_train", ",", "mus_test", ",", "y_test", ")", ":", "\n", "  ", "\"\"\"Compute explicitness score for a factor as ROC-AUC of a classifier.\n\n  Args:\n    mus_train: Representation for training, (num_codes, num_points)-np array.\n    y_train: Ground truth factors for training, (num_factors, num_points)-np\n      array.\n    mus_test: Representation for testing, (num_codes, num_points)-np array.\n    y_test: Ground truth factors for testing, (num_factors, num_points)-np\n      array.\n\n  Returns:\n    roc_train: ROC-AUC score of the classifier on training data.\n    roc_test: ROC-AUC score of the classifier on testing data.\n  \"\"\"", "\n", "x_train", "=", "np", ".", "transpose", "(", "mus_train", ")", "\n", "x_test", "=", "np", ".", "transpose", "(", "mus_test", ")", "\n", "clf", "=", "linear_model", ".", "LogisticRegression", "(", ")", ".", "fit", "(", "x_train", ",", "y_train", ")", "\n", "y_pred_train", "=", "clf", ".", "predict_proba", "(", "x_train", ")", "\n", "y_pred_test", "=", "clf", ".", "predict_proba", "(", "x_test", ")", "\n", "mlb", "=", "preprocessing", ".", "MultiLabelBinarizer", "(", ")", "\n", "roc_train", "=", "metrics", ".", "roc_auc_score", "(", "\n", "mlb", ".", "fit_transform", "(", "np", ".", "expand_dims", "(", "y_train", ",", "1", ")", ")", ",", "y_pred_train", ")", "\n", "roc_test", "=", "metrics", ".", "roc_auc_score", "(", "\n", "mlb", ".", "fit_transform", "(", "np", ".", "expand_dims", "(", "y_test", ",", "1", ")", ")", ",", "y_pred_test", ")", "\n", "return", "roc_train", ",", "roc_test", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness.modularity": [[115, 127], ["numpy.square", "numpy.max", "numpy.mean", "numpy.sum"], "function", ["None"], ["", "def", "modularity", "(", "mutual_information", ")", ":", "\n", "  ", "\"\"\"Computes the modularity from mutual information.\"\"\"", "\n", "# Mutual information has shape [num_codes, num_factors].", "\n", "squared_mi", "=", "np", ".", "square", "(", "mutual_information", ")", "\n", "max_squared_mi", "=", "np", ".", "max", "(", "squared_mi", ",", "axis", "=", "1", ")", "\n", "numerator", "=", "np", ".", "sum", "(", "squared_mi", ",", "axis", "=", "1", ")", "-", "max_squared_mi", "\n", "denominator", "=", "max_squared_mi", "*", "(", "squared_mi", ".", "shape", "[", "1", "]", "-", "1.", ")", "\n", "delta", "=", "numerator", "/", "denominator", "\n", "modularity_score", "=", "1.", "-", "delta", "\n", "index", "=", "(", "max_squared_mi", "==", "0.", ")", "\n", "modularity_score", "[", "index", "]", "=", "0.", "\n", "return", "np", ".", "mean", "(", "modularity_score", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.mig.compute_mig": [[27, 58], ["gin.configurable", "absl.logging.info", "disentanglement_lib.evaluation.metrics.utils.generate_batch_factor_code", "mig._compute_mig"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.generate_batch_factor_code", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.mig._compute_mig"], ["@", "gin", ".", "configurable", "(", "\n", "\"mig\"", ",", "\n", "blacklist", "=", "[", "\"ground_truth_data\"", ",", "\"representation_function\"", ",", "\"random_state\"", ",", "\n", "\"artifact_dir\"", "]", ")", "\n", "def", "compute_mig", "(", "ground_truth_data", ",", "\n", "representation_function", ",", "\n", "random_state", ",", "\n", "artifact_dir", "=", "None", ",", "\n", "num_train", "=", "gin", ".", "REQUIRED", ",", "\n", "batch_size", "=", "16", ")", ":", "\n", "  ", "\"\"\"Computes the mutual information gap.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    random_state: Numpy random state used for randomness.\n    artifact_dir: Optional path to directory where artifacts can be saved.\n    num_train: Number of points used for training.\n    batch_size: Batch size for sampling.\n\n  Returns:\n    Dict with average mutual information gap.\n  \"\"\"", "\n", "del", "artifact_dir", "\n", "logging", ".", "info", "(", "\"Generating training set.\"", ")", "\n", "mus_train", ",", "ys_train", "=", "utils", ".", "generate_batch_factor_code", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "num_train", ",", "\n", "random_state", ",", "batch_size", ")", "\n", "assert", "mus_train", ".", "shape", "[", "1", "]", "==", "num_train", "\n", "return", "_compute_mig", "(", "mus_train", ",", "ys_train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.mig._compute_mig": [[60, 73], ["disentanglement_lib.evaluation.metrics.utils.make_discretizer", "disentanglement_lib.evaluation.metrics.utils.discrete_mutual_info", "disentanglement_lib.evaluation.metrics.utils.discrete_entropy", "numpy.mean", "numpy.sort", "numpy.divide"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.make_discretizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.discrete_mutual_info", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.discrete_entropy"], ["", "def", "_compute_mig", "(", "mus_train", ",", "ys_train", ")", ":", "\n", "  ", "\"\"\"Computes score based on both training and testing codes and factors.\"\"\"", "\n", "score_dict", "=", "{", "}", "\n", "discretized_mus", "=", "utils", ".", "make_discretizer", "(", "mus_train", ")", "\n", "m", "=", "utils", ".", "discrete_mutual_info", "(", "discretized_mus", ",", "ys_train", ")", "\n", "assert", "m", ".", "shape", "[", "0", "]", "==", "mus_train", ".", "shape", "[", "0", "]", "\n", "assert", "m", ".", "shape", "[", "1", "]", "==", "ys_train", ".", "shape", "[", "0", "]", "\n", "# m is [num_latents, num_factors]", "\n", "entropy", "=", "utils", ".", "discrete_entropy", "(", "ys_train", ")", "\n", "sorted_m", "=", "np", ".", "sort", "(", "m", ",", "axis", "=", "0", ")", "[", ":", ":", "-", "1", "]", "\n", "score_dict", "[", "\"discrete_mig\"", "]", "=", "np", ".", "mean", "(", "\n", "np", ".", "divide", "(", "sorted_m", "[", "0", ",", ":", "]", "-", "sorted_m", "[", "1", ",", ":", "]", ",", "entropy", "[", ":", "]", ")", ")", "\n", "return", "score_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.mig.compute_mig_on_fixed_data": [[75, 98], ["gin.configurable", "disentanglement_lib.evaluation.metrics.utils.obtain_representation", "mig._compute_mig"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.obtain_representation", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.mig._compute_mig"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"mig_validation\"", ",", "\n", "blacklist", "=", "[", "\"observations\"", ",", "\"labels\"", ",", "\"representation_function\"", "]", ")", "\n", "def", "compute_mig_on_fixed_data", "(", "observations", ",", "labels", ",", "representation_function", ",", "\n", "batch_size", "=", "100", ")", ":", "\n", "  ", "\"\"\"Computes the MIG scores on the fixed set of observations and labels.\n\n  Args:\n    observations: Observations on which to compute the score. Observations have\n      shape (num_observations, 64, 64, num_channels).\n    labels: Observed factors of variations.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    batch_size: Batch size used to compute the representation.\n\n  Returns:\n    MIG computed on the provided observations and labels.\n  \"\"\"", "\n", "mus", "=", "utils", ".", "obtain_representation", "(", "observations", ",", "representation_function", ",", "\n", "batch_size", ")", "\n", "assert", "labels", ".", "shape", "[", "1", "]", "==", "observations", ".", "shape", "[", "0", "]", ",", "\"Wrong labels shape.\"", "\n", "assert", "mus", ".", "shape", "[", "1", "]", "==", "observations", ".", "shape", "[", "0", "]", ",", "\"Wrong representation shape.\"", "\n", "return", "_compute_mig", "(", "mus", ",", "labels", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.mig_test.MIGTest.test_metric": [[34, 43], ["gin.bind_parameter", "gin.bind_parameter", "disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.mig.compute_mig", "mig_test.MIGTest.assertBetween"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.mig.compute_mig"], ["  ", "def", "test_metric", "(", "self", ")", ":", "\n", "    ", "gin", ".", "bind_parameter", "(", "\"discretizer.discretizer_fn\"", ",", "_identity_discretizer", ")", "\n", "gin", ".", "bind_parameter", "(", "\"discretizer.num_bins\"", ",", "10", ")", "\n", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "representation_function", "=", "lambda", "x", ":", "x", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "mig", ".", "compute_mig", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "3000", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"discrete_mig\"", "]", ",", "0.9", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.mig_test.MIGTest.test_bad_metric": [[44, 53], ["gin.bind_parameter", "gin.bind_parameter", "disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.mig.compute_mig", "mig_test.MIGTest.assertBetween"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.mig.compute_mig"], ["", "def", "test_bad_metric", "(", "self", ")", ":", "\n", "    ", "gin", ".", "bind_parameter", "(", "\"discretizer.discretizer_fn\"", ",", "_identity_discretizer", ")", "\n", "gin", ".", "bind_parameter", "(", "\"discretizer.num_bins\"", ",", "10", ")", "\n", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "representation_function", "=", "np", ".", "zeros_like", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "mig", ".", "compute_mig", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "3000", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"discrete_mig\"", "]", ",", "0.0", ",", "0.2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.mig_test.MIGTest.test_duplicated_latent_space": [[54, 65], ["gin.bind_parameter", "gin.bind_parameter", "disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.mig.compute_mig", "mig_test.MIGTest.assertBetween", "numpy.array", "numpy.hstack"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.mig.compute_mig"], ["", "def", "test_duplicated_latent_space", "(", "self", ")", ":", "\n", "    ", "gin", ".", "bind_parameter", "(", "\"discretizer.discretizer_fn\"", ",", "_identity_discretizer", ")", "\n", "gin", ".", "bind_parameter", "(", "\"discretizer.num_bins\"", ",", "10", ")", "\n", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "def", "representation_function", "(", "x", ")", ":", "\n", "      ", "x", "=", "np", ".", "array", "(", "x", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "return", "np", ".", "hstack", "(", "[", "x", ",", "x", "]", ")", "\n", "", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "mig", ".", "compute_mig", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "3000", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"discrete_mig\"", "]", ",", "0.0", ",", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.mig_test._identity_discretizer": [[27, 30], ["None"], "function", ["None"], ["def", "_identity_discretizer", "(", "target", ",", "num_bins", ")", ":", "\n", "  ", "del", "num_bins", "\n", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unsupervised_metrics.unsupervised_metrics": [[24, 74], ["gin.configurable", "absl.logging.info", "disentanglement_lib.evaluation.metrics.utils.generate_batch_factor_code", "numpy.cov", "unsupervised_metrics.gaussian_total_correlation", "unsupervised_metrics.gaussian_wasserstein_correlation", "disentanglement_lib.evaluation.metrics.utils.make_discretizer", "disentanglement_lib.evaluation.metrics.utils.discrete_mutual_info", "numpy.fill_diagonal", "numpy.sum", "numpy.sum", "numpy.diag"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.generate_batch_factor_code", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unsupervised_metrics.gaussian_total_correlation", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unsupervised_metrics.gaussian_wasserstein_correlation", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.make_discretizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.discrete_mutual_info"], ["@", "gin", ".", "configurable", "(", "\n", "\"unsupervised_metrics\"", ",", "\n", "blacklist", "=", "[", "\"ground_truth_data\"", ",", "\"representation_function\"", ",", "\"random_state\"", ",", "\n", "\"artifact_dir\"", "]", ")", "\n", "def", "unsupervised_metrics", "(", "ground_truth_data", ",", "\n", "representation_function", ",", "\n", "random_state", ",", "\n", "artifact_dir", "=", "None", ",", "\n", "num_train", "=", "gin", ".", "REQUIRED", ",", "\n", "batch_size", "=", "16", ")", ":", "\n", "  ", "\"\"\"Computes unsupervised scores based on covariance and mutual information.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    random_state: Numpy random state used for randomness.\n    artifact_dir: Optional path to directory where artifacts can be saved.\n    num_train: Number of points used for training.\n    batch_size: Batch size for sampling.\n\n  Returns:\n    Dictionary with scores.\n  \"\"\"", "\n", "del", "artifact_dir", "\n", "scores", "=", "{", "}", "\n", "logging", ".", "info", "(", "\"Generating training set.\"", ")", "\n", "mus_train", ",", "_", "=", "utils", ".", "generate_batch_factor_code", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "num_train", ",", "random_state", ",", "\n", "batch_size", ")", "\n", "num_codes", "=", "mus_train", ".", "shape", "[", "0", "]", "\n", "cov_mus", "=", "np", ".", "cov", "(", "mus_train", ")", "\n", "assert", "num_codes", "==", "cov_mus", ".", "shape", "[", "0", "]", "\n", "\n", "# Gaussian total correlation.", "\n", "scores", "[", "\"gaussian_total_correlation\"", "]", "=", "gaussian_total_correlation", "(", "cov_mus", ")", "\n", "\n", "# Gaussian Wasserstein correlation.", "\n", "scores", "[", "\"gaussian_wasserstein_correlation\"", "]", "=", "gaussian_wasserstein_correlation", "(", "\n", "cov_mus", ")", "\n", "scores", "[", "\"gaussian_wasserstein_correlation_norm\"", "]", "=", "(", "\n", "scores", "[", "\"gaussian_wasserstein_correlation\"", "]", "/", "np", ".", "sum", "(", "np", ".", "diag", "(", "cov_mus", ")", ")", ")", "\n", "\n", "# Compute average mutual information between different factors.", "\n", "mus_discrete", "=", "utils", ".", "make_discretizer", "(", "mus_train", ")", "\n", "mutual_info_matrix", "=", "utils", ".", "discrete_mutual_info", "(", "mus_discrete", ",", "mus_discrete", ")", "\n", "np", ".", "fill_diagonal", "(", "mutual_info_matrix", ",", "0", ")", "\n", "mutual_info_score", "=", "np", ".", "sum", "(", "mutual_info_matrix", ")", "/", "(", "num_codes", "**", "2", "-", "num_codes", ")", "\n", "scores", "[", "\"mutual_info_score\"", "]", "=", "mutual_info_score", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unsupervised_metrics.kl_gaussians_numerically_unstable": [[76, 85], ["numpy.linalg.det", "numpy.linalg.det", "numpy.linalg.inv", "numpy.log", "numpy.trace", "numpy.dot", "numpy.matmul", "numpy.dot"], "function", ["None"], ["", "def", "kl_gaussians_numerically_unstable", "(", "mean_0", ",", "cov_0", ",", "mean_1", ",", "cov_1", ",", "k", ")", ":", "\n", "  ", "\"\"\"Unstable version used for testing gaussian_total_correlation.\"\"\"", "\n", "det_0", "=", "np", ".", "linalg", ".", "det", "(", "cov_0", ")", "\n", "det_1", "=", "np", ".", "linalg", ".", "det", "(", "cov_1", ")", "\n", "inv_1", "=", "np", ".", "linalg", ".", "inv", "(", "cov_1", ")", "\n", "return", "0.5", "*", "(", "\n", "np", ".", "trace", "(", "np", ".", "matmul", "(", "inv_1", ",", "cov_0", ")", ")", "+", "np", ".", "dot", "(", "mean_1", "-", "mean_0", ",", "\n", "np", ".", "dot", "(", "inv_1", ",", "mean_1", "-", "mean_0", ")", ")", "\n", "-", "k", "+", "np", ".", "log", "(", "det_1", "/", "det_0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unsupervised_metrics.gaussian_total_correlation": [[87, 102], ["numpy.sum", "numpy.log", "numpy.linalg.slogdet", "numpy.diag"], "function", ["None"], ["", "def", "gaussian_total_correlation", "(", "cov", ")", ":", "\n", "  ", "\"\"\"Computes the total correlation of a Gaussian with covariance matrix cov.\n\n  We use that the total correlation is the KL divergence between the Gaussian\n  and the product of its marginals. By design, the means of these two Gaussians\n  are zero and the covariance matrix of the second Gaussian is equal to the\n  covariance matrix of the first Gaussian with off-diagonal entries set to zero.\n\n  Args:\n    cov: Numpy array with covariance matrix.\n\n  Returns:\n    Scalar with total correlation.\n  \"\"\"", "\n", "return", "0.5", "*", "(", "np", ".", "sum", "(", "np", ".", "log", "(", "np", ".", "diag", "(", "cov", ")", ")", ")", "-", "np", ".", "linalg", ".", "slogdet", "(", "cov", ")", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unsupervised_metrics.gaussian_wasserstein_correlation": [[104, 115], ["scipy.linalg.sqrtm", "numpy.expand_dims", "numpy.trace", "numpy.trace", "numpy.diag"], "function", ["None"], ["", "def", "gaussian_wasserstein_correlation", "(", "cov", ")", ":", "\n", "  ", "\"\"\"Wasserstein L2 distance between Gaussian and the product of its marginals.\n\n  Args:\n    cov: Numpy array with covariance matrix.\n\n  Returns:\n    Scalar with score.\n  \"\"\"", "\n", "sqrtm", "=", "scipy", ".", "linalg", ".", "sqrtm", "(", "cov", "*", "np", ".", "expand_dims", "(", "np", ".", "diag", "(", "cov", ")", ",", "axis", "=", "1", ")", ")", "\n", "return", "2", "*", "np", ".", "trace", "(", "cov", ")", "-", "2", "*", "np", ".", "trace", "(", "sqrtm", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.factor_vae.compute_factor_vae": [[30, 101], ["gin.configurable", "absl.logging.info", "factor_vae._compute_variances", "factor_vae._prune_dims", "absl.logging.info", "factor_vae._generate_training_batch", "numpy.argmax", "numpy.arange", "absl.logging.info", "absl.logging.info", "absl.logging.info", "factor_vae._generate_training_batch", "absl.logging.info", "absl.logging.info", "len", "_prune_dims.any", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.factor_vae._compute_variances", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.factor_vae._prune_dims", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.beta_vae._generate_training_batch", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.beta_vae._generate_training_batch"], ["@", "gin", ".", "configurable", "(", "\n", "\"factor_vae_score\"", ",", "\n", "blacklist", "=", "[", "\"ground_truth_data\"", ",", "\"representation_function\"", ",", "\"random_state\"", ",", "\n", "\"artifact_dir\"", "]", ")", "\n", "def", "compute_factor_vae", "(", "ground_truth_data", ",", "\n", "representation_function", ",", "\n", "random_state", ",", "\n", "artifact_dir", "=", "None", ",", "\n", "batch_size", "=", "gin", ".", "REQUIRED", ",", "\n", "num_train", "=", "gin", ".", "REQUIRED", ",", "\n", "num_eval", "=", "gin", ".", "REQUIRED", ",", "\n", "num_variance_estimate", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "  ", "\"\"\"Computes the FactorVAE disentanglement metric.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    random_state: Numpy random state used for randomness.\n    artifact_dir: Optional path to directory where artifacts can be saved.\n    batch_size: Number of points to be used to compute the training_sample.\n    num_train: Number of points used for training.\n    num_eval: Number of points used for evaluation.\n    num_variance_estimate: Number of points used to estimate global variances.\n\n  Returns:\n    Dictionary with scores:\n      train_accuracy: Accuracy on training set.\n      eval_accuracy: Accuracy on evaluation set.\n  \"\"\"", "\n", "del", "artifact_dir", "\n", "logging", ".", "info", "(", "\"Computing global variances to standardise.\"", ")", "\n", "global_variances", "=", "_compute_variances", "(", "ground_truth_data", ",", "\n", "representation_function", ",", "\n", "num_variance_estimate", ",", "random_state", ")", "\n", "active_dims", "=", "_prune_dims", "(", "global_variances", ")", "\n", "scores_dict", "=", "{", "}", "\n", "\n", "if", "not", "active_dims", ".", "any", "(", ")", ":", "\n", "    ", "scores_dict", "[", "\"train_accuracy\"", "]", "=", "0.", "\n", "scores_dict", "[", "\"eval_accuracy\"", "]", "=", "0.", "\n", "scores_dict", "[", "\"num_active_dims\"", "]", "=", "0", "\n", "return", "scores_dict", "\n", "\n", "", "logging", ".", "info", "(", "\"Generating training set.\"", ")", "\n", "training_votes", "=", "_generate_training_batch", "(", "ground_truth_data", ",", "\n", "representation_function", ",", "batch_size", ",", "\n", "num_train", ",", "random_state", ",", "\n", "global_variances", ",", "active_dims", ")", "\n", "classifier", "=", "np", ".", "argmax", "(", "training_votes", ",", "axis", "=", "0", ")", "\n", "other_index", "=", "np", ".", "arange", "(", "training_votes", ".", "shape", "[", "1", "]", ")", "\n", "\n", "logging", ".", "info", "(", "\"Evaluate training set accuracy.\"", ")", "\n", "train_accuracy", "=", "np", ".", "sum", "(", "\n", "training_votes", "[", "classifier", ",", "other_index", "]", ")", "*", "1.", "/", "np", ".", "sum", "(", "training_votes", ")", "\n", "logging", ".", "info", "(", "\"Training set accuracy: %.2g\"", ",", "train_accuracy", ")", "\n", "\n", "logging", ".", "info", "(", "\"Generating evaluation set.\"", ")", "\n", "eval_votes", "=", "_generate_training_batch", "(", "ground_truth_data", ",", "\n", "representation_function", ",", "batch_size", ",", "\n", "num_eval", ",", "random_state", ",", "\n", "global_variances", ",", "active_dims", ")", "\n", "\n", "logging", ".", "info", "(", "\"Evaluate evaluation set accuracy.\"", ")", "\n", "eval_accuracy", "=", "np", ".", "sum", "(", "eval_votes", "[", "classifier", ",", "\n", "other_index", "]", ")", "*", "1.", "/", "np", ".", "sum", "(", "eval_votes", ")", "\n", "logging", ".", "info", "(", "\"Evaluation set accuracy: %.2g\"", ",", "eval_accuracy", ")", "\n", "scores_dict", "[", "\"train_accuracy\"", "]", "=", "train_accuracy", "\n", "scores_dict", "[", "\"eval_accuracy\"", "]", "=", "eval_accuracy", "\n", "scores_dict", "[", "\"num_active_dims\"", "]", "=", "len", "(", "active_dims", ")", "\n", "return", "scores_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.factor_vae._prune_dims": [[103, 108], ["gin.configurable", "numpy.sqrt"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"prune_dims\"", ",", "blacklist", "=", "[", "\"variances\"", "]", ")", "\n", "def", "_prune_dims", "(", "variances", ",", "threshold", "=", "0.", ")", ":", "\n", "  ", "\"\"\"Mask for dimensions collapsed to the prior.\"\"\"", "\n", "scale_z", "=", "np", ".", "sqrt", "(", "variances", ")", "\n", "return", "scale_z", ">=", "threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.factor_vae._compute_variances": [[110, 135], ["ground_truth_data.sample_observations", "disentanglement_lib.evaluation.metrics.utils.obtain_representation", "numpy.transpose", "numpy.var"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.ground_truth_data.GroundTruthData.sample_observations", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.obtain_representation"], ["", "def", "_compute_variances", "(", "ground_truth_data", ",", "\n", "representation_function", ",", "\n", "batch_size", ",", "\n", "random_state", ",", "\n", "eval_batch_size", "=", "64", ")", ":", "\n", "  ", "\"\"\"Computes the variance for each dimension of the representation.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observation as input and\n      outputs a representation.\n    batch_size: Number of points to be used to compute the variances.\n    random_state: Numpy random state used for randomness.\n    eval_batch_size: Batch size used to eval representation.\n\n  Returns:\n    Vector with the variance of each dimension.\n  \"\"\"", "\n", "observations", "=", "ground_truth_data", ".", "sample_observations", "(", "batch_size", ",", "random_state", ")", "\n", "representations", "=", "utils", ".", "obtain_representation", "(", "observations", ",", "\n", "representation_function", ",", "\n", "eval_batch_size", ")", "\n", "representations", "=", "np", ".", "transpose", "(", "representations", ")", "\n", "assert", "representations", ".", "shape", "[", "0", "]", "==", "batch_size", "\n", "return", "np", ".", "var", "(", "representations", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.factor_vae._generate_training_sample": [[137, 170], ["random_state.randint", "ground_truth_data.sample_factors", "ground_truth_data.sample_observations_from_factors", "representation_function", "numpy.var", "numpy.argmin"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors"], ["", "def", "_generate_training_sample", "(", "ground_truth_data", ",", "representation_function", ",", "\n", "batch_size", ",", "random_state", ",", "global_variances", ",", "\n", "active_dims", ")", ":", "\n", "  ", "\"\"\"Sample a single training sample based on a mini-batch of ground-truth data.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observation as input and\n      outputs a representation.\n    batch_size: Number of points to be used to compute the training_sample.\n    random_state: Numpy random state used for randomness.\n    global_variances: Numpy vector with variances for all dimensions of\n      representation.\n    active_dims: Indexes of active dimensions.\n\n  Returns:\n    factor_index: Index of factor coordinate to be used.\n    argmin: Index of representation coordinate with the least variance.\n  \"\"\"", "\n", "# Select random coordinate to keep fixed.", "\n", "factor_index", "=", "random_state", ".", "randint", "(", "ground_truth_data", ".", "num_factors", ")", "\n", "# Sample two mini batches of latent variables.", "\n", "factors", "=", "ground_truth_data", ".", "sample_factors", "(", "batch_size", ",", "random_state", ")", "\n", "# Fix the selected factor across mini-batch.", "\n", "factors", "[", ":", ",", "factor_index", "]", "=", "factors", "[", "0", ",", "factor_index", "]", "\n", "# Obtain the observations.", "\n", "observations", "=", "ground_truth_data", ".", "sample_observations_from_factors", "(", "\n", "factors", ",", "random_state", ")", "\n", "representations", "=", "representation_function", "(", "observations", ")", "\n", "local_variances", "=", "np", ".", "var", "(", "representations", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "argmin", "=", "np", ".", "argmin", "(", "local_variances", "[", "active_dims", "]", "/", "\n", "global_variances", "[", "active_dims", "]", ")", "\n", "return", "factor_index", ",", "argmin", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.factor_vae._generate_training_batch": [[172, 201], ["numpy.zeros", "six.moves.range", "factor_vae._generate_training_sample"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.beta_vae._generate_training_sample"], ["", "def", "_generate_training_batch", "(", "ground_truth_data", ",", "representation_function", ",", "\n", "batch_size", ",", "num_points", ",", "random_state", ",", "\n", "global_variances", ",", "active_dims", ")", ":", "\n", "  ", "\"\"\"Sample a set of training samples based on a batch of ground-truth data.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    batch_size: Number of points to be used to compute the training_sample.\n    num_points: Number of points to be sampled for training set.\n    random_state: Numpy random state used for randomness.\n    global_variances: Numpy vector with variances for all dimensions of\n      representation.\n    active_dims: Indexes of active dimensions.\n\n  Returns:\n    (num_factors, dim_representation)-sized numpy array with votes.\n  \"\"\"", "\n", "votes", "=", "np", ".", "zeros", "(", "(", "ground_truth_data", ".", "num_factors", ",", "global_variances", ".", "shape", "[", "0", "]", ")", ",", "\n", "dtype", "=", "np", ".", "int64", ")", "\n", "for", "_", "in", "range", "(", "num_points", ")", ":", "\n", "    ", "factor_index", ",", "argmin", "=", "_generate_training_sample", "(", "ground_truth_data", ",", "\n", "representation_function", ",", "\n", "batch_size", ",", "random_state", ",", "\n", "global_variances", ",", "\n", "active_dims", ")", "\n", "votes", "[", "factor_index", ",", "argmin", "]", "+=", "1", "\n", "", "return", "votes", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.irs_test.IrsTest.test_metric": [[35, 45], ["gin.bind_parameter", "gin.bind_parameter", "disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.irs.compute_irs", "irs_test.IrsTest.assertBetween", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.irs.compute_irs"], ["  ", "def", "test_metric", "(", "self", ")", ":", "\n", "    ", "gin", ".", "bind_parameter", "(", "\"discretizer.discretizer_fn\"", ",", "_identity_discretizer", ")", "\n", "gin", ".", "bind_parameter", "(", "\"discretizer.num_bins\"", ",", "10", ")", "\n", "\n", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "representation_function", "=", "lambda", "x", ":", "np", ".", "array", "(", "x", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "irs", ".", "compute_irs", "(", "ground_truth_data", ",", "representation_function", ",", "\n", "random_state", ",", "None", ",", "0.99", ",", "3000", ",", "3000", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"IRS\"", "]", ",", "0.9", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.irs_test.IrsTest.test_bad_metric": [[46, 56], ["gin.bind_parameter", "gin.bind_parameter", "disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.irs.compute_irs", "irs_test.IrsTest.assertBetween", "numpy.zeros_like"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.irs.compute_irs"], ["", "def", "test_bad_metric", "(", "self", ")", ":", "\n", "    ", "gin", ".", "bind_parameter", "(", "\"discretizer.discretizer_fn\"", ",", "_identity_discretizer", ")", "\n", "gin", ".", "bind_parameter", "(", "\"discretizer.num_bins\"", ",", "10", ")", "\n", "\n", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "representation_function", "=", "lambda", "x", ":", "np", ".", "zeros_like", "(", "x", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "irs", ".", "compute_irs", "(", "ground_truth_data", ",", "representation_function", ",", "\n", "random_state", ",", "None", ",", "0.99", ",", "3000", ",", "3000", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"IRS\"", "]", ",", "0.0", ",", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.irs_test.IrsTest.test_drop_constant_dims": [[57, 64], ["numpy.random.RandomState", "numpy.random.RandomState.normal", "disentanglement_lib.evaluation.metrics.irs._drop_constant_dims", "numpy.testing.assert_array_equal"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.irs._drop_constant_dims"], ["", "def", "test_drop_constant_dims", "(", "self", ")", ":", "\n", "    ", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "ys", "=", "random_state", ".", "normal", "(", "0.0", ",", "1.0", ",", "(", "100", ",", "100", ")", ")", "\n", "ys", "[", "0", ",", ":", "]", "=", "1.", "\n", "ys", "[", "-", "1", ",", ":", "]", "=", "0.", "\n", "active_ys", "=", "irs", ".", "_drop_constant_dims", "(", "ys", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "active_ys", ",", "ys", "[", "1", ":", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.irs_test._identity_discretizer": [[28, 31], ["None"], "function", ["None"], ["def", "_identity_discretizer", "(", "target", ",", "num_bins", ")", ":", "\n", "  ", "del", "num_bins", "\n", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.fairness_test.FairnessTest.test_metric": [[34, 43], ["gin.bind_parameter", "disentanglement_lib.data.ground_truth.dummy_data.DummyData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.fairness.compute_fairness", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.fairness.compute_fairness"], ["  ", "def", "test_metric", "(", "self", ")", ":", "\n", "    ", "gin", ".", "bind_parameter", "(", "\"predictor.predictor_fn\"", ",", "\n", "utils", ".", "gradient_boosting_classifier", ")", "\n", "ground_truth_data", "=", "dummy_data", ".", "DummyData", "(", ")", "\n", "def", "representation_function", "(", "x", ")", ":", "\n", "      ", "return", "np", ".", "array", "(", "x", ",", "dtype", "=", "np", ".", "float64", ")", "[", ":", ",", ":", ",", "0", ",", "0", "]", "\n", "", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "_", "=", "fairness", ".", "compute_fairness", "(", "ground_truth_data", ",", "representation_function", ",", "\n", "random_state", ",", "None", ",", "1000", ",", "1000", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.fairness_test.FairnessTest.test_inter_group_fairness": [[44, 54], ["numpy.array", "disentanglement_lib.evaluation.metrics.fairness.inter_group_fairness", "fairness_test.FairnessTest.assertAlmostEqual", "fairness_test.FairnessTest.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.fairness.inter_group_fairness"], ["", "def", "test_inter_group_fairness", "(", "self", ")", ":", "\n", "    ", "counts", "=", "np", ".", "array", "(", "[", "[", "0", ",", "100", "]", ",", "[", "100", ",", "100", "]", "]", ")", "\n", "mean_fairness", ",", "max_fairness", "=", "fairness", ".", "inter_group_fairness", "(", "counts", ")", "\n", "# The overall distribution is 1/3 to 2/3.", "\n", "# The first sensitive class has a distribution of 0 to 1.", "\n", "# The second sensitive class has a distribution of 1/2 to 1/2.", "\n", "# The total variation distances are hence 1/3 and 1/6 respectively.", "\n", "# The mean fairness is hence 1/3*1/3 + 2/3*1/6 = 2/9.", "\n", "self", ".", "assertAlmostEqual", "(", "mean_fairness", ",", "2.", "/", "9.", ")", "\n", "self", ".", "assertAlmostEqual", "(", "max_fairness", ",", "1", "/", "3.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.fairness_test.FairnessTest.test_compute_scores_dict": [[55, 91], ["numpy.array", "disentanglement_lib.evaluation.metrics.fairness.compute_scores_dict", "fairness_test.FairnessTest.assertDictEqual"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.fairness.compute_scores_dict"], ["", "def", "test_compute_scores_dict", "(", "self", ")", ":", "\n", "    ", "scores", "=", "np", ".", "array", "(", "[", "[", "0.", ",", "2.", ",", "4.", "]", ",", "[", "4.", ",", "0.", ",", "8.", "]", ",", "[", "2.", ",", "10.", ",", "0.", "]", "]", ")", "\n", "results", "=", "fairness", ".", "compute_scores_dict", "(", "scores", ",", "\"test\"", ")", "\n", "shouldbe", "=", "{", "\n", "# Single scores.", "\n", "\"test:pred0:sens1\"", ":", "2.", ",", "\n", "\"test:pred0:sens2\"", ":", "4.", ",", "\n", "\"test:pred1:sens0\"", ":", "4.", ",", "\n", "\"test:pred1:sens2\"", ":", "8.", ",", "\n", "\"test:pred2:sens0\"", ":", "2.", ",", "\n", "\"test:pred2:sens1\"", ":", "10.", ",", "\n", "# Column scores.", "\n", "\"test:pred0:mean_sens\"", ":", "3.", ",", "\n", "\"test:pred0:max_sens\"", ":", "4.", ",", "\n", "\"test:pred1:mean_sens\"", ":", "6.", ",", "\n", "\"test:pred1:max_sens\"", ":", "8.", ",", "\n", "\"test:pred2:mean_sens\"", ":", "6.", ",", "\n", "\"test:pred2:max_sens\"", ":", "10.", ",", "\n", "# Column scores.", "\n", "\"test:sens0:mean_pred\"", ":", "3.", ",", "\n", "\"test:sens0:max_pred\"", ":", "4.", ",", "\n", "\"test:sens1:mean_pred\"", ":", "6.", ",", "\n", "\"test:sens1:max_pred\"", ":", "10.", ",", "\n", "\"test:sens2:mean_pred\"", ":", "6.", ",", "\n", "\"test:sens2:max_pred\"", ":", "8.", ",", "\n", "# All scores.", "\n", "\"test:mean_sens:mean_pred\"", ":", "5.", ",", "\n", "\"test:mean_sens:max_pred\"", ":", "22.", "/", "3.", ",", "\n", "\"test:max_sens:mean_pred\"", ":", "6.", ",", "\n", "\"test:max_sens:max_pred\"", ":", "10.", ",", "\n", "\"test:mean_pred:mean_sens\"", ":", "5.", ",", "\n", "\"test:mean_pred:max_sens\"", ":", "22.", "/", "3.", ",", "\n", "\"test:max_pred:mean_sens\"", ":", "6.", ",", "\n", "\"test:max_pred:max_sens\"", ":", "10.", ",", "\n", "}", "\n", "self", ".", "assertDictEqual", "(", "shouldbe", ",", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci_test.DisentanglementTest.test_diagonal": [[33, 37], ["numpy.diag", "disentanglement_lib.evaluation.metrics.dci.disentanglement", "numpy.testing.assert_allclose", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.disentanglement"], ["  ", "def", "test_diagonal", "(", "self", ")", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "diag", "(", "5.", "*", "np", ".", "ones", "(", "5", ")", ")", "\n", "result", "=", "dci", ".", "disentanglement", "(", "importance_matrix", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci_test.DisentanglementTest.test_diagonal_empty_codes": [[38, 42], ["numpy.array", "disentanglement_lib.evaluation.metrics.dci.disentanglement", "numpy.testing.assert_allclose"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.disentanglement"], ["", "def", "test_diagonal_empty_codes", "(", "self", ")", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "array", "(", "[", "[", "1.", ",", "0.", ",", "]", ",", "[", "0.", ",", "1.", "]", ",", "[", "0.", ",", "0.", "]", "]", ")", "\n", "result", "=", "dci", ".", "disentanglement", "(", "importance_matrix", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci_test.DisentanglementTest.test_zero": [[43, 47], ["numpy.zeros", "disentanglement_lib.evaluation.metrics.dci.disentanglement", "numpy.testing.assert_allclose"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.disentanglement"], ["", "def", "test_zero", "(", "self", ")", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "zeros", "(", "shape", "=", "[", "10", ",", "10", "]", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "result", "=", "dci", ".", "disentanglement", "(", "importance_matrix", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", ".0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci_test.DisentanglementTest.test_redundant_codes": [[48, 53], ["numpy.diag", "numpy.vstack", "disentanglement_lib.evaluation.metrics.dci.disentanglement", "numpy.testing.assert_allclose", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.disentanglement"], ["", "def", "test_redundant_codes", "(", "self", ")", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "diag", "(", "5.", "*", "np", ".", "ones", "(", "5", ")", ")", "\n", "importance_matrix", "=", "np", ".", "vstack", "(", "[", "importance_matrix", ",", "importance_matrix", "]", ")", "\n", "result", "=", "dci", ".", "disentanglement", "(", "importance_matrix", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", "1.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci_test.DisentanglementTest.test_missed_factors": [[54, 58], ["numpy.diag", "disentanglement_lib.evaluation.metrics.dci.disentanglement", "numpy.testing.assert_allclose", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.disentanglement"], ["", "def", "test_missed_factors", "(", "self", ")", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "diag", "(", "5.", "*", "np", ".", "ones", "(", "5", ")", ")", "\n", "result", "=", "dci", ".", "disentanglement", "(", "importance_matrix", "[", ":", "2", ",", ":", "]", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci_test.DisentanglementTest.test_one_code_two_factors": [[59, 64], ["numpy.diag", "numpy.hstack", "disentanglement_lib.evaluation.metrics.dci.disentanglement", "numpy.testing.assert_allclose", "numpy.ones", "numpy.log", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.disentanglement"], ["", "def", "test_one_code_two_factors", "(", "self", ")", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "diag", "(", "5.", "*", "np", ".", "ones", "(", "5", ")", ")", "\n", "importance_matrix", "=", "np", ".", "hstack", "(", "[", "importance_matrix", ",", "importance_matrix", "]", ")", "\n", "result", "=", "dci", ".", "disentanglement", "(", "importance_matrix", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", "1.", "-", "np", ".", "log", "(", "2", ")", "/", "np", ".", "log", "(", "10", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci_test.CompletenessTest.test_diagonal": [[68, 72], ["numpy.diag", "disentanglement_lib.evaluation.metrics.dci.completeness", "numpy.testing.assert_allclose", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.completeness"], ["  ", "def", "test_diagonal", "(", "self", ")", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "diag", "(", "5.", "*", "np", ".", "ones", "(", "5", ")", ")", "\n", "result", "=", "dci", ".", "completeness", "(", "importance_matrix", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci_test.CompletenessTest.test_diagonal_empty_codes": [[73, 77], ["numpy.array", "disentanglement_lib.evaluation.metrics.dci.completeness", "numpy.testing.assert_allclose"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.completeness"], ["", "def", "test_diagonal_empty_codes", "(", "self", ")", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "array", "(", "[", "[", "1.", ",", "0.", ",", "]", ",", "[", "0.", ",", "1.", "]", ",", "[", "0.", ",", "0.", "]", "]", ")", "\n", "result", "=", "dci", ".", "completeness", "(", "importance_matrix", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci_test.CompletenessTest.test_zero": [[78, 82], ["numpy.zeros", "disentanglement_lib.evaluation.metrics.dci.completeness", "numpy.testing.assert_allclose"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.completeness"], ["", "def", "test_zero", "(", "self", ")", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "zeros", "(", "shape", "=", "[", "10", ",", "10", "]", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "result", "=", "dci", ".", "completeness", "(", "importance_matrix", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", ".0", ",", "atol", "=", "1e-7", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci_test.CompletenessTest.test_redundant_codes": [[83, 88], ["numpy.diag", "numpy.vstack", "disentanglement_lib.evaluation.metrics.dci.completeness", "numpy.testing.assert_allclose", "numpy.ones", "numpy.log", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.completeness"], ["", "def", "test_redundant_codes", "(", "self", ")", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "diag", "(", "5.", "*", "np", ".", "ones", "(", "5", ")", ")", "\n", "importance_matrix", "=", "np", ".", "vstack", "(", "[", "importance_matrix", ",", "importance_matrix", "]", ")", "\n", "result", "=", "dci", ".", "completeness", "(", "importance_matrix", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", "1.", "-", "np", ".", "log", "(", "2", ")", "/", "np", ".", "log", "(", "10", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci_test.CompletenessTest.test_missed_factors": [[89, 93], ["numpy.diag", "disentanglement_lib.evaluation.metrics.dci.completeness", "numpy.testing.assert_allclose", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.completeness"], ["", "def", "test_missed_factors", "(", "self", ")", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "diag", "(", "5.", "*", "np", ".", "ones", "(", "5", ")", ")", "\n", "result", "=", "dci", ".", "completeness", "(", "importance_matrix", "[", ":", "2", ",", ":", "]", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci_test.CompletenessTest.test_one_code_two_factors": [[94, 99], ["numpy.diag", "numpy.hstack", "disentanglement_lib.evaluation.metrics.dci.completeness", "numpy.testing.assert_allclose", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.completeness"], ["", "def", "test_one_code_two_factors", "(", "self", ")", ":", "\n", "    ", "importance_matrix", "=", "np", ".", "diag", "(", "5.", "*", "np", ".", "ones", "(", "5", ")", ")", "\n", "importance_matrix", "=", "np", ".", "hstack", "(", "[", "importance_matrix", ",", "importance_matrix", "]", ")", "\n", "result", "=", "dci", ".", "completeness", "(", "importance_matrix", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", "1.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci_test.DCITest.test_metric": [[103, 112], ["disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.dci.compute_dci", "dci_test.DCITest.assertBetween", "dci_test.DCITest.assertBetween", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.compute_dci"], ["  ", "def", "test_metric", "(", "self", ")", ":", "\n", "    ", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "representation_function", "=", "lambda", "x", ":", "np", ".", "array", "(", "x", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "dci", ".", "compute_dci", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "1000", ",", "\n", "1000", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"disentanglement\"", "]", ",", "0.9", ",", "1.0", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"completeness\"", "]", ",", "0.9", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci_test.DCITest.test_bad_metric": [[113, 129], ["disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.dci.compute_dci", "dci_test.DCITest.assertBetween", "dci_test.DCITest.assertBetween", "numpy.array", "six.moves.range", "numpy.random.RandomState.permutation"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.compute_dci"], ["", "def", "test_bad_metric", "(", "self", ")", ":", "\n", "    ", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "random_state_rep", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "# The representation which randomly permutes the factors, should have equal", "\n", "# non-zero importance which should give a low modularity score.", "\n", "def", "representation_function", "(", "x", ")", ":", "\n", "      ", "code", "=", "np", ".", "array", "(", "x", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "for", "i", "in", "range", "(", "code", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "code", "[", "i", ",", ":", "]", "=", "random_state_rep", ".", "permutation", "(", "code", "[", "i", ",", ":", "]", ")", "\n", "", "return", "code", "\n", "", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "dci", ".", "compute_dci", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "1000", ",", "\n", "1000", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"disentanglement\"", "]", ",", "0.0", ",", "0.2", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"completeness\"", "]", ",", "0.0", ",", "0.2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci_test.DCITest.test_duplicated_latent_space": [[130, 142], ["disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.dci.compute_dci", "dci_test.DCITest.assertBetween", "dci_test.DCITest.assertBetween", "numpy.array", "numpy.hstack", "numpy.log", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.compute_dci"], ["", "def", "test_duplicated_latent_space", "(", "self", ")", ":", "\n", "    ", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "def", "representation_function", "(", "x", ")", ":", "\n", "      ", "x", "=", "np", ".", "array", "(", "x", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "return", "np", ".", "hstack", "(", "[", "x", ",", "x", "]", ")", "\n", "", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "dci", ".", "compute_dci", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "1000", ",", "\n", "1000", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"disentanglement\"", "]", ",", "0.9", ",", "1.0", ")", "\n", "target", "=", "1.", "-", "np", ".", "log", "(", "2", ")", "/", "np", ".", "log", "(", "10", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"completeness\"", "]", ",", "target", "-", ".1", ",", "target", "+", ".1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.fairness.compute_fairness": [[37, 114], ["gin.configurable", "len", "disentanglement_lib.evaluation.metrics.utils.generate_batch_factor_code", "disentanglement_lib.evaluation.metrics.utils.make_predictor_fn", "numpy.zeros", "numpy.zeros", "six.moves.range", "scores.update", "scores.update", "utils.make_predictor_fn.", "predictor_model_fn.fit", "six.moves.range", "fairness.compute_scores_dict", "fairness.compute_scores_dict", "numpy.transpose", "ground_truth_data.sample_factors", "numpy.zeros", "six.moves.range", "fairness.inter_group_fairness", "numpy.copy", "ground_truth_data.sample_observations_from_factors", "disentanglement_lib.evaluation.metrics.utils.obtain_representation", "predictor_model_fn.predict", "numpy.bincount", "numpy.transpose"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.generate_batch_factor_code", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.make_predictor_fn", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.fairness.compute_scores_dict", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.fairness.compute_scores_dict", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.fairness.inter_group_fairness", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.obtain_representation"], ["@", "gin", ".", "configurable", "(", "\n", "\"fairness\"", ",", "\n", "blacklist", "=", "[", "\"ground_truth_data\"", ",", "\"representation_function\"", ",", "\"random_state\"", ",", "\n", "\"artifact_dir\"", "]", ")", "\n", "def", "compute_fairness", "(", "ground_truth_data", ",", "\n", "representation_function", ",", "\n", "random_state", ",", "\n", "artifact_dir", "=", "None", ",", "\n", "num_train", "=", "gin", ".", "REQUIRED", ",", "\n", "num_test_points_per_class", "=", "gin", ".", "REQUIRED", ",", "\n", "batch_size", "=", "16", ")", ":", "\n", "  ", "\"\"\"Computes unfairness scores.\n\n  We first compute either the mean or maximum total variation for a given\n  sensitive and target variable. Then, we either average or take the maximum\n  with respect to target and sensitive variable. For convenience, we compute and\n  save all combinations. The score used in Section 4 of the paper is here called\n  mean_fairness:mean_pred:mean_sens.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    random_state: Numpy random state used for randomness.\n    artifact_dir: Optional path to directory where artifacts can be saved.\n    num_train: Number of points used for training.\n    num_test_points_per_class: Number of points used for testing.\n    batch_size: Batch size for sampling.\n\n  Returns:\n    Dictionary with scores.\n  \"\"\"", "\n", "del", "artifact_dir", "\n", "factor_counts", "=", "ground_truth_data", ".", "factors_num_values", "\n", "num_factors", "=", "len", "(", "factor_counts", ")", "\n", "\n", "scores", "=", "{", "}", "\n", "# Training a predictive model.", "\n", "mus_train", ",", "ys_train", "=", "utils", ".", "generate_batch_factor_code", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "num_train", ",", "random_state", ",", "\n", "batch_size", ")", "\n", "predictor_model_fn", "=", "utils", ".", "make_predictor_fn", "(", ")", "\n", "\n", "# For each factor train a single predictive model.", "\n", "mean_fairness", "=", "np", ".", "zeros", "(", "(", "num_factors", ",", "num_factors", ")", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "max_fairness", "=", "np", ".", "zeros", "(", "(", "num_factors", ",", "num_factors", ")", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "for", "i", "in", "range", "(", "num_factors", ")", ":", "\n", "    ", "model", "=", "predictor_model_fn", "(", ")", "\n", "model", ".", "fit", "(", "np", ".", "transpose", "(", "mus_train", ")", ",", "ys_train", "[", "i", ",", ":", "]", ")", "\n", "\n", "for", "j", "in", "range", "(", "num_factors", ")", ":", "\n", "      ", "if", "i", "==", "j", ":", "\n", "        ", "continue", "\n", "# Sample a random set of factors once.", "\n", "", "original_factors", "=", "ground_truth_data", ".", "sample_factors", "(", "\n", "num_test_points_per_class", ",", "random_state", ")", "\n", "counts", "=", "np", ".", "zeros", "(", "(", "factor_counts", "[", "i", "]", ",", "factor_counts", "[", "j", "]", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "for", "c", "in", "range", "(", "factor_counts", "[", "j", "]", ")", ":", "\n", "# Intervene on the sensitive attribute.", "\n", "        ", "intervened_factors", "=", "np", ".", "copy", "(", "original_factors", ")", "\n", "intervened_factors", "[", ":", ",", "j", "]", "=", "c", "\n", "# Obtain the batched observations.", "\n", "observations", "=", "ground_truth_data", ".", "sample_observations_from_factors", "(", "\n", "intervened_factors", ",", "random_state", ")", "\n", "representations", "=", "utils", ".", "obtain_representation", "(", "observations", ",", "\n", "representation_function", ",", "\n", "batch_size", ")", "\n", "# Get the predictions.", "\n", "predictions", "=", "model", ".", "predict", "(", "np", ".", "transpose", "(", "representations", ")", ")", "\n", "# Update the counts.", "\n", "counts", "[", ":", ",", "c", "]", "=", "np", ".", "bincount", "(", "predictions", ",", "minlength", "=", "factor_counts", "[", "i", "]", ")", "\n", "", "mean_fairness", "[", "i", ",", "j", "]", ",", "max_fairness", "[", "i", ",", "j", "]", "=", "inter_group_fairness", "(", "counts", ")", "\n", "\n", "# Report the scores.", "\n", "", "", "scores", ".", "update", "(", "compute_scores_dict", "(", "mean_fairness", ",", "\"mean_fairness\"", ")", ")", "\n", "scores", ".", "update", "(", "compute_scores_dict", "(", "max_fairness", ",", "\"max_fairness\"", ")", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.fairness.compute_scores_dict": [[116, 171], ["six.moves.range", "six.moves.range", "six.moves.range", "numpy.mean", "numpy.mean", "numpy.amax", "numpy.amax", "numpy.mean", "numpy.mean", "numpy.amax", "numpy.amax", "six.moves.range", "numpy.mean", "numpy.amax", "rows_means.append", "rows_maxs.append", "numpy.mean", "numpy.amax", "column_means.append", "column_maxs.append", "six.moves.range", "six.moves.range"], "function", ["None"], ["", "def", "compute_scores_dict", "(", "metric", ",", "prefix", ")", ":", "\n", "  ", "\"\"\"Computes scores for combinations of predictive and sensitive factors.\n\n  Either average or take the maximum with respect to target and sensitive\n  variable for all combinations of predictive and sensitive factors.\n\n  Args:\n    metric: Matrix of shape [num_factors, num_factors] with fairness scores.\n    prefix: Prefix for the matrix in the returned dictionary.\n\n  Returns:\n    Dictionary containing all combinations of predictive and sensitive factors.\n  \"\"\"", "\n", "result", "=", "{", "}", "\n", "# Report min and max scores for each predictive and sensitive factor.", "\n", "for", "i", "in", "range", "(", "metric", ".", "shape", "[", "0", "]", ")", ":", "\n", "    ", "for", "j", "in", "range", "(", "metric", ".", "shape", "[", "1", "]", ")", ":", "\n", "      ", "if", "i", "!=", "j", ":", "\n", "        ", "result", "[", "\"{}:pred{}:sens{}\"", ".", "format", "(", "prefix", ",", "i", ",", "j", ")", "]", "=", "metric", "[", "i", ",", "j", "]", "\n", "\n", "# Compute mean and max values across rows.", "\n", "", "", "", "rows_means", "=", "[", "]", "\n", "rows_maxs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "metric", ".", "shape", "[", "0", "]", ")", ":", "\n", "    ", "relevant_scores", "=", "[", "metric", "[", "i", ",", "j", "]", "for", "j", "in", "range", "(", "metric", ".", "shape", "[", "1", "]", ")", "if", "i", "!=", "j", "]", "\n", "mean_score", "=", "np", ".", "mean", "(", "relevant_scores", ")", "\n", "max_score", "=", "np", ".", "amax", "(", "relevant_scores", ")", "\n", "result", "[", "\"{}:pred{}:mean_sens\"", ".", "format", "(", "prefix", ",", "i", ")", "]", "=", "mean_score", "\n", "result", "[", "\"{}:pred{}:max_sens\"", ".", "format", "(", "prefix", ",", "i", ")", "]", "=", "max_score", "\n", "rows_means", ".", "append", "(", "mean_score", ")", "\n", "rows_maxs", ".", "append", "(", "max_score", ")", "\n", "\n", "# Compute mean and max values across rows.", "\n", "", "column_means", "=", "[", "]", "\n", "column_maxs", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "metric", ".", "shape", "[", "1", "]", ")", ":", "\n", "    ", "relevant_scores", "=", "[", "metric", "[", "i", ",", "j", "]", "for", "i", "in", "range", "(", "metric", ".", "shape", "[", "0", "]", ")", "if", "i", "!=", "j", "]", "\n", "mean_score", "=", "np", ".", "mean", "(", "relevant_scores", ")", "\n", "max_score", "=", "np", ".", "amax", "(", "relevant_scores", ")", "\n", "result", "[", "\"{}:sens{}:mean_pred\"", ".", "format", "(", "prefix", ",", "j", ")", "]", "=", "mean_score", "\n", "result", "[", "\"{}:sens{}:max_pred\"", ".", "format", "(", "prefix", ",", "j", ")", "]", "=", "max_score", "\n", "column_means", ".", "append", "(", "mean_score", ")", "\n", "column_maxs", ".", "append", "(", "max_score", ")", "\n", "\n", "# Compute all combinations of scores.", "\n", "", "result", "[", "\"{}:mean_sens:mean_pred\"", ".", "format", "(", "prefix", ")", "]", "=", "np", ".", "mean", "(", "column_means", ")", "\n", "result", "[", "\"{}:mean_sens:max_pred\"", ".", "format", "(", "prefix", ")", "]", "=", "np", ".", "mean", "(", "column_maxs", ")", "\n", "result", "[", "\"{}:max_sens:mean_pred\"", ".", "format", "(", "prefix", ")", "]", "=", "np", ".", "amax", "(", "column_means", ")", "\n", "result", "[", "\"{}:max_sens:max_pred\"", ".", "format", "(", "prefix", ")", "]", "=", "np", ".", "amax", "(", "column_maxs", ")", "\n", "result", "[", "\"{}:mean_pred:mean_sens\"", ".", "format", "(", "prefix", ")", "]", "=", "np", ".", "mean", "(", "rows_means", ")", "\n", "result", "[", "\"{}:mean_pred:max_sens\"", ".", "format", "(", "prefix", ")", "]", "=", "np", ".", "mean", "(", "rows_maxs", ")", "\n", "result", "[", "\"{}:max_pred:mean_sens\"", ".", "format", "(", "prefix", ")", "]", "=", "np", ".", "amax", "(", "rows_means", ")", "\n", "result", "[", "\"{}:max_pred:max_sens\"", ".", "format", "(", "prefix", ")", "]", "=", "np", ".", "amax", "(", "rows_maxs", ")", "\n", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.fairness.inter_group_fairness": [[173, 201], ["numpy.sum", "np.sum.sum", "numpy.array", "numpy.sum", "numpy.expand_dims", "np.sum.sum", "numpy.expand_dims", "numpy.sum", "numpy.sum", "numpy.amax", "numpy.abs"], "function", ["None"], ["", "def", "inter_group_fairness", "(", "counts", ")", ":", "\n", "  ", "\"\"\"Computes the inter group fairness for predictions based on the TV distance.\n\n  Args:\n   counts: Numpy array with counts of predictions where rows correspond to\n     predicted classes and columns to sensitive classes.\n\n  Returns:\n    Mean and maximum total variation distance of a sensitive class to the\n      global average.\n  \"\"\"", "\n", "# Compute the distribution of predictions across all sensitive classes.", "\n", "overall_distribution", "=", "np", ".", "sum", "(", "counts", ",", "axis", "=", "1", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "overall_distribution", "/=", "overall_distribution", ".", "sum", "(", ")", "\n", "\n", "# Compute the distribution for each sensitive class.", "\n", "normalized_counts", "=", "np", ".", "array", "(", "counts", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "counts_per_class", "=", "np", ".", "sum", "(", "counts", ",", "axis", "=", "0", ")", "\n", "normalized_counts", "/=", "np", ".", "expand_dims", "(", "counts_per_class", ",", "0", ")", "\n", "\n", "# Compute the differences and sum up for each sensitive class.", "\n", "differences", "=", "normalized_counts", "-", "np", ".", "expand_dims", "(", "overall_distribution", ",", "1", ")", "\n", "total_variation_distances", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "differences", ")", ",", "0", ")", "/", "2.", "\n", "\n", "mean", "=", "(", "total_variation_distances", "*", "counts_per_class", ")", "\n", "mean", "/=", "counts_per_class", ".", "sum", "(", ")", "\n", "\n", "return", "np", ".", "sum", "(", "mean", ")", ",", "np", ".", "amax", "(", "total_variation_distances", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores_test.UnifiedScoreTest.test_metric_mig": [[39, 52], ["gin.bind_parameter", "gin.bind_parameter", "disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.unified_scores.compute_unified_scores", "unified_scores_test.UnifiedScoreTest.assertBetween", "unified_scores_test.UnifiedScoreTest.assertBetween", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.compute_unified_scores"], ["  ", "def", "test_metric_mig", "(", "self", ")", ":", "\n", "    ", "gin", ".", "bind_parameter", "(", "\"discretizer.discretizer_fn\"", ",", "_identity_discretizer", ")", "\n", "gin", ".", "bind_parameter", "(", "\"discretizer.num_bins\"", ",", "10", ")", "\n", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "representation_function", "=", "lambda", "x", ":", "np", ".", "array", "(", "x", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "unified_scores", ".", "compute_unified_scores", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "10000", ",", "\n", "100", ",", "matrix_fns", "=", "[", "unified_scores", ".", "mutual_information_matrix", "]", ")", "\n", "self", ".", "assertBetween", "(", "\n", "scores", "[", "\"mutual_information_matrix.mig\"", "]", ",", "0.9", ",", "1.0", ")", "\n", "self", ".", "assertBetween", "(", "\n", "scores", "[", "\"mutual_information_matrix.modularity\"", "]", ",", "0.9", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores_test.UnifiedScoreTest.test_metric_dci": [[53, 64], ["gin.bind_parameter", "gin.bind_parameter", "disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.unified_scores.compute_unified_scores", "unified_scores_test.UnifiedScoreTest.assertBetween", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.compute_unified_scores"], ["", "def", "test_metric_dci", "(", "self", ")", ":", "\n", "    ", "gin", ".", "bind_parameter", "(", "\"discretizer.discretizer_fn\"", ",", "_identity_discretizer", ")", "\n", "gin", ".", "bind_parameter", "(", "\"discretizer.num_bins\"", ",", "10", ")", "\n", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "representation_function", "=", "lambda", "x", ":", "np", ".", "array", "(", "x", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "unified_scores", ".", "compute_unified_scores", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "10000", ",", "\n", "100", ",", "matrix_fns", "=", "[", "unified_scores", ".", "importance_gbt_matrix", "]", ")", "\n", "self", ".", "assertBetween", "(", "\n", "scores", "[", "\"importance_gbt_matrix.dci_disentanglement\"", "]", ",", "0.9", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores_test.UnifiedScoreTest.test_duplicated_latent_space_mig": [[65, 80], ["gin.bind_parameter", "gin.bind_parameter", "disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.unified_scores.compute_unified_scores", "unified_scores_test.UnifiedScoreTest.assertBetween", "unified_scores_test.UnifiedScoreTest.assertBetween", "numpy.array", "numpy.hstack"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.compute_unified_scores"], ["", "def", "test_duplicated_latent_space_mig", "(", "self", ")", ":", "\n", "    ", "gin", ".", "bind_parameter", "(", "\"discretizer.discretizer_fn\"", ",", "_identity_discretizer", ")", "\n", "gin", ".", "bind_parameter", "(", "\"discretizer.num_bins\"", ",", "10", ")", "\n", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "def", "representation_function", "(", "x", ")", ":", "\n", "      ", "x", "=", "np", ".", "array", "(", "x", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "return", "np", ".", "hstack", "(", "[", "x", ",", "x", "]", ")", "\n", "", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "unified_scores", ".", "compute_unified_scores", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "1000", ",", "\n", "1000", ",", "matrix_fns", "=", "[", "unified_scores", ".", "mutual_information_matrix", "]", ")", "\n", "self", ".", "assertBetween", "(", "\n", "scores", "[", "\"mutual_information_matrix.mig\"", "]", ",", "0.0", ",", "0.2", ")", "\n", "self", ".", "assertBetween", "(", "\n", "scores", "[", "\"mutual_information_matrix.modularity\"", "]", ",", "0.9", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores_test.UnifiedScoreTest.test_duplicated_latent_space_dci": [[81, 94], ["gin.bind_parameter", "gin.bind_parameter", "disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.unified_scores.compute_unified_scores", "unified_scores_test.UnifiedScoreTest.assertBetween", "numpy.array", "numpy.hstack"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.compute_unified_scores"], ["", "def", "test_duplicated_latent_space_dci", "(", "self", ")", ":", "\n", "    ", "gin", ".", "bind_parameter", "(", "\"discretizer.discretizer_fn\"", ",", "_identity_discretizer", ")", "\n", "gin", ".", "bind_parameter", "(", "\"discretizer.num_bins\"", ",", "10", ")", "\n", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "def", "representation_function", "(", "x", ")", ":", "\n", "      ", "x", "=", "np", ".", "array", "(", "x", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "return", "np", ".", "hstack", "(", "[", "x", ",", "x", "]", ")", "\n", "", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "unified_scores", ".", "compute_unified_scores", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "1000", ",", "\n", "1000", ",", "matrix_fns", "=", "[", "unified_scores", ".", "importance_gbt_matrix", "]", ")", "\n", "self", ".", "assertBetween", "(", "\n", "scores", "[", "\"importance_gbt_matrix.dci_disentanglement\"", "]", ",", "0.9", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores_test.UnifiedScoreTest.test_duplicated_latent_space_sap": [[95, 107], ["gin.bind_parameter", "gin.bind_parameter", "disentanglement_lib.data.ground_truth.dummy_data.IdentityObservationsData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.unified_scores.compute_unified_scores", "unified_scores_test.UnifiedScoreTest.assertBetween", "numpy.array", "numpy.hstack"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.compute_unified_scores"], ["", "def", "test_duplicated_latent_space_sap", "(", "self", ")", ":", "\n", "    ", "gin", ".", "bind_parameter", "(", "\"discretizer.discretizer_fn\"", ",", "_identity_discretizer", ")", "\n", "gin", ".", "bind_parameter", "(", "\"discretizer.num_bins\"", ",", "10", ")", "\n", "ground_truth_data", "=", "dummy_data", ".", "IdentityObservationsData", "(", ")", "\n", "def", "representation_function", "(", "x", ")", ":", "\n", "      ", "x", "=", "np", ".", "array", "(", "x", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "return", "np", ".", "hstack", "(", "[", "x", ",", "x", "]", ")", "\n", "", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "unified_scores", ".", "compute_unified_scores", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "None", ",", "1000", ",", "\n", "1000", ",", "matrix_fns", "=", "[", "unified_scores", ".", "accuracy_svm_matrix", "]", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"accuracy_svm_matrix.sap\"", "]", ",", "0.0", ",", "0.2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores_test._identity_discretizer": [[32, 35], ["None"], "function", ["None"], ["def", "_identity_discretizer", "(", "target", ",", "num_bins", ")", ":", "\n", "  ", "del", "num_bins", "\n", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.strong_downstream_task_test.StrongDownstreamTaskTest.test_intervene": [[40, 57], ["disentanglement_lib.data.ground_truth.dummy_data.DummyData", "numpy.random.RandomState", "disentanglement_lib.data.ground_truth.dummy_data.DummyData.sample_factors", "disentanglement_lib.data.ground_truth.dummy_data.DummyData.sample_factors", "range", "disentanglement_lib.evaluation.metrics.strong_downstream_task.intervene", "dummy_data.DummyData.sample_factors.copy", "dummy_data.DummyData.sample_factors.copy"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.strong_downstream_task.intervene"], ["  ", "def", "test_intervene", "(", "self", ")", ":", "\n", "    ", "ground_truth_data", "=", "dummy_data", ".", "DummyData", "(", ")", "\n", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "\n", "ys_train", "=", "ground_truth_data", ".", "sample_factors", "(", "1000", ",", "random_state", ")", "\n", "ys_test", "=", "ground_truth_data", ".", "sample_factors", "(", "1000", ",", "random_state", ")", "\n", "num_factors", "=", "ys_train", ".", "shape", "[", "1", "]", "\n", "for", "i", "in", "range", "(", "num_factors", ")", ":", "\n", "      ", "(", "y_train_int", ",", "y_test_int", ",", "interv_factor", ",", "\n", "factor_interv_train", ")", "=", "strong_downstream_task", ".", "intervene", "(", "\n", "ys_train", ".", "copy", "(", ")", ",", "ys_test", ".", "copy", "(", ")", ",", "i", ",", "num_factors", ",", "ground_truth_data", ")", "\n", "assert", "interv_factor", "!=", "i", ",", "\"Wrong factor interevened on.\"", "\n", "assert", "(", "y_train_int", "[", ":", ",", "interv_factor", "]", "==", "factor_interv_train", "\n", ")", ".", "all", "(", ")", ",", "\"Training set not intervened on.\"", "\n", "assert", "(", "y_test_int", "[", ":", ",", "interv_factor", "]", "!=", "factor_interv_train", "\n", ")", ".", "all", "(", ")", ",", "\"Training set not intervened on.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.strong_downstream_task_test.StrongDownstreamTaskTest.test_task": [[58, 75], ["gin.bind_parameter", "gin.bind_parameter", "gin.bind_parameter", "gin.bind_parameter", "disentanglement_lib.data.ground_truth.dummy_data.DummyData", "numpy.random.RandomState", "disentanglement_lib.evaluation.metrics.strong_downstream_task.compute_strong_downstream_task", "strong_downstream_task_test.StrongDownstreamTaskTest.assertBetween", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.strong_downstream_task.compute_strong_downstream_task"], ["", "", "def", "test_task", "(", "self", ")", ":", "\n", "    ", "gin", ".", "bind_parameter", "(", "\"predictor.predictor_fn\"", ",", "\n", "utils", ".", "gradient_boosting_classifier", ")", "\n", "gin", ".", "bind_parameter", "(", "\"strong_downstream_task.num_train\"", ",", "\n", "[", "1000", "]", ")", "\n", "gin", ".", "bind_parameter", "(", "\"strong_downstream_task.num_test\"", ",", "\n", "1000", ")", "\n", "gin", ".", "bind_parameter", "(", "\"strong_downstream_task.n_experiment\"", ",", "\n", "2", ")", "\n", "ground_truth_data", "=", "dummy_data", ".", "DummyData", "(", ")", "\n", "def", "representation_function", "(", "x", ")", ":", "\n", "      ", "return", "np", ".", "array", "(", "x", ",", "dtype", "=", "np", ".", "float64", ")", "[", ":", ",", ":", ",", "0", ",", "0", "]", "\n", "", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "scores", "=", "strong_downstream_task", ".", "compute_strong_downstream_task", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "random_state", ",", "\n", "artifact_dir", "=", "None", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"1000:mean_strong_test_accuracy\"", "]", ",", "0.0", ",", "0.3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.strong_downstream_task_test._identity_discretizer": [[33, 36], ["None"], "function", ["None"], ["def", "_identity_discretizer", "(", "target", ",", "num_bins", ")", ":", "\n", "  ", "del", "num_bins", "\n", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.irs.compute_irs": [[30, 77], ["gin.configurable", "absl.logging.info", "disentanglement_lib.evaluation.metrics.utils.generate_batch_factor_code", "disentanglement_lib.evaluation.metrics.utils.make_discretizer", "irs._drop_constant_dims", "numpy.sum", "_drop_constant_dims.any", "irs.scalable_disentanglement_score"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.generate_batch_factor_code", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.make_discretizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.irs._drop_constant_dims", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.irs.scalable_disentanglement_score"], ["@", "gin", ".", "configurable", "(", "\n", "\"irs\"", ",", "\n", "blacklist", "=", "[", "\"ground_truth_data\"", ",", "\"representation_function\"", ",", "\"random_state\"", ",", "\n", "\"artifact_dir\"", "]", ")", "\n", "def", "compute_irs", "(", "ground_truth_data", ",", "\n", "representation_function", ",", "\n", "random_state", ",", "\n", "artifact_dir", "=", "None", ",", "\n", "diff_quantile", "=", "0.99", ",", "\n", "num_train", "=", "gin", ".", "REQUIRED", ",", "\n", "batch_size", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "  ", "\"\"\"Computes the Interventional Robustness Score.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    random_state: Numpy random state used for randomness.\n    artifact_dir: Optional path to directory where artifacts can be saved.\n    diff_quantile: Float value between 0 and 1 to decide what quantile of diffs\n      to select (use 1.0 for the version in the paper).\n    num_train: Number of points used for training.\n    batch_size: Batch size for sampling.\n\n  Returns:\n    Dict with IRS and number of active dimensions.\n  \"\"\"", "\n", "del", "artifact_dir", "\n", "logging", ".", "info", "(", "\"Generating training set.\"", ")", "\n", "mus", ",", "ys", "=", "utils", ".", "generate_batch_factor_code", "(", "ground_truth_data", ",", "\n", "representation_function", ",", "num_train", ",", "\n", "random_state", ",", "batch_size", ")", "\n", "assert", "mus", ".", "shape", "[", "1", "]", "==", "num_train", "\n", "\n", "ys_discrete", "=", "utils", ".", "make_discretizer", "(", "ys", ")", "\n", "active_mus", "=", "_drop_constant_dims", "(", "mus", ")", "\n", "\n", "if", "not", "active_mus", ".", "any", "(", ")", ":", "\n", "    ", "irs_score", "=", "0.0", "\n", "", "else", ":", "\n", "    ", "irs_score", "=", "scalable_disentanglement_score", "(", "ys_discrete", ".", "T", ",", "active_mus", ".", "T", ",", "\n", "diff_quantile", ")", "[", "\"avg_score\"", "]", "\n", "\n", "", "score_dict", "=", "{", "}", "\n", "score_dict", "[", "\"IRS\"", "]", "=", "irs_score", "\n", "score_dict", "[", "\"num_active_dims\"", "]", "=", "np", ".", "sum", "(", "active_mus", ")", "\n", "return", "score_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.irs._drop_constant_dims": [[79, 88], ["numpy.asarray", "np.asarray.var", "ValueError"], "function", ["None"], ["", "def", "_drop_constant_dims", "(", "ys", ")", ":", "\n", "  ", "\"\"\"Returns a view of the matrix `ys` with dropped constant rows.\"\"\"", "\n", "ys", "=", "np", ".", "asarray", "(", "ys", ")", "\n", "if", "ys", ".", "ndim", "!=", "2", ":", "\n", "    ", "raise", "ValueError", "(", "\"Expecting a matrix.\"", ")", "\n", "\n", "", "variances", "=", "ys", ".", "var", "(", "axis", "=", "1", ")", "\n", "active_mask", "=", "variances", ">", "0.", "\n", "return", "ys", "[", "active_mask", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.irs.scalable_disentanglement_score": [[90, 145], ["numpy.max", "numpy.zeros", "range", "irs_matrix.max", "irs_matrix.argmax", "numpy.abs", "numpy.unique", "range", "numpy.sum", "numpy.average", "numpy.mean", "numpy.mean", "numpy.abs", "numpy.percentile", "latents.mean"], "function", ["None"], ["", "def", "scalable_disentanglement_score", "(", "gen_factors", ",", "latents", ",", "diff_quantile", "=", "0.99", ")", ":", "\n", "  ", "\"\"\"Computes IRS scores of a dataset.\n\n  Assumes no noise in X and crossed generative factors (i.e. one sample per\n  combination of gen_factors). Assumes each g_i is an equally probable\n  realization of g_i and all g_i are independent.\n\n  Args:\n    gen_factors: Numpy array of shape (num samples, num generative factors),\n      matrix of ground truth generative factors.\n    latents: Numpy array of shape (num samples, num latent dimensions), matrix\n      of latent variables.\n    diff_quantile: Float value between 0 and 1 to decide what quantile of diffs\n      to select (use 1.0 for the version in the paper).\n\n  Returns:\n    Dictionary with IRS scores.\n  \"\"\"", "\n", "num_gen", "=", "gen_factors", ".", "shape", "[", "1", "]", "\n", "num_lat", "=", "latents", ".", "shape", "[", "1", "]", "\n", "\n", "# Compute normalizer.", "\n", "max_deviations", "=", "np", ".", "max", "(", "np", ".", "abs", "(", "latents", "-", "latents", ".", "mean", "(", "axis", "=", "0", ")", ")", ",", "axis", "=", "0", ")", "\n", "cum_deviations", "=", "np", ".", "zeros", "(", "[", "num_lat", ",", "num_gen", "]", ")", "\n", "for", "i", "in", "range", "(", "num_gen", ")", ":", "\n", "    ", "unique_factors", "=", "np", ".", "unique", "(", "gen_factors", "[", ":", ",", "i", "]", ",", "axis", "=", "0", ")", "\n", "assert", "unique_factors", ".", "ndim", "==", "1", "\n", "num_distinct_factors", "=", "unique_factors", ".", "shape", "[", "0", "]", "\n", "for", "k", "in", "range", "(", "num_distinct_factors", ")", ":", "\n", "# Compute E[Z | g_i].", "\n", "      ", "match", "=", "gen_factors", "[", ":", ",", "i", "]", "==", "unique_factors", "[", "k", "]", "\n", "e_loc", "=", "np", ".", "mean", "(", "latents", "[", "match", ",", ":", "]", ",", "axis", "=", "0", ")", "\n", "\n", "# Difference of each value within that group of constant g_i to its mean.", "\n", "diffs", "=", "np", ".", "abs", "(", "latents", "[", "match", ",", ":", "]", "-", "e_loc", ")", "\n", "max_diffs", "=", "np", ".", "percentile", "(", "diffs", ",", "q", "=", "diff_quantile", "*", "100", ",", "axis", "=", "0", ")", "\n", "cum_deviations", "[", ":", ",", "i", "]", "+=", "max_diffs", "\n", "", "cum_deviations", "[", ":", ",", "i", "]", "/=", "num_distinct_factors", "\n", "# Normalize value of each latent dimension with its maximal deviation.", "\n", "", "normalized_deviations", "=", "cum_deviations", "/", "max_deviations", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "irs_matrix", "=", "1.0", "-", "normalized_deviations", "\n", "disentanglement_scores", "=", "irs_matrix", ".", "max", "(", "axis", "=", "1", ")", "\n", "if", "np", ".", "sum", "(", "max_deviations", ")", ">", "0.0", ":", "\n", "    ", "avg_score", "=", "np", ".", "average", "(", "disentanglement_scores", ",", "weights", "=", "max_deviations", ")", "\n", "", "else", ":", "\n", "    ", "avg_score", "=", "np", ".", "mean", "(", "disentanglement_scores", ")", "\n", "\n", "", "parents", "=", "irs_matrix", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "score_dict", "=", "{", "}", "\n", "score_dict", "[", "\"disentanglement_scores\"", "]", "=", "disentanglement_scores", "\n", "score_dict", "[", "\"avg_score\"", "]", "=", "avg_score", "\n", "score_dict", "[", "\"parents\"", "]", "=", "parents", "\n", "score_dict", "[", "\"IRS_matrix\"", "]", "=", "irs_matrix", "\n", "score_dict", "[", "\"max_deviations\"", "]", "=", "max_deviations", "\n", "return", "score_dict", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.beta_vae.compute_beta_vae_sklearn": [[31, 86], ["gin.configurable", "absl.logging.info", "beta_vae._generate_training_batch", "absl.logging.info", "sklearn.linear_model.LogisticRegression", "linear_model.LogisticRegression.fit", "absl.logging.info", "linear_model.LogisticRegression.score", "numpy.mean", "absl.logging.info", "absl.logging.info", "beta_vae._generate_training_batch", "absl.logging.info", "linear_model.LogisticRegression.score", "absl.logging.info", "linear_model.LogisticRegression.predict"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.beta_vae._generate_training_batch", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.beta_vae._generate_training_batch"], ["@", "gin", ".", "configurable", "(", "\n", "\"beta_vae_sklearn\"", ",", "\n", "blacklist", "=", "[", "\"ground_truth_data\"", ",", "\"representation_function\"", ",", "\"random_state\"", ",", "\n", "\"artifact_dir\"", "]", ")", "\n", "def", "compute_beta_vae_sklearn", "(", "ground_truth_data", ",", "\n", "representation_function", ",", "\n", "random_state", ",", "\n", "artifact_dir", "=", "None", ",", "\n", "batch_size", "=", "gin", ".", "REQUIRED", ",", "\n", "num_train", "=", "gin", ".", "REQUIRED", ",", "\n", "num_eval", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "  ", "\"\"\"Computes the BetaVAE disentanglement metric using scikit-learn.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    random_state: Numpy random state used for randomness.\n    artifact_dir: Optional path to directory where artifacts can be saved.\n    batch_size: Number of points to be used to compute the training_sample.\n    num_train: Number of points used for training.\n    num_eval: Number of points used for evaluation.\n\n  Returns:\n    Dictionary with scores:\n      train_accuracy: Accuracy on training set.\n      eval_accuracy: Accuracy on evaluation set.\n  \"\"\"", "\n", "del", "artifact_dir", "\n", "logging", ".", "info", "(", "\"Generating training set.\"", ")", "\n", "train_points", ",", "train_labels", "=", "_generate_training_batch", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "batch_size", ",", "num_train", ",", "\n", "random_state", ")", "\n", "\n", "logging", ".", "info", "(", "\"Training sklearn model.\"", ")", "\n", "model", "=", "linear_model", ".", "LogisticRegression", "(", "random_state", "=", "random_state", ")", "\n", "model", ".", "fit", "(", "train_points", ",", "train_labels", ")", "\n", "\n", "logging", ".", "info", "(", "\"Evaluate training set accuracy.\"", ")", "\n", "train_accuracy", "=", "model", ".", "score", "(", "train_points", ",", "train_labels", ")", "\n", "train_accuracy", "=", "np", ".", "mean", "(", "model", ".", "predict", "(", "train_points", ")", "==", "train_labels", ")", "\n", "logging", ".", "info", "(", "\"Training set accuracy: %.2g\"", ",", "train_accuracy", ")", "\n", "\n", "logging", ".", "info", "(", "\"Generating evaluation set.\"", ")", "\n", "eval_points", ",", "eval_labels", "=", "_generate_training_batch", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "batch_size", ",", "num_eval", ",", "\n", "random_state", ")", "\n", "\n", "logging", ".", "info", "(", "\"Evaluate evaluation set accuracy.\"", ")", "\n", "eval_accuracy", "=", "model", ".", "score", "(", "eval_points", ",", "eval_labels", ")", "\n", "logging", ".", "info", "(", "\"Evaluation set accuracy: %.2g\"", ",", "eval_accuracy", ")", "\n", "scores_dict", "=", "{", "}", "\n", "scores_dict", "[", "\"train_accuracy\"", "]", "=", "train_accuracy", "\n", "scores_dict", "[", "\"eval_accuracy\"", "]", "=", "eval_accuracy", "\n", "return", "scores_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.beta_vae._generate_training_batch": [[88, 114], ["numpy.zeros", "six.moves.range", "beta_vae._generate_training_sample", "numpy.zeros"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.beta_vae._generate_training_sample"], ["", "def", "_generate_training_batch", "(", "ground_truth_data", ",", "representation_function", ",", "\n", "batch_size", ",", "num_points", ",", "random_state", ")", ":", "\n", "  ", "\"\"\"Sample a set of training samples based on a batch of ground-truth data.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    batch_size: Number of points to be used to compute the training_sample.\n    num_points: Number of points to be sampled for training set.\n    random_state: Numpy random state used for randomness.\n\n  Returns:\n    points: (num_points, dim_representation)-sized numpy array with training set\n      features.\n    labels: (num_points)-sized numpy array with training set labels.\n  \"\"\"", "\n", "points", "=", "None", "# Dimensionality depends on the representation function.", "\n", "labels", "=", "np", ".", "zeros", "(", "num_points", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "for", "i", "in", "range", "(", "num_points", ")", ":", "\n", "    ", "labels", "[", "i", "]", ",", "feature_vector", "=", "_generate_training_sample", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "batch_size", ",", "random_state", ")", "\n", "if", "points", "is", "None", ":", "\n", "      ", "points", "=", "np", ".", "zeros", "(", "(", "num_points", ",", "feature_vector", ".", "shape", "[", "0", "]", ")", ")", "\n", "", "points", "[", "i", ",", ":", "]", "=", "feature_vector", "\n", "", "return", "points", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.beta_vae._generate_training_sample": [[116, 149], ["random_state.randint", "ground_truth_data.sample_factors", "ground_truth_data.sample_factors", "ground_truth_data.sample_observations_from_factors", "ground_truth_data.sample_observations_from_factors", "representation_function", "representation_function", "numpy.mean", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors"], ["", "def", "_generate_training_sample", "(", "ground_truth_data", ",", "representation_function", ",", "\n", "batch_size", ",", "random_state", ")", ":", "\n", "  ", "\"\"\"Sample a single training sample based on a mini-batch of ground-truth data.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observation as input and\n      outputs a representation.\n    batch_size: Number of points to be used to compute the training_sample\n    random_state: Numpy random state used for randomness.\n\n  Returns:\n    index: Index of coordinate to be used.\n    feature_vector: Feature vector of training sample.\n  \"\"\"", "\n", "# Select random coordinate to keep fixed.", "\n", "index", "=", "random_state", ".", "randint", "(", "ground_truth_data", ".", "num_factors", ")", "\n", "# Sample two mini batches of latent variables.", "\n", "factors1", "=", "ground_truth_data", ".", "sample_factors", "(", "batch_size", ",", "random_state", ")", "\n", "factors2", "=", "ground_truth_data", ".", "sample_factors", "(", "batch_size", ",", "random_state", ")", "\n", "# Ensure sampled coordinate is the same across pairs of samples.", "\n", "factors2", "[", ":", ",", "index", "]", "=", "factors1", "[", ":", ",", "index", "]", "\n", "# Transform latent variables to observation space.", "\n", "observation1", "=", "ground_truth_data", ".", "sample_observations_from_factors", "(", "\n", "factors1", ",", "random_state", ")", "\n", "observation2", "=", "ground_truth_data", ".", "sample_observations_from_factors", "(", "\n", "factors2", ",", "random_state", ")", "\n", "# Compute representations based on the observations.", "\n", "representation1", "=", "representation_function", "(", "observation1", ")", "\n", "representation2", "=", "representation_function", "(", "observation2", ")", "\n", "# Compute the feature vector based on differences in representation.", "\n", "feature_vector", "=", "np", ".", "mean", "(", "np", ".", "abs", "(", "representation1", "-", "representation2", ")", ",", "axis", "=", "0", ")", "\n", "return", "index", ",", "feature_vector", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.compute_unified_scores": [[44, 85], ["gin.configurable", "absl.logging.info", "disentanglement_lib.evaluation.metrics.utils.generate_batch_factor_code", "disentanglement_lib.evaluation.metrics.utils.generate_batch_factor_code", "unified_scores.unified_scores"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.generate_batch_factor_code", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.generate_batch_factor_code", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.unified_scores"], ["@", "gin", ".", "configurable", "(", "\n", "\"unified_scores\"", ",", "\n", "blacklist", "=", "[", "\"ground_truth_data\"", ",", "\"representation_function\"", ",", "\"random_state\"", ",", "\n", "\"artifact_dir\"", "]", ")", "\n", "def", "compute_unified_scores", "(", "ground_truth_data", ",", "representation_function", ",", "\n", "random_state", ",", "\n", "artifact_dir", "=", "None", ",", "\n", "num_train", "=", "gin", ".", "REQUIRED", ",", "\n", "num_test", "=", "gin", ".", "REQUIRED", ",", "\n", "matrix_fns", "=", "gin", ".", "REQUIRED", ",", "\n", "batch_size", "=", "16", ")", ":", "\n", "  ", "\"\"\"Computes the unified disentanglement scores.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    random_state: Numpy random state used for randomness.\n    artifact_dir: Optional path to directory where artifacts can be saved.\n    num_train: Number of points used for training.\n    num_test: Number of points used for testing.\n    matrix_fns: List of functions to relate factors of variations and codes.\n    batch_size: Batch size for sampling.\n\n  Returns:\n    Unified scores.\n  \"\"\"", "\n", "logging", ".", "info", "(", "\"Generating training set.\"", ")", "\n", "# mus_train are of shape [num_codes, num_train], while ys_train are of shape", "\n", "# [num_factors, num_train].", "\n", "mus_train", ",", "ys_train", "=", "utils", ".", "generate_batch_factor_code", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "num_train", ",", "\n", "random_state", ",", "batch_size", ")", "\n", "assert", "mus_train", ".", "shape", "[", "1", "]", "==", "num_train", "\n", "assert", "ys_train", ".", "shape", "[", "1", "]", "==", "num_train", "\n", "mus_test", ",", "ys_test", "=", "utils", ".", "generate_batch_factor_code", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "num_test", ",", "\n", "random_state", ",", "batch_size", ")", "\n", "\n", "return", "unified_scores", "(", "mus_train", ",", "ys_train", ",", "mus_test", ",", "ys_test", ",", "matrix_fns", ",", "\n", "artifact_dir", ",", "ground_truth_data", ".", "factor_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.compute_unified_score_on_fixed_data": [[87, 120], ["gin.configurable", "disentanglement_lib.evaluation.metrics.utils.obtain_representation", "disentanglement_lib.evaluation.metrics.utils.split_train_test", "disentanglement_lib.evaluation.metrics.utils.split_train_test", "unified_scores.unified_scores"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.obtain_representation", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.split_train_test", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.split_train_test", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.unified_scores"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"unified_score_validation\"", ",", "\n", "blacklist", "=", "[", "\"observations\"", ",", "\"labels\"", ",", "\"representation_function\"", "]", ")", "\n", "def", "compute_unified_score_on_fixed_data", "(", "\n", "observations", ",", "labels", ",", "representation_function", ",", "\n", "train_percentage", "=", "gin", ".", "REQUIRED", ",", "matrix_fns", "=", "gin", ".", "REQUIRED", ",", "batch_size", "=", "100", ")", ":", "\n", "  ", "\"\"\"Computes the unified scores on the fixed set of observations and labels.\n\n  Args:\n    observations: Observations on which to compute the score. Observations have\n      shape (num_observations, 64, 64, num_channels).\n    labels: Observed factors of variations.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    train_percentage: Percentage of observations used for training.\n    matrix_fns: List of functions to relate factors of variations and codes.\n    batch_size: Batch size used to compute the representation.\n\n  Returns:\n    Unified scores.\n  \"\"\"", "\n", "mus", "=", "utils", ".", "obtain_representation", "(", "observations", ",", "representation_function", ",", "\n", "batch_size", ")", "\n", "assert", "labels", ".", "shape", "[", "1", "]", "==", "observations", ".", "shape", "[", "0", "]", ",", "\"Wrong labels shape.\"", "\n", "assert", "mus", ".", "shape", "[", "1", "]", "==", "observations", ".", "shape", "[", "0", "]", ",", "\"Wrong representation shape.\"", "\n", "\n", "mus_train", ",", "mus_test", "=", "utils", ".", "split_train_test", "(", "\n", "mus", ",", "\n", "train_percentage", ")", "\n", "ys_train", ",", "ys_test", "=", "utils", ".", "split_train_test", "(", "\n", "labels", ",", "\n", "train_percentage", ")", "\n", "return", "unified_scores", "(", "mus_train", ",", "ys_train", ",", "mus_test", ",", "ys_test", ",", "matrix_fns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.unified_scores": [[122, 152], ["disentanglement_lib.utils.results.namespaced_dict", "matrix_fn", "unified_scores.pr_curves_values", "disentanglement_lib.visualize.visualize_scores.heat_square", "disentanglement_lib.visualize.visualize_scores.plot_recovery_vs_independent", "disentanglement_lib.visualize.dendrogram.dendrogram_plot", "kws[].update", "aggregation_fn", "kws[].update", "matrix_fn.copy", "os.path.join", "matrix_fn.copy", "matrix_fn.copy"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.namespaced_dict", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.pr_curves_values", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores.heat_square", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores_test.VisualizeScoresTest.plot_recovery_vs_independent", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.dendrogram.dendrogram_plot"], ["", "def", "unified_scores", "(", "mus_train", ",", "ys_train", ",", "mus_test", ",", "ys_test", ",", "matrix_fns", ",", "\n", "artifact_dir", "=", "None", ",", "factor_names", "=", "None", ")", ":", "\n", "  ", "\"\"\"Computes unified scores.\"\"\"", "\n", "\n", "scores", "=", "{", "}", "\n", "kws", "=", "{", "}", "\n", "for", "matrix_fn", "in", "matrix_fns", ":", "\n", "# Matrix should have shape [num_codes, num_factors].", "\n", "    ", "matrix", "=", "matrix_fn", "(", "mus_train", ",", "ys_train", ",", "mus_test", ",", "ys_test", ")", "\n", "matrix_name", "=", "matrix_fn", ".", "__name__", "\n", "if", "artifact_dir", "is", "not", "None", ":", "\n", "      ", "visualize_scores", ".", "heat_square", "(", "matrix", ".", "copy", "(", ")", ",", "artifact_dir", ",", "matrix_name", ",", "\n", "\"Latent codes\"", ",", "\"Factors of Variation\"", ",", "\n", "factor_names", "=", "factor_names", ")", "\n", "visualize_scores", ".", "plot_recovery_vs_independent", "(", "matrix", ".", "copy", "(", ")", ".", "T", ",", "\n", "artifact_dir", ",", "\n", "matrix_name", "+", "\"_pr\"", ")", "\n", "merge_points", "=", "dendrogram", ".", "dendrogram_plot", "(", "matrix", ".", "copy", "(", ")", ".", "T", ",", "os", ".", "path", ".", "join", "(", "\n", "artifact_dir", ",", "matrix_name", "+", "\"_dendrogram\"", ")", ",", "factor_names", ")", "\n", "kws", "[", "matrix_name", "]", "=", "merge_points", "\n", "", "results_dict", "=", "pr_curves_values", "(", "matrix", ")", "\n", "if", "matrix_name", "in", "kws", ":", "\n", "      ", "kws", "[", "matrix_name", "]", ".", "update", "(", "results_dict", ")", "\n", "", "else", ":", "\n", "      ", "kws", "[", "matrix_name", "]", "=", "results_dict", "\n", "", "for", "aggregation_fn", "in", "AGGREGATION_FN", ":", "\n", "      ", "results_dict", "=", "aggregation_fn", "(", "matrix", ",", "ys_train", ")", "\n", "kws", "[", "matrix_name", "]", ".", "update", "(", "results_dict", ")", "\n", "", "", "scores", "=", "results", ".", "namespaced_dict", "(", "scores", ",", "**", "kws", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.pr_curves_values": [[154, 166], ["range", "max", "numpy.sort", "disentanglement_lib.visualize.visualize_scores.precision", "matrix.flatten", "len"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_scores.precision"], ["", "def", "pr_curves_values", "(", "matrix", ")", ":", "\n", "  ", "\"\"\"Computes area of precision curve and max recall.\"\"\"", "\n", "scores", "=", "{", "}", "\n", "thresholds", "=", "np", ".", "sort", "(", "matrix", ".", "flatten", "(", ")", ")", "[", ":", ":", "-", "1", "]", "\n", "precisions", "=", "[", "visualize_scores", ".", "precision", "(", "matrix", ",", "x", ")", "for", "x", "in", "thresholds", "]", "\n", "area", "=", "0.", "\n", "for", "i", "in", "range", "(", "len", "(", "precisions", ")", "-", "1", ")", ":", "\n", "    ", "area", "+=", "(", "\n", "precisions", "[", "i", "]", "+", "precisions", "[", "i", "+", "1", "]", ")", "*", "(", "thresholds", "[", "i", "]", "-", "thresholds", "[", "i", "+", "1", "]", ")", "*", "0.5", "\n", "", "scores", "[", "\"area_precision\"", "]", "=", "area", "\n", "scores", "[", "\"max_precision\"", "]", "=", "max", "(", "precisions", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.importance_gbt_matrix": [[168, 191], ["gin.configurable", "disentanglement_lib.evaluation.metrics.dci.compute_importance_gbt"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.compute_importance_gbt"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"importance_gbt_matrix\"", ",", "\n", "blacklist", "=", "[", "\"mus_train\"", ",", "\"ys_train\"", ",", "\"mus_test\"", ",", "\"ys_test\"", "]", ")", "\n", "def", "importance_gbt_matrix", "(", "mus_train", ",", "ys_train", ",", "mus_test", ",", "ys_test", ")", ":", "\n", "  ", "\"\"\"Computes the importance matrix of the DCI Disentanglement score.\n\n  The importance matrix is based on the importance of each code to predict a\n  factor of variation with GBT.\n\n  Args:\n    mus_train: Batch of learned representations to be used for training.\n    ys_train: Observed factors of variation corresponding to the representations\n      in mus_train.\n    mus_test: Batch of learned representations to be used for testing.\n    ys_test: Observed factors of variation corresponding to the representations\n    in mus_test.\n\n  Returns:\n    Importance matrix as computed for the DCI Disentanglement score.\n  \"\"\"", "\n", "matrix_importance_gbt", ",", "_", ",", "_", "=", "dci", ".", "compute_importance_gbt", "(", "\n", "mus_train", ",", "ys_train", ",", "mus_test", ",", "ys_test", ")", "\n", "return", "matrix_importance_gbt", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.mutual_information_matrix": [[193, 216], ["gin.configurable", "disentanglement_lib.evaluation.metrics.utils.make_discretizer", "disentanglement_lib.evaluation.metrics.utils.discrete_mutual_info"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.make_discretizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.discrete_mutual_info"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"mutual_information_matrix\"", ",", "\n", "blacklist", "=", "[", "\"mus_train\"", ",", "\"ys_train\"", ",", "\"mus_test\"", ",", "\"ys_test\"", "]", ")", "\n", "def", "mutual_information_matrix", "(", "mus_train", ",", "ys_train", ",", "mus_test", ",", "ys_test", ")", ":", "\n", "  ", "\"\"\"Computes the mutual information matrix between codes and factors.\n\n  The mutual information matrix is used to compute the MIG and Modularity\n  scores.\n\n  Args:\n    mus_train: Batch of learned representations to be used for training.\n    ys_train: Observed factors of variation corresponding to the representations\n      in mus_train.\n    mus_test: Unused.\n    ys_test: Unused.\n\n  Returns:\n    Mutual information matrix as computed for the MIG and Modularity scores.\n  \"\"\"", "\n", "del", "mus_test", ",", "ys_test", "\n", "discretized_mus", "=", "utils", ".", "make_discretizer", "(", "mus_train", ")", "\n", "m", "=", "utils", ".", "discrete_mutual_info", "(", "discretized_mus", ",", "ys_train", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.accuracy_svm_matrix": [[218, 239], ["gin.configurable", "disentanglement_lib.evaluation.metrics.sap_score.compute_score_matrix"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.sap_score.compute_score_matrix"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"accuracy_svm_matrix\"", ",", "\n", "blacklist", "=", "[", "\"mus_train\"", ",", "\"ys_train\"", ",", "\"mus_test\"", ",", "\"ys_test\"", "]", ")", "\n", "def", "accuracy_svm_matrix", "(", "mus_train", ",", "ys_train", ",", "mus_test", ",", "ys_test", ")", ":", "\n", "  ", "\"\"\"Prediction accuracy of a SVM predicting a factor from a single code.\n\n  The matrix of accuracies is used to compute the SAP score.\n\n  Args:\n    mus_train: Batch of learned representations to be used for training.\n    ys_train: Observed factors of variation corresponding to the representations\n      in mus_train.\n    mus_test: Batch of learned representations to be used for testing.\n    ys_test: Observed factors of variation corresponding to the representations\n    in mus_test.\n\n  Returns:\n    Accuracy matrix as computed for the SAP score.\n  \"\"\"", "\n", "return", "sap_score", ".", "compute_score_matrix", "(", "\n", "mus_train", ",", "ys_train", ",", "mus_test", ",", "ys_test", ",", "continuous_factors", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.aggregation_dci": [[241, 257], ["disentanglement_lib.evaluation.metrics.dci.disentanglement", "disentanglement_lib.evaluation.metrics.dci.completeness", "disentanglement_lib.evaluation.metrics.dci.disentanglement", "disentanglement_lib.evaluation.metrics.dci.disentanglement_per_code", "disentanglement_lib.evaluation.metrics.dci.completeness_per_factor", "range", "range", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.disentanglement", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.completeness", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.disentanglement", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.disentanglement_per_code", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.completeness_per_factor"], ["", "def", "aggregation_dci", "(", "matrix", ",", "ys", ")", ":", "\n", "  ", "\"\"\"Aggregation function of the DCI Disentanglement.\"\"\"", "\n", "del", "ys", "\n", "score", "=", "{", "}", "\n", "score", "[", "\"dci_disentanglement\"", "]", "=", "dci", ".", "disentanglement", "(", "matrix", ")", "\n", "score", "[", "\"dci_completeness\"", "]", "=", "dci", ".", "completeness", "(", "matrix", ")", "\n", "score", "[", "\"dci\"", "]", "=", "dci", ".", "disentanglement", "(", "matrix", ")", "\n", "disentanglement_per_code", "=", "dci", ".", "disentanglement_per_code", "(", "matrix", ")", "\n", "completeness_per_factor", "=", "dci", ".", "completeness_per_factor", "(", "matrix", ")", "\n", "assert", "len", "(", "disentanglement_per_code", ")", "==", "matrix", ".", "shape", "[", "0", "]", ",", "\"Wrong length.\"", "\n", "assert", "len", "(", "completeness_per_factor", ")", "==", "matrix", ".", "shape", "[", "1", "]", ",", "\"Wrong length.\"", "\n", "for", "i", "in", "range", "(", "len", "(", "disentanglement_per_code", ")", ")", ":", "\n", "    ", "score", "[", "\"dci_disentanglement.code_{}\"", ".", "format", "(", "i", ")", "]", "=", "disentanglement_per_code", "[", "i", "]", "\n", "", "for", "i", "in", "range", "(", "len", "(", "completeness_per_factor", ")", ")", ":", "\n", "    ", "score", "[", "\"dci_completeness.code_{}\"", ".", "format", "(", "i", ")", "]", "=", "completeness_per_factor", "[", "i", "]", "\n", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.aggregation_mig": [[259, 270], ["disentanglement_lib.evaluation.metrics.utils.discrete_entropy", "numpy.divide", "numpy.mean", "range", "numpy.sort", "len", "len"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.discrete_entropy"], ["", "def", "aggregation_mig", "(", "m", ",", "ys_train", ")", ":", "\n", "  ", "\"\"\"Aggregation function of the MIG.\"\"\"", "\n", "score", "=", "{", "}", "\n", "entropy", "=", "utils", ".", "discrete_entropy", "(", "ys_train", ")", "\n", "sorted_m", "=", "np", ".", "sort", "(", "m", ",", "axis", "=", "0", ")", "[", ":", ":", "-", "1", "]", "\n", "mig_per_factor", "=", "np", ".", "divide", "(", "sorted_m", "[", "0", ",", ":", "]", "-", "sorted_m", "[", "1", ",", ":", "]", ",", "entropy", "[", ":", "]", ")", "\n", "score", "[", "\"mig\"", "]", "=", "np", ".", "mean", "(", "mig_per_factor", ")", "\n", "assert", "len", "(", "mig_per_factor", ")", "==", "m", ".", "shape", "[", "1", "]", ",", "\"Wrong length.\"", "\n", "for", "i", "in", "range", "(", "len", "(", "mig_per_factor", ")", ")", ":", "\n", "    ", "score", "[", "\"mig.factor_{}\"", ".", "format", "(", "i", ")", "]", "=", "mig_per_factor", "[", "i", "]", "\n", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.aggregation_sap": [[272, 282], ["disentanglement_lib.evaluation.metrics.sap_score.compute_avg_diff_top_two", "unified_scores.sap_compute_diff_top_two", "range", "len", "len"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.sap_score.compute_avg_diff_top_two", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.sap_compute_diff_top_two"], ["", "def", "aggregation_sap", "(", "matrix", ",", "ys", ")", ":", "\n", "  ", "\"\"\"Aggregation function of the SAP score.\"\"\"", "\n", "del", "ys", "\n", "score", "=", "{", "}", "\n", "score", "[", "\"sap\"", "]", "=", "sap_score", ".", "compute_avg_diff_top_two", "(", "matrix", ")", "\n", "sap_per_factor", "=", "sap_compute_diff_top_two", "(", "matrix", ")", "\n", "assert", "len", "(", "sap_per_factor", ")", "==", "matrix", ".", "shape", "[", "1", "]", ",", "\"Wrong length.\"", "\n", "for", "i", "in", "range", "(", "len", "(", "sap_per_factor", ")", ")", ":", "\n", "    ", "score", "[", "\"sap.factor_{}\"", ".", "format", "(", "i", ")", "]", "=", "sap_per_factor", "[", "i", "]", "\n", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.sap_compute_diff_top_two": [[284, 287], ["numpy.sort"], "function", ["None"], ["", "def", "sap_compute_diff_top_two", "(", "matrix", ")", ":", "\n", "  ", "sorted_matrix", "=", "np", ".", "sort", "(", "matrix", ",", "axis", "=", "0", ")", "\n", "return", "sorted_matrix", "[", "-", "1", ",", ":", "]", "-", "sorted_matrix", "[", "-", "2", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.aggregation_modularity": [[289, 299], ["disentanglement_lib.evaluation.metrics.modularity_explicitness.modularity", "unified_scores.compute_modularity_per_code", "range", "len", "len"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.modularity_explicitness.modularity", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.compute_modularity_per_code"], ["", "def", "aggregation_modularity", "(", "matrix", ",", "ys", ")", ":", "\n", "  ", "\"\"\"Aggregation function of the modularity score.\"\"\"", "\n", "del", "ys", "\n", "score", "=", "{", "}", "\n", "score", "[", "\"modularity\"", "]", "=", "modularity_explicitness", ".", "modularity", "(", "matrix", ")", "\n", "modularity_per_code", "=", "compute_modularity_per_code", "(", "matrix", ")", "\n", "assert", "len", "(", "modularity_per_code", ")", "==", "matrix", ".", "shape", "[", "0", "]", ",", "\"Wrong length.\"", "\n", "for", "i", "in", "range", "(", "len", "(", "modularity_per_code", ")", ")", ":", "\n", "    ", "score", "[", "\"modularity.code_{}\"", ".", "format", "(", "i", ")", "]", "=", "modularity_per_code", "[", "i", "]", "\n", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.unified_scores.compute_modularity_per_code": [[301, 313], ["numpy.square", "numpy.max", "numpy.sum"], "function", ["None"], ["", "def", "compute_modularity_per_code", "(", "mutual_information", ")", ":", "\n", "  ", "\"\"\"Computes the modularity from mutual information.\"\"\"", "\n", "# Mutual information has shape [num_codes, num_factors].", "\n", "squared_mi", "=", "np", ".", "square", "(", "mutual_information", ")", "\n", "max_squared_mi", "=", "np", ".", "max", "(", "squared_mi", ",", "axis", "=", "1", ")", "\n", "numerator", "=", "np", ".", "sum", "(", "squared_mi", ",", "axis", "=", "1", ")", "-", "max_squared_mi", "\n", "denominator", "=", "max_squared_mi", "*", "(", "squared_mi", ".", "shape", "[", "1", "]", "-", "1.", ")", "\n", "delta", "=", "numerator", "/", "denominator", "\n", "modularity_score", "=", "1.", "-", "delta", "\n", "index", "=", "(", "max_squared_mi", "==", "0.", ")", "\n", "modularity_score", "[", "index", "]", "=", "0.", "\n", "return", "modularity_score", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.reduced_downstream_task.compute_reduced_downstream_task": [[32, 140], ["gin.configurable", "str", "disentanglement_lib.evaluation.metrics.utils.generate_batch_factor_code", "disentanglement_lib.evaluation.metrics.utils.generate_batch_factor_code", "six.moves.range", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "mus_train.copy", "mus_test.copy", "six.moves.range", "disentanglement_lib.evaluation.metrics.utils.make_predictor_fn", "reduced_downstream_task.compute_predictive_accuracy", "reduced_factor_train_scores.append", "reduced_factor_test_scores.append", "six.moves.range", "numpy.mean", "numpy.mean", "other_factors_train_scores.append", "other_factors_test_scores.append", "reduced_downstream_task.compute_reduced_representation", "numpy.transpose", "numpy.transpose", "len", "numpy.mean", "numpy.mean", "local_other_factors_train_scores.append", "local_other_factors_test_scores.append"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.generate_batch_factor_code", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.generate_batch_factor_code", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.make_predictor_fn", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.reduced_downstream_task.compute_predictive_accuracy", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.reduced_downstream_task.compute_reduced_representation"], ["@", "gin", ".", "configurable", "(", "\n", "\"reduced_downstream_task\"", ",", "\n", "blacklist", "=", "[", "\"ground_truth_data\"", ",", "\"representation_function\"", ",", "\"random_state\"", ",", "\n", "\"artifact_dir\"", "]", ")", "\n", "def", "compute_reduced_downstream_task", "(", "ground_truth_data", ",", "\n", "representation_function", ",", "\n", "random_state", ",", "\n", "artifact_dir", "=", "None", ",", "\n", "num_factors_to_remove", "=", "gin", ".", "REQUIRED", ",", "\n", "num_train", "=", "gin", ".", "REQUIRED", ",", "\n", "num_test", "=", "gin", ".", "REQUIRED", ",", "\n", "batch_size", "=", "16", ")", ":", "\n", "  ", "\"\"\"Computes loss of a reduced downstream task.\n\n  Measure the information leakage in each latent component after removing the\n  k (\"factors_to_remove\") most informative features for the prediction task.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    random_state: Numpy random state used for randomness.\n    artifact_dir: Optional path to directory where artifacts can be saved.\n    num_factors_to_remove: Number of factors to remove from the latent\n      representation.\n    num_train: Number of points used for training.\n    num_test: Number of points used for testing.\n    batch_size: Batch size for sampling.\n\n  Returns:\n    Dictionary with scores.\n  \"\"\"", "\n", "del", "artifact_dir", "\n", "scores", "=", "{", "}", "\n", "# Loop on different sizes of the training 'batch', as specified with gin.", "\n", "for", "train_size", "in", "num_train", ":", "\n", "    ", "size_string", "=", "str", "(", "train_size", ")", "\n", "mus_train", ",", "ys_train", "=", "utils", ".", "generate_batch_factor_code", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "train_size", ",", "random_state", ",", "\n", "batch_size", ")", "\n", "mus_test", ",", "ys_test", "=", "utils", ".", "generate_batch_factor_code", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "num_test", ",", "random_state", ",", "\n", "batch_size", ")", "\n", "# Create variables for aggregated scores.", "\n", "reduced_factor_train_scores", "=", "[", "]", "\n", "other_factors_train_scores", "=", "[", "]", "\n", "reduced_factor_test_scores", "=", "[", "]", "\n", "other_factors_test_scores", "=", "[", "]", "\n", "# Compute the reduced representation and test it for each factor of", "\n", "# variation.", "\n", "for", "factor_of_interest", "in", "range", "(", "ground_truth_data", ".", "num_factors", ")", ":", "\n", "# Copy the training data and eliminate the k most informative factors.", "\n", "      ", "reduced_mus_train", "=", "mus_train", ".", "copy", "(", ")", "\n", "reduced_mus_test", "=", "mus_test", ".", "copy", "(", ")", "\n", "for", "_", "in", "range", "(", "num_factors_to_remove", ")", ":", "\n", "        ", "reduced_mus_train", ",", "reduced_mus_test", "=", "compute_reduced_representation", "(", "reduced_mus_train", ",", "ys_train", ",", "\n", "reduced_mus_test", ",", "ys_test", ",", "\n", "factor_of_interest", ")", "\n", "", "predictor_model", "=", "utils", ".", "make_predictor_fn", "(", ")", "\n", "train_acc", ",", "test_acc", "=", "compute_predictive_accuracy", "(", "\n", "np", ".", "transpose", "(", "reduced_mus_train", ")", ",", "ys_train", ",", "\n", "np", ".", "transpose", "(", "reduced_mus_test", ")", ",", "ys_test", ",", "predictor_model", ")", "\n", "# Save scores for reduced factor.", "\n", "scores", "[", "size_string", "+", "\n", "\":reduced_factor_{}:mean_train_accuracy_reduced_factor\"", ".", "format", "(", "\n", "factor_of_interest", ")", "]", "=", "train_acc", "[", "factor_of_interest", "]", "\n", "scores", "[", "size_string", "+", "\n", "\":reduced_factor_{}:mean_test_accuracy_reduced_factor\"", ".", "format", "(", "\n", "factor_of_interest", ")", "]", "=", "test_acc", "[", "factor_of_interest", "]", "\n", "reduced_factor_train_scores", ".", "append", "(", "train_acc", "[", "factor_of_interest", "]", ")", "\n", "reduced_factor_test_scores", ".", "append", "(", "test_acc", "[", "factor_of_interest", "]", ")", "\n", "\n", "# Save the scores (accuracies) in the score dictionary.", "\n", "local_other_factors_train_scores", "=", "[", "]", "\n", "local_other_factors_test_scores", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "train_acc", ")", ")", ":", "\n", "        ", "scores", "[", "size_string", "+", "\n", "\":reduced_factor_{}:mean_train_accuracy_factor_{}\"", ".", "format", "(", "\n", "factor_of_interest", ",", "i", ")", "]", "=", "train_acc", "[", "i", "]", "\n", "scores", "[", "size_string", "+", "\n", "\":reduced_factor_{}:mean_test_accuracy_factor_{}\"", ".", "format", "(", "\n", "factor_of_interest", ",", "i", ")", "]", "=", "test_acc", "[", "i", "]", "\n", "if", "i", "!=", "factor_of_interest", ":", "\n", "          ", "local_other_factors_train_scores", ".", "append", "(", "train_acc", "[", "i", "]", ")", "\n", "local_other_factors_test_scores", ".", "append", "(", "test_acc", "[", "i", "]", ")", "\n", "# Save mean score for non-reduced factors.", "\n", "", "", "scores", "[", "size_string", "+", "\n", "\":reduced_factor_{}:mean_train_accuracy_non_reduced_factor\"", ".", "format", "(", "\n", "factor_of_interest", ")", "]", "=", "np", ".", "mean", "(", "\n", "local_other_factors_train_scores", ")", "\n", "scores", "[", "size_string", "+", "\n", "\":reduced_factor_{}:mean_test_accuracy_non_reduced_factor\"", ".", "format", "(", "\n", "factor_of_interest", ")", "]", "=", "np", ".", "mean", "(", "local_other_factors_test_scores", ")", "\n", "other_factors_train_scores", ".", "append", "(", "\n", "np", ".", "mean", "(", "local_other_factors_train_scores", ")", ")", "\n", "other_factors_test_scores", ".", "append", "(", "np", ".", "mean", "(", "local_other_factors_test_scores", ")", ")", "\n", "\n", "# Compute the aggregate scores.", "\n", "", "scores", "[", "size_string", "+", "\":mean_train_accuracy_reduced_factor\"", "]", "=", "np", ".", "mean", "(", "\n", "reduced_factor_train_scores", ")", "\n", "scores", "[", "size_string", "+", "\":mean_test_accuracy_reduced_factor\"", "]", "=", "np", ".", "mean", "(", "\n", "reduced_factor_test_scores", ")", "\n", "scores", "[", "size_string", "+", "\":mean_train_accuracy_other_factors\"", "]", "=", "np", ".", "mean", "(", "\n", "other_factors_train_scores", ")", "\n", "scores", "[", "size_string", "+", "\":mean_test_accuracy_other_factors\"", "]", "=", "np", ".", "mean", "(", "\n", "other_factors_test_scores", ")", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.reduced_downstream_task.compute_reduced_representation": [[142, 174], ["gin.configurable", "correlation_measure", "numpy.argmax", "numpy.delete", "numpy.delete", "mus_train.copy", "mus_test.copy"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"reduced_representation\"", ")", "\n", "def", "compute_reduced_representation", "(", "mus_train", ",", "\n", "ys_train", ",", "\n", "mus_test", ",", "\n", "ys_test", ",", "\n", "factor_of_interest", ",", "\n", "correlation_measure", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "  ", "\"\"\"Computes a reduced representation of the data.\n\n  The most informative factor with respect to the labels is deleted.\n\n  Args:\n    mus_train: latent means of the training batch.\n    ys_train: labels of the training batch.\n    mus_test: latent means of the test batch.\n    ys_test: labels of the test batch.\n    factor_of_interest: index of the factor of interest.\n    correlation_measure: measure of correlation.\n\n  Returns:\n    Tuple with reduced representations for the training and test set.\n  \"\"\"", "\n", "importance_matrix", "=", "correlation_measure", "(", "mus_train", ",", "ys_train", ",", "mus_test", ",", "\n", "ys_test", ")", "\n", "factor_of_interest_importance", "=", "importance_matrix", "[", ":", ",", "factor_of_interest", "]", "\n", "factor_to_remove_index", "=", "np", ".", "argmax", "(", "factor_of_interest_importance", ")", "\n", "# Remove the factor of variation above from the representation", "\n", "reduced_representation_train", "=", "np", ".", "delete", "(", "\n", "mus_train", ".", "copy", "(", ")", ",", "factor_to_remove_index", ",", "axis", "=", "0", ")", "\n", "reduced_representation_test", "=", "np", ".", "delete", "(", "\n", "mus_test", ".", "copy", "(", ")", ",", "factor_to_remove_index", ",", "axis", "=", "0", ")", "\n", "return", "reduced_representation_train", ",", "reduced_representation_test", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.reduced_downstream_task.compute_factorwise_dci": [[176, 196], ["gin.configurable", "disentanglement_lib.evaluation.metrics.dci.compute_importance_gbt"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.dci.compute_importance_gbt"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"factorwise_dci\"", ",", "\n", "blacklist", "=", "[", "\"mus_train\"", ",", "\"ys_train\"", ",", "\"mus_test\"", ",", "\"ys_test\"", "]", ")", "\n", "def", "compute_factorwise_dci", "(", "mus_train", ",", "ys_train", ",", "mus_test", ",", "ys_test", ")", ":", "\n", "  ", "\"\"\"Computes the DCI importance matrix of the attributes.\n\n  Args:\n    mus_train: latent means of the training batch.\n    ys_train: labels of the training batch.\n    mus_test: latent means of the test batch.\n    ys_test: labels of the test batch.\n\n  Returns:\n    Matrix with importance scores.\n  \"\"\"", "\n", "importance_matrix", ",", "_", ",", "_", "=", "dci", ".", "compute_importance_gbt", "(", "mus_train", ",", "ys_train", ",", "\n", "mus_test", ",", "ys_test", ")", "\n", "assert", "importance_matrix", ".", "shape", "[", "0", "]", "==", "mus_train", ".", "shape", "[", "0", "]", "\n", "assert", "importance_matrix", ".", "shape", "[", "1", "]", "==", "ys_train", ".", "shape", "[", "0", "]", "\n", "return", "importance_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.reduced_downstream_task.compute_predictive_accuracy": [[198, 221], ["six.moves.range", "predictor_fn", "predictor_fn.fit", "train_acc.append", "test_acc.append", "numpy.mean", "numpy.mean", "predictor_fn.predict", "predictor_fn.predict"], "function", ["None"], ["", "def", "compute_predictive_accuracy", "(", "x_train", ",", "y_train", ",", "x_test", ",", "y_test", ",", "predictor_fn", ")", ":", "\n", "  ", "\"\"\"Computes average predictive accuracy for train and test set.\n\n  Args:\n    x_train: data x of the training batch.\n    y_train: labels y of the training batch.\n    x_test: data x of the test batch.\n    y_test: labels y of the test batch.\n    predictor_fn: function that is used to fit and predict the labels.\n\n  Returns:\n    Tuple with lists of training and test set accuracies.\n  \"\"\"", "\n", "num_factors", "=", "y_train", ".", "shape", "[", "0", "]", "\n", "train_acc", "=", "[", "]", "\n", "test_acc", "=", "[", "]", "\n", "# Loop on the generative factors to predict", "\n", "for", "i", "in", "range", "(", "num_factors", ")", ":", "\n", "    ", "model", "=", "predictor_fn", "(", ")", "\n", "model", ".", "fit", "(", "x_train", ",", "y_train", "[", "i", ",", ":", "]", ")", "\n", "train_acc", ".", "append", "(", "np", ".", "mean", "(", "model", ".", "predict", "(", "x_train", ")", "==", "y_train", "[", "i", ",", ":", "]", ")", ")", "\n", "test_acc", ".", "append", "(", "np", ".", "mean", "(", "model", ".", "predict", "(", "x_test", ")", "==", "y_test", "[", "i", ",", ":", "]", ")", ")", "\n", "", "return", "train_acc", ",", "test_acc", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.downstream_task.compute_downstream_task": [[26, 80], ["gin.configurable", "disentanglement_lib.evaluation.metrics.utils.generate_batch_factor_code", "disentanglement_lib.evaluation.metrics.utils.generate_batch_factor_code", "disentanglement_lib.evaluation.metrics.utils.make_predictor_fn", "downstream_task._compute_loss", "str", "numpy.mean", "numpy.mean", "numpy.min", "numpy.min", "six.moves.range", "numpy.transpose", "numpy.transpose", "len"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.generate_batch_factor_code", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.generate_batch_factor_code", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.make_predictor_fn", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.strong_downstream_task._compute_loss"], ["@", "gin", ".", "configurable", "(", "\n", "\"downstream_task\"", ",", "\n", "blacklist", "=", "[", "\"ground_truth_data\"", ",", "\"representation_function\"", ",", "\"random_state\"", ",", "\n", "\"artifact_dir\"", "]", ")", "\n", "def", "compute_downstream_task", "(", "ground_truth_data", ",", "\n", "representation_function", ",", "\n", "random_state", ",", "\n", "artifact_dir", "=", "None", ",", "\n", "num_train", "=", "gin", ".", "REQUIRED", ",", "\n", "num_test", "=", "gin", ".", "REQUIRED", ",", "\n", "batch_size", "=", "16", ")", ":", "\n", "  ", "\"\"\"Computes loss of downstream task.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    random_state: Numpy random state used for randomness.\n    artifact_dir: Optional path to directory where artifacts can be saved.\n    num_train: Number of points used for training.\n    num_test: Number of points used for testing.\n    batch_size: Batch size for sampling.\n\n  Returns:\n    Dictionary with scores.\n  \"\"\"", "\n", "del", "artifact_dir", "\n", "scores", "=", "{", "}", "\n", "for", "train_size", "in", "num_train", ":", "\n", "    ", "mus_train", ",", "ys_train", "=", "utils", ".", "generate_batch_factor_code", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "train_size", ",", "random_state", ",", "\n", "batch_size", ")", "\n", "mus_test", ",", "ys_test", "=", "utils", ".", "generate_batch_factor_code", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "num_test", ",", "random_state", ",", "\n", "batch_size", ")", "\n", "predictor_model", "=", "utils", ".", "make_predictor_fn", "(", ")", "\n", "\n", "train_err", ",", "test_err", "=", "_compute_loss", "(", "\n", "np", ".", "transpose", "(", "mus_train", ")", ",", "ys_train", ",", "np", ".", "transpose", "(", "mus_test", ")", ",", "\n", "ys_test", ",", "predictor_model", ")", "\n", "size_string", "=", "str", "(", "train_size", ")", "\n", "scores", "[", "size_string", "+", "\n", "\":mean_train_accuracy\"", "]", "=", "np", ".", "mean", "(", "train_err", ")", "\n", "scores", "[", "size_string", "+", "\n", "\":mean_test_accuracy\"", "]", "=", "np", ".", "mean", "(", "test_err", ")", "\n", "scores", "[", "size_string", "+", "\n", "\":min_train_accuracy\"", "]", "=", "np", ".", "min", "(", "train_err", ")", "\n", "scores", "[", "size_string", "+", "\":min_test_accuracy\"", "]", "=", "np", ".", "min", "(", "test_err", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "train_err", ")", ")", ":", "\n", "      ", "scores", "[", "size_string", "+", "\n", "\":train_accuracy_factor_{}\"", ".", "format", "(", "i", ")", "]", "=", "train_err", "[", "i", "]", "\n", "scores", "[", "size_string", "+", "\":test_accuracy_factor_{}\"", ".", "format", "(", "i", ")", "]", "=", "test_err", "[", "i", "]", "\n", "\n", "", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.downstream_task._compute_loss": [[82, 93], ["six.moves.range", "predictor_fn", "predictor_fn.fit", "train_loss.append", "test_loss.append", "numpy.mean", "numpy.mean", "predictor_fn.predict", "predictor_fn.predict"], "function", ["None"], ["", "def", "_compute_loss", "(", "x_train", ",", "y_train", ",", "x_test", ",", "y_test", ",", "predictor_fn", ")", ":", "\n", "  ", "\"\"\"Compute average accuracy for train and test set.\"\"\"", "\n", "num_factors", "=", "y_train", ".", "shape", "[", "0", "]", "\n", "train_loss", "=", "[", "]", "\n", "test_loss", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_factors", ")", ":", "\n", "    ", "model", "=", "predictor_fn", "(", ")", "\n", "model", ".", "fit", "(", "x_train", ",", "y_train", "[", "i", ",", ":", "]", ")", "\n", "train_loss", ".", "append", "(", "np", ".", "mean", "(", "model", ".", "predict", "(", "x_train", ")", "==", "y_train", "[", "i", ",", ":", "]", ")", ")", "\n", "test_loss", ".", "append", "(", "np", ".", "mean", "(", "model", ".", "predict", "(", "x_test", ")", "==", "y_test", "[", "i", ",", ":", "]", ")", ")", "\n", "", "return", "train_loss", ",", "test_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils_test.UtilsTest.test_histogram_discretizer": [[27, 34], ["numpy.array", "disentanglement_lib.evaluation.metrics.utils._histogram_discretize", "numpy.array", "numpy.testing.assert_array_equal"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils._histogram_discretize"], ["  ", "def", "test_histogram_discretizer", "(", "self", ")", ":", "\n", "# Input of 2D samples.", "\n", "    ", "target", "=", "np", ".", "array", "(", "[", "[", "0.1", ",", "0.2", ",", "0.3", ",", "0.4", ",", "0.5", ",", "0.6", "]", ",", "\n", "[", "0.6", ",", ".5", ",", ".4", ",", ".3", ",", ".2", ",", ".1", "]", "]", ")", "\n", "result", "=", "utils", ".", "_histogram_discretize", "(", "target", ",", "num_bins", "=", "3", ")", "\n", "shouldbe", "=", "np", ".", "array", "(", "[", "[", "1", ",", "1", ",", "2", ",", "2", ",", "3", ",", "3", "]", ",", "[", "3", ",", "3", ",", "2", ",", "2", ",", "1", ",", "1", "]", "]", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "result", ",", "shouldbe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils_test.UtilsTest.test_discrete_entropy": [[35, 40], ["numpy.array", "disentanglement_lib.evaluation.metrics.utils.discrete_entropy", "numpy.log", "numpy.testing.assert_allclose"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.discrete_entropy"], ["", "def", "test_discrete_entropy", "(", "self", ")", ":", "\n", "    ", "target", "=", "np", ".", "array", "(", "[", "[", "1", ",", "1", ",", "2", ",", "2", ",", "3", ",", "3", "]", ",", "[", "3", ",", "3", ",", "2", ",", "2", ",", "1", ",", "1", "]", "]", ")", "\n", "result", "=", "utils", ".", "discrete_entropy", "(", "target", ")", "\n", "shouldbe", "=", "np", ".", "log", "(", "3", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", "[", "shouldbe", ",", "shouldbe", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils_test.UtilsTest.test_discrete_mutual_info": [[41, 47], ["numpy.array", "numpy.array", "disentanglement_lib.evaluation.metrics.utils.discrete_mutual_info", "numpy.array", "numpy.testing.assert_allclose", "numpy.log", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.discrete_mutual_info"], ["", "def", "test_discrete_mutual_info", "(", "self", ")", ":", "\n", "    ", "xs", "=", "np", ".", "array", "(", "[", "[", "1", ",", "2", ",", "1", ",", "2", "]", ",", "[", "1", ",", "1", ",", "2", ",", "2", "]", "]", ")", "\n", "ys", "=", "np", ".", "array", "(", "[", "[", "1", ",", "2", ",", "1", ",", "2", "]", ",", "[", "2", ",", "2", ",", "1", ",", "1", "]", "]", ")", "\n", "result", "=", "utils", ".", "discrete_mutual_info", "(", "xs", ",", "ys", ")", "\n", "shouldbe", "=", "np", ".", "array", "(", "[", "[", "np", ".", "log", "(", "2", ")", ",", "0.", "]", ",", "[", "0.", ",", "np", ".", "log", "(", "2", ")", "]", "]", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "result", ",", "shouldbe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils_test.UtilsTest.test_split_train_test": [[48, 55], ["numpy.zeros", "disentanglement_lib.evaluation.metrics.utils.split_train_test", "numpy.zeros", "numpy.zeros", "numpy.testing.assert_allclose", "numpy.testing.assert_allclose"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.split_train_test"], ["", "def", "test_split_train_test", "(", "self", ")", ":", "\n", "    ", "xs", "=", "np", ".", "zeros", "(", "[", "10", ",", "100", "]", ")", "\n", "xs_train", ",", "xs_test", "=", "utils", ".", "split_train_test", "(", "xs", ",", "0.9", ")", "\n", "shouldbe_train", "=", "np", ".", "zeros", "(", "[", "10", ",", "90", "]", ")", "\n", "shouldbe_test", "=", "np", ".", "zeros", "(", "[", "10", ",", "10", "]", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "xs_train", ",", "shouldbe_train", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "xs_test", ",", "shouldbe_test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.generate_batch_factor_code": [[29, 62], ["min", "ground_truth_data.sample", "numpy.transpose", "numpy.transpose", "representation_function", "numpy.vstack", "numpy.vstack", "representation_function"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_utils.NonActiveRelation.sample"], ["def", "generate_batch_factor_code", "(", "ground_truth_data", ",", "representation_function", ",", "\n", "num_points", ",", "random_state", ",", "batch_size", ")", ":", "\n", "  ", "\"\"\"Sample a single training sample based on a mini-batch of ground-truth data.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observation as input and\n      outputs a representation.\n    num_points: Number of points to sample.\n    random_state: Numpy random state used for randomness.\n    batch_size: Batchsize to sample points.\n\n  Returns:\n    representations: Codes (num_codes, num_points)-np array.\n    factors: Factors generating the codes (num_factors, num_points)-np array.\n  \"\"\"", "\n", "representations", "=", "None", "\n", "factors", "=", "None", "\n", "i", "=", "0", "\n", "while", "i", "<", "num_points", ":", "\n", "    ", "num_points_iter", "=", "min", "(", "num_points", "-", "i", ",", "batch_size", ")", "\n", "current_factors", ",", "current_observations", "=", "ground_truth_data", ".", "sample", "(", "num_points_iter", ",", "random_state", ")", "\n", "if", "i", "==", "0", ":", "\n", "      ", "factors", "=", "current_factors", "\n", "representations", "=", "representation_function", "(", "current_observations", ")", "\n", "", "else", ":", "\n", "      ", "factors", "=", "np", ".", "vstack", "(", "(", "factors", ",", "current_factors", ")", ")", "\n", "representations", "=", "np", ".", "vstack", "(", "(", "representations", ",", "\n", "representation_function", "(", "\n", "current_observations", ")", ")", ")", "\n", "", "i", "+=", "num_points_iter", "\n", "", "return", "np", ".", "transpose", "(", "representations", ")", ",", "np", ".", "transpose", "(", "factors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.split_train_test": [[64, 86], ["int", "numpy.ceil"], "function", ["None"], ["", "def", "split_train_test", "(", "observations", ",", "train_percentage", ")", ":", "\n", "  ", "\"\"\"Splits observations into a train and test set.\n\n  Args:\n    observations: Observations to split in train and test. They can be the\n      representation or the observed factors of variation. The shape is\n      (num_dimensions, num_points) and the split is over the points.\n    train_percentage: Fraction of observations to be used for training.\n\n  Returns:\n    observations_train: Observations to be used for training.\n    observations_test: Observations to be used for testing.\n  \"\"\"", "\n", "num_labelled_samples", "=", "observations", ".", "shape", "[", "1", "]", "\n", "num_labelled_samples_train", "=", "int", "(", "\n", "np", ".", "ceil", "(", "num_labelled_samples", "*", "train_percentage", ")", ")", "\n", "num_labelled_samples_test", "=", "num_labelled_samples", "-", "num_labelled_samples_train", "\n", "observations_train", "=", "observations", "[", ":", ",", ":", "num_labelled_samples_train", "]", "\n", "observations_test", "=", "observations", "[", ":", ",", "num_labelled_samples_train", ":", "]", "\n", "assert", "observations_test", ".", "shape", "[", "1", "]", "==", "num_labelled_samples_test", ",", "\"Wrong size of the test set.\"", "\n", "return", "observations_train", ",", "observations_test", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.obtain_representation": [[88, 113], ["numpy.transpose", "min", "representation_function", "numpy.vstack", "representation_function"], "function", ["None"], ["", "def", "obtain_representation", "(", "observations", ",", "representation_function", ",", "batch_size", ")", ":", "\n", "  ", "\"\"\"\"Obtain representations from observations.\n\n  Args:\n    observations: Observations for which we compute the representation.\n    representation_function: Function that takes observation as input and\n      outputs a representation.\n    batch_size: Batch size to compute the representation.\n  Returns:\n    representations: Codes (num_codes, num_points)-Numpy array.\n  \"\"\"", "\n", "representations", "=", "None", "\n", "num_points", "=", "observations", ".", "shape", "[", "0", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "num_points", ":", "\n", "    ", "num_points_iter", "=", "min", "(", "num_points", "-", "i", ",", "batch_size", ")", "\n", "current_observations", "=", "observations", "[", "i", ":", "i", "+", "num_points_iter", "]", "\n", "if", "i", "==", "0", ":", "\n", "      ", "representations", "=", "representation_function", "(", "current_observations", ")", "\n", "", "else", ":", "\n", "      ", "representations", "=", "np", ".", "vstack", "(", "(", "representations", ",", "\n", "representation_function", "(", "\n", "current_observations", ")", ")", ")", "\n", "", "i", "+=", "num_points_iter", "\n", "", "return", "np", ".", "transpose", "(", "representations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.discrete_mutual_info": [[115, 124], ["numpy.zeros", "six.moves.range", "six.moves.range", "sklearn.metrics.mutual_info_score"], "function", ["None"], ["", "def", "discrete_mutual_info", "(", "mus", ",", "ys", ")", ":", "\n", "  ", "\"\"\"Compute discrete mutual information.\"\"\"", "\n", "num_codes", "=", "mus", ".", "shape", "[", "0", "]", "\n", "num_factors", "=", "ys", ".", "shape", "[", "0", "]", "\n", "m", "=", "np", ".", "zeros", "(", "[", "num_codes", ",", "num_factors", "]", ")", "\n", "for", "i", "in", "range", "(", "num_codes", ")", ":", "\n", "    ", "for", "j", "in", "range", "(", "num_factors", ")", ":", "\n", "      ", "m", "[", "i", ",", "j", "]", "=", "sklearn", ".", "metrics", ".", "mutual_info_score", "(", "ys", "[", "j", ",", ":", "]", ",", "mus", "[", "i", ",", ":", "]", ")", "\n", "", "", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.discrete_entropy": [[126, 133], ["numpy.zeros", "six.moves.range", "sklearn.metrics.mutual_info_score"], "function", ["None"], ["", "def", "discrete_entropy", "(", "ys", ")", ":", "\n", "  ", "\"\"\"Compute discrete mutual information.\"\"\"", "\n", "num_factors", "=", "ys", ".", "shape", "[", "0", "]", "\n", "h", "=", "np", ".", "zeros", "(", "num_factors", ")", "\n", "for", "j", "in", "range", "(", "num_factors", ")", ":", "\n", "    ", "h", "[", "j", "]", "=", "sklearn", ".", "metrics", ".", "mutual_info_score", "(", "ys", "[", "j", ",", ":", "]", ",", "ys", "[", "j", ",", ":", "]", ")", "\n", "", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.make_discretizer": [[135, 141], ["gin.configurable", "discretizer_fn"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"discretizer\"", ",", "blacklist", "=", "[", "\"target\"", "]", ")", "\n", "def", "make_discretizer", "(", "target", ",", "num_bins", "=", "gin", ".", "REQUIRED", ",", "\n", "discretizer_fn", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "  ", "\"\"\"Wrapper that creates discretizers.\"\"\"", "\n", "return", "discretizer_fn", "(", "target", ",", "num_bins", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils._histogram_discretize": [[143, 151], ["gin.configurable", "numpy.zeros_like", "six.moves.range", "numpy.digitize", "numpy.histogram"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"histogram_discretizer\"", ",", "blacklist", "=", "[", "\"target\"", "]", ")", "\n", "def", "_histogram_discretize", "(", "target", ",", "num_bins", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "  ", "\"\"\"Discretization based on histograms.\"\"\"", "\n", "discretized", "=", "np", ".", "zeros_like", "(", "target", ")", "\n", "for", "i", "in", "range", "(", "target", ".", "shape", "[", "0", "]", ")", ":", "\n", "    ", "discretized", "[", "i", ",", ":", "]", "=", "np", ".", "digitize", "(", "target", "[", "i", ",", ":", "]", ",", "np", ".", "histogram", "(", "\n", "target", "[", "i", ",", ":", "]", ",", "num_bins", ")", "[", "1", "]", "[", ":", "-", "1", "]", ")", "\n", "", "return", "discretized", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.normalize_data": [[153, 159], ["numpy.mean", "numpy.std"], "function", ["None"], ["", "def", "normalize_data", "(", "data", ",", "mean", "=", "None", ",", "stddev", "=", "None", ")", ":", "\n", "  ", "if", "mean", "is", "None", ":", "\n", "    ", "mean", "=", "np", ".", "mean", "(", "data", ",", "axis", "=", "1", ")", "\n", "", "if", "stddev", "is", "None", ":", "\n", "    ", "stddev", "=", "np", ".", "std", "(", "data", ",", "axis", "=", "1", ")", "\n", "", "return", "(", "data", "-", "mean", "[", ":", ",", "np", ".", "newaxis", "]", ")", "/", "stddev", "[", ":", ",", "np", ".", "newaxis", "]", ",", "mean", ",", "stddev", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.make_predictor_fn": [[161, 165], ["gin.configurable"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"predictor\"", ")", "\n", "def", "make_predictor_fn", "(", "predictor_fn", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "  ", "\"\"\"Wrapper that creates classifiers.\"\"\"", "\n", "return", "predictor_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.logistic_regression_cv": [[167, 172], ["gin.configurable", "sklearn.linear_model.LogisticRegressionCV", "sklearn.model_selection.KFold"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"logistic_regression_cv\"", ")", "\n", "def", "logistic_regression_cv", "(", ")", ":", "\n", "  ", "\"\"\"Logistic regression with 5 folds cross validation.\"\"\"", "\n", "return", "linear_model", ".", "LogisticRegressionCV", "(", "Cs", "=", "10", ",", "\n", "cv", "=", "model_selection", ".", "KFold", "(", "n_splits", "=", "5", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.gradient_boosting_classifier": [[174, 178], ["gin.configurable", "sklearn.ensemble.GradientBoostingClassifier"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"gradient_boosting_classifier\"", ")", "\n", "def", "gradient_boosting_classifier", "(", ")", ":", "\n", "  ", "\"\"\"Default gradient boosting classifier.\"\"\"", "\n", "return", "ensemble", ".", "GradientBoostingClassifier", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.strong_downstream_task.compute_strong_downstream_task": [[26, 97], ["gin.configurable", "ground_truth_data.sample_factors", "ground_truth_data.sample_factors", "ground_truth_data.sample_observations_from_factors", "ground_truth_data.sample_observations_from_factors", "representation_function", "representation_function", "disentanglement_lib.evaluation.metrics.utils.make_predictor_fn", "numpy.transpose", "numpy.transpose", "strong_downstream_task._compute_loss", "strong_downstream_task._compute_loss_intervene", "str", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.make_predictor_fn", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.strong_downstream_task._compute_loss", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.strong_downstream_task._compute_loss_intervene"], ["@", "gin", ".", "configurable", "(", "\n", "\"strong_downstream_task\"", ",", "\n", "blacklist", "=", "[", "\"ground_truth_data\"", ",", "\"representation_function\"", ",", "\"random_state\"", ",", "\n", "\"artifact_dir\"", "]", ")", "\n", "def", "compute_strong_downstream_task", "(", "ground_truth_data", ",", "\n", "representation_function", ",", "\n", "random_state", ",", "\n", "artifact_dir", "=", "None", ",", "\n", "num_train", "=", "gin", ".", "REQUIRED", ",", "\n", "num_test", "=", "gin", ".", "REQUIRED", ",", "\n", "n_experiment", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "  ", "\"\"\"Computes loss of downstream task.\n\n  This task is about strong generalization under covariate shifts. We first\n  perform an intervention fixing a value for a factor in the whole training set.\n  Then, we train a GBT classifier, and at test time, we consider all other\n  values for that factor. We repeat the experiment n_experiment times, to ensure\n  robustness.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    random_state: Numpy random state used for randomness.\n    artifact_dir: Optional path to directory where artifacts can be saved.\n    num_train: Number of points used for training.\n    num_test: Number of points used for testing.\n    n_experiment: Number of repetitions of the experiment.\n\n  Returns:\n    Dictionary with scores.\n  \"\"\"", "\n", "del", "artifact_dir", "\n", "scores", "=", "{", "}", "\n", "for", "train_size", "in", "num_train", ":", "\n", "# sample factors", "\n", "    ", "factors_train", "=", "ground_truth_data", ".", "sample_factors", "(", "train_size", ",", "random_state", ")", "\n", "factors_test", "=", "ground_truth_data", ".", "sample_factors", "(", "num_test", ",", "random_state", ")", "\n", "# obtain_observations without intervention", "\n", "x_train", "=", "ground_truth_data", ".", "sample_observations_from_factors", "(", "\n", "factors_train", ",", "random_state", ")", "\n", "x_test", "=", "ground_truth_data", ".", "sample_observations_from_factors", "(", "\n", "factors_test", ",", "random_state", ")", "\n", "mus_train", "=", "representation_function", "(", "x_train", ")", "\n", "mus_test", "=", "representation_function", "(", "x_test", ")", "\n", "# train predictor on data without interbention", "\n", "predictor_model", "=", "utils", ".", "make_predictor_fn", "(", ")", "\n", "y_train", "=", "np", ".", "transpose", "(", "factors_train", ")", "\n", "y_test", "=", "np", ".", "transpose", "(", "factors_test", ")", "\n", "train_err", ",", "test_err", "=", "_compute_loss", "(", "\n", "mus_train", ",", "y_train", ",", "mus_test", ",", "\n", "y_test", ",", "predictor_model", ")", "\n", "\n", "# train predictor on data with interventions", "\n", "train_err_int", ",", "test_err_int", "=", "_compute_loss_intervene", "(", "\n", "factors_train", ",", "factors_test", ",", "predictor_model", ",", "ground_truth_data", ",", "\n", "representation_function", ",", "random_state", ",", "n_experiment", ")", "\n", "\n", "size_string", "=", "str", "(", "train_size", ")", "\n", "scores", "[", "size_string", "+", "\n", "\":mean_train_accuracy\"", "]", "=", "np", ".", "mean", "(", "train_err", ")", "\n", "scores", "[", "size_string", "+", "\n", "\":mean_test_accuracy\"", "]", "=", "np", ".", "mean", "(", "test_err", ")", "\n", "scores", "[", "size_string", "+", "\n", "\":mean_strong_train_accuracy\"", "]", "=", "np", ".", "mean", "(", "train_err_int", ")", "\n", "scores", "[", "size_string", "+", "\n", "\":mean_strong_test_accuracy\"", "]", "=", "np", ".", "mean", "(", "test_err_int", ")", "\n", "scores", "[", "size_string", "+", "\":strong_generalization_gap\"", "]", "=", "1.", "-", "(", "\n", "scores", "[", "size_string", "+", "\":mean_strong_test_accuracy\"", "]", "/", "\n", "scores", "[", "size_string", "+", "\":mean_test_accuracy\"", "]", ")", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.strong_downstream_task._compute_loss": [[99, 110], ["six.moves.range", "predictor_fn", "predictor_fn.fit", "train_loss.append", "test_loss.append", "numpy.mean", "numpy.mean", "predictor_fn.predict", "predictor_fn.predict"], "function", ["None"], ["", "def", "_compute_loss", "(", "x_train", ",", "y_train", ",", "x_test", ",", "y_test", ",", "predictor_fn", ")", ":", "\n", "  ", "\"\"\"Compute average accuracy for train and test set.\"\"\"", "\n", "num_factors", "=", "y_train", ".", "shape", "[", "0", "]", "\n", "train_loss", "=", "[", "]", "\n", "test_loss", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_factors", ")", ":", "\n", "    ", "model", "=", "predictor_fn", "(", ")", "\n", "model", ".", "fit", "(", "x_train", ",", "y_train", "[", "i", ",", ":", "]", ")", "\n", "train_loss", ".", "append", "(", "np", ".", "mean", "(", "model", ".", "predict", "(", "x_train", ")", "==", "y_train", "[", "i", ",", ":", "]", ")", ")", "\n", "test_loss", ".", "append", "(", "np", ".", "mean", "(", "model", ".", "predict", "(", "x_test", ")", "==", "y_test", "[", "i", ",", ":", "]", ")", ")", "\n", "", "return", "train_loss", ",", "test_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.strong_downstream_task._compute_loss_intervene": [[112, 141], ["six.moves.range", "six.moves.range", "strong_downstream_task.intervene", "ground_truth_data.sample_observations_from_factors", "ground_truth_data.sample_observations_from_factors", "representation_function", "representation_function", "numpy.transpose", "numpy.transpose", "predictor_fn", "predictor_fn.fit", "train_loss.append", "test_loss.append", "factors_train.copy", "factors_test.copy", "numpy.mean", "numpy.mean", "predictor_fn.predict", "predictor_fn.predict"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.strong_downstream_task.intervene", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors"], ["", "def", "_compute_loss_intervene", "(", "factors_train", ",", "factors_test", ",", "predictor_fn", ",", "\n", "ground_truth_data", ",", "representation_function", ",", "\n", "random_state", ",", "n_experiment", "=", "10", ")", ":", "\n", "  ", "\"\"\"Compute average accuracy for train and test set.\"\"\"", "\n", "num_factors", "=", "factors_train", ".", "shape", "[", "1", "]", "\n", "train_loss", "=", "[", "]", "\n", "test_loss", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_factors", ")", ":", "\n", "    ", "for", "_", "in", "range", "(", "n_experiment", ")", ":", "\n", "      ", "factors_train_int", ",", "factors_test_int", ",", "_", ",", "_", "=", "intervene", "(", "\n", "factors_train", ".", "copy", "(", ")", ",", "factors_test", ".", "copy", "(", ")", ",", "i", ",", "num_factors", ",", "\n", "ground_truth_data", ")", "\n", "\n", "obs_train_int", "=", "ground_truth_data", ".", "sample_observations_from_factors", "(", "\n", "factors_train_int", ",", "random_state", ")", "\n", "obs_test_int", "=", "ground_truth_data", ".", "sample_observations_from_factors", "(", "\n", "factors_test_int", ",", "random_state", ")", "\n", "\n", "x_train_int", "=", "representation_function", "(", "obs_train_int", ")", "\n", "x_test_int", "=", "representation_function", "(", "obs_test_int", ")", "\n", "# train predictor on data without intervention", "\n", "y_train_int", "=", "np", ".", "transpose", "(", "factors_train_int", ")", "\n", "y_test_int", "=", "np", ".", "transpose", "(", "factors_test_int", ")", "\n", "model", "=", "predictor_fn", "(", ")", "\n", "model", ".", "fit", "(", "x_train_int", ",", "y_train_int", "[", "i", ",", ":", "]", ")", "\n", "train_loss", ".", "append", "(", "\n", "np", ".", "mean", "(", "model", ".", "predict", "(", "x_train_int", ")", "==", "y_train_int", "[", "i", ",", ":", "]", ")", ")", "\n", "test_loss", ".", "append", "(", "np", ".", "mean", "(", "model", ".", "predict", "(", "x_test_int", ")", "==", "y_test_int", "[", "i", ",", ":", "]", ")", ")", "\n", "", "", "return", "train_loss", ",", "test_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.strong_downstream_task.intervene": [[143, 160], ["numpy.random.choice", "list", "numpy.random.choice", "list.remove", "numpy.random.choice", "six.moves.range", "six.moves.range"], "function", ["None"], ["", "def", "intervene", "(", "y_train", ",", "y_test", ",", "target_y", ",", "num_factors", ",", "ground_truth_data", ")", ":", "\n", "  ", "\"\"\"Make random intervention on training data and remove it from test.\"\"\"", "\n", "# sample coordinate to intervene on", "\n", "factor_list_to_interv", "=", "[", "j", "for", "j", "in", "range", "(", "num_factors", ")", "if", "j", "!=", "target_y", "]", "\n", "# pick a factor to intervene on", "\n", "interv_factor", "=", "np", ".", "random", ".", "choice", "(", "factor_list_to_interv", ")", "\n", "# get the factor range", "\n", "all_val_factor", "=", "list", "(", "range", "(", "\n", "ground_truth_data", ".", "factors_num_values", "[", "interv_factor", "]", ")", ")", "\n", "factor_interv_train", "=", "np", ".", "random", ".", "choice", "(", "all_val_factor", ")", "\n", "all_val_factor", ".", "remove", "(", "factor_interv_train", ")", "\n", "y_train", "[", ":", ",", "interv_factor", "]", "=", "factor_interv_train", "\n", "\n", "factor_interv_test", "=", "np", ".", "random", ".", "choice", "(", "all_val_factor", ",", "\n", "size", "=", "y_test", ".", "shape", "[", "0", "]", ")", "\n", "y_test", "[", ":", ",", "interv_factor", "]", "=", "factor_interv_test", "\n", "return", "y_train", ",", "y_test", ",", "interv_factor", ",", "factor_interv_train", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr.relative_strength_disentanglement": [[36, 47], ["numpy.nanmean", "numpy.nanmean", "numpy.nan_to_num", "numpy.nan_to_num", "numpy.power", "numpy.sum", "numpy.power", "numpy.sum", "numpy.ndarray.max", "numpy.ndarray.max"], "function", ["None"], ["def", "relative_strength_disentanglement", "(", "corr_matrix", ")", ":", "\n", "  ", "\"\"\"Computes disentanglement using relative strength score.\"\"\"", "\n", "score_x", "=", "np", ".", "nanmean", "(", "\n", "np", ".", "nan_to_num", "(", "\n", "np", ".", "power", "(", "np", ".", "ndarray", ".", "max", "(", "corr_matrix", ",", "axis", "=", "0", ")", ",", "2", ")", "/", "\n", "np", ".", "sum", "(", "corr_matrix", ",", "axis", "=", "0", ")", ",", "0", ")", ")", "\n", "score_y", "=", "np", ".", "nanmean", "(", "\n", "np", ".", "nan_to_num", "(", "\n", "np", ".", "power", "(", "np", ".", "ndarray", ".", "max", "(", "corr_matrix", ",", "axis", "=", "1", ")", ",", "2", ")", "/", "\n", "np", ".", "sum", "(", "corr_matrix", ",", "axis", "=", "1", ")", ",", "0", ")", ")", "\n", "return", "(", "score_x", "+", "score_y", ")", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr.spearman_correlation_conv": [[49, 72], ["range", "numpy.transpose", "range", "corr_y.append", "numpy.absolute", "scipy.stats.spearmanr", "corr_x.append", "numpy.stack", "numpy.stack"], "function", ["None"], ["", "def", "spearman_correlation_conv", "(", "vec1", ",", "vec2", ")", ":", "\n", "  ", "\"\"\"Computes Spearman correlation matrix of two representations.\n\n  Args:\n    vec1: 2d array of representations with axis 0 the batch dimension and axis 1\n      the representation dimension.\n    vec2: 2d array of representations with axis 0 the batch dimension and axis 1\n      the representation dimension.\n\n  Returns:\n    A 2d array with the correlations between all pairwise combinations of\n    elements of both representations are computed. Elements of vec1 correspond\n    to axis 0 and elements of vec2 correspond to axis 1.\n  \"\"\"", "\n", "assert", "vec1", ".", "shape", "==", "vec2", ".", "shape", "\n", "corr_y", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "vec1", ".", "shape", "[", "1", "]", ")", ":", "\n", "    ", "corr_x", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "vec2", ".", "shape", "[", "1", "]", ")", ":", "\n", "      ", "corr", ",", "_", "=", "scipy", ".", "stats", ".", "spearmanr", "(", "vec1", "[", ":", ",", "i", "]", ",", "vec2", "[", ":", ",", "j", "]", ",", "nan_policy", "=", "\"omit\"", ")", "\n", "corr_x", ".", "append", "(", "corr", ")", "\n", "", "corr_y", ".", "append", "(", "np", ".", "stack", "(", "corr_x", ")", ")", "\n", "", "return", "np", ".", "transpose", "(", "np", ".", "absolute", "(", "np", ".", "stack", "(", "corr_y", ",", "axis", "=", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr.lasso_correlation_matrix": [[74, 93], ["sklearn.linear_model.Lasso", "linear_model.Lasso.fit", "numpy.transpose", "numpy.absolute"], "function", ["None"], ["", "def", "lasso_correlation_matrix", "(", "vec1", ",", "vec2", ",", "random_state", "=", "None", ")", ":", "\n", "  ", "\"\"\"Computes correlation matrix of two representations using Lasso Regression.\n\n  Args:\n    vec1: 2d array of representations with axis 0 the batch dimension and axis 1\n      the representation dimension.\n    vec2: 2d array of representations with axis 0 the batch dimension and axis 1\n      the representation dimension.\n    random_state: int used to seed an RNG used for model training.\n\n  Returns:\n    A 2d array with the correlations between all pairwise combinations of\n    elements of both representations are computed. Elements of vec1 correspond\n    to axis 0 and elements of vec2 correspond to axis 1.\n  \"\"\"", "\n", "assert", "vec1", ".", "shape", "==", "vec2", ".", "shape", "\n", "model", "=", "linear_model", ".", "Lasso", "(", "random_state", "=", "random_state", ",", "alpha", "=", "0.1", ")", "\n", "model", ".", "fit", "(", "vec1", ",", "vec2", ")", "\n", "return", "np", ".", "transpose", "(", "np", ".", "absolute", "(", "model", ".", "coef_", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr._generate_representation_batch": [[95, 115], ["ground_truth_data.sample_observations", "fn"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.ground_truth_data.GroundTruthData.sample_observations"], ["", "def", "_generate_representation_batch", "(", "ground_truth_data", ",", "representation_functions", ",", "\n", "batch_size", ",", "random_state", ")", ":", "\n", "  ", "\"\"\"Sample a single mini-batch of representations from the ground-truth data.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_functions: functions that takes observations as input and\n      outputs a dim_representation sized representation for each observation and\n      a vector of the average kl divergence per latent.\n    batch_size: size of batches of representations to be collected at one time.\n    random_state: numpy random state used for randomness.\n\n  Returns:\n    representations: List[batch_size, dim_representation] List of representation\n      batches for each of the representation_functions.\n  \"\"\"", "\n", "# Sample a mini batch of latent variables", "\n", "observations", "=", "ground_truth_data", ".", "sample_observations", "(", "batch_size", ",", "random_state", ")", "\n", "# Compute representations based on the observations.", "\n", "return", "[", "fn", "(", "observations", ")", "for", "fn", "in", "representation_functions", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr._generate_representation_dataset": [[117, 159], ["range", "ValueError", "int", "udr._generate_representation_batch", "range", "len", "numpy.mean", "len", "kl_divergence.append", "representation_points.append", "numpy.zeros", "numpy.zeros", "int"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr._generate_representation_batch"], ["", "def", "_generate_representation_dataset", "(", "ground_truth_data", ",", "\n", "representation_functions", ",", "batch_size", ",", "\n", "num_data_points", ",", "random_state", ")", ":", "\n", "  ", "\"\"\"Sample dataset of represetations for all of the different models.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_functions: functions that takes observations as input and\n      outputs a dim_representation sized representation for each observation and\n      a vector of the average kl divergence per latent.\n    batch_size: size of batches of representations to be collected at one time.\n    num_data_points: total number of points to be sampled for training set.\n    random_state: numpy random state used for randomness.\n\n  Returns:\n    representation_points: (num_data_points, dim_representation)-sized numpy\n      array with training set features.\n    kl: (dim_representation) - The average KL divergence per latent in the\n      representation.\n  \"\"\"", "\n", "if", "num_data_points", "%", "batch_size", "!=", "0", ":", "\n", "    ", "raise", "ValueError", "(", "\"num_data_points must be a multiple of batch_size\"", ")", "\n", "\n", "", "representation_points", "=", "[", "]", "\n", "kl_divergence", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "int", "(", "num_data_points", "/", "batch_size", ")", ")", ":", "\n", "    ", "representation_batch", "=", "_generate_representation_batch", "(", "\n", "ground_truth_data", ",", "representation_functions", ",", "batch_size", ",", "random_state", ")", "\n", "\n", "for", "j", "in", "range", "(", "len", "(", "representation_functions", ")", ")", ":", "\n", "# Initialize the outputs if it hasn't been created yet.", "\n", "      ", "if", "len", "(", "representation_points", ")", "<=", "j", ":", "\n", "        ", "kl_divergence", ".", "append", "(", "\n", "np", ".", "zeros", "(", "(", "int", "(", "num_data_points", "/", "batch_size", ")", ",", "\n", "representation_batch", "[", "j", "]", "[", "1", "]", ".", "shape", "[", "0", "]", ")", ")", ")", "\n", "representation_points", ".", "append", "(", "\n", "np", ".", "zeros", "(", "(", "num_data_points", ",", "representation_batch", "[", "j", "]", "[", "0", "]", ".", "shape", "[", "1", "]", ")", ")", ")", "\n", "", "kl_divergence", "[", "j", "]", "[", "i", ",", ":", "]", "=", "representation_batch", "[", "j", "]", "[", "1", "]", "\n", "representation_points", "[", "j", "]", "[", "i", "*", "batch_size", ":", "(", "i", "+", "1", ")", "*", "batch_size", ",", ":", "]", "=", "(", "\n", "representation_batch", "[", "j", "]", "[", "0", "]", ")", "\n", "", "", "return", "representation_points", ",", "[", "np", ".", "mean", "(", "kl", ",", "axis", "=", "0", ")", "for", "kl", "in", "kl_divergence", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr.compute_udr_sklearn": [[161, 259], ["gin.configurable", "absl.logging.info", "udr._generate_representation_dataset", "len", "absl.logging.info", "absl.logging.info", "numpy.zeros", "range", "numpy.zeros", "range", "np.zeros.tolist", "range", "len", "sklearn.preprocessing.StandardScaler", "preprocessing.StandardScaler.fit", "preprocessing.StandardScaler.transform", "kl_mask.append", "range", "np.zeros.tolist", "model_scores.append", "numpy.greater", "udr.relative_strength_disentanglement", "numpy.median", "udr.lasso_correlation_matrix", "udr.spearman_correlation_conv", "numpy.delete"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr._generate_representation_dataset", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr.relative_strength_disentanglement", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr.lasso_correlation_matrix", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr.spearman_correlation_conv"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"udr_sklearn\"", ",", "\n", "blacklist", "=", "[", "\"ground_truth_data\"", ",", "\"representation_functions\"", ",", "\"random_state\"", "]", ")", "\n", "def", "compute_udr_sklearn", "(", "ground_truth_data", ",", "\n", "representation_functions", ",", "\n", "random_state", ",", "\n", "batch_size", ",", "\n", "num_data_points", ",", "\n", "correlation_matrix", "=", "\"lasso\"", ",", "\n", "filter_low_kl", "=", "True", ",", "\n", "include_raw_correlations", "=", "True", ",", "\n", "kl_filter_threshold", "=", "0.01", ")", ":", "\n", "  ", "\"\"\"Computes the UDR score using scikit-learn.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_functions: functions that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    random_state: numpy random state used for randomness.\n    batch_size: Number of datapoints to compute in a single batch. Useful for\n      reducing memory overhead for larger models.\n    num_data_points: total number of representation datapoints to generate for\n      computing the correlation matrix.\n    correlation_matrix: Type of correlation matrix to generate. Can be either\n      \"lasso\" or \"spearman\".\n    filter_low_kl: If True, filter out elements of the representation vector\n      which have low computed KL divergence.\n    include_raw_correlations: Whether or not to include the raw correlation\n      matrices in the results.\n    kl_filter_threshold: Threshold which latents with average KL divergence\n      lower than the threshold will be ignored when computing disentanglement.\n\n  Returns:\n    scores_dict: a dictionary of the scores computed for UDR with the following\n    keys:\n      raw_correlations: (num_models, num_models, latent_dim, latent_dim) -  The\n        raw computed correlation matrices for all models. The pair of models is\n        indexed by axis 0 and 1 and the matrix represents the computed\n        correlation matrix between latents in axis 2 and 3.\n      pairwise_disentanglement_scores: (num_models, num_models, 1) - The\n        computed disentanglement scores representing the similarity of\n        representation between pairs of models.\n      model_scores: (num_models) - List of aggregated model scores corresponding\n        to the median of the pairwise disentanglement scores for each model.\n  \"\"\"", "\n", "logging", ".", "info", "(", "\"Generating training set.\"", ")", "\n", "inferred_model_reps", ",", "kl", "=", "_generate_representation_dataset", "(", "\n", "ground_truth_data", ",", "representation_functions", ",", "batch_size", ",", "num_data_points", ",", "\n", "random_state", ")", "\n", "\n", "num_models", "=", "len", "(", "inferred_model_reps", ")", "\n", "logging", ".", "info", "(", "\"Number of Models: %s\"", ",", "num_models", ")", "\n", "\n", "logging", ".", "info", "(", "\"Training sklearn models.\"", ")", "\n", "latent_dim", "=", "inferred_model_reps", "[", "0", "]", ".", "shape", "[", "1", "]", "\n", "corr_matrix_all", "=", "np", ".", "zeros", "(", "(", "num_models", ",", "num_models", ",", "latent_dim", ",", "latent_dim", ")", ")", "\n", "\n", "# Normalize and calculate mask based off of kl divergence to remove", "\n", "# uninformative latents.", "\n", "kl_mask", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "inferred_model_reps", ")", ")", ":", "\n", "    ", "scaler", "=", "preprocessing", ".", "StandardScaler", "(", ")", "\n", "scaler", ".", "fit", "(", "inferred_model_reps", "[", "i", "]", ")", "\n", "inferred_model_reps", "[", "i", "]", "=", "scaler", ".", "transform", "(", "inferred_model_reps", "[", "i", "]", ")", "\n", "inferred_model_reps", "[", "i", "]", "=", "inferred_model_reps", "[", "i", "]", "*", "np", ".", "greater", "(", "kl", "[", "i", "]", ",", "0.01", ")", "\n", "kl_mask", ".", "append", "(", "kl", "[", "i", "]", ">", "kl_filter_threshold", ")", "\n", "\n", "", "disentanglement", "=", "np", ".", "zeros", "(", "(", "num_models", ",", "num_models", ",", "1", ")", ")", "\n", "for", "i", "in", "range", "(", "num_models", ")", ":", "\n", "    ", "for", "j", "in", "range", "(", "num_models", ")", ":", "\n", "      ", "if", "i", "==", "j", ":", "\n", "        ", "continue", "\n", "\n", "", "if", "correlation_matrix", "==", "\"lasso\"", ":", "\n", "        ", "corr_matrix", "=", "lasso_correlation_matrix", "(", "inferred_model_reps", "[", "i", "]", ",", "\n", "inferred_model_reps", "[", "j", "]", ",", "\n", "random_state", ")", "\n", "", "else", ":", "\n", "        ", "corr_matrix", "=", "spearman_correlation_conv", "(", "inferred_model_reps", "[", "i", "]", ",", "\n", "inferred_model_reps", "[", "j", "]", ")", "\n", "\n", "", "corr_matrix_all", "[", "i", ",", "j", ",", ":", ",", ":", "]", "=", "corr_matrix", "\n", "if", "filter_low_kl", ":", "\n", "        ", "corr_matrix", "=", "corr_matrix", "[", "kl_mask", "[", "i", "]", ",", "...", "]", "[", "...", ",", "kl_mask", "[", "j", "]", "]", "\n", "", "disentanglement", "[", "i", ",", "j", "]", "=", "relative_strength_disentanglement", "(", "corr_matrix", ")", "\n", "\n", "", "", "scores_dict", "=", "{", "}", "\n", "if", "include_raw_correlations", ":", "\n", "    ", "scores_dict", "[", "\"raw_correlations\"", "]", "=", "corr_matrix_all", ".", "tolist", "(", ")", "\n", "", "scores_dict", "[", "\"pairwise_disentanglement_scores\"", "]", "=", "disentanglement", ".", "tolist", "(", ")", "\n", "\n", "model_scores", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_models", ")", ":", "\n", "    ", "model_scores", ".", "append", "(", "np", ".", "median", "(", "np", ".", "delete", "(", "disentanglement", "[", ":", ",", "i", "]", ",", "i", ")", ")", ")", "\n", "\n", "", "scores_dict", "[", "\"model_scores\"", "]", "=", "model_scores", "\n", "\n", "return", "scores_dict", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr_test.UdrTest.test_metric_spearman": [[28, 57], ["disentanglement_lib.data.ground_truth.dummy_data.DummyData", "numpy.random.RandomState", "numpy.random.permutation", "numpy.random.choice", "disentanglement_lib.evaluation.udr.metrics.udr.compute_udr_sklearn", "udr_test.UdrTest.assertBetween", "udr_test.UdrTest.assertBetween", "int", "numpy.ones", "numpy.reshape", "numpy.ones", "numpy.reshape"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr.compute_udr_sklearn"], ["  ", "def", "test_metric_spearman", "(", "self", ")", ":", "\n", "    ", "ground_truth_data", "=", "dummy_data", ".", "DummyData", "(", ")", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "num_factors", "=", "ground_truth_data", ".", "num_factors", "\n", "batch_size", "=", "10", "\n", "num_data_points", "=", "1000", "\n", "\n", "permutation", "=", "np", ".", "random", ".", "permutation", "(", "num_factors", ")", "\n", "sign_inverse", "=", "np", ".", "random", ".", "choice", "(", "num_factors", ",", "int", "(", "num_factors", "/", "2", ")", ")", "\n", "\n", "def", "rep_fn1", "(", "data", ")", ":", "\n", "      ", "return", "(", "np", ".", "reshape", "(", "data", ",", "(", "batch_size", ",", "-", "1", ")", ")", "[", ":", ",", ":", "num_factors", "]", ",", "\n", "np", ".", "ones", "(", "num_factors", ")", ")", "\n", "\n", "# Should be invariant to permutation and sign inverse.", "\n", "", "def", "rep_fn2", "(", "data", ")", ":", "\n", "      ", "raw_representation", "=", "np", ".", "reshape", "(", "data", ",", "(", "batch_size", ",", "-", "1", ")", ")", "[", ":", ",", ":", "num_factors", "]", "\n", "perm_rep", "=", "raw_representation", "[", ":", ",", "permutation", "]", "\n", "perm_rep", "[", ":", ",", "sign_inverse", "]", "=", "-", "1.0", "*", "perm_rep", "[", ":", ",", "sign_inverse", "]", "\n", "return", "perm_rep", ",", "np", ".", "ones", "(", "num_factors", ")", "\n", "\n", "", "scores", "=", "udr", ".", "compute_udr_sklearn", "(", "\n", "ground_truth_data", ",", "[", "rep_fn1", ",", "rep_fn2", "]", ",", "\n", "random_state", ",", "\n", "batch_size", ",", "\n", "num_data_points", ",", "\n", "correlation_matrix", "=", "\"spearman\"", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"model_scores\"", "]", "[", "0", "]", ",", "0.8", ",", "1.0", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"model_scores\"", "]", "[", "1", "]", ",", "0.8", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr_test.UdrTest.test_metric_lasso": [[58, 87], ["disentanglement_lib.data.ground_truth.dummy_data.DummyData", "numpy.random.RandomState", "numpy.random.permutation", "numpy.random.choice", "disentanglement_lib.evaluation.udr.metrics.udr.compute_udr_sklearn", "udr_test.UdrTest.assertBetween", "udr_test.UdrTest.assertBetween", "int", "numpy.ones", "numpy.reshape", "numpy.ones", "numpy.reshape"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr.compute_udr_sklearn"], ["", "def", "test_metric_lasso", "(", "self", ")", ":", "\n", "    ", "ground_truth_data", "=", "dummy_data", ".", "DummyData", "(", ")", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "num_factors", "=", "ground_truth_data", ".", "num_factors", "\n", "batch_size", "=", "10", "\n", "num_data_points", "=", "1000", "\n", "\n", "permutation", "=", "np", ".", "random", ".", "permutation", "(", "num_factors", ")", "\n", "sign_inverse", "=", "np", ".", "random", ".", "choice", "(", "num_factors", ",", "int", "(", "num_factors", "/", "2", ")", ")", "\n", "\n", "def", "rep_fn1", "(", "data", ")", ":", "\n", "      ", "return", "(", "np", ".", "reshape", "(", "data", ",", "(", "batch_size", ",", "-", "1", ")", ")", "[", ":", ",", ":", "num_factors", "]", ",", "\n", "np", ".", "ones", "(", "num_factors", ")", ")", "\n", "\n", "# Should be invariant to permutation and sign inverse.", "\n", "", "def", "rep_fn2", "(", "data", ")", ":", "\n", "      ", "raw_representation", "=", "np", ".", "reshape", "(", "data", ",", "(", "batch_size", ",", "-", "1", ")", ")", "[", ":", ",", ":", "num_factors", "]", "\n", "perm_rep", "=", "raw_representation", "[", ":", ",", "permutation", "]", "\n", "perm_rep", "[", ":", ",", "sign_inverse", "]", "=", "-", "1.0", "*", "perm_rep", "[", ":", ",", "sign_inverse", "]", "\n", "return", "perm_rep", ",", "np", ".", "ones", "(", "num_factors", ")", "\n", "\n", "", "scores", "=", "udr", ".", "compute_udr_sklearn", "(", "\n", "ground_truth_data", ",", "[", "rep_fn1", ",", "rep_fn2", "]", ",", "\n", "random_state", ",", "\n", "batch_size", ",", "\n", "num_data_points", ",", "\n", "correlation_matrix", "=", "\"lasso\"", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"model_scores\"", "]", "[", "0", "]", ",", "0.8", ",", "1.0", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"model_scores\"", "]", "[", "1", "]", ",", "0.8", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr_test.UdrTest.test_metric_kl": [[88, 123], ["disentanglement_lib.data.ground_truth.dummy_data.DummyData", "numpy.random.RandomState", "disentanglement_lib.evaluation.udr.metrics.udr.compute_udr_sklearn", "udr_test.UdrTest.assertBetween", "udr_test.UdrTest.assertBetween", "disentanglement_lib.evaluation.udr.metrics.udr.compute_udr_sklearn", "udr_test.UdrTest.assertBetween", "udr_test.UdrTest.assertBetween", "numpy.concatenate", "numpy.zeros", "numpy.random.random_sample", "numpy.reshape"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr.compute_udr_sklearn", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr.compute_udr_sklearn"], ["", "def", "test_metric_kl", "(", "self", ")", ":", "\n", "    ", "ground_truth_data", "=", "dummy_data", ".", "DummyData", "(", ")", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "num_factors", "=", "ground_truth_data", ".", "num_factors", "\n", "batch_size", "=", "10", "\n", "num_data_points", "=", "1000", "\n", "\n", "# Representation without KL Mask where only first latent is valid.", "\n", "def", "rep_fn", "(", "data", ")", ":", "\n", "      ", "rep", "=", "np", ".", "concatenate", "(", "[", "\n", "np", ".", "reshape", "(", "data", ",", "(", "batch_size", ",", "-", "1", ")", ")", "[", ":", ",", ":", "1", "]", ",", "\n", "np", ".", "random", ".", "random_sample", "(", "(", "batch_size", ",", "num_factors", "-", "1", ")", ")", "\n", "]", ",", "\n", "axis", "=", "1", ")", "\n", "kl_mask", "=", "np", ".", "zeros", "(", "num_factors", ")", "\n", "kl_mask", "[", "0", "]", "=", "1.0", "\n", "return", "rep", ",", "kl_mask", "\n", "\n", "", "scores", "=", "udr", ".", "compute_udr_sklearn", "(", "\n", "ground_truth_data", ",", "[", "rep_fn", ",", "rep_fn", "]", ",", "\n", "random_state", ",", "\n", "batch_size", ",", "\n", "num_data_points", ",", "\n", "filter_low_kl", "=", "False", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"model_scores\"", "]", "[", "0", "]", ",", "0.0", ",", "0.2", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"model_scores\"", "]", "[", "1", "]", ",", "0.0", ",", "0.2", ")", "\n", "\n", "scores", "=", "udr", ".", "compute_udr_sklearn", "(", "\n", "ground_truth_data", ",", "[", "rep_fn", ",", "rep_fn", "]", ",", "\n", "random_state", ",", "\n", "batch_size", ",", "\n", "num_data_points", ",", "\n", "filter_low_kl", "=", "True", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"model_scores\"", "]", "[", "0", "]", ",", "0.8", ",", "1.0", ")", "\n", "self", ".", "assertBetween", "(", "scores", "[", "\"model_scores\"", "]", "[", "1", "]", ",", "0.8", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr_test.UdrTest.test_relative_strength_disentanglement": [[124, 138], ["numpy.array", "udr_test.UdrTest.assertEqual", "numpy.array", "udr_test.UdrTest.assertBetween", "numpy.array", "udr_test.UdrTest.assertBetween", "numpy.array", "udr_test.UdrTest.assertEqual", "disentanglement_lib.evaluation.udr.metrics.udr.relative_strength_disentanglement", "disentanglement_lib.evaluation.udr.metrics.udr.relative_strength_disentanglement", "disentanglement_lib.evaluation.udr.metrics.udr.relative_strength_disentanglement", "disentanglement_lib.evaluation.udr.metrics.udr.relative_strength_disentanglement"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr.relative_strength_disentanglement", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr.relative_strength_disentanglement", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr.relative_strength_disentanglement", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr.relative_strength_disentanglement"], ["", "def", "test_relative_strength_disentanglement", "(", "self", ")", ":", "\n", "    ", "corr_matrix", "=", "np", ".", "array", "(", "[", "[", "1.0", ",", "0.0", ",", "0.0", "]", ",", "[", "0.0", ",", "1.0", ",", "0.0", "]", ",", "[", "0.0", ",", "0.0", ",", "1.0", "]", "]", ")", "\n", "self", ".", "assertEqual", "(", "udr", ".", "relative_strength_disentanglement", "(", "corr_matrix", ")", ",", "1.0", ")", "\n", "\n", "corr_matrix", "=", "np", ".", "array", "(", "[", "[", "1.0", ",", "1.0", ",", "0.0", "]", ",", "[", "1.0", ",", "1.0", ",", "0.0", "]", ",", "[", "0.0", ",", "0.0", ",", "1.0", "]", "]", ")", "\n", "self", ".", "assertBetween", "(", "\n", "udr", ".", "relative_strength_disentanglement", "(", "corr_matrix", ")", ",", "0.6", ",", "0.7", ")", "\n", "\n", "corr_matrix", "=", "np", ".", "array", "(", "[", "[", "1.0", ",", "1.0", ",", "1.0", "]", ",", "[", "1.0", ",", "1.0", ",", "1.0", "]", ",", "[", "1.0", ",", "1.0", ",", "1.0", "]", "]", ")", "\n", "self", ".", "assertBetween", "(", "\n", "udr", ".", "relative_strength_disentanglement", "(", "corr_matrix", ")", ",", "0.3", ",", "0.4", ")", "\n", "\n", "corr_matrix", "=", "np", ".", "array", "(", "[", "[", "0.0", ",", "0.0", ",", "0.0", "]", ",", "[", "0.0", ",", "0.0", ",", "0.0", "]", ",", "[", "0.0", ",", "0.0", ",", "0.0", "]", "]", ")", "\n", "self", ".", "assertEqual", "(", "udr", ".", "relative_strength_disentanglement", "(", "corr_matrix", ")", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr_test.UdrTest.test_spearman_correlation": [[139, 162], ["numpy.random.RandomState", "numpy.random.RandomState.random_sample", "numpy.copy", "numpy.array", "udr_test.UdrTest.assertTrue", "numpy.random.RandomState.random_sample", "numpy.copy", "numpy.array", "udr_test.UdrTest.assertTrue", "numpy.allclose", "numpy.allclose", "disentanglement_lib.evaluation.udr.metrics.udr.spearman_correlation_conv", "disentanglement_lib.evaluation.udr.metrics.udr.spearman_correlation_conv"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr.spearman_correlation_conv", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr.spearman_correlation_conv"], ["", "def", "test_spearman_correlation", "(", "self", ")", ":", "\n", "    ", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "vec1", "=", "random_state", ".", "random_sample", "(", "(", "1000", ",", "3", ")", ")", "\n", "vec2", "=", "np", ".", "copy", "(", "vec1", ")", "\n", "expected_matrix", "=", "np", ".", "array", "(", "[", "[", "1.0", ",", "0.0", ",", "0.0", "]", ",", "[", "0.0", ",", "1.0", ",", "0.0", "]", ",", "\n", "[", "0.0", ",", "0.0", ",", "1.0", "]", "]", ")", "\n", "self", ".", "assertTrue", "(", "\n", "np", ".", "allclose", "(", "\n", "udr", ".", "spearman_correlation_conv", "(", "vec1", ",", "vec2", ")", ",", "\n", "expected_matrix", ",", "\n", "atol", "=", "0.1", ")", ")", "\n", "\n", "vec1", "=", "random_state", ".", "random_sample", "(", "(", "1000", ",", "3", ")", ")", "\n", "vec2", "=", "np", ".", "copy", "(", "vec1", ")", "\n", "vec2", "[", ":", ",", "1", "]", "=", "vec2", "[", ":", ",", "0", "]", "\n", "\n", "expected_matrix", "=", "np", ".", "array", "(", "[", "[", "1.0", ",", "1.0", ",", "0.0", "]", ",", "[", "0.0", ",", "0.0", ",", "0.0", "]", ",", "\n", "[", "0.0", ",", "0.0", ",", "1.0", "]", "]", ")", "\n", "self", ".", "assertTrue", "(", "\n", "np", ".", "allclose", "(", "\n", "udr", ".", "spearman_correlation_conv", "(", "vec1", ",", "vec2", ")", ",", "\n", "expected_matrix", ",", "\n", "atol", "=", "0.1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr_test.UdrTest.test_lasso_correlation": [[163, 186], ["numpy.random.RandomState", "numpy.copy", "numpy.array", "udr_test.UdrTest.assertTrue", "numpy.copy", "numpy.array", "udr_test.UdrTest.assertTrue", "numpy.random.RandomState.random_sample", "numpy.allclose", "numpy.random.RandomState.random_sample", "numpy.allclose", "disentanglement_lib.evaluation.udr.metrics.udr.lasso_correlation_matrix", "disentanglement_lib.evaluation.udr.metrics.udr.lasso_correlation_matrix"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr.lasso_correlation_matrix", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.udr.lasso_correlation_matrix"], ["", "def", "test_lasso_correlation", "(", "self", ")", ":", "\n", "    ", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "vec1", "=", "random_state", ".", "random_sample", "(", "(", "1000", ",", "3", ")", ")", "*", "10.0", "\n", "vec2", "=", "np", ".", "copy", "(", "vec1", ")", "\n", "expected_matrix", "=", "np", ".", "array", "(", "[", "[", "1.0", ",", "0.0", ",", "0.0", "]", ",", "[", "0.0", ",", "1.0", ",", "0.0", "]", ",", "\n", "[", "0.0", ",", "0.0", ",", "1.0", "]", "]", ")", "\n", "self", ".", "assertTrue", "(", "\n", "np", ".", "allclose", "(", "\n", "udr", ".", "lasso_correlation_matrix", "(", "vec1", ",", "vec2", ",", "random_state", "=", "random_state", ")", ",", "\n", "expected_matrix", ",", "\n", "atol", "=", "0.2", ")", ")", "\n", "\n", "vec1", "=", "random_state", ".", "random_sample", "(", "(", "1000", ",", "3", ")", ")", "*", "10.0", "\n", "vec2", "=", "np", ".", "copy", "(", "vec1", ")", "\n", "vec2", "[", ":", ",", "1", "]", "=", "vec2", "[", ":", ",", "0", "]", "\n", "\n", "expected_matrix", "=", "np", ".", "array", "(", "[", "[", "1.0", ",", "1.0", ",", "0.0", "]", ",", "[", "0.0", ",", "0.0", ",", "0.0", "]", ",", "\n", "[", "0.0", ",", "0.0", ",", "1.0", "]", "]", ")", "\n", "self", ".", "assertTrue", "(", "\n", "np", ".", "allclose", "(", "\n", "udr", ".", "lasso_correlation_matrix", "(", "vec1", ",", "vec2", ",", "random_state", "=", "random_state", ")", ",", "\n", "expected_matrix", ",", "\n", "atol", "=", "0.2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate_test.EvaluateTest.setUp": [[30, 44], ["super().setUp", "disentanglement_lib.utils.resources.get_file", "gin.clear_config", "disentanglement_lib.methods.unsupervised.train.train_with_gin", "disentanglement_lib.methods.unsupervised.train.train_with_gin", "evaluate_test.EvaluateTest.create_tempdir", "evaluate_test.EvaluateTest.create_tempdir", "evaluate_test.EvaluateTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.validation.validation_test.ValidateTest.setUp", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train_with_gin", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train_with_gin"], ["\n", "  ", "def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "EvaluateTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "self", ".", "model_dir", "=", "self", ".", "create_tempdir", "(", "\n", "\"model\"", ",", "cleanup", "=", "absltest", ".", "TempFileCleanup", ".", "OFF", ")", ".", "full_path", "\n", "model_config", "=", "resources", ".", "get_file", "(", "\n", "\"config/tests/methods/unsupervised/train_test.gin\"", ")", "\n", "train", ".", "train_with_gin", "(", "self", ".", "model_dir", ",", "True", ",", "[", "model_config", "]", ")", "\n", "self", ".", "output_dir", "=", "self", ".", "create_tempdir", "(", "\n", "\"output\"", ",", "cleanup", "=", "absltest", ".", "TempFileCleanup", ".", "OFF", ")", ".", "full_path", "\n", "postprocess_config", "=", "resources", ".", "get_file", "(", "\n", "\"config/tests/postprocessing/postprocess_test_configs/mean.gin\"", ")", "\n", "postprocess", ".", "postprocess_with_gin", "(", "self", ".", "model_dir", ",", "self", ".", "output_dir", ",", "True", ",", "\n", "[", "postprocess_config", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate_test.EvaluateTest.test_evaluate": [[45, 53], ["absl.testing.parameterized.parameters", "gin.clear_config", "gin.parse_config_files_and_bindings", "disentanglement_lib.evaluation.udr.evaluate.evaluate", "list", "disentanglement_lib.utils.resources.get_files_in_folder"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate.evaluate", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_files_in_folder"], ["", "@", "parameterized", ".", "parameters", "(", "\n", "list", "(", "\n", "resources", ".", "get_files_in_folder", "(", "\n", "\"config/tests/evaluation/evaluate_test_configs\"", ")", ")", ")", "\n", "def", "test_evaluate", "(", "self", ",", "gin_config", ")", ":", "\n", "# We clear the gin config before running. Otherwise, if a prior test fails,", "\n", "# the gin config is locked and the current test fails.", "\n", "    ", "gin", ".", "clear_config", "(", ")", "\n", "evaluate", ".", "evaluate_with_gin", "(", "self", ".", "output_dir", ",", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate.evaluate": [[42, 106], ["gin.configurable", "time.time", "os.path.join", "tensorflow.io.gfile.isdir", "disentanglement_lib.data.ground_truth.named_data.get_named_ground_truth_data", "os.path.join", "os.path.join", "disentanglement_lib.utils.results.update_result_directory", "gin.query_parameter", "os.path.join", "disentanglement_lib.utils.results.gin_dict", "tensorflow.io.gfile.rmtree", "contextlib.ExitStack", "evaluation_fn", "time.time", "gin.unlock_config", "print", "gin.bind_parameter", "stack.enter_context", "representation_functions.append", "gin_dict[].replace", "tensorflow_hub.eval_function_for_module", "f", "numpy.random.RandomState", "os.path.join", "numpy.mean", "dict", "numpy.array", "compute_gaussian_kl"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.named_data.get_named_ground_truth_data", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.update_result_directory", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.gin_dict", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.compute_gaussian_kl"], ["import", "tensorflow", ".", "compat", ".", "v1", "as", "tf", "\n", "import", "tensorflow_hub", "as", "hub", "\n", "\n", "import", "gin", ".", "tf", "\n", "\n", "\n", "def", "evaluate_with_gin", "(", "model_dir", ",", "\n", "output_dir", ",", "\n", "overwrite", "=", "False", ",", "\n", "gin_config_files", "=", "None", ",", "\n", "gin_bindings", "=", "None", ")", ":", "\n", "  ", "\"\"\"Evaluate a representation based on the provided gin configuration.\n\n  This function will set the provided gin bindings, call the evaluate()\n  function and clear the gin config. Please see the evaluate() for required\n  gin bindings.\n\n  Args:\n    model_dir: String with path to directory where the representation is saved.\n    output_dir: String with the path where the evaluation should be saved.\n    overwrite: Boolean indicating whether to overwrite output directory.\n    gin_config_files: List of gin config files to load.\n    gin_bindings: List of gin bindings to use.\n  \"\"\"", "\n", "if", "gin_config_files", "is", "None", ":", "\n", "    ", "gin_config_files", "=", "[", "]", "\n", "", "if", "gin_bindings", "is", "None", ":", "\n", "    ", "gin_bindings", "=", "[", "]", "\n", "", "gin", ".", "parse_config_files_and_bindings", "(", "gin_config_files", ",", "gin_bindings", ")", "\n", "evaluate", "(", "model_dir", ",", "output_dir", ",", "overwrite", ")", "\n", "gin", ".", "clear_config", "(", ")", "\n", "\n", "\n", "", "@", "gin", ".", "configurable", "(", "\n", "\"evaluation\"", ",", "blacklist", "=", "[", "\"model_dir\"", ",", "\"output_dir\"", ",", "\"overwrite\"", "]", ")", "\n", "def", "evaluate", "(", "model_dir", ",", "\n", "output_dir", ",", "\n", "overwrite", "=", "False", ",", "\n", "evaluation_fn", "=", "gin", ".", "REQUIRED", ",", "\n", "random_seed", "=", "gin", ".", "REQUIRED", ",", "\n", "name", "=", "\"\"", ")", ":", "\n", "  ", "\"\"\"Loads a representation TFHub module and computes disentanglement metrics.\n\n  Args:\n    model_dir: String with path to directory where the representation function\n      is saved.\n    output_dir: String with the path where the results should be saved.\n    overwrite: Boolean indicating whether to overwrite output directory.\n    evaluation_fn: Function used to evaluate the representation (see metrics/\n      for examples).\n    random_seed: Integer with random seed used for training.\n    name: Optional string with name of the metric (can be used to name metrics).\n  \"\"\"", "\n", "# Delete the output directory if it already exists.", "\n", "if", "tf", ".", "gfile", ".", "IsDirectory", "(", "output_dir", ")", ":", "\n", "    ", "if", "overwrite", ":", "\n", "      ", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "output_dir", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"Directory already exists and overwrite is False.\"", ")", "\n", "\n", "# Set up time to keep track of elapsed time in results.", "\n", "", "", "experiment_timer", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Automatically set the proper data set if necessary. We replace the active", "\n", "# gin config as this will lead to a valid gin config file where the data set", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.train_weak_test.TrainTest.test_train_model": [[67, 75], ["absl.testing.parameterized.parameters", "gin.clear_config", "disentanglement_lib.methods.weak.train_weak_lib.train_with_gin", "list", "train_weak_test._config_generator", "train_weak_test.TrainTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train_with_gin", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train_test._config_generator"], ["  ", "@", "parameterized", ".", "parameters", "(", "list", "(", "_config_generator", "(", ")", ")", ")", "\n", "def", "test_train_model", "(", "self", ",", "gin_configs", ",", "gin_bindings", ")", ":", "\n", "# We clear the gin config before running. Otherwise, if a prior test fails,", "\n", "# the gin config is locked and the current test fails.", "\n", "    ", "gin", ".", "clear_config", "(", ")", "\n", "\n", "train_weak_lib", ".", "train_with_gin", "(", "\n", "self", ".", "create_tempdir", "(", ")", ".", "full_path", ",", "True", ",", "gin_configs", ",", "gin_bindings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.train_weak_test.WeakDataTest.test_weak_data": [[79, 92], ["disentanglement_lib.data.ground_truth.dummy_data.DummyData", "gin.parse_config_files_and_bindings", "disentanglement_lib.methods.weak.train_weak_lib.weak_dataset_from_ground_truth_data", "tensorflow.compat.v1.data.make_one_shot_iterator", "tensorflow.compat.v1.data.make_one_shot_iterator.get_next", "train_weak_test.WeakDataTest.test_session", "sess.run", "train_weak_test.WeakDataTest.assertEqual", "train_weak_test.WeakDataTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.train_weak_lib.weak_dataset_from_ground_truth_data"], ["  ", "def", "test_weak_data", "(", "self", ")", ":", "\n", "    ", "ground_truth_data", "=", "dummy_data", ".", "DummyData", "(", ")", "\n", "binding", "=", "[", "\"dynamics.k = 1\"", "]", "\n", "gin", ".", "parse_config_files_and_bindings", "(", "[", "]", ",", "binding", ")", "\n", "dataset", "=", "train_weak_lib", ".", "weak_dataset_from_ground_truth_data", "(", "\n", "ground_truth_data", ",", "0", ")", "\n", "one_shot_iterator", "=", "tf", ".", "compat", ".", "v1", ".", "data", ".", "make_one_shot_iterator", "(", "dataset", ")", "\n", "next_element", "=", "one_shot_iterator", ".", "get_next", "(", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "elem", "=", "sess", ".", "run", "(", "next_element", ")", "\n", "self", ".", "assertEqual", "(", "elem", "[", "0", "]", ".", "shape", ",", "(", "128", ",", "64", ",", "1", ")", ")", "\n", "self", ".", "assertEqual", "(", "elem", "[", "1", "]", ".", "shape", ",", "(", "1", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.train_weak_test._config_generator": [[57, 63], ["disentanglement_lib.utils.resources.get_file"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file"], ["def", "_config_generator", "(", ")", ":", "\n", "  ", "\"\"\"Yields all model configurations that should be tested.\"\"\"", "\n", "model_config_path", "=", "resources", ".", "get_file", "(", "\n", "\"config/tests/methods/unsupervised/train_test.gin\"", ")", "\n", "for", "model", "in", "MODELS_TEST", ":", "\n", "    ", "yield", "[", "model_config_path", "]", ",", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.train_weak_lib.simple_dynamics": [[38, 58], ["gin.configurable", "gin.configurable", "random_state.choice", "random_state.randint", "random_state.choice", "numpy.random.choice", "range"], "function", ["None"], ["@", "gin", ".", "configurable", "(", "\"dynamics\"", ",", "blacklist", "=", "[", "\"z\"", ",", "\"ground_truth_data\"", ",", "\n", "\"random_state\"", ",", "\n", "\"return_index\"", "]", ")", "\n", "def", "simple_dynamics", "(", "z", ",", "ground_truth_data", ",", "random_state", ",", "\n", "return_index", "=", "False", ",", "k", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "  ", "\"\"\"Create the pairs.\"\"\"", "\n", "if", "k", "==", "-", "1", ":", "\n", "    ", "k_observed", "=", "random_state", ".", "randint", "(", "1", ",", "ground_truth_data", ".", "num_factors", ")", "\n", "", "else", ":", "\n", "    ", "k_observed", "=", "k", "\n", "", "index_list", "=", "random_state", ".", "choice", "(", "\n", "z", ".", "shape", "[", "1", "]", ",", "random_state", ".", "choice", "(", "[", "1", ",", "k_observed", "]", ")", ",", "replace", "=", "False", ")", "\n", "idx", "=", "-", "1", "\n", "for", "index", "in", "index_list", ":", "\n", "    ", "z", "[", ":", ",", "index", "]", "=", "np", ".", "random", ".", "choice", "(", "\n", "range", "(", "ground_truth_data", ".", "factors_num_values", "[", "index", "]", ")", ")", "\n", "idx", "=", "index", "\n", "", "if", "return_index", ":", "\n", "    ", "return", "z", ",", "idx", "\n", "", "return", "z", ",", "k_observed", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.train_weak_lib.train_with_gin": [[60, 82], ["gin.parse_config_files_and_bindings", "gin.parse_config_files_and_bindings", "train_weak_lib.train", "gin.clear_config", "gin.clear_config"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train"], ["", "def", "train_with_gin", "(", "model_dir", ",", "\n", "overwrite", "=", "False", ",", "\n", "gin_config_files", "=", "None", ",", "\n", "gin_bindings", "=", "None", ")", ":", "\n", "  ", "\"\"\"Trains a model based on the provided gin configuration.\n\n  This function will set the provided gin bindings, call the train() function\n  and clear the gin config. Please see the train() for required gin bindings.\n\n  Args:\n    model_dir: String with path to directory where model output should be saved.\n    overwrite: Boolean indicating whether to overwrite output directory.\n    gin_config_files: List of gin config files to load.\n    gin_bindings: List of gin bindings to use.\n  \"\"\"", "\n", "if", "gin_config_files", "is", "None", ":", "\n", "    ", "gin_config_files", "=", "[", "]", "\n", "", "if", "gin_bindings", "is", "None", ":", "\n", "    ", "gin_bindings", "=", "[", "]", "\n", "", "gin", ".", "parse_config_files_and_bindings", "(", "gin_config_files", ",", "gin_bindings", ")", "\n", "train", "(", "model_dir", ",", "overwrite", ")", "\n", "gin", ".", "clear_config", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.train_weak_lib.train": [[84, 164], ["gin.configurable", "gin.configurable", "tensorflow.compat.v1.gfile.IsDirectory", "numpy.random.RandomState", "disentanglement_lib.data.ground_truth.named_data.get_named_ground_truth_data", "tensorflow_estimator.python.estimator.tpu.tpu_config.RunConfig", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimator", "time.time", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimator.train", "os.path.join", "disentanglement_lib.methods.unsupervised.gaussian_encoder_model.export_as_tf_hub", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimator.evaluate", "os.path.join", "disentanglement_lib.utils.results.update_result_directory", "os.path.join", "train_weak_lib.visualize_weakly_supervised_dataset", "disentanglement_lib.data.ground_truth.named_data.get_named_ground_truth_data", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimator.latest_checkpoint", "time.time", "os.path.join", "tensorflow.compat.v1.gfile.DeleteRecursively", "ValueError", "tensorflow_estimator.python.estimator.tpu.tpu_config.TPUConfig", "train_weak_lib._make_input_fn", "train_weak_lib._make_input_fn", "np.random.RandomState.randint", "np.random.RandomState.randint"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.named_data.get_named_ground_truth_data", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.gaussian_encoder_model.export_as_tf_hub", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate.evaluate", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.update_result_directory", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.train_weak_lib.visualize_weakly_supervised_dataset", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.named_data.get_named_ground_truth_data", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train._make_input_fn", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train._make_input_fn"], ["", "@", "gin", ".", "configurable", "(", "\"model\"", ",", "blacklist", "=", "[", "\"model_dir\"", ",", "\"overwrite\"", "]", ")", "\n", "def", "train", "(", "model_dir", ",", "\n", "overwrite", "=", "False", ",", "\n", "model", "=", "gin", ".", "REQUIRED", ",", "\n", "training_steps", "=", "gin", ".", "REQUIRED", ",", "\n", "random_seed", "=", "gin", ".", "REQUIRED", ",", "\n", "batch_size", "=", "gin", ".", "REQUIRED", ",", "\n", "name", "=", "\"\"", ")", ":", "\n", "  ", "\"\"\"Trains the estimator and exports the snapshot and the gin config.\n\n  The use of this function requires the gin binding 'dataset.name' to be\n  specified as that determines the data set used for training.\n\n  Args:\n    model_dir: String with path to directory where model output should be saved.\n    overwrite: Boolean indicating whether to overwrite output directory.\n    model: GaussianEncoderModel that should be trained and exported.\n    training_steps: Integer with number of training steps.\n    random_seed: Integer with random seed used for training.\n    batch_size: Integer with the batch size.\n    name: Optional string with name of the model (can be used to name models).\n  \"\"\"", "\n", "# We do not use the variable 'name'. Instead, it can be used to name results", "\n", "# as it will be part of the saved gin config.", "\n", "del", "name", "\n", "\n", "# Delete the output directory if necessary.", "\n", "if", "tf", ".", "compat", ".", "v1", ".", "gfile", ".", "IsDirectory", "(", "model_dir", ")", ":", "\n", "    ", "if", "overwrite", ":", "\n", "      ", "tf", ".", "compat", ".", "v1", ".", "gfile", ".", "DeleteRecursively", "(", "model_dir", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"Directory already exists and overwrite is False.\"", ")", "\n", "\n", "# Create a numpy random state. We will sample the random seeds for training", "\n", "# and evaluation from this.", "\n", "", "", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "random_seed", ")", "\n", "\n", "# Obtain the dataset.", "\n", "dataset", "=", "named_data", ".", "get_named_ground_truth_data", "(", ")", "\n", "# We create a TPUEstimator based on the provided model. This is primarily so", "\n", "# that we could switch to TPU training in the future. For now, we train", "\n", "# locally on GPUs.", "\n", "run_config", "=", "tpu_config", ".", "RunConfig", "(", "\n", "tf_random_seed", "=", "random_seed", ",", "\n", "keep_checkpoint_max", "=", "1", ",", "\n", "tpu_config", "=", "tpu_config", ".", "TPUConfig", "(", "iterations_per_loop", "=", "500", ")", ")", "\n", "tpu_estimator", "=", "TPUEstimator", "(", "\n", "use_tpu", "=", "False", ",", "\n", "model_fn", "=", "model", ".", "model_fn", ",", "\n", "model_dir", "=", "model_dir", ",", "\n", "train_batch_size", "=", "batch_size", ",", "\n", "eval_batch_size", "=", "batch_size", ",", "\n", "config", "=", "run_config", ")", "\n", "\n", "# Set up time to keep track of elapsed time in results.", "\n", "experiment_timer", "=", "time", ".", "time", "(", ")", "\n", "# Do the actual training.", "\n", "tpu_estimator", ".", "train", "(", "\n", "input_fn", "=", "_make_input_fn", "(", "dataset", ",", "random_state", ".", "randint", "(", "2", "**", "32", ")", ")", ",", "\n", "steps", "=", "training_steps", ")", "\n", "# Save model as a TFHub module.", "\n", "output_shape", "=", "named_data", ".", "get_named_ground_truth_data", "(", ")", ".", "observation_shape", "\n", "module_export_path", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"tfhub\"", ")", "\n", "gaussian_encoder_model", ".", "export_as_tf_hub", "(", "model", ",", "output_shape", ",", "\n", "tpu_estimator", ".", "latest_checkpoint", "(", ")", ",", "\n", "module_export_path", ")", "\n", "\n", "# Save the results. The result dir will contain all the results and config", "\n", "# files that we copied along, as we progress in the pipeline. The idea is that", "\n", "# these files will be available for analysis at the end.", "\n", "results_dict", "=", "tpu_estimator", ".", "evaluate", "(", "\n", "input_fn", "=", "_make_input_fn", "(", "\n", "dataset", ",", "random_state", ".", "randint", "(", "2", "**", "32", ")", ",", "num_batches", "=", "1000", "\n", ")", ")", "\n", "results_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"results\"", ")", "\n", "results_dict", "[", "\"elapsed_time\"", "]", "=", "time", ".", "time", "(", ")", "-", "experiment_timer", "\n", "results", ".", "update_result_directory", "(", "results_dir", ",", "\"train\"", ",", "results_dict", ")", "\n", "visualize_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"visualizations\"", ")", "\n", "visualize_weakly_supervised_dataset", "(", "\n", "dataset", ",", "os", ".", "path", ".", "join", "(", "visualize_dir", ",", "\"weak\"", ")", ",", "num_frames", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.train_weak_lib._make_input_fn": [[166, 181], ["train_weak_lib.weak_dataset_from_ground_truth_data", "dataset.take.batch", "tensorflow.compat.v1.data.make_one_shot_iterator().get_next", "dataset.take.take", "tensorflow.compat.v1.data.make_one_shot_iterator"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.train_weak_lib.weak_dataset_from_ground_truth_data"], ["", "def", "_make_input_fn", "(", "ground_truth_data", ",", "seed", ",", "num_batches", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates an input function for the experiments.\"\"\"", "\n", "\n", "def", "load_dataset", "(", "params", ")", ":", "\n", "    ", "\"\"\"TPUEstimator compatible input fuction.\"\"\"", "\n", "dataset", "=", "weak_dataset_from_ground_truth_data", "(", "ground_truth_data", ",", "seed", ")", "\n", "batch_size", "=", "params", "[", "\"batch_size\"", "]", "\n", "# We need to drop the remainder as otherwise we lose the batch size in the", "\n", "# tensor shape. This has no effect as our data set is infinite.", "\n", "dataset", "=", "dataset", ".", "batch", "(", "batch_size", ",", "drop_remainder", "=", "True", ")", "\n", "if", "num_batches", "is", "not", "None", ":", "\n", "      ", "dataset", "=", "dataset", ".", "take", "(", "num_batches", ")", "\n", "", "return", "tf", ".", "compat", ".", "v1", ".", "data", ".", "make_one_shot_iterator", "(", "dataset", ")", ".", "get_next", "(", ")", "\n", "\n", "", "return", "load_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.train_weak_lib.weak_dataset_from_ground_truth_data": [[183, 229], ["numpy.copy", "tensorflow.data.Dataset.from_generator", "numpy.random.RandomState", "ground_truth_data.sample_factors", "ground_truth_data.sample_observations_from_factors", "train_weak_lib.simple_dynamics", "ground_truth_data.sample_observations_from_factors", "numpy.concatenate"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.train_weak_lib.simple_dynamics", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors"], ["", "def", "weak_dataset_from_ground_truth_data", "(", "\n", "ground_truth_data", ",", "random_seed", ")", ":", "\n", "  ", "\"\"\"Generate a tf.data.DataSet disentanglement on weakly-supervised data.\n\n  In this setting we have pairs of frames either temporally close to each other\n  or randomly chosen.\n\n  Args:\n    ground_truth_data: Dataset class.\n    random_seed: Random seed.\n\n  Returns:\n    tf.data.Dataset, each point contains two frames stacked along the first dim\n    and integer labels.\n    For dSprites each point is of type np.array(128, 64, 1).\n  \"\"\"", "\n", "\n", "def", "_generator", "(", ")", ":", "\n", "    ", "\"\"\"Generator fn for the dataset.\"\"\"", "\n", "# We need to hard code the random seed so that the data set can be reset.", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "random_seed", ")", "\n", "while", "True", ":", "\n", "      ", "sampled_factors", "=", "ground_truth_data", ".", "sample_factors", "(", "1", ",", "random_state", ")", "\n", "sampled_observation", "=", "ground_truth_data", ".", "sample_observations_from_factors", "(", "\n", "sampled_factors", ",", "random_state", ")", "\n", "\n", "next_factors", ",", "index", "=", "simple_dynamics", "(", "sampled_factors", ",", "\n", "ground_truth_data", ",", "\n", "random_state", ",", "\n", "return_index", "=", "True", ")", "\n", "next_observation", "=", "ground_truth_data", ".", "sample_observations_from_factors", "(", "\n", "next_factors", ",", "random_state", ")", "\n", "\n", "label", "=", "index", "\n", "yield", "(", "np", ".", "concatenate", "(", "(", "sampled_observation", ",", "next_observation", ")", ",", "\n", "axis", "=", "1", ")", "[", "0", "]", ",", "[", "label", "]", ")", "\n", "\n", "", "", "dataset_shape", "=", "np", ".", "copy", "(", "ground_truth_data", ".", "observation_shape", ")", "\n", "dataset_shape", "[", "0", "]", "=", "dataset_shape", "[", "0", "]", "*", "2", "\n", "weakly_supervised_dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "\n", "_generator", ",", "\n", "(", "tf", ".", "float32", ",", "tf", ".", "int32", ")", ",", "\n", "output_shapes", "=", "(", "dataset_shape", ",", "1", ")", ")", "\n", "\n", "return", "weakly_supervised_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.train_weak_lib.visualize_weakly_supervised_dataset": [[231, 270], ["numpy.random.RandomState", "range", "disentanglement_lib.visualize.visualize_util.save_animation", "tensorflow.compat.v1.gfile.IsDirectory", "tensorflow.compat.v1.gfile.MakeDirs", "images.append", "data.sample_factors", "images[].append", "range", "numpy.array", "os.path.join", "numpy.squeeze", "train_weak_lib.simple_dynamics", "images[].append", "data.sample_observations_from_factors", "numpy.squeeze", "data.sample_observations_from_factors"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_util.save_animation", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.train_weak_lib.simple_dynamics", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors"], ["", "def", "visualize_weakly_supervised_dataset", "(", "\n", "data", ",", "path", ",", "num_animations", "=", "10", ",", "num_frames", "=", "20", ",", "fps", "=", "10", ")", ":", "\n", "  ", "\"\"\"Visualizes the data set by saving images to output_path.\n\n  For each latent factor, outputs 16 images where only that latent factor is\n  varied while all others are kept constant.\n\n  Args:\n    data: String with name of dataset as defined in named_data.py.\n    path: String with path in which to create the visualizations.\n    num_animations: Integer with number of distinct animations to create.\n    num_frames: Integer with number of frames in each animation.\n    fps: Integer with frame rate for the animation.\n  \"\"\"", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "\n", "# Create output folder if necessary.", "\n", "if", "not", "tf", ".", "compat", ".", "v1", ".", "gfile", ".", "IsDirectory", "(", "path", ")", ":", "\n", "    ", "tf", ".", "compat", ".", "v1", ".", "gfile", ".", "MakeDirs", "(", "path", ")", "\n", "\n", "# Create animations.", "\n", "", "images", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_animations", ")", ":", "\n", "    ", "images", ".", "append", "(", "[", "]", ")", "\n", "factor", "=", "data", ".", "sample_factors", "(", "1", ",", "random_state", ")", "\n", "\n", "images", "[", "i", "]", ".", "append", "(", "\n", "np", ".", "squeeze", "(", "\n", "data", ".", "sample_observations_from_factors", "(", "factor", ",", "random_state", ")", ",", "\n", "axis", "=", "0", ")", ")", "\n", "for", "_", "in", "range", "(", "num_frames", ")", ":", "\n", "      ", "factor", ",", "_", "=", "simple_dynamics", "(", "factor", ",", "data", ",", "random_state", ")", "\n", "images", "[", "i", "]", ".", "append", "(", "\n", "np", ".", "squeeze", "(", "\n", "data", ".", "sample_observations_from_factors", "(", "factor", ",", "random_state", ")", ",", "\n", "axis", "=", "0", ")", ")", "\n", "\n", "", "", "visualize_util", ".", "save_animation", "(", "\n", "np", ".", "array", "(", "images", ")", ",", "os", ".", "path", ".", "join", "(", "path", ",", "\"animation.gif\"", ")", ",", "fps", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae_test.WeakVaeTest.test_aggregate_argmax": [[30, 58], ["absl.testing.parameterized.parameters", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "weak_vae_test.WeakVaeTest.session", "sess.run", "weak_vae_test.WeakVaeTest.assertEqual", "weak_vae_test.WeakVaeTest.assertEqual", "numpy.zeros", "numpy.zeros", "numpy.ones", "numpy.ones", "numpy.concatenate", "numpy.concatenate", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "disentanglement_lib.methods.weak.weak_vae.aggregate_argmax", "numpy.zeros", "numpy.ones", "numpy.ones", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.aggregate_argmax"], ["  ", "@", "parameterized", ".", "parameters", "(", "\n", "(", "np", ".", "zeros", "(", "[", "64", ",", "10", "]", ")", ",", "\n", "np", ".", "zeros", "(", "[", "64", ",", "10", "]", ")", ",", "\n", "np", ".", "ones", "(", "[", "64", ",", "10", "]", ")", ",", "\n", "np", ".", "ones", "(", "[", "64", ",", "10", "]", ")", ",", "\n", "np", ".", "concatenate", "(", "(", "np", ".", "zeros", "(", "[", "64", ",", "5", "]", ")", ",", "np", ".", "ones", "(", "[", "64", ",", "5", "]", ")", ")", ",", "axis", "=", "1", ")", ",", "\n", "np", ".", "concatenate", "(", "(", "np", ".", "ones", "(", "[", "64", ",", "5", "]", ")", ",", "np", ".", "zeros", "(", "[", "64", ",", "5", "]", ")", ")", ",", "axis", "=", "1", ")", ")", ",", "\n", "(", "np", ".", "array", "(", "[", "[", "1", ",", "1", "]", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "[", "1", ",", "1", "]", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "[", "0", ",", "0", "]", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "[", "0", ",", "0", "]", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "[", "0", ",", "0.1", "]", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "[", "0", ",", "1", "]", "]", ")", ")", "\n", ")", "\n", "def", "test_aggregate_argmax", "(", "self", ",", "z_mean", ",", "z_logvar", ",", "new_mean", ",", "new_log_var", ",", "\n", "kl_per_point", ",", "target", ")", ":", "\n", "\n", "    ", "mean_tf", "=", "tf", ".", "convert_to_tensor", "(", "z_mean", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "logvar_tf", "=", "tf", ".", "convert_to_tensor", "(", "z_logvar", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "new_mean_tf", "=", "tf", ".", "convert_to_tensor", "(", "new_mean", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "new_log_var_tf", "=", "tf", ".", "convert_to_tensor", "(", "new_log_var", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "kl_per_point_tf", "=", "tf", ".", "convert_to_tensor", "(", "kl_per_point", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "with", "self", ".", "session", "(", ")", "as", "sess", ":", "\n", "      ", "test_value", "=", "sess", ".", "run", "(", "weak_vae", ".", "aggregate_argmax", "(", "\n", "mean_tf", ",", "logvar_tf", ",", "new_mean_tf", ",", "new_log_var_tf", ",", "None", ",", "\n", "kl_per_point_tf", ")", ")", "\n", "self", ".", "assertEqual", "(", "(", "test_value", "[", "0", "]", "==", "target", ")", ".", "all", "(", ")", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "(", "test_value", "[", "1", "]", "==", "target", ")", ".", "all", "(", ")", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.GroupVAEBase.__init__": [[48, 57], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "beta", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "    ", "\"\"\"Creates a beta-VAE model with additional averaging for weak supervision.\n\n    Based on https://arxiv.org/abs/1809.02383.\n\n    Args:\n      beta: Hyperparameter for KL divergence.\n    \"\"\"", "\n", "self", ".", "beta", "=", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.GroupVAEBase.regularizer": [[58, 61], ["None"], "methods", ["None"], ["", "def", "regularizer", "(", "self", ",", "kl_loss", ",", "z_mean", ",", "z_logvar", ",", "z_sampled", ")", ":", "\n", "    ", "del", "z_mean", ",", "z_logvar", ",", "z_sampled", "\n", "return", "self", ".", "beta", "*", "kl_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.GroupVAEBase.model_fn": [[62, 140], ["int", "tensorflow.squeeze", "weak_vae.compute_kl", "tensorflow.exp", "tensorflow.exp", "tensorflow.math.log", "weak_vae.GroupVAEBase.aggregate", "weak_vae.GroupVAEBase.aggregate", "weak_vae.GroupVAEBase.sample_from_latent_distribution", "weak_vae.GroupVAEBase.sample_from_latent_distribution", "disentanglement_lib.methods.shared.losses.make_reconstruction_loss", "disentanglement_lib.methods.shared.losses.make_reconstruction_loss", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "disentanglement_lib.methods.unsupervised.vae.compute_gaussian_kl", "disentanglement_lib.methods.unsupervised.vae.compute_gaussian_kl", "weak_vae.GroupVAEBase.regularizer", "tensorflow.add", "tensorflow.add", "features.get_shape().as_list", "tensorflow.variable_scope", "weak_vae.GroupVAEBase.gaussian_encoder", "weak_vae.GroupVAEBase.gaussian_encoder", "tensorflow.one_hot", "tensorflow.variable_scope", "weak_vae.GroupVAEBase.decode", "weak_vae.GroupVAEBase.decode", "disentanglement_lib.methods.shared.optimizers.make_vae_optimizer", "tensorflow.get_collection", "disentanglement_lib.methods.shared.optimizers.make_vae_optimizer.minimize", "tensorflow.group", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.train.LoggingTensorHook", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimatorSpec", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimatorSpec", "NotImplementedError", "features.get_shape", "z_mean.get_shape().as_list", "tensorflow.train.get_global_step", "z_mean.get_shape", "weak_vae.make_metric_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.compute_kl", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.MLVaeArgmax.aggregate", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.MLVaeArgmax.aggregate", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.gaussian_encoder_model.GaussianEncoderModel.sample_from_latent_distribution", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.gaussian_encoder_model.GaussianEncoderModel.sample_from_latent_distribution", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.losses.make_reconstruction_loss", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.losses.make_reconstruction_loss", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.compute_gaussian_kl", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.compute_gaussian_kl", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.regularizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.gaussian_encoder", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.gaussian_encoder", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.decode", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.decode", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.optimizers.make_vae_optimizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.make_metric_fn"], ["", "def", "model_fn", "(", "self", ",", "features", ",", "labels", ",", "mode", ",", "params", ")", ":", "\n", "    ", "\"\"\"TPUEstimator compatible model function.\"\"\"", "\n", "is_training", "=", "(", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", "\n", "data_shape", "=", "features", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "data_shape", "[", "0", "]", "=", "int", "(", "data_shape", "[", "0", "]", "/", "2", ")", "\n", "features_1", "=", "features", "[", ":", ",", ":", "data_shape", "[", "0", "]", ",", ":", ",", ":", "]", "\n", "features_2", "=", "features", "[", ":", ",", "data_shape", "[", "0", "]", ":", ",", ":", ",", ":", "]", "\n", "with", "tf", ".", "variable_scope", "(", "\n", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "      ", "z_mean", ",", "z_logvar", "=", "self", ".", "gaussian_encoder", "(", "features_1", ",", "\n", "is_training", "=", "is_training", ")", "\n", "z_mean_2", ",", "z_logvar_2", "=", "self", ".", "gaussian_encoder", "(", "features_2", ",", "\n", "is_training", "=", "is_training", ")", "\n", "", "labels", "=", "tf", ".", "squeeze", "(", "tf", ".", "one_hot", "(", "labels", ",", "z_mean", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", ")", ")", "\n", "kl_per_point", "=", "compute_kl", "(", "z_mean", ",", "z_mean_2", ",", "z_logvar", ",", "z_logvar_2", ")", "\n", "\n", "new_mean", "=", "0.5", "*", "z_mean", "+", "0.5", "*", "z_mean_2", "\n", "var_1", "=", "tf", ".", "exp", "(", "z_logvar", ")", "\n", "var_2", "=", "tf", ".", "exp", "(", "z_logvar_2", ")", "\n", "new_log_var", "=", "tf", ".", "math", ".", "log", "(", "0.5", "*", "var_1", "+", "0.5", "*", "var_2", ")", "\n", "\n", "mean_sample_1", ",", "log_var_sample_1", "=", "self", ".", "aggregate", "(", "\n", "z_mean", ",", "z_logvar", ",", "new_mean", ",", "new_log_var", ",", "labels", ",", "kl_per_point", ")", "\n", "mean_sample_2", ",", "log_var_sample_2", "=", "self", ".", "aggregate", "(", "\n", "z_mean_2", ",", "z_logvar_2", ",", "new_mean", ",", "new_log_var", ",", "labels", ",", "kl_per_point", ")", "\n", "z_sampled_1", "=", "self", ".", "sample_from_latent_distribution", "(", "\n", "mean_sample_1", ",", "log_var_sample_1", ")", "\n", "z_sampled_2", "=", "self", ".", "sample_from_latent_distribution", "(", "\n", "mean_sample_2", ",", "log_var_sample_2", ")", "\n", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "      ", "reconstructions_1", "=", "self", ".", "decode", "(", "z_sampled_1", ",", "data_shape", ",", "is_training", ")", "\n", "reconstructions_2", "=", "self", ".", "decode", "(", "z_sampled_2", ",", "data_shape", ",", "is_training", ")", "\n", "", "per_sample_loss_1", "=", "losses", ".", "make_reconstruction_loss", "(", "\n", "features_1", ",", "reconstructions_1", ")", "\n", "per_sample_loss_2", "=", "losses", ".", "make_reconstruction_loss", "(", "\n", "features_2", ",", "reconstructions_2", ")", "\n", "reconstruction_loss_1", "=", "tf", ".", "reduce_mean", "(", "per_sample_loss_1", ")", "\n", "reconstruction_loss_2", "=", "tf", ".", "reduce_mean", "(", "per_sample_loss_2", ")", "\n", "reconstruction_loss", "=", "(", "0.5", "*", "reconstruction_loss_1", "+", "\n", "0.5", "*", "reconstruction_loss_2", ")", "\n", "kl_loss_1", "=", "vae", ".", "compute_gaussian_kl", "(", "mean_sample_1", ",", "log_var_sample_1", ")", "\n", "kl_loss_2", "=", "vae", ".", "compute_gaussian_kl", "(", "mean_sample_2", ",", "log_var_sample_2", ")", "\n", "kl_loss", "=", "0.5", "*", "kl_loss_1", "+", "0.5", "*", "kl_loss_2", "\n", "regularizer", "=", "self", ".", "regularizer", "(", "\n", "kl_loss", ",", "None", ",", "None", ",", "None", ")", "\n", "\n", "loss", "=", "tf", ".", "add", "(", "reconstruction_loss", ",", "\n", "regularizer", ",", "\n", "name", "=", "\"loss\"", ")", "\n", "elbo", "=", "tf", ".", "add", "(", "reconstruction_loss", ",", "kl_loss", ",", "name", "=", "\"elbo\"", ")", "\n", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ":", "\n", "      ", "optimizer", "=", "optimizers", ".", "make_vae_optimizer", "(", ")", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "train_op", "=", "optimizer", ".", "minimize", "(", "\n", "loss", "=", "loss", ",", "global_step", "=", "tf", ".", "train", ".", "get_global_step", "(", ")", ")", "\n", "train_op", "=", "tf", ".", "group", "(", "[", "train_op", ",", "update_ops", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"reconstruction_loss\"", ",", "reconstruction_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"elbo\"", ",", "-", "elbo", ")", "\n", "logging_hook", "=", "tf", ".", "train", ".", "LoggingTensorHook", "(", "{", "\n", "\"loss\"", ":", "loss", ",", "\n", "\"reconstruction_loss\"", ":", "reconstruction_loss", ",", "\n", "\"elbo\"", ":", "-", "elbo", ",", "\n", "}", ",", "\n", "every_n_iter", "=", "100", ")", "\n", "return", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "loss", "=", "loss", ",", "\n", "train_op", "=", "train_op", ",", "\n", "training_hooks", "=", "[", "logging_hook", "]", ")", "\n", "", "elif", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ":", "\n", "      ", "return", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "loss", "=", "loss", ",", "\n", "eval_metrics", "=", "(", "make_metric_fn", "(", "\"reconstruction_loss\"", ",", "\"elbo\"", ",", "\n", "\"regularizer\"", ",", "\"kl_loss\"", ")", ",", "\n", "[", "reconstruction_loss", ",", "-", "elbo", ",", "regularizer", ",", "kl_loss", "]", ")", ")", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "(", "\"Eval mode not supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.GroupVAELabels.aggregate": [[146, 150], ["weak_vae.aggregate_labels"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.aggregate_labels"], ["def", "aggregate", "(", "self", ",", "z_mean", ",", "z_logvar", ",", "new_mean", ",", "new_log_var", ",", "labels", ",", "\n", "kl_per_point", ")", ":", "\n", "    ", "return", "aggregate_labels", "(", "z_mean", ",", "z_logvar", ",", "new_mean", ",", "new_log_var", ",", "labels", ",", "\n", "kl_per_point", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.GroupVAEArgmax.aggregate": [[156, 160], ["weak_vae.aggregate_argmax"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.aggregate_argmax"], ["def", "aggregate", "(", "self", ",", "z_mean", ",", "z_logvar", ",", "new_mean", ",", "new_log_var", ",", "labels", ",", "\n", "kl_per_point", ")", ":", "\n", "    ", "return", "aggregate_argmax", "(", "z_mean", ",", "z_logvar", ",", "new_mean", ",", "new_log_var", ",", "labels", ",", "\n", "kl_per_point", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.MLVae.__init__": [[166, 175], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "beta", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "    ", "\"\"\"Creates a beta-VAE model with additional averaging for weak supervision.\n\n    Based on ML-VAE https://arxiv.org/abs/1705.08841.\n\n    Args:\n      beta: Hyperparameter total correlation.\n    \"\"\"", "\n", "self", ".", "beta", "=", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.MLVae.regularizer": [[176, 179], ["None"], "methods", ["None"], ["", "def", "regularizer", "(", "self", ",", "kl_loss", ",", "z_mean", ",", "z_logvar", ",", "z_sampled", ")", ":", "\n", "    ", "del", "z_mean", ",", "z_logvar", ",", "z_sampled", "\n", "return", "self", ".", "beta", "*", "kl_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.MLVae.model_fn": [[180, 261], ["int", "tensorflow.squeeze", "weak_vae.compute_kl", "tensorflow.exp", "tensorflow.exp", "tensorflow.math.log", "weak_vae.MLVae.aggregate", "weak_vae.MLVae.aggregate", "weak_vae.MLVae.sample_from_latent_distribution", "weak_vae.MLVae.sample_from_latent_distribution", "disentanglement_lib.methods.shared.losses.make_reconstruction_loss", "disentanglement_lib.methods.shared.losses.make_reconstruction_loss", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "disentanglement_lib.methods.unsupervised.vae.compute_gaussian_kl", "disentanglement_lib.methods.unsupervised.vae.compute_gaussian_kl", "weak_vae.MLVae.regularizer", "tensorflow.add", "tensorflow.add", "features.get_shape().as_list", "tensorflow.variable_scope", "weak_vae.MLVae.gaussian_encoder", "weak_vae.MLVae.gaussian_encoder", "tensorflow.one_hot", "tensorflow.variable_scope", "weak_vae.MLVae.decode", "weak_vae.MLVae.decode", "disentanglement_lib.methods.shared.optimizers.make_vae_optimizer", "tensorflow.get_collection", "disentanglement_lib.methods.shared.optimizers.make_vae_optimizer.minimize", "tensorflow.group", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.train.LoggingTensorHook", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimatorSpec", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimatorSpec", "NotImplementedError", "features.get_shape", "z_mean.get_shape().as_list", "tensorflow.train.get_global_step", "z_mean.get_shape", "weak_vae.make_metric_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.compute_kl", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.MLVaeArgmax.aggregate", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.MLVaeArgmax.aggregate", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.gaussian_encoder_model.GaussianEncoderModel.sample_from_latent_distribution", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.gaussian_encoder_model.GaussianEncoderModel.sample_from_latent_distribution", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.losses.make_reconstruction_loss", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.losses.make_reconstruction_loss", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.compute_gaussian_kl", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.compute_gaussian_kl", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.regularizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.gaussian_encoder", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.gaussian_encoder", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.decode", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.decode", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.optimizers.make_vae_optimizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.make_metric_fn"], ["", "def", "model_fn", "(", "self", ",", "features", ",", "labels", ",", "mode", ",", "params", ")", ":", "\n", "    ", "\"\"\"TPUEstimator compatible model function.\"\"\"", "\n", "is_training", "=", "(", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", "\n", "data_shape", "=", "features", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "data_shape", "[", "0", "]", "=", "int", "(", "data_shape", "[", "0", "]", "/", "2", ")", "\n", "features_1", "=", "features", "[", ":", ",", ":", "data_shape", "[", "0", "]", ",", ":", ",", ":", "]", "\n", "features_2", "=", "features", "[", ":", ",", "data_shape", "[", "0", "]", ":", ",", ":", ",", ":", "]", "\n", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "      ", "z_mean", ",", "z_logvar", "=", "self", ".", "gaussian_encoder", "(", "features_1", ",", "\n", "is_training", "=", "is_training", ")", "\n", "z_mean_2", ",", "z_logvar_2", "=", "self", ".", "gaussian_encoder", "(", "features_2", ",", "\n", "is_training", "=", "is_training", ")", "\n", "", "labels", "=", "tf", ".", "squeeze", "(", "tf", ".", "one_hot", "(", "labels", ",", "z_mean", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", ")", ")", "\n", "kl_per_point", "=", "compute_kl", "(", "z_mean", ",", "z_mean_2", ",", "z_logvar", ",", "z_logvar_2", ")", "\n", "\n", "var_1", "=", "tf", ".", "exp", "(", "z_logvar", ")", "\n", "var_2", "=", "tf", ".", "exp", "(", "z_logvar_2", ")", "\n", "new_var", "=", "2", "*", "var_1", "*", "var_2", "/", "(", "var_1", "+", "var_2", ")", "\n", "new_mean", "=", "(", "z_mean", "/", "var_1", "+", "z_mean_2", "/", "var_2", ")", "*", "new_var", "*", "0.5", "\n", "\n", "new_log_var", "=", "tf", ".", "math", ".", "log", "(", "new_var", ")", "\n", "\n", "mean_sample_1", ",", "log_var_sample_1", "=", "self", ".", "aggregate", "(", "\n", "z_mean", ",", "z_logvar", ",", "new_mean", ",", "new_log_var", ",", "labels", ",", "kl_per_point", ")", "\n", "mean_sample_2", ",", "log_var_sample_2", "=", "self", ".", "aggregate", "(", "\n", "z_mean_2", ",", "z_logvar_2", ",", "new_mean", ",", "new_log_var", ",", "labels", ",", "kl_per_point", ")", "\n", "\n", "z_sampled_1", "=", "self", ".", "sample_from_latent_distribution", "(", "\n", "mean_sample_1", ",", "log_var_sample_1", ")", "\n", "z_sampled_2", "=", "self", ".", "sample_from_latent_distribution", "(", "\n", "mean_sample_2", ",", "log_var_sample_2", ")", "\n", "with", "tf", ".", "variable_scope", "(", "\n", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "      ", "reconstructions_1", "=", "self", ".", "decode", "(", "z_sampled_1", ",", "data_shape", ",", "is_training", ")", "\n", "reconstructions_2", "=", "self", ".", "decode", "(", "z_sampled_2", ",", "data_shape", ",", "is_training", ")", "\n", "", "per_sample_loss_1", "=", "losses", ".", "make_reconstruction_loss", "(", "\n", "features_1", ",", "reconstructions_1", ")", "\n", "per_sample_loss_2", "=", "losses", ".", "make_reconstruction_loss", "(", "\n", "features_2", ",", "reconstructions_2", ")", "\n", "reconstruction_loss_1", "=", "tf", ".", "reduce_mean", "(", "per_sample_loss_1", ")", "\n", "reconstruction_loss_2", "=", "tf", ".", "reduce_mean", "(", "per_sample_loss_2", ")", "\n", "reconstruction_loss", "=", "(", "0.5", "*", "reconstruction_loss_1", "+", "\n", "0.5", "*", "reconstruction_loss_2", ")", "\n", "kl_loss_1", "=", "vae", ".", "compute_gaussian_kl", "(", "mean_sample_1", ",", "log_var_sample_1", ")", "\n", "kl_loss_2", "=", "vae", ".", "compute_gaussian_kl", "(", "mean_sample_2", ",", "log_var_sample_2", ")", "\n", "kl_loss", "=", "0.5", "*", "kl_loss_1", "+", "0.5", "*", "kl_loss_2", "\n", "regularizer", "=", "self", ".", "regularizer", "(", "\n", "kl_loss", ",", "None", ",", "None", ",", "None", ")", "\n", "\n", "loss", "=", "tf", ".", "add", "(", "reconstruction_loss", ",", "\n", "regularizer", ",", "\n", "name", "=", "\"loss\"", ")", "\n", "elbo", "=", "tf", ".", "add", "(", "reconstruction_loss", ",", "kl_loss", ",", "name", "=", "\"elbo\"", ")", "\n", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ":", "\n", "      ", "optimizer", "=", "optimizers", ".", "make_vae_optimizer", "(", ")", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "train_op", "=", "optimizer", ".", "minimize", "(", "\n", "loss", "=", "loss", ",", "global_step", "=", "tf", ".", "train", ".", "get_global_step", "(", ")", ")", "\n", "train_op", "=", "tf", ".", "group", "(", "[", "train_op", ",", "update_ops", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"reconstruction_loss\"", ",", "reconstruction_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"elbo\"", ",", "-", "elbo", ")", "\n", "logging_hook", "=", "tf", ".", "train", ".", "LoggingTensorHook", "(", "{", "\n", "\"loss\"", ":", "loss", ",", "\n", "\"reconstruction_loss\"", ":", "reconstruction_loss", ",", "\n", "\"elbo\"", ":", "-", "elbo", ",", "\n", "}", ",", "\n", "every_n_iter", "=", "100", ")", "\n", "return", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "loss", "=", "loss", ",", "\n", "train_op", "=", "train_op", ",", "\n", "training_hooks", "=", "[", "logging_hook", "]", ")", "\n", "", "elif", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ":", "\n", "      ", "return", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "loss", "=", "loss", ",", "\n", "eval_metrics", "=", "(", "make_metric_fn", "(", "\"reconstruction_loss\"", ",", "\"elbo\"", ",", "\n", "\"regularizer\"", ",", "\"kl_loss\"", ")", ",", "\n", "[", "reconstruction_loss", ",", "-", "elbo", ",", "regularizer", ",", "kl_loss", "]", ")", ")", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "(", "\"Eval mode not supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.MLVaeLabels.aggregate": [[267, 271], ["weak_vae.aggregate_labels"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.aggregate_labels"], ["def", "aggregate", "(", "self", ",", "z_mean", ",", "z_logvar", ",", "new_mean", ",", "new_log_var", ",", "labels", ",", "\n", "kl_per_point", ")", ":", "\n", "    ", "return", "aggregate_labels", "(", "z_mean", ",", "z_logvar", ",", "new_mean", ",", "new_log_var", ",", "labels", ",", "\n", "kl_per_point", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.MLVaeArgmax.aggregate": [[277, 281], ["weak_vae.aggregate_argmax"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.aggregate_argmax"], ["def", "aggregate", "(", "self", ",", "z_mean", ",", "z_logvar", ",", "new_mean", ",", "new_log_var", ",", "labels", ",", "\n", "kl_per_point", ")", ":", "\n", "    ", "return", "aggregate_argmax", "(", "z_mean", ",", "z_logvar", ",", "new_mean", ",", "new_log_var", ",", "labels", ",", "\n", "kl_per_point", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.make_weak_loss": [[37, 42], ["gin.configurable", "loss_fn"], "function", ["None"], ["@", "gin", ".", "configurable", "(", "\"weak_loss\"", ",", "blacklist", "=", "[", "\"z1\"", ",", "\"z2\"", ",", "\"labels\"", "]", ")", "\n", "def", "make_weak_loss", "(", "z1", ",", "z2", ",", "labels", ",", "loss_fn", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "  ", "\"\"\"Wrapper that creates weakly-supervised losses.\"\"\"", "\n", "\n", "return", "loss_fn", "(", "z1", ",", "z2", ",", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.aggregate_labels": [[283, 315], ["tensorflow.where", "tensorflow.where", "tensorflow.math.equal", "tensorflow.math.equal", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.reduce_max", "tensorflow.reduce_max"], "function", ["None"], ["", "", "def", "aggregate_labels", "(", "z_mean", ",", "z_logvar", ",", "new_mean", ",", "new_log_var", ",", "labels", ",", "\n", "kl_per_point", ")", ":", "\n", "  ", "\"\"\"Use labels to aggregate.\n\n  Labels contains a one-hot encoding with a single 1 of a factor shared. We\n  enforce which dimension of the latent code learn which factor (dimension 1\n  learns factor 1) and we enforce that each factor of variation is encoded in a\n  single dimension.\n\n  Args:\n    z_mean: Mean of the encoder distribution for the original image.\n    z_logvar: Logvar of the encoder distribution for the original image.\n    new_mean: Average mean of the encoder distribution of the pair of images.\n    new_log_var: Average logvar of the encoder distribution of the pair of\n      images.\n    labels: One-hot-encoding with the position of the dimension that should not\n      be shared.\n    kl_per_point: Distance between the two encoder distributions (unused).\n\n  Returns:\n    Mean and logvariance for the new observation.\n  \"\"\"", "\n", "del", "kl_per_point", "\n", "z_mean_averaged", "=", "tf", ".", "where", "(", "\n", "tf", ".", "math", ".", "equal", "(", "labels", ",", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "reduce_max", "(", "labels", ",", "axis", "=", "1", ")", ",", "1", ")", ")", ",", "\n", "z_mean", ",", "new_mean", ")", "\n", "z_logvar_averaged", "=", "tf", ".", "where", "(", "\n", "tf", ".", "math", ".", "equal", "(", "labels", ",", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "reduce_max", "(", "labels", ",", "axis", "=", "1", ")", ",", "1", ")", ")", ",", "\n", "z_logvar", ",", "new_log_var", ")", "\n", "return", "z_mean_averaged", ",", "z_logvar_averaged", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.aggregate_argmax": [[317, 344], ["tensorflow.equal", "tensorflow.where", "tensorflow.where", "tensorflow.map_fn"], "function", ["None"], ["", "def", "aggregate_argmax", "(", "z_mean", ",", "z_logvar", ",", "new_mean", ",", "new_log_var", ",", "labels", ",", "\n", "kl_per_point", ")", ":", "\n", "  ", "\"\"\"Argmax aggregation with adaptive k.\n\n  The bottom k dimensions in terms of distance are not averaged. K is\n  estimated adaptively by binning the distance into two bins of equal width.\n\n  Args:\n    z_mean: Mean of the encoder distribution for the original image.\n    z_logvar: Logvar of the encoder distribution for the original image.\n    new_mean: Average mean of the encoder distribution of the pair of images.\n    new_log_var: Average logvar of the encoder distribution of the pair of\n      images.\n    labels: One-hot-encoding with the position of the dimension that should not\n      be shared.\n    kl_per_point: Distance between the two encoder distributions.\n\n  Returns:\n    Mean and logvariance for the new observation.\n  \"\"\"", "\n", "del", "labels", "\n", "mask", "=", "tf", ".", "equal", "(", "\n", "tf", ".", "map_fn", "(", "discretize_in_bins", ",", "kl_per_point", ",", "tf", ".", "int32", ")", ",", "\n", "1", ")", "\n", "z_mean_averaged", "=", "tf", ".", "where", "(", "mask", ",", "z_mean", ",", "new_mean", ")", "\n", "z_logvar_averaged", "=", "tf", ".", "where", "(", "mask", ",", "z_logvar", ",", "new_log_var", ")", "\n", "return", "z_mean_averaged", ",", "z_logvar_averaged", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.discretize_in_bins": [[346, 350], ["tensorflow.histogram_fixed_width_bins", "tensorflow.reduce_min", "tensorflow.reduce_max"], "function", ["None"], ["", "def", "discretize_in_bins", "(", "x", ")", ":", "\n", "  ", "\"\"\"Discretize a vector in two bins.\"\"\"", "\n", "return", "tf", ".", "histogram_fixed_width_bins", "(", "\n", "x", ",", "[", "tf", ".", "reduce_min", "(", "x", ")", ",", "tf", ".", "reduce_max", "(", "x", ")", "]", ",", "nbins", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.compute_kl": [[352, 356], ["tensorflow.exp", "tensorflow.exp", "tensorflow.square"], "function", ["None"], ["", "def", "compute_kl", "(", "z_1", ",", "z_2", ",", "logvar_1", ",", "logvar_2", ")", ":", "\n", "  ", "var_1", "=", "tf", ".", "exp", "(", "logvar_1", ")", "\n", "var_2", "=", "tf", ".", "exp", "(", "logvar_2", ")", "\n", "return", "var_1", "/", "var_2", "+", "tf", ".", "square", "(", "z_2", "-", "z_1", ")", "/", "var_2", "-", "1", "+", "logvar_2", "-", "logvar_1", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.weak.weak_vae.make_metric_fn": [[358, 365], ["tensorflow.metrics.mean", "six.moves.zip"], "function", ["None"], ["", "def", "make_metric_fn", "(", "*", "names", ")", ":", "\n", "  ", "\"\"\"Utility function to report tf.metrics in model functions.\"\"\"", "\n", "\n", "def", "metric_fn", "(", "*", "args", ")", ":", "\n", "    ", "return", "{", "name", ":", "tf", ".", "metrics", ".", "mean", "(", "vec", ")", "for", "name", ",", "vec", "in", "zip", "(", "names", ",", "args", ")", "}", "\n", "\n", "", "return", "metric_fn", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.BaseS2VAE.__init__": [[41, 43], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "factor_sizes", ")", ":", "\n", "    ", "self", ".", "factor_sizes", "=", "factor_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.BaseS2VAE.model_fn": [[44, 112], ["tensorflow.to_float", "semi_supervised_vae.BaseS2VAE.sample_from_latent_distribution", "semi_supervised_vae.BaseS2VAE.decode", "disentanglement_lib.methods.shared.losses.make_reconstruction_loss", "tensorflow.reduce_mean", "semi_supervised_vae.compute_gaussian_kl", "semi_supervised_vae.make_annealer", "semi_supervised_vae.make_supervised_loss", "tensorflow.add", "tensorflow.add", "features.get_shape().as_list", "tensorflow.variable_scope", "semi_supervised_vae.BaseS2VAE.gaussian_encoder", "semi_supervised_vae.BaseS2VAE.gaussian_encoder", "tensorflow.train.get_global_step", "semi_supervised_vae.BaseS2VAE.unsupervised_regularizer", "disentanglement_lib.methods.shared.optimizers.make_vae_optimizer", "tensorflow.get_collection", "disentanglement_lib.methods.shared.optimizers.make_vae_optimizer.minimize", "tensorflow.group", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.train.LoggingTensorHook", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimatorSpec", "tensorflow.get_variable_scope", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimatorSpec", "NotImplementedError", "features.get_shape", "tensorflow.train.get_global_step", "semi_supervised_vae.make_metric_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.gaussian_encoder_model.GaussianEncoderModel.sample_from_latent_distribution", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.decode", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.losses.make_reconstruction_loss", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.compute_gaussian_kl", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.make_annealer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.make_supervised_loss", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.gaussian_encoder", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.gaussian_encoder", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.S2BetaTCVAE.unsupervised_regularizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.optimizers.make_vae_optimizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.make_metric_fn"], ["", "def", "model_fn", "(", "self", ",", "features", ",", "labels", ",", "mode", ",", "params", ")", ":", "\n", "    ", "\"\"\"TPUEstimator compatible model function.\n\n    Args:\n      features: Batch of images [batch_size, 64, 64, 3].\n      labels: Tuple with batch of features [batch_size, 64, 64, 3] and the\n        labels [batch_size, labels_size].\n      mode: Mode for the TPUEstimator.\n      params: Dict with parameters.\n\n    Returns:\n      TPU estimator.\n    \"\"\"", "\n", "\n", "is_training", "=", "(", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", "\n", "labelled_features", "=", "labels", "[", "0", "]", "\n", "labels", "=", "tf", ".", "to_float", "(", "labels", "[", "1", "]", ")", "\n", "data_shape", "=", "features", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "      ", "z_mean", ",", "z_logvar", "=", "self", ".", "gaussian_encoder", "(", "\n", "features", ",", "is_training", "=", "is_training", ")", "\n", "z_mean_labelled", ",", "_", "=", "self", ".", "gaussian_encoder", "(", "\n", "labelled_features", ",", "is_training", "=", "is_training", ")", "\n", "", "z_sampled", "=", "self", ".", "sample_from_latent_distribution", "(", "z_mean", ",", "z_logvar", ")", "\n", "reconstructions", "=", "self", ".", "decode", "(", "z_sampled", ",", "data_shape", ",", "is_training", ")", "\n", "per_sample_loss", "=", "losses", ".", "make_reconstruction_loss", "(", "features", ",", "reconstructions", ")", "\n", "reconstruction_loss", "=", "tf", ".", "reduce_mean", "(", "per_sample_loss", ")", "\n", "kl_loss", "=", "compute_gaussian_kl", "(", "z_mean", ",", "z_logvar", ")", "\n", "gamma_annealed", "=", "make_annealer", "(", "self", ".", "gamma_sup", ",", "tf", ".", "train", ".", "get_global_step", "(", ")", ")", "\n", "supervised_loss", "=", "make_supervised_loss", "(", "z_mean_labelled", ",", "labels", ",", "\n", "self", ".", "factor_sizes", ")", "\n", "regularizer", "=", "self", ".", "unsupervised_regularizer", "(", "\n", "kl_loss", ",", "z_mean", ",", "z_logvar", ",", "z_sampled", ")", "+", "gamma_annealed", "*", "supervised_loss", "\n", "loss", "=", "tf", ".", "add", "(", "reconstruction_loss", ",", "regularizer", ",", "name", "=", "\"loss\"", ")", "\n", "elbo", "=", "tf", ".", "add", "(", "reconstruction_loss", ",", "kl_loss", ",", "name", "=", "\"elbo\"", ")", "\n", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ":", "\n", "      ", "optimizer", "=", "optimizers", ".", "make_vae_optimizer", "(", ")", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "train_op", "=", "optimizer", ".", "minimize", "(", "\n", "loss", "=", "loss", ",", "global_step", "=", "tf", ".", "train", ".", "get_global_step", "(", ")", ")", "\n", "train_op", "=", "tf", ".", "group", "(", "[", "train_op", ",", "update_ops", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"reconstruction_loss\"", ",", "reconstruction_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"elbo\"", ",", "-", "elbo", ")", "\n", "\n", "logging_hook", "=", "tf", ".", "train", ".", "LoggingTensorHook", "(", "{", "\n", "\"loss\"", ":", "loss", ",", "\n", "\"reconstruction_loss\"", ":", "reconstruction_loss", ",", "\n", "\"elbo\"", ":", "-", "elbo", ",", "\n", "\"supervised_loss\"", ":", "supervised_loss", "\n", "}", ",", "\n", "every_n_iter", "=", "100", ")", "\n", "return", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "loss", "=", "loss", ",", "\n", "train_op", "=", "train_op", ",", "\n", "training_hooks", "=", "[", "logging_hook", "]", ")", "\n", "", "elif", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ":", "\n", "      ", "return", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "loss", "=", "loss", ",", "\n", "eval_metrics", "=", "(", "make_metric_fn", "(", "\"reconstruction_loss\"", ",", "\"elbo\"", ",", "\n", "\"regularizer\"", ",", "\"kl_loss\"", ",", "\n", "\"supervised_loss\"", ")", ",", "[", "\n", "reconstruction_loss", ",", "-", "elbo", ",", "\n", "regularizer", ",", "kl_loss", ",", "supervised_loss", "\n", "]", ")", ")", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "(", "\"Eval mode not supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.S2BetaVAE.__init__": [[364, 382], ["semi_supervised_vae.BaseS2VAE.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.__init__"], ["def", "__init__", "(", "self", ",", "factor_sizes", ",", "beta", "=", "gin", ".", "REQUIRED", ",", "gamma_sup", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "    ", "\"\"\"Creates a semi-supervised beta-VAE model.\n\n    Implementing Eq. 4 of \"beta-VAE: Learning Basic Visual Concepts with a\n    Constrained Variational Framework\"\n    (https://openreview.net/forum?id=Sy2fzU9gl) with additional supervision.\n\n    Args:\n      factor_sizes: Size of each factor of variation.\n      beta: Hyperparameter for the unsupervised regularizer.\n      gamma_sup: Hyperparameter for the supervised regularizer.\n\n    Returns:\n      model_fn: Model function for TPUEstimator.\n    \"\"\"", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "gamma_sup", "=", "gamma_sup", "\n", "super", "(", "S2BetaVAE", ",", "self", ")", ".", "__init__", "(", "factor_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.S2BetaVAE.unsupervised_regularizer": [[383, 387], ["None"], "methods", ["None"], ["", "def", "unsupervised_regularizer", "(", "self", ",", "kl_loss", ",", "z_mean", ",", "z_logvar", ",", "z_sampled", ")", ":", "\n", "    ", "\"\"\"Standard betaVAE regularizer.\"\"\"", "\n", "del", "z_mean", ",", "z_logvar", ",", "z_sampled", "\n", "return", "self", ".", "beta", "*", "kl_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.SupervisedVAE.model_fn": [[393, 453], ["tensorflow.to_float", "semi_supervised_vae.SupervisedVAE.sample_from_latent_distribution", "semi_supervised_vae.SupervisedVAE.decode", "disentanglement_lib.methods.shared.losses.make_reconstruction_loss", "tensorflow.reduce_mean", "semi_supervised_vae.make_supervised_loss", "tensorflow.add", "features.get_shape().as_list", "tensorflow.variable_scope", "semi_supervised_vae.SupervisedVAE.gaussian_encoder", "semi_supervised_vae.SupervisedVAE.gaussian_encoder", "tensorflow.stop_gradient", "disentanglement_lib.methods.shared.optimizers.make_vae_optimizer", "tensorflow.get_collection", "disentanglement_lib.methods.shared.optimizers.make_vae_optimizer.minimize", "tensorflow.group", "tensorflow.summary.scalar", "tensorflow.train.LoggingTensorHook", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimatorSpec", "tensorflow.get_variable_scope", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimatorSpec", "NotImplementedError", "features.get_shape", "tensorflow.train.get_global_step", "semi_supervised_vae.make_metric_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.gaussian_encoder_model.GaussianEncoderModel.sample_from_latent_distribution", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.decode", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.losses.make_reconstruction_loss", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.make_supervised_loss", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.gaussian_encoder", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.gaussian_encoder", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.optimizers.make_vae_optimizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.make_metric_fn"], ["def", "model_fn", "(", "self", ",", "features", ",", "labels", ",", "mode", ",", "params", ")", ":", "\n", "    ", "\"\"\"TPUEstimator compatible model function.\n\n    Args:\n      features: Batch of images [batch_size, 64, 64, 3].\n      labels: Tuple with batch of features [batch_size, 64, 64, 3] and the\n        labels [batch_size, labels_size].\n      mode: Mode for the TPUEstimator.\n      params: Dict with parameters.\n\n    Returns:\n      TPU Estimator.\n    \"\"\"", "\n", "\n", "is_training", "=", "(", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", "\n", "labelled_features", "=", "labels", "[", "0", "]", "\n", "labels", "=", "tf", ".", "to_float", "(", "labels", "[", "1", "]", ")", "\n", "data_shape", "=", "features", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "      ", "z_mean", ",", "z_logvar", "=", "self", ".", "gaussian_encoder", "(", "\n", "features", ",", "is_training", "=", "is_training", ")", "\n", "z_mean_labelled", ",", "_", "=", "self", ".", "gaussian_encoder", "(", "\n", "labelled_features", ",", "is_training", "=", "is_training", ")", "\n", "", "z_sampled", "=", "self", ".", "sample_from_latent_distribution", "(", "z_mean", ",", "z_logvar", ")", "\n", "reconstructions", "=", "self", ".", "decode", "(", "\n", "tf", ".", "stop_gradient", "(", "z_sampled", ")", ",", "data_shape", ",", "is_training", ")", "\n", "per_sample_loss", "=", "losses", ".", "make_reconstruction_loss", "(", "features", ",", "reconstructions", ")", "\n", "reconstruction_loss", "=", "tf", ".", "reduce_mean", "(", "per_sample_loss", ")", "\n", "supervised_loss", "=", "make_supervised_loss", "(", "z_mean_labelled", ",", "labels", ",", "\n", "self", ".", "factor_sizes", ")", "\n", "regularizer", "=", "supervised_loss", "\n", "loss", "=", "tf", ".", "add", "(", "reconstruction_loss", ",", "regularizer", ",", "name", "=", "\"loss\"", ")", "\n", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ":", "\n", "      ", "optimizer", "=", "optimizers", ".", "make_vae_optimizer", "(", ")", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "train_op", "=", "optimizer", ".", "minimize", "(", "\n", "loss", "=", "loss", ",", "global_step", "=", "tf", ".", "train", ".", "get_global_step", "(", ")", ")", "\n", "train_op", "=", "tf", ".", "group", "(", "[", "train_op", ",", "update_ops", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"reconstruction_loss\"", ",", "reconstruction_loss", ")", "\n", "\n", "logging_hook", "=", "tf", ".", "train", ".", "LoggingTensorHook", "(", "{", "\n", "\"loss\"", ":", "loss", ",", "\n", "\"reconstruction_loss\"", ":", "reconstruction_loss", ",", "\n", "\"supervised_loss\"", ":", "supervised_loss", "\n", "}", ",", "\n", "every_n_iter", "=", "100", ")", "\n", "return", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "loss", "=", "loss", ",", "\n", "train_op", "=", "train_op", ",", "\n", "training_hooks", "=", "[", "logging_hook", "]", ")", "\n", "", "elif", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ":", "\n", "      ", "return", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "loss", "=", "loss", ",", "\n", "eval_metrics", "=", "(", "make_metric_fn", "(", "\"reconstruction_loss\"", ",", "\"regularizer\"", ",", "\n", "\"supervised_loss\"", ")", ",", "\n", "[", "reconstruction_loss", ",", "regularizer", ",", "supervised_loss", "]", ")", ")", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "(", "\"Eval mode not supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.MineVAE.__init__": [[497, 510], ["semi_supervised_vae.BaseS2VAE.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.__init__"], ["def", "__init__", "(", "self", ",", "factor_sizes", ",", "gamma_sup", "=", "gin", ".", "REQUIRED", ",", "beta", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "    ", "\"\"\"Creates a semi-supervised MineVAE model.\n\n    Regularize mutual information using mine.\n\n    Args:\n      factor_sizes: Size of each factor of variation.\n      gamma_sup: Hyperparameter for the supervised regularizer.\n      beta: Hyperparameter for the unsupervised regularizer.\n    \"\"\"", "\n", "self", ".", "gamma_sup", "=", "gamma_sup", "\n", "self", ".", "beta", "=", "beta", "\n", "super", "(", "MineVAE", ",", "self", ")", ".", "__init__", "(", "factor_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.MineVAE.model_fn": [[511, 580], ["tensorflow.to_float", "range", "tensorflow.reshape", "semi_supervised_vae.MineVAE.sample_from_latent_distribution", "semi_supervised_vae.MineVAE.decode", "disentanglement_lib.methods.shared.losses.make_reconstruction_loss", "tensorflow.reduce_mean", "semi_supervised_vae.compute_gaussian_kl", "tensorflow.add", "semi_supervised_vae.make_annealer", "tensorflow.add", "features.get_shape().as_list", "tensorflow.variable_scope", "semi_supervised_vae.MineVAE.gaussian_encoder", "semi_supervised_vae.MineVAE.gaussian_encoder", "range", "tensorflow.add_n", "tensorflow.train.get_global_step", "disentanglement_lib.methods.shared.optimizers.make_vae_optimizer", "tensorflow.trainable_variables", "tensorflow.get_collection", "disentanglement_lib.methods.shared.optimizers.make_vae_optimizer.minimize", "tensorflow.group", "tensorflow.summary.scalar", "tensorflow.train.LoggingTensorHook", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimatorSpec", "tensorflow.get_variable_scope", "tensorflow.to_float.get_shape().as_list", "tensorflow.layers.flatten", "tensorflow.layers.flatten", "semi_supervised_vae.mine", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimatorSpec", "NotImplementedError", "features.get_shape", "z_mean.get_shape().as_list", "tensorflow.train.get_global_step", "tensorflow.to_float.get_shape", "z_mean.get_shape", "tensorflow.math.square", "semi_supervised_vae.make_metric_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.gaussian_encoder_model.GaussianEncoderModel.sample_from_latent_distribution", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.decode", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.losses.make_reconstruction_loss", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.compute_gaussian_kl", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.make_annealer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.gaussian_encoder", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.gaussian_encoder", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.optimizers.make_vae_optimizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.mine", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.make_metric_fn"], ["", "def", "model_fn", "(", "self", ",", "features", ",", "labels", ",", "mode", ",", "params", ")", ":", "\n", "    ", "\"\"\"TPUEstimator compatible model function.\"\"\"", "\n", "is_training", "=", "(", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", "\n", "labelled_features", "=", "labels", "[", "0", "]", "\n", "labels", "=", "tf", ".", "to_float", "(", "labels", "[", "1", "]", ")", "\n", "data_shape", "=", "features", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "      ", "z_mean", ",", "z_logvar", "=", "self", ".", "gaussian_encoder", "(", "\n", "features", ",", "is_training", "=", "is_training", ")", "\n", "z_mean_labelled", ",", "_", "=", "self", ".", "gaussian_encoder", "(", "\n", "labelled_features", ",", "is_training", "=", "is_training", ")", "\n", "\n", "", "supervised_loss", "=", "[", "]", "\n", "mine_ops", "=", "[", "]", "\n", "\n", "for", "l", "in", "range", "(", "labels", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", ")", ":", "\n", "      ", "for", "r", "in", "range", "(", "z_mean", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", ")", ":", "\n", "        ", "label_for_mi", "=", "tf", ".", "layers", ".", "flatten", "(", "labels", "[", ":", ",", "l", "]", ")", "\n", "representation_for_mi", "=", "tf", ".", "layers", ".", "flatten", "(", "z_mean_labelled", "[", ":", ",", "r", "]", ")", "\n", "mi_lr", ",", "op_lr", "=", "mine", "(", "representation_for_mi", ",", "label_for_mi", ",", "\n", "\"estimator_network_%d_%d\"", "%", "(", "l", ",", "r", ")", ")", "\n", "if", "l", "!=", "r", ":", "\n", "          ", "supervised_loss", "=", "supervised_loss", "+", "[", "tf", ".", "math", ".", "square", "(", "mi_lr", ")", "]", "\n", "", "mine_ops", "=", "mine_ops", "+", "[", "op_lr", "]", "\n", "", "", "supervised_loss", "=", "tf", ".", "reshape", "(", "tf", ".", "add_n", "(", "supervised_loss", ")", ",", "[", "]", ")", "\n", "z_sampled", "=", "self", ".", "sample_from_latent_distribution", "(", "z_mean", ",", "z_logvar", ")", "\n", "reconstructions", "=", "self", ".", "decode", "(", "z_sampled", ",", "data_shape", ",", "is_training", ")", "\n", "per_sample_loss", "=", "losses", ".", "make_reconstruction_loss", "(", "features", ",", "reconstructions", ")", "\n", "reconstruction_loss", "=", "tf", ".", "reduce_mean", "(", "per_sample_loss", ")", "\n", "kl_loss", "=", "compute_gaussian_kl", "(", "z_mean", ",", "z_logvar", ")", "\n", "standard_vae_loss", "=", "tf", ".", "add", "(", "\n", "reconstruction_loss", ",", "self", ".", "beta", "*", "kl_loss", ",", "name", "=", "\"VAE_loss\"", ")", "\n", "gamma_annealed", "=", "make_annealer", "(", "self", ".", "gamma_sup", ",", "tf", ".", "train", ".", "get_global_step", "(", ")", ")", "\n", "s2_mine_vae_loss", "=", "tf", ".", "add", "(", "\n", "standard_vae_loss", ",", "gamma_annealed", "*", "supervised_loss", ",", "\n", "name", "=", "\"s2_factor_VAE_loss\"", ")", "\n", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ":", "\n", "      ", "optimizer_vae", "=", "optimizers", ".", "make_vae_optimizer", "(", ")", "\n", "all_variables", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "encoder_vars", "=", "[", "var", "for", "var", "in", "all_variables", "if", "\"encoder\"", "in", "var", ".", "name", "]", "\n", "decoder_vars", "=", "[", "var", "for", "var", "in", "all_variables", "if", "\"decoder\"", "in", "var", ".", "name", "]", "\n", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "train_op_vae", "=", "optimizer_vae", ".", "minimize", "(", "\n", "loss", "=", "s2_mine_vae_loss", ",", "\n", "global_step", "=", "tf", ".", "train", ".", "get_global_step", "(", ")", ",", "\n", "var_list", "=", "encoder_vars", "+", "decoder_vars", ")", "\n", "train_op", "=", "tf", ".", "group", "(", "train_op_vae", ",", "mine_ops", ",", "update_ops", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"reconstruction_loss\"", ",", "reconstruction_loss", ")", "\n", "logging_hook", "=", "tf", ".", "train", ".", "LoggingTensorHook", "(", "{", "\n", "\"loss\"", ":", "s2_mine_vae_loss", ",", "\n", "\"reconstruction_loss\"", ":", "reconstruction_loss", ",", "\n", "\"supervised_loss\"", ":", "supervised_loss", ",", "\n", "}", ",", "\n", "every_n_iter", "=", "50", ")", "\n", "return", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "loss", "=", "s2_mine_vae_loss", ",", "\n", "train_op", "=", "train_op", ",", "\n", "training_hooks", "=", "[", "logging_hook", "]", ")", "\n", "", "elif", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ":", "\n", "      ", "return", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "loss", "=", "s2_mine_vae_loss", ",", "\n", "eval_metrics", "=", "(", "make_metric_fn", "(", "\"reconstruction_loss\"", ",", "\"supervised_loss\"", ",", "\n", "\"kl_loss\"", ")", ",", "\n", "[", "reconstruction_loss", ",", "supervised_loss", ",", "kl_loss", "]", ")", ")", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "(", "\"Eval mode not supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.S2FactorVAE.__init__": [[586, 600], ["semi_supervised_vae.BaseS2VAE.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.__init__"], ["def", "__init__", "(", "self", ",", "factor_sizes", ",", "gamma", "=", "gin", ".", "REQUIRED", ",", "gamma_sup", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "    ", "\"\"\"Creates a semi-supervised FactorVAE model.\n\n    Implementing Eq. 2 of \"Disentangling by Factorizing\"\n    (https://arxiv.org/pdf/1802.05983).\n\n    Args:\n      factor_sizes: Size of each factor of variation.\n      gamma: Hyperparameter for the unsupervised regularizer.\n      gamma_sup: Hyperparameter for the supervised regularizer.\n    \"\"\"", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "gamma_sup", "=", "gamma_sup", "\n", "super", "(", "S2FactorVAE", ",", "self", ")", ".", "__init__", "(", "factor_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.S2FactorVAE.model_fn": [[601, 679], ["tensorflow.to_float", "semi_supervised_vae.S2FactorVAE.sample_from_latent_distribution", "disentanglement_lib.methods.unsupervised.vae.shuffle_codes", "semi_supervised_vae.S2FactorVAE.decode", "disentanglement_lib.methods.shared.losses.make_reconstruction_loss", "tensorflow.reduce_mean", "semi_supervised_vae.compute_gaussian_kl", "tensorflow.add", "tensorflow.reduce_mean", "semi_supervised_vae.make_annealer", "semi_supervised_vae.make_supervised_loss", "tensorflow.add", "tensorflow.add", "features.get_shape().as_list", "tensorflow.variable_scope", "semi_supervised_vae.S2FactorVAE.gaussian_encoder", "semi_supervised_vae.S2FactorVAE.gaussian_encoder", "tensorflow.variable_scope", "disentanglement_lib.methods.shared.architectures.make_discriminator", "disentanglement_lib.methods.shared.architectures.make_discriminator", "tensorflow.train.get_global_step", "disentanglement_lib.methods.shared.optimizers.make_vae_optimizer", "disentanglement_lib.methods.shared.optimizers.make_discriminator_optimizer", "tensorflow.trainable_variables", "tensorflow.get_collection", "disentanglement_lib.methods.shared.optimizers.make_vae_optimizer.minimize", "disentanglement_lib.methods.shared.optimizers.make_discriminator_optimizer.minimize", "tensorflow.group", "tensorflow.summary.scalar", "tensorflow.train.LoggingTensorHook", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimatorSpec", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimatorSpec", "NotImplementedError", "features.get_shape", "tensorflow.log", "tensorflow.log", "tensorflow.train.get_global_step", "tensorflow.train.get_global_step", "semi_supervised_vae.make_metric_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.gaussian_encoder_model.GaussianEncoderModel.sample_from_latent_distribution", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.shuffle_codes", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.decode", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.losses.make_reconstruction_loss", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.compute_gaussian_kl", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.make_annealer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.make_supervised_loss", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.gaussian_encoder", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.gaussian_encoder", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.architectures.make_discriminator", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.architectures.make_discriminator", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.optimizers.make_vae_optimizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.optimizers.make_discriminator_optimizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.make_metric_fn"], ["", "def", "model_fn", "(", "self", ",", "features", ",", "labels", ",", "mode", ",", "params", ")", ":", "\n", "    ", "\"\"\"TPUEstimator compatible model function.\"\"\"", "\n", "is_training", "=", "(", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", "\n", "labelled_features", "=", "labels", "[", "0", "]", "\n", "labels", "=", "tf", ".", "to_float", "(", "labels", "[", "1", "]", ")", "\n", "data_shape", "=", "features", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "      ", "z_mean", ",", "z_logvar", "=", "self", ".", "gaussian_encoder", "(", "\n", "features", ",", "is_training", "=", "is_training", ")", "\n", "z_mean_labelled", ",", "_", "=", "self", ".", "gaussian_encoder", "(", "\n", "labelled_features", ",", "is_training", "=", "is_training", ")", "\n", "", "z_sampled", "=", "self", ".", "sample_from_latent_distribution", "(", "z_mean", ",", "z_logvar", ")", "\n", "z_shuffle", "=", "vae", ".", "shuffle_codes", "(", "z_sampled", ")", "\n", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "      ", "logits_z", ",", "probs_z", "=", "architectures", ".", "make_discriminator", "(", "\n", "z_sampled", ",", "is_training", "=", "is_training", ")", "\n", "_", ",", "probs_z_shuffle", "=", "architectures", ".", "make_discriminator", "(", "\n", "z_shuffle", ",", "is_training", "=", "is_training", ")", "\n", "", "reconstructions", "=", "self", ".", "decode", "(", "z_sampled", ",", "data_shape", ",", "is_training", ")", "\n", "per_sample_loss", "=", "losses", ".", "make_reconstruction_loss", "(", "features", ",", "reconstructions", ")", "\n", "reconstruction_loss", "=", "tf", ".", "reduce_mean", "(", "per_sample_loss", ")", "\n", "kl_loss", "=", "compute_gaussian_kl", "(", "z_mean", ",", "z_logvar", ")", "\n", "standard_vae_loss", "=", "tf", ".", "add", "(", "reconstruction_loss", ",", "kl_loss", ",", "name", "=", "\"VAE_loss\"", ")", "\n", "# tc = E[log(p_real)-log(p_fake)] = E[logit_real - logit_fake]", "\n", "tc_loss_per_sample", "=", "logits_z", "[", ":", ",", "0", "]", "-", "logits_z", "[", ":", ",", "1", "]", "\n", "tc_loss", "=", "tf", ".", "reduce_mean", "(", "tc_loss_per_sample", ",", "axis", "=", "0", ")", "\n", "regularizer", "=", "kl_loss", "+", "self", ".", "gamma", "*", "tc_loss", "\n", "gamma_annealed", "=", "make_annealer", "(", "self", ".", "gamma_sup", ",", "tf", ".", "train", ".", "get_global_step", "(", ")", ")", "\n", "supervised_loss", "=", "make_supervised_loss", "(", "z_mean_labelled", ",", "labels", ",", "\n", "self", ".", "factor_sizes", ")", "\n", "s2_factor_vae_loss", "=", "tf", ".", "add", "(", "\n", "standard_vae_loss", ",", "\n", "self", ".", "gamma", "*", "tc_loss", "+", "gamma_annealed", "*", "supervised_loss", ",", "\n", "name", "=", "\"s2_factor_VAE_loss\"", ")", "\n", "discr_loss", "=", "tf", ".", "add", "(", "\n", "0.5", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "log", "(", "probs_z", "[", ":", ",", "0", "]", ")", ")", ",", "\n", "0.5", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "log", "(", "probs_z_shuffle", "[", ":", ",", "1", "]", ")", ")", ",", "\n", "name", "=", "\"discriminator_loss\"", ")", "\n", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ":", "\n", "      ", "optimizer_vae", "=", "optimizers", ".", "make_vae_optimizer", "(", ")", "\n", "optimizer_discriminator", "=", "optimizers", ".", "make_discriminator_optimizer", "(", ")", "\n", "all_variables", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "encoder_vars", "=", "[", "var", "for", "var", "in", "all_variables", "if", "\"encoder\"", "in", "var", ".", "name", "]", "\n", "decoder_vars", "=", "[", "var", "for", "var", "in", "all_variables", "if", "\"decoder\"", "in", "var", ".", "name", "]", "\n", "discriminator_vars", "=", "[", "var", "for", "var", "in", "all_variables", "if", "\"discriminator\"", "in", "var", ".", "name", "]", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "train_op_vae", "=", "optimizer_vae", ".", "minimize", "(", "\n", "loss", "=", "s2_factor_vae_loss", ",", "\n", "global_step", "=", "tf", ".", "train", ".", "get_global_step", "(", ")", ",", "\n", "var_list", "=", "encoder_vars", "+", "decoder_vars", ")", "\n", "train_op_discr", "=", "optimizer_discriminator", ".", "minimize", "(", "\n", "loss", "=", "-", "discr_loss", ",", "\n", "global_step", "=", "tf", ".", "train", ".", "get_global_step", "(", ")", ",", "\n", "var_list", "=", "discriminator_vars", ")", "\n", "train_op", "=", "tf", ".", "group", "(", "train_op_vae", ",", "train_op_discr", ",", "update_ops", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"reconstruction_loss\"", ",", "reconstruction_loss", ")", "\n", "logging_hook", "=", "tf", ".", "train", ".", "LoggingTensorHook", "(", "{", "\n", "\"loss\"", ":", "s2_factor_vae_loss", ",", "\n", "\"reconstruction_loss\"", ":", "reconstruction_loss", "\n", "}", ",", "\n", "every_n_iter", "=", "50", ")", "\n", "return", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "loss", "=", "s2_factor_vae_loss", ",", "\n", "train_op", "=", "train_op", ",", "\n", "training_hooks", "=", "[", "logging_hook", "]", ")", "\n", "", "elif", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ":", "\n", "      ", "return", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "loss", "=", "s2_factor_vae_loss", ",", "\n", "eval_metrics", "=", "(", "make_metric_fn", "(", "\"reconstruction_loss\"", ",", "\"regularizer\"", ",", "\n", "\"kl_loss\"", ",", "\"supervised_loss\"", ")", ",", "[", "\n", "reconstruction_loss", ",", "regularizer", ",", "\n", "kl_loss", ",", "supervised_loss", "\n", "]", ")", ")", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "(", "\"Eval mode not supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.S2DIPVAE.__init__": [[685, 710], ["semi_supervised_vae.BaseS2VAE.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.__init__"], ["def", "__init__", "(", "self", ",", "\n", "factor_sizes", ",", "\n", "lambda_od", "=", "gin", ".", "REQUIRED", ",", "\n", "lambda_d_factor", "=", "gin", ".", "REQUIRED", ",", "\n", "gamma_sup", "=", "gin", ".", "REQUIRED", ",", "\n", "dip_type", "=", "\"i\"", ")", ":", "\n", "    ", "\"\"\"Creates a DIP-VAE model.\n\n    Based on Equation 6 and 7 of \"Variational Inference of Disentangled Latent\n    Concepts from Unlabeled Observations\"\n    (https://openreview.net/pdf?id=H1kG7GZAW).\n\n    Args:\n      factor_sizes: Size of each factor of variation.\n      lambda_od: Hyperparameter for off diagonal values of covariance matrix.\n      lambda_d_factor: Hyperparameter for diagonal values of covariance matrix\n        lambda_d = lambda_d_factor*lambda_od.\n      gamma_sup: Hyperparameter for the supervised regularizer.\n      dip_type: \"i\" or \"ii\".\n    \"\"\"", "\n", "self", ".", "lambda_od", "=", "lambda_od", "\n", "self", ".", "lambda_d_factor", "=", "lambda_d_factor", "\n", "self", ".", "dip_type", "=", "dip_type", "\n", "self", ".", "gamma_sup", "=", "gamma_sup", "\n", "super", "(", "S2DIPVAE", ",", "self", ")", ".", "__init__", "(", "factor_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.S2DIPVAE.unsupervised_regularizer": [[711, 728], ["disentanglement_lib.methods.unsupervised.vae.compute_covariance_z_mean", "disentanglement_lib.methods.unsupervised.vae.regularize_diag_off_diag_dip", "tensorflow.matrix_diag", "tensorflow.reduce_mean", "disentanglement_lib.methods.unsupervised.vae.regularize_diag_off_diag_dip", "NotImplementedError", "tensorflow.exp"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.compute_covariance_z_mean", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.regularize_diag_off_diag_dip", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.regularize_diag_off_diag_dip"], ["", "def", "unsupervised_regularizer", "(", "self", ",", "kl_loss", ",", "z_mean", ",", "z_logvar", ",", "z_sampled", ")", ":", "\n", "    ", "cov_z_mean", "=", "vae", ".", "compute_covariance_z_mean", "(", "z_mean", ")", "\n", "lambda_d", "=", "self", ".", "lambda_d_factor", "*", "self", ".", "lambda_od", "\n", "if", "self", ".", "dip_type", "==", "\"i\"", ":", "# Eq 6 page 4", "\n", "# mu = z_mean is [batch_size, num_latent]", "\n", "# Compute cov_p(x) [mu(x)] = E[mu*mu^T] - E[mu]E[mu]^T]", "\n", "      ", "cov_dip_regularizer", "=", "vae", ".", "regularize_diag_off_diag_dip", "(", "\n", "cov_z_mean", ",", "self", ".", "lambda_od", ",", "lambda_d", ")", "\n", "", "elif", "self", ".", "dip_type", "==", "\"ii\"", ":", "\n", "      ", "cov_enc", "=", "tf", ".", "matrix_diag", "(", "tf", ".", "exp", "(", "z_logvar", ")", ")", "\n", "expectation_cov_enc", "=", "tf", ".", "reduce_mean", "(", "cov_enc", ",", "axis", "=", "0", ")", "\n", "cov_z", "=", "expectation_cov_enc", "+", "cov_z_mean", "\n", "cov_dip_regularizer", "=", "vae", ".", "regularize_diag_off_diag_dip", "(", "\n", "cov_z", ",", "self", ".", "lambda_od", ",", "lambda_d", ")", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "(", "\"DIP variant not supported.\"", ")", "\n", "", "return", "kl_loss", "+", "cov_dip_regularizer", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.S2BetaTCVAE.__init__": [[734, 750], ["semi_supervised_vae.BaseS2VAE.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.__init__"], ["def", "__init__", "(", "self", ",", "factor_sizes", ",", "beta", "=", "gin", ".", "REQUIRED", ",", "gamma_sup", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "    ", "\"\"\"Creates a beta-TC-VAE model.\n\n    Based on Equation 5 with alpha = gamma = 1 of \"Isolating Sources of\n    Disentanglement in Variational Autoencoders\"\n    (https://arxiv.org/pdf/1802.04942).\n    If alpha = gamma = 1, Eq. 5 can be written as ELBO + (1 - beta) * TC.\n\n    Args:\n      factor_sizes: Size of each factor of variation.\n      beta: Hyperparameter total correlation.\n      gamma_sup: Hyperparameter for the supervised regularizer.\n    \"\"\"", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "gamma_sup", "=", "gamma_sup", "\n", "super", "(", "S2BetaTCVAE", ",", "self", ")", ".", "__init__", "(", "factor_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.S2BetaTCVAE.unsupervised_regularizer": [[751, 754], ["disentanglement_lib.methods.unsupervised.vae.total_correlation"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.total_correlation"], ["", "def", "unsupervised_regularizer", "(", "self", ",", "kl_loss", ",", "z_mean", ",", "z_logvar", ",", "z_sampled", ")", ":", "\n", "    ", "tc", "=", "(", "self", ".", "beta", "-", "1.", ")", "*", "vae", ".", "total_correlation", "(", "z_sampled", ",", "z_mean", ",", "z_logvar", ")", "\n", "return", "tc", "+", "kl_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.sample_from_latent_distribution": [[114, 120], ["tensorflow.add", "tensorflow.exp", "tensorflow.random_normal", "tensorflow.shape"], "function", ["None"], ["", "", "", "def", "sample_from_latent_distribution", "(", "z_mean", ",", "z_logvar", ")", ":", "\n", "  ", "\"\"\"Sample from the encoder distribution with reparametrization trick.\"\"\"", "\n", "return", "tf", ".", "add", "(", "\n", "z_mean", ",", "\n", "tf", ".", "exp", "(", "z_logvar", "/", "2", ")", "*", "tf", ".", "random_normal", "(", "tf", ".", "shape", "(", "z_mean", ")", ",", "0", ",", "1", ")", ",", "\n", "name", "=", "\"latent\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.compute_gaussian_kl": [[122, 128], ["tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.square", "tensorflow.exp"], "function", ["None"], ["", "def", "compute_gaussian_kl", "(", "z_mean", ",", "z_logvar", ")", ":", "\n", "  ", "\"\"\"Compute KL divergence between input Gaussian and Standard Normal.\"\"\"", "\n", "return", "tf", ".", "reduce_mean", "(", "\n", "0.5", "*", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "square", "(", "z_mean", ")", "+", "tf", ".", "exp", "(", "z_logvar", ")", "-", "z_logvar", "-", "1", ",", "[", "1", "]", ")", ",", "\n", "name", "=", "\"kl_loss\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.make_metric_fn": [[130, 137], ["tensorflow.metrics.mean", "six.moves.zip"], "function", ["None"], ["", "def", "make_metric_fn", "(", "*", "names", ")", ":", "\n", "  ", "\"\"\"Utility function to report tf.metrics in model functions.\"\"\"", "\n", "\n", "def", "metric_fn", "(", "*", "args", ")", ":", "\n", "    ", "return", "{", "name", ":", "tf", ".", "metrics", ".", "mean", "(", "vec", ")", "for", "name", ",", "vec", "in", "zip", "(", "names", ",", "args", ")", "}", "\n", "\n", "", "return", "metric_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.make_annealer": [[139, 146], ["gin.configurable", "anneal_fn"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"annealer\"", ",", "blacklist", "=", "[", "\"gamma\"", ",", "\"step\"", "]", ")", "\n", "def", "make_annealer", "(", "gamma", ",", "\n", "step", ",", "\n", "iteration_threshold", "=", "gin", ".", "REQUIRED", ",", "\n", "anneal_fn", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "  ", "\"\"\"Wrapper that creates annealing function.\"\"\"", "\n", "return", "anneal_fn", "(", "gamma", ",", "step", ",", "iteration_threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.fixed_annealer": [[148, 153], ["gin.configurable"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"fixed\"", ",", "blacklist", "=", "[", "\"gamma\"", ",", "\"step\"", "]", ")", "\n", "def", "fixed_annealer", "(", "gamma", ",", "step", ",", "iteration_threshold", ")", ":", "\n", "  ", "\"\"\"No annealing.\"\"\"", "\n", "del", "step", ",", "iteration_threshold", "\n", "return", "gamma", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.annealed_annealer": [[155, 160], ["gin.configurable", "tensorflow.math.minimum", "tensorflow.to_float"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"anneal\"", ",", "blacklist", "=", "[", "\"gamma\"", ",", "\"step\"", "]", ")", "\n", "def", "annealed_annealer", "(", "gamma", ",", "step", ",", "iteration_threshold", ")", ":", "\n", "  ", "\"\"\"Linear annealing.\"\"\"", "\n", "return", "tf", ".", "math", ".", "minimum", "(", "gamma", "*", "1.", ",", "\n", "gamma", "*", "1.", "*", "tf", ".", "to_float", "(", "step", ")", "/", "iteration_threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.fine_tune_annealer": [[162, 179], ["gin.configurable", "tensorflow.math.minimum", "tensorflow.to_float", "tensorflow.math.maximum", "tensorflow.to_float", "tensorflow.to_float"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"fine_tune\"", ",", "blacklist", "=", "[", "\"gamma\"", ",", "\"step\"", "]", ")", "\n", "def", "fine_tune_annealer", "(", "gamma", ",", "step", ",", "iteration_threshold", ")", ":", "\n", "  ", "\"\"\"Fine tuning.\n\n  This annealer returns zero if step < iteration_threshold and gamma otherwise.\n\n  Args:\n    gamma: Weight of supervised loss.\n    step: Current step of training.\n    iteration_threshold: When to return gamma instead of zero.\n\n  Returns:\n    Either gamma or zero.\n  \"\"\"", "\n", "return", "gamma", "*", "tf", ".", "math", ".", "minimum", "(", "\n", "tf", ".", "to_float", "(", "1", ")", ",", "\n", "tf", ".", "math", ".", "maximum", "(", "tf", ".", "to_float", "(", "0", ")", ",", "tf", ".", "to_float", "(", "step", "-", "iteration_threshold", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.make_supervised_loss": [[181, 188], ["gin.configurable", "tensorflow.variable_scope", "loss_fn"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"supervised_loss\"", ",", "blacklist", "=", "[", "\"representation\"", ",", "\"labels\"", "]", ")", "\n", "def", "make_supervised_loss", "(", "representation", ",", "labels", ",", "\n", "factor_sizes", "=", "None", ",", "loss_fn", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "  ", "\"\"\"Wrapper that creates supervised loss.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "\"supervised_loss\"", ")", ":", "\n", "    ", "loss", "=", "loss_fn", "(", "representation", ",", "labels", ",", "factor_sizes", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.normalize_labels": [[190, 206], ["numpy.repeat", "numpy.expand_dims", "numpy.float32"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.repeat"], ["", "def", "normalize_labels", "(", "labels", ",", "factors_num_values", ")", ":", "\n", "  ", "\"\"\"Normalize the labels in [0, 1].\n\n  Args:\n    labels: Numpy array of shape (num_labelled_samples, num_factors) of Float32.\n    factors_num_values: Numpy array of shape (num_factors,) containing the\n      number of distinct values each factor can take.\n\n  Returns:\n    labels normalized in [0, 1].\n  \"\"\"", "\n", "factors_num_values_reshaped", "=", "np", ".", "repeat", "(", "\n", "np", ".", "expand_dims", "(", "np", ".", "float32", "(", "factors_num_values", ")", ",", "axis", "=", "0", ")", ",", "\n", "labels", ".", "shape", "[", "0", "]", ",", "\n", "axis", "=", "0", ")", "\n", "return", "labels", "/", "factors_num_values_reshaped", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.supervised_regularizer_l2": [[208, 243], ["gin.configurable", "tensorflow.get_variable", "tensorflow.nn.l2_loss", "tensorflow.nn.l2_loss", "tensorflow.constant", "tensorflow.sigmoid", "semi_supervised_vae.normalize_labels", "tensorflow.expand_dims"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.losses.l2_loss", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.losses.l2_loss", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_model.sigmoid", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.normalize_labels"], ["", "@", "gin", ".", "configurable", "(", "\"l2\"", ",", "blacklist", "=", "[", "\"representation\"", ",", "\"labels\"", "]", ")", "\n", "def", "supervised_regularizer_l2", "(", "representation", ",", "labels", ",", "\n", "factor_sizes", "=", "None", ",", "\n", "learn_scale", "=", "True", ")", ":", "\n", "  ", "\"\"\"Implements a supervised l2 regularizer.\n\n  If the number of latent dimension is greater than the number of factor of\n  variations it only uses the first dimensions of the latent code to\n  regularize. The number of factors of variation must be smaller or equal to the\n  number of latent codes. The representation can be scaled with a learned\n  scaling to match the labels or the labels are normalized in [0,1] and the\n  representation is projected in the same interval using a sigmoid.\n\n  Args:\n    representation: Representation of labelled samples.\n    labels: Labels for the labelled samples.\n    factor_sizes: Cardinality of each factor of variation (unused).\n    learn_scale: Boolean indicating whether the scale should be learned or not.\n\n  Returns:\n    L2 loss between the representation and the labels.\n  \"\"\"", "\n", "number_latents", "=", "representation", ".", "shape", "[", "1", "]", ".", "value", "\n", "number_factors_of_variations", "=", "labels", ".", "shape", "[", "1", "]", ".", "value", "\n", "assert", "number_latents", ">=", "number_factors_of_variations", ",", "\"Not enough latents.\"", "\n", "if", "learn_scale", ":", "\n", "    ", "b", "=", "tf", ".", "get_variable", "(", "\"b\"", ",", "initializer", "=", "tf", ".", "constant", "(", "1.", ")", ")", "\n", "return", "2.", "*", "tf", ".", "nn", ".", "l2_loss", "(", "\n", "representation", "[", ":", ",", ":", "number_factors_of_variations", "]", "*", "b", "-", "labels", ")", "\n", "", "else", ":", "\n", "    ", "return", "2.", "*", "tf", ".", "nn", ".", "l2_loss", "(", "\n", "tf", ".", "sigmoid", "(", "\n", "tf", ".", "expand_dims", "(", "\n", "representation", "[", ":", ",", ":", "number_factors_of_variations", "]", ",", "axis", "=", "1", ")", ")", "-", "\n", "normalize_labels", "(", "labels", ",", "factor_sizes", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.supervised_regularizer_xent": [[245, 270], ["gin.configurable", "tensorflow.reduce_sum", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "semi_supervised_vae.normalize_labels"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.normalize_labels"], ["", "", "@", "gin", ".", "configurable", "(", "\"xent\"", ",", "blacklist", "=", "[", "\"representation\"", ",", "\"labels\"", "]", ")", "\n", "def", "supervised_regularizer_xent", "(", "representation", ",", "labels", ",", "\n", "factor_sizes", "=", "None", ")", ":", "\n", "  ", "\"\"\"Implements a supervised cross_entropy regularizer.\n\n  If the number of latent dimension is greater than the number of factor of\n  variations it only uses the first dimensions of the latent code to\n  regularize. If the number of factors of variation is larger than the latent\n  code dimension it raise an exception. Labels are in [0, 1].\n\n  Args:\n    representation: Representation of labelled samples.\n    labels: Labels for the labelled samples.\n    factor_sizes: Cardinality of each factor of variation.\n\n  Returns:\n    Xent loss between the representation and the labels.\n  \"\"\"", "\n", "number_latents", "=", "representation", ".", "shape", "[", "1", "]", ".", "value", "\n", "number_factors_of_variations", "=", "labels", ".", "shape", "[", "1", "]", ".", "value", "\n", "assert", "number_latents", ">=", "number_factors_of_variations", ",", "\"Not enough latents.\"", "\n", "return", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "\n", "logits", "=", "representation", "[", ":", ",", ":", "number_factors_of_variations", "]", ",", "\n", "labels", "=", "normalize_labels", "(", "labels", ",", "factor_sizes", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.supervised_regularizer_cov": [[272, 306], ["gin.configurable", "tensorflow.math.minimum", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.nn.l2_loss", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.linalg.set_diag", "tensorflow.zeros"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.losses.l2_loss"], ["", "@", "gin", ".", "configurable", "(", "\"cov\"", ",", "blacklist", "=", "[", "\"representation\"", ",", "\"labels\"", "]", ")", "\n", "def", "supervised_regularizer_cov", "(", "representation", ",", "labels", ",", "\n", "factor_sizes", "=", "None", ")", ":", "\n", "  ", "\"\"\"Implements a supervised regularizer using a covariance.\n\n  Penalize the deviation from the identity of the covariance between\n  representation and factors of varations.\n  If the number of latent dimension is greater than the number of factor of\n  variations it only uses the first dimensions of the latent code to\n  regularize. Labels are in [0, 1].\n\n  Args:\n    representation: Representation of labelled samples.\n    labels: Labels for the labelled samples.\n    factor_sizes: Cardinality of each factor of variation (unused).\n\n\n  Returns:\n    Loss between the representation and the labels.\n  \"\"\"", "\n", "del", "factor_sizes", "\n", "number_latents", "=", "representation", ".", "shape", "[", "1", "]", ".", "value", "\n", "number_factors_of_variations", "=", "labels", ".", "shape", "[", "1", "]", ".", "value", "\n", "num_diagonals", "=", "tf", ".", "math", ".", "minimum", "(", "number_latents", ",", "number_factors_of_variations", ")", "\n", "expectation_representation", "=", "tf", ".", "reduce_mean", "(", "representation", ",", "axis", "=", "0", ")", "\n", "expectation_labels", "=", "tf", ".", "reduce_mean", "(", "labels", ",", "axis", "=", "0", ")", "\n", "representation_centered", "=", "representation", "-", "expectation_representation", "\n", "labels_centered", "=", "labels", "-", "expectation_labels", "\n", "covariance", "=", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "expand_dims", "(", "representation_centered", ",", "2", ")", "*", "tf", ".", "expand_dims", "(", "\n", "labels_centered", ",", "1", ")", ",", "\n", "axis", "=", "0", ")", "\n", "return", "2.", "*", "tf", ".", "nn", ".", "l2_loss", "(", "\n", "tf", ".", "linalg", ".", "set_diag", "(", "covariance", ",", "tf", ".", "zeros", "(", "[", "num_diagonals", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.supervised_regularizer_embed": [[308, 358], ["gin.configurable", "range", "tensorflow.reduce_sum", "tensorflow.one_hot", "tensorflow.add_n", "tensorflow.variable_scope", "tensorflow.square", "tensorflow.to_int32", "tensorflow.losses.softmax_cross_entropy", "str", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.range", "tensorflow.expand_dims"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"embed\"", ",", "blacklist", "=", "[", "\"representation\"", ",", "\"labels\"", ",", "\n", "\"factor_sizes\"", "]", ")", "\n", "def", "supervised_regularizer_embed", "(", "representation", ",", "labels", ",", "\n", "factor_sizes", ",", "sigma", "=", "gin", ".", "REQUIRED", ",", "\n", "use_order", "=", "False", ")", ":", "\n", "  ", "\"\"\"Embed factors in 1d and compute softmax with the representation.\n\n  Assume a factor of variation indexed by j can take k values. We embed each\n  value into k real numbers e_1, ..., e_k. Call e_label(r_j) the embedding of an\n  observed label for the factor j. Then, for a dimension r_j of the\n  representation, the loss is computed as\n  exp(-((r_j - e_label(r_j))*sigma)^2)/sum_{i=1}^k exp(-(r_j - e_i)).\n  We compute this term for each factor of variation j and each point. Finally,\n  we add these terms into a single number.\n\n  Args:\n    representation: Computed representation, tensor of shape (batch_size,\n      num_latents)\n    labels: Observed values for the factors of variation, tensor of shape\n      (batch_size, num_factors).\n    factor_sizes: Cardinality of each factor of variation.\n    sigma: Temperature for the softmax. Set to \"learn\" if to be learned.\n    use_order: Boolean indicating whether to use the ordering information in the\n      factors of variations or not.\n\n  Returns:\n    Supervised loss based on the softmax between embedded labels and\n    representation.\n  \"\"\"", "\n", "number_factors_of_variations", "=", "labels", ".", "shape", "[", "1", "]", ".", "value", "\n", "supervised_representation", "=", "representation", "[", ":", ",", ":", "number_factors_of_variations", "]", "\n", "loss", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "number_factors_of_variations", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "str", "(", "i", ")", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "      ", "if", "use_order", ":", "\n", "        ", "bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "]", ")", "\n", "slope", "=", "tf", ".", "get_variable", "(", "\"slope\"", ",", "[", "]", ")", "\n", "embedding", "=", "tf", ".", "range", "(", "factor_sizes", "[", "i", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "*", "slope", "+", "bias", "\n", "", "else", ":", "\n", "        ", "embedding", "=", "tf", ".", "get_variable", "(", "\"embedding\"", ",", "[", "factor_sizes", "[", "i", "]", "]", ")", "\n", "", "if", "sigma", "==", "\"learn\"", ":", "\n", "        ", "sigma_value", "=", "tf", ".", "get_variable", "(", "\"sigma\"", ",", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "        ", "sigma_value", "=", "sigma", "\n", "", "", "logits", "=", "-", "tf", ".", "square", "(", "\n", "(", "tf", ".", "expand_dims", "(", "supervised_representation", "[", ":", ",", "i", "]", ",", "axis", "=", "1", ")", "-", "embedding", ")", "*", "\n", "sigma_value", ")", "\n", "one_hot_labels", "=", "tf", ".", "one_hot", "(", "tf", ".", "to_int32", "(", "labels", "[", ":", ",", "i", "]", ")", ",", "factor_sizes", "[", "i", "]", ")", "\n", "loss", "+=", "[", "tf", ".", "losses", ".", "softmax_cross_entropy", "(", "one_hot_labels", ",", "logits", ")", "]", "\n", "", "return", "tf", ".", "reduce_sum", "(", "tf", ".", "add_n", "(", "loss", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.mine": [[455, 491], ["disentanglement_lib.methods.unsupervised.vae.shuffle_codes", "tensorflow.concat", "tensorflow.stop_gradient", "tensorflow.trainable_variables", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.nn.elu", "tensorflow.layers.dense", "tensorflow.shape", "tensorflow.math.reduce_logsumexp", "tensorflow.train.AdamOptimizer", "tensorflow.reduce_mean", "tensorflow.math.log", "tensorflow.to_float"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.shuffle_codes"], ["", "", "", "def", "mine", "(", "x", ",", "z", ",", "name_net", "=", "\"estimator_network\"", ")", ":", "\n", "  ", "\"\"\"Computes I(X, Z).\n\n  Uses the algorithm in \"Mutual Information Neural Estimation\"\n  (https://arxiv.org/pdf/1801.04062.pdf).\n\n  Args:\n    x: Samples from x [batch_size, size_x].\n    z: Samples from z [batch_size, size_z].\n    name_net: Scope for the variables forming the network.\n\n  Returns:\n    Estimate of the mutual information and the update op for the optimizer.\n  \"\"\"", "\n", "z_shuffled", "=", "vae", ".", "shuffle_codes", "(", "z", ")", "\n", "\n", "concat_x_x", "=", "tf", ".", "concat", "(", "[", "x", ",", "x", "]", ",", "axis", "=", "0", ")", "\n", "concat_z_z_shuffled", "=", "tf", ".", "stop_gradient", "(", "tf", ".", "concat", "(", "[", "z", ",", "z_shuffled", "]", ",", "axis", "=", "0", ")", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "name_net", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "    ", "d1_x", "=", "tf", ".", "layers", ".", "dense", "(", "concat_x_x", ",", "20", ",", "name", "=", "\"d1_x\"", ")", "\n", "d1_z", "=", "tf", ".", "layers", ".", "dense", "(", "concat_z_z_shuffled", ",", "20", ",", "name", "=", "\"d1_z\"", ")", "\n", "d1", "=", "tf", ".", "nn", ".", "elu", "(", "d1_x", "+", "d1_z", ",", "name", "=", "\"d1\"", ")", "\n", "d2", "=", "tf", ".", "layers", ".", "dense", "(", "d1", ",", "1", ",", "name", "=", "\"d2\"", ")", "\n", "\n", "", "batch_size", "=", "tf", ".", "shape", "(", "x", ")", "[", "0", "]", "\n", "pred_x_z", "=", "d2", "[", ":", "batch_size", "]", "\n", "pred_x_z_shuffled", "=", "d2", "[", "batch_size", ":", "]", "\n", "loss", "=", "-", "(", "\n", "tf", ".", "reduce_mean", "(", "pred_x_z", ",", "axis", "=", "0", ")", "+", "tf", ".", "math", ".", "log", "(", "tf", ".", "to_float", "(", "batch_size", ")", ")", "-", "\n", "tf", ".", "math", ".", "reduce_logsumexp", "(", "pred_x_z_shuffled", ")", ")", "\n", "all_variables", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "mine_vars", "=", "[", "var", "for", "var", "in", "all_variables", "if", "\"estimator_network\"", "in", "var", ".", "name", "]", "\n", "mine_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "0.01", ")", ".", "minimize", "(", "\n", "loss", "=", "loss", ",", "var_list", "=", "mine_vars", ")", "\n", "return", "-", "loss", ",", "mine_op", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae_test.S2VaeTest.test_fixed_annealer": [[30, 38], ["absl.testing.parameterized.parameters", "disentanglement_lib.methods.semi_supervised.semi_supervised_vae.fixed_annealer", "semi_supervised_vae_test.S2VaeTest.assertBetween"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.fixed_annealer"], ["  ", "@", "parameterized", ".", "parameters", "(", "(", "0", ",", "100.", ",", "100.01", ")", ",", "(", "10", ",", "100.", ",", "100.01", ")", ",", "\n", "(", "100", ",", "100.", ",", "100.01", ")", ",", "(", "101", ",", "100.", ",", "100.01", ")", ")", "\n", "def", "test_fixed_annealer", "(", "self", ",", "step", ",", "target_low", ",", "target_high", ")", ":", "\n", "    ", "c_max", "=", "100.", "\n", "iteration_threshold", "=", "100", "\n", "test_value", "=", "semi_supervised_vae", ".", "fixed_annealer", "(", "c_max", ",", "step", ",", "\n", "iteration_threshold", ")", "\n", "self", ".", "assertBetween", "(", "test_value", ",", "target_low", ",", "target_high", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae_test.S2VaeTest.test_anneal_annealer": [[39, 49], ["absl.testing.parameterized.parameters", "semi_supervised_vae_test.S2VaeTest.test_session", "sess.run", "semi_supervised_vae_test.S2VaeTest.assertBetween", "disentanglement_lib.methods.semi_supervised.semi_supervised_vae.annealed_annealer"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.annealed_annealer"], ["", "@", "parameterized", ".", "parameters", "(", "(", "0", ",", "0.", ",", "0.01", ")", ",", "(", "10", ",", "10.", ",", "10.01", ")", ",", "\n", "(", "100", ",", "100.", ",", "100.01", ")", ",", "(", "101", ",", "100.", ",", "100.01", ")", ")", "\n", "def", "test_anneal_annealer", "(", "self", ",", "step", ",", "target_low", ",", "target_high", ")", ":", "\n", "    ", "c_max", "=", "100.", "\n", "iteration_threshold", "=", "100", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "test_value", "=", "sess", ".", "run", "(", "\n", "semi_supervised_vae", ".", "annealed_annealer", "(", "c_max", ",", "step", ",", "\n", "iteration_threshold", ")", ")", "\n", "self", ".", "assertBetween", "(", "test_value", ",", "target_low", ",", "target_high", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae_test.S2VaeTest.test_fine_tune_annealer": [[50, 60], ["absl.testing.parameterized.parameters", "semi_supervised_vae_test.S2VaeTest.test_session", "sess.run", "semi_supervised_vae_test.S2VaeTest.assertBetween", "disentanglement_lib.methods.semi_supervised.semi_supervised_vae.fine_tune_annealer"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.fine_tune_annealer"], ["", "", "@", "parameterized", ".", "parameters", "(", "(", "0", ",", "0.", ",", "0.01", ")", ",", "(", "10", ",", "0.", ",", "0.01", ")", ",", "\n", "(", "100", ",", "0.", ",", "0.01", ")", ",", "(", "101", ",", "100.", ",", "100.01", ")", ")", "\n", "def", "test_fine_tune_annealer", "(", "self", ",", "step", ",", "target_low", ",", "target_high", ")", ":", "\n", "    ", "c_max", "=", "100.", "\n", "iteration_threshold", "=", "100", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "test_value", "=", "sess", ".", "run", "(", "\n", "semi_supervised_vae", ".", "fine_tune_annealer", "(", "c_max", ",", "step", ",", "\n", "iteration_threshold", ")", ")", "\n", "self", ".", "assertBetween", "(", "test_value", ",", "target_low", ",", "target_high", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae_test.S2VaeTest.test_xent": [[61, 75], ["absl.testing.parameterized.parameters", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "semi_supervised_vae_test.S2VaeTest.test_session", "sess.run", "semi_supervised_vae_test.S2VaeTest.assertBetween", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.ones", "numpy.zeros", "disentanglement_lib.methods.semi_supervised.semi_supervised_vae.supervised_regularizer_xent"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.supervised_regularizer_xent"], ["", "", "@", "parameterized", ".", "parameters", "(", "\n", "(", "np", ".", "zeros", "(", "[", "64", ",", "10", "]", ")", ",", "np", ".", "zeros", "(", "[", "64", ",", "5", "]", ")", ",", "221.806", ",", "221.808", ")", ",", "\n", "(", "np", ".", "zeros", "(", "[", "64", ",", "10", "]", ")", ",", "np", ".", "zeros", "(", "[", "64", ",", "10", "]", ")", ",", "221.806", "*", "2", ",", "221.808", "*", "2", ")", ",", "\n", "(", "np", ".", "ones", "(", "[", "64", ",", "10", "]", ")", ",", "np", ".", "zeros", "(", "[", "64", ",", "10", "]", ")", ",", "840.47", ",", "840.49", ")", ")", "\n", "# Values for this test are computed with averaging x - x * z +", "\n", "# log(1 + exp(-x)).", "\n", "def", "test_xent", "(", "self", ",", "rep_np", ",", "labels_np", ",", "target_low", ",", "target_high", ")", ":", "\n", "    ", "representation", "=", "tf", ".", "convert_to_tensor", "(", "rep_np", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "labels", "=", "tf", ".", "convert_to_tensor", "(", "labels_np", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "test_value", "=", "sess", ".", "run", "(", "\n", "semi_supervised_vae", ".", "supervised_regularizer_xent", "(", "\n", "representation", ",", "labels", ",", "factor_sizes", "=", "[", "1", "]", "*", "labels_np", ".", "shape", "[", "1", "]", ")", ")", "\n", "self", ".", "assertBetween", "(", "test_value", ",", "target_low", ",", "target_high", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae_test.S2VaeTest.test_cov_det": [[76, 88], ["absl.testing.parameterized.parameters", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "semi_supervised_vae_test.S2VaeTest.test_session", "sess.run", "semi_supervised_vae_test.S2VaeTest.assertBetween", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.array", "numpy.array", "disentanglement_lib.methods.semi_supervised.semi_supervised_vae.supervised_regularizer_cov"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.supervised_regularizer_cov"], ["", "", "@", "parameterized", ".", "parameters", "(", "(", "np", ".", "zeros", "(", "[", "64", ",", "10", "]", ")", ",", "np", ".", "zeros", "(", "[", "64", ",", "5", "]", ")", ",", "0.", ",", "0.1", ")", ",", "\n", "(", "np", ".", "zeros", "(", "[", "64", ",", "10", "]", ")", ",", "np", ".", "zeros", "(", "[", "64", ",", "10", "]", ")", ",", "0.", ",", "0.1", ")", ",", "\n", "(", "np", ".", "array", "(", "[", "[", "1.", ",", "0.", "]", ",", "[", "0.", ",", "1.", "]", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "[", "0.", ",", "1.", "]", ",", "[", "1.", ",", "0.", "]", "]", ")", ",", "0.125", ",", "0.126", ")", ")", "\n", "def", "test_cov_det", "(", "self", ",", "rep_np", ",", "labels_np", ",", "target_low", ",", "target_high", ")", ":", "\n", "    ", "representation", "=", "tf", ".", "convert_to_tensor", "(", "rep_np", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "labels", "=", "tf", ".", "convert_to_tensor", "(", "labels_np", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "test_value", "=", "sess", ".", "run", "(", "\n", "semi_supervised_vae", ".", "supervised_regularizer_cov", "(", "representation", ",", "\n", "labels", ")", ")", "\n", "self", ".", "assertBetween", "(", "test_value", ",", "target_low", ",", "target_high", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae_test.S2VaeTest.test_cov_rand": [[89, 99], ["absl.testing.parameterized.parameters", "tensorflow.convert_to_tensor", "semi_supervised_vae_test.S2VaeTest.test_session", "sess.run", "semi_supervised_vae_test.S2VaeTest.assertBetween", "numpy.random.normal", "disentanglement_lib.methods.semi_supervised.semi_supervised_vae.supervised_regularizer_cov", "numpy.zeros", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.supervised_regularizer_cov"], ["", "", "@", "parameterized", ".", "parameters", "(", "(", "np", ".", "random", ".", "normal", "(", "\n", "loc", "=", "np", ".", "zeros", "(", "[", "1", ",", "10", "]", ")", ",", "scale", "=", "np", ".", "ones", "(", "[", "1", ",", "10", "]", ")", ",", "size", "=", "[", "100000", ",", "10", "]", ")", ",", "0.", ",", "\n", "0.01", ")", ")", "\n", "def", "test_cov_rand", "(", "self", ",", "samples", ",", "target_low", ",", "target_high", ")", ":", "\n", "    ", "samples", "=", "tf", ".", "convert_to_tensor", "(", "samples", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "test_value", "=", "sess", ".", "run", "(", "\n", "semi_supervised_vae", ".", "supervised_regularizer_cov", "(", "samples", ",", "\n", "samples", ")", ")", "\n", "self", ".", "assertBetween", "(", "test_value", ",", "target_low", ",", "target_high", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae_test.S2VaeTest.test_mine": [[100, 121], ["absl.testing.parameterized.parameters", "tensorflow.placeholder", "tensorflow.placeholder", "disentanglement_lib.methods.semi_supervised.semi_supervised_vae.mine", "numpy.sign", "semi_supervised_vae_test.S2VaeTest.test_session", "sess.run", "range", "semi_supervised_vae_test.S2VaeTest.assertBetween", "numpy.random.normal", "numpy.random.normal", "tensorflow.global_variables_initializer", "semi_supervised_vae_test.S2VaeTest.test_mine._gen_x"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_vae.mine"], ["", "", "@", "parameterized", ".", "parameters", "(", "\n", "(", "0.2", ",", "0.6", ",", "0.7", ")", ")", "\n", "# The real mutual information for this test case is about 0.6589.", "\n", "# Mine is noisy.", "\n", "def", "test_mine", "(", "self", ",", "var", ",", "target_low", ",", "target_high", ")", ":", "\n", "    ", "def", "_gen_x", "(", "batch_size", ")", ":", "\n", "      ", "return", "np", ".", "sign", "(", "np", ".", "random", ".", "normal", "(", "0.", ",", "1.", ",", "[", "batch_size", ",", "1", "]", ")", ")", "\n", "", "def", "_gen_y", "(", "x", ")", ":", "\n", "      ", "return", "x", "+", "np", ".", "random", ".", "normal", "(", "0.", ",", "np", ".", "sqrt", "(", "var", ")", ",", "x", ".", "shape", ")", "\n", "\n", "", "x_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "1", "]", ")", "\n", "y_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "1", "]", ")", "\n", "loss", ",", "mine_op", "=", "semi_supervised_vae", ".", "mine", "(", "x_ph", ",", "y_ph", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "for", "_", "in", "range", "(", "200", ")", ":", "\n", "        ", "x_sample", "=", "_gen_x", "(", "10000", ")", "\n", "y_sample", "=", "_gen_y", "(", "x_sample", ")", "\n", "mi", ",", "_", "=", "sess", ".", "run", "(", "[", "loss", ",", "mine_op", "]", ",", "\n", "feed_dict", "=", "{", "x_ph", ":", "x_sample", ",", "y_ph", ":", "y_sample", "}", ")", "\n", "", "self", ".", "assertBetween", "(", "mi", ",", "target_low", ",", "target_high", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_test.S2TrainTest.test_train_model": [[194, 201], ["absl.testing.parameterized.parameters", "gin.clear_config", "disentanglement_lib.methods.semi_supervised.train_semi_supervised_lib.train_with_gin", "list", "train_semi_supervised_test._s2_config_generator", "train_semi_supervised_test.S2TrainTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train_with_gin", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_test._s2_config_generator"], ["  ", "@", "parameterized", ".", "parameters", "(", "list", "(", "_s2_config_generator", "(", ")", ")", ")", "\n", "def", "test_train_model", "(", "self", ",", "gin_configs", ",", "gin_bindings", ")", ":", "\n", "# We clear the gin config before running. Otherwise, if a prior test fails,", "\n", "# the gin config is locked and the current test fails.", "\n", "    ", "gin", ".", "clear_config", "(", ")", "\n", "train_semi_supervised_lib", ".", "train_with_gin", "(", "self", ".", "create_tempdir", "(", ")", ".", "full_path", ",", "\n", "True", ",", "gin_configs", ",", "gin_bindings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_test.S2FactorTrainTest.test_train_model": [[205, 212], ["absl.testing.parameterized.parameters", "gin.clear_config", "disentanglement_lib.methods.semi_supervised.train_semi_supervised_lib.train_with_gin", "list", "train_semi_supervised_test._s2_factor_config_generator", "train_semi_supervised_test.S2FactorTrainTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train_with_gin", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_test._s2_factor_config_generator"], ["  ", "@", "parameterized", ".", "parameters", "(", "list", "(", "_s2_factor_config_generator", "(", ")", ")", ")", "\n", "def", "test_train_model", "(", "self", ",", "gin_configs", ",", "gin_bindings", ")", ":", "\n", "# We clear the gin config before running. Otherwise, if a prior test fails,", "\n", "# the gin config is locked and the current test fails.", "\n", "    ", "gin", ".", "clear_config", "(", ")", "\n", "train_semi_supervised_lib", ".", "train_with_gin", "(", "self", ".", "create_tempdir", "(", ")", ".", "full_path", ",", "\n", "True", ",", "gin_configs", ",", "gin_bindings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_test.S2DipTrainTest.test_train_model": [[216, 223], ["absl.testing.parameterized.parameters", "gin.clear_config", "disentanglement_lib.methods.semi_supervised.train_semi_supervised_lib.train_with_gin", "list", "train_semi_supervised_test._s2_dip_config_generator", "train_semi_supervised_test.S2DipTrainTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train_with_gin", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_test._s2_dip_config_generator"], ["  ", "@", "parameterized", ".", "parameters", "(", "list", "(", "_s2_dip_config_generator", "(", ")", ")", ")", "\n", "def", "test_train_model", "(", "self", ",", "gin_configs", ",", "gin_bindings", ")", ":", "\n", "# We clear the gin config before running. Otherwise, if a prior test fails,", "\n", "# the gin config is locked and the current test fails.", "\n", "    ", "gin", ".", "clear_config", "(", ")", "\n", "train_semi_supervised_lib", ".", "train_with_gin", "(", "self", ".", "create_tempdir", "(", ")", ".", "full_path", ",", "\n", "True", ",", "gin_configs", ",", "gin_bindings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_test.S2BetaTCCTrainTest.test_train_model": [[227, 233], ["absl.testing.parameterized.parameters", "disentanglement_lib.methods.semi_supervised.train_semi_supervised_lib.train_with_gin", "list", "train_semi_supervised_test._s2_beta_tc_config_generator", "train_semi_supervised_test.S2BetaTCCTrainTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train_with_gin", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_test._s2_beta_tc_config_generator"], ["  ", "@", "parameterized", ".", "parameters", "(", "list", "(", "_s2_beta_tc_config_generator", "(", ")", ")", ")", "\n", "def", "test_train_model", "(", "self", ",", "gin_configs", ",", "gin_bindings", ")", ":", "\n", "# We clear the gin config before running. Otherwise, if a prior test fails,", "\n", "# the gin config is locked and the current test fails.", "\n", "    ", "train_semi_supervised_lib", ".", "train_with_gin", "(", "self", ".", "create_tempdir", "(", ")", ".", "full_path", ",", "\n", "True", ",", "gin_configs", ",", "gin_bindings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_test.VAETrainTest.test_train_model": [[237, 243], ["absl.testing.parameterized.parameters", "disentanglement_lib.methods.semi_supervised.train_semi_supervised_lib.train_with_gin", "list", "train_semi_supervised_test._vae_config_generator", "train_semi_supervised_test.VAETrainTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train_with_gin", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_test._vae_config_generator"], ["  ", "@", "parameterized", ".", "parameters", "(", "list", "(", "_vae_config_generator", "(", ")", ")", ")", "\n", "def", "test_train_model", "(", "self", ",", "gin_configs", ",", "gin_bindings", ")", ":", "\n", "# We clear the gin config before running. Otherwise, if a prior test fails,", "\n", "# the gin config is locked and the current test fails.", "\n", "    ", "train_semi_supervised_lib", ".", "train_with_gin", "(", "self", ".", "create_tempdir", "(", ")", ".", "full_path", ",", "\n", "True", ",", "gin_configs", ",", "gin_bindings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_test._s2_config_generator": [[74, 89], ["disentanglement_lib.utils.resources.get_file"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file"], ["def", "_s2_config_generator", "(", ")", ":", "\n", "  ", "\"\"\"Yields all model configurations that should be tested.\"\"\"", "\n", "model_config_path", "=", "resources", ".", "get_file", "(", "\n", "\"config/tests/methods/semi_supervised/train_test.gin\"", ")", "\n", "# Test s2_vae.", "\n", "s2_vae", "=", "[", "\n", "\"model.model = @s2_vae\"", ",", "\"model.num_labelled_samples = 100\"", ",", "\n", "\"model.train_percentage = 0.9\"", ",", "\"s2_vae.beta = 4\"", ",", "\"s2_vae.gamma_sup = 4\"", ",", "\n", "\"annealer.iteration_threshold = 1\"", ",", "\n", "\"model.model_seed = 0\"", ",", "\n", "\"model.unsupervised_data_seed = 0\"", ",", "\"model.supervised_data_seed = 0\"", ",", "\n", "\"model.num_labelled_samples = 100\"", ",", "\"model.train_percentage = 0.9\"", "\n", "]", "\n", "for", "anneal_loss", "in", "ANNEAL_LOSS_LIST", ":", "\n", "    ", "yield", "[", "model_config_path", "]", ",", "s2_vae", "+", "anneal_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_test._supervised_config_generator": [[91, 106], ["disentanglement_lib.utils.resources.get_file"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file"], ["", "", "def", "_supervised_config_generator", "(", ")", ":", "\n", "  ", "\"\"\"Yields all model configurations that should be tested.\"\"\"", "\n", "model_config_path", "=", "resources", ".", "get_file", "(", "\n", "\"config/tests/methods/semi_supervised/train_test.gin\"", ")", "\n", "# Test for s2_vae.", "\n", "supervised", "=", "[", "\n", "\"model.model = @supervised\"", ",", "\"model.num_labelled_samples = 100\"", ",", "\n", "\"model.train_percentage = 0.9\"", ",", "\n", "\"annealer.iteration_threshold = 1\"", ",", "\n", "\"model.model_seed = 0\"", ",", "\n", "\"model.unsupervised_data_seed = 0\"", ",", "\"model.supervised_data_seed = 0\"", ",", "\n", "\"model.num_labelled_samples = 100\"", ",", "\"model.train_percentage = 0.9\"", "\n", "]", "\n", "for", "anneal_loss", "in", "ANNEAL_LOSS_LIST", ":", "\n", "    ", "yield", "[", "model_config_path", "]", ",", "supervised", "+", "anneal_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_test._s2_factor_config_generator": [[108, 125], ["disentanglement_lib.utils.resources.get_file"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file"], ["", "", "def", "_s2_factor_config_generator", "(", ")", ":", "\n", "  ", "\"\"\"Yields all model configurations that should be tested.\"\"\"", "\n", "model_config_path", "=", "resources", ".", "get_file", "(", "\n", "\"config/tests/methods/semi_supervised/train_test.gin\"", ")", "\n", "# Test for s2_factor_vae.", "\n", "s2_factor_vae", "=", "[", "\n", "\"model.model = @s2_factor_vae\"", ",", "\"model.num_labelled_samples = 100\"", ",", "\n", "\"model.train_percentage = 0.9\"", ",", "\"s2_factor_vae.gamma = 4\"", ",", "\n", "\"s2_factor_vae.gamma_sup = 4\"", ",", "\"annealer.iteration_threshold = 1\"", ",", "\n", "\"discriminator.discriminator_fn = @fc_discriminator\"", ",", "\n", "\"discriminator_optimizer.optimizer_fn = @AdamOptimizer\"", ",", "\n", "\"model.model_seed = 0\"", ",", "\n", "\"model.unsupervised_data_seed = 0\"", ",", "\"model.supervised_data_seed = 0\"", ",", "\n", "\"model.num_labelled_samples = 100\"", ",", "\"model.train_percentage = 0.9\"", "\n", "]", "\n", "for", "anneal_loss", "in", "ANNEAL_LOSS_LIST", ":", "\n", "    ", "yield", "[", "model_config_path", "]", ",", "s2_factor_vae", "+", "anneal_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_test._s2_dip_config_generator": [[127, 155], ["disentanglement_lib.utils.resources.get_file"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file"], ["", "", "def", "_s2_dip_config_generator", "(", ")", ":", "\n", "  ", "\"\"\"Yields all model configurations that should be tested.\"\"\"", "\n", "model_config_path", "=", "resources", ".", "get_file", "(", "\n", "\"config/tests/methods/semi_supervised/train_test.gin\"", ")", "\n", "# Test for s2_dip_vae.", "\n", "s2_dip_vae_i", "=", "[", "\n", "\"model.model = @s2_dip_vae\"", ",", "\"model.num_labelled_samples = 100\"", ",", "\n", "\"model.train_percentage = 0.9\"", ",", "\"s2_dip_vae.lambda_d_factor = 10\"", ",", "\n", "\"s2_dip_vae.dip_type = 'i'\"", ",", "\"s2_dip_vae.lambda_od = 10.\"", ",", "\n", "\"s2_dip_vae.gamma_sup = 4\"", ",", "\"annealer.iteration_threshold = 1\"", ",", "\n", "\"model.model_seed = 0\"", ",", "\n", "\"model.unsupervised_data_seed = 0\"", ",", "\"model.supervised_data_seed = 0\"", ",", "\n", "\"model.num_labelled_samples = 100\"", ",", "\"model.train_percentage = 0.9\"", "\n", "]", "\n", "for", "anneal_loss", "in", "ANNEAL_LOSS_LIST", ":", "\n", "    ", "yield", "[", "model_config_path", "]", ",", "s2_dip_vae_i", "+", "anneal_loss", "\n", "\n", "", "s2_dip_vae_ii", "=", "[", "\n", "\"model.model = @s2_dip_vae\"", ",", "\"model.num_labelled_samples = 100\"", ",", "\n", "\"model.train_percentage = 0.9\"", ",", "\"s2_dip_vae.lambda_d_factor = 1\"", ",", "\n", "\"s2_dip_vae.dip_type = 'ii'\"", ",", "\"s2_dip_vae.lambda_od = 10.\"", ",", "\n", "\"s2_dip_vae.gamma_sup = 4\"", ",", "\"annealer.iteration_threshold = 1\"", ",", "\n", "\"model.model_seed = 0\"", ",", "\n", "\"model.unsupervised_data_seed = 0\"", ",", "\"model.supervised_data_seed = 0\"", ",", "\n", "\"model.num_labelled_samples = 100\"", ",", "\"model.train_percentage = 0.9\"", "\n", "]", "\n", "for", "anneal_loss", "in", "ANNEAL_LOSS_LIST", ":", "\n", "    ", "yield", "[", "model_config_path", "]", ",", "s2_dip_vae_ii", "+", "anneal_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_test._s2_beta_tc_config_generator": [[157, 172], ["disentanglement_lib.utils.resources.get_file"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file"], ["", "", "def", "_s2_beta_tc_config_generator", "(", ")", ":", "\n", "  ", "\"\"\"Yields all model configurations that should be tested.\"\"\"", "\n", "model_config_path", "=", "resources", ".", "get_file", "(", "\n", "\"config/tests/methods/semi_supervised/train_test.gin\"", ")", "\n", "# Test for s2_beta_tc_vae.", "\n", "s2_beta_tc_vae", "=", "[", "\n", "\"model.model = @s2_beta_tc_vae\"", ",", "\"model.num_labelled_samples = 100\"", ",", "\n", "\"model.train_percentage = 0.9\"", ",", "\"s2_beta_tc_vae.beta = 10.\"", ",", "\n", "\"s2_beta_tc_vae.gamma_sup = 4\"", ",", "\"annealer.iteration_threshold = 1\"", ",", "\n", "\"model.model_seed = 0\"", ",", "\n", "\"model.unsupervised_data_seed = 0\"", ",", "\"model.supervised_data_seed = 0\"", ",", "\n", "\"model.num_labelled_samples = 100\"", ",", "\"model.train_percentage = 0.9\"", "\n", "]", "\n", "for", "anneal_loss", "in", "ANNEAL_LOSS_LIST", ":", "\n", "    ", "yield", "[", "model_config_path", "]", ",", "s2_beta_tc_vae", "+", "anneal_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_test._vae_config_generator": [[174, 190], ["disentanglement_lib.utils.resources.get_file"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file"], ["", "", "def", "_vae_config_generator", "(", ")", ":", "\n", "  ", "\"\"\"Yields all model configurations that should be tested.\"\"\"", "\n", "model_config_path", "=", "resources", ".", "get_file", "(", "\n", "\"config/tests/methods/semi_supervised/train_test.gin\"", ")", "\n", "# Test for vae, both unsupervised and s2 methods runs with the s2", "\n", "# training_lib.", "\n", "vae", "=", "[", "\n", "\"model.model = @vae\"", ",", "\"model.num_labelled_samples = 100\"", ",", "\n", "\"model.train_percentage = 0.9\"", ",", "\"vae.beta = 10.\"", ",", "\n", "\"annealer.iteration_threshold = 1\"", ",", "\n", "\"model.model_seed = 0\"", ",", "\n", "\"model.unsupervised_data_seed = 0\"", ",", "\"model.supervised_data_seed = 0\"", ",", "\n", "\"model.num_labelled_samples = 100\"", ",", "\"model.train_percentage = 0.9\"", "\n", "]", "\n", "for", "anneal_loss", "in", "ANNEAL_LOSS_LIST", ":", "\n", "    ", "yield", "[", "model_config_path", "]", ",", "vae", "+", "anneal_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.sample_supervised_data": [[28, 54], ["numpy.random.RandomState", "ground_truth_data.sample_factors", "ground_truth_data.sample_observations_from_factors", "semi_supervised_utils.make_labeller"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.pgm_data.Quantizer.sample_observations_from_factors", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.make_labeller"], ["def", "sample_supervised_data", "(", "supervised_seed", ",", "\n", "ground_truth_data", ",", "\n", "num_labelled_samples", ")", ":", "\n", "  ", "\"\"\"Samples data and queries the labeller to obtain labels.\n\n  Args:\n    supervised_seed: Seed for the supervised data. Fixing the seed ensures that\n      the same data is sampled across different parts of the pipeline.\n    ground_truth_data: Dataset class from which the data is to be sampled.\n    num_labelled_samples: How many labelled points should be sampled.\n\n  Returns:\n    sampled_observations: Numpy array with observations of shape\n      (num_labelled_samples, 64, 64, num_channels).\n    sampled_factors: Numpy array with observed factors of variations with shape\n      (num_labelled_samples, num_factors).\n  \"\"\"", "\n", "supervised_random_state", "=", "np", ".", "random", ".", "RandomState", "(", "supervised_seed", ")", "\n", "sampled_factors", "=", "ground_truth_data", ".", "sample_factors", "(", "num_labelled_samples", ",", "\n", "supervised_random_state", ")", "\n", "sampled_observations", "=", "ground_truth_data", ".", "sample_observations_from_factors", "(", "\n", "sampled_factors", ",", "supervised_random_state", ")", "\n", "sampled_factors", ",", "factor_sizes", "=", "make_labeller", "(", "sampled_factors", ",", "\n", "ground_truth_data", ",", "\n", "supervised_random_state", ")", "\n", "return", "sampled_observations", ",", "sampled_factors", ",", "factor_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.train_test_split": [[56, 96], ["int", "math.ceil"], "function", ["None"], ["", "def", "train_test_split", "(", "observations", ",", "labels", ",", "num_labelled_samples", ",", "\n", "train_percentage", ")", ":", "\n", "  ", "\"\"\"Splits observations and labels in train and test sets.\n\n  Args:\n    observations: Numpy array containing the observations with shape\n      (num_labelled_samples, 64, 64, num_channels).\n    labels: Numpy array containing the observed factors of variations with shape\n      (num_labelled_samples, num_factors).\n    num_labelled_samples: How many labelled observations are expected. Used to\n      check that the observations have the right shape.\n    train_percentage: Float in [0,1] indicating which fraction of the labelled\n      data should be used for training.\n\n  Returns:\n    observations_train: Numpy array of shape\n      (train_percentage * num_labelled_samples, 64, 64, num_channels) containing\n      the observations for the training.\n    labels_train: Numpy array of shape (train_percentage * num_labelled_samples,\n      num_factors) containing the observed factors of variation for the training\n      observations.\n    observations_test: Numpy array containing the observations for the testing\n      with shape ((1-train_percentage) * num_labelled_samples, 64, 64,\n        num_channels)\n    labels_test: Numpy array containing the observed factors of variation for\n      the testing data with shape ((1-train_percentage) * num_labelled_samples,\n      num_factors).\n  \"\"\"", "\n", "assert", "observations", ".", "shape", "[", "0", "]", "==", "num_labelled_samples", ",", "\"Wrong observations shape.\"", "\n", "num_labelled_samples_train", "=", "int", "(", "\n", "math", ".", "ceil", "(", "num_labelled_samples", "*", "train_percentage", ")", ")", "\n", "num_labelled_samples_test", "=", "num_labelled_samples", "-", "num_labelled_samples_train", "\n", "observations_train", "=", "observations", "[", ":", "num_labelled_samples_train", ",", ":", ",", ":", ",", ":", "]", "\n", "observations_test", "=", "observations", "[", "num_labelled_samples_train", ":", ",", ":", ",", ":", ",", ":", "]", "\n", "\n", "labels_train", "=", "labels", "[", ":", "num_labelled_samples_train", ",", ":", "]", "\n", "labels_test", "=", "labels", "[", "num_labelled_samples_train", ":", ",", ":", "]", "\n", "assert", "labels_test", ".", "shape", "[", "0", "]", "==", "num_labelled_samples_test", ",", "\"Wrong size test.\"", "\n", "return", "observations_train", ",", "labels_train", ",", "observations_test", ",", "labels_test", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.make_labeller": [[100, 107], ["gin.configurable", "gin.configurable", "labeller_fn"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"labeller\"", ",", "blacklist", "=", "[", "\"labels\"", ",", "\"dataset\"", "]", ")", "\n", "def", "make_labeller", "(", "labels", ",", "\n", "dataset", ",", "\n", "random_state", ",", "\n", "labeller_fn", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "  ", "\"\"\"Wrapper that creates labeller function.\"\"\"", "\n", "return", "labeller_fn", "(", "labels", ",", "dataset", ",", "random_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.perfect_labeller": [[109, 127], ["gin.configurable", "gin.configurable", "numpy.float32"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"perfect_labeller\"", ",", "blacklist", "=", "[", "\"labels\"", ",", "\"dataset\"", "]", ")", "\n", "def", "perfect_labeller", "(", "labels", ",", "dataset", ",", "random_state", ")", ":", "\n", "  ", "\"\"\"Returns the true factors of variations without artifacts.\n\n  Args:\n    labels: True observations of the factors of variations. Numpy array of shape\n      (num_labelled_samples, num_factors) of Float32.\n    dataset: Dataset class.\n    random_state: Random state for the noise (unused).\n\n  Returns:\n    labels: True observations of the factors of variations without artifacts.\n      Numpy array of shape (num_labelled_samples, num_factors) of Float32.\n  \"\"\"", "\n", "del", "random_state", "\n", "labels", "=", "np", ".", "float32", "(", "labels", ")", "\n", "return", "labels", ",", "dataset", ".", "factors_num_values", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.bin_labeller": [[129, 155], ["gin.configurable", "gin.configurable", "numpy.float32", "enumerate", "numpy.minimum", "numpy.minimum"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"bin_labeller\"", ",", "blacklist", "=", "[", "\"labels\"", ",", "\"dataset\"", "]", ")", "\n", "def", "bin_labeller", "(", "labels", ",", "dataset", ",", "random_state", ",", "num_bins", "=", "5", ")", ":", "\n", "  ", "\"\"\"Returns simplified factors of variations.\n\n  The factors of variations are binned to take at most num_bins different values\n  to simulate the process of a human roughly labelling the factors of\n  variations.\n\n  Args:\n    labels: True observations of the factors of variations.\n    dataset: Dataset class.\n    random_state: Random state for the noise (unused).\n    num_bins: Number of bins for the factors of variations.\n\n  Returns:\n    labels: Binned factors of variations without noise. Numpy array of shape\n      (num_labelled_samples, num_factors) of Float32.\n  \"\"\"", "\n", "del", "random_state", "\n", "labels", "=", "np", ".", "float32", "(", "labels", ")", "\n", "for", "i", ",", "num_values", "in", "enumerate", "(", "dataset", ".", "factors_num_values", ")", ":", "\n", "    ", "if", "num_values", ">", "num_bins", ":", "\n", "      ", "size_bin", "=", "(", "num_values", "/", "num_bins", ")", "\n", "labels", "[", ":", ",", "i", "]", "=", "np", ".", "minimum", "(", "labels", "[", ":", ",", "i", "]", "//", "size_bin", ",", "num_bins", "-", "1", ")", "\n", "", "", "factors_num_values_bin", "=", "np", ".", "minimum", "(", "dataset", ".", "factors_num_values", ",", "num_bins", ")", "\n", "return", "labels", ",", "factors_num_values_bin", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.noisy_labeller": [[157, 182], ["gin.configurable", "gin.configurable", "range", "numpy.float32", "enumerate", "random_state.rand", "random_state.randint"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"noisy_labeller\"", ",", "blacklist", "=", "[", "\"labels\"", ",", "\"dataset\"", "]", ")", "\n", "def", "noisy_labeller", "(", "labels", ",", "dataset", ",", "random_state", ",", "prob_random", "=", "0.1", ")", ":", "\n", "  ", "\"\"\"Returns noisy factors of variations.\n\n  With probability prob_random, the observation of the factor of variations is\n  uniformly sampled from all possible factor values.\n\n  Args:\n    labels: True observations of the factors of variations.\n    dataset: Dataset class.\n    random_state: Random state for the noise.\n    prob_random: Probability of observing random factors of variations.\n\n  Returns:\n    labels: Noisy factors of variations. Numpy array of shape\n      (num_labelled_samples, num_factors) of Float32.\n  \"\"\"", "\n", "for", "j", "in", "range", "(", "labels", ".", "shape", "[", "0", "]", ")", ":", "\n", "    ", "for", "i", ",", "num_values", "in", "enumerate", "(", "dataset", ".", "factors_num_values", ")", ":", "\n", "      ", "p", "=", "random_state", ".", "rand", "(", ")", "\n", "if", "p", "<", "prob_random", ":", "\n", "        ", "labels", "[", "j", ",", "i", "]", "=", "random_state", ".", "randint", "(", "num_values", ")", "\n", "", "", "", "labels", "=", "np", ".", "float32", "(", "labels", ")", "\n", "return", "labels", ",", "dataset", ".", "factors_num_values", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.permuted_labeller": [[184, 202], ["gin.configurable", "gin.configurable", "enumerate", "numpy.float32", "semi_supervised_utils.permute"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.permute"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"permuted_labeller\"", ",", "blacklist", "=", "[", "\"labels\"", ",", "\"dataset\"", "]", ")", "\n", "def", "permuted_labeller", "(", "labels", ",", "dataset", ",", "random_state", ")", ":", "\n", "  ", "\"\"\"Returns factors of variations where the ordinal information is broken.\n\n  Args:\n    labels: True observations of the factors of variations.\n    dataset: Dataset class.\n    random_state: Random state for the noise (unused).\n\n  Returns:\n    labels: Noisy factors of variations. Numpy array of shape\n      (num_labelled_samples, num_factors) of Float32.\n  \"\"\"", "\n", "for", "i", ",", "num_values", "in", "enumerate", "(", "dataset", ".", "factors_num_values", ")", ":", "\n", "    ", "labels", "[", ":", ",", "i", "]", "=", "permute", "(", "labels", "[", ":", ",", "i", "]", ",", "num_values", ",", "random_state", ")", "\n", "", "labels", "=", "np", ".", "float32", "(", "labels", ")", "\n", "return", "labels", ",", "dataset", ".", "factors_num_values", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.permute": [[204, 221], ["random_state.permutation", "range"], "function", ["None"], ["", "def", "permute", "(", "factor", ",", "num_values", ",", "random_state", ")", ":", "\n", "  ", "\"\"\"Permutes the ordinal information of a given factor.\n\n  Args:\n    factor: Numpy array with the observations of a factor of varation with shape\n      (num_labelled_samples,) and type Int64.\n    num_values: Int with number of distinct values the factor of variation can\n      take.\n    random_state: Random state used to sample the permutation.\n\n  Returns:\n    factor: Numpy array of Int64 with the observations of a factor of varation\n      with permuted values and shape (num_labelled_samples,).\n  \"\"\"", "\n", "unordered_dict", "=", "random_state", ".", "permutation", "(", "range", "(", "num_values", ")", ")", "\n", "factor", "[", ":", "]", "=", "unordered_dict", "[", "factor", "]", "\n", "return", "factor", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.filter_factors": [[223, 244], ["random_state.choice", "ValueError", "ValueError"], "function", ["None"], ["", "def", "filter_factors", "(", "labels", ",", "num_observed_factors", ",", "random_state", ")", ":", "\n", "  ", "\"\"\"Filter observed factor keeping only a random subset of them.\n\n  Args:\n    labels: Factors of variations. Numpy array of shape\n      (num_labelled_samples, num_factors) of Float32.\n    num_observed_factors: How many factors should be kept.\n    random_state: Random state used to sample the permutation.\n\n  Returns:\n    Filters the labels so that only num_observed_factors are observed.\n  \"\"\"", "\n", "if", "num_observed_factors", "<", "1", ":", "\n", "    ", "raise", "ValueError", "(", "\"Cannot observe negative amount of factors.\"", ")", "\n", "", "elif", "num_observed_factors", ">", "labels", ".", "shape", "[", "1", "]", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "\"Cannot observe more factors than the ones in the dataset.\"", ")", "\n", "", "factors_to_keep", "=", "random_state", ".", "choice", "(", "labels", ".", "shape", "[", "1", "]", ",", "\n", "size", "=", "num_observed_factors", ",", "\n", "replace", "=", "False", ")", "\n", "return", "labels", "[", ":", ",", "factors_to_keep", "]", ",", "factors_to_keep", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.partial_labeller": [[246, 270], ["gin.configurable", "gin.configurable", "numpy.float32", "semi_supervised_utils.filter_factors"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.filter_factors"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"partial_labeller\"", ",", "blacklist", "=", "[", "\"labels\"", ",", "\"dataset\"", "]", ")", "\n", "def", "partial_labeller", "(", "labels", ",", "dataset", ",", "random_state", ",", "\n", "num_observed_factors", "=", "2", ")", ":", "\n", "  ", "\"\"\"Returns a few factors of variations without artifacts.\n\n  Args:\n    labels: True observations of the factors of variations. Numpy array of shape\n      (num_labelled_samples, num_factors) of Float32.\n    dataset: Dataset class.\n    random_state: Random state for the noise (unused).\n    num_observed_factors: How many factors are observed.\n\n  Returns:\n    labels: True observations of the factors of variations without artifacts.\n      Numpy array of shape (num_labelled_samples, num_factors) of Float32.\n  \"\"\"", "\n", "labels", "=", "np", ".", "float32", "(", "labels", ")", "\n", "filtered_factors", ",", "factors_to_keep", "=", "filter_factors", "(", "labels", ",", "\n", "num_observed_factors", ",", "\n", "random_state", ")", "\n", "\n", "factors_num_values", "=", "[", "dataset", ".", "factors_num_values", "[", "i", "]", "for", "i", "in", "factors_to_keep", "]", "\n", "return", "filtered_factors", ",", "factors_num_values", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_lib.train_with_gin": [[39, 61], ["gin.parse_config_files_and_bindings", "gin.parse_config_files_and_bindings", "train_semi_supervised_lib.train", "gin.clear_config", "gin.clear_config"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train"], ["def", "train_with_gin", "(", "model_dir", ",", "\n", "overwrite", "=", "False", ",", "\n", "gin_config_files", "=", "None", ",", "\n", "gin_bindings", "=", "None", ")", ":", "\n", "  ", "\"\"\"Trains a model based on the provided gin configuration.\n\n  This function will set the provided gin bindings, call the train() function\n  and clear the gin config. Please see the train() for required gin bindings.\n\n  Args:\n    model_dir: String with path to directory where model output should be saved.\n    overwrite: Boolean indicating whether to overwrite output directory.\n    gin_config_files: List of gin config files to load.\n    gin_bindings: List of gin bindings to use.\n  \"\"\"", "\n", "if", "gin_config_files", "is", "None", ":", "\n", "    ", "gin_config_files", "=", "[", "]", "\n", "", "if", "gin_bindings", "is", "None", ":", "\n", "    ", "gin_bindings", "=", "[", "]", "\n", "", "gin", ".", "parse_config_files_and_bindings", "(", "gin_config_files", ",", "gin_bindings", ")", "\n", "train", "(", "model_dir", ",", "overwrite", ")", "\n", "gin", ".", "clear_config", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_lib.train": [[63, 164], ["gin.configurable", "gin.configurable", "tensorflow.gfile.IsDirectory", "disentanglement_lib.data.ground_truth.named_data.get_named_ground_truth_data", "disentanglement_lib.methods.semi_supervised.semi_supervised_utils.sample_supervised_data", "issubclass", "tensorflow_estimator.python.estimator.tpu.tpu_config.RunConfig", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimator", "time.time", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimator.train", "os.path.join", "disentanglement_lib.methods.unsupervised.gaussian_encoder_model.export_as_tf_hub", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimator.evaluate", "os.path.join", "disentanglement_lib.utils.results.update_result_directory", "model.", "model.", "disentanglement_lib.data.ground_truth.named_data.get_named_ground_truth_data", "tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimator.latest_checkpoint", "time.time", "tensorflow.gfile.DeleteRecursively", "ValueError", "tensorflow_estimator.python.estimator.tpu.tpu_config.TPUConfig", "train_semi_supervised_lib._make_input_fn", "train_semi_supervised_lib._make_input_fn"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.named_data.get_named_ground_truth_data", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.sample_supervised_data", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.gaussian_encoder_model.export_as_tf_hub", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate.evaluate", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.update_result_directory", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.named_data.get_named_ground_truth_data", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train._make_input_fn", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train._make_input_fn"], ["", "@", "gin", ".", "configurable", "(", "\"model\"", ",", "blacklist", "=", "[", "\"model_dir\"", "]", ")", "\n", "def", "train", "(", "model_dir", ",", "\n", "overwrite", "=", "False", ",", "\n", "model", "=", "gin", ".", "REQUIRED", ",", "\n", "training_steps", "=", "gin", ".", "REQUIRED", ",", "\n", "unsupervised_data_seed", "=", "gin", ".", "REQUIRED", ",", "\n", "supervised_data_seed", "=", "gin", ".", "REQUIRED", ",", "\n", "model_seed", "=", "gin", ".", "REQUIRED", ",", "\n", "batch_size", "=", "gin", ".", "REQUIRED", ",", "\n", "num_labelled_samples", "=", "gin", ".", "REQUIRED", ",", "\n", "train_percentage", "=", "gin", ".", "REQUIRED", ",", "\n", "name", "=", "\"\"", ")", ":", "\n", "  ", "\"\"\"Trains the estimator and exports the snapshot and the gin config.\n\n  The use of this function requires the gin binding 'dataset.name' to be\n  specified as that determines the data set used for training.\n\n  Args:\n    model_dir: String with path to directory where model output should be saved.\n    overwrite: Boolean indicating whether to overwrite output directory.\n    model: GaussianEncoderModel that should be trained and exported.\n    training_steps: Integer with number of training steps.\n    unsupervised_data_seed: Integer with random seed used for the unsupervised\n      data.\n    supervised_data_seed: Integer with random seed for supervised data.\n    model_seed: Integer with random seed used for the model.\n      batch_size: Integer with the batch size.\n    num_labelled_samples: Integer with number of labelled observations for\n      training.\n    train_percentage: Fraction of the labelled data to use for training (0,1)\n    name: Optional string with name of the model (can be used to name models).\n  \"\"\"", "\n", "# We do not use the variable 'name'. Instead, it can be used to name results", "\n", "# as it will be part of the saved gin config.", "\n", "del", "name", "\n", "\n", "# Delete the output directory if necessary.", "\n", "if", "tf", ".", "gfile", ".", "IsDirectory", "(", "model_dir", ")", ":", "\n", "    ", "if", "overwrite", ":", "\n", "      ", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "model_dir", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"Directory already exists and overwrite is False.\"", ")", "\n", "\n", "# Obtain the dataset.", "\n", "", "", "dataset", "=", "named_data", ".", "get_named_ground_truth_data", "(", ")", "\n", "(", "sampled_observations", ",", "\n", "sampled_factors", ",", "\n", "factor_sizes", ")", "=", "semi_supervised_utils", ".", "sample_supervised_data", "(", "\n", "supervised_data_seed", ",", "dataset", ",", "num_labelled_samples", ")", "\n", "# We instantiate the model class.", "\n", "if", "issubclass", "(", "model", ",", "semi_supervised_vae", ".", "BaseS2VAE", ")", ":", "\n", "    ", "model", "=", "model", "(", "factor_sizes", ")", "\n", "", "else", ":", "\n", "    ", "model", "=", "model", "(", ")", "\n", "\n", "# We create a TPUEstimator based on the provided model. This is primarily so", "\n", "# that we could switch to TPU training in the future. For now, we train", "\n", "# locally on GPUs.", "\n", "", "run_config", "=", "tpu_config", ".", "RunConfig", "(", "\n", "tf_random_seed", "=", "model_seed", ",", "\n", "keep_checkpoint_max", "=", "1", ",", "\n", "tpu_config", "=", "tpu_config", ".", "TPUConfig", "(", "iterations_per_loop", "=", "500", ")", ")", "\n", "tpu_estimator", "=", "TPUEstimator", "(", "\n", "use_tpu", "=", "False", ",", "\n", "model_fn", "=", "model", ".", "model_fn", ",", "\n", "model_dir", "=", "model_dir", ",", "\n", "train_batch_size", "=", "batch_size", ",", "\n", "eval_batch_size", "=", "batch_size", ",", "\n", "config", "=", "run_config", ")", "\n", "\n", "# Set up time to keep track of elapsed time in results.", "\n", "experiment_timer", "=", "time", ".", "time", "(", ")", "\n", "# Do the actual training.", "\n", "tpu_estimator", ".", "train", "(", "\n", "input_fn", "=", "_make_input_fn", "(", "dataset", ",", "num_labelled_samples", ",", "\n", "unsupervised_data_seed", ",", "sampled_observations", ",", "\n", "sampled_factors", ",", "train_percentage", ")", ",", "\n", "steps", "=", "training_steps", ")", "\n", "# Save model as a TFHub module.", "\n", "output_shape", "=", "named_data", ".", "get_named_ground_truth_data", "(", ")", ".", "observation_shape", "\n", "module_export_path", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"tfhub\"", ")", "\n", "gaussian_encoder_model", ".", "export_as_tf_hub", "(", "model", ",", "output_shape", ",", "\n", "tpu_estimator", ".", "latest_checkpoint", "(", ")", ",", "\n", "module_export_path", ")", "\n", "\n", "# Save the results. The result dir will contain all the results and config", "\n", "# files that we copied along, as we progress in the pipeline. The idea is that", "\n", "# these files will be available for analysis at the end.", "\n", "results_dict", "=", "tpu_estimator", ".", "evaluate", "(", "\n", "input_fn", "=", "_make_input_fn", "(", "\n", "dataset", ",", "\n", "num_labelled_samples", ",", "\n", "unsupervised_data_seed", ",", "\n", "sampled_observations", ",", "\n", "sampled_factors", ",", "\n", "train_percentage", ",", "\n", "num_batches", "=", "num_labelled_samples", ",", "\n", "validation", "=", "True", ")", ")", "\n", "results_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"results\"", ")", "\n", "results_dict", "[", "\"elapsed_time\"", "]", "=", "time", ".", "time", "(", ")", "-", "experiment_timer", "\n", "results", ".", "update_result_directory", "(", "results_dir", ",", "\"train\"", ",", "results_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_lib._make_input_fn": [[166, 195], ["train_semi_supervised_lib.semi_supervised_dataset_from_ground_truth_data", "dataset.take.batch", "dataset.take.make_one_shot_iterator().get_next", "dataset.take.take", "dataset.take.make_one_shot_iterator"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_lib.semi_supervised_dataset_from_ground_truth_data"], ["", "def", "_make_input_fn", "(", "ground_truth_data", ",", "\n", "num_labelled_samples", ",", "\n", "unsupervised_data_seed", ",", "\n", "sampled_observations", ",", "\n", "sampled_factors", ",", "\n", "train_percentage", ",", "\n", "num_batches", "=", "None", ",", "\n", "validation", "=", "False", ")", ":", "\n", "  ", "\"\"\"Creates an input function for the experiments.\"\"\"", "\n", "\n", "def", "load_dataset", "(", "params", ")", ":", "\n", "    ", "\"\"\"TPUEstimator compatible input fuction.\"\"\"", "\n", "dataset", "=", "semi_supervised_dataset_from_ground_truth_data", "(", "\n", "ground_truth_data", ",", "\n", "num_labelled_samples", ",", "\n", "unsupervised_data_seed", ",", "\n", "sampled_observations", ",", "\n", "sampled_factors", ",", "\n", "train_percentage", ",", "\n", "validation", "=", "validation", ")", "\n", "batch_size", "=", "params", "[", "\"batch_size\"", "]", "\n", "# We need to drop the remainder as otherwise we lose the batch size in the", "\n", "# tensor shape. This has no effect as our data set is infinite.", "\n", "dataset", "=", "dataset", ".", "batch", "(", "batch_size", ",", "drop_remainder", "=", "True", ")", "\n", "if", "num_batches", "is", "not", "None", ":", "\n", "      ", "dataset", "=", "dataset", ".", "take", "(", "num_batches", ")", "\n", "", "return", "dataset", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "\n", "", "return", "load_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_lib.semi_supervised_dataset_from_ground_truth_data": [[197, 256], ["tensorflow.data.Dataset.from_generator", "tensorflow.data.Dataset.from_tensor_slices().repeat", "tensorflow.data.Dataset.zip", "numpy.random.RandomState", "disentanglement_lib.methods.semi_supervised.semi_supervised_utils.train_test_split", "disentanglement_lib.methods.semi_supervised.semi_supervised_utils.train_test_split", "tensorflow.data.Dataset.from_tensor_slices", "ground_truth_data.sample_observations", "tensorflow.to_float", "tensorflow.to_float"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.abstract_reasoning.relational_layers.repeat", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.train_test_split", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.train_test_split", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.ground_truth_data.GroundTruthData.sample_observations"], ["", "def", "semi_supervised_dataset_from_ground_truth_data", "(", "ground_truth_data", ",", "\n", "num_labelled_samples", ",", "\n", "unsupervised_data_seed", ",", "\n", "sampled_observations", ",", "\n", "sampled_factors", ",", "\n", "train_percentage", "=", "1.", ",", "\n", "validation", "=", "False", ")", ":", "\n", "  ", "\"\"\"Generates a tf.data.DataSet for semi-supervised learning.\n\n  In this setting we have a fixed number of labelled samples and unlimited\n  unlabelled samples. The data set will yield of pairs of samples where one\n  image is labelled and one is not. Once all the labelled examples are used they\n  repeat.\n\n  Args:\n    ground_truth_data: Dataset class.\n    num_labelled_samples: Number of labelled examples.\n    unsupervised_data_seed: Random seed for unsupervised data.\n    sampled_observations: Sampled labelled observations.\n    sampled_factors: Observed factors of variations for the labelled\n      observations.\n    train_percentage: Percentage of training points.\n    validation: Flag for validation mode.\n\n  Returns:\n    tf.data.Dataset, each point is\n    (unsupervised observation, (supervised observation, label)).\n    For dSprites these are of type\n    (np.array(64, 64, 1), (np.array(64, 64, 1), list of length 5.))\n  \"\"\"", "\n", "\n", "def", "unsupervised_generator", "(", ")", ":", "\n", "# We need to hard code the random seed for the unsupervised data so that the", "\n", "# data set can be reset.", "\n", "    ", "unsupervised_random_state", "=", "np", ".", "random", ".", "RandomState", "(", "unsupervised_data_seed", ")", "\n", "while", "True", ":", "\n", "      ", "yield", "ground_truth_data", ".", "sample_observations", "(", "1", ",", "\n", "unsupervised_random_state", ")", "[", "0", "]", "\n", "\n", "", "", "unlabelled_dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "\n", "unsupervised_generator", ",", "\n", "tf", ".", "float32", ",", "\n", "output_shapes", "=", "ground_truth_data", ".", "observation_shape", ")", "\n", "\n", "if", "validation", ":", "\n", "    ", "(", "_", ",", "_", ",", "sampled_observations", ",", "\n", "sampled_factors", ")", "=", "semi_supervised_utils", ".", "train_test_split", "(", "\n", "sampled_observations", ",", "sampled_factors", ",", "num_labelled_samples", ",", "\n", "train_percentage", ")", "\n", "", "else", ":", "\n", "    ", "(", "sampled_observations", ",", "sampled_factors", ",", "_", ",", "\n", "_", ")", "=", "semi_supervised_utils", ".", "train_test_split", "(", "sampled_observations", ",", "\n", "sampled_factors", ",", "\n", "num_labelled_samples", ",", "\n", "train_percentage", ")", "\n", "", "labelled_dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "\n", "(", "tf", ".", "to_float", "(", "sampled_observations", ")", ",", "tf", ".", "to_float", "(", "sampled_factors", ")", "\n", ")", ")", ".", "repeat", "(", ")", "\n", "return", "tf", ".", "data", ".", "Dataset", ".", "zip", "(", "(", "unlabelled_dataset", ",", "labelled_dataset", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils_test.SemiSupervisedDataTest.test_semi_supervised_data": [[36, 56], ["gin.clear_config", "gin.parse_config_files_and_bindings", "disentanglement_lib.data.ground_truth.dummy_data.DummyData", "disentanglement_lib.methods.semi_supervised.semi_supervised_utils.sample_supervised_data", "disentanglement_lib.methods.semi_supervised.train_semi_supervised_lib.semi_supervised_dataset_from_ground_truth_data", "disentanglement_lib.methods.semi_supervised.train_semi_supervised_lib.semi_supervised_dataset_from_ground_truth_data.make_one_shot_iterator", "train_s2_lib.semi_supervised_dataset_from_ground_truth_data.make_one_shot_iterator.get_next", "semi_supervised_utils_test.SemiSupervisedDataTest.test_session", "six.moves.range", "sess.run", "semi_supervised_utils_test.SemiSupervisedDataTest.assertEqual", "semi_supervised_utils_test.SemiSupervisedDataTest.assertEqual", "semi_supervised_utils_test.SemiSupervisedDataTest.assertLen"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.sample_supervised_data", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.train_semi_supervised_lib.semi_supervised_dataset_from_ground_truth_data"], ["  ", "def", "test_semi_supervised_data", "(", "self", ")", ":", "\n", "    ", "num_labels", "=", "1000", "\n", "gin", ".", "clear_config", "(", ")", "\n", "gin_bindings", "=", "[", "\"labeller.labeller_fn = @perfect_labeller\"", "]", "\n", "gin", ".", "parse_config_files_and_bindings", "(", "[", "]", ",", "gin_bindings", ")", "\n", "ground_truth_data", "=", "dummy_data", ".", "DummyData", "(", ")", "\n", "(", "sampled_observations", ",", "sampled_factors", ",", "\n", "_", ")", "=", "semi_supervised_utils", ".", "sample_supervised_data", "(", "\n", "0", ",", "ground_truth_data", ",", "num_labels", ")", "\n", "dataset", "=", "train_s2_lib", ".", "semi_supervised_dataset_from_ground_truth_data", "(", "\n", "ground_truth_data", ",", "num_labels", ",", "0", ",", "sampled_observations", ",", "\n", "sampled_factors", ")", "\n", "one_shot_iterator", "=", "dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "next_element", "=", "one_shot_iterator", ".", "get_next", "(", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "for", "_", "in", "range", "(", "1", ")", ":", "\n", "        ", "elem", "=", "sess", ".", "run", "(", "next_element", ")", "\n", "self", ".", "assertEqual", "(", "elem", "[", "0", "]", ".", "shape", ",", "(", "64", ",", "64", ",", "1", ")", ")", "\n", "self", ".", "assertEqual", "(", "elem", "[", "1", "]", "[", "0", "]", ".", "shape", ",", "(", "64", ",", "64", ",", "1", ")", ")", "\n", "self", ".", "assertLen", "(", "elem", "[", "1", "]", "[", "1", "]", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils_test.LabellerTest.test_perfect_labeller": [[60, 68], ["absl.testing.parameterized.parameters", "disentanglement_lib.data.ground_truth.dummy_data.DummyData", "disentanglement_lib.methods.semi_supervised.semi_supervised_utils.perfect_labeller", "numpy.sum", "semi_supervised_utils_test.LabellerTest.assertEqual", "numpy.random.RandomState", "numpy.abs", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.perfect_labeller"], ["  ", "@", "parameterized", ".", "parameters", "(", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "5", ",", "size", "=", "(", "100", ",", "10", ")", ")", ",", "0.", ")", ")", "\n", "def", "test_perfect_labeller", "(", "self", ",", "labels", ",", "target", ")", ":", "\n", "\n", "    ", "ground_truth_data", "=", "dummy_data", ".", "DummyData", "(", ")", "\n", "processed_labels", ",", "_", "=", "semi_supervised_utils", ".", "perfect_labeller", "(", "\n", "labels", ",", "ground_truth_data", ",", "np", ".", "random", ".", "RandomState", "(", "0", ")", ")", "\n", "test_value", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "processed_labels", "-", "labels", ")", ")", "\n", "self", ".", "assertEqual", "(", "test_value", ",", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils_test.LabellerTest.test_bin_labeller": [[69, 89], ["absl.testing.parameterized.parameters", "labels.reshape.reshape.reshape", "target.reshape.reshape.reshape", "disentanglement_lib.data.ground_truth.dummy_data.DummyData", "disentanglement_lib.methods.semi_supervised.semi_supervised_utils.bin_labeller", "numpy.all", "semi_supervised_utils_test.LabellerTest.assertEqual", "numpy.random.RandomState", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.bin_labeller"], ["", "@", "parameterized", ".", "parameters", "(", "\n", "(", "np", ".", "array", "(", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "0", ",", "1", ",", "2", ",", "3", ",", "4", "]", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "np", ".", "array", "(", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "0", ",", "1", ",", "2", ",", "3", ",", "4", "]", ",", "dtype", "=", "np", ".", "int64", ")", ",", "10", ")", ",", "\n", "(", "np", ".", "array", "(", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "0", ",", "1", ",", "2", ",", "3", ",", "4", "]", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "np", ".", "array", "(", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "0", ",", "1", ",", "2", ",", "3", ",", "4", "]", ",", "dtype", "=", "np", ".", "int64", ")", ",", "5", ")", ",", "\n", "(", "np", ".", "array", "(", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "0", ",", "1", ",", "2", ",", "3", ",", "4", "]", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "np", ".", "array", "(", "[", "0", ",", "0", ",", "1", ",", "1", ",", "2", ",", "0", ",", "0", ",", "1", ",", "1", ",", "2", "]", ",", "dtype", "=", "np", ".", "int64", ")", ",", "3", ")", ",", "\n", "(", "np", ".", "array", "(", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "0", ",", "1", ",", "2", ",", "3", ",", "4", "]", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "1", ",", "1", ",", "0", ",", "0", ",", "0", ",", "1", ",", "1", "]", ",", "dtype", "=", "np", ".", "int64", ")", ",", "2", ")", ")", "\n", "def", "test_bin_labeller", "(", "self", ",", "labels", ",", "target", ",", "num_bins", ")", ":", "\n", "    ", "labels", "=", "labels", ".", "reshape", "(", "(", "1", ",", "10", ")", ")", "\n", "target", "=", "target", ".", "reshape", "(", "(", "1", ",", "10", ")", ")", "\n", "ground_truth_data", "=", "dummy_data", ".", "DummyData", "(", ")", "\n", "processed_labels", ",", "_", "=", "semi_supervised_utils", ".", "bin_labeller", "(", "\n", "labels", ",", "\n", "ground_truth_data", ",", "\n", "np", ".", "random", ".", "RandomState", "(", "0", ")", ",", "\n", "num_bins", "=", "num_bins", ")", "\n", "test_value", "=", "np", ".", "all", "(", "processed_labels", "==", "target", ")", "\n", "self", ".", "assertEqual", "(", "test_value", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils_test.LabellerTest.test_noisy_labeller": [[90, 101], ["absl.testing.parameterized.parameters", "disentanglement_lib.data.ground_truth.dummy_data.DummyData", "labels.copy", "disentanglement_lib.methods.semi_supervised.semi_supervised_utils.noisy_labeller", "numpy.count_nonzero", "semi_supervised_utils_test.LabellerTest.assertBetween", "numpy.random.RandomState", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.noisy_labeller"], ["", "@", "parameterized", ".", "parameters", "(", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "5", ",", "size", "=", "(", "10000", ",", "10", ")", ")", ",", "7000.", ",", "\n", "12000", ")", ")", "\n", "def", "test_noisy_labeller", "(", "self", ",", "labels", ",", "target_low", ",", "target_high", ")", ":", "\n", "\n", "    ", "ground_truth_data", "=", "dummy_data", ".", "DummyData", "(", ")", "\n", "old_labels", "=", "labels", ".", "copy", "(", ")", "\n", "processed_labels", ",", "_", "=", "semi_supervised_utils", ".", "noisy_labeller", "(", "\n", "labels", ",", "ground_truth_data", ",", "np", ".", "random", ".", "RandomState", "(", "0", ")", ",", "0.1", ")", "\n", "index_equal", "=", "(", "processed_labels", "-", "old_labels", ")", ".", "flatten", "(", ")", "\n", "test_value", "=", "np", ".", "count_nonzero", "(", "index_equal", ")", "\n", "self", ".", "assertBetween", "(", "test_value", ",", "target_low", ",", "target_high", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils_test.LabellerTest.test_permuted_labeller": [[102, 110], ["absl.testing.parameterized.parameters", "disentanglement_lib.methods.semi_supervised.semi_supervised_utils.permute", "semi_supervised_utils_test.LabellerTest.assertEqual", "numpy.random.RandomState", "numpy.all", "numpy.all", "numpy.random.randint", "numpy.logical_not"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.permute"], ["", "@", "parameterized", ".", "parameters", "(", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "2", ",", "size", "=", "(", "10", ")", ")", ",", "2", ")", ")", "\n", "def", "test_permuted_labeller", "(", "self", ",", "labels", ",", "num_factors", ")", ":", "\n", "    ", "permuted", "=", "semi_supervised_utils", ".", "permute", "(", "labels", ",", "num_factors", ",", "\n", "np", ".", "random", ".", "RandomState", "(", "0", ")", ")", "\n", "result", "=", "np", ".", "all", "(", "labels", "==", "permuted", ")", "or", "np", ".", "all", "(", "\n", "labels", "==", "np", ".", "logical_not", "(", "permuted", ")", ")", "\n", "\n", "self", ".", "assertEqual", "(", "result", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils_test.LabellerTest.test_filter_factors": [[111, 117], ["absl.testing.parameterized.parameters", "disentanglement_lib.methods.semi_supervised.semi_supervised_utils.filter_factors", "semi_supervised_utils_test.LabellerTest.assertEqual", "semi_supervised_utils_test.LabellerTest.assertEqual", "numpy.random.RandomState", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.filter_factors"], ["", "@", "parameterized", ".", "parameters", "(", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "5", ",", "size", "=", "(", "10000", ",", "10", ")", ")", ",", "3", ")", ")", "\n", "def", "test_filter_factors", "(", "self", ",", "labels", ",", "target", ")", ":", "\n", "    ", "new_labels", ",", "_", "=", "semi_supervised_utils", ".", "filter_factors", "(", "\n", "labels", ",", "target", ",", "np", ".", "random", ".", "RandomState", "(", "0", ")", ")", "\n", "self", ".", "assertEqual", "(", "new_labels", ".", "shape", "[", "0", "]", ",", "labels", ".", "shape", "[", "0", "]", ")", "\n", "self", ".", "assertEqual", "(", "new_labels", ".", "shape", "[", "1", "]", ",", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.optimizers_test.OptimizerTest.test_vae_optimizer": [[72, 90], ["absl.testing.parameterized.parameters", "gin.parse_config_files_and_bindings", "gin.parse_config_files_and_bindings", "gin.parse_config_files_and_bindings", "gin.parse_config_files_and_bindings", "gin.clear_config", "gin.clear_config", "gin.clear_config", "gin.clear_config", "list", "optimizers_test.OptimizerTest.test_session", "tensorflow.Variable", "tensorflow.pow", "tensorflow.train.get_or_create_global_step", "disentanglement_lib.methods.shared.optimizers.make_vae_optimizer", "disentanglement_lib.methods.shared.optimizers.make_vae_optimizer.minimize", "tensorflow.global_variables_initializer().run", "six.moves.range", "optimizers_test.OptimizerTest.evaluate", "optimizers_test.OptimizerTest.assertAlmostEqual", "optimizers_test._make_vae_optimizer_configs", "optimizers_test.OptimizerTest.evaluate", "optimizers_test.OptimizerTest.assertEqual", "tensorflow.global_variables_initializer", "optimizers_test.OptimizerTest.evaluate"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.optimizers.make_vae_optimizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate.evaluate", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.optimizers_test._make_vae_optimizer_configs", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate.evaluate", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate.evaluate"], ["  ", "@", "parameterized", ".", "parameters", "(", "list", "(", "_make_vae_optimizer_configs", "(", ")", ")", ")", "\n", "def", "test_vae_optimizer", "(", "self", ",", "gin_bindings", ",", "expected_learning_rate", ")", ":", "\n", "    ", "gin", ".", "parse_config_files_and_bindings", "(", "[", "]", ",", "gin_bindings", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "x", "=", "tf", ".", "Variable", "(", "0.0", ")", "\n", "y", "=", "tf", ".", "pow", "(", "x", "+", "2.0", ",", "2.0", ")", "\n", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "optimizer", "=", "optimizers", ".", "make_vae_optimizer", "(", ")", "\n", "train_op", "=", "optimizer", ".", "minimize", "(", "loss", "=", "y", ",", "global_step", "=", "global_step", ")", "\n", "tf", ".", "global_variables_initializer", "(", ")", ".", "run", "(", ")", "\n", "for", "it", "in", "range", "(", "10", ")", ":", "\n", "        ", "self", ".", "evaluate", "(", "train_op", ")", "\n", "self", ".", "assertEqual", "(", "it", "+", "1", ",", "self", ".", "evaluate", "(", "global_step", ")", ")", "\n", "", "current_learning_rate", "=", "self", ".", "evaluate", "(", "optimizer", ".", "_learning_rate_tensor", ")", "\n", "self", ".", "assertAlmostEqual", "(", "expected_learning_rate", ",", "current_learning_rate", ")", "\n", "\n", "", "gin", ".", "clear_config", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.optimizers_test._make_vae_optimizer_configs": [[29, 68], ["None"], "function", ["None"], ["def", "_make_vae_optimizer_configs", "(", ")", ":", "\n", "  ", "\"\"\"Yield different vae_optimizer test configurations.\n\n  Yields:\n    A tuple containing a list of gin bindings, and the expected learning rate\n    after 10 steps.\n  \"\"\"", "\n", "# Constant learning rate specified in the optimizer.", "\n", "bindings", "=", "[", "\n", "\"vae_optimizer.optimizer_fn = @GradientDescentOptimizer\"", ",", "\n", "\"GradientDescentOptimizer.learning_rate = 0.1\"", ",", "\n", "]", "\n", "yield", "(", "bindings", ",", "0.1", ")", "\n", "\n", "# Constant learning rate specified in vae_optimizer.", "\n", "bindings", "=", "[", "\n", "\"vae_optimizer.optimizer_fn = @GradientDescentOptimizer\"", ",", "\n", "\"vae_optimizer.learning_rate = 0.1\"", ",", "\n", "]", "\n", "yield", "(", "bindings", ",", "0.1", ")", "\n", "\n", "# Piecewise constant learning rate.", "\n", "bindings", "=", "[", "\n", "\"vae_optimizer.optimizer_fn = @GradientDescentOptimizer\"", ",", "\n", "\"vae_optimizer.learning_rate = @piecewise_constant\"", ",", "\n", "\"piecewise_constant.boundaries = (3, 5)\"", ",", "\n", "\"piecewise_constant.values = (0.2, 0.1, 0.01)\"", ",", "\n", "]", "\n", "yield", "(", "bindings", ",", "0.01", ")", "\n", "\n", "# Exponential decay learning rate.", "\n", "bindings", "=", "[", "\n", "\"vae_optimizer.optimizer_fn = @GradientDescentOptimizer\"", ",", "\n", "\"vae_optimizer.learning_rate = @exponential_decay\"", ",", "\n", "\"exponential_decay.learning_rate = 0.1\"", ",", "\n", "\"exponential_decay.decay_steps = 1\"", ",", "\n", "\"exponential_decay.decay_rate = 0.9\"", ",", "\n", "]", "\n", "yield", "(", "bindings", ",", "0.03486784401", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.architectures_test.ArchitecturesTest.test_encoder": [[28, 40], ["absl.testing.parameterized.named_parameters", "numpy.ones", "tensorflow.placeholder", "encoder_f", "architectures_test.ArchitecturesTest.test_session", "sess.run", "sess.run", "tensorflow.initialize_all_variables"], "methods", ["None"], ["  ", "@", "parameterized", ".", "named_parameters", "(", "\n", "(", "'fc_encoder'", ",", "architectures", ".", "fc_encoder", ")", ",", "\n", "(", "'conv_encoder'", ",", "architectures", ".", "conv_encoder", ")", ",", "\n", ")", "\n", "def", "test_encoder", "(", "self", ",", "encoder_f", ")", ":", "\n", "    ", "minibatch", "=", "np", ".", "ones", "(", "shape", "=", "(", "10", ",", "64", ",", "64", ",", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "input_tensor", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "64", ",", "64", ",", "1", ")", ")", "\n", "latent_mean", ",", "latent_logvar", "=", "encoder_f", "(", "input_tensor", ",", "10", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "initialize_all_variables", "(", ")", ")", "\n", "sess", ".", "run", "(", "\n", "[", "latent_mean", ",", "latent_logvar", "]", ",", "feed_dict", "=", "{", "input_tensor", ":", "minibatch", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.architectures_test.ArchitecturesTest.test_decoder": [[41, 52], ["absl.testing.parameterized.named_parameters", "numpy.ones", "tensorflow.placeholder", "decoder_f", "architectures_test.ArchitecturesTest.test_session", "sess.run", "sess.run", "tensorflow.initialize_all_variables"], "methods", ["None"], ["", "", "@", "parameterized", ".", "named_parameters", "(", "\n", "(", "'fc_decoder'", ",", "architectures", ".", "fc_decoder", ")", ",", "\n", "(", "'deconv_decoder'", ",", "architectures", ".", "deconv_decoder", ")", ",", "\n", ")", "\n", "def", "test_decoder", "(", "self", ",", "decoder_f", ")", ":", "\n", "    ", "latent_variable", "=", "np", ".", "ones", "(", "shape", "=", "(", "10", ",", "15", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "input_tensor", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "15", ")", ")", "\n", "images", "=", "decoder_f", "(", "input_tensor", ",", "[", "64", ",", "64", ",", "1", "]", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "initialize_all_variables", "(", ")", ")", "\n", "sess", ".", "run", "(", "images", ",", "feed_dict", "=", "{", "input_tensor", ":", "latent_variable", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.architectures_test.ArchitecturesTest.test_discriminator": [[53, 63], ["absl.testing.parameterized.named_parameters", "numpy.ones", "tensorflow.placeholder", "discriminator_f", "architectures_test.ArchitecturesTest.test_session", "sess.run", "sess.run", "tensorflow.initialize_all_variables"], "methods", ["None"], ["", "", "@", "parameterized", ".", "named_parameters", "(", "\n", "(", "'fc_discriminator'", ",", "architectures", ".", "fc_discriminator", ")", ",", "\n", ")", "\n", "def", "test_discriminator", "(", "self", ",", "discriminator_f", ")", ":", "\n", "    ", "images", "=", "np", ".", "ones", "(", "shape", "=", "(", "32", ",", "10", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "input_tensor", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "10", ")", ")", "\n", "logits", ",", "probs", "=", "discriminator_f", "(", "input_tensor", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "initialize_all_variables", "(", ")", ")", "\n", "sess", ".", "run", "(", "[", "logits", ",", "probs", "]", ",", "feed_dict", "=", "{", "input_tensor", ":", "images", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.architectures.make_gaussian_encoder": [[25, 54], ["gin.configurable", "tensorflow.variable_scope", "encoder_fn"], "function", ["None"], ["@", "gin", ".", "configurable", "(", "\"encoder\"", ",", "whitelist", "=", "[", "\"num_latent\"", ",", "\"encoder_fn\"", "]", ")", "\n", "def", "make_gaussian_encoder", "(", "input_tensor", ",", "\n", "is_training", "=", "True", ",", "\n", "num_latent", "=", "gin", ".", "REQUIRED", ",", "\n", "encoder_fn", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "  ", "\"\"\"Gin wrapper to create and apply a Gaussian encoder configurable with gin.\n\n  This is a separate function so that several different models (such as\n  BetaVAE and FactorVAE) can call this function while the gin binding always\n  stays 'encoder.(...)'. This makes it easier to configure models and parse\n  the results files.\n\n  Args:\n    input_tensor: Tensor with image that should be encoded.\n    is_training: Boolean that indicates whether we are training (usually\n      required for batch normalization).\n    num_latent: Integer with dimensionality of latent space.\n    encoder_fn: Function that that takes the arguments (input_tensor,\n      num_latent, is_training) and returns the tuple (means, log_vars) with the\n      encoder means and log variances.\n\n  Returns:\n    Tuple (means, log_vars) with the encoder means and log variances.\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "\"encoder\"", ")", ":", "\n", "    ", "return", "encoder_fn", "(", "\n", "input_tensor", "=", "input_tensor", ",", "\n", "num_latent", "=", "num_latent", ",", "\n", "is_training", "=", "is_training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.architectures.make_decoder": [[56, 85], ["gin.configurable", "tensorflow.variable_scope", "decoder_fn"], "function", ["None"], ["", "", "@", "gin", ".", "configurable", "(", "\"decoder\"", ",", "whitelist", "=", "[", "\"decoder_fn\"", "]", ")", "\n", "def", "make_decoder", "(", "latent_tensor", ",", "\n", "output_shape", ",", "\n", "is_training", "=", "True", ",", "\n", "decoder_fn", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "  ", "\"\"\"Gin wrapper to create and apply a decoder configurable with gin.\n\n  This is a separate function so that several different models (such as\n  BetaVAE and FactorVAE) can call this function while the gin binding always\n  stays 'decoder.(...)'. This makes it easier to configure models and parse\n  the results files.\n\n  Args:\n    latent_tensor: Tensor latent space embeddings to decode from.\n    output_shape: Tuple with the output shape of the observations to be\n      generated.\n    is_training: Boolean that indicates whether we are training (usually\n      required for batch normalization).\n    decoder_fn: Function that that takes the arguments (input_tensor,\n      output_shape, is_training) and returns the decoded observations.\n\n  Returns:\n    Tensor of decoded observations.\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "\"decoder\"", ")", ":", "\n", "    ", "return", "decoder_fn", "(", "\n", "latent_tensor", "=", "latent_tensor", ",", "\n", "output_shape", "=", "output_shape", ",", "\n", "is_training", "=", "is_training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.architectures.make_discriminator": [[87, 112], ["gin.configurable", "tensorflow.variable_scope", "discriminator_fn", "tensorflow.clip_by_value"], "function", ["None"], ["", "", "@", "gin", ".", "configurable", "(", "\"discriminator\"", ",", "whitelist", "=", "[", "\"discriminator_fn\"", "]", ")", "\n", "def", "make_discriminator", "(", "input_tensor", ",", "\n", "is_training", "=", "False", ",", "\n", "discriminator_fn", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "  ", "\"\"\"Gin wrapper to create and apply a discriminator configurable with gin.\n\n  This is a separate function so that several different models (such as\n  FactorVAE) can potentially call this function while the gin binding always\n  stays 'discriminator.(...)'. This makes it easier to configure models and\n  parse the results files.\n\n  Args:\n    input_tensor: Tensor on which the discriminator operates.\n    is_training: Boolean that indicates whether we are training (usually\n      required for batch normalization).\n    discriminator_fn: Function that that takes the arguments\n    (input_tensor, is_training) and returns tuple of (logits, clipped_probs).\n\n  Returns:\n    Tuple of (logits, clipped_probs) tensors.\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ")", ":", "\n", "    ", "logits", ",", "probs", "=", "discriminator_fn", "(", "input_tensor", ",", "is_training", "=", "is_training", ")", "\n", "clipped", "=", "tf", ".", "clip_by_value", "(", "probs", ",", "1e-6", ",", "1", "-", "1e-6", ")", "\n", "", "return", "logits", ",", "clipped", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.architectures.fc_encoder": [[114, 142], ["gin.configurable", "tensorflow.layers.flatten", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"fc_encoder\"", ",", "whitelist", "=", "[", "]", ")", "\n", "def", "fc_encoder", "(", "input_tensor", ",", "num_latent", ",", "is_training", "=", "True", ")", ":", "\n", "  ", "\"\"\"Fully connected encoder used in beta-VAE paper for the dSprites data.\n\n  Based on row 1 of Table 1 on page 13 of \"beta-VAE: Learning Basic Visual\n  Concepts with a Constrained Variational Framework\"\n  (https://openreview.net/forum?id=Sy2fzU9gl).\n\n  Args:\n    input_tensor: Input tensor of shape (batch_size, 64, 64, num_channels) to\n      build encoder on.\n    num_latent: Number of latent variables to output.\n    is_training: Whether or not the graph is built for training (UNUSED).\n\n  Returns:\n    means: Output tensor of shape (batch_size, num_latent) with latent variable\n      means.\n    log_var: Output tensor of shape (batch_size, num_latent) with latent\n      variable log variances.\n  \"\"\"", "\n", "del", "is_training", "\n", "\n", "flattened", "=", "tf", ".", "layers", ".", "flatten", "(", "input_tensor", ")", "\n", "e1", "=", "tf", ".", "layers", ".", "dense", "(", "flattened", ",", "1200", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "name", "=", "\"e1\"", ")", "\n", "e2", "=", "tf", ".", "layers", ".", "dense", "(", "e1", ",", "1200", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "name", "=", "\"e2\"", ")", "\n", "means", "=", "tf", ".", "layers", ".", "dense", "(", "e2", ",", "num_latent", ",", "activation", "=", "None", ")", "\n", "log_var", "=", "tf", ".", "layers", ".", "dense", "(", "e2", ",", "num_latent", ",", "activation", "=", "None", ")", "\n", "return", "means", ",", "log_var", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.architectures.conv_encoder": [[144, 207], ["gin.configurable", "tensorflow.layers.conv2d", "tensorflow.layers.conv2d", "tensorflow.layers.conv2d", "tensorflow.layers.conv2d", "tensorflow.layers.flatten", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"conv_encoder\"", ",", "whitelist", "=", "[", "]", ")", "\n", "def", "conv_encoder", "(", "input_tensor", ",", "num_latent", ",", "is_training", "=", "True", ")", ":", "\n", "  ", "\"\"\"Convolutional encoder used in beta-VAE paper for the chairs data.\n\n  Based on row 3 of Table 1 on page 13 of \"beta-VAE: Learning Basic Visual\n  Concepts with a Constrained Variational Framework\"\n  (https://openreview.net/forum?id=Sy2fzU9gl)\n\n  Args:\n    input_tensor: Input tensor of shape (batch_size, 64, 64, num_channels) to\n      build encoder on.\n    num_latent: Number of latent variables to output.\n    is_training: Whether or not the graph is built for training (UNUSED).\n\n  Returns:\n    means: Output tensor of shape (batch_size, num_latent) with latent variable\n      means.\n    log_var: Output tensor of shape (batch_size, num_latent) with latent\n      variable log variances.\n  \"\"\"", "\n", "del", "is_training", "\n", "\n", "e1", "=", "tf", ".", "layers", ".", "conv2d", "(", "\n", "inputs", "=", "input_tensor", ",", "\n", "filters", "=", "32", ",", "\n", "kernel_size", "=", "4", ",", "\n", "strides", "=", "2", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "name", "=", "\"e1\"", ",", "\n", ")", "\n", "e2", "=", "tf", ".", "layers", ".", "conv2d", "(", "\n", "inputs", "=", "e1", ",", "\n", "filters", "=", "32", ",", "\n", "kernel_size", "=", "4", ",", "\n", "strides", "=", "2", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "name", "=", "\"e2\"", ",", "\n", ")", "\n", "e3", "=", "tf", ".", "layers", ".", "conv2d", "(", "\n", "inputs", "=", "e2", ",", "\n", "filters", "=", "64", ",", "\n", "kernel_size", "=", "2", ",", "\n", "strides", "=", "2", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "name", "=", "\"e3\"", ",", "\n", ")", "\n", "e4", "=", "tf", ".", "layers", ".", "conv2d", "(", "\n", "inputs", "=", "e3", ",", "\n", "filters", "=", "64", ",", "\n", "kernel_size", "=", "2", ",", "\n", "strides", "=", "2", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "name", "=", "\"e4\"", ",", "\n", ")", "\n", "flat_e4", "=", "tf", ".", "layers", ".", "flatten", "(", "e4", ")", "\n", "e5", "=", "tf", ".", "layers", ".", "dense", "(", "flat_e4", ",", "256", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "name", "=", "\"e5\"", ")", "\n", "means", "=", "tf", ".", "layers", ".", "dense", "(", "e5", ",", "num_latent", ",", "activation", "=", "None", ",", "name", "=", "\"means\"", ")", "\n", "log_var", "=", "tf", ".", "layers", ".", "dense", "(", "e5", ",", "num_latent", ",", "activation", "=", "None", ",", "name", "=", "\"log_var\"", ")", "\n", "return", "means", ",", "log_var", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.architectures.fc_decoder": [[209, 232], ["gin.configurable", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.reshape", "numpy.prod"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"fc_decoder\"", ",", "whitelist", "=", "[", "]", ")", "\n", "def", "fc_decoder", "(", "latent_tensor", ",", "output_shape", ",", "is_training", "=", "True", ")", ":", "\n", "  ", "\"\"\"Fully connected encoder used in beta-VAE paper for the dSprites data.\n\n  Based on row 1 of Table 1 on page 13 of \"beta-VAE: Learning Basic Visual\n  Concepts with a Constrained Variational Framework\"\n  (https://openreview.net/forum?id=Sy2fzU9gl)\n\n  Args:\n    latent_tensor: Input tensor to connect decoder to.\n    output_shape: Shape of the data.\n    is_training: Whether or not the graph is built for training (UNUSED).\n\n  Returns:\n    Output tensor of shape (None, 64, 64, num_channels) with the [0,1] pixel\n    intensities.\n  \"\"\"", "\n", "del", "is_training", "\n", "d1", "=", "tf", ".", "layers", ".", "dense", "(", "latent_tensor", ",", "1200", ",", "activation", "=", "tf", ".", "nn", ".", "tanh", ")", "\n", "d2", "=", "tf", ".", "layers", ".", "dense", "(", "d1", ",", "1200", ",", "activation", "=", "tf", ".", "nn", ".", "tanh", ")", "\n", "d3", "=", "tf", ".", "layers", ".", "dense", "(", "d2", ",", "1200", ",", "activation", "=", "tf", ".", "nn", ".", "tanh", ")", "\n", "d4", "=", "tf", ".", "layers", ".", "dense", "(", "d3", ",", "np", ".", "prod", "(", "output_shape", ")", ")", "\n", "return", "tf", ".", "reshape", "(", "d4", ",", "shape", "=", "[", "-", "1", "]", "+", "output_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.architectures.deconv_decoder": [[234, 289], ["gin.configurable", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.reshape", "tensorflow.layers.conv2d_transpose", "tensorflow.layers.conv2d_transpose", "tensorflow.layers.conv2d_transpose", "tensorflow.layers.conv2d_transpose", "tensorflow.reshape"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"deconv_decoder\"", ",", "whitelist", "=", "[", "]", ")", "\n", "def", "deconv_decoder", "(", "latent_tensor", ",", "output_shape", ",", "is_training", "=", "True", ")", ":", "\n", "  ", "\"\"\"Convolutional decoder used in beta-VAE paper for the chairs data.\n\n  Based on row 3 of Table 1 on page 13 of \"beta-VAE: Learning Basic Visual\n  Concepts with a Constrained Variational Framework\"\n  (https://openreview.net/forum?id=Sy2fzU9gl)\n\n  Args:\n    latent_tensor: Input tensor of shape (batch_size,) to connect decoder to.\n    output_shape: Shape of the data.\n    is_training: Whether or not the graph is built for training (UNUSED).\n\n  Returns:\n    Output tensor of shape (batch_size, 64, 64, num_channels) with the [0,1]\n      pixel intensities.\n  \"\"\"", "\n", "del", "is_training", "\n", "d1", "=", "tf", ".", "layers", ".", "dense", "(", "latent_tensor", ",", "256", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "d2", "=", "tf", ".", "layers", ".", "dense", "(", "d1", ",", "1024", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "d2_reshaped", "=", "tf", ".", "reshape", "(", "d2", ",", "shape", "=", "[", "-", "1", ",", "4", ",", "4", ",", "64", "]", ")", "\n", "d3", "=", "tf", ".", "layers", ".", "conv2d_transpose", "(", "\n", "inputs", "=", "d2_reshaped", ",", "\n", "filters", "=", "64", ",", "\n", "kernel_size", "=", "4", ",", "\n", "strides", "=", "2", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "padding", "=", "\"same\"", ",", "\n", ")", "\n", "\n", "d4", "=", "tf", ".", "layers", ".", "conv2d_transpose", "(", "\n", "inputs", "=", "d3", ",", "\n", "filters", "=", "32", ",", "\n", "kernel_size", "=", "4", ",", "\n", "strides", "=", "2", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "padding", "=", "\"same\"", ",", "\n", ")", "\n", "\n", "d5", "=", "tf", ".", "layers", ".", "conv2d_transpose", "(", "\n", "inputs", "=", "d4", ",", "\n", "filters", "=", "32", ",", "\n", "kernel_size", "=", "4", ",", "\n", "strides", "=", "2", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "padding", "=", "\"same\"", ",", "\n", ")", "\n", "d6", "=", "tf", ".", "layers", ".", "conv2d_transpose", "(", "\n", "inputs", "=", "d5", ",", "\n", "filters", "=", "output_shape", "[", "2", "]", ",", "\n", "kernel_size", "=", "4", ",", "\n", "strides", "=", "2", ",", "\n", "padding", "=", "\"same\"", ",", "\n", ")", "\n", "return", "tf", ".", "reshape", "(", "d6", ",", "[", "-", "1", "]", "+", "output_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.architectures.fc_discriminator": [[291, 320], ["gin.configurable", "tensorflow.layers.flatten", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.nn.softmax"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"fc_discriminator\"", ",", "whitelist", "=", "[", "]", ")", "\n", "def", "fc_discriminator", "(", "input_tensor", ",", "is_training", "=", "True", ")", ":", "\n", "  ", "\"\"\"Fully connected discriminator used in FactorVAE paper for all datasets.\n\n  Based on Appendix A page 11 \"Disentangling by Factorizing\"\n  (https://arxiv.org/pdf/1802.05983.pdf)\n\n  Args:\n    input_tensor: Input tensor of shape (None, num_latents) to build\n      discriminator on.\n    is_training: Whether or not the graph is built for training (UNUSED).\n\n  Returns:\n    logits: Output tensor of shape (batch_size, 2) with logits from\n      discriminator.\n    probs: Output tensor of shape (batch_size, 2) with probabilities from\n      discriminator.\n  \"\"\"", "\n", "del", "is_training", "\n", "flattened", "=", "tf", ".", "layers", ".", "flatten", "(", "input_tensor", ")", "\n", "d1", "=", "tf", ".", "layers", ".", "dense", "(", "flattened", ",", "1000", ",", "activation", "=", "tf", ".", "nn", ".", "leaky_relu", ",", "name", "=", "\"d1\"", ")", "\n", "d2", "=", "tf", ".", "layers", ".", "dense", "(", "d1", ",", "1000", ",", "activation", "=", "tf", ".", "nn", ".", "leaky_relu", ",", "name", "=", "\"d2\"", ")", "\n", "d3", "=", "tf", ".", "layers", ".", "dense", "(", "d2", ",", "1000", ",", "activation", "=", "tf", ".", "nn", ".", "leaky_relu", ",", "name", "=", "\"d3\"", ")", "\n", "d4", "=", "tf", ".", "layers", ".", "dense", "(", "d3", ",", "1000", ",", "activation", "=", "tf", ".", "nn", ".", "leaky_relu", ",", "name", "=", "\"d4\"", ")", "\n", "d5", "=", "tf", ".", "layers", ".", "dense", "(", "d4", ",", "1000", ",", "activation", "=", "tf", ".", "nn", ".", "leaky_relu", ",", "name", "=", "\"d5\"", ")", "\n", "d6", "=", "tf", ".", "layers", ".", "dense", "(", "d5", ",", "1000", ",", "activation", "=", "tf", ".", "nn", ".", "leaky_relu", ",", "name", "=", "\"d6\"", ")", "\n", "logits", "=", "tf", ".", "layers", ".", "dense", "(", "d6", ",", "2", ",", "activation", "=", "None", ",", "name", "=", "\"logits\"", ")", "\n", "probs", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", "return", "logits", ",", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.architectures.test_encoder": [[322, 343], ["gin.configurable", "tensorflow.layers.flatten", "tensorflow.layers.dense", "tensorflow.layers.dense"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"test_encoder\"", ",", "whitelist", "=", "[", "\"num_latent\"", "]", ")", "\n", "def", "test_encoder", "(", "input_tensor", ",", "num_latent", ",", "is_training", ")", ":", "\n", "  ", "\"\"\"Simple encoder for testing.\n\n  Args:\n    input_tensor: Input tensor of shape (batch_size, 64, 64, num_channels) to\n      build encoder on.\n    num_latent: Number of latent variables to output.\n    is_training: Whether or not the graph is built for training (UNUSED).\n\n  Returns:\n    means: Output tensor of shape (batch_size, num_latent) with latent variable\n      means.\n    log_var: Output tensor of shape (batch_size, num_latent) with latent\n      variable log variances.\n  \"\"\"", "\n", "del", "is_training", "\n", "flattened", "=", "tf", ".", "layers", ".", "flatten", "(", "input_tensor", ")", "\n", "means", "=", "tf", ".", "layers", ".", "dense", "(", "flattened", ",", "num_latent", ",", "activation", "=", "None", ",", "name", "=", "\"e1\"", ")", "\n", "log_var", "=", "tf", ".", "layers", ".", "dense", "(", "flattened", ",", "num_latent", ",", "activation", "=", "None", ",", "name", "=", "\"e2\"", ")", "\n", "return", "means", ",", "log_var", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.architectures.test_decoder": [[345, 361], ["gin.configurable", "tensorflow.layers.dense", "tensorflow.reshape", "numpy.prod"], "function", ["None"], ["", "@", "gin", ".", "configurable", "(", "\"test_decoder\"", ",", "whitelist", "=", "[", "]", ")", "\n", "def", "test_decoder", "(", "latent_tensor", ",", "output_shape", ",", "is_training", "=", "False", ")", ":", "\n", "  ", "\"\"\"Simple decoder for testing.\n\n  Args:\n    latent_tensor: Input tensor to connect decoder to.\n    output_shape: Output shape.\n    is_training: Whether or not the graph is built for training (UNUSED).\n\n  Returns:\n    Output tensor of shape (batch_size, 64, 64, num_channels) with the [0,1]\n      pixel intensities.\n  \"\"\"", "\n", "del", "is_training", "\n", "output", "=", "tf", ".", "layers", ".", "dense", "(", "latent_tensor", ",", "np", ".", "prod", "(", "output_shape", ")", ",", "name", "=", "\"d1\"", ")", "\n", "return", "tf", ".", "reshape", "(", "output", ",", "shape", "=", "[", "-", "1", "]", "+", "output_shape", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.losses.bernoulli_loss": [[27, 63], ["gin.configurable", "numpy.prod", "tensorflow.reshape", "tensorflow.reshape", "tensorflow_probability.distributions.Bernoulli", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tf.reshape.get_shape().as_list", "tfp.distributions.Bernoulli.entropy", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.clip_by_value", "NotImplementedError", "tensorflow.clip_by_value", "tensorflow.reduce_sum", "tf.reshape.get_shape", "tensorflow.nn.tanh", "tensorflow.log", "tensorflow.log"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_model.tanh"], ["@", "gin", ".", "configurable", "(", "\"bernoulli_loss\"", ",", "whitelist", "=", "[", "\"subtract_true_image_entropy\"", "]", ")", "\n", "def", "bernoulli_loss", "(", "true_images", ",", "\n", "reconstructed_images", ",", "\n", "activation", ",", "\n", "subtract_true_image_entropy", "=", "False", ")", ":", "\n", "  ", "\"\"\"Computes the Bernoulli loss.\"\"\"", "\n", "flattened_dim", "=", "np", ".", "prod", "(", "true_images", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", ")", "\n", "reconstructed_images", "=", "tf", ".", "reshape", "(", "\n", "reconstructed_images", ",", "shape", "=", "[", "-", "1", ",", "flattened_dim", "]", ")", "\n", "true_images", "=", "tf", ".", "reshape", "(", "true_images", ",", "shape", "=", "[", "-", "1", ",", "flattened_dim", "]", ")", "\n", "\n", "# Because true images are not binary, the lower bound in the xent is not zero:", "\n", "# the lower bound in the xent is the entropy of the true images.", "\n", "if", "subtract_true_image_entropy", ":", "\n", "    ", "dist", "=", "tfp", ".", "distributions", ".", "Bernoulli", "(", "\n", "probs", "=", "tf", ".", "clip_by_value", "(", "true_images", ",", "1e-6", ",", "1", "-", "1e-6", ")", ")", "\n", "loss_lower_bound", "=", "tf", ".", "reduce_sum", "(", "dist", ".", "entropy", "(", ")", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "    ", "loss_lower_bound", "=", "0", "\n", "\n", "", "if", "activation", "==", "\"logits\"", ":", "\n", "    ", "loss", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "\n", "logits", "=", "reconstructed_images", ",", "labels", "=", "true_images", ")", ",", "\n", "axis", "=", "1", ")", "\n", "", "elif", "activation", "==", "\"tanh\"", ":", "\n", "    ", "reconstructed_images", "=", "tf", ".", "clip_by_value", "(", "\n", "tf", ".", "nn", ".", "tanh", "(", "reconstructed_images", ")", "/", "2", "+", "0.5", ",", "1e-6", ",", "1", "-", "1e-6", ")", "\n", "loss", "=", "-", "tf", ".", "reduce_sum", "(", "\n", "true_images", "*", "tf", ".", "log", "(", "reconstructed_images", ")", "+", "\n", "(", "1", "-", "true_images", ")", "*", "tf", ".", "log", "(", "1", "-", "reconstructed_images", ")", ",", "\n", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "    ", "raise", "NotImplementedError", "(", "\"Activation not supported.\"", ")", "\n", "\n", "", "return", "loss", "-", "loss_lower_bound", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.losses.l2_loss": [[65, 77], ["gin.configurable", "tensorflow.reduce_sum", "tensorflow.square", "tensorflow.reduce_sum", "NotImplementedError", "tensorflow.square", "tensorflow.nn.sigmoid", "tensorflow.nn.tanh"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_model.sigmoid", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.visualize.visualize_model.tanh"], ["", "@", "gin", ".", "configurable", "(", "\"l2_loss\"", ",", "whitelist", "=", "[", "]", ")", "\n", "def", "l2_loss", "(", "true_images", ",", "reconstructed_images", ",", "activation", ")", ":", "\n", "  ", "\"\"\"Computes the l2 loss.\"\"\"", "\n", "if", "activation", "==", "\"logits\"", ":", "\n", "    ", "return", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "square", "(", "true_images", "-", "tf", ".", "nn", ".", "sigmoid", "(", "reconstructed_images", ")", ")", ",", "[", "1", ",", "2", ",", "3", "]", ")", "\n", "", "elif", "activation", "==", "\"tanh\"", ":", "\n", "    ", "reconstructed_images", "=", "tf", ".", "nn", ".", "tanh", "(", "reconstructed_images", ")", "/", "2", "+", "0.5", "\n", "return", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "square", "(", "true_images", "-", "reconstructed_images", ")", ",", "[", "1", ",", "2", ",", "3", "]", ")", "\n", "", "else", ":", "\n", "    ", "raise", "NotImplementedError", "(", "\"Activation not supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.losses.make_reconstruction_loss": [[79, 89], ["gin.configurable", "tensorflow.variable_scope", "loss_fn"], "function", ["None"], ["", "", "@", "gin", ".", "configurable", "(", "\n", "\"reconstruction_loss\"", ",", "blacklist", "=", "[", "\"true_images\"", ",", "\"reconstructed_images\"", "]", ")", "\n", "def", "make_reconstruction_loss", "(", "true_images", ",", "\n", "reconstructed_images", ",", "\n", "loss_fn", "=", "gin", ".", "REQUIRED", ",", "\n", "activation", "=", "\"logits\"", ")", ":", "\n", "  ", "\"\"\"Wrapper that creates reconstruction loss.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "\"reconstruction_loss\"", ")", ":", "\n", "    ", "per_sample_loss", "=", "loss_fn", "(", "true_images", ",", "reconstructed_images", ",", "activation", ")", "\n", "", "return", "per_sample_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.optimizers.make_optimizer": [[24, 38], ["optimizer_fn", "callable", "optimizer_fn", "learning_rate.", "tensorflow.train.get_global_step"], "function", ["None"], ["def", "make_optimizer", "(", "optimizer_fn", ",", "learning_rate", ")", ":", "\n", "  ", "\"\"\"Wrapper to create the optimizer with a given learning_rate.\"\"\"", "\n", "if", "learning_rate", "is", "None", ":", "\n", "# Learning rate is specified in the optimizer_fn options, or left to its", "\n", "# default value.", "\n", "    ", "return", "optimizer_fn", "(", ")", "\n", "", "else", ":", "\n", "# Learning rate is explicitly specified in vae/discriminator optimizer.", "\n", "# If it is callable, we assume it's a LR decay function which needs the", "\n", "# current global step.", "\n", "    ", "if", "callable", "(", "learning_rate", ")", ":", "\n", "      ", "learning_rate", "=", "learning_rate", "(", "global_step", "=", "tf", ".", "train", ".", "get_global_step", "(", ")", ")", "\n", "\n", "", "return", "optimizer_fn", "(", "learning_rate", "=", "learning_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.optimizers.make_vae_optimizer": [[40, 44], ["gin.configurable", "optimizers.make_optimizer"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.optimizers.make_optimizer"], ["", "", "@", "gin", ".", "configurable", "(", "\"vae_optimizer\"", ")", "\n", "def", "make_vae_optimizer", "(", "optimizer_fn", "=", "gin", ".", "REQUIRED", ",", "learning_rate", "=", "None", ")", ":", "\n", "  ", "\"\"\"Wrapper that uses gin to construct an optimizer for VAEs.\"\"\"", "\n", "return", "make_optimizer", "(", "optimizer_fn", ",", "learning_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.optimizers.make_discriminator_optimizer": [[46, 50], ["gin.configurable", "optimizers.make_optimizer"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.optimizers.make_optimizer"], ["", "@", "gin", ".", "configurable", "(", "\"discriminator_optimizer\"", ")", "\n", "def", "make_discriminator_optimizer", "(", "optimizer_fn", "=", "gin", ".", "REQUIRED", ",", "learning_rate", "=", "None", ")", ":", "\n", "  ", "\"\"\"Wrapper that uses gin to construct an optimizer for the discriminator.\"\"\"", "\n", "return", "make_optimizer", "(", "optimizer_fn", ",", "learning_rate", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.gaussian_encoder_model.GaussianEncoderModel.model_fn": [[28, 31], ["NotImplementedError"], "methods", ["None"], ["def", "model_fn", "(", "self", ",", "features", ",", "labels", ",", "mode", ",", "params", ")", ":", "\n", "    ", "\"\"\"TPUEstimator compatible model function used for training/evaluation.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.gaussian_encoder_model.GaussianEncoderModel.gaussian_encoder": [[32, 43], ["NotImplementedError"], "methods", ["None"], ["", "def", "gaussian_encoder", "(", "self", ",", "input_tensor", ",", "is_training", ")", ":", "\n", "    ", "\"\"\"Applies the Gaussian encoder to images.\n\n    Args:\n      input_tensor: Tensor with the observations to be encoded.\n      is_training: Boolean indicating whether in training mode.\n\n    Returns:\n      Tuple of tensors with the mean and log variance of the Gaussian encoder.\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.gaussian_encoder_model.GaussianEncoderModel.decode": [[44, 47], ["NotImplementedError"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "latent_tensor", ",", "observation_shape", ",", "is_training", ")", ":", "\n", "    ", "\"\"\"Decodes the latent_tensor to an observation.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.gaussian_encoder_model.GaussianEncoderModel.sample_from_latent_distribution": [[48, 54], ["tensorflow.add", "tensorflow.exp", "tensorflow.random_normal", "tensorflow.shape"], "methods", ["None"], ["", "def", "sample_from_latent_distribution", "(", "self", ",", "z_mean", ",", "z_logvar", ")", ":", "\n", "    ", "\"\"\"Samples from the Gaussian distribution defined by z_mean and z_logvar.\"\"\"", "\n", "return", "tf", ".", "add", "(", "\n", "z_mean", ",", "\n", "tf", ".", "exp", "(", "z_logvar", "/", "2", ")", "*", "tf", ".", "random_normal", "(", "tf", ".", "shape", "(", "z_mean", ")", ",", "0", ",", "1", ")", ",", "\n", "name", "=", "\"sampled_latent_variable\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.gaussian_encoder_model.export_as_tf_hub": [[56, 123], ["gin.configurable", "tensorflow_hub.create_module_spec", "hub.create_module_spec.export", "tensorflow.variable_scope", "tensorflow.placeholder", "gaussian_encoder_model.gaussian_encoder", "tensorflow_hub.add_signature", "gaussian_encoder_model.sample_from_latent_distribution", "gaussian_encoder_model.decode", "tensorflow_hub.add_signature", "tensorflow.placeholder", "gaussian_encoder_model.decode", "tensorflow_hub.add_signature", "set", "tensorflow.get_variable_scope", "mean.get_shape"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.gaussian_encoder", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.gaussian_encoder_model.GaussianEncoderModel.sample_from_latent_distribution", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.decode", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.decode"], ["", "", "@", "gin", ".", "configurable", "(", "\"export_as_tf_hub\"", ",", "whitelist", "=", "[", "]", ")", "\n", "def", "export_as_tf_hub", "(", "gaussian_encoder_model", ",", "\n", "observation_shape", ",", "\n", "checkpoint_path", ",", "\n", "export_path", ",", "\n", "drop_collections", "=", "None", ")", ":", "\n", "  ", "\"\"\"Exports the provided GaussianEncoderModel as a TFHub module.\n\n  Args:\n    gaussian_encoder_model: GaussianEncoderModel to be exported.\n    observation_shape: Tuple with the observations shape.\n    checkpoint_path: String with path where to load weights from.\n    export_path: String with path where to save the TFHub module to.\n    drop_collections: List of collections to drop from the graph.\n  \"\"\"", "\n", "\n", "def", "module_fn", "(", "is_training", ")", ":", "\n", "    ", "\"\"\"Module function used for TFHub export.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "# Add a signature for the Gaussian encoder.", "\n", "      ", "image_placeholder", "=", "tf", ".", "placeholder", "(", "\n", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "None", "]", "+", "observation_shape", ")", "\n", "mean", ",", "logvar", "=", "gaussian_encoder_model", ".", "gaussian_encoder", "(", "\n", "image_placeholder", ",", "is_training", ")", "\n", "hub", ".", "add_signature", "(", "\n", "name", "=", "\"gaussian_encoder\"", ",", "\n", "inputs", "=", "{", "\"images\"", ":", "image_placeholder", "}", ",", "\n", "outputs", "=", "{", "\n", "\"mean\"", ":", "mean", ",", "\n", "\"logvar\"", ":", "logvar", "\n", "}", ")", "\n", "\n", "# Add a signature for reconstructions.", "\n", "latent_vector", "=", "gaussian_encoder_model", ".", "sample_from_latent_distribution", "(", "\n", "mean", ",", "logvar", ")", "\n", "reconstructed_images", "=", "gaussian_encoder_model", ".", "decode", "(", "\n", "latent_vector", ",", "observation_shape", ",", "is_training", ")", "\n", "hub", ".", "add_signature", "(", "\n", "name", "=", "\"reconstructions\"", ",", "\n", "inputs", "=", "{", "\"images\"", ":", "image_placeholder", "}", ",", "\n", "outputs", "=", "{", "\"images\"", ":", "reconstructed_images", "}", ")", "\n", "\n", "# Add a signature for the decoder.", "\n", "latent_placeholder", "=", "tf", ".", "placeholder", "(", "\n", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "mean", ".", "get_shape", "(", ")", "[", "1", "]", "]", ")", "\n", "decoded_images", "=", "gaussian_encoder_model", ".", "decode", "(", "latent_placeholder", ",", "\n", "observation_shape", ",", "\n", "is_training", ")", "\n", "\n", "hub", ".", "add_signature", "(", "\n", "name", "=", "\"decoder\"", ",", "\n", "inputs", "=", "{", "\"latent_vectors\"", ":", "latent_placeholder", "}", ",", "\n", "outputs", "=", "{", "\"images\"", ":", "decoded_images", "}", ")", "\n", "\n", "# Export the module.", "\n", "# Two versions of the model are exported:", "\n", "#   - one for \"test\" mode (the default tag)", "\n", "#   - one for \"training\" mode (\"is_training\" tag)", "\n", "# In the case that the encoder/decoder have dropout, or BN layers, these two", "\n", "# graphs are different.", "\n", "", "", "tags_and_args", "=", "[", "\n", "(", "{", "\"train\"", "}", ",", "{", "\"is_training\"", ":", "True", "}", ")", ",", "\n", "(", "set", "(", ")", ",", "{", "\"is_training\"", ":", "False", "}", ")", ",", "\n", "]", "\n", "spec", "=", "hub", ".", "create_module_spec", "(", "module_fn", ",", "tags_and_args", "=", "tags_and_args", ",", "\n", "drop_collections", "=", "drop_collections", ")", "\n", "spec", ".", "export", "(", "export_path", ",", "checkpoint_path", "=", "checkpoint_path", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train_test.TrainTest.test_train_model": [[86, 93], ["absl.testing.parameterized.parameters", "gin.clear_config", "disentanglement_lib.methods.unsupervised.train.train_with_gin", "list", "train_test._config_generator", "train_test.TrainTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train_with_gin", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train_test._config_generator"], ["  ", "@", "parameterized", ".", "parameters", "(", "list", "(", "_config_generator", "(", ")", ")", ")", "\n", "def", "test_train_model", "(", "self", ",", "gin_configs", ",", "gin_bindings", ")", ":", "\n", "# We clear the gin config before running. Otherwise, if a prior test fails,", "\n", "# the gin config is locked and the current test fails.", "\n", "    ", "gin", ".", "clear_config", "(", ")", "\n", "train", ".", "train_with_gin", "(", "self", ".", "create_tempdir", "(", ")", ".", "full_path", ",", "True", ",", "gin_configs", ",", "\n", "gin_bindings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train_test._config_generator": [[27, 82], ["disentanglement_lib.utils.resources.get_file"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file"], ["def", "_config_generator", "(", ")", ":", "\n", "  ", "\"\"\"Yields all model configurations that should be tested.\"\"\"", "\n", "model_config_path", "=", "resources", ".", "get_file", "(", "\n", "\"config/tests/methods/unsupervised/train_test.gin\"", ")", "\n", "# Test different losses.", "\n", "for", "loss", "in", "[", "\"@bernoulli_loss\"", ",", "\"@l2_loss\"", "]", ":", "\n", "    ", "rec_loss", "=", "[", "\"reconstruction_loss.loss_fn = \"", "+", "loss", "]", "\n", "# Test different activations.", "\n", "for", "act", "in", "[", "\"'logits'\"", ",", "\"'tanh'\"", "]", ":", "\n", "      ", "rec_loss", "+=", "[", "\"reconstruction_loss.activation = \"", "+", "act", "]", "\n", "latent_dim", "=", "[", "\"encoder.num_latent = 10\"", "]", "\n", "# Test different architectures.", "\n", "for", "encoder", ",", "decoder", "in", "[", "(", "\"@fc_encoder\"", ",", "\"@fc_decoder\"", ")", ",", "\n", "(", "\"@conv_encoder\"", ",", "\"@deconv_decoder\"", ")", "]", ":", "\n", "        ", "architectures", "=", "[", "\"encoder.encoder_fn = \"", "+", "encoder", ",", "\n", "\"decoder.decoder_fn = \"", "+", "decoder", "]", "\n", "structure", "=", "rec_loss", "+", "architectures", "+", "latent_dim", "\n", "# Train a BetaVAE with all these settings.", "\n", "beta_vae", "=", "[", "\"model.model = @vae()\"", ",", "\"vae.beta = 10.\"", "]", "\n", "yield", "[", "model_config_path", "]", ",", "beta_vae", "+", "structure", "\n", "\n", "# Test all the other different models.", "\n", "# Test AnnealedVAE.", "\n", "", "", "", "annealed_vae", "=", "[", "\n", "\"model.model = @annealed_vae()\"", ",", "\"annealed_vae.c_max = 25\"", ",", "\n", "\"annealed_vae.iteration_threshold = 100000\"", ",", "\"annealed_vae.gamma = 1000\"", "\n", "]", "\n", "yield", "[", "model_config_path", "]", ",", "annealed_vae", "\n", "\n", "# Test FactorVAE.", "\n", "factor_vae", "=", "[", "\n", "\"model.model = @factor_vae()\"", ",", "\n", "\"discriminator.discriminator_fn = @fc_discriminator\"", ",", "\n", "\"discriminator_optimizer.optimizer_fn = @AdamOptimizer\"", ",", "\n", "\"factor_vae.gamma = 10.\"", "\n", "]", "\n", "yield", "[", "model_config_path", "]", ",", "factor_vae", "\n", "\n", "# Test DIP-VAE.", "\n", "dip_vae_i", "=", "[", "\n", "\"model.model = @dip_vae()\"", ",", "\"dip_vae.lambda_d_factor = 10\"", ",", "\n", "\"dip_vae.dip_type = 'i'\"", ",", "\"dip_vae.lambda_od = 10.\"", "\n", "]", "\n", "yield", "[", "model_config_path", "]", ",", "dip_vae_i", "\n", "\n", "dip_vae_ii", "=", "[", "\n", "\"model.model = @dip_vae()\"", ",", "\"dip_vae.lambda_d_factor = 1\"", ",", "\n", "\"dip_vae.dip_type = 'ii'\"", ",", "\"dip_vae.lambda_od = 10.\"", "\n", "]", "\n", "yield", "[", "model_config_path", "]", ",", "dip_vae_ii", "\n", "\n", "# Test BetaTCVAE.", "\n", "beta_tc_vae", "=", "[", "\"model.model = @beta_tc_vae()\"", ",", "\"beta_tc_vae.beta = 10.\"", "]", "\n", "yield", "[", "model_config_path", "]", ",", "beta_tc_vae", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train_with_gin": [[34, 56], ["gin.parse_config_files_and_bindings", "gin.parse_config_files_and_bindings", "train.train", "gin.clear_config", "gin.clear_config"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train"], ["def", "train_with_gin", "(", "model_dir", ",", "\n", "overwrite", "=", "False", ",", "\n", "gin_config_files", "=", "None", ",", "\n", "gin_bindings", "=", "None", ")", ":", "\n", "  ", "\"\"\"Trains a model based on the provided gin configuration.\n\n  This function will set the provided gin bindings, call the train() function\n  and clear the gin config. Please see train() for required gin bindings.\n\n  Args:\n    model_dir: String with path to directory where model output should be saved.\n    overwrite: Boolean indicating whether to overwrite output directory.\n    gin_config_files: List of gin config files to load.\n    gin_bindings: List of gin bindings to use.\n  \"\"\"", "\n", "if", "gin_config_files", "is", "None", ":", "\n", "    ", "gin_config_files", "=", "[", "]", "\n", "", "if", "gin_bindings", "is", "None", ":", "\n", "    ", "gin_bindings", "=", "[", "]", "\n", "", "gin", ".", "parse_config_files_and_bindings", "(", "gin_config_files", ",", "gin_bindings", ")", "\n", "train", "(", "model_dir", ",", "overwrite", ")", "\n", "gin", ".", "clear_config", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train": [[58, 142], ["gin.configurable", "gin.configurable", "tensorflow.gfile.IsDirectory", "numpy.random.RandomState", "disentanglement_lib.data.ground_truth.named_data.get_named_ground_truth_data", "tensorflow.contrib.tpu.RunConfig", "tensorflow.contrib.tpu.TPUEstimator", "time.time", "contrib_tpu.TPUEstimator.train", "os.path.join", "disentanglement_lib.methods.unsupervised.gaussian_encoder_model.export_as_tf_hub", "contrib_tpu.TPUEstimator.evaluate", "os.path.join", "disentanglement_lib.utils.results.update_result_directory", "disentanglement_lib.data.ground_truth.named_data.get_named_ground_truth_data", "contrib_tpu.TPUEstimator.latest_checkpoint", "time.time", "tensorflow.gfile.DeleteRecursively", "ValueError", "tensorflow.contrib.tpu.TPUConfig", "os.path.join", "train._make_input_fn", "train._make_input_fn", "np.random.RandomState.randint", "np.random.RandomState.randint"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.named_data.get_named_ground_truth_data", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.gaussian_encoder_model.export_as_tf_hub", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.udr.evaluate.evaluate", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.update_result_directory", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.named_data.get_named_ground_truth_data", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train._make_input_fn", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train._make_input_fn"], ["", "@", "gin", ".", "configurable", "(", "\"model\"", ",", "blacklist", "=", "[", "\"model_dir\"", ",", "\"overwrite\"", "]", ")", "\n", "def", "train", "(", "model_dir", ",", "\n", "overwrite", "=", "False", ",", "\n", "model", "=", "gin", ".", "REQUIRED", ",", "\n", "training_steps", "=", "gin", ".", "REQUIRED", ",", "\n", "random_seed", "=", "gin", ".", "REQUIRED", ",", "\n", "batch_size", "=", "gin", ".", "REQUIRED", ",", "\n", "eval_steps", "=", "1000", ",", "\n", "name", "=", "\"\"", ",", "\n", "model_num", "=", "None", ")", ":", "\n", "  ", "\"\"\"Trains the estimator and exports the snapshot and the gin config.\n\n  The use of this function requires the gin binding 'dataset.name' to be\n  specified as that determines the data set used for training.\n\n  Args:\n    model_dir: String with path to directory where model output should be saved.\n    overwrite: Boolean indicating whether to overwrite output directory.\n    model: GaussianEncoderModel that should be trained and exported.\n    training_steps: Integer with number of training steps.\n    random_seed: Integer with random seed used for training.\n    batch_size: Integer with the batch size.\n    eval_steps: Optional integer with number of steps used for evaluation.\n    name: Optional string with name of the model (can be used to name models).\n    model_num: Optional integer with model number (can be used to identify\n      models).\n  \"\"\"", "\n", "# We do not use the variables 'name' and 'model_num'. Instead, they can be", "\n", "# used to name results as they will be part of the saved gin config.", "\n", "del", "name", ",", "model_num", "\n", "\n", "# Delete the output directory if it already exists.", "\n", "if", "tf", ".", "gfile", ".", "IsDirectory", "(", "model_dir", ")", ":", "\n", "    ", "if", "overwrite", ":", "\n", "      ", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "model_dir", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"Directory already exists and overwrite is False.\"", ")", "\n", "\n", "# Create a numpy random state. We will sample the random seeds for training", "\n", "# and evaluation from this.", "\n", "", "", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "random_seed", ")", "\n", "\n", "# Obtain the dataset.", "\n", "dataset", "=", "named_data", ".", "get_named_ground_truth_data", "(", ")", "\n", "\n", "# We create a TPUEstimator based on the provided model. This is primarily so", "\n", "# that we could switch to TPU training in the future. For now, we train", "\n", "# locally on GPUs.", "\n", "run_config", "=", "contrib_tpu", ".", "RunConfig", "(", "\n", "tf_random_seed", "=", "random_seed", ",", "\n", "keep_checkpoint_max", "=", "1", ",", "\n", "tpu_config", "=", "contrib_tpu", ".", "TPUConfig", "(", "iterations_per_loop", "=", "500", ")", ")", "\n", "tpu_estimator", "=", "contrib_tpu", ".", "TPUEstimator", "(", "\n", "use_tpu", "=", "False", ",", "\n", "model_fn", "=", "model", ".", "model_fn", ",", "\n", "model_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"tf_checkpoint\"", ")", ",", "\n", "train_batch_size", "=", "batch_size", ",", "\n", "eval_batch_size", "=", "batch_size", ",", "\n", "config", "=", "run_config", ")", "\n", "\n", "# Set up time to keep track of elapsed time in results.", "\n", "experiment_timer", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Do the actual training.", "\n", "tpu_estimator", ".", "train", "(", "\n", "input_fn", "=", "_make_input_fn", "(", "dataset", ",", "random_state", ".", "randint", "(", "2", "**", "32", ")", ")", ",", "\n", "steps", "=", "training_steps", ")", "\n", "\n", "# Save model as a TFHub module.", "\n", "output_shape", "=", "named_data", ".", "get_named_ground_truth_data", "(", ")", ".", "observation_shape", "\n", "module_export_path", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"tfhub\"", ")", "\n", "gaussian_encoder_model", ".", "export_as_tf_hub", "(", "model", ",", "output_shape", ",", "\n", "tpu_estimator", ".", "latest_checkpoint", "(", ")", ",", "\n", "module_export_path", ")", "\n", "\n", "# Save the results. The result dir will contain all the results and config", "\n", "# files that we copied along, as we progress in the pipeline. The idea is that", "\n", "# these files will be available for analysis at the end.", "\n", "results_dict", "=", "tpu_estimator", ".", "evaluate", "(", "\n", "input_fn", "=", "_make_input_fn", "(", "\n", "dataset", ",", "random_state", ".", "randint", "(", "2", "**", "32", ")", ",", "num_batches", "=", "eval_steps", ")", ")", "\n", "results_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"results\"", ")", "\n", "results_dict", "[", "\"elapsed_time\"", "]", "=", "time", ".", "time", "(", ")", "-", "experiment_timer", "\n", "results", ".", "update_result_directory", "(", "results_dir", ",", "\"train\"", ",", "results_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train._make_input_fn": [[144, 159], ["disentanglement_lib.data.ground_truth.util.tf_data_set_from_ground_truth_data", "dataset.take.batch", "dataset.take.make_one_shot_iterator().get_next", "dataset.take.take", "dataset.take.make_one_shot_iterator"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.util.tf_data_set_from_ground_truth_data"], ["", "def", "_make_input_fn", "(", "ground_truth_data", ",", "seed", ",", "num_batches", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates an input function for the experiments.\"\"\"", "\n", "\n", "def", "load_dataset", "(", "params", ")", ":", "\n", "    ", "\"\"\"TPUEstimator compatible input fuction.\"\"\"", "\n", "dataset", "=", "util", ".", "tf_data_set_from_ground_truth_data", "(", "ground_truth_data", ",", "seed", ")", "\n", "batch_size", "=", "params", "[", "\"batch_size\"", "]", "\n", "# We need to drop the remainder as otherwise we lose the batch size in the", "\n", "# tensor shape. This has no effect as our data set is infinite.", "\n", "dataset", "=", "dataset", ".", "batch", "(", "batch_size", ",", "drop_remainder", "=", "True", ")", "\n", "if", "num_batches", "is", "not", "None", ":", "\n", "      ", "dataset", "=", "dataset", ".", "take", "(", "num_batches", ")", "\n", "", "return", "dataset", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "\n", "", "return", "load_dataset", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae_test.VaeTest.test_compute_gaussian_kl": [[33, 42], ["absl.testing.parameterized.parameters", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "vae_test.VaeTest.test_session", "sess.run", "vae_test.VaeTest.assertBetween", "numpy.zeros", "numpy.zeros", "numpy.ones", "numpy.zeros", "numpy.ones", "numpy.ones", "disentanglement_lib.methods.unsupervised.vae.compute_gaussian_kl"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.compute_gaussian_kl"], ["  ", "@", "parameterized", ".", "parameters", "(", "(", "np", ".", "zeros", "(", "[", "10", ",", "10", "]", ")", ",", "np", ".", "zeros", "(", "[", "10", ",", "10", "]", ")", ",", "0.", ",", "0.01", ")", ",", "\n", "(", "np", ".", "ones", "(", "[", "10", ",", "10", "]", ")", ",", "np", ".", "zeros", "(", "[", "10", ",", "10", "]", ")", ",", "5.", ",", "5.01", ")", ",", "\n", "(", "np", ".", "ones", "(", "[", "10", ",", "10", "]", ")", ",", "np", ".", "ones", "(", "[", "10", ",", "10", "]", ")", ",", "8.58", ",", "8.6", ")", ")", "\n", "def", "test_compute_gaussian_kl", "(", "self", ",", "mean", ",", "logvar", ",", "target_low", ",", "target_high", ")", ":", "\n", "    ", "mean_tf", "=", "tf", ".", "convert_to_tensor", "(", "mean", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "logvar_tf", "=", "tf", ".", "convert_to_tensor", "(", "logvar", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "test_value", "=", "sess", ".", "run", "(", "vae", ".", "compute_gaussian_kl", "(", "mean_tf", ",", "logvar_tf", ")", ")", "\n", "self", ".", "assertBetween", "(", "test_value", ",", "target_low", ",", "target_high", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae_test.VaeTest.test_anneal": [[43, 51], ["absl.testing.parameterized.parameters", "vae_test.VaeTest.test_session", "sess.run", "vae_test.VaeTest.assertBetween", "disentanglement_lib.methods.unsupervised.vae.anneal"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.anneal"], ["", "", "@", "parameterized", ".", "parameters", "(", "(", "0", ",", "0.", ",", "0.01", ")", ",", "(", "10", ",", "10.", ",", "10.01", ")", ",", "\n", "(", "100", ",", "100.", ",", "100.01", ")", ",", "(", "101", ",", "100.", ",", "100.01", ")", ")", "\n", "def", "test_anneal", "(", "self", ",", "step", ",", "target_low", ",", "target_high", ")", ":", "\n", "    ", "c_max", "=", "100.", "\n", "iteration_threshold", "=", "100", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "test_value", "=", "sess", ".", "run", "(", "vae", ".", "anneal", "(", "c_max", ",", "step", ",", "iteration_threshold", ")", ")", "\n", "self", ".", "assertBetween", "(", "test_value", ",", "target_low", ",", "target_high", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae_test.VaeTest.test_compute_covariance_z_mean": [[52, 67], ["absl.testing.parameterized.parameters", "tensorflow.random.normal", "tensorflow.constant", "vae_test.VaeTest.test_session", "sess.run", "vae_test.VaeTest.assertBetween", "numpy.zeros", "numpy.ones", "numpy.zeros", "vae_test._make_symmetric_psd", "numpy.diag", "numpy.random.multivariate_normal", "disentanglement_lib.methods.unsupervised.vae.compute_covariance_z_mean", "numpy.sum", "numpy.random.random", "tensorflow.math.sqrt", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae_test._make_symmetric_psd", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.compute_covariance_z_mean"], ["", "", "@", "parameterized", ".", "parameters", "(", "\n", "(", "True", ",", "0.", ",", "1.", ")", ",", "(", "True", ",", "0.", ",", "4.", ")", ",", "(", "True", ",", "1.", ",", "1.", ")", ",", "\n", "(", "False", ",", "np", ".", "zeros", "(", "10", ")", ",", "np", ".", "ones", "(", "[", "10", ",", "10", "]", ")", ")", ",", "\n", "(", "False", ",", "np", ".", "zeros", "(", "10", ")", ",", "_make_symmetric_psd", "(", "np", ".", "random", ".", "random", "(", "(", "10", ",", "10", ")", ")", ")", ")", ")", "\n", "def", "test_compute_covariance_z_mean", "(", "self", ",", "diagonal", ",", "mean", ",", "cov", ")", ":", "\n", "    ", "if", "diagonal", ":", "\n", "      ", "samples", "=", "tf", ".", "random", ".", "normal", "(", "\n", "shape", "=", "(", "100000", ",", "10", ")", ",", "mean", "=", "mean", ",", "stddev", "=", "tf", ".", "math", ".", "sqrt", "(", "cov", ")", ")", "\n", "cov", "=", "np", ".", "diag", "(", "np", ".", "ones", "(", "[", "10", "]", ")", ")", "*", "cov", "\n", "", "else", ":", "\n", "      ", "samples", "=", "tf", ".", "constant", "(", "\n", "np", ".", "random", ".", "multivariate_normal", "(", "mean", ",", "cov", ",", "size", "=", "(", "1000000", ")", ")", ")", "\n", "", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "test_value", "=", "sess", ".", "run", "(", "vae", ".", "compute_covariance_z_mean", "(", "samples", ")", ")", "\n", "self", ".", "assertBetween", "(", "np", ".", "sum", "(", "(", "test_value", "-", "cov", ")", "**", "2", ")", ",", "0.", ",", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae_test.VaeTest.test_regularize_diag_off_diag_dip": [[68, 76], ["absl.testing.parameterized.parameters", "tensorflow.convert_to_tensor", "vae_test.VaeTest.test_session", "sess.run", "vae_test.VaeTest.assertBetween", "numpy.ones", "numpy.zeros", "numpy.diag", "disentanglement_lib.methods.unsupervised.vae.regularize_diag_off_diag_dip", "numpy.ones", "numpy.diag", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.regularize_diag_off_diag_dip"], ["", "", "@", "parameterized", ".", "parameters", "(", "\n", "(", "np", ".", "ones", "(", "[", "10", ",", "10", "]", ")", ",", "90.", ",", "90.1", ")", ",", "(", "np", ".", "zeros", "(", "[", "10", ",", "10", "]", ")", ",", "10.", ",", "10.1", ")", ",", "\n", "(", "np", ".", "diag", "(", "np", ".", "ones", "(", "10", ")", ")", ",", "0.", ",", "0.1", ")", ",", "(", "2.", "*", "np", ".", "diag", "(", "np", ".", "ones", "(", "10", ")", ")", ",", "10.", ",", "10.1", ")", ")", "\n", "def", "test_regularize_diag_off_diag_dip", "(", "self", ",", "matrix", ",", "target_low", ",", "target_high", ")", ":", "\n", "    ", "matrix_tf", "=", "tf", ".", "convert_to_tensor", "(", "matrix", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "test_value", "=", "sess", ".", "run", "(", "vae", ".", "regularize_diag_off_diag_dip", "(", "matrix_tf", ",", "1", ",", "1", ")", ")", "\n", "self", ".", "assertBetween", "(", "test_value", ",", "target_low", ",", "target_high", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae_test.VaeTest.test_gaussian_log_density": [[77, 83], ["absl.testing.parameterized.parameters", "tensorflow.ones", "vae_test.VaeTest.test_session", "vae_test.VaeTest.assertBetween", "sess.run", "disentanglement_lib.methods.unsupervised.vae.gaussian_log_density"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.gaussian_log_density"], ["", "", "@", "parameterized", ".", "parameters", "(", "(", "0.", ",", "-", "1.4190", ",", "-", "1.4188", ")", ",", "(", "1.", ",", "-", "0.92", ",", "-", "0.91", ")", ")", "\n", "def", "test_gaussian_log_density", "(", "self", ",", "z_mean", ",", "target_low", ",", "target_high", ")", ":", "\n", "    ", "matrix", "=", "tf", ".", "ones", "(", "1", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "test_value", "=", "sess", ".", "run", "(", "vae", ".", "gaussian_log_density", "(", "matrix", ",", "z_mean", ",", "0.", ")", ")", "[", "0", "]", "\n", "self", ".", "assertBetween", "(", "test_value", ",", "target_low", ",", "target_high", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae_test.VaeTest.test_total_correlation": [[84, 94], ["absl.testing.parameterized.parameters", "tensorflow.random.normal", "tensorflow.zeros", "tensorflow.zeros", "vae_test.VaeTest.test_session", "sess.run", "vae_test.VaeTest.assertBetween", "disentanglement_lib.methods.unsupervised.vae.total_correlation"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.total_correlation"], ["", "", "@", "parameterized", ".", "parameters", "(", "\n", "(", "1", ",", "0.", ",", "0.1", ")", ",", "(", "10", ",", "-", "82.9", ",", "-", "82.89", ")", ")", "# -82.893 = (10 - 1) * ln(10000)", "\n", "def", "test_total_correlation", "(", "self", ",", "num_dim", ",", "target_low", ",", "target_high", ")", ":", "\n", "# Since there is no dataset, the constant should be (num_latent - 1)*log(N)", "\n", "    ", "z", "=", "tf", ".", "random", ".", "normal", "(", "shape", "=", "(", "10000", ",", "num_dim", ")", ")", "\n", "z_mean", "=", "tf", ".", "zeros", "(", "shape", "=", "(", "10000", ",", "num_dim", ")", ")", "\n", "z_logvar", "=", "tf", ".", "zeros", "(", "shape", "=", "(", "10000", ",", "num_dim", ")", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "test_value", "=", "sess", ".", "run", "(", "vae", ".", "total_correlation", "(", "z", ",", "z_mean", ",", "z_logvar", ")", ")", "\n", "self", ".", "assertBetween", "(", "test_value", ",", "target_low", ",", "target_high", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae_test._make_symmetric_psd": [[27, 29], ["numpy.diag", "numpy.ones"], "function", ["None"], ["def", "_make_symmetric_psd", "(", "matrix", ")", ":", "\n", "  ", "return", "0.5", "*", "(", "matrix", "+", "matrix", ".", "T", ")", "+", "np", ".", "diag", "(", "np", ".", "ones", "(", "10", ")", ")", "*", "10.", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.model_fn": [[39, 82], ["vae.BaseVAE.gaussian_encoder", "vae.BaseVAE.sample_from_latent_distribution", "vae.BaseVAE.decode", "disentanglement_lib.methods.shared.losses.make_reconstruction_loss", "tensorflow.reduce_mean", "vae.compute_gaussian_kl", "vae.BaseVAE.regularizer", "tensorflow.add", "tensorflow.add", "features.get_shape().as_list", "disentanglement_lib.methods.shared.optimizers.make_vae_optimizer", "tensorflow.get_collection", "disentanglement_lib.methods.shared.optimizers.make_vae_optimizer.minimize", "tensorflow.group", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.train.LoggingTensorHook", "tensorflow.contrib.tpu.TPUEstimatorSpec", "tensorflow.contrib.tpu.TPUEstimatorSpec", "NotImplementedError", "features.get_shape", "tensorflow.train.get_global_step", "vae.make_metric_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.gaussian_encoder", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.gaussian_encoder_model.GaussianEncoderModel.sample_from_latent_distribution", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.decode", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.losses.make_reconstruction_loss", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.compute_gaussian_kl", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.regularizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.optimizers.make_vae_optimizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.make_metric_fn"], ["def", "model_fn", "(", "self", ",", "features", ",", "labels", ",", "mode", ",", "params", ")", ":", "\n", "    ", "\"\"\"TPUEstimator compatible model function.\"\"\"", "\n", "del", "labels", "\n", "is_training", "=", "(", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", "\n", "data_shape", "=", "features", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "z_mean", ",", "z_logvar", "=", "self", ".", "gaussian_encoder", "(", "features", ",", "is_training", "=", "is_training", ")", "\n", "z_sampled", "=", "self", ".", "sample_from_latent_distribution", "(", "z_mean", ",", "z_logvar", ")", "\n", "reconstructions", "=", "self", ".", "decode", "(", "z_sampled", ",", "data_shape", ",", "is_training", ")", "\n", "per_sample_loss", "=", "losses", ".", "make_reconstruction_loss", "(", "features", ",", "reconstructions", ")", "\n", "reconstruction_loss", "=", "tf", ".", "reduce_mean", "(", "per_sample_loss", ")", "\n", "kl_loss", "=", "compute_gaussian_kl", "(", "z_mean", ",", "z_logvar", ")", "\n", "regularizer", "=", "self", ".", "regularizer", "(", "kl_loss", ",", "z_mean", ",", "z_logvar", ",", "z_sampled", ")", "\n", "loss", "=", "tf", ".", "add", "(", "reconstruction_loss", ",", "regularizer", ",", "name", "=", "\"loss\"", ")", "\n", "elbo", "=", "tf", ".", "add", "(", "reconstruction_loss", ",", "kl_loss", ",", "name", "=", "\"elbo\"", ")", "\n", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ":", "\n", "      ", "optimizer", "=", "optimizers", ".", "make_vae_optimizer", "(", ")", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "train_op", "=", "optimizer", ".", "minimize", "(", "\n", "loss", "=", "loss", ",", "global_step", "=", "tf", ".", "train", ".", "get_global_step", "(", ")", ")", "\n", "train_op", "=", "tf", ".", "group", "(", "[", "train_op", ",", "update_ops", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"reconstruction_loss\"", ",", "reconstruction_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"elbo\"", ",", "-", "elbo", ")", "\n", "\n", "logging_hook", "=", "tf", ".", "train", ".", "LoggingTensorHook", "(", "{", "\n", "\"loss\"", ":", "loss", ",", "\n", "\"reconstruction_loss\"", ":", "reconstruction_loss", ",", "\n", "\"elbo\"", ":", "-", "elbo", "\n", "}", ",", "\n", "every_n_iter", "=", "100", ")", "\n", "return", "contrib_tpu", ".", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "loss", "=", "loss", ",", "\n", "train_op", "=", "train_op", ",", "\n", "training_hooks", "=", "[", "logging_hook", "]", ")", "\n", "", "elif", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ":", "\n", "      ", "return", "contrib_tpu", ".", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "loss", "=", "loss", ",", "\n", "eval_metrics", "=", "(", "make_metric_fn", "(", "\"reconstruction_loss\"", ",", "\"elbo\"", ",", "\n", "\"regularizer\"", ",", "\"kl_loss\"", ")", ",", "\n", "[", "reconstruction_loss", ",", "-", "elbo", ",", "regularizer", ",", "kl_loss", "]", ")", ")", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "(", "\"Eval mode not supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.gaussian_encoder": [[83, 95], ["disentanglement_lib.methods.shared.architectures.make_gaussian_encoder"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.architectures.make_gaussian_encoder"], ["", "", "def", "gaussian_encoder", "(", "self", ",", "input_tensor", ",", "is_training", ")", ":", "\n", "    ", "\"\"\"Applies the Gaussian encoder to images.\n\n    Args:\n      input_tensor: Tensor with the observations to be encoded.\n      is_training: Boolean indicating whether in training mode.\n\n    Returns:\n      Tuple of tensors with the mean and log variance of the Gaussian encoder.\n    \"\"\"", "\n", "return", "architectures", ".", "make_gaussian_encoder", "(", "\n", "input_tensor", ",", "is_training", "=", "is_training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.decode": [[96, 100], ["disentanglement_lib.methods.shared.architectures.make_decoder"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.architectures.make_decoder"], ["", "def", "decode", "(", "self", ",", "latent_tensor", ",", "observation_shape", ",", "is_training", ")", ":", "\n", "    ", "\"\"\"Decodes the latent_tensor to an observation.\"\"\"", "\n", "return", "architectures", ".", "make_decoder", "(", "\n", "latent_tensor", ",", "observation_shape", ",", "is_training", "=", "is_training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BetaVAE.__init__": [[139, 153], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "beta", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "    ", "\"\"\"Creates a beta-VAE model.\n\n    Implementing Eq. 4 of \"beta-VAE: Learning Basic Visual Concepts with a\n    Constrained Variational Framework\"\n    (https://openreview.net/forum?id=Sy2fzU9gl).\n\n    Args:\n      beta: Hyperparameter for the regularizer.\n\n    Returns:\n      model_fn: Model function for TPUEstimator.\n    \"\"\"", "\n", "self", ".", "beta", "=", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BetaVAE.regularizer": [[154, 157], ["None"], "methods", ["None"], ["", "def", "regularizer", "(", "self", ",", "kl_loss", ",", "z_mean", ",", "z_logvar", ",", "z_sampled", ")", ":", "\n", "    ", "del", "z_mean", ",", "z_logvar", ",", "z_sampled", "\n", "return", "self", ".", "beta", "*", "kl_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.AnnealedVAE.__init__": [[178, 195], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "gamma", "=", "gin", ".", "REQUIRED", ",", "\n", "c_max", "=", "gin", ".", "REQUIRED", ",", "\n", "iteration_threshold", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "    ", "\"\"\"Creates an AnnealedVAE model.\n\n    Implementing Eq. 8 of \"Understanding disentangling in beta-VAE\"\n    (https://arxiv.org/abs/1804.03599).\n\n    Args:\n      gamma: Hyperparameter for the regularizer.\n      c_max: Maximum capacity of the bottleneck.\n      iteration_threshold: How many iterations to reach c_max.\n    \"\"\"", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "c_max", "=", "c_max", "\n", "self", ".", "iteration_threshold", "=", "iteration_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.AnnealedVAE.regularizer": [[196, 200], ["vae.anneal", "tensorflow.train.get_global_step", "tensorflow.math.abs"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.anneal"], ["", "def", "regularizer", "(", "self", ",", "kl_loss", ",", "z_mean", ",", "z_logvar", ",", "z_sampled", ")", ":", "\n", "    ", "del", "z_mean", ",", "z_logvar", ",", "z_sampled", "\n", "c", "=", "anneal", "(", "self", ".", "c_max", ",", "tf", ".", "train", ".", "get_global_step", "(", ")", ",", "self", ".", "iteration_threshold", ")", "\n", "return", "self", ".", "gamma", "*", "tf", ".", "math", ".", "abs", "(", "kl_loss", "-", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.FactorVAE.__init__": [[206, 216], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "gamma", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "    ", "\"\"\"Creates a FactorVAE model.\n\n    Implementing Eq. 2 of \"Disentangling by Factorizing\"\n    (https://arxiv.org/pdf/1802.05983).\n\n    Args:\n      gamma: Hyperparameter for the regularizer.\n    \"\"\"", "\n", "self", ".", "gamma", "=", "gamma", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.FactorVAE.model_fn": [[217, 284], ["vae.FactorVAE.gaussian_encoder", "vae.FactorVAE.sample_from_latent_distribution", "vae.shuffle_codes", "vae.FactorVAE.decode", "disentanglement_lib.methods.shared.losses.make_reconstruction_loss", "tensorflow.reduce_mean", "vae.compute_gaussian_kl", "tensorflow.add", "tensorflow.reduce_mean", "tensorflow.add", "tensorflow.add", "features.get_shape().as_list", "tensorflow.variable_scope", "disentanglement_lib.methods.shared.architectures.make_discriminator", "disentanglement_lib.methods.shared.architectures.make_discriminator", "disentanglement_lib.methods.shared.optimizers.make_vae_optimizer", "disentanglement_lib.methods.shared.optimizers.make_discriminator_optimizer", "tensorflow.trainable_variables", "tensorflow.get_collection", "disentanglement_lib.methods.shared.optimizers.make_vae_optimizer.minimize", "disentanglement_lib.methods.shared.optimizers.make_discriminator_optimizer.minimize", "tensorflow.group", "tensorflow.summary.scalar", "tensorflow.train.LoggingTensorHook", "tensorflow.contrib.tpu.TPUEstimatorSpec", "tensorflow.get_variable_scope", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.contrib.tpu.TPUEstimatorSpec", "NotImplementedError", "features.get_shape", "tensorflow.log", "tensorflow.log", "tensorflow.train.get_global_step", "tensorflow.train.get_global_step", "vae.make_metric_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.gaussian_encoder", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.gaussian_encoder_model.GaussianEncoderModel.sample_from_latent_distribution", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.shuffle_codes", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BaseVAE.decode", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.losses.make_reconstruction_loss", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.compute_gaussian_kl", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.architectures.make_discriminator", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.architectures.make_discriminator", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.optimizers.make_vae_optimizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.shared.optimizers.make_discriminator_optimizer", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.make_metric_fn"], ["", "def", "model_fn", "(", "self", ",", "features", ",", "labels", ",", "mode", ",", "params", ")", ":", "\n", "    ", "\"\"\"TPUEstimator compatible model function.\"\"\"", "\n", "del", "labels", "\n", "is_training", "=", "(", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", "\n", "data_shape", "=", "features", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "z_mean", ",", "z_logvar", "=", "self", ".", "gaussian_encoder", "(", "features", ",", "is_training", "=", "is_training", ")", "\n", "z_sampled", "=", "self", ".", "sample_from_latent_distribution", "(", "z_mean", ",", "z_logvar", ")", "\n", "z_shuffle", "=", "shuffle_codes", "(", "z_sampled", ")", "\n", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "      ", "logits_z", ",", "probs_z", "=", "architectures", ".", "make_discriminator", "(", "\n", "z_sampled", ",", "is_training", "=", "is_training", ")", "\n", "_", ",", "probs_z_shuffle", "=", "architectures", ".", "make_discriminator", "(", "\n", "z_shuffle", ",", "is_training", "=", "is_training", ")", "\n", "", "reconstructions", "=", "self", ".", "decode", "(", "z_sampled", ",", "data_shape", ",", "is_training", ")", "\n", "per_sample_loss", "=", "losses", ".", "make_reconstruction_loss", "(", "\n", "features", ",", "reconstructions", ")", "\n", "reconstruction_loss", "=", "tf", ".", "reduce_mean", "(", "per_sample_loss", ")", "\n", "kl_loss", "=", "compute_gaussian_kl", "(", "z_mean", ",", "z_logvar", ")", "\n", "standard_vae_loss", "=", "tf", ".", "add", "(", "reconstruction_loss", ",", "kl_loss", ",", "name", "=", "\"VAE_loss\"", ")", "\n", "# tc = E[log(p_real)-log(p_fake)] = E[logit_real - logit_fake]", "\n", "tc_loss_per_sample", "=", "logits_z", "[", ":", ",", "0", "]", "-", "logits_z", "[", ":", ",", "1", "]", "\n", "tc_loss", "=", "tf", ".", "reduce_mean", "(", "tc_loss_per_sample", ",", "axis", "=", "0", ")", "\n", "regularizer", "=", "kl_loss", "+", "self", ".", "gamma", "*", "tc_loss", "\n", "factor_vae_loss", "=", "tf", ".", "add", "(", "\n", "standard_vae_loss", ",", "self", ".", "gamma", "*", "tc_loss", ",", "name", "=", "\"factor_VAE_loss\"", ")", "\n", "discr_loss", "=", "tf", ".", "add", "(", "\n", "0.5", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "log", "(", "probs_z", "[", ":", ",", "0", "]", ")", ")", ",", "\n", "0.5", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "log", "(", "probs_z_shuffle", "[", ":", ",", "1", "]", ")", ")", ",", "\n", "name", "=", "\"discriminator_loss\"", ")", "\n", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ":", "\n", "      ", "optimizer_vae", "=", "optimizers", ".", "make_vae_optimizer", "(", ")", "\n", "optimizer_discriminator", "=", "optimizers", ".", "make_discriminator_optimizer", "(", ")", "\n", "all_variables", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "encoder_vars", "=", "[", "var", "for", "var", "in", "all_variables", "if", "\"encoder\"", "in", "var", ".", "name", "]", "\n", "decoder_vars", "=", "[", "var", "for", "var", "in", "all_variables", "if", "\"decoder\"", "in", "var", ".", "name", "]", "\n", "discriminator_vars", "=", "[", "var", "for", "var", "in", "all_variables", "if", "\"discriminator\"", "in", "var", ".", "name", "]", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "train_op_vae", "=", "optimizer_vae", ".", "minimize", "(", "\n", "loss", "=", "factor_vae_loss", ",", "\n", "global_step", "=", "tf", ".", "train", ".", "get_global_step", "(", ")", ",", "\n", "var_list", "=", "encoder_vars", "+", "decoder_vars", ")", "\n", "train_op_discr", "=", "optimizer_discriminator", ".", "minimize", "(", "\n", "loss", "=", "-", "discr_loss", ",", "\n", "global_step", "=", "tf", ".", "train", ".", "get_global_step", "(", ")", ",", "\n", "var_list", "=", "discriminator_vars", ")", "\n", "train_op", "=", "tf", ".", "group", "(", "train_op_vae", ",", "train_op_discr", ",", "update_ops", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"reconstruction_loss\"", ",", "reconstruction_loss", ")", "\n", "logging_hook", "=", "tf", ".", "train", ".", "LoggingTensorHook", "(", "{", "\n", "\"loss\"", ":", "factor_vae_loss", ",", "\n", "\"reconstruction_loss\"", ":", "reconstruction_loss", "\n", "}", ",", "\n", "every_n_iter", "=", "50", ")", "\n", "return", "contrib_tpu", ".", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "loss", "=", "factor_vae_loss", ",", "\n", "train_op", "=", "train_op", ",", "\n", "training_hooks", "=", "[", "logging_hook", "]", ")", "\n", "", "elif", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ":", "\n", "      ", "return", "contrib_tpu", ".", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "loss", "=", "factor_vae_loss", ",", "\n", "eval_metrics", "=", "(", "make_metric_fn", "(", "\"reconstruction_loss\"", ",", "\"regularizer\"", ",", "\n", "\"kl_loss\"", ")", ",", "\n", "[", "reconstruction_loss", ",", "regularizer", ",", "kl_loss", "]", ")", ")", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "(", "\"Eval mode not supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.DIPVAE.__init__": [[335, 354], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "lambda_od", "=", "gin", ".", "REQUIRED", ",", "\n", "lambda_d_factor", "=", "gin", ".", "REQUIRED", ",", "\n", "dip_type", "=", "\"i\"", ")", ":", "\n", "    ", "\"\"\"Creates a DIP-VAE model.\n\n    Based on Equation 6 and 7 of \"Variational Inference of Disentangled Latent\n    Concepts from Unlabeled Observations\"\n    (https://openreview.net/pdf?id=H1kG7GZAW).\n\n    Args:\n      lambda_od: Hyperparameter for off diagonal values of covariance matrix.\n      lambda_d_factor: Hyperparameter for diagonal values of covariance matrix\n        lambda_d = lambda_d_factor*lambda_od.\n      dip_type: \"i\" or \"ii\".\n    \"\"\"", "\n", "self", ".", "lambda_od", "=", "lambda_od", "\n", "self", ".", "lambda_d_factor", "=", "lambda_d_factor", "\n", "self", ".", "dip_type", "=", "dip_type", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.DIPVAE.regularizer": [[355, 372], ["vae.compute_covariance_z_mean", "vae.regularize_diag_off_diag_dip", "tensorflow.matrix_diag", "tensorflow.reduce_mean", "vae.regularize_diag_off_diag_dip", "NotImplementedError", "tensorflow.exp"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.compute_covariance_z_mean", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.regularize_diag_off_diag_dip", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.regularize_diag_off_diag_dip"], ["", "def", "regularizer", "(", "self", ",", "kl_loss", ",", "z_mean", ",", "z_logvar", ",", "z_sampled", ")", ":", "\n", "    ", "cov_z_mean", "=", "compute_covariance_z_mean", "(", "z_mean", ")", "\n", "lambda_d", "=", "self", ".", "lambda_d_factor", "*", "self", ".", "lambda_od", "\n", "if", "self", ".", "dip_type", "==", "\"i\"", ":", "# Eq 6 page 4", "\n", "# mu = z_mean is [batch_size, num_latent]", "\n", "# Compute cov_p(x) [mu(x)] = E[mu*mu^T] - E[mu]E[mu]^T]", "\n", "      ", "cov_dip_regularizer", "=", "regularize_diag_off_diag_dip", "(", "\n", "cov_z_mean", ",", "self", ".", "lambda_od", ",", "lambda_d", ")", "\n", "", "elif", "self", ".", "dip_type", "==", "\"ii\"", ":", "\n", "      ", "cov_enc", "=", "tf", ".", "matrix_diag", "(", "tf", ".", "exp", "(", "z_logvar", ")", ")", "\n", "expectation_cov_enc", "=", "tf", ".", "reduce_mean", "(", "cov_enc", ",", "axis", "=", "0", ")", "\n", "cov_z", "=", "expectation_cov_enc", "+", "cov_z_mean", "\n", "cov_dip_regularizer", "=", "regularize_diag_off_diag_dip", "(", "\n", "cov_z", ",", "self", ".", "lambda_od", ",", "lambda_d", ")", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "(", "\"DIP variant not supported.\"", ")", "\n", "", "return", "kl_loss", "+", "cov_dip_regularizer", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BetaTCVAE.__init__": [[424, 436], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "beta", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "    ", "\"\"\"Creates a beta-TC-VAE model.\n\n    Based on Equation 4 with alpha = gamma = 1 of \"Isolating Sources of\n    Disentanglement in Variational Autoencoders\"\n    (https://arxiv.org/pdf/1802.04942).\n    If alpha = gamma = 1, Eq. 4 can be written as ELBO + (1 - beta) * TC.\n\n    Args:\n      beta: Hyperparameter total correlation.\n    \"\"\"", "\n", "self", ".", "beta", "=", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.BetaTCVAE.regularizer": [[437, 440], ["vae.total_correlation"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.total_correlation"], ["", "def", "regularizer", "(", "self", ",", "kl_loss", ",", "z_mean", ",", "z_logvar", ",", "z_sampled", ")", ":", "\n", "    ", "tc", "=", "(", "self", ".", "beta", "-", "1.", ")", "*", "total_correlation", "(", "z_sampled", ",", "z_mean", ",", "z_logvar", ")", "\n", "return", "tc", "+", "kl_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.shuffle_codes": [[102, 116], ["six.moves.range", "tensorflow.stack", "z_shuffle.append", "z.get_shape", "tensorflow.random_shuffle"], "function", ["None"], ["", "", "def", "shuffle_codes", "(", "z", ")", ":", "\n", "  ", "\"\"\"Shuffles latent variables across the batch.\n\n  Args:\n    z: [batch_size, num_latent] representation.\n\n  Returns:\n    shuffled: [batch_size, num_latent] shuffled representation across the batch.\n  \"\"\"", "\n", "z_shuffle", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "z", ".", "get_shape", "(", ")", "[", "1", "]", ")", ":", "\n", "    ", "z_shuffle", ".", "append", "(", "tf", ".", "random_shuffle", "(", "z", "[", ":", ",", "i", "]", ")", ")", "\n", "", "shuffled", "=", "tf", ".", "stack", "(", "z_shuffle", ",", "1", ",", "name", "=", "\"latent_shuffled\"", ")", "\n", "return", "shuffled", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.compute_gaussian_kl": [[118, 124], ["tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.square", "tensorflow.exp"], "function", ["None"], ["", "def", "compute_gaussian_kl", "(", "z_mean", ",", "z_logvar", ")", ":", "\n", "  ", "\"\"\"Compute KL divergence between input Gaussian and Standard Normal.\"\"\"", "\n", "return", "tf", ".", "reduce_mean", "(", "\n", "0.5", "*", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "square", "(", "z_mean", ")", "+", "tf", ".", "exp", "(", "z_logvar", ")", "-", "z_logvar", "-", "1", ",", "[", "1", "]", ")", ",", "\n", "name", "=", "\"kl_loss\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.make_metric_fn": [[126, 133], ["tensorflow.metrics.mean", "six.moves.zip"], "function", ["None"], ["", "def", "make_metric_fn", "(", "*", "names", ")", ":", "\n", "  ", "\"\"\"Utility function to report tf.metrics in model functions.\"\"\"", "\n", "\n", "def", "metric_fn", "(", "*", "args", ")", ":", "\n", "    ", "return", "{", "name", ":", "tf", ".", "metrics", ".", "mean", "(", "vec", ")", "for", "name", ",", "vec", "in", "zip", "(", "names", ",", "args", ")", "}", "\n", "\n", "", "return", "metric_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.anneal": [[159, 172], ["tensorflow.math.minimum", "tensorflow.to_float"], "function", ["None"], ["", "", "def", "anneal", "(", "c_max", ",", "step", ",", "iteration_threshold", ")", ":", "\n", "  ", "\"\"\"Anneal function for anneal_vae (https://arxiv.org/abs/1804.03599).\n\n  Args:\n    c_max: Maximum capacity.\n    step: Current step.\n    iteration_threshold: How many iterations to reach c_max.\n\n  Returns:\n    Capacity annealed linearly until c_max.\n  \"\"\"", "\n", "return", "tf", ".", "math", ".", "minimum", "(", "c_max", "*", "1.", ",", "\n", "c_max", "*", "1.", "*", "tf", ".", "to_float", "(", "step", ")", "/", "iteration_threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.compute_covariance_z_mean": [[286, 306], ["tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.subtract", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims"], "function", ["None"], ["", "", "", "def", "compute_covariance_z_mean", "(", "z_mean", ")", ":", "\n", "  ", "\"\"\"Computes the covariance of z_mean.\n\n  Uses cov(z_mean) = E[z_mean*z_mean^T] - E[z_mean]E[z_mean]^T.\n\n  Args:\n    z_mean: Encoder mean, tensor of size [batch_size, num_latent].\n\n  Returns:\n    cov_z_mean: Covariance of encoder mean, tensor of size [num_latent,\n      num_latent].\n  \"\"\"", "\n", "expectation_z_mean_z_mean_t", "=", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "expand_dims", "(", "z_mean", ",", "2", ")", "*", "tf", ".", "expand_dims", "(", "z_mean", ",", "1", ")", ",", "axis", "=", "0", ")", "\n", "expectation_z_mean", "=", "tf", ".", "reduce_mean", "(", "z_mean", ",", "axis", "=", "0", ")", "\n", "cov_z_mean", "=", "tf", ".", "subtract", "(", "\n", "expectation_z_mean_z_mean_t", ",", "\n", "tf", ".", "expand_dims", "(", "expectation_z_mean", ",", "1", ")", "*", "tf", ".", "expand_dims", "(", "\n", "expectation_z_mean", ",", "0", ")", ")", "\n", "return", "cov_z_mean", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.regularize_diag_off_diag_dip": [[308, 329], ["tensorflow.diag_part", "tensorflow.add", "tensorflow.diag", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "function", ["None"], ["", "def", "regularize_diag_off_diag_dip", "(", "covariance_matrix", ",", "lambda_od", ",", "lambda_d", ")", ":", "\n", "  ", "\"\"\"Compute on and off diagonal regularizers for DIP-VAE models.\n\n  Penalize deviations of covariance_matrix from the identity matrix. Uses\n  different weights for the deviations of the diagonal and off diagonal entries.\n\n  Args:\n    covariance_matrix: Tensor of size [num_latent, num_latent] to regularize.\n    lambda_od: Weight of penalty for off diagonal elements.\n    lambda_d: Weight of penalty for diagonal elements.\n\n  Returns:\n    dip_regularizer: Regularized deviation from diagonal of covariance_matrix.\n  \"\"\"", "\n", "covariance_matrix_diagonal", "=", "tf", ".", "diag_part", "(", "covariance_matrix", ")", "\n", "covariance_matrix_off_diagonal", "=", "covariance_matrix", "-", "tf", ".", "diag", "(", "\n", "covariance_matrix_diagonal", ")", "\n", "dip_regularizer", "=", "tf", ".", "add", "(", "\n", "lambda_od", "*", "tf", ".", "reduce_sum", "(", "covariance_matrix_off_diagonal", "**", "2", ")", ",", "\n", "lambda_d", "*", "tf", ".", "reduce_sum", "(", "(", "covariance_matrix_diagonal", "-", "1", ")", "**", "2", ")", ")", "\n", "return", "dip_regularizer", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.gaussian_log_density": [[374, 380], ["tensorflow.constant", "tensorflow.log", "tensorflow.exp"], "function", ["None"], ["", "", "def", "gaussian_log_density", "(", "samples", ",", "mean", ",", "log_var", ")", ":", "\n", "  ", "pi", "=", "tf", ".", "constant", "(", "math", ".", "pi", ")", "\n", "normalization", "=", "tf", ".", "log", "(", "2.", "*", "pi", ")", "\n", "inv_sigma", "=", "tf", ".", "exp", "(", "-", "log_var", ")", "\n", "tmp", "=", "(", "samples", "-", "mean", ")", "\n", "return", "-", "0.5", "*", "(", "tmp", "*", "tmp", "*", "inv_sigma", "+", "log_var", "+", "normalization", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.total_correlation": [[382, 418], ["vae.gaussian_log_density", "tensorflow.reduce_sum", "tensorflow.reduce_logsumexp", "tensorflow.reduce_mean", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.reduce_logsumexp", "tensorflow.reduce_sum"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.vae.gaussian_log_density"], ["", "def", "total_correlation", "(", "z", ",", "z_mean", ",", "z_logvar", ")", ":", "\n", "  ", "\"\"\"Estimate of total correlation on a batch.\n\n  We need to compute the expectation over a batch of: E_j [log(q(z(x_j))) -\n  log(prod_l q(z(x_j)_l))]. We ignore the constants as they do not matter\n  for the minimization. The constant should be equal to (num_latents - 1) *\n  log(batch_size * dataset_size)\n\n  Args:\n    z: [batch_size, num_latents]-tensor with sampled representation.\n    z_mean: [batch_size, num_latents]-tensor with mean of the encoder.\n    z_logvar: [batch_size, num_latents]-tensor with log variance of the encoder.\n\n  Returns:\n    Total correlation estimated on a batch.\n  \"\"\"", "\n", "# Compute log(q(z(x_j)|x_i)) for every sample in the batch, which is a", "\n", "# tensor of size [batch_size, batch_size, num_latents]. In the following", "\n", "# comments, [batch_size, batch_size, num_latents] are indexed by [j, i, l].", "\n", "log_qz_prob", "=", "gaussian_log_density", "(", "\n", "tf", ".", "expand_dims", "(", "z", ",", "1", ")", ",", "tf", ".", "expand_dims", "(", "z_mean", ",", "0", ")", ",", "\n", "tf", ".", "expand_dims", "(", "z_logvar", ",", "0", ")", ")", "\n", "# Compute log prod_l p(z(x_j)_l) = sum_l(log(sum_i(q(z(z_j)_l|x_i)))", "\n", "# + constant) for each sample in the batch, which is a vector of size", "\n", "# [batch_size,].", "\n", "log_qz_product", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "reduce_logsumexp", "(", "log_qz_prob", ",", "axis", "=", "1", ",", "keepdims", "=", "False", ")", ",", "\n", "axis", "=", "1", ",", "\n", "keepdims", "=", "False", ")", "\n", "# Compute log(q(z(x_j))) as log(sum_i(q(z(x_j)|x_i))) + constant =", "\n", "# log(sum_i(prod_l q(z(x_j)_l|x_i))) + constant.", "\n", "log_qz", "=", "tf", ".", "reduce_logsumexp", "(", "\n", "tf", ".", "reduce_sum", "(", "log_qz_prob", ",", "axis", "=", "2", ",", "keepdims", "=", "False", ")", ",", "\n", "axis", "=", "1", ",", "\n", "keepdims", "=", "False", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "log_qz", "-", "log_qz_product", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.validation.validate.validate_with_gin": [[48, 73], ["gin.parse_config_files_and_bindings", "validate.validate", "gin.clear_config"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.validation.validate.validate"], ["def", "validate_with_gin", "(", "model_dir", ",", "\n", "output_dir", ",", "\n", "overwrite", "=", "False", ",", "\n", "gin_config_files", "=", "None", ",", "\n", "gin_bindings", "=", "None", ")", ":", "\n", "  ", "\"\"\"Validate a representation based on the provided gin configuration.\n\n  This function will set the provided gin bindings, call the evaluate()\n  function and clear the gin config. Please see the evaluate() for required\n  gin bindings.\n\n  Args:\n    model_dir: String with path to directory where the representation is saved.\n    output_dir: String with the path where the evaluation should be saved.\n    overwrite: Boolean indicating whether to overwrite output directory.\n    gin_config_files: List of gin config files to load.\n    gin_bindings: List of gin bindings to use.\n  \"\"\"", "\n", "if", "gin_config_files", "is", "None", ":", "\n", "    ", "gin_config_files", "=", "[", "]", "\n", "", "if", "gin_bindings", "is", "None", ":", "\n", "    ", "gin_bindings", "=", "[", "]", "\n", "", "gin", ".", "parse_config_files_and_bindings", "(", "gin_config_files", ",", "gin_bindings", ")", "\n", "validate", "(", "model_dir", ",", "output_dir", ",", "overwrite", ")", "\n", "gin", ".", "clear_config", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.validation.validate.validate": [[75, 144], ["gin.configurable", "tensorflow.gfile.IsDirectory", "time.time", "disentanglement_lib.data.ground_truth.named_data.get_named_ground_truth_data", "disentanglement_lib.methods.semi_supervised.semi_supervised_utils.sample_supervised_data", "os.path.join", "os.path.join", "os.path.join", "disentanglement_lib.utils.results.update_result_directory", "gin.query_parameter", "os.path.join", "disentanglement_lib.utils.results.gin_dict", "tensorflow_hub.eval_function_for_module", "validation_fn", "time.time", "tensorflow.gfile.DeleteRecursively", "ValueError", "gin.unlock_config", "gin.bind_parameter", "f", "numpy.array", "numpy.transpose", "gin_dict[].replace", "dict"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.ground_truth.named_data.get_named_ground_truth_data", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.semi_supervised.semi_supervised_utils.sample_supervised_data", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.update_result_directory", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.results.gin_dict"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"validation\"", ",", "blacklist", "=", "[", "\"model_dir\"", ",", "\"output_dir\"", ",", "\"overwrite\"", "]", ")", "\n", "def", "validate", "(", "model_dir", ",", "\n", "output_dir", ",", "\n", "overwrite", "=", "False", ",", "\n", "validation_fn", "=", "gin", ".", "REQUIRED", ",", "\n", "random_seed", "=", "gin", ".", "REQUIRED", ",", "\n", "num_labelled_samples", "=", "gin", ".", "REQUIRED", ",", "\n", "name", "=", "\"\"", ")", ":", "\n", "  ", "\"\"\"Loads a representation TFHub module and computes disentanglement metrics.\n\n  Args:\n    model_dir: String with path to directory where the representation function\n      is saved.\n    output_dir: String with the path where the results should be saved.\n    overwrite: Boolean indicating whether to overwrite output directory.\n    validation_fn: Function used to validate the representation (see metrics/\n      for examples).\n    random_seed: Integer with random seed used for training.\n    num_labelled_samples: How many labelled samples are available.\n    name: Optional string with name of the metric (can be used to name metrics).\n  \"\"\"", "\n", "# We do not use the variable 'name'. Instead, it can be used to name scores", "\n", "# as it will be part of the saved gin config.", "\n", "del", "name", "\n", "\n", "# Delete the output directory if it already exists.", "\n", "if", "tf", ".", "gfile", ".", "IsDirectory", "(", "output_dir", ")", ":", "\n", "    ", "if", "overwrite", ":", "\n", "      ", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "output_dir", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"Directory already exists and overwrite is False.\"", ")", "\n", "\n", "# Set up time to keep track of elapsed time in results.", "\n", "", "", "experiment_timer", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Automatically set the proper data set if necessary. We replace the active", "\n", "# gin config as this will lead to a valid gin config file where the data set", "\n", "# is present.", "\n", "if", "gin", ".", "query_parameter", "(", "\"dataset.name\"", ")", "==", "\"auto\"", ":", "\n", "# Obtain the dataset name from the gin config of the previous step.", "\n", "    ", "gin_config_file", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"results\"", ",", "\"gin\"", ",", "\n", "\"postprocess.gin\"", ")", "\n", "gin_dict", "=", "results", ".", "gin_dict", "(", "gin_config_file", ")", "\n", "with", "gin", ".", "unlock_config", "(", ")", ":", "\n", "      ", "gin", ".", "bind_parameter", "(", "\"dataset.name\"", ",", "gin_dict", "[", "\"dataset.name\"", "]", ".", "replace", "(", "\n", "\"'\"", ",", "\"\"", ")", ")", "\n", "", "", "dataset", "=", "named_data", ".", "get_named_ground_truth_data", "(", ")", "\n", "observations", ",", "labels", ",", "_", "=", "semi_supervised_utils", ".", "sample_supervised_data", "(", "\n", "random_seed", ",", "dataset", ",", "num_labelled_samples", ")", "\n", "# Path to TFHub module of previously trained representation.", "\n", "module_path", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"tfhub\"", ")", "\n", "with", "hub", ".", "eval_function_for_module", "(", "module_path", ")", "as", "f", ":", "\n", "\n", "    ", "def", "_representation_function", "(", "x", ")", ":", "\n", "      ", "\"\"\"Computes representation vector for input images.\"\"\"", "\n", "output", "=", "f", "(", "dict", "(", "images", "=", "x", ")", ",", "signature", "=", "\"representation\"", ",", "as_dict", "=", "True", ")", "\n", "return", "np", ".", "array", "(", "output", "[", "\"default\"", "]", ")", "\n", "\n", "# Computes scores of the representation based on the evaluation_fn.", "\n", "", "results_dict", "=", "validation_fn", "(", "observations", ",", "np", ".", "transpose", "(", "labels", ")", ",", "\n", "_representation_function", ")", "\n", "\n", "# Save the results (and all previous results in the pipeline) on disk.", "\n", "", "original_results_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"results\"", ")", "\n", "results_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"results\"", ")", "\n", "results_dict", "[", "\"elapsed_time\"", "]", "=", "time", ".", "time", "(", ")", "-", "experiment_timer", "\n", "results", ".", "update_result_directory", "(", "results_dir", ",", "\"validation\"", ",", "results_dict", ",", "\n", "original_results_dir", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.validation.validation_test.ValidateTest.setUp": [[33, 46], ["super().setUp", "disentanglement_lib.utils.resources.get_file", "disentanglement_lib.methods.unsupervised.train.train_with_gin", "disentanglement_lib.utils.resources.get_file", "disentanglement_lib.postprocessing.postprocess.postprocess_with_gin", "validation_test.ValidateTest.create_tempdir", "validation_test.ValidateTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.validation.validation_test.ValidateTest.setUp", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.unsupervised.train.train_with_gin", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_file", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.postprocessing.postprocess.postprocess_with_gin"], ["  ", "def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "ValidateTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "self", ".", "model_dir", "=", "self", ".", "create_tempdir", "(", "\n", "\"model\"", ",", "cleanup", "=", "absltest", ".", "TempFileCleanup", ".", "OFF", ")", ".", "full_path", "\n", "model_config", "=", "resources", ".", "get_file", "(", "\n", "\"config/tests/methods/unsupervised/train_test.gin\"", ")", "\n", "train", ".", "train_with_gin", "(", "self", ".", "model_dir", ",", "True", ",", "[", "model_config", "]", ")", "\n", "self", ".", "output_dir", "=", "self", ".", "create_tempdir", "(", "\n", "\"output\"", ",", "cleanup", "=", "absltest", ".", "TempFileCleanup", ".", "OFF", ")", ".", "full_path", "\n", "postprocess_config", "=", "resources", ".", "get_file", "(", "\n", "\"config/tests/postprocessing/postprocess_test_configs/mean.gin\"", ")", "\n", "postprocess", ".", "postprocess_with_gin", "(", "self", ".", "model_dir", ",", "self", ".", "output_dir", ",", "True", ",", "\n", "[", "postprocess_config", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.validation.validation_test.ValidateTest.test_validate": [[47, 59], ["absl.testing.parameterized.parameters", "gin.clear_config", "disentanglement_lib.validation.validate.validate_with_gin", "list", "disentanglement_lib.utils.resources.get_files_in_folder", "validation_test.ValidateTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.validation.validate.validate_with_gin", "home.repos.pwc.inspect_result.google-research_disentanglement_lib.utils.resources.get_files_in_folder"], ["", "@", "parameterized", ".", "parameters", "(", "\n", "list", "(", "\n", "resources", ".", "get_files_in_folder", "(", "\n", "\"config/tests/validation/validation_test_configs\"", ")", ")", ")", "\n", "def", "test_validate", "(", "self", ",", "gin_config", ")", ":", "\n", "# We clear the gin config before running. Otherwise, if a prior test fails,", "\n", "# the gin config is locked and the current test fails.", "\n", "    ", "gin", ".", "clear_config", "(", ")", "\n", "\n", "validate", ".", "validate_with_gin", "(", "self", ".", "output_dir", ",", "\n", "self", ".", "create_tempdir", "(", ")", ".", "full_path", ",", "True", ",", "\n", "[", "gin_config", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.__init__": [[87, 90], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "gamma", "=", "gin", ".", "REQUIRED", ",", "target", "=", "gin", ".", "REQUIRED", ")", ":", "\n", "    ", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "target", "=", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.BottleneckVAE.regularizer": [[91, 96], ["tensorflow.math.abs"], "methods", ["None"], ["", "def", "regularizer", "(", "self", ",", "kl_loss", ",", "z_mean", ",", "z_logvar", ",", "z_sampled", ")", ":", "\n", "# This is how we customize BaseVAE. To learn more, have a look at the", "\n", "# different models in vae.py.", "\n", "    ", "del", "z_mean", ",", "z_logvar", ",", "z_sampled", "\n", "return", "self", ".", "gamma", "*", "tf", ".", "math", ".", "abs", "(", "kl_loss", "-", "self", ".", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_disentanglement_lib.examples.example.compute_custom_metric": [[157, 192], ["gin.configurable", "disentanglement_lib.evaluation.metrics.utils.generate_batch_factor_code"], "function", ["home.repos.pwc.inspect_result.google-research_disentanglement_lib.metrics.utils.generate_batch_factor_code"], ["", "@", "gin", ".", "configurable", "(", "\n", "\"custom_metric\"", ",", "\n", "blacklist", "=", "[", "\"ground_truth_data\"", ",", "\"representation_function\"", ",", "\"random_state\"", "]", ")", "\n", "def", "compute_custom_metric", "(", "ground_truth_data", ",", "\n", "representation_function", ",", "\n", "random_state", ",", "\n", "num_train", "=", "gin", ".", "REQUIRED", ",", "\n", "batch_size", "=", "16", ")", ":", "\n", "  ", "\"\"\"Example of a custom (dummy) metric.\n\n  Preimplemented metrics can be found in disentanglement_lib.evaluation.metrics.\n\n  Args:\n    ground_truth_data: GroundTruthData to be sampled from.\n    representation_function: Function that takes observations as input and\n      outputs a dim_representation sized representation for each observation.\n    random_state: Numpy random state used for randomness.\n    num_train: Number of points used for training.\n    batch_size: Batch size for sampling.\n\n  Returns:\n    Dict with disentanglement score.\n  \"\"\"", "\n", "score_dict", "=", "{", "}", "\n", "\n", "# This is how to obtain the representations of num_train points along with the", "\n", "# ground-truth factors of variation.", "\n", "representation", ",", "factors_of_variations", "=", "utils", ".", "generate_batch_factor_code", "(", "\n", "ground_truth_data", ",", "representation_function", ",", "num_train", ",", "random_state", ",", "\n", "batch_size", ")", "\n", "# We could now compute a metric based on representation and", "\n", "# factors_of_variations. However, for the sake of brevity, we just return 1.", "\n", "del", "representation", ",", "factors_of_variations", "\n", "score_dict", "[", "\"custom_metric\"", "]", "=", "1.", "\n", "return", "score_dict", "\n", "\n"]]}