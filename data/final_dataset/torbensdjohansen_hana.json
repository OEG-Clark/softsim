{"home.repos.pwc.inspect_result.torbensdjohansen_hana.None.get_accuracies.get_word_acc": [[13, 52], ["numpy.quantile", "zip", "print", "len", "len", "len", "len", "pred.split", "label.split", "range", "range", "round", "round", "range"], "function", ["None"], ["def", "get_word_acc", "(", "data", ",", "coverage", ",", "predcol", ")", ":", "\n", "    ", "threshold", "=", "np", ".", "quantile", "(", "data", "[", "'prob'", "]", ",", "1", "-", "coverage", ")", "\n", "sub", "=", "data", "[", "data", "[", "'prob'", "]", ">=", "threshold", "]", "\n", "\n", "realized_cov", "=", "len", "(", "sub", ")", "/", "len", "(", "data", ")", "\n", "\n", "is_correct", "=", "0", "\n", "counter", "=", "0", "\n", "\n", "for", "pred", ",", "label", "in", "zip", "(", "sub", "[", "predcol", "]", ",", "sub", "[", "'label'", "]", ")", ":", "\n", "        ", "pred", ",", "label", "=", "pred", ".", "split", "(", "' '", ")", ",", "label", ".", "split", "(", "' '", ")", "\n", "\n", "nb_names_label", "=", "len", "(", "label", ")", "\n", "nb_names_pred", "=", "len", "(", "pred", ")", "\n", "\n", "if", "nb_names_label", "==", "nb_names_pred", ":", "\n", "            ", "for", "i", "in", "range", "(", "nb_names_label", ")", ":", "\n", "                ", "is_correct", "+=", "pred", "[", "i", "]", "==", "label", "[", "i", "]", "\n", "counter", "+=", "1", "\n", "", "", "elif", "nb_names_label", ">", "nb_names_pred", ":", "# too few predictions. 1 error pr. too few", "\n", "            ", "counter", "+=", "nb_names_label", "-", "nb_names_pred", "# mistake cases since pred did not include all words", "\n", "for", "i", "in", "range", "(", "nb_names_pred", "-", "1", ")", ":", "# not all the way through since last is compared to last always", "\n", "                ", "is_correct", "+=", "pred", "[", "i", "]", "==", "label", "[", "i", "]", "\n", "counter", "+=", "1", "\n", "# finally handle last name", "\n", "", "is_correct", "+=", "pred", "[", "-", "1", "]", "==", "label", "[", "-", "1", "]", "\n", "counter", "+=", "1", "\n", "", "elif", "nb_names_pred", ">", "nb_names_label", ":", "# now too many predictions! one error pr. too many", "\n", "            ", "counter", "+=", "nb_names_pred", "-", "nb_names_label", "# mistake cases since pred includes too many", "\n", "for", "i", "in", "range", "(", "nb_names_label", "-", "1", ")", ":", "# not all the way through since last is compared to last always", "\n", "                ", "is_correct", "+=", "pred", "[", "i", "]", "==", "label", "[", "i", "]", "\n", "counter", "+=", "1", "\n", "# finally handle last name", "\n", "", "is_correct", "+=", "pred", "[", "-", "1", "]", "==", "label", "[", "-", "1", "]", "\n", "counter", "+=", "1", "\n", "\n", "", "", "acc", "=", "is_correct", "/", "counter", "\n", "\n", "print", "(", "f'Coverage: {round(100 * realized_cov, 2)}%. Word accuracy: {round(100 * acc, 2)}%.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.get_accuracies.parse_args": [[54, 70], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.None.train.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Get word accuracies'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--fn-preds'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--coverage'", ",", "type", "=", "float", ",", "default", "=", "None", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "coverage", "is", "None", ":", "\n", "        ", "args", ".", "coverage", "=", "0.9", "\n", "", "else", ":", "\n", "        ", "if", "1", "<", "args", ".", "coverage", "<", "100", ":", "\n", "            ", "args", ".", "coverage", "/=", "100", "\n", "", "assert", "0", "<", "args", ".", "coverage", "<", "1", ",", "args", ".", "coverage", "\n", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.get_accuracies.main": [[72, 84], ["get_accuracies.parse_args", "pandas.read_csv", "get_accuracies.get_word_acc", "get_accuracies.get_word_acc", "print", "get_accuracies.get_word_acc", "get_accuracies.get_word_acc"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.None.train.parse_args", "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.get_accuracies.get_word_acc", "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.get_accuracies.get_word_acc", "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.get_accuracies.get_word_acc", "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.get_accuracies.get_word_acc"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "preds", "=", "pd", ".", "read_csv", "(", "args", ".", "fn_preds", ")", "\n", "\n", "get_word_acc", "(", "preds", ",", "1", ",", "'pred'", ")", "\n", "get_word_acc", "(", "preds", ",", "args", ".", "coverage", ",", "'pred'", ")", "\n", "\n", "if", "'pred_m'", "in", "preds", ".", "columns", ":", "\n", "        ", "print", "(", "'\\nUsing matched predictions:'", ")", "\n", "get_word_acc", "(", "preds", ",", "1", ",", "'pred_m'", ")", "\n", "get_word_acc", "(", "preds", ",", "args", ".", "coverage", ",", "'pred_m'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.evaluate.evaluate": [[29, 117], ["print", "networks.constructor.load_models", "print", "networks.util.setup_functions.prepare_labels_csv", "networks.util.pytorch_datasets.SequenceDataset", "torch.utils.data.DataLoader", "print", "networks.util.pytorch_functions.predict_sequence", "print", "numpy.array", "numpy.array", "networks.util.pytorch_functions.eval_sequence", "pickle.dump", "print", "pandas.DataFrame", "pd.DataFrame.to_csv", "data_info.keys", "list", "list", "list", "len", "open", "util.PipeConstructor().get_pipe_from_settings", "map", "map", "networks.constructor.load_models.keys", "labels.astype", "util.PipeConstructor"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.constructor.load_models", "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.setup_functions.prepare_labels_csv", "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_functions.predict_sequence", "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_functions.eval_sequence", "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util.PipeConstructor.get_pipe_from_settings"], ["def", "evaluate", "(", "\n", "data_info", ":", "dict", ",", "\n", "model_info", ":", "dict", ",", "\n", "device", ":", "torch", ".", "device", ",", "# pylint: disable=E1101", "\n", "root", ":", "str", ",", "\n", "fn_results", ":", "str", "=", "None", ",", "\n", "fn_preds", ":", "str", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Perform evaluation by calculating accuracy on the test data. Also produces\n    predictions on the test data.\n\n    Parameters\n    ----------\n    data_info : dict\n        Dictionary contains all information on the data, i.e. where to locate\n        it, which batch size to use, and more.\n    model_info : dict\n        Dictionary contains information on how to build the models.\n    device : torch.device\n        Controls whether GPU or CPU is used.\n    root: str.\n        Directory where the models are loaded from. If model_info contains URL\n        to model weights, the weights will be loaded from there instead.\n    fn_results : str, optional\n        Name used to save the results (models used, number of observation\n        evaluated on, and accuracy). The default is None, in which case the\n        results are printed but not saved.\n    fn_preds : str, optional\n        Name of the file with the predictions.\n\n    Returns\n    -------\n    None.\n\n    \"\"\"", "\n", "print", "(", "'Initializing model(s).'", ")", "\n", "models", "=", "load_models", "(", "model_info", ",", "root", ",", "device", ")", "\n", "\n", "print", "(", "'Initializing generator.'", ")", "\n", "labels_raw", "=", "prepare_labels_csv", "(", "\n", "cells", "=", "data_info", "[", "'cells'", "]", ",", "\n", "root_labels", "=", "data_info", "[", "'root_labels'", "]", ",", "\n", "root_images", "=", "data_info", "[", "'root_images'", "]", ",", "\n", ")", "\n", "if", "'debug'", "in", "data_info", ".", "keys", "(", ")", ":", "\n", "        ", "labels_raw", "=", "labels_raw", "[", ":", "data_info", "[", "'debug'", "]", "]", "\n", "\n", "", "generator", "=", "SequenceDataset", "(", "\n", "labels_raw", "=", "labels_raw", ",", "\n", "transform_to_label", "=", "data_info", "[", "'transform_label'", "]", ",", "\n", "val_size", "=", "1.0", ",", "\n", "transform_pipe", "=", "PipeConstructor", "(", ")", ".", "get_pipe_from_settings", "(", "data_info", ")", ",", "\n", ")", "\n", "generator", ".", "status", "=", "'sample_val'", "\n", "\n", "dataset", "=", "DataLoader", "(", "generator", ",", "data_info", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "num_workers", "=", "8", ")", "\n", "\n", "print", "(", "'Predicting on test data!'", ")", "\n", "preds", ",", "seq_prob", ",", "files", ",", "labels", "=", "predict_sequence", "(", "\n", "models", "=", "models", ",", "\n", "dataset", "=", "dataset", ",", "\n", "device", "=", "device", ",", "\n", "retrieve_labels", "=", "True", ",", "\n", "nb_passes", "=", "1", ",", "\n", ")", "\n", "\n", "print", "(", "'Cleaning predictions and labels.'", ")", "\n", "preds_clean", "=", "np", ".", "array", "(", "list", "(", "map", "(", "data_info", "[", "'clean_pred'", "]", ",", "preds", ")", ")", ")", "\n", "labels_clean", "=", "np", ".", "array", "(", "list", "(", "map", "(", "data_info", "[", "'clean_pred'", "]", ",", "labels", ".", "astype", "(", "int", ")", ")", ")", ")", "\n", "\n", "acc", ",", "_", ",", "_", "=", "eval_sequence", "(", "labels_clean", ",", "preds_clean", ",", "seq_prob", ")", "\n", "\n", "results", "=", "{", "\n", "'Models used'", ":", "list", "(", "models", ".", "keys", "(", ")", ")", ",", "\n", "'Number of observations for testing'", ":", "len", "(", "generator", ")", ",", "\n", "'Full sequence accuracy'", ":", "acc", ",", "\n", "}", "\n", "pickle", ".", "dump", "(", "results", ",", "open", "(", "fn_results", ",", "'wb'", ")", ")", "\n", "print", "(", "results", ")", "\n", "\n", "pred_df", "=", "pd", ".", "DataFrame", "(", "{", "\n", "'filename_full'", ":", "files", ",", "\n", "'label'", ":", "labels_clean", ",", "\n", "'pred'", ":", "preds_clean", ",", "\n", "'prob'", ":", "seq_prob", ",", "\n", "}", ")", "\n", "pred_df", ".", "to_csv", "(", "fn_preds", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.evaluate.parse_args": [[119, 135], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "settings.SETTINGS.keys"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.None.train.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Evaluation'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--settings'", ",", "type", "=", "str", ",", "choices", "=", "SETTINGS", ".", "keys", "(", ")", ")", "\n", "parser", ".", "add_argument", "(", "'--datadir'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--root'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--fn-results'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--fn-preds'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "type", "=", "int", ",", "default", "=", "1024", ")", "\n", "parser", ".", "add_argument", "(", "'--debug'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "'Keep only specified number of obs. for debugging.'", ")", "\n", "parser", ".", "add_argument", "(", "'--custom-name'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--model-from-url'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "'Load model weights from URL.'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.evaluate.main": [[137, 178], ["evaluate.parse_args", "torch.device", "[].copy", "[].copy", "data_info[].format", "data_info[].format", "evaluate.evaluate", "os.path.join", "os.path.join", "list", "[].copy.pop", "print", "torch.cuda.is_available", "[].copy.keys"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.None.train.parse_args", "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.evaluate.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "settings", "=", "args", ".", "settings", "\n", "root", "=", "args", ".", "root", "\n", "fn_results", "=", "args", ".", "fn_results", "\n", "fn_preds", "=", "args", ".", "fn_preds", "\n", "\n", "if", "args", ".", "root", "is", "None", ":", "\n", "        ", "for", "_required", "in", "(", "args", ".", "model_from_url", ",", "args", ".", "fn_results", ",", "args", ".", "fn_preds", ")", ":", "\n", "            ", "assert", "_required", "is", "not", "None", ",", "'if root not specified, must specify model url and name of output files'", "\n", "\n", "", "", "if", "fn_results", "is", "None", ":", "\n", "        ", "fn_results", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'eval_results.pkl'", ")", "\n", "", "if", "fn_preds", "is", "None", ":", "\n", "        ", "fn_preds", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'preds.csv'", ")", "\n", "\n", "", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "# pylint: disable=E1101", "\n", "\n", "data_info", "=", "SETTINGS", "[", "settings", "]", "[", "'data_info'", "]", ".", "copy", "(", ")", "\n", "model_info", "=", "SETTINGS", "[", "settings", "]", "[", "'model_info'", "]", ".", "copy", "(", ")", "\n", "\n", "data_info", "[", "'root_labels'", "]", "=", "data_info", "[", "'root_labels'", "]", ".", "format", "(", "args", ".", "datadir", ",", "'test'", ")", "\n", "data_info", "[", "'root_images'", "]", "=", "data_info", "[", "'root_images'", "]", ".", "format", "(", "args", ".", "datadir", ")", "\n", "\n", "data_info", "[", "'batch_size'", "]", "=", "args", ".", "batch_size", "\n", "\n", "model_name", "=", "list", "(", "model_info", ".", "keys", "(", ")", ")", "[", "0", "]", "\n", "\n", "if", "args", ".", "model_from_url", "is", "not", "None", ":", "\n", "        ", "model_info", "[", "model_name", "]", "[", "'url'", "]", "=", "args", ".", "model_from_url", "\n", "\n", "", "if", "args", ".", "custom_name", "is", "not", "None", ":", "\n", "        ", "model_info", "[", "args", ".", "custom_name", "]", "=", "model_info", ".", "pop", "(", "model_name", ")", "\n", "model_name", "=", "args", ".", "custom_name", "\n", "\n", "", "if", "args", ".", "debug", "is", "not", "None", ":", "\n", "        ", "print", "(", "f'Debug mode using {args.debug} number of observations.'", ")", "\n", "data_info", "[", "'debug'", "]", "=", "args", ".", "debug", "\n", "\n", "", "evaluate", "(", "data_info", ",", "model_info", ",", "device", ",", "root", ",", "fn_results", ",", "fn_preds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.matching.MatchToStr.__init__": [[41, 53], ["isinstance", "isinstance", "dict", "set"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "potential_strs", ":", "set", ",", "cutoff", ":", "float", "=", "0.6", ",", "ignore", ":", "set", "=", "None", ")", ":", "\n", "        ", "if", "ignore", "is", "None", ":", "\n", "            ", "ignore", "=", "set", "(", ")", "\n", "\n", "", "assert", "isinstance", "(", "potential_strs", ",", "set", ")", "\n", "assert", "0", "<=", "cutoff", "<=", "1", "\n", "assert", "isinstance", "(", "ignore", ",", "set", ")", "\n", "\n", "self", ".", "potential_strs", "=", "potential_strs", "\n", "self", ".", "cutoff", "=", "cutoff", "\n", "self", ".", "ignore", "=", "ignore", "\n", "self", ".", "fuzzy_map", "=", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.matching.MatchToStr.match": [[54, 126], ["len", "time.time", "enumerate", "numpy.array", "print", "numpy.array.append", "time.time", "numpy.array.append", "numpy.array.append", "matching.MatchToStr.fuzzy_map.keys", "difflib.get_close_matches", "len", "len", "round", "round", "round"], "methods", ["None"], ["", "def", "match", "(", "self", ",", "strs_to_match", ":", "np", ".", "ndarray", ",", "verbose", ":", "bool", "=", "True", ")", "->", "(", "np", ".", "ndarray", ",", "int", ",", "int", ",", "dict", ")", ":", "\n", "        ", "\"\"\"\n        Matches strings to a set of valid strings - such as names.\n\n        Does not perform matching for strings in `ignore`. Returns UNMATCHABLE\n        if match \"similarity\" is below `cutoff`.\n\n        Parameters\n        ----------\n        strs_to_match : np.ndarray\n            The strings to match agains `self.potential_strs`.\n        verbose : bool\n            Whether to print progress.\n\n        Returns\n        -------\n        strs_matched : np.ndarray\n            The modified input, where all strings not in `self.potential_strs`\n            have been matched to the nearest valid string.\n        nb_exact : int\n            The number of exact matches perfored, i.e. where the string already\n            existed in `self.potential_strs`.\n        nb_fuzzy : int\n            Number of times where it was needed to match to nearest valid.\n        self.fuzzy_map : dict\n            Dictionary where the keys are the strings that were not valid and\n            the values the strings they were matched to.\n\n        \"\"\"", "\n", "nb_to_match", "=", "len", "(", "strs_to_match", ")", "\n", "strs_matched", "=", "[", "]", "\n", "nb_exact", "=", "0", "\n", "nb_fuzzy", "=", "0", "\n", "nb_ignore", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "i", ",", "str_to_match", "in", "enumerate", "(", "strs_to_match", ")", ":", "\n", "            ", "if", "(", "i", "+", "1", ")", "%", "1000", "==", "0", "and", "verbose", ":", "\n", "                ", "running_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "f'Progress: {round(i / nb_to_match * 100, 1)}%. '", "+", "\n", "f'Run time: {round(running_time, 1)} seconds. '", "+", "\n", "f'Per 1000 predictions: {round(running_time * 1000 / i, 1)} seconds. '", "+", "\n", "f'Exact: {nb_exact}. Fuzzy: {nb_fuzzy}. Ignored: {nb_ignore}. '", "+", "\n", "f'Number \"cached\": {len(self.fuzzy_map)}.'", "\n", ")", "\n", "\n", "", "if", "str_to_match", "in", "self", ".", "ignore", ":", "\n", "                ", "nb_ignore", "+=", "1", "\n", "strs_matched", ".", "append", "(", "str_to_match", ")", "\n", "", "elif", "str_to_match", "in", "self", ".", "potential_strs", ":", "\n", "                ", "nb_exact", "+=", "1", "\n", "strs_matched", ".", "append", "(", "str_to_match", ")", "\n", "", "else", ":", "\n", "                ", "nb_fuzzy", "+=", "1", "\n", "\n", "if", "str_to_match", "in", "self", ".", "fuzzy_map", ".", "keys", "(", ")", ":", "\n", "                    ", "str_matched", "=", "self", ".", "fuzzy_map", "[", "str_to_match", "]", "\n", "", "else", ":", "\n", "                    ", "near_matches", "=", "difflib", ".", "get_close_matches", "(", "\n", "str_to_match", ",", "self", ".", "potential_strs", ",", "n", "=", "1", ",", "cutoff", "=", "self", ".", "cutoff", ",", "\n", ")", "\n", "if", "len", "(", "near_matches", ")", "==", "0", ":", "\n", "                        ", "str_matched", "=", "'UNMATCHABLE'", "\n", "", "else", ":", "\n", "                        ", "str_matched", "=", "near_matches", "[", "0", "]", "\n", "", "self", ".", "fuzzy_map", "[", "str_to_match", "]", "=", "str_matched", "\n", "\n", "", "strs_matched", ".", "append", "(", "str_matched", ")", "\n", "\n", "", "", "strs_matched", "=", "np", ".", "array", "(", "strs_matched", ")", "\n", "\n", "return", "strs_matched", ",", "nb_exact", ",", "nb_fuzzy", ",", "nb_ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.matching.split_names": [[128, 142], ["numpy.char.split", "numpy.array().reshape", "numpy.array().reshape", "numpy.empty", "enumerate", "numpy.concatenate", "enumerate", "numpy.array", "len", "numpy.array", "len", "len", "len"], "function", ["None"], ["", "", "def", "split_names", "(", "names", ":", "np", ".", "ndarray", ",", "max_nb_middle_names", ":", "int", ")", ":", "\n", "    ", "split", "=", "np", ".", "char", ".", "split", "(", "names", ")", "\n", "last_names", "=", "np", ".", "array", "(", "[", "x", "[", "-", "1", "]", "for", "x", "in", "split", "]", ")", ".", "reshape", "(", "(", "len", "(", "names", ")", ",", "1", ")", ")", "\n", "remaining", "=", "[", "x", "[", ":", "-", "1", "]", "for", "x", "in", "split", "]", "\n", "first_names", "=", "np", ".", "array", "(", "[", "x", "[", "0", "]", "if", "len", "(", "x", ")", ">", "0", "else", "''", "for", "x", "in", "remaining", "]", ")", ".", "reshape", "(", "(", "len", "(", "names", ")", ",", "1", ")", ")", "\n", "middle_names", "=", "np", ".", "empty", "(", "(", "len", "(", "split", ")", ",", "max_nb_middle_names", ")", ",", "dtype", "=", "f'U{MAX_INDIVIDUAL_NAME_LEN}'", ")", "\n", "\n", "for", "i", ",", "names", "in", "enumerate", "(", "[", "x", "[", "1", ":", "]", "for", "x", "in", "remaining", "]", ")", ":", "\n", "        ", "for", "j", ",", "name", "in", "enumerate", "(", "names", ")", ":", "\n", "            ", "middle_names", "[", "i", ",", "j", "]", "=", "name", "\n", "\n", "", "", "names", "=", "np", ".", "concatenate", "(", "[", "first_names", ",", "middle_names", ",", "last_names", "]", ",", "axis", "=", "1", ")", "\n", "\n", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.matching.match": [[144, 178], ["names.copy", "matching.MatchToStr", "mapper.items", "pandas.DataFrame", "range", "names_matched_flat.apply.apply", "matching.MatchToStr", "matching.MatchToStr", "print", "matcher.match", "sum", "len", "re.sub().strip", "range", "range", "re.sub"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.None.matching.match"], ["", "def", "match", "(", "names", ":", "np", ".", "ndarray", ",", "lookup", ":", "dict", ")", ":", "\n", "    ", "nb_cols", "=", "names", ".", "shape", "[", "1", "]", "\n", "names_matched", "=", "names", ".", "copy", "(", ")", "\n", "\n", "middle_name_matcher", "=", "MatchToStr", "(", "lookup", "[", "'middle'", "]", ")", "# for re-use", "\n", "mapper", "=", "{", "\n", "0", ":", "MatchToStr", "(", "lookup", "[", "'first'", "]", ")", ",", "\n", "**", "{", "i", ":", "middle_name_matcher", "for", "i", "in", "range", "(", "1", ",", "nb_cols", "-", "1", ")", "}", ",", "\n", "(", "nb_cols", "-", "1", ")", ":", "MatchToStr", "(", "lookup", "[", "'last'", "]", ")", ",", "\n", "}", "\n", "nb_fuzzy", "=", "{", "}", "\n", "\n", "for", "i", ",", "matcher", "in", "mapper", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "f'Matching column {i + 1} of {nb_cols}.'", ")", "\n", "verbose", "=", "len", "(", "matcher", ".", "potential_strs", ")", ">", "1", "\n", "matched", ",", "_", ",", "nb_fuzzy_i", ",", "_", "=", "matcher", ".", "match", "(", "names", "[", ":", ",", "i", "]", ",", "verbose", ")", "\n", "names_matched", "[", ":", ",", "i", "]", "=", "matched", "\n", "nb_fuzzy", "[", "i", "]", "=", "nb_fuzzy_i", "\n", "\n", "", "nb_matches", "=", "{", "\n", "'Number of first names matched'", ":", "nb_fuzzy", "[", "0", "]", ",", "\n", "'Number of middle names matched'", ":", "sum", "(", "nb_fuzzy", "[", "i", "]", "for", "i", "in", "range", "(", "1", ",", "nb_cols", "-", "1", ")", ")", ",", "\n", "'Number of last names matched'", ":", "nb_fuzzy", "[", "nb_cols", "-", "1", "]", ",", "\n", "}", "\n", "\n", "names_matched", "=", "pd", ".", "DataFrame", "(", "names_matched", ")", "\n", "names_matched_flat", "=", "names_matched", "[", "0", "]", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "nb_cols", ")", ":", "\n", "        ", "names_matched_flat", "+=", "' '", "+", "names_matched", "[", "i", "]", "\n", "\n", "", "names_matched_flat", "=", "names_matched_flat", ".", "apply", "(", "lambda", "x", ":", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "x", ")", ".", "strip", "(", ")", ")", "\n", "\n", "return", "names_matched_flat", ".", "values", ",", "nb_matches", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.matching.parse_args": [[180, 197], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.None.train.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Matching'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--fn-lex-first'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--fn-lex-middle'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--fn-lex-last'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--root'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--fn-results'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--fn-preds'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--max-nb-middle-names'", ",", "type", "=", "int", ",", "default", "=", "MAX_NB_NAMES", "-", "2", ")", "\n", "parser", ".", "add_argument", "(", "'--allow-empty'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "default", "=", "[", "'first'", ",", "'middle'", "]", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.matching.construct_lookup": [[199, 216], ["pandas.read_csv().values.reshape", "pandas.read_csv().values.reshape", "pandas.read_csv().values.reshape", "set", "set", "set", "lookup[].union", "set", "pandas.read_csv", "pandas.read_csv", "pandas.read_csv"], "function", ["None"], ["", "def", "construct_lookup", "(", "args", ")", ":", "\n", "    ", "first", "=", "pd", ".", "read_csv", "(", "\n", "args", ".", "fn_lex_first", ",", "keep_default_na", "=", "False", ",", "\n", ")", ".", "values", ".", "reshape", "(", "-", "1", ")", "if", "args", ".", "fn_lex_first", "else", "[", "''", "]", "\n", "middle", "=", "pd", ".", "read_csv", "(", "\n", "args", ".", "fn_lex_middle", ",", "keep_default_na", "=", "False", ",", "\n", ")", ".", "values", ".", "reshape", "(", "-", "1", ")", "if", "args", ".", "fn_lex_middle", "else", "[", "''", "]", "\n", "last", "=", "pd", ".", "read_csv", "(", "\n", "args", ".", "fn_lex_last", ",", "keep_default_na", "=", "False", ",", "\n", ")", ".", "values", ".", "reshape", "(", "-", "1", ")", "if", "args", ".", "fn_lex_last", "else", "[", "''", "]", "\n", "\n", "lookup", "=", "{", "'first'", ":", "set", "(", "first", ")", ",", "'middle'", ":", "set", "(", "middle", ")", ",", "'last'", ":", "set", "(", "last", ")", "}", "\n", "\n", "for", "allow_empty", "in", "args", ".", "allow_empty", ":", "\n", "        ", "lookup", "[", "allow_empty", "]", "=", "lookup", "[", "allow_empty", "]", ".", "union", "(", "set", "(", "[", "''", "]", ")", ")", "\n", "\n", "", "return", "lookup", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.matching.main": [[218, 248], ["matching.parse_args", "pandas.read_csv", "pickle.load", "matching.construct_lookup", "matching.split_names", "matching.match", "pickle.load.update", "print", "pickle.dump", "pd.read_csv.to_csv", "os.path.join", "os.path.join", "open", "preds[].values.astype", "open", "os.path.join.replace", "os.path.join.replace"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.None.train.parse_args", "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.matching.construct_lookup", "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.matching.split_names", "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.matching.match"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "root", "is", "None", ":", "\n", "        ", "assert", "args", ".", "fn_results", "is", "not", "None", "and", "args", ".", "fn_preds", "is", "not", "None", "\n", "\n", "", "fn_results", "=", "args", ".", "fn_results", "\n", "fn_preds", "=", "args", ".", "fn_preds", "\n", "\n", "if", "fn_results", "is", "None", ":", "\n", "        ", "fn_results", "=", "os", ".", "path", ".", "join", "(", "args", ".", "root", ",", "'eval_results.pkl'", ")", "\n", "", "if", "fn_preds", "is", "None", ":", "\n", "        ", "fn_preds", "=", "os", ".", "path", ".", "join", "(", "args", ".", "root", ",", "'preds.csv'", ")", "\n", "\n", "", "preds", "=", "pd", ".", "read_csv", "(", "fn_preds", ")", "\n", "results", "=", "pickle", ".", "load", "(", "open", "(", "fn_results", ",", "'rb'", ")", ")", "\n", "\n", "lookup", "=", "construct_lookup", "(", "args", ")", "\n", "split_preds", "=", "split_names", "(", "preds", "[", "'pred'", "]", ".", "values", ".", "astype", "(", "'U'", ")", ",", "args", ".", "max_nb_middle_names", ")", "\n", "matched", ",", "nb_matches", "=", "match", "(", "split_preds", ",", "lookup", ")", "\n", "\n", "preds", "[", "'pred_m'", "]", "=", "matched", "\n", "acc", "=", "(", "preds", "[", "'pred_m'", "]", "==", "preds", "[", "'label'", "]", ")", ".", "mean", "(", ")", "\n", "\n", "results", ".", "update", "(", "nb_matches", ")", "\n", "results", "[", "'Full sequence accuracy (with matching)'", "]", "=", "acc", "\n", "print", "(", "results", ")", "\n", "\n", "pickle", ".", "dump", "(", "results", ",", "open", "(", "fn_results", ".", "replace", "(", "'.pkl'", ",", "'_matched.pkl'", ")", ",", "'wb'", ")", ")", "\n", "preds", ".", "to_csv", "(", "fn_preds", ".", "replace", "(", "'.csv'", ",", "'_matched.csv'", ")", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.train.train": [[24, 102], ["print", "networks.util.setup_functions.prepare_labels_csv", "networks.util.pytorch_datasets.SequenceDataset", "print", "torch.utils.data.DataLoader", "next", "print", "torch.utils.data.DataLoader", "print", "dict", "model_info.items", "networks.experiment.NetworkExperimentSequences", "networks.experiment.NetworkExperimentSequences.run", "data_info.keys", "iter", "util._setup_model_optimizer", "util.PipeConstructor().get_pipe_from_settings", "len", "min", "min", "len", "len", "util.PipeConstructor", "len"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.util.setup_functions.prepare_labels_csv", "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences.run", "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util._setup_model_optimizer", "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util.PipeConstructor.get_pipe_from_settings"], ["def", "train", "(", "\n", "data_info", ":", "dict", ",", "\n", "model_info", ":", "dict", ",", "\n", "device", ":", "torch", ".", "device", ",", "# pylint: disable=E1101", "\n", "root", ":", "str", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    \"Wrapper\" function to run. Allows one to easily change a lot of the\n    settings by simply passing new arguments.\n\n    Parameters\n    ----------\n    data_info : dict\n        Dictionary contains all information on the data, i.e. where to locate\n        it, which batch size and how many epochs to train, and more.\n    model_info : dict\n        Dictionary contains information on how to build the model, including\n        optimization and scheduler info.\n    device : torch.device\n        Controls whether GPU or CPU is used.\n    root : str\n        Directory where the checkpoints and the logs are saved.\n\n    Returns\n    -------\n    None.\n\n    \"\"\"", "\n", "print", "(", "'Initializing generator.'", ")", "\n", "labels_raw", "=", "prepare_labels_csv", "(", "\n", "cells", "=", "data_info", "[", "'cells'", "]", ",", "\n", "root_labels", "=", "data_info", "[", "'root_labels'", "]", ",", "\n", "root_images", "=", "data_info", "[", "'root_images'", "]", ",", "\n", ")", "\n", "if", "'debug'", "in", "data_info", ".", "keys", "(", ")", ":", "\n", "        ", "labels_raw", "=", "labels_raw", "[", ":", "data_info", "[", "'debug'", "]", "]", "\n", "\n", "", "generator", "=", "SequenceDataset", "(", "\n", "labels_raw", "=", "labels_raw", ",", "\n", "transform_to_label", "=", "data_info", "[", "'transform_label'", "]", ",", "\n", "val_size", "=", "0.05", ",", "\n", "transform_pipe", "=", "PipeConstructor", "(", ")", ".", "get_pipe_from_settings", "(", "data_info", ")", ",", "\n", ")", "\n", "\n", "print", "(", "'Generating validation data.'", ")", "\n", "generator", ".", "status", "=", "'sample_val'", "\n", "ds_val", "=", "DataLoader", "(", "generator", ",", "batch_size", "=", "len", "(", "generator", ")", ",", "shuffle", "=", "False", ")", "\n", "val_data", "=", "next", "(", "iter", "(", "ds_val", ")", ")", "\n", "del", "ds_val", "\n", "\n", "print", "(", "'Initializing training loader.'", ")", "\n", "generator", ".", "status", "=", "'sample_train'", "\n", "ds_train", "=", "DataLoader", "(", "generator", ",", "data_info", "[", "'batch_size'", "]", ",", "shuffle", "=", "True", ",", "num_workers", "=", "8", ")", "\n", "\n", "print", "(", "'Initializing models, optimizers, and schedulers.'", ")", "\n", "models", "=", "dict", "(", ")", "\n", "for", "model_name", ",", "info", "in", "model_info", ".", "items", "(", ")", ":", "\n", "        ", "models", "[", "model_name", "]", "=", "_setup_model_optimizer", "(", "\n", "info", "=", "info", ",", "\n", "batch_size", "=", "data_info", "[", "'batch_size'", "]", ",", "\n", "epoch_len", "=", "len", "(", "generator", ")", ",", "\n", "device", "=", "device", ",", "\n", ")", "\n", "\n", "", "experiment", "=", "NetworkExperimentSequences", "(", "\n", "dataset", "=", "ds_train", ",", "\n", "models", "=", "models", ",", "\n", "loss_function", "=", "sequence_loss", ",", "\n", "eval_loss", "=", "sequence_loss_eval", ",", "\n", "acc_function", "=", "sequence_acc", ",", "\n", "epochs", "=", "data_info", "[", "'nb_epochs'", "]", ",", "\n", "save_interval", "=", "min", "(", "10", "*", "len", "(", "ds_train", ")", ",", "10_000", ")", ",", "\n", "log_interval", "=", "min", "(", "len", "(", "ds_train", ")", ",", "1_000", ")", ",", "\n", "root", "=", "root", ",", "\n", "device", "=", "device", ",", "\n", ")", "\n", "\n", "experiment", ".", "run", "(", "val_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.train.parse_args": [[104, 121], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "settings.SETTINGS.keys"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.None.train.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Training'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--settings'", ",", "type", "=", "str", ",", "choices", "=", "SETTINGS", ".", "keys", "(", ")", ")", "\n", "parser", ".", "add_argument", "(", "'--root'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--datadir'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--fn-pretrained'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--url-pretrained'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--debug'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "'Keep only specified number of obs. for debugging.'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--custom-name'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--to-freeze'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "default", "=", "None", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.train.main": [[123, 166], ["train.parse_args", "torch.device", "[].copy", "[].copy", "data_info[].format", "data_info[].format", "train.train", "list", "[].copy.pop", "print", "print", "print", "print", "torch.cuda.is_available", "[].copy.keys"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.None.train.parse_args", "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.train.train"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "settings", "=", "args", ".", "settings", "\n", "root", "=", "args", ".", "root", "\n", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "# pylint: disable=E1101", "\n", "\n", "data_info", "=", "SETTINGS", "[", "settings", "]", "[", "'data_info'", "]", ".", "copy", "(", ")", "\n", "model_info", "=", "SETTINGS", "[", "settings", "]", "[", "'model_info'", "]", ".", "copy", "(", ")", "\n", "\n", "data_info", "[", "'root_labels'", "]", "=", "data_info", "[", "'root_labels'", "]", ".", "format", "(", "args", ".", "datadir", ",", "'train'", ")", "\n", "data_info", "[", "'root_images'", "]", "=", "data_info", "[", "'root_images'", "]", ".", "format", "(", "args", ".", "datadir", ")", "\n", "\n", "data_info", "[", "'batch_size'", "]", "=", "args", ".", "batch_size", "or", "data_info", "[", "'batch_size'", "]", "\n", "\n", "model_name", "=", "list", "(", "model_info", ".", "keys", "(", ")", ")", "[", "0", "]", "\n", "\n", "if", "args", ".", "custom_name", "is", "not", "None", ":", "\n", "        ", "model_info", "[", "args", ".", "custom_name", "]", "=", "model_info", ".", "pop", "(", "model_name", ")", "\n", "model_name", "=", "args", ".", "custom_name", "\n", "\n", "", "if", "args", ".", "fn_pretrained", "is", "not", "None", ":", "\n", "        ", "assert", "args", ".", "url_pretrained", "is", "None", ",", "'cannot request pretrained model from file AND url'", "\n", "print", "(", "f'Starting training from pretrained model {args.fn_pretrained}.'", ")", "\n", "model_info", "[", "model_name", "]", "[", "'fn_pretrained'", "]", "=", "args", ".", "fn_pretrained", "\n", "\n", "", "if", "args", ".", "url_pretrained", "is", "not", "None", ":", "\n", "        ", "print", "(", "f'Starting training from pretrained model {args.url_pretrained}.'", ")", "\n", "model_info", "[", "model_name", "]", "[", "'url'", "]", "=", "args", ".", "url_pretrained", "\n", "\n", "", "if", "args", ".", "lr", "is", "not", "None", ":", "\n", "        ", "print", "(", "f'Using custom learning rate: {args.lr}.'", ")", "\n", "model_info", "[", "model_name", "]", "[", "'learning_rate'", "]", "=", "args", ".", "lr", "\n", "\n", "", "if", "args", ".", "to_freeze", "is", "not", "None", ":", "\n", "        ", "model_info", "[", "model_name", "]", "[", "'to_freeze'", "]", "=", "args", ".", "to_freeze", "\n", "\n", "", "if", "args", ".", "debug", "is", "not", "None", ":", "\n", "        ", "print", "(", "f'Debug mode using {args.debug} number of observations.'", ")", "\n", "data_info", "[", "'debug'", "]", "=", "args", ".", "debug", "\n", "\n", "", "train", "(", "data_info", ",", "model_info", ",", "device", ",", "root", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util.PipeConstructor.init_resizer": [[233, 263], ["isinstance", "isinstance", "torchvision.transforms.Resize", "networks.augment.augmenters.ResizePad", "Exception"], "methods", ["None"], ["def", "init_resizer", "(", "self", ",", "resize_method", ",", "target_h", ",", "target_w", ")", ":", "\n", "        ", "\"\"\"\n        Setup for image transformation resizer.\n\n        Parameters\n        ----------\n        resize_method : str\n            The resize method uses to achieve desired image size.\n        target_h : int\n            The desired height.\n        target_w : int\n            The desired width.\n\n        \"\"\"", "\n", "\n", "assert", "resize_method", "in", "self", ".", "_ALLOWED_RESIZE_METHODS", "\n", "assert", "isinstance", "(", "target_h", ",", "int", ")", "and", "target_h", ">", "0", "\n", "assert", "isinstance", "(", "target_w", ",", "int", ")", "and", "target_w", ">", "0", "\n", "\n", "if", "resize_method", "==", "'resize'", ":", "\n", "            ", "self", ".", "resizer", "=", "transforms", ".", "Resize", "(", "(", "target_h", ",", "target_w", ")", ")", "\n", "", "elif", "resize_method", "==", "'resize_pad'", ":", "\n", "# Maybe allow for type of padding to be controlled.", "\n", "            ", "self", ".", "resizer", "=", "ResizePad", "(", "target_h", ",", "target_w", ",", "(", "'left'", ",", "'bottom'", ")", ",", "'constant'", ")", "\n", "", "else", ":", "\n", "            ", "err_msg", "=", "(", "\n", "'Must specify a valid resize method. Requested: '", "\n", "+", "f'\"{resize_method}\". Allowed: {self._ALLOWED_RESIZE_METHODS}.'", "\n", ")", "\n", "raise", "Exception", "(", "err_msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util.PipeConstructor.get_pipe": [[264, 282], ["torchvision.transforms.Compose", "torchvision.transforms.Compose", "networks.augment.pytorch_randaugment.rand_augment.RandAugment", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["None"], ["", "", "def", "get_pipe", "(", "self", ",", "nb_augments", ":", "int", "=", "3", ",", "magnitude", ":", "int", "=", "5", ")", "->", "dict", ":", "# pylint: disable=C0116", "\n", "        ", "pipe", "=", "{", "\n", "'sample_train'", ":", "transforms", ".", "Compose", "(", "[", "\n", "self", ".", "resizer", ",", "\n", "to_col", ",", "\n", "RandAugment", "(", "n", "=", "nb_augments", ",", "m", "=", "magnitude", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ",", "\n", "]", ")", ",", "\n", "'sample_val'", ":", "transforms", ".", "Compose", "(", "[", "\n", "self", ".", "resizer", ",", "\n", "to_col", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ",", "\n", "]", ")", "\n", "}", "\n", "\n", "return", "pipe", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util.PipeConstructor.get_pipe_from_settings": [[283, 291], ["util.PipeConstructor.init_resizer", "util.PipeConstructor.get_pipe"], "methods", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util.PipeConstructor.init_resizer", "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util.PipeConstructor.get_pipe"], ["", "def", "get_pipe_from_settings", "(", "self", ",", "data_setting", ":", "dict", ")", "->", "dict", ":", "# pylint: disable=C0116", "\n", "        ", "self", ".", "init_resizer", "(", "\n", "resize_method", "=", "data_setting", "[", "'resize_method'", "]", ",", "\n", "target_h", "=", "data_setting", "[", "'height'", "]", ",", "\n", "target_w", "=", "data_setting", "[", "'width'", "]", ",", "\n", ")", "\n", "\n", "return", "self", ".", "get_pipe", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util._transform_label_individual_name": [[32, 60], ["isinstance", "len", "numpy.array", "label.astype.astype", "label.astype.append", "util._clean_pred_individual_name"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util._clean_pred_individual_name"], ["def", "_transform_label_individual_name", "(", "raw_input", ":", "str", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "'''\n    Formats an individual name to array of floats representing characters. The\n    floats are just integers cast to float, as that format is used for training\n    the neural networks.\n\n    '''", "\n", "assert", "isinstance", "(", "raw_input", ",", "str", ")", "\n", "\n", "name_len", "=", "len", "(", "raw_input", ")", "\n", "\n", "assert", "MAX_INDIVIDUAL_NAME_LEN", ">=", "name_len", "\n", "\n", "label", "=", "[", "]", "\n", "\n", "for", "char", "in", "raw_input", ":", "\n", "        ", "label", ".", "append", "(", "MAP_LETTER_IDX", "[", "char", "]", ")", "\n", "\n", "", "label", "+=", "(", "MAX_INDIVIDUAL_NAME_LEN", "-", "name_len", ")", "*", "[", "MISSING_INDICATOR", "]", "\n", "\n", "label", "=", "np", ".", "array", "(", "label", ")", "\n", "\n", "# Assert cycle consistency", "\n", "assert", "raw_input", "==", "_clean_pred_individual_name", "(", "label", ",", "False", ")", "\n", "\n", "label", "=", "label", ".", "astype", "(", "'float'", ")", "\n", "\n", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util._clean_pred_individual_name": [[62, 96], ["enumerate", "numpy.concatenate", "clean.append", "util._transform_label_individual_name", "non_missings.append", "all", "Exception", "numpy.ones", "np.concatenate.astype", "len"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util._transform_label_individual_name"], ["", "def", "_clean_pred_individual_name", "(", "raw_pred", ":", "np", ".", "ndarray", ",", "assert_consistency", ":", "bool", "=", "True", ")", "->", "str", ":", "\n", "    ", "'''\n    Maps predictions back from integer to string representation.\n\n    '''", "\n", "non_missings", "=", "[", "]", "\n", "\n", "for", "i", ",", "val", "in", "enumerate", "(", "raw_pred", ")", ":", "\n", "        ", "if", "val", "!=", "MISSING_INDICATOR", ":", "\n", "            ", "non_missings", ".", "append", "(", "i", ")", "\n", "\n", "", "", "pred", "=", "np", ".", "concatenate", "(", "[", "\n", "raw_pred", "[", "non_missings", "]", ",", "\n", "np", ".", "ones", "(", "MAX_INDIVIDUAL_NAME_LEN", "-", "len", "(", "non_missings", ")", ",", "dtype", "=", "int", ")", "*", "MISSING_INDICATOR", ",", "\n", "]", ")", "\n", "\n", "clean", "=", "[", "]", "\n", "\n", "for", "idx", "in", "pred", ":", "\n", "        ", "if", "idx", "==", "MISSING_INDICATOR", ":", "\n", "            ", "continue", "\n", "", "clean", ".", "append", "(", "MAP_IDX_LETTER", "[", "idx", "]", ")", "\n", "\n", "", "clean", "=", "''", ".", "join", "(", "(", "clean", ")", ")", "\n", "\n", "# Need to be cycle consistent - however, the function may be called from", "\n", "# `transform_label`, and we do not want infinite recursion, hence the if.", "\n", "if", "assert_consistency", ":", "\n", "        ", "transformed_clean", "=", "_transform_label_individual_name", "(", "clean", ")", "\n", "\n", "if", "not", "all", "(", "pred", ".", "astype", "(", "'float'", ")", "==", "transformed_clean", ")", ":", "\n", "            ", "raise", "Exception", "(", "raw_pred", ",", "pred", ",", "clean", ",", "transformed_clean", ")", "\n", "\n", "", "", "return", "clean", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util.transform_label_last_name": [[98, 102], ["util._transform_label_individual_name", "raw_input.split"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util._transform_label_individual_name"], ["", "def", "transform_label_last_name", "(", "raw_input", ":", "str", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "last_name", "=", "raw_input", ".", "split", "(", "' '", ")", "[", "-", "1", "]", "\n", "\n", "return", "_transform_label_individual_name", "(", "last_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util.clean_pred_last_name": [[104, 106], ["util._clean_pred_individual_name"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util._clean_pred_individual_name"], ["", "def", "clean_pred_last_name", "(", "raw_pred", ":", "np", ".", "ndarray", ",", "assert_consistency", ":", "bool", "=", "True", ")", "->", "str", ":", "\n", "    ", "return", "_clean_pred_individual_name", "(", "raw_pred", ",", "assert_consistency", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util.transform_label_full_name": [[108, 127], ["raw_input.split", "len", "numpy.concatenate", "np.concatenate.append", "util.clean_pred_full_name", "util._transform_label_individual_name", "np.concatenate.astype"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util.clean_pred_full_name", "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util._transform_label_individual_name"], ["", "def", "transform_label_full_name", "(", "raw_input", ":", "str", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "names", "=", "raw_input", ".", "split", "(", "' '", ")", "\n", "last_name", "=", "names", "[", "-", "1", ":", "]", "\n", "remaining", "=", "names", "[", ":", "-", "1", "]", "\n", "\n", "nb_names", "=", "len", "(", "names", ")", "\n", "full_name", "=", "remaining", "+", "[", "''", "]", "*", "(", "MAX_NB_NAMES", "-", "nb_names", ")", "+", "last_name", "\n", "\n", "label", "=", "[", "]", "\n", "\n", "for", "name", "in", "full_name", ":", "\n", "        ", "label", ".", "append", "(", "_transform_label_individual_name", "(", "name", ")", ")", "\n", "\n", "", "label", "=", "np", ".", "concatenate", "(", "label", ")", "\n", "\n", "# Assert cycle consistency", "\n", "assert", "raw_input", "==", "clean_pred_full_name", "(", "label", ".", "astype", "(", "int", ")", ",", "False", ")", "\n", "\n", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util.clean_pred_full_name": [[129, 171], ["numpy.array", "enumerate", "numpy.concatenate", "re.sub().strip", "names.append", "util.transform_label_full_name", "range", "sub_preds_reordered.extend", "sub_preds_reordered.append", "all", "sub_preds_reordered.append", "util._clean_pred_individual_name", "re.sub", "all", "Exception", "sub_pred_reordered.append", "len", "numpy.array", "numpy.array", "np.concatenate.astype", "range", "len"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util.transform_label_full_name", "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util._clean_pred_individual_name"], ["", "def", "clean_pred_full_name", "(", "raw_pred", ":", "np", ".", "ndarray", ",", "assert_consistency", ":", "bool", "=", "True", ")", "->", "str", ":", "\n", "    ", "sub_preds", "=", "[", "\n", "raw_pred", "[", "i", "*", "MAX_INDIVIDUAL_NAME_LEN", ":", "(", "i", "+", "1", ")", "*", "MAX_INDIVIDUAL_NAME_LEN", "]", "\n", "for", "i", "in", "range", "(", "MAX_NB_NAMES", ")", "\n", "]", "\n", "\n", "sub_preds_reordered", "=", "[", "]", "\n", "empty_name", "=", "np", ".", "array", "(", "[", "MISSING_INDICATOR", "]", "*", "MAX_INDIVIDUAL_NAME_LEN", ")", "\n", "\n", "for", "i", ",", "sub_pred", "in", "enumerate", "(", "sub_preds", ")", ":", "\n", "        ", "sub_pred_reordered", "=", "[", "]", "\n", "for", "element", "in", "sub_pred", ":", "\n", "            ", "if", "element", "!=", "MISSING_INDICATOR", ":", "\n", "                ", "sub_pred_reordered", ".", "append", "(", "element", ")", "\n", "", "", "sub_pred_reordered", "+=", "[", "MISSING_INDICATOR", "]", "*", "(", "MAX_INDIVIDUAL_NAME_LEN", "-", "len", "(", "sub_pred_reordered", ")", ")", "\n", "\n", "if", "i", "+", "1", "==", "MAX_NB_NAMES", ":", "\n", "            ", "sub_preds_reordered", ".", "extend", "(", "[", "empty_name", "for", "_", "in", "range", "(", "MAX_NB_NAMES", "-", "1", "-", "len", "(", "sub_preds_reordered", ")", ")", "]", ")", "\n", "sub_preds_reordered", ".", "append", "(", "np", ".", "array", "(", "sub_pred_reordered", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "all", "(", "sub_pred_reordered", "==", "empty_name", ")", ":", "\n", "                ", "continue", "\n", "", "sub_preds_reordered", ".", "append", "(", "np", ".", "array", "(", "sub_pred_reordered", ")", ")", "\n", "\n", "", "", "raw_pred_reordered", "=", "np", ".", "concatenate", "(", "sub_preds_reordered", ")", "\n", "\n", "names", "=", "[", "]", "\n", "\n", "for", "sub_pred", "in", "sub_preds_reordered", ":", "\n", "        ", "names", ".", "append", "(", "_clean_pred_individual_name", "(", "sub_pred", ",", "assert_consistency", ")", ")", "\n", "\n", "", "clean", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "' '", ".", "join", "(", "names", ")", ")", ".", "strip", "(", ")", "\n", "\n", "# Need to be cycle consistent - however, the function may be called from", "\n", "# `transform_label`, and we do not want infinite recursion, hence the if.", "\n", "if", "assert_consistency", ":", "\n", "        ", "transformed_clean", "=", "transform_label_full_name", "(", "clean", ")", "\n", "\n", "if", "not", "all", "(", "raw_pred_reordered", ".", "astype", "(", "'float'", ")", "==", "transformed_clean", ")", ":", "\n", "            ", "raise", "Exception", "(", "raw_pred", ",", "names", ",", "clean", ",", "transformed_clean", ")", "\n", "\n", "", "", "return", "clean", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util.transform_label_first_and_last_name": [[173, 191], ["raw_input.split", "numpy.concatenate", "np.concatenate.append", "util.clean_pred_first_and_last_name", "util._transform_label_individual_name", "np.concatenate.astype"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util.clean_pred_first_and_last_name", "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util._transform_label_individual_name"], ["", "def", "transform_label_first_and_last_name", "(", "raw_input", ":", "str", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "names", "=", "raw_input", ".", "split", "(", "' '", ")", "\n", "first_name", "=", "names", "[", "0", "]", "\n", "last_name", "=", "names", "[", "-", "1", "]", "\n", "\n", "mod_input", "=", "' '", ".", "join", "(", "(", "first_name", ",", "last_name", ")", ")", "\n", "\n", "label", "=", "[", "]", "\n", "\n", "for", "name", "in", "(", "first_name", ",", "last_name", ")", ":", "\n", "        ", "label", ".", "append", "(", "_transform_label_individual_name", "(", "name", ")", ")", "\n", "\n", "", "label", "=", "np", ".", "concatenate", "(", "label", ")", "\n", "\n", "# Assert cycle consistency", "\n", "assert", "mod_input", "==", "clean_pred_first_and_last_name", "(", "label", ".", "astype", "(", "int", ")", ",", "False", ")", "\n", "\n", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util.clean_pred_first_and_last_name": [[193, 225], ["numpy.concatenate", "sub_preds_reordered.append", "names.append", "util.transform_label_first_and_last_name", "range", "numpy.array", "util._clean_pred_individual_name", "all", "Exception", "sub_pred_reordered.append", "len", "np.concatenate.astype"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util.transform_label_first_and_last_name", "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util._clean_pred_individual_name"], ["", "def", "clean_pred_first_and_last_name", "(", "raw_pred", ":", "np", ".", "ndarray", ",", "assert_consistency", ":", "bool", "=", "True", ")", "->", "str", ":", "\n", "    ", "sub_preds", "=", "[", "\n", "raw_pred", "[", "i", "*", "MAX_INDIVIDUAL_NAME_LEN", ":", "(", "i", "+", "1", ")", "*", "MAX_INDIVIDUAL_NAME_LEN", "]", "\n", "for", "i", "in", "range", "(", "2", ")", "\n", "]", "\n", "\n", "sub_preds_reordered", "=", "[", "]", "\n", "\n", "for", "sub_pred", "in", "sub_preds", ":", "\n", "        ", "sub_pred_reordered", "=", "[", "]", "\n", "for", "element", "in", "sub_pred", ":", "\n", "            ", "if", "element", "!=", "MISSING_INDICATOR", ":", "\n", "                ", "sub_pred_reordered", ".", "append", "(", "element", ")", "\n", "", "", "sub_pred_reordered", "+=", "[", "MISSING_INDICATOR", "]", "*", "(", "MAX_INDIVIDUAL_NAME_LEN", "-", "len", "(", "sub_pred_reordered", ")", ")", "\n", "sub_preds_reordered", ".", "append", "(", "np", ".", "array", "(", "sub_pred_reordered", ")", ")", "\n", "\n", "", "raw_pred_reordered", "=", "np", ".", "concatenate", "(", "sub_preds_reordered", ")", "\n", "\n", "names", "=", "[", "]", "\n", "\n", "for", "sub_pred", "in", "sub_preds_reordered", ":", "\n", "        ", "names", ".", "append", "(", "_clean_pred_individual_name", "(", "sub_pred", ",", "assert_consistency", ")", ")", "\n", "\n", "", "clean", "=", "' '", ".", "join", "(", "names", ")", "\n", "\n", "if", "assert_consistency", ":", "\n", "        ", "transformed_clean", "=", "transform_label_first_and_last_name", "(", "clean", ")", "\n", "\n", "if", "not", "all", "(", "raw_pred_reordered", ".", "astype", "(", "'float'", ")", "==", "transformed_clean", ")", ":", "\n", "            ", "raise", "Exception", "(", "raw_pred", ",", "names", ",", "clean", ",", "transformed_clean", ")", "\n", "\n", "", "", "return", "clean", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util._rgetattr": [[293, 305], ["functools.reduce", "getattr", "attr.split"], "function", ["None"], ["", "", "def", "_rgetattr", "(", "obj", ",", "attr", ",", "*", "args", ")", ":", "\n", "# https://stackoverflow.com/questions/31174295/getattr-and-setattr-on-nested-subobjects-chained-properties", "\n", "# Simple way to retrieve attributes of attributes (i.e. solve the problem", "\n", "# of nested objects). Useful to freeze (and unfreeze) layers that consists", "\n", "# of other layers.", "\n", "# This way, a PART of a submodule can be frozen. For example, if a module", "\n", "# contains a submodule for feature extraction, a submodule of the feature", "\n", "# extraction submodule can be frozen (rather than only the entire feature", "\n", "# extraction submodule)", "\n", "    ", "def", "_getattr", "(", "obj", ",", "attr", ")", ":", "\n", "        ", "return", "getattr", "(", "obj", ",", "attr", ",", "*", "args", ")", "\n", "", "return", "functools", ".", "reduce", "(", "_getattr", ",", "[", "obj", "]", "+", "attr", ".", "split", "(", "'.'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util._setup_model_optimizer": [[307, 350], ["networks.constructor.SequenceNet().to", "torch.optim.SGD", "torch.optim.lr_scheduler.StepLR", "info.keys", "SequenceNet().to.load_state_dict", "SequenceNet().to.load_state_dict", "info.keys", "networks.constructor.SequenceNet", "torch.load", "torch.hub.load_state_dict_from_url", "print", "_rgetattr().parameters", "SequenceNet().to.parameters", "util._rgetattr"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.None.util._rgetattr"], ["", "def", "_setup_model_optimizer", "(", "\n", "info", ":", "dict", ",", "\n", "batch_size", ":", "int", ",", "\n", "epoch_len", ":", "int", ",", "\n", "device", ":", "torch", ".", "device", ",", "# pylint: disable=E1101", "\n", ")", "->", "dict", ":", "\n", "    ", "model", "=", "SequenceNet", "(", "\n", "feature_extractor", "=", "info", "[", "'feature_extractor'", "]", ",", "\n", "classifier", "=", "info", "[", "'classifier'", "]", ",", "\n", "output_sizes", "=", "info", "[", "'output_sizes'", "]", ",", "\n", ")", ".", "to", "(", "device", ")", "\n", "\n", "if", "'fn_pretrained'", "in", "info", ".", "keys", "(", ")", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "info", "[", "'fn_pretrained'", "]", ")", ",", "strict", "=", "False", ")", "\n", "", "if", "'url'", "in", "info", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "torch", ".", "hub", ".", "load_state_dict_from_url", "(", "info", "[", "'url'", "]", ")", ")", "\n", "\n", "", "if", "'to_freeze'", "in", "info", ".", "keys", "(", ")", ":", "\n", "        ", "for", "layer", "in", "info", "[", "'to_freeze'", "]", ":", "\n", "            ", "print", "(", "f'Freezing {layer}!'", ")", "\n", "params", "=", "_rgetattr", "(", "model", ",", "layer", ")", ".", "parameters", "(", ")", "\n", "for", "param", "in", "params", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "params", "=", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "info", "[", "'learning_rate'", "]", "*", "batch_size", "/", "256", ",", "\n", "momentum", "=", "0.9", ",", "\n", "weight_decay", "=", "0.0005", ",", "\n", "nesterov", "=", "True", ",", "\n", ")", "\n", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "\n", "optimizer", ",", "\n", "step_size", "=", "epoch_len", "//", "batch_size", "*", "info", "[", "'epochs_between_anneal'", "]", ",", "\n", "gamma", "=", "info", "[", "'anneal_rate'", "]", ",", "\n", ")", "\n", "\n", "return", "{", "\n", "'model'", ":", "model", ",", "\n", "'optimizer'", ":", "optimizer", ",", "\n", "'scheduler'", ":", "scheduler", ",", "\n", "'state_objects'", ":", "[", "'model'", ",", "'optimizer'", ",", "'scheduler'", "]", ",", "\n", "'step_objects'", ":", "[", "'optimizer'", ",", "'scheduler'", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.constructor.SequenceNet.__init__": [[86, 101], ["torch.nn.Module.__init__", "constructor._build_input_transform", "constructor._build_feature_extractor", "constructor._build_classifier"], "methods", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.RandAugment.__init__", "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.constructor._build_input_transform", "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.constructor._build_feature_extractor", "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.constructor._build_classifier"], ["    ", "def", "__init__", "(", "# pylint: disable=R0913", "\n", "self", ",", "\n", "feature_extractor", ":", "str", ",", "\n", "classifier", ":", "str", ",", "\n", "output_sizes", ":", "list", "or", "tuple", ",", "\n", "pretrained", ":", "bool", "=", "True", ",", "\n", "input_transform", ":", "str", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_transform", "=", "_build_input_transform", "(", "input_transform", ")", "\n", "self", ".", "feature_extractor", ",", "out_nodes", "=", "_build_feature_extractor", "(", "\n", "feature_extractor", ",", "pretrained", "\n", ")", "\n", "self", ".", "classifier", "=", "_build_classifier", "(", "classifier", ",", "out_nodes", ",", "output_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.constructor.SequenceNet.forward": [[102, 109], ["constructor.SequenceNet.feature_extractor", "constructor.SequenceNet.classifier", "constructor.SequenceNet.input_transform"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "# pylint: disable=W0221", "\n", "        ", "if", "self", ".", "input_transform", ":", "\n", "            ", "x", "=", "self", ".", "input_transform", "(", "x", ")", "\n", "", "x", "=", "self", ".", "feature_extractor", "(", "x", ")", "\n", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.constructor._build_feature_extractor": [[53, 61], ["isinstance", "builder", "FEATURE_EXTRACTORS.keys"], "function", ["None"], ["def", "_build_feature_extractor", "(", "feature_extractor", ":", "str", ",", "pretrained", ":", "bool", ")", ":", "\n", "    ", "assert", "feature_extractor", "in", "FEATURE_EXTRACTORS", ".", "keys", "(", ")", "\n", "assert", "isinstance", "(", "pretrained", ",", "bool", ")", "\n", "\n", "builder", "=", "FEATURE_EXTRACTORS", "[", "feature_extractor", "]", "\n", "model", "=", "builder", "(", "pretrained", "=", "pretrained", ")", "\n", "\n", "return", "model", ",", "model", ".", "fc", ".", "in_features", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.constructor._build_classifier": [[63, 69], ["builder", "CLASSIFIERS.keys"], "function", ["None"], ["", "def", "_build_classifier", "(", "classifier", ":", "str", ",", "input_size", ":", "int", ",", "output_sizes", ":", "list", "or", "tuple", ")", ":", "\n", "    ", "assert", "classifier", "in", "CLASSIFIERS", ".", "keys", "(", ")", "\n", "\n", "builder", "=", "CLASSIFIERS", "[", "classifier", "]", "\n", "\n", "return", "builder", "(", "input_size", "=", "input_size", ",", "output_sizes", "=", "output_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.constructor._build_input_transform": [[71, 83], ["INPUT_TRANSFORMS.keys", "builder"], "function", ["None"], ["", "def", "_build_input_transform", "(", "input_transform", ":", "str", ")", ":", "\n", "    ", "if", "input_transform", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "assert", "input_transform", "in", "INPUT_TRANSFORMS", ".", "keys", "(", ")", "\n", "\n", "builder", "=", "INPUT_TRANSFORMS", "[", "input_transform", "]", "\n", "\n", "if", "builder", "==", "'map-1-3'", ":", "\n", "        ", "return", "builder", "(", "1", ",", "3", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n", "", "return", "builder", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.constructor._load_model": [[111, 126], ["SequenceNet().to", "SequenceNet().to.eval", "SequenceNet().to.load_state_dict", "SequenceNet().to.load_state_dict", "constructor.SequenceNet", "torch.hub.load_state_dict_from_url", "torch.load", "networks.util.setup_functions.get_model_file"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.util.setup_functions.get_model_file"], ["", "", "def", "_load_model", "(", "model_name", ":", "str", ",", "root", ":", "str", ",", "info", ":", "dict", ",", "device", ":", "torch", ".", "device", ")", ":", "# pylint: disable=E1101", "\n", "    ", "model", "=", "SequenceNet", "(", "\n", "feature_extractor", "=", "info", "[", "'feature_extractor'", "]", ",", "\n", "classifier", "=", "info", "[", "'classifier'", "]", ",", "\n", "output_sizes", "=", "info", "[", "'output_sizes'", "]", ",", "\n", ")", ".", "to", "(", "device", ")", "\n", "\n", "if", "'url'", "in", "info", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "torch", ".", "hub", ".", "load_state_dict_from_url", "(", "info", "[", "'url'", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "get_model_file", "(", "root", ",", "model_name", ")", ")", ")", "\n", "\n", "", "model", ".", "eval", "(", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.constructor.load_models": [[128, 157], ["dict", "model_info.items", "constructor._load_model"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._load_model"], ["", "def", "load_models", "(", "model_info", ":", "dict", ",", "root", ":", "str", ",", "device", ":", "torch", ".", "device", ")", "->", "dict", ":", "# pylint: disable=E1101", "\n", "    ", "\"\"\"\n    Loads multiple trained models (must be of type SequenceNet) and puts them\n    in eval mode.\n\n    Parameters\n    ----------\n    model_info : dict\n        Dictionary with the names of the models as well as the info used to\n        construct them.\n    root : str\n        The directory in which the models are saved (they will be in the sub-\n        folder \"./logs/\"). If model_info contains URL to model weights, the\n        weights will be loaded from there instead.\n    device : torch.device\n        The device (CPU/GPU) on which to load the models.\n\n    Returns\n    -------\n    dict\n        Dictionary of (model name, model) pairs.\n\n    \"\"\"", "\n", "models", "=", "dict", "(", ")", "\n", "\n", "for", "model_name", ",", "info", "in", "model_info", ".", "items", "(", ")", ":", "\n", "        ", "models", "[", "model_name", "]", "=", "_load_model", "(", "model_name", ",", "root", ",", "info", ",", "device", ")", "\n", "\n", "", "return", "models", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences.__init__": [[29, 104], ["experiment.NetworkExperimentSequences._check_folders", "experiment.NetworkExperimentSequences._check_objects", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "models.keys"], "methods", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._check_folders", "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._check_objects"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ":", "torch", ".", "utils", ".", "data", ".", "dataloader", ".", "DataLoader", ",", "\n", "models", ":", "dict", ",", "\n", "loss_function", ":", "types", ".", "FunctionType", ",", "\n", "eval_loss", ":", "types", ".", "FunctionType", ",", "\n", "acc_function", ":", "types", ".", "FunctionType", ",", "\n", "epochs", ":", "int", ",", "\n", "log_interval", ":", "int", ",", "\n", "save_interval", ":", "int", ",", "\n", "root", ":", "str", ",", "\n", "device", ":", "torch", ".", "device", ",", "# pylint: disable=E1101", "\n", ")", ":", "\n", "        ", "''' Initializes the parameters of the network experiment.\n        params:\n            :: dataset: the torch data set training data is drawn from.\n            :: models: a dictionary of the models, including optimizer,\n               scheduler, info on state_objects, and step_objects.\n            :: loss_function: function that takes as inputs output, target\n               and returns a loss.\n            :: eval_loss: function used to track loss of validation data,\n               returning both the sequence loss (int) and individual digit\n               losses (list of ints).\n            :: acc_function: function that takes as inputs output, target\n               and returns a tuple of two elements, the first of which is\n               the overall accuracy of the sequence and the second is a list\n               of the individual accuracy for each element in the sequence.\n            :: epochs: the number of epochs to train each network. Note that\n               if 7 is given but a network has already been trained for 5\n               epochs, it is trained for an additional 7, resulting in 12\n               total epochs of training.\n            :: log_inverval: how often to log stats to tensorboard (in steps).\n            :: save_interval: how often to save model (in steps).\n            :: root: the \"root\" folder in which the subfolders with logs\n               are located.\n            :: device: whether to run on CPU or GPU.\n        '''", "\n", "\n", "assert", "(", "\n", "isinstance", "(", "dataset", ",", "torch", ".", "utils", ".", "data", ".", "dataloader", ".", "DataLoader", ")", "\n", "and", "isinstance", "(", "models", ",", "dict", ")", "\n", "and", "isinstance", "(", "loss_function", ",", "types", ".", "FunctionType", ")", "\n", "and", "isinstance", "(", "acc_function", ",", "types", ".", "FunctionType", ")", "\n", "and", "isinstance", "(", "eval_loss", ",", "types", ".", "FunctionType", ")", "\n", "and", "isinstance", "(", "epochs", ",", "int", ")", "\n", "and", "epochs", ">", "0", "\n", "and", "isinstance", "(", "log_interval", ",", "int", ")", "\n", "and", "log_interval", ">", "0", "\n", "and", "isinstance", "(", "save_interval", ",", "int", ")", "\n", "and", "save_interval", ">", "0", "\n", "and", "isinstance", "(", "device", ",", "torch", ".", "device", ")", "# pylint: disable=E1101", "\n", ")", "\n", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "models", "=", "models", "\n", "self", ".", "loss_function", "=", "loss_function", "\n", "self", ".", "acc_function", "=", "acc_function", "\n", "self", ".", "eval_loss", "=", "eval_loss", "# if eval_loss is not None else loss_function", "\n", "\n", "self", ".", "epochs", "=", "epochs", "\n", "self", ".", "log_interval", "=", "log_interval", "\n", "self", ".", "save_interval", "=", "save_interval", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "device", "=", "device", "\n", "\n", "self", ".", "log_folders", "=", "{", "x", ":", "f'{root}/logs/{x}/'", "for", "x", "in", "models", ".", "keys", "(", ")", "}", "\n", "\n", "self", ".", "_check_folders", "(", ")", "\n", "self", ".", "_check_objects", "(", ")", "\n", "\n", "self", ".", "info", "=", "None", "\n", "self", ".", "test_split", "=", "None", "\n", "self", ".", "nb_test_obs", "=", "None", "\n", "self", ".", "running_losses", "=", "None", "\n", "self", ".", "log_test_results", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._check_folders": [[105, 113], ["os.path.exists", "print", "os.makedirs"], "methods", ["None"], ["", "def", "_check_folders", "(", "self", ")", ":", "\n", "        ", "'''Verifies that the needed folders for logs and saves exist. If not,\n        makes them.\n        '''", "\n", "for", "key", "in", "self", ".", "log_folders", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "log_folders", "[", "key", "]", ")", ":", "\n", "                ", "print", "(", "f'Folder {self.log_folders[key]} missing! Making it.'", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "log_folders", "[", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._check_objects": [[114, 126], ["experiment.NetworkExperimentSequences.models[].keys", "experiment.NetworkExperimentSequences.models[].keys", "experiment.NetworkExperimentSequences.models[].keys", "experiment.NetworkExperimentSequences.models[].keys"], "methods", ["None"], ["", "", "", "def", "_check_objects", "(", "self", ")", ":", "\n", "        ", "''' Verifies that if a model, for example, specifies that the\n        scheduler is an object on which .step() should be performed that a\n        scheduler actually exists.\n        '''", "\n", "for", "model_name", "in", "self", ".", "models", ":", "\n", "            ", "if", "'state_objects'", "in", "self", ".", "models", "[", "model_name", "]", ".", "keys", "(", ")", ":", "\n", "                ", "for", "key", "in", "self", ".", "models", "[", "model_name", "]", "[", "'state_objects'", "]", ":", "\n", "                    ", "assert", "key", "in", "self", ".", "models", "[", "model_name", "]", ".", "keys", "(", ")", "\n", "", "", "if", "'step_objects'", "in", "self", ".", "models", "[", "model_name", "]", ".", "keys", "(", ")", ":", "\n", "                ", "for", "key", "in", "self", ".", "models", "[", "model_name", "]", "[", "'step_objects'", "]", ":", "\n", "                    ", "assert", "key", "in", "self", ".", "models", "[", "model_name", "]", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._save_model": [[127, 154], ["json.dump", "torch.save", "open", "[].state_dict"], "methods", ["None"], ["", "", "", "", "def", "_save_model", "(", "self", ",", "model_name", ")", ":", "\n", "        ", "''' Saves all things related to model, including (if relevant)\n        the optimizer's and scheduler's state. Also some meta information,\n        so we know the current epoch and the current step.\n        '''", "\n", "# object holds a subset of the keys in self.models[model_name],", "\n", "# specifically those that have an associates state_dict, such as", "\n", "# the model, the optimizer, and the scheduler. This way, everything", "\n", "# that shall be saved thus can be saved thus.", "\n", "state_objects", "=", "self", ".", "models", "[", "model_name", "]", "[", "'state_objects'", "]", "\n", "\n", "epoch", "=", "self", ".", "info", "[", "model_name", "]", "[", "'epoch'", "]", "\n", "step", "=", "self", ".", "info", "[", "model_name", "]", "[", "'step'", "]", "\n", "\n", "meta_info", "=", "{", "\n", "'state_objects'", ":", "state_objects", ",", "\n", "'epoch'", ":", "epoch", ",", "\n", "'step'", ":", "step", ",", "\n", "}", "\n", "\n", "for", "key", "in", "state_objects", ":", "\n", "            ", "file", "=", "f'{self.log_folders[model_name]}{key}_{step}.pt'", "\n", "torch", ".", "save", "(", "self", ".", "models", "[", "model_name", "]", "[", "key", "]", ".", "state_dict", "(", ")", ",", "file", ")", "\n", "\n", "", "json", ".", "dump", "(", "\n", "meta_info", ",", "\n", "open", "(", "f'{self.log_folders[model_name]}meta_info.json'", ",", "'w'", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._load_model": [[156, 180], ["os.path.isfile", "print", "json.load", "print", "open", "[].load_state_dict", "torch.load"], "methods", ["None"], ["", "def", "_load_model", "(", "self", ",", "model_name", ")", ":", "\n", "        ", "''' Loads all things related to model, including (if relevant)\n        the optimizer's and scheduler's state. Starts from the newest epoch\n        where all information is saved (which fixes the case of a crash\n        occurring during a save that results in a model's state being saved\n        but an optimizer's state not being saved.)\n        '''", "\n", "file_meta_info", "=", "f'{self.log_folders[model_name]}meta_info.json'", "\n", "if", "os", ".", "path", ".", "isfile", "(", "file_meta_info", ")", ":", "\n", "            ", "print", "(", "f'Loading {model_name}.'", ")", "\n", "meta_info", "=", "json", ".", "load", "(", "open", "(", "file_meta_info", ",", "'rb'", ")", ")", "\n", "\n", "state_objects", "=", "meta_info", "[", "'state_objects'", "]", "\n", "epoch", "=", "meta_info", "[", "'epoch'", "]", "\n", "step", "=", "meta_info", "[", "'step'", "]", "\n", "\n", "for", "key", "in", "state_objects", ":", "\n", "                ", "file", "=", "f'{self.log_folders[model_name]}{key}_{step}.pt'", "\n", "self", ".", "models", "[", "model_name", "]", "[", "key", "]", ".", "load_state_dict", "(", "torch", ".", "load", "(", "file", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "f'Nothing to load for {model_name}; initializing.'", ")", "\n", "epoch", ",", "step", "=", "0", ",", "0", "# no training done yet; start from zero.", "\n", "\n", "", "return", "epoch", ",", "step", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._setup_tensorboard": [[181, 201], ["[].cpu", "[].eval", "torch.utils.tensorboard.SummaryWriter", "torch.utils.tensorboard.SummaryWriter.flush", "[].to", "torch.utils.tensorboard.SummaryWriter.add_graph", "x_train.float"], "methods", ["None"], ["", "def", "_setup_tensorboard", "(", "self", ",", "model_name", ",", "x_train", ",", "step", ")", ":", "\n", "        ", "''' Setup a tensorboard writer for each model, including creating\n        a graph.\n        '''", "\n", "self", ".", "models", "[", "model_name", "]", "[", "'model'", "]", ".", "cpu", "(", ")", "\n", "self", ".", "models", "[", "model_name", "]", "[", "'model'", "]", ".", "eval", "(", ")", "\n", "\n", "writer", "=", "SummaryWriter", "(", "log_dir", "=", "self", ".", "log_folders", "[", "model_name", "]", ")", "\n", "\n", "if", "step", "==", "0", ":", "\n", "            ", "writer", ".", "add_graph", "(", "# NOTE: This is potentially VERY slow (due to cpu). Also, test if `with torch.no_grad` is fine here", "\n", "self", ".", "models", "[", "model_name", "]", "[", "'model'", "]", ",", "\n", "input_to_model", "=", "(", "x_train", ".", "float", "(", ")", ")", ",", "\n", "verbose", "=", "False", ",", "\n", ")", "\n", "", "writer", ".", "flush", "(", ")", "\n", "\n", "self", ".", "models", "[", "model_name", "]", "[", "'model'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "return", "writer", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._setup": [[202, 228], ["next", "dict", "experiment.NetworkExperimentSequences.models.keys", "min", "iter", "experiment.NetworkExperimentSequences._load_model", "min.append", "experiment.NetworkExperimentSequences._setup_tensorboard", "[].train"], "methods", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._load_model", "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._setup_tensorboard", "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.train.train"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "        ", "''' Setup the models, such as retrieving information on current\n        epoch and step as well as set up writers.\n        '''", "\n", "data", "=", "next", "(", "iter", "(", "self", ".", "dataset", ")", ")", "\n", "x_train", "=", "data", "[", "'image'", "]", "[", ":", "1", "]", "\n", "self", ".", "info", "=", "dict", "(", ")", "\n", "\n", "start_epoch", "=", "[", "]", "\n", "\n", "for", "model_name", "in", "self", ".", "models", ".", "keys", "(", ")", ":", "\n", "            ", "epoch", ",", "step", "=", "self", ".", "_load_model", "(", "model_name", ")", "\n", "start_epoch", ".", "append", "(", "epoch", ")", "\n", "writer", "=", "self", ".", "_setup_tensorboard", "(", "model_name", ",", "x_train", ",", "step", ")", "\n", "\n", "self", ".", "info", "[", "model_name", "]", "=", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'step'", ":", "step", ",", "\n", "'writer'", ":", "writer", ",", "\n", "}", "\n", "\n", "self", ".", "models", "[", "model_name", "]", "[", "'model'", "]", ".", "train", "(", ")", "\n", "\n", "", "start_epoch", "=", "min", "(", "start_epoch", ")", "\n", "\n", "return", "start_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._write_loss_tb": [[229, 241], ["[].add_scalar", "enumerate", "[].add_scalar", "[].add_scalar"], "methods", ["None"], ["", "def", "_write_loss_tb", "(", "self", ",", "model_name", ",", "step", ",", "prefix", ",", "seq_loss", ",", "losses", ")", ":", "\n", "        ", "''' Writes a loss (a scalar) to tensorboard for specific model. '''", "\n", "if", "losses", ":", "\n", "            ", "self", ".", "info", "[", "model_name", "]", "[", "'writer'", "]", ".", "add_scalar", "(", "\n", "f'{prefix}/Losses/Loss'", ",", "seq_loss", ",", "step", ",", "\n", ")", "\n", "for", "i", ",", "loss", "in", "enumerate", "(", "losses", ")", ":", "\n", "                ", "self", ".", "info", "[", "model_name", "]", "[", "'writer'", "]", ".", "add_scalar", "(", "\n", "f'{prefix}/Losses/\"Digit\" {i} loss'", ",", "loss", ",", "step", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "info", "[", "model_name", "]", "[", "'writer'", "]", ".", "add_scalar", "(", "f'{prefix}/Losses/Loss'", ",", "seq_loss", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._write_acc_tb": [[242, 250], ["[].add_scalar", "enumerate", "[].add_scalar"], "methods", ["None"], ["", "", "def", "_write_acc_tb", "(", "self", ",", "model_name", ",", "step", ",", "prefix", ",", "seq_acc", ",", "accs", ")", ":", "\n", "        ", "''' Writes accuracies (scalars) to tensorboard for specific model. '''", "\n", "self", ".", "info", "[", "model_name", "]", "[", "'writer'", "]", ".", "add_scalar", "(", "\n", "f'{prefix}/Accuracies/Accuracy'", ",", "seq_acc", ",", "step", ",", "\n", ")", "\n", "for", "i", ",", "acc", "in", "enumerate", "(", "accs", ")", ":", "\n", "            ", "self", ".", "info", "[", "model_name", "]", "[", "'writer'", "]", ".", "add_scalar", "(", "\n", "f'{prefix}/Accuracies/\"Digit\" {i} accuracy'", ",", "acc", ",", "step", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._write_tb": [[252, 255], ["experiment.NetworkExperimentSequences._write_loss_tb", "experiment.NetworkExperimentSequences._write_acc_tb"], "methods", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._write_loss_tb", "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._write_acc_tb"], ["", "", "def", "_write_tb", "(", "self", ",", "model_name", ",", "step", ",", "prefix", ",", "seq_acc", ",", "accs", ",", "seq_loss", ",", "losses", "=", "None", ")", ":", "\n", "        ", "self", ".", "_write_loss_tb", "(", "model_name", ",", "step", ",", "prefix", ",", "seq_loss", ",", "losses", ")", "\n", "self", ".", "_write_acc_tb", "(", "model_name", ",", "step", ",", "prefix", ",", "seq_acc", ",", "accs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._train_step": [[256, 270], ["[].zero_grad", "experiment.NetworkExperimentSequences.loss_function", "experiment.NetworkExperimentSequences.backward", "experiment.NetworkExperimentSequences.item", "[].step"], "methods", ["None"], ["", "def", "_train_step", "(", "self", ",", "model_name", ",", "x_train", ",", "y_train", ")", ":", "\n", "        ", "''' Performs a single training step for a sigle model, i.e.\n        forward -> loss -> backward -> steps.\n        '''", "\n", "self", ".", "models", "[", "model_name", "]", "[", "'optimizer'", "]", ".", "zero_grad", "(", ")", "\n", "\n", "yhat", "=", "self", ".", "models", "[", "model_name", "]", "[", "'model'", "]", "(", "x_train", ")", "\n", "loss", "=", "self", ".", "loss_function", "(", "yhat", "=", "yhat", ",", "y", "=", "y_train", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "for", "step_object", "in", "self", ".", "models", "[", "model_name", "]", "[", "'step_objects'", "]", ":", "\n", "            ", "self", ".", "models", "[", "model_name", "]", "[", "step_object", "]", ".", "step", "(", ")", "\n", "\n", "", "return", "loss", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._print_run_info": [[271, 285], ["print", "len", "len"], "methods", ["None"], ["", "def", "_print_run_info", "(", "self", ")", ":", "\n", "        ", "print", "(", "\n", "f'''\nTraining {len(self.models)} models for {self.epochs} epochs,\neach epoch lasting {len(self.dataset)} steps with batch size\n{self.dataset.batch_size}.\n\nDirectory: {self.root}.\n\nLogging every {self.log_interval} step.\nLogging test results: {self.log_test_results}.\n\nSaving every {self.save_interval} step.\n            '''", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._log": [[287, 350], ["torch.no_grad", "[].eval", "experiment.NetworkExperimentSequences.acc_function", "experiment.NetworkExperimentSequences._write_tb", "[].train", "experiment.NetworkExperimentSequences._write_tb", "len", "experiment.NetworkExperimentSequences.eval_loss", "experiment.NetworkExperimentSequences.acc_function", "seq_loss_test_list.append", "losses_test_list.append", "seq_acc_test_list.append", "accs_test_list.append", "sum", "sum", "x_test_batch.to().float", "sum", "range", "sum", "range", "y_test_batch.to().long", "y_test_batch.to().long", "len", "len", "x_test_batch.to", "y_test_batch.to", "y_test_batch.to"], "methods", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._write_tb", "home.repos.pwc.inspect_result.torbensdjohansen_hana.None.train.train", "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._write_tb"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_log", "(", "self", ",", "model_name", ",", "x_train", ",", "y_train", ")", ":", "\n", "        ", "self", ".", "models", "[", "model_name", "]", "[", "'model'", "]", ".", "eval", "(", ")", "\n", "\n", "# with torch.no_grad():", "\n", "yhat", "=", "self", ".", "models", "[", "model_name", "]", "[", "'model'", "]", "(", "x_train", ")", "\n", "seq_acc", ",", "accs", "=", "self", ".", "acc_function", "(", "yhat", "=", "yhat", ",", "y", "=", "y_train", ")", "\n", "self", ".", "_write_tb", "(", "\n", "model_name", "=", "model_name", ",", "\n", "step", "=", "self", ".", "info", "[", "model_name", "]", "[", "'step'", "]", ",", "\n", "prefix", "=", "'Train'", ",", "\n", "seq_acc", "=", "seq_acc", ",", "\n", "accs", "=", "accs", ",", "\n", "seq_loss", "=", "self", ".", "running_losses", "[", "model_name", "]", ",", "\n", ")", "\n", "\n", "if", "self", ".", "log_test_results", ":", "\n", "            ", "seq_loss_test_list", "=", "[", "]", "\n", "losses_test_list", "=", "[", "]", "\n", "seq_acc_test_list", "=", "[", "]", "\n", "accs_test_list", "=", "[", "]", "\n", "\n", "for", "x_test_batch", ",", "y_test_batch", "in", "self", ".", "test_split", ":", "\n", "                ", "batch_size", "=", "len", "(", "x_test_batch", ")", "\n", "\n", "yhat_test_batch", "=", "self", ".", "models", "[", "model_name", "]", "[", "'model'", "]", "(", "\n", "x_test_batch", ".", "to", "(", "self", ".", "device", ")", ".", "float", "(", ")", "\n", ")", "\n", "seq_loss_test_batch", ",", "losses_test_batch", "=", "self", ".", "eval_loss", "(", "\n", "yhat", "=", "yhat_test_batch", ",", "y", "=", "y_test_batch", ".", "to", "(", "self", ".", "device", ")", ".", "long", "(", ")", "\n", ")", "\n", "seq_acc_test_batch", ",", "accs_test_batch", "=", "self", ".", "acc_function", "(", "\n", "yhat", "=", "yhat_test_batch", ",", "y", "=", "y_test_batch", ".", "to", "(", "self", ".", "device", ")", ".", "long", "(", ")", ")", "\n", "\n", "seq_loss_test_list", ".", "append", "(", "batch_size", "*", "seq_loss_test_batch", ")", "\n", "losses_test_list", ".", "append", "(", "[", "x", "*", "batch_size", "for", "x", "in", "losses_test_batch", "]", ")", "\n", "\n", "seq_acc_test_list", ".", "append", "(", "batch_size", "*", "seq_acc_test_batch", ")", "\n", "accs_test_list", ".", "append", "(", "[", "x", "*", "batch_size", "for", "x", "in", "accs_test_batch", "]", ")", "\n", "\n", "", "seq_loss_test", "=", "sum", "(", "seq_loss_test_list", ")", "/", "self", ".", "nb_test_obs", "\n", "losses_test", "=", "[", "\n", "sum", "(", "[", "x", "[", "i", "]", "for", "x", "in", "losses_test_list", "]", ")", "/", "self", ".", "nb_test_obs", "\n", "for", "i", "in", "range", "(", "len", "(", "yhat_test_batch", ")", ")", "\n", "]", "\n", "\n", "seq_acc_test", "=", "sum", "(", "seq_acc_test_list", ")", "/", "self", ".", "nb_test_obs", "\n", "accs_test", "=", "[", "\n", "sum", "(", "[", "x", "[", "i", "]", "for", "x", "in", "accs_test_list", "]", ")", "/", "self", ".", "nb_test_obs", "\n", "for", "i", "in", "range", "(", "len", "(", "yhat_test_batch", ")", ")", "\n", "]", "\n", "\n", "self", ".", "_write_tb", "(", "\n", "model_name", "=", "model_name", ",", "\n", "step", "=", "self", ".", "info", "[", "model_name", "]", "[", "'step'", "]", ",", "\n", "prefix", "=", "'Test'", ",", "\n", "seq_acc", "=", "seq_acc_test", ",", "\n", "accs", "=", "accs_test", ",", "\n", "seq_loss", "=", "seq_loss_test", ",", "\n", "losses", "=", "losses_test", ",", "\n", ")", "\n", "\n", "", "self", ".", "models", "[", "model_name", "]", "[", "'model'", "]", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._run_model_step": [[351, 366], ["experiment.NetworkExperimentSequences._train_step", "experiment.NetworkExperimentSequences._log", "experiment.NetworkExperimentSequences._save_model"], "methods", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._train_step", "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._log", "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._save_model"], ["", "def", "_run_model_step", "(", "self", ",", "model_name", ",", "x_train", ",", "y_train", ",", "step", ")", ":", "\n", "        ", "loss", "=", "self", ".", "_train_step", "(", "model_name", ",", "x_train", ",", "y_train", ")", "\n", "\n", "self", ".", "running_losses", "[", "model_name", "]", "=", "(", "\n", "(", "self", ".", "running_losses", "[", "model_name", "]", "*", "(", "step", "-", "1", ")", "+", "loss", ")", "/", "step", "\n", ")", "\n", "self", ".", "info", "[", "model_name", "]", "[", "'step'", "]", "+=", "1", "\n", "\n", "# TODO maybe also always write on step == 1 (useful to check start!).", "\n", "# Or even write on step 0 - i.e. before first train step", "\n", "if", "self", ".", "info", "[", "model_name", "]", "[", "'step'", "]", "%", "self", ".", "log_interval", "==", "0", ":", "\n", "            ", "self", ".", "_log", "(", "model_name", ",", "x_train", ",", "y_train", ")", "\n", "\n", "", "if", "self", ".", "info", "[", "model_name", "]", "[", "'step'", "]", "%", "self", ".", "save_interval", "==", "0", ":", "\n", "            ", "self", ".", "_save_model", "(", "model_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences.run": [[367, 403], ["experiment.NetworkExperimentSequences._print_run_info", "experiment.NetworkExperimentSequences._setup", "range", "experiment.NetworkExperimentSequences.models.keys", "networks.util.pytorch_functions.split_data", "experiment.NetworkExperimentSequences._save_model", "print", "enumerate", "experiment.NetworkExperimentSequences.models.keys", "data[].to().float", "data[].to().long", "experiment.NetworkExperimentSequences.models.keys", "experiment.NetworkExperimentSequences.models.keys", "experiment.NetworkExperimentSequences._run_model_step", "data[].to", "data[].to"], "methods", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._print_run_info", "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._setup", "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_functions.split_data", "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._save_model", "home.repos.pwc.inspect_result.torbensdjohansen_hana.networks.experiment.NetworkExperimentSequences._run_model_step"], ["", "", "def", "run", "(", "self", ",", "test_data", "=", "None", ")", ":", "\n", "        ", "''' Only \"public\" method, which runs the experiment. If test data is\n        provided, it logs the test losses.\n        Training losses are averaged over the epoch and always logged.\n        '''", "\n", "self", ".", "log_test_results", "=", "test_data", "is", "not", "None", "\n", "\n", "if", "self", ".", "log_test_results", ":", "\n", "            ", "self", ".", "test_split", ",", "self", ".", "nb_test_obs", "=", "split_data", "(", "\n", "data", "=", "test_data", ",", "\n", "batch_size", "=", "self", ".", "dataset", ".", "batch_size", ",", "\n", ")", "\n", "del", "test_data", "\n", "\n", "", "self", ".", "_print_run_info", "(", ")", "\n", "start_epoch", "=", "self", ".", "_setup", "(", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "self", ".", "epochs", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "print", "(", "f'Starting epoch {epoch + 1} of {self.epochs}'", ")", "\n", "self", ".", "running_losses", "=", "{", "model_name", ":", "0", "for", "model_name", "in", "self", ".", "models", ".", "keys", "(", ")", "}", "\n", "\n", "for", "step", ",", "data", "in", "enumerate", "(", "self", ".", "dataset", ",", "start", "=", "1", ")", ":", "\n", "                    ", "x_train", "=", "data", "[", "'image'", "]", ".", "to", "(", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "y_train", "=", "data", "[", "'label'", "]", ".", "to", "(", "self", ".", "device", ")", ".", "long", "(", ")", "\n", "\n", "for", "model_name", "in", "self", ".", "models", ".", "keys", "(", ")", ":", "\n", "                        ", "self", ".", "_run_model_step", "(", "model_name", ",", "x_train", ",", "y_train", ",", "step", ")", "\n", "\n", "", "", "for", "model_name", "in", "self", ".", "models", ".", "keys", "(", ")", ":", "\n", "                    ", "self", ".", "info", "[", "model_name", "]", "[", "'epoch'", "]", "+=", "1", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "                ", "break", "\n", "\n", "", "", "for", "model_name", "in", "self", ".", "models", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "_save_model", "(", "model_name", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_functions.sequence_loss": [[13, 16], ["len", "sum", "torch.nn.functional.nll_loss", "range"], "function", ["None"], ["def", "sequence_loss", "(", "yhat", ",", "y", ")", ":", "\n", "    ", "k", "=", "len", "(", "yhat", ")", "\n", "return", "sum", "(", "[", "nll_loss", "(", "yhat", "[", "i", "]", ",", "y", "[", ":", ",", "i", "]", ")", "for", "i", "in", "range", "(", "k", ")", "]", ")", "/", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_functions.sequence_loss_eval": [[18, 22], ["len", "torch.nn.functional.nll_loss().item", "range", "sum", "torch.nn.functional.nll_loss"], "function", ["None"], ["", "def", "sequence_loss_eval", "(", "yhat", ",", "y", ")", ":", "\n", "    ", "k", "=", "len", "(", "yhat", ")", "\n", "losses", "=", "[", "nll_loss", "(", "yhat", "[", "i", "]", ",", "y", "[", ":", ",", "i", "]", ")", ".", "item", "(", ")", "for", "i", "in", "range", "(", "k", ")", "]", "\n", "return", "sum", "(", "losses", ")", "/", "k", ",", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_functions.sequence_acc": [[24, 43], ["range", "len", "torch.argmax", "y_current.eq().sum().double", "accs.append", "status.append", "sum", "len", "len", "acc_current.item", "y_current.eq().sum", "all", "range", "y_current.eq", "len", "range", "len"], "function", ["None"], ["", "def", "sequence_acc", "(", "yhat", ",", "y", ")", ":", "\n", "    ", "accs", "=", "[", "]", "\n", "status", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "yhat", ")", ")", ":", "\n", "        ", "yhat_current", "=", "torch", ".", "argmax", "(", "yhat", "[", "i", "]", ",", "dim", "=", "1", ")", "# pylint: disable=E1101", "\n", "y_current", "=", "y", "[", ":", ",", "i", "]", "\n", "\n", "nb_correct", "=", "(", "y_current", ".", "eq", "(", "yhat_current", ")", ")", ".", "sum", "(", ")", ".", "double", "(", ")", "\n", "acc_current", "=", "nb_correct", "/", "len", "(", "y_current", ")", "\n", "\n", "accs", ".", "append", "(", "acc_current", ".", "item", "(", ")", ")", "\n", "status", ".", "append", "(", "y_current", "==", "yhat_current", ")", "\n", "\n", "", "seq_acc", "=", "sum", "(", "\n", "[", "all", "(", "[", "status", "[", "j", "]", "[", "i", "]", "for", "j", "in", "range", "(", "len", "(", "yhat", ")", ")", "]", ")", "for", "i", "in", "range", "(", "len", "(", "y", ")", ")", "]", "\n", ")", "/", "len", "(", "y", ")", "\n", "\n", "return", "seq_acc", ",", "accs", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_functions.split_data": [[45, 56], ["torch.split", "torch.split", "len", "tuple", "zip"], "function", ["None"], ["", "def", "split_data", "(", "data", ":", "dict", ",", "batch_size", ":", "int", ")", ":", "\n", "    ", "''' Splits data to batches. '''", "\n", "images", "=", "data", "[", "'image'", "]", "\n", "labels", "=", "data", "[", "'label'", "]", "\n", "\n", "images_split", "=", "torch", ".", "split", "(", "images", ",", "batch_size", ")", "\n", "labels_split", "=", "torch", ".", "split", "(", "labels", ",", "batch_size", ")", "\n", "\n", "nb_obs", "=", "len", "(", "labels", ")", "\n", "\n", "return", "tuple", "(", "zip", "(", "images_split", ",", "labels_split", ")", ")", ",", "nb_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_functions.predict_sequence": [[58, 169], ["torch.no_grad", "isinstance", "models.values", "print", "range", "probabilities.items", "range", "numpy.prod", "numpy.concatenate", "isinstance", "print", "enumerate", "len", "len", "numpy.concatenate", "models.keys", "range", "models.items", "range", "len", "print", "model", "probabilities[].append", "np.concatenate.append", "locals", "numpy.concatenate", "len", "numpy.concatenate", "batch[].to().float", "torch.nn.functional.softmax", "np.concatenate.append", "range", "numpy.argmax", "numpy.max", "p.cpu().detach().numpy", "batch[].numpy", "len", "len", "batch[].to", "range", "range", "p.cpu().detach", "len", "len", "p.cpu"], "function", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "predict_sequence", "(", "\n", "models", ":", "dict", ",", "\n", "dataset", ":", "torch", ".", "utils", ".", "data", ".", "DataLoader", ",", "\n", "device", ":", "torch", ".", "device", ",", "# pylint: disable=E1101", "\n", "retrieve_labels", ":", "bool", ",", "\n", "nb_passes", ":", "int", "=", "1", ",", "\n", ")", "->", "(", "np", ".", "ndarray", ",", "np", ".", "ndarray", ",", "np", ".", "ndarray", ",", "np", ".", "ndarray", "or", "list", ")", ":", "\n", "    ", "\"\"\"\n    Obtain the predictions of one or more models on a dataset as well as the\n    estimated probabilities of the entire sequence (assuming independence, i.e.\n    estimated as the product on digit probabilities). Iterates over batches of\n    a data loader and allows for device management. If multiple models are\n    passed as input, averages the probabilities (BEFORE estimating sequence\n    probability).\n\n    Parameters\n    ----------\n    model : dict\n        Dictionary of (model name, neural network) used to predict. If more\n        than one (key, value) pair, simple average is used as ensemble.\n    data : torch.utils.data.DataLoader\n        DataLoader to iterate over for batches.\n    device : torch.device\n        The device to perform the predictions on (CPU/GPU). Note that the model\n        must also be present on that device.\n    retrieve_labels : bool\n        Whether to retrieve the labels from the DataLoader. Note that these may\n        not always exist, hence the option NOT to retrieve labels.\n    nb_passes : int\n        Number of passes of the observation to iterate over. Only makes sense\n        to perform multiple passes when the pipe introduces noise. The default\n        is 1.\n\n    Returns\n    -------\n    preds : np.ndarray\n        Array of shape (number of observations, length of sequence) with the\n        predictions for each element in each sequence.\n    seq_prob : np.ndarray\n        Array of shape (number of observations,) with the estimated certainty\n        of the specific prediction, calculated as the product of the\n        certainties of the predictions of the individual elements of the\n        sequence.\n    files : np.ndarray\n        Array of shape (number of observations,) with the filenames, including\n        the full path to the file.\n    labels : np.ndarray or empty list\n        Array of shape (number of observations,) with labels or, provided\n        `retrieve_labels` is False, an empty list.\n\n    \"\"\"", "\n", "assert", "isinstance", "(", "dataset", ".", "sampler", ",", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "SequentialSampler", ")", "\n", "assert", "isinstance", "(", "nb_passes", ",", "int", ")", "and", "nb_passes", ">", "0", "\n", "\n", "for", "model", "in", "models", ".", "values", "(", ")", ":", "\n", "        ", "assert", "not", "model", ".", "training", "\n", "\n", "", "probabilities", "=", "{", "f'{k}_{i}'", ":", "[", "]", "for", "k", "in", "models", ".", "keys", "(", ")", "for", "i", "in", "range", "(", "nb_passes", ")", "}", "\n", "files", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "\n", "print", "(", "f'Performing predictions by averaging across {len(models)} models and {nb_passes} passes!'", ")", "\n", "\n", "for", "current_pass", "in", "range", "(", "nb_passes", ")", ":", "\n", "        ", "print", "(", "f'Starting pass {current_pass + 1} of {nb_passes} passes.'", ")", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "dataset", ",", "start", "=", "1", ")", ":", "\n", "\n", "            ", "if", "i", "%", "10", "==", "0", ":", "\n", "                ", "print", "(", "f'Predicting on batch {i} of {len(dataset)}.'", ")", "\n", "\n", "", "for", "model_name", ",", "model", "in", "models", ".", "items", "(", ")", ":", "\n", "                ", "yhat_batch", "=", "model", "(", "batch", "[", "'image'", "]", ".", "to", "(", "device", ")", ".", "float", "(", ")", ")", "\n", "prob", "=", "[", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "x", ",", "dim", "=", "1", ")", "for", "x", "in", "yhat_batch", "]", "\n", "probabilities", "[", "f'{model_name}_{current_pass}'", "]", ".", "append", "(", "\n", "[", "p", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "for", "p", "in", "prob", "]", "\n", ")", "\n", "\n", "", "if", "current_pass", "==", "0", ":", "\n", "                ", "files", ".", "append", "(", "batch", "[", "'fname'", "]", ")", "\n", "\n", "if", "retrieve_labels", ":", "\n", "                    ", "labels", ".", "append", "(", "batch", "[", "'label'", "]", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "", "", "for", "model_name_i", ",", "probs", "in", "probabilities", ".", "items", "(", ")", ":", "\n", "        ", "if", "not", "'probabilities_flat'", "in", "locals", "(", ")", ":", "\n", "            ", "probabilities_flat", "=", "[", "np", ".", "concatenate", "(", "\n", "[", "probs", "[", "i", "]", "[", "j", "]", "for", "i", "in", "range", "(", "len", "(", "probs", ")", ")", "]", "\n", ")", "for", "j", "in", "range", "(", "len", "(", "probs", "[", "0", "]", ")", ")", "]", "\n", "", "else", ":", "\n", "            ", "for", "j", "in", "range", "(", "len", "(", "probs", "[", "0", "]", ")", ")", ":", "\n", "                ", "probabilities_flat", "[", "j", "]", "+=", "np", ".", "concatenate", "(", "\n", "[", "probs", "[", "i", "]", "[", "j", "]", "for", "i", "in", "range", "(", "len", "(", "probs", ")", ")", "]", "\n", ")", "\n", "# note probs from prior loop", "\n", "", "", "", "for", "j", "in", "range", "(", "len", "(", "probs", "[", "0", "]", ")", ")", ":", "\n", "        ", "probabilities_flat", "[", "j", "]", "/=", "len", "(", "probabilities", ")", "\n", "\n", "", "preds", "=", "np", ".", "c_", "[", "[", "np", ".", "argmax", "(", "p", ",", "axis", "=", "1", ")", "for", "p", "in", "probabilities_flat", "]", "]", ".", "T", "\n", "digit_probs", "=", "np", ".", "c_", "[", "\n", "[", "np", ".", "max", "(", "p", ",", "axis", "=", "1", ")", "for", "p", "in", "probabilities_flat", "]", "\n", "]", ".", "T", "\n", "\n", "seq_prob", "=", "np", ".", "prod", "(", "digit_probs", ",", "axis", "=", "1", ")", "\n", "\n", "files", "=", "np", ".", "concatenate", "(", "files", ")", "\n", "\n", "if", "retrieve_labels", ":", "\n", "        ", "labels", "=", "np", ".", "concatenate", "(", "labels", ")", "\n", "\n", "", "return", "preds", ",", "seq_prob", ",", "files", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_functions.eval_sequence": [[171, 240], ["numpy.prod", "numpy.mean", "len", "is_equal.reshape.reshape", "numpy.mean", "numpy.mean"], "function", ["None"], ["", "def", "eval_sequence", "(", "\n", "targets", ":", "np", ".", "ndarray", ",", "\n", "preds", ":", "np", ".", "ndarray", ",", "\n", "seq_prob", ":", "np", ".", "ndarray", ",", "\n", "threshold", ":", "float", "=", "None", ",", "\n", ")", "->", "(", "float", ",", "float", "or", "None", ",", "float", "or", "None", ")", ":", "\n", "    ", "\"\"\"\n    Obtain the accuracy of predictions (over the entire sequence, i.e. all\n    digits must be correct for a prediction to be counted as correct). Further,\n    if a threhold value is provided, the accuracy of the predictions where the\n    model is \"at least\" as certain as the threshold value is provided, as well\n    as the associated coverage (i.e. how large a share the predictions above\n    the threshold constitute).\n\n    Parameters\n    ----------\n    targets : np.ndarray\n        Array of shape (number of observations, length of sequence) with the\n        targets for each element in each sequence. Alternatively, the targets\n        may be \"cleaned\" and in vector format, i.e. with shape\n        (number of observations,), provided the same clearning has been applied\n        to the predictions.\n    preds : np.ndarray\n        Array of shape (number of observations, length of sequence) with the\n        predictions for each element in each sequence. Alternatively, the\n        predictions may be \"cleaned\" and in vector format, i.e. with shape\n        (number of observations,), provided the same clearning has been applied\n        to the targets.\n    seq_prob : np.ndarray\n        Array of shape (number of observations,) with the estimated certainty\n        of the specific prediction, calculated as the product of the\n        certainties of the predictions of the individual elements of the\n        sequence.\n    threshold : float, optional\n        The threshold value used to calculate the accuracy (and coverage) of\n        predictions where the sequence probability is above the value If None,\n        this is not calculated. The default is None.\n\n    Returns\n    -------\n    seq_acc : float\n        The sequence accuracy.\n    seq_acc_threshold : float or None\n        The sequence accuracy for predictions where the sequence probability\n        is above the threshold. If the threshold is None, this is not\n        calculated and a None value is returned.\n    coverage_threshold : float or None\n        The coverage of the predictions where the sequence probability\n        is above the threshold. If the threshold is None, this is not\n        calculated and a None value is returned.\n\n    \"\"\"", "\n", "is_equal", "=", "targets", "==", "preds", "\n", "\n", "if", "len", "(", "is_equal", ".", "shape", ")", "==", "1", ":", "\n", "        ", "is_equal", "=", "is_equal", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "", "correct", "=", "np", ".", "prod", "(", "is_equal", ",", "axis", "=", "1", ")", "\n", "\n", "seq_acc", "=", "np", ".", "mean", "(", "correct", ")", "\n", "\n", "if", "threshold", "is", "not", "None", ":", "\n", "        ", "seq_acc_threshold", "=", "np", ".", "mean", "(", "correct", "[", "seq_prob", ">=", "threshold", "]", ")", "\n", "coverage_threshold", "=", "np", ".", "mean", "(", "seq_prob", ">=", "threshold", ")", "\n", "", "else", ":", "\n", "        ", "seq_acc_threshold", "=", "None", "\n", "coverage_threshold", "=", "None", "\n", "\n", "", "return", "seq_acc", ",", "seq_acc_threshold", ",", "coverage_threshold", "\n", "", ""]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_datasets.AbstractDataset.__init__": [[49, 52], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "transform_pipe", ":", "dict", ")", ":", "\n", "        ", "self", ".", "transform_pipe", "=", "transform_pipe", "\n", "self", ".", "status", "=", "'sample_train'", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_datasets.AbstractDataset._instantiate_labels": [[53, 55], ["NotImplementedError"], "methods", ["None"], ["", "def", "_instantiate_labels", "(", "self", ",", "labels_raw", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Abstract method meant to be overwritten.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_datasets.AbstractDataset._len": [[56, 63], ["Exception", "len", "len"], "methods", ["None"], ["", "def", "_len", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "status", "==", "'sample_train'", ":", "\n", "            ", "return", "len", "(", "self", ".", "labels_train", ")", "\n", "", "if", "self", ".", "status", "==", "'sample_val'", ":", "\n", "            ", "return", "len", "(", "self", ".", "labels_val", ")", "\n", "\n", "", "raise", "Exception", "(", "'Unrecognized sample length requested.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_datasets.AbstractDataset._getitem": [[64, 71], ["Exception"], "methods", ["None"], ["", "def", "_getitem", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "self", ".", "status", "==", "'sample_train'", ":", "\n", "            ", "return", "self", ".", "labels_train", "[", "idx", ",", ":", "]", "\n", "", "if", "self", ".", "status", "==", "'sample_val'", ":", "\n", "            ", "return", "self", ".", "labels_val", "[", "idx", ",", ":", "]", "\n", "\n", "", "raise", "Exception", "(", "'Unrecognized sample requested.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_datasets.AbstractDataset.__len__": [[72, 74], ["pytorch_datasets.AbstractDataset._len"], "methods", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_datasets.AbstractDataset._len"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_len", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_datasets.AbstractDataset.__getitem__": [[75, 88], ["torch.is_tensor", "pytorch_datasets.AbstractDataset._getitem", "PIL.Image.open", "idx.tolist.tolist.tolist"], "methods", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_datasets.AbstractDataset._getitem"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", "->", "dict", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "idx", ")", ":", "\n", "            ", "idx", "=", "idx", ".", "tolist", "(", ")", "\n", "\n", "", "sample", "=", "self", ".", "_getitem", "(", "idx", ")", "\n", "\n", "image", "=", "Image", ".", "open", "(", "sample", "[", "0", "]", ")", "\n", "label", "=", "sample", "[", "1", "]", "\n", "\n", "if", "self", ".", "transform_pipe", ":", "\n", "            ", "image", "=", "self", ".", "transform_pipe", "[", "self", ".", "status", "]", "(", "image", ")", "\n", "\n", "", "return", "{", "'image'", ":", "image", ",", "'label'", ":", "label", ",", "'fname'", ":", "sample", "[", "0", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_datasets.SequenceDataset.__init__": [[106, 119], ["pytorch_datasets.AbstractDataset.__init__", "pytorch_datasets.SequenceDataset._instantiate_labels", "pytorch_datasets.split_sample"], "methods", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.RandAugment.__init__", "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_datasets.SequenceDataset._instantiate_labels", "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_datasets.split_sample"], ["def", "__init__", "(", "\n", "self", ",", "\n", "labels_raw", ":", "str", ",", "\n", "transform_to_label", ":", "types", ".", "FunctionType", ",", "\n", "val_size", ":", "int", "or", "float", "=", "1000", ",", "\n", "transform_pipe", ":", "dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "transform_pipe", "=", "transform_pipe", ")", "\n", "\n", "self", ".", "transform_to_label", "=", "transform_to_label", "\n", "\n", "labels", "=", "self", ".", "_instantiate_labels", "(", "labels_raw", ")", "\n", "self", ".", "labels_train", ",", "self", ".", "labels_val", "=", "split_sample", "(", "labels", ",", "val_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_datasets.SequenceDataset._instantiate_labels": [[120, 133], ["list", "len", "print", "map", "enumerate"], "methods", ["None"], ["", "def", "_instantiate_labels", "(", "self", ",", "labels_raw", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "''' This method instantiates the labels by loading and transforming\n        them from raw sequences to lists of floats.\n        '''", "\n", "labels_raw", "[", ":", ",", "1", "]", "=", "list", "(", "map", "(", "self", ".", "transform_to_label", ",", "labels_raw", "[", ":", ",", "1", "]", ")", ")", "\n", "# It is assumed that bad labels are returned as None from", "\n", "# `self.transform_to_label`, and hence None are now removed", "\n", "self", ".", "nb_dropped", "=", "len", "(", "[", "x", "for", "x", "in", "labels_raw", "[", ":", ",", "1", "]", "if", "x", "is", "None", "]", ")", "\n", "print", "(", "f'Dropped {self.nb_dropped} observations due to bad labels.'", ")", "\n", "good_idxs", "=", "[", "i", "for", "i", ",", "x", "in", "enumerate", "(", "labels_raw", "[", ":", ",", "1", "]", ")", "if", "x", "is", "not", "None", "]", "\n", "labels", "=", "labels_raw", "[", "good_idxs", "]", "\n", "\n", "return", "labels", "\n", "", "", ""]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_datasets.split_sample": [[18, 26], ["sklearn.model_selection.train_test_split", "isinstance", "isinstance"], "function", ["None"], ["def", "split_sample", "(", "labels", ":", "np", ".", "ndarray", ",", "val_size", ":", "int", "or", "float", ")", "->", "tuple", ":", "\n", "    ", "''' Split based on integer or float. '''", "\n", "if", "isinstance", "(", "val_size", ",", "float", ")", "and", "val_size", "==", "0.0", ":", "\n", "        ", "return", "labels", ",", "None", "\n", "", "if", "isinstance", "(", "val_size", ",", "float", ")", "and", "val_size", "==", "1.0", ":", "\n", "        ", "return", "None", ",", "labels", "\n", "\n", "", "return", "train_test_split", "(", "labels", ",", "test_size", "=", "val_size", ",", "random_state", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_modules.SequenceEstimator.__init__": [[13, 19], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "isinstance", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.RandAugment.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "output_sizes", ")", ":", "\n", "        ", "super", "(", "SequenceEstimator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "for", "size", "in", "output_sizes", ":", "\n", "            ", "assert", "isinstance", "(", "size", ",", "int", ")", "and", "size", ">", "0", "\n", "", "self", ".", "fc_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "nn", ".", "Linear", "(", "input_size", ",", "size", ")", "for", "size", "in", "output_sizes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.pytorch_modules.SequenceEstimator.forward": [[20, 25], ["tuple", "fc", "torch.nn.functional.log_softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "affine_transform", "=", "[", "fc", "(", "x", ")", "for", "fc", "in", "self", ".", "fc_layers", "]", "\n", "x", "=", "[", "nn", ".", "functional", ".", "log_softmax", "(", "x", ",", "dim", "=", "1", ")", "for", "x", "in", "affine_transform", "]", "\n", "x", "=", "tuple", "(", "x", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.setup_functions._remove_labels_with_no_image": [[15, 33], ["os.listdir", "set().intersection", "numpy.array", "set", "range", "set", "labels_dict.items", "len", "labels_dict_pruned.items"], "function", ["None"], ["def", "_remove_labels_with_no_image", "(", "image_dir", ":", "str", ",", "labels", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "''' This method ensures that only files where we have the label and\n    the image are maintained.\n    '''", "\n", "image_files", "=", "os", ".", "listdir", "(", "image_dir", ")", "\n", "\n", "labels_dict", "=", "{", "labels", "[", "i", ",", "0", "]", ":", "labels", "[", "i", ",", "1", "]", "for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", "}", "\n", "overlap", "=", "set", "(", "image_files", ")", ".", "intersection", "(", "set", "(", "labels", "[", ":", ",", "0", "]", ")", ")", "\n", "labels_dict_pruned", "=", "{", "\n", "k", ":", "v", "for", "k", ",", "v", "in", "labels_dict", ".", "items", "(", ")", "if", "k", "in", "overlap", "\n", "}", "\n", "\n", "labels_array", "=", "np", ".", "array", "(", "\n", "[", "[", "x", ",", "y", "]", "for", "x", ",", "y", "in", "labels_dict_pruned", ".", "items", "(", ")", "]", ",", "\n", "dtype", "=", "object", ",", "\n", ")", "\n", "\n", "return", "labels_array", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.setup_functions.prepare_labels": [[35, 99], ["cells.copy.copy", "enumerate", "labels_info.values", "numpy.concatenate", "isinstance", "setup_functions._remove_labels_with_no_image", "isinstance", "numpy.load", "labels_info.values", "len"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.util.setup_functions._remove_labels_with_no_image"], ["", "def", "prepare_labels", "(", "cells", ":", "list", ",", "root_labels", ":", "str", ",", "root_images", ":", "str", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Convinience for label load. Takes a list of cells (the naming is used to\n    refer to the fact that we often use minipics of cells from tables - they\n    need not be cells. Just any list of strings such that the strings are\n    names of the label files in `root_labels` and subfolders in `root_images`).\n    The function works by considering each element of `cells` and \"mapping\" to\n    the labels and images by using, respectively, `root_labels` and\n    `root_images`.\n    Then, one element at a time, it loads the labels and ensures that only\n    labels where the associated image exists are kept. This solves problems\n    where our labels contain images we have not been able to crop, for example.\n    It also adds the path to the filename (such that a simple filename is\n    transformed to a full path + filename).\n    Finally, all label files are concatenated to create one array of labels.\n\n    Parameters\n    ----------\n    cells : list\n        List of strings, each of which refers to a label file (an .npy file -\n        it MUST be an .npy file, the first column of which is the filename and\n        the second column is the label) and a folder with images.\n        The elements may alternatively be tuples of exactly 2 elements, the\n        first of which refers to the label file and the second of which refers\n        to the image directory. This is useful if the name of the label file\n        and its corrosponding image directory does not match.\n        You may mix strings and 2-tuples.\n    root_labels : str\n        The directory containing all the label files (.npy files).\n    root_images : str\n        The directory containing all the image folders. Images can be any\n        standard type (.png, .jpg, etc.).\n\n    Returns\n    -------\n    labels_merged : np.ndarray\n        Array of labels. Consist of two columns, this first of which is the\n        filename (WITH full path) and the second of which is the labels.\n\n    \"\"\"", "\n", "cells", "=", "cells", ".", "copy", "(", ")", "\n", "\n", "for", "i", ",", "element", "in", "enumerate", "(", "cells", ")", ":", "\n", "        ", "if", "isinstance", "(", "element", ",", "str", ")", ":", "\n", "            ", "cells", "[", "i", "]", "=", "(", "element", ",", "element", ")", "\n", "", "else", ":", "\n", "            ", "assert", "isinstance", "(", "element", ",", "tuple", ")", "and", "len", "(", "element", ")", "==", "2", "\n", "\n", "", "", "labels_info", "=", "{", "cell", ":", "{", "\n", "'labels'", ":", "''", ".", "join", "(", "(", "root_labels", ",", "cell", "[", "0", "]", ",", "'.npy'", ")", ")", ",", "\n", "'image_dir'", ":", "''", ".", "join", "(", "(", "root_images", ",", "cell", "[", "1", "]", ",", "'/'", ")", ")", ",", "\n", "}", "for", "cell", "in", "cells", "}", "\n", "for", "value", "in", "labels_info", ".", "values", "(", ")", ":", "\n", "        ", "value", "[", "'array'", "]", "=", "_remove_labels_with_no_image", "(", "\n", "image_dir", "=", "value", "[", "'image_dir'", "]", ",", "\n", "labels", "=", "np", ".", "load", "(", "value", "[", "'labels'", "]", ",", "allow_pickle", "=", "True", ")", ",", "\n", ")", "\n", "value", "[", "'array'", "]", "[", ":", ",", "0", "]", "=", "[", "\n", "''", ".", "join", "(", "(", "value", "[", "'image_dir'", "]", ",", "f", ")", ")", "for", "f", "in", "value", "[", "'array'", "]", "[", ":", ",", "0", "]", "\n", "]", "# add path", "\n", "", "labels_merged", "=", "np", ".", "concatenate", "(", "\n", "[", "value", "[", "'array'", "]", "for", "value", "in", "labels_info", ".", "values", "(", ")", "]", "\n", ")", "\n", "return", "labels_merged", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.setup_functions.prepare_labels_csv": [[101, 129], ["cells.copy.copy", "enumerate", "labels_info.values", "numpy.concatenate", "isinstance", "pandas.read_csv", "setup_functions._remove_labels_with_no_image", "isinstance", "labels_info.values", "len"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.util.setup_functions._remove_labels_with_no_image"], ["", "def", "prepare_labels_csv", "(", "cells", ":", "list", ",", "root_labels", ":", "str", ",", "root_images", ":", "str", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "''' See function prepare_labels\n    '''", "\n", "cells", "=", "cells", ".", "copy", "(", ")", "\n", "\n", "for", "i", ",", "element", "in", "enumerate", "(", "cells", ")", ":", "\n", "        ", "if", "isinstance", "(", "element", ",", "str", ")", ":", "\n", "            ", "cells", "[", "i", "]", "=", "(", "element", ",", "element", ")", "\n", "", "else", ":", "\n", "            ", "assert", "isinstance", "(", "element", ",", "tuple", ")", "and", "len", "(", "element", ")", "==", "2", "\n", "\n", "", "", "labels_info", "=", "{", "cell", ":", "{", "\n", "'labels'", ":", "''", ".", "join", "(", "(", "root_labels", ",", "cell", "[", "0", "]", ",", "'.csv'", ")", ")", ",", "\n", "'image_dir'", ":", "''", ".", "join", "(", "(", "root_images", ",", "cell", "[", "1", "]", ",", "'/'", ")", ")", ",", "\n", "}", "for", "cell", "in", "cells", "}", "\n", "for", "value", "in", "labels_info", ".", "values", "(", ")", ":", "\n", "        ", "labels", "=", "pd", ".", "read_csv", "(", "value", "[", "'labels'", "]", ",", "keep_default_na", "=", "False", ")", "\n", "value", "[", "'array'", "]", "=", "_remove_labels_with_no_image", "(", "\n", "image_dir", "=", "value", "[", "'image_dir'", "]", ",", "\n", "labels", "=", "labels", ".", "values", ",", "\n", ")", "\n", "value", "[", "'array'", "]", "[", ":", ",", "0", "]", "=", "[", "\n", "''", ".", "join", "(", "(", "value", "[", "'image_dir'", "]", ",", "f", ")", ")", "for", "f", "in", "value", "[", "'array'", "]", "[", ":", ",", "0", "]", "\n", "]", "# add path", "\n", "", "labels_merged", "=", "np", ".", "concatenate", "(", "\n", "[", "value", "[", "'array'", "]", "for", "value", "in", "labels_info", ".", "values", "(", ")", "]", "\n", ")", "\n", "return", "labels_merged", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.setup_functions.prepare_fnames": [[131, 190], ["cells.copy.copy", "isinstance", "enumerate", "image_files.items", "numpy.concatenate", "len", "len", "isinstance", "os.listdir", "isinstance", "image_files.items", "list", "len", "len", "set", "isinstance", "image_dirs.items", "isinstance", "image_files.values", "set", "len", "x.split"], "function", ["None"], ["", "def", "prepare_fnames", "(", "cells", ":", "list", ",", "root_images", ":", "str", ",", "filetypes", ":", "str", "or", "tuple", "=", "None", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Prepares an array of image file names to be used for, for example,\n    prediction from models.\n\n    Parameters\n    ----------\n    cells : list\n        List of strings, each of which refers to a a folder with images. In\n        case the list consists of 2-tuples (possible in `prepare_labels`), the\n        second element of the tuples are correctly used to identify the image\n        directory.\n    root_images : str\n        The directory containing all the image folders. Images can be any\n        standard type (.png, .jpg, etc.).\n    filetypes : str or tuple, optional\n        On optional option to filter files from a folder. Only file types\n        matching those specified by `filetypes` are kept. The default is None.\n\n    Returns\n    -------\n    image_files_array : np.ndarray\n        Array of shape (n,) with filesnames. Importantly, these include the\n        full path to the file.\n\n    \"\"\"", "\n", "cells", "=", "cells", ".", "copy", "(", ")", "\n", "\n", "assert", "isinstance", "(", "cells", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "len", "(", "set", "(", "cells", ")", ")", "==", "len", "(", "cells", ")", "\n", "\n", "for", "i", ",", "element", "in", "enumerate", "(", "cells", ")", ":", "\n", "        ", "if", "isinstance", "(", "element", ",", "tuple", ")", ":", "\n", "            ", "assert", "len", "(", "element", ")", "==", "2", "\n", "cells", "[", "i", "]", "=", "element", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "assert", "isinstance", "(", "element", ",", "str", ")", "\n", "\n", "", "", "image_dirs", "=", "{", "c", ":", "''", ".", "join", "(", "(", "root_images", ",", "c", ",", "'/'", ")", ")", "for", "c", "in", "cells", "}", "\n", "image_files", "=", "{", "c", ":", "os", ".", "listdir", "(", "imdir", ")", "for", "c", ",", "imdir", "in", "image_dirs", ".", "items", "(", ")", "}", "\n", "\n", "if", "filetypes", "is", "not", "None", ":", "\n", "        ", "if", "isinstance", "(", "filetypes", ",", "str", ")", ":", "\n", "            ", "filetypes", "=", "(", "filetypes", ",", ")", "\n", "", "else", ":", "\n", "            ", "assert", "isinstance", "(", "filetypes", ",", "tuple", ")", "\n", "\n", "", "for", "key", ",", "value", "in", "image_files", ".", "items", "(", ")", ":", "\n", "            ", "image_files", "[", "key", "]", "=", "[", "x", "for", "x", "in", "value", "if", "x", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", "in", "filetypes", "]", "\n", "\n", "", "", "for", "key", ",", "value", "in", "image_files", ".", "items", "(", ")", ":", "\n", "        ", "image_files", "[", "key", "]", "=", "[", "''", ".", "join", "(", "(", "image_dirs", "[", "key", "]", ",", "x", ")", ")", "for", "x", "in", "value", "]", "\n", "\n", "", "image_files_array", "=", "np", ".", "concatenate", "(", "list", "(", "image_files", ".", "values", "(", ")", ")", ")", "\n", "\n", "# Below check should be redundant... maybe remove it", "\n", "assert", "len", "(", "set", "(", "image_files_array", ")", ")", "==", "len", "(", "image_files_array", ")", "\n", "\n", "return", "image_files_array", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.util.setup_functions.get_model_file": [[192, 201], ["json.load", "open"], "function", ["None"], ["", "def", "get_model_file", "(", "root", ":", "str", ",", "model_name", ":", "str", ")", ":", "\n", "    ", "''' Uses a root folder and a model name to retrieve the newest model, i.e.\n    the one trained for the highest number of steps.\n    '''", "\n", "directory", "=", "f'{root}/logs/{model_name}'", "\n", "meta_info", "=", "json", ".", "load", "(", "open", "(", "f'{directory}/meta_info.json'", ",", "'r'", ")", ")", "\n", "model_file", "=", "f'{directory}/model_{meta_info[\"step\"]}.pt'", "\n", "\n", "return", "model_file", "\n", "", ""]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.BasicBlock.__init__": [[63, 80], ["torch.Module.__init__", "resnet.conv3x3", "norm_layer", "torch.ReLU", "torch.ReLU", "resnet.conv3x3", "norm_layer", "ValueError", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.RandAugment.__init__", "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.conv3x3", "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "groups", "=", "1", ",", "\n", "base_width", "=", "64", ",", "dilation", "=", "1", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "if", "groups", "!=", "1", "or", "base_width", "!=", "64", ":", "\n", "            ", "raise", "ValueError", "(", "'BasicBlock only supports groups=1 and base_width=64'", ")", "\n", "", "if", "dilation", ">", "1", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Dilation > 1 not supported in BasicBlock\"", ")", "\n", "# Both self.conv1 and self.downsample layers downsample the input when stride != 1", "\n", "", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "norm_layer", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.BasicBlock.forward": [[81, 98], ["resnet.BasicBlock.conv1", "resnet.BasicBlock.bn1", "resnet.BasicBlock.relu", "resnet.BasicBlock.conv2", "resnet.BasicBlock.bn2", "resnet.BasicBlock.relu", "resnet.BasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.Bottleneck.__init__": [[109, 125], ["torch.Module.__init__", "resnet.conv1x1", "norm_layer", "resnet.conv3x3", "norm_layer", "resnet.conv1x1", "norm_layer", "torch.ReLU", "torch.ReLU", "int"], "methods", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.RandAugment.__init__", "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.conv1x1", "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.conv3x3", "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.conv1x1"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "groups", "=", "1", ",", "\n", "base_width", "=", "64", ",", "dilation", "=", "1", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "width", "=", "int", "(", "planes", "*", "(", "base_width", "/", "64.", ")", ")", "*", "groups", "\n", "# Both self.conv2 and self.downsample layers downsample the input when stride != 1", "\n", "self", ".", "conv1", "=", "conv1x1", "(", "inplanes", ",", "width", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "width", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "width", ",", "width", ",", "stride", ",", "groups", ",", "dilation", ")", "\n", "self", ".", "bn2", "=", "norm_layer", "(", "width", ")", "\n", "self", ".", "conv3", "=", "conv1x1", "(", "width", ",", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "bn3", "=", "norm_layer", "(", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.Bottleneck.forward": [[126, 147], ["resnet.Bottleneck.conv1", "resnet.Bottleneck.bn1", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv2", "resnet.Bottleneck.bn2", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv3", "resnet.Bottleneck.bn3", "resnet.Bottleneck.relu", "resnet.Bottleneck.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.ResNet.__init__": [[151, 201], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Linear", "torch.Linear", "resnet.ResNet.modules", "len", "ValueError", "isinstance", "resnet.ResNet.modules", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "isinstance", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.RandAugment.__init__", "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "num_classes", "=", "1000", ",", "zero_init_residual", "=", "False", ",", "\n", "groups", "=", "1", ",", "width_per_group", "=", "64", ",", "replace_stride_with_dilation", "=", "None", ",", "\n", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "self", ".", "_norm_layer", "=", "norm_layer", "\n", "\n", "self", ".", "inplanes", "=", "64", "\n", "self", ".", "dilation", "=", "1", "\n", "if", "replace_stride_with_dilation", "is", "None", ":", "\n", "# each element in the tuple indicates if we should replace", "\n", "# the 2x2 stride with a dilated convolution instead", "\n", "            ", "replace_stride_with_dilation", "=", "[", "False", ",", "False", ",", "False", "]", "\n", "", "if", "len", "(", "replace_stride_with_dilation", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"replace_stride_with_dilation should be None \"", "\n", "\"or a 3-element tuple, got {}\"", ".", "format", "(", "replace_stride_with_dilation", ")", ")", "\n", "", "self", ".", "groups", "=", "groups", "\n", "self", ".", "base_width", "=", "width_per_group", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "self", ".", "inplanes", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "self", ".", "inplanes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ",", "\n", "dilate", "=", "replace_stride_with_dilation", "[", "0", "]", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ",", "\n", "dilate", "=", "replace_stride_with_dilation", "[", "1", "]", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ",", "\n", "dilate", "=", "replace_stride_with_dilation", "[", "2", "]", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "(", "nn", ".", "BatchNorm2d", ",", "nn", ".", "GroupNorm", ")", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n", "# Zero-initialize the last BN in each residual branch,", "\n", "# so that the residual branch starts with zeros, and each residual block behaves like an identity.", "\n", "# This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677", "\n", "", "", "if", "zero_init_residual", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "Bottleneck", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn3", ".", "weight", ",", "0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "BasicBlock", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn2", ".", "weight", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.ResNet._make_layer": [[202, 225], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "resnet.conv1x1", "norm_layer", "block"], "methods", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.conv1x1"], ["", "", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ",", "dilate", "=", "False", ")", ":", "\n", "        ", "norm_layer", "=", "self", ".", "_norm_layer", "\n", "downsample", "=", "None", "\n", "previous_dilation", "=", "self", ".", "dilation", "\n", "if", "dilate", ":", "\n", "            ", "self", ".", "dilation", "*=", "stride", "\n", "stride", "=", "1", "\n", "", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "conv1x1", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "stride", ")", ",", "\n", "norm_layer", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ",", "self", ".", "groups", ",", "\n", "self", ".", "base_width", ",", "previous_dilation", ",", "norm_layer", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "_", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "groups", "=", "self", ".", "groups", ",", "\n", "base_width", "=", "self", ".", "base_width", ",", "dilation", "=", "self", ".", "dilation", ",", "\n", "norm_layer", "=", "norm_layer", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.ResNet._forward_impl": [[226, 243], ["resnet.ResNet.conv1", "resnet.ResNet.bn1", "resnet.ResNet.relu", "resnet.ResNet.maxpool", "resnet.ResNet.layer1", "resnet.ResNet.layer2", "resnet.ResNet.layer3", "resnet.ResNet.layer4", "resnet.ResNet.avgpool", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten"], "methods", ["None"], ["", "def", "_forward_impl", "(", "self", ",", "x", ")", ":", "\n", "# See note [TorchScript super()]", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "1", ")", "\n", "# x = self.fc(x)", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.ResNet.forward": [[244, 246], ["resnet.ResNet._forward_impl"], "methods", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.ResNet._forward_impl"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "_forward_impl", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.conv3x3": [[49, 53], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ",", "groups", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "dilation", ",", "groups", "=", "groups", ",", "bias", "=", "False", ",", "dilation", "=", "dilation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.conv1x1": [[55, 58], ["torch.Conv2d"], "function", ["None"], ["", "def", "conv1x1", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"1x1 convolution\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet._resnet": [[248, 255], ["resnet.ResNet", "torch.hub.load_state_dict_from_url", "ResNet.load_state_dict"], "function", ["None"], ["", "", "def", "_resnet", "(", "arch", ",", "block", ",", "layers", ",", "pretrained", ",", "progress", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "ResNet", "(", "block", ",", "layers", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "state_dict", "=", "load_state_dict_from_url", "(", "model_urls", "[", "arch", "]", ",", "\n", "progress", "=", "progress", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.resnet18": [[257, 266], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet._resnet"], ["", "def", "resnet18", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-18 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet18'", ",", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.resnet34": [[268, 277], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet._resnet"], ["", "def", "resnet34", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-34 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet34'", ",", "BasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.resnet50": [[279, 288], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet._resnet"], ["", "def", "resnet50", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-50 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet50'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.resnet101": [[290, 299], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet._resnet"], ["", "def", "resnet101", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-101 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet101'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.resnet152": [[301, 310], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet._resnet"], ["", "def", "resnet152", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-152 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet152'", ",", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.resnext50_32x4d": [[312, 323], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet._resnet"], ["", "def", "resnext50_32x4d", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNeXt-50 32x4d model from\n    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'groups'", "]", "=", "32", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "4", "\n", "return", "_resnet", "(", "'resnext50_32x4d'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.resnext101_32x8d": [[325, 336], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet._resnet"], ["", "def", "resnext101_32x8d", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNeXt-101 32x8d model from\n    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'groups'", "]", "=", "32", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "8", "\n", "return", "_resnet", "(", "'resnext101_32x8d'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.wide_resnet50_2": [[338, 352], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet._resnet"], ["", "def", "wide_resnet50_2", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"Wide ResNet-50-2 model from\n    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n    The model is the same as ResNet except for the bottleneck number of channels\n    which is twice larger in every block. The number of channels in outer 1x1\n    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "64", "*", "2", "\n", "return", "_resnet", "(", "'wide_resnet50_2'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.wide_resnet101_2": [[354, 368], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet._resnet"], ["", "def", "wide_resnet101_2", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"Wide ResNet-101-2 model from\n    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n    The model is the same as ResNet except for the bottleneck number of channels\n    which is twice larger in every block. The number of channels in outer 1x1\n    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "64", "*", "2", "\n", "return", "_resnet", "(", "'wide_resnet101_2'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.resnext101_32x8d_wsl": [[370, 380], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet._resnet"], ["", "def", "resnext101_32x8d_wsl", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt-101 32x8 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Args:\n        progress (bool): If True, displays a progress bar of the download to stderr.\n    \"\"\"", "\n", "kwargs", "[", "'groups'", "]", "=", "32", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "8", "\n", "return", "_resnet", "(", "'resnext101_32x8d_wsl'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.resnext101_32x16d_wsl": [[382, 392], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet._resnet"], ["", "def", "resnext101_32x16d_wsl", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt-101 32x16 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Args:\n        progress (bool): If True, displays a progress bar of the download to stderr.\n    \"\"\"", "\n", "kwargs", "[", "'groups'", "]", "=", "32", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "16", "\n", "return", "_resnet", "(", "'resnext101_32x16d_wsl'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.resnext101_32x32d_wsl": [[394, 404], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet._resnet"], ["", "def", "resnext101_32x32d_wsl", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt-101 32x32 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Args:\n        progress (bool): If True, displays a progress bar of the download to stderr.\n    \"\"\"", "\n", "kwargs", "[", "'groups'", "]", "=", "32", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "32", "\n", "return", "_resnet", "(", "'resnext101_32x32d_wsl'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet.resnext101_32x48d_wsl": [[406, 416], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.torchvision.resnet._resnet"], ["", "def", "resnext101_32x48d_wsl", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt-101 32x48 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Args:\n        progress (bool): If True, displays a progress bar of the download to stderr.\n    \"\"\"", "\n", "kwargs", "[", "'groups'", "]", "=", "32", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "48", "\n", "return", "_resnet", "(", "'resnext101_32x48d_wsl'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.augment.augmenters.ResizePad.__init__": [[15, 30], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "target_h", ":", "int", ",", "\n", "target_w", ":", "int", ",", "\n", "placement", ":", "str", "=", "(", "'middle'", ",", "'middle'", ")", ",", "\n", "padding_mode", ":", "str", "=", "'edge'", ",", "\n", ")", ":", "\n", "        ", "placements", "=", "[", "(", "x", ",", "y", ")", "for", "x", "in", "self", ".", "PLACEMENTS_X", "for", "y", "in", "self", ".", "PLACEMENTS_Y", "]", "\n", "assert", "placement", "in", "placements", "\n", "assert", "padding_mode", "in", "(", "'constant'", ",", "'edge'", ")", "\n", "\n", "self", ".", "target_h", "=", "target_h", "\n", "self", ".", "target_w", "=", "target_w", "\n", "self", ".", "placement", "=", "placement", "\n", "self", ".", "padding_mode", "=", "padding_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.augment.augmenters.ResizePad._get_padding": [[31, 53], ["int", "int", "random.random", "random.random"], "methods", ["None"], ["", "def", "_get_padding", "(", "self", ",", "delta_w", ",", "delta_h", ")", ":", "\n", "        ", "ratios", "=", "{", "\n", "'w'", ":", "{", "\n", "'left'", ":", "0.0", ",", "\n", "'right'", ":", "1.0", ",", "\n", "'middle'", ":", "0.5", ",", "\n", "'random'", ":", "random", ".", "random", "(", ")", ",", "\n", "}", ",", "\n", "'h'", ":", "{", "\n", "'top'", ":", "0.0", ",", "\n", "'bottom'", ":", "1.0", ",", "\n", "'middle'", ":", "0.5", ",", "\n", "'random'", ":", "random", ".", "random", "(", ")", ",", "\n", "}", ",", "\n", "}", "\n", "\n", "pad_left", "=", "int", "(", "delta_w", "*", "ratios", "[", "'w'", "]", "[", "self", ".", "placement", "[", "0", "]", "]", ")", "\n", "pad_top", "=", "int", "(", "delta_h", "*", "ratios", "[", "'h'", "]", "[", "self", ".", "placement", "[", "1", "]", "]", ")", "\n", "pad_right", "=", "delta_w", "-", "pad_left", "\n", "pad_bottom", "=", "delta_h", "-", "pad_top", "\n", "\n", "return", "pad_left", ",", "pad_top", ",", "pad_right", ",", "pad_bottom", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.augment.augmenters.ResizePad.__call__": [[54, 76], ["min", "augmenters.ResizePad._get_padding", "torchvision.transforms.functional.pad", "torchvision.transforms.functional.resize", "int", "int"], "methods", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.augment.augmenters.ResizePad._get_padding"], ["", "def", "__call__", "(", "self", ",", "image", ")", ":", "\n", "        ", "assert", "image", ".", "mode", "in", "(", "'L'", ",", "'RGB'", ")", "\n", "\n", "width", ",", "height", "=", "image", ".", "size", "\n", "fill", "=", "255", "if", "image", ".", "mode", "==", "'L'", "else", "(", "255", ",", "255", ",", "255", ")", "\n", "\n", "ratio_h", "=", "self", ".", "target_h", "/", "height", "\n", "ratio_w", "=", "self", ".", "target_w", "/", "width", "\n", "min_ratio", "=", "min", "(", "ratio_h", ",", "ratio_w", ")", "\n", "\n", "if", "min_ratio", "<", "1", ":", "\n", "            ", "image", "=", "transforms", ".", "functional", ".", "resize", "(", "\n", "image", ",", "\n", "(", "int", "(", "height", "*", "min_ratio", ")", ",", "int", "(", "width", "*", "min_ratio", ")", ")", ",", "\n", ")", "\n", "\n", "", "width", ",", "height", "=", "image", ".", "size", "\n", "padding", "=", "self", ".", "_get_padding", "(", "self", ".", "target_w", "-", "width", ",", "self", ".", "target_h", "-", "height", ")", "\n", "\n", "image", "=", "transforms", ".", "functional", ".", "pad", "(", "image", ",", "padding", ",", "fill", "=", "fill", ",", "padding_mode", "=", "self", ".", "padding_mode", ")", "\n", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.augment.augmenters.ResizePad.__repr__": [[77, 80], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(target_h={0}, target_w={1}, placement={2}, padding_mode={3})'", ".", "format", "(", "\n", "self", ".", "target_h", ",", "self", ".", "target_w", ",", "self", ".", "placement", ",", "self", ".", "padding_mode", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.augment.augmenters.to_col": [[83, 85], ["image.convert"], "function", ["None"], ["", "", "def", "to_col", "(", "image", ")", ":", "\n", "    ", "return", "image", ".", "convert", "(", "'RGB'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Lighting.__init__": [[216, 220], ["torch.Tensor", "torch.Tensor"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "alphastd", ",", "eigval", ",", "eigvec", ")", ":", "\n", "        ", "self", ".", "alphastd", "=", "alphastd", "\n", "self", ".", "eigval", "=", "torch", ".", "Tensor", "(", "eigval", ")", "\n", "self", ".", "eigvec", "=", "torch", ".", "Tensor", "(", "eigvec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Lighting.__call__": [[221, 232], ["img.new().resize_().normal_", "rand_augment.Lighting.eigvec.type_as().clone().mul().mul().sum().squeeze", "img.add", "rand_augment.Lighting.view().expand_as", "img.new().resize_", "rand_augment.Lighting.eigvec.type_as().clone().mul().mul().sum", "rand_augment.Lighting.view", "img.new", "rand_augment.Lighting.eigvec.type_as().clone().mul().mul", "rand_augment.Lighting.eigval.view().expand", "rand_augment.Lighting.eigvec.type_as().clone().mul", "img.new().resize_().normal_.view().expand", "rand_augment.Lighting.eigval.view", "rand_augment.Lighting.eigvec.type_as().clone", "img.new().resize_().normal_.view", "rand_augment.Lighting.eigvec.type_as"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "if", "self", ".", "alphastd", "==", "0", ":", "\n", "            ", "return", "img", "\n", "\n", "", "alpha", "=", "img", ".", "new", "(", ")", ".", "resize_", "(", "3", ")", ".", "normal_", "(", "0", ",", "self", ".", "alphastd", ")", "\n", "rgb", "=", "self", ".", "eigvec", ".", "type_as", "(", "img", ")", ".", "clone", "(", ")", ".", "mul", "(", "alpha", ".", "view", "(", "1", ",", "3", ")", ".", "expand", "(", "3", ",", "3", ")", ")", ".", "mul", "(", "self", ".", "eigval", ".", "view", "(", "1", ",", "3", ")", ".", "expand", "(", "3", ",", "3", ")", ")", ".", "sum", "(", "1", ")", ".", "squeeze", "(", ")", "\n", "\n", "return", "img", ".", "add", "(", "rgb", ".", "view", "(", "3", ",", "1", ",", "1", ")", ".", "expand_as", "(", "img", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.CutoutDefault.__init__": [[238, 240], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "length", ")", ":", "\n", "        ", "self", ".", "length", "=", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.CutoutDefault.__call__": [[241, 257], ["numpy.ones", "numpy.random.randint", "numpy.random.randint", "numpy.clip", "numpy.clip", "numpy.clip", "numpy.clip", "torch.from_numpy", "mask.expand_as.expand_as.expand_as", "img.size", "img.size"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "h", ",", "w", "=", "img", ".", "size", "(", "1", ")", ",", "img", ".", "size", "(", "2", ")", "\n", "mask", "=", "np", ".", "ones", "(", "(", "h", ",", "w", ")", ",", "np", ".", "float32", ")", "\n", "y", "=", "np", ".", "random", ".", "randint", "(", "h", ")", "\n", "x", "=", "np", ".", "random", ".", "randint", "(", "w", ")", "\n", "\n", "y1", "=", "np", ".", "clip", "(", "y", "-", "self", ".", "length", "//", "2", ",", "0", ",", "h", ")", "\n", "y2", "=", "np", ".", "clip", "(", "y", "+", "self", ".", "length", "//", "2", ",", "0", ",", "h", ")", "\n", "x1", "=", "np", ".", "clip", "(", "x", "-", "self", ".", "length", "//", "2", ",", "0", ",", "w", ")", "\n", "x2", "=", "np", ".", "clip", "(", "x", "+", "self", ".", "length", "//", "2", ",", "0", ",", "w", ")", "\n", "\n", "mask", "[", "y1", ":", "y2", ",", "x1", ":", "x2", "]", "=", "0.", "\n", "mask", "=", "torch", ".", "from_numpy", "(", "mask", ")", "\n", "mask", "=", "mask", ".", "expand_as", "(", "img", ")", "\n", "img", "*=", "mask", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.RandAugment.__init__": [[260, 264], ["rand_augment.augment_list"], "methods", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.augment_list"], ["    ", "def", "__init__", "(", "self", ",", "n", ",", "m", ")", ":", "\n", "        ", "self", ".", "n", "=", "n", "\n", "self", ".", "m", "=", "m", "# [0, 30]", "\n", "self", ".", "augment_list", "=", "augment_list", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.RandAugment.__call__": [[265, 272], ["random.choices", "op", "float", "float"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "ops", "=", "random", ".", "choices", "(", "self", ".", "augment_list", ",", "k", "=", "self", ".", "n", ")", "\n", "for", "op", ",", "minval", ",", "maxval", "in", "ops", ":", "\n", "            ", "val", "=", "(", "float", "(", "self", ".", "m", ")", "/", "30", ")", "*", "float", "(", "maxval", "-", "minval", ")", "+", "minval", "\n", "img", "=", "op", "(", "img", ",", "val", ")", "\n", "\n", "", "return", "img", "\n", "", "", ""]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.ShearX": [[18, 23], ["img.transform", "random.random"], "function", ["None"], ["def", "ShearX", "(", "img", ",", "v", ")", ":", "# [-0.3, 0.3]", "\n", "    ", "assert", "-", "0.3", "<=", "v", "<=", "0.3", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "return", "img", ".", "transform", "(", "img", ".", "size", ",", "PIL", ".", "Image", ".", "AFFINE", ",", "(", "1", ",", "v", ",", "0", ",", "0", ",", "1", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.ShearY": [[25, 30], ["img.transform", "random.random"], "function", ["None"], ["", "def", "ShearY", "(", "img", ",", "v", ")", ":", "# [-0.3, 0.3]", "\n", "    ", "assert", "-", "0.3", "<=", "v", "<=", "0.3", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "return", "img", ".", "transform", "(", "img", ".", "size", ",", "PIL", ".", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "0", ",", "v", ",", "1", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.TranslateX": [[32, 38], ["img.transform", "random.random"], "function", ["None"], ["", "def", "TranslateX", "(", "img", ",", "v", ")", ":", "# [-150, 150] => percentage: [-0.45, 0.45]", "\n", "    ", "assert", "-", "0.45", "<=", "v", "<=", "0.45", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "v", "=", "v", "*", "img", ".", "size", "[", "0", "]", "\n", "return", "img", ".", "transform", "(", "img", ".", "size", ",", "PIL", ".", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "v", ",", "0", ",", "1", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.TranslateXabs": [[40, 45], ["img.transform", "random.random"], "function", ["None"], ["", "def", "TranslateXabs", "(", "img", ",", "v", ")", ":", "# [-150, 150] => percentage: [-0.45, 0.45]", "\n", "    ", "assert", "0", "<=", "v", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "return", "img", ".", "transform", "(", "img", ".", "size", ",", "PIL", ".", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "v", ",", "0", ",", "1", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.TranslateY": [[47, 53], ["img.transform", "random.random"], "function", ["None"], ["", "def", "TranslateY", "(", "img", ",", "v", ")", ":", "# [-150, 150] => percentage: [-0.45, 0.45]", "\n", "    ", "assert", "-", "0.45", "<=", "v", "<=", "0.45", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "v", "=", "v", "*", "img", ".", "size", "[", "1", "]", "\n", "return", "img", ".", "transform", "(", "img", ".", "size", ",", "PIL", ".", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "0", ",", "0", ",", "1", ",", "v", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.TranslateYabs": [[55, 60], ["img.transform", "random.random"], "function", ["None"], ["", "def", "TranslateYabs", "(", "img", ",", "v", ")", ":", "# [-150, 150] => percentage: [-0.45, 0.45]", "\n", "    ", "assert", "0", "<=", "v", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "return", "img", ".", "transform", "(", "img", ".", "size", ",", "PIL", ".", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "0", ",", "0", ",", "1", ",", "v", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Rotate": [[62, 67], ["img.rotate", "random.random"], "function", ["None"], ["", "def", "Rotate", "(", "img", ",", "v", ")", ":", "# [-30, 30]", "\n", "    ", "assert", "-", "30", "<=", "v", "<=", "30", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "v", "=", "-", "v", "\n", "", "return", "img", ".", "rotate", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.AutoContrast": [[69, 71], ["PIL.ImageOps.autocontrast", "PIL.ImageOps.autocontrast", "PIL.ImageOps.autocontrast", "PIL.ImageOps.autocontrast"], "function", ["None"], ["", "def", "AutoContrast", "(", "img", ",", "_", ")", ":", "\n", "    ", "return", "PIL", ".", "ImageOps", ".", "autocontrast", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Invert": [[73, 75], ["PIL.ImageOps.invert", "PIL.ImageOps.invert", "PIL.ImageOps.invert", "PIL.ImageOps.invert"], "function", ["None"], ["", "def", "Invert", "(", "img", ",", "_", ")", ":", "\n", "    ", "return", "PIL", ".", "ImageOps", ".", "invert", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Equalize": [[77, 79], ["PIL.ImageOps.equalize", "PIL.ImageOps.equalize", "PIL.ImageOps.equalize", "PIL.ImageOps.equalize"], "function", ["None"], ["", "def", "Equalize", "(", "img", ",", "_", ")", ":", "\n", "    ", "return", "PIL", ".", "ImageOps", ".", "equalize", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Flip": [[81, 83], ["PIL.ImageOps.mirror", "PIL.ImageOps.mirror", "PIL.ImageOps.mirror", "PIL.ImageOps.mirror"], "function", ["None"], ["", "def", "Flip", "(", "img", ",", "_", ")", ":", "# not from the paper", "\n", "    ", "return", "PIL", ".", "ImageOps", ".", "mirror", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Solarize": [[85, 88], ["PIL.ImageOps.solarize", "PIL.ImageOps.solarize", "PIL.ImageOps.solarize", "PIL.ImageOps.solarize"], "function", ["None"], ["", "def", "Solarize", "(", "img", ",", "v", ")", ":", "# [0, 256]", "\n", "    ", "assert", "0", "<=", "v", "<=", "256", "\n", "return", "PIL", ".", "ImageOps", ".", "solarize", "(", "img", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.SolarizeAdd": [[90, 97], ["numpy.array().astype", "numpy.clip", "img_np.astype.astype", "PIL.Image.fromarray", "PIL.ImageOps.solarize", "PIL.ImageOps.solarize", "PIL.ImageOps.solarize", "PIL.ImageOps.solarize", "numpy.array"], "function", ["None"], ["", "def", "SolarizeAdd", "(", "img", ",", "addition", "=", "0", ",", "threshold", "=", "128", ")", ":", "\n", "    ", "img_np", "=", "np", ".", "array", "(", "img", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "img_np", "=", "img_np", "+", "addition", "\n", "img_np", "=", "np", ".", "clip", "(", "img_np", ",", "0", ",", "255", ")", "\n", "img_np", "=", "img_np", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "img", "=", "Image", ".", "fromarray", "(", "img_np", ")", "\n", "return", "PIL", ".", "ImageOps", ".", "solarize", "(", "img", ",", "threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Posterize": [[99, 103], ["int", "max", "PIL.ImageOps.posterize", "PIL.ImageOps.posterize", "PIL.ImageOps.posterize", "PIL.ImageOps.posterize"], "function", ["None"], ["", "def", "Posterize", "(", "img", ",", "v", ")", ":", "# [4, 8]", "\n", "    ", "v", "=", "int", "(", "v", ")", "\n", "v", "=", "max", "(", "1", ",", "v", ")", "\n", "return", "PIL", ".", "ImageOps", ".", "posterize", "(", "img", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Contrast": [[105, 108], ["PIL.ImageEnhance.Contrast().enhance", "PIL.ImageEnhance.Contrast().enhance", "PIL.ImageEnhance.Contrast().enhance", "PIL.ImageEnhance.Contrast().enhance", "PIL.ImageEnhance.Contrast", "PIL.ImageEnhance.Contrast", "PIL.ImageEnhance.Contrast", "PIL.ImageEnhance.Contrast"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Contrast", "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Contrast", "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Contrast", "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Contrast"], ["", "def", "Contrast", "(", "img", ",", "v", ")", ":", "# [0.1,1.9]", "\n", "    ", "assert", "0.1", "<=", "v", "<=", "1.9", "\n", "return", "PIL", ".", "ImageEnhance", ".", "Contrast", "(", "img", ")", ".", "enhance", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Color": [[110, 113], ["PIL.ImageEnhance.Color().enhance", "PIL.ImageEnhance.Color().enhance", "PIL.ImageEnhance.Color().enhance", "PIL.ImageEnhance.Color().enhance", "PIL.ImageEnhance.Color", "PIL.ImageEnhance.Color", "PIL.ImageEnhance.Color", "PIL.ImageEnhance.Color"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Color", "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Color", "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Color", "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Color"], ["", "def", "Color", "(", "img", ",", "v", ")", ":", "# [0.1,1.9]", "\n", "    ", "assert", "0.1", "<=", "v", "<=", "1.9", "\n", "return", "PIL", ".", "ImageEnhance", ".", "Color", "(", "img", ")", ".", "enhance", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Brightness": [[115, 118], ["PIL.ImageEnhance.Brightness().enhance", "PIL.ImageEnhance.Brightness().enhance", "PIL.ImageEnhance.Brightness().enhance", "PIL.ImageEnhance.Brightness().enhance", "PIL.ImageEnhance.Brightness", "PIL.ImageEnhance.Brightness", "PIL.ImageEnhance.Brightness", "PIL.ImageEnhance.Brightness"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Brightness", "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Brightness", "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Brightness", "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Brightness"], ["", "def", "Brightness", "(", "img", ",", "v", ")", ":", "# [0.1,1.9]", "\n", "    ", "assert", "0.1", "<=", "v", "<=", "1.9", "\n", "return", "PIL", ".", "ImageEnhance", ".", "Brightness", "(", "img", ")", ".", "enhance", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Sharpness": [[120, 123], ["PIL.ImageEnhance.Sharpness().enhance", "PIL.ImageEnhance.Sharpness().enhance", "PIL.ImageEnhance.Sharpness().enhance", "PIL.ImageEnhance.Sharpness().enhance", "PIL.ImageEnhance.Sharpness", "PIL.ImageEnhance.Sharpness", "PIL.ImageEnhance.Sharpness", "PIL.ImageEnhance.Sharpness"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Sharpness", "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Sharpness", "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Sharpness", "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Sharpness"], ["", "def", "Sharpness", "(", "img", ",", "v", ")", ":", "# [0.1,1.9]", "\n", "    ", "assert", "0.1", "<=", "v", "<=", "1.9", "\n", "return", "PIL", ".", "ImageEnhance", ".", "Sharpness", "(", "img", ")", ".", "enhance", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Cutout": [[125, 132], ["rand_augment.CutoutAbs"], "function", ["home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.CutoutAbs"], ["", "def", "Cutout", "(", "img", ",", "v", ")", ":", "# [0, 60] => percentage: [0, 0.2]", "\n", "    ", "assert", "0.0", "<=", "v", "<=", "0.2", "\n", "if", "v", "<=", "0.", ":", "\n", "        ", "return", "img", "\n", "\n", "", "v", "=", "v", "*", "img", ".", "size", "[", "0", "]", "\n", "return", "CutoutAbs", "(", "img", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.CutoutAbs": [[134, 153], ["numpy.random.uniform", "numpy.random.uniform", "int", "int", "min", "min", "img.copy.copy", "PIL.ImageDraw.Draw().rectangle", "PIL.ImageDraw.Draw().rectangle", "PIL.ImageDraw.Draw().rectangle", "PIL.ImageDraw.Draw().rectangle", "max", "max", "PIL.ImageDraw.Draw", "PIL.ImageDraw.Draw", "PIL.ImageDraw.Draw", "PIL.ImageDraw.Draw"], "function", ["None"], ["", "def", "CutoutAbs", "(", "img", ",", "v", ")", ":", "# [0, 60] => percentage: [0, 0.2]", "\n", "# assert 0 <= v <= 20", "\n", "    ", "if", "v", "<", "0", ":", "\n", "        ", "return", "img", "\n", "", "w", ",", "h", "=", "img", ".", "size", "\n", "x0", "=", "np", ".", "random", ".", "uniform", "(", "w", ")", "\n", "y0", "=", "np", ".", "random", ".", "uniform", "(", "h", ")", "\n", "\n", "x0", "=", "int", "(", "max", "(", "0", ",", "x0", "-", "v", "/", "2.", ")", ")", "\n", "y0", "=", "int", "(", "max", "(", "0", ",", "y0", "-", "v", "/", "2.", ")", ")", "\n", "x1", "=", "min", "(", "w", ",", "x0", "+", "v", ")", "\n", "y1", "=", "min", "(", "h", ",", "y0", "+", "v", ")", "\n", "\n", "xy", "=", "(", "x0", ",", "y0", ",", "x1", ",", "y1", ")", "\n", "color", "=", "(", "125", ",", "123", ",", "114", ")", "\n", "# color = (0, 0, 0)", "\n", "img", "=", "img", ".", "copy", "(", ")", "\n", "PIL", ".", "ImageDraw", ".", "Draw", "(", "img", ")", ".", "rectangle", "(", "xy", ",", "color", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.SamplePairing": [[155, 162], ["numpy.random.choice", "PIL.Image.fromarray", "PIL.Image.fromarray", "PIL.Image.fromarray", "PIL.Image.fromarray", "PIL.Image.blend", "PIL.Image.blend", "PIL.Image.blend", "PIL.Image.blend", "len"], "function", ["None"], ["", "def", "SamplePairing", "(", "imgs", ")", ":", "# [0, 0.4]", "\n", "    ", "def", "f", "(", "img1", ",", "v", ")", ":", "\n", "        ", "i", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "imgs", ")", ")", "\n", "img2", "=", "PIL", ".", "Image", ".", "fromarray", "(", "imgs", "[", "i", "]", ")", "\n", "return", "PIL", ".", "Image", ".", "blend", "(", "img1", ",", "img2", ",", "v", ")", "\n", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.Identity": [[164, 166], ["None"], "function", ["None"], ["", "def", "Identity", "(", "img", ",", "v", ")", ":", "\n", "    ", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.torbensdjohansen_hana.pytorch_randaugment.rand_augment.augment_list": [[168, 211], ["None"], "function", ["None"], ["", "def", "augment_list", "(", ")", ":", "# 16 oeprations and their ranges", "\n", "# https://github.com/google-research/uda/blob/master/image/randaugment/policies.py#L57", "\n", "# l = [", "\n", "#     (Identity, 0., 1.0),", "\n", "#     (ShearX, 0., 0.3),  # 0", "\n", "#     (ShearY, 0., 0.3),  # 1", "\n", "#     (TranslateX, 0., 0.33),  # 2", "\n", "#     (TranslateY, 0., 0.33),  # 3", "\n", "#     (Rotate, 0, 30),  # 4", "\n", "#     (AutoContrast, 0, 1),  # 5", "\n", "#     (Invert, 0, 1),  # 6", "\n", "#     (Equalize, 0, 1),  # 7", "\n", "#     (Solarize, 0, 110),  # 8", "\n", "#     (Posterize, 4, 8),  # 9", "\n", "#     # (Contrast, 0.1, 1.9),  # 10", "\n", "#     (Color, 0.1, 1.9),  # 11", "\n", "#     (Brightness, 0.1, 1.9),  # 12", "\n", "#     (Sharpness, 0.1, 1.9),  # 13", "\n", "#     # (Cutout, 0, 0.2),  # 14", "\n", "#     # (SamplePairing(imgs), 0, 0.4),  # 15", "\n", "# ]", "\n", "\n", "# https://github.com/tensorflow/tpu/blob/8462d083dd89489a79e3200bcc8d4063bf362186/models/official/efficientnet/autoaugment.py#L505", "\n", "    ", "l", "=", "[", "\n", "(", "AutoContrast", ",", "0", ",", "1", ")", ",", "\n", "(", "Equalize", ",", "0", ",", "1", ")", ",", "\n", "(", "Invert", ",", "0", ",", "1", ")", ",", "\n", "(", "Rotate", ",", "0", ",", "30", ")", ",", "\n", "(", "Posterize", ",", "0", ",", "4", ")", ",", "\n", "(", "Solarize", ",", "0", ",", "256", ")", ",", "\n", "(", "SolarizeAdd", ",", "0", ",", "110", ")", ",", "\n", "(", "Color", ",", "0.1", ",", "1.9", ")", ",", "\n", "(", "Contrast", ",", "0.1", ",", "1.9", ")", ",", "\n", "(", "Brightness", ",", "0.1", ",", "1.9", ")", ",", "\n", "(", "Sharpness", ",", "0.1", ",", "1.9", ")", ",", "\n", "(", "ShearX", ",", "0.", ",", "0.3", ")", ",", "\n", "(", "ShearY", ",", "0.", ",", "0.3", ")", ",", "\n", "(", "CutoutAbs", ",", "0", ",", "40", ")", ",", "\n", "(", "TranslateXabs", ",", "0.", ",", "100", ")", ",", "\n", "(", "TranslateYabs", ",", "0.", ",", "100", ")", ",", "\n", "]", "\n", "\n", "return", "l", "\n", "\n"]]}