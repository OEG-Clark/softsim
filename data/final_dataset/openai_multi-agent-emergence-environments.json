{"home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.bin.examine.main": [[18, 85], ["click.command", "click.argument", "mujoco_worldgen.util.parse_arguments.parse_arguments", "os.path.abspath", "print", "os.path.join", "len", "mujoco_worldgen.util.envs.examine_env", "len", "mujoco_worldgen.util.envs.load_env", "isinstance", "mae_envs.wrappers.multi_agent.JoinMultiAgentActions.reset", "numpy.all", "os.path.dirname", "mae_envs.wrappers.multi_agent.JoinMultiAgentActions", "Exception", "load_policy", "mujoco_worldgen.util.types.extract_matching_arguments", "set", "args_remaining.intersection.intersection", "args_remaining.intersection.intersection", "PolicyViewer", "PolicyViewer.run", "name.endswith", "enumerate", "set", "set", "len"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.load_policy.load_policy", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.policy_viewer.PolicyViewer.run"], ["@", "click", ".", "command", "(", ")", "\n", "@", "click", ".", "argument", "(", "'argv'", ",", "nargs", "=", "-", "1", ",", "required", "=", "False", ")", "\n", "def", "main", "(", "argv", ")", ":", "\n", "    ", "'''\n    examine.py is used to display environments and run policies.\n\n    For an example environment jsonnet, see\n        mujoco-worldgen/examples/example_env_examine.jsonnet\n    You can find saved policies and the in the 'examples' together with the environment they were\n    trained in and the hyperparameters used. The naming used is 'examples/<env_name>.jsonnet' for\n    the environment jsonnet file and 'examples/<env_name>.npz' for the policy weights file.\n    Example uses:\n        bin/examine.py hide_and_seek\n        bin/examine.py mae_envs/envs/base.py\n        bin/examine.py base n_boxes=6 n_ramps=2 n_agents=3\n        bin/examine.py my_env_jsonnet.jsonnet\n        bin/examine.py my_env_jsonnet.jsonnet my_policy.npz\n        bin/examine.py hide_and_seek my_policy.npz n_hiders=3 n_seekers=2 n_boxes=8 n_ramps=1\n    '''", "\n", "names", ",", "kwargs", "=", "parse_arguments", "(", "argv", ")", "\n", "\n", "env_name", "=", "names", "[", "0", "]", "\n", "core_dir", "=", "abspath", "(", "join", "(", "dirname", "(", "__file__", ")", ",", "'..'", ")", ")", "\n", "envs_dir", "=", "'mae_envs/envs'", ",", "\n", "xmls_dir", "=", "'xmls'", ",", "\n", "\n", "if", "len", "(", "names", ")", "==", "1", ":", "# examine the environment", "\n", "        ", "examine_env", "(", "env_name", ",", "kwargs", ",", "\n", "core_dir", "=", "core_dir", ",", "envs_dir", "=", "envs_dir", ",", "xmls_dir", "=", "xmls_dir", ",", "\n", "env_viewer", "=", "EnvViewer", ")", "\n", "\n", "", "if", "len", "(", "names", ")", ">=", "2", ":", "# run policies on the environment", "\n", "# importing PolicyViewer and load_policy here because they depend on several", "\n", "# packages which are only needed for playing policies, not for any of the", "\n", "# environments code.", "\n", "        ", "from", "mae_envs", ".", "viewer", ".", "policy_viewer", "import", "PolicyViewer", "\n", "from", "ma_policy", ".", "load_policy", "import", "load_policy", "\n", "policy_names", "=", "names", "[", "1", ":", "]", "\n", "env", ",", "args_remaining_env", "=", "load_env", "(", "env_name", ",", "core_dir", "=", "core_dir", ",", "\n", "envs_dir", "=", "envs_dir", ",", "xmls_dir", "=", "xmls_dir", ",", "\n", "return_args_remaining", "=", "True", ",", "**", "kwargs", ")", "\n", "\n", "if", "isinstance", "(", "env", ".", "action_space", ",", "Tuple", ")", ":", "\n", "            ", "env", "=", "JoinMultiAgentActions", "(", "env", ")", "\n", "", "if", "env", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "f'Could not find environment based on pattern {env_name}'", ")", "\n", "\n", "", "env", ".", "reset", "(", ")", "# generate action and observation spaces", "\n", "assert", "np", ".", "all", "(", "[", "name", ".", "endswith", "(", "'.npz'", ")", "for", "name", "in", "policy_names", "]", ")", "\n", "policies", "=", "[", "load_policy", "(", "name", ",", "env", "=", "env", ",", "scope", "=", "f'policy_{i}'", ")", "\n", "for", "i", ",", "name", "in", "enumerate", "(", "policy_names", ")", "]", "\n", "\n", "\n", "args_remaining_policy", "=", "args_remaining_env", "\n", "\n", "if", "env", "is", "not", "None", "and", "policies", "is", "not", "None", ":", "\n", "            ", "args_to_pass", ",", "args_remaining_viewer", "=", "extract_matching_arguments", "(", "PolicyViewer", ",", "kwargs", ")", "\n", "args_remaining", "=", "set", "(", "args_remaining_env", ")", "\n", "args_remaining", "=", "args_remaining", ".", "intersection", "(", "set", "(", "args_remaining_policy", ")", ")", "\n", "args_remaining", "=", "args_remaining", ".", "intersection", "(", "set", "(", "args_remaining_viewer", ")", ")", "\n", "assert", "len", "(", "args_remaining", ")", "==", "0", ",", "(", "\n", "f\"There left unused arguments: {args_remaining}. There shouldn't be any.\"", ")", "\n", "viewer", "=", "PolicyViewer", "(", "env", ",", "policies", ",", "**", "args_to_pass", ")", "\n", "viewer", ".", "run", "(", ")", "\n", "\n", "\n", "", "", "print", "(", "main", ".", "__doc__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.objects.Boxes.__init__": [[35, 43], ["type", "type"], "methods", ["None"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "n_boxes", ",", "n_elongated_boxes", "=", "0", ",", "placement_fn", "=", "None", ",", "\n", "box_size", "=", "0.5", ",", "box_mass", "=", "1.0", ",", "friction", "=", "None", ",", "box_only_z_rot", "=", "False", ",", "\n", "boxid_obs", "=", "True", ",", "boxsize_obs", "=", "False", ",", "polar_obs", "=", "True", ",", "mark_box_corners", "=", "False", ")", ":", "\n", "        ", "if", "type", "(", "n_boxes", ")", "not", "in", "[", "tuple", ",", "list", ",", "np", ".", "ndarray", "]", ":", "\n", "            ", "self", ".", "n_boxes", "=", "[", "n_boxes", ",", "n_boxes", "]", "\n", "", "if", "type", "(", "n_elongated_boxes", ")", "not", "in", "[", "tuple", ",", "list", ",", "np", ".", "ndarray", "]", ":", "\n", "            ", "self", ".", "n_elongated_boxes", "=", "[", "n_elongated_boxes", ",", "n_elongated_boxes", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.objects.Boxes.build_world_step": [[44, 93], ["env._random_state.randint", "numpy.zeros", "env.metadata[].astype", "env._random_state.randint", "range", "numpy.ones", "env._random_state.randint", "chr", "mujoco_worldgen.Geom", "mujoco_worldgen.Geom.set_material", "mujoco_worldgen.Geom.add_transform", "min", "numpy.array", "numpy.array", "mujoco_worldgen.Material", "mujoco_worldgen.transforms.set_geom_attr_transform", "enumerate", "mujoco_worldgen.Geom.add_transform", "mujoco_worldgen.Geom.add_transform", "mujoco_worldgen.Geom.add_transform", "mae_envs.modules.rejection_placement", "floor.append", "ord", "mujoco_worldgen.Geom.mark", "mujoco_worldgen.transforms.set_geom_attr_transform", "mae_envs.util.transforms.remove_hinge_axis_transform", "mae_envs.util.transforms.remove_hinge_axis_transform", "isinstance", "floor.append", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.rejection_placement", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.util.transforms.remove_hinge_axis_transform", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.util.transforms.remove_hinge_axis_transform"], ["", "", "def", "build_world_step", "(", "self", ",", "env", ",", "floor", ",", "floor_size", ")", ":", "\n", "        ", "env", ".", "metadata", "[", "'box_size'", "]", "=", "self", ".", "box_size", "\n", "\n", "self", ".", "curr_n_boxes", "=", "env", ".", "_random_state", ".", "randint", "(", "self", ".", "n_boxes", "[", "0", "]", ",", "self", ".", "n_boxes", "[", "1", "]", "+", "1", ")", "\n", "\n", "env", ".", "metadata", "[", "'curr_n_boxes'", "]", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_boxes", "[", "1", "]", ")", ")", "\n", "env", ".", "metadata", "[", "'curr_n_boxes'", "]", "[", ":", "self", ".", "curr_n_boxes", "]", "=", "1", "\n", "env", ".", "metadata", "[", "'curr_n_boxes'", "]", "=", "env", ".", "metadata", "[", "'curr_n_boxes'", "]", ".", "astype", "(", "np", ".", "bool", ")", "\n", "\n", "self", ".", "curr_n_elongated_boxes", "=", "env", ".", "_random_state", ".", "randint", "(", "\n", "self", ".", "n_elongated_boxes", "[", "0", "]", ",", "min", "(", "self", ".", "n_elongated_boxes", "[", "1", "]", ",", "self", ".", "curr_n_boxes", ")", "+", "1", ")", "\n", "\n", "self", ".", "box_size_array", "=", "self", ".", "box_size", "*", "np", ".", "ones", "(", "(", "self", ".", "curr_n_boxes", ",", "3", ")", ")", "\n", "if", "self", ".", "curr_n_elongated_boxes", ">", "0", ":", "\n", "# sample number of x-aligned boxes", "\n", "            ", "n_xaligned", "=", "env", ".", "_random_state", ".", "randint", "(", "self", ".", "curr_n_elongated_boxes", "+", "1", ")", "\n", "self", ".", "box_size_array", "[", ":", "n_xaligned", ",", ":", "]", "=", "self", ".", "box_size", "*", "np", ".", "array", "(", "[", "3.3", ",", "0.3", ",", "1.0", "]", ")", "\n", "self", ".", "box_size_array", "[", "n_xaligned", ":", "self", ".", "curr_n_elongated_boxes", ",", ":", "]", "=", "(", "self", ".", "box_size", "*", "np", ".", "array", "(", "[", "0.3", ",", "3.3", ",", "1.0", "]", ")", ")", "\n", "", "env", ".", "metadata", "[", "'box_size_array'", "]", "=", "self", ".", "box_size_array", "\n", "\n", "successful_placement", "=", "True", "\n", "for", "i", "in", "range", "(", "self", ".", "curr_n_boxes", ")", ":", "\n", "            ", "char", "=", "chr", "(", "ord", "(", "'A'", ")", "+", "i", "%", "26", ")", "\n", "geom", "=", "Geom", "(", "\"box\"", ",", "self", ".", "box_size_array", "[", "i", ",", ":", "]", ",", "name", "=", "f'moveable_box{i}'", ")", "\n", "geom", ".", "set_material", "(", "Material", "(", "texture", "=", "\"chars/\"", "+", "char", "+", "\".png\"", ")", ")", "\n", "geom", ".", "add_transform", "(", "set_geom_attr_transform", "(", "'mass'", ",", "self", ".", "box_mass", ")", ")", "\n", "if", "self", ".", "mark_box_corners", ":", "\n", "                ", "for", "j", ",", "(", "x", ",", "y", ")", "in", "enumerate", "(", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "1", "]", ",", "[", "1", ",", "0", "]", ",", "[", "1", ",", "1", "]", "]", ")", ":", "\n", "                    ", "geom", ".", "mark", "(", "f'moveable_box{i}_corner{j}'", ",", "relative_xyz", "=", "(", "x", ",", "y", ",", "0.5", ")", ",", "\n", "rgba", "=", "[", "1.", ",", "1.", ",", "1.", ",", "0.", "]", ")", "\n", "", "", "if", "self", ".", "friction", "is", "not", "None", ":", "\n", "                ", "geom", ".", "add_transform", "(", "set_geom_attr_transform", "(", "'friction'", ",", "self", ".", "friction", ")", ")", "\n", "", "if", "self", ".", "box_only_z_rot", ":", "\n", "                ", "geom", ".", "add_transform", "(", "remove_hinge_axis_transform", "(", "np", ".", "array", "(", "[", "1.0", ",", "0.0", ",", "0.0", "]", ")", ")", ")", "\n", "geom", ".", "add_transform", "(", "remove_hinge_axis_transform", "(", "np", ".", "array", "(", "[", "0.0", ",", "1.0", ",", "0.0", "]", ")", ")", ")", "\n", "\n", "", "if", "self", ".", "placement_fn", "is", "not", "None", ":", "\n", "                ", "_placement_fn", "=", "(", "self", ".", "placement_fn", "[", "i", "]", "\n", "if", "isinstance", "(", "self", ".", "placement_fn", ",", "list", ")", "\n", "else", "self", ".", "placement_fn", ")", "\n", "pos", ",", "_", "=", "rejection_placement", "(", "env", ",", "_placement_fn", ",", "floor_size", ",", "\n", "self", ".", "box_size_array", "[", "i", ",", ":", "2", "]", ")", "\n", "if", "pos", "is", "not", "None", ":", "\n", "                    ", "floor", ".", "append", "(", "geom", ",", "placement_xy", "=", "pos", ")", "\n", "", "else", ":", "\n", "                    ", "successful_placement", "=", "False", "\n", "", "", "else", ":", "\n", "                ", "floor", ".", "append", "(", "geom", ")", "\n", "", "", "return", "successful_placement", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.objects.Boxes.modify_sim_step": [[94, 106], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "sim.model.geom_name2id", "mujoco_worldgen.util.sim_funcs.qpos_idxs_from_joint_prefix", "mujoco_worldgen.util.sim_funcs.qvel_idxs_from_joint_prefix", "range", "range", "range", "sim.model.site_name2id", "range", "range"], "methods", ["None"], ["", "def", "modify_sim_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "# Cache qpos, qvel idxs", "\n", "        ", "self", ".", "box_geom_idxs", "=", "np", ".", "array", "(", "[", "sim", ".", "model", ".", "geom_name2id", "(", "f'moveable_box{i}'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "curr_n_boxes", ")", "]", ")", "\n", "self", ".", "box_qpos_idxs", "=", "np", ".", "array", "(", "[", "qpos_idxs_from_joint_prefix", "(", "sim", ",", "f'moveable_box{i}:'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "curr_n_boxes", ")", "]", ")", "\n", "self", ".", "box_qvel_idxs", "=", "np", ".", "array", "(", "[", "qvel_idxs_from_joint_prefix", "(", "sim", ",", "f'moveable_box{i}:'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "curr_n_boxes", ")", "]", ")", "\n", "if", "self", ".", "mark_box_corners", ":", "\n", "            ", "self", ".", "box_corner_idxs", "=", "np", ".", "array", "(", "[", "sim", ".", "model", ".", "site_name2id", "(", "f'moveable_box{i}_corner{j}'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "curr_n_boxes", ")", "\n", "for", "j", "in", "range", "(", "4", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.objects.Boxes.observation_step": [[107, 137], ["sim.data.qpos.copy", "sim.data.qvel.copy", "numpy.expand_dims", "numpy.expand_dims", "mujoco_worldgen.util.rotation.normalize_angles", "numpy.concatenate", "numpy.concatenate", "numpy.arange", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "obs.update", "numpy.cos", "numpy.sin", "numpy.expand_dims"], "methods", ["None"], ["", "", "def", "observation_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "        ", "qpos", "=", "sim", ".", "data", ".", "qpos", ".", "copy", "(", ")", "\n", "qvel", "=", "sim", ".", "data", ".", "qvel", ".", "copy", "(", ")", "\n", "\n", "box_inds", "=", "np", ".", "expand_dims", "(", "np", ".", "arange", "(", "self", ".", "curr_n_boxes", ")", ",", "-", "1", ")", "\n", "box_geom_idxs", "=", "np", ".", "expand_dims", "(", "self", ".", "box_geom_idxs", ",", "-", "1", ")", "\n", "box_qpos", "=", "qpos", "[", "self", ".", "box_qpos_idxs", "]", "\n", "box_qvel", "=", "qvel", "[", "self", ".", "box_qvel_idxs", "]", "\n", "box_angle", "=", "normalize_angles", "(", "box_qpos", "[", ":", ",", "3", ":", "]", ")", "\n", "polar_angle", "=", "np", ".", "concatenate", "(", "[", "np", ".", "cos", "(", "box_angle", ")", ",", "np", ".", "sin", "(", "box_angle", ")", "]", ",", "-", "1", ")", "\n", "if", "self", ".", "polar_obs", ":", "\n", "            ", "box_qpos", "=", "np", ".", "concatenate", "(", "[", "box_qpos", "[", ":", ",", ":", "3", "]", ",", "polar_angle", "]", ",", "-", "1", ")", "\n", "", "box_obs", "=", "np", ".", "concatenate", "(", "[", "box_qpos", ",", "box_qvel", "]", ",", "-", "1", ")", "\n", "\n", "if", "self", ".", "boxid_obs", ":", "\n", "            ", "box_obs", "=", "np", ".", "concatenate", "(", "[", "box_obs", ",", "box_inds", "]", ",", "-", "1", ")", "\n", "", "if", "self", ".", "n_elongated_boxes", "[", "1", "]", ">", "0", "or", "self", ".", "boxsize_obs", ":", "\n", "            ", "box_obs", "=", "np", ".", "concatenate", "(", "[", "box_obs", ",", "self", ".", "box_size_array", "]", ",", "-", "1", ")", "\n", "\n", "", "obs", "=", "{", "'box_obs'", ":", "box_obs", ",", "\n", "'box_angle'", ":", "box_angle", ",", "\n", "'box_geom_idxs'", ":", "box_geom_idxs", ",", "\n", "'box_pos'", ":", "box_qpos", "[", ":", ",", ":", "3", "]", ",", "\n", "'box_xpos'", ":", "sim", ".", "data", ".", "geom_xpos", "[", "self", ".", "box_geom_idxs", "]", "}", "\n", "\n", "if", "self", ".", "mark_box_corners", ":", "\n", "            ", "obs", ".", "update", "(", "{", "'box_corner_pos'", ":", "sim", ".", "data", ".", "site_xpos", "[", "self", ".", "box_corner_idxs", "]", ",", "\n", "'box_corner_idxs'", ":", "np", ".", "expand_dims", "(", "self", ".", "box_corner_idxs", ",", "-", "1", ")", "}", ")", "\n", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.objects.Ramps.__init__": [[151, 155], ["None"], "methods", ["None"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "n_ramps", ",", "placement_fn", "=", "None", ",", "friction", "=", "None", ",", "polar_obs", "=", "True", ",", "\n", "pad_ramp_size", "=", "False", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.objects.Ramps.build_world_step": [[156, 180], ["numpy.ones().astype", "range", "chr", "mujoco_worldgen.ObjFromXML", "mujoco_worldgen.ObjFromXML.set_material", "numpy.ones", "mujoco_worldgen.Material", "mujoco_worldgen.ObjFromXML.add_transform", "mae_envs.modules.rejection_placement", "floor.append", "ord", "mujoco_worldgen.transforms.set_geom_attr_transform", "isinstance", "mae_envs.modules.get_size_from_xml", "floor.append"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.rejection_placement", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.get_size_from_xml"], ["", "def", "build_world_step", "(", "self", ",", "env", ",", "floor", ",", "floor_size", ")", ":", "\n", "        ", "successful_placement", "=", "True", "\n", "\n", "env", ".", "metadata", "[", "'curr_n_ramps'", "]", "=", "np", ".", "ones", "(", "(", "self", ".", "n_ramps", ")", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "n_ramps", ")", ":", "\n", "            ", "char", "=", "chr", "(", "ord", "(", "'A'", ")", "+", "i", "%", "26", ")", "\n", "geom", "=", "geom", "=", "ObjFromXML", "(", "'ramp'", ",", "name", "=", "f\"ramp{i}\"", ")", "\n", "geom", ".", "set_material", "(", "Material", "(", "texture", "=", "\"chars/\"", "+", "char", "+", "\".png\"", ")", ")", "\n", "if", "self", ".", "friction", "is", "not", "None", ":", "\n", "                ", "geom", ".", "add_transform", "(", "set_geom_attr_transform", "(", "'friction'", ",", "self", ".", "friction", ")", ")", "\n", "\n", "", "if", "self", ".", "placement_fn", "is", "not", "None", ":", "\n", "                ", "_placement_fn", "=", "(", "self", ".", "placement_fn", "[", "i", "]", "\n", "if", "isinstance", "(", "self", ".", "placement_fn", ",", "list", ")", "\n", "else", "self", ".", "placement_fn", ")", "\n", "pos", ",", "_", "=", "rejection_placement", "(", "env", ",", "_placement_fn", ",", "floor_size", ",", "get_size_from_xml", "(", "geom", ")", ")", "\n", "if", "pos", "is", "not", "None", ":", "\n", "                    ", "floor", ".", "append", "(", "geom", ",", "placement_xy", "=", "pos", ")", "\n", "", "else", ":", "\n", "                    ", "successful_placement", "=", "False", "\n", "", "", "else", ":", "\n", "                ", "floor", ".", "append", "(", "geom", ")", "\n", "", "", "return", "successful_placement", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.objects.Ramps.modify_sim_step": [[181, 189], ["numpy.array", "numpy.array", "numpy.array", "mujoco_worldgen.util.sim_funcs.qpos_idxs_from_joint_prefix", "mujoco_worldgen.util.sim_funcs.qvel_idxs_from_joint_prefix", "sim.model.geom_name2id", "range", "range", "range"], "methods", ["None"], ["", "def", "modify_sim_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "# Cache qpos, qvel idxs", "\n", "        ", "self", ".", "ramp_qpos_idxs", "=", "np", ".", "array", "(", "[", "qpos_idxs_from_joint_prefix", "(", "sim", ",", "f'ramp{i}'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_ramps", ")", "]", ")", "\n", "self", ".", "ramp_qvel_idxs", "=", "np", ".", "array", "(", "[", "qvel_idxs_from_joint_prefix", "(", "sim", ",", "f'ramp{i}'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_ramps", ")", "]", ")", "\n", "self", ".", "ramp_geom_idxs", "=", "np", ".", "array", "(", "[", "sim", ".", "model", ".", "geom_name2id", "(", "f'ramp{i}:ramp'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_ramps", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.objects.Ramps.observation_step": [[190, 212], ["sim.data.qpos.copy", "sim.data.qvel.copy", "numpy.expand_dims", "mujoco_worldgen.util.rotation.normalize_angles", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.cos", "numpy.sin", "numpy.zeros"], "methods", ["None"], ["", "def", "observation_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "        ", "qpos", "=", "sim", ".", "data", ".", "qpos", ".", "copy", "(", ")", "\n", "qvel", "=", "sim", ".", "data", ".", "qvel", ".", "copy", "(", ")", "\n", "\n", "ramp_geom_idxs", "=", "np", ".", "expand_dims", "(", "self", ".", "ramp_geom_idxs", ",", "-", "1", ")", "\n", "ramp_qpos", "=", "qpos", "[", "self", ".", "ramp_qpos_idxs", "]", "\n", "ramp_qvel", "=", "qvel", "[", "self", ".", "ramp_qvel_idxs", "]", "\n", "ramp_angle", "=", "normalize_angles", "(", "ramp_qpos", "[", ":", ",", "3", ":", "]", ")", "\n", "polar_angle", "=", "np", ".", "concatenate", "(", "[", "np", ".", "cos", "(", "ramp_angle", ")", ",", "np", ".", "sin", "(", "ramp_angle", ")", "]", ",", "-", "1", ")", "\n", "if", "self", ".", "polar_obs", ":", "\n", "            ", "ramp_qpos", "=", "np", ".", "concatenate", "(", "[", "ramp_qpos", "[", ":", ",", ":", "3", "]", ",", "polar_angle", "]", ",", "-", "1", ")", "\n", "\n", "", "ramp_obs", "=", "np", ".", "concatenate", "(", "[", "ramp_qpos", ",", "ramp_qvel", "]", ",", "-", "1", ")", "\n", "if", "self", ".", "pad_ramp_size", ":", "\n", "            ", "ramp_obs", "=", "np", ".", "concatenate", "(", "[", "ramp_obs", ",", "np", ".", "zeros", "(", "(", "ramp_obs", ".", "shape", "[", "0", "]", ",", "3", ")", ")", "]", ",", "-", "1", ")", "\n", "\n", "", "obs", "=", "{", "'ramp_obs'", ":", "ramp_obs", ",", "\n", "'ramp_angle'", ":", "ramp_angle", ",", "\n", "'ramp_geom_idxs'", ":", "ramp_geom_idxs", ",", "\n", "'ramp_pos'", ":", "ramp_qpos", "[", ":", ",", ":", "3", "]", "}", "\n", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.objects.Cylinders.__init__": [[231, 238], ["type", "type"], "methods", ["None"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "n_objects", ",", "diameter", ",", "height", ",", "make_static", "=", "False", ",", "\n", "placement_fn", "=", "None", ",", "rgba", "=", "[", "1.", ",", "1.", ",", "1.", ",", "1.", "]", ")", ":", "\n", "        ", "if", "type", "(", "diameter", ")", "not", "in", "[", "list", ",", "np", ".", "ndarray", "]", ":", "\n", "            ", "self", ".", "diameter", "=", "[", "diameter", ",", "diameter", "]", "\n", "", "if", "type", "(", "height", ")", "not", "in", "[", "list", ",", "np", ".", "ndarray", "]", ":", "\n", "            ", "self", ".", "height", "=", "[", "height", ",", "height", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.objects.Cylinders.build_world_step": [[239, 263], ["env._random_state.uniform", "env._random_state.uniform", "range", "mujoco_worldgen.Geom", "mujoco_worldgen.Geom.mark_static", "mae_envs.modules.rejection_placement", "floor.append", "isinstance", "floor.append", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.rejection_placement"], ["", "", "def", "build_world_step", "(", "self", ",", "env", ",", "floor", ",", "floor_size", ")", ":", "\n", "        ", "default_name", "=", "'static_cylinder'", "if", "self", ".", "make_static", "else", "'moveable_cylinder'", "\n", "diameter", "=", "env", ".", "_random_state", ".", "uniform", "(", "self", ".", "diameter", "[", "0", "]", ",", "self", ".", "diameter", "[", "1", "]", ")", "\n", "height", "=", "env", ".", "_random_state", ".", "uniform", "(", "self", ".", "height", "[", "0", "]", ",", "self", ".", "height", "[", "1", "]", ")", "\n", "obj_size", "=", "(", "diameter", ",", "height", ",", "0", ")", "\n", "successful_placement", "=", "True", "\n", "for", "i", "in", "range", "(", "self", ".", "n_objects", ")", ":", "\n", "            ", "geom", "=", "Geom", "(", "'cylinder'", ",", "obj_size", ",", "name", "=", "f'{default_name}{i}'", ",", "rgba", "=", "self", ".", "rgba", ")", "\n", "if", "self", ".", "make_static", ":", "\n", "                ", "geom", ".", "mark_static", "(", ")", "\n", "\n", "", "if", "self", ".", "placement_fn", "is", "not", "None", ":", "\n", "                ", "_placement_fn", "=", "(", "self", ".", "placement_fn", "[", "i", "]", "\n", "if", "isinstance", "(", "self", ".", "placement_fn", ",", "list", ")", "\n", "else", "self", ".", "placement_fn", ")", "\n", "pos", ",", "_", "=", "rejection_placement", "(", "env", ",", "_placement_fn", ",", "floor_size", ",", "diameter", "*", "np", ".", "ones", "(", "2", ")", ")", "\n", "if", "pos", "is", "not", "None", ":", "\n", "                    ", "floor", ".", "append", "(", "geom", ",", "placement_xy", "=", "pos", ")", "\n", "", "else", ":", "\n", "                    ", "successful_placement", "=", "False", "\n", "", "", "else", ":", "\n", "                ", "floor", ".", "append", "(", "geom", ")", "\n", "\n", "", "", "return", "successful_placement", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.objects.Cylinders.modify_sim_step": [[264, 277], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "mujoco_worldgen.util.sim_funcs.qpos_idxs_from_joint_prefix", "mujoco_worldgen.util.sim_funcs.qvel_idxs_from_joint_prefix", "sim.model.geom_name2id", "sim.model.geom_name2id", "range", "range", "range", "range"], "methods", ["None"], ["", "def", "modify_sim_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "        ", "if", "self", ".", "make_static", ":", "\n", "            ", "self", ".", "s_cylinder_geom_idxs", "=", "np", ".", "array", "(", "[", "sim", ".", "model", ".", "geom_name2id", "(", "f'static_cylinder{i}'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_objects", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "m_cylinder_geom_idxs", "=", "np", ".", "array", "(", "[", "sim", ".", "model", ".", "geom_name2id", "(", "f'moveable_cylinder{i}'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_objects", ")", "]", ")", "\n", "qpos_idxs", "=", "[", "qpos_idxs_from_joint_prefix", "(", "sim", ",", "f'moveable_cylinder{i}'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_objects", ")", "]", "\n", "qvel_idxs", "=", "[", "qvel_idxs_from_joint_prefix", "(", "sim", ",", "f'moveable_cylinder{i}'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_objects", ")", "]", "\n", "self", ".", "m_cylinder_qpos_idxs", "=", "np", ".", "array", "(", "qpos_idxs", ")", "\n", "self", ".", "m_cylinder_qvel_idxs", "=", "np", ".", "array", "(", "qvel_idxs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.objects.Cylinders.observation_step": [[278, 301], ["sim.data.qpos.copy", "sim.data.qvel.copy", "numpy.expand_dims", "numpy.expand_dims", "mujoco_worldgen.util.rotation.normalize_angles", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.cos", "numpy.sin"], "methods", ["None"], ["", "", "def", "observation_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "        ", "qpos", "=", "sim", ".", "data", ".", "qpos", ".", "copy", "(", ")", "\n", "qvel", "=", "sim", ".", "data", ".", "qvel", ".", "copy", "(", ")", "\n", "\n", "if", "self", ".", "make_static", ":", "\n", "            ", "s_cylinder_geom_idxs", "=", "np", ".", "expand_dims", "(", "self", ".", "s_cylinder_geom_idxs", ",", "-", "1", ")", "\n", "s_cylinder_xpos", "=", "sim", ".", "data", ".", "geom_xpos", "[", "self", ".", "s_cylinder_geom_idxs", "]", "\n", "obs", "=", "{", "'static_cylinder_geom_idxs'", ":", "s_cylinder_geom_idxs", ",", "\n", "'static_cylinder_xpos'", ":", "s_cylinder_xpos", "}", "\n", "", "else", ":", "\n", "            ", "m_cylinder_geom_idxs", "=", "np", ".", "expand_dims", "(", "self", ".", "m_cylinder_geom_idxs", ",", "-", "1", ")", "\n", "m_cylinder_xpos", "=", "sim", ".", "data", ".", "geom_xpos", "[", "self", ".", "m_cylinder_geom_idxs", "]", "\n", "m_cylinder_qpos", "=", "qpos", "[", "self", ".", "m_cylinder_qpos_idxs", "]", "\n", "m_cylinder_qvel", "=", "qvel", "[", "self", ".", "m_cylinder_qvel_idxs", "]", "\n", "mc_angle", "=", "normalize_angles", "(", "m_cylinder_qpos", "[", ":", ",", "3", ":", "]", ")", "\n", "polar_angle", "=", "np", ".", "concatenate", "(", "[", "np", ".", "cos", "(", "mc_angle", ")", ",", "np", ".", "sin", "(", "mc_angle", ")", "]", ",", "-", "1", ")", "\n", "m_cylinder_qpos", "=", "np", ".", "concatenate", "(", "[", "m_cylinder_qpos", "[", ":", ",", ":", "3", "]", ",", "polar_angle", "]", ",", "-", "1", ")", "\n", "m_cylinder_obs", "=", "np", ".", "concatenate", "(", "[", "m_cylinder_qpos", ",", "m_cylinder_qvel", "]", ",", "-", "1", ")", "\n", "obs", "=", "{", "'moveable_cylinder_geom_idxs'", ":", "m_cylinder_geom_idxs", ",", "\n", "'moveable_cylinder_xpos'", ":", "m_cylinder_xpos", ",", "\n", "'moveable_cylinder_obs'", ":", "m_cylinder_obs", "}", "\n", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.objects.LidarSites.__init__": [[310, 313], ["None"], "methods", ["None"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "n_agents", ",", "n_lidar_per_agent", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.objects.LidarSites.build_world_step": [[314, 319], ["range", "range", "floor.mark", "numpy.zeros"], "methods", ["None"], ["", "def", "build_world_step", "(", "self", ",", "env", ",", "floor", ",", "floor_size", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "self", ".", "n_agents", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "n_lidar_per_agent", ")", ":", "\n", "                ", "floor", ".", "mark", "(", "f\"agent{i}:lidar{j}\"", ",", "(", "0.0", ",", "0.0", ",", "0.0", ")", ",", "rgba", "=", "np", ".", "zeros", "(", "(", "4", ",", ")", ")", ")", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.objects.LidarSites.modify_sim_step": [[320, 328], ["numpy.array", "sim.model.site_name2id", "range", "range"], "methods", ["None"], ["", "def", "modify_sim_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "# set lidar size and shape", "\n", "        ", "self", ".", "lidar_ids", "=", "np", ".", "array", "(", "[", "[", "sim", ".", "model", ".", "site_name2id", "(", "f\"agent{i}:lidar{j}\"", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "n_lidar_per_agent", ")", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n_agents", ")", "]", ")", "\n", "# set lidar site shape to cylinder", "\n", "sim", ".", "model", ".", "site_type", "[", "self", ".", "lidar_ids", "]", "=", "5", "\n", "sim", ".", "model", ".", "site_size", "[", "self", ".", "lidar_ids", ",", "0", "]", "=", "0.02", "\n", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.world.FloorAttributes.__init__": [[10, 12], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "kwargs", "=", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.world.FloorAttributes.build_world_step": [[13, 17], ["world.FloorAttributes.kwargs.items", "floor.add_transform", "mujoco_worldgen.transforms.set_geom_attr_transform"], "methods", ["None"], ["", "def", "build_world_step", "(", "self", ",", "env", ",", "floor", ",", "floor_size", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "self", ".", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "floor", ".", "add_transform", "(", "set_geom_attr_transform", "(", "k", ",", "v", ")", ")", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.world.WorldConstants.__init__": [[23, 25], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "kwargs", "=", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.world.WorldConstants.modify_sim_step": [[26, 32], ["world.WorldConstants.kwargs.items", "hasattr", "logging.warning", "getattr"], "methods", ["None"], ["", "def", "modify_sim_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "self", ".", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "not", "hasattr", "(", "sim", ".", "model", ".", "opt", ",", "k", ")", ":", "\n", "                ", "logging", ".", "warning", "(", "f\"sim.model.opt does not have attribute {k}\"", ")", "\n", "", "else", ":", "\n", "                ", "getattr", "(", "sim", ".", "model", ".", "opt", ",", "k", ")", "[", ":", "]", "=", "v", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.construction_sites.ConstructionSites.__init__": [[24, 31], ["type", "type"], "methods", ["None"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "n_sites", ",", "placement_fn", "=", "None", ",", "site_name", "=", "'construction_site'", ",", "\n", "site_size", "=", "0.5", ",", "site_height", "=", "0.25", ",", "n_elongated_sites", "=", "0", ")", ":", "\n", "        ", "if", "type", "(", "n_sites", ")", "not", "in", "[", "tuple", ",", "list", ",", "np", ".", "ndarray", "]", ":", "\n", "            ", "self", ".", "n_sites", "=", "[", "n_sites", ",", "n_sites", "]", "\n", "", "if", "type", "(", "n_elongated_sites", ")", "not", "in", "[", "tuple", ",", "list", ",", "np", ".", "ndarray", "]", ":", "\n", "            ", "self", ".", "n_elongated_sites", "=", "[", "n_elongated_sites", ",", "n_elongated_sites", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.construction_sites.ConstructionSites._mark_site_square": [[32, 47], ["floor.mark", "enumerate", "floor.mark"], "methods", ["None"], ["", "", "def", "_mark_site_square", "(", "self", ",", "floor", ",", "floor_size", ",", "site_name", ",", "\n", "site_relative_xyz", ",", "site_dims", ")", ":", "\n", "        ", "x", ",", "y", ",", "z", "=", "site_relative_xyz", "\n", "floor", ".", "mark", "(", "site_name", ",", "relative_xyz", "=", "(", "x", ",", "y", ",", "z", ")", ",", "\n", "rgba", "=", "[", "1.", ",", "1.", ",", "1.", ",", "1.", "]", ",", "size", "=", "0.1", ")", "\n", "\n", "corner_rel_offset_x", ",", "corner_rel_offset_y", "=", "(", "site_dims", "/", "floor_size", ")", "/", "2", "\n", "corner_rel_xy", "=", "[", "[", "x", "-", "corner_rel_offset_x", ",", "y", "-", "corner_rel_offset_y", "]", ",", "\n", "[", "x", "-", "corner_rel_offset_x", ",", "y", "+", "corner_rel_offset_y", "]", ",", "\n", "[", "x", "+", "corner_rel_offset_x", ",", "y", "-", "corner_rel_offset_y", "]", ",", "\n", "[", "x", "+", "corner_rel_offset_x", ",", "y", "+", "corner_rel_offset_y", "]", "]", "\n", "for", "i", ",", "(", "x_corner", ",", "y_corner", ")", "in", "enumerate", "(", "corner_rel_xy", ")", ":", "\n", "            ", "floor", ".", "mark", "(", "f'{site_name}_corner{i}'", ",", "\n", "relative_xyz", "=", "(", "x_corner", ",", "y_corner", ",", "z", ")", ",", "\n", "size", "=", "0.05", ",", "rgba", "=", "[", "0.8", ",", "0.8", ",", "0.8", ",", "1.", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.construction_sites.ConstructionSites.build_world_step": [[48, 86], ["env._random_state.randint", "env._random_state.randint", "range", "numpy.ones", "env._random_state.randint", "numpy.array", "numpy.array", "mae_envs.modules.rejection_placement", "env._random_state.uniform", "construction_sites.ConstructionSites._mark_site_square", "isinstance", "construction_sites.ConstructionSites._mark_site_square", "construction_sites.ConstructionSites.site_size_array[].max"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.rejection_placement", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.construction_sites.ConstructionSites._mark_site_square", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.construction_sites.ConstructionSites._mark_site_square"], ["", "", "def", "build_world_step", "(", "self", ",", "env", ",", "floor", ",", "floor_size", ")", ":", "\n", "        ", "self", ".", "curr_n_sites", "=", "env", ".", "_random_state", ".", "randint", "(", "self", ".", "n_sites", "[", "0", "]", ",", "self", ".", "n_sites", "[", "1", "]", "+", "1", ")", "\n", "self", ".", "curr_n_elongated_sites", "=", "env", ".", "_random_state", ".", "randint", "(", "\n", "self", ".", "n_elongated_sites", "[", "0", "]", ",", "self", ".", "n_elongated_sites", "[", "1", "]", "+", "1", ")", "\n", "\n", "env", ".", "metadata", "[", "'curr_n_sites'", "]", "=", "self", ".", "curr_n_sites", "\n", "env", ".", "metadata", "[", "'curr_n_elongated_sites'", "]", "=", "self", ".", "curr_n_elongated_sites", "\n", "\n", "self", ".", "site_size_array", "=", "self", ".", "site_size", "*", "np", ".", "ones", "(", "(", "self", ".", "curr_n_sites", ",", "2", ")", ")", "\n", "if", "self", ".", "curr_n_elongated_sites", ">", "0", ":", "\n", "            ", "n_xaligned", "=", "env", ".", "_random_state", ".", "randint", "(", "self", ".", "curr_n_elongated_sites", "+", "1", ")", "\n", "self", ".", "site_size_array", "[", ":", "n_xaligned", ",", ":", "]", "=", "self", ".", "site_size", "*", "np", ".", "array", "(", "[", "3.3", ",", "0.3", "]", ")", "\n", "self", ".", "site_size_array", "[", "n_xaligned", ":", "self", ".", "curr_n_elongated_sites", ",", ":", "]", "=", "(", "\n", "self", ".", "site_size", "*", "np", ".", "array", "(", "[", "0.3", ",", "3.3", "]", ")", ")", "\n", "\n", "", "successful_placement", "=", "True", "\n", "for", "i", "in", "range", "(", "self", ".", "curr_n_sites", ")", ":", "\n", "            ", "if", "self", ".", "placement_fn", "is", "not", "None", ":", "\n", "                ", "_placement_fn", "=", "(", "self", ".", "placement_fn", "[", "i", "]", "\n", "if", "isinstance", "(", "self", ".", "placement_fn", ",", "list", ")", "\n", "else", "self", ".", "placement_fn", ")", "\n", "pos", ",", "_", "=", "rejection_placement", "(", "env", ",", "_placement_fn", ",", "floor_size", ",", "\n", "self", ".", "site_size_array", "[", "i", "]", ")", "\n", "if", "pos", "is", "not", "None", ":", "\n", "                    ", "self", ".", "_mark_site_square", "(", "floor", ",", "floor_size", ",", "f'{self.site_name}{i}'", ",", "\n", "(", "pos", "[", "0", "]", ",", "pos", "[", "1", "]", ",", "self", ".", "site_height", ")", ",", "\n", "self", ".", "site_size_array", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                    ", "successful_placement", "=", "False", "\n", "", "", "else", ":", "\n", "# place the site so that all the corners are still within the play area", "\n", "                ", "pos_min", "=", "self", ".", "site_size_array", "[", "i", "]", ".", "max", "(", ")", "/", "(", "floor_size", "*", "1.1", ")", "/", "2", "\n", "pos", "=", "env", ".", "_random_state", ".", "uniform", "(", "pos_min", ",", "1", "-", "pos_min", ",", "2", ")", "\n", "self", ".", "_mark_site_square", "(", "floor", ",", "floor_size", ",", "f'{self.site_name}{i}'", ",", "\n", "(", "pos", "[", "0", "]", ",", "pos", "[", "1", "]", ",", "self", ".", "site_height", ")", ",", "\n", "self", ".", "site_size_array", "[", "i", "]", ")", "\n", "\n", "", "", "return", "successful_placement", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.construction_sites.ConstructionSites.modify_sim_step": [[87, 95], ["numpy.array", "numpy.array", "sim.model.site_name2id", "sim.model.site_name2id", "range", "range", "range"], "methods", ["None"], ["", "def", "modify_sim_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "        ", "self", ".", "construction_site_idxs", "=", "np", ".", "array", "(", "\n", "[", "sim", ".", "model", ".", "site_name2id", "(", "f'{self.site_name}{i}'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "curr_n_sites", ")", "]", "\n", ")", "\n", "self", ".", "construction_site_corner_idxs", "=", "np", ".", "array", "(", "\n", "[", "sim", ".", "model", ".", "site_name2id", "(", "f'{self.site_name}{i}_corner{j}'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "curr_n_sites", ")", "for", "j", "in", "range", "(", "4", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.construction_sites.ConstructionSites.observation_step": [[97, 112], ["numpy.concatenate", "numpy.ones", "site_corner_pos.reshape"], "methods", ["None"], ["", "def", "observation_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "        ", "site_pos", "=", "sim", ".", "data", ".", "site_xpos", "[", "self", ".", "construction_site_idxs", "]", "\n", "site_corner_pos", "=", "sim", ".", "data", ".", "site_xpos", "[", "self", ".", "construction_site_corner_idxs", "]", "\n", "site_obs", "=", "np", ".", "concatenate", "(", "(", "site_pos", ",", "\n", "site_corner_pos", ".", "reshape", "(", "(", "self", ".", "curr_n_sites", ",", "12", ")", ")", ")", ",", "\n", "axis", "=", "-", "1", ")", "\n", "\n", "mask_site_obs", "=", "np", ".", "ones", "(", "(", "env", ".", "n_agents", ",", "self", ".", "curr_n_sites", ")", ")", "\n", "\n", "obs", "=", "{", "'construction_site_pos'", ":", "site_pos", ",", "\n", "'construction_site_corner_pos'", ":", "site_corner_pos", ",", "\n", "'construction_site_obs'", ":", "site_obs", ",", "\n", "'mask_acs_obs'", ":", "mask_site_obs", "}", "\n", "\n", "return", "obs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.module.EnvModule.build_world_step": [[8, 22], ["None"], "methods", ["None"], ["def", "build_world_step", "(", "self", ",", "env", ",", "floor", ",", "floor_size", ")", ":", "\n", "        ", "'''\n            This function allows you to add objects to worldgen floor object.\n                You could also cache variables needed for observations or add\n                information to the env.metadata dict\n            Args:\n                env (gym.Env): the environment\n                floor (worldgen.Floor): square worldgen floor object\n                floor_size (float): size of the worlgen floor object\n            Returns: True if the the build_world_step was successful, False if it failed\n                e.g. your build_world_step might fail because no valid object placements\n                were found.\n        '''", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.module.EnvModule.modify_sim_step": [[23, 33], ["None"], "methods", ["None"], ["", "def", "modify_sim_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "        ", "'''\n            After an MJSim has been created, this function can be used to modify that sim\n                and cache any variables you can only get after the sim is created\n            Args:\n                env (gym.env): the environment\n                sim (mujoco_py.MJSim): mujoco simulation object\n            Returns: None\n        '''", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.module.EnvModule.observation_step": [[34, 43], ["None"], "methods", ["None"], ["", "def", "observation_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "        ", "'''\n            Create any observations specific to this module.\n            Args:\n                env (gym.env): the environment\n                sim (mujoco_py.MJSim): mujoco simulation object\n            Returns: dict of observations\n        '''", "\n", "return", "{", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.Wall.__init__": [[17, 35], ["numpy.any", "int", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.linalg.norm", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "pt1", ",", "pt2", ",", "height", "=", "0.5", ",", "rgba", "=", "(", "0", ",", "1", ",", "0", ",", "1", ")", ")", ":", "\n", "        ", "assert", "pt1", "[", "0", "]", "==", "pt2", "[", "0", "]", "or", "pt1", "[", "1", "]", "==", "pt2", "[", "1", "]", ",", "(", "\n", "\"Currently only horizontal and vertical walls are supported\"", ")", "\n", "self", ".", "is_vertical", "=", "pt1", "[", "0", "]", "==", "pt2", "[", "0", "]", "\n", "# Make sure pt2 is top right of pt1", "\n", "if", "np", ".", "any", "(", "np", ".", "array", "(", "pt2", ")", "-", "np", ".", "array", "(", "pt1", ")", "<", "0", ")", ":", "\n", "            ", "self", ".", "pt1", "=", "np", ".", "array", "(", "pt2", ")", "\n", "self", ".", "pt2", "=", "np", ".", "array", "(", "pt1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "pt1", "=", "np", ".", "array", "(", "pt1", ")", "\n", "self", ".", "pt2", "=", "np", ".", "array", "(", "pt2", ")", "\n", "", "self", ".", "length", "=", "int", "(", "np", ".", "linalg", ".", "norm", "(", "np", ".", "array", "(", "pt1", ")", "-", "np", ".", "array", "(", "pt2", ")", ")", ")", "\n", "self", ".", "height", "=", "height", "\n", "self", ".", "rgba", "=", "rgba", "\n", "# Variables defining where other walls split from this wall on the left and right.", "\n", "# For horizontal walls, left means below, right means above", "\n", "self", ".", "left_edges", "=", "[", "self", ".", "pt1", ",", "self", ".", "pt2", "]", "\n", "self", ".", "right_edges", "=", "[", "self", ".", "pt1", ",", "self", ".", "pt2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.Wall.is_touching": [[36, 44], ["None"], "methods", ["None"], ["", "def", "is_touching", "(", "self", ",", "pt", ")", ":", "\n", "        ", "'''\n            Is pt (tuple) touching this wall\n        '''", "\n", "if", "self", ".", "is_vertical", ":", "\n", "            ", "return", "pt", "[", "0", "]", "==", "self", ".", "pt1", "[", "0", "]", "and", "pt", "[", "1", "]", ">=", "self", ".", "pt1", "[", "1", "]", "and", "pt", "[", "1", "]", "<=", "self", ".", "pt2", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "return", "pt", "[", "1", "]", "==", "self", ".", "pt1", "[", "1", "]", "and", "pt", "[", "0", "]", ">=", "self", ".", "pt1", "[", "0", "]", "and", "pt", "[", "0", "]", "<=", "self", ".", "pt2", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.Wall.maybe_add_edge": [[45, 55], ["walls.Wall.is_touching", "walls.Wall.right_edges.append", "walls.Wall.is_touching", "walls.Wall.left_edges.append"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.Wall.is_touching", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.Wall.is_touching"], ["", "", "def", "maybe_add_edge", "(", "self", ",", "wall", ")", ":", "\n", "        ", "'''\n            Check if wall is originating from this wall. If so add it to the list of edges.\n        '''", "\n", "if", "self", ".", "is_vertical", "==", "wall", ".", "is_vertical", ":", "\n", "            ", "return", "\n", "", "if", "self", ".", "is_touching", "(", "wall", ".", "pt1", ")", ":", "\n", "            ", "self", ".", "right_edges", ".", "append", "(", "wall", ".", "pt1", ")", "\n", "", "elif", "self", ".", "is_touching", "(", "wall", ".", "pt2", ")", ":", "\n", "            ", "self", ".", "left_edges", ".", "append", "(", "wall", ".", "pt2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.Wall.intersects": [[56, 63], ["numpy.all", "numpy.logical_and"], "methods", ["None"], ["", "", "def", "intersects", "(", "self", ",", "wall", ")", ":", "\n", "        ", "'''\n            Check if intersects with wall.\n        '''", "\n", "if", "self", ".", "is_vertical", "==", "wall", ".", "is_vertical", ":", "\n", "            ", "return", "False", "\n", "", "return", "np", ".", "all", "(", "np", ".", "logical_and", "(", "self", ".", "pt1", "<", "wall", ".", "pt2", ",", "wall", ".", "pt1", "<", "self", ".", "pt2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.Wall.split_for_doors": [[64, 124], ["numpy.random.RandomState", "numpy.unique", "numpy.array", "numpy.diff", "numpy.arange", "min", "numpy.sort", "sorted", "len", "random_state.choice", "random_state.randint", "doors.append", "numpy.linalg.norm", "new_walls.append", "len", "len", "numpy.linalg.norm", "new_walls.append", "walls.Wall", "walls.Wall", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "split_for_doors", "(", "self", ",", "num_doors", "=", "1", ",", "door_size", "=", "1", ",", "all_connect", "=", "False", ",", "\n", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", ")", ")", ":", "\n", "        ", "'''\n            Split this wall into many walls with 'doors' in between.\n            Args:\n                num_doors (int): upper bound of number of doors to create\n                door_size (int): door size in grid cells\n                all_connect (bool): create a door in every wall segment between pairs of points\n                    where other walls connect with this wall\n                random_state (np.random.RandomState): random state to use for sampling\n        '''", "\n", "edges", "=", "np", ".", "unique", "(", "self", ".", "left_edges", "+", "self", ".", "right_edges", ",", "axis", "=", "0", ")", "\n", "edges", "=", "np", ".", "array", "(", "sorted", "(", "edges", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", "if", "self", ".", "is_vertical", "else", "x", "[", "0", "]", ")", ")", "\n", "rel_axis", "=", "edges", "[", ":", ",", "1", "]", "if", "self", ".", "is_vertical", "else", "edges", "[", ":", ",", "0", "]", "\n", "diffs", "=", "np", ".", "diff", "(", "rel_axis", ")", "\n", "possible_doors", "=", "diffs", ">=", "door_size", "+", "1", "\n", "\n", "# Door regions are stretches on the wall where we could create a door.", "\n", "door_regions", "=", "np", ".", "arange", "(", "len", "(", "edges", ")", "-", "1", ")", "\n", "door_regions", "=", "door_regions", "[", "possible_doors", "]", "\n", "\n", "# The number of doors on this wall we want to/can create", "\n", "num_doors", "=", "len", "(", "edges", ")", "-", "1", "if", "all_connect", "else", "num_doors", "\n", "num_doors", "=", "min", "(", "num_doors", ",", "len", "(", "door_regions", ")", ")", "\n", "if", "num_doors", "==", "0", "or", "door_size", "==", "0", ":", "\n", "            ", "return", "[", "self", "]", ",", "[", "]", "\n", "\n", "# Sample num_doors regions to which we will add doors.", "\n", "", "door_regions", "=", "np", ".", "sort", "(", "random_state", ".", "choice", "(", "door_regions", ",", "num_doors", ",", "replace", "=", "False", ")", ")", "\n", "new_walls", "=", "[", "]", "\n", "doors", "=", "[", "]", "\n", "new_wall_start", "=", "edges", "[", "0", "]", "\n", "for", "door", "in", "door_regions", ":", "\n", "# door_start and door_end are the first and last point on the wall bounding the door", "\n", "# (inclusive boundary)", "\n", "            ", "door_start", "=", "random_state", ".", "randint", "(", "1", ",", "diffs", "[", "door", "]", "-", "door_size", "+", "1", ")", "\n", "door_end", "=", "door_start", "+", "door_size", "-", "1", "\n", "\n", "# Because door boundaries are inclusive, we add 1 to the door_end to get next wall", "\n", "# start cell and subtract one from the door_start to get the current wall end cell.", "\n", "if", "self", ".", "is_vertical", ":", "\n", "                ", "new_wall_end", "=", "[", "edges", "[", "door", "]", "[", "0", "]", ",", "edges", "[", "door", "]", "[", "1", "]", "+", "door_start", "-", "1", "]", "\n", "next_new_wall_start", "=", "[", "new_wall_start", "[", "0", "]", ",", "edges", "[", "door", "]", "[", "1", "]", "+", "door_end", "+", "1", "]", "\n", "door_start_cell", "=", "[", "edges", "[", "door", "]", "[", "0", "]", ",", "edges", "[", "door", "]", "[", "1", "]", "+", "door_start", "]", "\n", "door_end_cell", "=", "[", "new_wall_start", "[", "0", "]", ",", "edges", "[", "door", "]", "[", "1", "]", "+", "door_end", "]", "\n", "", "else", ":", "\n", "                ", "new_wall_end", "=", "[", "edges", "[", "door", "]", "[", "0", "]", "+", "door_start", "-", "1", ",", "edges", "[", "door", "]", "[", "1", "]", "]", "\n", "next_new_wall_start", "=", "[", "edges", "[", "door", "]", "[", "0", "]", "+", "door_end", "+", "1", ",", "edges", "[", "door", "]", "[", "1", "]", "]", "\n", "door_start_cell", "=", "[", "edges", "[", "door", "]", "[", "0", "]", "+", "door_start", ",", "edges", "[", "door", "]", "[", "1", "]", "]", "\n", "door_end_cell", "=", "[", "new_wall_start", "[", "0", "]", "+", "door_end", ",", "edges", "[", "door", "]", "[", "1", "]", "]", "\n", "\n", "# Store doors as inclusive boundaries.", "\n", "", "doors", ".", "append", "(", "[", "door_start_cell", ",", "door_end_cell", "]", ")", "\n", "# Check that the new wall isn't size 0", "\n", "if", "np", ".", "linalg", ".", "norm", "(", "np", ".", "array", "(", "new_wall_start", ")", "-", "np", ".", "array", "(", "new_wall_end", ")", ")", ">", "0", ":", "\n", "                ", "new_walls", ".", "append", "(", "Wall", "(", "new_wall_start", ",", "new_wall_end", ")", ")", "\n", "", "new_wall_start", "=", "next_new_wall_start", "\n", "", "if", "np", ".", "linalg", ".", "norm", "(", "np", ".", "array", "(", "new_wall_start", ")", "-", "np", ".", "array", "(", "edges", "[", "-", "1", "]", ")", ")", ">", "0", ":", "\n", "            ", "new_walls", ".", "append", "(", "Wall", "(", "new_wall_start", ",", "edges", "[", "-", "1", "]", ")", ")", "\n", "", "return", "new_walls", ",", "doors", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.RandomWalls.__init__": [[313, 319], ["None"], "methods", ["None"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "grid_size", ",", "num_rooms", ",", "min_room_size", ",", "door_size", ",", "friction", "=", "None", ",", "\n", "num_tries", "=", "10", ",", "outside_wall_rgba", "=", "(", "0", ",", "1", ",", "0", ",", "0.1", ")", ",", "\n", "random_room_number", "=", "False", ",", "gen_door_obs", "=", "True", ",", "prob_outside_walls", "=", "1.0", ",", "\n", "low_outside_walls", "=", "False", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.RandomWalls.build_world_step": [[320, 356], ["walls.outside_walls", "walls.split_walls", "walls.walls_to_mujoco", "walls.add_walls_to_grid", "len", "walls.choose_new_split", "env._random_state.uniform", "walls.construct_door_obs", "env._random_state.randint", "walls.outside_walls", "outside_walls.append", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.outside_walls", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.split_walls", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.walls_to_mujoco", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.add_walls_to_grid", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.choose_new_split", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.construct_door_obs", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.outside_walls"], ["", "def", "build_world_step", "(", "self", ",", "env", ",", "floor", ",", "floor_size", ")", ":", "\n", "# Create rooms", "\n", "        ", "walls", "=", "outside_walls", "(", "self", ".", "grid_size", ",", "rgba", "=", "self", ".", "outside_wall_rgba", ",", "\n", "use_low_wall_height", "=", "self", ".", "low_outside_walls", ")", "\n", "failures", "=", "0", "\n", "\n", "if", "self", ".", "random_room_number", ":", "\n", "            ", "self", ".", "num_actual_rooms", "=", "env", ".", "_random_state", ".", "randint", "(", "self", ".", "num_rooms", ")", "+", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "num_actual_rooms", "=", "self", ".", "num_rooms", "\n", "\n", "", "while", "len", "(", "walls", ")", "<", "self", ".", "num_actual_rooms", "+", "3", ":", "\n", "            ", "new_wall", "=", "choose_new_split", "(", "walls", ",", "self", ".", "min_room_size", ",", "random_state", "=", "env", ".", "_random_state", ")", "\n", "if", "new_wall", "is", "None", ":", "\n", "                ", "walls", "=", "outside_walls", "(", "self", ".", "grid_size", ",", "rgba", "=", "self", ".", "outside_wall_rgba", ",", "\n", "use_low_wall_height", "=", "self", ".", "low_outside_walls", ")", "\n", "failures", "+=", "1", "\n", "", "else", ":", "\n", "                ", "walls", ".", "append", "(", "new_wall", ")", "\n", "", "if", "failures", "==", "self", ".", "num_tries", ":", "\n", "                ", "return", "False", "\n", "\n", "# Add doors", "\n", "", "", "new_walls", ",", "doors", "=", "split_walls", "(", "walls", "[", "4", ":", "]", ",", "self", ".", "door_size", ",", "random_state", "=", "env", ".", "_random_state", ")", "\n", "if", "env", ".", "_random_state", ".", "uniform", "(", ")", "<", "self", ".", "prob_outside_walls", ":", "\n", "            ", "walls", "=", "walls", "[", ":", "4", "]", "+", "new_walls", "\n", "", "else", ":", "\n", "            ", "walls", "=", "new_walls", "\n", "\n", "# Convert doors into mujoco frame", "\n", "", "if", "self", ".", "gen_door_obs", ":", "\n", "            ", "self", ".", "door_obs", "=", "construct_door_obs", "(", "np", ".", "array", "(", "doors", ")", ",", "floor_size", ",", "self", ".", "grid_size", ")", "\n", "\n", "", "walls_to_mujoco", "(", "floor", ",", "floor_size", ",", "self", ".", "grid_size", ",", "walls", ",", "friction", "=", "self", ".", "friction", ")", "\n", "add_walls_to_grid", "(", "env", ".", "placement_grid", ",", "walls", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.RandomWalls.observation_step": [[357, 364], ["None"], "methods", ["None"], ["", "def", "observation_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "        ", "if", "self", ".", "gen_door_obs", ":", "\n", "            ", "obs", "=", "{", "'door_obs'", ":", "self", ".", "door_obs", "}", "\n", "", "else", ":", "\n", "            ", "obs", "=", "{", "}", "\n", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.WallScenarios.__init__": [[385, 389], ["None"], "methods", ["None"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "grid_size", ",", "door_size", ",", "scenario", ",", "friction", "=", "None", ",", "p_door_dropout", "=", "0.0", ",", "\n", "low_outside_walls", "=", "False", ")", ":", "\n", "        ", "assert", "scenario", "in", "[", "'var_quadrant'", ",", "'quadrant'", ",", "'half'", ",", "'var_tri'", ",", "'empty'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.WallScenarios.build_world_step": [[390, 485], ["walls.outside_walls", "walls.split_walls", "numpy.array", "walls.walls_to_mujoco", "walls.add_walls_to_grid", "int", "len", "walls.construct_door_obs", "env._random_state.uniform", "outside_walls.Wall", "outside_walls.Wall", "env._random_state.uniform", "env._random_state.randint", "numpy.array", "outside_walls.Wall", "int", "range", "env._random_state.uniform", "env._random_state.uniform", "outside_walls.Wall", "env._random_state.uniform", "outside_walls.Wall", "outside_walls.Wall", "outside_walls.Wall", "outside_walls.Wall", "outside_walls.Wall"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.outside_walls", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.split_walls", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.walls_to_mujoco", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.add_walls_to_grid", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.construct_door_obs"], ["", "def", "build_world_step", "(", "self", ",", "env", ",", "floor", ",", "floor_size", ")", ":", "\n", "# Outside walls", "\n", "        ", "walls", "=", "outside_walls", "(", "self", ".", "grid_size", ",", "use_low_wall_height", "=", "self", ".", "low_outside_walls", ")", "\n", "if", "self", ".", "scenario", "in", "[", "'quadrant'", ",", "'var_quadrant'", "]", ":", "\n", "            ", "q_size", "=", "env", ".", "_random_state", ".", "uniform", "(", "0.3", ",", "0.6", ")", "if", "self", ".", "scenario", "==", "'var_quadrant'", "else", "0.5", "\n", "q_size", "=", "int", "(", "q_size", "*", "self", ".", "grid_size", ")", "\n", "env", ".", "metadata", "[", "'quadrant_size'", "]", "=", "q_size", "\n", "new_walls", "=", "[", "\n", "Wall", "(", "[", "self", ".", "grid_size", "-", "q_size", ",", "0", "]", ",", "[", "self", ".", "grid_size", "-", "q_size", ",", "q_size", "]", ")", ",", "\n", "Wall", "(", "[", "self", ".", "grid_size", "-", "q_size", ",", "q_size", "]", ",", "[", "self", ".", "grid_size", "-", "1", ",", "q_size", "]", ")", "]", "\n", "if", "env", ".", "_random_state", ".", "uniform", "(", "0", ",", "1", ")", "<", "self", ".", "p_door_dropout", ":", "\n", "                ", "wall_to_split", "=", "env", ".", "_random_state", ".", "randint", "(", "0", ",", "2", ")", "\n", "walls", "+=", "[", "new_walls", "[", "(", "1", "-", "wall_to_split", ")", "]", "]", "\n", "walls_to_split", "=", "[", "new_walls", "[", "wall_to_split", "]", "]", "\n", "", "else", ":", "\n", "                ", "walls_to_split", "=", "new_walls", "\n", "", "", "elif", "self", ".", "scenario", "==", "'half'", ":", "\n", "            ", "walls_to_split", "+=", "[", "Wall", "(", "[", "self", ".", "grid_size", "-", "1", ",", "self", ".", "grid_size", "//", "2", "]", ",", "\n", "[", "0", ",", "self", ".", "grid_size", "//", "2", "]", ")", "]", "\n", "", "elif", "self", ".", "scenario", "==", "'var_tri'", ":", "\n", "            ", "wall1_splitoff_point", ",", "wall2_splitoff_point", "=", "[", "\n", "int", "(", "self", ".", "grid_size", "*", "env", ".", "_random_state", ".", "uniform", "(", "0.4", ",", "0.6", ")", ")", "for", "_", "in", "range", "(", "2", ")", "\n", "]", "\n", "wall1_orientation", "=", "'vertical'", "if", "env", ".", "_random_state", ".", "uniform", "(", ")", "<", "0.5", "else", "'horizontal'", "\n", "# if first wall is horizontal, 'left' means below and 'right' means above", "\n", "wall2_orientation", "=", "'left'", "if", "env", ".", "_random_state", ".", "uniform", "(", ")", "<", "0.5", "else", "'right'", "\n", "\n", "env", ".", "metadata", "[", "'tri_wall_splitoff_points'", "]", "=", "[", "wall1_splitoff_point", ",", "wall2_splitoff_point", "]", "\n", "env", ".", "metadata", "[", "'tri_wall_orientations'", "]", "=", "[", "wall1_orientation", ",", "wall2_orientation", "]", "\n", "if", "wall1_orientation", "==", "'horizontal'", ":", "\n", "                ", "walls_to_split", "=", "[", "Wall", "(", "[", "self", ".", "grid_size", "-", "1", ",", "wall1_splitoff_point", "]", ",", "\n", "[", "0", ",", "wall1_splitoff_point", "]", ")", "]", "\n", "if", "wall2_orientation", "==", "'left'", ":", "\n", "                    ", "walls_to_split", "+=", "[", "Wall", "(", "[", "wall2_splitoff_point", ",", "wall1_splitoff_point", "]", ",", "\n", "[", "wall2_splitoff_point", ",", "0", "]", ")", "]", "\n", "rooms", "=", "[", "[", "(", "1", ",", "self", ".", "grid_size", "-", "1", ")", ",", "\n", "(", "wall1_splitoff_point", "+", "1", ",", "self", ".", "grid_size", "-", "1", ")", "]", ",", "\n", "[", "(", "1", ",", "wall2_splitoff_point", "-", "1", ")", ",", "\n", "(", "1", ",", "wall1_splitoff_point", "-", "1", ")", "]", ",", "\n", "[", "(", "wall2_splitoff_point", "+", "1", ",", "self", ".", "grid_size", "-", "1", ")", ",", "\n", "(", "1", ",", "wall1_splitoff_point", "-", "1", ")", "]", "]", "\n", "", "elif", "wall2_orientation", "==", "'right'", ":", "\n", "                    ", "walls_to_split", "+=", "[", "Wall", "(", "[", "wall2_splitoff_point", ",", "self", ".", "grid_size", "-", "1", "]", ",", "\n", "[", "wall2_splitoff_point", ",", "wall1_splitoff_point", "]", ")", "]", "\n", "rooms", "=", "[", "[", "(", "1", ",", "self", ".", "grid_size", "-", "1", ")", ",", "\n", "(", "0", ",", "wall1_splitoff_point", "-", "1", ")", "]", ",", "\n", "[", "(", "1", ",", "wall2_splitoff_point", "-", "1", ")", ",", "\n", "(", "wall1_splitoff_point", "+", "1", ",", "self", ".", "grid_size", "-", "1", ")", "]", ",", "\n", "[", "(", "wall2_splitoff_point", "+", "1", ",", "self", ".", "grid_size", "-", "1", ")", ",", "\n", "(", "wall1_splitoff_point", "+", "1", ",", "self", ".", "grid_size", "-", "1", ")", "]", "]", "\n", "", "", "elif", "wall1_orientation", "==", "'vertical'", ":", "\n", "                ", "walls_to_split", "=", "[", "Wall", "(", "[", "wall1_splitoff_point", ",", "self", ".", "grid_size", "-", "1", "]", ",", "\n", "[", "wall1_splitoff_point", ",", "0", "]", ")", "]", "\n", "if", "wall2_orientation", "==", "'left'", ":", "\n", "                    ", "walls_to_split", "+=", "[", "Wall", "(", "[", "wall1_splitoff_point", ",", "wall2_splitoff_point", "]", ",", "\n", "[", "0", ",", "wall2_splitoff_point", "]", ")", "]", "\n", "rooms", "=", "[", "[", "(", "wall1_splitoff_point", "+", "1", ",", "self", ".", "grid_size", "-", "1", ")", ",", "\n", "(", "1", ",", "self", ".", "grid_size", "-", "1", ")", "]", ",", "\n", "[", "(", "1", ",", "wall1_splitoff_point", "-", "1", ")", ",", "\n", "(", "1", ",", "wall2_splitoff_point", "-", "1", ")", "]", ",", "\n", "[", "(", "1", ",", "wall1_splitoff_point", "-", "1", ")", ",", "\n", "(", "wall2_splitoff_point", "+", "1", ",", "self", ".", "grid_size", "-", "1", ")", "]", "]", "\n", "", "elif", "wall2_orientation", "==", "'right'", ":", "\n", "                    ", "walls_to_split", "+=", "[", "Wall", "(", "[", "self", ".", "grid_size", "-", "1", ",", "wall2_splitoff_point", "]", ",", "\n", "[", "wall1_splitoff_point", ",", "wall2_splitoff_point", "]", ")", "]", "\n", "rooms", "=", "[", "[", "(", "0", ",", "wall1_splitoff_point", "-", "1", ")", ",", "\n", "(", "1", ",", "self", ".", "grid_size", "-", "1", ")", "]", ",", "\n", "[", "(", "wall1_splitoff_point", "+", "1", ",", "self", ".", "grid_size", "-", "1", ")", ",", "\n", "(", "1", ",", "wall2_splitoff_point", "-", "1", ")", "]", ",", "\n", "[", "(", "wall1_splitoff_point", "+", "1", ",", "self", ".", "grid_size", "-", "1", ")", ",", "\n", "(", "wall2_splitoff_point", "+", "1", ",", "self", ".", "grid_size", "-", "1", ")", "]", "]", "\n", "", "", "env", ".", "metadata", "[", "'tri_room_grid_cell_range'", "]", "=", "rooms", "\n", "\n", "# this is used when we want to consecutively place objects in every room", "\n", "# e.g. if we want object i to go in room (i % 3)", "\n", "env", ".", "metadata", "[", "'tri_placement_rotation'", "]", "=", "[", "]", "\n", "", "elif", "self", ".", "scenario", "==", "'empty'", ":", "\n", "            ", "walls_to_split", "=", "[", "]", "\n", "\n", "# Add doors", "\n", "", "new_walls", ",", "doors", "=", "split_walls", "(", "walls_to_split", ",", "self", ".", "door_size", ",", "\n", "random_state", "=", "env", ".", "_random_state", ")", "\n", "walls", "+=", "new_walls", "\n", "\n", "env", ".", "metadata", "[", "'doors'", "]", "=", "np", ".", "array", "(", "doors", ")", "\n", "\n", "# Convert doors into mujoco frame", "\n", "if", "len", "(", "doors", ")", ">", "0", ":", "\n", "            ", "self", ".", "door_obs", "=", "construct_door_obs", "(", "np", ".", "array", "(", "doors", ")", ",", "floor_size", ",", "self", ".", "grid_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "door_obs", "=", "None", "\n", "\n", "", "walls_to_mujoco", "(", "floor", ",", "floor_size", ",", "self", ".", "grid_size", ",", "walls", ",", "friction", "=", "self", ".", "friction", ")", "\n", "add_walls_to_grid", "(", "env", ".", "placement_grid", ",", "walls", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.WallScenarios.observation_step": [[486, 493], ["None"], "methods", ["None"], ["", "def", "observation_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "        ", "if", "self", ".", "door_obs", "is", "not", "None", ":", "\n", "            ", "obs", "=", "{", "'door_obs'", ":", "self", ".", "door_obs", "}", "\n", "", "else", ":", "\n", "            ", "obs", "=", "{", "}", "\n", "\n", "", "return", "obs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.connect_walls": [[126, 160], ["numpy.random.RandomState", "random_state.randint", "numpy.any", "numpy.linalg.norm().min", "wall2.is_touching", "walls.Wall", "numpy.array", "numpy.array", "numpy.linalg.norm", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.Wall.is_touching"], ["", "", "def", "connect_walls", "(", "wall1", ",", "wall2", ",", "min_dist_between", ",", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", ")", ")", ":", "\n", "    ", "'''\n        Draw a random new wall connecting wall1 and wall2. Return None if\n        the drawn wall was closer than min_dist_between to another wall\n        or the wall wasn't valid.\n        NOTE: This DOES NOT check if the created wall overlaps with any existing walls, that\n            should be done outside of this function\n        Args:\n            wall1, wall2 (Wall): walls to draw a new wall between\n            min_dist_between (int): closest another parallel wall can be to the new wall in grid cells.\n            random_state (np.random.RandomState): random state to use for sampling\n    '''", "\n", "if", "wall1", ".", "is_vertical", "!=", "wall2", ".", "is_vertical", ":", "\n", "        ", "return", "None", "\n", "", "length", "=", "random_state", ".", "randint", "(", "1", ",", "wall1", ".", "length", ")", "\n", "if", "wall1", ".", "is_vertical", ":", "\n", "        ", "pt1", "=", "[", "wall1", ".", "pt1", "[", "0", "]", ",", "wall1", ".", "pt1", "[", "1", "]", "+", "length", "]", "\n", "pt2", "=", "[", "wall2", ".", "pt1", "[", "0", "]", ",", "wall1", ".", "pt1", "[", "1", "]", "+", "length", "]", "\n", "", "else", ":", "\n", "        ", "pt1", "=", "[", "wall1", ".", "pt1", "[", "0", "]", "+", "length", ",", "wall1", ".", "pt1", "[", "1", "]", "]", "\n", "pt2", "=", "[", "wall1", ".", "pt1", "[", "0", "]", "+", "length", ",", "wall2", ".", "pt1", "[", "1", "]", "]", "\n", "\n", "# Make sure that the new wall actually touches both walls", "\n", "# and there is no wall close to this new wall", "\n", "", "wall1_right_of_wall2", "=", "np", ".", "any", "(", "np", ".", "array", "(", "pt2", ")", "-", "np", ".", "array", "(", "pt1", ")", "<", "0", ")", "\n", "if", "wall1_right_of_wall2", ":", "\n", "        ", "dists", "=", "np", ".", "array", "(", "pt1", ")", "[", "None", ",", ":", "]", "-", "np", ".", "array", "(", "wall1", ".", "left_edges", ")", "\n", "", "else", ":", "\n", "        ", "dists", "=", "np", ".", "array", "(", "pt1", ")", "[", "None", ",", ":", "]", "-", "np", ".", "array", "(", "wall1", ".", "right_edges", ")", "\n", "", "min_dist", "=", "np", ".", "linalg", ".", "norm", "(", "dists", ",", "axis", "=", "1", ")", ".", "min", "(", ")", "\n", "\n", "if", "wall2", ".", "is_touching", "(", "pt2", ")", "and", "min_dist", ">", "min_dist_between", ":", "\n", "        ", "return", "Wall", "(", "pt1", ",", "pt2", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.choose_new_split": [[162, 188], ["numpy.random.RandomState", "range", "random_state.choice", "len", "walls.connect_walls", "random_state.choice", "wall.maybe_add_edge", "random_state.choice.maybe_add_edge", "numpy.any", "wall.intersects"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.connect_walls", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.Wall.maybe_add_edge", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.Wall.maybe_add_edge", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.Wall.intersects"], ["", "def", "choose_new_split", "(", "walls", ",", "min_dist_between", ",", "num_tries", "=", "10", ",", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", ")", ")", ":", "\n", "    ", "'''\n        Given a list of walls, choose a random wall and draw a new wall perpendicular to it.\n        NOTE: Right now this O(n_walls^2). We could probably get this to linear if we did\n            something smarter with the occupancy grid. Until n_walls gets way bigger this\n            should be fine though.\n        Args:\n            walls (Wall list): walls to possibly draw a new wall from\n            min_dist_between (int): closest another parallel wall can be to the new wall in grid cells.\n            num_tries (int): number of times before we can fail in placing a wall before giving up\n            random_state (np.random.RandomState): random state to use for sampling\n    '''", "\n", "for", "i", "in", "range", "(", "num_tries", ")", ":", "\n", "        ", "wall1", "=", "random_state", ".", "choice", "(", "walls", ")", "\n", "proposed_walls", "=", "[", "connect_walls", "(", "wall1", ",", "wall2", ",", "min_dist_between", ",", "random_state", "=", "random_state", ")", "\n", "for", "wall2", "in", "walls", "if", "wall2", "!=", "wall1", "]", "\n", "proposed_walls", "=", "[", "wall", "for", "wall", "in", "proposed_walls", "\n", "if", "wall", "is", "not", "None", "\n", "and", "not", "np", ".", "any", "(", "[", "wall", ".", "intersects", "(", "_wall", ")", "for", "_wall", "in", "walls", "]", ")", "]", "\n", "if", "len", "(", "proposed_walls", ")", ":", "\n", "            ", "new_wall", "=", "random_state", ".", "choice", "(", "proposed_walls", ")", "\n", "for", "wall", "in", "walls", ":", "\n", "                ", "wall", ".", "maybe_add_edge", "(", "new_wall", ")", "\n", "new_wall", ".", "maybe_add_edge", "(", "wall", ")", "\n", "", "return", "new_wall", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.split_walls": [[190, 205], ["numpy.random.RandomState", "wall.split_for_doors"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.Wall.split_for_doors"], ["", "def", "split_walls", "(", "walls", ",", "door_size", ",", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", ")", ")", ":", "\n", "    ", "'''\n        Add a door to each wall in walls. Return the new walls and doors.\n        Args:\n            walls (Wall list): walls\n            door_size (int): door size in grid cells\n            random_state (np.random.RandomState): random state to use for sampling\n    '''", "\n", "split_walls", "=", "[", "]", "\n", "doors", "=", "[", "]", "\n", "for", "wall", "in", "walls", ":", "\n", "        ", "new_walls", ",", "new_doors", "=", "wall", ".", "split_for_doors", "(", "door_size", "=", "door_size", ",", "random_state", "=", "random_state", ")", "\n", "split_walls", "+=", "new_walls", "\n", "doors", "+=", "new_doors", "\n", "", "return", "split_walls", ",", "doors", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.construct_door_obs": [[207, 220], ["numpy.array", "numpy.array", "numpy.concatenate", "numpy.linalg.norm"], "function", ["None"], ["", "def", "construct_door_obs", "(", "doors", ",", "floor_size", ",", "grid_size", ")", ":", "\n", "    ", "'''\n        Construct door observations in mujoco frame from door positions in grid frame.\n        Args:\n            doors ((n_doors, 2, 2) array): list of pairs of points of door edges.\n            floor_size (float): size of floor\n            grid_size (int): size of placement grid\n    '''", "\n", "_doors", "=", "doors", "+", "0.5", "\n", "scaling", "=", "floor_size", "/", "grid_size", "\n", "_door_sizes", "=", "np", ".", "array", "(", "[", "np", ".", "linalg", ".", "norm", "(", "door", "[", "1", "]", "-", "door", "[", "0", "]", ")", "*", "scaling", "for", "door", "in", "_doors", "]", ")", "\n", "_doors", "=", "np", ".", "array", "(", "[", "(", "door", "[", "0", "]", "+", "(", "door", "[", "1", "]", "-", "door", "[", "0", "]", ")", "/", "2", ")", "*", "scaling", "for", "door", "in", "_doors", "]", ")", "\n", "return", "np", ".", "concatenate", "(", "[", "_doors", ",", "_door_sizes", "[", ":", ",", "None", "]", "]", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.add_walls_to_grid": [[222, 234], ["None"], "function", ["None"], ["", "def", "add_walls_to_grid", "(", "grid", ",", "walls", ")", ":", "\n", "    ", "'''\n        Draw walls onto a grid.\n        Args:\n            grid (np.ndarray): 2D occupancy grid\n            walls (Wall list): walls\n    '''", "\n", "for", "wall", "in", "walls", ":", "\n", "        ", "if", "wall", ".", "is_vertical", ":", "\n", "            ", "grid", "[", "wall", ".", "pt1", "[", "0", "]", ",", "wall", ".", "pt1", "[", "1", "]", ":", "wall", ".", "pt2", "[", "1", "]", "+", "1", "]", "=", "1", "\n", "", "else", ":", "\n", "            ", "grid", "[", "wall", ".", "pt1", "[", "0", "]", ":", "wall", ".", "pt2", "[", "0", "]", "+", "1", ",", "wall", ".", "pt1", "[", "1", "]", "]", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.walls_to_mujoco": [[236, 284], ["enumerate", "mujoco_worldgen.Geom", "mujoco_worldgen.Geom.mark_static", "mujoco_worldgen.Geom.add_transform", "mujoco_worldgen.Geom.add_transform", "floor.append", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "mujoco_worldgen.transforms.set_geom_attr_transform", "mujoco_worldgen.transforms.set_geom_attr_transform", "mujoco_worldgen.Geom.add_transform", "mujoco_worldgen.transforms.set_geom_attr_transform"], "function", ["None"], ["", "", "", "def", "walls_to_mujoco", "(", "floor", ",", "floor_size", ",", "grid_size", ",", "walls", ",", "friction", "=", "None", ")", ":", "\n", "    ", "'''\n        Take a list of walls in grid frame and add them to the floor in the worldgen frame.\n        Args:\n            floor (worldgen.Floor): floor\n            floor_size (float): size of floor\n            grid_size (int): size of placement grid\n            walls (Wall list): list of walls\n            friction (float): wall friction\n    '''", "\n", "wall_width", "=", "floor_size", "/", "grid_size", "/", "2", "\n", "grid_cell_length", "=", "floor_size", "/", "grid_size", "\n", "for", "i", ",", "wall", "in", "enumerate", "(", "walls", ")", ":", "\n", "        ", "if", "wall", ".", "is_vertical", ":", "\n", "            ", "wall_length_grid", "=", "(", "wall", ".", "pt2", "[", "1", "]", "-", "wall", ".", "pt1", "[", "1", "]", "+", "1", ")", "\n", "offset", "=", "np", ".", "array", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "wall_length_grid", "=", "(", "wall", ".", "pt2", "[", "0", "]", "-", "wall", ".", "pt1", "[", "0", "]", "+", "1", ")", "\n", "offset", "=", "np", ".", "array", "(", "[", "1", ",", "-", "1", "]", ")", "\n", "\n", "# Convert to mujoco frame", "\n", "", "wall_length", "=", "wall_length_grid", "*", "grid_cell_length", "\n", "# Subtract 1 grid_cell_length such that walls originate and end in the center of a grid cell", "\n", "# Subtract 1 wall_width such that perpendicular walls do not intersect at the center of a", "\n", "# grid cell", "\n", "wall_length", "-=", "grid_cell_length", "+", "wall_width", "\n", "\n", "if", "wall", ".", "is_vertical", ":", "\n", "            ", "size", "=", "(", "wall_width", ",", "wall_length", ",", "wall", ".", "height", ")", "\n", "", "else", ":", "\n", "            ", "size", "=", "(", "wall_length", ",", "wall_width", ",", "wall", ".", "height", ")", "\n", "\n", "# Position of object should be in the middle of a grid cell (add 0.5) shifted by", "\n", "#     the wall width such that corners don't overlap", "\n", "", "pos", "=", "np", ".", "array", "(", "[", "wall", ".", "pt1", "[", "0", "]", "+", "0.5", ",", "wall", ".", "pt1", "[", "1", "]", "+", "0.5", "]", ")", "/", "grid_size", "\n", "pos", "+=", "offset", "*", "wall_width", "/", "floor_size", "/", "2", "\n", "\n", "# Convert from mujoco to worldgen scale", "\n", "scale_x", "=", "(", "floor_size", "-", "size", "[", "0", "]", ")", "/", "floor_size", "\n", "scale_y", "=", "(", "floor_size", "-", "size", "[", "1", "]", ")", "/", "floor_size", "\n", "pos", "=", "pos", "/", "np", ".", "array", "(", "[", "scale_x", ",", "scale_y", "]", ")", "\n", "geom", "=", "Geom", "(", "'box'", ",", "size", ",", "name", "=", "f\"wall{i}\"", ")", "\n", "geom", ".", "mark_static", "(", ")", "\n", "geom", ".", "add_transform", "(", "set_geom_attr_transform", "(", "'rgba'", ",", "wall", ".", "rgba", ")", ")", "\n", "geom", ".", "add_transform", "(", "set_geom_attr_transform", "(", "'group'", ",", "1", ")", ")", "\n", "if", "friction", "is", "not", "None", ":", "\n", "            ", "geom", ".", "add_transform", "(", "set_geom_attr_transform", "(", "'friction'", ",", "friction", ")", ")", "\n", "", "floor", ".", "append", "(", "geom", ",", "placement_xy", "=", "pos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.walls.outside_walls": [[286, 292], ["walls.Wall", "walls.Wall", "walls.Wall", "walls.Wall"], "function", ["None"], ["", "", "def", "outside_walls", "(", "grid_size", ",", "rgba", "=", "(", "0", ",", "1", ",", "0", ",", "0.1", ")", ",", "use_low_wall_height", "=", "False", ")", ":", "\n", "    ", "height", "=", "0.5", "if", "use_low_wall_height", "else", "4.0", "\n", "return", "[", "Wall", "(", "[", "0", ",", "0", "]", ",", "[", "0", ",", "grid_size", "-", "1", "]", ",", "height", "=", "height", ",", "rgba", "=", "rgba", ")", ",", "\n", "Wall", "(", "[", "0", ",", "0", "]", ",", "[", "grid_size", "-", "1", ",", "0", "]", ",", "height", "=", "height", ",", "rgba", "=", "rgba", ")", ",", "\n", "Wall", "(", "[", "grid_size", "-", "1", ",", "0", "]", ",", "[", "grid_size", "-", "1", ",", "grid_size", "-", "1", "]", ",", "height", "=", "height", ",", "rgba", "=", "rgba", ")", ",", "\n", "Wall", "(", "[", "0", ",", "grid_size", "-", "1", "]", ",", "[", "grid_size", "-", "1", ",", "grid_size", "-", "1", "]", ",", "height", "=", "height", ",", "rgba", "=", "rgba", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.agents.Agents.__init__": [[27, 31], ["None"], "methods", ["None"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "n_agents", ",", "placement_fn", "=", "None", ",", "color", "=", "None", ",", "friction", "=", "None", ",", "\n", "damp_z", "=", "False", ",", "polar_obs", "=", "True", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.agents.Agents.build_world_step": [[32, 67], ["range", "range", "env.metadata.pop", "mujoco_worldgen.ObjFromXML", "mujoco_worldgen.ObjFromXML.add_transform", "mujoco_worldgen.ObjFromXML.add_transform", "mujoco_worldgen.ObjFromXML.add_transform", "mae_envs.modules.get_size_from_xml", "mae_envs.modules.rejection_placement", "floor.append", "mujoco_worldgen.transforms.set_geom_attr_transform", "isinstance", "mujoco_worldgen.transforms.set_geom_attr_transform", "mae_envs.util.transforms.set_joint_damping_transform", "isinstance", "floor.append"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.get_size_from_xml", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.rejection_placement", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.util.transforms.set_joint_damping_transform"], ["", "def", "build_world_step", "(", "self", ",", "env", ",", "floor", ",", "floor_size", ")", ":", "\n", "        ", "env", ".", "metadata", "[", "'n_agents'", "]", "=", "self", ".", "n_agents", "\n", "successful_placement", "=", "True", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "n_agents", ")", ":", "\n", "            ", "env", ".", "metadata", ".", "pop", "(", "f\"agent{i}_initpos\"", ",", "None", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "n_agents", ")", ":", "\n", "            ", "obj", "=", "ObjFromXML", "(", "\"particle_hinge\"", ",", "name", "=", "f\"agent{i}\"", ")", "\n", "if", "self", ".", "friction", "is", "not", "None", ":", "\n", "                ", "obj", ".", "add_transform", "(", "set_geom_attr_transform", "(", "'friction'", ",", "self", ".", "friction", ")", ")", "\n", "", "if", "self", ".", "color", "is", "not", "None", ":", "\n", "                ", "_color", "=", "(", "self", ".", "color", "[", "i", "]", "\n", "if", "isinstance", "(", "self", ".", "color", "[", "0", "]", ",", "(", "list", ",", "tuple", ",", "np", ".", "ndarray", ")", ")", "\n", "else", "self", ".", "color", ")", "\n", "obj", ".", "add_transform", "(", "set_geom_attr_transform", "(", "'rgba'", ",", "_color", ")", ")", "\n", "", "if", "not", "self", ".", "damp_z", ":", "\n", "                ", "obj", ".", "add_transform", "(", "set_joint_damping_transform", "(", "1", ",", "'tz'", ")", ")", "\n", "\n", "", "if", "self", ".", "placement_fn", "is", "not", "None", ":", "\n", "                ", "_placement_fn", "=", "(", "self", ".", "placement_fn", "[", "i", "]", "\n", "if", "isinstance", "(", "self", ".", "placement_fn", ",", "list", ")", "\n", "else", "self", ".", "placement_fn", ")", "\n", "obj_size", "=", "get_size_from_xml", "(", "obj", ")", "\n", "pos", ",", "pos_grid", "=", "rejection_placement", "(", "env", ",", "_placement_fn", ",", "floor_size", ",", "obj_size", ")", "\n", "if", "pos", "is", "not", "None", ":", "\n", "                    ", "floor", ".", "append", "(", "obj", ",", "placement_xy", "=", "pos", ")", "\n", "# store spawn position in metadata. This allows sampling subsequent agents", "\n", "# close to previous agents", "\n", "env", ".", "metadata", "[", "f\"agent{i}_initpos\"", "]", "=", "pos_grid", "\n", "", "else", ":", "\n", "                    ", "successful_placement", "=", "False", "\n", "", "", "else", ":", "\n", "                ", "floor", ".", "append", "(", "obj", ")", "\n", "", "", "return", "successful_placement", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.agents.Agents.modify_sim_step": [[68, 76], ["numpy.array", "numpy.array", "sim.model.geom_name2id", "mujoco_worldgen.util.sim_funcs.qpos_idxs_from_joint_prefix", "mujoco_worldgen.util.sim_funcs.qvel_idxs_from_joint_prefix", "range", "range", "range"], "methods", ["None"], ["", "def", "modify_sim_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "# Cache qpos, qvel idxs", "\n", "        ", "self", ".", "agent_qpos_idxs", "=", "np", ".", "array", "(", "[", "qpos_idxs_from_joint_prefix", "(", "sim", ",", "f'agent{i}'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_agents", ")", "]", ")", "\n", "self", ".", "agent_qvel_idxs", "=", "np", ".", "array", "(", "[", "qvel_idxs_from_joint_prefix", "(", "sim", ",", "f'agent{i}'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_agents", ")", "]", ")", "\n", "env", ".", "metadata", "[", "'agent_geom_idxs'", "]", "=", "[", "sim", ".", "model", ".", "geom_name2id", "(", "f'agent{i}:agent'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_agents", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.agents.Agents.observation_step": [[77, 95], ["sim.data.qpos.copy", "sim.data.qvel.copy", "numpy.concatenate", "numpy.concatenate", "mujoco_worldgen.util.rotation.normalize_angles", "numpy.concatenate", "numpy.cos", "numpy.sin"], "methods", ["None"], ["", "def", "observation_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "        ", "qpos", "=", "sim", ".", "data", ".", "qpos", ".", "copy", "(", ")", "\n", "qvel", "=", "sim", ".", "data", ".", "qvel", ".", "copy", "(", ")", "\n", "\n", "agent_qpos", "=", "qpos", "[", "self", ".", "agent_qpos_idxs", "]", "\n", "agent_qvel", "=", "qvel", "[", "self", ".", "agent_qvel_idxs", "]", "\n", "agent_angle", "=", "agent_qpos", "[", ":", ",", "[", "-", "1", "]", "]", "-", "np", ".", "pi", "/", "2", "# Rotate the angle to match visual front", "\n", "agent_qpos_qvel", "=", "np", ".", "concatenate", "(", "[", "agent_qpos", ",", "agent_qvel", "]", ",", "-", "1", ")", "\n", "polar_angle", "=", "np", ".", "concatenate", "(", "[", "np", ".", "cos", "(", "agent_angle", ")", ",", "np", ".", "sin", "(", "agent_angle", ")", "]", ",", "-", "1", ")", "\n", "if", "self", ".", "polar_obs", ":", "\n", "            ", "agent_qpos", "=", "np", ".", "concatenate", "(", "[", "agent_qpos", "[", ":", ",", ":", "-", "1", "]", ",", "polar_angle", "]", ",", "-", "1", ")", "\n", "", "agent_angle", "=", "normalize_angles", "(", "agent_angle", ")", "\n", "obs", "=", "{", "\n", "'agent_qpos_qvel'", ":", "agent_qpos_qvel", ",", "\n", "'agent_angle'", ":", "agent_angle", ",", "\n", "'agent_pos'", ":", "agent_qpos", "[", ":", ",", ":", "3", "]", "}", "\n", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.agents.AgentManipulation.__init__": [[102, 105], ["None"], "methods", ["None"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.agents.AgentManipulation.build_world_step": [[106, 111], ["range", "floor.add_transform", "mae_envs.util.transforms.add_weld_equality_constraint_transform"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.util.transforms.add_weld_equality_constraint_transform"], ["", "def", "build_world_step", "(", "self", ",", "env", ",", "floor", ",", "floor_size", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "env", ".", "n_agents", ")", ":", "\n", "            ", "floor", ".", "add_transform", "(", "add_weld_equality_constraint_transform", "(", "\n", "f'agent{i}:gripper'", ",", "f'agent{i}:particle'", ",", "'floor0'", ")", ")", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.agents.AgentManipulation.modify_sim_step": [[112, 114], ["None"], "methods", ["None"], ["", "def", "modify_sim_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "        ", "sim", ".", "model", ".", "eq_active", "[", ":", "]", "=", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.get_size_from_xml": [[5, 19], ["mujoco_worldgen.parser.parse_file", "body.get", "obj._generate_xml_path"], "function", ["None"], ["def", "get_size_from_xml", "(", "obj", ")", ":", "\n", "    ", "'''\n        Args:\n            obj (worldgen.Obj): worldgen object\n        Returns: size of object annotation:outerbound if it exists, None if it doesn't\n    '''", "\n", "outer_bound", "=", "None", "\n", "for", "body", "in", "parse_file", "(", "obj", ".", "_generate_xml_path", "(", ")", ")", "[", "'worldbody'", "]", "[", "'body'", "]", ":", "\n", "        ", "if", "body", ".", "get", "(", "'@name'", ",", "''", ")", "==", "'annotation:outer_bound'", ":", "\n", "            ", "outer_bound", "=", "body", "\n", "", "", "if", "outer_bound", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "else", ":", "\n", "        ", "return", "outer_bound", "[", "'geom'", "]", "[", "0", "]", "[", "'@size'", "]", "[", ":", "2", "]", "*", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.rejection_placement": [[21, 61], ["len", "numpy.ceil().astype", "range", "numpy.any", "numpy.ceil", "placement_fn", "numpy.array", "env._random_state.uniform", "env._random_state.randint", "env._random_state.randint"], "function", ["None"], ["", "", "def", "rejection_placement", "(", "env", ",", "placement_fn", ",", "floor_size", ",", "obj_size", ",", "num_tries", "=", "10", ")", ":", "\n", "    ", "'''\n        Args:\n            env (gym.Env): environment\n            placement_fn (function): Function that returns a position on a grid\n                Args:\n                    grid (np.ndarray): 2D occupancy grid. 1's mean occupied\n                    obj_size_in_cells (int np.ndarray): number of cells in [x, y]\n                        that this object would occupy on the grid. Currently only supports\n                        rectangular object sizes (but so does worldgen)\n                    env.metadata (dict): environment metadata\n                    random_state (np.random.RandomState): numpy random state\n                Returns: x, y placement position on grid\n            floor_size (float): size of floor\n            obj_size (float np.ndarray): [x, y] size of object\n            num_tries (int): number of tries to place object\n        Returns: int np.ndarray([x, y]) position on grid or None if no placement was found.\n    '''", "\n", "grid", "=", "env", ".", "placement_grid", "\n", "grid_size", "=", "len", "(", "grid", ")", "\n", "cell_size", "=", "floor_size", "/", "grid_size", "\n", "obj_size_in_cells", "=", "np", ".", "ceil", "(", "obj_size", "/", "cell_size", ")", ".", "astype", "(", "int", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_tries", ")", ":", "\n", "        ", "if", "placement_fn", "is", "not", "None", ":", "\n", "            ", "pos", "=", "placement_fn", "(", "grid", ",", "obj_size_in_cells", ",", "env", ".", "metadata", ",", "env", ".", "_random_state", ")", "\n", "", "else", ":", "\n", "# Assume that we'll always have boundary walls so don't sample there", "\n", "            ", "pos", "=", "np", ".", "array", "(", "[", "env", ".", "_random_state", ".", "randint", "(", "1", ",", "grid_size", "-", "obj_size_in_cells", "[", "0", "]", "-", "1", ")", ",", "\n", "env", ".", "_random_state", ".", "randint", "(", "1", ",", "grid_size", "-", "obj_size_in_cells", "[", "1", "]", "-", "1", ")", "]", ")", "\n", "", "if", "np", ".", "any", "(", "grid", "[", "pos", "[", "0", "]", ":", "pos", "[", "0", "]", "+", "obj_size_in_cells", "[", "0", "]", ",", "pos", "[", "1", "]", ":", "pos", "[", "1", "]", "+", "obj_size_in_cells", "[", "1", "]", "]", ")", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "            ", "extra_room", "=", "obj_size_in_cells", "*", "cell_size", "-", "obj_size", "\n", "pos_on_floor", "=", "pos", "/", "grid_size", "*", "floor_size", "\n", "pos_on_floor", "+=", "env", ".", "_random_state", ".", "uniform", "(", "[", "0", ",", "0", "]", ",", "extra_room", ")", "\n", "placement", "=", "pos_on_floor", "/", "(", "floor_size", "-", "obj_size", ")", "\n", "grid", "[", "pos", "[", "0", "]", ":", "pos", "[", "0", "]", "+", "obj_size_in_cells", "[", "0", "]", ",", "pos", "[", "1", "]", ":", "pos", "[", "1", "]", "+", "obj_size_in_cells", "[", "1", "]", "]", "=", "1", "\n", "return", "placement", ",", "pos", "\n", "", "", "return", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.uniform_placement": [[63, 69], ["len", "numpy.array", "random_state.randint", "random_state.randint"], "function", ["None"], ["", "def", "uniform_placement", "(", "grid", ",", "obj_size", ",", "metadata", ",", "random_state", ")", ":", "\n", "    ", "grid_size", "=", "len", "(", "grid", ")", "\n", "pos", "=", "np", ".", "array", "(", "[", "random_state", ".", "randint", "(", "1", ",", "grid_size", "-", "obj_size", "[", "0", "]", "-", "1", ")", ",", "\n", "random_state", ".", "randint", "(", "1", ",", "grid_size", "-", "obj_size", "[", "1", "]", "-", "1", ")", "]", ")", "\n", "\n", "return", "pos", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.close_to_other_object_placement": [[71, 94], ["len", "numpy.maximum", "numpy.minimum", "numpy.array", "random_state.randint", "random_state.randint"], "function", ["None"], ["", "def", "close_to_other_object_placement", "(", "object_type", ",", "object_index", ",", "radius_key", ")", ":", "\n", "    ", "def", "close_placement_fn", "(", "grid", ",", "obj_size", ",", "metadata", ",", "random_state", ")", ":", "\n", "        ", "init_pos_key", "=", "f\"{object_type}{object_index}_initpos\"", "\n", "\n", "assert", "init_pos_key", "in", "metadata", ",", "f\"First object position must be specified in metadata['{init_pos_key}']\"", "\n", "assert", "radius_key", "in", "metadata", ",", "f\"metadata['{radius_key}'] mus be specified.\"", "\n", "\n", "grid_size", "=", "len", "(", "grid", ")", "\n", "\n", "anchor_obj_pos", "=", "metadata", "[", "f\"{init_pos_key}\"", "]", "\n", "rad_in_cells", "=", "metadata", "[", "radius_key", "]", "\n", "\n", "distr_limits_min", "=", "np", ".", "maximum", "(", "1", ",", "anchor_obj_pos", "-", "rad_in_cells", ")", "\n", "distr_limits_max", "=", "np", ".", "minimum", "(", "grid_size", "-", "1", ",", "anchor_obj_pos", "+", "rad_in_cells", ")", "\n", "\n", "pos", "=", "np", ".", "array", "(", "[", "random_state", ".", "randint", "(", "distr_limits_min", "[", "0", "]", ",", "distr_limits_max", "[", "0", "]", ")", ",", "\n", "random_state", ".", "randint", "(", "distr_limits_min", "[", "1", "]", ",", "distr_limits_max", "[", "1", "]", ")", "]", ")", "\n", "\n", "return", "pos", "\n", "\n", "", "return", "close_placement_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.uniform_placement_middle": [[96, 123], ["len", "numpy.array", "random_state.randint", "random_state.randint"], "function", ["None"], ["", "def", "uniform_placement_middle", "(", "area_side_length_fraction", ")", ":", "\n", "    ", "'''\n        Creates a sampling function that samples object position uniformly within the\n        middle of the playing area. E.g. if the playing area is\n           ------\n           |AAAA|\n           |ABBA|\n           |ABBA|\n           |AAAA|\n           ------\n        then uniform_placement_middle(0.5) will returned a function that samples the object position\n        from any of the B cells.\n        Args:\n            area_side_length_fraction (float, between 0 and 1): Length of the sides of the middle\n                square being sampled from, as fraction of the overall playing field\n    '''", "\n", "def", "uniform_placement_middle_fn", "(", "grid", ",", "obj_size", ",", "metadata", ",", "random_state", ")", ":", "\n", "        ", "grid_size", "=", "len", "(", "grid", ")", "\n", "distr_limits_min", "=", "(", "(", "grid_size", "-", "obj_size", ")", "*", "(", "1", "-", "area_side_length_fraction", ")", "/", "2", "+", "area_side_length_fraction", ")", ".", "astype", "(", "int", ")", "\n", "distr_limits_max", "=", "(", "(", "grid_size", "-", "obj_size", ")", "*", "(", "1", "+", "area_side_length_fraction", ")", "/", "2", "-", "area_side_length_fraction", ")", ".", "astype", "(", "int", ")", "\n", "\n", "pos", "=", "np", ".", "array", "(", "[", "random_state", ".", "randint", "(", "distr_limits_min", "[", "0", "]", ",", "distr_limits_max", "[", "0", "]", ")", ",", "\n", "random_state", ".", "randint", "(", "distr_limits_min", "[", "1", "]", ",", "distr_limits_max", "[", "1", "]", ")", "]", ")", "\n", "\n", "return", "pos", "\n", "\n", "", "return", "uniform_placement_middle_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.center_placement": [[125, 130], ["int", "numpy.array", "len", "int", "int"], "function", ["None"], ["", "def", "center_placement", "(", "grid", ",", "obj_size_in_cells", ",", "metadata", ",", "random_state", ")", ":", "\n", "    ", "half_grid_size", "=", "int", "(", "len", "(", "grid", ")", "/", "2", ")", "\n", "pos", "=", "np", ".", "array", "(", "[", "half_grid_size", "-", "int", "(", "obj_size_in_cells", "[", "0", "]", "/", "2", ")", ",", "\n", "half_grid_size", "-", "int", "(", "obj_size_in_cells", "[", "1", "]", "/", "2", ")", "]", ")", "\n", "return", "pos", "\n", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.food.Food.__init__": [[16, 21], ["type"], "methods", ["None"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "n_food", ",", "food_size", "=", "0.1", ",", "placement_fn", "=", "None", ")", ":", "\n", "        ", "if", "type", "(", "n_food", ")", "not", "in", "[", "tuple", ",", "list", ",", "np", ".", "ndarray", "]", ":", "\n", "            ", "self", ".", "n_food", "=", "[", "n_food", ",", "n_food", "]", "\n", "", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.food.Food.build_world_step": [[22, 54], ["env._random_state.randint", "range", "range", "env.metadata.pop", "mae_envs.modules.rejection_placement", "floor.mark", "isinstance", "numpy.array", "floor.mark", "numpy.append"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.rejection_placement"], ["", "def", "build_world_step", "(", "self", ",", "env", ",", "floor", ",", "floor_size", ")", ":", "\n", "        ", "env", ".", "metadata", "[", "'food_size'", "]", "=", "self", ".", "food_size", "\n", "self", ".", "curr_n_food", "=", "env", ".", "_random_state", ".", "randint", "(", "self", ".", "n_food", "[", "0", "]", ",", "self", ".", "n_food", "[", "1", "]", "+", "1", ")", "\n", "env", ".", "metadata", "[", "'max_n_food'", "]", "=", "self", ".", "n_food", "[", "1", "]", "\n", "env", ".", "metadata", "[", "'curr_n_food'", "]", "=", "self", ".", "curr_n_food", "\n", "successful_placement", "=", "True", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "curr_n_food", ")", ":", "\n", "            ", "env", ".", "metadata", ".", "pop", "(", "f\"food{i}_initpos\"", ",", "None", ")", "\n", "\n", "# Add food sites", "\n", "", "for", "i", "in", "range", "(", "self", ".", "curr_n_food", ")", ":", "\n", "            ", "if", "self", ".", "placement_fn", "is", "not", "None", ":", "\n", "                ", "_placement_fn", "=", "(", "self", ".", "placement_fn", "[", "i", "]", "\n", "if", "isinstance", "(", "self", ".", "placement_fn", ",", "list", ")", "\n", "else", "self", ".", "placement_fn", ")", "\n", "pos", ",", "pos_grid", "=", "rejection_placement", "(", "env", ",", "_placement_fn", ",", "floor_size", ",", "\n", "np", ".", "array", "(", "[", "self", ".", "food_size", ",", "self", ".", "food_size", "]", ")", ")", "\n", "if", "pos", "is", "not", "None", ":", "\n", "                    ", "floor", ".", "mark", "(", "f\"food{i}\"", ",", "relative_xyz", "=", "np", ".", "append", "(", "pos", ",", "[", "self", ".", "food_size", "/", "2", "]", ")", ",", "\n", "size", "=", "(", "self", ".", "food_size", ",", "self", ".", "food_size", ",", "self", ".", "food_size", ")", ",", "\n", "rgba", "=", "(", "0.", ",", "1.", ",", "0.", ",", "1.", ")", ")", "\n", "\n", "# store spawn position in metadata. This allows sampling subsequent food items", "\n", "# close to previous food items", "\n", "env", ".", "metadata", "[", "f\"food{i}_initpos\"", "]", "=", "pos_grid", "\n", "", "else", ":", "\n", "                    ", "successful_placement", "=", "False", "\n", "", "", "else", ":", "\n", "                ", "floor", ".", "mark", "(", "f\"food{i}\"", ",", "rgba", "=", "(", "0.", ",", "1.", ",", "0.", ",", "1.", ")", ",", "\n", "size", "=", "(", "self", ".", "food_size", ",", "self", ".", "food_size", ",", "self", ".", "food_size", ")", ")", "\n", "", "", "return", "successful_placement", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.food.Food.modify_sim_step": [[55, 58], ["numpy.array", "sim.model.site_name2id", "range"], "methods", ["None"], ["", "def", "modify_sim_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "        ", "self", ".", "food_site_ids", "=", "np", ".", "array", "(", "[", "sim", ".", "model", ".", "site_name2id", "(", "f'food{i}'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "curr_n_food", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.food.Food.observation_step": [[59, 65], ["numpy.zeros"], "methods", ["None"], ["", "def", "observation_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "        ", "if", "self", ".", "curr_n_food", ">", "0", ":", "\n", "            ", "obs", "=", "{", "'food_pos'", ":", "sim", ".", "data", ".", "site_xpos", "[", "self", ".", "food_site_ids", "]", "}", "\n", "", "else", ":", "\n", "            ", "obs", "=", "{", "'food_pos'", ":", "np", ".", "zeros", "(", "(", "0", ",", "3", ")", ")", "}", "\n", "", "return", "obs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.hide_and_seek.TrackStatWrapper.__init__": [[35, 40], ["gym.Wrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "n_boxes", ",", "n_ramps", ",", "n_food", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "n_boxes", "=", "n_boxes", "\n", "self", ".", "n_ramps", "=", "n_ramps", "\n", "self", ".", "n_food", "=", "n_food", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.hide_and_seek.TrackStatWrapper.reset": [[41, 53], ["hide_and_seek.TrackStatWrapper.env.reset", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "if", "self", ".", "n_boxes", ">", "0", ":", "\n", "            ", "self", ".", "box_pos_start", "=", "obs", "[", "'box_pos'", "]", "\n", "", "if", "self", ".", "n_ramps", ">", "0", ":", "\n", "            ", "self", ".", "ramp_pos_start", "=", "obs", "[", "'ramp_pos'", "]", "\n", "", "if", "self", ".", "n_food", ">", "0", ":", "\n", "            ", "self", ".", "total_food_eaten", "=", "np", ".", "sum", "(", "obs", "[", "'food_eat'", "]", ")", "\n", "\n", "", "self", ".", "in_prep_phase", "=", "True", "\n", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.hide_and_seek.TrackStatWrapper.step": [[54, 102], ["hide_and_seek.TrackStatWrapper.env.step", "numpy.sum", "numpy.max", "numpy.sum", "numpy.max", "numpy.max", "numpy.sum", "info.update", "numpy.max", "info.update", "info.update", "numpy.linalg.norm", "numpy.linalg.norm", "numpy.sum", "numpy.linalg.norm", "numpy.linalg.norm", "numpy.sum", "info.update"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "\n", "if", "self", ".", "n_food", ">", "0", ":", "\n", "            ", "self", ".", "total_food_eaten", "+=", "np", ".", "sum", "(", "obs", "[", "'food_eat'", "]", ")", "\n", "\n", "", "if", "self", ".", "in_prep_phase", "and", "obs", "[", "'prep_obs'", "]", "[", "0", ",", "0", "]", "==", "1.0", ":", "\n", "# Track statistics at end of preparation phase", "\n", "            ", "self", ".", "in_prep_phase", "=", "False", "\n", "\n", "if", "self", ".", "n_boxes", ">", "0", ":", "\n", "                ", "self", ".", "max_box_move_prep", "=", "np", ".", "max", "(", "np", ".", "linalg", ".", "norm", "(", "obs", "[", "'box_pos'", "]", "-", "self", ".", "box_pos_start", ",", "axis", "=", "-", "1", ")", ")", "\n", "self", ".", "num_box_lock_prep", "=", "np", ".", "sum", "(", "obs", "[", "'obj_lock'", "]", ")", "\n", "", "if", "self", ".", "n_ramps", ">", "0", ":", "\n", "                ", "self", ".", "max_ramp_move_prep", "=", "np", ".", "max", "(", "np", ".", "linalg", ".", "norm", "(", "obs", "[", "'ramp_pos'", "]", "-", "self", ".", "ramp_pos_start", ",", "axis", "=", "-", "1", ")", ")", "\n", "if", "'ramp_obj_lock'", "in", "obs", ":", "\n", "                    ", "self", ".", "num_ramp_lock_prep", "=", "np", ".", "sum", "(", "obs", "[", "'ramp_obj_lock'", "]", ")", "\n", "", "", "if", "self", ".", "n_food", ">", "0", ":", "\n", "                ", "self", ".", "total_food_eaten_prep", "=", "self", ".", "total_food_eaten", "\n", "\n", "", "", "if", "done", ":", "\n", "# Track statistics at end of episode", "\n", "            ", "if", "self", ".", "n_boxes", ">", "0", ":", "\n", "                ", "self", ".", "max_box_move", "=", "np", ".", "max", "(", "np", ".", "linalg", ".", "norm", "(", "obs", "[", "'box_pos'", "]", "-", "self", ".", "box_pos_start", ",", "axis", "=", "-", "1", ")", ")", "\n", "self", ".", "num_box_lock", "=", "np", ".", "sum", "(", "obs", "[", "'obj_lock'", "]", ")", "\n", "info", ".", "update", "(", "{", "\n", "'max_box_move_prep'", ":", "self", ".", "max_box_move_prep", ",", "\n", "'max_box_move'", ":", "self", ".", "max_box_move", ",", "\n", "'num_box_lock_prep'", ":", "self", ".", "num_box_lock_prep", ",", "\n", "'num_box_lock'", ":", "self", ".", "num_box_lock", "}", ")", "\n", "\n", "", "if", "self", ".", "n_ramps", ">", "0", ":", "\n", "                ", "self", ".", "max_ramp_move", "=", "np", ".", "max", "(", "np", ".", "linalg", ".", "norm", "(", "obs", "[", "'ramp_pos'", "]", "-", "self", ".", "ramp_pos_start", ",", "axis", "=", "-", "1", ")", ")", "\n", "info", ".", "update", "(", "{", "\n", "'max_ramp_move_prep'", ":", "self", ".", "max_ramp_move_prep", ",", "\n", "'max_ramp_move'", ":", "self", ".", "max_ramp_move", "}", ")", "\n", "if", "'ramp_obj_lock'", "in", "obs", ":", "\n", "                    ", "self", ".", "num_ramp_lock", "=", "np", ".", "sum", "(", "obs", "[", "'ramp_obj_lock'", "]", ")", "\n", "info", ".", "update", "(", "{", "\n", "'num_ramp_lock_prep'", ":", "self", ".", "num_ramp_lock_prep", ",", "\n", "'num_ramp_lock'", ":", "self", ".", "num_ramp_lock", "}", ")", "\n", "\n", "", "", "if", "self", ".", "n_food", ">", "0", ":", "\n", "                ", "info", ".", "update", "(", "{", "\n", "'food_eaten'", ":", "self", ".", "total_food_eaten", ",", "\n", "'food_eaten_prep'", ":", "self", ".", "total_food_eaten_prep", "}", ")", "\n", "\n", "", "", "return", "obs", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.hide_and_seek.HideAndSeekRewardWrapper.__init__": [[119, 134], ["gym.Wrapper.__init__", "range", "range"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "n_hiders", ",", "n_seekers", ",", "rew_type", "=", "'selfish'", ",", "reward_scale", "=", "1.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "n_agents", "=", "self", ".", "unwrapped", ".", "n_agents", "\n", "self", ".", "rew_type", "=", "rew_type", "\n", "self", ".", "n_hiders", "=", "n_hiders", "\n", "self", ".", "n_seekers", "=", "n_seekers", "\n", "self", ".", "reward_scale", "=", "reward_scale", "\n", "assert", "n_hiders", "+", "n_seekers", "==", "self", ".", "n_agents", ",", "\"n_hiders + n_seekers must equal n_agents\"", "\n", "\n", "self", ".", "metadata", "[", "'n_hiders'", "]", "=", "n_hiders", "\n", "self", ".", "metadata", "[", "'n_seekers'", "]", "=", "n_seekers", "\n", "\n", "# Agent names are used to plot agent-specific rewards on tensorboard", "\n", "self", ".", "unwrapped", ".", "agent_names", "=", "[", "f'hider{i}'", "for", "i", "in", "range", "(", "self", ".", "n_hiders", ")", "]", "+", "[", "f'seeker{i}'", "for", "i", "in", "range", "(", "self", ".", "n_seekers", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.hide_and_seek.HideAndSeekRewardWrapper.step": [[135, 156], ["hide_and_seek.HideAndSeekRewardWrapper.env.step", "numpy.ones", "this_rew[].mean", "this_rew[].mean", "numpy.any", "numpy.min", "numpy.max", "numpy.any"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "\n", "this_rew", "=", "np", ".", "ones", "(", "(", "self", ".", "n_agents", ",", ")", ")", "\n", "this_rew", "[", ":", "self", ".", "n_hiders", "]", "[", "np", ".", "any", "(", "obs", "[", "'mask_aa_obs'", "]", "[", "self", ".", "n_hiders", ":", ",", ":", "self", ".", "n_hiders", "]", ",", "0", ")", "]", "=", "-", "1.0", "\n", "this_rew", "[", "self", ".", "n_hiders", ":", "]", "[", "~", "np", ".", "any", "(", "obs", "[", "'mask_aa_obs'", "]", "[", "self", ".", "n_hiders", ":", ",", ":", "self", ".", "n_hiders", "]", ",", "1", ")", "]", "=", "-", "1.0", "\n", "\n", "if", "self", ".", "rew_type", "==", "'joint_mean'", ":", "\n", "            ", "this_rew", "[", ":", "self", ".", "n_hiders", "]", "=", "this_rew", "[", ":", "self", ".", "n_hiders", "]", ".", "mean", "(", ")", "\n", "this_rew", "[", "self", ".", "n_hiders", ":", "]", "=", "this_rew", "[", "self", ".", "n_hiders", ":", "]", ".", "mean", "(", ")", "\n", "", "elif", "self", ".", "rew_type", "==", "'joint_zero_sum'", ":", "\n", "            ", "this_rew", "[", ":", "self", ".", "n_hiders", "]", "=", "np", ".", "min", "(", "this_rew", "[", ":", "self", ".", "n_hiders", "]", ")", "\n", "this_rew", "[", "self", ".", "n_hiders", ":", "]", "=", "np", ".", "max", "(", "this_rew", "[", "self", ".", "n_hiders", ":", "]", ")", "\n", "", "elif", "self", ".", "rew_type", "==", "'selfish'", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "f'Hide and Seek reward type {self.rew_type} is not implemented'", "\n", "\n", "", "this_rew", "*=", "self", ".", "reward_scale", "\n", "rew", "+=", "this_rew", "\n", "return", "obs", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.hide_and_seek.MaskUnseenAction.__init__": [[169, 175], ["gym.Wrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "team_idx", ",", "action_key", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "team_idx", "=", "team_idx", "\n", "self", ".", "action_key", "=", "action_key", "\n", "self", ".", "n_agents", "=", "self", ".", "unwrapped", ".", "n_agents", "\n", "self", ".", "n_hiders", "=", "self", ".", "metadata", "[", "'n_hiders'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.hide_and_seek.MaskUnseenAction.reset": [[176, 181], ["hide_and_seek.MaskUnseenAction.env.reset", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "prev_obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "self", ".", "this_team", "=", "self", ".", "metadata", "[", "'team_index'", "]", "==", "self", ".", "team_idx", "\n", "\n", "return", "deepcopy", "(", "self", ".", "prev_obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.hide_and_seek.MaskUnseenAction.step": [[182, 189], ["numpy.any", "hide_and_seek.MaskUnseenAction.env.step", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "is_caught", "=", "np", ".", "any", "(", "self", ".", "prev_obs", "[", "'mask_aa_obs'", "]", "[", "self", ".", "n_hiders", ":", ",", ":", "self", ".", "n_hiders", "]", ")", "\n", "if", "is_caught", ":", "\n", "            ", "action", "[", "self", ".", "action_key", "]", "[", "self", ".", "this_team", "]", "=", "0", "\n", "\n", "", "self", ".", "prev_obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "return", "deepcopy", "(", "self", ".", "prev_obs", ")", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.hide_and_seek.quadrant_placement": [[191, 200], ["len", "numpy.array", "random_state.randint", "random_state.randint"], "function", ["None"], ["", "", "def", "quadrant_placement", "(", "grid", ",", "obj_size", ",", "metadata", ",", "random_state", ")", ":", "\n", "    ", "'''\n        Places object within the bottom right quadrant of the playing field\n    '''", "\n", "grid_size", "=", "len", "(", "grid", ")", "\n", "qsize", "=", "metadata", "[", "'quadrant_size'", "]", "\n", "pos", "=", "np", ".", "array", "(", "[", "random_state", ".", "randint", "(", "grid_size", "-", "qsize", ",", "grid_size", "-", "obj_size", "[", "0", "]", "-", "1", ")", ",", "\n", "random_state", ".", "randint", "(", "1", ",", "qsize", "-", "obj_size", "[", "1", "]", "-", "1", ")", "]", ")", "\n", "return", "pos", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.hide_and_seek.outside_quadrant_placement": [[202, 217], ["len", "numpy.array", "numpy.array", "numpy.array", "random_state.randint", "random_state.randint", "random_state.randint", "random_state.randint", "random_state.randint", "random_state.randint", "random_state.randint"], "function", ["None"], ["", "def", "outside_quadrant_placement", "(", "grid", ",", "obj_size", ",", "metadata", ",", "random_state", ")", ":", "\n", "    ", "'''\n        Places object outside of the bottom right quadrant of the playing field\n    '''", "\n", "grid_size", "=", "len", "(", "grid", ")", "\n", "qsize", "=", "metadata", "[", "'quadrant_size'", "]", "\n", "poses", "=", "[", "\n", "np", ".", "array", "(", "[", "random_state", ".", "randint", "(", "1", ",", "grid_size", "-", "qsize", "-", "obj_size", "[", "0", "]", "-", "1", ")", ",", "\n", "random_state", ".", "randint", "(", "1", ",", "qsize", "-", "obj_size", "[", "1", "]", "-", "1", ")", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "random_state", ".", "randint", "(", "1", ",", "grid_size", "-", "qsize", "-", "obj_size", "[", "0", "]", "-", "1", ")", ",", "\n", "random_state", ".", "randint", "(", "qsize", ",", "grid_size", "-", "obj_size", "[", "1", "]", "-", "1", ")", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "random_state", ".", "randint", "(", "grid_size", "-", "qsize", ",", "grid_size", "-", "obj_size", "[", "0", "]", "-", "1", ")", ",", "\n", "random_state", ".", "randint", "(", "qsize", ",", "grid_size", "-", "obj_size", "[", "1", "]", "-", "1", ")", "]", ")", ",", "\n", "]", "\n", "return", "poses", "[", "random_state", ".", "randint", "(", "0", ",", "3", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.hide_and_seek.make_env": [[219, 436], ["mae_envs.envs.base.Base", "mae_envs.wrappers.manipulation.LockObjWrapper.add_module", "mae_envs.wrappers.manipulation.LockObjWrapper.add_module", "mae_envs.wrappers.manipulation.LockObjWrapper.add_module", "mae_envs.wrappers.manipulation.LockObjWrapper.reset", "mae_envs.wrappers.multi_agent.SplitMultiAgentActions", "mae_envs.wrappers.team.TeamMembership", "mae_envs.wrappers.line_of_sight.AgentAgentObsMask2D", "numpy.array", "mae_envs.wrappers.util.AddConstantObservationsWrapper", "hide_and_seek.HideAndSeekRewardWrapper", "mae_envs.wrappers.prep_phase.PreparationPhase", "mae_envs.wrappers.util.DiscretizeActionWrapper", "mae_envs.wrappers.multi_agent.SplitObservations", "mae_envs.wrappers.util.SpoofEntityWrapper", "mae_envs.wrappers.manipulation.LockAllWrapper", "mae_envs.wrappers.prep_phase.NoActionsInPrepPhase", "mae_envs.wrappers.util.DiscardMujocoExceptionEpisodes", "mae_envs.wrappers.util.ConcatenateObsWrapper", "mae_envs.wrappers.multi_agent.SelectKeysWrapper", "mae_envs.wrappers.manipulation.LockObjWrapper.add_module", "mae_envs.modules.agents.Agents", "numpy.max", "mae_envs.wrappers.manipulation.LockObjWrapper.add_module", "mae_envs.wrappers.manipulation.LockObjWrapper.add_module", "mae_envs.wrappers.manipulation.LockObjWrapper.add_module", "mae_envs.wrappers.manipulation.LockObjWrapper.add_module", "mae_envs.modules.agents.AgentManipulation", "mae_envs.wrappers.manipulation.LockObjWrapper.add_module", "mae_envs.modules.world.WorldConstants", "numpy.append", "mae_envs.wrappers.limit_mvmnt.RestrictAgentsRect", "numpy.max", "mae_envs.wrappers.line_of_sight.AgentGeomObsMask2D", "keys_mask_external.append", "mae_envs.wrappers.line_of_sight.AgentSiteObsMask2D", "mae_envs.wrappers.food.FoodHealthWrapper", "mae_envs.wrappers.util.MaskActionWrapper", "numpy.arange", "mae_envs.wrappers.food.AlwaysEatWrapper", "keys_mask_external.append", "mae_envs.wrappers.manipulation.LockObjWrapper", "mae_envs.wrappers.line_of_sight.AgentGeomObsMask2D", "keys_mask_external.append", "mae_envs.wrappers.manipulation.GrabObjWrapper", "mae_envs.wrappers.lidar.Lidar", "hide_and_seek.TrackStatWrapper", "numpy.max", "mae_envs.wrappers.util.SpoofEntityWrapper", "mae_envs.wrappers.util.SpoofEntityWrapper", "mae_envs.wrappers.util.MaskActionWrapper", "mae_envs.wrappers.manipulation.GrabClosestWrapper", "numpy.arange", "mae_envs.modules.walls.RandomWalls", "numpy.ceil().astype", "mae_envs.modules.util.close_to_other_object_placement", "numpy.ceil().astype", "mae_envs.modules.util.close_to_other_object_placement", "mae_envs.wrappers.manipulation.LockObjWrapper.add_module", "ValueError", "mae_envs.modules.objects.Boxes", "mae_envs.modules.objects.Ramps", "mae_envs.modules.objects.LidarSites", "numpy.ceil().astype", "numpy.repeat", "mae_envs.modules.food.Food", "mae_envs.modules.world.FloorAttributes", "numpy.zeros", "numpy.ones", "mae_envs.wrappers.prep_phase.MaskPrepPhaseAction", "hide_and_seek.MaskUnseenAction", "numpy.max", "mae_envs.wrappers.manipulation.LockObjWrapper", "numpy.max", "mae_envs.modules.walls.WallScenarios", "mae_envs.modules.util.uniform_placement_middle", "numpy.arange", "mae_envs.modules.util.close_to_other_object_placement", "numpy.arange", "numpy.max", "numpy.ceil", "numpy.ceil", "numpy.ceil", "numpy.arange", "numpy.max", "range", "range", "range", "numpy.max", "range", "numpy.max", "numpy.array"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.close_to_other_object_placement", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.close_to_other_object_placement", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.uniform_placement_middle", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.close_to_other_object_placement"], ["", "def", "make_env", "(", "n_substeps", "=", "15", ",", "horizon", "=", "80", ",", "deterministic_mode", "=", "False", ",", "\n", "floor_size", "=", "6.0", ",", "grid_size", "=", "30", ",", "door_size", "=", "2", ",", "\n", "n_hiders", "=", "1", ",", "n_seekers", "=", "1", ",", "max_n_agents", "=", "None", ",", "\n", "n_boxes", "=", "2", ",", "n_ramps", "=", "1", ",", "n_elongated_boxes", "=", "0", ",", "\n", "rand_num_elongated_boxes", "=", "False", ",", "n_min_boxes", "=", "None", ",", "\n", "box_size", "=", "0.5", ",", "boxid_obs", "=", "False", ",", "box_only_z_rot", "=", "True", ",", "\n", "rew_type", "=", "'joint_zero_sum'", ",", "\n", "lock_box", "=", "True", ",", "grab_box", "=", "True", ",", "lock_ramp", "=", "True", ",", "\n", "lock_type", "=", "'any_lock_specific'", ",", "\n", "lock_grab_radius", "=", "0.25", ",", "lock_out_of_vision", "=", "True", ",", "grab_exclusive", "=", "False", ",", "\n", "grab_out_of_vision", "=", "False", ",", "grab_selective", "=", "False", ",", "\n", "box_floor_friction", "=", "0.2", ",", "other_friction", "=", "0.01", ",", "gravity", "=", "[", "0", ",", "0", ",", "-", "50", "]", ",", "\n", "action_lims", "=", "(", "-", "0.9", ",", "0.9", ")", ",", "polar_obs", "=", "True", ",", "\n", "scenario", "=", "'quadrant'", ",", "quadrant_game_hider_uniform_placement", "=", "False", ",", "\n", "p_door_dropout", "=", "0.0", ",", "\n", "n_rooms", "=", "4", ",", "random_room_number", "=", "True", ",", "prob_outside_walls", "=", "1.0", ",", "\n", "n_lidar_per_agent", "=", "0", ",", "visualize_lidar", "=", "False", ",", "compress_lidar_scale", "=", "None", ",", "\n", "hiders_together_radius", "=", "None", ",", "seekers_together_radius", "=", "None", ",", "\n", "prep_fraction", "=", "0.4", ",", "prep_obs", "=", "False", ",", "\n", "team_size_obs", "=", "False", ",", "\n", "restrict_rect", "=", "None", ",", "penalize_objects_out", "=", "False", ",", "\n", "n_food", "=", "0", ",", "food_radius", "=", "None", ",", "food_respawn_time", "=", "None", ",", "max_food_health", "=", "1", ",", "\n", "food_together_radius", "=", "None", ",", "food_rew_type", "=", "'selfish'", ",", "eat_when_caught", "=", "False", ",", "\n", "food_reward_scale", "=", "1.0", ",", "food_normal_centered", "=", "False", ",", "food_box_centered", "=", "False", ",", "\n", "n_food_cluster", "=", "1", ")", ":", "\n", "\n", "    ", "grab_radius_multiplier", "=", "lock_grab_radius", "/", "box_size", "\n", "lock_radius_multiplier", "=", "lock_grab_radius", "/", "box_size", "\n", "\n", "env", "=", "Base", "(", "n_agents", "=", "n_hiders", "+", "n_seekers", ",", "n_substeps", "=", "n_substeps", ",", "horizon", "=", "horizon", ",", "\n", "floor_size", "=", "floor_size", ",", "grid_size", "=", "grid_size", ",", "\n", "action_lims", "=", "action_lims", ",", "\n", "deterministic_mode", "=", "deterministic_mode", ")", "\n", "\n", "if", "scenario", "==", "'randomwalls'", ":", "\n", "        ", "env", ".", "add_module", "(", "RandomWalls", "(", "\n", "grid_size", "=", "grid_size", ",", "num_rooms", "=", "n_rooms", ",", "\n", "random_room_number", "=", "random_room_number", ",", "min_room_size", "=", "6", ",", "\n", "door_size", "=", "door_size", ",", "\n", "prob_outside_walls", "=", "prob_outside_walls", ",", "gen_door_obs", "=", "False", ")", ")", "\n", "box_placement_fn", "=", "uniform_placement", "\n", "ramp_placement_fn", "=", "uniform_placement", "\n", "cell_size", "=", "floor_size", "/", "grid_size", "\n", "\n", "first_hider_placement", "=", "uniform_placement", "\n", "if", "hiders_together_radius", "is", "not", "None", ":", "\n", "            ", "htr_in_cells", "=", "np", ".", "ceil", "(", "hiders_together_radius", "/", "cell_size", ")", ".", "astype", "(", "int", ")", "\n", "\n", "env", ".", "metadata", "[", "'hiders_together_radius'", "]", "=", "htr_in_cells", "\n", "\n", "close_to_first_hider_placement", "=", "close_to_other_object_placement", "(", "\n", "\"agent\"", ",", "0", ",", "\"hiders_together_radius\"", ")", "\n", "\n", "agent_placement_fn", "=", "[", "first_hider_placement", "]", "+", "[", "close_to_first_hider_placement", "]", "*", "(", "n_hiders", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "agent_placement_fn", "=", "[", "first_hider_placement", "]", "*", "n_hiders", "\n", "\n", "", "first_seeker_placement", "=", "uniform_placement", "\n", "\n", "if", "seekers_together_radius", "is", "not", "None", ":", "\n", "            ", "str_in_cells", "=", "np", ".", "ceil", "(", "seekers_together_radius", "/", "cell_size", ")", ".", "astype", "(", "int", ")", "\n", "\n", "env", ".", "metadata", "[", "'seekers_together_radius'", "]", "=", "str_in_cells", "\n", "\n", "close_to_first_seeker_placement", "=", "close_to_other_object_placement", "(", "\n", "\"agent\"", ",", "n_hiders", ",", "\"seekers_together_radius\"", ")", "\n", "\n", "agent_placement_fn", "+=", "[", "first_seeker_placement", "]", "+", "[", "close_to_first_seeker_placement", "]", "*", "(", "n_seekers", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "agent_placement_fn", "+=", "[", "first_seeker_placement", "]", "*", "(", "n_seekers", ")", "\n", "\n", "", "", "elif", "scenario", "==", "'quadrant'", ":", "\n", "        ", "env", ".", "add_module", "(", "WallScenarios", "(", "grid_size", "=", "grid_size", ",", "door_size", "=", "door_size", ",", "\n", "scenario", "=", "scenario", ",", "friction", "=", "other_friction", ",", "\n", "p_door_dropout", "=", "p_door_dropout", ")", ")", "\n", "box_placement_fn", "=", "quadrant_placement", "\n", "ramp_placement_fn", "=", "uniform_placement", "\n", "hider_placement", "=", "uniform_placement", "if", "quadrant_game_hider_uniform_placement", "else", "quadrant_placement", "\n", "agent_placement_fn", "=", "[", "hider_placement", "]", "*", "n_hiders", "+", "[", "outside_quadrant_placement", "]", "*", "n_seekers", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Scenario {scenario} not supported.\"", ")", "\n", "\n", "", "env", ".", "add_module", "(", "Agents", "(", "n_hiders", "+", "n_seekers", ",", "\n", "placement_fn", "=", "agent_placement_fn", ",", "\n", "color", "=", "[", "np", ".", "array", "(", "(", "66.", ",", "235.", ",", "244.", ",", "255.", ")", ")", "/", "255", "]", "*", "n_hiders", "+", "[", "(", "1.", ",", "0.", ",", "0.", ",", "1.", ")", "]", "*", "n_seekers", ",", "\n", "friction", "=", "other_friction", ",", "\n", "polar_obs", "=", "polar_obs", ")", ")", "\n", "if", "np", ".", "max", "(", "n_boxes", ")", ">", "0", ":", "\n", "        ", "env", ".", "add_module", "(", "Boxes", "(", "n_boxes", "=", "n_boxes", ",", "placement_fn", "=", "box_placement_fn", ",", "\n", "friction", "=", "box_floor_friction", ",", "polar_obs", "=", "polar_obs", ",", "\n", "n_elongated_boxes", "=", "n_elongated_boxes", ",", "\n", "boxid_obs", "=", "boxid_obs", ",", "box_only_z_rot", "=", "box_only_z_rot", ")", ")", "\n", "", "if", "n_ramps", ">", "0", ":", "\n", "        ", "env", ".", "add_module", "(", "Ramps", "(", "n_ramps", "=", "n_ramps", ",", "placement_fn", "=", "ramp_placement_fn", ",", "friction", "=", "other_friction", ",", "polar_obs", "=", "polar_obs", ",", "\n", "pad_ramp_size", "=", "(", "np", ".", "max", "(", "n_elongated_boxes", ")", ">", "0", ")", ")", ")", "\n", "", "if", "n_lidar_per_agent", ">", "0", "and", "visualize_lidar", ":", "\n", "        ", "env", ".", "add_module", "(", "LidarSites", "(", "n_agents", "=", "n_hiders", "+", "n_seekers", ",", "n_lidar_per_agent", "=", "n_lidar_per_agent", ")", ")", "\n", "", "if", "n_food", ">", "0", ":", "\n", "        ", "if", "scenario", "==", "'quadrant'", ":", "\n", "            ", "first_food_placement", "=", "quadrant_placement", "\n", "", "elif", "food_box_centered", ":", "\n", "            ", "first_food_placement", "=", "uniform_placement_middle", "(", "0.25", ")", "\n", "", "else", ":", "\n", "            ", "first_food_placement", "=", "uniform_placement", "\n", "", "if", "food_together_radius", "is", "not", "None", ":", "\n", "            ", "cell_size", "=", "floor_size", "/", "grid_size", "\n", "ftr_in_cells", "=", "np", ".", "ceil", "(", "food_together_radius", "/", "cell_size", ")", ".", "astype", "(", "int", ")", "\n", "\n", "env", ".", "metadata", "[", "'food_together_radius'", "]", "=", "ftr_in_cells", "\n", "\n", "assert", "n_food", "%", "n_food_cluster", "==", "0", "\n", "cluster_assignments", "=", "np", ".", "repeat", "(", "np", ".", "arange", "(", "0", ",", "n_food", ",", "n_food", "//", "n_food_cluster", ")", ",", "n_food", "//", "n_food_cluster", ")", "\n", "food_placement", "=", "[", "close_to_other_object_placement", "(", "\n", "\"food\"", ",", "i", ",", "\"food_together_radius\"", ")", "for", "i", "in", "cluster_assignments", "]", "\n", "food_placement", "[", ":", ":", "n_food", "//", "n_food_cluster", "]", "=", "[", "first_food_placement", "]", "*", "n_food_cluster", "\n", "", "else", ":", "\n", "            ", "food_placement", "=", "first_food_placement", "\n", "", "env", ".", "add_module", "(", "Food", "(", "n_food", ",", "placement_fn", "=", "food_placement", ")", ")", "\n", "\n", "", "env", ".", "add_module", "(", "AgentManipulation", "(", ")", ")", "\n", "if", "box_floor_friction", "is", "not", "None", ":", "\n", "        ", "env", ".", "add_module", "(", "FloorAttributes", "(", "friction", "=", "box_floor_friction", ")", ")", "\n", "", "env", ".", "add_module", "(", "WorldConstants", "(", "gravity", "=", "gravity", ")", ")", "\n", "env", ".", "reset", "(", ")", "\n", "keys_self", "=", "[", "'agent_qpos_qvel'", ",", "'hider'", ",", "'prep_obs'", "]", "\n", "keys_mask_self", "=", "[", "'mask_aa_obs'", "]", "\n", "keys_external", "=", "[", "'agent_qpos_qvel'", "]", "\n", "keys_copy", "=", "[", "'you_lock'", ",", "'team_lock'", ",", "'ramp_you_lock'", ",", "'ramp_team_lock'", "]", "\n", "keys_mask_external", "=", "[", "]", "\n", "env", "=", "SplitMultiAgentActions", "(", "env", ")", "\n", "if", "team_size_obs", ":", "\n", "        ", "keys_self", "+=", "[", "'team_size'", "]", "\n", "", "env", "=", "TeamMembership", "(", "env", ",", "np", ".", "append", "(", "np", ".", "zeros", "(", "(", "n_hiders", ",", ")", ")", ",", "np", ".", "ones", "(", "(", "n_seekers", ",", ")", ")", ")", ")", "\n", "env", "=", "AgentAgentObsMask2D", "(", "env", ")", "\n", "hider_obs", "=", "np", ".", "array", "(", "[", "[", "1", "]", "]", "*", "n_hiders", "+", "[", "[", "0", "]", "]", "*", "n_seekers", ")", "\n", "env", "=", "AddConstantObservationsWrapper", "(", "env", ",", "new_obs", "=", "{", "'hider'", ":", "hider_obs", "}", ")", "\n", "env", "=", "HideAndSeekRewardWrapper", "(", "env", ",", "n_hiders", "=", "n_hiders", ",", "n_seekers", "=", "n_seekers", ",", "\n", "rew_type", "=", "rew_type", ")", "\n", "if", "restrict_rect", "is", "not", "None", ":", "\n", "        ", "env", "=", "RestrictAgentsRect", "(", "env", ",", "restrict_rect", "=", "restrict_rect", ",", "penalize_objects_out", "=", "penalize_objects_out", ")", "\n", "", "env", "=", "PreparationPhase", "(", "env", ",", "prep_fraction", "=", "prep_fraction", ")", "\n", "env", "=", "DiscretizeActionWrapper", "(", "env", ",", "'action_movement'", ")", "\n", "if", "np", ".", "max", "(", "n_boxes", ")", ">", "0", ":", "\n", "        ", "env", "=", "AgentGeomObsMask2D", "(", "env", ",", "pos_obs_key", "=", "'box_pos'", ",", "mask_obs_key", "=", "'mask_ab_obs'", ",", "\n", "geom_idxs_obs_key", "=", "'box_geom_idxs'", ")", "\n", "keys_external", "+=", "[", "'mask_ab_obs'", ",", "'box_obs'", "]", "\n", "keys_mask_external", ".", "append", "(", "'mask_ab_obs'", ")", "\n", "", "if", "n_food", ":", "\n", "        ", "env", "=", "AgentSiteObsMask2D", "(", "env", ",", "pos_obs_key", "=", "'food_pos'", ",", "mask_obs_key", "=", "'mask_af_obs'", ")", "\n", "env", "=", "FoodHealthWrapper", "(", "env", ",", "respawn_time", "=", "(", "np", ".", "inf", "if", "food_respawn_time", "is", "None", "else", "food_respawn_time", ")", ",", "\n", "eat_thresh", "=", "(", "np", ".", "inf", "if", "food_radius", "is", "None", "else", "food_radius", ")", ",", "\n", "max_food_health", "=", "max_food_health", ",", "food_rew_type", "=", "food_rew_type", ",", "\n", "reward_scale", "=", "food_reward_scale", ")", "\n", "env", "=", "MaskActionWrapper", "(", "env", ",", "'action_eat_food'", ",", "[", "'mask_af_obs'", "]", ")", "# Can only eat if in vision", "\n", "if", "prep_obs", ":", "\n", "            ", "env", "=", "MaskPrepPhaseAction", "(", "env", ",", "'action_eat_food'", ")", "\n", "", "if", "not", "eat_when_caught", ":", "\n", "            ", "env", "=", "MaskUnseenAction", "(", "env", ",", "0", ",", "'action_eat_food'", ")", "\n", "", "eat_agents", "=", "np", ".", "arange", "(", "n_hiders", ")", "\n", "env", "=", "AlwaysEatWrapper", "(", "env", ",", "agent_idx_allowed", "=", "eat_agents", ")", "\n", "keys_external", "+=", "[", "'mask_af_obs'", ",", "'food_obs'", "]", "\n", "keys_mask_external", ".", "append", "(", "'mask_af_obs'", ")", "\n", "", "if", "lock_box", "and", "np", ".", "max", "(", "n_boxes", ")", ">", "0", ":", "\n", "        ", "env", "=", "LockObjWrapper", "(", "env", ",", "body_names", "=", "[", "f'moveable_box{i}'", "for", "i", "in", "range", "(", "np", ".", "max", "(", "n_boxes", ")", ")", "]", ",", "\n", "agent_idx_allowed_to_lock", "=", "np", ".", "arange", "(", "n_hiders", "+", "n_seekers", ")", ",", "\n", "lock_type", "=", "lock_type", ",", "radius_multiplier", "=", "lock_radius_multiplier", ",", "\n", "obj_in_game_metadata_keys", "=", "[", "\"curr_n_boxes\"", "]", ",", "\n", "agent_allowed_to_lock_keys", "=", "None", "if", "lock_out_of_vision", "else", "[", "\"mask_ab_obs\"", "]", ")", "\n", "", "if", "n_ramps", ">", "0", ":", "\n", "        ", "env", "=", "AgentGeomObsMask2D", "(", "env", ",", "pos_obs_key", "=", "'ramp_pos'", ",", "mask_obs_key", "=", "'mask_ar_obs'", ",", "\n", "geom_idxs_obs_key", "=", "'ramp_geom_idxs'", ")", "\n", "if", "lock_ramp", ":", "\n", "            ", "env", "=", "LockObjWrapper", "(", "env", ",", "body_names", "=", "[", "f'ramp{i}:ramp'", "for", "i", "in", "range", "(", "n_ramps", ")", "]", ",", "\n", "agent_idx_allowed_to_lock", "=", "np", ".", "arange", "(", "n_hiders", "+", "n_seekers", ")", ",", "\n", "lock_type", "=", "lock_type", ",", "ac_obs_prefix", "=", "'ramp_'", ",", "\n", "radius_multiplier", "=", "lock_radius_multiplier", ",", "\n", "obj_in_game_metadata_keys", "=", "[", "'curr_n_ramps'", "]", ",", "\n", "agent_allowed_to_lock_keys", "=", "None", "if", "lock_out_of_vision", "else", "[", "\"mask_ar_obs\"", "]", ")", "\n", "", "keys_external", "+=", "[", "'ramp_obs'", "]", "\n", "keys_mask_external", ".", "append", "(", "'mask_ar_obs'", ")", "\n", "", "if", "grab_box", "and", "(", "np", ".", "max", "(", "n_boxes", ")", ">", "0", "or", "n_ramps", ">", "0", ")", ":", "\n", "        ", "env", "=", "GrabObjWrapper", "(", "env", ",", "[", "f'moveable_box{i}'", "for", "i", "in", "range", "(", "np", ".", "max", "(", "n_boxes", ")", ")", "]", "+", "(", "[", "f\"ramp{i}:ramp\"", "for", "i", "in", "range", "(", "n_ramps", ")", "]", ")", ",", "\n", "radius_multiplier", "=", "grab_radius_multiplier", ",", "\n", "grab_exclusive", "=", "grab_exclusive", ",", "\n", "obj_in_game_metadata_keys", "=", "[", "'curr_n_boxes'", ",", "'curr_n_ramps'", "]", ")", "\n", "\n", "", "if", "n_lidar_per_agent", ">", "0", ":", "\n", "        ", "env", "=", "Lidar", "(", "env", ",", "n_lidar_per_agent", "=", "n_lidar_per_agent", ",", "visualize_lidar", "=", "visualize_lidar", ",", "\n", "compress_lidar_scale", "=", "compress_lidar_scale", ")", "\n", "keys_copy", "+=", "[", "'lidar'", "]", "\n", "keys_external", "+=", "[", "'lidar'", "]", "\n", "\n", "", "if", "prep_obs", ":", "\n", "        ", "env", "=", "TrackStatWrapper", "(", "env", ",", "np", ".", "max", "(", "n_boxes", ")", ",", "n_ramps", ",", "n_food", ")", "\n", "", "env", "=", "SplitObservations", "(", "env", ",", "keys_self", "+", "keys_mask_self", ",", "keys_copy", "=", "keys_copy", ",", "keys_self_matrices", "=", "keys_mask_self", ")", "\n", "env", "=", "SpoofEntityWrapper", "(", "env", ",", "np", ".", "max", "(", "n_boxes", ")", ",", "[", "'box_obs'", ",", "'you_lock'", ",", "'team_lock'", ",", "'obj_lock'", "]", ",", "[", "'mask_ab_obs'", "]", ")", "\n", "if", "n_food", ":", "\n", "        ", "env", "=", "SpoofEntityWrapper", "(", "env", ",", "n_food", ",", "[", "'food_obs'", "]", ",", "[", "'mask_af_obs'", "]", ")", "\n", "", "keys_mask_external", "+=", "[", "'mask_ab_obs_spoof'", ",", "'mask_af_obs_spoof'", "]", "\n", "if", "max_n_agents", "is", "not", "None", ":", "\n", "        ", "env", "=", "SpoofEntityWrapper", "(", "env", ",", "max_n_agents", ",", "[", "'agent_qpos_qvel'", ",", "'hider'", ",", "'prep_obs'", "]", ",", "[", "'mask_aa_obs'", "]", ")", "\n", "", "env", "=", "LockAllWrapper", "(", "env", ",", "remove_object_specific_lock", "=", "True", ")", "\n", "if", "not", "grab_out_of_vision", "and", "grab_box", ":", "\n", "        ", "env", "=", "MaskActionWrapper", "(", "env", ",", "'action_pull'", ",", "\n", "[", "'mask_ab_obs'", "]", "+", "(", "[", "'mask_ar_obs'", "]", "if", "n_ramps", ">", "0", "else", "[", "]", ")", ")", "\n", "", "if", "not", "grab_selective", "and", "grab_box", ":", "\n", "        ", "env", "=", "GrabClosestWrapper", "(", "env", ")", "\n", "", "env", "=", "NoActionsInPrepPhase", "(", "env", ",", "np", ".", "arange", "(", "n_hiders", ",", "n_hiders", "+", "n_seekers", ")", ")", "\n", "env", "=", "DiscardMujocoExceptionEpisodes", "(", "env", ")", "\n", "env", "=", "ConcatenateObsWrapper", "(", "env", ",", "{", "'agent_qpos_qvel'", ":", "[", "'agent_qpos_qvel'", ",", "'hider'", ",", "'prep_obs'", "]", ",", "\n", "'box_obs'", ":", "[", "'box_obs'", ",", "'you_lock'", ",", "'team_lock'", ",", "'obj_lock'", "]", ",", "\n", "'ramp_obs'", ":", "[", "'ramp_obs'", "]", "+", "(", "[", "'ramp_you_lock'", ",", "'ramp_team_lock'", ",", "'ramp_obj_lock'", "]", "if", "lock_ramp", "else", "[", "]", ")", "}", ")", "\n", "env", "=", "SelectKeysWrapper", "(", "env", ",", "keys_self", "=", "keys_self", ",", "\n", "keys_other", "=", "keys_external", "+", "keys_mask_self", "+", "keys_mask_external", ")", "\n", "return", "env", "\n", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.__init__": [[27, 49], ["mujoco_worldgen.Env.__init__", "numpy.zeros", "isinstance", "tuple"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "horizon", "=", "250", ",", "n_substeps", "=", "5", ",", "n_agents", "=", "2", ",", "\n", "floor_size", "=", "6.", ",", "grid_size", "=", "30", ",", "\n", "action_lims", "=", "(", "-", "1.0", ",", "1.0", ")", ",", "deterministic_mode", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "get_sim", "=", "self", ".", "_get_sim", ",", "\n", "get_obs", "=", "self", ".", "_get_obs", ",", "\n", "action_space", "=", "tuple", "(", "action_lims", ")", ",", "\n", "horizon", "=", "horizon", ",", "\n", "deterministic_mode", "=", "deterministic_mode", ")", "\n", "self", ".", "n_agents", "=", "n_agents", "\n", "self", ".", "metadata", "=", "{", "}", "\n", "self", ".", "metadata", "[", "'n_actors'", "]", "=", "n_agents", "\n", "self", ".", "horizon", "=", "horizon", "\n", "self", ".", "n_substeps", "=", "n_substeps", "\n", "if", "not", "isinstance", "(", "floor_size", ",", "(", "tuple", ",", "list", ",", "np", ".", "ndarray", ")", ")", ":", "\n", "            ", "self", ".", "floor_size_dist", "=", "[", "floor_size", ",", "floor_size", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "floor_size_dist", "=", "floor_size", "\n", "", "self", ".", "grid_size", "=", "grid_size", "\n", "self", ".", "kwargs", "=", "kwargs", "\n", "self", ".", "placement_grid", "=", "np", ".", "zeros", "(", "(", "grid_size", ",", "grid_size", ")", ")", "\n", "self", ".", "modules", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module": [[50, 52], ["base.Base.modules.append"], "methods", ["None"], ["", "def", "add_module", "(", "self", ",", "module", ")", ":", "\n", "        ", "self", ".", "modules", ".", "append", "(", "module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base._get_obs": [[53, 62], ["obs.update", "module.observation_step"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.food.Food.observation_step"], ["", "def", "_get_obs", "(", "self", ",", "sim", ")", ":", "\n", "        ", "'''\n            Loops through modules, calls their observation_step functions, and\n                adds the result to the observation dictionary.\n        '''", "\n", "obs", "=", "{", "}", "\n", "for", "module", "in", "self", ".", "modules", ":", "\n", "            ", "obs", ".", "update", "(", "module", ".", "observation_step", "(", "self", ",", "self", ".", "sim", ")", ")", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base._get_sim": [[63, 94], ["numpy.random.uniform", "mujoco_worldgen.WorldParams", "mujoco_worldgen.WorldBuilder.get_sim", "mujoco_worldgen.WorldBuilder", "mujoco_worldgen.Floor", "mujoco_worldgen.WorldBuilder.append", "numpy.zeros", "numpy.all", "module.modify_sim_step", "logging.warning", "module.build_world_step"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.food.Food.modify_sim_step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.food.Food.build_world_step"], ["", "def", "_get_sim", "(", "self", ",", "seed", ")", ":", "\n", "        ", "'''\n            Calls build_world_step and then modify_sim_step for each module. If\n            a build_world_step failed, then restarts.\n        '''", "\n", "self", ".", "floor_size", "=", "np", ".", "random", ".", "uniform", "(", "self", ".", "floor_size_dist", "[", "0", "]", ",", "self", ".", "floor_size_dist", "[", "1", "]", ")", "\n", "self", ".", "metadata", "[", "'floor_size'", "]", "=", "self", ".", "floor_size", "\n", "world_params", "=", "WorldParams", "(", "size", "=", "(", "self", ".", "floor_size", ",", "self", ".", "floor_size", ",", "2.5", ")", ",", "\n", "num_substeps", "=", "self", ".", "n_substeps", ")", "\n", "successful_placement", "=", "False", "\n", "failures", "=", "0", "\n", "while", "not", "successful_placement", ":", "\n", "            ", "if", "(", "failures", "+", "1", ")", "%", "10", "==", "0", ":", "\n", "                ", "logging", ".", "warning", "(", "f\"Failed {failures} times in creating environment\"", ")", "\n", "", "builder", "=", "WorldBuilder", "(", "world_params", ",", "seed", ")", "\n", "floor", "=", "Floor", "(", ")", "\n", "\n", "builder", ".", "append", "(", "floor", ")", "\n", "\n", "self", ".", "placement_grid", "=", "np", ".", "zeros", "(", "(", "self", ".", "grid_size", ",", "self", ".", "grid_size", ")", ")", "\n", "\n", "successful_placement", "=", "np", ".", "all", "(", "[", "module", ".", "build_world_step", "(", "self", ",", "floor", ",", "self", ".", "floor_size", ")", "\n", "for", "module", "in", "self", ".", "modules", "]", ")", "\n", "failures", "+=", "1", "\n", "\n", "", "sim", "=", "builder", ".", "get_sim", "(", ")", "\n", "\n", "for", "module", "in", "self", ".", "modules", ":", "\n", "            ", "module", ".", "modify_sim_step", "(", "self", ",", "sim", ")", "\n", "\n", "", "return", "sim", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.make_env": [[96, 123], ["base.Base", "mae_envs.wrappers.util.DiscardMujocoExceptionEpisodes.add_module", "mae_envs.wrappers.util.DiscardMujocoExceptionEpisodes.add_module", "mae_envs.wrappers.util.DiscardMujocoExceptionEpisodes.reset", "mae_envs.wrappers.multi_agent.SplitMultiAgentActions", "mae_envs.wrappers.util.DiscretizeActionWrapper", "mae_envs.wrappers.line_of_sight.AgentAgentObsMask2D", "mae_envs.wrappers.multi_agent.SplitObservations", "mae_envs.wrappers.multi_agent.SelectKeysWrapper", "mae_envs.wrappers.util.DiscardMujocoExceptionEpisodes", "mae_envs.modules.walls.RandomWalls", "mae_envs.wrappers.util.DiscardMujocoExceptionEpisodes.add_module", "mae_envs.wrappers.util.DiscardMujocoExceptionEpisodes.add_module", "mae_envs.modules.agents.Agents", "mae_envs.modules.objects.Boxes", "mae_envs.modules.objects.Ramps"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module"], ["", "", "def", "make_env", "(", "n_substeps", "=", "5", ",", "horizon", "=", "250", ",", "deterministic_mode", "=", "False", ",", "n_agents", "=", "2", ",", "\n", "n_boxes", "=", "2", ",", "n_ramps", "=", "1", ")", ":", "\n", "    ", "'''\n        This make_env function is not used anywhere; it exists to provide a simple, bare-bones\n        example of how to construct a multi-agent environment using the modules framework.\n    '''", "\n", "env", "=", "Base", "(", "n_agents", "=", "n_agents", ",", "n_substeps", "=", "n_substeps", ",", "horizon", "=", "horizon", ",", "\n", "deterministic_mode", "=", "deterministic_mode", ")", "\n", "env", ".", "add_module", "(", "RandomWalls", "(", "grid_size", "=", "30", ",", "num_rooms", "=", "4", ",", "min_room_size", "=", "6", ",", "door_size", "=", "2", ")", ")", "\n", "if", "n_boxes", ">", "0", ":", "\n", "        ", "env", ".", "add_module", "(", "Boxes", "(", "n_boxes", "=", "n_boxes", ")", ")", "\n", "", "if", "n_ramps", ">", "0", ":", "\n", "        ", "env", ".", "add_module", "(", "Ramps", "(", "n_ramps", "=", "n_ramps", ")", ")", "\n", "", "env", ".", "add_module", "(", "Agents", "(", "n_agents", ")", ")", "\n", "env", ".", "reset", "(", ")", "\n", "keys_self", "=", "[", "'agent_qpos_qvel'", "]", "\n", "keys_mask_self", "=", "[", "'mask_aa_obs'", "]", "\n", "keys_external", "=", "[", "'agent_qpos_qvel'", "]", "\n", "keys_mask_external", "=", "[", "]", "\n", "env", "=", "SplitMultiAgentActions", "(", "env", ")", "\n", "env", "=", "DiscretizeActionWrapper", "(", "env", ",", "'action_movement'", ")", "\n", "env", "=", "AgentAgentObsMask2D", "(", "env", ")", "\n", "env", "=", "SplitObservations", "(", "env", ",", "keys_self", "+", "keys_mask_self", ")", "\n", "env", "=", "SelectKeysWrapper", "(", "env", ",", "keys_self", "=", "keys_self", ",", "\n", "keys_other", "=", "keys_external", "+", "keys_mask_self", "+", "keys_mask_external", ")", "\n", "env", "=", "DiscardMujocoExceptionEpisodes", "(", "env", ")", "\n", "return", "env", "\n", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.blueprint_construction.ConstructionDistancesWrapper.__init__": [[32, 34], ["gym.ObservationWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.blueprint_construction.ConstructionDistancesWrapper.observation": [[35, 51], ["numpy.linalg.norm", "numpy.linalg.norm", "numpy.linalg.norm", "obs.update"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "box_xpos", "=", "obs", "[", "'box_xpos'", "]", "\n", "boxcorner_pos", "=", "obs", "[", "'box_corner_pos'", "]", "\n", "site_pos", "=", "obs", "[", "'construction_site_pos'", "]", "\n", "sitecorner_pos", "=", "obs", "[", "'construction_site_corner_pos'", "]", "\n", "\n", "box_box_dist", "=", "np", ".", "linalg", ".", "norm", "(", "box_xpos", "[", "...", ",", "None", "]", "-", "box_xpos", ".", "T", "[", "None", ",", "...", "]", ",", "axis", "=", "1", ")", "\n", "box_site_dist", "=", "np", ".", "linalg", ".", "norm", "(", "box_xpos", "[", "...", ",", "None", "]", "-", "site_pos", ".", "T", "[", "None", ",", "...", "]", ",", "axis", "=", "1", ")", "\n", "boxcorner_sitecorner_dist", "=", "(", "\n", "np", ".", "linalg", ".", "norm", "(", "boxcorner_pos", "[", "...", ",", "None", "]", "-", "sitecorner_pos", ".", "T", "[", "None", ",", "...", "]", ",", "axis", "=", "1", ")", ")", "\n", "\n", "obs", ".", "update", "(", "{", "'box_box_dist'", ":", "box_box_dist", ",", "\n", "'box_site_dist'", ":", "box_site_dist", ",", "\n", "'boxcorner_sitecorner_dist'", ":", "boxcorner_sitecorner_dist", "}", ")", "\n", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.blueprint_construction.ConstructionDenseRewardWrapper.__init__": [[64, 70], ["gym.Wrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "use_corners", "=", "False", ",", "alpha", "=", "-", "8", ",", "reward_scale", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "assert", "alpha", "<", "0", ",", "'alpha must be negative for the SmoothMin function to work'", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "reward_scale", "=", "reward_scale", "\n", "self", ".", "use_corners", "=", "use_corners", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.blueprint_construction.ConstructionDenseRewardWrapper.step": [[71, 81], ["blueprint_construction.ConstructionDenseRewardWrapper.env.step", "numpy.exp", "numpy.sum", "numpy.sum", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "box_site_dist", "=", "(", "obs", "[", "'boxcorner_sitecorner_dist'", "]", "\n", "if", "self", ".", "use_corners", "\n", "else", "obs", "[", "'box_site_dist'", "]", ")", "\n", "scaling_factors", "=", "np", ".", "exp", "(", "self", ".", "alpha", "*", "box_site_dist", ")", "\n", "site_box_smoothmin_dists", "=", "(", "np", ".", "sum", "(", "box_site_dist", "*", "scaling_factors", ",", "axis", "=", "0", ")", "/", "\n", "np", ".", "sum", "(", "scaling_factors", ",", "axis", "=", "0", ")", ")", "\n", "rew", "-=", "np", ".", "mean", "(", "site_box_smoothmin_dists", ")", "*", "self", ".", "reward_scale", "\n", "return", "obs", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.blueprint_construction.ConstructionCompletedRewardWrapper.__init__": [[96, 102], ["gym.Wrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "use_corners", "=", "False", ",", "site_activation_radius", "=", "0.2", ",", "reward_scale", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "n_sites", "=", "self", ".", "metadata", "[", "'curr_n_sites'", "]", "\n", "self", ".", "site_activation_radius", "=", "site_activation_radius", "\n", "self", ".", "reward_scale", "=", "reward_scale", "\n", "self", ".", "use_corners", "=", "use_corners", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.blueprint_construction.ConstructionCompletedRewardWrapper.reset": [[103, 107], ["blueprint_construction.ConstructionCompletedRewardWrapper.env.reset"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "self", ".", "n_sites", "=", "self", ".", "metadata", "[", "'curr_n_sites'", "]", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.blueprint_construction.ConstructionCompletedRewardWrapper.step": [[108, 125], ["blueprint_construction.ConstructionCompletedRewardWrapper.env.step", "obs[].min", "obs[].min", "numpy.all", "numpy.all"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "site_dist_to_closest_box", "=", "obs", "[", "'box_site_dist'", "]", ".", "min", "(", "axis", "=", "0", ")", "\n", "sitecorner_dist_to_closest_boxcorner", "=", "obs", "[", "'boxcorner_sitecorner_dist'", "]", ".", "min", "(", "axis", "=", "0", ")", "\n", "activated_sites", "=", "site_dist_to_closest_box", "<", "self", ".", "site_activation_radius", "\n", "aligned_corners", "=", "sitecorner_dist_to_closest_boxcorner", "<", "self", ".", "site_activation_radius", "\n", "\n", "all_sites_activated", "=", "np", ".", "all", "(", "activated_sites", ")", "\n", "all_corners_aligned", "=", "np", ".", "all", "(", "aligned_corners", ")", "\n", "construction_completed", "=", "(", "(", "all_sites_activated", "and", "not", "self", ".", "use_corners", ")", "or", "\n", "(", "all_sites_activated", "and", "all_corners_aligned", ")", ")", "\n", "\n", "if", "construction_completed", ":", "\n", "            ", "rew", "+=", "self", ".", "n_sites", "*", "self", ".", "reward_scale", "\n", "done", "=", "True", "\n", "\n", "", "return", "obs", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.blueprint_construction.make_env": [[127, 270], ["mae_envs.envs.base.Base", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.wrappers.manipulation.GrabClosestWrapper.reset", "mae_envs.wrappers.util.AddConstantObservationsWrapper", "list", "mae_envs.wrappers.multi_agent.SplitMultiAgentActions", "mae_envs.wrappers.team.TeamMembership", "mae_envs.wrappers.line_of_sight.AgentAgentObsMask2D", "mae_envs.wrappers.util.DiscretizeActionWrapper", "blueprint_construction.ConstructionDistancesWrapper", "mae_envs.wrappers.util.NumpyArrayRewardWrapper", "mae_envs.wrappers.multi_agent.SplitObservations", "mae_envs.wrappers.util.SpoofEntityWrapper", "mae_envs.wrappers.util.SpoofEntityWrapper", "mae_envs.wrappers.manipulation.LockAllWrapper", "mae_envs.wrappers.util.DiscardMujocoExceptionEpisodes", "mae_envs.wrappers.util.ConcatenateObsWrapper", "mae_envs.wrappers.multi_agent.SelectKeysWrapper", "type", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.modules.agents.Agents", "numpy.max", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.modules.world.WorldConstants", "numpy.zeros", "numpy.max", "mae_envs.wrappers.line_of_sight.AgentGeomObsMask2D", "keys_mask_external.append", "mae_envs.wrappers.manipulation.LockObjWrapper", "mae_envs.wrappers.manipulation.GrabObjWrapper", "mae_envs.wrappers.lidar.Lidar", "mae_envs.wrappers.util.SpoofEntityWrapper", "mae_envs.wrappers.util.MaskActionWrapper", "mae_envs.wrappers.manipulation.GrabClosestWrapper", "mae_envs.modules.walls.RandomWalls", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.modules.objects.Boxes", "mae_envs.modules.construction_sites.ConstructionSites", "mae_envs.modules.objects.LidarSites", "numpy.max", "mae_envs.modules.agents.AgentManipulation", "mae_envs.modules.world.FloorAttributes", "numpy.max", "numpy.max", "mae_envs.modules.walls.WallScenarios", "numpy.arange", "mae_envs.modules.util.uniform_placement_middle", "ValueError", "range", "range", "numpy.array"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.uniform_placement_middle"], ["", "", "def", "make_env", "(", "n_substeps", "=", "15", ",", "horizon", "=", "80", ",", "deterministic_mode", "=", "False", ",", "\n", "floor_size", "=", "6.0", ",", "grid_size", "=", "30", ",", "\n", "n_agents", "=", "1", ",", "\n", "n_rooms", "=", "4", ",", "random_room_number", "=", "True", ",", "scenario", "=", "'empty'", ",", "door_size", "=", "2", ",", "\n", "n_sites", "=", "3", ",", "n_elongated_sites", "=", "0", ",", "site_placement", "=", "'uniform_away_from_walls'", ",", "\n", "reward_infos", "=", "[", "{", "'type'", ":", "'construction_dense'", "}", "]", ",", "\n", "n_boxes", "=", "2", ",", "n_elongated_boxes", "=", "0", ",", "\n", "n_min_boxes", "=", "None", ",", "box_size", "=", "0.5", ",", "box_only_z_rot", "=", "False", ",", "\n", "lock_box", "=", "True", ",", "grab_box", "=", "True", ",", "grab_selective", "=", "False", ",", "lock_grab_radius", "=", "0.25", ",", "\n", "lock_type", "=", "'any_lock_specific'", ",", "grab_exclusive", "=", "False", ",", "\n", "grab_out_of_vision", "=", "False", ",", "lock_out_of_vision", "=", "True", ",", "\n", "box_floor_friction", "=", "0.2", ",", "other_friction", "=", "0.01", ",", "gravity", "=", "[", "0", ",", "0", ",", "-", "50", "]", ",", "\n", "action_lims", "=", "(", "-", "0.9", ",", "0.9", ")", ",", "polar_obs", "=", "True", ",", "\n", "n_lidar_per_agent", "=", "0", ",", "visualize_lidar", "=", "False", ",", "compress_lidar_scale", "=", "None", ",", "\n", "boxid_obs", "=", "True", ",", "boxsize_obs", "=", "True", ",", "team_size_obs", "=", "False", ",", "additional_obs", "=", "{", "}", ")", ":", "\n", "\n", "    ", "grab_radius_multiplier", "=", "lock_grab_radius", "/", "box_size", "\n", "lock_radius_multiplier", "=", "lock_grab_radius", "/", "box_size", "\n", "\n", "if", "type", "(", "n_sites", ")", "not", "in", "[", "list", ",", "np", ".", "ndarray", "]", ":", "\n", "        ", "n_sites", "=", "[", "n_sites", ",", "n_sites", "]", "\n", "\n", "", "env", "=", "Base", "(", "n_agents", "=", "n_agents", ",", "n_substeps", "=", "n_substeps", ",", "horizon", "=", "horizon", ",", "\n", "floor_size", "=", "floor_size", ",", "grid_size", "=", "grid_size", ",", "\n", "action_lims", "=", "action_lims", ",", "deterministic_mode", "=", "deterministic_mode", ")", "\n", "\n", "if", "scenario", "==", "'randomwalls'", ":", "\n", "        ", "env", ".", "add_module", "(", "RandomWalls", "(", "grid_size", "=", "grid_size", ",", "num_rooms", "=", "n_rooms", ",", "\n", "random_room_number", "=", "random_room_number", ",", "min_room_size", "=", "6", ",", "\n", "door_size", "=", "door_size", ",", "gen_door_obs", "=", "False", ")", ")", "\n", "", "elif", "scenario", "==", "'empty'", ":", "\n", "        ", "env", ".", "add_module", "(", "WallScenarios", "(", "grid_size", "=", "grid_size", ",", "door_size", "=", "door_size", ",", "\n", "scenario", "=", "'empty'", ",", "\n", "friction", "=", "other_friction", ")", ")", "\n", "\n", "", "env", ".", "add_module", "(", "Agents", "(", "n_agents", ",", "\n", "placement_fn", "=", "uniform_placement", ",", "\n", "color", "=", "[", "np", ".", "array", "(", "(", "66.", ",", "235.", ",", "244.", ",", "255.", ")", ")", "/", "255", "]", "*", "n_agents", ",", "\n", "friction", "=", "other_friction", ",", "\n", "polar_obs", "=", "polar_obs", ")", ")", "\n", "if", "np", ".", "max", "(", "n_boxes", ")", ">", "0", ":", "\n", "        ", "env", ".", "add_module", "(", "Boxes", "(", "n_boxes", "=", "n_boxes", ",", "placement_fn", "=", "uniform_placement", ",", "\n", "friction", "=", "box_floor_friction", ",", "polar_obs", "=", "polar_obs", ",", "\n", "n_elongated_boxes", "=", "n_elongated_boxes", ",", "\n", "boxid_obs", "=", "boxid_obs", ",", "boxsize_obs", "=", "boxsize_obs", ",", "\n", "box_size", "=", "box_size", ",", "\n", "box_only_z_rot", "=", "box_only_z_rot", ",", "\n", "mark_box_corners", "=", "True", ")", ")", "\n", "", "if", "n_sites", "[", "1", "]", ">", "0", ":", "\n", "        ", "if", "site_placement", "==", "'center'", ":", "\n", "            ", "site_placement_fn", "=", "center_placement", "\n", "", "elif", "site_placement", "==", "'uniform'", ":", "\n", "            ", "site_placement_fn", "=", "uniform_placement", "\n", "", "elif", "site_placement", "==", "'uniform_away_from_walls'", ":", "\n", "            ", "site_placement_fn", "=", "uniform_placement_middle", "(", "0.85", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'Site placement option: {site_placement} not implemented.'", "\n", "' Please choose from center, uniform and uniform_away_from_walls.'", ")", "\n", "\n", "", "env", ".", "add_module", "(", "ConstructionSites", "(", "n_sites", ",", "placement_fn", "=", "site_placement_fn", ",", "\n", "site_size", "=", "box_size", ",", "site_height", "=", "box_size", "/", "2", ",", "\n", "n_elongated_sites", "=", "n_elongated_sites", ")", ")", "\n", "", "if", "n_lidar_per_agent", ">", "0", "and", "visualize_lidar", ":", "\n", "        ", "env", ".", "add_module", "(", "LidarSites", "(", "n_agents", "=", "n_agents", ",", "n_lidar_per_agent", "=", "n_lidar_per_agent", ")", ")", "\n", "", "if", "np", ".", "max", "(", "n_boxes", ")", ">", "0", "and", "grab_box", ":", "\n", "        ", "env", ".", "add_module", "(", "AgentManipulation", "(", ")", ")", "\n", "", "if", "box_floor_friction", "is", "not", "None", ":", "\n", "        ", "env", ".", "add_module", "(", "FloorAttributes", "(", "friction", "=", "box_floor_friction", ")", ")", "\n", "", "env", ".", "add_module", "(", "WorldConstants", "(", "gravity", "=", "gravity", ")", ")", "\n", "env", ".", "reset", "(", ")", "\n", "keys_self", "=", "[", "'agent_qpos_qvel'", ",", "'hider'", ",", "'prep_obs'", "]", "\n", "keys_mask_self", "=", "[", "'mask_aa_obs'", "]", "\n", "keys_external", "=", "[", "'agent_qpos_qvel'", ",", "'construction_site_obs'", "]", "\n", "keys_copy", "=", "[", "'you_lock'", ",", "'team_lock'", ",", "'ramp_you_lock'", ",", "'ramp_team_lock'", "]", "\n", "keys_mask_external", "=", "[", "]", "\n", "\n", "env", "=", "AddConstantObservationsWrapper", "(", "env", ",", "new_obs", "=", "additional_obs", ")", "\n", "keys_external", "+=", "list", "(", "additional_obs", ")", "\n", "keys_mask_external", "+=", "[", "ob", "for", "ob", "in", "additional_obs", "if", "'mask'", "in", "ob", "]", "\n", "\n", "env", "=", "SplitMultiAgentActions", "(", "env", ")", "\n", "if", "team_size_obs", ":", "\n", "        ", "keys_self", "+=", "[", "'team_size'", "]", "\n", "", "env", "=", "TeamMembership", "(", "env", ",", "np", ".", "zeros", "(", "(", "n_agents", ",", ")", ")", ")", "\n", "env", "=", "AgentAgentObsMask2D", "(", "env", ")", "\n", "env", "=", "DiscretizeActionWrapper", "(", "env", ",", "'action_movement'", ")", "\n", "if", "np", ".", "max", "(", "n_boxes", ")", ">", "0", ":", "\n", "        ", "env", "=", "AgentGeomObsMask2D", "(", "env", ",", "pos_obs_key", "=", "'box_pos'", ",", "mask_obs_key", "=", "'mask_ab_obs'", ",", "\n", "geom_idxs_obs_key", "=", "'box_geom_idxs'", ")", "\n", "keys_external", "+=", "[", "'mask_ab_obs'", ",", "'box_obs'", "]", "\n", "keys_mask_external", ".", "append", "(", "'mask_ab_obs'", ")", "\n", "", "if", "lock_box", "and", "np", ".", "max", "(", "n_boxes", ")", ">", "0", ":", "\n", "        ", "agent_allowed_to_lock_keys", "=", "None", "if", "lock_out_of_vision", "else", "[", "\"mask_ab_obs\"", "]", "\n", "env", "=", "LockObjWrapper", "(", "env", ",", "body_names", "=", "[", "f'moveable_box{i}'", "for", "i", "in", "range", "(", "n_boxes", ")", "]", ",", "\n", "agent_idx_allowed_to_lock", "=", "np", ".", "arange", "(", "n_agents", ")", ",", "\n", "lock_type", "=", "lock_type", ",", "\n", "radius_multiplier", "=", "lock_radius_multiplier", ",", "\n", "obj_in_game_metadata_keys", "=", "[", "\"curr_n_boxes\"", "]", ",", "\n", "agent_allowed_to_lock_keys", "=", "agent_allowed_to_lock_keys", ")", "\n", "", "if", "grab_box", "and", "np", ".", "max", "(", "n_boxes", ")", ">", "0", ":", "\n", "        ", "env", "=", "GrabObjWrapper", "(", "env", ",", "[", "f'moveable_box{i}'", "for", "i", "in", "range", "(", "n_boxes", ")", "]", ",", "\n", "radius_multiplier", "=", "grab_radius_multiplier", ",", "\n", "grab_exclusive", "=", "grab_exclusive", ",", "\n", "obj_in_game_metadata_keys", "=", "[", "'curr_n_boxes'", "]", ")", "\n", "\n", "", "if", "n_lidar_per_agent", ">", "0", ":", "\n", "        ", "env", "=", "Lidar", "(", "env", ",", "n_lidar_per_agent", "=", "n_lidar_per_agent", ",", "visualize_lidar", "=", "visualize_lidar", ",", "\n", "compress_lidar_scale", "=", "compress_lidar_scale", ")", "\n", "keys_copy", "+=", "[", "'lidar'", "]", "\n", "keys_external", "+=", "[", "'lidar'", "]", "\n", "\n", "", "env", "=", "ConstructionDistancesWrapper", "(", "env", ")", "\n", "env", "=", "NumpyArrayRewardWrapper", "(", "env", ")", "\n", "\n", "reward_wrappers", "=", "{", "\n", "'construction_dense'", ":", "ConstructionDenseRewardWrapper", ",", "\n", "'construction_completed'", ":", "ConstructionCompletedRewardWrapper", ",", "\n", "}", "\n", "\n", "for", "rew_info", "in", "reward_infos", ":", "\n", "        ", "rew_type", "=", "rew_info", "[", "'type'", "]", "\n", "del", "rew_info", "[", "'type'", "]", "\n", "env", "=", "reward_wrappers", "[", "rew_type", "]", "(", "env", ",", "**", "rew_info", ")", "\n", "\n", "", "env", "=", "SplitObservations", "(", "env", ",", "keys_self", "+", "keys_mask_self", ",", "keys_copy", "=", "keys_copy", ")", "\n", "if", "n_agents", "==", "1", ":", "\n", "        ", "env", "=", "SpoofEntityWrapper", "(", "env", ",", "2", ",", "[", "'agent_qpos_qvel'", ",", "'hider'", ",", "'prep_obs'", "]", ",", "[", "'mask_aa_obs'", "]", ")", "\n", "", "env", "=", "SpoofEntityWrapper", "(", "env", ",", "n_boxes", ",", "\n", "[", "'box_obs'", ",", "'you_lock'", ",", "'team_lock'", ",", "'obj_lock'", "]", ",", "\n", "[", "'mask_ab_obs'", "]", ")", "\n", "env", "=", "SpoofEntityWrapper", "(", "env", ",", "n_sites", "[", "1", "]", ",", "[", "'construction_site_obs'", "]", ",", "[", "'mask_acs_obs'", "]", ")", "\n", "keys_mask_external", "+=", "[", "'mask_ab_obs_spoof'", ",", "'mask_acs_obs_spoof'", "]", "\n", "env", "=", "LockAllWrapper", "(", "env", ",", "remove_object_specific_lock", "=", "True", ")", "\n", "if", "not", "grab_out_of_vision", "and", "grab_box", ":", "\n", "        ", "env", "=", "MaskActionWrapper", "(", "env", ",", "'action_pull'", ",", "[", "'mask_ab_obs'", "]", ")", "# Can only pull if in vision", "\n", "", "if", "not", "grab_selective", "and", "grab_box", ":", "\n", "        ", "env", "=", "GrabClosestWrapper", "(", "env", ")", "\n", "", "env", "=", "DiscardMujocoExceptionEpisodes", "(", "env", ")", "\n", "env", "=", "ConcatenateObsWrapper", "(", "env", ",", "{", "'agent_qpos_qvel'", ":", "[", "'agent_qpos_qvel'", ",", "'hider'", ",", "'prep_obs'", "]", ",", "\n", "'box_obs'", ":", "[", "'box_obs'", ",", "'you_lock'", ",", "'team_lock'", ",", "'obj_lock'", "]", "}", ")", "\n", "env", "=", "SelectKeysWrapper", "(", "env", ",", "keys_self", "=", "keys_self", ",", "\n", "keys_other", "=", "keys_external", "+", "keys_mask_self", "+", "keys_mask_external", ")", "\n", "return", "env", "\n", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.box_locking.LockObjectsTask.__init__": [[58, 90], ["gym.Wrapper.__init__", "list", "numpy.zeros", "box_locking.LockObjectsTask.task.replace", "range"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "n_objs", ",", "task", "=", "'all'", ",", "fixed_order", "=", "False", ",", "\n", "obj_lock_obs_key", "=", "'obj_lock'", ",", "obj_pos_obs_key", "=", "'box_pos'", ",", "\n", "act_lock_key", "=", "'action_glue'", ",", "agent_pos_key", "=", "'agent_pos'", ",", "\n", "lock_reward", "=", "5.0", ",", "unlock_penalty", "=", "10.0", ",", "shaped_reward_scale", "=", "1.0", ",", "\n", "success_reward", "=", "1", ",", "return_threshold", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "n_objs", "=", "n_objs", "\n", "self", ".", "task", "=", "task", "or", "'all'", "\n", "assert", "task", "in", "[", "'all'", ",", "'order'", ",", "'all-return'", ",", "'order-return'", "]", ",", "(", "\n", "f'task {task} is currently not supported'", ")", "\n", "self", ".", "need_return", "=", "'return'", "in", "self", ".", "task", "\n", "self", ".", "return_threshold", "=", "return_threshold", "\n", "if", "self", ".", "need_return", ":", "\n", "            ", "self", ".", "task", "=", "self", ".", "task", ".", "replace", "(", "'-return'", ",", "''", ")", "\n", "", "self", ".", "n_agents", "=", "self", ".", "unwrapped", ".", "n_agents", "\n", "assert", "self", ".", "n_agents", "==", "1", ",", "'The locking tasks only support 1 agent'", "\n", "self", ".", "agent_key", "=", "agent_pos_key", "\n", "self", ".", "obj_order", "=", "list", "(", "range", "(", "self", ".", "n_objs", ")", ")", "\n", "self", ".", "fixed_order", "=", "fixed_order", "\n", "self", ".", "lock_key", "=", "obj_lock_obs_key", "\n", "self", ".", "pos_key", "=", "obj_pos_obs_key", "\n", "self", ".", "act_key", "=", "act_lock_key", "\n", "self", ".", "lock_reward", "=", "lock_reward", "\n", "self", ".", "unlock_penalty", "=", "unlock_penalty", "\n", "self", ".", "shaped_reward_scale", "=", "shaped_reward_scale", "\n", "self", ".", "success_reward", "=", "success_reward", "\n", "self", ".", "objs_locked", "=", "np", ".", "zeros", "(", "(", "n_objs", ",", ")", ",", "dtype", "=", "np", ".", "int8", ")", "\n", "self", ".", "spawn_pos", "=", "None", "\n", "self", ".", "spawn_pos_dist", "=", "None", "\n", "self", ".", "next_obj", "=", "None", "\n", "self", ".", "next_obj_dist", "=", "0", "\n", "self", ".", "unlocked_objs", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.box_locking.LockObjectsTask.reset": [[91, 101], ["box_locking.LockObjectsTask.env.reset", "box_locking.LockObjectsTask._get_next_obj", "numpy.random.shuffle"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.box_locking.LockObjectsTask._get_next_obj"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "fixed_order", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "obj_order", ")", "\n", "", "self", ".", "objs_locked", "[", ":", "]", "=", "0", "\n", "self", ".", "unlocked_objs", "=", "self", ".", "obj_order", "\n", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "self", ".", "spawn_pos", "=", "obs", "[", "self", ".", "agent_key", "]", "[", "0", ",", ":", "2", "]", "\n", "self", ".", "spawn_pos_dist", "=", "0", "\n", "self", ".", "next_obj", ",", "self", ".", "next_obj_dist", "=", "self", ".", "_get_next_obj", "(", "obs", ")", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.box_locking.LockObjectsTask._get_next_obj": [[102, 120], ["len", "numpy.linalg.norm", "min", "numpy.linalg.norm"], "methods", ["None"], ["", "def", "_get_next_obj", "(", "self", ",", "obs", ")", ":", "\n", "        ", "'''\n            Return the next object that needs to be locked & the distance to it.\n        '''", "\n", "agent_pos", "=", "obs", "[", "self", ".", "agent_key", "]", "[", ":", ",", ":", "2", "]", "\n", "if", "len", "(", "self", ".", "unlocked_objs", ")", "==", "0", ":", "\n", "            ", "next_obj", "=", "None", "\n", "next_obj_dist", "=", "0", "\n", "", "elif", "self", ".", "task", "==", "'order'", ":", "\n", "            ", "next_obj", "=", "self", ".", "unlocked_objs", "[", "0", "]", "\n", "next_obj_pos", "=", "obs", "[", "self", ".", "pos_key", "]", "[", "next_obj", ",", ":", "2", "]", "\n", "next_obj_dist", "=", "np", ".", "linalg", ".", "norm", "(", "agent_pos", "-", "next_obj_pos", ")", "\n", "", "elif", "self", ".", "task", "==", "'all'", ":", "\n", "            ", "obj_dist", "=", "[", "(", "np", ".", "linalg", ".", "norm", "(", "obs", "[", "self", ".", "pos_key", "]", "[", "i", ",", ":", "2", "]", "-", "agent_pos", ")", ",", "i", ")", "\n", "for", "i", "in", "self", ".", "unlocked_objs", "]", "\n", "next_obj_dist", ",", "next_obj", "=", "min", "(", "obj_dist", ")", "\n", "\n", "", "return", "next_obj", ",", "next_obj_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.box_locking.LockObjectsTask._get_lock_reward": [[121, 129], ["numpy.sum", "numpy.sum", "numpy.logical_and", "numpy.logical_and"], "methods", ["None"], ["", "def", "_get_lock_reward", "(", "self", ",", "curr_objs_locked", ",", "old_objs_locked", ")", ":", "\n", "        ", "'''\n            Calculates the locking reward / unlocking penalty\n        '''", "\n", "n_new_lock", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "curr_objs_locked", "==", "1", ",", "old_objs_locked", "==", "0", ")", ")", "\n", "n_new_unlock", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "curr_objs_locked", "==", "0", ",", "old_objs_locked", "==", "1", ")", ")", "\n", "lock_reward", "=", "n_new_lock", "*", "self", ".", "lock_reward", "-", "n_new_unlock", "*", "self", ".", "unlock_penalty", "\n", "return", "lock_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.box_locking.LockObjectsTask._get_shaped_reward": [[130, 153], ["None"], "methods", ["None"], ["", "def", "_get_shaped_reward", "(", "self", ",", "new_next_obj", ",", "new_next_obj_dist", ",", "new_spawn_pos_dist", ")", ":", "\n", "        ", "'''\n            Calculates the shaped reward based on the change in distance from the target\n        '''", "\n", "rew", "=", "0", "\n", "if", "(", "self", ".", "next_obj", "is", "not", "None", ")", "and", "(", "new_next_obj", "==", "self", ".", "next_obj", ")", ":", "\n", "            ", "rew", "+=", "(", "self", ".", "next_obj_dist", "-", "new_next_obj_dist", ")", "*", "self", ".", "shaped_reward_scale", "\n", "", "elif", "(", "(", "self", ".", "next_obj", "is", "not", "None", ")", "and", "(", "new_next_obj", "!=", "self", ".", "next_obj", ")", ")", ":", "\n", "            ", "if", "self", ".", "objs_locked", "[", "self", ".", "next_obj", "]", "==", "1", ":", "\n", "# previous target object locked", "\n", "                ", "rew", "+=", "self", ".", "next_obj_dist", "*", "self", ".", "shaped_reward_scale", "\n", "", "else", ":", "\n", "# previously locked object unlocked", "\n", "                ", "rew", "-=", "new_next_obj_dist", "*", "self", ".", "shaped_reward_scale", "\n", "", "", "elif", "(", "self", ".", "next_obj", "is", "None", ")", "and", "(", "new_next_obj", "is", "not", "None", ")", ":", "\n", "# previously locked object unlocked", "\n", "            ", "rew", "-=", "new_next_obj_dist", "*", "self", ".", "shaped_reward_scale", "\n", "", "elif", "(", "self", ".", "next_obj", "is", "None", ")", "and", "(", "new_next_obj", "is", "None", ")", ":", "\n", "            ", "if", "self", ".", "need_return", ":", "\n", "# all objects locked; agent is rewarded for returning to its spawning point", "\n", "                ", "rew", "+=", "(", "self", ".", "spawn_pos_dist", "-", "new_spawn_pos_dist", ")", "*", "self", ".", "shaped_reward_scale", "\n", "\n", "", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.box_locking.LockObjectsTask.step": [[154, 186], ["box_locking.LockObjectsTask.env.step", "obs[].flatten().astype", "box_locking.LockObjectsTask._get_lock_reward", "box_locking.LockObjectsTask._get_next_obj", "numpy.linalg.norm", "box_locking.LockObjectsTask._get_shaped_reward", "len", "len", "obs[].flatten"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.box_locking.LockObjectsTask._get_lock_reward", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.box_locking.LockObjectsTask._get_next_obj", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.box_locking.LockObjectsTask._get_shaped_reward"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "self", ".", "task", "==", "'order'", ":", "\n", "            ", "\"\"\"\n                you can unlock any locked objs but only lock objs when all previous ones are locked\n            \"\"\"", "\n", "if", "len", "(", "self", ".", "unlocked_objs", ")", ">", "1", ":", "\n", "                ", "action", "[", "self", ".", "act_key", "]", "[", ":", ",", "self", ".", "unlocked_objs", "[", "1", ":", "]", "]", "=", "0", "\n", "\n", "", "", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "curr_objs_locked", "=", "obs", "[", "self", ".", "lock_key", "]", ".", "flatten", "(", ")", ".", "astype", "(", "np", ".", "int8", ")", "\n", "\n", "rew", "+=", "self", ".", "_get_lock_reward", "(", "curr_objs_locked", ",", "old_objs_locked", "=", "self", ".", "objs_locked", ")", "\n", "\n", "self", ".", "objs_locked", "=", "curr_objs_locked", "\n", "self", ".", "unlocked_objs", "=", "[", "i", "for", "i", "in", "self", ".", "obj_order", "if", "self", ".", "objs_locked", "[", "i", "]", "==", "0", "]", "\n", "\n", "new_next_obj", ",", "new_next_obj_dist", "=", "self", ".", "_get_next_obj", "(", "obs", ")", "\n", "agent_pos", "=", "obs", "[", "self", ".", "agent_key", "]", "[", ":", ",", ":", "2", "]", "\n", "new_spawn_pos_dist", "=", "np", ".", "linalg", ".", "norm", "(", "agent_pos", "-", "self", ".", "spawn_pos", ")", "\n", "rew", "+=", "self", ".", "_get_shaped_reward", "(", "new_next_obj", ",", "new_next_obj_dist", ",", "new_spawn_pos_dist", ")", "\n", "\n", "self", ".", "spawn_pos_dist", "=", "new_spawn_pos_dist", "\n", "self", ".", "next_obj_dist", "=", "new_next_obj_dist", "\n", "self", ".", "next_obj", "=", "new_next_obj", "\n", "\n", "n_unlocked", "=", "len", "(", "self", ".", "unlocked_objs", ")", "\n", "if", "n_unlocked", "==", "0", "and", "(", "(", "not", "self", ".", "need_return", ")", "or", "\n", "self", ".", "spawn_pos_dist", "<=", "self", ".", "return_threshold", ")", ":", "\n", "# reward for successfully completing the task", "\n", "            ", "rew", "+=", "self", ".", "success_reward", "\n", "\n", "", "return", "obs", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.box_locking.tri_placement": [[188, 202], ["numpy.array", "random_state.randint", "random_state.randint"], "function", ["None"], ["", "", "def", "tri_placement", "(", "tri_room_idx", ")", ":", "\n", "    ", "'''\n        This function expects the wall scenario to be 'var_tri'\n        Returns a placement function that randomly places objects in the room\n        with index tri_room_idx\n    '''", "\n", "def", "placement", "(", "grid", ",", "obj_size", ",", "metadata", ",", "random_state", ")", ":", "\n", "        ", "assert", "'tri_room_grid_cell_range'", "in", "metadata", "\n", "x_rag", ",", "y_rag", "=", "metadata", "[", "'tri_room_grid_cell_range'", "]", "[", "tri_room_idx", "]", "\n", "pos", "=", "np", ".", "array", "(", "[", "random_state", ".", "randint", "(", "x_rag", "[", "0", "]", ",", "x_rag", "[", "1", "]", "-", "obj_size", "[", "0", "]", ")", ",", "\n", "random_state", ".", "randint", "(", "y_rag", "[", "0", "]", ",", "y_rag", "[", "1", "]", "-", "obj_size", "[", "1", "]", ")", "]", ")", "\n", "return", "pos", "\n", "\n", "", "return", "placement", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.box_locking.rotate_tri_placement": [[204, 221], ["len", "filled_rooms.append", "len", "box_locking.tri_placement", "range", "random_state.randint"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.box_locking.tri_placement"], ["", "def", "rotate_tri_placement", "(", "grid", ",", "obj_size", ",", "metadata", ",", "random_state", ")", ":", "\n", "    ", "'''\n        This function expects the wall scenario to be 'var_tri'.\n        It places objects equally among the three rooms, so that any room has\n        contains at most 1 more object than any other room.\n    '''", "\n", "if", "'tri_placement_rotation'", "not", "in", "metadata", ":", "\n", "        ", "metadata", "[", "'tri_placement_rotation'", "]", "=", "[", "]", "\n", "", "filled_rooms", "=", "metadata", "[", "'tri_placement_rotation'", "]", "\n", "if", "len", "(", "filled_rooms", ")", "==", "3", ":", "\n", "        ", "filled_rooms", "=", "[", "]", "\n", "", "available_rooms", "=", "[", "i", "for", "i", "in", "range", "(", "3", ")", "if", "i", "not", "in", "filled_rooms", "]", "\n", "n_available_rooms", "=", "len", "(", "available_rooms", ")", "\n", "next_room", "=", "available_rooms", "[", "random_state", ".", "randint", "(", "0", ",", "10000", ")", "%", "n_available_rooms", "]", "\n", "filled_rooms", ".", "append", "(", "next_room", ")", "\n", "metadata", "[", "'tri_placement_rotation'", "]", "=", "filled_rooms", "\n", "return", "tri_placement", "(", "next_room", ")", "(", "grid", ",", "obj_size", ",", "metadata", ",", "random_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.box_locking.make_env": [[223, 402], ["mae_envs.envs.base.Base", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.wrappers.manipulation.GrabClosestWrapper.reset", "mae_envs.wrappers.multi_agent.SplitMultiAgentActions", "mae_envs.wrappers.team.TeamMembership", "mae_envs.wrappers.line_of_sight.AgentAgentObsMask2D", "mae_envs.wrappers.util.DiscretizeActionWrapper", "mae_envs.wrappers.util.NumpyArrayRewardWrapper", "mae_envs.wrappers.util.AddConstantObservationsWrapper", "list", "box_locking.LockObjectsTask", "mae_envs.wrappers.multi_agent.SplitObservations", "mae_envs.wrappers.util.SpoofEntityWrapper", "mae_envs.wrappers.manipulation.LockAllWrapper", "mae_envs.wrappers.util.DiscardMujocoExceptionEpisodes", "mae_envs.wrappers.util.ConcatenateObsWrapper", "mae_envs.wrappers.multi_agent.SelectKeysWrapper", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.modules.agents.Agents", "numpy.max", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.modules.world.WorldConstants", "numpy.zeros", "numpy.max", "mae_envs.wrappers.line_of_sight.AgentGeomObsMask2D", "keys_mask_external.append", "mae_envs.wrappers.manipulation.LockObjWrapper", "mae_envs.wrappers.line_of_sight.AgentGeomObsMask2D", "mae_envs.wrappers.manipulation.LockObjWrapper", "mae_envs.wrappers.manipulation.GrabObjWrapper", "mae_envs.wrappers.lidar.Lidar", "mae_envs.wrappers.util.SpoofEntityWrapper", "mae_envs.wrappers.util.MaskActionWrapper", "mae_envs.wrappers.manipulation.GrabClosestWrapper", "mae_envs.modules.walls.RandomWalls", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.modules.objects.Boxes", "mae_envs.modules.objects.Ramps", "mae_envs.modules.objects.LidarSites", "numpy.max", "mae_envs.modules.agents.AgentManipulation", "mae_envs.modules.world.FloorAttributes", "numpy.max", "numpy.max", "mae_envs.modules.walls.WallScenarios", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "numpy.arange", "numpy.arange", "mae_envs.modules.walls.WallScenarios", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "ValueError", "range", "range", "mae_envs.modules.walls.WallScenarios", "box_locking.tri_placement", "range", "range", "range", "numpy.array"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.box_locking.tri_placement"], ["", "def", "make_env", "(", "n_substeps", "=", "15", ",", "horizon", "=", "80", ",", "deterministic_mode", "=", "False", ",", "\n", "floor_size", "=", "6.0", ",", "grid_size", "=", "30", ",", "door_size", "=", "2", ",", "\n", "n_agents", "=", "1", ",", "fixed_agent_spawn", "=", "False", ",", "\n", "lock_box", "=", "True", ",", "grab_box", "=", "True", ",", "grab_selective", "=", "False", ",", "\n", "lock_type", "=", "'any_lock_specific'", ",", "\n", "lock_grab_radius", "=", "0.25", ",", "grab_exclusive", "=", "False", ",", "grab_out_of_vision", "=", "False", ",", "\n", "lock_out_of_vision", "=", "True", ",", "\n", "box_floor_friction", "=", "0.2", ",", "other_friction", "=", "0.01", ",", "gravity", "=", "[", "0", ",", "0", ",", "-", "50", "]", ",", "\n", "action_lims", "=", "(", "-", "0.9", ",", "0.9", ")", ",", "polar_obs", "=", "True", ",", "\n", "scenario", "=", "'quadrant'", ",", "p_door_dropout", "=", "0.0", ",", "\n", "n_rooms", "=", "4", ",", "random_room_number", "=", "True", ",", "\n", "n_lidar_per_agent", "=", "0", ",", "visualize_lidar", "=", "False", ",", "compress_lidar_scale", "=", "None", ",", "\n", "n_boxes", "=", "2", ",", "box_size", "=", "0.5", ",", "box_only_z_rot", "=", "False", ",", "\n", "boxid_obs", "=", "True", ",", "boxsize_obs", "=", "True", ",", "pad_ramp_size", "=", "True", ",", "additional_obs", "=", "{", "}", ",", "\n", "# lock-box task", "\n", "task_type", "=", "'all'", ",", "lock_reward", "=", "5.0", ",", "unlock_penalty", "=", "7.0", ",", "shaped_reward_scale", "=", "0.25", ",", "\n", "return_threshold", "=", "0.1", ",", "\n", "# ramps", "\n", "n_ramps", "=", "0", ")", ":", "\n", "\n", "    ", "grab_radius_multiplier", "=", "lock_grab_radius", "/", "box_size", "\n", "lock_radius_multiplier", "=", "lock_grab_radius", "/", "box_size", "\n", "\n", "env", "=", "Base", "(", "n_agents", "=", "n_agents", ",", "n_substeps", "=", "n_substeps", ",", "\n", "floor_size", "=", "floor_size", ",", "\n", "horizon", "=", "horizon", ",", "action_lims", "=", "action_lims", ",", "deterministic_mode", "=", "deterministic_mode", ",", "\n", "grid_size", "=", "grid_size", ")", "\n", "\n", "if", "scenario", "==", "'randomwalls'", ":", "\n", "        ", "env", ".", "add_module", "(", "RandomWalls", "(", "grid_size", "=", "grid_size", ",", "num_rooms", "=", "n_rooms", ",", "\n", "random_room_number", "=", "random_room_number", ",", "\n", "min_room_size", "=", "6", ",", "door_size", "=", "door_size", ",", "\n", "gen_door_obs", "=", "False", ")", ")", "\n", "box_placement_fn", "=", "uniform_placement", "\n", "ramp_placement_fn", "=", "uniform_placement", "\n", "agent_placement_fn", "=", "uniform_placement", "if", "not", "fixed_agent_spawn", "else", "center_placement", "\n", "", "elif", "scenario", "==", "'quadrant'", ":", "\n", "        ", "env", ".", "add_module", "(", "WallScenarios", "(", "grid_size", "=", "grid_size", ",", "door_size", "=", "door_size", ",", "\n", "scenario", "=", "scenario", ",", "friction", "=", "other_friction", ",", "\n", "p_door_dropout", "=", "p_door_dropout", ")", ")", "\n", "box_placement_fn", "=", "uniform_placement", "\n", "ramp_placement_fn", "=", "uniform_placement", "\n", "agent_placement_fn", "=", "quadrant_placement", "if", "not", "fixed_agent_spawn", "else", "center_placement", "\n", "", "elif", "scenario", "==", "'empty'", ":", "\n", "        ", "env", ".", "add_module", "(", "WallScenarios", "(", "grid_size", "=", "grid_size", ",", "door_size", "=", "2", ",", "scenario", "=", "'empty'", ")", ")", "\n", "box_placement_fn", "=", "uniform_placement", "\n", "ramp_placement_fn", "=", "uniform_placement", "\n", "agent_placement_fn", "=", "center_placement", "\n", "", "elif", "'var_tri'", "in", "scenario", ":", "\n", "        ", "env", ".", "add_module", "(", "WallScenarios", "(", "grid_size", "=", "grid_size", ",", "door_size", "=", "door_size", ",", "scenario", "=", "'var_tri'", ")", ")", "\n", "ramp_placement_fn", "=", "[", "tri_placement", "(", "i", "%", "3", ")", "for", "i", "in", "range", "(", "n_ramps", ")", "]", "\n", "agent_placement_fn", "=", "center_placement", "if", "fixed_agent_spawn", "else", "(", "uniform_placement", "if", "'uniform'", "in", "scenario", "else", "rotate_tri_placement", ")", "\n", "box_placement_fn", "=", "uniform_placement", "if", "'uniform'", "in", "scenario", "else", "rotate_tri_placement", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Scenario {scenario} not supported.\"", ")", "\n", "\n", "", "env", ".", "add_module", "(", "Agents", "(", "n_agents", ",", "\n", "placement_fn", "=", "agent_placement_fn", ",", "\n", "color", "=", "[", "np", ".", "array", "(", "(", "66.", ",", "235.", ",", "244.", ",", "255.", ")", ")", "/", "255", "]", "*", "n_agents", ",", "\n", "friction", "=", "other_friction", ",", "\n", "polar_obs", "=", "polar_obs", ")", ")", "\n", "if", "np", ".", "max", "(", "n_boxes", ")", ">", "0", ":", "\n", "        ", "env", ".", "add_module", "(", "Boxes", "(", "n_boxes", "=", "n_boxes", ",", "placement_fn", "=", "box_placement_fn", ",", "\n", "friction", "=", "box_floor_friction", ",", "polar_obs", "=", "polar_obs", ",", "\n", "n_elongated_boxes", "=", "0", ",", "\n", "boxid_obs", "=", "boxid_obs", ",", "\n", "box_only_z_rot", "=", "box_only_z_rot", ",", "\n", "boxsize_obs", "=", "boxsize_obs", ")", ")", "\n", "\n", "", "if", "n_ramps", ">", "0", ":", "\n", "        ", "env", ".", "add_module", "(", "Ramps", "(", "n_ramps", "=", "n_ramps", ",", "placement_fn", "=", "ramp_placement_fn", ",", "\n", "friction", "=", "other_friction", ",", "polar_obs", "=", "polar_obs", ",", "\n", "pad_ramp_size", "=", "pad_ramp_size", ")", ")", "\n", "\n", "", "if", "n_lidar_per_agent", ">", "0", "and", "visualize_lidar", ":", "\n", "        ", "env", ".", "add_module", "(", "LidarSites", "(", "n_agents", "=", "n_agents", ",", "n_lidar_per_agent", "=", "n_lidar_per_agent", ")", ")", "\n", "\n", "", "if", "np", ".", "max", "(", "n_boxes", ")", ">", "0", "and", "grab_box", ":", "\n", "        ", "env", ".", "add_module", "(", "AgentManipulation", "(", ")", ")", "\n", "", "if", "box_floor_friction", "is", "not", "None", ":", "\n", "        ", "env", ".", "add_module", "(", "FloorAttributes", "(", "friction", "=", "box_floor_friction", ")", ")", "\n", "", "env", ".", "add_module", "(", "WorldConstants", "(", "gravity", "=", "gravity", ")", ")", "\n", "env", ".", "reset", "(", ")", "\n", "keys_self", "=", "[", "'agent_qpos_qvel'", ",", "'hider'", ",", "'prep_obs'", "]", "\n", "keys_mask_self", "=", "[", "'mask_aa_obs'", "]", "\n", "keys_external", "=", "[", "'agent_qpos_qvel'", "]", "\n", "keys_copy", "=", "[", "'you_lock'", ",", "'team_lock'", "]", "\n", "keys_mask_external", "=", "[", "]", "\n", "\n", "env", "=", "SplitMultiAgentActions", "(", "env", ")", "\n", "env", "=", "TeamMembership", "(", "env", ",", "np", ".", "zeros", "(", "(", "n_agents", ",", ")", ")", ")", "\n", "env", "=", "AgentAgentObsMask2D", "(", "env", ")", "\n", "env", "=", "DiscretizeActionWrapper", "(", "env", ",", "'action_movement'", ")", "\n", "env", "=", "NumpyArrayRewardWrapper", "(", "env", ")", "\n", "\n", "if", "np", ".", "max", "(", "n_boxes", ")", ">", "0", ":", "\n", "        ", "env", "=", "AgentGeomObsMask2D", "(", "env", ",", "pos_obs_key", "=", "'box_pos'", ",", "mask_obs_key", "=", "'mask_ab_obs'", ",", "\n", "geom_idxs_obs_key", "=", "'box_geom_idxs'", ")", "\n", "keys_external", "+=", "[", "'mask_ab_obs'", ",", "'box_obs'", "]", "\n", "keys_mask_external", ".", "append", "(", "'mask_ab_obs'", ")", "\n", "", "if", "lock_box", "and", "np", ".", "max", "(", "n_boxes", ")", ">", "0", ":", "\n", "        ", "env", "=", "LockObjWrapper", "(", "env", ",", "body_names", "=", "[", "f'moveable_box{i}'", "for", "i", "in", "range", "(", "n_boxes", ")", "]", ",", "\n", "agent_idx_allowed_to_lock", "=", "np", ".", "arange", "(", "n_agents", ")", ",", "\n", "lock_type", "=", "lock_type", ",", "\n", "radius_multiplier", "=", "lock_radius_multiplier", ",", "\n", "obj_in_game_metadata_keys", "=", "[", "\"curr_n_boxes\"", "]", ",", "\n", "agent_allowed_to_lock_keys", "=", "None", "if", "lock_out_of_vision", "else", "[", "\"mask_ab_obs\"", "]", ")", "\n", "\n", "", "if", "n_ramps", ">", "0", ":", "\n", "        ", "env", "=", "AgentGeomObsMask2D", "(", "env", ",", "pos_obs_key", "=", "'ramp_pos'", ",", "mask_obs_key", "=", "'mask_ar_obs'", ",", "\n", "geom_idxs_obs_key", "=", "'ramp_geom_idxs'", ")", "\n", "env", "=", "LockObjWrapper", "(", "env", ",", "body_names", "=", "[", "f\"ramp{i}:ramp\"", "for", "i", "in", "range", "(", "n_ramps", ")", "]", ",", "\n", "agent_idx_allowed_to_lock", "=", "np", ".", "arange", "(", "n_agents", ")", ",", "\n", "lock_type", "=", "lock_type", ",", "ac_obs_prefix", "=", "'ramp_'", ",", "\n", "radius_multiplier", "=", "lock_radius_multiplier", ",", "\n", "agent_allowed_to_lock_keys", "=", "None", "if", "lock_out_of_vision", "else", "[", "\"mask_ar_obs\"", "]", ")", "\n", "\n", "keys_external", "+=", "[", "'ramp_obs'", "]", "\n", "keys_mask_external", "+=", "[", "'mask_ar_obs'", "]", "\n", "keys_copy", "+=", "[", "'ramp_you_lock'", ",", "'ramp_team_lock'", "]", "\n", "\n", "", "if", "grab_box", "and", "np", ".", "max", "(", "n_boxes", ")", ">", "0", ":", "\n", "        ", "body_names", "=", "(", "[", "f'moveable_box{i}'", "for", "i", "in", "range", "(", "n_boxes", ")", "]", "+", "\n", "[", "f\"ramp{i}:ramp\"", "for", "i", "in", "range", "(", "n_ramps", ")", "]", ")", "\n", "obj_in_game_meta_keys", "=", "[", "'curr_n_boxes'", "]", "+", "(", "[", "'curr_n_ramps'", "]", "if", "n_ramps", ">", "0", "else", "[", "]", ")", "\n", "env", "=", "GrabObjWrapper", "(", "env", ",", "\n", "body_names", "=", "body_names", ",", "\n", "radius_multiplier", "=", "grab_radius_multiplier", ",", "\n", "grab_exclusive", "=", "grab_exclusive", ",", "\n", "obj_in_game_metadata_keys", "=", "obj_in_game_meta_keys", ")", "\n", "\n", "", "if", "n_lidar_per_agent", ">", "0", ":", "\n", "        ", "env", "=", "Lidar", "(", "env", ",", "n_lidar_per_agent", "=", "n_lidar_per_agent", ",", "visualize_lidar", "=", "visualize_lidar", ",", "\n", "compress_lidar_scale", "=", "compress_lidar_scale", ")", "\n", "keys_copy", "+=", "[", "'lidar'", "]", "\n", "keys_external", "+=", "[", "'lidar'", "]", "\n", "\n", "", "env", "=", "AddConstantObservationsWrapper", "(", "env", ",", "new_obs", "=", "additional_obs", ")", "\n", "keys_external", "+=", "list", "(", "additional_obs", ")", "\n", "keys_mask_external", "+=", "[", "ob", "for", "ob", "in", "additional_obs", "if", "'mask'", "in", "ob", "]", "\n", "\n", "#############################################", "\n", "# lock Box Task Reward", "\n", "###", "\n", "env", "=", "LockObjectsTask", "(", "env", ",", "n_objs", "=", "n_boxes", ",", "task", "=", "task_type", ",", "fixed_order", "=", "True", ",", "\n", "obj_lock_obs_key", "=", "'obj_lock'", ",", "obj_pos_obs_key", "=", "'box_pos'", ",", "\n", "act_lock_key", "=", "'action_glue'", ",", "agent_pos_key", "=", "'agent_pos'", ",", "\n", "lock_reward", "=", "lock_reward", ",", "unlock_penalty", "=", "unlock_penalty", ",", "\n", "shaped_reward_scale", "=", "shaped_reward_scale", ",", "\n", "return_threshold", "=", "return_threshold", ")", "\n", "###", "\n", "#############################################", "\n", "\n", "env", "=", "SplitObservations", "(", "env", ",", "keys_self", "+", "keys_mask_self", ",", "keys_copy", "=", "keys_copy", ")", "\n", "env", "=", "SpoofEntityWrapper", "(", "env", ",", "n_boxes", ",", "\n", "[", "'box_obs'", ",", "'you_lock'", ",", "'team_lock'", ",", "'obj_lock'", "]", ",", "\n", "[", "'mask_ab_obs'", "]", ")", "\n", "keys_mask_external", "+=", "[", "'mask_ab_obs_spoof'", "]", "\n", "\n", "if", "n_agents", "<", "2", ":", "\n", "        ", "env", "=", "SpoofEntityWrapper", "(", "env", ",", "1", ",", "[", "'agent_qpos_qvel'", ",", "'hider'", ",", "'prep_obs'", "]", ",", "[", "'mask_aa_obs'", "]", ")", "\n", "\n", "", "env", "=", "LockAllWrapper", "(", "env", ",", "remove_object_specific_lock", "=", "True", ")", "\n", "if", "not", "grab_out_of_vision", "and", "grab_box", ":", "\n", "# Can only pull if in vision", "\n", "        ", "mask_keys", "=", "[", "'mask_ab_obs'", "]", "+", "(", "[", "'mask_ar_obs'", "]", "if", "n_ramps", ">", "0", "else", "[", "]", ")", "\n", "env", "=", "MaskActionWrapper", "(", "env", ",", "action_key", "=", "'action_pull'", ",", "mask_keys", "=", "mask_keys", ")", "\n", "", "if", "not", "grab_selective", "and", "grab_box", ":", "\n", "        ", "env", "=", "GrabClosestWrapper", "(", "env", ")", "\n", "", "env", "=", "DiscardMujocoExceptionEpisodes", "(", "env", ")", "\n", "env", "=", "ConcatenateObsWrapper", "(", "env", ",", "{", "'agent_qpos_qvel'", ":", "[", "'agent_qpos_qvel'", ",", "'hider'", ",", "'prep_obs'", "]", ",", "\n", "'box_obs'", ":", "[", "'box_obs'", ",", "'you_lock'", ",", "'team_lock'", ",", "'obj_lock'", "]", ",", "\n", "'ramp_obs'", ":", "[", "'ramp_obs'", ",", "'ramp_you_lock'", ",", "'ramp_team_lock'", ",", "\n", "'ramp_obj_lock'", "]", "}", ")", "\n", "env", "=", "SelectKeysWrapper", "(", "env", ",", "keys_self", "=", "keys_self", ",", "\n", "keys_other", "=", "keys_external", "+", "keys_mask_self", "+", "keys_mask_external", ")", "\n", "\n", "return", "env", "\n", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.shelter_construction.ShelterRewardWrapper.__init__": [[36, 55], ["gym.Wrapper.__init__", "range", "numpy.array", "shelter_construction.ShelterRewardWrapper.ray_start_points.extend"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "env", ",", "num_rays_per_side", "=", "30", ",", "reward_scale", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "ray_start_points", "=", "[", "]", "\n", "\n", "grid_cell_size", "=", "self", ".", "unwrapped", ".", "floor_size", "/", "self", ".", "unwrapped", ".", "grid_size", "\n", "# start points for the rays should not be exactly on the edge of the floor,", "\n", "# so that they do not hit the outside walls", "\n", "sp_min_xy", "=", "1.01", "*", "grid_cell_size", "\n", "sp_max_xy", "=", "self", ".", "unwrapped", ".", "floor_size", "-", "(", "1.01", "*", "grid_cell_size", ")", "\n", "for", "i", "in", "range", "(", "num_rays_per_side", ")", ":", "\n", "            ", "sp_offset", "=", "i", "/", "num_rays_per_side", "*", "(", "sp_max_xy", "-", "sp_min_xy", ")", "\n", "new_start_points", "=", "[", "(", "sp_min_xy", "+", "sp_offset", ",", "sp_min_xy", ",", "0", ")", ",", "\n", "(", "sp_max_xy", ",", "sp_min_xy", "+", "sp_offset", ",", "0", ")", ",", "\n", "(", "sp_max_xy", "-", "sp_offset", ",", "sp_max_xy", ",", "0", ")", ",", "\n", "(", "sp_min_xy", ",", "sp_max_xy", "-", "sp_offset", ",", "0", ")", "]", "\n", "self", ".", "ray_start_points", ".", "extend", "(", "new_start_points", ")", "\n", "\n", "", "self", ".", "ray_start_points", "=", "np", ".", "array", "(", "self", ".", "ray_start_points", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.shelter_construction.ShelterRewardWrapper.reset": [[56, 60], ["shelter_construction.ShelterRewardWrapper.env.reset"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "self", ".", "sim", "=", "self", ".", "unwrapped", ".", "sim", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.shelter_construction.ShelterRewardWrapper.step": [[61, 72], ["shelter_construction.ShelterRewardWrapper.env.step", "numpy.zeros", "mujoco_worldgen.util.geometry.raycast"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "target_geom", "=", "obs", "[", "'static_cylinder_geom_idxs'", "]", "[", "0", ",", "0", "]", "\n", "rew", "=", "rew", "+", "np", ".", "zeros", "(", "(", "self", ".", "unwrapped", ".", "n_agents", ",", "1", ")", ")", "\n", "for", "pt", "in", "self", ".", "ray_start_points", ":", "\n", "            ", "_", ",", "collision_geom", "=", "raycast", "(", "self", ".", "sim", ",", "pt1", "=", "pt", ",", "geom2_id", "=", "target_geom", ")", "\n", "if", "collision_geom", "==", "target_geom", ":", "\n", "                ", "rew", "-=", "1", "\n", "\n", "", "", "rew", "*=", "self", ".", "reward_scale", "\n", "return", "obs", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.shelter_construction.make_env": [[74, 187], ["mae_envs.envs.base.Base", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.wrappers.manipulation.GrabClosestWrapper.reset", "mae_envs.wrappers.util.AddConstantObservationsWrapper", "list", "shelter_construction.ShelterRewardWrapper", "mae_envs.wrappers.multi_agent.SplitMultiAgentActions", "mae_envs.wrappers.team.TeamMembership", "mae_envs.wrappers.line_of_sight.AgentAgentObsMask2D", "mae_envs.wrappers.util.DiscretizeActionWrapper", "mae_envs.wrappers.multi_agent.SplitObservations", "mae_envs.wrappers.util.SpoofEntityWrapper", "mae_envs.wrappers.manipulation.LockAllWrapper", "mae_envs.wrappers.util.DiscardMujocoExceptionEpisodes", "mae_envs.wrappers.util.ConcatenateObsWrapper", "mae_envs.wrappers.multi_agent.SelectKeysWrapper", "mae_envs.modules.walls.WallScenarios", "mae_envs.modules.objects.Cylinders", "mae_envs.modules.agents.Agents", "numpy.max", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.modules.agents.AgentManipulation", "mae_envs.wrappers.manipulation.GrabClosestWrapper.add_module", "mae_envs.modules.world.WorldConstants", "numpy.zeros", "numpy.max", "mae_envs.wrappers.line_of_sight.AgentGeomObsMask2D", "keys_mask_external.append", "mae_envs.wrappers.manipulation.LockObjWrapper", "mae_envs.wrappers.manipulation.GrabObjWrapper", "mae_envs.wrappers.lidar.Lidar", "mae_envs.wrappers.util.SpoofEntityWrapper", "mae_envs.wrappers.util.MaskActionWrapper", "mae_envs.wrappers.manipulation.GrabClosestWrapper", "mae_envs.modules.util.uniform_placement_middle", "mae_envs.modules.objects.Boxes", "mae_envs.modules.objects.LidarSites", "mae_envs.modules.world.FloorAttributes", "numpy.max", "numpy.max", "numpy.arange", "range", "range", "numpy.array"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.uniform_placement_middle"], ["", "", "def", "make_env", "(", "n_substeps", "=", "15", ",", "horizon", "=", "80", ",", "deterministic_mode", "=", "False", ",", "\n", "floor_size", "=", "6.0", ",", "grid_size", "=", "30", ",", "\n", "n_agents", "=", "1", ",", "\n", "objective_diameter", "=", "[", "1", ",", "1", "]", ",", "objective_placement", "=", "'center'", ",", "\n", "num_rays_per_side", "=", "25", ",", "shelter_reward_scale", "=", "1", ",", "\n", "n_boxes", "=", "2", ",", "n_elongated_boxes", "=", "0", ",", "\n", "box_size", "=", "0.5", ",", "box_only_z_rot", "=", "False", ",", "\n", "lock_box", "=", "True", ",", "grab_box", "=", "True", ",", "grab_selective", "=", "False", ",", "lock_grab_radius", "=", "0.25", ",", "\n", "lock_type", "=", "'any_lock_specific'", ",", "grab_exclusive", "=", "False", ",", "\n", "grab_out_of_vision", "=", "False", ",", "lock_out_of_vision", "=", "True", ",", "\n", "box_floor_friction", "=", "0.2", ",", "other_friction", "=", "0.01", ",", "gravity", "=", "[", "0", ",", "0", ",", "-", "50", "]", ",", "\n", "action_lims", "=", "(", "-", "0.9", ",", "0.9", ")", ",", "polar_obs", "=", "True", ",", "\n", "n_lidar_per_agent", "=", "0", ",", "visualize_lidar", "=", "False", ",", "compress_lidar_scale", "=", "None", ",", "\n", "boxid_obs", "=", "True", ",", "boxsize_obs", "=", "True", ",", "team_size_obs", "=", "False", ",", "additional_obs", "=", "{", "}", ")", ":", "\n", "\n", "    ", "grab_radius_multiplier", "=", "lock_grab_radius", "/", "box_size", "\n", "lock_radius_multiplier", "=", "lock_grab_radius", "/", "box_size", "\n", "\n", "env", "=", "Base", "(", "n_agents", "=", "n_agents", ",", "n_substeps", "=", "n_substeps", ",", "horizon", "=", "horizon", ",", "\n", "floor_size", "=", "floor_size", ",", "grid_size", "=", "grid_size", ",", "\n", "action_lims", "=", "action_lims", ",", "deterministic_mode", "=", "deterministic_mode", ")", "\n", "\n", "env", ".", "add_module", "(", "WallScenarios", "(", "grid_size", "=", "grid_size", ",", "door_size", "=", "2", ",", "scenario", "=", "'empty'", ",", "\n", "friction", "=", "other_friction", ")", ")", "\n", "\n", "if", "objective_placement", "==", "'center'", ":", "\n", "        ", "objective_placement_fn", "=", "center_placement", "\n", "", "elif", "objective_placement", "==", "'uniform_away_from_walls'", ":", "\n", "        ", "objective_placement_fn", "=", "uniform_placement_middle", "(", "0.7", ")", "\n", "\n", "", "env", ".", "add_module", "(", "Cylinders", "(", "1", ",", "diameter", "=", "objective_diameter", ",", "height", "=", "box_size", ",", "\n", "make_static", "=", "True", ",", "placement_fn", "=", "objective_placement_fn", ")", ")", "\n", "\n", "env", ".", "add_module", "(", "Agents", "(", "n_agents", ",", "\n", "placement_fn", "=", "uniform_placement", ",", "\n", "color", "=", "[", "np", ".", "array", "(", "(", "66.", ",", "235.", ",", "244.", ",", "255.", ")", ")", "/", "255", "]", "*", "n_agents", ",", "\n", "friction", "=", "other_friction", ",", "\n", "polar_obs", "=", "polar_obs", ")", ")", "\n", "if", "np", ".", "max", "(", "n_boxes", ")", ">", "0", ":", "\n", "        ", "env", ".", "add_module", "(", "Boxes", "(", "n_boxes", "=", "n_boxes", ",", "placement_fn", "=", "uniform_placement", ",", "\n", "friction", "=", "box_floor_friction", ",", "polar_obs", "=", "polar_obs", ",", "\n", "n_elongated_boxes", "=", "n_elongated_boxes", ",", "\n", "boxid_obs", "=", "boxid_obs", ",", "boxsize_obs", "=", "boxsize_obs", ",", "\n", "box_size", "=", "box_size", ",", "\n", "box_only_z_rot", "=", "box_only_z_rot", ")", ")", "\n", "", "if", "n_lidar_per_agent", ">", "0", "and", "visualize_lidar", ":", "\n", "        ", "env", ".", "add_module", "(", "LidarSites", "(", "n_agents", "=", "n_agents", ",", "n_lidar_per_agent", "=", "n_lidar_per_agent", ")", ")", "\n", "\n", "", "env", ".", "add_module", "(", "AgentManipulation", "(", ")", ")", "\n", "if", "box_floor_friction", "is", "not", "None", ":", "\n", "        ", "env", ".", "add_module", "(", "FloorAttributes", "(", "friction", "=", "box_floor_friction", ")", ")", "\n", "", "env", ".", "add_module", "(", "WorldConstants", "(", "gravity", "=", "gravity", ")", ")", "\n", "env", ".", "reset", "(", ")", "\n", "keys_self", "=", "[", "'agent_qpos_qvel'", ",", "'hider'", ",", "'prep_obs'", "]", "\n", "keys_mask_self", "=", "[", "'mask_aa_obs'", "]", "\n", "keys_external", "=", "[", "'agent_qpos_qvel'", "]", "\n", "keys_copy", "=", "[", "'you_lock'", ",", "'team_lock'", ",", "'ramp_you_lock'", ",", "'ramp_team_lock'", "]", "\n", "keys_mask_external", "=", "[", "]", "\n", "\n", "env", "=", "AddConstantObservationsWrapper", "(", "env", ",", "new_obs", "=", "additional_obs", ")", "\n", "keys_external", "+=", "list", "(", "additional_obs", ")", "\n", "keys_mask_external", "+=", "[", "ob", "for", "ob", "in", "additional_obs", "if", "'mask'", "in", "ob", "]", "\n", "\n", "env", "=", "ShelterRewardWrapper", "(", "env", ",", "num_rays_per_side", "=", "num_rays_per_side", ",", "\n", "reward_scale", "=", "shelter_reward_scale", ")", "\n", "env", "=", "SplitMultiAgentActions", "(", "env", ")", "\n", "\n", "if", "team_size_obs", ":", "\n", "        ", "keys_self", "+=", "[", "'team_size'", "]", "\n", "", "env", "=", "TeamMembership", "(", "env", ",", "np", ".", "zeros", "(", "(", "n_agents", ",", ")", ")", ")", "\n", "env", "=", "AgentAgentObsMask2D", "(", "env", ")", "\n", "env", "=", "DiscretizeActionWrapper", "(", "env", ",", "'action_movement'", ")", "\n", "if", "np", ".", "max", "(", "n_boxes", ")", ">", "0", ":", "\n", "        ", "env", "=", "AgentGeomObsMask2D", "(", "env", ",", "pos_obs_key", "=", "'box_pos'", ",", "mask_obs_key", "=", "'mask_ab_obs'", ",", "\n", "geom_idxs_obs_key", "=", "'box_geom_idxs'", ")", "\n", "keys_external", "+=", "[", "'mask_ab_obs'", ",", "'box_obs'", "]", "\n", "keys_mask_external", ".", "append", "(", "'mask_ab_obs'", ")", "\n", "", "if", "lock_box", "and", "np", ".", "max", "(", "n_boxes", ")", ">", "0", ":", "\n", "        ", "env", "=", "LockObjWrapper", "(", "env", ",", "body_names", "=", "[", "f'moveable_box{i}'", "for", "i", "in", "range", "(", "n_boxes", ")", "]", ",", "\n", "agent_idx_allowed_to_lock", "=", "np", ".", "arange", "(", "n_agents", ")", ",", "\n", "lock_type", "=", "lock_type", ",", "\n", "radius_multiplier", "=", "lock_radius_multiplier", ",", "\n", "obj_in_game_metadata_keys", "=", "[", "\"curr_n_boxes\"", "]", ",", "\n", "agent_allowed_to_lock_keys", "=", "None", "if", "lock_out_of_vision", "else", "[", "\"mask_ab_obs\"", "]", ")", "\n", "\n", "", "if", "grab_box", "and", "np", ".", "max", "(", "n_boxes", ")", ">", "0", ":", "\n", "        ", "env", "=", "GrabObjWrapper", "(", "env", ",", "[", "f'moveable_box{i}'", "for", "i", "in", "range", "(", "n_boxes", ")", "]", ",", "\n", "radius_multiplier", "=", "grab_radius_multiplier", ",", "\n", "grab_exclusive", "=", "grab_exclusive", ",", "\n", "obj_in_game_metadata_keys", "=", "[", "'curr_n_boxes'", "]", ")", "\n", "\n", "", "if", "n_lidar_per_agent", ">", "0", ":", "\n", "        ", "env", "=", "Lidar", "(", "env", ",", "n_lidar_per_agent", "=", "n_lidar_per_agent", ",", "visualize_lidar", "=", "visualize_lidar", ",", "\n", "compress_lidar_scale", "=", "compress_lidar_scale", ")", "\n", "keys_copy", "+=", "[", "'lidar'", "]", "\n", "keys_external", "+=", "[", "'lidar'", "]", "\n", "\n", "", "env", "=", "SplitObservations", "(", "env", ",", "keys_self", "+", "keys_mask_self", ",", "keys_copy", "=", "keys_copy", ")", "\n", "if", "n_agents", "==", "1", ":", "\n", "        ", "env", "=", "SpoofEntityWrapper", "(", "env", ",", "2", ",", "[", "'agent_qpos_qvel'", ",", "'hider'", ",", "'prep_obs'", "]", ",", "[", "'mask_aa_obs'", "]", ")", "\n", "", "env", "=", "SpoofEntityWrapper", "(", "env", ",", "n_boxes", ",", "[", "'box_obs'", ",", "'you_lock'", ",", "'team_lock'", ",", "'obj_lock'", "]", ",", "[", "'mask_ab_obs'", "]", ")", "\n", "keys_mask_external", "+=", "[", "'mask_ab_obs_spoof'", "]", "\n", "env", "=", "LockAllWrapper", "(", "env", ",", "remove_object_specific_lock", "=", "True", ")", "\n", "if", "not", "grab_out_of_vision", "and", "grab_box", ":", "\n", "        ", "env", "=", "MaskActionWrapper", "(", "env", ",", "'action_pull'", ",", "[", "'mask_ab_obs'", "]", ")", "# Can only pull if in vision", "\n", "", "if", "not", "grab_selective", "and", "grab_box", ":", "\n", "        ", "env", "=", "GrabClosestWrapper", "(", "env", ")", "\n", "", "env", "=", "DiscardMujocoExceptionEpisodes", "(", "env", ")", "\n", "env", "=", "ConcatenateObsWrapper", "(", "env", ",", "{", "'agent_qpos_qvel'", ":", "[", "'agent_qpos_qvel'", ",", "'hider'", ",", "'prep_obs'", "]", ",", "\n", "'box_obs'", ":", "[", "'box_obs'", ",", "'you_lock'", ",", "'team_lock'", ",", "'obj_lock'", "]", "}", ")", "\n", "env", "=", "SelectKeysWrapper", "(", "env", ",", "keys_self", "=", "keys_self", ",", "\n", "keys_other", "=", "keys_external", "+", "keys_mask_self", "+", "keys_mask_external", ")", "\n", "return", "env", "\n", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.env_viewer.EnvViewer.__init__": [[10, 24], ["env_viewer.EnvViewer.env.seed", "mujoco_py.MjViewer.__init__", "list", "len", "env_viewer.EnvViewer.num_actions", "env_viewer.EnvViewer.zero_action", "env_viewer.EnvViewer.env_reset", "env_viewer.EnvViewer.env.action_space.spaces.keys"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.env_viewer.EnvViewer.num_actions", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.zero_action", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.env_viewer.EnvViewer.env_reset"], ["    ", "def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "self", ".", "env", "=", "env", "\n", "self", ".", "elapsed", "=", "[", "0", "]", "\n", "self", ".", "seed", "=", "self", ".", "env", ".", "seed", "(", ")", "\n", "super", "(", ")", ".", "__init__", "(", "self", ".", "env", ".", "unwrapped", ".", "sim", ")", "\n", "self", ".", "n_agents", "=", "self", ".", "env", ".", "metadata", "[", "'n_actors'", "]", "\n", "self", ".", "action_types", "=", "list", "(", "self", ".", "env", ".", "action_space", ".", "spaces", ".", "keys", "(", ")", ")", "\n", "self", ".", "num_action_types", "=", "len", "(", "self", ".", "env", ".", "action_space", ".", "spaces", ")", "\n", "self", ".", "num_action", "=", "self", ".", "num_actions", "(", "self", ".", "env", ".", "action_space", ")", "\n", "self", ".", "agent_mod_index", "=", "0", "\n", "self", ".", "action_mod_index", "=", "0", "\n", "self", ".", "action_type_mod_index", "=", "0", "\n", "self", ".", "action", "=", "self", ".", "zero_action", "(", "self", ".", "env", ".", "action_space", ")", "\n", "self", ".", "env_reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.env_viewer.EnvViewer.num_actions": [[25, 39], ["ac_space.spaces.items", "isinstance", "n_actions.append", "isinstance", "n_actions.append", "isinstance", "n_actions.append", "NotImplementedError"], "methods", ["None"], ["", "def", "num_actions", "(", "self", ",", "ac_space", ")", ":", "\n", "        ", "n_actions", "=", "[", "]", "\n", "for", "k", ",", "tuple_space", "in", "ac_space", ".", "spaces", ".", "items", "(", ")", ":", "\n", "            ", "s", "=", "tuple_space", ".", "spaces", "[", "0", "]", "\n", "if", "isinstance", "(", "s", ",", "Box", ")", ":", "\n", "                ", "n_actions", ".", "append", "(", "s", ".", "shape", "[", "0", "]", ")", "\n", "", "elif", "isinstance", "(", "s", ",", "Discrete", ")", ":", "\n", "                ", "n_actions", ".", "append", "(", "1", ")", "\n", "", "elif", "isinstance", "(", "s", ",", "MultiDiscrete", ")", ":", "\n", "                ", "n_actions", ".", "append", "(", "s", ".", "nvec", ".", "shape", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "f\"not NotImplementedError\"", ")", "\n", "\n", "", "", "return", "n_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.env_viewer.EnvViewer.zero_action": [[40, 53], ["ac_space.spaces.items", "isinstance", "numpy.zeros_like", "isinstance", "space.sample", "isinstance", "numpy.ones_like", "NotImplementedError", "space.sample", "numpy.ones_like", "space.sample"], "methods", ["None"], ["", "def", "zero_action", "(", "self", ",", "ac_space", ")", ":", "\n", "        ", "ac", "=", "{", "}", "\n", "for", "k", ",", "space", "in", "ac_space", ".", "spaces", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "space", ".", "spaces", "[", "0", "]", ",", "Box", ")", ":", "\n", "                ", "ac", "[", "k", "]", "=", "np", ".", "zeros_like", "(", "space", ".", "sample", "(", ")", ")", "\n", "", "elif", "isinstance", "(", "space", ".", "spaces", "[", "0", "]", ",", "Discrete", ")", ":", "\n", "                ", "ac", "[", "k", "]", "=", "np", ".", "ones_like", "(", "space", ".", "sample", "(", ")", ")", "*", "(", "space", ".", "spaces", "[", "0", "]", ".", "n", "//", "2", ")", "\n", "", "elif", "isinstance", "(", "space", ".", "spaces", "[", "0", "]", ",", "MultiDiscrete", ")", ":", "\n", "                ", "ac", "[", "k", "]", "=", "np", ".", "ones_like", "(", "space", ".", "sample", "(", ")", ",", "dtype", "=", "int", ")", "*", "(", "space", ".", "spaces", "[", "0", "]", ".", "nvec", "//", "2", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\"MultiDiscrete not NotImplementedError\"", ")", "\n", "# return action_space.nvec // 2  # assume middle element is \"no action\" action", "\n", "", "", "return", "ac", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.env_viewer.EnvViewer.env_reset": [[54, 62], ["time.time", "env_viewer.EnvViewer.env.seed", "env_viewer.EnvViewer.env.reset", "env_viewer.EnvViewer.elapsed.append", "env_viewer.EnvViewer.update_sim", "time.time"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "env_reset", "(", "self", ")", ":", "\n", "        ", "start", "=", "time", ".", "time", "(", ")", "\n", "# get the seed before calling env.reset(), so we display the one", "\n", "# that was used for the reset.", "\n", "self", ".", "seed", "=", "self", ".", "env", ".", "seed", "(", ")", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "self", ".", "elapsed", ".", "append", "(", "time", ".", "time", "(", ")", "-", "start", ")", "\n", "self", ".", "update_sim", "(", "self", ".", "env", ".", "unwrapped", ".", "sim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.env_viewer.EnvViewer.key_callback": [[63, 119], ["super().key_callback", "env_viewer.EnvViewer.env.close", "isinstance", "env_viewer.EnvViewer.env.seed", "env_viewer.EnvViewer.env_reset", "env_viewer.EnvViewer.zero_action", "isinstance", "isinstance", "env_viewer.EnvViewer.env.seed", "env_viewer.EnvViewer.env_reset", "env_viewer.EnvViewer.zero_action", "isinstance", "isinstance", "max", "isinstance"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.policy_viewer.PolicyViewer.key_callback", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.env_viewer.EnvViewer.env_reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.zero_action", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.env_viewer.EnvViewer.env_reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.zero_action"], ["", "def", "key_callback", "(", "self", ",", "window", ",", "key", ",", "scancode", ",", "action", ",", "mods", ")", ":", "\n", "# Trigger on keyup only:", "\n", "        ", "if", "action", "!=", "glfw", ".", "RELEASE", ":", "\n", "            ", "return", "\n", "", "if", "key", "==", "glfw", ".", "KEY_ESCAPE", ":", "\n", "            ", "self", ".", "env", ".", "close", "(", ")", "\n", "\n", "# Increment experiment seed", "\n", "", "elif", "key", "==", "glfw", ".", "KEY_N", ":", "\n", "            ", "self", ".", "seed", "[", "0", "]", "+=", "1", "\n", "self", ".", "env", ".", "seed", "(", "self", ".", "seed", ")", "\n", "self", ".", "env_reset", "(", ")", "\n", "self", ".", "action", "=", "self", ".", "zero_action", "(", "self", ".", "env", ".", "action_space", ")", "\n", "# Decrement experiment trial", "\n", "", "elif", "key", "==", "glfw", ".", "KEY_P", ":", "\n", "            ", "self", ".", "seed", "=", "[", "max", "(", "self", ".", "seed", "[", "0", "]", "-", "1", ",", "0", ")", "]", "\n", "self", ".", "env", ".", "seed", "(", "self", ".", "seed", ")", "\n", "self", ".", "env_reset", "(", ")", "\n", "self", ".", "action", "=", "self", ".", "zero_action", "(", "self", ".", "env", ".", "action_space", ")", "\n", "", "current_action_space", "=", "self", ".", "env", ".", "action_space", ".", "spaces", "[", "self", ".", "action_types", "[", "self", ".", "action_type_mod_index", "]", "]", ".", "spaces", "[", "0", "]", "\n", "if", "key", "==", "glfw", ".", "KEY_A", ":", "\n", "            ", "if", "isinstance", "(", "current_action_space", ",", "Box", ")", ":", "\n", "                ", "self", ".", "action", "[", "self", ".", "action_types", "[", "self", ".", "action_type_mod_index", "]", "]", "[", "self", ".", "agent_mod_index", "]", "[", "self", ".", "action_mod_index", "]", "-=", "0.05", "\n", "", "elif", "isinstance", "(", "current_action_space", ",", "Discrete", ")", ":", "\n", "                ", "self", ".", "action", "[", "self", ".", "action_types", "[", "self", ".", "action_type_mod_index", "]", "]", "[", "self", ".", "agent_mod_index", "]", "=", "(", "self", ".", "action", "[", "self", ".", "action_types", "[", "self", ".", "action_type_mod_index", "]", "]", "[", "self", ".", "agent_mod_index", "]", "-", "1", ")", "%", "current_action_space", ".", "n", "\n", "", "elif", "isinstance", "(", "current_action_space", ",", "MultiDiscrete", ")", ":", "\n", "                ", "self", ".", "action", "[", "self", ".", "action_types", "[", "self", ".", "action_type_mod_index", "]", "]", "[", "self", ".", "agent_mod_index", "]", "[", "self", ".", "action_mod_index", "]", "=", "(", "self", ".", "action", "[", "self", ".", "action_types", "[", "self", ".", "action_type_mod_index", "]", "]", "[", "self", ".", "agent_mod_index", "]", "[", "self", ".", "action_mod_index", "]", "-", "1", ")", "%", "current_action_space", ".", "nvec", "[", "self", ".", "action_mod_index", "]", "\n", "", "", "elif", "key", "==", "glfw", ".", "KEY_Z", ":", "\n", "            ", "if", "isinstance", "(", "current_action_space", ",", "Box", ")", ":", "\n", "                ", "self", ".", "action", "[", "self", ".", "action_types", "[", "self", ".", "action_type_mod_index", "]", "]", "[", "self", ".", "agent_mod_index", "]", "[", "self", ".", "action_mod_index", "]", "+=", "0.05", "\n", "", "elif", "isinstance", "(", "current_action_space", ",", "Discrete", ")", ":", "\n", "                ", "self", ".", "action", "[", "self", ".", "action_types", "[", "self", ".", "action_type_mod_index", "]", "]", "[", "self", ".", "agent_mod_index", "]", "=", "(", "self", ".", "action", "[", "self", ".", "action_types", "[", "self", ".", "action_type_mod_index", "]", "]", "[", "self", ".", "agent_mod_index", "]", "+", "1", ")", "%", "current_action_space", ".", "n", "\n", "", "elif", "isinstance", "(", "current_action_space", ",", "MultiDiscrete", ")", ":", "\n", "                ", "self", ".", "action", "[", "self", ".", "action_types", "[", "self", ".", "action_type_mod_index", "]", "]", "[", "self", ".", "agent_mod_index", "]", "[", "self", ".", "action_mod_index", "]", "=", "(", "self", ".", "action", "[", "self", ".", "action_types", "[", "self", ".", "action_type_mod_index", "]", "]", "[", "self", ".", "agent_mod_index", "]", "[", "self", ".", "action_mod_index", "]", "+", "1", ")", "%", "current_action_space", ".", "nvec", "[", "self", ".", "action_mod_index", "]", "\n", "", "", "elif", "key", "==", "glfw", ".", "KEY_K", ":", "\n", "            ", "self", ".", "action_mod_index", "=", "(", "self", ".", "action_mod_index", "+", "1", ")", "%", "self", ".", "num_action", "[", "self", ".", "action_type_mod_index", "]", "\n", "", "elif", "key", "==", "glfw", ".", "KEY_J", ":", "\n", "            ", "self", ".", "action_mod_index", "=", "(", "self", ".", "action_mod_index", "-", "1", ")", "%", "self", ".", "num_action", "[", "self", ".", "action_type_mod_index", "]", "\n", "", "elif", "key", "==", "glfw", ".", "KEY_Y", ":", "\n", "            ", "self", ".", "agent_mod_index", "=", "(", "self", ".", "agent_mod_index", "+", "1", ")", "%", "self", ".", "n_agents", "\n", "", "elif", "key", "==", "glfw", ".", "KEY_U", ":", "\n", "            ", "self", ".", "agent_mod_index", "=", "(", "self", ".", "agent_mod_index", "-", "1", ")", "%", "self", ".", "n_agents", "\n", "", "elif", "key", "==", "glfw", ".", "KEY_G", ":", "\n", "            ", "self", ".", "action_type_mod_index", "=", "(", "self", ".", "action_type_mod_index", "+", "1", ")", "%", "self", ".", "num_action_types", "\n", "self", ".", "action_mod_index", "=", "0", "\n", "", "elif", "key", "==", "glfw", ".", "KEY_B", ":", "\n", "            ", "self", ".", "action_type_mod_index", "=", "(", "self", ".", "action_type_mod_index", "-", "1", ")", "%", "self", ".", "num_action_types", "\n", "self", ".", "action_mod_index", "=", "0", "\n", "\n", "", "super", "(", ")", ".", "key_callback", "(", "window", ",", "key", ",", "scancode", ",", "action", ",", "mods", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.env_viewer.EnvViewer.run": [[120, 135], ["env_viewer.EnvViewer.env.step", "env_info.get", "env_viewer.EnvViewer.add_overlay", "env_viewer.EnvViewer.add_overlay", "env_viewer.EnvViewer.add_overlay", "env_viewer.EnvViewer.add_overlay", "env_viewer.EnvViewer.add_overlay", "env_viewer.EnvViewer.add_overlay", "env_viewer.EnvViewer.add_overlay", "env_viewer.EnvViewer.render", "env_viewer.EnvViewer.env.reset", "str", "sum", "len"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "run", "(", "self", ",", "once", "=", "False", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "_", ",", "_", ",", "_", ",", "env_info", "=", "self", ".", "env", ".", "step", "(", "self", ".", "action", ")", "\n", "if", "env_info", ".", "get", "(", "'discard_episode'", ",", "False", ")", ":", "\n", "                ", "self", ".", "env", ".", "reset", "(", ")", "\n", "", "self", ".", "add_overlay", "(", "const", ".", "GRID_TOPRIGHT", ",", "\"Reset env; (current seed: {})\"", ".", "format", "(", "self", ".", "seed", ")", ",", "\"N - next / P - previous \"", ")", "\n", "self", ".", "add_overlay", "(", "const", ".", "GRID_TOPRIGHT", ",", "\"Apply action\"", ",", "\"A (-0.05) / Z (+0.05)\"", ")", "\n", "self", ".", "add_overlay", "(", "const", ".", "GRID_TOPRIGHT", ",", "\"on agent index %d out %d\"", "%", "(", "self", ".", "agent_mod_index", ",", "self", ".", "n_agents", ")", ",", "\"Y / U\"", ")", "\n", "self", ".", "add_overlay", "(", "const", ".", "GRID_TOPRIGHT", ",", "f\"on action type {self.action_types[self.action_type_mod_index]}\"", ",", "\"G / B\"", ")", "\n", "self", ".", "add_overlay", "(", "const", ".", "GRID_TOPRIGHT", ",", "\"on action index %d out %d\"", "%", "(", "self", ".", "action_mod_index", ",", "self", ".", "num_action", "[", "self", ".", "action_type_mod_index", "]", ")", ",", "\"J / K\"", ")", "\n", "self", ".", "add_overlay", "(", "const", ".", "GRID_BOTTOMRIGHT", ",", "\"Reset took\"", ",", "\"%.2f sec.\"", "%", "(", "sum", "(", "self", ".", "elapsed", ")", "/", "len", "(", "self", ".", "elapsed", ")", ")", ")", "\n", "self", ".", "add_overlay", "(", "const", ".", "GRID_BOTTOMRIGHT", ",", "\"Action\"", ",", "str", "(", "self", ".", "action", ")", ")", "\n", "self", ".", "render", "(", ")", "\n", "if", "once", ":", "\n", "                ", "return", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.policy_viewer.PolicyViewer.__init__": [[30, 49], ["env.reset", "hasattr", "mujoco_py.MjViewer.__init__", "env.seed", "policy.reset", "env.reset_goal", "policy_viewer.PolicyViewer.env.render", "env.seed", "len"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "env", ",", "policies", ",", "display_window", "=", "True", ",", "seed", "=", "None", ",", "duration", "=", "None", ")", ":", "\n", "        ", "if", "seed", "is", "None", ":", "\n", "            ", "self", ".", "seed", "=", "env", ".", "seed", "(", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "seed", "=", "seed", "\n", "env", ".", "seed", "(", "seed", ")", "\n", "", "self", ".", "total_rew", "=", "0.0", "\n", "self", ".", "ob", "=", "env", ".", "reset", "(", ")", "\n", "for", "policy", "in", "self", ".", "policies", ":", "\n", "            ", "policy", ".", "reset", "(", ")", "\n", "", "assert", "env", ".", "metadata", "[", "'n_actors'", "]", "%", "len", "(", "policies", ")", "==", "0", "\n", "if", "hasattr", "(", "env", ",", "\"reset_goal\"", ")", ":", "\n", "            ", "self", ".", "goal", "=", "env", ".", "reset_goal", "(", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "self", ".", "env", ".", "unwrapped", ".", "sim", ")", "\n", "# TO DO: remove circular dependency on viewer object. It looks fishy.", "\n", "self", ".", "env", ".", "unwrapped", ".", "viewer", "=", "self", "\n", "if", "self", ".", "render", "and", "self", ".", "display_window", ":", "\n", "            ", "self", ".", "env", ".", "render", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.policy_viewer.PolicyViewer.key_callback": [[50, 69], ["super().key_callback", "policy_viewer.PolicyViewer.reset_increment", "print", "max", "policy_viewer.PolicyViewer.env.seed", "policy_viewer.PolicyViewer.env.reset", "hasattr", "policy_viewer.PolicyViewer.update_sim", "policy.reset", "policy_viewer.PolicyViewer.env.reset_goal"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.policy_viewer.PolicyViewer.key_callback", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.policy_viewer.PolicyViewer.reset_increment", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "", "def", "key_callback", "(", "self", ",", "window", ",", "key", ",", "scancode", ",", "action", ",", "mods", ")", ":", "\n", "        ", "super", "(", ")", ".", "key_callback", "(", "window", ",", "key", ",", "scancode", ",", "action", ",", "mods", ")", "\n", "# Trigger on keyup only:", "\n", "if", "action", "!=", "glfw", ".", "RELEASE", ":", "\n", "            ", "return", "\n", "# Increment experiment seed", "\n", "", "if", "key", "==", "glfw", ".", "KEY_N", ":", "\n", "            ", "self", ".", "reset_increment", "(", ")", "\n", "# Decrement experiment trial", "\n", "", "elif", "key", "==", "glfw", ".", "KEY_P", ":", "\n", "            ", "print", "(", "\"Pressed P\"", ")", "\n", "self", ".", "seed", "=", "max", "(", "self", ".", "seed", "-", "1", ",", "0", ")", "\n", "self", ".", "env", ".", "seed", "(", "self", ".", "seed", ")", "\n", "self", ".", "ob", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "for", "policy", "in", "self", ".", "policies", ":", "\n", "                ", "policy", ".", "reset", "(", ")", "\n", "", "if", "hasattr", "(", "self", ".", "env", ",", "\"reset_goal\"", ")", ":", "\n", "                ", "self", ".", "goal", "=", "self", ".", "env", ".", "reset_goal", "(", ")", "\n", "", "self", ".", "update_sim", "(", "self", ".", "env", ".", "unwrapped", ".", "sim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.policy_viewer.PolicyViewer.run": [[70, 103], ["policy_viewer.PolicyViewer.env.step", "time.time", "time.time", "len", "policy_viewer.PolicyViewer.policies[].act", "policy_viewer.splitobs", "numpy.split", "enumerate", "ma_policy.util.listdict2dictnp", "env_info.get", "policy_viewer.PolicyViewer.reset_increment", "policy_viewer.PolicyViewer.add_overlay", "policy_viewer.PolicyViewer.add_overlay", "hasattr", "policy_viewer.PolicyViewer.env.render", "numpy.arange", "len", "ma_policy.util.listdict2dictnp", "policy.act", "actions.append", "str", "policy_viewer.PolicyViewer.env.unwrapped.viewer_stats.items", "len", "operator.itemgetter", "policy_viewer.PolicyViewer.add_overlay", "str"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.act", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.policy_viewer.splitobs", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.listdict2dictnp", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.policy_viewer.PolicyViewer.reset_increment", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.listdict2dictnp", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.act"], ["", "", "def", "run", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "duration", "is", "not", "None", ":", "\n", "            ", "self", ".", "end_time", "=", "time", ".", "time", "(", ")", "+", "self", ".", "duration", "\n", "", "self", ".", "total_rew_avg", "=", "0.0", "\n", "self", ".", "n_episodes", "=", "0", "\n", "while", "self", ".", "duration", "is", "None", "or", "time", ".", "time", "(", ")", "<", "self", ".", "end_time", ":", "\n", "            ", "if", "len", "(", "self", ".", "policies", ")", "==", "1", ":", "\n", "                ", "action", ",", "_", "=", "self", ".", "policies", "[", "0", "]", ".", "act", "(", "self", ".", "ob", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "ob", "=", "splitobs", "(", "self", ".", "ob", ",", "keepdims", "=", "False", ")", "\n", "ob_policy_idx", "=", "np", ".", "split", "(", "np", ".", "arange", "(", "len", "(", "self", ".", "ob", ")", ")", ",", "len", "(", "self", ".", "policies", ")", ")", "\n", "actions", "=", "[", "]", "\n", "for", "i", ",", "policy", "in", "enumerate", "(", "self", ".", "policies", ")", ":", "\n", "                    ", "inp", "=", "itemgetter", "(", "*", "ob_policy_idx", "[", "i", "]", ")", "(", "self", ".", "ob", ")", "\n", "inp", "=", "listdict2dictnp", "(", "[", "inp", "]", "if", "ob_policy_idx", "[", "i", "]", ".", "shape", "[", "0", "]", "==", "1", "else", "inp", ")", "\n", "ac", ",", "info", "=", "policy", ".", "act", "(", "inp", ")", "\n", "actions", ".", "append", "(", "ac", ")", "\n", "", "action", "=", "listdict2dictnp", "(", "actions", ",", "keepdims", "=", "True", ")", "\n", "\n", "", "self", ".", "ob", ",", "rew", ",", "done", ",", "env_info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "total_rew", "+=", "rew", "\n", "\n", "if", "done", "or", "env_info", ".", "get", "(", "'discard_episode'", ",", "False", ")", ":", "\n", "                ", "self", ".", "reset_increment", "(", ")", "\n", "\n", "", "if", "self", ".", "display_window", ":", "\n", "                ", "self", ".", "add_overlay", "(", "const", ".", "GRID_TOPRIGHT", ",", "\"Reset env; (current seed: {})\"", ".", "format", "(", "self", ".", "seed", ")", ",", "\"N - next / P - previous \"", ")", "\n", "self", ".", "add_overlay", "(", "const", ".", "GRID_TOPRIGHT", ",", "\"Reward\"", ",", "str", "(", "self", ".", "total_rew", ")", ")", "\n", "if", "hasattr", "(", "self", ".", "env", ".", "unwrapped", ",", "\"viewer_stats\"", ")", ":", "\n", "                    ", "for", "k", ",", "v", "in", "self", ".", "env", ".", "unwrapped", ".", "viewer_stats", ".", "items", "(", ")", ":", "\n", "                        ", "self", ".", "add_overlay", "(", "const", ".", "GRID_TOPRIGHT", ",", "k", ",", "str", "(", "v", ")", ")", "\n", "\n", "", "", "self", ".", "env", ".", "render", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.policy_viewer.PolicyViewer.reset_increment": [[104, 117], ["print", "policy_viewer.PolicyViewer.env.seed", "policy_viewer.PolicyViewer.env.reset", "hasattr", "policy_viewer.PolicyViewer.update_sim", "policy.reset", "policy_viewer.PolicyViewer.env.reset_goal"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "", "", "def", "reset_increment", "(", "self", ")", ":", "\n", "        ", "self", ".", "total_rew_avg", "=", "(", "self", ".", "n_episodes", "*", "self", ".", "total_rew_avg", "+", "self", ".", "total_rew", ")", "/", "(", "self", ".", "n_episodes", "+", "1", ")", "\n", "self", ".", "n_episodes", "+=", "1", "\n", "print", "(", "f\"Reward: {self.total_rew} (rolling average: {self.total_rew_avg})\"", ")", "\n", "self", ".", "total_rew", "=", "0.0", "\n", "self", ".", "seed", "+=", "1", "\n", "self", ".", "env", ".", "seed", "(", "self", ".", "seed", ")", "\n", "self", ".", "ob", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "for", "policy", "in", "self", ".", "policies", ":", "\n", "            ", "policy", ".", "reset", "(", ")", "\n", "", "if", "hasattr", "(", "self", ".", "env", ",", "\"reset_goal\"", ")", ":", "\n", "            ", "self", ".", "goal", "=", "self", ".", "env", ".", "reset_goal", "(", ")", "\n", "", "self", ".", "update_sim", "(", "self", ".", "env", ".", "unwrapped", ".", "sim", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.policy_viewer.splitobs": [[11, 19], ["range", "obs.items", "list", "obs.keys"], "function", ["None"], ["def", "splitobs", "(", "obs", ",", "keepdims", "=", "True", ")", ":", "\n", "    ", "'''\n        Split obs into list of single agent obs.\n        Args:\n            obs: dictionary of numpy arrays where first dim in each array is agent dim\n    '''", "\n", "n_agents", "=", "obs", "[", "list", "(", "obs", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "shape", "[", "0", "]", "\n", "return", "[", "{", "k", ":", "v", "[", "[", "i", "]", "]", "if", "keepdims", "else", "v", "[", "i", "]", "for", "k", ",", "v", "in", "obs", ".", "items", "(", ")", "}", "for", "i", "in", "range", "(", "n_agents", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.util.transforms.add_weld_equality_constraint_transform": [[6, 24], ["collections.OrderedDict", "[].append", "collections.OrderedDict"], "function", ["None"], ["def", "add_weld_equality_constraint_transform", "(", "name", ",", "body_name1", ",", "body_name2", ")", ":", "\n", "    ", "'''\n        Creates a weld constraint that maintains relative position and orientation between\n        two objects\n    '''", "\n", "def", "fun", "(", "xml_dict", ")", ":", "\n", "        ", "if", "'equality'", "not", "in", "xml_dict", ":", "\n", "            ", "xml_dict", "[", "'equality'", "]", "=", "OrderedDict", "(", ")", "\n", "xml_dict", "[", "'equality'", "]", "[", "'weld'", "]", "=", "[", "]", "\n", "", "constraint", "=", "OrderedDict", "(", ")", "\n", "constraint", "[", "'@name'", "]", "=", "name", "\n", "constraint", "[", "'@body1'", "]", "=", "body_name1", "\n", "constraint", "[", "'@body2'", "]", "=", "body_name2", "\n", "constraint", "[", "'@active'", "]", "=", "False", "\n", "xml_dict", "[", "'equality'", "]", "[", "'weld'", "]", ".", "append", "(", "constraint", ")", "\n", "return", "xml_dict", "\n", "\n", "", "return", "fun", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.util.transforms.set_joint_damping_transform": [[26, 38], ["mujoco_worldgen.transforms.closure_transform", "node.get"], "function", ["None"], ["", "def", "set_joint_damping_transform", "(", "damping", ",", "joint_name", ")", ":", "\n", "    ", "''' Set joints damping to a single value.\n        Args:\n            damping (float): damping to set\n            joint_name (string): partial name of joint. Any joint with joint_name\n                as a substring will be affected.\n    '''", "\n", "def", "closure", "(", "node", ")", ":", "\n", "        ", "for", "joint", "in", "node", ".", "get", "(", "'joint'", ",", "[", "]", ")", ":", "\n", "            ", "if", "joint_name", "in", "joint", "[", "'@name'", "]", ":", "\n", "                ", "joint", "[", "'@damping'", "]", "=", "damping", "\n", "", "", "", "return", "closure_transform", "(", "closure", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.util.transforms.remove_hinge_axis_transform": [[40, 50], ["mujoco_worldgen.transforms.closure_transform", "numpy.linalg.norm"], "function", ["None"], ["", "def", "remove_hinge_axis_transform", "(", "axis", ")", ":", "\n", "    ", "''' Removes specific hinge axis from the body. '''", "\n", "def", "fun", "(", "xml_dict", ")", ":", "\n", "        ", "def", "closure", "(", "node", ")", ":", "\n", "            ", "if", "'joint'", "in", "node", ":", "\n", "                ", "node", "[", "\"joint\"", "]", "=", "[", "j", "for", "j", "in", "node", "[", "\"joint\"", "]", "\n", "if", "j", "[", "\"@type\"", "]", "!=", "\"hinge\"", "\n", "or", "np", ".", "linalg", ".", "norm", "(", "j", "[", "\"@axis\"", "]", "-", "axis", ")", ">=", "1e-5", "]", "\n", "", "", "return", "closure_transform", "(", "closure", ")", "(", "xml_dict", ")", "\n", "", "return", "fun", "\n", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.util.vision.in_cone2d": [[6, 39], ["isinstance", "isinstance", "isinstance", "isinstance", "numpy.seterr", "numpy.sqrt", "numpy.sum", "numpy.arccos", "len", "numpy.array", "numpy.sum", "numpy.abs", "numpy.square", "numpy.isnan", "mujoco_worldgen.util.rotation.normalize_angles", "numpy.cos", "numpy.sin"], "function", ["None"], ["def", "in_cone2d", "(", "origin_pts", ",", "origin_angles", ",", "cone_angle", ",", "target_pts", ")", ":", "\n", "    ", "'''\n        Computes whether 2D points target_pts are in the cones originating from\n            origin_pts at angle origin_angles with cone spread angle cone_angle.\n        Args:\n            origin_pts (np.ndarray): array with shape (n_points, 2) of origin points\n            origin_angles (np.ndarray): array with shape (n_points,) of origin angles\n            cone_angle (float): cone angle width\n            target_pts (np.ndarray): target points to check whether in cones\n        Returns:\n            np.ndarray of bools. Each row corresponds to origin cone, and columns to\n                target points\n    '''", "\n", "assert", "isinstance", "(", "origin_pts", ",", "np", ".", "ndarray", ")", "\n", "assert", "isinstance", "(", "origin_angles", ",", "np", ".", "ndarray", ")", "\n", "assert", "isinstance", "(", "cone_angle", ",", "float", ")", "\n", "assert", "isinstance", "(", "target_pts", ",", "np", ".", "ndarray", ")", "\n", "assert", "origin_pts", ".", "shape", "[", "0", "]", "==", "origin_angles", ".", "shape", "[", "0", "]", "\n", "assert", "len", "(", "origin_angles", ".", "shape", ")", "==", "1", ",", "\"Angles should only have 1 dimension\"", "\n", "np", ".", "seterr", "(", "divide", "=", "'ignore'", ",", "invalid", "=", "'ignore'", ")", "\n", "cone_vec", "=", "np", ".", "array", "(", "[", "np", ".", "cos", "(", "origin_angles", ")", ",", "np", ".", "sin", "(", "origin_angles", ")", "]", ")", ".", "T", "\n", "# Compute normed vectors between all pairs of agents", "\n", "pos_diffs", "=", "target_pts", "[", "None", ",", "...", "]", "-", "origin_pts", "[", ":", ",", "None", ",", ":", "]", "\n", "norms", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "pos_diffs", ")", ",", "-", "1", ",", "keepdims", "=", "True", ")", ")", "\n", "unit_diffs", "=", "pos_diffs", "/", "norms", "\n", "# Dot product between unit vector in middle of cone and the vector", "\n", "dot_cone_diff", "=", "np", ".", "sum", "(", "unit_diffs", "*", "cone_vec", "[", ":", ",", "None", ",", ":", "]", ",", "-", "1", ")", "\n", "angle_between", "=", "np", ".", "arccos", "(", "dot_cone_diff", ")", "\n", "# Right now the only thing that should be nan will be targets that are on the origin point", "\n", "# This can only happen for the origin looking at itself, so just make this always true", "\n", "angle_between", "[", "np", ".", "isnan", "(", "angle_between", ")", "]", "=", "0.", "\n", "\n", "return", "np", ".", "abs", "(", "normalize_angles", "(", "angle_between", ")", ")", "<=", "cone_angle", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.util.vision.insight": [[41, 67], ["mujoco_worldgen.util.geometry.raycast", "numpy.linalg.norm"], "function", ["None"], ["", "def", "insight", "(", "sim", ",", "geom1_id", ",", "geom2_id", "=", "None", ",", "pt2", "=", "None", ",", "dist_thresh", "=", "np", ".", "inf", ",", "check_body", "=", "True", ")", ":", "\n", "    ", "'''\n        Check if geom2 or pt2 is in line of sight of geom1.\n        Args:\n            sim: Mujoco sim object\n            geom1 (int): geom id\n            geom2 (int): geom id\n            pt2 (tuple): xy point\n            dist_thresh (float): Adds a distance threshold for vision. Objects beyond the threshold\n                are considered out of sight.\n            check_body (bool): Check whether the raycast hit any geom in the body that geom2 is in\n                rather than if it just hit geom2\n    '''", "\n", "dist", ",", "collision_geom", "=", "raycast", "(", "sim", ",", "geom1_id", ",", "geom2_id", "=", "geom2_id", ",", "pt2", "=", "pt2", ")", "\n", "if", "geom2_id", "is", "not", "None", ":", "\n", "        ", "if", "check_body", ":", "\n", "            ", "body2_id", ",", "collision_body_id", "=", "sim", ".", "model", ".", "geom_bodyid", "[", "[", "geom2_id", ",", "collision_geom", "]", "]", "\n", "return", "(", "collision_body_id", "==", "body2_id", "and", "dist", "<", "dist_thresh", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "collision_geom", "==", "geom2_id", "and", "dist", "<", "dist_thresh", ")", "\n", "", "", "else", ":", "\n", "        ", "pt1", "=", "sim", ".", "data", ".", "geom_xpos", "[", "geom1_id", "]", "\n", "dist_pt2", "=", "np", ".", "linalg", ".", "norm", "(", "pt2", "-", "pt1", ")", "\n", "# if dist == -1 then we're raycasting from a geom to a point within itself,", "\n", "#   and all objects have line of sight of themselves.", "\n", "return", "(", "dist", "==", "-", "1.0", "or", "dist", ">", "dist_pt2", ")", "and", "dist_pt2", "<", "dist_thresh", "\n", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.util.geometry.dist_pt_to_cuboid": [[5, 55], ["numpy.concatenate", "numpy.repeat", "mujoco_worldgen.util.rotation.quat_mul", "numpy.maximum", "numpy.linalg.norm", "mujoco_worldgen.util.rotation.quat_conjugate", "mujoco_worldgen.util.rotation.quat_mul", "numpy.zeros_like", "numpy.abs"], "function", ["None"], ["def", "dist_pt_to_cuboid", "(", "pt1", ",", "cuboid_center", ",", "cuboid_dims", ",", "cuboid_quat", ")", ":", "\n", "    ", "'''\n        This function calculates the shortest distance between test points\n        and cuboids at arbitrary locations, widths and rotations\n\n        Args:\n            pt1 (num points x 3): test point positions\n            cuboid_center (num cuboids x 3): cuboid centers\n            cuboid_dims (num cuboids x 3): cuboid half-width\n            cuboid_quat (num cuboids x 4): cuboid quaternion\n\n        Returns:\n            Distance array of size num points x num cuboids\n    '''", "\n", "assert", "cuboid_center", ".", "shape", "[", "0", "]", "==", "cuboid_dims", ".", "shape", "[", "0", "]", "==", "cuboid_quat", ".", "shape", "[", "0", "]", ",", "\"First dimension of cuboid_center, cuboid_dims and cuboid_quat need to match, \"", "+", "f\"but were {cuboid_center.shape[0]}, {cuboid_dims.shape[0]} and {cuboid_quat.shape[0]}.\"", "\n", "assert", "pt1", ".", "shape", "[", "1", "]", "==", "cuboid_center", ".", "shape", "[", "1", "]", "==", "cuboid_dims", ".", "shape", "[", "1", "]", "==", "3", ",", "\"Second dimension of pt1, cuboid_center and cuboid_dims needs to be 3, \"", "+", "f\"but were {pt1.shape[1]}, {cuboid_center.shape[1]} and {cuboid_dims.shape[1]}.\"", "\n", "assert", "cuboid_quat", ".", "shape", "[", "1", "]", "==", "4", ",", "f\"Second dimension of cuboid_quat needs to be 4, but was {cuboid_quat.shape[1]}.\"", "\n", "\n", "# calculate relative position of test points", "\n", "rel_pos", "=", "pt1", "[", ":", ",", "None", ",", ":", "]", "-", "cuboid_center", "[", "None", ",", ":", ",", ":", "]", "\n", "\n", "# convert into quaternion (leading dimension is zero)", "\n", "q_rel_pos", "=", "np", ".", "concatenate", "(", "[", "np", ".", "zeros_like", "(", "rel_pos", "[", ":", ",", ":", ",", "[", "0", "]", "]", ")", ",", "rel_pos", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# broadcast cuboid_quat by hand", "\n", "cuboid_quat", "=", "np", ".", "repeat", "(", "cuboid_quat", "[", "None", ",", ":", "]", ",", "pt1", ".", "shape", "[", "0", "]", ",", "axis", "=", "0", ")", "\n", "\n", "# rotate relative position in cuboid frame", "\n", "# since cuboid_quat specifies how the cuboid is rotated wrt to the standard coordinate system,", "\n", "# we need to rotate the test points using the inverse rotation (i.e. conjugate quaternion)", "\n", "#", "\n", "# For rotation of vectors using quaternions see", "\n", "# https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation", "\n", "q_rel_pos", "=", "quat_mul", "(", "quat_conjugate", "(", "cuboid_quat", ")", ",", "quat_mul", "(", "q_rel_pos", ",", "cuboid_quat", ")", ")", "\n", "\n", "# now we can pretend that the cuboid is aligned to x-axis", "\n", "# calculate vector to closest point on the cuboid", "\n", "# this can be done as described here:", "\n", "# https://gamedev.stackexchange.com/questions/44483/how-do-i-calculate-distance-between-a-point-and-an-axis-aligned-rectangle", "\n", "dist_vec", "=", "np", ".", "maximum", "(", "0", ",", "np", ".", "abs", "(", "q_rel_pos", "[", ":", ",", ":", ",", "1", ":", "]", ")", "-", "cuboid_dims", "[", "None", ",", ":", ",", ":", "]", ")", "\n", "\n", "# distance is length of distance vector", "\n", "dist", "=", "np", ".", "linalg", ".", "norm", "(", "dist_vec", ",", "axis", "=", "-", "1", ")", "\n", "\n", "return", "dist", "\n", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.lidar.Lidar.__init__": [[21, 39], ["gym.ObservationWrapper.__init__", "mae_envs.wrappers.util.update_obs_space", "numpy.linspace", "numpy.array", "numpy.cos", "numpy.sin", "numpy.zeros_like"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], ["def", "__init__", "(", "self", ",", "env", ",", "n_lidar_per_agent", "=", "30", ",", "lidar_range", "=", "6.0", ",", "\n", "compress_lidar_scale", "=", "None", ",", "visualize_lidar", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "n_lidar_per_agent", "=", "n_lidar_per_agent", "\n", "self", ".", "lidar_range", "=", "lidar_range", "\n", "self", ".", "compress_lidar_scale", "=", "compress_lidar_scale", "\n", "self", ".", "visualize_lidar", "=", "visualize_lidar", "\n", "self", ".", "n_agents", "=", "self", ".", "unwrapped", ".", "n_agents", "\n", "\n", "self", ".", "observation_space", "=", "update_obs_space", "(", "\n", "env", ",", "{", "'lidar'", ":", "(", "self", ".", "n_agents", ",", "self", ".", "n_lidar_per_agent", ",", "1", ")", "}", ")", "\n", "\n", "# generate concentric lidar rays centered at origin", "\n", "self", ".", "lidar_angles", "=", "np", ".", "linspace", "(", "0", ",", "2", "*", "np", ".", "pi", ",", "num", "=", "self", ".", "n_lidar_per_agent", ",", "endpoint", "=", "False", ")", "\n", "self", ".", "lidar_rays", "=", "self", ".", "lidar_range", "*", "np", ".", "array", "(", "[", "np", ".", "cos", "(", "self", ".", "lidar_angles", ")", ",", "\n", "np", ".", "sin", "(", "self", ".", "lidar_angles", ")", ",", "\n", "np", ".", "zeros_like", "(", "self", ".", "lidar_angles", ")", "]", ")", ".", "T", "\n", "self", ".", "lidar_rays", "=", "self", ".", "lidar_rays", "[", "None", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.lidar.Lidar.reset": [[40, 57], ["lidar.Lidar.env.reset", "numpy.array", "numpy.array", "lidar.Lidar.observation", "numpy.array", "sim.model.body_name2id", "sim.model.geom_name2id", "range", "range", "sim.model.site_name2id", "range", "range"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n", "sim", "=", "self", ".", "unwrapped", ".", "sim", "\n", "\n", "# Cache ids", "\n", "self", ".", "agent_body_ids", "=", "np", ".", "array", "(", "[", "sim", ".", "model", ".", "body_name2id", "(", "f\"agent{i}:particle\"", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_agents", ")", "]", ")", "\n", "self", ".", "agent_geom_ids", "=", "np", ".", "array", "(", "[", "sim", ".", "model", ".", "geom_name2id", "(", "f'agent{i}:agent'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_agents", ")", "]", ")", "\n", "\n", "if", "self", ".", "visualize_lidar", ":", "\n", "            ", "self", ".", "lidar_ids", "=", "np", ".", "array", "(", "[", "[", "sim", ".", "model", ".", "site_name2id", "(", "f\"agent{i}:lidar{j}\"", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "n_lidar_per_agent", ")", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n_agents", ")", "]", ")", "\n", "\n", "", "return", "self", ".", "observation", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.lidar.Lidar.place_lidar_ray_markers": [[58, 91], ["numpy.linalg.norm", "numpy.array", "numpy.cross", "numpy.linalg.norm", "numpy.arctan2", "mujoco_worldgen.util.rotation.quat_from_angle_and_axis", "numpy.array", "numpy.dot"], "methods", ["None"], ["", "def", "place_lidar_ray_markers", "(", "self", ",", "agent_pos", ",", "lidar_endpoints", ")", ":", "\n", "        ", "sim", "=", "self", ".", "unwrapped", ".", "sim", "\n", "\n", "site_offset", "=", "sim", ".", "data", ".", "site_xpos", "[", "self", ".", "lidar_ids", ",", ":", "]", "-", "sim", ".", "model", ".", "site_pos", "[", "self", ".", "lidar_ids", ",", ":", "]", "\n", "\n", "# compute location of lidar rays", "\n", "sim", ".", "model", ".", "site_pos", "[", "self", ".", "lidar_ids", ",", ":", "]", "=", ".5", "*", "(", "agent_pos", "[", ":", ",", "None", ",", ":", "]", "+", "lidar_endpoints", ")", "-", "site_offset", "\n", "\n", "# compute length of lidar rays", "\n", "rel_vec", "=", "lidar_endpoints", "-", "agent_pos", "[", ":", ",", "None", ",", ":", "]", "\n", "rel_vec_length", "=", "np", ".", "linalg", ".", "norm", "(", "rel_vec", ",", "axis", "=", "-", "1", ")", "\n", "sim", ".", "model", ".", "site_size", "[", "self", ".", "lidar_ids", ",", "1", "]", "=", "rel_vec_length", "/", "2", "\n", "\n", "# compute rotation of lidar rays", "\n", "# normalize relative vector", "\n", "rel_vec_norm", "=", "rel_vec", "/", "rel_vec_length", "[", ":", ",", ":", ",", "None", "]", "\n", "# set small relative vectors to zero instead", "\n", "rel_vec_norm", "[", "rel_vec_length", "<=", "1e-8", ",", ":", "]", "=", "0.0", "\n", "# start vector", "\n", "start_vec", "=", "np", ".", "array", "(", "[", "0.0", ",", "0.0", ",", "1.0", "]", ")", "\n", "# calculate rotation axis: cross product between start and goal vector", "\n", "rot_axis", "=", "np", ".", "cross", "(", "start_vec", ",", "rel_vec_norm", ")", "\n", "norm_rot_axis", "=", "np", ".", "linalg", ".", "norm", "(", "rot_axis", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# calculate rotation angle and quaternion", "\n", "rot_angle", "=", "np", ".", "arctan2", "(", "norm_rot_axis", ",", "np", ".", "dot", "(", "rel_vec_norm", ",", "start_vec", ")", ")", "\n", "quat", "=", "quat_from_angle_and_axis", "(", "rot_angle", ",", "rot_axis", ")", "\n", "\n", "# if norm of cross product is very small, set rotation to identity", "\n", "eps", "=", "1e-3", "\n", "quat", "[", "norm_rot_axis", "<=", "eps", ",", ":", "]", "=", "np", ".", "array", "(", "[", "1.0", ",", "0.0", ",", "0.0", ",", "0.0", "]", ")", "\n", "\n", "sim", ".", "model", ".", "site_quat", "[", "self", ".", "lidar_ids", ",", ":", "]", "=", "quat", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.lidar.Lidar.observation": [[92, 122], ["numpy.zeros", "range", "range", "np.zeros.Lidar.place_lidar_ray_markers", "numpy.array", "sim.forward", "numpy.tanh", "mujoco_worldgen.util.geometry.raycast"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.lidar.Lidar.place_lidar_ray_markers"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "sim", "=", "self", ".", "unwrapped", ".", "sim", "\n", "agent_pos", "=", "sim", ".", "data", ".", "body_xpos", "[", "self", ".", "agent_body_ids", "]", "\n", "\n", "lidar_endpoints", "=", "agent_pos", "[", ":", ",", "None", ",", ":", "]", "+", "self", ".", "lidar_rays", "\n", "\n", "# Would be nice to vectorize in the future with better mujoco-py interface", "\n", "lidar", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_lidar_per_agent", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_agents", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "n_lidar_per_agent", ")", ":", "\n", "                ", "lidar", "[", "i", ",", "j", "]", "=", "raycast", "(", "sim", ",", "geom1_id", "=", "self", ".", "agent_geom_ids", "[", "i", "]", ",", "\n", "pt2", "=", "lidar_endpoints", "[", "i", ",", "j", "]", ",", "geom_group", "=", "None", ")", "[", "0", "]", "\n", "\n", "", "", "lidar", "[", "lidar", "<", "0.0", "]", "=", "self", ".", "lidar_range", "\n", "\n", "if", "self", ".", "compress_lidar_scale", "is", "not", "None", ":", "\n", "            ", "obs", "[", "'lidar'", "]", "=", "(", "self", ".", "compress_lidar_scale", "*", "\n", "np", ".", "tanh", "(", "lidar", "[", "...", ",", "None", "]", "/", "self", ".", "compress_lidar_scale", ")", ")", "\n", "", "else", ":", "\n", "            ", "obs", "[", "'lidar'", "]", "=", "lidar", "[", "...", ",", "None", "]", "\n", "\n", "", "if", "self", ".", "visualize_lidar", ":", "\n", "# recalculate lidar endpoints", "\n", "            ", "lidar_endpoints", "=", "agent_pos", "[", ":", ",", "None", ",", ":", "]", "+", "lidar", "[", ":", ",", ":", ",", "None", "]", "/", "self", ".", "lidar_range", "*", "self", ".", "lidar_rays", "\n", "self", ".", "place_lidar_ray_markers", "(", "agent_pos", ",", "lidar_endpoints", ")", "\n", "sim", ".", "model", ".", "site_rgba", "[", "self", ".", "lidar_ids", ",", ":", "]", "=", "np", ".", "array", "(", "[", "0.0", ",", "0.0", ",", "1.0", ",", "0.2", "]", ")", "\n", "sim", ".", "forward", "(", ")", "\n", "\n", "", "return", "obs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.team.TeamMembership.__init__": [[28, 49], ["gym.ObservationWrapper.__init__", "isinstance", "numpy.array", "numpy.array", "mae_envs.wrappers.util.update_obs_space", "numpy.array_split", "numpy.concatenate", "len", "numpy.arange", "numpy.ones_like", "enumerate"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], ["def", "__init__", "(", "self", ",", "env", ",", "team_index", "=", "None", ",", "n_teams", "=", "2", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "n_agents", "=", "self", ".", "metadata", "[", "'n_actors'", "]", "\n", "\n", "if", "team_index", "is", "None", ":", "\n", "            ", "assert", "n_teams", ">=", "1", ",", "\"Number of teams must be at least 1\"", "\n", "# split teams: 5 agents and 3 teams will result in team_index = [0,0,1,1,2]", "\n", "team_index", "=", "np", ".", "array_split", "(", "np", ".", "arange", "(", "self", ".", "n_agents", ")", ",", "n_teams", ")", "\n", "team_index", "=", "np", ".", "concatenate", "(", "[", "np", ".", "ones_like", "(", "ar", ")", "*", "i", "for", "i", ",", "ar", "in", "enumerate", "(", "team_index", ")", "]", ")", "\n", "\n", "", "assert", "len", "(", "team_index", ")", "==", "self", ".", "n_agents", ",", "(", "\n", "\"team_index parameter length must be equal to number of agents\"", ")", "\n", "if", "isinstance", "(", "team_index", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "assert", "team_index", ".", "ndim", "==", "1", ",", "(", "\n", "\"team_index parameter must be numpy array of dimension 1\"", ")", "\n", "\n", "# store in metadata property that gets automatically inherited", "\n", "# make sure we copy value of team_index if it's a numpy array", "\n", "", "self", ".", "metadata", "[", "'team_index'", "]", "=", "np", ".", "array", "(", "team_index", ")", "\n", "self", ".", "team_idx", "=", "np", ".", "array", "(", "team_index", ")", "\n", "self", ".", "observation_space", "=", "update_obs_space", "(", "env", ",", "{", "'team_size'", ":", "(", "self", ".", "n_agents", ",", "1", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.team.TeamMembership.observation": [[50, 54], ["numpy.sum"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "[", "'team_size'", "]", "=", "np", ".", "sum", "(", "self", ".", "team_idx", "[", ":", ",", "None", "]", "==", "self", ".", "team_idx", "[", "None", ",", ":", "]", ",", "\n", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "return", "obs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.line_of_sight.AgentAgentObsMask2D.__init__": [[12, 17], ["gym.ObservationWrapper.__init__", "mae_envs.wrappers.util.update_obs_space"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], ["def", "__init__", "(", "self", ",", "env", ",", "cone_angle", "=", "3", "/", "8", "*", "np", ".", "pi", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "cone_angle", "=", "cone_angle", "\n", "self", ".", "n_agents", "=", "self", ".", "unwrapped", ".", "n_agents", "\n", "self", ".", "observation_space", "=", "update_obs_space", "(", "env", ",", "{", "'mask_aa_obs'", ":", "(", "self", ".", "n_agents", ",", "self", ".", "n_agents", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.line_of_sight.AgentAgentObsMask2D.observation": [[18, 31], ["mae_envs.util.vision.in_cone2d", "numpy.argwhere", "numpy.squeeze", "mae_envs.util.vision.insight"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.util.vision.in_cone2d", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.util.vision.insight"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "# Agent to agent obs mask", "\n", "        ", "agent_pos2d", "=", "obs", "[", "'agent_pos'", "]", "[", ":", ",", ":", "-", "1", "]", "\n", "agent_angle", "=", "obs", "[", "'agent_angle'", "]", "\n", "cone_mask", "=", "in_cone2d", "(", "agent_pos2d", ",", "np", ".", "squeeze", "(", "agent_angle", ",", "-", "1", ")", ",", "self", ".", "cone_angle", ",", "agent_pos2d", ")", "\n", "# Make sure they are in line of sight", "\n", "for", "i", ",", "j", "in", "np", ".", "argwhere", "(", "cone_mask", ")", ":", "\n", "            ", "if", "i", "!=", "j", ":", "\n", "                ", "cone_mask", "[", "i", ",", "j", "]", "=", "insight", "(", "self", ".", "unwrapped", ".", "sim", ",", "\n", "self", ".", "metadata", "[", "'agent_geom_idxs'", "]", "[", "i", "]", ",", "\n", "self", ".", "metadata", "[", "'agent_geom_idxs'", "]", "[", "j", "]", ")", "\n", "", "", "obs", "[", "'mask_aa_obs'", "]", "=", "cone_mask", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.line_of_sight.AgentSiteObsMask2D.__init__": [[40, 49], ["gym.ObservationWrapper.__init__", "mae_envs.wrappers.util.update_obs_space"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], ["def", "__init__", "(", "self", ",", "env", ",", "pos_obs_key", ",", "mask_obs_key", ",", "cone_angle", "=", "3", "/", "8", "*", "np", ".", "pi", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "cone_angle", "=", "cone_angle", "\n", "self", ".", "n_agents", "=", "self", ".", "unwrapped", ".", "n_agents", "\n", "assert", "(", "self", ".", "n_agents", "==", "self", ".", "observation_space", ".", "spaces", "[", "'agent_pos'", "]", ".", "shape", "[", "0", "]", ")", "\n", "self", ".", "n_objects", "=", "self", ".", "observation_space", ".", "spaces", "[", "pos_obs_key", "]", ".", "shape", "[", "0", "]", "\n", "self", ".", "observation_space", "=", "update_obs_space", "(", "env", ",", "{", "mask_obs_key", ":", "(", "self", ".", "n_agents", ",", "self", ".", "n_objects", ")", "}", ")", "\n", "self", ".", "pos_obs_key", "=", "pos_obs_key", "\n", "self", ".", "mask_obs_key", "=", "mask_obs_key", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.line_of_sight.AgentSiteObsMask2D.observation": [[50, 62], ["mae_envs.util.vision.in_cone2d", "numpy.argwhere", "numpy.squeeze", "mae_envs.util.vision.insight"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.util.vision.in_cone2d", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.util.vision.insight"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "agent_pos2d", "=", "obs", "[", "'agent_pos'", "]", "[", ":", ",", ":", "-", "1", "]", "\n", "agent_angle", "=", "obs", "[", "'agent_angle'", "]", "\n", "pos2d", "=", "obs", "[", "self", ".", "pos_obs_key", "]", "[", ":", ",", ":", "2", "]", "\n", "cone_mask", "=", "in_cone2d", "(", "agent_pos2d", ",", "np", ".", "squeeze", "(", "agent_angle", ",", "-", "1", ")", ",", "self", ".", "cone_angle", ",", "pos2d", ")", "\n", "# Make sure they are in line of sight", "\n", "for", "i", ",", "j", "in", "np", ".", "argwhere", "(", "cone_mask", ")", ":", "\n", "            ", "agent_geom_id", "=", "self", ".", "metadata", "[", "'agent_geom_idxs'", "]", "[", "i", "]", "\n", "pt2", "=", "obs", "[", "self", ".", "pos_obs_key", "]", "[", "j", "]", "\n", "cone_mask", "[", "i", ",", "j", "]", "=", "insight", "(", "self", ".", "unwrapped", ".", "sim", ",", "agent_geom_id", ",", "pt2", "=", "pt2", ")", "\n", "", "obs", "[", "self", ".", "mask_obs_key", "]", "=", "cone_mask", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.line_of_sight.AgentGeomObsMask2D.__init__": [[74, 84], ["gym.ObservationWrapper.__init__", "mae_envs.wrappers.util.update_obs_space"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], ["def", "__init__", "(", "self", ",", "env", ",", "pos_obs_key", ",", "geom_idxs_obs_key", ",", "mask_obs_key", ",", "cone_angle", "=", "3", "/", "8", "*", "np", ".", "pi", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "cone_angle", "=", "cone_angle", "\n", "self", ".", "n_agents", "=", "self", ".", "unwrapped", ".", "n_agents", "\n", "assert", "(", "self", ".", "n_agents", "==", "self", ".", "observation_space", ".", "spaces", "[", "'agent_pos'", "]", ".", "shape", "[", "0", "]", ")", "\n", "self", ".", "n_objects", "=", "self", ".", "observation_space", ".", "spaces", "[", "pos_obs_key", "]", ".", "shape", "[", "0", "]", "\n", "self", ".", "observation_space", "=", "update_obs_space", "(", "env", ",", "{", "mask_obs_key", ":", "(", "self", ".", "n_agents", ",", "self", ".", "n_objects", ")", "}", ")", "\n", "self", ".", "pos_obs_key", "=", "pos_obs_key", "\n", "self", ".", "mask_obs_key", "=", "mask_obs_key", "\n", "self", ".", "geom_idxs_obs_key", "=", "geom_idxs_obs_key", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.line_of_sight.AgentGeomObsMask2D.observation": [[85, 103], ["mae_envs.util.vision.in_cone2d", "numpy.argwhere", "numpy.squeeze", "mae_envs.util.vision.insight"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.util.vision.in_cone2d", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.util.vision.insight"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "agent_pos2d", "=", "obs", "[", "'agent_pos'", "]", "[", ":", ",", ":", "-", "1", "]", "\n", "agent_angle", "=", "obs", "[", "'agent_angle'", "]", "\n", "pos2d", "=", "obs", "[", "self", ".", "pos_obs_key", "]", "[", ":", ",", ":", "2", "]", "\n", "cone_mask", "=", "in_cone2d", "(", "agent_pos2d", ",", "np", ".", "squeeze", "(", "agent_angle", ",", "-", "1", ")", ",", "self", ".", "cone_angle", ",", "pos2d", ")", "\n", "# Make sure they are in line of sight", "\n", "for", "i", ",", "j", "in", "np", ".", "argwhere", "(", "cone_mask", ")", ":", "\n", "            ", "agent_geom_id", "=", "self", ".", "metadata", "[", "'agent_geom_idxs'", "]", "[", "i", "]", "\n", "geom_id", "=", "obs", "[", "self", ".", "geom_idxs_obs_key", "]", "[", "j", ",", "0", "]", "\n", "if", "geom_id", "==", "-", "1", ":", "\n", "# This option is helpful if the number of geoms varies between episodes", "\n", "# If geoms don't exists this wrapper expects that the geom idx is", "\n", "# set to -1", "\n", "                ", "cone_mask", "[", "i", ",", "j", "]", "=", "0", "\n", "", "else", ":", "\n", "                ", "cone_mask", "[", "i", ",", "j", "]", "=", "insight", "(", "self", ".", "unwrapped", ".", "sim", ",", "agent_geom_id", ",", "geom2_id", "=", "geom_id", ")", "\n", "", "", "obs", "[", "self", ".", "mask_obs_key", "]", "=", "cone_mask", "\n", "return", "obs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.limit_mvmnt.RestrictAgentsRect.__init__": [[16, 31], ["gym.RewardWrapper.__init__", "numpy.array", "numpy.array", "len", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "restrict_rect", ",", "reward_scale", "=", "10.", ",", "penalize_objects_out", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "n_agents", "=", "self", ".", "unwrapped", ".", "n_agents", "\n", "self", ".", "restrict_rect", "=", "np", ".", "array", "(", "restrict_rect", ")", "\n", "self", ".", "reward_scale", "=", "reward_scale", "\n", "self", ".", "penalize_objects_out", "=", "penalize_objects_out", "\n", "\n", "assert", "len", "(", "self", ".", "restrict_rect", ")", "==", "4", ",", "\"Restriction rectangle must be of format [x_min, y_min, x_max, y_max]\"", "\n", "\n", "self", ".", "rect_middle", "=", "0.5", "*", "np", ".", "array", "(", "[", "restrict_rect", "[", "0", "]", "+", "restrict_rect", "[", "2", "]", ",", "\n", "restrict_rect", "[", "1", "]", "+", "restrict_rect", "[", "3", "]", "]", ")", "\n", "\n", "self", ".", "rect_size", "=", "np", ".", "array", "(", "[", "restrict_rect", "[", "2", "]", "-", "restrict_rect", "[", "0", "]", ",", "\n", "restrict_rect", "[", "3", "]", "-", "restrict_rect", "[", "1", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.limit_mvmnt.RestrictAgentsRect.reset": [[32, 43], ["limit_mvmnt.RestrictAgentsRect.env.reset", "numpy.array", "numpy.array", "sim.model.body_name2id", "range", "sim.model.body_name2id", "sim.model.body_name2id", "numpy.where", "numpy.where"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "sim", "=", "self", ".", "unwrapped", ".", "sim", "\n", "self", ".", "agent_body_idxs", "=", "np", ".", "array", "(", "[", "sim", ".", "model", ".", "body_name2id", "(", "f\"agent{i}:particle\"", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_agents", ")", "]", ")", "\n", "if", "self", ".", "penalize_objects_out", ":", "\n", "            ", "obj_body_idxs", "=", "(", "[", "sim", ".", "model", ".", "body_name2id", "(", "f'moveable_box{i}'", ")", "for", "i", "in", "np", ".", "where", "(", "self", ".", "metadata", "[", "'curr_n_boxes'", "]", ")", "[", "0", "]", "]", "+", "\n", "[", "sim", ".", "model", ".", "body_name2id", "(", "f'ramp{i}:ramp'", ")", "for", "i", "in", "np", ".", "where", "(", "self", ".", "metadata", "[", "'curr_n_ramps'", "]", ")", "[", "0", "]", "]", ")", "\n", "self", ".", "obj_body_idxs", "=", "np", ".", "array", "(", "obj_body_idxs", ")", "\n", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.limit_mvmnt.RestrictAgentsRect.reward": [[44, 56], ["numpy.any", "numpy.any", "numpy.abs", "numpy.abs"], "methods", ["None"], ["", "def", "reward", "(", "self", ",", "reward", ")", ":", "\n", "        ", "sim", "=", "self", ".", "unwrapped", ".", "sim", "\n", "agent_pos", "=", "sim", ".", "data", ".", "body_xpos", "[", "self", ".", "agent_body_idxs", ",", ":", "2", "]", "\n", "outside_rect", "=", "np", ".", "any", "(", "np", ".", "abs", "(", "agent_pos", "-", "self", ".", "rect_middle", ")", ">", "(", "self", ".", "rect_size", "/", "2", ")", ",", "axis", "=", "1", ")", "\n", "if", "self", ".", "penalize_objects_out", ":", "\n", "            ", "obj_pos", "=", "sim", ".", "data", ".", "body_xpos", "[", "self", ".", "obj_body_idxs", ",", ":", "2", "]", "\n", "any_obj_outside_rect", "=", "np", ".", "any", "(", "np", ".", "abs", "(", "obj_pos", "-", "self", ".", "rect_middle", ")", ">", "(", "self", ".", "rect_size", "/", "2", ")", ")", "\n", "if", "any_obj_outside_rect", ":", "\n", "                ", "reward", "[", ":", "]", "=", "-", "self", ".", "reward_scale", "\n", "", "", "reward", "[", "outside_rect", "]", "=", "-", "self", ".", "reward_scale", "\n", "\n", "return", "reward", "\n", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.prep_phase.PreparationPhase.__init__": [[13, 20], ["gym.Wrapper.__init__", "mae_envs.wrappers.util.update_obs_space"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], ["def", "__init__", "(", "self", ",", "env", ",", "prep_fraction", "=", ".2", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "prep_fraction", "=", "prep_fraction", "\n", "self", ".", "prep_time", "=", "self", ".", "prep_fraction", "*", "self", ".", "unwrapped", ".", "horizon", "\n", "self", ".", "n_agents", "=", "self", ".", "metadata", "[", "'n_agents'", "]", "\n", "self", ".", "step_counter", "=", "0", "\n", "self", ".", "observation_space", "=", "update_obs_space", "(", "self", ",", "{", "'prep_obs'", ":", "[", "self", ".", "n_agents", ",", "1", "]", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.prep_phase.PreparationPhase.reset": [[21, 25], ["prep_phase.PreparationPhase.observation", "prep_phase.PreparationPhase.env.reset"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "step_counter", "=", "0", "\n", "self", ".", "in_prep_phase", "=", "True", "\n", "return", "self", ".", "observation", "(", "self", ".", "env", ".", "reset", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.prep_phase.PreparationPhase.reward": [[26, 31], ["numpy.zeros_like"], "methods", ["None"], ["", "def", "reward", "(", "self", ",", "reward", ")", ":", "\n", "        ", "if", "self", ".", "in_prep_phase", ":", "\n", "            ", "reward", "=", "np", ".", "zeros_like", "(", "reward", ")", "\n", "\n", "", "return", "reward", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.prep_phase.PreparationPhase.observation": [[32, 37], ["numpy.ones", "numpy.minimum"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "[", "'prep_obs'", "]", "=", "(", "np", ".", "ones", "(", "(", "self", ".", "n_agents", ",", "1", ")", ")", "*", "\n", "np", ".", "minimum", "(", "1.0", ",", "self", ".", "step_counter", "/", "(", "self", ".", "prep_time", "+", "1e-5", ")", ")", ")", "\n", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.prep_phase.PreparationPhase.step": [[38, 46], ["prep_phase.PreparationPhase.env.step", "prep_phase.PreparationPhase.reward", "prep_phase.PreparationPhase.observation"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.NumpyArrayRewardWrapper.reward", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "rew", "=", "self", ".", "reward", "(", "rew", ")", "\n", "self", ".", "step_counter", "+=", "1", "\n", "self", ".", "in_prep_phase", "=", "self", ".", "step_counter", "<", "self", ".", "prep_time", "\n", "info", "[", "'in_prep_phase'", "]", "=", "self", ".", "in_prep_phase", "\n", "\n", "return", "self", ".", "observation", "(", "obs", ")", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.prep_phase.NoActionsInPrepPhase.__init__": [[52, 55], ["gym.Wrapper.__init__", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "agent_idxs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "agent_idxs", "=", "np", ".", "array", "(", "agent_idxs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.prep_phase.NoActionsInPrepPhase.reset": [[56, 60], ["prep_phase.NoActionsInPrepPhase.env.reset"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "self", ".", "in_prep_phase", "=", "True", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.prep_phase.NoActionsInPrepPhase.step": [[61, 65], ["prep_phase.NoActionsInPrepPhase.env.step", "prep_phase.NoActionsInPrepPhase.action"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.manipulation.LockAllWrapper.action"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "self", ".", "action", "(", "action", ")", ")", "\n", "self", ".", "in_prep_phase", "=", "info", "[", "'in_prep_phase'", "]", "\n", "return", "obs", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.prep_phase.NoActionsInPrepPhase.action": [[66, 80], ["copy.deepcopy", "prep_phase.NoActionsInPrepPhase.action_space.spaces.items", "isinstance", "isinstance"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "action", ")", ":", "\n", "        ", "ac", "=", "deepcopy", "(", "action", ")", "\n", "if", "self", ".", "in_prep_phase", ":", "\n", "            ", "for", "k", ",", "space", "in", "self", ".", "action_space", ".", "spaces", ".", "items", "(", ")", ":", "\n", "                ", "_space", "=", "space", ".", "spaces", "[", "0", "]", "\n", "if", "isinstance", "(", "_space", ",", "gym", ".", "spaces", ".", "MultiDiscrete", ")", ":", "\n", "                    ", "zero_ac", "=", "(", "_space", ".", "nvec", "-", "1", ")", "//", "2", "\n", "", "elif", "isinstance", "(", "_space", ",", "gym", ".", "spaces", ".", "Discrete", ")", ":", "\n", "                    ", "zero_ac", "=", "(", "_space", ".", "n", "-", "1", ")", "//", "2", "\n", "", "else", ":", "\n", "                    ", "zero_ac", "=", "0.0", "\n", "", "ac", "[", "k", "]", "[", "self", ".", "agent_idxs", "]", "=", "zero_ac", "\n", "\n", "", "", "return", "ac", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.prep_phase.MaskPrepPhaseAction.__init__": [[86, 89], ["gym.Wrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "action_key", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "action_key", "=", "action_key", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.prep_phase.MaskPrepPhaseAction.reset": [[90, 94], ["prep_phase.MaskPrepPhaseAction.env.reset"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "self", ".", "in_prep_phase", "=", "True", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.prep_phase.MaskPrepPhaseAction.step": [[95, 102], ["prep_phase.MaskPrepPhaseAction.env.step"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "action", "[", "self", ".", "action_key", "]", "=", "(", "action", "[", "self", ".", "action_key", "]", "*", "(", "1", "-", "self", ".", "in_prep_phase", ")", ")", ".", "astype", "(", "bool", ")", "\n", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "in_prep_phase", "=", "info", "[", "'in_prep_phase'", "]", "\n", "\n", "return", "obs", ",", "rew", ",", "done", ",", "info", "\n", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.NumpyArrayRewardWrapper.__init__": [[21, 23], ["gym.RewardWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["", "", "def", "rejection_placement", "(", "env", ",", "placement_fn", ",", "floor_size", ",", "obj_size", ",", "num_tries", "=", "10", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.NumpyArrayRewardWrapper.reward": [[24, 26], ["numpy.zeros"], "methods", ["None"], []], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.DiscretizeActionWrapper.__init__": [[36, 48], ["gym.ActionWrapper.__init__", "enumerate", "numpy.array", "isinstance", "numpy.array", "gym.spaces.MultiDiscrete", "util.DiscretizeActionWrapper.discrete_to_continuous_act_map.append", "numpy.ones", "numpy.linspace", "len", "zip"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["\n", "grid", "=", "env", ".", "placement_grid", "\n", "grid_size", "=", "len", "(", "grid", ")", "\n", "cell_size", "=", "floor_size", "/", "grid_size", "\n", "obj_size_in_cells", "=", "np", ".", "ceil", "(", "obj_size", "/", "cell_size", ")", ".", "astype", "(", "int", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_tries", ")", ":", "\n", "        ", "if", "placement_fn", "is", "not", "None", ":", "\n", "            ", "pos", "=", "placement_fn", "(", "grid", ",", "obj_size_in_cells", ",", "env", ".", "metadata", ",", "env", ".", "_random_state", ")", "\n", "", "else", ":", "\n", "# Assume that we'll always have boundary walls so don't sample there", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.DiscretizeActionWrapper.action": [[49, 59], ["copy.deepcopy", "numpy.tile", "numpy.tile().reshape", "numpy.arange", "numpy.tile", "numpy.arange"], "methods", ["None"], ["            ", "pos", "=", "np", ".", "array", "(", "[", "env", ".", "_random_state", ".", "randint", "(", "1", ",", "grid_size", "-", "obj_size_in_cells", "[", "0", "]", "-", "1", ")", ",", "\n", "env", ".", "_random_state", ".", "randint", "(", "1", ",", "grid_size", "-", "obj_size_in_cells", "[", "1", "]", "-", "1", ")", "]", ")", "\n", "", "if", "np", ".", "any", "(", "grid", "[", "pos", "[", "0", "]", ":", "pos", "[", "0", "]", "+", "obj_size_in_cells", "[", "0", "]", ",", "pos", "[", "1", "]", ":", "pos", "[", "1", "]", "+", "obj_size_in_cells", "[", "1", "]", "]", ")", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "            ", "extra_room", "=", "obj_size_in_cells", "*", "cell_size", "-", "obj_size", "\n", "pos_on_floor", "=", "pos", "/", "grid_size", "*", "floor_size", "\n", "pos_on_floor", "+=", "env", ".", "_random_state", ".", "uniform", "(", "[", "0", ",", "0", "]", ",", "extra_room", ")", "\n", "placement", "=", "pos_on_floor", "/", "(", "floor_size", "-", "obj_size", ")", "\n", "grid", "[", "pos", "[", "0", "]", ":", "pos", "[", "0", "]", "+", "obj_size_in_cells", "[", "0", "]", ",", "pos", "[", "1", "]", ":", "pos", "[", "1", "]", "+", "obj_size_in_cells", "[", "1", "]", "]", "=", "1", "\n", "return", "placement", ",", "pos", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.DiscardMujocoExceptionEpisodes.__init__": [[65, 68], ["gym.Wrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["pos", "=", "np", ".", "array", "(", "[", "random_state", ".", "randint", "(", "1", ",", "grid_size", "-", "obj_size", "[", "0", "]", "-", "1", ")", ",", "\n", "random_state", ".", "randint", "(", "1", ",", "grid_size", "-", "obj_size", "[", "1", "]", "-", "1", ")", "]", ")", "\n", "\n", "return", "pos", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.DiscardMujocoExceptionEpisodes.step": [[69, 86], ["util.DiscardMujocoExceptionEpisodes.env.step", "logging.info", "logging.info", "str"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step"], ["\n", "\n", "", "def", "close_to_other_object_placement", "(", "object_type", ",", "object_index", ",", "radius_key", ")", ":", "\n", "    ", "def", "close_placement_fn", "(", "grid", ",", "obj_size", ",", "metadata", ",", "random_state", ")", ":", "\n", "        ", "init_pos_key", "=", "f\"{object_type}{object_index}_initpos\"", "\n", "\n", "assert", "init_pos_key", "in", "metadata", ",", "f\"First object position must be specified in metadata['{init_pos_key}']\"", "\n", "assert", "radius_key", "in", "metadata", ",", "f\"metadata['{radius_key}'] mus be specified.\"", "\n", "\n", "grid_size", "=", "len", "(", "grid", ")", "\n", "\n", "anchor_obj_pos", "=", "metadata", "[", "f\"{init_pos_key}\"", "]", "\n", "rad_in_cells", "=", "metadata", "[", "radius_key", "]", "\n", "\n", "distr_limits_min", "=", "np", ".", "maximum", "(", "1", ",", "anchor_obj_pos", "-", "rad_in_cells", ")", "\n", "distr_limits_max", "=", "np", ".", "minimum", "(", "grid_size", "-", "1", ",", "anchor_obj_pos", "+", "rad_in_cells", ")", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.DiscardMujocoExceptionEpisodes.reset": [[87, 96], ["util.DiscardMujocoExceptionEpisodes.env.reset", "logging.info", "util.DiscardMujocoExceptionEpisodes.reset"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["\n", "pos", "=", "np", ".", "array", "(", "[", "random_state", ".", "randint", "(", "distr_limits_min", "[", "0", "]", ",", "distr_limits_max", "[", "0", "]", ")", ",", "\n", "random_state", ".", "randint", "(", "distr_limits_min", "[", "1", "]", ",", "distr_limits_max", "[", "1", "]", ")", "]", ")", "\n", "\n", "return", "pos", "\n", "\n", "", "return", "close_placement_fn", "\n", "\n", "\n", "", "def", "uniform_placement_middle", "(", "area_side_length_fraction", ")", ":", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.MaskActionWrapper.__init__": [[108, 112], ["gym.Wrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["\n", "def", "uniform_placement_middle_fn", "(", "grid", ",", "obj_size", ",", "metadata", ",", "random_state", ")", ":", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.MaskActionWrapper.reset": [[113, 116], ["util.MaskActionWrapper.env.reset", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["        ", "grid_size", "=", "len", "(", "grid", ")", "\n", "distr_limits_min", "=", "(", "(", "grid_size", "-", "obj_size", ")", "*", "(", "1", "-", "area_side_length_fraction", ")", "/", "2", "+", "area_side_length_fraction", ")", ".", "astype", "(", "int", ")", "\n", "distr_limits_max", "=", "(", "(", "grid_size", "-", "obj_size", ")", "*", "(", "1", "+", "area_side_length_fraction", ")", "/", "2", "-", "area_side_length_fraction", ")", ".", "astype", "(", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.MaskActionWrapper.step": [[117, 122], ["numpy.concatenate", "numpy.logical_and", "util.MaskActionWrapper.env.step", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step"], ["pos", "=", "np", ".", "array", "(", "[", "random_state", ".", "randint", "(", "distr_limits_min", "[", "0", "]", ",", "distr_limits_max", "[", "0", "]", ")", ",", "\n", "random_state", ".", "randint", "(", "distr_limits_min", "[", "1", "]", ",", "distr_limits_max", "[", "1", "]", ")", "]", ")", "\n", "\n", "return", "pos", "\n", "\n", "", "return", "uniform_placement_middle_fn", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.AddConstantObservationsWrapper.__init__": [[130, 140], ["gym.ObservationWrapper.__init__", "util.update_obs_space", "type", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], ["", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.AddConstantObservationsWrapper.observation": [[141, 145], ["util.AddConstantObservationsWrapper.new_obs.items"], "methods", ["None"], []], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.SpoofEntityWrapper.__init__": [[158, 170], ["gym.ObservationWrapper.__init__", "list", "util.update_obs_space", "list", "util.update_obs_space"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], []], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.SpoofEntityWrapper.observation": [[171, 183], ["numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.ones_like", "numpy.zeros", "numpy.zeros", "numpy.zeros"], "methods", ["None"], []], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.ConcatenateObsWrapper.__init__": [[191, 202], ["gym.ObservationWrapper.__init__", "obs_groups.items", "numpy.all", "sum", "util.update_obs_space", "list", "numpy.array", "numpy.array", "util.ConcatenateObsWrapper.observation_space.spaces.items"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], []], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.ConcatenateObsWrapper.observation": [[203, 207], ["util.ConcatenateObsWrapper.obs_groups.items", "numpy.concatenate"], "methods", ["None"], []], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space": [[9, 14], ["env.observation_space.spaces.copy", "delta.items", "gym.spaces.Dict", "gym.spaces.Box"], "function", ["None"], ["\n", "outer_bound", "=", "None", "\n", "for", "body", "in", "parse_file", "(", "obj", ".", "_generate_xml_path", "(", ")", ")", "[", "'worldbody'", "]", "[", "'body'", "]", ":", "\n", "        ", "if", "body", ".", "get", "(", "'@name'", ",", "''", ")", "==", "'annotation:outer_bound'", ":", "\n", "            ", "outer_bound", "=", "body", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.food.FoodHealthWrapper.__init__": [[28, 48], ["gym.Wrapper.__init__", "mae_envs.wrappers.util.update_obs_space", "gym.spaces.Tuple", "type", "gym.spaces.MultiDiscrete", "range"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], ["\n", "for", "i", "in", "range", "(", "self", ".", "curr_n_food", ")", ":", "\n", "            ", "env", ".", "metadata", ".", "pop", "(", "f\"food{i}_initpos\"", ",", "None", ")", "\n", "\n", "# Add food sites", "\n", "", "for", "i", "in", "range", "(", "self", ".", "curr_n_food", ")", ":", "\n", "            ", "if", "self", ".", "placement_fn", "is", "not", "None", ":", "\n", "                ", "_placement_fn", "=", "(", "self", ".", "placement_fn", "[", "i", "]", "\n", "if", "isinstance", "(", "self", ".", "placement_fn", ",", "list", ")", "\n", "else", "self", ".", "placement_fn", ")", "\n", "pos", ",", "pos_grid", "=", "rejection_placement", "(", "env", ",", "_placement_fn", ",", "floor_size", ",", "\n", "np", ".", "array", "(", "[", "self", ".", "food_size", ",", "self", ".", "food_size", "]", ")", ")", "\n", "if", "pos", "is", "not", "None", ":", "\n", "                    ", "floor", ".", "mark", "(", "f\"food{i}\"", ",", "relative_xyz", "=", "np", ".", "append", "(", "pos", ",", "[", "self", ".", "food_size", "/", "2", "]", ")", ",", "\n", "size", "=", "(", "self", ".", "food_size", ",", "self", ".", "food_size", ",", "self", ".", "food_size", ")", ",", "\n", "rgba", "=", "(", "0.", ",", "1.", ",", "0.", ",", "1.", ")", ")", "\n", "\n", "# store spawn position in metadata. This allows sampling subsequent food items", "\n", "# close to previous food items", "\n", "env", ".", "metadata", "[", "f\"food{i}_initpos\"", "]", "=", "pos_grid", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.food.FoodHealthWrapper.reset": [[49, 68], ["food.FoodHealthWrapper.env.reset", "numpy.array", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "food.FoodHealthWrapper.observation", "numpy.ones", "sim.model.site_name2id", "range"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["                    ", "successful_placement", "=", "False", "\n", "", "", "else", ":", "\n", "                ", "floor", ".", "mark", "(", "f\"food{i}\"", ",", "rgba", "=", "(", "0.", ",", "1.", ",", "0.", ",", "1.", ")", ",", "\n", "size", "=", "(", "self", ".", "food_size", ",", "self", ".", "food_size", ",", "self", ".", "food_size", ")", ")", "\n", "", "", "return", "successful_placement", "\n", "\n", "", "def", "modify_sim_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "        ", "self", ".", "food_site_ids", "=", "np", ".", "array", "(", "[", "sim", ".", "model", ".", "site_name2id", "(", "f'food{i}'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "curr_n_food", ")", "]", ")", "\n", "\n", "", "def", "observation_step", "(", "self", ",", "env", ",", "sim", ")", ":", "\n", "        ", "if", "self", ".", "curr_n_food", ">", "0", ":", "\n", "            ", "obs", "=", "{", "'food_pos'", ":", "sim", ".", "data", ".", "site_xpos", "[", "self", ".", "food_site_ids", "]", "}", "\n", "", "else", ":", "\n", "            ", "obs", "=", "{", "'food_pos'", ":", "np", ".", "zeros", "(", "(", "0", ",", "3", ")", ")", "}", "\n", "", "return", "obs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.food.FoodHealthWrapper.observation": [[69, 78], ["numpy.concatenate", "numpy.concatenate", "numpy.ones"], "methods", ["None"], []], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.food.FoodHealthWrapper.step": [[79, 132], ["action.pop", "food.FoodHealthWrapper.env.step", "numpy.linalg.norm", "numpy.logical_and", "numpy.logical_and().astype", "numpy.sum", "numpy.sum", "numpy.maximum", "numpy.all", "food.FoodHealthWrapper.observation", "numpy.sum", "numpy.sum", "numpy.logical_and", "numpy.sum", "numpy.unique", "ValueError", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], []], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.food.AlwaysEatWrapper.__init__": [[140, 144], ["gym.ActionWrapper.__init__", "food.AlwaysEatWrapper.action_space.spaces.pop"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], []], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.food.AlwaysEatWrapper.action": [[145, 149], ["numpy.zeros"], "methods", ["None"], []], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.multi_agent.SplitMultiAgentActions.__init__": [[12, 20], ["gym.ActionWrapper.__init__", "numpy.split", "numpy.split", "gym.spaces.Dict", "gym.spaces.Tuple", "gym.spaces.Box", "zip"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "n_agents", "=", "self", ".", "metadata", "[", "'n_actors'", "]", "\n", "lows", "=", "np", ".", "split", "(", "self", ".", "action_space", ".", "low", ",", "self", ".", "n_agents", ")", "\n", "highs", "=", "np", ".", "split", "(", "self", ".", "action_space", ".", "high", ",", "self", ".", "n_agents", ")", "\n", "self", ".", "action_space", "=", "Dict", "(", "{", "\n", "'action_movement'", ":", "Tuple", "(", "[", "Box", "(", "low", "=", "low", ",", "high", "=", "high", ",", "dtype", "=", "self", ".", "action_space", ".", "dtype", ")", "\n", "for", "low", ",", "high", "in", "zip", "(", "lows", ",", "highs", ")", "]", ")", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.multi_agent.SplitMultiAgentActions.action": [[22, 24], ["action[].flatten"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "action", ")", ":", "\n", "        ", "return", "action", "[", "'action_movement'", "]", ".", "flatten", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.multi_agent.JoinMultiAgentActions.__init__": [[27, 33], ["gym.ActionWrapper.__init__", "numpy.concatenate", "numpy.concatenate", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "n_agents", "=", "self", ".", "metadata", "[", "'n_actors'", "]", "\n", "low", "=", "np", ".", "concatenate", "(", "[", "space", ".", "low", "for", "space", "in", "self", ".", "action_space", ".", "spaces", "]", ")", "\n", "high", "=", "np", ".", "concatenate", "(", "[", "space", ".", "high", "for", "space", "in", "self", ".", "action_space", ".", "spaces", "]", ")", "\n", "self", ".", "action_space", "=", "Box", "(", "low", "=", "low", ",", "high", "=", "high", ",", "dtype", "=", "self", ".", "action_space", ".", "spaces", "[", "0", "]", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.multi_agent.JoinMultiAgentActions.action": [[34, 37], ["numpy.split"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "action", ")", ":", "\n", "# action should be a tuple of different agent actions", "\n", "        ", "return", "np", ".", "split", "(", "action", ",", "self", ".", "n_agents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.multi_agent.SplitObservations.__init__": [[51, 85], ["gym.ObservationWrapper.__init__", "sorted", "sorted", "sorted", "multi_agent.SplitObservations.observation_space.spaces.items", "gym.spaces.Dict", "len", "gym.spaces.Box", "numpy.tile().reshape", "numpy.tile().reshape", "gym.spaces.Box", "copy.deepcopy", "numpy.tile().reshape().transpose", "numpy.tile().reshape().transpose", "gym.spaces.Box", "numpy.tile", "numpy.tile", "numpy.tile().reshape", "numpy.tile().reshape", "numpy.tile", "numpy.tile"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "keys_self", ",", "keys_copy", "=", "[", "]", ",", "keys_self_matrices", "=", "[", "]", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "keys_self", "=", "sorted", "(", "keys_self", ")", "\n", "self", ".", "keys_copy", "=", "sorted", "(", "keys_copy", ")", "\n", "self", ".", "keys_self_matrices", "=", "sorted", "(", "keys_self_matrices", ")", "\n", "self", ".", "n_agents", "=", "self", ".", "metadata", "[", "'n_agents'", "]", "\n", "new_spaces", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "observation_space", ".", "spaces", ".", "items", "(", ")", ":", "\n", "# If obs is a self obs, then we only want to include other agents obs,", "\n", "# as we will pass the self obs separately.", "\n", "            ", "assert", "len", "(", "v", ".", "shape", ")", ">", "1", ",", "f'Obs {k} has shape {v.shape}'", "\n", "if", "'mask'", "in", "k", "and", "k", "not", "in", "self", ".", "keys_self_matrices", ":", "\n", "                ", "new_spaces", "[", "k", "]", "=", "v", "\n", "", "elif", "k", "in", "self", ".", "keys_self_matrices", ":", "\n", "                ", "new_spaces", "[", "k", "]", "=", "Box", "(", "low", "=", "v", ".", "low", "[", ":", ",", "1", ":", "]", ",", "high", "=", "v", ".", "high", "[", ":", ",", "1", ":", "]", ",", "dtype", "=", "v", ".", "dtype", ")", "\n", "", "elif", "k", "in", "self", ".", "keys_self", ":", "\n", "                ", "assert", "v", ".", "shape", "[", "0", "]", "==", "self", ".", "n_agents", ",", "f\"For self obs, obs dim 0 should equal number of agents. {k} has shape {v.shape}\"", "\n", "obs_shape", "=", "(", "v", ".", "shape", "[", "0", "]", ",", "self", ".", "n_agents", "-", "1", ",", "v", ".", "shape", "[", "1", "]", ")", "\n", "lows", "=", "np", ".", "tile", "(", "v", ".", "low", ",", "self", ".", "n_agents", "-", "1", ")", ".", "reshape", "(", "obs_shape", ")", "\n", "highs", "=", "np", ".", "tile", "(", "v", ".", "high", ",", "self", ".", "n_agents", "-", "1", ")", ".", "reshape", "(", "obs_shape", ")", "\n", "new_spaces", "[", "k", "]", "=", "Box", "(", "low", "=", "lows", ",", "high", "=", "highs", ",", "dtype", "=", "v", ".", "dtype", ")", "\n", "", "elif", "k", "in", "self", ".", "keys_copy", ":", "\n", "                ", "new_spaces", "[", "k", "]", "=", "deepcopy", "(", "v", ")", "\n", "", "else", ":", "\n", "                ", "obs_shape", "=", "(", "v", ".", "shape", "[", "0", "]", ",", "self", ".", "n_agents", ",", "v", ".", "shape", "[", "1", "]", ")", "\n", "lows", "=", "np", ".", "tile", "(", "v", ".", "low", ",", "self", ".", "n_agents", ")", ".", "reshape", "(", "obs_shape", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "highs", "=", "np", ".", "tile", "(", "v", ".", "high", ",", "self", ".", "n_agents", ")", ".", "reshape", "(", "obs_shape", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "new_spaces", "[", "k", "]", "=", "Box", "(", "low", "=", "lows", ",", "high", "=", "highs", ",", "dtype", "=", "v", ".", "dtype", ")", "\n", "\n", "", "", "for", "k", "in", "self", ".", "keys_self", ":", "\n", "            ", "new_spaces", "[", "k", "+", "'_self'", "]", "=", "self", ".", "observation_space", ".", "spaces", "[", "k", "]", "\n", "\n", "", "self", ".", "observation_space", "=", "Dict", "(", "new_spaces", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.multi_agent.SplitObservations.observation": [[86, 107], ["obs.items", "multi_agent.SplitObservations._process_self_matrix", "numpy.tile().reshape().transpose", "scipy.linalg.circulant", "numpy.arange", "numpy.tile().reshape", "numpy.tile"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.multi_agent.SplitObservations._process_self_matrix"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "new_obs", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "obs", ".", "items", "(", ")", ":", "\n", "# Masks that aren't self matrices should just be copied", "\n", "            ", "if", "'mask'", "in", "k", "and", "k", "not", "in", "self", ".", "keys_self_matrices", ":", "\n", "                ", "new_obs", "[", "k", "]", "=", "obs", "[", "k", "]", "\n", "# Circulant self matrices", "\n", "", "elif", "k", "in", "self", ".", "keys_self_matrices", ":", "\n", "                ", "new_obs", "[", "k", "]", "=", "self", ".", "_process_self_matrix", "(", "obs", "[", "k", "]", ")", "\n", "# Circulant self keys", "\n", "", "elif", "k", "in", "self", ".", "keys_self", ":", "\n", "                ", "new_obs", "[", "k", "+", "'_self'", "]", "=", "obs", "[", "k", "]", "\n", "new_obs", "[", "k", "]", "=", "obs", "[", "k", "]", "[", "circulant", "(", "np", ".", "arange", "(", "self", ".", "n_agents", ")", ")", "]", "\n", "new_obs", "[", "k", "]", "=", "new_obs", "[", "k", "]", "[", ":", ",", "1", ":", ",", ":", "]", "# Remove self observation", "\n", "", "elif", "k", "in", "self", ".", "keys_copy", ":", "\n", "                ", "new_obs", "[", "k", "]", "=", "obs", "[", "k", "]", "\n", "# Everything else should just get copied for each agent (e.g. external obs)", "\n", "", "else", ":", "\n", "                ", "new_obs", "[", "k", "]", "=", "np", ".", "tile", "(", "v", ",", "self", ".", "n_agents", ")", ".", "reshape", "(", "[", "v", ".", "shape", "[", "0", "]", ",", "self", ".", "n_agents", ",", "v", ".", "shape", "[", "1", "]", "]", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "\n", "", "", "return", "new_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.multi_agent.SplitObservations._process_self_matrix": [[108, 123], ["numpy.all", "multi_agent.SplitObservations.copy", "scipy.linalg.circulant", "numpy.arange", "numpy.array", "numpy.arange"], "methods", ["None"], ["", "def", "_process_self_matrix", "(", "self", ",", "self_matrix", ")", ":", "\n", "        ", "'''\n            self_matrix will be a (n_agent, n_agent) boolean matrix. Permute each row such that the matrix is consistent with\n                the circulant permutation used for self observations. E.g. this should be used for agent agent masks\n        '''", "\n", "assert", "np", ".", "all", "(", "self_matrix", ".", "shape", "[", ":", "2", "]", "==", "np", ".", "array", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_agents", ")", ")", ")", ",", "f\"The first two dimensions of {self_matrix} were not (n_agents, n_agents)\"", "\n", "\n", "new_mat", "=", "self_matrix", ".", "copy", "(", ")", "\n", "# Permute each row to the right by one more than the previous", "\n", "# E.g., [[1,2],[3,4]] -> [[1,2],[4,3]]", "\n", "idx", "=", "circulant", "(", "np", ".", "arange", "(", "self", ".", "n_agents", ")", ")", "\n", "new_mat", "=", "new_mat", "[", "np", ".", "arange", "(", "self", ".", "n_agents", ")", "[", ":", ",", "None", "]", ",", "idx", "]", "\n", "new_mat", "=", "new_mat", "[", ":", ",", "1", ":", "]", "# Remove self observation", "\n", "return", "new_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.multi_agent.SelectKeysWrapper.__init__": [[136, 158], ["gym.ObservationWrapper.__init__", "sorted", "sorted", "sum", "gym.spaces.Dict", "sum", "multi_agent.SelectKeysWrapper.update", "gym.spaces.Dict", "gym.spaces.Box", "gym.spaces.Box", "numpy.prod", "gym.spaces.Box", "multi_agent.SelectKeysWrapper.observation_space.spaces.items"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "keys_self", ",", "keys_other", ",", "flatten", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "keys_self", "=", "sorted", "(", "[", "k", "+", "'_self'", "for", "k", "in", "keys_self", "]", ")", "\n", "self", ".", "keys_other", "=", "sorted", "(", "keys_other", ")", "\n", "self", ".", "flatten", "=", "flatten", "\n", "\n", "# Change observation space to look like a single agent observation space.", "\n", "# This makes constructing policies much easier", "\n", "if", "flatten", ":", "\n", "            ", "size_self", "=", "sum", "(", "[", "np", ".", "prod", "(", "self", ".", "env", ".", "observation_space", ".", "spaces", "[", "k", "]", ".", "shape", "[", "1", ":", "]", ")", "\n", "for", "k", "in", "self", ".", "keys_self", "+", "self", ".", "keys_other", "]", ")", "\n", "self", ".", "observation_space", "=", "Dict", "(", "\n", "{", "'observation_self'", ":", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "(", "size_self", ",", ")", ",", "np", ".", "float32", ")", "}", ")", "\n", "", "else", ":", "\n", "            ", "size_self", "=", "sum", "(", "[", "self", ".", "env", ".", "observation_space", ".", "spaces", "[", "k", "]", ".", "shape", "[", "1", "]", "\n", "for", "k", "in", "self", ".", "keys_self", "]", ")", "\n", "obs_self", "=", "{", "'observation_self'", ":", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "(", "size_self", ",", ")", ",", "np", ".", "float32", ")", "}", "\n", "obs_extern", "=", "{", "k", ":", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "v", ".", "shape", "[", "1", ":", "]", ",", "np", ".", "float32", ")", "\n", "for", "k", ",", "v", "in", "self", ".", "observation_space", ".", "spaces", ".", "items", "(", ")", "\n", "if", "k", "in", "self", ".", "keys_other", "}", "\n", "obs_self", ".", "update", "(", "obs_extern", ")", "\n", "self", ".", "observation_space", "=", "Dict", "(", "obs_self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.multi_agent.SelectKeysWrapper.observation": [[159, 171], ["numpy.concatenate", "numpy.concatenate", "numpy.concatenate.update", "observation[].reshape", "observation.items"], "methods", ["None"], ["", "", "def", "observation", "(", "self", ",", "observation", ")", ":", "\n", "        ", "if", "self", ".", "flatten", ":", "\n", "            ", "other_obs", "=", "[", "observation", "[", "k", "]", ".", "reshape", "(", "(", "observation", "[", "k", "]", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "for", "k", "in", "self", ".", "keys_other", "]", "\n", "obs", "=", "np", ".", "concatenate", "(", "[", "observation", "[", "k", "]", "for", "k", "in", "self", ".", "keys_self", "]", "+", "other_obs", ",", "axis", "=", "-", "1", ")", "\n", "return", "{", "'observation_self'", ":", "obs", "}", "\n", "", "else", ":", "\n", "            ", "obs", "=", "np", ".", "concatenate", "(", "[", "observation", "[", "k", "]", "for", "k", "in", "self", ".", "keys_self", "]", ",", "-", "1", ")", "\n", "obs", "=", "{", "'observation_self'", ":", "obs", "}", "\n", "other_obs", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "observation", ".", "items", "(", ")", "if", "k", "in", "self", ".", "keys_other", "}", "\n", "obs", ".", "update", "(", "other_obs", ")", "\n", "return", "obs", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.manipulation.GrabObjWrapper.__init__": [[27, 45], ["gym.Wrapper.__init__", "len", "gym.spaces.Tuple", "mae_envs.wrappers.util.update_obs_space", "gym.spaces.MultiDiscrete", "range"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], ["def", "__init__", "(", "self", ",", "env", ",", "body_names", ",", "radius_multiplier", "=", "1.7", ",", "\n", "grab_dist", "=", "None", ",", "grab_exclusive", "=", "False", ",", "\n", "obj_in_game_metadata_keys", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "n_agents", "=", "self", ".", "unwrapped", ".", "n_agents", "\n", "self", ".", "body_names", "=", "body_names", "\n", "self", ".", "n_obj", "=", "len", "(", "body_names", ")", "\n", "self", ".", "obj_in_game_metadata_keys", "=", "obj_in_game_metadata_keys", "\n", "self", ".", "action_space", ".", "spaces", "[", "'action_pull'", "]", "=", "(", "\n", "Tuple", "(", "[", "MultiDiscrete", "(", "[", "2", "]", "*", "self", ".", "n_obj", ")", "for", "_", "in", "range", "(", "self", ".", "n_agents", ")", "]", ")", ")", "\n", "\n", "self", ".", "observation_space", "=", "update_obs_space", "(", "\n", "env", ",", "{", "'obj_pull'", ":", "(", "self", ".", "n_obj", ",", "1", ")", ",", "\n", "'you_pull'", ":", "(", "self", ".", "n_obj", ",", "self", ".", "n_agents", ")", "}", ")", "\n", "\n", "self", ".", "grab_radius", "=", "radius_multiplier", "*", "self", ".", "metadata", "[", "'box_size'", "]", "\n", "self", ".", "grab_dist", "=", "grab_dist", "\n", "self", ".", "grab_exclusive", "=", "grab_exclusive", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.manipulation.GrabObjWrapper.observation": [[46, 50], ["numpy.any"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "[", "'you_pull'", "]", "=", "self", ".", "obj_grabbed", ".", "T", "\n", "obs", "[", "'obj_pull'", "]", "=", "np", ".", "any", "(", "obs", "[", "'you_pull'", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.manipulation.GrabObjWrapper.reset": [[51, 82], ["manipulation.GrabObjWrapper.env.reset", "list", "len", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.zeros", "numpy.zeros", "manipulation.GrabObjWrapper.observation", "numpy.concatenate", "numpy.ones().astype", "itertools.compress", "len", "sim.model.body_name2id", "sim.model.body_name2id", "sim.model.geom_name2id", "sim.model.geom_name2id", "numpy.ones", "range", "range", "enumerate", "len"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "sim", "=", "self", ".", "unwrapped", ".", "sim", "\n", "\n", "if", "self", ".", "obj_in_game_metadata_keys", "is", "not", "None", ":", "\n", "            ", "self", ".", "actual_body_slice", "=", "np", ".", "concatenate", "(", "[", "self", ".", "metadata", "[", "k", "]", "for", "k", "in", "self", ".", "obj_in_game_metadata_keys", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "actual_body_slice", "=", "np", ".", "ones", "(", "(", "len", "(", "self", ".", "body_names", ")", ")", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "", "actual_body_names", "=", "list", "(", "compress", "(", "self", ".", "body_names", ",", "self", ".", "actual_body_slice", ")", ")", "\n", "self", ".", "n_obj", "=", "len", "(", "actual_body_names", ")", "\n", "\n", "# Cache body ids", "\n", "self", ".", "obj_body_idxs", "=", "np", ".", "array", "(", "[", "sim", ".", "model", ".", "body_name2id", "(", "body_name", ")", "for", "body_name", "in", "actual_body_names", "]", ")", "\n", "self", ".", "agent_body_idxs", "=", "np", ".", "array", "(", "[", "sim", ".", "model", ".", "body_name2id", "(", "f\"agent{i}:particle\"", ")", "for", "i", "in", "range", "(", "self", ".", "n_agents", ")", "]", ")", "\n", "\n", "# Cache geom ids", "\n", "self", ".", "obj_geom_ids", "=", "np", ".", "array", "(", "[", "sim", ".", "model", ".", "geom_name2id", "(", "body_name", ")", "for", "body_name", "in", "actual_body_names", "]", ")", "\n", "self", ".", "agent_geom_ids", "=", "np", ".", "array", "(", "[", "sim", ".", "model", ".", "geom_name2id", "(", "f'agent{i}:agent'", ")", "for", "i", "in", "range", "(", "self", ".", "n_agents", ")", "]", ")", "\n", "\n", "# Cache constraint ids", "\n", "self", ".", "agent_eq_ids", "=", "np", ".", "array", "(", "\n", "[", "i", "for", "i", ",", "obj1", "in", "enumerate", "(", "sim", ".", "model", ".", "eq_obj1id", ")", "\n", "if", "sim", ".", "model", ".", "body_names", "[", "obj1", "]", "==", "f\"agent{i}:particle\"", "]", ")", "\n", "assert", "len", "(", "self", ".", "agent_eq_ids", ")", "==", "self", ".", "n_agents", "\n", "\n", "# turn off equality constraints", "\n", "sim", ".", "model", ".", "eq_active", "[", "self", ".", "agent_eq_ids", "]", "=", "0", "\n", "self", ".", "obj_grabbed", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_obj", ")", ",", "dtype", "=", "bool", ")", "\n", "self", ".", "last_obj_grabbed", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_obj", ")", ",", "dtype", "=", "bool", ")", "\n", "\n", "return", "self", ".", "observation", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.manipulation.GrabObjWrapper.grab_obj": [[83, 155], ["mae_envs.util.geometry.dist_pt_to_cuboid", "numpy.logical_and", "mae_envs.util.geometry.dist_pt_to_cuboid.copy", "numpy.any", "numpy.zeros", "numpy.logical_and", "len", "len", "numpy.zeros", "numpy.any", "numpy.argmin", "numpy.argwhere", "numpy.any", "numpy.argwhere", "sim.data.body_xmat[].reshape", "sim.data.body_xmat[].reshape", "numpy.matmul", "mujoco_worldgen.util.rotation.mat2quat", "numpy.unravel_index", "numpy.matmul", "numpy.argmin", "numpy.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.util.geometry.dist_pt_to_cuboid"], ["", "def", "grab_obj", "(", "self", ",", "action", ")", ":", "\n", "        ", "'''\n            Implements object grabbing for all agents\n            Args:\n                action: Action dictionary\n        '''", "\n", "action_pull", "=", "action", "[", "'action_pull'", "]", "[", ":", ",", "self", ".", "actual_body_slice", "]", "\n", "sim", "=", "self", ".", "unwrapped", ".", "sim", "\n", "\n", "agent_pos", "=", "sim", ".", "data", ".", "body_xpos", "[", "self", ".", "agent_body_idxs", "]", "\n", "obj_pos", "=", "sim", ".", "data", ".", "body_xpos", "[", "self", ".", "obj_body_idxs", "]", "\n", "\n", "obj_width", "=", "sim", ".", "model", ".", "geom_size", "[", "self", ".", "obj_geom_ids", "]", "\n", "obj_quat", "=", "sim", ".", "data", ".", "body_xquat", "[", "self", ".", "obj_body_idxs", "]", "\n", "assert", "len", "(", "obj_width", ")", "==", "len", "(", "obj_quat", ")", ",", "(", "\n", "\"Number of object widths must be equal to number of quaternions for direct distance calculation method. \"", "+", "\n", "\"This might be caused by a body that contains several geoms.\"", ")", "\n", "obj_dist", "=", "dist_pt_to_cuboid", "(", "agent_pos", ",", "obj_pos", ",", "obj_width", ",", "obj_quat", ")", "\n", "\n", "allowed_and_desired", "=", "np", ".", "logical_and", "(", "action_pull", ",", "obj_dist", "<=", "self", ".", "grab_radius", ")", "\n", "obj_dist_masked", "=", "obj_dist", ".", "copy", "(", ")", "# Mask the obj dists to find a valid argmin", "\n", "obj_dist_masked", "[", "~", "allowed_and_desired", "]", "=", "np", ".", "inf", "\n", "\n", "if", "self", ".", "grab_exclusive", ":", "\n", "            ", "closest_obj", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", ")", ",", "dtype", "=", "int", ")", "\n", "\n", "while", "np", ".", "any", "(", "obj_dist_masked", "<", "np", ".", "inf", ")", ":", "\n", "# find agent and object of closest object distance", "\n", "                ", "agent_idx", ",", "obj_idx", "=", "np", ".", "unravel_index", "(", "np", ".", "argmin", "(", "obj_dist_masked", ")", ",", "obj_dist_masked", ".", "shape", ")", "\n", "# set closest object for this agent", "\n", "closest_obj", "[", "agent_idx", "]", "=", "obj_idx", "\n", "# ensure exclusivity of grabbing", "\n", "obj_dist_masked", "[", ":", ",", "obj_idx", "]", "=", "np", ".", "inf", "\n", "obj_dist_masked", "[", "agent_idx", ",", ":", "]", "=", "np", ".", "inf", "\n", "# mark same object as undesired for all other agents", "\n", "allowed_and_desired", "[", ":", "agent_idx", ",", "obj_idx", "]", "=", "False", "\n", "allowed_and_desired", "[", "(", "agent_idx", "+", "1", ")", ":", ",", "obj_idx", "]", "=", "False", "\n", "", "", "else", ":", "\n", "            ", "closest_obj", "=", "np", ".", "argmin", "(", "obj_dist_masked", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "valid_grabs", "=", "np", ".", "any", "(", "allowed_and_desired", ",", "axis", "=", "-", "1", ")", "# (n_agent,) which agents have valid grabs", "\n", "\n", "# Turn on/off agents with valid grabs", "\n", "sim", ".", "model", ".", "eq_active", "[", "self", ".", "agent_eq_ids", "]", "=", "valid_grabs", "\n", "sim", ".", "model", ".", "eq_obj2id", "[", "self", ".", "agent_eq_ids", "]", "=", "self", ".", "obj_body_idxs", "[", "closest_obj", "]", "\n", "\n", "# keep track of which object is being grabbed", "\n", "self", ".", "obj_grabbed", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_obj", ")", ",", "dtype", "=", "bool", ")", "\n", "agent_with_valid_grab", "=", "np", ".", "argwhere", "(", "valid_grabs", ")", "[", ":", ",", "0", "]", "\n", "self", ".", "obj_grabbed", "[", "agent_with_valid_grab", ",", "closest_obj", "[", "agent_with_valid_grab", "]", "]", "=", "1", "\n", "\n", "# If there are new grabs, then setup the weld constraint parameters", "\n", "new_grabs", "=", "np", ".", "logical_and", "(", "\n", "valid_grabs", ",", "np", ".", "any", "(", "self", ".", "obj_grabbed", "!=", "self", ".", "last_obj_grabbed", ",", "axis", "=", "-", "1", ")", ")", "\n", "for", "agent_idx", "in", "np", ".", "argwhere", "(", "new_grabs", ")", "[", ":", ",", "0", "]", ":", "\n", "            ", "agent_rot", "=", "sim", ".", "data", ".", "body_xmat", "[", "self", ".", "agent_body_idxs", "[", "agent_idx", "]", "]", ".", "reshape", "(", "(", "3", ",", "3", ")", ")", "\n", "obj_rot", "=", "sim", ".", "data", ".", "body_xmat", "[", "self", ".", "obj_body_idxs", "[", "closest_obj", "[", "agent_idx", "]", "]", "]", ".", "reshape", "(", "(", "3", ",", "3", ")", ")", "\n", "# Need to use the geom xpos rather than the qpos", "\n", "obj_pos", "=", "sim", ".", "data", ".", "body_xpos", "[", "self", ".", "obj_body_idxs", "[", "closest_obj", "[", "agent_idx", "]", "]", "]", "\n", "agent_pos", "=", "sim", ".", "data", ".", "body_xpos", "[", "self", ".", "agent_body_idxs", "[", "agent_idx", "]", "]", "\n", "\n", "grab_vec", "=", "agent_pos", "-", "obj_pos", "\n", "\n", "if", "self", ".", "grab_dist", "is", "not", "None", ":", "\n", "                ", "grab_vec", "=", "self", ".", "grab_dist", "/", "(", "1e-3", "+", "np", ".", "linalg", ".", "norm", "(", "grab_vec", ")", ")", "*", "grab_vec", "\n", "\n", "# The distance constraint needs to be rotated into the frame of reference of the agent", "\n", "", "sim", ".", "model", ".", "eq_data", "[", "self", ".", "agent_eq_ids", "[", "agent_idx", "]", ",", ":", "3", "]", "=", "np", ".", "matmul", "(", "agent_rot", ".", "T", ",", "grab_vec", ")", "\n", "# The angle constraint is the difference between the agents frame and the objects frame", "\n", "sim", ".", "model", ".", "eq_data", "[", "self", ".", "agent_eq_ids", "[", "agent_idx", "]", ",", "3", ":", "]", "=", "mat2quat", "(", "np", ".", "matmul", "(", "agent_rot", ".", "T", ",", "obj_rot", ")", ")", "\n", "\n", "", "self", ".", "last_obj_grabbed", "=", "self", ".", "obj_grabbed", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.manipulation.GrabObjWrapper.step": [[156, 160], ["manipulation.GrabObjWrapper.grab_obj", "manipulation.GrabObjWrapper.env.step", "manipulation.GrabObjWrapper.observation"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.manipulation.GrabObjWrapper.grab_obj", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "self", ".", "grab_obj", "(", "action", ")", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "return", "self", ".", "observation", "(", "obs", ")", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.manipulation.GrabClosestWrapper.__init__": [[168, 174], ["gym.ActionWrapper.__init__", "copy.deepcopy", "len", "gym.spaces.Tuple", "gym.spaces.Discrete", "range"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "action_space", "=", "deepcopy", "(", "self", ".", "action_space", ")", "\n", "self", ".", "n_obj", "=", "len", "(", "self", ".", "action_space", ".", "spaces", "[", "'action_pull'", "]", ".", "spaces", "[", "0", "]", ".", "nvec", ")", "\n", "self", ".", "action_space", ".", "spaces", "[", "'action_pull'", "]", "=", "(", "\n", "Tuple", "(", "[", "Discrete", "(", "2", ")", "for", "_", "in", "range", "(", "self", ".", "unwrapped", ".", "n_agents", ")", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.manipulation.GrabClosestWrapper.action": [[175, 179], ["copy.deepcopy", "numpy.repeat"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "action", ")", ":", "\n", "        ", "action", "=", "deepcopy", "(", "action", ")", "\n", "action", "[", "'action_pull'", "]", "=", "np", ".", "repeat", "(", "action", "[", "'action_pull'", "]", "[", ":", ",", "None", "]", ",", "self", ".", "n_obj", ",", "-", "1", ")", "\n", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.manipulation.LockObjWrapper.__init__": [[205, 224], ["gym.Wrapper.__init__", "len", "gym.spaces.Tuple", "mae_envs.wrappers.util.update_obs_space", "numpy.zeros", "numpy.arange", "gym.spaces.MultiDiscrete", "range"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], ["def", "__init__", "(", "self", ",", "env", ",", "body_names", ",", "radius_multiplier", "=", "1.5", ",", "agent_idx_allowed_to_lock", "=", "None", ",", "\n", "lock_type", "=", "\"any_lock\"", ",", "ac_obs_prefix", "=", "''", ",", "obj_in_game_metadata_keys", "=", "None", ",", "\n", "agent_allowed_to_lock_keys", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "n_agents", "=", "self", ".", "unwrapped", ".", "n_agents", "\n", "self", ".", "n_obj", "=", "len", "(", "body_names", ")", "\n", "self", ".", "body_names", "=", "body_names", "\n", "self", ".", "agent_idx_allowed_to_lock", "=", "np", ".", "arange", "(", "self", ".", "n_agents", ")", "if", "agent_idx_allowed_to_lock", "is", "None", "else", "agent_idx_allowed_to_lock", "\n", "self", ".", "lock_type", "=", "lock_type", "\n", "self", ".", "ac_obs_prefix", "=", "ac_obs_prefix", "\n", "self", ".", "obj_in_game_metadata_keys", "=", "obj_in_game_metadata_keys", "\n", "self", ".", "agent_allowed_to_lock_keys", "=", "agent_allowed_to_lock_keys", "\n", "self", ".", "action_space", ".", "spaces", "[", "f'action_{ac_obs_prefix}glue'", "]", "=", "(", "\n", "Tuple", "(", "[", "MultiDiscrete", "(", "[", "2", "]", "*", "self", ".", "n_obj", ")", "for", "_", "in", "range", "(", "self", ".", "n_agents", ")", "]", ")", ")", "\n", "self", ".", "observation_space", "=", "update_obs_space", "(", "env", ",", "{", "f'{ac_obs_prefix}obj_lock'", ":", "(", "self", ".", "n_obj", ",", "1", ")", ",", "\n", "f'{ac_obs_prefix}you_lock'", ":", "(", "self", ".", "n_agents", ",", "self", ".", "n_obj", ",", "1", ")", ",", "\n", "f'{ac_obs_prefix}team_lock'", ":", "(", "self", ".", "n_agents", ",", "self", ".", "n_obj", ",", "1", ")", "}", ")", "\n", "self", ".", "lock_radius", "=", "radius_multiplier", "*", "self", ".", "metadata", "[", "'box_size'", "]", "\n", "self", ".", "obj_locked", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_obj", ",", ")", ",", "dtype", "=", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.manipulation.LockObjWrapper.observation": [[225, 234], ["numpy.expand_dims", "numpy.zeros", "numpy.unique", "numpy.any", "numpy.arange"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "[", "f'{self.ac_obs_prefix}obj_lock'", "]", "=", "self", ".", "obj_locked", "[", ":", ",", "None", "]", "\n", "you_lock", "=", "np", ".", "arange", "(", "self", ".", "n_agents", ")", "[", ":", ",", "None", "]", "==", "self", ".", "which_locked", "[", "None", ",", ":", "]", "\n", "obs", "[", "f'{self.ac_obs_prefix}you_lock'", "]", "=", "np", ".", "expand_dims", "(", "you_lock", "*", "obs", "[", "f'{self.ac_obs_prefix}obj_lock'", "]", ".", "T", ",", "axis", "=", "-", "1", ")", "\n", "obs", "[", "f'{self.ac_obs_prefix}team_lock'", "]", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_obj", ",", "1", ")", ")", "\n", "for", "team", "in", "np", ".", "unique", "(", "self", ".", "metadata", "[", "'team_index'", "]", ")", ":", "\n", "            ", "team_mask", "=", "self", ".", "metadata", "[", "'team_index'", "]", "==", "team", "\n", "obs", "[", "f'{self.ac_obs_prefix}team_lock'", "]", "[", "team_mask", "]", "=", "np", ".", "any", "(", "obs", "[", "f'{self.ac_obs_prefix}you_lock'", "]", "[", "team_mask", "]", ",", "0", ")", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.manipulation.LockObjWrapper.reset": [[235, 266], ["manipulation.LockObjWrapper.env.reset", "list", "len", "numpy.array", "numpy.array", "numpy.array", "manipulation.LockObjWrapper.unlock_objs", "numpy.zeros", "numpy.zeros", "manipulation.LockObjWrapper.observation", "numpy.concatenate", "numpy.ones().astype", "itertools.compress", "numpy.concatenate", "numpy.ones", "sim.model.body_name2id", "numpy.where", "numpy.where", "sim.model.body_name2id", "sim.model.geom_name2id", "numpy.ones", "range", "range", "len"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.manipulation.LockObjWrapper.unlock_objs", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "sim", "=", "self", ".", "unwrapped", ".", "sim", "\n", "\n", "if", "self", ".", "obj_in_game_metadata_keys", "is", "not", "None", ":", "\n", "            ", "self", ".", "actual_body_slice", "=", "np", ".", "concatenate", "(", "[", "self", ".", "metadata", "[", "k", "]", "for", "k", "in", "self", ".", "obj_in_game_metadata_keys", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "actual_body_slice", "=", "np", ".", "ones", "(", "(", "len", "(", "self", ".", "body_names", ")", ")", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "\n", "", "actual_body_names", "=", "list", "(", "compress", "(", "self", ".", "body_names", ",", "self", ".", "actual_body_slice", ")", ")", "\n", "self", ".", "n_obj", "=", "len", "(", "actual_body_names", ")", "\n", "\n", "# Cache ids", "\n", "self", ".", "obj_body_idxs", "=", "np", ".", "array", "(", "[", "sim", ".", "model", ".", "body_name2id", "(", "body_name", ")", "for", "body_name", "in", "actual_body_names", "]", ")", "\n", "self", ".", "obj_jnt_idxs", "=", "[", "np", ".", "where", "(", "sim", ".", "model", ".", "jnt_bodyid", "==", "body_idx", ")", "[", "0", "]", "for", "body_idx", "in", "self", ".", "obj_body_idxs", "]", "\n", "self", ".", "obj_geom_ids", "=", "[", "np", ".", "where", "(", "sim", ".", "model", ".", "geom_bodyid", "==", "body_idx", ")", "[", "0", "]", "for", "body_idx", "in", "self", ".", "obj_body_idxs", "]", "\n", "self", ".", "agent_body_idxs", "=", "np", ".", "array", "(", "[", "sim", ".", "model", ".", "body_name2id", "(", "f\"agent{i}:particle\"", ")", "for", "i", "in", "range", "(", "self", ".", "n_agents", ")", "]", ")", "\n", "self", ".", "agent_body_idxs", "=", "self", ".", "agent_body_idxs", "[", "self", ".", "agent_idx_allowed_to_lock", "]", "\n", "self", ".", "agent_geom_ids", "=", "np", ".", "array", "(", "[", "sim", ".", "model", ".", "geom_name2id", "(", "f'agent{i}:agent'", ")", "for", "i", "in", "range", "(", "self", ".", "n_agents", ")", "]", ")", "\n", "self", ".", "agent_geom_ids", "=", "self", ".", "agent_geom_ids", "[", "self", ".", "agent_idx_allowed_to_lock", "]", "\n", "\n", "self", ".", "unlock_objs", "(", ")", "\n", "self", ".", "obj_locked", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_obj", ",", ")", ",", "dtype", "=", "bool", ")", "\n", "self", ".", "which_locked", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_obj", ",", ")", ",", "dtype", "=", "int", ")", "\n", "\n", "if", "self", ".", "agent_allowed_to_lock_keys", "is", "not", "None", ":", "\n", "            ", "self", ".", "agent_allowed_to_lock_mask", "=", "np", ".", "concatenate", "(", "[", "obs", "[", "k", "]", "for", "k", "in", "self", ".", "agent_allowed_to_lock_keys", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "agent_allowed_to_lock_mask", "=", "np", ".", "ones", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_obj", ")", ")", "\n", "\n", "", "return", "self", ".", "observation", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.manipulation.LockObjWrapper.lock_obj": [[267, 347], ["mae_envs.util.geometry.dist_pt_to_cuboid", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "numpy.isin", "numpy.isin", "numpy.logical_or", "len", "len", "numpy.any", "numpy.logical_and", "numpy.logical_and", "numpy.argwhere", "numpy.random.choice", "numpy.logical_and", "numpy.concatenate", "numpy.any", "numpy.any", "numpy.logical_and", "numpy.logical_and", "numpy.isin", "numpy.isin", "numpy.any", "numpy.logical_and", "numpy.logical_and", "numpy.any", "numpy.any", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "numpy.argwhere", "numpy.random.choice", "numpy.logical_and", "numpy.any", "numpy.logical_and", "numpy.logical_and", "numpy.argwhere().flatten", "numpy.arange", "numpy.any", "numpy.argwhere", "numpy.argwhere().flatten", "numpy.argwhere"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.util.geometry.dist_pt_to_cuboid"], ["", "def", "lock_obj", "(", "self", ",", "action_lock", ")", ":", "\n", "        ", "'''\n            Implements object gluing for all agents\n            Args:\n                lock: (n_agent, n_obj) boolean matrix\n        '''", "\n", "sim", "=", "self", ".", "unwrapped", ".", "sim", "\n", "action_lock", "=", "action_lock", "[", "self", ".", "agent_idx_allowed_to_lock", "]", "\n", "action_lock", "=", "action_lock", "[", ":", ",", "self", ".", "actual_body_slice", "]", "\n", "agent_pos", "=", "sim", ".", "data", ".", "body_xpos", "[", "self", ".", "agent_body_idxs", "]", "\n", "obj_pos", "=", "sim", ".", "data", ".", "body_xpos", "[", "self", ".", "obj_body_idxs", "]", "\n", "\n", "obj_width", "=", "sim", ".", "model", ".", "geom_size", "[", "np", ".", "concatenate", "(", "self", ".", "obj_geom_ids", ")", "]", "\n", "obj_quat", "=", "sim", ".", "data", ".", "body_xquat", "[", "self", ".", "obj_body_idxs", "]", "\n", "assert", "len", "(", "obj_width", ")", "==", "len", "(", "obj_quat", ")", ",", "(", "\n", "\"Number of object widths must be equal to number of quaternions for direct distance calculation method. \"", "+", "\n", "\"This might be caused by a body that contains several geoms.\"", ")", "\n", "obj_dist", "=", "dist_pt_to_cuboid", "(", "agent_pos", ",", "obj_pos", ",", "obj_width", ",", "obj_quat", ")", "\n", "\n", "allowed_and_desired", "=", "np", ".", "logical_and", "(", "action_lock", ",", "obj_dist", "<=", "self", ".", "lock_radius", ")", "\n", "allowed_and_desired", "=", "np", ".", "logical_and", "(", "allowed_and_desired", ",", "self", ".", "agent_allowed_to_lock_mask", ")", "\n", "allowed_and_not_desired", "=", "np", ".", "logical_and", "(", "1", "-", "action_lock", ",", "obj_dist", "<=", "self", ".", "lock_radius", ")", "\n", "allowed_and_not_desired", "=", "np", ".", "logical_and", "(", "allowed_and_not_desired", ",", "self", ".", "agent_allowed_to_lock_mask", ")", "\n", "\n", "# objs_to_lock should _all_ be locked this round. new_objs_to_lock are objs that were not locked last round", "\n", "# objs_to_unlock are objs that no one wants to lock this round", "\n", "if", "self", ".", "lock_type", "==", "\"any_lock\"", ":", "# If any agent wants to lock, the obj becomes locked", "\n", "            ", "objs_to_lock", "=", "np", ".", "any", "(", "allowed_and_desired", ",", "axis", "=", "0", ")", "\n", "objs_to_unlock", "=", "np", ".", "logical_and", "(", "np", ".", "any", "(", "allowed_and_not_desired", ",", "axis", "=", "0", ")", ",", "~", "objs_to_lock", ")", "\n", "new_objs_to_lock", "=", "np", ".", "logical_and", "(", "objs_to_lock", ",", "~", "self", ".", "obj_locked", ")", "\n", "", "elif", "self", ".", "lock_type", "==", "\"all_lock\"", ":", "# All agents that are close enough must want to lock the obj", "\n", "            ", "objs_to_unlock", "=", "np", ".", "any", "(", "allowed_and_not_desired", ",", "axis", "=", "0", ")", "\n", "objs_to_lock", "=", "np", ".", "logical_and", "(", "np", ".", "any", "(", "allowed_and_desired", ",", "axis", "=", "0", ")", ",", "~", "objs_to_unlock", ")", "\n", "new_objs_to_lock", "=", "np", ".", "logical_and", "(", "objs_to_lock", ",", "~", "self", ".", "obj_locked", ")", "\n", "", "elif", "self", ".", "lock_type", "==", "\"any_lock_specific\"", ":", "# If any agent wants to lock, the obj becomes locked", "\n", "            ", "allowed_to_unlock", "=", "np", ".", "arange", "(", "self", ".", "n_agents", ")", "[", ":", ",", "None", "]", "==", "self", ".", "which_locked", "[", "None", ",", ":", "]", "# (n_agent, n_obj)", "\n", "allowed_to_unlock", "=", "np", ".", "logical_and", "(", "allowed_to_unlock", ",", "self", ".", "obj_locked", "[", "None", ",", ":", "]", ")", "# Can't unlock an obj that isn't locked", "\n", "allowed_and_not_desired", "=", "np", ".", "logical_and", "(", "allowed_to_unlock", "[", "self", ".", "agent_idx_allowed_to_lock", "]", ",", "\n", "allowed_and_not_desired", ")", "\n", "objs_to_unlock", "=", "np", ".", "any", "(", "allowed_and_not_desired", ",", "axis", "=", "0", ")", "\n", "objs_to_lock", "=", "np", ".", "any", "(", "allowed_and_desired", ",", "axis", "=", "0", ")", "\n", "objs_to_relock", "=", "np", ".", "logical_and", "(", "objs_to_unlock", ",", "objs_to_lock", ")", "\n", "new_objs_to_lock", "=", "np", ".", "logical_and", "(", "np", ".", "logical_and", "(", "objs_to_lock", ",", "~", "objs_to_relock", ")", ",", "~", "self", ".", "obj_locked", ")", "\n", "objs_to_unlock", "=", "np", ".", "logical_and", "(", "objs_to_unlock", ",", "~", "objs_to_lock", ")", "\n", "\n", "for", "obj", "in", "np", ".", "argwhere", "(", "objs_to_relock", ")", "[", ":", ",", "0", "]", ":", "\n", "                ", "self", ".", "which_locked", "[", "obj", "]", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "agent_idx_allowed_to_lock", "[", "\n", "np", ".", "argwhere", "(", "allowed_and_desired", "[", ":", ",", "obj", "]", ")", ".", "flatten", "(", ")", "]", ")", "\n", "", "", "elif", "self", ".", "lock_type", "==", "\"all_lock_team_specific\"", ":", "\n", "# all close agents must want to lock the object", "\n", "# only agents from the same team as the locker can unlock", "\n", "            ", "allowed_to_unlock", "=", "self", ".", "metadata", "[", "'team_index'", "]", "[", ":", ",", "None", "]", "==", "(", "\n", "self", ".", "metadata", "[", "'team_index'", "]", "[", "None", ",", "self", ".", "which_locked", "]", ")", "\n", "allowed_and_not_desired", "=", "np", ".", "logical_and", "(", "allowed_to_unlock", "[", "self", ".", "agent_idx_allowed_to_lock", "]", ",", "allowed_and_not_desired", ")", "\n", "objs_to_unlock", "=", "np", ".", "any", "(", "allowed_and_not_desired", ",", "axis", "=", "0", ")", "\n", "objs_to_lock", "=", "np", ".", "logical_and", "(", "np", ".", "any", "(", "allowed_and_desired", ",", "axis", "=", "0", ")", ",", "~", "objs_to_unlock", ")", "\n", "new_objs_to_lock", "=", "np", ".", "logical_and", "(", "objs_to_lock", ",", "~", "self", ".", "obj_locked", ")", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "f\"{self.lock_type} lock type is not implemented\"", "\n", "\n", "", "joints_to_unlock", "=", "np", ".", "isin", "(", "sim", ".", "model", ".", "jnt_bodyid", ",", "self", ".", "obj_body_idxs", "[", "objs_to_unlock", "]", ")", "\n", "joints_to_lock", "=", "np", ".", "isin", "(", "sim", ".", "model", ".", "jnt_bodyid", ",", "self", ".", "obj_body_idxs", "[", "new_objs_to_lock", "]", ")", "\n", "\n", "# Turn on/off emission and joint limit", "\n", "matids_to_darken", "=", "sim", ".", "model", ".", "geom_matid", "[", "np", ".", "isin", "(", "sim", ".", "model", ".", "geom_bodyid", ",", "self", ".", "obj_body_idxs", "[", "objs_to_unlock", "]", ")", "]", "\n", "matids_to_lighten", "=", "sim", ".", "model", ".", "geom_matid", "[", "np", ".", "isin", "(", "sim", ".", "model", ".", "geom_bodyid", ",", "self", ".", "obj_body_idxs", "[", "new_objs_to_lock", "]", ")", "]", "\n", "matids_to_darken", "=", "matids_to_darken", "[", "matids_to_darken", "!=", "-", "1", "]", "\n", "matids_to_lighten", "=", "matids_to_lighten", "[", "matids_to_lighten", "!=", "-", "1", "]", "\n", "sim", ".", "model", ".", "mat_emission", "[", "matids_to_darken", "]", "=", "0", "\n", "sim", ".", "model", ".", "mat_emission", "[", "matids_to_lighten", "]", "=", "1", "\n", "sim", ".", "model", ".", "jnt_limited", "[", "joints_to_unlock", "]", "=", "0", "\n", "sim", ".", "model", ".", "jnt_limited", "[", "joints_to_lock", "]", "=", "1", "\n", "\n", "# For objs we need to newly lock, set the joint ranges to the current qpos of the obj.", "\n", "for", "obj", "in", "np", ".", "argwhere", "(", "new_objs_to_lock", ")", "[", ":", ",", "0", "]", ":", "\n", "            ", "sim", ".", "model", ".", "jnt_range", "[", "self", ".", "obj_jnt_idxs", "[", "obj", "]", ",", ":", "]", "=", "sim", ".", "data", ".", "qpos", "[", "self", ".", "obj_jnt_idxs", "[", "obj", "]", ",", "None", "]", "\n", "self", ".", "which_locked", "[", "obj", "]", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "agent_idx_allowed_to_lock", "[", "\n", "np", ".", "argwhere", "(", "allowed_and_desired", "[", ":", ",", "obj", "]", ")", ".", "flatten", "(", ")", "]", ")", "\n", "\n", "", "self", ".", "obj_locked", "=", "np", ".", "logical_or", "(", "np", ".", "logical_and", "(", "self", ".", "obj_locked", ",", "~", "objs_to_unlock", ")", ",", "objs_to_lock", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.manipulation.LockObjWrapper.unlock_objs": [[348, 354], ["numpy.isin", "numpy.isin", "numpy.arange"], "methods", ["None"], ["", "def", "unlock_objs", "(", "self", ")", ":", "\n", "        ", "sim", "=", "self", ".", "unwrapped", ".", "sim", "\n", "joints_to_unlock", "=", "np", ".", "isin", "(", "sim", ".", "model", ".", "jnt_bodyid", ",", "self", ".", "obj_body_idxs", "[", "np", ".", "arange", "(", "self", ".", "n_obj", ")", "]", ")", "\n", "objs_to_darken", "=", "np", ".", "isin", "(", "sim", ".", "model", ".", "geom_bodyid", ",", "self", ".", "obj_body_idxs", ")", "\n", "sim", ".", "model", ".", "mat_emission", "[", "sim", ".", "model", ".", "geom_matid", "[", "objs_to_darken", "]", "]", "=", "0", "\n", "sim", ".", "model", ".", "jnt_limited", "[", "joints_to_unlock", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.manipulation.LockObjWrapper.step": [[355, 365], ["manipulation.LockObjWrapper.lock_obj", "manipulation.LockObjWrapper.env.step", "numpy.concatenate", "numpy.ones", "manipulation.LockObjWrapper.observation"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.manipulation.LockObjWrapper.lock_obj", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "self", ".", "lock_obj", "(", "action", "[", "f'action_{self.ac_obs_prefix}glue'", "]", ")", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "\n", "if", "self", ".", "agent_allowed_to_lock_keys", "is", "not", "None", ":", "\n", "            ", "self", ".", "agent_allowed_to_lock_mask", "=", "np", ".", "concatenate", "(", "[", "obs", "[", "k", "]", "for", "k", "in", "self", ".", "agent_allowed_to_lock_keys", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "agent_allowed_to_lock_mask", "=", "np", ".", "ones", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_obj", ")", ")", "\n", "\n", "", "return", "self", ".", "observation", "(", "obs", ")", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.manipulation.LockAllWrapper.__init__": [[375, 385], ["gym.ActionWrapper.__init__", "gym.spaces.Tuple", "len", "manipulation.LockAllWrapper.action_space.spaces.keys", "gym.spaces.Discrete", "range"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "remove_object_specific_lock", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "n_agents", "=", "self", ".", "unwrapped", ".", "n_agents", "\n", "self", ".", "lock_actions", "=", "[", "k", "for", "k", "in", "self", ".", "action_space", ".", "spaces", ".", "keys", "(", ")", "if", "'glue'", "in", "k", "]", "\n", "self", ".", "n_obj", "=", "{", "k", ":", "len", "(", "self", ".", "action_space", ".", "spaces", "[", "k", "]", ".", "spaces", "[", "0", "]", ".", "nvec", ")", "for", "k", "in", "self", ".", "lock_actions", "}", "\n", "self", ".", "action_space", ".", "spaces", "[", "'action_glueall'", "]", "=", "(", "\n", "Tuple", "(", "[", "Discrete", "(", "2", ")", "for", "_", "in", "range", "(", "self", ".", "n_agents", ")", "]", ")", ")", "\n", "if", "remove_object_specific_lock", ":", "\n", "            ", "for", "k", "in", "self", ".", "lock_actions", ":", "\n", "                ", "del", "self", ".", "action_space", ".", "spaces", "[", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.manipulation.LockAllWrapper.action": [[386, 392], ["numpy.zeros"], "methods", ["None"], ["", "", "", "def", "action", "(", "self", ",", "action", ")", ":", "\n", "        ", "for", "k", "in", "self", ".", "lock_actions", ":", "\n", "            ", "action", "[", "k", "]", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_obj", "[", "k", "]", ")", ")", "\n", "action", "[", "k", "]", "[", "action", "[", "'action_glueall'", "]", "==", "1", ",", ":", "]", "=", "1", "\n", "\n", "", "return", "action", "\n", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.abstract_base_env.AbstractBaseEnv.__init__": [[11, 18], ["gym.spaces.Dict", "gym.spaces.Dict"], "methods", ["None"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "n_agents", ")", ":", "\n", "        ", "self", ".", "metadata", "=", "{", "}", "\n", "self", ".", "metadata", "[", "'n_agents'", "]", "=", "n_agents", "\n", "self", ".", "metadata", "[", "'n_actors'", "]", "=", "n_agents", "\n", "self", ".", "observation_space", "=", "Dict", "(", "{", "}", ")", "\n", "self", ".", "action_space", "=", "Dict", "(", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.abstract_base_env.AbstractBaseEnv.step": [[19, 21], ["numpy.zeros"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "return", "{", "}", ",", "np", ".", "zeros", "(", "self", ".", "n_agents", ")", ",", "False", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.abstract_base_env.AbstractBaseEnv.reset": [[22, 24], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "{", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_ipd.IteratedMatrixGameWrapper.__init__": [[24, 30], ["gym.Wrapper.__init__", "gym.spaces.Tuple", "mae_envs.wrappers.util.update_obs_space", "gym.spaces.Discrete", "range"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "env", ",", "payoff_matrix", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "n_agents", "=", "self", ".", "metadata", "[", "'n_agents'", "]", "\n", "self", ".", "action_space", ".", "spaces", "[", "'action_defect'", "]", "=", "Tuple", "(", "[", "Discrete", "(", "n", "=", "2", ")", "for", "_", "in", "range", "(", "self", ".", "n_agents", ")", "]", ")", "\n", "self", ".", "observation_space", "=", "update_obs_space", "(", "self", ",", "{", "'prev_ac'", ":", "[", "self", ".", "n_agents", ",", "1", "]", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_ipd.IteratedMatrixGameWrapper.reset": [[31, 36], ["numpy.zeros", "numpy.zeros", "env_ipd.IteratedMatrixGameWrapper.observation", "numpy.ones", "env_ipd.IteratedMatrixGameWrapper.env.reset"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "previous_action", "=", "-", "1", "*", "np", ".", "ones", "(", "self", ".", "n_agents", ")", "\n", "self", ".", "num_defects", "=", "np", ".", "zeros", "(", "self", ".", "n_agents", ")", "\n", "self", ".", "num_coops", "=", "np", ".", "zeros", "(", "self", ".", "n_agents", ")", "\n", "return", "self", ".", "observation", "(", "self", ".", "env", ".", "reset", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_ipd.IteratedMatrixGameWrapper.step": [[37, 49], ["action[].copy", "env_ipd.IteratedMatrixGameWrapper.env.step", "info.update", "info.update", "env_ipd.IteratedMatrixGameWrapper.observation", "enumerate", "enumerate"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "self", ".", "previous_action", "=", "action", "[", "'action_defect'", "]", ".", "copy", "(", ")", "\n", "obs", ",", "_", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "\n", "self", ".", "num_defects", "+=", "action", "[", "'action_defect'", "]", "\n", "self", ".", "num_coops", "+=", "(", "1", "-", "action", "[", "'action_defect'", "]", ")", "\n", "rew", "=", "self", ".", "payoff_matrix", "[", "action", "[", "'action_defect'", "]", "[", "0", "]", ",", "action", "[", "'action_defect'", "]", "[", "1", "]", "]", "\n", "\n", "if", "done", ":", "\n", "            ", "info", ".", "update", "(", "{", "f'actor{i}_n_defects'", ":", "n_defects", "for", "i", ",", "n_defects", "in", "enumerate", "(", "self", ".", "num_defects", ")", "}", ")", "\n", "info", ".", "update", "(", "{", "f'actor{i}_n_coops'", ":", "n_coops", "for", "i", ",", "n_coops", "in", "enumerate", "(", "self", ".", "num_coops", ")", "}", ")", "\n", "", "return", "self", ".", "observation", "(", "obs", ")", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_ipd.IteratedMatrixGameWrapper.observation": [[50, 53], ["None"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "[", "'prev_ac'", "]", "=", "self", ".", "previous_action", "[", ":", ",", "None", "]", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_ipd.LastAgentScripted.__init__": [[63, 70], ["gym.Wrapper.__init__", "env_ipd.LastAgentScripted.action_space.spaces.items", "gym.spaces.Tuple"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "policy_to_play", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "assert", "policy_to_play", "in", "[", "'allc'", ",", "'alld'", ",", "'tft'", "]", "\n", "self", ".", "policy_to_play", "=", "policy_to_play", "\n", "self", ".", "metadata", "[", "'n_actors'", "]", "-=", "1", "\n", "for", "k", ",", "v", "in", "self", ".", "action_space", ".", "spaces", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "action_space", ".", "spaces", "[", "k", "]", "=", "Tuple", "(", "v", ".", "spaces", "[", ":", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_ipd.LastAgentScripted.reset": [[71, 74], ["env_ipd.LastAgentScripted.observation", "env_ipd.LastAgentScripted.env.reset"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "previous_action", "=", "0", "\n", "return", "self", ".", "observation", "(", "self", ".", "env", ".", "reset", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_ipd.LastAgentScripted.step": [[75, 88], ["numpy.concatenate", "env_ipd.LastAgentScripted.env.step", "env_ipd.LastAgentScripted.observation"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "self", ".", "policy_to_play", "==", "'allc'", ":", "\n", "            ", "ac_to_play", "=", "0", "\n", "", "elif", "self", ".", "policy_to_play", "==", "'alld'", ":", "\n", "            ", "ac_to_play", "=", "1", "\n", "", "elif", "self", ".", "policy_to_play", "==", "'tft'", ":", "\n", "            ", "ac_to_play", "=", "self", ".", "previous_action", "\n", "\n", "", "self", ".", "previous_action", "=", "action", "[", "'action_defect'", "]", "[", "0", "]", "\n", "action", "[", "'action_defect'", "]", "=", "np", ".", "concatenate", "(", "[", "action", "[", "'action_defect'", "]", ",", "[", "ac_to_play", "]", "]", ")", "\n", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "return", "self", ".", "observation", "(", "obs", ")", ",", "rew", "[", ":", "-", "1", "]", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_ipd.LastAgentScripted.observation": [[89, 92], ["obs.items"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "=", "{", "k", ":", "v", "[", ":", "-", "1", "]", "for", "k", ",", "v", "in", "obs", ".", "items", "(", ")", "}", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_ipd.make_env": [[94, 149], ["rusp.abstract_base_env.AbstractBaseEnv", "rusp.wrappers_util.RandomizedHorizonWrapper", "list", "numpy.array", "env_ipd.IteratedMatrixGameWrapper", "rusp.wrappers_rusp.RUSPWrapper", "rusp.wrappers_rusp.add_rew_share_observation_keys", "mae_envs.wrappers.multi_agent.SplitObservations", "mae_envs.wrappers.util.ConcatenateObsWrapper", "mae_envs.wrappers.multi_agent.SelectKeysWrapper", "reversed", "env_ipd.LastAgentScripted"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.add_rew_share_observation_keys"], ["", "", "def", "make_env", "(", "horizon", "=", "10", ",", "horizon_lower", "=", "None", ",", "horizon_upper", "=", "None", ",", "\n", "prob_per_step_to_stop", "=", "0.1", ",", "# If set then we play the infinite game,", "\n", "mutual_cooperate", "=", "2", ",", "defected_against", "=", "-", "2", ",", "successful_defect", "=", "4", ",", "mutual_defect", "=", "0", ",", "\n", "# Evals", "\n", "against_all_c", "=", "False", ",", "against_all_d", "=", "False", ",", "against_tft", "=", "False", ",", "\n", "# Random Teams", "\n", "rusp_args", "=", "{", "}", ")", ":", "\n", "    ", "env", "=", "AbstractBaseEnv", "(", "2", ")", "\n", "\n", "env", "=", "RandomizedHorizonWrapper", "(", "env", ",", "lower_lim", "=", "horizon_lower", "or", "horizon", ",", "upper_lim", "=", "horizon_upper", "or", "horizon", ",", "\n", "prob_per_step_to_stop", "=", "prob_per_step_to_stop", ")", "\n", "# Construct Payoff Matrix", "\n", "cc", "=", "[", "mutual_cooperate", ",", "mutual_cooperate", "]", "\n", "cd", "=", "[", "defected_against", ",", "successful_defect", "]", "\n", "dc", "=", "list", "(", "reversed", "(", "cd", ")", ")", "\n", "dd", "=", "[", "mutual_defect", ",", "mutual_defect", "]", "\n", "payoff_matrix", "=", "np", ".", "array", "(", "[", "[", "cc", ",", "cd", "]", ",", "\n", "[", "dc", ",", "dd", "]", "]", ")", "\n", "env", "=", "IteratedMatrixGameWrapper", "(", "env", ",", "payoff_matrix", "=", "payoff_matrix", ")", "\n", "\n", "env", "=", "RUSPWrapper", "(", "env", ",", "**", "rusp_args", ")", "\n", "\n", "keys_self", "=", "[", "'prev_ac'", ",", "'timestep'", "]", "\n", "keys_additional_self_vf", "=", "[", "'fraction_episode_done'", ",", "'horizon'", "]", "\n", "\n", "keys_other_agents", "=", "[", "'prev_ac'", "]", "\n", "keys_additional_other_agents_vf", "=", "[", "]", "\n", "keys_self_matrices", "=", "[", "]", "\n", "add_rew_share_observation_keys", "(", "keys_self", "=", "keys_self", ",", "\n", "keys_additional_self_vf", "=", "keys_additional_self_vf", ",", "\n", "keys_other_agents", "=", "keys_other_agents", ",", "\n", "keys_additional_other_agents_vf", "=", "keys_additional_other_agents_vf", ",", "\n", "keys_self_matrices", "=", "keys_self_matrices", ",", "\n", "**", "rusp_args", ")", "\n", "keys_external", "=", "[", "'other_agents'", ",", "\n", "'other_agents_vf'", ",", "\n", "'additional_self_vf_obs'", "]", "\n", "\n", "env", "=", "SplitObservations", "(", "env", ",", "keys_self", "+", "keys_additional_self_vf", ",", "\n", "keys_copy", "=", "[", "]", ",", "keys_self_matrices", "=", "keys_self_matrices", ")", "\n", "env", "=", "ConcatenateObsWrapper", "(", "env", ",", "{", "'other_agents'", ":", "keys_other_agents", ",", "\n", "'other_agents_vf'", ":", "[", "'other_agents'", "]", "+", "keys_additional_other_agents_vf", ",", "\n", "'additional_self_vf_obs'", ":", "[", "k", "+", "'_self'", "for", "k", "in", "keys_additional_self_vf", "]", "}", ")", "\n", "env", "=", "SelectKeysWrapper", "(", "env", ",", "keys_self", "=", "keys_self", ",", "\n", "keys_other", "=", "keys_external", ")", "\n", "\n", "if", "against_all_c", "or", "against_all_d", "or", "against_tft", ":", "\n", "        ", "if", "against_all_c", ":", "\n", "            ", "policy_to_play", "=", "'allc'", "\n", "", "elif", "against_all_d", ":", "\n", "            ", "policy_to_play", "=", "'alld'", "\n", "", "elif", "against_tft", ":", "\n", "            ", "policy_to_play", "=", "'tft'", "\n", "", "env", "=", "LastAgentScripted", "(", "env", ",", "policy_to_play", ")", "\n", "", "return", "env", "\n", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.test_env_oasis.ExamineTest.test_examine_env": [[10, 19], ["test_env_oasis.ExamineTest.assertRaises", "subprocess.check_call", "os.path.join"], "methods", ["None"], ["    ", "def", "test_examine_env", "(", "self", ")", ":", "\n", "        ", "envs", "=", "[", "\n", "\"env_oasis.py\"", "\n", "]", "\n", "for", "env", "in", "envs", ":", "\n", "            ", "with", "self", ".", "assertRaises", "(", "subprocess", ".", "TimeoutExpired", ")", ":", "\n", "                ", "subprocess", ".", "check_call", "(", "\n", "[", "\"/usr/bin/env\"", ",", "\"python\"", ",", "EXAMINE_FILE_PATH", ",", "os", ".", "path", ".", "join", "(", "EXAMPLES_DIR", ",", "env", ")", "]", ",", "\n", "timeout", "=", "10", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.test_env_prisoners_buddy.test_env_runs": [[5, 14], ["rusp.env_prisoners_buddy.make_env", "rusp.env_prisoners_buddy.make_env.reset", "range", "numpy.all", "rusp.env_prisoners_buddy.make_env.step"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.make_env", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step"], ["def", "test_env_runs", "(", ")", ":", "\n", "    ", "env", "=", "make_env", "(", ")", "\n", "env", ".", "reset", "(", ")", "\n", "\n", "action", "=", "{", "'action_choose_agent'", ":", "[", "0", ",", "0", ",", "3", ",", "0", ",", "1", "]", ",", "'action_choose_option'", ":", "[", "1", ",", "0", ",", "0", ",", "0", ",", "0", "]", "}", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "        ", "obs", ",", "rew", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "\n", "", "assert", "np", ".", "all", "(", "rew", "==", "[", "1", ",", "-", "2", ",", "3", ",", "2", ",", "-", "2", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.RUSPGenerator.__init__": [[49, 67], ["numpy.all", "numpy.array"], "methods", ["None"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "*", ",", "\n", "# Prosociality Graph", "\n", "min_team_size", ":", "int", "=", "1", ",", "\n", "max_team_size", ":", "int", "=", "1", ",", "\n", "alpha", ":", "float", "=", "1.0", ",", "\n", "beta", ":", "float", "=", "1.0", ",", "\n", "allow_diagonal_non_1", ":", "bool", "=", "True", ",", "\n", "# Uncertainty", "\n", "obs_noise_std_range", ":", "Tuple", "[", "float", "]", "=", "[", "0.0", ",", "1.0", "]", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "assert", "min_team_size", ">=", "1", "\n", "assert", "max_team_size", ">=", "1", "\n", "assert", "max_team_size", ">=", "min_team_size", "\n", "assert", "alpha", ">", "0", "\n", "assert", "beta", ">", "0", "\n", "assert", "np", ".", "all", "(", "np", ".", "array", "(", "obs_noise_std_range", ")", ">=", "0", ")", "\n", "self", ".", "cached_partitions", "=", "{", "}", "# Keys are (n_agents, min_team_size, max_team_size)", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.RUSPGenerator._partition_agents": [[68, 79], ["list", "wrappers_rusp.get_all_integer_partitions", "numpy.random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.get_all_integer_partitions"], ["", "def", "_partition_agents", "(", "self", ",", "n_agents", ",", "min_team_size", ",", "max_team_size", ")", ":", "\n", "        ", "'''\n            Return a random partition from the set of all integer partitions\n        '''", "\n", "settings", "=", "(", "n_agents", ",", "min_team_size", ",", "max_team_size", ")", "\n", "if", "settings", "not", "in", "self", ".", "cached_partitions", ":", "\n", "            ", "self", ".", "cached_partitions", "[", "settings", "]", "=", "list", "(", "get_all_integer_partitions", "(", "n_agents", ",", "min_team_size", ",", "max_team_size", ")", ")", "\n", "", "all_partitions", "=", "self", ".", "cached_partitions", "[", "settings", "]", "\n", "random_partitions", "=", "all_partitions", "[", "np", ".", "random", ".", "randint", "(", "len", "(", "all_partitions", ")", ")", "]", "\n", "\n", "return", "random_partitions", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.RUSPGenerator._generate_social_preferences": [[80, 117], ["numpy.cumsum", "numpy.concatenate", "numpy.zeros", "range", "numpy.random.beta", "numpy.eye", "numpy.random.shuffle", "numpy.matmul", "wrappers_rusp.RUSPGenerator.reward_xform_mat.copy", "numpy.sum", "wrappers_rusp.RUSPGenerator._partition_agents", "numpy.random.randint", "slice", "numpy.tril", "numpy.fill_diagonal", "numpy.matmul", "len", "numpy.tril"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.RUSPGenerator._partition_agents"], ["", "def", "_generate_social_preferences", "(", "self", ",", "n_agents", ")", ":", "\n", "        ", "'''\n            Generate the relationship graph (without uncertainty)\n        '''", "\n", "# Generate random partitions", "\n", "if", "self", ".", "max_team_size", "!=", "self", ".", "min_team_size", ":", "\n", "            ", "random_partitions", "=", "self", ".", "_partition_agents", "(", "n_agents", ",", "self", ".", "min_team_size", ",", "self", ".", "max_team_size", ")", "\n", "", "else", ":", "\n", "            ", "random_partitions", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "min_team_size", ",", "self", ".", "max_team_size", "+", "1", ",", "(", "n_agents", ")", ")", "\n", "", "random_partitions", "=", "np", ".", "cumsum", "(", "random_partitions", ")", "\n", "random_partitions", "=", "random_partitions", "[", "random_partitions", "<=", "n_agents", "]", "\n", "random_partitions", "=", "np", ".", "concatenate", "(", "[", "[", "0", "]", ",", "random_partitions", ",", "[", "n_agents", "]", "]", ")", "\n", "\n", "# Convert random partitions into a block diagonal matrix", "\n", "self", ".", "reward_xform_mat", "=", "np", ".", "zeros", "(", "(", "n_agents", ",", "n_agents", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "random_partitions", ")", "-", "1", ")", ":", "\n", "            ", "block", "=", "slice", "(", "random_partitions", "[", "i", "]", ",", "random_partitions", "[", "i", "+", "1", "]", ")", "\n", "self", ".", "reward_xform_mat", "[", "block", ",", "block", "]", "=", "1", "\n", "\n", "# Randomize reward sharing values in block diagonal matrix", "\n", "", "self", ".", "reward_xform_mat", "*=", "np", ".", "random", ".", "beta", "(", "a", "=", "self", ".", "alpha", ",", "b", "=", "self", ".", "beta", ",", "size", "=", "(", "n_agents", ",", "n_agents", ")", ")", "\n", "\n", "# Make sure off-diagonal is symmetric", "\n", "self", ".", "reward_xform_mat", "=", "np", ".", "tril", "(", "self", ".", "reward_xform_mat", ",", "-", "1", ")", "+", "np", ".", "tril", "(", "self", ".", "reward_xform_mat", ")", ".", "T", "\n", "\n", "if", "not", "self", ".", "allow_diagonal_non_1", ":", "\n", "            ", "np", ".", "fill_diagonal", "(", "self", ".", "reward_xform_mat", ",", "1.0", ")", "\n", "\n", "# Randomly shuffle agents so that agent indicies do not matter", "\n", "", "random_shuffle_mat", "=", "np", ".", "eye", "(", "n_agents", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "random_shuffle_mat", ")", "\n", "# We rotate, sum over teams, then unrotate", "\n", "self", ".", "reward_xform_mat", "=", "np", ".", "matmul", "(", "np", ".", "matmul", "(", "random_shuffle_mat", ".", "T", ",", "self", ".", "reward_xform_mat", ")", ",", "random_shuffle_mat", ")", "\n", "\n", "# Normalize rows", "\n", "self", ".", "unnormalized_reward_xform_mat", "=", "self", ".", "reward_xform_mat", ".", "copy", "(", ")", "\n", "self", ".", "reward_xform_mat", "/=", "np", ".", "sum", "(", "self", ".", "reward_xform_mat", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.RUSPGenerator._generate_uncertainty": [[118, 126], ["numpy.random.uniform", "numpy.random.normal"], "methods", ["None"], ["", "def", "_generate_uncertainty", "(", "self", ",", "n_agents", ")", ":", "\n", "        ", "'''\n            Generate uncertainty levels and noise to be applied to the matrices\n        '''", "\n", "self", ".", "noise_std", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "self", ".", "obs_noise_std_range", "[", "0", "]", ",", "\n", "high", "=", "self", ".", "obs_noise_std_range", "[", "1", "]", ",", "\n", "size", "=", "(", "n_agents", ",", "n_agents", ",", "n_agents", ")", ")", "\n", "self", ".", "noise", "=", "np", ".", "random", ".", "normal", "(", "scale", "=", "self", ".", "noise_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.RUSPGenerator._precompute_observations": [[127, 169], ["numpy.repeat", "wrappers_rusp.RUSPGenerator._precompute_observations._index_into_mats"], "methods", ["None"], ["", "def", "_precompute_observations", "(", "self", ",", "n_agents", ")", ":", "\n", "        ", "'''\n            Precompute observations since they are static per episode.\n        '''", "\n", "# We have independent noisy observations per agents, so we copy the reward matrix n_agents times and", "\n", "#   then add the noise matrices", "\n", "rew_mats", "=", "np", ".", "repeat", "(", "np", ".", "expand_dims", "(", "self", ".", "unnormalized_reward_xform_mat", ",", "0", ")", ",", "n_agents", ",", "axis", "=", "0", ")", "\n", "noisy_rew_mats", "=", "rew_mats", "+", "self", ".", "noise", "\n", "self", ".", "precomputed_obs", "=", "{", "}", "\n", "\n", "def", "_index_into_mats", "(", "key", ",", "*", "indices", ")", ":", "\n", "            ", "'''\n                Helper function to create 3 observation types with the same indices\n            '''", "\n", "self", ".", "precomputed_obs", "[", "key", "]", "=", "rew_mats", "[", "indices", "]", "# Non-noisy version of the reward matrix", "\n", "self", ".", "precomputed_obs", "[", "key", "+", "\"_noisy\"", "]", "=", "noisy_rew_mats", "[", "indices", "]", "# Noisy version of the reward matrix", "\n", "self", ".", "precomputed_obs", "[", "key", "+", "'_noise_level'", "]", "=", "self", ".", "noise_std", "[", "indices", "]", "# Noise level associated with each entry in the noisy reward matrices", "\n", "\n", "", "def", "_transpose_existing", "(", "new_key", ",", "existing_key", ")", ":", "\n", "            ", "'''\n                Helper function to transpose all 3 observations for an key. This is useful if an agent policy\n                    or value function needs to observe what other agents observe about it.\n            '''", "\n", "self", ".", "precomputed_obs", "[", "new_key", "]", "=", "self", ".", "precomputed_obs", "[", "existing_key", "]", ".", "T", "\n", "self", ".", "precomputed_obs", "[", "new_key", "+", "\"_noisy\"", "]", "=", "self", ".", "precomputed_obs", "[", "existing_key", "+", "\"_noisy\"", "]", ".", "T", "\n", "self", ".", "precomputed_obs", "[", "new_key", "+", "'_noise_level'", "]", "=", "self", ".", "precomputed_obs", "[", "existing_key", "+", "'_noise_level'", "]", ".", "T", "\n", "\n", "# Relationship variable of myself (What is the weight over my own reward) with my own noise variable.", "\n", "#   This is in effect the 3D diagonal, so the output shape will be (n_agents,)", "\n", "", "_index_into_mats", "(", "'self_rew_value'", ",", "np", ".", "arange", "(", "n_agents", ")", ",", "np", ".", "arange", "(", "n_agents", ")", ",", "np", ".", "arange", "(", "n_agents", ")", ")", "\n", "\n", "# Relationship variable of other agents weight over their own reward with my own noise variable (s)", "\n", "#   Row i is the diagonal of the ith matrix", "\n", "_index_into_mats", "(", "'other_rew_value_s'", ",", "slice", "(", "None", ")", ",", "np", ".", "arange", "(", "n_agents", ")", ",", "np", ".", "arange", "(", "n_agents", ")", ")", "\n", "\n", "# My relationship variable with other agents (so) with my noise (s)", "\n", "#   Row i is row i of the ith matrix", "\n", "_index_into_mats", "(", "'rew_share_so_s'", ",", "np", ".", "arange", "(", "n_agents", ")", ",", "np", ".", "arange", "(", "n_agents", ")", ",", "slice", "(", "None", ")", ")", "\n", "\n", "# Others relationship variable with me (os) with their noise (o)", "\n", "#   Should only be used in the value function", "\n", "_transpose_existing", "(", "'rew_share_os_o'", ",", "'rew_share_so_s'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.RUSPWrapper.__init__": [[184, 204], ["wrappers_rusp.RUSPGenerator.__init__", "gym.Wrapper.__init__", "mae_envs.wrappers.util.update_obs_space"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "env", ",", "**", "graph_kwargs", ")", ":", "\n", "        ", "RUSPGenerator", ".", "__init__", "(", "self", ",", "**", "graph_kwargs", ")", "\n", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "n_a", "=", "self", ".", "metadata", "[", "'n_agents'", "]", "\n", "self", ".", "obs_keys_with_shapes", "=", "{", "\n", "'self_rew_value'", ":", "[", "n_a", ",", "1", "]", ",", "\n", "'self_rew_value_noisy'", ":", "[", "n_a", ",", "1", "]", ",", "\n", "'self_rew_value_noise_level'", ":", "[", "n_a", ",", "1", "]", ",", "\n", "'other_rew_value_s'", ":", "[", "n_a", ",", "n_a", ",", "1", "]", ",", "\n", "'other_rew_value_s_noisy'", ":", "[", "n_a", ",", "n_a", ",", "1", "]", ",", "\n", "'other_rew_value_s_noise_level'", ":", "[", "n_a", ",", "n_a", ",", "1", "]", ",", "\n", "'rew_share_so_s'", ":", "[", "n_a", ",", "n_a", ",", "1", "]", ",", "\n", "'rew_share_so_s_noisy'", ":", "[", "n_a", ",", "n_a", ",", "1", "]", ",", "\n", "'rew_share_so_s_noise_level'", ":", "[", "n_a", ",", "n_a", ",", "1", "]", ",", "\n", "'rew_share_os_o'", ":", "[", "n_a", ",", "n_a", ",", "1", "]", ",", "\n", "'rew_share_os_o_noisy'", ":", "[", "n_a", ",", "n_a", ",", "1", "]", ",", "\n", "'rew_share_os_o_noise_level'", ":", "[", "n_a", ",", "n_a", ",", "1", "]", ",", "\n", "}", "\n", "self", ".", "observation_space", "=", "update_obs_space", "(", "self", ",", "self", ".", "obs_keys_with_shapes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.RUSPWrapper.reset": [[205, 210], ["wrappers_rusp.RUSPWrapper._generate_social_preferences", "wrappers_rusp.RUSPWrapper._generate_uncertainty", "wrappers_rusp.RUSPWrapper._precompute_observations", "wrappers_rusp.RUSPWrapper.observation", "wrappers_rusp.RUSPWrapper.env.reset"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.RUSPGenerator._generate_social_preferences", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.RUSPGenerator._generate_uncertainty", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.RUSPGenerator._precompute_observations", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_generate_social_preferences", "(", "self", ".", "metadata", "[", "'n_agents'", "]", ")", "\n", "self", ".", "_generate_uncertainty", "(", "self", ".", "metadata", "[", "'n_agents'", "]", ")", "\n", "self", ".", "_precompute_observations", "(", "self", ".", "metadata", "[", "'n_agents'", "]", ")", "\n", "return", "self", ".", "observation", "(", "self", ".", "env", ".", "reset", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.RUSPWrapper.step": [[211, 215], ["wrappers_rusp.RUSPWrapper.env.step", "numpy.matmul", "wrappers_rusp.RUSPWrapper.observation"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "rew", "=", "np", ".", "matmul", "(", "self", ".", "reward_xform_mat", ",", "rew", ")", "\n", "return", "self", ".", "observation", "(", "obs", ")", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.RUSPWrapper.observation": [[216, 220], ["numpy.expand_dims"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "for", "k", "in", "self", ".", "obs_keys_with_shapes", ":", "\n", "            ", "obs", "[", "k", "]", "=", "np", ".", "expand_dims", "(", "self", ".", "precomputed_obs", "[", "k", "]", ",", "-", "1", ")", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.get_all_integer_partitions": [[8, 21], ["range", "wrappers_rusp.get_all_integer_partitions"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.get_all_integer_partitions"], ["def", "get_all_integer_partitions", "(", "n", ",", "min_team_size", "=", "1", ",", "max_team_size", "=", "np", ".", "inf", ")", ":", "\n", "    ", "'''\n        Return a list of all integer partitions of n.\n        Args:\n            n (int): number of entities.\n            min_team_size (int): minimum number of entities in a partition\n            max_team_size (int): maximum number of entities in a partition\n    '''", "\n", "if", "n", "<=", "max_team_size", ":", "\n", "        ", "yield", "(", "n", ",", ")", "\n", "", "for", "i", "in", "range", "(", "min_team_size", ",", "n", "//", "2", "+", "1", ")", ":", "\n", "        ", "for", "p", "in", "get_all_integer_partitions", "(", "n", "-", "i", ",", "i", ",", "max_team_size", ")", ":", "\n", "            ", "yield", "(", "i", ",", ")", "+", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.add_rew_share_observation_keys": [[222, 276], ["wrappers_rusp..append"], "function", ["None"], ["", "", "def", "add_rew_share_observation_keys", "(", "*", ",", "keys_self", ":", "List", "[", "str", "]", ",", "\n", "keys_additional_self_vf", ":", "List", "[", "str", "]", ",", "\n", "keys_other_agents", ":", "List", "[", "str", "]", ",", "\n", "keys_additional_other_agents_vf", ":", "List", "[", "str", "]", ",", "\n", "keys_self_matrices", ":", "List", "[", "str", "]", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "'''\n        Determines how keys about the relationship graph should be observed.\n        Args:\n            keys_self: keys that the agent should observe about itself\n            keys_additional_self_vf: keys about an agent but only that the value function should observe\n            keys_other_agents: keys about other agents\n            keys_additional_other_agents_vf: keys about other agents but only that the value function should observe\n            keys_self_matrices: keys that are shaped (n_agents, n_agents, X). These need to be dealth with differently\n    '''", "\n", "\n", "keys_self", "+=", "[", "\n", "'self_rew_value_noisy'", ",", "\n", "'self_rew_value_noise_level'", ",", "\n", "]", "\n", "keys_additional_self_vf", ".", "append", "(", "'self_rew_value'", ")", "\n", "\n", "keys_other_agents", "+=", "[", "\n", "'rew_share_so_s_noisy'", ",", "\n", "'rew_share_so_s_noise_level'", ",", "\n", "'other_rew_value_s_noisy'", ",", "\n", "'other_rew_value_s_noise_level'", "\n", "]", "\n", "\n", "other_rew_value_keys", "=", "[", "\n", "'other_rew_value_s_noisy'", ",", "\n", "'other_rew_value_s_noise_level'", ",", "\n", "]", "\n", "\n", "keys_additional_other_agents_vf", "+=", "[", "\n", "'rew_share_so_s'", ",", "\n", "'other_rew_value_s'", ",", "\n", "'rew_share_os_o_noisy'", ",", "\n", "'rew_share_os_o_noise_level'", ",", "\n", "]", "\n", "\n", "keys_self_matrices", "+=", "[", "\n", "'other_rew_value_s'", ",", "\n", "'other_rew_value_s_noisy'", ",", "\n", "'other_rew_value_s_noise_level'", ",", "\n", "'rew_share_so_s'", ",", "\n", "'rew_share_so_s_noisy'", ",", "\n", "'rew_share_so_s_noise_level'", ",", "\n", "'rew_share_os_o'", ",", "\n", "'rew_share_os_o_noisy'", ",", "\n", "'rew_share_os_o_noise_level'", ",", "\n", "]", "\n", "\n", "return", "keys_self", ",", "keys_additional_self_vf", ",", "keys_other_agents", ",", "keys_additional_other_agents_vf", ",", "keys_self_matrices", "\n", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.test_env_indirect_reciprocity._test_fixed_policy": [[6, 30], ["rusp.env_indirect_reciprocity.make_env", "rusp.env_indirect_reciprocity.make_env.reset", "range", "numpy.squeeze", "rusp.env_indirect_reciprocity.make_env.step", "numpy.all", "numpy.random.randint", "numpy.all", "numpy.all", "rusp.env_indirect_reciprocity.make_env.reset", "numpy.all", "numpy.all"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.make_env", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["def", "_test_fixed_policy", "(", "against_all_d", "=", "False", ",", "against_all_c", "=", "False", ")", ":", "\n", "    ", "env", "=", "make_env", "(", "against_all_d", "=", "against_all_d", ",", "against_all_c", "=", "against_all_c", ",", "\n", "last_agent_always_plays", "=", "True", ")", "\n", "prev_obs", "=", "env", ".", "reset", "(", ")", "\n", "for", "i", "in", "range", "(", "1000", ")", ":", "\n", "        ", "currently_playing", "=", "np", ".", "squeeze", "(", "prev_obs", "[", "'youre_playing_self'", "]", ")", "\n", "ac", "=", "{", "'action_defect'", ":", "np", ".", "random", ".", "randint", "(", "0", ",", "2", ",", "size", "=", "(", "env", ".", "metadata", "[", "'n_actors'", "]", ")", ")", "}", "\n", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "env", ".", "step", "(", "ac", ")", "\n", "\n", "if", "against_all_d", ":", "\n", "            ", "assert", "np", ".", "all", "(", "rew", "[", "currently_playing", "&", "(", "ac", "[", "'action_defect'", "]", "==", "0", ")", "]", "==", "-", "2", ")", "\n", "assert", "np", ".", "all", "(", "rew", "[", "currently_playing", "&", "(", "ac", "[", "'action_defect'", "]", "==", "1", ")", "]", "==", "0", ")", "\n", "", "elif", "against_all_c", ":", "\n", "            ", "assert", "np", ".", "all", "(", "rew", "[", "currently_playing", "&", "(", "ac", "[", "'action_defect'", "]", "==", "0", ")", "]", "==", "2", ")", "\n", "assert", "np", ".", "all", "(", "rew", "[", "currently_playing", "&", "(", "ac", "[", "'action_defect'", "]", "==", "1", ")", "]", "==", "4", ")", "\n", "", "else", ":", "\n", "            ", "assert", "False", "\n", "", "assert", "np", ".", "all", "(", "rew", "[", "~", "currently_playing", "]", "==", "0", ")", "\n", "\n", "prev_obs", "=", "obs", "\n", "\n", "if", "done", ":", "\n", "            ", "prev_obs", "=", "env", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.test_env_indirect_reciprocity.test_all_d": [[32, 34], ["test_env_indirect_reciprocity._test_fixed_policy"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.test_env_indirect_reciprocity._test_fixed_policy"], ["", "", "", "def", "test_all_d", "(", ")", ":", "\n", "    ", "_test_fixed_policy", "(", "against_all_d", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.test_env_indirect_reciprocity.test_all_c": [[36, 38], ["test_env_indirect_reciprocity._test_fixed_policy"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.test_env_indirect_reciprocity._test_fixed_policy"], ["", "def", "test_all_c", "(", ")", ":", "\n", "    ", "_test_fixed_policy", "(", "against_all_c", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.test_env_indirect_reciprocity.test_last_always_plays": [[41, 53], ["rusp.env_indirect_reciprocity.make_env", "rusp.env_indirect_reciprocity.make_env.reset", "range", "numpy.random.randint", "rusp.env_indirect_reciprocity.make_env.step", "rusp.env_indirect_reciprocity.make_env.reset"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.make_env", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "test_last_always_plays", "(", ")", ":", "\n", "    ", "env", "=", "make_env", "(", "last_agent_always_plays", "=", "True", ")", "\n", "obs", "=", "env", ".", "reset", "(", ")", "\n", "assert", "obs", "[", "'youre_playing_self'", "]", "[", "-", "1", ",", "0", "]", "\n", "ac", "=", "{", "'action_defect'", ":", "np", ".", "random", ".", "randint", "(", "0", ",", "2", ",", "size", "=", "(", "env", ".", "metadata", "[", "'n_actors'", "]", ")", ")", "}", "\n", "for", "i", "in", "range", "(", "1000", ")", ":", "\n", "        ", "obs", ",", "_", ",", "done", ",", "_", "=", "env", ".", "step", "(", "ac", ")", "\n", "assert", "obs", "[", "'youre_playing_self'", "]", "[", "-", "1", ",", "0", "]", "\n", "\n", "if", "done", ":", "\n", "            ", "obs", "=", "env", ".", "reset", "(", ")", "\n", "assert", "obs", "[", "'youre_playing_self'", "]", "[", "-", "1", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.test_env_indirect_reciprocity.test_last_first_versus_last": [[55, 68], ["rusp.env_indirect_reciprocity.make_env", "rusp.env_indirect_reciprocity.make_env.reset", "range", "numpy.random.randint", "rusp.env_indirect_reciprocity.make_env.step", "copy.deepcopy", "rusp.env_indirect_reciprocity.make_env.reset"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.make_env", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "", "", "def", "test_last_first_versus_last", "(", ")", ":", "\n", "    ", "env", "=", "make_env", "(", "last_step_first_agent_vs_last_agent", "=", "True", ")", "\n", "prev_obs", "=", "env", ".", "reset", "(", ")", "\n", "ac", "=", "{", "'action_defect'", ":", "np", ".", "random", ".", "randint", "(", "0", ",", "2", ",", "size", "=", "(", "env", ".", "metadata", "[", "'n_actors'", "]", ")", ")", "}", "\n", "for", "i", "in", "range", "(", "1000", ")", ":", "\n", "        ", "obs", ",", "_", ",", "done", ",", "_", "=", "env", ".", "step", "(", "ac", ")", "\n", "\n", "if", "done", ":", "\n", "            ", "assert", "prev_obs", "[", "'youre_playing_self'", "]", "[", "-", "1", ",", "0", "]", "\n", "assert", "prev_obs", "[", "'youre_playing_self'", "]", "[", "0", ",", "0", "]", "\n", "obs", "=", "env", ".", "reset", "(", ")", "\n", "\n", "", "prev_obs", "=", "deepcopy", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.test_env_indirect_reciprocity.test_last_doesnt_play_until": [[70, 86], ["rusp.env_indirect_reciprocity.make_env", "rusp.env_indirect_reciprocity.make_env.reset", "range", "numpy.random.randint", "rusp.env_indirect_reciprocity.make_env.step", "rusp.env_indirect_reciprocity.make_env.reset"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.make_env", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "", "def", "test_last_doesnt_play_until", "(", ")", ":", "\n", "    ", "env", "=", "make_env", "(", "last_doesnt_play_until_t", "=", "5", ")", "\n", "ac", "=", "{", "'action_defect'", ":", "np", ".", "random", ".", "randint", "(", "0", ",", "2", ",", "size", "=", "(", "env", ".", "metadata", "[", "'n_actors'", "]", ")", ")", "}", "\n", "obs", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "t", "=", "0", "\n", "for", "i", "in", "range", "(", "1000", ")", ":", "\n", "        ", "if", "t", "<", "5", ":", "\n", "            ", "assert", "not", "obs", "[", "'youre_playing_self'", "]", "[", "-", "1", ",", "0", "]", "\n", "", "obs", ",", "rew", ",", "done", ",", "info", "=", "env", ".", "step", "(", "ac", ")", "\n", "t", "+=", "1", "\n", "\n", "if", "done", ":", "\n", "            ", "obs", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "t", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.test_env_indirect_reciprocity.test_last_doesnt_play_until_and_last_must_play_at_t": [[88, 106], ["rusp.env_indirect_reciprocity.make_env", "rusp.env_indirect_reciprocity.make_env.reset", "range", "numpy.random.randint", "rusp.env_indirect_reciprocity.make_env.step", "rusp.env_indirect_reciprocity.make_env.reset"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.make_env", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "", "", "def", "test_last_doesnt_play_until_and_last_must_play_at_t", "(", ")", ":", "\n", "    ", "env", "=", "make_env", "(", "last_doesnt_play_until_t", "=", "5", ",", "last_must_play_at_t", "=", "True", ")", "\n", "ac", "=", "{", "'action_defect'", ":", "np", ".", "random", ".", "randint", "(", "0", ",", "2", ",", "size", "=", "(", "env", ".", "metadata", "[", "'n_actors'", "]", ")", ")", "}", "\n", "obs", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "t", "=", "0", "\n", "for", "i", "in", "range", "(", "1000", ")", ":", "\n", "        ", "if", "t", "<", "5", ":", "\n", "            ", "assert", "not", "obs", "[", "'youre_playing_self'", "]", "[", "-", "1", ",", "0", "]", "\n", "", "if", "t", "==", "5", ":", "\n", "            ", "assert", "obs", "[", "'youre_playing_self'", "]", "[", "-", "1", ",", "0", "]", "\n", "", "obs", ",", "rew", ",", "done", ",", "info", "=", "env", ".", "step", "(", "ac", ")", "\n", "t", "+=", "1", "\n", "\n", "if", "done", ":", "\n", "            ", "obs", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "t", "=", "0", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_prisoners_buddy.PrisonersBuddy.__init__": [[31, 46], ["rusp.wrappers_util.OtherActorAttentionAction.__init__", "mae_envs.wrappers.util.update_obs_space"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "env", ",", "choosing_period", ",", "\n", "agent_identity_dim", "=", "4", ",", "\n", "mutual_cooperate_rew", "=", "2", ",", "\n", "defected_against_rew", "=", "-", "1", ",", "\n", "successful_defect_rew", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ",", "'action_choose_agent'", ")", "\n", "self", ".", "observation_space", "=", "update_obs_space", "(", "self", ",", "{", "\n", "'chose_me'", ":", "[", "self", ".", "n_agents", ",", "self", ".", "n_agents", ",", "1", "]", ",", "\n", "'i_chose'", ":", "[", "self", ".", "n_agents", ",", "self", ".", "n_agents", ",", "1", "]", ",", "\n", "'chose_me_rew'", ":", "[", "self", ".", "n_agents", ",", "self", ".", "n_agents", ",", "1", "]", ",", "\n", "'i_chose_rew'", ":", "[", "self", ".", "n_agents", ",", "self", ".", "n_agents", ",", "1", "]", ",", "\n", "'i_chose_any_rew'", ":", "[", "self", ".", "n_agents", ",", "1", "]", ",", "\n", "'previous_choice_identity'", ":", "[", "self", ".", "n_agents", ",", "agent_identity_dim", "]", ",", "\n", "'next_choice_is_real'", ":", "[", "self", ".", "n_agents", ",", "1", "]", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_prisoners_buddy.PrisonersBuddy.reset": [[48, 66], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "collections.defaultdict", "numpy.zeros", "env_prisoners_buddy.PrisonersBuddy.observation", "numpy.ones", "env_prisoners_buddy.PrisonersBuddy.env.reset"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_t", "=", "1", "# Start t at 1 such that first round is not a reward round", "\n", "self", ".", "_chose_me", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_agents", ")", ")", "\n", "self", ".", "_chose_me_rew", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_agents", ")", ")", "\n", "self", ".", "_n_times_not_chosen", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ")", ")", "\n", "self", ".", "_n_times_team_changed", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ")", ")", "\n", "self", ".", "_n_agents_on_team", "=", "[", "]", "\n", "self", ".", "_previous_choice_identity", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "self", ".", "agent_identity_dim", ")", ")", "\n", "self", ".", "_i_chose_any_rew_obs", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "1", ")", ")", "\n", "self", ".", "_team_lengths", "=", "[", "]", "\n", "self", ".", "_n_successful_defections", "=", "0", "\n", "self", ".", "_current_team_lengths", "=", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "self", ".", "_previous_teams", "=", "np", ".", "ones", "(", "self", ".", "n_agents", ",", "dtype", "=", "int", ")", "*", "-", "1", "\n", "self", ".", "_both_chose", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_agents", ")", ",", "dtype", "=", "bool", ")", "\n", "self", ".", "_perfect_game", "=", "True", "\n", "self", ".", "_first_choice", "=", "True", "\n", "\n", "return", "self", ".", "observation", "(", "self", ".", "env", ".", "reset", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_prisoners_buddy.PrisonersBuddy.step": [[67, 127], ["env_prisoners_buddy.PrisonersBuddy.env.step", "numpy.zeros", "range", "numpy.ones", "env_prisoners_buddy.PrisonersBuddy._get_target_actor", "len", "env_prisoners_buddy.PrisonersBuddy._chose_me.copy", "numpy.argmax", "env_prisoners_buddy.PrisonersBuddy._prisoners_buddy_reward_update", "list", "list", "numpy.sum", "numpy.mean", "numpy.sum", "env_prisoners_buddy.PrisonersBuddy.observation", "map", "env_prisoners_buddy.PrisonersBuddy._team_lengths.append", "numpy.any", "numpy.all", "env_prisoners_buddy.PrisonersBuddy._current_team_lengths.values", "len", "numpy.mean", "numpy.all", "numpy.nonzero", "env_prisoners_buddy.PrisonersBuddy._current_team_lengths.keys", "numpy.sum", "numpy.sum", "numpy.triu"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_util.OtherActorAttentionAction._get_target_actor", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_prisoners_buddy.PrisonersBuddy._prisoners_buddy_reward_update", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "_chose_me", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_agents", ")", ",", "dtype", "=", "bool", ")", "\n", "targets", "=", "np", ".", "ones", "(", "self", ".", "n_agents", ",", "dtype", "=", "int", ")", "*", "-", "1", "\n", "for", "i", "in", "range", "(", "self", ".", "n_agents", ")", ":", "\n", "            ", "target", "=", "self", ".", "_get_target_actor", "(", "i", ",", "action", ")", "\n", "if", "len", "(", "target", ")", ":", "\n", "                ", "targets", "[", "i", "]", "=", "target", "[", "0", "]", "\n", "self", ".", "_chose_me", "[", "target", "[", "0", "]", ",", "i", "]", "=", "1", "\n", "\n", "", "", "self", ".", "_previous_choice_identity", "=", "obs", "[", "'agent_identity'", "]", "[", "targets", "]", "\n", "self", ".", "_previous_choice_identity", "[", "targets", "==", "-", "1", "]", "=", "0", "\n", "\n", "# Reward rounds", "\n", "if", "self", ".", "_t", "%", "self", ".", "choosing_period", "==", "0", ":", "\n", "            ", "self", ".", "_both_chose", "=", "self", ".", "_chose_me", "*", "self", ".", "_chose_me", ".", "T", "\n", "self", ".", "_chose_me_rew", "=", "self", ".", "_chose_me", ".", "copy", "(", ")", "\n", "\n", "self", ".", "_teams", "=", "np", ".", "argmax", "(", "self", ".", "_both_chose", ",", "axis", "=", "1", ")", "# Indicies of teamate", "\n", "self", ".", "_teams", "[", "np", ".", "all", "(", "self", ".", "_both_chose", "==", "0", ",", "axis", "=", "1", ")", "]", "=", "-", "1", "# Make sure those without team are set to -1 instead of 0", "\n", "\n", "rew", "=", "self", ".", "_prisoners_buddy_reward_update", "(", "rew", ")", "\n", "\n", "# Track stats", "\n", "self", ".", "_n_times_not_chosen", "[", "np", ".", "sum", "(", "self", ".", "_chose_me", ",", "1", ")", "==", "0", "]", "+=", "1", "\n", "# Since both_chose is symmetric, just get the index of nonzero entry in upper triangle", "\n", "current_team_indices", "=", "np", ".", "c_", "[", "np", ".", "nonzero", "(", "np", ".", "triu", "(", "self", ".", "_both_chose", ")", ")", "]", "\n", "current_team_tuples", "=", "list", "(", "map", "(", "tuple", ",", "current_team_indices", ")", ")", "\n", "teams_done", "=", "[", "k", "for", "k", "in", "self", ".", "_current_team_lengths", ".", "keys", "(", ")", "if", "k", "not", "in", "current_team_tuples", "]", "\n", "\n", "for", "team_done", "in", "teams_done", ":", "\n", "                ", "self", ".", "_team_lengths", ".", "append", "(", "self", ".", "_current_team_lengths", "[", "team_done", "]", ")", "\n", "del", "self", ".", "_current_team_lengths", "[", "team_done", "]", "\n", "", "for", "current_team_tuple", "in", "current_team_tuples", ":", "\n", "                ", "self", ".", "_current_team_lengths", "[", "current_team_tuple", "]", "+=", "1", "\n", "\n", "", "self", ".", "_i_chose_any_rew_obs", "=", "np", ".", "any", "(", "self", ".", "_chose_me_rew", ",", "0", ")", "[", ":", ",", "None", "]", "\n", "\n", "if", "self", ".", "_first_choice", ":", "\n", "                ", "self", ".", "_first_choice", "=", "False", "\n", "", "else", ":", "\n", "                ", "all_teams_didnt_change", "=", "np", ".", "all", "(", "self", ".", "_previous_teams", "==", "self", ".", "_teams", ")", "\n", "max_number_of_teams_filled", "=", "np", ".", "sum", "(", "self", ".", "_teams", "!=", "-", "1", ")", "==", "(", "(", "self", ".", "n_agents", "//", "2", ")", "*", "2", ")", "\n", "self", ".", "_perfect_game", "=", "self", ".", "_perfect_game", "and", "all_teams_didnt_change", "and", "max_number_of_teams_filled", "\n", "\n", "", "self", ".", "_previous_teams", "=", "self", ".", "_teams", "\n", "\n", "", "self", ".", "_t", "+=", "1", "\n", "\n", "if", "done", ":", "\n", "            ", "self", ".", "_team_lengths", "+=", "list", "(", "self", ".", "_current_team_lengths", ".", "values", "(", ")", ")", "\n", "info", "[", "'average_team_length'", "]", "=", "np", ".", "mean", "(", "self", ".", "_team_lengths", ")", "if", "len", "(", "self", ".", "_team_lengths", ")", "else", "0", "\n", "info", "[", "'n_times_team_changed'", "]", "=", "np", ".", "sum", "(", "self", ".", "_n_times_team_changed", ")", "\n", "info", "[", "'n_agents_on_team_per_step'", "]", "=", "np", ".", "mean", "(", "self", ".", "_n_agents_on_team", ")", "\n", "info", "[", "'number_decisions'", "]", "=", "self", ".", "_t", "/", "self", ".", "choosing_period", "\n", "info", "[", "'n_unique_not_chosen'", "]", "=", "np", ".", "sum", "(", "self", ".", "_n_times_not_chosen", ">", "0", ")", "\n", "info", "[", "'n_successful_defections'", "]", "=", "self", ".", "_n_successful_defections", "\n", "info", "[", "'perfect_game'", "]", "=", "self", ".", "_perfect_game", "\n", "\n", "", "return", "self", ".", "observation", "(", "obs", ")", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_prisoners_buddy.PrisonersBuddy.observation": [[128, 138], ["numpy.ones", "numpy.zeros"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "[", "'chose_me'", "]", "=", "self", ".", "_chose_me", "[", ":", ",", ":", ",", "None", "]", "\n", "obs", "[", "'i_chose'", "]", "=", "self", ".", "_chose_me", ".", "T", "[", ":", ",", ":", ",", "None", "]", "\n", "obs", "[", "'chose_me_rew'", "]", "=", "self", ".", "_chose_me_rew", "[", ":", ",", ":", ",", "None", "]", "\n", "obs", "[", "'i_chose_rew'", "]", "=", "self", ".", "_chose_me_rew", ".", "T", "[", ":", ",", ":", ",", "None", "]", "\n", "obs", "[", "'i_chose_any_rew'", "]", "=", "self", ".", "_i_chose_any_rew_obs", "\n", "obs", "[", "'previous_choice_identity'", "]", "=", "self", ".", "_previous_choice_identity", "\n", "# assumes this is called after t is increased", "\n", "obs", "[", "'next_choice_is_real'", "]", "=", "np", ".", "ones", "(", "(", "self", ".", "n_agents", ",", "1", ")", ")", "if", "self", ".", "_t", "%", "self", ".", "choosing_period", "==", "0", "else", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "1", ")", ")", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_prisoners_buddy.PrisonersBuddy._prisoners_buddy_reward_update": [[139, 161], ["numpy.any", "numpy.sum", "numpy.any", "numpy.all", "numpy.all", "numpy.sum", "env_prisoners_buddy.PrisonersBuddy._n_agents_on_team.append", "numpy.sum", "numpy.sum"], "methods", ["None"], ["", "def", "_prisoners_buddy_reward_update", "(", "self", ",", "rew", ")", ":", "\n", "        ", "on_team", "=", "np", ".", "any", "(", "self", ".", "_both_chose", ",", "axis", "=", "1", ")", "\n", "chose_me_oneway", "=", "(", "self", ".", "_chose_me", "&", "~", "self", ".", "_both_chose", ")", "\n", "num_chose_me_oneway", "=", "np", ".", "sum", "(", "chose_me_oneway", ",", "axis", "=", "1", ")", "\n", "i_chose_one_way", "=", "np", ".", "any", "(", "chose_me_oneway", ",", "axis", "=", "0", ")", "\n", "\n", "assert", "np", ".", "all", "(", "np", ".", "sum", "(", "chose_me_oneway", ",", "axis", "=", "0", ")", "<=", "1", ")", "\n", "assert", "np", ".", "all", "(", "(", "i_chose_one_way", "&", "on_team", ")", "==", "0", ")", "\n", "\n", "previous_has_team", "=", "(", "self", ".", "_previous_teams", "!=", "-", "1", ")", "\n", "your_team_changed", "=", "(", "self", ".", "_teams", "!=", "self", ".", "_previous_teams", ")", "\n", "\n", "rew", "[", "on_team", "]", "+=", "self", ".", "mutual_cooperate_rew", "\n", "rew", "[", "i_chose_one_way", "]", "+=", "self", ".", "defected_against_rew", "\n", "rew", "+=", "num_chose_me_oneway", "*", "self", ".", "successful_defect_rew", "\n", "\n", "# Stats", "\n", "self", ".", "_n_successful_defections", "+=", "np", ".", "sum", "(", "i_chose_one_way", ")", "\n", "self", ".", "_n_times_team_changed", "+=", "(", "previous_has_team", "&", "your_team_changed", ")", "\n", "self", ".", "_n_agents_on_team", ".", "append", "(", "np", ".", "sum", "(", "on_team", ")", ")", "\n", "\n", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_prisoners_buddy.make_env": [[163, 227], ["rusp.abstract_base_env.AbstractBaseEnv", "rusp.wrappers_util.RandomizedHorizonWrapper", "rusp.wrappers_util.RandomIdentityVector", "env_prisoners_buddy.PrisonersBuddy", "rusp.wrappers_util.ActionOptionsWrapper", "rusp.wrappers_rusp.RUSPWrapper", "rusp.wrappers_rusp.add_rew_share_observation_keys", "mae_envs.wrappers.multi_agent.SplitObservations", "mae_envs.wrappers.util.ConcatenateObsWrapper", "mae_envs.wrappers.multi_agent.SelectKeysWrapper"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.add_rew_share_observation_keys"], ["", "", "def", "make_env", "(", "n_agents", "=", "5", ",", "horizon", "=", "50", ",", "horizon_lower", "=", "None", ",", "horizon_upper", "=", "None", ",", "\n", "prob_per_step_to_stop", "=", "0.02", ",", "\n", "choosing_period", "=", "5", ",", "\n", "mutual_cooperate_rew", "=", "2", ",", "defected_against_rew", "=", "-", "2", ",", "successful_defect_rew", "=", "1", ",", "\n", "agent_identity_dim", "=", "16", ",", "\n", "rusp_args", "=", "{", "}", ")", ":", "\n", "    ", "env", "=", "AbstractBaseEnv", "(", "n_agents", ")", "\n", "env", "=", "RandomizedHorizonWrapper", "(", "env", ",", "lower_lim", "=", "horizon_lower", "or", "horizon", ",", "upper_lim", "=", "horizon_upper", "or", "horizon", ",", "\n", "prob_per_step_to_stop", "=", "prob_per_step_to_stop", ")", "\n", "env", "=", "RandomIdentityVector", "(", "env", ",", "vector_dim", "=", "agent_identity_dim", ")", "\n", "\n", "env", "=", "PrisonersBuddy", "(", "env", ",", "choosing_period", "=", "choosing_period", ",", "\n", "agent_identity_dim", "=", "agent_identity_dim", ",", "\n", "mutual_cooperate_rew", "=", "mutual_cooperate_rew", ",", "defected_against_rew", "=", "defected_against_rew", ",", "\n", "successful_defect_rew", "=", "successful_defect_rew", ")", "\n", "\n", "env", "=", "ActionOptionsWrapper", "(", "env", ",", "[", "'action_choose_agent'", "]", ",", "{", "'action_choose_agent'", ":", "-", "1", "}", ")", "\n", "\n", "env", "=", "RUSPWrapper", "(", "env", ",", "**", "rusp_args", ")", "\n", "\n", "keys_self", "=", "[", "'previous_choice'", ",", "\n", "'next_choice_is_real'", ",", "\n", "'i_chose_any_rew'", ",", "\n", "'agent_identity'", ",", "\n", "'previous_choice_identity'", ",", "\n", "'timestep'", "]", "\n", "keys_additional_self_vf", "=", "[", "'fraction_episode_done'", ",", "'horizon'", "]", "\n", "\n", "keys_other_agents", "=", "[", "\n", "'previous_choice'", ",", "\n", "'chose_me'", ",", "\n", "'i_chose'", ",", "\n", "'chose_me_rew'", ",", "\n", "'i_chose_rew'", ",", "\n", "'i_chose_any_rew'", ",", "\n", "'agent_identity'", ",", "\n", "'previous_choice_identity'", "\n", "]", "\n", "keys_additional_other_agents_vf", "=", "[", "]", "\n", "keys_self_matrices", "=", "[", "'chose_me'", ",", "\n", "'i_chose'", ",", "\n", "'chose_me_rew'", ",", "\n", "'i_chose_rew'", "]", "\n", "\n", "keys_external", "=", "[", "'other_agents'", ",", "\n", "'other_agents_vf'", ",", "\n", "'additional_self_vf_obs'", "]", "\n", "\n", "add_rew_share_observation_keys", "(", "keys_self", "=", "keys_self", ",", "\n", "keys_additional_self_vf", "=", "keys_additional_self_vf", ",", "\n", "keys_other_agents", "=", "keys_other_agents", ",", "\n", "keys_additional_other_agents_vf", "=", "keys_additional_other_agents_vf", ",", "\n", "keys_self_matrices", "=", "keys_self_matrices", ",", "\n", "**", "rusp_args", ")", "\n", "\n", "env", "=", "SplitObservations", "(", "env", ",", "keys_self", "+", "keys_additional_self_vf", ",", "\n", "keys_copy", "=", "[", "]", ",", "keys_self_matrices", "=", "keys_self_matrices", ")", "\n", "env", "=", "ConcatenateObsWrapper", "(", "env", ",", "{", "'other_agents'", ":", "keys_other_agents", ",", "\n", "'other_agents_vf'", ":", "[", "'other_agents'", "]", "+", "keys_additional_other_agents_vf", ",", "\n", "'additional_self_vf_obs'", ":", "[", "k", "+", "'_self'", "for", "k", "in", "keys_additional_self_vf", "]", "}", ")", "\n", "env", "=", "SelectKeysWrapper", "(", "env", ",", "keys_self", "=", "keys_self", ",", "\n", "keys_other", "=", "keys_external", ")", "\n", "\n", "return", "env", "\n", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_util.RandomizedHorizonWrapper.__init__": [[28, 40], ["gym.Wrapper.__init__", "mae_envs.wrappers.util.update_obs_space", "mae_envs.wrappers.util.update_obs_space"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "env", ",", "lower_lim", "=", "None", ",", "upper_lim", "=", "None", ",", "prob_per_step_to_stop", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "assert", "(", "lower_lim", "is", "not", "None", "and", "upper_lim", "is", "not", "None", ")", "or", "prob_per_step_to_stop", "is", "not", "None", "\n", "if", "prob_per_step_to_stop", "is", "not", "None", ":", "\n", "            ", "assert", "prob_per_step_to_stop", ">", "0", "and", "prob_per_step_to_stop", "<", "1", "\n", "", "self", ".", "observation_space", "=", "update_obs_space", "(", "self", ",", "{", "\n", "'fraction_episode_done'", ":", "[", "self", ".", "metadata", "[", "'n_agents'", "]", ",", "1", "]", ",", "\n", "'horizon'", ":", "[", "self", ".", "metadata", "[", "'n_agents'", "]", ",", "1", "]", ",", "\n", "'timestep'", ":", "[", "self", ".", "metadata", "[", "'n_agents'", "]", ",", "1", "]", "\n", "}", ")", "\n", "self", ".", "observation_space", "=", "update_obs_space", "(", "self", ",", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_util.RandomizedHorizonWrapper.reset": [[41, 48], ["wrappers_util.RandomizedHorizonWrapper.observation", "numpy.random.geometric", "wrappers_util.RandomizedHorizonWrapper.env.reset", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_t", "=", "0", "\n", "if", "self", ".", "prob_per_step_to_stop", "is", "not", "None", ":", "\n", "            ", "self", ".", "_horizon", "=", "np", ".", "random", ".", "geometric", "(", "p", "=", "self", ".", "prob_per_step_to_stop", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_horizon", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "lower_lim", ",", "self", ".", "upper_lim", "+", "1", ")", "if", "self", ".", "lower_lim", "<", "self", ".", "upper_lim", "else", "self", ".", "lower_lim", "\n", "", "return", "self", ".", "observation", "(", "self", ".", "env", ".", "reset", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_util.RandomizedHorizonWrapper.step": [[49, 55], ["wrappers_util.RandomizedHorizonWrapper.env.step", "wrappers_util.RandomizedHorizonWrapper.observation"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "self", ".", "_t", "+=", "1", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "if", "self", ".", "_t", ">=", "self", ".", "_horizon", ":", "\n", "            ", "done", "=", "True", "\n", "", "return", "self", ".", "observation", "(", "obs", ")", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_util.RandomizedHorizonWrapper.observation": [[56, 61], ["numpy.ones", "numpy.ones", "numpy.ones"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "[", "'timestep'", "]", "=", "np", ".", "ones", "(", "(", "self", ".", "metadata", "[", "'n_agents'", "]", ",", "1", ")", ",", "dtype", "=", "int", ")", "*", "self", ".", "_t", "\n", "obs", "[", "'fraction_episode_done'", "]", "=", "np", ".", "ones", "(", "(", "self", ".", "metadata", "[", "'n_agents'", "]", ",", "1", ")", ")", "*", "self", ".", "_t", "/", "self", ".", "_horizon", "\n", "obs", "[", "'horizon'", "]", "=", "np", ".", "ones", "(", "(", "self", ".", "metadata", "[", "'n_agents'", "]", ",", "1", ")", ")", "*", "self", ".", "_horizon", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_util.RandomIdentityVector.__init__": [[73, 77], ["gym.Wrapper.__init__", "mae_envs.wrappers.util.update_obs_space"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "env", ",", "vector_dim", "=", "16", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "observation_space", "=", "update_obs_space", "(", "self", ",", "{", "'agent_identity'", ":", "[", "self", ".", "metadata", "[", "'n_agents'", "]", ",", "self", ".", "vector_dim", "]", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_util.RandomIdentityVector.reset": [[78, 81], ["numpy.random.uniform", "wrappers_util.RandomIdentityVector.observation", "wrappers_util.RandomIdentityVector.env.reset"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent_identities", "=", "np", ".", "random", ".", "uniform", "(", "0", ",", "1", ",", "(", "self", ".", "metadata", "[", "'n_agents'", "]", ",", "self", ".", "vector_dim", ")", ")", "\n", "return", "self", ".", "observation", "(", "self", ".", "env", ".", "reset", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_util.RandomIdentityVector.observation": [[82, 85], ["None"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "[", "'agent_identity'", "]", "=", "self", ".", "agent_identities", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_util.RandomIdentityVector.step": [[86, 89], ["wrappers_util.RandomIdentityVector.env.step", "wrappers_util.RandomIdentityVector.observation"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "return", "self", ".", "observation", "(", "obs", ")", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_util.OtherActorAttentionAction.__init__": [[105, 116], ["gym.Wrapper.__init__", "gym.spaces.Tuple", "dict", "numpy.arange", "zip", "gym.spaces.Discrete", "numpy.arange", "range", "scipy.linalg.circulant", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "env", ",", "action_name", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "action_name", "=", "action_name", "\n", "self", ".", "n_agents", "=", "self", ".", "metadata", "[", "'n_agents'", "]", "\n", "self", ".", "action_space", ".", "spaces", "[", "action_name", "]", "=", "Tuple", "(", "[", "Discrete", "(", "n", "=", "self", ".", "metadata", "[", "'n_agents'", "]", "-", "1", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "n_agents", ")", "]", ")", "\n", "\n", "# This matches the circulant ordering used for \"Others\" Observations (see mae_envs.wrappers.multi_agent:SplitObservations)", "\n", "self", ".", "other_actors", "=", "np", ".", "arange", "(", "self", ".", "n_agents", ")", "[", "circulant", "(", "np", ".", "arange", "(", "self", ".", "n_agents", ")", ")", "[", ":", ",", "1", ":", "]", "]", "\n", "self", ".", "other_actors", "=", "dict", "(", "zip", "(", "np", ".", "arange", "(", "self", ".", "n_agents", ")", ",", "self", ".", "other_actors", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_util.OtherActorAttentionAction._get_target_actor": [[117, 128], ["numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "_get_target_actor", "(", "self", ",", "actor", ",", "action", ")", ":", "\n", "        ", "'''\n            Return the true index of the targeted agent. Indicies given by the action will be in a rotated space defined\n                based on how entities are presented to the policy, so we must map back to the underlying ordering.\n\n            If the index is -1, this means no other agent was chosen.\n        '''", "\n", "if", "action", "[", "self", ".", "action_name", "]", "[", "actor", "]", "==", "-", "1", ":", "\n", "            ", "return", "np", ".", "array", "(", "[", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "array", "(", "[", "self", ".", "other_actors", "[", "actor", "]", "[", "action", "[", "self", ".", "action_name", "]", "[", "actor", "]", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_util.ActionOptionsWrapper.__init__": [[145, 154], ["gym.Wrapper.__init__", "gym.spaces.Tuple", "mae_envs.wrappers.util.update_obs_space", "wrappers_util.ActionOptionsWrapper.action_keys.append", "gym.spaces.Discrete", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "env", ",", "action_keys", ",", "defaults", ",", "do_nothing_option", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "if", "self", ".", "do_nothing_option", ":", "\n", "            ", "self", ".", "action_keys", ".", "append", "(", "'do_nothing'", ")", "\n", "", "self", ".", "n_agents", "=", "self", ".", "metadata", "[", "'n_agents'", "]", "\n", "self", ".", "action_space", ".", "spaces", "[", "'action_choose_option'", "]", "=", "Tuple", "(", "[", "Discrete", "(", "n", "=", "len", "(", "self", ".", "action_keys", ")", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "metadata", "[", "'n_agents'", "]", ")", "]", ")", "\n", "self", ".", "observation_space", "=", "update_obs_space", "(", "self", ",", "{", "'previous_choice'", ":", "[", "self", ".", "metadata", "[", "'n_agents'", "]", ",", "len", "(", "self", ".", "action_keys", ")", "]", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_util.ActionOptionsWrapper.reset": [[155, 158], ["numpy.zeros", "wrappers_util.ActionOptionsWrapper.observation", "wrappers_util.ActionOptionsWrapper.env.reset", "len"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "previous_choice", "=", "np", ".", "zeros", "(", "(", "self", ".", "metadata", "[", "'n_agents'", "]", ",", "len", "(", "self", ".", "action_keys", ")", ")", ")", "\n", "return", "self", ".", "observation", "(", "self", ".", "env", ".", "reset", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_util.ActionOptionsWrapper.step": [[159, 168], ["range", "wrappers_util.ActionOptionsWrapper.env.step", "enumerate", "numpy.eye", "wrappers_util.ActionOptionsWrapper.observation", "len"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "self", ".", "n_agents", ")", ":", "\n", "            ", "for", "ac_ind", ",", "ac_name", "in", "enumerate", "(", "self", ".", "action_keys", ")", ":", "\n", "                ", "if", "ac_ind", "!=", "action", "[", "'action_choose_option'", "]", "[", "i", "]", "and", "ac_name", "!=", "'do_nothing'", ":", "\n", "                    ", "action", "[", "ac_name", "]", "[", "i", "]", "=", "self", ".", "defaults", "[", "ac_name", "]", "\n", "\n", "", "", "", "self", ".", "previous_choice", "=", "np", ".", "eye", "(", "len", "(", "self", ".", "action_keys", ")", ")", "[", "action", "[", "'action_choose_option'", "]", "]", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "return", "self", ".", "observation", "(", "obs", ")", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_util.ActionOptionsWrapper.observation": [[169, 172], ["None"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "[", "'previous_choice'", "]", "=", "self", ".", "previous_choice", "\n", "return", "obs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_indirect_reciprocity.MaskYourePlaying.__init__": [[19, 23], ["gym.ObservationWrapper.__init__", "gym.spaces.Dict", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "observation_space", ".", "spaces", "[", "'mask'", "]", "=", "gym", ".", "spaces", ".", "Dict", "(", "{", "\n", "'action_defect'", ":", "gym", ".", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "(", "self", ".", "metadata", "[", "'n_actors'", "]", ",", "2", ")", ",", "float", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_indirect_reciprocity.MaskYourePlaying.observation": [[25, 29], ["numpy.zeros", "numpy.squeeze"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "[", "'mask'", "]", "=", "{", "'action_defect'", ":", "np", ".", "zeros", "(", "(", "self", ".", "metadata", "[", "'n_actors'", "]", ",", "2", ")", ",", "dtype", "=", "bool", ")", "}", "\n", "obs", "[", "'mask'", "]", "[", "'action_defect'", "]", "[", "np", ".", "squeeze", "(", "obs", "[", "'youre_playing_self'", "]", ",", "-", "1", ")", "]", "=", "1", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_indirect_reciprocity.LastAgentScripted.__init__": [[40, 48], ["gym.Wrapper.__init__", "env_indirect_reciprocity.LastAgentScripted.action_space.spaces.items", "gym.spaces.Tuple"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "policy_to_play", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "assert", "policy_to_play", "in", "[", "'allc'", ",", "'alld'", ",", "'tft'", "]", "\n", "self", ".", "n_agents", "=", "self", ".", "unwrapped", ".", "n_agents", "\n", "self", ".", "policy_to_play", "=", "policy_to_play", "\n", "self", ".", "metadata", "[", "'n_actors'", "]", "-=", "1", "\n", "for", "k", ",", "v", "in", "self", ".", "action_space", ".", "spaces", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "action_space", ".", "spaces", "[", "k", "]", "=", "Tuple", "(", "v", ".", "spaces", "[", ":", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_indirect_reciprocity.LastAgentScripted.reset": [[49, 55], ["numpy.zeros", "env_indirect_reciprocity.LastAgentScripted.env.reset", "numpy.squeeze", "env_indirect_reciprocity.LastAgentScripted.observation", "obs[].copy"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "previous_action_against_me", "=", "np", ".", "zeros", "(", "self", ".", "n_agents", "-", "1", ",", "dtype", "=", "int", ")", "\n", "\n", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "self", ".", "_youre_playing", "=", "np", ".", "squeeze", "(", "obs", "[", "'youre_playing_self'", "]", ".", "copy", "(", ")", ",", "-", "1", ")", "\n", "return", "self", ".", "observation", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_indirect_reciprocity.LastAgentScripted.step": [[56, 75], ["copy.deepcopy", "numpy.concatenate", "env_indirect_reciprocity.LastAgentScripted.env.step", "numpy.squeeze", "obs[].copy", "env_indirect_reciprocity.LastAgentScripted.observation"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "action", "=", "deepcopy", "(", "action", ")", "\n", "if", "self", ".", "policy_to_play", "==", "'allc'", ":", "\n", "            ", "ac_to_play", "=", "0", "\n", "", "elif", "self", ".", "policy_to_play", "==", "'alld'", ":", "\n", "            ", "ac_to_play", "=", "1", "\n", "", "elif", "self", ".", "policy_to_play", "==", "'tft'", ":", "\n", "# Take the zeroeth index incase this agent isn't currently playing", "\n", "            ", "ac_to_play", "=", "self", ".", "previous_action_against_me", "[", "self", ".", "_youre_playing", "[", ":", "-", "1", "]", "]", "[", "0", "]", "\n", "\n", "# Only update previous action against me if scripted agent is playing", "\n", "", "if", "self", ".", "_youre_playing", "[", "-", "1", "]", ":", "\n", "            ", "self", ".", "previous_action_against_me", "[", "self", ".", "_youre_playing", "[", ":", "-", "1", "]", "]", "=", "action", "[", "'action_defect'", "]", "[", "self", ".", "_youre_playing", "[", ":", "-", "1", "]", "]", "\n", "\n", "", "action", "[", "'action_defect'", "]", "=", "np", ".", "concatenate", "(", "[", "action", "[", "'action_defect'", "]", ",", "[", "ac_to_play", "]", "]", ")", "\n", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "_youre_playing", "=", "np", ".", "squeeze", "(", "obs", "[", "'youre_playing_self'", "]", ".", "copy", "(", ")", ",", "-", "1", ")", "\n", "return", "self", ".", "observation", "(", "obs", ")", ",", "rew", "[", ":", "-", "1", "]", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_indirect_reciprocity.LastAgentScripted.observation": [[76, 79], ["obs.items"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "=", "{", "k", ":", "v", "[", ":", "-", "1", "]", "for", "k", ",", "v", "in", "obs", ".", "items", "(", ")", "}", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_indirect_reciprocity.MultiPlayerIteratedMatrixGame.__init__": [[95, 104], ["gym.Wrapper.__init__", "gym.spaces.Tuple", "mae_envs.wrappers.util.update_obs_space", "gym.spaces.Discrete", "range"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "env", ",", "payoff_matrix", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "n_agents", "=", "self", ".", "unwrapped", ".", "n_agents", "\n", "# 0 means to cooperate, 1 means to defect", "\n", "self", ".", "action_space", ".", "spaces", "[", "'action_defect'", "]", "=", "Tuple", "(", "[", "Discrete", "(", "n", "=", "2", ")", "for", "_", "in", "range", "(", "self", ".", "n_agents", ")", "]", ")", "\n", "self", ".", "observation_space", "=", "update_obs_space", "(", "self", ",", "{", "\n", "'prev_ac'", ":", "[", "self", ".", "n_agents", ",", "1", "]", ",", "\n", "'prev_ac_while_playing'", ":", "[", "self", ".", "n_agents", ",", "1", "]", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_indirect_reciprocity.MultiPlayerIteratedMatrixGame.reset": [[106, 123], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "env_indirect_reciprocity.MultiPlayerIteratedMatrixGame.env.reset", "numpy.squeeze", "env_indirect_reciprocity.MultiPlayerIteratedMatrixGame.observation", "numpy.ones", "numpy.ones", "obs[].copy"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "previous_action", "=", "-", "1", "*", "np", ".", "ones", "(", "self", ".", "n_agents", ")", "\n", "self", ".", "previous_action_while_playing", "=", "-", "1", "*", "np", ".", "ones", "(", "self", ".", "n_agents", ")", "\n", "self", ".", "num_defects", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_agents", ")", ")", "\n", "self", ".", "num_coops", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_agents", ")", ")", "\n", "\n", "# sls stands for \"since last started\". This is useful for evaluation settings", "\n", "#   where we want agents to gain rapport. Since last started means since the", "\n", "#   last agent (index n-1) took its first action", "\n", "self", ".", "num_defects_sls", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_agents", ")", ")", "\n", "self", ".", "num_coops_sls", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_agents", ")", ")", "\n", "self", ".", "last_started", "=", "False", "\n", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n", "# This comes from ChooseAgentsToPlay wrapper", "\n", "self", ".", "_youre_playing", "=", "np", ".", "squeeze", "(", "obs", "[", "'youre_playing'", "]", ".", "copy", "(", ")", ",", "-", "1", ")", "\n", "return", "self", ".", "observation", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_indirect_reciprocity.MultiPlayerIteratedMatrixGame.step": [[124, 176], ["env_indirect_reciprocity.MultiPlayerIteratedMatrixGame.env.step", "action[].copy", "[].copy", "numpy.zeros", "numpy.all", "numpy.squeeze", "numpy.where", "obs[].copy", "info.update", "info.update", "info.update", "info.update", "env_indirect_reciprocity.MultiPlayerIteratedMatrixGame.observation", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "info.update", "info.update", "numpy.isnan", "numpy.isnan", "enumerate", "enumerate", "numpy.sum", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "obs", ",", "_", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "\n", "# Update statistics for agents that are playing (p1 and p2)", "\n", "p1", ",", "p2", "=", "np", ".", "where", "(", "self", ".", "_youre_playing", ")", "[", "0", "]", "\n", "self", ".", "num_defects", "[", "p1", ",", "p2", "]", "+=", "action", "[", "'action_defect'", "]", "[", "p1", "]", "\n", "self", ".", "num_defects", "[", "p2", ",", "p1", "]", "+=", "action", "[", "'action_defect'", "]", "[", "p2", "]", "\n", "self", ".", "num_coops", "[", "p1", ",", "p2", "]", "+=", "1", "-", "action", "[", "'action_defect'", "]", "[", "p1", "]", "\n", "self", ".", "num_coops", "[", "p2", ",", "p1", "]", "+=", "1", "-", "action", "[", "'action_defect'", "]", "[", "p2", "]", "\n", "if", "p1", "==", "self", ".", "n_agents", "-", "1", "or", "p2", "==", "self", ".", "n_agents", "-", "1", "or", "self", ".", "last_started", ":", "\n", "            ", "self", ".", "last_started", "=", "True", "\n", "self", ".", "num_defects_sls", "[", "p1", ",", "p2", "]", "+=", "action", "[", "'action_defect'", "]", "[", "p1", "]", "\n", "self", ".", "num_defects_sls", "[", "p2", ",", "p1", "]", "+=", "action", "[", "'action_defect'", "]", "[", "p2", "]", "\n", "self", ".", "num_coops_sls", "[", "p1", ",", "p2", "]", "+=", "1", "-", "action", "[", "'action_defect'", "]", "[", "p1", "]", "\n", "self", ".", "num_coops_sls", "[", "p2", ",", "p1", "]", "+=", "1", "-", "action", "[", "'action_defect'", "]", "[", "p2", "]", "\n", "\n", "", "self", ".", "previous_action", "=", "action", "[", "'action_defect'", "]", ".", "copy", "(", ")", "\n", "self", ".", "previous_action", "[", "~", "self", ".", "_youre_playing", "]", "=", "-", "1", "# if you weren't playing don't give info on what you chose", "\n", "self", ".", "previous_action_while_playing", "[", "self", ".", "_youre_playing", "]", "=", "action", "[", "'action_defect'", "]", "[", "self", ".", "_youre_playing", "]", ".", "copy", "(", ")", "\n", "\n", "rew", "=", "np", ".", "zeros", "(", "self", ".", "n_agents", ")", "\n", "rew", "[", "[", "p1", ",", "p2", "]", "]", "=", "self", ".", "payoff_matrix", "[", "action", "[", "'action_defect'", "]", "[", "p1", "]", ",", "action", "[", "'action_defect'", "]", "[", "p2", "]", "]", "\n", "assert", "np", ".", "all", "(", "rew", "[", "~", "self", ".", "_youre_playing", "]", "==", "0", ")", "\n", "\n", "# Calling step will update the next players, so update this after computing reward.", "\n", "self", ".", "_youre_playing", "=", "np", ".", "squeeze", "(", "obs", "[", "'youre_playing'", "]", ".", "copy", "(", ")", ",", "-", "1", ")", "\n", "\n", "if", "done", ":", "\n", "            ", "info", ".", "update", "(", "{", "f'actor{i}_n_coops'", ":", "n_coops", "for", "i", ",", "n_coops", "in", "enumerate", "(", "np", ".", "sum", "(", "self", ".", "num_coops", ",", "1", ")", ")", "}", ")", "\n", "info", ".", "update", "(", "{", "f'actor{i}_n_defects'", ":", "n_defects", "for", "i", ",", "n_defects", "in", "enumerate", "(", "np", ".", "sum", "(", "self", ".", "num_defects", ",", "1", ")", ")", "}", ")", "\n", "\n", "# Compute fraction of actions that were defects against", "\n", "#    (a) all agents as compared to the last agent, i.e. the difference in these fractions", "\n", "#    (b) the last agent", "\n", "# We compute these statistics because for evaluation the last agent may be scripted, and so they are useful", "\n", "#   in comparing e.g. the difference in fraction of defects against an all-defect versus all-cooperate policy", "\n", "num_actions", "=", "self", ".", "num_coops", "+", "self", ".", "num_defects", "\n", "frac_defects_against_each_other", "=", "np", ".", "sum", "(", "self", ".", "num_defects", "[", ":", "-", "1", ",", ":", "-", "1", "]", ")", "/", "np", ".", "sum", "(", "num_actions", "[", ":", "-", "1", ",", ":", "-", "1", "]", ")", "\n", "frac_defects_against_last", "=", "np", ".", "sum", "(", "self", ".", "num_defects", "[", ":", "-", "1", ",", "-", "1", "]", ")", "/", "np", ".", "sum", "(", "num_actions", "[", ":", "-", "1", ",", "-", "1", "]", ")", "\n", "info", ".", "update", "(", "{", "'frac_defects_all_minus_last'", ":", "frac_defects_against_each_other", "}", ")", "\n", "info", ".", "update", "(", "{", "'frac_defects_against_last'", ":", "frac_defects_against_last", "}", ")", "\n", "\n", "# In the Prior Rapport setting (see paper), we want to measure the fraction of defects against the last agent", "\n", "#   AFTER the last agent has started acting, which is after the period in which the other agents have been able to", "\n", "#   gain rapport.", "\n", "num_actions_sls", "=", "self", ".", "num_coops_sls", "+", "self", ".", "num_defects_sls", "\n", "frac_defects_against_each_other_sls", "=", "np", ".", "sum", "(", "self", ".", "num_defects_sls", "[", ":", "-", "1", ",", ":", "-", "1", "]", ")", "/", "np", ".", "sum", "(", "num_actions_sls", "[", ":", "-", "1", ",", ":", "-", "1", "]", ")", "\n", "frac_defects_against_last_sls", "=", "np", ".", "sum", "(", "self", ".", "num_defects_sls", "[", ":", "-", "1", ",", "-", "1", "]", ")", "/", "np", ".", "sum", "(", "num_actions_sls", "[", ":", "-", "1", ",", "-", "1", "]", ")", "\n", "if", "not", "(", "np", ".", "isnan", "(", "frac_defects_against_each_other_sls", ")", "or", "np", ".", "isnan", "(", "frac_defects_against_last_sls", ")", ")", ":", "\n", "                ", "info", ".", "update", "(", "{", "'frac_defects_all_minus_last_sls'", ":", "frac_defects_against_each_other_sls", "}", ")", "\n", "info", ".", "update", "(", "{", "'frac_defects_against_last_sls'", ":", "frac_defects_against_last_sls", "}", ")", "\n", "", "", "return", "self", ".", "observation", "(", "obs", ")", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_indirect_reciprocity.MultiPlayerIteratedMatrixGame.observation": [[177, 181], ["None"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "[", "'prev_ac'", "]", "=", "self", ".", "previous_action", "[", ":", ",", "None", "]", "\n", "obs", "[", "'prev_ac_while_playing'", "]", "=", "self", ".", "previous_action_while_playing", "[", ":", ",", "None", "]", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_indirect_reciprocity.ChooseAgentsToPlay.__init__": [[193, 203], ["gym.Wrapper.__init__", "mae_envs.wrappers.util.update_obs_space"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "env", ",", "\n", "last_step_first_agent_vs_last_agent", ":", "bool", ",", "\n", "last_agent_always_plays", ":", "bool", ",", "\n", "last_doesnt_play_until_t", ":", "int", "=", "None", ",", "\n", "last_must_play_at_t", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "n_agents", "=", "self", ".", "unwrapped", ".", "n_agents", "\n", "self", ".", "observation_space", "=", "update_obs_space", "(", "self", ",", "{", "'you_played'", ":", "[", "self", ".", "n_agents", ",", "1", "]", ",", "\n", "'youre_playing'", ":", "[", "self", ".", "n_agents", ",", "1", "]", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_indirect_reciprocity.ChooseAgentsToPlay.step": [[204, 211], ["env_indirect_reciprocity.ChooseAgentsToPlay.env.step", "env_indirect_reciprocity.ChooseAgentsToPlay._youre_playing.copy", "env_indirect_reciprocity.ChooseAgentsToPlay._sample_new_players", "obs[].copy", "env_indirect_reciprocity.ChooseAgentsToPlay.observation"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_indirect_reciprocity.ChooseAgentsToPlay._sample_new_players", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "_t", "=", "obs", "[", "'timestep'", "]", ".", "copy", "(", ")", "[", "0", ",", "0", "]", "# Comes from RandomizedHorizonWrapper", "\n", "\n", "self", ".", "_you_played", "=", "self", ".", "_youre_playing", ".", "copy", "(", ")", "\n", "self", ".", "_sample_new_players", "(", ")", "\n", "return", "self", ".", "observation", "(", "obs", ")", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_indirect_reciprocity.ChooseAgentsToPlay.reset": [[212, 219], ["env_indirect_reciprocity.ChooseAgentsToPlay.env.reset", "numpy.zeros().astype", "env_indirect_reciprocity.ChooseAgentsToPlay._sample_new_players", "env_indirect_reciprocity.ChooseAgentsToPlay.observation", "obs[].copy", "obs[].copy", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_indirect_reciprocity.ChooseAgentsToPlay._sample_new_players", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "self", ".", "_t", "=", "obs", "[", "'timestep'", "]", ".", "copy", "(", ")", "[", "0", ",", "0", "]", "\n", "self", ".", "_horizon", "=", "obs", "[", "'horizon'", "]", ".", "copy", "(", ")", "[", "0", ",", "0", "]", "\n", "self", ".", "_you_played", "=", "np", ".", "zeros", "(", "self", ".", "n_agents", ")", ".", "astype", "(", "bool", ")", "\n", "self", ".", "_sample_new_players", "(", ")", "\n", "return", "self", ".", "observation", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_indirect_reciprocity.ChooseAgentsToPlay.observation": [[220, 225], ["None"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "# We call observation after reseting players, so the mask should be for the current teams.", "\n", "        ", "obs", "[", "'you_played'", "]", "=", "self", ".", "_you_played", "[", ":", ",", "None", "]", "\n", "obs", "[", "'youre_playing'", "]", "=", "self", ".", "_youre_playing", "[", ":", ",", "None", "]", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_indirect_reciprocity.ChooseAgentsToPlay._sample_new_players": [[226, 256], ["numpy.arange", "numpy.arange", "numpy.random.choice", "numpy.random.choice", "numpy.zeros", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "_sample_new_players", "(", "self", ")", ":", "\n", "        ", "exclude_first", "=", "self", ".", "last_step_first_agent_vs_last_agent", "and", "self", ".", "_t", "<", "self", ".", "_horizon", "-", "1", "\n", "must_include_first_last", "=", "(", "self", ".", "last_step_first_agent_vs_last_agent", "and", "self", ".", "_t", "==", "self", ".", "_horizon", "-", "1", ")", "\n", "exclude_last", "=", "(", "self", ".", "last_doesnt_play_until_t", "is", "not", "None", "and", "self", ".", "_t", "<", "self", ".", "last_doesnt_play_until_t", ")", "\n", "\n", "p1_options", "=", "np", ".", "arange", "(", "self", ".", "n_agents", ")", "\n", "p2_options", "=", "np", ".", "arange", "(", "self", ".", "n_agents", ")", "\n", "\n", "if", "self", ".", "last_agent_always_plays", "and", "not", "exclude_last", ":", "\n", "            ", "p2_options", "=", "np", ".", "array", "(", "[", "self", ".", "n_agents", "-", "1", "]", ")", "\n", "p1_options", "=", "p1_options", "[", "p1_options", "!=", "p2_options", "]", "\n", "", "if", "exclude_last", ":", "\n", "            ", "p1_options", "=", "p1_options", "[", "p1_options", "!=", "self", ".", "n_agents", "-", "1", "]", "\n", "p2_options", "=", "p2_options", "[", "p2_options", "!=", "self", ".", "n_agents", "-", "1", "]", "\n", "", "if", "must_include_first_last", ":", "\n", "            ", "p1_options", "=", "np", ".", "array", "(", "[", "0", "]", ")", "\n", "p2_options", "=", "np", ".", "array", "(", "[", "self", ".", "n_agents", "-", "1", "]", ")", "\n", "", "if", "exclude_first", ":", "\n", "            ", "p1_options", "=", "p1_options", "[", "p1_options", "!=", "0", "]", "\n", "p2_options", "=", "p2_options", "[", "p2_options", "!=", "0", "]", "\n", "", "if", "self", ".", "last_doesnt_play_until_t", "is", "not", "None", "and", "self", ".", "last_doesnt_play_until_t", "==", "self", ".", "_t", "and", "self", ".", "last_must_play_at_t", ":", "\n", "            ", "p1_options", "=", "p1_options", "[", "p1_options", "!=", "self", ".", "n_agents", "-", "1", "]", "\n", "p2_options", "=", "np", ".", "array", "(", "[", "self", ".", "n_agents", "-", "1", "]", ")", "\n", "\n", "", "p1", "=", "np", ".", "random", ".", "choice", "(", "p1_options", ")", "\n", "p2_options", "=", "p2_options", "[", "p2_options", "!=", "p1", "]", "\n", "p2", "=", "np", ".", "random", ".", "choice", "(", "p2_options", ")", "\n", "\n", "self", ".", "_youre_playing", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", ")", ",", "dtype", "=", "bool", ")", "\n", "self", ".", "_youre_playing", "[", "[", "p1", ",", "p2", "]", "]", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_indirect_reciprocity.make_env": [[258, 340], ["rusp.abstract_base_env.AbstractBaseEnv", "rusp.wrappers_util.RandomizedHorizonWrapper", "rusp.wrappers_util.RandomIdentityVector", "env_indirect_reciprocity.ChooseAgentsToPlay", "list", "numpy.array", "env_indirect_reciprocity.MultiPlayerIteratedMatrixGame", "rusp.wrappers_rusp.RUSPWrapper", "rusp.wrappers_rusp.add_rew_share_observation_keys", "mae_envs.wrappers.multi_agent.SplitObservations", "mae_envs.wrappers.util.ConcatenateObsWrapper", "mae_envs.wrappers.multi_agent.SelectKeysWrapper", "env_indirect_reciprocity.MaskYourePlaying", "reversed", "env_indirect_reciprocity.LastAgentScripted"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.add_rew_share_observation_keys"], ["", "", "def", "make_env", "(", "n_agents", "=", "3", ",", "\n", "# Horizon", "\n", "horizon", "=", "20", ",", "horizon_lower", "=", "None", ",", "horizon_upper", "=", "None", ",", "\n", "prob_per_step_to_stop", "=", "0.05", ",", "\n", "# Matrix Payouts", "\n", "mutual_cooperate", "=", "2", ",", "defected_against", "=", "-", "2", ",", "successful_defect", "=", "4", ",", "mutual_defect", "=", "0", ",", "\n", "# Agent IDs", "\n", "agent_identity_dim", "=", "16", ",", "\n", "# Evals", "\n", "against_all_c", "=", "False", ",", "against_all_d", "=", "False", ",", "against_tft", "=", "False", ",", "\n", "last_step_first_agent_vs_last_agent", "=", "False", ",", "last_agent_always_plays", "=", "False", ",", "\n", "last_doesnt_play_until_t", "=", "None", ",", "\n", "last_must_play_at_t", "=", "False", ",", "\n", "# RUSP", "\n", "rusp_args", "=", "{", "}", ")", ":", "\n", "    ", "env", "=", "AbstractBaseEnv", "(", "n_agents", ")", "\n", "\n", "env", "=", "RandomizedHorizonWrapper", "(", "env", ",", "lower_lim", "=", "horizon_lower", "or", "horizon", ",", "upper_lim", "=", "horizon_upper", "or", "horizon", ",", "\n", "prob_per_step_to_stop", "=", "prob_per_step_to_stop", ")", "\n", "\n", "env", "=", "RandomIdentityVector", "(", "env", ",", "vector_dim", "=", "agent_identity_dim", ")", "\n", "\n", "env", "=", "ChooseAgentsToPlay", "(", "env", ",", "last_step_first_agent_vs_last_agent", "=", "last_step_first_agent_vs_last_agent", ",", "\n", "last_agent_always_plays", "=", "last_agent_always_plays", ",", "\n", "last_doesnt_play_until_t", "=", "last_doesnt_play_until_t", ",", "\n", "last_must_play_at_t", "=", "last_must_play_at_t", ")", "\n", "\n", "# Construct Payoff Matrix", "\n", "cc", "=", "[", "mutual_cooperate", ",", "mutual_cooperate", "]", "\n", "cd", "=", "[", "defected_against", ",", "successful_defect", "]", "\n", "dc", "=", "list", "(", "reversed", "(", "cd", ")", ")", "\n", "dd", "=", "[", "mutual_defect", ",", "mutual_defect", "]", "\n", "payoff_matrix", "=", "np", ".", "array", "(", "[", "[", "cc", ",", "cd", "]", ",", "\n", "[", "dc", ",", "dd", "]", "]", ")", "\n", "env", "=", "MultiPlayerIteratedMatrixGame", "(", "env", ",", "payoff_matrix", "=", "payoff_matrix", ")", "\n", "\n", "env", "=", "RUSPWrapper", "(", "env", ",", "**", "rusp_args", ")", "\n", "\n", "keys_self", "=", "[", "'prev_ac'", ",", "\n", "'you_played'", ",", "\n", "'youre_playing'", ",", "\n", "'agent_identity'", ",", "\n", "'timestep'", "]", "\n", "keys_additional_self_vf", "=", "[", "'fraction_episode_done'", ",", "'horizon'", "]", "\n", "\n", "keys_other_agents", "=", "[", "'prev_ac'", ",", "'youre_playing'", ",", "'agent_identity'", "]", "\n", "\n", "keys_additional_other_agents_vf", "=", "[", "]", "\n", "keys_self_matrices", "=", "[", "]", "\n", "add_rew_share_observation_keys", "(", "keys_self", "=", "keys_self", ",", "\n", "keys_additional_self_vf", "=", "keys_additional_self_vf", ",", "\n", "keys_other_agents", "=", "keys_other_agents", ",", "\n", "keys_additional_other_agents_vf", "=", "keys_additional_other_agents_vf", ",", "\n", "keys_self_matrices", "=", "keys_self_matrices", ",", "\n", "**", "rusp_args", ")", "\n", "keys_external", "=", "[", "'other_agents'", ",", "\n", "'other_agents_vf'", ",", "\n", "'additional_self_vf_obs'", "]", "\n", "\n", "keys_copy", "=", "[", "]", "\n", "\n", "env", "=", "SplitObservations", "(", "env", ",", "keys_self", "+", "keys_additional_self_vf", ",", "\n", "keys_copy", "=", "keys_copy", ",", "keys_self_matrices", "=", "keys_self_matrices", ")", "\n", "\n", "env", "=", "ConcatenateObsWrapper", "(", "env", ",", "{", "'other_agents'", ":", "keys_other_agents", ",", "\n", "'other_agents_vf'", ":", "[", "'other_agents'", "]", "+", "keys_additional_other_agents_vf", ",", "\n", "'additional_self_vf_obs'", ":", "[", "k", "+", "'_self'", "for", "k", "in", "keys_additional_self_vf", "]", "}", ")", "\n", "\n", "env", "=", "SelectKeysWrapper", "(", "env", ",", "keys_self", "=", "keys_self", ",", "\n", "keys_other", "=", "keys_external", "+", "keys_copy", "+", "[", "'youre_playing_self'", "]", ")", "# need to copy youre_playing_self through for the LastAgentScripted wrapper", "\n", "\n", "if", "against_all_c", "or", "against_all_d", "or", "against_tft", ":", "\n", "        ", "if", "against_all_c", ":", "\n", "            ", "policy_to_play", "=", "'allc'", "\n", "", "elif", "against_all_d", ":", "\n", "            ", "policy_to_play", "=", "'alld'", "\n", "", "elif", "against_tft", ":", "\n", "            ", "policy_to_play", "=", "'tft'", "\n", "", "env", "=", "LastAgentScripted", "(", "env", ",", "policy_to_play", ")", "\n", "", "env", "=", "MaskYourePlaying", "(", "env", ")", "\n", "\n", "return", "env", "\n", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.test_env_ipd.test_env_runs": [[5, 24], ["rusp.env_ipd.make_env", "rusp.env_ipd.make_env.reset", "rusp.env_ipd.make_env.step", "numpy.all", "rusp.env_ipd.make_env.step", "numpy.all", "rusp.env_ipd.make_env.step", "numpy.all", "rusp.env_ipd.make_env.step", "numpy.all", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.make_env", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step"], ["def", "test_env_runs", "(", ")", ":", "\n", "    ", "env", "=", "make_env", "(", ")", "\n", "env", ".", "reset", "(", ")", "\n", "\n", "action", "=", "{", "'action_defect'", ":", "np", ".", "array", "(", "[", "0", ",", "0", "]", ")", "}", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "assert", "np", ".", "all", "(", "rew", "==", "np", ".", "array", "(", "[", "2", ",", "2", "]", ")", ")", "\n", "\n", "action", "=", "{", "'action_defect'", ":", "np", ".", "array", "(", "[", "1", ",", "0", "]", ")", "}", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "assert", "np", ".", "all", "(", "rew", "==", "np", ".", "array", "(", "[", "4", ",", "-", "2", "]", ")", ")", "\n", "\n", "action", "=", "{", "'action_defect'", ":", "np", ".", "array", "(", "[", "0", ",", "1", "]", ")", "}", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "assert", "np", ".", "all", "(", "rew", "==", "np", ".", "array", "(", "[", "-", "2", ",", "4", "]", ")", ")", "\n", "\n", "action", "=", "{", "'action_defect'", ":", "np", ".", "array", "(", "[", "1", ",", "1", "]", ")", "}", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "assert", "np", ".", "all", "(", "rew", "==", "np", ".", "array", "(", "[", "0", ",", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.test_env_ipd.test_env_against_all_c": [[26, 37], ["rusp.env_ipd.make_env", "rusp.env_ipd.make_env.reset", "rusp.env_ipd.make_env.step", "numpy.all", "rusp.env_ipd.make_env.step", "numpy.all", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.make_env", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step"], ["", "def", "test_env_against_all_c", "(", ")", ":", "\n", "    ", "env", "=", "make_env", "(", "against_all_c", "=", "True", ")", "\n", "env", ".", "reset", "(", ")", "\n", "\n", "action", "=", "{", "'action_defect'", ":", "np", ".", "array", "(", "[", "0", "]", ")", "}", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "assert", "np", ".", "all", "(", "rew", "==", "np", ".", "array", "(", "[", "2", "]", ")", ")", "\n", "\n", "action", "=", "{", "'action_defect'", ":", "np", ".", "array", "(", "[", "1", "]", ")", "}", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "assert", "np", ".", "all", "(", "rew", "==", "np", ".", "array", "(", "[", "4", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.test_env_ipd.test_env_against_all_d": [[39, 50], ["rusp.env_ipd.make_env", "rusp.env_ipd.make_env.reset", "rusp.env_ipd.make_env.step", "numpy.all", "rusp.env_ipd.make_env.step", "numpy.all", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.make_env", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step"], ["", "def", "test_env_against_all_d", "(", ")", ":", "\n", "    ", "env", "=", "make_env", "(", "against_all_d", "=", "True", ")", "\n", "env", ".", "reset", "(", ")", "\n", "\n", "action", "=", "{", "'action_defect'", ":", "np", ".", "array", "(", "[", "0", "]", ")", "}", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "assert", "np", ".", "all", "(", "rew", "==", "np", ".", "array", "(", "[", "-", "2", "]", ")", ")", "\n", "\n", "action", "=", "{", "'action_defect'", ":", "np", ".", "array", "(", "[", "1", "]", ")", "}", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "assert", "np", ".", "all", "(", "rew", "==", "np", ".", "array", "(", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.test_env_ipd.test_env_against_tft": [[52, 75], ["rusp.env_ipd.make_env", "rusp.env_ipd.make_env.reset", "rusp.env_ipd.make_env.step", "numpy.all", "rusp.env_ipd.make_env.step", "numpy.all", "rusp.env_ipd.make_env.step", "numpy.all", "rusp.env_ipd.make_env.step", "numpy.all", "rusp.env_ipd.make_env.step", "numpy.all", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.make_env", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step"], ["", "def", "test_env_against_tft", "(", ")", ":", "\n", "    ", "env", "=", "make_env", "(", "against_tft", "=", "True", ")", "\n", "env", ".", "reset", "(", ")", "\n", "\n", "action", "=", "{", "'action_defect'", ":", "np", ".", "array", "(", "[", "0", "]", ")", "}", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "assert", "np", ".", "all", "(", "rew", "==", "np", ".", "array", "(", "[", "2", "]", ")", ")", "\n", "\n", "action", "=", "{", "'action_defect'", ":", "np", ".", "array", "(", "[", "1", "]", ")", "}", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "assert", "np", ".", "all", "(", "rew", "==", "np", ".", "array", "(", "[", "4", "]", ")", ")", "\n", "\n", "action", "=", "{", "'action_defect'", ":", "np", ".", "array", "(", "[", "1", "]", ")", "}", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "assert", "np", ".", "all", "(", "rew", "==", "np", ".", "array", "(", "[", "0", "]", ")", ")", "\n", "\n", "action", "=", "{", "'action_defect'", ":", "np", ".", "array", "(", "[", "0", "]", ")", "}", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "assert", "np", ".", "all", "(", "rew", "==", "np", ".", "array", "(", "[", "-", "2", "]", ")", ")", "\n", "\n", "action", "=", "{", "'action_defect'", ":", "np", ".", "array", "(", "[", "0", "]", ")", "}", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "assert", "np", ".", "all", "(", "rew", "==", "np", ".", "array", "(", "[", "2", "]", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.test_wrapper_rusp.test_compute_observations": [[8, 55], ["os.path.dirname", "rusp.wrappers_rusp.RUSPGenerator", "rusp.wrappers_rusp.RUSPGenerator._generate_social_preferences", "rusp.wrappers_rusp.RUSPGenerator._generate_uncertainty", "numpy.arange().reshape", "numpy.arange().reshape", "rusp.wrappers_rusp.RUSPGenerator._precompute_observations", "numpy.all", "numpy.all", "numpy.all", "numpy.all", "numpy.all", "numpy.all", "numpy.all", "numpy.all", "numpy.all", "numpy.all", "numpy.all", "numpy.all", "os.path.abspath", "numpy.arange().reshape", "numpy.arange", "numpy.arange", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.arange", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.RUSPGenerator._generate_social_preferences", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.RUSPGenerator._generate_uncertainty", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.RUSPGenerator._precompute_observations"], ["def", "test_compute_observations", "(", ")", ":", "\n", "    ", "N_AGENTS", "=", "2", "\n", "FILE_PATH", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "graph_generator", "=", "RUSPGenerator", "(", ")", "\n", "\n", "graph_generator", ".", "_generate_social_preferences", "(", "N_AGENTS", ")", "\n", "graph_generator", ".", "_generate_uncertainty", "(", "N_AGENTS", ")", "\n", "\n", "graph_generator", ".", "noise_std", "=", "np", ".", "arange", "(", "1", ",", "N_AGENTS", "**", "3", "+", "1", ")", ".", "reshape", "(", "(", "N_AGENTS", ",", "N_AGENTS", ",", "N_AGENTS", ")", ")", "\n", "graph_generator", ".", "noise", "=", "np", ".", "arange", "(", "1", ",", "N_AGENTS", "**", "3", "+", "1", ")", ".", "reshape", "(", "(", "N_AGENTS", ",", "N_AGENTS", ",", "N_AGENTS", ")", ")", "*", "10", "\n", "graph_generator", ".", "unnormalized_reward_xform_mat", "=", "graph_generator", ".", "reward_xform_mat", "=", "np", ".", "arange", "(", "1", ",", "N_AGENTS", "**", "2", "+", "1", ")", ".", "reshape", "(", "(", "N_AGENTS", ",", "N_AGENTS", ")", ")", "\n", "\n", "graph_generator", ".", "_precompute_observations", "(", "N_AGENTS", ")", "\n", "\n", "assert", "np", ".", "all", "(", "graph_generator", ".", "precomputed_obs", "[", "'self_rew_value'", "]", "==", "np", ".", "array", "(", "[", "1", ",", "4", "]", ")", ")", "\n", "assert", "np", ".", "all", "(", "graph_generator", ".", "precomputed_obs", "[", "'self_rew_value_noisy'", "]", "==", "np", ".", "array", "(", "[", "1", ",", "4", "]", ")", "+", "np", ".", "array", "(", "[", "10", ",", "80", "]", ")", ")", "\n", "assert", "np", ".", "all", "(", "graph_generator", ".", "precomputed_obs", "[", "'self_rew_value_noise_level'", "]", "==", "np", ".", "array", "(", "[", "1", ",", "8", "]", ")", ")", "\n", "\n", "assert", "np", ".", "all", "(", "graph_generator", ".", "precomputed_obs", "[", "'other_rew_value_s'", "]", "==", "np", ".", "array", "(", "\n", "[", "[", "1", ",", "4", "]", ",", "\n", "[", "1", ",", "4", "]", "]", ")", ")", "\n", "assert", "np", ".", "all", "(", "graph_generator", ".", "precomputed_obs", "[", "'other_rew_value_s_noisy'", "]", "==", "np", ".", "array", "(", "\n", "[", "[", "1", "+", "10", ",", "4", "+", "40", "]", ",", "\n", "[", "1", "+", "50", ",", "4", "+", "80", "]", "]", ")", ")", "\n", "assert", "np", ".", "all", "(", "graph_generator", ".", "precomputed_obs", "[", "'other_rew_value_s_noise_level'", "]", "==", "np", ".", "array", "(", "\n", "[", "[", "1", ",", "4", "]", ",", "\n", "[", "5", ",", "8", "]", "]", ")", ")", "\n", "\n", "assert", "np", ".", "all", "(", "graph_generator", ".", "precomputed_obs", "[", "'rew_share_so_s'", "]", "==", "np", ".", "array", "(", "\n", "[", "[", "1", ",", "2", "]", ",", "\n", "[", "3", ",", "4", "]", "]", ")", ")", "\n", "assert", "np", ".", "all", "(", "graph_generator", ".", "precomputed_obs", "[", "'rew_share_so_s_noisy'", "]", "==", "np", ".", "array", "(", "\n", "[", "[", "1", "+", "10", ",", "2", "+", "20", "]", ",", "\n", "[", "3", "+", "70", ",", "4", "+", "80", "]", "]", ")", ")", "\n", "assert", "np", ".", "all", "(", "graph_generator", ".", "precomputed_obs", "[", "'rew_share_so_s_noise_level'", "]", "==", "np", ".", "array", "(", "\n", "[", "[", "1", ",", "2", "]", ",", "\n", "[", "7", ",", "8", "]", "]", ")", ")", "\n", "\n", "assert", "np", ".", "all", "(", "graph_generator", ".", "precomputed_obs", "[", "'rew_share_os_o'", "]", "==", "np", ".", "array", "(", "\n", "[", "[", "1", ",", "3", "]", ",", "\n", "[", "2", ",", "4", "]", "]", ")", ")", "\n", "assert", "np", ".", "all", "(", "graph_generator", ".", "precomputed_obs", "[", "'rew_share_os_o_noisy'", "]", "==", "np", ".", "array", "(", "\n", "[", "[", "1", "+", "10", ",", "3", "+", "70", "]", ",", "\n", "[", "2", "+", "20", ",", "4", "+", "80", "]", "]", ")", ")", "\n", "assert", "np", ".", "all", "(", "graph_generator", ".", "precomputed_obs", "[", "'rew_share_os_o_noise_level'", "]", "==", "np", ".", "array", "(", "\n", "[", "[", "1", ",", "7", "]", ",", "\n", "[", "2", ",", "8", "]", "]", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ZeroRews.step": [[46, 49], ["env_oasis.ZeroRews.env.step", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step"], ["def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "return", "obs", ",", "np", ".", "zeros", "(", "(", "self", ".", "metadata", "[", "'n_agents'", "]", ",", ")", ")", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.OasisActionMasks.__init__": [[57, 64], ["gym.ObservationWrapper.__init__", "gym.spaces.Dict", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "env", ",", "mask_all_when_dead", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "observation_space", ".", "spaces", "[", "'mask'", "]", "=", "gym", ".", "spaces", ".", "Dict", "(", "{", "\n", "'action_movement'", ":", "gym", ".", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "(", "self", ".", "metadata", "[", "'n_actors'", "]", ",", "11", ")", ",", "float", ")", ",", "\n", "'action_attack_agent'", ":", "gym", ".", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "(", "self", ".", "metadata", "[", "'n_actors'", "]", ",", "self", ".", "metadata", "[", "'n_actors'", "]", "-", "1", ")", ",", "float", ")", ",", "\n", "'action_choose_option'", ":", "gym", ".", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "(", "self", ".", "metadata", "[", "'n_actors'", "]", ",", "3", ")", ",", "float", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.OasisActionMasks.observation": [[66, 77], ["numpy.ones", "numpy.ones", "numpy.ones", "[].astype"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "[", "'mask'", "]", "=", "{", "\n", "'action_movement'", ":", "np", ".", "ones", "(", "(", "self", ".", "metadata", "[", "'n_actors'", "]", ",", "3", ",", "11", ")", ",", "dtype", "=", "bool", ")", ",", "\n", "'action_attack_agent'", ":", "np", ".", "ones", "(", "(", "self", ".", "metadata", "[", "'n_actors'", "]", ",", "self", ".", "metadata", "[", "'n_actors'", "]", "-", "1", ")", ",", "dtype", "=", "bool", ")", ",", "\n", "'action_choose_option'", ":", "np", ".", "ones", "(", "(", "self", ".", "metadata", "[", "'n_actors'", "]", ",", "3", ")", ",", "dtype", "=", "bool", ")", ",", "\n", "}", "\n", "if", "self", ".", "mask_all_when_dead", ":", "\n", "            ", "obs", "[", "'mask'", "]", "[", "'action_movement'", "]", "*=", "(", "1", "-", "obs", "[", "'mask_is_dead'", "]", ")", "[", "...", ",", "None", "]", ".", "astype", "(", "bool", ")", "\n", "obs", "[", "'mask'", "]", "[", "'action_attack_agent'", "]", "*=", "(", "1", "-", "obs", "[", "'mask_is_dead'", "]", ")", ".", "astype", "(", "bool", ")", "\n", "obs", "[", "'mask'", "]", "[", "'action_choose_option'", "]", "*=", "(", "1", "-", "obs", "[", "'mask_is_dead'", "]", ")", ".", "astype", "(", "bool", ")", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AgentHealthWrapper.__init__": [[97, 110], ["gym.Wrapper.__init__", "mae_envs.wrappers.util.update_obs_space", "env_oasis.zero_action", "logging.info", "env_oasis.AgentHealthWrapper.zero_action.keys"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.zero_action"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "env", ",", "max_health", "=", "20", ",", "death_rew", "=", "-", "100", ",", "steps_freeze_on_death", "=", "100", ",", "life_rew", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "assert", "death_rew", "<=", "0", "\n", "assert", "life_rew", ">=", "0", "\n", "assert", "steps_freeze_on_death", ">=", "0", "\n", "self", ".", "observation_space", "=", "update_obs_space", "(", "self", ",", "{", "\n", "'agent_health'", ":", "[", "self", ".", "metadata", "[", "'n_agents'", "]", ",", "1", "]", ",", "\n", "'is_dead'", ":", "[", "self", ".", "metadata", "[", "'n_agents'", "]", ",", "1", "]", ",", "\n", "'time_to_alive'", ":", "[", "self", ".", "metadata", "[", "'n_agents'", "]", ",", "1", "]", "\n", "}", ")", "\n", "self", ".", "zero_action", "=", "zero_action", "(", "self", ".", "action_space", ")", "\n", "logging", ".", "info", "(", "f\"Only {self.zero_action.keys()} will be zerod during death\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AgentHealthWrapper.reset": [[111, 117], ["numpy.zeros", "numpy.zeros", "env_oasis.AgentHealthWrapper.observation", "numpy.ones", "numpy.ones", "env_oasis.AgentHealthWrapper.env.reset"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "healths", "=", "np", ".", "ones", "(", "self", ".", "metadata", "[", "'n_agents'", "]", ")", "*", "self", ".", "max_health", "\n", "self", ".", "time_since_death", "=", "np", ".", "ones", "(", "self", ".", "metadata", "[", "'n_agents'", "]", ")", "*", "np", ".", "inf", "\n", "self", ".", "is_dead", "=", "np", ".", "zeros", "(", "self", ".", "metadata", "[", "'n_agents'", "]", ")", "\n", "self", ".", "agent_died_count", "=", "np", ".", "zeros", "(", "self", ".", "metadata", "[", "'n_agents'", "]", ")", "\n", "return", "self", ".", "observation", "(", "self", ".", "env", ".", "reset", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AgentHealthWrapper.step": [[118, 160], ["numpy.logical_or", "env_oasis.AgentHealthWrapper.unwrapped.sim.forward", "numpy.any", "env_oasis.AgentHealthWrapper.env.step", "numpy.minimum", "numpy.where", "env_oasis.AgentHealthWrapper.unwrapped.sim.model.joint_name2id", "env_oasis.AgentHealthWrapper.unwrapped.sim.model.joint_name2id", "numpy.random.choice", "numpy.random.choice", "action.items", "numpy.sum", "numpy.sum", "numpy.min", "numpy.max", "numpy.std", "env_oasis.AgentHealthWrapper.observation", "numpy.sum", "numpy.sum", "numpy.max", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "self", ".", "is_dead", "=", "np", ".", "logical_or", "(", "self", ".", "healths", "<=", "0", ",", "self", ".", "time_since_death", "<", "self", ".", "steps_freeze_on_death", ")", "\n", "# If an agent just died, its health will be <= 0, update position and health", "\n", "for", "i", "in", "np", ".", "where", "(", "self", ".", "healths", "<=", "0", ")", "[", "0", "]", ":", "\n", "            ", "x_ind", "=", "self", ".", "unwrapped", ".", "sim", ".", "model", ".", "joint_name2id", "(", "f'agent{i}:tx'", ")", "\n", "y_ind", "=", "self", ".", "unwrapped", ".", "sim", ".", "model", ".", "joint_name2id", "(", "f'agent{i}:ty'", ")", "\n", "fs", "=", "self", ".", "unwrapped", ".", "floor_size", "\n", "self", ".", "unwrapped", ".", "sim", ".", "data", ".", "qpos", "[", "x_ind", "]", "=", "np", ".", "random", ".", "choice", "(", "[", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "0", ")", ",", "np", ".", "random", ".", "uniform", "(", "fs", ",", "fs", "+", "1", ")", "]", ")", "\n", "self", ".", "unwrapped", ".", "sim", ".", "data", ".", "qpos", "[", "y_ind", "]", "=", "np", ".", "random", ".", "choice", "(", "[", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "0", ")", ",", "np", ".", "random", ".", "uniform", "(", "fs", ",", "fs", "+", "1", ")", "]", ")", "\n", "self", ".", "healths", "[", "i", "]", "=", "self", ".", "max_health", "\n", "self", ".", "time_since_death", "[", "i", "]", "=", "0", "\n", "self", ".", "agent_died_count", "[", "i", "]", "+=", "1", "\n", "", "self", ".", "unwrapped", ".", "sim", ".", "forward", "(", ")", "# Forward the sim so their position gets updated sooner", "\n", "\n", "# Zero out actions for all dead agents", "\n", "if", "np", ".", "any", "(", "self", ".", "is_dead", ")", ":", "\n", "            ", "for", "ac_key", ",", "ac", "in", "action", ".", "items", "(", ")", ":", "\n", "                ", "ac", "[", "self", ".", "is_dead", "]", "=", "self", ".", "zero_action", "[", "ac_key", "]", "[", "self", ".", "is_dead", "]", "\n", "\n", "", "", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "\n", "# Update healths", "\n", "self", ".", "healths", "[", "~", "self", ".", "is_dead", "]", "+=", "info", "[", "'health_delta'", "]", "[", "~", "self", ".", "is_dead", "]", "# only change health of alive agents", "\n", "self", ".", "healths", "=", "np", ".", "minimum", "(", "self", ".", "healths", ",", "self", ".", "max_health", ")", "\n", "self", ".", "time_since_death", "+=", "1", "\n", "\n", "rew", "[", "self", ".", "healths", "<=", "0", "]", "+=", "self", ".", "death_rew", "\n", "\n", "# Reward for living", "\n", "rew", "[", "~", "self", ".", "is_dead", "]", "+=", "self", ".", "life_rew", "\n", "\n", "# Done stats", "\n", "if", "done", ":", "\n", "            ", "info", "[", "'n_unique_died'", "]", "=", "np", ".", "sum", "(", "self", ".", "agent_died_count", ">", "0", ")", "\n", "info", "[", "'only_one_died'", "]", "=", "(", "np", ".", "sum", "(", "self", ".", "agent_died_count", ">", "0", ")", "==", "1", ")", "\n", "info", "[", "'n_died'", "]", "=", "np", ".", "sum", "(", "self", ".", "agent_died_count", ")", "\n", "info", "[", "'n_died_min'", "]", "=", "np", ".", "min", "(", "self", ".", "agent_died_count", ")", "\n", "info", "[", "'n_died_max'", "]", "=", "np", ".", "max", "(", "self", ".", "agent_died_count", ")", "\n", "info", "[", "'n_died_std'", "]", "=", "np", ".", "std", "(", "self", ".", "agent_died_count", ")", "\n", "info", "[", "'n_died_total_minus_max'", "]", "=", "np", ".", "sum", "(", "self", ".", "agent_died_count", ")", "-", "np", ".", "max", "(", "self", ".", "agent_died_count", ")", "\n", "\n", "", "return", "self", ".", "observation", "(", "obs", ")", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AgentHealthWrapper.observation": [[161, 167], ["env_oasis.AgentHealthWrapper.is_dead[].astype", "numpy.minimum"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "[", "'agent_health'", "]", "=", "self", ".", "healths", "[", ":", ",", "None", "]", "\n", "obs", "[", "'is_dead'", "]", "=", "self", ".", "is_dead", "[", ":", ",", "None", "]", "\n", "obs", "[", "'mask_is_dead'", "]", "=", "self", ".", "is_dead", "[", ":", ",", "None", "]", ".", "astype", "(", "bool", ")", "\n", "obs", "[", "'time_to_alive'", "]", "=", "np", ".", "minimum", "(", "1", ",", "self", ".", "time_since_death", "/", "self", ".", "steps_freeze_on_death", ")", "[", ":", ",", "None", "]", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.FoodIncreaseHealth.__init__": [[177, 180], ["gym.Wrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "health_per_food_bounds", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "health_per_food_bounds", "=", "health_per_food_bounds", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.FoodIncreaseHealth.reset": [[181, 184], ["numpy.random.uniform", "env_oasis.FoodIncreaseHealth.env.reset"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "health_per_food", "=", "np", ".", "random", ".", "uniform", "(", "self", ".", "health_per_food_bounds", "[", "0", "]", ",", "self", ".", "health_per_food_bounds", "[", "1", "]", ")", "\n", "return", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.FoodIncreaseHealth.step": [[185, 194], ["env_oasis.FoodIncreaseHealth.env.step", "numpy.zeros", "numpy.sum", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "if", "'health_delta'", "not", "in", "info", ":", "\n", "            ", "info", "[", "'health_delta'", "]", "=", "np", ".", "zeros", "(", "(", "self", ".", "metadata", "[", "'n_agents'", "]", ")", ")", "\n", "\n", "", "info", "[", "'health_delta'", "]", "+=", "np", ".", "sum", "(", "info", "[", "'agents_eat'", "]", ",", "1", ")", "*", "self", ".", "health_per_food", "\n", "info", "[", "'total_health_gained_from_food'", "]", "=", "np", ".", "sum", "(", "info", "[", "'agents_eat'", "]", ")", "*", "self", ".", "health_per_food", "\n", "\n", "return", "obs", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.TimeDecreaseHealth.__init__": [[203, 206], ["gym.Wrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "env", ",", "health_per_step", "=", "-", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.TimeDecreaseHealth.step": [[207, 215], ["env_oasis.TimeDecreaseHealth.env.step", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "if", "'health_delta'", "not", "in", "info", ":", "\n", "            ", "info", "[", "'health_delta'", "]", "=", "np", ".", "zeros", "(", "(", "self", ".", "metadata", "[", "'n_agents'", "]", ")", ")", "\n", "\n", "", "info", "[", "'health_delta'", "]", "+=", "self", ".", "health_per_step", "\n", "\n", "return", "obs", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.__init__": [[234, 243], ["rusp.wrappers_util.OtherActorAttentionAction.__init__", "mae_envs.wrappers.util.update_obs_space"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.wrappers.util.update_obs_space"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "env", ",", "attack_damage", "=", "-", "5", ",", "attack_range", "=", "0.7", ",", "mask_eat_if_attacked", "=", "True", ",", "\n", "only_attack_in_front", "=", "True", ")", ":", "\n", "        ", "assert", "attack_damage", "<=", "0", "\n", "assert", "attack_range", ">=", "0", "\n", "super", "(", ")", ".", "__init__", "(", "env", ",", "'action_attack_agent'", ")", "\n", "self", ".", "observation_space", "=", "update_obs_space", "(", "self", ",", "{", "\n", "'attacked_me'", ":", "[", "self", ".", "n_agents", ",", "self", ".", "n_agents", ",", "1", "]", ",", "\n", "'n_attacked_me'", ":", "[", "self", ".", "n_agents", ",", "1", "]", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.reset": [[245, 250], ["numpy.zeros", "numpy.zeros", "env_oasis.AttackAction.observation", "env_oasis.AttackAction.env.reset"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "attack_counts", "=", "np", ".", "zeros", "(", "self", ".", "n_agents", ")", "\n", "self", ".", "attacked_me", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_agents", ")", ")", "\n", "self", ".", "previous_obs", "=", "self", ".", "observation", "(", "self", ".", "env", ".", "reset", "(", ")", ")", "\n", "return", "self", ".", "previous_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.step": [[251, 290], ["numpy.zeros", "range", "numpy.sum", "numpy.zeros", "numpy.sum", "env_oasis.AttackAction.env.step", "env_oasis.AttackAction.observation", "env_oasis.AttackAction._get_target_actor", "len", "numpy.sum", "numpy.mean", "numpy.linalg.norm", "numpy.any", "numpy.any", "numpy.logical_and", "numpy.argsort"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_util.OtherActorAttentionAction._get_target_actor"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "attack_matrix", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_agents", ")", ",", "dtype", "=", "bool", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_agents", ")", ":", "\n", "            ", "target_actors", "=", "self", ".", "_get_target_actor", "(", "i", ",", "action", ")", "\n", "if", "len", "(", "target_actors", ")", ":", "\n", "# See if the targeted agent can be attacked (in range and in front)", "\n", "                ", "aa_ranges", "=", "np", ".", "linalg", ".", "norm", "(", "self", ".", "previous_obs", "[", "'agent_pos'", "]", "[", "i", "]", "-", "self", ".", "previous_obs", "[", "'agent_pos'", "]", "[", "target_actors", "]", ",", "axis", "=", "1", ")", "\n", "in_range", "=", "aa_ranges", "<", "self", ".", "attack_range", "\n", "in_front", "=", "self", ".", "previous_obs", "[", "'mask_aa_obs'", "]", "[", "i", ",", "target_actors", "]", "\n", "able_to_attack", "=", "np", ".", "logical_and", "(", "in_range", ",", "in_front", ")", "if", "self", ".", "only_attack_in_front", "else", "in_range", "\n", "if", "np", ".", "any", "(", "able_to_attack", ")", ":", "\n", "# Filter down to those that are in range and in front", "\n", "                    ", "target_actors", "=", "target_actors", "[", "able_to_attack", "]", "\n", "aa_ranges", "=", "aa_ranges", "[", "able_to_attack", "]", "\n", "# Only attack the closest agent to you", "\n", "target_actor", "=", "target_actors", "[", "np", ".", "argsort", "(", "aa_ranges", ")", "[", "0", "]", "]", "\n", "attack_matrix", "[", "i", ",", "target_actor", "]", "=", "1", "\n", "", "", "", "self", ".", "attacked_me", "=", "attack_matrix", ".", "T", "\n", "self", ".", "attack_counts", "+=", "np", ".", "sum", "(", "attack_matrix", ",", "1", ")", "\n", "\n", "# Compute health updates", "\n", "health_deltas", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_agents", ",", "self", ".", "n_agents", ")", ")", "\n", "health_deltas", "[", "self", ".", "attacked_me", "]", "+=", "self", ".", "attack_damage", "\n", "\n", "health_deltas", "=", "np", ".", "sum", "(", "health_deltas", ",", "1", ")", "\n", "\n", "# Turn off the eat action if you were attacked", "\n", "if", "self", ".", "mask_eat_if_attacked", ":", "\n", "            ", "action", "[", "'action_eat_food'", "]", "*=", "~", "np", ".", "any", "(", "self", ".", "attacked_me", ",", "1", ",", "keepdims", "=", "True", ")", "\n", "\n", "", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "info", "[", "'health_delta'", "]", "+=", "health_deltas", "\n", "self", ".", "previous_obs", "=", "self", ".", "observation", "(", "obs", ")", "\n", "\n", "if", "done", ":", "\n", "            ", "info", "[", "'n_attacks'", "]", "=", "np", ".", "sum", "(", "self", ".", "attack_counts", ")", "\n", "info", "[", "'n_attacks_per_agent'", "]", "=", "np", ".", "mean", "(", "self", ".", "attack_counts", ")", "\n", "\n", "", "return", "self", ".", "previous_obs", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.AttackAction.observation": [[291, 295], ["numpy.sum"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "[", "'attacked_me'", "]", "=", "self", ".", "attacked_me", "[", ":", ",", ":", ",", "None", "]", "\n", "obs", "[", "'n_attacked_me'", "]", "=", "np", ".", "sum", "(", "self", ".", "attacked_me", ",", "1", ",", "keepdims", "=", "True", ")", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.__init__": [[302, 309], ["gym.Wrapper.__init__", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__"], ["@", "store_args", "\n", "def", "__init__", "(", "self", ",", "env", ",", "action_key", ",", "options_list", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "colors", "=", "{", "\n", "'action_attack_agent'", ":", "np", ".", "array", "(", "[", "1.", ",", "0", ",", "0", ",", "1.0", "]", ")", ",", "\n", "'action_eat_food'", ":", "np", ".", "array", "(", "[", "0", ",", "1.", ",", "0", ",", "1.0", "]", ")", ",", "\n", "'do_nothing'", ":", "np", ".", "array", "(", "[", "0", ",", "1", ",", "1", ",", "1", "]", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step": [[311, 315], ["range", "env_oasis.ColorAgentsByOption.env.step", "env_oasis.ColorAgentsByOption._color_agent"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption.step", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption._color_agent"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "self", ".", "unwrapped", ".", "n_agents", ")", ":", "\n", "            ", "self", ".", "_color_agent", "(", "self", ".", "options_list", "[", "action", "[", "self", ".", "action_key", "]", "[", "i", "]", "]", ",", "i", ")", "\n", "", "return", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.ColorAgentsByOption._color_agent": [[316, 320], ["sim.model.geom_name2id"], "methods", ["None"], ["", "def", "_color_agent", "(", "self", ",", "ac_name", ",", "agent_ind", ")", ":", "\n", "        ", "sim", "=", "self", ".", "unwrapped", ".", "sim", "\n", "geom_ind", "=", "sim", ".", "model", ".", "geom_name2id", "(", "f'agent{agent_ind}:agent'", ")", "\n", "sim", ".", "model", ".", "geom_rgba", "[", "geom_ind", "]", "=", "self", ".", "colors", "[", "ac_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.zero_action": [[22, 39], ["collections.OrderedDict", "ac_space.spaces.items", "isinstance", "isinstance", "numpy.zeros_like", "isinstance", "s.sample", "isinstance", "numpy.ones_like", "NotImplementedError", "s.sample", "numpy.ones_like", "s.sample"], "function", ["None"], ["def", "zero_action", "(", "ac_space", ")", ":", "\n", "    ", "'''\n        Define default zero action for when an agent dies such that it stays in place and doesn't do anything.\n    '''", "\n", "ac", "=", "OrderedDict", "(", ")", "\n", "for", "ac_key", ",", "s", "in", "ac_space", ".", "spaces", ".", "items", "(", ")", ":", "\n", "        ", "assert", "isinstance", "(", "s", ",", "gym", ".", "spaces", ".", "Tuple", ")", ",", "f\"space {s} is not a Tuple\"", "\n", "single_agent_space", "=", "s", ".", "spaces", "[", "0", "]", "\n", "if", "isinstance", "(", "single_agent_space", ",", "gym", ".", "spaces", ".", "Box", ")", ":", "\n", "            ", "ac", "[", "ac_key", "]", "=", "np", ".", "zeros_like", "(", "s", ".", "sample", "(", ")", ")", "\n", "", "elif", "isinstance", "(", "single_agent_space", ",", "gym", ".", "spaces", ".", "Discrete", ")", ":", "\n", "            ", "ac", "[", "ac_key", "]", "=", "np", ".", "ones_like", "(", "s", ".", "sample", "(", ")", ")", "*", "(", "single_agent_space", ".", "n", "//", "2", ")", "\n", "", "elif", "isinstance", "(", "single_agent_space", ",", "gym", ".", "spaces", ".", "MultiDiscrete", ")", ":", "\n", "            ", "ac", "[", "ac_key", "]", "=", "np", ".", "ones_like", "(", "s", ".", "sample", "(", ")", ",", "dtype", "=", "int", ")", "*", "(", "single_agent_space", ".", "nvec", "//", "2", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"MultiDiscrete not NotImplementedError\"", ")", "\n", "", "", "return", "ac", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.env_oasis.make_env": [[322, 453], ["mae_envs.envs.base.Base", "OasisActionMasks.add_module", "OasisActionMasks.add_module", "numpy.repeat", "OasisActionMasks.add_module", "OasisActionMasks.reset", "rusp.wrappers_rusp.add_rew_share_observation_keys", "mae_envs.wrappers.multi_agent.SplitMultiAgentActions", "mae_envs.wrappers.util.DiscretizeActionWrapper", "mae_envs.wrappers.line_of_sight.AgentAgentObsMask2D", "env_oasis.ZeroRews", "rusp.wrappers_util.RandomizedHorizonWrapper", "mae_envs.wrappers.food.FoodHealthWrapper", "keys_copy.append", "env_oasis.FoodIncreaseHealth", "env_oasis.TimeDecreaseHealth", "env_oasis.AttackAction", "rusp.wrappers_util.ActionOptionsWrapper", "env_oasis.ColorAgentsByOption", "env_oasis..append", "keys_other_agents.append", "env_oasis..append", "env_oasis..append", "env_oasis.AgentHealthWrapper", "mae_envs.wrappers.food.AlwaysEatWrapper", "rusp.wrappers_rusp.RUSPWrapper", "rusp.wrappers_util.RandomIdentityVector", "mae_envs.wrappers.multi_agent.SplitObservations", "mae_envs.wrappers.util.ConcatenateObsWrapper", "mae_envs.wrappers.util.DiscardMujocoExceptionEpisodes", "mae_envs.wrappers.multi_agent.SelectKeysWrapper", "env_oasis.OasisActionMasks", "OasisActionMasks.add_module", "mae_envs.modules.world.WorldConstants", "mae_envs.modules.agents.Agents", "numpy.arange", "mae_envs.modules.util.close_to_other_object_placement", "mae_envs.modules.food.Food", "mae_envs.modules.world.FloorAttributes", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.rusp.wrappers_rusp.add_rew_share_observation_keys", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.envs.base.Base.add_module", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.modules.util.close_to_other_object_placement"], ["", "", "def", "make_env", "(", "n_substeps", "=", "15", ",", "n_agents", "=", "3", ",", "\n", "floor_size", "=", "[", "1.5", ",", "6", "]", ",", "action_lims", "=", "(", "-", "0.9", ",", "0.9", ")", ",", "\n", "grid_size", "=", "60", ",", "other_friction", "=", "0.01", ",", "box_floor_friction", "=", "0.2", ",", "gravity", "=", "[", "0", ",", "0", ",", "-", "50", "]", ",", "\n", "horizon", "=", "1000", ",", "horizon_lower", "=", "None", ",", "horizon_upper", "=", "None", ",", "prob_per_step_to_stop", "=", "0.001", ",", "\n", "# Food", "\n", "n_food", "=", "1", ",", "n_food_cluster", "=", "1", ",", "food_radius", "=", "0.4", ",", "\n", "food_respawn_time", "=", "0", ",", "max_food_health", "=", "5", ",", "food_together_radius", "=", "0.4", ",", "\n", "food_rew_type", "=", "'selfish'", ",", "food_reward_scale", "=", "0.0", ",", "\n", "# Health", "\n", "max_agent_health", "=", "20", ",", "health_per_food_bounds", "=", "[", "2.1", ",", "2.7", "]", ",", "health_per_step", "=", "-", "1.0", ",", "\n", "# Attacking", "\n", "attack_range", "=", "0.7", ",", "attack_damage", "=", "-", "5.0", ",", "only_attack_in_front", "=", "True", ",", "\n", "# Death", "\n", "life_rew", "=", "1", ",", "death_rew", "=", "-", "100", ",", "steps_freeze_on_death", "=", "100", ",", "\n", "# Random Teams", "\n", "rusp_args", "=", "{", "}", ",", "\n", "# ID", "\n", "id_dim", "=", "16", ",", "\n", "# Action Masking", "\n", "mask_all_when_dead", "=", "True", ")", ":", "\n", "    ", "env", "=", "Base", "(", "n_agents", "=", "n_agents", ",", "\n", "n_substeps", "=", "n_substeps", ",", "\n", "floor_size", "=", "floor_size", ",", "\n", "horizon", "=", "99999999999999", ",", "# Just a big number so actual horizon is done by RandomizedHorizonWrapper", "\n", "action_lims", "=", "action_lims", ",", "\n", "deterministic_mode", "=", "False", ",", "\n", "grid_size", "=", "grid_size", ")", "\n", "if", "box_floor_friction", "is", "not", "None", ":", "\n", "        ", "env", ".", "add_module", "(", "FloorAttributes", "(", "friction", "=", "box_floor_friction", ")", ")", "\n", "", "env", ".", "add_module", "(", "WorldConstants", "(", "gravity", "=", "gravity", ")", ")", "\n", "\n", "env", ".", "add_module", "(", "Agents", "(", "n_agents", ",", "\n", "placement_fn", "=", "uniform_placement", ",", "\n", "friction", "=", "other_friction", ")", ")", "\n", "\n", "# Food", "\n", "env", ".", "metadata", "[", "'food_together_radius'", "]", "=", "food_together_radius", "\n", "\n", "assert", "n_food", "%", "n_food_cluster", "==", "0", "\n", "cluster_assignments", "=", "np", ".", "repeat", "(", "np", ".", "arange", "(", "0", ",", "n_food", ",", "n_food", "//", "n_food_cluster", ")", ",", "n_food", "//", "n_food_cluster", ")", "\n", "food_placement", "=", "[", "close_to_other_object_placement", "(", "\n", "\"food\"", ",", "i", ",", "\"food_together_radius\"", ")", "for", "i", "in", "cluster_assignments", "]", "\n", "food_placement", "[", ":", ":", "n_food", "//", "n_food_cluster", "]", "=", "[", "uniform_placement", "]", "*", "n_food_cluster", "\n", "\n", "env", ".", "add_module", "(", "Food", "(", "n_food", ",", "placement_fn", "=", "food_placement", ")", ")", "\n", "\n", "env", ".", "reset", "(", ")", "\n", "\n", "keys_self", "=", "[", "\n", "'agent_qpos_qvel'", ",", "\n", "'agent_identity'", ",", "\n", "'agent_health'", ",", "\n", "'is_dead'", ",", "\n", "'time_to_alive'", ",", "\n", "'timestep'", "\n", "]", "\n", "keys_additional_self_vf", "=", "[", "'fraction_episode_done'", ",", "'horizon'", "]", "\n", "keys_copy", "=", "[", "'mask_is_dead'", "]", "\n", "keys_other_agents", "=", "[", "\n", "'agent_qpos_qvel'", ",", "\n", "'agent_identity'", ",", "\n", "'agent_health'", ",", "\n", "'is_dead'", ",", "\n", "'time_to_alive'", ",", "\n", "]", "\n", "keys_additional_other_agents_vf", "=", "[", "]", "\n", "keys_self_matrices", "=", "[", "]", "\n", "\n", "add_rew_share_observation_keys", "(", "keys_self", "=", "keys_self", ",", "\n", "keys_additional_self_vf", "=", "keys_additional_self_vf", ",", "\n", "keys_other_agents", "=", "keys_other_agents", ",", "\n", "keys_additional_other_agents_vf", "=", "keys_additional_other_agents_vf", ",", "\n", "keys_self_matrices", "=", "keys_self_matrices", ",", "\n", "**", "rusp_args", ")", "\n", "\n", "keys_external", "=", "[", "'other_agents'", ",", "\n", "'other_agents_vf'", ",", "\n", "'additional_self_vf_obs'", "]", "\n", "\n", "keys_self_masks", "=", "[", "'mask_aa_obs'", "]", "\n", "\n", "env", "=", "SplitMultiAgentActions", "(", "env", ")", "\n", "env", "=", "DiscretizeActionWrapper", "(", "env", ",", "'action_movement'", ")", "\n", "env", "=", "AgentAgentObsMask2D", "(", "env", ")", "\n", "\n", "env", "=", "ZeroRews", "(", "env", ")", "\n", "\n", "env", "=", "RandomizedHorizonWrapper", "(", "env", ",", "lower_lim", "=", "horizon_lower", "or", "horizon", ",", "upper_lim", "=", "horizon_upper", "or", "horizon", ",", "\n", "prob_per_step_to_stop", "=", "prob_per_step_to_stop", ")", "\n", "\n", "env", "=", "FoodHealthWrapper", "(", "env", ",", "respawn_time", "=", "(", "np", ".", "inf", "if", "food_respawn_time", "is", "None", "else", "food_respawn_time", ")", ",", "\n", "eat_thresh", "=", "(", "np", ".", "inf", "if", "food_radius", "is", "None", "else", "food_radius", ")", ",", "\n", "max_food_health", "=", "max_food_health", ",", "food_rew_type", "=", "food_rew_type", ",", "\n", "reward_scale", "=", "food_reward_scale", ",", "split_eat_between_agents", "=", "True", ")", "\n", "keys_external", "+=", "[", "'mask_af_obs'", ",", "'food_obs'", "]", "\n", "keys_copy", ".", "append", "(", "'close_enough_to_food'", ")", "\n", "\n", "env", "=", "FoodIncreaseHealth", "(", "env", ",", "health_per_food_bounds", "=", "health_per_food_bounds", ")", "\n", "env", "=", "TimeDecreaseHealth", "(", "env", ",", "health_per_step", "=", "health_per_step", ")", "\n", "\n", "# Attack action should go before Food Health wrapper, since it masks eat action", "\n", "env", "=", "AttackAction", "(", "env", ",", "attack_damage", "=", "attack_damage", ",", "attack_range", "=", "attack_range", ",", "\n", "only_attack_in_front", "=", "only_attack_in_front", ")", "\n", "env", "=", "ActionOptionsWrapper", "(", "env", ",", "[", "'action_attack_agent'", ",", "'action_eat_food'", "]", ",", "{", "'action_attack_agent'", ":", "-", "1", ",", "'action_eat_food'", ":", "0", "}", ")", "\n", "env", "=", "ColorAgentsByOption", "(", "env", ",", "'action_choose_option'", ",", "[", "'action_attack_agent'", ",", "'action_eat_food'", ",", "'do_nothing'", "]", ")", "\n", "keys_self", ".", "append", "(", "'previous_choice'", ")", "\n", "keys_other_agents", ".", "append", "(", "'previous_choice'", ")", "\n", "keys_self_matrices", ".", "append", "(", "'attacked_me'", ")", "\n", "keys_self", ".", "append", "(", "'n_attacked_me'", ")", "\n", "keys_other_agents", "+=", "[", "'attacked_me'", ",", "'n_attacked_me'", "]", "\n", "\n", "env", "=", "AgentHealthWrapper", "(", "env", ",", "max_health", "=", "max_agent_health", ",", "death_rew", "=", "death_rew", ",", "\n", "steps_freeze_on_death", "=", "steps_freeze_on_death", ",", "life_rew", "=", "life_rew", ")", "\n", "\n", "# This needs to come before options wrapper, so we can't group it above", "\n", "env", "=", "AlwaysEatWrapper", "(", "env", ",", "agent_idx_allowed", "=", "np", ".", "arange", "(", "n_agents", ")", ")", "\n", "\n", "env", "=", "RUSPWrapper", "(", "env", ",", "**", "rusp_args", ")", "\n", "\n", "env", "=", "RandomIdentityVector", "(", "env", ",", "vector_dim", "=", "id_dim", ")", "\n", "\n", "env", "=", "SplitObservations", "(", "env", ",", "keys_self", "+", "keys_additional_self_vf", ",", "\n", "keys_copy", "=", "keys_copy", ",", "keys_self_matrices", "=", "keys_self_matrices", "+", "keys_self_masks", ")", "\n", "env", "=", "ConcatenateObsWrapper", "(", "env", ",", "{", "'other_agents'", ":", "keys_other_agents", ",", "\n", "'other_agents_vf'", ":", "[", "'other_agents'", "]", "+", "keys_additional_other_agents_vf", ",", "\n", "'additional_self_vf_obs'", ":", "[", "k", "+", "'_self'", "for", "k", "in", "keys_additional_self_vf", "]", "}", ")", "\n", "env", "=", "DiscardMujocoExceptionEpisodes", "(", "env", ")", "\n", "env", "=", "SelectKeysWrapper", "(", "env", ",", "keys_self", "=", "keys_self", ",", "\n", "keys_other", "=", "keys_external", "+", "keys_copy", "+", "keys_self_masks", ")", "\n", "env", "=", "OasisActionMasks", "(", "env", ",", "mask_all_when_dead", "=", "mask_all_when_dead", ")", "\n", "return", "env", "\n", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.examples.test_all_policies.ExamineTest.test_examine_env": [[10, 24], ["test_all_policies.ExamineTest.assertRaises", "subprocess.check_call", "os.path.join"], "methods", ["None"], ["    ", "def", "test_examine_env", "(", "self", ")", ":", "\n", "        ", "envs", "=", "[", "\n", "\"hide_and_seek_full.jsonnet\"", ",", "\n", "\"hide_and_seek_quadrant.jsonnet\"", ",", "\n", "\"blueprint.jsonnet\"", ",", "\n", "\"lock_and_return.jsonnet\"", ",", "\n", "\"sequential_lock.jsonnet\"", ",", "\n", "\"shelter.jsonnet\"", ",", "\n", "]", "\n", "for", "env", "in", "envs", ":", "\n", "            ", "with", "self", ".", "assertRaises", "(", "subprocess", ".", "TimeoutExpired", ")", ":", "\n", "                ", "subprocess", ".", "check_call", "(", "\n", "[", "\"/usr/bin/env\"", ",", "\"python\"", ",", "EXAMINE_FILE_PATH", ",", "os", ".", "path", ".", "join", "(", "EXAMPLES_DIR", ",", "env", ")", "]", ",", "\n", "timeout", "=", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.examples.test_all_policies.ExamineTest.test_examine_policies": [[26, 40], ["test_all_policies.ExamineTest.assertRaises", "subprocess.check_call", "os.path.join", "os.path.join"], "methods", ["None"], ["", "", "", "def", "test_examine_policies", "(", "self", ")", ":", "\n", "        ", "envs_policies", "=", "[", "\n", "(", "\"hide_and_seek_full.jsonnet\"", ",", "\"hide_and_seek_full.npz\"", ")", ",", "\n", "(", "\"hide_and_seek_quadrant.jsonnet\"", ",", "\"hide_and_seek_quadrant.npz\"", ")", ",", "\n", "(", "\"blueprint.jsonnet\"", ",", "\"blueprint.npz\"", ")", ",", "\n", "(", "\"lock_and_return.jsonnet\"", ",", "\"lock_and_return.npz\"", ")", ",", "\n", "(", "\"sequential_lock.jsonnet\"", ",", "\"sequential_lock.npz\"", ")", ",", "\n", "(", "\"shelter.jsonnet\"", ",", "\"shelter.npz\"", ")", ",", "\n", "]", "\n", "for", "env", ",", "policy", "in", "envs_policies", ":", "\n", "            ", "with", "self", ".", "assertRaises", "(", "subprocess", ".", "TimeoutExpired", ")", ":", "\n", "                ", "subprocess", ".", "check_call", "(", "\n", "[", "\"/usr/bin/env\"", ",", "\"python\"", ",", "EXAMINE_FILE_PATH", ",", "os", ".", "path", ".", "join", "(", "EXAMPLES_DIR", ",", "env", ")", ",", "os", ".", "path", ".", "join", "(", "EXAMPLES_DIR", ",", "policy", ")", "]", ",", "\n", "timeout", "=", "15", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.normalizers.EMAMeanStd.__init__": [[33, 66], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "normalizers._std_from_mean_and_square", "tensorflow.maximum", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.maximum"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.normalizers._std_from_mean_and_square"], ["def", "__init__", "(", "self", ",", "beta", ",", "scope", "=", "\"ema\"", ",", "reuse", "=", "None", ",", "epsilon", "=", "1e-6", ",", "per_element_update", "=", "False", ",", "shape", "=", "(", ")", ",", "version", "=", "1", ")", ":", "\n", "        ", "self", ".", "_version", "=", "version", "\n", "self", ".", "_per_element_update", "=", "per_element_update", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "# Expected value of x", "\n", "            ", "self", ".", "_biased_mean", "=", "tf", ".", "get_variable", "(", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "shape", "=", "shape", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ",", "\n", "name", "=", "\"mean\"", ",", "\n", "trainable", "=", "False", ")", "\n", "# Expected value of x^2", "\n", "self", ".", "_biased_sq", "=", "tf", ".", "get_variable", "(", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "shape", "=", "shape", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ",", "\n", "name", "=", "\"sq\"", ",", "\n", "trainable", "=", "False", ")", "\n", "# How to integrate observations of x over time", "\n", "self", ".", "_one_minus_beta", "=", "1.0", "-", "beta", "\n", "# Weight placed on ema[-1] == 0.0 which we divide out to debias", "\n", "self", ".", "_debiasing_term", "=", "tf", ".", "get_variable", "(", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "shape", "=", "shape", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ",", "\n", "name", "=", "\"debiasing_term\"", ",", "\n", "trainable", "=", "False", ")", "\n", "self", ".", "shape", "=", "shape", "\n", "\n", "# the stored mean and square are biased due to setting ema[-1] = 0.0,", "\n", "# we correct for this by dividing by the debiasing term:", "\n", "self", ".", "mean", "=", "self", ".", "_biased_mean", "/", "tf", ".", "maximum", "(", "self", ".", "_debiasing_term", ",", "epsilon", ")", "\n", "self", ".", "std", "=", "_std_from_mean_and_square", "(", "mean", "=", "self", ".", "mean", ",", "square", "=", "self", ".", "_biased_sq", "/", "tf", ".", "maximum", "(", "self", ".", "_debiasing_term", ",", "epsilon", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.normalizers.EMAMeanStd.update_op": [[67, 88], ["tensorflow.cast", "tensorflow.constant", "tensorflow.to_float", "tensorflow.to_float", "tensorflow.group", "normalizers._mean_std_update_size", "tensorflow.cast", "tensorflow.assign", "tensorflow.assign", "tensorflow.assign", "tensorflow.to_float", "normalizers._interpolate", "normalizers._interpolate", "normalizers._interpolate", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.cast", "tensorflow.to_float", "tensorflow.square", "tensorflow.to_float"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.normalizers._mean_std_update_size", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.normalizers._interpolate", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.normalizers._interpolate", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.normalizers._interpolate"], ["", "", "def", "update_op", "(", "self", ",", "x", ",", "axes", "=", "(", "0", ",", ")", ")", ":", "\n", "        ", "scaled_weight", "=", "tf", ".", "cast", "(", "self", ".", "_one_minus_beta", ",", "tf", ".", "float64", ")", "\n", "if", "self", ".", "_per_element_update", ":", "\n", "# many updates were done at once in a batch, so we figure out what power", "\n", "# to raise `1-beta` to.", "\n", "# using the fact that for small 1.0 - beta we have:", "\n", "# 1 - beta^N ~= (1.0 - beta) * N", "\n", "            ", "size", "=", "_mean_std_update_size", "(", "x", ",", "axes", ")", "\n", "scaled_weight", "*=", "tf", ".", "cast", "(", "size", ",", "tf", ".", "float64", ")", "\n", "", "one", "=", "tf", ".", "constant", "(", "1.0", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "old_weight", "=", "one", "-", "scaled_weight", "\n", "old_weight_fp32", "=", "tf", ".", "to_float", "(", "old_weight", ")", "\n", "scaled_weight_fp32", "=", "tf", ".", "to_float", "(", "scaled_weight", ")", "\n", "return", "tf", ".", "group", "(", "\n", "# increment the running debiasing term by the contribution of the initial ema[-1] == 0.0 observation", "\n", "# (e.g. boost the observed value by how much it was initially discounted on step 1)", "\n", "tf", ".", "assign", "(", "self", ".", "_debiasing_term", ",", "tf", ".", "to_float", "(", "_interpolate", "(", "old", "=", "tf", ".", "cast", "(", "self", ".", "_debiasing_term", ",", "tf", ".", "float64", ")", ",", "new", "=", "one", ",", "old_weight", "=", "old_weight", ",", "scaled_weight", "=", "scaled_weight", ")", ")", ")", ",", "\n", "# do an interpolation on the expected value of X", "\n", "tf", ".", "assign", "(", "self", ".", "_biased_mean", ",", "_interpolate", "(", "old", "=", "self", ".", "_biased_mean", ",", "new", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "to_float", "(", "x", ")", ",", "axis", "=", "axes", ")", ",", "old_weight", "=", "old_weight_fp32", ",", "scaled_weight", "=", "scaled_weight_fp32", ")", ")", ",", "\n", "# do an interpolation on the expected value of X^2", "\n", "tf", ".", "assign", "(", "self", ".", "_biased_sq", ",", "_interpolate", "(", "old", "=", "self", ".", "_biased_sq", ",", "new", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "tf", ".", "to_float", "(", "x", ")", ")", ",", "axis", "=", "axes", ")", ",", "old_weight", "=", "old_weight_fp32", ",", "scaled_weight", "=", "scaled_weight_fp32", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.normalizers._mean_std_update_size": [[4, 9], ["tensorflow.shape", "tensorflow.gather", "tensorflow.reduce_prod"], "function", ["None"], ["def", "_mean_std_update_size", "(", "x", ",", "axes", ")", ":", "\n", "    ", "x_shape", "=", "tf", ".", "shape", "(", "x", ")", "\n", "x_dims_to_reduce", "=", "tf", ".", "gather", "(", "x_shape", ",", "axes", ")", "\n", "size", "=", "tf", ".", "reduce_prod", "(", "x_dims_to_reduce", ")", "\n", "return", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.normalizers._interpolate": [[11, 13], ["None"], "function", ["None"], ["", "def", "_interpolate", "(", "old", ",", "new", ",", "old_weight", ",", "scaled_weight", ")", ":", "\n", "    ", "return", "old", "*", "old_weight", "+", "new", "*", "scaled_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.normalizers._std_from_mean_and_square": [[15, 18], ["tensorflow.sqrt", "tensorflow.to_float", "tensorflow.square", "tensorflow.maximum"], "function", ["None"], ["", "def", "_std_from_mean_and_square", "(", "mean", ",", "square", ")", ":", "\n", "    ", "var_est", "=", "tf", ".", "to_float", "(", "square", ")", "-", "tf", ".", "square", "(", "mean", ")", "\n", "return", "tf", ".", "sqrt", "(", "tf", ".", "maximum", "(", "var_est", ",", "1e-2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.graph_construct.construct_tf_graph": [[17, 225], ["collections.OrderedDict", "logger.info", "tensorflow.variable_scope", "enumerate", "all_inputs.items", "copy.deepcopy", "copy.deepcopy.pop", "copy.deepcopy.pop", "copy.deepcopy.pop", "copy.deepcopy.pop", "tensorflow.variable_scope", "traceback.print_exc", "print", "sys.exit", "copy.deepcopy.pop", "range", "len", "len", "len", "tensorflow.layers.dense", "copy.deepcopy.pop", "tensorflow.variable_scope", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.LSTMStateTuple", "tensorflow.nn.dynamic_rnn", "copy.deepcopy.pop", "tensorflow.contrib.layers.xavier_initializer", "len", "len", "tensorflow.variable_scope", "tensorflow.concat", "copy.deepcopy.pop", "len", "len", "len", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.variable_scope", "ma_policy.layers.entity_concat", "copy.deepcopy.pop", "len", "len", "len", "ma_policy.util.shape_list", "ma_policy.util.shape_list", "ma_policy.util.shape_list", "len", "ma_policy.util.shape_list", "ma_policy.layers.concat_entity_masks", "ma_policy.util.shape_list", "slice", "tensorflow.variable_scope", "copy.deepcopy.pop", "ma_policy.layers.residual_sa_block", "copy.deepcopy.get", "copy.deepcopy.pop", "ma_policy.util.shape_list", "ma_policy.util.shape_list", "ma_policy.util.shape_list", "len", "ma_policy.util.shape_list", "range", "len", "tensorflow.variable_scope", "copy.deepcopy.pop", "ma_policy.util.shape_list", "len", "len", "len", "len", "tensorflow.variable_scope", "ma_policy.layers.circ_conv1d", "copy.deepcopy.pop", "ma_policy.util.shape_list", "copy.deepcopy.pop", "ma_policy.layers.entity_avg_pooling_masked", "tensorflow.reduce_mean", "tensorflow.variable_scope", "ma_policy.util.shape_list", "tensorflow.reshape", "copy.deepcopy.pop", "NotImplementedError", "copy.deepcopy.pop", "mask.get_shape", "inp[].get_shape", "mask.get_shape", "inp[].get_shape", "ma_policy.layers.entity_max_pooling_masked", "tensorflow.reduce_max", "tensorflow.variable_scope", "tensorflow.contrib.layers.layer_norm", "numpy.prod"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.layers.entity_concat", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.layers.concat_entity_masks", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.layers.residual_sa_block", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.layers.circ_conv1d", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.layers.entity_avg_pooling_masked", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.layers.entity_max_pooling_masked"], ["def", "construct_tf_graph", "(", "all_inputs", ",", "spec", ",", "act", ",", "scope", "=", "''", ",", "reuse", "=", "False", ",", ")", ":", "\n", "    ", "'''\n        Construct tensorflow graph from spec.\n        Args:\n            main_inp (tf) -- input activations\n            other_inp (dict of tf) -- other input activations such as state\n            spec (list of dicts) -- network specification. see Usage below\n            scope (string) -- tf variable scope\n            reuse (bool) -- tensorflow reuse flag\n        Usage:\n            Each layer spec has optional arguments: nodes_in and nodes_in. If these arguments\n                are omitted, then the default in and out nodes will be 'main'. For layers such as\n                concatentation, these arguments must be specified.\n            Dense layer (MLP) --\n            {\n                'layer_type': 'dense'\n                'units': int (number of neurons)\n                'activation': 'relu', 'tanh', or '' for no activation\n            }\n            LSTM layer --\n            {\n                'layer_type': 'lstm'\n                'units': int (hidden state size)\n            }\n            Concat layer --\n            Two use cases.\n                First: the first input has one less dimension than the second input. In this case,\n                    broadcast the first input along the second to last dimension and concatenated\n                    along last dimension\n                Second: Both inputs have the same dimension, and will be concatenated along last\n                    dimension\n            {\n                'layer_type': 'concat'\n                'nodes_in': ['node_one', 'node_two']\n                'nodes_out': ['node_out']\n            }\n            Entity Concat Layer --\n            Concatenate along entity dimension (second to last)\n            {\n                'layer_type': 'entity_concat'\n                'nodes_in': ['node_one', 'node_two']\n                'nodes_out': ['node_out']\n            }\n            Entity Self Attention --\n            Self attention over entity dimension (second to last)\n            See policy.utils:residual_sa_block for args\n            {\n                'layer_type': 'residual_sa_block'\n                'nodes_in': ['node_one']\n                'nodes_out': ['node_out']\n                ...\n            }\n            Entity Pooling --\n            Pooling along entity dimension (second to last)\n            {\n                'layer_type': 'entity_pooling'\n                'nodes_in': ['node_one', 'node_two']\n                'nodes_out': ['node_out']\n                'type': (optional string, default 'avg_pooling') type of pooling\n                         Current options are 'avg_pooling' and 'max_pooling'\n            }\n            Circular 1d convolution layer (second to last dimension) --\n            {\n                'layer_type': 'circ_conv1d',\n                'filters': number of filters\n                'kernel_size': kernel size\n                'activation': 'relu', 'tanh', or '' for no activation\n            }\n            Flatten outer dimension --\n            Flatten all dimensions higher or equal to 3 (necessary after conv layer)\n            {\n                'layer_type': 'flatten_outer',\n            }\n            Layernorm --\n\n    '''", "\n", "# Make a new dict to not overwrite input", "\n", "inp", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "all_inputs", ".", "items", "(", ")", "}", "\n", "inp", "[", "'main'", "]", "=", "inp", "[", "'observation_self'", "]", "\n", "\n", "valid_activations", "=", "{", "'relu'", ":", "tf", ".", "nn", ".", "relu", ",", "'tanh'", ":", "tf", ".", "tanh", ",", "''", ":", "None", "}", "\n", "state_variables", "=", "OrderedDict", "(", ")", "\n", "logger", ".", "info", "(", "f\"Spec:\\n{spec}\"", ")", "\n", "entity_locations", "=", "{", "}", "\n", "reset_ops", "=", "[", "]", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "for", "i", ",", "layer", "in", "enumerate", "(", "spec", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "layer", "=", "deepcopy", "(", "layer", ")", "\n", "layer_type", "=", "layer", ".", "pop", "(", "'layer_type'", ")", "\n", "extra_layer_scope", "=", "layer", ".", "pop", "(", "'scope'", ",", "''", ")", "\n", "nodes_in", "=", "layer", ".", "pop", "(", "'nodes_in'", ",", "[", "'main'", "]", ")", "\n", "nodes_out", "=", "layer", ".", "pop", "(", "'nodes_out'", ",", "[", "'main'", "]", ")", "\n", "with", "tf", ".", "variable_scope", "(", "extra_layer_scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "                    ", "if", "layer_type", "==", "'dense'", ":", "\n", "                        ", "assert", "len", "(", "nodes_in", ")", "==", "len", "(", "nodes_out", ")", ",", "f\"Dense layer must have same number of nodes in as nodes out. \\\n                            Nodes in: {nodes_in}, Nodes out {nodes_out}\"", "\n", "\n", "layer", "[", "'activation'", "]", "=", "valid_activations", "[", "layer", "[", "'activation'", "]", "]", "\n", "layer_name", "=", "layer", ".", "pop", "(", "'layer_name'", ",", "f'dense{i}'", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "nodes_in", ")", ")", ":", "\n", "                            ", "inp", "[", "nodes_out", "[", "j", "]", "]", "=", "tf", ".", "layers", ".", "dense", "(", "inp", "[", "nodes_in", "[", "j", "]", "]", ",", "\n", "name", "=", "f'{layer_name}-{j}'", ",", "\n", "kernel_initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", ",", "\n", "reuse", "=", "reuse", ",", "\n", "**", "layer", ")", "\n", "", "", "elif", "layer_type", "==", "'lstm'", ":", "\n", "                        ", "layer_name", "=", "layer", ".", "pop", "(", "'layer_name'", ",", "f'lstm{i}'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "layer_name", ",", "reuse", "=", "reuse", ")", ":", "\n", "                            ", "assert", "len", "(", "nodes_in", ")", "==", "len", "(", "nodes_out", ")", "==", "1", "\n", "cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "BasicLSTMCell", "(", "layer", "[", "'units'", "]", ")", "\n", "initial_state", "=", "tf", ".", "contrib", ".", "rnn", ".", "LSTMStateTuple", "(", "inp", "[", "scope", "+", "f'_lstm{i}_state_c'", "]", ",", "\n", "inp", "[", "scope", "+", "f'_lstm{i}_state_h'", "]", ")", "\n", "inp", "[", "nodes_out", "[", "0", "]", "]", ",", "state_out", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "cell", ",", "\n", "inp", "[", "nodes_in", "[", "0", "]", "]", ",", "\n", "initial_state", "=", "initial_state", ")", "\n", "state_variables", "[", "scope", "+", "f'_lstm{i}_state_c'", "]", "=", "state_out", ".", "c", "\n", "state_variables", "[", "scope", "+", "f'_lstm{i}_state_h'", "]", "=", "state_out", ".", "h", "\n", "", "", "elif", "layer_type", "==", "'concat'", ":", "\n", "                        ", "layer_name", "=", "layer", ".", "pop", "(", "'layer_name'", ",", "f'concat{i}'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "layer_name", ")", ":", "\n", "                            ", "assert", "len", "(", "nodes_out", ")", "==", "1", ",", "f\"Concat op must only have one node out. Nodes Out: {nodes_out}\"", "\n", "assert", "len", "(", "nodes_in", ")", "==", "2", ",", "f\"Concat op must have two nodes in. Nodes In: {nodes_in}\"", "\n", "assert", "(", "len", "(", "shape_list", "(", "inp", "[", "nodes_in", "[", "0", "]", "]", ")", ")", "==", "len", "(", "shape_list", "(", "inp", "[", "nodes_in", "[", "1", "]", "]", ")", ")", "or", "\n", "len", "(", "shape_list", "(", "inp", "[", "nodes_in", "[", "0", "]", "]", ")", ")", "==", "len", "(", "shape_list", "(", "inp", "[", "nodes_in", "[", "1", "]", "]", ")", ")", "-", "1", ")", ",", "f\"shapes were {nodes_in[0]}:{shape_list(inp[nodes_in[0]])}, {nodes_in[1]}:{shape_list(inp[nodes_in[1]])}\"", "\n", "\n", "inp0", ",", "inp1", "=", "inp", "[", "nodes_in", "[", "0", "]", "]", ",", "inp", "[", "nodes_in", "[", "1", "]", "]", "\n", "# tile inp0 along second to last dimension to match inp1", "\n", "if", "len", "(", "shape_list", "(", "inp", "[", "nodes_in", "[", "0", "]", "]", ")", ")", "==", "len", "(", "shape_list", "(", "inp1", ")", ")", "-", "1", ":", "\n", "                                ", "inp0", "=", "tf", ".", "expand_dims", "(", "inp", "[", "nodes_in", "[", "0", "]", "]", ",", "-", "2", ")", "\n", "tile_dims", "=", "[", "1", "for", "i", "in", "range", "(", "len", "(", "shape_list", "(", "inp0", ")", ")", ")", "]", "\n", "tile_dims", "[", "-", "2", "]", "=", "shape_list", "(", "inp1", ")", "[", "-", "2", "]", "\n", "inp0", "=", "tf", ".", "tile", "(", "inp0", ",", "tile_dims", ")", "\n", "", "inp", "[", "nodes_out", "[", "0", "]", "]", "=", "tf", ".", "concat", "(", "[", "inp0", ",", "inp1", "]", ",", "-", "1", ")", "\n", "", "", "elif", "layer_type", "==", "'entity_concat'", ":", "\n", "                        ", "layer_name", "=", "layer", ".", "pop", "(", "'layer_name'", ",", "f'entity-concat{i}'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "layer_name", ")", ":", "\n", "                            ", "ec_inps", "=", "[", "inp", "[", "node_in", "]", "for", "node_in", "in", "nodes_in", "]", "\n", "inp", "[", "nodes_out", "[", "0", "]", "]", "=", "entity_concat", "(", "ec_inps", ")", "\n", "if", "\"masks_in\"", "in", "layer", ":", "\n", "                                ", "masks_in", "=", "[", "inp", "[", "_m", "]", "if", "_m", "is", "not", "None", "else", "None", "for", "_m", "in", "layer", "[", "\"masks_in\"", "]", "]", "\n", "inp", "[", "layer", "[", "\"mask_out\"", "]", "]", "=", "concat_entity_masks", "(", "ec_inps", ",", "masks_in", ")", "\n", "# Store where the entities are. We'll store with key nodes_out[0]", "\n", "", "_ent_locs", "=", "{", "}", "\n", "loc", "=", "0", "\n", "for", "node_in", "in", "nodes_in", ":", "\n", "                                ", "shape_in", "=", "shape_list", "(", "inp", "[", "node_in", "]", ")", "\n", "n_ent", "=", "shape_in", "[", "2", "]", "if", "len", "(", "shape_in", ")", "==", "4", "else", "1", "\n", "_ent_locs", "[", "node_in", "]", "=", "slice", "(", "loc", ",", "loc", "+", "n_ent", ")", "\n", "loc", "+=", "n_ent", "\n", "", "entity_locations", "[", "nodes_out", "[", "0", "]", "]", "=", "_ent_locs", "\n", "", "", "elif", "layer_type", "==", "'residual_sa_block'", ":", "\n", "                        ", "layer_name", "=", "layer", ".", "pop", "(", "'layer_name'", ",", "f'self-attention{i}'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "layer_name", ")", ":", "\n", "                            ", "assert", "len", "(", "nodes_in", ")", "==", "1", ",", "\"self attention should only have one input\"", "\n", "sa_inp", "=", "inp", "[", "nodes_in", "[", "0", "]", "]", "\n", "\n", "mask", "=", "inp", "[", "layer", ".", "pop", "(", "'mask'", ")", "]", "if", "'mask'", "in", "layer", "else", "None", "\n", "internal_layer_name", "=", "layer", ".", "pop", "(", "'internal_layer_name'", ",", "f'residual_sa_block{i}'", ")", "\n", "inp", "[", "nodes_out", "[", "0", "]", "]", "=", "residual_sa_block", "(", "sa_inp", ",", "mask", ",", "**", "layer", ",", "\n", "scope", "=", "internal_layer_name", ",", "\n", "reuse", "=", "reuse", ")", "\n", "", "", "elif", "layer_type", "==", "'entity_pooling'", ":", "\n", "                        ", "pool_type", "=", "layer", ".", "get", "(", "'type'", ",", "'avg_pooling'", ")", "\n", "assert", "pool_type", "in", "[", "'avg_pooling'", ",", "'max_pooling'", "]", ",", "f\"Pooling type {pool_type} \\\n                            not available. Pooling type must be either 'avg_pooling' or 'max_pooling'.\"", "\n", "layer_name", "=", "layer", ".", "pop", "(", "'layer_name'", ",", "f'entity-{pool_type}-pooling{i}'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "layer_name", ")", ":", "\n", "                            ", "if", "'mask'", "in", "layer", ":", "\n", "                                ", "mask", "=", "inp", "[", "layer", ".", "pop", "(", "'mask'", ")", "]", "\n", "assert", "mask", ".", "get_shape", "(", ")", "[", "-", "1", "]", "==", "inp", "[", "nodes_in", "[", "0", "]", "]", ".", "get_shape", "(", ")", "[", "-", "2", "]", ",", "f\"Outer dim of mask must match second to last dim of input. \\\n                                     Mask shape: {mask.get_shape()}. Input shape: {inp[nodes_in[0]].get_shape()}\"", "\n", "if", "pool_type", "==", "'avg_pooling'", ":", "\n", "                                    ", "inp", "[", "nodes_out", "[", "0", "]", "]", "=", "entity_avg_pooling_masked", "(", "inp", "[", "nodes_in", "[", "0", "]", "]", ",", "mask", ")", "\n", "", "elif", "pool_type", "==", "'max_pooling'", ":", "\n", "                                    ", "inp", "[", "nodes_out", "[", "0", "]", "]", "=", "entity_max_pooling_masked", "(", "inp", "[", "nodes_in", "[", "0", "]", "]", ",", "mask", ")", "\n", "", "", "else", ":", "\n", "                                ", "if", "pool_type", "==", "'avg_pooling'", ":", "\n", "                                    ", "inp", "[", "nodes_out", "[", "0", "]", "]", "=", "tf", ".", "reduce_mean", "(", "inp", "[", "nodes_in", "[", "0", "]", "]", ",", "-", "2", ")", "\n", "", "elif", "pool_type", "==", "'max_pooling'", ":", "\n", "                                    ", "inp", "[", "nodes_out", "[", "0", "]", "]", "=", "tf", ".", "reduce_max", "(", "inp", "[", "nodes_in", "[", "0", "]", "]", ",", "-", "2", ")", "\n", "", "", "", "", "elif", "layer_type", "==", "'circ_conv1d'", ":", "\n", "                        ", "assert", "len", "(", "nodes_in", ")", "==", "len", "(", "nodes_out", ")", "==", "1", ",", "f\"Circular convolution layer must have one nodes and one nodes out. \\\n                            Nodes in: {nodes_in}, Nodes out {nodes_out}\"", "\n", "layer_name", "=", "layer", ".", "pop", "(", "'layer_name'", ",", "f'circ_conv1d{i}'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "layer_name", ",", "reuse", "=", "reuse", ")", ":", "\n", "                            ", "inp", "[", "nodes_out", "[", "0", "]", "]", "=", "circ_conv1d", "(", "inp", "[", "nodes_in", "[", "0", "]", "]", ",", "**", "layer", ")", "\n", "", "", "elif", "layer_type", "==", "'flatten_outer'", ":", "\n", "                        ", "layer_name", "=", "layer", ".", "pop", "(", "'layer_name'", ",", "f'flatten_outer{i}'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "layer_name", ",", "reuse", "=", "reuse", ")", ":", "\n", "# flatten all dimensions higher or equal to 3", "\n", "                            ", "inp0", "=", "inp", "[", "nodes_in", "[", "0", "]", "]", "\n", "inp0_shape", "=", "shape_list", "(", "inp0", ")", "\n", "inp", "[", "nodes_out", "[", "0", "]", "]", "=", "tf", ".", "reshape", "(", "inp0", ",", "shape", "=", "inp0_shape", "[", "0", ":", "2", "]", "+", "[", "np", ".", "prod", "(", "inp0_shape", "[", "2", ":", "]", ")", "]", ")", "\n", "", "", "elif", "layer_type", "==", "\"layernorm\"", ":", "\n", "                        ", "layer_name", "=", "layer", ".", "pop", "(", "'layer_name'", ",", "f'layernorm{i}'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "layer_name", ",", "reuse", "=", "reuse", ")", ":", "\n", "                            ", "inp", "[", "nodes_out", "[", "0", "]", "]", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "inp", "[", "nodes_in", "[", "0", "]", "]", ",", "begin_norm_axis", "=", "2", ")", "\n", "", "", "else", ":", "\n", "                        ", "raise", "NotImplementedError", "(", "f\"Layer type -- {layer_type} -- not yet implemented\"", ")", "\n", "", "", "", "except", "Exception", ":", "\n", "                ", "traceback", ".", "print_exc", "(", "file", "=", "sys", ".", "stdout", ")", "\n", "print", "(", "f\"Error in {layer_type} layer: \\n{layer}\\nNodes in: {nodes_in}, Nodes out: {nodes_out}\"", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "", "", "", "return", "inp", ",", "state_variables", ",", "reset_ops", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.graph_construct.construct_schemas_zero_state": [[227, 246], ["collections.OrderedDict", "collections.OrderedDict", "enumerate", "copy.deepcopy", "copy.deepcopy.pop", "ma_policy.variable_schema.VariableSchema", "ma_policy.variable_schema.VariableSchema", "numpy.expand_dims", "numpy.expand_dims", "tensorflow.contrib.rnn.BasicLSTMCell", "numpy.zeros", "numpy.zeros"], "function", ["None"], ["", "def", "construct_schemas_zero_state", "(", "spec", ",", "ob_space", ",", "scope", "=", "''", ")", ":", "\n", "    ", "'''\n        Takes a network spec (as specified in construct_tf_graph docstring) and returns\n            input schemas and zero states.\n    '''", "\n", "schemas", "=", "OrderedDict", "(", ")", "\n", "zero_states", "=", "OrderedDict", "(", ")", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "spec", ")", ":", "\n", "        ", "layer", "=", "deepcopy", "(", "layer", ")", "\n", "layer_type", "=", "layer", ".", "pop", "(", "'layer_type'", ")", "\n", "\n", "if", "layer_type", "==", "'lstm'", ":", "\n", "            ", "size", "=", "tf", ".", "contrib", ".", "rnn", ".", "BasicLSTMCell", "(", "layer", "[", "'units'", "]", ")", ".", "state_size", "\n", "schemas", "[", "scope", "+", "f'_lstm{i}_state_c'", "]", "=", "VariableSchema", "(", "shape", "=", "[", "BATCH", ",", "size", ".", "c", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "schemas", "[", "scope", "+", "f'_lstm{i}_state_h'", "]", "=", "VariableSchema", "(", "shape", "=", "[", "BATCH", ",", "size", ".", "h", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "zero_states", "[", "scope", "+", "f'_lstm{i}_state_c'", "]", "=", "np", ".", "expand_dims", "(", "np", ".", "zeros", "(", "size", ".", "c", ",", "dtype", "=", "np", ".", "float32", ")", ",", "0", ")", "\n", "zero_states", "[", "scope", "+", "f'_lstm{i}_state_h'", "]", "=", "np", ".", "expand_dims", "(", "np", ".", "zeros", "(", "size", ".", "h", ",", "dtype", "=", "np", ".", "float32", ")", ",", "0", ")", "\n", "\n", "", "", "return", "schemas", ",", "zero_states", "\n", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.load_policy.shape_list": [[12, 19], ["x.get_shape().as_list", "tensorflow.shape", "x.get_shape", "range", "len"], "function", ["None"], ["def", "shape_list", "(", "x", ")", ":", "\n", "    ", "'''\n        deal with dynamic shape in tensorflow cleanly\n    '''", "\n", "ps", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "ts", "=", "tf", ".", "shape", "(", "x", ")", "\n", "return", "[", "ts", "[", "i", "]", "if", "ps", "[", "i", "]", "is", "None", "else", "ps", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "ps", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.load_policy.replace_base_scope": [[21, 25], ["var_name.split", "os.path.normpath"], "function", ["None"], ["", "def", "replace_base_scope", "(", "var_name", ",", "new_base_scope", ")", ":", "\n", "    ", "split", "=", "var_name", ".", "split", "(", "'/'", ")", "\n", "split", "[", "0", "]", "=", "new_base_scope", "\n", "return", "os", ".", "path", ".", "normpath", "(", "'/'", ".", "join", "(", "split", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.load_policy.load_variables": [[27, 45], ["policy.get_variables", "tensorflow.get_default_session().run", "os.path.normpath", "load_policy.replace_base_scope", "os.path.normpath", "weights.items", "weights.items", "logging.warning", "tensorflow.get_default_session().run", "tensorflow.get_default_session", "numpy.all", "assign_ops.append", "tensorflow.get_default_session", "var.assign", "traceback.print_exc", "print", "sys.exit", "numpy.array", "numpy.array", "load_policy.shape_list"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.get_variables", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.policy_viewer.PolicyViewer.run", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.load_policy.replace_base_scope", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.policy_viewer.PolicyViewer.run", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list"], ["", "def", "load_variables", "(", "policy", ",", "weights", ")", ":", "\n", "    ", "weights", "=", "{", "os", ".", "path", ".", "normpath", "(", "key", ")", ":", "value", "for", "key", ",", "value", "in", "weights", ".", "items", "(", ")", "}", "\n", "weights", "=", "{", "replace_base_scope", "(", "key", ",", "policy", ".", "scope", ")", ":", "value", "for", "key", ",", "value", "in", "weights", ".", "items", "(", ")", "}", "\n", "assign_ops", "=", "[", "]", "\n", "for", "var", "in", "policy", ".", "get_variables", "(", ")", ":", "\n", "        ", "var_name", "=", "os", ".", "path", ".", "normpath", "(", "var", ".", "name", ")", "\n", "if", "var_name", "not", "in", "weights", ":", "\n", "            ", "logging", ".", "warning", "(", "f\"{var_name} was not found in weights dict. This will be reinitialized.\"", ")", "\n", "tf", ".", "get_default_session", "(", ")", ".", "run", "(", "var", ".", "initializer", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "assert", "np", ".", "all", "(", "np", ".", "array", "(", "shape_list", "(", "var", ")", ")", "==", "np", ".", "array", "(", "weights", "[", "var_name", "]", ".", "shape", ")", ")", "\n", "assign_ops", ".", "append", "(", "var", ".", "assign", "(", "weights", "[", "var_name", "]", ")", ")", "\n", "", "except", "Exception", ":", "\n", "                ", "traceback", ".", "print_exc", "(", "file", "=", "sys", ".", "stdout", ")", "\n", "print", "(", "f\"Error assigning weights of shape {weights[var_name].shape} to {var}\"", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "", "", "tf", ".", "get_default_session", "(", ")", ".", "run", "(", "assign_ops", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.load_policy.load_policy": [[47, 78], ["dict", "cloudpickle.loads", "ma_policy.ma_policy.MAPolicy", "load_policy.load_variables", "tensorflow.get_default_session", "tensorflow.ConfigProto", "tensorflow.Session", "tf.Session.__enter__", "numpy.load"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.load_policy.load_variables"], ["", "def", "load_policy", "(", "path", ",", "env", "=", "None", ",", "scope", "=", "'policy'", ")", ":", "\n", "    ", "'''\n        Load a policy.\n        Args:\n            path (string): policy path\n            env (Gym.Env): This will update the observation space of the\n                policy that is returned\n            scope (string): The base scope for the policy variables\n    '''", "\n", "# TODO this will probably need to be changed when trying to run policy on GPU", "\n", "if", "tf", ".", "get_default_session", "(", ")", "is", "None", ":", "\n", "        ", "tf_config", "=", "tf", ".", "ConfigProto", "(", "\n", "inter_op_parallelism_threads", "=", "1", ",", "\n", "intra_op_parallelism_threads", "=", "1", ")", "\n", "sess", "=", "tf", ".", "Session", "(", "config", "=", "tf_config", ")", "\n", "sess", ".", "__enter__", "(", ")", "\n", "\n", "", "policy_dict", "=", "dict", "(", "np", ".", "load", "(", "path", ")", ")", "\n", "policy_fn_and_args_raw", "=", "pickle", ".", "loads", "(", "policy_dict", "[", "'policy_fn_and_args'", "]", ")", "\n", "policy_args", "=", "policy_fn_and_args_raw", "[", "'args'", "]", "\n", "policy_args", "[", "'scope'", "]", "=", "scope", "\n", "\n", "if", "env", "is", "not", "None", ":", "\n", "        ", "policy_args", "[", "'ob_space'", "]", "=", "env", ".", "observation_space", "\n", "policy_args", "[", "'ac_space'", "]", "=", "env", ".", "action_space", "\n", "\n", "", "policy", "=", "MAPolicy", "(", "**", "policy_args", ")", "\n", "del", "policy_dict", "[", "'policy_fn_and_args'", "]", "\n", "\n", "load_variables", "(", "policy", ",", "policy_dict", ")", "\n", "return", "policy", "\n", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.layers.entity_avg_pooling_masked": [[10, 21], ["tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "function", ["None"], ["def", "entity_avg_pooling_masked", "(", "x", ",", "mask", ")", ":", "\n", "    ", "'''\n        Masks and pools x along the second to last dimension. Arguments have dimensions:\n            x:    batch x time x n_entities x n_features\n            mask: batch x time x n_entities\n    '''", "\n", "mask", "=", "tf", ".", "expand_dims", "(", "mask", ",", "-", "1", ")", "\n", "masked", "=", "x", "*", "mask", "\n", "summed", "=", "tf", ".", "reduce_sum", "(", "masked", ",", "-", "2", ")", "\n", "denom", "=", "tf", ".", "reduce_sum", "(", "mask", ",", "-", "2", ")", "+", "1e-5", "\n", "return", "summed", "/", "denom", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.layers.entity_max_pooling_masked": [[23, 34], ["tensorflow.expand_dims", "tensorflow.sign", "tensorflow.reduce_max", "tensorflow.reduce_sum"], "function", ["None"], ["", "def", "entity_max_pooling_masked", "(", "x", ",", "mask", ")", ":", "\n", "    ", "'''\n        Masks and pools x along the second to last dimension. Arguments have dimensions:\n            x:    batch x time x n_entities x n_features\n            mask: batch x time x n_entities\n    '''", "\n", "mask", "=", "tf", ".", "expand_dims", "(", "mask", ",", "-", "1", ")", "\n", "has_unmasked_entities", "=", "tf", ".", "sign", "(", "tf", ".", "reduce_sum", "(", "mask", ",", "axis", "=", "-", "2", ",", "keepdims", "=", "True", ")", ")", "\n", "offset", "=", "(", "mask", "-", "1", ")", "*", "1e9", "\n", "masked", "=", "(", "x", "+", "offset", ")", "*", "has_unmasked_entities", "\n", "return", "tf", ".", "reduce_max", "(", "masked", ",", "-", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.layers.entity_concat": [[40, 57], ["tensorflow.variable_scope", "numpy.all", "tensorflow.concat", "ma_policy.util.shape_list", "ma_policy.util.shape_list", "tensorflow.expand_dims", "zip", "len"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list"], ["", "def", "entity_concat", "(", "inps", ")", ":", "\n", "    ", "'''\n        Concat 4D tensors along the third dimension. If a 3D tensor is in the list\n            then treat it as a single entity and expand the third dimension\n        Args:\n            inps (list of tensors): tensors to concatenate\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "'concat_entities'", ")", ":", "\n", "        ", "shapes", "=", "[", "shape_list", "(", "_x", ")", "for", "_x", "in", "inps", "]", "\n", "# For inputs that don't have entity dimension add one.", "\n", "inps", "=", "[", "_x", "if", "len", "(", "_shape", ")", "==", "4", "else", "tf", ".", "expand_dims", "(", "_x", ",", "2", ")", "for", "_x", ",", "_shape", "in", "zip", "(", "inps", ",", "shapes", ")", "]", "\n", "shapes", "=", "[", "shape_list", "(", "_x", ")", "for", "_x", "in", "inps", "]", "\n", "assert", "np", ".", "all", "(", "[", "_shape", "[", "-", "1", "]", "==", "shapes", "[", "0", "]", "[", "-", "1", "]", "for", "_shape", "in", "shapes", "]", ")", ",", "f\"Some entities don't have the same outer or inner dimensions {shapes}\"", "\n", "# Concatenate along entity dimension", "\n", "out", "=", "tf", ".", "concat", "(", "inps", ",", "-", "2", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.layers.concat_entity_masks": [[59, 82], ["len", "len", "tensorflow.variable_scope", "zip", "tensorflow.concat", "ma_policy.util.shape_list", "ma_policy.util.shape_list", "new_masks.append", "len", "new_masks.append", "tensorflow.ones", "len", "new_masks.append", "tensorflow.ones"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list"], ["", "def", "concat_entity_masks", "(", "inps", ",", "masks", ")", ":", "\n", "    ", "'''\n        Concats masks together. If mask is None, then it creates\n            a tensor of 1's with shape (BS, T, NE).\n        Args:\n            inps (list of tensors): tensors that masks apply to\n            masks (list of tensors): corresponding masks\n    '''", "\n", "assert", "len", "(", "inps", ")", "==", "len", "(", "masks", ")", ",", "\"There should be the same number of inputs as masks\"", "\n", "with", "tf", ".", "variable_scope", "(", "'concat_masks'", ")", ":", "\n", "        ", "shapes", "=", "[", "shape_list", "(", "_x", ")", "for", "_x", "in", "inps", "]", "\n", "new_masks", "=", "[", "]", "\n", "for", "inp", ",", "mask", "in", "zip", "(", "inps", ",", "masks", ")", ":", "\n", "            ", "if", "mask", "is", "None", ":", "\n", "                ", "inp_shape", "=", "shape_list", "(", "inp", ")", "\n", "if", "len", "(", "inp_shape", ")", "==", "4", ":", "# this is an entity tensor", "\n", "                    ", "new_masks", ".", "append", "(", "tf", ".", "ones", "(", "inp_shape", "[", ":", "3", "]", ")", ")", "\n", "", "elif", "len", "(", "inp_shape", ")", "==", "3", ":", "# this is a pooled or main tensor. Set NE (outer dimension) to 1", "\n", "                    ", "new_masks", ".", "append", "(", "tf", ".", "ones", "(", "inp_shape", "[", ":", "2", "]", "+", "[", "1", "]", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "new_masks", ".", "append", "(", "mask", ")", "\n", "", "", "new_mask", "=", "tf", ".", "concat", "(", "new_masks", ",", "-", "1", ")", "\n", "", "return", "new_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.layers.residual_sa_block": [[89, 140], ["tensorflow.variable_scope", "layers..", "numpy.sqrt", "tensorflow.layers.dense", "numpy.sqrt", "tensorflow.layers.dense", "numpy.sqrt", "tensorflow.layers.dense", "tensorflow.random_normal_initializer", "tensorflow.variable_scope", "tensorflow.contrib.layers.layer_norm", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "def", "residual_sa_block", "(", "inp", ",", "mask", ",", "heads", ",", "n_embd", ",", "\n", "layer_norm", "=", "False", ",", "post_sa_layer_norm", "=", "False", ",", "\n", "n_mlp", "=", "1", ",", "qk_w", "=", "0.125", ",", "v_w", "=", "0.125", ",", "post_w", "=", "0.125", ",", "\n", "mlp_w1", "=", "0.125", ",", "mlp_w2", "=", "0.125", ",", "\n", "scope", "=", "\"residual_sa_block\"", ",", "reuse", "=", "False", ")", ":", "\n", "    ", "'''\n        Residual self attention block for entities.\n        Notation:\n            T  - Time\n            NE - Number entities\n        Args:\n            inp (tf): (BS, T, NE, f)\n            mask (tf): (BS, T, NE)\n            heads (int) -- number of attention heads\n            n_embd (int) -- dimension of queries, keys, and values will be n_embd / heads\n            layer_norm (bool) -- normalize embedding prior to computing qkv\n            n_mlp (int) -- number of mlp layers. If there are more than 1 mlp layers, we'll add a residual\n                connection from after the first mlp to after the last mlp.\n            qk_w, v_w, post_w, mlp_w1, mlp_w2 (float) -- scale for gaussian init for keys/queries, values, mlp\n                post self attention, second mlp, and third mlp, respectively. Std will be sqrt(scale/n_embd)\n            scope (string) -- tf scope\n            reuse (bool) -- tf reuse\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "a", "=", "self_attention", "(", "inp", ",", "mask", ",", "heads", ",", "n_embd", ",", "layer_norm", "=", "layer_norm", ",", "qk_w", "=", "qk_w", ",", "v_w", "=", "v_w", ",", "\n", "scope", "=", "'self_attention'", ",", "reuse", "=", "reuse", ")", "\n", "post_scale", "=", "np", ".", "sqrt", "(", "post_w", "/", "n_embd", ")", "\n", "post_a_mlp", "=", "tf", ".", "layers", ".", "dense", "(", "a", ",", "\n", "n_embd", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "post_scale", ")", ",", "\n", "name", "=", "\"mlp1\"", ")", "\n", "x", "=", "inp", "+", "post_a_mlp", "\n", "if", "post_sa_layer_norm", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'post_a_layernorm'", ")", ":", "\n", "                ", "x", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "x", ",", "begin_norm_axis", "=", "3", ")", "\n", "", "", "if", "n_mlp", ">", "1", ":", "\n", "            ", "mlp", "=", "x", "\n", "mlp2_scale", "=", "np", ".", "sqrt", "(", "mlp_w1", "/", "n_embd", ")", "\n", "mlp", "=", "tf", ".", "layers", ".", "dense", "(", "mlp", ",", "\n", "n_embd", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "mlp2_scale", ")", ",", "\n", "name", "=", "\"mlp2\"", ")", "\n", "", "if", "n_mlp", ">", "2", ":", "\n", "            ", "mlp3_scale", "=", "np", ".", "sqrt", "(", "mlp_w2", "/", "n_embd", ")", "\n", "mlp", "=", "tf", ".", "layers", ".", "dense", "(", "mlp", ",", "\n", "n_embd", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "mlp3_scale", ")", ",", "\n", "name", "=", "\"mlp3\"", ")", "\n", "", "if", "n_mlp", ">", "1", ":", "\n", "            ", "x", "=", "x", "+", "mlp", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.layers.self_attention": [[142, 183], ["tensorflow.variable_scope", "ma_policy.util.shape_list", "layers.qkv_embed", "tensorflow.matmul", "numpy.sqrt", "layers.stable_masked_softmax", "tensorflow.matmul", "tensorflow.variable_scope", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.variable_scope", "numpy.all", "tensorflow.expand_dims", "ma_policy.util.shape_list", "numpy.array", "numpy.array", "ma_policy.util.shape_list", "ma_policy.util.shape_list", "tf.expand_dims.get_shape().as_list", "inp.get_shape().as_list", "tf.expand_dims.get_shape", "inp.get_shape"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.layers.qkv_embed", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.layers.stable_masked_softmax", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list"], ["", "", "def", "self_attention", "(", "inp", ",", "mask", ",", "heads", ",", "n_embd", ",", "layer_norm", "=", "False", ",", "qk_w", "=", "1.0", ",", "v_w", "=", "0.01", ",", "\n", "scope", "=", "''", ",", "reuse", "=", "False", ")", ":", "\n", "    ", "'''\n        Self attention over entities.\n        Notation:\n            T  - Time\n            NE - Number entities\n        Args:\n            inp (tf) -- tensor w/ shape (bs, T, NE, features)\n            mask (tf) -- binary tensor with shape (bs, T, NE). For each batch x time,\n                            nner matrix represents entity i's ability to see entity j\n            heads (int) -- number of attention heads\n            n_embd (int) -- dimension of queries, keys, and values will be n_embd / heads\n            layer_norm (bool) -- normalize embedding prior to computing qkv\n            qk_w, v_w (float) -- scale for gaussian init for keys/queries and values\n                Std will be sqrt(scale/n_embd)\n            scope (string) -- tf scope\n            reuse (bool) -- tf reuse\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "bs", ",", "T", ",", "NE", ",", "features", "=", "shape_list", "(", "inp", ")", "\n", "# Put mask in format correct for logit matrix", "\n", "entity_mask", "=", "None", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'expand_mask'", ")", ":", "\n", "                ", "assert", "np", ".", "all", "(", "np", ".", "array", "(", "mask", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "==", "np", ".", "array", "(", "inp", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", ":", "3", "]", ")", ")", ",", "f\"Mask and input should have the same first 3 dimensions. {shape_list(mask)} -- {shape_list(inp)}\"", "\n", "entity_mask", "=", "mask", "\n", "mask", "=", "tf", ".", "expand_dims", "(", "mask", ",", "-", "2", ")", "# (BS, T, 1, NE)", "\n", "\n", "", "", "query", ",", "key", ",", "value", "=", "qkv_embed", "(", "inp", ",", "heads", ",", "n_embd", ",", "layer_norm", "=", "layer_norm", ",", "qk_w", "=", "qk_w", ",", "v_w", "=", "v_w", ",", "reuse", "=", "reuse", ")", "\n", "logits", "=", "tf", ".", "matmul", "(", "query", ",", "key", ",", "name", "=", "\"matmul_qk_parallel\"", ")", "# (bs, T, heads, NE, NE)", "\n", "logits", "/=", "np", ".", "sqrt", "(", "n_embd", "/", "heads", ")", "\n", "softmax", "=", "stable_masked_softmax", "(", "logits", ",", "mask", ")", "\n", "att_sum", "=", "tf", ".", "matmul", "(", "softmax", ",", "value", ",", "name", "=", "\"matmul_softmax_value\"", ")", "# (bs, T, heads, NE, features)", "\n", "with", "tf", ".", "variable_scope", "(", "'flatten_heads'", ")", ":", "\n", "            ", "out", "=", "tf", ".", "transpose", "(", "att_sum", ",", "(", "0", ",", "1", ",", "3", ",", "2", ",", "4", ")", ")", "# (bs, T, n_output_entities, heads, features)", "\n", "n_output_entities", "=", "shape_list", "(", "out", ")", "[", "2", "]", "\n", "out", "=", "tf", ".", "reshape", "(", "out", ",", "(", "bs", ",", "T", ",", "n_output_entities", ",", "n_embd", ")", ")", "# (bs, T, n_output_entities, n_embd)", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.layers.stable_masked_softmax": [[185, 208], ["tensorflow.variable_scope", "tensorflow.reduce_max", "tensorflow.exp", "tensorflow.expand_dims", "tensorflow.reduce_sum"], "function", ["None"], ["", "", "def", "stable_masked_softmax", "(", "logits", ",", "mask", ")", ":", "\n", "    ", "'''\n        Args:\n            logits (tf): tensor with shape (bs, T, heads, NE, NE)\n            mask (tf): tensor with shape(bs, T, 1, NE)\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "'stable_softmax'", ")", ":", "\n", "#  Subtract a big number from the masked logits so they don't interfere with computing the max value", "\n", "        ", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "tf", ".", "expand_dims", "(", "mask", ",", "2", ")", "\n", "logits", "-=", "(", "1.0", "-", "mask", ")", "*", "1e10", "\n", "\n", "#  Subtract the max logit from everything so we don't overflow", "\n", "", "logits", "-=", "tf", ".", "reduce_max", "(", "logits", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "unnormalized_p", "=", "tf", ".", "exp", "(", "logits", ")", "\n", "\n", "#  Mask the unnormalized probibilities and then normalize and remask", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "unnormalized_p", "*=", "mask", "\n", "", "normalized_p", "=", "unnormalized_p", "/", "(", "tf", ".", "reduce_sum", "(", "unnormalized_p", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "+", "1e-10", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "normalized_p", "*=", "mask", "\n", "", "", "return", "normalized_p", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.layers.qkv_embed": [[210, 257], ["tensorflow.variable_scope", "ma_policy.util.shape_list", "numpy.sqrt", "tensorflow.layers.dense", "tensorflow.reshape", "numpy.sqrt", "tensorflow.layers.dense", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.squeeze", "tensorflow.variable_scope", "tensorflow.contrib.layers.layer_norm", "tensorflow.random_normal_initializer", "tensorflow.split", "tensorflow.random_normal_initializer"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list"], ["", "def", "qkv_embed", "(", "inp", ",", "heads", ",", "n_embd", ",", "layer_norm", "=", "False", ",", "qk_w", "=", "1.0", ",", "v_w", "=", "0.01", ",", "reuse", "=", "False", ")", ":", "\n", "    ", "'''\n        Compute queries, keys, and values\n        Args:\n            inp (tf) -- tensor w/ shape (bs, T, NE, features)\n            heads (int) -- number of attention heads\n            n_embd (int) -- dimension of queries, keys, and values will be n_embd / heads\n            layer_norm (bool) -- normalize embedding prior to computing qkv\n            qk_w (float) -- Initialization scale for keys and queries. Actual scale will be\n                sqrt(qk_w / #input features)\n            v_w (float) -- Initialization scale for values. Actual scale will be sqrt(v_w / #input features)\n            reuse (bool) -- tf reuse\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "'qkv_embed'", ")", ":", "\n", "        ", "bs", ",", "T", ",", "NE", ",", "features", "=", "shape_list", "(", "inp", ")", "\n", "if", "layer_norm", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'pre_sa_layer_norm'", ")", ":", "\n", "                ", "inp", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "inp", ",", "begin_norm_axis", "=", "3", ")", "\n", "\n", "# qk shape (bs x T x NE x h x n_embd/h)", "\n", "", "", "qk_scale", "=", "np", ".", "sqrt", "(", "qk_w", "/", "features", ")", "\n", "qk", "=", "tf", ".", "layers", ".", "dense", "(", "inp", ",", "\n", "n_embd", "*", "2", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "qk_scale", ")", ",", "\n", "reuse", "=", "reuse", ",", "\n", "name", "=", "\"qk_embed\"", ")", "# bs x T x n_embd*2", "\n", "qk", "=", "tf", ".", "reshape", "(", "qk", ",", "(", "bs", ",", "T", ",", "NE", ",", "heads", ",", "n_embd", "//", "heads", ",", "2", ")", ")", "\n", "\n", "# (bs, T, NE, heads, features)", "\n", "query", ",", "key", "=", "[", "tf", ".", "squeeze", "(", "x", ",", "-", "1", ")", "for", "x", "in", "tf", ".", "split", "(", "qk", ",", "2", ",", "-", "1", ")", "]", "\n", "\n", "v_scale", "=", "np", ".", "sqrt", "(", "v_w", "/", "features", ")", "\n", "value", "=", "tf", ".", "layers", ".", "dense", "(", "inp", ",", "\n", "n_embd", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "v_scale", ")", ",", "\n", "reuse", "=", "reuse", ",", "\n", "name", "=", "\"v_embed\"", ")", "# bs x T x n_embd", "\n", "value", "=", "tf", ".", "reshape", "(", "value", ",", "(", "bs", ",", "T", ",", "NE", ",", "heads", ",", "n_embd", "//", "heads", ")", ")", "\n", "\n", "query", "=", "tf", ".", "transpose", "(", "query", ",", "(", "0", ",", "1", ",", "3", ",", "2", ",", "4", ")", ",", "\n", "name", "=", "\"transpose_query\"", ")", "# (bs, T, heads, NE, n_embd / heads)", "\n", "key", "=", "tf", ".", "transpose", "(", "key", ",", "(", "0", ",", "1", ",", "3", ",", "4", ",", "2", ")", ",", "\n", "name", "=", "\"transpose_key\"", ")", "# (bs, T, heads, n_embd / heads, NE)", "\n", "value", "=", "tf", ".", "transpose", "(", "value", ",", "(", "0", ",", "1", ",", "3", ",", "2", ",", "4", ")", ",", "\n", "name", "=", "\"transpose_value\"", ")", "# (bs, T, heads, NE, n_embd / heads)", "\n", "\n", "", "return", "query", ",", "key", ",", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.layers.circ_conv1d": [[263, 281], ["ma_policy.util.shape_list", "tensorflow.reshape", "tensorflow.concat", "tensorflow.layers.conv1d", "tensorflow.reshape", "tensorflow.contrib.layers.xavier_initializer"], "function", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list"], ["", "def", "circ_conv1d", "(", "inp", ",", "**", "conv_kwargs", ")", ":", "\n", "    ", "valid_activations", "=", "{", "'relu'", ":", "tf", ".", "nn", ".", "relu", ",", "'tanh'", ":", "tf", ".", "tanh", ",", "''", ":", "None", "}", "\n", "assert", "'kernel_size'", "in", "conv_kwargs", ",", "f\"Kernel size needs to be specified for circular convolution layer.\"", "\n", "conv_kwargs", "[", "'activation'", "]", "=", "valid_activations", "[", "conv_kwargs", "[", "'activation'", "]", "]", "\n", "\n", "# concatenate input for circular convolution", "\n", "kernel_size", "=", "conv_kwargs", "[", "'kernel_size'", "]", "\n", "num_pad", "=", "kernel_size", "//", "2", "\n", "inp_shape", "=", "shape_list", "(", "inp", ")", "\n", "inp_rs", "=", "tf", ".", "reshape", "(", "inp", ",", "shape", "=", "[", "inp_shape", "[", "0", "]", "*", "inp_shape", "[", "1", "]", "]", "+", "inp_shape", "[", "2", ":", "]", ")", "#  (BS * T, NE, feats)", "\n", "inp_padded", "=", "tf", ".", "concat", "(", "[", "inp_rs", "[", "...", ",", "-", "num_pad", ":", ",", ":", "]", ",", "inp_rs", ",", "inp_rs", "[", "...", ",", ":", "num_pad", ",", ":", "]", "]", ",", "-", "2", ")", "\n", "out", "=", "tf", ".", "layers", ".", "conv1d", "(", "inp_padded", ",", "\n", "kernel_initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", ",", "\n", "padding", "=", "'valid'", ",", "\n", "**", "conv_kwargs", ")", "\n", "\n", "out", "=", "tf", ".", "reshape", "(", "out", ",", "shape", "=", "inp_shape", "[", ":", "3", "]", "+", "[", "conv_kwargs", "[", "'filters'", "]", "]", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.layers.layernorm": [[287, 299], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "x.get_shape", "tensorflow.square", "tensorflow.rsqrt", "tensorflow.constant_initializer", "tensorflow.constant_initializer"], "function", ["None"], ["", "def", "layernorm", "(", "x", ",", "scope", ",", "epsilon", "=", "1e-5", ",", "reuse", "=", "False", ")", ":", "\n", "    ", "'''\n        normalize state vector to be zero mean / unit variance + learned scale/shift\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "n_state", "=", "x", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n", "gain", "=", "tf", ".", "get_variable", "(", "'gain'", ",", "[", "n_state", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "1", ")", ")", "\n", "bias", "=", "tf", ".", "get_variable", "(", "'bias'", ",", "[", "n_state", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0", ")", ")", "\n", "mean", "=", "tf", ".", "reduce_mean", "(", "x", ",", "axis", "=", "[", "-", "1", "]", ",", "keep_dims", "=", "True", ")", "\n", "variance", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "x", "-", "mean", ")", ",", "axis", "=", "[", "-", "1", "]", ",", "keep_dims", "=", "True", ")", "\n", "norm_x", "=", "(", "x", "-", "mean", ")", "*", "tf", ".", "rsqrt", "(", "variance", "+", "epsilon", ")", "\n", "return", "norm_x", "*", "gain", "+", "bias", "\n", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.variable_schema.VariableSchema.__init__": [[9, 25], ["all", "tensorflow.as_dtype", "isinstance"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "shape", ",", "dtype", ")", ":", "\n", "        ", "\"\"\"Creates a schema for a variable used in policy.\n        Allows for symbolic definition of shape. Shape can consist of integers, as well as\n        strings BATCH and TIMESTEPS. This is taken advantage of in the optimizers, to\n        create placeholders or variables that asynchronously prefetch the inputs.\n\n        Parameters\n        ----------\n        shape: [int, np.int64, np.int32, or str]\n            shape of the variable, e.g. [12, 4], [BATCH, 12], [BATCH, 'timestep']\n        dtype:\n            tensorflow type of the variable, e.g. tf.float32, tf.int32\n        \"\"\"", "\n", "assert", "all", "(", "isinstance", "(", "s", ",", "(", "int", ",", "np", ".", "int64", ",", "np", ".", "int32", ")", ")", "or", "s", "in", "[", "BATCH", ",", "TIMESTEPS", "]", "for", "s", "in", "shape", ")", ",", "'Bad shape %s'", "%", "shape", "\n", "self", ".", "shape", "=", "shape", "\n", "self", ".", "dtype", "=", "tf", ".", "as_dtype", "(", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.variable_schema.VariableSchema._substituted_shape": [[26, 29], ["dict", "dict.get"], "methods", ["None"], ["", "def", "_substituted_shape", "(", "self", ",", "batch", "=", "None", ",", "timesteps", "=", "None", ")", ":", "\n", "        ", "feeds", "=", "dict", "(", "batch", "=", "batch", ",", "timesteps", "=", "timesteps", ")", "\n", "return", "[", "feeds", ".", "get", "(", "v", ",", "v", ")", "for", "v", "in", "self", ".", "shape", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.variable_schema.VariableSchema.substitute": [[30, 37], ["variable_schema.VariableSchema._substituted_shape", "variable_schema.VariableSchema"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.variable_schema.VariableSchema._substituted_shape"], ["", "def", "substitute", "(", "self", ",", "*", ",", "batch", "=", "BATCH", ",", "timesteps", "=", "TIMESTEPS", ")", ":", "\n", "        ", "\"\"\"Make a new VariableSchema with batch or timesteps optionally filled in.\"\"\"", "\n", "# Coerse None to default value.", "\n", "batch", "=", "batch", "or", "BATCH", "\n", "timesteps", "=", "timesteps", "or", "TIMESTEPS", "\n", "shape", "=", "self", ".", "_substituted_shape", "(", "batch", ",", "timesteps", ")", "\n", "return", "VariableSchema", "(", "shape", "=", "shape", ",", "dtype", "=", "self", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.variable_schema.VariableSchema.placeholder": [[38, 41], ["variable_schema.VariableSchema._substituted_shape", "tensorflow.placeholder"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.variable_schema.VariableSchema._substituted_shape", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.variable_schema.VariableSchema.placeholder"], ["", "def", "placeholder", "(", "self", ",", "*", ",", "batch", "=", "None", ",", "timesteps", "=", "None", ",", "name", "=", "None", ")", ":", "\n", "        ", "real_shape", "=", "self", ".", "_substituted_shape", "(", "batch", ",", "timesteps", ")", "\n", "return", "tf", ".", "placeholder", "(", "self", ".", "dtype", ",", "real_shape", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.variable_schema.VariableSchema.variable": [[42, 46], ["variable_schema.VariableSchema._substituted_shape", "tensorflow.get_variable"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.variable_schema.VariableSchema._substituted_shape"], ["", "def", "variable", "(", "self", ",", "*", ",", "name", ",", "batch", "=", "None", ",", "timesteps", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "real_shape", "=", "self", ".", "_substituted_shape", "(", "batch", ",", "timesteps", ")", "\n", "assert", "None", "not", "in", "real_shape", "\n", "return", "tf", ".", "get_variable", "(", "name", ",", "real_shape", ",", "self", ".", "dtype", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.variable_schema.VariableSchema.np_zeros": [[47, 51], ["variable_schema.VariableSchema._substituted_shape", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.variable_schema.VariableSchema._substituted_shape"], ["", "def", "np_zeros", "(", "self", ",", "*", ",", "batch", "=", "None", ",", "timesteps", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "real_shape", "=", "self", ".", "_substituted_shape", "(", "batch", ",", "timesteps", ")", "\n", "np_dtype", "=", "self", ".", "dtype", ".", "as_numpy_dtype", "\n", "return", "np", ".", "zeros", "(", "shape", "=", "real_shape", ",", "dtype", "=", "np_dtype", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.variable_schema.VariableSchema.match_shape": [[52, 60], ["variable_schema.VariableSchema._substituted_shape", "zip", "len", "len"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.variable_schema.VariableSchema._substituted_shape"], ["", "def", "match_shape", "(", "self", ",", "shape", ",", "*", ",", "batch", "=", "None", ",", "timesteps", "=", "None", ")", ":", "\n", "        ", "expected", "=", "self", ".", "_substituted_shape", "(", "batch", ",", "timesteps", ")", "\n", "if", "len", "(", "expected", ")", "!=", "len", "(", "shape", ")", ":", "\n", "            ", "return", "False", "\n", "", "for", "expected", ",", "actual", "in", "zip", "(", "expected", ",", "shape", ")", ":", "\n", "            ", "if", "expected", "is", "not", "None", "and", "expected", "!=", "actual", ":", "\n", "                ", "return", "False", "\n", "", "", "return", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.normc_initializer": [[5, 11], ["numpy.random.randn().astype", "tensorflow.constant", "numpy.sqrt", "numpy.random.randn", "numpy.square().sum", "numpy.square"], "function", ["None"], ["def", "get_size_from_xml", "(", "obj", ")", ":", "\n", "    ", "'''\n        Args:\n            obj (worldgen.Obj): worldgen object\n        Returns: size of object annotation:outerbound if it exists, None if it doesn't\n    '''", "\n", "outer_bound", "=", "None", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.listdict2dictnp": [[13, 25], ["numpy.concatenate", "numpy.array"], "function", ["None"], ["        ", "if", "body", ".", "get", "(", "'@name'", ",", "''", ")", "==", "'annotation:outer_bound'", ":", "\n", "            ", "outer_bound", "=", "body", "\n", "", "", "if", "outer_bound", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "else", ":", "\n", "        ", "return", "outer_bound", "[", "'geom'", "]", "[", "0", "]", "[", "'@size'", "]", "[", ":", "2", "]", "*", "2", "\n", "\n", "\n", "", "", "def", "rejection_placement", "(", "env", ",", "placement_fn", ",", "floor_size", ",", "obj_size", ",", "num_tries", "=", "10", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list": [[27, 34], ["x.get_shape().as_list", "tensorflow.shape", "x.get_shape", "range", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.l2_loss": [[36, 47], ["tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.square", "tensorflow.square"], "function", ["None"], ["\n", "grid", "=", "env", ".", "placement_grid", "\n", "grid_size", "=", "len", "(", "grid", ")", "\n", "cell_size", "=", "floor_size", "/", "grid_size", "\n", "obj_size_in_cells", "=", "np", ".", "ceil", "(", "obj_size", "/", "cell_size", ")", ".", "astype", "(", "int", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_tries", ")", ":", "\n", "        ", "if", "placement_fn", "is", "not", "None", ":", "\n", "            ", "pos", "=", "placement_fn", "(", "grid", ",", "obj_size_in_cells", ",", "env", ".", "metadata", ",", "env", ".", "_random_state", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.__init__": [[29, 92], ["copy.deepcopy", "isinstance", "isinstance", "ma_policy.MAPolicy.ob_space.spaces.items", "ma_policy.graph_construct.construct_schemas_zero_state", "ma_policy.graph_construct.construct_schemas_zero_state", "ma_policy.MAPolicy.input_schemas.update", "ma_policy.MAPolicy.input_schemas.update", "ma_policy.MAPolicy.zero_state.update", "ma_policy.MAPolicy.zero_state.update", "baselines.common.distributions.make_pdtype", "ma_policy.variable_schema.VariableSchema", "ma_policy.variable_schema.VariableSchema", "list", "list", "ma_policy.MAPolicy.build", "ma_policy.MAPolicy.ac_space.spaces.items", "ma_policy.MAPolicy.ac_space.spaces.items", "ma_policy.MAPolicy.pdtypes.items", "v_state_schemas.keys", "pi_state_schemas.keys", "tensorflow.variable_scope", "pdtype.sample_dtype", "schema.placeholder", "pdtype.sample_shape", "list", "ma_policy.MAPolicy.get_input_schemas().items", "ma_policy.MAPolicy.get_input_schemas"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.graph_construct.construct_schemas_zero_state", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.graph_construct.construct_schemas_zero_state", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.build", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.variable_schema.VariableSchema.placeholder", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.get_input_schemas"], ["def", "__init__", "(", "self", ",", "scope", ",", "*", ",", "ob_space", ",", "ac_space", ",", "network_spec", ",", "v_network_spec", "=", "None", ",", "\n", "stochastic", "=", "True", ",", "reuse", "=", "False", ",", "build_act", "=", "True", ",", "\n", "trainable_vars", "=", "None", ",", "not_trainable_vars", "=", "None", ",", "\n", "gaussian_fixed_var", "=", "True", ",", "weight_decay", "=", "0.0", ",", "ema_beta", "=", "0.99999", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "reuse", "=", "reuse", "\n", "self", ".", "scope", "=", "scope", "\n", "self", ".", "ob_space", "=", "ob_space", "\n", "self", ".", "ac_space", "=", "deepcopy", "(", "ac_space", ")", "\n", "self", ".", "network_spec", "=", "network_spec", "\n", "self", ".", "v_network_spec", "=", "v_network_spec", "or", "self", ".", "network_spec", "\n", "self", ".", "stochastic", "=", "stochastic", "\n", "self", ".", "trainable_vars", "=", "trainable_vars", "\n", "self", ".", "not_trainable_vars", "=", "not_trainable_vars", "\n", "self", ".", "gaussian_fixed_var", "=", "gaussian_fixed_var", "\n", "self", ".", "weight_decay", "=", "weight_decay", "\n", "self", ".", "kwargs", "=", "kwargs", "\n", "self", ".", "build_act", "=", "build_act", "\n", "self", ".", "_reset_ops", "=", "[", "]", "\n", "self", ".", "_auxiliary_losses", "=", "[", "]", "\n", "self", ".", "_running_mean_stds", "=", "{", "}", "\n", "self", ".", "_ema_beta", "=", "ema_beta", "\n", "self", ".", "training_stats", "=", "[", "]", "\n", "\n", "assert", "isinstance", "(", "self", ".", "ac_space", ",", "gym", ".", "spaces", ".", "Dict", ")", "\n", "assert", "isinstance", "(", "self", ".", "ob_space", ",", "gym", ".", "spaces", ".", "Dict", ")", "\n", "assert", "'observation_self'", "in", "self", ".", "ob_space", ".", "spaces", "\n", "\n", "# Action space will come in as a MA action space. Convert to a SA action space.", "\n", "self", ".", "ac_space", ".", "spaces", "=", "{", "k", ":", "v", ".", "spaces", "[", "0", "]", "for", "k", ",", "v", "in", "self", ".", "ac_space", ".", "spaces", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "pdtypes", "=", "{", "k", ":", "make_pdtype", "(", "s", ")", "for", "k", ",", "s", "in", "self", ".", "ac_space", ".", "spaces", ".", "items", "(", ")", "}", "\n", "\n", "# Create input schemas for each action type", "\n", "self", ".", "input_schemas", "=", "{", "\n", "k", ":", "VariableSchema", "(", "shape", "=", "[", "BATCH", ",", "TIMESTEPS", "]", "+", "pdtype", ".", "sample_shape", "(", ")", ",", "\n", "dtype", "=", "pdtype", ".", "sample_dtype", "(", ")", ")", "\n", "for", "k", ",", "pdtype", "in", "self", ".", "pdtypes", ".", "items", "(", ")", "\n", "}", "\n", "\n", "# Creat input schemas for each observation", "\n", "for", "k", ",", "v", "in", "self", ".", "ob_space", ".", "spaces", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "input_schemas", "[", "k", "]", "=", "VariableSchema", "(", "shape", "=", "[", "BATCH", ",", "TIMESTEPS", "]", "+", "list", "(", "v", ".", "shape", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# Setup schemas and zero state for layers with state", "\n", "", "v_state_schemas", ",", "v_zero_states", "=", "construct_schemas_zero_state", "(", "\n", "self", ".", "v_network_spec", ",", "self", ".", "ob_space", ",", "'vpred_net'", ")", "\n", "pi_state_schemas", ",", "pi_zero_states", "=", "construct_schemas_zero_state", "(", "\n", "self", ".", "network_spec", ",", "self", ".", "ob_space", ",", "'policy_net'", ")", "\n", "\n", "self", ".", "state_keys", "=", "list", "(", "v_state_schemas", ".", "keys", "(", ")", ")", "+", "list", "(", "pi_state_schemas", ".", "keys", "(", ")", ")", "\n", "self", ".", "input_schemas", ".", "update", "(", "v_state_schemas", ")", "\n", "self", ".", "input_schemas", ".", "update", "(", "pi_state_schemas", ")", "\n", "self", ".", "zero_state", "=", "{", "}", "\n", "self", ".", "zero_state", ".", "update", "(", "v_zero_states", ")", "\n", "self", ".", "zero_state", ".", "update", "(", "pi_zero_states", ")", "\n", "\n", "if", "build_act", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ",", "reuse", "=", "self", ".", "reuse", ")", ":", "\n", "                ", "self", ".", "phs", "=", "{", "name", ":", "schema", ".", "placeholder", "(", "name", "=", "name", ")", "\n", "for", "name", ",", "schema", "in", "self", ".", "get_input_schemas", "(", ")", ".", "items", "(", ")", "}", "\n", "", "self", ".", "build", "(", "self", ".", "phs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.build": [[93, 97], ["tensorflow.variable_scope", "ma_policy.MAPolicy._init", "tensorflow.get_variable_scope"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy._init"], ["", "", "def", "build", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ",", "reuse", "=", "self", ".", "reuse", ")", ":", "\n", "            ", "self", ".", "full_scope_name", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "self", ".", "_init", "(", "inputs", ",", "**", "self", ".", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy._init": [[98, 139], ["ma_policy.MAPolicy._normalize_inputs", "collections.OrderedDict", "ma_policy.graph_construct.construct_tf_graph", "ma_policy.MAPolicy._init_vpred_head", "ma_policy.graph_construct.construct_tf_graph", "ma_policy.MAPolicy.state_out.update", "ma_policy.MAPolicy.state_out.update", "ma_policy.MAPolicy._init_policy_out", "ma_policy.MAPolicy.reset", "tensorflow.reduce_sum", "ma_policy.MAPolicy.add_auxiliary_loss", "ma_policy.MAPolicy.pdtypes.keys", "inputs.items", "ma_policy.MAPolicy.pdtypes.keys", "ma_policy.MAPolicy.get_trainable_variables", "tensorflow.nn.l2_loss"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy._normalize_inputs", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.graph_construct.construct_tf_graph", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy._init_vpred_head", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.graph_construct.construct_tf_graph", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy._init_policy_out", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.add_auxiliary_loss", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.get_trainable_variables", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.l2_loss"], ["", "", "def", "_init", "(", "self", ",", "inputs", ",", "gaussian_fixed_var", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "'''\n            Args:\n                inputs (dict): input dictionary containing tf tensors\n                gaussian_fixed_var (bool): If True the policies variance won't be conditioned on state\n        '''", "\n", "taken_actions", "=", "{", "k", ":", "inputs", "[", "k", "]", "for", "k", "in", "self", ".", "pdtypes", ".", "keys", "(", ")", "}", "\n", "\n", "#  Copy inputs to not overwrite. Don't need to pass actions to policy, so exlcude these", "\n", "processed_inp", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "inputs", ".", "items", "(", ")", "if", "k", "not", "in", "self", ".", "pdtypes", ".", "keys", "(", ")", "}", "\n", "\n", "self", ".", "_normalize_inputs", "(", "processed_inp", ")", "\n", "\n", "self", ".", "state_out", "=", "OrderedDict", "(", ")", "\n", "\n", "# Value network", "\n", "(", "vpred", ",", "\n", "vpred_state_out", ",", "\n", "vpred_reset_ops", ")", "=", "construct_tf_graph", "(", "\n", "processed_inp", ",", "self", ".", "v_network_spec", ",", "scope", "=", "'vpred_net'", ",", "act", "=", "self", ".", "build_act", ")", "\n", "\n", "self", ".", "_init_vpred_head", "(", "vpred", ",", "processed_inp", ",", "'vpred_out0'", ",", "\"value0\"", ")", "\n", "\n", "# Policy network", "\n", "(", "pi", ",", "\n", "pi_state_out", ",", "\n", "pi_reset_ops", ")", "=", "construct_tf_graph", "(", "\n", "processed_inp", ",", "self", ".", "network_spec", ",", "scope", "=", "'policy_net'", ",", "act", "=", "self", ".", "build_act", ")", "\n", "\n", "self", ".", "state_out", ".", "update", "(", "vpred_state_out", ")", "\n", "self", ".", "state_out", ".", "update", "(", "pi_state_out", ")", "\n", "self", ".", "_reset_ops", "+=", "vpred_reset_ops", "+", "pi_reset_ops", "\n", "self", ".", "_init_policy_out", "(", "pi", ",", "taken_actions", ")", "\n", "if", "self", ".", "weight_decay", "!=", "0.0", ":", "\n", "            ", "kernels", "=", "[", "var", "for", "var", "in", "self", ".", "get_trainable_variables", "(", ")", "if", "'kernel'", "in", "var", ".", "name", "]", "\n", "w_norm_sum", "=", "tf", ".", "reduce_sum", "(", "[", "tf", ".", "nn", ".", "l2_loss", "(", "var", ")", "for", "var", "in", "kernels", "]", ")", "\n", "w_norm_loss", "=", "w_norm_sum", "*", "self", ".", "weight_decay", "\n", "self", ".", "add_auxiliary_loss", "(", "'weight_decay'", ",", "w_norm_loss", ")", "\n", "\n", "# set state to zero state", "\n", "", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy._init_policy_out": [[140, 187], ["tensorflow.variable_scope", "ma_policy.MAPolicy.pdtypes.keys", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "sum", "tensorflow.variable_scope", "sum", "tensorflow.variable_scope", "sum", "tensorflow.variable_scope", "pdtype.pdfromflat", "isinstance", "tensorflow.layers.dense", "tensorflow.get_variable", "tensorflow.concat", "ma_policy.MAPolicy.pdtypes.items", "pd.sample", "pd.mode", "ma_policy.MAPolicy.pds.items", "ma_policy.MAPolicy.pds[].logp", "pd.entropy", "ma_policy.MAPolicy.pds[].logp", "isinstance", "tensorflow.layers.dense", "ma_policy.MAPolicy.pdtypes.keys", "ma_policy.MAPolicy.pds.values", "ma_policy.MAPolicy.pdtypes.keys", "ma_policy.util.normc_initializer", "tensorflow.zeros_initializer", "isinstance", "ma_policy.MAPolicy.pdtypes[].param_shape", "tensorflow.reshape", "ma_policy.MAPolicy.pdtypes[].param_shape", "ma_policy.util.normc_initializer", "pi[].get_shape", "numpy.prod", "ma_policy.MAPolicy.pdtypes[].param_shape", "ma_policy.MAPolicy.pdtypes[].param_shape", "pi[].get_shape", "ma_policy.MAPolicy.pdtypes[].param_shape", "ma_policy.util.shape_list", "pi[].get_shape", "numpy.prod", "pi[].get_shape"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.normc_initializer", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.normc_initializer", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.shape_list"], ["", "def", "_init_policy_out", "(", "self", ",", "pi", ",", "taken_actions", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'policy_out'", ")", ":", "\n", "            ", "self", ".", "pdparams", "=", "{", "}", "\n", "for", "k", "in", "self", ".", "pdtypes", ".", "keys", "(", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "k", ")", ":", "\n", "                    ", "if", "self", ".", "gaussian_fixed_var", "and", "isinstance", "(", "self", ".", "ac_space", ".", "spaces", "[", "k", "]", ",", "gym", ".", "spaces", ".", "Box", ")", ":", "\n", "                        ", "mean", "=", "tf", ".", "layers", ".", "dense", "(", "pi", "[", "\"main\"", "]", ",", "\n", "self", ".", "pdtypes", "[", "k", "]", ".", "param_shape", "(", ")", "[", "0", "]", "//", "2", ",", "\n", "kernel_initializer", "=", "normc_initializer", "(", "0.01", ")", ",", "\n", "activation", "=", "None", ")", "\n", "logstd", "=", "tf", ".", "get_variable", "(", "name", "=", "\"logstd\"", ",", "\n", "shape", "=", "[", "1", ",", "self", ".", "pdtypes", "[", "k", "]", ".", "param_shape", "(", ")", "[", "0", "]", "//", "2", "]", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "self", ".", "pdparams", "[", "k", "]", "=", "tf", ".", "concat", "(", "[", "mean", ",", "mean", "*", "0.0", "+", "logstd", "]", ",", "axis", "=", "2", ")", "\n", "", "elif", "k", "in", "pi", ":", "\n", "# This is just for the case of entity specific actions", "\n", "                        ", "if", "isinstance", "(", "self", ".", "ac_space", ".", "spaces", "[", "k", "]", ",", "(", "gym", ".", "spaces", ".", "Discrete", ")", ")", ":", "\n", "                            ", "assert", "pi", "[", "k", "]", ".", "get_shape", "(", ")", "[", "-", "1", "]", "==", "1", "\n", "self", ".", "pdparams", "[", "k", "]", "=", "pi", "[", "k", "]", "[", "...", ",", "0", "]", "\n", "", "elif", "isinstance", "(", "self", ".", "ac_space", ".", "spaces", "[", "k", "]", ",", "(", "gym", ".", "spaces", ".", "MultiDiscrete", ")", ")", ":", "\n", "                            ", "assert", "np", ".", "prod", "(", "pi", "[", "k", "]", ".", "get_shape", "(", ")", "[", "-", "2", ":", "]", ")", "==", "self", ".", "pdtypes", "[", "k", "]", ".", "param_shape", "(", ")", "[", "0", "]", ",", "f\"policy had shape {pi[k].get_shape()} for action {k}, but required {self.pdtypes[k].param_shape()}\"", "\n", "new_shape", "=", "shape_list", "(", "pi", "[", "k", "]", ")", "[", ":", "-", "2", "]", "+", "[", "np", ".", "prod", "(", "pi", "[", "k", "]", ".", "get_shape", "(", ")", "[", "-", "2", ":", "]", ")", ".", "value", "]", "\n", "self", ".", "pdparams", "[", "k", "]", "=", "tf", ".", "reshape", "(", "pi", "[", "k", "]", ",", "shape", "=", "new_shape", ")", "\n", "", "else", ":", "\n", "                            ", "assert", "False", "\n", "", "", "else", ":", "\n", "                        ", "self", ".", "pdparams", "[", "k", "]", "=", "tf", ".", "layers", ".", "dense", "(", "pi", "[", "\"main\"", "]", ",", "\n", "self", ".", "pdtypes", "[", "k", "]", ".", "param_shape", "(", ")", "[", "0", "]", ",", "\n", "kernel_initializer", "=", "normc_initializer", "(", "0.01", ")", ",", "\n", "activation", "=", "None", ")", "\n", "\n", "", "", "", "with", "tf", ".", "variable_scope", "(", "'pds'", ")", ":", "\n", "                ", "self", ".", "pds", "=", "{", "k", ":", "pdtype", ".", "pdfromflat", "(", "self", ".", "pdparams", "[", "k", "]", ")", "\n", "for", "k", ",", "pdtype", "in", "self", ".", "pdtypes", ".", "items", "(", ")", "}", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'sampled_action'", ")", ":", "\n", "                ", "self", ".", "sampled_action", "=", "{", "k", ":", "pd", ".", "sample", "(", ")", "if", "self", ".", "stochastic", "else", "pd", ".", "mode", "(", ")", "\n", "for", "k", ",", "pd", "in", "self", ".", "pds", ".", "items", "(", ")", "}", "\n", "", "with", "tf", ".", "variable_scope", "(", "'sampled_action_logp'", ")", ":", "\n", "                ", "self", ".", "sampled_action_logp", "=", "sum", "(", "[", "self", ".", "pds", "[", "k", "]", ".", "logp", "(", "self", ".", "sampled_action", "[", "k", "]", ")", "\n", "for", "k", "in", "self", ".", "pdtypes", ".", "keys", "(", ")", "]", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'entropy'", ")", ":", "\n", "                ", "self", ".", "entropy", "=", "sum", "(", "[", "pd", ".", "entropy", "(", ")", "for", "pd", "in", "self", ".", "pds", ".", "values", "(", ")", "]", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'taken_action_logp'", ")", ":", "\n", "                ", "self", ".", "taken_action_logp", "=", "sum", "(", "[", "self", ".", "pds", "[", "k", "]", ".", "logp", "(", "taken_actions", "[", "k", "]", ")", "\n", "for", "k", "in", "self", ".", "pdtypes", ".", "keys", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy._init_vpred_head": [[188, 201], ["tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.squeeze", "functools.partial", "functools.partial", "functools.partial.", "ma_policy.MAPolicy.add_running_mean_std", "tensorflow.contrib.layers.xavier_initializer", "processed_inp.get", "enumerate", "tensorflow.squeeze.get_shape"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.add_running_mean_std"], ["", "", "", "def", "_init_vpred_head", "(", "self", ",", "vpred", ",", "processed_inp", ",", "vpred_scope", ",", "feedback_name", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "vpred_scope", ")", ":", "\n", "            ", "_vpred", "=", "tf", ".", "layers", ".", "dense", "(", "vpred", "[", "'main'", "]", ",", "1", ",", "activation", "=", "None", ",", "\n", "kernel_initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", ")", "\n", "_vpred", "=", "tf", ".", "squeeze", "(", "_vpred", ",", "-", "1", ")", "\n", "normalize_axes", "=", "(", "0", ",", "1", ")", "\n", "loss_fn", "=", "partial", "(", "l2_loss", ",", "mask", "=", "processed_inp", ".", "get", "(", "feedback_name", "+", "\"_mask\"", ",", "None", ")", ")", "\n", "rms_class", "=", "partial", "(", "EMAMeanStd", ",", "beta", "=", "self", ".", "_ema_beta", ")", "\n", "\n", "rms_shape", "=", "[", "dim", "for", "i", ",", "dim", "in", "enumerate", "(", "_vpred", ".", "get_shape", "(", ")", ")", "if", "i", "not", "in", "normalize_axes", "]", "\n", "self", ".", "value_rms", "=", "rms_class", "(", "shape", "=", "rms_shape", ",", "scope", "=", "'value0filter'", ")", "\n", "self", ".", "scaled_value_tensor", "=", "self", ".", "value_rms", ".", "mean", "+", "_vpred", "*", "self", ".", "value_rms", ".", "std", "\n", "self", ".", "add_running_mean_std", "(", "rms", "=", "self", ".", "value_rms", ",", "name", "=", "'feedback.value0'", ",", "axes", "=", "normalize_axes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy._normalize_inputs": [[202, 223], ["ma_policy.MAPolicy.ob_space.spaces.keys", "tensorflow.variable_scope", "ma_policy.normalizers.EMAMeanStd", "ma_policy.MAPolicy.add_running_mean_std", "tensorflow.clip_by_value", "tensorflow.variable_scope", "ma_policy.normalizers.EMAMeanStd", "tensorflow.clip_by_value", "ma_policy.MAPolicy.add_running_mean_std"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.add_running_mean_std", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.add_running_mean_std"], ["", "", "def", "_normalize_inputs", "(", "self", ",", "processed_inp", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'normalize_self_obs'", ")", ":", "\n", "            ", "ob_rms_self", "=", "EMAMeanStd", "(", "shape", "=", "self", ".", "ob_space", ".", "spaces", "[", "'observation_self'", "]", ".", "shape", ",", "\n", "scope", "=", "\"obsfilter\"", ",", "beta", "=", "self", ".", "_ema_beta", ",", "per_element_update", "=", "False", ")", "\n", "self", ".", "add_running_mean_std", "(", "\"observation_self\"", ",", "ob_rms_self", ",", "axes", "=", "(", "0", ",", "1", ")", ")", "\n", "normalized", "=", "(", "processed_inp", "[", "'observation_self'", "]", "-", "ob_rms_self", ".", "mean", ")", "/", "ob_rms_self", ".", "std", "\n", "clipped", "=", "tf", ".", "clip_by_value", "(", "normalized", ",", "-", "5.0", ",", "5.0", ")", "\n", "processed_inp", "[", "'observation_self'", "]", "=", "clipped", "\n", "\n", "", "for", "key", "in", "self", ".", "ob_space", ".", "spaces", ".", "keys", "(", ")", ":", "\n", "            ", "if", "key", "==", "'observation_self'", ":", "\n", "                ", "continue", "\n", "", "elif", "'mask'", "in", "key", ":", "# Don't normalize observation masks", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "f'normalize_{key}'", ")", ":", "\n", "                    ", "ob_rms", "=", "EMAMeanStd", "(", "shape", "=", "self", ".", "ob_space", ".", "spaces", "[", "key", "]", ".", "shape", "[", "1", ":", "]", ",", "\n", "scope", "=", "f\"obsfilter/{key}\"", ",", "beta", "=", "self", ".", "_ema_beta", ",", "per_element_update", "=", "False", ")", "\n", "normalized", "=", "(", "processed_inp", "[", "key", "]", "-", "ob_rms", ".", "mean", ")", "/", "ob_rms", ".", "std", "\n", "processed_inp", "[", "key", "]", "=", "tf", ".", "clip_by_value", "(", "normalized", ",", "-", "5.0", ",", "5.0", ")", "\n", "self", ".", "add_running_mean_std", "(", "key", ",", "ob_rms", ",", "axes", "=", "(", "0", ",", "1", ",", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.get_input_schemas": [[224, 226], ["ma_policy.MAPolicy.input_schemas.copy"], "methods", ["None"], ["", "", "", "", "def", "get_input_schemas", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "input_schemas", ".", "copy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.process_state_batch": [[227, 235], ["ma_policy.util.listdict2dictnp"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.listdict2dictnp"], ["", "def", "process_state_batch", "(", "self", ",", "states", ")", ":", "\n", "        ", "'''\n            Batch states together.\n            args:\n                states -- list (batch) of dicts of states with shape (n_agent, dim state).\n        '''", "\n", "new_states", "=", "listdict2dictnp", "(", "states", ",", "keepdims", "=", "True", ")", "\n", "return", "new_states", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.process_observation_batch": [[236, 252], ["copy.deepcopy", "list", "ma_policy.util.listdict2dictnp", "map", "ma_policy.MAPolicy.reshape_ma_observations", "zip", "ma_policy.util.listdict2dictnp", "ma_policy.util.listdict2dictnp.items"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.listdict2dictnp", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reshape_ma_observations", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.util.listdict2dictnp"], ["", "def", "process_observation_batch", "(", "self", ",", "obs", ")", ":", "\n", "        ", "'''\n            Batch obs together.\n            Args:\n                obs -- list of lists (batch, time), where elements are dictionary observations\n        '''", "\n", "\n", "new_obs", "=", "deepcopy", "(", "obs", ")", "\n", "# List tranpose -- now in (time, batch)", "\n", "new_obs", "=", "list", "(", "map", "(", "list", ",", "zip", "(", "*", "new_obs", ")", ")", ")", "\n", "# Convert list of list of dicts to dict of numpy arrays", "\n", "new_obs", "=", "listdict2dictnp", "(", "[", "listdict2dictnp", "(", "batch", ",", "keepdims", "=", "True", ")", "for", "batch", "in", "new_obs", "]", ")", "\n", "# Flatten out the agent dimension, so batches look like normal SA batches", "\n", "new_obs", "=", "{", "k", ":", "self", ".", "reshape_ma_observations", "(", "v", ")", "for", "k", ",", "v", "in", "new_obs", ".", "items", "(", ")", "}", "\n", "\n", "return", "new_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reshape_ma_observations": [[253, 268], ["obs.copy().transpose", "len", "len", "obs.copy", "len", "ValueError"], "methods", ["None"], ["", "def", "reshape_ma_observations", "(", "self", ",", "obs", ")", ":", "\n", "# Observations with shape (time, batch)", "\n", "        ", "if", "len", "(", "obs", ".", "shape", ")", "==", "2", ":", "\n", "            ", "batch_first_ordering", "=", "(", "1", ",", "0", ")", "\n", "# Observations with shape (time, batch, dim obs)", "\n", "", "elif", "len", "(", "obs", ".", "shape", ")", "==", "3", ":", "\n", "            ", "batch_first_ordering", "=", "(", "1", ",", "0", ",", "2", ")", "\n", "# Observations with shape (time, batch, n_entity, dim obs)", "\n", "", "elif", "len", "(", "obs", ".", "shape", ")", "==", "4", ":", "\n", "            ", "batch_first_ordering", "=", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Obs dim {obs.shape}. Only supports dim 3 or 4\"", ")", "\n", "", "new_obs", "=", "obs", ".", "copy", "(", ")", ".", "transpose", "(", "batch_first_ordering", ")", "# (n_agent, batch, time, dim obs)", "\n", "\n", "return", "new_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.prepare_input": [[269, 277], ["copy.deepcopy", "copy.deepcopy.update", "copy.deepcopy.update"], "methods", ["None"], ["", "def", "prepare_input", "(", "self", ",", "observation", ",", "state_in", ",", "taken_action", "=", "None", ")", ":", "\n", "        ", "''' Add in time dimension to observations, assumes that first dimension of observation is\n            already the batch dimension and does not need to be added.'''", "\n", "obs", "=", "deepcopy", "(", "observation", ")", "\n", "obs", ".", "update", "(", "state_in", ")", "\n", "if", "taken_action", "is", "not", "None", ":", "\n", "            ", "obs", ".", "update", "(", "taken_action", ")", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.act": [[278, 317], ["copy.deepcopy", "ma_policy.MAPolicy.state.items", "copy.deepcopy.items", "ma_policy.MAPolicy.prepare_input", "feed_dict.update", "tensorflow.get_default_session().run", "numpy.expand_dims", "isinstance", "ma_policy.MAPolicy.act.preprocess_act_output"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.prepare_input", "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.policy_viewer.PolicyViewer.run"], ["", "def", "act", "(", "self", ",", "observation", ",", "extra_feed_dict", "=", "{", "}", ")", ":", "\n", "        ", "outputs", "=", "{", "\n", "'ac'", ":", "self", ".", "sampled_action", ",", "\n", "'ac_logp'", ":", "self", ".", "sampled_action_logp", ",", "\n", "'vpred'", ":", "self", ".", "scaled_value_tensor", ",", "\n", "'state'", ":", "self", ".", "state_out", "}", "\n", "# Add timestep dimension to observations", "\n", "obs", "=", "deepcopy", "(", "observation", ")", "\n", "n_agents", "=", "observation", "[", "'observation_self'", "]", ".", "shape", "[", "0", "]", "\n", "\n", "# Make sure that there are as many states as there are agents.", "\n", "# This should only happen with the zero state.", "\n", "for", "k", ",", "v", "in", "self", ".", "state", ".", "items", "(", ")", ":", "\n", "            ", "assert", "v", ".", "shape", "[", "0", "]", "==", "1", "or", "v", ".", "shape", "[", "0", "]", "==", "n_agents", "\n", "if", "v", ".", "shape", "[", "0", "]", "==", "1", "and", "v", ".", "shape", "[", "0", "]", "!=", "n_agents", ":", "\n", "                ", "self", ".", "state", "[", "k", "]", "=", "np", ".", "repeat", "(", "v", ",", "n_agents", ",", "0", ")", "\n", "\n", "# Add time dimension to obs", "\n", "", "", "for", "k", ",", "v", "in", "obs", ".", "items", "(", ")", ":", "\n", "            ", "obs", "[", "k", "]", "=", "np", ".", "expand_dims", "(", "v", ",", "1", ")", "\n", "", "inputs", "=", "self", ".", "prepare_input", "(", "observation", "=", "obs", ",", "state_in", "=", "self", ".", "state", ")", "\n", "feed_dict", "=", "{", "self", ".", "phs", "[", "k", "]", ":", "v", "for", "k", ",", "v", "in", "inputs", ".", "items", "(", ")", "}", "\n", "feed_dict", ".", "update", "(", "extra_feed_dict", ")", "\n", "\n", "outputs", "=", "tf", ".", "get_default_session", "(", ")", ".", "run", "(", "outputs", ",", "feed_dict", ")", "\n", "self", ".", "state", "=", "outputs", "[", "'state'", "]", "\n", "\n", "# Remove time dimension from outputs", "\n", "def", "preprocess_act_output", "(", "act_output", ")", ":", "\n", "            ", "if", "isinstance", "(", "act_output", ",", "dict", ")", ":", "\n", "                ", "return", "{", "k", ":", "np", ".", "squeeze", "(", "v", ",", "1", ")", "for", "k", ",", "v", "in", "act_output", ".", "items", "(", ")", "}", "\n", "", "else", ":", "\n", "                ", "return", "np", ".", "squeeze", "(", "act_output", ",", "1", ")", "\n", "\n", "", "", "info", "=", "{", "'vpred'", ":", "preprocess_act_output", "(", "outputs", "[", "'vpred'", "]", ")", ",", "\n", "'ac_logp'", ":", "preprocess_act_output", "(", "outputs", "[", "'ac_logp'", "]", ")", ",", "\n", "'state'", ":", "outputs", "[", "'state'", "]", "}", "\n", "\n", "return", "preprocess_act_output", "(", "outputs", "[", "'ac'", "]", ")", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.get_variables": [[318, 321], ["tensorflow.get_collection"], "methods", ["None"], ["", "def", "get_variables", "(", "self", ")", ":", "\n", "        ", "variables", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "full_scope_name", "+", "'/'", ")", "\n", "return", "variables", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.get_trainable_variables": [[322, 332], ["tensorflow.get_collection", "any", "any"], "methods", ["None"], ["", "def", "get_trainable_variables", "(", "self", ")", ":", "\n", "        ", "variables", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "self", ".", "full_scope_name", "+", "'/'", ")", "\n", "if", "self", ".", "trainable_vars", "is", "not", "None", ":", "\n", "            ", "variables", "=", "[", "v", "for", "v", "in", "variables", "\n", "if", "any", "(", "[", "tr_v", "in", "v", ".", "name", "for", "tr_v", "in", "self", ".", "trainable_vars", "]", ")", "]", "\n", "", "elif", "self", ".", "not_trainable_vars", "is", "not", "None", ":", "\n", "            ", "variables", "=", "[", "v", "for", "v", "in", "variables", "\n", "if", "not", "any", "(", "[", "tr_v", "in", "v", ".", "name", "for", "tr_v", "in", "self", ".", "not_trainable_vars", "]", ")", "]", "\n", "", "variables", "=", "[", "v", "for", "v", "in", "variables", "if", "'not_trainable'", "not", "in", "v", ".", "name", "]", "\n", "return", "variables", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.reset": [[333, 337], ["copy.deepcopy", "tensorflow.get_default_session", "tensorflow.get_default_session().run", "tensorflow.get_default_session"], "methods", ["home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.viewer.policy_viewer.PolicyViewer.run"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "state", "=", "deepcopy", "(", "self", ".", "zero_state", ")", "\n", "if", "tf", ".", "get_default_session", "(", ")", "is", "not", "None", ":", "\n", "            ", "tf", ".", "get_default_session", "(", ")", ".", "run", "(", "self", ".", "_reset_ops", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.set_state": [[338, 340], ["copy.deepcopy"], "methods", ["None"], ["", "", "def", "set_state", "(", "self", ",", "state", ")", ":", "\n", "        ", "self", ".", "state", "=", "deepcopy", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.auxiliary_losses": [[341, 344], ["None"], "methods", ["None"], ["", "def", "auxiliary_losses", "(", "self", ")", ":", "\n", "        ", "\"\"\" Any extra losses internal to the policy, automatically added to the total loss.\"\"\"", "\n", "return", "self", ".", "_auxiliary_losses", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.add_auxiliary_loss": [[345, 348], ["ma_policy.MAPolicy.training_stats.append", "ma_policy.MAPolicy._auxiliary_losses.append"], "methods", ["None"], ["", "def", "add_auxiliary_loss", "(", "self", ",", "name", ",", "loss", ")", ":", "\n", "        ", "self", ".", "training_stats", ".", "append", "(", "(", "name", ",", "'scalar'", ",", "loss", ",", "lambda", "x", ":", "x", ")", ")", "\n", "self", ".", "_auxiliary_losses", ".", "append", "(", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.openai_multi-agent-emergence-environments.ma_policy.ma_policy.MAPolicy.add_running_mean_std": [[349, 360], ["None"], "methods", ["None"], ["", "def", "add_running_mean_std", "(", "self", ",", "name", ",", "rms", ",", "axes", "=", "(", "0", ",", "1", ")", ")", ":", "\n", "        ", "\"\"\"\n        Add a RunningMeanStd/EMAMeanStd object to the policy's list. It will then get updated during optimization.\n        :param name: name of the input field to update from.\n        :param rms: RMS object to update.\n        :param axes: axes of the input to average over.\n            RMS's shape should be equal to input's shape after axes are removed.\n            e.g. if inputs is [5, 6, 7, 8] and axes is [0, 2], then RMS's shape should be [6, 8].\n        :return:\n        \"\"\"", "\n", "self", ".", "_running_mean_stds", "[", "name", "]", "=", "{", "'rms'", ":", "rms", ",", "'axes'", ":", "axes", "}", "\n", "", "", ""]]}