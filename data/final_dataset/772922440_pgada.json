{"home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.projector_SIMCLR.__init__": [[29, 36], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__"], ["def", "__init__", "(", "self", ",", "in_dim", ",", "out_dim", ")", ":", "\n", "        ", "super", "(", "projector_SIMCLR", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_dim", "=", "in_dim", "\n", "self", ".", "out_dim", "=", "out_dim", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "in_dim", ",", "in_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "in_dim", ",", "out_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.projector_SIMCLR.forward": [[37, 39], ["erm_training_steps.projector_SIMCLR.fc2", "torch.nn.functional.relu", "erm_training_steps.projector_SIMCLR.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "fc2", "(", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.get_few_shot_split": [[40, 66], ["configs.dataset_config.DATASET", "len", "configs.dataset_config.DATASET", "hasattr", "enumerate", "list", "list", "dataset_config.DATASET.id_to_class.keys", "dataset_config.DATASET.id_to_class.keys"], "function", ["None"], ["", "", "def", "get_few_shot_split", "(", "two_stream", "=", "False", ")", "->", "(", "Dataset", ",", "Dataset", ")", ":", "\n", "    ", "temp_train_set", "=", "dataset_config", ".", "DATASET", "(", "\n", "dataset_config", ".", "DATA_ROOT", ",", "\"train\"", ",", "dataset_config", ".", "IMAGE_SIZE", ",", "two_stream", "=", "two_stream", "\n", ")", "\n", "temp_train_classes", "=", "len", "(", "temp_train_set", ".", "id_to_class", ")", "\n", "temp_val_set", "=", "dataset_config", ".", "DATASET", "(", "\n", "dataset_config", ".", "DATA_ROOT", ",", "\n", "\"val\"", ",", "\n", "dataset_config", ".", "IMAGE_SIZE", ",", "\n", "target_transform", "=", "lambda", "label", ":", "label", "+", "temp_train_classes", ",", "\n", "two_stream", "=", "two_stream", "\n", ")", "\n", "if", "hasattr", "(", "dataset_config", ".", "DATASET", ",", "\"__name__\"", ")", ":", "\n", "        ", "if", "dataset_config", ".", "DATASET", ".", "__name__", "==", "\"CIFAR100CMeta\"", ":", "\n", "            ", "label_mapping", "=", "{", "\n", "v", ":", "k", "\n", "for", "k", ",", "v", "in", "enumerate", "(", "\n", "list", "(", "temp_train_set", ".", "id_to_class", ".", "keys", "(", ")", ")", "\n", "+", "list", "(", "temp_val_set", ".", "id_to_class", ".", "keys", "(", ")", ")", "\n", ")", "\n", "}", "\n", "temp_train_set", ".", "target_transform", "=", "(", "\n", "temp_val_set", ".", "target_transform", "\n", ")", "=", "lambda", "label", ":", "label_mapping", "[", "label", "]", "\n", "\n", "", "", "return", "temp_train_set", ",", "temp_val_set", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.get_non_few_shot_split": [[68, 85], ["torch.utils.data.ConcatDataset", "int", "torch.utils.data.random_split", "len", "torch.Generator().manual_seed", "len", "torch.Generator"], "function", ["None"], ["", "def", "get_non_few_shot_split", "(", "\n", "temp_train_set", ":", "Dataset", ",", "temp_val_set", ":", "Dataset", "\n", ")", "->", "(", "Subset", ",", "Subset", ")", ":", "\n", "    ", "train_and_val_set", "=", "ConcatDataset", "(", "\n", "[", "\n", "temp_train_set", ",", "\n", "temp_val_set", ",", "\n", "]", "\n", ")", "\n", "n_train_images", "=", "int", "(", "\n", "len", "(", "train_and_val_set", ")", "*", "erm_training_config", ".", "TRAIN_IMAGES_PROPORTION", "\n", ")", "\n", "return", "random_split", "(", "\n", "train_and_val_set", ",", "\n", "[", "n_train_images", ",", "len", "(", "train_and_val_set", ")", "-", "n_train_images", "]", ",", "\n", "generator", "=", "torch", ".", "Generator", "(", ")", ".", "manual_seed", "(", "\n", "erm_training_config", ".", "TRAIN_VAL_SPLIT_RANDOM_SEED", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.get_data": [[89, 130], ["loguru.logger.info", "src.utils.get_episodic_loader", "src.utils.get_episodic_loader", "len", "erm_training_steps.get_few_shot_split", "erm_training_steps.get_non_few_shot_split", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "len", "len"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.src.utils.get_episodic_loader", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.get_episodic_loader", "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.get_few_shot_split", "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.get_non_few_shot_split"], ["", "def", "get_data", "(", "two_stream", "=", "False", ")", "->", "(", "DataLoader", ",", "DataLoader", ",", "int", ")", ":", "# mix training and validation", "\n", "    ", "logger", ".", "info", "(", "\"Initializing data loaders...\"", ")", "\n", "\n", "if", "dataset_config", ".", "DATASET", ".", "__name__", "==", "\"FEMNIST\"", ":", "\n", "        ", "train_loader", ",", "train_set", "=", "get_episodic_loader", "(", "\n", "\"train\"", ",", "\n", "n_way", "=", "32", ",", "\n", "n_source", "=", "1", ",", "\n", "n_target", "=", "1", ",", "\n", "n_episodes", "=", "200", ",", "\n", ")", "\n", "val_loader", ",", "val_set", "=", "get_episodic_loader", "(", "\n", "\"val\"", ",", "\n", "n_way", "=", "training_config", ".", "N_WAY", ",", "\n", "n_source", "=", "training_config", ".", "N_SOURCE", ",", "\n", "n_target", "=", "training_config", ".", "N_TARGET", ",", "\n", "n_episodes", "=", "training_config", ".", "N_VAL_TASKS", ",", "\n", ")", "\n", "# Assume that train and val classes are entirely disjoints", "\n", "n_classes", "=", "len", "(", "train_set", ".", "id_to_class", ")", "\n", "\n", "", "else", ":", "\n", "        ", "temp_train_set", ",", "temp_val_set", "=", "get_few_shot_split", "(", "two_stream", ")", "\n", "\n", "train_set", ",", "val_set", "=", "get_non_few_shot_split", "(", "temp_train_set", ",", "temp_val_set", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "batch_size", "=", "erm_training_config", ".", "BATCH_SIZE", ",", "\n", "num_workers", "=", "erm_training_config", ".", "N_WORKERS", ",", "\n", "shuffle", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "batch_size", "=", "erm_training_config", ".", "BATCH_SIZE", ",", "\n", "num_workers", "=", "erm_training_config", ".", "N_WORKERS", ",", "\n", ")", "\n", "# Assume that train and val classes are entirely disjoints", "\n", "n_classes", "=", "len", "(", "temp_val_set", ".", "id_to_class", ")", "+", "len", "(", "temp_train_set", ".", "id_to_class", ")", "\n", "\n", "", "return", "train_loader", ",", "val_loader", ",", "n_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.get_model": [[132, 147], ["loguru.logger.info", "src.utils.set_device", "src.utils.set_device", "src.utils.set_device", "src.utils.set_device", "torch.nn.CrossEntropyLoss", "src.NTXentLoss.NTXentLoss", "configs.erm_training_config.OPTIMIZER", "configs.erm_training_config.OPTIMIZER", "configs.model_config.BACKBONE", "torch.nn.Linear", "configs.model_config.H", "erm_training_steps.projector_SIMCLR", "src.utils.set_device.H.parameters", "list", "list", "list", "src.utils.set_device.clf_SIMCLR.parameters", "src.utils.set_device.trunk.parameters", "src.utils.set_device.clf.parameters"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device"], ["", "def", "get_model", "(", "n_classes", ":", "int", ")", "->", "nn", ".", "Module", ":", "\n", "    ", "logger", ".", "info", "(", "f\"Initializing {model_config.BACKBONE.__name__}...\"", ")", "\n", "\n", "model", "=", "set_device", "(", "model_config", ".", "BACKBONE", "(", ")", ")", "\n", "\n", "model", ".", "clf", "=", "set_device", "(", "nn", ".", "Linear", "(", "model", ".", "final_feat_dim", ",", "n_classes", ")", ")", "\n", "model", ".", "H", "=", "set_device", "(", "model_config", ".", "H", "(", ")", ")", "\n", "model", ".", "clf_SIMCLR", "=", "set_device", "(", "projector_SIMCLR", "(", "model", ".", "final_feat_dim", ",", "erm_training_config", ".", "SIMCLR_projection_dim", ")", ")", "\n", "\n", "model", ".", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'mean'", ")", "# SY ADD", "\n", "model", ".", "loss_fn_SIMCLR", "=", "NTXentLoss", "(", "'cuda'", ",", "erm_training_config", ".", "BATCH_SIZE", ",", "erm_training_config", ".", "SIMCLR_temp", ",", "True", ")", "\n", "\n", "model", ".", "optimizer", "=", "erm_training_config", ".", "OPTIMIZER", "(", "list", "(", "model", ".", "trunk", ".", "parameters", "(", ")", ")", "+", "list", "(", "model", ".", "clf", ".", "parameters", "(", ")", ")", "+", "list", "(", "model", ".", "clf_SIMCLR", ".", "parameters", "(", ")", ")", ")", "\n", "model", ".", "optimizer_H", "=", "erm_training_config", ".", "OPTIMIZER", "(", "model", ".", "H", ".", "parameters", "(", ")", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.get_n_batches": [[149, 155], ["min", "len", "configs.erm_training_config.N_TRAINING_IMAGES_PER_EPOCH", "configs.erm_training_config.N_VAL_IMAGES_PER_EPOCH"], "function", ["None"], ["", "def", "get_n_batches", "(", "data_loader", ":", "DataLoader", ",", "n_images_per_epoch", ":", "int", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Computes the number of batches in a training epoch from the intended number of seen images.\n    \"\"\"", "\n", "\n", "return", "min", "(", "n_images_per_epoch", "//", "erm_training_config", ".", "BATCH_SIZE", ",", "len", "(", "data_loader", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.train": [[158, 247], ["torch.utils.tensorboard.SummaryWriter", "erm_training_steps.get_n_batches", "erm_training_steps.get_n_batches", "configs.dataset_config.DATASET", "configs.dataset_config.DATASET", "torch.randperm", "torch.utils.data.Subset", "torch.utils.data.Subset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "loguru.logger.info", "range", "len", "src.NTXentLoss.NTXentLoss", "src.NTXentLoss.NTXentLoss", "float", "erm_training_steps.training_epoch", "torch.utils.tensorboard.SummaryWriter.add_scalar", "int", "int", "len", "float", "loguru.logger.info", "erm_training_steps.validation", "torch.utils.tensorboard.SummaryWriter.add_scalar", "erm_training_steps.validation_acc", "torch.utils.tensorboard.SummaryWriter.add_scalar", "loguru.logger.info", "torch.save", "loguru.logger.info", "torch.save", "len", "len", "model.state_dict", "model.state_dict", "hasattr", "hasattr"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.get_n_batches", "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.get_n_batches", "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.training_epoch", "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.validation", "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.validation_acc"], ["", "def", "train", "(", "\n", "model", ":", "nn", ".", "Module", ",", "train_loader", ":", "DataLoader", ",", "val_loader", ":", "DataLoader", "\n", ")", "->", "(", "OrderedDict", ",", "int", ")", ":", "\n", "    ", "writer", "=", "SummaryWriter", "(", "log_dir", "=", "experiment_config", ".", "SAVE_DIR", ")", "\n", "n_training_batches", "=", "get_n_batches", "(", "\n", "train_loader", ",", "erm_training_config", ".", "N_TRAINING_IMAGES_PER_EPOCH", "\n", ")", "\n", "n_val_batches", "=", "get_n_batches", "(", "\n", "val_loader", ",", "erm_training_config", ".", "N_VAL_IMAGES_PER_EPOCH", "\n", ")", "\n", "\n", "test_set_temp1", "=", "dataset_config", ".", "DATASET", "(", "\n", "dataset_config", ".", "DATA_ROOT", ",", "\"test\"", ",", "dataset_config", ".", "IMAGE_SIZE", ",", "augmentation", "=", "True", ",", "two_stream", "=", "True", ",", "\n", ")", "\n", "test_set_temp2", "=", "dataset_config", ".", "DATASET", "(", "\n", "dataset_config", ".", "DATA_ROOT", ",", "\"test\"", ",", "dataset_config", ".", "IMAGE_SIZE", ",", "augmentation", "=", "True", ",", "two_stream", "=", "True", ",", "SIMCLR_val", "=", "True", "\n", ")", "\n", "\n", "ind", "=", "torch", ".", "randperm", "(", "len", "(", "test_set_temp1", ")", ")", "\n", "\n", "test_set_train_ind", "=", "ind", "[", ":", "int", "(", "0.9", "*", "len", "(", "ind", ")", ")", "]", "\n", "test_set_val_ind", "=", "ind", "[", "int", "(", "0.9", "*", "len", "(", "ind", ")", ")", ":", "]", "\n", "\n", "test_set_train", "=", "Subset", "(", "test_set_temp1", ",", "test_set_train_ind", ")", "\n", "test_set_val", "=", "Subset", "(", "test_set_temp2", ",", "test_set_val_ind", ")", "\n", "\n", "test_loader_train", "=", "DataLoader", "(", "\n", "test_set_train", ",", "\n", "batch_size", "=", "erm_training_config", ".", "BATCH_SIZE", ",", "\n", "num_workers", "=", "erm_training_config", ".", "N_WORKERS", ",", "\n", "shuffle", "=", "True", ",", "\n", ")", "\n", "\n", "test_loader_val", "=", "DataLoader", "(", "\n", "test_set_val", ",", "\n", "batch_size", "=", "erm_training_config", ".", "BATCH_SIZE", ",", "\n", "num_workers", "=", "erm_training_config", ".", "N_WORKERS", ",", "\n", "shuffle", "=", "False", ",", "\n", ")", "\n", "\n", "if", "erm_training_config", ".", "batch_validate", ":", "\n", "        ", "model", ".", "loss_fn_SIMCLR_val", "=", "NTXentLoss", "(", "'cuda'", ",", "erm_training_config", ".", "BATCH_SIZE", ",", "erm_training_config", ".", "SIMCLR_temp", ",", "True", ")", "\n", "", "else", ":", "\n", "        ", "model", ".", "loss_fn_SIMCLR_val", "=", "NTXentLoss", "(", "'cuda'", ",", "len", "(", "test_set_val", ")", ",", "erm_training_config", ".", "SIMCLR_temp", ",", "True", ")", "\n", "\n", "", "if", "erm_training_config", ".", "SIMCLR", ":", "\n", "        ", "min_val_loss", "=", "float", "(", "\"inf\"", ")", "\n", "", "else", ":", "\n", "        ", "max_val_acc", "=", "-", "float", "(", "\"inf\"", ")", "\n", "", "best_model_epoch", "=", "0", "\n", "logger", ".", "info", "(", "\"Model and data are ready. Starting training...\"", ")", "\n", "for", "epoch", "in", "range", "(", "erm_training_config", ".", "N_EPOCHS", ")", ":", "\n", "\n", "        ", "if", "epoch", ">", "best_model_epoch", "+", "10", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Training early stops.\"", ")", "\n", "return", "\n", "\n", "", "model", ",", "average_loss", "=", "training_epoch", "(", "\n", "model", ",", "train_loader", ",", "epoch", ",", "n_training_batches", ",", "test_loader_train", "\n", ")", "\n", "\n", "writer", ".", "add_scalar", "(", "\"Train/loss\"", ",", "average_loss", ",", "epoch", ")", "\n", "\n", "if", "erm_training_config", ".", "SIMCLR", ":", "\n", "            ", "val_loss", "=", "validation", "(", "model", ",", "val_loader", ",", "epoch", ",", "n_val_batches", ",", "test_loader_val", ")", "\n", "writer", ".", "add_scalar", "(", "\"Val/loss\"", ",", "val_loss", ",", "epoch", ")", "\n", "if", "val_loss", "<", "min_val_loss", ":", "\n", "                ", "min_val_loss", "=", "val_loss", "\n", "best_model_epoch", "=", "epoch", "\n", "logger", ".", "info", "(", "f\"Best model found at training epoch {best_model_epoch}.\"", ")", "\n", "state_dict_path", "=", "(", "\n", "experiment_config", ".", "SAVE_DIR", "\n", "/", "f\"{model_config.BACKBONE.__name__}_{dataset_config.DATASET.__name__ if hasattr(dataset_config.DATASET, '__name__') else dataset_config.DATASET.func.__name__}_{epoch}.tar\"", "\n", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "state_dict_path", ")", "\n", "", "", "else", ":", "\n", "            ", "val_acc", "=", "validation_acc", "(", "model", ",", "val_loader", ",", "epoch", ",", "n_val_batches", ",", "test_loader_val", ")", "\n", "writer", ".", "add_scalar", "(", "\"Val/acc\"", ",", "val_acc", ",", "epoch", ")", "\n", "if", "val_acc", ">", "max_val_acc", ":", "\n", "                ", "max_val_acc", "=", "val_acc", "\n", "best_model_epoch", "=", "epoch", "\n", "logger", ".", "info", "(", "f\"Best model found at training epoch {best_model_epoch} .\"", ")", "\n", "state_dict_path", "=", "(", "\n", "experiment_config", ".", "SAVE_DIR", "\n", "/", "f\"{model_config.BACKBONE.__name__}_{dataset_config.DATASET.__name__ if hasattr(dataset_config.DATASET, '__name__') else dataset_config.DATASET.func.__name__}_{epoch}.tar\"", "\n", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "state_dict_path", ")", "\n", "\n", "", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.training_epoch": [[248, 280], ["model.train", "print", "zip", "zip", "range", "torch.as_tensor", "erm_training_steps.fit", "loss_clf_list.append", "loss_cos_list.append", "print", "range", "erm_training_steps.fit", "loss_clf_list.append", "loss_cos_list.append", "print", "numpy.asarray().mean", "numpy.asarray().mean", "src.utils.set_device", "src.utils.set_device", "src.utils.set_device", "src.utils.set_device", "src.utils.set_device", "src.utils.set_device", "src.utils.set_device", "src.utils.set_device", "src.utils.set_device", "src.utils.set_device", "numpy.asarray", "numpy.asarray", "numpy.asarray().mean", "numpy.asarray().mean", "numpy.asarray().mean", "numpy.asarray().mean", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.train", "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.fit", "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.fit", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device"], ["", "def", "training_epoch", "(", "\n", "model", ":", "nn", ".", "Module", ",", "data_loader", ":", "DataLoader", ",", "epoch", ":", "int", ",", "n_batches", ":", "int", ",", "test_loader_train", ":", "DataLoader", "\n", ")", "->", "(", "nn", ".", "Module", ",", "float", ")", ":", "\n", "    ", "loss_clf_list", "=", "[", "]", "\n", "loss_cos_list", "=", "[", "]", "\n", "model", ".", "train", "(", ")", "\n", "\n", "if", "dataset_config", ".", "DATASET", ".", "__name__", "==", "\"FEMNIST\"", ":", "\n", "        ", "for", "batch_id", ",", "(", "support_images", ",", "\n", "support_labels", ",", "\n", "query_images", ",", "\n", "query_labels", ",", "\n", "class_ids", ",", "\n", "source_domain", ",", "\n", "target_domain", ",", ")", ",", "(", "test_img1", ",", "test_img2", ",", "_", ",", "_", ")", "in", "zip", "(", "range", "(", "n_batches", ")", ",", "data_loader", ",", "test_loader_train", ")", ":", "\n", "            ", "labels", "=", "torch", ".", "as_tensor", "(", "[", "class_ids", "[", "i", "]", "for", "i", "in", "support_labels", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "model", ",", "loss_clf", ",", "loss_cos", "=", "fit", "(", "model", ",", "set_device", "(", "support_images", ")", ",", "set_device", "(", "query_images", ")", ",", "set_device", "(", "labels", ")", ",", "set_device", "(", "test_img1", ")", ",", "set_device", "(", "test_img2", ")", ")", "\n", "\n", "loss_clf_list", ".", "append", "(", "loss_clf", ")", "\n", "loss_cos_list", ".", "append", "(", "loss_cos", ")", "\n", "\n", "print", "(", "f\"epoch {epoch} [{batch_id+1:03d}/{n_batches}]: clf loss={np.asarray(loss_clf_list).mean():.3f}, cos loss={np.asarray(loss_cos_list).mean():.3f}\"", ",", "end", "=", "\"     \\r\"", ")", "\n", "", "", "else", ":", "\n", "        ", "for", "batch_id", ",", "(", "images", ",", "images_perturbation", ",", "labels", ",", "_", ")", ",", "(", "test_img1", ",", "test_img2", ",", "_", ",", "_", ")", "in", "zip", "(", "range", "(", "n_batches", ")", ",", "data_loader", ",", "test_loader_train", ")", ":", "\n", "            ", "model", ",", "loss_clf", ",", "loss_cos", "=", "fit", "(", "model", ",", "set_device", "(", "images", ")", ",", "set_device", "(", "images_perturbation", ")", ",", "set_device", "(", "labels", ")", ",", "set_device", "(", "test_img1", ")", ",", "set_device", "(", "test_img2", ")", ")", "\n", "\n", "loss_clf_list", ".", "append", "(", "loss_clf", ")", "\n", "loss_cos_list", ".", "append", "(", "loss_cos", ")", "\n", "\n", "print", "(", "f\"epoch {epoch} [{batch_id+1:04d}/{n_batches}]: clf loss={np.asarray(loss_clf_list).mean():.3f}, cos loss={np.asarray(loss_cos_list).mean():.3f}\"", ",", "end", "=", "\"     \\r\"", ")", "\n", "", "", "print", "(", ")", "\n", "return", "model", ",", "np", ".", "asarray", "(", "loss_clf_list", ")", ".", "mean", "(", ")", "+", "np", ".", "asarray", "(", "loss_cos_list", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.fit": [[281, 321], ["model.optimizer_H.zero_grad", "model.H.eval", "model.trunk", "model.trunk", "torch.nn.functional.cosine_similarity().mean", "model.clf", "model.loss_fn", "loss_H.backward", "model.optimizer_H.step", "model.optimizer.zero_grad", "model.H.train", "model.clf", "model.clf", "loss_M_clf.backward", "model.optimizer.step", "model.H", "torch.no_grad", "model.H", "model.trunk", "model.trunk", "model.loss_fn", "model.loss_fn", "model.clf_SIMCLR", "model.clf_SIMCLR", "model.loss_fn_SIMCLR", "loss_M_clf.item", "F.cosine_similarity().mean.item", "torch.nn.functional.cosine_similarity", "model.trunk", "model.trunk"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.train"], ["", "def", "fit", "(", "\n", "model", ":", "nn", ".", "Module", ",", "images", ":", "torch", ".", "Tensor", ",", "images_perturbation", ":", "torch", ".", "Tensor", ",", "\n", "labels", ":", "torch", ".", "Tensor", ",", "test_img1", ":", "torch", ".", "Tensor", ",", "test_img2", ":", "torch", ".", "Tensor", "\n", ")", "->", "(", "nn", ".", "Module", ",", "float", ")", ":", "\n", "\n", "#train H", "\n", "    ", "model", ".", "optimizer_H", ".", "zero_grad", "(", ")", "\n", "model", ".", "H", ".", "eval", "(", ")", "\n", "f_H", "=", "model", ".", "trunk", "(", "model", ".", "H", "(", "images", ")", ")", "\n", "f_perturbation", "=", "model", ".", "trunk", "(", "images_perturbation", ")", "\n", "# f_H_norm = f_H / f_H.norm(dim=1)[:, None]", "\n", "# f_perturbation_norm = f_perturbation / f_perturbation.norm(dim=1)[:, None]    ", "\n", "# loss_cos_similarity = torch.mm(f_H_norm, f_perturbation_norm.transpose(0,1)).mean()", "\n", "loss_cos_similarity", "=", "F", ".", "cosine_similarity", "(", "f_H", ",", "f_perturbation", ")", ".", "mean", "(", ")", "\n", "out", "=", "model", ".", "clf", "(", "f_H", ")", "\n", "loss_clf", "=", "model", ".", "loss_fn", "(", "out", ",", "labels", ")", "\n", "loss_H", "=", "loss_clf", "+", "loss_cos_similarity", "\n", "# loss_H = loss_cos_similarity", "\n", "loss_H", ".", "backward", "(", ")", "\n", "model", ".", "optimizer_H", ".", "step", "(", ")", "\n", "\n", "#train M, clf", "\n", "model", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "model", ".", "H", ".", "train", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "images_H", "=", "model", ".", "H", "(", "images", ")", "\n", "", "out", "=", "model", ".", "clf", "(", "model", ".", "trunk", "(", "images_H", ")", ")", "\n", "out_p", "=", "model", ".", "clf", "(", "model", ".", "trunk", "(", "images_perturbation", ")", ")", "\n", "loss_CE", "=", "model", ".", "loss_fn", "(", "out", ",", "labels", ")", "+", "model", ".", "loss_fn", "(", "out_p", ",", "labels", ")", "\n", "if", "erm_training_config", ".", "SIMCLR", ":", "\n", "        ", "z1", "=", "model", ".", "clf_SIMCLR", "(", "model", ".", "trunk", "(", "test_img1", ")", ")", "\n", "z2", "=", "model", ".", "clf_SIMCLR", "(", "model", ".", "trunk", "(", "test_img2", ")", ")", "\n", "loss_SIMCLR", "=", "model", ".", "loss_fn_SIMCLR", "(", "z1", ",", "z2", ")", "\n", "loss_M_clf", "=", "loss_CE", "+", "loss_SIMCLR", "\n", "", "else", ":", "\n", "        ", "loss_M_clf", "=", "loss_CE", "\n", "", "loss_M_clf", ".", "backward", "(", ")", "\n", "model", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "return", "model", ",", "loss_M_clf", ".", "item", "(", ")", ",", "loss_cos_similarity", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.validation": [[322, 376], ["model.eval", "print", "torch.no_grad", "zip", "torch.stack().mean", "torch.cat", "torch.cat", "model.loss_fn_SIMCLR_val", "src.utils.set_device", "src.utils.set_device.eval", "range", "src.utils.set_device", "src.utils.set_device", "model.clf_SIMCLR", "model.clf_SIMCLR", "configs.model_config.MODEL", "torch.no_grad", "src.utils.set_device.eval_loop", "torch.no_grad", "zip", "model.trunk", "model.trunk", "torch.cat.append", "torch.cat.append", "torch.stack", "range", "src.utils.set_device", "src.utils.set_device", "model.clf", "model.loss_fn", "len", "src.NTXentLoss.NTXentLoss", "losses_SIMCLR.append", "losses_SIMCLR.append", "model.trunk", "len", "src.NTXentLoss.NTXentLoss.", "model.loss_fn_SIMCLR_val"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.eval_loop", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device"], ["", "def", "validation", "(", "\n", "model", ":", "nn", ".", "Module", ",", "data_loader", ":", "DataLoader", ",", "epoch", ":", "int", ",", "n_batches", ":", "int", ",", "test_loader_val", ":", "DataLoader", "\n", ")", "->", "float", ":", "\n", "\n", "    ", "if", "erm_training_config", ".", "batch_validate", ":", "\n", "        ", "losses_SIMCLR", "=", "[", "]", "\n", "", "else", ":", "\n", "        ", "z1s", "=", "[", "]", "\n", "z2s", "=", "[", "]", "\n", "\n", "", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch_id", ",", "(", "test_img1", ",", "test_img2", ",", "_", ",", "_", ")", "in", "zip", "(", "range", "(", "n_batches", ")", ",", "test_loader_val", ")", ":", "\n", "            ", "test_img1", "=", "set_device", "(", "test_img1", ")", "\n", "test_img2", "=", "set_device", "(", "test_img2", ")", "\n", "\n", "z1", "=", "model", ".", "clf_SIMCLR", "(", "model", ".", "trunk", "(", "test_img1", ")", ")", "\n", "z2", "=", "model", ".", "clf_SIMCLR", "(", "model", ".", "trunk", "(", "test_img2", ")", ")", "\n", "\n", "if", "erm_training_config", ".", "batch_validate", ":", "\n", "                ", "if", "len", "(", "test_img1", ")", "!=", "erm_training_config", ".", "BATCH_SIZE", ":", "\n", "                    ", "criterion_small_set", "=", "NTXentLoss", "(", "\n", "'cuda'", ",", "len", "(", "test_img1", ")", ",", "erm_training_config", ".", "SIMCLR_temp", ",", "True", ")", "\n", "losses_SIMCLR", ".", "append", "(", "criterion_small_set", "(", "z1", ",", "z2", ")", ")", "\n", "", "else", ":", "\n", "                    ", "losses_SIMCLR", ".", "append", "(", "model", ".", "loss_fn_SIMCLR_val", "(", "z1", ",", "z2", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "z1s", ".", "append", "(", "z1", ")", "\n", "z2s", ".", "append", "(", "z2", ")", "\n", "\n", "", "", "", "if", "erm_training_config", ".", "batch_validate", ":", "\n", "        ", "loss_SIMCLR", "=", "torch", ".", "stack", "(", "losses_SIMCLR", ")", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "        ", "z1s", "=", "torch", ".", "cat", "(", "z1s", ",", "dim", "=", "0", ")", "\n", "z2s", "=", "torch", ".", "cat", "(", "z2s", ",", "dim", "=", "0", ")", "\n", "loss_SIMCLR", "=", "model", ".", "loss_fn_SIMCLR_val", "(", "z1s", ",", "z2s", ")", "\n", "\n", "", "if", "dataset_config", ".", "DATASET", ".", "__name__", "==", "\"FEMNIST\"", ":", "\n", "        ", "val_model", "=", "set_device", "(", "model_config", ".", "MODEL", "(", "model_config", ".", "BACKBONE", ")", ")", "\n", "val_model", ".", "feature", "=", "model", "\n", "val_model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "loss", ",", "acc", ",", "stats_df", "=", "val_model", ".", "eval_loop", "(", "data_loader", ")", "\n", "", "", "else", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch_id", ",", "(", "images", ",", "images_perturbation", ",", "labels", ",", "_", ")", "in", "zip", "(", "range", "(", "n_batches", ")", ",", "data_loader", ")", ":", "\n", "                ", "images_perturbation", "=", "set_device", "(", "images_perturbation", ")", "\n", "labels", "=", "set_device", "(", "labels", ")", "\n", "\n", "out_p", "=", "model", ".", "clf", "(", "model", ".", "trunk", "(", "images_perturbation", ")", ")", "\n", "loss", "=", "model", ".", "loss_fn", "(", "out_p", ",", "labels", ")", "\n", "\n", "", "", "", "print", "(", "f\"epoch {epoch} : loss={loss+loss_SIMCLR:.3f}\"", ")", "\n", "return", "loss", "+", "loss_SIMCLR", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.validation_acc": [[377, 402], ["src.utils.set_device", "src.utils.set_device.eval", "src.utils.set_device.eval_loop", "model.eval", "print", "numpy.asarray().mean", "configs.model_config.MODEL", "torch.no_grad", "zip", "range", "val_acc_list.append", "print", "numpy.asarray", "float", "len", "numpy.asarray().mean", "numpy.asarray", "src.utils.set_device", "model.clf().data.topk", "model.clf", "model.trunk", "src.utils.set_device"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.eval_loop", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device"], ["", "def", "validation_acc", "(", "model", ":", "nn", ".", "Module", ",", "data_loader", ":", "DataLoader", ",", "epoch", ":", "int", ",", "n_batches", ":", "int", ",", "test_loader_val", ":", "DataLoader", ")", "->", "float", ":", "\n", "    ", "if", "dataset_config", ".", "DATASET", ".", "__name__", "==", "\"FEMNIST\"", ":", "\n", "        ", "val_model", "=", "set_device", "(", "model_config", ".", "MODEL", "(", "model_config", ".", "BACKBONE", ")", ")", "\n", "val_model", ".", "feature", "=", "model", "\n", "val_model", ".", "eval", "(", ")", "\n", "loss", ",", "acc", ",", "stats_df", "=", "val_model", ".", "eval_loop", "(", "data_loader", ")", "\n", "\n", "return", "acc", "\n", "", "else", ":", "\n", "        ", "val_acc_list", "=", "[", "]", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch_id", ",", "(", "images", ",", "images_perturbation", ",", "labels", ",", "_", ")", "in", "zip", "(", "range", "(", "n_batches", ")", ",", "data_loader", ")", ":", "\n", "                    ", "val_acc_list", ".", "append", "(", "\n", "float", "(", "\n", "(", "\n", "model", ".", "clf", "(", "model", ".", "trunk", "(", "set_device", "(", "images_perturbation", ")", ")", ")", ".", "data", ".", "topk", "(", "1", ",", "1", ",", "True", ",", "True", ")", "[", "1", "]", "[", ":", ",", "0", "]", "\n", "==", "set_device", "(", "labels", ")", "\n", ")", ".", "sum", "(", ")", "\n", ")", "\n", "/", "len", "(", "labels", ")", "\n", ")", "\n", "print", "(", "f\"validation [{batch_id+1:03d}/{n_batches}]: acc={np.asarray(val_acc_list).mean():.3f}\"", ",", "end", "=", "\"     \\r\"", ")", "\n", "", "", "print", "(", ")", "\n", "return", "np", ".", "asarray", "(", "val_acc_list", ")", ".", "mean", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.src.running_steps.prepare_output": [[27, 48], ["configs.experiment_config.SAVE_DIR.mkdir", "loguru.logger.add", "distutils.dir_util.copy_tree", "loguru.logger.info", "loguru.logger.info", "configs.experiment_config.SAVE_DIR.exists", "shutil.rmtree", "loguru.logger.info", "str", "str"], "function", ["None"], ["def", "prepare_output", "(", ")", ":", "\n", "    ", "if", "experiment_config", ".", "SAVE_RESULTS", ":", "\n", "        ", "if", "experiment_config", ".", "OVERWRITE", "&", "experiment_config", ".", "SAVE_DIR", ".", "exists", "(", ")", ":", "\n", "            ", "rmtree", "(", "str", "(", "experiment_config", ".", "SAVE_DIR", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"Deleting previous content of {directory}\"", ",", "\n", "directory", "=", "experiment_config", ".", "SAVE_DIR", ",", "\n", ")", "\n", "\n", "", "experiment_config", ".", "SAVE_DIR", ".", "mkdir", "(", "\n", "parents", "=", "True", ",", "exist_ok", "=", "experiment_config", ".", "USE_POLYAXON", "\n", ")", "\n", "logger", ".", "add", "(", "experiment_config", ".", "SAVE_DIR", "/", "\"running.log\"", ")", "\n", "copy_tree", "(", "\"configs\"", ",", "str", "(", "experiment_config", ".", "SAVE_DIR", "/", "\"experiment_parameters\"", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"Parameters and outputs of this experiment will be saved in {directory}\"", ",", "\n", "directory", "=", "experiment_config", ".", "SAVE_DIR", ",", "\n", ")", "\n", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"This experiment will not be saved on disk.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.running_steps.set_and_print_random_seed": [[50, 69], ["numpy.random.seed", "torch.manual_seed", "random.seed", "loguru.logger.info", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint"], "function", ["None"], ["", "", "def", "set_and_print_random_seed", "(", ")", ":", "\n", "    ", "\"\"\"\n    Set and print numpy random seed, for reproducibility of the training,\n    and set torch seed based on numpy random seed\n    Returns:\n        int: numpy random seed\n\n    \"\"\"", "\n", "random_seed", "=", "experiment_config", ".", "RANDOM_SEED", "\n", "if", "not", "random_seed", ":", "\n", "        ", "random_seed", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "2", "**", "32", "-", "1", ")", "\n", "", "np", ".", "random", ".", "seed", "(", "random_seed", ")", "\n", "torch", ".", "manual_seed", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "2", "**", "32", "-", "1", ")", ")", "\n", "random", ".", "seed", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "2", "**", "32", "-", "1", ")", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "logger", ".", "info", "(", "f\"Random seed : {random_seed}\"", ")", "\n", "\n", "return", "random_seed", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.running_steps.train_model": [[71, 146], ["loguru.logger.info", "src.utils.get_episodic_loader", "src.utils.get_episodic_loader", "loguru.logger.info", "src.utils.set_device", "configs.training_config.OPTIMIZER", "torch.utils.tensorboard.SummaryWriter", "loguru.logger.info", "range", "loguru.logger.info", "loguru.logger.info", "src.utils.set_device.load_state_dict", "loguru.logger.info", "torch.utils.tensorboard.SummaryWriter.close", "src.utils.get_episodic_loader", "configs.model_config.MODEL", "src.utils.set_device.parameters", "src.utils.set_device.train", "src.utils.set_device.train_loop", "torch.utils.tensorboard.SummaryWriter.add_scalar", "torch.utils.tensorboard.SummaryWriter.add_scalar", "src.utils.set_device.eval", "src.utils.set_device.eval_loop", "torch.utils.tensorboard.SummaryWriter.add_scalar", "torch.utils.tensorboard.SummaryWriter.add_scalar", "src.utils.set_device.state_dict", "torch.save", "loguru.logger.info", "src.utils.set_device.eval_loop", "torch.utils.tensorboard.SummaryWriter.add_scalar"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.src.utils.get_episodic_loader", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.get_episodic_loader", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.get_episodic_loader", "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.train", "home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.train_loop", "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.eval_loop", "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.eval_loop"], ["", "def", "train_model", "(", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"Initializing data loaders...\"", ")", "\n", "train_loader", ",", "_", "=", "get_episodic_loader", "(", "\n", "\"train\"", ",", "\n", "n_way", "=", "training_config", ".", "N_WAY", ",", "\n", "n_source", "=", "training_config", ".", "N_SOURCE", ",", "\n", "n_target", "=", "training_config", ".", "N_TARGET", ",", "\n", "n_episodes", "=", "training_config", ".", "N_EPISODES", ",", "\n", ")", "\n", "val_loader", ",", "_", "=", "get_episodic_loader", "(", "\n", "\"val\"", ",", "\n", "n_way", "=", "training_config", ".", "N_WAY", ",", "\n", "n_source", "=", "training_config", ".", "N_SOURCE", ",", "\n", "n_target", "=", "training_config", ".", "N_TARGET", ",", "\n", "n_episodes", "=", "training_config", ".", "N_VAL_TASKS", ",", "\n", ")", "\n", "if", "training_config", ".", "TEST_SET_VALIDATION_FREQUENCY", ":", "\n", "        ", "test_loader", ",", "_", "=", "get_episodic_loader", "(", "\n", "\"test\"", ",", "\n", "n_way", "=", "training_config", ".", "N_WAY", ",", "\n", "n_source", "=", "training_config", ".", "N_SOURCE", ",", "\n", "n_target", "=", "training_config", ".", "N_TARGET", ",", "\n", "n_episodes", "=", "training_config", ".", "N_VAL_TASKS", ",", "\n", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Initializing model...\"", ")", "\n", "\n", "model", "=", "set_device", "(", "model_config", ".", "MODEL", "(", "model_config", ".", "BACKBONE", ")", ")", "\n", "optimizer", "=", "training_config", ".", "OPTIMIZER", "(", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "max_acc", "=", "-", "1.0", "\n", "best_model_epoch", "=", "-", "1", "\n", "best_model_state", "=", "None", "\n", "\n", "writer", "=", "SummaryWriter", "(", "log_dir", "=", "experiment_config", ".", "SAVE_DIR", ")", "\n", "\n", "logger", ".", "info", "(", "\"Model and data are ready. Starting training...\"", ")", "\n", "for", "epoch", "in", "range", "(", "training_config", ".", "N_EPOCHS", ")", ":", "#SY: seeing the batch size", "\n", "# Set model to training mode", "\n", "        ", "model", ".", "train", "(", ")", "\n", "# Execute a training loop of the model", "\n", "train_loss", ",", "train_acc", "=", "model", ".", "train_loop", "(", "epoch", ",", "train_loader", ",", "optimizer", ")", "\n", "writer", ".", "add_scalar", "(", "\"Train/loss\"", ",", "train_loss", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "\"Train/acc\"", ",", "train_acc", ",", "epoch", ")", "\n", "# Set model to evaluation mode", "\n", "model", ".", "eval", "(", ")", "\n", "# Evaluate on validation set", "\n", "val_loss", ",", "val_acc", ",", "_", "=", "model", ".", "eval_loop", "(", "val_loader", ")", "\n", "writer", ".", "add_scalar", "(", "\"Val/loss\"", ",", "val_loss", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "\"Val/acc\"", ",", "val_acc", ",", "epoch", ")", "\n", "\n", "# We make sure the best model is saved on disk, in case the training breaks", "\n", "if", "val_acc", ">", "max_acc", ":", "\n", "            ", "max_acc", "=", "val_acc", "\n", "best_model_epoch", "=", "epoch", "\n", "best_model_state", "=", "model", ".", "state_dict", "(", ")", "\n", "torch", ".", "save", "(", "best_model_state", ",", "experiment_config", ".", "SAVE_DIR", "/", "\"best_model.tar\"", ")", "\n", "\n", "", "if", "training_config", ".", "TEST_SET_VALIDATION_FREQUENCY", ":", "\n", "            ", "if", "(", "\n", "epoch", "%", "training_config", ".", "TEST_SET_VALIDATION_FREQUENCY", "\n", "==", "training_config", ".", "TEST_SET_VALIDATION_FREQUENCY", "-", "1", "\n", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\"Validating on test set...\"", ")", "\n", "_", ",", "test_acc", ",", "_", "=", "model", ".", "eval_loop", "(", "test_loader", ")", "\n", "writer", ".", "add_scalar", "(", "\"Test/acc\"", ",", "test_acc", ",", "epoch", ")", "\n", "\n", "", "", "", "logger", ".", "info", "(", "f\"Training over after {training_config.N_EPOCHS} epochs\"", ")", "\n", "logger", ".", "info", "(", "\"Retrieving model with best validation accuracy...\"", ")", "\n", "model", ".", "load_state_dict", "(", "best_model_state", ")", "\n", "logger", ".", "info", "(", "f\"Retrieved model from epoch {best_model_epoch}\"", ")", "\n", "\n", "writer", ".", "close", "(", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.running_steps.load_model_episodic": [[148, 151], ["model.load_state_dict"], "function", ["None"], ["", "def", "load_model_episodic", "(", "model", ":", "nn", ".", "Module", ",", "state_dict", ":", "OrderedDict", ")", "->", "nn", ".", "Module", ":", "# episodic ", "\n", "    ", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.running_steps.load_model_non_episodic": [[153, 187], ["list", "enumerate", "model.feature.load_state_dict", "src.utils.set_device", "state_dict.keys", "torch.nn.Linear", "key.replace", "state_dict.pop", "collections.OrderedDict", "collections.OrderedDict", "state_dict.items", "state_dict.items"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device"], ["", "def", "load_model_non_episodic", "(", "\n", "model", ":", "nn", ".", "Module", ",", "state_dict", ":", "OrderedDict", ",", "use_fc", ":", "bool", "\n", ")", "->", "nn", ".", "Module", ":", "\n", "    ", "if", "use_fc", ":", "\n", "# model.feature.clf = set_device(", "\n", "#     nn.Linear(", "\n", "#         model.feature.final_feat_dim,", "\n", "#         dataset_config.CLASSES[\"train\"] + dataset_config.CLASSES[\"val\"],", "\n", "#     )", "\n", "# )", "\n", "        ", "model", ".", "feature", ".", "trunk", ".", "fc", "=", "set_device", "(", "\n", "nn", ".", "Linear", "(", "\n", "model", ".", "feature", ".", "final_feat_dim", ",", "\n", "dataset_config", ".", "CLASSES", "[", "\"train\"", "]", "+", "dataset_config", ".", "CLASSES", "[", "\"val\"", "]", ",", "\n", ")", "\n", ")", "\n", "", "state_keys", "=", "list", "(", "state_dict", ".", "keys", "(", ")", ")", "\n", "for", "_", ",", "key", "in", "enumerate", "(", "state_keys", ")", ":", "\n", "        ", "if", "\"clf.\"", "in", "key", ":", "\n", "            ", "newkey", "=", "key", ".", "replace", "(", "\"clf.\"", ",", "\"trunk.fc.\"", ")", "\n", "state_dict", "[", "newkey", "]", "=", "state_dict", ".", "pop", "(", "key", ")", "\n", "\n", "", "", "model", ".", "feature", ".", "load_state_dict", "(", "\n", "OrderedDict", "(", "[", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", "if", "\"H.\"", "not", "in", "k", "]", ")", "\n", "if", "use_fc", "\n", "else", "OrderedDict", "(", "[", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", "if", "\"fc\"", "not", "in", "k", "and", "\"H.\"", "not", "in", "k", "]", ")", "\n", ")", "\n", "\n", "# model.feature.load_state_dict(", "\n", "#     state_dict", "\n", "#     if use_fc", "\n", "#     else OrderedDict([(k, v) for k, v in state_dict.items() if \".fc.\" not in k])", "\n", "# )", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.running_steps.load_model": [[189, 209], ["src.utils.set_device", "torch.load", "loguru.logger.info", "configs.model_config.MODEL", "loguru.logger.info", "running_steps.load_model_episodic", "running_steps.load_model_non_episodic"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.running_steps.load_model_episodic", "home.repos.pwc.inspect_result.772922440_pgada.src.running_steps.load_model_non_episodic"], ["", "def", "load_model", "(", "\n", "state_path", ":", "Path", ",", "episodic", ":", "bool", ",", "use_fc", ":", "bool", ",", "force_ot", ":", "bool", "\n", ")", "->", "nn", ".", "Module", ":", "\n", "    ", "model", "=", "set_device", "(", "model_config", ".", "MODEL", "(", "model_config", ".", "BACKBONE", ")", ")", "\n", "\n", "if", "force_ot", ":", "\n", "        ", "model", ".", "transportation_module", "=", "model_config", ".", "TRANSPORTATION_MODULE", "\n", "logger", ".", "info", "(", "\"Forced the Optimal Transport module into the model.\"", ")", "\n", "\n", "", "state_dict", "=", "torch", ".", "load", "(", "state_path", ")", "\n", "model", "=", "(", "\n", "load_model_episodic", "(", "model", ",", "state_dict", ")", "\n", "if", "episodic", "\n", "else", "\n", "load_model_non_episodic", "(", "model", ",", "state_dict", ",", "use_fc", ")", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "f\"Loaded model from {state_path}\"", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.running_steps.eval_model": [[211, 233], ["loguru.logger.info", "src.utils.get_episodic_loader", "loguru.logger.info", "model.eval", "model.eval_loop", "src.utils.elucidate_ids", "src.utils.elucidate_ids.to_csv", "torch.utils.tensorboard.SummaryWriter", "torch.utils.tensorboard.SummaryWriter.add_scalar", "torch.utils.tensorboard.SummaryWriter.close"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.src.utils.get_episodic_loader", "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.eval_loop", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.elucidate_ids"], ["", "def", "eval_model", "(", "model", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"Initializing test data...\"", ")", "\n", "test_loader", ",", "test_dataset", "=", "get_episodic_loader", "(", "\n", "\"test\"", ",", "\n", "n_way", "=", "configs", ".", "evaluation_config", ".", "N_WAY_EVAL", ",", "\n", "n_source", "=", "configs", ".", "evaluation_config", ".", "N_SOURCE_EVAL", ",", "\n", "n_target", "=", "configs", ".", "evaluation_config", ".", "N_TARGET_EVAL", ",", "\n", "n_episodes", "=", "configs", ".", "evaluation_config", ".", "N_TASKS_EVAL", ",", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\"Starting model evaluation...\"", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "_", ",", "acc", ",", "stats_df", "=", "model", ".", "eval_loop", "(", "test_loader", ")", "\n", "\n", "stats_df", "=", "elucidate_ids", "(", "stats_df", ",", "test_dataset", ")", "\n", "\n", "stats_df", ".", "to_csv", "(", "experiment_config", ".", "SAVE_DIR", "/", "\"evaluation_stats.csv\"", ",", "index", "=", "False", ")", "\n", "writer", "=", "SummaryWriter", "(", "log_dir", "=", "experiment_config", ".", "SAVE_DIR", ")", "\n", "writer", ".", "add_scalar", "(", "\"Evaluation accuracy\"", ",", "acc", ")", "\n", "writer", ".", "close", "(", ")", "\n", "return", "acc", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.src.training_statistics.TrainingStatistics.__init__": [[8, 22], ["len", "pandas.DataFrame", "pandas.DataFrame", "numpy.zeros"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            dataset (SetDataset): a set dataset on which we compute the statistics of meta-training\n        \"\"\"", "\n", "\n", "n_classes", "=", "len", "(", "dataset", ")", "\n", "self", ".", "confusion_matrix", "=", "pd", ".", "DataFrame", "(", "\n", "np", ".", "zeros", "(", "(", "n_classes", ",", "n_classes", ")", ")", ",", "\n", "index", "=", "dataset", ".", "label_list", ",", "\n", "columns", "=", "dataset", ".", "label_list", ",", "\n", ")", "\n", "self", ".", "label_count", "=", "pd", ".", "DataFrame", "(", "index", "=", "dataset", ".", "label_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.training_statistics.TrainingStatistics.update": [[23, 34], ["training_statistics.TrainingStatistics.update_confusion", "training_statistics.TrainingStatistics.update_label_count"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.src.training_statistics.TrainingStatistics.update_confusion", "home.repos.pwc.inspect_result.772922440_pgada.src.training_statistics.TrainingStatistics.update_label_count"], ["", "def", "update", "(", "self", ",", "prediction_scores", ",", "true_class_ids", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Update the training statistics based on the classifications from one episode.\n        Args:\n            prediction_scores (torch.Tensor): shape(n_query*n_way, n_way), classification prediction for each query data\n            true_class_ids (list): value of index i is the true class id corresponding to artificial label i\n            epoch (int): current epoch\n\n        \"\"\"", "\n", "self", ".", "update_confusion", "(", "prediction_scores", ",", "true_class_ids", ")", "\n", "self", ".", "update_label_count", "(", "true_class_ids", ",", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.training_statistics.TrainingStatistics.update_confusion": [[35, 56], ["len", "isinstance", "torch.from_numpy", "torch.argmax", "sklearn.metrics.confusion_matrix", "enumerate", "prediction_scores.size", "numpy.repeat", "prediction_scores.cpu", "enumerate", "range"], "methods", ["None"], ["", "def", "update_confusion", "(", "self", ",", "prediction_scores", ",", "true_labels", ")", ":", "\n", "        ", "\"\"\"\n        Update the confusion matrix based on the classifications from one episode.\n        Args:\n            prediction_scores (torch.Tensor): shape(n_query*n_way, n_way), classification prediction for each query data\n            true_labels (list[int]): list of true labels composing the episode\n\n        \"\"\"", "\n", "n_way", "=", "len", "(", "true_labels", ")", "\n", "n_query", "=", "prediction_scores", ".", "size", "(", "0", ")", "//", "n_way", "\n", "assert", "isinstance", "(", "n_query", ",", "int", ")", "\n", "\n", "classification_gt", "=", "torch", ".", "from_numpy", "(", "np", ".", "repeat", "(", "range", "(", "n_way", ")", ",", "n_query", ")", ")", "\n", "classification", "=", "torch", ".", "argmax", "(", "prediction_scores", ".", "cpu", "(", ")", ",", "dim", "=", "1", ")", "\n", "local_confusion", "=", "confusion_matrix", "(", "classification_gt", ",", "classification", ")", "\n", "\n", "for", "(", "local_label1", ",", "true_label1", ")", "in", "enumerate", "(", "true_labels", ")", ":", "\n", "            ", "for", "(", "local_label2", ",", "true_label2", ")", "in", "enumerate", "(", "true_labels", ")", ":", "\n", "                ", "self", ".", "confusion_matrix", ".", "at", "[", "true_label1", ",", "true_label2", "]", "=", "(", "\n", "self", ".", "confusion_matrix", ".", "at", "[", "true_label1", ",", "true_label2", "]", "\n", "+", "local_confusion", "[", "local_label1", ",", "local_label2", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.training_statistics.TrainingStatistics.update_label_count": [[58, 69], ["None"], "methods", ["None"], ["", "", "", "def", "update_label_count", "(", "self", ",", "true_labels", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Updates the label_count matrix, i.e. the number of times each label was sampled in an episode during each epoch\n        Args:\n            true_labels (list[int]): list of true labels composing the episode\n            epoch (int): current epoch\n        \"\"\"", "\n", "if", "epoch", "not", "in", "self", ".", "label_count", ".", "columns", ":", "\n", "            ", "self", ".", "label_count", "[", "epoch", "]", "=", "0", "\n", "\n", "", "self", ".", "label_count", ".", "loc", "[", "true_labels", ",", "epoch", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.training_statistics.compute_biconfusion_matrix": [[71, 86], ["sklearn.metrics.confusion_matrix.add", "confusion_matrix.add.update", "numpy.fill_diagonal"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.src.training_statistics.TrainingStatistics.update"], ["", "", "def", "compute_biconfusion_matrix", "(", "confusion_matrix", ")", ":", "\n", "    ", "\"\"\"\n    The biconfusion matrix is typically used to measure the hardness of the discrimination task between two classes.\n        Element (i,j) corresponds to the number of missclassifications between classes i and j, regardless of the\n        direction (i to j or j to i).\n    Args:\n        confusion_matrix(pd.DataFrame): a 2-dimentional square matrix\n\n    Returns:\n        pd.DataFrame: a 2-dimentional symmetric square matrix of the same shape as confusion_matrix.\n    \"\"\"", "\n", "biconfusion_matrix", "=", "confusion_matrix", ".", "add", "(", "confusion_matrix", ".", "T", ")", "\n", "biconfusion_matrix", ".", "update", "(", "np", ".", "fill_diagonal", "(", "biconfusion_matrix", ".", "values", ",", "0", ")", ")", "\n", "\n", "return", "biconfusion_matrix", "\n", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.src.NTXentLoss.NTXentLoss.__init__": [[7, 17], ["super().__init__", "torch.nn.Softmax", "NTXentLoss.NTXentLoss._get_correlated_mask().type", "NTXentLoss.NTXentLoss._get_similarity_function", "torch.nn.CrossEntropyLoss", "NTXentLoss.NTXentLoss._get_correlated_mask"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__", "home.repos.pwc.inspect_result.772922440_pgada.src.NTXentLoss.NTXentLoss._get_similarity_function", "home.repos.pwc.inspect_result.772922440_pgada.src.NTXentLoss.NTXentLoss._get_correlated_mask"], ["    ", "def", "__init__", "(", "self", ",", "device", ",", "batch_size", ",", "temperature", ",", "use_cosine_similarity", ")", ":", "\n", "        ", "super", "(", "NTXentLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "softmax", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "self", ".", "mask_samples_from_same_repr", "=", "self", ".", "_get_correlated_mask", "(", ")", ".", "type", "(", "torch", ".", "bool", ")", "\n", "self", ".", "similarity_function", "=", "self", ".", "_get_similarity_function", "(", "\n", "use_cosine_similarity", ")", "\n", "self", ".", "criterion", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "\"sum\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.NTXentLoss.NTXentLoss._get_similarity_function": [[18, 24], ["torch.nn.CosineSimilarity"], "methods", ["None"], ["", "def", "_get_similarity_function", "(", "self", ",", "use_cosine_similarity", ")", ":", "\n", "        ", "if", "use_cosine_similarity", ":", "\n", "            ", "self", ".", "_cosine_similarity", "=", "torch", ".", "nn", ".", "CosineSimilarity", "(", "dim", "=", "-", "1", ")", "\n", "return", "self", ".", "_cosine_simililarity", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_dot_simililarity", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.NTXentLoss.NTXentLoss._get_correlated_mask": [[25, 34], ["numpy.eye", "numpy.eye", "numpy.eye", "torch.from_numpy", "torch.from_numpy.to"], "methods", ["None"], ["", "", "def", "_get_correlated_mask", "(", "self", ")", ":", "\n", "        ", "diag", "=", "np", ".", "eye", "(", "2", "*", "self", ".", "batch_size", ")", "\n", "l1", "=", "np", ".", "eye", "(", "(", "2", "*", "self", ".", "batch_size", ")", ",", "2", "*", "\n", "self", ".", "batch_size", ",", "k", "=", "-", "self", ".", "batch_size", ")", "\n", "l2", "=", "np", ".", "eye", "(", "(", "2", "*", "self", ".", "batch_size", ")", ",", "2", "*", "\n", "self", ".", "batch_size", ",", "k", "=", "self", ".", "batch_size", ")", "\n", "mask", "=", "torch", ".", "from_numpy", "(", "(", "diag", "+", "l1", "+", "l2", ")", ")", "\n", "mask", "=", "(", "1", "-", "mask", ")", ".", "type", "(", "torch", ".", "bool", ")", "\n", "return", "mask", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.NTXentLoss.NTXentLoss._dot_simililarity": [[35, 42], ["torch.tensordot", "x.unsqueeze", "y.T.unsqueeze"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_dot_simililarity", "(", "x", ",", "y", ")", ":", "\n", "        ", "v", "=", "torch", ".", "tensordot", "(", "x", ".", "unsqueeze", "(", "1", ")", ",", "y", ".", "T", ".", "unsqueeze", "(", "0", ")", ",", "dims", "=", "2", ")", "\n", "# x shape: (N, 1, C)", "\n", "# y shape: (1, C, 2N)", "\n", "# v shape: (N, 2N)", "\n", "return", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.NTXentLoss.NTXentLoss._cosine_simililarity": [[43, 49], ["NTXentLoss.NTXentLoss._cosine_similarity", "x.unsqueeze", "y.unsqueeze"], "methods", ["None"], ["", "def", "_cosine_simililarity", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "# x shape: (N, 1, C)", "\n", "# y shape: (1, 2N, C)", "\n", "# v shape: (N, 2N)", "\n", "        ", "v", "=", "self", ".", "_cosine_similarity", "(", "x", ".", "unsqueeze", "(", "1", ")", ",", "y", ".", "unsqueeze", "(", "0", ")", ")", "\n", "return", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.NTXentLoss.NTXentLoss.forward": [[50, 71], ["torch.cat", "NTXentLoss.NTXentLoss.similarity_function", "torch.diag", "torch.diag", "torch.cat().view", "similarity_matrix[].view", "torch.cat", "torch.zeros().to().long", "NTXentLoss.NTXentLoss.criterion", "torch.cat", "torch.zeros().to", "torch.zeros"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "zis", ",", "zjs", ")", ":", "\n", "        ", "representations", "=", "torch", ".", "cat", "(", "[", "zjs", ",", "zis", "]", ",", "dim", "=", "0", ")", "\n", "\n", "similarity_matrix", "=", "self", ".", "similarity_function", "(", "\n", "representations", ",", "representations", ")", "\n", "\n", "# filter out the scores from the positive samples", "\n", "l_pos", "=", "torch", ".", "diag", "(", "similarity_matrix", ",", "self", ".", "batch_size", ")", "\n", "r_pos", "=", "torch", ".", "diag", "(", "similarity_matrix", ",", "-", "self", ".", "batch_size", ")", "\n", "positives", "=", "torch", ".", "cat", "(", "[", "l_pos", ",", "r_pos", "]", ")", ".", "view", "(", "2", "*", "self", ".", "batch_size", ",", "1", ")", "\n", "\n", "negatives", "=", "similarity_matrix", "[", "self", ".", "mask_samples_from_same_repr", "]", ".", "view", "(", "\n", "2", "*", "self", ".", "batch_size", ",", "-", "1", ")", "\n", "\n", "logits", "=", "torch", ".", "cat", "(", "(", "positives", ",", "negatives", ")", ",", "dim", "=", "1", ")", "\n", "logits", "/=", "self", ".", "temperature", "\n", "\n", "labels", "=", "torch", ".", "zeros", "(", "2", "*", "self", ".", "batch_size", ")", ".", "to", "(", "self", ".", "device", ")", ".", "long", "(", ")", "\n", "loss", "=", "self", ".", "criterion", "(", "logits", ",", "labels", ")", "\n", "\n", "return", "loss", "/", "(", "2", "*", "self", ".", "batch_size", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device": [[12, 18], ["x.to", "torch.cuda.is_available"], "function", ["None"], ["def", "set_device", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    Switch a tensor to GPU if CUDA is available, to CPU otherwise\n    \"\"\"", "\n", "device", "=", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", "\n", "return", "x", ".", "to", "(", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.utils.plot_episode": [[20, 40], ["torchvision.utils.make_grid", "utils.plot_episode.matplotlib_imshow"], "function", ["None"], ["", "def", "plot_episode", "(", "support_images", ",", "query_images", ")", ":", "\n", "    ", "\"\"\"\n    Plot images of an episode, separating support and query images.\n    Args:\n        support_images (torch.Tensor): tensor of multiple-channel support images\n        query_images (torch.Tensor): tensor of multiple-channel query images\n    \"\"\"", "\n", "\n", "def", "matplotlib_imshow", "(", "img", ")", ":", "\n", "        ", "npimg", "=", "img", ".", "numpy", "(", ")", "\n", "plt", ".", "imshow", "(", "np", ".", "transpose", "(", "npimg", ",", "(", "1", ",", "2", ",", "0", ")", ")", ")", "\n", "\n", "", "support_grid", "=", "torchvision", ".", "utils", ".", "make_grid", "(", "support_images", ")", "\n", "matplotlib_imshow", "(", "support_grid", ")", "\n", "plt", ".", "title", "(", "\"support images\"", ")", "\n", "plt", ".", "show", "(", ")", "\n", "query_grid", "=", "torchvision", ".", "utils", ".", "make_grid", "(", "query_images", ")", "\n", "plt", ".", "title", "(", "\"query images\"", ")", "\n", "matplotlib_imshow", "(", "query_grid", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.utils.elucidate_ids": [[42, 58], ["df.replace"], "function", ["None"], ["", "def", "elucidate_ids", "(", "df", ",", "dataset", ")", ":", "\n", "    ", "\"\"\"\n    Retrieves explicit class and domain names in dataset from their integer index,\n        and returns modified DataFrame\n    Args:\n        df (pd.DataFrame): input DataFrame. Must be the same format as the output of AbstractMetaLearner.get_task_perf()\n        dataset (Dataset): the dataset\n    Returns:\n        pd.DataFrame: output DataFrame with explicit class and domain names\n    \"\"\"", "\n", "return", "df", ".", "replace", "(", "\n", "{", "\n", "\"predicted_label\"", ":", "dataset", ".", "id_to_class", ",", "\n", "\"true_label\"", ":", "dataset", ".", "id_to_class", ",", "\n", "\"source_domain\"", ":", "dataset", ".", "id_to_domain", ",", "\n", "\"target_domain\"", ":", "dataset", ".", "id_to_domain", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.src.utils.get_episodic_loader": [[62, 83], ["configs.dataset_config.DATASET", "dataset_config.DATASET.get_sampler", "torch.utils.data.DataLoader"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.datasets.cifar_c_meta.CIFAR100CMeta.get_sampler"], ["", "def", "get_episodic_loader", "(", "\n", "split", ":", "str", ",", "n_way", ":", "int", ",", "n_source", ":", "int", ",", "n_target", ":", "int", ",", "n_episodes", ":", "int", "\n", ")", ":", "\n", "    ", "dataset", "=", "dataset_config", ".", "DATASET", "(", "\n", "dataset_config", ".", "DATA_ROOT", ",", "split", ",", "dataset_config", ".", "IMAGE_SIZE", "\n", ")", "\n", "sampler", "=", "dataset", ".", "get_sampler", "(", ")", "(", "\n", "n_way", "=", "n_way", ",", "\n", "n_source", "=", "n_source", ",", "\n", "n_target", "=", "n_target", ",", "\n", "n_episodes", "=", "n_episodes", ",", "\n", ")", "\n", "return", "(", "\n", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_sampler", "=", "sampler", ",", "\n", "num_workers", "=", "12", ",", "\n", "pin_memory", "=", "False", ",", "# SY changed", "\n", "collate_fn", "=", "episodic_collate_fn", ",", "\n", ")", ",", "\n", "dataset", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.MotionImage.motion_blur": [[39, 41], ["wand.api.library.MagickMotionBlurImage"], "methods", ["None"], ["    ", "def", "motion_blur", "(", "self", ",", "radius", "=", "0.0", ",", "sigma", "=", "0.0", ",", "angle", "=", "0.0", ")", ":", "\n", "        ", "wandlibrary", ".", "MagickMotionBlurImage", "(", "self", ".", "wand", ",", "radius", ",", "sigma", ",", "angle", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.disk": [[22, 35], ["numpy.meshgrid", "numpy.array", "numpy.sum", "cv2.GaussianBlur", "numpy.arange", "numpy.arange"], "function", ["None"], ["def", "disk", "(", "radius", ",", "alias_blur", "=", "0.1", ",", "dtype", "=", "np", ".", "float32", ")", ":", "\n", "    ", "if", "radius", "<=", "8", ":", "\n", "        ", "L", "=", "np", ".", "arange", "(", "-", "8", ",", "8", "+", "1", ")", "\n", "ksize", "=", "(", "3", ",", "3", ")", "\n", "", "else", ":", "\n", "        ", "L", "=", "np", ".", "arange", "(", "-", "radius", ",", "radius", "+", "1", ")", "\n", "ksize", "=", "(", "5", ",", "5", ")", "\n", "", "X", ",", "Y", "=", "np", ".", "meshgrid", "(", "L", ",", "L", ")", "\n", "aliased_disk", "=", "np", ".", "array", "(", "(", "X", "**", "2", "+", "Y", "**", "2", ")", "<=", "radius", "**", "2", ",", "dtype", "=", "dtype", ")", "\n", "aliased_disk", "/=", "np", ".", "sum", "(", "aliased_disk", ")", "\n", "\n", "# supersample disk to antialias", "\n", "return", "cv2", ".", "GaussianBlur", "(", "aliased_disk", ",", "ksize", "=", "ksize", ",", "sigmaX", "=", "alias_blur", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.plasma_fractal": [[44, 99], ["numpy.empty", "np.empty.min", "numpy.roll", "perturbations.plasma_fractal.wibbledmean"], "function", ["None"], ["", "", "def", "plasma_fractal", "(", "image_size", ",", "wibbledecay", "=", "3", ")", ":", "\n", "    ", "\"\"\"\n    Generate a heightmap using diamond-square algorithm.\n    Return square 2d array, side length 'mapsize', of floats in range 0-255.\n    'mapsize' must be a power of two.\n    \"\"\"", "\n", "mapsize", "=", "2", "**", "(", "image_size", "-", "1", ")", ".", "bit_length", "(", ")", "\n", "assert", "mapsize", "&", "(", "mapsize", "-", "1", ")", "==", "0", "\n", "maparray", "=", "np", ".", "empty", "(", "(", "mapsize", ",", "mapsize", ")", ",", "dtype", "=", "np", ".", "float_", ")", "\n", "maparray", "[", "0", ",", "0", "]", "=", "0", "\n", "stepsize", "=", "mapsize", "\n", "wibble", "=", "100", "\n", "\n", "def", "wibbledmean", "(", "array", ")", ":", "\n", "        ", "return", "array", "/", "4", "+", "wibble", "*", "np", ".", "random", ".", "uniform", "(", "-", "wibble", ",", "wibble", ",", "array", ".", "shape", ")", "\n", "\n", "", "def", "fillsquares", "(", ")", ":", "\n", "        ", "\"\"\"For each square of points stepsize apart,\n        calculate middle value as mean of points + wibble\"\"\"", "\n", "cornerref", "=", "maparray", "[", "0", ":", "mapsize", ":", "stepsize", ",", "0", ":", "mapsize", ":", "stepsize", "]", "\n", "squareaccum", "=", "cornerref", "+", "np", ".", "roll", "(", "cornerref", ",", "shift", "=", "-", "1", ",", "axis", "=", "0", ")", "\n", "squareaccum", "+=", "np", ".", "roll", "(", "squareaccum", ",", "shift", "=", "-", "1", ",", "axis", "=", "1", ")", "\n", "maparray", "[", "\n", "stepsize", "//", "2", ":", "mapsize", ":", "stepsize", ",", "stepsize", "//", "2", ":", "mapsize", ":", "stepsize", "\n", "]", "=", "wibbledmean", "(", "squareaccum", ")", "\n", "\n", "", "def", "filldiamonds", "(", ")", ":", "\n", "        ", "\"\"\"For each diamond of points stepsize apart,\n        calculate middle value as mean of points + wibble\"\"\"", "\n", "mapsize", "=", "maparray", ".", "shape", "[", "0", "]", "\n", "drgrid", "=", "maparray", "[", "\n", "stepsize", "//", "2", ":", "mapsize", ":", "stepsize", ",", "stepsize", "//", "2", ":", "mapsize", ":", "stepsize", "\n", "]", "\n", "ulgrid", "=", "maparray", "[", "0", ":", "mapsize", ":", "stepsize", ",", "0", ":", "mapsize", ":", "stepsize", "]", "\n", "ldrsum", "=", "drgrid", "+", "np", ".", "roll", "(", "drgrid", ",", "1", ",", "axis", "=", "0", ")", "\n", "lulsum", "=", "ulgrid", "+", "np", ".", "roll", "(", "ulgrid", ",", "-", "1", ",", "axis", "=", "1", ")", "\n", "ltsum", "=", "ldrsum", "+", "lulsum", "\n", "maparray", "[", "0", ":", "mapsize", ":", "stepsize", ",", "stepsize", "//", "2", ":", "mapsize", ":", "stepsize", "]", "=", "wibbledmean", "(", "\n", "ltsum", "\n", ")", "\n", "tdrsum", "=", "drgrid", "+", "np", ".", "roll", "(", "drgrid", ",", "1", ",", "axis", "=", "1", ")", "\n", "tulsum", "=", "ulgrid", "+", "np", ".", "roll", "(", "ulgrid", ",", "-", "1", ",", "axis", "=", "0", ")", "\n", "ttsum", "=", "tdrsum", "+", "tulsum", "\n", "maparray", "[", "stepsize", "//", "2", ":", "mapsize", ":", "stepsize", ",", "0", ":", "mapsize", ":", "stepsize", "]", "=", "wibbledmean", "(", "\n", "ttsum", "\n", ")", "\n", "\n", "", "while", "stepsize", ">=", "2", ":", "\n", "        ", "fillsquares", "(", ")", "\n", "filldiamonds", "(", ")", "\n", "stepsize", "//=", "2", "\n", "wibble", "/=", "wibbledecay", "\n", "\n", "", "maparray", "-=", "maparray", ".", "min", "(", ")", "\n", "return", "maparray", "/", "maparray", ".", "max", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.clipped_zoom": [[101, 114], ["int", "scipy.ndimage.zoom", "numpy.ceil"], "function", ["None"], ["", "def", "clipped_zoom", "(", "img", ",", "zoom_factor", ")", ":", "\n", "    ", "h", "=", "img", ".", "shape", "[", "0", "]", "\n", "# ceil crop height(= crop width)", "\n", "ch", "=", "int", "(", "np", ".", "ceil", "(", "h", "/", "zoom_factor", ")", ")", "\n", "\n", "top", "=", "(", "h", "-", "ch", ")", "//", "2", "\n", "img", "=", "scizoom", "(", "\n", "img", "[", "top", ":", "top", "+", "ch", ",", "top", ":", "top", "+", "ch", "]", ",", "(", "zoom_factor", ",", "zoom_factor", ",", "1", ")", ",", "order", "=", "1", "\n", ")", "\n", "# trim off any extra pixels", "\n", "trim_top", "=", "(", "img", ".", "shape", "[", "0", "]", "-", "h", ")", "//", "2", "\n", "\n", "return", "img", "[", "trim_top", ":", "trim_top", "+", "h", ",", "trim_top", ":", "trim_top", "+", "h", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.gaussian_noise": [[122, 126], ["numpy.array", "numpy.clip", "numpy.random.normal"], "function", ["None"], ["", "def", "gaussian_noise", "(", "x", ",", "severity_params", ",", "image_size", ")", ":", "\n", "    ", "x", "=", "np", ".", "array", "(", "x", ")", "/", "255.0", "\n", "return", "(", "\n", "np", ".", "clip", "(", "x", "+", "np", ".", "random", ".", "normal", "(", "size", "=", "x", ".", "shape", ",", "scale", "=", "severity_params", ")", ",", "0", ",", "1", ")", "*", "255", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.shot_noise": [[129, 132], ["numpy.array", "numpy.clip", "numpy.random.poisson"], "function", ["None"], ["", "def", "shot_noise", "(", "x", ",", "severity_params", ",", "image_size", ")", ":", "\n", "    ", "x", "=", "np", ".", "array", "(", "x", ")", "/", "255.0", "\n", "return", "np", ".", "clip", "(", "np", ".", "random", ".", "poisson", "(", "x", "*", "severity_params", ")", "/", "severity_params", ",", "0", ",", "1", ")", "*", "255", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.impulse_noise": [[134, 137], ["skimage.util.random_noise", "numpy.clip", "numpy.array"], "function", ["None"], ["", "def", "impulse_noise", "(", "x", ",", "severity_params", ",", "image_size", ")", ":", "\n", "    ", "x", "=", "sk", ".", "util", ".", "random_noise", "(", "np", ".", "array", "(", "x", ")", "/", "255.0", ",", "mode", "=", "\"s&p\"", ",", "amount", "=", "severity_params", ")", "\n", "return", "np", ".", "clip", "(", "x", ",", "0", ",", "1", ")", "*", "255", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.speckle_noise": [[139, 144], ["numpy.array", "numpy.clip", "numpy.random.normal"], "function", ["None"], ["", "def", "speckle_noise", "(", "x", ",", "severity_params", ",", "image_size", ")", ":", "\n", "    ", "x", "=", "np", ".", "array", "(", "x", ")", "/", "255.0", "\n", "return", "(", "\n", "np", ".", "clip", "(", "x", "+", "x", "*", "np", ".", "random", ".", "normal", "(", "size", "=", "x", ".", "shape", ",", "scale", "=", "severity_params", ")", ",", "0", ",", "1", ")", "\n", "*", "255", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.gaussian_blur": [[147, 150], ["skimage.filters.gaussian", "numpy.clip", "numpy.array"], "function", ["None"], ["", "def", "gaussian_blur", "(", "x", ",", "severity_params", ",", "image_size", ")", ":", "\n", "    ", "x", "=", "gaussian", "(", "np", ".", "array", "(", "x", ")", "/", "255.0", ",", "sigma", "=", "severity_params", ",", "multichannel", "=", "True", ")", "\n", "return", "np", ".", "clip", "(", "x", ",", "0", ",", "1", ")", "*", "255", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.glass_blur": [[152, 171], ["numpy.uint8", "range", "range", "numpy.clip", "skimage.filters.gaussian", "range", "skimage.filters.gaussian", "numpy.random.randint", "numpy.array"], "function", ["None"], ["", "def", "glass_blur", "(", "x", ",", "severity_params", ",", "image_size", ")", ":", "\n", "    ", "x", "=", "np", ".", "uint8", "(", "\n", "gaussian", "(", "np", ".", "array", "(", "x", ")", "/", "255.0", ",", "sigma", "=", "severity_params", "[", "0", "]", ",", "multichannel", "=", "True", ")", "*", "255", "\n", ")", "\n", "\n", "# locally shuffle pixels", "\n", "for", "i", "in", "range", "(", "severity_params", "[", "2", "]", ")", ":", "\n", "        ", "for", "h", "in", "range", "(", "image_size", "-", "severity_params", "[", "1", "]", ",", "severity_params", "[", "1", "]", ",", "-", "1", ")", ":", "\n", "            ", "for", "w", "in", "range", "(", "image_size", "-", "severity_params", "[", "1", "]", ",", "severity_params", "[", "1", "]", ",", "-", "1", ")", ":", "\n", "                ", "dx", ",", "dy", "=", "np", ".", "random", ".", "randint", "(", "\n", "-", "severity_params", "[", "1", "]", ",", "severity_params", "[", "1", "]", ",", "size", "=", "(", "2", ",", ")", "\n", ")", "\n", "h_prime", ",", "w_prime", "=", "h", "+", "dy", ",", "w", "+", "dx", "\n", "# swap", "\n", "x", "[", "h", ",", "w", "]", ",", "x", "[", "h_prime", ",", "w_prime", "]", "=", "x", "[", "h_prime", ",", "w_prime", "]", ",", "x", "[", "h", ",", "w", "]", "\n", "\n", "", "", "", "return", "(", "\n", "np", ".", "clip", "(", "gaussian", "(", "x", "/", "255.0", ",", "sigma", "=", "severity_params", "[", "0", "]", ",", "multichannel", "=", "True", ")", ",", "0", ",", "1", ")", "\n", "*", "255", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.defocus_blur": [[174, 186], ["perturbations.disk", "range", "numpy.array().transpose", "numpy.array", "np.array().transpose.append", "numpy.clip", "cv2.filter2D", "numpy.array"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.disk"], ["", "def", "defocus_blur", "(", "x", ",", "severity_params", ",", "image_size", ")", ":", "\n", "    ", "x", "=", "np", ".", "array", "(", "x", ")", "/", "255.0", "\n", "kernel", "=", "disk", "(", "radius", "=", "severity_params", "[", "0", "]", ",", "alias_blur", "=", "severity_params", "[", "1", "]", ")", "\n", "\n", "channels", "=", "[", "]", "\n", "for", "d", "in", "range", "(", "3", ")", ":", "\n", "        ", "channels", ".", "append", "(", "cv2", ".", "filter2D", "(", "x", "[", ":", ",", ":", ",", "d", "]", ",", "-", "1", ",", "kernel", ")", ")", "\n", "", "channels", "=", "np", ".", "array", "(", "channels", ")", ".", "transpose", "(", "\n", "(", "1", ",", "2", ",", "0", ")", "\n", ")", "# 3ximage_sizeximage_size -> image_sizeximage_sizex3", "\n", "\n", "return", "np", ".", "clip", "(", "channels", ",", "0", ",", "1", ")", "*", "255", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.motion_blur": [[188, 205], ["io.BytesIO", "cv2.imdecode.save", "perturbations.MotionImage", "cv2.imdecode.motion_blur", "cv2.imdecode", "numpy.fromstring", "numpy.clip", "numpy.clip", "io.BytesIO.getvalue", "numpy.random.uniform", "cv2.imdecode.make_blob", "numpy.array().transpose", "numpy.array"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.motion_blur"], ["", "def", "motion_blur", "(", "x", ",", "severity_params", ",", "image_size", ")", ":", "\n", "    ", "output", "=", "BytesIO", "(", ")", "\n", "x", ".", "save", "(", "output", ",", "format", "=", "\"PNG\"", ")", "\n", "x", "=", "MotionImage", "(", "blob", "=", "output", ".", "getvalue", "(", ")", ")", "\n", "\n", "x", ".", "motion_blur", "(", "\n", "radius", "=", "severity_params", "[", "0", "]", ",", "\n", "sigma", "=", "severity_params", "[", "1", "]", ",", "\n", "angle", "=", "np", ".", "random", ".", "uniform", "(", "-", "45", ",", "45", ")", ",", "\n", ")", "\n", "\n", "x", "=", "cv2", ".", "imdecode", "(", "np", ".", "fromstring", "(", "x", ".", "make_blob", "(", ")", ",", "np", ".", "uint8", ")", ",", "cv2", ".", "IMREAD_UNCHANGED", ")", "\n", "\n", "if", "x", ".", "shape", "!=", "(", "image_size", ",", "image_size", ")", ":", "\n", "        ", "return", "np", ".", "clip", "(", "x", "[", "...", ",", "[", "2", ",", "1", ",", "0", "]", "]", ",", "0", ",", "255", ")", "# BGR to RGB", "\n", "", "else", ":", "# greyscale to RGB", "\n", "        ", "return", "np", ".", "clip", "(", "np", ".", "array", "(", "[", "x", ",", "x", ",", "x", "]", ")", ".", "transpose", "(", "(", "1", ",", "2", ",", "0", ")", ")", ",", "0", ",", "255", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.zoom_blur": [[207, 215], ["numpy.zeros_like", "perturbations.clipped_zoom", "numpy.clip", "len", "numpy.array"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.clipped_zoom"], ["", "", "def", "zoom_blur", "(", "x", ",", "severity_params", ",", "image_size", ")", ":", "\n", "    ", "x", "=", "(", "np", ".", "array", "(", "x", ")", "/", "255.0", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "out", "=", "np", ".", "zeros_like", "(", "x", ")", "\n", "for", "zoom_factor", "in", "severity_params", ":", "\n", "        ", "out", "+=", "clipped_zoom", "(", "x", ",", "zoom_factor", ")", "\n", "\n", "", "x", "=", "(", "x", "+", "out", ")", "/", "(", "len", "(", "severity_params", ")", "+", "1", ")", "\n", "return", "np", ".", "clip", "(", "x", ",", "0", ",", "1", ")", "*", "255", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.fog": [[217, 227], ["x.max", "numpy.array", "numpy.clip", "perturbations.plasma_fractal"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.plasma_fractal"], ["", "def", "fog", "(", "x", ",", "severity_params", ",", "image_size", ")", ":", "\n", "    ", "x", "=", "np", ".", "array", "(", "x", ")", "/", "255.0", "\n", "max_val", "=", "x", ".", "max", "(", ")", "\n", "x", "+=", "(", "\n", "severity_params", "[", "0", "]", "\n", "*", "plasma_fractal", "(", "wibbledecay", "=", "severity_params", "[", "1", "]", ",", "image_size", "=", "image_size", ")", "[", "\n", ":", "image_size", ",", ":", "image_size", "\n", "]", "[", "...", ",", "np", ".", "newaxis", "]", "\n", ")", "\n", "return", "np", ".", "clip", "(", "x", "*", "max_val", "/", "(", "max_val", "+", "severity_params", "[", "0", "]", ")", ",", "0", ",", "1", ")", "*", "255", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.frost": [[229, 264], ["numpy.random.randint", "numpy.clip", "numpy.random.randint", "numpy.random.randint", "cv2.imread", "cv2.resize", "loguru.logger.warning", "time.sleep", "loguru.logger.info", "numpy.array"], "function", ["None"], ["", "def", "frost", "(", "x", ",", "severity_params", ",", "image_size", ")", ":", "\n", "    ", "idx", "=", "np", ".", "random", ".", "randint", "(", "5", ")", "\n", "filename", "=", "[", "\n", "\"src/data_tools/filters/frost2.png\"", ",", "\n", "\"src/data_tools/filters/frost3.png\"", ",", "\n", "\"src/data_tools/filters/frost1.png\"", ",", "\n", "\"src/data_tools/filters/frost4.jpg\"", ",", "\n", "\"src/data_tools/filters/frost5.jpg\"", ",", "\n", "\"src/data_tools/filters/frost6.jpg\"", ",", "\n", "]", "[", "idx", "]", "\n", "# TODO: this is a bit dirty. We have a non reproducible bug here and we need to find out what's what.", "\n", "while", "True", ":", "\n", "        ", "try", ":", "\n", "            ", "frost", "=", "cv2", ".", "imread", "(", "filename", ")", "\n", "if", "image_size", "<=", "32", ":", "\n", "                ", "frost", "=", "cv2", ".", "resize", "(", "frost", ",", "(", "0", ",", "0", ")", ",", "fx", "=", "0.2", ",", "fy", "=", "0.2", ")", "\n", "", "break", "\n", "", "except", "cv2", ".", "error", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "f\"Error trying to read {filename}. Maybe it was locked by an other process?\"", "\n", ")", "\n", "time", ".", "sleep", "(", "1", ")", "\n", "logger", ".", "info", "(", "\"Retrying...\"", ")", "\n", "\n", "# randomly crop and convert to rgb", "\n", "", "", "x_start", ",", "y_start", "=", "(", "\n", "np", ".", "random", ".", "randint", "(", "0", ",", "frost", ".", "shape", "[", "0", "]", "-", "image_size", ")", ",", "\n", "np", ".", "random", ".", "randint", "(", "0", ",", "frost", ".", "shape", "[", "1", "]", "-", "image_size", ")", ",", "\n", ")", "\n", "frost", "=", "frost", "[", "x_start", ":", "x_start", "+", "image_size", ",", "y_start", ":", "y_start", "+", "image_size", "]", "[", "\n", "...", ",", "[", "2", ",", "1", ",", "0", "]", "\n", "]", "\n", "\n", "return", "np", ".", "clip", "(", "\n", "severity_params", "[", "0", "]", "*", "np", ".", "array", "(", "x", ")", "+", "severity_params", "[", "1", "]", "*", "frost", ",", "0", ",", "255", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.snow": [[267, 303], ["numpy.random.normal", "perturbations.clipped_zoom", "PIL.Image.fromarray", "io.BytesIO", "MotionImage.save", "perturbations.MotionImage", "perturbations.MotionImage.motion_blur", "numpy.array", "cv2.imdecode", "numpy.clip", "io.BytesIO.getvalue", "numpy.random.uniform", "numpy.fromstring", "numpy.maximum", "MotionImage.make_blob", "numpy.rot90", "numpy.clip", "MotionImage.squeeze", "cv2.cvtColor().reshape", "cv2.cvtColor"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.clipped_zoom", "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.motion_blur"], ["", "def", "snow", "(", "x", ",", "severity_params", ",", "image_size", ")", ":", "\n", "    ", "x", "=", "np", ".", "array", "(", "x", ",", "dtype", "=", "np", ".", "float32", ")", "/", "255.0", "\n", "snow_layer", "=", "np", ".", "random", ".", "normal", "(", "\n", "size", "=", "x", ".", "shape", "[", ":", "2", "]", ",", "loc", "=", "severity_params", "[", "0", "]", ",", "scale", "=", "severity_params", "[", "1", "]", "\n", ")", "# [:2] for monochrome", "\n", "\n", "snow_layer", "=", "clipped_zoom", "(", "snow_layer", "[", "...", ",", "np", ".", "newaxis", "]", ",", "severity_params", "[", "2", "]", ")", "\n", "snow_layer", "[", "snow_layer", "<", "severity_params", "[", "3", "]", "]", "=", "0", "\n", "\n", "snow_layer", "=", "PILImage", ".", "fromarray", "(", "\n", "(", "np", ".", "clip", "(", "snow_layer", ".", "squeeze", "(", ")", ",", "0", ",", "1", ")", "*", "255", ")", ".", "astype", "(", "np", ".", "uint8", ")", ",", "mode", "=", "\"L\"", "\n", ")", "\n", "output", "=", "BytesIO", "(", ")", "\n", "snow_layer", ".", "save", "(", "output", ",", "format", "=", "\"PNG\"", ")", "\n", "snow_layer", "=", "MotionImage", "(", "blob", "=", "output", ".", "getvalue", "(", ")", ")", "\n", "\n", "snow_layer", ".", "motion_blur", "(", "\n", "radius", "=", "severity_params", "[", "4", "]", ",", "\n", "sigma", "=", "severity_params", "[", "5", "]", ",", "\n", "angle", "=", "np", ".", "random", ".", "uniform", "(", "-", "135", ",", "-", "45", ")", ",", "\n", ")", "\n", "\n", "snow_layer", "=", "(", "\n", "cv2", ".", "imdecode", "(", "\n", "np", ".", "fromstring", "(", "snow_layer", ".", "make_blob", "(", ")", ",", "np", ".", "uint8", ")", ",", "cv2", ".", "IMREAD_UNCHANGED", "\n", ")", "\n", "/", "255.0", "\n", ")", "\n", "snow_layer", "=", "snow_layer", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "\n", "x", "=", "severity_params", "[", "6", "]", "*", "x", "+", "(", "1", "-", "severity_params", "[", "6", "]", ")", "*", "np", ".", "maximum", "(", "\n", "x", ",", "\n", "cv2", ".", "cvtColor", "(", "x", ",", "cv2", ".", "COLOR_RGB2GRAY", ")", ".", "reshape", "(", "image_size", ",", "image_size", ",", "1", ")", "*", "1.5", "\n", "+", "0.5", ",", "\n", ")", "\n", "return", "np", ".", "clip", "(", "x", "+", "snow_layer", "+", "np", ".", "rot90", "(", "snow_layer", ",", "k", "=", "2", ")", ",", "0", ",", "1", ")", "*", "255", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.spatter": [[305, 362], ["numpy.random.normal", "skimage.filters.gaussian", "numpy.array", "cv2.distanceTransform", "cv2.threshold", "cv2.blur().astype", "cv2.equalizeHist", "numpy.array", "cv2.filter2D", "cv2.blur().astype", "cv2.cvtColor", "numpy.max", "numpy.concatenate", "cv2.cvtColor", "cv2.cvtColor", "numpy.where", "skimage.filters.gaussian", "numpy.concatenate", "cv2.Canny", "cv2.cvtColor", "skimage.filters.gaussian.astype", "numpy.clip", "cv2.blur", "cv2.blur", "numpy.clip", "numpy.ones_like", "numpy.ones_like", "numpy.ones_like", "numpy.ones_like", "numpy.ones_like", "numpy.ones_like"], "function", ["None"], ["", "def", "spatter", "(", "x", ",", "severity_params", ",", "image_size", ")", ":", "\n", "    ", "x", "=", "np", ".", "array", "(", "x", ",", "dtype", "=", "np", ".", "float32", ")", "/", "255.0", "\n", "\n", "liquid_layer", "=", "np", ".", "random", ".", "normal", "(", "\n", "size", "=", "x", ".", "shape", "[", ":", "2", "]", ",", "loc", "=", "severity_params", "[", "0", "]", ",", "scale", "=", "severity_params", "[", "1", "]", "\n", ")", "\n", "\n", "liquid_layer", "=", "gaussian", "(", "liquid_layer", ",", "sigma", "=", "severity_params", "[", "2", "]", ")", "\n", "liquid_layer", "[", "liquid_layer", "<", "severity_params", "[", "3", "]", "]", "=", "0", "\n", "if", "severity_params", "[", "5", "]", "==", "0", ":", "\n", "        ", "liquid_layer", "=", "(", "liquid_layer", "*", "255", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "dist", "=", "255", "-", "cv2", ".", "Canny", "(", "liquid_layer", ",", "50", ",", "150", ")", "\n", "dist", "=", "cv2", ".", "distanceTransform", "(", "dist", ",", "cv2", ".", "DIST_L2", ",", "5", ")", "\n", "_", ",", "dist", "=", "cv2", ".", "threshold", "(", "dist", ",", "20", ",", "20", ",", "cv2", ".", "THRESH_TRUNC", ")", "\n", "dist", "=", "cv2", ".", "blur", "(", "dist", ",", "(", "3", ",", "3", ")", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "dist", "=", "cv2", ".", "equalizeHist", "(", "dist", ")", "\n", "ker", "=", "np", ".", "array", "(", "[", "[", "-", "2", ",", "-", "1", ",", "0", "]", ",", "[", "-", "1", ",", "1", ",", "1", "]", ",", "[", "0", ",", "1", ",", "2", "]", "]", ")", "\n", "dist", "=", "cv2", ".", "filter2D", "(", "dist", ",", "cv2", ".", "CV_8U", ",", "ker", ")", "\n", "dist", "=", "cv2", ".", "blur", "(", "dist", ",", "(", "3", ",", "3", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "m", "=", "cv2", ".", "cvtColor", "(", "liquid_layer", "*", "dist", ",", "cv2", ".", "COLOR_GRAY2BGRA", ")", "\n", "m", "/=", "np", ".", "max", "(", "m", ",", "axis", "=", "(", "0", ",", "1", ")", ")", "\n", "m", "*=", "severity_params", "[", "4", "]", "\n", "\n", "# water is pale turquoise", "\n", "color", "=", "np", ".", "concatenate", "(", "\n", "(", "\n", "175", "/", "255.0", "*", "np", ".", "ones_like", "(", "m", "[", "...", ",", ":", "1", "]", ")", ",", "\n", "238", "/", "255.0", "*", "np", ".", "ones_like", "(", "m", "[", "...", ",", ":", "1", "]", ")", ",", "\n", "238", "/", "255.0", "*", "np", ".", "ones_like", "(", "m", "[", "...", ",", ":", "1", "]", ")", ",", "\n", ")", ",", "\n", "axis", "=", "2", ",", "\n", ")", "\n", "\n", "color", "=", "cv2", ".", "cvtColor", "(", "color", ",", "cv2", ".", "COLOR_BGR2BGRA", ")", "\n", "x", "=", "cv2", ".", "cvtColor", "(", "x", ",", "cv2", ".", "COLOR_BGR2BGRA", ")", "\n", "\n", "return", "cv2", ".", "cvtColor", "(", "np", ".", "clip", "(", "x", "+", "m", "*", "color", ",", "0", ",", "1", ")", ",", "cv2", ".", "COLOR_BGRA2BGR", ")", "*", "255", "\n", "", "else", ":", "\n", "        ", "m", "=", "np", ".", "where", "(", "liquid_layer", ">", "severity_params", "[", "3", "]", ",", "1", ",", "0", ")", "\n", "m", "=", "gaussian", "(", "m", ".", "astype", "(", "np", ".", "float32", ")", ",", "sigma", "=", "severity_params", "[", "4", "]", ")", "\n", "m", "[", "m", "<", "0.8", "]", "=", "0", "\n", "\n", "# mud brown", "\n", "color", "=", "np", ".", "concatenate", "(", "\n", "(", "\n", "63", "/", "255.0", "*", "np", ".", "ones_like", "(", "x", "[", "...", ",", ":", "1", "]", ")", ",", "\n", "42", "/", "255.0", "*", "np", ".", "ones_like", "(", "x", "[", "...", ",", ":", "1", "]", ")", ",", "\n", "20", "/", "255.0", "*", "np", ".", "ones_like", "(", "x", "[", "...", ",", ":", "1", "]", ")", ",", "\n", ")", ",", "\n", "axis", "=", "2", ",", "\n", ")", "\n", "\n", "color", "*=", "m", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "x", "*=", "1", "-", "m", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "\n", "return", "np", ".", "clip", "(", "x", "+", "color", ",", "0", ",", "1", ")", "*", "255", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.contrast": [[364, 368], ["numpy.mean", "numpy.array", "numpy.clip"], "function", ["None"], ["", "", "def", "contrast", "(", "x", ",", "severity_params", ",", "image_size", ")", ":", "\n", "    ", "x", "=", "np", ".", "array", "(", "x", ")", "/", "255.0", "\n", "means", "=", "np", ".", "mean", "(", "x", ",", "axis", "=", "(", "0", ",", "1", ")", ",", "keepdims", "=", "True", ")", "\n", "return", "np", ".", "clip", "(", "(", "x", "-", "means", ")", "*", "severity_params", "+", "means", ",", "0", ",", "1", ")", "*", "255", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.brightness": [[370, 377], ["skimage.color.rgb2hsv", "numpy.clip", "skimage.color.hsv2rgb", "numpy.array", "numpy.clip"], "function", ["None"], ["", "def", "brightness", "(", "x", ",", "severity_params", ",", "image_size", ")", ":", "\n", "    ", "x", "=", "np", ".", "array", "(", "x", ")", "/", "255.0", "\n", "x", "=", "sk", ".", "color", ".", "rgb2hsv", "(", "x", ")", "\n", "x", "[", ":", ",", ":", ",", "2", "]", "=", "np", ".", "clip", "(", "x", "[", ":", ",", ":", ",", "2", "]", "+", "severity_params", ",", "0", ",", "1", ")", "\n", "x", "=", "sk", ".", "color", ".", "hsv2rgb", "(", "x", ")", "\n", "\n", "return", "np", ".", "clip", "(", "x", ",", "0", ",", "1", ")", "*", "255", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.saturate": [[379, 386], ["skimage.color.rgb2hsv", "numpy.clip", "skimage.color.hsv2rgb", "numpy.array", "numpy.clip"], "function", ["None"], ["", "def", "saturate", "(", "x", ",", "severity_params", ",", "image_size", ")", ":", "\n", "    ", "x", "=", "np", ".", "array", "(", "x", ")", "/", "255.0", "\n", "x", "=", "sk", ".", "color", ".", "rgb2hsv", "(", "x", ")", "\n", "x", "[", ":", ",", ":", ",", "1", "]", "=", "np", ".", "clip", "(", "x", "[", ":", ",", ":", ",", "1", "]", "*", "severity_params", "[", "0", "]", "+", "severity_params", "[", "1", "]", ",", "0", ",", "1", ")", "\n", "x", "=", "sk", ".", "color", ".", "hsv2rgb", "(", "x", ")", "\n", "\n", "return", "np", ".", "clip", "(", "x", ",", "0", ",", "1", ")", "*", "255", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.jpeg_compression": [[388, 394], ["io.BytesIO", "PILImage.open.save", "PIL.Image.open"], "function", ["None"], ["", "def", "jpeg_compression", "(", "x", ",", "severity_params", ",", "image_size", ")", ":", "\n", "    ", "output", "=", "BytesIO", "(", ")", "\n", "x", ".", "save", "(", "output", ",", "\"JPEG\"", ",", "quality", "=", "severity_params", ")", "\n", "x", "=", "PILImage", ".", "open", "(", "output", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.pixelate": [[396, 404], ["x.resize.resize", "x.resize.resize", "int", "int"], "function", ["None"], ["", "def", "pixelate", "(", "x", ",", "severity_params", ",", "image_size", ")", ":", "\n", "    ", "x", "=", "x", ".", "resize", "(", "\n", "(", "int", "(", "image_size", "*", "severity_params", ")", ",", "int", "(", "image_size", "*", "severity_params", ")", ")", ",", "\n", "PILImage", ".", "BOX", ",", "\n", ")", "\n", "x", "=", "x", ".", "resize", "(", "(", "image_size", ",", "image_size", ")", ",", "PILImage", ".", "BOX", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.perturbations.elastic_transform": [[407, 457], ["tuple", "numpy.float32", "cv2.getAffineTransform", "cv2.warpAffine", "numpy.meshgrid", "numpy.array", "numpy.float32", "min", "numpy.random.uniform().astype", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.reshape", "numpy.reshape", "numpy.reshape", "numpy.clip", "scipy.ndimage.interpolation.map_coordinates().reshape", "numpy.random.uniform", "skimage.filters.gaussian", "skimage.filters.gaussian", "numpy.random.uniform", "numpy.random.uniform", "scipy.ndimage.interpolation.map_coordinates"], "function", ["None"], ["", "def", "elastic_transform", "(", "image", ",", "severity_params", ",", "image_size", ")", ":", "\n", "    ", "c", "=", "tuple", "(", "image_size", "*", "param", "for", "param", "in", "severity_params", ")", "\n", "\n", "image", "=", "np", ".", "array", "(", "image", ",", "dtype", "=", "np", ".", "float32", ")", "/", "255.0", "\n", "shape", "=", "image", ".", "shape", "\n", "shape_size", "=", "shape", "[", ":", "2", "]", "\n", "\n", "# random affine", "\n", "center_square", "=", "np", ".", "float32", "(", "shape_size", ")", "//", "2", "\n", "square_size", "=", "min", "(", "shape_size", ")", "//", "3", "\n", "pts1", "=", "np", ".", "float32", "(", "\n", "[", "\n", "center_square", "+", "square_size", ",", "\n", "[", "center_square", "[", "0", "]", "+", "square_size", ",", "center_square", "[", "1", "]", "-", "square_size", "]", ",", "\n", "center_square", "-", "square_size", ",", "\n", "]", "\n", ")", "\n", "pts2", "=", "pts1", "+", "np", ".", "random", ".", "uniform", "(", "-", "c", "[", "2", "]", ",", "c", "[", "2", "]", ",", "size", "=", "pts1", ".", "shape", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "M", "=", "cv2", ".", "getAffineTransform", "(", "pts1", ",", "pts2", ")", "\n", "image", "=", "cv2", ".", "warpAffine", "(", "\n", "image", ",", "M", ",", "shape_size", "[", ":", ":", "-", "1", "]", ",", "borderMode", "=", "cv2", ".", "BORDER_REFLECT_101", "\n", ")", "\n", "\n", "dx", "=", "(", "\n", "gaussian", "(", "\n", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ",", "size", "=", "shape", "[", ":", "2", "]", ")", ",", "c", "[", "1", "]", ",", "mode", "=", "\"reflect\"", ",", "truncate", "=", "3", "\n", ")", "\n", "*", "c", "[", "0", "]", "\n", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "dy", "=", "(", "\n", "gaussian", "(", "\n", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ",", "size", "=", "shape", "[", ":", "2", "]", ")", ",", "c", "[", "1", "]", ",", "mode", "=", "\"reflect\"", ",", "truncate", "=", "3", "\n", ")", "\n", "*", "c", "[", "0", "]", "\n", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "dx", ",", "dy", "=", "dx", "[", "...", ",", "np", ".", "newaxis", "]", ",", "dy", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "\n", "x", ",", "y", ",", "z", "=", "np", ".", "meshgrid", "(", "np", ".", "arange", "(", "shape", "[", "1", "]", ")", ",", "np", ".", "arange", "(", "shape", "[", "0", "]", ")", ",", "np", ".", "arange", "(", "shape", "[", "2", "]", ")", ")", "\n", "indices", "=", "(", "\n", "np", ".", "reshape", "(", "y", "+", "dy", ",", "(", "-", "1", ",", "1", ")", ")", ",", "\n", "np", ".", "reshape", "(", "x", "+", "dx", ",", "(", "-", "1", ",", "1", ")", ")", ",", "\n", "np", ".", "reshape", "(", "z", ",", "(", "-", "1", ",", "1", ")", ")", ",", "\n", ")", "\n", "return", "(", "\n", "np", ".", "clip", "(", "\n", "map_coordinates", "(", "image", ",", "indices", ",", "order", "=", "1", ",", "mode", "=", "\"reflect\"", ")", ".", "reshape", "(", "shape", ")", ",", "\n", "0", ",", "\n", "1", ",", "\n", ")", "\n", "*", "255", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.transform.ImageJitter.__init__": [[19, 22], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "transform_params", ")", ":", "\n", "        ", "self", ".", "transforms", "=", "[", "\n", "(", "TRANSFORM_TYPES", "[", "k", "]", ",", "transform_params", "[", "k", "]", ")", "for", "k", "in", "transform_params", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.transform.ImageJitter.__call__": [[24, 33], ["torch.rand", "enumerate", "len", "transformer().enhance().convert", "transformer().enhance", "transformer"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "out", "=", "img", "\n", "random_tensor", "=", "torch", ".", "rand", "(", "len", "(", "self", ".", "transforms", ")", ")", "\n", "\n", "for", "i", ",", "(", "transformer", ",", "alpha", ")", "in", "enumerate", "(", "self", ".", "transforms", ")", ":", "\n", "            ", "r", "=", "alpha", "*", "(", "random_tensor", "[", "i", "]", "*", "2.0", "-", "1.0", ")", "+", "1", "\n", "out", "=", "transformer", "(", "out", ")", ".", "enhance", "(", "r", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.transform.TransformLoader.__init__": [[36, 45], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "image_size", ",", "\n", "normalize_param", "=", "None", ",", "\n", "jitter_param", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "image_size", "=", "image_size", "\n", "self", ".", "normalize_param", "=", "normalize_param", "if", "normalize_param", "else", "NORMALIZE_DEFAULT", "\n", "self", ".", "jitter_param", "=", "jitter_param", "if", "jitter_param", "else", "JITTER_DEFAULT", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.transform.TransformLoader.parse_transform": [[46, 65], ["getattr", "transform.ImageJitter", "ImageJitter.", "ImageJitter.", "ImageJitter.", "ImageJitter.", "ImageJitter.", "int", "int"], "methods", ["None"], ["", "def", "parse_transform", "(", "\n", "self", ",", "transform_type", "\n", ")", ":", "# Returns transformation method from its String name", "\n", "        ", "if", "(", "\n", "transform_type", "==", "\"ImageJitter\"", "\n", ")", ":", "# Change Brightness, Constrast, Color and Sharpness randomly", "\n", "            ", "method", "=", "ImageJitter", "(", "self", ".", "jitter_param", ")", "\n", "return", "method", "\n", "", "method", "=", "getattr", "(", "transforms", ",", "transform_type", ")", "\n", "if", "transform_type", "==", "\"RandomResizedCrop\"", ":", "\n", "            ", "return", "method", "(", "self", ".", "image_size", ")", "\n", "", "elif", "transform_type", "==", "\"CenterCrop\"", ":", "\n", "            ", "return", "method", "(", "self", ".", "image_size", ")", "\n", "", "elif", "transform_type", "==", "\"Resize\"", ":", "\n", "            ", "return", "method", "(", "[", "int", "(", "self", ".", "image_size", "*", "1.15", ")", ",", "int", "(", "self", ".", "image_size", "*", "1.15", ")", "]", ")", "\n", "", "elif", "transform_type", "==", "\"Normalize\"", ":", "\n", "            ", "return", "method", "(", "**", "self", ".", "normalize_param", ")", "\n", "", "else", ":", "\n", "            ", "return", "method", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.transform.TransformLoader.get_composed_transform": [[66, 86], ["torchvision.transforms.Compose", "transforms.Compose.TransformLoader.parse_transform"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.data_tools.transform.TransformLoader.parse_transform"], ["", "", "def", "get_composed_transform", "(", "self", ",", "aug", "=", "False", ")", ":", "# Returns composed transformation", "\n", "        ", "if", "aug", ":", "\n", "            ", "transform_list", "=", "[", "\n", "\"RandomResizedCrop\"", ",", "\n", "\"ImageJitter\"", ",", "\n", "\"RandomHorizontalFlip\"", ",", "\n", "\"ToTensor\"", ",", "\n", "\"Normalize\"", ",", "\n", "]", "\n", "", "else", ":", "\n", "            ", "transform_list", "=", "[", "\n", "\"Resize\"", ",", "\n", "\"CenterCrop\"", ",", "\n", "\"ToTensor\"", ",", "\n", "# \"Normalize\",", "\n", "]", "\n", "\n", "", "transform_funcs", "=", "[", "self", ".", "parse_transform", "(", "x", ")", "for", "x", "in", "transform_list", "]", "\n", "transform", "=", "transforms", ".", "Compose", "(", "transform_funcs", ")", "\n", "return", "transform", "\n", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.utils.episodic_collate_fn": [[11, 54], ["all", "list", "torch.cat", "torch.tensor", "torch.cat", "torch.tensor", "set", "int", "int", "x[].unsqueeze", "list.index", "x[].unsqueeze", "list.index"], "function", ["None"], ["\n", "def", "set_device", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    Switch a tensor to GPU if CUDA is available, to CPU otherwise\n    \"\"\"", "\n", "device", "=", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", "\n", "return", "x", ".", "to", "(", "device", "=", "device", ")", "\n", "\n", "\n", "", "def", "plot_episode", "(", "support_images", ",", "query_images", ")", ":", "\n", "    ", "\"\"\"\n    Plot images of an episode, separating support and query images.\n    Args:\n        support_images (torch.Tensor): tensor of multiple-channel support images\n        query_images (torch.Tensor): tensor of multiple-channel query images\n    \"\"\"", "\n", "\n", "def", "matplotlib_imshow", "(", "img", ")", ":", "\n", "        ", "npimg", "=", "img", ".", "numpy", "(", ")", "\n", "plt", ".", "imshow", "(", "np", ".", "transpose", "(", "npimg", ",", "(", "1", ",", "2", ",", "0", ")", ")", ")", "\n", "\n", "", "support_grid", "=", "torchvision", ".", "utils", ".", "make_grid", "(", "support_images", ")", "\n", "matplotlib_imshow", "(", "support_grid", ")", "\n", "plt", ".", "title", "(", "\"support images\"", ")", "\n", "plt", ".", "show", "(", ")", "\n", "query_grid", "=", "torchvision", ".", "utils", ".", "make_grid", "(", "query_images", ")", "\n", "plt", ".", "title", "(", "\"query images\"", ")", "\n", "matplotlib_imshow", "(", "query_grid", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "\n", "", "def", "elucidate_ids", "(", "df", ",", "dataset", ")", ":", "\n", "    ", "\"\"\"\n    Retrieves explicit class and domain names in dataset from their integer index,\n        and returns modified DataFrame\n    Args:\n        df (pd.DataFrame): input DataFrame. Must be the same format as the output of AbstractMetaLearner.get_task_perf()\n        dataset (Dataset): the dataset\n    Returns:\n        pd.DataFrame: output DataFrame with explicit class and domain names\n    \"\"\"", "\n", "return", "df", ".", "replace", "(", "\n", "{", "\n", "\"predicted_label\"", ":", "dataset", ".", "id_to_class", ",", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.utils.get_perturbations": [[57, 91], ["perturbation_specs.items", "dict", "enumerate", "perturbations.append", "id_to_domain_list.append", "functools.partial", "utils.clean_name"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.data_tools.utils.clean_name"], ["\"target_domain\"", ":", "dataset", ".", "id_to_domain", ",", "\n", "}", "\n", ")", "\n", "\n", "\n", "", "def", "get_episodic_loader", "(", "\n", "split", ":", "str", ",", "n_way", ":", "int", ",", "n_source", ":", "int", ",", "n_target", ":", "int", ",", "n_episodes", ":", "int", "\n", ")", ":", "\n", "    ", "dataset", "=", "dataset_config", ".", "DATASET", "(", "\n", "dataset_config", ".", "DATA_ROOT", ",", "split", ",", "dataset_config", ".", "IMAGE_SIZE", "\n", ")", "\n", "sampler", "=", "dataset", ".", "get_sampler", "(", ")", "(", "\n", "n_way", "=", "n_way", ",", "\n", "n_source", "=", "n_source", ",", "\n", "n_target", "=", "n_target", ",", "\n", "n_episodes", "=", "n_episodes", ",", "\n", ")", "\n", "return", "(", "\n", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_sampler", "=", "sampler", ",", "\n", "num_workers", "=", "12", ",", "\n", "pin_memory", "=", "False", ",", "# SY changed", "\n", "collate_fn", "=", "episodic_collate_fn", ",", "\n", ")", ",", "\n", "dataset", ",", "\n", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.utils.clean_name": [[93, 95], ["re.sub"], "function", ["None"], []], "home.repos.pwc.inspect_result.772922440_pgada.data_tools.utils.load_image_as_array": [[97, 100], ["numpy.asarray", "cv2.resize", "cv2.imread"], "function", ["None"], []], "home.repos.pwc.inspect_result.772922440_pgada.datasets.mini_imagenet_c.MiniImageNetC.__init__": [[26, 73], ["src.data_tools.transform.TransformLoader().get_composed_transform", "src.data_tools.transform.TransformLoader().get_composed_transform", "torchvision.datasets.VisionDataset.__init__", "src.data_tools.utils.get_perturbations", "pandas.read_csv().assign", "numpy.stack", "pandas.read_csv().assign.class_name.unique", "dict", "list", "open", "json.load", "enumerate", "pandas.read_csv().assign.class_name.map", "src.data_tools.transform.TransformLoader", "src.data_tools.transform.TransformLoader", "mini_imagenet_c.MiniImageNetC.id_to_domain.items", "pandas.read_csv", "src.data_tools.utils.load_image_as_array", "mini_imagenet_c.MiniImageNetC.id_to_class.items", "df.apply", "tqdm.tqdm.tqdm", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.data_tools.transform.TransformLoader.get_composed_transform", "home.repos.pwc.inspect_result.772922440_pgada.data_tools.transform.TransformLoader.get_composed_transform", "home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__", "home.repos.pwc.inspect_result.772922440_pgada.data_tools.utils.get_perturbations", "home.repos.pwc.inspect_result.772922440_pgada.data_tools.utils.load_image_as_array"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "root", ":", "str", ",", "\n", "split", ":", "str", ",", "\n", "image_size", ":", "int", ",", "\n", "target_transform", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "augmentation", ":", "Optional", "[", "Callable", "]", "=", "False", ",", "\n", "two_stream", ":", "Optional", "[", "Callable", "]", "=", "False", ",", "\n", "SIMCLR_val", ":", "bool", "=", "False", "\n", ")", ":", "\n", "        ", "self", ".", "two_stream", "=", "two_stream", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "SIMCLR_val", "=", "SIMCLR_val", "\n", "transform", "=", "TransformLoader", "(", "image_size", ")", ".", "get_composed_transform", "(", "aug", "=", "augmentation", ")", "\n", "self", ".", "transform_test", "=", "TransformLoader", "(", "image_size", ")", ".", "get_composed_transform", "(", "aug", "=", "False", ")", "\n", "\n", "super", "(", "MiniImageNetC", ",", "self", ")", ".", "__init__", "(", "\n", "root", ",", "transform", "=", "transform", ",", "target_transform", "=", "target_transform", "\n", ")", "\n", "# We need to write this import here (and not at the top) to avoid cyclic imports", "\n", "from", "configs", ".", "dataset_config", "import", "SPECS_ROOT", "\n", "\n", "# Get perturbations", "\n", "with", "open", "(", "SPECS_ROOT", "/", "f\"{split}.json\"", ",", "\"r\"", ")", "as", "file", ":", "\n", "            ", "split_specs", "=", "json", ".", "load", "(", "file", ")", "\n", "", "self", ".", "perturbations", ",", "self", ".", "id_to_domain", "=", "get_perturbations", "(", "\n", "split_specs", "[", "\"perturbations\"", "]", ",", "PERTURBATION_PARAMS", ",", "image_size", "\n", ")", "\n", "self", ".", "domain_to_id", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "id_to_domain", ".", "items", "(", ")", "}", "\n", "\n", "# Get images and labels", "\n", "images_df", "=", "pd", ".", "read_csv", "(", "SPECS_ROOT", "/", "f\"{split}_images.csv\"", ")", ".", "assign", "(", "\n", "image_paths", "=", "lambda", "df", ":", "df", ".", "apply", "(", "\n", "lambda", "row", ":", "os", ".", "path", ".", "join", "(", "root", ",", "*", "row", ")", ",", "axis", "=", "1", "\n", ")", "\n", ")", "\n", "self", ".", "images", "=", "np", ".", "stack", "(", "\n", "[", "\n", "load_image_as_array", "(", "image_path", ",", "image_size", ")", "\n", "for", "image_path", "in", "tqdm", "(", "images_df", ".", "image_paths", ")", "\n", "]", "\n", ")", "\n", "\n", "self", ".", "class_list", "=", "images_df", ".", "class_name", ".", "unique", "(", ")", "\n", "self", ".", "id_to_class", "=", "dict", "(", "enumerate", "(", "self", ".", "class_list", ")", ")", "\n", "self", ".", "class_to_id", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "id_to_class", ".", "items", "(", ")", "}", "\n", "self", ".", "labels", "=", "list", "(", "images_df", ".", "class_name", ".", "map", "(", "self", ".", "class_to_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.datasets.mini_imagenet_c.MiniImageNetC.__len__": [[74, 76], ["len", "len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "images", ")", "*", "len", "(", "self", ".", "perturbations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.datasets.mini_imagenet_c.MiniImageNetC.__getitem__": [[77, 108], ["len", "len", "PIL.Image.fromarray", "isinstance", "mini_imagenet_c.MiniImageNetC.transform", "mini_imagenet_c.MiniImageNetC.transform", "mini_imagenet_c.MiniImageNetC.target_transform", "PIL.Image.fromarray.astype", "PIL.Image.fromarray", "mini_imagenet_c.MiniImageNetC.transform_test", "mini_imagenet_c.MiniImageNetC.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "original_data_index", "=", "item", "//", "len", "(", "self", ".", "perturbations", ")", "\n", "perturbation_index", "=", "item", "%", "len", "(", "self", ".", "perturbations", ")", "\n", "\n", "img", ",", "label", "=", "(", "\n", "Image", ".", "fromarray", "(", "self", ".", "images", "[", "original_data_index", "]", ")", ",", "\n", "self", ".", "labels", "[", "original_data_index", "]", ",", "\n", ")", "\n", "\n", "img_p", "=", "self", ".", "perturbations", "[", "perturbation_index", "]", "(", "img", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "# TODO: some perturbations output arrays, some output images. We need to clean that.", "\n", "            ", "if", "isinstance", "(", "img_p", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "img_p", "=", "img_p", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "img_p", "=", "Image", ".", "fromarray", "(", "img_p", ")", "\n", "", "img_p", "=", "self", ".", "transform", "(", "img_p", ")", "\n", "img1", "=", "self", ".", "transform_test", "(", "img", ")", "if", "self", ".", "SIMCLR_val", "else", "self", ".", "transform", "(", "img", ")", "\n", "img2", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "label", "=", "self", ".", "target_transform", "(", "label", ")", "\n", "\n", "", "if", "self", ".", "two_stream", ":", "\n", "            ", "if", "self", ".", "split", "==", "\"test\"", ":", "\n", "                ", "return", "img1", ",", "img2", ",", "label", ",", "perturbation_index", "\n", "", "else", ":", "\n", "                ", "return", "img1", ",", "img_p", ",", "label", ",", "perturbation_index", "\n", "", "", "else", ":", "\n", "            ", "return", "img_p", ",", "label", ",", "perturbation_index", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.datasets.mini_imagenet_c.MiniImageNetC.get_sampler": [[109, 111], ["functools.partial"], "methods", ["None"], ["", "", "def", "get_sampler", "(", "self", ")", ":", "\n", "        ", "return", "partial", "(", "BeforeCorruptionSampler", ",", "self", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.datasets.tiered_imagenet_c.TieredImageNetC.__init__": [[26, 99], ["src.data_tools.transform.TransformLoader().get_composed_transform", "torchvision.datasets.VisionDataset.__init__", "pathlib.Path", "dict", "src.data_tools.utils.get_perturbations", "loguru.logger.info", "open", "json.load", "enumerate", "pickle_path.exists", "tiered_imagenet_c.TieredImageNetC.get_images_and_labels", "src.data_tools.transform.TransformLoader", "tiered_imagenet_c.TieredImageNetC.id_to_class.items", "tiered_imagenet_c.TieredImageNetC.id_to_domain.items", "pandas.read_pickle", "pandas.concat().sort_values().reset_index", "tiered_imagenet_c.TieredImageNetC.images_df.to_pickle", "pandas.DataFrame().merge", "pandas.DataFrame", "pandas.concat().sort_values", "pandas.DataFrame", "list", "pandas.concat", "tiered_imagenet_c.TieredImageNetC.id_to_domain.keys", "os.path.basename", "pandas.DataFrame().assign", "tqdm.tqdm.tqdm", "pandas.DataFrame", "tiered_imagenet_c.TieredImageNetC.class_to_id.items"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.data_tools.transform.TransformLoader.get_composed_transform", "home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__", "home.repos.pwc.inspect_result.772922440_pgada.data_tools.utils.get_perturbations", "home.repos.pwc.inspect_result.772922440_pgada.datasets.tiered_imagenet_c.TieredImageNetC.get_images_and_labels"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "root", ":", "str", ",", "\n", "split", ":", "str", ",", "\n", "image_size", ":", "int", ",", "\n", "target_transform", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "load_corrupted_dataset", "=", "False", ",", "\n", ")", ":", "\n", "        ", "transform", "=", "TransformLoader", "(", "image_size", ")", ".", "get_composed_transform", "(", "aug", "=", "False", ")", "\n", "super", "(", "TieredImageNetC", ",", "self", ")", ".", "__init__", "(", "\n", "root", ",", "transform", "=", "transform", ",", "target_transform", "=", "target_transform", "\n", ")", "\n", "# We need to write this import here (and not at the top) to avoid cyclic imports", "\n", "from", "configs", ".", "dataset_config", "import", "SPECS_ROOT", "\n", "\n", "with", "open", "(", "SPECS_ROOT", "/", "f\"{split}.json\"", ",", "\"r\"", ")", "as", "file", ":", "\n", "            ", "split_specs", "=", "json", ".", "load", "(", "file", ")", "\n", "\n", "", "self", ".", "root", "=", "Path", "(", "root", ")", "\n", "self", ".", "class_list", "=", "split_specs", "[", "\"class_names\"", "]", "\n", "self", ".", "id_to_class", "=", "dict", "(", "enumerate", "(", "self", ".", "class_list", ")", ")", "\n", "self", ".", "class_to_id", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "id_to_class", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "perturbations", ",", "self", ".", "id_to_domain", "=", "get_perturbations", "(", "\n", "split_specs", "[", "\"perturbations\"", "]", ",", "PERTURBATION_PARAMS", ",", "image_size", "\n", ")", "\n", "self", ".", "domain_to_id", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "id_to_domain", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "load_corrupted_dataset", "=", "load_corrupted_dataset", "\n", "logger", ".", "info", "(", "f\"Retrieving {split} images ...\"", ")", "\n", "if", "self", ".", "load_corrupted_dataset", ":", "\n", "            ", "pickle_path", "=", "self", ".", "root", "/", "f\"{split}.pkl\"", "\n", "if", "pickle_path", ".", "exists", "(", ")", ":", "\n", "                ", "self", ".", "images_df", "=", "pd", ".", "read_pickle", "(", "pickle_path", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "images_df", "=", "(", "\n", "pd", ".", "concat", "(", "\n", "[", "\n", "pd", ".", "DataFrame", "(", "\n", "[", "\n", "[", "\n", "img_path", ".", "parts", "[", "-", "1", "]", ",", "\n", "self", ".", "domain_to_id", "[", "img_path", ".", "parts", "[", "-", "2", "]", "]", ",", "\n", "]", "\n", "for", "img_path", "in", "(", "self", ".", "root", "/", "class_name", ")", ".", "glob", "(", "\n", "\"*/*.png\"", "\n", ")", "\n", "]", ",", "\n", "columns", "=", "[", "\"img_name\"", ",", "\"domain_id\"", "]", ",", "\n", ")", ".", "assign", "(", "class_id", "=", "class_id", ")", "\n", "for", "class_name", ",", "class_id", "in", "tqdm", "(", "\n", "self", ".", "class_to_id", ".", "items", "(", ")", ",", "unit", "=", "\"classes\"", "\n", ")", "\n", "]", ",", "\n", "ignore_index", "=", "True", ",", "\n", ")", "\n", ".", "sort_values", "(", "by", "=", "[", "\"class_id\"", ",", "\"img_name\"", ",", "\"domain_id\"", "]", ")", "\n", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", ")", "\n", "self", ".", "images_df", ".", "to_pickle", "(", "pickle_path", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "images", ",", "self", ".", "labels", "=", "self", ".", "get_images_and_labels", "(", ")", "\n", "self", ".", "images_df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "\"class_id\"", ":", "self", ".", "labels", ",", "\n", "\"img_name\"", ":", "[", "os", ".", "path", ".", "basename", "(", "x", ")", "for", "x", "in", "self", ".", "images", "]", ",", "\n", "\"key\"", ":", "1", ",", "\n", "}", "\n", ")", ".", "merge", "(", "\n", "pd", ".", "DataFrame", "(", "{", "\"domain_id\"", ":", "list", "(", "self", ".", "id_to_domain", ".", "keys", "(", ")", ")", ",", "\"key\"", ":", "1", "}", ")", ",", "\n", "on", "=", "\"key\"", ",", "\n", ")", "[", "\n", "[", "\"class_id\"", ",", "\"domain_id\"", ",", "\"img_name\"", "]", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.datasets.tiered_imagenet_c.TieredImageNetC.__len__": [[101, 103], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "images_df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.datasets.tiered_imagenet_c.TieredImageNetC.__getitem__": [[104, 133], ["tiered_imagenet_c.TieredImageNetC.transform", "PIL.Image.open().convert", "isinstance", "tiered_imagenet_c.TieredImageNetC.target_transform", "int", "int", "int", "PIL.Image.open", "torchvision.transforms.Resize", "PIL.Image.fromarray.astype", "PIL.Image.fromarray", "PIL.Image.open", "torchvision.transforms.ToTensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "img_name", "=", "self", ".", "images_df", ".", "img_name", ".", "iloc", "[", "int", "(", "item", ")", "]", "\n", "label", "=", "self", ".", "images_df", ".", "class_id", ".", "iloc", "[", "int", "(", "item", ")", "]", "\n", "domain_id", "=", "self", ".", "images_df", ".", "domain_id", ".", "iloc", "[", "int", "(", "item", ")", "]", "\n", "\n", "if", "self", ".", "load_corrupted_dataset", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "\n", "Image", ".", "open", "(", "\n", "self", ".", "root", "\n", "/", "self", ".", "id_to_class", "[", "label", "]", "\n", "/", "self", ".", "id_to_domain", "[", "domain_id", "]", "\n", "/", "img_name", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "self", ".", "root", "/", "self", ".", "id_to_class", "[", "label", "]", "/", "img_name", ")", ".", "convert", "(", "\n", "\"RGB\"", "\n", ")", "\n", "img", "=", "transforms", ".", "Resize", "(", "(", "224", ",", "224", ")", ")", "(", "img", ")", "\n", "img", "=", "self", ".", "perturbations", "[", "domain_id", "]", "(", "img", ")", "\n", "if", "isinstance", "(", "img", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "img", "=", "img", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "", "img", "=", "transforms", ".", "ToTensor", "(", ")", "(", "img", ")", ".", "type", "(", "torch", ".", "float32", ")", "\n", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "label", "=", "self", ".", "target_transform", "(", "label", ")", "\n", "\n", "", "return", "img", ",", "label", ",", "domain_id", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.datasets.tiered_imagenet_c.TieredImageNetC.get_images_and_labels": [[134, 155], ["enumerate", "str", "len", "image_path.is_file"], "methods", ["None"], ["", "def", "get_images_and_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Provides image paths and corresponding labels, as expected to define our VisionDataset objects.\n        Returns:\n            tuple(list(str), list(int): respectively the list of all paths to images belonging in the split defined in\n            the input JSON file, and their class ids\n        \"\"\"", "\n", "\n", "image_names", "=", "[", "]", "\n", "image_labels", "=", "[", "]", "\n", "\n", "for", "class_id", ",", "class_name", "in", "enumerate", "(", "self", ".", "class_list", ")", ":", "\n", "            ", "class_images_paths", "=", "[", "\n", "str", "(", "image_path", ")", "\n", "for", "image_path", "in", "(", "self", ".", "root", "/", "class_name", ")", ".", "glob", "(", "\"*\"", ")", "\n", "if", "image_path", ".", "is_file", "(", ")", "\n", "]", "\n", "image_names", "+=", "class_images_paths", "\n", "image_labels", "+=", "len", "(", "class_images_paths", ")", "*", "[", "class_id", "]", "\n", "\n", "", "return", "image_names", ",", "image_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.datasets.tiered_imagenet_c.TieredImageNetC.get_sampler": [[156, 161], ["functools.partial", "functools.partial"], "methods", ["None"], ["", "def", "get_sampler", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "load_corrupted_dataset", ":", "\n", "            ", "return", "partial", "(", "AfterCorruptionSampler", ",", "self", ")", "\n", "", "else", ":", "\n", "            ", "return", "partial", "(", "BeforeCorruptionSampler", ",", "self", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.datasets.femnist.FEMNIST.__init__": [[18, 51], ["src.data_tools.transform.TransformLoader().get_composed_transform", "src.data_tools.transform.TransformLoader().get_composed_transform", "torchvision.datasets.VisionDataset.__init__", "pathlib.Path", "numpy.load", "pandas.read_csv", "dict", "dict", "enumerate", "enumerate", "src.data_tools.transform.TransformLoader", "src.data_tools.transform.TransformLoader", "femnist.FEMNIST.meta_data.class_name.sort_values().unique", "femnist.FEMNIST.id_to_class.items", "femnist.FEMNIST.meta_data.user.unique", "femnist.FEMNIST.id_to_domain.items", "femnist.FEMNIST.meta_data.class_name.sort_values"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.data_tools.transform.TransformLoader.get_composed_transform", "home.repos.pwc.inspect_result.772922440_pgada.data_tools.transform.TransformLoader.get_composed_transform", "home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "root", ":", "str", ",", "\n", "split", ":", "str", ",", "\n", "image_size", ":", "int", "=", "28", ",", "\n", "target_transform", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "augmentation", ":", "Optional", "[", "Callable", "]", "=", "False", ",", "\n", "two_stream", "=", "False", ",", "\n", "SIMCLR_val", "=", "False", "\n", ")", ":", "\n", "        ", "self", ".", "two_stream", "=", "two_stream", "\n", "self", ".", "SIMCLR_val", "=", "SIMCLR_val", "\n", "transform", "=", "TransformLoader", "(", "image_size", ")", ".", "get_composed_transform", "(", "aug", "=", "augmentation", ")", "\n", "self", ".", "transform_test", "=", "TransformLoader", "(", "image_size", ")", ".", "get_composed_transform", "(", "aug", "=", "False", ")", "\n", "\n", "super", "(", "FEMNIST", ",", "self", ")", ".", "__init__", "(", "\n", "root", ",", "transform", "=", "transform", ",", "target_transform", "=", "target_transform", "\n", ")", "\n", "self", ".", "root", "=", "Path", "(", "root", ")", "\n", "\n", "self", ".", "images", "=", "np", ".", "load", "(", "self", ".", "root", "/", "f\"{split}.npy\"", ")", "\n", "\n", "# We need to write this import here (and not at the top) to avoid cyclic imports", "\n", "from", "configs", ".", "dataset_config", "import", "SPECS_ROOT", "\n", "\n", "self", ".", "meta_data", "=", "pd", ".", "read_csv", "(", "SPECS_ROOT", "/", "f\"{split}.csv\"", ",", "index_col", "=", "0", ")", "\n", "\n", "self", ".", "id_to_class", "=", "dict", "(", "\n", "enumerate", "(", "self", ".", "meta_data", ".", "class_name", ".", "sort_values", "(", ")", ".", "unique", "(", ")", ")", "\n", ")", "\n", "self", ".", "class_to_id", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "id_to_class", ".", "items", "(", ")", "}", "\n", "self", ".", "id_to_domain", "=", "dict", "(", "enumerate", "(", "self", ".", "meta_data", ".", "user", ".", "unique", "(", ")", ")", ")", "\n", "self", ".", "domain_to_id", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "id_to_domain", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.datasets.femnist.FEMNIST.__len__": [[52, 54], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.datasets.femnist.FEMNIST.__getitem__": [[55, 82], ["femnist.FEMNIST.target_transform", "femnist.FEMNIST.transform_test", "torchvision.transforms.ToPILImage", "femnist.FEMNIST.transform_test", "femnist.FEMNIST.transform", "femnist.FEMNIST.transform", "femnist.FEMNIST.transform", "int", "int", "torchvision.transforms.ToTensor", "int"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "label", "=", "self", ".", "class_to_id", "[", "self", ".", "meta_data", ".", "class_name", ".", "iloc", "[", "int", "(", "item", ")", "]", "]", "\n", "domain_id", "=", "self", ".", "domain_to_id", "[", "self", ".", "meta_data", ".", "user", ".", "iloc", "[", "int", "(", "item", ")", "]", "]", "\n", "\n", "img", "=", "transforms", ".", "ToTensor", "(", ")", "(", "self", ".", "images", "[", "int", "(", "item", ")", "]", ")", ".", "repeat", "(", "3", ",", "1", ",", "1", ")", ".", "float", "(", ")", "\n", "img", "=", "transforms", ".", "ToPILImage", "(", ")", "(", "img", ")", ".", "convert", "(", "'RGB'", ")", "\n", "# img = self.transform(img)", "\n", "# if self.transform is not None:", "\n", "#     img = self.images[int(item)]", "\n", "#     # TODO: some perturbations output arrays, some output images. We need to clean that.", "\n", "#     if isinstance(img, np.ndarray):", "\n", "#         # img = img.astype(np.uint8)", "\n", "#         img = Image.fromarray(img, 'RGB')", "\n", "#     img = self.transform(img)", "\n", "# else:", "\n", "#     img = self.transform(self.images[int(item)]).repeat(3, 1, 1).float()", "\n", "\n", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "label", "=", "self", ".", "target_transform", "(", "label", ")", "\n", "\n", "", "if", "self", ".", "two_stream", ":", "\n", "            ", "if", "self", ".", "SIMCLR_val", ":", "\n", "                ", "return", "self", ".", "transform_test", "(", "img", ")", ",", "self", ".", "transform", "(", "img", ")", ",", "label", ",", "domain_id", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "transform", "(", "img", ")", ",", "self", ".", "transform", "(", "img", ")", ",", "label", ",", "domain_id", "\n", "", "", "else", ":", "\n", "            ", "return", "self", ".", "transform_test", "(", "img", ")", ",", "label", ",", "domain_id", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.datasets.femnist.FEMNIST.get_sampler": [[83, 85], ["functools.partial"], "methods", ["None"], ["", "", "def", "get_sampler", "(", "self", ")", ":", "\n", "        ", "return", "partial", "(", "GroupedDatasetSampler", ",", "self", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.datasets.cifar_c_meta.CIFAR100CMeta.__init__": [[18, 87], ["src.data_tools.transform.TransformLoader().get_composed_transform", "src.data_tools.transform.TransformLoader().get_composed_transform", "torchvision.datasets.CIFAR100.__init__", "cifar_c_meta.CIFAR100CMeta._load_meta", "numpy.vstack().reshape", "cifar_c_meta.CIFAR100CMeta.images.transpose", "src.data_tools.utils.get_perturbations", "cifar_c_meta.CIFAR100CMeta.download", "cifar_c_meta.CIFAR100CMeta._check_integrity", "RuntimeError", "open", "json.load", "os.path.join", "src.data_tools.transform.TransformLoader", "src.data_tools.transform.TransformLoader", "cifar_c_meta.CIFAR100CMeta.class_to_idx.items", "open", "pickle.load", "cifar_c_meta.CIFAR100CMeta.images.append", "cifar_c_meta.CIFAR100CMeta.labels.extend", "numpy.vstack", "range", "len", "cifar_c_meta.CIFAR100CMeta.class_to_idx.values"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.data_tools.transform.TransformLoader.get_composed_transform", "home.repos.pwc.inspect_result.772922440_pgada.data_tools.transform.TransformLoader.get_composed_transform", "home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__", "home.repos.pwc.inspect_result.772922440_pgada.data_tools.utils.get_perturbations"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "root", ":", "str", ",", "\n", "split", ":", "str", ",", "\n", "image_size", ":", "int", ",", "\n", "target_transform", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "download", ":", "bool", "=", "True", ",", "# Siyang Changed", "\n", "augmentation", ":", "Optional", "[", "Callable", "]", "=", "False", ",", "\n", "two_stream", ":", "Optional", "[", "Callable", "]", "=", "False", ",", "\n", "SIMCLR_val", ":", "bool", "=", "False", "\n", ")", ":", "\n", "        ", "self", ".", "two_stream", "=", "two_stream", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "SIMCLR_val", "=", "SIMCLR_val", "\n", "transform", "=", "TransformLoader", "(", "image_size", ")", ".", "get_composed_transform", "(", "aug", "=", "augmentation", ")", "\n", "self", ".", "transform_test", "=", "TransformLoader", "(", "image_size", ")", ".", "get_composed_transform", "(", "aug", "=", "False", ")", "\n", "\n", "super", "(", "CIFAR10", ",", "self", ")", ".", "__init__", "(", "\n", "root", ",", "transform", "=", "transform", ",", "target_transform", "=", "target_transform", "\n", ")", "\n", "\n", "if", "download", ":", "\n", "            ", "self", ".", "download", "(", ")", "\n", "\n", "", "if", "not", "self", ".", "_check_integrity", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Dataset not found or corrupted.\"", "\n", "+", "\" You can use download=True to download it\"", "\n", ")", "\n", "\n", "", "downloaded_list", "=", "self", ".", "train_list", "+", "self", ".", "test_list", "\n", "\n", "self", ".", "_load_meta", "(", ")", "\n", "\n", "# We need to write this import here (and not at the top) to avoid cyclic imports", "\n", "from", "configs", ".", "dataset_config", "import", "SPECS_ROOT", "\n", "\n", "with", "open", "(", "SPECS_ROOT", "/", "f\"{split}.json\"", ",", "\"r\"", ")", "as", "file", ":", "\n", "            ", "self", ".", "split_specs", "=", "json", ".", "load", "(", "file", ")", "\n", "\n", "", "self", ".", "class_to_idx", "=", "{", "\n", "class_name", ":", "self", ".", "class_to_idx", "[", "class_name", "]", "\n", "for", "class_name", "in", "self", ".", "split_specs", "[", "\"class_names\"", "]", "\n", "}", "\n", "self", ".", "id_to_class", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "class_to_idx", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "images", ":", "Any", "=", "[", "]", "\n", "self", ".", "labels", "=", "[", "]", "\n", "\n", "# now load the picked numpy arrays", "\n", "for", "file_name", ",", "checksum", "in", "downloaded_list", ":", "\n", "            ", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ",", "file_name", ")", "\n", "with", "open", "(", "file_path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "                ", "entry", "=", "pickle", ".", "load", "(", "f", ",", "encoding", "=", "\"latin1\"", ")", "\n", "items_to_keep", "=", "[", "\n", "item", "\n", "for", "item", "in", "range", "(", "len", "(", "entry", "[", "\"data\"", "]", ")", ")", "\n", "if", "entry", "[", "\"fine_labels\"", "]", "[", "item", "]", "in", "self", ".", "class_to_idx", ".", "values", "(", ")", "\n", "]", "\n", "self", ".", "images", ".", "append", "(", "[", "entry", "[", "\"data\"", "]", "[", "item", "]", "for", "item", "in", "items_to_keep", "]", ")", "\n", "self", ".", "labels", ".", "extend", "(", "\n", "[", "entry", "[", "\"fine_labels\"", "]", "[", "item", "]", "for", "item", "in", "items_to_keep", "]", "\n", ")", "\n", "\n", "", "", "self", ".", "images", "=", "np", ".", "vstack", "(", "self", ".", "images", ")", ".", "reshape", "(", "-", "1", ",", "3", ",", "32", ",", "32", ")", "\n", "self", ".", "images", "=", "self", ".", "images", ".", "transpose", "(", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "# convert to HWC", "\n", "\n", "self", ".", "perturbations", ",", "self", ".", "id_to_domain", "=", "get_perturbations", "(", "\n", "self", ".", "split_specs", "[", "\"perturbations\"", "]", ",", "PERTURBATION_PARAMS", ",", "image_size", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.datasets.cifar_c_meta.CIFAR100CMeta.__len__": [[89, 91], ["len", "len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "images", ")", "*", "len", "(", "self", ".", "perturbations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.datasets.cifar_c_meta.CIFAR100CMeta.__getitem__": [[92, 123], ["len", "len", "PIL.Image.fromarray", "isinstance", "cifar_c_meta.CIFAR100CMeta.transform", "cifar_c_meta.CIFAR100CMeta.transform", "cifar_c_meta.CIFAR100CMeta.target_transform", "PIL.Image.fromarray.astype", "PIL.Image.fromarray", "cifar_c_meta.CIFAR100CMeta.transform_test", "cifar_c_meta.CIFAR100CMeta.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "original_data_index", "=", "item", "//", "len", "(", "self", ".", "perturbations", ")", "\n", "perturbation_index", "=", "item", "%", "len", "(", "self", ".", "perturbations", ")", "\n", "\n", "img", ",", "label", "=", "(", "\n", "Image", ".", "fromarray", "(", "self", ".", "images", "[", "original_data_index", "]", ")", ",", "\n", "self", ".", "labels", "[", "original_data_index", "]", ",", "\n", ")", "\n", "\n", "img_p", "=", "self", ".", "perturbations", "[", "perturbation_index", "]", "(", "img", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "# TODO: some perturbations output arrays, some output images. We need to clean that.", "\n", "            ", "if", "isinstance", "(", "img_p", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "img_p", "=", "img_p", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "img_p", "=", "Image", ".", "fromarray", "(", "img_p", ")", "\n", "", "img_p", "=", "self", ".", "transform", "(", "img_p", ")", "\n", "img1", "=", "self", ".", "transform_test", "(", "img", ")", "if", "self", ".", "SIMCLR_val", "else", "self", ".", "transform", "(", "img", ")", "\n", "img2", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "label", "=", "self", ".", "target_transform", "(", "label", ")", "\n", "\n", "", "if", "self", ".", "two_stream", ":", "\n", "            ", "if", "self", ".", "split", "==", "\"test\"", ":", "\n", "                ", "return", "img1", ",", "img2", ",", "label", ",", "perturbation_index", "\n", "", "else", ":", "\n", "                ", "return", "img1", ",", "img_p", ",", "label", ",", "perturbation_index", "\n", "", "", "else", ":", "\n", "            ", "return", "img_p", ",", "label", ",", "perturbation_index", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.datasets.cifar_c_meta.CIFAR100CMeta.get_sampler": [[124, 126], ["functools.partial"], "methods", ["None"], ["", "", "def", "get_sampler", "(", "self", ")", ":", "\n", "        ", "return", "partial", "(", "BeforeCorruptionSampler", ",", "self", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.datasets.preprocess_femnist.main": [[14, 50], ["click.option", "click.option", "click.option", "click.option", "click.command", "specs_dir.glob", "numpy.save", "loguru.logger.info", "pathlib.Path", "pathlib.Path", "pandas.read_csv", "numpy.stack", "numpy.asarray", "PIL.Image.open().convert().resize", "len", "str", "PIL.Image.open().convert", "PIL.Image.open"], "function", ["None"], ["@", "click", ".", "option", "(", "\n", "\"--specs-dir\"", ",", "\n", "help", "=", "\"Directory where the CSV specification files for train, val and test are located\"", ",", "\n", "type", "=", "Path", ",", "\n", "default", "=", "Path", "(", "\"configs/dataset_specs/femnist\"", ")", ",", "\n", ")", "\n", "@", "click", ".", "option", "(", "\n", "\"--save-dir\"", ",", "\n", "help", "=", "\"Where to save the data files\"", ",", "\n", "type", "=", "Path", ",", "\n", "default", "=", "Path", "(", "\"data/femnist\"", ")", ",", "\n", ")", "\n", "@", "click", ".", "option", "(", "\n", "\"--mode\"", ",", "\n", "help", "=", "\"Image mode (see https://pillow.readthedocs.io/en/stable/handbook/concepts.html)\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"L\"", ",", "\n", ")", "\n", "@", "click", ".", "option", "(", "\n", "\"--size\"", ",", "\n", "help", "=", "\"Size of square image\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "28", ",", "\n", ")", "\n", "@", "click", ".", "command", "(", ")", "\n", "def", "main", "(", "specs_dir", ",", "save_dir", ",", "mode", ",", "size", ")", ":", "\n", "    ", "for", "specs_file_path", "in", "specs_dir", ".", "glob", "(", "\"*.csv\"", ")", ":", "\n", "        ", "images_path", "=", "pd", ".", "read_csv", "(", "specs_file_path", ",", "index_col", "=", "0", ")", ".", "img_path", "\n", "images", "=", "[", "\n", "np", ".", "asarray", "(", "Image", ".", "open", "(", "img_path", ")", ".", "convert", "(", "mode", ")", ".", "resize", "(", "(", "size", ",", "size", ")", ")", ")", "/", "255", "\n", "for", "img_path", "in", "images_path", "\n", "]", "\n", "output_path", "=", "save_dir", "/", "f\"{specs_file_path.stem}.npy\"", "\n", "np", ".", "save", "(", "output_path", ",", "np", ".", "stack", "(", "images", ")", ")", "\n", "logger", ".", "info", "(", "\n", "f\"Saved {len(images)} images  from {specs_file_path.name} in {str(output_path)}.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.datasets.write_tieredimagenet_c.main": [[11, 49], ["click.option", "click.option", "click.command", "src.data_tools.datasets.TieredImageNetC", "src.data_tools.datasets.TieredImageNetC", "src.data_tools.datasets.TieredImageNetC", "output_dir.mkdir", "torchvision.transforms.ToPILImage", "write_tieredimagenet_c.main.save_set"], "function", ["None"], ["@", "click", ".", "option", "(", "\n", "\"--input-dir\"", ",", "\n", "help", "=", "\"Path to ImageNet data\"", ",", "\n", "type", "=", "Path", ",", "\n", "default", "=", "Path", "(", "\"/ILSVRC2015/Data/CLS-LOC/train\"", ")", ",", "\n", ")", "\n", "@", "click", ".", "option", "(", "\n", "\"--output-dir\"", ",", "\n", "help", "=", "\"Where to save the tieredImageNet-C dataset\"", ",", "\n", "type", "=", "Path", ",", "\n", "default", "=", "Path", "(", "\"/tiered_imagenet_c\"", ")", ",", "\n", ")", "\n", "@", "click", ".", "command", "(", ")", "\n", "def", "main", "(", "input_dir", ",", "output_dir", ")", ":", "\n", "    ", "train_set", "=", "TieredImageNetC", "(", "input_dir", ",", "\"train\"", ",", "224", ",", "load_corrupted_dataset", "=", "False", ")", "\n", "val_set", "=", "TieredImageNetC", "(", "input_dir", ",", "\"val\"", ",", "224", ",", "load_corrupted_dataset", "=", "False", ")", "\n", "test_set", "=", "TieredImageNetC", "(", "input_dir", ",", "\"test\"", ",", "224", ",", "load_corrupted_dataset", "=", "False", ")", "\n", "\n", "output_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "trans", "=", "transforms", ".", "ToPILImage", "(", ")", "\n", "\n", "def", "save_set", "(", "dataset", ",", "setname", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Writing {setname} set in {output_dir / setname}...\"", ")", "\n", "for", "i", ",", "x", "in", "tqdm", "(", "enumerate", "(", "dataset", ")", ",", "total", "=", "len", "(", "dataset", ")", ")", ":", "\n", "            ", "this_output_dir", "=", "(", "\n", "output_dir", "\n", "/", "setname", "\n", "/", "dataset", ".", "id_to_class", "[", "x", "[", "1", "]", "]", "\n", "/", "dataset", ".", "id_to_domain", "[", "x", "[", "2", "]", "]", "\n", ")", "\n", "this_output_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "trans", "(", "x", "[", "0", "]", ")", ".", "save", "(", "this_output_dir", "/", "f\"{i:08d}.png\"", ",", "format", "=", "\"PNG\"", ")", "\n", "\n", "", "logger", ".", "info", "(", "f\"{setname} set has been written.\"", ")", "\n", "\n", "", "save_set", "(", "train_set", ",", "\"train\"", ")", "\n", "save_set", "(", "val_set", ",", "\"val\"", ")", "\n", "save_set", "(", "test_set", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.samplers.after_corruption_sampler.AfterCorruptionSampler.__init__": [[8, 16], ["list", "list", "after_corruption_sampler.AfterCorruptionSampler.data.class_id.unique", "after_corruption_sampler.AfterCorruptionSampler.data.domain_id.unique"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "n_way", ",", "n_source", ",", "n_target", ",", "n_episodes", ")", ":", "\n", "        ", "self", ".", "data", "=", "dataset", ".", "images_df", "[", "[", "\"class_id\"", ",", "\"domain_id\"", "]", "]", "\n", "self", ".", "class_list", "=", "list", "(", "self", ".", "data", ".", "class_id", ".", "unique", "(", ")", ")", "\n", "self", ".", "domain_list", "=", "list", "(", "self", ".", "data", ".", "domain_id", ".", "unique", "(", ")", ")", "\n", "self", ".", "n_way", "=", "n_way", "\n", "self", ".", "n_source", "=", "n_source", "\n", "self", ".", "n_target", "=", "n_target", "\n", "self", ".", "n_episodes", "=", "n_episodes", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.samplers.after_corruption_sampler.AfterCorruptionSampler.__len__": [[17, 19], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_episodes", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.samplers.after_corruption_sampler.AfterCorruptionSampler._sample_instances": [[20, 28], ["torch.tensor", "random.sample", "list"], "methods", ["None"], ["", "def", "_sample_instances", "(", "self", ",", "label", ",", "domain", ",", "n_samples", ")", ":", "\n", "        ", "eligible_indices", "=", "self", ".", "data", ".", "index", "[", "\n", "(", "self", ".", "data", ".", "domain_id", "==", "domain", ")", "&", "(", "self", ".", "data", ".", "class_id", "==", "label", ")", "\n", "]", "\n", "return", "torch", ".", "tensor", "(", "\n", "eligible_indices", "\n", "if", "n_samples", "==", "-", "1", "\n", "else", "random", ".", "sample", "(", "list", "(", "eligible_indices", ")", ",", "n_samples", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.samplers.after_corruption_sampler.AfterCorruptionSampler._get_episode_items": [[30, 49], ["random.sample", "random.sample", "torch.cat", "torch.cat", "torch.cat", "after_corruption_sampler.AfterCorruptionSampler._sample_instances", "after_corruption_sampler.AfterCorruptionSampler._sample_instances"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.samplers.grouped_dataset_sampler.GroupedDatasetSampler._sample_instances", "home.repos.pwc.inspect_result.772922440_pgada.samplers.grouped_dataset_sampler.GroupedDatasetSampler._sample_instances"], ["", "def", "_get_episode_items", "(", "self", ")", ":", "\n", "        ", "labels", "=", "random", ".", "sample", "(", "self", ".", "class_list", ",", "self", ".", "n_way", ")", "\n", "source_domain", ",", "target_domain", "=", "random", ".", "sample", "(", "self", ".", "domain_list", ",", "2", ")", "\n", "\n", "source_items", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "self", ".", "_sample_instances", "(", "label", ",", "source_domain", ",", "self", ".", "n_source", ")", "\n", "for", "label", "in", "labels", "\n", "]", "\n", ")", "\n", "\n", "target_items", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "self", ".", "_sample_instances", "(", "label", ",", "target_domain", ",", "self", ".", "n_target", ")", "\n", "for", "label", "in", "labels", "\n", "]", "\n", ")", "\n", "\n", "return", "torch", ".", "cat", "(", "(", "source_items", ",", "target_items", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.samplers.after_corruption_sampler.AfterCorruptionSampler.__iter__": [[50, 53], ["range", "after_corruption_sampler.AfterCorruptionSampler._get_episode_items"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.samplers.grouped_dataset_sampler.GroupedDatasetSampler._get_episode_items"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "_", "in", "range", "(", "self", ".", "n_episodes", ")", ":", "\n", "            ", "yield", "self", ".", "_get_episode_items", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.samplers.before_corruption_sampler.BeforeCorruptionSampler.__init__": [[18, 33], ["len", "len", "enumerate", "before_corruption_sampler.BeforeCorruptionSampler.items_per_label.keys", "before_corruption_sampler.BeforeCorruptionSampler.items_per_label[].append"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "n_way", ",", "n_source", ",", "n_target", ",", "n_episodes", ")", ":", "\n", "        ", "self", ".", "n_domains", "=", "len", "(", "dataset", ".", "id_to_domain", ")", "\n", "self", ".", "n_total_images", "=", "len", "(", "dataset", ".", "images", ")", "\n", "self", ".", "n_way", "=", "n_way", "\n", "self", ".", "n_source", "=", "n_source", "\n", "self", ".", "n_target", "=", "n_target", "\n", "self", ".", "n_episodes", "=", "n_episodes", "\n", "\n", "self", ".", "items_per_label", "=", "{", "}", "\n", "\n", "for", "item", ",", "label", "in", "enumerate", "(", "dataset", ".", "labels", ")", ":", "\n", "            ", "if", "label", "in", "self", ".", "items_per_label", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "items_per_label", "[", "label", "]", ".", "append", "(", "item", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "items_per_label", "[", "label", "]", "=", "[", "item", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.samplers.before_corruption_sampler.BeforeCorruptionSampler.__len__": [[34, 36], ["None"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_episodes", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.samplers.before_corruption_sampler.BeforeCorruptionSampler._split_source_target": [[37, 47], ["sklearn.model_selection.train_test_split"], "methods", ["None"], ["", "def", "_split_source_target", "(", "self", ",", "labels", ")", ":", "\n", "        ", "source_items_per_label", "=", "{", "}", "\n", "target_items_per_label", "=", "{", "}", "\n", "\n", "for", "label", "in", "labels", ":", "\n", "            ", "(", "\n", "source_items_per_label", "[", "label", "]", ",", "\n", "target_items_per_label", "[", "label", "]", ",", "\n", ")", "=", "train_test_split", "(", "self", ".", "items_per_label", "[", "label", "]", ",", "train_size", "=", "0.5", ")", "\n", "", "return", "source_items_per_label", ",", "target_items_per_label", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.samplers.before_corruption_sampler.BeforeCorruptionSampler._sample_instances": [[48, 52], ["torch.tensor", "random.sample"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_sample_instances", "(", "items", ",", "n_samples", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "\n", "items", "if", "n_samples", "==", "-", "1", "else", "random", ".", "sample", "(", "items", ",", "n_samples", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.samplers.before_corruption_sampler.BeforeCorruptionSampler._get_episode_items": [[54, 92], ["random.sample", "before_corruption_sampler.BeforeCorruptionSampler._split_source_target", "torch.cat", "before_corruption_sampler.BeforeCorruptionSampler.items_per_label.keys", "torch.randperm", "torch.randperm", "torch.cat", "torch.cat", "before_corruption_sampler.BeforeCorruptionSampler._sample_instances", "before_corruption_sampler.BeforeCorruptionSampler._sample_instances"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.samplers.before_corruption_sampler.BeforeCorruptionSampler._split_source_target", "home.repos.pwc.inspect_result.772922440_pgada.samplers.grouped_dataset_sampler.GroupedDatasetSampler._sample_instances", "home.repos.pwc.inspect_result.772922440_pgada.samplers.grouped_dataset_sampler.GroupedDatasetSampler._sample_instances"], ["", "def", "_get_episode_items", "(", "self", ")", ":", "\n", "        ", "labels", "=", "random", ".", "sample", "(", "self", ".", "items_per_label", ".", "keys", "(", ")", ",", "self", ".", "n_way", ")", "\n", "\n", "source_items_per_label", ",", "target_items_per_label", "=", "self", ".", "_split_source_target", "(", "\n", "labels", "\n", ")", "\n", "\n", "if", "SUPPORT_QUERY_SHIFT", ":", "\n", "            ", "source_perturbation", ",", "target_perturbation", "=", "torch", ".", "randperm", "(", "self", ".", "n_domains", ")", "[", "\n", ":", "2", "\n", "]", "\n", "", "else", ":", "\n", "            ", "source_perturbation", "=", "torch", ".", "randperm", "(", "self", ".", "n_domains", ")", "[", ":", "1", "]", "\n", "target_perturbation", "=", "source_perturbation", "\n", "\n", "", "source_items", "=", "(", "\n", "torch", ".", "cat", "(", "\n", "[", "\n", "self", ".", "_sample_instances", "(", "source_items_per_label", "[", "label", "]", ",", "self", ".", "n_source", ")", "\n", "for", "label", "in", "labels", "\n", "]", "\n", ")", "\n", "*", "self", ".", "n_domains", "\n", "+", "source_perturbation", "\n", ")", "\n", "\n", "target_items", "=", "(", "\n", "torch", ".", "cat", "(", "\n", "[", "\n", "self", ".", "_sample_instances", "(", "target_items_per_label", "[", "label", "]", ",", "self", ".", "n_target", ")", "\n", "for", "label", "in", "labels", "\n", "]", "\n", ")", "\n", "*", "self", ".", "n_domains", "\n", "+", "target_perturbation", "\n", ")", "\n", "\n", "return", "torch", ".", "cat", "(", "(", "source_items", ",", "target_items", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.samplers.before_corruption_sampler.BeforeCorruptionSampler.__iter__": [[93, 96], ["range", "before_corruption_sampler.BeforeCorruptionSampler._get_episode_items"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.samplers.grouped_dataset_sampler.GroupedDatasetSampler._get_episode_items"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "_", "in", "range", "(", "self", ".", "n_episodes", ")", ":", "\n", "            ", "yield", "self", ".", "_get_episode_items", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.samplers.grouped_dataset_sampler.GroupedDatasetSampler.__init__": [[11, 43], ["list", "list", "grouped_dataset_sampler.GroupedDatasetSampler.meta_data.groupby().size().rename().reset_index", "grouped_dataset_sampler.GroupedDatasetSampler.eligible_pairs_no_shift.user.value_counts().gt", "grouped_dataset_sampler.GroupedDatasetSampler.meta_data.class_name.unique", "grouped_dataset_sampler.GroupedDatasetSampler.meta_data.user.unique", "grouped_dataset_sampler.GroupedDatasetSampler.meta_data.groupby().size().rename", "grouped_dataset_sampler.GroupedDatasetSampler.eligible_pairs_no_shift.user.value_counts", "grouped_dataset_sampler.GroupedDatasetSampler.meta_data.groupby().size", "grouped_dataset_sampler.GroupedDatasetSampler.meta_data.groupby"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "n_way", ",", "n_source", ",", "n_target", ",", "n_episodes", ")", ":", "\n", "        ", "self", ".", "n_way", "=", "n_way", "\n", "self", ".", "n_source", "=", "n_source", "\n", "self", ".", "n_target", "=", "n_target", "\n", "self", ".", "n_episodes", "=", "n_episodes", "\n", "\n", "self", ".", "meta_data", "=", "dataset", ".", "meta_data", "[", "[", "\"user\"", ",", "\"class_name\"", "]", "]", "\n", "self", ".", "class_list", "=", "list", "(", "self", ".", "meta_data", ".", "class_name", ".", "unique", "(", ")", ")", "\n", "self", ".", "domain_list", "=", "list", "(", "self", ".", "meta_data", ".", "user", ".", "unique", "(", ")", ")", "\n", "\n", "self", ".", "user_class_occurrences", "=", "(", "\n", "self", ".", "meta_data", ".", "groupby", "(", "[", "\"user\"", ",", "\"class_name\"", "]", ")", "\n", ".", "size", "(", ")", "\n", ".", "rename", "(", "\"n_images\"", ")", "\n", ".", "reset_index", "(", ")", "\n", ")", "\n", "\n", "self", ".", "eligible_pairs_source", "=", "self", ".", "user_class_occurrences", "[", "\n", "[", "\"user\"", ",", "\"class_name\"", "]", "\n", "]", ".", "loc", "[", "self", ".", "user_class_occurrences", ".", "n_images", ">=", "n_source", "]", "\n", "self", ".", "eligible_pairs_target", "=", "self", ".", "user_class_occurrences", "[", "\n", "[", "\"user\"", ",", "\"class_name\"", "]", "\n", "]", ".", "loc", "[", "self", ".", "user_class_occurrences", ".", "n_images", ">=", "n_target", "]", "\n", "\n", "self", ".", "eligible_pairs_no_shift", "=", "self", ".", "user_class_occurrences", "[", "\n", "[", "\"user\"", ",", "\"class_name\"", "]", "\n", "]", ".", "loc", "[", "self", ".", "user_class_occurrences", ".", "n_images", ">=", "n_source", "+", "n_target", "]", "\n", "domains_are_eligible_no_shift", "=", "self", ".", "eligible_pairs_no_shift", ".", "user", ".", "value_counts", "(", "\n", "sort", "=", "False", "\n", ")", ".", "gt", "(", "n_way", ")", "\n", "self", ".", "eligible_domains_no_shift", "=", "domains_are_eligible_no_shift", ".", "index", "[", "\n", "domains_are_eligible_no_shift", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.samplers.grouped_dataset_sampler.GroupedDatasetSampler.__len__": [[45, 47], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_episodes", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.samplers.grouped_dataset_sampler.GroupedDatasetSampler._sample_domains_and_labels": [[48, 73], ["range", "TimeoutError", "numpy.random.choice", "numpy.random.choice", "set().intersection", "grouped_dataset_sampler.GroupedDatasetSampler.eligible_pairs_source.user.unique", "grouped_dataset_sampler.GroupedDatasetSampler.eligible_pairs_target.user.unique", "set", "len", "random.sample", "set"], "methods", ["None"], ["", "def", "_sample_domains_and_labels", "(", "self", ")", ":", "\n", "        ", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "            ", "source_domain", "=", "np", ".", "random", ".", "choice", "(", "\n", "self", ".", "eligible_pairs_source", ".", "user", ".", "unique", "(", ")", ",", "1", "\n", ")", "[", "0", "]", "\n", "target_domain", "=", "np", ".", "random", ".", "choice", "(", "\n", "self", ".", "eligible_pairs_target", ".", "user", ".", "unique", "(", ")", ",", "1", "\n", ")", "[", "0", "]", "\n", "if", "source_domain", "!=", "target_domain", ":", "\n", "                ", "eligible_labels", "=", "set", "(", "\n", "self", ".", "eligible_pairs_source", ".", "class_name", ".", "loc", "[", "\n", "self", ".", "eligible_pairs_source", ".", "user", "==", "source_domain", "\n", "]", "\n", ")", ".", "intersection", "(", "\n", "set", "(", "\n", "self", ".", "eligible_pairs_target", ".", "class_name", ".", "loc", "[", "\n", "self", ".", "eligible_pairs_target", ".", "user", "==", "target_domain", "\n", "]", "\n", ")", "\n", ")", "\n", "if", "len", "(", "eligible_labels", ")", ">=", "self", ".", "n_way", ":", "\n", "                    ", "labels", "=", "random", ".", "sample", "(", "eligible_labels", ",", "self", ".", "n_way", ")", "\n", "return", "source_domain", ",", "target_domain", ",", "labels", "\n", "", "", "", "raise", "TimeoutError", "(", "\n", "\"Couldn't find a suitable task to sample (too many trials). Consider reducing task size.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.samplers.grouped_dataset_sampler.GroupedDatasetSampler._sample_instances": [[75, 83], ["torch.tensor", "random.sample", "list"], "methods", ["None"], ["", "def", "_sample_instances", "(", "self", ",", "label", ",", "domain", ",", "n_samples", ")", ":", "\n", "        ", "eligible_indices", "=", "self", ".", "meta_data", ".", "index", "[", "\n", "(", "self", ".", "meta_data", ".", "user", "==", "domain", ")", "&", "(", "self", ".", "meta_data", ".", "class_name", "==", "label", ")", "\n", "]", "\n", "return", "torch", ".", "tensor", "(", "\n", "eligible_indices", "\n", "if", "n_samples", "==", "-", "1", "\n", "else", "random", ".", "sample", "(", "list", "(", "eligible_indices", ")", ",", "n_samples", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.samplers.grouped_dataset_sampler.GroupedDatasetSampler._get_episode_items": [[85, 122], ["torch.cat", "grouped_dataset_sampler.GroupedDatasetSampler._sample_domains_and_labels", "torch.cat", "torch.cat", "numpy.random.choice", "torch.stack", "sampled_items[].flatten", "sampled_items[].flatten", "numpy.random.choice", "grouped_dataset_sampler.GroupedDatasetSampler._sample_instances", "grouped_dataset_sampler.GroupedDatasetSampler._sample_instances", "grouped_dataset_sampler.GroupedDatasetSampler._sample_instances"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.samplers.grouped_dataset_sampler.GroupedDatasetSampler._sample_domains_and_labels", "home.repos.pwc.inspect_result.772922440_pgada.samplers.grouped_dataset_sampler.GroupedDatasetSampler._sample_instances", "home.repos.pwc.inspect_result.772922440_pgada.samplers.grouped_dataset_sampler.GroupedDatasetSampler._sample_instances", "home.repos.pwc.inspect_result.772922440_pgada.samplers.grouped_dataset_sampler.GroupedDatasetSampler._sample_instances"], ["", "def", "_get_episode_items", "(", "self", ")", ":", "\n", "        ", "if", "SUPPORT_QUERY_SHIFT", ":", "\n", "            ", "source_domain", ",", "target_domain", ",", "labels", "=", "self", ".", "_sample_domains_and_labels", "(", ")", "\n", "\n", "source_items", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "self", ".", "_sample_instances", "(", "label", ",", "source_domain", ",", "self", ".", "n_source", ")", "\n", "for", "label", "in", "labels", "\n", "]", "\n", ")", "\n", "\n", "target_items", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "self", ".", "_sample_instances", "(", "label", ",", "target_domain", ",", "self", ".", "n_target", ")", "\n", "for", "label", "in", "labels", "\n", "]", "\n", ")", "\n", "\n", "", "else", ":", "\n", "            ", "domain", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "eligible_domains_no_shift", ",", "1", ")", "[", "0", "]", "\n", "labels", "=", "np", ".", "random", ".", "choice", "(", "\n", "self", ".", "eligible_pairs_no_shift", ".", "class_name", ".", "loc", "[", "\n", "self", ".", "eligible_pairs_no_shift", ".", "user", "==", "domain", "\n", "]", ",", "\n", "self", ".", "n_way", ",", "\n", "replace", "=", "False", ",", "\n", ")", "\n", "sampled_items", "=", "torch", ".", "stack", "(", "\n", "[", "\n", "self", ".", "_sample_instances", "(", "label", ",", "domain", ",", "self", ".", "n_source", "+", "self", ".", "n_target", ")", "\n", "for", "label", "in", "labels", "\n", "]", "\n", ")", "\n", "source_items", "=", "sampled_items", "[", ":", ",", ":", "self", ".", "n_source", "]", ".", "flatten", "(", ")", "\n", "target_items", "=", "sampled_items", "[", ":", ",", "self", ".", "n_source", ":", "]", ".", "flatten", "(", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "(", "source_items", ",", "target_items", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.samplers.grouped_dataset_sampler.GroupedDatasetSampler.__iter__": [[123, 126], ["range", "grouped_dataset_sampler.GroupedDatasetSampler._get_episode_items"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.samplers.grouped_dataset_sampler.GroupedDatasetSampler._get_episode_items"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "_", "in", "range", "(", "self", ".", "n_episodes", ")", ":", "\n", "            ", "yield", "self", ".", "_get_episode_items", "(", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.modules.optimal_transport.OptimalTransport.__init__": [[9, 26], ["torch.nn.Module.__init__", "src.modules.sinkhorn.Sinkhorn"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "regularization", ",", "\n", "max_iter", ",", "\n", "stopping_criterion", ",", "\n", "learn_regularization", "=", "False", ",", "\n", "power_transform", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "super", "(", "OptimalTransport", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sinkhorn", "=", "Sinkhorn", "(", "\n", "eps", "=", "regularization", ",", "\n", "max_iter", "=", "max_iter", ",", "\n", "thresh", "=", "stopping_criterion", ",", "\n", "eps_parameter", "=", "learn_regularization", ",", "\n", ")", "\n", "self", ".", "beta", "=", "power_transform", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.optimal_transport.OptimalTransport.forward": [[27, 49], ["optimal_transport.OptimalTransport.sinkhorn", "torch.matmul", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.pow", "torch.pow", "transport_plan.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "z_support", ",", "z_query", ")", ":", "\n", "        ", "\"\"\"\n        Applies Optimal Transport from query images to support images,\n            and uses the outcome to predict query classification scores.\n        Args:\n            z_support (torch.Tensor): shape (number_of_support_set_images, feature_dim)\n            z_query (torch.Tensor): shape (number_of_query_set_images, feature_dim)\n        Returns:\n            tuple(torch.Tensor, torch.Tensor) : resp. transported support set features,\n                and unmodified query set features\n        \"\"\"", "\n", "if", "self", ".", "beta", ":", "\n", "            ", "z_support", "=", "F", ".", "normalize", "(", "torch", ".", "pow", "(", "z_support", "+", "1e-6", ",", "self", ".", "beta", ")", ")", "\n", "z_query", "=", "F", ".", "normalize", "(", "torch", ".", "pow", "(", "z_query", "+", "1e-6", ",", "self", ".", "beta", ")", ")", "\n", "\n", "", "_", ",", "transport_plan", ",", "_", "=", "self", ".", "sinkhorn", "(", "z_support", ",", "z_query", ")", "\n", "\n", "z_support_transported", "=", "torch", ".", "matmul", "(", "\n", "transport_plan", "/", "transport_plan", ".", "sum", "(", "axis", "=", "1", ",", "keepdims", "=", "True", ")", ",", "z_query", "\n", ")", "\n", "\n", "return", "z_support_transported", ",", "z_query", "\n", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.modules.hyper_networks.MultiLayerPerceptron.__init__": [[10, 23], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Sequential"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ")", ":", "\n", "        ", "super", "(", "MultiLayerPerceptron", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "layer_1", "=", "nn", ".", "Linear", "(", "num_features", ",", "1024", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm1d", "(", "1024", ")", "\n", "self", ".", "layer_2", "=", "nn", ".", "Linear", "(", "1024", ",", "1024", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm1d", "(", "1024", ")", "\n", "self", ".", "layer_3", "=", "nn", ".", "Linear", "(", "1024", ",", "1", ")", "\n", "\n", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "mlp", "=", "nn", ".", "Sequential", "(", "\n", "self", ".", "layer_1", ",", "self", ".", "bn1", ",", "relu", ",", "self", ".", "layer_2", ",", "self", ".", "bn2", ",", "relu", ",", "self", ".", "layer_3", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.hyper_networks.MultiLayerPerceptron.forward": [[25, 27], ["src.methods.utils.softplus", "hyper_networks.MultiLayerPerceptron.mlp"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.utils.softplus"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "softplus", "(", "self", ".", "mlp", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.hyper_networks.RelationNet.__init__": [[36, 54], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "hyper_networks.RelationNet.lin_1.weight.data.fill_", "hyper_networks.RelationNet.lin_1.bias.data.fill_", "hyper_networks.RelationNet.lin_2.weight.data.fill_", "hyper_networks.RelationNet.lin_2.bias.data.fill_", "hyper_networks.RelationNet.lin_3.weight.data.fill_", "hyper_networks.RelationNet.lin_3.bias.data.fill_", "torch.nn.ReLU", "torch.nn.Sequential"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__"], ["def", "__init__", "(", "self", ",", "num_features", ")", ":", "\n", "        ", "super", "(", "RelationNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "lin_1", "=", "nn", ".", "Linear", "(", "num_features", ",", "64", ")", "\n", "self", ".", "lin_2", "=", "nn", ".", "Linear", "(", "64", ",", "8", ")", "\n", "self", ".", "lin_3", "=", "nn", ".", "Linear", "(", "8", ",", "1", ")", "\n", "\n", "# We enforce to start from sigma=0.1 to prevent learning failure. MANDATORY!", "\n", "self", ".", "lin_1", ".", "weight", ".", "data", ".", "fill_", "(", "0.0", ")", "\n", "self", ".", "lin_1", ".", "bias", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "self", ".", "lin_2", ".", "weight", ".", "data", ".", "fill_", "(", "0.0", ")", "\n", "self", ".", "lin_2", ".", "bias", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "self", ".", "lin_3", ".", "weight", ".", "data", ".", "fill_", "(", "0.0", ")", "\n", "self", ".", "lin_3", ".", "bias", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "self", ".", "lin_1", ",", "relu", ",", "self", ".", "lin_2", ",", "relu", ",", "self", ".", "lin_3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.hyper_networks.RelationNet.forward": [[55, 58], ["hyper_networks.RelationNet.net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "sigma", "=", "self", ".", "net", "(", "x", ")", "\n", "return", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.hyper_networks.FullyContextualEmbedding.__init__": [[65, 70], ["torch.nn.Module.__init__", "src.utils.set_device", "torch.nn.Softmax", "src.utils.set_device", "torch.nn.LSTMCell", "torch.autograd.Variable", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device"], ["def", "__init__", "(", "self", ",", "num_features", ")", ":", "\n", "        ", "super", "(", "FullyContextualEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lstm_cell", "=", "set_device", "(", "nn", ".", "LSTMCell", "(", "num_features", "*", "2", ",", "num_features", ")", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", ")", "\n", "self", ".", "c_0", "=", "set_device", "(", "Variable", "(", "torch", ".", "zeros", "(", "1", ",", "num_features", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.hyper_networks.FullyContextualEmbedding.forward": [[71, 85], ["hyper_networks.FullyContextualEmbedding.c_0.expand_as", "encoded_support_features.size", "range", "h.mm", "hyper_networks.FullyContextualEmbedding.softmax", "hyper_networks.FullyContextualEmbedding.mm", "torch.cat", "hyper_networks.FullyContextualEmbedding.lstm_cell"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "query_features", ",", "encoded_support_features", ")", ":", "\n", "        ", "h", "=", "query_features", "\n", "c", "=", "self", ".", "c_0", ".", "expand_as", "(", "query_features", ")", "\n", "K", "=", "encoded_support_features", ".", "size", "(", "0", ")", "# Tuna to be comfirmed", "\n", "for", "k", "in", "range", "(", "K", ")", ":", "\n", "            ", "logit_a", "=", "h", ".", "mm", "(", "encoded_support_features", ".", "T", ")", "\n", "a", "=", "self", ".", "softmax", "(", "logit_a", ")", "\n", "r", "=", "a", ".", "mm", "(", "encoded_support_features", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "query_features", ",", "r", ")", ",", "1", ")", "\n", "\n", "h", ",", "c", "=", "self", ".", "lstm_cell", "(", "x", ",", "(", "h", ",", "c", ")", ")", "\n", "h", "=", "h", "+", "query_features", "\n", "\n", "", "return", "h", "\n", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.modules.batch_norm.TransductiveBatchNorm.forward": [[13, 27], ["src.utils.set_device", "src.utils.set_device", "torch.batch_norm", "torch.batch_norm", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "x.data.size", "x.data.size"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device"], ["    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# Placeholders for F.batch_norm, not used since momentum=1.", "\n", "        ", "running_mean", "=", "set_device", "(", "torch", ".", "zeros", "(", "x", ".", "data", ".", "size", "(", ")", "[", "1", "]", ")", ")", "\n", "running_var", "=", "set_device", "(", "torch", ".", "ones", "(", "x", ".", "data", ".", "size", "(", ")", "[", "1", "]", ")", ")", "\n", "out", "=", "F", ".", "batch_norm", "(", "\n", "x", ",", "\n", "running_mean", ",", "\n", "running_var", ",", "\n", "self", ".", "weight", ",", "\n", "self", ".", "bias", ",", "\n", "training", "=", "True", ",", "\n", "momentum", "=", "1", ",", "\n", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.batch_norm.NormalizationLayer.forward": [[35, 43], ["None"], "methods", ["None"], ["@", "abstractmethod", "\n", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Normalize activations.\n        :param x: input activations\n        :return: normalized activations\n        \"\"\"", "\n", "pass", "# always override this method", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.batch_norm.NormalizationLayer._normalize": [[44, 55], ["batch_norm.NormalizationLayer.bias.view", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "batch_norm.NormalizationLayer.weight.view"], "methods", ["None"], ["", "def", "_normalize", "(", "self", ",", "x", ",", "mean", ",", "var", ")", ":", "\n", "        ", "\"\"\"\n        Normalize activations.\n        :param x: input activations\n        :param mean: mean used to normalize\n        :param var: var used to normalize\n        :return: normalized activations\n        \"\"\"", "\n", "return", "(", "\n", "self", ".", "weight", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "*", "(", "x", "-", "mean", ")", "/", "torch", ".", "sqrt", "(", "var", "+", "self", ".", "eps", ")", "\n", ")", "+", "self", ".", "bias", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.batch_norm.NormalizationLayer._compute_batch_moments": [[56, 65], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.var", "torch.var", "torch.var", "torch.var"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_compute_batch_moments", "(", "x", ")", ":", "\n", "        ", "\"\"\"\n        Compute conventional batch mean and variance.\n        :param x: input activations\n        :return: batch mean, batch variance\n        \"\"\"", "\n", "return", "torch", ".", "mean", "(", "x", ",", "dim", "=", "(", "0", ",", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", ",", "torch", ".", "var", "(", "\n", "x", ",", "dim", "=", "(", "0", ",", "2", ",", "3", ")", ",", "keepdim", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.batch_norm.NormalizationLayer._compute_instance_moments": [[67, 76], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.var", "torch.var", "torch.var", "torch.var"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_compute_instance_moments", "(", "x", ")", ":", "\n", "        ", "\"\"\"\n        Compute instance mean and variance.\n        :param x: input activations\n        :return: instance mean, instance variance\n        \"\"\"", "\n", "return", "torch", ".", "mean", "(", "x", ",", "dim", "=", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", ",", "torch", ".", "var", "(", "\n", "x", ",", "dim", "=", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.batch_norm.NormalizationLayer._compute_layer_moments": [[78, 87], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.var", "torch.var", "torch.var", "torch.var"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_compute_layer_moments", "(", "x", ")", ":", "\n", "        ", "\"\"\"\n        Compute layer mean and variance.\n        :param x: input activations\n        :return: layer mean, layer variance\n        \"\"\"", "\n", "return", "torch", ".", "mean", "(", "x", ",", "dim", "=", "(", "1", ",", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", ",", "torch", ".", "var", "(", "\n", "x", ",", "dim", "=", "(", "1", ",", "2", ",", "3", ")", ",", "keepdim", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.batch_norm.NormalizationLayer._compute_pooled_moments": [[89, 108], ["augment_moment_fn"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_compute_pooled_moments", "(", "x", ",", "alpha", ",", "batch_mean", ",", "batch_var", ",", "augment_moment_fn", ")", ":", "\n", "        ", "\"\"\"\n        Combine batch moments with augment moments using blend factor alpha.\n        :param x: input activations\n        :param alpha: moment blend factor\n        :param batch_mean: standard batch mean\n        :param batch_var: standard batch variance\n        :param augment_moment_fn: function to compute augment moments\n        :return: pooled mean, pooled variance\n        \"\"\"", "\n", "augment_mean", ",", "augment_var", "=", "augment_moment_fn", "(", "x", ")", "\n", "pooled_mean", "=", "alpha", "*", "batch_mean", "+", "(", "1.0", "-", "alpha", ")", "*", "augment_mean", "\n", "batch_mean_diff", "=", "batch_mean", "-", "pooled_mean", "\n", "augment_mean_diff", "=", "augment_mean", "-", "pooled_mean", "\n", "pooled_var", "=", "alpha", "*", "(", "batch_var", "+", "(", "batch_mean_diff", "*", "batch_mean_diff", ")", ")", "+", "(", "\n", "1.0", "-", "alpha", "\n", ")", "*", "(", "augment_var", "+", "(", "augment_mean_diff", "*", "augment_mean_diff", ")", ")", "\n", "return", "pooled_mean", ",", "pooled_var", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.batch_norm.TaskNormBase.__init__": [[113, 121], ["torch.nn.BatchNorm2d.__init__", "batch_norm.TaskNormBase.register_extra_weights", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__", "home.repos.pwc.inspect_result.772922440_pgada.modules.batch_norm.TaskNormBase.register_extra_weights"], ["def", "__init__", "(", "self", ",", "num_features", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Initialize\n        :param num_features: number of channels in the 2D convolutional layer\n        \"\"\"", "\n", "super", "(", "TaskNormBase", ",", "self", ")", ".", "__init__", "(", "num_features", ",", "**", "kwargs", ")", "\n", "self", ".", "register_extra_weights", "(", ")", "# see register_extra_weights (not in original code)", "\n", "self", ".", "sigmoid", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.batch_norm.TaskNormBase.register_extra_weights": [[122, 159], ["torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "batch_norm.TaskNormBase.register_parameter", "batch_norm.TaskNormBase.register_parameter", "batch_norm.TaskNormBase.register_buffer", "batch_norm.TaskNormBase.register_buffer", "batch_norm.TaskNormBase.register_buffer", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "register_extra_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        The parameters here get registered after initialization because the pre-trained resnet model does not have\n        these parameters and would fail to load if these were declared at initialization.\n        :return: Nothing\n        \"\"\"", "\n", "device", "=", "self", ".", "weight", ".", "device", "\n", "\n", "# Initialize and register the learned parameters 'a' (SCALE) and 'b' (OFFSET)", "\n", "# for calculating alpha as a function of context size.", "\n", "scale", "=", "torch", ".", "Tensor", "(", "[", "0.0", "]", ")", ".", "to", "(", "device", ")", "\n", "offset", "=", "torch", ".", "Tensor", "(", "[", "0.0", "]", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "register_parameter", "(", "\n", "name", "=", "\"scale\"", ",", "param", "=", "torch", ".", "nn", ".", "Parameter", "(", "scale", ",", "requires_grad", "=", "True", ")", "\n", ")", "\n", "self", ".", "register_parameter", "(", "\n", "name", "=", "\"offset\"", ",", "param", "=", "torch", ".", "nn", ".", "Parameter", "(", "offset", ",", "requires_grad", "=", "True", ")", "\n", ")", "\n", "\n", "# Variables to store the context moments to use for normalizing the target.", "\n", "self", ".", "register_buffer", "(", "\n", "name", "=", "\"batch_mean\"", ",", "\n", "tensor", "=", "torch", ".", "zeros", "(", "\n", "(", "1", ",", "self", ".", "num_features", ",", "1", ",", "1", ")", ",", "requires_grad", "=", "True", ",", "device", "=", "device", "\n", ")", ",", "\n", ")", "\n", "self", ".", "register_buffer", "(", "\n", "name", "=", "\"batch_var\"", ",", "\n", "tensor", "=", "torch", ".", "ones", "(", "\n", "(", "1", ",", "self", ".", "num_features", ",", "1", ",", "1", ")", ",", "requires_grad", "=", "True", ",", "device", "=", "device", "\n", ")", ",", "\n", ")", "\n", "\n", "# Variable to save the context size.", "\n", "self", ".", "register_buffer", "(", "\n", "name", "=", "\"context_size\"", ",", "\n", "tensor", "=", "torch", ".", "zeros", "(", "(", "1", ")", ",", "requires_grad", "=", "False", ",", "device", "=", "device", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.batch_norm.TaskNormBase._get_augment_moment_fn": [[161, 167], ["None"], "methods", ["None"], ["", "def", "_get_augment_moment_fn", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Provides the function to compute augment moemnts.\n        :return: function to compute augment moments.\n        \"\"\"", "\n", "pass", "# always override this function", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.batch_norm.TaskNormBase.forward": [[168, 200], ["batch_norm.TaskNormBase._normalize", "batch_norm.TaskNormBase.sigmoid", "batch_norm.TaskNormBase._compute_batch_moments", "batch_norm.TaskNormBase._compute_pooled_moments", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "batch_norm.TaskNormBase.sigmoid", "batch_norm.TaskNormBase._compute_pooled_moments", "batch_norm.TaskNormBase._get_augment_moment_fn", "batch_norm.TaskNormBase._get_augment_moment_fn", "x.size", "x.size"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.modules.batch_norm.NormalizationLayer._normalize", "home.repos.pwc.inspect_result.772922440_pgada.modules.batch_norm.NormalizationLayer._compute_batch_moments", "home.repos.pwc.inspect_result.772922440_pgada.modules.batch_norm.NormalizationLayer._compute_pooled_moments", "home.repos.pwc.inspect_result.772922440_pgada.modules.batch_norm.NormalizationLayer._compute_pooled_moments", "home.repos.pwc.inspect_result.772922440_pgada.modules.batch_norm.TaskNormI._get_augment_moment_fn", "home.repos.pwc.inspect_result.772922440_pgada.modules.batch_norm.TaskNormI._get_augment_moment_fn"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Normalize activations.\n        :param x: input activations\n        :return: normalized activations\n        \"\"\"", "\n", "if", "(", "\n", "self", ".", "training", "\n", ")", ":", "# compute the pooled moments for the context and save off the moments and context size", "\n", "            ", "alpha", "=", "self", ".", "sigmoid", "(", "\n", "self", ".", "scale", "*", "(", "x", ".", "size", "(", ")", ")", "[", "0", "]", "+", "self", ".", "offset", "\n", ")", "# compute alpha with context size", "\n", "batch_mean", ",", "batch_var", "=", "self", ".", "_compute_batch_moments", "(", "x", ")", "\n", "pooled_mean", ",", "pooled_var", "=", "self", ".", "_compute_pooled_moments", "(", "\n", "x", ",", "alpha", ",", "batch_mean", ",", "batch_var", ",", "self", ".", "_get_augment_moment_fn", "(", ")", "\n", ")", "\n", "self", ".", "context_batch_mean", "=", "batch_mean", "\n", "self", ".", "context_batch_var", "=", "batch_var", "\n", "self", ".", "context_size", "=", "torch", ".", "full_like", "(", "self", ".", "context_size", ",", "x", ".", "size", "(", ")", "[", "0", "]", ")", "\n", "", "else", ":", "# compute the pooled moments for the target", "\n", "            ", "alpha", "=", "self", ".", "sigmoid", "(", "\n", "self", ".", "scale", "*", "self", ".", "context_size", "+", "self", ".", "offset", "\n", ")", "# compute alpha with saved context size", "\n", "pooled_mean", ",", "pooled_var", "=", "self", ".", "_compute_pooled_moments", "(", "\n", "x", ",", "\n", "alpha", ",", "\n", "self", ".", "context_batch_mean", ",", "\n", "self", ".", "context_batch_var", ",", "\n", "self", ".", "_get_augment_moment_fn", "(", ")", ",", "\n", ")", "\n", "\n", "", "return", "self", ".", "_normalize", "(", "x", ",", "pooled_mean", ",", "pooled_var", ")", "# normalize", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.batch_norm.TaskNormI._get_augment_moment_fn": [[207, 213], ["None"], "methods", ["None"], ["def", "_get_augment_moment_fn", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Override the base class to get the function to compute instance moments.\n        :return: function to compute instance moments\n        \"\"\"", "\n", "return", "self", ".", "_compute_instance_moments", "\n", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.modules.sinkhorn.Sinkhorn.__init__": [[25, 38], ["torch.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__"], ["def", "__init__", "(", "self", ",", "eps", ",", "eps_parameter", ",", "max_iter", ",", "thresh", ",", "reduction", "=", "\"none\"", ")", ":", "\n", "        ", "super", "(", "Sinkhorn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "eps_parameter", "=", "eps_parameter", "\n", "\n", "# TODO: very dirty: makes the typing of eps unknown, plus it breaks the load_state_dict of OT-less models", "\n", "self", ".", "eps", "=", "eps", "\n", "if", "self", ".", "eps_parameter", ":", "\n", "            ", "self", ".", "eps", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "self", ".", "eps", ")", ")", "\n", "\n", "", "self", ".", "max_iter", "=", "max_iter", "\n", "self", ".", "thresh", "=", "thresh", "\n", "self", ".", "reduction", "=", "reduction", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.sinkhorn.Sinkhorn.forward": [[39, 106], ["sinkhorn.Sinkhorn._cost_matrix", "sinkhorn.Sinkhorn.max", "src.utils.set_device", "src.utils.set_device", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "range", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "x.dim", "torch.empty().fill_().squeeze", "torch.empty().fill_().squeeze", "torch.empty().fill_().squeeze", "torch.empty().fill_().squeeze", "torch.empty().fill_().squeeze", "torch.empty().fill_().squeeze", "torch.empty().fill_().squeeze", "torch.empty().fill_().squeeze", "sinkhorn.Sinkhorn.M", "cost.sum.sum.mean", "err.item", "cost.sum.sum.sum", "torch.empty().fill_", "torch.empty().fill_", "torch.empty().fill_", "torch.empty().fill_", "torch.empty().fill_", "torch.empty().fill_", "torch.empty().fill_", "torch.empty().fill_", "torch.log", "torch.log", "torch.log", "torch.log", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.log", "torch.log", "torch.log", "torch.log", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "sinkhorn.Sinkhorn.M", "sinkhorn.Sinkhorn.M().transpose", "sinkhorn.Sinkhorn.M"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.modules.sinkhorn.Sinkhorn._cost_matrix", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.modules.sinkhorn.Sinkhorn.M", "home.repos.pwc.inspect_result.772922440_pgada.modules.sinkhorn.Sinkhorn.M", "home.repos.pwc.inspect_result.772922440_pgada.modules.sinkhorn.Sinkhorn.M"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "# The Sinkhorn algorithm takes as input three variables :", "\n", "        ", "C", "=", "self", ".", "_cost_matrix", "(", "x", ",", "y", ")", "# Wasserstein cost function", "\n", "cost_normalization", "=", "C", ".", "max", "(", ")", "\n", "C", "=", "(", "\n", "C", "/", "cost_normalization", "\n", ")", "# Needs to normalize the matrix to be consistent with reg", "\n", "\n", "x_points", "=", "x", ".", "shape", "[", "-", "2", "]", "\n", "y_points", "=", "y", ".", "shape", "[", "-", "2", "]", "\n", "if", "x", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "batch_size", "=", "1", "\n", "", "else", ":", "\n", "            ", "batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "\n", "# both marginals are fixed with equal weights", "\n", "", "mu", "=", "set_device", "(", "\n", "torch", ".", "empty", "(", "batch_size", ",", "x_points", ",", "dtype", "=", "torch", ".", "float", ",", "requires_grad", "=", "False", ")", "\n", ".", "fill_", "(", "1.0", "/", "x_points", ")", "\n", ".", "squeeze", "(", ")", "\n", ")", "\n", "nu", "=", "set_device", "(", "\n", "torch", ".", "empty", "(", "batch_size", ",", "y_points", ",", "dtype", "=", "torch", ".", "float", ",", "requires_grad", "=", "False", ")", "\n", ".", "fill_", "(", "1.0", "/", "y_points", ")", "\n", ".", "squeeze", "(", ")", "\n", ")", "\n", "\n", "u", "=", "torch", ".", "zeros_like", "(", "mu", ")", "\n", "v", "=", "torch", ".", "zeros_like", "(", "nu", ")", "\n", "# To check if algorithm terminates because of threshold", "\n", "# or max iterations reached", "\n", "actual_nits", "=", "0", "\n", "\n", "# Sinkhorn iterations", "\n", "for", "i", "in", "range", "(", "self", ".", "max_iter", ")", ":", "\n", "            ", "u1", "=", "u", "# useful to check the update", "\n", "u", "=", "(", "\n", "self", ".", "eps", "\n", "*", "(", "torch", ".", "log", "(", "mu", "+", "1e-8", ")", "-", "torch", ".", "logsumexp", "(", "self", ".", "M", "(", "C", ",", "u", ",", "v", ")", ",", "dim", "=", "-", "1", ")", ")", "\n", "+", "u", "\n", ")", "\n", "v", "=", "(", "\n", "self", ".", "eps", "\n", "*", "(", "\n", "torch", ".", "log", "(", "nu", "+", "1e-8", ")", "\n", "-", "torch", ".", "logsumexp", "(", "self", ".", "M", "(", "C", ",", "u", ",", "v", ")", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "\n", ")", "\n", "+", "v", "\n", ")", "\n", "err", "=", "(", "u", "-", "u1", ")", ".", "abs", "(", ")", ".", "sum", "(", "-", "1", ")", ".", "mean", "(", ")", "\n", "\n", "actual_nits", "+=", "1", "\n", "if", "err", ".", "item", "(", ")", "<", "self", ".", "thresh", ":", "\n", "                ", "break", "\n", "\n", "", "", "U", ",", "V", "=", "u", ",", "v", "\n", "# Transport plan pi = diag(a)*K*diag(b)", "\n", "pi", "=", "torch", ".", "exp", "(", "self", ".", "M", "(", "C", ",", "U", ",", "V", ")", ")", "\n", "# Sinkhorn distance", "\n", "cost", "=", "torch", ".", "sum", "(", "pi", "*", "C", ",", "dim", "=", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "\n", "if", "self", ".", "reduction", "==", "\"mean\"", ":", "\n", "            ", "cost", "=", "cost", ".", "mean", "(", ")", "\n", "", "elif", "self", ".", "reduction", "==", "\"sum\"", ":", "\n", "            ", "cost", "=", "cost", ".", "sum", "(", ")", "\n", "\n", "", "return", "cost", ",", "pi", ",", "C", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.sinkhorn.Sinkhorn.M": [[107, 111], ["v.unsqueeze", "u.unsqueeze"], "methods", ["None"], ["", "def", "M", "(", "self", ",", "C", ",", "u", ",", "v", ")", ":", "\n", "        ", "\"Modified cost for logarithmic updates\"", "\n", "\"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"", "\n", "return", "(", "-", "C", "+", "u", ".", "unsqueeze", "(", "-", "1", ")", "+", "v", ".", "unsqueeze", "(", "-", "2", ")", ")", "/", "self", ".", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.sinkhorn.Sinkhorn._cost_matrix": [[112, 119], ["x.unsqueeze", "y.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_cost_matrix", "(", "x", ",", "y", ",", "p", "=", "2", ")", ":", "\n", "        ", "\"Returns the matrix of $|x_i-y_j|^p$.\"", "\n", "x_col", "=", "x", ".", "unsqueeze", "(", "-", "2", ")", "\n", "y_lin", "=", "y", ".", "unsqueeze", "(", "-", "3", ")", "\n", "C", "=", "torch", ".", "sum", "(", "(", "torch", ".", "abs", "(", "x_col", "-", "y_lin", ")", ")", "**", "p", ",", "-", "1", ")", "\n", "return", "C", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.sinkhorn.Sinkhorn.ave": [[120, 124], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "ave", "(", "u", ",", "u1", ",", "tau", ")", ":", "\n", "        ", "\"Barycenter subroutine, used by kinetic acceleration through extrapolation.\"", "\n", "return", "tau", "*", "u", "+", "(", "1", "-", "tau", ")", "*", "u1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.distLinear.__init__": [[27, 40], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.nn.utils.weight_norm.WeightNorm.apply", "torch.nn.utils.weight_norm.WeightNorm.apply", "torch.nn.utils.weight_norm.WeightNorm.apply"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__"], ["    ", "def", "__init__", "(", "self", ",", "indim", ",", "outdim", ")", ":", "\n", "        ", "super", "(", "distLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "L", "=", "nn", ".", "Linear", "(", "indim", ",", "outdim", ",", "bias", "=", "False", ")", "\n", "self", ".", "class_wise_learnable_norm", "=", "True", "# See the issue#4&8 in the github", "\n", "if", "self", ".", "class_wise_learnable_norm", ":", "\n", "            ", "WeightNorm", ".", "apply", "(", "\n", "self", ".", "L", ",", "\"weight\"", ",", "dim", "=", "0", "\n", ")", "# split the weight update component to direction and norm", "\n", "\n", "", "if", "outdim", "<=", "200", ":", "\n", "            ", "self", ".", "scale_factor", "=", "2", "# a fixed scale factor to scale the output of cos value into a reasonably large input for softmax", "\n", "", "else", ":", "\n", "            ", "self", ".", "scale_factor", "=", "10", "# in omniglot, a larger scale factor is required to handle >1000 output classes.", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.distLinear.forward": [[41, 57], ["torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "x.div", "backbones.distLinear.L", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "backbones.distLinear.L.weight.data.div", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_norm", "=", "torch", ".", "norm", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "x", ")", "\n", "x_normalized", "=", "x", ".", "div", "(", "x_norm", "+", "0.00001", ")", "\n", "if", "not", "self", ".", "class_wise_learnable_norm", ":", "\n", "            ", "L_norm", "=", "(", "\n", "torch", ".", "norm", "(", "self", ".", "L", ".", "weight", ".", "data", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", ".", "unsqueeze", "(", "1", ")", "\n", ".", "expand_as", "(", "self", ".", "L", ".", "weight", ".", "data", ")", "\n", ")", "\n", "self", ".", "L", ".", "weight", ".", "data", "=", "self", ".", "L", ".", "weight", ".", "data", ".", "div", "(", "L_norm", "+", "0.00001", ")", "\n", "", "cos_dist", "=", "self", ".", "L", "(", "\n", "x_normalized", "\n", ")", "# matrix product by forward function, but when using WeightNorm, this also multiply the cosine distance by a class-wise learnable norm, see the issue#4&8 in the github", "\n", "scores", "=", "self", ".", "scale_factor", "*", "(", "cos_dist", ")", "\n", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.Flatten.__init__": [[60, 62], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Flatten", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.Flatten.forward": [[63, 65], ["x.view", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.Linear_fw.__init__": [[68, 72], ["torch.Linear.__init__"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ")", ":", "\n", "        ", "super", "(", "Linear_fw", ",", "self", ")", ".", "__init__", "(", "in_features", ",", "out_features", ")", "\n", "self", ".", "weight", ".", "fast", "=", "None", "# Lazy hack to add fast weight link", "\n", "self", ".", "bias", ".", "fast", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.Linear_fw.forward": [[73, 81], ["torch.linear", "torch.linear", "torch.linear", "super().forward"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ResNet.forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "weight", ".", "fast", "is", "not", "None", "and", "self", ".", "bias", ".", "fast", "is", "not", "None", ":", "\n", "            ", "out", "=", "F", ".", "linear", "(", "\n", "x", ",", "self", ".", "weight", ".", "fast", ",", "self", ".", "bias", ".", "fast", "\n", ")", "# weight.fast (fast weight) is the temporaily adapted weight", "\n", "", "else", ":", "\n", "            ", "out", "=", "super", "(", "Linear_fw", ",", "self", ")", ".", "forward", "(", "x", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.Conv2d_fw.__init__": [[84, 98], ["torch.Conv2d.__init__"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "True", "\n", ")", ":", "\n", "        ", "super", "(", "Conv2d_fw", ",", "self", ")", ".", "__init__", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "\n", "bias", "=", "bias", ",", "\n", ")", "\n", "self", ".", "weight", ".", "fast", "=", "None", "\n", "if", "not", "self", ".", "bias", "is", "None", ":", "\n", "            ", "self", ".", "bias", ".", "fast", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.Conv2d_fw.forward": [[99, 120], ["torch.conv2d", "torch.conv2d", "torch.conv2d", "super().forward", "torch.conv2d", "torch.conv2d", "torch.conv2d", "super().forward"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ResNet.forward", "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ResNet.forward"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "bias", "is", "None", ":", "\n", "            ", "if", "self", ".", "weight", ".", "fast", "is", "not", "None", ":", "\n", "                ", "out", "=", "F", ".", "conv2d", "(", "\n", "x", ",", "self", ".", "weight", ".", "fast", ",", "None", ",", "stride", "=", "self", ".", "stride", ",", "padding", "=", "self", ".", "padding", "\n", ")", "\n", "", "else", ":", "\n", "                ", "out", "=", "super", "(", "Conv2d_fw", ",", "self", ")", ".", "forward", "(", "x", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "weight", ".", "fast", "is", "not", "None", "and", "self", ".", "bias", ".", "fast", "is", "not", "None", ":", "\n", "                ", "out", "=", "F", ".", "conv2d", "(", "\n", "x", ",", "\n", "self", ".", "weight", ".", "fast", ",", "\n", "self", ".", "bias", ".", "fast", ",", "\n", "stride", "=", "self", ".", "stride", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "out", "=", "super", "(", "Conv2d_fw", ",", "self", ")", ".", "forward", "(", "x", ")", "\n", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.BatchNorm2d_fw.__init__": [[123, 127], ["torch.BatchNorm2d.__init__"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "BatchNorm2d_fw", ",", "self", ")", ".", "__init__", "(", "num_features", ",", "kwargs", ")", "\n", "self", ".", "weight", ".", "fast", "=", "None", "\n", "self", ".", "bias", ".", "fast", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.BatchNorm2d_fw.forward": [[128, 153], ["src.utils.set_device", "src.utils.set_device", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.batch_norm", "torch.batch_norm", "torch.batch_norm", "torch.batch_norm", "torch.batch_norm", "torch.batch_norm", "x.data.size", "x.data.size"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "running_mean", "=", "set_device", "(", "torch", ".", "zeros", "(", "x", ".", "data", ".", "size", "(", ")", "[", "1", "]", ")", ")", "\n", "running_var", "=", "set_device", "(", "torch", ".", "ones", "(", "x", ".", "data", ".", "size", "(", ")", "[", "1", "]", ")", ")", "\n", "if", "self", ".", "weight", ".", "fast", "is", "not", "None", "and", "self", ".", "bias", ".", "fast", "is", "not", "None", ":", "\n", "            ", "out", "=", "F", ".", "batch_norm", "(", "\n", "x", ",", "\n", "running_mean", ",", "\n", "running_var", ",", "\n", "self", ".", "weight", ".", "fast", ",", "\n", "self", ".", "bias", ".", "fast", ",", "\n", "training", "=", "True", ",", "\n", "momentum", "=", "1", ",", "\n", ")", "\n", "# batch_norm momentum hack: follow hack of Kate Rakelly in pytorch-maml/src/layers.py", "\n", "", "else", ":", "\n", "            ", "out", "=", "F", ".", "batch_norm", "(", "\n", "x", ",", "\n", "running_mean", ",", "\n", "running_var", ",", "\n", "self", ".", "weight", ",", "\n", "self", ".", "bias", ",", "\n", "training", "=", "True", ",", "\n", "momentum", "=", "1", ",", "\n", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ConvBlock.__init__": [[159, 180], ["torch.Module.__init__", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Sequential", "torch.Sequential", "torch.Sequential", "backbones.Conv2d_fw", "backbones.BatchNorm2d_fw", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "configs.model_config.BATCHNORM", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "backbones.ConvBlock.parametrized_layers.append", "backbones.init_layer"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__", "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.init_layer"], ["def", "__init__", "(", "self", ",", "indim", ",", "outdim", ",", "pool", "=", "True", ",", "padding", "=", "1", ")", ":", "\n", "        ", "super", "(", "ConvBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "indim", "=", "indim", "\n", "self", ".", "outdim", "=", "outdim", "\n", "if", "self", ".", "maml", ":", "\n", "            ", "self", ".", "C", "=", "Conv2d_fw", "(", "indim", ",", "outdim", ",", "3", ",", "padding", "=", "padding", ")", "\n", "self", ".", "BN", "=", "BatchNorm2d_fw", "(", "outdim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "C", "=", "nn", ".", "Conv2d", "(", "indim", ",", "outdim", ",", "3", ",", "padding", "=", "padding", ")", "\n", "self", ".", "BN", "=", "BATCHNORM", "(", "outdim", ")", "\n", "", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "parametrized_layers", "=", "[", "self", ".", "C", ",", "self", ".", "BN", ",", "self", ".", "relu", "]", "\n", "if", "pool", ":", "\n", "            ", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "parametrized_layers", ".", "append", "(", "self", ".", "pool", ")", "\n", "\n", "", "for", "layer", "in", "self", ".", "parametrized_layers", ":", "\n", "            ", "init_layer", "(", "layer", ")", "\n", "\n", "", "self", ".", "trunk", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "parametrized_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ConvBlock.forward": [[181, 184], ["backbones.ConvBlock.trunk"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "trunk", "(", "x", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.SimpleBlock.__init__": [[190, 246], ["torch.Module.__init__", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "backbones.Conv2d_fw", "backbones.BatchNorm2d_fw", "backbones.Conv2d_fw", "backbones.BatchNorm2d_fw", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "backbones.SimpleBlock.parametrized_layers.append", "backbones.SimpleBlock.parametrized_layers.append", "backbones.init_layer", "backbones.Conv2d_fw", "backbones.BatchNorm2d_fw", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__", "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.init_layer"], ["def", "__init__", "(", "self", ",", "indim", ",", "outdim", ",", "half_res", ")", ":", "\n", "        ", "super", "(", "SimpleBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "indim", "=", "indim", "\n", "self", ".", "outdim", "=", "outdim", "\n", "if", "self", ".", "maml", ":", "\n", "            ", "self", ".", "C1", "=", "Conv2d_fw", "(", "\n", "indim", ",", "\n", "outdim", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "2", "if", "half_res", "else", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", ")", "\n", "self", ".", "BN1", "=", "BatchNorm2d_fw", "(", "outdim", ")", "\n", "self", ".", "C2", "=", "Conv2d_fw", "(", "outdim", ",", "outdim", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "BN2", "=", "BatchNorm2d_fw", "(", "outdim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "C1", "=", "nn", ".", "Conv2d", "(", "\n", "indim", ",", "\n", "outdim", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "2", "if", "half_res", "else", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", ")", "\n", "self", ".", "BN1", "=", "nn", ".", "BatchNorm2d", "(", "outdim", ")", "\n", "self", ".", "C2", "=", "nn", ".", "Conv2d", "(", "outdim", ",", "outdim", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "BN2", "=", "nn", ".", "BatchNorm2d", "(", "outdim", ")", "\n", "", "self", ".", "relu1", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "relu2", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "parametrized_layers", "=", "[", "self", ".", "C1", ",", "self", ".", "C2", ",", "self", ".", "BN1", ",", "self", ".", "BN2", "]", "\n", "\n", "self", ".", "half_res", "=", "half_res", "\n", "\n", "# if the input number of channels is not equal to the output, then need a 1x1 convolution", "\n", "if", "indim", "!=", "outdim", ":", "\n", "            ", "if", "self", ".", "maml", ":", "\n", "                ", "self", ".", "shortcut", "=", "Conv2d_fw", "(", "\n", "indim", ",", "outdim", ",", "1", ",", "2", "if", "half_res", "else", "1", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "BNshortcut", "=", "BatchNorm2d_fw", "(", "outdim", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "shortcut", "=", "nn", ".", "Conv2d", "(", "\n", "indim", ",", "outdim", ",", "1", ",", "2", "if", "half_res", "else", "1", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "BNshortcut", "=", "nn", ".", "BatchNorm2d", "(", "outdim", ")", "\n", "\n", "", "self", ".", "parametrized_layers", ".", "append", "(", "self", ".", "shortcut", ")", "\n", "self", ".", "parametrized_layers", ".", "append", "(", "self", ".", "BNshortcut", ")", "\n", "self", ".", "shortcut_type", "=", "\"1x1\"", "\n", "", "else", ":", "\n", "            ", "self", ".", "shortcut_type", "=", "\"identity\"", "\n", "\n", "", "for", "layer", "in", "self", ".", "parametrized_layers", ":", "\n", "            ", "init_layer", "(", "layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.SimpleBlock.forward": [[247, 259], ["backbones.SimpleBlock.C1", "backbones.SimpleBlock.BN1", "backbones.SimpleBlock.relu1", "backbones.SimpleBlock.C2", "backbones.SimpleBlock.BN2", "backbones.SimpleBlock.relu2", "backbones.SimpleBlock.BNshortcut", "backbones.SimpleBlock.shortcut"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "C1", "(", "x", ")", "\n", "out", "=", "self", ".", "BN1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu1", "(", "out", ")", "\n", "out", "=", "self", ".", "C2", "(", "out", ")", "\n", "out", "=", "self", ".", "BN2", "(", "out", ")", "\n", "short_out", "=", "(", "\n", "x", "if", "self", ".", "shortcut_type", "==", "\"identity\"", "else", "self", ".", "BNshortcut", "(", "self", ".", "shortcut", "(", "x", ")", ")", "\n", ")", "\n", "out", "=", "out", "+", "short_out", "\n", "out", "=", "self", ".", "relu2", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.BottleneckBlock.__init__": [[265, 326], ["torch.Module.__init__", "int", "torch.ReLU", "torch.ReLU", "torch.ReLU", "backbones.Conv2d_fw", "backbones.BatchNorm2d_fw", "backbones.Conv2d_fw", "backbones.BatchNorm2d_fw", "backbones.Conv2d_fw", "backbones.BatchNorm2d_fw", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "backbones.BottleneckBlock.parametrized_layers.append", "backbones.init_layer", "backbones.Conv2d_fw", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__", "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.init_layer"], ["def", "__init__", "(", "self", ",", "indim", ",", "outdim", ",", "half_res", ")", ":", "\n", "        ", "super", "(", "BottleneckBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "bottleneckdim", "=", "int", "(", "outdim", "/", "4", ")", "\n", "self", ".", "indim", "=", "indim", "\n", "self", ".", "outdim", "=", "outdim", "\n", "if", "self", ".", "maml", ":", "\n", "            ", "self", ".", "C1", "=", "Conv2d_fw", "(", "indim", ",", "bottleneckdim", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "BN1", "=", "BatchNorm2d_fw", "(", "bottleneckdim", ")", "\n", "self", ".", "C2", "=", "Conv2d_fw", "(", "\n", "bottleneckdim", ",", "\n", "bottleneckdim", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "2", "if", "half_res", "else", "1", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", "self", ".", "BN2", "=", "BatchNorm2d_fw", "(", "bottleneckdim", ")", "\n", "self", ".", "C3", "=", "Conv2d_fw", "(", "bottleneckdim", ",", "outdim", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "BN3", "=", "BatchNorm2d_fw", "(", "outdim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "C1", "=", "nn", ".", "Conv2d", "(", "indim", ",", "bottleneckdim", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "BN1", "=", "nn", ".", "BatchNorm2d", "(", "bottleneckdim", ")", "\n", "self", ".", "C2", "=", "nn", ".", "Conv2d", "(", "\n", "bottleneckdim", ",", "\n", "bottleneckdim", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "2", "if", "half_res", "else", "1", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", "self", ".", "BN2", "=", "nn", ".", "BatchNorm2d", "(", "bottleneckdim", ")", "\n", "self", ".", "C3", "=", "nn", ".", "Conv2d", "(", "bottleneckdim", ",", "outdim", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "BN3", "=", "nn", ".", "BatchNorm2d", "(", "outdim", ")", "\n", "\n", "", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "parametrized_layers", "=", "[", "\n", "self", ".", "C1", ",", "\n", "self", ".", "BN1", ",", "\n", "self", ".", "C2", ",", "\n", "self", ".", "BN2", ",", "\n", "self", ".", "C3", ",", "\n", "self", ".", "BN3", ",", "\n", "]", "\n", "self", ".", "half_res", "=", "half_res", "\n", "\n", "# if the input number of channels is not equal to the output, then need a 1x1 convolution", "\n", "if", "indim", "!=", "outdim", ":", "\n", "            ", "if", "self", ".", "maml", ":", "\n", "                ", "self", ".", "shortcut", "=", "Conv2d_fw", "(", "\n", "indim", ",", "outdim", ",", "1", ",", "stride", "=", "2", "if", "half_res", "else", "1", ",", "bias", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "shortcut", "=", "nn", ".", "Conv2d", "(", "\n", "indim", ",", "outdim", ",", "1", ",", "stride", "=", "2", "if", "half_res", "else", "1", ",", "bias", "=", "False", "\n", ")", "\n", "\n", "", "self", ".", "parametrized_layers", ".", "append", "(", "self", ".", "shortcut", ")", "\n", "self", ".", "shortcut_type", "=", "\"1x1\"", "\n", "", "else", ":", "\n", "            ", "self", ".", "shortcut_type", "=", "\"identity\"", "\n", "\n", "", "for", "layer", "in", "self", ".", "parametrized_layers", ":", "\n", "            ", "init_layer", "(", "layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.BottleneckBlock.forward": [[327, 342], ["backbones.BottleneckBlock.C1", "backbones.BottleneckBlock.BN1", "backbones.BottleneckBlock.relu", "backbones.BottleneckBlock.C2", "backbones.BottleneckBlock.BN2", "backbones.BottleneckBlock.relu", "backbones.BottleneckBlock.C3", "backbones.BottleneckBlock.BN3", "backbones.BottleneckBlock.relu", "backbones.BottleneckBlock.shortcut"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "short_out", "=", "x", "if", "self", ".", "shortcut_type", "==", "\"identity\"", "else", "self", ".", "shortcut", "(", "x", ")", "\n", "out", "=", "self", ".", "C1", "(", "x", ")", "\n", "out", "=", "self", ".", "BN1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "C2", "(", "out", ")", "\n", "out", "=", "self", ".", "BN2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "C3", "(", "out", ")", "\n", "out", "=", "self", ".", "BN3", "(", "out", ")", "\n", "out", "=", "out", "+", "short_out", "\n", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ConvNet.__init__": [[345, 359], ["torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "backbones.ConvBlock", "trunk.append", "trunk.append", "backbones.Flatten", "int"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__"], ["    ", "def", "__init__", "(", "self", ",", "depth", ",", "flatten", "=", "True", ")", ":", "\n", "        ", "super", "(", "ConvNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "trunk", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "depth", ")", ":", "\n", "            ", "indim", "=", "3", "if", "i", "==", "0", "else", "64", "\n", "outdim", "=", "64", "\n", "B", "=", "ConvBlock", "(", "indim", ",", "outdim", ",", "pool", "=", "(", "i", "<", "4", ")", ")", "# only pooling for fist 4 layers", "\n", "trunk", ".", "append", "(", "B", ")", "\n", "\n", "", "if", "flatten", ":", "\n", "            ", "trunk", ".", "append", "(", "Flatten", "(", ")", ")", "\n", "\n", "", "self", ".", "trunk", "=", "nn", ".", "Sequential", "(", "*", "trunk", ")", "\n", "self", ".", "final_feat_dim", "=", "(", "int", "(", "IMAGE_SIZE", "/", "16", ")", "*", "8", ")", "**", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ConvNet.forward": [[360, 363], ["backbones.ConvNet.trunk"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "trunk", "(", "x", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ConvNetNopool.__init__": [[368, 381], ["torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "backbones.ConvBlock", "trunk.append"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__"], ["    ", "def", "__init__", "(", "self", ",", "depth", ")", ":", "\n", "        ", "super", "(", "ConvNetNopool", ",", "self", ")", ".", "__init__", "(", ")", "\n", "trunk", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "depth", ")", ":", "\n", "            ", "indim", "=", "3", "if", "i", "==", "0", "else", "64", "\n", "outdim", "=", "64", "\n", "B", "=", "ConvBlock", "(", "\n", "indim", ",", "outdim", ",", "pool", "=", "(", "i", "in", "[", "0", ",", "1", "]", ")", ",", "padding", "=", "0", "if", "i", "in", "[", "0", ",", "1", "]", "else", "1", "\n", ")", "# only first two layer has pooling and no padding TODO: why ?", "\n", "trunk", ".", "append", "(", "B", ")", "\n", "\n", "", "self", ".", "trunk", "=", "nn", ".", "Sequential", "(", "*", "trunk", ")", "\n", "self", ".", "final_feat_dim", "=", "[", "64", ",", "19", ",", "19", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ConvNetNopool.forward": [[382, 385], ["backbones.ConvNetNopool.trunk"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "trunk", "(", "x", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ConvNetS.__init__": [[388, 403], ["torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "backbones.ConvBlock", "trunk.append", "trunk.append", "backbones.Flatten"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__"], ["    ", "def", "__init__", "(", "self", ",", "depth", ",", "flatten", "=", "True", ")", ":", "\n", "        ", "super", "(", "ConvNetS", ",", "self", ")", ".", "__init__", "(", ")", "\n", "trunk", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "depth", ")", ":", "\n", "            ", "indim", "=", "1", "if", "i", "==", "0", "else", "64", "\n", "outdim", "=", "64", "\n", "B", "=", "ConvBlock", "(", "indim", ",", "outdim", ",", "pool", "=", "(", "i", "<", "4", ")", ")", "# only pooling for fist 4 layers", "\n", "trunk", ".", "append", "(", "B", ")", "\n", "\n", "", "if", "flatten", ":", "\n", "            ", "trunk", ".", "append", "(", "Flatten", "(", ")", ")", "\n", "\n", "", "self", ".", "trunk", "=", "nn", ".", "Sequential", "(", "*", "trunk", ")", "\n", "# TODO: final_feat_dim ne doit pas \u00eatre d\u00e9clar\u00e9 comme \u00e7a", "\n", "self", ".", "final_feat_dim", "=", "64", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ConvNetS.forward": [[404, 408], ["backbones.ConvNetS.trunk"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "x", "[", ":", ",", "0", ":", "1", ",", ":", ",", ":", "]", "# only use the first dimension", "\n", "out", "=", "self", ".", "trunk", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ConvNetSNopool.__init__": [[413, 426], ["torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "backbones.ConvBlock", "trunk.append"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__"], ["    ", "def", "__init__", "(", "self", ",", "depth", ")", ":", "\n", "        ", "super", "(", "ConvNetSNopool", ",", "self", ")", ".", "__init__", "(", ")", "\n", "trunk", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "depth", ")", ":", "\n", "            ", "indim", "=", "1", "if", "i", "==", "0", "else", "64", "\n", "outdim", "=", "64", "\n", "B", "=", "ConvBlock", "(", "\n", "indim", ",", "outdim", ",", "pool", "=", "(", "i", "in", "[", "0", ",", "1", "]", ")", ",", "padding", "=", "0", "if", "i", "in", "[", "0", ",", "1", "]", "else", "1", "\n", ")", "# only first two layer has pooling and no padding", "\n", "trunk", ".", "append", "(", "B", ")", "\n", "\n", "", "self", ".", "trunk", "=", "nn", ".", "Sequential", "(", "*", "trunk", ")", "\n", "self", ".", "final_feat_dim", "=", "[", "64", ",", "5", ",", "5", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ConvNetSNopool.forward": [[427, 431], ["backbones.ConvNetSNopool.trunk"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "x", "[", ":", ",", "0", ":", "1", ",", ":", ",", ":", "]", "# only use the first dimension", "\n", "out", "=", "self", ".", "trunk", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ResNet.__init__": [[434, 468], ["torch.Module.__init__", "backbones.Conv2d_fw", "configs.model_config.BATCHNORM", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "backbones.init_layer", "backbones.init_layer", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "len", "range", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "trunk.append", "trunk.append", "block", "trunk.append", "backbones.Flatten"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__", "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.init_layer", "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.init_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "list_of_num_layers", ",", "list_of_out_dims", ",", "flatten", "=", "True", ")", ":", "\n", "# list_of_num_layers specifies number of layers in each stage", "\n", "# list_of_out_dims specifies number of output channel for each stage", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "len", "(", "list_of_num_layers", ")", "==", "4", ",", "\"Can have only four stages\"", "\n", "\n", "conv1", "=", "Conv2d_fw", "(", "3", ",", "64", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "bias", "=", "False", ")", "\n", "bn1", "=", "BATCHNORM", "(", "64", ")", "\n", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "pool1", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "\n", "init_layer", "(", "conv1", ")", "\n", "init_layer", "(", "bn1", ")", "\n", "\n", "trunk", "=", "[", "conv1", ",", "bn1", ",", "relu", ",", "pool1", "]", "\n", "\n", "indim", "=", "64", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "\n", "            ", "for", "j", "in", "range", "(", "list_of_num_layers", "[", "i", "]", ")", ":", "\n", "                ", "half_res", "=", "(", "i", ">=", "1", ")", "and", "(", "j", "==", "0", ")", "\n", "B", "=", "block", "(", "indim", ",", "list_of_out_dims", "[", "i", "]", ",", "half_res", ")", "\n", "trunk", ".", "append", "(", "B", ")", "\n", "indim", "=", "list_of_out_dims", "[", "i", "]", "\n", "\n", "", "", "if", "flatten", ":", "\n", "            ", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "7", ")", "\n", "trunk", ".", "append", "(", "avgpool", ")", "\n", "trunk", ".", "append", "(", "Flatten", "(", ")", ")", "\n", "self", ".", "final_feat_dim", "=", "indim", "\n", "", "else", ":", "\n", "            ", "self", ".", "final_feat_dim", "=", "[", "indim", ",", "7", ",", "7", "]", "\n", "\n", "", "self", ".", "trunk", "=", "nn", ".", "Sequential", "(", "*", "trunk", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ResNet.forward": [[469, 472], ["backbones.ResNet.trunk"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "trunk", "(", "x", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.init_layer": [[16, 24], ["isinstance", "L.weight.data.normal_", "isinstance", "math.sqrt", "L.weight.data.fill_", "L.bias.data.fill_", "float"], "function", ["None"], ["def", "init_layer", "(", "L", ")", ":", "\n", "# Initialization using fan-in", "\n", "    ", "if", "isinstance", "(", "L", ",", "nn", ".", "Conv2d", ")", ":", "\n", "        ", "n", "=", "L", ".", "kernel_size", "[", "0", "]", "*", "L", ".", "kernel_size", "[", "1", "]", "*", "L", ".", "out_channels", "\n", "L", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.0", "/", "float", "(", "n", ")", ")", ")", "\n", "", "elif", "isinstance", "(", "L", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "L", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "L", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.Conv4": [[474, 476], ["backbones.ConvNet"], "function", ["None"], ["", "", "def", "Conv4", "(", "flatten", "=", "True", ")", ":", "\n", "    ", "return", "ConvNet", "(", "4", ",", "flatten", "=", "flatten", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.Conv6": [[478, 480], ["backbones.ConvNet"], "function", ["None"], ["", "def", "Conv6", "(", "flatten", "=", "True", ")", ":", "\n", "    ", "return", "ConvNet", "(", "6", ",", "flatten", "=", "flatten", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.Conv4S": [[482, 484], ["backbones.ConvNetS"], "function", ["None"], ["", "def", "Conv4S", "(", "flatten", "=", "True", ")", ":", "\n", "    ", "return", "ConvNetS", "(", "4", ",", "flatten", "=", "flatten", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ResNet10": [[486, 488], ["backbones.ResNet"], "function", ["None"], ["", "def", "ResNet10", "(", "flatten", "=", "True", ")", ":", "\n", "    ", "return", "ResNet", "(", "SimpleBlock", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "[", "64", ",", "128", ",", "256", ",", "512", "]", ",", "flatten", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ResNet18": [[490, 492], ["backbones.ResNet"], "function", ["None"], ["", "def", "ResNet18", "(", "flatten", "=", "True", ")", ":", "\n", "    ", "return", "ResNet", "(", "SimpleBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "[", "64", ",", "128", ",", "256", ",", "512", "]", ",", "flatten", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ResNet34": [[494, 496], ["backbones.ResNet"], "function", ["None"], ["", "def", "ResNet34", "(", "flatten", "=", "True", ")", ":", "\n", "    ", "return", "ResNet", "(", "SimpleBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "[", "64", ",", "128", ",", "256", ",", "512", "]", ",", "flatten", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ResNet50": [[498, 500], ["backbones.ResNet"], "function", ["None"], ["", "def", "ResNet50", "(", "flatten", "=", "True", ")", ":", "\n", "    ", "return", "ResNet", "(", "BottleneckBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "[", "256", ",", "512", ",", "1024", ",", "2048", "]", ",", "flatten", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ResNet101": [[502, 504], ["backbones.ResNet"], "function", ["None"], ["", "def", "ResNet101", "(", "flatten", "=", "True", ")", ":", "\n", "    ", "return", "ResNet", "(", "BottleneckBlock", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "[", "256", ",", "512", ",", "1024", ",", "2048", "]", ",", "flatten", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.H_3": [[506, 526], ["torch.Sequential", "torch.Conv2d", "configs.model_config.BATCHNORM", "torch.ReLU", "torch.Dropout2d", "torch.Conv2d", "configs.model_config.BATCHNORM", "torch.ReLU", "torch.Dropout2d", "torch.Conv2d", "configs.model_config.BATCHNORM", "torch.ReLU", "torch.Dropout2d", "torch.Conv2d", "configs.model_config.BATCHNORM", "torch.ReLU"], "function", ["None"], ["", "def", "H_3", "(", ")", ":", "\n", "    ", "return", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "3", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "BATCHNORM", "(", "64", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout2d", "(", ")", ",", "\n", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "BATCHNORM", "(", "64", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout2d", "(", ")", ",", "\n", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "BATCHNORM", "(", "64", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout2d", "(", ")", ",", "\n", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "3", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "BATCHNORM", "(", "3", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", ")", ""]], "home.repos.pwc.inspect_result.772922440_pgada.methods.matchingnet.MatchingNet.__init__": [[15, 35], ["src.methods.abstract_meta_learner.AbstractMetaLearner.__init__", "torch.NLLLoss", "torch.NLLLoss", "src.modules.hyper_networks.FullyContextualEmbedding", "src.utils.set_device", "torch.ReLU", "torch.ReLU", "torch.Softmax", "torch.Softmax", "torch.LSTM", "torch.LSTM"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device"], ["    ", "def", "__init__", "(", "self", ",", "model_func", ",", "transportation", "=", "None", ",", "training_stats", "=", "None", ")", ":", "\n", "        ", "super", "(", "MatchingNet", ",", "self", ")", ".", "__init__", "(", "\n", "model_func", ",", "transportation", "=", "transportation", ",", "training_stats", "=", "training_stats", "\n", ")", "\n", "\n", "self", ".", "loss_fn", "=", "nn", ".", "NLLLoss", "(", ")", "\n", "\n", "self", ".", "FCE", "=", "FullyContextualEmbedding", "(", "self", ".", "feature", ".", "final_feat_dim", ")", "\n", "self", ".", "support_features_encoder", "=", "set_device", "(", "\n", "nn", ".", "LSTM", "(", "\n", "self", ".", "feature", ".", "final_feat_dim", ",", "\n", "self", ".", "feature", ".", "final_feat_dim", ",", "\n", "1", ",", "\n", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "True", ",", "\n", ")", "\n", ")", "\n", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.matchingnet.MatchingNet.encode_support_features": [[36, 55], ["[].squeeze", "[].squeeze.div", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "matchingnet.MatchingNet.support_features_encoder", "support_features.unsqueeze", "support_features.size", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "support_features.size", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "methods", ["None"], ["", "def", "encode_support_features", "(", "\n", "self", ",", "\n", "support_features", ":", "torch", ".", "Tensor", ",", "\n", ")", ":", "\n", "        ", "encoded_support_features", "=", "self", ".", "support_features_encoder", "(", "\n", "support_features", ".", "unsqueeze", "(", "0", ")", "\n", ")", "[", "0", "]", ".", "squeeze", "(", "0", ")", "\n", "encoded_support_features", "=", "(", "\n", "support_features", "\n", "+", "encoded_support_features", "[", ":", ",", ":", "support_features", ".", "size", "(", "1", ")", "]", "\n", "+", "encoded_support_features", "[", ":", ",", "support_features", ".", "size", "(", "1", ")", ":", "]", "\n", ")", "\n", "normalized_encoded_support_features", "=", "encoded_support_features", ".", "div", "(", "\n", "torch", ".", "norm", "(", "encoded_support_features", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", ".", "unsqueeze", "(", "1", ")", "\n", ".", "expand_as", "(", "encoded_support_features", ")", "\n", "+", "0.00001", "\n", ")", "\n", "return", "encoded_support_features", ",", "normalized_encoded_support_features", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.matchingnet.MatchingNet.get_logprobs": [[56, 80], ["matchingnet.MatchingNet.FCE", "matchingnet.MatchingNet.softmax", "matchingnet.MatchingNet.relu", "matchingnet.MatchingNet.div().mm", "matchingnet.MatchingNet.mm", "normalized_encoded_support_features.transpose", "matchingnet.MatchingNet.div", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze().expand_as", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "methods", ["None"], ["", "def", "get_logprobs", "(", "\n", "self", ",", "\n", "query_features", ",", "\n", "encoded_support_features", ",", "\n", "normalized_encoded_support_features", ",", "\n", "one_hot_support_labels", ",", "\n", ")", ":", "\n", "\n", "        ", "contextualized_query_features", "=", "self", ".", "FCE", "(", "\n", "query_features", ",", "encoded_support_features", "\n", ")", "\n", "scores", "=", "self", ".", "softmax", "(", "\n", "self", ".", "relu", "(", "\n", "contextualized_query_features", ".", "div", "(", "\n", "torch", ".", "norm", "(", "contextualized_query_features", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", ".", "unsqueeze", "(", "1", ")", "\n", ".", "expand_as", "(", "contextualized_query_features", ")", "\n", "+", "0.00001", "\n", ")", ".", "mm", "(", "normalized_encoded_support_features", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", ")", "\n", "*", "100", "\n", ")", "\n", "logprobs", "=", "(", "scores", ".", "mm", "(", "one_hot_support_labels", ")", "+", "1e-6", ")", ".", "log", "(", ")", "\n", "return", "logprobs", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.matchingnet.MatchingNet.set_forward": [[81, 104], ["matchingnet.MatchingNet.extract_features", "matchingnet.MatchingNet.encode_support_features", "src.methods.utils.one_hot", "matchingnet.MatchingNet.get_logprobs", "matchingnet.MatchingNet.transportation_module"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.extract_features", "home.repos.pwc.inspect_result.772922440_pgada.methods.matchingnet.MatchingNet.encode_support_features", "home.repos.pwc.inspect_result.772922440_pgada.methods.utils.one_hot", "home.repos.pwc.inspect_result.772922440_pgada.methods.matchingnet.MatchingNet.get_logprobs"], ["", "def", "set_forward", "(", "self", ",", "support_images", ",", "support_labels", ",", "query_images", ")", ":", "\n", "        ", "\"\"\"\n        Overwrites method set_forward in AbstractMetaLearner.\n        \"\"\"", "\n", "z_support", ",", "z_query", "=", "self", ".", "extract_features", "(", "support_images", ",", "query_images", ")", "\n", "# If a transportation method in the feature space has been defined, use it", "\n", "if", "self", ".", "transportation_module", ":", "\n", "            ", "z_support", ",", "z_query", "=", "self", ".", "transportation_module", "(", "z_support", ",", "z_query", ")", "\n", "\n", "", "(", "\n", "encoded_support_features", ",", "\n", "encoded_support_features", ",", "\n", ")", "=", "self", ".", "encode_support_features", "(", "z_support", ")", "\n", "\n", "support_labels_one_hot", "=", "utils", ".", "one_hot", "(", "support_labels", ")", "\n", "\n", "logprobs", "=", "self", ".", "get_logprobs", "(", "\n", "z_query", ",", "\n", "encoded_support_features", ",", "\n", "encoded_support_features", ",", "\n", "support_labels_one_hot", ",", "\n", ")", "\n", "return", "logprobs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.methods.uda_ot.UnsupDomAdapOT.set_forward": [[9, 62], ["len", "zip", "torch.cat", "torch.cat", "z_support.numpy.numpy.numpy", "z_query.numpy.numpy.numpy", "support_labels.cpu().numpy.cpu().numpy.cpu().numpy", "sklearn.linear_model.RidgeClassifier", "sklearn.linear_model.RidgeClassifier.fit", "torch.tensor", "src.utils.set_device", "support_images.chunk", "query_images.chunk", "support_chunk.append", "query_chunk.append", "sklearn.linear_model.RidgeClassifier.decision_function", "features.detach().cpu", "support_features.detach().cpu", "query_features.detach().cpu", "z.cpu", "support_labels.cpu().numpy.cpu().numpy.cpu", "uda_ot.UnsupDomAdapOT.extract_features", "uda_ot.UnsupDomAdapOT.transportation_module", "features.detach", "src.utils.set_device", "src.utils.set_device", "support_features.detach", "query_features.detach", "src.utils.set_device", "src.utils.set_device"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.fit", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.extract_features", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device"], ["    ", "def", "set_forward", "(", "self", ",", "support_images", ",", "support_labels", ",", "query_images", ")", ":", "\n", "        ", "\"\"\"\n        Overwrites method set_forward in AbstractMetaLearner.\n        \"\"\"", "\n", "\n", "support_query_size", "=", "len", "(", "support_images", ")", "\n", "n_chunks", "=", "support_query_size", "//", "32", "+", "1", "\n", "\n", "support_chunk", "=", "[", "]", "\n", "query_chunk", "=", "[", "]", "\n", "\n", "for", "support", ",", "query", "in", "zip", "(", "\n", "support_images", ".", "chunk", "(", "n_chunks", ")", ",", "query_images", ".", "chunk", "(", "n_chunks", ")", "\n", ")", ":", "\n", "\n", "            ", "support_features", ",", "query_features", "=", "(", "\n", "features", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "for", "features", "in", "self", ".", "extract_features", "(", "\n", "set_device", "(", "support", ")", ",", "set_device", "(", "query", ")", "\n", ")", "\n", ")", "\n", "\n", "support_chunk", ".", "append", "(", "support_features", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", "\n", "query_chunk", ".", "append", "(", "query_features", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", "\n", "\n", "", "z_support", "=", "torch", ".", "cat", "(", "support_chunk", ",", "dim", "=", "0", ")", "\n", "\n", "del", "support_chunk", "\n", "\n", "z_query", "=", "torch", ".", "cat", "(", "query_chunk", ",", "dim", "=", "0", ")", "\n", "\n", "del", "query_chunk", "\n", "\n", "# If a transportation method in the feature space has been defined, use it", "\n", "if", "self", ".", "transportation_module", ":", "\n", "            ", "z_support", ",", "z_query", "=", "(", "\n", "z", ".", "cpu", "(", ")", "\n", "for", "z", "in", "self", ".", "transportation_module", "(", "\n", "set_device", "(", "z_support", ")", ",", "set_device", "(", "z_query", ")", "\n", ")", "\n", ")", "\n", "\n", "", "z_support", "=", "z_support", ".", "numpy", "(", ")", "\n", "z_query", "=", "z_query", ".", "numpy", "(", ")", "\n", "support_labels", "=", "support_labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "linear_classifier", "=", "RidgeClassifier", "(", "alpha", "=", "0.1", ")", "\n", "linear_classifier", ".", "fit", "(", "z_support", ",", "support_labels", ")", "\n", "\n", "scores", "=", "torch", ".", "tensor", "(", "linear_classifier", ".", "decision_function", "(", "z_query", ")", ")", "\n", "\n", "scores", "=", "set_device", "(", "scores", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.uda_ot.UnsupDomAdapOT.train_loop": [[63, 66], ["NotImplementedError"], "methods", ["None"], ["", "def", "train_loop", "(", "self", ",", "epoch", ",", "train_loader", ",", "optimizer", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\n", "\"UDA-OT from Courty et al. does not support episodic training\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.__init__": [[20, 33], ["torch.Module.__init__", "model_func", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__"], ["def", "__init__", "(", "self", ",", "model_func", ",", "transportation", "=", "None", ",", "training_stats", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            model_func (src.backbones object): backbone function\n            training_stats (Statistics): training statistics of the model, updated during training\n\n        \"\"\"", "\n", "super", "(", "AbstractMetaLearner", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "feature", "=", "model_func", "(", ")", "\n", "self", ".", "training_stats", "=", "training_stats", "\n", "self", ".", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "transportation_module", "=", "transportation", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.set_forward": [[34, 48], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "set_forward", "(", "self", ",", "support_images", ",", "support_labels", ",", "query_images", ")", ":", "\n", "        ", "\"\"\"\n        Predict query set labels using information from support set labelled images.\n        Must be implemented in all classes extending AbstractMetaLearner.\n        Args:\n            support_images (torch.Tensor): shape (number_of_support_set_images, **image_shape)\n            support_labels (torch.Tensor): artificial support set labels in range (0, n_way)\n            query_images (torch.Tensor): shape (number_of_query_set_images, **image_shape)\n\n        Returns:\n            torch.Tensor: shape(n_query*n_way, n_way), classification prediction for each query data\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.fit_on_task": [[49, 73], ["optimizer.zero_grad", "abstract_meta_learner.AbstractMetaLearner.set_forward", "abstract_meta_learner.AbstractMetaLearner.loss_fn", "abstract_meta_learner.AbstractMetaLearner.backward", "optimizer.step", "abstract_meta_learner.AbstractMetaLearner.detach", "abstract_meta_learner.AbstractMetaLearner.detach().item", "abstract_meta_learner.AbstractMetaLearner.detach"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.set_forward"], ["", "def", "fit_on_task", "(", "\n", "self", ",", "support_images", ",", "support_labels", ",", "query_images", ",", "query_labels", ",", "optimizer", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Perform a forward pass and a backward pass on one episode.\n        Args:\n            support_images (torch.Tensor): shape (number_of_support_set_images, **image_shape)\n            support_labels (torch.Tensor): artificial support set labels in range (0, n_way)\n            query_images (torch.Tensor): shape (number_of_query_set_images, **image_shape)\n            query_labels (torch.Tensor): artificial query set labels in range (0, n_way)\n            optimizer (torch.optim.Optimizer): model optimizer\n\n        Returns:\n            tuple(torch.Tensor, torch.Tensor): detached from the computational graph\n                - shape(n_query*n_way, n_way), classification prediction for each query data\n                - shape(,), training loss\n        \"\"\"", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "scores", "=", "self", ".", "set_forward", "(", "support_images", ",", "support_labels", ",", "query_images", ")", "\n", "loss", "=", "self", ".", "loss_fn", "(", "scores", ",", "query_labels", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "return", "scores", ".", "detach", "(", ")", ",", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.extract_features": [[74, 93], ["src.utils.set_device", "src.utils.set_device", "abstract_meta_learner.AbstractMetaLearner.feature.forward", "abstract_meta_learner.AbstractMetaLearner.feature.forward"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ResNet.forward", "home.repos.pwc.inspect_result.772922440_pgada.modules.backbones.ResNet.forward"], ["", "def", "extract_features", "(", "self", ",", "support_images", ",", "query_images", ")", ":", "\n", "        ", "\"\"\"\n        Computes the features vectors of the support and query sets\n        Args:\n            support_images (torch.Tensor): shape (n_support_images, **image_dim) input data\n            query_images (torch.Tensor): shape (n_query_images, **image_dim) input data\n\n        Returns:\n            Tuple(torch.Tensor, torch.Tensor): features vectors of the support and query sets, respectively of shapes\n            (n_support_images, features_dim) and (n_query_images, features_dim)\n        \"\"\"", "\n", "# Set to CUDA if available", "\n", "support_images", "=", "set_device", "(", "support_images", ")", "\n", "query_images", "=", "set_device", "(", "query_images", ")", "\n", "\n", "z_support", "=", "self", ".", "feature", ".", "forward", "(", "support_images", ")", "\n", "z_query", "=", "self", ".", "feature", ".", "forward", "(", "query_images", ")", "\n", "\n", "return", "z_support", ",", "z_query", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.get_prototypes": [[94, 109], ["len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "features[].mean", "range", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_prototypes", "(", "features", ",", "labels", ")", ":", "\n", "        ", "\"\"\"\n        Compute a prototype for each class.\n        Args:\n            features (torch.Tensor): shape[n_images, feature_dim], feature vectors\n            labels (torch.Tensor): shape[n_images], label corresponding to each feature vector\n        Returns:\n            torch.Tensor: prototypes. shape[number_of_unique_values_in_labels, feature_dim]\n        \"\"\"", "\n", "\n", "n_way", "=", "len", "(", "torch", ".", "unique", "(", "labels", ")", ")", "\n", "# Prototype i is the mean of all instances of features corresponding to labels == i", "\n", "return", "torch", ".", "cat", "(", "\n", "[", "features", "[", "torch", ".", "nonzero", "(", "labels", "==", "label", ")", "]", ".", "mean", "(", "0", ")", "for", "label", "in", "range", "(", "n_way", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.evaluate": [[111, 126], ["scores.data.topk", "float", "float", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "evaluate", "(", "scores", ",", "query_labels", ")", ":", "\n", "        ", "\"\"\"\n        Predict labels of query images and returns the number of correct top1 predictions\n        Args:\n            scores (torch.Tensor): shape (number_of_query_set_images, n_way)\n            query_labels (torch.Tensor): artificial query set labels in range (0, n_way)\n\n        Returns:\n            float: classification accuracy in [0,1]\n        \"\"\"", "\n", "\n", "topk_scores", ",", "topk_labels", "=", "scores", ".", "data", ".", "topk", "(", "1", ",", "1", ",", "True", ",", "True", ")", "\n", "top1_correct", "=", "float", "(", "(", "topk_labels", "[", ":", ",", "0", "]", "==", "query_labels", ")", ".", "sum", "(", ")", ")", "\n", "return", "float", "(", "top1_correct", ")", "/", "len", "(", "query_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.get_task_perf": [[127, 162], ["pandas.concat", "pandas.DataFrame", "range", "range"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_task_perf", "(", "\n", "task_id", ",", "classification_scores", ",", "labels", ",", "class_ids", ",", "source_id", ",", "target_id", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Records the classification results for each query instance.\n        Args:\n            task_id (int): index of the task\n            classification_scores (torch.Tensor): predicted classification scores\n            labels (torch.Tensor): ground truth labels\n            class_ids (list[int]): indices of the classes composing the current classification task\n            source_id (int): index of the source domain for this task\n            target_id (int): index of the target domain for this task\n\n        Returns:\n            pd.DataFrame: for each couple (query, class), gives classification score, class_id,\n                ground truth query label, current task id and source and target domain,\n        \"\"\"", "\n", "return", "pd", ".", "concat", "(", "\n", "[", "\n", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "\"task_id\"", ":", "task_id", ",", "\n", "\"source_domain\"", ":", "source_id", ",", "\n", "\"target_domain\"", ":", "target_id", ",", "\n", "\"image_id\"", ":", "i", ",", "\n", "\"true_label\"", ":", "class_ids", "[", "labels", "[", "i", "]", "]", ",", "\n", "\"predicted_label\"", ":", "[", "\n", "class_ids", "[", "label", "]", "\n", "for", "label", "in", "range", "(", "classification_scores", ".", "shape", "[", "1", "]", ")", "\n", "]", ",", "\n", "\"score\"", ":", "classification_scores", "[", "i", "]", ",", "\n", "}", "\n", ")", "\n", "for", "i", "in", "range", "(", "labels", ".", "shape", "[", "0", "]", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.train_loop": [[165, 209], ["enumerate", "src.utils.set_device", "abstract_meta_learner.AbstractMetaLearner.fit_on_task", "loss_list.append", "acc_list.append", "numpy.asarray().mean", "numpy.asarray().mean", "loguru.logger.info", "abstract_meta_learner.AbstractMetaLearner.evaluate", "numpy.asarray", "numpy.asarray", "len", "numpy.asarray().mean", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.fit_on_task", "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.evaluate"], ["", "def", "train_loop", "(", "self", ",", "epoch", ",", "train_loader", ",", "optimizer", ")", ":", "\n", "        ", "\"\"\"\n        Executes one training epoch\n        Args:\n            epoch (int): current epoch\n            train_loader (DataLoader): loader of a given number of episodes\n            optimizer (torch.optim.Optimizer): model optimizer\n\n        Returns:\n            tuple(float, float): resp. average loss and classification accuracy\n        \"\"\"", "\n", "print_freq", "=", "100", "\n", "\n", "loss_list", "=", "[", "]", "\n", "acc_list", "=", "[", "]", "\n", "for", "episode_index", ",", "(", "\n", "support_images", ",", "\n", "support_labels", ",", "\n", "query_images", ",", "\n", "query_labels", ",", "\n", "_", ",", "\n", "_", ",", "\n", "_", ",", "\n", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "query_labels", "=", "set_device", "(", "query_labels", ")", "\n", "scores", ",", "loss_value", "=", "self", ".", "fit_on_task", "(", "\n", "support_images", ",", "support_labels", ",", "query_images", ",", "query_labels", ",", "optimizer", "\n", ")", "\n", "\n", "loss_list", ".", "append", "(", "loss_value", ")", "\n", "\n", "acc_list", ".", "append", "(", "self", ".", "evaluate", "(", "scores", ",", "query_labels", ")", "*", "100", ")", "\n", "\n", "if", "episode_index", "%", "print_freq", "==", "print_freq", "-", "1", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"Epoch {epoch} | Batch {episode_index}/{n_batches} | Loss {loss}\"", ".", "format", "(", "\n", "epoch", "=", "epoch", ",", "\n", "episode_index", "=", "episode_index", "+", "1", ",", "\n", "n_batches", "=", "len", "(", "train_loader", ")", ",", "\n", "loss", "=", "np", ".", "asarray", "(", "loss_list", ")", ".", "mean", "(", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "", "", "return", "np", ".", "asarray", "(", "loss_list", ")", ".", "mean", "(", ")", ",", "np", ".", "asarray", "(", "acc_list", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.eval_loop": [[210, 267], ["len", "tqdm.tqdm.tqdm", "pandas.concat", "numpy.asarray", "numpy.mean", "numpy.std", "loguru.logger.info", "enumerate", "src.utils.set_device", "abstract_meta_learner.AbstractMetaLearner.set_forward().detach", "abstract_meta_learner.AbstractMetaLearner.loss_fn().detach().item", "evaluation_stats.append", "loss_all.append", "numpy.asarray.append", "numpy.asarray().mean", "abstract_meta_learner.AbstractMetaLearner.get_task_perf", "abstract_meta_learner.AbstractMetaLearner.set_forward", "abstract_meta_learner.AbstractMetaLearner.loss_fn().detach", "abstract_meta_learner.AbstractMetaLearner.cpu", "src.utils.set_device.cpu().detach", "abstract_meta_learner.AbstractMetaLearner.evaluate", "src.methods.utils.confidence_interval", "numpy.asarray", "abstract_meta_learner.AbstractMetaLearner.loss_fn", "src.utils.set_device.cpu"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.get_task_perf", "home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.set_forward", "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.evaluate", "home.repos.pwc.inspect_result.772922440_pgada.methods.utils.confidence_interval"], ["", "def", "eval_loop", "(", "self", ",", "test_loader", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            test_loader (DataLoader): loader of a given number of episodes\n\n        Returns:\n            tuple(float, float, pd.DataFrame): resp. average loss and classification accuracy,\n                and advanced evaluation statistics\n        \"\"\"", "\n", "acc_all", "=", "[", "]", "\n", "loss_all", "=", "[", "]", "\n", "evaluation_stats", "=", "[", "]", "\n", "\n", "n_tasks", "=", "len", "(", "test_loader", ")", "\n", "for", "episode_index", ",", "(", "\n", "support_images", ",", "\n", "support_labels", ",", "\n", "query_images", ",", "\n", "query_labels", ",", "\n", "class_ids", ",", "\n", "source_domain", ",", "\n", "target_domain", ",", "\n", ")", "in", "tqdm", "(", "enumerate", "(", "test_loader", ")", ")", ":", "\n", "\n", "            ", "query_labels", "=", "set_device", "(", "query_labels", ")", "\n", "scores", "=", "self", ".", "set_forward", "(", "\n", "support_images", ",", "support_labels", ",", "query_images", "\n", ")", ".", "detach", "(", ")", "\n", "\n", "loss_value", "=", "self", ".", "loss_fn", "(", "scores", ",", "query_labels", ")", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "\n", "evaluation_stats", ".", "append", "(", "\n", "self", ".", "get_task_perf", "(", "\n", "episode_index", ",", "\n", "scores", ".", "cpu", "(", ")", ",", "\n", "query_labels", ".", "cpu", "(", ")", ".", "detach", "(", ")", ",", "\n", "class_ids", ",", "\n", "source_domain", ",", "\n", "target_domain", ",", "\n", ")", "\n", ")", "\n", "\n", "loss_all", ".", "append", "(", "loss_value", ")", "\n", "\n", "acc_all", ".", "append", "(", "self", ".", "evaluate", "(", "scores", ",", "query_labels", ")", "*", "100", ")", "\n", "\n", "", "evaluations_stats_df", "=", "pd", ".", "concat", "(", "evaluation_stats", ",", "ignore_index", "=", "True", ")", "\n", "acc_all", "=", "np", ".", "asarray", "(", "acc_all", ")", "\n", "acc_mean", "=", "np", ".", "mean", "(", "acc_all", ")", "\n", "acc_std", "=", "np", ".", "std", "(", "acc_all", ")", "\n", "logger", ".", "info", "(", "\n", "\"%d Test Accuracy = %4.2f%% +- %4.2f%%\"", "\n", "%", "(", "n_tasks", ",", "acc_mean", ",", "confidence_interval", "(", "acc_std", ",", "n_tasks", ")", ")", "\n", ")", "\n", "\n", "return", "np", ".", "asarray", "(", "loss_all", ")", ".", "mean", "(", ")", ",", "acc_mean", ",", "evaluations_stats_df", "\n", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.GaussianModel.__init__": [[48, 71], ["[].mean", "ndatas.reshape"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "n_ways", ",", "\n", "lam", ",", "\n", "ndatas", ",", "\n", "n_runs", ",", "\n", "n_shot", ",", "\n", "n_queries", ",", "\n", "n_nfeat", ",", "\n", "n_lsamples", ",", "\n", "n_usamples", ",", "\n", ")", ":", "\n", "        ", "self", ".", "n_ways", "=", "n_ways", "\n", "self", ".", "mus", "=", "None", "# shape [n_runs][n_ways][n_nfeat]", "\n", "self", ".", "lam", "=", "lam", "\n", "self", ".", "n_runs", "=", "n_runs", "\n", "self", ".", "n_queries", "=", "n_queries", "\n", "self", ".", "n_lsamples", "=", "n_lsamples", "\n", "self", ".", "n_usamples", "=", "n_usamples", "\n", "self", ".", "mus", "=", "ndatas", ".", "reshape", "(", "n_runs", ",", "n_shot", "+", "n_queries", ",", "n_ways", ",", "n_nfeat", ")", "[", "\n", ":", ",", "\n", ":", "n_shot", ",", "\n", "]", ".", "mean", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.GaussianModel.cuda": [[72, 75], ["maximum_a_posteriori.GaussianModel.mus.cuda"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.GaussianModel.cuda"], ["", "def", "cuda", "(", "self", ")", ":", "\n", "# Inplace", "\n", "        ", "self", ".", "mus", "=", "self", ".", "mus", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.GaussianModel.updateFromEstimate": [[76, 80], ["None"], "methods", ["None"], ["", "def", "updateFromEstimate", "(", "self", ",", "estimate", ",", "alpha", ")", ":", "\n", "\n", "        ", "Dmus", "=", "estimate", "-", "self", ".", "mus", "\n", "self", ".", "mus", "=", "self", ".", "mus", "+", "alpha", "*", "(", "Dmus", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.GaussianModel.compute_optimal_transport": [[81, 101], ["r.cuda.cuda.cuda", "c.cuda.cuda.cuda", "torch.exp", "torch.zeros().cuda", "torch.exp.view().sum().unsqueeze().unsqueeze", "torch.max", "torch.exp.sum", "torch.sum", "torch.zeros", "torch.abs", "torch.exp.view().sum().unsqueeze", "torch.exp.sum", "torch.exp.view().sum", "torch.exp.sum", "torch.exp.view"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.GaussianModel.cuda", "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.GaussianModel.cuda", "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.GaussianModel.cuda"], ["", "def", "compute_optimal_transport", "(", "self", ",", "M", ",", "r", ",", "c", ",", "epsilon", "=", "1e-6", ")", ":", "\n", "\n", "        ", "r", "=", "r", ".", "cuda", "(", ")", "\n", "c", "=", "c", ".", "cuda", "(", ")", "\n", "n_runs", ",", "n", ",", "m", "=", "M", ".", "shape", "\n", "P", "=", "torch", ".", "exp", "(", "-", "self", ".", "lam", "*", "M", ")", "\n", "P", "=", "P", "/", "P", ".", "view", "(", "(", "n_runs", ",", "-", "1", ")", ")", ".", "sum", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "u", "=", "torch", ".", "zeros", "(", "n_runs", ",", "n", ")", ".", "cuda", "(", ")", "\n", "maxiters", "=", "1000", "\n", "iters", "=", "1", "\n", "# normalize this matrix", "\n", "while", "torch", ".", "max", "(", "torch", ".", "abs", "(", "u", "-", "P", ".", "sum", "(", "2", ")", ")", ")", ">", "epsilon", ":", "\n", "            ", "u", "=", "P", ".", "sum", "(", "2", ")", "\n", "P", "=", "P", "*", "(", "r", "/", "u", ")", ".", "view", "(", "(", "n_runs", ",", "-", "1", ",", "1", ")", ")", "\n", "P", "=", "P", "*", "(", "c", "/", "P", ".", "sum", "(", "1", ")", ")", ".", "view", "(", "(", "n_runs", ",", "1", ",", "-", "1", ")", ")", "\n", "if", "iters", "==", "maxiters", ":", "\n", "                ", "break", "\n", "", "iters", "=", "iters", "+", "1", "\n", "", "return", "P", ",", "torch", ".", "sum", "(", "P", "*", "M", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.GaussianModel.getProbas": [[102, 120], ["torch.zeros_like", "torch.ones", "maximum_a_posteriori.GaussianModel.compute_optimal_transport", "p_xj[].scatter", "torch.ones", "labels[].unsqueeze", "ndatas.unsqueeze", "maximum_a_posteriori.GaussianModel.mus.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.GaussianModel.compute_optimal_transport"], ["", "def", "getProbas", "(", "self", ",", "ndatas", ",", "labels", ")", ":", "\n", "# compute squared dist to centroids [n_runs][n_samples][n_ways]", "\n", "        ", "dist", "=", "(", "ndatas", ".", "unsqueeze", "(", "2", ")", "-", "self", ".", "mus", ".", "unsqueeze", "(", "1", ")", ")", ".", "norm", "(", "dim", "=", "3", ")", ".", "pow", "(", "2", ")", "\n", "\n", "p_xj", "=", "torch", ".", "zeros_like", "(", "dist", ")", "\n", "r", "=", "torch", ".", "ones", "(", "self", ".", "n_runs", ",", "self", ".", "n_usamples", ")", "\n", "c", "=", "torch", ".", "ones", "(", "self", ".", "n_runs", ",", "self", ".", "n_ways", ")", "*", "self", ".", "n_queries", "\n", "\n", "p_xj_test", ",", "_", "=", "self", ".", "compute_optimal_transport", "(", "\n", "dist", "[", ":", ",", "self", ".", "n_lsamples", ":", "]", ",", "r", ",", "c", ",", "epsilon", "=", "1e-6", "\n", ")", "\n", "p_xj", "[", ":", ",", "self", ".", "n_lsamples", ":", "]", "=", "p_xj_test", "\n", "\n", "p_xj", "[", ":", ",", ":", "self", ".", "n_lsamples", "]", "=", "p_xj", "[", ":", ",", ":", "self", ".", "n_lsamples", "]", ".", "scatter", "(", "\n", "2", ",", "labels", "[", ":", ",", ":", "self", ".", "n_lsamples", "]", ".", "unsqueeze", "(", "2", ")", ",", "1", "\n", ")", "\n", "\n", "return", "p_xj", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.GaussianModel.estimateFromMask": [[121, 126], ["mask.permute().matmul().div", "mask.sum().unsqueeze", "mask.permute().matmul", "mask.sum", "mask.permute"], "methods", ["None"], ["", "def", "estimateFromMask", "(", "self", ",", "mask", ",", "ndatas", ")", ":", "\n", "\n", "        ", "emus", "=", "mask", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "matmul", "(", "ndatas", ")", ".", "div", "(", "mask", ".", "sum", "(", "dim", "=", "1", ")", ".", "unsqueeze", "(", "2", ")", ")", "\n", "\n", "return", "emus", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.MAP.__init__": [[129, 133], ["src.methods.abstract_meta_learner.AbstractMetaLearner.__init__", "torch.nn.NLLLoss"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model_func", ",", "transportation", "=", "None", ",", "power_transform", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model_func", ")", "\n", "self", ".", "loss_fn", "=", "nn", ".", "NLLLoss", "(", ")", "\n", "self", ".", "power_transform", "=", "power_transform", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.MAP.set_forward": [[134, 217], ["maximum_a_posteriori.MAP.extract_features", "torch.cat", "torch.cat", "torch.cat().unsqueeze", "torch.arange().view().expand().clone().view", "maximum_a_posteriori.QRreduction", "ndatas.cuda.cuda.size", "maximum_a_posteriori.scaleEachUnitaryDatas", "maximum_a_posteriori.centerDatas", "print", "ndatas.cuda.cuda.cuda", "labels.cuda.cuda.cuda", "maximum_a_posteriori.GaussianModel", "maximum_a_posteriori.MAP.loop", "torch.pow", "ndatas.cuda.cuda.size", "support_labels.view().permute().sort", "torch.cat", "torch.arange().view().expand().clone", "maximum_a_posteriori.MAP.squeeze", "range", "range", "torch.cat.sort", "support_labels.view().permute", "torch.arange().view().expand", "support_labels.view", "torch.arange().view", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.extract_features", "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.QRreduction", "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.scaleEachUnitaryDatas", "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.centerDatas", "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.GaussianModel.cuda", "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.GaussianModel.cuda", "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.MAP.loop"], ["", "def", "set_forward", "(", "self", ",", "support_images", ",", "support_labels", ",", "query_images", ")", ":", "\n", "        ", "\"\"\"\n        Overwrites method set_forward in AbstractMetaLearner.\n        \"\"\"", "\n", "n_shot", "=", "evaluation_config", ".", "N_SOURCE_EVAL", "\n", "n_ways", "=", "evaluation_config", ".", "N_WAY_EVAL", "\n", "n_queries", "=", "evaluation_config", ".", "N_TARGET_EVAL", "\n", "n_runs", "=", "1", "\n", "n_lsamples", "=", "n_ways", "*", "n_shot", "\n", "n_usamples", "=", "n_ways", "*", "n_queries", "\n", "n_samples", "=", "n_lsamples", "+", "n_usamples", "\n", "self", ".", "n_lsamples", "=", "n_lsamples", "\n", "self", ".", "n_runs", "=", "n_runs", "\n", "\n", "z_support", ",", "z_query", "=", "self", ".", "extract_features", "(", "support_images", ",", "query_images", ")", "\n", "label_mapping", "=", "support_labels", ".", "view", "(", "n_ways", ",", "n_shot", ")", ".", "permute", "(", "1", ",", "0", ")", ".", "sort", "(", ")", "[", "1", "]", "[", "0", "]", "\n", "\n", "support_mapping", "=", "torch", ".", "cat", "(", "[", "label_mapping", "*", "n_shot", "+", "i", "for", "i", "in", "range", "(", "n_shot", ")", "]", ")", "\n", "query_mapping", "=", "torch", ".", "cat", "(", "\n", "[", "label_mapping", "*", "n_queries", "+", "i", "for", "i", "in", "range", "(", "n_queries", ")", "]", "\n", ")", "\n", "\n", "ndatas", "=", "torch", ".", "cat", "(", "\n", "(", "z_support", "[", "support_mapping", "]", ",", "z_query", "[", "query_mapping", "]", ")", ",", "dim", "=", "0", "\n", ")", ".", "unsqueeze", "(", "0", ")", "\n", "labels", "=", "(", "\n", "torch", ".", "arange", "(", "n_ways", ")", "\n", ".", "view", "(", "1", ",", "1", ",", "n_ways", ")", "\n", ".", "expand", "(", "n_runs", ",", "n_shot", "+", "n_queries", ",", "5", ")", "\n", ".", "clone", "(", ")", "\n", ".", "view", "(", "n_runs", ",", "n_samples", ")", "\n", ")", "\n", "\n", "if", "self", ".", "power_transform", ":", "\n", "# Power transform", "\n", "            ", "beta", "=", "0.5", "\n", "ndatas", "[", ":", ",", "]", "=", "torch", ".", "pow", "(", "\n", "ndatas", "[", "\n", ":", ",", "\n", "]", "\n", "+", "1e-6", ",", "\n", "beta", ",", "\n", ")", "\n", "\n", "", "ndatas", "=", "QRreduction", "(", "ndatas", ")", "# Now ndatas has shape (1, n_samples, n_samples)", "\n", "n_nfeat", "=", "ndatas", ".", "size", "(", "2", ")", "\n", "\n", "ndatas", "=", "scaleEachUnitaryDatas", "(", "ndatas", ")", "\n", "\n", "# trans-mean-sub", "\n", "\n", "ndatas", "=", "centerDatas", "(", "ndatas", ",", "n_lsamples", ")", "\n", "\n", "print", "(", "\"size of the datas...\"", ",", "ndatas", ".", "size", "(", ")", ")", "\n", "\n", "# switch to cuda", "\n", "ndatas", "=", "ndatas", ".", "cuda", "(", ")", "\n", "labels", "=", "labels", ".", "cuda", "(", ")", "\n", "\n", "# MAP", "\n", "lam", "=", "10", "\n", "model", "=", "GaussianModel", "(", "\n", "n_ways", ",", "\n", "lam", ",", "\n", "ndatas", ",", "\n", "n_runs", ",", "\n", "n_shot", ",", "\n", "n_queries", ",", "\n", "n_nfeat", ",", "\n", "n_lsamples", ",", "\n", "n_usamples", ",", "\n", ")", "\n", "\n", "self", ".", "alpha", "=", "0.2", "\n", "\n", "self", ".", "ndatas", "=", "ndatas", "\n", "self", ".", "labels", "=", "labels", "\n", "\n", "probas", "=", "self", ".", "loop", "(", "model", ",", "n_epochs", "=", "20", ")", "\n", "\n", "# TODO remettre les labels dans le sens originel", "\n", "\n", "return", "probas", ".", "squeeze", "(", "0", ")", "[", "n_lsamples", ":", "]", "[", "query_mapping", ".", "sort", "(", ")", "[", "1", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.MAP.getAccuracy": [[218, 226], ["probas.argmax", "labels.eq().float", "matches[].mean", "matches[].mean.mean().item", "math.sqrt", "labels.eq", "matches[].mean.mean", "matches[].mean.std().item", "matches[].mean.std"], "methods", ["None"], ["", "def", "getAccuracy", "(", "self", ",", "probas", ",", "labels", ")", ":", "\n", "        ", "olabels", "=", "probas", ".", "argmax", "(", "dim", "=", "2", ")", "\n", "matches", "=", "labels", ".", "eq", "(", "olabels", ")", ".", "float", "(", ")", "\n", "acc_test", "=", "matches", "[", ":", ",", "self", ".", "n_lsamples", ":", "]", ".", "mean", "(", "1", ")", "\n", "\n", "m", "=", "acc_test", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "pm", "=", "acc_test", ".", "std", "(", ")", ".", "item", "(", ")", "*", "1.96", "/", "math", ".", "sqrt", "(", "self", ".", "n_runs", ")", "\n", "return", "m", ",", "pm", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.MAP.performEpoch": [[227, 235], ["model.getProbas", "model.estimateFromMask", "model.updateFromEstimate"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.GaussianModel.getProbas", "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.GaussianModel.estimateFromMask", "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.GaussianModel.updateFromEstimate"], ["", "def", "performEpoch", "(", "self", ",", "model", ",", "epochInfo", "=", "None", ")", ":", "\n", "        ", "p_xj", "=", "model", ".", "getProbas", "(", "self", ".", "ndatas", ",", "self", ".", "labels", ")", "\n", "self", ".", "probas", "=", "p_xj", "\n", "\n", "m_estimates", "=", "model", ".", "estimateFromMask", "(", "self", ".", "probas", ",", "self", ".", "ndatas", ")", "\n", "\n", "# update centroids", "\n", "model", ".", "updateFromEstimate", "(", "m_estimates", ",", "self", ".", "alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.MAP.loop": [[236, 245], ["model.getProbas", "tqdm.tqdm.tqdm", "model.getProbas", "range", "maximum_a_posteriori.MAP.performEpoch"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.GaussianModel.getProbas", "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.GaussianModel.getProbas", "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.MAP.performEpoch"], ["", "def", "loop", "(", "self", ",", "model", ",", "n_epochs", "=", "20", ")", ":", "\n", "        ", "self", ".", "probas", "=", "model", ".", "getProbas", "(", "self", ".", "ndatas", ",", "self", ".", "labels", ")", "\n", "\n", "for", "epoch", "in", "tqdm", "(", "range", "(", "1", ",", "n_epochs", "+", "1", ")", ")", ":", "\n", "            ", "self", ".", "performEpoch", "(", "model", ",", "epochInfo", "=", "(", "epoch", ",", "n_epochs", ")", ")", "\n", "\n", "# get final accuracy and return it", "\n", "", "op_xj", "=", "model", ".", "getProbas", "(", "self", ".", "ndatas", ",", "self", ".", "labels", ")", "\n", "return", "op_xj", "\n", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.centerDatas": [[22, 33], ["datas[].mean", "datas[].mean", "torch.zeros_like", "torch.norm", "torch.norm"], "function", ["None"], ["def", "centerDatas", "(", "datas", ",", "n_lsamples", ")", ":", "\n", "    ", "support_means", "=", "datas", "[", ":", ",", ":", "n_lsamples", "]", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "query_means", "=", "datas", "[", ":", ",", "n_lsamples", ":", "]", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "support_norm", "=", "torch", ".", "norm", "(", "datas", "[", ":", ",", ":", "n_lsamples", "]", ",", "2", ",", "2", ")", "[", ":", ",", ":", ",", "None", "]", "\n", "query_norm", "=", "torch", ".", "norm", "(", "datas", "[", ":", ",", "n_lsamples", ":", "]", ",", "2", ",", "2", ")", "[", ":", ",", ":", ",", "None", "]", "\n", "\n", "datas_out", "=", "torch", ".", "zeros_like", "(", "datas", ")", "\n", "datas_out", "[", ":", ",", ":", "n_lsamples", "]", "=", "(", "datas", "[", ":", ",", ":", "n_lsamples", "]", "-", "support_means", ")", "/", "support_norm", "\n", "datas_out", "[", ":", ",", "n_lsamples", ":", "]", "=", "(", "datas", "[", ":", ",", "n_lsamples", ":", "]", "-", "query_means", ")", "/", "query_norm", "\n", "\n", "return", "datas_out", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.scaleEachUnitaryDatas": [[35, 38], ["datas.norm"], "function", ["None"], ["", "def", "scaleEachUnitaryDatas", "(", "datas", ")", ":", "\n", "    ", "norms", "=", "datas", ".", "norm", "(", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "return", "datas", "/", "norms", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.maximum_a_posteriori.QRreduction": [[40, 44], ["ndatas.permute.permute", "torch.qr", "datas.permute"], "function", ["None"], ["", "def", "QRreduction", "(", "datas", ")", ":", "\n", "    ", "ndatas", "=", "torch", ".", "qr", "(", "datas", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", ".", "R", "\n", "ndatas", "=", "ndatas", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "return", "ndatas", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.protonet.ProtoNet.set_forward": [[7, 22], ["protonet.ProtoNet.extract_features", "protonet.ProtoNet.get_prototypes", "src.methods.utils.euclidean_dist", "protonet.ProtoNet.transportation_module"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.extract_features", "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.get_prototypes", "home.repos.pwc.inspect_result.772922440_pgada.methods.utils.euclidean_dist"], ["    ", "def", "set_forward", "(", "self", ",", "support_images", ",", "support_labels", ",", "query_images", ")", ":", "\n", "        ", "\"\"\"\n        Overwrites method set_forward in AbstractMetaLearner.\n        \"\"\"", "\n", "z_support", ",", "z_query", "=", "self", ".", "extract_features", "(", "support_images", ",", "query_images", ")", "\n", "\n", "# If a transportation method in the feature space has been defined, use it", "\n", "if", "self", ".", "transportation_module", ":", "\n", "            ", "z_support", ",", "z_query", "=", "self", ".", "transportation_module", "(", "z_support", ",", "z_query", ")", "\n", "\n", "", "z_proto", "=", "self", ".", "get_prototypes", "(", "z_support", ",", "support_labels", ")", "\n", "\n", "dists", "=", "euclidean_dist", "(", "z_query", ",", "z_proto", ")", "\n", "scores", "=", "-", "dists", "\n", "return", "scores", "\n", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.methods.utils.confidence_interval": [[8, 19], ["numpy.sqrt"], "function", ["None"], ["from", "src", ".", "data_tools", ".", "utils", "import", "episodic_collate_fn", "\n", "\n", "\n", "\n", "def", "set_device", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    Switch a tensor to GPU if CUDA is available, to CPU otherwise\n    \"\"\"", "\n", "device", "=", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", "\n", "return", "x", ".", "to", "(", "device", "=", "device", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.utils.one_hot": [[21, 34], ["src.utils.set_device", "torch.max", "torch.max", "torch.zeros().scatter_", "torch.zeros().scatter_", "labels.unsqueeze", "torch.zeros", "torch.zeros", "len"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device"], ["    ", "\"\"\"\n    Plot images of an episode, separating support and query images.\n    Args:\n        support_images (torch.Tensor): tensor of multiple-channel support images\n        query_images (torch.Tensor): tensor of multiple-channel query images\n    \"\"\"", "\n", "\n", "def", "matplotlib_imshow", "(", "img", ")", ":", "\n", "        ", "npimg", "=", "img", ".", "numpy", "(", ")", "\n", "plt", ".", "imshow", "(", "np", ".", "transpose", "(", "npimg", ",", "(", "1", ",", "2", ",", "0", ")", ")", ")", "\n", "\n", "", "support_grid", "=", "torchvision", ".", "utils", ".", "make_grid", "(", "support_images", ")", "\n", "matplotlib_imshow", "(", "support_grid", ")", "\n", "plt", ".", "title", "(", "\"support images\"", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.utils.euclidean_dist": [[37, 49], ["x.unsqueeze().expand.size", "y.unsqueeze().expand.size", "x.unsqueeze().expand.size", "x.unsqueeze().expand.unsqueeze().expand", "y.unsqueeze().expand.unsqueeze().expand", "torch.pow().sum", "torch.pow().sum", "y.unsqueeze().expand.size", "x.unsqueeze().expand.unsqueeze", "y.unsqueeze().expand.unsqueeze", "torch.pow", "torch.pow"], "function", ["None"], ["plt", ".", "title", "(", "\"query images\"", ")", "\n", "matplotlib_imshow", "(", "query_grid", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "\n", "", "def", "elucidate_ids", "(", "df", ",", "dataset", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.772922440_pgada.methods.utils.softplus": [[51, 53], ["torch.log", "torch.log", "x.exp"], "function", ["None"], ["\n", "return", "df", ".", "replace", "(", "\n", "{", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.utils.entropy": [[55, 67], ["entropy.mean", "torch.Softmax"], "function", ["None"], ["\"true_label\"", ":", "dataset", ".", "id_to_class", ",", "\n", "\"source_domain\"", ":", "dataset", ".", "id_to_domain", ",", "\n", "\"target_domain\"", ":", "dataset", ".", "id_to_domain", ",", "\n", "}", "\n", ")", "\n", "\n", "\n", "", "def", "get_episodic_loader", "(", "\n", "split", ":", "str", ",", "n_way", ":", "int", ",", "n_source", ":", "int", ",", "n_target", ":", "int", ",", "n_episodes", ":", "int", "\n", ")", ":", "\n", "    ", "dataset", "=", "dataset_config", ".", "DATASET", "(", "\n", "dataset_config", ".", "DATA_ROOT", ",", "split", ",", "dataset_config", ".", "IMAGE_SIZE", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_propagation_net.TransPropNet.__init__": [[9, 29], ["src.methods.abstract_meta_learner.AbstractMetaLearner.__init__", "src.modules.hyper_networks.RelationNet"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "model_func", ",", "\n", "transportation", "=", "None", ",", "\n", "training_stats", "=", "None", ",", "\n", "alpha", "=", "0.99", ",", "\n", "eps", "=", "1e-8", ",", "\n", "k", "=", "20", ",", "\n", ")", ":", "\n", "        ", "super", "(", "TransPropNet", ",", "self", ")", ".", "__init__", "(", "\n", "model_func", ",", "transportation", "=", "transportation", ",", "training_stats", "=", "training_stats", "\n", ")", "\n", "\n", "# Hypernetwork that fits scaling factor in similarity", "\n", "self", ".", "length_scale", "=", "RelationNet", "(", "self", ".", "feature", ".", "final_feat_dim", ")", "\n", "\n", "# Hyper-parameters used in the paper.", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "k", "=", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_propagation_net.TransPropNet.set_forward": [[30, 51], ["transductive_propagation_net.TransPropNet.extract_features", "transductive_propagation_net.TransPropNet.get_similarity", "torch.matmul", "transductive_propagation_net.TransPropNet.propagate", "transductive_propagation_net.TransPropNet.transportation_module", "torch.matmul", "support_images.size"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.extract_features", "home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_propagation_net.TransPropNet.get_similarity", "home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_propagation_net.TransPropNet.propagate"], ["", "def", "set_forward", "(", "self", ",", "support_images", ",", "support_labels", ",", "query_images", ")", ":", "\n", "        ", "\"\"\"\n        Overwrites method set_forward in AbstractMetaLearner.\n        \"\"\"", "\n", "\n", "z_support", ",", "z_query", "=", "self", ".", "extract_features", "(", "support_images", ",", "query_images", ")", "\n", "\n", "# If a transportation method in the feature space has been defined, use it", "\n", "if", "self", ".", "transportation_module", ":", "\n", "            ", "z_support", ",", "z_query", "=", "self", ".", "transportation_module", "(", "z_support", ",", "z_query", ")", "\n", "\n", "", "similarity", "=", "self", ".", "get_similarity", "(", "z_support", ",", "z_query", ")", "\n", "\n", "# Normalization of the laplacian", "\n", "normalize", "=", "(", "1.0", "/", "(", "similarity", "+", "self", ".", "eps", ")", ".", "sum", "(", "dim", "=", "0", ")", ")", ".", "diag", "(", ")", ".", "sqrt", "(", ")", "\n", "\n", "laplacian", "=", "torch", ".", "matmul", "(", "normalize", ",", "torch", ".", "matmul", "(", "similarity", ",", "normalize", ")", ")", "\n", "\n", "scores", "=", "self", ".", "propagate", "(", "laplacian", ",", "support_labels", ")", "\n", "\n", "return", "scores", "[", "support_images", ".", "size", "(", "0", ")", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_propagation_net.TransPropNet.get_similarity": [[52, 77], ["torch.cat", "torch.exp", "torch.exp.topk", "transductive_propagation_net.TransPropNet.length_scale", "transductive_propagation_net.TransPropNet.length_scale", "torch.exp.scatter", "src.methods.utils.euclidean_dist"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.utils.euclidean_dist"], ["", "def", "get_similarity", "(", "self", ",", "z_support", ",", "z_query", ")", ":", "\n", "        ", "\"\"\"\n        Compute the similarity matrix sample to sample for label propagation.\n        Note that support and query are merged.\n        See eq (2) of LEARNING TO PROPAGATE LABELS: TRANSDUCTIVE PROPAGATION NETWORK FOR FEW-SHOT LEARNING\n        Args:\n            z_support (torch.Tensor): shape (n_support, features_dim)\n            z_query (torch.Tensor): shape (n_query, features_dim)\n        Returns:\n            torch.Tensor: shape(n_support + n_query, n_support + n_query), similarity matrix between samples.\n        \"\"\"", "\n", "# scaling with forward of self.length_scale", "\n", "z_support", "=", "z_support", "/", "(", "self", ".", "length_scale", "(", "z_support", ")", "+", "self", ".", "eps", ")", "\n", "z_query", "=", "z_query", "/", "(", "self", ".", "length_scale", "(", "z_query", ")", "+", "self", ".", "eps", ")", "\n", "\n", "z", "=", "torch", ".", "cat", "(", "[", "z_support", ",", "z_query", "]", ",", "dim", "=", "0", ")", "\n", "\n", "similarity", "=", "torch", ".", "exp", "(", "-", "0.5", "*", "euclidean_dist", "(", "z", ",", "z", ")", "/", "z", ".", "shape", "[", "1", "]", ")", "\n", "\n", "if", "similarity", ".", "shape", "[", "1", "]", ">", "self", ".", "k", ":", "\n", "# Keep only top k values in the similarity matrix, set 0. otherwise.", "\n", "            ", "_", ",", "indices", "=", "similarity", ".", "topk", "(", "self", ".", "k", ",", "dim", "=", "1", ")", "\n", "similarity", "=", "similarity", "-", "similarity", ".", "scatter", "(", "1", ",", "indices", ",", "0", ")", "\n", "\n", "", "return", "similarity", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_propagation_net.TransPropNet.propagate": [[78, 113], ["len", "laplacian.size", "support_labels.size", "src.utils.set_device", "torch.cat", "torch.matmul", "torch.unique", "torch.zeros", "src.utils.set_device", "torch.arange", "torch.zeros", "src.utils.set_device", "torch.eye", "laplacian.size"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device"], ["", "def", "propagate", "(", "self", ",", "laplacian", ",", "support_labels", ")", ":", "\n", "        ", "\"\"\"\n        Compute label propagation.\n        See eq (4) of LEARNING TO PROPAGATE LABELS: TRANSDUCTIVE PROPAGATION NETWORK FOR FEW-SHOT LEARNING\n        Args:\n            laplacian (torch.Tensor): shape (n_support + n_query, n_support + n_query)\n            support_labels (torch.Tensor): artificial support set labels in range (0, n_way)\n        Returns:\n            torch.Tensor: shape(n_support + n_query, n_support + n_query), similarity matrix between samples.\n        \"\"\"", "\n", "\n", "# compute labels as one_hot", "\n", "n_way", "=", "len", "(", "torch", ".", "unique", "(", "support_labels", ")", ")", "\n", "n_support_query", "=", "laplacian", ".", "size", "(", "0", ")", "\n", "n_support", "=", "support_labels", ".", "size", "(", "0", ")", "\n", "n_query", "=", "n_support_query", "-", "n_support", "\n", "\n", "## compute support labels as one hot", "\n", "one_hot_labels", "=", "set_device", "(", "torch", ".", "zeros", "(", "n_support", ",", "n_way", ")", ")", "\n", "\n", "one_hot_labels", "[", "torch", ".", "arange", "(", "n_support", ")", ",", "support_labels", "]", "=", "1.0", "\n", "\n", "## sample to predict has 0 everywhere", "\n", "one_hot_labels", "=", "torch", ".", "cat", "(", "\n", "[", "one_hot_labels", ",", "set_device", "(", "torch", ".", "zeros", "(", "n_query", ",", "n_way", ")", ")", "]", "\n", ")", "\n", "\n", "# compute label propagation", "\n", "propagation", "=", "(", "\n", "set_device", "(", "torch", ".", "eye", "(", "laplacian", ".", "size", "(", "0", ")", ")", ")", "-", "self", ".", "alpha", "*", "laplacian", "+", "self", ".", "eps", "\n", ")", ".", "inverse", "(", ")", "\n", "\n", "scores", "=", "torch", ".", "matmul", "(", "propagation", ",", "one_hot_labels", ")", "\n", "\n", "return", "scores", "\n", "", "", ""]], "home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__": [[14, 39], ["src.methods.abstract_meta_learner.AbstractMetaLearner.__init__", "transductive_fine_tuning.TransFineTune.feature.trunk.add_module", "transductive_fine_tuning.TransFineTune.feature.trunk.add_module", "src.utils.set_device", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.__init__", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "model_func", ",", "\n", "transportation", "=", "None", ",", "\n", "training_stats", "=", "None", ",", "\n", "lr", "=", "5.0", "*", "1e-5", ",", "\n", "epochs", "=", "25", ",", "\n", ")", ":", "\n", "        ", "super", "(", "TransFineTune", ",", "self", ")", ".", "__init__", "(", "\n", "model_func", ",", "transportation", "=", "transportation", ",", "training_stats", "=", "training_stats", "\n", ")", "\n", "\n", "# Hyper-parameters used in the paper.", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "epochs", "=", "epochs", "\n", "\n", "# Use the output of fc, not the backbone output.", "\n", "self", ".", "feature", ".", "trunk", ".", "add_module", "(", "\n", "\"fc\"", ",", "set_device", "(", "nn", ".", "Linear", "(", "self", ".", "feature", ".", "final_feat_dim", ",", "CLASSES", "[", "\"train\"", "]", ")", ")", "\n", ")", "\n", "\n", "# Add a non-linearity to the output", "\n", "self", ".", "feature", ".", "trunk", ".", "add_module", "(", "\"relu\"", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "self", ".", "linear_model", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.set_forward": [[40, 71], ["src.utils.set_device", "src.utils.set_device", "src.utils.set_device", "copy.deepcopy().cpu().state_dict", "src.utils.set_device", "transductive_fine_tuning.TransFineTune.support_based_initializer", "transductive_fine_tuning.TransFineTune.fine_tune", "transductive_fine_tuning.TransFineTune.linear_model", "transductive_fine_tuning.TransFineTune.feature.load_state_dict", "torch.Linear", "torch.Linear", "transductive_fine_tuning.TransFineTune.feature", "copy.deepcopy().cpu", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.src.utils.set_device", "home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.support_based_initializer", "home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.fine_tune"], ["", "def", "set_forward", "(", "self", ",", "support_images", ",", "support_labels", ",", "query_images", ")", ":", "\n", "        ", "\"\"\"\n        Overwrites method set_forward in AbstractMetaLearner.\n        \"\"\"", "\n", "support_images", "=", "set_device", "(", "support_images", ")", "\n", "query_images", "=", "set_device", "(", "query_images", ")", "\n", "support_labels", "=", "set_device", "(", "support_labels", ")", "\n", "\n", "# Save parameters", "\n", "feature_parameters", "=", "copy", ".", "deepcopy", "(", "self", ".", "feature", ")", ".", "cpu", "(", ")", ".", "state_dict", "(", ")", "\n", "\n", "# Init linear model", "\n", "self", ".", "linear_model", "=", "set_device", "(", "nn", ".", "Linear", "(", "CLASSES", "[", "\"train\"", "]", ",", "N_WAY_EVAL", ")", ")", "\n", "self", ".", "support_based_initializer", "(", "support_images", ",", "support_labels", ")", "\n", "\n", "# Compute the linear model", "\n", "self", ".", "fine_tune", "(", "support_images", ",", "support_labels", ",", "query_images", ")", "\n", "\n", "# Compute score of query", "\n", "#wei added, for OT", "\n", "# if self.transportation_module:", "\n", "#     z_support, z_query = self.extract_features(support_images, query_images)", "\n", "#     z_query, z_support = self.transportation_module(z_query, z_support)", "\n", "#     scores = self.linear_model(z_query)", "\n", "# else:", "\n", "scores", "=", "self", ".", "linear_model", "(", "self", ".", "feature", "(", "query_images", ")", ")", "\n", "\n", "# Refresh parameters", "\n", "self", ".", "feature", ".", "load_state_dict", "(", "feature_parameters", ")", "\n", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.fine_tune": [[72, 102], ["torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "transductive_fine_tuning.TransFineTune.train", "range", "transductive_fine_tuning.TransFineTune.eval", "torch.optim.Adam.zero_grad", "torch.optim.Adam.zero_grad", "transductive_fine_tuning.TransFineTune.extract_features", "transductive_fine_tuning.TransFineTune.linear_model", "transductive_fine_tuning.TransFineTune.linear_model", "transductive_fine_tuning.TransFineTune.loss_fn", "src.methods.utils.entropy", "loss.backward", "torch.optim.Adam.step", "torch.optim.Adam.step", "transductive_fine_tuning.TransFineTune.transportation_module", "list", "list", "transductive_fine_tuning.TransFineTune.linear_model.parameters", "transductive_fine_tuning.TransFineTune.feature.parameters"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.train", "home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.extract_features", "home.repos.pwc.inspect_result.772922440_pgada.methods.utils.entropy"], ["", "def", "fine_tune", "(", "self", ",", "support_images", ",", "support_labels", ",", "query_images", ")", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "params", "=", "list", "(", "self", ".", "linear_model", ".", "parameters", "(", ")", ")", "\n", "+", "list", "(", "self", ".", "feature", ".", "parameters", "(", ")", ")", ",", "\n", "lr", "=", "self", ".", "lr", ",", "\n", "weight_decay", "=", "0.0", ",", "\n", ")", "\n", "\n", "self", ".", "train", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "epochs", ")", ":", "\n", "            ", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "z_support", ",", "z_query", "=", "self", ".", "extract_features", "(", "support_images", ",", "query_images", ")", "\n", "\n", "#wei added, for OT", "\n", "if", "self", ".", "transportation_module", ":", "\n", "                ", "z_support", ",", "z_query", "=", "self", ".", "transportation_module", "(", "z_support", ",", "z_query", ")", "\n", "\n", "", "support_output", "=", "self", ".", "linear_model", "(", "z_support", ")", "\n", "query_output", "=", "self", ".", "linear_model", "(", "z_query", ")", "\n", "\n", "classif_loss", "=", "self", ".", "loss_fn", "(", "support_output", ",", "support_labels", ")", "\n", "entropy_loss", "=", "entropy", "(", "query_output", ")", "\n", "\n", "loss", "=", "classif_loss", "+", "entropy_loss", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "optimizer", ".", "step", "(", ")", "\n", "", "self", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.support_based_initializer": [[103, 117], ["transductive_fine_tuning.TransFineTune.feature().detach", "transductive_fine_tuning.TransFineTune.get_prototypes", "w.clone", "torch.zeros_like().clone", "torch.zeros_like().clone", "torch.zeros_like().clone", "torch.zeros_like().clone", "transductive_fine_tuning.TransFineTune.norm", "transductive_fine_tuning.TransFineTune.feature", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.772922440_pgada.methods.abstract_meta_learner.AbstractMetaLearner.get_prototypes"], ["", "def", "support_based_initializer", "(", "self", ",", "support_images", ",", "support_labels", ")", ":", "\n", "        ", "\"\"\"\n        Support based intialization\n        See eq (6) A BASELINE FOR FEW-SHOT IMAGE CLASSIFICATION\n        \"\"\"", "\n", "z_support", "=", "self", ".", "feature", "(", "support_images", ")", ".", "detach", "(", ")", "\n", "\n", "z_proto", "=", "self", ".", "get_prototypes", "(", "z_support", ",", "support_labels", ")", "\n", "\n", "w", "=", "z_proto", "/", "z_proto", ".", "norm", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "self", ".", "linear_model", ".", "weight", ".", "data", "=", "w", ".", "clone", "(", ")", "\n", "self", ".", "linear_model", ".", "bias", ".", "data", "=", "torch", ".", "zeros_like", "(", "\n", "self", ".", "linear_model", ".", "bias", ".", "data", "\n", ")", ".", "clone", "(", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.methods.transductive_fine_tuning.TransFineTune.train_loop": [[119, 122], ["NotImplementedError"], "methods", ["None"], ["", "def", "train_loop", "(", "self", ",", "epoch", ",", "train_loader", ",", "optimizer", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\n", "\"Transductive Fine-Tuning does not support episodic training.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.scripts.eval_model.main": [[21, 53], ["click.option", "click.option", "click.option", "click.option", "click.command", "src.running_steps.prepare_output", "src.running_steps.load_model", "src.running_steps.set_and_print_random_seed", "src.running_steps.eval_model"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.src.running_steps.prepare_output", "home.repos.pwc.inspect_result.772922440_pgada.src.running_steps.load_model", "home.repos.pwc.inspect_result.772922440_pgada.src.running_steps.set_and_print_random_seed", "home.repos.pwc.inspect_result.772922440_pgada.src.running_steps.eval_model"], ["@", "click", ".", "option", "(", "\n", "\"--model-path\"", ",", "\n", "help", "=", "\"Path to the model state to be loaded\"", ",", "\n", "type", "=", "Path", ",", "\n", "required", "=", "True", ",", "\n", ")", "\n", "@", "click", ".", "option", "(", "\n", "\"--episodic\"", ",", "\n", "help", "=", "\"Whether the model was trained using episodic training\"", ",", "\n", "type", "=", "bool", ",", "\n", "default", "=", "True", ",", "\n", ")", "\n", "@", "click", ".", "option", "(", "\n", "\"--use-fc\"", ",", "\n", "help", "=", "\"Whether the model load the fc layer in the backbone\"", ",", "\n", "type", "=", "bool", ",", "\n", "default", "=", "False", ",", "\n", ")", "\n", "@", "click", ".", "option", "(", "\n", "\"--force-ot\"", ",", "\n", "help", "=", "\"If True, will force a transportation module into the model\"", ",", "\n", "type", "=", "bool", ",", "\n", "default", "=", "False", ",", "\n", ")", "\n", "@", "click", ".", "command", "(", ")", "\n", "def", "main", "(", "model_path", ":", "Path", ",", "episodic", ":", "bool", ",", "use_fc", ":", "bool", ",", "force_ot", ":", "bool", ")", ":", "\n", "    ", "prepare_output", "(", ")", "\n", "\n", "trained_model", "=", "load_model", "(", "model_path", ",", "episodic", ",", "use_fc", ",", "force_ot", ")", "\n", "\n", "set_and_print_random_seed", "(", ")", "\n", "eval_model", "(", "trained_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.772922440_pgada.scripts.erm_training.main": [[9, 18], ["src.running_steps.prepare_output", "src.running_steps.set_and_print_random_seed", "src.erm_training_steps.get_data", "src.erm_training_steps.get_model", "src.erm_training_steps.train"], "function", ["home.repos.pwc.inspect_result.772922440_pgada.src.running_steps.prepare_output", "home.repos.pwc.inspect_result.772922440_pgada.src.running_steps.set_and_print_random_seed", "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.get_data", "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.get_model", "home.repos.pwc.inspect_result.772922440_pgada.src.erm_training_steps.train"], ["def", "main", "(", ")", ":", "\n", "    ", "prepare_output", "(", ")", "\n", "set_and_print_random_seed", "(", ")", "\n", "\n", "train_loader", ",", "val_loader", ",", "n_classes", "=", "get_data", "(", "two_stream", "=", "True", ")", "\n", "\n", "model", "=", "get_model", "(", "n_classes", ")", "\n", "\n", "train", "(", "model", ",", "train_loader", ",", "val_loader", ")", "\n", "\n"]]}