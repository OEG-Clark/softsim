{"home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.train_util.get_input_from_batch": [[6, 60], ["len", "torch.autograd.Variable", "torch.autograd.Variable().float", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().float", "torch.autograd.Variable", "torch.autograd.Variable", "torch.zeros", "torch.zeros", "torch.autograd.Variable", "torch.autograd.Variable", "enc_batch.cuda.cuda", "enc_padding_mask.cuda.cuda", "enc_batch_2.cuda.cuda", "enc_padding_mask_2.cuda.cuda", "c_t_1.cuda.cuda", "c_t_1_2.cuda.cuda", "torch.autograd.Variable", "torch.from_numpy().long", "torch.from_numpy().long", "torch.autograd.Variable", "torch.autograd.Variable", "torch.zeros", "torch.zeros", "enc_batch_extend_vocab.cuda.cuda", "enc_batch_extend_vocab_2.cuda.cuda", "extra_zeros.cuda.cuda", "extra_zeros_2.cuda.cuda", "coverage.cuda.cuda", "coverage_2.cuda.cuda", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.zeros", "torch.zeros", "enc_batch.cuda.size", "enc_batch_2.cuda.size", "torch.from_numpy", "torch.from_numpy"], "function", ["None"], ["def", "get_input_from_batch", "(", "batch", ",", "use_cuda", ")", ":", "\n", "  ", "batch_size", "=", "len", "(", "batch", ".", "enc_lens", ")", "\n", "\n", "enc_batch", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "batch", ".", "enc_batch", ")", ".", "long", "(", ")", ")", "\n", "enc_padding_mask", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "batch", ".", "enc_padding_mask", ")", ")", ".", "float", "(", ")", "\n", "enc_lens", "=", "batch", ".", "enc_lens", "\n", "\n", "enc_batch_2", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "batch", ".", "enc_batch_2", ")", ".", "long", "(", ")", ")", "\n", "enc_padding_mask_2", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "batch", ".", "enc_padding_mask_2", ")", ".", "float", "(", ")", ")", "\n", "enc_lens_2", "=", "batch", ".", "enc_lens_2", "\n", "\n", "extra_zeros", "=", "None", "\n", "enc_batch_extend_vocab", "=", "None", "\n", "\n", "extra_zeros_2", "=", "None", "\n", "enc_batch_extend_vocab_2", "=", "None", "\n", "\n", "if", "config", ".", "pointer_gen", ":", "\n", "    ", "enc_batch_extend_vocab", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "batch", ".", "enc_batch_extend_vocab", ")", ".", "long", "(", ")", ")", "\n", "enc_batch_extend_vocab_2", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "batch", ".", "enc_batch_extend_vocab_2", ")", ".", "long", "(", ")", ")", "\n", "# max_art_oovs is the max over all the article oov list in the batch", "\n", "if", "batch", ".", "max_art_oovs", ">", "0", "or", "batch", ".", "max_art_oovs_2", ">", "0", ":", "\n", "      ", "extra_zeros", "=", "Variable", "(", "torch", ".", "zeros", "(", "(", "batch_size", ",", "batch", ".", "max_art_oovs", ")", ")", ")", "\n", "extra_zeros_2", "=", "Variable", "(", "torch", ".", "zeros", "(", "(", "batch_size", ",", "batch", ".", "max_art_oovs_2", ")", ")", ")", "\n", "\n", "", "", "c_t_1", "=", "Variable", "(", "torch", ".", "zeros", "(", "(", "batch_size", ",", "2", "*", "config", ".", "hidden_dim", ")", ")", ")", "\n", "c_t_1_2", "=", "Variable", "(", "torch", ".", "zeros", "(", "(", "batch_size", ",", "2", "*", "config", ".", "hidden_dim", ")", ")", ")", "\n", "\n", "coverage", "=", "None", "\n", "coverage_2", "=", "None", "\n", "if", "config", ".", "is_coverage", ":", "\n", "    ", "coverage", "=", "Variable", "(", "torch", ".", "zeros", "(", "enc_batch", ".", "size", "(", ")", ")", ")", "\n", "coverage_2", "=", "Variable", "(", "torch", ".", "zeros", "(", "enc_batch_2", ".", "size", "(", ")", ")", ")", "\n", "\n", "", "if", "use_cuda", ":", "\n", "    ", "enc_batch", "=", "enc_batch", ".", "cuda", "(", ")", "\n", "enc_padding_mask", "=", "enc_padding_mask", ".", "cuda", "(", ")", "\n", "enc_batch_2", "=", "enc_batch_2", ".", "cuda", "(", ")", "\n", "enc_padding_mask_2", "=", "enc_padding_mask_2", ".", "cuda", "(", ")", "\n", "\n", "if", "enc_batch_extend_vocab", "is", "not", "None", ":", "\n", "      ", "enc_batch_extend_vocab", "=", "enc_batch_extend_vocab", ".", "cuda", "(", ")", "\n", "enc_batch_extend_vocab_2", "=", "enc_batch_extend_vocab_2", ".", "cuda", "(", ")", "\n", "", "if", "extra_zeros", "is", "not", "None", ":", "\n", "      ", "extra_zeros", "=", "extra_zeros", ".", "cuda", "(", ")", "\n", "extra_zeros_2", "=", "extra_zeros_2", ".", "cuda", "(", ")", "\n", "", "c_t_1", "=", "c_t_1", ".", "cuda", "(", ")", "\n", "c_t_1_2", "=", "c_t_1_2", ".", "cuda", "(", ")", "\n", "\n", "if", "coverage", "is", "not", "None", ":", "\n", "      ", "coverage", "=", "coverage", ".", "cuda", "(", ")", "\n", "coverage_2", "=", "coverage_2", ".", "cuda", "(", ")", "\n", "\n", "", "", "return", "[", "enc_batch", ",", "enc_batch_2", "]", ",", "[", "enc_padding_mask", ",", "enc_padding_mask_2", "]", ",", "[", "enc_lens", ",", "enc_lens_2", "]", ",", "[", "enc_batch_extend_vocab", ",", "enc_batch_extend_vocab_2", "]", ",", "[", "extra_zeros", ",", "extra_zeros_2", "]", ",", "[", "c_t_1", ",", "c_t_1_2", "]", ",", "[", "coverage", ",", "coverage_2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.train_util.get_output_from_batch": [[61, 78], ["torch.autograd.Variable", "torch.autograd.Variable().float", "numpy.max", "torch.autograd.Variable().float", "torch.autograd.Variable().long", "torch.from_numpy().long", "dec_batch.cuda.cuda", "dec_padding_mask.cuda.cuda", "dec_lens_var.cuda.cuda", "target_batch.cuda.cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "function", ["None"], ["", "def", "get_output_from_batch", "(", "batch", ",", "use_cuda", ")", ":", "\n", "  ", "dec_batch", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "batch", ".", "dec_batch", ")", ".", "long", "(", ")", ")", "\n", "dec_padding_mask", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "batch", ".", "dec_padding_mask", ")", ")", ".", "float", "(", ")", "\n", "dec_lens", "=", "batch", ".", "dec_lens", "\n", "max_dec_len", "=", "np", ".", "max", "(", "dec_lens", ")", "\n", "dec_lens_var", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "dec_lens", ")", ")", ".", "float", "(", ")", "\n", "\n", "target_batch", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "batch", ".", "target_batch", ")", ")", ".", "long", "(", ")", "\n", "\n", "if", "use_cuda", ":", "\n", "    ", "dec_batch", "=", "dec_batch", ".", "cuda", "(", ")", "\n", "dec_padding_mask", "=", "dec_padding_mask", ".", "cuda", "(", ")", "\n", "dec_lens_var", "=", "dec_lens_var", ".", "cuda", "(", ")", "\n", "target_batch", "=", "target_batch", ".", "cuda", "(", ")", "\n", "\n", "\n", "", "return", "dec_batch", ",", "dec_padding_mask", ",", "max_dec_len", ",", "dec_lens_var", ",", "target_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.eval.Evaluate.__init__": [[24, 37], ["data_util.data.Vocab", "data_util.batcher.Batcher", "time.sleep", "os.path.basename", "os.path.join", "tensorflow.summary.FileWriter", "model.Model", "os.path.exists", "os.mkdir"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model_file_path", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "Vocab", "(", "config", ".", "vocab_path", ",", "config", ".", "vocab_size", ")", "\n", "self", ".", "batcher", "=", "Batcher", "(", "config", ".", "eval_data_path", ",", "self", ".", "vocab", ",", "mode", "=", "'eval'", ",", "\n", "batch_size", "=", "config", ".", "batch_size", ",", "single_pass", "=", "True", ")", "\n", "time", ".", "sleep", "(", "15", ")", "\n", "model_name", "=", "os", ".", "path", ".", "basename", "(", "model_file_path", ")", "\n", "\n", "eval_dir", "=", "os", ".", "path", ".", "join", "(", "config", ".", "log_root", ",", "'eval_%s'", "%", "(", "model_name", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "eval_dir", ")", "\n", "", "self", ".", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "eval_dir", ")", "\n", "\n", "self", ".", "model", "=", "Model", "(", "model_file_path", ",", "is_eval", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.eval.Evaluate.eval_one_batch": [[38, 127], ["train_util.get_input_from_batch", "train_util.get_output_from_batch", "zip", "range", "eval.Evaluate.write_words", "eval.Evaluate.write_words", "torch.sum", "torch.mean", "torch.mean.item", "sorted", "sorted.reverse", "enumerate", "torch.index_select", "eval.Evaluate.model.encoder", "torch.index_select", "torch.index_select().view", "tuple", "encoder_outputs_list.append", "encoder_feature_list.append", "tuple", "min", "eval.Evaluate.model.decoder", "torch.gather().squeeze", "range", "range", "target_words.append", "output_words.append", "step_losses.append", "torch.stack", "range", "eval.Evaluate.model.reduce_state", "eval.Evaluate.model.reduce_state", "eval.Evaluate.vocab.word_to_id.iteritems", "final_dist.max", "final_dist.topk", "target_step.append", "output_step.append", "torch.log", "range", "len", "range", "torch.LongTensor", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor().cuda", "torch.index_select", "torch.index_select", "torch.index_select", "torch.gather", "output_ids[].item", "len", "torch.sum", "len", "sorted_encoder_feature.view", "target.unsqueeze", "target[].item", "len", "step_mask[].item", "output_ids[].item", "len", "step_mask[].item", "torch.min", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor().cuda", "target[].item", "output_ids[].item", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.train_util.get_input_from_batch", "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.train_util.get_output_from_batch", "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.eval.Evaluate.write_words", "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.eval.Evaluate.write_words"], ["", "def", "eval_one_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "enc_batch_list", ",", "enc_padding_mask_list", ",", "enc_lens_list", ",", "enc_batch_extend_vocab_list", ",", "extra_zeros_list", ",", "c_t_1_list", ",", "coverage_list", "=", "get_input_from_batch", "(", "batch", ",", "use_cuda", ")", "\n", "dec_batch", ",", "dec_padding_mask", ",", "max_dec_len", ",", "dec_lens_var", ",", "target_batch", "=", "get_output_from_batch", "(", "batch", ",", "use_cuda", ")", "\n", "\n", "encoder_outputs_list", "=", "[", "]", "\n", "encoder_feature_list", "=", "[", "]", "\n", "s_t_1", "=", "None", "\n", "s_t_1_0", "=", "None", "\n", "s_t_1_1", "=", "None", "\n", "for", "enc_batch", ",", "enc_lens", "in", "zip", "(", "enc_batch_list", ",", "enc_lens_list", ")", ":", "\n", "            ", "sorted_indices", "=", "sorted", "(", "range", "(", "len", "(", "enc_lens", ")", ")", ",", "key", "=", "enc_lens", ".", "__getitem__", ")", "\n", "sorted_indices", ".", "reverse", "(", ")", "\n", "inverse_sorted_indices", "=", "[", "-", "1", "for", "_", "in", "range", "(", "len", "(", "sorted_indices", ")", ")", "]", "\n", "for", "index", ",", "position", "in", "enumerate", "(", "sorted_indices", ")", ":", "\n", "                ", "inverse_sorted_indices", "[", "position", "]", "=", "index", "\n", "", "sorted_enc_batch", "=", "torch", ".", "index_select", "(", "enc_batch", ",", "0", ",", "torch", ".", "LongTensor", "(", "sorted_indices", ")", "if", "not", "use_cuda", "else", "torch", ".", "LongTensor", "(", "sorted_indices", ")", ".", "cuda", "(", ")", ")", "\n", "sorted_enc_lens", "=", "enc_lens", "[", "sorted_indices", "]", "\n", "sorted_encoder_outputs", ",", "sorted_encoder_feature", ",", "sorted_encoder_hidden", "=", "self", ".", "model", ".", "encoder", "(", "sorted_enc_batch", "\n", ",", "sorted_enc_lens", ")", "\n", "encoder_outputs", "=", "torch", ".", "index_select", "(", "sorted_encoder_outputs", ",", "0", ",", "torch", ".", "LongTensor", "(", "inverse_sorted_indices", ")", "if", "\n", "not", "use_cuda", "else", "torch", ".", "LongTensor", "(", "inverse_sorted_indices", ")", ".", "cuda", "(", ")", ")", "\n", "encoder_feature", "=", "torch", ".", "index_select", "(", "sorted_encoder_feature", ".", "view", "(", "encoder_outputs", ".", "shape", ")", ",", "0", ",", "torch", ".", "LongTensor", "(", "inverse_sorted_indices", ")", "if", "not", "use_cuda", "else", "torch", ".", "LongTensor", "(", "inverse_sorted_indices", ")", ".", "cuda", "(", ")", ")", ".", "view", "(", "sorted_encoder_feature", ".", "shape", ")", "\n", "encoder_hidden", "=", "tuple", "(", "[", "torch", ".", "index_select", "(", "sorted_encoder_hidden", "[", "0", "]", ",", "1", ",", "torch", ".", "LongTensor", "(", "inverse_sorted_indices", ")", "if", "not", "use_cuda", "else", "torch", ".", "LongTensor", "(", "inverse_sorted_indices", ")", ".", "cuda", "(", ")", ")", ",", "torch", ".", "index_select", "(", "sorted_encoder_hidden", "[", "1", "]", ",", "1", ",", "torch", ".", "LongTensor", "(", "inverse_sorted_indices", ")", "if", "not", "use_cuda", "else", "torch", ".", "LongTensor", "(", "inverse_sorted_indices", ")", ".", "cuda", "(", ")", ")", "]", ")", "\n", "#encoder_outputs, encoder_feature, encoder_hidden = self.model.encoder(enc_batch, enc_lens)", "\n", "encoder_outputs_list", ".", "append", "(", "encoder_outputs", ")", "\n", "encoder_feature_list", ".", "append", "(", "encoder_feature", ")", "\n", "if", "s_t_1", "is", "None", ":", "\n", "                ", "s_t_1", "=", "self", ".", "model", ".", "reduce_state", "(", "encoder_hidden", ")", "\n", "s_t_1_0", ",", "s_t_1_1", "=", "s_t_1", "\n", "", "else", ":", "\n", "                ", "s_t_1_new", "=", "self", ".", "model", ".", "reduce_state", "(", "encoder_hidden", ")", "\n", "s_t_1_0", "=", "s_t_1_0", "+", "s_t_1_new", "[", "0", "]", "\n", "s_t_1_1", "=", "s_t_1_1", "+", "s_t_1_new", "[", "1", "]", "\n", "", "s_t_1", "=", "tuple", "(", "[", "s_t_1_0", ",", "s_t_1_1", "]", ")", "\n", "\n", "#encoder_outputs, encoder_feature, encoder_hidden = self.model.encoder(enc_batch, enc_lens)", "\n", "#s_t_1 = self.model.reduce_state(encoder_hidden)", "\n", "\n", "", "step_losses", "=", "[", "]", "\n", "target_words", "=", "[", "]", "\n", "output_words", "=", "[", "]", "\n", "id_to_words", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "vocab", ".", "word_to_id", ".", "iteritems", "(", ")", "}", "\n", "for", "di", "in", "range", "(", "min", "(", "max_dec_len", ",", "config", ".", "max_dec_steps", ")", ")", ":", "\n", "            ", "y_t_1", "=", "dec_batch", "[", ":", ",", "di", "]", "# Teacher forcing", "\n", "final_dist", ",", "s_t_1", ",", "c_t_1_list", ",", "attn_dist_list", ",", "p_gen", ",", "next_coverage_list", "=", "self", ".", "model", ".", "decoder", "(", "y_t_1", ",", "s_t_1", ",", "encoder_outputs_list", ",", "encoder_feature_list", ",", "enc_padding_mask_list", ",", "c_t_1_list", ",", "extra_zeros_list", ",", "enc_batch_extend_vocab_list", ",", "coverage_list", ",", "di", ")", "\n", "target", "=", "target_batch", "[", ":", ",", "di", "]", "\n", "gold_probs", "=", "torch", ".", "gather", "(", "final_dist", ",", "1", ",", "target", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", ")", "\n", "output_ids", "=", "final_dist", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "output_2_candidates", "=", "final_dist", ".", "topk", "(", "2", ",", "1", ")", "[", "1", "]", "\n", "for", "ind", "in", "range", "(", "output_ids", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "if", "self", ".", "vocab", ".", "word_to_id", "[", "'X'", "]", "==", "output_ids", "[", "ind", "]", ".", "item", "(", ")", ":", "\n", "                    ", "output_ids", "[", "ind", "]", "=", "output_2_candidates", "[", "ind", "]", "[", "1", "]", "\n", "", "", "target_step", "=", "[", "]", "\n", "output_step", "=", "[", "]", "\n", "step_mask", "=", "dec_padding_mask", "[", ":", ",", "di", "]", "\n", "for", "i", "in", "range", "(", "target", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "if", "target", "[", "i", "]", ".", "item", "(", ")", ">=", "len", "(", "id_to_words", ")", "or", "step_mask", "[", "i", "]", ".", "item", "(", ")", "==", "0", ":", "\n", "                    ", "target", "[", "i", "]", "=", "0", "\n", "", "target_step", ".", "append", "(", "id_to_words", "[", "target", "[", "i", "]", ".", "item", "(", ")", "]", ")", "\n", "if", "output_ids", "[", "i", "]", ".", "item", "(", ")", ">=", "len", "(", "id_to_words", ")", "or", "step_mask", "[", "i", "]", ".", "item", "(", ")", "==", "0", ":", "\n", "                    ", "output_ids", "[", "i", "]", "=", "0", "\n", "", "output_step", ".", "append", "(", "id_to_words", "[", "output_ids", "[", "i", "]", ".", "item", "(", ")", "]", ")", "\n", "", "target_words", ".", "append", "(", "target_step", ")", "\n", "output_words", ".", "append", "(", "output_step", ")", "\n", "step_loss", "=", "-", "torch", ".", "log", "(", "gold_probs", "+", "config", ".", "eps", ")", "\n", "if", "config", ".", "is_coverage", ":", "\n", "#step_coverage_loss = torch.sum(torch.min(attn_dist, coverage), 1)", "\n", "#step_loss = step_loss + config.cov_loss_wt * step_coverage_loss", "\n", "#coverage = next_coverage", "\n", "                ", "step_coverage_loss", "=", "0.0", "\n", "for", "ind", "in", "range", "(", "len", "(", "coverage_list", ")", ")", ":", "\n", "                    ", "step_coverage_loss", "+=", "torch", ".", "sum", "(", "torch", ".", "min", "(", "attn_dist_list", "[", "ind", "]", ",", "coverage_list", "[", "ind", "]", ")", ",", "1", ")", "\n", "coverage_list", "[", "ind", "]", "=", "next_coverage_list", "[", "ind", "]", "\n", "", "step_loss", "=", "step_loss", "+", "config", ".", "cov_loss_wt", "*", "step_coverage_loss", "\n", "\n", "", "step_mask", "=", "dec_padding_mask", "[", ":", ",", "di", "]", "\n", "step_loss", "=", "step_loss", "*", "step_mask", "\n", "step_losses", ".", "append", "(", "step_loss", ")", "\n", "\n", "", "self", ".", "write_words", "(", "output_words", ",", "\"output.txt\"", ")", "\n", "self", ".", "write_words", "(", "target_words", ",", "\"input.txt\"", ")", "\n", "\n", "sum_step_losses", "=", "torch", ".", "sum", "(", "torch", ".", "stack", "(", "step_losses", ",", "1", ")", ",", "1", ")", "\n", "batch_avg_loss", "=", "sum_step_losses", "/", "dec_lens_var", "\n", "loss", "=", "torch", ".", "mean", "(", "batch_avg_loss", ")", "\n", "\n", "return", "loss", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.eval.Evaluate.write_words": [[128, 141], ["range", "open", "open.close", "len", "range", "open.write", "range", "range", "len", "len", "len", "sentence.strip"], "methods", ["None"], ["", "def", "write_words", "(", "self", ",", "len_batch_words", ",", "output_file", ")", ":", "\n", "        ", "batch_sentences", "=", "[", "\"\"", "for", "_", "in", "range", "(", "len", "(", "len_batch_words", "[", "0", "]", ")", ")", "]", "\n", "batch_sentences_done", "=", "[", "False", "for", "_", "in", "range", "(", "len", "(", "len_batch_words", "[", "0", "]", ")", ")", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "len_batch_words", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "len", "(", "len_batch_words", "[", "i", "]", ")", ")", ":", "\n", "                ", "if", "len_batch_words", "[", "i", "]", "[", "j", "]", "==", "\"[STOP]\"", ":", "\n", "                    ", "batch_sentences_done", "[", "j", "]", "=", "True", "\n", "", "if", "batch_sentences_done", "[", "j", "]", "!=", "True", ":", "\n", "                    ", "batch_sentences", "[", "j", "]", "+=", "len_batch_words", "[", "i", "]", "[", "j", "]", "+", "\" \"", "\n", "", "", "", "f", "=", "open", "(", "output_file", ",", "\"a\"", ")", "\n", "for", "sentence", "in", "batch_sentences", ":", "\n", "            ", "f", ".", "write", "(", "sentence", ".", "strip", "(", ")", "+", "\"\\n\"", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.eval.Evaluate.run_eval": [[143, 161], ["time.time", "eval.Evaluate.batcher.next_batch", "eval.Evaluate.eval_one_batch", "data_util.utils.calc_running_avg_loss", "eval.Evaluate.batcher.next_batch", "eval.Evaluate.summary_writer.flush", "print", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.eval.Evaluate.eval_one_batch", "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.data_util.utils.calc_running_avg_loss"], ["", "def", "run_eval", "(", "self", ")", ":", "\n", "        ", "running_avg_loss", ",", "iter", "=", "0", ",", "0", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "batch", "=", "self", ".", "batcher", ".", "next_batch", "(", ")", "\n", "while", "batch", "is", "not", "None", ":", "\n", "            ", "loss", "=", "self", ".", "eval_one_batch", "(", "batch", ")", "\n", "\n", "running_avg_loss", "=", "calc_running_avg_loss", "(", "loss", ",", "running_avg_loss", ",", "self", ".", "summary_writer", ",", "iter", ")", "\n", "iter", "+=", "1", "\n", "\n", "if", "iter", "%", "100", "==", "0", ":", "\n", "                ", "self", ".", "summary_writer", ".", "flush", "(", ")", "\n", "", "print_interval", "=", "1", "\n", "if", "iter", "%", "print_interval", "==", "0", ":", "\n", "                ", "print", "(", "'steps %d, seconds for %d batch: %.2f , loss: %f'", "%", "(", "\n", "iter", ",", "print_interval", ",", "time", ".", "time", "(", ")", "-", "start", ",", "running_avg_loss", ")", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "", "batch", "=", "self", ".", "batcher", ".", "next_batch", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.train.Train.__init__": [[23, 38], ["data_util.data.Vocab", "data_util.batcher.Batcher", "time.sleep", "os.path.join", "os.path.join", "tensorflow.summary.FileWriter", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "int", "time.time"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "Vocab", "(", "config", ".", "vocab_path", ",", "config", ".", "vocab_size", ")", "\n", "self", ".", "batcher", "=", "Batcher", "(", "config", ".", "train_data_path", ",", "self", ".", "vocab", ",", "mode", "=", "'train'", ",", "\n", "batch_size", "=", "config", ".", "batch_size", ",", "single_pass", "=", "False", ")", "\n", "time", ".", "sleep", "(", "15", ")", "\n", "\n", "train_dir", "=", "os", ".", "path", ".", "join", "(", "config", ".", "log_root", ",", "'train_%d'", "%", "(", "int", "(", "time", ".", "time", "(", ")", ")", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "train_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "train_dir", ")", "\n", "\n", "", "self", ".", "model_dir", "=", "os", ".", "path", ".", "join", "(", "train_dir", ",", "'model'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "model_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "self", ".", "model_dir", ")", "\n", "\n", "", "self", ".", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "train_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.train.Train.save_model": [[39, 50], ["os.path.join", "torch.save", "train.Train.model.encoder.state_dict", "train.Train.model.decoder.state_dict", "train.Train.model.reduce_state.state_dict", "train.Train.optimizer.state_dict", "int", "time.time"], "methods", ["None"], ["", "def", "save_model", "(", "self", ",", "running_avg_loss", ",", "iter", ")", ":", "\n", "        ", "state", "=", "{", "\n", "'iter'", ":", "iter", ",", "\n", "'encoder_state_dict'", ":", "self", ".", "model", ".", "encoder", ".", "state_dict", "(", ")", ",", "\n", "'decoder_state_dict'", ":", "self", ".", "model", ".", "decoder", ".", "state_dict", "(", ")", ",", "\n", "'reduce_state_dict'", ":", "self", ".", "model", ".", "reduce_state", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'current_loss'", ":", "running_avg_loss", "\n", "}", "\n", "model_save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "model_dir", ",", "'model_%d_%d'", "%", "(", "iter", ",", "int", "(", "time", ".", "time", "(", ")", ")", ")", ")", "\n", "torch", ".", "save", "(", "state", ",", "model_save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.train.Train.setup_train": [[51, 75], ["model.Model", "torch.optim.Adam", "list", "torch.load", "list", "list", "train.Train.model.reduce_state.parameters", "train.Train.optimizer.load_state_dict", "train.Train.model.encoder.parameters", "train.Train.model.decoder.parameters", "train.Train.optimizer.state.values", "torch.load.items", "torch.is_tensor", "v.cuda"], "methods", ["None"], ["", "def", "setup_train", "(", "self", ",", "model_file_path", "=", "None", ")", ":", "\n", "        ", "self", ".", "model", "=", "Model", "(", "model_file_path", ")", "\n", "\n", "params", "=", "list", "(", "self", ".", "model", ".", "encoder", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "model", ".", "decoder", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "model", ".", "reduce_state", ".", "parameters", "(", ")", ")", "\n", "initial_lr", "=", "config", ".", "lr_coverage", "if", "config", ".", "is_coverage", "else", "config", ".", "lr", "\n", "self", ".", "optimizer", "=", "Adam", "(", "params", ",", "lr", "=", "initial_lr", ")", "#Adagrad(params, lr=initial_lr, initial_accumulator_value=config.adagrad_init_acc)", "\n", "\n", "start_iter", ",", "start_loss", "=", "0", ",", "0", "\n", "\n", "if", "model_file_path", "is", "not", "None", ":", "\n", "            ", "state", "=", "torch", ".", "load", "(", "model_file_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "start_iter", "=", "state", "[", "'iter'", "]", "\n", "start_loss", "=", "state", "[", "'current_loss'", "]", "\n", "\n", "if", "not", "config", ".", "is_coverage", ":", "\n", "                ", "self", ".", "optimizer", ".", "load_state_dict", "(", "state", "[", "'optimizer'", "]", ")", "\n", "if", "use_cuda", ":", "\n", "                    ", "for", "state", "in", "self", ".", "optimizer", ".", "state", ".", "values", "(", ")", ":", "\n", "                        ", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", ":", "\n", "                            ", "if", "torch", ".", "is_tensor", "(", "v", ")", ":", "\n", "                                ", "state", "[", "k", "]", "=", "v", ".", "cuda", "(", ")", "\n", "\n", "", "", "", "", "", "", "return", "start_iter", ",", "start_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.train.Train.train_one_batch": [[76, 147], ["train_util.get_input_from_batch", "train_util.get_output_from_batch", "train.Train.optimizer.zero_grad", "zip", "range", "torch.sum", "torch.mean", "torch.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "train.Train.optimizer.step", "torch.mean.item", "sorted", "sorted.reverse", "enumerate", "torch.index_select", "train.Train.model.encoder", "torch.index_select", "torch.index_select().view", "tuple", "encoder_outputs_list.append", "encoder_feature_list.append", "tuple", "min", "train.Train.model.decoder", "torch.gather().squeeze", "step_losses.append", "torch.stack", "train.Train.model.encoder.parameters", "train.Train.model.decoder.parameters", "train.Train.model.reduce_state.parameters", "range", "train.Train.model.reduce_state", "train.Train.model.reduce_state", "torch.log", "range", "len", "range", "torch.LongTensor", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor().cuda", "torch.index_select", "torch.index_select", "torch.index_select", "torch.gather", "len", "torch.sum", "len", "sorted_encoder_feature.view", "target.unsqueeze", "torch.min", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.train_util.get_input_from_batch", "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.train_util.get_output_from_batch"], ["", "def", "train_one_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "enc_batch_list", ",", "enc_padding_mask_list", ",", "enc_lens_list", ",", "enc_batch_extend_vocab_list", ",", "extra_zeros_list", ",", "c_t_1_list", ",", "coverage_list", "=", "get_input_from_batch", "(", "batch", ",", "use_cuda", ")", "\n", "dec_batch", ",", "dec_padding_mask", ",", "max_dec_len", ",", "dec_lens_var", ",", "target_batch", "=", "get_output_from_batch", "(", "batch", ",", "use_cuda", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "encoder_outputs_list", "=", "[", "]", "\n", "encoder_feature_list", "=", "[", "]", "\n", "s_t_1", "=", "None", "\n", "s_t_1_0", "=", "None", "\n", "s_t_1_1", "=", "None", "\n", "for", "enc_batch", ",", "enc_lens", "in", "zip", "(", "enc_batch_list", ",", "enc_lens_list", ")", ":", "\n", "            ", "sorted_indices", "=", "sorted", "(", "range", "(", "len", "(", "enc_lens", ")", ")", ",", "key", "=", "enc_lens", ".", "__getitem__", ")", "\n", "sorted_indices", ".", "reverse", "(", ")", "\n", "inverse_sorted_indices", "=", "[", "-", "1", "for", "_", "in", "range", "(", "len", "(", "sorted_indices", ")", ")", "]", "\n", "for", "index", ",", "position", "in", "enumerate", "(", "sorted_indices", ")", ":", "\n", "                ", "inverse_sorted_indices", "[", "position", "]", "=", "index", "\n", "", "sorted_enc_batch", "=", "torch", ".", "index_select", "(", "enc_batch", ",", "0", ",", "torch", ".", "LongTensor", "(", "sorted_indices", ")", "if", "not", "use_cuda", "else", "torch", ".", "LongTensor", "(", "sorted_indices", ")", ".", "cuda", "(", ")", ")", "\n", "sorted_enc_lens", "=", "enc_lens", "[", "sorted_indices", "]", "\n", "sorted_encoder_outputs", ",", "sorted_encoder_feature", ",", "sorted_encoder_hidden", "=", "self", ".", "model", ".", "encoder", "(", "sorted_enc_batch", ",", "sorted_enc_lens", ")", "\n", "encoder_outputs", "=", "torch", ".", "index_select", "(", "sorted_encoder_outputs", ",", "0", ",", "torch", ".", "LongTensor", "(", "inverse_sorted_indices", ")", "if", "not", "use_cuda", "else", "torch", ".", "LongTensor", "(", "inverse_sorted_indices", ")", ".", "cuda", "(", ")", ")", "\n", "encoder_feature", "=", "torch", ".", "index_select", "(", "sorted_encoder_feature", ".", "view", "(", "encoder_outputs", ".", "shape", ")", ",", "0", ",", "torch", ".", "LongTensor", "(", "inverse_sorted_indices", ")", "if", "not", "use_cuda", "else", "torch", ".", "LongTensor", "(", "inverse_sorted_indices", ")", ".", "cuda", "(", ")", ")", ".", "view", "(", "sorted_encoder_feature", ".", "shape", ")", "\n", "encoder_hidden", "=", "tuple", "(", "[", "torch", ".", "index_select", "(", "sorted_encoder_hidden", "[", "0", "]", ",", "1", ",", "torch", ".", "LongTensor", "(", "inverse_sorted_indices", ")", "if", "not", "use_cuda", "else", "torch", ".", "LongTensor", "(", "inverse_sorted_indices", ")", ".", "cuda", "(", ")", ")", ",", "torch", ".", "index_select", "(", "sorted_encoder_hidden", "[", "1", "]", ",", "1", ",", "torch", ".", "LongTensor", "(", "inverse_sorted_indices", ")", "if", "not", "use_cuda", "else", "torch", ".", "LongTensor", "(", "inverse_sorted_indices", ")", ".", "cuda", "(", ")", ")", "]", ")", "\n", "#encoder_outputs, encoder_feature, encoder_hidden = self.model.encoder(enc_batch, enc_lens)", "\n", "encoder_outputs_list", ".", "append", "(", "encoder_outputs", ")", "\n", "encoder_feature_list", ".", "append", "(", "encoder_feature", ")", "\n", "if", "s_t_1", "is", "None", ":", "\n", "                ", "s_t_1", "=", "self", ".", "model", ".", "reduce_state", "(", "encoder_hidden", ")", "\n", "s_t_1_0", ",", "s_t_1_1", "=", "s_t_1", "\n", "", "else", ":", "\n", "                ", "s_t_1_new", "=", "self", ".", "model", ".", "reduce_state", "(", "encoder_hidden", ")", "\n", "s_t_1_0", "=", "s_t_1_0", "+", "s_t_1_new", "[", "0", "]", "\n", "s_t_1_1", "=", "s_t_1_1", "+", "s_t_1_new", "[", "1", "]", "\n", "", "s_t_1", "=", "tuple", "(", "[", "s_t_1_0", ",", "s_t_1_1", "]", ")", "\n", "\n", "#c_t_1_list = [c_t_1]", "\n", "#coverage_list = [coverage]", "\n", "\n", "", "step_losses", "=", "[", "]", "\n", "for", "di", "in", "range", "(", "min", "(", "max_dec_len", ",", "config", ".", "max_dec_steps", ")", ")", ":", "\n", "            ", "y_t_1", "=", "dec_batch", "[", ":", ",", "di", "]", "# Teacher forcing", "\n", "final_dist", ",", "s_t_1", ",", "c_t_1_list", ",", "attn_dist_list", ",", "p_gen", ",", "next_coverage_list", "=", "self", ".", "model", ".", "decoder", "(", "y_t_1", ",", "s_t_1", ",", "encoder_outputs_list", ",", "encoder_feature_list", ",", "enc_padding_mask_list", ",", "c_t_1_list", ",", "extra_zeros_list", ",", "enc_batch_extend_vocab_list", ",", "coverage_list", ",", "di", ")", "\n", "target", "=", "target_batch", "[", ":", ",", "di", "]", "\n", "gold_probs", "=", "torch", ".", "gather", "(", "final_dist", ",", "1", ",", "target", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", ")", "\n", "step_loss", "=", "-", "torch", ".", "log", "(", "gold_probs", "+", "config", ".", "eps", ")", "\n", "if", "config", ".", "is_coverage", ":", "\n", "                ", "step_coverage_loss", "=", "0.0", "\n", "for", "ind", "in", "range", "(", "len", "(", "coverage_list", ")", ")", ":", "\n", "                    ", "step_coverage_loss", "+=", "torch", ".", "sum", "(", "torch", ".", "min", "(", "attn_dist_list", "[", "ind", "]", ",", "coverage_list", "[", "ind", "]", ")", ",", "1", ")", "\n", "coverage_list", "[", "ind", "]", "=", "next_coverage_list", "[", "ind", "]", "\n", "", "step_loss", "=", "step_loss", "+", "config", ".", "cov_loss_wt", "*", "step_coverage_loss", "\n", "\n", "", "step_mask", "=", "dec_padding_mask", "[", ":", ",", "di", "]", "\n", "step_loss", "=", "step_loss", "*", "step_mask", "\n", "step_losses", ".", "append", "(", "step_loss", ")", "\n", "\n", "", "sum_losses", "=", "torch", ".", "sum", "(", "torch", ".", "stack", "(", "step_losses", ",", "1", ")", ",", "1", ")", "\n", "batch_avg_loss", "=", "sum_losses", "/", "dec_lens_var", "\n", "loss", "=", "torch", ".", "mean", "(", "batch_avg_loss", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "self", ".", "norm", "=", "clip_grad_norm_", "(", "self", ".", "model", ".", "encoder", ".", "parameters", "(", ")", ",", "config", ".", "max_grad_norm", ")", "\n", "clip_grad_norm_", "(", "self", ".", "model", ".", "decoder", ".", "parameters", "(", ")", ",", "config", ".", "max_grad_norm", ")", "\n", "clip_grad_norm_", "(", "self", ".", "model", ".", "reduce_state", ".", "parameters", "(", ")", ",", "config", ".", "max_grad_norm", ")", "\n", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "return", "loss", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.train.Train.trainIters": [[148, 167], ["train.Train.setup_train", "time.time", "train.Train.batcher.next_batch", "train.Train.train_one_batch", "data_util.utils.calc_running_avg_loss", "train.Train.summary_writer.flush", "print", "time.time", "train.Train.save_model", "time.time"], "methods", ["home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.train.Train.setup_train", "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.train.Train.train_one_batch", "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.data_util.utils.calc_running_avg_loss", "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.training_ptr_gen.train.Train.save_model"], ["", "def", "trainIters", "(", "self", ",", "n_iters", ",", "model_file_path", "=", "None", ")", ":", "\n", "        ", "iter", ",", "running_avg_loss", "=", "self", ".", "setup_train", "(", "model_file_path", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "while", "iter", "<", "n_iters", ":", "\n", "            ", "batch", "=", "self", ".", "batcher", ".", "next_batch", "(", ")", "\n", "loss", "=", "self", ".", "train_one_batch", "(", "batch", ")", "\n", "\n", "running_avg_loss", "=", "calc_running_avg_loss", "(", "loss", ",", "running_avg_loss", ",", "self", ".", "summary_writer", ",", "iter", ")", "\n", "iter", "+=", "1", "\n", "\n", "if", "iter", "%", "100", "==", "0", ":", "\n", "                ", "self", ".", "summary_writer", ".", "flush", "(", ")", "\n", "", "print_interval", "=", "500", "\n", "if", "iter", "%", "print_interval", "==", "0", ":", "\n", "                ", "print", "(", "'steps %d, seconds for %d batch: %.2f , loss: %f'", "%", "(", "iter", ",", "print_interval", ",", "\n", "time", ".", "time", "(", ")", "-", "start", ",", "loss", ")", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "", "if", "iter", "%", "500", "==", "0", ":", "\n", "                ", "self", ".", "save_model", "(", "running_avg_loss", ",", "iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.data_util.utils.print_results": [[7, 13], ["print", "print", "print", "print", "print"], "function", ["None"], ["def", "print_results", "(", "article", ",", "abstract", ",", "decoded_output", ")", ":", "\n", "  ", "print", "(", "\"\"", ")", "\n", "print", "(", "'ARTICLE:  %s'", ",", "article", ")", "\n", "print", "(", "'REFERENCE SUMMARY: %s'", ",", "abstract", ")", "\n", "print", "(", "'GENERATED SUMMARY: %s'", ",", "decoded_output", ")", "\n", "print", "(", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.data_util.utils.make_html_safe": [[15, 19], ["s.replace", "s.replace"], "function", ["None"], ["", "def", "make_html_safe", "(", "s", ")", ":", "\n", "  ", "s", ".", "replace", "(", "\"<\"", ",", "\"&lt;\"", ")", "\n", "s", ".", "replace", "(", "\">\"", ",", "\"&gt;\"", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.data_util.utils.rouge_eval": [[21, 30], ["pyrouge.Rouge155", "logging.getLogger().setLevel", "pyrouge.Rouge155.convert_and_evaluate", "pyrouge.Rouge155.output_to_dict", "logging.getLogger"], "function", ["None"], ["", "def", "rouge_eval", "(", "ref_dir", ",", "dec_dir", ")", ":", "\n", "  ", "r", "=", "pyrouge", ".", "Rouge155", "(", ")", "\n", "r", ".", "model_filename_pattern", "=", "'#ID#_reference.txt'", "\n", "r", ".", "system_filename_pattern", "=", "'(\\d+)_decoded.txt'", "\n", "r", ".", "model_dir", "=", "ref_dir", "\n", "r", ".", "system_dir", "=", "dec_dir", "\n", "logging", ".", "getLogger", "(", "'global'", ")", ".", "setLevel", "(", "logging", ".", "WARNING", ")", "# silence pyrouge logging", "\n", "rouge_results", "=", "r", ".", "convert_and_evaluate", "(", ")", "\n", "return", "r", ".", "output_to_dict", "(", "rouge_results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.data_util.utils.rouge_log": [[32, 49], ["print", "os.path.join", "print", "open", "f.write"], "function", ["None"], ["", "def", "rouge_log", "(", "results_dict", ",", "dir_to_write", ")", ":", "\n", "  ", "log_str", "=", "\"\"", "\n", "for", "x", "in", "[", "\"1\"", ",", "\"2\"", ",", "\"l\"", "]", ":", "\n", "    ", "log_str", "+=", "\"\\nROUGE-%s:\\n\"", "%", "x", "\n", "for", "y", "in", "[", "\"f_score\"", ",", "\"recall\"", ",", "\"precision\"", "]", ":", "\n", "      ", "key", "=", "\"rouge_%s_%s\"", "%", "(", "x", ",", "y", ")", "\n", "key_cb", "=", "key", "+", "\"_cb\"", "\n", "key_ce", "=", "key", "+", "\"_ce\"", "\n", "val", "=", "results_dict", "[", "key", "]", "\n", "val_cb", "=", "results_dict", "[", "key_cb", "]", "\n", "val_ce", "=", "results_dict", "[", "key_ce", "]", "\n", "log_str", "+=", "\"%s: %.4f with confidence interval (%.4f, %.4f)\\n\"", "%", "(", "key", ",", "val", ",", "val_cb", ",", "val_ce", ")", "\n", "", "", "print", "(", "log_str", ")", "\n", "results_file", "=", "os", ".", "path", ".", "join", "(", "dir_to_write", ",", "\"ROUGE_results.txt\"", ")", "\n", "print", "(", "\"Writing final ROUGE results to %s...\"", "%", "(", "results_file", ")", ")", "\n", "with", "open", "(", "results_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "    ", "f", ".", "write", "(", "log_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.data_util.utils.calc_running_avg_loss": [[51, 62], ["min", "tensorflow.Summary", "tf.Summary.value.add", "summary_writer.add_summary"], "function", ["None"], ["", "", "def", "calc_running_avg_loss", "(", "loss", ",", "running_avg_loss", ",", "summary_writer", ",", "step", ",", "decay", "=", "0.99", ")", ":", "\n", "  ", "if", "running_avg_loss", "==", "0", ":", "# on the first iteration just take the loss", "\n", "    ", "running_avg_loss", "=", "loss", "\n", "", "else", ":", "\n", "    ", "running_avg_loss", "=", "running_avg_loss", "*", "decay", "+", "(", "1", "-", "decay", ")", "*", "loss", "\n", "", "running_avg_loss", "=", "min", "(", "running_avg_loss", ",", "12", ")", "# clip", "\n", "loss_sum", "=", "tf", ".", "Summary", "(", ")", "\n", "tag_name", "=", "'running_avg_loss/decay=%f'", "%", "(", "decay", ")", "\n", "loss_sum", ".", "value", ".", "add", "(", "tag", "=", "tag_name", ",", "simple_value", "=", "running_avg_loss", ")", "\n", "summary_writer", ".", "add_summary", "(", "loss_sum", ",", "step", ")", "\n", "return", "running_avg_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.data_util.utils.write_for_rouge": [[64, 90], ["os.path.join", "os.path.join", "len", "decoded_sents.append", "utils.make_html_safe", "utils.make_html_safe", "open", "enumerate", "open", "enumerate", "decoded_words.index", "len", "f.write", "f.write", "f.write", "f.write", "len", "len"], "function", ["home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.data_util.utils.make_html_safe", "home.repos.pwc.inspect_result.darsh10_split_encoder_pointer_summarizer.data_util.utils.make_html_safe"], ["", "def", "write_for_rouge", "(", "reference_sents", ",", "decoded_words", ",", "ex_index", ",", "\n", "_rouge_ref_dir", ",", "_rouge_dec_dir", ")", ":", "\n", "  ", "decoded_sents", "=", "[", "]", "\n", "while", "len", "(", "decoded_words", ")", ">", "0", ":", "\n", "    ", "try", ":", "\n", "      ", "fst_period_idx", "=", "decoded_words", ".", "index", "(", "\".\"", ")", "\n", "", "except", "ValueError", ":", "\n", "      ", "fst_period_idx", "=", "len", "(", "decoded_words", ")", "\n", "", "sent", "=", "decoded_words", "[", ":", "fst_period_idx", "+", "1", "]", "\n", "decoded_words", "=", "decoded_words", "[", "fst_period_idx", "+", "1", ":", "]", "\n", "decoded_sents", ".", "append", "(", "' '", ".", "join", "(", "sent", ")", ")", "\n", "\n", "# pyrouge calls a perl script that puts the data into HTML files.", "\n", "# Therefore we need to make our output HTML safe.", "\n", "", "decoded_sents", "=", "[", "make_html_safe", "(", "w", ")", "for", "w", "in", "decoded_sents", "]", "\n", "reference_sents", "=", "[", "make_html_safe", "(", "w", ")", "for", "w", "in", "reference_sents", "]", "\n", "\n", "ref_file", "=", "os", ".", "path", ".", "join", "(", "_rouge_ref_dir", ",", "\"%06d_reference.txt\"", "%", "ex_index", ")", "\n", "decoded_file", "=", "os", ".", "path", ".", "join", "(", "_rouge_dec_dir", ",", "\"%06d_decoded.txt\"", "%", "ex_index", ")", "\n", "\n", "with", "open", "(", "ref_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "    ", "for", "idx", ",", "sent", "in", "enumerate", "(", "reference_sents", ")", ":", "\n", "      ", "f", ".", "write", "(", "sent", ")", "if", "idx", "==", "len", "(", "reference_sents", ")", "-", "1", "else", "f", ".", "write", "(", "sent", "+", "\"\\n\"", ")", "\n", "", "", "with", "open", "(", "decoded_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "    ", "for", "idx", ",", "sent", "in", "enumerate", "(", "decoded_sents", ")", ":", "\n", "      ", "f", ".", "write", "(", "sent", ")", "if", "idx", "==", "len", "(", "decoded_sents", ")", "-", "1", "else", "f", ".", "write", "(", "sent", "+", "\"\\n\"", ")", "\n", "\n"]]}