{"home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.dev.util.navigate_child_dirs": [[15, 27], ["next", "os.walk"], "function", ["None"], ["def", "navigate_child_dirs", "(", "path", ":", "str", ")", "->", "list", ":", "\n", "    ", "\"\"\"\n    Naivgate to all child directories relatve to a given file path.\n\n    Args:\n        path: (str): path to navigate to (file or directory; note that the child of a file is directory,\n                    and the children of a directory is its child directory)\n\n    Returns:\n        a list containing all immediate child directories\n    \"\"\"", "\n", "return", "next", "(", "os", ".", "walk", "(", "path", ")", ")", "[", "1", "]", "# [x[0] for x in os.walk(path)]", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.dev.util.navigate_parent_dirs": [[29, 53], ["os.path.abspath", "os.path.isfile", "ValueError", "os.path.join", "os.path.dirname", "os.path.sep.join", "range"], "function", ["None"], ["", "def", "navigate_parent_dirs", "(", "path", ":", "str", ",", "levels", ":", "int", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Navigate to a parent directory relative to a given file path.\n\n    Args:\n        path (str): path to navigate from (file or directory; note that the parent of a file is directory,\n                    and the parent of a directory is its parent directory)\n        levels (int): number of levels to navigate (must be >= 0)\n\n    Returns:\n        str: absolute path of the parent directory that sits `levels` above given path\n\n    Raises:\n        ValueError: if `levels` is negative\n    \"\"\"", "\n", "if", "levels", "<", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"levels must be >= 0, not {}\"", ".", "format", "(", "levels", ")", ")", "\n", "\n", "", "result", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "path", ",", "os", ".", "path", ".", "sep", ".", "join", "(", "\"..\"", "for", "_", "in", "range", "(", "levels", ")", ")", ")", ")", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "result", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "dirname", "(", "result", ")", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.dev.util.makedirs": [[55, 69], ["os.path.isfile", "os.makedirs", "ValueError"], "function", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.dev.util.makedirs"], ["", "def", "makedirs", "(", "path", ":", "str", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Create a directory (and its parents) if it does not exist.\n\n    Args:\n        path (str): directory path to create, including any missing parents\n\n    Raises:\n        ValueError: if the resolved path already exists as a file\n    \"\"\"", "\n", "if", "os", ".", "path", ".", "isfile", "(", "path", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"path '{}' is an existing file; cannot create as a directory\"", ".", "format", "(", "path", ")", ")", "\n", "\n", "", "os", ".", "makedirs", "(", "path", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.dev.util.find_repo_root": [[71, 79], ["util.navigate_parent_dirs", "os.path.dirname"], "function", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.dev.util.navigate_parent_dirs"], ["", "def", "find_repo_root", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Find the root path of this repository.\n\n    Returns:\n        str: absolute path of the root of this repository\n    \"\"\"", "\n", "return", "navigate_parent_dirs", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.dev.util.find_data_root": [[81, 89], ["os.path.join", "util.find_repo_root"], "function", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.dev.util.find_repo_root"], ["", "def", "find_data_root", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Find the root \"data\" directory within this repository.\n\n    Returns:\n        str: absolute path of the \"data\" directory within this repository\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "join", "(", "find_repo_root", "(", ")", ",", "DATA_DIR", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.dev.util.find_data_dir": [[91, 117], ["os.path.join", "util.find_data_root", "util.makedirs"], "function", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.dev.util.find_data_root", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.dev.util.makedirs"], ["", "def", "find_data_dir", "(", "relative_path", ":", "str", ",", "create", "=", "True", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Find a custom data directory within this repository, and optionally create it if it does not exist.\n\n    For example, to resolve the absolute path of the \"work\" data directory (and create it if needed)::\n\n        work_dir = find_data_dir(WORK_DATA_DIR)\n        work_dir_2 = find_data_dir(WORK_DATA_DIR + \"2\")\n        # can proceed assuming these directories exist\n\n    Args:\n        relative_path (str): relative directory path to find, within this repository's \"data\" directory\n        create (bool): flag to create the directory if it does not exist (default = True)\n\n    Returns:\n        str: absolute path of the \"data/`relative_path`\" directory\n\n    Raises:\n        ValueError: if `create` is True and the resolved path already exists as a file\n    \"\"\"", "\n", "custom_dir_absolute", "=", "os", ".", "path", ".", "join", "(", "find_data_root", "(", ")", ",", "relative_path", ")", "\n", "\n", "if", "create", ":", "\n", "        ", "makedirs", "(", "custom_dir_absolute", ")", "\n", "\n", "", "return", "custom_dir_absolute", "\n", "", ""]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.AlgOT.cost_mat": [[6, 55], ["tran.size", "tran.size", "torch.sqrt", "torch.sqrt", "torch.t", "torch.t", "torch.t", "torch.t", "torch.ones", "torch.ones", "emb_s.size", "emb_t.size", "torch.t"], "function", ["None"], ["def", "cost_mat", "(", "cost_s", ":", "torch", ".", "Tensor", ",", "\n", "cost_t", ":", "torch", ".", "Tensor", ",", "\n", "p_s", ":", "torch", ".", "Tensor", ",", "\n", "p_t", ":", "torch", ".", "Tensor", ",", "\n", "tran", ":", "torch", ".", "Tensor", ",", "\n", "emb_s", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "emb_t", ":", "torch", ".", "Tensor", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Implement cost_mat for Gromov-Wasserstein discrepancy (GWD)\n\n    Suppose the loss function in GWD is |a-b|^2 = a^2 - 2ab + b^2. We have:\n\n    f1(a) = a^2,\n    f2(b) = b^2,\n    h1(a) = a,\n    h2(b) = 2b\n\n    When the loss function can be represented in the following format: loss(a, b) = f1(a) + f2(b) - h1(a)h2(b), we have\n\n    cost_st = f1(cost_s)*mu_s*1_nt^T + 1_ns*mu_t^T*f2(cost_t)^T\n    cost = cost_st - h1(cost_s)*trans*h2(cost_t)^T\n\n    Args:\n        cost_s: (ns, ns) matrix (torch tensor), representing distance matrix of samples or adjacency matrix of a graph\n        cost_t: (nt, nt) matrix (torch tensor), representing distance matrix of samples or adjacency matrix of a graph\n        p_s: (ns, 1) vector (torch tensor), representing the empirical distribution of samples or nodes\n        p_t: (nt, 1) vector (torch tensor), representing the empirical distribution of samples or nodes\n        tran: (ns, nt) matrix (torch tensor), representing the optimal transport from source to target domain.\n        emb_s: (ns, d) matrix\n        emb_t: (nt, d) matrix\n    Returns:\n        cost: (ns, nt) matrix (torch tensor), representing the cost matrix conditioned on current optimal transport\n    \"\"\"", "\n", "f1_st", "=", "(", "(", "cost_s", "**", "2", ")", "@", "p_s", ")", ".", "repeat", "(", "1", ",", "tran", ".", "size", "(", "1", ")", ")", "\n", "f2_st", "=", "(", "torch", ".", "t", "(", "p_t", ")", "@", "torch", ".", "t", "(", "cost_t", "**", "2", ")", ")", ".", "repeat", "(", "tran", ".", "size", "(", "0", ")", ",", "1", ")", "\n", "cost_st", "=", "f1_st", "+", "f2_st", "\n", "cost", "=", "cost_st", "-", "2", "*", "cost_s", "@", "tran", "@", "torch", ".", "t", "(", "cost_t", ")", "\n", "\n", "if", "emb_s", "is", "not", "None", "and", "emb_t", "is", "not", "None", ":", "\n", "        ", "tmp1", "=", "emb_s", "@", "torch", ".", "t", "(", "emb_t", ")", "\n", "tmp2", "=", "torch", ".", "sqrt", "(", "(", "emb_s", "**", "2", ")", "@", "torch", ".", "ones", "(", "emb_s", ".", "size", "(", "1", ")", ",", "1", ")", ")", "\n", "tmp3", "=", "torch", ".", "sqrt", "(", "(", "emb_t", "**", "2", ")", "@", "torch", ".", "ones", "(", "emb_t", ".", "size", "(", "1", ")", ",", "1", ")", ")", "\n", "cost", "+=", "0.5", "*", "(", "1", "-", "tmp1", "/", "(", "tmp2", "@", "torch", ".", "t", "(", "tmp3", ")", ")", ")", "\n", "# tmp1 = 2 * emb_s @ torch.t(emb_t)", "\n", "# tmp2 = ((emb_s ** 2) @ torch.ones(emb_s.size(1), 1)).repeat(1, tran.size(1))", "\n", "# tmp3 = ((emb_t ** 2) @ torch.ones(emb_t.size(1), 1)).repeat(1, tran.size(0))", "\n", "# tmp = 0.1 * (tmp2 + torch.t(tmp3) - tmp1) / (emb_s.size(1) ** 2)", "\n", "# cost += tmp", "\n", "", "return", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.AlgOT.ot_badmm": [[57, 116], ["torch.ones", "torch.ones", "range", "p_s.size", "p_t.size", "torch.exp", "torch.exp", "torch.t", "torch.t", "torch.t", "AlgOT.cost_mat", "torch.t"], "function", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.AlgOT.cost_mat"], ["", "def", "ot_badmm", "(", "cost_s", ":", "torch", ".", "Tensor", ",", "\n", "cost_t", ":", "torch", ".", "Tensor", ",", "\n", "p_s", ":", "torch", ".", "Tensor", ",", "\n", "p_t", ":", "torch", ".", "Tensor", ",", "\n", "tran", ":", "torch", ".", "Tensor", ",", "\n", "dual", ":", "torch", ".", "Tensor", ",", "\n", "gamma", ":", "float", ",", "\n", "num_layer", ":", "int", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Solve min_{trans in Pi(p_s, p_t)} <cost_st - 2 * cost_s * tran * cost_t^T, tran> via Bregman ADMM (B-ADMM)\n\n    Introducing an auxiliary variable \"aux\", we reformulate the problem as\n\n    min <cost_st - 2 * cost_s * aux * cost_t^T, tran>\n    s.t. tran in Pi(p_s, .), aux in Pi(., p_t), and tran = aux\n\n    and solve it via B-ADMM.\n\n    Specifically, further introducing a dual variable \"dual\",\n    we repeat the following steps till converge:\n\n    step 1:\n    min_{tran in Pi(p_s, .)} <cost_st - 2 * cost_s * aux * cost_t^T, tran> + <dual, tran - aux> + gamma * KL(tran | aux)\n\n    step 2:\n    min_{aux in Pi(., p_t)} <-2 * cost_s^T * tran * cost_t, aux> + <dual, tran - aux> + gamma * KL(aux | tran)\n\n    step 3:\n    dual = dual + gamma * (tran - aux)\n\n    Args:\n        cost_s: (ns, ns) matrix (torch tensor), representing distance matrix of samples or adjacency matrix of a graph\n        cost_t: (nt, nt) matrix (torch tensor), representing distance matrix of samples or adjacency matrix of a graph\n        p_s: (ns, 1) vector (torch tensor), representing the empirical distribution of samples or nodes\n        p_t: (nt, 1) vector (torch tensor), representing the empirical distribution of samples or nodes\n        tran: (ns, nt) matrix (torch tensor), representing initial optimal transport from source to target domain.\n        dual: (ns, nt) matrix (torch tensor), representing dual variables\n        gamma: the weight of Bergman divergence\n        num_layer: the number of iterations (the number of layers in this computation module)\n\n    Returns:\n        tran: (ns, nt) matrix (torch tensor), representing updated optimal transport from source to target domain.\n        dual: (ns, nt) matrix (torch tensor), representing updated dual variables\n\n    \"\"\"", "\n", "all1_s", "=", "torch", ".", "ones", "(", "p_s", ".", "size", "(", ")", ")", "\n", "all1_t", "=", "torch", ".", "ones", "(", "p_t", ".", "size", "(", ")", ")", "\n", "for", "m", "in", "range", "(", "num_layer", ")", ":", "\n", "        ", "kernel_a", "=", "torch", ".", "exp", "(", "(", "dual", "+", "2", "*", "torch", ".", "t", "(", "cost_s", ")", "@", "tran", "@", "cost_t", ")", "/", "gamma", ")", "*", "tran", "\n", "b", "=", "p_t", "/", "(", "torch", ".", "t", "(", "kernel_a", ")", "@", "all1_s", ")", "\n", "aux", "=", "(", "all1_s", "@", "torch", ".", "t", "(", "b", ")", ")", "*", "kernel_a", "\n", "\n", "dual", "=", "dual", "+", "gamma", "*", "(", "tran", "-", "aux", ")", "\n", "\n", "kernel_t", "=", "torch", ".", "exp", "(", "-", "(", "cost_mat", "(", "cost_s", ",", "cost_t", ",", "p_s", ",", "p_t", ",", "aux", ")", "+", "dual", ")", "/", "gamma", ")", "*", "aux", "\n", "a", "=", "p_s", "/", "(", "kernel_t", "@", "all1_t", ")", "\n", "tran", "=", "(", "a", "@", "torch", ".", "t", "(", "all1_t", ")", ")", "*", "kernel_t", "\n", "\n", "", "return", "tran", ",", "dual", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.AlgOT.ot_ppa": [[118, 164], ["range", "range", "torch.exp", "torch.t", "torch.t", "torch.t", "AlgOT.cost_mat"], "function", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.AlgOT.cost_mat"], ["", "def", "ot_ppa", "(", "cost_s", ":", "torch", ".", "Tensor", ",", "\n", "cost_t", ":", "torch", ".", "Tensor", ",", "\n", "p_s", ":", "torch", ".", "Tensor", ",", "\n", "p_t", ":", "torch", ".", "Tensor", ",", "\n", "tran", ":", "torch", ".", "Tensor", ",", "\n", "dual", ":", "torch", ".", "Tensor", ",", "\n", "gamma", ":", "float", ",", "\n", "num_layer", ":", "int", ",", "\n", "sinkhorn_iters", ":", "int", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Solve min_{trans in Pi(p_s, p_t)} <cost_st - 2 * cost_s * tran * cost_t^T, tran> via proximal point algorithm (ppa)\n\n    Specifically, at each iteration, we solve the following problem:\n\n    min_{tran in Pi(p_s, p_t)} <cost_st - 2 * cost_s * tran0 * cost_t^T, tran> + gamma * KL(tran | tran0)\n\n    where \"tran0\" is previous estimation. This problem can be reformulated as\n\n    min_{tran in Pi(p_s, p_t)} <cost_st - 2 * cost_s * tran0 * cost_t^T - gamma * log(tran0), tran> + gamma * H(tran)\n\n    where \"H(tran)\" is the entropy of tran.\n    This problem can be solved by Sinkhorn-Knopp iterations via introducing a dual variable \"dual\".\n\n    Args:\n        cost_s: (ns, ns) matrix (torch tensor), representing distance matrix of samples or adjacency matrix of a graph\n        cost_t: (nt, nt) matrix (torch tensor), representing distance matrix of samples or adjacency matrix of a graph\n        p_s: (ns, 1) vector (torch tensor), representing the empirical distribution of samples or nodes\n        p_t: (nt, 1) vector (torch tensor), representing the empirical distribution of samples or nodes\n        tran: (ns, nt) matrix (torch tensor), representing initial optimal transport from source to target domain.\n        dual: (ns, 1) vector (torch tensor), representing dual variables\n        gamma: the weight of Bergman proximal term\n        num_layer: the number of iterations (the number of layers in this computation module)\n        sinkhorn_iters: the number of Sinkhorn-Knopp iterations\n\n    Returns:\n        tran: (ns, nt) matrix (torch tensor), representing updated optimal transport from source to target domain.\n        dual: (ns, nt) matrix (torch tensor), representing updated dual variables\n    \"\"\"", "\n", "for", "m", "in", "range", "(", "num_layer", ")", ":", "\n", "        ", "kernel", "=", "torch", ".", "exp", "(", "-", "cost_mat", "(", "cost_s", ",", "cost_t", ",", "p_s", ",", "p_t", ",", "tran", ")", "/", "gamma", ")", "*", "tran", "\n", "b", "=", "p_t", "/", "(", "torch", ".", "t", "(", "kernel", ")", "@", "dual", ")", "\n", "for", "i", "in", "range", "(", "sinkhorn_iters", ")", ":", "\n", "            ", "dual", "=", "p_s", "/", "(", "kernel", "@", "b", ")", "\n", "b", "=", "p_t", "/", "(", "torch", ".", "t", "(", "kernel", ")", "@", "dual", ")", "\n", "", "tran", "=", "(", "dual", "@", "torch", ".", "t", "(", "b", ")", ")", "*", "kernel", "\n", "", "return", "tran", ",", "dual", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.AlgOT.optimal_transport": [[166, 202], ["torch.t", "range", "torch.ones", "p_s.size", "range", "torch.ones", "torch.ones", "torch.zeros", "range", "p_s.size", "torch.exp", "p_s.size", "p_t.size", "p_s.size", "p_t.size", "AlgOT.cost_mat", "torch.t", "torch.t", "torch.exp", "torch.exp", "torch.t", "torch.t", "torch.t", "torch.t", "AlgOT.cost_mat", "AlgOT.cost_mat", "torch.t"], "function", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.AlgOT.cost_mat", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.AlgOT.cost_mat", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.AlgOT.cost_mat"], ["", "def", "optimal_transport", "(", "cost_s", ":", "torch", ".", "Tensor", ",", "\n", "cost_t", ":", "torch", ".", "Tensor", ",", "\n", "p_s", ":", "torch", ".", "Tensor", ",", "\n", "p_t", ":", "torch", ".", "Tensor", ",", "\n", "ot_method", ":", "str", ",", "\n", "gamma", ":", "float", ",", "\n", "num_layer", ":", "int", ",", "\n", "emb_s", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "emb_t", ":", "torch", ".", "Tensor", "=", "None", ")", ":", "\n", "    ", "tran", "=", "p_s", "@", "torch", ".", "t", "(", "p_t", ")", "\n", "if", "ot_method", "==", "'ppa'", ":", "\n", "        ", "dual", "=", "torch", ".", "ones", "(", "p_s", ".", "size", "(", ")", ")", "/", "p_s", ".", "size", "(", "0", ")", "\n", "for", "m", "in", "range", "(", "num_layer", ")", ":", "\n", "            ", "kernel", "=", "torch", ".", "exp", "(", "-", "cost_mat", "(", "cost_s", ",", "cost_t", ",", "p_s", ",", "p_t", ",", "tran", ",", "emb_s", ",", "emb_t", ")", "/", "gamma", ")", "*", "tran", "\n", "b", "=", "p_t", "/", "(", "torch", ".", "t", "(", "kernel", ")", "@", "dual", ")", "\n", "for", "i", "in", "range", "(", "20", ")", ":", "\n", "                ", "dual", "=", "p_s", "/", "(", "kernel", "@", "b", ")", "\n", "b", "=", "p_t", "/", "(", "torch", ".", "t", "(", "kernel", ")", "@", "dual", ")", "\n", "", "tran", "=", "(", "dual", "@", "torch", ".", "t", "(", "b", ")", ")", "*", "kernel", "\n", "\n", "", "", "elif", "ot_method", "==", "'b-admm'", ":", "\n", "        ", "all1_s", "=", "torch", ".", "ones", "(", "p_s", ".", "size", "(", ")", ")", "\n", "all1_t", "=", "torch", ".", "ones", "(", "p_t", ".", "size", "(", ")", ")", "\n", "dual", "=", "torch", ".", "zeros", "(", "p_s", ".", "size", "(", "0", ")", ",", "p_t", ".", "size", "(", "0", ")", ")", "\n", "for", "m", "in", "range", "(", "num_layer", ")", ":", "\n", "            ", "kernel_a", "=", "torch", ".", "exp", "(", "(", "dual", "+", "2", "*", "torch", ".", "t", "(", "cost_s", ")", "@", "tran", "@", "cost_t", ")", "/", "gamma", ")", "*", "tran", "\n", "b", "=", "p_t", "/", "(", "torch", ".", "t", "(", "kernel_a", ")", "@", "all1_s", ")", "\n", "aux", "=", "(", "all1_s", "@", "torch", ".", "t", "(", "b", ")", ")", "*", "kernel_a", "\n", "\n", "dual", "=", "dual", "+", "gamma", "*", "(", "tran", "-", "aux", ")", "\n", "\n", "kernel_t", "=", "torch", ".", "exp", "(", "-", "(", "cost_mat", "(", "cost_s", ",", "cost_t", ",", "p_s", ",", "p_t", ",", "aux", ",", "emb_s", ",", "emb_t", ")", "+", "dual", ")", "/", "gamma", ")", "*", "aux", "\n", "a", "=", "p_s", "/", "(", "kernel_t", "@", "all1_t", ")", "\n", "tran", "=", "(", "a", "@", "torch", ".", "t", "(", "all1_t", ")", ")", "*", "kernel_t", "\n", "", "", "d_gw", "=", "(", "cost_mat", "(", "cost_s", ",", "cost_t", ",", "p_s", ",", "p_t", ",", "tran", ",", "emb_s", ",", "emb_t", ")", "*", "tran", ")", ".", "sum", "(", ")", "\n", "return", "d_gw", ",", "tran", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.AlgOT.ot_fgw": [[204, 244], ["torch.t", "range", "torch.ones", "p_s.size", "AlgOT.cost_mat", "range", "torch.ones", "torch.ones", "torch.zeros", "range", "p_s.size", "torch.exp", "p_s.size", "p_t.size", "p_s.size", "p_t.size", "AlgOT.cost_mat", "AlgOT.cost_mat", "torch.t", "torch.t", "torch.exp", "torch.exp", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t"], "function", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.AlgOT.cost_mat", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.AlgOT.cost_mat", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.AlgOT.cost_mat"], ["", "def", "ot_fgw", "(", "cost_s", ":", "torch", ".", "Tensor", ",", "\n", "cost_t", ":", "torch", ".", "Tensor", ",", "\n", "p_s", ":", "torch", ".", "Tensor", ",", "\n", "p_t", ":", "torch", ".", "Tensor", ",", "\n", "ot_method", ":", "str", ",", "\n", "gamma", ":", "float", ",", "\n", "num_layer", ":", "int", ",", "\n", "emb_s", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "emb_t", ":", "torch", ".", "Tensor", "=", "None", ")", ":", "\n", "    ", "tran", "=", "p_s", "@", "torch", ".", "t", "(", "p_t", ")", "\n", "if", "ot_method", "==", "'ppa'", ":", "\n", "        ", "dual", "=", "torch", ".", "ones", "(", "p_s", ".", "size", "(", ")", ")", "/", "p_s", ".", "size", "(", "0", ")", "\n", "for", "m", "in", "range", "(", "num_layer", ")", ":", "\n", "            ", "cost", "=", "cost_mat", "(", "cost_s", ",", "cost_t", ",", "p_s", ",", "p_t", ",", "tran", ",", "emb_s", ",", "emb_t", ")", "\n", "# cost /= torch.max(cost)", "\n", "kernel", "=", "torch", ".", "exp", "(", "-", "cost", "/", "gamma", ")", "*", "tran", "\n", "b", "=", "p_t", "/", "(", "torch", ".", "t", "(", "kernel", ")", "@", "dual", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "                ", "dual", "=", "p_s", "/", "(", "kernel", "@", "b", ")", "\n", "b", "=", "p_t", "/", "(", "torch", ".", "t", "(", "kernel", ")", "@", "dual", ")", "\n", "", "tran", "=", "(", "dual", "@", "torch", ".", "t", "(", "b", ")", ")", "*", "kernel", "\n", "\n", "", "", "elif", "ot_method", "==", "'b-admm'", ":", "\n", "        ", "all1_s", "=", "torch", ".", "ones", "(", "p_s", ".", "size", "(", ")", ")", "\n", "all1_t", "=", "torch", ".", "ones", "(", "p_t", ".", "size", "(", ")", ")", "\n", "dual", "=", "torch", ".", "zeros", "(", "p_s", ".", "size", "(", "0", ")", ",", "p_t", ".", "size", "(", "0", ")", ")", "\n", "for", "m", "in", "range", "(", "num_layer", ")", ":", "\n", "            ", "kernel_a", "=", "torch", ".", "exp", "(", "(", "dual", "+", "2", "*", "torch", ".", "t", "(", "cost_s", ")", "@", "tran", "@", "cost_t", ")", "/", "gamma", ")", "*", "tran", "\n", "b", "=", "p_t", "/", "(", "torch", ".", "t", "(", "kernel_a", ")", "@", "all1_s", ")", "\n", "aux", "=", "(", "all1_s", "@", "torch", ".", "t", "(", "b", ")", ")", "*", "kernel_a", "\n", "\n", "dual", "=", "dual", "+", "gamma", "*", "(", "tran", "-", "aux", ")", "\n", "\n", "cost", "=", "cost_mat", "(", "cost_s", ",", "cost_t", ",", "p_s", ",", "p_t", ",", "aux", ",", "emb_s", ",", "emb_t", ")", "\n", "# cost /= torch.max(cost)", "\n", "kernel_t", "=", "torch", ".", "exp", "(", "-", "(", "cost", "+", "dual", ")", "/", "gamma", ")", "*", "aux", "\n", "a", "=", "p_s", "/", "(", "kernel_t", "@", "all1_t", ")", "\n", "tran", "=", "(", "a", "@", "torch", ".", "t", "(", "all1_t", ")", ")", "*", "kernel_t", "\n", "", "", "d_gw", "=", "(", "cost_mat", "(", "cost_s", ",", "cost_t", ",", "p_s", ",", "p_t", ",", "tran", ",", "emb_s", ",", "emb_t", ")", "*", "tran", ")", ".", "sum", "(", ")", "\n", "return", "d_gw", ",", "tran", "\n", "", ""]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.ras_algorithm": [[14, 34], ["print", "numpy.diag", "numpy.diag", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.abs", "numpy.abs"], "function", ["None"], ["def", "ras_algorithm", "(", "input_mat", ":", "np", ".", "ndarray", ",", "p_s", ":", "np", ".", "ndarray", ",", "p_t", ":", "np", ".", "ndarray", ",", "\n", "error_bound", ":", "float", "=", "1e-5", ",", "max_iter", ":", "int", "=", "2000", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "relative_error", "=", "np", ".", "inf", "\n", "t", "=", "0", "\n", "previous", "=", "input_mat", "\n", "while", "t", "<", "max_iter", "and", "relative_error", ">", "error_bound", ":", "\n", "        ", "weight", "=", "p_s", "[", ":", ",", "0", "]", "/", "(", "np", ".", "sum", "(", "input_mat", ",", "axis", "=", "1", ")", "+", "1e-10", ")", "\n", "input_mat", "=", "np", ".", "diag", "(", "weight", ")", "@", "input_mat", "\n", "\n", "weight", "=", "p_t", "[", ":", ",", "0", "]", "/", "(", "np", ".", "sum", "(", "input_mat", ",", "axis", "=", "0", ")", "+", "1e-10", ")", "\n", "input_mat", "=", "input_mat", "@", "np", ".", "diag", "(", "weight", ")", "\n", "\n", "relative_error", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "input_mat", "-", "previous", ")", ")", "/", "np", ".", "sum", "(", "np", ".", "abs", "(", "previous", ")", ")", "\n", "# print(relative_error)", "\n", "previous", "=", "input_mat", "\n", "t", "+=", "1", "\n", "", "if", "t", "==", "max_iter", ":", "\n", "        ", "print", "(", "'not converge... {}, {}'", ".", "format", "(", "t", ",", "relative_error", ")", ")", "\n", "\n", "", "return", "previous", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.orthogonal_basis": [[36, 46], ["numpy.zeros", "range", "numpy.ones", "numpy.sqrt", "numpy.sqrt"], "function", ["None"], ["", "def", "orthogonal_basis", "(", "dim", ":", "int", ")", ":", "\n", "    ", "basis", "=", "np", ".", "zeros", "(", "(", "dim", ",", "dim", ")", ")", "\n", "for", "i", "in", "range", "(", "dim", ")", ":", "\n", "        ", "if", "i", "==", "0", ":", "\n", "            ", "basis", "[", ":", ",", "i", "]", "=", "np", ".", "ones", "(", "(", "dim", ",", ")", ")", "/", "np", ".", "sqrt", "(", "dim", ")", "\n", "", "else", ":", "\n", "            ", "basis", "[", "i", "-", "1", ",", "i", "]", "=", "i", "-", "dim", "\n", "basis", "[", "i", ":", ",", "i", "]", "=", "1", "\n", "basis", "[", ":", ",", "i", "]", "=", "basis", "[", ":", ",", "i", "]", "/", "np", ".", "sqrt", "(", "(", "dim", "-", "i", ")", "**", "2", "+", "dim", "-", "i", ")", "\n", "", "", "return", "basis", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.node_distribution_similarity": [[48, 71], ["numpy.repeat", "numpy.repeat", "numpy.repeat", "numpy.repeat"], "function", ["None"], ["", "def", "node_distribution_similarity", "(", "p_s", ":", "np", ".", "ndarray", ",", "p_t", ":", "np", ".", "ndarray", ",", "values", ":", "list", "=", "None", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Calculate the node distribution similarity matrix\n    Args:\n        p_s: (n_s, 1) array representing the distribution of source node\n        p_t: (n_t, 1) array representing the distribution of target node\n        values: prior distribution of nodes\n    Returns:\n        cost_st: (n_s, n_t) the cost matrix between node probability\n    \"\"\"", "\n", "# index_s = np.argsort(p_s[:, 0]) / p_s.shape[0]", "\n", "# index_s = np.reshape(index_s, p_s.shape)", "\n", "# index_t = np.argsort(p_t[:, 0]) / p_t.shape[0]", "\n", "# index_t = np.reshape(index_t, p_t.shape)", "\n", "# cost_st = (np.repeat(index_s, p_t.shape[0], axis=1) - np.repeat(index_t, p_s.shape[0], axis=1).T) ** 2\\", "\n", "#             - 2 * index_s @ index_t.T", "\n", "if", "values", "is", "None", ":", "\n", "        ", "cost_st", "=", "(", "np", ".", "repeat", "(", "p_s", ",", "p_t", ".", "shape", "[", "0", "]", ",", "axis", "=", "1", ")", "-", "\n", "np", ".", "repeat", "(", "p_t", ",", "p_s", ".", "shape", "[", "0", "]", ",", "axis", "=", "1", ")", ".", "T", ")", "**", "2", "# - 2 * p_s @ p_t.T", "\n", "", "else", ":", "\n", "        ", "cost_st", "=", "(", "np", ".", "repeat", "(", "values", "[", "0", "]", "*", "p_s", ",", "p_t", ".", "shape", "[", "0", "]", ",", "axis", "=", "1", ")", "-", "\n", "np", ".", "repeat", "(", "values", "[", "1", "]", "*", "p_t", ",", "p_s", ".", "shape", "[", "0", "]", ",", "axis", "=", "1", ")", ".", "T", ")", "**", "2", "# - 2 * p_s @ p_t.T", "\n", "", "return", "cost_st", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.softmax_grad": [[73, 85], ["x.reshape", "numpy.diagflat", "numpy.dot"], "function", ["None"], ["", "def", "softmax_grad", "(", "x", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    The gradient of softmax function\n    Args:\n        x: (N, 1) or (N, ) array representing a distribution generated by softmax function\n\n    Returns:\n        grad_x: (N, N) array, the Jacobian matrix representing the gradient of softmax\n\n    \"\"\"", "\n", "s", "=", "x", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "return", "np", ".", "diagflat", "(", "s", ")", "-", "np", ".", "dot", "(", "s", ",", "s", ".", "T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.update_distribution": [[87, 115], ["numpy.matmul", "numpy.mean", "scipy.special.softmax", "numpy.log", "GromovWassersteinFramework.softmax_grad", "numpy.sum", "numpy.log"], "function", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.softmax_grad"], ["", "def", "update_distribution", "(", "a", ":", "np", ".", "ndarray", ",", "p_s0", ":", "np", ".", "ndarray", ",", "theta0", ":", "np", ".", "ndarray", ",", "\n", "beta", ":", "float", ",", "lr", ":", "float", ",", "weight", ":", "float", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", "]", ":", "\n", "    ", "\"\"\"\n    Update distribution via gradient descent\n    Args:\n        a: (n_s, 1) dual vector\n        p_s0: (n_s, 1) current distribution\n        theta0: (n_s, 1) current parameters of the distribution\n        beta: the weight of first term\n        lr: the learning rate\n        weight: the weight of second term (regularizer)\n\n    Returns:\n        p_s: (n_s, 1) array of updated distribution\n        theta: (n_s, 1) array of updated parameters\n    \"\"\"", "\n", "# update source distribution", "\n", "# grad_ps = beta * (np.log(a) - np.matmul((np.matmul(np.log(a), all1.transpose()) / kernel), all1))", "\n", "grad_ps", "=", "beta", "*", "np", ".", "log", "(", "a", ")", "\n", "if", "weight", ">", "0", ":", "\n", "        ", "grad_ps", "-=", "(", "weight", "*", "(", "np", ".", "log", "(", "p_s0", ")", "+", "1", ")", ")", "\n", "", "grad_theta", "=", "np", ".", "matmul", "(", "softmax_grad", "(", "p_s0", ")", ",", "grad_ps", ")", "\n", "# normalization", "\n", "grad_theta", "-=", "np", ".", "mean", "(", "grad_theta", ")", "\n", "grad_theta", "/=", "(", "1e-10", "+", "np", ".", "sum", "(", "grad_theta", "**", "2", ")", "**", "0.5", ")", "\n", "theta", "=", "theta0", "-", "lr", "*", "grad_theta", "\n", "p_s", "=", "softmax", "(", "theta", ")", "\n", "return", "p_s", ",", "theta", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.bregman_admm_iteration": [[117, 193], ["numpy.zeros", "numpy.ones", "numpy.ones", "GromovWassersteinFramework.node_cost", "numpy.exp", "numpy.sum", "numpy.diag", "GromovWassersteinFramework.node_cost", "numpy.exp", "numpy.sum", "numpy.diag", "numpy.sum", "numpy.sum", "d_gw.append", "numpy.abs", "numpy.abs", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.node_cost", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.node_cost"], ["", "def", "bregman_admm_iteration", "(", "cost_st", ":", "np", ".", "ndarray", ",", "cost_s", ":", "csr_matrix", ",", "cost_t", ":", "csr_matrix", ",", "\n", "p_s", ":", "np", ".", "ndarray", "=", "None", ",", "p_t", ":", "np", ".", "ndarray", "=", "None", ",", "trans0", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "beta", ":", "float", "=", "1e-1", ",", "loss_type", ":", "str", "=", "'L2'", ",", "error_bound", ":", "float", "=", "1e-3", ",", "\n", "max_iter", ":", "int", "=", "50", ",", "test_mode", ":", "bool", "=", "False", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", ",", "List", "]", ":", "\n", "    ", "\"\"\"\n    Bregman-ADMM iteration algorithm\n\n    Original problem:\n    min_{trans in Pi(p_s, p_t)} <cost, trans>\n\n    B-ADMM solves this problem via introducing an auxiliary variable \"trans0\", and a dual variable \"Z\"\n    1) min_{trans1 in Pi(p_s)} <cost, trans1> + <Z, trans1> + beta * KL(trans1 || trans0)\n    2) min_{trans0 in Pi(p_t)} <-Z, trans0> + beta * KL(trans0 || trans1)\n    3) Z = Z + beta * (trans1 - trans0)\n\n    The sub-problems 1 and 2 have closed form solutions\n\n    Args:\n        cost_st: (n_s, n_t) array representing distance between nodes\n        cost_s: (n_s, n_s) array representing distance between nodes\n        cost_t: (n_s, n_s) array representing distance between nodes\n        p_s: (n_s, 1) array representing the distribution of source nodes\n        p_t: (n_t, 1) array representing the distribution of target nodes\n        trans0: (n_s, n_t) initial array of optimal transport\n        beta: the weight of entropic regularizer\n        loss_type: L2 or KL\n        error_bound: the error bound to check convergence\n        max_iter: the maximum number of iterations\n        test_mode: whether calculate GW discrepancy\n    \"\"\"", "\n", "if", "p_s", "is", "None", ":", "\n", "        ", "p_s", "=", "np", ".", "ones", "(", "(", "cost_st", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "/", "cost_st", ".", "shape", "[", "0", "]", "\n", "\n", "", "if", "p_t", "is", "None", ":", "\n", "        ", "p_t", "=", "np", ".", "ones", "(", "(", "cost_st", ".", "shape", "[", "1", "]", ",", "1", ")", ")", "/", "cost_st", ".", "shape", "[", "1", "]", "\n", "\n", "", "if", "trans0", "is", "not", "None", ":", "\n", "        ", "trans0", "=", "p_s", "@", "p_t", ".", "T", "\n", "", "trans1", "=", "0", "\n", "\n", "# initialize dual variable", "\n", "dual", "=", "np", ".", "zeros", "(", "trans0", ".", "shape", ")", "\n", "\n", "relative_error", "=", "np", ".", "inf", "\n", "i", "=", "0", "\n", "d_gw", "=", "[", "]", "\n", "# eps = 1e-16", "\n", "# print(a)", "\n", "while", "relative_error", ">", "error_bound", "and", "i", "<", "max_iter", ":", "\n", "\n", "# solve sub-problem 1", "\n", "        ", "cost1", "=", "node_cost", "(", "cost_s", ",", "cost_t", ",", "trans0", ",", "cost_st", ",", "loss_type", ")", "-", "beta", "*", "trans0", "\n", "# cost1 = cost_st - 2 * (cost_s @ trans0 @ cost_t.T) - beta * trans0", "\n", "trans1", "=", "trans0", "*", "np", ".", "exp", "(", "-", "(", "cost1", "+", "dual", ")", "/", "beta", ")", "\n", "weight", "=", "p_t", "[", ":", ",", "0", "]", "/", "(", "np", ".", "sum", "(", "trans1", ",", "axis", "=", "0", ")", ")", "\n", "trans1", "=", "trans1", "@", "np", ".", "diag", "(", "weight", ")", "\n", "\n", "# solve sub-problem 2", "\n", "cost2", "=", "node_cost", "(", "cost_s", ".", "T", ",", "cost_t", ".", "T", ",", "trans1", ",", "cost_st", "=", "None", ",", "loss_type", "=", "loss_type", ")", "-", "beta", "*", "trans1", "\n", "# cost2 = -2 * (cost_s.T @ trans1 @ cost_t) - beta * trans1", "\n", "# cost2 = cost_st - 2 * (cost_s @ trans1 @ cost_t.T) - beta * trans1", "\n", "trans0", "=", "trans1", "*", "np", ".", "exp", "(", "-", "(", "cost2", "-", "dual", ")", "/", "beta", ")", "\n", "weight", "=", "p_s", "[", ":", ",", "0", "]", "/", "(", "np", ".", "sum", "(", "trans0", ",", "axis", "=", "1", ")", ")", "\n", "trans0", "=", "np", ".", "diag", "(", "weight", ")", "@", "trans0", "\n", "\n", "# update dual variable", "\n", "dual", "+=", "beta", "*", "(", "trans1", "-", "trans0", ")", "\n", "\n", "relative_error", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "trans1", "-", "trans0", ")", ")", "/", "np", ".", "sum", "(", "np", ".", "abs", "(", "trans1", ")", ")", "\n", "i", "=", "i", "+", "1", "\n", "\n", "if", "test_mode", ":", "\n", "            ", "cost", "=", "cost_st", "-", "2", "*", "(", "cost_s", "@", "trans1", "@", "cost_t", ".", "T", ")", "\n", "d_gw", ".", "append", "(", "np", ".", "sum", "(", "cost", "*", "trans1", ")", ")", "\n", "\n", "", "", "return", "trans1", ",", "trans0", ",", "d_gw", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.bregman_admm_iteration2": [[195, 256], ["numpy.zeros", "numpy.ones", "numpy.ones", "numpy.exp", "numpy.diag", "numpy.exp", "numpy.diag", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.abs", "numpy.abs"], "function", ["None"], ["", "def", "bregman_admm_iteration2", "(", "cost", ":", "np", ".", "ndarray", ",", "p_s", ":", "np", ".", "ndarray", "=", "None", ",", "p_t", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "dual0", ":", "np", ".", "ndarray", "=", "None", ",", "trans0", ":", "np", ".", "ndarray", "=", "None", ",", "beta", ":", "float", "=", "1e-1", ",", "\n", "error_bound", ":", "float", "=", "1e-3", ",", "max_iter", ":", "int", "=", "50", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", ",", "np", ".", "ndarray", "]", ":", "\n", "    ", "\"\"\"\n    Bregman-ADMM iteration algorithm\n\n    Original problem:\n    min_{trans in Pi(p_s, p_t)} <cost, trans>\n\n    B-ADMM solves this problem via introducing an auxiliary variable \"trans0\", and a dual variable \"Z\"\n    1) min_{trans1 in Pi(p_s)} <cost, trans1> + <Z, trans1> + beta * KL(trans1 || trans0)\n    2) min_{trans0 in Pi(p_t)} <-Z, trans0> + beta * KL(trans0 || trans1)\n    3) Z = Z + beta * (trans1 - trans0)\n\n    The sub-problems 1 and 2 have closed form solutions\n\n    Args:\n        cost: (n_s, n_t) array representing distance between nodes\n        p_s: (n_s, 1) array representing the distribution of source nodes\n        p_t: (n_t, 1) array representing the distribution of target nodes\n        dual0: (n_s, n_t) initial array of dual variable\n        trans0: (n_s, n_t) initial array of optimal transport\n        beta: the weight of entropic regularizer\n        error_bound: the error bound to check convergence\n        max_iter: the maximum number of iterations\n    \"\"\"", "\n", "if", "p_s", "is", "None", ":", "\n", "        ", "p_s", "=", "np", ".", "ones", "(", "(", "cost", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "/", "cost", ".", "shape", "[", "0", "]", "\n", "\n", "", "if", "p_t", "is", "None", ":", "\n", "        ", "p_t", "=", "np", ".", "ones", "(", "(", "cost", ".", "shape", "[", "1", "]", ",", "1", ")", ")", "/", "cost", ".", "shape", "[", "1", "]", "\n", "\n", "", "if", "trans0", "is", "not", "None", ":", "\n", "        ", "trans0", "=", "p_s", "@", "p_t", ".", "T", "\n", "", "trans1", "=", "0", "\n", "\n", "if", "dual0", "is", "None", ":", "\n", "        ", "dual0", "=", "np", ".", "zeros", "(", "cost", ".", "shape", ")", "\n", "\n", "", "relative_error", "=", "np", ".", "inf", "\n", "i", "=", "0", "\n", "eps", "=", "1e-16", "\n", "# print(a)", "\n", "while", "relative_error", ">", "error_bound", "and", "i", "<", "max_iter", ":", "\n", "# solve sub-problem 1", "\n", "        ", "trans1", "=", "trans0", "*", "np", ".", "exp", "(", "-", "(", "cost", "+", "dual0", ")", "/", "beta", ")", "\n", "weight", "=", "p_t", "[", ":", ",", "0", "]", "/", "(", "np", ".", "sum", "(", "trans1", ",", "axis", "=", "0", ")", "+", "eps", ")", "\n", "trans1", "=", "trans1", "@", "np", ".", "diag", "(", "weight", ")", "\n", "\n", "# solve sub-problem 2", "\n", "trans0", "=", "trans1", "*", "np", ".", "exp", "(", "dual0", "/", "beta", ")", "\n", "weight", "=", "p_s", "[", ":", ",", "0", "]", "/", "(", "np", ".", "sum", "(", "trans0", ",", "axis", "=", "1", ")", "+", "eps", ")", "\n", "trans0", "=", "np", ".", "diag", "(", "weight", ")", "@", "trans0", "\n", "\n", "# solve sub-problem 3", "\n", "dual0", "+=", "beta", "*", "(", "trans1", "-", "trans0", ")", "\n", "relative_error", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "trans1", "-", "trans0", ")", ")", "/", "np", ".", "sum", "(", "np", ".", "abs", "(", "trans1", ")", ")", "\n", "# print(relative_error)", "\n", "i", "=", "i", "+", "1", "\n", "\n", "", "return", "trans1", ",", "trans0", ",", "dual0", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.sinkhorn_knopp_iteration": [[258, 315], ["numpy.max", "numpy.exp", "numpy.matmul", "numpy.ones", "numpy.ones", "numpy.ones", "numpy.exp", "numpy.matmul", "numpy.matmul", "numpy.sum", "numpy.sum", "numpy.abs", "numpy.abs"], "function", ["None"], ["", "def", "sinkhorn_knopp_iteration", "(", "cost", ":", "np", ".", "ndarray", ",", "p_s", ":", "np", ".", "ndarray", "=", "None", ",", "p_t", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "a", ":", "np", ".", "ndarray", "=", "None", ",", "trans0", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "beta", ":", "float", "=", "1e-1", ",", "error_bound", ":", "float", "=", "1e-3", ",", "\n", "max_iter", ":", "int", "=", "50", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", "]", ":", "\n", "    ", "\"\"\"\n    Sinkhorn-Knopp iteration algorithm\n\n    When initial optimal transport \"trans0\" is not available, the function solves\n        min_{trans in Pi(p_s, p_t)} <cost, trans> + beta * <log(trans), trans>\n\n    When initial optimal transport \"trans0\" is given, the function solves:\n        min_{trans in Pi(p_s, p_t)} <cost, trans> + beta * KL(trans || trans0)\n\n    Args:\n        cost: (n_s, n_t) array representing distance between nodes\n        p_s: (n_s, 1) array representing the distribution of source nodes\n        p_t: (n_t, 1) array representing the distribution of target nodes\n        a: (n_s, 1) array representing the dual variable\n        trans0: (n_s, n_t) initial array of optimal transport\n        beta: the weight of entropic regularizer\n        error_bound: the error bound to check convergence\n        max_iter: the maximum number of iterations\n\n    Returns:\n        trans: optimal transport\n        a: updated dual variable\n\n    \"\"\"", "\n", "if", "p_s", "is", "None", ":", "\n", "        ", "p_s", "=", "np", ".", "ones", "(", "(", "cost", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "/", "cost", ".", "shape", "[", "0", "]", "\n", "\n", "", "if", "p_t", "is", "None", ":", "\n", "        ", "p_t", "=", "np", ".", "ones", "(", "(", "cost", ".", "shape", "[", "1", "]", ",", "1", ")", ")", "/", "cost", ".", "shape", "[", "1", "]", "\n", "\n", "", "if", "a", "is", "None", ":", "\n", "        ", "a", "=", "np", ".", "ones", "(", "(", "cost", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "/", "cost", ".", "shape", "[", "0", "]", "\n", "\n", "", "cost", "/=", "np", ".", "max", "(", "cost", ")", "\n", "if", "trans0", "is", "not", "None", ":", "\n", "        ", "kernel", "=", "np", ".", "exp", "(", "-", "cost", "/", "beta", ")", "*", "trans0", "\n", "", "else", ":", "\n", "        ", "kernel", "=", "np", ".", "exp", "(", "-", "cost", "/", "beta", ")", "\n", "\n", "", "relative_error", "=", "np", ".", "inf", "\n", "b", "=", "[", "]", "\n", "i", "=", "0", "\n", "# print(a)", "\n", "# while relative_error > error_bound and i < max_iter:", "\n", "while", "i", "<", "max_iter", ":", "\n", "        ", "b", "=", "p_t", "/", "(", "np", ".", "matmul", "(", "kernel", ".", "T", ",", "a", ")", ")", "\n", "a_new", "=", "p_s", "/", "np", ".", "matmul", "(", "kernel", ",", "b", ")", "\n", "relative_error", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "a_new", "-", "a", ")", ")", "/", "np", ".", "sum", "(", "np", ".", "abs", "(", "a", ")", ")", "\n", "a", "=", "a_new", "\n", "i", "+=", "1", "\n", "", "trans", "=", "np", ".", "matmul", "(", "a", ",", "b", ".", "T", ")", "*", "kernel", "\n", "# print('sinkhorn iteration = {}'.format(i))", "\n", "return", "trans", ",", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.node_cost_st": [[317, 358], ["numpy.repeat", "numpy.repeat", "numpy.repeat", "numpy.repeat", "numpy.matmul", "GromovWassersteinFramework.node_distribution_similarity", "numpy.log"], "function", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.node_distribution_similarity"], ["", "def", "node_cost_st", "(", "cost_s", ":", "csr_matrix", ",", "cost_t", ":", "csr_matrix", ",", "\n", "p_s", ":", "np", ".", "ndarray", ",", "p_t", ":", "np", ".", "ndarray", ",", "loss_type", ":", "str", "=", "'L2'", ",", "prior", ":", "float", "=", "None", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Calculate invariant cost between the nodes in different graphs based on learned optimal transport\n    Args:\n        cost_s: (n_s, n_s) array, the cost matrix of source graph\n        cost_t: (n_t, n_t) array, the cost matrix of target graph\n        p_s: (n_s, 1) array, the distribution of source nodes\n        p_t: (n_t, 1) array, the distribution of target nodes\n        loss_type: 'L2' the Euclidean loss type for Gromov-Wasserstein discrepancy\n                   'KL' the KL-divergence loss type for Gromov-Wasserstein discrepancy\n        prior: whether use node distribution similarity matrix as a prior\n\n    Returns:\n        cost_st: (n_s, n_t) array, the estimated invariant cost between the nodes in two graphs\n    \"\"\"", "\n", "n_s", "=", "cost_s", ".", "shape", "[", "0", "]", "\n", "n_t", "=", "cost_t", ".", "shape", "[", "0", "]", "\n", "if", "loss_type", "==", "'L2'", ":", "\n", "# f1(a) = a^2, f2(b) = b^2, h1(a) = a, h2(b) = 2b", "\n", "# cost_st = f1(cost_s)*mu_s*1_nt^T + 1_ns*mu_t^T*f2(cost_t)^T", "\n", "# cost = cost_st - h1(cost_s)*trans*h2(cost_t)^T", "\n", "\n", "# f1_st = np.repeat(np.matmul(cost_s ** 2, p_s), n_t, axis=1)", "\n", "# f2_st = np.repeat(np.matmul(p_t.T, (cost_t ** 2).T), n_s, axis=0)", "\n", "        ", "f1_st", "=", "np", ".", "repeat", "(", "(", "cost_s", "**", "2", ")", "@", "p_s", ",", "n_t", ",", "axis", "=", "1", ")", "\n", "f2_st", "=", "np", ".", "repeat", "(", "(", "(", "cost_t", "**", "2", ")", "@", "p_t", ")", ".", "T", ",", "n_s", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "# f1(a) = a*log(a) - a, f2(b) = b, h1(a) = a, h2(b) = log(b)", "\n", "# cost_st = f1(cost_s)*mu_s*1_nt^T + 1_ns*mu_t^T*f2(cost_t)^T", "\n", "# cost = cost_st - h1(cost_s)*trans*h2(cost_t)^T", "\n", "\n", "        ", "f1_st", "=", "np", ".", "repeat", "(", "np", ".", "matmul", "(", "cost_s", "*", "np", ".", "log", "(", "cost_s", "+", "1e-15", ")", "-", "cost_s", ",", "p_s", ")", ",", "n_t", ",", "axis", "=", "1", ")", "\n", "# f2_st = np.repeat(np.matmul(p_t.T, cost_t.T), n_s, axis=0)", "\n", "f2_st", "=", "np", ".", "repeat", "(", "(", "cost_t", "@", "p_t", ")", ".", "T", ",", "n_s", ",", "axis", "=", "0", ")", "\n", "\n", "", "cost_st", "=", "f1_st", "+", "f2_st", "\n", "if", "prior", "is", "not", "None", ":", "\n", "        ", "cost_st", "+=", "(", "prior", "*", "node_distribution_similarity", "(", "p_s", ",", "p_t", ")", ")", "\n", "\n", "", "return", "cost_st", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.node_cost": [[360, 393], ["numpy.matmul", "numpy.log"], "function", ["None"], ["", "def", "node_cost", "(", "cost_s", ":", "csr_matrix", ",", "cost_t", ":", "csr_matrix", ",", "trans", ":", "np", ".", "ndarray", ",", "\n", "cost_st", ":", "np", ".", "ndarray", "=", "None", ",", "loss_type", ":", "str", "=", "'L2'", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Calculate the cost between the nodes in different graphs based on learned optimal transport\n    Args:\n        cost_s: (n_s, n_s) array, the cost matrix of source graph\n        cost_t: (n_t, n_t) array, the cost matrix of target graph\n        trans: (n_s, n_t) array, the learned optimal transport between two graphs\n        cost_st: (n_s, n_t) array, the estimated invariant cost between the nodes in two graphs\n        loss_type: 'L2' the Euclidean loss type for Gromov-Wasserstein discrepancy\n                   'KL' the KL-divergence loss type for Gromov-Wasserstein discrepancy\n\n    Returns:\n        cost: (n_s, n_t) array, the estimated cost between the nodes in two graphs\n    \"\"\"", "\n", "if", "cost_st", "is", "None", ":", "\n", "        ", "cost_st", "=", "0", "\n", "\n", "", "if", "loss_type", "==", "'L2'", ":", "\n", "# f1(a) = a^2, f2(b) = b^2, h1(a) = a, h2(b) = 2b", "\n", "# cost_st = f1(cost_s)*mu_s*1_nt^T + 1_ns*mu_t^T*f2(cost_t)^T", "\n", "# cost = cost_st - h1(cost_s)*trans*h2(cost_t)^T", "\n", "\n", "# cost = cost_st - 2 * np.matmul(np.matmul(cost_s, trans), cost_t.T)", "\n", "        ", "cost", "=", "cost_st", "-", "2", "*", "(", "cost_s", "@", "trans", "@", "cost_t", ".", "T", ")", "\n", "", "else", ":", "\n", "# f1(a) = a*log(a) - a, f2(b) = b, h1(a) = a, h2(b) = log(b)", "\n", "# cost_st = f1(cost_s)*mu_s*1_nt^T + 1_ns*mu_t^T*f2(cost_t)^T", "\n", "# cost = cost_st - h1(cost_s)*trans*h2(cost_t)^T", "\n", "\n", "# cost = cost_st - np.matmul(np.matmul(cost_s, trans), (np.log(cost_t + 1e-15)).T)", "\n", "        ", "cost", "=", "cost_st", "-", "np", ".", "matmul", "(", "cost_s", "@", "trans", ",", "(", "np", ".", "log", "(", "cost_t", "+", "1e-15", ")", ")", ".", "T", ")", "\n", "", "return", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.gromov_wasserstein_average": [[395, 431], ["costs.keys", "costs.keys", "costs.keys", "numpy.exp", "numpy.matmul", "numpy.matmul", "numpy.matmul", "numpy.matmul", "numpy.log"], "function", ["None"], ["", "def", "gromov_wasserstein_average", "(", "transports", ":", "Dict", ",", "costs", ":", "Dict", ",", "\n", "p_center", ":", "np", ".", "ndarray", ",", "weights", ":", "Dict", ",", "loss_type", ":", "str", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Averaging of cost matrix\n\n    Args:\n        transports: a dictionary, whose keys are graph ids and values are (n_s, n_c) np.ndarray of optimal transports\n        costs: a dictionary, whose keys are graph ids and values are (n_s, n_s) np.ndarray of cost matrices\n        p_center: (n_c, 1) np.ndarray of barycenter's distribution\n        weights: a dictionary, whose keys are graph ids and values are float number of weight\n        loss_type: 'L2' the Euclidean loss type for Gromov-Wasserstein discrepancy\n                   'KL' the KL-divergence loss type for Gromov-Wasserstein discrepancy\n\n    Returns:\n        barycenter: (N, N) np.ndarray, the barycenter of cost matrix\n    \"\"\"", "\n", "weight_sum", "=", "0", "\n", "for", "n", "in", "costs", ".", "keys", "(", ")", ":", "\n", "        ", "weight_sum", "+=", "weights", "[", "n", "]", "\n", "\n", "", "barycenter", "=", "0", "\n", "if", "loss_type", "==", "'L2'", ":", "\n", "        ", "for", "n", "in", "costs", ".", "keys", "(", ")", ":", "\n", "            ", "cost", "=", "costs", "[", "n", "]", "\n", "trans", "=", "transports", "[", "n", "]", "\n", "# barycenter += weights[n] * np.matmul(np.matmul(trans.T, cost), trans)", "\n", "barycenter", "+=", "weights", "[", "n", "]", "*", "(", "trans", ".", "T", "@", "(", "cost", "@", "trans", ")", ")", "\n", "", "barycenter", "/=", "(", "weight_sum", "*", "np", ".", "matmul", "(", "p_center", ",", "p_center", ".", "T", ")", ")", "\n", "", "else", ":", "\n", "        ", "for", "n", "in", "costs", ".", "keys", "(", ")", ":", "\n", "            ", "cost", "=", "costs", "[", "n", "]", "\n", "trans", "=", "transports", "[", "n", "]", "\n", "barycenter", "+=", "weights", "[", "n", "]", "*", "np", ".", "matmul", "(", "np", ".", "matmul", "(", "trans", ".", "T", ",", "np", ".", "log", "(", "cost", "+", "1e-15", ")", ")", ",", "trans", ")", "\n", "", "barycenter", "/=", "(", "weight_sum", "*", "np", ".", "matmul", "(", "p_center", ",", "p_center", ".", "T", ")", ")", "\n", "barycenter", "=", "np", ".", "exp", "(", "barycenter", ")", "\n", "", "return", "barycenter", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.gromov_wasserstein_discrepancy": [[433, 549], ["GromovWassersteinFramework.node_cost_st", "numpy.zeros", "scipy.special.softmax", "numpy.zeros", "numpy.matmul", "numpy.ones", "GromovWassersteinFramework.node_cost", "GromovWassersteinFramework.sinkhorn_knopp_iteration", "numpy.sum", "numpy.sum", "GromovWassersteinFramework.update_distribution", "GromovWassersteinFramework.sinkhorn_knopp_iteration", "numpy.abs", "numpy.abs", "d_gw.extend", "GromovWassersteinFramework.node_cost", "d_gw.append", "GromovWassersteinFramework.bregman_admm_iteration", "GromovWassersteinFramework.sinkhorn_knopp_iteration"], "function", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.node_cost_st", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.node_cost", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.sinkhorn_knopp_iteration", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.update_distribution", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.sinkhorn_knopp_iteration", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.node_cost", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.bregman_admm_iteration", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.sinkhorn_knopp_iteration"], ["", "def", "gromov_wasserstein_discrepancy", "(", "cost_s", ":", "csr_matrix", ",", "cost_t", ":", "csr_matrix", ",", "\n", "p_s", ":", "np", ".", "ndarray", ",", "p_t", ":", "np", ".", "ndarray", ",", "\n", "ot_hyperpara", ":", "Dict", ",", "trans0", "=", "None", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "List", ",", "np", ".", "ndarray", "]", ":", "\n", "    ", "\"\"\"\n    Calculate Gromov-Wasserstein discrepancy with optionally-updated source probability\n\n    Args:\n        cost_s: (n_s, n_s) np.ndarray of source cost matrix\n        cost_t: (n_t, n_t) np.ndarray of target cost matrix\n        p_s: (n_s, 1) np.ndarray, the predefined source distribution\n        p_t: (n_t, 1) np.ndarray, the predefined target distribution\n        ot_hyperpara: dictionary of hyperparameter\n        trans0: optional (n_s, n_t) array, the initial transport\n\n    Returns:\n        trans0: (n_s, n_t) array, the optimal transport\n        d_gw: a float representing Gromov-Wasserstein discrepancy\n        p_s: (n_s, 1) array, the optimal source distribution\n    \"\"\"", "\n", "d_gw", "=", "[", "]", "\n", "n_s", "=", "cost_s", ".", "shape", "[", "0", "]", "\n", "if", "ot_hyperpara", "[", "'update_p'", "]", ":", "\n", "        ", "theta", "=", "np", ".", "zeros", "(", "(", "n_s", ",", "1", ")", ")", "\n", "p_s", "=", "softmax", "(", "theta", ")", "\n", "", "else", ":", "\n", "        ", "theta", "=", "np", ".", "zeros", "(", "(", "n_s", ",", "1", ")", ")", "\n", "\n", "", "if", "trans0", "is", "None", ":", "\n", "        ", "trans0", "=", "np", ".", "matmul", "(", "p_s", ",", "p_t", ".", "T", ")", "\n", "\n", "", "a", "=", "np", ".", "ones", "(", "(", "n_s", ",", "1", ")", ")", "/", "n_s", "\n", "\n", "t", "=", "0", "\n", "dgw", "=", "0", "\n", "relative_error", "=", "np", ".", "inf", "\n", "# calculate invariant cost matrix", "\n", "cost_st", "=", "node_cost_st", "(", "cost_s", ",", "cost_t", ",", "p_s", ",", "p_t", ",", "\n", "loss_type", "=", "ot_hyperpara", "[", "'loss_type'", "]", ",", "prior", "=", "ot_hyperpara", "[", "'node_prior'", "]", ")", "\n", "while", "relative_error", ">", "ot_hyperpara", "[", "'iter_bound'", "]", "and", "t", "<", "ot_hyperpara", "[", "'outer_iteration'", "]", ":", "\n", "# update optimal transport via Sinkhorn iteration method", "\n", "        ", "cost", "=", "node_cost", "(", "cost_s", ",", "cost_t", ",", "trans0", ",", "cost_st", ",", "ot_hyperpara", "[", "'loss_type'", "]", ")", "\n", "if", "ot_hyperpara", "[", "'ot_method'", "]", "==", "'proximal'", ":", "\n", "            ", "trans", ",", "a", "=", "sinkhorn_knopp_iteration", "(", "cost", "=", "cost", ",", "\n", "p_s", "=", "p_s", ",", "\n", "p_t", "=", "p_t", ",", "\n", "a", "=", "a", ",", "\n", "trans0", "=", "trans0", ",", "\n", "beta", "=", "ot_hyperpara", "[", "'beta'", "]", ",", "\n", "error_bound", "=", "ot_hyperpara", "[", "'sk_bound'", "]", ",", "\n", "max_iter", "=", "ot_hyperpara", "[", "'inner_iteration'", "]", ")", "\n", "", "elif", "ot_hyperpara", "[", "'ot_method'", "]", "==", "'entropy'", ":", "\n", "            ", "trans", ",", "a", "=", "sinkhorn_knopp_iteration", "(", "cost", "=", "cost", ",", "\n", "p_s", "=", "p_s", ",", "\n", "p_t", "=", "p_t", ",", "\n", "a", "=", "a", ",", "\n", "trans0", "=", "None", ",", "\n", "beta", "=", "ot_hyperpara", "[", "'beta'", "]", ",", "\n", "error_bound", "=", "ot_hyperpara", "[", "'sk_bound'", "]", ",", "\n", "max_iter", "=", "ot_hyperpara", "[", "'inner_iteration'", "]", ")", "\n", "", "elif", "ot_hyperpara", "[", "'ot_method'", "]", "==", "'b-admm'", ":", "\n", "# # solve sub-problem 1", "\n", "# cost1 = cost_st - 2 * (cost_s @ trans0 @ cost_t.T) - ot_hyperpara['beta'] * trans0", "\n", "# trans = trans0 * np.exp(-(cost1 + dual) / ot_hyperpara['beta'])", "\n", "# weight = p_t[:, 0] / (np.sum(trans, axis=0))", "\n", "# trans = trans @ np.diag(weight)", "\n", "#", "\n", "# # solve sub-problem 2", "\n", "# cost2 = -2 * (cost_s.T @ trans @ cost_t) - ot_hyperpara['beta'] * trans", "\n", "# # C2 = cost_st - 2 * (cost_s @ trans1 @ cost_t.T) - beta * trans1", "\n", "# trans0 = trans * np.exp(-(cost2 - dual) / ot_hyperpara['beta'])", "\n", "# weight = p_s[:, 0] / (np.sum(trans0, axis=1))", "\n", "# trans0 = np.diag(weight) @ trans0", "\n", "#", "\n", "# # update dual variable", "\n", "# dual += ot_hyperpara['beta'] * (trans - trans0)", "\n", "\n", "            ", "trans", ",", "_", ",", "dgw", "=", "bregman_admm_iteration", "(", "cost_st", "=", "cost_st", ",", "\n", "cost_s", "=", "cost_s", ",", "\n", "cost_t", "=", "cost_t", ",", "\n", "p_s", "=", "p_s", ",", "\n", "p_t", "=", "p_t", ",", "\n", "trans0", "=", "trans0", ",", "\n", "beta", "=", "ot_hyperpara", "[", "'beta'", "]", ",", "\n", "loss_type", "=", "ot_hyperpara", "[", "'loss_type'", "]", ",", "\n", "error_bound", "=", "ot_hyperpara", "[", "'sk_bound'", "]", ",", "\n", "max_iter", "=", "ot_hyperpara", "[", "'inner_iteration'", "]", ",", "\n", "test_mode", "=", "ot_hyperpara", "[", "'test_mode'", "]", ")", "\n", "", "else", ":", "# default method: ppa", "\n", "            ", "trans", ",", "a", "=", "sinkhorn_knopp_iteration", "(", "cost", "=", "cost", ",", "\n", "p_s", "=", "p_s", ",", "\n", "p_t", "=", "p_t", ",", "\n", "a", "=", "a", ",", "\n", "trans0", "=", "trans0", ",", "\n", "beta", "=", "ot_hyperpara", "[", "'beta'", "]", ",", "\n", "error_bound", "=", "ot_hyperpara", "[", "'sk_bound'", "]", ",", "\n", "max_iter", "=", "ot_hyperpara", "[", "'inner_iteration'", "]", ")", "\n", "", "relative_error", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "trans", "-", "trans0", ")", ")", "/", "np", ".", "sum", "(", "np", ".", "abs", "(", "trans0", ")", ")", "\n", "trans0", "=", "trans", "\n", "t", "+=", "1", "\n", "\n", "# optionally, update source distribution", "\n", "if", "ot_hyperpara", "[", "'update_p'", "]", ":", "\n", "            ", "p_s", ",", "theta", "=", "update_distribution", "(", "a", ",", "p_s", ",", "theta", ",", "\n", "ot_hyperpara", "[", "'beta'", "]", ",", "ot_hyperpara", "[", "'lr'", "]", ",", "ot_hyperpara", "[", "'alpha'", "]", ")", "\n", "", "if", "ot_hyperpara", "[", "'test_mode'", "]", ":", "\n", "            ", "if", "ot_hyperpara", "[", "'ot_method'", "]", "==", "'b-admm'", ":", "\n", "                ", "d_gw", ".", "extend", "(", "dgw", ")", "\n", "", "else", ":", "\n", "# print('proximal iteration = {}'.format(t))", "\n", "                ", "cost", "=", "node_cost", "(", "cost_s", ",", "cost_t", ",", "trans0", ",", "cost_st", ",", "ot_hyperpara", "[", "'loss_type'", "]", ")", "\n", "d_gw", ".", "append", "(", "(", "cost", "*", "trans0", ")", ".", "sum", "(", ")", ")", "\n", "\n", "# # print('proximal iteration = {}'.format(t))", "\n", "# cost = node_cost(cost_s, cost_t, trans0, cost_st, ot_hyperpara['loss_type'])", "\n", "# d_gw.append((cost * trans0).sum())", "\n", "", "", "", "return", "trans0", ",", "d_gw", ",", "p_s", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.gromov_wasserstein_barycenter": [[551, 605], ["len", "costs.keys", "scipy.sparse.csr_matrix", "numpy.matmul", "costs.keys", "numpy.diag", "costs.keys", "GromovWassersteinFramework.gromov_wasserstein_average", "d_gw_sum.append", "GromovWassersteinFramework.gromov_wasserstein_discrepancy", "numpy.sum", "numpy.sum", "numpy.abs", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.gromov_wasserstein_average", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.GromovWassersteinFramework.gromov_wasserstein_discrepancy"], ["", "def", "gromov_wasserstein_barycenter", "(", "costs", ":", "Dict", ",", "p_s", ":", "Dict", ",", "p_center", ":", "np", ".", "ndarray", ",", "\n", "ot_hyperpara", ":", "Dict", ",", "weights", ":", "Dict", "=", "None", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "Dict", ",", "List", "]", ":", "\n", "    ", "\"\"\"\n    Multi-graph matching based on one-step Gromov-Wasserstein barycenter learning.\n\n    Args:\n        costs: a dictionary, whose keys are graph ids and values are (n_s, n_s) cost matrices of different graphs\n        p_s: a dictionary, whose keys are graph ids and values ara (n_s, 1) distributions of nodes of different graphs\n        p_center: (n_c, 1) array, the distribution of barycenter's nodes\n        ot_hyperpara: the dictionary of hyperparameters to train the Gromov-Wasserstein barycenter.\n        weights: a dictionary, whose keys are graph ids and values are the weights of the graphs\n\n    Returns:\n        barycenter: (n_c, n_c) the cost matrix corresponding to the barycenter graph\n        transports: a dictionary whose keys are graph ids and values are (n_s, n_c) optimal transports\n        d_gw_sum: the sum of Gromov-Wasserstein discrepancy over iterations\n    \"\"\"", "\n", "# initialization", "\n", "num", "=", "len", "(", "costs", ")", "\n", "transports", "=", "{", "}", "\n", "for", "n", "in", "costs", ".", "keys", "(", ")", ":", "\n", "        ", "transports", "[", "n", "]", "=", "np", ".", "matmul", "(", "p_s", "[", "n", "]", ",", "p_center", ".", "T", ")", "\n", "\n", "", "if", "weights", "is", "None", ":", "\n", "        ", "weights", "=", "{", "}", "\n", "for", "n", "in", "costs", ".", "keys", "(", ")", ":", "\n", "            ", "weights", "[", "n", "]", "=", "1", "/", "num", "\n", "\n", "# barycenter0 = np.random.rand(p_center.shape[0], p_center.shape[0])", "\n", "", "", "barycenter0", "=", "csr_matrix", "(", "np", ".", "diag", "(", "p_center", "[", ":", ",", "0", "]", ")", ")", "\n", "# barycenter0 = csr_matrix(np.zeros((p_center.shape[0], p_center.shape[0])))", "\n", "# barycenter0 = csr_matrix(np.eye(p_center.shape[0]))", "\n", "\n", "d_gw_sum", "=", "[", "]", "\n", "i", "=", "0", "\n", "relative_error", "=", "np", ".", "inf", "\n", "while", "relative_error", ">", "ot_hyperpara", "[", "'cost_bound'", "]", "and", "i", "<", "ot_hyperpara", "[", "'max_iter'", "]", ":", "\n", "# update optimal transport", "\n", "        ", "d_gw", "=", "{", "}", "\n", "for", "n", "in", "costs", ".", "keys", "(", ")", ":", "\n", "            ", "transports", "[", "n", "]", ",", "d_gw", "[", "n", "]", ",", "p_s", "[", "n", "]", "=", "gromov_wasserstein_discrepancy", "(", "costs", "[", "n", "]", ",", "barycenter0", ",", "\n", "p_s", "[", "n", "]", ",", "p_center", ",", "\n", "ot_hyperpara", ",", "transports", "[", "n", "]", ")", "\n", "# averaging cost matrix", "\n", "", "barycenter", "=", "gromov_wasserstein_average", "(", "transports", ",", "costs", ",", "p_center", ",", "weights", ",", "ot_hyperpara", "[", "'loss_type'", "]", ")", "\n", "# if i > 50:", "\n", "#     barycenter[barycenter < 0.5] = 0", "\n", "#     barycenter[barycenter >= 0.5] = 1", "\n", "relative_error", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "barycenter", "-", "barycenter0", ")", ")", "/", "np", ".", "sum", "(", "np", ".", "abs", "(", "barycenter0", ")", ")", "\n", "i", "+=", "1", "\n", "barycenter0", "=", "barycenter", "\n", "d_gw_sum", ".", "append", "(", "d_gw", ")", "\n", "# print('barycenter iteration = {}'.format(i))", "\n", "", "return", "barycenter0", ",", "transports", ",", "d_gw_sum", "\n", "", ""]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.GraphSampler.__init__": [[589, 595], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ":", "List", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            data: a list of data include [[edges, #nodes, (optional label)], ...]\n        \"\"\"", "\n", "self", ".", "data", "=", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.GraphSampler.__len__": [[596, 598], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.GraphSampler.__getitem__": [[599, 630], ["numpy.zeros", "numpy.ones", "[].tolist", "numpy.sum", "torch.from_numpy().type", "torch.from_numpy().type", "numpy.sum", "numpy.sum", "len", "print", "len", "torch.LongTensor", "torch.from_numpy", "torch.from_numpy", "numpy.nonzero"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "edges", "=", "self", ".", "data", "[", "idx", "]", "[", "0", "]", "\n", "num_nodes", "=", "self", ".", "data", "[", "idx", "]", "[", "1", "]", "\n", "adj", "=", "np", ".", "zeros", "(", "(", "num_nodes", ",", "num_nodes", ")", ")", "\n", "dist", "=", "np", ".", "ones", "(", "(", "num_nodes", ",", "1", ")", ")", "\n", "\n", "for", "edge", "in", "edges", ":", "\n", "            ", "src", "=", "edge", "[", "0", "]", "\n", "dst", "=", "edge", "[", "1", "]", "\n", "adj", "[", "src", ",", "dst", "]", "=", "1", "\n", "dist", "[", "src", ",", "0", "]", "+=", "1", "\n", "dist", "[", "dst", ",", "0", "]", "+=", "1", "\n", "\n", "", "counts", "=", "np", ".", "sum", "(", "adj", ",", "axis", "=", "0", ")", "+", "np", ".", "sum", "(", "adj", ",", "axis", "=", "1", ")", "\n", "subset_nodes", "=", "np", ".", "nonzero", "(", "counts", ")", "[", "0", "]", ".", "tolist", "(", ")", "\n", "if", "len", "(", "subset_nodes", ")", "<", "num_nodes", ":", "\n", "            ", "print", "(", "'subset!'", ")", "\n", "adj", "=", "adj", "[", "subset_nodes", ",", ":", "]", "\n", "adj", "=", "adj", "[", ":", ",", "subset_nodes", "]", "\n", "dist", "=", "dist", "[", "subset_nodes", ",", ":", "]", "\n", "\n", "", "dist", "/=", "np", ".", "sum", "(", "dist", ")", "\n", "\n", "dist", "=", "torch", ".", "from_numpy", "(", "dist", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "adj", "=", "torch", ".", "from_numpy", "(", "adj", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "\n", "if", "len", "(", "self", ".", "data", "[", "idx", "]", ")", ">", "2", ":", "\n", "            ", "label", "=", "torch", ".", "LongTensor", "(", "[", "self", ".", "data", "[", "idx", "]", "[", "2", "]", "]", ")", "\n", "return", "[", "adj", ",", "dist", ",", "label", "]", "\n", "", "else", ":", "\n", "            ", "return", "[", "adj", ",", "dist", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.StructuralDataSampler.__init__": [[635, 641], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ":", "List", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            data: a list of data include [[edges, #nodes, (optional label)], ...]\n        \"\"\"", "\n", "self", ".", "data", "=", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.StructuralDataSampler.__len__": [[642, 644], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.StructuralDataSampler.__getitem__": [[645, 673], ["numpy.zeros", "numpy.ones", "numpy.sum", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type", "torch.LongTensor", "len", "numpy.ones", "numpy.sum", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "edges", "=", "self", ".", "data", "[", "idx", "]", "[", "0", "]", "\n", "num_nodes", "=", "self", ".", "data", "[", "idx", "]", "[", "1", "]", "\n", "adj", "=", "np", ".", "zeros", "(", "(", "num_nodes", ",", "num_nodes", ")", ")", "\n", "dist", "=", "np", ".", "ones", "(", "(", "num_nodes", ",", "1", ")", ")", "\n", "dist", "/=", "np", ".", "sum", "(", "dist", ")", "\n", "for", "edge", "in", "edges", ":", "\n", "            ", "src", "=", "edge", "[", "0", "]", "\n", "dst", "=", "edge", "[", "1", "]", "\n", "adj", "[", "src", ",", "dst", "]", "=", "1", "\n", "\n", "", "if", "len", "(", "self", ".", "data", "[", "idx", "]", ")", "==", "3", ":", "\n", "            ", "features", "=", "np", ".", "ones", "(", "(", "num_nodes", ",", "1", ")", ")", "\n", "for", "edge", "in", "edges", ":", "\n", "                ", "src", "=", "edge", "[", "0", "]", "\n", "dst", "=", "edge", "[", "1", "]", "\n", "features", "[", "src", ",", "0", "]", "+=", "1", "\n", "features", "[", "dst", ",", "0", "]", "+=", "1", "\n", "", "features", "/=", "np", ".", "sum", "(", "features", ")", "\n", "", "else", ":", "\n", "            ", "features", "=", "self", ".", "data", "[", "idx", "]", "[", "2", "]", "\n", "\n", "", "features", "=", "torch", ".", "from_numpy", "(", "features", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "dist", "=", "torch", ".", "from_numpy", "(", "dist", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "adj", "=", "torch", ".", "from_numpy", "(", "adj", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "label", "=", "torch", ".", "LongTensor", "(", "[", "self", ".", "data", "[", "idx", "]", "[", "-", "1", "]", "]", ")", "\n", "\n", "return", "[", "adj", ",", "dist", ",", "features", ",", "label", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.load_txt_community_file": [[19, 93], ["f.close", "node2idx.keys", "len", "numpy.zeros", "scipy.sparse.lil_matrix", "scipy.sparse.csr_matrix", "numpy.sum", "f.close", "numpy.zeros", "open", "f.readlines", "x.strip", "edge.find", "open", "f.readlines", "x.strip", "label.find", "edges.append", "int", "node2idx.keys", "node2idx.keys", "len", "len"], "function", ["None"], ["def", "load_txt_community_file", "(", "edge_path", ":", "str", ",", "label_path", ":", "str", ",", "flag", ":", "str", "=", "' '", ")", "->", "Dict", ":", "\n", "    ", "\"\"\"\n    Load edge list in .txt file and community label in .txt file\n    Args:\n        edge_path: the path of an edge list\n        label_path: the path of community labels\n        flag: the segment flag between src and dst\n\n    Returns:\n        database = {'cost': an adjacency matrix of a graph,\n                    'prob': a distribution of nodes in a graph,\n                    'idx2node': a dictionary mapping index to node name,\n                    'label': community index}\n    \"\"\"", "\n", "with", "open", "(", "edge_path", ")", "as", "f", ":", "\n", "        ", "edges_str", "=", "f", ".", "readlines", "(", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "# you may also want to remove whitespace characters like `\\n` at the end of each line", "\n", "edges_str", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "edges_str", "]", "\n", "\n", "edges", "=", "[", "]", "\n", "node2idx", "=", "{", "}", "\n", "index", "=", "0", "\n", "for", "edge", "in", "edges_str", ":", "\n", "        ", "idx", "=", "edge", ".", "find", "(", "flag", ")", "\n", "if", "idx", ">", "-", "1", ":", "\n", "            ", "src", "=", "edge", "[", ":", "idx", "]", "\n", "dst", "=", "edge", "[", "(", "idx", "+", "len", "(", "flag", ")", ")", ":", "]", "\n", "if", "src", "not", "in", "node2idx", ".", "keys", "(", ")", ":", "\n", "                ", "node2idx", "[", "src", "]", "=", "index", "\n", "index", "+=", "1", "\n", "", "if", "dst", "not", "in", "node2idx", ".", "keys", "(", ")", ":", "\n", "                ", "node2idx", "[", "dst", "]", "=", "index", "\n", "index", "+=", "1", "\n", "", "edges", ".", "append", "(", "[", "node2idx", "[", "src", "]", ",", "node2idx", "[", "dst", "]", "]", ")", "\n", "\n", "", "", "idx2node", "=", "{", "}", "\n", "for", "name", "in", "node2idx", ".", "keys", "(", ")", ":", "\n", "        ", "index", "=", "node2idx", "[", "name", "]", "\n", "idx2node", "[", "index", "]", "=", "name", "\n", "\n", "# build adjacency matrix and node distribution", "\n", "", "num_nodes", "=", "len", "(", "node2idx", ")", "\n", "prob", "=", "np", ".", "zeros", "(", "(", "num_nodes", ",", "1", ")", ")", "\n", "cost", "=", "lil_matrix", "(", "(", "num_nodes", ",", "num_nodes", ")", ")", "\n", "for", "edge", "in", "edges", ":", "\n", "        ", "src", "=", "edge", "[", "0", "]", "\n", "dst", "=", "edge", "[", "1", "]", "\n", "cost", "[", "src", ",", "dst", "]", "+=", "1", "\n", "prob", "[", "src", ",", "0", "]", "+=", "1", "\n", "prob", "[", "dst", ",", "0", "]", "+=", "1", "\n", "", "cost", "=", "csr_matrix", "(", "cost", ")", "\n", "prob", "/=", "np", ".", "sum", "(", "prob", ")", "\n", "\n", "with", "open", "(", "label_path", ")", "as", "f", ":", "\n", "        ", "labels_str", "=", "f", ".", "readlines", "(", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "# you may also want to remove whitespace characters like `\\n` at the end of each line", "\n", "labels_str", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "labels_str", "]", "\n", "labels", "=", "np", ".", "zeros", "(", "(", "num_nodes", ",", ")", ")", "\n", "for", "label", "in", "labels_str", ":", "\n", "        ", "idx", "=", "label", ".", "find", "(", "flag", ")", "\n", "if", "idx", ">", "-", "1", ":", "\n", "            ", "node", "=", "label", "[", ":", "idx", "]", "\n", "index", "=", "node2idx", "[", "node", "]", "\n", "community", "=", "int", "(", "label", "[", "(", "idx", "+", "len", "(", "flag", ")", ")", ":", "]", ")", "\n", "labels", "[", "index", "]", "=", "community", "\n", "\n", "", "", "database", "=", "{", "'cost'", ":", "cost", ",", "\n", "'prob'", ":", "prob", ",", "\n", "'idx2node'", ":", "idx2node", ",", "\n", "'label'", ":", "labels", ",", "\n", "'edges'", ":", "edges", "}", "\n", "return", "database", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.load_multilayer_edge_file": [[95, 188], ["pandas.read_csv", "pandas.read_csv.iterrows", "print", "print", "pandas.read_csv.iterrows", "len", "pandas.read_csv.iterrows", "range", "len", "edges[].append", "len", "node2idxs[].keys", "idx2nodes.append", "len", "print", "numpy.zeros", "scipy.sparse.lil_matrix", "scipy.sparse.csr_matrix", "numpy.sum", "costs.append", "probs.append", "node2idx.keys", "node2idx.keys", "graph2idx.keys", "range", "range", "range", "node2idxs[].keys", "node2idxs[].keys"], "function", ["None"], ["", "def", "load_multilayer_edge_file", "(", "file_path", ":", "str", ",", "tags", ":", "List", ")", "->", "Dict", ":", "\n", "    ", "\"\"\"\n    Load edge list stored in .csv file\n    The file should be one edge per line as follows,\n    src1, net1, dst1\n    src2, net2, dst2\n    ...\n    srcN, netN, dstN\n\n    Args:\n        file_path: the path of an edge list file.\n        tags: a list of column tags in csv files\n\n    Returns:\n        database = {'costs': a list of adjacency matrices of different graphs,\n                    'probs': a list of distributions of nodes in different graphs,\n                    'idx2nodes': a list of dictionaries mapping index to node name,\n                    'correspondence': None or a list of correspondence set}\n    \"\"\"", "\n", "pd_lib", "=", "pandas", ".", "read_csv", "(", "file_path", ")", "\n", "\n", "num_edges", "=", "0", "\n", "index", "=", "0", "\n", "node2idx", "=", "{", "}", "\n", "for", "i", ",", "row", "in", "pd_lib", ".", "iterrows", "(", ")", ":", "\n", "        ", "num_edges", "+=", "1", "\n", "src", "=", "row", "[", "tags", "[", "0", "]", "]", "\n", "dst", "=", "row", "[", "tags", "[", "2", "]", "]", "\n", "if", "src", "not", "in", "node2idx", ".", "keys", "(", ")", ":", "\n", "            ", "node2idx", "[", "src", "]", "=", "index", "\n", "index", "+=", "1", "\n", "", "if", "dst", "not", "in", "node2idx", ".", "keys", "(", ")", ":", "\n", "            ", "node2idx", "[", "dst", "]", "=", "index", "\n", "index", "+=", "1", "\n", "", "", "print", "(", "num_edges", ")", "\n", "print", "(", "len", "(", "node2idx", ")", ")", "\n", "\n", "# build graph2idx", "\n", "graph2idx", "=", "{", "}", "\n", "index", "=", "0", "\n", "for", "i", ",", "row", "in", "pd_lib", ".", "iterrows", "(", ")", ":", "\n", "        ", "net", "=", "row", "[", "tags", "[", "1", "]", "]", "\n", "if", "net", "not", "in", "graph2idx", ".", "keys", "(", ")", ":", "\n", "            ", "graph2idx", "[", "net", "]", "=", "index", "\n", "index", "+=", "1", "\n", "\n", "# build node2idxs and idx2nodes and edge lists", "\n", "", "", "num_graphs", "=", "len", "(", "graph2idx", ")", "\n", "node2idxs", "=", "[", "{", "}", "for", "_", "in", "range", "(", "num_graphs", ")", "]", "\n", "indices", "=", "[", "0", "for", "_", "in", "range", "(", "num_graphs", ")", "]", "\n", "edges", "=", "[", "[", "]", "for", "_", "in", "range", "(", "num_graphs", ")", "]", "\n", "for", "i", ",", "row", "in", "pd_lib", ".", "iterrows", "(", ")", ":", "\n", "        ", "net", "=", "row", "[", "tags", "[", "1", "]", "]", "\n", "src", "=", "row", "[", "tags", "[", "0", "]", "]", "\n", "dst", "=", "row", "[", "tags", "[", "2", "]", "]", "\n", "net_idx", "=", "graph2idx", "[", "net", "]", "\n", "if", "src", "not", "in", "node2idxs", "[", "net_idx", "]", ".", "keys", "(", ")", ":", "\n", "            ", "node2idxs", "[", "net_idx", "]", "[", "src", "]", "=", "indices", "[", "net_idx", "]", "\n", "indices", "[", "net_idx", "]", "+=", "1", "\n", "", "if", "dst", "not", "in", "node2idxs", "[", "net_idx", "]", ".", "keys", "(", ")", ":", "\n", "            ", "node2idxs", "[", "net_idx", "]", "[", "dst", "]", "=", "indices", "[", "net_idx", "]", "\n", "indices", "[", "net_idx", "]", "+=", "1", "\n", "", "edges", "[", "net_idx", "]", ".", "append", "(", "[", "node2idxs", "[", "net_idx", "]", "[", "src", "]", ",", "node2idxs", "[", "net_idx", "]", "[", "dst", "]", "]", ")", "\n", "\n", "", "costs", "=", "[", "]", "\n", "probs", "=", "[", "]", "\n", "idx2nodes", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "edges", ")", ")", ":", "\n", "        ", "idx2node", "=", "{", "}", "\n", "for", "name", "in", "node2idxs", "[", "i", "]", ".", "keys", "(", ")", ":", "\n", "            ", "idx", "=", "node2idxs", "[", "i", "]", "[", "name", "]", "\n", "idx2node", "[", "name", "]", "=", "idx", "\n", "", "idx2nodes", ".", "append", "(", "idx2node", ")", "\n", "num_nodes", "=", "len", "(", "idx2node", ")", "\n", "print", "(", "num_nodes", ")", "\n", "prob", "=", "np", ".", "zeros", "(", "(", "num_nodes", ",", "1", ")", ")", "\n", "cost", "=", "lil_matrix", "(", "(", "num_nodes", ",", "num_nodes", ")", ")", "\n", "for", "edge", "in", "edges", "[", "i", "]", ":", "\n", "            ", "src", "=", "edge", "[", "0", "]", "\n", "dst", "=", "edge", "[", "1", "]", "\n", "cost", "[", "src", ",", "dst", "]", "+=", "1", "\n", "prob", "[", "src", ",", "0", "]", "+=", "1", "\n", "prob", "[", "dst", ",", "0", "]", "+=", "1", "\n", "", "cost", "=", "csr_matrix", "(", "cost", ")", "\n", "prob", "/=", "np", ".", "sum", "(", "prob", ")", "\n", "costs", ".", "append", "(", "cost", ")", "\n", "probs", ".", "append", "(", "prob", ")", "\n", "\n", "", "database", "=", "{", "'costs'", ":", "costs", ",", "\n", "'probs'", ":", "probs", ",", "\n", "'idx2nodes'", ":", "idx2nodes", "}", "\n", "\n", "return", "database", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.load_layer_edge_file": [[190, 253], ["pandas.read_csv", "pandas.read_csv.iterrows", "node2idx.keys", "len", "numpy.zeros", "scipy.sparse.lil_matrix", "scipy.sparse.csr_matrix", "numpy.sum", "edges.append", "node2idx.keys", "node2idx.keys"], "function", ["None"], ["", "def", "load_layer_edge_file", "(", "file_path", ":", "str", ",", "tags", ":", "List", ",", "net_idx", ":", "int", ")", "->", "Tuple", "[", "csr_matrix", ",", "np", ".", "ndarray", ",", "Dict", ",", "Dict", "]", ":", "\n", "    ", "\"\"\"\n    Load edge list stored in .csv file\n    The file should be one edge per line as follows,\n    src1, net1, dst1\n    src2, net2, dst2\n    ...\n    srcN, netN, dstN\n\n    Args:\n        file_path: the path of an edge list file.\n        tags: a list of column tags in csv files\n        net_idx: the index of network\n\n    Returns:\n        database = {'costs': a list of adjacency matrices of different graphs,\n                    'probs': a list of distributions of nodes in different graphs,\n                    'idx2nodes': a list of dictionaries mapping index to node name,\n                    'correspondence': None or a list of correspondence set}\n    \"\"\"", "\n", "pd_lib", "=", "pandas", ".", "read_csv", "(", "file_path", ")", "\n", "\n", "# build node2idxs and idx2nodes and edge lists", "\n", "node2idx", "=", "{", "}", "\n", "index", "=", "0", "\n", "edges", "=", "[", "]", "\n", "for", "i", ",", "row", "in", "pd_lib", ".", "iterrows", "(", ")", ":", "\n", "        ", "net", "=", "row", "[", "tags", "[", "1", "]", "]", "\n", "src", "=", "row", "[", "tags", "[", "0", "]", "]", "\n", "dst", "=", "row", "[", "tags", "[", "2", "]", "]", "\n", "if", "net", "==", "net_idx", ":", "\n", "            ", "if", "src", "not", "in", "node2idx", ".", "keys", "(", ")", ":", "\n", "                ", "node2idx", "[", "src", "]", "=", "index", "\n", "index", "+=", "1", "\n", "", "if", "dst", "not", "in", "node2idx", ".", "keys", "(", ")", ":", "\n", "                ", "node2idx", "[", "dst", "]", "=", "index", "\n", "index", "+=", "1", "\n", "", "edges", ".", "append", "(", "[", "node2idx", "[", "src", "]", ",", "node2idx", "[", "dst", "]", "]", ")", "\n", "\n", "", "", "idx2node", "=", "{", "}", "\n", "for", "name", "in", "node2idx", ".", "keys", "(", ")", ":", "\n", "        ", "idx", "=", "node2idx", "[", "name", "]", "\n", "idx2node", "[", "idx", "]", "=", "name", "\n", "\n", "", "num_nodes", "=", "len", "(", "idx2node", ")", "\n", "prob", "=", "np", ".", "zeros", "(", "(", "num_nodes", ",", "1", ")", ")", "\n", "cost", "=", "lil_matrix", "(", "(", "num_nodes", ",", "num_nodes", ")", ")", "\n", "for", "edge", "in", "edges", ":", "\n", "        ", "src", "=", "edge", "[", "0", "]", "\n", "dst", "=", "edge", "[", "1", "]", "\n", "cost", "[", "src", ",", "dst", "]", "+=", "1", "\n", "prob", "[", "src", ",", "0", "]", "+=", "1", "\n", "prob", "[", "dst", ",", "0", "]", "+=", "1", "\n", "", "cost", "=", "csr_matrix", "(", "cost", ")", "\n", "prob", "/=", "np", ".", "sum", "(", "prob", ")", "\n", "\n", "# with open('{}.tab'.format(net_idx), 'a') as f:", "\n", "#     for edge in edges:", "\n", "#         src = 'n' + str(idx2node[edge[0]])", "\n", "#         dst = 'n' + str(idx2node[edge[1]])", "\n", "#         f.write('{}\\t{}\\n'.format(src, dst))", "\n", "# f.close()", "\n", "return", "cost", ",", "prob", ",", "idx2node", ",", "node2idx", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.load_txt_edge_file": [[255, 317], ["f.close", "node2idx.keys", "len", "numpy.zeros", "scipy.sparse.lil_matrix", "scipy.sparse.csr_matrix", "numpy.sum", "open", "f.readlines", "x.strip", "edge.find", "edges.append", "node2idx.keys", "node2idx.keys", "len"], "function", ["None"], ["", "def", "load_txt_edge_file", "(", "file_path", ":", "str", ",", "flag", ":", "str", "=", "'\\t'", ")", "->", "Tuple", "[", "csr_matrix", ",", "np", ".", "ndarray", ",", "Dict", ",", "Dict", "]", ":", "\n", "    ", "\"\"\"\n    Load edge list stored in .tab/.txt/other text-format file\n    The file should be one edge per line as follows,\n    src1 dst1\n    src2 dst2\n    ...\n    srcN dstN\n\n    Args:\n        file_path: the path of an edge list file.\n        flag: the string used to segment src and dst\n\n    Returns:\n        database = {'node2gt': a list of correspondence between each observed graph and the ground truth,\n                    'correspondence': a (num_node, num_graph) array storing all correspondences across graphs\n                    'nums': a list of #nodes in each graph,\n                    'realE': a list of real edges in each graph,\n                    'obsE': a list of observed edges in each graph}\n    \"\"\"", "\n", "# build edge list, node2idx and idx2node maps", "\n", "with", "open", "(", "file_path", ")", "as", "f", ":", "\n", "        ", "edges_str", "=", "f", ".", "readlines", "(", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "\n", "# you may also want to remove whitespace characters like `\\n` at the end of each line", "\n", "edges_str", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "edges_str", "]", "\n", "edges", "=", "[", "]", "\n", "node2idx", "=", "{", "}", "\n", "index", "=", "0", "\n", "for", "edge", "in", "edges_str", ":", "\n", "        ", "idx", "=", "edge", ".", "find", "(", "flag", ")", "\n", "if", "idx", ">", "-", "1", ":", "\n", "            ", "src", "=", "edge", "[", ":", "idx", "]", "\n", "dst", "=", "edge", "[", "(", "idx", "+", "len", "(", "flag", ")", ")", ":", "]", "\n", "if", "src", "not", "in", "node2idx", ".", "keys", "(", ")", ":", "\n", "                ", "node2idx", "[", "src", "]", "=", "index", "\n", "index", "+=", "1", "\n", "", "if", "dst", "not", "in", "node2idx", ".", "keys", "(", ")", ":", "\n", "                ", "node2idx", "[", "dst", "]", "=", "index", "\n", "index", "+=", "1", "\n", "", "edges", ".", "append", "(", "[", "node2idx", "[", "src", "]", ",", "node2idx", "[", "dst", "]", "]", ")", "\n", "\n", "", "", "idx2node", "=", "{", "}", "\n", "for", "name", "in", "node2idx", ".", "keys", "(", ")", ":", "\n", "        ", "index", "=", "node2idx", "[", "name", "]", "\n", "idx2node", "[", "index", "]", "=", "name", "\n", "\n", "# build adjacency matrix and node distribution", "\n", "", "num_nodes", "=", "len", "(", "node2idx", ")", "\n", "prob", "=", "np", ".", "zeros", "(", "(", "num_nodes", ",", "1", ")", ")", "\n", "cost", "=", "lil_matrix", "(", "(", "num_nodes", ",", "num_nodes", ")", ")", "\n", "for", "edge", "in", "edges", ":", "\n", "        ", "src", "=", "edge", "[", "0", "]", "\n", "dst", "=", "edge", "[", "1", "]", "\n", "cost", "[", "src", ",", "dst", "]", "+=", "1", "\n", "prob", "[", "src", ",", "0", "]", "+=", "1", "\n", "prob", "[", "dst", ",", "0", "]", "+=", "1", "\n", "", "cost", "=", "csr_matrix", "(", "cost", ")", "\n", "prob", "/=", "np", ".", "sum", "(", "prob", ")", "\n", "\n", "return", "cost", ",", "prob", ",", "idx2node", ",", "node2idx", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.csv2tab_edge_files": [[319, 329], ["range", "len", "pandas.read_csv", "f.close", "open", "pandas.read_csv.iterrows", "f.write"], "function", ["None"], ["", "def", "csv2tab_edge_files", "(", "path_list", ":", "List", ")", ":", "\n", "    ", "for", "n", "in", "range", "(", "len", "(", "path_list", ")", ")", ":", "\n", "        ", "pd_lib", "=", "pandas", ".", "read_csv", "(", "path_list", "[", "n", "]", ")", "\n", "\n", "with", "open", "(", "'graph_{}.tab'", ".", "format", "(", "n", ")", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "for", "i", ",", "row", "in", "pd_lib", ".", "iterrows", "(", ")", ":", "\n", "                ", "source", "=", "row", "[", "'Source'", "]", "\n", "target", "=", "row", "[", "'Target'", "]", "\n", "f", ".", "write", "(", "'{}\\t{}\\n'", ".", "format", "(", "source", ",", "target", ")", ")", "\n", "", "", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.extract_graph_info": [[331, 362], ["range", "numpy.zeros", "scipy.sparse.lil_matrix", "len", "scipy.sparse.csr_matrix", "len", "len", "len"], "function", ["None"], ["", "", "def", "extract_graph_info", "(", "graph", ":", "nx", ".", "Graph", ",", "weights", ":", "np", ".", "ndarray", "=", "None", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "csr_matrix", ",", "Dict", "]", ":", "\n", "    ", "\"\"\"\n    Plot adjacency matrix of a graph as a pdf file\n    Args:\n        graph: the graph instance generated via networkx\n        weights: the weights of edge\n\n    Returns:\n        probs: the distribution of nodes\n        adj: adjacency matrix\n        idx2node: a dictionary {key: idx, value: node name}\n    \"\"\"", "\n", "idx2node", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "graph", ".", "nodes", ")", ")", ":", "\n", "        ", "idx2node", "[", "i", "]", "=", "i", "\n", "\n", "", "probs", "=", "np", ".", "zeros", "(", "(", "len", "(", "graph", ".", "nodes", ")", ",", "1", ")", ")", "\n", "adj", "=", "lil_matrix", "(", "(", "len", "(", "graph", ".", "nodes", ")", ",", "len", "(", "graph", ".", "nodes", ")", ")", ")", "\n", "for", "edge", "in", "graph", ".", "edges", ":", "\n", "        ", "src", "=", "edge", "[", "0", "]", "\n", "dst", "=", "edge", "[", "1", "]", "\n", "if", "weights", "is", "None", ":", "\n", "            ", "adj", "[", "src", ",", "dst", "]", "+=", "1", "\n", "probs", "[", "src", ",", "0", "]", "+=", "1", "\n", "probs", "[", "dst", ",", "0", "]", "+=", "1", "\n", "", "else", ":", "\n", "            ", "adj", "[", "src", ",", "dst", "]", "+=", "weights", "[", "src", ",", "dst", "]", "\n", "probs", "[", "src", ",", "0", "]", "+=", "weights", "[", "src", ",", "dst", "]", "\n", "probs", "[", "dst", ",", "0", "]", "+=", "weights", "[", "src", ",", "dst", "]", "\n", "\n", "", "", "return", "probs", ",", "csr_matrix", "(", "adj", ")", ",", "idx2node", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.extract_graph_info_dense": [[364, 395], ["range", "numpy.zeros", "numpy.zeros", "len", "len", "len", "len"], "function", ["None"], ["", "def", "extract_graph_info_dense", "(", "graph", ":", "nx", ".", "Graph", ",", "weights", ":", "np", ".", "ndarray", "=", "None", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", ",", "Dict", "]", ":", "\n", "    ", "\"\"\"\n    Plot adjacency matrix of a graph as a pdf file\n    Args:\n        graph: the graph instance generated via networkx\n        weights: the weights of edge\n\n    Returns:\n        probs: the distribution of nodes\n        adj: adjacency matrix\n        idx2node: a dictionary {key: idx, value: node name}\n    \"\"\"", "\n", "idx2node", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "graph", ".", "nodes", ")", ")", ":", "\n", "        ", "idx2node", "[", "i", "]", "=", "i", "\n", "\n", "", "probs", "=", "np", ".", "zeros", "(", "(", "len", "(", "graph", ".", "nodes", ")", ",", "1", ")", ")", "\n", "adj", "=", "np", ".", "zeros", "(", "(", "len", "(", "graph", ".", "nodes", ")", ",", "len", "(", "graph", ".", "nodes", ")", ")", ")", "\n", "for", "edge", "in", "graph", ".", "edges", ":", "\n", "        ", "src", "=", "edge", "[", "0", "]", "\n", "dst", "=", "edge", "[", "1", "]", "\n", "if", "weights", "is", "None", ":", "\n", "            ", "adj", "[", "src", ",", "dst", "]", "+=", "1", "\n", "probs", "[", "src", ",", "0", "]", "+=", "1", "\n", "probs", "[", "dst", ",", "0", "]", "+=", "1", "\n", "", "else", ":", "\n", "            ", "adj", "[", "src", ",", "dst", "]", "+=", "weights", "[", "src", ",", "dst", "]", "\n", "probs", "[", "src", ",", "0", "]", "+=", "weights", "[", "src", ",", "dst", "]", "\n", "probs", "[", "dst", ",", "0", "]", "+=", "weights", "[", "src", ",", "dst", "]", "\n", "\n", "", "", "return", "probs", ",", "adj", ",", "idx2node", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.add_noisy_nodes": [[397, 424], ["len", "int", "len", "int", "copy.deepcopy", "range", "copy.deepcopy.add_node", "int", "random.choice", "list", "copy.deepcopy.add_edge", "range", "int", "int"], "function", ["None"], ["", "def", "add_noisy_nodes", "(", "graph", ":", "nx", ".", "graph", ",", "noisy_level", ":", "float", ")", "->", "nx", ".", "graph", ":", "\n", "    ", "\"\"\"\n        Add noisy (random) nodes in a graph\n        Args:\n            graph: the graph instance generated via networkx\n            noisy_level: the percentage of noisy nodes compared with original edges\n\n        Returns:\n            graph_noisy: the noisy graph\n        \"\"\"", "\n", "num_nodes", "=", "len", "(", "graph", ".", "nodes", ")", "\n", "num_noisy_nodes", "=", "int", "(", "noisy_level", "*", "num_nodes", ")", "\n", "\n", "num_edges", "=", "len", "(", "graph", ".", "edges", ")", "\n", "num_noisy_edges", "=", "int", "(", "noisy_level", "*", "num_edges", "/", "num_nodes", "+", "1", ")", "\n", "\n", "graph_noisy", "=", "copy", ".", "deepcopy", "(", "graph", ")", "\n", "if", "num_noisy_nodes", ">", "0", ":", "\n", "        ", "for", "i", "in", "range", "(", "num_noisy_nodes", ")", ":", "\n", "            ", "graph_noisy", ".", "add_node", "(", "int", "(", "i", "+", "num_nodes", ")", ")", "\n", "j", "=", "0", "\n", "while", "j", "<", "num_noisy_edges", ":", "\n", "                ", "src", "=", "random", ".", "choice", "(", "list", "(", "range", "(", "i", "+", "num_nodes", ")", ")", ")", "\n", "if", "(", "src", ",", "int", "(", "i", "+", "num_nodes", ")", ")", "not", "in", "graph_noisy", ".", "edges", ":", "\n", "                    ", "graph_noisy", ".", "add_edge", "(", "src", ",", "int", "(", "i", "+", "num_nodes", ")", ")", "\n", "j", "+=", "1", "\n", "", "", "", "", "return", "graph_noisy", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.add_noisy_edges": [[426, 449], ["list", "len", "int", "copy.deepcopy", "random.choice", "random.choice", "copy.deepcopy.add_edge"], "function", ["None"], ["", "def", "add_noisy_edges", "(", "graph", ":", "nx", ".", "graph", ",", "noisy_level", ":", "float", ")", "->", "nx", ".", "graph", ":", "\n", "    ", "\"\"\"\n    Add noisy (random) edges in a graph\n    Args:\n        graph: the graph instance generated via networkx\n        noisy_level: the percentage of noisy edges compared with original edges\n\n    Returns:\n        graph_noisy: the noisy graph\n    \"\"\"", "\n", "nodes", "=", "list", "(", "graph", ".", "nodes", ")", "\n", "num_edges", "=", "len", "(", "graph", ".", "edges", ")", "\n", "num_noisy_edges", "=", "int", "(", "noisy_level", "*", "num_edges", ")", "\n", "graph_noisy", "=", "copy", ".", "deepcopy", "(", "graph", ")", "\n", "if", "num_noisy_edges", ">", "0", ":", "\n", "        ", "i", "=", "0", "\n", "while", "i", "<", "num_noisy_edges", ":", "\n", "            ", "src", "=", "random", ".", "choice", "(", "nodes", ")", "\n", "dst", "=", "random", ".", "choice", "(", "nodes", ")", "\n", "if", "(", "src", ",", "dst", ")", "not", "in", "graph_noisy", ".", "edges", ":", "\n", "                ", "graph_noisy", ".", "add_edge", "(", "src", ",", "dst", ")", "\n", "i", "+=", "1", "\n", "", "", "", "return", "graph_noisy", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.sparse_mx_to_torch_sparse_tensor": [[451, 459], ["sparse_mx.tocoo().astype.tocoo().astype", "torch.from_numpy", "torch.from_numpy", "torch.Size", "torch.sparse.FloatTensor", "numpy.vstack().astype", "sparse_mx.tocoo().astype.tocoo", "numpy.vstack"], "function", ["None"], ["", "def", "sparse_mx_to_torch_sparse_tensor", "(", "sparse_mx", ")", ":", "\n", "    ", "\"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"", "\n", "sparse_mx", "=", "sparse_mx", ".", "tocoo", "(", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "indices", "=", "torch", ".", "from_numpy", "(", "\n", "np", ".", "vstack", "(", "(", "sparse_mx", ".", "row", ",", "sparse_mx", ".", "col", ")", ")", ".", "astype", "(", "np", ".", "int64", ")", ")", "\n", "values", "=", "torch", ".", "from_numpy", "(", "sparse_mx", ".", "data", ")", "\n", "shape", "=", "torch", ".", "Size", "(", "sparse_mx", ".", "shape", ")", "\n", "return", "torch", ".", "sparse", ".", "FloatTensor", "(", "indices", ",", "values", ",", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.graph_data_split": [[461, 507], ["range", "open", "pickle.load", "len", "graph_data.append", "sklearn.model_selection.train_test_split", "range", "sklearn.model_selection.train_test_split", "range", "range", "len", "train_labels.append", "len", "train_labels.append", "len", "train_labels.append"], "function", ["None"], ["", "def", "graph_data_split", "(", "pkl_path", ":", "str", ",", "split_rate", ":", "float", "=", "0.8", ",", "labeling_rate", ":", "float", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Split graph data into training and testing sets, the training sets can be unlabeled or partially labeled\n    Args:\n        pkl_path: the path of pkl file\n        split_rate: the rate to split training and testing data\n        labeling_rate: the rate of labels, in [0, 1]\n\n    Returns:\n        training data, testing data, training labels\n    \"\"\"", "\n", "with", "open", "(", "pkl_path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "graph2edge", ",", "graph2size", ",", "graph2labels", ",", "num_class", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "graph_data", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "graph2size", ")", ")", ":", "\n", "        ", "graph_data", ".", "append", "(", "[", "graph2edge", "[", "i", "]", ",", "graph2size", "[", "i", "]", ",", "graph2labels", "[", "i", "]", "]", ")", "\n", "\n", "", "if", "split_rate", "<", "1", ":", "\n", "        ", "train_graphs", ",", "test_graphs", "=", "train_test_split", "(", "graph_data", ",", "\n", "test_size", "=", "1", "-", "split_rate", ",", "\n", "random_state", "=", "42", ")", "\n", "", "else", ":", "\n", "        ", "train_graphs", "=", "graph_data", "\n", "test_graphs", "=", "[", "]", "\n", "\n", "", "if", "labeling_rate", "==", "0", ":", "\n", "        ", "train_labels", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "train_graphs", ")", ")", ":", "\n", "            ", "train_labels", ".", "append", "(", "train_graphs", "[", "i", "]", "[", "2", "]", ")", "\n", "train_graphs", "[", "i", "]", "=", "[", "train_graphs", "[", "i", "]", "[", "0", "]", ",", "train_graphs", "[", "i", "]", "[", "1", "]", "]", "\n", "", "", "else", ":", "\n", "        ", "labeled_train_graphs", ",", "unlabeled_train_graphs", "=", "train_test_split", "(", "train_graphs", ",", "\n", "test_size", "=", "1", "-", "labeling_rate", ",", "\n", "random_state", "=", "42", ")", "\n", "train_labels", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "labeled_train_graphs", ")", ")", ":", "\n", "            ", "train_labels", ".", "append", "(", "labeled_train_graphs", "[", "i", "]", "[", "2", "]", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "unlabeled_train_graphs", ")", ")", ":", "\n", "            ", "train_labels", ".", "append", "(", "unlabeled_train_graphs", "[", "i", "]", "[", "2", "]", ")", "\n", "unlabeled_train_graphs", "[", "i", "]", "=", "[", "unlabeled_train_graphs", "[", "i", "]", "[", "0", "]", ",", "unlabeled_train_graphs", "[", "i", "]", "[", "1", "]", "]", "\n", "\n", "", "train_graphs", "=", "labeled_train_graphs", "+", "unlabeled_train_graphs", "\n", "\n", "", "return", "train_graphs", ",", "test_graphs", ",", "train_labels", ",", "num_class", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.structure_data_split": [[509, 536], ["range", "sklearn.model_selection.train_test_split", "range", "range", "open", "pickle.load", "len", "graph_data.append", "len", "labels.append", "len", "labels.append"], "function", ["None"], ["", "def", "structure_data_split", "(", "pkl_path", ":", "str", ",", "split_rate", ":", "float", "=", "0.9", ")", ":", "\n", "    ", "\"\"\"\n    Split graph data into training and testing sets, the training sets can be unlabeled or partially labeled\n    Args:\n        pkl_path: the path of pkl file\n        split_rate: the rate to split training and testing data\n\n    Returns:\n        training data, testing data, training labels\n    \"\"\"", "\n", "with", "open", "(", "pkl_path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "graph2edge", ",", "graph2size", ",", "graph2labels", ",", "num_class", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "graph_data", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "graph2size", ")", ")", ":", "\n", "        ", "graph_data", ".", "append", "(", "[", "graph2edge", "[", "i", "]", ",", "graph2size", "[", "i", "]", ",", "graph2labels", "[", "i", "]", "]", ")", "\n", "\n", "", "train_graphs", ",", "test_graphs", "=", "train_test_split", "(", "graph_data", ",", "\n", "test_size", "=", "1", "-", "split_rate", ",", "\n", "random_state", "=", "42", ")", "\n", "labels", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "train_graphs", ")", ")", ":", "\n", "        ", "labels", ".", "append", "(", "train_graphs", "[", "i", "]", "[", "2", "]", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "test_graphs", ")", ")", ":", "\n", "        ", "labels", ".", "append", "(", "test_graphs", "[", "i", "]", "[", "2", "]", ")", "\n", "\n", "", "return", "train_graphs", ",", "test_graphs", ",", "labels", ",", "num_class", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.pointset_data_split": [[538, 585], ["range", "open", "pickle.load", "len", "graph_data.append", "sklearn.model_selection.train_test_split", "range", "sklearn.model_selection.train_test_split", "range", "range", "len", "train_labels.append", "len", "train_labels.append", "len", "train_labels.append"], "function", ["None"], ["", "def", "pointset_data_split", "(", "pkl_path", ":", "str", ",", "split_rate", ":", "float", "=", "0.8", ",", "labeling_rate", ":", "float", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Split point set data into training and testing sets, the training sets can be unlabeled or partially labeled\n    Args:\n        pkl_path: the path of pkl file\n        split_rate: the rate to split training and testing data\n        labeling_rate: the rate of labels, in [0, 1]\n\n    Returns:\n        training data, testing data, num_class\n    \"\"\"", "\n", "with", "open", "(", "pkl_path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "graph2edge", ",", "graph2size", ",", "graph2labels", ",", "graph2feature", ",", "num_class", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "graph_data", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "graph2size", ")", ")", ":", "\n", "        ", "graph_data", ".", "append", "(", "[", "graph2edge", "[", "i", "]", ",", "graph2size", "[", "i", "]", ",", "graph2feature", "[", "i", "]", ",", "graph2labels", "[", "i", "]", "]", ")", "\n", "\n", "", "if", "split_rate", "<", "1", ":", "\n", "        ", "train_graphs", ",", "test_graphs", "=", "train_test_split", "(", "graph_data", ",", "\n", "test_size", "=", "1", "-", "split_rate", ",", "\n", "random_state", "=", "42", ")", "\n", "", "else", ":", "\n", "        ", "train_graphs", "=", "graph_data", "\n", "test_graphs", "=", "[", "]", "\n", "\n", "", "if", "labeling_rate", "==", "0", ":", "\n", "        ", "train_labels", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "train_graphs", ")", ")", ":", "\n", "            ", "train_labels", ".", "append", "(", "train_graphs", "[", "i", "]", "[", "3", "]", ")", "\n", "train_graphs", "[", "i", "]", "=", "[", "train_graphs", "[", "i", "]", "[", "0", "]", ",", "train_graphs", "[", "i", "]", "[", "1", "]", ",", "train_graphs", "[", "i", "]", "[", "2", "]", "]", "\n", "", "", "else", ":", "\n", "        ", "labeled_train_graphs", ",", "unlabeled_train_graphs", "=", "train_test_split", "(", "train_graphs", ",", "\n", "test_size", "=", "1", "-", "labeling_rate", ",", "\n", "random_state", "=", "42", ")", "\n", "train_labels", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "labeled_train_graphs", ")", ")", ":", "\n", "            ", "train_labels", ".", "append", "(", "labeled_train_graphs", "[", "i", "]", "[", "3", "]", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "unlabeled_train_graphs", ")", ")", ":", "\n", "            ", "train_labels", ".", "append", "(", "unlabeled_train_graphs", "[", "i", "]", "[", "3", "]", ")", "\n", "unlabeled_train_graphs", "[", "i", "]", "=", "[", "unlabeled_train_graphs", "[", "i", "]", "[", "0", "]", ",", "\n", "unlabeled_train_graphs", "[", "i", "]", "[", "1", "]", ",", "\n", "unlabeled_train_graphs", "[", "i", "]", "[", "2", "]", "]", "\n", "\n", "", "train_graphs", "=", "labeled_train_graphs", "+", "unlabeled_train_graphs", "\n", "\n", "", "return", "train_graphs", ",", "test_graphs", ",", "train_labels", ",", "num_class", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.structural_data_list": [[675, 709], ["open", "pickle.load", "len", "range", "range", "len", "graph_data.append", "len", "graph_data.append"], "function", ["None"], ["", "", "def", "structural_data_list", "(", "pkl_path", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Split graph data into training and testing sets, the training sets can be unlabeled or partially labeled\n    Args:\n        pkl_path: the path of pkl file\n\n    Returns:\n        training data, testing data, training labels\n    \"\"\"", "\n", "with", "open", "(", "pkl_path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "data", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "if", "len", "(", "data", ")", "==", "5", ":", "\n", "        ", "graph2edge", "=", "data", "[", "0", "]", "\n", "graph2size", "=", "data", "[", "1", "]", "\n", "graph2labels", "=", "data", "[", "2", "]", "\n", "graph2feature", "=", "data", "[", "3", "]", "\n", "num_class", "=", "data", "[", "4", "]", "\n", "\n", "graph_data", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "graph2size", ")", ")", ":", "\n", "            ", "graph_data", ".", "append", "(", "[", "graph2edge", "[", "i", "]", ",", "graph2size", "[", "i", "]", ",", "graph2feature", "[", "i", "]", ",", "graph2labels", "[", "i", "]", "]", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "graph2edge", "=", "data", "[", "0", "]", "\n", "graph2size", "=", "data", "[", "1", "]", "\n", "graph2labels", "=", "data", "[", "2", "]", "\n", "num_class", "=", "data", "[", "3", "]", "\n", "\n", "graph_data", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "graph2size", ")", ")", ":", "\n", "            ", "graph_data", ".", "append", "(", "[", "graph2edge", "[", "i", "]", ",", "graph2size", "[", "i", "]", ",", "graph2labels", "[", "i", "]", "]", ")", "\n", "\n", "", "", "return", "graph_data", ",", "num_class", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.structural_data_split": [[711, 733], ["sklearn.model_selection.train_test_split", "range", "range", "len", "train_labels.append", "len", "test_labels.append"], "function", ["None"], ["", "def", "structural_data_split", "(", "graph_data", ":", "list", ",", "split_rate", ":", "float", "=", "0.9", ")", ":", "\n", "    ", "\"\"\"\n    Split graph data into training and testing sets, the training sets can be unlabeled or partially labeled\n    Args:\n        graph_data: a list of samples\n        split_rate: the rate to split training and testing data\n\n    Returns:\n        training data, testing data, training labels\n    \"\"\"", "\n", "\n", "train_graphs", ",", "test_graphs", "=", "train_test_split", "(", "graph_data", ",", "\n", "test_size", "=", "1", "-", "split_rate", ",", "\n", "random_state", "=", "42", ")", "\n", "train_labels", "=", "[", "]", "\n", "test_labels", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "train_graphs", ")", ")", ":", "\n", "        ", "train_labels", ".", "append", "(", "train_graphs", "[", "i", "]", "[", "3", "]", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "test_graphs", ")", ")", ":", "\n", "        ", "test_labels", ".", "append", "(", "test_graphs", "[", "i", "]", "[", "3", "]", ")", "\n", "\n", "", "return", "train_graphs", ",", "test_graphs", ",", "train_labels", ",", "test_labels", "\n", "", ""]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.FGWF.__init__": [[27, 123], ["torch.Module.__init__", "len", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "range", "prior.__len__", "list", "random.shuffle", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "range", "print", "print", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "FusedGromovWassersteinFactorization.FGWF.ps.append", "FusedGromovWassersteinFactorization.FGWF.atoms.append", "FusedGromovWassersteinFactorization.FGWF.embeddings.append", "range", "prior.__getitem__", "graph.size", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "FusedGromovWassersteinFactorization.FGWF.ps.append", "FusedGromovWassersteinFactorization.FGWF.atoms.append", "FusedGromovWassersteinFactorization.FGWF.embeddings.append", "base_label.append", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.FGWF.__init__", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.StructuralDataSampler.__len__", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.StructuralDataSampler.__getitem__"], ["def", "__init__", "(", "self", ",", "\n", "num_samples", ":", "int", ",", "\n", "num_classes", ":", "int", ",", "\n", "size_atoms", ":", "List", ",", "\n", "dim_embedding", ":", "int", "=", "1", ",", "\n", "ot_method", ":", "str", "=", "'ppa'", ",", "\n", "gamma", ":", "float", "=", "1e-1", ",", "\n", "gwb_layers", ":", "int", "=", "5", ",", "\n", "ot_layers", ":", "int", "=", "5", ",", "\n", "prior", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            num_samples: the number of samples\n            size_atoms: a list, its length is the number of atoms, each element is the size of the corresponding atom\n            dim_embedding: the dimension of embedding\n            ot_method: ppa or b-admm\n            gamma: the weight of Bregman divergence term\n            gwb_layers: the number of gwb layers in each gwf module\n            ot_layers: the number of ot layers in each gwb module\n        \"\"\"", "\n", "super", "(", "FGWF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_samples", "=", "num_samples", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "size_atoms", "=", "size_atoms", "\n", "self", ".", "num_atoms", "=", "len", "(", "self", ".", "size_atoms", ")", "\n", "self", ".", "dim_embedding", "=", "dim_embedding", "\n", "self", ".", "ot_method", "=", "ot_method", "\n", "self", ".", "gwb_layers", "=", "gwb_layers", "\n", "self", ".", "ot_layers", "=", "ot_layers", "\n", "self", ".", "gamma", "=", "gamma", "\n", "\n", "# weights of atoms", "\n", "self", ".", "weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "self", ".", "num_atoms", ",", "self", ".", "num_samples", ")", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "0", ")", "\n", "\n", "# basis and their node distribution", "\n", "if", "prior", "is", "None", ":", "\n", "            ", "self", ".", "ps", "=", "[", "]", "\n", "self", ".", "atoms", "=", "nn", ".", "ParameterList", "(", ")", "\n", "self", ".", "embeddings", "=", "nn", ".", "ParameterList", "(", ")", "\n", "for", "k", "in", "range", "(", "self", ".", "num_atoms", ")", ":", "\n", "                ", "atom", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "self", ".", "size_atoms", "[", "k", "]", ",", "self", ".", "size_atoms", "[", "k", "]", ")", ")", "\n", "embedding", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "self", ".", "size_atoms", "[", "k", "]", ",", "self", ".", "dim_embedding", ")", "/", "self", ".", "dim_embedding", ")", "\n", "dist", "=", "torch", ".", "ones", "(", "self", ".", "size_atoms", "[", "k", "]", ",", "1", ")", "/", "self", ".", "size_atoms", "[", "k", "]", "# .type(torch.FloatTensor)", "\n", "self", ".", "ps", ".", "append", "(", "dist", ")", "\n", "self", ".", "atoms", ".", "append", "(", "atom", ")", "\n", "self", ".", "embeddings", ".", "append", "(", "embedding", ")", "\n", "", "", "else", ":", "\n", "# num_atoms_per_class = int(self.num_atoms / self.num_classes)", "\n", "# counts = np.zeros((self.num_classes,))", "\n", "# self.ps = []", "\n", "# self.atoms = []", "\n", "# self.size_atoms = []", "\n", "# self.embeddings = []", "\n", "# base_label = []", "\n", "# for n in range(prior.__len__()):", "\n", "#     data = prior.__getitem__(n)", "\n", "#     graph = data[0]", "\n", "#     prob = data[1]", "\n", "#     emb = data[2]", "\n", "#     gt = int(data[3][0])", "\n", "#     if counts[gt] < num_atoms_per_class:", "\n", "#         self.size_atoms.append(graph.size(0))", "\n", "#         atom = nn.Parameter(graph)", "\n", "#         embedding = nn.Parameter(emb)", "\n", "#         self.ps.append(prob)", "\n", "#         self.atoms.append(atom)", "\n", "#         self.embeddings.append(embedding)", "\n", "#         base_label.append(gt)", "\n", "#         counts[gt] += 1", "\n", "\n", "            ", "num_samples", "=", "prior", ".", "__len__", "(", ")", "\n", "index_samples", "=", "list", "(", "range", "(", "num_samples", ")", ")", "\n", "random", ".", "shuffle", "(", "index_samples", ")", "\n", "self", ".", "ps", "=", "[", "]", "\n", "self", ".", "atoms", "=", "nn", ".", "ParameterList", "(", ")", "\n", "self", ".", "embeddings", "=", "nn", ".", "ParameterList", "(", ")", "\n", "base_label", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "self", ".", "num_atoms", ")", ":", "\n", "                ", "idx", "=", "index_samples", "[", "k", "]", "\n", "data", "=", "prior", ".", "__getitem__", "(", "idx", ")", "\n", "graph", "=", "data", "[", "0", "]", "\n", "prob", "=", "data", "[", "1", "]", "\n", "emb", "=", "data", "[", "2", "]", "\n", "gt", "=", "data", "[", "3", "]", "\n", "self", ".", "size_atoms", "[", "k", "]", "=", "graph", ".", "size", "(", "0", ")", "\n", "atom", "=", "nn", ".", "Parameter", "(", "graph", ")", "\n", "embedding", "=", "nn", ".", "Parameter", "(", "emb", ")", "\n", "self", ".", "ps", ".", "append", "(", "prob", ")", "\n", "self", ".", "atoms", ".", "append", "(", "atom", ")", "\n", "self", ".", "embeddings", ".", "append", "(", "embedding", ")", "\n", "base_label", ".", "append", "(", "gt", "[", "0", "]", ")", "\n", "\n", "", "print", "(", "self", ".", "size_atoms", ")", "\n", "print", "(", "base_label", ")", "\n", "", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.FGWF.output_weights": [[124, 129], ["FusedGromovWassersteinFactorization.FGWF.softmax", "FusedGromovWassersteinFactorization.FGWF.softmax"], "methods", ["None"], ["", "def", "output_weights", "(", "self", ",", "idx", ":", "int", "=", "None", ")", ":", "\n", "        ", "if", "idx", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "softmax", "(", "self", ".", "weights", "[", ":", ",", "idx", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "softmax", "(", "self", ".", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.FGWF.output_atoms": [[130, 135], ["FusedGromovWassersteinFactorization.FGWF.sigmoid", "FusedGromovWassersteinFactorization.FGWF.sigmoid", "range", "len"], "methods", ["None"], ["", "", "def", "output_atoms", "(", "self", ",", "idx", ":", "int", "=", "None", ")", ":", "\n", "        ", "if", "idx", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "sigmoid", "(", "self", ".", "atoms", "[", "idx", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "[", "self", ".", "sigmoid", "(", "self", ".", "atoms", "[", "idx", "]", ")", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "atoms", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.FGWF.fgwb": [[136, 167], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "pb.size", "pb.size", "pb.size", "FusedGromovWassersteinFactorization.FGWF.output_atoms", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t"], "methods", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.FGWF.output_atoms"], ["", "", "def", "fgwb", "(", "self", ",", "\n", "pb", ":", "torch", ".", "Tensor", ",", "\n", "trans", ":", "List", ",", "\n", "weights", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Solve GW Barycetner problem\n        barycenter = argmin_{B} sum_k w[k] * d_gw(atom[k], B) via proximal point-based alternating optimization:\n\n        step 1: Given current barycenter, for k = 1:K, we calculate trans[k] by the OT-PPA layer.\n        step 2: Given new trans, we update barycenter by\n            barycenter = sum_k trans[k] * atom[k] * trans[k]^T / (pb * pb^T)\n\n        Args:\n            pb: (nb, 1) vector (torch tensor), the empirical distribution of the nodes/samples of the barycenter\n            trans: a dictionary {key: index of atoms, value: the (ns, nb) initial optimal transport}\n            weights: (K,) vector (torch tensor), representing the weights of the atoms\n\n        Returns:\n            barycenter: (nb, nb) matrix (torch tensor) representing the updated GW barycenter\n        \"\"\"", "\n", "tmp1", "=", "pb", "@", "torch", ".", "t", "(", "pb", ")", "\n", "tmp2", "=", "pb", "@", "torch", ".", "ones", "(", "1", ",", "self", ".", "dim_embedding", ")", "\n", "graph", "=", "torch", ".", "zeros", "(", "pb", ".", "size", "(", "0", ")", ",", "pb", ".", "size", "(", "0", ")", ")", "\n", "embedding", "=", "torch", ".", "zeros", "(", "pb", ".", "size", "(", "0", ")", ",", "self", ".", "dim_embedding", ")", "\n", "for", "k", "in", "range", "(", "self", ".", "num_atoms", ")", ":", "\n", "            ", "graph_k", "=", "self", ".", "output_atoms", "(", "k", ")", "\n", "graph", "+=", "weights", "[", "k", "]", "*", "(", "torch", ".", "t", "(", "trans", "[", "k", "]", ")", "@", "graph_k", "@", "trans", "[", "k", "]", ")", "\n", "embedding", "+=", "weights", "[", "k", "]", "*", "(", "torch", ".", "t", "(", "trans", "[", "k", "]", ")", "@", "self", ".", "embeddings", "[", "k", "]", ")", "\n", "", "graph", "=", "graph", "/", "tmp1", "\n", "embedding", "=", "embedding", "/", "tmp2", "\n", "return", "graph", ",", "embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.FGWF.forward": [[168, 195], ["FusedGromovWassersteinFactorization.FGWF.softmax", "FusedGromovWassersteinFactorization.FGWF.fgwb", "FusedGromovWassersteinFactorization.fgwd"], "methods", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.FGWF.fgwb", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.fgwd"], ["", "def", "forward", "(", "self", ",", "graph", ":", "torch", ".", "Tensor", ",", "prob", ":", "torch", ".", "Tensor", ",", "embedding", ":", "torch", ".", "Tensor", ",", "\n", "index", ":", "int", ",", "trans", ":", "List", ",", "tran", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        For \"n\" unknown samples, given their disimilarity/adjacency matrix \"cost\" and distribution \"p\", we calculate\n        \"d_gw(barycenter(atoms, weights), cost)\" approximately.\n\n        Args:\n            graph: (n, n) matrix (torch.Tensor), representing disimilarity/adjacency matrix\n            prob: (n, 1) vector (torch.Tensor), the empirical distribution of the nodes/samples in \"graph\"\n            embedding: (n, d) matrix (torch.Tensor)\n            index: the index of the \"cost\" in the dataset\n            trans: a list of (ns, nb) OT matrices\n            tran: a (n, nb) OT matrix\n\n        Returns:\n            d_gw: the value of loss function\n            barycenter: the proposed GW barycenter\n            tran0: the optimal transport between barycenter and cost\n            trans: the optimal transports between barycenter and atoms\n            weights: the weights of atoms\n        \"\"\"", "\n", "# variables", "\n", "weights", "=", "self", ".", "softmax", "(", "self", ".", "weights", "[", ":", ",", "index", "]", ")", "\n", "graph_b", ",", "embedding_b", "=", "self", ".", "fgwb", "(", "prob", ",", "trans", ",", "weights", ")", "\n", "d_fgw", "=", "fgwd", "(", "graph", ",", "embedding", ",", "prob", ",", "graph_b", ",", "embedding_b", ",", "prob", ",", "tran", ")", "\n", "\n", "return", "d_fgw", ",", "self", ".", "weights", "[", ":", ",", "index", "]", ",", "graph_b", ",", "embedding_b", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.fgwd": [[16, 20], ["methods.AlgOT.cost_mat"], "function", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.AlgOT.cost_mat"], ["def", "fgwd", "(", "graph1", ",", "embedding1", ",", "prob1", ",", "\n", "graph2", ",", "embedding2", ",", "prob2", ",", "tran", ")", ":", "\n", "    ", "cost", "=", "cost_mat", "(", "graph1", ",", "graph2", ",", "prob1", ",", "prob2", ",", "tran", ",", "embedding1", ",", "embedding2", ")", "\n", "return", "(", "cost", "*", "tran", ")", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.train_usl": [[197, 366], ["model.train", "methods.DataIO.StructuralDataSampler", "methods.DataIO.StructuralDataSampler.__len__", "list", "list", "float", "range", "torch.Adam", "model.parameters", "torch.Adam", "range", "range", "time.time", "optim.Adam.zero_grad", "print", "model.parameters", "random.shuffle", "methods.DataIO.StructuralDataSampler.__getitem__", "range", "torch.diag", "torch.diag", "torch.diag", "model", "copy.deepcopy", "FusedGromovWassersteinFactorization.tsne_weights", "list", "numpy.asarray", "int", "matplotlib.figure", "range", "matplotlib.legend", "print", "matplotlib.savefig", "matplotlib.close", "methods.AlgOT.ot_fgw", "trans.append", "random.shuffle", "model.output_atoms", "model.output_atoms", "methods.AlgOT.ot_fgw", "FusedGromovWassersteinFactorization.fgwd", "loss_total.backward", "optim.Adam.step", "print", "time.time", "optim.Adam.zero_grad", "range", "np.asarray.append", "matplotlib.scatter", "list", "model.output_atoms", "numpy.max", "model.parameters", "time.time"], "function", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.StructuralDataSampler.__len__", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.StructuralDataSampler.__getitem__", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.tsne_weights", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.AlgOT.ot_fgw", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.FGWF.output_atoms", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.FGWF.output_atoms", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.AlgOT.ot_fgw", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.fgwd", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.FGWF.output_atoms"], ["", "", "def", "train_usl", "(", "model", ",", "\n", "database", ",", "\n", "size_batch", ":", "int", "=", "16", ",", "\n", "epochs", ":", "int", "=", "10", ",", "\n", "lr", ":", "float", "=", "1e-1", ",", "\n", "weight_decay", ":", "float", "=", "0", ",", "\n", "shuffle_data", ":", "bool", "=", "True", ",", "\n", "zeta", ":", "float", "=", "None", ",", "\n", "mode", ":", "str", "=", "'fit'", ",", "\n", "visualize_prefix", ":", "str", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    training a FGWF model\n    Args:\n        model: a FGWF model\n        database: a list of data, each element is a list representing [cost, distriubtion, feature, label]\n        size_batch: the size of batch, deciding the frequency of backpropagation\n        epochs: the number epochs\n        lr: learning rate\n        weight_decay: the weight of the l2-norm regularization of parameters\n        shuffle_data: whether shuffle data in each epoch\n        zeta: the weight of the regularizer enhancing the diversity of atoms\n        mode: fit or transform\n        visualize_prefix: display learning result after each epoch or not\n    \"\"\"", "\n", "if", "mode", "==", "'fit'", ":", "\n", "        ", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "weight_decay", "=", "weight_decay", ")", "\n", "", "else", ":", "\n", "        ", "n", "=", "0", "\n", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "n", ">", "0", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "n", "+=", "1", "\n", "\n", "# only update partial model's parameters", "\n", "", "optimizer", "=", "optim", ".", "Adam", "(", "[", "list", "(", "model", ".", "parameters", "(", ")", ")", "[", "0", "]", "]", ",", "lr", "=", "lr", ",", "weight_decay", "=", "weight_decay", ")", "\n", "", "model", ".", "train", "(", ")", "\n", "\n", "data_sampler", "=", "StructuralDataSampler", "(", "database", ")", "\n", "num_samples", "=", "data_sampler", ".", "__len__", "(", ")", "\n", "index_samples", "=", "list", "(", "range", "(", "num_samples", ")", ")", "\n", "index_atoms", "=", "list", "(", "range", "(", "model", ".", "num_atoms", ")", ")", "\n", "\n", "best_loss", "=", "float", "(", "\"Inf\"", ")", "\n", "best_model", "=", "None", "\n", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "        ", "counts", "=", "0", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "loss_epoch", "=", "0", "\n", "loss_total", "=", "0", "\n", "d_fgw_total", "=", "0", "\n", "reg_total", "=", "0", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "shuffle_data", ":", "\n", "            ", "random", ".", "shuffle", "(", "index_samples", ")", "\n", "\n", "", "for", "idx", "in", "index_samples", ":", "\n", "            ", "data", "=", "data_sampler", ".", "__getitem__", "(", "idx", ")", "\n", "graph", "=", "data", "[", "0", "]", "\n", "prob", "=", "data", "[", "1", "]", "\n", "emb", "=", "data", "[", "2", "]", "\n", "\n", "# Envelop Theorem", "\n", "# feed-forward computation of barycenter B({Ck}, w) and its transports {Trans_k}", "\n", "trans", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "model", ".", "num_atoms", ")", ":", "\n", "                ", "graph_k", "=", "model", ".", "output_atoms", "(", "k", ")", ".", "data", "\n", "emb_k", "=", "model", ".", "embeddings", "[", "k", "]", ".", "data", "\n", "_", ",", "tran_k", "=", "ot_fgw", "(", "graph_k", ",", "graph", ",", "model", ".", "ps", "[", "k", "]", ",", "prob", ",", "\n", "model", ".", "ot_method", ",", "model", ".", "gamma", ",", "model", ".", "ot_layers", ",", "\n", "emb_k", ",", "emb", ")", "\n", "trans", ".", "append", "(", "tran_k", ")", "\n", "", "tran", "=", "torch", ".", "diag", "(", "prob", "[", ":", ",", "0", "]", ")", "\n", "\n", "# trans = []", "\n", "# graph_b = graph", "\n", "# emb_b = emb", "\n", "# weights = model.output_weights(idx).data", "\n", "# tmp1 = prob @ torch.t(prob)", "\n", "# tmp2 = prob @ torch.ones(1, model.dim_embedding)", "\n", "# for n in range(model.gwb_layers):", "\n", "#     graph_b_tmp = 0", "\n", "#     emb_b_tmp = 0", "\n", "#     trans = []", "\n", "#     for k in range(model.num_atoms):", "\n", "#         graph_k = model.output_atoms(k).data", "\n", "#         emb_k = model.embeddings[k].data", "\n", "#         _, tran_k = ot_fgw(graph_k, graph_b, model.ps[k], prob,", "\n", "#                            model.ot_method, model.gamma, model.ot_layers,", "\n", "#                            emb_k, emb_b)", "\n", "#         trans.append(tran_k)", "\n", "#         graph_b_tmp += weights[k] * (torch.t(tran_k) @ graph_k @ tran_k)", "\n", "#         emb_b_tmp += weights[k] * (torch.t(tran_k) @ emb_k)", "\n", "#     graph_b = graph_b_tmp / tmp1", "\n", "#     emb_b = emb_b_tmp / tmp2", "\n", "\n", "# _, tran = ot_fgw(graph, graph_b, prob, prob,", "\n", "#                  model.ot_method, model.gamma, model.ot_layers,", "\n", "#                  emb, emb_b)", "\n", "\n", "d_fgw", ",", "_", ",", "_", ",", "_", "=", "model", "(", "graph", ",", "prob", ",", "emb", ",", "idx", ",", "trans", ",", "tran", ")", "\n", "d_fgw_total", "+=", "d_fgw", "\n", "loss_total", "+=", "d_fgw", "\n", "\n", "if", "zeta", "is", "not", "None", "and", "mode", "==", "'fit'", ":", "\n", "                ", "random", ".", "shuffle", "(", "index_atoms", ")", "\n", "graph1", "=", "model", ".", "output_atoms", "(", "index_atoms", "[", "0", "]", ")", "\n", "emb1", "=", "model", ".", "embeddings", "[", "index_atoms", "[", "0", "]", "]", "\n", "p1", "=", "model", ".", "ps", "[", "index_atoms", "[", "0", "]", "]", "\n", "\n", "graph2", "=", "model", ".", "output_atoms", "(", "index_atoms", "[", "1", "]", ")", "\n", "emb2", "=", "model", ".", "embeddings", "[", "index_atoms", "[", "1", "]", "]", "\n", "p2", "=", "model", ".", "ps", "[", "index_atoms", "[", "1", "]", "]", "\n", "\n", "_", ",", "tran12", "=", "ot_fgw", "(", "graph1", ".", "data", ",", "graph2", ".", "data", ",", "p1", ",", "p2", ",", "\n", "model", ".", "ot_method", ",", "model", ".", "gamma", ",", "model", ".", "ot_layers", ",", "\n", "emb1", ".", "data", ",", "emb2", ".", "data", ")", "\n", "reg", "=", "fgwd", "(", "graph1", ",", "emb1", ",", "p1", ",", "graph2", ",", "emb2", ",", "p2", ",", "tran12", ")", "\n", "\n", "reg_total", "+=", "zeta", "*", "reg", "\n", "loss_total", "-=", "zeta", "*", "reg", "\n", "\n", "", "counts", "+=", "1", "\n", "if", "counts", "%", "size_batch", "==", "0", "or", "counts", "==", "num_samples", ":", "\n", "                ", "if", "counts", "%", "size_batch", "==", "0", ":", "\n", "                    ", "num", "=", "size_batch", "\n", "", "else", ":", "\n", "                    ", "num", "=", "counts", "%", "size_batch", "\n", "", "loss_epoch", "+=", "loss_total", "\n", "loss_total", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "print", "(", "'-- {}/{} [{:.1f}%], loss={:.4f}, dgw={:.4f}, reg={:.4f}, time={:.2f}s.'", ".", "format", "(", "\n", "counts", ",", "num_samples", ",", "counts", "/", "num_samples", "*", "100.0", ",", "\n", "loss_total", "/", "num", ",", "d_fgw_total", "/", "num", ",", "reg_total", "/", "num", ",", "time", ".", "time", "(", ")", "-", "t_start", ")", ")", "\n", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "loss_total", "=", "0", "\n", "d_fgw_total", "=", "0", "\n", "reg_total", "=", "0", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "", "if", "best_loss", ">", "loss_epoch", ".", "data", "/", "num_samples", ":", "\n", "            ", "best_model", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "best_loss", "=", "loss_epoch", ".", "data", "/", "num_samples", "\n", "\n", "", "print", "(", "'{}: Epoch {}/{}, loss = {:.4f}, best loss = {:.4f}'", ".", "format", "(", "\n", "mode", ",", "epoch", "+", "1", ",", "epochs", ",", "loss_epoch", "/", "num_samples", ",", "best_loss", ")", ")", "\n", "\n", "if", "visualize_prefix", "is", "not", "None", ":", "\n", "            ", "embeddings", "=", "tsne_weights", "(", "model", ")", "\n", "index", "=", "list", "(", "range", "(", "num_samples", ")", ")", "\n", "labels", "=", "[", "]", "\n", "for", "idx", "in", "index", ":", "\n", "                ", "labels", ".", "append", "(", "data_sampler", ".", "data", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "labels", "=", "np", ".", "asarray", "(", "labels", ")", "\n", "num_classes", "=", "int", "(", "np", ".", "max", "(", "labels", ")", "+", "1", ")", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "6", ",", "6", ")", ")", "\n", "for", "i", "in", "range", "(", "num_classes", ")", ":", "\n", "                ", "plt", ".", "scatter", "(", "embeddings", "[", "labels", "==", "i", ",", "0", "]", ",", "\n", "embeddings", "[", "labels", "==", "i", ",", "1", "]", ",", "\n", "s", "=", "4", ",", "\n", "label", "=", "'class {}'", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "", "plt", ".", "legend", "(", ")", "\n", "print", "(", "'{}_usl_tsne_{}_{}.pdf'", ".", "format", "(", "visualize_prefix", ",", "mode", ",", "epoch", "+", "1", ")", ")", "\n", "plt", ".", "savefig", "(", "'{}_usl_tsne_{}_{}.pdf'", ".", "format", "(", "visualize_prefix", ",", "mode", ",", "epoch", "+", "1", ")", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", "", "return", "best_model", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.train_ssl": [[368, 557], ["methods.DataIO.structural_data_split", "numpy.asarray", "int", "torch.Linear", "torch.CrossEntropyLoss", "methods.DataIO.StructuralDataSampler", "methods.DataIO.StructuralDataSampler", "len", "list", "list", "range", "torch.Adam", "model.parameters", "torch.Adam", "range", "range", "model.train", "nn.Linear.train", "time.time", "optim.Adam.zero_grad", "nn.Linear.eval", "model.eval", "range", "len", "print", "numpy.max", "random.shuffle", "range", "torch.diag", "torch.diag", "torch.diag", "model", "len", "methods.DataIO.StructuralDataSampler.__getitem__", "nn.Linear.", "torch.max", "torch.max", "torch.max", "copy.deepcopy", "copy.deepcopy", "FusedGromovWassersteinFactorization.tsne_weights", "matplotlib.figure", "range", "matplotlib.legend", "matplotlib.title", "print", "matplotlib.savefig", "matplotlib.close", "list", "list", "list", "len", "methods.DataIO.StructuralDataSampler.__getitem__", "methods.DataIO.StructuralDataSampler.__getitem__", "methods.AlgOT.ot_fgw", "trans.append", "random.shuffle", "model.output_atoms", "model.output_atoms", "methods.AlgOT.ot_fgw", "FusedGromovWassersteinFactorization.fgwd", "len", "nn.CrossEntropyLoss.", "loss_total.backward", "optim.Adam.step", "print", "time.time", "optim.Adam.zero_grad", "weights.unsqueeze", "matplotlib.scatter", "matplotlib.scatter", "model.parameters", "nn.Linear.parameters", "nn.Linear.parameters", "model.output_atoms", "nn.Linear.", "len", "len", "len", "len", "list", "len", "weights.unsqueeze", "len", "len", "model.parameters", "time.time", "len", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.structural_data_split", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.StructuralDataSampler.__getitem__", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.tsne_weights", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.StructuralDataSampler.__getitem__", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.DataIO.StructuralDataSampler.__getitem__", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.AlgOT.ot_fgw", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.FGWF.output_atoms", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.FGWF.output_atoms", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.AlgOT.ot_fgw", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.fgwd", "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.FGWF.output_atoms"], ["", "def", "train_ssl", "(", "model", ",", "\n", "database", ":", "list", ",", "\n", "size_batch", ":", "int", "=", "16", ",", "\n", "epochs", ":", "int", "=", "10", ",", "\n", "lr", ":", "float", "=", "1e-1", ",", "\n", "weight_decay", ":", "float", "=", "0", ",", "\n", "shuffle_data", ":", "bool", "=", "True", ",", "\n", "zeta", ":", "float", "=", "None", ",", "\n", "mode", ":", "str", "=", "'fit'", ",", "\n", "ssl", ":", "float", "=", "0.1", ",", "\n", "visualize_prefix", ":", "str", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    training a FGWF model\n    Args:\n        model: a FGWF model\n        database: a list of data, each element is a list representing [cost, distriubtion, feature, label]\n        size_batch: the size of batch, deciding the frequency of backpropagation\n        epochs: the number epochs\n        lr: learning rate\n        weight_decay: the weight of the l2-norm regularization of parameters\n        shuffle_data: whether shuffle data in each epoch\n        zeta: the weight of the regularizer enhancing the diversity of atoms\n        mode: fit or transform\n        ssl: the percentage of labeled samples\n        visualize_prefix: display learning result after each epoch or not\n    \"\"\"", "\n", "c", "=", "[", "'blue'", ",", "'orange'", ",", "'red'", ",", "'green'", ",", "'yellow'", ",", "'grey'", "]", "\n", "train_graphs", ",", "test_graphs", ",", "train_labels", ",", "test_labels", "=", "structural_data_split", "(", "database", ",", "split_rate", "=", "ssl", ")", "\n", "labels", "=", "train_labels", "+", "test_labels", "\n", "labels", "=", "np", ".", "asarray", "(", "labels", ")", "\n", "num_classes", "=", "int", "(", "np", ".", "max", "(", "labels", ")", "+", "1", ")", "\n", "\n", "predictor", "=", "nn", ".", "Linear", "(", "model", ".", "num_atoms", ",", "num_classes", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "if", "mode", "==", "'fit'", ":", "\n", "        ", "optimizer", "=", "optim", ".", "Adam", "(", "list", "(", "model", ".", "parameters", "(", ")", ")", "+", "list", "(", "predictor", ".", "parameters", "(", ")", ")", ",", "\n", "lr", "=", "lr", ",", "weight_decay", "=", "weight_decay", ")", "\n", "", "else", ":", "\n", "        ", "n", "=", "0", "\n", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "n", ">", "0", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "n", "+=", "1", "\n", "\n", "# only update partial model's parameters", "\n", "", "optimizer", "=", "optim", ".", "Adam", "(", "[", "list", "(", "model", ".", "parameters", "(", ")", ")", "[", "0", "]", "]", "+", "list", "(", "predictor", ".", "parameters", "(", ")", ")", ",", "\n", "lr", "=", "lr", ",", "weight_decay", "=", "weight_decay", ")", "\n", "\n", "", "train_sampler", "=", "StructuralDataSampler", "(", "train_graphs", ")", "\n", "test_sampler", "=", "StructuralDataSampler", "(", "test_graphs", ")", "\n", "\n", "num_samples", "=", "len", "(", "database", ")", "\n", "index_samples", "=", "list", "(", "range", "(", "num_samples", ")", ")", "\n", "index_atoms", "=", "list", "(", "range", "(", "model", ".", "num_atoms", ")", ")", "\n", "\n", "best_acc", "=", "0", "\n", "best_model", "=", "None", "\n", "best_predictor", "=", "None", "\n", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "        ", "model", ".", "train", "(", ")", "\n", "predictor", ".", "train", "(", ")", "\n", "\n", "counts", "=", "0", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "loss_epoch", "=", "0", "\n", "loss_total", "=", "0", "\n", "d_fgw_total", "=", "0", "\n", "reg_total", "=", "0", "\n", "lle_total", "=", "0", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "shuffle_data", ":", "\n", "            ", "random", ".", "shuffle", "(", "index_samples", ")", "\n", "\n", "", "for", "idx", "in", "index_samples", ":", "\n", "            ", "if", "idx", "<", "len", "(", "train_graphs", ")", ":", "\n", "                ", "data", "=", "train_sampler", ".", "__getitem__", "(", "idx", ")", "\n", "", "else", ":", "\n", "                ", "data", "=", "test_sampler", ".", "__getitem__", "(", "idx", "-", "len", "(", "train_graphs", ")", ")", "\n", "", "graph", "=", "data", "[", "0", "]", "\n", "prob", "=", "data", "[", "1", "]", "\n", "emb", "=", "data", "[", "2", "]", "\n", "label", "=", "data", "[", "3", "]", "\n", "\n", "# Envelop Theorem", "\n", "# feed-forward computation of barycenter B({Ck}, w) and its transports {Trans_k}", "\n", "trans", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "model", ".", "num_atoms", ")", ":", "\n", "                ", "graph_k", "=", "model", ".", "output_atoms", "(", "k", ")", ".", "data", "\n", "emb_k", "=", "model", ".", "embeddings", "[", "k", "]", ".", "data", "\n", "_", ",", "tran_k", "=", "ot_fgw", "(", "graph_k", ",", "graph", ",", "model", ".", "ps", "[", "k", "]", ",", "prob", ",", "\n", "model", ".", "ot_method", ",", "model", ".", "gamma", ",", "model", ".", "ot_layers", ",", "\n", "emb_k", ",", "emb", ")", "\n", "trans", ".", "append", "(", "tran_k", ")", "\n", "", "tran", "=", "torch", ".", "diag", "(", "prob", "[", ":", ",", "0", "]", ")", "\n", "\n", "d_fgw", ",", "weights", ",", "_", ",", "_", "=", "model", "(", "graph", ",", "prob", ",", "emb", ",", "idx", ",", "trans", ",", "tran", ")", "\n", "d_fgw_total", "+=", "d_fgw", "\n", "loss_total", "+=", "d_fgw", "\n", "\n", "if", "zeta", "is", "not", "None", "and", "mode", "==", "'fit'", ":", "\n", "                ", "random", ".", "shuffle", "(", "index_atoms", ")", "\n", "graph1", "=", "model", ".", "output_atoms", "(", "index_atoms", "[", "0", "]", ")", "\n", "emb1", "=", "model", ".", "embeddings", "[", "index_atoms", "[", "0", "]", "]", "\n", "p1", "=", "model", ".", "ps", "[", "index_atoms", "[", "0", "]", "]", "\n", "\n", "graph2", "=", "model", ".", "output_atoms", "(", "index_atoms", "[", "1", "]", ")", "\n", "emb2", "=", "model", ".", "embeddings", "[", "index_atoms", "[", "1", "]", "]", "\n", "p2", "=", "model", ".", "ps", "[", "index_atoms", "[", "1", "]", "]", "\n", "\n", "_", ",", "tran12", "=", "ot_fgw", "(", "graph1", ".", "data", ",", "graph2", ".", "data", ",", "p1", ",", "p2", ",", "\n", "model", ".", "ot_method", ",", "model", ".", "gamma", ",", "model", ".", "ot_layers", ",", "\n", "emb1", ".", "data", ",", "emb2", ".", "data", ")", "\n", "reg", "=", "fgwd", "(", "graph1", ",", "emb1", ",", "p1", ",", "graph2", ",", "emb2", ",", "p2", ",", "tran12", ")", "\n", "\n", "reg_total", "+=", "zeta", "*", "reg", "\n", "loss_total", "-=", "zeta", "*", "reg", "\n", "\n", "", "if", "idx", "<", "len", "(", "train_graphs", ")", ":", "\n", "                ", "lle", "=", "criterion", "(", "predictor", "(", "weights", ".", "unsqueeze", "(", "0", ")", ")", ",", "label", ")", "\n", "lle_total", "+=", "0.02", "*", "lle", "\n", "loss_total", "+=", "0.02", "*", "lle", "\n", "\n", "", "counts", "+=", "1", "\n", "if", "counts", "%", "size_batch", "==", "0", "or", "counts", "==", "num_samples", ":", "\n", "                ", "if", "counts", "%", "size_batch", "==", "0", ":", "\n", "                    ", "num", "=", "size_batch", "\n", "", "else", ":", "\n", "                    ", "num", "=", "counts", "%", "size_batch", "\n", "", "loss_epoch", "+=", "loss_total", "\n", "loss_total", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "print", "(", "'-- {}/{} [{:.1f}%], loss={:.4f}, dgw={:.4f}, ssl={:.4f}, reg={:.4f}, time={:.2f}s.'", ".", "format", "(", "\n", "counts", ",", "num_samples", ",", "counts", "/", "num_samples", "*", "100.0", ",", "\n", "loss_total", "/", "num", ",", "d_fgw_total", "/", "num", ",", "lle_total", "/", "num", ",", "reg_total", "/", "num", ",", "time", ".", "time", "(", ")", "-", "t_start", ")", ")", "\n", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "loss_total", "=", "0", "\n", "d_fgw_total", "=", "0", "\n", "reg_total", "=", "0", "\n", "lle_total", "=", "0", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# validation", "\n", "", "", "valid_acc", "=", "0", "\n", "predictor", ".", "eval", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "test_graphs", ")", ")", ":", "\n", "            ", "data", "=", "test_sampler", ".", "__getitem__", "(", "i", ")", "\n", "weights", "=", "model", ".", "weights", "[", ":", ",", "i", "+", "len", "(", "train_graphs", ")", "]", "# output_weights(i + len(train_graphs))", "\n", "pred", "=", "predictor", "(", "weights", ".", "unsqueeze", "(", "0", ")", ")", "\n", "_", ",", "est", "=", "torch", ".", "max", "(", "pred", ",", "1", ")", "\n", "if", "est", "==", "data", "[", "3", "]", ".", "data", ":", "\n", "                ", "valid_acc", "+=", "1", "\n", "\n", "", "", "valid_acc", "/=", "len", "(", "test_graphs", ")", "\n", "if", "best_acc", "<=", "valid_acc", ":", "\n", "            ", "best_acc", "=", "valid_acc", "\n", "best_model", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "best_predictor", "=", "copy", ".", "deepcopy", "(", "predictor", ")", "\n", "\n", "", "print", "(", "'{}: Epoch {}/{}, loss = {:.4f}, best acc = {:.4f}'", ".", "format", "(", "\n", "mode", ",", "epoch", "+", "1", ",", "epochs", ",", "loss_epoch", "/", "num_samples", ",", "best_acc", ")", ")", "\n", "\n", "if", "visualize_prefix", "is", "not", "None", ":", "\n", "            ", "embeddings", "=", "tsne_weights", "(", "model", ")", "\n", "embeddings_train", "=", "embeddings", "[", ":", "len", "(", "train_graphs", ")", ",", ":", "]", "\n", "embeddings_valid", "=", "embeddings", "[", "len", "(", "train_graphs", ")", ":", ",", ":", "]", "\n", "labels_train", "=", "labels", "[", ":", "len", "(", "train_graphs", ")", "]", "\n", "labels_valid", "=", "labels", "[", "len", "(", "train_graphs", ")", ":", "]", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "6", ",", "6", ")", ")", "\n", "for", "i", "in", "range", "(", "num_classes", ")", ":", "\n", "                ", "plt", ".", "scatter", "(", "embeddings_train", "[", "np", ".", "asarray", "(", "labels_train", ")", "==", "i", ",", "0", "]", ",", "\n", "embeddings_train", "[", "np", ".", "asarray", "(", "labels_train", ")", "==", "i", ",", "1", "]", ",", "\n", "s", "=", "4", ",", "\n", "c", "=", "c", "[", "i", "]", ",", "\n", "label", "=", "'train class {}'", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "plt", ".", "scatter", "(", "embeddings_valid", "[", "np", ".", "asarray", "(", "labels_valid", ")", "==", "i", ",", "0", "]", ",", "\n", "embeddings_valid", "[", "np", ".", "asarray", "(", "labels_valid", ")", "==", "i", ",", "1", "]", ",", "\n", "c", "=", "c", "[", "i", "]", ",", "\n", "label", "=", "'test class {}'", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "title", "(", "'best acc = {:.4f}'", ".", "format", "(", "best_acc", ")", ")", "\n", "print", "(", "'{}_ssl_tsne_{}_{}_{}.png'", ".", "format", "(", "visualize_prefix", ",", "len", "(", "train_graphs", ")", ",", "mode", ",", "epoch", "+", "1", ")", ")", "\n", "plt", ".", "savefig", "(", "'{}_ssl_tsne_{}_{}_{}.png'", ".", "format", "(", "visualize_prefix", ",", "len", "(", "train_graphs", ")", ",", "mode", ",", "epoch", "+", "1", ")", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", "", "return", "best_model", ",", "best_predictor", ",", "best_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.tsne_weights": [[559, 573], ["model.eval", "model.weights.cpu().data.numpy", "sklearn.manifold.TSNE().fit_transform", "model.weights.cpu", "sklearn.manifold.TSNE"], "function", ["None"], ["", "def", "tsne_weights", "(", "model", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Learn the 2D embeddings of the weights associated with atoms via t-SNE\n    Returns:\n        embeddings: (num_samples, 2) matrix representing the embeddings of weights\n    \"\"\"", "\n", "model", ".", "eval", "(", ")", "\n", "features", "=", "model", ".", "weights", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "features", "=", "features", ".", "T", "\n", "if", "features", ".", "shape", "[", "1", "]", "==", "2", ":", "\n", "        ", "embeddings", "=", "features", "\n", "", "else", ":", "\n", "        ", "embeddings", "=", "TSNE", "(", "n_components", "=", "2", ")", ".", "fit_transform", "(", "features", ")", "\n", "", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.clustering": [[575, 582], ["model.eval", "model.output_weights().data.numpy", "numpy.argmax", "model.output_weights"], "function", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.FGWF.output_weights"], ["", "def", "clustering", "(", "model", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Taking the atoms as clustering centers, we cluster data based on their weights associated with the atoms\n    \"\"\"", "\n", "model", ".", "eval", "(", ")", "\n", "feature", "=", "model", ".", "output_weights", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "return", "np", ".", "argmax", "(", "feature", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.save_model": [[584, 592], ["torch.save", "torch.save", "torch.save", "model.state_dict"], "function", ["None"], ["", "def", "save_model", "(", "model", ",", "full_path", ")", ":", "\n", "    ", "\"\"\"\n    Save trained model\n    Args:\n        model: the target model\n        full_path: the path of directory\n    \"\"\"", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "full_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.load_model": [[594, 603], ["model.load_state_dict", "torch.load", "torch.load", "torch.load"], "function", ["None"], ["", "def", "load_model", "(", "model", ",", "full_path", ")", ":", "\n", "    ", "\"\"\"\n    Load pre-trained model\n    Args:\n        model: the target model\n        full_path: the path of directory\n    \"\"\"", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "full_path", ")", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.visualize_atoms": [[605, 643], ["model.output_atoms().cpu().data.numpy", "model.embeddings[].cpu().data.numpy", "matplotlib.figure", "matplotlib.scatter", "range", "sklearn.manifold.MDS().fit_transform", "range", "matplotlib.savefig", "matplotlib.savefig", "sklearn.manifold.TSNE().fit_transform", "model.output_atoms().cpu", "model.embeddings[].cpu", "sklearn.manifold.MDS", "numpy.asarray", "matplotlib.plot", "sklearn.manifold.TSNE", "model.output_atoms"], "function", ["home.repos.pwc.inspect_result.HongtengXu_Relational-Factorization-Model.methods.FusedGromovWassersteinFactorization.FGWF.output_atoms"], ["", "def", "visualize_atoms", "(", "model", ",", "idx", ":", "int", ",", "threshold", ":", "float", "=", "0.5", ",", "filename", ":", "str", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Learning the 2D embeddings of the atoms via multi-dimensional scaling (MDS)\n    Args:\n        model: a FGWF model\n        idx: an index of the atoms\n        threshold: the threshold of edge\n        filename: the prefix of image name\n\n    Returns:\n        embeddings: (size_atom, 2) matrix representing the embeddings of nodes/samples corresponding to the atom.\n    \"\"\"", "\n", "graph", "=", "model", ".", "output_atoms", "(", "idx", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "emb", "=", "model", ".", "embeddings", "[", "idx", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "\n", "if", "emb", ".", "shape", "[", "1", "]", "==", "1", ":", "\n", "        ", "cost", "=", "graph", "+", "graph", ".", "T", "\n", "emb", "=", "MDS", "(", "n_components", "=", "2", ",", "dissimilarity", "=", "'precomputed'", ")", ".", "fit_transform", "(", "cost", ")", "\n", "", "elif", "emb", ".", "shape", "[", "1", "]", ">", "2", ":", "\n", "        ", "emb", "=", "TSNE", "(", "n_components", "=", "2", ")", ".", "fit_transform", "(", "emb", ")", "\n", "\n", "", "graph", "[", "graph", ">=", "threshold", "]", "=", "1", "\n", "graph", "[", "graph", "<", "threshold", "]", "=", "0", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "6", ",", "6", ")", ")", "\n", "plt", ".", "scatter", "(", "emb", "[", ":", ",", "0", "]", ",", "emb", "[", ":", ",", "1", "]", ",", "s", "=", "80", ")", "\n", "for", "i", "in", "range", "(", "graph", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "graph", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "if", "graph", "[", "i", ",", "j", "]", ">", "0", "and", "i", "!=", "j", ":", "\n", "                ", "pair", "=", "np", ".", "asarray", "(", "[", "i", ",", "j", "]", ")", "\n", "x", "=", "emb", "[", "pair", ",", "0", "]", "\n", "y", "=", "emb", "[", "pair", ",", "1", "]", "\n", "plt", ".", "plot", "(", "x", ",", "y", ",", "'r-'", ")", "\n", "\n", "", "", "", "if", "filename", "is", "None", ":", "\n", "        ", "plt", ".", "savefig", "(", "'atom_{}.pdf'", ".", "format", "(", "idx", ")", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "savefig", "(", "'{}_{}.pdf'", ".", "format", "(", "filename", ",", "idx", ")", ")", "\n", "", "", ""]]}