{"home.repos.pwc.inspect_result.seanjia_srunit.None.train.print_current_losses": [[9, 19], ["losses.items", "print", "open", "f.write"], "function", ["None"], ["def", "print_current_losses", "(", "epoch", ",", "iters", ",", "losses", ",", "t_comp", ",", "t_data", ",", "path", ")", ":", "\n", "    ", "message", "=", "'(epoch: %d, iters: %d, time: %.3f, data: %.3f) '", "%", "(", "epoch", ",", "iters", ",", "t_comp", ",", "t_data", ")", "\n", "for", "k", ",", "v", "in", "losses", ".", "items", "(", ")", ":", "\n", "        ", "if", "k", "==", "'reg'", ":", "\n", "            ", "message", "+=", "'%s: %.7f '", "%", "(", "k", ",", "v", ")", "\n", "", "else", ":", "\n", "           ", "message", "+=", "'%s: %.3f '", "%", "(", "k", ",", "v", ")", "\n", "", "", "print", "(", "message", ")", "# print the message", "\n", "with", "open", "(", "path", ",", "'a+'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "message", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.util.image_pool.ImagePool.__init__": [[12, 22], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "pool_size", ")", ":", "\n", "        ", "\"\"\"Initialize the ImagePool class\n\n        Parameters:\n            pool_size (int) -- the size of image buffer, if pool_size=0, no buffer will be created\n        \"\"\"", "\n", "self", ".", "pool_size", "=", "pool_size", "\n", "if", "self", ".", "pool_size", ">", "0", ":", "# create an empty pool", "\n", "            ", "self", ".", "num_imgs", "=", "0", "\n", "self", ".", "images", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.util.image_pool.ImagePool.query": [[23, 55], ["torch.cat", "torch.unsqueeze", "image_pool.ImagePool.images.append", "torch.cat.append", "random.uniform", "random.randint", "image_pool.ImagePool.images[].clone", "torch.cat.append", "torch.cat.append"], "methods", ["None"], ["", "", "def", "query", "(", "self", ",", "images", ")", ":", "\n", "        ", "\"\"\"Return an image from the pool.\n\n        Parameters:\n            images: the latest generated images from the generator\n\n        Returns images from the buffer.\n\n        By 50/100, the buffer will return input images.\n        By 50/100, the buffer will return images previously stored in the buffer,\n        and insert the current images to the buffer.\n        \"\"\"", "\n", "if", "self", ".", "pool_size", "==", "0", ":", "# if the buffer size is 0, do nothing", "\n", "            ", "return", "images", "\n", "", "return_images", "=", "[", "]", "\n", "for", "image", "in", "images", ":", "\n", "            ", "image", "=", "torch", ".", "unsqueeze", "(", "image", ".", "data", ",", "0", ")", "\n", "if", "self", ".", "num_imgs", "<", "self", ".", "pool_size", ":", "# if the buffer is not full; keep inserting current images to the buffer", "\n", "                ", "self", ".", "num_imgs", "=", "self", ".", "num_imgs", "+", "1", "\n", "self", ".", "images", ".", "append", "(", "image", ")", "\n", "return_images", ".", "append", "(", "image", ")", "\n", "", "else", ":", "\n", "                ", "p", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "if", "p", ">", "0.5", ":", "# by 50% chance, the buffer will return a previously stored image, and insert the current image into the buffer", "\n", "                    ", "random_id", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "pool_size", "-", "1", ")", "# randint is inclusive", "\n", "tmp", "=", "self", ".", "images", "[", "random_id", "]", ".", "clone", "(", ")", "\n", "self", ".", "images", "[", "random_id", "]", "=", "image", "\n", "return_images", ".", "append", "(", "tmp", ")", "\n", "", "else", ":", "# by another 50% chance, the buffer will return the current image", "\n", "                    ", "return_images", ".", "append", "(", "image", ")", "\n", "", "", "", "return_images", "=", "torch", ".", "cat", "(", "return_images", ",", "0", ")", "# collect all the images and return", "\n", "return", "return_images", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seanjia_srunit.util.get_data.GetData.__init__": [[27, 34], ["url_dict.get", "technique.lower"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.util.get_data.GetData.get"], ["def", "__init__", "(", "self", ",", "technique", "=", "'cyclegan'", ",", "verbose", "=", "True", ")", ":", "\n", "        ", "url_dict", "=", "{", "\n", "'pix2pix'", ":", "'http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/'", ",", "\n", "'cyclegan'", ":", "'https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets'", "\n", "}", "\n", "self", ".", "url", "=", "url_dict", ".", "get", "(", "technique", ".", "lower", "(", ")", ")", "\n", "self", ".", "_verbose", "=", "verbose", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.util.get_data.GetData._print": [[35, 38], ["print"], "methods", ["None"], ["", "def", "_print", "(", "self", ",", "text", ")", ":", "\n", "        ", "if", "self", ".", "_verbose", ":", "\n", "            ", "print", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.util.get_data.GetData._get_options": [[39, 45], ["bs4.BeautifulSoup", "bs4.BeautifulSoup.find_all", "h.text.endswith"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_get_options", "(", "r", ")", ":", "\n", "        ", "soup", "=", "BeautifulSoup", "(", "r", ".", "text", ",", "'lxml'", ")", "\n", "options", "=", "[", "h", ".", "text", "for", "h", "in", "soup", ".", "find_all", "(", "'a'", ",", "href", "=", "True", ")", "\n", "if", "h", ".", "text", ".", "endswith", "(", "(", "'.zip'", ",", "'tar.gz'", ")", ")", "]", "\n", "return", "options", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.util.get_data.GetData._present_options": [[46, 55], ["requests.get", "get_data.GetData._get_options", "print", "enumerate", "input", "print", "int"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.util.get_data.GetData.get", "home.repos.pwc.inspect_result.seanjia_srunit.util.get_data.GetData._get_options"], ["", "def", "_present_options", "(", "self", ")", ":", "\n", "        ", "r", "=", "requests", ".", "get", "(", "self", ".", "url", ")", "\n", "options", "=", "self", ".", "_get_options", "(", "r", ")", "\n", "print", "(", "'Options:\\n'", ")", "\n", "for", "i", ",", "o", "in", "enumerate", "(", "options", ")", ":", "\n", "            ", "print", "(", "\"{0}: {1}\"", ".", "format", "(", "i", ",", "o", ")", ")", "\n", "", "choice", "=", "input", "(", "\"\\nPlease enter the number of the \"", "\n", "\"dataset above you wish to download:\"", ")", "\n", "return", "options", "[", "int", "(", "choice", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.util.get_data.GetData._download_data": [[56, 78], ["os.path.basename", "os.path.join", "os.path.basename.endswith", "get_data.GetData._print", "zipfile.ZipFile.extractall", "zipfile.ZipFile.close", "os.remove", "os.path.isdir", "os.makedirs", "open", "requests.get", "f.write", "tarfile.open", "os.path.basename.endswith", "zipfile.ZipFile", "ValueError"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.util.get_data.GetData._print", "home.repos.pwc.inspect_result.seanjia_srunit.util.get_data.GetData.get"], ["", "def", "_download_data", "(", "self", ",", "dataset_url", ",", "save_path", ")", ":", "\n", "        ", "if", "not", "isdir", "(", "save_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "save_path", ")", "\n", "\n", "", "base", "=", "basename", "(", "dataset_url", ")", "\n", "temp_save_path", "=", "join", "(", "save_path", ",", "base", ")", "\n", "\n", "with", "open", "(", "temp_save_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "r", "=", "requests", ".", "get", "(", "dataset_url", ")", "\n", "f", ".", "write", "(", "r", ".", "content", ")", "\n", "\n", "", "if", "base", ".", "endswith", "(", "'.tar.gz'", ")", ":", "\n", "            ", "obj", "=", "tarfile", ".", "open", "(", "temp_save_path", ")", "\n", "", "elif", "base", ".", "endswith", "(", "'.zip'", ")", ":", "\n", "            ", "obj", "=", "ZipFile", "(", "temp_save_path", ",", "'r'", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown File Type: {0}.\"", ".", "format", "(", "base", ")", ")", "\n", "\n", "", "self", ".", "_print", "(", "\"Unpacking Data...\"", ")", "\n", "obj", ".", "extractall", "(", "save_path", ")", "\n", "obj", ".", "close", "(", ")", "\n", "os", ".", "remove", "(", "temp_save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.util.get_data.GetData.get": [[79, 111], ["os.path.join", "os.path.isdir", "os.path.abspath", "get_data.GetData._present_options", "warnings.warn", "get_data.GetData._print", "get_data.GetData._download_data", "get_data.GetData.split"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.util.get_data.GetData._present_options", "home.repos.pwc.inspect_result.seanjia_srunit.util.get_data.GetData._print", "home.repos.pwc.inspect_result.seanjia_srunit.util.get_data.GetData._download_data"], ["", "def", "get", "(", "self", ",", "save_path", ",", "dataset", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        Download a dataset.\n\n        Parameters:\n            save_path (str) -- A directory to save the data to.\n            dataset (str)   -- (optional). A specific dataset to download.\n                            Note: this must include the file extension.\n                            If None, options will be presented for you\n                            to choose from.\n\n        Returns:\n            save_path_full (str) -- the absolute path to the downloaded data.\n\n        \"\"\"", "\n", "if", "dataset", "is", "None", ":", "\n", "            ", "selected_dataset", "=", "self", ".", "_present_options", "(", ")", "\n", "", "else", ":", "\n", "            ", "selected_dataset", "=", "dataset", "\n", "\n", "", "save_path_full", "=", "join", "(", "save_path", ",", "selected_dataset", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", "\n", "\n", "if", "isdir", "(", "save_path_full", ")", ":", "\n", "            ", "warn", "(", "\"\\n'{0}' already exists. Voiding Download.\"", ".", "format", "(", "\n", "save_path_full", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_print", "(", "'Downloading Data...'", ")", "\n", "url", "=", "\"{0}/{1}\"", ".", "format", "(", "self", ".", "url", ",", "selected_dataset", ")", "\n", "self", ".", "_download_data", "(", "url", ",", "save_path", "=", "save_path", ")", "\n", "\n", "", "return", "abspath", "(", "save_path_full", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seanjia_srunit.util.util.str2bool": [[13, 22], ["isinstance", "v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["def", "str2bool", "(", "v", ")", ":", "\n", "    ", "if", "isinstance", "(", "v", ",", "bool", ")", ":", "\n", "        ", "return", "v", "\n", "", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.util.util.copyconf": [[24, 29], ["argparse.Namespace", "setattr", "vars"], "function", ["None"], ["", "", "def", "copyconf", "(", "default_opt", ",", "**", "kwargs", ")", ":", "\n", "    ", "conf", "=", "Namespace", "(", "**", "vars", "(", "default_opt", ")", ")", "\n", "for", "key", "in", "kwargs", ":", "\n", "        ", "setattr", "(", "conf", ",", "key", ",", "kwargs", "[", "key", "]", ")", "\n", "", "return", "conf", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.util.util.find_class_in_module": [[31, 42], ["target_cls_name.replace().lower.replace().lower", "importlib.import_module", "importlib.import_module.__dict__.items", "target_cls_name.replace().lower.replace", "name.lower"], "function", ["None"], ["", "def", "find_class_in_module", "(", "target_cls_name", ",", "module", ")", ":", "\n", "    ", "target_cls_name", "=", "target_cls_name", ".", "replace", "(", "'_'", ",", "''", ")", ".", "lower", "(", ")", "\n", "clslib", "=", "importlib", ".", "import_module", "(", "module", ")", "\n", "cls", "=", "None", "\n", "for", "name", ",", "clsobj", "in", "clslib", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "        ", "if", "name", ".", "lower", "(", ")", "==", "target_cls_name", ":", "\n", "            ", "cls", "=", "clsobj", "\n", "\n", "", "", "assert", "cls", "is", "not", "None", ",", "\"In %s, there should be a class whose name matches %s in lowercase without underscore(_)\"", "%", "(", "module", ",", "target_cls_name", ")", "\n", "\n", "return", "cls", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.util.util.tensor2im": [[44, 63], ["np.tile.astype", "isinstance", "isinstance", "image_tensor[].clamp().cpu().float().numpy", "numpy.tile", "image_tensor[].clamp().cpu().float", "numpy.transpose", "image_tensor[].clamp().cpu", "image_tensor[].clamp"], "function", ["None"], ["", "def", "tensor2im", "(", "input_image", ",", "imtype", "=", "np", ".", "uint8", ")", ":", "\n", "    ", "\"\"\"\"Converts a Tensor array into a numpy image array.\n\n    Parameters:\n        input_image (tensor) --  the input image tensor array\n        imtype (type)        --  the desired type of the converted numpy array\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "input_image", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "if", "isinstance", "(", "input_image", ",", "torch", ".", "Tensor", ")", ":", "# get the data from a variable", "\n", "            ", "image_tensor", "=", "input_image", ".", "data", "\n", "", "else", ":", "\n", "            ", "return", "input_image", "\n", "", "image_numpy", "=", "image_tensor", "[", "0", "]", ".", "clamp", "(", "-", "1.0", ",", "1.0", ")", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "# convert it into a numpy array", "\n", "if", "image_numpy", ".", "shape", "[", "0", "]", "==", "1", ":", "# grayscale to RGB", "\n", "            ", "image_numpy", "=", "np", ".", "tile", "(", "image_numpy", ",", "(", "3", ",", "1", ",", "1", ")", ")", "\n", "", "image_numpy", "=", "(", "np", ".", "transpose", "(", "image_numpy", ",", "(", "1", ",", "2", ",", "0", ")", ")", "+", "1", ")", "/", "2.0", "*", "255.0", "# post-processing: tranpose and scaling", "\n", "", "else", ":", "# if it is a numpy array, do nothing", "\n", "        ", "image_numpy", "=", "input_image", "\n", "", "return", "image_numpy", ".", "astype", "(", "imtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.util.util.diagnose_network": [[65, 82], ["net.parameters", "print", "print", "torch.mean", "torch.abs"], "function", ["None"], ["", "def", "diagnose_network", "(", "net", ",", "name", "=", "'network'", ")", ":", "\n", "    ", "\"\"\"Calculate and print the mean of average absolute(gradients)\n\n    Parameters:\n        net (torch network) -- Torch network\n        name (str) -- the name of the network\n    \"\"\"", "\n", "mean", "=", "0.0", "\n", "count", "=", "0", "\n", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "        ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "            ", "mean", "+=", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "param", ".", "grad", ".", "data", ")", ")", "\n", "count", "+=", "1", "\n", "", "", "if", "count", ">", "0", ":", "\n", "        ", "mean", "=", "mean", "/", "count", "\n", "", "print", "(", "name", ")", "\n", "print", "(", "mean", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.util.util.save_image": [[84, 102], ["PIL.Image.fromarray", "image_pil.resize.save", "image_pil.resize.resize", "image_pil.resize.resize", "int", "int"], "function", ["None"], ["", "def", "save_image", "(", "image_numpy", ",", "image_path", ",", "aspect_ratio", "=", "1.0", ")", ":", "\n", "    ", "\"\"\"Save a numpy image to the disk\n\n    Parameters:\n        image_numpy (numpy array) -- input numpy array\n        image_path (str)          -- the path of the image\n    \"\"\"", "\n", "\n", "image_pil", "=", "Image", ".", "fromarray", "(", "image_numpy", ")", "\n", "h", ",", "w", ",", "_", "=", "image_numpy", ".", "shape", "\n", "\n", "if", "aspect_ratio", "is", "None", ":", "\n", "        ", "pass", "\n", "", "elif", "aspect_ratio", ">", "1.0", ":", "\n", "        ", "image_pil", "=", "image_pil", ".", "resize", "(", "(", "h", ",", "int", "(", "w", "*", "aspect_ratio", ")", ")", ",", "Image", ".", "BICUBIC", ")", "\n", "", "elif", "aspect_ratio", "<", "1.0", ":", "\n", "        ", "image_pil", "=", "image_pil", ".", "resize", "(", "(", "int", "(", "h", "/", "aspect_ratio", ")", ",", "w", ")", ",", "Image", ".", "BICUBIC", ")", "\n", "", "image_pil", ".", "save", "(", "image_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.util.util.print_numpy": [[104, 118], ["x.flatten.astype", "print", "x.flatten.flatten", "print", "numpy.mean", "numpy.min", "numpy.max", "numpy.median", "numpy.std"], "function", ["None"], ["", "def", "print_numpy", "(", "x", ",", "val", "=", "True", ",", "shp", "=", "False", ")", ":", "\n", "    ", "\"\"\"Print the mean, min, max, median, std, and size of a numpy array\n\n    Parameters:\n        val (bool) -- if print the values of the numpy array\n        shp (bool) -- if print the shape of the numpy array\n    \"\"\"", "\n", "x", "=", "x", ".", "astype", "(", "np", ".", "float64", ")", "\n", "if", "shp", ":", "\n", "        ", "print", "(", "'shape,'", ",", "x", ".", "shape", ")", "\n", "", "if", "val", ":", "\n", "        ", "x", "=", "x", ".", "flatten", "(", ")", "\n", "print", "(", "'mean = %3.3f, min = %3.3f, max = %3.3f, median = %3.3f, std=%3.3f'", "%", "(", "\n", "np", ".", "mean", "(", "x", ")", ",", "np", ".", "min", "(", "x", ")", ",", "np", ".", "max", "(", "x", ")", ",", "np", ".", "median", "(", "x", ")", ",", "np", ".", "std", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.util.util.mkdirs": [[120, 131], ["isinstance", "util.mkdir", "isinstance", "util.mkdir"], "function", ["home.repos.pwc.inspect_result.seanjia_srunit.util.util.mkdir", "home.repos.pwc.inspect_result.seanjia_srunit.util.util.mkdir"], ["", "", "def", "mkdirs", "(", "paths", ")", ":", "\n", "    ", "\"\"\"create empty directories if they don't exist\n\n    Parameters:\n        paths (str list) -- a list of directory paths\n    \"\"\"", "\n", "if", "isinstance", "(", "paths", ",", "list", ")", "and", "not", "isinstance", "(", "paths", ",", "str", ")", ":", "\n", "        ", "for", "path", "in", "paths", ":", "\n", "            ", "mkdir", "(", "path", ")", "\n", "", "", "else", ":", "\n", "        ", "mkdir", "(", "paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.util.util.mkdir": [[133, 141], ["os.path.exists", "os.makedirs"], "function", ["None"], ["", "", "def", "mkdir", "(", "path", ")", ":", "\n", "    ", "\"\"\"create a single empty directory if it didn't exist\n\n    Parameters:\n        path (str) -- a single directory path\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.util.util.correct_resize_label": [[143, 155], ["t.detach().cpu.detach().cpu", "range", "torch.stack().to", "t.detach().cpu.size", "numpy.transpose", "PIL.Image.fromarray().resize", "torch.from_numpy().long", "resized.append", "t.detach().cpu.detach", "one_t.numpy().astype", "torch.stack", "PIL.Image.fromarray", "torch.from_numpy", "one_t.numpy", "numpy.array"], "function", ["None"], ["", "", "def", "correct_resize_label", "(", "t", ",", "size", ")", ":", "\n", "    ", "device", "=", "t", ".", "device", "\n", "t", "=", "t", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "resized", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "t", ".", "size", "(", "0", ")", ")", ":", "\n", "        ", "one_t", "=", "t", "[", "i", ",", ":", "1", "]", "\n", "one_np", "=", "np", ".", "transpose", "(", "one_t", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "uint8", ")", ",", "(", "1", ",", "2", ",", "0", ")", ")", "\n", "one_np", "=", "one_np", "[", ":", ",", ":", ",", "0", "]", "\n", "one_image", "=", "Image", ".", "fromarray", "(", "one_np", ")", ".", "resize", "(", "size", ",", "Image", ".", "NEAREST", ")", "\n", "resized_t", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "one_image", ")", ")", ".", "long", "(", ")", "\n", "resized", ".", "append", "(", "resized_t", ")", "\n", "", "return", "torch", ".", "stack", "(", "resized", ",", "dim", "=", "0", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.util.util.correct_resize": [[157, 167], ["t.detach().cpu.detach().cpu", "range", "torch.stack().to", "t.detach().cpu.size", "PIL.Image.fromarray().resize", "resized.append", "t.detach().cpu.detach", "torch.stack", "PIL.Image.fromarray", "torchvision.transforms.functional.to_tensor", "util.tensor2im"], "function", ["home.repos.pwc.inspect_result.seanjia_srunit.util.util.tensor2im"], ["", "def", "correct_resize", "(", "t", ",", "size", ",", "mode", "=", "Image", ".", "BICUBIC", ")", ":", "\n", "    ", "device", "=", "t", ".", "device", "\n", "t", "=", "t", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "resized", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "t", ".", "size", "(", "0", ")", ")", ":", "\n", "        ", "one_t", "=", "t", "[", "i", ":", "i", "+", "1", "]", "\n", "one_image", "=", "Image", ".", "fromarray", "(", "tensor2im", "(", "one_t", ")", ")", ".", "resize", "(", "size", ",", "Image", ".", "BICUBIC", ")", "\n", "resized_t", "=", "torchvision", ".", "transforms", ".", "functional", ".", "to_tensor", "(", "one_image", ")", "*", "2", "-", "1.0", "\n", "resized", ".", "append", "(", "resized_t", ")", "\n", "", "return", "torch", ".", "stack", "(", "resized", ",", "dim", "=", "0", ")", ".", "to", "(", "device", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.seanjia_srunit.models.sincut_model.SinCUTModel.modify_commandline_options": [[12, 55], ["cut_model.CUTModel.modify_commandline_options", "cut_model.CUTModel.modify_commandline_options.add_argument", "cut_model.CUTModel.modify_commandline_options.add_argument", "cut_model.CUTModel.modify_commandline_options.set_defaults", "cut_model.CUTModel.modify_commandline_options.set_defaults", "cut_model.CUTModel.modify_commandline_options.set_defaults"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.data.template_dataset.TemplateDataset.modify_commandline_options"], ["@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", "=", "True", ")", ":", "\n", "        ", "parser", "=", "CUTModel", ".", "modify_commandline_options", "(", "parser", ",", "is_train", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_R1'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "'weight for the R1 gradient penalty'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_identity'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "'the \"identity preservation loss\"'", ")", "\n", "\n", "parser", ".", "set_defaults", "(", "nce_includes_all_negatives_from_minibatch", "=", "True", ",", "\n", "dataset_mode", "=", "\"singleimage\"", ",", "\n", "netG", "=", "\"stylegan2\"", ",", "\n", "stylegan2_G_num_downsampling", "=", "1", ",", "\n", "netD", "=", "\"stylegan2\"", ",", "\n", "gan_mode", "=", "\"nonsaturating\"", ",", "\n", "num_patches", "=", "1", ",", "\n", "nce_layers", "=", "\"0,2,4\"", ",", "\n", "lambda_NCE", "=", "4.0", ",", "\n", "ngf", "=", "10", ",", "\n", "ndf", "=", "8", ",", "\n", "lr", "=", "0.002", ",", "\n", "beta1", "=", "0.0", ",", "\n", "beta2", "=", "0.99", ",", "\n", "load_size", "=", "1024", ",", "\n", "crop_size", "=", "64", ",", "\n", "preprocess", "=", "\"zoom_and_patch\"", ",", "\n", ")", "\n", "\n", "if", "is_train", ":", "\n", "            ", "parser", ".", "set_defaults", "(", "preprocess", "=", "\"zoom_and_patch\"", ",", "\n", "batch_size", "=", "16", ",", "\n", "save_epoch_freq", "=", "1", ",", "\n", "save_latest_freq", "=", "20000", ",", "\n", "n_epochs", "=", "8", ",", "\n", "n_epochs_decay", "=", "8", ",", "\n", "\n", ")", "\n", "", "else", ":", "\n", "            ", "parser", ".", "set_defaults", "(", "preprocess", "=", "\"none\"", ",", "# load the whole image as it is", "\n", "batch_size", "=", "1", ",", "\n", "num_test", "=", "1", ",", "\n", ")", "\n", "\n", "", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.sincut_model.SinCUTModel.__init__": [[56, 63], ["cut_model.CUTModel.__init__"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "opt", ")", "\n", "if", "self", ".", "isTrain", ":", "\n", "            ", "if", "opt", ".", "lambda_R1", ">", "0.0", ":", "\n", "                ", "self", ".", "loss_names", "+=", "[", "'D_R1'", "]", "\n", "", "if", "opt", ".", "lambda_identity", ">", "0.0", ":", "\n", "                ", "self", ".", "loss_names", "+=", "[", "'idt'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.sincut_model.SinCUTModel.compute_D_loss": [[64, 70], ["sincut_model.SinCUTModel.real_B.requires_grad_", "super().compute_D_loss", "sincut_model.SinCUTModel.R1_loss"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.compute_D_loss", "home.repos.pwc.inspect_result.seanjia_srunit.models.sincut_model.SinCUTModel.R1_loss"], ["", "", "", "def", "compute_D_loss", "(", "self", ")", ":", "\n", "        ", "self", ".", "real_B", ".", "requires_grad_", "(", ")", "\n", "GAN_loss_D", "=", "super", "(", ")", ".", "compute_D_loss", "(", ")", "\n", "self", ".", "loss_D_R1", "=", "self", ".", "R1_loss", "(", "self", ".", "pred_real", ",", "self", ".", "real_B", ")", "\n", "self", ".", "loss_D", "=", "GAN_loss_D", "+", "self", ".", "loss_D_R1", "\n", "return", "self", ".", "loss_D", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.sincut_model.SinCUTModel.compute_G_loss": [[71, 75], ["super().compute_G_loss", "torch.nn.functional.l1_loss"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.compute_G_loss"], ["", "def", "compute_G_loss", "(", "self", ")", ":", "\n", "        ", "CUT_loss_G", "=", "super", "(", ")", ".", "compute_G_loss", "(", ")", "\n", "self", ".", "loss_idt", "=", "torch", ".", "nn", ".", "functional", ".", "l1_loss", "(", "self", ".", "idt_B", ",", "self", ".", "real_B", ")", "*", "self", ".", "opt", ".", "lambda_identity", "\n", "return", "CUT_loss_G", "+", "self", ".", "loss_idt", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.sincut_model.SinCUTModel.R1_loss": [[76, 80], ["torch.autograd.grad", "grad_real.pow().view().sum().mean", "real_pred.sum", "grad_real.pow().view().sum", "grad_real.pow().view", "grad_real.pow"], "methods", ["None"], ["", "def", "R1_loss", "(", "self", ",", "real_pred", ",", "real_img", ")", ":", "\n", "        ", "grad_real", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "outputs", "=", "real_pred", ".", "sum", "(", ")", ",", "inputs", "=", "real_img", ",", "create_graph", "=", "True", ",", "retain_graph", "=", "True", ")", "\n", "grad_penalty", "=", "grad_real", ".", "pow", "(", "2", ")", ".", "view", "(", "grad_real", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ".", "sum", "(", "1", ")", ".", "mean", "(", ")", "\n", "return", "grad_penalty", "*", "(", "self", ".", "opt", ".", "lambda_R1", "*", "0.5", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.Downsample.__init__": [[38, 52], ["torch.Module.__init__", "int", "networks.get_filter", "networks.Downsample.register_buffer", "int", "int", "int", "int", "filt[].repeat", "networks.get_pad_layer", "numpy.ceil", "numpy.ceil"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.get_filter", "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.get_pad_layer"], ["    ", "def", "__init__", "(", "self", ",", "channels", ",", "pad_type", "=", "'reflect'", ",", "filt_size", "=", "3", ",", "stride", "=", "2", ",", "pad_off", "=", "0", ")", ":", "\n", "        ", "super", "(", "Downsample", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "filt_size", "=", "filt_size", "\n", "self", ".", "pad_off", "=", "pad_off", "\n", "self", ".", "pad_sizes", "=", "[", "int", "(", "1.", "*", "(", "filt_size", "-", "1", ")", "/", "2", ")", ",", "int", "(", "np", ".", "ceil", "(", "1.", "*", "(", "filt_size", "-", "1", ")", "/", "2", ")", ")", ",", "int", "(", "1.", "*", "(", "filt_size", "-", "1", ")", "/", "2", ")", ",", "int", "(", "np", ".", "ceil", "(", "1.", "*", "(", "filt_size", "-", "1", ")", "/", "2", ")", ")", "]", "\n", "self", ".", "pad_sizes", "=", "[", "pad_size", "+", "pad_off", "for", "pad_size", "in", "self", ".", "pad_sizes", "]", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "off", "=", "int", "(", "(", "self", ".", "stride", "-", "1", ")", "/", "2.", ")", "\n", "self", ".", "channels", "=", "channels", "\n", "\n", "filt", "=", "get_filter", "(", "filt_size", "=", "self", ".", "filt_size", ")", "\n", "self", ".", "register_buffer", "(", "'filt'", ",", "filt", "[", "None", ",", "None", ",", ":", ",", ":", "]", ".", "repeat", "(", "(", "self", ".", "channels", ",", "1", ",", "1", ",", "1", ")", ")", ")", "\n", "\n", "self", ".", "pad", "=", "get_pad_layer", "(", "pad_type", ")", "(", "self", ".", "pad_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.Downsample.forward": [[53, 61], ["torch.conv2d", "torch.conv2d", "torch.conv2d", "networks.Downsample.pad", "networks.Downsample.pad"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "if", "(", "self", ".", "filt_size", "==", "1", ")", ":", "\n", "            ", "if", "(", "self", ".", "pad_off", "==", "0", ")", ":", "\n", "                ", "return", "inp", "[", ":", ",", ":", ",", ":", ":", "self", ".", "stride", ",", ":", ":", "self", ".", "stride", "]", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "pad", "(", "inp", ")", "[", ":", ",", ":", ",", ":", ":", "self", ".", "stride", ",", ":", ":", "self", ".", "stride", "]", "\n", "", "", "else", ":", "\n", "            ", "return", "F", ".", "conv2d", "(", "self", ".", "pad", "(", "inp", ")", ",", "self", ".", "filt", ",", "stride", "=", "self", ".", "stride", ",", "groups", "=", "inp", ".", "shape", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.Upsample2.__init__": [[64, 68], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "scale_factor", ",", "mode", "=", "'nearest'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "factor", "=", "scale_factor", "\n", "self", ".", "mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.Upsample2.forward": [[69, 71], ["torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "x", ",", "scale_factor", "=", "self", ".", "factor", ",", "mode", "=", "self", ".", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.Upsample.__init__": [[74, 87], ["torch.Module.__init__", "int", "int", "networks.Upsample.register_buffer", "numpy.mod", "networks.get_filter", "filt[].repeat", "networks.get_pad_layer"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.get_filter", "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.get_pad_layer"], ["    ", "def", "__init__", "(", "self", ",", "channels", ",", "pad_type", "=", "'repl'", ",", "filt_size", "=", "4", ",", "stride", "=", "2", ")", ":", "\n", "        ", "super", "(", "Upsample", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "filt_size", "=", "filt_size", "\n", "self", ".", "filt_odd", "=", "np", ".", "mod", "(", "filt_size", ",", "2", ")", "==", "1", "\n", "self", ".", "pad_size", "=", "int", "(", "(", "filt_size", "-", "1", ")", "/", "2", ")", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "off", "=", "int", "(", "(", "self", ".", "stride", "-", "1", ")", "/", "2.", ")", "\n", "self", ".", "channels", "=", "channels", "\n", "\n", "filt", "=", "get_filter", "(", "filt_size", "=", "self", ".", "filt_size", ")", "*", "(", "stride", "**", "2", ")", "\n", "self", ".", "register_buffer", "(", "'filt'", ",", "filt", "[", "None", ",", "None", ",", ":", ",", ":", "]", ".", "repeat", "(", "(", "self", ".", "channels", ",", "1", ",", "1", ",", "1", ")", ")", ")", "\n", "\n", "self", ".", "pad", "=", "get_pad_layer", "(", "pad_type", ")", "(", "[", "1", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.Upsample.forward": [[88, 94], ["torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "networks.Upsample.pad"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "ret_val", "=", "F", ".", "conv_transpose2d", "(", "self", ".", "pad", "(", "inp", ")", ",", "self", ".", "filt", ",", "stride", "=", "self", ".", "stride", ",", "padding", "=", "1", "+", "self", ".", "pad_size", ",", "groups", "=", "inp", ".", "shape", "[", "1", "]", ")", "[", ":", ",", ":", ",", "1", ":", ",", "1", ":", "]", "\n", "if", "(", "self", ".", "filt_odd", ")", ":", "\n", "            ", "return", "ret_val", "\n", "", "else", ":", "\n", "            ", "return", "ret_val", "[", ":", ",", ":", ",", ":", "-", "1", ",", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.Identity.forward": [[109, 111], ["None"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.GANLoss.__init__": [[350, 373], ["torch.Module.__init__", "networks.GANLoss.register_buffer", "networks.GANLoss.register_buffer", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "gan_mode", ",", "target_real_label", "=", "1.0", ",", "target_fake_label", "=", "0.0", ")", ":", "\n", "        ", "\"\"\" Initialize the GANLoss class.\n\n        Parameters:\n            gan_mode (str) - - the type of GAN objective. It currently supports vanilla, lsgan, and wgangp.\n            target_real_label (bool) - - label for a real image\n            target_fake_label (bool) - - label of a fake image\n\n        Note: Do not use sigmoid as the last layer of Discriminator.\n        LSGAN needs no sigmoid. vanilla GANs will handle it with BCEWithLogitsLoss.\n        \"\"\"", "\n", "super", "(", "GANLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "register_buffer", "(", "'real_label'", ",", "torch", ".", "tensor", "(", "target_real_label", ")", ")", "\n", "self", ".", "register_buffer", "(", "'fake_label'", ",", "torch", ".", "tensor", "(", "target_fake_label", ")", ")", "\n", "self", ".", "gan_mode", "=", "gan_mode", "\n", "if", "gan_mode", "==", "'lsgan'", ":", "\n", "            ", "self", ".", "loss", "=", "nn", ".", "MSELoss", "(", ")", "\n", "", "elif", "gan_mode", "==", "'vanilla'", ":", "\n", "            ", "self", ".", "loss", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "", "elif", "gan_mode", "in", "[", "'wgangp'", ",", "'nonsaturating'", "]", ":", "\n", "            ", "self", ".", "loss", "=", "None", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'gan mode %s not implemented'", "%", "gan_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.GANLoss.get_target_tensor": [[374, 390], ["target_tensor.expand_as"], "methods", ["None"], ["", "", "def", "get_target_tensor", "(", "self", ",", "prediction", ",", "target_is_real", ")", ":", "\n", "        ", "\"\"\"Create label tensors with the same size as the input.\n\n        Parameters:\n            prediction (tensor) - - tpyically the prediction from a discriminator\n            target_is_real (bool) - - if the ground truth label is for real images or fake images\n\n        Returns:\n            A label tensor filled with ground truth label, and with the size of the input\n        \"\"\"", "\n", "\n", "if", "target_is_real", ":", "\n", "            ", "target_tensor", "=", "self", ".", "real_label", "\n", "", "else", ":", "\n", "            ", "target_tensor", "=", "self", ".", "fake_label", "\n", "", "return", "target_tensor", ".", "expand_as", "(", "prediction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.GANLoss.__call__": [[391, 416], ["prediction.size", "networks.GANLoss.get_target_tensor", "networks.GANLoss.loss", "prediction.mean", "prediction.mean", "torch.softplus().view().mean", "torch.softplus().view().mean", "torch.softplus().view().mean", "torch.softplus().view().mean", "torch.softplus().view().mean", "torch.softplus().view().mean", "torch.softplus().view", "torch.softplus().view", "torch.softplus().view", "torch.softplus().view", "torch.softplus().view", "torch.softplus().view", "torch.softplus", "torch.softplus", "torch.softplus", "torch.softplus", "torch.softplus", "torch.softplus"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.networks.GANLoss.get_target_tensor"], ["", "def", "__call__", "(", "self", ",", "prediction", ",", "target_is_real", ")", ":", "\n", "        ", "\"\"\"Calculate loss given Discriminator's output and grount truth labels.\n\n        Parameters:\n            prediction (tensor) - - tpyically the prediction output from a discriminator\n            target_is_real (bool) - - if the ground truth label is for real images or fake images\n\n        Returns:\n            the calculated loss.\n        \"\"\"", "\n", "bs", "=", "prediction", ".", "size", "(", "0", ")", "\n", "if", "self", ".", "gan_mode", "in", "[", "'lsgan'", ",", "'vanilla'", "]", ":", "\n", "            ", "target_tensor", "=", "self", ".", "get_target_tensor", "(", "prediction", ",", "target_is_real", ")", "\n", "loss", "=", "self", ".", "loss", "(", "prediction", ",", "target_tensor", ")", "\n", "", "elif", "self", ".", "gan_mode", "==", "'wgangp'", ":", "\n", "            ", "if", "target_is_real", ":", "\n", "                ", "loss", "=", "-", "prediction", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "prediction", ".", "mean", "(", ")", "\n", "", "", "elif", "self", ".", "gan_mode", "==", "'nonsaturating'", ":", "\n", "            ", "if", "target_is_real", ":", "\n", "                ", "loss", "=", "F", ".", "softplus", "(", "-", "prediction", ")", ".", "view", "(", "bs", ",", "-", "1", ")", ".", "mean", "(", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "F", ".", "softplus", "(", "prediction", ")", ".", "view", "(", "bs", ",", "-", "1", ")", ".", "mean", "(", "dim", "=", "1", ")", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.Normalize.__init__": [[457, 460], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "power", "=", "2", ")", ":", "\n", "        ", "super", "(", "Normalize", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "power", "=", "power", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.Normalize.forward": [[461, 466], ["x.pow().sum().pow", "x.div", "x.pow().sum", "x.pow"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "+", "1e-12", "\n", "norm", "=", "x", ".", "pow", "(", "self", ".", "power", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ".", "pow", "(", "1.", "/", "self", ".", "power", ")", "\n", "out", "=", "x", ".", "div", "(", "norm", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.PoolingF.__init__": [[469, 474], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "networks.Normalize", "torch.AdaptiveMaxPool2d", "torch.AdaptiveMaxPool2d", "torch.AdaptiveMaxPool2d"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "PoolingF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "model", "=", "[", "nn", ".", "AdaptiveMaxPool2d", "(", "1", ")", "]", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "self", ".", "l2norm", "=", "Normalize", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.PoolingF.forward": [[475, 477], ["networks.PoolingF.l2norm", "networks.PoolingF.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "l2norm", "(", "self", ".", "model", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.ReshapeF.__init__": [[480, 485], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "networks.Normalize", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "ReshapeF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "model", "=", "[", "nn", ".", "AdaptiveAvgPool2d", "(", "4", ")", "]", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "self", ".", "l2norm", "=", "Normalize", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.ReshapeF.forward": [[486, 490], ["networks.ReshapeF.model", "networks.ReshapeF.permute().flatten", "networks.ReshapeF.l2norm", "networks.ReshapeF.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "model", "(", "x", ")", "\n", "x_reshape", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "flatten", "(", "0", ",", "2", ")", "\n", "return", "self", ".", "l2norm", "(", "x_reshape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.StridedConvF.__init__": [[493, 503], ["torch.Module.__init__", "networks.Normalize"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# self.conv1 = nn.Conv2d(256, 128, 3, stride=2)", "\n", "# self.conv2 = nn.Conv2d(128, 64, 3, stride=1)", "\n", "self", ".", "l2_norm", "=", "Normalize", "(", "2", ")", "\n", "self", ".", "mlps", "=", "{", "}", "\n", "self", ".", "moving_averages", "=", "{", "}", "\n", "self", ".", "init_type", "=", "init_type", "\n", "self", ".", "init_gain", "=", "init_gain", "\n", "self", ".", "gpu_ids", "=", "gpu_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.StridedConvF.create_mlp": [[504, 516], ["int", "range", "torch.Sequential.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "networks.init_net", "numpy.rint", "torch.Sequential.append", "torch.Sequential.append", "max", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "numpy.log2", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "max"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.networks.init_net"], ["", "def", "create_mlp", "(", "self", ",", "x", ")", ":", "\n", "        ", "C", ",", "H", "=", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "2", "]", "\n", "n_down", "=", "int", "(", "np", ".", "rint", "(", "np", ".", "log2", "(", "H", "/", "32", ")", ")", ")", "\n", "mlp", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_down", ")", ":", "\n", "            ", "mlp", ".", "append", "(", "nn", ".", "Conv2d", "(", "C", ",", "max", "(", "C", "//", "2", ",", "64", ")", ",", "3", ",", "stride", "=", "2", ")", ")", "\n", "mlp", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "C", "=", "max", "(", "C", "//", "2", ",", "64", ")", "\n", "", "mlp", ".", "append", "(", "nn", ".", "Conv2d", "(", "C", ",", "64", ",", "3", ")", ")", "\n", "mlp", "=", "nn", ".", "Sequential", "(", "*", "mlp", ")", "\n", "init_net", "(", "mlp", ",", "self", ".", "init_type", ",", "self", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "return", "mlp", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.StridedConvF.update_moving_average": [[517, 522], ["x.detach", "x.detach"], "methods", ["None"], ["", "def", "update_moving_average", "(", "self", ",", "key", ",", "x", ")", ":", "\n", "        ", "if", "key", "not", "in", "self", ".", "moving_averages", ":", "\n", "            ", "self", ".", "moving_averages", "[", "key", "]", "=", "x", ".", "detach", "(", ")", "\n", "\n", "", "self", ".", "moving_averages", "[", "key", "]", "=", "self", ".", "moving_averages", "[", "key", "]", "*", "0.999", "+", "x", ".", "detach", "(", ")", "*", "0.001", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.StridedConvF.forward": [[523, 536], ["mlp", "networks.StridedConvF.update_moving_average", "networks.StridedConvF.l2_norm", "networks.StridedConvF.create_mlp", "networks.StridedConvF.add_module", "torch.instance_norm", "torch.instance_norm", "torch.instance_norm"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.networks.StridedConvF.update_moving_average", "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.PatchSampleF.create_mlp"], ["", "def", "forward", "(", "self", ",", "x", ",", "use_instance_norm", "=", "False", ")", ":", "\n", "        ", "C", ",", "H", "=", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "2", "]", "\n", "key", "=", "'%d_%d'", "%", "(", "C", ",", "H", ")", "\n", "if", "key", "not", "in", "self", ".", "mlps", ":", "\n", "            ", "self", ".", "mlps", "[", "key", "]", "=", "self", ".", "create_mlp", "(", "x", ")", "\n", "self", ".", "add_module", "(", "\"child_%s\"", "%", "key", ",", "self", ".", "mlps", "[", "key", "]", ")", "\n", "", "mlp", "=", "self", ".", "mlps", "[", "key", "]", "\n", "x", "=", "mlp", "(", "x", ")", "\n", "self", ".", "update_moving_average", "(", "key", ",", "x", ")", "\n", "x", "=", "x", "-", "self", ".", "moving_averages", "[", "key", "]", "\n", "if", "use_instance_norm", ":", "\n", "            ", "x", "=", "F", ".", "instance_norm", "(", "x", ")", "\n", "", "return", "self", ".", "l2_norm", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.PatchSampleF.__init__": [[539, 549], ["torch.Module.__init__", "networks.Normalize"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "use_mlp", "=", "False", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "nc", "=", "256", ",", "gpu_ids", "=", "[", "]", ")", ":", "\n", "# potential issues: currently, we use the same patch_ids for multiple images in the batch", "\n", "        ", "super", "(", "PatchSampleF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "l2norm", "=", "Normalize", "(", "2", ")", "\n", "self", ".", "use_mlp", "=", "use_mlp", "\n", "self", ".", "nc", "=", "nc", "# hard-coded", "\n", "self", ".", "mlp_init", "=", "False", "\n", "self", ".", "init_type", "=", "init_type", "\n", "self", ".", "init_gain", "=", "init_gain", "\n", "self", ".", "gpu_ids", "=", "gpu_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.PatchSampleF.create_mlp": [[550, 559], ["enumerate", "networks.init_net", "torch.Sequential", "torch.Sequential", "torch.Sequential", "setattr", "len", "torch.Sequential.cuda", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.networks.init_net"], ["", "def", "create_mlp", "(", "self", ",", "feats", ")", ":", "\n", "        ", "for", "mlp_id", ",", "feat", "in", "enumerate", "(", "feats", ")", ":", "\n", "            ", "input_nc", "=", "feat", ".", "shape", "[", "1", "]", "\n", "mlp", "=", "nn", ".", "Sequential", "(", "*", "[", "nn", ".", "Linear", "(", "input_nc", ",", "self", ".", "nc", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Linear", "(", "self", ".", "nc", ",", "self", ".", "nc", ")", "]", ")", "\n", "if", "len", "(", "self", ".", "gpu_ids", ")", ">", "0", ":", "\n", "                ", "mlp", ".", "cuda", "(", ")", "\n", "", "setattr", "(", "self", ",", "'mlp_%d'", "%", "mlp_id", ",", "mlp", ")", "\n", "", "init_net", "(", "self", ",", "self", ".", "init_type", ",", "self", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "self", ".", "mlp_init", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.PatchSampleF.forward": [[560, 590], ["enumerate", "networks.PatchSampleF.create_mlp", "feat.permute().flatten", "return_ids.append", "networks.PatchSampleF.l2norm", "return_feats.append", "feat_reshape[].flatten", "getattr", "getattr.", "x_sample.permute().reshape.permute().reshape.permute().reshape", "feat.permute", "numpy.random.permutation", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "x_sample.permute().reshape.permute().reshape.permute", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "min"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.networks.PatchSampleF.create_mlp"], ["", "def", "forward", "(", "self", ",", "feats", ",", "num_patches", "=", "64", ",", "patch_ids", "=", "None", ",", "choice", "=", "None", ",", "use_mlp", "=", "True", ")", ":", "\n", "        ", "return_ids", "=", "[", "]", "\n", "return_feats", "=", "[", "]", "\n", "if", "self", ".", "use_mlp", "and", "not", "self", ".", "mlp_init", ":", "\n", "            ", "self", ".", "create_mlp", "(", "feats", ")", "\n", "", "for", "feat_id", ",", "feat", "in", "enumerate", "(", "feats", ")", ":", "\n", "            ", "B", ",", "H", ",", "W", "=", "feat", ".", "shape", "[", "0", "]", ",", "feat", ".", "shape", "[", "2", "]", ",", "feat", ".", "shape", "[", "3", "]", "\n", "feat_reshape", "=", "feat", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "flatten", "(", "1", ",", "2", ")", "\n", "if", "num_patches", ">", "0", ":", "\n", "                ", "if", "patch_ids", "is", "not", "None", ":", "\n", "                    ", "patch_id", "=", "patch_ids", "[", "feat_id", "]", "\n", "", "else", ":", "\n", "# a potential (minor) issue: same patch_ids for multiple images in the batch", "\n", "                    ", "patch_id", "=", "np", ".", "random", ".", "permutation", "(", "feat_reshape", ".", "shape", "[", "1", "]", ")", "\n", "patch_id", "=", "torch", ".", "from_numpy", "(", "patch_id", "[", ":", "min", "(", "num_patches", ",", "patch_id", ".", "shape", "[", "0", "]", ")", "]", ")", ".", "to", "(", "feats", "[", "0", "]", ".", "device", ")", "\n", "", "x_sample", "=", "feat_reshape", "[", ":", ",", "patch_id", ",", ":", "]", ".", "flatten", "(", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "                ", "x_sample", "=", "feat_reshape", "\n", "patch_id", "=", "[", "]", "\n", "", "if", "self", ".", "use_mlp", "and", "use_mlp", ":", "\n", "                ", "feat_id", "=", "feat_id", "if", "choice", "is", "None", "else", "choice", "\n", "mlp", "=", "getattr", "(", "self", ",", "'mlp_%d'", "%", "feat_id", ")", "\n", "x_sample", "=", "mlp", "(", "x_sample", ")", "\n", "", "return_ids", ".", "append", "(", "patch_id", ")", "\n", "x_sample", "=", "self", ".", "l2norm", "(", "x_sample", ")", "\n", "\n", "if", "num_patches", "==", "0", ":", "\n", "                ", "x_sample", "=", "x_sample", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "reshape", "(", "[", "B", ",", "x_sample", ".", "shape", "[", "-", "1", "]", ",", "H", ",", "W", "]", ")", "\n", "", "return_feats", ".", "append", "(", "x_sample", ")", "\n", "", "return", "return_feats", ",", "return_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.G_Resnet.__init__": [[593, 603], ["torch.Module.__init__", "networks.ContentEncoder", "networks.Decoder", "networks.Decoder_all"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "nz", ",", "num_downs", ",", "n_res", ",", "ngf", "=", "64", ",", "\n", "norm", "=", "None", ",", "nl_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "G_Resnet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "n_downsample", "=", "num_downs", "\n", "pad_type", "=", "'reflect'", "\n", "self", ".", "enc_content", "=", "ContentEncoder", "(", "n_downsample", ",", "n_res", ",", "input_nc", ",", "ngf", ",", "norm", ",", "nl_layer", ",", "pad_type", "=", "pad_type", ")", "\n", "if", "nz", "==", "0", ":", "\n", "            ", "self", ".", "dec", "=", "Decoder", "(", "n_downsample", ",", "n_res", ",", "self", ".", "enc_content", ".", "output_dim", ",", "output_nc", ",", "norm", "=", "norm", ",", "activ", "=", "nl_layer", ",", "pad_type", "=", "pad_type", ",", "nz", "=", "nz", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dec", "=", "Decoder_all", "(", "n_downsample", ",", "n_res", ",", "self", ".", "enc_content", ".", "output_dim", ",", "output_nc", ",", "norm", "=", "norm", ",", "activ", "=", "nl_layer", ",", "pad_type", "=", "pad_type", ",", "nz", "=", "nz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.G_Resnet.decode": [[604, 606], ["networks.G_Resnet.dec"], "methods", ["None"], ["", "", "def", "decode", "(", "self", ",", "content", ",", "style", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "dec", "(", "content", ",", "style", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.G_Resnet.forward": [[607, 617], ["networks.G_Resnet.enc_content", "networks.G_Resnet.decode", "len"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.networks.G_Resnet.decode"], ["", "def", "forward", "(", "self", ",", "image", ",", "style", "=", "None", ",", "nce_layers", "=", "[", "]", ",", "encode_only", "=", "False", ")", ":", "\n", "        ", "content", ",", "feats", "=", "self", ".", "enc_content", "(", "image", ",", "nce_layers", "=", "nce_layers", ",", "encode_only", "=", "encode_only", ")", "\n", "if", "encode_only", ":", "\n", "            ", "return", "feats", "\n", "", "else", ":", "\n", "            ", "images_recon", "=", "self", ".", "decode", "(", "content", ",", "style", ")", "\n", "if", "len", "(", "nce_layers", ")", ">", "0", ":", "\n", "                ", "return", "images_recon", ",", "feats", "\n", "", "else", ":", "\n", "                ", "return", "images_recon", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.E_adaIN.__init__": [[624, 629], ["torch.Module.__init__", "networks.StyleEncoder"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", "=", "1", ",", "nef", "=", "64", ",", "n_layers", "=", "4", ",", "\n", "norm", "=", "None", ",", "nl_layer", "=", "None", ",", "vae", "=", "False", ")", ":", "\n", "# style encoder", "\n", "        ", "super", "(", "E_adaIN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "enc_style", "=", "StyleEncoder", "(", "n_layers", ",", "input_nc", ",", "nef", ",", "output_nc", ",", "norm", "=", "'none'", ",", "activ", "=", "'relu'", ",", "vae", "=", "vae", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.E_adaIN.forward": [[630, 633], ["networks.E_adaIN.enc_style"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "image", ")", ":", "\n", "        ", "style", "=", "self", ".", "enc_style", "(", "image", ")", "\n", "return", "style", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.StyleEncoder.__init__": [[636, 655], ["torch.Module.__init__", "range", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "networks.Conv2dBlock", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "networks.Conv2dBlock", "networks.Conv2dBlock", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_downsample", ",", "input_dim", ",", "dim", ",", "style_dim", ",", "norm", ",", "activ", ",", "vae", "=", "False", ")", ":", "\n", "        ", "super", "(", "StyleEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vae", "=", "vae", "\n", "self", ".", "model", "=", "[", "]", "\n", "self", ".", "model", "+=", "[", "Conv2dBlock", "(", "input_dim", ",", "dim", ",", "7", ",", "1", ",", "3", ",", "norm", "=", "norm", ",", "activation", "=", "activ", ",", "pad_type", "=", "'reflect'", ")", "]", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "            ", "self", ".", "model", "+=", "[", "Conv2dBlock", "(", "dim", ",", "2", "*", "dim", ",", "4", ",", "2", ",", "1", ",", "norm", "=", "norm", ",", "activation", "=", "activ", ",", "pad_type", "=", "'reflect'", ")", "]", "\n", "dim", "*=", "2", "\n", "", "for", "i", "in", "range", "(", "n_downsample", "-", "2", ")", ":", "\n", "            ", "self", ".", "model", "+=", "[", "Conv2dBlock", "(", "dim", ",", "dim", ",", "4", ",", "2", ",", "1", ",", "norm", "=", "norm", ",", "activation", "=", "activ", ",", "pad_type", "=", "'reflect'", ")", "]", "\n", "", "self", ".", "model", "+=", "[", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "]", "# global average pooling", "\n", "if", "self", ".", "vae", ":", "\n", "            ", "self", ".", "fc_mean", "=", "nn", ".", "Linear", "(", "dim", ",", "style_dim", ")", "# , 1, 1, 0)", "\n", "self", ".", "fc_var", "=", "nn", ".", "Linear", "(", "dim", ",", "style_dim", ")", "# , 1, 1, 0)", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", "+=", "[", "nn", ".", "Conv2d", "(", "dim", ",", "style_dim", ",", "1", ",", "1", ",", "0", ")", "]", "\n", "\n", "", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "model", ")", "\n", "self", ".", "output_dim", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.StyleEncoder.forward": [[656, 665], ["networks.StyleEncoder.model", "output.view.view.view", "networks.StyleEncoder.fc_mean", "networks.StyleEncoder.fc_var", "networks.StyleEncoder.model().view", "x.size", "x.size", "networks.StyleEncoder.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "vae", ":", "\n", "            ", "output", "=", "self", ".", "model", "(", "x", ")", "\n", "output", "=", "output", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "output_mean", "=", "self", ".", "fc_mean", "(", "output", ")", "\n", "output_var", "=", "self", ".", "fc_var", "(", "output", ")", "\n", "return", "output_mean", ",", "output_var", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "model", "(", "x", ")", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.ContentEncoder.__init__": [[668, 680], ["torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "networks.Conv2dBlock", "networks.ResBlocks", "networks.Conv2dBlock"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_downsample", ",", "n_res", ",", "input_dim", ",", "dim", ",", "norm", ",", "activ", ",", "pad_type", "=", "'zero'", ")", ":", "\n", "        ", "super", "(", "ContentEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "[", "]", "\n", "self", ".", "model", "+=", "[", "Conv2dBlock", "(", "input_dim", ",", "dim", ",", "7", ",", "1", ",", "3", ",", "norm", "=", "norm", ",", "activation", "=", "activ", ",", "pad_type", "=", "'reflect'", ")", "]", "\n", "# downsampling blocks", "\n", "for", "i", "in", "range", "(", "n_downsample", ")", ":", "\n", "            ", "self", ".", "model", "+=", "[", "Conv2dBlock", "(", "dim", ",", "2", "*", "dim", ",", "4", ",", "2", ",", "1", ",", "norm", "=", "norm", ",", "activation", "=", "activ", ",", "pad_type", "=", "'reflect'", ")", "]", "\n", "dim", "*=", "2", "\n", "# residual blocks", "\n", "", "self", ".", "model", "+=", "[", "ResBlocks", "(", "n_res", ",", "dim", ",", "norm", "=", "norm", ",", "activation", "=", "activ", ",", "pad_type", "=", "pad_type", ")", "]", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "model", ")", "\n", "self", ".", "output_dim", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.ContentEncoder.forward": [[681, 697], ["enumerate", "len", "enumerate", "print", "layer", "networks.ContentEncoder.model", "feats.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "nce_layers", "=", "[", "]", ",", "encode_only", "=", "False", ")", ":", "\n", "        ", "if", "len", "(", "nce_layers", ")", ">", "0", ":", "\n", "            ", "feat", "=", "x", "\n", "feats", "=", "[", "]", "\n", "for", "layer_id", ",", "layer", "in", "enumerate", "(", "self", ".", "model", ")", ":", "\n", "                ", "feat", "=", "layer", "(", "feat", ")", "\n", "if", "layer_id", "in", "nce_layers", ":", "\n", "                    ", "feats", ".", "append", "(", "feat", ")", "\n", "", "if", "layer_id", "==", "nce_layers", "[", "-", "1", "]", "and", "encode_only", ":", "\n", "                    ", "return", "None", ",", "feats", "\n", "", "", "return", "feat", ",", "feats", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "model", "(", "x", ")", ",", "None", "\n", "\n", "", "for", "layer_id", ",", "layer", "in", "enumerate", "(", "self", ".", "model", ")", ":", "\n", "            ", "print", "(", "layer_id", ",", "layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.Decoder_all.__init__": [[700, 714], ["torch.Module.__init__", "networks.ResBlocks", "range", "setattr", "setattr", "networks.Conv2dBlock", "networks.Upsample2", "networks.Conv2dBlock", "torch.Sequential", "torch.Sequential", "torch.Sequential"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_upsample", ",", "n_res", ",", "dim", ",", "output_dim", ",", "norm", "=", "'batch'", ",", "activ", "=", "'relu'", ",", "pad_type", "=", "'zero'", ",", "nz", "=", "0", ")", ":", "\n", "        ", "super", "(", "Decoder_all", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# AdaIN residual blocks", "\n", "self", ".", "resnet_block", "=", "ResBlocks", "(", "n_res", ",", "dim", ",", "norm", ",", "activ", ",", "pad_type", "=", "pad_type", ",", "nz", "=", "nz", ")", "\n", "self", ".", "n_blocks", "=", "0", "\n", "# upsampling blocks", "\n", "for", "i", "in", "range", "(", "n_upsample", ")", ":", "\n", "            ", "block", "=", "[", "Upsample2", "(", "scale_factor", "=", "2", ")", ",", "Conv2dBlock", "(", "dim", "+", "nz", ",", "dim", "//", "2", ",", "5", ",", "1", ",", "2", ",", "norm", "=", "'ln'", ",", "activation", "=", "activ", ",", "pad_type", "=", "'reflect'", ")", "]", "\n", "setattr", "(", "self", ",", "'block_{:d}'", ".", "format", "(", "self", ".", "n_blocks", ")", ",", "nn", ".", "Sequential", "(", "*", "block", ")", ")", "\n", "self", ".", "n_blocks", "+=", "1", "\n", "dim", "//=", "2", "\n", "# use reflection padding in the last conv layer", "\n", "", "setattr", "(", "self", ",", "'block_{:d}'", ".", "format", "(", "self", ".", "n_blocks", ")", ",", "Conv2dBlock", "(", "dim", "+", "nz", ",", "output_dim", ",", "7", ",", "1", ",", "3", ",", "norm", "=", "'none'", ",", "activation", "=", "'tanh'", ",", "pad_type", "=", "'reflect'", ")", ")", "\n", "self", ".", "n_blocks", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.Decoder_all.forward": [[715, 725], ["networks.Decoder_all.resnet_block", "range", "networks.cat_feature", "getattr", "getattr.", "getattr.", "networks.cat_feature"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.networks.cat_feature", "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.cat_feature"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", "=", "None", ")", ":", "\n", "        ", "if", "y", "is", "not", "None", ":", "\n", "            ", "output", "=", "self", ".", "resnet_block", "(", "cat_feature", "(", "x", ",", "y", ")", ")", "\n", "for", "n", "in", "range", "(", "self", ".", "n_blocks", ")", ":", "\n", "                ", "block", "=", "getattr", "(", "self", ",", "'block_{:d}'", ".", "format", "(", "n", ")", ")", "\n", "if", "n", ">", "0", ":", "\n", "                    ", "output", "=", "block", "(", "cat_feature", "(", "output", ",", "y", ")", ")", "\n", "", "else", ":", "\n", "                    ", "output", "=", "block", "(", "output", ")", "\n", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.Decoder.__init__": [[728, 745], ["torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "networks.ResBlocks", "networks.Conv2dBlock", "networks.Upsample2", "networks.Conv2dBlock"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_upsample", ",", "n_res", ",", "dim", ",", "output_dim", ",", "norm", "=", "'batch'", ",", "activ", "=", "'relu'", ",", "pad_type", "=", "'zero'", ",", "nz", "=", "0", ")", ":", "\n", "        ", "super", "(", "Decoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "model", "=", "[", "]", "\n", "# AdaIN residual blocks", "\n", "self", ".", "model", "+=", "[", "ResBlocks", "(", "n_res", ",", "dim", ",", "norm", ",", "activ", ",", "pad_type", "=", "pad_type", ",", "nz", "=", "nz", ")", "]", "\n", "# upsampling blocks", "\n", "for", "i", "in", "range", "(", "n_upsample", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "input_dim", "=", "dim", "+", "nz", "\n", "", "else", ":", "\n", "                ", "input_dim", "=", "dim", "\n", "", "self", ".", "model", "+=", "[", "Upsample2", "(", "scale_factor", "=", "2", ")", ",", "Conv2dBlock", "(", "input_dim", ",", "dim", "//", "2", ",", "5", ",", "1", ",", "2", ",", "norm", "=", "'ln'", ",", "activation", "=", "activ", ",", "pad_type", "=", "'reflect'", ")", "]", "\n", "dim", "//=", "2", "\n", "# use reflection padding in the last conv layer", "\n", "", "self", ".", "model", "+=", "[", "Conv2dBlock", "(", "dim", ",", "output_dim", ",", "7", ",", "1", ",", "3", ",", "norm", "=", "'none'", ",", "activation", "=", "'tanh'", ",", "pad_type", "=", "'reflect'", ")", "]", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.Decoder.forward": [[746, 751], ["networks.Decoder.model", "networks.Decoder.model", "networks.cat_feature"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.networks.cat_feature"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", "=", "None", ")", ":", "\n", "        ", "if", "y", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "model", "(", "cat_feature", "(", "x", ",", "y", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "model", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.ResBlocks.__init__": [[758, 764], ["torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "networks.ResBlock"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_blocks", ",", "dim", ",", "norm", "=", "'inst'", ",", "activation", "=", "'relu'", ",", "pad_type", "=", "'zero'", ",", "nz", "=", "0", ")", ":", "\n", "        ", "super", "(", "ResBlocks", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_blocks", ")", ":", "\n", "            ", "self", ".", "model", "+=", "[", "ResBlock", "(", "dim", ",", "norm", "=", "norm", ",", "activation", "=", "activation", ",", "pad_type", "=", "pad_type", ",", "nz", "=", "nz", ")", "]", "\n", "", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.ResBlocks.forward": [[765, 767], ["networks.ResBlocks.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "model", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.ResBlock.__init__": [[780, 787], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "networks.Conv2dBlock", "networks.Conv2dBlock"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "norm", "=", "'inst'", ",", "activation", "=", "'relu'", ",", "pad_type", "=", "'zero'", ",", "nz", "=", "0", ")", ":", "\n", "        ", "super", "(", "ResBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "model", "=", "[", "]", "\n", "model", "+=", "[", "Conv2dBlock", "(", "dim", "+", "nz", ",", "dim", ",", "3", ",", "1", ",", "1", ",", "norm", "=", "norm", ",", "activation", "=", "activation", ",", "pad_type", "=", "pad_type", ")", "]", "\n", "model", "+=", "[", "Conv2dBlock", "(", "dim", ",", "dim", "+", "nz", ",", "3", ",", "1", ",", "1", ",", "norm", "=", "norm", ",", "activation", "=", "'none'", ",", "pad_type", "=", "pad_type", ")", "]", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.ResBlock.forward": [[788, 793], ["networks.ResBlock.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "out", "=", "self", ".", "model", "(", "x", ")", "\n", "out", "+=", "residual", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.Conv2dBlock.__init__": [[796, 839], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "networks.LayerNorm", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.SELU", "torch.SELU", "torch.SELU", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "output_dim", ",", "kernel_size", ",", "stride", ",", "\n", "padding", "=", "0", ",", "norm", "=", "'none'", ",", "activation", "=", "'relu'", ",", "pad_type", "=", "'zero'", ")", ":", "\n", "        ", "super", "(", "Conv2dBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "use_bias", "=", "True", "\n", "# initialize padding", "\n", "if", "pad_type", "==", "'reflect'", ":", "\n", "            ", "self", ".", "pad", "=", "nn", ".", "ReflectionPad2d", "(", "padding", ")", "\n", "", "elif", "pad_type", "==", "'zero'", ":", "\n", "            ", "self", ".", "pad", "=", "nn", ".", "ZeroPad2d", "(", "padding", ")", "\n", "", "else", ":", "\n", "            ", "assert", "0", ",", "\"Unsupported padding type: {}\"", ".", "format", "(", "pad_type", ")", "\n", "\n", "# initialize normalization", "\n", "", "norm_dim", "=", "output_dim", "\n", "if", "norm", "==", "'batch'", ":", "\n", "            ", "self", ".", "norm", "=", "nn", ".", "BatchNorm2d", "(", "norm_dim", ")", "\n", "", "elif", "norm", "==", "'inst'", ":", "\n", "            ", "self", ".", "norm", "=", "nn", ".", "InstanceNorm2d", "(", "norm_dim", ",", "track_running_stats", "=", "False", ")", "\n", "", "elif", "norm", "==", "'ln'", ":", "\n", "            ", "self", ".", "norm", "=", "LayerNorm", "(", "norm_dim", ")", "\n", "", "elif", "norm", "==", "'none'", ":", "\n", "            ", "self", ".", "norm", "=", "None", "\n", "", "else", ":", "\n", "            ", "assert", "0", ",", "\"Unsupported normalization: {}\"", ".", "format", "(", "norm", ")", "\n", "\n", "# initialize activation", "\n", "", "if", "activation", "==", "'relu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "", "elif", "activation", "==", "'lrelu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", "\n", "", "elif", "activation", "==", "'prelu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "PReLU", "(", ")", "\n", "", "elif", "activation", "==", "'selu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "SELU", "(", "inplace", "=", "True", ")", "\n", "", "elif", "activation", "==", "'tanh'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "", "elif", "activation", "==", "'none'", ":", "\n", "            ", "self", ".", "activation", "=", "None", "\n", "", "else", ":", "\n", "            ", "assert", "0", ",", "\"Unsupported activation: {}\"", ".", "format", "(", "activation", ")", "\n", "\n", "# initialize convolution", "\n", "", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "input_dim", ",", "output_dim", ",", "kernel_size", ",", "stride", ",", "bias", "=", "self", ".", "use_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.Conv2dBlock.forward": [[840, 847], ["networks.Conv2dBlock.conv", "networks.Conv2dBlock.pad", "networks.Conv2dBlock.norm", "networks.Conv2dBlock.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv", "(", "self", ".", "pad", "(", "x", ")", ")", "\n", "if", "self", ".", "norm", ":", "\n", "            ", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "", "if", "self", ".", "activation", ":", "\n", "            ", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.LinearBlock.__init__": [[850, 884], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.InstanceNorm1d", "torch.InstanceNorm1d", "torch.InstanceNorm1d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "networks.LayerNorm", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.SELU", "torch.SELU", "torch.SELU", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "output_dim", ",", "norm", "=", "'none'", ",", "activation", "=", "'relu'", ")", ":", "\n", "        ", "super", "(", "LinearBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "use_bias", "=", "True", "\n", "# initialize fully connected layer", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ",", "bias", "=", "use_bias", ")", "\n", "\n", "# initialize normalization", "\n", "norm_dim", "=", "output_dim", "\n", "if", "norm", "==", "'batch'", ":", "\n", "            ", "self", ".", "norm", "=", "nn", ".", "BatchNorm1d", "(", "norm_dim", ")", "\n", "", "elif", "norm", "==", "'inst'", ":", "\n", "            ", "self", ".", "norm", "=", "nn", ".", "InstanceNorm1d", "(", "norm_dim", ")", "\n", "", "elif", "norm", "==", "'ln'", ":", "\n", "            ", "self", ".", "norm", "=", "LayerNorm", "(", "norm_dim", ")", "\n", "", "elif", "norm", "==", "'none'", ":", "\n", "            ", "self", ".", "norm", "=", "None", "\n", "", "else", ":", "\n", "            ", "assert", "0", ",", "\"Unsupported normalization: {}\"", ".", "format", "(", "norm", ")", "\n", "\n", "# initialize activation", "\n", "", "if", "activation", "==", "'relu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "", "elif", "activation", "==", "'lrelu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", "\n", "", "elif", "activation", "==", "'prelu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "PReLU", "(", ")", "\n", "", "elif", "activation", "==", "'selu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "SELU", "(", "inplace", "=", "True", ")", "\n", "", "elif", "activation", "==", "'tanh'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "", "elif", "activation", "==", "'none'", ":", "\n", "            ", "self", ".", "activation", "=", "None", "\n", "", "else", ":", "\n", "            ", "assert", "0", ",", "\"Unsupported activation: {}\"", ".", "format", "(", "activation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.LinearBlock.forward": [[885, 892], ["networks.LinearBlock.fc", "networks.LinearBlock.norm", "networks.LinearBlock.activation"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "fc", "(", "x", ")", "\n", "if", "self", ".", "norm", ":", "\n", "            ", "out", "=", "self", ".", "norm", "(", "out", ")", "\n", "", "if", "self", ".", "activation", ":", "\n", "            ", "out", "=", "self", ".", "activation", "(", "out", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.LayerNorm.__init__": [[899, 908], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "eps", "=", "1e-5", ",", "affine", "=", "True", ")", ":", "\n", "        ", "super", "(", "LayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "affine", "=", "affine", "\n", "self", ".", "eps", "=", "eps", "\n", "\n", "if", "self", ".", "affine", ":", "\n", "            ", "self", ".", "gamma", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_features", ")", ".", "uniform_", "(", ")", ")", "\n", "self", ".", "beta", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_features", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.LayerNorm.forward": [[909, 919], ["x.view().mean().view", "x.view().std().view", "x.view().mean", "x.view().std", "networks.LayerNorm.beta.view", "x.dim", "networks.LayerNorm.gamma.view", "x.view", "x.view", "x.dim", "x.size", "x.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shape", "=", "[", "-", "1", "]", "+", "[", "1", "]", "*", "(", "x", ".", "dim", "(", ")", "-", "1", ")", "\n", "mean", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", ".", "mean", "(", "1", ")", ".", "view", "(", "*", "shape", ")", "\n", "std", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", ".", "std", "(", "1", ")", ".", "view", "(", "*", "shape", ")", "\n", "x", "=", "(", "x", "-", "mean", ")", "/", "(", "std", "+", "self", ".", "eps", ")", "\n", "\n", "if", "self", ".", "affine", ":", "\n", "            ", "shape", "=", "[", "1", ",", "-", "1", "]", "+", "[", "1", "]", "*", "(", "x", ".", "dim", "(", ")", "-", "2", ")", "\n", "x", "=", "x", "*", "self", ".", "gamma", ".", "view", "(", "*", "shape", ")", "+", "self", ".", "beta", ".", "view", "(", "*", "shape", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.ResnetGenerator.__init__": [[927, 992], ["torch.Module.__init__", "range", "range", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Tanh", "torch.Tanh", "torch.Tanh", "networks.ResnetBlock", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "networks.Downsample", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "networks.Upsample", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "ngf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ",", "n_blocks", "=", "6", ",", "padding_type", "=", "'reflect'", ",", "no_antialias", "=", "False", ",", "no_antialias_up", "=", "False", ",", "opt", "=", "None", ")", ":", "\n", "        ", "\"\"\"Construct a Resnet-based generator\n\n        Parameters:\n            input_nc (int)      -- the number of channels in input images\n            output_nc (int)     -- the number of channels in output images\n            ngf (int)           -- the number of filters in the last conv layer\n            norm_layer          -- normalization layer\n            use_dropout (bool)  -- if use dropout layers\n            n_blocks (int)      -- the number of ResNet blocks\n            padding_type (str)  -- the name of padding layer in conv layers: reflect | replicate | zero\n        \"\"\"", "\n", "assert", "(", "n_blocks", ">=", "0", ")", "\n", "super", "(", "ResnetGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "model", "=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", ",", "\n", "nn", ".", "Conv2d", "(", "input_nc", ",", "ngf", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "\n", "n_downsampling", "=", "2", "\n", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "# add downsampling layers", "\n", "            ", "mult", "=", "2", "**", "i", "\n", "if", "(", "no_antialias", ")", ":", "\n", "                ", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", "*", "mult", ",", "ngf", "*", "mult", "*", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", "*", "mult", "*", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "", "else", ":", "\n", "                ", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", "*", "mult", ",", "ngf", "*", "mult", "*", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", "*", "mult", "*", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "Downsample", "(", "ngf", "*", "mult", "*", "2", ")", "]", "\n", "\n", "", "", "mult", "=", "2", "**", "n_downsampling", "\n", "for", "i", "in", "range", "(", "n_blocks", ")", ":", "# add ResNet blocks", "\n", "\n", "            ", "model", "+=", "[", "ResnetBlock", "(", "ngf", "*", "mult", ",", "padding_type", "=", "padding_type", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "use_bias", "=", "use_bias", ")", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "# add upsampling layers", "\n", "            ", "mult", "=", "2", "**", "(", "n_downsampling", "-", "i", ")", "\n", "if", "no_antialias_up", ":", "\n", "                ", "model", "+=", "[", "nn", ".", "ConvTranspose2d", "(", "ngf", "*", "mult", ",", "int", "(", "ngf", "*", "mult", "/", "2", ")", ",", "\n", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "output_padding", "=", "1", ",", "\n", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "int", "(", "ngf", "*", "mult", "/", "2", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "", "else", ":", "\n", "                ", "model", "+=", "[", "Upsample", "(", "ngf", "*", "mult", ")", ",", "\n", "nn", ".", "Conv2d", "(", "ngf", "*", "mult", ",", "int", "(", "ngf", "*", "mult", "/", "2", ")", ",", "\n", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "# output_padding=1,", "\n", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "int", "(", "ngf", "*", "mult", "/", "2", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "", "", "model", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", "]", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", ",", "output_nc", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ")", "]", "\n", "model", "+=", "[", "nn", ".", "Tanh", "(", ")", "]", "\n", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.ResnetGenerator.forward": [[993, 1048], ["enumerate", "enumerate", "len", "zip", "layers.append", "len", "enumerate", "enumerate", "layer", "len", "len", "len", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "unit_noise.div.div.pow().sum().pow", "unit_noise.div.div.div", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "sampled_noise_magnitude.append", "feats_perturbed.append", "len", "layer", "layer", "layer", "list", "layer", "list", "layer", "feats.append", "unit_noise.div.div.pow().sum", "layer.size", "layer.size", "layer.size", "unit_noise.div.div.pow"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", "=", "None", ",", "layers", "=", "[", "]", ",", "encode_only", "=", "False", ",", "enc", "=", "False", ",", "dec", "=", "False", ",", "feats", "=", "[", "]", ",", "noises", "=", "[", "]", ")", ":", "\n", "        ", "if", "enc", ":", "\n", "            ", "fake", "=", "input", "\n", "for", "layer_id", ",", "layer", "in", "enumerate", "(", "self", ".", "model", ")", ":", "\n", "                ", "fake", "=", "layer", "(", "fake", ")", "\n", "if", "layer_id", "==", "16", ":", "\n", "                    ", "return", "fake", "\n", "", "", "", "if", "dec", ":", "\n", "            ", "fake", "=", "input", "\n", "for", "layer_id", ",", "layer", "in", "enumerate", "(", "self", ".", "model", ")", ":", "\n", "                ", "if", "layer_id", ">", "16", ":", "\n", "                    ", "fake", "=", "layer", "(", "fake", ")", "\n", "", "", "return", "fake", "\n", "\n", "", "if", "len", "(", "noises", ")", ">", "0", ":", "\n", "            ", "assert", "len", "(", "noises", ")", "==", "len", "(", "feats", ")", "==", "len", "(", "layers", ")", "\n", "feats_perturbed", ",", "sampled_noise_magnitude", "=", "[", "]", ",", "[", "]", "\n", "for", "noise", ",", "layer_id", ",", "feat", "in", "zip", "(", "noises", ",", "layers", ",", "feats", ")", ":", "\n", "                ", "unit_noise", "=", "torch", ".", "randn", "(", "*", "feat", ".", "shape", ",", "device", "=", "feat", ".", "device", ")", "\n", "norm", "=", "unit_noise", ".", "pow", "(", "2", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ".", "pow", "(", "0.5", ")", "\n", "unit_noise", "=", "unit_noise", ".", "div", "(", "norm", "+", "1e-12", ")", "\n", "rand_magnitude", "=", "torch", ".", "rand", "(", "\n", "[", "feat", ".", "size", "(", "0", ")", ",", "1", ",", "feat", ".", "size", "(", "2", ")", ",", "feat", ".", "size", "(", "3", ")", "]", ",", "device", "=", "feat", ".", "device", ")", "\n", "noise_magnitude", "=", "1e-7", "+", "(", "noise", "-", "1e-7", ")", "*", "rand_magnitude", "# 1e-7 is the minimum magnitude", "\n", "sampled_noise_magnitude", ".", "append", "(", "noise_magnitude", ")", "\n", "feat", "=", "feat", "+", "unit_noise", "*", "noise", "\n", "for", "layer", "in", "list", "(", "self", ".", "model", ")", "[", "layer_id", "+", "1", ":", "]", ":", "\n", "                    ", "feat", "=", "layer", "(", "feat", ")", "\n", "", "for", "layer", "in", "list", "(", "self", ".", "model", ")", "[", ":", "layer_id", "+", "1", "]", ":", "\n", "                    ", "feat", "=", "layer", "(", "feat", ")", "\n", "", "feats_perturbed", ".", "append", "(", "feat", ")", "\n", "", "return", "feats_perturbed", ",", "sampled_noise_magnitude", "\n", "\n", "", "if", "-", "1", "in", "layers", ":", "\n", "            ", "layers", ".", "append", "(", "len", "(", "self", ".", "model", ")", ")", "\n", "\n", "", "if", "len", "(", "layers", ")", ">", "0", ":", "\n", "            ", "feat", "=", "input", "\n", "feats", "=", "[", "]", "\n", "for", "layer_id", ",", "layer", "in", "enumerate", "(", "self", ".", "model", ")", ":", "\n", "                ", "feat", "=", "layer", "(", "feat", ")", "\n", "if", "layer_id", "in", "layers", ":", "\n", "                    ", "feats", ".", "append", "(", "feat", ")", "\n", "", "if", "layer_id", "==", "layers", "[", "-", "1", "]", "and", "encode_only", ":", "\n", "# print('encoder only return features')", "\n", "                    ", "return", "feats", "# return intermediate features alone; stop in the last layers", "\n", "", "", "return", "feat", ",", "feats", "# return both output and intermediate features", "\n", "", "else", ":", "\n", "            ", "\"\"\"Standard forward\"\"\"", "\n", "fake", "=", "input", "\n", "for", "layer_id", ",", "layer", "in", "enumerate", "(", "self", ".", "model", ")", ":", "\n", "                ", "fake", "=", "layer", "(", "fake", ")", "\n", "if", "layer_id", "==", "16", ":", "\n", "                    ", "feat", "=", "fake", "\n", "", "", "return", "fake", ",", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.ResnetDecoder.__init__": [[1054, 1101], ["torch.Module.__init__", "range", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Tanh", "torch.Tanh", "torch.Tanh", "networks.ResnetBlock", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "networks.Upsample", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "ngf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ",", "n_blocks", "=", "6", ",", "padding_type", "=", "'reflect'", ",", "no_antialias", "=", "False", ")", ":", "\n", "        ", "\"\"\"Construct a Resnet-based decoder\n\n        Parameters:\n            input_nc (int)      -- the number of channels in input images\n            output_nc (int)     -- the number of channels in output images\n            ngf (int)           -- the number of filters in the last conv layer\n            norm_layer          -- normalization layer\n            use_dropout (bool)  -- if use dropout layers\n            n_blocks (int)      -- the number of ResNet blocks\n            padding_type (str)  -- the name of padding layer in conv layers: reflect | replicate | zero\n        \"\"\"", "\n", "assert", "(", "n_blocks", ">=", "0", ")", "\n", "super", "(", "ResnetDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "", "model", "=", "[", "]", "\n", "n_downsampling", "=", "2", "\n", "mult", "=", "2", "**", "n_downsampling", "\n", "for", "i", "in", "range", "(", "n_blocks", ")", ":", "# add ResNet blocks", "\n", "\n", "            ", "model", "+=", "[", "ResnetBlock", "(", "ngf", "*", "mult", ",", "padding_type", "=", "padding_type", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "use_bias", "=", "use_bias", ")", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "# add upsampling layers", "\n", "            ", "mult", "=", "2", "**", "(", "n_downsampling", "-", "i", ")", "\n", "if", "(", "no_antialias", ")", ":", "\n", "                ", "model", "+=", "[", "nn", ".", "ConvTranspose2d", "(", "ngf", "*", "mult", ",", "int", "(", "ngf", "*", "mult", "/", "2", ")", ",", "\n", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "output_padding", "=", "1", ",", "\n", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "int", "(", "ngf", "*", "mult", "/", "2", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "", "else", ":", "\n", "                ", "model", "+=", "[", "Upsample", "(", "ngf", "*", "mult", ")", ",", "\n", "nn", ".", "Conv2d", "(", "ngf", "*", "mult", ",", "int", "(", "ngf", "*", "mult", "/", "2", ")", ",", "\n", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "int", "(", "ngf", "*", "mult", "/", "2", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "", "", "model", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", "]", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", ",", "output_nc", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ")", "]", "\n", "model", "+=", "[", "nn", ".", "Tanh", "(", ")", "]", "\n", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.ResnetDecoder.forward": [[1102, 1105], ["networks.ResnetDecoder.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward\"\"\"", "\n", "return", "self", ".", "model", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.ResnetEncoder.__init__": [[1111, 1154], ["torch.Module.__init__", "range", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "networks.ResnetBlock", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "networks.Downsample"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "ngf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ",", "n_blocks", "=", "6", ",", "padding_type", "=", "'reflect'", ",", "no_antialias", "=", "False", ")", ":", "\n", "        ", "\"\"\"Construct a Resnet-based encoder\n\n        Parameters:\n            input_nc (int)      -- the number of channels in input images\n            output_nc (int)     -- the number of channels in output images\n            ngf (int)           -- the number of filters in the last conv layer\n            norm_layer          -- normalization layer\n            use_dropout (bool)  -- if use dropout layers\n            n_blocks (int)      -- the number of ResNet blocks\n            padding_type (str)  -- the name of padding layer in conv layers: reflect | replicate | zero\n        \"\"\"", "\n", "assert", "(", "n_blocks", ">=", "0", ")", "\n", "super", "(", "ResnetEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "model", "=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", ",", "\n", "nn", ".", "Conv2d", "(", "input_nc", ",", "ngf", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "\n", "n_downsampling", "=", "2", "\n", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "# add downsampling layers", "\n", "            ", "mult", "=", "2", "**", "i", "\n", "if", "(", "no_antialias", ")", ":", "\n", "                ", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", "*", "mult", ",", "ngf", "*", "mult", "*", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", "*", "mult", "*", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "", "else", ":", "\n", "                ", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", "*", "mult", ",", "ngf", "*", "mult", "*", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", "*", "mult", "*", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "Downsample", "(", "ngf", "*", "mult", "*", "2", ")", "]", "\n", "\n", "", "", "mult", "=", "2", "**", "n_downsampling", "\n", "for", "i", "in", "range", "(", "n_blocks", ")", ":", "# add ResNet blocks", "\n", "\n", "            ", "model", "+=", "[", "ResnetBlock", "(", "ngf", "*", "mult", ",", "padding_type", "=", "padding_type", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "use_bias", "=", "use_bias", ")", "]", "\n", "\n", "", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.ResnetEncoder.forward": [[1155, 1158], ["networks.ResnetEncoder.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward\"\"\"", "\n", "return", "self", ".", "model", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.ResnetBlock.__init__": [[1163, 1173], ["torch.Module.__init__", "networks.ResnetBlock.build_conv_block"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.ResnetBlock.build_conv_block"], ["def", "__init__", "(", "self", ",", "dim", ",", "padding_type", ",", "norm_layer", ",", "use_dropout", ",", "use_bias", ")", ":", "\n", "        ", "\"\"\"Initialize the Resnet block\n\n        A resnet block is a conv block with skip connections\n        We construct a conv block with build_conv_block function,\n        and implement skip connections in <forward> function.\n        Original Resnet paper: https://arxiv.org/pdf/1512.03385.pdf\n        \"\"\"", "\n", "super", "(", "ResnetBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_block", "=", "self", ".", "build_conv_block", "(", "dim", ",", "padding_type", ",", "norm_layer", ",", "use_dropout", ",", "use_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.ResnetBlock.build_conv_block": [[1174, 1213], ["torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "NotImplementedError", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "NotImplementedError"], "methods", ["None"], ["", "def", "build_conv_block", "(", "self", ",", "dim", ",", "padding_type", ",", "norm_layer", ",", "use_dropout", ",", "use_bias", ")", ":", "\n", "        ", "\"\"\"Construct a convolutional block.\n\n        Parameters:\n            dim (int)           -- the number of channels in the conv layer.\n            padding_type (str)  -- the name of padding layer: reflect | replicate | zero\n            norm_layer          -- normalization layer\n            use_dropout (bool)  -- if use dropout layers.\n            use_bias (bool)     -- if the conv layer uses bias or not\n\n        Returns a conv block (with a conv layer, a normalization layer, and a non-linearity layer (ReLU))\n        \"\"\"", "\n", "conv_block", "=", "[", "]", "\n", "p", "=", "0", "\n", "if", "padding_type", "==", "'reflect'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'replicate'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReplicationPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'zero'", ":", "\n", "            ", "p", "=", "1", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'padding [%s] is not implemented'", "%", "padding_type", ")", "\n", "\n", "", "conv_block", "+=", "[", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "kernel_size", "=", "3", ",", "padding", "=", "p", ",", "bias", "=", "use_bias", ")", ",", "norm_layer", "(", "dim", ")", ",", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "if", "use_dropout", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "Dropout", "(", "0.5", ")", "]", "\n", "\n", "", "p", "=", "0", "\n", "if", "padding_type", "==", "'reflect'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'replicate'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReplicationPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'zero'", ":", "\n", "            ", "p", "=", "1", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'padding [%s] is not implemented'", "%", "padding_type", ")", "\n", "", "conv_block", "+=", "[", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "kernel_size", "=", "3", ",", "padding", "=", "p", ",", "bias", "=", "use_bias", ")", ",", "norm_layer", "(", "dim", ")", "]", "\n", "\n", "return", "nn", ".", "Sequential", "(", "*", "conv_block", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.ResnetBlock.forward": [[1214, 1218], ["networks.ResnetBlock.conv_block"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Forward function (with skip connections)\"\"\"", "\n", "out", "=", "x", "+", "self", ".", "conv_block", "(", "x", ")", "# add skip connections", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.UnetGenerator.__init__": [[1223, 1246], ["torch.Module.__init__", "networks.UnetSkipConnectionBlock", "range", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "num_downs", ",", "ngf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ")", ":", "\n", "        ", "\"\"\"Construct a Unet generator\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            output_nc (int) -- the number of channels in output images\n            num_downs (int) -- the number of downsamplings in UNet. For example, # if |num_downs| == 7,\n                                image of size 128x128 will become of size 1x1 # at the bottleneck\n            ngf (int)       -- the number of filters in the last conv layer\n            norm_layer      -- normalization layer\n\n        We construct the U-Net from the innermost layer to the outermost layer.\n        It is a recursive process.\n        \"\"\"", "\n", "super", "(", "UnetGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# construct unet structure", "\n", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "8", ",", "ngf", "*", "8", ",", "input_nc", "=", "None", ",", "submodule", "=", "None", ",", "norm_layer", "=", "norm_layer", ",", "innermost", "=", "True", ")", "# add the innermost layer", "\n", "for", "i", "in", "range", "(", "num_downs", "-", "5", ")", ":", "# add intermediate layers with ngf * 8 filters", "\n", "            ", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "8", ",", "ngf", "*", "8", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ")", "\n", "# gradually reduce the number of filters from ngf * 8 to ngf", "\n", "", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "4", ",", "ngf", "*", "8", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ")", "\n", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "2", ",", "ngf", "*", "4", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ")", "\n", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", ",", "ngf", "*", "2", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "model", "=", "UnetSkipConnectionBlock", "(", "output_nc", ",", "ngf", ",", "input_nc", "=", "input_nc", ",", "submodule", "=", "unet_block", ",", "outermost", "=", "True", ",", "norm_layer", "=", "norm_layer", ")", "# add the outermost layer", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.UnetGenerator.forward": [[1247, 1250], ["networks.UnetGenerator.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward\"\"\"", "\n", "return", "self", ".", "model", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.UnetSkipConnectionBlock.__init__": [[1258, 1314], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "norm_layer", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "outer_nc", ",", "inner_nc", ",", "input_nc", "=", "None", ",", "\n", "submodule", "=", "None", ",", "outermost", "=", "False", ",", "innermost", "=", "False", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ")", ":", "\n", "        ", "\"\"\"Construct a Unet submodule with skip connections.\n\n        Parameters:\n            outer_nc (int) -- the number of filters in the outer conv layer\n            inner_nc (int) -- the number of filters in the inner conv layer\n            input_nc (int) -- the number of channels in input images/features\n            submodule (UnetSkipConnectionBlock) -- previously defined submodules\n            outermost (bool)    -- if this module is the outermost module\n            innermost (bool)    -- if this module is the innermost module\n            norm_layer          -- normalization layer\n            use_dropout (bool)  -- if use dropout layers.\n        \"\"\"", "\n", "super", "(", "UnetSkipConnectionBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "outermost", "=", "outermost", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "", "if", "input_nc", "is", "None", ":", "\n", "            ", "input_nc", "=", "outer_nc", "\n", "", "downconv", "=", "nn", ".", "Conv2d", "(", "input_nc", ",", "inner_nc", ",", "kernel_size", "=", "4", ",", "\n", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "downrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "downnorm", "=", "norm_layer", "(", "inner_nc", ")", "\n", "uprelu", "=", "nn", ".", "ReLU", "(", "True", ")", "\n", "upnorm", "=", "norm_layer", "(", "outer_nc", ")", "\n", "\n", "if", "outermost", ":", "\n", "            ", "upconv", "=", "nn", ".", "ConvTranspose2d", "(", "inner_nc", "*", "2", ",", "outer_nc", ",", "\n", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ")", "\n", "down", "=", "[", "downconv", "]", "\n", "up", "=", "[", "uprelu", ",", "upconv", ",", "nn", ".", "Tanh", "(", ")", "]", "\n", "model", "=", "down", "+", "[", "submodule", "]", "+", "up", "\n", "", "elif", "innermost", ":", "\n", "            ", "upconv", "=", "nn", ".", "ConvTranspose2d", "(", "inner_nc", ",", "outer_nc", ",", "\n", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "down", "=", "[", "downrelu", ",", "downconv", "]", "\n", "up", "=", "[", "uprelu", ",", "upconv", ",", "upnorm", "]", "\n", "model", "=", "down", "+", "up", "\n", "", "else", ":", "\n", "            ", "upconv", "=", "nn", ".", "ConvTranspose2d", "(", "inner_nc", "*", "2", ",", "outer_nc", ",", "\n", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "down", "=", "[", "downrelu", ",", "downconv", ",", "downnorm", "]", "\n", "up", "=", "[", "uprelu", ",", "upconv", ",", "upnorm", "]", "\n", "\n", "if", "use_dropout", ":", "\n", "                ", "model", "=", "down", "+", "[", "submodule", "]", "+", "up", "+", "[", "nn", ".", "Dropout", "(", "0.5", ")", "]", "\n", "", "else", ":", "\n", "                ", "model", "=", "down", "+", "[", "submodule", "]", "+", "up", "\n", "\n", "", "", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.UnetSkipConnectionBlock.forward": [[1315, 1320], ["networks.UnetSkipConnectionBlock.model", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "networks.UnetSkipConnectionBlock.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "outermost", ":", "\n", "            ", "return", "self", ".", "model", "(", "x", ")", "\n", "", "else", ":", "# add skip connections", "\n", "            ", "return", "torch", ".", "cat", "(", "[", "x", ",", "self", ".", "model", "(", "x", ")", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.NLayerDiscriminator.__init__": [[1325, 1376], ["torch.Module.__init__", "range", "min", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "min", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "networks.Downsample", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "networks.Downsample"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "ndf", "=", "64", ",", "n_layers", "=", "3", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "no_antialias", "=", "False", ",", "noise", "=", "0.0", ")", ":", "\n", "        ", "\"\"\"Construct a PatchGAN discriminator\n\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            ndf (int)       -- the number of filters in the last conv layer\n            n_layers (int)  -- the number of conv layers in the discriminator\n            norm_layer      -- normalization layer\n        \"\"\"", "\n", "super", "(", "NLayerDiscriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "noise", "=", "noise", "\n", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "# no need to use bias as BatchNorm2d has affine parameters", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "kw", "=", "4", "\n", "padw", "=", "1", "\n", "if", "(", "no_antialias", ")", ":", "\n", "            ", "sequence", "=", "[", "nn", ".", "Conv2d", "(", "input_nc", ",", "ndf", ",", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "padding", "=", "padw", ")", ",", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "]", "\n", "", "else", ":", "\n", "            ", "sequence", "=", "[", "nn", ".", "Conv2d", "(", "input_nc", ",", "ndf", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ")", ",", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", ",", "Downsample", "(", "ndf", ")", "]", "\n", "", "nf_mult", "=", "1", "\n", "nf_mult_prev", "=", "1", "\n", "for", "n", "in", "range", "(", "1", ",", "n_layers", ")", ":", "# gradually increase the number of filters", "\n", "            ", "nf_mult_prev", "=", "nf_mult", "\n", "nf_mult", "=", "min", "(", "2", "**", "n", ",", "8", ")", "\n", "if", "(", "no_antialias", ")", ":", "\n", "                ", "sequence", "+=", "[", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult_prev", ",", "ndf", "*", "nf_mult", ",", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "padding", "=", "padw", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "nf_mult", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "]", "\n", "", "else", ":", "\n", "                ", "sequence", "+=", "[", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult_prev", ",", "ndf", "*", "nf_mult", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "nf_mult", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", ",", "\n", "Downsample", "(", "ndf", "*", "nf_mult", ")", "]", "\n", "\n", "", "", "nf_mult_prev", "=", "nf_mult", "\n", "nf_mult", "=", "min", "(", "2", "**", "n_layers", ",", "8", ")", "\n", "sequence", "+=", "[", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult_prev", ",", "ndf", "*", "nf_mult", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "nf_mult", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "]", "\n", "\n", "sequence", "+=", "[", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult", ",", "1", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ")", "]", "# output 1 channel prediction map", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.NLayerDiscriminator.forward": [[1377, 1382], ["networks.NLayerDiscriminator.model", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward.\"\"\"", "\n", "if", "self", ".", "noise", ">", "0", ":", "\n", "            ", "input", "=", "input", "+", "self", ".", "noise", "*", "torch", ".", "randn", "(", "*", "input", ".", "shape", ",", "device", "=", "input", ".", "device", ")", "\n", "", "return", "self", ".", "model", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.PixelDiscriminator.__init__": [[1387, 1410], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "ndf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "\"\"\"Construct a 1x1 PatchGAN discriminator\n\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            ndf (int)       -- the number of filters in the last conv layer\n            norm_layer      -- normalization layer\n        \"\"\"", "\n", "super", "(", "PixelDiscriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "# no need to use bias as BatchNorm2d has affine parameters", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "self", ".", "net", "=", "[", "\n", "nn", ".", "Conv2d", "(", "input_nc", ",", "ndf", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "ndf", ",", "ndf", "*", "2", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "2", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "2", ",", "1", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "use_bias", ")", "]", "\n", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "net", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.PixelDiscriminator.forward": [[1411, 1414], ["networks.PixelDiscriminator.net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward.\"\"\"", "\n", "return", "self", ".", "net", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.FeatureDiscriminator.__init__": [[1417, 1427], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_nc", "=", "256", ",", "ndf", "=", "256", ")", ":", "\n", "        ", "super", "(", "FeatureDiscriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "net", "=", "[", "\n", "nn", ".", "Linear", "(", "input_nc", ",", "ndf", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "ndf", ",", "ndf", "*", "2", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "ndf", "*", "2", ",", "1", ")", ",", "\n", "]", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "net", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.FeatureDiscriminator.forward": [[1428, 1431], ["networks.FeatureDiscriminator.net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward.\"\"\"", "\n", "return", "self", ".", "net", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.PatchDiscriminator.__init__": [[1436, 1439], ["networks.NLayerDiscriminator.__init__"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "ndf", "=", "64", ",", "n_layers", "=", "3", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "no_antialias", "=", "False", ",", "noise", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "input_nc", ",", "ndf", ",", "2", ",", "norm_layer", ",", "no_antialias", ")", "\n", "self", ".", "noise", "=", "noise", "# Used for adding Gaussian noises to the input patches.", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.PatchDiscriminator.forward": [[1440, 1450], ["input.permute().contiguous().view.permute().contiguous().view.view", "input.permute().contiguous().view.permute().contiguous().view.permute().contiguous().view", "networks.NLayerDiscriminator.forward", "input.permute().contiguous().view.permute().contiguous().view.size", "input.permute().contiguous().view.permute().contiguous().view.size", "input.permute().contiguous().view.permute().contiguous().view.size", "input.permute().contiguous().view.permute().contiguous().view.size", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "input.permute().contiguous().view.permute().contiguous().view.permute().contiguous", "input.permute().contiguous().view.permute().contiguous().view.permute"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.forward"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "self", ".", "noise", ">", "0", ":", "\n", "            ", "input", "+=", "self", ".", "noise", "*", "torch", ".", "randn", "(", "*", "input", ".", "shape", ",", "device", "=", "input", ".", "device", ")", "\n", "", "B", ",", "C", ",", "H", ",", "W", "=", "input", ".", "size", "(", "0", ")", ",", "input", ".", "size", "(", "1", ")", ",", "input", ".", "size", "(", "2", ")", ",", "input", ".", "size", "(", "3", ")", "\n", "size", "=", "16", "\n", "Y", "=", "H", "//", "size", "\n", "X", "=", "W", "//", "size", "\n", "input", "=", "input", ".", "view", "(", "B", ",", "C", ",", "Y", ",", "size", ",", "X", ",", "size", ")", "\n", "input", "=", "input", ".", "permute", "(", "0", ",", "2", ",", "4", ",", "1", ",", "3", ",", "5", ")", ".", "contiguous", "(", ")", ".", "view", "(", "B", "*", "Y", "*", "X", ",", "C", ",", "size", ",", "size", ")", "\n", "return", "super", "(", ")", ".", "forward", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.GroupedChannelNorm.__init__": [[1453, 1456], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_groups", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_groups", "=", "num_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.GroupedChannelNorm.forward": [[1457, 1465], ["list", "x.view.view.view", "x.view.view.mean", "x.view.view.std", "x_norm.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shape", "=", "list", "(", "x", ".", "shape", ")", "\n", "new_shape", "=", "[", "shape", "[", "0", "]", ",", "self", ".", "num_groups", ",", "shape", "[", "1", "]", "//", "self", ".", "num_groups", "]", "+", "shape", "[", "2", ":", "]", "\n", "x", "=", "x", ".", "view", "(", "*", "new_shape", ")", "\n", "mean", "=", "x", ".", "mean", "(", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "std", "=", "x", ".", "std", "(", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "x_norm", "=", "(", "x", "-", "mean", ")", "/", "(", "std", "+", "1e-7", ")", "\n", "return", "x_norm", ".", "view", "(", "*", "shape", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.get_filter": [[15, 35], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.array", "torch.sum", "torch.sum", "torch.sum", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "function", ["None"], ["def", "get_filter", "(", "filt_size", "=", "3", ")", ":", "\n", "    ", "if", "(", "filt_size", "==", "1", ")", ":", "\n", "        ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "]", ")", "\n", "", "elif", "(", "filt_size", "==", "2", ")", ":", "\n", "        ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "1.", "]", ")", "\n", "", "elif", "(", "filt_size", "==", "3", ")", ":", "\n", "        ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "2.", ",", "1.", "]", ")", "\n", "", "elif", "(", "filt_size", "==", "4", ")", ":", "\n", "        ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "3.", ",", "3.", ",", "1.", "]", ")", "\n", "", "elif", "(", "filt_size", "==", "5", ")", ":", "\n", "        ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "4.", ",", "6.", ",", "4.", ",", "1.", "]", ")", "\n", "", "elif", "(", "filt_size", "==", "6", ")", ":", "\n", "        ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "5.", ",", "10.", ",", "10.", ",", "5.", ",", "1.", "]", ")", "\n", "", "elif", "(", "filt_size", "==", "7", ")", ":", "\n", "        ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "6.", ",", "15.", ",", "20.", ",", "15.", ",", "6.", ",", "1.", "]", ")", "\n", "\n", "", "filt", "=", "torch", ".", "Tensor", "(", "a", "[", ":", ",", "None", "]", "*", "a", "[", "None", ",", ":", "]", ")", "\n", "filt", "=", "filt", "/", "torch", ".", "sum", "(", "filt", ")", "\n", "\n", "return", "filt", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.get_pad_layer": [[96, 106], ["print"], "function", ["None"], ["", "", "", "def", "get_pad_layer", "(", "pad_type", ")", ":", "\n", "    ", "if", "(", "pad_type", "in", "[", "'refl'", ",", "'reflect'", "]", ")", ":", "\n", "        ", "PadLayer", "=", "nn", ".", "ReflectionPad2d", "\n", "", "elif", "(", "pad_type", "in", "[", "'repl'", ",", "'replicate'", "]", ")", ":", "\n", "        ", "PadLayer", "=", "nn", ".", "ReplicationPad2d", "\n", "", "elif", "(", "pad_type", "==", "'zero'", ")", ":", "\n", "        ", "PadLayer", "=", "nn", ".", "ZeroPad2d", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Pad type [%s] not recognized'", "%", "pad_type", ")", "\n", "", "return", "PadLayer", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.get_norm_layer": [[113, 132], ["functools.partial", "functools.partial", "NotImplementedError", "networks.Identity"], "function", ["None"], ["", "", "def", "get_norm_layer", "(", "norm_type", "=", "'instance'", ")", ":", "\n", "    ", "\"\"\"Return a normalization layer\n\n    Parameters:\n        norm_type (str) -- the name of the normalization layer: batch | instance | none\n\n    For BatchNorm, we use learnable affine parameters and track running statistics (mean/stddev).\n    For InstanceNorm, we do not use learnable affine parameters. We do not track running statistics.\n    \"\"\"", "\n", "if", "norm_type", "==", "'batch'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "BatchNorm2d", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", "\n", "", "elif", "norm_type", "==", "'instance'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "InstanceNorm2d", ",", "affine", "=", "False", ",", "track_running_stats", "=", "False", ")", "\n", "", "elif", "norm_type", "==", "'none'", ":", "\n", "        ", "def", "norm_layer", "(", "x", ")", ":", "\n", "            ", "return", "Identity", "(", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'normalization layer [%s] is not found'", "%", "norm_type", ")", "\n", "", "return", "norm_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.get_scheduler": [[134, 161], ["torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.ReduceLROnPlateau", "max", "float", "torch.optim.lr_scheduler.CosineAnnealingLR", "NotImplementedError"], "function", ["None"], ["", "def", "get_scheduler", "(", "optimizer", ",", "opt", ")", ":", "\n", "    ", "\"\"\"Return a learning rate scheduler\n\n    Parameters:\n        optimizer          -- the optimizer of the network\n        opt (option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\uff0e\u3000\n                              opt.lr_policy is the name of learning rate policy: linear | step | plateau | cosine\n\n    For 'linear', we keep the same learning rate for the first <opt.n_epochs> epochs\n    and linearly decay the rate to zero over the next <opt.n_epochs_decay> epochs.\n    For other schedulers (step, plateau, and cosine), we use the default PyTorch schedulers.\n    See https://pytorch.org/docs/stable/optim.html for more details.\n    \"\"\"", "\n", "if", "opt", ".", "lr_policy", "==", "'linear'", ":", "\n", "        ", "def", "lambda_rule", "(", "epoch", ")", ":", "\n", "            ", "lr_l", "=", "1.0", "-", "max", "(", "0", ",", "epoch", "+", "opt", ".", "epoch_count", "-", "opt", ".", "n_epochs", ")", "/", "float", "(", "opt", ".", "n_epochs_decay", "+", "1", ")", "\n", "return", "lr_l", "\n", "", "scheduler", "=", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", "=", "lambda_rule", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'step'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "StepLR", "(", "optimizer", ",", "step_size", "=", "opt", ".", "lr_decay_iters", ",", "gamma", "=", "0.1", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'plateau'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'min'", ",", "factor", "=", "0.2", ",", "threshold", "=", "0.01", ",", "patience", "=", "5", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'cosine'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "CosineAnnealingLR", "(", "optimizer", ",", "T_max", "=", "opt", ".", "n_epochs", ",", "eta_min", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "return", "NotImplementedError", "(", "'learning rate policy [%s] is not implemented'", ",", "opt", ".", "lr_policy", ")", "\n", "", "return", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.init_weights": [[163, 196], ["net.apply", "hasattr", "print", "torch.nn.init.normal_", "hasattr", "torch.nn.init.constant_", "classname.find", "torch.nn.init.normal_", "torch.nn.init.constant_", "classname.find", "classname.find", "torch.nn.init.xavier_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.orthogonal_", "NotImplementedError"], "function", ["None"], ["", "def", "init_weights", "(", "net", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "debug", "=", "False", ")", ":", "\n", "    ", "\"\"\"Initialize network weights.\n\n    Parameters:\n        net (network)   -- network to be initialized\n        init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n        init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n\n    We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n    work better for some applications. Feel free to try yourself.\n    \"\"\"", "\n", "def", "init_func", "(", "m", ")", ":", "# define the initialization function", "\n", "        ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "hasattr", "(", "m", ",", "'weight'", ")", "and", "(", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", "or", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ")", ":", "\n", "            ", "if", "debug", ":", "\n", "                ", "print", "(", "classname", ")", "\n", "", "if", "init_type", "==", "'normal'", ":", "\n", "                ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "0.0", ",", "init_gain", ")", "\n", "", "elif", "init_type", "==", "'xavier'", ":", "\n", "                ", "init", ".", "xavier_normal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "init_gain", ")", "\n", "", "elif", "init_type", "==", "'kaiming'", ":", "\n", "                ", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ".", "data", ",", "a", "=", "0", ",", "mode", "=", "'fan_in'", ")", "\n", "", "elif", "init_type", "==", "'orthogonal'", ":", "\n", "                ", "init", ".", "orthogonal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "init_gain", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'initialization method [%s] is not implemented'", "%", "init_type", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'BatchNorm2d'", ")", "!=", "-", "1", ":", "# BatchNorm Layer's weight is not a matrix; only normal distribution applies.", "\n", "            ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "1.0", ",", "init_gain", ")", "\n", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "\n", "", "", "net", ".", "apply", "(", "init_func", ")", "# apply the initialization function <init_func>", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.init_net": [[198, 216], ["len", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "net.to", "networks.init_weights"], "function", ["home.repos.pwc.inspect_result.seanjia_srunit.models.networks.init_weights"], ["", "def", "init_net", "(", "net", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ",", "debug", "=", "False", ",", "initialize_weights", "=", "True", ")", ":", "\n", "    ", "\"\"\"Initialize a network: 1. register CPU/GPU device (with multi-GPU support); 2. initialize the network weights\n    Parameters:\n        net (network)      -- the network to be initialized\n        init_type (str)    -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n        gain (float)       -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n\n    Return an initialized network.\n    \"\"\"", "\n", "if", "len", "(", "gpu_ids", ")", ">", "0", ":", "\n", "        ", "assert", "(", "torch", ".", "cuda", ".", "is_available", "(", ")", ")", "\n", "net", ".", "to", "(", "gpu_ids", "[", "0", "]", ")", "\n", "# if not amp:", "\n", "# net = torch.nn.DataParallel(net, gpu_ids)  # multi-GPUs for non-AMP training", "\n", "", "if", "initialize_weights", ":", "\n", "        ", "init_weights", "(", "net", ",", "init_type", ",", "init_gain", "=", "init_gain", ",", "debug", "=", "debug", ")", "\n", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.define_G": [[218, 269], ["networks.get_norm_layer", "networks.init_net", "networks.ResnetGenerator", "networks.ResnetGenerator", "networks.ResnetGenerator", "networks.UnetGenerator", "networks.UnetGenerator", "stylegan_networks.StyleGAN2Generator", "stylegan_networks.StyleGAN2Generator", "networks.G_Resnet", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.seanjia_srunit.models.networks.get_norm_layer", "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.init_net"], ["", "def", "define_G", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "netG", ",", "norm", "=", "'batch'", ",", "use_dropout", "=", "False", ",", "init_type", "=", "'normal'", ",", "\n", "init_gain", "=", "0.02", ",", "no_antialias", "=", "False", ",", "no_antialias_up", "=", "False", ",", "gpu_ids", "=", "[", "]", ",", "opt", "=", "None", ")", ":", "\n", "    ", "\"\"\"Create a generator\n\n    Parameters:\n        input_nc (int) -- the number of channels in input images\n        output_nc (int) -- the number of channels in output images\n        ngf (int) -- the number of filters in the last conv layer\n        netG (str) -- the architecture's name: resnet_9blocks | resnet_6blocks | unet_256 | unet_128\n        norm (str) -- the name of normalization layers used in the network: batch | instance | none\n        use_dropout (bool) -- if use dropout layers.\n        init_type (str)    -- the name of our initialization method.\n        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n\n    Returns a generator\n\n    Our current implementation provides two types of generators:\n        U-Net: [unet_128] (for 128x128 input images) and [unet_256] (for 256x256 input images)\n        The original U-Net paper: https://arxiv.org/abs/1505.04597\n\n        Resnet-based generator: [resnet_6blocks] (with 6 Resnet blocks) and [resnet_9blocks] (with 9 Resnet blocks)\n        Resnet-based generator consists of several Resnet blocks between a few downsampling/upsampling operations.\n        We adapt Torch code from Justin Johnson's neural style transfer project (https://github.com/jcjohnson/fast-neural-style).\n\n\n    The generator has been initialized by <init_net>. It uses RELU for non-linearity.\n    \"\"\"", "\n", "net", "=", "None", "\n", "norm_layer", "=", "get_norm_layer", "(", "norm_type", "=", "norm", ")", "\n", "\n", "if", "netG", "==", "'resnet_9blocks'", ":", "\n", "        ", "net", "=", "ResnetGenerator", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "no_antialias", "=", "no_antialias", ",", "no_antialias_up", "=", "no_antialias_up", ",", "n_blocks", "=", "9", ",", "opt", "=", "opt", ")", "\n", "", "elif", "netG", "==", "'resnet_6blocks'", ":", "\n", "        ", "net", "=", "ResnetGenerator", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "no_antialias", "=", "no_antialias", ",", "no_antialias_up", "=", "no_antialias_up", ",", "n_blocks", "=", "6", ",", "opt", "=", "opt", ")", "\n", "", "elif", "netG", "==", "'resnet_4blocks'", ":", "\n", "        ", "net", "=", "ResnetGenerator", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "no_antialias", "=", "no_antialias", ",", "no_antialias_up", "=", "no_antialias_up", ",", "n_blocks", "=", "4", ",", "opt", "=", "opt", ")", "\n", "", "elif", "netG", "==", "'unet_128'", ":", "\n", "        ", "net", "=", "UnetGenerator", "(", "input_nc", ",", "output_nc", ",", "7", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ")", "\n", "", "elif", "netG", "==", "'unet_256'", ":", "\n", "        ", "net", "=", "UnetGenerator", "(", "input_nc", ",", "output_nc", ",", "8", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ")", "\n", "", "elif", "netG", "==", "'stylegan2'", ":", "\n", "        ", "net", "=", "StyleGAN2Generator", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "use_dropout", "=", "use_dropout", ",", "opt", "=", "opt", ")", "\n", "", "elif", "netG", "==", "'smallstylegan2'", ":", "\n", "        ", "net", "=", "StyleGAN2Generator", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "use_dropout", "=", "use_dropout", ",", "n_blocks", "=", "2", ",", "opt", "=", "opt", ")", "\n", "", "elif", "netG", "==", "'resnet_cat'", ":", "\n", "        ", "n_blocks", "=", "8", "\n", "net", "=", "G_Resnet", "(", "input_nc", ",", "output_nc", ",", "opt", ".", "nz", ",", "num_downs", "=", "2", ",", "n_res", "=", "n_blocks", "-", "4", ",", "ngf", "=", "ngf", ",", "norm", "=", "'inst'", ",", "nl_layer", "=", "'relu'", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Generator model name [%s] is not recognized'", "%", "netG", ")", "\n", "", "return", "init_net", "(", "net", ",", "init_type", ",", "init_gain", ",", "gpu_ids", ",", "initialize_weights", "=", "(", "'stylegan2'", "not", "in", "netG", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.define_F": [[271, 285], ["networks.init_net", "networks.PoolingF", "networks.ReshapeF", "networks.PatchSampleF", "networks.PatchSampleF", "networks.StridedConvF", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.seanjia_srunit.models.networks.init_net"], ["", "def", "define_F", "(", "input_nc", ",", "netF", ",", "norm", "=", "'batch'", ",", "use_dropout", "=", "False", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "no_antialias", "=", "False", ",", "gpu_ids", "=", "[", "]", ",", "opt", "=", "None", ")", ":", "\n", "    ", "if", "netF", "==", "'global_pool'", ":", "\n", "        ", "net", "=", "PoolingF", "(", ")", "\n", "", "elif", "netF", "==", "'reshape'", ":", "\n", "        ", "net", "=", "ReshapeF", "(", ")", "\n", "", "elif", "netF", "==", "'sample'", ":", "\n", "        ", "net", "=", "PatchSampleF", "(", "use_mlp", "=", "False", ",", "init_type", "=", "init_type", ",", "init_gain", "=", "init_gain", ",", "gpu_ids", "=", "gpu_ids", ",", "nc", "=", "opt", ".", "netF_nc", ")", "\n", "", "elif", "netF", "==", "'mlp_sample'", ":", "\n", "        ", "net", "=", "PatchSampleF", "(", "use_mlp", "=", "True", ",", "init_type", "=", "init_type", ",", "init_gain", "=", "init_gain", ",", "gpu_ids", "=", "gpu_ids", ",", "nc", "=", "opt", ".", "netF_nc", ")", "\n", "", "elif", "netF", "==", "'strided_conv'", ":", "\n", "        ", "net", "=", "StridedConvF", "(", "init_type", "=", "init_type", ",", "init_gain", "=", "init_gain", ",", "gpu_ids", "=", "gpu_ids", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'projection model name [%s] is not recognized'", "%", "netF", ")", "\n", "", "return", "init_net", "(", "net", ",", "init_type", ",", "init_gain", ",", "gpu_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.define_D": [[287, 333], ["networks.get_norm_layer", "networks.init_net", "networks.NLayerDiscriminator", "networks.NLayerDiscriminator", "networks.PixelDiscriminator", "stylegan_networks.StyleGAN2Discriminator", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.seanjia_srunit.models.networks.get_norm_layer", "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.init_net"], ["", "def", "define_D", "(", "input_nc", ",", "ndf", ",", "netD", ",", "n_layers_D", "=", "3", ",", "norm", "=", "'batch'", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "no_antialias", "=", "False", ",", "gpu_ids", "=", "[", "]", ",", "opt", "=", "None", ",", "noise", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"Create a discriminator\n\n    Parameters:\n        input_nc (int)     -- the number of channels in input images\n        ndf (int)          -- the number of filters in the first conv layer\n        netD (str)         -- the architecture's name: basic | n_layers | pixel\n        n_layers_D (int)   -- the number of conv layers in the discriminator; effective when netD=='n_layers'\n        norm (str)         -- the type of normalization layers used in the network.\n        init_type (str)    -- the name of the initialization method.\n        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n        noise              -- size of the Gaussian noises added to the inputs.\n\n    Returns a discriminator\n\n    Our current implementation provides three types of discriminators:\n        [basic]: 'PatchGAN' classifier described in the original pix2pix paper.\n        It can classify whether 70 by 70 overlapping patches are real or fake.\n        Such a patch-level discriminator architecture has fewer parameters\n        than a full-image discriminator and can work on arbitrarily-sized images\n        in a fully convolutional fashion.\n\n        [n_layers]: With this mode, you cna specify the number of conv layers in the discriminator\n        with the parameter <n_layers_D> (default=3 as used in [basic] (PatchGAN).)\n\n        [pixel]: 1x1 PixelGAN discriminator can classify whether a pixel is real or not.\n        It encourages greater color diversity but has no effect on spatial statistics.\n\n    The discriminator has been initialized by <init_net>. It uses Leaky RELU for non-linearity.\n    \"\"\"", "\n", "net", "=", "None", "\n", "norm_layer", "=", "get_norm_layer", "(", "norm_type", "=", "norm", ")", "\n", "\n", "if", "netD", "==", "'basic'", ":", "# default PatchGAN classifier", "\n", "        ", "net", "=", "NLayerDiscriminator", "(", "input_nc", ",", "ndf", ",", "n_layers", "=", "3", ",", "norm_layer", "=", "norm_layer", ",", "no_antialias", "=", "no_antialias", ",", "noise", "=", "noise", ")", "\n", "", "elif", "netD", "==", "'n_layers'", ":", "# more options", "\n", "        ", "net", "=", "NLayerDiscriminator", "(", "input_nc", ",", "ndf", ",", "n_layers_D", ",", "norm_layer", "=", "norm_layer", ",", "no_antialias", "=", "no_antialias", ",", "noise", "=", "noise", ")", "\n", "", "elif", "netD", "==", "'pixel'", ":", "# classify if each pixel is real or fake", "\n", "        ", "net", "=", "PixelDiscriminator", "(", "input_nc", ",", "ndf", ",", "norm_layer", "=", "norm_layer", ",", "noise", "=", "noise", ")", "\n", "", "elif", "'stylegan2'", "in", "netD", ":", "\n", "        ", "net", "=", "StyleGAN2Discriminator", "(", "input_nc", ",", "ndf", ",", "n_layers_D", ",", "no_antialias", "=", "no_antialias", ",", "opt", "=", "opt", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Discriminator model name [%s] is not recognized'", "%", "netD", ")", "\n", "", "return", "init_net", "(", "net", ",", "init_type", ",", "init_gain", ",", "gpu_ids", ",", "\n", "initialize_weights", "=", "(", "'stylegan2'", "not", "in", "netD", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.define_d": [[335, 338], ["networks.FeatureDiscriminator", "networks.init_net"], "function", ["home.repos.pwc.inspect_result.seanjia_srunit.models.networks.init_net"], ["", "def", "define_d", "(", "input_nc", ",", "ndf", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ")", ":", "\n", "    ", "net", "=", "FeatureDiscriminator", "(", "input_nc", ",", "ndf", ")", "\n", "return", "init_net", "(", "net", ",", "init_type", ",", "init_gain", ",", "gpu_ids", ",", "initialize_weights", "=", "(", "False", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.cal_gradient_penalty": [[418, 453], ["interpolatesv.requires_grad_", "netD", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "gradients[].view", "real_data.size", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.rand", "torch.rand", "torch.rand", "alpha.expand().contiguous().view.expand().contiguous().view", "NotImplementedError", "torch.ones", "torch.ones", "torch.ones", "alpha.expand().contiguous().view.expand().contiguous", "netD.size", "alpha.expand().contiguous().view.expand", "real_data.nelement"], "function", ["None"], ["", "", "def", "cal_gradient_penalty", "(", "netD", ",", "real_data", ",", "fake_data", ",", "device", ",", "type", "=", "'mixed'", ",", "constant", "=", "1.0", ",", "lambda_gp", "=", "10.0", ")", ":", "\n", "    ", "\"\"\"Calculate the gradient penalty loss, used in WGAN-GP paper https://arxiv.org/abs/1704.00028\n\n    Arguments:\n        netD (network)              -- discriminator network\n        real_data (tensor array)    -- real images\n        fake_data (tensor array)    -- generated images from the generator\n        device (str)                -- GPU / CPU: from torch.device('cuda:{}'.format(self.gpu_ids[0])) if self.gpu_ids else torch.device('cpu')\n        type (str)                  -- if we mix real and fake data or not [real | fake | mixed].\n        constant (float)            -- the constant used in formula ( | |gradient||_2 - constant)^2\n        lambda_gp (float)           -- weight for this loss\n\n    Returns the gradient penalty loss\n    \"\"\"", "\n", "if", "lambda_gp", ">", "0.0", ":", "\n", "        ", "if", "type", "==", "'real'", ":", "# either use real images, fake images, or a linear interpolation of two.", "\n", "            ", "interpolatesv", "=", "real_data", "\n", "", "elif", "type", "==", "'fake'", ":", "\n", "            ", "interpolatesv", "=", "fake_data", "\n", "", "elif", "type", "==", "'mixed'", ":", "\n", "            ", "alpha", "=", "torch", ".", "rand", "(", "real_data", ".", "shape", "[", "0", "]", ",", "1", ",", "device", "=", "device", ")", "\n", "alpha", "=", "alpha", ".", "expand", "(", "real_data", ".", "shape", "[", "0", "]", ",", "real_data", ".", "nelement", "(", ")", "//", "real_data", ".", "shape", "[", "0", "]", ")", ".", "contiguous", "(", ")", ".", "view", "(", "*", "real_data", ".", "shape", ")", "\n", "interpolatesv", "=", "alpha", "*", "real_data", "+", "(", "(", "1", "-", "alpha", ")", "*", "fake_data", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'{} not implemented'", ".", "format", "(", "type", ")", ")", "\n", "", "interpolatesv", ".", "requires_grad_", "(", "True", ")", "\n", "disc_interpolates", "=", "netD", "(", "interpolatesv", ")", "\n", "gradients", "=", "torch", ".", "autograd", ".", "grad", "(", "outputs", "=", "disc_interpolates", ",", "inputs", "=", "interpolatesv", ",", "\n", "grad_outputs", "=", "torch", ".", "ones", "(", "disc_interpolates", ".", "size", "(", ")", ")", ".", "to", "(", "device", ")", ",", "\n", "create_graph", "=", "True", ",", "retain_graph", "=", "True", ",", "only_inputs", "=", "True", ")", "\n", "gradients", "=", "gradients", "[", "0", "]", ".", "view", "(", "real_data", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# flat the data", "\n", "gradient_penalty", "=", "(", "(", "(", "gradients", "+", "1e-16", ")", ".", "norm", "(", "2", ",", "dim", "=", "1", ")", "-", "constant", ")", "**", "2", ")", ".", "mean", "(", ")", "*", "lambda_gp", "# added eps", "\n", "return", "gradient_penalty", ",", "gradients", "\n", "", "else", ":", "\n", "        ", "return", "0.0", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.cat_feature": [[772, 777], ["y.view().expand", "torch.cat", "torch.cat", "torch.cat", "y.size", "y.size", "x.size", "x.size", "y.view", "y.size", "y.size"], "function", ["None"], ["", "", "def", "cat_feature", "(", "x", ",", "y", ")", ":", "\n", "    ", "y_expand", "=", "y", ".", "view", "(", "y", ".", "size", "(", "0", ")", ",", "y", ".", "size", "(", "1", ")", ",", "1", ",", "1", ")", ".", "expand", "(", "\n", "y", ".", "size", "(", "0", ")", ",", "y", ".", "size", "(", "1", ")", ",", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", "\n", "x_cat", "=", "torch", ".", "cat", "(", "[", "x", ",", "y_expand", "]", ",", "1", ")", "\n", "return", "x_cat", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.patchnce.PatchNCELoss.__init__": [[7, 12], ["torch.nn.Module.__init__", "torch.nn.CrossEntropyLoss", "packaging.version.parse", "packaging.version.parse"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.parse", "home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.parse"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "cross_entropy_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", "\n", "self", ".", "mask_dtype", "=", "torch", ".", "uint8", "if", "version", ".", "parse", "(", "torch", ".", "__version__", ")", "<", "version", ".", "parse", "(", "'1.2.0'", ")", "else", "torch", ".", "bool", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.patchnce.PatchNCELoss.forward": [[13, 55], ["feat_k.view.view.detach", "torch.bmm", "l_pos.view.view.view", "feat_q.view.view.view", "feat_k.view.view.view", "feat_q.view.view.size", "torch.bmm", "torch.bmm.masked_fill_", "torch.bmm.view", "patchnce.PatchNCELoss.cross_entropy_loss", "feat_q.view.view.view", "feat_k.view.view.view", "feat_k.view.view.transpose", "torch.eye", "torch.cat", "torch.zeros", "out.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "feat_q", ",", "feat_k", ")", ":", "\n", "        ", "batchSize", "=", "feat_q", ".", "shape", "[", "0", "]", "\n", "dim", "=", "feat_q", ".", "shape", "[", "1", "]", "\n", "feat_k", "=", "feat_k", ".", "detach", "(", ")", "\n", "\n", "# pos logit", "\n", "l_pos", "=", "torch", ".", "bmm", "(", "feat_q", ".", "view", "(", "batchSize", ",", "1", ",", "-", "1", ")", ",", "feat_k", ".", "view", "(", "batchSize", ",", "-", "1", ",", "1", ")", ")", "\n", "l_pos", "=", "l_pos", ".", "view", "(", "batchSize", ",", "1", ")", "\n", "\n", "# neg logit", "\n", "\n", "# Should the negatives from the other samples of a minibatch be utilized?", "\n", "# In CUT and FastCUT, we found that it's best to only include negatives", "\n", "# from the same image. Therefore, we set", "\n", "# --nce_includes_all_negatives_from_minibatch as False", "\n", "# However, for single-image translation, the minibatch consists of", "\n", "# crops from the \"same\" high-resolution image.", "\n", "# Therefore, we will include the negatives from the entire minibatch.", "\n", "if", "self", ".", "opt", ".", "nce_includes_all_negatives_from_minibatch", ":", "\n", "# reshape features as if they are all negatives of minibatch of size 1.", "\n", "            ", "batch_dim_for_bmm", "=", "1", "\n", "", "else", ":", "\n", "            ", "batch_dim_for_bmm", "=", "self", ".", "opt", ".", "batch_size", "\n", "\n", "# reshape features to batch size", "\n", "", "feat_q", "=", "feat_q", ".", "view", "(", "batch_dim_for_bmm", ",", "-", "1", ",", "dim", ")", "\n", "feat_k", "=", "feat_k", ".", "view", "(", "batch_dim_for_bmm", ",", "-", "1", ",", "dim", ")", "\n", "npatches", "=", "feat_q", ".", "size", "(", "1", ")", "\n", "l_neg_curbatch", "=", "torch", ".", "bmm", "(", "feat_q", ",", "feat_k", ".", "transpose", "(", "2", ",", "1", ")", ")", "\n", "\n", "# diagonal entries are similarity between same features, and hence meaningless.", "\n", "# just fill the diagonal with very small number, which is exp(-10) and almost zero", "\n", "diagonal", "=", "torch", ".", "eye", "(", "npatches", ",", "device", "=", "feat_q", ".", "device", ",", "dtype", "=", "self", ".", "mask_dtype", ")", "[", "None", ",", ":", ",", ":", "]", "\n", "l_neg_curbatch", ".", "masked_fill_", "(", "diagonal", ",", "-", "10.0", ")", "\n", "l_neg", "=", "l_neg_curbatch", ".", "view", "(", "-", "1", ",", "npatches", ")", "\n", "\n", "out", "=", "torch", ".", "cat", "(", "(", "l_pos", ",", "l_neg", ")", ",", "dim", "=", "1", ")", "/", "self", ".", "opt", ".", "nce_T", "\n", "\n", "loss", "=", "self", ".", "cross_entropy_loss", "(", "out", ",", "torch", ".", "zeros", "(", "out", ".", "size", "(", "0", ")", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "feat_q", ".", "device", ")", ")", "\n", "\n", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seanjia_srunit.models.cycle_gan_model.CycleGANModel.modify_commandline_options": [[23, 51], ["parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", "=", "True", ")", ":", "\n", "        ", "\"\"\"Add new dataset-specific options, and rewrite default values for existing options.\n\n        Parameters:\n            parser          -- original option parser\n            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n\n        Returns:\n            the modified parser.\n\n        For CycleGAN, in addition to GAN losses, we introduce lambda_A, lambda_B, and lambda_identity for the following losses.\n        A (source domain), B (target domain).\n        Generators: G_A: A -> B; G_B: B -> A.\n        Discriminators: D_A: G_A(A) vs. B; D_B: G_B(B) vs. A.\n        Forward cycle loss:  lambda_A * ||G_B(G_A(A)) - A|| (Eqn. (2) in the paper)\n        Backward cycle loss: lambda_B * ||G_A(G_B(B)) - B|| (Eqn. (2) in the paper)\n        Identity loss (optional): lambda_identity * (||G_A(B) - B|| * lambda_B + ||G_B(A) - A|| * lambda_A) (Sec 5.2 \"Photo generation from paintings\" in the paper)\n        Dropout is not used in the original CycleGAN paper.\n        \"\"\"", "\n", "# parser.set_defaults(no_dropout=True, no_antialias=True, no_antialias_up=True)  # default CycleGAN did not use dropout", "\n", "# parser.set_defaults(no_dropout=True)", "\n", "if", "is_train", ":", "\n", "            ", "parser", ".", "add_argument", "(", "'--lambda_A'", ",", "type", "=", "float", ",", "default", "=", "10.0", ",", "help", "=", "'weight for cycle loss (A -> B -> A)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_B'", ",", "type", "=", "float", ",", "default", "=", "10.0", ",", "help", "=", "'weight for cycle loss (B -> A -> B)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_identity'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'use identity mapping. Setting lambda_identity other than 0 has an effect of scaling the weight of the identity mapping loss. For example, if the weight of the identity loss should be 10 times smaller than the weight of the reconstruction loss, please set lambda_identity = 0.1'", ")", "\n", "\n", "", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.cycle_gan_model.CycleGANModel.__init__": [[52, 103], ["base_model.BaseModel.__init__", "networks.define_G", "networks.define_G", "visual_names_A.append", "visual_names_B.append", "networks.define_D", "networks.define_D", "util.image_pool.ImagePool", "util.image_pool.ImagePool", "networks.GANLoss().to", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.optim.Adam", "torch.optim.Adam", "cycle_gan_model.CycleGANModel.optimizers.append", "cycle_gan_model.CycleGANModel.optimizers.append", "itertools.chain", "itertools.chain", "networks.GANLoss", "cycle_gan_model.CycleGANModel.netG_A.parameters", "cycle_gan_model.CycleGANModel.netG_B.parameters", "cycle_gan_model.CycleGANModel.netD_A.parameters", "cycle_gan_model.CycleGANModel.netD_B.parameters"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.define_G", "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.define_G", "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.define_D", "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.define_D"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the CycleGAN class.\n\n        Parameters:\n            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "BaseModel", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "# specify the training losses you want to print out. The training/test scripts will call <BaseModel.get_current_losses>", "\n", "self", ".", "loss_names", "=", "[", "'D_A'", ",", "'G_A'", ",", "'cycle_A'", ",", "'idt_A'", ",", "'D_B'", ",", "'G_B'", ",", "'cycle_B'", ",", "'idt_B'", "]", "\n", "# specify the images you want to save/display. The training/test scripts will call <BaseModel.get_current_visuals>", "\n", "visual_names_A", "=", "[", "'real_A'", ",", "'fake_B'", ",", "'rec_A'", "]", "\n", "visual_names_B", "=", "[", "'real_B'", ",", "'fake_A'", ",", "'rec_B'", "]", "\n", "if", "self", ".", "isTrain", "and", "self", ".", "opt", ".", "lambda_identity", ">", "0.0", ":", "# if identity loss is used, we also visualize idt_B=G_A(B) ad idt_A=G_A(B)", "\n", "            ", "visual_names_A", ".", "append", "(", "'idt_B'", ")", "\n", "visual_names_B", ".", "append", "(", "'idt_A'", ")", "\n", "\n", "", "self", ".", "visual_names", "=", "visual_names_A", "+", "visual_names_B", "# combine visualizations for A and B", "\n", "# specify the models you want to save to the disk. The training/test scripts will call <BaseModel.save_networks> and <BaseModel.load_networks>.", "\n", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "model_names", "=", "[", "'G_A'", ",", "'G_B'", ",", "'D_A'", ",", "'D_B'", "]", "\n", "", "else", ":", "# during test time, only load Gs", "\n", "            ", "self", ".", "model_names", "=", "[", "'G_A'", ",", "'G_B'", "]", "\n", "\n", "# define networks (both Generators and discriminators)", "\n", "# The naming is different from those used in the paper.", "\n", "# Code (vs. paper): G_A (G), G_B (F), D_A (D_Y), D_B (D_X)", "\n", "", "self", ".", "netG_A", "=", "networks", ".", "define_G", "(", "opt", ".", "input_nc", ",", "opt", ".", "output_nc", ",", "opt", ".", "ngf", ",", "opt", ".", "netG", ",", "opt", ".", "normG", ",", "\n", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "opt", ".", "no_antialias", ",", "opt", ".", "no_antialias_up", ",", "self", ".", "gpu_ids", ",", "opt", "=", "opt", ")", "\n", "self", ".", "netG_B", "=", "networks", ".", "define_G", "(", "opt", ".", "output_nc", ",", "opt", ".", "input_nc", ",", "opt", ".", "ngf", ",", "opt", ".", "netG", ",", "opt", ".", "normG", ",", "\n", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "opt", ".", "no_antialias", ",", "opt", ".", "no_antialias_up", ",", "self", ".", "gpu_ids", ",", "opt", "=", "opt", ")", "\n", "\n", "if", "self", ".", "isTrain", ":", "# define discriminators", "\n", "            ", "self", ".", "netD_A", "=", "networks", ".", "define_D", "(", "opt", ".", "output_nc", ",", "opt", ".", "ndf", ",", "opt", ".", "netD", ",", "\n", "opt", ".", "n_layers_D", ",", "opt", ".", "normD", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "opt", ".", "no_antialias", ",", "self", ".", "gpu_ids", ",", "opt", "=", "opt", ")", "\n", "self", ".", "netD_B", "=", "networks", ".", "define_D", "(", "opt", ".", "input_nc", ",", "opt", ".", "ndf", ",", "opt", ".", "netD", ",", "\n", "opt", ".", "n_layers_D", ",", "opt", ".", "normD", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "opt", ".", "no_antialias", ",", "self", ".", "gpu_ids", ",", "opt", "=", "opt", ")", "\n", "\n", "", "if", "self", ".", "isTrain", ":", "\n", "            ", "if", "opt", ".", "lambda_identity", ">", "0.0", ":", "# only works when input and output images have the same number of channels", "\n", "                ", "assert", "(", "opt", ".", "input_nc", "==", "opt", ".", "output_nc", ")", "\n", "", "self", ".", "fake_A_pool", "=", "ImagePool", "(", "opt", ".", "pool_size", ")", "# create image buffer to store previously generated images", "\n", "self", ".", "fake_B_pool", "=", "ImagePool", "(", "opt", ".", "pool_size", ")", "# create image buffer to store previously generated images", "\n", "# define loss functions", "\n", "self", ".", "criterionGAN", "=", "networks", ".", "GANLoss", "(", "opt", ".", "gan_mode", ")", ".", "to", "(", "self", ".", "device", ")", "# define GAN loss.", "\n", "self", ".", "criterionCycle", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", "\n", "self", ".", "criterionIdt", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", "\n", "# initialize optimizers; schedulers will be automatically created by function <BaseModel.setup>.", "\n", "self", ".", "optimizer_G", "=", "torch", ".", "optim", ".", "Adam", "(", "itertools", ".", "chain", "(", "self", ".", "netG_A", ".", "parameters", "(", ")", ",", "self", ".", "netG_B", ".", "parameters", "(", ")", ")", ",", "lr", "=", "opt", ".", "lr", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "0.999", ")", ")", "\n", "self", ".", "optimizer_D", "=", "torch", ".", "optim", ".", "Adam", "(", "itertools", ".", "chain", "(", "self", ".", "netD_A", ".", "parameters", "(", ")", ",", "self", ".", "netD_B", ".", "parameters", "(", ")", ")", ",", "lr", "=", "opt", ".", "lr", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "0.999", ")", ")", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_G", ")", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_D", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.cycle_gan_model.CycleGANModel.set_input": [[104, 116], ["input[].to", "input[].to"], "methods", ["None"], ["", "", "def", "set_input", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n\n        Parameters:\n            input (dict): include the data itself and its metadata information.\n\n        The option 'direction' can be used to swap domain A and domain B.\n        \"\"\"", "\n", "AtoB", "=", "self", ".", "opt", ".", "direction", "==", "'AtoB'", "\n", "self", ".", "real_A", "=", "input", "[", "'A'", "if", "AtoB", "else", "'B'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "real_B", "=", "input", "[", "'B'", "if", "AtoB", "else", "'A'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "image_paths", "=", "input", "[", "'A_paths'", "if", "AtoB", "else", "'B_paths'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.cycle_gan_model.CycleGANModel.forward": [[117, 123], ["cycle_gan_model.CycleGANModel.netG_A", "cycle_gan_model.CycleGANModel.netG_B", "cycle_gan_model.CycleGANModel.netG_B", "cycle_gan_model.CycleGANModel.netG_A"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "\"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"", "\n", "self", ".", "fake_B", "=", "self", ".", "netG_A", "(", "self", ".", "real_A", ")", "# G_A(A)", "\n", "self", ".", "rec_A", "=", "self", ".", "netG_B", "(", "self", ".", "fake_B", ")", "# G_B(G_A(A))", "\n", "self", ".", "fake_A", "=", "self", ".", "netG_B", "(", "self", ".", "real_B", ")", "# G_B(B)", "\n", "self", ".", "rec_B", "=", "self", ".", "netG_A", "(", "self", ".", "fake_A", ")", "# G_A(G_B(B))", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.cycle_gan_model.CycleGANModel.backward_D_basic": [[124, 149], ["netD", "cycle_gan_model.CycleGANModel.criterionGAN", "netD", "cycle_gan_model.CycleGANModel.criterionGAN", "fake.detach", "loss_D.backward", "amp.scale_loss", "scaled_loss.backward"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.backward", "home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.backward"], ["", "def", "backward_D_basic", "(", "self", ",", "netD", ",", "real", ",", "fake", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for the discriminator\n\n        Parameters:\n            netD (network)      -- the discriminator D\n            real (tensor array) -- real images\n            fake (tensor array) -- images generated by a generator\n\n        Return the discriminator loss.\n        We also call loss_D.backward() to calculate the gradients.\n        \"\"\"", "\n", "# Real", "\n", "pred_real", "=", "netD", "(", "real", ")", "\n", "loss_D_real", "=", "self", ".", "criterionGAN", "(", "pred_real", ",", "True", ")", "\n", "# Fake", "\n", "pred_fake", "=", "netD", "(", "fake", ".", "detach", "(", ")", ")", "\n", "loss_D_fake", "=", "self", ".", "criterionGAN", "(", "pred_fake", ",", "False", ")", "\n", "# Combined loss and calculate gradients", "\n", "loss_D", "=", "(", "loss_D_real", "+", "loss_D_fake", ")", "*", "0.5", "\n", "if", "self", ".", "opt", ".", "amp", ":", "\n", "            ", "with", "amp", ".", "scale_loss", "(", "loss_D", ",", "self", ".", "optimizer_D", ")", "as", "scaled_loss", ":", "\n", "                ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "loss_D", ".", "backward", "(", ")", "\n", "", "return", "loss_D", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.cycle_gan_model.CycleGANModel.backward_D_A": [[150, 154], ["cycle_gan_model.CycleGANModel.fake_B_pool.query", "cycle_gan_model.CycleGANModel.backward_D_basic"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.util.image_pool.ImagePool.query", "home.repos.pwc.inspect_result.seanjia_srunit.models.cycle_gan_model.CycleGANModel.backward_D_basic"], ["", "def", "backward_D_A", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for discriminator D_A\"\"\"", "\n", "fake_B", "=", "self", ".", "fake_B_pool", ".", "query", "(", "self", ".", "fake_B", ")", "\n", "self", ".", "loss_D_A", "=", "self", ".", "backward_D_basic", "(", "self", ".", "netD_A", ",", "self", ".", "real_B", ",", "fake_B", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.cycle_gan_model.CycleGANModel.backward_D_B": [[155, 159], ["cycle_gan_model.CycleGANModel.fake_A_pool.query", "cycle_gan_model.CycleGANModel.backward_D_basic"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.util.image_pool.ImagePool.query", "home.repos.pwc.inspect_result.seanjia_srunit.models.cycle_gan_model.CycleGANModel.backward_D_basic"], ["", "def", "backward_D_B", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for discriminator D_B\"\"\"", "\n", "fake_A", "=", "self", ".", "fake_A_pool", ".", "query", "(", "self", ".", "fake_A", ")", "\n", "self", ".", "loss_D_B", "=", "self", ".", "backward_D_basic", "(", "self", ".", "netD_B", ",", "self", ".", "real_A", ",", "fake_A", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.cycle_gan_model.CycleGANModel.backward_G": [[160, 192], ["cycle_gan_model.CycleGANModel.criterionGAN", "cycle_gan_model.CycleGANModel.criterionGAN", "cycle_gan_model.CycleGANModel.netG_A", "cycle_gan_model.CycleGANModel.netG_B", "cycle_gan_model.CycleGANModel.netD_A", "cycle_gan_model.CycleGANModel.netD_B", "cycle_gan_model.CycleGANModel.criterionCycle", "cycle_gan_model.CycleGANModel.criterionCycle", "cycle_gan_model.CycleGANModel.loss_G.backward", "amp.scale_loss", "scaled_loss.backward", "cycle_gan_model.CycleGANModel.criterionIdt", "cycle_gan_model.CycleGANModel.criterionIdt"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.backward", "home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.backward"], ["", "def", "backward_G", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate the loss for generators G_A and G_B\"\"\"", "\n", "lambda_idt", "=", "self", ".", "opt", ".", "lambda_identity", "\n", "lambda_A", "=", "self", ".", "opt", ".", "lambda_A", "\n", "lambda_B", "=", "self", ".", "opt", ".", "lambda_B", "\n", "# Identity loss", "\n", "if", "lambda_idt", ">", "0", ":", "\n", "# G_A should be identity if real_B is fed: ||G_A(B) - B||", "\n", "            ", "self", ".", "idt_A", "=", "self", ".", "netG_A", "(", "self", ".", "real_B", ")", "\n", "self", ".", "loss_idt_A", "=", "self", ".", "criterionIdt", "(", "self", ".", "idt_A", ",", "self", ".", "real_B", ")", "*", "lambda_B", "*", "lambda_idt", "\n", "# G_B should be identity if real_A is fed: ||G_B(A) - A||", "\n", "self", ".", "idt_B", "=", "self", ".", "netG_B", "(", "self", ".", "real_A", ")", "\n", "self", ".", "loss_idt_B", "=", "self", ".", "criterionIdt", "(", "self", ".", "idt_B", ",", "self", ".", "real_A", ")", "*", "lambda_A", "*", "lambda_idt", "\n", "", "else", ":", "\n", "            ", "self", ".", "loss_idt_A", "=", "0", "\n", "self", ".", "loss_idt_B", "=", "0", "\n", "\n", "# GAN loss D_A(G_A(A))", "\n", "", "self", ".", "loss_G_A", "=", "self", ".", "criterionGAN", "(", "self", ".", "netD_A", "(", "self", ".", "fake_B", ")", ",", "True", ")", "\n", "# GAN loss D_B(G_B(B))", "\n", "self", ".", "loss_G_B", "=", "self", ".", "criterionGAN", "(", "self", ".", "netD_B", "(", "self", ".", "fake_A", ")", ",", "True", ")", "\n", "# Forward cycle loss || G_B(G_A(A)) - A||", "\n", "self", ".", "loss_cycle_A", "=", "self", ".", "criterionCycle", "(", "self", ".", "rec_A", ",", "self", ".", "real_A", ")", "*", "lambda_A", "\n", "# Backward cycle loss || G_A(G_B(B)) - B||", "\n", "self", ".", "loss_cycle_B", "=", "self", ".", "criterionCycle", "(", "self", ".", "rec_B", ",", "self", ".", "real_B", ")", "*", "lambda_B", "\n", "# combined loss and calculate gradients", "\n", "self", ".", "loss_G", "=", "self", ".", "loss_G_A", "+", "self", ".", "loss_G_B", "+", "self", ".", "loss_cycle_A", "+", "self", ".", "loss_cycle_B", "+", "self", ".", "loss_idt_A", "+", "self", ".", "loss_idt_B", "\n", "if", "self", ".", "opt", ".", "amp", ":", "\n", "            ", "with", "amp", ".", "scale_loss", "(", "self", ".", "loss_G", ",", "self", ".", "optimizer_G", ")", "as", "scaled_loss", ":", "\n", "                ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "loss_G", ".", "backward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.cycle_gan_model.CycleGANModel.data_dependent_initialize": [[193, 195], ["None"], "methods", ["None"], ["", "", "def", "data_dependent_initialize", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.cycle_gan_model.CycleGANModel.generate_visuals_for_evaluation": [[196, 207], ["torch.no_grad", "data[].to", "G", "ValueError"], "methods", ["None"], ["", "def", "generate_visuals_for_evaluation", "(", "self", ",", "data", ",", "mode", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "visuals", "=", "{", "}", "\n", "AtoB", "=", "self", ".", "opt", ".", "direction", "==", "\"AtoB\"", "\n", "G", "=", "self", ".", "netG_A", "\n", "source", "=", "data", "[", "\"A\"", "if", "AtoB", "else", "\"B\"", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "if", "mode", "==", "\"forward\"", ":", "\n", "                ", "visuals", "[", "\"fake_B\"", "]", "=", "G", "(", "source", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"mode %s is not recognized\"", "%", "mode", ")", "\n", "", "return", "visuals", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.cycle_gan_model.CycleGANModel.optimize_parameters": [[208, 223], ["cycle_gan_model.CycleGANModel.forward", "cycle_gan_model.CycleGANModel.set_requires_grad", "cycle_gan_model.CycleGANModel.optimizer_G.zero_grad", "cycle_gan_model.CycleGANModel.backward_G", "cycle_gan_model.CycleGANModel.optimizer_G.step", "cycle_gan_model.CycleGANModel.set_requires_grad", "cycle_gan_model.CycleGANModel.optimizer_D.zero_grad", "cycle_gan_model.CycleGANModel.backward_D_A", "cycle_gan_model.CycleGANModel.backward_D_B", "cycle_gan_model.CycleGANModel.optimizer_D.step"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.forward", "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.seanjia_srunit.models.cycle_gan_model.CycleGANModel.backward_G", "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.seanjia_srunit.models.cycle_gan_model.CycleGANModel.backward_D_A", "home.repos.pwc.inspect_result.seanjia_srunit.models.cycle_gan_model.CycleGANModel.backward_D_B"], ["", "", "def", "optimize_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"", "\n", "# forward", "\n", "self", ".", "forward", "(", ")", "# compute fake images and reconstruction images.", "\n", "# G_A and G_B", "\n", "self", ".", "set_requires_grad", "(", "[", "self", ".", "netD_A", ",", "self", ".", "netD_B", "]", ",", "False", ")", "# Ds require no gradients when optimizing Gs", "\n", "self", ".", "optimizer_G", ".", "zero_grad", "(", ")", "# set G_A and G_B's gradients to zero", "\n", "self", ".", "backward_G", "(", ")", "# calculate gradients for G_A and G_B", "\n", "self", ".", "optimizer_G", ".", "step", "(", ")", "# update G_A and G_B's weights", "\n", "# D_A and D_B", "\n", "self", ".", "set_requires_grad", "(", "[", "self", ".", "netD_A", ",", "self", ".", "netD_B", "]", ",", "True", ")", "\n", "self", ".", "optimizer_D", ".", "zero_grad", "(", ")", "# set D_A and D_B's gradients to zero", "\n", "self", ".", "backward_D_A", "(", ")", "# calculate gradients for D_A", "\n", "self", ".", "backward_D_B", "(", ")", "# calculate graidents for D_B", "\n", "self", ".", "optimizer_D", ".", "step", "(", ")", "# update D_A and D_B's weights", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seanjia_srunit.models.__init__.find_model_using_name": [[25, 46], ["importlib.import_module", "importlib.import_module.__dict__.items", "model_name.replace", "print", "exit", "issubclass", "name.lower", "target_model_name.lower"], "function", ["None"], []], "home.repos.pwc.inspect_result.seanjia_srunit.models.__init__.get_option_setter": [[48, 52], ["__init__.find_model_using_name"], "function", ["home.repos.pwc.inspect_result.seanjia_srunit.models.__init__.find_model_using_name"], []], "home.repos.pwc.inspect_result.seanjia_srunit.models.__init__.create_model": [[54, 68], ["__init__.find_model_using_name", "find_model_using_name.", "print", "type"], "function", ["home.repos.pwc.inspect_result.seanjia_srunit.models.__init__.find_model_using_name"], []], "home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.modify_commandline_options": [[21, 61], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.set_defaults", "parser.parse_known_args", "opt.CUT_mode.lower", "parser.set_defaults", "opt.CUT_mode.lower", "parser.set_defaults", "ValueError"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", "=", "True", ")", ":", "\n", "        ", "\"\"\"  Configures options specific for CUT model\n\n        Configs w.r.t. semantic robustness loss are in options/base_options.py\n        \"\"\"", "\n", "parser", ".", "add_argument", "(", "'--CUT_mode'", ",", "type", "=", "str", ",", "default", "=", "\"CUT\"", ",", "choices", "=", "'(CUT, cut, FastCUT, fastcut)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_GAN'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'weight for GAN loss\uff1aGAN(G(X))'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_NCE'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'weight for NCE loss: NCE(G(X), X)'", ")", "\n", "parser", ".", "add_argument", "(", "'--nce_idt'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "False", ",", "help", "=", "'use NCE loss for identity mapping: NCE(G(Y), Y))'", ")", "\n", "parser", ".", "add_argument", "(", "'--nce_layers'", ",", "type", "=", "str", ",", "default", "=", "'0,4,8,12,16'", ",", "help", "=", "'compute NCE loss on which layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--nce_includes_all_negatives_from_minibatch'", ",", "\n", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "False", ",", "\n", "help", "=", "'(used for single image translation) If True, include the negatives from the other samples of the minibatch when computing the contrastive loss. Please see models/patchnce.py for more details.'", ")", "\n", "parser", ".", "add_argument", "(", "'--netF'", ",", "type", "=", "str", ",", "default", "=", "'mlp_sample'", ",", "choices", "=", "[", "'sample'", ",", "'reshape'", ",", "'mlp_sample'", "]", ",", "help", "=", "'how to downsample the feature map'", ")", "\n", "parser", ".", "add_argument", "(", "'--netF_nc'", ",", "type", "=", "int", ",", "default", "=", "256", ")", "\n", "parser", ".", "add_argument", "(", "'--nce_T'", ",", "type", "=", "float", ",", "default", "=", "0.07", ",", "help", "=", "'temperature for NCE loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_patches'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'number of patches per layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--flip_equivariance'", ",", "\n", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "False", ",", "\n", "help", "=", "\"Enforce flip-equivariance as additional regularization. It's used by FastCUT, but not CUT\"", ")", "\n", "parser", ".", "add_argument", "(", "'--nfdf'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'# of feature discrim filters in the first conv layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--reg_layers'", ",", "type", "=", "str", ",", "default", "=", "'0,1,2,3,4'", ",", "help", "=", "'semantic robustness regularization on which layers'", ")", "\n", "\n", "parser", ".", "set_defaults", "(", "pool_size", "=", "0", ")", "# no image pooling", "\n", "\n", "opt", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "\n", "# Set default parameters for CUT and FastCUT", "\n", "if", "opt", ".", "CUT_mode", ".", "lower", "(", ")", "==", "\"cut\"", ":", "\n", "            ", "parser", ".", "set_defaults", "(", "nce_idt", "=", "True", ",", "lambda_NCE", "=", "1.0", ")", "\n", "", "elif", "opt", ".", "CUT_mode", ".", "lower", "(", ")", "==", "\"fastcut\"", ":", "\n", "            ", "parser", ".", "set_defaults", "(", "\n", "nce_idt", "=", "False", ",", "lambda_NCE", "=", "10.0", ",", "flip_equivariance", "=", "True", ",", "\n", "n_epochs", "=", "150", ",", "n_epochs_decay", "=", "50", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "opt", ".", "CUT_mode", ")", "\n", "\n", "", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.__init__": [[62, 112], ["base_model.BaseModel.__init__", "torch.nn.ReLU", "networks.define_G", "networks.define_F", "networks.GANLoss().to", "int", "float", "srunit_model.SRUNITModel.criterionNCE.append", "networks.define_D", "torch.nn.L1Loss().to", "torch.optim.Adam", "torch.optim.Adam", "srunit_model.SRUNITModel.optimizers.append", "srunit_model.SRUNITModel.optimizers.append", "srunit_model.SRUNITModel.opt.nce_layers.split", "networks.GANLoss", "patchnce.PatchNCELoss().to", "srunit_model.SRUNITModel.netG.parameters", "srunit_model.SRUNITModel.netD.parameters", "torch.nn.L1Loss", "patchnce.PatchNCELoss"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.define_G", "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.define_F", "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.define_D"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "BaseModel", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "# specify the training losses you want to print out.", "\n", "# The training/test scripts will call <BaseModel.get_current_losses>", "\n", "self", ".", "loss_names", "=", "[", "'G_GAN'", ",", "'D_real'", ",", "'D_fake'", ",", "'G'", ",", "'NCE'", "]", "\n", "self", ".", "visual_names", "=", "[", "'real_A'", ",", "'fake_B'", ",", "'real_B'", "]", "\n", "self", ".", "nce_layers", "=", "[", "int", "(", "i", ")", "for", "i", "in", "self", ".", "opt", ".", "nce_layers", ".", "split", "(", "','", ")", "]", "\n", "\n", "if", "self", ".", "opt", ".", "isTrain", ":", "\n", "            ", "self", ".", "reg", "=", "float", "(", "opt", ".", "reg", ")", "\n", "if", "self", ".", "reg", ">", "0.0", ":", "\n", "                ", "assert", "self", ".", "opt", ".", "netF", "==", "'mlp_sample'", "\n", "assert", "self", ".", "opt", ".", "reg_type", "\n", "assert", "self", ".", "opt", ".", "reg_noise", ">", "0.0", "\n", "self", ".", "loss_names", "+=", "[", "'reg'", "]", "\n", "\n", "", "", "if", "opt", ".", "nce_idt", "and", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "loss_names", "+=", "[", "'NCE_Y'", "]", "\n", "self", ".", "visual_names", "+=", "[", "'idt_B'", "]", "\n", "\n", "", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "model_names", "=", "[", "'G'", ",", "'F'", ",", "'D'", "]", "\n", "", "else", ":", "# during test time, only load G", "\n", "            ", "self", ".", "model_names", "=", "[", "'G'", "]", "\n", "\n", "# define networks (both generator and discriminator)", "\n", "", "self", ".", "netG", "=", "networks", ".", "define_G", "(", "\n", "opt", ".", "input_nc", ",", "opt", ".", "output_nc", ",", "opt", ".", "ngf", ",", "opt", ".", "netG", ",", "opt", ".", "normG", ",", "not", "opt", ".", "no_dropout", ",", "\n", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "opt", ".", "no_antialias", ",", "opt", ".", "no_antialias_up", ",", "self", ".", "gpu_ids", ",", "opt", ")", "\n", "self", ".", "netF", "=", "networks", ".", "define_F", "(", "\n", "opt", ".", "input_nc", ",", "opt", ".", "netF", ",", "opt", ".", "normG", ",", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "\n", "opt", ".", "init_gain", ",", "opt", ".", "no_antialias", ",", "self", ".", "gpu_ids", ",", "opt", ")", "\n", "\n", "# define loss functions", "\n", "self", ".", "criterionGAN", "=", "networks", ".", "GANLoss", "(", "opt", ".", "gan_mode", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "criterionNCE", "=", "[", "]", "\n", "for", "nce_layer", "in", "self", ".", "nce_layers", ":", "\n", "            ", "self", ".", "criterionNCE", ".", "append", "(", "PatchNCELoss", "(", "opt", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "\n", "", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "netD", "=", "networks", ".", "define_D", "(", "\n", "opt", ".", "output_nc", ",", "opt", ".", "ndf", ",", "opt", ".", "netD", ",", "opt", ".", "n_layers_D", ",", "opt", ".", "normD", ",", "opt", ".", "init_type", ",", "\n", "opt", ".", "init_gain", ",", "opt", ".", "no_antialias", ",", "self", ".", "gpu_ids", ",", "opt", ",", "noise", "=", "opt", ".", "D_noise", ")", "\n", "self", ".", "criterionIdt", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "optimizer_G", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "netG", ".", "parameters", "(", ")", ",", "lr", "=", "opt", ".", "lr", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "opt", ".", "beta2", ")", ")", "\n", "self", ".", "optimizer_D", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "netD", ".", "parameters", "(", ")", ",", "lr", "=", "opt", ".", "lr", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "opt", ".", "beta2", ")", ")", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_G", ")", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_D", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.data_dependent_initialize": [[113, 133], ["srunit_model.SRUNITModel.set_input", "srunit_model.SRUNITModel.forward", "srunit_model.SRUNITModel.real_A.size", "max", "srunit_model.SRUNITModel.compute_D_loss().backward", "srunit_model.SRUNITModel.compute_G_loss().backward", "len", "torch.optim.Adam", "srunit_model.SRUNITModel.optimizers.append", "srunit_model.SRUNITModel.compute_D_loss", "srunit_model.SRUNITModel.compute_G_loss", "srunit_model.SRUNITModel.netF.parameters"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.set_input", "home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.forward", "home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.backward", "home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.backward", "home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.compute_D_loss", "home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.compute_G_loss"], ["", "", "def", "data_dependent_initialize", "(", "self", ",", "data", ",", "infer_mode", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        The feature network netF is defined in terms of the shape of the intermediate, extracted\n        features of the encoder portion of netG. Because of this, the weights of netF are\n        initialized at the first feedforward pass with some input images.\n        Please also see PatchSampleF.create_mlp(), which is called at the first forward() call.\n        \"\"\"", "\n", "self", ".", "set_input", "(", "data", ")", "\n", "bs_per_gpu", "=", "self", ".", "real_A", ".", "size", "(", "0", ")", "//", "max", "(", "len", "(", "self", ".", "opt", ".", "gpu_ids", ")", ",", "1", ")", "\n", "self", ".", "real_A", "=", "self", ".", "real_A", "[", ":", "bs_per_gpu", "]", "\n", "self", ".", "real_B", "=", "self", ".", "real_B", "[", ":", "bs_per_gpu", "]", "\n", "self", ".", "forward", "(", "infer_init", "=", "infer_mode", ")", "# compute fake images: G(A)", "\n", "\n", "if", "self", ".", "opt", ".", "isTrain", ":", "\n", "            ", "self", ".", "compute_D_loss", "(", ")", ".", "backward", "(", ")", "# calculate gradients for D", "\n", "self", ".", "compute_G_loss", "(", ")", ".", "backward", "(", ")", "# calculate graidents for G", "\n", "if", "self", ".", "opt", ".", "lambda_NCE", ">", "0.0", ":", "\n", "                ", "self", ".", "optimizer_F", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "self", ".", "netF", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "opt", ".", "lr", ",", "betas", "=", "(", "self", ".", "opt", ".", "beta1", ",", "self", ".", "opt", ".", "beta2", ")", ")", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_F", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.optimize_parameters": [[134, 178], ["srunit_model.SRUNITModel.forward", "srunit_model.SRUNITModel.set_requires_grad", "srunit_model.SRUNITModel.optimizer_D.zero_grad", "srunit_model.SRUNITModel.compute_D_loss", "srunit_model.SRUNITModel.loss_D.backward", "srunit_model.SRUNITModel.optimizer_D.step", "srunit_model.SRUNITModel.set_requires_grad", "srunit_model.SRUNITModel.set_requires_grad", "srunit_model.SRUNITModel.optimizer_G.zero_grad", "srunit_model.SRUNITModel.compute_G_loss", "srunit_model.SRUNITModel.loss_G.backward", "srunit_model.SRUNITModel.optimizer_G.step", "srunit_model.SRUNITModel.optimizer_F.zero_grad", "loss.backward", "srunit_model.SRUNITModel.optimizer_G.step", "srunit_model.SRUNITModel.optimizer_F.step", "srunit_model.SRUNITModel.optimizer_F.zero_grad", "srunit_model.SRUNITModel.optimizer_F.step", "srunit_model.SRUNITModel.loss_G.backward", "srunit_model.SRUNITModel.set_requires_grad", "srunit_model.SRUNITModel.compute_reg_loss", "srunit_model.SRUNITModel.compute_reg_loss"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.forward", "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.compute_D_loss", "home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.backward", "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.compute_G_loss", "home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.backward", "home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.backward", "home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.backward", "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.compute_reg_loss", "home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.compute_reg_loss"], ["", "", "", "def", "optimize_parameters", "(", "self", ",", "curr_epoch", ")", ":", "\n", "# forward", "\n", "        ", "self", ".", "forward", "(", ")", "\n", "\n", "# update D", "\n", "self", ".", "set_requires_grad", "(", "self", ".", "netD", ",", "True", ")", "\n", "self", ".", "optimizer_D", ".", "zero_grad", "(", ")", "\n", "self", ".", "loss_D", "=", "self", ".", "compute_D_loss", "(", ")", "# G detached.", "\n", "self", ".", "loss_D", ".", "backward", "(", ")", "\n", "self", ".", "optimizer_D", ".", "step", "(", ")", "\n", "\n", "# update G", "\n", "self", ".", "set_requires_grad", "(", "self", ".", "netD", ",", "False", ")", "\n", "self", ".", "set_requires_grad", "(", "self", ".", "netF", ",", "True", ")", "\n", "self", ".", "optimizer_G", ".", "zero_grad", "(", ")", "\n", "self", ".", "loss_G", "=", "self", ".", "compute_G_loss", "(", ")", "\n", "\n", "if", "self", ".", "reg", ">", "0.0", ":", "# The Semantic Robustness Regularization in SRUNIT.", "\n", "            ", "if", "curr_epoch", ">", "self", ".", "opt", ".", "inact_epochs", ":", "\n", "                ", "self", ".", "optimizer_F", ".", "zero_grad", "(", ")", "# self.opt.netF must be 'mlp_sample' here.", "\n", "\n", "if", "self", ".", "opt", ".", "reg_type", "==", "'v1'", ":", "\n", "                    ", "self", ".", "loss_G", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "self", ".", "set_requires_grad", "(", "self", ".", "netF", ",", "False", ")", "\n", "self", ".", "loss_reg", "=", "self", ".", "compute_reg_loss", "(", ")", "\n", "loss", "=", "self", ".", "reg", "*", "self", ".", "loss_reg", "\n", "", "elif", "self", ".", "opt", ".", "reg_type", "==", "'v2'", ":", "\n", "                    ", "self", ".", "loss_reg", "=", "self", ".", "compute_reg_loss", "(", ")", "\n", "loss", "=", "self", ".", "loss_G", "+", "self", ".", "reg", "*", "self", ".", "loss_reg", "\n", "", "else", ":", "\n", "                    ", "assert", "False", ",", "self", ".", "opt", ".", "reg_type", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer_G", ".", "step", "(", ")", "\n", "self", ".", "optimizer_F", ".", "step", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "loss_reg", "=", "0.0", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "opt", ".", "netF", "==", "'mlp_sample'", ":", "\n", "                ", "self", ".", "optimizer_F", ".", "zero_grad", "(", ")", "# Clean the gradient before loss_G.backward()", "\n", "", "self", ".", "loss_G", ".", "backward", "(", ")", "\n", "self", ".", "optimizer_G", ".", "step", "(", ")", "\n", "if", "self", ".", "opt", ".", "netF", "==", "'mlp_sample'", ":", "\n", "                ", "self", ".", "optimizer_F", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.set_input": [[179, 189], ["input[].to", "input[].to"], "methods", ["None"], ["", "", "", "def", "set_input", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n        Parameters:\n            input (dict): include the data itself and its metadata information.\n        The option 'direction' can be used to swap domain A and domain B.\n        \"\"\"", "\n", "AtoB", "=", "self", ".", "opt", ".", "direction", "==", "'AtoB'", "\n", "self", ".", "real_A", "=", "input", "[", "'A'", "if", "AtoB", "else", "'B'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "real_B", "=", "input", "[", "'B'", "if", "AtoB", "else", "'A'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "image_paths", "=", "input", "[", "'A_paths'", "if", "AtoB", "else", "'B_paths'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.forward": [[190, 216], ["srunit_model.SRUNITModel.netG", "srunit_model.SRUNITModel.netG", "torch.cat", "srunit_model.SRUNITModel.netG", "srunit_model.SRUNITModel.netG", "torch.flip", "srunit_model.SRUNITModel.real_A.size", "srunit_model.SRUNITModel.real_A.size", "int", "numpy.random.choice", "numpy.random.random", "srunit_model.SRUNITModel.opt.reg_layers.split"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "infer_init", "=", "False", ")", ":", "\n", "        ", "\"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"", "\n", "self", ".", "real", "=", "torch", ".", "cat", "(", "(", "self", ".", "real_A", ",", "self", ".", "real_B", ")", ",", "dim", "=", "0", ")", "if", "self", ".", "opt", ".", "nce_idt", "and", "self", ".", "opt", ".", "isTrain", "else", "self", ".", "real_A", "\n", "if", "self", ".", "opt", ".", "flip_equivariance", ":", "\n", "            ", "self", ".", "flipped_for_equivariance", "=", "self", ".", "opt", ".", "isTrain", "and", "(", "np", ".", "random", ".", "random", "(", ")", "<", "0.5", ")", "\n", "if", "self", ".", "flipped_for_equivariance", ":", "\n", "                ", "self", ".", "real", "=", "torch", ".", "flip", "(", "self", ".", "real", ",", "[", "3", "]", ")", "\n", "\n", "", "", "self", ".", "real_A", "=", "self", ".", "real", "[", ":", "self", ".", "real_A", ".", "size", "(", "0", ")", "]", "\n", "self", ".", "real_B", "=", "self", ".", "real", "[", "self", ".", "real_A", ".", "size", "(", "0", ")", ":", "]", "\n", "self", ".", "fake_B", ",", "self", ".", "feats_real_A", "=", "self", ".", "netG", "(", "self", ".", "real_A", ",", "self", ".", "nce_layers", ")", "\n", "self", ".", "feats_fake_B", "=", "self", ".", "netG", "(", "self", ".", "fake_B", ",", "self", ".", "nce_layers", ",", "encode_only", "=", "True", ")", "\n", "\n", "if", "self", ".", "isTrain", "and", "self", ".", "reg", ">", "0.0", ":", "\n", "\n", "# Only choose one layer each time to speed up SRUNIT.", "\n", "            ", "choices", "=", "[", "int", "(", "l", ")", "for", "l", "in", "self", ".", "opt", ".", "reg_layers", ".", "split", "(", "','", ")", "]", "\n", "self", ".", "choice", "=", "np", ".", "random", ".", "choice", "(", "choices", ",", "1", ")", "[", "0", "]", "\n", "self", ".", "feats_perturbed", ",", "self", ".", "noise_magnitude", "=", "self", ".", "netG", "(", "\n", "layers", "=", "[", "self", ".", "nce_layers", "[", "self", ".", "choice", "]", "]", ",", "\n", "feats", "=", "[", "self", ".", "feats_real_A", "[", "self", ".", "choice", "]", "]", ",", "\n", "noises", "=", "[", "self", ".", "opt", ".", "reg_noise", "]", ")", "\n", "\n", "", "if", "self", ".", "opt", ".", "isTrain", "and", "self", ".", "opt", ".", "nce_idt", ":", "\n", "            ", "self", ".", "idt_B", ",", "self", ".", "feats_real_B", "=", "self", ".", "netG", "(", "self", ".", "real_B", ",", "self", ".", "nce_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.compute_reg_loss": [[217, 236], ["srunit_model.SRUNITModel.netF", "srunit_model.SRUNITModel.netF", "zip", "d.pow", "[].flatten", "loss.mean", "len", "d.pow().sum", "srunit_model.SRUNITModel.compute_reg_loss.euc_dis"], "methods", ["None"], ["", "", "def", "compute_reg_loss", "(", "self", ")", ":", "\n", "\n", "# Distance function.", "\n", "        ", "def", "euc_dis", "(", "x", ",", "y", ",", "dim", "=", "-", "1", ")", ":", "\n", "            ", "d", "=", "x", "-", "y", "\n", "d", "=", "d", ".", "pow", "(", "2", ")", ".", "sum", "(", "dim", ")", "+", "1e-12", "\n", "return", "d", ".", "pow", "(", "0.5", ")", "\n", "\n", "# To speed up SRUNIT, we only sample patches to compute the semantic robustness loss.", "\n", "", "feat_k_pool", ",", "sample_ids", "=", "self", ".", "netF", "(", "\n", "[", "self", ".", "feats_real_A", "[", "self", ".", "choice", "]", "]", ",", "self", ".", "opt", ".", "num_patches", ",", "None", ",", "use_mlp", "=", "True", ",", "choice", "=", "self", ".", "choice", ")", "\n", "feat_q_pool", ",", "_", "=", "self", ".", "netF", "(", "\n", "self", ".", "feats_perturbed", ",", "self", ".", "opt", ".", "num_patches", ",", "sample_ids", ",", "use_mlp", "=", "True", ",", "choice", "=", "self", ".", "choice", ")", "\n", "total_reg_loss", "=", "0.0", "\n", "for", "f_q", ",", "f_k", ",", "noise_mag", ",", "samples", "in", "zip", "(", "feat_q_pool", ",", "feat_k_pool", ",", "self", ".", "noise_magnitude", ",", "sample_ids", ")", ":", "\n", "            ", "noise_mag", "=", "(", "noise_mag", ".", "flatten", "(", "1", ",", "3", ")", "[", ":", ",", "samples", "]", ")", ".", "flatten", "(", "0", ",", "1", ")", "# to support batch_size > 1 per gpu.", "\n", "loss", "=", "euc_dis", "(", "f_q", ",", "f_k", ")", "/", "noise_mag", "\n", "total_reg_loss", "+=", "loss", ".", "mean", "(", ")", "\n", "", "return", "total_reg_loss", "/", "len", "(", "self", ".", "nce_layers", ")", "# actually len(self.nce_layers) == 1 here.", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.compute_D_loss": [[237, 250], ["srunit_model.SRUNITModel.fake_B.detach", "srunit_model.SRUNITModel.netD", "srunit_model.SRUNITModel.criterionGAN().mean", "srunit_model.SRUNITModel.netD", "srunit_model.SRUNITModel.criterionGAN().mean", "srunit_model.SRUNITModel.criterionGAN", "srunit_model.SRUNITModel.criterionGAN"], "methods", ["None"], ["", "def", "compute_D_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for the discriminator\"\"\"", "\n", "fake", "=", "self", ".", "fake_B", ".", "detach", "(", ")", "\n", "# Fake; stop backprop to the generator by detaching fake_B", "\n", "pred_fake", "=", "self", ".", "netD", "(", "fake", ")", "\n", "self", ".", "loss_D_fake", "=", "self", ".", "criterionGAN", "(", "pred_fake", ",", "False", ")", ".", "mean", "(", ")", "\n", "# Real", "\n", "self", ".", "pred_real", "=", "self", ".", "netD", "(", "self", ".", "real_B", ")", "\n", "self", ".", "loss_D_real", "=", "self", ".", "criterionGAN", "(", "self", ".", "pred_real", ",", "True", ")", ".", "mean", "(", ")", "\n", "\n", "# combine loss and calculate gradients", "\n", "self", ".", "loss_D", "=", "(", "self", ".", "loss_D_fake", "+", "self", ".", "loss_D_real", ")", "*", "0.5", "\n", "return", "self", ".", "loss_D", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.compute_G_loss": [[251, 274], ["srunit_model.SRUNITModel.netD", "srunit_model.SRUNITModel.calculate_NCE_loss", "srunit_model.SRUNITModel.netG", "srunit_model.SRUNITModel.calculate_NCE_loss", "srunit_model.SRUNITModel.criterionGAN().mean", "srunit_model.SRUNITModel.criterionGAN"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.calculate_NCE_loss", "home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.calculate_NCE_loss"], ["", "def", "compute_G_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate GAN and NCE loss for the generator\"\"\"", "\n", "fake", "=", "self", ".", "fake_B", "\n", "# First, G(A) should fake the discriminator", "\n", "if", "self", ".", "opt", ".", "lambda_GAN", ">", "0.0", ":", "\n", "            ", "pred_fake", "=", "self", ".", "netD", "(", "fake", ")", "\n", "self", ".", "loss_G_GAN", "=", "self", ".", "criterionGAN", "(", "pred_fake", ",", "True", ")", ".", "mean", "(", ")", "*", "self", ".", "opt", ".", "lambda_GAN", "\n", "", "else", ":", "\n", "            ", "self", ".", "loss_G_GAN", "=", "0.0", "\n", "\n", "", "if", "self", ".", "opt", ".", "lambda_NCE", ">", "0.0", ":", "\n", "            ", "self", ".", "loss_NCE", "=", "self", ".", "calculate_NCE_loss", "(", "self", ".", "feats_real_A", ",", "self", ".", "feats_fake_B", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "loss_NCE", ",", "self", ".", "loss_NCE_bd", "=", "0.0", ",", "0.0", "\n", "\n", "", "if", "self", ".", "opt", ".", "nce_idt", "and", "self", ".", "opt", ".", "lambda_NCE", ">", "0.0", ":", "\n", "            ", "self", ".", "feats_idt_B", "=", "self", ".", "netG", "(", "self", ".", "idt_B", ",", "self", ".", "nce_layers", ",", "encode_only", "=", "True", ")", "\n", "self", ".", "loss_NCE_Y", "=", "self", ".", "calculate_NCE_loss", "(", "self", ".", "feats_real_B", ",", "self", ".", "feats_idt_B", ")", "\n", "loss_NCE_both", "=", "(", "self", ".", "loss_NCE", "+", "self", ".", "loss_NCE_Y", ")", "*", "0.5", "\n", "", "else", ":", "\n", "            ", "loss_NCE_both", "=", "self", ".", "loss_NCE", "\n", "", "self", ".", "loss_G", "=", "self", ".", "loss_G_GAN", "+", "loss_NCE_both", "\n", "return", "self", ".", "loss_G", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.srunit_model.SRUNITModel.calculate_NCE_loss": [[275, 291], ["len", "srunit_model.SRUNITModel.netF", "srunit_model.SRUNITModel.netF", "zip", "loss.mean", "torch.flip", "crit"], "methods", ["None"], ["", "def", "calculate_NCE_loss", "(", "self", ",", "src", ",", "tgt", ")", ":", "\n", "        ", "n_layers", "=", "len", "(", "self", ".", "nce_layers", ")", "\n", "\n", "assert", "not", "(", "self", ".", "opt", ".", "flip_equivariance", "and", "self", ".", "flipped_for_equivariance", ")", "\n", "if", "self", ".", "opt", ".", "flip_equivariance", "and", "self", ".", "flipped_for_equivariance", ":", "\n", "            ", "feat_q", "=", "[", "torch", ".", "flip", "(", "fq", ",", "[", "3", "]", ")", "for", "fq", "in", "feat_q", "]", "\n", "\n", "", "feat_k_pool", ",", "sample_ids", "=", "self", ".", "netF", "(", "src", ",", "self", ".", "opt", ".", "num_patches", ",", "None", ")", "\n", "feat_q_pool", ",", "_", "=", "self", ".", "netF", "(", "tgt", ",", "self", ".", "opt", ".", "num_patches", ",", "sample_ids", ")", "\n", "\n", "total_nce_loss", "=", "0.0", "\n", "for", "f_q", ",", "f_k", ",", "crit", ",", "nce_layer", "in", "zip", "(", "\n", "feat_q_pool", ",", "feat_k_pool", ",", "self", ".", "criterionNCE", ",", "self", ".", "nce_layers", ")", ":", "\n", "            ", "loss", "=", "crit", "(", "f_q", ",", "f_k", ")", "*", "self", ".", "opt", ".", "lambda_NCE", "\n", "total_nce_loss", "+=", "loss", ".", "mean", "(", ")", "\n", "", "return", "total_nce_loss", "/", "n_layers", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.FusedLeakyReLU.__init__": [[22, 27], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channel", ",", "negative_slope", "=", "0.2", ",", "scale", "=", "2", "**", "0.5", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "channel", ",", "1", ",", "1", ")", ")", "\n", "self", ".", "negative_slope", "=", "negative_slope", "\n", "self", ".", "scale", "=", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.FusedLeakyReLU.forward": [[28, 35], ["stylegan_networks.fused_leaky_relu"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.fused_leaky_relu"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# print(\"FusedLeakyReLU: \", input.abs().mean())", "\n", "        ", "out", "=", "fused_leaky_relu", "(", "input", ",", "self", ".", "bias", ",", "\n", "self", ".", "negative_slope", ",", "\n", "self", ".", "scale", ")", "\n", "# print(\"FusedLeakyReLU: \", out.abs().mean())", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.PixelNorm.__init__": [[79, 81], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.PixelNorm.forward": [[82, 84], ["torch.rsqrt", "torch.mean"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "input", "*", "torch", ".", "rsqrt", "(", "torch", ".", "mean", "(", "input", "**", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "+", "1e-8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.Upsample.__init__": [[98, 111], ["torch.nn.Module.__init__", "stylegan_networks.Upsample.register_buffer", "stylegan_networks.make_kernel"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.make_kernel"], ["    ", "def", "__init__", "(", "self", ",", "kernel", ",", "factor", "=", "2", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "factor", "=", "factor", "\n", "kernel", "=", "make_kernel", "(", "kernel", ")", "*", "(", "factor", "**", "2", ")", "\n", "self", ".", "register_buffer", "(", "'kernel'", ",", "kernel", ")", "\n", "\n", "p", "=", "kernel", ".", "shape", "[", "0", "]", "-", "factor", "\n", "\n", "pad0", "=", "(", "p", "+", "1", ")", "//", "2", "+", "factor", "-", "1", "\n", "pad1", "=", "p", "//", "2", "\n", "\n", "self", ".", "pad", "=", "(", "pad0", ",", "pad1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.Upsample.forward": [[112, 116], ["stylegan_networks.upfirdn2d"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.upfirdn2d"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "out", "=", "upfirdn2d", "(", "input", ",", "self", ".", "kernel", ",", "up", "=", "self", ".", "factor", ",", "down", "=", "1", ",", "pad", "=", "self", ".", "pad", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.Downsample.__init__": [[119, 132], ["torch.nn.Module.__init__", "stylegan_networks.make_kernel", "stylegan_networks.Downsample.register_buffer"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.make_kernel"], ["    ", "def", "__init__", "(", "self", ",", "kernel", ",", "factor", "=", "2", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "factor", "=", "factor", "\n", "kernel", "=", "make_kernel", "(", "kernel", ")", "\n", "self", ".", "register_buffer", "(", "'kernel'", ",", "kernel", ")", "\n", "\n", "p", "=", "kernel", ".", "shape", "[", "0", "]", "-", "factor", "\n", "\n", "pad0", "=", "(", "p", "+", "1", ")", "//", "2", "\n", "pad1", "=", "p", "//", "2", "\n", "\n", "self", ".", "pad", "=", "(", "pad0", ",", "pad1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.Downsample.forward": [[133, 137], ["stylegan_networks.upfirdn2d"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.upfirdn2d"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "out", "=", "upfirdn2d", "(", "input", ",", "self", ".", "kernel", ",", "up", "=", "1", ",", "down", "=", "self", ".", "factor", ",", "pad", "=", "self", ".", "pad", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.Blur.__init__": [[140, 151], ["torch.nn.Module.__init__", "stylegan_networks.make_kernel", "stylegan_networks.Blur.register_buffer"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.make_kernel"], ["    ", "def", "__init__", "(", "self", ",", "kernel", ",", "pad", ",", "upsample_factor", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "kernel", "=", "make_kernel", "(", "kernel", ")", "\n", "\n", "if", "upsample_factor", ">", "1", ":", "\n", "            ", "kernel", "=", "kernel", "*", "(", "upsample_factor", "**", "2", ")", "\n", "\n", "", "self", ".", "register_buffer", "(", "'kernel'", ",", "kernel", ")", "\n", "\n", "self", ".", "pad", "=", "pad", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.Blur.forward": [[152, 156], ["stylegan_networks.upfirdn2d"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.upfirdn2d"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "out", "=", "upfirdn2d", "(", "input", ",", "self", ".", "kernel", ",", "pad", "=", "self", ".", "pad", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.EqualConv2d.__init__": [[159, 177], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.randn", "math.sqrt", "math.sqrt", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_channel", ",", "out_channel", ",", "kernel_size", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "True", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "randn", "(", "out_channel", ",", "in_channel", ",", "kernel_size", ",", "kernel_size", ")", "\n", ")", "\n", "self", ".", "scale", "=", "math", ".", "sqrt", "(", "1", ")", "/", "math", ".", "sqrt", "(", "in_channel", "*", "(", "kernel_size", "**", "2", ")", ")", "\n", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "out_channel", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.EqualConv2d.forward": [[178, 190], ["torch.nn.functional.conv2d"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# print(\"Before EqualConv2d: \", input.abs().mean())", "\n", "        ", "out", "=", "F", ".", "conv2d", "(", "\n", "input", ",", "\n", "self", ".", "weight", "*", "self", ".", "scale", ",", "\n", "bias", "=", "self", ".", "bias", ",", "\n", "stride", "=", "self", ".", "stride", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", ")", "\n", "# print(\"After EqualConv2d: \", out.abs().mean(), (self.weight * self.scale).abs().mean())", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.EqualConv2d.__repr__": [[191, 194], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "f'{self.__class__.__name__}({self.weight.shape[1]}, {self.weight.shape[0]},'", "\n", "f' {self.weight.shape[2]}, stride={self.stride}, padding={self.padding})'", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.EqualLinear.__init__": [[199, 216], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.randn().div_", "torch.nn.Parameter", "torch.zeros().fill_", "math.sqrt", "math.sqrt", "torch.randn", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_dim", ",", "out_dim", ",", "bias", "=", "True", ",", "bias_init", "=", "0", ",", "lr_mul", "=", "1", ",", "activation", "=", "None", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "out_dim", ",", "in_dim", ")", ".", "div_", "(", "lr_mul", ")", ")", "\n", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "out_dim", ")", ".", "fill_", "(", "bias_init", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "\n", "", "self", ".", "activation", "=", "activation", "\n", "\n", "self", ".", "scale", "=", "(", "math", ".", "sqrt", "(", "1", ")", "/", "math", ".", "sqrt", "(", "in_dim", ")", ")", "*", "lr_mul", "\n", "self", ".", "lr_mul", "=", "lr_mul", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.EqualLinear.forward": [[217, 228], ["torch.nn.functional.linear", "stylegan_networks.fused_leaky_relu", "torch.nn.functional.linear"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.fused_leaky_relu"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "self", ".", "activation", ":", "\n", "            ", "out", "=", "F", ".", "linear", "(", "input", ",", "self", ".", "weight", "*", "self", ".", "scale", ")", "\n", "out", "=", "fused_leaky_relu", "(", "out", ",", "self", ".", "bias", "*", "self", ".", "lr_mul", ")", "\n", "\n", "", "else", ":", "\n", "            ", "out", "=", "F", ".", "linear", "(", "\n", "input", ",", "self", ".", "weight", "*", "self", ".", "scale", ",", "bias", "=", "self", ".", "bias", "*", "self", ".", "lr_mul", "\n", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.EqualLinear.__repr__": [[229, 232], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "f'{self.__class__.__name__}({self.weight.shape[1]}, {self.weight.shape[0]})'", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.ScaledLeakyReLU.__init__": [[236, 240], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "negative_slope", "=", "0.2", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "negative_slope", "=", "negative_slope", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.ScaledLeakyReLU.forward": [[241, 245], ["torch.nn.functional.leaky_relu", "math.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "out", "=", "F", ".", "leaky_relu", "(", "input", ",", "negative_slope", "=", "self", ".", "negative_slope", ")", "\n", "\n", "return", "out", "*", "math", ".", "sqrt", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.ModulatedConv2d.__init__": [[248, 296], ["torch.nn.Module.__init__", "torch.nn.Parameter", "stylegan_networks.Blur", "stylegan_networks.Blur", "math.sqrt", "math.sqrt", "torch.randn", "stylegan_networks.EqualLinear", "len", "len"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channel", ",", "\n", "out_channel", ",", "\n", "kernel_size", ",", "\n", "style_dim", ",", "\n", "demodulate", "=", "True", ",", "\n", "upsample", "=", "False", ",", "\n", "downsample", "=", "False", ",", "\n", "blur_kernel", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "eps", "=", "1e-8", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "in_channel", "=", "in_channel", "\n", "self", ".", "out_channel", "=", "out_channel", "\n", "self", ".", "upsample", "=", "upsample", "\n", "self", ".", "downsample", "=", "downsample", "\n", "\n", "if", "upsample", ":", "\n", "            ", "factor", "=", "2", "\n", "p", "=", "(", "len", "(", "blur_kernel", ")", "-", "factor", ")", "-", "(", "kernel_size", "-", "1", ")", "\n", "pad0", "=", "(", "p", "+", "1", ")", "//", "2", "+", "factor", "-", "1", "\n", "pad1", "=", "p", "//", "2", "+", "1", "\n", "\n", "self", ".", "blur", "=", "Blur", "(", "blur_kernel", ",", "pad", "=", "(", "pad0", ",", "pad1", ")", ",", "upsample_factor", "=", "factor", ")", "\n", "\n", "", "if", "downsample", ":", "\n", "            ", "factor", "=", "2", "\n", "p", "=", "(", "len", "(", "blur_kernel", ")", "-", "factor", ")", "+", "(", "kernel_size", "-", "1", ")", "\n", "pad0", "=", "(", "p", "+", "1", ")", "//", "2", "\n", "pad1", "=", "p", "//", "2", "\n", "\n", "self", ".", "blur", "=", "Blur", "(", "blur_kernel", ",", "pad", "=", "(", "pad0", ",", "pad1", ")", ")", "\n", "\n", "", "fan_in", "=", "in_channel", "*", "kernel_size", "**", "2", "\n", "self", ".", "scale", "=", "math", ".", "sqrt", "(", "1", ")", "/", "math", ".", "sqrt", "(", "fan_in", ")", "\n", "self", ".", "padding", "=", "kernel_size", "//", "2", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "randn", "(", "1", ",", "out_channel", ",", "in_channel", ",", "kernel_size", ",", "kernel_size", ")", "\n", ")", "\n", "\n", "if", "style_dim", "is", "not", "None", "and", "style_dim", ">", "0", ":", "\n", "            ", "self", ".", "modulation", "=", "EqualLinear", "(", "style_dim", ",", "in_channel", ",", "bias_init", "=", "1", ")", "\n", "\n", "", "self", ".", "demodulate", "=", "demodulate", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.ModulatedConv2d.__repr__": [[297, 300], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "f'{self.__class__.__name__}({self.in_channel}, {self.out_channel}, {self.kernel_size}, '", "\n", "f'upsample={self.upsample}, downsample={self.downsample})'", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.ModulatedConv2d.forward": [[303, 348], ["weight.transpose().reshape.transpose().reshape.view", "stylegan_networks.ModulatedConv2d.modulation().view", "torch.ones().cuda", "torch.rsqrt", "input.view.view.view", "weight.transpose().reshape.transpose().reshape.view", "weight.transpose().reshape.transpose().reshape.transpose().reshape", "torch.nn.functional.conv_transpose2d", "out.view.view.view", "stylegan_networks.ModulatedConv2d.blur", "torch.rsqrt.view", "stylegan_networks.ModulatedConv2d.blur", "input.view.view.view", "torch.nn.functional.conv2d", "out.view.view.view", "input.view.view.view", "torch.nn.functional.conv2d", "out.view.view.view", "stylegan_networks.ModulatedConv2d.modulation", "torch.ones", "weight.transpose().reshape.transpose().reshape.pow().sum", "weight.transpose().reshape.transpose().reshape.transpose", "weight.transpose().reshape.transpose().reshape.pow"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "style", ")", ":", "\n", "        ", "batch", ",", "in_channel", ",", "height", ",", "width", "=", "input", ".", "shape", "\n", "\n", "if", "style", "is", "not", "None", ":", "\n", "            ", "style", "=", "self", ".", "modulation", "(", "style", ")", ".", "view", "(", "batch", ",", "1", ",", "in_channel", ",", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "style", "=", "torch", ".", "ones", "(", "batch", ",", "1", ",", "in_channel", ",", "1", ",", "1", ")", ".", "cuda", "(", ")", "\n", "", "weight", "=", "self", ".", "scale", "*", "self", ".", "weight", "*", "style", "\n", "\n", "if", "self", ".", "demodulate", ":", "\n", "            ", "demod", "=", "torch", ".", "rsqrt", "(", "weight", ".", "pow", "(", "2", ")", ".", "sum", "(", "[", "2", ",", "3", ",", "4", "]", ")", "+", "1e-8", ")", "\n", "weight", "=", "weight", "*", "demod", ".", "view", "(", "batch", ",", "self", ".", "out_channel", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "", "weight", "=", "weight", ".", "view", "(", "\n", "batch", "*", "self", ".", "out_channel", ",", "in_channel", ",", "self", ".", "kernel_size", ",", "self", ".", "kernel_size", "\n", ")", "\n", "\n", "if", "self", ".", "upsample", ":", "\n", "            ", "input", "=", "input", ".", "view", "(", "1", ",", "batch", "*", "in_channel", ",", "height", ",", "width", ")", "\n", "weight", "=", "weight", ".", "view", "(", "\n", "batch", ",", "self", ".", "out_channel", ",", "in_channel", ",", "self", ".", "kernel_size", ",", "self", ".", "kernel_size", "\n", ")", "\n", "weight", "=", "weight", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "\n", "batch", "*", "in_channel", ",", "self", ".", "out_channel", ",", "self", ".", "kernel_size", ",", "self", ".", "kernel_size", "\n", ")", "\n", "out", "=", "F", ".", "conv_transpose2d", "(", "input", ",", "weight", ",", "padding", "=", "0", ",", "stride", "=", "2", ",", "groups", "=", "batch", ")", "\n", "_", ",", "_", ",", "height", ",", "width", "=", "out", ".", "shape", "\n", "out", "=", "out", ".", "view", "(", "batch", ",", "self", ".", "out_channel", ",", "height", ",", "width", ")", "\n", "out", "=", "self", ".", "blur", "(", "out", ")", "\n", "\n", "", "elif", "self", ".", "downsample", ":", "\n", "            ", "input", "=", "self", ".", "blur", "(", "input", ")", "\n", "_", ",", "_", ",", "height", ",", "width", "=", "input", ".", "shape", "\n", "input", "=", "input", ".", "view", "(", "1", ",", "batch", "*", "in_channel", ",", "height", ",", "width", ")", "\n", "out", "=", "F", ".", "conv2d", "(", "input", ",", "weight", ",", "padding", "=", "0", ",", "stride", "=", "2", ",", "groups", "=", "batch", ")", "\n", "_", ",", "_", ",", "height", ",", "width", "=", "out", ".", "shape", "\n", "out", "=", "out", ".", "view", "(", "batch", ",", "self", ".", "out_channel", ",", "height", ",", "width", ")", "\n", "\n", "", "else", ":", "\n", "            ", "input", "=", "input", ".", "view", "(", "1", ",", "batch", "*", "in_channel", ",", "height", ",", "width", ")", "\n", "out", "=", "F", ".", "conv2d", "(", "input", ",", "weight", ",", "padding", "=", "self", ".", "padding", ",", "groups", "=", "batch", ")", "\n", "_", ",", "_", ",", "height", ",", "width", "=", "out", ".", "shape", "\n", "out", "=", "out", ".", "view", "(", "batch", ",", "self", ".", "out_channel", ",", "height", ",", "width", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.NoiseInjection.__init__": [[351, 355], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.NoiseInjection.forward": [[356, 362], ["image.new_empty().normal_", "image.new_empty"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "image", ",", "noise", "=", "None", ")", ":", "\n", "        ", "if", "noise", "is", "None", ":", "\n", "            ", "batch", ",", "_", ",", "height", ",", "width", "=", "image", ".", "shape", "\n", "noise", "=", "image", ".", "new_empty", "(", "batch", ",", "1", ",", "height", ",", "width", ")", ".", "normal_", "(", ")", "\n", "\n", "", "return", "image", "+", "self", ".", "weight", "*", "noise", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.ConstantInput.__init__": [[365, 369], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channel", ",", "size", "=", "4", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "1", ",", "channel", ",", "size", ",", "size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.ConstantInput.forward": [[370, 375], ["stylegan_networks.ConstantInput.input.repeat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "batch", "=", "input", ".", "shape", "[", "0", "]", "\n", "out", "=", "self", ".", "input", ".", "repeat", "(", "batch", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.StyledConv.__init__": [[378, 406], ["torch.nn.Module.__init__", "stylegan_networks.ModulatedConv2d", "stylegan_networks.NoiseInjection", "stylegan_networks.FusedLeakyReLU"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channel", ",", "\n", "out_channel", ",", "\n", "kernel_size", ",", "\n", "style_dim", "=", "None", ",", "\n", "upsample", "=", "False", ",", "\n", "blur_kernel", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "\n", "demodulate", "=", "True", ",", "\n", "inject_noise", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "inject_noise", "=", "inject_noise", "\n", "self", ".", "conv", "=", "ModulatedConv2d", "(", "\n", "in_channel", ",", "\n", "out_channel", ",", "\n", "kernel_size", ",", "\n", "style_dim", ",", "\n", "upsample", "=", "upsample", ",", "\n", "blur_kernel", "=", "blur_kernel", ",", "\n", "demodulate", "=", "demodulate", ",", "\n", ")", "\n", "\n", "self", ".", "noise", "=", "NoiseInjection", "(", ")", "\n", "# self.bias = nn.Parameter(torch.zeros(1, out_channel, 1, 1))", "\n", "# self.activate = ScaledLeakyReLU(0.2)", "\n", "self", ".", "activate", "=", "FusedLeakyReLU", "(", "out_channel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.StyledConv.forward": [[407, 415], ["stylegan_networks.StyledConv.conv", "stylegan_networks.StyledConv.activate", "stylegan_networks.StyledConv.noise"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "style", "=", "None", ",", "noise", "=", "None", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv", "(", "input", ",", "style", ")", "\n", "if", "self", ".", "inject_noise", ":", "\n", "            ", "out", "=", "self", ".", "noise", "(", "out", ",", "noise", "=", "noise", ")", "\n", "# out = out + self.bias", "\n", "", "out", "=", "self", ".", "activate", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.ToRGB.__init__": [[418, 426], ["torch.nn.Module.__init__", "stylegan_networks.ModulatedConv2d", "torch.nn.Parameter", "stylegan_networks.Upsample", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channel", ",", "style_dim", ",", "upsample", "=", "True", ",", "blur_kernel", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "upsample", ":", "\n", "            ", "self", ".", "upsample", "=", "Upsample", "(", "blur_kernel", ")", "\n", "\n", "", "self", ".", "conv", "=", "ModulatedConv2d", "(", "in_channel", ",", "3", ",", "1", ",", "style_dim", ",", "demodulate", "=", "False", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "3", ",", "1", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.ToRGB.forward": [[427, 437], ["stylegan_networks.ToRGB.conv", "stylegan_networks.ToRGB.upsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "style", ",", "skip", "=", "None", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv", "(", "input", ",", "style", ")", "\n", "out", "=", "out", "+", "self", ".", "bias", "\n", "\n", "if", "skip", "is", "not", "None", ":", "\n", "            ", "skip", "=", "self", ".", "upsample", "(", "skip", ")", "\n", "\n", "out", "=", "out", "+", "skip", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.Generator.__init__": [[440, 524], ["torch.nn.Module.__init__", "range", "torch.nn.Sequential", "stylegan_networks.ConstantInput", "stylegan_networks.StyledConv", "stylegan_networks.ToRGB", "int", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Module", "range", "range", "stylegan_networks.PixelNorm", "layers.append", "math.log", "stylegan_networks.Generator.noises.register_buffer", "stylegan_networks.Generator.convs.append", "stylegan_networks.Generator.convs.append", "stylegan_networks.Generator.to_rgbs.append", "stylegan_networks.EqualLinear", "torch.randn", "stylegan_networks.StyledConv", "stylegan_networks.StyledConv", "stylegan_networks.ToRGB"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "size", ",", "\n", "style_dim", ",", "\n", "n_mlp", ",", "\n", "channel_multiplier", "=", "2", ",", "\n", "blur_kernel", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "\n", "lr_mlp", "=", "0.01", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "size", "=", "size", "\n", "\n", "self", ".", "style_dim", "=", "style_dim", "\n", "\n", "layers", "=", "[", "PixelNorm", "(", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "            ", "layers", ".", "append", "(", "\n", "EqualLinear", "(", "\n", "style_dim", ",", "style_dim", ",", "lr_mul", "=", "lr_mlp", ",", "activation", "=", "'fused_lrelu'", "\n", ")", "\n", ")", "\n", "\n", "", "self", ".", "style", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n", "self", ".", "channels", "=", "{", "\n", "4", ":", "512", ",", "\n", "8", ":", "512", ",", "\n", "16", ":", "512", ",", "\n", "32", ":", "512", ",", "\n", "64", ":", "256", "*", "channel_multiplier", ",", "\n", "128", ":", "128", "*", "channel_multiplier", ",", "\n", "256", ":", "64", "*", "channel_multiplier", ",", "\n", "512", ":", "32", "*", "channel_multiplier", ",", "\n", "1024", ":", "16", "*", "channel_multiplier", ",", "\n", "}", "\n", "\n", "self", ".", "input", "=", "ConstantInput", "(", "self", ".", "channels", "[", "4", "]", ")", "\n", "self", ".", "conv1", "=", "StyledConv", "(", "\n", "self", ".", "channels", "[", "4", "]", ",", "self", ".", "channels", "[", "4", "]", ",", "3", ",", "style_dim", ",", "blur_kernel", "=", "blur_kernel", "\n", ")", "\n", "self", ".", "to_rgb1", "=", "ToRGB", "(", "self", ".", "channels", "[", "4", "]", ",", "style_dim", ",", "upsample", "=", "False", ")", "\n", "\n", "self", ".", "log_size", "=", "int", "(", "math", ".", "log", "(", "size", ",", "2", ")", ")", "\n", "self", ".", "num_layers", "=", "(", "self", ".", "log_size", "-", "2", ")", "*", "2", "+", "1", "\n", "\n", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "upsamples", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "to_rgbs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "noises", "=", "nn", ".", "Module", "(", ")", "\n", "\n", "in_channel", "=", "self", ".", "channels", "[", "4", "]", "\n", "\n", "for", "layer_idx", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "res", "=", "(", "layer_idx", "+", "5", ")", "//", "2", "\n", "shape", "=", "[", "1", ",", "1", ",", "2", "**", "res", ",", "2", "**", "res", "]", "\n", "self", ".", "noises", ".", "register_buffer", "(", "f'noise_{layer_idx}'", ",", "torch", ".", "randn", "(", "*", "shape", ")", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "3", ",", "self", ".", "log_size", "+", "1", ")", ":", "\n", "            ", "out_channel", "=", "self", ".", "channels", "[", "2", "**", "i", "]", "\n", "\n", "self", ".", "convs", ".", "append", "(", "\n", "StyledConv", "(", "\n", "in_channel", ",", "\n", "out_channel", ",", "\n", "3", ",", "\n", "style_dim", ",", "\n", "upsample", "=", "True", ",", "\n", "blur_kernel", "=", "blur_kernel", ",", "\n", ")", "\n", ")", "\n", "\n", "self", ".", "convs", ".", "append", "(", "\n", "StyledConv", "(", "\n", "out_channel", ",", "out_channel", ",", "3", ",", "style_dim", ",", "blur_kernel", "=", "blur_kernel", "\n", ")", "\n", ")", "\n", "\n", "self", ".", "to_rgbs", ".", "append", "(", "ToRGB", "(", "out_channel", ",", "style_dim", ")", ")", "\n", "\n", "in_channel", "=", "out_channel", "\n", "\n", "", "self", ".", "n_latent", "=", "self", ".", "log_size", "*", "2", "-", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.Generator.make_noise": [[525, 535], ["range", "torch.randn", "range", "noises.append", "torch.randn"], "methods", ["None"], ["", "def", "make_noise", "(", "self", ")", ":", "\n", "        ", "device", "=", "self", ".", "input", ".", "input", ".", "device", "\n", "\n", "noises", "=", "[", "torch", ".", "randn", "(", "1", ",", "1", ",", "2", "**", "2", ",", "2", "**", "2", ",", "device", "=", "device", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "3", ",", "self", ".", "log_size", "+", "1", ")", ":", "\n", "            ", "for", "_", "in", "range", "(", "2", ")", ":", "\n", "                ", "noises", ".", "append", "(", "torch", ".", "randn", "(", "1", ",", "1", ",", "2", "**", "i", ",", "2", "**", "i", ",", "device", "=", "device", ")", ")", "\n", "\n", "", "", "return", "noises", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.Generator.mean_latent": [[536, 543], ["torch.randn", "stylegan_networks.Generator.style().mean", "stylegan_networks.Generator.style"], "methods", ["None"], ["", "def", "mean_latent", "(", "self", ",", "n_latent", ")", ":", "\n", "        ", "latent_in", "=", "torch", ".", "randn", "(", "\n", "n_latent", ",", "self", ".", "style_dim", ",", "device", "=", "self", ".", "input", ".", "input", ".", "device", "\n", ")", "\n", "latent", "=", "self", ".", "style", "(", "latent_in", ")", ".", "mean", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "\n", "return", "latent", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.Generator.get_latent": [[544, 546], ["stylegan_networks.Generator.style"], "methods", ["None"], ["", "def", "get_latent", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "self", ".", "style", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.Generator.forward": [[547, 619], ["stylegan_networks.Generator.input", "stylegan_networks.Generator.conv1", "stylegan_networks.Generator.to_rgb1", "zip", "len", "styles[].unsqueeze().repeat", "styles[].unsqueeze().repeat", "torch.cat", "conv1", "conv2", "to_rgb", "stylegan_networks.Generator.style", "style_t.append", "len", "styles[].unsqueeze().repeat", "random.randint", "getattr", "styles[].unsqueeze", "styles[].unsqueeze", "range", "styles[].unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "styles", ",", "\n", "return_latents", "=", "False", ",", "\n", "inject_index", "=", "None", ",", "\n", "truncation", "=", "1", ",", "\n", "truncation_latent", "=", "None", ",", "\n", "input_is_latent", "=", "False", ",", "\n", "noise", "=", "None", ",", "\n", "randomize_noise", "=", "True", ",", "\n", ")", ":", "\n", "        ", "if", "not", "input_is_latent", ":", "\n", "            ", "styles", "=", "[", "self", ".", "style", "(", "s", ")", "for", "s", "in", "styles", "]", "\n", "\n", "", "if", "noise", "is", "None", ":", "\n", "            ", "if", "randomize_noise", ":", "\n", "                ", "noise", "=", "[", "None", "]", "*", "self", ".", "num_layers", "\n", "", "else", ":", "\n", "                ", "noise", "=", "[", "\n", "getattr", "(", "self", ".", "noises", ",", "f'noise_{i}'", ")", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", "\n", "]", "\n", "\n", "", "", "if", "truncation", "<", "1", ":", "\n", "            ", "style_t", "=", "[", "]", "\n", "\n", "for", "style", "in", "styles", ":", "\n", "                ", "style_t", ".", "append", "(", "\n", "truncation_latent", "+", "truncation", "*", "(", "style", "-", "truncation_latent", ")", "\n", ")", "\n", "\n", "", "styles", "=", "style_t", "\n", "\n", "", "if", "len", "(", "styles", ")", "<", "2", ":", "\n", "            ", "inject_index", "=", "self", ".", "n_latent", "\n", "\n", "if", "len", "(", "styles", "[", "0", "]", ".", "shape", ")", "<", "3", ":", "\n", "                ", "latent", "=", "styles", "[", "0", "]", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "inject_index", ",", "1", ")", "\n", "\n", "", "else", ":", "\n", "                ", "latent", "=", "styles", "[", "0", "]", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "inject_index", "is", "None", ":", "\n", "                ", "inject_index", "=", "random", ".", "randint", "(", "1", ",", "self", ".", "n_latent", "-", "1", ")", "\n", "\n", "", "latent", "=", "styles", "[", "0", "]", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "inject_index", ",", "1", ")", "\n", "latent2", "=", "styles", "[", "1", "]", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "self", ".", "n_latent", "-", "inject_index", ",", "1", ")", "\n", "\n", "latent", "=", "torch", ".", "cat", "(", "[", "latent", ",", "latent2", "]", ",", "1", ")", "\n", "\n", "", "out", "=", "self", ".", "input", "(", "latent", ")", "\n", "out", "=", "self", ".", "conv1", "(", "out", ",", "latent", "[", ":", ",", "0", "]", ",", "noise", "=", "noise", "[", "0", "]", ")", "\n", "\n", "skip", "=", "self", ".", "to_rgb1", "(", "out", ",", "latent", "[", ":", ",", "1", "]", ")", "\n", "\n", "i", "=", "1", "\n", "for", "conv1", ",", "conv2", ",", "noise1", ",", "noise2", ",", "to_rgb", "in", "zip", "(", "\n", "self", ".", "convs", "[", ":", ":", "2", "]", ",", "self", ".", "convs", "[", "1", ":", ":", "2", "]", ",", "noise", "[", "1", ":", ":", "2", "]", ",", "noise", "[", "2", ":", ":", "2", "]", ",", "self", ".", "to_rgbs", "\n", ")", ":", "\n", "            ", "out", "=", "conv1", "(", "out", ",", "latent", "[", ":", ",", "i", "]", ",", "noise", "=", "noise1", ")", "\n", "out", "=", "conv2", "(", "out", ",", "latent", "[", ":", ",", "i", "+", "1", "]", ",", "noise", "=", "noise2", ")", "\n", "skip", "=", "to_rgb", "(", "out", ",", "latent", "[", ":", ",", "i", "+", "2", "]", ",", "skip", ")", "\n", "\n", "i", "+=", "2", "\n", "\n", "", "image", "=", "skip", "\n", "\n", "if", "return_latents", ":", "\n", "            ", "return", "image", ",", "latent", "\n", "\n", "", "else", ":", "\n", "            ", "return", "image", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.ConvLayer.__init__": [[622, 668], ["layers.append", "torch.nn.Sequential.__init__", "layers.append", "stylegan_networks.EqualConv2d", "stylegan_networks.Blur", "layers.append", "layers.append", "len", "stylegan_networks.FusedLeakyReLU", "stylegan_networks.ScaledLeakyReLU"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channel", ",", "\n", "out_channel", ",", "\n", "kernel_size", ",", "\n", "downsample", "=", "False", ",", "\n", "blur_kernel", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "\n", "bias", "=", "True", ",", "\n", "activate", "=", "True", ",", "\n", ")", ":", "\n", "        ", "layers", "=", "[", "]", "\n", "\n", "if", "downsample", ":", "\n", "            ", "factor", "=", "2", "\n", "p", "=", "(", "len", "(", "blur_kernel", ")", "-", "factor", ")", "+", "(", "kernel_size", "-", "1", ")", "\n", "pad0", "=", "(", "p", "+", "1", ")", "//", "2", "\n", "pad1", "=", "p", "//", "2", "\n", "\n", "layers", ".", "append", "(", "Blur", "(", "blur_kernel", ",", "pad", "=", "(", "pad0", ",", "pad1", ")", ")", ")", "\n", "\n", "stride", "=", "2", "\n", "self", ".", "padding", "=", "0", "\n", "\n", "", "else", ":", "\n", "            ", "stride", "=", "1", "\n", "self", ".", "padding", "=", "kernel_size", "//", "2", "\n", "\n", "", "layers", ".", "append", "(", "\n", "EqualConv2d", "(", "\n", "in_channel", ",", "\n", "out_channel", ",", "\n", "kernel_size", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", "stride", "=", "stride", ",", "\n", "bias", "=", "bias", "and", "not", "activate", ",", "\n", ")", "\n", ")", "\n", "\n", "if", "activate", ":", "\n", "            ", "if", "bias", ":", "\n", "                ", "layers", ".", "append", "(", "FusedLeakyReLU", "(", "out_channel", ")", ")", "\n", "\n", "", "else", ":", "\n", "                ", "layers", ".", "append", "(", "ScaledLeakyReLU", "(", "0.2", ")", ")", "\n", "\n", "", "", "super", "(", ")", ".", "__init__", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.ResBlock.__init__": [[671, 684], ["torch.nn.Module.__init__", "stylegan_networks.ConvLayer", "stylegan_networks.ConvLayer", "stylegan_networks.ConvLayer", "torch.nn.Identity"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channel", ",", "out_channel", ",", "blur_kernel", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "downsample", "=", "True", ",", "skip_gain", "=", "1.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "skip_gain", "=", "skip_gain", "\n", "self", ".", "conv1", "=", "ConvLayer", "(", "in_channel", ",", "in_channel", ",", "3", ")", "\n", "self", ".", "conv2", "=", "ConvLayer", "(", "in_channel", ",", "out_channel", ",", "3", ",", "downsample", "=", "downsample", ",", "blur_kernel", "=", "blur_kernel", ")", "\n", "\n", "if", "in_channel", "!=", "out_channel", "or", "downsample", ":", "\n", "            ", "self", ".", "skip", "=", "ConvLayer", "(", "\n", "in_channel", ",", "out_channel", ",", "1", ",", "downsample", "=", "downsample", ",", "activate", "=", "False", ",", "bias", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "skip", "=", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.ResBlock.forward": [[685, 693], ["stylegan_networks.ResBlock.conv1", "stylegan_networks.ResBlock.conv2", "stylegan_networks.ResBlock.skip", "math.sqrt"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv1", "(", "input", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "\n", "skip", "=", "self", ".", "skip", "(", "input", ")", "\n", "out", "=", "(", "out", "*", "self", ".", "skip_gain", "+", "skip", ")", "/", "math", ".", "sqrt", "(", "self", ".", "skip_gain", "**", "2", "+", "1.0", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.StyleGAN2Discriminator.__init__": [[696, 750], ["torch.nn.Module.__init__", "int", "range", "torch.nn.Sequential", "stylegan_networks.ConvLayer", "min", "min", "min", "min", "int", "int", "int", "int", "int", "stylegan_networks.ConvLayer", "math.log", "convs.append", "stylegan_networks.ConvLayer", "torch.nn.Sequential", "int", "int", "int", "int", "int", "stylegan_networks.ResBlock", "stylegan_networks.EqualLinear", "stylegan_networks.EqualLinear", "numpy.rint", "int", "numpy.log2", "numpy.log2", "min"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_nc", ",", "ndf", "=", "64", ",", "n_layers", "=", "3", ",", "no_antialias", "=", "False", ",", "size", "=", "None", ",", "opt", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "stddev_group", "=", "16", "\n", "if", "size", "is", "None", ":", "\n", "            ", "size", "=", "2", "**", "int", "(", "(", "np", ".", "rint", "(", "np", ".", "log2", "(", "min", "(", "opt", ".", "load_size", ",", "opt", ".", "crop_size", ")", ")", ")", ")", ")", "\n", "if", "\"patch\"", "in", "self", ".", "opt", ".", "netD", "and", "self", ".", "opt", ".", "D_patch_size", "is", "not", "None", ":", "\n", "                ", "size", "=", "2", "**", "int", "(", "np", ".", "log2", "(", "self", ".", "opt", ".", "D_patch_size", ")", ")", "\n", "\n", "", "", "blur_kernel", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", "\n", "channel_multiplier", "=", "ndf", "/", "64", "\n", "channels", "=", "{", "\n", "4", ":", "min", "(", "384", ",", "int", "(", "4096", "*", "channel_multiplier", ")", ")", ",", "\n", "8", ":", "min", "(", "384", ",", "int", "(", "2048", "*", "channel_multiplier", ")", ")", ",", "\n", "16", ":", "min", "(", "384", ",", "int", "(", "1024", "*", "channel_multiplier", ")", ")", ",", "\n", "32", ":", "min", "(", "384", ",", "int", "(", "512", "*", "channel_multiplier", ")", ")", ",", "\n", "64", ":", "int", "(", "256", "*", "channel_multiplier", ")", ",", "\n", "128", ":", "int", "(", "128", "*", "channel_multiplier", ")", ",", "\n", "256", ":", "int", "(", "64", "*", "channel_multiplier", ")", ",", "\n", "512", ":", "int", "(", "32", "*", "channel_multiplier", ")", ",", "\n", "1024", ":", "int", "(", "16", "*", "channel_multiplier", ")", ",", "\n", "}", "\n", "\n", "convs", "=", "[", "ConvLayer", "(", "3", ",", "channels", "[", "size", "]", ",", "1", ")", "]", "\n", "\n", "log_size", "=", "int", "(", "math", ".", "log", "(", "size", ",", "2", ")", ")", "\n", "\n", "in_channel", "=", "channels", "[", "size", "]", "\n", "\n", "if", "\"smallpatch\"", "in", "self", ".", "opt", ".", "netD", ":", "\n", "            ", "final_res_log2", "=", "4", "\n", "", "elif", "\"patch\"", "in", "self", ".", "opt", ".", "netD", ":", "\n", "            ", "final_res_log2", "=", "3", "\n", "", "else", ":", "\n", "            ", "final_res_log2", "=", "2", "\n", "\n", "", "for", "i", "in", "range", "(", "log_size", ",", "final_res_log2", ",", "-", "1", ")", ":", "\n", "            ", "out_channel", "=", "channels", "[", "2", "**", "(", "i", "-", "1", ")", "]", "\n", "\n", "convs", ".", "append", "(", "ResBlock", "(", "in_channel", ",", "out_channel", ",", "blur_kernel", ")", ")", "\n", "\n", "in_channel", "=", "out_channel", "\n", "\n", "", "self", ".", "convs", "=", "nn", ".", "Sequential", "(", "*", "convs", ")", "\n", "\n", "if", "False", "and", "\"tile\"", "in", "self", ".", "opt", ".", "netD", ":", "\n", "            ", "in_channel", "+=", "1", "\n", "", "self", ".", "final_conv", "=", "ConvLayer", "(", "in_channel", ",", "channels", "[", "4", "]", ",", "3", ")", "\n", "if", "\"patch\"", "in", "self", ".", "opt", ".", "netD", ":", "\n", "            ", "self", ".", "final_linear", "=", "ConvLayer", "(", "channels", "[", "4", "]", ",", "1", ",", "3", ",", "bias", "=", "False", ",", "activate", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "final_linear", "=", "nn", ".", "Sequential", "(", "\n", "EqualLinear", "(", "channels", "[", "4", "]", "*", "4", "*", "4", ",", "channels", "[", "4", "]", ",", "activation", "=", "'fused_lrelu'", ")", ",", "\n", "EqualLinear", "(", "channels", "[", "4", "]", ",", "1", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.StyleGAN2Discriminator.forward": [[752, 784], ["enumerate", "stylegan_networks.StyleGAN2Discriminator.final_conv", "stylegan_networks.StyleGAN2Discriminator.final_linear", "torch.randint", "torch.randint", "conv", "min", "out.view.view.view", "torch.sqrt", "stddev.repeat.repeat.mean().squeeze", "stddev.repeat.repeat.repeat", "torch.cat", "out.view.view.view", "input.size", "input.size", "stddev.repeat.repeat.var", "stddev.repeat.repeat.mean"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "get_minibatch_features", "=", "False", ")", ":", "\n", "        ", "if", "\"patch\"", "in", "self", ".", "opt", ".", "netD", "and", "self", ".", "opt", ".", "D_patch_size", "is", "not", "None", ":", "\n", "            ", "h", ",", "w", "=", "input", ".", "size", "(", "2", ")", ",", "input", ".", "size", "(", "3", ")", "\n", "y", "=", "torch", ".", "randint", "(", "h", "-", "self", ".", "opt", ".", "D_patch_size", ",", "(", ")", ")", "\n", "x", "=", "torch", ".", "randint", "(", "w", "-", "self", ".", "opt", ".", "D_patch_size", ",", "(", ")", ")", "\n", "input", "=", "input", "[", ":", ",", ":", ",", "y", ":", "y", "+", "self", ".", "opt", ".", "D_patch_size", ",", "x", ":", "x", "+", "self", ".", "opt", ".", "D_patch_size", "]", "\n", "", "out", "=", "input", "\n", "for", "i", ",", "conv", "in", "enumerate", "(", "self", ".", "convs", ")", ":", "\n", "            ", "out", "=", "conv", "(", "out", ")", "\n", "# print(i, out.abs().mean())", "\n", "# out = self.convs(input)", "\n", "\n", "", "batch", ",", "channel", ",", "height", ",", "width", "=", "out", ".", "shape", "\n", "\n", "if", "False", "and", "\"tile\"", "in", "self", ".", "opt", ".", "netD", ":", "\n", "            ", "group", "=", "min", "(", "batch", ",", "self", ".", "stddev_group", ")", "\n", "stddev", "=", "out", ".", "view", "(", "\n", "group", ",", "-", "1", ",", "1", ",", "channel", "//", "1", ",", "height", ",", "width", "\n", ")", "\n", "stddev", "=", "torch", ".", "sqrt", "(", "stddev", ".", "var", "(", "0", ",", "unbiased", "=", "False", ")", "+", "1e-8", ")", "\n", "stddev", "=", "stddev", ".", "mean", "(", "[", "2", ",", "3", ",", "4", "]", ",", "keepdim", "=", "True", ")", ".", "squeeze", "(", "2", ")", "\n", "stddev", "=", "stddev", ".", "repeat", "(", "group", ",", "1", ",", "height", ",", "width", ")", "\n", "out", "=", "torch", ".", "cat", "(", "[", "out", ",", "stddev", "]", ",", "1", ")", "\n", "\n", "", "out", "=", "self", ".", "final_conv", "(", "out", ")", "\n", "# print(out.abs().mean())", "\n", "\n", "if", "\"patch\"", "not", "in", "self", ".", "opt", ".", "netD", ":", "\n", "            ", "out", "=", "out", ".", "view", "(", "batch", ",", "-", "1", ")", "\n", "", "out", "=", "self", ".", "final_linear", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.TileStyleGAN2Discriminator.forward": [[787, 795], ["input.permute().contiguous().view.permute().contiguous().view.view", "input.permute().contiguous().view.permute().contiguous().view.permute().contiguous().view", "stylegan_networks.StyleGAN2Discriminator.forward", "input.permute().contiguous().view.permute().contiguous().view.size", "input.permute().contiguous().view.permute().contiguous().view.size", "input.permute().contiguous().view.permute().contiguous().view.size", "input.permute().contiguous().view.permute().contiguous().view.size", "input.permute().contiguous().view.permute().contiguous().view.permute().contiguous", "input.permute().contiguous().view.permute().contiguous().view.permute"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.forward"], ["    ", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "B", ",", "C", ",", "H", ",", "W", "=", "input", ".", "size", "(", "0", ")", ",", "input", ".", "size", "(", "1", ")", ",", "input", ".", "size", "(", "2", ")", ",", "input", ".", "size", "(", "3", ")", "\n", "size", "=", "self", ".", "opt", ".", "D_patch_size", "\n", "Y", "=", "H", "//", "size", "\n", "X", "=", "W", "//", "size", "\n", "input", "=", "input", ".", "view", "(", "B", ",", "C", ",", "Y", ",", "size", ",", "X", ",", "size", ")", "\n", "input", "=", "input", ".", "permute", "(", "0", ",", "2", ",", "4", ",", "1", ",", "3", ",", "5", ")", ".", "contiguous", "(", ")", ".", "view", "(", "B", "*", "Y", "*", "X", ",", "C", ",", "size", ",", "size", ")", "\n", "return", "super", "(", ")", ".", "forward", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.StyleGAN2Encoder.__init__": [[798, 833], ["torch.nn.Module.__init__", "range", "range", "torch.nn.Sequential", "min", "min", "min", "min", "int", "int", "int", "int", "int", "int", "torch.nn.Identity", "stylegan_networks.ConvLayer", "convs.append", "convs.append", "int", "int", "int", "int", "round", "round", "round", "round", "round", "numpy.rint", "stylegan_networks.ResBlock", "stylegan_networks.ResBlock", "round", "round", "round", "round", "numpy.log2", "min"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "ngf", "=", "64", ",", "use_dropout", "=", "False", ",", "n_blocks", "=", "6", ",", "padding_type", "=", "'reflect'", ",", "no_antialias", "=", "False", ",", "opt", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "opt", "is", "not", "None", "\n", "self", ".", "opt", "=", "opt", "\n", "channel_multiplier", "=", "ngf", "/", "32", "\n", "channels", "=", "{", "\n", "4", ":", "min", "(", "512", ",", "int", "(", "round", "(", "4096", "*", "channel_multiplier", ")", ")", ")", ",", "\n", "8", ":", "min", "(", "512", ",", "int", "(", "round", "(", "2048", "*", "channel_multiplier", ")", ")", ")", ",", "\n", "16", ":", "min", "(", "512", ",", "int", "(", "round", "(", "1024", "*", "channel_multiplier", ")", ")", ")", ",", "\n", "32", ":", "min", "(", "512", ",", "int", "(", "round", "(", "512", "*", "channel_multiplier", ")", ")", ")", ",", "\n", "64", ":", "int", "(", "round", "(", "256", "*", "channel_multiplier", ")", ")", ",", "\n", "128", ":", "int", "(", "round", "(", "128", "*", "channel_multiplier", ")", ")", ",", "\n", "256", ":", "int", "(", "round", "(", "64", "*", "channel_multiplier", ")", ")", ",", "\n", "512", ":", "int", "(", "round", "(", "32", "*", "channel_multiplier", ")", ")", ",", "\n", "1024", ":", "int", "(", "round", "(", "16", "*", "channel_multiplier", ")", ")", ",", "\n", "}", "\n", "\n", "blur_kernel", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", "\n", "\n", "cur_res", "=", "2", "**", "int", "(", "(", "np", ".", "rint", "(", "np", ".", "log2", "(", "min", "(", "opt", ".", "load_size", ",", "opt", ".", "crop_size", ")", ")", ")", ")", ")", "\n", "convs", "=", "[", "nn", ".", "Identity", "(", ")", ",", "\n", "ConvLayer", "(", "3", ",", "channels", "[", "cur_res", "]", ",", "1", ")", "]", "\n", "\n", "num_downsampling", "=", "self", ".", "opt", ".", "stylegan2_G_num_downsampling", "\n", "for", "i", "in", "range", "(", "num_downsampling", ")", ":", "\n", "            ", "in_channel", "=", "channels", "[", "cur_res", "]", "\n", "out_channel", "=", "channels", "[", "cur_res", "//", "2", "]", "\n", "convs", ".", "append", "(", "ResBlock", "(", "in_channel", ",", "out_channel", ",", "blur_kernel", ",", "downsample", "=", "True", ")", ")", "\n", "cur_res", "=", "cur_res", "//", "2", "\n", "\n", "", "for", "i", "in", "range", "(", "n_blocks", "//", "2", ")", ":", "\n", "            ", "n_channel", "=", "channels", "[", "cur_res", "]", "\n", "convs", ".", "append", "(", "ResBlock", "(", "n_channel", ",", "n_channel", ",", "downsample", "=", "False", ")", ")", "\n", "\n", "", "self", ".", "convs", "=", "nn", ".", "Sequential", "(", "*", "convs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.StyleGAN2Encoder.forward": [[834, 849], ["enumerate", "layers.append", "layer", "feats.append", "len"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "layers", "=", "[", "]", ",", "get_features", "=", "False", ")", ":", "\n", "        ", "feat", "=", "input", "\n", "feats", "=", "[", "]", "\n", "if", "-", "1", "in", "layers", ":", "\n", "            ", "layers", ".", "append", "(", "len", "(", "self", ".", "convs", ")", "-", "1", ")", "\n", "", "for", "layer_id", ",", "layer", "in", "enumerate", "(", "self", ".", "convs", ")", ":", "\n", "            ", "feat", "=", "layer", "(", "feat", ")", "\n", "# print(layer_id, \" features \", feat.abs().mean())", "\n", "if", "layer_id", "in", "layers", ":", "\n", "                ", "feats", ".", "append", "(", "feat", ")", "\n", "\n", "", "", "if", "get_features", ":", "\n", "            ", "return", "feat", ",", "feats", "\n", "", "else", ":", "\n", "            ", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.StyleGAN2Decoder.__init__": [[852, 892], ["torch.nn.Module.__init__", "range", "range", "convs.append", "torch.nn.Sequential", "min", "min", "min", "min", "int", "int", "int", "int", "int", "convs.append", "convs.append", "stylegan_networks.ConvLayer", "int", "int", "int", "int", "round", "round", "round", "round", "round", "int", "stylegan_networks.ResBlock", "stylegan_networks.StyledConv", "round", "round", "round", "round", "numpy.rint", "numpy.log2", "min"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "ngf", "=", "64", ",", "use_dropout", "=", "False", ",", "n_blocks", "=", "6", ",", "padding_type", "=", "'reflect'", ",", "no_antialias", "=", "False", ",", "opt", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "opt", "is", "not", "None", "\n", "self", ".", "opt", "=", "opt", "\n", "\n", "blur_kernel", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", "\n", "\n", "channel_multiplier", "=", "ngf", "/", "32", "\n", "channels", "=", "{", "\n", "4", ":", "min", "(", "512", ",", "int", "(", "round", "(", "4096", "*", "channel_multiplier", ")", ")", ")", ",", "\n", "8", ":", "min", "(", "512", ",", "int", "(", "round", "(", "2048", "*", "channel_multiplier", ")", ")", ")", ",", "\n", "16", ":", "min", "(", "512", ",", "int", "(", "round", "(", "1024", "*", "channel_multiplier", ")", ")", ")", ",", "\n", "32", ":", "min", "(", "512", ",", "int", "(", "round", "(", "512", "*", "channel_multiplier", ")", ")", ")", ",", "\n", "64", ":", "int", "(", "round", "(", "256", "*", "channel_multiplier", ")", ")", ",", "\n", "128", ":", "int", "(", "round", "(", "128", "*", "channel_multiplier", ")", ")", ",", "\n", "256", ":", "int", "(", "round", "(", "64", "*", "channel_multiplier", ")", ")", ",", "\n", "512", ":", "int", "(", "round", "(", "32", "*", "channel_multiplier", ")", ")", ",", "\n", "1024", ":", "int", "(", "round", "(", "16", "*", "channel_multiplier", ")", ")", ",", "\n", "}", "\n", "\n", "num_downsampling", "=", "self", ".", "opt", ".", "stylegan2_G_num_downsampling", "\n", "cur_res", "=", "2", "**", "int", "(", "(", "np", ".", "rint", "(", "np", ".", "log2", "(", "min", "(", "opt", ".", "load_size", ",", "opt", ".", "crop_size", ")", ")", ")", ")", ")", "//", "(", "2", "**", "num_downsampling", ")", "\n", "convs", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "n_blocks", "//", "2", ")", ":", "\n", "            ", "n_channel", "=", "channels", "[", "cur_res", "]", "\n", "convs", ".", "append", "(", "ResBlock", "(", "n_channel", ",", "n_channel", ",", "downsample", "=", "False", ")", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "num_downsampling", ")", ":", "\n", "            ", "in_channel", "=", "channels", "[", "cur_res", "]", "\n", "out_channel", "=", "channels", "[", "cur_res", "*", "2", "]", "\n", "inject_noise", "=", "\"small\"", "not", "in", "self", ".", "opt", ".", "netG", "\n", "convs", ".", "append", "(", "\n", "StyledConv", "(", "in_channel", ",", "out_channel", ",", "3", ",", "upsample", "=", "True", ",", "blur_kernel", "=", "blur_kernel", ",", "inject_noise", "=", "inject_noise", ")", "\n", ")", "\n", "cur_res", "=", "cur_res", "*", "2", "\n", "\n", "", "convs", ".", "append", "(", "ConvLayer", "(", "channels", "[", "cur_res", "]", ",", "3", ",", "1", ")", ")", "\n", "\n", "self", ".", "convs", "=", "nn", ".", "Sequential", "(", "*", "convs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.StyleGAN2Decoder.forward": [[893, 895], ["stylegan_networks.StyleGAN2Decoder.convs"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "self", ".", "convs", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.StyleGAN2Generator.__init__": [[898, 903], ["torch.nn.Module.__init__", "stylegan_networks.StyleGAN2Encoder", "stylegan_networks.StyleGAN2Decoder"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "ngf", "=", "64", ",", "use_dropout", "=", "False", ",", "n_blocks", "=", "6", ",", "padding_type", "=", "'reflect'", ",", "no_antialias", "=", "False", ",", "opt", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "encoder", "=", "StyleGAN2Encoder", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "use_dropout", ",", "n_blocks", ",", "padding_type", ",", "no_antialias", ",", "opt", ")", "\n", "self", ".", "decoder", "=", "StyleGAN2Decoder", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "use_dropout", ",", "n_blocks", ",", "padding_type", ",", "no_antialias", ",", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.StyleGAN2Generator.forward": [[904, 915], ["stylegan_networks.StyleGAN2Generator.encoder", "stylegan_networks.StyleGAN2Generator.decoder", "len"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "layers", "=", "[", "]", ",", "encode_only", "=", "False", ")", ":", "\n", "        ", "feat", ",", "feats", "=", "self", ".", "encoder", "(", "input", ",", "layers", ",", "True", ")", "\n", "if", "encode_only", ":", "\n", "            ", "return", "feats", "\n", "", "else", ":", "\n", "            ", "fake", "=", "self", ".", "decoder", "(", "feat", ")", "\n", "\n", "if", "len", "(", "layers", ")", ">", "0", ":", "\n", "                ", "return", "fake", ",", "feats", "\n", "", "else", ":", "\n", "                ", "return", "fake", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.fused_leaky_relu": [[17, 19], ["torch.nn.functional.leaky_relu"], "function", ["None"], ["def", "fused_leaky_relu", "(", "input", ",", "bias", ",", "negative_slope", "=", "0.2", ",", "scale", "=", "2", "**", "0.5", ")", ":", "\n", "    ", "return", "F", ".", "leaky_relu", "(", "input", "+", "bias", ",", "negative_slope", ")", "*", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.upfirdn2d_native": [[37, 72], ["input.view", "torch.nn.functional.pad", "out.reshape.view", "torch.nn.functional.pad", "out.reshape.reshape", "torch.flip().view", "torch.nn.functional.conv2d", "out.reshape.reshape", "max", "max", "max", "max", "torch.flip", "max", "max", "max", "max"], "function", ["None"], ["", "", "def", "upfirdn2d_native", "(", "\n", "input", ",", "kernel", ",", "up_x", ",", "up_y", ",", "down_x", ",", "down_y", ",", "pad_x0", ",", "pad_x1", ",", "pad_y0", ",", "pad_y1", "\n", ")", ":", "\n", "    ", "_", ",", "minor", ",", "in_h", ",", "in_w", "=", "input", ".", "shape", "\n", "kernel_h", ",", "kernel_w", "=", "kernel", ".", "shape", "\n", "\n", "out", "=", "input", ".", "view", "(", "-", "1", ",", "minor", ",", "in_h", ",", "1", ",", "in_w", ",", "1", ")", "\n", "out", "=", "F", ".", "pad", "(", "out", ",", "[", "0", ",", "up_x", "-", "1", ",", "0", ",", "0", ",", "0", ",", "up_y", "-", "1", ",", "0", ",", "0", "]", ")", "\n", "out", "=", "out", ".", "view", "(", "-", "1", ",", "minor", ",", "in_h", "*", "up_y", ",", "in_w", "*", "up_x", ")", "\n", "\n", "out", "=", "F", ".", "pad", "(", "\n", "out", ",", "[", "max", "(", "pad_x0", ",", "0", ")", ",", "max", "(", "pad_x1", ",", "0", ")", ",", "max", "(", "pad_y0", ",", "0", ")", ",", "max", "(", "pad_y1", ",", "0", ")", "]", "\n", ")", "\n", "out", "=", "out", "[", "\n", ":", ",", "\n", ":", ",", "\n", "max", "(", "-", "pad_y0", ",", "0", ")", ":", "out", ".", "shape", "[", "2", "]", "-", "max", "(", "-", "pad_y1", ",", "0", ")", ",", "\n", "max", "(", "-", "pad_x0", ",", "0", ")", ":", "out", ".", "shape", "[", "3", "]", "-", "max", "(", "-", "pad_x1", ",", "0", ")", ",", "\n", "]", "\n", "\n", "# out = out.permute(0, 3, 1, 2)", "\n", "out", "=", "out", ".", "reshape", "(", "\n", "[", "-", "1", ",", "1", ",", "in_h", "*", "up_y", "+", "pad_y0", "+", "pad_y1", ",", "in_w", "*", "up_x", "+", "pad_x0", "+", "pad_x1", "]", "\n", ")", "\n", "w", "=", "torch", ".", "flip", "(", "kernel", ",", "[", "0", ",", "1", "]", ")", ".", "view", "(", "1", ",", "1", ",", "kernel_h", ",", "kernel_w", ")", "\n", "out", "=", "F", ".", "conv2d", "(", "out", ",", "w", ")", "\n", "out", "=", "out", ".", "reshape", "(", "\n", "-", "1", ",", "\n", "minor", ",", "\n", "in_h", "*", "up_y", "+", "pad_y0", "+", "pad_y1", "-", "kernel_h", "+", "1", ",", "\n", "in_w", "*", "up_x", "+", "pad_x0", "+", "pad_x1", "-", "kernel_w", "+", "1", ",", "\n", ")", "\n", "# out = out.permute(0, 2, 3, 1)", "\n", "\n", "return", "out", "[", ":", ",", ":", ",", ":", ":", "down_y", ",", ":", ":", "down_x", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.upfirdn2d": [[74, 76], ["stylegan_networks.upfirdn2d_native"], "function", ["home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.upfirdn2d_native"], ["", "def", "upfirdn2d", "(", "input", ",", "kernel", ",", "up", "=", "1", ",", "down", "=", "1", ",", "pad", "=", "(", "0", ",", "0", ")", ")", ":", "\n", "    ", "return", "upfirdn2d_native", "(", "input", ",", "kernel", ",", "up", ",", "up", ",", "down", ",", "down", ",", "pad", "[", "0", "]", ",", "pad", "[", "1", "]", ",", "pad", "[", "0", "]", ",", "pad", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.stylegan_networks.make_kernel": [[86, 95], ["torch.tensor", "torch.tensor.sum", "len"], "function", ["None"], ["", "", "def", "make_kernel", "(", "k", ")", ":", "\n", "    ", "k", "=", "torch", ".", "tensor", "(", "k", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "if", "len", "(", "k", ".", "shape", ")", "==", "1", ":", "\n", "        ", "k", "=", "k", "[", "None", ",", ":", "]", "*", "k", "[", ":", ",", "None", "]", "\n", "\n", "", "k", "/=", "k", ".", "sum", "(", ")", "\n", "\n", "return", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.__init__": [[18, 45], ["os.path.join", "torch.device", "torch.device"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the BaseModel class.\n\n        Parameters:\n            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n\n        When creating your custom class, you need to implement your own initialization.\n        In this fucntion, you should first call <BaseModel.__init__(self, opt)>\n        Then, you need to define four lists:\n            -- self.loss_names (str list):          specify the training losses that you want to plot and save.\n            -- self.model_names (str list):         specify the images that you want to display and save.\n            -- self.visual_names (str list):        define networks used in our training.\n            -- self.optimizers (optimizer list):    define and initialize optimizers. You can define one optimizer for each network. If two networks are updated at the same time, you can use itertools.chain to group them. See cycle_gan_model.py for an example.\n        \"\"\"", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "gpu_ids", "=", "opt", ".", "gpu_ids", "\n", "self", ".", "isTrain", "=", "opt", ".", "isTrain", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda:{}'", ".", "format", "(", "self", ".", "gpu_ids", "[", "0", "]", ")", ")", "if", "self", ".", "gpu_ids", "else", "torch", ".", "device", "(", "'cpu'", ")", "# get device name: CPU or GPU", "\n", "self", ".", "save_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ")", "# save all the checkpoints to save_dir", "\n", "if", "opt", ".", "preprocess", "!=", "'scale_width'", ":", "# with [scale_width], input images might have different sizes, which hurts the performance of cudnn.benchmark.", "\n", "            ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "", "self", ".", "loss_names", "=", "[", "]", "\n", "self", ".", "model_names", "=", "[", "]", "\n", "self", ".", "visual_names", "=", "[", "]", "\n", "self", ".", "optimizers", "=", "[", "]", "\n", "self", ".", "image_paths", "=", "[", "]", "\n", "self", ".", "metric", "=", "0", "# used for learning rate policy 'plateau'", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.dict_grad_hook_factory": [[46, 56], ["dict", "add_func"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "dict_grad_hook_factory", "(", "add_func", "=", "lambda", "x", ":", "x", ")", ":", "\n", "        ", "saved_dict", "=", "dict", "(", ")", "\n", "\n", "def", "hook_gen", "(", "name", ")", ":", "\n", "            ", "def", "grad_hook", "(", "grad", ")", ":", "\n", "                ", "saved_vals", "=", "add_func", "(", "grad", ")", "\n", "saved_dict", "[", "name", "]", "=", "saved_vals", "\n", "", "return", "grad_hook", "\n", "", "return", "hook_gen", ",", "saved_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.modify_commandline_options": [[57, 69], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "\"\"\"Add new model-specific options, and rewrite default values for existing options.\n\n        Parameters:\n            parser          -- original option parser\n            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n\n        Returns:\n            the modified parser.\n        \"\"\"", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.set_input": [[70, 78], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "set_input", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n\n        Parameters:\n            input (dict): includes the data itself and its metadata information.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.forward": [[79, 83], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "forward", "(", "self", ")", ":", "\n", "        ", "\"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.optimize_parameters": [[84, 88], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "optimize_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.setup": [[89, 102], ["base_model.BaseModel.print_networks", "base_model.BaseModel.load_networks", "networks.get_scheduler", "int"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.print_networks", "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.load_networks", "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.get_scheduler"], ["", "def", "setup", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Load and print networks; create schedulers\n\n        Parameters:\n            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "schedulers", "=", "[", "networks", ".", "get_scheduler", "(", "optimizer", ",", "opt", ")", "for", "optimizer", "in", "self", ".", "optimizers", "]", "\n", "", "if", "not", "self", ".", "isTrain", "or", "opt", ".", "pretrained_name", ":", "\n", "            ", "assert", "opt", ".", "epoch", "==", "'latest'", "or", "int", "(", "opt", ".", "epoch", ")", ">", "1", ",", "'Should specify `--opt.epoch`.'", "\n", "self", ".", "load_networks", "(", "opt", ".", "epoch", ")", "\n", "\n", "", "self", ".", "print_networks", "(", "opt", ".", "verbose", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.parallelize": [[103, 108], ["isinstance", "getattr", "setattr", "torch.nn.DataParallel"], "methods", ["None"], ["", "def", "parallelize", "(", "self", ")", ":", "\n", "        ", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "setattr", "(", "self", ",", "'net'", "+", "name", ",", "torch", ".", "nn", ".", "DataParallel", "(", "net", ",", "self", ".", "opt", ".", "gpu_ids", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.data_dependent_initialize": [[109, 111], ["None"], "methods", ["None"], ["", "", "", "def", "data_dependent_initialize", "(", "self", ",", "data", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.eval": [[112, 118], ["isinstance", "getattr", "getattr.eval"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.eval"], ["", "def", "eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"Make models eval mode during test time\"\"\"", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "net", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.test": [[119, 128], ["torch.no_grad", "base_model.BaseModel.forward", "base_model.BaseModel.compute_visuals"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.forward", "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.compute_visuals"], ["", "", "", "def", "test", "(", "self", ")", ":", "\n", "        ", "\"\"\"Forward function used in test time.\n\n        This function wraps <forward> function in no_grad() so we don't save intermediate steps for backprop\n        It also calls <compute_visuals> to produce additional visualization results\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "forward", "(", ")", "\n", "self", ".", "compute_visuals", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.compute_visuals": [[129, 132], ["None"], "methods", ["None"], ["", "", "def", "compute_visuals", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate additional output images\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.get_image_paths": [[133, 136], ["None"], "methods", ["None"], ["", "def", "get_image_paths", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return image paths that are used to load current data\"\"\"", "\n", "return", "self", ".", "image_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.update_learning_rate": [[137, 147], ["print", "scheduler.step", "scheduler.step"], "methods", ["None"], ["", "def", "update_learning_rate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Update learning rates for all the networks; called at the end of every epoch\"\"\"", "\n", "for", "scheduler", "in", "self", ".", "schedulers", ":", "\n", "            ", "if", "self", ".", "opt", ".", "lr_policy", "==", "'plateau'", ":", "\n", "                ", "scheduler", ".", "step", "(", "self", ".", "metric", ")", "\n", "", "else", ":", "\n", "                ", "scheduler", ".", "step", "(", ")", "\n", "\n", "", "", "lr", "=", "self", ".", "optimizers", "[", "0", "]", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "print", "(", "'learning rate = %.7f'", "%", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.get_current_visuals": [[148, 155], ["collections.OrderedDict", "isinstance", "getattr"], "methods", ["None"], ["", "def", "get_current_visuals", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return visualization images.\"\"\"", "\n", "visual_ret", "=", "OrderedDict", "(", ")", "\n", "for", "name", "in", "self", ".", "visual_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "visual_ret", "[", "name", "]", "=", "getattr", "(", "self", ",", "name", ")", "\n", "", "", "return", "visual_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.get_current_losses": [[156, 163], ["collections.OrderedDict", "isinstance", "float", "getattr"], "methods", ["None"], ["", "def", "get_current_losses", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return traning losses / errors. train.py will print out these errors on console, and save them to a file\"\"\"", "\n", "errors_ret", "=", "OrderedDict", "(", ")", "\n", "for", "name", "in", "self", ".", "loss_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "errors_ret", "[", "name", "]", "=", "float", "(", "getattr", "(", "self", ",", "'loss_'", "+", "name", ")", ")", "# float(...) works for both scalar tensor and float number", "\n", "", "", "return", "errors_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.save_networks": [[164, 181], ["isinstance", "os.path.join", "getattr", "torch.cuda.is_available", "torch.save", "getattr.cuda", "torch.save", "len", "getattr.module.cpu().state_dict", "getattr.cpu().state_dict", "getattr.module.cpu", "getattr.cpu"], "methods", ["None"], ["", "def", "save_networks", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Save all the networks to the disk.\n\n        Parameters:\n            epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n        \"\"\"", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "save_filename", "=", "'%s_net_%s.pth'", "%", "(", "epoch", ",", "name", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "save_filename", ")", "\n", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "\n", "if", "len", "(", "self", ".", "gpu_ids", ")", ">", "0", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "torch", ".", "save", "(", "net", ".", "module", ".", "cpu", "(", ")", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "net", ".", "cuda", "(", "self", ".", "gpu_ids", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "save", "(", "net", ".", "cpu", "(", ")", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.__patch_instance_norm_state_dict": [[182, 195], ["len", "base_model.BaseModel.__patch_instance_norm_state_dict", "module.__class__.__name__.startswith", "module.__class__.__name__.startswith", "state_dict.pop", "getattr", "getattr", "state_dict.pop"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.__patch_instance_norm_state_dict"], ["", "", "", "", "def", "__patch_instance_norm_state_dict", "(", "self", ",", "state_dict", ",", "module", ",", "keys", ",", "i", "=", "0", ")", ":", "\n", "        ", "\"\"\"Fix InstanceNorm checkpoints incompatibility (prior to 0.4)\"\"\"", "\n", "key", "=", "keys", "[", "i", "]", "\n", "if", "i", "+", "1", "==", "len", "(", "keys", ")", ":", "# at the end, pointing to a parameter/buffer", "\n", "            ", "if", "module", ".", "__class__", ".", "__name__", ".", "startswith", "(", "'InstanceNorm'", ")", "and", "(", "key", "==", "'running_mean'", "or", "key", "==", "'running_var'", ")", ":", "\n", "                ", "if", "getattr", "(", "module", ",", "key", ")", "is", "None", ":", "\n", "                    ", "state_dict", ".", "pop", "(", "'.'", ".", "join", "(", "keys", ")", ")", "\n", "", "", "if", "module", ".", "__class__", ".", "__name__", ".", "startswith", "(", "'InstanceNorm'", ")", "and", "(", "key", "==", "'num_batches_tracked'", ")", ":", "\n", "                ", "state_dict", ".", "pop", "(", "'.'", ".", "join", "(", "keys", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "__patch_instance_norm_state_dict", "(", "state_dict", ",", "getattr", "(", "module", ",", "key", ")", ",", "keys", ",", "i", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.load_networks": [[196, 225], ["isinstance", "os.path.join", "getattr", "isinstance", "print", "torch.load", "hasattr", "getattr.load_state_dict", "os.path.join", "str"], "methods", ["None"], ["", "", "def", "load_networks", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Load all the networks from the disk.\n\n        Parameters:\n            epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n        \"\"\"", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "load_filename", "=", "'%s_net_%s.pth'", "%", "(", "epoch", ",", "name", ")", "\n", "if", "self", ".", "opt", ".", "isTrain", "and", "self", ".", "opt", ".", "pretrained_name", "is", "not", "None", ":", "\n", "                    ", "load_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "opt", ".", "checkpoints_dir", ",", "self", ".", "opt", ".", "pretrained_name", ")", "\n", "", "else", ":", "\n", "                    ", "load_dir", "=", "self", ".", "save_dir", "\n", "\n", "", "load_path", "=", "os", ".", "path", ".", "join", "(", "load_dir", ",", "load_filename", ")", "\n", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "if", "isinstance", "(", "net", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "                    ", "net", "=", "net", ".", "module", "\n", "", "print", "(", "'loading the model from %s'", "%", "load_path", ")", "\n", "# if you are using PyTorch newer than 0.4 (e.g., built from", "\n", "# GitHub source), you can remove str() on self.device", "\n", "state_dict", "=", "torch", ".", "load", "(", "load_path", ",", "map_location", "=", "str", "(", "self", ".", "device", ")", ")", "\n", "if", "hasattr", "(", "state_dict", ",", "'_metadata'", ")", ":", "\n", "                    ", "del", "state_dict", ".", "_metadata", "\n", "\n", "# patch InstanceNorm checkpoints prior to 0.4", "\n", "# for key in list(state_dict.keys()):  # need to copy keys here because we mutate in loop", "\n", "#    self.__patch_instance_norm_state_dict(state_dict, net, key.split('.'))", "\n", "", "net", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.print_networks": [[226, 243], ["print", "print", "isinstance", "getattr", "getattr.parameters", "print", "param.numel", "print"], "methods", ["None"], ["", "", "", "def", "print_networks", "(", "self", ",", "verbose", ")", ":", "\n", "        ", "\"\"\"Print the total number of parameters in the network and (if verbose) network architecture\n\n        Parameters:\n            verbose (bool) -- if verbose: print the network architecture\n        \"\"\"", "\n", "print", "(", "'---------- Networks initialized -------------'", ")", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "num_params", "=", "0", "\n", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "                    ", "num_params", "+=", "param", ".", "numel", "(", ")", "\n", "", "if", "verbose", ":", "\n", "                    ", "print", "(", "net", ")", "\n", "", "print", "(", "'[Network %s] Total number of parameters : %.3f M'", "%", "(", "name", ",", "num_params", "/", "1e6", ")", ")", "\n", "", "", "print", "(", "'-----------------------------------------------'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.set_requires_grad": [[244, 256], ["isinstance", "net.parameters"], "methods", ["None"], ["", "def", "set_requires_grad", "(", "self", ",", "nets", ",", "requires_grad", "=", "False", ")", ":", "\n", "        ", "\"\"\"Set requies_grad=Fasle for all the networks to avoid unnecessary computations\n        Parameters:\n            nets (network list)   -- a list of networks\n            requires_grad (bool)  -- whether the networks require gradients or not\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "nets", ",", "list", ")", ":", "\n", "            ", "nets", "=", "[", "nets", "]", "\n", "", "for", "net", "in", "nets", ":", "\n", "            ", "if", "net", "is", "not", "None", ":", "\n", "                ", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "requires_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.base_model.BaseModel.generate_visuals_for_evaluation": [[257, 259], ["None"], "methods", ["None"], ["", "", "", "", "def", "generate_visuals_for_evaluation", "(", "self", ",", "data", ",", "mode", ")", ":", "\n", "        ", "return", "{", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.modify_commandline_options": [[24, 40], ["parser.set_defaults", "parser.add_argument"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", "=", "True", ")", ":", "\n", "        ", "\"\"\"Add new model-specific options and rewrite default values for existing options.\n\n        Parameters:\n            parser -- the option parser\n            is_train -- if it is training phase or test phase. You can use this flag to add training-specific or test-specific options.\n\n        Returns:\n            the modified parser.\n        \"\"\"", "\n", "parser", ".", "set_defaults", "(", "dataset_mode", "=", "'aligned'", ")", "# You can rewrite default values for this model. For example, this model usually uses aligned dataset as its dataset.", "\n", "if", "is_train", ":", "\n", "            ", "parser", ".", "add_argument", "(", "'--lambda_regression'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'weight for the regression loss'", ")", "# You can define new arguments for this model.", "\n", "\n", "", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.__init__": [[41, 69], ["base_model.BaseModel.__init__", "networks.define_G", "torch.nn.L1Loss", "torch.optim.Adam", "template_model.TemplateModel.netG.parameters"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.seanjia_srunit.models.networks.define_G"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize this model class.\n\n        Parameters:\n            opt -- training/test options\n\n        A few things can be done here.\n        - (required) call the initialization function of BaseModel\n        - define loss function, visualization images, model names, and optimizers\n        \"\"\"", "\n", "BaseModel", ".", "__init__", "(", "self", ",", "opt", ")", "# call the initialization method of BaseModel", "\n", "# specify the training losses you want to print out. The program will call base_model.get_current_losses to plot the losses to the console and save them to the disk.", "\n", "self", ".", "loss_names", "=", "[", "'loss_G'", "]", "\n", "# specify the images you want to save and display. The program will call base_model.get_current_visuals to save and display these images.", "\n", "self", ".", "visual_names", "=", "[", "'data_A'", ",", "'data_B'", ",", "'output'", "]", "\n", "# specify the models you want to save to the disk. The program will call base_model.save_networks and base_model.load_networks to save and load networks.", "\n", "# you can use opt.isTrain to specify different behaviors for training and test. For example, some networks will not be used during test, and you don't need to load them.", "\n", "self", ".", "model_names", "=", "[", "'G'", "]", "\n", "# define networks; you can use opt.isTrain to specify different behaviors for training and test.", "\n", "self", ".", "netG", "=", "networks", ".", "define_G", "(", "opt", ".", "input_nc", ",", "opt", ".", "output_nc", ",", "opt", ".", "ngf", ",", "opt", ".", "netG", ",", "gpu_ids", "=", "self", ".", "gpu_ids", ")", "\n", "if", "self", ".", "isTrain", ":", "# only defined during training time", "\n", "# define your loss functions. You can use losses provided by torch.nn such as torch.nn.L1Loss.", "\n", "# We also provide a GANLoss class \"networks.GANLoss\". self.criterionGAN = networks.GANLoss().to(self.device)", "\n", "            ", "self", ".", "criterionLoss", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", "\n", "# define and initialize optimizers. You can define one optimizer for each network.", "\n", "# If two networks are updated at the same time, you can use itertools.chain to group them. See cycle_gan_model.py for an example.", "\n", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "netG", ".", "parameters", "(", ")", ",", "lr", "=", "opt", ".", "lr", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "0.999", ")", ")", "\n", "self", ".", "optimizers", "=", "[", "self", ".", "optimizer", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.set_input": [[72, 82], ["input[].to", "input[].to"], "methods", ["None"], ["", "", "def", "set_input", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n\n        Parameters:\n            input: a dictionary that contains the data itself and its metadata information.\n        \"\"\"", "\n", "AtoB", "=", "self", ".", "opt", ".", "direction", "==", "'AtoB'", "# use <direction> to swap data_A and data_B", "\n", "self", ".", "data_A", "=", "input", "[", "'A'", "if", "AtoB", "else", "'B'", "]", ".", "to", "(", "self", ".", "device", ")", "# get image data A", "\n", "self", ".", "data_B", "=", "input", "[", "'B'", "if", "AtoB", "else", "'A'", "]", ".", "to", "(", "self", ".", "device", ")", "# get image data B", "\n", "self", ".", "image_paths", "=", "input", "[", "'A_paths'", "if", "AtoB", "else", "'B_paths'", "]", "# get image paths", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.forward": [[83, 86], ["template_model.TemplateModel.netG"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "\"\"\"Run forward pass. This will be called by both functions <optimize_parameters> and <test>.\"\"\"", "\n", "self", ".", "output", "=", "self", ".", "netG", "(", "self", ".", "data_A", ")", "# generate output image given the input data_A", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.backward": [[87, 93], ["template_model.TemplateModel.loss_G.backward", "template_model.TemplateModel.criterionLoss"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.backward"], ["", "def", "backward", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"", "\n", "# caculate the intermediate results if necessary; here self.output has been computed during function <forward>", "\n", "# calculate loss given the input and intermediate results", "\n", "self", ".", "loss_G", "=", "self", ".", "criterionLoss", "(", "self", ".", "output", ",", "self", ".", "data_B", ")", "*", "self", ".", "opt", ".", "lambda_regression", "\n", "self", ".", "loss_G", ".", "backward", "(", ")", "# calculate gradients of network G w.r.t. loss_G", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.optimize_parameters": [[94, 100], ["template_model.TemplateModel.forward", "template_model.TemplateModel.optimizer.zero_grad", "template_model.TemplateModel.backward", "template_model.TemplateModel.optimizer.step"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.forward", "home.repos.pwc.inspect_result.seanjia_srunit.models.template_model.TemplateModel.backward"], ["", "def", "optimize_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Update network weights; it will be called in every training iteration.\"\"\"", "\n", "self", ".", "forward", "(", ")", "# first call forward to calculate intermediate results", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "# clear network G's existing gradients", "\n", "self", ".", "backward", "(", ")", "# calculate gradients for network G", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "# update gradients for network G", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seanjia_srunit.data.singleimage_dataset.SingleImageDataset.__init__": [[21, 66], ["data.base_dataset.BaseDataset.__init__", "os.path.join", "os.path.join", "len", "len", "PIL.Image.open().convert", "PIL.Image.open().convert", "print", "numpy.random.uniform", "numpy.reshape", "numpy.random.uniform", "numpy.reshape", "list", "random.shuffle", "list", "random.shuffle", "os.path.exists", "os.path.exists", "sorted", "sorted", "numpy.tile", "numpy.tile", "range", "range", "data.image_folder.make_dataset", "data.image_folder.make_dataset", "len", "len", "PIL.Image.open", "PIL.Image.open", "len", "len", "str", "str", "len", "len"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.seanjia_srunit.data.image_folder.make_dataset", "home.repos.pwc.inspect_result.seanjia_srunit.data.image_folder.make_dataset"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize this dataset class.\n\n        Parameters:\n            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "BaseDataset", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "\n", "self", ".", "dir_A", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "dataroot", ",", "'trainA'", ")", "# create a path '/path/to/data/trainA'", "\n", "self", ".", "dir_B", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "dataroot", ",", "'trainB'", ")", "# create a path '/path/to/data/trainB'", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "dir_A", ")", "and", "os", ".", "path", ".", "exists", "(", "self", ".", "dir_B", ")", ":", "\n", "            ", "self", ".", "A_paths", "=", "sorted", "(", "make_dataset", "(", "self", ".", "dir_A", ",", "opt", ".", "max_dataset_size", ")", ")", "# load images from '/path/to/data/trainA'", "\n", "self", ".", "B_paths", "=", "sorted", "(", "make_dataset", "(", "self", ".", "dir_B", ",", "opt", ".", "max_dataset_size", ")", ")", "# load images from '/path/to/data/trainB'", "\n", "", "self", ".", "A_size", "=", "len", "(", "self", ".", "A_paths", ")", "# get the size of dataset A", "\n", "self", ".", "B_size", "=", "len", "(", "self", ".", "B_paths", ")", "# get the size of dataset B", "\n", "\n", "assert", "len", "(", "self", ".", "A_paths", ")", "==", "1", "and", "len", "(", "self", ".", "B_paths", ")", "==", "1", ",", "\"SingleImageDataset class should be used with one image in each domain\"", "\n", "A_img", "=", "Image", ".", "open", "(", "self", ".", "A_paths", "[", "0", "]", ")", ".", "convert", "(", "'RGB'", ")", "\n", "B_img", "=", "Image", ".", "open", "(", "self", ".", "B_paths", "[", "0", "]", ")", ".", "convert", "(", "'RGB'", ")", "\n", "print", "(", "\"Image sizes %s and %s\"", "%", "(", "str", "(", "A_img", ".", "size", ")", ",", "str", "(", "B_img", ".", "size", ")", ")", ")", "\n", "\n", "self", ".", "A_img", "=", "A_img", "\n", "self", ".", "B_img", "=", "B_img", "\n", "\n", "# In single-image translation, we augment the data loader by applying", "\n", "# random scaling. Still, we design the data loader such that the", "\n", "# amount of scaling is the same within a minibatch. To do this,", "\n", "# we precompute the random scaling values, and repeat them by |batch_size|.", "\n", "A_zoom", "=", "1", "/", "self", ".", "opt", ".", "random_scale_max", "\n", "zoom_levels_A", "=", "np", ".", "random", ".", "uniform", "(", "A_zoom", ",", "1.0", ",", "size", "=", "(", "len", "(", "self", ")", "//", "opt", ".", "batch_size", "+", "1", ",", "1", ",", "2", ")", ")", "\n", "self", ".", "zoom_levels_A", "=", "np", ".", "reshape", "(", "np", ".", "tile", "(", "zoom_levels_A", ",", "(", "1", ",", "opt", ".", "batch_size", ",", "1", ")", ")", ",", "[", "-", "1", ",", "2", "]", ")", "\n", "\n", "B_zoom", "=", "1", "/", "self", ".", "opt", ".", "random_scale_max", "\n", "zoom_levels_B", "=", "np", ".", "random", ".", "uniform", "(", "B_zoom", ",", "1.0", ",", "size", "=", "(", "len", "(", "self", ")", "//", "opt", ".", "batch_size", "+", "1", ",", "1", ",", "2", ")", ")", "\n", "self", ".", "zoom_levels_B", "=", "np", ".", "reshape", "(", "np", ".", "tile", "(", "zoom_levels_B", ",", "(", "1", ",", "opt", ".", "batch_size", ",", "1", ")", ")", ",", "[", "-", "1", ",", "2", "]", ")", "\n", "\n", "# While the crop locations are randomized, the negative samples should", "\n", "# not come from the same location. To do this, we precompute the", "\n", "# crop locations with no repetition.", "\n", "self", ".", "patch_indices_A", "=", "list", "(", "range", "(", "len", "(", "self", ")", ")", ")", "\n", "random", ".", "shuffle", "(", "self", ".", "patch_indices_A", ")", "\n", "self", ".", "patch_indices_B", "=", "list", "(", "range", "(", "len", "(", "self", ")", ")", ")", "\n", "random", ".", "shuffle", "(", "self", ".", "patch_indices_B", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.singleimage_dataset.SingleImageDataset.__getitem__": [[67, 104], ["data.base_dataset.get_transform", "data.base_dataset.get_transform.", "data.base_dataset.get_transform", "data.base_dataset.get_transform.", "data.base_dataset.get_transform", "data.base_dataset.get_transform.", "data.base_dataset.get_transform.", "random.random", "random.random"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.get_transform", "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.get_transform", "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.get_transform"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return a data point and its metadata information.\n\n        Parameters:\n            index (int)      -- a random integer for data indexing\n\n        Returns a dictionary that contains A, B, A_paths and B_paths\n            A (tensor)       -- an image in the input domain\n            B (tensor)       -- its corresponding image in the target domain\n            A_paths (str)    -- image paths\n            B_paths (str)    -- image paths\n        \"\"\"", "\n", "A_path", "=", "self", ".", "A_paths", "[", "0", "]", "\n", "B_path", "=", "self", ".", "B_paths", "[", "0", "]", "\n", "A_img", "=", "self", ".", "A_img", "\n", "B_img", "=", "self", ".", "B_img", "\n", "\n", "# apply image transformation", "\n", "if", "self", ".", "opt", ".", "phase", "==", "\"train\"", ":", "\n", "            ", "param", "=", "{", "'scale_factor'", ":", "self", ".", "zoom_levels_A", "[", "index", "]", ",", "\n", "'patch_index'", ":", "self", ".", "patch_indices_A", "[", "index", "]", ",", "\n", "'flip'", ":", "random", ".", "random", "(", ")", ">", "0.5", "}", "\n", "\n", "transform_A", "=", "get_transform", "(", "self", ".", "opt", ",", "params", "=", "param", ",", "method", "=", "Image", ".", "BILINEAR", ")", "\n", "A", "=", "transform_A", "(", "A_img", ")", "\n", "\n", "param", "=", "{", "'scale_factor'", ":", "self", ".", "zoom_levels_B", "[", "index", "]", ",", "\n", "'patch_index'", ":", "self", ".", "patch_indices_B", "[", "index", "]", ",", "\n", "'flip'", ":", "random", ".", "random", "(", ")", ">", "0.5", "}", "\n", "transform_B", "=", "get_transform", "(", "self", ".", "opt", ",", "params", "=", "param", ",", "method", "=", "Image", ".", "BILINEAR", ")", "\n", "B", "=", "transform_B", "(", "B_img", ")", "\n", "", "else", ":", "\n", "            ", "transform", "=", "get_transform", "(", "self", ".", "opt", ",", "method", "=", "Image", ".", "BILINEAR", ")", "\n", "A", "=", "transform", "(", "A_img", ")", "\n", "B", "=", "transform", "(", "B_img", ")", "\n", "\n", "", "return", "{", "'A'", ":", "A", ",", "'B'", ":", "B", ",", "'A_paths'", ":", "A_path", ",", "'B_paths'", ":", "B_path", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.singleimage_dataset.SingleImageDataset.__len__": [[105, 109], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Let's pretend the single image contains 100,000 crops for convenience.\n        \"\"\"", "\n", "return", "100000", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.BaseDataset.__init__": [[23, 32], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the class; save the options in the class\n\n        Parameters:\n            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "root", "=", "opt", ".", "dataroot", "\n", "self", ".", "current_epoch", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.BaseDataset.modify_commandline_options": [[33, 45], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "\"\"\"Add new dataset-specific options, and rewrite default values for existing options.\n\n        Parameters:\n            parser          -- original option parser\n            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n\n        Returns:\n            the modified parser.\n        \"\"\"", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.BaseDataset.__len__": [[46, 50], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the total number of images in the dataset.\"\"\"", "\n", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.BaseDataset.__getitem__": [[51, 62], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return a data point and its metadata information.\n\n        Parameters:\n            index - - a random integer for data indexing\n\n        Returns:\n            a dictionary of data with their names. It ususally contains the data itself and its metadata information.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.get_params": [[64, 80], ["random.randint", "random.randint", "numpy.maximum", "numpy.maximum", "random.random"], "function", ["None"], ["", "", "def", "get_params", "(", "opt", ",", "size", ")", ":", "\n", "    ", "w", ",", "h", "=", "size", "\n", "new_h", "=", "h", "\n", "new_w", "=", "w", "\n", "if", "opt", ".", "preprocess", "==", "'resize_and_crop'", ":", "\n", "        ", "new_h", "=", "new_w", "=", "opt", ".", "load_size", "\n", "", "elif", "opt", ".", "preprocess", "==", "'scale_width_and_crop'", ":", "\n", "        ", "new_w", "=", "opt", ".", "load_size", "\n", "new_h", "=", "opt", ".", "load_size", "*", "h", "//", "w", "\n", "\n", "", "x", "=", "random", ".", "randint", "(", "0", ",", "np", ".", "maximum", "(", "0", ",", "new_w", "-", "opt", ".", "crop_size", ")", ")", "\n", "y", "=", "random", ".", "randint", "(", "0", ",", "np", ".", "maximum", "(", "0", ",", "new_h", "-", "opt", ".", "crop_size", ")", ")", "\n", "\n", "flip", "=", "random", ".", "random", "(", ")", ">", "0.5", "\n", "\n", "return", "{", "'crop_pos'", ":", "(", "x", ",", "y", ")", ",", "'flip'", ":", "flip", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.get_transform": [[82, 134], ["transform_list.append", "torchvision.Compose", "transform_list.append", "transform_list.append", "transform_list.append", "transform_list.append", "transform_list.append", "torchvision.Lambda", "torchvision.Grayscale", "torchvision.Resize", "torchvision.Resize", "transform_list.append", "transform_list.append", "transform_list.append", "transform_list.append", "transform_list.append", "torchvision.Lambda", "torchvision.Lambda", "transform_list.append", "torchvision.ToTensor", "torchvision.Lambda", "transform_list.append", "torchvision.Lambda", "torchvision.Lambda", "torchvision.RandomCrop", "torchvision.Lambda", "base_dataset.__make_power_2", "torchvision.RandomHorizontalFlip", "transform_list.append", "torchvision.Normalize", "torchvision.Normalize", "torchvision.Lambda", "base_dataset.__patch", "base_dataset.__trim", "torchvision.Lambda", "base_dataset.__scale_width", "base_dataset.__random_zoom", "base_dataset.__random_zoom", "base_dataset.__crop", "base_dataset.__scale_shortside", "base_dataset.__flip"], "function", ["home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.__make_power_2", "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.__patch", "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.__trim", "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.__scale_width", "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.__random_zoom", "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.__random_zoom", "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.__crop", "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.__scale_shortside", "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.__flip"], ["", "def", "get_transform", "(", "opt", ",", "params", "=", "None", ",", "grayscale", "=", "False", ",", "method", "=", "Image", ".", "BICUBIC", ",", "convert", "=", "True", ")", ":", "\n", "    ", "transform_list", "=", "[", "]", "\n", "if", "grayscale", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Grayscale", "(", "1", ")", ")", "\n", "", "if", "'fixsize'", "in", "opt", ".", "preprocess", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Resize", "(", "params", "[", "\"size\"", "]", ",", "method", ")", ")", "\n", "", "if", "'resize'", "in", "opt", ".", "preprocess", ":", "\n", "        ", "osize", "=", "[", "opt", ".", "load_size", ",", "opt", ".", "load_size", "]", "\n", "if", "\"gta2cityscapes\"", "in", "opt", ".", "dataroot", ":", "\n", "            ", "osize", "[", "0", "]", "=", "opt", ".", "load_size", "//", "2", "\n", "", "transform_list", ".", "append", "(", "transforms", ".", "Resize", "(", "osize", ",", "method", ")", ")", "\n", "", "elif", "'scale_width'", "in", "opt", ".", "preprocess", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "__scale_width", "(", "img", ",", "opt", ".", "load_size", ",", "opt", ".", "crop_size", ",", "method", ")", ")", ")", "\n", "", "elif", "'scale_shortside'", "in", "opt", ".", "preprocess", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "__scale_shortside", "(", "img", ",", "opt", ".", "load_size", ",", "opt", ".", "crop_size", ",", "method", ")", ")", ")", "\n", "# if 'none' in opt.preprocess:", "\n", "#     transform_list.append(transforms.Pad(30)) ##############", "\n", "\n", "", "if", "'zoom'", "in", "opt", ".", "preprocess", ":", "\n", "        ", "if", "params", "is", "None", ":", "\n", "            ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "__random_zoom", "(", "img", ",", "opt", ".", "load_size", ",", "opt", ".", "crop_size", ",", "method", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "__random_zoom", "(", "img", ",", "opt", ".", "load_size", ",", "opt", ".", "crop_size", ",", "method", ",", "factor", "=", "params", "[", "\"scale_factor\"", "]", ")", ")", ")", "\n", "\n", "", "", "if", "'crop'", "in", "opt", ".", "preprocess", ":", "\n", "        ", "if", "params", "is", "None", "or", "'crop_pos'", "not", "in", "params", ":", "\n", "            ", "transform_list", ".", "append", "(", "transforms", ".", "RandomCrop", "(", "opt", ".", "crop_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "__crop", "(", "img", ",", "params", "[", "'crop_pos'", "]", ",", "opt", ".", "crop_size", ")", ")", ")", "\n", "\n", "", "", "if", "'patch'", "in", "opt", ".", "preprocess", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "__patch", "(", "img", ",", "params", "[", "'patch_index'", "]", ",", "opt", ".", "crop_size", ")", ")", ")", "\n", "\n", "", "if", "'trim'", "in", "opt", ".", "preprocess", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "__trim", "(", "img", ",", "opt", ".", "crop_size", ")", ")", ")", "\n", "\n", "# if opt.preprocess == 'none':", "\n", "", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "__make_power_2", "(", "img", ",", "base", "=", "4", ",", "method", "=", "method", ")", ")", ")", "\n", "\n", "if", "not", "opt", ".", "no_flip", ":", "\n", "        ", "if", "params", "is", "None", "or", "'flip'", "not", "in", "params", ":", "\n", "            ", "transform_list", ".", "append", "(", "transforms", ".", "RandomHorizontalFlip", "(", ")", ")", "\n", "", "elif", "'flip'", "in", "params", ":", "\n", "            ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "__flip", "(", "img", ",", "params", "[", "'flip'", "]", ")", ")", ")", "\n", "\n", "", "", "if", "convert", ":", "\n", "        ", "transform_list", "+=", "[", "transforms", ".", "ToTensor", "(", ")", "]", "\n", "if", "grayscale", ":", "\n", "            ", "transform_list", "+=", "[", "transforms", ".", "Normalize", "(", "(", "0.5", ",", ")", ",", "(", "0.5", ",", ")", ")", "]", "\n", "", "else", ":", "\n", "            ", "transform_list", "+=", "[", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "]", "\n", "", "", "return", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.__make_power_2": [[136, 144], ["int", "int", "img.resize", "round", "round"], "function", ["None"], ["", "def", "__make_power_2", "(", "img", ",", "base", ",", "method", "=", "Image", ".", "BICUBIC", ")", ":", "\n", "    ", "ow", ",", "oh", "=", "img", ".", "size", "\n", "h", "=", "int", "(", "round", "(", "oh", "/", "base", ")", "*", "base", ")", "\n", "w", "=", "int", "(", "round", "(", "ow", "/", "base", ")", "*", "base", ")", "\n", "if", "h", "==", "oh", "and", "w", "==", "ow", ":", "\n", "        ", "return", "img", "\n", "\n", "", "return", "img", ".", "resize", "(", "(", "w", ",", "h", ")", ",", "method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.__random_zoom": [[146, 156], ["max", "max", "img.resize.resize", "numpy.random.uniform", "int", "int", "round", "round"], "function", ["None"], ["", "def", "__random_zoom", "(", "img", ",", "target_width", ",", "crop_width", ",", "method", "=", "Image", ".", "BICUBIC", ",", "factor", "=", "None", ")", ":", "\n", "    ", "if", "factor", "is", "None", ":", "\n", "        ", "zoom_level", "=", "np", ".", "random", ".", "uniform", "(", "0.8", ",", "1.0", ",", "size", "=", "[", "2", "]", ")", "\n", "", "else", ":", "\n", "        ", "zoom_level", "=", "(", "factor", "[", "0", "]", ",", "factor", "[", "1", "]", ")", "\n", "", "iw", ",", "ih", "=", "img", ".", "size", "\n", "zoomw", "=", "max", "(", "crop_width", ",", "iw", "*", "zoom_level", "[", "0", "]", ")", "\n", "zoomh", "=", "max", "(", "crop_width", ",", "ih", "*", "zoom_level", "[", "1", "]", ")", "\n", "img", "=", "img", ".", "resize", "(", "(", "int", "(", "round", "(", "zoomw", ")", ")", ",", "int", "(", "round", "(", "zoomh", ")", ")", ")", ",", "method", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.__scale_shortside": [[158, 166], ["min", "img.resize", "round", "round"], "function", ["None"], ["", "def", "__scale_shortside", "(", "img", ",", "target_width", ",", "crop_width", ",", "method", "=", "Image", ".", "BICUBIC", ")", ":", "\n", "    ", "ow", ",", "oh", "=", "img", ".", "size", "\n", "shortside", "=", "min", "(", "ow", ",", "oh", ")", "\n", "if", "shortside", ">=", "target_width", ":", "\n", "        ", "return", "img", "\n", "", "else", ":", "\n", "        ", "scale", "=", "target_width", "/", "shortside", "\n", "return", "img", ".", "resize", "(", "(", "round", "(", "ow", "*", "scale", ")", ",", "round", "(", "oh", "*", "scale", ")", ")", ",", "method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.__trim": [[168, 183], ["img.crop", "numpy.random.randint", "numpy.random.randint"], "function", ["None"], ["", "", "def", "__trim", "(", "img", ",", "trim_width", ")", ":", "\n", "    ", "ow", ",", "oh", "=", "img", ".", "size", "\n", "if", "ow", ">", "trim_width", ":", "\n", "        ", "xstart", "=", "np", ".", "random", ".", "randint", "(", "ow", "-", "trim_width", ")", "\n", "xend", "=", "xstart", "+", "trim_width", "\n", "", "else", ":", "\n", "        ", "xstart", "=", "0", "\n", "xend", "=", "ow", "\n", "", "if", "oh", ">", "trim_width", ":", "\n", "        ", "ystart", "=", "np", ".", "random", ".", "randint", "(", "oh", "-", "trim_width", ")", "\n", "yend", "=", "ystart", "+", "trim_width", "\n", "", "else", ":", "\n", "        ", "ystart", "=", "0", "\n", "yend", "=", "oh", "\n", "", "return", "img", ".", "crop", "(", "(", "xstart", ",", "ystart", ",", "xend", ",", "yend", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.__scale_width": [[185, 192], ["int", "img.resize", "max"], "function", ["None"], ["", "def", "__scale_width", "(", "img", ",", "target_width", ",", "crop_width", ",", "method", "=", "Image", ".", "BICUBIC", ")", ":", "\n", "    ", "ow", ",", "oh", "=", "img", ".", "size", "\n", "if", "ow", "==", "target_width", "and", "oh", ">=", "crop_width", ":", "\n", "        ", "return", "img", "\n", "", "w", "=", "target_width", "\n", "h", "=", "int", "(", "max", "(", "target_width", "*", "oh", "/", "ow", ",", "crop_width", ")", ")", "\n", "return", "img", ".", "resize", "(", "(", "w", ",", "h", ")", ",", "method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.__crop": [[194, 201], ["img.crop"], "function", ["None"], ["", "def", "__crop", "(", "img", ",", "pos", ",", "size", ")", ":", "\n", "    ", "ow", ",", "oh", "=", "img", ".", "size", "\n", "x1", ",", "y1", "=", "pos", "\n", "tw", "=", "th", "=", "size", "\n", "if", "(", "ow", ">", "tw", "or", "oh", ">", "th", ")", ":", "\n", "        ", "return", "img", ".", "crop", "(", "(", "x1", ",", "y1", ",", "x1", "+", "tw", ",", "y1", "+", "th", ")", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.__patch": [[203, 217], ["numpy.random.randint", "numpy.random.randint", "img.crop", "int", "int"], "function", ["None"], ["", "def", "__patch", "(", "img", ",", "index", ",", "size", ")", ":", "\n", "    ", "ow", ",", "oh", "=", "img", ".", "size", "\n", "nw", ",", "nh", "=", "ow", "//", "size", ",", "oh", "//", "size", "\n", "roomx", "=", "ow", "-", "nw", "*", "size", "\n", "roomy", "=", "oh", "-", "nh", "*", "size", "\n", "startx", "=", "np", ".", "random", ".", "randint", "(", "int", "(", "roomx", ")", "+", "1", ")", "\n", "starty", "=", "np", ".", "random", ".", "randint", "(", "int", "(", "roomy", ")", "+", "1", ")", "\n", "\n", "index", "=", "index", "%", "(", "nw", "*", "nh", ")", "\n", "ix", "=", "index", "//", "nh", "\n", "iy", "=", "index", "%", "nh", "\n", "gridx", "=", "startx", "+", "ix", "*", "size", "\n", "gridy", "=", "starty", "+", "iy", "*", "size", "\n", "return", "img", ".", "crop", "(", "(", "gridx", ",", "gridy", ",", "gridx", "+", "size", ",", "gridy", "+", "size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.__flip": [[219, 223], ["img.transpose"], "function", ["None"], ["", "def", "__flip", "(", "img", ",", "flip", ")", ":", "\n", "    ", "if", "flip", ":", "\n", "        ", "return", "img", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.__print_size_warning": [[225, 233], ["hasattr", "print"], "function", ["None"], ["", "def", "__print_size_warning", "(", "ow", ",", "oh", ",", "w", ",", "h", ")", ":", "\n", "    ", "\"\"\"Print warning information about image size(only print once)\"\"\"", "\n", "if", "not", "hasattr", "(", "__print_size_warning", ",", "'has_printed'", ")", ":", "\n", "        ", "print", "(", "\"The image size needs to be a multiple of 4. \"", "\n", "\"The loaded image size was (%d, %d), so it was adjusted to \"", "\n", "\"(%d, %d). This adjustment will be done to all images \"", "\n", "\"whose sizes are not multiples of 4\"", "%", "(", "ow", ",", "oh", ",", "w", ",", "h", ")", ")", "\n", "__print_size_warning", ".", "has_printed", "=", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seanjia_srunit.data.single_dataset.SingleDataset.__init__": [[12, 22], ["data.base_dataset.BaseDataset.__init__", "sorted", "data.base_dataset.get_transform", "data.image_folder.make_dataset"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.get_transform", "home.repos.pwc.inspect_result.seanjia_srunit.data.image_folder.make_dataset"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize this dataset class.\n\n        Parameters:\n            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "BaseDataset", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "self", ".", "A_paths", "=", "sorted", "(", "make_dataset", "(", "opt", ".", "dataroot", ",", "opt", ".", "max_dataset_size", ")", ")", "\n", "input_nc", "=", "self", ".", "opt", ".", "output_nc", "if", "self", ".", "opt", ".", "direction", "==", "'BtoA'", "else", "self", ".", "opt", ".", "input_nc", "\n", "self", ".", "transform", "=", "get_transform", "(", "opt", ",", "grayscale", "=", "(", "input_nc", "==", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.single_dataset.SingleDataset.__getitem__": [[23, 37], ["PIL.Image.open().convert", "single_dataset.SingleDataset.transform", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return a data point and its metadata information.\n\n        Parameters:\n            index - - a random integer for data indexing\n\n        Returns a dictionary that contains A and A_paths\n            A(tensor) - - an image in one domain\n            A_paths(str) - - the path of the image\n        \"\"\"", "\n", "A_path", "=", "self", ".", "A_paths", "[", "index", "]", "\n", "A_img", "=", "Image", ".", "open", "(", "A_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "A", "=", "self", ".", "transform", "(", "A_img", ")", "\n", "return", "{", "'A'", ":", "A", ",", "'A_paths'", ":", "A_path", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.single_dataset.SingleDataset.__len__": [[38, 41], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the total number of images in the dataset.\"\"\"", "\n", "return", "len", "(", "self", ".", "A_paths", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seanjia_srunit.data.template_dataset.TemplateDataset.modify_commandline_options": [[21, 35], ["parser.add_argument", "parser.set_defaults"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "\"\"\"Add new dataset-specific options, and rewrite default values for existing options.\n\n        Parameters:\n            parser          -- original option parser\n            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n\n        Returns:\n            the modified parser.\n        \"\"\"", "\n", "parser", ".", "add_argument", "(", "'--new_dataset_option'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'new dataset option'", ")", "\n", "parser", ".", "set_defaults", "(", "max_dataset_size", "=", "10", ",", "new_dataset_option", "=", "2.0", ")", "# specify dataset-specific default values", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.template_dataset.TemplateDataset.__init__": [[36, 53], ["data.base_dataset.BaseDataset.__init__", "data.base_dataset.get_transform"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.get_transform"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize this dataset class.\n\n        Parameters:\n            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n\n        A few things can be done here.\n        - save the options (have been done in BaseDataset)\n        - get image paths and meta information of the dataset.\n        - define the image transformation.\n        \"\"\"", "\n", "# save the option and dataset root", "\n", "BaseDataset", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "# get the image paths of your dataset;", "\n", "self", ".", "image_paths", "=", "[", "]", "# You can call sorted(make_dataset(self.root, opt.max_dataset_size)) to get all the image paths under the directory self.root", "\n", "# define the default transform function. You can use <base_dataset.get_transform>; You can also define your custom transform function", "\n", "self", ".", "transform", "=", "get_transform", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.template_dataset.TemplateDataset.__getitem__": [[54, 72], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return a data point and its metadata information.\n\n        Parameters:\n            index -- a random integer for data indexing\n\n        Returns:\n            a dictionary of data with their names. It usually contains the data itself and its metadata information.\n\n        Step 1: get a random image path: e.g., path = self.image_paths[index]\n        Step 2: load your data from the disk: e.g., image = Image.open(path).convert('RGB').\n        Step 3: convert your data to a PyTorch tensor. You can use helpder functions such as self.transform. e.g., data = self.transform(image)\n        Step 4: return a data point as a dictionary.\n        \"\"\"", "\n", "path", "=", "'temp'", "# needs to be a string", "\n", "data_A", "=", "None", "# needs to be a tensor", "\n", "data_B", "=", "None", "# needs to be a tensor", "\n", "return", "{", "'data_A'", ":", "data_A", ",", "'data_B'", ":", "data_B", ",", "'path'", ":", "path", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.template_dataset.TemplateDataset.__len__": [[73, 76], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the total number of images.\"\"\"", "\n", "return", "len", "(", "self", ".", "image_paths", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seanjia_srunit.data.image_folder.ImageFolder.__init__": [[42, 54], ["image_folder.make_dataset", "len", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.data.image_folder.make_dataset"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "transform", "=", "None", ",", "return_paths", "=", "False", ",", "\n", "loader", "=", "default_loader", ")", ":", "\n", "        ", "imgs", "=", "make_dataset", "(", "root", ")", "\n", "if", "len", "(", "imgs", ")", "==", "0", ":", "\n", "            ", "raise", "(", "RuntimeError", "(", "\"Found 0 images in: \"", "+", "root", "+", "\"\\n\"", "\n", "\"Supported image extensions are: \"", "+", "\",\"", ".", "join", "(", "IMG_EXTENSIONS", ")", ")", ")", "\n", "\n", "", "self", ".", "root", "=", "root", "\n", "self", ".", "imgs", "=", "imgs", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "return_paths", "=", "return_paths", "\n", "self", ".", "loader", "=", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.image_folder.ImageFolder.__getitem__": [[55, 64], ["image_folder.ImageFolder.loader", "image_folder.ImageFolder.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "self", ".", "imgs", "[", "index", "]", "\n", "img", "=", "self", ".", "loader", "(", "path", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "if", "self", ".", "return_paths", ":", "\n", "            ", "return", "img", ",", "path", "\n", "", "else", ":", "\n", "            ", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.image_folder.ImageFolder.__len__": [[65, 67], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "imgs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seanjia_srunit.data.image_folder.is_image_file": [[20, 22], ["any", "filename.endswith"], "function", ["None"], ["def", "is_image_file", "(", "filename", ")", ":", "\n", "    ", "return", "any", "(", "filename", ".", "endswith", "(", "extension", ")", "for", "extension", "in", "IMG_EXTENSIONS", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.image_folder.make_dataset": [[24, 34], ["float", "sorted", "os.path.isdir", "os.path.isdir", "os.path.islink", "os.path.islink", "os.walk", "os.walk", "image_folder.is_image_file", "min", "os.path.join", "os.path.join", "images.append", "len"], "function", ["home.repos.pwc.inspect_result.seanjia_srunit.data.image_folder.is_image_file"], ["", "def", "make_dataset", "(", "dir", ",", "max_dataset_size", "=", "float", "(", "\"inf\"", ")", ")", ":", "\n", "    ", "images", "=", "[", "]", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "dir", ")", "or", "os", ".", "path", ".", "islink", "(", "dir", ")", ",", "'%s is not a valid directory'", "%", "dir", "\n", "\n", "for", "root", ",", "_", ",", "fnames", "in", "sorted", "(", "os", ".", "walk", "(", "dir", ",", "followlinks", "=", "True", ")", ")", ":", "\n", "        ", "for", "fname", "in", "fnames", ":", "\n", "            ", "if", "is_image_file", "(", "fname", ")", ":", "\n", "                ", "path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "fname", ")", "\n", "images", ".", "append", "(", "path", ")", "\n", "", "", "", "return", "images", "[", ":", "min", "(", "max_dataset_size", ",", "len", "(", "images", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.image_folder.default_loader": [[36, 38], ["PIL.Image.open().convert", "PIL.Image.open"], "function", ["None"], ["", "def", "default_loader", "(", "path", ")", ":", "\n", "    ", "return", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.__init__.CustomDatasetDataLoader.__init__": [[65, 81], ["__init__.find_dataset_using_name", "find_dataset_using_name.", "print", "torch.utils.data.DataLoader", "int", "type"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.data.__init__.find_dataset_using_name"], []], "home.repos.pwc.inspect_result.seanjia_srunit.data.__init__.CustomDatasetDataLoader.set_epoch": [[83, 85], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.seanjia_srunit.data.__init__.CustomDatasetDataLoader.load_data": [[86, 88], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.seanjia_srunit.data.__init__.CustomDatasetDataLoader.__len__": [[89, 92], ["min", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.seanjia_srunit.data.__init__.CustomDatasetDataLoader.__iter__": [[93, 99], ["enumerate"], "methods", ["None"], []], "home.repos.pwc.inspect_result.seanjia_srunit.data.__init__.find_dataset_using_name": [[18, 39], ["importlib.import_module", "importlib.import_module.__dict__.items", "dataset_name.replace", "NotImplementedError", "issubclass", "name.lower", "target_dataset_name.lower"], "function", ["None"], []], "home.repos.pwc.inspect_result.seanjia_srunit.data.__init__.get_option_setter": [[41, 45], ["__init__.find_dataset_using_name"], "function", ["home.repos.pwc.inspect_result.seanjia_srunit.data.__init__.find_dataset_using_name"], []], "home.repos.pwc.inspect_result.seanjia_srunit.data.__init__.create_dataset": [[47, 60], ["__init__.CustomDatasetDataLoader", "__init__.CustomDatasetDataLoader.load_data"], "function", ["home.repos.pwc.inspect_result.seanjia_srunit.data.__init__.CustomDatasetDataLoader.load_data"], []], "home.repos.pwc.inspect_result.seanjia_srunit.data.unaligned_dataset.UnalignedDataset.__init__": [[22, 39], ["data.base_dataset.BaseDataset.__init__", "os.path.join", "os.path.join", "sorted", "sorted", "len", "len", "print", "data.image_folder.make_dataset", "data.image_folder.make_dataset"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.seanjia_srunit.data.image_folder.make_dataset", "home.repos.pwc.inspect_result.seanjia_srunit.data.image_folder.make_dataset"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize this dataset class.\n\n        Parameters:\n            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "BaseDataset", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "self", ".", "dir_A", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "dataroot", ",", "opt", ".", "phase", "+", "'A'", ")", "\n", "self", ".", "dir_B", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "dataroot", ",", "opt", ".", "phase", "+", "'B'", ")", "\n", "\n", "self", ".", "A_paths", "=", "sorted", "(", "make_dataset", "(", "self", ".", "dir_A", ",", "opt", ".", "max_dataset_size", ")", ")", "\n", "self", ".", "B_paths", "=", "sorted", "(", "make_dataset", "(", "self", ".", "dir_B", ",", "opt", ".", "max_dataset_size", ")", ")", "\n", "\n", "self", ".", "A_size", "=", "len", "(", "self", ".", "A_paths", ")", "# get the size of dataset A", "\n", "self", ".", "B_size", "=", "len", "(", "self", ".", "B_paths", ")", "# get the size of dataset B", "\n", "\n", "print", "(", "f'Dataset sizes are {self.A_size} for A and {self.B_size} for B.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.unaligned_dataset.UnalignedDataset.__getitem__": [[40, 72], ["PIL.Image.open().convert", "PIL.Image.open().convert", "util.copyconf", "data.base_dataset.get_transform", "data.base_dataset.get_transform.", "data.base_dataset.get_transform.", "random.randint", "PIL.Image.open", "PIL.Image.open"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.util.util.copyconf", "home.repos.pwc.inspect_result.seanjia_srunit.data.base_dataset.get_transform"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return a data point and its metadata information.\n\n        Parameters:\n            index (int)      -- a random integer for data indexing\n\n        Returns a dictionary that contains A, B, A_paths and B_paths\n            A (tensor)       -- an image in the input domain\n            B (tensor)       -- its corresponding image in the target domain\n            A_paths (str)    -- image paths\n            B_paths (str)    -- image paths\n        \"\"\"", "\n", "A_path", "=", "self", ".", "A_paths", "[", "index", "%", "self", ".", "A_size", "]", "# make sure index is within then range", "\n", "if", "self", ".", "opt", ".", "serial_batches", ":", "# make sure index is within then range", "\n", "            ", "index_B", "=", "index", "%", "self", ".", "B_size", "\n", "", "else", ":", "# randomize the index for domain B to avoid fixed pairs.", "\n", "            ", "index_B", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "B_size", "-", "1", ")", "\n", "", "B_path", "=", "self", ".", "B_paths", "[", "index_B", "]", "\n", "A_img", "=", "Image", ".", "open", "(", "A_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "B_img", "=", "Image", ".", "open", "(", "B_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n", "# Apply image transformation", "\n", "# For FastCUT mode, if in finetuning phase (learning rate is decaying),", "\n", "# do not perform resize-crop data augmentation of CycleGAN.", "\n", "#        print('current_epoch', self.current_epoch)", "\n", "is_finetuning", "=", "self", ".", "opt", ".", "isTrain", "and", "self", ".", "current_epoch", ">", "self", ".", "opt", ".", "n_epochs", "\n", "modified_opt", "=", "util", ".", "copyconf", "(", "self", ".", "opt", ",", "load_size", "=", "self", ".", "opt", ".", "crop_size", "if", "is_finetuning", "else", "self", ".", "opt", ".", "load_size", ")", "\n", "transform", "=", "get_transform", "(", "modified_opt", ")", "\n", "A", "=", "transform", "(", "A_img", ")", "\n", "B", "=", "transform", "(", "B_img", ")", "\n", "\n", "return", "{", "'A'", ":", "A", ",", "'B'", ":", "B", ",", "'A_paths'", ":", "A_path", ",", "'B_paths'", ":", "B_path", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.data.unaligned_dataset.UnalignedDataset.__len__": [[73, 75], ["max"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "max", "(", "self", ".", "A_size", ",", "self", ".", "B_size", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seanjia_srunit.options.test_options.TestOptions.initialize": [[10, 23], ["base_options.BaseOptions.initialize", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.set_defaults", "base_options.BaseOptions.initialize.get_default"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.initialize"], ["def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "parser", "=", "BaseOptions", ".", "initialize", "(", "self", ",", "parser", ")", "# define shared options", "\n", "parser", ".", "add_argument", "(", "'--phase'", ",", "type", "=", "str", ",", "default", "=", "'val'", ",", "help", "=", "'train, val, test, etc'", ")", "\n", "# Dropout and Batchnorm has different behavioir during training and test.", "\n", "parser", ".", "add_argument", "(", "'--eval'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use eval mode during test time.'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_test'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'how many test images to run'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_path'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'output path to store the inferece results.'", ")", "\n", "parser", ".", "add_argument", "(", "'--gan_mode'", ",", "type", "=", "str", ",", "default", "=", "'lsgan'", ",", "help", "=", "'the type of GAN objective. [vanilla| lsgan | wgangp]. vanilla GAN loss is the cross-entropy objective used in the original GAN paper.'", ")", "\n", "\n", "# To avoid cropping, the load_size should be the same as crop_size", "\n", "parser", ".", "set_defaults", "(", "load_size", "=", "parser", ".", "get_default", "(", "'crop_size'", ")", ")", "\n", "self", ".", "isTrain", "=", "False", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seanjia_srunit.options.train_options.TrainOptions.initialize": [[10, 38], ["base_options.BaseOptions.initialize", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.initialize"], ["def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "parser", "=", "BaseOptions", ".", "initialize", "(", "self", ",", "parser", ")", "\n", "\n", "# network saving and loading parameters", "\n", "parser", ".", "add_argument", "(", "'--save_latest_freq'", ",", "type", "=", "int", ",", "default", "=", "5000", ",", "help", "=", "'frequency of saving the latest results'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_epoch_freq'", ",", "type", "=", "int", ",", "default", "=", "25", ",", "help", "=", "'frequency of saving checkpoints at the end of epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--evaluation_freq'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "help", "=", "'evaluation freq'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_by_iter'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether saves model by iteration'", ")", "\n", "parser", ".", "add_argument", "(", "'--continue_train'", ",", "action", "=", "'store_true'", ",", "help", "=", "'continue training: load the model specified by `--epoch`'", ")", "\n", "parser", ".", "add_argument", "(", "'--epoch_count'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'the starting epoch count, we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>, ...'", ")", "\n", "parser", ".", "add_argument", "(", "'--phase'", ",", "type", "=", "str", ",", "default", "=", "'train'", ",", "help", "=", "'train, val, test, etc'", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrained_name'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "'resume training from another checkpoint'", ")", "\n", "parser", ".", "add_argument", "(", "'--print_freq'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'frequency of showing training results on console'", ")", "\n", "\n", "# training parameters", "\n", "parser", ".", "add_argument", "(", "'--n_epochs'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "help", "=", "'number of epochs with the initial learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_epochs_decay'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "help", "=", "'number of epochs to linearly decay learning rate to zero'", ")", "\n", "parser", ".", "add_argument", "(", "'--beta1'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'momentum term of adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--beta2'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "help", "=", "'momentum term of adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--gan_mode'", ",", "type", "=", "str", ",", "default", "=", "'lsgan'", ",", "help", "=", "'the type of GAN objective. [vanilla| lsgan | wgangp]. vanilla GAN loss is the cross-entropy objective used in the original GAN paper.'", ")", "\n", "parser", ".", "add_argument", "(", "'--pool_size'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'the size of image buffer that stores previously generated images'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_policy'", ",", "type", "=", "str", ",", "default", "=", "'linear'", ",", "help", "=", "'learning rate policy. [linear | step | plateau | cosine]'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_decay_iters'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'multiply by a gamma every lr_decay_iters iterations'", ")", "\n", "parser", ".", "add_argument", "(", "'--D_noise'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "help", "=", "'Gaussian noise on inputs of the discriminators'", ")", "\n", "\n", "\n", "self", ".", "isTrain", "=", "True", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.__init__": [[16, 22], ["cmd_line.split"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cmd_line", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reset the class; indicates the class hasn't been initailized\"\"\"", "\n", "self", ".", "initialized", "=", "False", "\n", "self", ".", "cmd_line", "=", "None", "\n", "if", "cmd_line", "is", "not", "None", ":", "\n", "            ", "self", ".", "cmd_line", "=", "cmd_line", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.initialize": [[23, 80], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "float"], "methods", ["None"], ["", "", "def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "\"\"\"Define the common options that are used in both training and test.\"\"\"", "\n", "# basic parameters", "\n", "parser", ".", "add_argument", "(", "'--dataroot'", ",", "default", "=", "'placeholder'", ",", "help", "=", "'path to images (should have subfolders trainA, trainB, valA, valB, etc)'", ")", "\n", "parser", ".", "add_argument", "(", "'--name'", ",", "type", "=", "str", ",", "default", "=", "'experiment_name'", ",", "help", "=", "'name of the experiment. It decides where to store samples and models'", ")", "\n", "parser", ".", "add_argument", "(", "'--easy_label'", ",", "type", "=", "str", ",", "default", "=", "'experiment_name'", ",", "help", "=", "'Interpretable name'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_ids'", ",", "type", "=", "str", ",", "default", "=", "'0'", ",", "help", "=", "'gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoints_dir'", ",", "type", "=", "str", ",", "default", "=", "'./checkpoints'", ",", "help", "=", "'models are saved here'", ")", "\n", "# model parameters", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "default", "=", "'srunit'", ",", "help", "=", "'chooses which model to use.'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_nc'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'# of input image channels: 3 for RGB and 1 for grayscale'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_nc'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'# of output image channels: 3 for RGB and 1 for grayscale'", ")", "\n", "parser", ".", "add_argument", "(", "'--ngf'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'# of gen filters in the last conv layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--ndf'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'# of discrim filters in the first conv layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--netD'", ",", "type", "=", "str", ",", "default", "=", "'basic'", ",", "choices", "=", "[", "'basic'", ",", "'n_layers'", ",", "'pixel'", ",", "'patch'", ",", "'tilestylegan2'", ",", "'stylegan2'", "]", ",", "help", "=", "'specify discriminator architecture. The basic model is a 70x70 PatchGAN. n_layers allows you to specify the layers in the discriminator'", ")", "\n", "parser", ".", "add_argument", "(", "'--netG'", ",", "type", "=", "str", ",", "default", "=", "'resnet_9blocks'", ",", "choices", "=", "[", "'resnet_9blocks'", ",", "'resnet_6blocks'", ",", "'unet_256'", ",", "'unet_128'", ",", "'stylegan2'", ",", "'smallstylegan2'", ",", "'resnet_cat'", "]", ",", "help", "=", "'specify generator architecture'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_layers_D'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'only used if netD==n_layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--normG'", ",", "type", "=", "str", ",", "default", "=", "'instance'", ",", "choices", "=", "[", "'instance'", ",", "'batch'", ",", "'none'", "]", ",", "help", "=", "'instance normalization or batch normalization for G'", ")", "\n", "parser", ".", "add_argument", "(", "'--normD'", ",", "type", "=", "str", ",", "default", "=", "'instance'", ",", "choices", "=", "[", "'instance'", ",", "'batch'", ",", "'none'", "]", ",", "help", "=", "'instance normalization or batch normalization for D'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_type'", ",", "type", "=", "str", ",", "default", "=", "'xavier'", ",", "choices", "=", "[", "'normal'", ",", "'xavier'", ",", "'kaiming'", ",", "'orthogonal'", "]", ",", "help", "=", "'network initialization'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_gain'", ",", "type", "=", "float", ",", "default", "=", "0.02", ",", "help", "=", "'scaling factor for normal, xavier and orthogonal.'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_dropout'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "True", ",", "\n", "help", "=", "'no dropout for the generator'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_antialias'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, use stride=2 convs instead of antialiased-downsampling (sad)'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_antialias_up'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, use [upconv(learned filter)] instead of [upconv(hard-coded [1,3,3,1] filter), conv]'", ")", "\n", "# dataset parameters", "\n", "parser", ".", "add_argument", "(", "'--dataset_mode'", ",", "type", "=", "str", ",", "default", "=", "'unaligned'", ",", "help", "=", "'chooses how datasets are loaded. [unaligned | aligned | single | colorization]'", ")", "\n", "parser", ".", "add_argument", "(", "'--direction'", ",", "type", "=", "str", ",", "default", "=", "'AtoB'", ",", "help", "=", "'AtoB or BtoA'", ")", "\n", "parser", ".", "add_argument", "(", "'--serial_batches'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if true, takes images in order to make batches, otherwise takes them randomly'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_threads'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "'# threads for loading data'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'input batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--load_size'", ",", "type", "=", "int", ",", "default", "=", "286", ",", "help", "=", "'scale images to this size'", ")", "\n", "parser", ".", "add_argument", "(", "'--crop_size'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'then crop to this size'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_dataset_size'", ",", "type", "=", "int", ",", "default", "=", "float", "(", "\"inf\"", ")", ",", "help", "=", "'Maximum number of samples allowed per dataset. If the dataset directory contains more than max_dataset_size, only a subset is loaded.'", ")", "\n", "parser", ".", "add_argument", "(", "'--preprocess'", ",", "type", "=", "str", ",", "default", "=", "'resize_and_crop'", ",", "help", "=", "'scaling and cropping of images at load time [resize_and_crop | crop | scale_width | scale_width_and_crop | none]'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_flip'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, do not flip the images for data augmentation'", ")", "\n", "parser", ".", "add_argument", "(", "'--random_scale_max'", ",", "type", "=", "float", ",", "default", "=", "3.0", ",", "\n", "help", "=", "'(used for single image translation) Randomly scale the image by the specified factor as data augmentation.'", ")", "\n", "# additional parameters", "\n", "parser", ".", "add_argument", "(", "'--epoch'", ",", "type", "=", "str", ",", "default", "=", "'latest'", ",", "help", "=", "'which epoch to load? set to latest to use latest cached model'", ")", "\n", "parser", ".", "add_argument", "(", "'--verbose'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, print more debugging information'", ")", "\n", "parser", ".", "add_argument", "(", "'--suffix'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "help", "=", "'customized suffix: opt.name = opt.name + suffix: e.g., {model}_{netG}_size{load_size}'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.0002", ",", "help", "=", "'initial learning rate for adam'", ")", "\n", "\n", "# parameters related to StyleGAN2-based networks", "\n", "parser", ".", "add_argument", "(", "'--stylegan2_G_num_downsampling'", ",", "\n", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of downsampling layers used by StyleGAN2Generator'", ")", "\n", "\n", "# Semantic Robustness Regularization (hyper-parameters for SRUNIT)", "\n", "parser", ".", "add_argument", "(", "'--reg_type'", ",", "type", "=", "str", ",", "default", "=", "'v2'", ",", "help", "=", "'version 1 or version 2 for semantic robustness (SR) regularization'", ")", "\n", "parser", ".", "add_argument", "(", "'--reg'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'coefficient for the SR regularization loss term'", ")", "\n", "parser", ".", "add_argument", "(", "'--reg_noise'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'Gaussian noise used in the semantic robustness loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--inact_epochs'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'regularization inactivated for the first couples of epochs'", ")", "\n", "\n", "self", ".", "initialized", "=", "True", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.gather_options": [[81, 117], ["models.get_option_setter", "models.get_option_setter.", "data.get_option_setter", "data.get_option_setter.", "argparse.ArgumentParser", "base_options.BaseOptions.initialize", "base_options.BaseOptions.parse_known_args", "base_options.BaseOptions.parse_known_args", "base_options.BaseOptions.parse_known_args", "base_options.BaseOptions.parse_known_args", "base_options.BaseOptions.parse_args", "base_options.BaseOptions.parse_args"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.data.__init__.get_option_setter", "home.repos.pwc.inspect_result.seanjia_srunit.data.__init__.get_option_setter", "home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.initialize"], ["", "def", "gather_options", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initialize our parser with basic options(only once).\n        Add additional model-specific and dataset-specific options.\n        These options are defined in the <modify_commandline_options> function\n        in model and dataset classes.\n        \"\"\"", "\n", "if", "not", "self", ".", "initialized", ":", "# check if it has been initialized", "\n", "            ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", "=", "self", ".", "initialize", "(", "parser", ")", "\n", "\n", "# get the basic options", "\n", "", "if", "self", ".", "cmd_line", "is", "None", ":", "\n", "            ", "opt", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "", "else", ":", "\n", "            ", "opt", ",", "_", "=", "parser", ".", "parse_known_args", "(", "self", ".", "cmd_line", ")", "\n", "\n", "# modify model-related parser options", "\n", "", "model_name", "=", "opt", ".", "model", "\n", "model_option_setter", "=", "models", ".", "get_option_setter", "(", "model_name", ")", "\n", "parser", "=", "model_option_setter", "(", "parser", ",", "self", ".", "isTrain", ")", "\n", "if", "self", ".", "cmd_line", "is", "None", ":", "\n", "            ", "opt", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "# parse again with new defaults", "\n", "", "else", ":", "\n", "            ", "opt", ",", "_", "=", "parser", ".", "parse_known_args", "(", "self", ".", "cmd_line", ")", "# parse again with new defaults", "\n", "\n", "# modify dataset-related parser options", "\n", "", "dataset_name", "=", "opt", ".", "dataset_mode", "\n", "dataset_option_setter", "=", "data", ".", "get_option_setter", "(", "dataset_name", ")", "\n", "parser", "=", "dataset_option_setter", "(", "parser", ",", "self", ".", "isTrain", ")", "\n", "\n", "# save and return the parser", "\n", "self", ".", "parser", "=", "parser", "\n", "if", "self", ".", "cmd_line", "is", "None", ":", "\n", "            ", "return", "parser", ".", "parse_args", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "parser", ".", "parse_args", "(", "self", ".", "cmd_line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.print_options": [[118, 146], ["sorted", "print", "os.path.join", "util.util.util.mkdirs", "os.path.join", "vars().items", "base_options.BaseOptions.parser.get_default", "str", "str", "open", "opt_file.write", "opt_file.write", "print", "vars", "str"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.util.util.mkdirs"], ["", "", "def", "print_options", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Print and save options\n\n        It will print both current options and default values(if different).\n        It will save options into a text file / [checkpoints_dir] / opt.txt\n        \"\"\"", "\n", "message", "=", "''", "\n", "message", "+=", "'----------------- Options ---------------\\n'", "\n", "for", "k", ",", "v", "in", "sorted", "(", "vars", "(", "opt", ")", ".", "items", "(", ")", ")", ":", "\n", "            ", "comment", "=", "''", "\n", "default", "=", "self", ".", "parser", ".", "get_default", "(", "k", ")", "\n", "if", "v", "!=", "default", ":", "\n", "                ", "comment", "=", "'\\t[default: %s]'", "%", "str", "(", "default", ")", "\n", "", "message", "+=", "'{:>25}: {:<30}{}\\n'", ".", "format", "(", "str", "(", "k", ")", ",", "str", "(", "v", ")", ",", "comment", ")", "\n", "", "message", "+=", "'----------------- End -------------------'", "\n", "print", "(", "message", ")", "\n", "\n", "# save to the disk", "\n", "expr_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ")", "\n", "util", ".", "mkdirs", "(", "expr_dir", ")", "\n", "file_name", "=", "os", ".", "path", ".", "join", "(", "expr_dir", ",", "'{}_opt.txt'", ".", "format", "(", "opt", ".", "phase", ")", ")", "\n", "try", ":", "\n", "            ", "with", "open", "(", "file_name", ",", "'wt'", ")", "as", "opt_file", ":", "\n", "                ", "opt_file", ".", "write", "(", "message", ")", "\n", "opt_file", ".", "write", "(", "'\\n'", ")", "\n", "", "", "except", "PermissionError", "as", "error", ":", "\n", "            ", "print", "(", "\"permission error {}\"", ".", "format", "(", "error", ")", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.parse": [[147, 171], ["base_options.BaseOptions.gather_options", "base_options.BaseOptions.print_options", "base_options.BaseOptions.gpu_ids.split", "int", "len", "torch.cuda.set_device", "base_options.BaseOptions.gpu_ids.append", "base_options.BaseOptions.suffix.format", "vars"], "methods", ["home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.gather_options", "home.repos.pwc.inspect_result.seanjia_srunit.options.base_options.BaseOptions.print_options"], ["", "", "def", "parse", "(", "self", ")", ":", "\n", "        ", "\"\"\"Parse our options, create checkpoints directory suffix, and set up gpu device.\"\"\"", "\n", "opt", "=", "self", ".", "gather_options", "(", ")", "\n", "opt", ".", "isTrain", "=", "self", ".", "isTrain", "# train or test", "\n", "\n", "# process opt.suffix", "\n", "if", "opt", ".", "suffix", ":", "\n", "            ", "suffix", "=", "(", "'_'", "+", "opt", ".", "suffix", ".", "format", "(", "**", "vars", "(", "opt", ")", ")", ")", "if", "opt", ".", "suffix", "!=", "''", "else", "''", "\n", "opt", ".", "name", "=", "opt", ".", "name", "+", "suffix", "\n", "\n", "", "self", ".", "print_options", "(", "opt", ")", "\n", "\n", "# set gpu ids", "\n", "str_ids", "=", "opt", ".", "gpu_ids", ".", "split", "(", "','", ")", "\n", "opt", ".", "gpu_ids", "=", "[", "]", "\n", "for", "str_id", "in", "str_ids", ":", "\n", "            ", "id", "=", "int", "(", "str_id", ")", "\n", "if", "id", ">=", "0", ":", "\n", "                ", "opt", ".", "gpu_ids", ".", "append", "(", "id", ")", "\n", "", "", "if", "len", "(", "opt", ".", "gpu_ids", ")", ">", "0", ":", "\n", "            ", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "gpu_ids", "[", "0", "]", ")", "\n", "\n", "", "self", ".", "opt", "=", "opt", "\n", "return", "self", ".", "opt", "\n", "", "", ""]]}