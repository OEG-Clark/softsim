{"home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.splitcross.SplitCrossEntropyLoss.__init__": [[11, 25], ["torch.Module.__init__", "collections.defaultdict", "len", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.locked_dropout.LockedDropout.__init__"], ["def", "__init__", "(", "self", ",", "hidden_size", ",", "splits", ",", "verbose", "=", "False", ")", ":", "\n", "# We assume splits is [0, split1, split2, N] where N >= |V|", "\n", "# For example, a vocab of 1000 words may have splits [0] + [100, 500] + [inf]", "\n", "        ", "super", "(", "SplitCrossEntropyLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "splits", "=", "[", "0", "]", "+", "splits", "+", "[", "100", "*", "1000000", "]", "\n", "self", ".", "nsplits", "=", "len", "(", "self", ".", "splits", ")", "-", "1", "\n", "self", ".", "stats", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "verbose", "=", "verbose", "\n", "# Each of the splits that aren't in the head require a pretend token, we'll call them tombstones", "\n", "# The probability given to this tombstone is the probability of selecting an item from the represented split", "\n", "if", "self", ".", "nsplits", ">", "1", ":", "\n", "            ", "self", ".", "tail_vectors", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "nsplits", "-", "1", ",", "hidden_size", ")", ")", "\n", "self", ".", "tail_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "nsplits", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.splitcross.SplitCrossEntropyLoss.logprob": [[26, 71], ["torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "list", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "results.append", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "softmaxed_head_res[].contiguous", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "results.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "softmaxed_head_res[].contiguous.view"], "methods", ["None"], ["", "", "def", "logprob", "(", "self", ",", "weight", ",", "bias", ",", "hiddens", ",", "splits", "=", "None", ",", "softmaxed_head_res", "=", "None", ",", "verbose", "=", "False", ")", ":", "\n", "# First we perform the first softmax on the head vocabulary and the tombstones", "\n", "        ", "if", "softmaxed_head_res", "is", "None", ":", "\n", "            ", "start", ",", "end", "=", "self", ".", "splits", "[", "0", "]", ",", "self", ".", "splits", "[", "1", "]", "\n", "head_weight", "=", "None", "if", "end", "-", "start", "==", "0", "else", "weight", "[", "start", ":", "end", "]", "\n", "head_bias", "=", "None", "if", "end", "-", "start", "==", "0", "else", "bias", "[", "start", ":", "end", "]", "\n", "# We only add the tombstones if we have more than one split", "\n", "if", "self", ".", "nsplits", ">", "1", ":", "\n", "                ", "head_weight", "=", "self", ".", "tail_vectors", "if", "head_weight", "is", "None", "else", "torch", ".", "cat", "(", "[", "head_weight", ",", "self", ".", "tail_vectors", "]", ")", "\n", "head_bias", "=", "self", ".", "tail_bias", "if", "head_bias", "is", "None", "else", "torch", ".", "cat", "(", "[", "head_bias", ",", "self", ".", "tail_bias", "]", ")", "\n", "\n", "# Perform the softmax calculation for the word vectors in the head for all splits", "\n", "# We need to guard against empty splits as torch.cat does not like random lists", "\n", "", "head_res", "=", "torch", ".", "nn", ".", "functional", ".", "linear", "(", "hiddens", ",", "head_weight", ",", "bias", "=", "head_bias", ")", "\n", "softmaxed_head_res", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "head_res", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "if", "splits", "is", "None", ":", "\n", "            ", "splits", "=", "list", "(", "range", "(", "self", ".", "nsplits", ")", ")", "\n", "\n", "", "results", "=", "[", "]", "\n", "running_offset", "=", "0", "\n", "for", "idx", "in", "splits", ":", "\n", "\n", "# For those targets in the head (idx == 0) we only need to return their loss", "\n", "            ", "if", "idx", "==", "0", ":", "\n", "                ", "results", ".", "append", "(", "softmaxed_head_res", "[", ":", ",", ":", "-", "(", "self", ".", "nsplits", "-", "1", ")", "]", ")", "\n", "\n", "# If the target is in one of the splits, the probability is the p(tombstone) * p(word within tombstone)", "\n", "", "else", ":", "\n", "                ", "start", ",", "end", "=", "self", ".", "splits", "[", "idx", "]", ",", "self", ".", "splits", "[", "idx", "+", "1", "]", "\n", "tail_weight", "=", "weight", "[", "start", ":", "end", "]", "\n", "tail_bias", "=", "bias", "[", "start", ":", "end", "]", "\n", "\n", "# Calculate the softmax for the words in the tombstone", "\n", "tail_res", "=", "torch", ".", "nn", ".", "functional", ".", "linear", "(", "hiddens", ",", "tail_weight", ",", "bias", "=", "tail_bias", ")", "\n", "\n", "# Then we calculate p(tombstone) * p(word in tombstone)", "\n", "# Adding is equivalent to multiplication in log space", "\n", "head_entropy", "=", "(", "softmaxed_head_res", "[", ":", ",", "-", "idx", "]", ")", ".", "contiguous", "(", ")", "\n", "tail_entropy", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "tail_res", ",", "dim", "=", "-", "1", ")", "\n", "results", ".", "append", "(", "head_entropy", ".", "view", "(", "-", "1", ",", "1", ")", "+", "tail_entropy", ")", "\n", "\n", "", "", "if", "len", "(", "results", ")", ">", "1", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "results", ",", "dim", "=", "1", ")", "\n", "", "return", "results", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.splitcross.SplitCrossEntropyLoss.split_on_targets": [[72, 105], ["range", "range", "split_targets.append", "split_hiddens.append", "sum", "len", "split_targets.append", "split_hiddens.append", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "hiddens.masked_select().view", "hiddens.size", "len", "hiddens.masked_select", "tmp_mask.unsqueeze().expand_as", "tmp_mask.unsqueeze"], "methods", ["None"], ["", "def", "split_on_targets", "(", "self", ",", "hiddens", ",", "targets", ")", ":", "\n", "# Split the targets into those in the head and in the tail", "\n", "        ", "split_targets", "=", "[", "]", "\n", "split_hiddens", "=", "[", "]", "\n", "\n", "# Determine to which split each element belongs (for each start split value, add 1 if equal or greater)", "\n", "# This method appears slower at least for WT-103 values for approx softmax", "\n", "#masks = [(targets >= self.splits[idx]).view(1, -1) for idx in range(1, self.nsplits)]", "\n", "#mask = torch.sum(torch.cat(masks, dim=0), dim=0)", "\n", "###", "\n", "# This is equally fast for smaller splits as method below but scales linearly", "\n", "mask", "=", "None", "\n", "for", "idx", "in", "range", "(", "1", ",", "self", ".", "nsplits", ")", ":", "\n", "            ", "partial_mask", "=", "targets", ">=", "self", ".", "splits", "[", "idx", "]", "\n", "mask", "=", "mask", "+", "partial_mask", "if", "mask", "is", "not", "None", "else", "partial_mask", "\n", "###", "\n", "#masks = torch.stack([targets] * (self.nsplits - 1))", "\n", "#mask = torch.sum(masks >= self.split_starts, dim=0)", "\n", "", "for", "idx", "in", "range", "(", "self", ".", "nsplits", ")", ":", "\n", "# If there are no splits, avoid costly masked select", "\n", "            ", "if", "self", ".", "nsplits", "==", "1", ":", "\n", "                ", "split_targets", ",", "split_hiddens", "=", "[", "targets", "]", ",", "[", "hiddens", "]", "\n", "continue", "\n", "# If all the words are covered by earlier targets, we have empties so later stages don't freak out", "\n", "", "if", "sum", "(", "len", "(", "t", ")", "for", "t", "in", "split_targets", ")", "==", "len", "(", "targets", ")", ":", "\n", "                ", "split_targets", ".", "append", "(", "[", "]", ")", "\n", "split_hiddens", ".", "append", "(", "[", "]", ")", "\n", "continue", "\n", "# Are you in our split?", "\n", "", "tmp_mask", "=", "mask", "==", "idx", "\n", "split_targets", ".", "append", "(", "torch", ".", "masked_select", "(", "targets", ",", "tmp_mask", ")", ")", "\n", "split_hiddens", ".", "append", "(", "hiddens", ".", "masked_select", "(", "tmp_mask", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "hiddens", ")", ")", ".", "view", "(", "-", "1", ",", "hiddens", ".", "size", "(", "1", ")", ")", ")", "\n", "", "return", "split_targets", ",", "split_hiddens", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.splitcross.SplitCrossEntropyLoss.forward": [[106, 170], ["splitcross.SplitCrossEntropyLoss.split_on_targets", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "range", "sorted", "print", "len", "hiddens.view.view.view", "splitcross.SplitCrossEntropyLoss.stats[].append", "len", "print", "hiddens.view.view.size", "hiddens.view.view.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "splitcross.SplitCrossEntropyLoss.logprob", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "entropy.float().sum", "range", "len", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "splitcross.SplitCrossEntropyLoss.stats[].append", "entropy.float().sum", "len", "int", "torch.cat.size", "torch.cat.size", "head_weight.size", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "entropy.float", "numpy.mean", "len", "split_targets[].view", "len", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "entropy.float", "split_hiddens[].size", "tail_weight.size"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.splitcross.SplitCrossEntropyLoss.split_on_targets", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.splitcross.SplitCrossEntropyLoss.logprob"], ["", "def", "forward", "(", "self", ",", "weight", ",", "bias", ",", "hiddens", ",", "targets", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "verbose", "or", "verbose", ":", "\n", "            ", "for", "idx", "in", "sorted", "(", "self", ".", "stats", ")", ":", "\n", "                ", "print", "(", "'{}: {}'", ".", "format", "(", "idx", ",", "int", "(", "np", ".", "mean", "(", "self", ".", "stats", "[", "idx", "]", ")", ")", ")", ",", "end", "=", "', '", ")", "\n", "", "print", "(", ")", "\n", "\n", "", "total_loss", "=", "None", "\n", "if", "len", "(", "hiddens", ".", "size", "(", ")", ")", ">", "2", ":", "hiddens", "=", "hiddens", ".", "view", "(", "-", "1", ",", "hiddens", ".", "size", "(", "2", ")", ")", "\n", "\n", "split_targets", ",", "split_hiddens", "=", "self", ".", "split_on_targets", "(", "hiddens", ",", "targets", ")", "\n", "\n", "# First we perform the first softmax on the head vocabulary and the tombstones", "\n", "start", ",", "end", "=", "self", ".", "splits", "[", "0", "]", ",", "self", ".", "splits", "[", "1", "]", "\n", "head_weight", "=", "None", "if", "end", "-", "start", "==", "0", "else", "weight", "[", "start", ":", "end", "]", "\n", "head_bias", "=", "None", "if", "end", "-", "start", "==", "0", "else", "bias", "[", "start", ":", "end", "]", "\n", "\n", "# We only add the tombstones if we have more than one split", "\n", "if", "self", ".", "nsplits", ">", "1", ":", "\n", "            ", "head_weight", "=", "self", ".", "tail_vectors", "if", "head_weight", "is", "None", "else", "torch", ".", "cat", "(", "[", "head_weight", ",", "self", ".", "tail_vectors", "]", ")", "\n", "head_bias", "=", "self", ".", "tail_bias", "if", "head_bias", "is", "None", "else", "torch", ".", "cat", "(", "[", "head_bias", ",", "self", ".", "tail_bias", "]", ")", "\n", "\n", "# Perform the softmax calculation for the word vectors in the head for all splits", "\n", "# We need to guard against empty splits as torch.cat does not like random lists", "\n", "", "combo", "=", "torch", ".", "cat", "(", "[", "split_hiddens", "[", "i", "]", "for", "i", "in", "range", "(", "self", ".", "nsplits", ")", "if", "len", "(", "split_hiddens", "[", "i", "]", ")", "]", ")", "\n", "###", "\n", "all_head_res", "=", "torch", ".", "nn", ".", "functional", ".", "linear", "(", "combo", ",", "head_weight", ",", "bias", "=", "head_bias", ")", "\n", "softmaxed_all_head_res", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "all_head_res", ",", "dim", "=", "-", "1", ")", "\n", "if", "self", ".", "verbose", "or", "verbose", ":", "\n", "            ", "self", ".", "stats", "[", "0", "]", ".", "append", "(", "combo", ".", "size", "(", ")", "[", "0", "]", "*", "head_weight", ".", "size", "(", ")", "[", "0", "]", ")", "\n", "\n", "", "running_offset", "=", "0", "\n", "for", "idx", "in", "range", "(", "self", ".", "nsplits", ")", ":", "\n", "# If there are no targets for this split, continue", "\n", "            ", "if", "len", "(", "split_targets", "[", "idx", "]", ")", "==", "0", ":", "continue", "\n", "\n", "# For those targets in the head (idx == 0) we only need to return their loss", "\n", "if", "idx", "==", "0", ":", "\n", "                ", "softmaxed_head_res", "=", "softmaxed_all_head_res", "[", "running_offset", ":", "running_offset", "+", "len", "(", "split_hiddens", "[", "idx", "]", ")", "]", "\n", "entropy", "=", "-", "torch", ".", "gather", "(", "softmaxed_head_res", ",", "dim", "=", "1", ",", "index", "=", "split_targets", "[", "idx", "]", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "# If the target is in one of the splits, the probability is the p(tombstone) * p(word within tombstone)", "\n", "", "else", ":", "\n", "                ", "softmaxed_head_res", "=", "softmaxed_all_head_res", "[", "running_offset", ":", "running_offset", "+", "len", "(", "split_hiddens", "[", "idx", "]", ")", "]", "\n", "\n", "if", "self", ".", "verbose", "or", "verbose", ":", "\n", "                    ", "start", ",", "end", "=", "self", ".", "splits", "[", "idx", "]", ",", "self", ".", "splits", "[", "idx", "+", "1", "]", "\n", "tail_weight", "=", "weight", "[", "start", ":", "end", "]", "\n", "self", ".", "stats", "[", "idx", "]", ".", "append", "(", "split_hiddens", "[", "idx", "]", ".", "size", "(", ")", "[", "0", "]", "*", "tail_weight", ".", "size", "(", ")", "[", "0", "]", ")", "\n", "\n", "# Calculate the softmax for the words in the tombstone", "\n", "", "tail_res", "=", "self", ".", "logprob", "(", "weight", ",", "bias", ",", "split_hiddens", "[", "idx", "]", ",", "splits", "=", "[", "idx", "]", ",", "softmaxed_head_res", "=", "softmaxed_head_res", ")", "\n", "\n", "# Then we calculate p(tombstone) * p(word in tombstone)", "\n", "# Adding is equivalent to multiplication in log space", "\n", "head_entropy", "=", "softmaxed_head_res", "[", ":", ",", "-", "idx", "]", "\n", "# All indices are shifted - if the first split handles [0,...,499] then the 500th in the second split will be 0 indexed", "\n", "indices", "=", "(", "split_targets", "[", "idx", "]", "-", "self", ".", "splits", "[", "idx", "]", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "# Warning: if you don't squeeze, you get an N x 1 return, which acts oddly with broadcasting", "\n", "tail_entropy", "=", "torch", ".", "gather", "(", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "tail_res", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "1", ",", "index", "=", "indices", ")", ".", "squeeze", "(", ")", "\n", "entropy", "=", "-", "(", "head_entropy", "+", "tail_entropy", ")", "\n", "###", "\n", "", "running_offset", "+=", "len", "(", "split_hiddens", "[", "idx", "]", ")", "\n", "total_loss", "=", "entropy", ".", "float", "(", ")", ".", "sum", "(", ")", "if", "total_loss", "is", "None", "else", "total_loss", "+", "entropy", ".", "float", "(", ")", ".", "sum", "(", ")", "\n", "\n", "", "return", "(", "total_loss", "/", "len", "(", "targets", ")", ")", ".", "type_as", "(", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.pointer.one_hot": [[52, 58], ["numpy.zeros", "torch.autograd.Variable", "torch.from_numpy", "torch.from_numpy", "v.cuda.cuda"], "function", ["None"], ["def", "one_hot", "(", "idx", ",", "size", ",", "cuda", "=", "True", ")", ":", "\n", "    ", "a", "=", "np", ".", "zeros", "(", "(", "1", ",", "size", ")", ",", "np", ".", "float32", ")", "\n", "a", "[", "0", "]", "[", "idx", "]", "=", "1", "\n", "v", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "a", ")", ")", "\n", "if", "cuda", ":", "v", "=", "v", ".", "cuda", "(", ")", "\n", "return", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.pointer.evaluate": [[59, 114], ["model.eval", "len", "model.init_hidden", "range", "model.reset", "utils.get_batch", "model", "rnn_outs[].squeeze", "output.view", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "enumerate", "utils.repackage_hidden", "len", "data_source.size", "print", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.autograd.Variable", "torch.cat", "torch.cat", "len", "math.exp", "torch.mv", "torch.mv", "torch.nn.functional.softmax().view", "torch.nn.functional.softmax().view", "pointer.one_hot", "torch.cat", "torch.cat", "torch.autograd.Variable", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.log", "torch.log", "pointer.one_hot", "torch.nn.functional.softmax().view.expand_as"], "function", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.utils.get_batch", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.utils.repackage_hidden", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.pointer.one_hot", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.pointer.one_hot"], ["", "def", "evaluate", "(", "data_source", ",", "batch_size", "=", "10", ",", "window", "=", "args", ".", "window", ")", ":", "\n", "# Turn on evaluation mode which disables dropout.", "\n", "    ", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "total_loss", "=", "0", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "batch_size", ")", "\n", "next_word_history", "=", "None", "\n", "pointer_history", "=", "None", "\n", "for", "i", "in", "range", "(", "0", ",", "data_source", ".", "size", "(", "0", ")", "-", "1", ",", "args", ".", "bptt", ")", ":", "\n", "        ", "if", "i", ">", "0", ":", "print", "(", "i", ",", "len", "(", "data_source", ")", ",", "math", ".", "exp", "(", "total_loss", "/", "i", ")", ")", "\n", "data", ",", "targets", "=", "get_batch", "(", "data_source", ",", "i", ",", "evaluation", "=", "True", ",", "args", "=", "args", ")", "\n", "output", ",", "hidden", ",", "rnn_outs", ",", "_", "=", "model", "(", "data", ",", "hidden", ",", "return_h", "=", "True", ")", "\n", "rnn_out", "=", "rnn_outs", "[", "-", "1", "]", ".", "squeeze", "(", ")", "\n", "output_flat", "=", "output", ".", "view", "(", "-", "1", ",", "ntokens", ")", "\n", "###", "\n", "# Fill pointer history", "\n", "start_idx", "=", "len", "(", "next_word_history", ")", "if", "next_word_history", "is", "not", "None", "else", "0", "\n", "next_word_history", "=", "torch", ".", "cat", "(", "[", "one_hot", "(", "t", ".", "data", "[", "0", "]", ",", "ntokens", ")", "for", "t", "in", "targets", "]", ")", "if", "next_word_history", "is", "None", "else", "torch", ".", "cat", "(", "[", "next_word_history", ",", "torch", ".", "cat", "(", "[", "one_hot", "(", "t", ".", "data", "[", "0", "]", ",", "ntokens", ")", "for", "t", "in", "targets", "]", ")", "]", ")", "\n", "#print(next_word_history)", "\n", "pointer_history", "=", "Variable", "(", "rnn_out", ".", "data", ")", "if", "pointer_history", "is", "None", "else", "torch", ".", "cat", "(", "[", "pointer_history", ",", "Variable", "(", "rnn_out", ".", "data", ")", "]", ",", "dim", "=", "0", ")", "\n", "#print(pointer_history)", "\n", "###", "\n", "# Built-in cross entropy", "\n", "# total_loss += len(data) * criterion(output_flat, targets).data[0]", "\n", "###", "\n", "# Manual cross entropy", "\n", "# softmax_output_flat = torch.nn.functional.softmax(output_flat)", "\n", "# soft = torch.gather(softmax_output_flat, dim=1, index=targets.view(-1, 1))", "\n", "# entropy = -torch.log(soft)", "\n", "# total_loss += len(data) * entropy.mean().data[0]", "\n", "###", "\n", "# Pointer manual cross entropy", "\n", "loss", "=", "0", "\n", "softmax_output_flat", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "output_flat", ")", "\n", "for", "idx", ",", "vocab_loss", "in", "enumerate", "(", "softmax_output_flat", ")", ":", "\n", "            ", "p", "=", "vocab_loss", "\n", "if", "start_idx", "+", "idx", ">", "window", ":", "\n", "                ", "valid_next_word", "=", "next_word_history", "[", "start_idx", "+", "idx", "-", "window", ":", "start_idx", "+", "idx", "]", "\n", "valid_pointer_history", "=", "pointer_history", "[", "start_idx", "+", "idx", "-", "window", ":", "start_idx", "+", "idx", "]", "\n", "logits", "=", "torch", ".", "mv", "(", "valid_pointer_history", ",", "rnn_out", "[", "idx", "]", ")", "\n", "theta", "=", "args", ".", "theta", "\n", "ptr_attn", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "theta", "*", "logits", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "ptr_dist", "=", "(", "ptr_attn", ".", "expand_as", "(", "valid_next_word", ")", "*", "valid_next_word", ")", ".", "sum", "(", "0", ")", ".", "squeeze", "(", ")", "\n", "lambdah", "=", "args", ".", "lambdasm", "\n", "p", "=", "lambdah", "*", "ptr_dist", "+", "(", "1", "-", "lambdah", ")", "*", "vocab_loss", "\n", "###", "\n", "", "target_loss", "=", "p", "[", "targets", "[", "idx", "]", ".", "data", "]", "\n", "loss", "+=", "(", "-", "torch", ".", "log", "(", "target_loss", ")", ")", ".", "data", "[", "0", "]", "\n", "", "total_loss", "+=", "loss", "/", "batch_size", "\n", "###", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "next_word_history", "=", "next_word_history", "[", "-", "window", ":", "]", "\n", "pointer_history", "=", "pointer_history", "[", "-", "window", ":", "]", "\n", "", "return", "total_loss", "/", "len", "(", "data_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.forget_mult.CPUForgetMult.__init__": [[75, 77], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.locked_dropout.LockedDropout.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "CPUForgetMult", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.forget_mult.CPUForgetMult.forward": [[78, 92], ["f.split", "enumerate", "torch.stack", "h.view.view.view", "result.append", "h.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "f", ",", "x", ",", "hidden_init", "=", "None", ")", ":", "\n", "        ", "result", "=", "[", "]", "\n", "###", "\n", "forgets", "=", "f", ".", "split", "(", "1", ",", "dim", "=", "0", ")", "\n", "prev_h", "=", "hidden_init", "\n", "for", "i", ",", "h", "in", "enumerate", "(", "(", "f", "*", "x", ")", ".", "split", "(", "1", ",", "dim", "=", "0", ")", ")", ":", "\n", "            ", "if", "prev_h", "is", "not", "None", ":", "h", "=", "h", "+", "(", "1", "-", "forgets", "[", "i", "]", ")", "*", "prev_h", "\n", "# h is (1, batch, hidden) when it needs to be (batch_hidden)", "\n", "# Calling squeeze will result in badness if batch size is 1", "\n", "h", "=", "h", ".", "view", "(", "h", ".", "size", "(", ")", "[", "1", ":", "]", ")", "\n", "result", ".", "append", "(", "h", ")", "\n", "prev_h", "=", "h", "\n", "###", "\n", "", "return", "torch", ".", "stack", "(", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.forget_mult.GPUForgetMult.__init__": [[97, 99], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.locked_dropout.LockedDropout.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "GPUForgetMult", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.forget_mult.GPUForgetMult.compile": [[100, 119], ["pynvrtc.compiler.Program", "pynvrtc.compiler.Program.compile", "torch.cuda.current_device", "cupy.cuda.function.Module", "cupy.cuda.function.Module.load", "cupy.cuda.function.Module.get_function", "cupy.cuda.function.Module.get_function", "collections.namedtuple", "collections.namedtuple.", "bytes", "torch.cuda.current_device", "forget_mult.GPUForgetMult.ptx.encode", "torch.cuda.current_device", "torch.cuda.current_stream"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.forget_mult.GPUForgetMult.compile"], ["", "def", "compile", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "ptx", "is", "None", ":", "\n", "#program = Program(kernel.encode(), 'recurrent_forget_mult.cu'.encode())", "\n", "            ", "program", "=", "Program", "(", "kernel", ",", "'recurrent_forget_mult.cu'", ")", "\n", "GPUForgetMult", ".", "ptx", "=", "program", ".", "compile", "(", ")", "\n", "\n", "", "if", "torch", ".", "cuda", ".", "current_device", "(", ")", "not", "in", "GPUForgetMult", ".", "configured_gpus", ":", "\n", "            ", "m", "=", "function", ".", "Module", "(", ")", "\n", "m", ".", "load", "(", "bytes", "(", "self", ".", "ptx", ".", "encode", "(", ")", ")", ")", "\n", "\n", "self", ".", "forget_mult", "=", "m", ".", "get_function", "(", "'recurrent_forget_mult'", ")", "\n", "self", ".", "bwd_forget_mult", "=", "m", ".", "get_function", "(", "'bwd_recurrent_forget_mult'", ")", "\n", "\n", "Stream", "=", "namedtuple", "(", "'Stream'", ",", "[", "'ptr'", "]", ")", "\n", "self", ".", "stream", "=", "Stream", "(", "ptr", "=", "torch", ".", "cuda", ".", "current_stream", "(", ")", ".", "cuda_stream", ")", "\n", "\n", "GPUForgetMult", ".", "configured_gpus", "[", "torch", ".", "cuda", ".", "current_device", "(", ")", "]", "=", "(", "self", ".", "forget_mult", ",", "self", ".", "bwd_forget_mult", ",", "self", ".", "stream", ")", "\n", "\n", "", "self", ".", "forget_mult", ",", "self", ".", "bwd_forget_mult", ",", "self", ".", "stream", "=", "GPUForgetMult", ".", "configured_gpus", "[", "torch", ".", "cuda", ".", "current_device", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.forget_mult.GPUForgetMult.forward": [[120, 135], ["forget_mult.GPUForgetMult.compile", "f.size", "f.new", "min", "forget_mult.GPUForgetMult.forget_mult", "forget_mult.GPUForgetMult.save_for_backward", "result.zero_.zero_.zero_", "math.ceil", "result.zero_.zero_.data_ptr", "f.data_ptr", "x.data_ptr"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.forget_mult.GPUForgetMult.compile"], ["", "def", "forward", "(", "self", ",", "f", ",", "x", ",", "hidden_init", "=", "None", ")", ":", "\n", "        ", "self", ".", "compile", "(", ")", "\n", "seq_size", ",", "batch_size", ",", "hidden_size", "=", "f", ".", "size", "(", ")", "\n", "result", "=", "f", ".", "new", "(", "seq_size", "+", "1", ",", "batch_size", ",", "hidden_size", ")", "\n", "# We only zero the result array (result[0]) if we don't set a hidden initial state", "\n", "# All other values (result[1:]) are overwritten by default", "\n", "if", "hidden_init", "is", "not", "None", ":", "result", "[", "0", ",", ":", ",", ":", "]", "=", "hidden_init", "\n", "else", ":", "result", "=", "result", ".", "zero_", "(", ")", "\n", "###", "\n", "grid_hidden_size", "=", "min", "(", "hidden_size", ",", "512", ")", "\n", "grid", "=", "(", "math", ".", "ceil", "(", "hidden_size", "/", "grid_hidden_size", ")", ",", "batch_size", ")", "\n", "self", ".", "forget_mult", "(", "grid", "=", "grid", ",", "block", "=", "(", "grid_hidden_size", ",", "1", ")", ",", "args", "=", "[", "result", ".", "data_ptr", "(", ")", ",", "f", ".", "data_ptr", "(", ")", ",", "x", ".", "data_ptr", "(", ")", ",", "seq_size", ",", "batch_size", ",", "hidden_size", "]", ",", "stream", "=", "self", ".", "stream", ")", "\n", "self", ".", "save_for_backward", "(", "f", ",", "x", ",", "hidden_init", ")", "\n", "self", ".", "result", "=", "result", "\n", "return", "result", "[", "1", ":", ",", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.forget_mult.GPUForgetMult.backward": [[136, 154], ["forget_mult.GPUForgetMult.compile", "f.size", "f.new", "f.new", "f.new", "min", "forget_mult.GPUForgetMult.bwd_forget_mult", "math.ceil", "f.size", "f.size", "h.data_ptr", "f.data_ptr", "x.data_ptr", "grad_h.data_ptr", "f.new.data_ptr", "f.new.data_ptr", "f.new.data_ptr"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.forget_mult.GPUForgetMult.compile"], ["", "def", "backward", "(", "self", ",", "grad_h", ")", ":", "\n", "        ", "self", ".", "compile", "(", ")", "\n", "f", ",", "x", ",", "hidden_init", "=", "self", ".", "saved_tensors", "\n", "h", "=", "self", ".", "result", "\n", "###", "\n", "seq_size", ",", "batch_size", ",", "hidden_size", "=", "f", ".", "size", "(", ")", "\n", "# Zeroing is not necessary as these will be overwritten", "\n", "grad_f", "=", "f", ".", "new", "(", "*", "f", ".", "size", "(", ")", ")", "\n", "grad_x", "=", "f", ".", "new", "(", "*", "f", ".", "size", "(", ")", ")", "\n", "grad_h_init", "=", "f", ".", "new", "(", "1", ",", "batch_size", ",", "hidden_size", ")", "\n", "###", "\n", "grid_hidden_size", "=", "min", "(", "hidden_size", ",", "512", ")", "\n", "grid", "=", "(", "math", ".", "ceil", "(", "hidden_size", "/", "grid_hidden_size", ")", ",", "batch_size", ")", "\n", "self", ".", "bwd_forget_mult", "(", "grid", "=", "grid", ",", "block", "=", "(", "grid_hidden_size", ",", "1", ")", ",", "args", "=", "[", "h", ".", "data_ptr", "(", ")", ",", "f", ".", "data_ptr", "(", ")", ",", "x", ".", "data_ptr", "(", ")", ",", "grad_h", ".", "data_ptr", "(", ")", ",", "grad_f", ".", "data_ptr", "(", ")", ",", "grad_x", ".", "data_ptr", "(", ")", ",", "grad_h_init", ".", "data_ptr", "(", ")", ",", "seq_size", ",", "batch_size", ",", "hidden_size", "]", ",", "stream", "=", "self", ".", "stream", ")", "\n", "###", "\n", "if", "hidden_init", "is", "not", "None", ":", "\n", "            ", "return", "grad_f", ",", "grad_x", ",", "grad_h_init", "\n", "", "return", "grad_f", ",", "grad_x", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.forget_mult.ForgetMult.__init__": [[169, 171], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.locked_dropout.LockedDropout.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "ForgetMult", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.forget_mult.ForgetMult.forward": [[172, 181], ["torch.cuda.is_available", "forget_mult.GPUForgetMult", "forget_mult.CPUForgetMult", "forget_mult.GPUForgetMult", "forget_mult.CPUForgetMult"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "f", ",", "x", ",", "hidden_init", "=", "None", ",", "use_cuda", "=", "True", ")", ":", "\n", "# Use CUDA by default unless it's available", "\n", "        ", "use_cuda", "=", "use_cuda", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "# Ensure the user is aware when ForgetMult is not GPU version as it's far faster", "\n", "if", "use_cuda", ":", "assert", "f", ".", "is_cuda", "and", "x", ".", "is_cuda", ",", "'GPU ForgetMult with fast element-wise CUDA kernel requested but tensors not on GPU'", "\n", "###", "\n", "# Avoiding 'RuntimeError: expected a Variable argument, but got NoneType' when hidden_init is None", "\n", "if", "hidden_init", "is", "None", ":", "return", "GPUForgetMult", "(", ")", "(", "f", ",", "x", ")", "if", "use_cuda", "else", "CPUForgetMult", "(", ")", "(", "f", ",", "x", ")", "\n", "return", "GPUForgetMult", "(", ")", "(", "f", ",", "x", ",", "hidden_init", ")", "if", "use_cuda", "else", "CPUForgetMult", "(", ")", "(", "f", ",", "x", ",", "hidden_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.main.model_save": [[107, 114], ["open", "torch.save", "torch.save", "open", "torch.save", "torch.save", "os.path.join", "os.path.join"], "function", ["None"], ["def", "model_save", "(", "fn", ")", ":", "\n", "    ", "if", "args", ".", "use_sg", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "\"weights/\"", ",", "fn", "+", "\".pt\"", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "torch", ".", "save", "(", "[", "model", ",", "criterion", ",", "optimizer", ",", "backward_interface", ",", "sgoptimizer", "]", ",", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "\"weights/\"", ",", "fn", "+", "\".pt\"", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "torch", ".", "save", "(", "[", "model", ",", "criterion", ",", "optimizer", "]", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.main.model_load": [[115, 124], ["open", "torch.load", "torch.load", "open", "torch.load", "torch.load", "os.path.join", "os.path.join"], "function", ["None"], ["", "", "", "def", "model_load", "(", "fn", ")", ":", "\n", "    ", "if", "args", ".", "resumesg", "or", "args", ".", "use_sg", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "\"weights/\"", ",", "fn", "+", "\".pt\"", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "model", ",", "criterion", ",", "optimizer", ",", "backward_interface", ",", "sgoptimizer", "=", "torch", ".", "load", "(", "f", ")", "\n", "", "return", "model", ",", "criterion", ",", "optimizer", ",", "backward_interface", ",", "sgoptimizer", "\n", "", "else", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "\"weights/\"", ",", "fn", "+", "\".pt\"", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "model", ",", "criterion", ",", "optimizer", "=", "torch", ".", "load", "(", "f", ")", "\n", "", "return", "model", ",", "criterion", ",", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.main.evaluate": [[199, 212], ["model.eval", "len", "model.init_hidden", "range", "model.reset", "utils.get_batch", "model", "utils.repackage_hidden", "total_loss.item", "len", "data_source.size", "len", "criterion"], "function", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.utils.get_batch", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.utils.repackage_hidden"], ["def", "evaluate", "(", "data_source", ",", "batch_size", "=", "10", ")", ":", "\n", "# Turn on evaluation mode which disables dropout.", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "total_loss", "=", "0", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "batch_size", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "data_source", ".", "size", "(", "0", ")", "-", "1", ",", "args", ".", "bptt", ")", ":", "\n", "        ", "data", ",", "targets", "=", "get_batch", "(", "data_source", ",", "i", ",", "args", ",", "evaluation", "=", "True", ")", "\n", "output", ",", "hidden", "=", "model", "(", "data", ",", "hidden", ")", "\n", "total_loss", "+=", "len", "(", "data", ")", "*", "criterion", "(", "model", ".", "decoder", ".", "weight", ",", "model", ".", "decoder", ".", "bias", ",", "output", ",", "targets", ")", ".", "data", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "", "return", "total_loss", ".", "item", "(", ")", "/", "len", "(", "data_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.main.train": [[213, 285], ["time.time", "len", "model.init_hidden", "print", "model.reset", "max", "model.train", "utils.get_batch", "utils.repackage_hidden", "optimizer.zero_grad", "optimizer.step", "total_loss.item", "time.time", "int", "sgoptimizer.zero_grad", "model", "criterion", "loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "math.exp", "train_data.size", "numpy.random.random", "numpy.random.normal", "dni.defer_backward", "model", "criterion", "dni.backward", "sgoptimizer.step", "len", "math.log", "sum", "sum", "sum", "sum", "dropped_rnn_h.pow().mean", "dropped_rnn_h.pow().mean", "dropped_rnn_h.pow", "dropped_rnn_h.pow"], "function", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.main.train", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.utils.get_batch", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.utils.repackage_hidden", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._Manager.backward", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.defer_backward", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._Manager.backward"], ["", "def", "train", "(", ")", ":", "\n", "# Turn on training mode which enables dropout.", "\n", "    ", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "args", ".", "batch_size", ")", "\n", "batch", ",", "i", "=", "0", ",", "0", "\n", "\n", "while", "i", "<", "train_data", ".", "size", "(", "0", ")", "-", "1", "-", "1", ":", "\n", "        ", "bptt", "=", "args", ".", "bptt", "if", "np", ".", "random", ".", "random", "(", ")", "<", "0.95", "else", "args", ".", "bptt", "/", "2.", "\n", "# Prevent excessively small or negative sequence lengths", "\n", "seq_len", "=", "max", "(", "5", ",", "int", "(", "np", ".", "random", ".", "normal", "(", "bptt", ",", "5", ")", ")", ")", "\n", "# There's a very small chance that it could select a very long sequence length resulting in OOM", "\n", "# seq_len = min(seq_len, args.bptt + 10)", "\n", "\n", "lr2", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "*", "seq_len", "/", "args", ".", "bptt", "\n", "model", ".", "train", "(", ")", "\n", "\n", "data", ",", "targets", "=", "get_batch", "(", "train_data", ",", "i", ",", "args", ",", "seq_len", "=", "seq_len", ")", "\n", "\n", "# Starting each batch, we detach the hidden state from how it was previously produced.", "\n", "# If we didn't, the model would try backpropagating all the way to start of the dataset.", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "args", ".", "use_sg", ":", "\n", "            ", "sgoptimizer", ".", "zero_grad", "(", ")", "\n", "with", "dni", ".", "defer_backward", "(", ")", ":", "\n", "                ", "output", ",", "hidden", ",", "rnn_hs", ",", "dropped_rnn_hs", "=", "model", "(", "data", ",", "hidden", ",", "return_h", "=", "True", ",", "use_sg", "=", "switcher", ",", "backward_interface", "=", "backward_interface", ")", "\n", "raw_loss", "=", "criterion", "(", "model", ".", "decoder", ".", "weight", ",", "model", ".", "decoder", ".", "bias", ",", "output", ",", "targets", ")", "\n", "\n", "loss", "=", "raw_loss", "\n", "# Activiation Regularization", "\n", "if", "args", ".", "alpha", ":", "loss", "=", "loss", "+", "sum", "(", "args", ".", "alpha", "*", "dropped_rnn_h", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "dropped_rnn_h", "in", "dropped_rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "# Temporal Activation Regularization (slowness)", "\n", "if", "args", ".", "beta", ":", "loss", "=", "loss", "+", "sum", "(", "args", ".", "beta", "*", "(", "rnn_h", "[", "1", ":", "]", "-", "rnn_h", "[", ":", "-", "1", "]", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "rnn_h", "in", "rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "\n", "dni", ".", "backward", "(", "loss", ")", "\n", "", "if", "not", "args", ".", "fixsg", ":", "\n", "                ", "sgoptimizer", ".", "step", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "output", ",", "hidden", ",", "rnn_hs", ",", "dropped_rnn_hs", "=", "model", "(", "data", ",", "hidden", ",", "return_h", "=", "True", ")", "\n", "raw_loss", "=", "criterion", "(", "model", ".", "decoder", ".", "weight", ",", "model", ".", "decoder", ".", "bias", ",", "output", ",", "targets", ")", "\n", "\n", "loss", "=", "raw_loss", "\n", "# Activiation Regularization", "\n", "if", "args", ".", "alpha", ":", "loss", "=", "loss", "+", "sum", "(", "args", ".", "alpha", "*", "dropped_rnn_h", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "dropped_rnn_h", "in", "dropped_rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "# Temporal Activation Regularization (slowness)", "\n", "if", "args", ".", "beta", ":", "loss", "=", "loss", "+", "sum", "(", "args", ".", "beta", "*", "(", "rnn_h", "[", "1", ":", "]", "-", "rnn_h", "[", ":", "-", "1", "]", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "rnn_h", "in", "rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.", "\n", "", "if", "args", ".", "clip", ":", "\n", "            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "params", ",", "args", ".", "clip", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "\n", "total_loss", "+=", "raw_loss", ".", "data", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "\n", "###", "\n", "batch", "+=", "1", "\n", "i", "+=", "seq_len", "\n", "\n", "", "cur_loss", "=", "total_loss", ".", "item", "(", ")", "/", "batch", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "'| epoch {:3d} | {:5d}/{:5d} batches | lr {:05.5f} | ms/batch {:5.2f} | '", "\n", "'loss {:5.2f} | ppl {:8.2f} | bpc {:8.3f} | use_sg: {}'", ".", "format", "(", "\n", "epoch", ",", "batch", ",", "len", "(", "train_data", ")", "//", "args", ".", "bptt", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "\n", "elapsed", "*", "1000", "/", "args", ".", "log_interval", ",", "cur_loss", ",", "math", ".", "exp", "(", "cur_loss", ")", ",", "cur_loss", "/", "math", ".", "log", "(", "2", ")", ",", "switcher", "*", "args", ".", "use_sg", ")", ")", "\n", "return", "cur_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.main._cosine_anneal_schedule": [[293, 298], ["float", "numpy.cos"], "function", ["None"], ["def", "_cosine_anneal_schedule", "(", "nb_epochs", ",", "t", ")", ":", "\n", "    ", "cos_inner", "=", "np", ".", "pi", "*", "(", "t", "%", "(", "nb_epochs", "//", "1", ")", ")", "# t - 1 is used when t has 1-based indexing.", "\n", "cos_inner", "/=", "nb_epochs", "//", "1", "\n", "cos_out", "=", "np", ".", "cos", "(", "cos_inner", ")", "+", "1", "\n", "return", "float", "(", "args", ".", "lr", "/", "2", "*", "cos_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.UnidirectionalInterface.__init__": [[19, 23], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.locked_dropout.LockedDropout.__init__"], ["def", "__init__", "(", "self", ",", "synthesizer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "synthesizer", "=", "synthesizer", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.UnidirectionalInterface.receive": [[24, 38], ["dni.UnidirectionalInterface.synthesizer().detach", "dni.UnidirectionalInterface.synthesizer", "dni._Manager.get_current_context"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._Manager.get_current_context"], ["", "def", "receive", "(", "self", ",", "trigger", ")", ":", "\n", "        ", "\"\"\"Synthesizes a `message` based on `trigger`.\n\n        Detaches `message` so no gradient will go through it during the\n        backward pass.\n\n        Args:\n            trigger: `trigger` to use to synthesize a `message`.\n\n        Returns:\n            The synthesized `message`.\n        \"\"\"", "\n", "return", "self", ".", "synthesizer", "(", "\n", "trigger", ",", "_Manager", ".", "get_current_context", "(", ")", "\n", ")", ".", "detach", "(", ")", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.UnidirectionalInterface.send": [[40, 59], ["dni.UnidirectionalInterface.synthesizer", "torch.nn.functional.mse_loss", "dni._Manager.backward", "trigger.detach", "dni._Manager.get_current_context", "message.detach"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._Manager.backward", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._Manager.get_current_context"], ["", "def", "send", "(", "self", ",", "message", ",", "trigger", ")", ":", "\n", "        ", "\"\"\"Updates the estimate of synthetic `message` based on `trigger`.\n\n        Synthesizes a `message` based on `trigger`, computes the MSE between it\n        and the input `message` and backpropagates it to compute its gradient\n        w.r.t. `Synthesizer` parameters. Does not backpropagate through\n        `trigger`.\n\n        Args:\n            message: Ground truth `message` that should be synthesized based on\n                `trigger`.\n            trigger: `trigger` that the `message` should be synthesized based\n                on.\n        \"\"\"", "\n", "synthetic_message", "=", "self", ".", "synthesizer", "(", "\n", "trigger", ".", "detach", "(", ")", ",", "_Manager", ".", "get_current_context", "(", ")", "\n", ")", "\n", "loss", "=", "F", ".", "mse_loss", "(", "synthetic_message", ",", "message", ".", "detach", "(", ")", ")", "\n", "_Manager", ".", "backward", "(", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.ForwardInterface.forward": [[73, 97], ["dni.ForwardInterface.send", "dni.ForwardInterface.receive"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BidirectionalInterface.send", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BidirectionalInterface.receive"], ["def", "forward", "(", "self", ",", "message", ",", "trigger", ")", ":", "\n", "        ", "\"\"\"Synthetic forward pass, no backward pass.\n\n        Convenience method combining `send` and `receive`. Updates the\n        `message` estimate based on `trigger` and returns a synthetic\n        `message`.\n\n        Works only in `training` mode, otherwise just returns the input\n        `message`.\n\n        Args:\n            message: Ground truth `message` that should be synthesized based on\n                `trigger`.\n            trigger: `trigger` that the `message` should be synthesized based\n                on.\n\n        Returns:\n            The synthesized `message`.\n        \"\"\"", "\n", "if", "self", ".", "training", ":", "\n", "            ", "self", ".", "send", "(", "message", ",", "trigger", ")", "\n", "return", "self", ".", "receive", "(", "trigger", ")", "\n", "", "else", ":", "\n", "            ", "return", "message", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BackwardInterface.forward": [[108, 135], ["dni.BackwardInterface.backward", "dni.BackwardInterface.make_trigger", "trigger.detach"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._Manager.backward", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BackwardInterface.make_trigger"], ["def", "forward", "(", "self", ",", "trigger", ")", ":", "\n", "        ", "\"\"\"Normal forward pass, synthetic backward pass.\n\n        Convenience method combining `backward` and `make_trigger`. Can be\n        used when we want to backpropagate synthetic gradients from and\n        intercept real gradients at the same `Variable`, for example for\n        update decoupling feed-forward networks.\n\n        Backpropagates synthetic gradient from `trigger` and returns a copy of\n        `trigger` with a synthetic gradient update operation attached.\n\n        Works only in `training` mode, otherwise just returns the input\n        `trigger`.\n\n        Args:\n            trigger: `trigger` to backpropagate synthetic gradient from and\n                intercept real gradient at.\n\n        Returns:\n            A copy of `trigger` with a synthetic gradient update operation\n            attached.\n        \"\"\"", "\n", "if", "self", ".", "training", ":", "\n", "            ", "self", ".", "backward", "(", "trigger", ")", "\n", "return", "self", ".", "make_trigger", "(", "trigger", ".", "detach", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "trigger", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BackwardInterface.backward": [[136, 153], ["dni.BackwardInterface.receive", "dni._Manager.backward", "trigger.detach"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BidirectionalInterface.receive", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._Manager.backward"], ["", "", "def", "backward", "(", "self", ",", "trigger", ",", "factor", "=", "1", ")", ":", "\n", "        ", "\"\"\"Backpropagates synthetic gradient from `trigger`.\n\n        Computes synthetic gradient based on `trigger`, scales it by `factor`\n        and backpropagates it from `trigger`.\n\n        Works only in `training` mode, otherwise is a no-op.\n\n        Args:\n            trigger: `trigger` to compute synthetic gradient based on and to\n                backpropagate it from.\n            factor (optional): Factor by which to scale the synthetic gradient.\n                Defaults to 1.\n        \"\"\"", "\n", "# if self.training:", "\n", "synthetic_gradient", "=", "self", ".", "receive", "(", "trigger", ".", "detach", "(", ")", ")", "\n", "_Manager", ".", "backward", "(", "trigger", ",", "synthetic_gradient", ".", "data", "*", "factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BackwardInterface.make_trigger": [[154, 176], ["_SyntheticGradientUpdater.apply", "dni.BackwardInterface.synthesizer", "dni._Manager.get_current_context"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._Manager.get_current_context"], ["", "def", "make_trigger", "(", "self", ",", "trigger", ")", ":", "\n", "        ", "\"\"\"Attaches a synthetic gradient update operation to `trigger`.\n\n        Returns a `Variable` with the same `data` as `trigger`, that during\n        the backward pass will intercept gradient passing through it and use\n        this gradient to update the `Synthesizer`'s estimate.\n\n        Works only in `training` mode, otherwise just returns the input\n        `trigger`.\n\n        Returns:\n            A copy of `trigger` with a synthetic gradient update operation\n            attached.\n        \"\"\"", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "_SyntheticGradientUpdater", ".", "apply", "(", "\n", "trigger", ",", "\n", "self", ".", "synthesizer", "(", "trigger", ",", "_Manager", ".", "get_current_context", "(", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "trigger", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._SyntheticGradientUpdater.forward": [[180, 191], ["ctx.save_for_backward", "trigger.clone", "ValueError"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "trigger", ",", "synthetic_gradient", ")", ":", "\n", "        ", "(", "_", ",", "needs_synthetic_gradient_grad", ")", "=", "ctx", ".", "needs_input_grad", "\n", "if", "not", "needs_synthetic_gradient_grad", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'synthetic_gradient should need gradient but it does not'", "\n", ")", "\n", "", "ctx", ".", "save_for_backward", "(", "synthetic_gradient", ")", "\n", "# clone trigger to force creating a new Variable with", "\n", "# requires_grad=True", "\n", "return", "trigger", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._SyntheticGradientUpdater.backward": [[192, 202], ["synthetic_gradient.size"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "true_gradient", ")", ":", "\n", "        ", "(", "synthetic_gradient", ",", ")", "=", "ctx", ".", "saved_tensors", "\n", "# compute MSE gradient manually to avoid dependency on PyTorch", "\n", "# internals", "\n", "(", "batch_size", ",", "*", "_", ")", "=", "synthetic_gradient", ".", "size", "(", ")", "\n", "grad_synthetic_gradient", "=", "(", "\n", "2", "/", "batch_size", "*", "(", "synthetic_gradient", ".", "data", "-", "true_gradient", ".", "data", ")", "\n", ")", "\n", "return", "(", "true_gradient", ",", "grad_synthetic_gradient", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BidirectionalInterface.__init__": [[215, 220], ["super().__init__", "dni.ForwardInterface", "dni.BackwardInterface"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.locked_dropout.LockedDropout.__init__"], ["def", "__init__", "(", "self", ",", "forward_synthesizer", ",", "backward_synthesizer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "forward_interface", "=", "ForwardInterface", "(", "forward_synthesizer", ")", "\n", "self", ".", "backward_interface", "=", "BackwardInterface", "(", "backward_synthesizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BidirectionalInterface.forward": [[221, 241], ["dni.BidirectionalInterface.send", "dni.BidirectionalInterface.receive"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BidirectionalInterface.send", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BidirectionalInterface.receive"], ["", "def", "forward", "(", "self", ",", "message", ",", "trigger", ")", ":", "\n", "        ", "\"\"\"Synthetic forward pass, synthetic backward pass.\n\n        Convenience method combining `send` and `receive`. Can be used when we\n        want to `send` and immediately `receive` using the same `trigger`. For\n        more complex scenarios, `send` and `receive` need to be used\n        separately.\n\n        Updates the `message` estimate based on `trigger`, backpropagates\n        synthetic gradient from `message` and returns a synthetic `message`\n        with a synthetic gradient update operation attached.\n\n        Works only in `training` mode, otherwise just returns the input\n        `message`.\n        \"\"\"", "\n", "if", "self", ".", "training", ":", "\n", "            ", "self", ".", "send", "(", "message", ",", "trigger", ")", "\n", "return", "self", ".", "receive", "(", "trigger", ")", "\n", "", "else", ":", "\n", "            ", "return", "message", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BidirectionalInterface.receive": [[242, 258], ["dni.BidirectionalInterface.forward_interface.receive", "dni.BidirectionalInterface.backward_interface.make_trigger"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BidirectionalInterface.receive", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BackwardInterface.make_trigger"], ["", "", "def", "receive", "(", "self", ",", "trigger", ")", ":", "\n", "        ", "\"\"\"Combination of `ForwardInterface.receive` and\n        `BackwardInterface.make_trigger`.\n\n        Generates a synthetic `message` based on `trigger` and attaches to it\n        a synthetic gradient update operation.\n\n        Args:\n            trigger: `trigger` to use to synthesize a `message`.\n\n        Returns:\n            The synthesized `message` with a synthetic gradient update\n            operation attached.\n        \"\"\"", "\n", "message", "=", "self", ".", "forward_interface", ".", "receive", "(", "trigger", ")", "\n", "return", "self", ".", "backward_interface", ".", "make_trigger", "(", "message", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BidirectionalInterface.send": [[259, 275], ["dni.BidirectionalInterface.forward_interface.send", "dni.BidirectionalInterface.backward_interface.backward"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BidirectionalInterface.send", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._Manager.backward"], ["", "def", "send", "(", "self", ",", "message", ",", "trigger", ")", ":", "\n", "        ", "\"\"\"Combination of `ForwardInterface.send` and\n        `BackwardInterface.backward`.\n\n        Updates the estimate of synthetic `message` based on `trigger` and\n        backpropagates synthetic gradient from `message`.\n\n        Args:\n            message: Ground truth `message` that should be synthesized based on\n                `trigger` and that synthetic gradient should be backpropagated\n                from.\n            trigger: `trigger` that the `message` should be synthesized based\n                on.\n        \"\"\"", "\n", "self", ".", "forward_interface", ".", "send", "(", "message", ",", "trigger", ")", "\n", "self", ".", "backward_interface", ".", "backward", "(", "message", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BasicSynthesizer.__init__": [[291, 330], ["super().__init__", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.Linear", "torch.nn.init.constant", "torch.nn.init.constant", "torch.nn.Linear", "torch.nn.init.constant", "range"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.locked_dropout.LockedDropout.__init__"], ["def", "__init__", "(", "self", ",", "output_dim", ",", "n_hidden", "=", "0", ",", "hidden_dim", "=", "None", ",", "\n", "trigger_dim", "=", "None", ",", "context_dim", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "hidden_dim", "is", "None", ":", "\n", "            ", "hidden_dim", "=", "output_dim", "\n", "", "if", "trigger_dim", "is", "None", ":", "\n", "            ", "trigger_dim", "=", "output_dim", "\n", "\n", "", "top_layer_dim", "=", "output_dim", "if", "n_hidden", "==", "0", "else", "hidden_dim", "\n", "\n", "self", ".", "input_trigger", "=", "torch", ".", "nn", ".", "Linear", "(", "\n", "in_features", "=", "trigger_dim", ",", "out_features", "=", "top_layer_dim", "\n", ")", "\n", "\n", "if", "context_dim", "is", "not", "None", ":", "\n", "            ", "self", ".", "input_context", "=", "torch", ".", "nn", ".", "Linear", "(", "\n", "in_features", "=", "context_dim", ",", "out_features", "=", "top_layer_dim", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "input_context", "=", "None", "\n", "\n", "", "self", ".", "layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", "[", "\n", "torch", ".", "nn", ".", "Linear", "(", "\n", "in_features", "=", "hidden_dim", ",", "\n", "out_features", "=", "(", "\n", "hidden_dim", "if", "layer_index", "<", "n_hidden", "-", "1", "else", "output_dim", "\n", ")", "\n", ")", "\n", "for", "layer_index", "in", "range", "(", "n_hidden", ")", "\n", "]", ")", "\n", "\n", "# zero-initialize the last layer, as in the paper", "\n", "if", "n_hidden", ">", "0", ":", "\n", "            ", "init", ".", "constant", "(", "self", ".", "layers", "[", "-", "1", "]", ".", "weight", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "init", ".", "constant", "(", "self", ".", "input_trigger", ".", "weight", ",", "0", ")", "\n", "if", "context_dim", "is", "not", "None", ":", "\n", "                ", "init", ".", "constant", "(", "self", ".", "input_context", ".", "weight", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BasicSynthesizer.forward": [[331, 353], ["dni.BasicSynthesizer.input_trigger", "dni.BasicSynthesizer.input_context", "layer", "torch.nn.functional.relu"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "trigger", ",", "context", ")", ":", "\n", "        ", "\"\"\"Synthesizes a `message` based on `trigger` and `context`.\n\n        Args:\n            trigger: `trigger` to synthesize the `message` based on. Size:\n                (`batch_size`, `trigger_dim`).\n            context: `context` to condition the synthesizer. Ignored if\n                `context_dim` has not been specified in the constructor. Size:\n                (`batch_size`, `context_dim`).\n\n        Returns:\n            The synthesized `message`.\n        \"\"\"", "\n", "last", "=", "self", ".", "input_trigger", "(", "trigger", ")", "\n", "\n", "if", "self", ".", "input_context", "is", "not", "None", ":", "\n", "            ", "last", "+=", "self", ".", "input_context", "(", "context", ")", "\n", "\n", "", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "last", "=", "layer", "(", "F", ".", "relu", "(", "last", ")", ")", "\n", "\n", "", "return", "last", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._Manager.reset_defer_backward": [[404, 408], ["None"], "methods", ["None"], ["@", "classmethod", "\n", "def", "reset_defer_backward", "(", "cls", ")", ":", "\n", "        ", "cls", ".", "defer_backward", "=", "False", "\n", "cls", ".", "deferred_gradients", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._Manager.backward": [[409, 418], ["dni._ones_like", "cls.deferred_gradients.append", "variable.backward"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._ones_like", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._Manager.backward"], ["", "@", "classmethod", "\n", "def", "backward", "(", "cls", ",", "variable", ",", "gradient", "=", "None", ")", ":", "\n", "        ", "if", "gradient", "is", "None", ":", "\n", "            ", "gradient", "=", "_ones_like", "(", "variable", ".", "data", ")", "\n", "\n", "", "if", "cls", ".", "defer_backward", ":", "\n", "            ", "cls", ".", "deferred_gradients", ".", "append", "(", "(", "variable", ",", "gradient", ")", ")", "\n", "", "else", ":", "\n", "            ", "variable", ".", "backward", "(", "gradient", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._Manager.get_current_context": [[419, 425], ["None"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "get_current_context", "(", "cls", ")", ":", "\n", "        ", "if", "cls", ".", "context_stack", ":", "\n", "            ", "return", "cls", ".", "context_stack", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.defer_backward": [[355, 382], ["RuntimeError", "dni._Manager.reset_defer_backward", "zip", "torch.autograd.backward"], "function", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._Manager.reset_defer_backward", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._Manager.backward"], ["", "", "@", "contextmanager", "\n", "def", "defer_backward", "(", ")", ":", "\n", "    ", "\"\"\"Defers backpropagation until the end of scope.\n\n    Accumulates all gradients passed to `dni.backward` inside the scope and\n    backpropagates them all in a single `torch.autograd.backward` call.\n\n    Use it and `dni.backward` whenever you want to backpropagate multiple times\n    through the same nodes in the computation graph, for example when mixing\n    real and synthetic gradients. Otherwise, PyTorch will complain about\n    backpropagating more than once through the same graph.\n\n    Scopes of this context manager cannot be nested.\n    \"\"\"", "\n", "if", "_Manager", ".", "defer_backward", ":", "\n", "        ", "raise", "RuntimeError", "(", "'cannot nest defer_backward'", ")", "\n", "", "_Manager", ".", "defer_backward", "=", "True", "\n", "\n", "try", ":", "\n", "        ", "yield", "\n", "\n", "if", "_Manager", ".", "deferred_gradients", ":", "\n", "            ", "(", "variables", ",", "gradients", ")", "=", "zip", "(", "*", "_Manager", ".", "deferred_gradients", ")", "\n", "torch", ".", "autograd", ".", "backward", "(", "variables", ",", "gradients", ")", "\n", "\n", "", "", "finally", ":", "\n", "        ", "_Manager", ".", "reset_defer_backward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.synthesizer_context": [[384, 396], ["_Manager.context_stack.append", "_Manager.context_stack.pop"], "function", ["None"], ["", "", "@", "contextmanager", "\n", "def", "synthesizer_context", "(", "context", ")", ":", "\n", "    ", "\"\"\"Conditions `Synthesizer` calls within the scope on the given `context`.\n\n    All `Synthesizer.forward` calls within the scope will receive `context`\n    as an argument.\n\n    Scopes of this context manager can be nested.\n    \"\"\"", "\n", "_Manager", ".", "context_stack", ".", "append", "(", "context", ")", "\n", "yield", "\n", "_Manager", ".", "context_stack", ".", "pop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._ones_like": [[445, 447], ["tensor.new().resize_().fill_", "tensor.new().resize_", "tensor.size", "tensor.new"], "function", ["None"], ["def", "_ones_like", "(", "tensor", ")", ":", "\n", "    ", "return", "tensor", ".", "new", "(", ")", ".", "resize_", "(", "tensor", ".", "size", "(", ")", ")", ".", "fill_", "(", "1", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.embed_regularize.embedded_dropout": [[5, 23], ["torch.nn.functional.embedding", "embed.weight.data.new().resize_().bernoulli_().expand_as", "scale.expand_as", "embed.weight.data.new().resize_().bernoulli_", "embed.weight.data.new().resize_", "embed.weight.data.new", "embed.weight.size"], "function", ["None"], ["def", "embedded_dropout", "(", "embed", ",", "words", ",", "dropout", "=", "0.1", ",", "scale", "=", "None", ")", ":", "\n", "  ", "if", "dropout", ":", "\n", "    ", "mask", "=", "embed", ".", "weight", ".", "data", ".", "new", "(", ")", ".", "resize_", "(", "(", "embed", ".", "weight", ".", "size", "(", "0", ")", ",", "1", ")", ")", ".", "bernoulli_", "(", "1", "-", "dropout", ")", ".", "expand_as", "(", "embed", ".", "weight", ")", "/", "(", "1", "-", "dropout", ")", "\n", "masked_embed_weight", "=", "mask", "*", "embed", ".", "weight", "\n", "", "else", ":", "\n", "    ", "masked_embed_weight", "=", "embed", ".", "weight", "\n", "", "if", "scale", ":", "\n", "    ", "masked_embed_weight", "=", "scale", ".", "expand_as", "(", "masked_embed_weight", ")", "*", "masked_embed_weight", "\n", "\n", "", "padding_idx", "=", "embed", ".", "padding_idx", "\n", "if", "padding_idx", "is", "None", ":", "\n", "      ", "padding_idx", "=", "-", "1", "\n", "\n", "", "X", "=", "torch", ".", "nn", ".", "functional", ".", "embedding", "(", "words", ",", "masked_embed_weight", ",", "\n", "padding_idx", ",", "embed", ".", "max_norm", ",", "embed", ".", "norm_type", ",", "\n", "embed", ".", "scale_grad_by_freq", ",", "embed", ".", "sparse", "\n", ")", "\n", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.weight_drop.WeightDrop.__init__": [[6, 13], ["super().__init__", "weight_drop.WeightDrop._setup"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.locked_dropout.LockedDropout.__init__", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.weight_drop.WeightDrop._setup"], ["    ", "def", "__init__", "(", "self", ",", "module", ",", "weights", ",", "dropout", "=", "0", ",", "variational", "=", "False", ")", ":", "\n", "        ", "super", "(", "WeightDrop", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "module", "=", "module", "\n", "self", ".", "weights", "=", "weights", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "variational", "=", "variational", "\n", "self", ".", "_setup", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.weight_drop.WeightDrop.widget_demagnetizer_y2k_edition": [[14, 20], ["None"], "methods", ["None"], ["", "def", "widget_demagnetizer_y2k_edition", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# We need to replace flatten_parameters with a nothing function", "\n", "# It must be a function rather than a lambda as otherwise pickling explodes", "\n", "# We can't write boring code though, so ... WIDGET DEMAGNETIZER Y2K EDITION!", "\n", "# (\u256f\u00b0\u25a1\u00b0\uff09\u256f\ufe35 \u253b\u2501\u253b", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.weight_drop.WeightDrop._setup": [[21, 31], ["issubclass", "type", "print", "getattr", "weight_drop.WeightDrop.module.register_parameter", "torch.nn.Parameter"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "# Terrible temporary solution to an issue regarding compacting weights re: CUDNN RNN", "\n", "        ", "if", "issubclass", "(", "type", "(", "self", ".", "module", ")", ",", "torch", ".", "nn", ".", "RNNBase", ")", ":", "\n", "            ", "self", ".", "module", ".", "flatten_parameters", "=", "self", ".", "widget_demagnetizer_y2k_edition", "\n", "\n", "", "for", "name_w", "in", "self", ".", "weights", ":", "\n", "            ", "print", "(", "'Applying weight drop of {} to {}'", ".", "format", "(", "self", ".", "dropout", ",", "name_w", ")", ")", "\n", "w", "=", "getattr", "(", "self", ".", "module", ",", "name_w", ")", "\n", "del", "self", ".", "module", ".", "_parameters", "[", "name_w", "]", "\n", "self", ".", "module", ".", "register_parameter", "(", "name_w", "+", "'_raw'", ",", "Parameter", "(", "w", ".", "data", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.weight_drop.WeightDrop._setweights": [[32, 44], ["getattr", "setattr", "torch.autograd.Variable", "torch.nn.functional.dropout", "torch.nn.functional.dropout", "torch.ones", "mask.cuda.cuda.cuda", "mask.cuda.cuda.expand_as", "getattr.size"], "methods", ["None"], ["", "", "def", "_setweights", "(", "self", ")", ":", "\n", "        ", "for", "name_w", "in", "self", ".", "weights", ":", "\n", "            ", "raw_w", "=", "getattr", "(", "self", ".", "module", ",", "name_w", "+", "'_raw'", ")", "\n", "w", "=", "None", "\n", "if", "self", ".", "variational", ":", "\n", "                ", "mask", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "ones", "(", "raw_w", ".", "size", "(", "0", ")", ",", "1", ")", ")", "\n", "if", "raw_w", ".", "is_cuda", ":", "mask", "=", "mask", ".", "cuda", "(", ")", "\n", "mask", "=", "torch", ".", "nn", ".", "functional", ".", "dropout", "(", "mask", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "True", ")", "\n", "w", "=", "mask", ".", "expand_as", "(", "raw_w", ")", "*", "raw_w", "\n", "", "else", ":", "\n", "                ", "w", "=", "torch", ".", "nn", ".", "functional", ".", "dropout", "(", "raw_w", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "", "setattr", "(", "self", ".", "module", ",", "name_w", ",", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.weight_drop.WeightDrop.forward": [[45, 48], ["weight_drop.WeightDrop._setweights", "weight_drop.WeightDrop.module.forward"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.weight_drop.WeightDrop._setweights", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.locked_dropout.LockedDropout.forward"], ["", "", "def", "forward", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "self", ".", "_setweights", "(", ")", "\n", "return", "self", ".", "module", ".", "forward", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.data.Dictionary.__init__": [[8, 13], ["collections.Counter"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "word2idx", "=", "{", "}", "\n", "self", ".", "idx2word", "=", "[", "]", "\n", "self", ".", "counter", "=", "Counter", "(", ")", "\n", "self", ".", "total", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.data.Dictionary.add_word": [[14, 22], ["data.Dictionary.idx2word.append", "len"], "methods", ["None"], ["", "def", "add_word", "(", "self", ",", "word", ")", ":", "\n", "        ", "if", "word", "not", "in", "self", ".", "word2idx", ":", "\n", "            ", "self", ".", "idx2word", ".", "append", "(", "word", ")", "\n", "self", ".", "word2idx", "[", "word", "]", "=", "len", "(", "self", ".", "idx2word", ")", "-", "1", "\n", "", "token_id", "=", "self", ".", "word2idx", "[", "word", "]", "\n", "self", ".", "counter", "[", "token_id", "]", "+=", "1", "\n", "self", ".", "total", "+=", "1", "\n", "return", "self", ".", "word2idx", "[", "word", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.data.Dictionary.__len__": [[23, 25], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idx2word", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.data.Corpus.__init__": [[28, 33], ["data.Dictionary", "data.Corpus.tokenize", "data.Corpus.tokenize", "data.Corpus.tokenize", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.data.Corpus.tokenize", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.data.Corpus.tokenize", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.data.Corpus.tokenize"], ["    ", "def", "__init__", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "dictionary", "=", "Dictionary", "(", ")", "\n", "self", ".", "train", "=", "self", ".", "tokenize", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ")", "\n", "self", ".", "valid", "=", "self", ".", "tokenize", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ")", "\n", "self", ".", "test", "=", "self", ".", "tokenize", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.data.Corpus.tokenize": [[34, 57], ["os.path.exists", "open", "open", "torch.LongTensor", "len", "line.split", "data.Corpus.dictionary.add_word", "line.split"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.data.Dictionary.add_word"], ["", "def", "tokenize", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"Tokenizes a text file.\"\"\"", "\n", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "# Add words to the dictionary", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "tokens", "=", "0", "\n", "for", "line", "in", "f", ":", "\n", "                ", "words", "=", "line", ".", "split", "(", ")", "+", "[", "'<eos>'", "]", "\n", "tokens", "+=", "len", "(", "words", ")", "\n", "for", "word", "in", "words", ":", "\n", "                    ", "self", ".", "dictionary", ".", "add_word", "(", "word", ")", "\n", "\n", "# Tokenize file content", "\n", "", "", "", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "ids", "=", "torch", ".", "LongTensor", "(", "tokens", ")", "\n", "token", "=", "0", "\n", "for", "line", "in", "f", ":", "\n", "                ", "words", "=", "line", ".", "split", "(", ")", "+", "[", "'<eos>'", "]", "\n", "for", "word", "in", "words", ":", "\n", "                    ", "ids", "[", "token", "]", "=", "self", ".", "dictionary", ".", "word2idx", "[", "word", "]", "\n", "token", "+=", "1", "\n", "\n", "", "", "", "return", "ids", "\n", "", "", ""]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.__init__": [[12, 65], ["torch.Module.__init__", "locked_dropout.LockedDropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Embedding", "torch.Embedding", "print", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.Linear", "torch.Linear", "model.RNNModel.init_weights", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.GRU", "torch.nn.GRU", "torch.nn.GRU", "torch.nn.GRU", "range", "weight_drop.WeightDrop", "range", "weight_drop.WeightDrop", "QRNNLayer", "weight_drop.WeightDrop", "range"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.locked_dropout.LockedDropout.__init__", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNSynthesizer.init_weights"], ["def", "__init__", "(", "self", ",", "batchsize", ",", "rnn_type", ",", "ntoken", ",", "ninp", ",", "nhid", ",", "nlayers", ",", "\n", "dropout", "=", "0.5", ",", "dropouth", "=", "0.5", ",", "dropouti", "=", "0.5", ",", "dropoute", "=", "0.1", ",", "wdrop", "=", "0", ",", "tie_weights", "=", "False", ",", "use_sg", "=", "False", ")", ":", "\n", "        ", "super", "(", "RNNModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "lockdrop", "=", "LockedDropout", "(", ")", "\n", "self", ".", "idrop", "=", "nn", ".", "Dropout", "(", "dropouti", ")", "\n", "self", ".", "hdrop", "=", "nn", ".", "Dropout", "(", "dropouth", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "encoder", "=", "nn", ".", "Embedding", "(", "ntoken", ",", "ninp", ")", "\n", "assert", "rnn_type", "in", "[", "'LSTM'", ",", "'QRNN'", ",", "'GRU'", ",", "'INDRNN'", "]", ",", "'RNN type is not supported'", "\n", "if", "rnn_type", "==", "'LSTM'", ":", "\n", "            ", "self", ".", "rnns", "=", "[", "torch", ".", "nn", ".", "LSTM", "(", "ninp", "if", "l", "==", "0", "else", "nhid", ",", "nhid", "if", "l", "!=", "nlayers", "-", "1", "else", "(", "ninp", "if", "tie_weights", "else", "nhid", ")", ",", "1", ",", "dropout", "=", "0", ")", "for", "l", "in", "range", "(", "nlayers", ")", "]", "\n", "if", "wdrop", ":", "\n", "                ", "self", ".", "rnns", "=", "[", "WeightDrop", "(", "rnn", ",", "[", "'weight_hh_l0'", "]", ",", "dropout", "=", "wdrop", ")", "for", "rnn", "in", "self", ".", "rnns", "]", "\n", "", "", "if", "rnn_type", "==", "'GRU'", ":", "\n", "            ", "self", ".", "rnns", "=", "[", "torch", ".", "nn", ".", "GRU", "(", "ninp", "if", "l", "==", "0", "else", "nhid", ",", "nhid", "if", "l", "!=", "nlayers", "-", "1", "else", "ninp", ",", "1", ",", "dropout", "=", "0", ")", "for", "l", "in", "range", "(", "nlayers", ")", "]", "\n", "if", "wdrop", ":", "\n", "                ", "self", ".", "rnns", "=", "[", "WeightDrop", "(", "rnn", ",", "[", "'weight_hh_l0'", "]", ",", "dropout", "=", "wdrop", ")", "for", "rnn", "in", "self", ".", "rnns", "]", "\n", "", "", "elif", "rnn_type", "==", "'QRNN'", ":", "\n", "            ", "from", "torchqrnn", "import", "QRNNLayer", "\n", "self", ".", "rnns", "=", "[", "QRNNLayer", "(", "input_size", "=", "ninp", "if", "l", "==", "0", "else", "nhid", ",", "hidden_size", "=", "nhid", "if", "l", "!=", "nlayers", "-", "1", "else", "(", "ninp", "if", "tie_weights", "else", "nhid", ")", ",", "save_prev_x", "=", "True", ",", "zoneout", "=", "0", ",", "window", "=", "2", "if", "l", "==", "0", "else", "1", ",", "output_gate", "=", "True", ")", "for", "l", "in", "range", "(", "nlayers", ")", "]", "\n", "for", "rnn", "in", "self", ".", "rnns", ":", "\n", "                ", "rnn", ".", "linear", "=", "WeightDrop", "(", "rnn", ".", "linear", ",", "[", "'weight'", "]", ",", "dropout", "=", "wdrop", ")", "\n", "\n", "# self.lns = [torch.nn.LayerNorm(nhid if l != nlayers - 1 else (ninp if tie_weights else nhid)) for l in range(nlayers)]", "\n", "", "", "print", "(", "self", ".", "rnns", ")", "\n", "\n", "self", ".", "rnns", "=", "torch", ".", "nn", ".", "ModuleList", "(", "self", ".", "rnns", ")", "\n", "# self.lns = torch.nn.ModuleList(self.lns)", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "nhid", ",", "ntoken", ")", "\n", "\n", "# Optionally tie weights as in:", "\n", "# \"Using the Output Embedding to Improve Language Models\" (Press & Wolf 2016)", "\n", "# https://arxiv.org/abs/1608.05859", "\n", "# and", "\n", "# \"Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling\" (Inan et al. 2016)", "\n", "# https://arxiv.org/abs/1611.01462", "\n", "if", "tie_weights", ":", "\n", "#if nhid != ninp:", "\n", "#    raise ValueError('When using the tied flag, nhid must be equal to emsize')", "\n", "            ", "self", ".", "decoder", ".", "weight", "=", "self", ".", "encoder", ".", "weight", "\n", "\n", "", "self", ".", "rnn_type", "=", "rnn_type", "\n", "self", ".", "ninp", "=", "ninp", "\n", "self", ".", "nhid", "=", "nhid", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "dropouti", "=", "dropouti", "\n", "self", ".", "dropouth", "=", "dropouth", "\n", "self", ".", "dropoute", "=", "dropoute", "\n", "self", ".", "tie_weights", "=", "tie_weights", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.reset": [[66, 68], ["r.reset"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "rnn_type", "==", "'QRNN'", ":", "[", "r", ".", "reset", "(", ")", "for", "r", "in", "self", ".", "rnns", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.init_weights": [[69, 74], ["model.RNNModel.encoder.weight.data.uniform_", "model.RNNModel.decoder.bias.data.fill_", "model.RNNModel.decoder.weight.data.uniform_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "self", ".", "encoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "decoder", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "decoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.forward": [[75, 114], ["embed_regularize.embedded_dropout", "model.RNNModel.lockdrop", "enumerate", "model.RNNModel.lockdrop", "outputs.append", "model.RNNModel.reshape", "model.RNNModel.join_hidden", "backward_interface.make_trigger", "model.RNNModel.split_hidden", "rnn", "model.RNNModel.append", "raw_outputs.append", "model.RNNModel.join_hidden", "model.RNNModel.backward", "model.RNNModel.split_hidden", "model.RNNModel.size", "model.RNNModel.lockdrop", "outputs.append", "model.RNNModel.size", "model.RNNModel.size", "backward_interface.receive"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.embed_regularize.embedded_dropout", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.join_hidden", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BackwardInterface.make_trigger", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.split_hidden", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.join_hidden", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni._Manager.backward", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.split_hidden", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.dni.BidirectionalInterface.receive"], ["", "def", "forward", "(", "self", ",", "input", ",", "hidden", ",", "return_h", "=", "False", ",", "use_sg", "=", "False", ",", "backward_interface", "=", "None", ")", ":", "\n", "        ", "emb", "=", "embedded_dropout", "(", "self", ".", "encoder", ",", "input", ",", "dropout", "=", "self", ".", "dropoute", "if", "self", ".", "training", "else", "0", ")", "\n", "#emb = self.idrop(emb)", "\n", "\n", "emb", "=", "self", ".", "lockdrop", "(", "emb", ",", "self", ".", "dropouti", ")", "\n", "\n", "raw_output", "=", "emb", "\n", "new_hidden", "=", "[", "]", "\n", "\n", "raw_outputs", "=", "[", "]", "\n", "outputs", "=", "[", "]", "\n", "\n", "if", "backward_interface", ":", "\n", "            ", "hidden", "=", "self", ".", "join_hidden", "(", "hidden", ")", "\n", "hidden", "=", "backward_interface", ".", "make_trigger", "(", "hidden", ")", "\n", "hidden", "=", "self", ".", "split_hidden", "(", "hidden", ")", "\n", "\n", "", "for", "l", ",", "rnn", "in", "enumerate", "(", "self", ".", "rnns", ")", ":", "\n", "            ", "raw_output", ",", "new_h", "=", "rnn", "(", "raw_output", ",", "hidden", "[", "l", "]", ")", "\n", "\n", "new_hidden", ".", "append", "(", "new_h", ")", "\n", "raw_outputs", ".", "append", "(", "raw_output", ")", "\n", "if", "l", "!=", "self", ".", "nlayers", "-", "1", ":", "\n", "#self.hdrop(raw_output)", "\n", "                ", "raw_output", "=", "self", ".", "lockdrop", "(", "raw_output", ",", "self", ".", "dropouth", ")", "\n", "outputs", ".", "append", "(", "raw_output", ")", "\n", "\n", "", "", "if", "backward_interface", "and", "use_sg", "and", "self", ".", "training", ":", "\n", "            ", "new_hidden", "=", "self", ".", "join_hidden", "(", "new_hidden", ")", "\n", "new_hidden", ".", "backward", "(", "backward_interface", ".", "receive", "(", "new_hidden", ")", ".", "data", "*", "0.1", ",", "retain_graph", "=", "True", ")", "\n", "new_hidden", "=", "self", ".", "split_hidden", "(", "new_hidden", ")", "\n", "", "hidden", "=", "new_hidden", "\n", "output", "=", "self", ".", "lockdrop", "(", "raw_output", ",", "self", ".", "dropout", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "\n", "result", "=", "output", ".", "reshape", "(", "output", ".", "size", "(", "0", ")", "*", "output", ".", "size", "(", "1", ")", ",", "output", ".", "size", "(", "2", ")", ")", "\n", "if", "return_h", ":", "\n", "            ", "return", "result", ",", "hidden", ",", "raw_outputs", ",", "outputs", "\n", "", "return", "result", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.init_hidden": [[115, 124], ["next", "model.RNNModel.parameters", "weight.new().zero_", "weight.new().zero_", "range", "weight.new().zero_", "range", "weight.new", "weight.new", "weight.new"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "weight", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "data", "\n", "if", "self", ".", "rnn_type", "==", "'LSTM'", ":", "\n", "            ", "return", "[", "(", "weight", ".", "new", "(", "1", ",", "bsz", ",", "self", ".", "nhid", "if", "l", "!=", "self", ".", "nlayers", "-", "1", "else", "(", "self", ".", "ninp", "if", "self", ".", "tie_weights", "else", "self", ".", "nhid", ")", ")", ".", "zero_", "(", ")", ",", "\n", "weight", ".", "new", "(", "1", ",", "bsz", ",", "self", ".", "nhid", "if", "l", "!=", "self", ".", "nlayers", "-", "1", "else", "(", "self", ".", "ninp", "if", "self", ".", "tie_weights", "else", "self", ".", "nhid", ")", ")", ".", "zero_", "(", ")", ")", "\n", "for", "l", "in", "range", "(", "self", ".", "nlayers", ")", "]", "\n", "", "elif", "self", ".", "rnn_type", "==", "'QRNN'", "or", "self", ".", "rnn_type", "==", "'GRU'", "or", "self", ".", "rnn_type", "==", "'INDRNN'", ":", "\n", "            ", "return", "[", "weight", ".", "new", "(", "1", ",", "bsz", ",", "self", ".", "nhid", "if", "l", "!=", "self", ".", "nlayers", "-", "1", "else", "(", "self", ".", "ninp", "if", "self", ".", "tie_weights", "else", "self", ".", "nhid", ")", ")", ".", "zero_", "(", ")", "\n", "for", "l", "in", "range", "(", "self", ".", "nlayers", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.join_hidden": [[125, 130], ["isinstance", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.RNNModel.join_hidden", "model.RNNModel.join_hidden"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.join_hidden", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.join_hidden"], ["", "", "def", "join_hidden", "(", "self", ",", "hidden", ")", ":", "\n", "        ", "if", "isinstance", "(", "hidden", "[", "0", "]", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "hidden", ",", "dim", "=", "2", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "join_hidden", "(", "[", "self", ".", "join_hidden", "(", "h", ")", "for", "h", "in", "hidden", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.split_hidden": [[131, 144], ["torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "h.contiguous", "h.contiguous", "range", "range", "range"], "methods", ["None"], ["", "", "def", "split_hidden", "(", "self", ",", "hidden", ")", ":", "\n", "        ", "if", "self", ".", "rnn_type", "==", "\"LSTM\"", ":", "\n", "            ", "hidden", "=", "torch", ".", "split", "(", "hidden", ",", "\n", "split_size_or_sections", "=", "[", "(", "self", ".", "nhid", "if", "l", "<", "(", "self", ".", "nlayers", "-", "1", ")", "*", "2", "else", "(", "self", ".", "ninp", "if", "self", ".", "tie_weights", "else", "self", ".", "nhid", ")", ")", "for", "l", "in", "range", "(", "self", ".", "nlayers", "*", "2", ")", "]", ",", "\n", "dim", "=", "2", ")", "\n", "hidden", "=", "[", "h", ".", "contiguous", "(", ")", "for", "h", "in", "hidden", "]", "\n", "hidden", "=", "[", "(", "hidden", "[", "l", "]", ",", "hidden", "[", "l", "+", "1", "]", ")", "for", "l", "in", "range", "(", "0", ",", "self", ".", "nlayers", "*", "2", ",", "2", ")", "]", "\n", "", "else", ":", "\n", "            ", "hidden", "=", "torch", ".", "split", "(", "hidden", ",", "\n", "split_size_or_sections", "=", "[", "self", ".", "nhid", "if", "l", "!=", "self", ".", "nlayers", "-", "1", "else", "(", "self", ".", "ninp", "if", "self", ".", "tie_weights", "else", "self", ".", "nhid", ")", "for", "l", "in", "range", "(", "self", ".", "nlayers", ")", "]", ",", "\n", "dim", "=", "2", ")", "\n", "hidden", "=", "[", "h", ".", "contiguous", "(", ")", "for", "h", "in", "hidden", "]", "\n", "", "return", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNSynthesizer.__init__": [[146, 169], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "print", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "model.RNNSynthesizer.init_weights", "model.RNNSynthesizer.reset_states", "torch.nn.GRU", "torch.nn.GRU", "torch.nn.GRU", "torch.nn.GRU", "range", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "range", "QRNNLayer", "range"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.locked_dropout.LockedDropout.__init__", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNSynthesizer.init_weights", "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNSynthesizer.reset_states"], ["    ", "def", "__init__", "(", "self", ",", "sgtype", "=", "\"GRU\"", ",", "nhid", "=", "50", ",", "nlayers", "=", "2", ",", "input_features", "=", "1", ",", "sg_dropout", "=", "0.", ")", ":", "\n", "        ", "super", "(", "RNNSynthesizer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "nn", ".", "Linear", "(", "in_features", "=", "input_features", ",", "out_features", "=", "nhid", ")", "\n", "\n", "if", "sgtype", "==", "\"GRU\"", ":", "\n", "            ", "self", ".", "rnns", "=", "[", "torch", ".", "nn", ".", "GRU", "(", "nhid", ",", "nhid", ",", "dropout", "=", "0.", ",", "batch_first", "=", "True", ")", "for", "l", "in", "range", "(", "nlayers", ")", "]", "\n", "", "elif", "sgtype", "==", "\"LSTM\"", ":", "\n", "            ", "self", ".", "rnns", "=", "[", "torch", ".", "nn", ".", "LSTM", "(", "nhid", ",", "nhid", ",", "dropout", "=", "0.", ",", "batch_first", "=", "True", ")", "for", "l", "in", "range", "(", "nlayers", ")", "]", "\n", "", "elif", "sgtype", "==", "'QRNN'", ":", "\n", "            ", "from", "torchqrnn", "import", "QRNNLayer", "\n", "self", ".", "rnns", "=", "[", "QRNNLayer", "(", "nhid", ",", "nhid", ",", "save_prev_x", "=", "True", ",", "zoneout", "=", "0.1", ",", "window", "=", "2", "if", "l", "==", "0", "else", "1", ",", "output_gate", "=", "True", ",", "use_cuda", "=", "True", ")", "for", "l", "in", "range", "(", "nlayers", ")", "]", "\n", "\n", "", "self", ".", "rnns", "=", "torch", ".", "nn", ".", "ModuleList", "(", "self", ".", "rnns", ")", "\n", "print", "(", "self", ".", "rnns", ")", "\n", "self", ".", "sgtype", "=", "sgtype", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "nhid", ",", "input_features", ")", "\n", "self", ".", "nhid", "=", "nhid", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "sg_dropout", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "reset_states", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNSynthesizer.init_weights": [[170, 179], ["model.RNNSynthesizer.encoder.bias.data.fill_", "model.RNNSynthesizer.decoder.bias.data.fill_", "model.RNNSynthesizer.encoder.weight.data.uniform_", "model.RNNSynthesizer.decoder.weight.data.uniform_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "decoder", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "encoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "self", ".", "decoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "if", "self", ".", "sgtype", "!=", "'QRNN'", ":", "\n", "            ", "for", "rnn", "in", "self", ".", "rnns", ":", "\n", "                ", "torch", ".", "nn", ".", "init", ".", "orthogonal_", "(", "rnn", ".", "weight_ih_l0", ".", "data", ")", "\n", "torch", ".", "nn", ".", "init", ".", "orthogonal_", "(", "rnn", ".", "weight_hh_l0", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNSynthesizer.forward": [[180, 199], ["trigger.reshape", "model.RNNSynthesizer.encoder", "enumerate", "model.RNNSynthesizer.repackage_hidden", "model.RNNSynthesizer.decoder", "model.RNNSynthesizer.reshape", "rnn", "new_hidden.append", "torch.ones_like().normal_", "torch.ones_like().normal_", "torch.ones_like().normal_", "torch.ones_like().normal_", "model.RNNSynthesizer.dropout", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.utils.repackage_hidden"], ["", "", "", "def", "forward", "(", "self", ",", "trigger", ",", "context", "=", "None", ")", ":", "\n", "        ", "data", "=", "trigger", ".", "reshape", "(", "-", "1", ",", "1", ",", "1", ")", "\n", "data", "=", "self", ".", "encoder", "(", "data", "*", "torch", ".", "ones_like", "(", "data", ")", ".", "normal_", "(", "mean", "=", "1", ",", "std", "=", "0.5", ")", ")", "\n", "\n", "raw_output", "=", "data", "\n", "new_hidden", "=", "[", "]", "\n", "\n", "for", "l", ",", "rnn", "in", "enumerate", "(", "self", ".", "rnns", ")", ":", "\n", "            ", "raw_output", ",", "new_h", "=", "rnn", "(", "raw_output", ",", "self", ".", "states", "[", "l", "]", ")", "\n", "if", "l", "!=", "self", ".", "nlayers", "-", "1", ":", "\n", "                ", "raw_output", "=", "self", ".", "dropout", "(", "raw_output", ")", "\n", "", "new_hidden", ".", "append", "(", "new_h", ")", "\n", "", "self", ".", "states", "=", "self", ".", "repackage_hidden", "(", "new_hidden", ")", "\n", "\n", "raw_output", "=", "self", ".", "decoder", "(", "raw_output", ")", "\n", "\n", "result", "=", "raw_output", ".", "reshape", "(", "trigger", ".", "shape", ")", "\n", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNSynthesizer.reset_states": [[200, 203], ["r.reset"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNModel.reset"], ["", "def", "reset_states", "(", "self", ")", ":", "\n", "        ", "self", ".", "states", "=", "[", "None", "]", "*", "self", ".", "nlayers", "\n", "if", "self", ".", "sgtype", "==", "'QRNN'", ":", "[", "r", ".", "reset", "(", ")", "for", "r", "in", "self", ".", "rnns", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.model.RNNSynthesizer.repackage_hidden": [[204, 211], ["isinstance", "h.detach", "tuple", "model.RNNSynthesizer.repackage_hidden"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.utils.repackage_hidden"], ["", "def", "repackage_hidden", "(", "self", ",", "h", ")", ":", "\n", "        ", "\"\"\"Wraps hidden states in new Tensors,\n        to detach them from their history.\"\"\"", "\n", "if", "isinstance", "(", "h", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "h", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "tuple", "(", "self", ".", "repackage_hidden", "(", "v", ")", "for", "v", "in", "h", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.locked_dropout.LockedDropout.__init__": [[6, 8], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.locked_dropout.LockedDropout.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.locked_dropout.LockedDropout.forward": [[9, 16], ["x.data.new().bernoulli_", "mask.expand_as.expand_as.expand_as", "torch.autograd.Variable", "torch.autograd.Variable", "x.data.new", "x.size", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "dropout", "=", "0.5", ")", ":", "\n", "        ", "if", "not", "self", ".", "training", "or", "not", "dropout", ":", "\n", "            ", "return", "x", "\n", "", "m", "=", "x", ".", "data", ".", "new", "(", "1", ",", "x", ".", "size", "(", "1", ")", ",", "x", ".", "size", "(", "2", ")", ")", ".", "bernoulli_", "(", "1", "-", "dropout", ")", "\n", "mask", "=", "Variable", "(", "m", ",", "requires_grad", "=", "False", ")", "/", "(", "1", "-", "dropout", ")", "\n", "mask", "=", "mask", ".", "expand_as", "(", "x", ")", "\n", "return", "mask", "*", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.utils.repackage_hidden": [[4, 11], ["isinstance", "h.detach", "tuple", "utils.repackage_hidden"], "function", ["home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.utils.repackage_hidden"], ["def", "repackage_hidden", "(", "h", ")", ":", "\n", "    ", "\"\"\"Wraps hidden states in new Tensors,\n    to detach them from their history.\"\"\"", "\n", "if", "isinstance", "(", "h", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "h", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "tuple", "(", "repackage_hidden", "(", "v", ")", "for", "v", "in", "h", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.utils.batchify": [[13, 23], ["data.cuda.narrow", "data.cuda.view().t().contiguous", "data.cuda.size", "data.cuda.cuda", "data.cuda.view().t", "data.cuda.view"], "function", ["None"], ["", "", "def", "batchify", "(", "data", ",", "bsz", ",", "args", ")", ":", "\n", "# Work out how cleanly we can divide the dataset into bsz parts.", "\n", "    ", "nbatch", "=", "data", ".", "size", "(", "0", ")", "//", "bsz", "\n", "# Trim off any extra elements that wouldn't cleanly fit (remainders).", "\n", "data", "=", "data", ".", "narrow", "(", "0", ",", "0", ",", "nbatch", "*", "bsz", ")", "\n", "# Evenly divide the data across the bsz batches.", "\n", "data", "=", "data", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", "\n", "if", "args", ".", "cuda", ":", "\n", "        ", "data", "=", "data", ".", "cuda", "(", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.parap1uie-s_alternate_sg.None.utils.get_batch": [[25, 30], ["min", "source[].view", "len"], "function", ["None"], ["", "def", "get_batch", "(", "source", ",", "i", ",", "args", ",", "seq_len", "=", "None", ",", "evaluation", "=", "False", ")", ":", "\n", "    ", "seq_len", "=", "min", "(", "seq_len", "if", "seq_len", "else", "args", ".", "bptt", ",", "len", "(", "source", ")", "-", "1", "-", "i", ")", "\n", "data", "=", "source", "[", "i", ":", "i", "+", "seq_len", "]", "\n", "target", "=", "source", "[", "i", "+", "1", ":", "i", "+", "1", "+", "seq_len", "]", ".", "view", "(", "-", "1", ")", "\n", "return", "data", ",", "target", "\n", "", ""]]}