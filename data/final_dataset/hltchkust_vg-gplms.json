{"home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.set_random_seed": [[11, 17], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed"], "function", ["None"], ["def", "set_random_seed", "(", "random_seed", ")", ":", "\n", "    ", "random", ".", "seed", "(", "random_seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "random_seed", ")", "\n", "torch", ".", "manual_seed", "(", "random_seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "random_seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.save": [[18, 28], ["os.path.dirname", "open", "pickle.dump", "open.close", "os.path.exists", "os.makedirs"], "function", ["None"], ["", "def", "save", "(", "toBeSaved", ",", "filename", ",", "mode", "=", "'wb'", ")", ":", "\n", "    ", "'''\n    save data to pickle file\n    '''", "\n", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirname", ")", "\n", "", "file", "=", "open", "(", "filename", ",", "mode", ")", "\n", "pickle", ".", "dump", "(", "toBeSaved", ",", "file", ",", "protocol", "=", "4", ")", "# protocol 4 allows large size object, it's the default since python 3.8", "\n", "file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.load": [[29, 37], ["open", "pickle.load", "open.close"], "function", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.load"], ["", "def", "load", "(", "filename", ",", "mode", "=", "'rb'", ")", ":", "\n", "    ", "'''\n    load pickle file\n    '''", "\n", "file", "=", "open", "(", "filename", ",", "mode", ")", "\n", "loaded", "=", "pickle", ".", "load", "(", "file", ")", "\n", "file", ".", "close", "(", ")", "\n", "return", "loaded", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.pad_sents": [[38, 53], ["utils.get_lens", "min", "enumerate", "max", "new_len.append", "sents_padded.append"], "function", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.get_lens"], ["", "def", "pad_sents", "(", "sents", ",", "pad_token", "=", "0", ",", "max_len", "=", "512", ")", ":", "\n", "    ", "'''\n    pad input to max length\n    '''", "\n", "sents_padded", "=", "[", "]", "\n", "lens", "=", "get_lens", "(", "sents", ")", "\n", "max_len", "=", "min", "(", "max", "(", "lens", ")", ",", "max_len", ")", "\n", "sents_padded", "=", "[", "]", "\n", "new_len", "=", "[", "]", "\n", "for", "i", ",", "l", "in", "enumerate", "(", "lens", ")", ":", "\n", "        ", "if", "l", ">", "max_len", ":", "\n", "            ", "l", "=", "max_len", "\n", "", "new_len", ".", "append", "(", "l", ")", "\n", "sents_padded", ".", "append", "(", "sents", "[", "i", "]", "[", ":", "l", "]", "+", "[", "pad_token", "]", "*", "(", "max_len", "-", "l", ")", ")", "\n", "", "return", "sents_padded", ",", "new_len", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.get_mask": [[54, 66], ["utils.get_lens", "min", "max", "mask.append"], "function", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.get_lens"], ["", "def", "get_mask", "(", "sents", ",", "unmask_idx", "=", "1", ",", "mask_idx", "=", "0", ",", "max_len", "=", "512", ")", ":", "\n", "    ", "'''\n    make mask for padded input\n    '''", "\n", "lens", "=", "get_lens", "(", "sents", ")", "\n", "max_len", "=", "min", "(", "max", "(", "lens", ")", ",", "max_len", ")", "\n", "mask", "=", "[", "]", "\n", "for", "l", "in", "lens", ":", "\n", "        ", "if", "l", ">", "max_len", ":", "\n", "            ", "l", "=", "max_len", "\n", "", "mask", ".", "append", "(", "[", "unmask_idx", "]", "*", "l", "+", "[", "mask_idx", "]", "*", "(", "max_len", "-", "l", ")", ")", "\n", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.get_lens": [[68, 70], ["len"], "function", ["None"], ["", "def", "get_lens", "(", "sents", ")", ":", "\n", "    ", "return", "[", "len", "(", "sent", ")", "for", "sent", "in", "sents", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.get_max_len": [[71, 74], ["max", "len"], "function", ["None"], ["", "def", "get_max_len", "(", "sents", ")", ":", "\n", "    ", "max_len", "=", "max", "(", "[", "len", "(", "sent", ")", "for", "sent", "in", "sents", "]", ")", "\n", "return", "max_len", "", "", ""]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.tools.python_rouge.calculate_rouge": [[10, 24], ["range", "print", "print", "print", "len", "rouge.rouge_n_sentence_level", "rouge1.append", "rouge.rouge_n_sentence_level", "rouge2.append", "rouge.rouge_l_sentence_level", "rougel.append", "numpy.mean", "numpy.mean", "numpy.mean"], "function", ["None"], ["def", "calculate_rouge", "(", "summary_sentences", ",", "reference_sentences", ")", ":", "\n", "    ", "rouge1", "=", "[", "]", "\n", "rouge2", "=", "[", "]", "\n", "rougel", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "reference_sentences", ")", ")", ":", "\n", "        ", "score", "=", "rouge_n_sentence_level", "(", "summary_sentences", "[", "i", "]", ",", "reference_sentences", "[", "i", "]", ",", "1", ")", "\n", "rouge1", ".", "append", "(", "score", ".", "f1_measure", ")", "\n", "_", ",", "_", ",", "rouge_2", "=", "rouge_n_sentence_level", "(", "summary_sentences", "[", "i", "]", ",", "reference_sentences", "[", "i", "]", ",", "2", ")", "\n", "rouge2", ".", "append", "(", "rouge_2", ")", "\n", "_", ",", "_", ",", "rouge_l", "=", "rouge_l_sentence_level", "(", "summary_sentences", "[", "i", "]", ",", "reference_sentences", "[", "i", "]", ")", "\n", "rougel", ".", "append", "(", "rouge_l", ")", "\n", "", "print", "(", "np", ".", "mean", "(", "rouge1", ")", ")", "\n", "print", "(", "np", ".", "mean", "(", "rouge2", ")", ")", "\n", "print", "(", "np", ".", "mean", "(", "rougel", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.tools.cal_rouge.process": [[15, 47], ["len", "time.strftime", "time.localtime", "os.path.isdir", "os.mkdir", "os.mkdir", "os.mkdir", "range", "my_pyrouge.Rouge155", "my_pyrouge.Rouge155.convert_and_evaluate", "my_pyrouge.Rouge155.output_to_dict", "os.path.isdir", "shutil.rmtree", "len", "open", "f.write", "open", "f.write"], "function", ["None"], ["def", "process", "(", "data", ")", ":", "\n", "    ", "candidates", ",", "references", ",", "pool_id", "=", "data", "\n", "cnt", "=", "len", "(", "candidates", ")", "\n", "current_time", "=", "time", ".", "strftime", "(", "'%Y-%m-%d-%H-%M-%S'", ",", "time", ".", "localtime", "(", ")", ")", "\n", "tmp_dir", "=", "\"rouge-tmp-{}-{}\"", ".", "format", "(", "current_time", ",", "pool_id", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "tmp_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "tmp_dir", ")", "\n", "os", ".", "mkdir", "(", "tmp_dir", "+", "\"/candidate\"", ")", "\n", "os", ".", "mkdir", "(", "tmp_dir", "+", "\"/reference\"", ")", "\n", "", "try", ":", "\n", "        ", "for", "i", "in", "range", "(", "cnt", ")", ":", "\n", "            ", "if", "len", "(", "references", "[", "i", "]", ")", "<", "1", ":", "\n", "                ", "continue", "\n", "", "with", "open", "(", "tmp_dir", "+", "\"/candidate/cand.{}.txt\"", ".", "format", "(", "i", ")", ",", "\"w\"", ",", "\n", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "candidates", "[", "i", "]", ")", "\n", "", "with", "open", "(", "tmp_dir", "+", "\"/reference/ref.{}.txt\"", ".", "format", "(", "i", ")", ",", "\"w\"", ",", "\n", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "references", "[", "i", "]", ")", "\n", "", "", "r", "=", "Rouge155", "(", ")", "\n", "r", ".", "model_dir", "=", "tmp_dir", "+", "\"/reference/\"", "\n", "r", ".", "system_dir", "=", "tmp_dir", "+", "\"/candidate/\"", "\n", "r", ".", "model_filename_pattern", "=", "'ref.#ID#.txt'", "\n", "r", ".", "system_filename_pattern", "=", "r'cand.(\\d+).txt'", "\n", "rouge_results", "=", "r", ".", "convert_and_evaluate", "(", ")", "\n", "# print(rouge_results)", "\n", "results_dict", "=", "r", ".", "output_to_dict", "(", "rouge_results", ")", "\n", "", "finally", ":", "\n", "        ", "pass", "\n", "if", "os", ".", "path", ".", "isdir", "(", "tmp_dir", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "tmp_dir", ")", "\n", "", "", "return", "results_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.tools.cal_rouge.chunks": [[51, 55], ["range", "len"], "function", ["None"], ["", "def", "chunks", "(", "l", ",", "n", ")", ":", "\n", "    ", "\"\"\"Yield successive n-sized chunks from l.\"\"\"", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "l", ")", ",", "n", ")", ":", "\n", "        ", "yield", "l", "[", "i", ":", "i", "+", "n", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.tools.cal_rouge.test_rouge": [[56, 84], ["list", "list", "len", "range", "multiprocessing.Pool", "multiprocessing.Pool.map", "enumerate", "line.strip", "line.strip", "len", "len", "cal_rouge.chunks", "cal_rouge.chunks", "arg_lst.append", "int", "int", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.tools.cal_rouge.chunks", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.tools.cal_rouge.chunks"], ["", "", "def", "test_rouge", "(", "cand", ",", "ref", ",", "num_processes", ")", ":", "\n", "    ", "\"\"\"Calculate ROUGE scores of sequences passed as an iterator\n       e.g. a list of str, an open file, StringIO or even sys.stdin\n    \"\"\"", "\n", "candidates", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "cand", "]", "\n", "references", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "ref", "]", "\n", "\n", "# print(len(candidates))", "\n", "# print(len(references))", "\n", "assert", "len", "(", "candidates", ")", "==", "len", "(", "references", ")", "\n", "candidates_chunks", "=", "list", "(", "chunks", "(", "candidates", ",", "int", "(", "len", "(", "candidates", ")", "/", "num_processes", ")", ")", ")", "\n", "references_chunks", "=", "list", "(", "chunks", "(", "references", ",", "int", "(", "len", "(", "references", ")", "/", "num_processes", ")", ")", ")", "\n", "n_pool", "=", "len", "(", "candidates_chunks", ")", "\n", "arg_lst", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_pool", ")", ":", "\n", "        ", "arg_lst", ".", "append", "(", "(", "candidates_chunks", "[", "i", "]", ",", "references_chunks", "[", "i", "]", ",", "i", ")", ")", "\n", "", "pool", "=", "Pool", "(", "n_pool", ")", "\n", "results", "=", "pool", ".", "map", "(", "process", ",", "arg_lst", ")", "\n", "final_results", "=", "{", "}", "\n", "for", "i", ",", "r", "in", "enumerate", "(", "results", ")", ":", "\n", "        ", "for", "k", "in", "r", ":", "\n", "            ", "if", "(", "k", "not", "in", "final_results", ")", ":", "\n", "                ", "final_results", "[", "k", "]", "=", "r", "[", "k", "]", "*", "len", "(", "candidates_chunks", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "final_results", "[", "k", "]", "+=", "r", "[", "k", "]", "*", "len", "(", "candidates_chunks", "[", "i", "]", ")", "\n", "", "", "", "for", "k", "in", "final_results", ":", "\n", "        ", "final_results", "[", "k", "]", "=", "final_results", "[", "k", "]", "/", "len", "(", "candidates", ")", "\n", "", "return", "final_results", "\n", "", "def", "rouge_results_to_str", "(", "results_dict", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.tools.cal_rouge.rouge_results_to_str": [[84, 100], ["None"], "function", ["None"], ["", "def", "rouge_results_to_str", "(", "results_dict", ")", ":", "\n", "    ", "return", "\">> ROUGE-F(1/2/l): {:.2f}/{:.2f}/{:.2f}\\nROUGE-R(1/2/l): {:.2f}/{:.2f}/{:.2f}\\nROUGE-P(1/2/l): {:.2f}/{:.2f}/{:.2f}\\n\"", ".", "format", "(", "\n", "results_dict", "[", "\"rouge_1_f_score\"", "]", "*", "100", ",", "\n", "results_dict", "[", "\"rouge_2_f_score\"", "]", "*", "100", ",", "\n", "# results_dict[\"rouge_3_f_score\"] * 100,", "\n", "results_dict", "[", "\"rouge_l_f_score\"", "]", "*", "100", ",", "\n", "\n", "results_dict", "[", "\"rouge_1_recall\"", "]", "*", "100", ",", "\n", "results_dict", "[", "\"rouge_2_recall\"", "]", "*", "100", ",", "\n", "# results_dict[\"rouge_3_f_score\"] * 100,", "\n", "results_dict", "[", "\"rouge_l_recall\"", "]", "*", "100", ",", "\n", "\n", "results_dict", "[", "\"rouge_1_precision\"", "]", "*", "100", ",", "\n", "results_dict", "[", "\"rouge_2_precision\"", "]", "*", "100", ",", "\n", "# results_dict[\"rouge_3_f_score\"] * 100,", "\n", "results_dict", "[", "\"rouge_l_precision\"", "]", "*", "100", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartLearnedPositionalEmbedding.__init__": [[112, 118], ["torch.nn.Embedding.__init__"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["def", "__init__", "(", "self", ",", "num_embeddings", ":", "int", ",", "embedding_dim", ":", "int", ",", "padding_idx", ":", "int", ")", ":", "\n", "        ", "assert", "padding_idx", "is", "not", "None", ",", "\"`padding_idx` should not be None, but of type int\"", "\n", "# Bart is set up so that if padding_idx is specified then offset the embedding ids by 2", "\n", "# and adjust num_embeddings appropriately. Other models dont have this hack", "\n", "self", ".", "offset", "=", "2", "\n", "super", "(", ")", ".", "__init__", "(", "num_embeddings", "+", "self", ".", "offset", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartLearnedPositionalEmbedding.forward": [[119, 126], ["torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "super().forward"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.img_transformer.PositionalEncoding.forward"], ["", "def", "forward", "(", "self", ",", "input_ids_shape", ":", "torch", ".", "Size", ",", "past_key_values_length", ":", "int", "=", "0", ")", ":", "\n", "        ", "\"\"\"`input_ids_shape` is expected to be [bsz x seqlen].\"\"\"", "\n", "bsz", ",", "seq_len", "=", "input_ids_shape", "[", ":", "2", "]", "\n", "positions", "=", "torch", ".", "arange", "(", "\n", "past_key_values_length", ",", "past_key_values_length", "+", "seq_len", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "weight", ".", "device", "\n", ")", "\n", "return", "super", "(", ")", ".", "forward", "(", "positions", "+", "self", ".", "offset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartAttention.__init__": [[131, 154], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embed_dim", ":", "int", ",", "\n", "num_heads", ":", "int", ",", "\n", "dropout", ":", "float", "=", "0.0", ",", "\n", "is_decoder", ":", "bool", "=", "False", ",", "\n", "bias", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "(", "\n", "self", ".", "head_dim", "*", "num_heads", "==", "self", ".", "embed_dim", "\n", ")", ",", "f\"embed_dim must be divisible by num_heads (got `embed_dim`: {self.embed_dim} and `num_heads`: {num_heads}).\"", "\n", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "self", ".", "is_decoder", "=", "is_decoder", "\n", "\n", "self", ".", "k_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "bias", ")", "\n", "self", ".", "v_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "bias", ")", "\n", "self", ".", "q_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "bias", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartAttention._shape": [[155, 157], ["tensor.view().transpose().contiguous", "tensor.view().transpose", "tensor.view"], "methods", ["None"], ["", "def", "_shape", "(", "self", ",", "tensor", ":", "torch", ".", "Tensor", ",", "seq_len", ":", "int", ",", "bsz", ":", "int", ")", ":", "\n", "        ", "return", "tensor", ".", "view", "(", "bsz", ",", "seq_len", ",", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartAttention.forward": [[158, 268], ["hidden_states.size", "modeling_bart.BartAttention._shape().view", "modeling_bart.BartAttention.view", "modeling_bart.BartAttention.view", "modeling_bart.BartAttention.size", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.softmax", "torch.dropout", "torch.dropout", "torch.dropout", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "modeling_bart.BartAttention.view().transpose().reshape", "modeling_bart.BartAttention.out_proj", "modeling_bart.BartAttention.q_proj", "modeling_bart.BartAttention.transpose", "attn_weights.view.view.size", "attn_weights.view.view.view", "attn_weights.view.view.view", "attn_weights.view.view.view", "attn_weights_reshaped.view.view.view", "modeling_bart.BartAttention.size", "modeling_bart.BartAttention._shape", "modeling_bart.BartAttention._shape", "modeling_bart.BartAttention._shape", "attn_weights.view.view.size", "attention_mask.size", "attn_weights.view.view.view", "layer_head_mask.size", "layer_head_mask.view", "attn_weights.view.view.view", "modeling_bart.BartAttention.size", "modeling_bart.BartAttention.view().transpose", "modeling_bart.BartAttention.k_proj", "modeling_bart.BartAttention.v_proj", "modeling_bart.BartAttention._shape", "modeling_bart.BartAttention._shape", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_bart.BartAttention._shape", "modeling_bart.BartAttention._shape", "attention_mask.size", "layer_head_mask.size", "modeling_bart.BartAttention.k_proj", "modeling_bart.BartAttention.v_proj", "modeling_bart.BartAttention.k_proj", "modeling_bart.BartAttention.v_proj", "modeling_bart.BartAttention.view"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartAttention._shape", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartAttention._shape", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartAttention._shape", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartAttention._shape", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartAttention._shape", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartAttention._shape", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartAttention._shape"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ":", "torch", ".", "Tensor", ",", "\n", "key_value_states", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "past_key_value", ":", "Optional", "[", "Tuple", "[", "torch", ".", "Tensor", "]", "]", "=", "None", ",", "\n", "attention_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "layer_head_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "output_attentions", ":", "bool", "=", "False", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "Optional", "[", "torch", ".", "Tensor", "]", ",", "Optional", "[", "Tuple", "[", "torch", ".", "Tensor", "]", "]", "]", ":", "\n", "        ", "\"\"\"Input shape: Batch x Time x Channel\"\"\"", "\n", "\n", "# if key_value_states are provided this layer is used as a cross-attention layer", "\n", "# for the decoder", "\n", "is_cross_attention", "=", "key_value_states", "is", "not", "None", "\n", "bsz", ",", "tgt_len", ",", "embed_dim", "=", "hidden_states", ".", "size", "(", ")", "\n", "\n", "# get query proj", "\n", "query_states", "=", "self", ".", "q_proj", "(", "hidden_states", ")", "*", "self", ".", "scaling", "\n", "# get key, value proj", "\n", "if", "is_cross_attention", "and", "past_key_value", "is", "not", "None", ":", "\n", "# reuse k,v, cross_attentions", "\n", "            ", "key_states", "=", "past_key_value", "[", "0", "]", "\n", "value_states", "=", "past_key_value", "[", "1", "]", "\n", "", "elif", "is_cross_attention", ":", "\n", "# cross_attentions", "\n", "            ", "key_states", "=", "self", ".", "_shape", "(", "self", ".", "k_proj", "(", "key_value_states", ")", ",", "-", "1", ",", "bsz", ")", "\n", "value_states", "=", "self", ".", "_shape", "(", "self", ".", "v_proj", "(", "key_value_states", ")", ",", "-", "1", ",", "bsz", ")", "\n", "", "elif", "past_key_value", "is", "not", "None", ":", "\n", "# reuse k, v, self_attention", "\n", "            ", "key_states", "=", "self", ".", "_shape", "(", "self", ".", "k_proj", "(", "hidden_states", ")", ",", "-", "1", ",", "bsz", ")", "\n", "value_states", "=", "self", ".", "_shape", "(", "self", ".", "v_proj", "(", "hidden_states", ")", ",", "-", "1", ",", "bsz", ")", "\n", "key_states", "=", "torch", ".", "cat", "(", "[", "past_key_value", "[", "0", "]", ",", "key_states", "]", ",", "dim", "=", "2", ")", "\n", "value_states", "=", "torch", ".", "cat", "(", "[", "past_key_value", "[", "1", "]", ",", "value_states", "]", ",", "dim", "=", "2", ")", "\n", "", "else", ":", "\n", "# self_attention", "\n", "            ", "key_states", "=", "self", ".", "_shape", "(", "self", ".", "k_proj", "(", "hidden_states", ")", ",", "-", "1", ",", "bsz", ")", "\n", "value_states", "=", "self", ".", "_shape", "(", "self", ".", "v_proj", "(", "hidden_states", ")", ",", "-", "1", ",", "bsz", ")", "\n", "\n", "", "if", "self", ".", "is_decoder", ":", "\n", "# if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.", "\n", "# Further calls to cross_attention layer can then reuse all cross-attention", "\n", "# key/value_states (first \"if\" case)", "\n", "# if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of", "\n", "# all previous decoder key/value_states. Further calls to uni-directional self-attention", "\n", "# can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)", "\n", "# if encoder bi-directional self-attention `past_key_value` is always `None`", "\n", "            ", "past_key_value", "=", "(", "key_states", ",", "value_states", ")", "\n", "\n", "", "proj_shape", "=", "(", "bsz", "*", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "query_states", "=", "self", ".", "_shape", "(", "query_states", ",", "tgt_len", ",", "bsz", ")", ".", "view", "(", "*", "proj_shape", ")", "\n", "key_states", "=", "key_states", ".", "view", "(", "*", "proj_shape", ")", "\n", "value_states", "=", "value_states", ".", "view", "(", "*", "proj_shape", ")", "\n", "\n", "src_len", "=", "key_states", ".", "size", "(", "1", ")", "\n", "attn_weights", "=", "torch", ".", "bmm", "(", "query_states", ",", "key_states", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "\n", "assert", "attn_weights", ".", "size", "(", ")", "==", "(", "\n", "bsz", "*", "self", ".", "num_heads", ",", "\n", "tgt_len", ",", "\n", "src_len", ",", "\n", ")", ",", "f\"Attention weights should be of size {(bsz * self.num_heads, tgt_len, src_len)}, but is {attn_weights.size()}\"", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "            ", "assert", "attention_mask", ".", "size", "(", ")", "==", "(", "\n", "bsz", ",", "\n", "1", ",", "\n", "tgt_len", ",", "\n", "src_len", ",", "\n", ")", ",", "f\"Attention mask should be of size {(bsz, 1, tgt_len, src_len)}, but is {attention_mask.size()}\"", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "+", "attention_mask", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "attn_weights", "=", "F", ".", "softmax", "(", "attn_weights", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "layer_head_mask", "is", "not", "None", ":", "\n", "            ", "assert", "layer_head_mask", ".", "size", "(", ")", "==", "(", "\n", "self", ".", "num_heads", ",", "\n", ")", ",", "f\"Head mask for a single layer should be of size {(self.num_heads,)}, but is {layer_head_mask.size()}\"", "\n", "attn_weights", "=", "layer_head_mask", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "*", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "if", "output_attentions", ":", "\n", "# this operation is a bit akward, but it's required to", "\n", "# make sure that attn_weights keeps its gradient.", "\n", "# In order to do so, attn_weights have to reshaped", "\n", "# twice and have to be reused in the following", "\n", "            ", "attn_weights_reshaped", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "attn_weights", "=", "attn_weights_reshaped", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "", "else", ":", "\n", "            ", "attn_weights_reshaped", "=", "None", "\n", "\n", "", "attn_probs", "=", "F", ".", "dropout", "(", "attn_weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "attn_output", "=", "torch", ".", "bmm", "(", "attn_probs", ",", "value_states", ")", "\n", "\n", "assert", "attn_output", ".", "size", "(", ")", "==", "(", "\n", "bsz", "*", "self", ".", "num_heads", ",", "\n", "tgt_len", ",", "\n", "self", ".", "head_dim", ",", "\n", ")", ",", "f\"`attn_output` should be of size {(bsz, self.num_heads, tgt_len, self.head_dim)}, but is {attn_output.size()}\"", "\n", "\n", "attn_output", "=", "(", "\n", "attn_output", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", ")", "\n", ".", "transpose", "(", "1", ",", "2", ")", "\n", ".", "reshape", "(", "bsz", ",", "tgt_len", ",", "embed_dim", ")", "\n", ")", "\n", "\n", "attn_output", "=", "self", ".", "out_proj", "(", "attn_output", ")", "\n", "\n", "return", "attn_output", ",", "attn_weights_reshaped", ",", "past_key_value", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartEncoderLayer.__init__": [[271, 286], ["torch.nn.Module.__init__", "modeling_bart.BartAttention", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "config", ".", "d_model", "\n", "self", ".", "self_attn", "=", "BartAttention", "(", "\n", "embed_dim", "=", "self", ".", "embed_dim", ",", "\n", "num_heads", "=", "config", ".", "encoder_attention_heads", ",", "\n", "dropout", "=", "config", ".", "attention_dropout", ",", "\n", ")", "\n", "self", ".", "self_attn_layer_norm", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "activation_fn", "=", "ACT2FN", "[", "config", ".", "activation_function", "]", "\n", "self", ".", "activation_dropout", "=", "config", ".", "activation_dropout", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "config", ".", "encoder_ffn_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "config", ".", "encoder_ffn_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "final_layer_norm", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartEncoderLayer.forward": [[287, 334], ["modeling_bart.BartEncoderLayer.self_attn", "torch.dropout", "torch.dropout", "torch.dropout", "modeling_bart.BartEncoderLayer.self_attn_layer_norm", "modeling_bart.BartEncoderLayer.activation_fn", "torch.dropout", "torch.dropout", "torch.dropout", "modeling_bart.BartEncoderLayer.fc2", "torch.dropout", "torch.dropout", "torch.dropout", "modeling_bart.BartEncoderLayer.final_layer_norm", "modeling_bart.BartEncoderLayer.fc1", "torch.isinf().any", "torch.isinf().any", "torch.isinf().any", "torch.isinf().any", "torch.isinf().any", "torch.isinf().any", "torch.isinf().any", "torch.isinf().any", "torch.isinf().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.isinf", "torch.isinf", "torch.isinf", "torch.isinf", "torch.isinf", "torch.isinf", "torch.isinf", "torch.isinf", "torch.isinf", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.finfo", "torch.finfo", "torch.finfo", "torch.finfo", "torch.finfo", "torch.finfo", "torch.finfo", "torch.finfo", "torch.finfo"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ":", "torch", ".", "Tensor", ",", "\n", "attention_mask", ":", "torch", ".", "Tensor", ",", "\n", "layer_head_mask", ":", "torch", ".", "Tensor", ",", "\n", "output_attentions", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            hidden_states (:obj:`torch.FloatTensor`): input to the layer of shape `(seq_len, batch, embed_dim)`\n            attention_mask (:obj:`torch.FloatTensor`): attention mask of size\n                `(batch, 1, tgt_len, src_len)` where padding elements are indicated by very large negative values.\n            layer_head_mask (:obj:`torch.FloatTensor`): mask for attention heads in a given layer of size\n                `(config.encoder_attention_heads,)`.\n            output_attentions (:obj:`bool`, `optional`):\n                Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under\n                returned tensors for more detail.\n        \"\"\"", "\n", "residual", "=", "hidden_states", "\n", "hidden_states", ",", "attn_weights", ",", "_", "=", "self", ".", "self_attn", "(", "\n", "hidden_states", "=", "hidden_states", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "layer_head_mask", "=", "layer_head_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "hidden_states", "=", "F", ".", "dropout", "(", "hidden_states", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "hidden_states", "=", "residual", "+", "hidden_states", "\n", "hidden_states", "=", "self", ".", "self_attn_layer_norm", "(", "hidden_states", ")", "\n", "\n", "residual", "=", "hidden_states", "\n", "hidden_states", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "hidden_states", ")", ")", "\n", "hidden_states", "=", "F", ".", "dropout", "(", "hidden_states", ",", "p", "=", "self", ".", "activation_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "hidden_states", "=", "self", ".", "fc2", "(", "hidden_states", ")", "\n", "hidden_states", "=", "F", ".", "dropout", "(", "hidden_states", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "hidden_states", "=", "residual", "+", "hidden_states", "\n", "hidden_states", "=", "self", ".", "final_layer_norm", "(", "hidden_states", ")", "\n", "\n", "if", "torch", ".", "isinf", "(", "hidden_states", ")", ".", "any", "(", ")", "or", "torch", ".", "isnan", "(", "hidden_states", ")", ".", "any", "(", ")", ":", "\n", "            ", "clamp_value", "=", "torch", ".", "finfo", "(", "hidden_states", ".", "dtype", ")", ".", "max", "-", "1000", "\n", "hidden_states", "=", "torch", ".", "clamp", "(", "hidden_states", ",", "min", "=", "-", "clamp_value", ",", "max", "=", "clamp_value", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "\n", "if", "output_attentions", ":", "\n", "            ", "outputs", "+=", "(", "attn_weights", ",", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartDecoderLayer.__init__": [[337, 362], ["torch.nn.Module.__init__", "modeling_bart.BartAttention", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "modeling_bart.BartAttention", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "config", ".", "d_model", "\n", "\n", "self", ".", "self_attn", "=", "BartAttention", "(", "\n", "embed_dim", "=", "self", ".", "embed_dim", ",", "\n", "num_heads", "=", "config", ".", "decoder_attention_heads", ",", "\n", "dropout", "=", "config", ".", "attention_dropout", ",", "\n", "is_decoder", "=", "True", ",", "\n", ")", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "activation_fn", "=", "ACT2FN", "[", "config", ".", "activation_function", "]", "\n", "self", ".", "activation_dropout", "=", "config", ".", "activation_dropout", "\n", "\n", "self", ".", "self_attn_layer_norm", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "encoder_attn", "=", "BartAttention", "(", "\n", "self", ".", "embed_dim", ",", "\n", "config", ".", "decoder_attention_heads", ",", "\n", "dropout", "=", "config", ".", "attention_dropout", ",", "\n", "is_decoder", "=", "True", ",", "\n", ")", "\n", "self", ".", "encoder_attn_layer_norm", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "config", ".", "decoder_ffn_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "config", ".", "decoder_ffn_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "final_layer_norm", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartDecoderLayer.forward": [[363, 450], ["modeling_bart.BartDecoderLayer.self_attn", "torch.dropout", "torch.dropout", "torch.dropout", "modeling_bart.BartDecoderLayer.self_attn_layer_norm", "modeling_bart.BartDecoderLayer.activation_fn", "torch.dropout", "torch.dropout", "torch.dropout", "modeling_bart.BartDecoderLayer.fc2", "torch.dropout", "torch.dropout", "torch.dropout", "modeling_bart.BartDecoderLayer.final_layer_norm", "modeling_bart.BartDecoderLayer.encoder_attn", "torch.dropout", "torch.dropout", "torch.dropout", "modeling_bart.BartDecoderLayer.encoder_attn_layer_norm", "modeling_bart.BartDecoderLayer.fc1"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ":", "torch", ".", "Tensor", ",", "\n", "attention_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "encoder_hidden_states", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "encoder_attention_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "layer_head_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "encoder_layer_head_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "past_key_value", ":", "Optional", "[", "Tuple", "[", "torch", ".", "Tensor", "]", "]", "=", "None", ",", "\n", "output_attentions", ":", "Optional", "[", "bool", "]", "=", "False", ",", "\n", "use_cache", ":", "Optional", "[", "bool", "]", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            hidden_states (:obj:`torch.FloatTensor`): input to the layer of shape `(seq_len, batch, embed_dim)`\n            attention_mask (:obj:`torch.FloatTensor`): attention mask of size\n                `(batch, 1, tgt_len, src_len)` where padding elements are indicated by very large negative values.\n            encoder_hidden_states (:obj:`torch.FloatTensor`): cross attention input to the layer of shape `(seq_len, batch, embed_dim)`\n            encoder_attention_mask (:obj:`torch.FloatTensor`): encoder attention mask of size\n                `(batch, 1, tgt_len, src_len)` where padding elements are indicated by very large negative values.\n            layer_head_mask (:obj:`torch.FloatTensor`): mask for attention heads in a given layer of size\n                `(config.encoder_attention_heads,)`.\n            encoder_layer_head_mask (:obj:`torch.FloatTensor`): mask for encoder attention heads in a given layer of\n                size `(config.encoder_attention_heads,)`.\n            past_key_value (:obj:`Tuple(torch.FloatTensor)`): cached past key and value projection states\n            output_attentions (:obj:`bool`, `optional`):\n                Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under\n                returned tensors for more detail.\n        \"\"\"", "\n", "residual", "=", "hidden_states", "\n", "\n", "# Self Attention", "\n", "# decoder uni-directional self-attention cached key/values tuple is at positions 1,2", "\n", "self_attn_past_key_value", "=", "past_key_value", "[", ":", "2", "]", "if", "past_key_value", "is", "not", "None", "else", "None", "\n", "# add present self-attn cache to positions 1,2 of present_key_value tuple", "\n", "hidden_states", ",", "self_attn_weights", ",", "present_key_value", "=", "self", ".", "self_attn", "(", "\n", "hidden_states", "=", "hidden_states", ",", "\n", "past_key_value", "=", "self_attn_past_key_value", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "layer_head_mask", "=", "layer_head_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "hidden_states", "=", "F", ".", "dropout", "(", "hidden_states", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "hidden_states", "=", "residual", "+", "hidden_states", "\n", "hidden_states", "=", "self", ".", "self_attn_layer_norm", "(", "hidden_states", ")", "\n", "\n", "# Cross-Attention Block", "\n", "cross_attn_present_key_value", "=", "None", "\n", "cross_attn_weights", "=", "None", "\n", "if", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "residual", "=", "hidden_states", "\n", "\n", "# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple", "\n", "cross_attn_past_key_value", "=", "past_key_value", "[", "-", "2", ":", "]", "if", "past_key_value", "is", "not", "None", "else", "None", "\n", "hidden_states", ",", "cross_attn_weights", ",", "cross_attn_present_key_value", "=", "self", ".", "encoder_attn", "(", "\n", "hidden_states", "=", "hidden_states", ",", "\n", "key_value_states", "=", "encoder_hidden_states", ",", "\n", "attention_mask", "=", "encoder_attention_mask", ",", "\n", "layer_head_mask", "=", "encoder_layer_head_mask", ",", "\n", "past_key_value", "=", "cross_attn_past_key_value", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "hidden_states", "=", "F", ".", "dropout", "(", "hidden_states", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "hidden_states", "=", "residual", "+", "hidden_states", "\n", "hidden_states", "=", "self", ".", "encoder_attn_layer_norm", "(", "hidden_states", ")", "\n", "\n", "# add cross-attn to positions 3,4 of present_key_value tuple", "\n", "present_key_value", "=", "present_key_value", "+", "cross_attn_present_key_value", "\n", "\n", "# Fully Connected", "\n", "", "residual", "=", "hidden_states", "\n", "hidden_states", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "hidden_states", ")", ")", "\n", "hidden_states", "=", "F", ".", "dropout", "(", "hidden_states", ",", "p", "=", "self", ".", "activation_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "hidden_states", "=", "self", ".", "fc2", "(", "hidden_states", ")", "\n", "hidden_states", "=", "F", ".", "dropout", "(", "hidden_states", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "hidden_states", "=", "residual", "+", "hidden_states", "\n", "hidden_states", "=", "self", ".", "final_layer_norm", "(", "hidden_states", ")", "\n", "\n", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "\n", "if", "output_attentions", ":", "\n", "            ", "outputs", "+=", "(", "self_attn_weights", ",", "cross_attn_weights", ")", "\n", "\n", "", "if", "use_cache", ":", "\n", "            ", "outputs", "+=", "(", "present_key_value", ",", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartPretrainedModel._init_weights": [[455, 465], ["isinstance", "module.weight.data.normal_", "isinstance", "module.bias.data.zero_", "module.weight.data.normal_", "module.weight.data[].zero_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "std", "=", "self", ".", "config", ".", "init_std", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "std", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ":", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "std", ")", "\n", "if", "module", ".", "padding_idx", "is", "not", "None", ":", "\n", "                ", "module", ".", "weight", ".", "data", "[", "module", ".", "padding_idx", "]", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartPretrainedModel.dummy_inputs": [[466, 475], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.ne", "torch.tensor.ne", "torch.tensor.ne"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "dummy_inputs", "(", "self", ")", ":", "\n", "        ", "pad_token", "=", "self", ".", "config", ".", "pad_token_id", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "[", "[", "0", ",", "6", ",", "10", ",", "4", ",", "2", "]", ",", "[", "0", ",", "8", ",", "12", ",", "2", ",", "pad_token", "]", "]", ",", "device", "=", "self", ".", "device", ")", "\n", "dummy_inputs", "=", "{", "\n", "\"attention_mask\"", ":", "input_ids", ".", "ne", "(", "pad_token", ")", ",", "\n", "\"input_ids\"", ":", "input_ids", ",", "\n", "}", "\n", "return", "dummy_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.PretrainedBartModel.__init_subclass__": [[478, 482], ["warnings.warn"], "methods", ["None"], ["    ", "def", "__init_subclass__", "(", "self", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "\"The class `PretrainedBartModel` has been depreciated, please use `BartPretrainedModel` instead.\"", ",", "\n", "FutureWarning", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartEncoder.__init__": [[633, 717], ["transformers.modeling_utils.PreTrainedModel.__init__", "modeling_bart.BartLearnedPositionalEmbedding", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "modeling_bart.BartEncoder.init_weights", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "math.sqrt", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "models.img_transformer.ImageTransformerEncoder", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "modeling_bart.BartEncoderLayer", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "range", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.MultiheadAttention", "torch.nn.MultiheadAttention", "torch.nn.MultiheadAttention", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.MultiheadAttention", "torch.nn.MultiheadAttention", "torch.nn.MultiheadAttention", "ValueError", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ",", "embed_tokens", ":", "Optional", "[", "nn", ".", "Embedding", "]", "=", "None", ",", "\n", "fusion_layer", "=", "None", ",", "use_img_trans", "=", "None", ",", "use_forget_gate", "=", "None", ",", "cross_attn_type", "=", "None", ",", "dim_common", "=", "256", ",", "n_attn_heads", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "layerdrop", "=", "config", ".", "encoder_layerdrop", "\n", "\n", "embed_dim", "=", "config", ".", "d_model", "\n", "self", ".", "padding_idx", "=", "config", ".", "pad_token_id", "\n", "self", ".", "max_source_positions", "=", "config", ".", "max_position_embeddings", "\n", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "embed_dim", ")", "if", "config", ".", "scale_embedding", "else", "1.0", "\n", "\n", "if", "embed_tokens", "is", "not", "None", ":", "\n", "            ", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "", "else", ":", "\n", "            ", "self", ".", "embed_tokens", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "embed_dim", ",", "self", ".", "padding_idx", ")", "\n", "\n", "", "self", ".", "embed_positions", "=", "BartLearnedPositionalEmbedding", "(", "\n", "config", ".", "max_position_embeddings", ",", "\n", "embed_dim", ",", "\n", "self", ".", "padding_idx", ",", "\n", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "BartEncoderLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "encoder_layers", ")", "]", ")", "\n", "self", ".", "layernorm_embedding", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n", "# ==================== Modification Starts ====================", "\n", "\n", "self", ".", "fusion_layer", "=", "fusion_layer", "\n", "self", ".", "use_forget_gate", "=", "use_forget_gate", "\n", "self", ".", "use_img_trans", "=", "use_img_trans", "\n", "self", ".", "cross_attn_type", "=", "cross_attn_type", "\n", "\n", "if", "self", ".", "use_img_trans", ":", "\n", "            ", "self", ".", "img_transformer", "=", "ImageTransformerEncoder", "(", "d_model", "=", "2048", ",", "num_layers", "=", "4", ",", "num_heads", "=", "8", ",", "dim_feedforward", "=", "2048", ")", "\n", "\n", "# Some global variables", "\n", "", "visual_feature_dim", "=", "2048", "\n", "text_feature_dim", "=", "embed_dim", "# 768", "\n", "\n", "if", "cross_attn_type", "==", "0", ":", "\n", "            ", "self", ".", "_linear_1", "=", "nn", ".", "Linear", "(", "visual_feature_dim", ",", "text_feature_dim", ")", "\n", "self", ".", "_linear_2", "=", "nn", ".", "Linear", "(", "text_feature_dim", "+", "visual_feature_dim", ",", "text_feature_dim", ")", "\n", "if", "use_forget_gate", ":", "\n", "                ", "self", ".", "fg", "=", "nn", ".", "Linear", "(", "visual_feature_dim", "+", "text_feature_dim", ",", "visual_feature_dim", ")", "\n", "", "", "elif", "cross_attn_type", "==", "1", ":", "\n", "            ", "self", ".", "_linear_1", "=", "nn", ".", "Linear", "(", "visual_feature_dim", ",", "text_feature_dim", ")", "\n", "self", ".", "_linear_2", "=", "nn", ".", "Linear", "(", "2", "*", "text_feature_dim", ",", "text_feature_dim", ")", "\n", "if", "use_forget_gate", ":", "\n", "                ", "self", ".", "fg", "=", "nn", ".", "Linear", "(", "2", "*", "text_feature_dim", ",", "text_feature_dim", ")", "\n", "", "", "elif", "cross_attn_type", "==", "2", ":", "\n", "            ", "self", ".", "_linear_1", "=", "nn", ".", "Linear", "(", "visual_feature_dim", ",", "text_feature_dim", ")", "\n", "if", "use_forget_gate", ":", "\n", "                ", "self", ".", "fg", "=", "nn", ".", "Linear", "(", "2", "*", "text_feature_dim", ",", "text_feature_dim", ")", "\n", "", "", "elif", "cross_attn_type", "==", "3", ":", "\n", "            ", "self", ".", "_linear_1", "=", "nn", ".", "Linear", "(", "text_feature_dim", ",", "dim_common", ")", "\n", "self", ".", "_linear_2", "=", "nn", ".", "Linear", "(", "visual_feature_dim", ",", "dim_common", ")", "\n", "self", ".", "_linear_3", "=", "nn", ".", "Linear", "(", "text_feature_dim", "+", "visual_feature_dim", ",", "text_feature_dim", ")", "\n", "if", "use_forget_gate", ":", "\n", "                ", "self", ".", "fg", "=", "nn", ".", "Linear", "(", "visual_feature_dim", "+", "text_feature_dim", ",", "visual_feature_dim", ")", "\n", "", "", "elif", "cross_attn_type", "==", "4", ":", "\n", "            ", "self", ".", "_linear_1", "=", "nn", ".", "Linear", "(", "visual_feature_dim", ",", "dim_common", ")", "# K", "\n", "self", ".", "_linear_2", "=", "nn", ".", "Linear", "(", "visual_feature_dim", ",", "dim_common", ")", "# V", "\n", "self", ".", "_linear_3", "=", "nn", ".", "Linear", "(", "text_feature_dim", ",", "dim_common", ")", "# Q", "\n", "self", ".", "_multi_head_attn", "=", "nn", ".", "MultiheadAttention", "(", "dim_common", ",", "n_attn_heads", ")", "\n", "self", ".", "_linear_4", "=", "nn", ".", "Linear", "(", "text_feature_dim", "+", "dim_common", ",", "text_feature_dim", ")", "\n", "if", "use_forget_gate", ":", "\n", "                ", "self", ".", "fg", "=", "nn", ".", "Linear", "(", "dim_common", "+", "text_feature_dim", ",", "dim_common", ")", "\n", "", "", "elif", "cross_attn_type", "==", "5", ":", "\n", "            ", "self", ".", "_linear_1", "=", "nn", ".", "Linear", "(", "visual_feature_dim", ",", "dim_common", ")", "# K", "\n", "self", ".", "_linear_2", "=", "nn", ".", "Linear", "(", "visual_feature_dim", ",", "dim_common", ")", "# V", "\n", "self", ".", "_linear_3", "=", "nn", ".", "Linear", "(", "text_feature_dim", ",", "dim_common", ")", "# Q", "\n", "self", ".", "_multi_head_attn", "=", "nn", ".", "MultiheadAttention", "(", "dim_common", ",", "n_attn_heads", ")", "\n", "if", "use_forget_gate", ":", "\n", "                ", "self", ".", "fg", "=", "nn", ".", "Linear", "(", "dim_common", "+", "text_feature_dim", ",", "dim_common", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Wrong cross_attn_type value!'", ")", "\n", "\n", "# if use_forget_gate:", "\n", "#     self.fg = nn.Linear(visual_feature_dim + text_feature_dim, visual_feature_dim)", "\n", "\n", "", "self", ".", "final_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "sigmiod", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "# ==================== Modification Ends ====================", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartEncoder.forward": [[739, 975], ["modeling_bart.BartEncoder.embed_positions", "modeling_bart.BartEncoder.layernorm_embedding", "torch.dropout", "torch.dropout", "torch.dropout", "enumerate", "transformers.modeling_outputs.BaseModelOutput", "ValueError", "modeling_bart._expand_mask", "random.uniform", "tuple", "modeling_bart.BartEncoder.img_transformer", "input_ids.view.view.size", "input_ids.view.view.view", "modeling_bart.BartEncoder.embed_tokens", "len", "ValueError", "head_mask.size", "len", "getattr", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "encoder_layer", "modeling_bart.BartEncoder.fg", "modeling_bart.BartEncoder.sigmiod", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout.mul", "torch.dropout", "torch.dropout", "torch.dropout", "modeling_bart.BartEncoder.final_layer_norm", "inputs_embeds.size", "head_mask.size", "modeling_bart.BartEncoder.forward.create_custom_forward"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart._expand_mask"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "image_features", "=", "None", ",", "\n", "image_len", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        Args:\n            input_ids (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`):\n                Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you\n                provide it.\n\n                Indices can be obtained using :class:`~transformers.BartTokenizer`. See\n                :meth:`transformers.PreTrainedTokenizer.encode` and :meth:`transformers.PreTrainedTokenizer.__call__`\n                for details.\n\n                `What are input IDs? <../glossary.html#input-ids>`__\n            attention_mask (:obj:`torch.Tensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n                Mask to avoid performing attention on padding token indices. Mask values selected in ``[0, 1]``:\n\n                - 1 for tokens that are **not masked**,\n                - 0 for tokens that are **masked**.\n\n                `What are attention masks? <../glossary.html#attention-mask>`__\n            head_mask (:obj:`torch.Tensor` of shape :obj:`(num_layers, num_heads)`, `optional`):\n                Mask to nullify selected heads of the attention modules. Mask values selected in ``[0, 1]``:\n\n                - 1 indicates the head is **not masked**,\n                - 0 indicates the heas is **masked**.\n\n            inputs_embeds (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`, `optional`):\n                Optionally, instead of passing :obj:`input_ids` you can choose to directly pass an embedded\n                representation. This is useful if you want more control over how to convert :obj:`input_ids` indices\n                into associated vectors than the model's internal embedding lookup matrix.\n            output_attentions (:obj:`bool`, `optional`):\n                Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under\n                returned tensors for more detail.\n            output_hidden_states (:obj:`bool`, `optional`):\n                Whether or not to return the hidden states of all layers. See ``hidden_states`` under returned tensors\n                for more detail.\n            return_dict (:obj:`bool`, `optional`):\n                Whether or not to return a :class:`~transformers.file_utils.ModelOutput` instead of a plain tuple.\n        \"\"\"", "\n", "# ============================ image transformer ==========================================", "\n", "# image_features = self.img_transformer(image_features, image_len)", "\n", "# print('='*50)", "\n", "# print(f'image_features len = {len(image_features)}')", "\n", "# print(f'image_features size = {image_features[0].shape}')", "\n", "# exit()", "\n", "\n", "if", "self", ".", "use_img_trans", ":", "\n", "            ", "image_features", "=", "self", ".", "img_transformer", "(", "image_features", ",", "image_len", ")", "[", "-", "1", "]", "\n", "# ============================ image transformer ==========================================", "\n", "\n", "", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "# retrieve input_ids and inputs_embeds", "\n", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "embed_tokens", "(", "input_ids", ")", "*", "self", ".", "embed_scale", "\n", "\n", "", "embed_pos", "=", "self", ".", "embed_positions", "(", "input_shape", ")", "\n", "\n", "hidden_states", "=", "inputs_embeds", "+", "embed_pos", "\n", "hidden_states", "=", "self", ".", "layernorm_embedding", "(", "hidden_states", ")", "\n", "hidden_states", "=", "F", ".", "dropout", "(", "hidden_states", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# expand attention_mask", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]", "\n", "            ", "attention_mask", "=", "_expand_mask", "(", "attention_mask", ",", "inputs_embeds", ".", "dtype", ")", "\n", "\n", "", "encoder_states", "=", "(", ")", "if", "output_hidden_states", "else", "None", "\n", "all_attentions", "=", "(", ")", "if", "output_attentions", "else", "None", "\n", "\n", "# check if head_mask has a correct number of layers specified if desired", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "assert", "head_mask", ".", "size", "(", ")", "[", "0", "]", "==", "(", "\n", "len", "(", "self", ".", "layers", ")", "\n", ")", ",", "f\"The head_mask should be specified for {len(self.layers)} layers, but it is for {head_mask.size()[0]}.\"", "\n", "", "for", "idx", ",", "encoder_layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "if", "output_hidden_states", ":", "\n", "                ", "encoder_states", "=", "encoder_states", "+", "(", "hidden_states", ",", ")", "\n", "# add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)", "\n", "", "dropout_probability", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "training", "and", "(", "dropout_probability", "<", "self", ".", "layerdrop", ")", ":", "# skip the layer", "\n", "                ", "layer_outputs", "=", "(", "None", ",", "None", ")", "\n", "", "else", ":", "\n", "                ", "if", "getattr", "(", "self", ".", "config", ",", "\"gradient_checkpointing\"", ",", "False", ")", "and", "self", ".", "training", ":", "\n", "\n", "                    ", "def", "create_custom_forward", "(", "module", ")", ":", "\n", "                        ", "def", "custom_forward", "(", "*", "inputs", ")", ":", "\n", "                            ", "return", "module", "(", "*", "inputs", ",", "output_attentions", ")", "\n", "\n", "", "return", "custom_forward", "\n", "\n", "", "layer_outputs", "=", "torch", ".", "utils", ".", "checkpoint", ".", "checkpoint", "(", "\n", "create_custom_forward", "(", "encoder_layer", ")", ",", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "(", "head_mask", "[", "idx", "]", "if", "head_mask", "is", "not", "None", "else", "None", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "layer_outputs", "=", "encoder_layer", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "layer_head_mask", "=", "(", "head_mask", "[", "idx", "]", "if", "head_mask", "is", "not", "None", "else", "None", ")", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "\n", "", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "\n", "# ==================== text-to-video fusion  =====================", "\n", "def", "forget_gate", "(", "image_features", ",", "text_features", ")", ":", "\n", "                    ", "forget_mask", "=", "self", ".", "fg", "(", "torch", ".", "cat", "(", "(", "image_features", ",", "text_features", ")", ",", "2", ")", ")", "\n", "forget_mask", "=", "self", ".", "sigmiod", "(", "forget_mask", ")", "\n", "forget_mask", "=", "F", ".", "dropout", "(", "forget_mask", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "image_features", "=", "forget_mask", ".", "mul", "(", "image_features", ")", "\n", "return", "image_features", "\n", "\n", "", "if", "idx", "==", "self", ".", "fusion_layer", ":", "\n", "                    ", "if", "self", ".", "cross_attn_type", "==", "0", ":", "\n", "                        ", "image_features_transformed", "=", "self", ".", "_linear_1", "(", "image_features", ")", "\n", "attn", "=", "torch", ".", "bmm", "(", "hidden_states", ",", "image_features_transformed", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "attn", "=", "F", ".", "softmax", "(", "attn", ",", "dim", "=", "1", ")", "\n", "image_features", "=", "torch", ".", "bmm", "(", "attn", ",", "image_features", ")", "# (S_t, D_v)", "\n", "if", "self", ".", "use_forget_gate", ":", "\n", "                            ", "image_features", "=", "forget_gate", "(", "image_features", ",", "hidden_states", ")", "\n", "", "output", "=", "self", ".", "_linear_2", "(", "torch", ".", "cat", "(", "(", "hidden_states", ",", "image_features", ")", ",", "2", ")", ")", "\n", "", "elif", "self", ".", "cross_attn_type", "==", "1", ":", "\n", "                        ", "image_features", "=", "self", ".", "_linear_1", "(", "image_features", ")", "\n", "attn", "=", "torch", ".", "bmm", "(", "hidden_states", ",", "image_features", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "attn", "=", "F", ".", "softmax", "(", "attn", ",", "dim", "=", "1", ")", "\n", "image_features", "=", "torch", ".", "bmm", "(", "attn", ",", "image_features", ")", "# (S_t, D_t)", "\n", "if", "self", ".", "use_forget_gate", ":", "\n", "                            ", "image_features", "=", "forget_gate", "(", "image_features", ",", "hidden_states", ")", "\n", "", "output", "=", "self", ".", "_linear_2", "(", "torch", ".", "cat", "(", "(", "hidden_states", ",", "image_features", ")", ",", "2", ")", ")", "\n", "", "elif", "self", ".", "cross_attn_type", "==", "2", ":", "\n", "                        ", "image_features", "=", "self", ".", "_linear_1", "(", "image_features", ")", "\n", "attn", "=", "torch", ".", "bmm", "(", "hidden_states", ",", "image_features", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "attn", "=", "F", ".", "softmax", "(", "attn", ",", "dim", "=", "1", ")", "\n", "image_features", "=", "torch", ".", "bmm", "(", "attn", ",", "image_features", ")", "# (S_t, D_t)", "\n", "if", "self", ".", "use_forget_gate", ":", "\n", "                            ", "image_features", "=", "forget_gate", "(", "image_features", ",", "hidden_states", ")", "\n", "", "output", "=", "image_features", "\n", "", "elif", "self", ".", "cross_attn_type", "==", "3", ":", "\n", "                        ", "hidden_states_transformed", "=", "self", ".", "_linear_1", "(", "hidden_states", ")", "\n", "image_features_transformed", "=", "self", ".", "_linear_2", "(", "image_features", ")", "\n", "attn", "=", "torch", ".", "bmm", "(", "hidden_states_transformed", ",", "image_features_transformed", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "attn", "=", "F", ".", "softmax", "(", "attn", ",", "dim", "=", "1", ")", "\n", "image_features", "=", "torch", ".", "bmm", "(", "attn", ",", "image_features", ")", "\n", "if", "self", ".", "use_forget_gate", ":", "\n", "                            ", "image_features", "=", "forget_gate", "(", "image_features", ",", "hidden_states", ")", "\n", "", "output", "=", "self", ".", "_linear_3", "(", "torch", ".", "cat", "(", "(", "hidden_states", ",", "image_features", ")", ",", "2", ")", ")", "\n", "", "elif", "self", ".", "cross_attn_type", "==", "4", ":", "\n", "                        ", "K", "=", "self", ".", "_linear_1", "(", "image_features", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "V", "=", "self", ".", "_linear_2", "(", "image_features", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "Q", "=", "self", ".", "_linear_3", "(", "hidden_states", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "attn_output", ",", "_", "=", "self", ".", "_multi_head_attn", "(", "Q", ",", "K", ",", "V", ")", "\n", "attn_output", "=", "attn_output", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "use_forget_gate", ":", "\n", "                            ", "forget_mask", "=", "self", ".", "fg", "(", "torch", ".", "cat", "(", "(", "attn_output", ",", "hidden_states", ")", ",", "2", ")", ")", "\n", "forget_mask", "=", "self", ".", "sigmiod", "(", "forget_mask", ")", "\n", "forget_mask", "=", "F", ".", "dropout", "(", "forget_mask", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "attn_output", "=", "forget_mask", ".", "mul", "(", "attn_output", ")", "\n", "", "output", "=", "self", ".", "_linear_4", "(", "torch", ".", "cat", "(", "(", "hidden_states", ",", "attn_output", ")", ",", "2", ")", ")", "\n", "", "elif", "self", ".", "cross_attn_type", "==", "5", ":", "\n", "                        ", "K", "=", "self", ".", "_linear_1", "(", "image_features", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "V", "=", "self", ".", "_linear_2", "(", "image_features", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "Q", "=", "self", ".", "_linear_3", "(", "hidden_states", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "attn_output", ",", "_", "=", "self", ".", "_multi_head_attn", "(", "Q", ",", "K", ",", "V", ")", "\n", "attn_output", "=", "attn_output", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "use_forget_gate", ":", "\n", "                            ", "forget_mask", "=", "self", ".", "fg", "(", "torch", ".", "cat", "(", "(", "attn_output", ",", "hidden_states", ")", ",", "2", ")", ")", "\n", "forget_mask", "=", "self", ".", "sigmiod", "(", "forget_mask", ")", "\n", "forget_mask", "=", "F", ".", "dropout", "(", "forget_mask", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "attn_output", "=", "forget_mask", ".", "mul", "(", "attn_output", ")", "\n", "", "output", "=", "attn_output", "\n", "\n", "# # make image feature for every text token", "\n", "# image_feature_2 = self.img_feature_transfers[idx](image_features)", "\n", "# att = F.softmax(torch.bmm(hidden_states, torch.transpose(image_feature_2, 1, 2)), dim=1)", "\n", "# image_feature_3 = torch.bmm(att, image_features)", "\n", "\n", "# # forgate gate", "\n", "# forget = self.sigmiod(self.fgs[idx](torch.cat((image_feature_3, hidden_states), 2)))", "\n", "# forget = F.dropout(forget, p=self.dropout, training=self.training)", "\n", "# forget = forget.mul(image_feature_3)", "\n", "\n", "# # Text image fusion", "\n", "# output = self.fcs[idx](torch.cat((hidden_states, forget), 2))", "\n", "", "output", "=", "F", ".", "dropout", "(", "output", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# Residual Connection", "\n", "hidden_states", "=", "hidden_states", "+", "output", "\n", "hidden_states", "=", "self", ".", "final_layer_norm", "(", "hidden_states", ")", "\n", "\n", "# print('='*40)", "\n", "# print('BartEncoder')", "\n", "# print(f'hidden_state shape = {hidden_states.shape}')", "\n", "# # print(hidden_states)", "\n", "# print(f'image_feature shape = {image_feature.shape}')", "\n", "# # print(attention_mask)", "\n", "# print('='*40)", "\n", "# exit()", "\n", "# ==================== text-to-video fusion  =====================", "\n", "\n", "", "", "if", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "\n", "", "", "if", "output_hidden_states", ":", "\n", "            ", "encoder_states", "=", "encoder_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "return", "tuple", "(", "v", "for", "v", "in", "[", "hidden_states", ",", "encoder_states", ",", "all_attentions", "]", "if", "v", "is", "not", "None", ")", "\n", "", "return", "BaseModelOutput", "(", "\n", "last_hidden_state", "=", "hidden_states", ",", "hidden_states", "=", "encoder_states", ",", "attentions", "=", "all_attentions", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartDecoder.__init__": [[987, 1009], ["transformers.modeling_utils.PreTrainedModel.__init__", "modeling_bart.BartLearnedPositionalEmbedding", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "modeling_bart.BartDecoder.init_weights", "math.sqrt", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "modeling_bart.BartDecoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ",", "embed_tokens", ":", "Optional", "[", "nn", ".", "Embedding", "]", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "layerdrop", "=", "config", ".", "decoder_layerdrop", "\n", "self", ".", "padding_idx", "=", "config", ".", "pad_token_id", "\n", "self", ".", "max_target_positions", "=", "config", ".", "max_position_embeddings", "\n", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "config", ".", "d_model", ")", "if", "config", ".", "scale_embedding", "else", "1.0", "\n", "\n", "if", "embed_tokens", "is", "not", "None", ":", "\n", "            ", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "", "else", ":", "\n", "            ", "self", ".", "embed_tokens", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "d_model", ",", "self", ".", "padding_idx", ")", "\n", "\n", "", "self", ".", "embed_positions", "=", "BartLearnedPositionalEmbedding", "(", "\n", "config", ".", "max_position_embeddings", ",", "\n", "config", ".", "d_model", ",", "\n", "self", ".", "padding_idx", ",", "\n", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "BartDecoderLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "decoder_layers", ")", "]", ")", "\n", "self", ".", "layernorm_embedding", "=", "nn", ".", "LayerNorm", "(", "config", ".", "d_model", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartDecoder.get_input_embeddings": [[1010, 1012], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embed_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartDecoder.set_input_embeddings": [[1013, 1015], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "embed_tokens", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartDecoder._prepare_decoder_attention_mask": [[1016, 1033], ["_make_causal_mask().to", "modeling_bart._expand_mask", "modeling_bart._make_causal_mask"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart._expand_mask", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart._make_causal_mask"], ["", "def", "_prepare_decoder_attention_mask", "(", "self", ",", "attention_mask", ",", "input_shape", ",", "inputs_embeds", ",", "past_key_values_length", ")", ":", "\n", "# create causal mask", "\n", "# [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]", "\n", "        ", "combined_attention_mask", "=", "None", "\n", "if", "input_shape", "[", "-", "1", "]", ">", "1", ":", "\n", "            ", "combined_attention_mask", "=", "_make_causal_mask", "(", "\n", "input_shape", ",", "inputs_embeds", ".", "dtype", ",", "past_key_values_length", "=", "past_key_values_length", "\n", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "# [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]", "\n", "            ", "expanded_attn_mask", "=", "_expand_mask", "(", "attention_mask", ",", "inputs_embeds", ".", "dtype", ",", "tgt_len", "=", "input_shape", "[", "-", "1", "]", ")", "\n", "combined_attention_mask", "=", "(", "\n", "expanded_attn_mask", "if", "combined_attention_mask", "is", "None", "else", "expanded_attn_mask", "+", "combined_attention_mask", "\n", ")", "\n", "\n", "", "return", "combined_attention_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartDecoder.forward": [[1034, 1241], ["modeling_bart.BartDecoder._prepare_decoder_attention_mask", "modeling_bart.BartDecoder.embed_positions", "modeling_bart.BartDecoder.layernorm_embedding", "torch.dropout", "torch.dropout", "torch.dropout", "enumerate", "transformers.modeling_outputs.BaseModelOutputWithPastAndCrossAttentions", "ValueError", "modeling_bart._expand_mask", "random.uniform", "tuple", "input_ids.view.view.size", "input_ids.view.view.view", "modeling_bart.BartDecoder.embed_tokens", "len", "getattr", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "decoder_layer", "ValueError", "head_mask.size", "len", "logger.warn", "modeling_bart.BartDecoder.forward.create_custom_forward"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartDecoder._prepare_decoder_attention_mask", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart._expand_mask"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_head_mask", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        Args:\n            input_ids (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`):\n                Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you\n                provide it.\n\n                Indices can be obtained using :class:`~transformers.BartTokenizer`. See\n                :meth:`transformers.PreTrainedTokenizer.encode` and :meth:`transformers.PreTrainedTokenizer.__call__`\n                for details.\n\n                `What are input IDs? <../glossary.html#input-ids>`__\n            attention_mask (:obj:`torch.Tensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n                Mask to avoid performing attention on padding token indices. Mask values selected in ``[0, 1]``:\n\n                - 1 for tokens that are **not masked**,\n                - 0 for tokens that are **masked**.\n\n                `What are attention masks? <../glossary.html#attention-mask>`__\n            encoder_hidden_states (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, encoder_sequence_length, hidden_size)`, `optional`):\n                Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention\n                of the decoder.\n            encoder_attention_mask (:obj:`torch.LongTensor` of shape :obj:`(batch_size, encoder_sequence_length)`, `optional`):\n                Mask to avoid performing cross-attention on padding tokens indices of encoder input_ids. Mask values\n                selected in ``[0, 1]``:\n\n                - 1 for tokens that are **not masked**,\n                - 0 for tokens that are **masked**.\n\n                `What are attention masks? <../glossary.html#attention-mask>`__\n            head_mask (:obj:`torch.Tensor` of shape :obj:`(num_layers, num_heads)`, `optional`):\n                Mask to nullify selected heads of the attention modules. Mask values selected in ``[0, 1]``:\n\n                - 1 indicates the head is **not masked**,\n                - 0 indicates the heas is **masked**.\n\n            encoder_head_mask (:obj:`torch.Tensor` of shape :obj:`(num_layers, num_heads)`, `optional`):\n                Mask to nullify selected heads of the attention modules in encoder to avoid performing cross-attention\n                on hidden heads. Mask values selected in ``[0, 1]``:\n\n                - 1 indicates the head is **not masked**,\n                - 0 indicates the heas is **masked**.\n\n            past_key_values (:obj:`Tuple[Tuple[torch.Tensor]]` of length :obj:`config.n_layers` with each tuple having 2 tuples each of which has 2 tensors of shape :obj:`(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n                Contains precomputed key and value hidden-states of the attention blocks. Can be used to speed up\n                decoding.\n\n                If :obj:`past_key_values` are used, the user can optionally input only the last\n                :obj:`decoder_input_ids` (those that don't have their past key value states given to this model) of\n                shape :obj:`(batch_size, 1)` instead of all :obj:`decoder_input_ids`` of shape :obj:`(batch_size,\n                sequence_length)`.\n            inputs_embeds (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`, `optional`):\n                Optionally, instead of passing :obj:`input_ids` you can choose to directly pass an embedded\n                representation. This is useful if you want more control over how to convert :obj:`input_ids` indices\n                into associated vectors than the model's internal embedding lookup matrix.\n            output_attentions (:obj:`bool`, `optional`):\n                Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under\n                returned tensors for more detail.\n            output_hidden_states (:obj:`bool`, `optional`):\n                Whether or not to return the hidden states of all layers. See ``hidden_states`` under returned tensors\n                for more detail.\n            return_dict (:obj:`bool`, `optional`):\n                Whether or not to return a :class:`~transformers.file_utils.ModelOutput` instead of a plain tuple.\n        \"\"\"", "\n", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "use_cache", "=", "use_cache", "if", "use_cache", "is", "not", "None", "else", "self", ".", "config", ".", "use_cache", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "# retrieve input_ids and inputs_embeds", "\n", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both decoder_input_ids and decoder_inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either decoder_input_ids or decoder_inputs_embeds\"", ")", "\n", "\n", "# past_key_values_length", "\n", "", "past_key_values_length", "=", "past_key_values", "[", "0", "]", "[", "0", "]", ".", "shape", "[", "2", "]", "if", "past_key_values", "is", "not", "None", "else", "0", "\n", "\n", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "embed_tokens", "(", "input_ids", ")", "*", "self", ".", "embed_scale", "\n", "\n", "", "attention_mask", "=", "self", ".", "_prepare_decoder_attention_mask", "(", "\n", "attention_mask", ",", "input_shape", ",", "inputs_embeds", ",", "past_key_values_length", "\n", ")", "\n", "\n", "# expand encoder attention mask", "\n", "if", "encoder_hidden_states", "is", "not", "None", "and", "encoder_attention_mask", "is", "not", "None", ":", "\n", "# [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]", "\n", "            ", "encoder_attention_mask", "=", "_expand_mask", "(", "encoder_attention_mask", ",", "inputs_embeds", ".", "dtype", ",", "tgt_len", "=", "input_shape", "[", "-", "1", "]", ")", "\n", "\n", "# embed positions", "\n", "", "positions", "=", "self", ".", "embed_positions", "(", "input_shape", ",", "past_key_values_length", ")", "\n", "\n", "hidden_states", "=", "inputs_embeds", "+", "positions", "\n", "hidden_states", "=", "self", ".", "layernorm_embedding", "(", "hidden_states", ")", "\n", "\n", "hidden_states", "=", "F", ".", "dropout", "(", "hidden_states", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# decoder layers", "\n", "all_hidden_states", "=", "(", ")", "if", "output_hidden_states", "else", "None", "\n", "all_self_attns", "=", "(", ")", "if", "output_attentions", "else", "None", "\n", "all_cross_attentions", "=", "(", ")", "if", "(", "output_attentions", "and", "encoder_hidden_states", "is", "not", "None", ")", "else", "None", "\n", "next_decoder_cache", "=", "(", ")", "if", "use_cache", "else", "None", "\n", "\n", "# check if head_mask has a correct number of layers specified if desired", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "assert", "head_mask", ".", "size", "(", ")", "[", "0", "]", "==", "(", "\n", "len", "(", "self", ".", "layers", ")", "\n", ")", ",", "f\"The head_mask should be specified for {len(self.layers)} layers, but it is for {head_mask.size()[0]}.\"", "\n", "", "for", "idx", ",", "decoder_layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "# add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)", "\n", "            ", "if", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "+=", "(", "hidden_states", ",", ")", "\n", "", "dropout_probability", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "training", "and", "(", "dropout_probability", "<", "self", ".", "layerdrop", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "past_key_value", "=", "past_key_values", "[", "idx", "]", "if", "past_key_values", "is", "not", "None", "else", "None", "\n", "\n", "if", "getattr", "(", "self", ".", "config", ",", "\"gradient_checkpointing\"", ",", "False", ")", "and", "self", ".", "training", ":", "\n", "\n", "                ", "if", "use_cache", ":", "\n", "                    ", "logger", ".", "warn", "(", "\n", "\"`use_cache=True` is incompatible with `config.gradient_checkpointing=True`. Setting \"", "\n", "\"`use_cache=False`...\"", "\n", ")", "\n", "use_cache", "=", "False", "\n", "\n", "", "def", "create_custom_forward", "(", "module", ")", ":", "\n", "                    ", "def", "custom_forward", "(", "*", "inputs", ")", ":", "\n", "# None for past_key_value", "\n", "                        ", "return", "module", "(", "*", "inputs", ",", "output_attentions", ",", "use_cache", ")", "\n", "\n", "", "return", "custom_forward", "\n", "\n", "", "layer_outputs", "=", "torch", ".", "utils", ".", "checkpoint", ".", "checkpoint", "(", "\n", "create_custom_forward", "(", "decoder_layer", ")", ",", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", "head_mask", "[", "idx", "]", "if", "head_mask", "is", "not", "None", "else", "None", ",", "\n", "encoder_head_mask", "[", "idx", "]", "if", "encoder_head_mask", "is", "not", "None", "else", "None", ",", "\n", "None", ",", "\n", ")", "\n", "", "else", ":", "\n", "\n", "                ", "layer_outputs", "=", "decoder_layer", "(", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_attention_mask", ",", "\n", "layer_head_mask", "=", "(", "head_mask", "[", "idx", "]", "if", "head_mask", "is", "not", "None", "else", "None", ")", ",", "\n", "encoder_layer_head_mask", "=", "(", "encoder_head_mask", "[", "idx", "]", "if", "encoder_head_mask", "is", "not", "None", "else", "None", ")", ",", "\n", "past_key_value", "=", "past_key_value", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", ")", "\n", "", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "\n", "if", "use_cache", ":", "\n", "                ", "next_decoder_cache", "+=", "(", "layer_outputs", "[", "3", "if", "output_attentions", "else", "1", "]", ",", ")", "\n", "\n", "", "if", "output_attentions", ":", "\n", "                ", "all_self_attns", "+=", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "\n", "if", "encoder_hidden_states", "is", "not", "None", ":", "\n", "                    ", "all_cross_attentions", "+=", "(", "layer_outputs", "[", "2", "]", ",", ")", "\n", "\n", "# add hidden states from the last decoder layer", "\n", "", "", "", "if", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "+=", "(", "hidden_states", ",", ")", "\n", "\n", "", "next_cache", "=", "next_decoder_cache", "if", "use_cache", "else", "None", "\n", "if", "not", "return_dict", ":", "\n", "            ", "return", "tuple", "(", "\n", "v", "\n", "for", "v", "in", "[", "hidden_states", ",", "next_cache", ",", "all_hidden_states", ",", "all_self_attns", ",", "all_cross_attentions", "]", "\n", "if", "v", "is", "not", "None", "\n", ")", "\n", "", "return", "BaseModelOutputWithPastAndCrossAttentions", "(", "\n", "last_hidden_state", "=", "hidden_states", ",", "\n", "past_key_values", "=", "next_cache", ",", "\n", "hidden_states", "=", "all_hidden_states", ",", "\n", "attentions", "=", "all_self_attns", ",", "\n", "cross_attentions", "=", "all_cross_attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartModel.__init__": [[1249, 1261], ["transformers.modeling_utils.PreTrainedModel.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "modeling_bart.BartEncoder", "modeling_bart.BartDecoder", "modeling_bart.BartModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ",", "\n", "fusion_layer", "=", "None", ",", "use_img_trans", "=", "None", ",", "use_forget_gate", "=", "None", ",", "cross_attn_type", "=", "None", ",", "dim_common", "=", "256", ",", "n_attn_heads", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "padding_idx", ",", "vocab_size", "=", "config", ".", "pad_token_id", ",", "config", ".", "vocab_size", "\n", "self", ".", "shared", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "config", ".", "d_model", ",", "padding_idx", ")", "\n", "\n", "self", ".", "encoder", "=", "BartEncoder", "(", "config", ",", "self", ".", "shared", ",", "\n", "fusion_layer", ",", "use_img_trans", ",", "use_forget_gate", ",", "cross_attn_type", ",", "dim_common", ",", "n_attn_heads", ")", "\n", "self", ".", "decoder", "=", "BartDecoder", "(", "config", ",", "self", ".", "shared", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartModel.get_input_embeddings": [[1262, 1264], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "shared", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartModel.set_input_embeddings": [[1265, 1269], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "shared", "=", "value", "\n", "self", ".", "encoder", ".", "embed_tokens", "=", "self", ".", "shared", "\n", "self", ".", "decoder", ".", "embed_tokens", "=", "self", ".", "shared", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartModel.get_encoder": [[1270, 1272], ["None"], "methods", ["None"], ["", "def", "get_encoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartModel.get_decoder": [[1273, 1275], ["None"], "methods", ["None"], ["", "def", "get_decoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartModel.forward": [[1276, 1364], ["transformers.file_utils.add_start_docstrings_to_model_forward", "transformers.file_utils.add_code_sample_docstrings", "modeling_bart.BartModel.decoder", "transformers.modeling_outputs.Seq2SeqModelOutput", "modeling_bart.shift_tokens_right", "modeling_bart.BartModel.encoder", "transformers.modeling_outputs.BaseModelOutput", "isinstance", "len", "len"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.shift_tokens_right"], ["", "@", "add_start_docstrings_to_model_forward", "(", "BART_INPUTS_DOCSTRING", ")", "\n", "@", "add_code_sample_docstrings", "(", "\n", "tokenizer_class", "=", "_TOKENIZER_FOR_DOC", ",", "\n", "checkpoint", "=", "\"facebook/bart-large\"", ",", "\n", "output_type", "=", "Seq2SeqModelOutput", ",", "\n", "config_class", "=", "_CONFIG_FOR_DOC", ",", "\n", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "decoder_head_mask", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "decoder_inputs_embeds", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "image_features", "=", "None", ",", "\n", "image_len", "=", "None", "\n", ")", ":", "\n", "# different to other models, Bart automatically creates decoder_input_ids from", "\n", "# input_ids if no decoder_input_ids are provided", "\n", "        ", "if", "decoder_input_ids", "is", "None", "and", "decoder_inputs_embeds", "is", "None", ":", "\n", "            ", "decoder_input_ids", "=", "shift_tokens_right", "(", "\n", "input_ids", ",", "self", ".", "config", ".", "pad_token_id", ",", "self", ".", "config", ".", "decoder_start_token_id", "\n", ")", "\n", "\n", "", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "use_cache", "=", "use_cache", "if", "use_cache", "is", "not", "None", "else", "self", ".", "config", ".", "use_cache", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "if", "encoder_outputs", "is", "None", ":", "\n", "            ", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", "image_features", "=", "image_features", ",", "\n", "image_len", "=", "image_len", "\n", ")", "\n", "# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True", "\n", "", "elif", "return_dict", "and", "not", "isinstance", "(", "encoder_outputs", ",", "BaseModelOutput", ")", ":", "\n", "            ", "encoder_outputs", "=", "BaseModelOutput", "(", "\n", "last_hidden_state", "=", "encoder_outputs", "[", "0", "]", ",", "\n", "hidden_states", "=", "encoder_outputs", "[", "1", "]", "if", "len", "(", "encoder_outputs", ")", ">", "1", "else", "None", ",", "\n", "attentions", "=", "encoder_outputs", "[", "2", "]", "if", "len", "(", "encoder_outputs", ")", ">", "2", "else", "None", ",", "\n", ")", "\n", "\n", "# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)", "\n", "", "decoder_outputs", "=", "self", ".", "decoder", "(", "\n", "input_ids", "=", "decoder_input_ids", ",", "\n", "attention_mask", "=", "decoder_attention_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_outputs", "[", "0", "]", ",", "\n", "encoder_attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "decoder_head_mask", ",", "\n", "encoder_head_mask", "=", "head_mask", ",", "\n", "past_key_values", "=", "past_key_values", ",", "\n", "inputs_embeds", "=", "decoder_inputs_embeds", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "if", "not", "return_dict", ":", "\n", "            ", "return", "decoder_outputs", "+", "encoder_outputs", "\n", "\n", "", "return", "Seq2SeqModelOutput", "(", "\n", "last_hidden_state", "=", "decoder_outputs", ".", "last_hidden_state", ",", "\n", "past_key_values", "=", "decoder_outputs", ".", "past_key_values", ",", "\n", "decoder_hidden_states", "=", "decoder_outputs", ".", "hidden_states", ",", "\n", "decoder_attentions", "=", "decoder_outputs", ".", "attentions", ",", "\n", "cross_attentions", "=", "decoder_outputs", ".", "cross_attentions", ",", "\n", "encoder_last_hidden_state", "=", "encoder_outputs", ".", "last_hidden_state", ",", "\n", "encoder_hidden_states", "=", "encoder_outputs", ".", "hidden_states", ",", "\n", "encoder_attentions", "=", "encoder_outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartForMultiModalGeneration.__init__": [[1379, 1386], ["transformers.modeling_utils.PreTrainedModel.__init__", "modeling_bart.BartModel", "modeling_bart.BartForMultiModalGeneration.register_buffer", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "modeling_bart.BartForMultiModalGeneration.init_weights", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ",", "fusion_layer", "=", "None", ",", "use_img_trans", "=", "None", ",", "use_forget_gate", "=", "None", ",", "cross_attn_type", "=", "None", ",", "dim_common", "=", "256", ",", "n_attn_heads", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "model", "=", "BartModel", "(", "config", ",", "fusion_layer", ",", "use_img_trans", ",", "use_forget_gate", ",", "cross_attn_type", ",", "dim_common", ",", "n_attn_heads", ")", "\n", "self", ".", "register_buffer", "(", "\"final_logits_bias\"", ",", "torch", ".", "zeros", "(", "(", "1", ",", "self", ".", "model", ".", "shared", ".", "num_embeddings", ")", ")", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "self", ".", "model", ".", "shared", ".", "num_embeddings", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartForMultiModalGeneration.get_encoder": [[1387, 1389], ["modeling_bart.BartForMultiModalGeneration.model.get_encoder"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.get_encoder"], ["", "def", "get_encoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "get_encoder", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartForMultiModalGeneration.get_decoder": [[1390, 1392], ["modeling_bart.BartForMultiModalGeneration.model.get_decoder"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5ForMultiModalGeneration.get_decoder"], ["", "def", "get_decoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "get_decoder", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartForMultiModalGeneration.resize_token_embeddings": [[1393, 1397], ["super().resize_token_embeddings", "modeling_bart.BartForMultiModalGeneration._resize_final_logits_bias"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartForMultiModalGeneration.resize_token_embeddings", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartForMultiModalGeneration._resize_final_logits_bias"], ["", "def", "resize_token_embeddings", "(", "self", ",", "new_num_tokens", ":", "int", ")", "->", "nn", ".", "Embedding", ":", "\n", "        ", "new_embeddings", "=", "super", "(", ")", ".", "resize_token_embeddings", "(", "new_num_tokens", ")", "\n", "self", ".", "_resize_final_logits_bias", "(", "new_num_tokens", ")", "\n", "return", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartForMultiModalGeneration._resize_final_logits_bias": [[1398, 1406], ["modeling_bart.BartForMultiModalGeneration.register_buffer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "_resize_final_logits_bias", "(", "self", ",", "new_num_tokens", ":", "int", ")", "->", "None", ":", "\n", "        ", "old_num_tokens", "=", "self", ".", "final_logits_bias", ".", "shape", "[", "-", "1", "]", "\n", "if", "new_num_tokens", "<=", "old_num_tokens", ":", "\n", "            ", "new_bias", "=", "self", ".", "final_logits_bias", "[", ":", ",", ":", "new_num_tokens", "]", "\n", "", "else", ":", "\n", "            ", "extra_bias", "=", "torch", ".", "zeros", "(", "(", "1", ",", "new_num_tokens", "-", "old_num_tokens", ")", ",", "device", "=", "self", ".", "final_logits_bias", ".", "device", ")", "\n", "new_bias", "=", "torch", ".", "cat", "(", "[", "self", ".", "final_logits_bias", ",", "extra_bias", "]", ",", "dim", "=", "1", ")", "\n", "", "self", ".", "register_buffer", "(", "\"final_logits_bias\"", ",", "new_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartForMultiModalGeneration.get_output_embeddings": [[1407, 1409], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartForMultiModalGeneration.set_output_embeddings": [[1410, 1412], ["None"], "methods", ["None"], ["", "def", "set_output_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "lm_head", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartForMultiModalGeneration.forward": [[1413, 1492], ["transformers.file_utils.add_start_docstrings_to_model_forward", "transformers.file_utils.replace_return_docstrings", "transformers.file_utils.add_end_docstrings", "modeling_bart.BartForMultiModalGeneration.model", "transformers.modeling_outputs.Seq2SeqLMOutput", "modeling_bart.BartForMultiModalGeneration.lm_head", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_bart.shift_tokens_right", "lm_logits.view", "labels.view"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.shift_tokens_right"], ["", "@", "add_start_docstrings_to_model_forward", "(", "BART_INPUTS_DOCSTRING", ")", "\n", "@", "replace_return_docstrings", "(", "output_type", "=", "Seq2SeqLMOutput", ",", "config_class", "=", "_CONFIG_FOR_DOC", ")", "\n", "@", "add_end_docstrings", "(", "BART_GENERATION_EXAMPLE", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "decoder_head_mask", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "decoder_inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "image_features", "=", "None", ",", "\n", "image_len", "=", "None", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n            Labels for computing the masked language modeling loss. Indices should either be in ``[0, ...,\n            config.vocab_size]`` or -100 (see ``input_ids`` docstring). Tokens with indices set to ``-100`` are ignored\n            (masked), the loss is only computed for the tokens with labels in ``[0, ..., config.vocab_size]``.\n\n        Returns:\n        \"\"\"", "\n", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "decoder_input_ids", "is", "None", ":", "\n", "                ", "decoder_input_ids", "=", "shift_tokens_right", "(", "\n", "labels", ",", "self", ".", "config", ".", "pad_token_id", ",", "self", ".", "config", ".", "decoder_start_token_id", "\n", ")", "\n", "\n", "", "", "outputs", "=", "self", ".", "model", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "encoder_outputs", "=", "encoder_outputs", ",", "\n", "decoder_attention_mask", "=", "decoder_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "decoder_head_mask", "=", "decoder_head_mask", ",", "\n", "past_key_values", "=", "past_key_values", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "decoder_inputs_embeds", "=", "decoder_inputs_embeds", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", "image_features", "=", "image_features", ",", "\n", "image_len", "=", "image_len", "\n", ")", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "outputs", "[", "0", "]", ")", "+", "self", ".", "final_logits_bias", "\n", "\n", "masked_lm_loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "lm_logits", ",", ")", "+", "outputs", "[", "1", ":", "]", "\n", "return", "(", "(", "masked_lm_loss", ",", ")", "+", "output", ")", "if", "masked_lm_loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "Seq2SeqLMOutput", "(", "\n", "loss", "=", "masked_lm_loss", ",", "\n", "logits", "=", "lm_logits", ",", "\n", "past_key_values", "=", "outputs", ".", "past_key_values", ",", "\n", "decoder_hidden_states", "=", "outputs", ".", "decoder_hidden_states", ",", "\n", "decoder_attentions", "=", "outputs", ".", "decoder_attentions", ",", "\n", "cross_attentions", "=", "outputs", ".", "cross_attentions", ",", "\n", "encoder_last_hidden_state", "=", "outputs", ".", "encoder_last_hidden_state", ",", "\n", "encoder_hidden_states", "=", "outputs", ".", "encoder_hidden_states", ",", "\n", "encoder_attentions", "=", "outputs", ".", "encoder_attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartForMultiModalGeneration.prepare_inputs_for_generation": [[1494, 1516], ["None"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "\n", "self", ",", "\n", "decoder_input_ids", ",", "\n", "past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "# cut decoder_input_ids if past is used", "\n", "        ", "if", "past", "is", "not", "None", ":", "\n", "            ", "decoder_input_ids", "=", "decoder_input_ids", "[", ":", ",", "-", "1", ":", "]", "\n", "\n", "", "return", "{", "\n", "\"input_ids\"", ":", "None", ",", "# encoder_outputs is defined. input_ids not needed", "\n", "\"encoder_outputs\"", ":", "encoder_outputs", ",", "\n", "\"past_key_values\"", ":", "past", ",", "\n", "\"decoder_input_ids\"", ":", "decoder_input_ids", ",", "\n", "\"attention_mask\"", ":", "attention_mask", ",", "\n", "\"head_mask\"", ":", "head_mask", ",", "\n", "\"use_cache\"", ":", "use_cache", ",", "# change this to avoid caching (presumably for debugging)", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartForMultiModalGeneration.adjust_logits_during_generation": [[1518, 1524], ["modeling_bart.BartForMultiModalGeneration._force_token_id_to_be_generated", "modeling_bart.BartForMultiModalGeneration._force_token_id_to_be_generated"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartForMultiModalGeneration._force_token_id_to_be_generated", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartForMultiModalGeneration._force_token_id_to_be_generated"], ["", "def", "adjust_logits_during_generation", "(", "self", ",", "logits", ",", "cur_len", ",", "max_length", ")", ":", "\n", "        ", "if", "cur_len", "==", "1", "and", "self", ".", "config", ".", "force_bos_token_to_be_generated", ":", "\n", "            ", "self", ".", "_force_token_id_to_be_generated", "(", "logits", ",", "self", ".", "config", ".", "bos_token_id", ")", "\n", "", "elif", "cur_len", "==", "max_length", "-", "1", "and", "self", ".", "config", ".", "eos_token_id", "is", "not", "None", ":", "\n", "            ", "self", ".", "_force_token_id_to_be_generated", "(", "logits", ",", "self", ".", "config", ".", "eos_token_id", ")", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartForMultiModalGeneration._force_token_id_to_be_generated": [[1525, 1529], ["float", "range"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_force_token_id_to_be_generated", "(", "scores", ",", "token_id", ")", "->", "None", ":", "\n", "        ", "\"\"\"force one of token_ids to be generated by setting prob of all other tokens to 0 (logprob=-float(\"inf\"))\"\"\"", "\n", "scores", "[", ":", ",", "[", "x", "for", "x", "in", "range", "(", "scores", ".", "shape", "[", "1", "]", ")", "if", "x", "!=", "token_id", "]", "]", "=", "-", "float", "(", "\"inf\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.BartForMultiModalGeneration._reorder_cache": [[1530, 1539], ["tuple", "past_state.index_select"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_reorder_cache", "(", "past", ",", "beam_idx", ")", ":", "\n", "        ", "reordered_past", "=", "(", ")", "\n", "for", "layer_past", "in", "past", ":", "\n", "# cached cross_attention states don't have to be reordered -> they are always the same", "\n", "            ", "reordered_past", "+=", "(", "\n", "tuple", "(", "past_state", ".", "index_select", "(", "0", ",", "beam_idx", ")", "for", "past_state", "in", "layer_past", "[", ":", "2", "]", ")", "+", "layer_past", "[", "2", ":", "]", ",", "\n", ")", "\n", "", "return", "reordered_past", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart.shift_tokens_right": [[63, 76], ["input_ids.new_zeros", "input_ids[].clone", "input_ids.new_zeros.masked_fill_"], "function", ["None"], ["def", "shift_tokens_right", "(", "input_ids", ":", "torch", ".", "Tensor", ",", "pad_token_id", ":", "int", ",", "decoder_start_token_id", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Shift input ids one token to the right.\n    \"\"\"", "\n", "shifted_input_ids", "=", "input_ids", ".", "new_zeros", "(", "input_ids", ".", "shape", ")", "\n", "shifted_input_ids", "[", ":", ",", "1", ":", "]", "=", "input_ids", "[", ":", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "shifted_input_ids", "[", ":", ",", "0", "]", "=", "decoder_start_token_id", "\n", "\n", "assert", "pad_token_id", "is", "not", "None", ",", "\"self.model.config.pad_token_id has to be defined.\"", "\n", "# replace possible -100 values in labels by `pad_token_id`", "\n", "shifted_input_ids", ".", "masked_fill_", "(", "shifted_input_ids", "==", "-", "100", ",", "pad_token_id", ")", "\n", "\n", "return", "shifted_input_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart._make_causal_mask": [[78, 91], ["torch.full", "torch.full", "torch.full", "torch.arange", "torch.arange", "torch.arange", "torch.cat.masked_fill_", "torch.cat.to", "mask[].expand", "float", "torch.cat.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.zeros", "torch.zeros", "torch.zeros"], "function", ["None"], ["", "def", "_make_causal_mask", "(", "input_ids_shape", ":", "torch", ".", "Size", ",", "dtype", ":", "torch", ".", "dtype", ",", "past_key_values_length", ":", "int", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Make causal mask used for bi-directional self-attention.\n    \"\"\"", "\n", "bsz", ",", "tgt_len", "=", "input_ids_shape", "\n", "mask", "=", "torch", ".", "full", "(", "(", "tgt_len", ",", "tgt_len", ")", ",", "float", "(", "\"-inf\"", ")", ")", "\n", "mask_cond", "=", "torch", ".", "arange", "(", "mask", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", ".", "masked_fill_", "(", "mask_cond", "<", "(", "mask_cond", "+", "1", ")", ".", "view", "(", "mask", ".", "size", "(", "-", "1", ")", ",", "1", ")", ",", "0", ")", "\n", "mask", "=", "mask", ".", "to", "(", "dtype", ")", "\n", "\n", "if", "past_key_values_length", ">", "0", ":", "\n", "        ", "mask", "=", "torch", ".", "cat", "(", "[", "torch", ".", "zeros", "(", "tgt_len", ",", "past_key_values_length", ",", "dtype", "=", "dtype", ")", ",", "mask", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "return", "mask", "[", "None", ",", "None", ",", ":", ",", ":", "]", ".", "expand", "(", "bsz", ",", "1", ",", "tgt_len", ",", "tgt_len", "+", "past_key_values_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_bart._expand_mask": [[93, 105], ["mask.size", "mask[].expand().to", "inverted_mask.masked_fill", "inverted_mask.bool", "mask[].expand", "torch.finfo", "torch.finfo", "torch.finfo"], "function", ["None"], ["", "def", "_expand_mask", "(", "mask", ":", "torch", ".", "Tensor", ",", "dtype", ":", "torch", ".", "dtype", ",", "tgt_len", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Expands attention_mask from `[bsz, seq_len]` to `[bsz, 1, tgt_seq_len, src_seq_len]`.\n    \"\"\"", "\n", "bsz", ",", "src_len", "=", "mask", ".", "size", "(", ")", "\n", "tgt_len", "=", "tgt_len", "if", "tgt_len", "is", "not", "None", "else", "src_len", "\n", "\n", "expanded_mask", "=", "mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", ".", "expand", "(", "bsz", ",", "1", ",", "tgt_len", ",", "src_len", ")", ".", "to", "(", "dtype", ")", "\n", "\n", "inverted_mask", "=", "1.0", "-", "expanded_mask", "\n", "\n", "return", "inverted_mask", ".", "masked_fill", "(", "inverted_mask", ".", "bool", "(", ")", ",", "torch", ".", "finfo", "(", "dtype", ")", ".", "min", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5LayerNorm.__init__": [[231, 238], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "eps", "=", "1e-6", ")", ":", "\n", "        ", "\"\"\"\n        Construct a layernorm module in the T5 style No bias and no subtraction of mean.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "hidden_size", ")", ")", "\n", "self", ".", "variance_epsilon", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5LayerNorm.forward": [[239, 248], ["hidden_states.to.to.to().pow().mean", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "hidden_states.to.to.to", "hidden_states.to.to.to().pow", "hidden_states.to.to.to"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# layer norm should always be calculated in float32", "\n", "        ", "variance", "=", "hidden_states", ".", "to", "(", "torch", ".", "float32", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "hidden_states", "=", "hidden_states", "*", "torch", ".", "rsqrt", "(", "variance", "+", "self", ".", "variance_epsilon", ")", "\n", "\n", "# convert into float16 if necessary", "\n", "if", "self", ".", "weight", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "            ", "hidden_states", "=", "hidden_states", ".", "to", "(", "torch", ".", "float16", ")", "\n", "", "return", "self", ".", "weight", "*", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5DenseReluDense.__init__": [[251, 256], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "wi", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "d_ff", ",", "bias", "=", "False", ")", "\n", "self", ".", "wo", "=", "nn", ".", "Linear", "(", "config", ".", "d_ff", ",", "config", ".", "d_model", ",", "bias", "=", "False", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5DenseReluDense.forward": [[257, 263], ["modeling_t5.T5DenseReluDense.wi", "torch.relu", "torch.relu", "modeling_t5.T5DenseReluDense.dropout", "modeling_t5.T5DenseReluDense.wo"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "wi", "(", "hidden_states", ")", "\n", "hidden_states", "=", "F", ".", "relu", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "wo", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5DenseGatedGeluDense.__init__": [[266, 273], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "wi_0", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "d_ff", ",", "bias", "=", "False", ")", "\n", "self", ".", "wi_1", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "d_ff", ",", "bias", "=", "False", ")", "\n", "self", ".", "wo", "=", "nn", ".", "Linear", "(", "config", ".", "d_ff", ",", "config", ".", "d_model", ",", "bias", "=", "False", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "self", ".", "gelu_act", "=", "ACT2FN", "[", "\"gelu_new\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5DenseGatedGeluDense.forward": [[274, 281], ["modeling_t5.T5DenseGatedGeluDense.gelu_act", "modeling_t5.T5DenseGatedGeluDense.wi_1", "modeling_t5.T5DenseGatedGeluDense.dropout", "modeling_t5.T5DenseGatedGeluDense.wo", "modeling_t5.T5DenseGatedGeluDense.wi_0"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_gelu", "=", "self", ".", "gelu_act", "(", "self", ".", "wi_0", "(", "hidden_states", ")", ")", "\n", "hidden_linear", "=", "self", ".", "wi_1", "(", "hidden_states", ")", "\n", "hidden_states", "=", "hidden_gelu", "*", "hidden_linear", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "wo", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5LayerFF.__init__": [[284, 297], ["torch.nn.Module.__init__", "modeling_t5.T5LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "modeling_t5.T5DenseReluDense", "modeling_t5.T5DenseGatedGeluDense", "ValueError"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "feed_forward_proj", "==", "\"relu\"", ":", "\n", "            ", "self", ".", "DenseReluDense", "=", "T5DenseReluDense", "(", "config", ")", "\n", "", "elif", "config", ".", "feed_forward_proj", "==", "\"gated-gelu\"", ":", "\n", "            ", "self", ".", "DenseReluDense", "=", "T5DenseGatedGeluDense", "(", "config", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"{self.config.feed_forward_proj} is not supported. Choose between `relu` and `gated-gelu`\"", "\n", ")", "\n", "\n", "", "self", ".", "layer_norm", "=", "T5LayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5LayerFF.forward": [[298, 303], ["modeling_t5.T5LayerFF.layer_norm", "modeling_t5.T5LayerFF.DenseReluDense", "modeling_t5.T5LayerFF.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "forwarded_states", "=", "self", ".", "layer_norm", "(", "hidden_states", ")", "\n", "forwarded_states", "=", "self", ".", "DenseReluDense", "(", "forwarded_states", ")", "\n", "hidden_states", "=", "hidden_states", "+", "self", ".", "dropout", "(", "forwarded_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Attention.__init__": [[306, 327], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "set", "torch.nn.Embedding", "torch.nn.Embedding"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "T5Config", ",", "has_relative_attention_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "self", ".", "has_relative_attention_bias", "=", "has_relative_attention_bias", "\n", "\n", "self", ".", "relative_attention_num_buckets", "=", "config", ".", "relative_attention_num_buckets", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "key_value_proj_dim", "=", "config", ".", "d_kv", "\n", "self", ".", "n_heads", "=", "config", ".", "num_heads", "\n", "self", ".", "dropout", "=", "config", ".", "dropout_rate", "\n", "self", ".", "inner_dim", "=", "self", ".", "n_heads", "*", "self", ".", "key_value_proj_dim", "\n", "\n", "# Mesh TensorFlow initialization to avoid scaling before softmax", "\n", "self", ".", "q", "=", "nn", ".", "Linear", "(", "self", ".", "d_model", ",", "self", ".", "inner_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "k", "=", "nn", ".", "Linear", "(", "self", ".", "d_model", ",", "self", ".", "inner_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "v", "=", "nn", ".", "Linear", "(", "self", ".", "d_model", ",", "self", ".", "inner_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "o", "=", "nn", ".", "Linear", "(", "self", ".", "inner_dim", ",", "self", ".", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "if", "self", ".", "has_relative_attention_bias", ":", "\n", "            ", "self", ".", "relative_attention_bias", "=", "nn", ".", "Embedding", "(", "self", ".", "relative_attention_num_buckets", ",", "self", ".", "n_heads", ")", "\n", "", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Attention.prune_heads": [[328, 343], ["transformers.modeling_utils.find_pruneable_heads_and_indices", "transformers.modeling_utils.prune_linear_layer", "transformers.modeling_utils.prune_linear_layer", "transformers.modeling_utils.prune_linear_layer", "transformers.modeling_utils.prune_linear_layer", "modeling_t5.T5Attention.pruned_heads.union", "len", "len"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "heads", ",", "index", "=", "find_pruneable_heads_and_indices", "(", "\n", "heads", ",", "self", ".", "n_heads", ",", "self", ".", "key_value_proj_dim", ",", "self", ".", "pruned_heads", "\n", ")", "\n", "# Prune linear layers", "\n", "self", ".", "q", "=", "prune_linear_layer", "(", "self", ".", "q", ",", "index", ")", "\n", "self", ".", "k", "=", "prune_linear_layer", "(", "self", ".", "k", ",", "index", ")", "\n", "self", ".", "v", "=", "prune_linear_layer", "(", "self", ".", "v", ",", "index", ")", "\n", "self", ".", "o", "=", "prune_linear_layer", "(", "self", ".", "o", ",", "index", ",", "dim", "=", "1", ")", "\n", "# Update hyper params", "\n", "self", ".", "n_heads", "=", "self", ".", "n_heads", "-", "len", "(", "heads", ")", "\n", "self", ".", "inner_dim", "=", "self", ".", "key_value_proj_dim", "*", "self", ".", "n_heads", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Attention._relative_position_bucket": [[344, 391], ["torch.min", "torch.min", "torch.min", "torch.min", "torch.where", "torch.where", "torch.where", "torch.where", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.min", "torch.min", "torch.min", "torch.min", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.log", "torch.log", "torch.log", "torch.log", "math.log", "torch.abs.float", "torch.abs.float"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_relative_position_bucket", "(", "relative_position", ",", "bidirectional", "=", "True", ",", "num_buckets", "=", "32", ",", "max_distance", "=", "128", ")", ":", "\n", "        ", "\"\"\"\n        Adapted from Mesh Tensorflow:\n        https://github.com/tensorflow/mesh/blob/0cb87fe07da627bf0b7e60475d59f95ed6b5be3d/mesh_tensorflow/transformer/transformer_layers.py#L593\n\n        Translate relative position to a bucket number for relative attention. The relative position is defined as\n        memory_position - query_position, i.e. the distance in tokens from the attending position to the attended-to\n        position. If bidirectional=False, then positive relative positions are invalid. We use smaller buckets for\n        small absolute relative_position and larger buckets for larger absolute relative_positions. All relative\n        positions >=max_distance map to the same bucket. All relative positions <=-max_distance map to the same bucket.\n        This should allow for more graceful generalization to longer sequences than the model has been trained on\n\n        Args:\n            relative_position: an int32 Tensor\n            bidirectional: a boolean - whether the attention is bidirectional\n            num_buckets: an integer\n            max_distance: an integer\n\n        Returns:\n            a Tensor with the same shape as relative_position, containing int32 values in the range [0, num_buckets)\n        \"\"\"", "\n", "relative_buckets", "=", "0", "\n", "if", "bidirectional", ":", "\n", "            ", "num_buckets", "//=", "2", "\n", "relative_buckets", "+=", "(", "relative_position", ">", "0", ")", ".", "to", "(", "torch", ".", "long", ")", "*", "num_buckets", "\n", "relative_position", "=", "torch", ".", "abs", "(", "relative_position", ")", "\n", "", "else", ":", "\n", "            ", "relative_position", "=", "-", "torch", ".", "min", "(", "relative_position", ",", "torch", ".", "zeros_like", "(", "relative_position", ")", ")", "\n", "# now relative_position is in the range [0, inf)", "\n", "\n", "# half of the buckets are for exact increments in positions", "\n", "", "max_exact", "=", "num_buckets", "//", "2", "\n", "is_small", "=", "relative_position", "<", "max_exact", "\n", "\n", "# The other half of the buckets are for logarithmically bigger bins in positions up to max_distance", "\n", "relative_postion_if_large", "=", "max_exact", "+", "(", "\n", "torch", ".", "log", "(", "relative_position", ".", "float", "(", ")", "/", "max_exact", ")", "\n", "/", "math", ".", "log", "(", "max_distance", "/", "max_exact", ")", "\n", "*", "(", "num_buckets", "-", "max_exact", ")", "\n", ")", ".", "to", "(", "torch", ".", "long", ")", "\n", "relative_postion_if_large", "=", "torch", ".", "min", "(", "\n", "relative_postion_if_large", ",", "torch", ".", "full_like", "(", "relative_postion_if_large", ",", "num_buckets", "-", "1", ")", "\n", ")", "\n", "\n", "relative_buckets", "+=", "torch", ".", "where", "(", "is_small", ",", "relative_position", ",", "relative_postion_if_large", ")", "\n", "return", "relative_buckets", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Attention.compute_bias": [[392, 406], ["modeling_t5.T5Attention._relative_position_bucket", "relative_position_bucket.to.to.to", "modeling_t5.T5Attention.relative_attention_bias", "values.permute().unsqueeze.permute().unsqueeze.permute().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "values.permute().unsqueeze.permute().unsqueeze.permute"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Attention._relative_position_bucket"], ["", "def", "compute_bias", "(", "self", ",", "query_length", ",", "key_length", ")", ":", "\n", "        ", "\"\"\" Compute binned relative position bias \"\"\"", "\n", "context_position", "=", "torch", ".", "arange", "(", "query_length", ",", "dtype", "=", "torch", ".", "long", ")", "[", ":", ",", "None", "]", "\n", "memory_position", "=", "torch", ".", "arange", "(", "key_length", ",", "dtype", "=", "torch", ".", "long", ")", "[", "None", ",", ":", "]", "\n", "relative_position", "=", "memory_position", "-", "context_position", "# shape (query_length, key_length)", "\n", "relative_position_bucket", "=", "self", ".", "_relative_position_bucket", "(", "\n", "relative_position", ",", "# shape (query_length, key_length)", "\n", "bidirectional", "=", "(", "not", "self", ".", "is_decoder", ")", ",", "\n", "num_buckets", "=", "self", ".", "relative_attention_num_buckets", ",", "\n", ")", "\n", "relative_position_bucket", "=", "relative_position_bucket", ".", "to", "(", "self", ".", "relative_attention_bias", ".", "weight", ".", "device", ")", "\n", "values", "=", "self", ".", "relative_attention_bias", "(", "relative_position_bucket", ")", "# shape (query_length, key_length, num_heads)", "\n", "values", "=", "values", ".", "permute", "(", "[", "2", ",", "0", ",", "1", "]", ")", ".", "unsqueeze", "(", "0", ")", "# shape (1, num_heads, query_length, key_length)", "\n", "return", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Attention.forward": [[407, 521], ["modeling_t5.T5Attention.forward.shape"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "mask", "=", "None", ",", "\n", "key_value_states", "=", "None", ",", "\n", "position_bias", "=", "None", ",", "\n", "past_key_value", "=", "None", ",", "\n", "layer_head_mask", "=", "None", ",", "\n", "query_length", "=", "None", ",", "\n", "use_cache", "=", "False", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Self-attention (if key_value_states is None) or attention over source sentence (provided by key_value_states).\n        \"\"\"", "\n", "# Input is (batch_size, seq_length, dim)", "\n", "# Mask is (batch_size, key_length) (non-causal) or (batch_size, key_length, key_length)", "\n", "# past_key_value[0] is (batch_size, n_heads, q_len - 1, dim_per_head)", "\n", "batch_size", ",", "seq_length", "=", "hidden_states", ".", "shape", "[", ":", "2", "]", "\n", "\n", "real_seq_length", "=", "seq_length", "\n", "\n", "if", "past_key_value", "is", "not", "None", ":", "\n", "            ", "assert", "(", "\n", "len", "(", "past_key_value", ")", "==", "2", "\n", ")", ",", "\"past_key_value should have 2 past states: keys and values. Got {} past states\"", ".", "format", "(", "\n", "len", "(", "past_key_value", ")", "\n", ")", "\n", "real_seq_length", "+=", "past_key_value", "[", "0", "]", ".", "shape", "[", "2", "]", "if", "query_length", "is", "None", "else", "query_length", "\n", "\n", "", "key_length", "=", "real_seq_length", "if", "key_value_states", "is", "None", "else", "key_value_states", ".", "shape", "[", "1", "]", "\n", "\n", "def", "shape", "(", "states", ")", ":", "\n", "            ", "\"\"\"  projection \"\"\"", "\n", "return", "states", ".", "view", "(", "batch_size", ",", "-", "1", ",", "self", ".", "n_heads", ",", "self", ".", "key_value_proj_dim", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "def", "unshape", "(", "states", ")", ":", "\n", "            ", "\"\"\"  reshape \"\"\"", "\n", "return", "states", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ",", "self", ".", "inner_dim", ")", "\n", "\n", "", "def", "project", "(", "hidden_states", ",", "proj_layer", ",", "key_value_states", ",", "past_key_value", ")", ":", "\n", "            ", "\"\"\" projects hidden states correctly to key/query states \"\"\"", "\n", "if", "key_value_states", "is", "None", ":", "\n", "# self-attn", "\n", "# (batch_size, n_heads, seq_length, dim_per_head)", "\n", "                ", "hidden_states", "=", "shape", "(", "proj_layer", "(", "hidden_states", ")", ")", "\n", "", "elif", "past_key_value", "is", "None", ":", "\n", "# cross-attn", "\n", "# (batch_size, n_heads, seq_length, dim_per_head)", "\n", "                ", "hidden_states", "=", "shape", "(", "proj_layer", "(", "key_value_states", ")", ")", "\n", "\n", "", "if", "past_key_value", "is", "not", "None", ":", "\n", "                ", "if", "key_value_states", "is", "None", ":", "\n", "# self-attn", "\n", "# (batch_size, n_heads, key_length, dim_per_head)", "\n", "                    ", "hidden_states", "=", "torch", ".", "cat", "(", "[", "past_key_value", ",", "hidden_states", "]", ",", "dim", "=", "2", ")", "\n", "", "else", ":", "\n", "# cross-attn", "\n", "                    ", "hidden_states", "=", "past_key_value", "\n", "", "", "return", "hidden_states", "\n", "\n", "# get query states", "\n", "", "query_states", "=", "shape", "(", "self", ".", "q", "(", "hidden_states", ")", ")", "# (batch_size, n_heads, seq_length, dim_per_head)", "\n", "\n", "# get key/value states", "\n", "key_states", "=", "project", "(", "\n", "hidden_states", ",", "self", ".", "k", ",", "key_value_states", ",", "past_key_value", "[", "0", "]", "if", "past_key_value", "is", "not", "None", "else", "None", "\n", ")", "\n", "value_states", "=", "project", "(", "\n", "hidden_states", ",", "self", ".", "v", ",", "key_value_states", ",", "past_key_value", "[", "1", "]", "if", "past_key_value", "is", "not", "None", "else", "None", "\n", ")", "\n", "\n", "# compute scores", "\n", "scores", "=", "torch", ".", "matmul", "(", "\n", "query_states", ",", "key_states", ".", "transpose", "(", "3", ",", "2", ")", "\n", ")", "# equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), compatible with onnx op>9", "\n", "\n", "if", "position_bias", "is", "None", ":", "\n", "            ", "if", "not", "self", ".", "has_relative_attention_bias", ":", "\n", "                ", "position_bias", "=", "torch", ".", "zeros", "(", "\n", "(", "1", ",", "self", ".", "n_heads", ",", "real_seq_length", ",", "key_length", ")", ",", "device", "=", "scores", ".", "device", ",", "dtype", "=", "scores", ".", "dtype", "\n", ")", "\n", "", "else", ":", "\n", "                ", "position_bias", "=", "self", ".", "compute_bias", "(", "real_seq_length", ",", "key_length", ")", "\n", "\n", "# if key and values are already calculated", "\n", "# we want only the last query position bias", "\n", "", "if", "past_key_value", "is", "not", "None", ":", "\n", "                ", "position_bias", "=", "position_bias", "[", ":", ",", ":", ",", "-", "seq_length", ":", ",", ":", "]", "\n", "\n", "", "if", "mask", "is", "not", "None", ":", "\n", "                ", "position_bias", "=", "position_bias", "+", "mask", "# (batch_size, n_heads, seq_length, key_length)", "\n", "\n", "", "", "scores", "+=", "position_bias", "\n", "attn_weights", "=", "F", ".", "softmax", "(", "scores", ".", "float", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "type_as", "(", "\n", "scores", "\n", ")", "# (batch_size, n_heads, seq_length, key_length)", "\n", "attn_weights", "=", "F", ".", "dropout", "(", "\n", "attn_weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", "\n", ")", "# (batch_size, n_heads, seq_length, key_length)", "\n", "\n", "# Mask heads if we want to", "\n", "if", "layer_head_mask", "is", "not", "None", ":", "\n", "            ", "attn_weights", "=", "attn_weights", "*", "layer_head_mask", "\n", "\n", "", "attn_output", "=", "unshape", "(", "torch", ".", "matmul", "(", "attn_weights", ",", "value_states", ")", ")", "# (batch_size, seq_length, dim)", "\n", "attn_output", "=", "self", ".", "o", "(", "attn_output", ")", "\n", "\n", "present_key_value_state", "=", "(", "key_states", ",", "value_states", ")", "if", "(", "self", ".", "is_decoder", "and", "use_cache", ")", "else", "None", "\n", "outputs", "=", "(", "attn_output", ",", ")", "+", "(", "present_key_value_state", ",", ")", "+", "(", "position_bias", ",", ")", "\n", "\n", "if", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "attn_weights", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5LayerSelfAttention.__init__": [[524, 529], ["torch.nn.Module.__init__", "modeling_t5.T5Attention", "modeling_t5.T5LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "has_relative_attention_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "SelfAttention", "=", "T5Attention", "(", "config", ",", "has_relative_attention_bias", "=", "has_relative_attention_bias", ")", "\n", "self", ".", "layer_norm", "=", "T5LayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5LayerSelfAttention.forward": [[530, 553], ["modeling_t5.T5LayerSelfAttention.layer_norm", "modeling_t5.T5LayerSelfAttention.SelfAttention", "modeling_t5.T5LayerSelfAttention.dropout"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "position_bias", "=", "None", ",", "\n", "layer_head_mask", "=", "None", ",", "\n", "past_key_value", "=", "None", ",", "\n", "use_cache", "=", "False", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "        ", "normed_hidden_states", "=", "self", ".", "layer_norm", "(", "hidden_states", ")", "\n", "attention_output", "=", "self", ".", "SelfAttention", "(", "\n", "normed_hidden_states", ",", "\n", "mask", "=", "attention_mask", ",", "\n", "position_bias", "=", "position_bias", ",", "\n", "layer_head_mask", "=", "layer_head_mask", ",", "\n", "past_key_value", "=", "past_key_value", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "hidden_states", "=", "hidden_states", "+", "self", ".", "dropout", "(", "attention_output", "[", "0", "]", ")", "\n", "outputs", "=", "(", "hidden_states", ",", ")", "+", "attention_output", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5LayerCrossAttention.__init__": [[556, 561], ["torch.nn.Module.__init__", "modeling_t5.T5Attention", "modeling_t5.T5LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "EncDecAttention", "=", "T5Attention", "(", "config", ",", "has_relative_attention_bias", "=", "False", ")", "\n", "self", ".", "layer_norm", "=", "T5LayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5LayerCrossAttention.forward": [[562, 589], ["modeling_t5.T5LayerCrossAttention.layer_norm", "modeling_t5.T5LayerCrossAttention.EncDecAttention", "modeling_t5.T5LayerCrossAttention.dropout"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "key_value_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "position_bias", "=", "None", ",", "\n", "layer_head_mask", "=", "None", ",", "\n", "past_key_value", "=", "None", ",", "\n", "use_cache", "=", "False", ",", "\n", "query_length", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "        ", "normed_hidden_states", "=", "self", ".", "layer_norm", "(", "hidden_states", ")", "\n", "attention_output", "=", "self", ".", "EncDecAttention", "(", "\n", "normed_hidden_states", ",", "\n", "mask", "=", "attention_mask", ",", "\n", "key_value_states", "=", "key_value_states", ",", "\n", "position_bias", "=", "position_bias", ",", "\n", "layer_head_mask", "=", "layer_head_mask", ",", "\n", "past_key_value", "=", "past_key_value", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "query_length", "=", "query_length", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "layer_output", "=", "hidden_states", "+", "self", ".", "dropout", "(", "attention_output", "[", "0", "]", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "attention_output", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Block.__init__": [[592, 601], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "modeling_t5.T5Block.layer.append", "modeling_t5.T5Block.layer.append", "modeling_t5.T5LayerSelfAttention", "modeling_t5.T5Block.layer.append", "modeling_t5.T5LayerFF", "modeling_t5.T5LayerCrossAttention"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "has_relative_attention_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "layer", ".", "append", "(", "T5LayerSelfAttention", "(", "config", ",", "has_relative_attention_bias", "=", "has_relative_attention_bias", ")", ")", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "self", ".", "layer", ".", "append", "(", "T5LayerCrossAttention", "(", "config", ")", ")", "\n", "\n", "", "self", ".", "layer", ".", "append", "(", "T5LayerFF", "(", "config", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Block.forward": [[602, 692], ["torch.isinf().any", "torch.isinf().any", "torch.isinf().any", "torch.isinf().any", "torch.isinf().any", "torch.isinf().any", "torch.isinf().any", "torch.isinf().any", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.isinf().any", "torch.isinf().any", "torch.isinf().any", "torch.isinf().any", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "len", "len", "torch.isinf", "torch.isinf", "torch.isinf", "torch.isinf", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.isinf", "torch.isinf", "torch.isinf", "torch.isinf", "torch.finfo", "torch.finfo", "torch.finfo", "torch.finfo", "torch.isinf", "torch.isinf", "torch.isinf", "torch.isinf", "torch.finfo", "torch.finfo", "torch.finfo", "torch.finfo", "torch.finfo", "torch.finfo", "torch.finfo", "torch.finfo"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "position_bias", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "encoder_decoder_position_bias", "=", "None", ",", "\n", "layer_head_mask", "=", "None", ",", "\n", "encoder_layer_head_mask", "=", "None", ",", "\n", "past_key_value", "=", "None", ",", "\n", "use_cache", "=", "False", ",", "\n", "output_attentions", "=", "False", ",", "\n", "return_dict", "=", "True", ",", "\n", ")", ":", "\n", "\n", "        ", "if", "past_key_value", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "is_decoder", ",", "\"Only decoder can use `past_key_values`\"", "\n", "expected_num_past_key_values", "=", "2", "if", "encoder_hidden_states", "is", "None", "else", "4", "\n", "\n", "error_message", "=", "\"There should be {} past states. 2 (past / key) for self attention.{} Got {} past key / value states\"", ".", "format", "(", "\n", "expected_num_past_key_values", ",", "\n", "\"2 (past / key) for cross attention\"", "if", "expected_num_past_key_values", "==", "4", "else", "\"\"", ",", "\n", "len", "(", "past_key_value", ")", ",", "\n", ")", "\n", "assert", "len", "(", "past_key_value", ")", "==", "expected_num_past_key_values", ",", "error_message", "\n", "\n", "self_attn_past_key_value", "=", "past_key_value", "[", ":", "2", "]", "\n", "cross_attn_past_key_value", "=", "past_key_value", "[", "2", ":", "]", "\n", "", "else", ":", "\n", "            ", "self_attn_past_key_value", ",", "cross_attn_past_key_value", "=", "None", ",", "None", "\n", "\n", "", "self_attention_outputs", "=", "self", ".", "layer", "[", "0", "]", "(", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "position_bias", "=", "position_bias", ",", "\n", "layer_head_mask", "=", "layer_head_mask", ",", "\n", "past_key_value", "=", "self_attn_past_key_value", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "hidden_states", ",", "present_key_value_state", "=", "self_attention_outputs", "[", ":", "2", "]", "\n", "attention_outputs", "=", "self_attention_outputs", "[", "2", ":", "]", "# Keep self-attention outputs and relative position weights", "\n", "\n", "# clamp inf values to enable fp16 training", "\n", "if", "torch", ".", "isinf", "(", "hidden_states", ")", ".", "any", "(", ")", ":", "\n", "            ", "clamp_value", "=", "torch", ".", "finfo", "(", "hidden_states", ".", "dtype", ")", ".", "max", "-", "1000", "\n", "hidden_states", "=", "torch", ".", "clamp", "(", "hidden_states", ",", "min", "=", "-", "clamp_value", ",", "max", "=", "clamp_value", ")", "\n", "\n", "", "do_cross_attention", "=", "self", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", "\n", "if", "do_cross_attention", ":", "\n", "# the actual query length is unknown for cross attention", "\n", "# if using past key value states. Need to inject it here", "\n", "            ", "if", "present_key_value_state", "is", "not", "None", ":", "\n", "                ", "query_length", "=", "present_key_value_state", "[", "0", "]", ".", "shape", "[", "2", "]", "\n", "", "else", ":", "\n", "                ", "query_length", "=", "None", "\n", "\n", "", "cross_attention_outputs", "=", "self", ".", "layer", "[", "1", "]", "(", "\n", "hidden_states", ",", "\n", "key_value_states", "=", "encoder_hidden_states", ",", "\n", "attention_mask", "=", "encoder_attention_mask", ",", "\n", "position_bias", "=", "encoder_decoder_position_bias", ",", "\n", "layer_head_mask", "=", "encoder_layer_head_mask", ",", "\n", "past_key_value", "=", "cross_attn_past_key_value", ",", "\n", "query_length", "=", "query_length", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "hidden_states", "=", "cross_attention_outputs", "[", "0", "]", "\n", "if", "torch", ".", "isinf", "(", "hidden_states", ")", ".", "any", "(", ")", ":", "\n", "                ", "clamp_value", "=", "torch", ".", "finfo", "(", "hidden_states", ".", "dtype", ")", ".", "max", "-", "1000", "\n", "hidden_states", "=", "torch", ".", "clamp", "(", "hidden_states", ",", "min", "=", "-", "clamp_value", ",", "max", "=", "clamp_value", ")", "\n", "\n", "# Combine self attn and cross attn key value states", "\n", "", "if", "present_key_value_state", "is", "not", "None", ":", "\n", "                ", "present_key_value_state", "=", "present_key_value_state", "+", "cross_attention_outputs", "[", "1", "]", "\n", "\n", "# Keep cross-attention outputs and relative position weights", "\n", "", "attention_outputs", "=", "attention_outputs", "+", "cross_attention_outputs", "[", "2", ":", "]", "\n", "\n", "# Apply Feed Forward layer", "\n", "", "hidden_states", "=", "self", ".", "layer", "[", "-", "1", "]", "(", "hidden_states", ")", "\n", "if", "torch", ".", "isinf", "(", "hidden_states", ")", ".", "any", "(", ")", ":", "\n", "            ", "clamp_value", "=", "torch", ".", "finfo", "(", "hidden_states", ".", "dtype", ")", ".", "max", "-", "1000", "\n", "hidden_states", "=", "torch", ".", "clamp", "(", "hidden_states", ",", "min", "=", "-", "clamp_value", ",", "max", "=", "clamp_value", ")", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "\n", "outputs", "=", "outputs", "+", "(", "present_key_value_state", ",", ")", "+", "attention_outputs", "\n", "return", "outputs", "# hidden-states, present_key_value_states, (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5PreTrainedModel.dummy_inputs": [[705, 715], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["@", "property", "\n", "def", "dummy_inputs", "(", "self", ")", ":", "\n", "        ", "input_ids", "=", "torch", ".", "tensor", "(", "DUMMY_INPUTS", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "DUMMY_MASK", ")", "\n", "dummy_inputs", "=", "{", "\n", "\"decoder_input_ids\"", ":", "input_ids", ",", "\n", "\"input_ids\"", ":", "input_ids", ",", "\n", "\"decoder_attention_mask\"", ":", "input_mask", ",", "\n", "}", "\n", "return", "dummy_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5PreTrainedModel._init_weights": [[716, 757], ["isinstance", "module.weight.data.fill_", "isinstance", "module.shared.weight.data.normal_", "isinstance", "module.wi.weight.data.normal_", "module.wo.weight.data.normal_", "isinstance", "hasattr", "module.wi.bias.data.zero_", "hasattr", "module.wo.bias.data.zero_", "module.wi_0.weight.data.normal_", "module.wi_1.weight.data.normal_", "module.wo.weight.data.normal_", "isinstance", "hasattr", "module.wi_0.bias.data.zero_", "hasattr", "module.wi_1.bias.data.zero_", "hasattr", "module.wo.bias.data.zero_", "module.q.weight.data.normal_", "module.k.weight.data.normal_", "module.v.weight.data.normal_", "module.o.weight.data.normal_", "module.relative_attention_bias.weight.data.normal_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights \"\"\"", "\n", "factor", "=", "self", ".", "config", ".", "initializer_factor", "# Used for testing weights initialization", "\n", "if", "isinstance", "(", "module", ",", "T5LayerNorm", ")", ":", "\n", "            ", "module", ".", "weight", ".", "data", ".", "fill_", "(", "factor", "*", "1.0", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "(", "T5Model", ",", "T5ForMultiModalGeneration", ",", "T5EncoderModel", ")", ")", ":", "\n", "# Mesh TensorFlow embeddings initialization", "\n", "# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L1624", "\n", "            ", "module", ".", "shared", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "1.0", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "T5DenseReluDense", ")", ":", "\n", "# Mesh TensorFlow FF initialization", "\n", "# See https://github.com/tensorflow/mesh/blob/master/mesh_tensorflow/transformer/transformer_layers.py#L56", "\n", "# and https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L89", "\n", "            ", "module", ".", "wi", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "self", ".", "config", ".", "d_model", ")", "**", "-", "0.5", ")", ")", "\n", "if", "hasattr", "(", "module", ".", "wi", ",", "\"bias\"", ")", "and", "module", ".", "wi", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "wi", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "module", ".", "wo", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "self", ".", "config", ".", "d_ff", ")", "**", "-", "0.5", ")", ")", "\n", "if", "hasattr", "(", "module", ".", "wo", ",", "\"bias\"", ")", "and", "module", ".", "wo", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "wo", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "T5DenseGatedGeluDense", ")", ":", "\n", "            ", "module", ".", "wi_0", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "self", ".", "config", ".", "d_model", ")", "**", "-", "0.5", ")", ")", "\n", "if", "hasattr", "(", "module", ".", "wi_0", ",", "\"bias\"", ")", "and", "module", ".", "wi_0", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "wi_0", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "module", ".", "wi_1", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "self", ".", "config", ".", "d_model", ")", "**", "-", "0.5", ")", ")", "\n", "if", "hasattr", "(", "module", ".", "wi_1", ",", "\"bias\"", ")", "and", "module", ".", "wi_1", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "wi_1", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "module", ".", "wo", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "self", ".", "config", ".", "d_ff", ")", "**", "-", "0.5", ")", ")", "\n", "if", "hasattr", "(", "module", ".", "wo", ",", "\"bias\"", ")", "and", "module", ".", "wo", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "wo", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "T5Attention", ")", ":", "\n", "# Mesh TensorFlow attention initialization to avoid scaling before softmax", "\n", "# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/attention.py#L136", "\n", "            ", "d_model", "=", "self", ".", "config", ".", "d_model", "\n", "key_value_proj_dim", "=", "self", ".", "config", ".", "d_kv", "\n", "n_heads", "=", "self", ".", "config", ".", "num_heads", "\n", "module", ".", "q", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "d_model", "*", "key_value_proj_dim", ")", "**", "-", "0.5", ")", ")", "\n", "module", ".", "k", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "d_model", "**", "-", "0.5", ")", ")", "\n", "module", ".", "v", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "d_model", "**", "-", "0.5", ")", ")", "\n", "module", ".", "o", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "n_heads", "*", "key_value_proj_dim", ")", "**", "-", "0.5", ")", ")", "\n", "if", "module", ".", "has_relative_attention_bias", ":", "\n", "                ", "module", ".", "relative_attention_bias", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "d_model", ")", "**", "-", "0.5", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5PreTrainedModel._shift_right": [[758, 778], ["input_ids.new_zeros", "input_ids[].clone", "input_ids.new_zeros.masked_fill_", "torch.all().item", "torch.all().item", "torch.all().item", "torch.all().item", "torch.all", "torch.all", "torch.all", "torch.all"], "methods", ["None"], ["", "", "", "def", "_shift_right", "(", "self", ",", "input_ids", ")", ":", "\n", "        ", "decoder_start_token_id", "=", "self", ".", "config", ".", "decoder_start_token_id", "\n", "pad_token_id", "=", "self", ".", "config", ".", "pad_token_id", "\n", "\n", "assert", "(", "\n", "decoder_start_token_id", "is", "not", "None", "\n", ")", ",", "\"self.model.config.decoder_start_token_id has to be defined. In T5 it is usually set to the pad_token_id. See T5 docs for more information\"", "\n", "\n", "# shift inputs to the right", "\n", "shifted_input_ids", "=", "input_ids", ".", "new_zeros", "(", "input_ids", ".", "shape", ")", "\n", "shifted_input_ids", "[", "...", ",", "1", ":", "]", "=", "input_ids", "[", "...", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "shifted_input_ids", "[", "...", ",", "0", "]", "=", "decoder_start_token_id", "\n", "\n", "assert", "pad_token_id", "is", "not", "None", ",", "\"self.model.config.pad_token_id has to be defined.\"", "\n", "# replace possible -100 values in labels by `pad_token_id`", "\n", "shifted_input_ids", ".", "masked_fill_", "(", "shifted_input_ids", "==", "-", "100", ",", "pad_token_id", ")", "\n", "\n", "assert", "torch", ".", "all", "(", "shifted_input_ids", ">=", "0", ")", ".", "item", "(", ")", ",", "\"Verify that `shifted_input_ids` has only positive values\"", "\n", "\n", "return", "shifted_input_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Stack.__init__": [[781, 853], ["transformers.modeling_utils.PreTrainedModel.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "modeling_t5.T5LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "modeling_t5.T5Stack.init_weights", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "models.img_transformer.ImageTransformerEncoder", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "modeling_t5.T5Block", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "range", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "bool", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.MultiheadAttention", "torch.nn.MultiheadAttention", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.MultiheadAttention", "torch.nn.MultiheadAttention", "ValueError", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "embed_tokens", "=", "None", ",", "fusion_layer", "=", "None", ",", "use_img_trans", "=", "None", ",", "use_forget_gate", "=", "None", ",", "cross_attn_type", "=", "None", ",", "dim_common", "=", "256", ",", "n_attn_heads", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "# ==================== Modification Starts ====================", "\n", "self", ".", "fusion_layer", "=", "fusion_layer", "\n", "self", ".", "use_forget_gate", "=", "use_forget_gate", "\n", "self", ".", "use_img_trans", "=", "use_img_trans", "\n", "self", ".", "cross_attn_type", "=", "cross_attn_type", "\n", "if", "not", "self", ".", "is_decoder", ":", "\n", "            ", "if", "self", ".", "use_img_trans", ":", "\n", "                ", "self", ".", "img_transformer", "=", "ImageTransformerEncoder", "(", "d_model", "=", "2048", ",", "num_layers", "=", "4", ",", "num_heads", "=", "8", ",", "dim_feedforward", "=", "2048", ")", "\n", "\n", "# Some global variables", "\n", "", "visual_feature_dim", "=", "2048", "\n", "text_feature_dim", "=", "768", "# 768", "\n", "\n", "if", "cross_attn_type", "==", "0", ":", "\n", "                ", "self", ".", "_linear_1", "=", "nn", ".", "Linear", "(", "visual_feature_dim", ",", "text_feature_dim", ")", "\n", "self", ".", "_linear_2", "=", "nn", ".", "Linear", "(", "text_feature_dim", "+", "visual_feature_dim", ",", "text_feature_dim", ")", "\n", "if", "use_forget_gate", ":", "\n", "                    ", "self", ".", "fg", "=", "nn", ".", "Linear", "(", "visual_feature_dim", "+", "text_feature_dim", ",", "visual_feature_dim", ")", "\n", "", "", "elif", "cross_attn_type", "==", "1", ":", "\n", "                ", "self", ".", "_linear_1", "=", "nn", ".", "Linear", "(", "visual_feature_dim", ",", "text_feature_dim", ")", "\n", "self", ".", "_linear_2", "=", "nn", ".", "Linear", "(", "2", "*", "text_feature_dim", ",", "text_feature_dim", ")", "\n", "if", "use_forget_gate", ":", "\n", "                    ", "self", ".", "fg", "=", "nn", ".", "Linear", "(", "2", "*", "text_feature_dim", ",", "text_feature_dim", ")", "\n", "", "", "elif", "cross_attn_type", "==", "2", ":", "\n", "                ", "self", ".", "_linear_1", "=", "nn", ".", "Linear", "(", "visual_feature_dim", ",", "text_feature_dim", ")", "\n", "if", "use_forget_gate", ":", "\n", "                    ", "self", ".", "fg", "=", "nn", ".", "Linear", "(", "2", "*", "text_feature_dim", ",", "text_feature_dim", ")", "\n", "", "", "elif", "cross_attn_type", "==", "3", ":", "\n", "                ", "self", ".", "_linear_1", "=", "nn", ".", "Linear", "(", "text_feature_dim", ",", "dim_common", ")", "\n", "self", ".", "_linear_2", "=", "nn", ".", "Linear", "(", "visual_feature_dim", ",", "dim_common", ")", "\n", "self", ".", "_linear_3", "=", "nn", ".", "Linear", "(", "text_feature_dim", "+", "visual_feature_dim", ",", "text_feature_dim", ")", "\n", "if", "use_forget_gate", ":", "\n", "                    ", "self", ".", "fg", "=", "nn", ".", "Linear", "(", "visual_feature_dim", "+", "text_feature_dim", ",", "visual_feature_dim", ")", "\n", "", "", "elif", "cross_attn_type", "==", "4", ":", "\n", "                ", "self", ".", "_linear_1", "=", "nn", ".", "Linear", "(", "visual_feature_dim", ",", "dim_common", ")", "# K", "\n", "self", ".", "_linear_2", "=", "nn", ".", "Linear", "(", "visual_feature_dim", ",", "dim_common", ")", "# V", "\n", "self", ".", "_linear_3", "=", "nn", ".", "Linear", "(", "text_feature_dim", ",", "dim_common", ")", "# Q", "\n", "self", ".", "_multi_head_attn", "=", "nn", ".", "MultiheadAttention", "(", "dim_common", ",", "n_attn_heads", ")", "\n", "self", ".", "_linear_4", "=", "nn", ".", "Linear", "(", "text_feature_dim", "+", "dim_common", ",", "text_feature_dim", ")", "\n", "if", "use_forget_gate", ":", "\n", "                    ", "self", ".", "fg", "=", "nn", ".", "Linear", "(", "dim_common", "+", "text_feature_dim", ",", "dim_common", ")", "\n", "", "", "elif", "cross_attn_type", "==", "5", ":", "\n", "                ", "self", ".", "_linear_1", "=", "nn", ".", "Linear", "(", "visual_feature_dim", ",", "dim_common", ")", "# K", "\n", "self", ".", "_linear_2", "=", "nn", ".", "Linear", "(", "visual_feature_dim", ",", "dim_common", ")", "# V", "\n", "self", ".", "_linear_3", "=", "nn", ".", "Linear", "(", "text_feature_dim", ",", "dim_common", ")", "# Q", "\n", "self", ".", "_multi_head_attn", "=", "nn", ".", "MultiheadAttention", "(", "dim_common", ",", "n_attn_heads", ")", "\n", "if", "use_forget_gate", ":", "\n", "                    ", "self", ".", "fg", "=", "nn", ".", "Linear", "(", "dim_common", "+", "text_feature_dim", ",", "dim_common", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Wrong cross_attn_type value!'", ")", "\n", "\n", "# if use_forget_gate:", "\n", "#     self.fg = nn.Linear(visual_feature_dim + text_feature_dim, visual_feature_dim)", "\n", "\n", "", "self", ".", "custom_layer_norm", "=", "nn", ".", "LayerNorm", "(", "text_feature_dim", ")", "\n", "self", ".", "sigmiod", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "# ==================== Modification Ends ====================", "\n", "", "self", ".", "block", "=", "nn", ".", "ModuleList", "(", "\n", "[", "T5Block", "(", "config", ",", "has_relative_attention_bias", "=", "bool", "(", "i", "==", "0", ")", ")", "for", "i", "in", "range", "(", "config", ".", "num_layers", ")", "]", "\n", ")", "\n", "self", ".", "final_layer_norm", "=", "T5LayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "# Model parallel", "\n", "self", ".", "model_parallel", "=", "False", "\n", "self", ".", "device_map", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Stack.parallelize": [[854, 874], ["transformers.file_utils.add_start_docstrings", "transformers.utils.model_parallel_utils.assert_device_map", "modeling_t5.T5Stack.device_map.items", "modeling_t5.T5Stack.embed_tokens.to", "modeling_t5.T5Stack.final_layer_norm.to", "transformers.utils.model_parallel_utils.get_device_map", "len", "str", "len", "range", "modeling_t5.T5Stack.device_map.keys", "str", "max", "modeling_t5.T5Stack.block[].to", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "min", "modeling_t5.T5Stack.device_map.keys", "str", "modeling_t5.T5Stack.device_map.keys"], "methods", ["None"], ["", "@", "add_start_docstrings", "(", "PARALLELIZE_DOCSTRING", ")", "\n", "def", "parallelize", "(", "self", ",", "device_map", "=", "None", ")", ":", "\n", "# Check validity of device_map", "\n", "        ", "self", ".", "device_map", "=", "(", "\n", "get_device_map", "(", "len", "(", "self", ".", "block", ")", ",", "range", "(", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", ")", "if", "device_map", "is", "None", "else", "device_map", "\n", ")", "\n", "assert_device_map", "(", "self", ".", "device_map", ",", "len", "(", "self", ".", "block", ")", ")", "\n", "self", ".", "model_parallel", "=", "True", "\n", "self", ".", "first_device", "=", "\"cpu\"", "if", "\"cpu\"", "in", "self", ".", "device_map", ".", "keys", "(", ")", "else", "\"cuda:\"", "+", "str", "(", "min", "(", "self", ".", "device_map", ".", "keys", "(", ")", ")", ")", "\n", "self", ".", "last_device", "=", "\"cuda:\"", "+", "str", "(", "max", "(", "self", ".", "device_map", ".", "keys", "(", ")", ")", ")", "\n", "# Load onto devices", "\n", "for", "k", ",", "v", "in", "self", ".", "device_map", ".", "items", "(", ")", ":", "\n", "            ", "for", "layer", "in", "v", ":", "\n", "                ", "cuda_device", "=", "\"cuda:\"", "+", "str", "(", "k", ")", "\n", "self", ".", "block", "[", "layer", "]", "=", "self", ".", "block", "[", "layer", "]", ".", "to", "(", "cuda_device", ")", "\n", "\n", "# Set embed_tokens to first layer", "\n", "", "", "self", ".", "embed_tokens", "=", "self", ".", "embed_tokens", ".", "to", "(", "self", ".", "first_device", ")", "\n", "# Set final layer norm to last device", "\n", "self", ".", "final_layer_norm", "=", "self", ".", "final_layer_norm", ".", "to", "(", "self", ".", "last_device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Stack.deparallelize": [[875, 886], ["transformers.file_utils.add_start_docstrings", "range", "modeling_t5.T5Stack.embed_tokens.to", "modeling_t5.T5Stack.final_layer_norm.to", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "len", "modeling_t5.T5Stack.block[].to"], "methods", ["None"], ["", "@", "add_start_docstrings", "(", "PARALLELIZE_DOCSTRING", ")", "\n", "def", "deparallelize", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_parallel", "=", "False", "\n", "self", ".", "device_map", "=", "None", "\n", "self", ".", "first_device", "=", "\"cpu\"", "\n", "self", ".", "last_device", "=", "\"cpu\"", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "block", ")", ")", ":", "\n", "            ", "self", ".", "block", "[", "i", "]", "=", "self", ".", "block", "[", "i", "]", ".", "to", "(", "\"cpu\"", ")", "\n", "", "self", ".", "embed_tokens", "=", "self", ".", "embed_tokens", ".", "to", "(", "\"cpu\"", ")", "\n", "self", ".", "final_layer_norm", "=", "self", ".", "final_layer_norm", ".", "to", "(", "\"cpu\"", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Stack.get_input_embeddings": [[887, 889], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embed_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Stack.set_input_embeddings": [[890, 892], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "embed_tokens", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Stack.forward": [[893, 1162], ["modeling_t5.T5Stack.get_extended_attention_mask", "modeling_t5.T5Stack.get_head_mask", "modeling_t5.T5Stack.get_head_mask", "modeling_t5.T5Stack.dropout", "enumerate", "modeling_t5.T5Stack.final_layer_norm", "modeling_t5.T5Stack.dropout", "transformers.modeling_outputs.BaseModelOutputWithPastAndCrossAttentions", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "modeling_t5.T5Stack.embed_tokens.to", "ValueError", "modeling_t5.T5Stack.embed_tokens", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "modeling_t5.T5Stack.invert_attention_mask", "zip", "layer_module", "tuple", "input_ids.view.view.size", "input_ids.view.view.view", "len", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "modeling_t5.T5Stack.device_map.items", "modeling_t5.T5Stack.fg", "modeling_t5.T5Stack.sigmiod", "modeling_t5.T5Stack.dropout", "modeling_t5.T5Stack.mul", "modeling_t5.T5Stack.dropout", "modeling_t5.T5Stack.custom_layer_norm", "ValueError", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "attention_mask.to.to.to", "position_bias.to.to.to", "encoder_hidden_states.to.to.to", "encoder_extended_attention_mask.to.to.to", "encoder_decoder_position_bias.to.to.to", "layer_head_mask.to.to.to", "encoder_layer_head_mask.to.to.to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_t5.T5Stack._linear_1", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "modeling_t5.T5Stack._linear_2", "modeling_t5.T5Stack.size", "hidden_states.to.to.to", "modeling_t5.T5Stack.transpose", "modeling_t5.T5Stack.forward.forget_gate"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_head_mask", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "image_features", "=", "None", ",", "\n", "image_len", "=", "None", ",", "\n", ")", ":", "\n", "# Model parallel", "\n", "        ", "if", "self", ".", "model_parallel", ":", "\n", "            ", "torch", ".", "cuda", ".", "set_device", "(", "self", ".", "first_device", ")", "\n", "self", ".", "embed_tokens", "=", "self", ".", "embed_tokens", ".", "to", "(", "self", ".", "first_device", ")", "\n", "", "use_cache", "=", "use_cache", "if", "use_cache", "is", "not", "None", "else", "self", ".", "config", ".", "use_cache", "\n", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "err_msg_prefix", "=", "\"decoder_\"", "if", "self", ".", "is_decoder", "else", "\"\"", "\n", "raise", "ValueError", "(", "\n", "f\"You cannot specify both {err_msg_prefix}inputs and {err_msg_prefix}inputs_embeds at the same time\"", "\n", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "err_msg_prefix", "=", "\"decoder_\"", "if", "self", ".", "is_decoder", "else", "\"\"", "\n", "raise", "ValueError", "(", "f\"You have to specify either {err_msg_prefix}inputs or {err_msg_prefix}inputs_embeds\"", ")", "\n", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "assert", "self", ".", "embed_tokens", "is", "not", "None", ",", "\"You have to initialize the model with valid token embeddings\"", "\n", "inputs_embeds", "=", "self", ".", "embed_tokens", "(", "input_ids", ")", "\n", "\n", "", "batch_size", ",", "seq_length", "=", "input_shape", "\n", "\n", "# required mask seq length can be calculated via length of past", "\n", "mask_seq_length", "=", "past_key_values", "[", "0", "]", "[", "0", "]", ".", "shape", "[", "2", "]", "+", "seq_length", "if", "past_key_values", "is", "not", "None", "else", "seq_length", "\n", "\n", "if", "use_cache", "is", "True", ":", "\n", "            ", "assert", "self", ".", "is_decoder", ",", "\":obj:`use_cache` can only be set to `True` if {} is used as a decoder\"", ".", "format", "(", "\n", "self", "\n", ")", "\n", "\n", "", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "batch_size", ",", "mask_seq_length", ")", ".", "to", "(", "inputs_embeds", ".", "device", ")", "\n", "", "if", "self", ".", "is_decoder", "and", "encoder_attention_mask", "is", "None", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "encoder_seq_length", "=", "encoder_hidden_states", ".", "shape", "[", "1", "]", "\n", "encoder_attention_mask", "=", "torch", ".", "ones", "(", "\n", "batch_size", ",", "encoder_seq_length", ",", "device", "=", "inputs_embeds", ".", "device", ",", "dtype", "=", "torch", ".", "long", "\n", ")", "\n", "\n", "# initialize past_key_values with `None` if past does not exist", "\n", "", "if", "past_key_values", "is", "None", ":", "\n", "            ", "past_key_values", "=", "[", "None", "]", "*", "len", "(", "self", ".", "block", ")", "\n", "\n", "# ourselves in which case we just need to make it broadcastable to all heads.", "\n", "", "extended_attention_mask", "=", "self", ".", "get_extended_attention_mask", "(", "attention_mask", ",", "input_shape", ",", "inputs_embeds", ".", "device", ")", "\n", "\n", "if", "self", ".", "is_decoder", "and", "encoder_attention_mask", "is", "not", "None", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "self", ".", "invert_attention_mask", "(", "encoder_attention_mask", ")", "\n", "", "else", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "", "head_mask", "=", "self", ".", "get_head_mask", "(", "head_mask", ",", "self", ".", "config", ".", "num_layers", ")", "\n", "encoder_head_mask", "=", "self", ".", "get_head_mask", "(", "encoder_head_mask", ",", "self", ".", "config", ".", "num_layers", ")", "\n", "present_key_value_states", "=", "(", ")", "if", "use_cache", "else", "None", "\n", "all_hidden_states", "=", "(", ")", "if", "output_hidden_states", "else", "None", "\n", "all_attentions", "=", "(", ")", "if", "output_attentions", "else", "None", "\n", "all_cross_attentions", "=", "(", ")", "if", "(", "output_attentions", "and", "self", ".", "is_decoder", ")", "else", "None", "\n", "position_bias", "=", "None", "\n", "encoder_decoder_position_bias", "=", "None", "\n", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "inputs_embeds", ")", "\n", "\n", "for", "i", ",", "(", "layer_module", ",", "past_key_value", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "block", ",", "past_key_values", ")", ")", ":", "\n", "            ", "layer_head_mask", "=", "head_mask", "[", "i", "]", "\n", "encoder_layer_head_mask", "=", "encoder_head_mask", "[", "i", "]", "\n", "# Model parallel", "\n", "if", "self", ".", "model_parallel", ":", "\n", "                ", "torch", ".", "cuda", ".", "set_device", "(", "hidden_states", ".", "device", ")", "\n", "# Ensure that attention_mask is always on the same device as hidden_states", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                    ", "attention_mask", "=", "attention_mask", ".", "to", "(", "hidden_states", ".", "device", ")", "\n", "", "if", "position_bias", "is", "not", "None", ":", "\n", "                    ", "position_bias", "=", "position_bias", ".", "to", "(", "hidden_states", ".", "device", ")", "\n", "", "if", "encoder_hidden_states", "is", "not", "None", ":", "\n", "                    ", "encoder_hidden_states", "=", "encoder_hidden_states", ".", "to", "(", "hidden_states", ".", "device", ")", "\n", "", "if", "encoder_extended_attention_mask", "is", "not", "None", ":", "\n", "                    ", "encoder_extended_attention_mask", "=", "encoder_extended_attention_mask", ".", "to", "(", "hidden_states", ".", "device", ")", "\n", "", "if", "encoder_decoder_position_bias", "is", "not", "None", ":", "\n", "                    ", "encoder_decoder_position_bias", "=", "encoder_decoder_position_bias", ".", "to", "(", "hidden_states", ".", "device", ")", "\n", "", "if", "layer_head_mask", "is", "not", "None", ":", "\n", "                    ", "layer_head_mask", "=", "layer_head_mask", ".", "to", "(", "hidden_states", ".", "device", ")", "\n", "", "if", "encoder_layer_head_mask", "is", "not", "None", ":", "\n", "                    ", "encoder_layer_head_mask", "=", "encoder_layer_head_mask", ".", "to", "(", "hidden_states", ".", "device", ")", "\n", "", "", "if", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "layer_outputs", "=", "layer_module", "(", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "position_bias", "=", "position_bias", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "\n", "encoder_decoder_position_bias", "=", "encoder_decoder_position_bias", ",", "\n", "layer_head_mask", "=", "layer_head_mask", ",", "\n", "encoder_layer_head_mask", "=", "encoder_layer_head_mask", ",", "\n", "past_key_value", "=", "past_key_value", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "# layer_outputs is a tuple with:", "\n", "# hidden-states, key-value-states, (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)", "\n", "hidden_states", ",", "present_key_value_state", "=", "layer_outputs", "[", ":", "2", "]", "\n", "\n", "# We share the position biases between the layers - the first layer store them", "\n", "# layer_outputs = hidden-states, key-value-states (self-attention weights),", "\n", "# (self-attention position bias), (cross-attention weights), (cross-attention position bias)", "\n", "position_bias", "=", "layer_outputs", "[", "2", "]", "\n", "if", "self", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "                ", "encoder_decoder_position_bias", "=", "layer_outputs", "[", "4", "if", "output_attentions", "else", "3", "]", "\n", "# append next layer key value states", "\n", "", "if", "use_cache", ":", "\n", "                ", "present_key_value_states", "=", "present_key_value_states", "+", "(", "present_key_value_state", ",", ")", "\n", "\n", "", "if", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "3", "]", ",", ")", "\n", "if", "self", ".", "is_decoder", ":", "\n", "                    ", "all_cross_attentions", "=", "all_cross_attentions", "+", "(", "layer_outputs", "[", "5", "]", ",", ")", "\n", "\n", "# Model Parallel: If it's the last layer for that device, put things on the next device", "\n", "", "", "if", "self", ".", "model_parallel", ":", "\n", "                ", "for", "k", ",", "v", "in", "self", ".", "device_map", ".", "items", "(", ")", ":", "\n", "                    ", "if", "i", "==", "v", "[", "-", "1", "]", "and", "\"cuda:\"", "+", "str", "(", "k", ")", "!=", "self", ".", "last_device", ":", "\n", "                        ", "hidden_states", "=", "hidden_states", ".", "to", "(", "\"cuda:\"", "+", "str", "(", "k", "+", "1", ")", ")", "\n", "\n", "", "", "", "", "hidden_states", "=", "self", ".", "final_layer_norm", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "# ==================== text-to-video fusion  =====================", "\n", "if", "not", "self", ".", "is_decoder", ":", "\n", "            ", "def", "forget_gate", "(", "image_features", ",", "text_features", ")", ":", "\n", "                ", "forget_mask", "=", "self", ".", "fg", "(", "torch", ".", "cat", "(", "(", "image_features", ",", "text_features", ")", ",", "2", ")", ")", "\n", "forget_mask", "=", "self", ".", "sigmiod", "(", "forget_mask", ")", "\n", "forget_mask", "=", "self", ".", "dropout", "(", "forget_mask", ")", "\n", "image_features", "=", "forget_mask", ".", "mul", "(", "image_features", ")", "\n", "return", "image_features", "\n", "\n", "", "if", "self", ".", "fusion_layer", ":", "\n", "                ", "if", "self", ".", "cross_attn_type", "==", "0", ":", "\n", "                    ", "image_features_transformed", "=", "self", ".", "_linear_1", "(", "image_features", ")", "\n", "attn", "=", "torch", ".", "bmm", "(", "hidden_states", ",", "image_features_transformed", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "attn", "=", "F", ".", "softmax", "(", "attn", ",", "dim", "=", "1", ")", "\n", "image_features", "=", "torch", ".", "bmm", "(", "attn", ",", "image_features", ")", "# (S_t, D_v)", "\n", "if", "self", ".", "use_forget_gate", ":", "\n", "                        ", "image_features", "=", "forget_gate", "(", "image_features", ",", "hidden_states", ")", "\n", "", "output", "=", "self", ".", "_linear_2", "(", "torch", ".", "cat", "(", "(", "hidden_states", ",", "image_features", ")", ",", "2", ")", ")", "\n", "", "elif", "self", ".", "cross_attn_type", "==", "1", ":", "\n", "                    ", "image_features", "=", "self", ".", "_linear_1", "(", "image_features", ")", "\n", "attn", "=", "torch", ".", "bmm", "(", "hidden_states", ",", "image_features", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "attn", "=", "F", ".", "softmax", "(", "attn", ",", "dim", "=", "1", ")", "\n", "image_features", "=", "torch", ".", "bmm", "(", "attn", ",", "image_features", ")", "# (S_t, D_t)", "\n", "if", "self", ".", "use_forget_gate", ":", "\n", "                        ", "image_features", "=", "forget_gate", "(", "image_features", ",", "hidden_states", ")", "\n", "", "output", "=", "self", ".", "_linear_2", "(", "torch", ".", "cat", "(", "(", "hidden_states", ",", "image_features", ")", ",", "2", ")", ")", "\n", "", "elif", "self", ".", "cross_attn_type", "==", "2", ":", "\n", "                    ", "image_features", "=", "self", ".", "_linear_1", "(", "image_features", ")", "\n", "attn", "=", "torch", ".", "bmm", "(", "hidden_states", ",", "image_features", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "attn", "=", "F", ".", "softmax", "(", "attn", ",", "dim", "=", "1", ")", "\n", "image_features", "=", "torch", ".", "bmm", "(", "attn", ",", "image_features", ")", "# (S_t, D_t)", "\n", "if", "self", ".", "use_forget_gate", ":", "\n", "                        ", "image_features", "=", "forget_gate", "(", "image_features", ",", "hidden_states", ")", "\n", "", "output", "=", "image_features", "\n", "", "elif", "self", ".", "cross_attn_type", "==", "3", ":", "\n", "                    ", "hidden_states_transformed", "=", "self", ".", "_linear_1", "(", "hidden_states", ")", "\n", "image_features_transformed", "=", "self", ".", "_linear_2", "(", "image_features", ")", "\n", "attn", "=", "torch", ".", "bmm", "(", "hidden_states_transformed", ",", "image_features_transformed", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "attn", "=", "F", ".", "softmax", "(", "attn", ",", "dim", "=", "1", ")", "\n", "image_features", "=", "torch", ".", "bmm", "(", "attn", ",", "image_features", ")", "\n", "if", "self", ".", "use_forget_gate", ":", "\n", "                        ", "image_features", "=", "forget_gate", "(", "image_features", ",", "hidden_states", ")", "\n", "", "output", "=", "self", ".", "_linear_3", "(", "torch", ".", "cat", "(", "(", "hidden_states", ",", "image_features", ")", ",", "2", ")", ")", "\n", "", "elif", "self", ".", "cross_attn_type", "==", "4", ":", "\n", "                    ", "K", "=", "self", ".", "_linear_1", "(", "image_features", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "V", "=", "self", ".", "_linear_2", "(", "image_features", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "Q", "=", "self", ".", "_linear_3", "(", "hidden_states", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "attn_output", ",", "_", "=", "self", ".", "_multi_head_attn", "(", "Q", ",", "K", ",", "V", ")", "\n", "attn_output", "=", "attn_output", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "use_forget_gate", ":", "\n", "                        ", "forget_mask", "=", "self", ".", "fg", "(", "torch", ".", "cat", "(", "(", "attn_output", ",", "hidden_states", ")", ",", "2", ")", ")", "\n", "forget_mask", "=", "self", ".", "sigmiod", "(", "forget_mask", ")", "\n", "forget_mask", "=", "self", ".", "dropout", "(", "forget_mask", ")", "\n", "attn_output", "=", "forget_mask", ".", "mul", "(", "attn_output", ")", "\n", "", "output", "=", "self", ".", "_linear_4", "(", "torch", ".", "cat", "(", "(", "hidden_states", ",", "attn_output", ")", ",", "2", ")", ")", "\n", "", "elif", "self", ".", "cross_attn_type", "==", "5", ":", "\n", "                    ", "K", "=", "self", ".", "_linear_1", "(", "image_features", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "V", "=", "self", ".", "_linear_2", "(", "image_features", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "Q", "=", "self", ".", "_linear_3", "(", "hidden_states", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "attn_output", ",", "_", "=", "self", ".", "_multi_head_attn", "(", "Q", ",", "K", ",", "V", ")", "\n", "attn_output", "=", "attn_output", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "use_forget_gate", ":", "\n", "                        ", "forget_mask", "=", "self", ".", "fg", "(", "torch", ".", "cat", "(", "(", "attn_output", ",", "hidden_states", ")", ",", "2", ")", ")", "\n", "forget_mask", "=", "self", ".", "sigmiod", "(", "forget_mask", ")", "\n", "forget_mask", "=", "self", ".", "dropout", "(", "forget_mask", ")", "\n", "attn_output", "=", "forget_mask", ".", "mul", "(", "attn_output", ")", "\n", "", "output", "=", "attn_output", "\n", "\n", "# # make image feature for every text token", "\n", "# image_feature_2 = self.img_feature_transfers[idx](image_features)", "\n", "# att = F.softmax(torch.bmm(hidden_states, torch.transpose(image_feature_2, 1, 2)), dim=1)", "\n", "# image_feature_3 = torch.bmm(att, image_features)", "\n", "\n", "# # forgate gate", "\n", "# forget = self.sigmiod(self.fgs[idx](torch.cat((image_feature_3, hidden_states), 2)))", "\n", "# forget = F.dropout(forget, p=self.dropout, training=self.training)", "\n", "# forget = forget.mul(image_feature_3)", "\n", "\n", "# # Text image fusion", "\n", "# output = self.fcs[idx](torch.cat((hidden_states, forget), 2))", "\n", "", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "\n", "# Residual Connection", "\n", "hidden_states", "=", "hidden_states", "+", "output", "\n", "hidden_states", "=", "self", ".", "custom_layer_norm", "(", "hidden_states", ")", "\n", "# print('='*40)", "\n", "# print('BartEncoder')", "\n", "# print(f'hidden_state shape = {hidden_states.shape}')", "\n", "# # print(hidden_states)", "\n", "# print(f'image_feature shape = {image_feature.shape}')", "\n", "# # print(attention_mask)", "\n", "# print('='*40)", "\n", "# exit()", "\n", "# ==================== text-to-video fusion  =====================", "\n", "\n", "# Add last layer", "\n", "", "", "if", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "return", "tuple", "(", "\n", "v", "\n", "for", "v", "in", "[", "\n", "hidden_states", ",", "\n", "present_key_value_states", ",", "\n", "all_hidden_states", ",", "\n", "all_attentions", ",", "\n", "all_cross_attentions", ",", "\n", "]", "\n", "if", "v", "is", "not", "None", "\n", ")", "\n", "", "return", "BaseModelOutputWithPastAndCrossAttentions", "(", "\n", "last_hidden_state", "=", "hidden_states", ",", "\n", "past_key_values", "=", "present_key_value_states", ",", "\n", "hidden_states", "=", "all_hidden_states", ",", "\n", "attentions", "=", "all_attentions", ",", "\n", "cross_attentions", "=", "all_cross_attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Model.__init__": [[1340, 1361], ["transformers.modeling_utils.PreTrainedModel.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "copy.deepcopy", "modeling_t5.T5Stack", "copy.deepcopy", "modeling_t5.T5Stack", "modeling_t5.T5Model.init_weights"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "T5Config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "shared", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "d_model", ")", "\n", "\n", "encoder_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "encoder_config", ".", "is_decoder", "=", "False", "\n", "encoder_config", ".", "use_cache", "=", "False", "\n", "encoder_config", ".", "is_encoder_decoder", "=", "False", "\n", "self", ".", "encoder", "=", "T5Stack", "(", "encoder_config", ",", "self", ".", "shared", ")", "\n", "\n", "decoder_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "decoder_config", ".", "is_decoder", "=", "True", "\n", "decoder_config", ".", "is_encoder_decoder", "=", "False", "\n", "decoder_config", ".", "num_layers", "=", "config", ".", "num_decoder_layers", "\n", "self", ".", "decoder", "=", "T5Stack", "(", "decoder_config", ",", "self", ".", "shared", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n", "# Model parallel", "\n", "self", ".", "model_parallel", "=", "False", "\n", "self", ".", "device_map", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Model.parallelize": [[1362, 1373], ["transformers.file_utils.add_start_docstrings", "transformers.utils.model_parallel_utils.assert_device_map", "modeling_t5.T5Model.encoder.parallelize", "modeling_t5.T5Model.decoder.parallelize", "transformers.utils.model_parallel_utils.get_device_map", "len", "len", "range", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.parallelize", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.parallelize"], ["", "@", "add_start_docstrings", "(", "PARALLELIZE_DOCSTRING", ")", "\n", "def", "parallelize", "(", "self", ",", "device_map", "=", "None", ")", ":", "\n", "        ", "self", ".", "device_map", "=", "(", "\n", "get_device_map", "(", "len", "(", "self", ".", "encoder", ".", "block", ")", ",", "range", "(", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", ")", "\n", "if", "device_map", "is", "None", "\n", "else", "device_map", "\n", ")", "\n", "assert_device_map", "(", "self", ".", "device_map", ",", "len", "(", "self", ".", "encoder", ".", "block", ")", ")", "\n", "self", ".", "encoder", ".", "parallelize", "(", "self", ".", "device_map", ")", "\n", "self", ".", "decoder", ".", "parallelize", "(", "self", ".", "device_map", ")", "\n", "self", ".", "model_parallel", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Model.deparallelize": [[1374, 1383], ["transformers.file_utils.add_start_docstrings", "modeling_t5.T5Model.encoder.deparallelize", "modeling_t5.T5Model.decoder.deparallelize", "modeling_t5.T5Model.encoder.to", "modeling_t5.T5Model.decoder.to", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.deparallelize", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.deparallelize"], ["", "@", "add_start_docstrings", "(", "DEPARALLELIZE_DOCSTRING", ")", "\n", "def", "deparallelize", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "deparallelize", "(", ")", "\n", "self", ".", "decoder", ".", "deparallelize", "(", ")", "\n", "self", ".", "encoder", "=", "self", ".", "encoder", ".", "to", "(", "\"cpu\"", ")", "\n", "self", ".", "decoder", "=", "self", ".", "decoder", ".", "to", "(", "\"cpu\"", ")", "\n", "self", ".", "model_parallel", "=", "False", "\n", "self", ".", "device_map", "=", "None", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Model.get_input_embeddings": [[1384, 1386], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "shared", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Model.set_input_embeddings": [[1387, 1391], ["modeling_t5.T5Model.encoder.set_input_embeddings", "modeling_t5.T5Model.decoder.set_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.set_input_embeddings", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.set_input_embeddings"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "shared", "=", "new_embeddings", "\n", "self", ".", "encoder", ".", "set_input_embeddings", "(", "new_embeddings", ")", "\n", "self", ".", "decoder", ".", "set_input_embeddings", "(", "new_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Model.get_encoder": [[1392, 1394], ["None"], "methods", ["None"], ["", "def", "get_encoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Model.get_decoder": [[1395, 1397], ["None"], "methods", ["None"], ["", "def", "get_decoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Model._prune_heads": [[1398, 1405], ["heads_to_prune.items", "modeling_t5.T5Model.encoder.layer[].attention.prune_heads"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\"\n        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n        class PreTrainedModel\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Model.forward": [[1406, 1510], ["transformers.file_utils.add_start_docstrings_to_model_forward", "transformers.file_utils.replace_return_docstrings", "modeling_t5.T5Model.decoder", "transformers.modeling_outputs.Seq2SeqModelOutput", "modeling_t5.T5Model.encoder", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "hidden_states.to.to.to", "warnings.warn", "transformers.modeling_outputs.BaseModelOutput", "decoder_input_ids.to.to.to", "attention_mask.to.to.to", "decoder_attention_mask.to.to.to", "isinstance", "len", "len"], "methods", ["None"], ["", "", "@", "add_start_docstrings_to_model_forward", "(", "T5_INPUTS_DOCSTRING", ")", "\n", "@", "replace_return_docstrings", "(", "output_type", "=", "Seq2SeqModelOutput", ",", "config_class", "=", "_CONFIG_FOR_DOC", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "decoder_head_mask", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "decoder_inputs_embeds", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        Returns:\n\n        Example::\n\n            >>> from transformers import T5Tokenizer, T5Model\n\n            >>> tokenizer = T5Tokenizer.from_pretrained('t5-small')\n            >>> model = T5Model.from_pretrained('t5-small')\n\n            >>> input_ids = tokenizer(\"Studies have been shown that owning a dog is good for you\", return_tensors=\"pt\").input_ids  # Batch size 1\n            >>> decoder_input_ids = tokenizer(\"Studies show that\", return_tensors=\"pt\").input_ids  # Batch size 1\n            >>> outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n\n            >>> last_hidden_states = outputs.last_hidden_state\n        \"\"\"", "\n", "use_cache", "=", "use_cache", "if", "use_cache", "is", "not", "None", "else", "self", ".", "config", ".", "use_cache", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "# FutureWarning: head_mask was separated into two input args - head_mask, decoder_head_mask", "\n", "if", "head_mask", "is", "not", "None", "and", "decoder_head_mask", "is", "None", ":", "\n", "            ", "if", "self", ".", "config", ".", "num_layers", "==", "self", ".", "config", ".", "num_decoder_layers", ":", "\n", "                ", "warnings", ".", "warn", "(", "__HEAD_MASK_WARNING_MSG", ",", "FutureWarning", ")", "\n", "decoder_head_mask", "=", "head_mask", "\n", "\n", "# Encode if needed (training, first prediction pass)", "\n", "", "", "if", "encoder_outputs", "is", "None", ":", "\n", "            ", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "", "elif", "return_dict", "and", "not", "isinstance", "(", "encoder_outputs", ",", "BaseModelOutput", ")", ":", "\n", "            ", "encoder_outputs", "=", "BaseModelOutput", "(", "\n", "last_hidden_state", "=", "encoder_outputs", "[", "0", "]", ",", "\n", "hidden_states", "=", "encoder_outputs", "[", "1", "]", "if", "len", "(", "encoder_outputs", ")", ">", "1", "else", "None", ",", "\n", "attentions", "=", "encoder_outputs", "[", "2", "]", "if", "len", "(", "encoder_outputs", ")", ">", "2", "else", "None", ",", "\n", ")", "\n", "\n", "", "hidden_states", "=", "encoder_outputs", "[", "0", "]", "\n", "if", "self", ".", "model_parallel", ":", "\n", "            ", "torch", ".", "cuda", ".", "set_device", "(", "self", ".", "decoder", ".", "first_device", ")", "\n", "# Set device for model parallelism", "\n", "", "if", "self", ".", "model_parallel", ":", "\n", "            ", "torch", ".", "cuda", ".", "set_device", "(", "self", ".", "decoder", ".", "first_device", ")", "\n", "hidden_states", "=", "hidden_states", ".", "to", "(", "self", ".", "decoder", ".", "first_device", ")", "\n", "if", "decoder_input_ids", "is", "not", "None", ":", "\n", "                ", "decoder_input_ids", "=", "decoder_input_ids", ".", "to", "(", "self", ".", "decoder", ".", "first_device", ")", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "attention_mask", "=", "attention_mask", ".", "to", "(", "self", ".", "decoder", ".", "first_device", ")", "\n", "", "if", "decoder_attention_mask", "is", "not", "None", ":", "\n", "                ", "decoder_attention_mask", "=", "decoder_attention_mask", ".", "to", "(", "self", ".", "decoder", ".", "first_device", ")", "\n", "\n", "# Decode", "\n", "", "", "decoder_outputs", "=", "self", ".", "decoder", "(", "\n", "input_ids", "=", "decoder_input_ids", ",", "\n", "attention_mask", "=", "decoder_attention_mask", ",", "\n", "inputs_embeds", "=", "decoder_inputs_embeds", ",", "\n", "past_key_values", "=", "past_key_values", ",", "\n", "encoder_hidden_states", "=", "hidden_states", ",", "\n", "encoder_attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "decoder_head_mask", ",", "\n", "encoder_head_mask", "=", "head_mask", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "if", "not", "return_dict", ":", "\n", "            ", "return", "decoder_outputs", "+", "encoder_outputs", "\n", "\n", "", "return", "Seq2SeqModelOutput", "(", "\n", "last_hidden_state", "=", "decoder_outputs", ".", "last_hidden_state", ",", "\n", "past_key_values", "=", "decoder_outputs", ".", "past_key_values", ",", "\n", "decoder_hidden_states", "=", "decoder_outputs", ".", "hidden_states", ",", "\n", "decoder_attentions", "=", "decoder_outputs", ".", "attentions", ",", "\n", "cross_attentions", "=", "decoder_outputs", ".", "cross_attentions", ",", "\n", "encoder_last_hidden_state", "=", "encoder_outputs", ".", "last_hidden_state", ",", "\n", "encoder_hidden_states", "=", "encoder_outputs", ".", "hidden_states", ",", "\n", "encoder_attentions", "=", "encoder_outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5ForMultiModalGeneration.__init__": [[1524, 1549], ["transformers.modeling_utils.PreTrainedModel.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "copy.deepcopy", "modeling_t5.T5Stack", "copy.deepcopy", "modeling_t5.T5Stack", "torch.nn.Linear", "torch.nn.Linear", "modeling_t5.T5ForMultiModalGeneration.init_weights"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "fusion_layer", "=", "None", ",", "use_img_trans", "=", "None", ",", "use_forget_gate", "=", "None", ",", "cross_attn_type", "=", "None", ",", "dim_common", "=", "256", ",", "n_attn_heads", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "model_dim", "=", "config", ".", "d_model", "\n", "\n", "self", ".", "shared", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "d_model", ")", "\n", "\n", "encoder_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "encoder_config", ".", "is_decoder", "=", "False", "\n", "encoder_config", ".", "use_cache", "=", "False", "\n", "encoder_config", ".", "is_encoder_decoder", "=", "False", "\n", "self", ".", "encoder", "=", "T5Stack", "(", "encoder_config", ",", "self", ".", "shared", ",", "fusion_layer", ",", "use_img_trans", ",", "use_forget_gate", ",", "cross_attn_type", ",", "dim_common", ",", "n_attn_heads", ")", "\n", "\n", "decoder_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "decoder_config", ".", "is_decoder", "=", "True", "\n", "decoder_config", ".", "is_encoder_decoder", "=", "False", "\n", "decoder_config", ".", "num_layers", "=", "config", ".", "num_decoder_layers", "\n", "self", ".", "decoder", "=", "T5Stack", "(", "decoder_config", ",", "self", ".", "shared", ")", "\n", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n", "# Model parallel", "\n", "self", ".", "model_parallel", "=", "False", "\n", "self", ".", "device_map", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5ForMultiModalGeneration.parallelize": [[1550, 1562], ["transformers.file_utils.add_start_docstrings", "transformers.utils.model_parallel_utils.assert_device_map", "modeling_t5.T5ForMultiModalGeneration.encoder.parallelize", "modeling_t5.T5ForMultiModalGeneration.decoder.parallelize", "modeling_t5.T5ForMultiModalGeneration.lm_head.to", "transformers.utils.model_parallel_utils.get_device_map", "len", "len", "range", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.parallelize", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.parallelize"], ["", "@", "add_start_docstrings", "(", "PARALLELIZE_DOCSTRING", ")", "\n", "def", "parallelize", "(", "self", ",", "device_map", "=", "None", ")", ":", "\n", "        ", "self", ".", "device_map", "=", "(", "\n", "get_device_map", "(", "len", "(", "self", ".", "encoder", ".", "block", ")", ",", "range", "(", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", ")", "\n", "if", "device_map", "is", "None", "\n", "else", "device_map", "\n", ")", "\n", "assert_device_map", "(", "self", ".", "device_map", ",", "len", "(", "self", ".", "encoder", ".", "block", ")", ")", "\n", "self", ".", "encoder", ".", "parallelize", "(", "self", ".", "device_map", ")", "\n", "self", ".", "decoder", ".", "parallelize", "(", "self", ".", "device_map", ")", "\n", "self", ".", "lm_head", "=", "self", ".", "lm_head", ".", "to", "(", "self", ".", "decoder", ".", "first_device", ")", "\n", "self", ".", "model_parallel", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5ForMultiModalGeneration.deparallelize": [[1563, 1573], ["transformers.file_utils.add_start_docstrings", "modeling_t5.T5ForMultiModalGeneration.encoder.deparallelize", "modeling_t5.T5ForMultiModalGeneration.decoder.deparallelize", "modeling_t5.T5ForMultiModalGeneration.encoder.to", "modeling_t5.T5ForMultiModalGeneration.decoder.to", "modeling_t5.T5ForMultiModalGeneration.lm_head.to", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.deparallelize", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.deparallelize"], ["", "@", "add_start_docstrings", "(", "DEPARALLELIZE_DOCSTRING", ")", "\n", "def", "deparallelize", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "deparallelize", "(", ")", "\n", "self", ".", "decoder", ".", "deparallelize", "(", ")", "\n", "self", ".", "encoder", "=", "self", ".", "encoder", ".", "to", "(", "\"cpu\"", ")", "\n", "self", ".", "decoder", "=", "self", ".", "decoder", ".", "to", "(", "\"cpu\"", ")", "\n", "self", ".", "lm_head", "=", "self", ".", "lm_head", ".", "to", "(", "\"cpu\"", ")", "\n", "self", ".", "model_parallel", "=", "False", "\n", "self", ".", "device_map", "=", "None", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5ForMultiModalGeneration.get_input_embeddings": [[1574, 1576], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "shared", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5ForMultiModalGeneration.set_input_embeddings": [[1577, 1581], ["modeling_t5.T5ForMultiModalGeneration.encoder.set_input_embeddings", "modeling_t5.T5ForMultiModalGeneration.decoder.set_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.set_input_embeddings", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.set_input_embeddings"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "shared", "=", "new_embeddings", "\n", "self", ".", "encoder", ".", "set_input_embeddings", "(", "new_embeddings", ")", "\n", "self", ".", "decoder", ".", "set_input_embeddings", "(", "new_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5ForMultiModalGeneration.set_output_embeddings": [[1582, 1584], ["None"], "methods", ["None"], ["", "def", "set_output_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "lm_head", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5ForMultiModalGeneration.get_output_embeddings": [[1585, 1587], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5ForMultiModalGeneration.get_encoder": [[1588, 1590], ["None"], "methods", ["None"], ["", "def", "get_encoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5ForMultiModalGeneration.get_decoder": [[1591, 1593], ["None"], "methods", ["None"], ["", "def", "get_decoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5ForMultiModalGeneration.forward": [[1594, 1750], ["transformers.file_utils.add_start_docstrings_to_model_forward", "transformers.file_utils.replace_return_docstrings", "modeling_t5.T5ForMultiModalGeneration.decoder", "modeling_t5.T5ForMultiModalGeneration.lm_head", "transformers.modeling_outputs.Seq2SeqLMOutput", "modeling_t5.T5ForMultiModalGeneration.encoder", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "modeling_t5.T5ForMultiModalGeneration._shift_right", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "hidden_states.to.to.to", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "modeling_t5.T5ForMultiModalGeneration.lm_head.to", "sequence_output.to.to.to", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "warnings.warn", "transformers.modeling_outputs.BaseModelOutput", "decoder_input_ids.to.to.to", "attention_mask.to.to.to", "decoder_attention_mask.to.to.to", "modeling_t5.T5ForMultiModalGeneration.view", "labels.view", "isinstance", "modeling_t5.T5ForMultiModalGeneration.size", "len", "len"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5PreTrainedModel._shift_right"], ["", "@", "add_start_docstrings_to_model_forward", "(", "T5_INPUTS_DOCSTRING", ")", "\n", "@", "replace_return_docstrings", "(", "output_type", "=", "Seq2SeqLMOutput", ",", "config_class", "=", "_CONFIG_FOR_DOC", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "decoder_head_mask", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "decoder_inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "image_features", "=", "None", ",", "\n", "image_len", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[-100, 0, ...,\n            config.vocab_size - 1]`. All labels set to ``-100`` are ignored (masked), the loss is only computed for\n            labels in ``[0, ..., config.vocab_size]``\n\n        Returns:\n\n        Examples::\n\n            >>> from transformers import T5Tokenizer, T5ForConditionalGeneration\n\n            >>> tokenizer = T5Tokenizer.from_pretrained('t5-small')\n            >>> model = T5ForConditionalGeneration.from_pretrained('t5-small')\n\n            >>> input_ids = tokenizer('The <extra_id_0> walks in <extra_id_1> park', return_tensors='pt').input_ids\n            >>> labels = tokenizer('<extra_id_0> cute dog <extra_id_1> the <extra_id_2> </s>', return_tensors='pt').input_ids\n            >>> outputs = model(input_ids=input_ids, labels=labels)\n            >>> loss = outputs.loss\n            >>> logits = outputs.logits\n\n            >>> input_ids = tokenizer(\"summarize: studies have shown that owning a dog is good for you \", return_tensors=\"pt\").input_ids  # Batch size 1\n            >>> outputs = model.generate(input_ids)\n        \"\"\"", "\n", "use_cache", "=", "use_cache", "if", "use_cache", "is", "not", "None", "else", "self", ".", "config", ".", "use_cache", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "# FutureWarning: head_mask was separated into two input args - head_mask, decoder_head_mask", "\n", "if", "head_mask", "is", "not", "None", "and", "decoder_head_mask", "is", "None", ":", "\n", "            ", "if", "self", ".", "config", ".", "num_layers", "==", "self", ".", "config", ".", "num_decoder_layers", ":", "\n", "                ", "warnings", ".", "warn", "(", "__HEAD_MASK_WARNING_MSG", ",", "FutureWarning", ")", "\n", "decoder_head_mask", "=", "head_mask", "\n", "\n", "# Encode if needed (training, first prediction pass)", "\n", "", "", "if", "encoder_outputs", "is", "None", ":", "\n", "# Convert encoder inputs in embeddings if needed", "\n", "            ", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", "image_features", "=", "image_features", ",", "\n", "image_len", "=", "image_len", ",", "\n", ")", "\n", "", "elif", "return_dict", "and", "not", "isinstance", "(", "encoder_outputs", ",", "BaseModelOutput", ")", ":", "\n", "            ", "encoder_outputs", "=", "BaseModelOutput", "(", "\n", "last_hidden_state", "=", "encoder_outputs", "[", "0", "]", ",", "\n", "hidden_states", "=", "encoder_outputs", "[", "1", "]", "if", "len", "(", "encoder_outputs", ")", ">", "1", "else", "None", ",", "\n", "attentions", "=", "encoder_outputs", "[", "2", "]", "if", "len", "(", "encoder_outputs", ")", ">", "2", "else", "None", ",", "\n", ")", "\n", "\n", "", "hidden_states", "=", "encoder_outputs", "[", "0", "]", "\n", "\n", "if", "self", ".", "model_parallel", ":", "\n", "            ", "torch", ".", "cuda", ".", "set_device", "(", "self", ".", "decoder", ".", "first_device", ")", "\n", "\n", "", "if", "labels", "is", "not", "None", "and", "decoder_input_ids", "is", "None", "and", "decoder_inputs_embeds", "is", "None", ":", "\n", "# get decoder inputs from shifting lm labels to the right", "\n", "            ", "decoder_input_ids", "=", "self", ".", "_shift_right", "(", "labels", ")", "\n", "\n", "# If decoding with past key value states, only the last tokens", "\n", "# should be given as an input", "\n", "", "if", "past_key_values", "is", "not", "None", ":", "\n", "            ", "assert", "labels", "is", "None", ",", "\"Decoder should not use cached key value states when training.\"", "\n", "if", "decoder_input_ids", "is", "not", "None", ":", "\n", "                ", "decoder_input_ids", "=", "decoder_input_ids", "[", ":", ",", "-", "1", ":", "]", "\n", "", "if", "decoder_inputs_embeds", "is", "not", "None", ":", "\n", "                ", "decoder_inputs_embeds", "=", "decoder_inputs_embeds", "[", ":", ",", "-", "1", ":", "]", "\n", "\n", "# Set device for model parallelism", "\n", "", "", "if", "self", ".", "model_parallel", ":", "\n", "            ", "torch", ".", "cuda", ".", "set_device", "(", "self", ".", "decoder", ".", "first_device", ")", "\n", "hidden_states", "=", "hidden_states", ".", "to", "(", "self", ".", "decoder", ".", "first_device", ")", "\n", "if", "decoder_input_ids", "is", "not", "None", ":", "\n", "                ", "decoder_input_ids", "=", "decoder_input_ids", ".", "to", "(", "self", ".", "decoder", ".", "first_device", ")", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "attention_mask", "=", "attention_mask", ".", "to", "(", "self", ".", "decoder", ".", "first_device", ")", "\n", "", "if", "decoder_attention_mask", "is", "not", "None", ":", "\n", "                ", "decoder_attention_mask", "=", "decoder_attention_mask", ".", "to", "(", "self", ".", "decoder", ".", "first_device", ")", "\n", "\n", "# Decode", "\n", "", "", "decoder_outputs", "=", "self", ".", "decoder", "(", "\n", "input_ids", "=", "decoder_input_ids", ",", "\n", "attention_mask", "=", "decoder_attention_mask", ",", "\n", "inputs_embeds", "=", "decoder_inputs_embeds", ",", "\n", "past_key_values", "=", "past_key_values", ",", "\n", "encoder_hidden_states", "=", "hidden_states", ",", "\n", "encoder_attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "decoder_head_mask", ",", "\n", "encoder_head_mask", "=", "head_mask", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "decoder_outputs", "[", "0", "]", "\n", "\n", "# Set device for model parallelism", "\n", "if", "self", ".", "model_parallel", ":", "\n", "            ", "torch", ".", "cuda", ".", "set_device", "(", "self", ".", "encoder", ".", "first_device", ")", "\n", "self", ".", "lm_head", "=", "self", ".", "lm_head", ".", "to", "(", "self", ".", "encoder", ".", "first_device", ")", "\n", "sequence_output", "=", "sequence_output", ".", "to", "(", "self", ".", "lm_head", ".", "weight", ".", "device", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "tie_word_embeddings", ":", "\n", "# Rescale output before projecting on vocab", "\n", "# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586", "\n", "            ", "sequence_output", "=", "sequence_output", "*", "(", "self", ".", "model_dim", "**", "-", "0.5", ")", "\n", "\n", "", "lm_logits", "=", "self", ".", "lm_head", "(", "sequence_output", ")", "\n", "\n", "loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "100", ")", "\n", "loss", "=", "loss_fct", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "lm_logits", ".", "size", "(", "-", "1", ")", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "# TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "lm_logits", ",", ")", "+", "decoder_outputs", "[", "1", ":", "]", "+", "encoder_outputs", "\n", "return", "(", "(", "loss", ",", ")", "+", "output", ")", "if", "loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "Seq2SeqLMOutput", "(", "\n", "loss", "=", "loss", ",", "\n", "logits", "=", "lm_logits", ",", "\n", "past_key_values", "=", "decoder_outputs", ".", "past_key_values", ",", "\n", "decoder_hidden_states", "=", "decoder_outputs", ".", "hidden_states", ",", "\n", "decoder_attentions", "=", "decoder_outputs", ".", "attentions", ",", "\n", "cross_attentions", "=", "decoder_outputs", ".", "cross_attentions", ",", "\n", "encoder_last_hidden_state", "=", "encoder_outputs", ".", "last_hidden_state", ",", "\n", "encoder_hidden_states", "=", "encoder_outputs", ".", "hidden_states", ",", "\n", "encoder_attentions", "=", "encoder_outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5ForMultiModalGeneration.prepare_inputs_for_generation": [[1752, 1766], ["None"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "\n", "self", ",", "input_ids", ",", "past", "=", "None", ",", "attention_mask", "=", "None", ",", "use_cache", "=", "None", ",", "encoder_outputs", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "\n", "# cut decoder_input_ids if past is used", "\n", "        ", "if", "past", "is", "not", "None", ":", "\n", "            ", "input_ids", "=", "input_ids", "[", ":", ",", "-", "1", ":", "]", "\n", "\n", "", "return", "{", "\n", "\"decoder_input_ids\"", ":", "input_ids", ",", "\n", "\"past_key_values\"", ":", "past", ",", "\n", "\"encoder_outputs\"", ":", "encoder_outputs", ",", "\n", "\"attention_mask\"", ":", "attention_mask", ",", "\n", "\"use_cache\"", ":", "use_cache", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5ForMultiModalGeneration._reorder_cache": [[1768, 1791], ["logger.warning", "len", "len", "layer_past_state.index_select"], "methods", ["None"], ["", "def", "_reorder_cache", "(", "self", ",", "past", ",", "beam_idx", ")", ":", "\n", "# if decoder past is not included in output", "\n", "# speedy decoding is disabled and no need to reorder", "\n", "        ", "if", "past", "is", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\"You might want to consider setting `use_cache=True` to speed up decoding\"", ")", "\n", "return", "past", "\n", "\n", "", "reordered_decoder_past", "=", "(", ")", "\n", "for", "layer_past_states", "in", "past", ":", "\n", "# get the correct batch idx from layer past batch dim", "\n", "# batch dim of `past` is at 2nd position", "\n", "            ", "reordered_layer_past_states", "=", "(", ")", "\n", "for", "layer_past_state", "in", "layer_past_states", ":", "\n", "# need to set correct `past` for each of the four key / value states", "\n", "                ", "reordered_layer_past_states", "=", "reordered_layer_past_states", "+", "(", "\n", "layer_past_state", ".", "index_select", "(", "0", ",", "beam_idx", ")", ",", "\n", ")", "\n", "\n", "", "assert", "reordered_layer_past_states", "[", "0", "]", ".", "shape", "==", "layer_past_states", "[", "0", "]", ".", "shape", "\n", "assert", "len", "(", "reordered_layer_past_states", ")", "==", "len", "(", "layer_past_states", ")", "\n", "\n", "reordered_decoder_past", "=", "reordered_decoder_past", "+", "(", "reordered_layer_past_states", ",", ")", "\n", "", "return", "reordered_decoder_past", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.__init__": [[1802, 1816], ["transformers.modeling_utils.PreTrainedModel.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "copy.deepcopy", "modeling_t5.T5Stack", "modeling_t5.T5EncoderModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "T5Config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "shared", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "d_model", ")", "\n", "\n", "encoder_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "encoder_config", ".", "use_cache", "=", "False", "\n", "encoder_config", ".", "is_encoder_decoder", "=", "False", "\n", "self", ".", "encoder", "=", "T5Stack", "(", "encoder_config", ",", "self", ".", "shared", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n", "# Model parallel", "\n", "self", ".", "model_parallel", "=", "False", "\n", "self", ".", "device_map", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.parallelize": [[1817, 1827], ["transformers.file_utils.add_start_docstrings", "transformers.utils.model_parallel_utils.assert_device_map", "modeling_t5.T5EncoderModel.encoder.parallelize", "transformers.utils.model_parallel_utils.get_device_map", "len", "len", "range", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.parallelize"], ["", "@", "add_start_docstrings", "(", "PARALLELIZE_DOCSTRING", ")", "\n", "def", "parallelize", "(", "self", ",", "device_map", "=", "None", ")", ":", "\n", "        ", "self", ".", "device_map", "=", "(", "\n", "get_device_map", "(", "len", "(", "self", ".", "encoder", ".", "block", ")", ",", "range", "(", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", ")", "\n", "if", "device_map", "is", "None", "\n", "else", "device_map", "\n", ")", "\n", "assert_device_map", "(", "self", ".", "device_map", ",", "len", "(", "self", ".", "encoder", ".", "block", ")", ")", "\n", "self", ".", "encoder", ".", "parallelize", "(", "self", ".", "device_map", ")", "\n", "self", ".", "model_parallel", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.deparallelize": [[1828, 1835], ["transformers.file_utils.add_start_docstrings", "modeling_t5.T5EncoderModel.encoder.deparallelize", "modeling_t5.T5EncoderModel.encoder.to", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.deparallelize"], ["", "@", "add_start_docstrings", "(", "DEPARALLELIZE_DOCSTRING", ")", "\n", "def", "deparallelize", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "deparallelize", "(", ")", "\n", "self", ".", "encoder", "=", "self", ".", "encoder", ".", "to", "(", "\"cpu\"", ")", "\n", "self", ".", "model_parallel", "=", "False", "\n", "self", ".", "device_map", "=", "None", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.get_input_embeddings": [[1836, 1838], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "shared", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.set_input_embeddings": [[1839, 1842], ["modeling_t5.T5EncoderModel.encoder.set_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.set_input_embeddings"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "shared", "=", "new_embeddings", "\n", "self", ".", "encoder", ".", "set_input_embeddings", "(", "new_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.get_encoder": [[1843, 1845], ["None"], "methods", ["None"], ["", "def", "get_encoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel._prune_heads": [[1846, 1853], ["heads_to_prune.items", "modeling_t5.T5EncoderModel.encoder.layer[].attention.prune_heads"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\"\n        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n        class PreTrainedModel\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.T5EncoderModel.forward": [[1854, 1891], ["transformers.file_utils.add_start_docstrings_to_model_forward", "transformers.file_utils.replace_return_docstrings", "modeling_t5.T5EncoderModel.encoder"], "methods", ["None"], ["", "", "@", "add_start_docstrings_to_model_forward", "(", "T5_ENCODER_INPUTS_DOCSTRING", ")", "\n", "@", "replace_return_docstrings", "(", "output_type", "=", "BaseModelOutput", ",", "config_class", "=", "_CONFIG_FOR_DOC", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        Returns:\n\n        Example::\n\n            >>> from transformers import T5Tokenizer, T5EncoderModel\n            >>> tokenizer = T5Tokenizer.from_pretrained('t5-small')\n            >>> model = T5EncoderModel.from_pretrained('t5-small')\n            >>> input_ids = tokenizer(\"Studies have been shown that owning a dog is good for you\", return_tensors=\"pt\").input_ids  # Batch size 1\n            >>> outputs = model(input_ids=input_ids)\n            >>> last_hidden_states = outputs.last_hidden_state\n        \"\"\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "return", "encoder_outputs", "", "", "", ""]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.modeling_t5.load_tf_weights_in_t5": [[72, 176], ["os.path.abspath", "logger.info", "tf.train.list_variables", "logger.info", "logger.info", "tf.train.load_variable", "names.append", "txt_name.split", "any", "logger.info", "torch.from_numpy", "torch.from_numpy", "tf_weights.pop", "logger.error", "logger.info", "tf_weights.pop", "logger.info", "tf_weights.pop", "re.fullmatch", "getattr", "logger.info", "np.transpose", "np.transpose.astype", "re.split", "getattr", "len", "int", "tf_weights.keys", "getattr", "getattr", "getattr", "hasattr", "getattr", "hasattr", "getattr", "getattr", "getattr", "getattr", "getattr", "scope_names[].isdigit", "getattr", "len", "getattr", "logger.info"], "function", ["None"], ["def", "load_tf_weights_in_t5", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", ":", "\n", "    ", "\"\"\"Load tf checkpoints in a pytorch model.\"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "\n", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "tf_weights", "=", "{", "}", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "tf_weights", "[", "name", "]", "=", "array", "\n", "\n", "", "for", "txt_name", "in", "names", ":", "\n", "        ", "name", "=", "txt_name", ".", "split", "(", "\"/\"", ")", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "any", "(", "\n", "n", "in", "[", "\"adam_v\"", ",", "\"adam_m\"", ",", "\"AdamWeightDecayOptimizer\"", ",", "\"AdamWeightDecayOptimizer_1\"", ",", "\"global_step\"", "]", "\n", "for", "n", "in", "name", "\n", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "tf_weights", ".", "pop", "(", "txt_name", ",", "None", ")", "\n", "continue", "\n", "", "if", "\"_slot_\"", "in", "name", "[", "-", "1", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "tf_weights", ".", "pop", "(", "txt_name", ",", "None", ")", "\n", "continue", "\n", "", "pointer", "=", "model", "\n", "array", "=", "tf_weights", "[", "txt_name", "]", "\n", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r\"[A-Za-z]+_\\d+\"", ",", "m_name", ")", ":", "\n", "                ", "scope_names", "=", "re", ".", "split", "(", "r\"_(\\d+)\"", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "scope_names", "=", "[", "m_name", "]", "\n", "", "if", "scope_names", "[", "0", "]", "in", "[", "\"kernel\"", ",", "\"scale\"", ",", "\"embedding\"", "]", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"self_attention\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"layer\"", ")", "\n", "pointer", "=", "pointer", "[", "0", "]", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"enc_dec_attention\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"layer\"", ")", "\n", "pointer", "=", "pointer", "[", "1", "]", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"dense_relu_dense\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"layer\"", ")", "\n", "pointer", "=", "pointer", "[", "2", "]", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"rms_norm\"", ":", "\n", "                ", "if", "hasattr", "(", "pointer", ",", "\"layer_norm\"", ")", ":", "\n", "                    ", "pointer", "=", "getattr", "(", "pointer", ",", "\"layer_norm\"", ")", "\n", "", "elif", "hasattr", "(", "pointer", ",", "\"final_layer_norm\"", ")", ":", "\n", "                    ", "pointer", "=", "getattr", "(", "pointer", ",", "\"final_layer_norm\"", ")", "\n", "", "", "elif", "scope_names", "[", "0", "]", "==", "\"scale\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"output_bias\"", "or", "scope_names", "[", "0", "]", "==", "\"beta\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"bias\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"squad\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"classifier\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"decoder\"", "and", "name", "[", "1", "]", "==", "\"logits\"", ":", "\n", "                ", "continue", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"logits\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"lm_head\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"wi\"", "and", "len", "(", "scope_names", ")", ">", "1", "and", "scope_names", "[", "1", "]", ".", "isdigit", "(", ")", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "f\"wi_{scope_names[1]}\"", ")", "\n", "continue", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "pointer", "=", "getattr", "(", "pointer", ",", "scope_names", "[", "0", "]", ")", "\n", "", "except", "AttributeError", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "", "if", "len", "(", "scope_names", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "scope_names", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "if", "scope_names", "[", "0", "]", "not", "in", "[", "\"kernel\"", ",", "\"scale\"", ",", "\"embedding\"", "]", ":", "\n", "            ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "if", "scope_names", "[", "0", "]", "!=", "\"embedding\"", ":", "\n", "            ", "logger", ".", "info", "(", "\"Transposing numpy weight of shape {} for {}\"", ".", "format", "(", "array", ".", "shape", ",", "name", ")", ")", "\n", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "try", ":", "\n", "            ", "assert", "(", "\n", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", ")", ",", "f\"Pointer shape {pointer.shape} and array shape {array.shape} mismatched\"", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "tf_weights", ".", "pop", "(", "txt_name", ",", "None", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Weights not copied to PyTorch model: {}\"", ".", "format", "(", "\", \"", ".", "join", "(", "tf_weights", ".", "keys", "(", ")", ")", ")", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.multi_modal_model.BartMultiModal.__init__": [[8, 20], ["models.base_model.BaseModel.__init__", "models.modeling_bart.BartForMultiModalGeneration.from_pretrained", "transformers.BartTokenizer.from_pretrained", "datasets.load_metric"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "super", "(", "BartMultiModal", ",", "self", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "model", "=", "BartForMultiModalGeneration", ".", "from_pretrained", "(", "'facebook/bart-base'", ",", "\n", "fusion_layer", "=", "args", ".", "fusion_layer", ",", "\n", "use_img_trans", "=", "args", ".", "use_img_trans", ",", "\n", "use_forget_gate", "=", "args", ".", "use_forget_gate", ",", "\n", "cross_attn_type", "=", "args", ".", "cross_attn_type", ",", "\n", "dim_common", "=", "args", ".", "dim_common", ",", "\n", "n_attn_heads", "=", "args", ".", "n_attn_heads", ")", "\n", "self", ".", "tokenizer", "=", "BartTokenizer", ".", "from_pretrained", "(", "'facebook/bart-base'", ")", "\n", "self", ".", "rouge", "=", "load_metric", "(", "'rouge'", ",", "experiment_id", "=", "self", ".", "args", ".", "log_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.multi_modal_model.BartMultiModal.forward": [[21, 29], ["multi_modal_model.BartMultiModal.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", ",", "decoder_input_ids", ",", "labels", ",", "image_features", ",", "image_len", ")", ":", "\n", "        ", "loss", "=", "self", ".", "model", "(", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "labels", "=", "labels", ",", "\n", "image_features", "=", "image_features", ",", "\n", "image_len", "=", "image_len", ")", "[", "0", "]", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.multi_modal_model.BartMultiModal.training_step": [[30, 38], ["multi_modal_model.BartMultiModal.", "multi_modal_model.BartMultiModal.log", "image_features.float"], "methods", ["None"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "# batch", "\n", "        ", "src_ids", ",", "decoder_ids", ",", "mask", ",", "label_ids", ",", "image_features", ",", "image_len", "=", "batch", "\n", "# get loss", "\n", "loss", "=", "self", "(", "input_ids", "=", "src_ids", ",", "attention_mask", "=", "mask", ",", "decoder_input_ids", "=", "decoder_ids", ",", "labels", "=", "label_ids", ",", "image_features", "=", "image_features", ".", "float", "(", ")", ",", "image_len", "=", "image_len", ")", "\n", "# logs", "\n", "self", ".", "log", "(", "'train_loss'", ",", "loss", ",", "on_step", "=", "True", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.multi_modal_model.BartMultiModal.validation_step": [[39, 52], ["multi_modal_model.BartMultiModal.model.generate", "image_features.float"], "methods", ["None"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "# batch", "\n", "        ", "src_ids", ",", "decoder_ids", ",", "mask", ",", "label_ids", ",", "image_features", ",", "image_len", "=", "batch", "\n", "# get summary", "\n", "summary_ids", "=", "self", ".", "model", ".", "generate", "(", "input_ids", "=", "src_ids", ",", "\n", "attention_mask", "=", "mask", ",", "\n", "num_beams", "=", "self", ".", "args", ".", "n_beams", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_output_len", ",", "\n", "early_stopping", "=", "True", ",", "\n", "no_repeat_ngram_size", "=", "self", ".", "args", ".", "no_repeat_ngram_size", ",", "\n", "image_features", "=", "image_features", ".", "float", "(", ")", ",", "\n", "image_len", "=", "image_len", ")", "\n", "return", "[", "summary_ids", ",", "label_ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.multi_modal_model.BartMultiModal.validation_epoch_end": [[53, 69], ["multi_modal_model.BartMultiModal.calrouge", "multi_modal_model.BartMultiModal.log", "multi_modal_model.BartMultiModal.log", "multi_modal_model.BartMultiModal.log", "multi_modal_model.BartMultiModal.save_txt", "multi_modal_model.BartMultiModal.save_txt", "multi_modal_model.BartMultiModal.tokenizer.decode", "multi_modal_model.BartMultiModal.tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.calrouge", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.save_txt", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.save_txt"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "summary", "=", "[", "]", "\n", "reference", "=", "[", "]", "\n", "for", "item", "in", "outputs", ":", "\n", "            ", "summary_id", "=", "item", "[", "0", "]", "\n", "label_id", "=", "item", "[", "1", "]", "\n", "one_summary", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "[", "i", "for", "i", "in", "g", "if", "i", "!=", "-", "100", "]", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "False", ")", "for", "g", "in", "summary_id", "]", "\n", "one_reference", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "[", "i", "for", "i", "in", "g", "if", "i", "!=", "-", "100", "]", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "False", ")", "for", "g", "in", "label_id", "]", "\n", "summary", "+=", "one_summary", "\n", "reference", "+=", "one_reference", "\n", "", "avg_rouge1", ",", "avg_rouge2", ",", "avg_rougeL", "=", "self", ".", "calrouge", "(", "summary", ",", "reference", ",", "self", ".", "rouge", ")", "\n", "self", ".", "log", "(", "'validation_Rouge1_one_epoch'", ",", "avg_rouge1", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "log", "(", "'validation_Rouge2_one_epoch'", ",", "avg_rouge2", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "log", "(", "'validation_RougeL_one_epoch'", ",", "avg_rougeL", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "save_txt", "(", "self", ".", "args", ".", "val_save_file", ",", "summary", ")", "\n", "self", ".", "save_txt", "(", "self", ".", "args", ".", "val_save_file", "+", "'reference'", ",", "reference", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.multi_modal_model.BartMultiModal.test_step": [[70, 83], ["multi_modal_model.BartMultiModal.model.generate", "image_features.float"], "methods", ["None"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "# batch", "\n", "        ", "src_ids", ",", "decoder_ids", ",", "mask", ",", "label_ids", ",", "image_features", ",", "image_len", "=", "batch", "\n", "# get summary", "\n", "summary_ids", "=", "self", ".", "model", ".", "generate", "(", "input_ids", "=", "src_ids", ",", "\n", "attention_mask", "=", "mask", ",", "\n", "num_beams", "=", "self", ".", "args", ".", "n_beams", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_output_len", ",", "\n", "early_stopping", "=", "True", ",", "\n", "no_repeat_ngram_size", "=", "self", ".", "args", ".", "no_repeat_ngram_size", ",", "\n", "image_features", "=", "image_features", ".", "float", "(", ")", ",", "\n", "image_len", "=", "image_len", ")", "\n", "return", "[", "summary_ids", ",", "label_ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.multi_modal_model.BartMultiModal.test_epoch_end": [[84, 100], ["datasets.load_metric", "multi_modal_model.BartMultiModal.calrouge", "multi_modal_model.BartMultiModal.log", "multi_modal_model.BartMultiModal.log", "multi_modal_model.BartMultiModal.log", "multi_modal_model.BartMultiModal.save_txt", "multi_modal_model.BartMultiModal.tokenizer.decode", "multi_modal_model.BartMultiModal.tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.calrouge", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.save_txt"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "rouge", "=", "load_metric", "(", "'rouge'", ",", "experiment_id", "=", "self", ".", "args", ".", "log_name", ")", "\n", "summary", "=", "[", "]", "\n", "reference", "=", "[", "]", "\n", "for", "item", "in", "outputs", ":", "\n", "            ", "summary_id", "=", "item", "[", "0", "]", "\n", "label_id", "=", "item", "[", "1", "]", "\n", "one_summary", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "[", "i", "for", "i", "in", "g", "if", "i", "!=", "-", "100", "]", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "False", ")", "for", "g", "in", "summary_id", "]", "\n", "one_reference", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "[", "i", "for", "i", "in", "g", "if", "i", "!=", "-", "100", "]", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "False", ")", "for", "g", "in", "label_id", "]", "\n", "summary", "+=", "one_summary", "\n", "reference", "+=", "one_reference", "\n", "", "avg_rouge1", ",", "avg_rouge2", ",", "avg_rougeL", "=", "self", ".", "calrouge", "(", "summary", ",", "reference", ",", "rouge", ")", "\n", "self", ".", "log", "(", "'test_Rouge1_one_epoch'", ",", "avg_rouge1", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "log", "(", "'test_Rouge2_one_epoch'", ",", "avg_rouge2", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "log", "(", "'test_RougeL_one_epoch'", ",", "avg_rougeL", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "save_txt", "(", "self", ".", "args", ".", "test_save_file", ",", "summary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.multi_modal_model.BartMultiModal.calrouge": [[101, 108], ["rouge.add_batch", "rouge.compute"], "methods", ["None"], ["", "def", "calrouge", "(", "self", ",", "summary", ",", "reference", ",", "rouge", ")", ":", "\n", "        ", "rouge", ".", "add_batch", "(", "predictions", "=", "summary", ",", "references", "=", "reference", ")", "\n", "final_results", "=", "rouge", ".", "compute", "(", "rouge_types", "=", "[", "\"rouge1\"", ",", "\"rouge2\"", ",", "\"rougeL\"", "]", ")", "\n", "R1_F1", "=", "final_results", "[", "\"rouge1\"", "]", ".", "mid", ".", "fmeasure", "*", "100", "\n", "R2_F1", "=", "final_results", "[", "\"rouge2\"", "]", ".", "mid", ".", "fmeasure", "*", "100", "\n", "RL_F1", "=", "final_results", "[", "\"rougeL\"", "]", ".", "mid", ".", "fmeasure", "*", "100", "\n", "return", "R1_F1", ",", "R2_F1", ",", "RL_F1", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.multi_modal_model.BartMultiModal.save_txt": [[109, 114], ["open", "open.writelines", "open.close"], "methods", ["None"], ["", "def", "save_txt", "(", "self", ",", "file_name", ",", "list_data", ")", ":", "\n", "        ", "file", "=", "open", "(", "file_name", ",", "'w'", ")", "\n", "list_data", "=", "[", "item", "+", "'\\n'", "for", "item", "in", "list_data", "]", "\n", "file", ".", "writelines", "(", "list_data", ")", "\n", "file", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.t5.T5Origin.__init__": [[9, 15], ["models.base_model.BaseModel.__init__", "transformers.T5ForConditionalGeneration.from_pretrained", "transformers.T5Tokenizer.from_pretrained", "datasets.load_metric"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "super", "(", "T5Origin", ",", "self", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "model", "=", "T5ForConditionalGeneration", ".", "from_pretrained", "(", "'t5-base'", ")", "\n", "self", ".", "tokenizer", "=", "T5Tokenizer", ".", "from_pretrained", "(", "'t5-base'", ")", "\n", "self", ".", "rouge", "=", "load_metric", "(", "'rouge'", ",", "experiment_id", "=", "self", ".", "args", ".", "log_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.t5.T5Origin.forward": [[16, 19], ["t5.T5Origin.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", ",", "decoder_input_ids", ",", "labels", ")", ":", "\n", "        ", "loss", "=", "self", ".", "model", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "decoder_input_ids", "=", "decoder_input_ids", ",", "labels", "=", "labels", ")", "[", "0", "]", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.t5.T5Origin.validation_step": [[20, 31], ["t5.T5Origin.model.generate"], "methods", ["None"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "# batch", "\n", "        ", "src_ids", ",", "decoder_ids", ",", "mask", ",", "label_ids", "=", "batch", "\n", "# get summary", "\n", "summary_ids", "=", "self", ".", "model", ".", "generate", "(", "input_ids", "=", "src_ids", ",", "\n", "attention_mask", "=", "mask", ",", "\n", "num_beams", "=", "self", ".", "args", ".", "n_beams", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_output_len", ",", "\n", "early_stopping", "=", "True", ",", "\n", "no_repeat_ngram_size", "=", "self", ".", "args", ".", "no_repeat_ngram_size", ")", "\n", "return", "[", "summary_ids", ",", "label_ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.t5.T5Origin.validation_epoch_end": [[32, 48], ["t5.T5Origin.calrouge", "t5.T5Origin.log", "t5.T5Origin.log", "t5.T5Origin.log", "t5.T5Origin.save_txt", "t5.T5Origin.save_txt", "t5.T5Origin.tokenizer.decode", "t5.T5Origin.tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.calrouge", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.save_txt", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.save_txt"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "summary", "=", "[", "]", "\n", "reference", "=", "[", "]", "\n", "for", "item", "in", "outputs", ":", "\n", "            ", "summary_id", "=", "item", "[", "0", "]", "\n", "label_id", "=", "item", "[", "1", "]", "\n", "one_summary", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "[", "i", "for", "i", "in", "g", "if", "i", "!=", "-", "100", "]", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "False", ")", "for", "g", "in", "summary_id", "]", "\n", "one_reference", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "[", "i", "for", "i", "in", "g", "if", "i", "!=", "-", "100", "]", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "False", ")", "for", "g", "in", "label_id", "]", "\n", "summary", "+=", "one_summary", "\n", "reference", "+=", "one_reference", "\n", "", "avg_rouge1", ",", "avg_rouge2", ",", "avg_rougeL", "=", "self", ".", "calrouge", "(", "summary", ",", "reference", ",", "self", ".", "rouge", ")", "\n", "self", ".", "log", "(", "'validation_Rouge1_one_epoch'", ",", "avg_rouge1", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "log", "(", "'validation_Rouge2_one_epoch'", ",", "avg_rouge2", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "log", "(", "'validation_RougeL_one_epoch'", ",", "avg_rougeL", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "save_txt", "(", "self", ".", "args", ".", "val_save_file", "+", "'reference'", ",", "reference", ")", "\n", "self", ".", "save_txt", "(", "self", ".", "args", ".", "val_save_file", ",", "summary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.t5.T5Origin.test_step": [[49, 60], ["t5.T5Origin.model.generate"], "methods", ["None"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "# batch", "\n", "        ", "src_ids", ",", "decoder_ids", ",", "mask", ",", "label_ids", "=", "batch", "\n", "# get summary", "\n", "summary_ids", "=", "self", ".", "model", ".", "generate", "(", "input_ids", "=", "src_ids", ",", "\n", "attention_mask", "=", "mask", ",", "\n", "num_beams", "=", "self", ".", "args", ".", "n_beams", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_output_len", ",", "\n", "early_stopping", "=", "True", ",", "\n", "no_repeat_ngram_size", "=", "self", ".", "args", ".", "no_repeat_ngram_size", ")", "\n", "return", "[", "summary_ids", ",", "label_ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.t5.T5Origin.test_epoch_end": [[61, 77], ["datasets.load_metric", "t5.T5Origin.calrouge", "t5.T5Origin.log", "t5.T5Origin.log", "t5.T5Origin.log", "t5.T5Origin.save_txt", "t5.T5Origin.tokenizer.decode", "t5.T5Origin.tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.calrouge", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.save_txt"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "rouge", "=", "load_metric", "(", "'rouge'", ",", "experiment_id", "=", "self", ".", "args", ".", "log_name", ")", "\n", "summary", "=", "[", "]", "\n", "reference", "=", "[", "]", "\n", "for", "item", "in", "outputs", ":", "\n", "            ", "summary_id", "=", "item", "[", "0", "]", "\n", "label_id", "=", "item", "[", "1", "]", "\n", "one_summary", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "[", "i", "for", "i", "in", "g", "if", "i", "!=", "-", "100", "]", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "False", ")", "for", "g", "in", "summary_id", "]", "\n", "one_reference", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "[", "i", "for", "i", "in", "g", "if", "i", "!=", "-", "100", "]", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "False", ")", "for", "g", "in", "label_id", "]", "\n", "summary", "+=", "one_summary", "\n", "reference", "+=", "one_reference", "\n", "", "avg_rouge1", ",", "avg_rouge2", ",", "avg_rougeL", "=", "self", ".", "calrouge", "(", "summary", ",", "reference", ",", "rouge", ")", "\n", "self", ".", "log", "(", "'test_Rouge1_one_epoch'", ",", "avg_rouge1", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "log", "(", "'test_Rouge2_one_epoch'", ",", "avg_rouge2", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "log", "(", "'test_RougeL_one_epoch'", ",", "avg_rougeL", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "save_txt", "(", "self", ".", "args", ".", "test_save_file", ",", "summary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.t5.T5Origin.calrouge": [[78, 85], ["rouge.add_batch", "rouge.compute"], "methods", ["None"], ["", "def", "calrouge", "(", "self", ",", "summary", ",", "reference", ",", "rouge", ")", ":", "\n", "        ", "rouge", ".", "add_batch", "(", "predictions", "=", "summary", ",", "references", "=", "reference", ")", "\n", "final_results", "=", "rouge", ".", "compute", "(", "rouge_types", "=", "[", "\"rouge1\"", ",", "\"rouge2\"", ",", "\"rougeL\"", "]", ")", "\n", "R1_F1", "=", "final_results", "[", "\"rouge1\"", "]", ".", "mid", ".", "fmeasure", "*", "100", "\n", "R2_F1", "=", "final_results", "[", "\"rouge2\"", "]", ".", "mid", ".", "fmeasure", "*", "100", "\n", "RL_F1", "=", "final_results", "[", "\"rougeL\"", "]", ".", "mid", ".", "fmeasure", "*", "100", "\n", "return", "R1_F1", ",", "R2_F1", ",", "RL_F1", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.t5.T5Origin.save_txt": [[86, 91], ["open", "open.writelines", "open.close"], "methods", ["None"], ["", "def", "save_txt", "(", "self", ",", "file_name", ",", "list_data", ")", ":", "\n", "        ", "file", "=", "open", "(", "file_name", ",", "'w'", ")", "\n", "list_data", "=", "[", "item", "+", "'\\n'", "for", "item", "in", "list_data", "]", "\n", "file", ".", "writelines", "(", "list_data", ")", "\n", "file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.t5.T5MultiModal.__init__": [[95, 107], ["models.base_model.BaseModel.__init__", "models.modeling_t5.T5ForMultiModalGeneration.from_pretrained", "transformers.T5Tokenizer.from_pretrained", "datasets.load_metric"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "super", "(", "T5MultiModal", ",", "self", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "model", "=", "T5ForMultiModalGeneration", ".", "from_pretrained", "(", "'t5-base'", ",", "\n", "fusion_layer", "=", "args", ".", "fusion_layer", ",", "\n", "use_img_trans", "=", "args", ".", "use_img_trans", ",", "\n", "use_forget_gate", "=", "args", ".", "use_forget_gate", ",", "\n", "cross_attn_type", "=", "args", ".", "cross_attn_type", ",", "\n", "dim_common", "=", "args", ".", "dim_common", ",", "\n", "n_attn_heads", "=", "args", ".", "n_attn_heads", ")", "\n", "self", ".", "tokenizer", "=", "T5Tokenizer", ".", "from_pretrained", "(", "'t5-base'", ")", "\n", "self", ".", "rouge", "=", "load_metric", "(", "'rouge'", ",", "experiment_id", "=", "self", ".", "args", ".", "log_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.t5.T5MultiModal.forward": [[108, 116], ["t5.T5MultiModal.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", ",", "decoder_input_ids", ",", "labels", ",", "image_features", ",", "image_len", ")", ":", "\n", "        ", "loss", "=", "self", ".", "model", "(", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "labels", "=", "labels", ",", "\n", "image_features", "=", "image_features", ",", "\n", "image_len", "=", "image_len", ")", "[", "0", "]", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.t5.T5MultiModal.training_step": [[117, 125], ["t5.T5MultiModal.", "t5.T5MultiModal.log", "image_features.float"], "methods", ["None"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "# batch", "\n", "        ", "src_ids", ",", "decoder_ids", ",", "mask", ",", "label_ids", ",", "image_features", ",", "image_len", "=", "batch", "\n", "# get loss", "\n", "loss", "=", "self", "(", "input_ids", "=", "src_ids", ",", "attention_mask", "=", "mask", ",", "decoder_input_ids", "=", "decoder_ids", ",", "labels", "=", "label_ids", ",", "image_features", "=", "image_features", ".", "float", "(", ")", ",", "image_len", "=", "image_len", ")", "\n", "# logs", "\n", "self", ".", "log", "(", "'train_loss'", ",", "loss", ",", "on_step", "=", "True", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.t5.T5MultiModal.validation_step": [[126, 139], ["t5.T5MultiModal.model.generate", "image_features.float"], "methods", ["None"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "# batch", "\n", "        ", "src_ids", ",", "decoder_ids", ",", "mask", ",", "label_ids", ",", "image_features", ",", "image_len", "=", "batch", "\n", "# get summary", "\n", "summary_ids", "=", "self", ".", "model", ".", "generate", "(", "input_ids", "=", "src_ids", ",", "\n", "attention_mask", "=", "mask", ",", "\n", "num_beams", "=", "self", ".", "args", ".", "n_beams", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_output_len", ",", "\n", "early_stopping", "=", "True", ",", "\n", "no_repeat_ngram_size", "=", "self", ".", "args", ".", "no_repeat_ngram_size", ",", "\n", "image_features", "=", "image_features", ".", "float", "(", ")", ",", "\n", "image_len", "=", "image_len", ")", "\n", "return", "[", "summary_ids", ",", "label_ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.t5.T5MultiModal.validation_epoch_end": [[140, 156], ["t5.T5MultiModal.calrouge", "t5.T5MultiModal.log", "t5.T5MultiModal.log", "t5.T5MultiModal.log", "t5.T5MultiModal.save_txt", "t5.T5MultiModal.save_txt", "t5.T5MultiModal.tokenizer.decode", "t5.T5MultiModal.tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.calrouge", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.save_txt", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.save_txt"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "summary", "=", "[", "]", "\n", "reference", "=", "[", "]", "\n", "for", "item", "in", "outputs", ":", "\n", "            ", "summary_id", "=", "item", "[", "0", "]", "\n", "label_id", "=", "item", "[", "1", "]", "\n", "one_summary", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "[", "i", "for", "i", "in", "g", "if", "i", "!=", "-", "100", "]", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "False", ")", "for", "g", "in", "summary_id", "]", "\n", "one_reference", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "[", "i", "for", "i", "in", "g", "if", "i", "!=", "-", "100", "]", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "False", ")", "for", "g", "in", "label_id", "]", "\n", "summary", "+=", "one_summary", "\n", "reference", "+=", "one_reference", "\n", "", "avg_rouge1", ",", "avg_rouge2", ",", "avg_rougeL", "=", "self", ".", "calrouge", "(", "summary", ",", "reference", ",", "self", ".", "rouge", ")", "\n", "self", ".", "log", "(", "'validation_Rouge1_one_epoch'", ",", "avg_rouge1", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "log", "(", "'validation_Rouge2_one_epoch'", ",", "avg_rouge2", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "log", "(", "'validation_RougeL_one_epoch'", ",", "avg_rougeL", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "save_txt", "(", "self", ".", "args", ".", "val_save_file", ",", "summary", ")", "\n", "self", ".", "save_txt", "(", "self", ".", "args", ".", "val_save_file", "+", "'reference'", ",", "reference", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.t5.T5MultiModal.test_step": [[157, 170], ["t5.T5MultiModal.model.generate", "image_features.float"], "methods", ["None"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "# batch", "\n", "        ", "src_ids", ",", "decoder_ids", ",", "mask", ",", "label_ids", ",", "image_features", ",", "image_len", "=", "batch", "\n", "# get summary", "\n", "summary_ids", "=", "self", ".", "model", ".", "generate", "(", "input_ids", "=", "src_ids", ",", "\n", "attention_mask", "=", "mask", ",", "\n", "num_beams", "=", "self", ".", "args", ".", "n_beams", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_output_len", ",", "\n", "early_stopping", "=", "True", ",", "\n", "no_repeat_ngram_size", "=", "self", ".", "args", ".", "no_repeat_ngram_size", ",", "\n", "image_features", "=", "image_features", ".", "float", "(", ")", ",", "\n", "image_len", "=", "image_len", ")", "\n", "return", "[", "summary_ids", ",", "label_ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.t5.T5MultiModal.test_epoch_end": [[171, 187], ["datasets.load_metric", "t5.T5MultiModal.calrouge", "t5.T5MultiModal.log", "t5.T5MultiModal.log", "t5.T5MultiModal.log", "t5.T5MultiModal.save_txt", "t5.T5MultiModal.tokenizer.decode", "t5.T5MultiModal.tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.calrouge", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.save_txt"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "rouge", "=", "load_metric", "(", "'rouge'", ",", "experiment_id", "=", "self", ".", "args", ".", "log_name", ")", "\n", "summary", "=", "[", "]", "\n", "reference", "=", "[", "]", "\n", "for", "item", "in", "outputs", ":", "\n", "            ", "summary_id", "=", "item", "[", "0", "]", "\n", "label_id", "=", "item", "[", "1", "]", "\n", "one_summary", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "[", "i", "for", "i", "in", "g", "if", "i", "!=", "-", "100", "]", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "False", ")", "for", "g", "in", "summary_id", "]", "\n", "one_reference", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "[", "i", "for", "i", "in", "g", "if", "i", "!=", "-", "100", "]", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "False", ")", "for", "g", "in", "label_id", "]", "\n", "summary", "+=", "one_summary", "\n", "reference", "+=", "one_reference", "\n", "", "avg_rouge1", ",", "avg_rouge2", ",", "avg_rougeL", "=", "self", ".", "calrouge", "(", "summary", ",", "reference", ",", "rouge", ")", "\n", "self", ".", "log", "(", "'test_Rouge1_one_epoch'", ",", "avg_rouge1", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "log", "(", "'test_Rouge2_one_epoch'", ",", "avg_rouge2", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "log", "(", "'test_RougeL_one_epoch'", ",", "avg_rougeL", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "save_txt", "(", "self", ".", "args", ".", "test_save_file", ",", "summary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.t5.T5MultiModal.calrouge": [[188, 195], ["rouge.add_batch", "rouge.compute"], "methods", ["None"], ["", "def", "calrouge", "(", "self", ",", "summary", ",", "reference", ",", "rouge", ")", ":", "\n", "        ", "rouge", ".", "add_batch", "(", "predictions", "=", "summary", ",", "references", "=", "reference", ")", "\n", "final_results", "=", "rouge", ".", "compute", "(", "rouge_types", "=", "[", "\"rouge1\"", ",", "\"rouge2\"", ",", "\"rougeL\"", "]", ")", "\n", "R1_F1", "=", "final_results", "[", "\"rouge1\"", "]", ".", "mid", ".", "fmeasure", "*", "100", "\n", "R2_F1", "=", "final_results", "[", "\"rouge2\"", "]", ".", "mid", ".", "fmeasure", "*", "100", "\n", "RL_F1", "=", "final_results", "[", "\"rougeL\"", "]", ".", "mid", ".", "fmeasure", "*", "100", "\n", "return", "R1_F1", ",", "R2_F1", ",", "RL_F1", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.t5.T5MultiModal.save_txt": [[196, 201], ["open", "open.writelines", "open.close"], "methods", ["None"], ["", "def", "save_txt", "(", "self", ",", "file_name", ",", "list_data", ")", ":", "\n", "        ", "file", "=", "open", "(", "file_name", ",", "'w'", ")", "\n", "list_data", "=", "[", "item", "+", "'\\n'", "for", "item", "in", "list_data", "]", "\n", "file", ".", "writelines", "(", "list_data", ")", "\n", "file", ".", "close", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.__init__": [[8, 14], ["models.base_model.BaseModel.__init__", "transformers.BartForConditionalGeneration.from_pretrained", "transformers.BartTokenizer.from_pretrained", "datasets.load_metric"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "super", "(", "BartOrigin", ",", "self", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "model", "=", "BartForConditionalGeneration", ".", "from_pretrained", "(", "'facebook/bart-base'", ")", "\n", "self", ".", "tokenizer", "=", "BartTokenizer", ".", "from_pretrained", "(", "'facebook/bart-base'", ")", "\n", "self", ".", "rouge", "=", "load_metric", "(", "'rouge'", ",", "experiment_id", "=", "self", ".", "args", ".", "log_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.forward": [[15, 18], ["bart.BartOrigin.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", ",", "decoder_input_ids", ",", "labels", ")", ":", "\n", "        ", "loss", "=", "self", ".", "model", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "decoder_input_ids", "=", "decoder_input_ids", ",", "labels", "=", "labels", ")", "[", "0", "]", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.validation_step": [[19, 30], ["bart.BartOrigin.model.generate"], "methods", ["None"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "# batch", "\n", "        ", "src_ids", ",", "decoder_ids", ",", "mask", ",", "label_ids", "=", "batch", "\n", "# get summary", "\n", "summary_ids", "=", "self", ".", "model", ".", "generate", "(", "input_ids", "=", "src_ids", ",", "\n", "attention_mask", "=", "mask", ",", "\n", "num_beams", "=", "self", ".", "args", ".", "n_beams", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_output_len", ",", "\n", "early_stopping", "=", "True", ",", "\n", "no_repeat_ngram_size", "=", "self", ".", "args", ".", "no_repeat_ngram_size", ")", "\n", "return", "[", "summary_ids", ",", "label_ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.validation_epoch_end": [[31, 47], ["bart.BartOrigin.calrouge", "bart.BartOrigin.log", "bart.BartOrigin.log", "bart.BartOrigin.log", "bart.BartOrigin.save_txt", "bart.BartOrigin.save_txt", "bart.BartOrigin.tokenizer.decode", "bart.BartOrigin.tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.calrouge", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.save_txt", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.save_txt"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "summary", "=", "[", "]", "\n", "reference", "=", "[", "]", "\n", "for", "item", "in", "outputs", ":", "\n", "            ", "summary_id", "=", "item", "[", "0", "]", "\n", "label_id", "=", "item", "[", "1", "]", "\n", "one_summary", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "[", "i", "for", "i", "in", "g", "if", "i", "!=", "-", "100", "]", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "False", ")", "for", "g", "in", "summary_id", "]", "\n", "one_reference", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "[", "i", "for", "i", "in", "g", "if", "i", "!=", "-", "100", "]", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "False", ")", "for", "g", "in", "label_id", "]", "\n", "summary", "+=", "one_summary", "\n", "reference", "+=", "one_reference", "\n", "", "avg_rouge1", ",", "avg_rouge2", ",", "avg_rougeL", "=", "self", ".", "calrouge", "(", "summary", ",", "reference", ",", "self", ".", "rouge", ")", "\n", "self", ".", "log", "(", "'validation_Rouge1_one_epoch'", ",", "avg_rouge1", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "log", "(", "'validation_Rouge2_one_epoch'", ",", "avg_rouge2", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "log", "(", "'validation_RougeL_one_epoch'", ",", "avg_rougeL", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "save_txt", "(", "self", ".", "args", ".", "val_save_file", "+", "'_reference'", ",", "reference", ")", "\n", "self", ".", "save_txt", "(", "self", ".", "args", ".", "val_save_file", "+", "'_summary'", ",", "summary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.test_step": [[48, 59], ["bart.BartOrigin.model.generate"], "methods", ["None"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "# batch", "\n", "        ", "src_ids", ",", "decoder_ids", ",", "mask", ",", "label_ids", "=", "batch", "\n", "# get summary", "\n", "summary_ids", "=", "self", ".", "model", ".", "generate", "(", "input_ids", "=", "src_ids", ",", "\n", "attention_mask", "=", "mask", ",", "\n", "num_beams", "=", "self", ".", "args", ".", "n_beams", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_output_len", ",", "\n", "early_stopping", "=", "True", ",", "\n", "no_repeat_ngram_size", "=", "self", ".", "args", ".", "no_repeat_ngram_size", ")", "\n", "return", "[", "summary_ids", ",", "label_ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.test_epoch_end": [[60, 76], ["datasets.load_metric", "bart.BartOrigin.calrouge", "bart.BartOrigin.log", "bart.BartOrigin.log", "bart.BartOrigin.log", "bart.BartOrigin.save_txt", "bart.BartOrigin.tokenizer.decode", "bart.BartOrigin.tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.calrouge", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.save_txt"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "rouge", "=", "load_metric", "(", "'rouge'", ",", "experiment_id", "=", "self", ".", "args", ".", "log_name", ")", "\n", "summary", "=", "[", "]", "\n", "reference", "=", "[", "]", "\n", "for", "item", "in", "outputs", ":", "\n", "            ", "summary_id", "=", "item", "[", "0", "]", "\n", "label_id", "=", "item", "[", "1", "]", "\n", "one_summary", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "[", "i", "for", "i", "in", "g", "if", "i", "!=", "-", "100", "]", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "False", ")", "for", "g", "in", "summary_id", "]", "\n", "one_reference", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "[", "i", "for", "i", "in", "g", "if", "i", "!=", "-", "100", "]", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "False", ")", "for", "g", "in", "label_id", "]", "\n", "summary", "+=", "one_summary", "\n", "reference", "+=", "one_reference", "\n", "", "avg_rouge1", ",", "avg_rouge2", ",", "avg_rougeL", "=", "self", ".", "calrouge", "(", "summary", ",", "reference", ",", "rouge", ")", "\n", "self", ".", "log", "(", "'test_Rouge1_one_epoch'", ",", "avg_rouge1", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "log", "(", "'test_Rouge2_one_epoch'", ",", "avg_rouge2", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "log", "(", "'test_RougeL_one_epoch'", ",", "avg_rougeL", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "self", ".", "save_txt", "(", "self", ".", "args", ".", "test_save_file", ",", "summary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.calrouge": [[77, 84], ["rouge.add_batch", "rouge.compute"], "methods", ["None"], ["", "def", "calrouge", "(", "self", ",", "summary", ",", "reference", ",", "rouge", ")", ":", "\n", "        ", "rouge", ".", "add_batch", "(", "predictions", "=", "summary", ",", "references", "=", "reference", ")", "\n", "final_results", "=", "rouge", ".", "compute", "(", "rouge_types", "=", "[", "\"rouge1\"", ",", "\"rouge2\"", ",", "\"rougeL\"", "]", ")", "\n", "R1_F1", "=", "final_results", "[", "\"rouge1\"", "]", ".", "mid", ".", "fmeasure", "*", "100", "\n", "R2_F1", "=", "final_results", "[", "\"rouge2\"", "]", ".", "mid", ".", "fmeasure", "*", "100", "\n", "RL_F1", "=", "final_results", "[", "\"rougeL\"", "]", ".", "mid", ".", "fmeasure", "*", "100", "\n", "return", "R1_F1", ",", "R2_F1", ",", "RL_F1", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.bart.BartOrigin.save_txt": [[85, 90], ["open", "open.writelines", "open.close"], "methods", ["None"], ["", "def", "save_txt", "(", "self", ",", "file_name", ",", "list_data", ")", ":", "\n", "        ", "file", "=", "open", "(", "file_name", ",", "'w'", ")", "\n", "list_data", "=", "[", "item", "+", "'\\n'", "for", "item", "in", "list_data", "]", "\n", "file", ".", "writelines", "(", "list_data", ")", "\n", "file", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.base_model.BaseModel.__init__": [[7, 11], ["pytorch_lightning.LightningModule.__init__"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "learning_rate", "=", "args", ".", "learning_rate", "\n", "", "def", "forward", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.base_model.BaseModel.forward": [[11, 13], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.base_model.BaseModel.training_step": [[14, 22], ["base_model.BaseModel.", "base_model.BaseModel.log"], "methods", ["None"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "# batch", "\n", "        ", "src_ids", ",", "decoder_ids", ",", "mask", ",", "label_ids", "=", "batch", "\n", "# get loss", "\n", "loss", "=", "self", "(", "input_ids", "=", "src_ids", ",", "attention_mask", "=", "mask", ",", "decoder_input_ids", "=", "decoder_ids", ",", "labels", "=", "label_ids", ")", "\n", "# logs", "\n", "self", ".", "log", "(", "'train_loss'", ",", "loss", ",", "on_step", "=", "True", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.base_model.BaseModel.validation_step": [[23, 30], ["base_model.BaseModel.", "base_model.BaseModel.log"], "methods", ["None"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "# batch", "\n", "        ", "src_ids", ",", "decoder_ids", ",", "mask", ",", "label_ids", "=", "batch", "\n", "# get loss", "\n", "loss", "=", "self", "(", "input_ids", "=", "src_ids", ",", "attention_mask", "=", "mask", ",", "decoder_input_ids", "=", "decoder_ids", ",", "labels", "=", "label_ids", ")", "\n", "self", ".", "log", "(", "'validation_loss'", ",", "loss", ",", "on_step", "=", "True", ",", "on_epoch", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.base_model.BaseModel.validation_epoch_end": [[31, 34], ["torch.stack().mean", "base_model.BaseModel.log", "torch.stack"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "avg_loss", "=", "torch", ".", "stack", "(", "[", "x", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "self", ".", "log", "(", "'val_loss_each_epoch'", ",", "avg_loss", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.base_model.BaseModel.test_step": [[35, 41], ["base_model.BaseModel."], "methods", ["None"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "# batch", "\n", "        ", "src_ids", ",", "decoder_ids", ",", "mask", ",", "label_ids", "=", "batch", "\n", "# get loss", "\n", "loss", "=", "self", "(", "input_ids", "=", "src_ids", ",", "attention_mask", "=", "mask", ",", "decoder_input_ids", "=", "decoder_ids", ",", "labels", "=", "label_ids", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.base_model.BaseModel.test_epoch_end": [[42, 45], ["torch.stack().mean", "base_model.BaseModel.log", "torch.stack"], "methods", ["None"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "avg_loss", "=", "torch", ".", "stack", "(", "[", "x", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "self", ".", "log", "(", "'test_loss'", ",", "avg_loss", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.base_model.BaseModel.configure_optimizers": [[46, 210], ["torch.optim.lr_scheduler.StepLR", "torch.optim.Adam", "_img_related_para.append", "torch.optim.Adam", "print", "print", "print", "print", "print", "print", "print", "torch.optim.Adam", "base_model.BaseModel.model.parameters", "base_model.BaseModel.model.model.encoder._linear_1.parameters", "base_model.BaseModel.model.model.encoder._linear_2.parameters", "base_model.BaseModel.model.model.encoder.fg.parameters", "img_related_para.append", "bart_para.append", "_img_related_para.append", "base_model.BaseModel.model.parameters", "base_model.BaseModel.model.model.encoder._linear_1.parameters", "base_model.BaseModel.model.model.encoder._linear_2.parameters", "torch.equal", "base_model.BaseModel.model.parameters", "base_model.BaseModel.model.encoder._linear_1.parameters", "base_model.BaseModel.model.encoder._linear_2.parameters", "base_model.BaseModel.model.encoder.fg.parameters", "img_related_para.append", "bart_para.append", "base_model.BaseModel.model.model.encoder._linear_1.parameters", "base_model.BaseModel.model.encoder._linear_1.parameters", "base_model.BaseModel.model.encoder._linear_2.parameters", "torch.equal", "base_model.BaseModel.model.model.encoder._linear_1.parameters", "base_model.BaseModel.model.model.encoder._linear_2.parameters", "base_model.BaseModel.model.model.encoder._linear_3.parameters", "base_model.BaseModel.model.encoder._linear_1.parameters", "base_model.BaseModel.model.model.encoder._linear_1.parameters", "base_model.BaseModel.model.model.encoder._linear_2.parameters", "base_model.BaseModel.model.model.encoder._linear_3.parameters", "base_model.BaseModel.model.model.encoder._linear_4.parameters", "base_model.BaseModel.model.model.encoder._multi_head_attn.parameters", "base_model.BaseModel.model.encoder._linear_1.parameters", "base_model.BaseModel.model.encoder._linear_2.parameters", "base_model.BaseModel.model.encoder._linear_3.parameters", "base_model.BaseModel.model.model.encoder._linear_1.parameters", "base_model.BaseModel.model.model.encoder._linear_2.parameters", "base_model.BaseModel.model.model.encoder._linear_3.parameters", "base_model.BaseModel.model.model.encoder._multi_head_attn.parameters", "base_model.BaseModel.model.encoder._linear_1.parameters", "base_model.BaseModel.model.encoder._linear_2.parameters", "base_model.BaseModel.model.encoder._linear_3.parameters", "base_model.BaseModel.model.encoder._linear_4.parameters", "base_model.BaseModel.model.encoder._multi_head_attn.parameters", "base_model.BaseModel.model.encoder._linear_1.parameters", "base_model.BaseModel.model.encoder._linear_2.parameters", "base_model.BaseModel.model.encoder._linear_3.parameters", "base_model.BaseModel.model.encoder._multi_head_attn.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "img_lr_factor", "!=", "1", "and", "self", ".", "args", ".", "model", "==", "'multi_modal_bart'", ":", "\n", "# make parameter groups", "\n", "            ", "all_para", "=", "[", "p", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", "]", "\n", "# img_related_para = [p for p in self.model.model.encoder.img_transformer.parameters()] \\", "\n", "#                   +[p for p in self.model.model.encoder.img_feature_transfers.parameters()] \\", "\n", "#                   +[p for p in self.model.model.encoder.fcs.parameters()] \\", "\n", "#                   +[p for p in self.model.model.encoder.final_layer_norm.parameters()] \\", "\n", "#                   +[p for p in self.model.model.encoder.fgs.parameters()]", "\n", "\n", "# img_related_para = [p for p in self.model.model.encoder.img_feature_transfers.parameters()] \\", "\n", "#                   +[p for p in self.model.model.encoder.fcs.parameters()] \\", "\n", "#                   +[p for p in self.model.model.encoder.final_layer_norm.parameters()] \\", "\n", "#                   +[p for p in self.model.model.encoder.fgs.parameters()]", "\n", "\n", "_img_related_para", "=", "[", "]", "\n", "if", "self", ".", "args", ".", "cross_attn_type", "==", "0", ":", "\n", "                ", "_img_related_para", "+=", "[", "\n", "self", ".", "model", ".", "model", ".", "encoder", ".", "_linear_1", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "model", ".", "encoder", ".", "_linear_2", ".", "parameters", "(", ")", "\n", "]", "\n", "", "elif", "self", ".", "args", ".", "cross_attn_type", "==", "1", ":", "\n", "                ", "_img_related_para", "+=", "[", "\n", "self", ".", "model", ".", "model", ".", "encoder", ".", "_linear_1", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "model", ".", "encoder", ".", "_linear_2", ".", "parameters", "(", ")", "\n", "]", "\n", "", "elif", "self", ".", "args", ".", "cross_attn_type", "==", "2", ":", "\n", "                ", "_img_related_para", "+=", "[", "\n", "self", ".", "model", ".", "model", ".", "encoder", ".", "_linear_1", ".", "parameters", "(", ")", "\n", "]", "\n", "", "elif", "self", ".", "args", ".", "cross_attn_type", "==", "3", ":", "\n", "                ", "_img_related_para", "+=", "[", "\n", "self", ".", "model", ".", "model", ".", "encoder", ".", "_linear_1", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "model", ".", "encoder", ".", "_linear_2", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "model", ".", "encoder", ".", "_linear_3", ".", "parameters", "(", ")", "\n", "]", "\n", "", "elif", "self", ".", "args", ".", "cross_attn_type", "==", "4", ":", "\n", "                ", "_img_related_para", "+=", "[", "\n", "self", ".", "model", ".", "model", ".", "encoder", ".", "_linear_1", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "model", ".", "encoder", ".", "_linear_2", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "model", ".", "encoder", ".", "_linear_3", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "model", ".", "encoder", ".", "_linear_4", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "model", ".", "encoder", ".", "_multi_head_attn", ".", "parameters", "(", ")", "\n", "]", "\n", "", "elif", "self", ".", "args", ".", "cross_attn_type", "==", "5", ":", "\n", "                ", "_img_related_para", "+=", "[", "\n", "self", ".", "model", ".", "model", ".", "encoder", ".", "_linear_1", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "model", ".", "encoder", ".", "_linear_2", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "model", ".", "encoder", ".", "_linear_3", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "model", ".", "encoder", ".", "_multi_head_attn", ".", "parameters", "(", ")", "\n", "]", "\n", "\n", "", "if", "self", ".", "args", ".", "use_forget_gate", ":", "\n", "                ", "_img_related_para", ".", "append", "(", "self", ".", "model", ".", "model", ".", "encoder", ".", "fg", ".", "parameters", "(", ")", ")", "\n", "\n", "", "img_related_para", "=", "[", "]", "\n", "for", "params", "in", "_img_related_para", ":", "\n", "                ", "for", "param", "in", "params", ":", "\n", "                    ", "img_related_para", ".", "append", "(", "param", ")", "\n", "\n", "", "", "bart_para", "=", "[", "]", "\n", "\n", "for", "p", "in", "all_para", ":", "\n", "                ", "flag", "=", "0", "\n", "for", "q", "in", "img_related_para", ":", "\n", "                    ", "if", "p", ".", "shape", "==", "q", ".", "shape", ":", "\n", "                        ", "if", "torch", ".", "equal", "(", "p", ",", "q", ")", ":", "\n", "                            ", "flag", "=", "1", "\n", "", "", "", "if", "flag", "==", "0", ":", "\n", "                    ", "bart_para", ".", "append", "(", "p", ")", "\n", "continue", "\n", "\n", "", "", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "[", "\n", "{", "'params'", ":", "bart_para", "}", ",", "\n", "{", "'params'", ":", "img_related_para", ",", "'lr'", ":", "self", ".", "learning_rate", "*", "self", ".", "args", ".", "img_lr_factor", "}", ",", "\n", "]", ",", "lr", "=", "self", ".", "learning_rate", ")", "\n", "\n", "", "elif", "self", ".", "args", ".", "img_lr_factor", "!=", "1", "and", "self", ".", "args", ".", "model", "==", "'multi_modal_t5'", ":", "\n", "# make parameter groups", "\n", "            ", "all_para", "=", "[", "p", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", "]", "\n", "# img_related_para = [p for p in self.model.model.encoder.img_transformer.parameters()] \\", "\n", "#                   +[p for p in self.model.model.encoder.img_feature_transfers.parameters()] \\", "\n", "#                   +[p for p in self.model.model.encoder.fcs.parameters()] \\", "\n", "#                   +[p for p in self.model.model.encoder.final_layer_norm.parameters()] \\", "\n", "#                   +[p for p in self.model.model.encoder.fgs.parameters()]", "\n", "\n", "# img_related_para = [p for p in self.model.model.encoder.img_feature_transfers.parameters()] \\", "\n", "#                   +[p for p in self.model.model.encoder.fcs.parameters()] \\", "\n", "#                   +[p for p in self.model.model.encoder.final_layer_norm.parameters()] \\", "\n", "#                   +[p for p in self.model.model.encoder.fgs.parameters()]", "\n", "\n", "_img_related_para", "=", "[", "]", "\n", "if", "self", ".", "args", ".", "cross_attn_type", "==", "0", ":", "\n", "                ", "_img_related_para", "+=", "[", "\n", "self", ".", "model", ".", "encoder", ".", "_linear_1", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "encoder", ".", "_linear_2", ".", "parameters", "(", ")", "\n", "]", "\n", "", "elif", "self", ".", "args", ".", "cross_attn_type", "==", "1", ":", "\n", "                ", "_img_related_para", "+=", "[", "\n", "self", ".", "model", ".", "encoder", ".", "_linear_1", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "encoder", ".", "_linear_2", ".", "parameters", "(", ")", "\n", "]", "\n", "", "elif", "self", ".", "args", ".", "cross_attn_type", "==", "2", ":", "\n", "                ", "_img_related_para", "+=", "[", "\n", "self", ".", "model", ".", "encoder", ".", "_linear_1", ".", "parameters", "(", ")", "\n", "]", "\n", "", "elif", "self", ".", "args", ".", "cross_attn_type", "==", "3", ":", "\n", "                ", "_img_related_para", "+=", "[", "\n", "self", ".", "model", ".", "encoder", ".", "_linear_1", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "encoder", ".", "_linear_2", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "encoder", ".", "_linear_3", ".", "parameters", "(", ")", "\n", "]", "\n", "", "elif", "self", ".", "args", ".", "cross_attn_type", "==", "4", ":", "\n", "                ", "_img_related_para", "+=", "[", "\n", "self", ".", "model", ".", "encoder", ".", "_linear_1", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "encoder", ".", "_linear_2", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "encoder", ".", "_linear_3", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "encoder", ".", "_linear_4", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "encoder", ".", "_multi_head_attn", ".", "parameters", "(", ")", "\n", "]", "\n", "", "elif", "self", ".", "args", ".", "cross_attn_type", "==", "5", ":", "\n", "                ", "_img_related_para", "+=", "[", "\n", "self", ".", "model", ".", "encoder", ".", "_linear_1", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "encoder", ".", "_linear_2", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "encoder", ".", "_linear_3", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "encoder", ".", "_multi_head_attn", ".", "parameters", "(", ")", "\n", "]", "\n", "\n", "", "if", "self", ".", "args", ".", "use_forget_gate", ":", "\n", "                ", "_img_related_para", ".", "append", "(", "self", ".", "model", ".", "encoder", ".", "fg", ".", "parameters", "(", ")", ")", "\n", "\n", "", "img_related_para", "=", "[", "]", "\n", "for", "params", "in", "_img_related_para", ":", "\n", "                ", "for", "param", "in", "params", ":", "\n", "                    ", "img_related_para", ".", "append", "(", "param", ")", "\n", "\n", "", "", "bart_para", "=", "[", "]", "\n", "\n", "for", "p", "in", "all_para", ":", "\n", "                ", "flag", "=", "0", "\n", "for", "q", "in", "img_related_para", ":", "\n", "                    ", "if", "p", ".", "shape", "==", "q", ".", "shape", ":", "\n", "                        ", "if", "torch", ".", "equal", "(", "p", ",", "q", ")", ":", "\n", "                            ", "flag", "=", "1", "\n", "", "", "", "if", "flag", "==", "0", ":", "\n", "                    ", "bart_para", ".", "append", "(", "p", ")", "\n", "continue", "\n", "\n", "", "", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "[", "\n", "{", "'params'", ":", "bart_para", "}", ",", "\n", "{", "'params'", ":", "img_related_para", ",", "'lr'", ":", "self", ".", "learning_rate", "*", "self", ".", "args", ".", "img_lr_factor", "}", ",", "\n", "]", ",", "lr", "=", "self", ".", "learning_rate", ")", "\n", "print", "(", "'LEARNING RATE SET SUCCESSFUL'", ")", "\n", "print", "(", "'LEARNING RATE SET SUCCESSFUL'", ")", "\n", "print", "(", "'LEARNING RATE SET SUCCESSFUL'", ")", "\n", "print", "(", "'LEARNING RATE SET SUCCESSFUL'", ")", "\n", "print", "(", "'LEARNING RATE SET SUCCESSFUL'", ")", "\n", "print", "(", "'LEARNING RATE SET SUCCESSFUL'", ")", "\n", "print", "(", "'LEARNING RATE SET SUCCESSFUL'", ")", "\n", "", "else", ":", "\n", "            ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "learning_rate", ")", "\n", "# return optimizer", "\n", "", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "optimizer", ",", "step_size", "=", "self", ".", "args", ".", "scheduler_lambda1", ",", "gamma", "=", "self", ".", "args", ".", "scheduler_lambda2", ")", "\n", "return", "[", "optimizer", "]", ",", "[", "scheduler", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.img_transformer.ImageTransformerEncoder.__init__": [[8, 14], ["torch.nn.Module.__init__", "torch.nn.TransformerEncoderLayer", "img_transformer._TransformerEncoder", "img_transformer.PositionalEncoding"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "num_layers", ",", "num_heads", ",", "dim_feedforward", "=", "2048", ")", ":", "\n", "        ", "super", "(", "ImageTransformerEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "d_model", "=", "d_model", "\n", "encoder_layer", "=", "nn", ".", "TransformerEncoderLayer", "(", "d_model", "=", "d_model", ",", "nhead", "=", "num_heads", ",", "dim_feedforward", "=", "dim_feedforward", ")", "\n", "self", ".", "encoder", "=", "_TransformerEncoder", "(", "encoder_layer", ",", "num_layers", "=", "num_layers", ")", "\n", "self", ".", "pos_encoder", "=", "PositionalEncoding", "(", "d_model", ",", "dropout", "=", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.img_transformer.ImageTransformerEncoder.forward": [[15, 32], ["img_transformer.ImageTransformerEncoder.permute", "img_transformer.ImageTransformerEncoder.pos_encoder", "img_transformer.ImageTransformerEncoder.encoder", "max", "torch.tensor().to", "math.sqrt", "o.permute", "torch.tensor"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ":", "torch", ".", "Tensor", ",", "lens", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "None", ")", ":", "\n", "        ", "if", "lens", "is", "not", "None", ":", "\n", "            ", "max_len", "=", "max", "(", "lens", ")", "\n", "\n", "mask", "=", "[", "(", "[", "False", "]", "*", "l", "+", "[", "True", "]", "*", "(", "max_len", "-", "l", ")", ")", "for", "l", "in", "lens", "]", "\n", "mask", "=", "torch", ".", "tensor", "(", "mask", ")", ".", "to", "(", "device", "=", "inputs", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "mask", "=", "None", "\n", "\n", "", "inputs", "=", "inputs", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n", "inputs", "=", "inputs", "*", "math", ".", "sqrt", "(", "self", ".", "d_model", ")", "\n", "inputs", "=", "self", ".", "pos_encoder", "(", "inputs", ")", "\n", "\n", "outputs", "=", "self", ".", "encoder", "(", "src", "=", "inputs", ",", "src_key_padding_mask", "=", "mask", ")", "# (seq_len, bs, dim)", "\n", "\n", "return", "[", "o", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "for", "o", "in", "outputs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.img_transformer._TransformerEncoder.__init__": [[42, 47], ["torch.nn.Module.__init__", "img_transformer._get_clones"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.img_transformer._get_clones"], ["    ", "def", "__init__", "(", "self", ",", "encoder_layer", ",", "num_layers", ",", "norm", "=", "None", ")", ":", "\n", "        ", "super", "(", "_TransformerEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "_get_clones", "(", "encoder_layer", ",", "num_layers", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "norm", "=", "norm", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.img_transformer._TransformerEncoder.forward": [[48, 59], ["mod", "outputs.append", "img_transformer._TransformerEncoder.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ":", "torch", ".", "Tensor", ",", "mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "src_key_padding_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "outputs", "=", "[", "src", "]", "\n", "\n", "for", "mod", "in", "self", ".", "layers", ":", "\n", "            ", "output", "=", "mod", "(", "outputs", "[", "-", "1", "]", ",", "src_mask", "=", "mask", ",", "src_key_padding_mask", "=", "src_key_padding_mask", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "\n", "", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "outputs", "[", "-", "1", "]", "=", "self", ".", "norm", "(", "outputs", "[", "-", "1", "]", ")", "\n", "\n", "", "return", "outputs", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.img_transformer.PositionalEncoding.__init__": [[61, 72], ["torch.nn.Module.__init__", "torch.nn.Dropout", "torch.zeros", "torch.arange().unsqueeze", "torch.exp", "torch.sin", "torch.cos", "pe.unsqueeze().transpose.unsqueeze().transpose.unsqueeze().transpose", "img_transformer.PositionalEncoding.register_buffer", "torch.arange", "torch.arange().float", "pe.unsqueeze().transpose.unsqueeze().transpose.unsqueeze", "torch.arange", "math.log"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "dropout", "=", "0.1", ",", "max_len", "=", "5000", ")", ":", "\n", "        ", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n", "pe", "=", "torch", ".", "zeros", "(", "max_len", ",", "d_model", ")", "\n", "position", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ",", "dtype", "=", "torch", ".", "float", ")", ".", "unsqueeze", "(", "1", ")", "\n", "div_term", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "0", ",", "d_model", ",", "2", ")", ".", "float", "(", ")", "*", "(", "-", "math", ".", "log", "(", "10000.0", ")", "/", "d_model", ")", ")", "\n", "pe", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "sin", "(", "position", "*", "div_term", ")", "\n", "pe", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "cos", "(", "position", "*", "div_term", ")", "\n", "pe", "=", "pe", ".", "unsqueeze", "(", "0", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "self", ".", "register_buffer", "(", "'pe'", ",", "pe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.img_transformer.PositionalEncoding.forward": [[73, 76], ["img_transformer.PositionalEncoding.dropout", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "+", "self", ".", "pe", "[", ":", "x", ".", "size", "(", "0", ")", ",", ":", "]", "\n", "return", "self", ".", "dropout", "(", "x", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.img_transformer.padTensor": [[34, 37], ["t.size", "torch.cat", "torch.zeros().to", "torch.zeros"], "function", ["None"], ["", "", "def", "padTensor", "(", "t", ":", "torch", ".", "Tensor", ",", "targetLen", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "oriLen", ",", "dim", "=", "t", ".", "size", "(", ")", "\n", "return", "torch", ".", "cat", "(", "(", "t", ",", "torch", ".", "zeros", "(", "targetLen", "-", "oriLen", ",", "dim", ")", ".", "to", "(", "t", ".", "device", ")", ")", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.models.img_transformer._get_clones": [[38, 40], ["torch.nn.ModuleList", "copy.deepcopy", "range"], "function", ["None"], ["", "def", "_get_clones", "(", "module", ",", "N", ")", ":", "\n", "    ", "return", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "module", ")", "for", "i", "in", "range", "(", "N", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.OurDataset.__init__": [[11, 36], ["data_builder.OurDataset.file_reader", "data_builder.OurDataset.file_reader", "print", "data_builder.OurDataset.tokenize", "data_builder.OurDataset.tokenize", "transformers.T5Tokenizer.from_pretrained", "transformers.BartTokenizer.from_pretrained", "item.split", "item.split", "item.split"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.OurDataset.file_reader", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.OurDataset.file_reader", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.OurDataset.tokenize", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.OurDataset.tokenize"], ["def", "__init__", "(", "self", ",", "args", ",", "mode", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "# initial tokenizer and text", "\n", "if", "'t5'", "in", "self", ".", "args", ".", "model", ":", "\n", "            ", "self", ".", "tokenizer", "=", "T5Tokenizer", ".", "from_pretrained", "(", "'t5-base'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tokenizer", "=", "BartTokenizer", ".", "from_pretrained", "(", "'facebook/bart-base'", ")", "\n", "", "if", "mode", "==", "'train'", ":", "\n", "            ", "src_path", "=", "args", ".", "train_src_path", "\n", "tgt_path", "=", "args", ".", "train_tgt_path", "\n", "", "if", "mode", "==", "'val'", ":", "\n", "            ", "src_path", "=", "args", ".", "val_src_path", "\n", "tgt_path", "=", "args", ".", "val_tgt_path", "\n", "", "if", "mode", "==", "'test'", ":", "\n", "            ", "src_path", "=", "args", ".", "test_src_path", "\n", "tgt_path", "=", "args", ".", "test_tgt_path", "\n", "", "self", ".", "src", "=", "self", ".", "file_reader", "(", "src_path", ")", "\n", "self", ".", "tgt", "=", "self", ".", "file_reader", "(", "tgt_path", ")", "\n", "self", ".", "data_id", "=", "[", "item", ".", "split", "(", ")", "[", "0", "]", "for", "item", "in", "self", ".", "tgt", "]", "\n", "self", ".", "src", "=", "[", "\" \"", ".", "join", "(", "item", ".", "split", "(", ")", "[", "1", ":", "]", ")", "for", "item", "in", "self", ".", "src", "]", "\n", "self", ".", "tgt", "=", "[", "\" \"", ".", "join", "(", "item", ".", "split", "(", ")", "[", "1", ":", "]", ")", "for", "item", "in", "self", ".", "tgt", "]", "\n", "# get tokenized test", "\n", "print", "(", "'==================== Tokening {} set ======================'", ".", "format", "(", "mode", ")", ")", "\n", "self", ".", "src_ids", "=", "self", ".", "tokenize", "(", "self", ".", "src", ")", "\n", "self", ".", "tgt_ids", "=", "self", ".", "tokenize", "(", "self", ".", "tgt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.OurDataset.__len__": [[37, 39], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.OurDataset.__getitem__": [[40, 42], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "src_ids", "[", "idx", "]", ",", "self", ".", "tgt_ids", "[", "idx", "]", ",", "self", ".", "data_id", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.OurDataset.tokenize": [[43, 46], ["data_builder.OurDataset.tokenizer.encode", "tqdm.tqdm.tqdm"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ",", "data", ")", ":", "\n", "        ", "tokenized_text", "=", "[", "self", ".", "tokenizer", ".", "encode", "(", "i", ",", "add_special_tokens", "=", "False", ")", "for", "i", "in", "tqdm", "(", "data", ")", "]", "\n", "return", "tokenized_text", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.OurDataset.file_reader": [[47, 51], ["open", "item.strip", "open.readlines"], "methods", ["None"], ["", "def", "file_reader", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "file", "=", "open", "(", "file_path", ",", "'r'", ")", "\n", "lines", "=", "[", "item", ".", "strip", "(", "'\\n'", ")", "for", "item", "in", "file", ".", "readlines", "(", ")", "]", "\n", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.OurDataset.collate_fn": [[52, 183], ["range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "src.append", "tgt.append", "utils.utils.get_mask", "numpy.zeros", "range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "utils.utils.pad_sents", "utils.utils.pad_sents", "utils.utils.pad_sents", "len", "src.append", "tgt.append", "img_len.append", "utils.utils.get_mask", "torch.tensor", "range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "numpy.load", "utils.utils.pad_sents", "utils.utils.pad_sents", "utils.utils.pad_sents", "len", "src.append", "tgt.append", "utils.utils.get_mask", "numpy.zeros", "range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "ValueError", "max", "utils.utils.pad_sents", "utils.utils.pad_sents", "utils.utils.pad_sents", "len", "src.append", "tgt.append", "img_len.append", "utils.utils.get_mask", "torch.tensor", "len", "utils.utils.pad_sents", "utils.utils.pad_sents", "utils.utils.pad_sents", "numpy.load", "numpy.load", "max"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.get_mask", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.pad_sents", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.pad_sents", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.pad_sents", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.get_mask", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.load", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.pad_sents", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.pad_sents", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.pad_sents", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.get_mask", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.pad_sents", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.pad_sents", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.pad_sents", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.get_mask", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.pad_sents", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.pad_sents", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.pad_sents", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.load", "home.repos.pwc.inspect_result.hltchkust_vg-gplms.utils.utils.load"], ["", "def", "collate_fn", "(", "self", ",", "data", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "model", "==", "'text_only_bart'", ":", "\n", "# rebuild the raw text and truncate to max length", "\n", "            ", "max_input_len", "=", "self", ".", "args", ".", "max_input_len", "\n", "max_output_len", "=", "self", ".", "args", ".", "max_output_len", "\n", "raw_src", "=", "[", "pair", "[", "0", "]", "for", "pair", "in", "data", "]", "\n", "raw_tgt", "=", "[", "pair", "[", "1", "]", "for", "pair", "in", "data", "]", "\n", "raw_src", "=", "[", "i", "[", ":", "max_input_len", "-", "1", "]", "for", "i", "in", "raw_src", "]", "\n", "raw_tgt", "=", "[", "i", "[", ":", "max_output_len", "-", "1", "]", "for", "i", "in", "raw_tgt", "]", "\n", "src", "=", "[", "]", "\n", "tgt", "=", "[", "]", "\n", "# remove blank data", "\n", "for", "i", "in", "range", "(", "len", "(", "raw_src", ")", ")", ":", "\n", "                ", "src", ".", "append", "(", "raw_src", "[", "i", "]", ")", "\n", "tgt", ".", "append", "(", "raw_tgt", "[", "i", "]", ")", "\n", "# make input mask", "\n", "", "mask", "=", "torch", ".", "tensor", "(", "get_mask", "(", "src", ",", "max_len", "=", "max_input_len", ")", ")", "\n", "# make input ids", "\n", "src_ids", "=", "torch", ".", "tensor", "(", "pad_sents", "(", "src", ",", "1", ",", "max_len", "=", "max_input_len", ")", "[", "0", "]", ")", "\n", "# make output ids", "\n", "decoder_ids", "=", "[", "[", "0", "]", "+", "i", "for", "i", "in", "tgt", "]", "\n", "# make output labels", "\n", "label_ids", "=", "[", "i", "+", "[", "2", "]", "for", "i", "in", "tgt", "]", "\n", "decoder_ids", "=", "torch", ".", "tensor", "(", "pad_sents", "(", "decoder_ids", ",", "1", ",", "max_len", "=", "max_output_len", ")", "[", "0", "]", ")", "\n", "label_ids", "=", "torch", ".", "tensor", "(", "pad_sents", "(", "label_ids", ",", "-", "100", ",", "max_len", "=", "max_output_len", ")", "[", "0", "]", ")", "\n", "\n", "return", "src_ids", ",", "decoder_ids", ",", "mask", ",", "label_ids", "\n", "\n", "", "elif", "self", ".", "args", ".", "model", "==", "'multi_modal_bart'", ":", "\n", "# rebuild the raw text and truncate to max length", "\n", "            ", "max_input_len", "=", "self", ".", "args", ".", "max_input_len", "\n", "max_output_len", "=", "self", ".", "args", ".", "max_output_len", "\n", "max_img_len", "=", "self", ".", "args", ".", "max_img_len", "\n", "raw_src", "=", "[", "pair", "[", "0", "]", "for", "pair", "in", "data", "]", "\n", "raw_tgt", "=", "[", "pair", "[", "1", "]", "for", "pair", "in", "data", "]", "\n", "data_id", "=", "[", "pair", "[", "2", "]", "for", "pair", "in", "data", "]", "\n", "raw_src", "=", "[", "i", "[", ":", "max_input_len", "-", "1", "]", "for", "i", "in", "raw_src", "]", "\n", "raw_tgt", "=", "[", "i", "[", ":", "max_output_len", "-", "1", "]", "for", "i", "in", "raw_tgt", "]", "\n", "src", "=", "[", "]", "\n", "tgt", "=", "[", "]", "\n", "img", "=", "np", ".", "zeros", "(", "[", "len", "(", "raw_src", ")", ",", "self", ".", "args", ".", "max_img_len", ",", "2048", "]", ")", "\n", "img_len", "=", "[", "]", "\n", "# remove blank data", "\n", "for", "i", "in", "range", "(", "len", "(", "raw_src", ")", ")", ":", "\n", "                ", "src", ".", "append", "(", "raw_src", "[", "i", "]", ")", "\n", "tgt", ".", "append", "(", "raw_tgt", "[", "i", "]", ")", "\n", "image_feature", "=", "np", ".", "load", "(", "self", ".", "args", ".", "image_feature_path", "+", "data_id", "[", "i", "]", "+", "'.npy'", ")", "[", ":", "max_img_len", "]", "\n", "img", "[", "i", "]", "[", ":", "image_feature", ".", "shape", "[", "0", "]", "]", "=", "image_feature", "\n", "img_len", ".", "append", "(", "image_feature", ".", "shape", "[", "0", "]", ")", "\n", "", "img", "=", "img", "[", ":", ",", ":", "max", "(", "img_len", ")", "]", "\n", "\n", "# make input mask", "\n", "mask", "=", "torch", ".", "tensor", "(", "get_mask", "(", "src", ",", "max_len", "=", "max_input_len", ")", ")", "\n", "# make input ids", "\n", "src_ids", "=", "torch", ".", "tensor", "(", "pad_sents", "(", "src", ",", "1", ",", "max_len", "=", "max_input_len", ")", "[", "0", "]", ")", "\n", "# make output ids", "\n", "decoder_ids", "=", "[", "[", "0", "]", "+", "i", "for", "i", "in", "tgt", "]", "\n", "# make output labels", "\n", "label_ids", "=", "[", "i", "+", "[", "2", "]", "for", "i", "in", "tgt", "]", "\n", "decoder_ids", "=", "torch", ".", "tensor", "(", "pad_sents", "(", "decoder_ids", ",", "1", ",", "max_len", "=", "max_output_len", ")", "[", "0", "]", ")", "\n", "label_ids", "=", "torch", ".", "tensor", "(", "pad_sents", "(", "label_ids", ",", "-", "100", ",", "max_len", "=", "max_output_len", ")", "[", "0", "]", ")", "\n", "return", "src_ids", ",", "decoder_ids", ",", "mask", ",", "label_ids", ",", "torch", ".", "tensor", "(", "img", ")", ",", "img_len", "\n", "\n", "", "elif", "self", ".", "args", ".", "model", "==", "'text_only_t5'", ":", "\n", "# rebuild the raw text and truncate to max length", "\n", "            ", "max_input_len", "=", "self", ".", "args", ".", "max_input_len", "\n", "max_output_len", "=", "self", ".", "args", ".", "max_output_len", "\n", "raw_src", "=", "[", "pair", "[", "0", "]", "for", "pair", "in", "data", "]", "\n", "raw_tgt", "=", "[", "pair", "[", "1", "]", "for", "pair", "in", "data", "]", "\n", "raw_src", "=", "[", "i", "[", ":", "max_input_len", "-", "1", "]", "for", "i", "in", "raw_src", "]", "\n", "raw_tgt", "=", "[", "i", "[", ":", "max_output_len", "-", "1", "]", "for", "i", "in", "raw_tgt", "]", "\n", "src", "=", "[", "]", "\n", "tgt", "=", "[", "]", "\n", "# remove blank data", "\n", "for", "i", "in", "range", "(", "len", "(", "raw_src", ")", ")", ":", "\n", "                ", "src", ".", "append", "(", "raw_src", "[", "i", "]", ")", "\n", "tgt", ".", "append", "(", "raw_tgt", "[", "i", "]", ")", "\n", "# make input mask", "\n", "", "mask", "=", "torch", ".", "tensor", "(", "get_mask", "(", "src", ",", "max_len", "=", "max_input_len", ")", ")", "\n", "# make input ids", "\n", "src_ids", "=", "torch", ".", "tensor", "(", "pad_sents", "(", "src", ",", "0", ",", "max_len", "=", "max_input_len", ")", "[", "0", "]", ")", "\n", "# make output ids", "\n", "decoder_ids", "=", "[", "[", "0", "]", "+", "i", "for", "i", "in", "tgt", "]", "\n", "# make output labels", "\n", "label_ids", "=", "[", "i", "+", "[", "1", "]", "for", "i", "in", "tgt", "]", "\n", "decoder_ids", "=", "torch", ".", "tensor", "(", "pad_sents", "(", "decoder_ids", ",", "0", ",", "max_len", "=", "max_output_len", ")", "[", "0", "]", ")", "\n", "label_ids", "=", "torch", ".", "tensor", "(", "pad_sents", "(", "label_ids", ",", "-", "100", ",", "max_len", "=", "max_output_len", ")", "[", "0", "]", ")", "\n", "\n", "return", "src_ids", ",", "decoder_ids", ",", "mask", ",", "label_ids", "\n", "\n", "", "elif", "self", ".", "args", ".", "model", "==", "'multi_modal_t5'", ":", "\n", "# rebuild the raw text and truncate to max length", "\n", "            ", "max_input_len", "=", "self", ".", "args", ".", "max_input_len", "\n", "max_output_len", "=", "self", ".", "args", ".", "max_output_len", "\n", "max_img_len", "=", "self", ".", "args", ".", "max_img_len", "\n", "raw_src", "=", "[", "pair", "[", "0", "]", "for", "pair", "in", "data", "]", "\n", "raw_tgt", "=", "[", "pair", "[", "1", "]", "for", "pair", "in", "data", "]", "\n", "data_id", "=", "[", "pair", "[", "2", "]", "for", "pair", "in", "data", "]", "\n", "raw_src", "=", "[", "i", "[", ":", "max_input_len", "-", "1", "]", "for", "i", "in", "raw_src", "]", "\n", "raw_tgt", "=", "[", "i", "[", ":", "max_output_len", "-", "1", "]", "for", "i", "in", "raw_tgt", "]", "\n", "src", "=", "[", "]", "\n", "tgt", "=", "[", "]", "\n", "img", "=", "np", ".", "zeros", "(", "[", "len", "(", "raw_src", ")", ",", "self", ".", "args", ".", "max_img_len", ",", "2048", "]", ")", "\n", "img_len", "=", "[", "]", "\n", "# remove blank data", "\n", "for", "i", "in", "range", "(", "len", "(", "raw_src", ")", ")", ":", "\n", "                ", "src", ".", "append", "(", "raw_src", "[", "i", "]", ")", "\n", "tgt", ".", "append", "(", "raw_tgt", "[", "i", "]", ")", "\n", "if", "self", ".", "args", ".", "vision_use_noise", ":", "\n", "                    ", "image_feature", "=", "np", ".", "load", "(", "self", ".", "args", ".", "image_feature_path", "+", "data_id", "[", "i", "]", "+", "'_noise.npy'", ")", "[", ":", "max_img_len", "]", "\n", "", "else", ":", "\n", "                    ", "image_feature", "=", "np", ".", "load", "(", "self", ".", "args", ".", "image_feature_path", "+", "data_id", "[", "i", "]", "+", "'.npy'", ")", "[", ":", "max_img_len", "]", "\n", "# image_feature = np.load(self.args.image_feature_path + data_id[i]+ '.npy')[:max_img_len]", "\n", "", "img", "[", "i", "]", "[", ":", "image_feature", ".", "shape", "[", "0", "]", "]", "=", "image_feature", "\n", "img_len", ".", "append", "(", "image_feature", ".", "shape", "[", "0", "]", ")", "\n", "", "img", "=", "img", "[", ":", ",", ":", "max", "(", "img_len", ")", "]", "\n", "\n", "# make input mask", "\n", "mask", "=", "torch", ".", "tensor", "(", "get_mask", "(", "src", ",", "max_len", "=", "max_input_len", ")", ")", "\n", "# make input ids", "\n", "src_ids", "=", "torch", ".", "tensor", "(", "pad_sents", "(", "src", ",", "0", ",", "max_len", "=", "max_input_len", ")", "[", "0", "]", ")", "\n", "# make output ids", "\n", "decoder_ids", "=", "[", "[", "0", "]", "+", "i", "for", "i", "in", "tgt", "]", "\n", "# make output labels", "\n", "label_ids", "=", "[", "i", "+", "[", "1", "]", "for", "i", "in", "tgt", "]", "\n", "decoder_ids", "=", "torch", ".", "tensor", "(", "pad_sents", "(", "decoder_ids", ",", "0", ",", "max_len", "=", "max_output_len", ")", "[", "0", "]", ")", "\n", "label_ids", "=", "torch", ".", "tensor", "(", "pad_sents", "(", "label_ids", ",", "-", "100", ",", "max_len", "=", "max_output_len", ")", "[", "0", "]", ")", "\n", "return", "src_ids", ",", "decoder_ids", ",", "mask", ",", "label_ids", ",", "torch", ".", "tensor", "(", "img", ")", ",", "img_len", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid model\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__": [[186, 206], ["pytorch_lightning.LightningDataModule.__init__", "data_builder.OurDataset", "data_builder.OurDataset", "data_builder.OurDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.__init__"], ["  ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "train_set", "=", "OurDataset", "(", "args", ",", "'train'", ")", "\n", "val_set", "=", "OurDataset", "(", "args", ",", "'val'", ")", "\n", "test_set", "=", "OurDataset", "(", "args", ",", "'test'", ")", "\n", "self", ".", "train_loader", "=", "DataLoader", "(", "dataset", "=", "train_set", ",", "batch_size", "=", "args", ".", "batch_size", ",", "num_workers", "=", "3", ",", "shuffle", "=", "True", ",", "collate_fn", "=", "train_set", ".", "collate_fn", ")", "\n", "self", ".", "val_loader", "=", "DataLoader", "(", "dataset", "=", "val_set", ",", "batch_size", "=", "args", ".", "batch_size", ",", "num_workers", "=", "3", ",", "shuffle", "=", "False", ",", "collate_fn", "=", "val_set", ".", "collate_fn", ")", "\n", "self", ".", "test_loader", "=", "DataLoader", "(", "dataset", "=", "test_set", ",", "batch_size", "=", "args", ".", "batch_size", ",", "num_workers", "=", "3", ",", "shuffle", "=", "False", ",", "collate_fn", "=", "test_set", ".", "collate_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.train_dataloader": [[207, 209], ["None"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "train_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.val_dataloader": [[210, 212], ["None"], "methods", ["None"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "val_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.data_preprocess.data_builder.SummaryDataModule.test_dataloader": [[213, 215], ["None"], "methods", ["None"], ["", "def", "test_dataloader", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "test_loader", "", "", "", ""]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.evaluation.calculate_content_f1.cal_content_f1": [[6, 70], ["open", "open.readlines", "open.close", "print", "item[].split", "item[].split", "sum", "sum", "len", "len", "new_items.append", "numpy.mean", "one_item.append", "items.append", "ref_remove_words.append", "hyp_remove_words.append", "remove_pair.append", "keep_pair.append", "ref_word_bag.append", "hyp_word_bag.append", "int", "int", "int", "line.split", "item[].split", "item[].split", "int", "numbers[].split", "int", "int", "numbers[].split", "numbers[].split", "numbers[].split"], "function", ["None"], ["def", "cal_content_f1", "(", "file", ")", ":", "\n", "    ", "F", "=", "open", "(", "file", ")", "\n", "data", "=", "F", ".", "readlines", "(", ")", "\n", "F", ".", "close", "(", ")", "\n", "items", "=", "[", "]", "\n", "one_item", "=", "[", "]", "\n", "for", "line", "in", "data", ":", "\n", "        ", "if", "line", "!=", "'\\n'", ":", "\n", "            ", "one_item", ".", "append", "(", "line", ")", "\n", "", "else", ":", "\n", "            ", "items", ".", "append", "(", "one_item", ")", "\n", "one_item", "=", "[", "]", "\n", "\n", "\n", "", "", "new_items", "=", "[", "]", "\n", "for", "item", "in", "items", ":", "\n", "        ", "new_item", "=", "{", "}", "\n", "ref", "=", "item", "[", "2", "]", ".", "split", "(", ")", "\n", "gen", "=", "item", "[", "1", "]", ".", "split", "(", ")", "\n", "new_item", "[", "'ref_text'", "]", "=", "ref", "\n", "new_item", "[", "'hyp_text'", "]", "=", "gen", "\n", "remove_pair", "=", "[", "]", "\n", "keep_pair", "=", "[", "]", "\n", "ref_remove_words", "=", "[", "]", "\n", "hyp_remove_words", "=", "[", "]", "\n", "for", "line", "in", "item", "[", "4", ":", "]", ":", "\n", "            ", "numbers", "=", "[", "item", "for", "item", "in", "line", ".", "split", "(", "'\\t'", ")", "if", "item", "!=", "''", "]", "[", ":", "2", "]", "\n", "if", "ref", "[", "int", "(", "numbers", "[", "0", "]", ".", "split", "(", "':'", ")", "[", "0", "]", ")", "]", "in", "summary_words", "and", "int", "(", "numbers", "[", "0", "]", ".", "split", "(", "':'", ")", "[", "1", "]", ")", "==", "1", ":", "\n", "                ", "ref_remove_words", ".", "append", "(", "ref", "[", "int", "(", "numbers", "[", "0", "]", ".", "split", "(", "':'", ")", "[", "0", "]", ")", "]", ")", "\n", "hyp_remove_words", ".", "append", "(", "gen", "[", "int", "(", "numbers", "[", "1", "]", ".", "split", "(", "':'", ")", "[", "0", "]", ")", "]", ")", "\n", "remove_pair", ".", "append", "(", "numbers", ")", "\n", "continue", "\n", "", "else", ":", "\n", "                ", "keep_pair", ".", "append", "(", "numbers", ")", "\n", "", "", "new_item", "[", "'remove_pair'", "]", "=", "remove_pair", "\n", "new_item", "[", "'keep_pair'", "]", "=", "keep_pair", "\n", "new_item", "[", "'ref_remove_words'", "]", "=", "ref_remove_words", "\n", "new_item", "[", "'hyp_remove_words'", "]", "=", "hyp_remove_words", "\n", "\n", "ref_word_bag", "=", "[", "]", "\n", "hyp_word_bag", "=", "[", "]", "\n", "for", "word", "in", "new_item", "[", "'ref_text'", "]", ":", "\n", "            ", "if", "word", "not", "in", "ref_word_bag", "and", "word", "not", "in", "new_item", "[", "'ref_remove_words'", "]", ":", "\n", "                ", "ref_word_bag", ".", "append", "(", "word", ")", "\n", "\n", "", "", "for", "word", "in", "new_item", "[", "'hyp_text'", "]", ":", "\n", "            ", "if", "word", "not", "in", "hyp_word_bag", "and", "word", "not", "in", "new_item", "[", "'hyp_remove_words'", "]", ":", "\n", "                ", "hyp_word_bag", ".", "append", "(", "word", ")", "\n", "\n", "", "", "new_item", "[", "'ref_word_bag'", "]", "=", "ref_word_bag", "\n", "new_item", "[", "'hyp_word_bag'", "]", "=", "hyp_word_bag", "\n", "\n", "ref_align_number", "=", "sum", "(", "[", "int", "(", "item", "[", "0", "]", ".", "split", "(", "':'", ")", "[", "1", "]", ")", "for", "item", "in", "keep_pair", "]", ")", "\n", "hyp_align_number", "=", "sum", "(", "[", "int", "(", "item", "[", "1", "]", ".", "split", "(", "':'", ")", "[", "1", "]", ")", "for", "item", "in", "keep_pair", "]", ")", "\n", "ref_len", "=", "len", "(", "ref_word_bag", ")", "\n", "hyp_len", "=", "len", "(", "hyp_word_bag", ")", "\n", "\n", "recall", "=", "hyp_align_number", "/", "hyp_len", "\n", "precision", "=", "ref_align_number", "/", "ref_len", "\n", "f1", "=", "2", "*", "(", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "new_item", "[", "'f1'", "]", "=", "f1", "\n", "new_items", ".", "append", "(", "new_item", ")", "\n", "\n", "", "print", "(", "np", ".", "mean", "(", "[", "item", "[", "'f1'", "]", "for", "item", "in", "new_items", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hltchkust_vg-gplms.evaluation.python_rouge.calculate_rouge": [[11, 25], ["range", "print", "print", "print", "len", "rouge.rouge_n_sentence_level", "rouge1.append", "rouge.rouge_n_sentence_level", "rouge2.append", "rouge.rouge_l_sentence_level", "rougel.append", "numpy.mean", "numpy.mean", "numpy.mean"], "function", ["None"], ["    ", "rouge1", "=", "[", "]", "\n", "rouge2", "=", "[", "]", "\n", "rougel", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "reference_sentences", ")", ")", ":", "\n", "        ", "score", "=", "rouge_n_sentence_level", "(", "summary_sentences", "[", "i", "]", ",", "reference_sentences", "[", "i", "]", ",", "1", ")", "\n", "rouge1", ".", "append", "(", "score", ".", "f1_measure", ")", "\n", "_", ",", "_", ",", "rouge_2", "=", "rouge_n_sentence_level", "(", "summary_sentences", "[", "i", "]", ",", "reference_sentences", "[", "i", "]", ",", "2", ")", "\n", "rouge2", ".", "append", "(", "rouge_2", ")", "\n", "_", ",", "_", ",", "rouge_l", "=", "rouge_l_sentence_level", "(", "summary_sentences", "[", "i", "]", ",", "reference_sentences", "[", "i", "]", ")", "\n", "rougel", ".", "append", "(", "rouge_l", ")", "\n", "", "print", "(", "np", ".", "mean", "(", "rouge1", ")", ")", "\n", "print", "(", "np", ".", "mean", "(", "rouge2", ")", ")", "\n", "print", "(", "np", ".", "mean", "(", "rougel", ")", ")", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n"]]}