{"home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.nocaps_model.FewVLMCOCOCaption.__init__": [[8, 10], ["modeling_t5.FewVLM.__init__"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.nocaps_model.FewVLMCOCOCaption.train_step": [[11, 36], ["batch[].to", "batch[].to", "batch[].to", "batch[].to", "nocaps_model.FewVLMCOCOCaption.", "batch[].to.size", "next", "nocaps_model.FewVLMCOCOCaption.parameters"], "methods", ["None"], ["", "def", "train_step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "vis_feats", "=", "batch", "[", "'vis_feats'", "]", ".", "to", "(", "device", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", ".", "to", "(", "device", ")", "\n", "vis_pos", "=", "batch", "[", "'boxes'", "]", ".", "to", "(", "device", ")", "\n", "\n", "lm_labels", "=", "batch", "[", "\"target_ids\"", "]", ".", "to", "(", "device", ")", "\n", "\n", "reduce_loss", "=", "True", "\n", "output", "=", "self", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vis_inputs", "=", "(", "vis_feats", ",", "vis_pos", ")", ",", "\n", "labels", "=", "lm_labels", ",", "\n", "reduce_loss", "=", "reduce_loss", "\n", ")", "\n", "\n", "lm_mask", "=", "lm_labels", "!=", "-", "100", "\n", "B", ",", "L", "=", "lm_labels", ".", "size", "(", ")", "\n", "\n", "loss", "=", "output", "[", "'loss'", "]", "\n", "\n", "result", "=", "{", "\n", "'loss'", ":", "loss", "\n", "}", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.nocaps_model.FewVLMCOCOCaption.test_step": [[37, 56], ["batch[].to", "batch[].to", "batch[].to", "nocaps_model.FewVLMCOCOCaption.generate", "nocaps_model.FewVLMCOCOCaption.tokenizer.batch_decode", "next", "nocaps_model.FewVLMCOCOCaption.parameters"], "methods", ["None"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "**", "kwargs", ")", ":", "\n", "        ", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "vis_feats", "=", "batch", "[", "'vis_feats'", "]", ".", "to", "(", "device", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", ".", "to", "(", "device", ")", "\n", "vis_pos", "=", "batch", "[", "'boxes'", "]", ".", "to", "(", "device", ")", "\n", "img_ids", "=", "batch", "[", "'image_id'", "]", "\n", "\n", "output", "=", "self", ".", "generate", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vis_inputs", "=", "(", "vis_feats", ",", "vis_pos", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "\n", "generated_sents", "=", "self", ".", "tokenizer", ".", "batch_decode", "(", "output", ",", "skip_special_tokens", "=", "True", ")", "\n", "result", "=", "{", "}", "\n", "result", "[", "'pred'", "]", "=", "generated_sents", "\n", "result", "[", "'image_id'", "]", "=", "img_ids", "\n", "\n", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.nocaps.Trainer.__init__": [[48, 105], ["trainer_base.TrainerBase.__init__", "nocaps.Trainer.create_config", "nocaps.Trainer.create_tokenizer", "nocaps.Trainer.create_model", "print", "nocaps.Trainer.model.to", "nocaps.Trainer.model.resize_token_embeddings", "nocaps.Trainer.load_checkpoint", "nocaps.Trainer.init_weights", "time", "nocaps.Trainer.create_optimizer_and_scheduler", "print", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "amp.initialize", "time"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_config", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_tokenizer", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_model", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load_checkpoint", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.init_weights", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_optimizer_and_scheduler"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "train_loader", "=", "None", ",", "val_loader", "=", "None", ",", "test_loader", "=", "None", ",", "train", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "args", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "test_loader", "=", "test_loader", ",", "\n", "train", "=", "train", ")", "\n", "\n", "from", "nocaps_model", "import", "FewVLMCOCOCaption", "\n", "\n", "model_kwargs", "=", "{", "}", "\n", "if", "'t5'", "in", "args", ".", "backbone", ":", "\n", "            ", "model_class", "=", "FewVLMCOCOCaption", "\n", "\n", "", "config", "=", "self", ".", "create_config", "(", ")", "\n", "self", ".", "tokenizer", "=", "self", ".", "create_tokenizer", "(", ")", "\n", "\n", "self", ".", "model", "=", "self", ".", "create_model", "(", "model_class", ",", "config", ",", "**", "model_kwargs", ")", "\n", "\n", "if", "'t5'", "in", "self", ".", "args", ".", "tokenizer", ":", "\n", "            ", "self", ".", "model", ".", "resize_token_embeddings", "(", "self", ".", "tokenizer", ".", "vocab_size", ")", "\n", "\n", "", "self", ".", "model", ".", "tokenizer", "=", "self", ".", "tokenizer", "\n", "\n", "# Load Checkpoint", "\n", "self", ".", "start_epoch", "=", "None", "\n", "if", "args", ".", "load", "is", "not", "None", ":", "\n", "            ", "ckpt_path", "=", "args", ".", "load", "+", "'.pth'", "\n", "self", ".", "load_checkpoint", "(", "ckpt_path", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "from_scratch", ":", "\n", "            ", "self", ".", "init_weights", "(", ")", "\n", "\n", "# GPU Options", "\n", "", "print", "(", "f'Model Launching at GPU {self.args.gpu}'", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "from", "time", "import", "time", "\n", "start", "=", "time", "(", ")", "\n", "", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "args", ".", "gpu", ")", "\n", "\n", "# Optimizer", "\n", "if", "train", ":", "\n", "            ", "self", ".", "optim", ",", "self", ".", "lr_scheduler", "=", "self", ".", "create_optimizer_and_scheduler", "(", ")", "\n", "\n", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                ", "self", ".", "scaler", "=", "torch", ".", "cuda", ".", "amp", ".", "GradScaler", "(", ")", "\n", "", "elif", "_use_apex", ":", "\n", "                ", "self", ".", "model", ",", "self", ".", "optim", "=", "amp", ".", "initialize", "(", "\n", "self", ".", "model", ",", "self", ".", "optim", ",", "opt_level", "=", "'O1'", ",", "verbosity", "=", "self", ".", "verbose", ")", "\n", "\n", "", "", "if", "args", ".", "multiGPU", ":", "\n", "            ", "if", "args", ".", "distributed", ":", "\n", "                ", "self", ".", "model", "=", "DDP", "(", "self", ".", "model", ",", "device_ids", "=", "[", "args", ".", "gpu", "]", ",", "\n", "find_unused_parameters", "=", "True", "\n", ")", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "f'It took {time() - start:.1f}s'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.nocaps.Trainer.train": [[106, 279], ["utils.LossMeter", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "range", "nocaps.Trainer.evaluate", "pprint.pprint.pformat", "print", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "nocaps.Trainer.model.train", "enumerate", "nocaps.Trainer.save", "os.path.isdir", "os.makedirs", "os.path.join", "nocaps.Trainer.load", "print", "nocaps.Trainer.train_loader.sampler.set_epoch", "tqdm.tqdm.tqdm", "loss.detach.detach.detach", "nocaps.Trainer.items", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "tqdm.tqdm.tqdm.close", "nocaps.Trainer.evaluate", "pprint.pprint.pformat", "print", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "os.path.join", "nocaps.Trainer.scaler.scale().backward", "nocaps.Trainer.model.parameters", "utils.LossMeter.update", "tqdm.tqdm.tqdm.set_description", "tqdm.tqdm.tqdm.update", "nocaps.Trainer.save", "len", "autocast", "nocaps.Trainer.model.module.train_step", "nocaps.Trainer.model.train_step", "loss.detach.detach.backward", "nocaps.Trainer.scaler.unscale_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "nocaps.Trainer.scaler.step", "nocaps.Trainer.scaler.update", "nocaps.Trainer.optim.step", "nocaps.Trainer.lr_scheduler.step", "v.item", "packaging.version.parse", "packaging.version.parse", "loss.detach.detach.item", "nocaps.Trainer.model.module.train_step", "nocaps.Trainer.model.train_step", "nocaps.Trainer.scaler.scale", "amp.scale_loss", "scaled_loss.backward", "nocaps.Trainer.model.parameters", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "nocaps.Trainer.lr_scheduler.get_last_lr", "nocaps.Trainer.lr_scheduler.get_lr", "nocaps.Trainer.optim.get_lr", "amp.master_params", "nocaps.Trainer.model.parameters", "len"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.train", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step"], ["", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "verbose", ":", "\n", "            ", "loss_meter", "=", "LossMeter", "(", ")", "\n", "best_valid", "=", "0.", "\n", "best_epoch", "=", "0", "\n", "\n", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "global_step", "=", "0", "\n", "epochs", "=", "self", ".", "args", ".", "epochs", "\n", "\n", "if", "not", "self", ".", "args", ".", "test_only", ":", "\n", "            ", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "\n", "                ", "if", "self", ".", "start_epoch", "is", "not", "None", ":", "\n", "                    ", "epoch", "+=", "self", ".", "start_epoch", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "self", ".", "train_loader", ".", "sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                    ", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "self", ".", "train_loader", ")", ",", "ncols", "=", "120", ")", "\n", "\n", "", "epoch_results", "=", "{", "\n", "'loss'", ":", "0.", ",", "\n", "\n", "}", "\n", "\n", "for", "step_i", ",", "batch", "in", "enumerate", "(", "self", ".", "train_loader", ")", ":", "\n", "\n", "                    ", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                        ", "with", "autocast", "(", ")", ":", "\n", "                            ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                                ", "results", "=", "self", ".", "model", ".", "module", ".", "train_step", "(", "batch", ")", "\n", "", "else", ":", "\n", "                                ", "results", "=", "self", ".", "model", ".", "train_step", "(", "batch", ")", "\n", "", "", "", "else", ":", "\n", "                        ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                            ", "results", "=", "self", ".", "model", ".", "module", ".", "train_step", "(", "batch", ")", "\n", "", "else", ":", "\n", "                            ", "results", "=", "self", ".", "model", ".", "train_step", "(", "batch", ")", "\n", "\n", "", "", "loss", "=", "results", "[", "'loss'", "]", "\n", "\n", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                        ", "self", ".", "scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "", "elif", "self", ".", "args", ".", "fp16", "and", "_use_apex", ":", "\n", "                        ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "self", ".", "optim", ")", "as", "scaled_loss", ":", "\n", "                            ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                        ", "loss", ".", "backward", "(", ")", "\n", "\n", "\n", "", "loss", "=", "loss", ".", "detach", "(", ")", "\n", "\n", "# Update Parameters", "\n", "if", "self", ".", "args", ".", "clip_grad_norm", ">", "0", ":", "\n", "                        ", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                            ", "self", ".", "scaler", ".", "unscale_", "(", "self", ".", "optim", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "", "elif", "self", ".", "args", ".", "fp16", "and", "_use_apex", ":", "\n", "                            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "\n", "self", ".", "optim", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "", "else", ":", "\n", "                            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "\n", "", "", "update", "=", "True", "\n", "if", "self", ".", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                        ", "if", "step_i", "==", "0", ":", "\n", "                            ", "update", "=", "False", "\n", "", "elif", "step_i", "%", "self", ".", "args", ".", "gradient_accumulation_steps", "==", "0", "or", "step_i", "==", "len", "(", "self", ".", "train_loader", ")", "-", "1", ":", "\n", "                            ", "update", "=", "True", "\n", "", "else", ":", "\n", "                            ", "update", "=", "False", "\n", "\n", "", "", "if", "update", ":", "\n", "                        ", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                            ", "self", ".", "scaler", ".", "step", "(", "self", ".", "optim", ")", "\n", "self", ".", "scaler", ".", "update", "(", ")", "\n", "", "else", ":", "\n", "                            ", "self", ".", "optim", ".", "step", "(", ")", "\n", "\n", "", "if", "self", ".", "lr_scheduler", ":", "\n", "                            ", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "# self.model.zero_grad()", "\n", "", "for", "param", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "                            ", "param", ".", "grad", "=", "None", "\n", "", "global_step", "+=", "1", "\n", "\n", "", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", ":", "\n", "                        ", "if", "k", "in", "epoch_results", ":", "\n", "                            ", "epoch_results", "[", "k", "]", "+=", "v", ".", "item", "(", ")", "\n", "\n", "", "", "if", "self", ".", "lr_scheduler", ":", "\n", "                        ", "if", "version", ".", "parse", "(", "torch", ".", "__version__", ")", ">=", "version", ".", "parse", "(", "\"1.4\"", ")", ":", "\n", "                            ", "lr", "=", "self", ".", "lr_scheduler", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                            ", "lr", "=", "self", ".", "lr_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "", "", "else", ":", "\n", "                        ", "try", ":", "\n", "                            ", "lr", "=", "self", ".", "optim", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "", "except", "AttributeError", ":", "\n", "                            ", "lr", "=", "self", ".", "args", ".", "lr", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "                        ", "loss_meter", ".", "update", "(", "loss", ".", "item", "(", ")", ")", "\n", "desc_str", "=", "f'Epoch {epoch} | LR {lr:.6f} | Steps {global_step}'", "\n", "desc_str", "+=", "f' | Loss {loss_meter.val:4f}'", "\n", "pbar", ".", "set_description", "(", "desc_str", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                    ", "pbar", ".", "close", "(", ")", "\n", "\n", "# format ex)", "\n", "# {'Bleu_1': 0.9999999997500004,", "\n", "#  'Bleu_2': 0.5773502690332603,", "\n", "#  'Bleu_3': 4.3679023223468616e-06,", "\n", "#  'Bleu_4': 1.4287202142987477e-08,", "\n", "#  'CIDEr': 3.333333333333333,", "\n", "#  'METEOR': 0.43354749322305886,", "\n", "#  'ROUGE_L': 0.75,", "\n", "#  'SPICE': 0.6666666666666666}", "\n", "\n", "# Validation", "\n", "valid_results", "=", "self", ".", "evaluate", "(", "self", ".", "val_loader", ")", "\n", "\n", "valid_score", "=", "valid_results", "[", "'CIDEr'", "]", "\n", "\n", "if", "valid_score", ">", "best_valid", "or", "epoch", "==", "0", ":", "\n", "                        ", "best_valid", "=", "valid_score", "\n", "best_epoch", "=", "epoch", "\n", "self", ".", "save", "(", "\"BEST\"", ")", "\n", "\n", "", "log_str", "=", "''", "\n", "\n", "log_str", "+=", "pformat", "(", "valid_results", ")", "\n", "log_str", "+=", "\"\\nEpoch %d: Valid CIDEr %0.4f\"", "%", "(", "epoch", ",", "valid_score", ")", "\n", "log_str", "+=", "\"\\nEpoch %d: Best CIDEr %0.4f\\n\"", "%", "(", "best_epoch", ",", "best_valid", ")", "\n", "\n", "print", "(", "log_str", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "dist", ".", "barrier", "(", ")", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "                ", "self", ".", "save", "(", "\"LAST\"", ")", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "args", ".", "output", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "self", ".", "args", ".", "output", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Test Set", "\n", "", "if", "not", "self", ".", "args", ".", "test_only", ":", "\n", "                ", "best_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output", ",", "'BEST'", ")", "\n", "self", ".", "load", "(", "best_path", ")", "\n", "print", "(", "f'\\nUploaded checkpoint {best_epoch}'", ",", "best_path", ")", "\n", "\n", "", "test_results", "=", "self", ".", "evaluate", "(", "self", ".", "test_loader", ",", "dump_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output", ",", "'submit.json'", ")", ")", "\n", "\n", "log_str", "=", "'Test set results\\n'", "\n", "log_str", "+=", "pformat", "(", "test_results", ")", "\n", "\n", "print", "(", "log_str", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.nocaps.Trainer.predict": [[280, 333], ["nocaps.Trainer.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "tqdm.tqdm.tqdm", "predictions.extend", "zip", "open", "json.dump", "nocaps.Trainer.model.module.test_step", "nocaps.Trainer.model.test_step", "output.append", "targets.extend"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.test_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.test_step"], ["", "", "def", "predict", "(", "self", ",", "loader", ",", "dump_path", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Predict the answers to questions in a data split.\n        :param eval_tuple: The data tuple to be evaluated.\n        :param dump: The path of saved file to dump results.\n        :return: A dict of question_id to answer.\n        \"\"\"", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "            ", "predictions", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "output", "=", "[", "]", "\n", "\n", "gen_kwargs", "=", "{", "}", "\n", "gen_kwargs", "[", "'num_beams'", "]", "=", "self", ".", "args", ".", "num_beams", "\n", "gen_kwargs", "[", "'max_length'", "]", "=", "self", ".", "args", ".", "gen_max_length", "\n", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "tqdm", "(", "loader", ",", "ncols", "=", "120", ",", "desc", "=", "\"Prediction\"", ")", ")", ":", "\n", "\n", "                ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "results", "=", "self", ".", "model", ".", "module", ".", "test_step", "(", "\n", "batch", ",", "\n", "**", "gen_kwargs", ")", "\n", "", "else", ":", "\n", "                    ", "results", "=", "self", ".", "model", ".", "test_step", "(", "\n", "batch", ",", "\n", "**", "gen_kwargs", ")", "\n", "\n", "", "predictions", ".", "extend", "(", "results", "[", "'pred'", "]", ")", "\n", "for", "img", ",", "sent", "in", "zip", "(", "results", "[", "'image_id'", "]", ",", "results", "[", "'pred'", "]", ")", ":", "\n", "                    ", "output", ".", "append", "(", "{", "\"image_id\"", ":", "img", ",", "\"caption\"", ":", "sent", "}", ")", "\n", "\n", "", "if", "'targets'", "in", "batch", ":", "\n", "                    ", "targets", ".", "extend", "(", "batch", "[", "'targets'", "]", ")", "\n", "\n", "", "", "with", "open", "(", "dump_path", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "output", ",", "f", ")", "\n", "\n", "", "results", "=", "{", "\n", "'predictions'", ":", "predictions", ",", "\n", "'targets'", ":", "targets", "\n", "}", "\n", "# if not self.args.nocaptest:", "\n", "#     evaluator = NocapsEvaluator(\"val\")", "\n", "#     evaluation_metrics = evaluator.evaluate(output)", "\n", "\n", "#     for metric_name in evaluation_metrics:", "\n", "#         print(f\"\\t{metric_name}:\")", "\n", "#         for domain in evaluation_metrics[metric_name]:", "\n", "#             print(f\"\\t\\t{domain}:\", evaluation_metrics[metric_name][domain])", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.nocaps.Trainer.evaluate": [[334, 343], ["nocaps.Trainer.predict", "evaluator.evaluate"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.predict", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate"], ["", "", "def", "evaluate", "(", "self", ",", "loader", ",", "dump_path", "=", "None", ")", ":", "\n", "        ", "evaluator", "=", "loader", ".", "evaluator", "\n", "results", "=", "self", ".", "predict", "(", "loader", ",", "dump_path", ")", "\n", "\n", "predictions", "=", "results", "[", "'predictions'", "]", "\n", "if", "dump_path", "is", "None", ":", "\n", "            ", "targets", "=", "results", "[", "'targets'", "]", "\n", "eval_results", "=", "evaluator", ".", "evaluate", "(", "predictions", ",", "targets", ")", "\n", "return", "eval_results", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.nocaps.Trainer.oracle_score": [[344, 358], ["enumerate", "evaluator.evaluate", "label.max", "zip", "label.cpu().numpy", "label.cpu"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate"], ["", "", "@", "staticmethod", "\n", "def", "oracle_score", "(", "loader", ")", ":", "\n", "        ", "evaluator", "=", "loader", ".", "evaluator", "\n", "quesid2ans", "=", "{", "}", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "loader", ")", ":", "\n", "\n", "            ", "ques_id", "=", "batch", "[", "'question_ids'", "]", "\n", "label", "=", "batch", "[", "'targets'", "]", "\n", "\n", "_", ",", "label", "=", "label", ".", "max", "(", "1", ")", "\n", "for", "qid", ",", "l", "in", "zip", "(", "ques_id", ",", "label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ":", "\n", "                ", "ans", "=", "loader", ".", "dataset", ".", "raw_dataset", ".", "label2ans", "[", "l", "]", "\n", "quesid2ans", "[", "qid", "]", "=", "ans", "\n", "", "", "return", "evaluator", ".", "evaluate", "(", "quesid2ans", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.nocaps.main_worker": [[359, 406], ["print", "print", "nocaps_data.get_loader", "nocaps.Trainer", "nocaps.Trainer.train", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.init_process_group", "print", "nocaps_data.get_loader", "print", "print", "nocaps_data.get_loader", "len"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.train", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader"], ["", "", "def", "main_worker", "(", "gpu", ",", "args", ")", ":", "\n", "# GPU is assigned", "\n", "    ", "args", ".", "gpu", "=", "gpu", "\n", "args", ".", "rank", "=", "gpu", "\n", "print", "(", "f'Process Launching at GPU {gpu}'", ")", "\n", "\n", "if", "args", ".", "distributed", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "dist", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "\n", "", "print", "(", "f'Building train loader at GPU {gpu}'", ")", "\n", "train_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "train", ",", "mode", "=", "'train'", ",", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "distributed", "=", "args", ".", "distributed", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "args", ".", "num_workers", ",", "\n", "topk", "=", "args", ".", "train_topk", ",", "\n", ")", "\n", "if", "gpu", "==", "0", ":", "\n", "        ", "if", "args", ".", "valid_batch_size", "is", "not", "None", ":", "\n", "            ", "valid_batch_size", "=", "args", ".", "valid_batch_size", "\n", "", "else", ":", "\n", "            ", "valid_batch_size", "=", "args", ".", "batch_size", "\n", "", "print", "(", "f'Building val loader at GPU {gpu}'", ")", "\n", "val_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "valid", ",", "mode", "=", "'val'", ",", "batch_size", "=", "valid_batch_size", ",", "\n", "distributed", "=", "False", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "4", ",", "\n", "topk", "=", "args", ".", "valid_topk", ",", "\n", ")", "\n", "print", "(", "'# len val loader:'", ",", "len", "(", "val_loader", ")", ")", "\n", "\n", "print", "(", "f'Building test loader at GPU {gpu}'", ")", "\n", "test_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "test", ",", "mode", "=", "'test'", ",", "batch_size", "=", "valid_batch_size", ",", "\n", "distributed", "=", "False", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "4", ",", "\n", "topk", "=", "args", ".", "valid_topk", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "val_loader", "=", "None", "\n", "test_loader", "=", "None", "\n", "\n", "", "trainer", "=", "Trainer", "(", "args", ",", "train_loader", ",", "val_loader", ",", "test_loader", ",", "train", "=", "True", ")", "\n", "trainer", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.nocaps_data.COCOCaptionFineTuneDataset.__init__": [[33, 161], ["torch.utils.data.Dataset.__init__", "dataset_dir.joinpath", "torch.cuda.device_count", "print", "open", "json.load", "nocaps_dir.joinpath", "print", "print", "random.seed", "random.shuffle", "print", "nocaps_data.COCOCaptionFineTuneDataset.source_to_h5.update", "tokenization.FewVLMTokenizerFast.from_pretrained", "transformers.T5TokenizerFast.from_pretrained", "open", "json.load", "nocaps_dir.joinpath", "data.append", "print", "len", "open", "json.load", "data.append", "coco_dir.joinpath().joinpath", "coco_dir.joinpath().joinpath", "nocaps_dir.joinpath().joinpath", "nocaps_dir.joinpath().joinpath", "nocaps_data.COCOCaptionFineTuneDataset.source.split", "data.append", "datum[].split", "len", "datum[].split", "d[].strip", "d[].strip", "coco_dir.joinpath", "coco_dir.joinpath", "nocaps_dir.joinpath", "nocaps_dir.joinpath", "d[].strip"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load"], ["    ", "def", "__init__", "(", "self", ",", "split", "=", "'karpathy_train'", ",", "raw_dataset", "=", "None", ",", "rank", "=", "-", "1", ",", "topk", "=", "-", "1", ",", "verbose", "=", "True", ",", "args", "=", "None", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "raw_dataset", "=", "raw_dataset", "\n", "self", ".", "topk", "=", "topk", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "mode", "=", "mode", "\n", "\n", "# Loading datasets to data", "\n", "self", ".", "source", "=", "split", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "'Data source: '", ",", "self", ".", "source", ")", "\n", "\n", "\n", "", "if", "self", ".", "args", ".", "tokenizer", "is", "None", ":", "\n", "            ", "self", ".", "args", ".", "tokenizer", "=", "self", ".", "args", ".", "backbone", "\n", "\n", "", "if", "'t5'", "in", "self", ".", "args", ".", "tokenizer", ":", "\n", "            ", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "                ", "self", ".", "tokenizer", "=", "FewVLMTokenizerFast", ".", "from_pretrained", "(", "\n", "args", ".", "backbone", ",", "\n", "# max_length=self.args.max_text_length,", "\n", "do_lower_case", "=", "self", ".", "args", ".", "do_lower_case", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "tokenizer", "=", "T5TokenizerFast", ".", "from_pretrained", "(", "\n", "args", ".", "backbone", ",", "\n", "# max_length=self.args.max_text_length,", "\n", "do_lower_case", "=", "self", ".", "args", ".", "do_lower_case", ")", "\n", "\n", "", "", "data_info_path", "=", "dataset_dir", ".", "joinpath", "(", "f'COCO/{args.caption_data}.json'", ")", "\n", "with", "open", "(", "data_info_path", ")", "as", "f", ":", "\n", "            ", "karpathy_data", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "\n", "", "split_rename", "=", "{", "\n", "'train'", ":", "'train'", ",", "\n", "'restval'", ":", "'train'", ",", "\n", "'val'", ":", "'val'", ",", "\n", "'test'", ":", "'test'", "\n", "}", "\n", "\n", "n_images", "=", "0", "\n", "\n", "data", "=", "[", "]", "\n", "\n", "if", "split", "==", "'karpathy_test'", ":", "\n", "            ", "data_info_path", "=", "nocaps_dir", ".", "joinpath", "(", "'nocaps_val_image_info.json'", ")", "\n", "with", "open", "(", "data_info_path", ")", "as", "f", ":", "\n", "                ", "nocaps_val", "=", "json", ".", "load", "(", "f", ")", "\n", "", "if", "self", ".", "args", ".", "nocaptest", ":", "\n", "                ", "data_info_path", "=", "nocaps_dir", ".", "joinpath", "(", "'nocaps_test_image_info.json'", ")", "\n", "with", "open", "(", "data_info_path", ")", "as", "f", ":", "\n", "                    ", "nocaps_val", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "for", "d", "in", "nocaps_val", "[", "'images'", "]", ":", "\n", "                ", "img_id", "=", "d", "[", "'open_images_id'", "]", "\n", "ids", "=", "d", "[", "'id'", "]", "\n", "new_datum", "=", "{", "\n", "'img_id'", ":", "img_id", ",", "\n", "'image_id'", ":", "ids", ",", "\n", "'is_train'", ":", "False", ",", "\n", "}", "\n", "data", ".", "append", "(", "new_datum", ")", "\n", "\n", "n_images", "+=", "1", "\n", "\n", "\n", "", "", "else", ":", "\n", "            ", "for", "datum", "in", "karpathy_data", "[", "'images'", "]", ":", "\n", "                ", "re_split", "=", "split_rename", "[", "datum", "[", "'split'", "]", "]", "\n", "if", "re_split", "!=", "self", ".", "source", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "re_split", "==", "'train'", ":", "\n", "                    ", "for", "d", "in", "datum", "[", "'sentences'", "]", ":", "\n", "                        ", "img_id", "=", "datum", "[", "'filename'", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "new_datum", "=", "{", "\n", "'img_id'", ":", "img_id", ",", "\n", "'sent'", ":", "d", "[", "'raw'", "]", ".", "strip", "(", ")", ",", "\n", "'targets'", ":", "[", "d", "[", "'raw'", "]", ".", "strip", "(", ")", "for", "d", "in", "datum", "[", "'sentences'", "]", "]", ",", "\n", "'is_train'", ":", "True", ",", "\n", "}", "\n", "data", ".", "append", "(", "new_datum", ")", "\n", "", "", "else", ":", "\n", "                    ", "img_id", "=", "datum", "[", "'filename'", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "new_datum", "=", "{", "\n", "'img_id'", ":", "img_id", ",", "\n", "# 'sent': d['raw'],", "\n", "'targets'", ":", "[", "d", "[", "'raw'", "]", ".", "strip", "(", ")", "for", "d", "in", "datum", "[", "'sentences'", "]", "]", ",", "\n", "'is_train'", ":", "False", ",", "\n", "}", "\n", "data", ".", "append", "(", "new_datum", ")", "\n", "\n", "", "n_images", "+=", "1", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "f\"{self.source} has {n_images} images\"", ")", "\n", "print", "(", "f\"Loaded {len(data)} data from\"", ",", "split", ")", "\n", "\n", "", "self", ".", "n_gpus", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "self", ".", "rank", "=", "rank", "\n", "if", "self", ".", "topk", ">", "0", ":", "\n", "            ", "data", "=", "data", "[", ":", "self", ".", "topk", "]", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "f\"Use only {self.topk} data\"", ")", "\n", "\n", "", "", "self", ".", "data", "=", "data", "\n", "if", "args", ".", "subsample", "and", "'train'", "in", "split", ":", "\n", "            ", "random", ".", "seed", "(", "args", ".", "dataseed", ")", "\n", "random", ".", "shuffle", "(", "self", ".", "data", ")", "\n", "if", "'train'", "in", "split", "and", "mode", "==", "'train'", ":", "\n", "                ", "self", ".", "data", "=", "self", ".", "data", "[", ":", "args", ".", "num_data", "]", "\n", "", "elif", "'train'", "in", "split", "and", "mode", "==", "'val'", ":", "\n", "                ", "self", ".", "data", "=", "self", ".", "data", "[", "args", ".", "num_data", ":", "2", "*", "args", ".", "num_data", "]", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "\"# all sentences:\"", ",", "len", "(", "self", ".", "data", ")", ")", "\n", "\n", "", "self", ".", "source_to_h5", "=", "{", "}", "\n", "\n", "if", "self", ".", "args", ".", "max_n_boxes", "==", "36", ":", "\n", "            ", "self", ".", "source_to_h5", ".", "update", "(", "{", "\n", "'train2014'", ":", "coco_dir", ".", "joinpath", "(", "'features'", ")", ".", "joinpath", "(", "'train2014_obj36.h5'", ")", ",", "\n", "'val2014'", ":", "coco_dir", ".", "joinpath", "(", "'features'", ")", ".", "joinpath", "(", "'val2014_obj36.h5'", ")", ",", "\n", "'nocap_val'", ":", "nocaps_dir", ".", "joinpath", "(", "'features'", ")", ".", "joinpath", "(", "'valid_boxes36.h5'", ")", ",", "\n", "'nocap_test'", ":", "nocaps_dir", ".", "joinpath", "(", "'features'", ")", ".", "joinpath", "(", "'test_boxes36.h5'", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.nocaps_data.COCOCaptionFineTuneDataset.__len__": [[164, 166], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.nocaps_data.COCOCaptionFineTuneDataset.__getitem__": [[167, 275], ["torch.LongTensor", "len", "isinstance", "numpy.testing.assert_array_less", "numpy.testing.assert_array_less", "torch.from_numpy", "torch.from_numpy.clamp_", "len", "numpy.zeros", "f[].read_direct", "torch.from_numpy", "min", "datum[].strip", "len", "torch.LongTensor", "len", "h5py.File", "nocaps_data.COCOCaptionFineTuneDataset.tokenizer.encode", "nocaps_data.COCOCaptionFineTuneDataset.tokenizer.encode", "len", "len", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "out_dict", "=", "{", "}", "\n", "out_dict", "[", "'args'", "]", "=", "self", ".", "args", "\n", "\n", "datum", "=", "self", ".", "data", "[", "idx", "]", "\n", "\n", "###### Image ######", "\n", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "            ", "img_id", "=", "datum", "[", "'img_id'", "]", "\n", "out_dict", "[", "'img_id'", "]", "=", "img_id", "\n", "out_dict", "[", "'image_id'", "]", "=", "datum", "[", "'image_id'", "]", "\n", "\n", "\n", "if", "'train'", "in", "img_id", ":", "\n", "                ", "source", "=", "'train2014'", "\n", "", "elif", "'val'", "in", "img_id", ":", "\n", "                ", "source", "=", "'val2014'", "\n", "", "elif", "'test'", "in", "img_id", ":", "\n", "                ", "source", "=", "'val2014'", "\n", "", "if", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "source", "=", "'nocap_val'", "\n", "if", "self", ".", "args", ".", "nocaptest", ":", "\n", "                    ", "source", "=", "'nocap_test'", "\n", "\n", "", "", "f", "=", "self", ".", "source_to_h5", "[", "source", "]", "\n", "\n", "if", "isinstance", "(", "f", ",", "Path", ")", ":", "\n", "# path = self.data_source_to_h5_path[source]", "\n", "                ", "f", "=", "h5py", ".", "File", "(", "f", ",", "'r'", ")", "\n", "# self.split_to_h5_features[split_i] = f", "\n", "self", ".", "source_to_h5", "[", "source", "]", "=", "f", "\n", "\n", "# Normalize the boxes (to 0 ~ 1)", "\n", "", "img_h", "=", "f", "[", "f'{img_id}/img_h'", "]", "[", "(", ")", "]", "\n", "img_w", "=", "f", "[", "f'{img_id}/img_w'", "]", "[", "(", ")", "]", "\n", "boxes", "=", "f", "[", "f'{img_id}/boxes'", "]", "[", "(", ")", "]", "# (x1, y1, x2, y2)", "\n", "boxes", "[", ":", ",", "(", "0", ",", "2", ")", "]", "/=", "img_w", "\n", "boxes", "[", ":", ",", "(", "1", ",", "3", ")", "]", "/=", "img_h", "\n", "np", ".", "testing", ".", "assert_array_less", "(", "boxes", ",", "1", "+", "1e-5", ")", "\n", "# np.testing.assert_array_less(boxes, 1+5e-2)", "\n", "np", ".", "testing", ".", "assert_array_less", "(", "-", "boxes", ",", "0", "+", "1e-5", ")", "\n", "boxes", "=", "torch", ".", "from_numpy", "(", "boxes", ")", "\n", "\n", "boxes", ".", "clamp_", "(", "min", "=", "0.0", ",", "max", "=", "1.0", ")", "\n", "\n", "n_boxes", "=", "len", "(", "boxes", ")", "\n", "\n", "feats", "=", "np", ".", "zeros", "(", "shape", "=", "(", "n_boxes", ",", "2048", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "f", "[", "f'{img_id}/features'", "]", ".", "read_direct", "(", "feats", ")", "\n", "feats", "=", "torch", ".", "from_numpy", "(", "feats", ")", "\n", "\n", "if", "self", ".", "args", ".", "n_boxes", "==", "100", ":", "\n", "                ", "assert", "n_boxes", "==", "100", "\n", "assert", "len", "(", "feats", ")", "==", "100", "\n", "assert", "len", "(", "boxes", ")", "==", "100", "\n", "\n", "", "n_boxes", "=", "min", "(", "n_boxes", ",", "self", ".", "args", ".", "max_n_boxes", ")", "\n", "out_dict", "[", "'n_boxes'", "]", "=", "n_boxes", "\n", "boxes", "=", "boxes", "[", ":", "n_boxes", "]", "\n", "feats", "=", "feats", "[", ":", "n_boxes", "]", "\n", "out_dict", "[", "'boxes'", "]", "=", "boxes", "\n", "out_dict", "[", "'vis_feats'", "]", "=", "feats", "\n", "\n", "###### Text #####", "\n", "", "if", "self", ".", "args", ".", "no_prefix", ":", "\n", "            ", "input_text", "=", "''", "\n", "input_ids", "=", "[", "]", "\n", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "args", ".", "prefix", "is", "None", ":", "\n", "                ", "prefix", "=", "''", "\n", "", "elif", "self", ".", "args", ".", "prefix", "==", "'picture'", ":", "\n", "                ", "prefix", "=", "'a picture of'", "\n", "", "elif", "self", ".", "args", ".", "prefix", "==", "'image'", ":", "\n", "                ", "prefix", "=", "'an image of'", "\n", "", "elif", "self", ".", "args", ".", "prefix", "==", "'photo'", ":", "\n", "                ", "prefix", "=", "'a photo of'", "\n", "\n", "\n", "", "input_tokens", "=", "[", "prefix", "]", "\n", "\n", "input_text", "=", "' '", ".", "join", "(", "input_tokens", ")", "\n", "\n", "if", "'t5'", "in", "self", ".", "args", ".", "tokenizer", ":", "\n", "                ", "input_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "\n", "input_text", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_text_length", ",", "truncation", "=", "True", ")", "\n", "\n", "", "", "out_dict", "[", "'input_text'", "]", "=", "input_text", "\n", "\n", "out_dict", "[", "'input_ids'", "]", "=", "torch", ".", "LongTensor", "(", "input_ids", ")", "\n", "out_dict", "[", "'input_length'", "]", "=", "len", "(", "input_ids", ")", "\n", "if", "datum", "[", "'is_train'", "]", ":", "\n", "            ", "sent", "=", "datum", "[", "'sent'", "]", ".", "strip", "(", ")", "\n", "if", "'t5'", "in", "self", ".", "args", ".", "tokenizer", ":", "\n", "                ", "target_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "sent", ",", "max_length", "=", "self", ".", "args", ".", "gen_max_length", ",", "truncation", "=", "True", ")", "\n", "\n", "", "assert", "len", "(", "target_ids", ")", "<=", "self", ".", "args", ".", "gen_max_length", ",", "len", "(", "target_ids", ")", "\n", "out_dict", "[", "'sent'", "]", "=", "sent", "\n", "out_dict", "[", "'target_ids'", "]", "=", "torch", ".", "LongTensor", "(", "target_ids", ")", "\n", "out_dict", "[", "'target_length'", "]", "=", "len", "(", "target_ids", ")", "\n", "\n", "", "if", "'targets'", "in", "datum", ":", "\n", "            ", "out_dict", "[", "'targets'", "]", "=", "datum", "[", "'targets'", "]", "\n", "\n", "\n", "", "return", "out_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.nocaps_data.COCOCaptionFineTuneDataset.collate_fn": [[276, 355], ["len", "max", "enumerate", "torch.ones", "max", "torch.zeros", "torch.zeros", "torch.zeros", "max", "input_ids.size", "torch.ones", "img_ids.append", "image_ids.append", "input_text.append", "targets.append"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "batch", ")", ":", "\n", "        ", "batch_entry", "=", "{", "}", "\n", "\n", "B", "=", "len", "(", "batch", ")", "\n", "\n", "S_W_L", "=", "max", "(", "entry", "[", "'input_length'", "]", "for", "entry", "in", "batch", ")", "\n", "input_ids", "=", "torch", ".", "ones", "(", "B", ",", "S_W_L", ",", "dtype", "=", "torch", ".", "long", ")", "*", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "\n", "if", "self", ".", "args", ".", "no_prefix", ":", "\n", "            ", "assert", "input_ids", ".", "size", "(", ")", "==", "(", "B", ",", "0", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "            ", "V_L", "=", "max", "(", "entry", "[", "'n_boxes'", "]", "for", "entry", "in", "batch", ")", "\n", "# V_L = len(batch[0]['boxes'])", "\n", "feat_dim", "=", "batch", "[", "0", "]", "[", "'vis_feats'", "]", ".", "shape", "[", "-", "1", "]", "\n", "\n", "boxes", "=", "torch", ".", "zeros", "(", "B", ",", "V_L", ",", "4", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "vis_feats", "=", "torch", ".", "zeros", "(", "B", ",", "V_L", ",", "feat_dim", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "vis_attention_mask", "=", "torch", ".", "zeros", "(", "B", ",", "V_L", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "if", "'target_ids'", "in", "batch", "[", "0", "]", ":", "\n", "            ", "T_W_L", "=", "max", "(", "entry", "[", "'target_length'", "]", "for", "entry", "in", "batch", ")", "\n", "target_ids", "=", "torch", ".", "ones", "(", "B", ",", "T_W_L", ",", "dtype", "=", "torch", ".", "long", ")", "*", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "\n", "# sentences = []", "\n", "\n", "", "targets", "=", "[", "]", "\n", "img_ids", "=", "[", "]", "\n", "image_ids", "=", "[", "]", "\n", "img_paths", "=", "[", "]", "\n", "input_text", "=", "[", "]", "\n", "\n", "for", "i", ",", "entry", "in", "enumerate", "(", "batch", ")", ":", "\n", "            ", "input_ids", "[", "i", ",", ":", "entry", "[", "'input_length'", "]", "]", "=", "entry", "[", "'input_ids'", "]", "\n", "\n", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "                ", "n_boxes", "=", "entry", "[", "'n_boxes'", "]", "\n", "boxes", "[", "i", ",", ":", "n_boxes", "]", "=", "entry", "[", "'boxes'", "]", "\n", "vis_feats", "[", "i", ",", ":", "n_boxes", "]", "=", "entry", "[", "'vis_feats'", "]", "\n", "vis_attention_mask", "[", "i", ",", ":", "n_boxes", "]", "=", "1", "\n", "img_ids", ".", "append", "(", "entry", "[", "'img_id'", "]", ")", "\n", "image_ids", ".", "append", "(", "entry", "[", "'image_id'", "]", ")", "\n", "# img_paths.append(entry['img_path'])", "\n", "\n", "", "if", "'target_ids'", "in", "entry", ":", "\n", "                ", "target_ids", "[", "i", ",", ":", "entry", "[", "'target_length'", "]", "]", "=", "entry", "[", "'target_ids'", "]", "\n", "\n", "", "if", "'input_text'", "in", "entry", ":", "\n", "                ", "input_text", ".", "append", "(", "entry", "[", "'input_text'", "]", ")", "\n", "\n", "# sentences.append(entry['sent'])", "\n", "\n", "", "if", "'targets'", "in", "entry", ":", "\n", "                ", "targets", ".", "append", "(", "entry", "[", "'targets'", "]", ")", "\n", "\n", "\n", "", "", "batch_entry", "[", "'input_ids'", "]", "=", "input_ids", "\n", "if", "'target_ids'", "in", "batch", "[", "0", "]", ":", "\n", "            ", "word_mask", "=", "target_ids", "!=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "target_ids", "[", "~", "word_mask", "]", "=", "-", "100", "\n", "batch_entry", "[", "'target_ids'", "]", "=", "target_ids", "\n", "\n", "", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "            ", "batch_entry", "[", "'boxes'", "]", "=", "boxes", "\n", "batch_entry", "[", "'vis_feats'", "]", "=", "vis_feats", "\n", "batch_entry", "[", "'vis_attention_mask'", "]", "=", "vis_attention_mask", "\n", "batch_entry", "[", "'img_id'", "]", "=", "img_ids", "\n", "batch_entry", "[", "'img_paths'", "]", "=", "img_paths", "\n", "\n", "# batch_entry['sent'] = sentences", "\n", "\n", "", "batch_entry", "[", "'input_text'", "]", "=", "input_text", "\n", "\n", "batch_entry", "[", "'targets'", "]", "=", "targets", "\n", "\n", "batch_entry", "[", "'task'", "]", "=", "'caption'", "\n", "batch_entry", "[", "'image_id'", "]", "=", "image_ids", "\n", "\n", "return", "batch_entry", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.nocaps_data.COCOCaptionEvaluator.__init__": [[405, 408], ["language_evaluation.CocoEvaluator"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "import", "language_evaluation", "\n", "self", ".", "evaluator", "=", "language_evaluation", ".", "CocoEvaluator", "(", "verbose", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.nocaps_data.COCOCaptionEvaluator.evaluate": [[410, 415], ["nocaps_data.COCOCaptionEvaluator.evaluator.run_evaluation"], "methods", ["None"], ["", "def", "evaluate", "(", "self", ",", "predicts", ",", "answers", ")", ":", "\n", "\n", "        ", "results", "=", "self", ".", "evaluator", ".", "run_evaluation", "(", "predicts", ",", "answers", ")", "\n", "\n", "return", "results", "", "", "", ""]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.nocaps_data.get_loader": [[357, 401], ["nocaps_data.COCOCaptionFineTuneDataset", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "nocaps_data.COCOCaptionEvaluator"], "function", ["None"], ["", "", "def", "get_loader", "(", "args", ",", "split", "=", "'train'", ",", "mode", "=", "'train'", ",", "\n", "batch_size", "=", "32", ",", "workers", "=", "4", ",", "distributed", "=", "False", ",", "gpu", "=", "0", ",", "\n", "topk", "=", "-", "1", ")", ":", "\n", "\n", "# if 'mscoco' in split:", "\n", "    ", "verbose", "=", "(", "gpu", "==", "0", ")", "\n", "\n", "dataset", "=", "COCOCaptionFineTuneDataset", "(", "\n", "split", ",", "\n", "# raw_dataset=_dset,", "\n", "rank", "=", "gpu", ",", "\n", "topk", "=", "topk", ",", "\n", "verbose", "=", "verbose", ",", "\n", "args", "=", "args", ",", "\n", "mode", "=", "mode", ")", "\n", "# elif 'CC' in split:", "\n", "#     dataset = CCDataset(split, transform=transform, topk=topk)", "\n", "\n", "if", "distributed", "and", "mode", "==", "'train'", ":", "\n", "# sampler = DistributedSampler(dataset, num_replicas=world_size, rank=local_rank)", "\n", "        ", "train_sampler", "=", "DistributedSampler", "(", "dataset", ")", "\n", "# train_sampler = RandomNonreplacmentSampler(dataset, dataset.n_iter)", "\n", "", "else", ":", "\n", "        ", "train_sampler", "=", "None", "\n", "", "if", "mode", "==", "'train'", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "(", "train_sampler", "is", "None", ")", ",", "\n", "num_workers", "=", "workers", ",", "pin_memory", "=", "True", ",", "sampler", "=", "train_sampler", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ")", "\n", "", "else", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "workers", ",", "pin_memory", "=", "True", ",", "\n", "sampler", "=", "None", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ",", "\n", "drop_last", "=", "False", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "        ", "loader", ".", "evaluator", "=", "COCOCaptionEvaluator", "(", ")", "\n", "\n", "", "loader", ".", "task", "=", "'caption'", "\n", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.get_world_size": [[23, 29], ["torch.get_world_size", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.get_world_size"], ["def", "get_world_size", "(", ")", "->", "int", ":", "\n", "    ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "return", "dist", ".", "get_world_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.get_rank": [[31, 37], ["torch.get_rank", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.get_rank"], ["", "def", "get_rank", "(", ")", "->", "int", ":", "\n", "    ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "return", "dist", ".", "get_rank", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.get_local_rank": [[39, 50], ["torch.get_rank", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.get_rank"], ["", "def", "get_local_rank", "(", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Returns:\n        The rank of the current process within the local (per-machine) process group.\n    \"\"\"", "\n", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "assert", "_LOCAL_PROCESS_GROUP", "is", "not", "None", "\n", "return", "dist", ".", "get_rank", "(", "group", "=", "_LOCAL_PROCESS_GROUP", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.get_local_size": [[52, 63], ["torch.get_world_size", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.get_world_size"], ["", "def", "get_local_size", "(", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Returns:\n        The size of the per-machine process group,\n        i.e. the number of processes per machine.\n    \"\"\"", "\n", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "return", "dist", ".", "get_world_size", "(", "group", "=", "_LOCAL_PROCESS_GROUP", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.is_main_process": [[65, 67], ["dist_utils.get_rank"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.get_rank"], ["", "def", "is_main_process", "(", ")", "->", "bool", ":", "\n", "    ", "return", "get_rank", "(", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.synchronize": [[69, 82], ["torch.get_world_size", "torch.barrier", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.get_world_size"], ["", "def", "synchronize", "(", ")", ":", "\n", "    ", "\"\"\"\n    Helper function to synchronize (barrier) among all processes when\n    using distributed training\n    \"\"\"", "\n", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "\n", "", "world_size", "=", "dist", ".", "get_world_size", "(", ")", "\n", "if", "world_size", "==", "1", ":", "\n", "        ", "return", "\n", "", "dist", ".", "barrier", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils._get_global_gloo_group": [[84, 94], ["functools.lru_cache", "torch.get_backend", "torch.new_group"], "function", ["None"], ["", "@", "functools", ".", "lru_cache", "(", ")", "\n", "def", "_get_global_gloo_group", "(", ")", ":", "\n", "    ", "\"\"\"\n    Return a process group based on gloo backend, containing all the ranks\n    The result is cached.\n    \"\"\"", "\n", "if", "dist", ".", "get_backend", "(", ")", "==", "\"nccl\"", ":", "\n", "        ", "return", "dist", ".", "new_group", "(", "backend", "=", "\"gloo\"", ")", "\n", "", "else", ":", "\n", "        ", "return", "dist", ".", "group", ".", "WORLD", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils._serialize_to_tensor": [[96, 112], ["torch.get_backend", "torch.device", "torch.device", "torch.device", "pickle.dumps", "torch.ByteStorage.from_buffer", "torch.ByteStorage.from_buffer", "torch.ByteStorage.from_buffer", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "len", "logging.getLogger", "logging.getLogger.warning", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "dist_utils.get_rank", "len"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.get_rank"], ["", "", "def", "_serialize_to_tensor", "(", "data", ",", "group", ")", ":", "\n", "    ", "backend", "=", "dist", ".", "get_backend", "(", "group", ")", "\n", "assert", "backend", "in", "[", "\"gloo\"", ",", "\"nccl\"", "]", "\n", "device", "=", "torch", ".", "device", "(", "\"cpu\"", "if", "backend", "==", "\"gloo\"", "else", "\"cuda\"", ")", "\n", "\n", "buffer", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "if", "len", "(", "buffer", ")", ">", "1024", "**", "3", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Rank {} trying to all-gather {:.2f} GB of data on device {}\"", ".", "format", "(", "\n", "get_rank", "(", ")", ",", "len", "(", "buffer", ")", "/", "(", "1024", "**", "3", ")", ",", "device", "\n", ")", "\n", ")", "\n", "", "storage", "=", "torch", ".", "ByteStorage", ".", "from_buffer", "(", "buffer", ")", "\n", "tensor", "=", "torch", ".", "ByteTensor", "(", "storage", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils._pad_to_largest_tensor": [[114, 143], ["torch.get_world_size", "torch.tensor", "torch.tensor", "torch.tensor", "torch.all_gather", "max", "torch.zeros", "torch.zeros", "torch.zeros", "int", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat.numel", "range", "size.item"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.get_world_size", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.all_gather"], ["", "def", "_pad_to_largest_tensor", "(", "tensor", ",", "group", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        list[int]: size of the tensor, on each rank\n        Tensor: padded tensor that has the max size\n    \"\"\"", "\n", "world_size", "=", "dist", ".", "get_world_size", "(", "group", "=", "group", ")", "\n", "assert", "(", "\n", "world_size", ">=", "1", "\n", ")", ",", "\"comm.gather/all_gather must be called from ranks within the given group!\"", "\n", "local_size", "=", "torch", ".", "tensor", "(", "\n", "[", "tensor", ".", "numel", "(", ")", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "tensor", ".", "device", ")", "\n", "size_list", "=", "[", "\n", "torch", ".", "zeros", "(", "[", "1", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "tensor", ".", "device", ")", "\n", "for", "_", "in", "range", "(", "world_size", ")", "\n", "]", "\n", "dist", ".", "all_gather", "(", "size_list", ",", "local_size", ",", "group", "=", "group", ")", "\n", "size_list", "=", "[", "int", "(", "size", ".", "item", "(", ")", ")", "for", "size", "in", "size_list", "]", "\n", "\n", "max_size", "=", "max", "(", "size_list", ")", "\n", "\n", "# we pad the tensor because torch all_gather does not support", "\n", "# gathering tensors of different shapes", "\n", "if", "local_size", "!=", "max_size", ":", "\n", "        ", "padding", "=", "torch", ".", "zeros", "(", "\n", "(", "max_size", "-", "local_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "tensor", ".", "device", "\n", ")", "\n", "tensor", "=", "torch", ".", "cat", "(", "(", "tensor", ",", "padding", ")", ",", "dim", "=", "0", ")", "\n", "", "return", "size_list", ",", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.all_gather": [[145, 180], ["dist_utils._serialize_to_tensor", "dist_utils._pad_to_largest_tensor", "max", "torch.all_gather", "zip", "dist_utils.get_world_size", "dist_utils._get_global_gloo_group", "torch.get_world_size", "torch.empty", "torch.empty", "torch.empty", "data_list.append", "_serialize_to_tensor.cpu().numpy().tobytes", "pickle.loads", "_serialize_to_tensor.cpu().numpy", "_serialize_to_tensor.cpu"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils._serialize_to_tensor", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils._pad_to_largest_tensor", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.all_gather", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.get_world_size", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils._get_global_gloo_group", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.get_world_size"], ["", "def", "all_gather", "(", "data", ",", "group", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Run all_gather on arbitrary picklable data (not necessarily tensors).\n    Args:\n        data: any picklable object\n        group: a torch process group. By default, will use a group which\n            contains all ranks on gloo backend.\n    Returns:\n        list[data]: list of data gathered from each rank\n    \"\"\"", "\n", "if", "get_world_size", "(", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "", "if", "group", "is", "None", ":", "\n", "        ", "group", "=", "_get_global_gloo_group", "(", ")", "\n", "", "if", "dist", ".", "get_world_size", "(", "group", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "\n", "", "tensor", "=", "_serialize_to_tensor", "(", "data", ",", "group", ")", "\n", "\n", "size_list", ",", "tensor", "=", "_pad_to_largest_tensor", "(", "tensor", ",", "group", ")", "\n", "max_size", "=", "max", "(", "size_list", ")", "\n", "\n", "# receiving Tensor from all ranks", "\n", "tensor_list", "=", "[", "\n", "torch", ".", "empty", "(", "(", "max_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "tensor", ".", "device", ")", "\n", "for", "_", "in", "size_list", "\n", "]", "\n", "dist", ".", "all_gather", "(", "tensor_list", ",", "tensor", ",", "group", "=", "group", ")", "\n", "\n", "data_list", "=", "[", "]", "\n", "for", "size", ",", "tensor", "in", "zip", "(", "size_list", ",", "tensor_list", ")", ":", "\n", "        ", "buffer", "=", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tobytes", "(", ")", "[", ":", "size", "]", "\n", "data_list", ".", "append", "(", "pickle", ".", "loads", "(", "buffer", ")", ")", "\n", "\n", "", "return", "data_list", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.gather": [[182, 222], ["torch.get_rank", "dist_utils._serialize_to_tensor", "dist_utils._pad_to_largest_tensor", "dist_utils.get_world_size", "dist_utils._get_global_gloo_group", "torch.get_world_size", "max", "torch.gather", "zip", "torch.gather", "torch.empty", "torch.empty", "torch.empty", "data_list.append", "_serialize_to_tensor.cpu().numpy().tobytes", "pickle.loads", "_serialize_to_tensor.cpu().numpy", "_serialize_to_tensor.cpu"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.get_rank", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils._serialize_to_tensor", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils._pad_to_largest_tensor", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.get_world_size", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils._get_global_gloo_group", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.get_world_size", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.gather", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.gather"], ["", "def", "gather", "(", "data", ",", "dst", "=", "0", ",", "group", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Run gather on arbitrary picklable data (not necessarily tensors).\n    Args:\n        data: any picklable object\n        dst (int): destination rank\n        group: a torch process group. By default, will use a group which\n            contains all ranks on gloo backend.\n    Returns:\n        list[data]: on dst, a list of data gathered from each rank. Otherwise,\n            an empty list.\n    \"\"\"", "\n", "if", "get_world_size", "(", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "", "if", "group", "is", "None", ":", "\n", "        ", "group", "=", "_get_global_gloo_group", "(", ")", "\n", "", "if", "dist", ".", "get_world_size", "(", "group", "=", "group", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "", "rank", "=", "dist", ".", "get_rank", "(", "group", "=", "group", ")", "\n", "\n", "tensor", "=", "_serialize_to_tensor", "(", "data", ",", "group", ")", "\n", "size_list", ",", "tensor", "=", "_pad_to_largest_tensor", "(", "tensor", ",", "group", ")", "\n", "\n", "# receiving Tensor from all ranks", "\n", "if", "rank", "==", "dst", ":", "\n", "        ", "max_size", "=", "max", "(", "size_list", ")", "\n", "tensor_list", "=", "[", "\n", "torch", ".", "empty", "(", "(", "max_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "tensor", ".", "device", ")", "\n", "for", "_", "in", "size_list", "\n", "]", "\n", "dist", ".", "gather", "(", "tensor", ",", "tensor_list", ",", "dst", "=", "dst", ",", "group", "=", "group", ")", "\n", "\n", "data_list", "=", "[", "]", "\n", "for", "size", ",", "tensor", "in", "zip", "(", "size_list", ",", "tensor_list", ")", ":", "\n", "            ", "buffer", "=", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tobytes", "(", ")", "[", ":", "size", "]", "\n", "data_list", ".", "append", "(", "pickle", ".", "loads", "(", "buffer", ")", ")", "\n", "", "return", "data_list", "\n", "", "else", ":", "\n", "        ", "dist", ".", "gather", "(", "tensor", ",", "[", "]", ",", "dst", "=", "dst", ",", "group", "=", "group", ")", "\n", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.shared_random_seed": [[224, 235], ["numpy.random.randint", "dist_utils.all_gather"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.all_gather"], ["", "", "def", "shared_random_seed", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        int: a random number that is the same across all workers.\n            If workers need a shared RNG, they can use this shared seed to\n            create one.\n    All workers must call this function, otherwise it will deadlock.\n    \"\"\"", "\n", "ints", "=", "np", ".", "random", ".", "randint", "(", "2", "**", "31", ")", "\n", "all_ints", "=", "all_gather", "(", "ints", ")", "\n", "return", "all_ints", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.reduce_dict": [[267, 306], ["dist_utils.get_world_size", "torch.no_grad", "torch.no_grad", "torch.no_grad", "input_dict.items", "sorted", "torch.stack", "torch.stack", "torch.stack", "torch.reduce", "input_dict_cuda_vals.items", "names.append", "torch.stack.append", "type", "v.to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.get_rank", "zip"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.get_world_size", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.get_rank"], ["", "def", "reduce_dict", "(", "input_dict", ",", "average", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Reduce the values in the dictionary from all processes so that process with rank\n    0 has the reduced results.\n    Args:\n        input_dict (dict): inputs to be reduced. (values not necessarily tensors).\n        average (bool): whether to do average or sum\n    Returns:\n        a dict with the same keys as input_dict, after reduction.\n    \"\"\"", "\n", "\n", "world_size", "=", "get_world_size", "(", ")", "\n", "if", "world_size", "<", "2", ":", "\n", "        ", "return", "input_dict", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "# Convert to CUDA Tensor for dist.reduce()", "\n", "        ", "input_dict_cuda_vals", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "input_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "type", "(", "v", ")", "==", "torch", ".", "Tensor", ":", "\n", "                ", "input_dict_cuda_vals", "[", "k", "]", "=", "v", ".", "to", "(", "'cuda'", ")", "\n", "", "else", ":", "\n", "                ", "input_dict_cuda_vals", "[", "k", "]", "=", "torch", ".", "tensor", "(", "v", ",", "device", "=", "'cuda'", ")", "\n", "\n", "", "", "names", "=", "[", "]", "\n", "values", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "sorted", "(", "input_dict_cuda_vals", ".", "items", "(", ")", ")", ":", "\n", "            ", "names", ".", "append", "(", "k", ")", "\n", "values", ".", "append", "(", "v", ")", "\n", "", "values", "=", "torch", ".", "stack", "(", "values", ",", "dim", "=", "0", ")", "\n", "dist", ".", "reduce", "(", "values", ",", "dst", "=", "0", ")", "# reduce to gpu 0", "\n", "\n", "if", "dist", ".", "get_rank", "(", ")", "==", "0", "and", "average", ":", "\n", "# only main process gets accumulated, so only divide by", "\n", "# world_size in this case", "\n", "            ", "values", "/=", "world_size", "\n", "", "reduced_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "names", ",", "values", ")", "}", "\n", "", "return", "reduced_dict", "\n", "", ""]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_data.COCOCaptionFineTuneDataset.__init__": [[30, 131], ["torch.utils.data.Dataset.__init__", "dataset_dir.joinpath", "torch.cuda.device_count", "print", "open", "json.load", "print", "print", "random.seed", "random.shuffle", "print", "flickr_data.COCOCaptionFineTuneDataset.source_to_h5.update", "tokenization.FewVLMTokenizerFast.from_pretrained", "transformers.T5TokenizerFast.from_pretrained", "data.append", "print", "len", "flickr_data.COCOCaptionFineTuneDataset.source.split", "data.append", "datum[].split", "flickr_dir.joinpath().joinpath", "datum[].split", "d[].strip", "d[].strip", "len", "d[].strip", "flickr_dir.joinpath"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update"], ["    ", "def", "__init__", "(", "self", ",", "split", "=", "'karpathy_train'", ",", "raw_dataset", "=", "None", ",", "rank", "=", "-", "1", ",", "topk", "=", "-", "1", ",", "verbose", "=", "True", ",", "args", "=", "None", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "raw_dataset", "=", "raw_dataset", "\n", "self", ".", "topk", "=", "topk", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "mode", "=", "mode", "\n", "\n", "# Loading datasets to data", "\n", "self", ".", "source", "=", "split", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "'Data source: '", ",", "self", ".", "source", ")", "\n", "\n", "\n", "", "if", "self", ".", "args", ".", "tokenizer", "is", "None", ":", "\n", "            ", "self", ".", "args", ".", "tokenizer", "=", "self", ".", "args", ".", "backbone", "\n", "\n", "", "if", "'t5'", "in", "self", ".", "args", ".", "tokenizer", ":", "\n", "            ", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "                ", "self", ".", "tokenizer", "=", "FewVLMTokenizerFast", ".", "from_pretrained", "(", "\n", "args", ".", "backbone", ",", "\n", "# max_length=self.args.max_text_length,", "\n", "do_lower_case", "=", "self", ".", "args", ".", "do_lower_case", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "tokenizer", "=", "T5TokenizerFast", ".", "from_pretrained", "(", "\n", "args", ".", "backbone", ",", "\n", "# max_length=self.args.max_text_length,", "\n", "do_lower_case", "=", "self", ".", "args", ".", "do_lower_case", ")", "\n", "\n", "", "", "data_info_path", "=", "dataset_dir", ".", "joinpath", "(", "f'flickr30k/{args.caption_data}.json'", ")", "\n", "with", "open", "(", "data_info_path", ")", "as", "f", ":", "\n", "            ", "karpathy_data", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "split_rename", "=", "{", "\n", "'train'", ":", "'train'", ",", "\n", "'restval'", ":", "'train'", ",", "\n", "'val'", ":", "'val'", ",", "\n", "'test'", ":", "'test'", "\n", "}", "\n", "\n", "n_images", "=", "0", "\n", "\n", "data", "=", "[", "]", "\n", "for", "datum", "in", "karpathy_data", "[", "'images'", "]", ":", "\n", "            ", "re_split", "=", "split_rename", "[", "datum", "[", "'split'", "]", "]", "\n", "if", "re_split", "!=", "self", ".", "source", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "re_split", "==", "'train'", ":", "\n", "                ", "for", "d", "in", "datum", "[", "'sentences'", "]", ":", "\n", "                    ", "img_id", "=", "datum", "[", "'filename'", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "new_datum", "=", "{", "\n", "'img_id'", ":", "img_id", ",", "\n", "'sent'", ":", "d", "[", "'raw'", "]", ".", "strip", "(", ")", ",", "\n", "'targets'", ":", "[", "d", "[", "'raw'", "]", ".", "strip", "(", ")", "for", "d", "in", "datum", "[", "'sentences'", "]", "]", ",", "\n", "'is_train'", ":", "True", ",", "\n", "}", "\n", "data", ".", "append", "(", "new_datum", ")", "\n", "", "", "else", ":", "\n", "                ", "img_id", "=", "datum", "[", "'filename'", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "new_datum", "=", "{", "\n", "'img_id'", ":", "img_id", ",", "\n", "# 'sent': d['raw'],", "\n", "'targets'", ":", "[", "d", "[", "'raw'", "]", ".", "strip", "(", ")", "for", "d", "in", "datum", "[", "'sentences'", "]", "]", ",", "\n", "'is_train'", ":", "False", ",", "\n", "}", "\n", "data", ".", "append", "(", "new_datum", ")", "\n", "\n", "", "n_images", "+=", "1", "\n", "\n", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "f\"{self.source} has {n_images} images\"", ")", "\n", "print", "(", "f\"Loaded {len(data)} data from\"", ",", "split", ")", "\n", "\n", "", "self", ".", "n_gpus", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "self", ".", "rank", "=", "rank", "\n", "if", "self", ".", "topk", ">", "0", ":", "\n", "            ", "data", "=", "data", "[", ":", "self", ".", "topk", "]", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "f\"Use only {self.topk} data\"", ")", "\n", "\n", "", "", "self", ".", "data", "=", "data", "\n", "if", "args", ".", "subsample", "and", "'train'", "in", "split", ":", "\n", "            ", "random", ".", "seed", "(", "args", ".", "dataseed", ")", "\n", "random", ".", "shuffle", "(", "self", ".", "data", ")", "\n", "if", "'train'", "in", "split", "and", "mode", "==", "'train'", ":", "\n", "                ", "self", ".", "data", "=", "self", ".", "data", "[", ":", "args", ".", "num_data", "]", "\n", "", "elif", "'train'", "in", "split", "and", "mode", "==", "'val'", ":", "\n", "                ", "self", ".", "data", "=", "self", ".", "data", "[", "args", ".", "num_data", ":", "2", "*", "args", ".", "num_data", "]", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "\"# all sentences:\"", ",", "len", "(", "self", ".", "data", ")", ")", "\n", "\n", "", "self", ".", "source_to_h5", "=", "{", "}", "\n", "\n", "if", "self", ".", "args", ".", "max_n_boxes", "==", "36", ":", "\n", "            ", "self", ".", "source_to_h5", ".", "update", "(", "{", "\n", "'all'", ":", "flickr_dir", ".", "joinpath", "(", "'features'", ")", ".", "joinpath", "(", "'flickr30k_boxes36.h5'", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_data.COCOCaptionFineTuneDataset.__len__": [[134, 136], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_data.COCOCaptionFineTuneDataset.__getitem__": [[137, 236], ["torch.LongTensor", "len", "isinstance", "numpy.testing.assert_array_less", "numpy.testing.assert_array_less", "torch.from_numpy", "torch.from_numpy.clamp_", "len", "numpy.zeros", "f[].read_direct", "torch.from_numpy", "min", "datum[].strip", "len", "torch.LongTensor", "len", "h5py.File", "flickr_data.COCOCaptionFineTuneDataset.tokenizer.encode", "flickr_data.COCOCaptionFineTuneDataset.tokenizer.encode", "len", "len", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "out_dict", "=", "{", "}", "\n", "out_dict", "[", "'args'", "]", "=", "self", ".", "args", "\n", "\n", "datum", "=", "self", ".", "data", "[", "idx", "]", "\n", "\n", "###### Image ######", "\n", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "            ", "img_id", "=", "datum", "[", "'img_id'", "]", "\n", "out_dict", "[", "'img_id'", "]", "=", "img_id", "\n", "\n", "\n", "\n", "f", "=", "self", ".", "source_to_h5", "[", "'all'", "]", "\n", "\n", "if", "isinstance", "(", "f", ",", "Path", ")", ":", "\n", "# path = self.data_source_to_h5_path[source]", "\n", "                ", "f", "=", "h5py", ".", "File", "(", "f", ",", "'r'", ")", "\n", "# self.split_to_h5_features[split_i] = f", "\n", "self", ".", "source_to_h5", "[", "'all'", "]", "=", "f", "\n", "\n", "# Normalize the boxes (to 0 ~ 1)", "\n", "", "img_h", "=", "f", "[", "f'{img_id}/img_h'", "]", "[", "(", ")", "]", "\n", "img_w", "=", "f", "[", "f'{img_id}/img_w'", "]", "[", "(", ")", "]", "\n", "boxes", "=", "f", "[", "f'{img_id}/boxes'", "]", "[", "(", ")", "]", "# (x1, y1, x2, y2)", "\n", "boxes", "[", ":", ",", "(", "0", ",", "2", ")", "]", "/=", "img_w", "\n", "boxes", "[", ":", ",", "(", "1", ",", "3", ")", "]", "/=", "img_h", "\n", "np", ".", "testing", ".", "assert_array_less", "(", "boxes", ",", "1", "+", "1e-5", ")", "\n", "# np.testing.assert_array_less(boxes, 1+5e-2)", "\n", "np", ".", "testing", ".", "assert_array_less", "(", "-", "boxes", ",", "0", "+", "1e-5", ")", "\n", "boxes", "=", "torch", ".", "from_numpy", "(", "boxes", ")", "\n", "\n", "boxes", ".", "clamp_", "(", "min", "=", "0.0", ",", "max", "=", "1.0", ")", "\n", "\n", "n_boxes", "=", "len", "(", "boxes", ")", "\n", "\n", "feats", "=", "np", ".", "zeros", "(", "shape", "=", "(", "n_boxes", ",", "2048", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "f", "[", "f'{img_id}/features'", "]", ".", "read_direct", "(", "feats", ")", "\n", "feats", "=", "torch", ".", "from_numpy", "(", "feats", ")", "\n", "\n", "if", "self", ".", "args", ".", "n_boxes", "==", "100", ":", "\n", "                ", "assert", "n_boxes", "==", "100", "\n", "assert", "len", "(", "feats", ")", "==", "100", "\n", "assert", "len", "(", "boxes", ")", "==", "100", "\n", "\n", "", "n_boxes", "=", "min", "(", "n_boxes", ",", "self", ".", "args", ".", "max_n_boxes", ")", "\n", "out_dict", "[", "'n_boxes'", "]", "=", "n_boxes", "\n", "boxes", "=", "boxes", "[", ":", "n_boxes", "]", "\n", "feats", "=", "feats", "[", ":", "n_boxes", "]", "\n", "out_dict", "[", "'boxes'", "]", "=", "boxes", "\n", "out_dict", "[", "'vis_feats'", "]", "=", "feats", "\n", "\n", "###### Text #####", "\n", "", "if", "self", ".", "args", ".", "no_prefix", ":", "\n", "            ", "input_text", "=", "''", "\n", "input_ids", "=", "[", "]", "\n", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "args", ".", "prefix", "is", "None", ":", "\n", "                ", "prefix", "=", "''", "\n", "", "elif", "self", ".", "args", ".", "prefix", "==", "'picture'", ":", "\n", "                ", "prefix", "=", "'a picture of'", "\n", "", "elif", "self", ".", "args", ".", "prefix", "==", "'image'", ":", "\n", "                ", "prefix", "=", "'an image of'", "\n", "", "elif", "self", ".", "args", ".", "prefix", "==", "'photo'", ":", "\n", "                ", "prefix", "=", "'a photo of'", "\n", "\n", "\n", "\n", "", "input_tokens", "=", "[", "prefix", "]", "\n", "\n", "input_text", "=", "' '", ".", "join", "(", "input_tokens", ")", "\n", "\n", "if", "'t5'", "in", "self", ".", "args", ".", "tokenizer", ":", "\n", "                ", "input_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "\n", "input_text", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_text_length", ",", "truncation", "=", "True", ")", "\n", "\n", "", "", "out_dict", "[", "'input_text'", "]", "=", "input_text", "\n", "\n", "out_dict", "[", "'input_ids'", "]", "=", "torch", ".", "LongTensor", "(", "input_ids", ")", "\n", "out_dict", "[", "'input_length'", "]", "=", "len", "(", "input_ids", ")", "\n", "if", "datum", "[", "'is_train'", "]", ":", "\n", "            ", "sent", "=", "datum", "[", "'sent'", "]", ".", "strip", "(", ")", "\n", "if", "'t5'", "in", "self", ".", "args", ".", "tokenizer", ":", "\n", "                ", "target_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "sent", ",", "max_length", "=", "self", ".", "args", ".", "gen_max_length", ",", "truncation", "=", "True", ")", "\n", "# target_ids = self.tokenizer.encode('<extra_id_0> '+sent, max_length=self.args.gen_max_length, truncation=True)", "\n", "\n", "", "assert", "len", "(", "target_ids", ")", "<=", "self", ".", "args", ".", "gen_max_length", ",", "len", "(", "target_ids", ")", "\n", "out_dict", "[", "'sent'", "]", "=", "sent", "\n", "out_dict", "[", "'target_ids'", "]", "=", "torch", ".", "LongTensor", "(", "target_ids", ")", "\n", "out_dict", "[", "'target_length'", "]", "=", "len", "(", "target_ids", ")", "\n", "\n", "", "if", "'targets'", "in", "datum", ":", "\n", "            ", "out_dict", "[", "'targets'", "]", "=", "datum", "[", "'targets'", "]", "\n", "\n", "\n", "", "return", "out_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_data.COCOCaptionFineTuneDataset.collate_fn": [[237, 313], ["len", "max", "enumerate", "torch.ones", "max", "torch.zeros", "torch.zeros", "torch.zeros", "max", "input_ids.size", "torch.ones", "img_ids.append", "input_text.append", "targets.append"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "batch", ")", ":", "\n", "        ", "batch_entry", "=", "{", "}", "\n", "\n", "B", "=", "len", "(", "batch", ")", "\n", "\n", "S_W_L", "=", "max", "(", "entry", "[", "'input_length'", "]", "for", "entry", "in", "batch", ")", "\n", "input_ids", "=", "torch", ".", "ones", "(", "B", ",", "S_W_L", ",", "dtype", "=", "torch", ".", "long", ")", "*", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "\n", "if", "self", ".", "args", ".", "no_prefix", ":", "\n", "            ", "assert", "input_ids", ".", "size", "(", ")", "==", "(", "B", ",", "0", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "            ", "V_L", "=", "max", "(", "entry", "[", "'n_boxes'", "]", "for", "entry", "in", "batch", ")", "\n", "# V_L = len(batch[0]['boxes'])", "\n", "feat_dim", "=", "batch", "[", "0", "]", "[", "'vis_feats'", "]", ".", "shape", "[", "-", "1", "]", "\n", "\n", "boxes", "=", "torch", ".", "zeros", "(", "B", ",", "V_L", ",", "4", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "vis_feats", "=", "torch", ".", "zeros", "(", "B", ",", "V_L", ",", "feat_dim", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "vis_attention_mask", "=", "torch", ".", "zeros", "(", "B", ",", "V_L", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "if", "'target_ids'", "in", "batch", "[", "0", "]", ":", "\n", "            ", "T_W_L", "=", "max", "(", "entry", "[", "'target_length'", "]", "for", "entry", "in", "batch", ")", "\n", "target_ids", "=", "torch", ".", "ones", "(", "B", ",", "T_W_L", ",", "dtype", "=", "torch", ".", "long", ")", "*", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "\n", "# sentences = []", "\n", "\n", "", "targets", "=", "[", "]", "\n", "img_ids", "=", "[", "]", "\n", "img_paths", "=", "[", "]", "\n", "input_text", "=", "[", "]", "\n", "\n", "for", "i", ",", "entry", "in", "enumerate", "(", "batch", ")", ":", "\n", "            ", "input_ids", "[", "i", ",", ":", "entry", "[", "'input_length'", "]", "]", "=", "entry", "[", "'input_ids'", "]", "\n", "\n", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "                ", "n_boxes", "=", "entry", "[", "'n_boxes'", "]", "\n", "boxes", "[", "i", ",", ":", "n_boxes", "]", "=", "entry", "[", "'boxes'", "]", "\n", "vis_feats", "[", "i", ",", ":", "n_boxes", "]", "=", "entry", "[", "'vis_feats'", "]", "\n", "vis_attention_mask", "[", "i", ",", ":", "n_boxes", "]", "=", "1", "\n", "img_ids", ".", "append", "(", "entry", "[", "'img_id'", "]", ")", "\n", "# img_paths.append(entry['img_path'])", "\n", "\n", "", "if", "'target_ids'", "in", "entry", ":", "\n", "                ", "target_ids", "[", "i", ",", ":", "entry", "[", "'target_length'", "]", "]", "=", "entry", "[", "'target_ids'", "]", "\n", "\n", "", "if", "'input_text'", "in", "entry", ":", "\n", "                ", "input_text", ".", "append", "(", "entry", "[", "'input_text'", "]", ")", "\n", "\n", "# sentences.append(entry['sent'])", "\n", "\n", "", "if", "'targets'", "in", "entry", ":", "\n", "                ", "targets", ".", "append", "(", "entry", "[", "'targets'", "]", ")", "\n", "\n", "\n", "", "", "batch_entry", "[", "'input_ids'", "]", "=", "input_ids", "\n", "if", "'target_ids'", "in", "batch", "[", "0", "]", ":", "\n", "            ", "word_mask", "=", "target_ids", "!=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "target_ids", "[", "~", "word_mask", "]", "=", "-", "100", "\n", "batch_entry", "[", "'target_ids'", "]", "=", "target_ids", "\n", "\n", "", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "            ", "batch_entry", "[", "'boxes'", "]", "=", "boxes", "\n", "batch_entry", "[", "'vis_feats'", "]", "=", "vis_feats", "\n", "batch_entry", "[", "'vis_attention_mask'", "]", "=", "vis_attention_mask", "\n", "batch_entry", "[", "'img_id'", "]", "=", "img_ids", "\n", "batch_entry", "[", "'img_paths'", "]", "=", "img_paths", "\n", "\n", "# batch_entry['sent'] = sentences", "\n", "\n", "", "batch_entry", "[", "'input_text'", "]", "=", "input_text", "\n", "\n", "batch_entry", "[", "'targets'", "]", "=", "targets", "\n", "\n", "batch_entry", "[", "'task'", "]", "=", "'caption'", "\n", "\n", "return", "batch_entry", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_data.COCOCaptionEvaluator.__init__": [[363, 366], ["language_evaluation.CocoEvaluator"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "import", "language_evaluation", "\n", "self", ".", "evaluator", "=", "language_evaluation", ".", "CocoEvaluator", "(", "verbose", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_data.COCOCaptionEvaluator.evaluate": [[368, 373], ["flickr_data.COCOCaptionEvaluator.evaluator.run_evaluation"], "methods", ["None"], ["", "def", "evaluate", "(", "self", ",", "predicts", ",", "answers", ")", ":", "\n", "\n", "        ", "results", "=", "self", ".", "evaluator", ".", "run_evaluation", "(", "predicts", ",", "answers", ")", "\n", "\n", "return", "results", "", "", "", ""]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_data.get_loader": [[315, 359], ["flickr_data.COCOCaptionFineTuneDataset", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "flickr_data.COCOCaptionEvaluator"], "function", ["None"], ["", "", "def", "get_loader", "(", "args", ",", "split", "=", "'train'", ",", "mode", "=", "'train'", ",", "\n", "batch_size", "=", "32", ",", "workers", "=", "4", ",", "distributed", "=", "False", ",", "gpu", "=", "0", ",", "\n", "topk", "=", "-", "1", ")", ":", "\n", "\n", "# if 'mscoco' in split:", "\n", "    ", "verbose", "=", "(", "gpu", "==", "0", ")", "\n", "\n", "dataset", "=", "COCOCaptionFineTuneDataset", "(", "\n", "split", ",", "\n", "# raw_dataset=_dset,", "\n", "rank", "=", "gpu", ",", "\n", "topk", "=", "topk", ",", "\n", "verbose", "=", "verbose", ",", "\n", "args", "=", "args", ",", "\n", "mode", "=", "mode", ")", "\n", "# elif 'CC' in split:", "\n", "#     dataset = CCDataset(split, transform=transform, topk=topk)", "\n", "\n", "if", "distributed", "and", "mode", "==", "'train'", ":", "\n", "# sampler = DistributedSampler(dataset, num_replicas=world_size, rank=local_rank)", "\n", "        ", "train_sampler", "=", "DistributedSampler", "(", "dataset", ")", "\n", "# train_sampler = RandomNonreplacmentSampler(dataset, dataset.n_iter)", "\n", "", "else", ":", "\n", "        ", "train_sampler", "=", "None", "\n", "", "if", "mode", "==", "'train'", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "(", "train_sampler", "is", "None", ")", ",", "\n", "num_workers", "=", "workers", ",", "pin_memory", "=", "True", ",", "sampler", "=", "train_sampler", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ")", "\n", "", "else", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "workers", ",", "pin_memory", "=", "True", ",", "\n", "sampler", "=", "None", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ",", "\n", "drop_last", "=", "False", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "        ", "loader", ".", "evaluator", "=", "COCOCaptionEvaluator", "(", ")", "\n", "\n", "", "loader", ".", "task", "=", "'caption'", "\n", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.param.Config.__init__": [[218, 222], ["kwargs.items", "setattr"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Configuration Class: set kwargs as class attributes with setattr\"\"\"", "\n", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "setattr", "(", "self", ",", "k", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.param.Config.config_str": [[223, 226], ["pprint.pformat"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "config_str", "(", "self", ")", ":", "\n", "        ", "return", "pprint", ".", "pformat", "(", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.param.Config.__repr__": [[227, 232], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Pretty-print configurations in alphabetical order\"\"\"", "\n", "config_str", "=", "'Configurations\\n'", "\n", "config_str", "+=", "self", ".", "config_str", "\n", "return", "config_str", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.param.Config.save": [[233, 236], ["open", "yaml.dump"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "path", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "yaml", ".", "dump", "(", "self", ".", "__dict__", ",", "f", ",", "default_flow_style", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.param.Config.load": [[237, 243], ["param.Config", "open", "yaml.load"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load"], ["", "", "@", "classmethod", "\n", "def", "load", "(", "cls", ",", "path", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "kwargs", "=", "yaml", ".", "load", "(", "f", ")", "\n", "\n", "", "return", "Config", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.param.str2bool": [[11, 18], ["v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["def", "str2bool", "(", "v", ")", ":", "\n", "    ", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.param.is_interactive": [[20, 23], ["hasattr"], "function", ["None"], ["", "", "def", "is_interactive", "(", ")", ":", "\n", "    ", "import", "__main__", "as", "main", "\n", "return", "not", "hasattr", "(", "main", ",", "'__file__'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.param.get_optimizer": [[25, 52], ["print", "print", "print", "print", "print"], "function", ["None"], ["", "def", "get_optimizer", "(", "optim", ",", "verbose", "=", "False", ")", ":", "\n", "# Bind the optimizer", "\n", "    ", "if", "optim", "==", "'rms'", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "\"Optimizer: Using RMSProp\"", ")", "\n", "", "optimizer", "=", "torch", ".", "optim", ".", "RMSprop", "\n", "", "elif", "optim", "==", "'adam'", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "\"Optimizer: Using Adam\"", ")", "\n", "", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "\n", "", "elif", "optim", "==", "'adamw'", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "\"Optimizer: Using AdamW\"", ")", "\n", "# optimizer = torch.optim.AdamW", "\n", "", "optimizer", "=", "'adamw'", "\n", "", "elif", "optim", "==", "'adamax'", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "\"Optimizer: Using Adamax\"", ")", "\n", "", "optimizer", "=", "torch", ".", "optim", ".", "Adamax", "\n", "", "elif", "optim", "==", "'sgd'", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "\"Optimizer: SGD\"", ")", "\n", "", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "\n", "", "else", ":", "\n", "        ", "assert", "False", ",", "\"Please add your optimizer %s in the list.\"", "%", "optim", "\n", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.param.parse_args": [[54, 215], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "vars", "vars.update", "param.Config", "param.get_optimizer", "torch.manual_seed", "random.seed", "numpy.random.seed", "argparse.ArgumentParser.parse_args", "argparse.ArgumentParser.parse_known_args"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.param.get_optimizer", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.param.parse_args"], ["", "def", "parse_args", "(", "parse", "=", "True", ",", "**", "optional_kwargs", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "9595", ",", "help", "=", "'random seed'", ")", "\n", "\n", "# Data Splits", "\n", "parser", ".", "add_argument", "(", "\"--train\"", ",", "default", "=", "'train'", ")", "\n", "parser", ".", "add_argument", "(", "\"--valid\"", ",", "default", "=", "'valid'", ")", "\n", "parser", ".", "add_argument", "(", "\"--test\"", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--test_only'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--submit'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "# Quick experiments", "\n", "parser", ".", "add_argument", "(", "'--train_topk'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--valid_topk'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "\n", "# Checkpoint", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "type", "=", "str", ",", "default", "=", "'snap/test'", ")", "\n", "parser", ".", "add_argument", "(", "'--load'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "'Load the model (usually the fine-tuned model).'", ")", "\n", "parser", ".", "add_argument", "(", "'--from_scratch'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "# CPU/GPU", "\n", "parser", ".", "add_argument", "(", "\"--multiGPU\"", ",", "action", "=", "'store_const'", ",", "default", "=", "False", ",", "const", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "\"--distributed\"", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_workers\"", ",", "default", "=", "0", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--local_rank'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--master-port\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Master port (for multi-node SLURM jobs)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cpu\"", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether not to use CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--ddp-backend\"", ",", "type", "=", "str", ",", "default", "=", "'pytorch'", ",", "choices", "=", "[", "'pytorch'", ",", "'apex'", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--debug-slurm\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Debug multi-GPU / multi-node within a SLURM job\"", ")", "\n", "\n", "# Model Config", "\n", "parser", ".", "add_argument", "(", "'--backbone'", ",", "type", "=", "str", ",", "default", "=", "'t5-base'", ")", "\n", "parser", ".", "add_argument", "(", "'--tokenizer'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--feat_dim'", ",", "type", "=", "float", ",", "default", "=", "2048", ")", "\n", "parser", ".", "add_argument", "(", "'--pos_dim'", ",", "type", "=", "float", ",", "default", "=", "4", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--use_vision'", ",", "default", "=", "True", ",", "type", "=", "str2bool", ")", "\n", "parser", ".", "add_argument", "(", "'--use_vis_order_embedding'", ",", "default", "=", "True", ",", "type", "=", "str2bool", ")", "\n", "parser", ".", "add_argument", "(", "'--use_vis_layer_norm'", ",", "default", "=", "True", ",", "type", "=", "str2bool", ")", "\n", "parser", ".", "add_argument", "(", "'--individual_vis_layer_norm'", ",", "default", "=", "True", ",", "type", "=", "str2bool", ")", "\n", "parser", ".", "add_argument", "(", "'--share_vis_lang_layer_norm'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--n_boxes'", ",", "type", "=", "int", ",", "default", "=", "36", ")", "\n", "parser", ".", "add_argument", "(", "'--max_n_boxes'", ",", "type", "=", "int", ",", "default", "=", "36", ")", "\n", "parser", ".", "add_argument", "(", "'--max_text_length'", ",", "type", "=", "int", ",", "default", "=", "20", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--image_size'", ",", "type", "=", "float", ",", "default", "=", "8192", ")", "\n", "\n", "# Training", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "256", ")", "\n", "parser", ".", "add_argument", "(", "'--valid_batch_size'", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--optim'", ",", "default", "=", "'adamw'", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_ratio'", ",", "type", "=", "float", ",", "default", "=", "0.05", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_decay'", ",", "type", "=", "float", ",", "default", "=", "0.01", ")", "\n", "parser", ".", "add_argument", "(", "'--clip_grad_norm'", ",", "type", "=", "float", ",", "default", "=", "-", "1.0", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "1e-4", ")", "\n", "parser", ".", "add_argument", "(", "'--adam_eps'", ",", "type", "=", "float", ",", "default", "=", "1e-6", ")", "\n", "parser", ".", "add_argument", "(", "'--adam_beta1'", ",", "type", "=", "float", ",", "default", "=", "0.9", ")", "\n", "parser", ".", "add_argument", "(", "'--adam_beta2'", ",", "type", "=", "float", ",", "default", "=", "0.999", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "12", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--losses\"", ",", "default", "=", "'prefix,lm'", ",", "type", "=", "str", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--log_train_accuracy'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--n_ground'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--wordMaskRate\"", ",", "dest", "=", "'word_mask_rate'", ",", "default", "=", "0.15", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--objMaskRate\"", ",", "dest", "=", "'obj_mask_rate'", ",", "default", "=", "0.15", ",", "type", "=", "float", ")", "\n", "\n", "# Inference", "\n", "parser", ".", "add_argument", "(", "'--num_beams'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--gen_max_length'", ",", "type", "=", "int", ",", "default", "=", "20", ")", "\n", "\n", "# Data", "\n", "parser", ".", "add_argument", "(", "'--caption_only'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--coco_only'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--caption_cocoonly'", ",", "default", "=", "True", ",", "type", "=", "str2bool", ")", "\n", "parser", ".", "add_argument", "(", "'--caption_data'", ",", "type", "=", "str", ",", "default", "=", "'dataset_coco'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--do_lower_case'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--oscar_tags'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--prefix'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "\n", "# Pretraining", "\n", "parser", ".", "add_argument", "(", "'--ground_upsample'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--ground_weight'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--itm_cocoonly'", ",", "default", "=", "True", ",", "type", "=", "str2bool", ")", "\n", "parser", ".", "add_argument", "(", "'--single_vqa_prefix'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--caption_no_eos'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--freeze_text'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--vis_size'", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "\n", "# Resnet", "\n", "parser", ".", "add_argument", "(", "'--pretrained'", ",", "default", "=", "True", ",", "type", "=", "str2bool", ")", "\n", "parser", ".", "add_argument", "(", "\"--arch\"", ",", "default", "=", "'resnext50_32x4d'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--resnet_dim'", ",", "type", "=", "float", ",", "default", "=", "1000", ")", "\n", "parser", ".", "add_argument", "(", "'--two_prefix'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "# COCO Caption", "\n", "parser", ".", "add_argument", "(", "'--no_prefix'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--BUTD100\"", ",", "action", "=", "'store_true'", ")", "\n", "\n", "# VQA", "\n", "parser", ".", "add_argument", "(", "\"--raw_label\"", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "\"--answer_normalize\"", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "\"--classifier\"", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_answerable\"", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--prompt'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--dataseed'", ",", "type", "=", "int", ",", "default", "=", "9595", ",", "help", "=", "'random seed'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_data'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "'random seed'", ")", "\n", "parser", ".", "add_argument", "(", "'--subsample'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_mask_target'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "# RefCOCOg", "\n", "parser", ".", "add_argument", "(", "'--RefCOCO_GT'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--RefCOCO_BUTD'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "\"--shuffle_boxes\"", ",", "action", "=", "'store_true'", ")", "\n", "\n", "# Multitask", "\n", "parser", ".", "add_argument", "(", "\"--multitask_sampling\"", ",", "type", "=", "str", ",", "default", "=", "'roundrobin'", ")", "\n", "parser", ".", "add_argument", "(", "\"--tasks\"", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "\n", "# Etc.", "\n", "parser", ".", "add_argument", "(", "'--comment'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "\"--dry\"", ",", "action", "=", "'store_true'", ")", "\n", "\n", "# Parse the arguments.", "\n", "if", "parse", ":", "\n", "        ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "# For interative engironmnet (ex. jupyter)", "\n", "", "else", ":", "\n", "        ", "args", "=", "parser", ".", "parse_known_args", "(", ")", "[", "0", "]", "\n", "\n", "# Namespace => Dictionary", "\n", "", "kwargs", "=", "vars", "(", "args", ")", "\n", "kwargs", ".", "update", "(", "optional_kwargs", ")", "\n", "\n", "args", "=", "Config", "(", "**", "kwargs", ")", "\n", "\n", "# Bind optimizer class.", "\n", "verbose", "=", "False", "\n", "args", ".", "optimizer", "=", "get_optimizer", "(", "args", ".", "optim", ",", "verbose", "=", "verbose", ")", "\n", "\n", "# Set seeds", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.__init__": [[39, 56], ["utils.set_global_logging_level"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.set_global_logging_level"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "train_loader", "=", "None", ",", "val_loader", "=", "None", ",", "test_loader", "=", "None", ",", "train", "=", "True", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "train_loader", "=", "train_loader", "\n", "self", ".", "val_loader", "=", "val_loader", "\n", "self", ".", "test_loader", "=", "test_loader", "\n", "\n", "self", ".", "verbose", "=", "True", "\n", "if", "self", ".", "args", ".", "distributed", ":", "\n", "            ", "if", "self", ".", "args", ".", "gpu", "!=", "0", ":", "\n", "                ", "self", ".", "verbose", "=", "False", "\n", "\n", "", "", "if", "self", ".", "args", ".", "tokenizer", "is", "None", ":", "\n", "            ", "self", ".", "args", ".", "tokenizer", "=", "self", ".", "args", ".", "backbone", "\n", "\n", "", "if", "not", "self", ".", "verbose", ":", "\n", "            ", "set_global_logging_level", "(", "logging", ".", "ERROR", ",", "[", "\"transformers\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_config": [[57, 93], ["config_class.from_pretrained"], "methods", ["None"], ["", "", "def", "create_config", "(", "self", ")", ":", "\n", "        ", "from", "transformers", "import", "T5Config", "\n", "\n", "if", "'t5'", "in", "self", ".", "args", ".", "backbone", ":", "\n", "            ", "config_class", "=", "T5Config", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n", "", "config", "=", "config_class", ".", "from_pretrained", "(", "self", ".", "args", ".", "backbone", ")", "\n", "\n", "args", "=", "self", ".", "args", "\n", "\n", "config", ".", "feat_dim", "=", "args", ".", "feat_dim", "\n", "config", ".", "pos_dim", "=", "args", ".", "pos_dim", "\n", "config", ".", "n_images", "=", "2", "\n", "\n", "config", ".", "use_vis_order_embedding", "=", "args", ".", "use_vis_order_embedding", "\n", "\n", "config", ".", "dropout_rate", "=", "args", ".", "dropout", "\n", "config", ".", "dropout", "=", "args", ".", "dropout", "\n", "config", ".", "attention_dropout", "=", "args", ".", "dropout", "\n", "config", ".", "activation_dropout", "=", "args", ".", "dropout", "\n", "\n", "config", ".", "use_vis_layer_norm", "=", "args", ".", "use_vis_layer_norm", "\n", "config", ".", "individual_vis_layer_norm", "=", "args", ".", "individual_vis_layer_norm", "\n", "config", ".", "losses", "=", "args", ".", "losses", "\n", "\n", "config", ".", "share_vis_lang_layer_norm", "=", "args", ".", "share_vis_lang_layer_norm", "\n", "config", ".", "classifier", "=", "args", ".", "classifier", "\n", "\n", "config", ".", "pretrained", "=", "args", ".", "pretrained", "\n", "config", ".", "arch", "=", "args", ".", "arch", "\n", "config", ".", "resnet_dim", "=", "args", ".", "resnet_dim", "\n", "config", ".", "two_prefix", "=", "args", ".", "two_prefix", "\n", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_model": [[95, 106], ["print", "model_class.from_pretrained"], "methods", ["None"], ["", "def", "create_model", "(", "self", ",", "model_class", ",", "config", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "print", "(", "f'Building Model at GPU {self.args.gpu}'", ")", "\n", "\n", "model_name", "=", "self", ".", "args", ".", "backbone", "\n", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "\n", "model_name", ",", "\n", "config", "=", "config", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_tokenizer": [[107, 127], ["tokenizer_class.from_pretrained"], "methods", ["None"], ["", "def", "create_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "from", "transformers", "import", "T5TokenizerFast", "\n", "from", "tokenization", "import", "FewVLMTokenizerFast", "\n", "\n", "if", "'t5'", "in", "self", ".", "args", ".", "tokenizer", ":", "\n", "            ", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "                ", "tokenizer_class", "=", "FewVLMTokenizerFast", "\n", "", "else", ":", "\n", "                ", "tokenizer_class", "=", "T5TokenizerFast", "\n", "\n", "", "", "tokenizer_name", "=", "self", ".", "args", ".", "backbone", "\n", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "tokenizer_name", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_text_length", ",", "\n", "do_lower_case", "=", "self", ".", "args", ".", "do_lower_case", ",", "\n", "**", "kwargs", "\n", ")", "\n", "\n", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_optimizer_and_scheduler": [[128, 187], ["print", "len", "int", "list", "AdamW", "get_linear_schedule_with_warmup", "trainer_base.TrainerBase.args.optimizer", "print", "print", "print", "print", "filter", "list", "trainer_base.TrainerBase.model.named_parameters", "any", "trainer_base.TrainerBase.model.parameters", "any"], "methods", ["None"], ["", "def", "create_optimizer_and_scheduler", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "'Building Optimizer'", ")", "\n", "\n", "", "lr_scheduler", "=", "None", "\n", "\n", "if", "'adamw'", "in", "self", ".", "args", ".", "optim", ":", "\n", "            ", "from", "transformers", ".", "optimization", "import", "AdamW", ",", "get_linear_schedule_with_warmup", "\n", "batch_per_epoch", "=", "len", "(", "self", ".", "train_loader", ")", "\n", "t_total", "=", "batch_per_epoch", "//", "self", ".", "args", ".", "gradient_accumulation_steps", "*", "self", ".", "args", ".", "epochs", "\n", "warmup_ratio", "=", "self", ".", "args", ".", "warmup_ratio", "\n", "warmup_iters", "=", "int", "(", "t_total", "*", "warmup_ratio", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "\"Batch per epoch: %d\"", "%", "batch_per_epoch", ")", "\n", "print", "(", "\"Total Iters: %d\"", "%", "t_total", ")", "\n", "print", "(", "'Warmup ratio:'", ",", "warmup_ratio", ")", "\n", "print", "(", "\"Warm up Iters: %d\"", "%", "warmup_iters", ")", "\n", "\n", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "params", "=", "list", "(", "filter", "(", "lambda", "p", ":", "p", "[", "1", "]", ".", "requires_grad", ",", "self", ".", "model", ".", "named_parameters", "(", ")", ")", ")", "\n", "param_1", "=", "[", "p", "for", "n", ",", "p", "in", "params", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", "\n", "\n", "param_2", "=", "[", "p", "for", "n", ",", "p", "in", "params", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", "\n", "# grad_para_2 = filter(lambda p: p.requires_grad, param_2)", "\n", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "param_1", ",", "\n", "\"weight_decay\"", ":", "self", ".", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "param_2", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "\n", "# no_decay = [\"bias\", \"LayerNorm.weight\"]", "\n", "# optimizer_grouped_parameters = [", "\n", "#     {", "\n", "#         \"params\": [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],", "\n", "#         \"weight_decay\": self.args.weight_decay,", "\n", "#     },", "\n", "#     {", "\n", "#         \"params\": [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],", "\n", "#         \"weight_decay\": 0.0,", "\n", "#     },", "\n", "# ]", "\n", "\n", "optim", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "self", ".", "args", ".", "lr", ",", "eps", "=", "self", ".", "args", ".", "adam_eps", ")", "\n", "lr_scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optim", ",", "warmup_iters", ",", "t_total", ")", "\n", "\n", "", "else", ":", "\n", "            ", "optim", "=", "self", ".", "args", ".", "optimizer", "(", "\n", "list", "(", "self", ".", "model", ".", "parameters", "(", ")", ")", ",", "self", ".", "args", ".", "lr", ")", "\n", "\n", "", "return", "optim", ",", "lr_scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load_checkpoint": [[188, 205], ["utils.load_state_dict", "list", "trainer_base.TrainerBase.model.load_state_dict", "utils.load_state_dict.keys", "key.startswith", "key.startswith", "print", "pprint.pprint.pprint", "utils.load_state_dict.pop", "utils.load_state_dict.pop", "len", "len"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.load_state_dict", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.load_state_dict"], ["", "def", "load_checkpoint", "(", "self", ",", "ckpt_path", ")", ":", "\n", "        ", "state_dict", "=", "load_state_dict", "(", "ckpt_path", ",", "'cpu'", ")", "\n", "\n", "original_keys", "=", "list", "(", "state_dict", ".", "keys", "(", ")", ")", "\n", "for", "key", "in", "original_keys", ":", "\n", "            ", "if", "key", ".", "startswith", "(", "\"vis_encoder.\"", ")", ":", "\n", "                ", "new_key", "=", "'encoder.'", "+", "key", "[", "len", "(", "\"vis_encoder.\"", ")", ":", "]", "\n", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "key", ")", "\n", "\n", "", "if", "key", ".", "startswith", "(", "\"model.vis_encoder.\"", ")", ":", "\n", "                ", "new_key", "=", "'model.encoder.'", "+", "key", "[", "len", "(", "\"model.vis_encoder.\"", ")", ":", "]", "\n", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "key", ")", "\n", "\n", "", "", "results", "=", "self", ".", "model", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "False", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "'Model loaded from '", ",", "ckpt_path", ")", "\n", "pprint", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.init_weights": [[206, 221], ["trainer_base.TrainerBase.model.apply", "trainer_base.TrainerBase.model.init_weights", "isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.init_weights"], ["", "", "def", "init_weights", "(", "self", ")", ":", "\n", "\n", "        ", "def", "init_bert_weights", "(", "module", ")", ":", "\n", "            ", "\"\"\" Initialize the weights.\"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "                ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "1", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "self", ".", "model", ".", "apply", "(", "init_bert_weights", ")", "\n", "self", ".", "model", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.predict": [[222, 224], ["None"], "methods", ["None"], ["", "def", "predict", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.evaluate": [[225, 227], ["None"], "methods", ["None"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save": [[228, 232], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "os.path.isdir", "os.makedirs", "trainer_base.TrainerBase.model.state_dict", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save"], ["", "def", "save", "(", "self", ",", "name", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "args", ".", "output", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "args", ".", "output", ",", "exist_ok", "=", "True", ")", "\n", "", "torch", ".", "save", "(", "self", ".", "model", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output", ",", "\"%s.pth\"", "%", "name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load": [[233, 252], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "list", "trainer_base.TrainerBase.model.load_state_dict", "hasattr", "torch.load.keys", "torch.load.keys", "torch.load.keys", "torch.load.keys", "torch.load.keys", "key.startswith", "key.startswith", "print", "pprint.pprint.pprint", "torch.load.pop", "torch.load.pop", "torch.load.pop", "torch.load.pop", "torch.load.pop", "torch.load.pop", "torch.load.pop", "torch.load.pop", "torch.load.pop", "torch.load.pop", "len", "len"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.load_state_dict"], ["", "def", "load", "(", "self", ",", "path", ",", "loc", "=", "None", ")", ":", "\n", "        ", "if", "loc", "is", "None", "and", "hasattr", "(", "self", ".", "args", ",", "'gpu'", ")", ":", "\n", "            ", "loc", "=", "f'cuda:{self.args.gpu}'", "\n", "", "state_dict", "=", "torch", ".", "load", "(", "\"%s.pth\"", "%", "path", ",", "map_location", "=", "loc", ")", "\n", "\n", "original_keys", "=", "list", "(", "state_dict", ".", "keys", "(", ")", ")", "\n", "for", "key", "in", "original_keys", ":", "\n", "            ", "if", "key", ".", "startswith", "(", "\"module.vis_encoder.\"", ")", ":", "\n", "                ", "new_key", "=", "'module.encoder.'", "+", "key", "[", "len", "(", "\"module.vis_encoder.\"", ")", ":", "]", "\n", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "key", ")", "\n", "\n", "", "if", "key", ".", "startswith", "(", "\"module.model.vis_encoder.\"", ")", ":", "\n", "                ", "new_key", "=", "'module.model.encoder.'", "+", "key", "[", "len", "(", "\"module.model.vis_encoder.\"", ")", ":", "]", "\n", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "key", ")", "\n", "\n", "", "", "results", "=", "self", ".", "model", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "False", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "'Model loaded from '", ",", "path", ")", "\n", "pprint", "(", "results", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.modeling_t5.VisualEmbedding.__init__": [[26, 75], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "feat_embedding.append", "torch.Linear", "torch.Linear", "absolute_vis_pos_embedding.append", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Embedding", "torch.Embedding", "transformers.models.t5.modeling_t5.T5LayerNorm", "transformers.models.t5.modeling_t5.T5LayerNorm", "transformers.models.t5.modeling_t5.T5LayerNorm"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "obj_order_embedding", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "feat_dim", "=", "config", ".", "feat_dim", "\n", "pos_dim", "=", "config", ".", "pos_dim", "\n", "# n_objs = config.n_objs", "\n", "n_images", "=", "config", ".", "n_images", "\n", "\n", "if", "self", ".", "config", ".", "individual_vis_layer_norm", ":", "\n", "\n", "# Object feature encoding", "\n", "            ", "feat_embedding", "=", "[", "nn", ".", "Linear", "(", "feat_dim", ",", "config", ".", "d_model", ")", "]", "\n", "if", "self", ".", "config", ".", "use_vis_layer_norm", ":", "\n", "                ", "feat_embedding", ".", "append", "(", "T5LayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", ")", "\n", "", "self", ".", "feat_embedding", "=", "nn", ".", "Sequential", "(", "*", "feat_embedding", ")", "\n", "\n", "# self.relative_vis_pos_embedding = nn.Linear(pos_dim + 1, config.num_heads)", "\n", "absolute_vis_pos_embedding", "=", "[", "nn", ".", "Linear", "(", "pos_dim", "+", "1", ",", "config", ".", "d_model", ")", "]", "\n", "if", "self", ".", "config", ".", "use_vis_layer_norm", ":", "\n", "                ", "absolute_vis_pos_embedding", ".", "append", "(", "T5LayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", ")", "\n", "", "self", ".", "absolute_vis_pos_embedding", "=", "nn", ".", "Sequential", "(", "*", "absolute_vis_pos_embedding", ")", "\n", "# self.absolute_vis_pos_layer_norm = T5LayerNorm(config.d_model, eps=config.layer_norm_epsilon)", "\n", "\n", "if", "self", ".", "config", ".", "use_vis_order_embedding", ":", "\n", "# self.obj_order_embedding = nn.Embedding(n_objs, config.d_model)", "\n", "                ", "self", ".", "obj_order_embedding", "=", "obj_order_embedding", "\n", "self", ".", "img_order_embedding", "=", "nn", ".", "Embedding", "(", "n_images", ",", "config", ".", "d_model", ")", "\n", "\n", "", "", "else", ":", "\n", "# Object feature encoding", "\n", "            ", "feat_embedding", "=", "[", "nn", ".", "Linear", "(", "feat_dim", ",", "config", ".", "d_model", ")", "]", "\n", "# if self.config.use_vis_layer_norm:", "\n", "#     feat_embedding.append(T5LayerNorm(config.d_model, eps=config.layer_norm_epsilon))", "\n", "self", ".", "feat_embedding", "=", "nn", ".", "Sequential", "(", "*", "feat_embedding", ")", "\n", "\n", "# self.relative_vis_pos_embedding = nn.Linear(pos_dim + 1, config.num_heads)", "\n", "absolute_vis_pos_embedding", "=", "[", "nn", ".", "Linear", "(", "pos_dim", "+", "1", ",", "config", ".", "d_model", ")", "]", "\n", "# if self.config.use_vis_layer_norm:", "\n", "#     absolute_vis_pos_embedding.append(T5LayerNorm(config.d_model, eps=config.layer_norm_epsilon))", "\n", "self", ".", "absolute_vis_pos_embedding", "=", "nn", ".", "Sequential", "(", "*", "absolute_vis_pos_embedding", ")", "\n", "# self.absolute_vis_pos_layer_norm = T5LayerNorm(config.d_model, eps=config.layer_norm_epsilon)", "\n", "\n", "if", "self", ".", "config", ".", "use_vis_order_embedding", ":", "\n", "# self.obj_order_embedding = nn.Embedding(n_objs, config.d_model)", "\n", "                ", "self", ".", "obj_order_embedding", "=", "obj_order_embedding", "\n", "self", ".", "img_order_embedding", "=", "nn", ".", "Embedding", "(", "n_images", ",", "config", ".", "d_model", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "use_vis_layer_norm", ":", "\n", "                ", "self", ".", "layer_norm", "=", "T5LayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.modeling_t5.VisualEmbedding.get_area": [[76, 89], ["None"], "methods", ["None"], ["", "", "", "def", "get_area", "(", "self", ",", "pos", ")", ":", "\n", "        ", "\"\"\"\n        Args\n            pos: [B, N, 4]\n                (x1, x2, y1, y2)\n        Return\n            area : [B, N]\n        \"\"\"", "\n", "# [B, N]", "\n", "height", "=", "pos", "[", ":", ",", ":", ",", "3", "]", "-", "pos", "[", ":", ",", ":", ",", "2", "]", "\n", "width", "=", "pos", "[", ":", ",", ":", ",", "1", "]", "-", "pos", "[", ":", ",", ":", ",", "0", "]", "\n", "area", "=", "height", "*", "width", "\n", "return", "area", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.modeling_t5.VisualEmbedding.forward": [[91, 142], ["feats.size", "modeling_t5.VisualEmbedding.feat_embedding", "modeling_t5.VisualEmbedding.get_area().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_t5.VisualEmbedding.absolute_vis_pos_embedding", "torch.cat.size", "torch.cat.size", "modeling_t5.VisualEmbedding.img_order_embedding", "modeling_t5.VisualEmbedding.obj_order_embedding", "modeling_t5.VisualEmbedding.get_area", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "img_order_ids.unsqueeze.unsqueeze.unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "obj_order_ids.unsqueeze.unsqueeze.unsqueeze", "modeling_t5.VisualEmbedding.layer_norm"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.get_area"], ["", "def", "forward", "(", "self", ",", "feats", ",", "pos", ",", "img_order_ids", "=", "None", ",", "obj_order_ids", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args\n            feats: [B, N, feat_dim]\n            pos: [B, N, 4]\n                (x1, x2, y1, y2)\n        Return\n            relative_vis_pos_embedding: [B, N, N, n_heads]\n            absolute_vis_pos_embedding: # [B, N, d_model]\n        \"\"\"", "\n", "\n", "B", ",", "N", ",", "_", "=", "feats", ".", "size", "(", ")", "\n", "assert", "pos", ".", "size", "(", ")", "==", "(", "B", ",", "N", ",", "4", ")", "\n", "\n", "feat_embedding", "=", "self", ".", "feat_embedding", "(", "feats", ")", "\n", "\n", "device", "=", "feats", ".", "device", "\n", "dtype", "=", "feats", ".", "dtype", "\n", "\n", "area", "=", "self", ".", "get_area", "(", "pos", ")", ".", "unsqueeze", "(", "2", ")", "# [B, N, 1]", "\n", "pos", "=", "torch", ".", "cat", "(", "[", "pos", ",", "area", "]", ",", "dim", "=", "2", ")", "# [B, N, 5]", "\n", "\n", "# [B, N, d_model]", "\n", "absolute_vis_pos_embedding", "=", "self", ".", "absolute_vis_pos_embedding", "(", "pos", ")", "\n", "# absolute_vis_pos_embedding = self.absolute_vis_pos_layer_norm(absolute_vis_pos_embedding)", "\n", "\n", "\n", "if", "self", ".", "config", ".", "use_vis_order_embedding", ":", "\n", "            ", "if", "img_order_ids", "is", "None", ":", "\n", "                ", "img_order_ids", "=", "torch", ".", "zeros", "(", "N", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "img_order_ids", "=", "img_order_ids", ".", "unsqueeze", "(", "0", ")", "#.expand(B, -1)", "\n", "", "img_order_embedding", "=", "self", ".", "img_order_embedding", "(", "img_order_ids", ")", "\n", "\n", "if", "obj_order_ids", "is", "None", ":", "\n", "                ", "obj_order_ids", "=", "torch", ".", "arange", "(", "N", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "obj_order_ids", "=", "obj_order_ids", ".", "unsqueeze", "(", "0", ")", "#.expand(B,-1)", "\n", "# assert obj_order_ids.max().item() < 32200, obj_order_ids", "\n", "", "obj_order_ids", "=", "self", ".", "obj_order_embedding", ".", "num_embeddings", "-", "obj_order_ids", "-", "1", "\n", "obj_order_embedding", "=", "self", ".", "obj_order_embedding", "(", "obj_order_ids", ")", "\n", "\n", "vis_embedding", "=", "feat_embedding", "+", "absolute_vis_pos_embedding", "+", "img_order_embedding", "+", "obj_order_embedding", "\n", "\n", "", "else", ":", "\n", "            ", "vis_embedding", "=", "feat_embedding", "+", "absolute_vis_pos_embedding", "\n", "\n", "", "if", "not", "self", ".", "config", ".", "individual_vis_layer_norm", ":", "\n", "            ", "if", "self", ".", "config", ".", "use_vis_layer_norm", ":", "\n", "                ", "vis_embedding", "=", "self", ".", "layer_norm", "(", "vis_embedding", ")", "\n", "\n", "", "", "return", "vis_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.modeling_t5.JointEncoder.__init__": [[145, 166], ["transformers.models.t5.modeling_t5.T5Stack.__init__", "modeling_t5.VisualEmbedding", "torch.ModuleList", "torch.ModuleList", "transformers.models.t5.modeling_t5.T5LayerNorm", "torch.Dropout", "torch.Dropout", "modeling_t5.JointEncoder.init_weights", "transformers.models.t5.modeling_t5.T5Block", "range"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "embed_tokens", "=", "None", ")", ":", "\n", "        ", "super", "(", "T5Stack", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "self", ".", "is_decoder", "=", "self", ".", "config", ".", "is_decoder", "\n", "assert", "self", ".", "config", ".", "is_decoder", "is", "False", "\n", "\n", "self", ".", "visual_embedding", "=", "VisualEmbedding", "(", "self", ".", "config", ",", "embed_tokens", ")", "\n", "\n", "self", ".", "block", "=", "nn", ".", "ModuleList", "(", "\n", "[", "T5Block", "(", "config", ",", "has_relative_attention_bias", "=", "(", "i", "==", "0", ")", ")", "\n", "for", "i", "in", "range", "(", "config", ".", "num_layers", ")", "]", "\n", ")", "\n", "self", ".", "final_layer_norm", "=", "T5LayerNorm", "(", "\n", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "model_parallel", "=", "False", "\n", "self", ".", "device_map", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.modeling_t5.JointEncoder.set_input_embeddings": [[167, 170], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "embed_tokens", "=", "new_embeddings", "\n", "self", ".", "visual_embedding", ".", "obj_order_embedding", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.modeling_t5.JointEncoder.forward": [[171, 328], ["modeling_t5.JointEncoder.visual_embedding", "modeling_t5.JointEncoder.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_t5.JointEncoder.get_extended_attention_mask", "modeling_t5.JointEncoder.get_head_mask", "modeling_t5.JointEncoder.dropout", "modeling_t5.JointEncoder.final_layer_norm", "modeling_t5.JointEncoder.dropout", "transformers.modeling_outputs.BaseModelOutputWithPastAndCrossAttentions", "modeling_t5.JointEncoder.embed_tokens", "modeling_t5.JointEncoder.size", "len", "len", "input_ids.ne().to", "input_ids.ne().to.new_ones", "modeling_t5.JointEncoder.block[].layer[].SelfAttention.compute_bias", "modeling_t5.JointEncoder.size", "modeling_t5.JointEncoder.new_zeros", "enumerate", "tuple", "len", "zip", "layer_module", "input_ids.ne"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "\n", "vis_inputs", "=", "None", ",", "\n", "vis_attention_mask", "=", "None", ",", "\n", "\n", "inputs_embeds", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "assert", "self", ".", "embed_tokens", "is", "not", "None", ",", "\"You have to initialize the model with valid token embeddings\"", "\n", "inputs_embeds", "=", "self", ".", "embed_tokens", "(", "input_ids", ")", "\n", "\n", "", "B", ",", "L", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "\n", "vis_feats", "=", "vis_inputs", "[", "0", "]", "\n", "boxes", "=", "vis_inputs", "[", "1", "]", "\n", "img_order_ids", "=", "None", "\n", "obj_order_ids", "=", "None", "\n", "if", "len", "(", "vis_inputs", ")", ">=", "3", ":", "\n", "            ", "img_order_ids", "=", "vis_inputs", "[", "2", "]", "\n", "", "if", "len", "(", "vis_inputs", ")", "==", "4", ":", "\n", "            ", "obj_order_ids", "=", "vis_inputs", "[", "3", "]", "\n", "\n", "", "vis_embeds", "=", "self", ".", "visual_embedding", "(", "\n", "vis_feats", ",", "boxes", ",", "img_order_ids", ",", "obj_order_ids", ")", "\n", "\n", "V_L", "=", "vis_embeds", ".", "size", "(", "1", ")", "\n", "\n", "inputs_embeds", "=", "torch", ".", "cat", "(", "[", "inputs_embeds", ",", "vis_embeds", "]", ",", "dim", "=", "1", ")", "\n", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "input_ids", ".", "ne", "(", "self", ".", "config", ".", "pad_token_id", ")", ".", "to", "(", "dtype", "=", "inputs_embeds", ".", "dtype", ",", "device", "=", "inputs_embeds", ".", "device", ")", "\n", "\n", "", "if", "vis_attention_mask", "is", "None", ":", "\n", "            ", "vis_attention_mask", "=", "attention_mask", ".", "new_ones", "(", "B", ",", "V_L", ")", "\n", "\n", "", "attention_mask", "=", "torch", ".", "cat", "(", "[", "attention_mask", ",", "vis_attention_mask", "]", ",", "dim", "=", "1", ")", "\n", "\n", "# ourselves in which case we just need to make it broadcastable to all heads.", "\n", "extended_attention_mask", "=", "self", ".", "get_extended_attention_mask", "(", "\n", "attention_mask", ",", "\n", "(", "B", ",", "L", "+", "V_L", ")", ",", "\n", "inputs_embeds", ".", "device", ")", "\n", "\n", "# initialize past_key_values with `None` if past does not exist", "\n", "if", "past_key_values", "is", "None", ":", "\n", "            ", "past_key_values", "=", "[", "None", "]", "*", "len", "(", "self", ".", "block", ")", "\n", "\n", "# Prepare head mask if needed", "\n", "", "head_mask", "=", "self", ".", "get_head_mask", "(", "head_mask", ",", "self", ".", "config", ".", "num_layers", ")", "\n", "present_key_value_states", "=", "(", ")", "if", "use_cache", "else", "None", "\n", "all_hidden_states", "=", "(", ")", "if", "output_hidden_states", "else", "None", "\n", "all_attentions", "=", "(", ")", "if", "output_attentions", "else", "None", "\n", "all_cross_attentions", "=", "(", ")", "if", "(", "output_attentions", "and", "self", ".", "is_decoder", ")", "else", "None", "\n", "# position_bias = None", "\n", "# encoder_decoder_position_bias = None", "\n", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "inputs_embeds", ")", "\n", "\n", "if", "self", ".", "config", ".", "num_layers", ">", "0", ":", "\n", "\n", "            ", "assert", "self", ".", "block", "[", "0", "]", ".", "layer", "[", "0", "]", ".", "SelfAttention", ".", "has_relative_attention_bias", "\n", "\n", "seq_length", "=", "L", "+", "V_L", "\n", "q_len", "=", "seq_length", "\n", "k_len", "=", "seq_length", "\n", "\n", "# [1, n_heads, Q_len, K_len]", "\n", "text_position_bias", "=", "self", ".", "block", "[", "0", "]", ".", "layer", "[", "0", "]", ".", "SelfAttention", ".", "compute_bias", "(", "\n", "L", ",", "L", ")", "\n", "num_heads", "=", "text_position_bias", ".", "size", "(", "1", ")", "\n", "position_bias", "=", "text_position_bias", ".", "new_zeros", "(", "\n", "1", ",", "num_heads", ",", "seq_length", ",", "seq_length", ")", "\n", "position_bias", "[", ":", ",", ":", ",", ":", "L", ",", ":", "L", "]", "=", "text_position_bias", "\n", "\n", "# print('position_bias size', position_bias.size())", "\n", "# print('attention_mask size', attention_mask.size())", "\n", "# print('extended_attention_mask size', extended_attention_mask.size())", "\n", "# relative position bias only between Text <-> Text", "\n", "# no relative position bias Text -> Vision", "\n", "# no relative position bias Vision -> Text", "\n", "# no relative position bias Vision <-> Vision", "\n", "# position_bias[:, :, L:, :] = 0", "\n", "# position_bias[:, :, :, L:] = 0", "\n", "position_bias", "=", "position_bias", "+", "extended_attention_mask", "\n", "\n", "for", "i", ",", "(", "layer_module", ",", "past_key_value", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "block", ",", "past_key_values", ")", ")", ":", "\n", "\n", "# if output_hidden_states:", "\n", "#     all_hidden_states = all_hidden_states + (hidden_states,)", "\n", "\n", "                ", "layer_outputs", "=", "layer_module", "(", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "position_bias", "=", "position_bias", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "encoder_decoder_position_bias", "=", "None", ",", "\n", "head_mask", "=", "head_mask", "[", "i", "]", ",", "\n", "past_key_value", "=", "past_key_value", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "# layer_outputs is a tuple with:", "\n", "# hidden-states, key-value-states, (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)", "\n", "hidden_states", ",", "present_key_value_state", "=", "layer_outputs", "[", ":", "2", "]", "\n", "\n", "# We share the position biases between the layers - the first layer store them", "\n", "# layer_outputs = hidden-states, key-value-states (self-attention weights),", "\n", "# (self-attention position bias), (cross-attention weights), (cross-attention position bias)", "\n", "position_bias", "=", "layer_outputs", "[", "2", "]", "\n", "\n", "# append next layer key value states", "\n", "if", "use_cache", ":", "\n", "                    ", "present_key_value_states", "=", "present_key_value_states", "+", "(", "present_key_value_state", ",", ")", "\n", "\n", "# if output_attentions:", "\n", "#     all_attentions = all_attentions + (layer_outputs[3],)", "\n", "#     if self.is_decoder:", "\n", "#         all_cross_attentions = all_cross_attentions + \\", "\n", "#             (layer_outputs[5],)", "\n", "\n", "", "", "", "hidden_states", "=", "self", ".", "final_layer_norm", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "\n", "# Add last layer", "\n", "if", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "return", "tuple", "(", "\n", "v", "\n", "for", "v", "in", "[", "\n", "hidden_states", ",", "\n", "present_key_value_states", ",", "\n", "all_hidden_states", ",", "\n", "all_attentions", ",", "\n", "all_cross_attentions", ",", "\n", "]", "\n", "if", "v", "is", "not", "None", "\n", ")", "\n", "", "return", "BaseModelOutputWithPastAndCrossAttentions", "(", "\n", "last_hidden_state", "=", "hidden_states", ",", "\n", "past_key_values", "=", "present_key_value_states", ",", "\n", "hidden_states", "=", "all_hidden_states", ",", "\n", "attentions", "=", "all_attentions", ",", "\n", "cross_attentions", "=", "all_cross_attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.modeling_t5.FewVLM.__init__": [[341, 373], ["transformers.models.t5.modeling_t5.T5ForConditionalGeneration.__init__", "torch.Embedding", "torch.Embedding", "copy.deepcopy", "modeling_t5.JointEncoder", "copy.deepcopy", "transformers.models.t5.modeling_t5.T5Stack", "torch.Linear", "torch.Linear", "modeling_t5.FewVLM.init_weights"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "T5ForConditionalGeneration", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "model_dim", "=", "config", ".", "d_model", "\n", "\n", "self", ".", "shared", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "d_model", ")", "\n", "\n", "encoder_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "encoder_config", ".", "is_decoder", "=", "False", "\n", "encoder_config", ".", "use_cache", "=", "False", "\n", "encoder_config", ".", "is_encoder_decoder", "=", "False", "\n", "\n", "#---- Modified ----#", "\n", "# self.encoder = T5Stack(encoder_config, self.shared)", "\n", "self", ".", "encoder", "=", "JointEncoder", "(", "encoder_config", ",", "self", ".", "shared", ")", "\n", "#------------------#", "\n", "\n", "decoder_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "decoder_config", ".", "is_decoder", "=", "True", "\n", "decoder_config", ".", "is_encoder_decoder", "=", "False", "\n", "\n", "self", ".", "decoder", "=", "T5Stack", "(", "decoder_config", ",", "self", ".", "shared", ")", "\n", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n", "# Model parallel", "\n", "self", ".", "model_parallel", "=", "False", "\n", "self", ".", "device_map", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.modeling_t5.FewVLM.set_input_embeddings": [[374, 378], ["modeling_t5.FewVLM.encoder.set_input_embeddings", "modeling_t5.FewVLM.decoder.set_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.modeling_t5.FewVLM.set_input_embeddings", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.modeling_t5.FewVLM.set_input_embeddings"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "shared", "=", "new_embeddings", "\n", "self", ".", "encoder", ".", "set_input_embeddings", "(", "new_embeddings", ")", "\n", "self", ".", "decoder", ".", "set_input_embeddings", "(", "new_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.modeling_t5.FewVLM.extend_vocab": [[379, 404], ["torch.Embedding", "torch.Embedding", "modeling_t5.FewVLM.shared.weight.data.detach().clone", "modeling_t5.FewVLM.size", "torch.Linear", "torch.Linear", "modeling_t5.FewVLM.lm_head.weight.data.detach().clone", "modeling_t5.FewVLM.size", "modeling_t5.FewVLM.shared.weight.data.detach", "modeling_t5.FewVLM.lm_head.weight.data.detach"], "methods", ["None"], ["", "def", "extend_vocab", "(", "self", ",", "vocab_size", ")", ":", "\n", "\n", "        ", "new_shared", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "self", ".", "config", ".", "d_model", ")", "\n", "old_weight", "=", "self", ".", "shared", ".", "weight", ".", "data", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "old_vocab_size", "=", "old_weight", ".", "size", "(", "0", ")", "\n", "new_shared", ".", "weight", ".", "data", "[", ":", "old_vocab_size", ",", ":", "]", "=", "old_weight", "\n", "self", ".", "shared", "=", "new_shared", "\n", "\n", "new_lm_head", "=", "nn", ".", "Linear", "(", "self", ".", "config", ".", "d_model", ",", "vocab_size", ",", "bias", "=", "False", ")", "\n", "old_weight", "=", "self", ".", "lm_head", ".", "weight", ".", "data", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "old_vocab_size", "=", "old_weight", ".", "size", "(", "0", ")", "\n", "new_lm_head", ".", "weight", ".", "data", "[", ":", "old_vocab_size", ",", ":", "]", "=", "old_weight", "\n", "self", ".", "lm_head", "=", "new_lm_head", "\n", "\n", "self", ".", "vis_encoder", ".", "visual_embedding", ".", "obj_order_embedding", "=", "self", ".", "shared", "\n", "\n", "self", ".", "encoder", ".", "embed_tokens", "=", "self", ".", "shared", "\n", "self", ".", "decoder", ".", "embed_tokens", "=", "self", ".", "shared", "\n", "\n", "self", ".", "lm_head", ".", "weight", "=", "self", ".", "shared", ".", "weight", "\n", "\n", "self", ".", "config", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "encoder", ".", "config", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "vis_encoder", ".", "config", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "decoder", ".", "config", ".", "vocab_size", "=", "vocab_size", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.modeling_t5.FewVLM.forward": [[408, 546], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_t5.FewVLM.decoder", "modeling_t5.FewVLM.lm_head", "modeling_t5.VLSeq2SeqLMOutput", "modeling_t5.FewVLM.encoder", "modeling_t5.FewVLM._shift_right", "input_ids.ne().to", "input_ids.ne().to.size", "input_ids.ne().to.new_ones", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "transformers.modeling_outputs.BaseModelOutput", "encoder_outputs[].size", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "modeling_t5.FewVLM.view", "labels.view", "isinstance", "input_ids.ne", "modeling_t5.FewVLM.size", "len", "len"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "\n", "\n", "vis_inputs", "=", "None", ",", "\n", "vis_attention_mask", "=", "None", ",", "\n", "\n", "decoder_input_ids", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "decoder_inputs_embeds", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "reduce_loss", "=", "False", ",", "\n", "\n", "return_hidden_state", "=", "False", ",", "\n", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "\n", "        ", "use_cache", "=", "use_cache", "if", "use_cache", "is", "not", "None", "else", "self", ".", "config", ".", "use_cache", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "if", "encoder_outputs", "is", "None", ":", "\n", "\n", "            ", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "\n", "vis_inputs", "=", "vis_inputs", ",", "\n", "vis_attention_mask", "=", "vis_attention_mask", ",", "\n", "\n", "head_mask", "=", "head_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "", "elif", "return_dict", "and", "not", "isinstance", "(", "encoder_outputs", ",", "BaseModelOutput", ")", ":", "\n", "            ", "encoder_outputs", "=", "BaseModelOutput", "(", "\n", "last_hidden_state", "=", "encoder_outputs", "[", "0", "]", ",", "\n", "hidden_states", "=", "encoder_outputs", "[", "1", "]", "if", "len", "(", "\n", "encoder_outputs", ")", ">", "1", "else", "None", ",", "\n", "attentions", "=", "encoder_outputs", "[", "2", "]", "if", "len", "(", "\n", "encoder_outputs", ")", ">", "2", "else", "None", ",", "\n", ")", "\n", "\n", "", "hidden_states", "=", "encoder_outputs", "[", "0", "]", "\n", "\n", "if", "labels", "is", "not", "None", "and", "decoder_input_ids", "is", "None", "and", "decoder_inputs_embeds", "is", "None", ":", "\n", "# get decoder inputs from shifting lm labels to the right", "\n", "            ", "decoder_input_ids", "=", "self", ".", "_shift_right", "(", "labels", ")", "\n", "\n", "# If decoding with past key value states, only the last tokens", "\n", "# should be given as an input", "\n", "", "if", "past_key_values", "is", "not", "None", ":", "\n", "            ", "assert", "labels", "is", "None", ",", "\"Decoder should not use cached key value states when training.\"", "\n", "if", "decoder_input_ids", "is", "not", "None", ":", "\n", "                ", "decoder_input_ids", "=", "decoder_input_ids", "[", ":", ",", "-", "1", ":", "]", "\n", "", "if", "decoder_inputs_embeds", "is", "not", "None", ":", "\n", "                ", "decoder_inputs_embeds", "=", "decoder_inputs_embeds", "[", ":", ",", "-", "1", ":", "]", "\n", "\n", "", "", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "input_ids", ".", "ne", "(", "self", ".", "config", ".", "pad_token_id", ")", ".", "to", "(", "dtype", "=", "hidden_states", ".", "dtype", ",", "device", "=", "hidden_states", ".", "device", ")", "\n", "", "if", "vis_attention_mask", "is", "None", ":", "\n", "            ", "B", ",", "L", "=", "attention_mask", ".", "size", "(", ")", "\n", "V_L", "=", "encoder_outputs", "[", "0", "]", ".", "size", "(", "1", ")", "-", "L", "\n", "vis_attention_mask", "=", "attention_mask", ".", "new_ones", "(", "B", ",", "V_L", ")", "\n", "", "encoder_attention_mask", "=", "torch", ".", "cat", "(", "[", "attention_mask", ",", "vis_attention_mask", "]", ",", "dim", "=", "1", ")", "\n", "\n", "# Decode", "\n", "decoder_outputs", "=", "self", ".", "decoder", "(", "\n", "input_ids", "=", "decoder_input_ids", ",", "\n", "attention_mask", "=", "decoder_attention_mask", ",", "\n", "inputs_embeds", "=", "decoder_inputs_embeds", ",", "\n", "past_key_values", "=", "past_key_values", ",", "\n", "\n", "encoder_hidden_states", "=", "hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_attention_mask", ",", "\n", "\n", "head_mask", "=", "head_mask", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "# print('decoder_outputs')", "\n", "# print(decoder_outputs)", "\n", "\n", "sequence_output", "=", "decoder_outputs", "[", "0", "]", "\n", "\n", "assert", "self", ".", "config", ".", "tie_word_embeddings", "is", "True", "\n", "\n", "if", "self", ".", "config", ".", "tie_word_embeddings", ":", "\n", "# Rescale output before projecting on vocab", "\n", "# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586", "\n", "            ", "sequence_output", "=", "sequence_output", "*", "(", "self", ".", "model_dim", "**", "-", "0.5", ")", "\n", "\n", "", "if", "return_hidden_state", ":", "\n", "            ", "return", "sequence_output", "\n", "\n", "", "lm_logits", "=", "self", ".", "lm_head", "(", "sequence_output", ")", "\n", "\n", "loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# loss_fct = CrossEntropyLoss(ignore_index=-100)", "\n", "# loss = loss_fct(", "\n", "#     lm_logits.view(-1, lm_logits.size(-1)), labels.view(-1))", "\n", "# TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666", "\n", "\n", "            ", "if", "reduce_loss", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "100", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "100", ",", "reduction", "=", "'none'", ")", "\n", "", "loss", "=", "loss_fct", "(", "\n", "lm_logits", ".", "view", "(", "-", "1", ",", "lm_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "# print('loss')", "\n", "# print(loss)", "\n", "\n", "# if not return_dict:", "\n", "#     output = (lm_logits,) + decoder_outputs[1:] + encoder_outputs", "\n", "#     return ((loss,) + output) if loss is not None else output", "\n", "\n", "", "return", "VLSeq2SeqLMOutput", "(", "\n", "loss", "=", "loss", ",", "\n", "logits", "=", "lm_logits", ",", "\n", "past_key_values", "=", "decoder_outputs", ".", "past_key_values", ",", "\n", "decoder_last_hidden_state", "=", "decoder_outputs", ".", "last_hidden_state", ",", "\n", "decoder_hidden_states", "=", "decoder_outputs", ".", "hidden_states", ",", "\n", "# decoder_attentions=decoder_outputs.attentions,", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.modeling_t5.FewVLM.prepare_inputs_for_generation": [[556, 577], ["None"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "\n", "self", ",", "input_ids", ",", "past", "=", "None", ",", "attention_mask", "=", "None", ",", "use_cache", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "# cut decoder_input_ids if past is used", "\n", "        ", "if", "past", "is", "not", "None", ":", "\n", "            ", "input_ids", "=", "input_ids", "[", ":", ",", "-", "1", ":", "]", "\n", "\n", "", "output", "=", "{", "\n", "\"decoder_input_ids\"", ":", "input_ids", ",", "\n", "\"past_key_values\"", ":", "past", ",", "\n", "\"encoder_outputs\"", ":", "encoder_outputs", ",", "\n", "\"attention_mask\"", ":", "attention_mask", ",", "\n", "\"use_cache\"", ":", "use_cache", ",", "\n", "}", "\n", "\n", "if", "'vis_attention_mask'", "in", "kwargs", ":", "\n", "            ", "output", "[", "'vis_attention_mask'", "]", "=", "kwargs", "[", "'vis_attention_mask'", "]", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.modeling_t5.FewVLM._expand_inputs_for_generation": [[578, 614], ["torch.arange().view().repeat().view().to", "torch.arange().view().repeat().view().to", "torch.arange().view().repeat().view().to", "torch.arange().view().repeat().view().to", "input_ids.index_select.index_select.index_select", "token_type_ids.index_select", "attention_mask.index_select", "model_kwargs.get", "model_kwargs[].index_select", "encoder_outputs.last_hidden_state.index_select", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_expand_inputs_for_generation", "(", "\n", "input_ids", ":", "torch", ".", "LongTensor", ",", "\n", "expand_size", ":", "int", "=", "1", ",", "\n", "is_encoder_decoder", ":", "bool", "=", "False", ",", "\n", "attention_mask", ":", "torch", ".", "LongTensor", "=", "None", ",", "\n", "encoder_outputs", ":", "ModelOutput", "=", "None", ",", "\n", "**", "model_kwargs", "\n", ")", "->", "Tuple", "[", "torch", ".", "LongTensor", ",", "Dict", "[", "str", ",", "Any", "]", "]", ":", "\n", "        ", "expanded_return_idx", "=", "(", "\n", "torch", ".", "arange", "(", "input_ids", ".", "shape", "[", "0", "]", ")", ".", "view", "(", "-", "1", ",", "1", ")", ".", "repeat", "(", "1", ",", "\n", "expand_size", ")", ".", "view", "(", "-", "1", ")", ".", "to", "(", "input_ids", ".", "device", ")", "\n", ")", "\n", "input_ids", "=", "input_ids", ".", "index_select", "(", "0", ",", "expanded_return_idx", ")", "\n", "\n", "if", "\"token_type_ids\"", "in", "model_kwargs", ":", "\n", "            ", "token_type_ids", "=", "model_kwargs", "[", "\"token_type_ids\"", "]", "\n", "model_kwargs", "[", "\"token_type_ids\"", "]", "=", "token_type_ids", ".", "index_select", "(", "\n", "0", ",", "expanded_return_idx", ")", "\n", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "            ", "model_kwargs", "[", "\"attention_mask\"", "]", "=", "attention_mask", ".", "index_select", "(", "\n", "0", ",", "expanded_return_idx", ")", "\n", "\n", "", "if", "model_kwargs", ".", "get", "(", "\"vis_attention_mask\"", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "model_kwargs", "[", "'vis_attention_mask'", "]", "=", "model_kwargs", "[", "'vis_attention_mask'", "]", ".", "index_select", "(", "\n", "0", ",", "expanded_return_idx", ")", "\n", "\n", "", "if", "is_encoder_decoder", ":", "\n", "            ", "assert", "encoder_outputs", "is", "not", "None", "\n", "encoder_outputs", "[", "\"last_hidden_state\"", "]", "=", "encoder_outputs", ".", "last_hidden_state", ".", "index_select", "(", "\n", "0", ",", "expanded_return_idx", "\n", ")", "\n", "model_kwargs", "[", "\"encoder_outputs\"", "]", "=", "encoder_outputs", "\n", "\n", "", "return", "input_ids", ",", "model_kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_model.FewVLMPretraining.__init__": [[9, 13], ["modeling_t5.FewVLM.__init__", "pretrain_model.FewVLMPretraining.config.losses.split"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "losses", "=", "self", ".", "config", ".", "losses", ".", "split", "(", "','", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_model.FewVLMPretraining.train_step": [[14, 65], ["batch[].to", "batch[].to", "batch[].to", "batch[].to", "batch[].to", "pretrain_model.FewVLMPretraining.", "lm_mask.float.float.float", "batch[].to.size", "loss.detach().sum", "len", "zip", "next", "loss.view", "loss.sum", "lm_mask.float.float.sum().clamp", "loss.detach", "pretrain_model.FewVLMPretraining.parameters", "loss.detach", "lm_mask.float.float.sum"], "methods", ["None"], ["", "def", "train_step", "(", "self", ",", "batch", ")", ":", "\n", "\n", "        ", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "vis_feats", "=", "batch", "[", "'vis_feats'", "]", ".", "to", "(", "device", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", ".", "to", "(", "device", ")", "\n", "vis_pos", "=", "batch", "[", "'boxes'", "]", ".", "to", "(", "device", ")", "\n", "\n", "lm_labels", "=", "batch", "[", "\"target_ids\"", "]", ".", "to", "(", "device", ")", "\n", "\n", "loss_weights", "=", "batch", "[", "\"loss_weights\"", "]", ".", "to", "(", "device", ")", "\n", "\n", "output", "=", "self", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vis_inputs", "=", "(", "vis_feats", ",", "vis_pos", ")", ",", "\n", "labels", "=", "lm_labels", ",", "\n", "return_dict", "=", "True", "\n", ")", "\n", "assert", "'loss'", "in", "output", "\n", "\n", "lm_mask", "=", "lm_labels", "!=", "-", "100", "\n", "lm_mask", "=", "lm_mask", ".", "float", "(", ")", "\n", "B", ",", "L", "=", "lm_labels", ".", "size", "(", ")", "\n", "\n", "loss", "=", "output", "[", "'loss'", "]", "\n", "\n", "loss", "=", "loss", ".", "view", "(", "B", ",", "L", ")", "*", "lm_mask", "\n", "\n", "loss", "=", "loss", ".", "sum", "(", "dim", "=", "1", ")", "/", "lm_mask", ".", "sum", "(", "dim", "=", "1", ")", ".", "clamp", "(", "min", "=", "1", ")", "# B", "\n", "\n", "task_counts", "=", "{", "task", ":", "0", "for", "task", "in", "self", ".", "losses", "}", "\n", "task_loss", "=", "{", "task", ":", "0", "for", "task", "in", "self", ".", "losses", "}", "\n", "\n", "results", "=", "{", "}", "\n", "\n", "results", "[", "'loss'", "]", "=", "(", "loss", "*", "loss_weights", ")", ".", "mean", "(", ")", "\n", "results", "[", "'total_loss'", "]", "=", "loss", ".", "detach", "(", ")", ".", "sum", "(", ")", "\n", "results", "[", "'total_loss_count'", "]", "=", "len", "(", "loss", ")", "\n", "\n", "task_counts", "=", "{", "task", ":", "0", "for", "task", "in", "self", ".", "losses", "}", "\n", "task_loss", "=", "{", "task", ":", "0", "for", "task", "in", "self", ".", "losses", "}", "\n", "\n", "for", "_loss", ",", "task", "in", "zip", "(", "loss", ".", "detach", "(", ")", ",", "batch", "[", "'task'", "]", ")", ":", "\n", "            ", "task_loss", "[", "task", "]", "+=", "_loss", "\n", "task_counts", "[", "task", "]", "+=", "1", "\n", "\n", "", "for", "task", "in", "self", ".", "losses", ":", "\n", "            ", "if", "task_counts", "[", "task", "]", ">", "0", ":", "\n", "                ", "results", "[", "f'{task}_loss'", "]", "=", "task_loss", "[", "task", "]", "\n", "results", "[", "f'{task}_loss_count'", "]", "=", "task_counts", "[", "task", "]", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_model.FewVLMPretraining.valid_step": [[66, 118], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "pretrain_model.FewVLMPretraining.eval", "batch[].to", "batch[].to", "batch[].to", "batch[].to", "batch[].to", "pretrain_model.FewVLMPretraining.", "lm_mask.float.float.float", "batch[].to.size", "loss.detach().sum", "len", "zip", "next", "loss.view", "loss.sum", "lm_mask.float.float.sum().clamp", "loss.detach", "pretrain_model.FewVLMPretraining.parameters", "loss.detach", "lm_mask.float.float.sum"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "valid_step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "self", ".", "eval", "(", ")", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "vis_feats", "=", "batch", "[", "'vis_feats'", "]", ".", "to", "(", "device", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", ".", "to", "(", "device", ")", "\n", "vis_pos", "=", "batch", "[", "'boxes'", "]", ".", "to", "(", "device", ")", "\n", "\n", "lm_labels", "=", "batch", "[", "\"target_ids\"", "]", ".", "to", "(", "device", ")", "\n", "\n", "loss_weights", "=", "batch", "[", "\"loss_weights\"", "]", ".", "to", "(", "device", ")", "\n", "\n", "output", "=", "self", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vis_inputs", "=", "(", "vis_feats", ",", "vis_pos", ")", ",", "\n", "labels", "=", "lm_labels", ",", "\n", "return_dict", "=", "True", "\n", ")", "\n", "assert", "'loss'", "in", "output", "\n", "\n", "lm_mask", "=", "lm_labels", "!=", "-", "100", "\n", "lm_mask", "=", "lm_mask", ".", "float", "(", ")", "\n", "B", ",", "L", "=", "lm_labels", ".", "size", "(", ")", "\n", "\n", "loss", "=", "output", "[", "'loss'", "]", "\n", "\n", "loss", "=", "loss", ".", "view", "(", "B", ",", "L", ")", "*", "lm_mask", "\n", "\n", "loss", "=", "loss", ".", "sum", "(", "dim", "=", "1", ")", "/", "lm_mask", ".", "sum", "(", "dim", "=", "1", ")", ".", "clamp", "(", "min", "=", "1", ")", "# B", "\n", "\n", "results", "=", "{", "}", "\n", "\n", "results", "[", "'loss'", "]", "=", "(", "loss", "*", "loss_weights", ")", ".", "mean", "(", ")", "\n", "results", "[", "'total_loss'", "]", "=", "loss", ".", "detach", "(", ")", ".", "sum", "(", ")", "\n", "results", "[", "'total_loss_count'", "]", "=", "len", "(", "loss", ")", "\n", "\n", "task_counts", "=", "{", "task", ":", "0", "for", "task", "in", "self", ".", "losses", "}", "\n", "task_loss", "=", "{", "task", ":", "0", "for", "task", "in", "self", ".", "losses", "}", "\n", "\n", "for", "_loss", ",", "task", "in", "zip", "(", "loss", ".", "detach", "(", ")", ",", "batch", "[", "'task'", "]", ")", ":", "\n", "            ", "task_loss", "[", "task", "]", "+=", "_loss", "\n", "task_counts", "[", "task", "]", "+=", "1", "\n", "\n", "", "for", "task", "in", "self", ".", "losses", ":", "\n", "            ", "if", "task_counts", "[", "task", "]", ">", "0", ":", "\n", "# result[f'{task}_loss'] = task_loss[task] / task_counts[task]", "\n", "                ", "results", "[", "f'{task}_loss'", "]", "=", "task_loss", "[", "task", "]", "\n", "results", "[", "f'{task}_loss_count'", "]", "=", "task_counts", "[", "task", "]", "\n", "# else:", "\n", "#     result[f'{task}_loss'] = torch.zeros_like(loss)", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_model.FewVLMPretraining.generate_step": [[119, 140], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "pretrain_model.FewVLMPretraining.eval", "batch[].to", "batch[].to", "batch[].to", "pretrain_model.FewVLMPretraining.generate", "pretrain_model.FewVLMPretraining.tokenizer.batch_decode", "next", "batch[].to", "pretrain_model.FewVLMPretraining.parameters"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate_step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "self", ".", "eval", "(", ")", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "vis_feats", "=", "batch", "[", "'vis_feats'", "]", ".", "to", "(", "device", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", ".", "to", "(", "device", ")", "\n", "vis_pos", "=", "batch", "[", "'boxes'", "]", ".", "to", "(", "device", ")", "\n", "\n", "vis_attention_mask", "=", "None", "\n", "if", "'vis_attention_mask'", "in", "batch", ":", "\n", "            ", "vis_attention_mask", "=", "batch", "[", "'vis_attention_mask'", "]", ".", "to", "(", "device", ")", "\n", "\n", "", "output", "=", "self", ".", "generate", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vis_inputs", "=", "(", "vis_feats", ",", "vis_pos", ")", ",", "\n", "vis_attention_mask", "=", "vis_attention_mask", ",", "\n", ")", "\n", "\n", "generated_sents", "=", "self", ".", "tokenizer", ".", "batch_decode", "(", "output", ",", "skip_special_tokens", "=", "True", ")", "\n", "\n", "return", "generated_sents", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_model.FewVLMOKVQA.__init__": [[9, 23], ["modeling_t5.FewVLM.__init__", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.GELU", "torch.GELU", "torch.GELU", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "num_answers", "=", "None", ",", "label2ans", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "if", "config", ".", "classifier", ":", "\n", "            ", "self", ".", "answer_head", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "d_model", "*", "2", ")", ",", "\n", "nn", ".", "GELU", "(", ")", ",", "\n", "nn", ".", "LayerNorm", "(", "config", ".", "d_model", "*", "2", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "d_model", "*", "2", ",", "num_answers", ")", "\n", ")", "\n", "\n", "", "self", ".", "num_answers", "=", "num_answers", "\n", "self", ".", "label2ans", "=", "label2ans", "\n", "self", ".", "bce_loss", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_model.FewVLMOKVQA.train_step": [[24, 82], ["batch[].to", "batch[].to", "batch[].to", "next", "len", "okvqa_model.FewVLMOKVQA.", "batch[].to", "okvqa_model.FewVLMOKVQA.answer_head", "okvqa_model.FewVLMOKVQA.bce_loss", "batch[].to", "okvqa_model.FewVLMOKVQA.", "batch[].to.size", "loss.mean.mean.mean", "okvqa_model.FewVLMOKVQA.parameters", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "last_layer_hidden_state.view", "loss.mean.mean.view", "loss.mean.mean.sum", "lm_mask.sum().clamp", "batch[].to", "lm_mask.sum"], "methods", ["None"], ["", "def", "train_step", "(", "self", ",", "batch", ")", ":", "\n", "\n", "        ", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "vis_feats", "=", "batch", "[", "'vis_feats'", "]", ".", "to", "(", "device", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", ".", "to", "(", "device", ")", "\n", "vis_pos", "=", "batch", "[", "'boxes'", "]", ".", "to", "(", "device", ")", "\n", "\n", "if", "self", ".", "config", ".", "classifier", ":", "\n", "            ", "B", "=", "len", "(", "input_ids", ")", "\n", "\n", "decoder_input_ids", "=", "torch", ".", "ones", "(", "\n", "B", ",", "1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "*", "self", ".", "config", ".", "decoder_start_token_id", "\n", "\n", "output", "=", "self", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vis_inputs", "=", "(", "vis_feats", ",", "vis_pos", ")", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "output_hidden_states", "=", "True", ",", "\n", "return_dict", "=", "True", "\n", ")", "\n", "target", "=", "batch", "[", "'targets'", "]", ".", "to", "(", "device", ")", "\n", "\n", "last_layer_hidden_state", "=", "output", ".", "decoder_hidden_states", "[", "-", "1", "]", "\n", "last_hidden_state", "=", "last_layer_hidden_state", ".", "view", "(", "B", ",", "-", "1", ",", "self", ".", "config", ".", "d_model", ")", "[", ":", ",", "-", "1", "]", "\n", "\n", "# [B, num_answers]", "\n", "logit", "=", "self", ".", "answer_head", "(", "last_hidden_state", ")", "\n", "\n", "loss", "=", "self", ".", "bce_loss", "(", "logit", ",", "target", ")", "\n", "\n", "", "else", ":", "\n", "            ", "lm_labels", "=", "batch", "[", "\"target_ids\"", "]", ".", "to", "(", "device", ")", "\n", "output", "=", "self", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vis_inputs", "=", "(", "vis_feats", ",", "vis_pos", ")", ",", "\n", "labels", "=", "lm_labels", ",", "\n", "return_dict", "=", "True", "\n", ")", "\n", "assert", "'loss'", "in", "output", "\n", "\n", "lm_mask", "=", "(", "lm_labels", "!=", "-", "100", ")", ".", "float", "(", ")", "\n", "B", ",", "L", "=", "lm_labels", ".", "size", "(", ")", "\n", "\n", "loss", "=", "output", "[", "'loss'", "]", "\n", "\n", "loss", "=", "loss", ".", "view", "(", "B", ",", "L", ")", "*", "lm_mask", "\n", "\n", "loss", "=", "loss", ".", "sum", "(", "dim", "=", "1", ")", "/", "lm_mask", ".", "sum", "(", "dim", "=", "1", ")", ".", "clamp", "(", "min", "=", "1", ")", "# B", "\n", "\n", "loss", "=", "loss", "*", "batch", "[", "'scores'", "]", ".", "to", "(", "device", "=", "device", ")", "\n", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "\n", "", "result", "=", "{", "\n", "'loss'", ":", "loss", "\n", "}", "\n", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_model.FewVLMOKVQA.test_step": [[83, 129], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "okvqa_model.FewVLMOKVQA.eval", "batch[].to", "batch[].to", "batch[].to", "next", "len", "okvqa_model.FewVLMOKVQA.", "okvqa_model.FewVLMOKVQA.answer_head", "okvqa_model.FewVLMOKVQA.max", "pred_ans_id.cpu().numpy.cpu().numpy.cpu().numpy", "okvqa_model.FewVLMOKVQA.generate", "okvqa_model.FewVLMOKVQA.tokenizer.batch_decode", "okvqa_model.FewVLMOKVQA.parameters", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "last_layer_hidden_state.view", "pred_ans_id.cpu().numpy.cpu().numpy.cpu"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "test_step", "(", "self", ",", "batch", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "eval", "(", ")", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "vis_feats", "=", "batch", "[", "'vis_feats'", "]", ".", "to", "(", "device", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", ".", "to", "(", "device", ")", "\n", "vis_pos", "=", "batch", "[", "'boxes'", "]", ".", "to", "(", "device", ")", "\n", "\n", "result", "=", "{", "}", "\n", "if", "self", ".", "config", ".", "classifier", ":", "\n", "            ", "B", "=", "len", "(", "input_ids", ")", "\n", "\n", "decoder_input_ids", "=", "torch", ".", "ones", "(", "\n", "B", ",", "1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "*", "self", ".", "config", ".", "decoder_start_token_id", "\n", "\n", "output", "=", "self", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vis_inputs", "=", "(", "vis_feats", ",", "vis_pos", ")", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "output_hidden_states", "=", "True", ",", "\n", "return_dict", "=", "True", "\n", ")", "\n", "\n", "last_layer_hidden_state", "=", "output", ".", "decoder_hidden_states", "[", "-", "1", "]", "\n", "last_hidden_state", "=", "last_layer_hidden_state", ".", "view", "(", "B", ",", "-", "1", ",", "self", ".", "config", ".", "d_model", ")", "[", ":", ",", "-", "1", "]", "\n", "\n", "# [B, num_answers]", "\n", "logit", "=", "self", ".", "answer_head", "(", "last_hidden_state", ")", "\n", "\n", "score", ",", "pred_ans_id", "=", "logit", ".", "max", "(", "1", ")", "\n", "pred_ans_id", "=", "pred_ans_id", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pred_ans", "=", "[", "self", ".", "label2ans", "[", "ans_id", "]", "for", "ans_id", "in", "pred_ans_id", "]", "\n", "\n", "result", "[", "'pred_ans'", "]", "=", "pred_ans", "\n", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "generate", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vis_inputs", "=", "(", "vis_feats", ",", "vis_pos", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "generated_sents", "=", "self", ".", "tokenizer", ".", "batch_decode", "(", "output", ",", "skip_special_tokens", "=", "True", ")", "\n", "result", "[", "'token_ids'", "]", "=", "output", "\n", "result", "[", "'pred_ans'", "]", "=", "generated_sents", "\n", "\n", "", "return", "result", "", "", "", ""]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_data.VQAFineTuneDataset.__init__": [[33, 118], ["torch.utils.data.Dataset.__init__", "split.split", "vqa_data.VQAEvaluator", "torch.cuda.device_count", "print", "dataset_dir.joinpath", "random.seed", "random.shuffle", "print", "coco_feature_dir.joinpath", "coco_feature_dir.joinpath", "coco_feature_dir.joinpath", "coco_feature_dir.joinpath", "dataset_dir.joinpath().joinpath", "coco_feature_dir.joinpath", "coco_feature_dir.joinpath", "tokenization.FewVLMTokenizerFast.from_pretrained", "transformers.T5TokenizerFast.from_pretrained", "open", "json.load", "data_info_dicts.extend", "print", "print", "len", "dataset_dir.joinpath", "len"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load"], ["    ", "def", "__init__", "(", "self", ",", "split", "=", "'train'", ",", "raw_dataset", "=", "None", ",", "rank", "=", "-", "1", ",", "topk", "=", "-", "1", ",", "verbose", "=", "True", ",", "args", "=", "None", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "raw_dataset", "=", "raw_dataset", "\n", "self", ".", "topk", "=", "topk", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "mode", "=", "mode", "\n", "\n", "# Loading datasets to data", "\n", "self", ".", "sources", "=", "split", ".", "split", "(", "','", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "'Data sources: '", ",", "self", ".", "sources", ")", "\n", "\n", "", "if", "'t5'", "in", "self", ".", "args", ".", "backbone", ":", "\n", "            ", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "                ", "self", ".", "tokenizer", "=", "FewVLMTokenizerFast", ".", "from_pretrained", "(", "\n", "args", ".", "backbone", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_text_length", ",", "\n", "do_lower_case", "=", "self", ".", "args", ".", "do_lower_case", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "tokenizer", "=", "T5TokenizerFast", ".", "from_pretrained", "(", "\n", "args", ".", "backbone", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_text_length", ",", "\n", "do_lower_case", "=", "self", ".", "args", ".", "do_lower_case", ")", "\n", "\n", "", "", "self", ".", "answer_normalizer", "=", "VQAEvaluator", "(", ")", "\n", "\n", "self", ".", "img_ids_to_source", "=", "{", "}", "\n", "data_info_dicts", "=", "[", "]", "\n", "for", "source", "in", "self", ".", "sources", ":", "\n", "            ", "data_info_path", "=", "dataset_dir", ".", "joinpath", "(", "f'vqa/{source}.json'", ")", "\n", "with", "open", "(", "data_info_path", ")", "as", "f", ":", "\n", "                ", "_data_info_dicts", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "_d", "in", "_data_info_dicts", ":", "\n", "                    ", "if", "'vg_qa_full'", "==", "source", ":", "\n", "                        ", "self", ".", "img_ids_to_source", "[", "_d", "[", "'img_id'", "]", "]", "=", "'vg'", "\n", "", "elif", "'train2014'", "in", "_d", "[", "'img_id'", "]", ":", "\n", "                        ", "self", ".", "img_ids_to_source", "[", "_d", "[", "'img_id'", "]", "]", "=", "'train2014'", "\n", "", "elif", "'val2014'", "in", "_d", "[", "'img_id'", "]", ":", "\n", "                        ", "self", ".", "img_ids_to_source", "[", "_d", "[", "'img_id'", "]", "]", "=", "'val2014'", "\n", "", "else", ":", "\n", "                        ", "self", ".", "img_ids_to_source", "[", "_d", "[", "'img_id'", "]", "]", "=", "source", "\n", "_d", "[", "'source'", "]", "=", "source", "\n", "\n", "", "", "data_info_dicts", ".", "extend", "(", "_data_info_dicts", ")", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "f\"Loaded {len(_data_info_dicts)} data from\"", ",", "source", ")", "\n", "\n", "", "", "data", "=", "data_info_dicts", "\n", "\n", "self", ".", "n_gpus", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "self", ".", "rank", "=", "rank", "\n", "\n", "if", "self", ".", "topk", ">", "0", ":", "\n", "            ", "data", "=", "data", "[", ":", "self", ".", "topk", "]", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "f\"Use only {self.topk} data\"", ")", "\n", "\n", "", "", "self", ".", "data", "=", "data", "\n", "if", "args", ".", "subsample", "and", "split", "==", "'train'", ":", "\n", "            ", "random", ".", "seed", "(", "args", ".", "dataseed", ")", "\n", "random", ".", "shuffle", "(", "self", ".", "data", ")", "\n", "if", "'train'", "in", "split", "and", "mode", "==", "'train'", ":", "\n", "                ", "self", ".", "data", "=", "self", ".", "data", "[", ":", "args", ".", "num_data", "]", "\n", "", "elif", "'train'", "in", "split", "and", "mode", "==", "'val'", ":", "\n", "                ", "self", ".", "data", "=", "self", ".", "data", "[", "args", ".", "num_data", ":", "2", "*", "args", ".", "num_data", "]", "\n", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "\"# all sentences:\"", ",", "len", "(", "self", ".", "data", ")", ")", "\n", "\n", "", "self", ".", "n_boxes", "=", "args", ".", "n_boxes", "\n", "self", ".", "source_to_h5", "=", "{", "\n", "'train'", ":", "coco_feature_dir", ".", "joinpath", "(", "f'train2014_obj36.h5'", ")", ",", "\n", "'minival'", ":", "coco_feature_dir", ".", "joinpath", "(", "f'val2014_obj36.h5'", ")", ",", "\n", "'nominival'", ":", "coco_feature_dir", ".", "joinpath", "(", "f'val2014_obj36.h5'", ")", ",", "\n", "'test'", ":", "coco_feature_dir", ".", "joinpath", "(", "f'test2015_obj36.h5'", ")", ",", "\n", "\n", "'vg'", ":", "dataset_dir", ".", "joinpath", "(", "'VG/features'", ")", ".", "joinpath", "(", "'vg_gqa_obj36.h5'", ")", ",", "\n", "\n", "'train2014'", ":", "coco_feature_dir", ".", "joinpath", "(", "f'train2014_obj36.h5'", ")", ",", "\n", "'val2014'", ":", "coco_feature_dir", ".", "joinpath", "(", "f'val2014_obj36.h5'", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_data.VQAFineTuneDataset.__len__": [[120, 122], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_data.VQAFineTuneDataset.__getitem__": [[123, 237], ["torch.LongTensor", "len", "isinstance", "numpy.zeros", "torch.from_numpy", "numpy.testing.assert_array_less", "numpy.testing.assert_array_less", "torch.from_numpy", "torch.from_numpy.clamp_", "vqa_data.VQAFineTuneDataset.tokenizer.encode", "label.items", "sum", "torch.LongTensor", "len", "h5py.File", "f[].read_direct", "vqa_data.VQAFineTuneDataset.tokenizer.encode", "answers.append", "scores.append", "numpy.random.multinomial().argmax", "vqa_data.VQAFineTuneDataset.tokenizer.encode", "vqa_data.VQAFineTuneDataset.tokenizer.encode", "print", "print", "exit", "vqa_data.VQAFineTuneDataset.tokenizer.encode", "len", "vqa_data.VQAFineTuneDataset.tokenizer.encode", "numpy.random.multinomial"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "out_dict", "=", "{", "}", "\n", "out_dict", "[", "'args'", "]", "=", "self", ".", "args", "\n", "\n", "datum", "=", "self", ".", "data", "[", "idx", "]", "\n", "\n", "###### Image ######", "\n", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "            ", "img_id", "=", "datum", "[", "'img_id'", "]", "\n", "out_dict", "[", "'img_id'", "]", "=", "img_id", "\n", "\n", "source", "=", "self", ".", "img_ids_to_source", "[", "img_id", "]", "\n", "\n", "f", "=", "self", ".", "source_to_h5", "[", "source", "]", "\n", "\n", "if", "isinstance", "(", "f", ",", "Path", ")", ":", "\n", "# path = self.data_source_to_h5_path[source]", "\n", "                ", "f", "=", "h5py", ".", "File", "(", "f", ",", "'r'", ")", "\n", "# self.split_to_h5_features[split_i] = f", "\n", "self", ".", "source_to_h5", "[", "source", "]", "=", "f", "\n", "\n", "", "feats", "=", "np", ".", "zeros", "(", "shape", "=", "(", "self", ".", "n_boxes", ",", "2048", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "try", ":", "\n", "                ", "f", "[", "f'{img_id}/features'", "]", ".", "read_direct", "(", "feats", ")", "\n", "", "except", "KeyError", ":", "\n", "                ", "print", "(", "'img_id'", ",", "img_id", ")", "\n", "print", "(", "datum", ")", "\n", "exit", "(", ")", "\n", "\n", "", "feats", "=", "torch", ".", "from_numpy", "(", "feats", ")", "\n", "out_dict", "[", "'vis_feats'", "]", "=", "feats", "\n", "\n", "# Normalize the boxes (to 0 ~ 1)", "\n", "img_h", "=", "f", "[", "f'{img_id}/img_h'", "]", "[", "(", ")", "]", "\n", "img_w", "=", "f", "[", "f'{img_id}/img_w'", "]", "[", "(", ")", "]", "\n", "boxes", "=", "f", "[", "f'{img_id}/boxes'", "]", "[", "(", ")", "]", "# (x1, y1, x2, y2)", "\n", "boxes", "[", ":", ",", "(", "0", ",", "2", ")", "]", "/=", "img_w", "\n", "boxes", "[", ":", ",", "(", "1", ",", "3", ")", "]", "/=", "img_h", "\n", "np", ".", "testing", ".", "assert_array_less", "(", "boxes", ",", "1", "+", "1e-5", ")", "\n", "# np.testing.assert_array_less(boxes, 1+5e-2)", "\n", "np", ".", "testing", ".", "assert_array_less", "(", "-", "boxes", ",", "0", "+", "1e-5", ")", "\n", "boxes", "=", "torch", ".", "from_numpy", "(", "boxes", ")", "\n", "\n", "boxes", ".", "clamp_", "(", "min", "=", "0.0", ",", "max", "=", "1.0", ")", "\n", "\n", "out_dict", "[", "'boxes'", "]", "=", "boxes", "\n", "\n", "###### Text #####", "\n", "# caption = datum['caption']", "\n", "", "if", "'sent'", "in", "datum", ":", "\n", "            ", "sent", "=", "datum", "[", "'sent'", "]", "\n", "", "elif", "'question'", "in", "datum", ":", "\n", "            ", "sent", "=", "datum", "[", "'question'", "]", "\n", "\n", "", "if", "self", ".", "args", ".", "prompt", "==", "0", ":", "\n", "            ", "input_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "sent", ",", "max_length", "=", "20", ",", "truncation", "=", "True", ")", "\n", "", "elif", "self", ".", "args", ".", "prompt", "==", "1", ":", "\n", "            ", "input_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "f'{sent} <extra_id_0>'", ",", "max_length", "=", "20", ",", "truncation", "=", "True", ")", "\n", "", "elif", "self", ".", "args", ".", "prompt", "==", "2", ":", "\n", "            ", "input_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "f'question: {sent} answer: '", ",", "max_length", "=", "20", ",", "truncation", "=", "True", ")", "\n", "", "elif", "self", ".", "args", ".", "prompt", "==", "3", ":", "\n", "            ", "input_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "f'question: {sent} answer: <extra_id_0>'", ",", "max_length", "=", "20", ",", "truncation", "=", "True", ")", "\n", "\n", "\n", "", "question_id", "=", "datum", "[", "'question_id'", "]", "\n", "out_dict", "[", "'question_id'", "]", "=", "question_id", "\n", "\n", "\n", "out_dict", "[", "'sent'", "]", "=", "sent", "\n", "out_dict", "[", "'input_ids'", "]", "=", "torch", ".", "LongTensor", "(", "input_ids", ")", "\n", "out_dict", "[", "'input_length'", "]", "=", "len", "(", "input_ids", ")", "\n", "# out_dict['target_ids'] = torch.LongTensor(target_ids)", "\n", "# out_dict['target_length'] = len(target_ids)", "\n", "\n", "if", "'is_topk_optimal'", "in", "datum", ":", "\n", "            ", "out_dict", "[", "'is_topk_optimal'", "]", "=", "datum", "[", "'is_topk_optimal'", "]", "\n", "\n", "", "if", "'label'", "in", "datum", ":", "\n", "            ", "label", "=", "datum", "[", "'label'", "]", "\n", "out_dict", "[", "'label'", "]", "=", "label", "\n", "\n", "answers", "=", "[", "]", "\n", "scores", "=", "[", "]", "\n", "for", "a", ",", "s", "in", "label", ".", "items", "(", ")", ":", "\n", "                ", "answers", ".", "append", "(", "a", ")", "\n", "scores", ".", "append", "(", "s", ")", "\n", "\n", "", "score_sum", "=", "sum", "(", "scores", ")", "\n", "\n", "if", "score_sum", "==", "0", ":", "\n", "                ", "answer", "=", "''", "\n", "score", "=", "0.", "\n", "", "else", ":", "\n", "                ", "prob", "=", "[", "score", "/", "score_sum", "for", "score", "in", "scores", "]", "\n", "choice", "=", "np", ".", "random", ".", "multinomial", "(", "1", ",", "prob", ")", ".", "argmax", "(", ")", "\n", "answer", "=", "answers", "[", "choice", "]", "\n", "score", "=", "scores", "[", "choice", "]", "\n", "assert", "len", "(", "answer", ")", ">", "0", ",", "(", "sent", ",", "label", ",", "choice", ",", "answer", ")", "\n", "\n", "", "out_dict", "[", "'answer'", "]", "=", "answer", "\n", "out_dict", "[", "'score'", "]", "=", "score", "\n", "out_dict", "[", "'all_answers'", "]", "=", "answers", "\n", "\n", "\n", "if", "self", ".", "args", ".", "no_mask_target", ":", "\n", "                ", "target_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "answer", ",", "max_length", "=", "10", ",", "truncation", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "target_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "f'<extra_id_0> {answer}'", ",", "max_length", "=", "10", ",", "truncation", "=", "True", ")", "\n", "\n", "", "out_dict", "[", "'target_ids'", "]", "=", "torch", ".", "LongTensor", "(", "target_ids", ")", "\n", "out_dict", "[", "'target_length'", "]", "=", "len", "(", "target_ids", ")", "\n", "\n", "", "return", "out_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_data.VQAFineTuneDataset.collate_fn": [[239, 328], ["len", "max", "enumerate", "torch.FloatTensor", "torch.ones", "len", "torch.zeros", "torch.zeros", "torch.zeros", "max", "sentences.append", "question_ids.append", "len", "torch.ones", "answers.append", "all_answers.append", "scores.append", "labels.append", "is_topk_optimal.append"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "batch", ")", ":", "\n", "        ", "batch_entry", "=", "{", "}", "\n", "\n", "args", "=", "batch", "[", "0", "]", "[", "'args'", "]", "\n", "\n", "B", "=", "len", "(", "batch", ")", "\n", "\n", "S_W_L", "=", "max", "(", "entry", "[", "'input_length'", "]", "for", "entry", "in", "batch", ")", "\n", "input_ids", "=", "torch", ".", "ones", "(", "B", ",", "S_W_L", ",", "dtype", "=", "torch", ".", "long", ")", "*", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "\n", "if", "args", ".", "use_vision", ":", "\n", "            ", "V_L", "=", "len", "(", "batch", "[", "0", "]", "[", "'boxes'", "]", ")", "\n", "feat_dim", "=", "batch", "[", "0", "]", "[", "'vis_feats'", "]", ".", "shape", "[", "-", "1", "]", "\n", "\n", "boxes", "=", "torch", ".", "zeros", "(", "B", ",", "V_L", ",", "4", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "vis_feats", "=", "torch", ".", "zeros", "(", "B", ",", "V_L", ",", "feat_dim", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "if", "'target'", "in", "batch", "[", "0", "]", ":", "\n", "# targets = []", "\n", "            ", "targets", "=", "torch", ".", "zeros", "(", "B", ",", "len", "(", "batch", "[", "0", "]", "[", "'target'", "]", ")", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "", "if", "'target_ids'", "in", "batch", "[", "0", "]", ":", "\n", "            ", "T_W_L", "=", "max", "(", "entry", "[", "'target_length'", "]", "for", "entry", "in", "batch", ")", "\n", "target_ids", "=", "torch", ".", "ones", "(", "B", ",", "T_W_L", ",", "dtype", "=", "torch", ".", "long", ")", "*", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "\n", "", "sentences", "=", "[", "]", "\n", "question_ids", "=", "[", "]", "\n", "answers", "=", "[", "]", "\n", "all_answers", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "scores", "=", "[", "]", "\n", "is_topk_optimal", "=", "[", "]", "\n", "\n", "for", "i", ",", "entry", "in", "enumerate", "(", "batch", ")", ":", "\n", "            ", "input_ids", "[", "i", ",", ":", "entry", "[", "'input_length'", "]", "]", "=", "entry", "[", "'input_ids'", "]", "\n", "\n", "if", "args", ".", "use_vision", ":", "\n", "                ", "boxes", "[", "i", "]", "+=", "entry", "[", "'boxes'", "]", "\n", "vis_feats", "[", "i", "]", "+=", "entry", "[", "'vis_feats'", "]", "\n", "# img_ids.append(entry['img_id'])", "\n", "# img_paths.append(entry['img_path'])", "\n", "\n", "", "if", "'target_ids'", "in", "entry", ":", "\n", "                ", "target_ids", "[", "i", ",", ":", "entry", "[", "'target_length'", "]", "]", "=", "entry", "[", "'target_ids'", "]", "\n", "\n", "", "if", "'target'", "in", "entry", ":", "\n", "                ", "targets", "[", "i", "]", "+=", "entry", "[", "'target'", "]", "\n", "# targets.append(entry['target'])", "\n", "\n", "", "sentences", ".", "append", "(", "entry", "[", "'sent'", "]", ")", "\n", "question_ids", ".", "append", "(", "entry", "[", "'question_id'", "]", ")", "\n", "if", "'answer'", "in", "entry", ":", "\n", "                ", "answers", ".", "append", "(", "entry", "[", "'answer'", "]", ")", "\n", "", "if", "'all_answers'", "in", "entry", ":", "\n", "                ", "all_answers", ".", "append", "(", "entry", "[", "'all_answers'", "]", ")", "\n", "", "if", "'score'", "in", "entry", ":", "\n", "                ", "scores", ".", "append", "(", "entry", "[", "'score'", "]", ")", "\n", "\n", "", "if", "'label'", "in", "entry", ":", "\n", "                ", "labels", ".", "append", "(", "entry", "[", "'label'", "]", ")", "\n", "\n", "", "if", "'is_topk_optimal'", "in", "entry", ":", "\n", "                ", "is_topk_optimal", ".", "append", "(", "entry", "[", "'is_topk_optimal'", "]", ")", "\n", "\n", "", "", "batch_entry", "[", "'input_ids'", "]", "=", "input_ids", "\n", "if", "'target_ids'", "in", "batch", "[", "0", "]", ":", "\n", "            ", "word_mask", "=", "target_ids", "!=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "target_ids", "[", "~", "word_mask", "]", "=", "-", "100", "\n", "batch_entry", "[", "'target_ids'", "]", "=", "target_ids", "\n", "", "if", "'target'", "in", "batch", "[", "0", "]", ":", "\n", "# targets = torch.stack(targets, dim=0)", "\n", "            ", "batch_entry", "[", "'targets'", "]", "=", "targets", "\n", "\n", "", "if", "args", ".", "use_vision", ":", "\n", "            ", "batch_entry", "[", "'boxes'", "]", "=", "boxes", "\n", "batch_entry", "[", "'vis_feats'", "]", "=", "vis_feats", "\n", "# batch_entry['img_id'] = img_ids", "\n", "# batch_entry['img_paths'] = img_paths", "\n", "\n", "", "batch_entry", "[", "'sent'", "]", "=", "sentences", "\n", "batch_entry", "[", "'question_ids'", "]", "=", "question_ids", "\n", "batch_entry", "[", "'answers'", "]", "=", "answers", "\n", "batch_entry", "[", "'all_answers'", "]", "=", "all_answers", "\n", "batch_entry", "[", "'scores'", "]", "=", "torch", ".", "FloatTensor", "(", "scores", ")", "\n", "batch_entry", "[", "'labels'", "]", "=", "labels", "\n", "\n", "batch_entry", "[", "'args'", "]", "=", "args", "\n", "batch_entry", "[", "'task'", "]", "=", "'vqa'", "\n", "\n", "return", "batch_entry", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_data.VQADataset.__init__": [[389, 429], ["splits.split", "json.load", "json.load", "open", "json.load", "open", "json.load", "vqa_data.VQADataset.data.extend", "print", "open", "open", "len", "len", "dataset_dir.joinpath", "dataset_dir.joinpath", "json.load", "vqa_dir.joinpath", "vqa_dir.joinpath", "open", "vqa_dir.joinpath", "len"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load"], ["def", "__init__", "(", "self", ",", "splits", ":", "str", ",", "verbose", "=", "True", ")", ":", "\n", "        ", "self", ".", "name", "=", "splits", "\n", "self", ".", "splits", "=", "splits", ".", "split", "(", "','", ")", "\n", "\n", "with", "open", "(", "dataset_dir", ".", "joinpath", "(", "f'vqa/v2_mscoco_train2014_annotations.json'", ")", ")", "as", "f", ":", "\n", "            ", "train2014_data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "dataset_dir", ".", "joinpath", "(", "f'vqa/v2_mscoco_val2014_annotations.json'", ")", ")", "as", "f", ":", "\n", "            ", "val2014_data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "train2014_id2datum", "=", "{", "}", "\n", "for", "datum", "in", "train2014_data", "[", "'annotations'", "]", ":", "\n", "            ", "qid", "=", "datum", "[", "'question_id'", "]", "\n", "train2014_id2datum", "[", "qid", "]", "=", "datum", "\n", "", "val2014_id2datum", "=", "{", "}", "\n", "for", "datum", "in", "val2014_data", "[", "'annotations'", "]", ":", "\n", "            ", "qid", "=", "datum", "[", "'question_id'", "]", "\n", "val2014_id2datum", "[", "qid", "]", "=", "datum", "\n", "", "self", ".", "id2datum_gt", "=", "{", "**", "train2014_id2datum", ",", "**", "val2014_id2datum", "}", "\n", "\n", "# Loading datasets", "\n", "self", ".", "data", "=", "[", "]", "\n", "for", "split", "in", "self", ".", "splits", ":", "\n", "            ", "self", ".", "data", ".", "extend", "(", "\n", "json", ".", "load", "(", "open", "(", "vqa_dir", ".", "joinpath", "(", "\"%s.json\"", "%", "split", ")", ")", ")", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "\"Load %d data from split(s) %s.\"", "%", "\n", "(", "len", "(", "self", ".", "data", ")", ",", "self", ".", "name", ")", ")", "\n", "\n", "# Convert list to dict (for evaluation)", "\n", "", "self", ".", "id2datum", "=", "{", "\n", "datum", "[", "'question_id'", "]", ":", "datum", "\n", "for", "datum", "in", "self", ".", "data", "\n", "}", "\n", "\n", "# Topk Answers", "\n", "self", ".", "ans2label", "=", "json", ".", "load", "(", "\n", "open", "(", "vqa_dir", ".", "joinpath", "(", "\"trainval_ans2label.json\"", ")", ")", ")", "\n", "self", ".", "label2ans", "=", "json", ".", "load", "(", "\n", "open", "(", "vqa_dir", ".", "joinpath", "(", "\"trainval_label2ans.json\"", ")", ")", ")", "\n", "assert", "len", "(", "self", ".", "ans2label", ")", "==", "len", "(", "self", ".", "label2ans", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_data.VQADataset.num_answers": [[431, 434], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_answers", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ans2label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_data.VQADataset.__len__": [[435, 437], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_data.VQAEvaluator.__init__": [[440, 494], ["re.compile", "re.compile"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ":", "VQADataset", "=", "None", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "\n", "\"\"\"https://github.com/GT-Vision-Lab/VQA/blob/master/PythonEvaluationTools/vqaEvaluation/vqaEval.py\"\"\"", "\n", "\n", "self", ".", "contractions", "=", "{", "\"aint\"", ":", "\"ain't\"", ",", "\"arent\"", ":", "\"aren't\"", ",", "\"cant\"", ":", "\"can't\"", ",", "\"couldve\"", ":", "\"could've\"", ",", "\"couldnt\"", ":", "\"couldn't\"", ",", "\"couldn'tve\"", ":", "\"couldn't've\"", ",", "\"couldnt've\"", ":", "\"couldn't've\"", ",", "\"didnt\"", ":", "\"didn't\"", ",", "\"doesnt\"", ":", "\"doesn't\"", ",", "\"dont\"", ":", "\"don't\"", ",", "\"hadnt\"", ":", "\"hadn't\"", ",", "\"hadnt've\"", ":", "\"hadn't've\"", ",", "\"hadn'tve\"", ":", "\"hadn't've\"", ",", "\"hasnt\"", ":", "\"hasn't\"", ",", "\"havent\"", ":", "\"haven't\"", ",", "\"hed\"", ":", "\"he'd\"", ",", "\"hed've\"", ":", "\"he'd've\"", ",", "\"he'dve\"", ":", "\"he'd've\"", ",", "\"hes\"", ":", "\"he's\"", ",", "\"howd\"", ":", "\"how'd\"", ",", "\"howll\"", ":", "\"how'll\"", ",", "\"hows\"", ":", "\"how's\"", ",", "\"Id've\"", ":", "\"I'd've\"", ",", "\"I'dve\"", ":", "\"I'd've\"", ",", "\"Im\"", ":", "\"I'm\"", ",", "\"Ive\"", ":", "\"I've\"", ",", "\"isnt\"", ":", "\"isn't\"", ",", "\"itd\"", ":", "\"it'd\"", ",", "\"itd've\"", ":", "\"it'd've\"", ",", "\"it'dve\"", ":", "\"it'd've\"", ",", "\"itll\"", ":", "\"it'll\"", ",", "\"let's\"", ":", "\"let's\"", ",", "\"maam\"", ":", "\"ma'am\"", ",", "\"mightnt\"", ":", "\"mightn't\"", ",", "\"mightnt've\"", ":", "\"mightn't've\"", ",", "\"mightn'tve\"", ":", "\"mightn't've\"", ",", "\"mightve\"", ":", "\"might've\"", ",", "\"mustnt\"", ":", "\"mustn't\"", ",", "\"mustve\"", ":", "\"must've\"", ",", "\"neednt\"", ":", "\"needn't\"", ",", "\"notve\"", ":", "\"not've\"", ",", "\"oclock\"", ":", "\"o'clock\"", ",", "\"oughtnt\"", ":", "\"oughtn't\"", ",", "\"ow's'at\"", ":", "\"'ow's'at\"", ",", "\"'ows'at\"", ":", "\"'ow's'at\"", ",", "\"'ow'sat\"", ":", "\"'ow's'at\"", ",", "\"shant\"", ":", "\"shan't\"", ",", "\"shed've\"", ":", "\"she'd've\"", ",", "\"she'dve\"", ":", "\"she'd've\"", ",", "\"she's\"", ":", "\"she's\"", ",", "\"shouldve\"", ":", "\"should've\"", ",", "\"shouldnt\"", ":", "\"shouldn't\"", ",", "\"shouldnt've\"", ":", "\"shouldn't've\"", ",", "\"shouldn'tve\"", ":", "\"shouldn't've\"", ",", "\"somebody'd\"", ":", "\"somebodyd\"", ",", "\"somebodyd've\"", ":", "\"somebody'd've\"", ",", "\"somebody'dve\"", ":", "\"somebody'd've\"", ",", "\"somebodyll\"", ":", "\"somebody'll\"", ",", "\"somebodys\"", ":", "\"somebody's\"", ",", "\"someoned\"", ":", "\"someone'd\"", ",", "\"someoned've\"", ":", "\"someone'd've\"", ",", "\"someone'dve\"", ":", "\"someone'd've\"", ",", "\"someonell\"", ":", "\"someone'll\"", ",", "\"someones\"", ":", "\"someone's\"", ",", "\"somethingd\"", ":", "\"something'd\"", ",", "\"somethingd've\"", ":", "\"something'd've\"", ",", "\"something'dve\"", ":", "\"something'd've\"", ",", "\"somethingll\"", ":", "\"something'll\"", ",", "\"thats\"", ":", "\"that's\"", ",", "\"thered\"", ":", "\"there'd\"", ",", "\"thered've\"", ":", "\"there'd've\"", ",", "\"there'dve\"", ":", "\"there'd've\"", ",", "\"therere\"", ":", "\"there're\"", ",", "\"theres\"", ":", "\"there's\"", ",", "\"theyd\"", ":", "\"they'd\"", ",", "\"theyd've\"", ":", "\"they'd've\"", ",", "\"they'dve\"", ":", "\"they'd've\"", ",", "\"theyll\"", ":", "\"they'll\"", ",", "\"theyre\"", ":", "\"they're\"", ",", "\"theyve\"", ":", "\"they've\"", ",", "\"twas\"", ":", "\"'twas\"", ",", "\"wasnt\"", ":", "\"wasn't\"", ",", "\"wed've\"", ":", "\"we'd've\"", ",", "\"we'dve\"", ":", "\"we'd've\"", ",", "\"weve\"", ":", "\"we've\"", ",", "\"werent\"", ":", "\"weren't\"", ",", "\"whatll\"", ":", "\"what'll\"", ",", "\"whatre\"", ":", "\"what're\"", ",", "\"whats\"", ":", "\"what's\"", ",", "\"whatve\"", ":", "\"what've\"", ",", "\"whens\"", ":", "\"when's\"", ",", "\"whered\"", ":", "\"where'd\"", ",", "\"wheres\"", ":", "\"where's\"", ",", "\"whereve\"", ":", "\"where've\"", ",", "\"whod\"", ":", "\"who'd\"", ",", "\"whod've\"", ":", "\"who'd've\"", ",", "\"who'dve\"", ":", "\"who'd've\"", ",", "\"wholl\"", ":", "\"who'll\"", ",", "\"whos\"", ":", "\"who's\"", ",", "\"whove\"", ":", "\"who've\"", ",", "\"whyll\"", ":", "\"why'll\"", ",", "\"whyre\"", ":", "\"why're\"", ",", "\"whys\"", ":", "\"why's\"", ",", "\"wont\"", ":", "\"won't\"", ",", "\"wouldve\"", ":", "\"would've\"", ",", "\"wouldnt\"", ":", "\"wouldn't\"", ",", "\"wouldnt've\"", ":", "\"wouldn't've\"", ",", "\"wouldn'tve\"", ":", "\"wouldn't've\"", ",", "\"yall\"", ":", "\"y'all\"", ",", "\"yall'll\"", ":", "\"y'all'll\"", ",", "\"y'allll\"", ":", "\"y'all'll\"", ",", "\"yall'd've\"", ":", "\"y'all'd've\"", ",", "\"y'alld've\"", ":", "\"y'all'd've\"", ",", "\"y'all'dve\"", ":", "\"y'all'd've\"", ",", "\"youd\"", ":", "\"you'd\"", ",", "\"youd've\"", ":", "\"you'd've\"", ",", "\"you'dve\"", ":", "\"you'd've\"", ",", "\"youll\"", ":", "\"you'll\"", ",", "\"youre\"", ":", "\"you're\"", ",", "\"youve\"", ":", "\"you've\"", "}", "\n", "\n", "self", ".", "manualMap", "=", "{", "'none'", ":", "'0'", ",", "\n", "'zero'", ":", "'0'", ",", "\n", "'one'", ":", "'1'", ",", "\n", "'two'", ":", "'2'", ",", "\n", "'three'", ":", "'3'", ",", "\n", "'four'", ":", "'4'", ",", "\n", "'five'", ":", "'5'", ",", "\n", "'six'", ":", "'6'", ",", "\n", "'seven'", ":", "'7'", ",", "\n", "'eight'", ":", "'8'", ",", "\n", "'nine'", ":", "'9'", ",", "\n", "'ten'", ":", "'10'", "\n", "}", "\n", "\n", "self", ".", "articles", "=", "[", "'a'", ",", "\n", "'an'", ",", "\n", "'the'", "\n", "]", "\n", "\n", "self", ".", "periodStrip", "=", "re", ".", "compile", "(", "\"(?!<=\\d)(\\.)(?!\\d)\"", ")", "\n", "self", ".", "commaStrip", "=", "re", ".", "compile", "(", "\"(\\d)(\\,)(\\d)\"", ")", "\n", "self", ".", "punct", "=", "[", "';'", ",", "r\"/\"", ",", "'['", ",", "']'", ",", "'\"'", ",", "'{'", ",", "'}'", ",", "\n", "'('", ",", "')'", ",", "'='", ",", "'+'", ",", "'\\\\'", ",", "'_'", ",", "'-'", ",", "\n", "'>'", ",", "'<'", ",", "'@'", ",", "'`'", ",", "','", ",", "'?'", ",", "'!'", "]", "\n", "\n", "self", ".", "n", "=", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_data.VQAEvaluator.evaluate": [[495, 503], ["quesid2ans.items", "len"], "methods", ["None"], ["", "def", "evaluate", "(", "self", ",", "quesid2ans", ":", "dict", ")", ":", "\n", "        ", "score", "=", "0.", "\n", "for", "quesid", ",", "ans", "in", "quesid2ans", ".", "items", "(", ")", ":", "\n", "            ", "datum", "=", "self", ".", "dataset", ".", "id2datum", "[", "quesid", "]", "\n", "label", "=", "datum", "[", "'label'", "]", "\n", "if", "ans", "in", "label", ":", "\n", "                ", "score", "+=", "label", "[", "ans", "]", "\n", "", "", "return", "score", "/", "len", "(", "quesid2ans", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_data.VQAEvaluator.dump_result": [[504, 524], ["open", "quesid2ans.items", "json.dump", "result.append"], "methods", ["None"], ["", "def", "dump_result", "(", "self", ",", "quesid2ans", ":", "dict", ",", "path", ")", ":", "\n", "        ", "\"\"\"\n        Dump results to a json file, which could be submitted to the VQA online evaluation.\n        VQA json file submission requirement:\n            results = [result]\n            result = {\n                \"question_id\": int,\n                \"answer\": str\n            }\n        :param quesid2ans: dict of quesid --> ans\n        :param path: The desired path of saved file.\n        \"\"\"", "\n", "with", "open", "(", "path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "result", "=", "[", "]", "\n", "for", "ques_id", ",", "ans", "in", "quesid2ans", ".", "items", "(", ")", ":", "\n", "                ", "result", ".", "append", "(", "{", "\n", "'question_id'", ":", "ques_id", ",", "\n", "'answer'", ":", "ans", "\n", "}", ")", "\n", "", "json", ".", "dump", "(", "result", ",", "f", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_data.VQAEvaluator.evaluate_raw": [[525, 604], ["tqdm.tqdm.tqdm", "quesid2ans.items", "int", "qids.append", "vqa_data.VQAEvaluator.replace", "vqa_data.VQAEvaluator.replace", "vqa_data.VQAEvaluator.strip", "vqa_data.VQAEvaluator.processPunctuation", "vqa_data.VQAEvaluator.processDigitArticle", "vqa_data.VQAEvaluator.split", "vqa_data.VQAEvaluator.split.append", "accQA.append", "accQuesType[].append", "accAnsType[].append", "vqa_data.VQAEvaluator.setEvalQA", "vqa_data.VQAEvaluator.setEvalQuesType", "vqa_data.VQAEvaluator.setEvalAnsType", "preds.append", "gtt.append", "len", "vqa_data.VQAEvaluator.setAccuracy", "len", "len", "min", "gtAcc.append", "float", "len", "set", "vqa_data.VQAEvaluator.processPunctuation", "sum", "float", "len"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAEvaluator.processPunctuation", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.processDigitArticle", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.setEvalQA", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.setEvalQuesType", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.setEvalAnsType", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.setAccuracy", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAEvaluator.processPunctuation"], ["", "", "def", "evaluate_raw", "(", "self", ",", "quesid2ans", ":", "dict", ",", "is_topk_optimal", "=", "None", ")", ":", "\n", "        ", "\"\"\"https://github.com/GT-Vision-Lab/VQA/blob/master/PythonEvaluationTools/vqaEvaluation/vqaEval.py\"\"\"", "\n", "\n", "gts", "=", "self", ".", "dataset", ".", "id2datum_gt", "\n", "\n", "self", ".", "accuracy", "=", "{", "}", "\n", "self", ".", "evalQA", "=", "{", "}", "\n", "self", ".", "evalQuesType", "=", "{", "}", "\n", "self", ".", "evalAnsType", "=", "{", "}", "\n", "\n", "accQA", "=", "[", "]", "\n", "accQuesType", "=", "{", "}", "\n", "accAnsType", "=", "{", "}", "\n", "\n", "# print(\"Computing accuracy\")", "\n", "\n", "gtt", "=", "[", "]", "\n", "qids", "=", "[", "]", "\n", "preds", "=", "[", "]", "\n", "\n", "for", "quesId", ",", "resAns", "in", "tqdm", "(", "quesid2ans", ".", "items", "(", ")", ",", "total", "=", "len", "(", "quesid2ans", ")", ",", "ncols", "=", "80", ")", ":", "\n", "\n", "            ", "quesId", "=", "int", "(", "quesId", ")", "\n", "qids", ".", "append", "(", "quesId", ")", "\n", "\n", "datum", "=", "self", ".", "dataset", ".", "id2datum", "[", "quesId", "]", "\n", "\n", "if", "is_topk_optimal", "is", "None", ":", "\n", "                ", "pass", "\n", "", "elif", "'is_topk_optimal'", "in", "datum", ":", "\n", "                ", "if", "datum", "[", "'is_topk_optimal'", "]", "!=", "is_topk_optimal", ":", "\n", "                    ", "continue", "\n", "\n", "", "", "resAns", "=", "resAns", ".", "replace", "(", "'\\n'", ",", "' '", ")", "\n", "resAns", "=", "resAns", ".", "replace", "(", "'\\t'", ",", "' '", ")", "\n", "resAns", "=", "resAns", ".", "strip", "(", ")", "\n", "resAns", "=", "self", ".", "processPunctuation", "(", "resAns", ")", "\n", "resAns", "=", "self", ".", "processDigitArticle", "(", "resAns", ")", "\n", "\n", "answers", "=", "resAns", ".", "split", "(", ")", "\n", "answers", ".", "append", "(", "resAns", ")", "\n", "gtAcc", "=", "[", "]", "\n", "gtAnswers", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "gts", "[", "quesId", "]", "[", "'answers'", "]", "]", "\n", "if", "len", "(", "set", "(", "gtAnswers", ")", ")", ">", "1", ":", "\n", "                ", "for", "ansDic", "in", "gts", "[", "quesId", "]", "[", "'answers'", "]", ":", "\n", "                    ", "ansDic", "[", "'answer'", "]", "=", "self", ".", "processPunctuation", "(", "ansDic", "[", "'answer'", "]", ")", "\n", "", "", "for", "gtAnsDatum", "in", "gts", "[", "quesId", "]", "[", "'answers'", "]", ":", "\n", "                ", "otherGTAns", "=", "[", "item", "for", "item", "in", "gts", "[", "quesId", "]", "[", "'answers'", "]", "if", "item", "!=", "gtAnsDatum", "]", "\n", "matchingAns", "=", "[", "item", "for", "item", "in", "otherGTAns", "if", "item", "[", "'answer'", "]", "==", "resAns", "]", "\n", "acc", "=", "min", "(", "1", ",", "float", "(", "len", "(", "matchingAns", ")", ")", "/", "3", ")", "\n", "gtAcc", ".", "append", "(", "acc", ")", "\n", "", "quesType", "=", "gts", "[", "quesId", "]", "[", "'question_type'", "]", "\n", "ansType", "=", "gts", "[", "quesId", "]", "[", "'answer_type'", "]", "\n", "avgGTAcc", "=", "float", "(", "sum", "(", "gtAcc", ")", ")", "/", "len", "(", "gtAcc", ")", "\n", "accQA", ".", "append", "(", "avgGTAcc", ")", "\n", "if", "quesType", "not", "in", "accQuesType", ":", "\n", "                ", "accQuesType", "[", "quesType", "]", "=", "[", "]", "\n", "", "accQuesType", "[", "quesType", "]", ".", "append", "(", "avgGTAcc", ")", "\n", "if", "ansType", "not", "in", "accAnsType", ":", "\n", "                ", "accAnsType", "[", "ansType", "]", "=", "[", "]", "\n", "", "accAnsType", "[", "ansType", "]", ".", "append", "(", "avgGTAcc", ")", "\n", "\n", "self", ".", "setEvalQA", "(", "quesId", ",", "avgGTAcc", ")", "\n", "self", ".", "setEvalQuesType", "(", "quesId", ",", "quesType", ",", "avgGTAcc", ")", "\n", "self", ".", "setEvalAnsType", "(", "quesId", ",", "ansType", ",", "avgGTAcc", ")", "\n", "preds", ".", "append", "(", "resAns", ")", "\n", "gtt", ".", "append", "(", "gtAnswers", ")", "\n", "\n", "\n", "", "if", "len", "(", "accQA", ")", "==", "0", ":", "\n", "            ", "return", "{", "\n", "'overall'", ":", "0", ",", "\n", "'perQuestionType'", ":", "{", "}", ",", "\n", "'perAnswerType'", ":", "{", "}", "\n", "}", "\n", "", "else", ":", "\n", "            ", "self", ".", "setAccuracy", "(", "accQA", ",", "accQuesType", ",", "accAnsType", ")", "\n", "\n", "", "return", "self", ".", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_data.VQAEvaluator.normalize_answer": [[605, 613], ["resAns.replace.replace.replace", "resAns.replace.replace.replace", "resAns.replace.replace.strip", "vqa_data.VQAEvaluator.processPunctuation", "vqa_data.VQAEvaluator.processDigitArticle", "resAns.replace.replace.replace"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAEvaluator.processPunctuation", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.processDigitArticle"], ["", "def", "normalize_answer", "(", "self", ",", "resAns", ")", ":", "\n", "        ", "resAns", "=", "resAns", ".", "replace", "(", "'\\n'", ",", "' '", ")", "\n", "resAns", "=", "resAns", ".", "replace", "(", "'\\t'", ",", "' '", ")", "\n", "resAns", "=", "resAns", ".", "strip", "(", ")", "\n", "resAns", "=", "self", ".", "processPunctuation", "(", "resAns", ")", "\n", "resAns", "=", "self", ".", "processDigitArticle", "(", "resAns", ")", "\n", "resAns", "=", "resAns", ".", "replace", "(", "','", ",", "''", ")", "\n", "return", "resAns", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_data.VQAEvaluator.processPunctuation": [[614, 625], ["vqa_data.VQAEvaluator.periodStrip.sub", "outText.replace.replace.replace", "outText.replace.replace.replace", "re.search"], "methods", ["None"], ["", "def", "processPunctuation", "(", "self", ",", "inText", ")", ":", "\n", "        ", "outText", "=", "inText", "\n", "for", "p", "in", "self", ".", "punct", ":", "\n", "            ", "if", "(", "p", "+", "' '", "in", "inText", "or", "' '", "+", "p", "in", "inText", ")", "or", "(", "re", ".", "search", "(", "self", ".", "commaStrip", ",", "inText", ")", "!=", "None", ")", ":", "\n", "                ", "outText", "=", "outText", ".", "replace", "(", "p", ",", "''", ")", "\n", "", "else", ":", "\n", "                ", "outText", "=", "outText", ".", "replace", "(", "p", ",", "' '", ")", "\n", "", "", "outText", "=", "self", ".", "periodStrip", ".", "sub", "(", "\"\"", ",", "\n", "outText", ",", "\n", "re", ".", "UNICODE", ")", "\n", "return", "outText", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_data.VQAEvaluator.processDigitArticle": [[626, 640], ["inText.lower().split", "enumerate", "vqa_data.VQAEvaluator.manualMap.setdefault", "inText.lower", "outText.append"], "methods", ["None"], ["", "def", "processDigitArticle", "(", "self", ",", "inText", ")", ":", "\n", "        ", "outText", "=", "[", "]", "\n", "tempText", "=", "inText", ".", "lower", "(", ")", ".", "split", "(", ")", "\n", "for", "word", "in", "tempText", ":", "\n", "            ", "word", "=", "self", ".", "manualMap", ".", "setdefault", "(", "word", ",", "word", ")", "\n", "if", "word", "not", "in", "self", ".", "articles", ":", "\n", "                ", "outText", ".", "append", "(", "word", ")", "\n", "", "else", ":", "\n", "                ", "pass", "\n", "", "", "for", "wordId", ",", "word", "in", "enumerate", "(", "outText", ")", ":", "\n", "            ", "if", "word", "in", "self", ".", "contractions", ":", "\n", "                ", "outText", "[", "wordId", "]", "=", "self", ".", "contractions", "[", "word", "]", "\n", "", "", "outText", "=", "' '", ".", "join", "(", "outText", ")", "\n", "return", "outText", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_data.VQAEvaluator.setEvalQA": [[641, 643], ["round"], "methods", ["None"], ["", "def", "setEvalQA", "(", "self", ",", "quesId", ",", "acc", ")", ":", "\n", "        ", "self", ".", "evalQA", "[", "quesId", "]", "=", "round", "(", "100", "*", "acc", ",", "self", ".", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_data.VQAEvaluator.setEvalQuesType": [[644, 648], ["round"], "methods", ["None"], ["", "def", "setEvalQuesType", "(", "self", ",", "quesId", ",", "quesType", ",", "acc", ")", ":", "\n", "        ", "if", "quesType", "not", "in", "self", ".", "evalQuesType", ":", "\n", "            ", "self", ".", "evalQuesType", "[", "quesType", "]", "=", "{", "}", "\n", "", "self", ".", "evalQuesType", "[", "quesType", "]", "[", "quesId", "]", "=", "round", "(", "100", "*", "acc", ",", "self", ".", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_data.VQAEvaluator.setEvalAnsType": [[649, 653], ["round"], "methods", ["None"], ["", "def", "setEvalAnsType", "(", "self", ",", "quesId", ",", "ansType", ",", "acc", ")", ":", "\n", "        ", "if", "ansType", "not", "in", "self", ".", "evalAnsType", ":", "\n", "            ", "self", ".", "evalAnsType", "[", "ansType", "]", "=", "{", "}", "\n", "", "self", ".", "evalAnsType", "[", "ansType", "]", "[", "quesId", "]", "=", "round", "(", "100", "*", "acc", ",", "self", ".", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_data.VQAEvaluator.setAccuracy": [[654, 658], ["round", "round", "round", "len", "float", "len", "len", "sum", "float", "float", "sum", "sum"], "methods", ["None"], ["", "def", "setAccuracy", "(", "self", ",", "accQA", ",", "accQuesType", ",", "accAnsType", ")", ":", "\n", "        ", "self", ".", "accuracy", "[", "'overall'", "]", "=", "round", "(", "100", "*", "float", "(", "sum", "(", "accQA", ")", ")", "/", "len", "(", "accQA", ")", ",", "self", ".", "n", ")", "\n", "self", ".", "accuracy", "[", "'perQuestionType'", "]", "=", "{", "quesType", ":", "round", "(", "100", "*", "float", "(", "sum", "(", "accQuesType", "[", "quesType", "]", ")", ")", "/", "len", "(", "accQuesType", "[", "quesType", "]", ")", ",", "self", ".", "n", ")", "for", "quesType", "in", "accQuesType", "}", "\n", "self", ".", "accuracy", "[", "'perAnswerType'", "]", "=", "{", "ansType", ":", "round", "(", "100", "*", "float", "(", "sum", "(", "accAnsType", "[", "ansType", "]", ")", ")", "/", "len", "(", "accAnsType", "[", "ansType", "]", ")", ",", "self", ".", "n", ")", "for", "ansType", "in", "accAnsType", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_data.get_loader": [[330, 372], ["vqa_data.VQADataset", "vqa_data.VQAFineTuneDataset", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "vqa_data.VQAEvaluator"], "function", ["None"], ["", "", "def", "get_loader", "(", "args", ",", "split", "=", "'karpathy_train'", ",", "mode", "=", "'train'", ",", "\n", "batch_size", "=", "32", ",", "workers", "=", "4", ",", "distributed", "=", "False", ",", "gpu", "=", "0", ",", "topk", "=", "-", "1", ")", ":", "\n", "\n", "    ", "verbose", "=", "(", "gpu", "==", "0", ")", "\n", "\n", "_dset", "=", "VQADataset", "(", "split", ",", "verbose", ")", "\n", "\n", "dataset", "=", "VQAFineTuneDataset", "(", "\n", "split", ",", "\n", "raw_dataset", "=", "_dset", ",", "\n", "rank", "=", "gpu", ",", "\n", "topk", "=", "topk", ",", "\n", "verbose", "=", "verbose", ",", "\n", "args", "=", "args", ",", "\n", "mode", "=", "mode", ")", "\n", "\n", "if", "distributed", ":", "\n", "        ", "sampler", "=", "DistributedSampler", "(", "dataset", ")", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "None", "\n", "\n", "", "if", "mode", "==", "'train'", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "(", "sampler", "is", "None", ")", ",", "\n", "num_workers", "=", "workers", ",", "pin_memory", "=", "True", ",", "sampler", "=", "sampler", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ")", "\n", "", "else", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "workers", ",", "pin_memory", "=", "True", ",", "\n", "sampler", "=", "sampler", ",", "\n", "shuffle", "=", "None", "if", "(", "sampler", "is", "not", "None", ")", "else", "False", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ",", "\n", "drop_last", "=", "False", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "        ", "loader", ".", "evaluator", "=", "VQAEvaluator", "(", "_dset", ")", "\n", "\n", "", "loader", ".", "task", "=", "'vqa'", "\n", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAFineTuneDataset.__init__": [[33, 118], ["torch.utils.data.Dataset.__init__", "split.split", "okvqa_data.OKVQAEvaluator", "torch.cuda.device_count", "print", "dataset_dir.joinpath", "random.seed", "random.shuffle", "print", "coco_feature_dir.joinpath", "coco_feature_dir.joinpath", "coco_feature_dir.joinpath", "coco_feature_dir.joinpath", "dataset_dir.joinpath().joinpath", "coco_feature_dir.joinpath", "coco_feature_dir.joinpath", "tokenization.FewVLMTokenizerFast.from_pretrained", "transformers.T5TokenizerFast.from_pretrained", "open", "json.load", "data_info_dicts.extend", "print", "print", "len", "dataset_dir.joinpath", "len"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load"], ["    ", "def", "__init__", "(", "self", ",", "split", "=", "'train'", ",", "raw_dataset", "=", "None", ",", "rank", "=", "-", "1", ",", "topk", "=", "-", "1", ",", "verbose", "=", "True", ",", "args", "=", "None", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "raw_dataset", "=", "raw_dataset", "\n", "self", ".", "topk", "=", "topk", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "mode", "=", "mode", "\n", "\n", "# Loading datasets to data", "\n", "self", ".", "sources", "=", "split", ".", "split", "(", "','", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "'Data sources: '", ",", "self", ".", "sources", ")", "\n", "\n", "", "if", "'t5'", "in", "self", ".", "args", ".", "backbone", ":", "\n", "            ", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "                ", "self", ".", "tokenizer", "=", "FewVLMTokenizerFast", ".", "from_pretrained", "(", "\n", "args", ".", "backbone", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_text_length", ",", "\n", "do_lower_case", "=", "self", ".", "args", ".", "do_lower_case", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "tokenizer", "=", "T5TokenizerFast", ".", "from_pretrained", "(", "\n", "args", ".", "backbone", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_text_length", ",", "\n", "do_lower_case", "=", "self", ".", "args", ".", "do_lower_case", ")", "\n", "\n", "\n", "", "", "self", ".", "answer_normalizer", "=", "OKVQAEvaluator", "(", ")", "\n", "\n", "self", ".", "img_ids_to_source", "=", "{", "}", "\n", "data_info_dicts", "=", "[", "]", "\n", "for", "source", "in", "self", ".", "sources", ":", "\n", "            ", "data_info_path", "=", "dataset_dir", ".", "joinpath", "(", "f'okvqa/{source}.json'", ")", "\n", "with", "open", "(", "data_info_path", ")", "as", "f", ":", "\n", "                ", "_data_info_dicts", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "_d", "in", "_data_info_dicts", ":", "\n", "                    ", "if", "'vg_qa_full'", "==", "source", ":", "\n", "                        ", "self", ".", "img_ids_to_source", "[", "_d", "[", "'img_id'", "]", "]", "=", "'vg'", "\n", "", "elif", "'train2014'", "in", "_d", "[", "'img_id'", "]", ":", "\n", "                        ", "self", ".", "img_ids_to_source", "[", "_d", "[", "'img_id'", "]", "]", "=", "'train2014'", "\n", "", "elif", "'val2014'", "in", "_d", "[", "'img_id'", "]", ":", "\n", "                        ", "self", ".", "img_ids_to_source", "[", "_d", "[", "'img_id'", "]", "]", "=", "'val2014'", "\n", "", "else", ":", "\n", "                        ", "self", ".", "img_ids_to_source", "[", "_d", "[", "'img_id'", "]", "]", "=", "source", "\n", "_d", "[", "'source'", "]", "=", "source", "\n", "\n", "", "", "data_info_dicts", ".", "extend", "(", "_data_info_dicts", ")", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "f\"Loaded {len(_data_info_dicts)} data from\"", ",", "source", ")", "\n", "\n", "", "", "data", "=", "data_info_dicts", "\n", "\n", "self", ".", "n_gpus", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "self", ".", "rank", "=", "rank", "\n", "\n", "if", "self", ".", "topk", ">", "0", ":", "\n", "            ", "data", "=", "data", "[", ":", "self", ".", "topk", "]", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "f\"Use only {self.topk} data\"", ")", "\n", "\n", "", "", "self", ".", "data", "=", "data", "\n", "if", "args", ".", "subsample", "and", "split", "==", "'train'", ":", "\n", "            ", "random", ".", "seed", "(", "args", ".", "dataseed", ")", "\n", "random", ".", "shuffle", "(", "self", ".", "data", ")", "\n", "if", "'train'", "in", "split", "and", "mode", "==", "'train'", ":", "\n", "                ", "self", ".", "data", "=", "self", ".", "data", "[", ":", "args", ".", "num_data", "]", "\n", "", "elif", "'train'", "in", "split", "and", "mode", "==", "'val'", ":", "\n", "                ", "self", ".", "data", "=", "self", ".", "data", "[", "args", ".", "num_data", ":", "2", "*", "args", ".", "num_data", "]", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "\"# all sentences:\"", ",", "len", "(", "self", ".", "data", ")", ")", "\n", "\n", "", "self", ".", "n_boxes", "=", "args", ".", "n_boxes", "\n", "self", ".", "source_to_h5", "=", "{", "\n", "'train'", ":", "coco_feature_dir", ".", "joinpath", "(", "f'train2014_obj36.h5'", ")", ",", "\n", "'minival'", ":", "coco_feature_dir", ".", "joinpath", "(", "f'val2014_obj36.h5'", ")", ",", "\n", "'nominival'", ":", "coco_feature_dir", ".", "joinpath", "(", "f'val2014_obj36.h5'", ")", ",", "\n", "'test'", ":", "coco_feature_dir", ".", "joinpath", "(", "f'test2015_obj36.h5'", ")", ",", "\n", "\n", "'vg'", ":", "dataset_dir", ".", "joinpath", "(", "'VG/features'", ")", ".", "joinpath", "(", "'vg_gqa_obj36.h5'", ")", ",", "\n", "\n", "'train2014'", ":", "coco_feature_dir", ".", "joinpath", "(", "f'train2014_obj36.h5'", ")", ",", "\n", "'val2014'", ":", "coco_feature_dir", ".", "joinpath", "(", "f'val2014_obj36.h5'", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAFineTuneDataset.__len__": [[120, 122], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAFineTuneDataset.__getitem__": [[123, 238], ["torch.LongTensor", "len", "isinstance", "numpy.zeros", "torch.from_numpy", "numpy.testing.assert_array_less", "numpy.testing.assert_array_less", "torch.from_numpy", "torch.from_numpy.clamp_", "okvqa_data.OKVQAFineTuneDataset.tokenizer.encode", "label.items", "sum", "torch.LongTensor", "len", "h5py.File", "f[].read_direct", "okvqa_data.OKVQAFineTuneDataset.tokenizer.encode", "answers.append", "scores.append", "numpy.random.multinomial().argmax", "okvqa_data.OKVQAFineTuneDataset.tokenizer.encode", "okvqa_data.OKVQAFineTuneDataset.tokenizer.encode", "print", "print", "exit", "okvqa_data.OKVQAFineTuneDataset.tokenizer.encode", "len", "okvqa_data.OKVQAFineTuneDataset.tokenizer.encode", "numpy.random.multinomial"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "out_dict", "=", "{", "}", "\n", "out_dict", "[", "'args'", "]", "=", "self", ".", "args", "\n", "\n", "datum", "=", "self", ".", "data", "[", "idx", "]", "\n", "\n", "###### Image ######", "\n", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "            ", "img_id", "=", "datum", "[", "'img_id'", "]", "\n", "out_dict", "[", "'img_id'", "]", "=", "img_id", "\n", "\n", "source", "=", "self", ".", "img_ids_to_source", "[", "img_id", "]", "\n", "\n", "f", "=", "self", ".", "source_to_h5", "[", "source", "]", "\n", "\n", "if", "isinstance", "(", "f", ",", "Path", ")", ":", "\n", "# path = self.data_source_to_h5_path[source]", "\n", "                ", "f", "=", "h5py", ".", "File", "(", "f", ",", "'r'", ")", "\n", "# self.split_to_h5_features[split_i] = f", "\n", "self", ".", "source_to_h5", "[", "source", "]", "=", "f", "\n", "\n", "", "feats", "=", "np", ".", "zeros", "(", "shape", "=", "(", "self", ".", "n_boxes", ",", "2048", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "try", ":", "\n", "                ", "f", "[", "f'{img_id}/features'", "]", ".", "read_direct", "(", "feats", ")", "\n", "", "except", "KeyError", ":", "\n", "                ", "print", "(", "'img_id'", ",", "img_id", ")", "\n", "print", "(", "datum", ")", "\n", "exit", "(", ")", "\n", "\n", "", "feats", "=", "torch", ".", "from_numpy", "(", "feats", ")", "\n", "out_dict", "[", "'vis_feats'", "]", "=", "feats", "\n", "\n", "# Normalize the boxes (to 0 ~ 1)", "\n", "img_h", "=", "f", "[", "f'{img_id}/img_h'", "]", "[", "(", ")", "]", "\n", "img_w", "=", "f", "[", "f'{img_id}/img_w'", "]", "[", "(", ")", "]", "\n", "boxes", "=", "f", "[", "f'{img_id}/boxes'", "]", "[", "(", ")", "]", "# (x1, y1, x2, y2)", "\n", "boxes", "[", ":", ",", "(", "0", ",", "2", ")", "]", "/=", "img_w", "\n", "boxes", "[", ":", ",", "(", "1", ",", "3", ")", "]", "/=", "img_h", "\n", "np", ".", "testing", ".", "assert_array_less", "(", "boxes", ",", "1", "+", "1e-5", ")", "\n", "# np.testing.assert_array_less(boxes, 1+5e-2)", "\n", "np", ".", "testing", ".", "assert_array_less", "(", "-", "boxes", ",", "0", "+", "1e-5", ")", "\n", "boxes", "=", "torch", ".", "from_numpy", "(", "boxes", ")", "\n", "\n", "boxes", ".", "clamp_", "(", "min", "=", "0.0", ",", "max", "=", "1.0", ")", "\n", "\n", "out_dict", "[", "'boxes'", "]", "=", "boxes", "\n", "\n", "###### Text #####", "\n", "# caption = datum['caption']", "\n", "", "if", "'sent'", "in", "datum", ":", "\n", "            ", "sent", "=", "datum", "[", "'sent'", "]", "\n", "", "elif", "'question'", "in", "datum", ":", "\n", "            ", "sent", "=", "datum", "[", "'question'", "]", "\n", "\n", "", "if", "self", ".", "args", ".", "prompt", "==", "0", ":", "\n", "            ", "input_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "sent", ",", "max_length", "=", "20", ",", "truncation", "=", "True", ")", "\n", "", "elif", "self", ".", "args", ".", "prompt", "==", "1", ":", "\n", "            ", "input_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "f'{sent} <extra_id_0>'", ",", "max_length", "=", "20", ",", "truncation", "=", "True", ")", "\n", "", "elif", "self", ".", "args", ".", "prompt", "==", "2", ":", "\n", "            ", "input_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "f'question: {sent} answer: '", ",", "max_length", "=", "20", ",", "truncation", "=", "True", ")", "\n", "", "elif", "self", ".", "args", ".", "prompt", "==", "3", ":", "\n", "            ", "input_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "f'question: {sent} answer: <extra_id_0>'", ",", "max_length", "=", "20", ",", "truncation", "=", "True", ")", "\n", "\n", "\n", "", "question_id", "=", "datum", "[", "'question_id'", "]", "\n", "out_dict", "[", "'question_id'", "]", "=", "question_id", "\n", "\n", "\n", "out_dict", "[", "'sent'", "]", "=", "sent", "\n", "out_dict", "[", "'input_ids'", "]", "=", "torch", ".", "LongTensor", "(", "input_ids", ")", "\n", "out_dict", "[", "'input_length'", "]", "=", "len", "(", "input_ids", ")", "\n", "# out_dict['target_ids'] = torch.LongTensor(target_ids)", "\n", "# out_dict['target_length'] = len(target_ids)", "\n", "\n", "if", "'is_topk_optimal'", "in", "datum", ":", "\n", "            ", "out_dict", "[", "'is_topk_optimal'", "]", "=", "datum", "[", "'is_topk_optimal'", "]", "\n", "\n", "", "if", "'label'", "in", "datum", ":", "\n", "            ", "label", "=", "datum", "[", "'label'", "]", "\n", "out_dict", "[", "'label'", "]", "=", "label", "\n", "\n", "answers", "=", "[", "]", "\n", "scores", "=", "[", "]", "\n", "for", "a", ",", "s", "in", "label", ".", "items", "(", ")", ":", "\n", "                ", "answers", ".", "append", "(", "a", ")", "\n", "scores", ".", "append", "(", "s", ")", "\n", "\n", "", "score_sum", "=", "sum", "(", "scores", ")", "\n", "\n", "if", "score_sum", "==", "0", ":", "\n", "                ", "answer", "=", "''", "\n", "score", "=", "0.", "\n", "", "else", ":", "\n", "                ", "prob", "=", "[", "score", "/", "score_sum", "for", "score", "in", "scores", "]", "\n", "choice", "=", "np", ".", "random", ".", "multinomial", "(", "1", ",", "prob", ")", ".", "argmax", "(", ")", "\n", "answer", "=", "answers", "[", "choice", "]", "\n", "score", "=", "scores", "[", "choice", "]", "\n", "assert", "len", "(", "answer", ")", ">", "0", ",", "(", "sent", ",", "label", ",", "choice", ",", "answer", ")", "\n", "\n", "", "out_dict", "[", "'answer'", "]", "=", "answer", "\n", "out_dict", "[", "'score'", "]", "=", "score", "\n", "out_dict", "[", "'all_answers'", "]", "=", "answers", "\n", "\n", "\n", "\n", "if", "self", ".", "args", ".", "no_mask_target", ":", "\n", "                ", "target_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "answer", ",", "max_length", "=", "10", ",", "truncation", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "target_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "f'<extra_id_0> {answer}'", ",", "max_length", "=", "10", ",", "truncation", "=", "True", ")", "\n", "\n", "", "out_dict", "[", "'target_ids'", "]", "=", "torch", ".", "LongTensor", "(", "target_ids", ")", "\n", "out_dict", "[", "'target_length'", "]", "=", "len", "(", "target_ids", ")", "\n", "\n", "", "return", "out_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAFineTuneDataset.collate_fn": [[240, 329], ["len", "max", "enumerate", "torch.FloatTensor", "torch.ones", "len", "torch.zeros", "torch.zeros", "torch.zeros", "max", "sentences.append", "question_ids.append", "len", "torch.ones", "answers.append", "all_answers.append", "scores.append", "labels.append", "is_topk_optimal.append"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "batch", ")", ":", "\n", "        ", "batch_entry", "=", "{", "}", "\n", "\n", "args", "=", "batch", "[", "0", "]", "[", "'args'", "]", "\n", "\n", "B", "=", "len", "(", "batch", ")", "\n", "\n", "S_W_L", "=", "max", "(", "entry", "[", "'input_length'", "]", "for", "entry", "in", "batch", ")", "\n", "input_ids", "=", "torch", ".", "ones", "(", "B", ",", "S_W_L", ",", "dtype", "=", "torch", ".", "long", ")", "*", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "\n", "if", "args", ".", "use_vision", ":", "\n", "            ", "V_L", "=", "len", "(", "batch", "[", "0", "]", "[", "'boxes'", "]", ")", "\n", "feat_dim", "=", "batch", "[", "0", "]", "[", "'vis_feats'", "]", ".", "shape", "[", "-", "1", "]", "\n", "\n", "boxes", "=", "torch", ".", "zeros", "(", "B", ",", "V_L", ",", "4", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "vis_feats", "=", "torch", ".", "zeros", "(", "B", ",", "V_L", ",", "feat_dim", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "if", "'target'", "in", "batch", "[", "0", "]", ":", "\n", "# targets = []", "\n", "            ", "targets", "=", "torch", ".", "zeros", "(", "B", ",", "len", "(", "batch", "[", "0", "]", "[", "'target'", "]", ")", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "", "if", "'target_ids'", "in", "batch", "[", "0", "]", ":", "\n", "            ", "T_W_L", "=", "max", "(", "entry", "[", "'target_length'", "]", "for", "entry", "in", "batch", ")", "\n", "target_ids", "=", "torch", ".", "ones", "(", "B", ",", "T_W_L", ",", "dtype", "=", "torch", ".", "long", ")", "*", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "\n", "", "sentences", "=", "[", "]", "\n", "question_ids", "=", "[", "]", "\n", "answers", "=", "[", "]", "\n", "all_answers", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "scores", "=", "[", "]", "\n", "is_topk_optimal", "=", "[", "]", "\n", "\n", "for", "i", ",", "entry", "in", "enumerate", "(", "batch", ")", ":", "\n", "            ", "input_ids", "[", "i", ",", ":", "entry", "[", "'input_length'", "]", "]", "=", "entry", "[", "'input_ids'", "]", "\n", "\n", "if", "args", ".", "use_vision", ":", "\n", "                ", "boxes", "[", "i", "]", "+=", "entry", "[", "'boxes'", "]", "\n", "vis_feats", "[", "i", "]", "+=", "entry", "[", "'vis_feats'", "]", "\n", "# img_ids.append(entry['img_id'])", "\n", "# img_paths.append(entry['img_path'])", "\n", "\n", "", "if", "'target_ids'", "in", "entry", ":", "\n", "                ", "target_ids", "[", "i", ",", ":", "entry", "[", "'target_length'", "]", "]", "=", "entry", "[", "'target_ids'", "]", "\n", "\n", "", "if", "'target'", "in", "entry", ":", "\n", "                ", "targets", "[", "i", "]", "+=", "entry", "[", "'target'", "]", "\n", "# targets.append(entry['target'])", "\n", "\n", "", "sentences", ".", "append", "(", "entry", "[", "'sent'", "]", ")", "\n", "question_ids", ".", "append", "(", "entry", "[", "'question_id'", "]", ")", "\n", "if", "'answer'", "in", "entry", ":", "\n", "                ", "answers", ".", "append", "(", "entry", "[", "'answer'", "]", ")", "\n", "", "if", "'all_answers'", "in", "entry", ":", "\n", "                ", "all_answers", ".", "append", "(", "entry", "[", "'all_answers'", "]", ")", "\n", "", "if", "'score'", "in", "entry", ":", "\n", "                ", "scores", ".", "append", "(", "entry", "[", "'score'", "]", ")", "\n", "\n", "", "if", "'label'", "in", "entry", ":", "\n", "                ", "labels", ".", "append", "(", "entry", "[", "'label'", "]", ")", "\n", "\n", "", "if", "'is_topk_optimal'", "in", "entry", ":", "\n", "                ", "is_topk_optimal", ".", "append", "(", "entry", "[", "'is_topk_optimal'", "]", ")", "\n", "\n", "", "", "batch_entry", "[", "'input_ids'", "]", "=", "input_ids", "\n", "if", "'target_ids'", "in", "batch", "[", "0", "]", ":", "\n", "            ", "word_mask", "=", "target_ids", "!=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "target_ids", "[", "~", "word_mask", "]", "=", "-", "100", "\n", "batch_entry", "[", "'target_ids'", "]", "=", "target_ids", "\n", "", "if", "'target'", "in", "batch", "[", "0", "]", ":", "\n", "# targets = torch.stack(targets, dim=0)", "\n", "            ", "batch_entry", "[", "'targets'", "]", "=", "targets", "\n", "\n", "", "if", "args", ".", "use_vision", ":", "\n", "            ", "batch_entry", "[", "'boxes'", "]", "=", "boxes", "\n", "batch_entry", "[", "'vis_feats'", "]", "=", "vis_feats", "\n", "# batch_entry['img_id'] = img_ids", "\n", "# batch_entry['img_paths'] = img_paths", "\n", "\n", "", "batch_entry", "[", "'sent'", "]", "=", "sentences", "\n", "batch_entry", "[", "'question_ids'", "]", "=", "question_ids", "\n", "batch_entry", "[", "'answers'", "]", "=", "answers", "\n", "batch_entry", "[", "'all_answers'", "]", "=", "all_answers", "\n", "batch_entry", "[", "'scores'", "]", "=", "torch", ".", "FloatTensor", "(", "scores", ")", "\n", "batch_entry", "[", "'labels'", "]", "=", "labels", "\n", "\n", "batch_entry", "[", "'args'", "]", "=", "args", "\n", "batch_entry", "[", "'task'", "]", "=", "'okvqa'", "\n", "\n", "return", "batch_entry", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQADataset.__init__": [[390, 422], ["splits.split", "open", "json.load", "open", "json.load", "okvqa_data.OKVQADataset.data.extend", "print", "dataset_dir.joinpath", "dataset_dir.joinpath", "json.load", "open", "okvqa_dir.joinpath", "len"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load"], ["def", "__init__", "(", "self", ",", "splits", ":", "str", ",", "verbose", "=", "True", ")", ":", "\n", "        ", "self", ".", "name", "=", "splits", "\n", "self", ".", "splits", "=", "splits", ".", "split", "(", "','", ")", "\n", "\n", "with", "open", "(", "dataset_dir", ".", "joinpath", "(", "f'okvqa/mscoco_train2014_annotations.json'", ")", ")", "as", "f", ":", "\n", "            ", "train2014_data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "dataset_dir", ".", "joinpath", "(", "f'okvqa/mscoco_val2014_annotations.json'", ")", ")", "as", "f", ":", "\n", "            ", "val2014_data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "train2014_id2datum", "=", "{", "}", "\n", "for", "datum", "in", "train2014_data", "[", "'annotations'", "]", ":", "\n", "            ", "qid", "=", "datum", "[", "'question_id'", "]", "\n", "train2014_id2datum", "[", "qid", "]", "=", "datum", "\n", "", "val2014_id2datum", "=", "{", "}", "\n", "for", "datum", "in", "val2014_data", "[", "'annotations'", "]", ":", "\n", "            ", "qid", "=", "datum", "[", "'question_id'", "]", "\n", "val2014_id2datum", "[", "qid", "]", "=", "datum", "\n", "", "self", ".", "id2datum_gt", "=", "{", "**", "train2014_id2datum", ",", "**", "val2014_id2datum", "}", "\n", "\n", "# Loading datasets", "\n", "self", ".", "data", "=", "[", "]", "\n", "for", "split", "in", "self", ".", "splits", ":", "\n", "            ", "self", ".", "data", ".", "extend", "(", "\n", "json", ".", "load", "(", "open", "(", "okvqa_dir", ".", "joinpath", "(", "\"%s.json\"", "%", "split", ")", ")", ")", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "\"Load %d data from split(s) %s.\"", "%", "\n", "(", "len", "(", "self", ".", "data", ")", ",", "self", ".", "name", ")", ")", "\n", "\n", "# Convert list to dict (for evaluation)", "\n", "", "self", ".", "id2datum", "=", "{", "\n", "datum", "[", "'question_id'", "]", ":", "datum", "\n", "for", "datum", "in", "self", ".", "data", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQADataset.num_answers": [[425, 428], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_answers", "(", "self", ")", ":", "\n", "        ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQADataset.__len__": [[429, 431], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.__init__": [[434, 488], ["re.compile", "re.compile"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ":", "OKVQADataset", "=", "None", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "\n", "\"\"\"https://github.com/GT-Vision-Lab/VQA/blob/master/PythonEvaluationTools/vqaEvaluation/vqaEval.py\"\"\"", "\n", "\n", "self", ".", "contractions", "=", "{", "\"aint\"", ":", "\"ain't\"", ",", "\"arent\"", ":", "\"aren't\"", ",", "\"cant\"", ":", "\"can't\"", ",", "\"couldve\"", ":", "\"could've\"", ",", "\"couldnt\"", ":", "\"couldn't\"", ",", "\"couldn'tve\"", ":", "\"couldn't've\"", ",", "\"couldnt've\"", ":", "\"couldn't've\"", ",", "\"didnt\"", ":", "\"didn't\"", ",", "\"doesnt\"", ":", "\"doesn't\"", ",", "\"dont\"", ":", "\"don't\"", ",", "\"hadnt\"", ":", "\"hadn't\"", ",", "\"hadnt've\"", ":", "\"hadn't've\"", ",", "\"hadn'tve\"", ":", "\"hadn't've\"", ",", "\"hasnt\"", ":", "\"hasn't\"", ",", "\"havent\"", ":", "\"haven't\"", ",", "\"hed\"", ":", "\"he'd\"", ",", "\"hed've\"", ":", "\"he'd've\"", ",", "\"he'dve\"", ":", "\"he'd've\"", ",", "\"hes\"", ":", "\"he's\"", ",", "\"howd\"", ":", "\"how'd\"", ",", "\"howll\"", ":", "\"how'll\"", ",", "\"hows\"", ":", "\"how's\"", ",", "\"Id've\"", ":", "\"I'd've\"", ",", "\"I'dve\"", ":", "\"I'd've\"", ",", "\"Im\"", ":", "\"I'm\"", ",", "\"Ive\"", ":", "\"I've\"", ",", "\"isnt\"", ":", "\"isn't\"", ",", "\"itd\"", ":", "\"it'd\"", ",", "\"itd've\"", ":", "\"it'd've\"", ",", "\"it'dve\"", ":", "\"it'd've\"", ",", "\"itll\"", ":", "\"it'll\"", ",", "\"let's\"", ":", "\"let's\"", ",", "\"maam\"", ":", "\"ma'am\"", ",", "\"mightnt\"", ":", "\"mightn't\"", ",", "\"mightnt've\"", ":", "\"mightn't've\"", ",", "\"mightn'tve\"", ":", "\"mightn't've\"", ",", "\"mightve\"", ":", "\"might've\"", ",", "\"mustnt\"", ":", "\"mustn't\"", ",", "\"mustve\"", ":", "\"must've\"", ",", "\"neednt\"", ":", "\"needn't\"", ",", "\"notve\"", ":", "\"not've\"", ",", "\"oclock\"", ":", "\"o'clock\"", ",", "\"oughtnt\"", ":", "\"oughtn't\"", ",", "\"ow's'at\"", ":", "\"'ow's'at\"", ",", "\"'ows'at\"", ":", "\"'ow's'at\"", ",", "\"'ow'sat\"", ":", "\"'ow's'at\"", ",", "\"shant\"", ":", "\"shan't\"", ",", "\"shed've\"", ":", "\"she'd've\"", ",", "\"she'dve\"", ":", "\"she'd've\"", ",", "\"she's\"", ":", "\"she's\"", ",", "\"shouldve\"", ":", "\"should've\"", ",", "\"shouldnt\"", ":", "\"shouldn't\"", ",", "\"shouldnt've\"", ":", "\"shouldn't've\"", ",", "\"shouldn'tve\"", ":", "\"shouldn't've\"", ",", "\"somebody'd\"", ":", "\"somebodyd\"", ",", "\"somebodyd've\"", ":", "\"somebody'd've\"", ",", "\"somebody'dve\"", ":", "\"somebody'd've\"", ",", "\"somebodyll\"", ":", "\"somebody'll\"", ",", "\"somebodys\"", ":", "\"somebody's\"", ",", "\"someoned\"", ":", "\"someone'd\"", ",", "\"someoned've\"", ":", "\"someone'd've\"", ",", "\"someone'dve\"", ":", "\"someone'd've\"", ",", "\"someonell\"", ":", "\"someone'll\"", ",", "\"someones\"", ":", "\"someone's\"", ",", "\"somethingd\"", ":", "\"something'd\"", ",", "\"somethingd've\"", ":", "\"something'd've\"", ",", "\"something'dve\"", ":", "\"something'd've\"", ",", "\"somethingll\"", ":", "\"something'll\"", ",", "\"thats\"", ":", "\"that's\"", ",", "\"thered\"", ":", "\"there'd\"", ",", "\"thered've\"", ":", "\"there'd've\"", ",", "\"there'dve\"", ":", "\"there'd've\"", ",", "\"therere\"", ":", "\"there're\"", ",", "\"theres\"", ":", "\"there's\"", ",", "\"theyd\"", ":", "\"they'd\"", ",", "\"theyd've\"", ":", "\"they'd've\"", ",", "\"they'dve\"", ":", "\"they'd've\"", ",", "\"theyll\"", ":", "\"they'll\"", ",", "\"theyre\"", ":", "\"they're\"", ",", "\"theyve\"", ":", "\"they've\"", ",", "\"twas\"", ":", "\"'twas\"", ",", "\"wasnt\"", ":", "\"wasn't\"", ",", "\"wed've\"", ":", "\"we'd've\"", ",", "\"we'dve\"", ":", "\"we'd've\"", ",", "\"weve\"", ":", "\"we've\"", ",", "\"werent\"", ":", "\"weren't\"", ",", "\"whatll\"", ":", "\"what'll\"", ",", "\"whatre\"", ":", "\"what're\"", ",", "\"whats\"", ":", "\"what's\"", ",", "\"whatve\"", ":", "\"what've\"", ",", "\"whens\"", ":", "\"when's\"", ",", "\"whered\"", ":", "\"where'd\"", ",", "\"wheres\"", ":", "\"where's\"", ",", "\"whereve\"", ":", "\"where've\"", ",", "\"whod\"", ":", "\"who'd\"", ",", "\"whod've\"", ":", "\"who'd've\"", ",", "\"who'dve\"", ":", "\"who'd've\"", ",", "\"wholl\"", ":", "\"who'll\"", ",", "\"whos\"", ":", "\"who's\"", ",", "\"whove\"", ":", "\"who've\"", ",", "\"whyll\"", ":", "\"why'll\"", ",", "\"whyre\"", ":", "\"why're\"", ",", "\"whys\"", ":", "\"why's\"", ",", "\"wont\"", ":", "\"won't\"", ",", "\"wouldve\"", ":", "\"would've\"", ",", "\"wouldnt\"", ":", "\"wouldn't\"", ",", "\"wouldnt've\"", ":", "\"wouldn't've\"", ",", "\"wouldn'tve\"", ":", "\"wouldn't've\"", ",", "\"yall\"", ":", "\"y'all\"", ",", "\"yall'll\"", ":", "\"y'all'll\"", ",", "\"y'allll\"", ":", "\"y'all'll\"", ",", "\"yall'd've\"", ":", "\"y'all'd've\"", ",", "\"y'alld've\"", ":", "\"y'all'd've\"", ",", "\"y'all'dve\"", ":", "\"y'all'd've\"", ",", "\"youd\"", ":", "\"you'd\"", ",", "\"youd've\"", ":", "\"you'd've\"", ",", "\"you'dve\"", ":", "\"you'd've\"", ",", "\"youll\"", ":", "\"you'll\"", ",", "\"youre\"", ":", "\"you're\"", ",", "\"youve\"", ":", "\"you've\"", "}", "\n", "\n", "self", ".", "manualMap", "=", "{", "'none'", ":", "'0'", ",", "\n", "'zero'", ":", "'0'", ",", "\n", "'one'", ":", "'1'", ",", "\n", "'two'", ":", "'2'", ",", "\n", "'three'", ":", "'3'", ",", "\n", "'four'", ":", "'4'", ",", "\n", "'five'", ":", "'5'", ",", "\n", "'six'", ":", "'6'", ",", "\n", "'seven'", ":", "'7'", ",", "\n", "'eight'", ":", "'8'", ",", "\n", "'nine'", ":", "'9'", ",", "\n", "'ten'", ":", "'10'", "\n", "}", "\n", "\n", "self", ".", "articles", "=", "[", "'a'", ",", "\n", "'an'", ",", "\n", "'the'", "\n", "]", "\n", "\n", "self", ".", "periodStrip", "=", "re", ".", "compile", "(", "\"(?!<=\\d)(\\.)(?!\\d)\"", ")", "\n", "self", ".", "commaStrip", "=", "re", ".", "compile", "(", "\"(\\d)(\\,)(\\d)\"", ")", "\n", "self", ".", "punct", "=", "[", "';'", ",", "r\"/\"", ",", "'['", ",", "']'", ",", "'\"'", ",", "'{'", ",", "'}'", ",", "\n", "'('", ",", "')'", ",", "'='", ",", "'+'", ",", "'\\\\'", ",", "'_'", ",", "'-'", ",", "\n", "'>'", ",", "'<'", ",", "'@'", ",", "'`'", ",", "','", ",", "'?'", ",", "'!'", "]", "\n", "\n", "self", ".", "n", "=", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.evaluate": [[489, 497], ["quesid2ans.items", "len"], "methods", ["None"], ["", "def", "evaluate", "(", "self", ",", "quesid2ans", ":", "dict", ")", ":", "\n", "        ", "score", "=", "0.", "\n", "for", "quesid", ",", "ans", "in", "quesid2ans", ".", "items", "(", ")", ":", "\n", "            ", "datum", "=", "self", ".", "dataset", ".", "id2datum", "[", "quesid", "]", "\n", "label", "=", "datum", "[", "'label'", "]", "\n", "if", "ans", "in", "label", ":", "\n", "                ", "score", "+=", "label", "[", "ans", "]", "\n", "", "", "return", "score", "/", "len", "(", "quesid2ans", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.dump_result": [[498, 518], ["open", "quesid2ans.items", "json.dump", "result.append"], "methods", ["None"], ["", "def", "dump_result", "(", "self", ",", "quesid2ans", ":", "dict", ",", "path", ")", ":", "\n", "        ", "\"\"\"\n        Dump results to a json file, which could be submitted to the VQA online evaluation.\n        VQA json file submission requirement:\n            results = [result]\n            result = {\n                \"question_id\": int,\n                \"answer\": str\n            }\n        :param quesid2ans: dict of quesid --> ans\n        :param path: The desired path of saved file.\n        \"\"\"", "\n", "with", "open", "(", "path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "result", "=", "[", "]", "\n", "for", "ques_id", ",", "ans", "in", "quesid2ans", ".", "items", "(", ")", ":", "\n", "                ", "result", ".", "append", "(", "{", "\n", "'question_id'", ":", "ques_id", ",", "\n", "'answer'", ":", "ans", "\n", "}", ")", "\n", "", "json", ".", "dump", "(", "result", ",", "f", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.evaluate_raw": [[519, 600], ["tqdm.tqdm.tqdm", "quesid2ans.items", "int", "qids.append", "okvqa_data.OKVQAEvaluator.replace", "okvqa_data.OKVQAEvaluator.replace", "okvqa_data.OKVQAEvaluator.strip", "okvqa_data.OKVQAEvaluator.processPunctuation", "okvqa_data.OKVQAEvaluator.processDigitArticle", "okvqa_data.OKVQAEvaluator.split", "okvqa_data.OKVQAEvaluator.split.append", "accQA.append", "accQuesType[].append", "accAnsType[].append", "okvqa_data.OKVQAEvaluator.setEvalQA", "okvqa_data.OKVQAEvaluator.setEvalQuesType", "okvqa_data.OKVQAEvaluator.setEvalAnsType", "preds.append", "gtt.append", "len", "okvqa_data.OKVQAEvaluator.setAccuracy", "len", "len", "min", "gtAcc.append", "float", "len", "set", "okvqa_data.OKVQAEvaluator.processPunctuation", "sum", "float", "len"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAEvaluator.processPunctuation", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.processDigitArticle", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.setEvalQA", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.setEvalQuesType", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.setEvalAnsType", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.setAccuracy", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAEvaluator.processPunctuation"], ["", "", "def", "evaluate_raw", "(", "self", ",", "quesid2ans", ":", "dict", ",", "is_topk_optimal", "=", "None", ")", ":", "\n", "        ", "\"\"\"https://github.com/GT-Vision-Lab/VQA/blob/master/PythonEvaluationTools/vqaEvaluation/vqaEval.py\"\"\"", "\n", "\n", "gts", "=", "self", ".", "dataset", ".", "id2datum_gt", "\n", "\n", "self", ".", "accuracy", "=", "{", "}", "\n", "self", ".", "evalQA", "=", "{", "}", "\n", "self", ".", "evalQuesType", "=", "{", "}", "\n", "self", ".", "evalAnsType", "=", "{", "}", "\n", "\n", "accQA", "=", "[", "]", "\n", "accQuesType", "=", "{", "}", "\n", "accAnsType", "=", "{", "}", "\n", "\n", "# print(\"Computing accuracy\")", "\n", "\n", "gtt", "=", "[", "]", "\n", "qids", "=", "[", "]", "\n", "preds", "=", "[", "]", "\n", "\n", "for", "quesId", ",", "resAns", "in", "tqdm", "(", "quesid2ans", ".", "items", "(", ")", ",", "total", "=", "len", "(", "quesid2ans", ")", ",", "ncols", "=", "80", ")", ":", "\n", "\n", "            ", "quesId", "=", "int", "(", "quesId", ")", "\n", "qids", ".", "append", "(", "quesId", ")", "\n", "\n", "datum", "=", "self", ".", "dataset", ".", "id2datum", "[", "quesId", "]", "\n", "\n", "if", "is_topk_optimal", "is", "None", ":", "\n", "                ", "pass", "\n", "", "elif", "'is_topk_optimal'", "in", "datum", ":", "\n", "                ", "if", "datum", "[", "'is_topk_optimal'", "]", "!=", "is_topk_optimal", ":", "\n", "                    ", "continue", "\n", "\n", "", "", "resAns", "=", "resAns", ".", "replace", "(", "'\\n'", ",", "' '", ")", "\n", "resAns", "=", "resAns", ".", "replace", "(", "'\\t'", ",", "' '", ")", "\n", "resAns", "=", "resAns", ".", "strip", "(", ")", "\n", "resAns", "=", "self", ".", "processPunctuation", "(", "resAns", ")", "\n", "resAns", "=", "self", ".", "processDigitArticle", "(", "resAns", ")", "\n", "\n", "answers", "=", "resAns", ".", "split", "(", ")", "\n", "answers", ".", "append", "(", "resAns", ")", "\n", "gtAcc", "=", "[", "]", "\n", "gtAnswers", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "gts", "[", "quesId", "]", "[", "'answers'", "]", "]", "\n", "if", "len", "(", "set", "(", "gtAnswers", ")", ")", ">", "1", ":", "\n", "                ", "for", "ansDic", "in", "gts", "[", "quesId", "]", "[", "'answers'", "]", ":", "\n", "                    ", "ansDic", "[", "'answer'", "]", "=", "self", ".", "processPunctuation", "(", "ansDic", "[", "'answer'", "]", ")", "\n", "", "", "for", "gtAnsDatum", "in", "gts", "[", "quesId", "]", "[", "'answers'", "]", ":", "\n", "                ", "otherGTAns", "=", "[", "item", "for", "item", "in", "gts", "[", "quesId", "]", "[", "'answers'", "]", "if", "item", "!=", "gtAnsDatum", "]", "\n", "matchingAns", "=", "[", "item", "for", "item", "in", "otherGTAns", "if", "item", "[", "'answer'", "]", "==", "resAns", "]", "\n", "# matchingAns = [item for item in otherGTAns if item['answer'] in answers]", "\n", "acc", "=", "min", "(", "1", ",", "float", "(", "len", "(", "matchingAns", ")", ")", "/", "3", ")", "\n", "gtAcc", ".", "append", "(", "acc", ")", "\n", "", "quesType", "=", "gts", "[", "quesId", "]", "[", "'question_type'", "]", "\n", "ansType", "=", "gts", "[", "quesId", "]", "[", "'answer_type'", "]", "\n", "avgGTAcc", "=", "float", "(", "sum", "(", "gtAcc", ")", ")", "/", "len", "(", "gtAcc", ")", "\n", "accQA", ".", "append", "(", "avgGTAcc", ")", "\n", "if", "quesType", "not", "in", "accQuesType", ":", "\n", "                ", "accQuesType", "[", "quesType", "]", "=", "[", "]", "\n", "", "accQuesType", "[", "quesType", "]", ".", "append", "(", "avgGTAcc", ")", "\n", "if", "ansType", "not", "in", "accAnsType", ":", "\n", "                ", "accAnsType", "[", "ansType", "]", "=", "[", "]", "\n", "", "accAnsType", "[", "ansType", "]", ".", "append", "(", "avgGTAcc", ")", "\n", "\n", "self", ".", "setEvalQA", "(", "quesId", ",", "avgGTAcc", ")", "\n", "self", ".", "setEvalQuesType", "(", "quesId", ",", "quesType", ",", "avgGTAcc", ")", "\n", "self", ".", "setEvalAnsType", "(", "quesId", ",", "ansType", ",", "avgGTAcc", ")", "\n", "preds", ".", "append", "(", "resAns", ")", "\n", "gtt", ".", "append", "(", "gtAnswers", ")", "\n", "\n", "\n", "\n", "", "if", "len", "(", "accQA", ")", "==", "0", ":", "\n", "            ", "return", "{", "\n", "'overall'", ":", "0", ",", "\n", "'perQuestionType'", ":", "{", "}", ",", "\n", "'perAnswerType'", ":", "{", "}", "\n", "}", "\n", "", "else", ":", "\n", "            ", "self", ".", "setAccuracy", "(", "accQA", ",", "accQuesType", ",", "accAnsType", ")", "\n", "\n", "", "return", "self", ".", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.normalize_answer": [[601, 609], ["resAns.replace.replace.replace", "resAns.replace.replace.replace", "resAns.replace.replace.strip", "okvqa_data.OKVQAEvaluator.processPunctuation", "okvqa_data.OKVQAEvaluator.processDigitArticle", "resAns.replace.replace.replace"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAEvaluator.processPunctuation", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.processDigitArticle"], ["", "def", "normalize_answer", "(", "self", ",", "resAns", ")", ":", "\n", "        ", "resAns", "=", "resAns", ".", "replace", "(", "'\\n'", ",", "' '", ")", "\n", "resAns", "=", "resAns", ".", "replace", "(", "'\\t'", ",", "' '", ")", "\n", "resAns", "=", "resAns", ".", "strip", "(", ")", "\n", "resAns", "=", "self", ".", "processPunctuation", "(", "resAns", ")", "\n", "resAns", "=", "self", ".", "processDigitArticle", "(", "resAns", ")", "\n", "resAns", "=", "resAns", ".", "replace", "(", "','", ",", "''", ")", "\n", "return", "resAns", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.processPunctuation": [[610, 621], ["okvqa_data.OKVQAEvaluator.periodStrip.sub", "outText.replace.replace.replace", "outText.replace.replace.replace", "re.search"], "methods", ["None"], ["", "def", "processPunctuation", "(", "self", ",", "inText", ")", ":", "\n", "        ", "outText", "=", "inText", "\n", "for", "p", "in", "self", ".", "punct", ":", "\n", "            ", "if", "(", "p", "+", "' '", "in", "inText", "or", "' '", "+", "p", "in", "inText", ")", "or", "(", "re", ".", "search", "(", "self", ".", "commaStrip", ",", "inText", ")", "!=", "None", ")", ":", "\n", "                ", "outText", "=", "outText", ".", "replace", "(", "p", ",", "''", ")", "\n", "", "else", ":", "\n", "                ", "outText", "=", "outText", ".", "replace", "(", "p", ",", "' '", ")", "\n", "", "", "outText", "=", "self", ".", "periodStrip", ".", "sub", "(", "\"\"", ",", "\n", "outText", ",", "\n", "re", ".", "UNICODE", ")", "\n", "return", "outText", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.processDigitArticle": [[622, 636], ["inText.lower().split", "enumerate", "okvqa_data.OKVQAEvaluator.manualMap.setdefault", "inText.lower", "outText.append"], "methods", ["None"], ["", "def", "processDigitArticle", "(", "self", ",", "inText", ")", ":", "\n", "        ", "outText", "=", "[", "]", "\n", "tempText", "=", "inText", ".", "lower", "(", ")", ".", "split", "(", ")", "\n", "for", "word", "in", "tempText", ":", "\n", "            ", "word", "=", "self", ".", "manualMap", ".", "setdefault", "(", "word", ",", "word", ")", "\n", "if", "word", "not", "in", "self", ".", "articles", ":", "\n", "                ", "outText", ".", "append", "(", "word", ")", "\n", "", "else", ":", "\n", "                ", "pass", "\n", "", "", "for", "wordId", ",", "word", "in", "enumerate", "(", "outText", ")", ":", "\n", "            ", "if", "word", "in", "self", ".", "contractions", ":", "\n", "                ", "outText", "[", "wordId", "]", "=", "self", ".", "contractions", "[", "word", "]", "\n", "", "", "outText", "=", "' '", ".", "join", "(", "outText", ")", "\n", "return", "outText", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.setEvalQA": [[637, 639], ["round"], "methods", ["None"], ["", "def", "setEvalQA", "(", "self", ",", "quesId", ",", "acc", ")", ":", "\n", "        ", "self", ".", "evalQA", "[", "quesId", "]", "=", "round", "(", "100", "*", "acc", ",", "self", ".", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.setEvalQuesType": [[640, 644], ["round"], "methods", ["None"], ["", "def", "setEvalQuesType", "(", "self", ",", "quesId", ",", "quesType", ",", "acc", ")", ":", "\n", "        ", "if", "quesType", "not", "in", "self", ".", "evalQuesType", ":", "\n", "            ", "self", ".", "evalQuesType", "[", "quesType", "]", "=", "{", "}", "\n", "", "self", ".", "evalQuesType", "[", "quesType", "]", "[", "quesId", "]", "=", "round", "(", "100", "*", "acc", ",", "self", ".", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.setEvalAnsType": [[645, 649], ["round"], "methods", ["None"], ["", "def", "setEvalAnsType", "(", "self", ",", "quesId", ",", "ansType", ",", "acc", ")", ":", "\n", "        ", "if", "ansType", "not", "in", "self", ".", "evalAnsType", ":", "\n", "            ", "self", ".", "evalAnsType", "[", "ansType", "]", "=", "{", "}", "\n", "", "self", ".", "evalAnsType", "[", "ansType", "]", "[", "quesId", "]", "=", "round", "(", "100", "*", "acc", ",", "self", ".", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.setAccuracy": [[650, 654], ["round", "round", "round", "len", "float", "len", "len", "sum", "float", "float", "sum", "sum"], "methods", ["None"], ["", "def", "setAccuracy", "(", "self", ",", "accQA", ",", "accQuesType", ",", "accAnsType", ")", ":", "\n", "        ", "self", ".", "accuracy", "[", "'overall'", "]", "=", "round", "(", "100", "*", "float", "(", "sum", "(", "accQA", ")", ")", "/", "len", "(", "accQA", ")", ",", "self", ".", "n", ")", "\n", "self", ".", "accuracy", "[", "'perQuestionType'", "]", "=", "{", "quesType", ":", "round", "(", "100", "*", "float", "(", "sum", "(", "accQuesType", "[", "quesType", "]", ")", ")", "/", "len", "(", "accQuesType", "[", "quesType", "]", ")", ",", "self", ".", "n", ")", "for", "quesType", "in", "accQuesType", "}", "\n", "self", ".", "accuracy", "[", "'perAnswerType'", "]", "=", "{", "ansType", ":", "round", "(", "100", "*", "float", "(", "sum", "(", "accAnsType", "[", "ansType", "]", ")", ")", "/", "len", "(", "accAnsType", "[", "ansType", "]", ")", ",", "self", ".", "n", ")", "for", "ansType", "in", "accAnsType", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.get_loader": [[331, 373], ["okvqa_data.OKVQADataset", "okvqa_data.OKVQAFineTuneDataset", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "okvqa_data.OKVQAEvaluator"], "function", ["None"], ["", "", "def", "get_loader", "(", "args", ",", "split", "=", "'karpathy_train'", ",", "mode", "=", "'train'", ",", "\n", "batch_size", "=", "32", ",", "workers", "=", "4", ",", "distributed", "=", "False", ",", "gpu", "=", "0", ",", "topk", "=", "-", "1", ")", ":", "\n", "\n", "    ", "verbose", "=", "(", "gpu", "==", "0", ")", "\n", "\n", "_dset", "=", "OKVQADataset", "(", "split", ",", "verbose", ")", "\n", "\n", "dataset", "=", "OKVQAFineTuneDataset", "(", "\n", "split", ",", "\n", "raw_dataset", "=", "_dset", ",", "\n", "rank", "=", "gpu", ",", "\n", "topk", "=", "topk", ",", "\n", "verbose", "=", "verbose", ",", "\n", "args", "=", "args", ",", "\n", "mode", "=", "mode", ")", "\n", "\n", "if", "distributed", ":", "\n", "        ", "sampler", "=", "DistributedSampler", "(", "dataset", ")", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "None", "\n", "\n", "", "if", "mode", "==", "'train'", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "(", "sampler", "is", "None", ")", ",", "\n", "num_workers", "=", "workers", ",", "pin_memory", "=", "True", ",", "sampler", "=", "sampler", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ")", "\n", "", "else", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "workers", ",", "pin_memory", "=", "True", ",", "\n", "sampler", "=", "sampler", ",", "\n", "shuffle", "=", "None", "if", "(", "sampler", "is", "not", "None", ")", "else", "False", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ",", "\n", "drop_last", "=", "False", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "        ", "loader", ".", "evaluator", "=", "OKVQAEvaluator", "(", "_dset", ")", "\n", "\n", "", "loader", ".", "task", "=", "'okvqa'", "\n", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.cococaption.Trainer.__init__": [[46, 103], ["trainer_base.TrainerBase.__init__", "cococaption.Trainer.create_config", "cococaption.Trainer.create_tokenizer", "cococaption.Trainer.create_model", "print", "cococaption.Trainer.model.to", "cococaption.Trainer.model.resize_token_embeddings", "cococaption.Trainer.load_checkpoint", "cococaption.Trainer.init_weights", "time", "cococaption.Trainer.create_optimizer_and_scheduler", "print", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "amp.initialize", "time"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_config", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_tokenizer", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_model", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load_checkpoint", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.init_weights", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_optimizer_and_scheduler"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "train_loader", "=", "None", ",", "val_loader", "=", "None", ",", "test_loader", "=", "None", ",", "train", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "args", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "test_loader", "=", "test_loader", ",", "\n", "train", "=", "train", ")", "\n", "\n", "from", "cococaption_model", "import", "FewVLMCOCOCaption", "\n", "\n", "model_kwargs", "=", "{", "}", "\n", "if", "'t5'", "in", "args", ".", "backbone", ":", "\n", "            ", "model_class", "=", "FewVLMCOCOCaption", "\n", "\n", "\n", "", "config", "=", "self", ".", "create_config", "(", ")", "\n", "self", ".", "tokenizer", "=", "self", ".", "create_tokenizer", "(", ")", "\n", "\n", "self", ".", "model", "=", "self", ".", "create_model", "(", "model_class", ",", "config", ",", "**", "model_kwargs", ")", "\n", "\n", "if", "'t5'", "in", "self", ".", "args", ".", "tokenizer", ":", "\n", "            ", "self", ".", "model", ".", "resize_token_embeddings", "(", "self", ".", "tokenizer", ".", "vocab_size", ")", "\n", "", "self", ".", "model", ".", "tokenizer", "=", "self", ".", "tokenizer", "\n", "\n", "# Load Checkpoint", "\n", "self", ".", "start_epoch", "=", "None", "\n", "if", "args", ".", "load", "is", "not", "None", ":", "\n", "            ", "ckpt_path", "=", "args", ".", "load", "+", "'.pth'", "\n", "self", ".", "load_checkpoint", "(", "ckpt_path", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "from_scratch", ":", "\n", "            ", "self", ".", "init_weights", "(", ")", "\n", "\n", "# GPU Options", "\n", "", "print", "(", "f'Model Launching at GPU {self.args.gpu}'", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "from", "time", "import", "time", "\n", "start", "=", "time", "(", ")", "\n", "", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "args", ".", "gpu", ")", "\n", "\n", "# Optimizer", "\n", "if", "train", ":", "\n", "            ", "self", ".", "optim", ",", "self", ".", "lr_scheduler", "=", "self", ".", "create_optimizer_and_scheduler", "(", ")", "\n", "\n", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                ", "self", ".", "scaler", "=", "torch", ".", "cuda", ".", "amp", ".", "GradScaler", "(", ")", "\n", "", "elif", "_use_apex", ":", "\n", "                ", "self", ".", "model", ",", "self", ".", "optim", "=", "amp", ".", "initialize", "(", "\n", "self", ".", "model", ",", "self", ".", "optim", ",", "opt_level", "=", "'O1'", ",", "verbosity", "=", "self", ".", "verbose", ")", "\n", "\n", "", "", "if", "args", ".", "multiGPU", ":", "\n", "            ", "if", "args", ".", "distributed", ":", "\n", "                ", "self", ".", "model", "=", "DDP", "(", "self", ".", "model", ",", "device_ids", "=", "[", "args", ".", "gpu", "]", ",", "\n", "find_unused_parameters", "=", "True", "\n", ")", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "f'It took {time() - start:.1f}s'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.cococaption.Trainer.train": [[104, 275], ["utils.LossMeter", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "range", "cococaption.Trainer.evaluate", "pprint.pprint.pformat", "print", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "cococaption.Trainer.model.train", "enumerate", "cococaption.Trainer.save", "os.path.isdir", "os.makedirs", "os.path.join", "cococaption.Trainer.load", "print", "cococaption.Trainer.train_loader.sampler.set_epoch", "tqdm.tqdm.tqdm", "loss.detach.detach.detach", "cococaption.Trainer.items", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "tqdm.tqdm.tqdm.close", "cococaption.Trainer.evaluate", "pprint.pprint.pformat", "print", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "cococaption.Trainer.scaler.scale().backward", "cococaption.Trainer.model.parameters", "utils.LossMeter.update", "tqdm.tqdm.tqdm.set_description", "tqdm.tqdm.tqdm.update", "cococaption.Trainer.save", "len", "autocast", "cococaption.Trainer.model.module.train_step", "cococaption.Trainer.model.train_step", "loss.detach.detach.backward", "cococaption.Trainer.scaler.unscale_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "cococaption.Trainer.scaler.step", "cococaption.Trainer.scaler.update", "cococaption.Trainer.optim.step", "cococaption.Trainer.lr_scheduler.step", "v.item", "packaging.version.parse", "packaging.version.parse", "loss.detach.detach.item", "cococaption.Trainer.model.module.train_step", "cococaption.Trainer.model.train_step", "cococaption.Trainer.scaler.scale", "amp.scale_loss", "scaled_loss.backward", "cococaption.Trainer.model.parameters", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "cococaption.Trainer.lr_scheduler.get_last_lr", "cococaption.Trainer.lr_scheduler.get_lr", "cococaption.Trainer.optim.get_lr", "amp.master_params", "cococaption.Trainer.model.parameters", "len"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.train", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step"], ["", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "verbose", ":", "\n", "            ", "loss_meter", "=", "LossMeter", "(", ")", "\n", "best_valid", "=", "0.", "\n", "best_epoch", "=", "0", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "global_step", "=", "0", "\n", "epochs", "=", "self", ".", "args", ".", "epochs", "\n", "\n", "if", "not", "self", ".", "args", ".", "test_only", ":", "\n", "            ", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "\n", "                ", "if", "self", ".", "start_epoch", "is", "not", "None", ":", "\n", "                    ", "epoch", "+=", "self", ".", "start_epoch", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "self", ".", "train_loader", ".", "sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                    ", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "self", ".", "train_loader", ")", ",", "ncols", "=", "120", ")", "\n", "\n", "", "epoch_results", "=", "{", "\n", "'loss'", ":", "0.", ",", "\n", "\n", "}", "\n", "\n", "for", "step_i", ",", "batch", "in", "enumerate", "(", "self", ".", "train_loader", ")", ":", "\n", "\n", "                    ", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                        ", "with", "autocast", "(", ")", ":", "\n", "                            ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                                ", "results", "=", "self", ".", "model", ".", "module", ".", "train_step", "(", "batch", ")", "\n", "", "else", ":", "\n", "                                ", "results", "=", "self", ".", "model", ".", "train_step", "(", "batch", ")", "\n", "", "", "", "else", ":", "\n", "                        ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                            ", "results", "=", "self", ".", "model", ".", "module", ".", "train_step", "(", "batch", ")", "\n", "", "else", ":", "\n", "                            ", "results", "=", "self", ".", "model", ".", "train_step", "(", "batch", ")", "\n", "\n", "", "", "loss", "=", "results", "[", "'loss'", "]", "\n", "\n", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                        ", "self", ".", "scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "", "elif", "self", ".", "args", ".", "fp16", "and", "_use_apex", ":", "\n", "                        ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "self", ".", "optim", ")", "as", "scaled_loss", ":", "\n", "                            ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                        ", "loss", ".", "backward", "(", ")", "\n", "\n", "\n", "", "loss", "=", "loss", ".", "detach", "(", ")", "\n", "\n", "# Update Parameters", "\n", "if", "self", ".", "args", ".", "clip_grad_norm", ">", "0", ":", "\n", "                        ", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                            ", "self", ".", "scaler", ".", "unscale_", "(", "self", ".", "optim", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "", "elif", "self", ".", "args", ".", "fp16", "and", "_use_apex", ":", "\n", "                            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "\n", "self", ".", "optim", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "", "else", ":", "\n", "                            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "\n", "", "", "update", "=", "True", "\n", "if", "self", ".", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                        ", "if", "step_i", "==", "0", ":", "\n", "                            ", "update", "=", "False", "\n", "", "elif", "step_i", "%", "self", ".", "args", ".", "gradient_accumulation_steps", "==", "0", "or", "step_i", "==", "len", "(", "self", ".", "train_loader", ")", "-", "1", ":", "\n", "                            ", "update", "=", "True", "\n", "", "else", ":", "\n", "                            ", "update", "=", "False", "\n", "\n", "", "", "if", "update", ":", "\n", "                        ", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                            ", "self", ".", "scaler", ".", "step", "(", "self", ".", "optim", ")", "\n", "self", ".", "scaler", ".", "update", "(", ")", "\n", "", "else", ":", "\n", "                            ", "self", ".", "optim", ".", "step", "(", ")", "\n", "\n", "", "if", "self", ".", "lr_scheduler", ":", "\n", "                            ", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "# self.model.zero_grad()", "\n", "", "for", "param", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "                            ", "param", ".", "grad", "=", "None", "\n", "", "global_step", "+=", "1", "\n", "\n", "", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", ":", "\n", "                        ", "if", "k", "in", "epoch_results", ":", "\n", "                            ", "epoch_results", "[", "k", "]", "+=", "v", ".", "item", "(", ")", "\n", "\n", "", "", "if", "self", ".", "lr_scheduler", ":", "\n", "                        ", "if", "version", ".", "parse", "(", "torch", ".", "__version__", ")", ">=", "version", ".", "parse", "(", "\"1.4\"", ")", ":", "\n", "                            ", "lr", "=", "self", ".", "lr_scheduler", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                            ", "lr", "=", "self", ".", "lr_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "", "", "else", ":", "\n", "                        ", "try", ":", "\n", "                            ", "lr", "=", "self", ".", "optim", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "", "except", "AttributeError", ":", "\n", "                            ", "lr", "=", "self", ".", "args", ".", "lr", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "                        ", "loss_meter", ".", "update", "(", "loss", ".", "item", "(", ")", ")", "\n", "desc_str", "=", "f'Epoch {epoch} | LR {lr:.6f} | Steps {global_step}'", "\n", "desc_str", "+=", "f' | Loss {loss_meter.val:4f}'", "\n", "pbar", ".", "set_description", "(", "desc_str", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                    ", "pbar", ".", "close", "(", ")", "\n", "\n", "# format ex)", "\n", "# {'Bleu_1': 0.9999999997500004,", "\n", "#  'Bleu_2': 0.5773502690332603,", "\n", "#  'Bleu_3': 4.3679023223468616e-06,", "\n", "#  'Bleu_4': 1.4287202142987477e-08,", "\n", "#  'CIDEr': 3.333333333333333,", "\n", "#  'METEOR': 0.43354749322305886,", "\n", "#  'ROUGE_L': 0.75,", "\n", "#  'SPICE': 0.6666666666666666}", "\n", "\n", "# Validation", "\n", "valid_results", "=", "self", ".", "evaluate", "(", "self", ".", "val_loader", ")", "\n", "\n", "valid_score", "=", "valid_results", "[", "'CIDEr'", "]", "\n", "\n", "if", "valid_score", ">", "best_valid", "or", "epoch", "==", "0", ":", "\n", "                        ", "best_valid", "=", "valid_score", "\n", "best_epoch", "=", "epoch", "\n", "self", ".", "save", "(", "\"BEST\"", ")", "\n", "\n", "", "log_str", "=", "''", "\n", "\n", "log_str", "+=", "pformat", "(", "valid_results", ")", "\n", "log_str", "+=", "\"\\nEpoch %d: Valid CIDEr %0.4f\"", "%", "(", "epoch", ",", "valid_score", ")", "\n", "log_str", "+=", "\"\\nEpoch %d: Best CIDEr %0.4f\\n\"", "%", "(", "best_epoch", ",", "best_valid", ")", "\n", "\n", "print", "(", "log_str", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "dist", ".", "barrier", "(", ")", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "                ", "self", ".", "save", "(", "\"LAST\"", ")", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "\n", "# Test Set", "\n", "            ", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "args", ".", "output", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "self", ".", "args", ".", "output", ",", "exist_ok", "=", "True", ")", "\n", "", "if", "not", "self", ".", "args", ".", "test_only", ":", "\n", "                ", "best_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output", ",", "'BEST'", ")", "\n", "self", ".", "load", "(", "best_path", ")", "\n", "print", "(", "f'\\nUploaded checkpoint {best_epoch}'", ",", "best_path", ")", "\n", "\n", "", "test_results", "=", "self", ".", "evaluate", "(", "self", ".", "test_loader", ")", "\n", "\n", "log_str", "=", "'Test set results\\n'", "\n", "log_str", "+=", "pformat", "(", "test_results", ")", "\n", "\n", "print", "(", "log_str", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.cococaption.Trainer.predict": [[276, 315], ["cococaption.Trainer.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "tqdm.tqdm.tqdm", "predictions.extend", "cococaption.Trainer.model.module.test_step", "cococaption.Trainer.model.test_step", "targets.extend"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.test_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.test_step"], ["", "", "def", "predict", "(", "self", ",", "loader", ",", "dump_path", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Predict the answers to questions in a data split.\n        :param eval_tuple: The data tuple to be evaluated.\n        :param dump: The path of saved file to dump results.\n        :return: A dict of question_id to answer.\n        \"\"\"", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "            ", "predictions", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "\n", "gen_kwargs", "=", "{", "}", "\n", "gen_kwargs", "[", "'num_beams'", "]", "=", "self", ".", "args", ".", "num_beams", "\n", "gen_kwargs", "[", "'max_length'", "]", "=", "self", ".", "args", ".", "gen_max_length", "\n", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "tqdm", "(", "loader", ",", "ncols", "=", "120", ",", "desc", "=", "\"Prediction\"", ")", ")", ":", "\n", "\n", "                ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "results", "=", "self", ".", "model", ".", "module", ".", "test_step", "(", "\n", "batch", ",", "\n", "**", "gen_kwargs", ")", "\n", "", "else", ":", "\n", "                    ", "results", "=", "self", ".", "model", ".", "test_step", "(", "\n", "batch", ",", "\n", "**", "gen_kwargs", ")", "\n", "\n", "", "predictions", ".", "extend", "(", "results", "[", "'pred'", "]", ")", "\n", "\n", "if", "'targets'", "in", "batch", ":", "\n", "                    ", "targets", ".", "extend", "(", "batch", "[", "'targets'", "]", ")", "\n", "\n", "", "", "results", "=", "{", "\n", "'predictions'", ":", "predictions", ",", "\n", "'targets'", ":", "targets", "\n", "}", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.cococaption.Trainer.evaluate": [[316, 325], ["cococaption.Trainer.predict", "evaluator.evaluate"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.predict", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate"], ["", "", "def", "evaluate", "(", "self", ",", "loader", ",", "dump_path", "=", "None", ")", ":", "\n", "        ", "evaluator", "=", "loader", ".", "evaluator", "\n", "results", "=", "self", ".", "predict", "(", "loader", ",", "dump_path", ")", "\n", "\n", "predictions", "=", "results", "[", "'predictions'", "]", "\n", "if", "dump_path", "is", "None", ":", "\n", "            ", "targets", "=", "results", "[", "'targets'", "]", "\n", "eval_results", "=", "evaluator", ".", "evaluate", "(", "predictions", ",", "targets", ")", "\n", "return", "eval_results", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.cococaption.Trainer.oracle_score": [[326, 340], ["enumerate", "evaluator.evaluate", "label.max", "zip", "label.cpu().numpy", "label.cpu"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate"], ["", "", "@", "staticmethod", "\n", "def", "oracle_score", "(", "loader", ")", ":", "\n", "        ", "evaluator", "=", "loader", ".", "evaluator", "\n", "quesid2ans", "=", "{", "}", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "loader", ")", ":", "\n", "\n", "            ", "ques_id", "=", "batch", "[", "'question_ids'", "]", "\n", "label", "=", "batch", "[", "'targets'", "]", "\n", "\n", "_", ",", "label", "=", "label", ".", "max", "(", "1", ")", "\n", "for", "qid", ",", "l", "in", "zip", "(", "ques_id", ",", "label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ":", "\n", "                ", "ans", "=", "loader", ".", "dataset", ".", "raw_dataset", ".", "label2ans", "[", "l", "]", "\n", "quesid2ans", "[", "qid", "]", "=", "ans", "\n", "", "", "return", "evaluator", ".", "evaluate", "(", "quesid2ans", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.cococaption.main_worker": [[341, 388], ["print", "print", "cococaption_data.get_loader", "cococaption.Trainer", "cococaption.Trainer.train", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.init_process_group", "print", "cococaption_data.get_loader", "print", "print", "cococaption_data.get_loader", "len"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.train", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader"], ["", "", "def", "main_worker", "(", "gpu", ",", "args", ")", ":", "\n", "# GPU is assigned", "\n", "    ", "args", ".", "gpu", "=", "gpu", "\n", "args", ".", "rank", "=", "gpu", "\n", "print", "(", "f'Process Launching at GPU {gpu}'", ")", "\n", "\n", "if", "args", ".", "distributed", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "dist", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "\n", "", "print", "(", "f'Building train loader at GPU {gpu}'", ")", "\n", "train_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "train", ",", "mode", "=", "'train'", ",", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "distributed", "=", "args", ".", "distributed", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "args", ".", "num_workers", ",", "\n", "topk", "=", "args", ".", "train_topk", ",", "\n", ")", "\n", "if", "gpu", "==", "0", ":", "\n", "        ", "if", "args", ".", "valid_batch_size", "is", "not", "None", ":", "\n", "            ", "valid_batch_size", "=", "args", ".", "valid_batch_size", "\n", "", "else", ":", "\n", "            ", "valid_batch_size", "=", "args", ".", "batch_size", "\n", "", "print", "(", "f'Building val loader at GPU {gpu}'", ")", "\n", "val_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "valid", ",", "mode", "=", "'val'", ",", "batch_size", "=", "valid_batch_size", ",", "\n", "distributed", "=", "False", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "4", ",", "\n", "topk", "=", "args", ".", "valid_topk", ",", "\n", ")", "\n", "print", "(", "'# len val loader:'", ",", "len", "(", "val_loader", ")", ")", "\n", "\n", "print", "(", "f'Building test loader at GPU {gpu}'", ")", "\n", "test_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "test", ",", "mode", "=", "'val'", ",", "batch_size", "=", "valid_batch_size", ",", "\n", "distributed", "=", "False", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "4", ",", "\n", "topk", "=", "args", ".", "valid_topk", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "val_loader", "=", "None", "\n", "test_loader", "=", "None", "\n", "\n", "", "trainer", "=", "Trainer", "(", "args", ",", "train_loader", ",", "val_loader", ",", "test_loader", ",", "train", "=", "True", ")", "\n", "trainer", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_model.FewVLMGQA.__init__": [[9, 11], ["modeling_t5.FewVLM.__init__"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_model.FewVLMGQA.train_step": [[12, 44], ["batch[].to", "batch[].to", "batch[].to", "batch[].to", "gqa_model.FewVLMGQA.", "batch[].to.size", "loss.mean.mean.mean", "next", "loss.mean.mean.view", "loss.mean.mean.sum", "lm_mask.sum().clamp", "gqa_model.FewVLMGQA.parameters", "lm_mask.sum"], "methods", ["None"], ["", "def", "train_step", "(", "self", ",", "batch", ")", ":", "\n", "\n", "        ", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "vis_feats", "=", "batch", "[", "'vis_feats'", "]", ".", "to", "(", "device", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", ".", "to", "(", "device", ")", "\n", "vis_pos", "=", "batch", "[", "'boxes'", "]", ".", "to", "(", "device", ")", "\n", "\n", "lm_labels", "=", "batch", "[", "\"target_ids\"", "]", ".", "to", "(", "device", ")", "\n", "\n", "output", "=", "self", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vis_inputs", "=", "(", "vis_feats", ",", "vis_pos", ")", ",", "\n", "labels", "=", "lm_labels", ",", "\n", "return_dict", "=", "True", "\n", ")", "\n", "assert", "'loss'", "in", "output", "\n", "\n", "lm_mask", "=", "lm_labels", "!=", "-", "100", "\n", "B", ",", "L", "=", "lm_labels", ".", "size", "(", ")", "\n", "\n", "loss", "=", "output", "[", "'loss'", "]", "\n", "\n", "loss", "=", "loss", ".", "view", "(", "B", ",", "L", ")", "*", "lm_mask", "\n", "\n", "loss", "=", "loss", ".", "sum", "(", "dim", "=", "1", ")", "/", "lm_mask", ".", "sum", "(", "dim", "=", "1", ")", ".", "clamp", "(", "min", "=", "1", ")", "# B", "\n", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "\n", "result", "=", "{", "\n", "'loss'", ":", "loss", "\n", "}", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_model.FewVLMGQA.test_step": [[45, 64], ["batch[].to", "batch[].to", "batch[].to", "gqa_model.FewVLMGQA.generate", "gqa_model.FewVLMGQA.tokenizer.batch_decode", "next", "gqa_model.FewVLMGQA.parameters"], "methods", ["None"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "**", "kwargs", ")", ":", "\n", "        ", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "vis_feats", "=", "batch", "[", "'vis_feats'", "]", ".", "to", "(", "device", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", ".", "to", "(", "device", ")", "\n", "vis_pos", "=", "batch", "[", "'boxes'", "]", ".", "to", "(", "device", ")", "\n", "\n", "\n", "output", "=", "self", ".", "generate", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vis_inputs", "=", "(", "vis_feats", ",", "vis_pos", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "\n", "generated_sents", "=", "self", ".", "tokenizer", ".", "batch_decode", "(", "output", ",", "skip_special_tokens", "=", "True", ")", "\n", "\n", "result", "=", "{", "}", "\n", "result", "[", "'pred_ans'", "]", "=", "generated_sents", "\n", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.tokenization.FewVLMTokenizer.__init__": [[15, 57], ["transformers.PreTrainedTokenizer.__init__", "sentencepiece.SentencePieceProcessor", "tokenization.FewVLMTokenizer.sp_model.Load", "additional_special_tokens.extend", "len", "range", "set", "ValueError", "filter", "range", "bool"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "vocab_file", ",", "\n", "eos_token", "=", "\"</s>\"", ",", "\n", "unk_token", "=", "\"<unk>\"", ",", "\n", "pad_token", "=", "\"<pad>\"", ",", "\n", "extra_ids", "=", "100", ",", "\n", "vis_extra_ids", "=", "100", ",", "\n", "additional_special_tokens", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "# Add extra_ids to the special token list", "\n", "        ", "if", "extra_ids", ">", "0", "and", "additional_special_tokens", "is", "None", ":", "\n", "            ", "additional_special_tokens", "=", "[", "\"<extra_id_{}>\"", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "extra_ids", ")", "]", "\n", "", "elif", "extra_ids", ">", "0", "and", "additional_special_tokens", "is", "not", "None", ":", "\n", "# Check that we have the right number of extra_id special tokens", "\n", "            ", "extra_tokens", "=", "len", "(", "set", "(", "filter", "(", "lambda", "x", ":", "bool", "(", "\"extra_id\"", "in", "x", ")", ",", "additional_special_tokens", ")", ")", ")", "\n", "if", "extra_tokens", "!=", "extra_ids", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"Both extra_ids ({extra_ids}) and additional_special_tokens ({additional_special_tokens}) are provided to T5Tokenizer. \"", "\n", "\"In this case the additional_special_tokens must include the extra_ids tokens\"", "\n", ")", "\n", "\n", "", "", "if", "vis_extra_ids", ">", "0", ":", "\n", "            ", "additional_special_tokens", ".", "extend", "(", "[", "\"<vis_extra_id_{}>\"", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "vis_extra_ids", ")", "]", ")", "\n", "\n", "", "PreTrainedTokenizer", ".", "__init__", "(", "\n", "self", ",", "\n", "eos_token", "=", "eos_token", ",", "\n", "unk_token", "=", "unk_token", ",", "\n", "pad_token", "=", "pad_token", ",", "\n", "extra_ids", "=", "extra_ids", ",", "\n", "additional_special_tokens", "=", "additional_special_tokens", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "\n", "self", ".", "vocab_file", "=", "vocab_file", "\n", "self", ".", "_extra_ids", "=", "extra_ids", "\n", "self", ".", "_vis_extra_ids", "=", "vis_extra_ids", "\n", "\n", "self", ".", "sp_model", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp_model", ".", "Load", "(", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.tokenization.FewVLMTokenizer.vocab_size": [[58, 61], ["tokenization.FewVLMTokenizer.sp_model.get_piece_size"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sp_model", ".", "get_piece_size", "(", ")", "+", "self", ".", "_extra_ids", "+", "self", ".", "_vis_extra_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.tokenization.FewVLMTokenizer.get_vocab": [[62, 67], ["vocab.update", "tokenization.FewVLMTokenizer.convert_ids_to_tokens", "range"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update"], ["", "def", "get_vocab", "(", "self", ")", ":", "\n", "        ", "vocab", "=", "{", "self", ".", "convert_ids_to_tokens", "(", "\n", "i", ")", ":", "i", "for", "i", "in", "range", "(", "self", ".", "vocab_size", ")", "}", "\n", "vocab", ".", "update", "(", "self", ".", "added_tokens_encoder", ")", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.tokenization.FewVLMTokenizer._convert_token_to_id": [[68, 79], ["token.startswith", "tokenization.FewVLMTokenizer.sp_model.piece_to_id", "re.match", "int", "token.startswith", "re.match.group", "re.match", "int", "re.match.group"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str) in an id using the vocab. \"\"\"", "\n", "if", "token", ".", "startswith", "(", "\"<extra_id_\"", ")", ":", "\n", "            ", "match", "=", "re", ".", "match", "(", "r\"<extra_id_(\\d+)>\"", ",", "token", ")", "\n", "num", "=", "int", "(", "match", ".", "group", "(", "1", ")", ")", "\n", "return", "self", ".", "vocab_size", "-", "num", "-", "1", "-", "self", ".", "_vis_extra_ids", "\n", "", "elif", "token", ".", "startswith", "(", "\"<vis_extra_id_\"", ")", ":", "\n", "            ", "match", "=", "re", ".", "match", "(", "r\"<vis_extra_id_(\\d+)>\"", ",", "token", ")", "\n", "num", "=", "int", "(", "match", ".", "group", "(", "1", ")", ")", "\n", "return", "self", ".", "vocab_size", "-", "num", "-", "1", "\n", "", "return", "self", ".", "sp_model", ".", "piece_to_id", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.tokenization.FewVLMTokenizer._convert_id_to_token": [[80, 90], ["tokenization.FewVLMTokenizer.sp_model.get_piece_size", "tokenization.FewVLMTokenizer.sp_model.IdToPiece", "tokenization.FewVLMTokenizer.sp_model.get_piece_size"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"", "\n", "if", "index", "<", "self", ".", "sp_model", ".", "get_piece_size", "(", ")", ":", "\n", "            ", "token", "=", "self", ".", "sp_model", ".", "IdToPiece", "(", "index", ")", "\n", "", "else", ":", "\n", "            ", "if", "index", ">", "self", ".", "sp_model", ".", "get_piece_size", "(", ")", "+", "self", ".", "_extra_ids", "-", "1", ":", "\n", "                ", "token", "=", "\"<vis_extra_id_{}>\"", ".", "format", "(", "self", ".", "vocab_size", "-", "1", "-", "index", ")", "\n", "", "else", ":", "\n", "                ", "token", "=", "\"<extra_id_{}>\"", ".", "format", "(", "self", ".", "vocab_size", "-", "self", ".", "_vis_extra_ids", "-", "1", "-", "index", ")", "\n", "", "", "return", "token", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.tokenization.FewVLMConverter.vocab": [[100, 111], ["range", "range"], "methods", ["None"], ["    ", "def", "vocab", "(", "self", ",", "proto", ")", ":", "\n", "        ", "vocab", "=", "[", "(", "piece", ".", "piece", ",", "piece", ".", "score", ")", "for", "piece", "in", "proto", ".", "pieces", "]", "\n", "num_extra_ids", "=", "self", ".", "original_tokenizer", ".", "_extra_ids", "\n", "vocab", "+=", "[", "(", "\"<extra_id_{}>\"", ".", "format", "(", "i", ")", ",", "0.0", ")", "\n", "for", "i", "in", "range", "(", "num_extra_ids", "-", "1", ",", "-", "1", ",", "-", "1", ")", "]", "\n", "\n", "num_vis_extra_ids", "=", "self", ".", "original_tokenizer", ".", "_vis_extra_ids", "\n", "vocab", "+=", "[", "(", "\"<vis_extra_id_{}>\"", ".", "format", "(", "i", ")", ",", "0.0", ")", "\n", "for", "i", "in", "range", "(", "num_vis_extra_ids", "-", "1", ",", "-", "1", ",", "-", "1", ")", "]", "\n", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.tokenization.FewVLMConverter.post_processor": [[112, 118], ["tokenizers.processors.TemplateProcessing", "tokenization.FewVLMConverter.original_tokenizer.convert_tokens_to_ids"], "methods", ["None"], ["", "def", "post_processor", "(", "self", ")", ":", "\n", "        ", "return", "processors", ".", "TemplateProcessing", "(", "\n", "single", "=", "[", "\"$A\"", ",", "\"</s>\"", "]", ",", "\n", "pair", "=", "[", "\"$A\"", ",", "\"</s>\"", ",", "\"$B\"", ",", "\"</s>\"", "]", ",", "\n", "special_tokens", "=", "[", "\n", "(", "\"</s>\"", ",", "self", ".", "original_tokenizer", ".", "convert_tokens_to_ids", "(", "\"</s>\"", ")", ")", ",", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.tokenization.FewVLMTokenizerFast.__init__": [[136, 192], ["tokenization.FewVLMTokenizerFast.slow_tokenizer_class", "tokenization.convert_slow_fewvlmtokenizer", "transformers.PreTrainedTokenizerBase.__init__", "additional_special_tokens.extend", "len", "range", "set", "ValueError", "filter", "range", "bool"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.tokenization.convert_slow_fewvlmtokenizer", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_file", ",", "\n", "tokenizer_file", "=", "None", ",", "\n", "eos_token", "=", "\"</s>\"", ",", "\n", "unk_token", "=", "\"<unk>\"", ",", "\n", "pad_token", "=", "\"<pad>\"", ",", "\n", "extra_ids", "=", "100", ",", "\n", "vis_extra_ids", "=", "100", ",", "\n", "additional_special_tokens", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "# Add extra_ids to the special token list", "\n", "        ", "if", "extra_ids", ">", "0", "and", "additional_special_tokens", "is", "None", ":", "\n", "            ", "additional_special_tokens", "=", "[", "\"<extra_id_{}>\"", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "extra_ids", ")", "]", "\n", "", "elif", "extra_ids", ">", "0", "and", "additional_special_tokens", "is", "not", "None", ":", "\n", "# Check that we have the right number of extra_id special tokens", "\n", "            ", "extra_tokens", "=", "len", "(", "set", "(", "filter", "(", "lambda", "x", ":", "bool", "(", "\"extra_id\"", "in", "x", ")", ",", "additional_special_tokens", ")", ")", ")", "\n", "if", "extra_tokens", "!=", "extra_ids", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"Both extra_ids ({extra_ids}) and additional_special_tokens ({additional_special_tokens}) are provided to T5Tokenizer. \"", "\n", "\"In this case the additional_special_tokens must include the extra_ids tokens\"", "\n", ")", "\n", "\n", "", "", "if", "vis_extra_ids", ">", "0", ":", "\n", "            ", "additional_special_tokens", ".", "extend", "(", "[", "\"<vis_extra_id_{}>\"", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "vis_extra_ids", ")", "]", ")", "\n", "\n", "", "slow_tokenizer", "=", "self", ".", "slow_tokenizer_class", "(", "\n", "vocab_file", ",", "\n", "tokenizer_file", "=", "tokenizer_file", ",", "\n", "eos_token", "=", "eos_token", ",", "\n", "unk_token", "=", "unk_token", ",", "\n", "pad_token", "=", "pad_token", ",", "\n", "extra_ids", "=", "extra_ids", ",", "\n", "vis_extra_ids", "=", "vis_extra_ids", ",", "\n", "# additional_special_tokens=additional_special_tokens,", "\n", "**", "kwargs", "\n", ")", "\n", "fast_tokenizer", "=", "convert_slow_fewvlmtokenizer", "(", "slow_tokenizer", ")", "\n", "self", ".", "_tokenizer", "=", "fast_tokenizer", "\n", "\n", "PreTrainedTokenizerBase", ".", "__init__", "(", "\n", "self", ",", "\n", "tokenizer_file", "=", "tokenizer_file", ",", "\n", "eos_token", "=", "eos_token", ",", "\n", "unk_token", "=", "unk_token", ",", "\n", "pad_token", "=", "pad_token", ",", "\n", "extra_ids", "=", "extra_ids", ",", "\n", "vis_extra_ids", "=", "vis_extra_ids", ",", "\n", "additional_special_tokens", "=", "additional_special_tokens", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "\n", "self", ".", "vocab_file", "=", "vocab_file", "\n", "self", ".", "_extra_ids", "=", "extra_ids", "\n", "self", ".", "_vis_extra_ids", "=", "vis_extra_ids", "\n", "", "", ""]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.tokenization.convert_slow_fewvlmtokenizer": [[122, 124], ["FewVLMConverter().converted", "tokenization.FewVLMConverter"], "function", ["None"], ["", "", "def", "convert_slow_fewvlmtokenizer", "(", "fewvlmtokenizer", ")", ":", "\n", "    ", "return", "FewVLMConverter", "(", "fewvlmtokenizer", ")", ".", "converted", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain.Trainer.__init__": [[44, 109], ["trainer_base.TrainerBase.__init__", "pretrain.Trainer.create_config", "pretrain.Trainer.create_tokenizer", "pretrain.Trainer.create_model", "print", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "pretrain.Trainer.model.to", "print", "print", "pretrain.Trainer.model.resize_token_embeddings", "pretrain.Trainer.load_checkpoint", "int", "pretrain.Trainer.init_weights", "time", "pretrain.count_parameters", "sum", "pretrain.Trainer.create_optimizer_and_scheduler", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "print", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "args.load.split", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "p.numel", "amp.initialize", "pretrain.Trainer.model.parameters", "time"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_config", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_tokenizer", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_model", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load_checkpoint", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.init_weights", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.count_parameters", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_optimizer_and_scheduler"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "train_loader", "=", "None", ",", "val_loader", "=", "None", ",", "test_loader", "=", "None", ",", "train", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "args", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "test_loader", "=", "test_loader", ",", "\n", "train", "=", "train", ")", "\n", "\n", "from", "pretrain_model", "import", "FewVLMPretraining", "\n", "\n", "model_kwargs", "=", "{", "}", "\n", "if", "'t5'", "in", "args", ".", "backbone", ":", "\n", "            ", "model_class", "=", "FewVLMPretraining", "\n", "\n", "", "config", "=", "self", ".", "create_config", "(", ")", "\n", "self", ".", "tokenizer", "=", "self", ".", "create_tokenizer", "(", ")", "\n", "\n", "\n", "self", ".", "model", "=", "self", ".", "create_model", "(", "model_class", ",", "config", ",", "**", "model_kwargs", ")", "\n", "\n", "if", "'t5'", "in", "self", ".", "args", ".", "tokenizer", ":", "\n", "            ", "self", ".", "model", ".", "resize_token_embeddings", "(", "self", ".", "tokenizer", ".", "vocab_size", ")", "\n", "\n", "", "self", ".", "model", ".", "tokenizer", "=", "self", ".", "tokenizer", "\n", "\n", "# Load Checkpoint", "\n", "self", ".", "start_epoch", "=", "None", "\n", "if", "args", ".", "load", "is", "not", "None", ":", "\n", "            ", "ckpt_path", "=", "args", ".", "load", "+", "'.pth'", "\n", "self", ".", "load_checkpoint", "(", "ckpt_path", ")", "\n", "self", ".", "start_epoch", "=", "int", "(", "args", ".", "load", ".", "split", "(", "'Epoch'", ")", "[", "-", "1", "]", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "from_scratch", ":", "\n", "            ", "self", ".", "init_weights", "(", ")", "\n", "\n", "# GPU Options", "\n", "", "print", "(", "f'Model Launching at GPU {self.args.gpu}'", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "from", "time", "import", "time", "\n", "start", "=", "time", "(", ")", "\n", "\n", "", "device", "=", "torch", ".", "device", "(", "f'cuda:{torch.cuda.current_device()}'", ")", "\n", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "device", ")", "\n", "\n", "print", "(", "\"num grad param:\"", ",", "count_parameters", "(", "self", ".", "model", ")", ")", "\n", "print", "(", "\"num total elements:\"", ",", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", ")", ")", "\n", "\n", "\n", "# Optimizer", "\n", "if", "train", ":", "\n", "            ", "self", ".", "optim", ",", "self", ".", "lr_scheduler", "=", "self", ".", "create_optimizer_and_scheduler", "(", ")", "\n", "\n", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                ", "self", ".", "scaler", "=", "torch", ".", "cuda", ".", "amp", ".", "GradScaler", "(", ")", "\n", "", "elif", "_use_apex", ":", "\n", "                ", "self", ".", "model", ",", "self", ".", "optim", "=", "amp", ".", "initialize", "(", "\n", "self", ".", "model", ",", "self", ".", "optim", ",", "opt_level", "=", "'O1'", ",", "verbosity", "=", "self", ".", "verbose", ")", "\n", "\n", "\n", "", "", "if", "args", ".", "distributed", ":", "\n", "            ", "self", ".", "model", "=", "DDP", "(", "self", ".", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", "\n", ")", "\n", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "f'It took {time() - start:.1f}s'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain.Trainer.train": [[110, 302], ["enumerate", "pretrain.Trainer.evaluate_epoch", "wandb.init", "wandb.config.update", "wandb.watch", "str", "str", "wandb.save", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "range", "pretrain.Trainer.model.train", "enumerate", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "dist_utils.reduce_dict", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "pretrain.Trainer.evaluate_epoch", "dist_utils.reduce_dict", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "wandb.log", "utils.LossMeter", "pathlib.Path().resolve", "os.path.join", "pretrain.Trainer.train_loader.sampler.set_epoch", "tqdm.tqdm.tqdm", "loss.detach.detach.detach", "pretrain.Trainer.items", "tqdm.tqdm.tqdm.close", "pretrain.Trainer.items", "print", "dist_utils.reduce_dict.items", "print", "pretrain.Trainer.save", "range", "pretrain.Trainer.scaler.scale().backward", "pretrain.Trainer.model.parameters", "enumerate", "tqdm.tqdm.tqdm.set_description", "tqdm.tqdm.tqdm.update", "len", "pathlib.Path", "len", "autocast", "pretrain.Trainer.model.module.train_step", "pretrain.Trainer.model.train_step", "loss.detach.detach.backward", "pretrain.Trainer.scaler.step", "pretrain.Trainer.scaler.update", "pretrain.Trainer.optim.step", "pretrain.Trainer.lr_scheduler.step", "packaging.version.parse", "packaging.version.parse", "isinstance", "zip", "int", "int", "pretrain.Trainer.model.module.train_step", "pretrain.Trainer.model.train_step", "pretrain.Trainer.scaler.scale", "amp.scale_loss", "scaled_loss.backward", "pretrain.Trainer.scaler.unscale_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "pretrain.Trainer.lr_scheduler.get_last_lr", "pretrain.Trainer.lr_scheduler.get_lr", "pretrain.Trainer.optim.get_lr", "isinstance", "loss_meter.update", "len", "wandb.log", "wandb.log", "pretrain.Trainer.model.parameters", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "v.item", "amp.master_params", "pretrain.Trainer.model.parameters"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain.Trainer.evaluate_epoch", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.train", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.reduce_dict", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain.Trainer.evaluate_epoch", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.reduce_dict", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update"], ["", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "LOSSES_NAME", "=", "self", ".", "args", ".", "LOSSES_NAME", "\n", "\n", "if", "self", ".", "args", ".", "dry", ":", "\n", "            ", "results", "=", "self", ".", "evaluate_epoch", "(", "epoch", "=", "0", ")", "\n", "\n", "", "if", "self", ".", "verbose", ":", "\n", "            ", "loss_meters", "=", "[", "LossMeter", "(", ")", "for", "_", "in", "range", "(", "len", "(", "LOSSES_NAME", ")", ")", "]", "\n", "best_eval_loss", "=", "9595.", "\n", "\n", "if", "'t5'", "in", "self", ".", "args", ".", "backbone", ":", "\n", "                ", "project_name", "=", "\"FewVLM_Pretrain\"", "\n", "\n", "", "wandb", ".", "init", "(", "project", "=", "project_name", ")", "\n", "wandb", ".", "run", ".", "name", "=", "self", ".", "args", ".", "run_name", "\n", "wandb", ".", "config", ".", "update", "(", "self", ".", "args", ")", "\n", "wandb", ".", "watch", "(", "self", ".", "model", ")", "\n", "\n", "src_dir", "=", "Path", "(", "__file__", ")", ".", "resolve", "(", ")", ".", "parent", "\n", "base_path", "=", "str", "(", "src_dir", ".", "parent", ")", "\n", "src_dir", "=", "str", "(", "src_dir", ")", "\n", "wandb", ".", "save", "(", "os", ".", "path", ".", "join", "(", "src_dir", "+", "\"/*.py\"", ")", ",", "base_path", "=", "base_path", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "global_step", "=", "0", "\n", "for", "step", ",", "epoch", "in", "enumerate", "(", "range", "(", "self", ".", "args", ".", "epochs", ")", ")", ":", "\n", "            ", "if", "self", ".", "start_epoch", "is", "not", "None", ":", "\n", "                ", "epoch", "+=", "self", ".", "start_epoch", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                ", "self", ".", "train_loader", ".", "sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "\n", "# Train", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "self", ".", "train_loader", ")", ",", "ncols", "=", "250", ")", "\n", "\n", "", "epoch_results", "=", "{", "}", "\n", "for", "loss_name", "in", "LOSSES_NAME", ":", "\n", "                ", "epoch_results", "[", "loss_name", "]", "=", "0.", "\n", "epoch_results", "[", "f'{loss_name}_count'", "]", "=", "0", "\n", "\n", "", "for", "step_i", ",", "batch", "in", "enumerate", "(", "self", ".", "train_loader", ")", ":", "\n", "\n", "                ", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                    ", "with", "autocast", "(", ")", ":", "\n", "                        ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                            ", "results", "=", "self", ".", "model", ".", "module", ".", "train_step", "(", "batch", ")", "\n", "", "else", ":", "\n", "                            ", "results", "=", "self", ".", "model", ".", "train_step", "(", "batch", ")", "\n", "", "", "", "else", ":", "\n", "                    ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                        ", "results", "=", "self", ".", "model", ".", "module", ".", "train_step", "(", "batch", ")", "\n", "", "else", ":", "\n", "                        ", "results", "=", "self", ".", "model", ".", "train_step", "(", "batch", ")", "\n", "\n", "", "", "loss", "=", "results", "[", "'loss'", "]", "\n", "\n", "if", "self", ".", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                    ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                    ", "self", ".", "scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "", "elif", "self", ".", "args", ".", "fp16", "and", "_use_apex", ":", "\n", "                    ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "self", ".", "optim", ")", "as", "scaled_loss", ":", "\n", "                        ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                    ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "loss", "=", "loss", ".", "detach", "(", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "self", ".", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "# Update Parameters", "\n", "                    ", "if", "self", ".", "args", ".", "clip_grad_norm", ">", "0", ":", "\n", "                        ", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                            ", "self", ".", "scaler", ".", "unscale_", "(", "self", ".", "optim", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "", "elif", "self", ".", "args", ".", "fp16", "and", "_use_apex", ":", "\n", "                            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "self", ".", "optim", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "", "else", ":", "\n", "                            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "\n", "", "", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                        ", "self", ".", "scaler", ".", "step", "(", "self", ".", "optim", ")", "\n", "self", ".", "scaler", ".", "update", "(", ")", "\n", "", "else", ":", "\n", "                        ", "self", ".", "optim", ".", "step", "(", ")", "\n", "\n", "", "if", "self", ".", "lr_scheduler", ":", "\n", "                        ", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "\n", "# self.model.zero_grad()", "\n", "", "for", "param", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "                        ", "param", ".", "grad", "=", "None", "\n", "\n", "", "global_step", "+=", "1", "\n", "\n", "", "if", "self", ".", "lr_scheduler", ":", "\n", "                    ", "if", "version", ".", "parse", "(", "torch", ".", "__version__", ")", ">=", "version", ".", "parse", "(", "\"1.4\"", ")", ":", "\n", "                        ", "lr", "=", "self", ".", "lr_scheduler", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                        ", "lr", "=", "self", ".", "lr_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "", "", "else", ":", "\n", "                    ", "try", ":", "\n", "                        ", "lr", "=", "self", ".", "optim", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "", "except", "AttributeError", ":", "\n", "                        ", "lr", "=", "self", ".", "args", ".", "lr", "\n", "\n", "", "", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", ":", "\n", "                    ", "if", "k", "in", "epoch_results", ":", "\n", "                        ", "if", "isinstance", "(", "v", ",", "int", ")", ":", "\n", "                            ", "epoch_results", "[", "k", "]", "+=", "v", "\n", "", "elif", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                            ", "epoch_results", "[", "k", "]", "+=", "v", ".", "item", "(", ")", "\n", "\n", "", "", "", "if", "self", ".", "verbose", ":", "\n", "                    ", "desc_str", "=", "f'Epoch {epoch} | LR {lr:.6f} |'", "\n", "\n", "for", "i", ",", "(", "loss_name", ",", "loss_meter", ")", "in", "enumerate", "(", "zip", "(", "LOSSES_NAME", ",", "loss_meters", ")", ")", ":", "\n", "\n", "                        ", "if", "loss_name", "in", "results", ":", "\n", "                            ", "loss_meter", ".", "update", "(", "results", "[", "f'{loss_name}'", "]", "/", "results", "[", "f'{loss_name}_count'", "]", ")", "\n", "", "if", "len", "(", "loss_meter", ")", ">", "0", ":", "\n", "                            ", "loss_count", "=", "epoch_results", "[", "f'{loss_name}_count'", "]", "\n", "desc_str", "+=", "f' {loss_name} ({loss_count}) {loss_meter.val:.3f}'", "\n", "\n", "", "", "pbar", ".", "set_description", "(", "desc_str", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "                ", "pbar", ".", "close", "(", ")", "\n", "\n", "", "dist", ".", "barrier", "(", ")", "\n", "\n", "results", "=", "reduce_dict", "(", "epoch_results", ",", "average", "=", "False", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "train_loss", "=", "results", "[", "'total_loss'", "]", "\n", "train_loss_count", "=", "results", "[", "'total_loss_count'", "]", "\n", "\n", "avg_train_loss", "=", "train_loss", "/", "train_loss_count", "\n", "losses_str", "=", "f\"Train Loss: {avg_train_loss:.3f}\\n\"", "\n", "\n", "for", "name", ",", "loss", "in", "results", ".", "items", "(", ")", ":", "\n", "                    ", "if", "name", "[", "-", "4", ":", "]", "==", "'loss'", ":", "\n", "                        ", "loss_count", "=", "int", "(", "results", "[", "name", "+", "'_count'", "]", ")", "\n", "if", "loss_count", ">", "0", ":", "\n", "                            ", "avg_loss", "=", "loss", "/", "loss_count", "\n", "losses_str", "+=", "f\"{name} ({loss_count}): {avg_loss:.3f} \"", "\n", "wandb", ".", "log", "(", "{", "f'Train Loss/{name}'", ":", "avg_loss", "}", ",", "step", "=", "epoch", ")", "\n", "\n", "", "", "", "losses_str", "+=", "'\\n'", "\n", "print", "(", "losses_str", ")", "\n", "\n", "", "dist", ".", "barrier", "(", ")", "\n", "\n", "# Validation", "\n", "valid_results", ",", "valid_uid2ans", "=", "self", ".", "evaluate_epoch", "(", "epoch", "=", "epoch", ")", "\n", "\n", "valid_results", "=", "reduce_dict", "(", "valid_results", ",", "average", "=", "False", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "valid_loss", "=", "valid_results", "[", "'total_loss'", "]", "\n", "valid_loss_count", "=", "valid_results", "[", "'total_loss_count'", "]", "\n", "\n", "avg_valid_loss", "=", "valid_loss", "/", "valid_loss_count", "\n", "losses_str", "=", "f\"Valid Loss: {avg_valid_loss:.3f}\\n\"", "\n", "\n", "for", "name", ",", "loss", "in", "valid_results", ".", "items", "(", ")", ":", "\n", "                    ", "if", "name", "[", "-", "4", ":", "]", "==", "'loss'", ":", "\n", "                        ", "loss_count", "=", "int", "(", "valid_results", "[", "name", "+", "'_count'", "]", ")", "\n", "if", "loss_count", ">", "0", ":", "\n", "                            ", "avg_loss", "=", "loss", "/", "loss_count", "\n", "losses_str", "+=", "f\"{name} ({loss_count}): {avg_loss:.3f} \"", "\n", "wandb", ".", "log", "(", "{", "f'Valid Loss/{name}'", ":", "avg_loss", "}", ",", "step", "=", "epoch", ")", "\n", "\n", "", "", "", "losses_str", "+=", "'\\n'", "\n", "print", "(", "losses_str", ")", "\n", "\n", "", "dist", ".", "barrier", "(", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "# Save", "\n", "                ", "if", "avg_valid_loss", "<", "best_eval_loss", ":", "\n", "                    ", "best_eval_loss", "=", "avg_valid_loss", "\n", "#     self.save(\"BEST_EVAL_LOSS\")", "\n", "", "self", ".", "save", "(", "\"Epoch%02d\"", "%", "(", "epoch", "+", "1", ")", ")", "\n", "\n", "", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "if", "self", ".", "verbose", ":", "\n", "            ", "wandb", ".", "log", "(", "{", "'finished'", ":", "True", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain.Trainer.evaluate_epoch": [[303, 355], ["pretrain.Trainer.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "utils.LossMeter", "tqdm.tqdm.tqdm", "pretrain.Trainer.items", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "tqdm.tqdm.tqdm.close", "utils.LossMeter", "pretrain.Trainer.model.module.valid_step", "pretrain.Trainer.model.valid_step", "enumerate", "tqdm.tqdm.tqdm.set_description", "tqdm.tqdm.tqdm.update", "range", "len", "isinstance", "zip", "len", "isinstance", "utils.LossMeter.update", "len", "v.item"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_model.FewVLMPretraining.valid_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_model.FewVLMPretraining.valid_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update"], ["", "", "def", "evaluate_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "LOSSES_NAME", "=", "self", ".", "args", ".", "LOSSES_NAME", "\n", "\n", "epoch_results", "=", "{", "}", "\n", "for", "loss_name", "in", "LOSSES_NAME", ":", "\n", "            ", "epoch_results", "[", "loss_name", "]", "=", "0.", "\n", "epoch_results", "[", "f'{loss_name}_count'", "]", "=", "0", "\n", "\n", "", "uid2ans", "=", "{", "}", "\n", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "self", ".", "verbose", ":", "\n", "                ", "loss_meter", "=", "LossMeter", "(", ")", "\n", "loss_meters", "=", "[", "LossMeter", "(", ")", "for", "_", "in", "range", "(", "len", "(", "LOSSES_NAME", ")", ")", "]", "\n", "\n", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "self", ".", "val_loader", ")", ",", "ncols", "=", "250", ")", "\n", "\n", "", "for", "step_i", ",", "batch", "in", "enumerate", "(", "self", ".", "val_loader", ")", ":", "\n", "\n", "                ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "results", "=", "self", ".", "model", ".", "module", ".", "valid_step", "(", "batch", ")", "\n", "", "else", ":", "\n", "                    ", "results", "=", "self", ".", "model", ".", "valid_step", "(", "batch", ")", "\n", "\n", "\n", "", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", ":", "\n", "                    ", "if", "k", "in", "epoch_results", ":", "\n", "                        ", "if", "isinstance", "(", "v", ",", "int", ")", ":", "\n", "                            ", "epoch_results", "[", "k", "]", "+=", "v", "\n", "", "elif", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                            ", "epoch_results", "[", "k", "]", "+=", "v", ".", "item", "(", ")", "\n", "\n", "", "", "", "if", "self", ".", "verbose", ":", "\n", "                    ", "desc_str", "=", "f'Valid Epoch {epoch} |'", "\n", "for", "i", ",", "(", "loss_name", ",", "loss_meter", ")", "in", "enumerate", "(", "zip", "(", "LOSSES_NAME", ",", "loss_meters", ")", ")", ":", "\n", "\n", "                        ", "if", "loss_name", "in", "results", ":", "\n", "                            ", "loss_meter", ".", "update", "(", "results", "[", "f'{loss_name}'", "]", "/", "results", "[", "f'{loss_name}_count'", "]", ")", "\n", "", "if", "len", "(", "loss_meter", ")", ">", "0", ":", "\n", "                            ", "loss_count", "=", "epoch_results", "[", "f'{loss_name}_count'", "]", "\n", "desc_str", "+=", "f' {loss_name} ({loss_count}) {loss_meter.val:.3f}'", "\n", "\n", "", "", "pbar", ".", "set_description", "(", "desc_str", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                ", "pbar", ".", "close", "(", ")", "\n", "", "dist", ".", "barrier", "(", ")", "\n", "\n", "return", "epoch_results", ",", "uid2ans", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain.count_parameters": [[40, 42], ["sum", "p.numel", "model.parameters"], "function", ["None"], ["def", "count_parameters", "(", "model", ")", ":", "\n", "    ", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain.main_worker": [[356, 386], ["print", "print", "pretrain_data.get_loader", "print", "pretrain_data.get_loader", "pretrain.Trainer", "pretrain.Trainer.train", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.init_process_group"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.train"], ["", "", "", "def", "main_worker", "(", "gpu", ",", "args", ")", ":", "\n", "# GPU is assigned", "\n", "    ", "args", ".", "gpu", "=", "gpu", "\n", "args", ".", "rank", "=", "gpu", "\n", "print", "(", "f'Process Launching at GPU {gpu}'", ")", "\n", "\n", "if", "args", ".", "distributed", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "dist", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "\n", "\n", "", "print", "(", "f'Building train loader at GPU {gpu}'", ")", "\n", "train_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "train", ",", "mode", "=", "'train'", ",", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "distributed", "=", "args", ".", "distributed", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "args", ".", "num_workers", ",", "\n", "topk", "=", "args", ".", "train_topk", ",", ")", "\n", "\n", "print", "(", "f'Building val loader at GPU {gpu}'", ")", "\n", "val_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "valid", ",", "mode", "=", "'val'", ",", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "distributed", "=", "args", ".", "distributed", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "args", ".", "num_workers", ",", "\n", "topk", "=", "args", ".", "valid_topk", ",", ")", "\n", "\n", "trainer", "=", "Trainer", "(", "args", ",", "train_loader", ",", "val_loader", ",", "train", "=", "True", ")", "\n", "\n", "trainer", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa.Trainer.__init__": [[50, 112], ["trainer_base.TrainerBase.__init__", "vqa.Trainer.create_config", "vqa.Trainer.create_tokenizer", "vqa.Trainer.create_model", "print", "vqa.Trainer.model.to", "print", "print", "utils.set_global_logging_level", "vqa.Trainer.model.resize_token_embeddings", "vqa.Trainer.load_checkpoint", "vqa.Trainer.init_weights", "time", "vqa.count_parameters", "sum", "vqa.Trainer.create_optimizer_and_scheduler", "print", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "p.numel", "amp.initialize", "vqa.Trainer.model.parameters", "time"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_config", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_tokenizer", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_model", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.set_global_logging_level", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load_checkpoint", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.init_weights", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.count_parameters", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_optimizer_and_scheduler"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "train_loader", "=", "None", ",", "val_loader", "=", "None", ",", "test_loader", "=", "None", ",", "train", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "args", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "test_loader", "=", "test_loader", ",", "\n", "train", "=", "train", ")", "\n", "\n", "if", "not", "self", ".", "verbose", ":", "\n", "            ", "set_global_logging_level", "(", "logging", ".", "ERROR", ",", "[", "\"transformers\"", "]", ")", "\n", "\n", "", "from", "vqa_model", "import", "FewVLMVQA", "\n", "\n", "model_kwargs", "=", "{", "}", "\n", "if", "'t5'", "in", "args", ".", "backbone", ":", "\n", "            ", "model_class", "=", "FewVLMVQA", "\n", "\n", "", "config", "=", "self", ".", "create_config", "(", ")", "\n", "self", ".", "tokenizer", "=", "self", ".", "create_tokenizer", "(", ")", "\n", "\n", "self", ".", "model", "=", "self", ".", "create_model", "(", "model_class", ",", "config", ",", "**", "model_kwargs", ")", "\n", "\n", "if", "'t5'", "in", "self", ".", "args", ".", "tokenizer", ":", "\n", "            ", "self", ".", "model", ".", "resize_token_embeddings", "(", "self", ".", "tokenizer", ".", "vocab_size", ")", "\n", "\n", "", "self", ".", "model", ".", "tokenizer", "=", "self", ".", "tokenizer", "\n", "\n", "# Load Checkpoint", "\n", "self", ".", "start_epoch", "=", "None", "\n", "if", "args", ".", "load", "is", "not", "None", ":", "\n", "            ", "ckpt_path", "=", "args", ".", "load", "+", "'.pth'", "\n", "self", ".", "load_checkpoint", "(", "ckpt_path", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "from_scratch", ":", "\n", "            ", "self", ".", "init_weights", "(", ")", "\n", "\n", "# GPU Options", "\n", "", "print", "(", "f'Model Launching at GPU {self.args.gpu}'", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "from", "time", "import", "time", "\n", "start", "=", "time", "(", ")", "\n", "", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "args", ".", "gpu", ")", "\n", "print", "(", "\"num grad param:\"", ",", "count_parameters", "(", "self", ".", "model", ")", ")", "\n", "print", "(", "\"num total elements:\"", ",", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", ")", ")", "\n", "\n", "# Optimizer", "\n", "if", "train", ":", "\n", "            ", "self", ".", "optim", ",", "self", ".", "lr_scheduler", "=", "self", ".", "create_optimizer_and_scheduler", "(", ")", "\n", "\n", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                ", "self", ".", "scaler", "=", "torch", ".", "cuda", ".", "amp", ".", "GradScaler", "(", ")", "\n", "", "elif", "_use_apex", ":", "\n", "                ", "self", ".", "model", ",", "self", ".", "optim", "=", "amp", ".", "initialize", "(", "\n", "self", ".", "model", ",", "self", ".", "optim", ",", "opt_level", "=", "'O1'", ",", "verbosity", "=", "self", ".", "verbose", ")", "\n", "\n", "", "", "if", "args", ".", "multiGPU", ":", "\n", "            ", "if", "args", ".", "distributed", ":", "\n", "                ", "self", ".", "model", "=", "DDP", "(", "self", ".", "model", ",", "device_ids", "=", "[", "args", ".", "gpu", "]", ",", "\n", "find_unused_parameters", "=", "True", "\n", ")", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "f'It took {time() - start:.1f}s'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa.Trainer.train": [[114, 286], ["vqa.Trainer.predict", "utils.LossMeter", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "range", "os.path.join", "vqa.Trainer.load", "evaluator.evaluate", "evaluator.dump_result", "evaluator.evaluate_raw", "evaluator.evaluate_raw", "evaluator.evaluate_raw", "acc_dict_all[].items", "acc_dict_all[].items", "print", "os.path.join", "vqa.Trainer.predict", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "exit", "vqa.Trainer.model.train", "enumerate", "vqa.Trainer.evaluate", "vqa.Trainer.save", "os.path.isdir", "os.makedirs", "vqa.Trainer.train_loader.sampler.set_epoch", "tqdm.tqdm.tqdm", "loss.detach.detach.detach", "vqa.Trainer.model.parameters", "vqa.Trainer.items", "tqdm.tqdm.tqdm.close", "print", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "vqa.Trainer.scaler.scale().backward", "vqa.Trainer.scaler.step", "vqa.Trainer.scaler.update", "vqa.Trainer.optim.step", "vqa.Trainer.lr_scheduler.step", "utils.LossMeter.update", "tqdm.tqdm.tqdm.set_description", "tqdm.tqdm.tqdm.update", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "vqa.Trainer.save", "len", "autocast", "vqa.Trainer.model.module.train_step", "vqa.Trainer.model.train_step", "loss.detach.detach.backward", "vqa.Trainer.scaler.unscale_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "v.item", "packaging.version.parse", "packaging.version.parse", "loss.detach.detach.item", "vqa.Trainer.model.module.train_step", "vqa.Trainer.model.train_step", "vqa.Trainer.scaler.scale", "amp.scale_loss", "scaled_loss.backward", "vqa.Trainer.model.parameters", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "vqa.Trainer.lr_scheduler.get_last_lr", "vqa.Trainer.lr_scheduler.get_lr", "vqa.Trainer.optim.get_lr", "amp.master_params", "vqa.Trainer.model.parameters"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.predict", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAEvaluator.dump_result", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.evaluate_raw", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.evaluate_raw", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.evaluate_raw", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.predict", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.train", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step"], ["", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "verbose", ":", "\n", "            ", "loss_meter", "=", "LossMeter", "(", ")", "\n", "best_valid", "=", "0.", "\n", "best_epoch", "=", "0", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "global_step", "=", "0", "\n", "if", "not", "self", ".", "args", ".", "test_only", ":", "\n", "            ", "for", "epoch", "in", "range", "(", "self", ".", "args", ".", "epochs", ")", ":", "\n", "                ", "if", "self", ".", "start_epoch", "is", "not", "None", ":", "\n", "                    ", "epoch", "+=", "self", ".", "start_epoch", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "self", ".", "train_loader", ".", "sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                    ", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "self", ".", "train_loader", ")", ",", "ncols", "=", "120", ")", "\n", "\n", "", "epoch_results", "=", "{", "\n", "'loss'", ":", "0.", ",", "\n", "\n", "}", "\n", "\n", "quesid2ans", "=", "{", "}", "\n", "\n", "for", "step_i", ",", "batch", "in", "enumerate", "(", "self", ".", "train_loader", ")", ":", "\n", "\n", "                    ", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                        ", "with", "autocast", "(", ")", ":", "\n", "                            ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                                ", "results", "=", "self", ".", "model", ".", "module", ".", "train_step", "(", "batch", ")", "\n", "", "else", ":", "\n", "                                ", "results", "=", "self", ".", "model", ".", "train_step", "(", "batch", ")", "\n", "", "", "", "else", ":", "\n", "                        ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                            ", "results", "=", "self", ".", "model", ".", "module", ".", "train_step", "(", "batch", ")", "\n", "", "else", ":", "\n", "                            ", "results", "=", "self", ".", "model", ".", "train_step", "(", "batch", ")", "\n", "\n", "", "", "loss", "=", "results", "[", "'loss'", "]", "\n", "\n", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                        ", "self", ".", "scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "", "elif", "self", ".", "args", ".", "fp16", "and", "_use_apex", ":", "\n", "                        ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "self", ".", "optim", ")", "as", "scaled_loss", ":", "\n", "                            ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                        ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "loss", "=", "loss", ".", "detach", "(", ")", "\n", "\n", "# Update Parameters", "\n", "if", "self", ".", "args", ".", "clip_grad_norm", ">", "0", ":", "\n", "                        ", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                            ", "self", ".", "scaler", ".", "unscale_", "(", "self", ".", "optim", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "", "elif", "self", ".", "args", ".", "fp16", "and", "_use_apex", ":", "\n", "                            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "\n", "self", ".", "optim", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "", "else", ":", "\n", "                            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "\n", "", "", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                        ", "self", ".", "scaler", ".", "step", "(", "self", ".", "optim", ")", "\n", "self", ".", "scaler", ".", "update", "(", ")", "\n", "", "else", ":", "\n", "                        ", "self", ".", "optim", ".", "step", "(", ")", "\n", "\n", "", "if", "self", ".", "lr_scheduler", ":", "\n", "                        ", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "", "for", "param", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "                        ", "param", ".", "grad", "=", "None", "\n", "\n", "", "global_step", "+=", "1", "\n", "\n", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", ":", "\n", "                        ", "if", "k", "in", "epoch_results", ":", "\n", "                            ", "epoch_results", "[", "k", "]", "+=", "v", ".", "item", "(", ")", "\n", "\n", "", "", "if", "self", ".", "lr_scheduler", ":", "\n", "                        ", "if", "version", ".", "parse", "(", "torch", ".", "__version__", ")", ">=", "version", ".", "parse", "(", "\"1.4\"", ")", ":", "\n", "                            ", "lr", "=", "self", ".", "lr_scheduler", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                            ", "lr", "=", "self", ".", "lr_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "", "", "else", ":", "\n", "                        ", "try", ":", "\n", "                            ", "lr", "=", "self", ".", "optim", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "", "except", "AttributeError", ":", "\n", "                            ", "lr", "=", "self", ".", "args", ".", "lr", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "                        ", "loss_meter", ".", "update", "(", "loss", ".", "item", "(", ")", ")", "\n", "desc_str", "=", "f'Epoch {epoch} | LR {lr:.6f}'", "\n", "desc_str", "+=", "f' | Loss {loss_meter.val:4f}'", "\n", "\n", "pbar", ".", "set_description", "(", "desc_str", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                        ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "                    ", "pbar", ".", "close", "(", ")", "\n", "\n", "# Validation", "\n", "", "score_dict", "=", "self", ".", "evaluate", "(", "self", ".", "val_loader", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "                    ", "valid_score", "=", "score_dict", "[", "'topk_score'", "]", "*", "100.", "\n", "valid_score_raw", "=", "score_dict", "[", "'overall'", "]", "\n", "if", "valid_score_raw", ">=", "best_valid", "or", "epoch", "==", "0", ":", "\n", "                        ", "best_valid", "=", "valid_score_raw", "\n", "best_epoch", "=", "epoch", "\n", "self", ".", "save", "(", "\"BEST\"", ")", "\n", "\n", "", "log_str", "=", "''", "\n", "log_str", "+=", "\"\\nEpoch %d: Valid Raw %0.2f Topk %0.2f\"", "%", "(", "epoch", ",", "valid_score_raw", ",", "valid_score", ")", "\n", "log_str", "+=", "\"\\nEpoch %d: Best Raw %0.2f\\n\"", "%", "(", "best_epoch", ",", "best_valid", ")", "\n", "\n", "print", "(", "log_str", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "                ", "self", ".", "save", "(", "\"LAST\"", ")", "\n", "\n", "", "", "if", "not", "self", ".", "args", ".", "test_only", ":", "\n", "            ", "best_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output", ",", "'BEST'", ")", "\n", "# best_path = os.path.join(self.args.output, 'LAST')", "\n", "\n", "self", ".", "load", "(", "best_path", ")", "\n", "\n", "", "quesid2ans", "=", "self", ".", "predict", "(", "self", ".", "test_loader", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "evaluator", "=", "self", ".", "test_loader", ".", "evaluator", "\n", "score_dict", "=", "evaluator", ".", "evaluate", "(", "quesid2ans", ")", "\n", "\n", "evaluator", ".", "dump_result", "(", "quesid2ans", ",", "'result.txt'", ")", "\n", "\n", "acc_dict_all", "=", "evaluator", ".", "evaluate_raw", "(", "quesid2ans", ")", "\n", "acc_dict_answerable", "=", "evaluator", ".", "evaluate_raw", "(", "quesid2ans", ",", "is_topk_optimal", "=", "True", ")", "\n", "acc_dict_unanswerable", "=", "evaluator", ".", "evaluate_raw", "(", "quesid2ans", ",", "is_topk_optimal", "=", "False", ")", "\n", "\n", "log_dict", "=", "{", "}", "\n", "log_dict", "[", "'Test/overall'", "]", "=", "acc_dict_all", "[", "'overall'", "]", "\n", "log_dict", "[", "'Test/topk_optimal'", "]", "=", "acc_dict_answerable", "[", "'overall'", "]", "\n", "log_dict", "[", "'Test/topk_not_optimal'", "]", "=", "acc_dict_unanswerable", "[", "'overall'", "]", "\n", "\n", "for", "qtype", ",", "score", "in", "acc_dict_all", "[", "'perQuestionType'", "]", ".", "items", "(", ")", ":", "\n", "                ", "log_dict", "[", "f'Test_Qtypes/{qtype}'", "]", "=", "score", "\n", "", "for", "atype", ",", "score", "in", "acc_dict_all", "[", "'perAnswerType'", "]", ".", "items", "(", ")", ":", "\n", "                ", "if", "atype", "==", "'yes/no'", ":", "\n", "                    ", "atype", "=", "'yes_no'", "\n", "", "log_dict", "[", "f'Test_Atypes/{atype}'", "]", "=", "score", "\n", "\n", "", "print", "(", "log_dict", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "submit", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "args", ".", "output", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "self", ".", "args", ".", "output", ",", "exist_ok", "=", "True", ")", "\n", "", "dump_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output", ",", "'submit.json'", ")", "\n", "self", ".", "predict", "(", "self", ".", "submit_test_loader", ",", "dump_path", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa.Trainer.predict": [[287, 326], ["vqa.Trainer.model.eval", "dist_utils.all_gather", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "tqdm.tqdm.tqdm", "zip", "tqdm.tqdm.tqdm.close", "qid2ans.items", "evaluator.dump_result", "vqa.Trainer.model.module.test_step", "vqa.Trainer.model.test_step", "tqdm.tqdm.tqdm.update", "len"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.all_gather", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAEvaluator.dump_result", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.test_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.test_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update"], ["", "", "def", "predict", "(", "self", ",", "loader", ",", "dump_path", "=", "None", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "quesid2ans", "=", "{", "}", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "loader", ")", ",", "ncols", "=", "120", ",", "desc", "=", "\"Prediction\"", ")", "\n", "", "for", "i", ",", "batch", "in", "enumerate", "(", "loader", ")", ":", "\n", "                ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "results", "=", "self", ".", "model", ".", "module", ".", "test_step", "(", "batch", ")", "\n", "", "else", ":", "\n", "                    ", "results", "=", "self", ".", "model", ".", "test_step", "(", "batch", ")", "\n", "\n", "", "pred_ans", "=", "results", "[", "'pred_ans'", "]", "\n", "ques_ids", "=", "batch", "[", "'question_ids'", "]", "\n", "\n", "for", "qid", ",", "ans", "in", "zip", "(", "ques_ids", ",", "pred_ans", ")", ":", "\n", "                    ", "quesid2ans", "[", "qid", "]", "=", "ans", "\n", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                    ", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "                ", "pbar", ".", "close", "(", ")", "\n", "\n", "", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "qid2ans_list", "=", "dist_utils", ".", "all_gather", "(", "quesid2ans", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "quesid2ans", "=", "{", "}", "\n", "for", "qid2ans", "in", "qid2ans_list", ":", "\n", "                ", "for", "k", ",", "v", "in", "qid2ans", ".", "items", "(", ")", ":", "\n", "                    ", "quesid2ans", "[", "k", "]", "=", "v", "\n", "\n", "", "", "if", "dump_path", "is", "not", "None", ":", "\n", "                ", "evaluator", "=", "loader", ".", "evaluator", "\n", "evaluator", ".", "dump_result", "(", "quesid2ans", ",", "dump_path", ")", "\n", "\n", "", "", "return", "quesid2ans", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa.Trainer.evaluate": [[327, 337], ["vqa.Trainer.predict", "evaluator.evaluate_raw", "evaluator.evaluate"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.predict", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.evaluate_raw", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate"], ["", "def", "evaluate", "(", "self", ",", "loader", ",", "dump_path", "=", "None", ")", ":", "\n", "        ", "quesid2ans", "=", "self", ".", "predict", "(", "loader", ",", "dump_path", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "evaluator", "=", "loader", ".", "evaluator", "\n", "acc_dict", "=", "evaluator", ".", "evaluate_raw", "(", "quesid2ans", ")", "\n", "topk_score", "=", "evaluator", ".", "evaluate", "(", "quesid2ans", ")", "\n", "acc_dict", "[", "'topk_score'", "]", "=", "topk_score", "\n", "\n", "return", "acc_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa.count_parameters": [[46, 48], ["sum", "p.numel", "model.parameters"], "function", ["None"], ["def", "count_parameters", "(", "model", ")", ":", "\n", "    ", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa.main_worker": [[338, 394], ["print", "print", "vqa_data.get_loader", "print", "vqa_data.get_loader", "print", "vqa_data.get_loader", "vqa.Trainer", "vqa.Trainer.train", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.init_process_group", "print", "vqa_data.get_loader"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.train", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader"], ["", "", "", "def", "main_worker", "(", "gpu", ",", "args", ")", ":", "\n", "# GPU is assigned", "\n", "    ", "args", ".", "gpu", "=", "gpu", "\n", "args", ".", "rank", "=", "gpu", "\n", "print", "(", "f'Process Launching at GPU {gpu}'", ")", "\n", "\n", "if", "args", ".", "distributed", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "dist", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "\n", "\n", "", "print", "(", "f'Building train loader at GPU {gpu}'", ")", "\n", "train_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "train", ",", "mode", "=", "'train'", ",", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "distributed", "=", "args", ".", "distributed", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "args", ".", "num_workers", ",", "\n", "topk", "=", "args", ".", "train_topk", ",", "\n", ")", "\n", "\n", "if", "args", ".", "valid_batch_size", "is", "not", "None", ":", "\n", "        ", "valid_batch_size", "=", "args", ".", "valid_batch_size", "\n", "", "else", ":", "\n", "        ", "valid_batch_size", "=", "args", ".", "batch_size", "\n", "", "print", "(", "f'Building val loader at GPU {gpu}'", ")", "\n", "val_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "valid", ",", "mode", "=", "'val'", ",", "batch_size", "=", "valid_batch_size", ",", "\n", "distributed", "=", "args", ".", "distributed", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "4", ",", "\n", "topk", "=", "args", ".", "valid_topk", ",", "\n", ")", "\n", "\n", "print", "(", "f'Building test loader at GPU {gpu}'", ")", "\n", "test_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "test", ",", "mode", "=", "'val'", ",", "batch_size", "=", "valid_batch_size", ",", "\n", "distributed", "=", "args", ".", "distributed", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "4", ",", "\n", "topk", "=", "args", ".", "valid_topk", ",", "\n", ")", "\n", "\n", "trainer", "=", "Trainer", "(", "args", ",", "train_loader", ",", "val_loader", ",", "test_loader", ",", "train", "=", "True", ")", "\n", "\n", "if", "args", ".", "submit", ":", "\n", "        ", "print", "(", "f'Building test submit loader at GPU {gpu}'", ")", "\n", "submit_test_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "'test'", ",", "mode", "=", "'val'", ",", "batch_size", "=", "valid_batch_size", ",", "\n", "distributed", "=", "args", ".", "distributed", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "4", ",", "\n", "topk", "=", "args", ".", "valid_topk", ",", "\n", ")", "\n", "trainer", ".", "submit_test_loader", "=", "submit_test_loader", "\n", "\n", "", "trainer", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa.Trainer.__init__": [[46, 107], ["trainer_base.TrainerBase.__init__", "okvqa.Trainer.create_config", "okvqa.Trainer.create_tokenizer", "okvqa.Trainer.create_model", "print", "okvqa.Trainer.model.to", "utils.set_global_logging_level", "okvqa.Trainer.model.resize_token_embeddings", "okvqa.Trainer.load_checkpoint", "okvqa.Trainer.init_weights", "time", "okvqa.Trainer.create_optimizer_and_scheduler", "print", "okvqa.Trainer.model.resize_token_embeddings", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "amp.initialize", "time"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_config", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_tokenizer", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_model", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.set_global_logging_level", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load_checkpoint", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.init_weights", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_optimizer_and_scheduler"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "train_loader", "=", "None", ",", "val_loader", "=", "None", ",", "test_loader", "=", "None", ",", "train", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "args", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "test_loader", "=", "test_loader", ",", "\n", "train", "=", "train", ")", "\n", "\n", "if", "not", "self", ".", "verbose", ":", "\n", "            ", "set_global_logging_level", "(", "logging", ".", "ERROR", ",", "[", "\"transformers\"", "]", ")", "\n", "\n", "", "from", "okvqa_model", "import", "FewVLMOKVQA", "\n", "\n", "model_kwargs", "=", "{", "}", "\n", "if", "'t5'", "in", "args", ".", "backbone", ":", "\n", "            ", "model_class", "=", "FewVLMOKVQA", "\n", "\n", "", "config", "=", "self", ".", "create_config", "(", ")", "\n", "self", ".", "tokenizer", "=", "self", ".", "create_tokenizer", "(", ")", "\n", "self", ".", "model", "=", "self", ".", "create_model", "(", "model_class", ",", "config", ",", "**", "model_kwargs", ")", "\n", "\n", "if", "'t5'", "in", "self", ".", "args", ".", "tokenizer", ":", "\n", "            ", "self", ".", "model", ".", "resize_token_embeddings", "(", "self", ".", "tokenizer", ".", "vocab_size", ")", "\n", "", "elif", "'bart'", "in", "self", ".", "args", ".", "tokenizer", ":", "\n", "            ", "self", ".", "model", ".", "resize_token_embeddings", "(", "self", ".", "model", ".", "model", ".", "shared", ".", "num_embeddings", "+", "num_added_toks", ")", "\n", "\n", "", "self", ".", "model", ".", "tokenizer", "=", "self", ".", "tokenizer", "\n", "\n", "# Load Checkpoint", "\n", "self", ".", "start_epoch", "=", "None", "\n", "if", "args", ".", "load", "is", "not", "None", ":", "\n", "            ", "ckpt_path", "=", "args", ".", "load", "+", "'.pth'", "\n", "self", ".", "load_checkpoint", "(", "ckpt_path", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "from_scratch", ":", "\n", "            ", "self", ".", "init_weights", "(", ")", "\n", "\n", "# GPU Options", "\n", "", "print", "(", "f'Model Launching at GPU {self.args.gpu}'", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "from", "time", "import", "time", "\n", "start", "=", "time", "(", ")", "\n", "", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "args", ".", "gpu", ")", "\n", "\n", "# Optimizer", "\n", "if", "train", ":", "\n", "            ", "self", ".", "optim", ",", "self", ".", "lr_scheduler", "=", "self", ".", "create_optimizer_and_scheduler", "(", ")", "\n", "\n", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                ", "self", ".", "scaler", "=", "torch", ".", "cuda", ".", "amp", ".", "GradScaler", "(", ")", "\n", "", "elif", "_use_apex", ":", "\n", "                ", "self", ".", "model", ",", "self", ".", "optim", "=", "amp", ".", "initialize", "(", "\n", "self", ".", "model", ",", "self", ".", "optim", ",", "opt_level", "=", "'O1'", ",", "verbosity", "=", "self", ".", "verbose", ")", "\n", "\n", "", "", "if", "args", ".", "multiGPU", ":", "\n", "            ", "if", "args", ".", "distributed", ":", "\n", "                ", "self", ".", "model", "=", "DDP", "(", "self", ".", "model", ",", "device_ids", "=", "[", "args", ".", "gpu", "]", ",", "\n", "find_unused_parameters", "=", "True", "\n", ")", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "f'It took {time() - start:.1f}s'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa.Trainer.train": [[109, 281], ["okvqa.Trainer.predict", "utils.LossMeter", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "range", "os.path.join", "okvqa.Trainer.load", "evaluator.evaluate", "evaluator.dump_result", "evaluator.evaluate_raw", "evaluator.evaluate_raw", "evaluator.evaluate_raw", "acc_dict_all[].items", "acc_dict_all[].items", "print", "os.path.join", "okvqa.Trainer.predict", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "exit", "okvqa.Trainer.model.train", "enumerate", "okvqa.Trainer.evaluate", "okvqa.Trainer.save", "okvqa.Trainer.train_loader.sampler.set_epoch", "tqdm.tqdm.tqdm", "loss.detach.detach.detach", "okvqa.Trainer.model.parameters", "okvqa.Trainer.items", "tqdm.tqdm.tqdm.close", "print", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "okvqa.Trainer.scaler.scale().backward", "okvqa.Trainer.scaler.step", "okvqa.Trainer.scaler.update", "okvqa.Trainer.optim.step", "okvqa.Trainer.lr_scheduler.step", "utils.LossMeter.update", "tqdm.tqdm.tqdm.set_description", "tqdm.tqdm.tqdm.update", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "okvqa.Trainer.save", "len", "autocast", "okvqa.Trainer.model.module.train_step", "okvqa.Trainer.model.train_step", "loss.detach.detach.backward", "okvqa.Trainer.scaler.unscale_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "v.item", "packaging.version.parse", "packaging.version.parse", "loss.detach.detach.item", "okvqa.Trainer.model.module.train_step", "okvqa.Trainer.model.train_step", "okvqa.Trainer.scaler.scale", "amp.scale_loss", "scaled_loss.backward", "okvqa.Trainer.model.parameters", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "okvqa.Trainer.lr_scheduler.get_last_lr", "okvqa.Trainer.lr_scheduler.get_lr", "okvqa.Trainer.optim.get_lr", "amp.master_params", "okvqa.Trainer.model.parameters"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.predict", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAEvaluator.dump_result", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.evaluate_raw", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.evaluate_raw", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.evaluate_raw", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.predict", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.train", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step"], ["", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "verbose", ":", "\n", "            ", "loss_meter", "=", "LossMeter", "(", ")", "\n", "best_valid", "=", "0.", "\n", "best_epoch", "=", "0", "\n", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "global_step", "=", "0", "\n", "if", "not", "self", ".", "args", ".", "test_only", ":", "\n", "            ", "for", "epoch", "in", "range", "(", "self", ".", "args", ".", "epochs", ")", ":", "\n", "                ", "if", "self", ".", "start_epoch", "is", "not", "None", ":", "\n", "                    ", "epoch", "+=", "self", ".", "start_epoch", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "self", ".", "train_loader", ".", "sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                    ", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "self", ".", "train_loader", ")", ",", "ncols", "=", "120", ")", "\n", "\n", "", "epoch_results", "=", "{", "\n", "'loss'", ":", "0.", ",", "\n", "\n", "}", "\n", "\n", "quesid2ans", "=", "{", "}", "\n", "\n", "for", "step_i", ",", "batch", "in", "enumerate", "(", "self", ".", "train_loader", ")", ":", "\n", "\n", "                    ", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                        ", "with", "autocast", "(", ")", ":", "\n", "                            ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                                ", "results", "=", "self", ".", "model", ".", "module", ".", "train_step", "(", "batch", ")", "\n", "", "else", ":", "\n", "                                ", "results", "=", "self", ".", "model", ".", "train_step", "(", "batch", ")", "\n", "", "", "", "else", ":", "\n", "                        ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                            ", "results", "=", "self", ".", "model", ".", "module", ".", "train_step", "(", "batch", ")", "\n", "", "else", ":", "\n", "                            ", "results", "=", "self", ".", "model", ".", "train_step", "(", "batch", ")", "\n", "\n", "", "", "loss", "=", "results", "[", "'loss'", "]", "\n", "\n", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                        ", "self", ".", "scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "", "elif", "self", ".", "args", ".", "fp16", "and", "_use_apex", ":", "\n", "                        ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "self", ".", "optim", ")", "as", "scaled_loss", ":", "\n", "                            ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                        ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "loss", "=", "loss", ".", "detach", "(", ")", "\n", "\n", "# Update Parameters", "\n", "if", "self", ".", "args", ".", "clip_grad_norm", ">", "0", ":", "\n", "                        ", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                            ", "self", ".", "scaler", ".", "unscale_", "(", "self", ".", "optim", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "", "elif", "self", ".", "args", ".", "fp16", "and", "_use_apex", ":", "\n", "                            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "\n", "self", ".", "optim", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "", "else", ":", "\n", "                            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "\n", "", "", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                        ", "self", ".", "scaler", ".", "step", "(", "self", ".", "optim", ")", "\n", "self", ".", "scaler", ".", "update", "(", ")", "\n", "", "else", ":", "\n", "                        ", "self", ".", "optim", ".", "step", "(", ")", "\n", "\n", "", "if", "self", ".", "lr_scheduler", ":", "\n", "                        ", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "", "for", "param", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "                        ", "param", ".", "grad", "=", "None", "\n", "\n", "", "global_step", "+=", "1", "\n", "\n", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", ":", "\n", "                        ", "if", "k", "in", "epoch_results", ":", "\n", "                            ", "epoch_results", "[", "k", "]", "+=", "v", ".", "item", "(", ")", "\n", "\n", "", "", "if", "self", ".", "lr_scheduler", ":", "\n", "                        ", "if", "version", ".", "parse", "(", "torch", ".", "__version__", ")", ">=", "version", ".", "parse", "(", "\"1.4\"", ")", ":", "\n", "                            ", "lr", "=", "self", ".", "lr_scheduler", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                            ", "lr", "=", "self", ".", "lr_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "", "", "else", ":", "\n", "                        ", "try", ":", "\n", "                            ", "lr", "=", "self", ".", "optim", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "", "except", "AttributeError", ":", "\n", "                            ", "lr", "=", "self", ".", "args", ".", "lr", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "                        ", "loss_meter", ".", "update", "(", "loss", ".", "item", "(", ")", ")", "\n", "desc_str", "=", "f'Epoch {epoch} | LR {lr:.6f}'", "\n", "desc_str", "+=", "f' | Loss {loss_meter.val:4f}'", "\n", "\n", "pbar", ".", "set_description", "(", "desc_str", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                        ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "                    ", "pbar", ".", "close", "(", ")", "\n", "\n", "# Validation", "\n", "", "score_dict", "=", "self", ".", "evaluate", "(", "self", ".", "val_loader", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "                    ", "valid_score", "=", "score_dict", "[", "'topk_score'", "]", "*", "100.", "\n", "valid_score_raw", "=", "score_dict", "[", "'overall'", "]", "\n", "if", "valid_score_raw", ">=", "best_valid", "or", "epoch", "==", "0", ":", "\n", "                        ", "best_valid", "=", "valid_score_raw", "\n", "best_epoch", "=", "epoch", "\n", "self", ".", "save", "(", "\"BEST\"", ")", "\n", "\n", "", "log_str", "=", "''", "\n", "log_str", "+=", "\"\\nEpoch %d: Valid Raw %0.2f Topk %0.2f\"", "%", "(", "epoch", ",", "valid_score_raw", ",", "valid_score", ")", "\n", "log_str", "+=", "\"\\nEpoch %d: Best Raw %0.2f\\n\"", "%", "(", "best_epoch", ",", "best_valid", ")", "\n", "\n", "print", "(", "log_str", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "                ", "self", ".", "save", "(", "\"LAST\"", ")", "\n", "\n", "", "", "if", "not", "self", ".", "args", ".", "test_only", ":", "\n", "            ", "best_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output", ",", "'BEST'", ")", "\n", "# best_path = os.path.join(self.args.output, 'LAST')", "\n", "\n", "self", ".", "load", "(", "best_path", ")", "\n", "\n", "", "quesid2ans", "=", "self", ".", "predict", "(", "self", ".", "test_loader", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "evaluator", "=", "self", ".", "test_loader", ".", "evaluator", "\n", "score_dict", "=", "evaluator", ".", "evaluate", "(", "quesid2ans", ")", "\n", "\n", "evaluator", ".", "dump_result", "(", "quesid2ans", ",", "'result.txt'", ")", "\n", "\n", "acc_dict_all", "=", "evaluator", ".", "evaluate_raw", "(", "quesid2ans", ")", "\n", "acc_dict_answerable", "=", "evaluator", ".", "evaluate_raw", "(", "quesid2ans", ",", "is_topk_optimal", "=", "True", ")", "\n", "acc_dict_unanswerable", "=", "evaluator", ".", "evaluate_raw", "(", "quesid2ans", ",", "is_topk_optimal", "=", "False", ")", "\n", "\n", "log_dict", "=", "{", "}", "\n", "log_dict", "[", "'Test/overall'", "]", "=", "acc_dict_all", "[", "'overall'", "]", "\n", "log_dict", "[", "'Test/topk_optimal'", "]", "=", "acc_dict_answerable", "[", "'overall'", "]", "\n", "log_dict", "[", "'Test/topk_not_optimal'", "]", "=", "acc_dict_unanswerable", "[", "'overall'", "]", "\n", "\n", "for", "qtype", ",", "score", "in", "acc_dict_all", "[", "'perQuestionType'", "]", ".", "items", "(", ")", ":", "\n", "                ", "log_dict", "[", "f'Test_Qtypes/{qtype}'", "]", "=", "score", "\n", "", "for", "atype", ",", "score", "in", "acc_dict_all", "[", "'perAnswerType'", "]", ".", "items", "(", ")", ":", "\n", "                ", "if", "atype", "==", "'yes/no'", ":", "\n", "                    ", "atype", "=", "'yes_no'", "\n", "", "log_dict", "[", "f'Test_Atypes/{atype}'", "]", "=", "score", "\n", "\n", "", "print", "(", "log_dict", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "submit", ":", "\n", "            ", "dump_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output", ",", "'submit.json'", ")", "\n", "self", ".", "predict", "(", "self", ".", "submit_test_loader", ",", "dump_path", ")", "\n", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa.Trainer.predict": [[282, 321], ["okvqa.Trainer.model.eval", "dist_utils.all_gather", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "tqdm.tqdm.tqdm", "zip", "tqdm.tqdm.tqdm.close", "qid2ans.items", "evaluator.dump_result", "okvqa.Trainer.model.module.test_step", "okvqa.Trainer.model.test_step", "tqdm.tqdm.tqdm.update", "len"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.dist_utils.all_gather", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAEvaluator.dump_result", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.test_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.test_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update"], ["", "", "def", "predict", "(", "self", ",", "loader", ",", "dump_path", "=", "None", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "quesid2ans", "=", "{", "}", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "loader", ")", ",", "ncols", "=", "120", ",", "desc", "=", "\"Prediction\"", ")", "\n", "", "for", "i", ",", "batch", "in", "enumerate", "(", "loader", ")", ":", "\n", "                ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "results", "=", "self", ".", "model", ".", "module", ".", "test_step", "(", "batch", ")", "\n", "", "else", ":", "\n", "                    ", "results", "=", "self", ".", "model", ".", "test_step", "(", "batch", ")", "\n", "\n", "", "pred_ans", "=", "results", "[", "'pred_ans'", "]", "\n", "ques_ids", "=", "batch", "[", "'question_ids'", "]", "\n", "\n", "for", "qid", ",", "ans", "in", "zip", "(", "ques_ids", ",", "pred_ans", ")", ":", "\n", "                    ", "quesid2ans", "[", "qid", "]", "=", "ans", "\n", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                    ", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "                ", "pbar", ".", "close", "(", ")", "\n", "\n", "", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "qid2ans_list", "=", "dist_utils", ".", "all_gather", "(", "quesid2ans", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "quesid2ans", "=", "{", "}", "\n", "for", "qid2ans", "in", "qid2ans_list", ":", "\n", "                ", "for", "k", ",", "v", "in", "qid2ans", ".", "items", "(", ")", ":", "\n", "                    ", "quesid2ans", "[", "k", "]", "=", "v", "\n", "\n", "", "", "if", "dump_path", "is", "not", "None", ":", "\n", "                ", "evaluator", "=", "loader", ".", "evaluator", "\n", "evaluator", ".", "dump_result", "(", "quesid2ans", ",", "dump_path", ")", "\n", "\n", "", "", "return", "quesid2ans", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa.Trainer.evaluate": [[322, 332], ["okvqa.Trainer.predict", "evaluator.evaluate_raw", "evaluator.evaluate"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.predict", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa_data.OKVQAEvaluator.evaluate_raw", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate"], ["", "def", "evaluate", "(", "self", ",", "loader", ",", "dump_path", "=", "None", ")", ":", "\n", "        ", "quesid2ans", "=", "self", ".", "predict", "(", "loader", ",", "dump_path", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "evaluator", "=", "loader", ".", "evaluator", "\n", "acc_dict", "=", "evaluator", ".", "evaluate_raw", "(", "quesid2ans", ")", "\n", "topk_score", "=", "evaluator", ".", "evaluate", "(", "quesid2ans", ")", "\n", "acc_dict", "[", "'topk_score'", "]", "=", "topk_score", "\n", "\n", "return", "acc_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.okvqa.main_worker": [[333, 389], ["print", "print", "okvqa_data.get_loader", "print", "okvqa_data.get_loader", "print", "okvqa_data.get_loader", "okvqa.Trainer", "okvqa.Trainer.train", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.init_process_group", "print", "okvqa_data.get_loader"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.train", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader"], ["", "", "", "def", "main_worker", "(", "gpu", ",", "args", ")", ":", "\n", "# GPU is assigned", "\n", "    ", "args", ".", "gpu", "=", "gpu", "\n", "args", ".", "rank", "=", "gpu", "\n", "print", "(", "f'Process Launching at GPU {gpu}'", ")", "\n", "\n", "if", "args", ".", "distributed", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "dist", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "\n", "\n", "", "print", "(", "f'Building train loader at GPU {gpu}'", ")", "\n", "train_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "train", ",", "mode", "=", "'train'", ",", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "distributed", "=", "args", ".", "distributed", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "args", ".", "num_workers", ",", "\n", "topk", "=", "args", ".", "train_topk", ",", "\n", ")", "\n", "\n", "if", "args", ".", "valid_batch_size", "is", "not", "None", ":", "\n", "        ", "valid_batch_size", "=", "args", ".", "valid_batch_size", "\n", "", "else", ":", "\n", "        ", "valid_batch_size", "=", "args", ".", "batch_size", "\n", "", "print", "(", "f'Building val loader at GPU {gpu}'", ")", "\n", "val_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "valid", ",", "mode", "=", "'val'", ",", "batch_size", "=", "valid_batch_size", ",", "\n", "distributed", "=", "args", ".", "distributed", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "4", ",", "\n", "topk", "=", "args", ".", "valid_topk", ",", "\n", ")", "\n", "\n", "print", "(", "f'Building test loader at GPU {gpu}'", ")", "\n", "test_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "test", ",", "mode", "=", "'val'", ",", "batch_size", "=", "valid_batch_size", ",", "\n", "distributed", "=", "args", ".", "distributed", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "4", ",", "\n", "topk", "=", "args", ".", "valid_topk", ",", "\n", ")", "\n", "\n", "trainer", "=", "Trainer", "(", "args", ",", "train_loader", ",", "val_loader", ",", "test_loader", ",", "train", "=", "True", ")", "\n", "\n", "if", "args", ".", "submit", ":", "\n", "        ", "print", "(", "f'Building test submit loader at GPU {gpu}'", ")", "\n", "submit_test_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "'test'", ",", "mode", "=", "'val'", ",", "batch_size", "=", "valid_batch_size", ",", "\n", "distributed", "=", "args", ".", "distributed", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "4", ",", "\n", "topk", "=", "args", ".", "valid_topk", ",", "\n", ")", "\n", "trainer", ".", "submit_test_loader", "=", "submit_test_loader", "\n", "\n", "", "trainer", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.cococaption_data.COCOCaptionFineTuneDataset.__init__": [[30, 133], ["torch.utils.data.Dataset.__init__", "dataset_dir.joinpath", "torch.cuda.device_count", "print", "open", "json.load", "print", "print", "random.seed", "random.shuffle", "print", "cococaption_data.COCOCaptionFineTuneDataset.source_to_h5.update", "tokenization.FewVLMTokenizerFast.from_pretrained", "transformers.T5TokenizerFast.from_pretrained", "data.append", "print", "len", "cococaption_data.COCOCaptionFineTuneDataset.source.split", "data.append", "datum[].split", "coco_dir.joinpath().joinpath", "coco_dir.joinpath().joinpath", "datum[].split", "d[].strip", "d[].strip", "len", "d[].strip", "coco_dir.joinpath", "coco_dir.joinpath"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update"], ["    ", "def", "__init__", "(", "self", ",", "split", "=", "'karpathy_train'", ",", "raw_dataset", "=", "None", ",", "rank", "=", "-", "1", ",", "topk", "=", "-", "1", ",", "verbose", "=", "True", ",", "args", "=", "None", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "raw_dataset", "=", "raw_dataset", "\n", "self", ".", "topk", "=", "topk", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "mode", "=", "mode", "\n", "\n", "# Loading datasets to data", "\n", "self", ".", "source", "=", "split", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "'Data source: '", ",", "self", ".", "source", ")", "\n", "\n", "\n", "", "if", "self", ".", "args", ".", "tokenizer", "is", "None", ":", "\n", "            ", "self", ".", "args", ".", "tokenizer", "=", "self", ".", "args", ".", "backbone", "\n", "\n", "", "if", "'t5'", "in", "self", ".", "args", ".", "tokenizer", ":", "\n", "            ", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "                ", "self", ".", "tokenizer", "=", "FewVLMTokenizerFast", ".", "from_pretrained", "(", "\n", "args", ".", "backbone", ",", "\n", "# max_length=self.args.max_text_length,", "\n", "do_lower_case", "=", "self", ".", "args", ".", "do_lower_case", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "tokenizer", "=", "T5TokenizerFast", ".", "from_pretrained", "(", "\n", "args", ".", "backbone", ",", "\n", "# max_length=self.args.max_text_length,", "\n", "do_lower_case", "=", "self", ".", "args", ".", "do_lower_case", ")", "\n", "\n", "# TODO: change here", "\n", "", "", "data_info_path", "=", "dataset_dir", ".", "joinpath", "(", "f'COCO/{args.caption_data}.json'", ")", "\n", "with", "open", "(", "data_info_path", ")", "as", "f", ":", "\n", "            ", "karpathy_data", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "split_rename", "=", "{", "\n", "'train'", ":", "'train'", ",", "\n", "'restval'", ":", "'train'", ",", "\n", "'val'", ":", "'val'", ",", "\n", "'test'", ":", "'test'", "\n", "}", "\n", "\n", "n_images", "=", "0", "\n", "\n", "data", "=", "[", "]", "\n", "for", "datum", "in", "karpathy_data", "[", "'images'", "]", ":", "\n", "            ", "re_split", "=", "split_rename", "[", "datum", "[", "'split'", "]", "]", "\n", "if", "re_split", "!=", "self", ".", "source", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "re_split", "==", "'train'", ":", "\n", "                ", "for", "d", "in", "datum", "[", "'sentences'", "]", ":", "\n", "                    ", "img_id", "=", "datum", "[", "'filename'", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "new_datum", "=", "{", "\n", "'img_id'", ":", "img_id", ",", "\n", "'sent'", ":", "d", "[", "'raw'", "]", ".", "strip", "(", ")", ",", "\n", "'targets'", ":", "[", "d", "[", "'raw'", "]", ".", "strip", "(", ")", "for", "d", "in", "datum", "[", "'sentences'", "]", "]", ",", "\n", "'is_train'", ":", "True", ",", "\n", "}", "\n", "data", ".", "append", "(", "new_datum", ")", "\n", "", "", "else", ":", "\n", "                ", "img_id", "=", "datum", "[", "'filename'", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "new_datum", "=", "{", "\n", "'img_id'", ":", "img_id", ",", "\n", "# 'sent': d['raw'],", "\n", "'targets'", ":", "[", "d", "[", "'raw'", "]", ".", "strip", "(", ")", "for", "d", "in", "datum", "[", "'sentences'", "]", "]", ",", "\n", "'is_train'", ":", "False", ",", "\n", "}", "\n", "data", ".", "append", "(", "new_datum", ")", "\n", "\n", "", "n_images", "+=", "1", "\n", "\n", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "f\"{self.source} has {n_images} images\"", ")", "\n", "print", "(", "f\"Loaded {len(data)} data from\"", ",", "split", ")", "\n", "\n", "", "self", ".", "n_gpus", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "self", ".", "rank", "=", "rank", "\n", "if", "self", ".", "topk", ">", "0", ":", "\n", "            ", "data", "=", "data", "[", ":", "self", ".", "topk", "]", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "f\"Use only {self.topk} data\"", ")", "\n", "\n", "", "", "self", ".", "data", "=", "data", "\n", "if", "args", ".", "subsample", "and", "'train'", "in", "split", ":", "\n", "            ", "random", ".", "seed", "(", "args", ".", "dataseed", ")", "\n", "random", ".", "shuffle", "(", "self", ".", "data", ")", "\n", "if", "'train'", "in", "split", "and", "mode", "==", "'train'", ":", "\n", "                ", "self", ".", "data", "=", "self", ".", "data", "[", ":", "args", ".", "num_data", "]", "\n", "", "elif", "'train'", "in", "split", "and", "mode", "==", "'val'", ":", "\n", "                ", "self", ".", "data", "=", "self", ".", "data", "[", "args", ".", "num_data", ":", "2", "*", "args", ".", "num_data", "]", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "\"# all sentences:\"", ",", "len", "(", "self", ".", "data", ")", ")", "\n", "\n", "", "self", ".", "source_to_h5", "=", "{", "}", "\n", "\n", "if", "self", ".", "args", ".", "max_n_boxes", "==", "36", ":", "\n", "            ", "self", ".", "source_to_h5", ".", "update", "(", "{", "\n", "'train2014'", ":", "coco_dir", ".", "joinpath", "(", "'features'", ")", ".", "joinpath", "(", "'train2014_obj36.h5'", ")", ",", "\n", "'val2014'", ":", "coco_dir", ".", "joinpath", "(", "'features'", ")", ".", "joinpath", "(", "'val2014_obj36.h5'", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.cococaption_data.COCOCaptionFineTuneDataset.__len__": [[136, 138], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.cococaption_data.COCOCaptionFineTuneDataset.__getitem__": [[139, 238], ["torch.LongTensor", "len", "isinstance", "numpy.testing.assert_array_less", "numpy.testing.assert_array_less", "torch.from_numpy", "torch.from_numpy.clamp_", "len", "numpy.zeros", "f[].read_direct", "torch.from_numpy", "min", "datum[].strip", "len", "torch.LongTensor", "len", "h5py.File", "cococaption_data.COCOCaptionFineTuneDataset.tokenizer.encode", "cococaption_data.COCOCaptionFineTuneDataset.tokenizer.encode", "len", "len", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "out_dict", "=", "{", "}", "\n", "out_dict", "[", "'args'", "]", "=", "self", ".", "args", "\n", "\n", "datum", "=", "self", ".", "data", "[", "idx", "]", "\n", "\n", "###### Image ######", "\n", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "            ", "img_id", "=", "datum", "[", "'img_id'", "]", "\n", "out_dict", "[", "'img_id'", "]", "=", "img_id", "\n", "\n", "if", "'train'", "in", "img_id", ":", "\n", "                ", "source", "=", "'train2014'", "\n", "", "elif", "'val'", "in", "img_id", ":", "\n", "                ", "source", "=", "'val2014'", "\n", "\n", "", "f", "=", "self", ".", "source_to_h5", "[", "source", "]", "\n", "\n", "if", "isinstance", "(", "f", ",", "Path", ")", ":", "\n", "# path = self.data_source_to_h5_path[source]", "\n", "                ", "f", "=", "h5py", ".", "File", "(", "f", ",", "'r'", ")", "\n", "# self.split_to_h5_features[split_i] = f", "\n", "self", ".", "source_to_h5", "[", "source", "]", "=", "f", "\n", "\n", "# Normalize the boxes (to 0 ~ 1)", "\n", "", "img_h", "=", "f", "[", "f'{img_id}/img_h'", "]", "[", "(", ")", "]", "\n", "img_w", "=", "f", "[", "f'{img_id}/img_w'", "]", "[", "(", ")", "]", "\n", "boxes", "=", "f", "[", "f'{img_id}/boxes'", "]", "[", "(", ")", "]", "# (x1, y1, x2, y2)", "\n", "boxes", "[", ":", ",", "(", "0", ",", "2", ")", "]", "/=", "img_w", "\n", "boxes", "[", ":", ",", "(", "1", ",", "3", ")", "]", "/=", "img_h", "\n", "np", ".", "testing", ".", "assert_array_less", "(", "boxes", ",", "1", "+", "1e-5", ")", "\n", "# np.testing.assert_array_less(boxes, 1+5e-2)", "\n", "np", ".", "testing", ".", "assert_array_less", "(", "-", "boxes", ",", "0", "+", "1e-5", ")", "\n", "boxes", "=", "torch", ".", "from_numpy", "(", "boxes", ")", "\n", "\n", "boxes", ".", "clamp_", "(", "min", "=", "0.0", ",", "max", "=", "1.0", ")", "\n", "\n", "n_boxes", "=", "len", "(", "boxes", ")", "\n", "\n", "feats", "=", "np", ".", "zeros", "(", "shape", "=", "(", "n_boxes", ",", "2048", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "f", "[", "f'{img_id}/features'", "]", ".", "read_direct", "(", "feats", ")", "\n", "feats", "=", "torch", ".", "from_numpy", "(", "feats", ")", "\n", "\n", "if", "self", ".", "args", ".", "n_boxes", "==", "100", ":", "\n", "                ", "assert", "n_boxes", "==", "100", "\n", "assert", "len", "(", "feats", ")", "==", "100", "\n", "assert", "len", "(", "boxes", ")", "==", "100", "\n", "\n", "", "n_boxes", "=", "min", "(", "n_boxes", ",", "self", ".", "args", ".", "max_n_boxes", ")", "\n", "out_dict", "[", "'n_boxes'", "]", "=", "n_boxes", "\n", "boxes", "=", "boxes", "[", ":", "n_boxes", "]", "\n", "feats", "=", "feats", "[", ":", "n_boxes", "]", "\n", "out_dict", "[", "'boxes'", "]", "=", "boxes", "\n", "out_dict", "[", "'vis_feats'", "]", "=", "feats", "\n", "\n", "###### Text #####", "\n", "", "if", "self", ".", "args", ".", "no_prefix", ":", "\n", "            ", "input_text", "=", "''", "\n", "input_ids", "=", "[", "]", "\n", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "args", ".", "prefix", "is", "None", ":", "\n", "                ", "prefix", "=", "''", "\n", "", "elif", "self", ".", "args", ".", "prefix", "==", "'picture'", ":", "\n", "                ", "prefix", "=", "'a picture of'", "\n", "", "elif", "self", ".", "args", ".", "prefix", "==", "'image'", ":", "\n", "                ", "prefix", "=", "'an image of'", "\n", "", "elif", "self", ".", "args", ".", "prefix", "==", "'photo'", ":", "\n", "                ", "prefix", "=", "'a photo of'", "\n", "\n", "", "input_tokens", "=", "[", "prefix", "]", "\n", "\n", "input_text", "=", "' '", ".", "join", "(", "input_tokens", ")", "\n", "\n", "if", "'t5'", "in", "self", ".", "args", ".", "tokenizer", ":", "\n", "                ", "input_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "\n", "input_text", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_text_length", ",", "truncation", "=", "True", ")", "\n", "\n", "", "", "out_dict", "[", "'input_text'", "]", "=", "input_text", "\n", "\n", "out_dict", "[", "'input_ids'", "]", "=", "torch", ".", "LongTensor", "(", "input_ids", ")", "\n", "out_dict", "[", "'input_length'", "]", "=", "len", "(", "input_ids", ")", "\n", "if", "datum", "[", "'is_train'", "]", ":", "\n", "            ", "sent", "=", "datum", "[", "'sent'", "]", ".", "strip", "(", ")", "\n", "if", "'t5'", "in", "self", ".", "args", ".", "tokenizer", ":", "\n", "                ", "target_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "sent", ",", "max_length", "=", "self", ".", "args", ".", "gen_max_length", ",", "truncation", "=", "True", ")", "\n", "\n", "", "assert", "len", "(", "target_ids", ")", "<=", "self", ".", "args", ".", "gen_max_length", ",", "len", "(", "target_ids", ")", "\n", "out_dict", "[", "'sent'", "]", "=", "sent", "\n", "out_dict", "[", "'target_ids'", "]", "=", "torch", ".", "LongTensor", "(", "target_ids", ")", "\n", "out_dict", "[", "'target_length'", "]", "=", "len", "(", "target_ids", ")", "\n", "\n", "", "if", "'targets'", "in", "datum", ":", "\n", "            ", "out_dict", "[", "'targets'", "]", "=", "datum", "[", "'targets'", "]", "\n", "\n", "\n", "", "return", "out_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.cococaption_data.COCOCaptionFineTuneDataset.collate_fn": [[239, 315], ["len", "max", "enumerate", "torch.ones", "max", "torch.zeros", "torch.zeros", "torch.zeros", "max", "input_ids.size", "torch.ones", "img_ids.append", "input_text.append", "targets.append"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "batch", ")", ":", "\n", "        ", "batch_entry", "=", "{", "}", "\n", "\n", "B", "=", "len", "(", "batch", ")", "\n", "\n", "S_W_L", "=", "max", "(", "entry", "[", "'input_length'", "]", "for", "entry", "in", "batch", ")", "\n", "input_ids", "=", "torch", ".", "ones", "(", "B", ",", "S_W_L", ",", "dtype", "=", "torch", ".", "long", ")", "*", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "\n", "if", "self", ".", "args", ".", "no_prefix", ":", "\n", "            ", "assert", "input_ids", ".", "size", "(", ")", "==", "(", "B", ",", "0", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "            ", "V_L", "=", "max", "(", "entry", "[", "'n_boxes'", "]", "for", "entry", "in", "batch", ")", "\n", "# V_L = len(batch[0]['boxes'])", "\n", "feat_dim", "=", "batch", "[", "0", "]", "[", "'vis_feats'", "]", ".", "shape", "[", "-", "1", "]", "\n", "\n", "boxes", "=", "torch", ".", "zeros", "(", "B", ",", "V_L", ",", "4", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "vis_feats", "=", "torch", ".", "zeros", "(", "B", ",", "V_L", ",", "feat_dim", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "vis_attention_mask", "=", "torch", ".", "zeros", "(", "B", ",", "V_L", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "if", "'target_ids'", "in", "batch", "[", "0", "]", ":", "\n", "            ", "T_W_L", "=", "max", "(", "entry", "[", "'target_length'", "]", "for", "entry", "in", "batch", ")", "\n", "target_ids", "=", "torch", ".", "ones", "(", "B", ",", "T_W_L", ",", "dtype", "=", "torch", ".", "long", ")", "*", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "\n", "# sentences = []", "\n", "\n", "", "targets", "=", "[", "]", "\n", "img_ids", "=", "[", "]", "\n", "img_paths", "=", "[", "]", "\n", "input_text", "=", "[", "]", "\n", "\n", "for", "i", ",", "entry", "in", "enumerate", "(", "batch", ")", ":", "\n", "            ", "input_ids", "[", "i", ",", ":", "entry", "[", "'input_length'", "]", "]", "=", "entry", "[", "'input_ids'", "]", "\n", "\n", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "                ", "n_boxes", "=", "entry", "[", "'n_boxes'", "]", "\n", "boxes", "[", "i", ",", ":", "n_boxes", "]", "=", "entry", "[", "'boxes'", "]", "\n", "vis_feats", "[", "i", ",", ":", "n_boxes", "]", "=", "entry", "[", "'vis_feats'", "]", "\n", "vis_attention_mask", "[", "i", ",", ":", "n_boxes", "]", "=", "1", "\n", "img_ids", ".", "append", "(", "entry", "[", "'img_id'", "]", ")", "\n", "# img_paths.append(entry['img_path'])", "\n", "\n", "", "if", "'target_ids'", "in", "entry", ":", "\n", "                ", "target_ids", "[", "i", ",", ":", "entry", "[", "'target_length'", "]", "]", "=", "entry", "[", "'target_ids'", "]", "\n", "\n", "", "if", "'input_text'", "in", "entry", ":", "\n", "                ", "input_text", ".", "append", "(", "entry", "[", "'input_text'", "]", ")", "\n", "\n", "# sentences.append(entry['sent'])", "\n", "\n", "", "if", "'targets'", "in", "entry", ":", "\n", "                ", "targets", ".", "append", "(", "entry", "[", "'targets'", "]", ")", "\n", "\n", "\n", "", "", "batch_entry", "[", "'input_ids'", "]", "=", "input_ids", "\n", "if", "'target_ids'", "in", "batch", "[", "0", "]", ":", "\n", "            ", "word_mask", "=", "target_ids", "!=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "target_ids", "[", "~", "word_mask", "]", "=", "-", "100", "\n", "batch_entry", "[", "'target_ids'", "]", "=", "target_ids", "\n", "\n", "", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "            ", "batch_entry", "[", "'boxes'", "]", "=", "boxes", "\n", "batch_entry", "[", "'vis_feats'", "]", "=", "vis_feats", "\n", "batch_entry", "[", "'vis_attention_mask'", "]", "=", "vis_attention_mask", "\n", "batch_entry", "[", "'img_id'", "]", "=", "img_ids", "\n", "batch_entry", "[", "'img_paths'", "]", "=", "img_paths", "\n", "\n", "# batch_entry['sent'] = sentences", "\n", "\n", "", "batch_entry", "[", "'input_text'", "]", "=", "input_text", "\n", "\n", "batch_entry", "[", "'targets'", "]", "=", "targets", "\n", "\n", "batch_entry", "[", "'task'", "]", "=", "'caption'", "\n", "\n", "return", "batch_entry", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.cococaption_data.COCOCaptionEvaluator.__init__": [[365, 368], ["language_evaluation.CocoEvaluator"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "import", "language_evaluation", "\n", "self", ".", "evaluator", "=", "language_evaluation", ".", "CocoEvaluator", "(", "verbose", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.cococaption_data.COCOCaptionEvaluator.evaluate": [[370, 375], ["cococaption_data.COCOCaptionEvaluator.evaluator.run_evaluation"], "methods", ["None"], ["", "def", "evaluate", "(", "self", ",", "predicts", ",", "answers", ")", ":", "\n", "\n", "        ", "results", "=", "self", ".", "evaluator", ".", "run_evaluation", "(", "predicts", ",", "answers", ")", "\n", "\n", "return", "results", "", "", "", ""]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.cococaption_data.get_loader": [[317, 361], ["cococaption_data.COCOCaptionFineTuneDataset", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "cococaption_data.COCOCaptionEvaluator"], "function", ["None"], ["", "", "def", "get_loader", "(", "args", ",", "split", "=", "'train'", ",", "mode", "=", "'train'", ",", "\n", "batch_size", "=", "32", ",", "workers", "=", "4", ",", "distributed", "=", "False", ",", "gpu", "=", "0", ",", "\n", "topk", "=", "-", "1", ")", ":", "\n", "\n", "# if 'mscoco' in split:", "\n", "    ", "verbose", "=", "(", "gpu", "==", "0", ")", "\n", "\n", "dataset", "=", "COCOCaptionFineTuneDataset", "(", "\n", "split", ",", "\n", "# raw_dataset=_dset,", "\n", "rank", "=", "gpu", ",", "\n", "topk", "=", "topk", ",", "\n", "verbose", "=", "verbose", ",", "\n", "args", "=", "args", ",", "\n", "mode", "=", "mode", ")", "\n", "# elif 'CC' in split:", "\n", "#     dataset = CCDataset(split, transform=transform, topk=topk)", "\n", "\n", "if", "distributed", "and", "mode", "==", "'train'", ":", "\n", "# sampler = DistributedSampler(dataset, num_replicas=world_size, rank=local_rank)", "\n", "        ", "train_sampler", "=", "DistributedSampler", "(", "dataset", ")", "\n", "# train_sampler = RandomNonreplacmentSampler(dataset, dataset.n_iter)", "\n", "", "else", ":", "\n", "        ", "train_sampler", "=", "None", "\n", "", "if", "mode", "==", "'train'", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "(", "train_sampler", "is", "None", ")", ",", "\n", "num_workers", "=", "workers", ",", "pin_memory", "=", "True", ",", "sampler", "=", "train_sampler", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ")", "\n", "", "else", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "workers", ",", "pin_memory", "=", "True", ",", "\n", "sampler", "=", "None", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ",", "\n", "drop_last", "=", "False", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "        ", "loader", ".", "evaluator", "=", "COCOCaptionEvaluator", "(", ")", "\n", "\n", "", "loader", ".", "task", "=", "'caption'", "\n", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.preprocess.corrupt_spans": [[7, 80], ["text.split", "len", "int", "mask_indices.tolist.tolist", "enumerate", "copy.deepcopy", "enumerate", "max", "[].sort", "len", "target_tokens.append", "target_tokens.extend", "spans.append", "torch.randperm", "len", "len"], "function", ["None"], ["def", "corrupt_spans", "(", "text", ",", "mask_ratio", "=", "0.15", ")", ":", "\n", "    ", "\"\"\"T5-style Masked Language Modeling with corrupted span prediction\n    Args:\n        text\n\n    Returns:\n        source_text (masked_text)\n        target_text\n\n    Ex) (in vocab ids)\n    input\n        In this tutorial, we\u2019ll explore how to preprocess your data using Transformers. The main tool for this is what we call a tokenizer.\n\n    masked_text\n        <extra_id_0> this tutorial, we\u2019ll explore how to preprocess your data <extra_id_1> Transformers. The main tool for this is what <extra_id_2> call a tokenizer.\n    target_text\n        <extra_id_0> In <extra_id_1> using <extra_id_2> we\n    \"\"\"", "\n", "\n", "tokens", "=", "text", ".", "split", "(", ")", "\n", "\n", "n_tokens", "=", "len", "(", "tokens", ")", "\n", "\n", "n_mask", "=", "int", "(", "max", "(", "mask_ratio", "*", "n_tokens", ",", "1", ")", ")", "\n", "mask_indices", "=", "torch", ".", "randperm", "(", "n_tokens", ")", "[", ":", "n_mask", "]", ".", "sort", "(", ")", ".", "values", "\n", "\n", "assert", "len", "(", "mask_indices", ")", ">", "0", ",", "text", "\n", "\n", "mask_indices", "=", "mask_indices", ".", "tolist", "(", ")", "\n", "span", "=", "[", "mask_indices", "[", "0", "]", ",", "mask_indices", "[", "0", "]", "+", "1", "]", "\n", "spans", "=", "[", "]", "\n", "\n", "for", "i", ",", "mask_index", "in", "enumerate", "(", "mask_indices", ")", ":", "\n", "# if current mask is not the last one & the next mask is right after current mask", "\n", "        ", "if", "i", "<", "len", "(", "mask_indices", ")", "-", "1", "and", "mask_indices", "[", "i", "+", "1", "]", "==", "mask_index", "+", "1", ":", "\n", "            ", "contiguous", "=", "True", "\n", "", "else", ":", "\n", "            ", "contiguous", "=", "False", "\n", "\n", "", "if", "contiguous", ":", "\n", "            ", "span", "[", "1", "]", "+=", "1", "\n", "\n", "", "else", ":", "\n", "# non contiguous -> output current span", "\n", "            ", "spans", ".", "append", "(", "span", ")", "\n", "# if current mask is not the last one -> create next span", "\n", "if", "i", "<", "len", "(", "mask_indices", ")", "-", "1", ":", "\n", "                ", "span", "=", "[", "mask_indices", "[", "i", "+", "1", "]", ",", "mask_indices", "[", "i", "+", "1", "]", "+", "1", "]", "\n", "\n", "", "", "", "masked_tokens", "=", "deepcopy", "(", "tokens", ")", "\n", "\n", "target_tokens", "=", "[", "]", "\n", "cum_span_length", "=", "0", "\n", "for", "i", ",", "span", "in", "enumerate", "(", "spans", ")", ":", "\n", "        ", "start", ",", "end", "=", "span", "\n", "\n", "masked_tokens", "[", "start", "-", "cum_span_length", "+", "i", ":", "end", "-", "\n", "cum_span_length", "+", "i", "]", "=", "[", "f'<extra_id_{i}>'", "]", "\n", "\n", "target_tokens", ".", "append", "(", "f'<extra_id_{i}>'", ")", "\n", "target_tokens", ".", "extend", "(", "tokens", "[", "start", ":", "end", "]", ")", "\n", "\n", "cum_span_length", "+=", "(", "end", "-", "start", ")", "\n", "\n", "# target_tokens.append(f'<extra_id_{i+1}>')", "\n", "# target_tokens.append(f'</s>')", "\n", "\n", "", "masked_text", "=", "\" \"", ".", "join", "(", "masked_tokens", ")", "\n", "source_text", "=", "masked_text", "\n", "\n", "target_text", "=", "\" \"", ".", "join", "(", "target_tokens", ")", "\n", "\n", "return", "source_text", ",", "target_text", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.preprocess.corrupt_prefix": [[82, 109], ["input_text.split", "len", "random.randint"], "function", ["None"], ["", "def", "corrupt_prefix", "(", "input_text", ")", ":", "\n", "    ", "\"\"\"T5-style Prefix Language Modeling\n    Args:\n        text\n\n    Returns:\n        source_text (prefix)\n        target_text\n\n    Ex) (in vocab ids)\n    input\n        In this tutorial, we\u2019ll explore how to preprocess your data using Transformers. The main tool for this is what we call a tokenizer.\n\n    source text\n        this tutorial, we\u2019ll explore how to preprocess your data using Transformers. The main tool\n    target_text\n        for this is what we call a tokenizer.\n    \"\"\"", "\n", "\n", "tokens", "=", "input_text", ".", "split", "(", ")", "\n", "\n", "n_tokens", "=", "len", "(", "tokens", ")", "\n", "split", "=", "random", ".", "randint", "(", "1", ",", "n_tokens", "-", "1", ")", "\n", "source_text", "=", "\" \"", ".", "join", "(", "tokens", "[", ":", "split", "]", ")", "\n", "target_text", "=", "\" \"", ".", "join", "(", "tokens", "[", "split", ":", "]", ")", "\n", "\n", "return", "source_text", ",", "target_text", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.cococaption_model.FewVLMCOCOCaption.__init__": [[8, 10], ["modeling_t5.FewVLM.__init__"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.cococaption_model.FewVLMCOCOCaption.train_step": [[11, 36], ["batch[].to", "batch[].to", "batch[].to", "batch[].to", "cococaption_model.FewVLMCOCOCaption.", "batch[].to.size", "next", "cococaption_model.FewVLMCOCOCaption.parameters"], "methods", ["None"], ["", "def", "train_step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "vis_feats", "=", "batch", "[", "'vis_feats'", "]", ".", "to", "(", "device", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", ".", "to", "(", "device", ")", "\n", "vis_pos", "=", "batch", "[", "'boxes'", "]", ".", "to", "(", "device", ")", "\n", "\n", "lm_labels", "=", "batch", "[", "\"target_ids\"", "]", ".", "to", "(", "device", ")", "\n", "\n", "reduce_loss", "=", "True", "\n", "output", "=", "self", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vis_inputs", "=", "(", "vis_feats", ",", "vis_pos", ")", ",", "\n", "labels", "=", "lm_labels", ",", "\n", "reduce_loss", "=", "reduce_loss", "\n", ")", "\n", "\n", "lm_mask", "=", "lm_labels", "!=", "-", "100", "\n", "B", ",", "L", "=", "lm_labels", ".", "size", "(", ")", "\n", "\n", "loss", "=", "output", "[", "'loss'", "]", "\n", "\n", "result", "=", "{", "\n", "'loss'", ":", "loss", "\n", "}", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.cococaption_model.FewVLMCOCOCaption.test_step": [[37, 56], ["batch[].to", "batch[].to", "batch[].to", "cococaption_model.FewVLMCOCOCaption.generate", "cococaption_model.FewVLMCOCOCaption.tokenizer.batch_decode", "next", "cococaption_model.FewVLMCOCOCaption.parameters"], "methods", ["None"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "**", "kwargs", ")", ":", "\n", "        ", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "vis_feats", "=", "batch", "[", "'vis_feats'", "]", ".", "to", "(", "device", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", ".", "to", "(", "device", ")", "\n", "vis_pos", "=", "batch", "[", "'boxes'", "]", ".", "to", "(", "device", ")", "\n", "\n", "output", "=", "self", ".", "generate", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vis_inputs", "=", "(", "vis_feats", ",", "vis_pos", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "\n", "generated_sents", "=", "self", ".", "tokenizer", ".", "batch_decode", "(", "output", ",", "skip_special_tokens", "=", "True", ")", "\n", "# print(generated_sents)", "\n", "\n", "result", "=", "{", "}", "\n", "result", "[", "'pred'", "]", "=", "generated_sents", "\n", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_model.FewVLMVQA.__init__": [[9, 23], ["modeling_t5.FewVLM.__init__", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.GELU", "torch.GELU", "torch.GELU", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "num_answers", "=", "None", ",", "label2ans", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "if", "config", ".", "classifier", ":", "\n", "            ", "self", ".", "answer_head", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "d_model", "*", "2", ")", ",", "\n", "nn", ".", "GELU", "(", ")", ",", "\n", "nn", ".", "LayerNorm", "(", "config", ".", "d_model", "*", "2", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "d_model", "*", "2", ",", "num_answers", ")", "\n", ")", "\n", "\n", "", "self", ".", "num_answers", "=", "num_answers", "\n", "self", ".", "label2ans", "=", "label2ans", "\n", "self", ".", "bce_loss", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_model.FewVLMVQA.train_step": [[24, 82], ["batch[].to", "batch[].to", "batch[].to", "next", "len", "vqa_model.FewVLMVQA.", "batch[].to", "vqa_model.FewVLMVQA.answer_head", "vqa_model.FewVLMVQA.bce_loss", "batch[].to", "vqa_model.FewVLMVQA.", "batch[].to.size", "loss.mean.mean.mean", "vqa_model.FewVLMVQA.parameters", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "last_layer_hidden_state.view", "loss.mean.mean.view", "loss.mean.mean.sum", "lm_mask.sum().clamp", "batch[].to", "lm_mask.sum"], "methods", ["None"], ["", "def", "train_step", "(", "self", ",", "batch", ")", ":", "\n", "\n", "        ", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "vis_feats", "=", "batch", "[", "'vis_feats'", "]", ".", "to", "(", "device", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", ".", "to", "(", "device", ")", "\n", "vis_pos", "=", "batch", "[", "'boxes'", "]", ".", "to", "(", "device", ")", "\n", "\n", "if", "self", ".", "config", ".", "classifier", ":", "\n", "            ", "B", "=", "len", "(", "input_ids", ")", "\n", "\n", "decoder_input_ids", "=", "torch", ".", "ones", "(", "\n", "B", ",", "1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "*", "self", ".", "config", ".", "decoder_start_token_id", "\n", "\n", "output", "=", "self", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vis_inputs", "=", "(", "vis_feats", ",", "vis_pos", ")", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "output_hidden_states", "=", "True", ",", "\n", "return_dict", "=", "True", "\n", ")", "\n", "target", "=", "batch", "[", "'targets'", "]", ".", "to", "(", "device", ")", "\n", "\n", "last_layer_hidden_state", "=", "output", ".", "decoder_hidden_states", "[", "-", "1", "]", "\n", "last_hidden_state", "=", "last_layer_hidden_state", ".", "view", "(", "B", ",", "-", "1", ",", "self", ".", "config", ".", "d_model", ")", "[", ":", ",", "-", "1", "]", "\n", "\n", "# [B, num_answers]", "\n", "logit", "=", "self", ".", "answer_head", "(", "last_hidden_state", ")", "\n", "\n", "loss", "=", "self", ".", "bce_loss", "(", "logit", ",", "target", ")", "\n", "\n", "", "else", ":", "\n", "            ", "lm_labels", "=", "batch", "[", "\"target_ids\"", "]", ".", "to", "(", "device", ")", "\n", "output", "=", "self", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vis_inputs", "=", "(", "vis_feats", ",", "vis_pos", ")", ",", "\n", "labels", "=", "lm_labels", ",", "\n", "return_dict", "=", "True", "\n", ")", "\n", "assert", "'loss'", "in", "output", "\n", "\n", "lm_mask", "=", "(", "lm_labels", "!=", "-", "100", ")", ".", "float", "(", ")", "\n", "B", ",", "L", "=", "lm_labels", ".", "size", "(", ")", "\n", "\n", "loss", "=", "output", "[", "'loss'", "]", "\n", "\n", "loss", "=", "loss", ".", "view", "(", "B", ",", "L", ")", "*", "lm_mask", "\n", "\n", "loss", "=", "loss", ".", "sum", "(", "dim", "=", "1", ")", "/", "lm_mask", ".", "sum", "(", "dim", "=", "1", ")", ".", "clamp", "(", "min", "=", "1", ")", "# B", "\n", "\n", "loss", "=", "loss", "*", "batch", "[", "'scores'", "]", ".", "to", "(", "device", "=", "device", ")", "\n", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "\n", "", "result", "=", "{", "\n", "'loss'", ":", "loss", "\n", "}", "\n", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.vqa_model.FewVLMVQA.test_step": [[83, 129], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "vqa_model.FewVLMVQA.eval", "batch[].to", "batch[].to", "batch[].to", "next", "len", "vqa_model.FewVLMVQA.", "vqa_model.FewVLMVQA.answer_head", "vqa_model.FewVLMVQA.max", "pred_ans_id.cpu().numpy.cpu().numpy.cpu().numpy", "vqa_model.FewVLMVQA.generate", "vqa_model.FewVLMVQA.tokenizer.batch_decode", "vqa_model.FewVLMVQA.parameters", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "last_layer_hidden_state.view", "pred_ans_id.cpu().numpy.cpu().numpy.cpu"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "test_step", "(", "self", ",", "batch", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "eval", "(", ")", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "vis_feats", "=", "batch", "[", "'vis_feats'", "]", ".", "to", "(", "device", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", ".", "to", "(", "device", ")", "\n", "vis_pos", "=", "batch", "[", "'boxes'", "]", ".", "to", "(", "device", ")", "\n", "\n", "result", "=", "{", "}", "\n", "if", "self", ".", "config", ".", "classifier", ":", "\n", "            ", "B", "=", "len", "(", "input_ids", ")", "\n", "\n", "decoder_input_ids", "=", "torch", ".", "ones", "(", "\n", "B", ",", "1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "*", "self", ".", "config", ".", "decoder_start_token_id", "\n", "\n", "output", "=", "self", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vis_inputs", "=", "(", "vis_feats", ",", "vis_pos", ")", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "output_hidden_states", "=", "True", ",", "\n", "return_dict", "=", "True", "\n", ")", "\n", "\n", "last_layer_hidden_state", "=", "output", ".", "decoder_hidden_states", "[", "-", "1", "]", "\n", "last_hidden_state", "=", "last_layer_hidden_state", ".", "view", "(", "B", ",", "-", "1", ",", "self", ".", "config", ".", "d_model", ")", "[", ":", ",", "-", "1", "]", "\n", "\n", "# [B, num_answers]", "\n", "logit", "=", "self", ".", "answer_head", "(", "last_hidden_state", ")", "\n", "\n", "score", ",", "pred_ans_id", "=", "logit", ".", "max", "(", "1", ")", "\n", "pred_ans_id", "=", "pred_ans_id", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pred_ans", "=", "[", "self", ".", "label2ans", "[", "ans_id", "]", "for", "ans_id", "in", "pred_ans_id", "]", "\n", "\n", "result", "[", "'pred_ans'", "]", "=", "pred_ans", "\n", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "generate", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vis_inputs", "=", "(", "vis_feats", ",", "vis_pos", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "generated_sents", "=", "self", ".", "tokenizer", ".", "batch_decode", "(", "output", ",", "skip_special_tokens", "=", "True", ")", "\n", "result", "[", "'token_ids'", "]", "=", "output", "\n", "result", "[", "'pred_ans'", "]", "=", "generated_sents", "\n", "\n", "", "return", "result", "", "", "", ""]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAFineTuneDataset.__init__": [[35, 118], ["torch.utils.data.Dataset.__init__", "split.split", "torch.cuda.device_count", "print", "dataset_dir.joinpath", "random.seed", "random.shuffle", "print", "vg_dir.joinpath", "gqa_dir.joinpath", "tokenization.FewVLMTokenizerFast.from_pretrained", "transformers.T5TokenizerFast.from_pretrained", "open", "json.load", "data_info_dicts.extend", "print", "print", "len", "len"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load"], ["    ", "def", "__init__", "(", "self", ",", "split", "=", "'train,valid'", ",", "raw_dataset", "=", "None", ",", "rank", "=", "-", "1", ",", "topk", "=", "-", "1", ",", "verbose", "=", "True", ",", "args", "=", "None", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "raw_dataset", "=", "raw_dataset", "\n", "self", ".", "topk", "=", "topk", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "mode", "=", "mode", "\n", "\n", "# Loading datasets to data", "\n", "self", ".", "sources", "=", "split", ".", "split", "(", "','", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "'Data sources: '", ",", "self", ".", "sources", ")", "\n", "\n", "", "if", "'t5'", "in", "self", ".", "args", ".", "backbone", ":", "\n", "            ", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "                ", "self", ".", "tokenizer", "=", "FewVLMTokenizerFast", ".", "from_pretrained", "(", "\n", "args", ".", "backbone", ",", "\n", "# max_length=self.args.max_text_length,", "\n", "do_lower_case", "=", "self", ".", "args", ".", "do_lower_case", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "tokenizer", "=", "T5TokenizerFast", ".", "from_pretrained", "(", "\n", "args", ".", "backbone", ",", "\n", "# max_length=self.args.max_text_length,", "\n", "do_lower_case", "=", "self", ".", "args", ".", "do_lower_case", ")", "\n", "\n", "", "", "self", ".", "img_ids_to_source", "=", "{", "}", "\n", "data_info_dicts", "=", "[", "]", "\n", "for", "source", "in", "self", ".", "sources", ":", "\n", "            ", "data_info_path", "=", "dataset_dir", ".", "joinpath", "(", "f'GQA/{source}.json'", ")", "\n", "with", "open", "(", "data_info_path", ")", "as", "f", ":", "\n", "                ", "_data_info_dicts", "=", "json", ".", "load", "(", "f", ")", "\n", "# source_img_ids.append([d['img_id'] for d in _data_info_dicts])", "\n", "for", "_d", "in", "_data_info_dicts", ":", "\n", "                    ", "self", ".", "img_ids_to_source", "[", "_d", "[", "'img_id'", "]", "]", "=", "source", "\n", "_d", "[", "'source'", "]", "=", "source", "\n", "\n", "", "data_info_dicts", ".", "extend", "(", "_data_info_dicts", ")", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "f\"Loaded {len(_data_info_dicts)} data from\"", ",", "source", ")", "\n", "\n", "", "", "data", "=", "data_info_dicts", "\n", "\n", "self", ".", "n_gpus", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "self", ".", "rank", "=", "rank", "\n", "\n", "if", "self", ".", "topk", ">", "0", ":", "\n", "            ", "data", "=", "data", "[", ":", "self", ".", "topk", "]", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "f\"Use only {self.topk} data\"", ")", "\n", "\n", "", "", "self", ".", "data", "=", "data", "\n", "\n", "if", "args", ".", "subsample", "and", "split", "==", "'train'", ":", "\n", "            ", "random", ".", "seed", "(", "args", ".", "dataseed", ")", "\n", "random", ".", "shuffle", "(", "self", ".", "data", ")", "\n", "if", "'train'", "in", "split", "and", "mode", "==", "'train'", ":", "\n", "                ", "self", ".", "data", "=", "self", ".", "data", "[", ":", "args", ".", "num_data", "]", "\n", "", "elif", "'train'", "in", "split", "and", "mode", "==", "'val'", ":", "\n", "                ", "self", ".", "data", "=", "self", ".", "data", "[", "args", ".", "num_data", ":", "2", "*", "args", ".", "num_data", "]", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "\"# all sentences:\"", ",", "len", "(", "self", ".", "data", ")", ")", "\n", "\n", "", "self", ".", "n_boxes", "=", "args", ".", "n_boxes", "\n", "\n", "self", ".", "source_to_featname", "=", "{", "\n", "'train'", ":", "'others'", ",", "\n", "'valid'", ":", "'others'", ",", "\n", "'submit'", ":", "'others'", ",", "\n", "'train_10'", ":", "'others'", ",", "'train_20'", ":", "'others'", ",", "'train_30'", ":", "'others'", ",", "'train_40'", ":", "'others'", ",", "'train_50'", ":", "'others'", ",", "\n", "'val_10'", ":", "'others'", ",", "'val_20'", ":", "'others'", ",", "'val_30'", ":", "'others'", ",", "'val_40'", ":", "'others'", ",", "'val_50'", ":", "'others'", ",", "\n", "'train_30_2'", ":", "'others'", ",", "'train_30_3'", ":", "'others'", ",", "'val_30_2'", ":", "'others'", ",", "'val_30_3'", ":", "'others'", ",", "\n", "'train_16'", ":", "'others'", ",", "'train_16_2'", ":", "'others'", ",", "'train_16_3'", ":", "'others'", ",", "'val_16'", ":", "'others'", ",", "'val_16_2'", ":", "'others'", ",", "'val_16_3'", ":", "'others'", ",", "\n", "'train_4'", ":", "'others'", ",", "'train_4_2'", ":", "'others'", ",", "'train_4_3'", ":", "'others'", ",", "'val_4'", ":", "'others'", ",", "'val_4_2'", ":", "'others'", ",", "'val_4_3'", ":", "'others'", ",", "\n", "'testdev'", ":", "'testdev'", "\n", "}", "\n", "\n", "self", ".", "featname_to_h5", "=", "{", "\n", "'others'", ":", "vg_dir", ".", "joinpath", "(", "'features/vg_gqa_obj36.h5'", ")", ",", "\n", "'testdev'", ":", "gqa_dir", ".", "joinpath", "(", "'features/gqa_testdev_obj36.h5'", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAFineTuneDataset.__len__": [[121, 123], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAFineTuneDataset.__getitem__": [[124, 245], ["torch.LongTensor", "len", "isinstance", "numpy.zeros", "f[].read_direct", "torch.from_numpy", "numpy.testing.assert_array_less", "numpy.testing.assert_array_less", "torch.from_numpy", "torch.from_numpy.clamp_", "gqa_data.GQAFineTuneDataset.tokenizer.encode", "label.items", "sum", "torch.LongTensor", "len", "h5py.File", "gqa_data.GQAFineTuneDataset.tokenizer.encode", "answers.append", "scores.append", "numpy.random.multinomial().argmax", "sum", "max", "label.items", "gqa_data.GQAFineTuneDataset.tokenizer.encode", "gqa_data.GQAFineTuneDataset.tokenizer.encode", "gqa_data.GQAFineTuneDataset.tokenizer.encode", "len", "gqa_data.GQAFineTuneDataset.tokenizer.encode", "gqa_data.GQAFineTuneDataset.tokenizer.encode", "numpy.random.multinomial", "best_answers.append"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "out_dict", "=", "{", "}", "\n", "out_dict", "[", "'args'", "]", "=", "self", ".", "args", "\n", "\n", "datum", "=", "self", ".", "data", "[", "idx", "]", "\n", "# uid = datum['uid']", "\n", "# out_dict['uid'] = uid", "\n", "# out_dict['uid'] = uid", "\n", "\n", "###### Image ######", "\n", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "            ", "img_id", "=", "datum", "[", "'img_id'", "]", "\n", "out_dict", "[", "'img_id'", "]", "=", "img_id", "\n", "\n", "source", "=", "self", ".", "img_ids_to_source", "[", "img_id", "]", "\n", "\n", "featname", "=", "self", ".", "source_to_featname", "[", "source", "]", "\n", "\n", "# f = self.source_to_h5[source]", "\n", "f", "=", "self", ".", "featname_to_h5", "[", "featname", "]", "\n", "\n", "if", "isinstance", "(", "f", ",", "Path", ")", ":", "\n", "# path = self.data_source_to_h5_path[source]", "\n", "                ", "f", "=", "h5py", ".", "File", "(", "f", ",", "'r'", ")", "\n", "# self.split_to_h5_features[split_i] = f", "\n", "# self.source_to_h5[source] = f", "\n", "self", ".", "featname_to_h5", "[", "featname", "]", "=", "f", "\n", "\n", "", "feats", "=", "np", ".", "zeros", "(", "shape", "=", "(", "self", ".", "n_boxes", ",", "2048", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "f", "[", "f'{img_id}/features'", "]", ".", "read_direct", "(", "feats", ")", "\n", "feats", "=", "torch", ".", "from_numpy", "(", "feats", ")", "\n", "out_dict", "[", "'vis_feats'", "]", "=", "feats", "\n", "\n", "# Normalize the boxes (to 0 ~ 1)", "\n", "img_h", "=", "f", "[", "f'{img_id}/img_h'", "]", "[", "(", ")", "]", "\n", "img_w", "=", "f", "[", "f'{img_id}/img_w'", "]", "[", "(", ")", "]", "\n", "boxes", "=", "f", "[", "f'{img_id}/boxes'", "]", "[", "(", ")", "]", "# (x1, y1, x2, y2)", "\n", "boxes", "[", ":", ",", "(", "0", ",", "2", ")", "]", "/=", "img_w", "\n", "boxes", "[", ":", ",", "(", "1", ",", "3", ")", "]", "/=", "img_h", "\n", "np", ".", "testing", ".", "assert_array_less", "(", "boxes", ",", "1", "+", "1e-5", ")", "\n", "# np.testing.assert_array_less(boxes, 1+5e-2)", "\n", "np", ".", "testing", ".", "assert_array_less", "(", "-", "boxes", ",", "0", "+", "1e-5", ")", "\n", "boxes", "=", "torch", ".", "from_numpy", "(", "boxes", ")", "\n", "\n", "boxes", ".", "clamp_", "(", "min", "=", "0.0", ",", "max", "=", "1.0", ")", "\n", "\n", "out_dict", "[", "'boxes'", "]", "=", "boxes", "\n", "\n", "###### Text #####", "\n", "# caption = datum['caption']", "\n", "", "sent", "=", "datum", "[", "'sent'", "]", "\n", "\n", "\n", "if", "self", ".", "args", ".", "prompt", "==", "0", ":", "\n", "            ", "input_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "sent", ",", "max_length", "=", "20", ",", "truncation", "=", "True", ")", "\n", "", "elif", "self", ".", "args", ".", "prompt", "==", "1", ":", "\n", "            ", "input_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "f'{sent} <extra_id_0>'", ",", "max_length", "=", "20", ",", "truncation", "=", "True", ")", "\n", "", "elif", "self", ".", "args", ".", "prompt", "==", "2", ":", "\n", "            ", "input_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "f'question: {sent} answer: '", ",", "max_length", "=", "20", ",", "truncation", "=", "True", ")", "\n", "", "elif", "self", ".", "args", ".", "prompt", "==", "3", ":", "\n", "            ", "input_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "f'question: {sent} answer: <extra_id_0>'", ",", "max_length", "=", "20", ",", "truncation", "=", "True", ")", "\n", "\n", "", "question_id", "=", "datum", "[", "'question_id'", "]", "\n", "out_dict", "[", "'question_id'", "]", "=", "question_id", "\n", "\n", "out_dict", "[", "'sent'", "]", "=", "sent", "\n", "out_dict", "[", "'input_ids'", "]", "=", "torch", ".", "LongTensor", "(", "input_ids", ")", "\n", "out_dict", "[", "'input_length'", "]", "=", "len", "(", "input_ids", ")", "\n", "\n", "if", "'label'", "in", "datum", ":", "\n", "            ", "label", "=", "datum", "[", "'label'", "]", "\n", "out_dict", "[", "'label'", "]", "=", "label", "\n", "\n", "# https://github.com/airsplay/lxmert/blob/master/src/pretrain/lxmert_pretrain.py#L191", "\n", "answers", "=", "[", "]", "\n", "scores", "=", "[", "]", "\n", "for", "a", ",", "s", "in", "label", ".", "items", "(", ")", ":", "\n", "                ", "answers", ".", "append", "(", "a", ")", "\n", "scores", ".", "append", "(", "s", ")", "\n", "\n", "", "score_sum", "=", "sum", "(", "scores", ")", "\n", "\n", "if", "score_sum", "==", "0", ":", "\n", "                ", "answer", "=", "''", "\n", "score", "=", "0.", "\n", "", "else", ":", "\n", "                ", "prob", "=", "[", "score", "/", "score_sum", "for", "score", "in", "scores", "]", "\n", "choice", "=", "np", ".", "random", ".", "multinomial", "(", "1", ",", "prob", ")", ".", "argmax", "(", ")", "\n", "answer", "=", "answers", "[", "choice", "]", "\n", "score", "=", "scores", "[", "choice", "]", "\n", "assert", "len", "(", "answer", ")", ">", "0", ",", "(", "sent", ",", "label", ",", "choice", ",", "answer", ")", "\n", "\n", "", "out_dict", "[", "'answer'", "]", "=", "answer", "\n", "out_dict", "[", "'score'", "]", "=", "score", "\n", "out_dict", "[", "'all_answers'", "]", "=", "answers", "\n", "\n", "if", "sum", "(", "scores", ")", ">", "0", ":", "\n", "                ", "best_answers", "=", "[", "]", "\n", "best_score", "=", "max", "(", "scores", ")", "\n", "for", "a", ",", "s", "in", "label", ".", "items", "(", ")", ":", "\n", "                    ", "if", "s", "==", "best_score", "and", "s", ">", "0", ":", "\n", "                        ", "best_answers", ".", "append", "(", "a", ")", "\n", "", "", "out_dict", "[", "'best_answers_tokenized'", "]", "=", "[", "self", ".", "tokenizer", ".", "encode", "(", "a", ")", "for", "a", "in", "best_answers", "]", "\n", "", "else", ":", "\n", "                ", "out_dict", "[", "'best_answers_tokenized'", "]", "=", "[", "[", "]", "]", "\n", "\n", "", "if", "self", ".", "args", ".", "no_mask_target", ":", "\n", "                ", "target_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "answer", ")", "\n", "", "else", ":", "\n", "                ", "target_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "f'<extra_id_0> {answer}'", ")", "\n", "\n", "# if self.args.prompt in [2,4]:", "\n", "#     target_ids = self.tokenizer.encode(f'<extra_id_0> {answer}')", "\n", "# else:", "\n", "#     target_ids = self.tokenizer.encode(answer)", "\n", "\n", "", "out_dict", "[", "'target_ids'", "]", "=", "torch", ".", "LongTensor", "(", "target_ids", ")", "\n", "out_dict", "[", "'target_length'", "]", "=", "len", "(", "target_ids", ")", "\n", "\n", "", "return", "out_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAFineTuneDataset.collate_fn": [[247, 341], ["len", "max", "enumerate", "torch.FloatTensor", "torch.ones", "len", "torch.zeros", "torch.zeros", "torch.zeros", "max", "sentences.append", "question_ids.append", "len", "torch.ones", "answers.append", "all_answers.append", "all_answers_tokenized.append", "best_answers_tokenized.append", "scores.append", "labels.append"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "batch", ")", ":", "\n", "        ", "batch_entry", "=", "{", "}", "\n", "\n", "args", "=", "batch", "[", "0", "]", "[", "'args'", "]", "\n", "\n", "B", "=", "len", "(", "batch", ")", "\n", "\n", "S_W_L", "=", "max", "(", "entry", "[", "'input_length'", "]", "for", "entry", "in", "batch", ")", "\n", "input_ids", "=", "torch", ".", "ones", "(", "B", ",", "S_W_L", ",", "dtype", "=", "torch", ".", "long", ")", "*", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "\n", "if", "args", ".", "use_vision", ":", "\n", "            ", "V_L", "=", "len", "(", "batch", "[", "0", "]", "[", "'boxes'", "]", ")", "\n", "feat_dim", "=", "batch", "[", "0", "]", "[", "'vis_feats'", "]", ".", "shape", "[", "-", "1", "]", "\n", "\n", "boxes", "=", "torch", ".", "zeros", "(", "B", ",", "V_L", ",", "4", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "vis_feats", "=", "torch", ".", "zeros", "(", "B", ",", "V_L", ",", "feat_dim", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "if", "'target'", "in", "batch", "[", "0", "]", ":", "\n", "# targets = []", "\n", "            ", "targets", "=", "torch", ".", "zeros", "(", "B", ",", "len", "(", "batch", "[", "0", "]", "[", "'target'", "]", ")", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "", "if", "'target_ids'", "in", "batch", "[", "0", "]", ":", "\n", "            ", "T_W_L", "=", "max", "(", "entry", "[", "'target_length'", "]", "for", "entry", "in", "batch", ")", "\n", "target_ids", "=", "torch", ".", "ones", "(", "B", ",", "T_W_L", ",", "dtype", "=", "torch", ".", "long", ")", "*", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "\n", "", "sentences", "=", "[", "]", "\n", "question_ids", "=", "[", "]", "\n", "answers", "=", "[", "]", "\n", "all_answers", "=", "[", "]", "\n", "all_answers_tokenized", "=", "[", "]", "\n", "best_answers_tokenized", "=", "[", "]", "\n", "img_ids", "=", "[", "]", "\n", "img_paths", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "scores", "=", "[", "]", "\n", "\n", "for", "i", ",", "entry", "in", "enumerate", "(", "batch", ")", ":", "\n", "            ", "input_ids", "[", "i", ",", ":", "entry", "[", "'input_length'", "]", "]", "=", "entry", "[", "'input_ids'", "]", "\n", "\n", "if", "args", ".", "use_vision", ":", "\n", "                ", "boxes", "[", "i", "]", "+=", "entry", "[", "'boxes'", "]", "\n", "vis_feats", "[", "i", "]", "+=", "entry", "[", "'vis_feats'", "]", "\n", "# img_ids.append(entry['img_id'])", "\n", "# img_paths.append(entry['img_path'])", "\n", "\n", "", "if", "'target_ids'", "in", "entry", ":", "\n", "                ", "target_ids", "[", "i", ",", ":", "entry", "[", "'target_length'", "]", "]", "=", "entry", "[", "'target_ids'", "]", "\n", "\n", "", "if", "'target'", "in", "entry", ":", "\n", "                ", "targets", "[", "i", "]", "+=", "entry", "[", "'target'", "]", "\n", "# targets.append(entry['target'])", "\n", "\n", "", "sentences", ".", "append", "(", "entry", "[", "'sent'", "]", ")", "\n", "question_ids", ".", "append", "(", "entry", "[", "'question_id'", "]", ")", "\n", "if", "'answer'", "in", "entry", ":", "\n", "                ", "answers", ".", "append", "(", "entry", "[", "'answer'", "]", ")", "\n", "", "if", "'all_answers'", "in", "entry", ":", "\n", "                ", "all_answers", ".", "append", "(", "entry", "[", "'all_answers'", "]", ")", "\n", "", "if", "'all_answers_tokenized'", "in", "entry", ":", "\n", "                ", "all_answers_tokenized", ".", "append", "(", "entry", "[", "'all_answers_tokenized'", "]", ")", "\n", "", "if", "'best_answers_tokenized'", "in", "entry", ":", "\n", "                ", "best_answers_tokenized", ".", "append", "(", "entry", "[", "'best_answers_tokenized'", "]", ")", "\n", "", "if", "'score'", "in", "entry", ":", "\n", "                ", "scores", ".", "append", "(", "entry", "[", "'score'", "]", ")", "\n", "\n", "", "if", "'label'", "in", "entry", ":", "\n", "                ", "labels", ".", "append", "(", "entry", "[", "'label'", "]", ")", "\n", "\n", "", "", "batch_entry", "[", "'input_ids'", "]", "=", "input_ids", "\n", "if", "'target_ids'", "in", "batch", "[", "0", "]", ":", "\n", "            ", "word_mask", "=", "target_ids", "!=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "target_ids", "[", "~", "word_mask", "]", "=", "-", "100", "\n", "batch_entry", "[", "'target_ids'", "]", "=", "target_ids", "\n", "", "if", "'target'", "in", "batch", "[", "0", "]", ":", "\n", "# targets = torch.stack(targets, dim=0)", "\n", "            ", "batch_entry", "[", "'targets'", "]", "=", "targets", "\n", "\n", "", "if", "args", ".", "use_vision", ":", "\n", "            ", "batch_entry", "[", "'boxes'", "]", "=", "boxes", "\n", "batch_entry", "[", "'vis_feats'", "]", "=", "vis_feats", "\n", "# batch_entry['img_id'] = img_ids", "\n", "# batch_entry['img_paths'] = img_paths", "\n", "\n", "", "batch_entry", "[", "'sent'", "]", "=", "sentences", "\n", "batch_entry", "[", "'question_ids'", "]", "=", "question_ids", "\n", "batch_entry", "[", "'answers'", "]", "=", "answers", "\n", "batch_entry", "[", "'all_answers'", "]", "=", "all_answers", "\n", "batch_entry", "[", "'all_answers_tokenized'", "]", "=", "all_answers_tokenized", "\n", "batch_entry", "[", "'best_answers_tokenized'", "]", "=", "best_answers_tokenized", "\n", "batch_entry", "[", "'scores'", "]", "=", "torch", ".", "FloatTensor", "(", "scores", ")", "\n", "batch_entry", "[", "'labels'", "]", "=", "labels", "\n", "\n", "batch_entry", "[", "'task'", "]", "=", "'gqa'", "\n", "\n", "return", "batch_entry", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQADataset.__init__": [[399, 423], ["splits.split", "json.load", "json.load", "gqa_data.GQADataset.ans2label.items", "gqa_data.GQADataset.data.extend", "print", "open", "open", "len", "len", "json.load", "gqa_dir.joinpath", "gqa_dir.joinpath", "open", "gqa_dir.joinpath", "len"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load"], ["def", "__init__", "(", "self", ",", "splits", ":", "str", ",", "verbose", "=", "True", ")", ":", "\n", "        ", "self", ".", "name", "=", "splits", "\n", "self", ".", "splits", "=", "splits", ".", "split", "(", "','", ")", "\n", "\n", "# Loading datasets to data", "\n", "self", ".", "data", "=", "[", "]", "\n", "for", "split", "in", "self", ".", "splits", ":", "\n", "            ", "self", ".", "data", ".", "extend", "(", "json", ".", "load", "(", "open", "(", "gqa_dir", ".", "joinpath", "(", "\"%s.json\"", "%", "split", ")", ")", ")", ")", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "\"Load %d data from split(s) %s.\"", "%", "\n", "(", "len", "(", "self", ".", "data", ")", ",", "self", ".", "name", ")", ")", "\n", "\n", "# List to dict (for evaluation and others)", "\n", "", "self", ".", "id2datum", "=", "{", "\n", "datum", "[", "'question_id'", "]", ":", "datum", "\n", "for", "datum", "in", "self", ".", "data", "\n", "}", "\n", "\n", "# Answers", "\n", "self", ".", "ans2label", "=", "json", ".", "load", "(", "open", "(", "gqa_dir", ".", "joinpath", "(", "\"trainval_ans2label.json\"", ")", ")", ")", "\n", "self", ".", "label2ans", "=", "json", ".", "load", "(", "open", "(", "gqa_dir", ".", "joinpath", "(", "\"trainval_label2ans.json\"", ")", ")", ")", "\n", "assert", "len", "(", "self", ".", "ans2label", ")", "==", "len", "(", "self", ".", "label2ans", ")", "\n", "for", "ans", ",", "label", "in", "self", ".", "ans2label", ".", "items", "(", ")", ":", "\n", "            ", "assert", "self", ".", "label2ans", "[", "label", "]", "==", "ans", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQADataset.num_answers": [[424, 427], ["len"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "num_answers", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ans2label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQADataset.__len__": [[428, 430], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAEvaluator.__init__": [[433, 441], ["re.compile", "re.compile"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ":", "GQADataset", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "punct", "=", "[", "';'", ",", "r\"/\"", ",", "'['", ",", "']'", ",", "'\"'", ",", "'{'", ",", "'}'", ",", "\n", "'('", ",", "')'", ",", "'='", ",", "'+'", ",", "'\\\\'", ",", "'_'", ",", "'-'", ",", "\n", "'>'", ",", "'<'", ",", "'@'", ",", "'`'", ",", "','", ",", "'?'", ",", "'!'", "]", "\n", "self", ".", "periodStrip", "=", "re", ".", "compile", "(", "\"(?!<=\\d)(\\.)(?!\\d)\"", ")", "\n", "self", ".", "commaStrip", "=", "re", ".", "compile", "(", "\"(\\d)(\\,)(\\d)\"", ")", "\n", "self", ".", "articles", "=", "[", "'a'", ",", "'an'", ",", "'the'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAEvaluator.processArticle": [[442, 450], ["inText.lower().split", "inText.lower", "outText.append"], "methods", ["None"], ["", "def", "processArticle", "(", "self", ",", "inText", ")", ":", "\n", "        ", "outText", "=", "[", "]", "\n", "tempText", "=", "inText", ".", "lower", "(", ")", ".", "split", "(", ")", "\n", "for", "word", "in", "tempText", ":", "\n", "            ", "if", "word", "not", "in", "self", ".", "articles", ":", "\n", "                ", "outText", ".", "append", "(", "word", ")", "\n", "", "", "outText", "=", "\" \"", ".", "join", "(", "outText", ")", "\n", "return", "outText", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAEvaluator.processPunctuation": [[451, 462], ["gqa_data.GQAEvaluator.periodStrip.sub", "outText.replace.replace.replace", "outText.replace.replace.replace", "re.search"], "methods", ["None"], ["", "def", "processPunctuation", "(", "self", ",", "inText", ")", ":", "\n", "        ", "outText", "=", "inText", "\n", "for", "p", "in", "self", ".", "punct", ":", "\n", "            ", "if", "(", "p", "+", "' '", "in", "inText", "or", "' '", "+", "p", "in", "inText", ")", "or", "(", "re", ".", "search", "(", "self", ".", "commaStrip", ",", "inText", ")", "!=", "None", ")", ":", "\n", "                ", "outText", "=", "outText", ".", "replace", "(", "p", ",", "''", ")", "\n", "", "else", ":", "\n", "                ", "outText", "=", "outText", ".", "replace", "(", "p", ",", "' '", ")", "\n", "", "", "outText", "=", "self", ".", "periodStrip", ".", "sub", "(", "\"\"", ",", "\n", "outText", ",", "\n", "re", ".", "UNICODE", ")", "\n", "return", "outText", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAEvaluator.evaluate": [[463, 473], ["quesid2ans.items", "gqa_data.GQAEvaluator.processPunctuation", "gqa_data.GQAEvaluator.processArticle", "len"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAEvaluator.processPunctuation", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAEvaluator.processArticle"], ["", "def", "evaluate", "(", "self", ",", "quesid2ans", ":", "dict", ")", ":", "\n", "        ", "score", "=", "0.", "\n", "for", "quesid", ",", "ans", "in", "quesid2ans", ".", "items", "(", ")", ":", "\n", "            ", "datum", "=", "self", ".", "dataset", ".", "id2datum", "[", "quesid", "]", "\n", "label", "=", "datum", "[", "'label'", "]", "\n", "ans", "=", "self", ".", "processPunctuation", "(", "ans", ")", "\n", "ans", "=", "self", ".", "processArticle", "(", "ans", ")", "\n", "if", "ans", "in", "label", ":", "\n", "                ", "score", "+=", "label", "[", "ans", "]", "\n", "", "", "return", "score", "/", "len", "(", "quesid2ans", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAEvaluator.dump_result": [[474, 498], ["open", "quesid2ans.items", "json.dump", "result.append"], "methods", ["None"], ["", "def", "dump_result", "(", "self", ",", "quesid2ans", ":", "dict", ",", "path", ")", ":", "\n", "        ", "\"\"\"\n        Dump the result to a GQA-challenge submittable json file.\n        GQA json file submission requirement:\n            results = [result]\n            result = {\n                \"questionId\": str,      # Note: it's a actually an int number but the server requires an str.\n                \"prediction\": str\n            }\n        :param quesid2ans: A dict mapping question id to its predicted answer.\n        :param path: The file path to save the json file.\n        :return:\n        \"\"\"", "\n", "with", "open", "(", "path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "result", "=", "[", "]", "\n", "for", "ques_id", ",", "ans", "in", "quesid2ans", ".", "items", "(", ")", ":", "\n", "                ", "datum", "=", "self", ".", "dataset", ".", "id2datum", "[", "ques_id", "]", "\n", "label", "=", "datum", "[", "'label'", "]", "\n", "result", ".", "append", "(", "{", "\n", "'questionId'", ":", "ques_id", ",", "\n", "'prediction'", ":", "ans", ",", "\n", "'label'", ":", "label", "\n", "}", ")", "\n", "", "json", ".", "dump", "(", "result", ",", "f", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.get_loader": [[343, 384], ["gqa_data.GQADataset", "gqa_data.GQAFineTuneDataset", "gqa_data.GQAEvaluator", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "function", ["None"], ["", "", "def", "get_loader", "(", "args", ",", "split", "=", "'train'", ",", "mode", "=", "'train'", ",", "\n", "batch_size", "=", "32", ",", "workers", "=", "4", ",", "distributed", "=", "False", ",", "gpu", "=", "0", ",", "\n", "topk", "=", "-", "1", ",", "verbose", "=", "None", ")", ":", "\n", "\n", "    ", "if", "verbose", "is", "None", ":", "\n", "        ", "verbose", "=", "(", "gpu", "==", "0", ")", "\n", "\n", "", "_dset", "=", "GQADataset", "(", "split", ",", "verbose", ")", "\n", "\n", "dataset", "=", "GQAFineTuneDataset", "(", "\n", "split", ",", "\n", "raw_dataset", "=", "_dset", ",", "\n", "rank", "=", "gpu", ",", "\n", "topk", "=", "topk", ",", "\n", "verbose", "=", "verbose", ",", "\n", "args", "=", "args", ",", "\n", "mode", "=", "mode", ")", "\n", "\n", "if", "distributed", ":", "\n", "        ", "sampler", "=", "DistributedSampler", "(", "dataset", ")", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "None", "\n", "", "if", "mode", "==", "'train'", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "(", "sampler", "is", "None", ")", ",", "\n", "num_workers", "=", "workers", ",", "pin_memory", "=", "True", ",", "sampler", "=", "sampler", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ")", "\n", "", "else", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "workers", ",", "pin_memory", "=", "True", ",", "\n", "sampler", "=", "sampler", ",", "\n", "shuffle", "=", "None", "if", "(", "sampler", "is", "not", "None", ")", "else", "False", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ",", "\n", "drop_last", "=", "False", ")", "\n", "\n", "", "loader", ".", "evaluator", "=", "GQAEvaluator", "(", "_dset", ")", "\n", "loader", ".", "task", "=", "'gqa'", "\n", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr.Trainer.__init__": [[46, 103], ["trainer_base.TrainerBase.__init__", "flickr.Trainer.create_config", "flickr.Trainer.create_tokenizer", "flickr.Trainer.create_model", "print", "flickr.Trainer.model.to", "flickr.Trainer.model.resize_token_embeddings", "flickr.Trainer.load_checkpoint", "flickr.Trainer.init_weights", "time", "flickr.Trainer.create_optimizer_and_scheduler", "print", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "amp.initialize", "time"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_config", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_tokenizer", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_model", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load_checkpoint", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.init_weights", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_optimizer_and_scheduler"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "train_loader", "=", "None", ",", "val_loader", "=", "None", ",", "test_loader", "=", "None", ",", "train", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "args", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "test_loader", "=", "test_loader", ",", "\n", "train", "=", "train", ")", "\n", "\n", "from", "flickr_model", "import", "FewVLMCOCOCaption", "\n", "\n", "model_kwargs", "=", "{", "}", "\n", "if", "'t5'", "in", "args", ".", "backbone", ":", "\n", "            ", "model_class", "=", "FewVLMCOCOCaption", "\n", "\n", "", "config", "=", "self", ".", "create_config", "(", ")", "\n", "self", ".", "tokenizer", "=", "self", ".", "create_tokenizer", "(", ")", "\n", "\n", "self", ".", "model", "=", "self", ".", "create_model", "(", "model_class", ",", "config", ",", "**", "model_kwargs", ")", "\n", "\n", "if", "'t5'", "in", "self", ".", "args", ".", "tokenizer", ":", "\n", "            ", "self", ".", "model", ".", "resize_token_embeddings", "(", "self", ".", "tokenizer", ".", "vocab_size", ")", "\n", "\n", "", "self", ".", "model", ".", "tokenizer", "=", "self", ".", "tokenizer", "\n", "\n", "# Load Checkpoint", "\n", "self", ".", "start_epoch", "=", "None", "\n", "if", "args", ".", "load", "is", "not", "None", ":", "\n", "            ", "ckpt_path", "=", "args", ".", "load", "+", "'.pth'", "\n", "self", ".", "load_checkpoint", "(", "ckpt_path", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "from_scratch", ":", "\n", "            ", "self", ".", "init_weights", "(", ")", "\n", "\n", "# GPU Options", "\n", "", "print", "(", "f'Model Launching at GPU {self.args.gpu}'", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "from", "time", "import", "time", "\n", "start", "=", "time", "(", ")", "\n", "", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "args", ".", "gpu", ")", "\n", "\n", "# Optimizer", "\n", "if", "train", ":", "\n", "            ", "self", ".", "optim", ",", "self", ".", "lr_scheduler", "=", "self", ".", "create_optimizer_and_scheduler", "(", ")", "\n", "\n", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                ", "self", ".", "scaler", "=", "torch", ".", "cuda", ".", "amp", ".", "GradScaler", "(", ")", "\n", "", "elif", "_use_apex", ":", "\n", "                ", "self", ".", "model", ",", "self", ".", "optim", "=", "amp", ".", "initialize", "(", "\n", "self", ".", "model", ",", "self", ".", "optim", ",", "opt_level", "=", "'O1'", ",", "verbosity", "=", "self", ".", "verbose", ")", "\n", "\n", "", "", "if", "args", ".", "multiGPU", ":", "\n", "            ", "if", "args", ".", "distributed", ":", "\n", "                ", "self", ".", "model", "=", "DDP", "(", "self", ".", "model", ",", "device_ids", "=", "[", "args", ".", "gpu", "]", ",", "\n", "find_unused_parameters", "=", "True", "\n", ")", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "f'It took {time() - start:.1f}s'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr.Trainer.train": [[104, 275], ["utils.LossMeter", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "range", "flickr.Trainer.evaluate", "pprint.pprint.pformat", "print", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "flickr.Trainer.model.train", "enumerate", "flickr.Trainer.save", "os.path.isdir", "os.makedirs", "os.path.join", "flickr.Trainer.load", "print", "flickr.Trainer.train_loader.sampler.set_epoch", "tqdm.tqdm.tqdm", "loss.detach.detach.detach", "flickr.Trainer.items", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "tqdm.tqdm.tqdm.close", "flickr.Trainer.evaluate", "pprint.pprint.pformat", "print", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "flickr.Trainer.scaler.scale().backward", "flickr.Trainer.model.parameters", "utils.LossMeter.update", "tqdm.tqdm.tqdm.set_description", "tqdm.tqdm.tqdm.update", "flickr.Trainer.save", "len", "autocast", "flickr.Trainer.model.module.train_step", "flickr.Trainer.model.train_step", "loss.detach.detach.backward", "flickr.Trainer.scaler.unscale_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "flickr.Trainer.scaler.step", "flickr.Trainer.scaler.update", "flickr.Trainer.optim.step", "flickr.Trainer.lr_scheduler.step", "v.item", "packaging.version.parse", "packaging.version.parse", "loss.detach.detach.item", "flickr.Trainer.model.module.train_step", "flickr.Trainer.model.train_step", "flickr.Trainer.scaler.scale", "amp.scale_loss", "scaled_loss.backward", "flickr.Trainer.model.parameters", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "flickr.Trainer.lr_scheduler.get_last_lr", "flickr.Trainer.lr_scheduler.get_lr", "flickr.Trainer.optim.get_lr", "amp.master_params", "flickr.Trainer.model.parameters", "len"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.train", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step"], ["", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "verbose", ":", "\n", "            ", "loss_meter", "=", "LossMeter", "(", ")", "\n", "best_valid", "=", "0.", "\n", "best_epoch", "=", "0", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "global_step", "=", "0", "\n", "epochs", "=", "self", ".", "args", ".", "epochs", "\n", "\n", "if", "not", "self", ".", "args", ".", "test_only", ":", "\n", "            ", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "\n", "                ", "if", "self", ".", "start_epoch", "is", "not", "None", ":", "\n", "                    ", "epoch", "+=", "self", ".", "start_epoch", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "self", ".", "train_loader", ".", "sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                    ", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "self", ".", "train_loader", ")", ",", "ncols", "=", "120", ")", "\n", "\n", "", "epoch_results", "=", "{", "\n", "'loss'", ":", "0.", ",", "\n", "\n", "}", "\n", "\n", "for", "step_i", ",", "batch", "in", "enumerate", "(", "self", ".", "train_loader", ")", ":", "\n", "\n", "                    ", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                        ", "with", "autocast", "(", ")", ":", "\n", "                            ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                                ", "results", "=", "self", ".", "model", ".", "module", ".", "train_step", "(", "batch", ")", "\n", "", "else", ":", "\n", "                                ", "results", "=", "self", ".", "model", ".", "train_step", "(", "batch", ")", "\n", "", "", "", "else", ":", "\n", "                        ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                            ", "results", "=", "self", ".", "model", ".", "module", ".", "train_step", "(", "batch", ")", "\n", "", "else", ":", "\n", "                            ", "results", "=", "self", ".", "model", ".", "train_step", "(", "batch", ")", "\n", "\n", "", "", "loss", "=", "results", "[", "'loss'", "]", "\n", "\n", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                        ", "self", ".", "scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "", "elif", "self", ".", "args", ".", "fp16", "and", "_use_apex", ":", "\n", "                        ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "self", ".", "optim", ")", "as", "scaled_loss", ":", "\n", "                            ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                        ", "loss", ".", "backward", "(", ")", "\n", "\n", "\n", "", "loss", "=", "loss", ".", "detach", "(", ")", "\n", "\n", "# Update Parameters", "\n", "if", "self", ".", "args", ".", "clip_grad_norm", ">", "0", ":", "\n", "                        ", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                            ", "self", ".", "scaler", ".", "unscale_", "(", "self", ".", "optim", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "", "elif", "self", ".", "args", ".", "fp16", "and", "_use_apex", ":", "\n", "                            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "\n", "self", ".", "optim", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "", "else", ":", "\n", "                            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "\n", "", "", "update", "=", "True", "\n", "if", "self", ".", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                        ", "if", "step_i", "==", "0", ":", "\n", "                            ", "update", "=", "False", "\n", "", "elif", "step_i", "%", "self", ".", "args", ".", "gradient_accumulation_steps", "==", "0", "or", "step_i", "==", "len", "(", "self", ".", "train_loader", ")", "-", "1", ":", "\n", "                            ", "update", "=", "True", "\n", "", "else", ":", "\n", "                            ", "update", "=", "False", "\n", "\n", "", "", "if", "update", ":", "\n", "                        ", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                            ", "self", ".", "scaler", ".", "step", "(", "self", ".", "optim", ")", "\n", "self", ".", "scaler", ".", "update", "(", ")", "\n", "", "else", ":", "\n", "                            ", "self", ".", "optim", ".", "step", "(", ")", "\n", "\n", "", "if", "self", ".", "lr_scheduler", ":", "\n", "                            ", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "# self.model.zero_grad()", "\n", "", "for", "param", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "                            ", "param", ".", "grad", "=", "None", "\n", "", "global_step", "+=", "1", "\n", "\n", "", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", ":", "\n", "                        ", "if", "k", "in", "epoch_results", ":", "\n", "                            ", "epoch_results", "[", "k", "]", "+=", "v", ".", "item", "(", ")", "\n", "\n", "", "", "if", "self", ".", "lr_scheduler", ":", "\n", "                        ", "if", "version", ".", "parse", "(", "torch", ".", "__version__", ")", ">=", "version", ".", "parse", "(", "\"1.4\"", ")", ":", "\n", "                            ", "lr", "=", "self", ".", "lr_scheduler", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                            ", "lr", "=", "self", ".", "lr_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "", "", "else", ":", "\n", "                        ", "try", ":", "\n", "                            ", "lr", "=", "self", ".", "optim", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "", "except", "AttributeError", ":", "\n", "                            ", "lr", "=", "self", ".", "args", ".", "lr", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "                        ", "loss_meter", ".", "update", "(", "loss", ".", "item", "(", ")", ")", "\n", "desc_str", "=", "f'Epoch {epoch} | LR {lr:.6f} | Steps {global_step}'", "\n", "desc_str", "+=", "f' | Loss {loss_meter.val:4f}'", "\n", "pbar", ".", "set_description", "(", "desc_str", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                    ", "pbar", ".", "close", "(", ")", "\n", "\n", "# format ex)", "\n", "# {'Bleu_1': 0.9999999997500004,", "\n", "#  'Bleu_2': 0.5773502690332603,", "\n", "#  'Bleu_3': 4.3679023223468616e-06,", "\n", "#  'Bleu_4': 1.4287202142987477e-08,", "\n", "#  'CIDEr': 3.333333333333333,", "\n", "#  'METEOR': 0.43354749322305886,", "\n", "#  'ROUGE_L': 0.75,", "\n", "#  'SPICE': 0.6666666666666666}", "\n", "\n", "# Validation", "\n", "valid_results", "=", "self", ".", "evaluate", "(", "self", ".", "val_loader", ")", "\n", "\n", "valid_score", "=", "valid_results", "[", "'CIDEr'", "]", "\n", "\n", "if", "valid_score", ">", "best_valid", "or", "epoch", "==", "0", ":", "\n", "                        ", "best_valid", "=", "valid_score", "\n", "best_epoch", "=", "epoch", "\n", "self", ".", "save", "(", "\"BEST\"", ")", "\n", "\n", "", "log_str", "=", "''", "\n", "\n", "log_str", "+=", "pformat", "(", "valid_results", ")", "\n", "log_str", "+=", "\"\\nEpoch %d: Valid CIDEr %0.4f\"", "%", "(", "epoch", ",", "valid_score", ")", "\n", "log_str", "+=", "\"\\nEpoch %d: Best CIDEr %0.4f\\n\"", "%", "(", "best_epoch", ",", "best_valid", ")", "\n", "\n", "print", "(", "log_str", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "dist", ".", "barrier", "(", ")", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "                ", "self", ".", "save", "(", "\"LAST\"", ")", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "\n", "# Test Set", "\n", "            ", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "args", ".", "output", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "self", ".", "args", ".", "output", ",", "exist_ok", "=", "True", ")", "\n", "", "if", "not", "self", ".", "args", ".", "test_only", ":", "\n", "                ", "best_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output", ",", "'BEST'", ")", "\n", "self", ".", "load", "(", "best_path", ")", "\n", "print", "(", "f'\\nUploaded checkpoint {best_epoch}'", ",", "best_path", ")", "\n", "\n", "", "test_results", "=", "self", ".", "evaluate", "(", "self", ".", "test_loader", ")", "\n", "\n", "log_str", "=", "'Test set results\\n'", "\n", "log_str", "+=", "pformat", "(", "test_results", ")", "\n", "\n", "print", "(", "log_str", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr.Trainer.predict": [[276, 315], ["flickr.Trainer.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "tqdm.tqdm.tqdm", "predictions.extend", "flickr.Trainer.model.module.test_step", "flickr.Trainer.model.test_step", "targets.extend"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.test_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.test_step"], ["", "", "def", "predict", "(", "self", ",", "loader", ",", "dump_path", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Predict the answers to questions in a data split.\n        :param eval_tuple: The data tuple to be evaluated.\n        :param dump: The path of saved file to dump results.\n        :return: A dict of question_id to answer.\n        \"\"\"", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "            ", "predictions", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "\n", "gen_kwargs", "=", "{", "}", "\n", "gen_kwargs", "[", "'num_beams'", "]", "=", "self", ".", "args", ".", "num_beams", "\n", "gen_kwargs", "[", "'max_length'", "]", "=", "self", ".", "args", ".", "gen_max_length", "\n", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "tqdm", "(", "loader", ",", "ncols", "=", "120", ",", "desc", "=", "\"Prediction\"", ")", ")", ":", "\n", "\n", "                ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "results", "=", "self", ".", "model", ".", "module", ".", "test_step", "(", "\n", "batch", ",", "\n", "**", "gen_kwargs", ")", "\n", "", "else", ":", "\n", "                    ", "results", "=", "self", ".", "model", ".", "test_step", "(", "\n", "batch", ",", "\n", "**", "gen_kwargs", ")", "\n", "\n", "", "predictions", ".", "extend", "(", "results", "[", "'pred'", "]", ")", "\n", "\n", "if", "'targets'", "in", "batch", ":", "\n", "                    ", "targets", ".", "extend", "(", "batch", "[", "'targets'", "]", ")", "\n", "\n", "", "", "results", "=", "{", "\n", "'predictions'", ":", "predictions", ",", "\n", "'targets'", ":", "targets", "\n", "}", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr.Trainer.evaluate": [[316, 325], ["flickr.Trainer.predict", "evaluator.evaluate"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.predict", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate"], ["", "", "def", "evaluate", "(", "self", ",", "loader", ",", "dump_path", "=", "None", ")", ":", "\n", "        ", "evaluator", "=", "loader", ".", "evaluator", "\n", "results", "=", "self", ".", "predict", "(", "loader", ",", "dump_path", ")", "\n", "\n", "predictions", "=", "results", "[", "'predictions'", "]", "\n", "if", "dump_path", "is", "None", ":", "\n", "            ", "targets", "=", "results", "[", "'targets'", "]", "\n", "eval_results", "=", "evaluator", ".", "evaluate", "(", "predictions", ",", "targets", ")", "\n", "return", "eval_results", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr.Trainer.oracle_score": [[326, 340], ["enumerate", "evaluator.evaluate", "label.max", "zip", "label.cpu().numpy", "label.cpu"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate"], ["", "", "@", "staticmethod", "\n", "def", "oracle_score", "(", "loader", ")", ":", "\n", "        ", "evaluator", "=", "loader", ".", "evaluator", "\n", "quesid2ans", "=", "{", "}", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "loader", ")", ":", "\n", "\n", "            ", "ques_id", "=", "batch", "[", "'question_ids'", "]", "\n", "label", "=", "batch", "[", "'targets'", "]", "\n", "\n", "_", ",", "label", "=", "label", ".", "max", "(", "1", ")", "\n", "for", "qid", ",", "l", "in", "zip", "(", "ques_id", ",", "label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ":", "\n", "                ", "ans", "=", "loader", ".", "dataset", ".", "raw_dataset", ".", "label2ans", "[", "l", "]", "\n", "quesid2ans", "[", "qid", "]", "=", "ans", "\n", "", "", "return", "evaluator", ".", "evaluate", "(", "quesid2ans", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr.main_worker": [[341, 388], ["print", "print", "flickr_data.get_loader", "flickr.Trainer", "flickr.Trainer.train", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.init_process_group", "print", "flickr_data.get_loader", "print", "print", "flickr_data.get_loader", "len"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.train", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader"], ["", "", "def", "main_worker", "(", "gpu", ",", "args", ")", ":", "\n", "# GPU is assigned", "\n", "    ", "args", ".", "gpu", "=", "gpu", "\n", "args", ".", "rank", "=", "gpu", "\n", "print", "(", "f'Process Launching at GPU {gpu}'", ")", "\n", "\n", "if", "args", ".", "distributed", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "dist", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "\n", "", "print", "(", "f'Building train loader at GPU {gpu}'", ")", "\n", "train_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "train", ",", "mode", "=", "'train'", ",", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "distributed", "=", "args", ".", "distributed", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "args", ".", "num_workers", ",", "\n", "topk", "=", "args", ".", "train_topk", ",", "\n", ")", "\n", "if", "gpu", "==", "0", ":", "\n", "        ", "if", "args", ".", "valid_batch_size", "is", "not", "None", ":", "\n", "            ", "valid_batch_size", "=", "args", ".", "valid_batch_size", "\n", "", "else", ":", "\n", "            ", "valid_batch_size", "=", "args", ".", "batch_size", "\n", "", "print", "(", "f'Building val loader at GPU {gpu}'", ")", "\n", "val_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "valid", ",", "mode", "=", "'val'", ",", "batch_size", "=", "valid_batch_size", ",", "\n", "distributed", "=", "False", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "4", ",", "\n", "topk", "=", "args", ".", "valid_topk", ",", "\n", ")", "\n", "print", "(", "'# len val loader:'", ",", "len", "(", "val_loader", ")", ")", "\n", "\n", "print", "(", "f'Building test loader at GPU {gpu}'", ")", "\n", "test_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "test", ",", "mode", "=", "'val'", ",", "batch_size", "=", "valid_batch_size", ",", "\n", "distributed", "=", "False", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "4", ",", "\n", "topk", "=", "args", ".", "valid_topk", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "val_loader", "=", "None", "\n", "test_loader", "=", "None", "\n", "\n", "", "trainer", "=", "Trainer", "(", "args", ",", "train_loader", ",", "val_loader", ",", "test_loader", ",", "train", "=", "True", ")", "\n", "trainer", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.PretrainDataset.__init__": [[107, 221], ["split.split", "args.losses.split", "len", "len", "print", "dataset_dir.joinpath", "print", "multiprocessing.Pool", "print", "Counter", "print", "Counter.items", "print", "coco_dir.joinpath().joinpath", "coco_dir.joinpath().joinpath", "coco_dir.joinpath().joinpath", "vg_dir.joinpath().joinpath", "cc_dir.joinpath().joinpath", "cc_dir.joinpath().joinpath", "open", "json.load", "data.extend", "len", "print", "print", "len", "tokenization.FewVLMTokenizerFast.from_pretrained", "transformers.T5TokenizerFast.from_pretrained", "open", "json.load", "print", "Counter.update", "coco_dir.joinpath", "coco_dir.joinpath", "coco_dir.joinpath", "vg_dir.joinpath", "cc_dir.joinpath", "cc_dir.joinpath", "dataset_dir.joinpath", "tqdm.tqdm.tqdm", "pool.imap", "print", "exit", "pool.imap", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update"], ["    ", "def", "__init__", "(", "self", ",", "split", "=", "'vg'", ",", "rank", "=", "-", "1", ",", "topk", "=", "-", "1", ",", "verbose", "=", "True", ",", "args", "=", "None", ",", "is_train", "=", "True", ")", ":", "\n", "\n", "        ", "self", ".", "topk", "=", "topk", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "pointer_h5", "=", "None", "\n", "\n", "# Loading datasets to data", "\n", "self", ".", "sources", "=", "split", ".", "split", "(", "','", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "'Data sources: '", ",", "self", ".", "sources", ")", "\n", "\n", "", "self", ".", "img_ids_to_source", "=", "{", "}", "\n", "\n", "losses", "=", "args", ".", "losses", ".", "split", "(", "','", ")", "\n", "\n", "data", "=", "[", "]", "\n", "for", "img_source", "in", "self", ".", "sources", ":", "\n", "            ", "if", "img_source", "==", "'cc_train'", ":", "\n", "                ", "with", "open", "(", "dataset_dir", ".", "joinpath", "(", "'lxmert/cc_train_pointer_h5.json'", ")", ")", "as", "f", ":", "\n", "                    ", "self", ".", "pointer_h5", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "\n", "", "", "data_info_path", "=", "dataset_dir", ".", "joinpath", "(", "f'lxmert/{img_source}.json'", ")", "\n", "with", "open", "(", "data_info_path", ")", "as", "f", ":", "\n", "                ", "_data", "=", "json", ".", "load", "(", "f", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "                    ", "print", "(", "f\"Loaded {len(_data)} data from\"", ",", "img_source", ")", "\n", "# source_img_ids.append([d['img_id'] for d in _data])", "\n", "", "for", "datum", "in", "_data", ":", "\n", "                    ", "self", ".", "img_ids_to_source", "[", "datum", "[", "'img_id'", "]", "]", "=", "img_source", "\n", "# datum['img_source'] = img_source", "\n", "datum", "[", "'args'", "]", "=", "args", "\n", "datum", "[", "'is_train'", "]", "=", "is_train", "\n", "datum", "[", "'caption_only'", "]", "=", "args", ".", "caption_only", "\n", "\n", "datum", "[", "'lm'", "]", "=", "'lm'", "in", "losses", "\n", "datum", "[", "'prefix'", "]", "=", "'prefix'", "in", "losses", "\n", "\n", "datum", "[", "'backbone'", "]", "=", "self", ".", "args", ".", "backbone", "\n", "\n", "", "data", ".", "extend", "(", "_data", ")", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "\"# images:\"", ",", "len", "(", "data", ")", ")", "\n", "\n", "", "if", "self", ".", "topk", ">", "0", ":", "\n", "            ", "data", "=", "data", "[", ":", "self", ".", "topk", "]", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "f\"Use only {self.topk} data\"", ")", "\n", "\n", "\n", "", "", "with", "Pool", "(", "8", ")", "as", "pool", ":", "\n", "            ", "if", "self", ".", "verbose", ":", "\n", "                ", "data", "=", "[", "datum", "for", "_data", "in", "tqdm", "(", "\n", "pool", ".", "imap", "(", "get_datum", ",", "data", ")", ",", "total", "=", "len", "(", "data", ")", ",", "ncols", "=", "100", ",", "desc", "=", "\"Creating pretrainig data examples\"", ")", "for", "datum", "in", "_data", "]", "\n", "", "else", ":", "\n", "                ", "data", "=", "[", "datum", "for", "_data", "in", "pool", ".", "imap", "(", "\n", "get_datum", ",", "data", ")", "for", "datum", "in", "_data", "]", "\n", "\n", "", "", "if", "self", ".", "args", ".", "itm_cocoonly", ":", "\n", "            ", "caption_sources", "=", "[", "'mscoco'", "]", "\n", "", "else", ":", "\n", "            ", "caption_sources", "=", "[", "'mscoco'", ",", "'vg'", ",", "'cc'", "]", "\n", "", "self", ".", "data_captions", "=", "[", "datum", "for", "datum", "in", "data", "if", "datum", "[", "'text_source'", "]", "in", "caption_sources", "]", "\n", "self", ".", "n_data_captions", "=", "len", "(", "self", ".", "data_captions", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "'# itm data:'", ",", "self", ".", "n_data_captions", ")", "\n", "\n", "", "self", ".", "data", "=", "data", "\n", "self", ".", "n_data", "=", "len", "(", "self", ".", "data", ")", "\n", "\n", "if", "self", ".", "verbose", "and", "is_train", ":", "\n", "            ", "from", "collections", "import", "Counter", "\n", "task_counter", "=", "Counter", "(", ")", "\n", "for", "datum", "in", "data", ":", "\n", "                ", "try", ":", "\n", "                    ", "task_counter", ".", "update", "(", "[", "datum", "[", "'task'", "]", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "                    ", "print", "(", "datum", ")", "\n", "exit", "(", ")", "\n", "\n", "", "", "print", "(", "task_counter", ")", "\n", "for", "k", ",", "v", "in", "task_counter", ".", "items", "(", ")", ":", "\n", "                ", "print", "(", "k", ",", "f'{v/len(data)*100:.1f}%'", ")", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "\"# examples:\"", ",", "len", "(", "data", ")", ")", "\n", "\n", "", "self", ".", "source_to_h5", "=", "{", "\n", "'mscoco_resplit_train_train2014'", ":", "coco_dir", ".", "joinpath", "(", "'features'", ")", ".", "joinpath", "(", "'train2014_obj36.h5'", ")", ",", "\n", "'mscoco_resplit_train_val2014'", ":", "coco_dir", ".", "joinpath", "(", "'features'", ")", ".", "joinpath", "(", "'val2014_obj36.h5'", ")", ",", "\n", "'mscoco_resplit_val'", ":", "coco_dir", ".", "joinpath", "(", "'features'", ")", ".", "joinpath", "(", "'resplit_val_obj36.h5'", ")", ",", "\n", "'vgnococo'", ":", "vg_dir", ".", "joinpath", "(", "'features'", ")", ".", "joinpath", "(", "'vg_gqa_obj36.h5'", ")", ",", "\n", "'cc_train'", ":", "cc_dir", ".", "joinpath", "(", "'features'", ")", ".", "joinpath", "(", "'train_obj36.h5'", ")", ",", "\n", "'cc_valid'", ":", "cc_dir", ".", "joinpath", "(", "'features'", ")", ".", "joinpath", "(", "'valid_obj36.h5'", ")", ",", "\n", "\n", "}", "\n", "\n", "self", ".", "n_boxes", "=", "args", ".", "n_boxes", "\n", "\n", "if", "'t5'", "in", "self", ".", "args", ".", "backbone", ":", "\n", "            ", "if", "self", ".", "args", ".", "use_vision", ":", "\n", "# self.tokenizer = FewVLMTokenizer.from_pretrained(", "\n", "#     args.backbone, do_lower_case=args.do_lower_case)", "\n", "                ", "self", ".", "tokenizer", "=", "FewVLMTokenizerFast", ".", "from_pretrained", "(", "\n", "args", ".", "backbone", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "", "else", ":", "\n", "# self.tokenizer = T5Tokenizer.from_pretrained(", "\n", "#     args.backbone, do_lower_case=args.do_lower_case)", "\n", "                ", "self", ".", "tokenizer", "=", "T5TokenizerFast", ".", "from_pretrained", "(", "\n", "args", ".", "backbone", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.PretrainDataset.__len__": [[224, 227], ["None"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "# return len(self.data)", "\n", "        ", "return", "self", ".", "n_data", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.PretrainDataset.__getitem__": [[228, 323], ["pretrain_data.PretrainDataset.tokenizer.encode", "pretrain_data.PretrainDataset.tokenizer.encode", "torch.LongTensor", "len", "torch.LongTensor", "len", "numpy.zeros", "torch.from_numpy", "numpy.testing.assert_array_less", "numpy.testing.assert_array_less", "torch.from_numpy", "torch.from_numpy.clamp_", "cc_dir.joinpath().joinpath", "h5py.File", "isinstance", "preprocess.corrupt_spans", "f[].read_direct", "h5py.File", "preprocess.corrupt_prefix", "print", "print", "print", "exit", "cc_dir.joinpath"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.preprocess.corrupt_spans", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.preprocess.corrupt_prefix"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "out_dict", "=", "{", "}", "\n", "out_dict", "[", "'args'", "]", "=", "self", ".", "args", "\n", "\n", "datum", "=", "self", ".", "data", "[", "idx", "]", "\n", "uid", "=", "datum", "[", "'uid'", "]", "\n", "out_dict", "[", "'uid'", "]", "=", "uid", "\n", "\n", "###### Image ######", "\n", "img_id", "=", "datum", "[", "'img_id'", "]", "\n", "source", "=", "datum", "[", "'img_source'", "]", "\n", "if", "source", "==", "'cc_train'", ":", "\n", "            ", "path", "=", "cc_dir", ".", "joinpath", "(", "'features'", ")", ".", "joinpath", "(", "self", ".", "pointer_h5", "[", "img_id", "]", ")", "\n", "f", "=", "h5py", ".", "File", "(", "path", ",", "'r'", ")", "\n", "", "else", ":", "\n", "            ", "f", "=", "self", ".", "source_to_h5", "[", "source", "]", "\n", "if", "isinstance", "(", "f", ",", "Path", ")", ":", "\n", "                ", "path", "=", "self", ".", "source_to_h5", "[", "source", "]", "\n", "f", "=", "h5py", ".", "File", "(", "path", ",", "'r'", ")", "\n", "# self.source_to_h5[source] = f", "\n", "\n", "", "", "text_source", "=", "datum", "[", "'text_source'", "]", "\n", "task", "=", "datum", "[", "'task'", "]", "\n", "\n", "loss_weight", "=", "1", "\n", "\n", "# T5 Corrupt span", "\n", "if", "task", "==", "'lm'", ":", "\n", "            ", "assert", "text_source", "in", "[", "\"mscoco\"", ",", "'vg'", ",", "'cc'", "]", "\n", "\n", "# prefix = \"span prediction:\"", "\n", "sent", "=", "datum", "[", "'sent'", "]", "\n", "source_text", ",", "target_text", "=", "preprocess", ".", "corrupt_spans", "(", "\n", "sent", ",", "mask_ratio", "=", "self", ".", "args", ".", "word_mask_rate", ")", "\n", "\n", "input_tokens", "=", "[", "source_text", "]", "\n", "source_text", "=", "' '", ".", "join", "(", "input_tokens", ")", "\n", "\n", "\n", "", "elif", "task", "==", "'prefix'", ":", "\n", "            ", "assert", "text_source", "in", "[", "\"mscoco\"", ",", "'vg'", ",", "'cc'", "]", "\n", "\n", "sent", "=", "datum", "[", "'sent'", "]", "\n", "source_text", ",", "target_text", "=", "preprocess", ".", "corrupt_prefix", "(", "sent", ")", "\n", "\n", "input_tokens", "=", "[", "source_text", "]", "\n", "\n", "source_text", "=", "' '", ".", "join", "(", "input_tokens", ")", "\n", "\n", "", "input_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "\n", "source_text", ",", "padding", "=", "True", ",", "truncation", "=", "True", ",", "max_length", "=", "self", ".", "args", ".", "max_text_length", ")", "\n", "target_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "\n", "target_text", ",", "padding", "=", "True", ",", "truncation", "=", "True", ",", "max_length", "=", "self", ".", "args", ".", "gen_max_length", ")", "\n", "\n", "\n", "out_dict", "[", "'input_ids'", "]", "=", "torch", ".", "LongTensor", "(", "input_ids", ")", "\n", "out_dict", "[", "'input_length'", "]", "=", "len", "(", "input_ids", ")", "\n", "out_dict", "[", "'target_ids'", "]", "=", "torch", ".", "LongTensor", "(", "target_ids", ")", "\n", "out_dict", "[", "'target_length'", "]", "=", "len", "(", "target_ids", ")", "\n", "\n", "out_dict", "[", "'source_text'", "]", "=", "source_text", "\n", "out_dict", "[", "'target_text'", "]", "=", "target_text", "\n", "\n", "out_dict", "[", "'task'", "]", "=", "task", "\n", "out_dict", "[", "'sent'", "]", "=", "sent", "\n", "\n", "out_dict", "[", "'loss_weight'", "]", "=", "loss_weight", "\n", "\n", "feats", "=", "np", ".", "zeros", "(", "shape", "=", "(", "self", ".", "n_boxes", ",", "2048", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "try", ":", "\n", "            ", "f", "[", "f'{img_id}/features'", "]", ".", "read_direct", "(", "feats", ")", "\n", "", "except", "KeyError", ":", "\n", "            ", "print", "(", "uid", ")", "\n", "print", "(", "source", ")", "\n", "print", "(", "img_id", ")", "\n", "exit", "(", ")", "\n", "\n", "", "feats", "=", "torch", ".", "from_numpy", "(", "feats", ")", "\n", "out_dict", "[", "'vis_feats'", "]", "=", "feats", "\n", "\n", "# Normalize the boxes (to 0 ~ 1)", "\n", "img_h", "=", "f", "[", "f'{img_id}/img_h'", "]", "[", "(", ")", "]", "\n", "img_w", "=", "f", "[", "f'{img_id}/img_w'", "]", "[", "(", ")", "]", "\n", "boxes", "=", "f", "[", "f'{img_id}/boxes'", "]", "[", "(", ")", "]", "# (x1, y1, x2, y2)", "\n", "boxes", "[", ":", ",", "(", "0", ",", "2", ")", "]", "/=", "img_w", "\n", "boxes", "[", ":", ",", "(", "1", ",", "3", ")", "]", "/=", "img_h", "\n", "np", ".", "testing", ".", "assert_array_less", "(", "boxes", ",", "1", "+", "1e-5", ")", "\n", "# np.testing.assert_array_less(boxes, 1+5e-2)", "\n", "np", ".", "testing", ".", "assert_array_less", "(", "-", "boxes", ",", "0", "+", "1e-5", ")", "\n", "boxes", "=", "torch", ".", "from_numpy", "(", "boxes", ")", "\n", "boxes", ".", "clamp_", "(", "min", "=", "0.0", ",", "max", "=", "1.0", ")", "\n", "out_dict", "[", "'boxes'", "]", "=", "boxes", "\n", "\n", "return", "out_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.PretrainDataset.collate_fn": [[325, 398], ["len", "len", "max", "max", "torch.zeros", "torch.zeros", "torch.ones", "enumerate", "torch.ones", "torch.ones", "sentences.append", "uids.append", "ans.append", "tasks.append", "source_text.append", "target_text.append"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "batch", ")", ":", "\n", "        ", "batch_entry", "=", "{", "}", "\n", "\n", "B", "=", "len", "(", "batch", ")", "\n", "\n", "args", "=", "self", ".", "args", "\n", "\n", "V_L", "=", "len", "(", "batch", "[", "0", "]", "[", "'boxes'", "]", ")", "\n", "\n", "S_W_L", "=", "max", "(", "entry", "[", "'input_length'", "]", "for", "entry", "in", "batch", ")", "\n", "T_W_L", "=", "max", "(", "entry", "[", "'target_length'", "]", "for", "entry", "in", "batch", ")", "\n", "\n", "feat_dim", "=", "batch", "[", "0", "]", "[", "'vis_feats'", "]", ".", "shape", "[", "-", "1", "]", "\n", "\n", "input_ids", "=", "torch", ".", "ones", "(", "B", ",", "S_W_L", ",", "dtype", "=", "torch", ".", "long", ")", "*", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "target_ids", "=", "torch", ".", "ones", "(", "B", ",", "T_W_L", ",", "dtype", "=", "torch", ".", "long", ")", "*", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "\n", "boxes", "=", "torch", ".", "zeros", "(", "B", ",", "V_L", ",", "4", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "vis_feats", "=", "torch", ".", "zeros", "(", "B", ",", "V_L", ",", "feat_dim", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "loss_weights", "=", "torch", ".", "ones", "(", "B", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "sentences", "=", "[", "]", "\n", "ans", "=", "[", "]", "\n", "uids", "=", "[", "]", "\n", "tasks", "=", "[", "]", "\n", "\n", "source_text", "=", "[", "]", "\n", "target_text", "=", "[", "]", "\n", "\n", "for", "i", ",", "entry", "in", "enumerate", "(", "batch", ")", ":", "\n", "            ", "input_ids", "[", "i", ",", ":", "entry", "[", "'input_length'", "]", "]", "=", "entry", "[", "'input_ids'", "]", "\n", "target_ids", "[", "i", ",", ":", "entry", "[", "'target_length'", "]", "]", "=", "entry", "[", "'target_ids'", "]", "\n", "\n", "boxes", "[", "i", "]", "+=", "entry", "[", "'boxes'", "]", "\n", "vis_feats", "[", "i", "]", "+=", "entry", "[", "'vis_feats'", "]", "\n", "\n", "if", "'ans'", "in", "entry", ":", "\n", "                ", "ans", ".", "append", "(", "entry", "[", "'ans'", "]", ")", "\n", "\n", "", "if", "'task'", "in", "entry", ":", "\n", "                ", "tasks", ".", "append", "(", "entry", "[", "'task'", "]", ")", "\n", "\n", "", "sentences", ".", "append", "(", "entry", "[", "'sent'", "]", ")", "\n", "uids", ".", "append", "(", "entry", "[", "'uid'", "]", ")", "\n", "\n", "if", "'source_text'", "in", "entry", ":", "\n", "                ", "source_text", ".", "append", "(", "entry", "[", "'source_text'", "]", ")", "\n", "", "if", "'target_text'", "in", "entry", ":", "\n", "                ", "target_text", ".", "append", "(", "entry", "[", "'target_text'", "]", ")", "\n", "\n", "", "if", "'loss_weight'", "in", "entry", ":", "\n", "                ", "loss_weights", "[", "i", "]", "=", "entry", "[", "'loss_weight'", "]", "\n", "\n", "", "", "word_mask", "=", "target_ids", "!=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "target_ids", "[", "~", "word_mask", "]", "=", "-", "100", "\n", "batch_entry", "[", "'task'", "]", "=", "tasks", "\n", "\n", "batch_entry", "[", "'source_text'", "]", "=", "source_text", "\n", "batch_entry", "[", "'target_text'", "]", "=", "target_text", "\n", "\n", "batch_entry", "[", "'input_ids'", "]", "=", "input_ids", "\n", "batch_entry", "[", "'target_ids'", "]", "=", "target_ids", "\n", "\n", "batch_entry", "[", "'boxes'", "]", "=", "boxes", "\n", "batch_entry", "[", "'vis_feats'", "]", "=", "vis_feats", "\n", "\n", "batch_entry", "[", "'loss_weights'", "]", "=", "loss_weights", "\n", "\n", "batch_entry", "[", "'uid'", "]", "=", "uids", "\n", "batch_entry", "[", "'sent'", "]", "=", "sentences", "\n", "\n", "return", "batch_entry", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.make_uid": [[32, 34], ["None"], "function", ["None"], ["def", "make_uid", "(", "img_id", ",", "dset", ",", "sent_idx", ")", ":", "\n", "    ", "return", "\"%s_%s_%03d\"", "%", "(", "img_id", ",", "dset", ",", "sent_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_datum": [[36, 103], ["datum[].items", "enumerate", "_sents.append", "datum[].keys", "print", "pretrain_data.make_uid", "copy.deepcopy", "data.append", "copy.deepcopy", "data.append", "datum[].keys", "len", "sent.split"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.make_uid"], ["", "def", "get_datum", "(", "datum", ")", ":", "\n", "    ", "data", "=", "[", "]", "\n", "_sents", "=", "[", "]", "\n", "\n", "args", "=", "datum", "[", "'args'", "]", "\n", "\n", "if", "datum", "[", "'is_train'", "]", ":", "\n", "        ", "if", "'COCO_train2014'", "in", "datum", "[", "'img_id'", "]", ":", "\n", "            ", "img_source", "=", "'mscoco_resplit_train_train2014'", "\n", "", "elif", "'COCO_val2014'", "in", "datum", "[", "'img_id'", "]", ":", "\n", "            ", "img_source", "=", "'mscoco_resplit_train_val2014'", "\n", "", "elif", "'cc'", "in", "datum", "[", "'sentf'", "]", ".", "keys", "(", ")", ":", "\n", "            ", "img_source", "=", "'cc_train'", "\n", "", "else", ":", "\n", "            ", "img_source", "=", "'vgnococo'", "\n", "", "", "else", ":", "\n", "        ", "if", "'COCO_val2014'", "in", "datum", "[", "'img_id'", "]", ":", "\n", "            ", "img_source", "=", "'mscoco_resplit_val'", "\n", "", "elif", "'cc'", "in", "datum", "[", "'sentf'", "]", ".", "keys", "(", ")", ":", "\n", "            ", "img_source", "=", "'cc_valid'", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"no!\"", ")", "\n", "\n", "", "", "for", "text_source", ",", "sents", "in", "datum", "[", "'sentf'", "]", ".", "items", "(", ")", ":", "\n", "        ", "if", "text_source", "not", "in", "[", "'mscoco'", ",", "'vg'", ",", "'cc'", "]", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "args", ".", "coco_only", ":", "\n", "            ", "if", "text_source", "!=", "'mscoco'", ":", "\n", "                ", "continue", "\n", "\n", "", "", "labels", "=", "None", "\n", "img_id", "=", "datum", "[", "'img_id'", "]", "\n", "\n", "for", "sent_idx", ",", "sent", "in", "enumerate", "(", "sents", ")", ":", "\n", "\n", "            ", "if", "'t5'", "in", "datum", "[", "'backbone'", "]", "and", "len", "(", "sent", ".", "split", "(", ")", ")", "<=", "2", ":", "\n", "                ", "continue", "\n", "\n", "# remove duplicate sentence", "\n", "", "if", "sent", "in", "_sents", ":", "\n", "                ", "continue", "\n", "\n", "", "new_datum", "=", "{", "\n", "'uid'", ":", "make_uid", "(", "img_id", ",", "text_source", ",", "sent_idx", ")", ",", "\n", "'img_id'", ":", "img_id", ",", "\n", "'img_source'", ":", "img_source", ",", "\n", "'sent'", ":", "sent", ",", "\n", "'text_source'", ":", "text_source", "\n", "}", "\n", "\n", "# Task: Language modeling", "\n", "if", "datum", "[", "'lm'", "]", "and", "labels", "is", "None", ":", "\n", "                ", "new_datum", "=", "deepcopy", "(", "new_datum", ")", "\n", "new_datum", "[", "'task'", "]", "=", "'lm'", "\n", "new_datum", "[", "'label'", "]", "=", "None", "\n", "data", ".", "append", "(", "new_datum", ")", "\n", "\n", "", "if", "datum", "[", "'prefix'", "]", "and", "labels", "is", "None", ":", "\n", "                ", "new_datum", "=", "deepcopy", "(", "new_datum", ")", "\n", "new_datum", "[", "'task'", "]", "=", "'prefix'", "\n", "new_datum", "[", "'label'", "]", "=", "None", "\n", "data", ".", "append", "(", "new_datum", ")", "\n", "\n", "", "_sents", ".", "append", "(", "sent", ")", "\n", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader": [[400, 436], ["pretrain_data.PretrainDataset", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "function", ["None"], ["", "", "def", "get_loader", "(", "args", ",", "split", "=", "'vgnococo'", ",", "mode", "=", "'train'", ",", "\n", "batch_size", "=", "32", ",", "workers", "=", "4", ",", "distributed", "=", "False", ",", "gpu", "=", "0", ",", "\n", "topk", "=", "-", "1", ")", ":", "\n", "\n", "\n", "    ", "verbose", "=", "(", "gpu", "==", "0", ")", "\n", "dataset", "=", "PretrainDataset", "(", "\n", "split", ",", "\n", "rank", "=", "-", "1", ",", "\n", "topk", "=", "topk", ",", "\n", "verbose", "=", "verbose", ",", "\n", "args", "=", "args", ",", "\n", "is_train", "=", "(", "mode", "==", "'train'", ")", ",", "\n", ")", "\n", "\n", "if", "distributed", ":", "\n", "        ", "sampler", "=", "DistributedSampler", "(", "dataset", ")", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "None", "\n", "\n", "", "if", "mode", "==", "'train'", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "(", "sampler", "is", "None", ")", ",", "\n", "num_workers", "=", "workers", ",", "pin_memory", "=", "True", ",", "sampler", "=", "sampler", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ")", "\n", "", "else", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "workers", ",", "pin_memory", "=", "True", ",", "\n", "sampler", "=", "sampler", ",", "\n", "shuffle", "=", "None", "if", "(", "sampler", "is", "not", "None", ")", "else", "False", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ",", "\n", "drop_last", "=", "False", ")", "\n", "\n", "", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.__init__": [[41, 44], ["collections.deque"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "maxlen", "=", "100", ")", ":", "\n", "        ", "\"\"\"Computes and stores the running average\"\"\"", "\n", "self", ".", "vals", "=", "collections", ".", "deque", "(", "[", "]", ",", "maxlen", "=", "maxlen", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.__len__": [[45, 47], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "vals", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update": [[48, 50], ["utils.LossMeter.vals.append"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "new_val", ")", ":", "\n", "        ", "self", ".", "vals", ".", "append", "(", "new_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.val": [[51, 54], ["sum", "len"], "methods", ["None"], ["", "@", "property", "\n", "def", "val", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "self", ".", "vals", ")", "/", "len", "(", "self", ".", "vals", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.__repr__": [[55, 57], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.get_area": [[8, 22], ["None"], "function", ["None"], ["def", "get_area", "(", "pos", ")", ":", "\n", "    ", "\"\"\"\n    Args\n        pos: [B, N, 4]\n            (x1, x2, y1, y2)\n\n    Return\n        area : [B, N]\n    \"\"\"", "\n", "# [B, N]", "\n", "height", "=", "pos", "[", ":", ",", ":", ",", "3", "]", "-", "pos", "[", ":", ",", ":", ",", "2", "]", "\n", "width", "=", "pos", "[", ":", ",", ":", ",", "1", "]", "-", "pos", "[", ":", ",", ":", ",", "0", "]", "\n", "area", "=", "height", "*", "width", "\n", "return", "area", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.get_relative_distance": [[23, 38], ["pos.unsqueeze", "pos.unsqueeze"], "function", ["None"], ["", "def", "get_relative_distance", "(", "pos", ")", ":", "\n", "    ", "\"\"\"\n    Args\n        pos: [B, N, 4]\n            (x1, x2, y1, y2)\n\n    Return\n        out : [B, N, N, 4]\n    \"\"\"", "\n", "# B, N = pos.size()[:-1]", "\n", "\n", "# [B, N, N, 4]", "\n", "relative_distance", "=", "pos", ".", "unsqueeze", "(", "1", ")", "-", "pos", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "return", "relative_distance", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.count_parameters": [[59, 61], ["sum", "p.numel", "model.parameters"], "function", ["None"], ["", "", "def", "count_parameters", "(", "model", ")", ":", "\n", "    ", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.load_state_dict": [[63, 72], ["torch.load", "torch.load", "list", "torch.load.keys", "key.startswith", "torch.load.pop", "len"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load"], ["", "def", "load_state_dict", "(", "state_dict_path", ",", "loc", "=", "'cpu'", ")", ":", "\n", "    ", "state_dict", "=", "torch", ".", "load", "(", "state_dict_path", ",", "map_location", "=", "loc", ")", "\n", "# Change Multi GPU to single GPU", "\n", "original_keys", "=", "list", "(", "state_dict", ".", "keys", "(", ")", ")", "\n", "for", "key", "in", "original_keys", ":", "\n", "        ", "if", "key", ".", "startswith", "(", "\"module.\"", ")", ":", "\n", "            ", "new_key", "=", "key", "[", "len", "(", "\"module.\"", ")", ":", "]", "\n", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "key", ")", "\n", "", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.set_global_logging_level": [[74, 89], ["re.compile", "re.match", "logging.getLogger().setLevel", "logging.getLogger"], "function", ["None"], ["", "def", "set_global_logging_level", "(", "level", "=", "logging", ".", "ERROR", ",", "prefices", "=", "[", "\"\"", "]", ")", ":", "\n", "    ", "\"\"\"\n    Override logging levels of different modules based on their name as a prefix.\n    It needs to be invoked after the modules have been loaded so that their loggers have been initialized.\n\n    Args:\n        - level: desired level. e.g. logging.INFO. Optional. Default is logging.ERROR\n        - prefices: list of one or more str prefices to match (e.g. [\"transformers\", \"torch\"]). Optional.\n          Default is `[\"\"]` to match all active loggers.\n          The match is a case-sensitive `module_name.startswith(prefix)`\n    \"\"\"", "\n", "prefix_re", "=", "re", ".", "compile", "(", "fr'^(?:{ \"|\".join(prefices) })'", ")", "\n", "for", "name", "in", "logging", ".", "root", ".", "manager", ".", "loggerDict", ":", "\n", "        ", "if", "re", ".", "match", "(", "prefix_re", ",", "name", ")", ":", "\n", "            ", "logging", ".", "getLogger", "(", "name", ")", ".", "setLevel", "(", "level", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.get_iou": [[91, 134], ["anchors.size", "gt_boxes.view.size", "anchors.view().expand", "gt_boxes.view.view().expand", "gt_boxes.view.size", "gt_boxes.view.view", "anchors.view", "gt_boxes.view.view", "torch.min", "torch.min", "torch.max", "torch.max", "torch.min", "torch.min", "torch.max", "torch.max"], "function", ["None"], ["", "", "", "def", "get_iou", "(", "anchors", ",", "gt_boxes", ")", ":", "\n", "    ", "\"\"\"\n    anchors: (N, 4) torch floattensor\n    gt_boxes: (K, 4) torch floattensor\n    overlaps: (N, K) ndarray of overlap between boxes and query_boxes\n    \"\"\"", "\n", "N", "=", "anchors", ".", "size", "(", "0", ")", "\n", "\n", "if", "gt_boxes", ".", "size", "(", ")", "==", "(", "4", ",", ")", ":", "\n", "        ", "gt_boxes", "=", "gt_boxes", ".", "view", "(", "1", ",", "4", ")", "\n", "", "K", "=", "gt_boxes", ".", "size", "(", "0", ")", "\n", "\n", "gt_boxes_area", "=", "(", "\n", "(", "gt_boxes", "[", ":", ",", "2", "]", "-", "gt_boxes", "[", ":", ",", "0", "]", "+", "1", ")", "*", "\n", "(", "gt_boxes", "[", ":", ",", "3", "]", "-", "gt_boxes", "[", ":", ",", "1", "]", "+", "1", ")", "\n", ")", ".", "view", "(", "1", ",", "K", ")", "\n", "\n", "anchors_area", "=", "(", "\n", "(", "anchors", "[", ":", ",", "2", "]", "-", "anchors", "[", ":", ",", "0", "]", "+", "1", ")", "*", "\n", "(", "anchors", "[", ":", ",", "3", "]", "-", "anchors", "[", ":", ",", "1", "]", "+", "1", ")", "\n", ")", ".", "view", "(", "N", ",", "1", ")", "\n", "\n", "boxes", "=", "anchors", ".", "view", "(", "N", ",", "1", ",", "4", ")", ".", "expand", "(", "N", ",", "K", ",", "4", ")", "\n", "query_boxes", "=", "gt_boxes", ".", "view", "(", "1", ",", "K", ",", "4", ")", ".", "expand", "(", "N", ",", "K", ",", "4", ")", "\n", "\n", "iw", "=", "(", "\n", "torch", ".", "min", "(", "boxes", "[", ":", ",", ":", ",", "2", "]", ",", "query_boxes", "[", ":", ",", ":", ",", "2", "]", ")", "\n", "-", "torch", ".", "max", "(", "boxes", "[", ":", ",", ":", ",", "0", "]", ",", "query_boxes", "[", ":", ",", ":", ",", "0", "]", ")", "\n", "+", "1", "\n", ")", "\n", "iw", "[", "iw", "<", "0", "]", "=", "0", "\n", "\n", "ih", "=", "(", "\n", "torch", ".", "min", "(", "boxes", "[", ":", ",", ":", ",", "3", "]", ",", "query_boxes", "[", ":", ",", ":", ",", "3", "]", ")", "\n", "-", "torch", ".", "max", "(", "boxes", "[", ":", ",", ":", ",", "1", "]", ",", "query_boxes", "[", ":", ",", ":", ",", "1", "]", ")", "\n", "+", "1", "\n", ")", "\n", "ih", "[", "ih", "<", "0", "]", "=", "0", "\n", "\n", "ua", "=", "anchors_area", "+", "gt_boxes_area", "-", "(", "iw", "*", "ih", ")", "\n", "overlaps", "=", "iw", "*", "ih", "/", "ua", "\n", "\n", "return", "overlaps", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.xywh_to_xyxy": [[136, 139], ["numpy.hstack"], "function", ["None"], ["", "def", "xywh_to_xyxy", "(", "boxes", ")", ":", "\n", "    ", "\"\"\"Convert [x y w h] box format to [x1 y1 x2 y2] format.\"\"\"", "\n", "return", "np", ".", "hstack", "(", "(", "boxes", "[", ":", ",", "0", ":", "2", "]", ",", "boxes", "[", ":", ",", "0", ":", "2", "]", "+", "boxes", "[", ":", ",", "2", ":", "4", "]", "-", "1", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.__init__": [[9, 11], ["modeling_t5.FewVLM.__init__"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step": [[12, 37], ["batch[].to", "batch[].to", "batch[].to", "batch[].to", "flickr_model.FewVLMCOCOCaption.", "batch[].to.size", "next", "flickr_model.FewVLMCOCOCaption.parameters"], "methods", ["None"], ["", "def", "train_step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "vis_feats", "=", "batch", "[", "'vis_feats'", "]", ".", "to", "(", "device", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", ".", "to", "(", "device", ")", "\n", "vis_pos", "=", "batch", "[", "'boxes'", "]", ".", "to", "(", "device", ")", "\n", "\n", "lm_labels", "=", "batch", "[", "\"target_ids\"", "]", ".", "to", "(", "device", ")", "\n", "\n", "reduce_loss", "=", "True", "\n", "output", "=", "self", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vis_inputs", "=", "(", "vis_feats", ",", "vis_pos", ")", ",", "\n", "labels", "=", "lm_labels", ",", "\n", "reduce_loss", "=", "reduce_loss", "\n", ")", "\n", "\n", "lm_mask", "=", "lm_labels", "!=", "-", "100", "\n", "B", ",", "L", "=", "lm_labels", ".", "size", "(", ")", "\n", "\n", "loss", "=", "output", "[", "'loss'", "]", "\n", "\n", "result", "=", "{", "\n", "'loss'", ":", "loss", "\n", "}", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.test_step": [[38, 56], ["batch[].to", "batch[].to", "batch[].to", "flickr_model.FewVLMCOCOCaption.generate", "flickr_model.FewVLMCOCOCaption.tokenizer.batch_decode", "next", "flickr_model.FewVLMCOCOCaption.parameters"], "methods", ["None"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "**", "kwargs", ")", ":", "\n", "        ", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "vis_feats", "=", "batch", "[", "'vis_feats'", "]", ".", "to", "(", "device", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", ".", "to", "(", "device", ")", "\n", "vis_pos", "=", "batch", "[", "'boxes'", "]", ".", "to", "(", "device", ")", "\n", "\n", "output", "=", "self", ".", "generate", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vis_inputs", "=", "(", "vis_feats", ",", "vis_pos", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "\n", "generated_sents", "=", "self", ".", "tokenizer", ".", "batch_decode", "(", "output", ",", "skip_special_tokens", "=", "True", ")", "\n", "\n", "result", "=", "{", "}", "\n", "result", "[", "'pred'", "]", "=", "generated_sents", "\n", "\n", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__": [[46, 104], ["trainer_base.TrainerBase.__init__", "gqa.Trainer.create_config", "gqa.Trainer.create_tokenizer", "gqa.Trainer.create_model", "print", "gqa.Trainer.model.to", "gqa.Trainer.model.resize_token_embeddings", "gqa.Trainer.load_checkpoint", "gqa.Trainer.init_weights", "time", "gqa.Trainer.create_optimizer_and_scheduler", "print", "gqa.Trainer.model.resize_token_embeddings", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "amp.initialize", "time"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.__init__", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_config", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_tokenizer", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_model", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load_checkpoint", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.init_weights", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.create_optimizer_and_scheduler"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "train_loader", "=", "None", ",", "val_loader", "=", "None", ",", "test_loader", "=", "None", ",", "train", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "args", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "test_loader", "=", "test_loader", ",", "\n", "train", "=", "train", ")", "\n", "\n", "from", "gqa_model", "import", "FewVLMGQA", "\n", "\n", "model_kwargs", "=", "{", "}", "\n", "if", "'t5'", "in", "args", ".", "backbone", ":", "\n", "            ", "model_class", "=", "FewVLMGQA", "\n", "\n", "", "config", "=", "self", ".", "create_config", "(", ")", "\n", "self", ".", "tokenizer", "=", "self", ".", "create_tokenizer", "(", ")", "\n", "self", ".", "model", "=", "self", ".", "create_model", "(", "model_class", ",", "config", ",", "**", "model_kwargs", ")", "\n", "\n", "if", "'t5'", "in", "self", ".", "args", ".", "tokenizer", ":", "\n", "            ", "self", ".", "model", ".", "resize_token_embeddings", "(", "self", ".", "tokenizer", ".", "vocab_size", ")", "\n", "", "elif", "'bart'", "in", "self", ".", "args", ".", "tokenizer", ":", "\n", "            ", "self", ".", "model", ".", "resize_token_embeddings", "(", "self", ".", "model", ".", "model", ".", "shared", ".", "num_embeddings", "+", "num_added_toks", ")", "\n", "\n", "", "self", ".", "model", ".", "tokenizer", "=", "self", ".", "tokenizer", "\n", "\n", "# Load Checkpoint", "\n", "self", ".", "start_epoch", "=", "None", "\n", "if", "args", ".", "load", "is", "not", "None", ":", "\n", "            ", "ckpt_path", "=", "args", ".", "load", "+", "'.pth'", "\n", "self", ".", "load_checkpoint", "(", "ckpt_path", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "from_scratch", ":", "\n", "            ", "self", ".", "init_weights", "(", ")", "\n", "\n", "# GPU Options", "\n", "", "print", "(", "f'Model Launching at GPU {self.args.gpu}'", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "from", "time", "import", "time", "\n", "start", "=", "time", "(", ")", "\n", "", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "args", ".", "gpu", ")", "\n", "\n", "# Optimizer", "\n", "if", "train", ":", "\n", "            ", "self", ".", "optim", ",", "self", ".", "lr_scheduler", "=", "self", ".", "create_optimizer_and_scheduler", "(", ")", "\n", "\n", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                ", "self", ".", "scaler", "=", "torch", ".", "cuda", ".", "amp", ".", "GradScaler", "(", ")", "\n", "", "elif", "_use_apex", ":", "\n", "                ", "self", ".", "model", ",", "self", ".", "optim", "=", "amp", ".", "initialize", "(", "\n", "self", ".", "model", ",", "self", ".", "optim", ",", "opt_level", "=", "'O1'", ",", "verbosity", "=", "self", ".", "verbose", ")", "\n", "\n", "", "", "if", "args", ".", "multiGPU", ":", "\n", "            ", "if", "args", ".", "distributed", ":", "\n", "                ", "self", ".", "model", "=", "DDP", "(", "self", ".", "model", ",", "device_ids", "=", "[", "args", ".", "gpu", "]", ",", "\n", "find_unused_parameters", "=", "True", "\n", ")", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "f'It took {time() - start:.1f}s'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.train": [[105, 258], ["utils.LossMeter", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "range", "os.path.join", "gqa.Trainer.predict", "print", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "exit", "gqa.Trainer.model.train", "enumerate", "gqa.Trainer.save", "os.path.join", "gqa.Trainer.load", "gqa.Trainer.evaluate", "gqa.Trainer.train_loader.sampler.set_epoch", "tqdm.tqdm.tqdm", "loss.detach.detach.detach", "gqa.Trainer.model.parameters", "gqa.Trainer.items", "tqdm.tqdm.tqdm.close", "print", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "gqa.Trainer.scaler.scale().backward", "gqa.Trainer.scaler.step", "gqa.Trainer.scaler.update", "gqa.Trainer.optim.step", "gqa.Trainer.lr_scheduler.step", "utils.LossMeter.update", "tqdm.tqdm.tqdm.set_description", "tqdm.tqdm.tqdm.update", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "torch.barrier", "gqa.Trainer.evaluate", "gqa.Trainer.save", "len", "autocast", "gqa.Trainer.model.module.train_step", "gqa.Trainer.model.train_step", "loss.detach.detach.backward", "gqa.Trainer.scaler.unscale_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "v.item", "packaging.version.parse", "packaging.version.parse", "loss.detach.detach.item", "gqa.Trainer.model.module.train_step", "gqa.Trainer.model.train_step", "gqa.Trainer.scaler.scale", "amp.scale_loss", "scaled_loss.backward", "gqa.Trainer.model.parameters", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "gqa.Trainer.lr_scheduler.get_last_lr", "gqa.Trainer.lr_scheduler.get_lr", "gqa.Trainer.optim.get_lr", "amp.master_params", "gqa.Trainer.model.parameters"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.predict", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.train", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.load", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.trainer_base.TrainerBase.save", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.train_step"], ["", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "verbose", ":", "\n", "            ", "loss_meter", "=", "LossMeter", "(", ")", "\n", "\n", "best_valid", "=", "0.", "\n", "best_epoch", "=", "0", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "\n", "# torch.autograd.set_detect_anomaly(True)", "\n", "\n", "# print(f'GPU{self.args.gpu} before training starts')", "\n", "\n", "", "global_step", "=", "0", "\n", "if", "not", "args", ".", "test_only", ":", "\n", "            ", "for", "epoch", "in", "range", "(", "self", ".", "args", ".", "epochs", ")", ":", "\n", "                ", "if", "self", ".", "start_epoch", "is", "not", "None", ":", "\n", "                    ", "epoch", "+=", "self", ".", "start_epoch", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "self", ".", "train_loader", ".", "sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                    ", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "self", ".", "train_loader", ")", ",", "ncols", "=", "120", ")", "\n", "\n", "", "epoch_results", "=", "{", "\n", "'loss'", ":", "0.", ",", "\n", "\n", "}", "\n", "\n", "\n", "for", "step_i", ",", "batch", "in", "enumerate", "(", "self", ".", "train_loader", ")", ":", "\n", "\n", "                    ", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                        ", "with", "autocast", "(", ")", ":", "\n", "                            ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                                ", "results", "=", "self", ".", "model", ".", "module", ".", "train_step", "(", "batch", ")", "\n", "", "else", ":", "\n", "                                ", "results", "=", "self", ".", "model", ".", "train_step", "(", "batch", ")", "\n", "", "", "", "else", ":", "\n", "                        ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                            ", "results", "=", "self", ".", "model", ".", "module", ".", "train_step", "(", "batch", ")", "\n", "", "else", ":", "\n", "                            ", "results", "=", "self", ".", "model", ".", "train_step", "(", "batch", ")", "\n", "\n", "", "", "loss", "=", "results", "[", "'loss'", "]", "\n", "\n", "\n", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                        ", "self", ".", "scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "", "elif", "self", ".", "args", ".", "fp16", "and", "_use_apex", ":", "\n", "                        ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "self", ".", "optim", ")", "as", "scaled_loss", ":", "\n", "                            ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                        ", "loss", ".", "backward", "(", ")", "\n", "\n", "\n", "", "loss", "=", "loss", ".", "detach", "(", ")", "\n", "\n", "# Update Parameters", "\n", "if", "self", ".", "args", ".", "clip_grad_norm", ">", "0", ":", "\n", "                        ", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                            ", "self", ".", "scaler", ".", "unscale_", "(", "self", ".", "optim", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "", "elif", "self", ".", "args", ".", "fp16", "and", "_use_apex", ":", "\n", "                            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "\n", "self", ".", "optim", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "", "else", ":", "\n", "                            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "clip_grad_norm", ")", "\n", "\n", "", "", "if", "self", ".", "args", ".", "fp16", "and", "_use_native_amp", ":", "\n", "                        ", "self", ".", "scaler", ".", "step", "(", "self", ".", "optim", ")", "\n", "self", ".", "scaler", ".", "update", "(", ")", "\n", "", "else", ":", "\n", "                        ", "self", ".", "optim", ".", "step", "(", ")", "\n", "\n", "", "if", "self", ".", "lr_scheduler", ":", "\n", "                        ", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "\n", "", "for", "param", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "                        ", "param", ".", "grad", "=", "None", "\n", "\n", "", "global_step", "+=", "1", "\n", "\n", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", ":", "\n", "                        ", "if", "k", "in", "epoch_results", ":", "\n", "                            ", "epoch_results", "[", "k", "]", "+=", "v", ".", "item", "(", ")", "\n", "\n", "", "", "if", "self", ".", "lr_scheduler", ":", "\n", "                        ", "if", "version", ".", "parse", "(", "torch", ".", "__version__", ")", ">=", "version", ".", "parse", "(", "\"1.4\"", ")", ":", "\n", "                            ", "lr", "=", "self", ".", "lr_scheduler", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                            ", "lr", "=", "self", ".", "lr_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "", "", "else", ":", "\n", "                        ", "try", ":", "\n", "                            ", "lr", "=", "self", ".", "optim", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "", "except", "AttributeError", ":", "\n", "                            ", "lr", "=", "self", ".", "args", ".", "lr", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "                        ", "loss_meter", ".", "update", "(", "loss", ".", "item", "(", ")", ")", "\n", "desc_str", "=", "f'Epoch {epoch} | LR {lr:.6f}'", "\n", "desc_str", "+=", "f' | Loss {loss_meter.val:4f}'", "\n", "\n", "pbar", ".", "set_description", "(", "desc_str", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                        ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "                    ", "pbar", ".", "close", "(", ")", "\n", "\n", "log_str", "=", "''", "\n", "\n", "# Validation", "\n", "valid_score", "=", "self", ".", "evaluate", "(", "self", ".", "val_loader", ")", "*", "100.", "\n", "if", "valid_score", ">", "best_valid", ":", "\n", "                        ", "best_valid", "=", "valid_score", "\n", "best_epoch", "=", "epoch", "\n", "self", ".", "save", "(", "\"BEST\"", ")", "\n", "\n", "", "log_str", "+=", "\"\\nEpoch %d: Valid %0.2f\"", "%", "(", "epoch", ",", "valid_score", ")", "\n", "log_str", "+=", "\"\\nEpoch %d: Best %0.2f\\n\"", "%", "(", "best_epoch", ",", "best_valid", ")", "\n", "\n", "print", "(", "log_str", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "                ", "self", ".", "save", "(", "\"LAST\"", ")", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "\n", "            ", "if", "not", "self", ".", "args", ".", "test_only", ":", "\n", "                ", "best_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output", ",", "'BEST'", ")", "\n", "self", ".", "load", "(", "best_path", ")", "\n", "\n", "", "dump_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output", ",", "'submit.json'", ")", "\n", "\n", "self", ".", "predict", "(", "self", ".", "test_loader", ",", "dump_path", "=", "dump_path", ")", "\n", "\n", "test_score", "=", "self", ".", "evaluate", "(", "self", ".", "test_loader", ")", "*", "100.", "\n", "\n", "print", "(", "\"Testdev %0.2f\"", "%", "test_score", ")", "\n", "\n", "\n", "", "if", "self", ".", "args", ".", "distributed", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.predict": [[259, 301], ["gqa.Trainer.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "tqdm.tqdm.tqdm", "zip", "print", "loader.evaluator.dump_result", "gqa.Trainer.model.module.test_step", "gqa.Trainer.model.test_step", "tqdm.tqdm.tqdm.update", "os.path.isdir", "os.makedirs", "len"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa_data.GQAEvaluator.dump_result", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.test_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.flickr_model.FewVLMCOCOCaption.test_step", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.utils.LossMeter.update"], ["", "", "def", "predict", "(", "self", ",", "loader", ",", "dump_path", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Predict the answers to questions in a data split.\n        :param eval_tuple: The data tuple to be evaluated.\n        :param dump: The path of saved file to dump results.\n        :return: A dict of question_id to answer.\n        \"\"\"", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "quesid2ans", "=", "{", "}", "\n", "\n", "gen_kwargs", "=", "{", "}", "\n", "if", "self", ".", "args", ".", "num_beams", ">", "1", ":", "\n", "                ", "gen_kwargs", "[", "'num_beams'", "]", "=", "self", ".", "args", ".", "num_beams", "\n", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                ", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "loader", ")", ",", "ncols", "=", "120", ",", "desc", "=", "\"Prediction\"", ")", "\n", "\n", "", "for", "i", ",", "batch", "in", "enumerate", "(", "loader", ")", ":", "\n", "\n", "                ", "if", "self", ".", "args", ".", "distributed", ":", "\n", "                    ", "results", "=", "self", ".", "model", ".", "module", ".", "test_step", "(", "batch", ",", "**", "gen_kwargs", ")", "\n", "", "else", ":", "\n", "                    ", "results", "=", "self", ".", "model", ".", "test_step", "(", "batch", ",", "**", "gen_kwargs", ")", "\n", "\n", "", "pred_ans", "=", "results", "[", "'pred_ans'", "]", "\n", "ques_ids", "=", "batch", "[", "'question_ids'", "]", "\n", "\n", "for", "qid", ",", "ans", "in", "zip", "(", "ques_ids", ",", "pred_ans", ")", ":", "\n", "                    ", "quesid2ans", "[", "qid", "]", "=", "ans", "\n", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                    ", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "\n", "\n", "", "", "if", "dump_path", "is", "not", "None", ":", "\n", "                ", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "args", ".", "output", ")", ":", "\n", "                    ", "os", ".", "makedirs", "(", "self", ".", "args", ".", "output", ",", "exist_ok", "=", "True", ")", "\n", "", "print", "(", "'\\nsave dump at'", ",", "dump_path", ")", "\n", "loader", ".", "evaluator", ".", "dump_result", "(", "quesid2ans", ",", "dump_path", ")", "\n", "", "return", "quesid2ans", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate": [[302, 306], ["gqa.Trainer.predict", "evaluator.evaluate"], "methods", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.predict", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.evaluate"], ["", "", "def", "evaluate", "(", "self", ",", "loader", ",", "dump_path", "=", "None", ")", ":", "\n", "        ", "evaluator", "=", "loader", ".", "evaluator", "\n", "quesid2ans", "=", "self", ".", "predict", "(", "loader", ",", "dump_path", ")", "\n", "return", "evaluator", ".", "evaluate", "(", "quesid2ans", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.main_worker": [[307, 350], ["print", "print", "gqa_data.get_loader", "print", "gqa_data.get_loader", "print", "gqa_data.get_loader", "gqa.Trainer", "gqa.Trainer.train", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.init_process_group"], "function", ["home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.pretrain_data.get_loader", "home.repos.pwc.inspect_result.woojeongjin_fewvlm.src.gqa.Trainer.train"], ["", "", "def", "main_worker", "(", "gpu", ",", "args", ")", ":", "\n", "# GPU is assigned", "\n", "    ", "args", ".", "gpu", "=", "gpu", "\n", "args", ".", "rank", "=", "gpu", "\n", "print", "(", "f'Process Launching at GPU {gpu}'", ")", "\n", "\n", "if", "args", ".", "distributed", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "dist", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "\n", "", "print", "(", "f'Building train loader at GPU {gpu}'", ")", "\n", "train_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "train", ",", "mode", "=", "'train'", ",", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "distributed", "=", "args", ".", "distributed", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "args", ".", "num_workers", ",", "\n", "topk", "=", "args", ".", "train_topk", ",", "\n", ")", "\n", "\n", "if", "args", ".", "valid_batch_size", "is", "not", "None", ":", "\n", "        ", "valid_batch_size", "=", "args", ".", "valid_batch_size", "\n", "", "else", ":", "\n", "        ", "valid_batch_size", "=", "args", ".", "batch_size", "\n", "", "print", "(", "f'Building val loader at GPU {gpu}'", ")", "\n", "val_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "valid", ",", "mode", "=", "'val'", ",", "batch_size", "=", "valid_batch_size", ",", "\n", "distributed", "=", "args", ".", "distributed", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "4", ",", "\n", "topk", "=", "args", ".", "valid_topk", ",", "\n", ")", "\n", "\n", "print", "(", "f'Building test loader at GPU {gpu}'", ")", "\n", "test_loader", "=", "get_loader", "(", "\n", "args", ",", "\n", "split", "=", "args", ".", "test", ",", "mode", "=", "'val'", ",", "batch_size", "=", "valid_batch_size", ",", "\n", "distributed", "=", "args", ".", "distributed", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "workers", "=", "4", ",", "\n", "topk", "=", "args", ".", "valid_topk", ",", "\n", ")", "\n", "\n", "trainer", "=", "Trainer", "(", "args", ",", "train_loader", ",", "val_loader", ",", "test_loader", ",", "train", "=", "True", ")", "\n", "trainer", ".", "train", "(", ")", "\n", "\n"]]}