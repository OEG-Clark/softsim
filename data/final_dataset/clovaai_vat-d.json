{"home.repos.pwc.inspect_result.clovaai_vat-d.None.data_utils.loader_labeled.__init__": [[135, 142], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset_text", ",", "dataset_label", ",", "tokenizer", ",", "max_seq_len", ",", "n_labels", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "text", "=", "dataset_text", "\n", "self", ".", "labels", "=", "dataset_label", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "self", ".", "n_labels", "=", "n_labels", "\n", "self", ".", "trans_dist", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.data_utils.loader_labeled.__len__": [[143, 145], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.data_utils.loader_labeled.get_tokenized": [[146, 171], ["data_utils.loader_labeled.tokenizer.tokenize", "data_utils.loader_labeled.insert", "data_utils.loader_labeled.append", "len", "data_utils.loader_labeled.tokenizer.convert_tokens_to_ids", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len"], "methods", ["None"], ["", "def", "get_tokenized", "(", "self", ",", "text", ")", ":", "\n", "        ", "tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "if", "len", "(", "tokens", ")", ">", "self", ".", "max_seq_len", "-", "2", ":", "\n", "            ", "if", "self", ".", "n_labels", "==", "2", ":", "\n", "                ", "length", "=", "self", ".", "max_seq_len", "-", "2", "\n", "tokens", "=", "tokens", "[", "-", "length", ":", "]", "\n", "", "else", ":", "\n", "                ", "tokens", "=", "tokens", "[", ":", "self", ".", "max_seq_len", "-", "2", "]", "\n", "", "", "tokens", ".", "insert", "(", "0", ",", "'[CLS]'", ")", "\n", "tokens", ".", "append", "(", "'[SEP]'", ")", "\n", "length", "=", "len", "(", "tokens", ")", "\n", "encode_result", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "padding", "=", "[", "0", "]", "*", "(", "self", ".", "max_seq_len", "-", "len", "(", "encode_result", ")", ")", "\n", "encode_result", "+=", "padding", "\n", "\n", "attention_mask", "=", "[", "1", "]", "*", "length", "\n", "attention_mask", "=", "attention_mask", "+", "padding", "\n", "token_type_ids", "=", "[", "0", "]", "*", "self", ".", "max_seq_len", "\n", "\n", "inputs", "=", "{", "}", "\n", "inputs", "[", "'input_ids'", "]", "=", "torch", ".", "tensor", "(", "encode_result", ")", "\n", "inputs", "[", "'attention_mask'", "]", "=", "torch", ".", "tensor", "(", "attention_mask", ")", "\n", "inputs", "[", "'token_type_ids'", "]", "=", "torch", ".", "tensor", "(", "token_type_ids", ")", "\n", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.data_utils.loader_labeled.__getitem__": [[172, 177], ["data_utils.loader_labeled.get_tokenized"], "methods", ["home.repos.pwc.inspect_result.clovaai_vat-d.None.data_utils.loader_unlabeled.get_tokenized"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "text", "=", "self", ".", "text", "[", "idx", "]", "\n", "input_label", "=", "self", ".", "get_tokenized", "(", "text", ")", "\n", "\n", "return", "input_label", ",", "self", ".", "labels", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.data_utils.loader_unlabeled.__init__": [[180, 186], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset_text", ",", "unlabeled_idxs", ",", "tokenizer", ",", "max_seq_len", ",", "n_labels", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "text", "=", "dataset_text", "\n", "self", ".", "ids", "=", "unlabeled_idxs", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "self", ".", "n_labels", "=", "n_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.data_utils.loader_unlabeled.__len__": [[187, 189], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.data_utils.loader_unlabeled.get_tokenized": [[190, 215], ["data_utils.loader_unlabeled.tokenizer.tokenize", "data_utils.loader_unlabeled.insert", "data_utils.loader_unlabeled.append", "len", "data_utils.loader_unlabeled.tokenizer.convert_tokens_to_ids", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len"], "methods", ["None"], ["", "def", "get_tokenized", "(", "self", ",", "text", ")", ":", "\n", "        ", "tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "if", "len", "(", "tokens", ")", ">", "self", ".", "max_seq_len", "-", "2", ":", "\n", "            ", "if", "self", ".", "n_labels", "==", "2", ":", "\n", "                ", "length", "=", "self", ".", "max_seq_len", "-", "2", "\n", "tokens", "=", "tokens", "[", "-", "length", ":", "]", "\n", "", "else", ":", "\n", "                ", "tokens", "=", "tokens", "[", ":", "self", ".", "max_seq_len", "-", "2", "]", "\n", "", "", "tokens", ".", "insert", "(", "0", ",", "'[CLS]'", ")", "\n", "tokens", ".", "append", "(", "'[SEP]'", ")", "\n", "length", "=", "len", "(", "tokens", ")", "\n", "encode_result", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "padding", "=", "[", "0", "]", "*", "(", "self", ".", "max_seq_len", "-", "len", "(", "encode_result", ")", ")", "\n", "encode_result", "+=", "padding", "\n", "\n", "attention_mask", "=", "[", "1", "]", "*", "length", "\n", "attention_mask", "=", "attention_mask", "+", "padding", "\n", "token_type_ids", "=", "[", "0", "]", "*", "self", ".", "max_seq_len", "\n", "\n", "inputs", "=", "{", "}", "\n", "inputs", "[", "'input_ids'", "]", "=", "torch", ".", "tensor", "(", "encode_result", ")", "\n", "inputs", "[", "'attention_mask'", "]", "=", "torch", ".", "tensor", "(", "attention_mask", ")", "\n", "inputs", "[", "'token_type_ids'", "]", "=", "torch", ".", "tensor", "(", "token_type_ids", ")", "\n", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.data_utils.loader_unlabeled.__getitem__": [[216, 222], ["data_utils.loader_unlabeled.get_tokenized"], "methods", ["home.repos.pwc.inspect_result.clovaai_vat-d.None.data_utils.loader_unlabeled.get_tokenized"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "text", "=", "self", ".", "text", "[", "idx", "]", "\n", "input_unlabel", "=", "self", ".", "get_tokenized", "(", "text", ")", "\n", "\n", "return", "input_unlabel", "\n", "", "", ""]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.data_utils.get_data": [[14, 90], ["transformers.BertTokenizer.from_pretrained", "pandas.read_csv", "pandas.read_csv", "train_df.to_numpy.to_numpy", "test_df.to_numpy.to_numpy", "data_utils.train_val_split", "data_utils.loader_labeled", "data_utils.loader_unlabeled", "data_utils.loader_labeled", "data_utils.loader_labeled", "logging.info", "max", "pandas.read_csv", "train_unsup_df.to_numpy.to_numpy", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.clovaai_vat-d.None.data_utils.train_val_split"], ["def", "get_data", "(", "data_path", ",", "n_labeled_per_class", ",", "unlabeled_per_class", "=", "5000", ",", "max_seq_len", "=", "256", ",", "model", "=", "'bert-base-uncased'", ")", ":", "\n", "    ", "\"\"\" Read data, split the dataset, and build dataset for dataloaders.\n\n    Arguments:\n        data_path {str}           -- Path to your dataset folder: contain a train.csv and test.csv\n        n_labeled_per_class {int} -- Number of labeled data per class\n\n    Keyword Arguments:\n        unlabeled_per_class {int} -- Number of unlabeled data per class (default: {5000})\n        max_seq_len {int}         -- Maximum sequence length (default: {256})\n        model {str}               -- Model name (default: {'bert-base-uncased'})\n\n    AGNEWS (# Class : 4)\n    label, title, content\n \n    Yahoo! (# Class : 10) \n    label, label, content(preprocessed)\n   \n    IMDB (# Class : 2)\n    content, label\n\n    DBPedia (# Class : 14)\n    label, title, content\n    \"\"\"", "\n", "\n", "# Load the tokenizer for bert", "\n", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "model", ")", "\n", "\n", "# a bit of hack", "\n", "\n", "train_df", "=", "pd", ".", "read_csv", "(", "data_path", "+", "'train.csv'", ",", "header", "=", "None", ")", "\n", "test_df", "=", "pd", ".", "read_csv", "(", "data_path", "+", "'test.csv'", ",", "header", "=", "None", ")", "\n", "\n", "train_df", "=", "train_df", ".", "to_numpy", "(", ")", "\n", "test_df", "=", "test_df", ".", "to_numpy", "(", ")", "\n", "\n", "train_labels", "=", "train_df", "[", ":", ",", "0", "]", "-", "1", "\n", "train_text", "=", "train_df", "[", ":", ",", "2", "]", "\n", "del", "train_df", "\n", "test_labels", "=", "test_df", "[", ":", ",", "0", "]", "-", "1", "\n", "test_text", "=", "test_df", "[", ":", ",", "2", "]", "\n", "del", "test_df", "\n", "\n", "n_labels", "=", "max", "(", "test_labels", ")", "+", "1", "\n", "\n", "if", "n_labels", "==", "2", ":", "\n", "        ", "train_unsup_df", "=", "pd", ".", "read_csv", "(", "data_path", "+", "'train_unsup.csv'", ",", "header", "=", "None", ")", "\n", "train_unsup_df", "=", "train_unsup_df", ".", "to_numpy", "(", ")", "\n", "train_unsup_text", "=", "train_unsup_df", "[", ":", ",", "2", "]", "\n", "\n", "# Split the labeled training set, unlabeled training set, development set", "\n", "", "train_labeled_idxs", ",", "train_unlabeled_idxs", ",", "val_idxs", "=", "train_val_split", "(", "train_labels", ",", "n_labeled_per_class", ",", "\n", "unlabeled_per_class", ",", "n_labels", ")", "\n", "\n", "unlabeled_text", "=", "train_text", "[", "train_unlabeled_idxs", "]", "if", "n_labels", "!=", "2", "else", "train_unsup_text", "\n", "\n", "# Build the dataset class for each set", "\n", "train_labeled_dataset", "=", "loader_labeled", "(", "\n", "train_text", "[", "train_labeled_idxs", "]", ",", "train_labels", "[", "train_labeled_idxs", "]", ",", "tokenizer", ",", "max_seq_len", ",", "n_labels", "\n", ")", "\n", "train_unlabeled_dataset", "=", "loader_unlabeled", "(", "\n", "unlabeled_text", ",", "train_unlabeled_idxs", ",", "tokenizer", ",", "max_seq_len", ",", "n_labels", ",", "\n", ")", "\n", "val_dataset", "=", "loader_labeled", "(", "\n", "train_text", "[", "val_idxs", "]", ",", "train_labels", "[", "val_idxs", "]", ",", "tokenizer", ",", "max_seq_len", ",", "n_labels", "\n", ")", "\n", "test_dataset", "=", "loader_labeled", "(", "\n", "test_text", ",", "test_labels", ",", "tokenizer", ",", "max_seq_len", ",", "n_labels", "\n", ")", "\n", "\n", "logging", ".", "info", "(", "\" | Number of Labeled Samples : {} \\t Number of Unlabeled Samples : {} \"", "\n", "\"\\t Number of Valid Samples {} \\t Number of Test Samples {}\"", ".", "format", "(", "len", "(", "\n", "train_labeled_idxs", ")", ",", "len", "(", "unlabeled_text", ")", ",", "len", "(", "val_idxs", ")", ",", "len", "(", "test_labels", ")", ")", ")", "\n", "\n", "return", "train_labeled_dataset", ",", "train_unlabeled_dataset", ",", "val_dataset", ",", "test_dataset", ",", "n_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.data_utils.train_val_split": [[92, 132], ["numpy.array", "range", "numpy.random.shuffle", "numpy.random.shuffle", "numpy.random.shuffle", "numpy.random.shuffle", "numpy.where", "numpy.concatenate", "train_labeled_idxs.extend", "val_idxs.extend", "numpy.concatenate", "train_labeled_idxs.extend", "train_unlabeled_idxs.extend", "val_idxs.extend"], "function", ["None"], ["", "def", "train_val_split", "(", "labels", ",", "n_labeled_per_class", ",", "unlabeled_per_class", ",", "n_labels", ")", ":", "\n", "    ", "\"\"\"Split the original training set into labeled training set, unlabeled training set, development set\n\n    Arguments:\n        labels {list}             -- List of labeles for original training set\n        n_labeled_per_class {int} -- Number of labeled data per class\n        unlabeled_per_class {int} -- Number of unlabeled data per class\n        n_labels {int}            -- The number of classes\n\n    Returns:\n        [list] -- idx for labeled training set, unlabeled training set, development set\n    \"\"\"", "\n", "\n", "labels", "=", "np", ".", "array", "(", "labels", ")", "\n", "train_labeled_idxs", "=", "[", "]", "\n", "train_unlabeled_idxs", "=", "[", "]", "\n", "val_idxs", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "n_labels", ")", ":", "\n", "        ", "idxs", "=", "np", ".", "where", "(", "labels", "==", "i", ")", "[", "0", "]", "\n", "np", ".", "random", ".", "shuffle", "(", "idxs", ")", "\n", "\n", "if", "n_labels", "==", "2", ":", "\n", "            ", "train_pool", "=", "np", ".", "concatenate", "(", "(", "idxs", "[", ":", "500", "]", ",", "idxs", "[", ":", "-", "2000", "]", ")", ")", "\n", "train_labeled_idxs", ".", "extend", "(", "train_pool", "[", ":", "n_labeled_per_class", "]", ")", "\n", "train_unlabeled_idxs", "=", "None", "\n", "val_idxs", ".", "extend", "(", "idxs", "[", "-", "2000", ":", "]", ")", "\n", "\n", "", "else", ":", "\n", "            ", "train_pool", "=", "np", ".", "concatenate", "(", "(", "idxs", "[", ":", "500", "]", ",", "idxs", "[", "5500", ":", "-", "2000", "]", ")", ")", "\n", "train_labeled_idxs", ".", "extend", "(", "train_pool", "[", ":", "n_labeled_per_class", "]", ")", "\n", "train_unlabeled_idxs", ".", "extend", "(", "idxs", "[", "500", ":", "500", "+", "unlabeled_per_class", "]", ")", "\n", "val_idxs", ".", "extend", "(", "idxs", "[", "-", "2000", ":", "]", ")", "\n", "\n", "", "", "np", ".", "random", ".", "shuffle", "(", "train_labeled_idxs", ")", "\n", "if", "n_labels", "!=", "2", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "train_unlabeled_idxs", ")", "\n", "", "np", ".", "random", ".", "shuffle", "(", "val_idxs", ")", "\n", "\n", "return", "train_labeled_idxs", ",", "train_unlabeled_idxs", ",", "val_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.dvat.DVAT.__init__": [[16, 27], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.clovaai_vat-d.None.model.LMBert.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "\n", "        ", "super", "(", "DVAT", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "tsa", "=", "args", ".", "tsa", "\n", "self", ".", "confidence", "=", "args", ".", "confidence", "\n", "self", ".", "sharpening", "=", "args", ".", "sharpening", "\n", "self", ".", "topk", "=", "args", ".", "topk", "\n", "self", ".", "swap_ratio", "=", "args", ".", "swap_ratio", "\n", "self", ".", "total_steps", "=", "args", ".", "epochs", "*", "args", ".", "val_iteration", "\n", "self", ".", "normalize_grad", "=", "args", ".", "normalize_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.dvat.DVAT.forward": [[28, 91], ["inputs_u[].clone", "model.bert.bert.embeddings.word_embeddings().clone", "src_embeds.detach.detach.detach().requires_grad_", "utils.tokens_to_embeds", "model", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.kl_div", "torch.kl_div", "utils.project.detach", "src_embeds.detach.detach.detach", "model.zero_grad", "utils.project", "model.bert.bert.embeddings.word_embeddings.weight.clone().detach", "dvat.DVAT.discrete_vat", "utils.embeds_to_tokens", "model", "torch.log_softmax", "torch.log_softmax", "torch.kl_div", "torch.kl_div", "model", "model.clone().detach", "pred_s.sum", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "utils.get_tsa_thresh", "sup_mask.float.float.float", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "model.bert.bert.embeddings.word_embeddings", "src_embeds.detach.detach.detach", "model.bert.bert.embeddings.word_embeddings.weight.clone", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.max", "torch.max", "torch.max", "torch.max", "model.clone", "torch.log_softmax", "torch.log_softmax", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.softmax", "torch.softmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.clovaai_vat-d.None.utils.tokens_to_embeds", "home.repos.pwc.inspect_result.clovaai_vat-d.None.utils.project", "home.repos.pwc.inspect_result.clovaai_vat-d.None.dvat.DVAT.discrete_vat", "home.repos.pwc.inspect_result.clovaai_vat-d.None.utils.embeds_to_tokens", "home.repos.pwc.inspect_result.clovaai_vat-d.None.utils.get_tsa_thresh"], ["", "def", "forward", "(", "self", ",", "model", ",", "inputs_s", ",", "targets_s", ",", "inputs_u", ",", "train_step", ",", "model_lm", ")", ":", "\n", "\n", "# tokens to embeds", "\n", "\n", "        ", "src_tokens", "=", "inputs_u", "[", "'input_ids'", "]", ".", "clone", "(", ")", "\n", "src_embeds", "=", "model", ".", "bert", ".", "bert", ".", "embeddings", ".", "word_embeddings", "(", "src_tokens", ")", ".", "clone", "(", ")", "\n", "src_embeds", "=", "src_embeds", ".", "detach", "(", ")", ".", "requires_grad_", "(", "True", ")", "\n", "inputs_u", "=", "tokens_to_embeds", "(", "inputs_u", ",", "inputs_u", ",", "src_embeds", ")", "\n", "\n", "# model forward & sharpening logit", "\n", "\n", "pred", "=", "model", "(", "inputs_u", ")", "\n", "pred_log_p", "=", "F", ".", "log_softmax", "(", "pred", ",", "dim", "=", "-", "1", ")", "\n", "pred_p", "=", "torch", ".", "softmax", "(", "pred", ".", "clone", "(", ")", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", "\n", "pred_s", "=", "pred_p", "**", "(", "1", "/", "self", ".", "sharpening", ")", "\n", "pred_s", "=", "pred_s", "/", "pred_s", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "# calculate adversarial direction (first-order approx. with sharpened label dist.)", "\n", "\n", "adv_loss", "=", "F", ".", "kl_div", "(", "pred_log_p", ",", "pred_s", ",", "None", ",", "None", ",", "reduction", "=", "'batchmean'", ")", "\n", "delta_grad", "=", "torch", ".", "autograd", ".", "grad", "(", "adv_loss", ",", "src_embeds", ",", "only_inputs", "=", "True", ")", "[", "0", "]", "\n", "delta_grad", "=", "delta_grad", ".", "detach", "(", ")", "# B S H ", "\n", "src_embeds", "=", "src_embeds", ".", "detach", "(", ")", "# B S H", "\n", "\n", "# discard gradients", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "# normalize gradients & get VAT-D inputs", "\n", "\n", "delta_grad", "=", "project", "(", "delta_grad", ",", "norm_type", "=", "self", ".", "normalize_grad", ")", "\n", "embedding_matrix", "=", "model", ".", "bert", ".", "bert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "adv_tokens", "=", "self", ".", "discrete_vat", "(", "\n", "delta_grad", ",", "embedding_matrix", ",", "src_tokens", ",", "src_embeds", ",", "inputs_u", ",", "model_lm", "\n", ")", "\n", "\n", "adv_inputs_u", "=", "{", "}", "\n", "adv_inputs_u", "=", "embeds_to_tokens", "(", "adv_inputs_u", ",", "inputs_u", ",", "adv_tokens", ")", "\n", "\n", "pred_hat", "=", "model", "(", "adv_inputs_u", ")", "\n", "logp_hat", "=", "F", ".", "log_softmax", "(", "pred_hat", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# consistency loss", "\n", "\n", "loss_const", "=", "F", ".", "kl_div", "(", "logp_hat", ",", "pred_s", ",", "None", ",", "None", ",", "reduction", "=", "'batchmean'", ")", "\n", "\n", "# cross-entropy loss", "\n", "\n", "logits_x", "=", "model", "(", "inputs_s", ")", "\n", "loss_ce", "=", "-", "1", "*", "torch", ".", "sum", "(", "F", ".", "log_softmax", "(", "logits_x", ",", "dim", "=", "1", ")", "*", "targets_s", ",", "dim", "=", "1", ")", "\n", "\n", "# apply tsa", "\n", "\n", "if", "self", ".", "tsa", "is", "not", "None", ":", "\n", "            ", "tsa_thresh", "=", "get_tsa_thresh", "(", "self", ".", "tsa", ",", "train_step", ",", "self", ".", "total_steps", ",", "start", "=", "1.", "/", "logits_x", ".", "shape", "[", "-", "1", "]", ",", "end", "=", "1", ")", "\n", "sup_mask", "=", "torch", ".", "sum", "(", "F", ".", "softmax", "(", "logits_x", ",", "dim", "=", "-", "1", ")", "*", "targets_s", ",", "dim", "=", "1", ")", "<", "tsa_thresh", "\n", "sup_mask", "=", "sup_mask", ".", "float", "(", ")", "\n", "loss_ce", "=", "torch", ".", "sum", "(", "loss_ce", "*", "sup_mask", ",", "dim", "=", "-", "1", ")", "/", "torch", ".", "max", "(", "torch", ".", "sum", "(", "sup_mask", ",", "dim", "=", "-", "1", ")", ",", "\n", "torch", ".", "tensor", "(", "1.", ")", ".", "to", "(", "device", ")", ")", "\n", "", "else", ":", "\n", "            ", "loss_ce", "=", "torch", ".", "mean", "(", "loss_ce", ")", "\n", "\n", "", "return", "loss_ce", ",", "loss_const", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.dvat.DVAT.discrete_vat": [[93, 158], ["src_embeds.clone().detach.clone().detach.clone().detach", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "dvat.pairwise_distance", "src_tokens.clone().data.fill_", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to.clone", "torch.rand().to.clone", "mask_idx.clamp.clamp.clamp", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "inputs_u[].unsqueeze", "dir_dot_grad.clone().data.fill_", "dir_dot_grad.clone().data.fill_.scatter_", "dir_dot_grad.clone", "dir_dot_grad.clone.scatter_", "dir_dot_grad.clone.max", "mask_idx.clamp.clamp.clamp", "src_tokens.clone", "adv_tokens.long.long.long", "torch.einsum.unsqueeze", "torch.einsum.unsqueeze", "torch.rand().to.long", "torch.rand().to.long", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model_lm", "src_tokens.unsqueeze", "src_embeds.clone().detach.clone().detach.clone", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "src_tokens.clone", "src_tokens.size", "dir_dot_grad.clone"], "methods", ["home.repos.pwc.inspect_result.clovaai_vat-d.None.dvat.pairwise_distance"], ["", "def", "discrete_vat", "(", "self", ",", "delta_grad", ",", "embedding_matrix", ",", "src_tokens", ",", "src_embeds", ",", "inputs_u", ",", "model_lm", ")", ":", "\n", "\n", "        ", "\"\"\" \n        Code heavily inspired from Paul Michel \n        https://github.com/pmichel31415/translate/blob/paul/pytorch_translate/research/adversarial/adversaries/brute_force_adversary.py\n        \"\"\"", "\n", "\n", "# hotflip", "\n", "\n", "src_embeds", "=", "src_embeds", ".", "clone", "(", ")", ".", "detach", "(", ")", "# B S H", "\n", "\n", "new_embed_dot_grad", "=", "torch", ".", "einsum", "(", "\n", "\"bij,kj->bik\"", ",", "(", "delta_grad", ",", "embedding_matrix", ")", "\n", ")", "\n", "prev_embed_dot_grad", "=", "torch", ".", "einsum", "(", "\n", "\"bij,bij->bi\"", ",", "(", "delta_grad", ",", "src_embeds", ")", "\n", ")", "\n", "\n", "dir_dot_grad", "=", "prev_embed_dot_grad", ".", "unsqueeze", "(", "-", "1", ")", "-", "new_embed_dot_grad", "# B S V        ", "\n", "dir_dot_grad", "*=", "-", "1", "\n", "dir_norm", "=", "pairwise_distance", "(", "src_embeds", ",", "embedding_matrix", ")", "\n", "dir_dot_grad", "/=", "dir_norm", "\n", "\n", "# get tokens to perturb", "\n", "\n", "no_special_tokens", "=", "(", "src_tokens", ">=", "999", ")", ".", "float", "(", ")", "# no special tokens for perturbation (BERT ver.)", "\n", "mask_idx", "=", "src_tokens", ".", "clone", "(", ")", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "mask_idx", "=", "mask_idx", "*", "no_special_tokens", "\n", "\n", "rand", "=", "torch", ".", "rand", "(", "src_tokens", ".", "size", "(", ")", ")", ".", "to", "(", "device", ")", "\n", "rand", "=", "rand", ">", "(", "1", "-", "self", ".", "swap_ratio", ")", "\n", "rand", "=", "mask_idx", "*", "rand", ".", "long", "(", ")", "\n", "mask_idx", "=", "rand", ".", "clone", "(", ")", "\n", "\n", "mask_idx", "=", "mask_idx", ".", "clamp", "(", "0", ",", "1", ")", "\n", "\n", "# LM filtering part", "\n", "\n", "inputs_u", "[", "'inputs_embeds'", "]", "=", "src_embeds", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "pred_lm", "=", "model_lm", "(", "inputs_u", ")", "\n", "\n", "", "_", ",", "top_k_lm_idx", "=", "torch", ".", "topk", "(", "pred_lm", ",", "dim", "=", "2", ",", "k", "=", "self", ".", "topk", ")", "\n", "top_k_lm_idx", "*=", "inputs_u", "[", "'attention_mask'", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "mask", "=", "dir_dot_grad", ".", "clone", "(", ")", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "mask", "*=", "-", "np", ".", "inf", "\n", "mask", ".", "scatter_", "(", "2", ",", "top_k_lm_idx", ",", "0", ")", "\n", "filtered_dir_dot_grad", "=", "dir_dot_grad", ".", "clone", "(", ")", "\n", "filtered_dir_dot_grad", "+=", "mask", "\n", "\n", "filtered_dir_dot_grad", "[", ":", ",", ":", ",", ":", "999", "]", "=", "-", "np", ".", "inf", "# no special tokens as candidates      ", "\n", "filtered_dir_dot_grad", ".", "scatter_", "(", "2", ",", "src_tokens", ".", "unsqueeze", "(", "-", "1", ")", ",", "-", "np", ".", "inf", ")", "\n", "\n", "_", ",", "adv_flip", "=", "filtered_dir_dot_grad", ".", "max", "(", "2", ")", "\n", "\n", "mask_idx", "=", "mask_idx", ".", "clamp", "(", "0", ",", "1", ")", "\n", "\n", "ori_tokens", "=", "src_tokens", ".", "clone", "(", ")", "\n", "ori_tokens", "=", "ori_tokens", "*", "(", "1", "-", "mask_idx", ")", "\n", "adv_tokens", "=", "adv_flip", "*", "mask_idx", "\n", "adv_tokens", "=", "ori_tokens", "+", "adv_tokens", "\n", "adv_tokens", "=", "adv_tokens", ".", "long", "(", ")", "\n", "\n", "return", "adv_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.dvat.pairwise_dot_product": [[160, 171], ["torch.einsum", "torch.einsum", "torch.normalize", "torch.normalize"], "function", ["None"], ["", "", "def", "pairwise_dot_product", "(", "src_embeds", ",", "vocab_embeds", ",", "cosine", "=", "False", ")", ":", "\n", "    ", "\"\"\"Compute the cosine similarity between each word in the vocab and each\n    word in the source\n    If `cosine=True` this returns the pairwise cosine similarity\"\"\"", "\n", "# Normlize vectors for the cosine similarity", "\n", "if", "cosine", ":", "\n", "        ", "src_embeds", "=", "F", ".", "normalize", "(", "src_embeds", ",", "dim", "=", "-", "1", ",", "p", "=", "2", ")", "\n", "vocab_embeds", "=", "F", ".", "normalize", "(", "vocab_embeds", ",", "dim", "=", "-", "1", ",", "p", "=", "2", ")", "\n", "# Take the dot product", "\n", "", "dot_product", "=", "torch", ".", "einsum", "(", "\"bij,kj->bik\"", ",", "(", "src_embeds", ",", "vocab_embeds", ")", ")", "\n", "return", "dot_product", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.dvat.pairwise_distance": [[173, 200], ["vocab_embeds.norm", "src_embeds.norm", "dvat.pairwise_dot_product", "vocab_sq_norm.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "src_sq_norm.unsqueeze.unsqueeze", "sq_norm.sqrt", "vocab_sq_norm.unsqueeze().unsqueeze.unsqueeze", "torch.relu"], "function", ["home.repos.pwc.inspect_result.clovaai_vat-d.None.dvat.pairwise_dot_product"], ["", "def", "pairwise_distance", "(", "src_embeds", ",", "vocab_embeds", ",", "squared", "=", "False", ")", ":", "\n", "    ", "\"\"\"Compute the euclidean distance between each word in the vocab and each\n    word in the source\"\"\"", "\n", "# We will compute the squared norm first to avoid having to compute all", "\n", "# the directions (which would have space complexity B x T x |V| x d)", "\n", "# First compute the squared norm of each word vector", "\n", "vocab_sq", "=", "vocab_embeds", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "\n", "vocab_sq_norm", "=", "vocab_sq", "**", "2", "\n", "src_sq", "=", "src_embeds", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "\n", "src_sq_norm", "=", "src_sq", "**", "2", "\n", "# Take the dot product", "\n", "dot_product", "=", "pairwise_dot_product", "(", "src_embeds", ",", "vocab_embeds", ")", "\n", "# Reshape for broadcasting", "\n", "# 1 x 1 x |V|", "\n", "vocab_sq_norm", "=", "vocab_sq_norm", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "# B x T x 1", "\n", "src_sq_norm", "=", "src_sq_norm", ".", "unsqueeze", "(", "2", ")", "\n", "# Compute squared difference", "\n", "sq_norm", "=", "vocab_sq_norm", "+", "src_sq_norm", "-", "2", "*", "dot_product", "\n", "# Either return the squared norm or return the sqrt", "\n", "if", "squared", ":", "\n", "        ", "return", "sq_norm", "\n", "", "else", ":", "\n", "# Relu + epsilon for numerical stability", "\n", "        ", "sq_norm", "=", "F", ".", "relu", "(", "sq_norm", ")", "+", "1e-20", "\n", "# Take the square root", "\n", "return", "sq_norm", ".", "sqrt", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.train.main": [[23, 111], ["utils.set_seed", "data_utils.get_data", "torch.DataLoader", "torch.DataLoader", "torch.DataLoader", "torch.DataLoader", "utils.repeat_dataloader", "utils.repeat_dataloader", "model.ClassificationBert().to", "model.LMBert().to", "LMBert().to.eval", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logging.info", "dvat.DVAT", "torch.CrossEntropyLoss", "range", "logging.info", "logging.info", "logging.info", "train.train", "train.validate", "logging.info", "model.ClassificationBert", "model.LMBert", "int", "train.validate", "int", "ClassificationBert().to.named_parameters", "ClassificationBert().to.named_parameters", "any", "any"], "function", ["home.repos.pwc.inspect_result.clovaai_vat-d.None.utils.set_seed", "home.repos.pwc.inspect_result.clovaai_vat-d.None.data_utils.get_data", "home.repos.pwc.inspect_result.clovaai_vat-d.None.utils.repeat_dataloader", "home.repos.pwc.inspect_result.clovaai_vat-d.None.utils.repeat_dataloader", "home.repos.pwc.inspect_result.clovaai_vat-d.None.train.train", "home.repos.pwc.inspect_result.clovaai_vat-d.None.train.validate", "home.repos.pwc.inspect_result.clovaai_vat-d.None.train.validate"], ["def", "main", "(", "args", ")", ":", "\n", "\n", "    ", "set_seed", "(", "args", ".", "seed", ")", "\n", "\n", "# read dataset and build dataloaders", "\n", "\n", "train_labeled_set", ",", "train_unlabeled_set", ",", "val_set", ",", "test_set", ",", "n_labels", "=", "get_data", "(", "\n", "data_path", "=", "args", ".", "data_path", ",", "n_labeled_per_class", "=", "args", ".", "n_labeled", ",", "\n", "unlabeled_per_class", "=", "args", ".", "un_labeled", ",", "model", "=", "args", ".", "model_ver", "\n", ")", "\n", "labeled_trainloader", "=", "Data", ".", "DataLoader", "(", "\n", "dataset", "=", "train_labeled_set", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", "\n", ")", "\n", "unlabeled_trainloader", "=", "Data", ".", "DataLoader", "(", "\n", "dataset", "=", "train_unlabeled_set", ",", "batch_size", "=", "args", ".", "batch_size_u", ",", "shuffle", "=", "True", "\n", ")", "\n", "val_loader", "=", "Data", ".", "DataLoader", "(", "\n", "dataset", "=", "val_set", ",", "batch_size", "=", "512", ",", "shuffle", "=", "False", "\n", ")", "\n", "test_loader", "=", "Data", ".", "DataLoader", "(", "\n", "dataset", "=", "test_set", ",", "batch_size", "=", "512", ",", "shuffle", "=", "False", "\n", ")", "\n", "\n", "labeled_trainiter", "=", "repeat_dataloader", "(", "labeled_trainloader", ")", "\n", "unlabeled_trainiter", "=", "repeat_dataloader", "(", "unlabeled_trainloader", ")", "\n", "\n", "# define the models, set the optimizer", "\n", "\n", "model", "=", "ClassificationBert", "(", "args", ".", "model_ver", ",", "n_labels", ")", ".", "to", "(", "device", ")", "\n", "model_lm", "=", "LMBert", "(", "args", ".", "model_ver", ")", ".", "to", "(", "device", ")", "\n", "\n", "model_lm", ".", "eval", "(", ")", "\n", "\n", "t_total", "=", "args", ".", "epochs", "*", "args", ".", "val_iteration", "\n", "\n", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", "\n", "}", ",", "\n", "]", "\n", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "logging", ".", "info", "(", "\" | Training with Discrete VAT\"", ")", "\n", "train_criterion", "=", "DVAT", "(", "args", ")", "\n", "use_unlabeled", "=", "True", "\n", "val_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "best_val_acc", "=", "0", "\n", "best_test_acc", "=", "0", "\n", "\n", "# start training", "\n", "\n", "for", "epoch", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "\n", "        ", "train", "(", "\n", "args", ",", "labeled_trainiter", ",", "unlabeled_trainiter", ",", "model", ",", "optimizer", ",", "scheduler", ",", "\n", "train_criterion", ",", "epoch", ",", "n_labels", ",", "model_lm", ",", "use_unlabeled", "\n", ")", "\n", "\n", "val_loss", ",", "val_acc", "=", "validate", "(", "\n", "val_loader", ",", "model", ",", "val_criterion", "\n", ")", "\n", "\n", "logging", ".", "info", "(", "\" | Train Step : {}  Validation Accuracy : {:.2f}  Validation Loss : {:.2f}\"", ".", "format", "(", "\n", "int", "(", "(", "epoch", "+", "1", ")", "*", "args", ".", "val_iteration", ")", ",", "val_acc", ",", "val_loss", ")", "\n", ")", "\n", "\n", "if", "val_acc", ">=", "best_val_acc", ":", "\n", "            ", "best_val_acc", "=", "val_acc", "\n", "best_step", "=", "int", "(", "(", "epoch", "+", "1", ")", "*", "args", ".", "val_iteration", ")", "\n", "_", ",", "test_acc", "=", "validate", "(", "\n", "test_loader", ",", "model", ",", "val_criterion", "\n", ")", "\n", "best_test_acc", "=", "test_acc", "\n", "\n", "", "", "logging", ".", "info", "(", "' | Best Performance at Train Step : {}'", ".", "format", "(", "best_step", ")", ")", "\n", "logging", ".", "info", "(", "' | Best Validation Accuracy : {:.2f}'", ".", "format", "(", "best_val_acc", ")", ")", "\n", "logging", ".", "info", "(", "' | Best Test Accuracy : {:.2f}'", ".", "format", "(", "best_test_acc", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.train.train": [[113, 152], ["model.train", "range", "next", "next", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "utils.to_device", "targets_s.to.to", "utils.to_device", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "optimizer.zero_grad", "torch.mean.backward", "optimizer.step", "scheduler.step", "targets_s.to.view", "criterion", "loss_ce.item", "loss_const.item", "model", "torch.mean", "torch.mean", "torch.mean", "torch.mean.item", "model.parameters", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sum", "torch.sum", "torch.sum", "inputs_s[].size", "torch.log_softmax"], "function", ["home.repos.pwc.inspect_result.clovaai_vat-d.None.train.train", "home.repos.pwc.inspect_result.clovaai_vat-d.None.utils.to_device", "home.repos.pwc.inspect_result.clovaai_vat-d.None.utils.to_device"], ["", "def", "train", "(", "args", ",", "labeled_trainiter", ",", "unlabeled_trainiter", ",", "model", ",", "optimizer", ",", "scheduler", ",", "criterion", ",", "epoch", ",", "n_labels", ",", "\n", "model_lm", ",", "use_unlabeled", ")", ":", "\n", "\n", "    ", "train_step", "=", "epoch", "*", "args", ".", "val_iteration", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "loss_ce_log", "=", "0", "\n", "loss_const_log", "=", "0", "\n", "\n", "for", "_", "in", "range", "(", "args", ".", "val_iteration", ")", ":", "\n", "\n", "        ", "train_step", "+=", "1", "\n", "\n", "inputs_s", ",", "targets_s", "=", "next", "(", "labeled_trainiter", ")", "\n", "inputs_u", "=", "next", "(", "unlabeled_trainiter", ")", "\n", "targets_s", "=", "torch", ".", "zeros", "(", "inputs_s", "[", "'input_ids'", "]", ".", "size", "(", "0", ")", ",", "n_labels", ")", ".", "scatter_", "(", "1", ",", "targets_s", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", "\n", "inputs_s", "=", "to_device", "(", "inputs_s", ")", "\n", "targets_s", "=", "targets_s", ".", "to", "(", "device", ")", "\n", "inputs_u", "=", "to_device", "(", "inputs_u", ")", "\n", "\n", "if", "use_unlabeled", ":", "\n", "            ", "loss_ce", ",", "loss_const", "=", "criterion", "(", "model", ",", "inputs_s", ",", "targets_s", ",", "inputs_u", ",", "train_step", ",", "model_lm", ")", "\n", "loss_ce_log", "+=", "loss_ce", ".", "item", "(", ")", "\n", "loss_const_log", "+=", "loss_const", ".", "item", "(", ")", "\n", "loss", "=", "loss_const", "+", "loss_ce", "\n", "", "else", ":", "\n", "            ", "pred", "=", "model", "(", "inputs_s", ")", "\n", "loss", "=", "-", "1", "*", "torch", ".", "sum", "(", "F", ".", "log_softmax", "(", "pred", ",", "dim", "=", "1", ")", "*", "targets_s", ",", "dim", "=", "1", ")", "\n", "loss", "=", "torch", ".", "mean", "(", "loss", ")", "\n", "loss_ce_log", "+=", "loss", ".", "item", "(", ")", "\n", "loss_const_log", "=", "100", "\n", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.train.validate": [[154, 183], ["model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "torch.tensor().to().float", "torch.tensor().to().float", "torch.tensor().to().float", "utils.to_device", "targets.to.to", "model", "criterion", "torch.max", "torch.max", "torch.max", "torch.sum().float", "torch.sum().float", "torch.sum().float", "criterion.item", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.sum", "torch.sum", "torch.sum", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.clovaai_vat-d.None.utils.to_device"], ["", "", "def", "validate", "(", "validloader", ",", "model", ",", "criterion", ")", ":", "\n", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "        ", "loss_total", "=", "0", "\n", "num_sample", "=", "0", "\n", "num_correct", "=", "0", "\n", "\n", "for", "_", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "validloader", ")", ":", "\n", "\n", "            ", "inputs", "=", "to_device", "(", "inputs", ")", "\n", "targets", "=", "targets", ".", "to", "(", "device", ")", "\n", "outputs", "=", "model", "(", "inputs", ")", "\n", "\n", "loss", "=", "criterion", "(", "outputs", ",", "targets", ")", "\n", "\n", "_", ",", "predicted", "=", "torch", ".", "max", "(", "outputs", ".", "data", ",", "1", ")", "\n", "\n", "num_correct", "+=", "torch", ".", "sum", "(", "predicted", "==", "targets", ")", ".", "float", "(", ")", "\n", "loss_total", "+=", "loss", ".", "item", "(", ")", "*", "inputs", "[", "'input_ids'", "]", ".", "shape", "[", "0", "]", "\n", "num_sample", "+=", "inputs", "[", "'input_ids'", "]", ".", "shape", "[", "0", "]", "\n", "\n", "", "num_sample", "=", "torch", ".", "tensor", "(", "num_sample", ")", ".", "to", "(", "device", ")", ".", "float", "(", ")", "\n", "acc_total", "=", "(", "num_correct", "/", "num_sample", ")", "*", "100", "\n", "loss_total", "=", "loss_total", "/", "num_sample", "\n", "\n", "", "return", "loss_total", ",", "acc_total", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.model.ClassificationBert.__init__": [[10, 15], ["torch.Module.__init__", "transformers.BertConfig.from_pretrained", "transformers.BertForSequenceClassification.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.clovaai_vat-d.None.model.LMBert.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model_version", ",", "num_labels", "=", "2", ")", ":", "\n", "        ", "super", "(", "ClassificationBert", ",", "self", ")", ".", "__init__", "(", ")", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "model_version", ")", "\n", "config", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "bert", "=", "BertForSequenceClassification", ".", "from_pretrained", "(", "model_version", ",", "config", "=", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.model.ClassificationBert.forward": [[16, 19], ["model.ClassificationBert.bert"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "**", "inputs", ")", "\n", "return", "outputs", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.model.LMBert.__init__": [[22, 26], ["torch.Module.__init__", "transformers.BertConfig.from_pretrained", "transformers.BertForMaskedLM.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.clovaai_vat-d.None.model.LMBert.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model_version", ")", ":", "\n", "        ", "super", "(", "LMBert", ",", "self", ")", ".", "__init__", "(", ")", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "model_version", ")", "\n", "self", ".", "bert", "=", "BertForMaskedLM", ".", "from_pretrained", "(", "model_version", ",", "config", "=", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.model.LMBert.forward": [[27, 30], ["model.LMBert.bert"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "**", "inputs", ")", "\n", "return", "outputs", "[", "0", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.utils.to_device": [[16, 20], ["inputs.keys", "inputs[].to"], "function", ["None"], ["def", "to_device", "(", "inputs", ")", ":", "\n", "    ", "for", "k", "in", "inputs", ".", "keys", "(", ")", ":", "\n", "        ", "inputs", "[", "k", "]", "=", "inputs", "[", "k", "]", ".", "to", "(", "device", ")", "\n", "", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.utils.set_seed": [[22, 27], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seed", "(", "seed", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.utils.get_tsa_thresh": [[29, 41], ["torch.tensor", "torch.exp.to", "float", "float", "torch.exp", "torch.exp"], "function", ["None"], ["", "def", "get_tsa_thresh", "(", "schedule", ",", "global_step", ",", "num_train_steps", ",", "start", ",", "end", ")", ":", "\n", "    ", "training_progress", "=", "torch", ".", "tensor", "(", "float", "(", "global_step", ")", "/", "float", "(", "num_train_steps", ")", ")", "\n", "if", "schedule", "==", "'lin_schedule'", ":", "\n", "        ", "threshold", "=", "training_progress", "\n", "", "elif", "schedule", "==", "'exp_schedule'", ":", "\n", "        ", "scale", "=", "5", "\n", "threshold", "=", "torch", ".", "exp", "(", "(", "training_progress", "-", "1", ")", "*", "scale", ")", "\n", "", "elif", "schedule", "==", "'log_schedule'", ":", "\n", "        ", "scale", "=", "5", "\n", "threshold", "=", "1", "-", "torch", ".", "exp", "(", "(", "-", "training_progress", ")", "*", "scale", ")", "\n", "", "threshold", "=", "threshold", "*", "(", "end", "-", "start", ")", "+", "start", "\n", "return", "threshold", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.utils.get_confidence_mask": [[43, 52], ["unsup_loss_mask.to.type", "torch.ones", "unsup_loss_mask.to.to", "len", "torch.max"], "function", ["None"], ["", "def", "get_confidence_mask", "(", "confidence_threshold", ",", "prob_dist", ")", ":", "\n", "    ", "if", "confidence_threshold", "!=", "-", "1", ":", "\n", "            ", "unsup_loss_mask", "=", "torch", ".", "max", "(", "prob_dist", ",", "dim", "=", "-", "1", ")", "[", "0", "]", ">", "confidence_threshold", "\n", "unsup_loss_mask", "=", "unsup_loss_mask", ".", "type", "(", "torch", ".", "float32", ")", "\n", "", "else", ":", "\n", "        ", "unsup_loss_mask", "=", "torch", ".", "ones", "(", "len", "(", "prob_dist", ")", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "unsup_loss_mask", "=", "unsup_loss_mask", ".", "to", "(", "device", ")", "\n", "\n", "", "return", "unsup_loss_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.utils.project": [[54, 60], ["grad.sign", "torch.norm"], "function", ["None"], ["", "def", "project", "(", "grad", ",", "norm_type", "=", "'inf'", ",", "eps", "=", "1e-6", ")", ":", "\n", "    ", "if", "norm_type", "==", "'l2'", ":", "\n", "        ", "direction", "=", "grad", "/", "(", "torch", ".", "norm", "(", "grad", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "+", "eps", ")", "\n", "", "elif", "norm_type", "==", "'inf'", ":", "\n", "        ", "direction", "=", "grad", ".", "sign", "(", ")", "\n", "", "return", "direction", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.utils.tokens_to_embeds": [[62, 69], ["orig_dict[].clone", "orig_dict[].clone"], "function", ["None"], ["", "def", "tokens_to_embeds", "(", "empty_dict", ",", "orig_dict", ",", "new_embeds", ")", ":", "\n", "    ", "empty_dict", "[", "'input_ids'", "]", "=", "None", "\n", "empty_dict", "[", "'inputs_embeds'", "]", "=", "new_embeds", "\n", "empty_dict", "[", "'attention_mask'", "]", "=", "orig_dict", "[", "'attention_mask'", "]", ".", "clone", "(", ")", "\n", "empty_dict", "[", "'token_type_ids'", "]", "=", "orig_dict", "[", "'token_type_ids'", "]", ".", "clone", "(", ")", "\n", "\n", "return", "empty_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.utils.embeds_to_tokens": [[71, 78], ["orig_dict[].clone", "orig_dict[].clone"], "function", ["None"], ["", "def", "embeds_to_tokens", "(", "empty_dict", ",", "orig_dict", ",", "new_tokens", ")", ":", "\n", "    ", "empty_dict", "[", "'input_ids'", "]", "=", "new_tokens", "\n", "empty_dict", "[", "'inputs_embeds'", "]", "=", "None", "\n", "empty_dict", "[", "'attention_mask'", "]", "=", "orig_dict", "[", "'attention_mask'", "]", ".", "clone", "(", ")", "\n", "empty_dict", "[", "'token_type_ids'", "]", "=", "orig_dict", "[", "'token_type_ids'", "]", ".", "clone", "(", ")", "\n", "\n", "return", "empty_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.clovaai_vat-d.None.utils.repeat_dataloader": [[80, 84], ["None"], "function", ["None"], ["", "def", "repeat_dataloader", "(", "iterable", ")", ":", "\n", "    ", "while", "True", ":", "\n", "        ", "for", "x", "in", "iterable", ":", "\n", "            ", "yield", "x", "", "", "", "", ""]]}