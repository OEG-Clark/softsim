{"home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_gen.set_seed": [[75, 80], ["numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_gen.prepare_ctrl_input": [[87, 95], ["tokenizer.encode", "logger.info", "any", "logger.info", "tokenizer.control_codes.values"], "function", ["None"], ["", "", "def", "prepare_ctrl_input", "(", "args", ",", "_", ",", "tokenizer", ",", "prompt_text", ")", ":", "\n", "    ", "if", "args", ".", "temperature", ">", "0.7", ":", "\n", "        ", "logger", ".", "info", "(", "\"CTRL typically works better with lower temperatures (and lower top_k).\"", ")", "\n", "\n", "", "encoded_prompt", "=", "tokenizer", ".", "encode", "(", "prompt_text", ",", "add_special_tokens", "=", "False", ")", "\n", "if", "not", "any", "(", "encoded_prompt", "[", "0", "]", "==", "x", "for", "x", "in", "tokenizer", ".", "control_codes", ".", "values", "(", ")", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"WARNING! You are not starting your generation from a control code so you won't get good results\"", ")", "\n", "", "return", "prompt_text", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_gen.prepare_xlm_input": [[97, 119], ["hasattr", "hasattr", "model.config.lang2id.keys", "input", "str", "list"], "function", ["None"], ["", "def", "prepare_xlm_input", "(", "args", ",", "model", ",", "tokenizer", ",", "prompt_text", ")", ":", "\n", "# kwargs = {\"language\": None, \"mask_token_id\": None}", "\n", "\n", "# Set the language", "\n", "    ", "use_lang_emb", "=", "hasattr", "(", "model", ".", "config", ",", "\"use_lang_emb\"", ")", "and", "model", ".", "config", ".", "use_lang_emb", "\n", "if", "hasattr", "(", "model", ".", "config", ",", "\"lang2id\"", ")", "and", "use_lang_emb", ":", "\n", "        ", "available_languages", "=", "model", ".", "config", ".", "lang2id", ".", "keys", "(", ")", "\n", "if", "args", ".", "xlm_language", "in", "available_languages", ":", "\n", "            ", "language", "=", "args", ".", "xlm_language", "\n", "", "else", ":", "\n", "            ", "language", "=", "None", "\n", "while", "language", "not", "in", "available_languages", ":", "\n", "                ", "language", "=", "input", "(", "\"Using XLM. Select language in \"", "+", "str", "(", "list", "(", "available_languages", ")", ")", "+", "\" >>> \"", ")", "\n", "# kwargs[\"language\"] = tokenizer.lang2id[language]", "\n", "\n", "# TODO fix mask_token_id setup when configurations will be synchronized between models and tokenizers", "\n", "# XLM masked-language modeling (MLM) models need masked token", "\n", "# is_xlm_mlm = \"mlm\" in args.model_name_or_path", "\n", "# if is_xlm_mlm:", "\n", "#     kwargs[\"mask_token_id\"] = tokenizer.mask_token_id", "\n", "\n", "", "", "", "return", "prompt_text", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_gen.prepare_xlnet_input": [[121, 124], ["None"], "function", ["None"], ["", "def", "prepare_xlnet_input", "(", "args", ",", "_", ",", "tokenizer", ",", "prompt_text", ")", ":", "\n", "    ", "prompt_text", "=", "(", "args", ".", "padding_text", "if", "args", ".", "padding_text", "else", "PADDING_TEXT", ")", "+", "prompt_text", "\n", "return", "prompt_text", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_gen.prepare_transfoxl_input": [[126, 129], ["None"], "function", ["None"], ["", "def", "prepare_transfoxl_input", "(", "args", ",", "_", ",", "tokenizer", ",", "prompt_text", ")", ":", "\n", "    ", "prompt_text", "=", "(", "args", ".", "padding_text", "if", "args", ".", "padding_text", "else", "PADDING_TEXT", ")", "+", "prompt_text", "\n", "return", "prompt_text", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_gen.adjust_length_to_model": [[139, 147], ["None"], "function", ["None"], ["def", "adjust_length_to_model", "(", "length", ",", "max_sequence_length", ")", ":", "\n", "    ", "if", "length", "<", "0", "and", "max_sequence_length", ">", "0", ":", "\n", "        ", "length", "=", "max_sequence_length", "\n", "", "elif", "0", "<", "max_sequence_length", "<", "length", ":", "\n", "        ", "length", "=", "max_sequence_length", "# No generation bigger than model size", "\n", "", "elif", "length", "<", "0", ":", "\n", "        ", "length", "=", "MAX_LENGTH", "# avoid infinite loop", "\n", "", "return", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_gen.main": [[149, 291], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.device", "torch.cuda.device_count", "run_gen.set_seed", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_gen.adjust_length_to_model", "logger.info", "parser.parse_args.model_type.lower", "pandas.read_csv", "data[].values.tolist", "data[].values.tolist", "open", "len", "open.write", "open.close", "run_gen.main.prompt_gen"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_lm.set_seed", "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_gen.adjust_length_to_model", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--prompt\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--length\"", ",", "type", "=", "int", ",", "default", "=", "20", ")", "\n", "parser", ".", "add_argument", "(", "\"--stop_token\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Token at which text generation is stopped\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--temperature\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"temperature of 1.0 has no effect, lower tend toward greedy sampling\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--repetition_penalty\"", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "\"primarily useful for CTRL model; in that case, use 1.2\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--k\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--p\"", ",", "type", "=", "float", ",", "default", "=", "0.9", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--padding_text\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"Padding text for Transfo-XL and XLNet.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--xlm_language\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"Optional language when used with the XLM model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_file\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Generate without file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--prompt_file\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"Prompt text and the conditional label\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_file\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"Output directory\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--use_fact\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"whether the input data contain the fact information\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--fact_sep\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"whether the input data contain the fact information\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cond_gen\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"whether the input data contain the fact information\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "args", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Initialize the model and tokenizer", "\n", "try", ":", "\n", "        ", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "", "except", "KeyError", ":", "\n", "        ", "raise", "KeyError", "(", "\"the model {} you specified is not supported. You are welcome to add it and open a PR :)\"", ")", "\n", "\n", "", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "args", ".", "length", "=", "adjust_length_to_model", "(", "args", ".", "length", ",", "max_sequence_length", "=", "model", ".", "config", ".", "max_position_embeddings", ")", "\n", "logger", ".", "info", "(", "args", ")", "\n", "\n", "\n", "def", "file_gen", "(", "args", ")", ":", "\n", "# prompt_list = open(args.prompt_file.format(\"src\"),'r').readlines()", "\n", "# ref_list = open(args.prompt_file.format(\"tgt\"),'r').readlines()", "\n", "# ref_content = [\" \".join(i.strip().split()[:400]) for i in ref_list]", "\n", "        ", "data", "=", "pd", ".", "read_csv", "(", "args", ".", "prompt_file", ",", "sep", "=", "\"\\t\"", ")", "\n", "prompt_list", "=", "data", "[", "'title'", "]", ".", "values", ".", "tolist", "(", ")", "\n", "ref_list", "=", "data", "[", "'content'", "]", ".", "values", ".", "tolist", "(", ")", "\n", "ref_content", "=", "[", "\" \"", ".", "join", "(", "i", ".", "strip", "(", ")", ".", "split", "(", ")", "[", ":", "400", "]", ")", "for", "i", "in", "ref_list", "]", "\n", "\n", "# fact_list = [\"<f-begin>\" + \" \".join((\" \".join(i[-2].split(\"|\"))).split(\",\")) + \"<f-end>\" for i in prompt_list]", "\n", "fact_raw", "=", "prompt_list", "\n", "\n", "\n", "encoded_prompt", "=", "[", "tokenizer", ".", "encode", "(", "prompt_text", "+", "\" <c-begin> \"", ".", "strip", "(", ")", ",", "add_special_tokens", "=", "False", ",", "return_tensors", "=", "\"pt\"", ")", "[", ":", "100", "]", "for", "prompt_text", "in", "\n", "prompt_list", "]", "\n", "\n", "\n", "\n", "fout", "=", "open", "(", "args", ".", "output_file", ",", "'w+'", ")", "\n", "total", "=", "len", "(", "encoded_prompt", ")", "\n", "# iter = zip(encoded_prompt, prompt_labels_list)", "\n", "fout", ".", "write", "(", "\"prompt\\tref_fact\\tref\\tgen\\tstyle_label\\n\"", ")", "\n", "with", "tqdm", "(", "total", "=", "total", ")", "as", "pbar", ":", "\n", "\n", "            ", "for", "i", ",", "e_p", "in", "enumerate", "(", "encoded_prompt", ")", ":", "\n", "                ", "e_p", "=", "e_p", ".", "to", "(", "args", ".", "device", ")", "\n", "output_sequences", "=", "model", ".", "generate", "(", "\n", "input_ids", "=", "e_p", ",", "\n", "max_length", "=", "args", ".", "length", ",", "\n", "temperature", "=", "args", ".", "temperature", ",", "\n", "top_k", "=", "args", ".", "k", ",", "\n", "top_p", "=", "args", ".", "p", ",", "\n", "repetition_penalty", "=", "args", ".", "repetition_penalty", ",", "\n", "do_sample", "=", "True", "\n", ")", "\n", "\n", "\n", "\n", "generated_sequence", "=", "output_sequences", "[", "0", "]", ".", "tolist", "(", ")", "\n", "text", "=", "tokenizer", ".", "decode", "(", "generated_sequence", ",", "clean_up_tokenization_spaces", "=", "True", ")", "\n", "text", "=", "text", "[", "text", ".", "find", "(", "\"<c-begin>\"", ")", ":", "text", ".", "find", "(", "args", ".", "stop_token", ")", "if", "args", ".", "stop_token", "else", "None", "]", "\n", "text", "=", "text", ".", "replace", "(", "\"<pad>\"", ",", "\"\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"<c-begin>\"", ",", "\"\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "prompt_text", "=", "tokenizer", ".", "decode", "(", "e_p", ".", "cpu", "(", ")", "[", "0", "]", ".", "tolist", "(", ")", ",", "clean_up_tokenization_spaces", "=", "True", ")", "\n", "\n", "fout", ".", "write", "(", "\"{}\\t{}\\t{}\\t{}\\t{}\\n\"", ".", "format", "(", "prompt_text", ".", "strip", "(", ")", ",", "fact_raw", "[", "i", "]", ".", "strip", "(", ")", ",", "ref_content", "[", "i", "]", ".", "strip", "(", ")", ",", "text", ".", "strip", "(", ")", ",", "1", ")", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "", "", "fout", ".", "close", "(", ")", "\n", "", "def", "prompt_gen", "(", ")", ":", "\n", "        ", "while", "True", ":", "\n", "                    ", "text", "=", "input", "(", "\"Prompt Text>>\"", ")", "\n", "e_p", "=", "tokenizer", ".", "encode", "(", "text", ",", "add_special_tokens", "=", "False", ",", "return_tensors", "=", "\"pt\"", ")", "\n", "e_p", "=", "e_p", ".", "to", "(", "args", ".", "device", ")", "\n", "output_sequences", "=", "model", ".", "generate", "(", "\n", "input_ids", "=", "e_p", ",", "\n", "max_length", "=", "args", ".", "length", ",", "\n", "temperature", "=", "args", ".", "temperature", ",", "\n", "top_k", "=", "args", ".", "k", ",", "\n", "top_p", "=", "args", ".", "p", ",", "\n", "repetition_penalty", "=", "args", ".", "repetition_penalty", ",", "\n", "do_sample", "=", "True", "\n", ")", "\n", "\n", "# Batch size == 1. to add more examples please use num_return_sequences > 1", "\n", "generated_sequence", "=", "output_sequences", "[", "0", "]", ".", "tolist", "(", ")", "\n", "text", "=", "tokenizer", ".", "decode", "(", "generated_sequence", ",", "clean_up_tokenization_spaces", "=", "True", ")", "\n", "text", "=", "text", "[", ":", "text", ".", "find", "(", "args", ".", "stop_token", ")", "if", "args", ".", "stop_token", "else", "None", "]", "\n", "text", "=", "text", ".", "replace", "(", "\"<pad>\"", ",", "\"\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "print", "(", "text", ")", "\n", "", "", "if", "args", ".", "no_file", ":", "\n", "        ", "prompt_gen", "(", ")", "\n", "", "else", ":", "\n", "        ", "file_gen", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_lm.load_dataset": [[91, 97], ["GPT2datastaset.GPT2Dataset"], "function", ["None"], ["def", "load_dataset", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ")", ":", "\n", "\n", "    ", "dataset", "=", "GPT2Dataset", "(", "\n", "tokenizer", "=", "tokenizer", ",", "args", "=", "args", ",", "file_path", "=", "args", ".", "eval_data_file", "if", "evaluate", "else", "args", ".", "train_data_file", ",", "block_size", "=", "args", ".", "block_size", "\n", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_lm.set_seed": [[100, 106], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_lm._rotate_checkpoints": [[108, 136], ["glob.glob", "sorted", "max", "os.path.join", "len", "logger.info", "shutil.rmtree", "ordering_and_checkpoint_path.append", "re.match", "len", "re.match.groups", "ordering_and_checkpoint_path.append", "os.path.getmtime", "float", "re.match.groups"], "function", ["None"], ["", "", "def", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", ",", "use_mtime", "=", "False", ")", ":", "\n", "    ", "if", "not", "args", ".", "save_total_limit", ":", "\n", "        ", "return", "\n", "", "if", "args", ".", "save_total_limit", "<=", "0", ":", "\n", "        ", "return", "\n", "\n", "# Check if we should delete older checkpoint(s)", "\n", "", "glob_checkpoints", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-*\"", ".", "format", "(", "checkpoint_prefix", ")", ")", ")", "\n", "if", "len", "(", "glob_checkpoints", ")", "<=", "args", ".", "save_total_limit", ":", "\n", "        ", "return", "\n", "\n", "", "ordering_and_checkpoint_path", "=", "[", "]", "\n", "for", "path", "in", "glob_checkpoints", ":", "\n", "        ", "if", "use_mtime", ":", "\n", "            ", "ordering_and_checkpoint_path", ".", "append", "(", "(", "os", ".", "path", ".", "getmtime", "(", "path", ")", ",", "path", ")", ")", "\n", "", "else", ":", "\n", "            ", "regex_match", "=", "re", ".", "match", "(", "\".*{}-([0-9]*\\.[0-9]+|[0-9]+)\"", ".", "format", "(", "checkpoint_prefix", ")", ",", "path", ")", "\n", "if", "regex_match", "and", "regex_match", ".", "groups", "(", ")", ":", "\n", "                ", "ordering_and_checkpoint_path", ".", "append", "(", "(", "float", "(", "regex_match", ".", "groups", "(", ")", "[", "0", "]", ")", ",", "path", ")", ")", "\n", "\n", "", "", "", "checkpoints_sorted", "=", "sorted", "(", "ordering_and_checkpoint_path", ",", "reverse", "=", "True", ")", "\n", "\n", "checkpoints_sorted", "=", "[", "checkpoint", "[", "1", "]", "for", "checkpoint", "in", "checkpoints_sorted", "]", "\n", "number_of_checkpoints_to_delete", "=", "max", "(", "0", ",", "len", "(", "checkpoints_sorted", ")", "-", "args", ".", "save_total_limit", ")", "\n", "checkpoints_to_be_deleted", "=", "checkpoints_sorted", "[", ":", "number_of_checkpoints_to_delete", "]", "\n", "for", "checkpoint", "in", "checkpoints_to_be_deleted", ":", "\n", "        ", "logger", ".", "info", "(", "\"Deleting older checkpoint [{}] due to args.save_total_limit\"", ".", "format", "(", "checkpoint", ")", ")", "\n", "shutil", ".", "rmtree", "(", "checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_lm.mask_tokens": [[138, 161], ["inputs.clone", "torch.full", "torch.full.masked_fill_", "torch.bernoulli().bool", "tokenizer.convert_tokens_to_ids", "torch.randint", "tokenizer.get_special_tokens_mask", "torch.tensor", "torch.bernoulli().bool", "len", "inputs.clone.tolist", "torch.bernoulli", "torch.bernoulli().bool", "torch.bernoulli", "torch.full", "torch.bernoulli", "torch.full"], "function", ["None"], ["", "", "def", "mask_tokens", "(", "inputs", ":", "torch", ".", "Tensor", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "args", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\" Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. \"\"\"", "\n", "labels", "=", "inputs", ".", "clone", "(", ")", "\n", "# We sample a few tokens in each sequence for masked-LM training (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)", "\n", "probability_matrix", "=", "torch", ".", "full", "(", "labels", ".", "shape", ",", "args", ".", "mlm_probability", ")", "\n", "special_tokens_mask", "=", "[", "\n", "tokenizer", ".", "get_special_tokens_mask", "(", "val", ",", "already_has_special_tokens", "=", "True", ")", "for", "val", "in", "labels", ".", "tolist", "(", ")", "\n", "]", "\n", "probability_matrix", ".", "masked_fill_", "(", "torch", ".", "tensor", "(", "special_tokens_mask", ",", "dtype", "=", "torch", ".", "bool", ")", ",", "value", "=", "0.0", ")", "\n", "masked_indices", "=", "torch", ".", "bernoulli", "(", "probability_matrix", ")", ".", "bool", "(", ")", "\n", "labels", "[", "~", "masked_indices", "]", "=", "-", "100", "# We only compute loss on masked tokens", "\n", "\n", "# 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])", "\n", "indices_replaced", "=", "torch", ".", "bernoulli", "(", "torch", ".", "full", "(", "labels", ".", "shape", ",", "0.8", ")", ")", ".", "bool", "(", ")", "&", "masked_indices", "\n", "inputs", "[", "indices_replaced", "]", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "mask_token", ")", "\n", "\n", "# 10% of the time, we replace masked input tokens with random word", "\n", "indices_random", "=", "torch", ".", "bernoulli", "(", "torch", ".", "full", "(", "labels", ".", "shape", ",", "0.5", ")", ")", ".", "bool", "(", ")", "&", "masked_indices", "&", "~", "indices_replaced", "\n", "random_words", "=", "torch", ".", "randint", "(", "len", "(", "tokenizer", ")", ",", "labels", ".", "shape", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "inputs", "[", "indices_random", "]", "=", "random_words", "[", "indices_random", "]", "\n", "\n", "# The rest of the time (10% of the time) we keep the masked input tokens unchanged", "\n", "return", "inputs", ",", "labels", "\n", "#", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_lm.train": [[183, 367], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "os.path.exists", "model_to_resize.resize_token_embeddings", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_lm.set_seed", "SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "logger.info", "logger.info", "logger.info", "logger.info", "hasattr", "len", "int", "enumerate", "SummaryWriter.close", "map", "torch.nn.parallel.DistributedDataParallel.train", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "tqdm.trange.close", "len", "ImportError", "torch.distributed.get_world_size", "loss.mean.mean", "loss.mean.backward", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "i.to", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "run_lm.evaluate", "results[].detach().cpu().numpy", "os.path.join", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "torch.save", "torch.save", "logger.info", "logger.info", "run_lm._rotate_checkpoints", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "run_lm.evaluate", "evaluate.items", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "transformers.AdamW.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "any", "SummaryWriter.add_scalar", "transformers.get_linear_schedule_with_warmup.get_lr", "results[].detach().cpu", "str", "results[].detach"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.zero_grad", "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_lm.set_seed", "home.repos.pwc.inspect_result.bigheiniu_FactGen.NeuralGenerationDetection.RoBERTaDetect.train", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor.step", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor.step", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.zero_grad", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_lm.evaluate", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_lm._rotate_checkpoints", "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_lm.evaluate", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.state_dict", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.state_dict"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "and", "p", ".", "requires_grad", "]", ",", "\n", "# \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "and", "p", ".", "requires_grad", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "# {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "# Check if continuing training from a checkpoint", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "model_name_or_path", ")", ":", "\n", "# set global_step to gobal_step of last saved checkpoint from model path", "\n", "# global_step = int(args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0])", "\n", "# epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)", "\n", "# steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)", "\n", "\n", "        ", "logger", ".", "info", "(", "\"  Continuing training from checkpoint, will skip to saved global_step\"", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from epoch %d\"", ",", "epochs_trained", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from global step %d\"", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"  Will skip the first %d steps in the first epoch\"", ",", "steps_trained_in_current_epoch", ")", "\n", "\n", "", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "\n", "model_to_resize", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_resize", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "\n", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproducibility", "\n", "for", "_", "in", "train_iterator", ":", "\n", "\n", "# epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])", "\n", "        ", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "\n", "# Skip past any already trained steps if resuming training", "\n", "            ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "# inputs, positions, labels, _ = map(lambda i: i.to(args.device), batch)", "\n", "", "inputs", ",", "labels", "=", "map", "(", "lambda", "i", ":", "i", ".", "to", "(", "args", ".", "device", ")", ",", "batch", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "\n", "# outputs = model(inputs, labels=labels, position_ids=positions)", "\n", "outputs", "=", "model", "(", "inputs", ",", "labels", "=", "labels", ")", "\n", "\n", "\n", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "                    ", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", "\n", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "\"lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss\"", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "                    ", "checkpoint_prefix", "=", "\"checkpoint\"", "\n", "# Save model checkpoint", "\n", "\n", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "\n", "ppl", "=", "results", "[", "'perplexity'", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "ppl", "=", "ppl", "if", "ppl", "<", "9999", "else", "9999", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-{}\"", ".", "format", "(", "checkpoint_prefix", ",", "str", "(", "ppl", ")", ")", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", ")", "\n", "\n", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "\n", "                ", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_lm.evaluate": [[369, 420], ["run_lm.load_dataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "torch.exp", "os.path.join", "os.makedirs", "max", "torch.nn.DataParallel", "len", "map", "torch.tensor", "open", "logger.info", "sorted", "os.path.exists", "torch.no_grad", "torch.nn.DataParallel.", "lm_loss.mean().item", "result.keys", "logger.info", "writer.write", "i.to", "str", "lm_loss.mean", "str"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.load_dataset", "home.repos.pwc.inspect_result.bigheiniu_FactGen.NeuralGenerationDetection.RoBERTaDetect.eval", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "eval_dataset", "=", "load_dataset", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "True", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "i", "=", "0", "\n", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "\n", "\n", "# inputs, positions, labels, _ = map(lambda i: i.to(args.device), batch)", "\n", "        ", "inputs", ",", "labels", "=", "map", "(", "lambda", "i", ":", "i", ".", "to", "(", "args", ".", "device", ")", ",", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# outputs = model(inputs, labels=labels, position_ids=positions)", "\n", "            ", "outputs", "=", "model", "(", "inputs", ",", "labels", "=", "labels", ")", "\n", "\n", "lm_loss", "=", "outputs", "[", "0", "]", "\n", "eval_loss", "+=", "lm_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "\n", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "exp", "(", "torch", ".", "tensor", "(", "eval_loss", ")", ")", "\n", "result", "=", "{", "\"perplexity\"", ":", "perplexity", ",", "\"acc\"", ":", "0", "}", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "prefix", ",", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_lm.main": [[422, 734], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_lm.set_seed", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "min", "model_class.from_pretrained", "tokenizer_class.from_pretrained.add_special_tokens", "tokenizer_class.from_pretrained.add_tokens", "model_class.from_pretrained.resize_token_embeddings", "setattr", "model_class.from_pretrained.to", "logger.info", "ValueError", "ValueError", "os.path.exists", "os.listdir", "ValueError", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "len", "torch.distributed.barrier", "run_lm.load_dataset", "run_lm.train", "logger.info", "logger.info", "model_to_save.save_pretrained", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "model_class.from_pretrained", "tokenizer_class.from_pretrained", "setattr", "model_class.from_pretrained.to", "logger.info", "bool", "torch.distributed.barrier", "torch.distributed.barrier", "os.makedirs", "hasattr", "os.path.join", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "setattr", "model_class.from_pretrained.to", "run_lm.evaluate", "dict", "results.update", "torch.distributed.get_rank", "os.path.exists", "torch.cuda.is_available", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "checkpoint.find", "checkpoint.split", "sorted", "dict.items", "glob.glob"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_lm.set_seed", "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.load_dataset", "home.repos.pwc.inspect_result.bigheiniu_FactGen.NeuralGenerationDetection.RoBERTaDetect.train", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.run_lm.evaluate", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.update"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"The input training data file (a text file).\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_data_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "\"bert\"", ",", "type", "=", "str", ",", "help", "=", "\"The model architecture to be fine-tuned.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "\"bert-base-cased\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mlm\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Train with masked-language modeling loss instead of language modeling.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mlm_probability\"", ",", "type", "=", "float", ",", "default", "=", "0.15", ",", "help", "=", "\"Ratio of tokens to mask for masked language modeling loss\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained config name or path if not the same as model_name_or_path\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional directory to store the pre-trained models downloaded from s3 (instread of the default one)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--block_size\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Optional input sequence length after tokenization.\"", "\n", "\"The training dataset will be truncated in block of this size for training.\"", "\n", "\"Default to the model max input length for single sentence inputs (take into account special tokens).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Run evaluation during training at each logging step.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_total_limit\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "5", ",", "\n", "help", "=", "\"Limit the total amount of checkpoints, delete the older checkpoints in the output_dir, does not delete by default\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_all_checkpoints\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name_or_path ending and ending with step number\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the content of the output directory\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_ip\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_port\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_length\"", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "\"Max length of the input sequence.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask_task\"", ",", "action", "=", "\"store_true\"", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"roberta\"", ",", "\"distilbert\"", ",", "\"camembert\"", "]", "and", "not", "args", ".", "mlm", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"BERT and RoBERTa do not have LM heads but masked LM heads. They must be run using the --mlm \"", "\n", "\"flag (masked language modeling).\"", "\n", ")", "\n", "", "if", "args", ".", "eval_data_file", "is", "None", "and", "args", ".", "do_eval", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Cannot do evaluation without an evaluation data file. Either supply a file to --eval_data_file \"", "\n", "\"or remove the --do_eval argument.\"", "\n", ")", "\n", "\n", "", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", "\n", ")", "\n", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", "add_prefix_space", "=", "True", ",", "\n", "max_length", "=", "args", ".", "max_length", ",", "\n", ")", "\n", "# add the pad tokens", "\n", "\n", "if", "args", ".", "block_size", "<=", "0", ":", "\n", "        ", "args", ".", "block_size", "=", "(", "\n", "tokenizer", ".", "max_len_single_sentence", "\n", ")", "# Our input block size will be the max possible for the model", "\n", "", "args", ".", "block_size", "=", "min", "(", "args", ".", "block_size", ",", "tokenizer", ".", "max_len_single_sentence", ")", "\n", "model", ",", "load_info", "=", "model_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", "output_loading_info", "=", "True", "\n", ")", "\n", "tokenizer", ".", "add_special_tokens", "(", "{", "\"pad_token\"", ":", "\"<pad>\"", "}", ")", "\n", "tokenizer", ".", "add_tokens", "(", "[", "\"<c-begin>\"", ",", "'<mask>'", "]", ")", "\n", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "setattr", "(", "model", ",", "\"pad_index\"", ",", "tokenizer", ".", "pad_token_id", ")", "\n", "# for n, p in model.named_parameters():", "\n", "#     if n in load_info['missing_keys']:", "\n", "#         p.requires_grad = True", "\n", "#     else:", "\n", "#         p.requires_grad = False", "\n", "# for n, p in model.named_parameters():", "\n", "#     if \"embedding\" in n or 'weight_layer' in n or 'bias_layer' in n or 'hidden_dense' in n:", "\n", "#         p.requires_grad = False", "\n", "#     else:", "\n", "#         p.requires_grad = True", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# End of barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "", "train_dataset", "=", "load_dataset", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ")", "\n", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "setattr", "(", "model", ",", "\"pad_index\"", ",", "tokenizer", ".", "pad_token_id", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# AutomaticEvaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "\n", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", "\n", ")", "\n", "logging", ".", "getLogger", "(", "\"transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "prefix", "=", "checkpoint", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "if", "checkpoint", ".", "find", "(", "\"checkpoint\"", ")", "!=", "-", "1", "else", "\"\"", "\n", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "setattr", "(", "model", ",", "\"pad_index\"", ",", "tokenizer", ".", "pad_token_id", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "prefix", ")", "\n", "result", "=", "dict", "(", "(", "k", "+", "\"_{}\"", ".", "format", "(", "global_step", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.GPT2datastaset.GPT2Dataset.__init__": [[8, 43], ["torch.utils.data.Dataset.__init__", "file_path.format().replace", "os.path.exists", "pandas.read_csv", "src_list.values.tolist.values.tolist.values.tolist", "print", "file_path.format", "open", "pickle.load", "pickle.load.items", "GPT2datastaset.GPT2Dataset.mask_handle", "GPT2datastaset.GPT2Dataset.examples.append", "GPT2datastaset.GPT2Dataset.labels.append", "open", "pickle.dump", "setattr", "len"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.GPT2datastaset.GPT2Dataset.mask_handle"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "tokenizer", ",", "block_size", ",", "file_path", ",", "mask_task", "=", "True", ")", ":", "\n", "        ", "super", "(", "GPT2Dataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mask_task", "=", "mask_task", "\n", "self", ".", "mask_token", "=", "\"<mask>\"", "\n", "self", ".", "pad_token", "=", "\"<pad>\"", "\n", "self", ".", "mask_pro", "=", "0.8", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_length", "=", "block_size", "\n", "cached_features_file", "=", "file_path", ".", "format", "(", "\"all\"", ")", ".", "replace", "(", "\"txt\"", ",", "'pickle'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "# logger.info(\"Loading features from cached file %s\", cached_features_file)", "\n", "            ", "with", "open", "(", "cached_features_file", "+", "\"_mask\"", "if", "mask_task", "else", "\"\"", ",", "\"rb\"", ")", "as", "handle", ":", "\n", "                ", "result", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "for", "key", ",", "value", "in", "result", ".", "items", "(", ")", ":", "\n", "                    ", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "", "", "", "else", ":", "\n", "# logger.info(\"Creating features from dataset file at %s\", cached_features_file)", "\n", "            ", "src_list", "=", "pd", ".", "read_csv", "(", "file_path", ",", "sep", "=", "\"\\t\"", ")", "\n", "src_list", "=", "src_list", ".", "values", ".", "tolist", "(", ")", "\n", "\n", "\n", "self", ".", "examples", "=", "[", "]", "\n", "self", ".", "labels", "=", "[", "]", "\n", "for", "src", "in", "src_list", ":", "\n", "\n", "                ", "encode_all", ",", "labels", "=", "self", ".", "mask_handle", "(", "src", ")", "\n", "self", ".", "examples", ".", "append", "(", "encode_all", ")", "\n", "self", ".", "labels", ".", "append", "(", "labels", ")", "\n", "\n", "# logger.info(\"Saving features into cached file %s\", cached_features_file)", "\n", "", "print", "(", "\"there are {} samples in {}\"", ".", "format", "(", "len", "(", "self", ".", "examples", ")", ",", "file_path", ")", ")", "\n", "with", "open", "(", "cached_features_file", "+", "\"_mask\"", "if", "mask_task", "else", "\"\"", ",", "\"wb\"", ")", "as", "handle", ":", "\n", "                ", "result", "=", "{", "\"examples\"", ":", "self", ".", "examples", ",", "\n", "\"labels\"", ":", "self", ".", "labels", "}", "\n", "pickle", ".", "dump", "(", "result", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.GPT2datastaset.GPT2Dataset.mask_handle": [[45, 89], ["prompt.replace().replace.replace().replace.replace().replace", "fact.replace().replace.replace().replace.replace().replace", "torch.ones", "inputs.tolist.tolist.clone", "torch.full", "torch.bernoulli().bool", "inputs.tolist.tolist.tolist", "zip", "GPT2datastaset.GPT2Dataset.tokenizer.encode", "len", "GPT2datastaset.GPT2Dataset.tokenizer.encode", "len", "torch.bernoulli().bool", "i.split", "zip", "fact_masked_list.append", "labels.append", "GPT2datastaset.GPT2Dataset.tokenizer.encode", "prompt.replace().replace.replace().replace.replace", "fact.replace().replace.replace().replace.replace", "fact.replace().replace.replace().replace.split", "torch.bernoulli", "fact.replace().replace.replace().replace.split", "fact_mask.append", "padfact.append", "torch.bernoulli", "torch.full", "len", "GPT2datastaset.GPT2Dataset.tokenizer.encode", "len", "GPT2datastaset.GPT2Dataset.tokenizer.encode"], "methods", ["None"], ["", "", "", "def", "mask_handle", "(", "self", ",", "src_line", ")", ":", "\n", "\n", "        ", "_", ",", "prompt", ",", "_", ",", "fact", "=", "src_line", "\n", "prompt", "=", "prompt", ".", "replace", "(", "\"<t>\"", ",", "\"\"", ")", ".", "replace", "(", "\"<\\t>\"", ",", "\"\"", ")", "\n", "fact", "=", "fact", ".", "replace", "(", "\"<t>\"", ",", "\"\"", ")", ".", "replace", "(", "\"<\\t>\"", ",", "\"\"", ")", "\n", "# mask can be N * 3", "\n", "# BERT Mask: Random Mask Part of elements in the sequence", "\n", "\n", "inputs", "=", "torch", ".", "ones", "(", "len", "(", "fact", ".", "split", "(", "\"|\"", ")", ")", ",", "3", ")", "\n", "padded", "=", "inputs", ".", "clone", "(", ")", "\n", "# We sample a few tokens in each sequence for masked-LM training (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)", "\n", "probability_matrix", "=", "torch", ".", "full", "(", "padded", ".", "shape", ",", "self", ".", "mask_pro", ")", "\n", "masked_indices", "=", "torch", ".", "bernoulli", "(", "probability_matrix", ")", ".", "bool", "(", ")", "\n", "padded", "[", "~", "masked_indices", "]", "=", "-", "1", "# We only compute loss on masked tokens", "\n", "\n", "# 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])", "\n", "indices_replaced", "=", "torch", ".", "bernoulli", "(", "torch", ".", "full", "(", "padded", ".", "shape", ",", "0.8", ")", ")", ".", "bool", "(", ")", "&", "masked_indices", "\n", "inputs", "[", "indices_replaced", "]", "=", "0", "\n", "inputs", "=", "inputs", ".", "tolist", "(", ")", "\n", "# inputs is the mask and labels is the mask tokens and the pad", "\n", "fact_list", "=", "[", "i", ".", "split", "(", "\",\"", ")", "for", "i", "in", "fact", ".", "split", "(", "\"|\"", ")", "]", "\n", "fact_masked_list", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "fact_entry", ",", "mask", "in", "zip", "(", "fact_list", ",", "inputs", ")", ":", "\n", "            ", "fact_mask", "=", "[", "]", "\n", "padfact", "=", "[", "]", "\n", "for", "entry", ",", "index", "in", "zip", "(", "fact_entry", ",", "mask", ")", ":", "\n", "                ", "label_entry", "=", "\" \"", ".", "join", "(", "len", "(", "self", ".", "tokenizer", ".", "encode", "(", "entry", ")", ")", "*", "[", "self", ".", "pad_token", "]", ")", "\n", "if", "index", "==", "0.", ":", "\n", "                    ", "label_entry", "=", "entry", "\n", "entry", "=", "\" \"", ".", "join", "(", "len", "(", "self", ".", "tokenizer", ".", "encode", "(", "entry", ")", ")", "*", "[", "self", ".", "mask_token", "]", ")", "\n", "\n", "", "fact_mask", ".", "append", "(", "entry", ")", "\n", "padfact", ".", "append", "(", "label_entry", ")", "\n", "", "fact_masked_list", ".", "append", "(", "fact_mask", ")", "\n", "labels", ".", "append", "(", "\" \"", ".", "join", "(", "padfact", ")", ")", "\n", "\n", "\n", "", "input_encode", "=", "self", ".", "tokenizer", ".", "encode", "(", "prompt", "+", "\" <c-begin> \"", "+", "\" \"", ".", "join", "(", "[", "\" \"", ".", "join", "(", "i", ")", "for", "i", "in", "fact_masked_list", "]", ")", ",", "pad_to_max_length", "=", "True", ",", "max_length", "=", "self", ".", "max_length", ")", "\n", "labels", "=", "\" \"", ".", "join", "(", "labels", ")", "\n", "prompt_encode_len", "=", "len", "(", "self", ".", "tokenizer", ".", "encode", "(", "prompt", "+", "\" <c-begin> \"", ")", ")", "\n", "labels", "=", "\" \"", ".", "join", "(", "prompt_encode_len", "*", "[", "self", ".", "pad_token", "]", ")", "+", "\" \"", "+", "labels", "\n", "label_encode", "=", "self", ".", "tokenizer", ".", "encode", "(", "labels", ",", "max_length", "=", "self", ".", "max_length", ",", "pad_to_max_length", "=", "True", ")", "\n", "return", "input_encode", ",", "label_encode", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.GPT2datastaset.GPT2Dataset.__len__": [[93, 95], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.GPT2datastaset.GPT2Dataset.__getitem__": [[96, 100], ["torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return_tuple", "=", "(", "\n", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "item", "]", ")", ",", "torch", ".", "tensor", "(", "self", ".", "labels", "[", "item", "]", ")", ")", "\n", "return", "return_tuple", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.decode_text.decode_text": [[9, 43], ["print", "open().readlines", "open", "open", "pickle.load", "line.strip", "text.replace.replace", "bytearray().decode", "decoded.replace.replace", "decoded.replace.replace", "print", "fw.write", "ValueError", "open", "text.replace.split", "bytearray", "len", "decoded.replace.split"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write"], ["def", "decode_text", "(", "args", ")", ":", "\n", "\n", "\n", "    ", "if", "args", ".", "dst", "is", "None", ":", "\n", "        ", "if", "args", ".", "src", "[", "-", "4", ":", "]", "==", "'.bpe'", ":", "\n", "            ", "args", ".", "dst", "=", "args", ".", "src", "[", ":", "-", "4", "]", "\n", "", "elif", "args", ".", "src", "[", "-", "8", ":", "]", "==", "'.encoded'", ":", "\n", "            ", "args", ".", "dst", "=", "args", ".", "src", "[", ":", "-", "8", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'dst needed or src that ends in .bpe or .encoded'", ")", "\n", "\n", "", "", "i", "=", "0", "\n", "if", "\"pickle\"", "in", "args", ".", "src", ":", "\n", "        ", "with", "open", "(", "args", ".", "src", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "data", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "data", "=", "open", "(", "args", ".", "src", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "# print(args.dst)", "\n", "# exit()", "\n", "", "with", "open", "(", "args", ".", "dst", ",", "'w'", ")", "as", "fw", ":", "\n", "        ", "for", "line", "in", "data", ":", "\n", "            ", "i", "+=", "1", "\n", "# line = line[0]", "\n", "text", "=", "line", ".", "strip", "(", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\\x00\"", ",", "\"\"", ")", "\n", "text", "=", "''", ".", "join", "(", "text", ".", "split", "(", "' '", ")", ")", "\n", "\n", "decoded", "=", "bytearray", "(", "[", "enc", ".", "byte_decoder", "[", "c", "]", "for", "c", "in", "text", "]", ")", ".", "decode", "(", "'utf-8'", ",", "errors", "=", "enc", ".", "errors", ")", "\n", "decoded", "=", "decoded", ".", "replace", "(", "'\\n'", ",", "''", ")", "# We need one example per line", "\n", "decoded", "=", "decoded", ".", "replace", "(", "'\\r'", ",", "''", ")", "\n", "decoded", "+=", "'\\n'", "\n", "print", "(", "\"The length is {}\"", ".", "format", "(", "len", "(", "decoded", ".", "split", "(", ")", ")", ")", ")", "\n", "fw", ".", "write", "(", "decoded", ")", "\n", "", "", "print", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.encode_text.encode_file": [[7, 39], ["regex.compile", "transformers.GPT2Tokenizer.from_pretrained", "os.path.join", "print", "open", "open", "line.strip", "regex.findall", "fw.write", "txt.replace.replace", "bpe_tokens.extend", "GPT2Tokenizer.from_pretrained.bpe().split", "token.encode", "GPT2Tokenizer.from_pretrained.bpe"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write"], ["def", "encode_file", "(", "directory", ")", ":", "\n", "    ", "pat", "=", "re", ".", "compile", "(", "r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"", ")", "\n", "enc", "=", "GPT2Tokenizer", ".", "from_pretrained", "(", "'gpt2'", ")", "\n", "with_tldr", "=", "False", "\n", "replace_newline", "=", "False", "\n", "tok_trunc", "=", "1000000", "\n", "\n", "\n", "for", "type", "in", "[", "\"train\"", ",", "'val'", "]", ":", "\n", "        ", "for", "t", "in", "[", "\"src\"", ",", "'tgt'", "]", ":", "\n", "# for t in ['src']:", "\n", "            ", "filename", "=", "osjoin", "(", "directory", ",", "type", "+", "\".txt.\"", "+", "t", ")", "\n", "print", "(", "filename", ")", "\n", "write_name", "=", "filename", "+", "'.bpe'", "\n", "if", "with_tldr", "and", "'src'", "in", "filename", ":", "\n", "                ", "write_name", "+=", "'.tldr'", "\n", "\n", "", "with", "open", "(", "filename", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "with", "open", "(", "write_name", ",", "'w'", ")", "as", "fw", ":", "\n", "                    ", "for", "line", "in", "f", ":", "\n", "                        ", "txt", "=", "line", ".", "strip", "(", ")", "\n", "if", "with_tldr", "and", "'src'", "in", "filename", ":", "\n", "                            ", "txt", "+=", "'\\nTL;DR:'", "\n", "\n", "", "if", "replace_newline", ":", "\n", "                            ", "txt", "=", "txt", ".", "replace", "(", "'<newline>'", ",", "'\\n'", ")", "\n", "\n", "", "bpe_tokens", "=", "[", "]", "\n", "for", "token", "in", "re", ".", "findall", "(", "pat", ",", "txt", ")", ":", "# line.strip() to make sure newline is not encoded", "\n", "                            ", "token", "=", "''", ".", "join", "(", "enc", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "token", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "bpe_tokens", ".", "extend", "(", "enc", ".", "bpe", "(", "token", ")", ".", "split", "(", "' '", ")", ")", "\n", "", "fw", ".", "write", "(", "' '", ".", "join", "(", "bpe_tokens", "[", ":", "tok_trunc", "]", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.encode_text.decode_file": [[40, 48], ["transformers.GPT2Tokenizer.from_pretrained", "open", "f1.readlines", "GPT2Tokenizer.from_pretrained.convert_tokens_to_string", "print", "exit", "line.split"], "function", ["None"], ["", "", "", "", "", "", "def", "decode_file", "(", "file_name", ")", ":", "\n", "    ", "with", "open", "(", "file_name", ",", "'r'", ")", "as", "f1", ":", "\n", "        ", "data", "=", "f1", ".", "readlines", "(", ")", "\n", "", "enc", "=", "GPT2Tokenizer", ".", "from_pretrained", "(", "'gpt2'", ")", "\n", "for", "line", "in", "data", ":", "\n", "        ", "th", "=", "enc", ".", "convert_tokens_to_string", "(", "line", ".", "split", "(", ")", ")", "\n", "print", "(", "th", ")", "\n", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.gpt2.data_split.src_tgt_split": [[4, 18], ["pandas.read_csv", "data[].agg", "data[].values.tolist", "data[].values.tolist", "file.replace.replace", "open", "open", "f1.write", "f1.write", "line.replace", "line.replace"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write"], ["def", "src_tgt_split", "(", "file", ")", ":", "\n", "    ", "data", "=", "pd", ".", "read_csv", "(", "file", ",", "sep", "=", "\"\\t\"", "if", "\"tsv\"", "in", "file", "else", "\",\"", ")", "\n", "data", "[", "'src'", "]", "=", "data", "[", "[", "'fact_col'", ",", "'title'", "]", "]", ".", "agg", "(", "\" \"", ".", "join", ",", "axis", "=", "1", ")", "\n", "data", "[", "'tgt'", "]", "=", "data", "[", "'content'", "]", "\n", "src", "=", "data", "[", "'src'", "]", ".", "values", ".", "tolist", "(", ")", "\n", "tgt", "=", "data", "[", "'tgt'", "]", ".", "values", ".", "tolist", "(", ")", "\n", "file", "=", "file", ".", "replace", "(", "\"_fact.tsv\"", ",", "\".txt\"", ")", "\n", "with", "open", "(", "file", "+", "\".src\"", ",", "'w'", ")", "as", "f1", ":", "\n", "        ", "for", "line", "in", "src", ":", "\n", "# line = line.replace(\"|\", \" \")", "\n", "            ", "f1", ".", "write", "(", "line", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "+", "\"\\n\"", ")", "\n", "", "", "with", "open", "(", "file", "+", "\".tgt\"", ",", "'w'", ")", "as", "f1", ":", "\n", "        ", "for", "line", "in", "tgt", ":", "\n", "            ", "f1", ".", "write", "(", "line", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.AutomaticEvaluation.consistence_eval.fnc": [[21, 47], ["open", "csv.reader", "enumerate", "open", "csv.reader", "enumerate", "tqdm.tqdm", "tqdm.tqdm", "list", "int", "list", "int", "line[].strip", "line[].strip", "line[].strip", "h.append", "l.append", "b.append"], "function", ["None"], ["def", "fnc", "(", "path_headlines", ",", "path_bodies", ")", ":", "\n", "\n", "    ", "map", "=", "{", "'agree'", ":", "0", ",", "'disagree'", ":", "1", ",", "'discuss'", ":", "2", ",", "'unrelated'", ":", "3", "}", "\n", "\n", "with", "open", "(", "path_bodies", ",", "encoding", "=", "'utf_8'", ")", "as", "fb", ":", "# Body ID,articleBody", "\n", "        ", "body_dict", "=", "{", "}", "\n", "lines_b", "=", "csv", ".", "reader", "(", "fb", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "tqdm", "(", "list", "(", "lines_b", ")", ",", "ncols", "=", "80", ",", "leave", "=", "False", ")", ")", ":", "\n", "            ", "if", "i", ">", "0", ":", "\n", "                ", "body_id", "=", "int", "(", "line", "[", "0", "]", ".", "strip", "(", ")", ")", "\n", "body_dict", "[", "body_id", "]", "=", "line", "[", "1", "]", "\n", "\n", "", "", "", "with", "open", "(", "path_headlines", ",", "encoding", "=", "'utf_8'", ")", "as", "fh", ":", "# Headline,Body ID,Stance", "\n", "        ", "lines_h", "=", "csv", ".", "reader", "(", "fh", ")", "\n", "h", "=", "[", "]", "\n", "b", "=", "[", "]", "\n", "l", "=", "[", "]", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "tqdm", "(", "list", "(", "lines_h", ")", ",", "ncols", "=", "80", ",", "leave", "=", "False", ")", ")", ":", "\n", "            ", "if", "i", ">", "0", ":", "\n", "                ", "body_id", "=", "int", "(", "line", "[", "1", "]", ".", "strip", "(", ")", ")", "\n", "labels", "=", "line", "[", "2", "]", ".", "strip", "(", ")", "\n", "if", "labels", "in", "map", "and", "body_id", "in", "body_dict", ":", "\n", "                    ", "h", ".", "append", "(", "line", "[", "0", "]", ")", "\n", "l", ".", "append", "(", "map", "[", "line", "[", "2", "]", "]", ")", "\n", "b", ".", "append", "(", "body_dict", "[", "body_id", "]", ")", "\n", "", "", "", "", "return", "h", ",", "b", ",", "l", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.AutomaticEvaluation.consistence_eval.train_stance_clf": [[49, 74], ["consistence_eval.fnc", "list", "pandas.DataFrame", "sklearn.model_selection.train_test_split", "simpletransformers.classification.ClassificationModel", "simpletransformers.classification.ClassificationModel.train_model", "os.path.join", "os.path.join", "zip"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.AutomaticEvaluation.consistence_eval.fnc"], ["", "def", "train_stance_clf", "(", "data_dir", ",", "output_dir", ",", "**", "kwargs", ")", ":", "\n", "    ", "headlines", ",", "bodies", ",", "labels", "=", "fnc", "(", "\n", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'combined_stances_train.csv'", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'combined_bodies_train.csv'", ")", "\n", ")", "\n", "\n", "list_of_tuples", "=", "list", "(", "zip", "(", "headlines", ",", "bodies", ",", "labels", ")", ")", "\n", "df", "=", "pd", ".", "DataFrame", "(", "list_of_tuples", ",", "columns", "=", "[", "'text_a'", ",", "'text_b'", ",", "'label'", "]", ")", "\n", "train_df", ",", "val_df", "=", "train_test_split", "(", "df", ",", "random_state", "=", "123", ")", "\n", "train_args", "=", "{", "\n", "'learning_rate'", ":", "3e-5", ",", "\n", "'num_train_epochs'", ":", "5", ",", "\n", "'reprocess_input_data'", ":", "True", ",", "\n", "'overwrite_output_dir'", ":", "False", ",", "\n", "'process_count'", ":", "10", ",", "\n", "'train_batch_size'", ":", "4", ",", "\n", "'eval_batch_size'", ":", "20", ",", "\n", "'max_seq_length'", ":", "300", ",", "\n", "\"fp16\"", ":", "False", ",", "\n", "'output_dir'", ":", "output_dir", "\n", "}", "\n", "\n", "model", "=", "ClassificationModel", "(", "'roberta'", ",", "\"roberta-base\"", ",", "num_labels", "=", "4", ",", "use_cuda", "=", "True", ",", "cuda_device", "=", "0", ",", "args", "=", "train_args", ")", "\n", "\n", "model", ".", "train_model", "(", "train_df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.AutomaticEvaluation.consistence_eval.eval_stance_clf": [[76, 102], ["open().readlines", "open().readlines", "simpletransformers.classification.ClassificationModel", "simpletransformers.classification.ClassificationModel.predict", "collections.Counter", "sorted", "print", "i.strip", "i.strip", "sorted.items", "open", "open", "zip"], "function", ["None"], ["", "def", "eval_stance_clf", "(", "model_path", ",", "src_path", ",", "gen_path", ",", "**", "kwargs", ")", ":", "\n", "    ", "src", "=", "open", "(", "src_path", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "gen", "=", "open", "(", "gen_path", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "gen", "=", "[", "i", ".", "strip", "(", ")", "for", "i", "in", "gen", "]", "\n", "src", "=", "[", "i", ".", "strip", "(", ")", "for", "i", "in", "src", "]", "\n", "\n", "\n", "train_args", "=", "{", "\n", "'learning_rate'", ":", "3e-5", ",", "\n", "'num_train_epochs'", ":", "5", ",", "\n", "'reprocess_input_data'", ":", "True", ",", "\n", "'overwrite_output_dir'", ":", "False", ",", "\n", "'process_count'", ":", "10", ",", "\n", "'train_batch_size'", ":", "4", ",", "\n", "'eval_batch_size'", ":", "400", ",", "\n", "'max_seq_length'", ":", "300", ",", "\n", "\"fp16\"", ":", "False", "\n", "}", "\n", "\n", "model", "=", "ClassificationModel", "(", "'roberta'", ",", "model_path", ",", "num_labels", "=", "4", ",", "use_cuda", "=", "True", ",", "cuda_device", "=", "0", ",", "args", "=", "train_args", ")", "\n", "\n", "input", "=", "[", "[", "i", ",", "j", "]", "for", "i", ",", "j", "in", "zip", "(", "src", ",", "gen", ")", "]", "\n", "predictions", ",", "raw_outputs", "=", "model", ".", "predict", "(", "input", ")", "\n", "th", "=", "Counter", "(", "predictions", ")", "\n", "th", "=", "sorted", "(", "th", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "print", "(", "th", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.AutomaticEvaluation.richness_eval.multiprocess_function": [[9, 21], ["range", "range", "multiprocessing.Process", "jobs.append", "multiprocessing.Process.start", "jobs[].join"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.start"], ["def", "multiprocess_function", "(", "num_process", ",", "function_ref", ",", "args", ")", ":", "\n", "    ", "jobs", "=", "[", "]", "\n", "\n", "for", "idx", "in", "range", "(", "num_process", ")", ":", "\n", "\n", "        ", "process", "=", "Process", "(", "target", "=", "function_ref", ",", "args", "=", "(", "idx", ",", ")", "+", "args", ")", "\n", "process", ".", "daemon", "=", "True", "\n", "jobs", ".", "append", "(", "process", ")", "\n", "process", ".", "start", "(", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "num_process", ")", ":", "\n", "        ", "jobs", "[", "i", "]", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.AutomaticEvaluation.richness_eval.chunkify": [[22, 24], ["range"], "function", ["None"], ["", "", "def", "chunkify", "(", "lst", ",", "n", ")", ":", "\n", "    ", "return", "[", "lst", "[", "i", ":", ":", "n", "]", "for", "i", "in", "range", "(", "n", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.AutomaticEvaluation.richness_eval.evaluate_entity": [[25, 33], ["spacy.load", "print", "spacy.load.", "entity_avg.append", "numpy.sum", "len", "len", "set", "i.text.lower"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load"], ["", "def", "evaluate_entity", "(", "idx", ",", "text_chunk", ")", ":", "\n", "    ", "nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_sm\"", ")", "\n", "entity_avg", "=", "[", "]", "\n", "text_chunk_idx", "=", "text_chunk", "[", "idx", "]", "\n", "for", "line", "in", "text_chunk_idx", ":", "\n", "        ", "doc", "=", "nlp", "(", "line", ")", "\n", "entity_avg", ".", "append", "(", "len", "(", "set", "(", "i", ".", "text", ".", "lower", "(", ")", "for", "i", "in", "doc", ".", "ents", ")", ")", ")", "\n", "", "print", "(", "np", ".", "sum", "(", "entity_avg", ")", ",", "\"\\t\"", ",", "len", "(", "entity_avg", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.AutomaticEvaluation.BLEU_eval.get_bleu": [[6, 11], ["nltk.translate.bleu_score.corpus_bleu", "print", "i.split", "i.split"], "function", ["None"], ["def", "get_bleu", "(", "candidate", ",", "ref", ")", ":", "\n", "    ", "candidate", "=", "[", "i", ".", "split", "(", ")", "for", "i", "in", "candidate", "]", "\n", "ref", "=", "[", "[", "i", ".", "split", "(", ")", "]", "for", "i", "in", "ref", "]", "\n", "score", "=", "corpus_bleu", "(", "ref", ",", "candidate", ")", "\n", "print", "(", "\"BLEU score is {}\"", ".", "format", "(", "score", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.translate.constraint_iter_func": [[17, 28], ["json.loads", "all_tags.append", "len"], "function", ["None"], ["def", "constraint_iter_func", "(", "f_iter", ")", ":", "\n", "    ", "all_tags", "=", "[", "]", "\n", "for", "json_line", "in", "f_iter", ":", "\n", "        ", "data", "=", "json", ".", "loads", "(", "json_line", ")", "\n", "words", "=", "data", "[", "'words'", "]", "\n", "probs", "=", "[", "p", "[", "1", "]", "for", "p", "in", "data", "[", "'class_probabilities'", "]", "[", ":", "len", "(", "words", ")", "]", "]", "\n", "tags", "=", "[", "1", "if", "p", ">", "opt", ".", "bu_threshold", "else", "0", "for", "p", "in", "probs", "]", "\n", "all_tags", ".", "append", "(", "tags", ")", "\n", "#print(len(words), len(data['class_probabilities']))", "\n", "#all_tags.append(words)", "\n", "", "return", "all_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.translate.main": [[30, 72], ["onmt.utils.parse.ArgumentParser.validate_translate_opts", "onmt.utils.logging.init_logger", "onmt.translate.translator.build_translator", "zip", "enumerate", "onmt.utils.misc.split_corpus", "open", "pickle.dump", "open", "pickle.load", "onmt.utils.misc.split_corpus", "itertools.repeat", "onmt.utils.logging.init_logger.info", "onmt.translate.translator.build_translator.translate", "onmt.utils.misc.split_corpus", "next", "open", "pickle.dump"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.validate_translate_opts", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.logging.init_logger", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.build_translator", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.split_corpus", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.split_corpus", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator.translate", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.split_corpus"], ["", "def", "main", "(", "opt", ")", ":", "\n", "    ", "ArgumentParser", ".", "validate_translate_opts", "(", "opt", ")", "\n", "logger", "=", "init_logger", "(", "opt", ".", "log_file", ")", "\n", "\n", "if", "opt", ".", "constraint_file", ":", "\n", "        ", "tag_shards", "=", "split_corpus", "(", "opt", ".", "constraint_file", ",", "opt", ".", "shard_size", ",", "iter_func", "=", "constraint_iter_func", ",", "binary", "=", "False", ")", "\n", "\n", "", "with", "open", "(", "\"opt.pkl\"", ",", "'wb'", ")", "as", "f1", ":", "\n", "        ", "pickle", ".", "dump", "(", "opt", ",", "f1", ")", "\n", "", "with", "open", "(", "\"opt.pkl\"", ",", "'rb'", ")", "as", "f1", ":", "\n", "        ", "opt1", "=", "pickle", ".", "load", "(", "f1", ")", "\n", "", "translator", "=", "build_translator", "(", "opt", ",", "report_score", "=", "True", ")", "\n", "\n", "if", "opt", ".", "data_type", "==", "'imgvec'", ":", "\n", "        ", "assert", "opt", ".", "shard_size", "<=", "0", "\n", "src_shards", "=", "[", "opt", ".", "src", "]", "\n", "", "else", ":", "\n", "        ", "if", "opt", ".", "data_type", "==", "'none'", ":", "\n", "            ", "src_shards", "=", "[", "None", "]", "*", "99999", "\n", "", "else", ":", "\n", "            ", "src_shards", "=", "split_corpus", "(", "opt", ".", "src", ",", "opt", ".", "shard_size", ")", "\n", "", "", "tgt_shards", "=", "split_corpus", "(", "opt", ".", "tgt", ",", "opt", ".", "shard_size", ")", "if", "opt", ".", "tgt", "is", "not", "None", "else", "repeat", "(", "None", ")", "\n", "shard_pairs", "=", "zip", "(", "src_shards", ",", "tgt_shards", ")", "\n", "\n", "for", "i", ",", "(", "src_shard", ",", "tgt_shard", ")", "in", "enumerate", "(", "shard_pairs", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Translating shard %d.\"", "%", "i", ")", "\n", "\n", "tag_shard", "=", "None", "\n", "if", "opt", ".", "constraint_file", ":", "\n", "            ", "tag_shard", "=", "next", "(", "tag_shards", ")", "\n", "\n", "", "all_scores", ",", "all_predictions", "=", "translator", ".", "translate", "(", "\n", "src", "=", "src_shard", ",", "\n", "tgt", "=", "tgt_shard", ",", "\n", "src_dir", "=", "opt", ".", "src_dir", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "attn_debug", "=", "opt", ".", "attn_debug", ",", "\n", "tag_shard", "=", "tag_shard", "\n", ")", "\n", "with", "open", "(", "\"result_{}.pickle\"", ".", "format", "(", "i", ")", ",", "'wb'", ")", "as", "f1", ":", "\n", "            ", "pickle", ".", "dump", "(", "all_predictions", ",", "f1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.translate._get_parser": [[75, 81], ["onmt.utils.parse.ArgumentParser", "onmt.config_opts", "onmt.translate_opts"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.opts.config_opts", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.opts.translate_opts"], ["", "", "", "def", "_get_parser", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", "description", "=", "'translate.py'", ")", "\n", "\n", "opts", ".", "config_opts", "(", "parser", ")", "\n", "opts", ".", "translate_opts", "(", "parser", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.translate.build_opt": [[82, 86], ["open", "pickle.load"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load"], ["", "def", "build_opt", "(", ")", ":", "\n", "    ", "with", "open", "(", "\"opt.pkl\"", ",", "'rb'", ")", "as", "f1", ":", "\n", "        ", "opt1", "=", "pickle", ".", "load", "(", "f1", ")", "\n", "", "return", "opt1", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.train.ErrorHandler.__init__": [[66, 76], ["threading.Thread", "train.ErrorHandler.error_thread.start", "signal.signal"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.start"], ["def", "__init__", "(", "self", ",", "error_queue", ")", ":", "\n", "        ", "\"\"\" init error handler \"\"\"", "\n", "import", "signal", "\n", "import", "threading", "\n", "self", ".", "error_queue", "=", "error_queue", "\n", "self", ".", "children_pids", "=", "[", "]", "\n", "self", ".", "error_thread", "=", "threading", ".", "Thread", "(", "\n", "target", "=", "self", ".", "error_listener", ",", "daemon", "=", "True", ")", "\n", "self", ".", "error_thread", ".", "start", "(", ")", "\n", "signal", ".", "signal", "(", "signal", ".", "SIGUSR1", ",", "self", ".", "signal_handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.train.ErrorHandler.add_child": [[77, 80], ["train.ErrorHandler.children_pids.append"], "methods", ["None"], ["", "def", "add_child", "(", "self", ",", "pid", ")", ":", "\n", "        ", "\"\"\" error handler \"\"\"", "\n", "self", ".", "children_pids", ".", "append", "(", "pid", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.train.ErrorHandler.error_listener": [[81, 86], ["train.ErrorHandler.error_queue.get", "train.ErrorHandler.error_queue.put", "os.kill", "os.getpid"], "methods", ["None"], ["", "def", "error_listener", "(", "self", ")", ":", "\n", "        ", "\"\"\" error listener \"\"\"", "\n", "(", "rank", ",", "original_trace", ")", "=", "self", ".", "error_queue", ".", "get", "(", ")", "\n", "self", ".", "error_queue", ".", "put", "(", "(", "rank", ",", "original_trace", ")", ")", "\n", "os", ".", "kill", "(", "os", ".", "getpid", "(", ")", ",", "signal", ".", "SIGUSR1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.train.ErrorHandler.signal_handler": [[87, 96], ["train.ErrorHandler.error_queue.get", "Exception", "os.kill"], "methods", ["None"], ["", "def", "signal_handler", "(", "self", ",", "signalnum", ",", "stackframe", ")", ":", "\n", "        ", "\"\"\" signal handler \"\"\"", "\n", "for", "pid", "in", "self", ".", "children_pids", ":", "\n", "            ", "os", ".", "kill", "(", "pid", ",", "signal", ".", "SIGINT", ")", "# kill children processes", "\n", "", "(", "rank", ",", "original_trace", ")", "=", "self", ".", "error_queue", ".", "get", "(", ")", "\n", "msg", "=", "\"\"\"\\n\\n-- Tracebacks above this line can probably\n                 be ignored --\\n\\n\"\"\"", "\n", "msg", "+=", "original_trace", "\n", "raise", "Exception", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.train.main": [[17, 44], ["onmt.utils.parse.ArgumentParser.validate_train_opts", "onmt.utils.parse.ArgumentParser.update_model_opts", "onmt.utils.parse.ArgumentParser.validate_model_opts", "len", "torch.multiprocessing.get_context", "torch.multiprocessing.get_context.SimpleQueue", "train.ErrorHandler", "range", "procs.append", "procs[].start", "onmt.utils.logging.logger.info", "train.ErrorHandler.add_child", "p.join", "onmt.train_single.main", "onmt.train_single.main", "torch.multiprocessing.get_context.Process"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.validate_train_opts", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.update_model_opts", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.validate_model_opts", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.start", "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.train.ErrorHandler.add_child", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.train_single.main", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.train_single.main"], ["def", "main", "(", "opt", ")", ":", "\n", "    ", "ArgumentParser", ".", "validate_train_opts", "(", "opt", ")", "\n", "ArgumentParser", ".", "update_model_opts", "(", "opt", ")", "\n", "ArgumentParser", ".", "validate_model_opts", "(", "opt", ")", "\n", "\n", "nb_gpu", "=", "len", "(", "opt", ".", "gpu_ranks", ")", "\n", "\n", "if", "opt", ".", "world_size", ">", "1", ":", "\n", "        ", "mp", "=", "torch", ".", "multiprocessing", ".", "get_context", "(", "'spawn'", ")", "\n", "# Create a thread to listen for errors in the child processes.", "\n", "error_queue", "=", "mp", ".", "SimpleQueue", "(", ")", "\n", "error_handler", "=", "ErrorHandler", "(", "error_queue", ")", "\n", "# Train with multiprocessing.", "\n", "procs", "=", "[", "]", "\n", "for", "device_id", "in", "range", "(", "nb_gpu", ")", ":", "\n", "            ", "procs", ".", "append", "(", "mp", ".", "Process", "(", "target", "=", "run", ",", "args", "=", "(", "\n", "opt", ",", "device_id", ",", "error_queue", ",", ")", ",", "daemon", "=", "True", ")", ")", "\n", "procs", "[", "device_id", "]", ".", "start", "(", ")", "\n", "logger", ".", "info", "(", "\" Starting process pid: %d  \"", "%", "procs", "[", "device_id", "]", ".", "pid", ")", "\n", "error_handler", ".", "add_child", "(", "procs", "[", "device_id", "]", ".", "pid", ")", "\n", "", "for", "p", "in", "procs", ":", "\n", "            ", "p", ".", "join", "(", ")", "\n", "\n", "", "", "elif", "nb_gpu", "==", "1", ":", "# case 1 GPU only", "\n", "        ", "single_main", "(", "opt", ",", "0", ")", "\n", "", "else", ":", "# case only CPU", "\n", "        ", "single_main", "(", "opt", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.train.run": [[46, 60], ["onmt.utils.distributed.multi_init", "onmt.utils.distributed.multi_init", "onmt.train_single.main", "AssertionError", "error_queue.put", "traceback.format_exc"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.distributed.multi_init", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.distributed.multi_init", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.train_single.main"], ["", "", "def", "run", "(", "opt", ",", "device_id", ",", "error_queue", ")", ":", "\n", "    ", "\"\"\" run process \"\"\"", "\n", "try", ":", "\n", "        ", "gpu_rank", "=", "onmt", ".", "utils", ".", "distributed", ".", "multi_init", "(", "opt", ",", "device_id", ")", "\n", "if", "gpu_rank", "!=", "opt", ".", "gpu_ranks", "[", "device_id", "]", ":", "\n", "            ", "raise", "AssertionError", "(", "\"An error occurred in \\\n                  Distributed initialization\"", ")", "\n", "", "single_main", "(", "opt", ",", "device_id", ")", "\n", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "pass", "# killed by parent, do nothing", "\n", "", "except", "Exception", ":", "\n", "# propagate exception to parent process, keeping original traceback", "\n", "        ", "import", "traceback", "\n", "error_queue", ".", "put", "(", "(", "opt", ".", "gpu_ranks", "[", "device_id", "]", ",", "traceback", ".", "format_exc", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.train._get_parser": [[98, 105], ["onmt.utils.parse.ArgumentParser", "onmt.config_opts", "onmt.model_opts", "onmt.train_opts"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.opts.config_opts", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.opts.model_opts", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.opts.train_opts"], ["", "", "def", "_get_parser", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", "description", "=", "'train.py'", ")", "\n", "\n", "opts", ".", "config_opts", "(", "parser", ")", "\n", "opts", ".", "model_opts", "(", "parser", ")", "\n", "opts", ".", "train_opts", "(", "parser", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.preprocess.check_existing_pt_files": [[20, 29], ["pattern.format", "glob.glob", "sys.stderr.write", "sys.exit"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write"], ["def", "check_existing_pt_files", "(", "opt", ")", ":", "\n", "    ", "\"\"\" Check if there are existing .pt files to avoid overwriting them \"\"\"", "\n", "pattern", "=", "opt", ".", "save_data", "+", "'.{}*.pt'", "\n", "for", "t", "in", "[", "'train'", ",", "'valid'", ",", "'vocab'", "]", ":", "\n", "        ", "path", "=", "pattern", ".", "format", "(", "t", ")", "\n", "if", "glob", ".", "glob", "(", "path", ")", ":", "\n", "            ", "sys", ".", "stderr", ".", "write", "(", "\"Please backup existing pt files: %s, \"", "\n", "\"to avoid overwriting them!\\n\"", "%", "path", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.preprocess.build_save_dataset": [[31, 117], ["onmt.utils.logging.logger.info", "onmt.utils.misc.split_corpus", "zip", "enumerate", "fields.keys", "onmt.utils.misc.split_labels", "functools.partial", "onmt.utils.logging.logger.info", "onmt.Dataset", "dataset_paths.append", "onmt.utils.logging.logger.info", "inputters.Dataset.save", "gc.collect", "gc.collect", "onmt.utils.misc.split_corpus", "len", "len"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.split_corpus", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.split_labels", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.split_corpus"], ["", "", "", "def", "build_save_dataset", "(", "corpus_type", ",", "fields", ",", "src_reader", ",", "tgt_reader", ",", "opt", ")", ":", "\n", "    ", "assert", "corpus_type", "in", "[", "'train'", ",", "'valid'", "]", "\n", "\n", "if", "corpus_type", "==", "'train'", ":", "\n", "        ", "src", "=", "opt", ".", "train_src", "\n", "tgt", "=", "opt", ".", "train_tgt", "\n", "pointers_file", "=", "opt", ".", "pointers_file", "\n", "", "else", ":", "\n", "        ", "src", "=", "opt", ".", "valid_src", "\n", "tgt", "=", "opt", ".", "valid_tgt", "\n", "pointers_file", "=", "None", "\n", "\n", "\n", "", "logger", ".", "info", "(", "\"Reading source and target files: %s %s.\"", "%", "(", "src", ",", "tgt", ")", ")", "\n", "\n", "tgt_shards", "=", "split_corpus", "(", "tgt", ",", "opt", ".", "shard_size", ")", "\n", "if", "opt", ".", "data_type", "==", "'imgvec'", ":", "\n", "        ", "assert", "opt", ".", "shard_size", "<=", "0", "\n", "src_shards", "=", "[", "src", "]", "\n", "", "elif", "opt", ".", "data_type", "==", "'none'", ":", "\n", "        ", "src_shards", "=", "[", "None", "]", "*", "99999", "\n", "", "else", ":", "\n", "        ", "src_shards", "=", "split_corpus", "(", "src", ",", "opt", ".", "shard_size", ")", "\n", "\n", "", "if", "\"label\"", "in", "fields", ".", "keys", "(", ")", ":", "\n", "        ", "if", "corpus_type", "==", "'train'", ":", "\n", "            ", "label_file", "=", "opt", ".", "train_label", "\n", "", "else", ":", "\n", "            ", "label_file", "=", "opt", ".", "valid_label", "\n", "# label_shards = [[1] * 11490]", "\n", "", "label_shards", "=", "split_labels", "(", "label_file", ",", "opt", ".", "shard_size", ")", "\n", "", "else", ":", "\n", "        ", "label_shards", "=", "[", "[", "1", "]", "*", "99999", "]", "\n", "\n", "\n", "", "shard_pairs", "=", "zip", "(", "src_shards", ",", "tgt_shards", ",", "label_shards", ")", "\n", "\n", "dataset_paths", "=", "[", "]", "\n", "if", "(", "corpus_type", "==", "\"train\"", "or", "opt", ".", "filter_valid", ")", "and", "tgt", "is", "not", "None", ":", "\n", "        ", "filter_pred", "=", "partial", "(", "\n", "inputters", ".", "filter_example", ",", "use_src_len", "=", "opt", ".", "data_type", "==", "\"text\"", ",", "\n", "max_src_len", "=", "opt", ".", "src_seq_length", ",", "max_tgt_len", "=", "opt", ".", "tgt_seq_length", ")", "\n", "", "else", ":", "\n", "        ", "filter_pred", "=", "None", "\n", "\n", "", "for", "i", ",", "(", "src_shard", ",", "tgt_shard", ",", "label", ")", "in", "enumerate", "(", "shard_pairs", ")", ":", "\n", "        ", "assert", "opt", ".", "data_type", "in", "[", "'imgvec'", ",", "'none'", "]", "or", "len", "(", "src_shard", ")", "==", "len", "(", "tgt_shard", ")", "\n", "logger", ".", "info", "(", "\"Building shard %d.\"", "%", "i", ")", "\n", "\n", "if", "src_reader", "and", "tgt_reader", ":", "\n", "            ", "readers", "=", "[", "src_reader", ",", "tgt_reader", ",", "None", "]", "\n", "data", "=", "(", "[", "(", "\"src\"", ",", "src_shard", ")", ",", "(", "\"tgt\"", ",", "tgt_shard", ")", ",", "(", "'label'", ",", "label", ")", "]", ")", "\n", "dirs", "=", "[", "opt", ".", "src_dir", ",", "None", "]", "\n", "", "elif", "src_reader", "and", "not", "tgt_reader", ":", "\n", "            ", "readers", "=", "[", "src_reader", "]", "\n", "data", "=", "(", "[", "(", "\"src\"", ",", "src_shard", ")", "]", ")", "\n", "dirs", "=", "[", "opt", ".", "src_dir", "]", "\n", "", "elif", "not", "src_reader", "and", "tgt_reader", ":", "\n", "            ", "readers", "=", "[", "tgt_reader", "]", "\n", "data", "=", "(", "[", "(", "\"tgt\"", ",", "tgt_shard", ")", "]", ")", "\n", "dirs", "=", "[", "None", "]", "\n", "\n", "", "dataset", "=", "inputters", ".", "Dataset", "(", "\n", "fields", ",", "\n", "readers", "=", "readers", ",", "\n", "data", "=", "data", ",", "\n", "dirs", "=", "dirs", ",", "\n", "sort_key", "=", "inputters", ".", "str2sortkey", "[", "opt", ".", "data_type", "]", ",", "\n", "filter_pred", "=", "filter_pred", ",", "\n", "pointers_file", "=", "pointers_file", "\n", ")", "\n", "\n", "data_path", "=", "\"{:s}.{:s}.{:d}.pt\"", ".", "format", "(", "opt", ".", "save_data", ",", "corpus_type", ",", "i", ")", "\n", "dataset_paths", ".", "append", "(", "data_path", ")", "\n", "\n", "logger", ".", "info", "(", "\" * saving %sth %s data shard to %s.\"", "\n", "%", "(", "i", ",", "corpus_type", ",", "data_path", ")", ")", "\n", "\n", "dataset", ".", "save", "(", "data_path", ")", "\n", "\n", "del", "dataset", ".", "examples", "\n", "gc", ".", "collect", "(", ")", "\n", "del", "dataset", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "", "return", "dataset_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.preprocess.build_save_vocab": [[119, 131], ["onmt.build_vocab", "torch.save"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.build_vocab", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.save"], ["", "def", "build_save_vocab", "(", "train_dataset", ",", "fields", ",", "opt", ")", ":", "\n", "    ", "fields", "=", "inputters", ".", "build_vocab", "(", "\n", "train_dataset", ",", "fields", ",", "opt", ".", "data_type", ",", "opt", ".", "share_vocab", ",", "\n", "opt", ".", "src_vocab", ",", "opt", ".", "src_vocab_size", ",", "opt", ".", "src_words_min_frequency", ",", "\n", "opt", ".", "tgt_vocab", ",", "opt", ".", "tgt_vocab_size", ",", "opt", ".", "tgt_words_min_frequency", ",", "\n", "fixed_vocab", "=", "opt", ".", "fixed_vocab", ",", "\n", "free_src", "=", "opt", ".", "free_src", ",", "free_tgt", "=", "opt", ".", "free_tgt", ",", "\n", "vocab_size_multiple", "=", "opt", ".", "vocab_size_multiple", "\n", ")", "\n", "\n", "vocab_path", "=", "opt", ".", "save_data", "+", "'.vocab.pt'", "\n", "torch", ".", "save", "(", "fields", ",", "vocab_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.preprocess.count_features": [[133, 142], ["codecs.open", "f.readline().split", "len", "first_tok.split", "f.readline"], "function", ["None"], ["", "def", "count_features", "(", "path", ")", ":", "\n", "    ", "\"\"\"\n    path: location of a corpus file with whitespace-delimited tokens and\n                    \uffe8-delimited features within the token\n    returns: the number of features in the dataset\n    \"\"\"", "\n", "with", "codecs", ".", "open", "(", "path", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "first_tok", "=", "f", ".", "readline", "(", ")", ".", "split", "(", "None", ",", "1", ")", "[", "0", "]", "\n", "return", "len", "(", "first_tok", ".", "split", "(", "u\"\uffe8\"", ")", ")", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.preprocess.main": [[144, 222], ["onmt.utils.parse.ArgumentParser.validate_preprocess_args", "torch.manual_seed", "preprocess.check_existing_pt_files", "onmt.utils.logging.init_logger", "onmt.utils.logging.logger.info", "preprocess.count_features", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.get_fields", "onmt.str2reader[].from_opt", "onmt.utils.logging.logger.info", "preprocess.build_save_dataset", "onmt.utils.logging.logger.info", "preprocess.build_save_vocab", "preprocess.count_features", "onmt.str2reader[].from_opt", "torchtext.data.Field", "onmt.utils.logging.logger.info", "preprocess.build_save_dataset"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.validate_preprocess_args", "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.preprocess.check_existing_pt_files", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.logging.init_logger", "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.preprocess.count_features", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.preprocess.build_save_dataset", "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.preprocess.build_save_vocab", "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.preprocess.count_features", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.preprocess.build_save_dataset"], ["", "", "def", "main", "(", "opt", ")", ":", "\n", "    ", "ArgumentParser", ".", "validate_preprocess_args", "(", "opt", ")", "\n", "torch", ".", "manual_seed", "(", "opt", ".", "seed", ")", "\n", "check_existing_pt_files", "(", "opt", ")", "\n", "\n", "init_logger", "(", "opt", ".", "log_file", ")", "\n", "logger", ".", "info", "(", "\"Extracting features...\"", ")", "\n", "\n", "src_nfeats", "=", "count_features", "(", "opt", ".", "train_src", ")", "if", "opt", ".", "data_type", "==", "'text'", "else", "0", "\n", "tgt_nfeats", "=", "count_features", "(", "opt", ".", "train_tgt", ")", "# tgt always text so far", "\n", "logger", ".", "info", "(", "\" * number of source features: %d.\"", "%", "src_nfeats", ")", "\n", "logger", ".", "info", "(", "\" * number of target features: %d.\"", "%", "tgt_nfeats", ")", "\n", "logger", ".", "info", "(", "\"Building `Fields` object...\"", ")", "\n", "\n", "if", "opt", ".", "fixed_vocab", ":", "\n", "        ", "tgt_bos", "=", "'<|endoftext|>'", "\n", "tgt_eos", "=", "'\\u0120GDDR'", "\n", "tgt_pad", "=", "'\\u0120SHALL'", "\n", "tgt_unk", "=", "'\\u0120RELE'", "\n", "\n", "if", "opt", ".", "no_spec_src", ":", "\n", "            ", "src_pad", "=", "None", "\n", "src_unk", "=", "None", "\n", "", "elif", "opt", ".", "free_src", ":", "\n", "            ", "src_pad", "=", "'<blank>'", "\n", "src_unk", "=", "'<unk>'", "\n", "", "else", ":", "\n", "            ", "src_pad", "=", "'\\u0120SHALL'", "\n", "src_unk", "=", "'\\u0120RELE'", "\n", "\n", "", "", "else", ":", "\n", "        ", "tgt_bos", "=", "'<s>'", "\n", "tgt_eos", "=", "'</s>'", "\n", "tgt_pad", "=", "'<blank>'", "\n", "tgt_unk", "=", "'<unk>'", "\n", "src_pad", "=", "'<blank>'", "\n", "src_unk", "=", "'<unk>'", "\n", "\n", "", "fields", "=", "inputters", ".", "get_fields", "(", "\n", "opt", ".", "data_type", ",", "\n", "src_nfeats", ",", "\n", "tgt_nfeats", ",", "\n", "dynamic_dict", "=", "opt", ".", "dynamic_dict", ",", "\n", "src_truncate", "=", "opt", ".", "src_seq_length_trunc", ",", "\n", "tgt_truncate", "=", "opt", ".", "tgt_seq_length_trunc", ",", "\n", "src_pad", "=", "src_pad", ",", "\n", "src_unk", "=", "src_unk", ",", "\n", "tgt_pad", "=", "tgt_pad", ",", "\n", "tgt_unk", "=", "tgt_unk", ",", "\n", "tgt_bos", "=", "tgt_bos", ",", "\n", "tgt_eos", "=", "tgt_eos", ",", "\n", "include_ptrs", "=", "opt", ".", "pointers_file", "is", "not", "None", ")", "\n", "\n", "\n", "\n", "if", "opt", ".", "data_type", "==", "'none'", ":", "\n", "        ", "src_reader", "=", "None", "\n", "", "else", ":", "\n", "        ", "src_reader", "=", "inputters", ".", "str2reader", "[", "opt", ".", "data_type", "]", ".", "from_opt", "(", "opt", ")", "\n", "", "tgt_reader", "=", "inputters", ".", "str2reader", "[", "\"text\"", "]", ".", "from_opt", "(", "opt", ")", "\n", "\n", "if", "opt", ".", "train_clf", ":", "\n", "# train the classification model", "\n", "        ", "label_field", "=", "Field", "(", "sequential", "=", "False", ",", "use_vocab", "=", "False", ")", "\n", "fields", "[", "'label'", "]", "=", "label_field", "\n", "\n", "\n", "", "logger", ".", "info", "(", "\"Building & saving training data...\"", ")", "\n", "train_dataset_files", "=", "build_save_dataset", "(", "\n", "'train'", ",", "fields", ",", "src_reader", ",", "tgt_reader", ",", "opt", ")", "\n", "\n", "if", "(", "opt", ".", "valid_src", "or", "opt", ".", "data_type", "==", "'none'", ")", "and", "opt", ".", "valid_tgt", ":", "\n", "        ", "logger", ".", "info", "(", "\"Building & saving validation data...\"", ")", "\n", "build_save_dataset", "(", "'valid'", ",", "fields", ",", "src_reader", ",", "tgt_reader", ",", "opt", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Building & saving vocabulary...\"", ")", "\n", "build_save_vocab", "(", "train_dataset_files", ",", "fields", ",", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.preprocess._get_parser": [[224, 230], ["onmt.utils.parse.ArgumentParser", "onmt.config_opts", "onmt.preprocess_opts"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.opts.config_opts", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.opts.preprocess_opts"], ["", "def", "_get_parser", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", "description", "=", "'preprocess.py'", ")", "\n", "\n", "opts", ".", "config_opts", "(", "parser", ")", "\n", "opts", ".", "preprocess_opts", "(", "parser", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.classification.constraint_iter_func": [[21, 32], ["json.loads", "all_tags.append", "len"], "function", ["None"], ["def", "constraint_iter_func", "(", "f_iter", ")", ":", "\n", "    ", "all_tags", "=", "[", "]", "\n", "for", "json_line", "in", "f_iter", ":", "\n", "        ", "data", "=", "json", ".", "loads", "(", "json_line", ")", "\n", "words", "=", "data", "[", "'words'", "]", "\n", "probs", "=", "[", "p", "[", "1", "]", "for", "p", "in", "data", "[", "'class_probabilities'", "]", "[", ":", "len", "(", "words", ")", "]", "]", "\n", "tags", "=", "[", "1", "if", "p", ">", "opt", ".", "bu_threshold", "else", "0", "for", "p", "in", "probs", "]", "\n", "all_tags", ".", "append", "(", "tags", ")", "\n", "#print(len(words), len(data['class_probabilities']))", "\n", "#all_tags.append(words)", "\n", "", "return", "all_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.classification.main": [[34, 63], ["onmt.utils.parse.ArgumentParser.validate_translate_opts", "onmt.utils.logging.init_logger", "load_test_model", "transformers.GPT2Tokenizer.from_pretrained", "GPT2Tokenizer.from_pretrained.decoder.get", "open().readlines", "model.cuda.cuda", "model.cuda.eval", "len", "torch.no_grad", "range", "print", "open", "i.strip", "len", "torch.tensor", "torch.tensor", "torch.transpose", "tokens_ids.cuda.unsqueeze_", "tokens_ids.cuda.cuda", "lengths.cuda.cuda", "result.tolist.tolist", "predict_list.extend", "GPT2Tokenizer.from_pretrained.encode", "model.cuda.", "sklearn.metrics.accuracy_score", "len", "len", "GPT2Tokenizer.from_pretrained.encode", "GPT2Tokenizer.from_pretrained.encode"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.validate_translate_opts", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.logging.init_logger", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.load_test_model", "home.repos.pwc.inspect_result.bigheiniu_FactGen.NeuralGenerationDetection.RoBERTaDetect.eval"], ["", "def", "main", "(", "opt", ")", ":", "\n", "    ", "ArgumentParser", ".", "validate_translate_opts", "(", "opt", ")", "\n", "logger", "=", "init_logger", "(", "opt", ".", "log_file", ")", "\n", "load_test_model", "=", "onmt", ".", "model_builder", ".", "load_test_model", "\n", "_", ",", "model", ",", "_", "=", "load_test_model", "(", "opt", ")", "\n", "\n", "tokenizer", "=", "GPT2Tokenizer", ".", "from_pretrained", "(", "'gpt2'", ")", "\n", "tokenizer", ".", "pad_token", "=", "tokenizer", ".", "decoder", ".", "get", "(", "50163", ")", "\n", "input_data", "=", "open", "(", "opt", ".", "src", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "input_data", "=", "[", "i", ".", "strip", "(", ")", "for", "i", "in", "input_data", "]", "[", ":", "-", "100", "]", "\n", "labels", "=", "[", "0", "]", "*", "len", "(", "input_data", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "predict_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "0", ",", "len", "(", "input_data", ")", ",", "30", ")", ":", "\n", "            ", "batch", "=", "input_data", "[", "i", ":", "i", "+", "30", "]", "\n", "tokens_ids", "=", "[", "tokenizer", ".", "encode", "(", "i", ",", "pad_to_max_length", "=", "True", ",", "max_length", "=", "200", ")", "for", "i", "in", "batch", "]", "\n", "lengths", "=", "torch", ".", "tensor", "(", "[", "len", "(", "tokenizer", ".", "encode", "(", "i", ")", ")", "if", "len", "(", "tokenizer", ".", "encode", "(", "i", ")", ")", "<", "200", "else", "200", "for", "i", "in", "batch", "]", ")", "\n", "tokens_ids", "=", "torch", ".", "tensor", "(", "tokens_ids", ")", "\n", "tokens_ids", "=", "torch", ".", "transpose", "(", "tokens_ids", ",", "1", ",", "0", ")", "\n", "tokens_ids", ".", "unsqueeze_", "(", "-", "1", ")", "\n", "tokens_ids", "=", "tokens_ids", ".", "cuda", "(", ")", "\n", "lengths", "=", "lengths", ".", "cuda", "(", ")", "\n", "kwargs", "=", "{", "\"facts\"", ":", "None", "}", "\n", "result", "=", "model", "(", "tokens_ids", ",", "tokens_ids", ",", "lengths", ",", "**", "kwargs", ")", "[", "-", "1", "]", "\n", "result", "=", "result", ".", "tolist", "(", ")", "\n", "predict_list", ".", "extend", "(", "result", ")", "\n", "", "print", "(", "\"Acc Score is {}\"", ".", "format", "(", "accuracy_score", "(", "y_true", "=", "labels", ",", "y_pred", "=", "predict_list", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.classification._get_parser": [[68, 74], ["onmt.utils.parse.ArgumentParser", "onmt.config_opts", "onmt.translate_opts"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.opts.config_opts", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.opts.translate_opts"], ["", "", "def", "_get_parser", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", "description", "=", "'translate.py'", ")", "\n", "\n", "opts", ".", "config_opts", "(", "parser", ")", "\n", "opts", ".", "translate_opts", "(", "parser", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.classification.build_opt": [[75, 79], ["open", "pickle.load"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load"], ["", "def", "build_opt", "(", ")", ":", "\n", "    ", "with", "open", "(", "\"opt.pkl\"", ",", "'rb'", ")", "as", "f1", ":", "\n", "        ", "opt1", "=", "pickle", ".", "load", "(", "f1", ")", "\n", "", "return", "opt1", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.opts.StoreLoggingLevelAction.__init__": [[839, 842], ["configargparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "help", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "StoreLoggingLevelAction", ",", "self", ")", ".", "__init__", "(", "\n", "option_strings", ",", "dest", ",", "help", "=", "help", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.opts.StoreLoggingLevelAction.__call__": [[843, 847], ["StoreLoggingLevelAction.LEVELS.get", "setattr"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "value", ",", "option_string", "=", "None", ")", ":", "\n", "# Get the key 'value' in the dict, or just use 'value'", "\n", "        ", "level", "=", "StoreLoggingLevelAction", ".", "LEVELS", ".", "get", "(", "value", ",", "value", ")", "\n", "setattr", "(", "namespace", ",", "self", ".", "dest", ",", "level", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.opts.DeprecateAction.__init__": [[852, 855], ["configargparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "help", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DeprecateAction", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "nargs", "=", "0", ",", "\n", "help", "=", "help", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.opts.DeprecateAction.__call__": [[856, 860], ["configargparse.ArgumentTypeError"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "flag_name", ")", ":", "\n", "        ", "help", "=", "self", ".", "help", "if", "self", ".", "help", "is", "not", "None", "else", "\"\"", "\n", "msg", "=", "\"Flag '%s' is deprecated. %s\"", "%", "(", "flag_name", ",", "help", ")", "\n", "raise", "configargparse", ".", "ArgumentTypeError", "(", "msg", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.opts.config_opts": [[8, 16], ["parser.add", "parser.add", "parser.add"], "function", ["None"], ["def", "config_opts", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add", "(", "'-config'", ",", "'--config'", ",", "required", "=", "False", ",", "\n", "is_config_file_arg", "=", "True", ",", "help", "=", "'config file path'", ")", "\n", "parser", ".", "add", "(", "'-save_config'", ",", "'--save_config'", ",", "required", "=", "False", ",", "\n", "is_write_out_config_file_arg", "=", "True", ",", "\n", "help", "=", "'config file save path'", ")", "\n", "parser", ".", "add", "(", "'--run_name'", ",", "'-run_name'", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Name for run.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.opts.model_opts": [[17, 272], ["parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add"], "function", ["None"], ["", "def", "model_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\"\n    These options are passed to the construction of the model.\n    Be careful with these as they will be used during translation.\n    \"\"\"", "\n", "\n", "# Embedding Options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model-Embeddings'", ")", "\n", "group", ".", "add", "(", "'--src_word_vec_size'", ",", "'-src_word_vec_size'", ",", "\n", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Word embedding size for src.'", ")", "\n", "group", ".", "add", "(", "'--tgt_word_vec_size'", ",", "'-tgt_word_vec_size'", ",", "\n", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Word embedding size for tgt.'", ")", "\n", "group", ".", "add", "(", "'--word_vec_size'", ",", "'-word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Word embedding size for src and tgt.'", ")", "\n", "group", ".", "add", "(", "'--attn_hidden'", ",", "'-attn_hidden'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Attn hidden size for self attention on input.'", ")", "\n", "\n", "group", ".", "add", "(", "'--share_decoder_embeddings'", ",", "'-share_decoder_embeddings'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use a shared weight matrix for the input and \"", "\n", "\"output word  embeddings in the decoder.\"", ")", "\n", "group", ".", "add", "(", "'--share_embeddings'", ",", "'-share_embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share the word embeddings between encoder \"", "\n", "\"and decoder. Need to use shared dictionary for this \"", "\n", "\"option.\"", ")", "\n", "group", ".", "add", "(", "'--share_position_embeddings'", ",", "'-share_position_embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share learned position word embeddings between encoder \"", "\n", "\"and decoder. Need to use shared dictionary for this \"", "\n", "\"option.\"", ")", "\n", "group", ".", "add", "(", "'--position_encoding'", ",", "'-position_encoding'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use a sin to mark relative words positions. \"", "\n", "\"Necessary for non-RNN style models.\"", ")", "\n", "group", ".", "add", "(", "'--position_encoding_learned'", ",", "'-position_encoding_learned'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use learned position encoding for both encoder and decoder.\"", ")", "\n", "group", ".", "add", "(", "'--position_encoding_learned_enc'", ",", "'-position_encoding_learned_enc'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use learned position encoding for encoder.\"", ")", "\n", "group", ".", "add", "(", "'--position_encoding_learned_dec'", ",", "'-position_encoding_learned_dec'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use learned position encoding for decoder.\"", ")", "\n", "group", ".", "add", "(", "'--position_encoding_ctxsize'", ",", "'-position_encoding_ctxsize'", ",", "type", "=", "int", ",", "default", "=", "1024", ",", "\n", "help", "=", "\"Maximum context size for transformer\"", ")", "\n", "group", ".", "add", "(", "'--gpt2_params_path'", ",", "'-gpt2_params_path'", ",", "type", "=", "str", ",", "\n", "help", "=", "\"If not None, load the GPT2 pretrained parameters.\"", ")", "\n", "group", ".", "add", "(", "'--gpt_emb_only'", ",", "'-gpt_emb_only'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Only load the embeddings from the gpt2 model.\"", ")", "\n", "group", ".", "add", "(", "'--gpt_wpe_only'", ",", "'-gpt_wpe_only'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Only load the position embeddings from the gpt2 model.\"", ")", "\n", "group", ".", "add", "(", "'--use_GPT_version_ctxattn'", ",", "'-use_GPT_version_ctxattn'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use the slightly different GPT transformer version.\"", ")", "\n", "group", ".", "add", "(", "'--use_GPT_version_psa'", ",", "'-use_GPT_version_psa'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use the psa attn GPT transformer version.\"", ")", "\n", "group", ".", "add", "(", "'--use_GPT_version_unconditional'", ",", "'-use_GPT_version_unconditional'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use the unconditional GPT transformer version.\"", ")", "\n", "group", ".", "add", "(", "'--notrain_emb'", ",", "'-notrain_emb'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Do not train either embeddings or generator weights.\"", ")", "\n", "group", ".", "add", "(", "'--notrain_embanddec'", ",", "'-notrain_embanddec'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Do not train embeddings, generator weights, or decoder except ctx attn. Does train gen bias\"", ")", "\n", "group", ".", "add", "(", "'--notrain_enc'", ",", "'-notrain_enc'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Do not train encoder.\"", ")", "\n", "group", ".", "add", "(", "'--notrain_genbias'", ",", "'-notrain_genbias'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Do not train generator bias.\"", ")", "\n", "group", ".", "add", "(", "'--onlytrainln'", ",", "'-onlytrainln'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Only train layernorm layers.\"", ")", "\n", "group", ".", "add", "(", "'--onlytrainoutp'", ",", "'-onlytrainoutp'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Only train output layer.\"", ")", "\n", "group", ".", "add", "(", "'--gpt2_init_embanddec'", ",", "'-gpt2_init_embanddec'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"If true, initialize network with gpt2 weights.\"", ")", "\n", "group", ".", "add", "(", "'--gpt2_init_embandenc'", ",", "'-gpt2_init_embandenc'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"If true, initialize encoder network with gpt2 weights.\"", ")", "\n", "group", ".", "add", "(", "'--gpt2_init_zero'", ",", "'-gpt2_init_zero'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"If true, initialize all weights to be 0 before loading gpt values.\"", ")", "\n", "group", ".", "add", "(", "'--gpt2_params_std'", ",", "'-gpt2_params_std'", ",", "type", "=", "float", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Stdev for gpt2 loaded parameters away from mean value.\"", ")", "\n", "group", ".", "add", "(", "'--simple_fusion'", ",", "'-simple_fusion'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use simple fusion.\"", ")", "\n", "group", ".", "add", "(", "'--encdec_share_params'", ",", "'-encdec_share_params'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Force the encoder and decoder to share parameters.\"", ")", "\n", "group", ".", "add", "(", "'--ctx_weight_param'", ",", "'-ctx_weight_param'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Train an additional parameter per layer to weight the ctx output.\"", ")", "\n", "group", ".", "add", "(", "'--full_context_lr'", ",", "'-full_context_lr'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use the normal full lr (instead of disc ft) for the context blocks.\"", ")", "\n", "group", ".", "add", "(", "'--base_encoder_type'", ",", "'-base_encoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'brnn'", ",", "'mean'", ",", "'transformer'", ",", "'cnn'", "]", ",", "\n", "help", "=", "\"Type of encoder layer to use. Non-RNN layers \"", "\n", "\"are experimental. Options are \"", "\n", "\"[rnn|brnn|mean|transformer|cnn].\"", ")", "\n", "group", ".", "add", "(", "'--sf_pretrain_dec_emb'", ",", "'-sf_pretrain_dec_emb'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Pretrain decoder embeddings if using simple fusion.\"", ")", "\n", "group", ".", "add", "(", "'--unconditional'", ",", "'-unconditional'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Do not use an encoder.\"", ")", "\n", "group", ".", "add", "(", "'--enc_use_GPT_version'", ",", "'-enc_use_GPT_version'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use the exact GPT version for the encoder transformer.\"", ")", "\n", "group", ".", "add", "(", "'--encoder_from'", ",", "'-encoder_from'", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path to checkpoint with pretrained encoder.\"", ")", "\n", "group", ".", "add", "(", "'--padded_vocab_fix_me_later'", ",", "'-padded_vocab_fix_me_later'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Processed vocab is padded.\"", ")", "\n", "group", ".", "add", "(", "'--GPT_representation_mode'", ",", "'-GPT_representation_mode'", ",", "type", "=", "str", ",", "default", "=", "'none'", ",", "\n", "choices", "=", "[", "'none'", ",", "'elmo'", ",", "'ft'", "]", ",", "\n", "help", "=", "\"How should GPT be used as pretrained embeddings.\"", ")", "\n", "group", ".", "add", "(", "'--GPT_representation_loc'", ",", "'-GPT_representation_loc'", ",", "type", "=", "str", ",", "default", "=", "'src'", ",", "\n", "choices", "=", "[", "'src'", ",", "'tgt'", ",", "'both'", "]", ",", "\n", "help", "=", "\"Where the GPT representation is added.\"", ")", "\n", "group", ".", "add", "(", "'--nopretrain_decemb'", ",", "'-nopretrain_decemb'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Do not pretrain the decoder input and output embeddings.\"", ")", "\n", "group", ".", "add", "(", "'--zero_bias_init'", ",", "'-zero_bias_init'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Initialize with 0 for bias values.\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model-Embedding Features'", ")", "\n", "group", ".", "add", "(", "'--feat_merge'", ",", "'-feat_merge'", ",", "type", "=", "str", ",", "default", "=", "'concat'", ",", "\n", "choices", "=", "[", "'concat'", ",", "'sum'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"Merge action for incorporating features embeddings. \"", "\n", "\"Options [concat|sum|mlp].\"", ")", "\n", "group", ".", "add", "(", "'--feat_vec_size'", ",", "'-feat_vec_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"If specified, feature embedding sizes \"", "\n", "\"will be set to this. Otherwise, feat_vec_exponent \"", "\n", "\"will be used.\"", ")", "\n", "group", ".", "add", "(", "'--feat_vec_exponent'", ",", "'-feat_vec_exponent'", ",", "\n", "type", "=", "float", ",", "default", "=", "0.7", ",", "\n", "help", "=", "\"If -feat_merge_size is not set, feature \"", "\n", "\"embedding sizes will be set to N^feat_vec_exponent \"", "\n", "\"where N is the number of values the feature takes.\"", ")", "\n", "\n", "# Encoder-Decoder Options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model- Encoder-Decoder'", ")", "\n", "group", ".", "add", "(", "'--model_type'", ",", "'-model_type'", ",", "default", "=", "'text'", ",", "\n", "choices", "=", "[", "'text'", ",", "'img'", ",", "'audio'", ",", "'imgvec'", ",", "'none'", "]", ",", "\n", "help", "=", "\"Type of source model to use. Allows \"", "\n", "\"the system to incorporate non-text inputs. \"", "\n", "\"Options are [text|img|audio].\"", ")", "\n", "group", ".", "add", "(", "'--model_dtype'", ",", "'-model_dtype'", ",", "default", "=", "'fp32'", ",", "\n", "choices", "=", "[", "'fp32'", ",", "'fp16'", "]", ",", "\n", "help", "=", "'Data type of the model.'", ")", "\n", "\n", "group", ".", "add", "(", "'--encoder_type'", ",", "'-encoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'brnn'", ",", "'mean'", ",", "'transformer'", ",", "'cnn'", "]", ",", "\n", "help", "=", "\"Type of encoder layer to use. Non-RNN layers \"", "\n", "\"are experimental. Options are \"", "\n", "\"[rnn|brnn|mean|transformer|cnn].\"", ")", "\n", "group", ".", "add", "(", "'--decoder_type'", ",", "'-decoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'transformer'", ",", "'cnn'", ",", "\n", "'rnn_uncond'", "]", ",", "\n", "help", "=", "\"Type of decoder layer to use. Non-RNN layers \"", "\n", "\"are experimental. Options are \"", "\n", "\"[rnn|transformer|cnn].\"", ")", "\n", "\n", "group", ".", "add", "(", "'--layers'", ",", "'-layers'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Number of layers in enc/dec.'", ")", "\n", "group", ".", "add", "(", "'--enc_layers'", ",", "'-enc_layers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of layers in the encoder'", ")", "\n", "group", ".", "add", "(", "'--dec_layers'", ",", "'-dec_layers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of layers in the decoder'", ")", "\n", "group", ".", "add", "(", "'--rnn_size'", ",", "'-rnn_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Size of rnn hidden states. Overwrites \"", "\n", "\"enc_rnn_size and dec_rnn_size\"", ")", "\n", "group", ".", "add", "(", "'--enc_rnn_size'", ",", "'-enc_rnn_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "\"Size of encoder rnn hidden states. \"", "\n", "\"Must be equal to dec_rnn_size except for \"", "\n", "\"speech-to-text.\"", ")", "\n", "group", ".", "add", "(", "'--dec_rnn_size'", ",", "'-dec_rnn_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "\"Size of decoder rnn hidden states. \"", "\n", "\"Must be equal to enc_rnn_size except for \"", "\n", "\"speech-to-text.\"", ")", "\n", "group", ".", "add", "(", "'--audio_enc_pooling'", ",", "'-audio_enc_pooling'", ",", "\n", "type", "=", "str", ",", "default", "=", "'1'", ",", "\n", "help", "=", "\"The amount of pooling of audio encoder, \"", "\n", "\"either the same amount of pooling across all layers \"", "\n", "\"indicated by a single number, or different amounts of \"", "\n", "\"pooling per layer separated by comma.\"", ")", "\n", "group", ".", "add", "(", "'--cnn_kernel_width'", ",", "'-cnn_kernel_width'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "\"Size of windows in the cnn, the kernel_size is \"", "\n", "\"(cnn_kernel_width, 1) in conv layer\"", ")", "\n", "\n", "group", ".", "add", "(", "'--input_feed'", ",", "'-input_feed'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Feed the context vector at each time step as \"", "\n", "\"additional input (via concatenation with the word \"", "\n", "\"embeddings) to the decoder.\"", ")", "\n", "group", ".", "add", "(", "'--bridge'", ",", "'-bridge'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Have an additional layer between the last encoder \"", "\n", "\"state and the first decoder state\"", ")", "\n", "group", ".", "add", "(", "'--rnn_type'", ",", "'-rnn_type'", ",", "type", "=", "str", ",", "default", "=", "'LSTM'", ",", "\n", "choices", "=", "[", "'LSTM'", ",", "'GRU'", ",", "'SRU'", "]", ",", "\n", "action", "=", "CheckSRU", ",", "\n", "help", "=", "\"The gate type to use in the RNNs\"", ")", "\n", "# group.add('--residual', '-residual',   action=\"store_true\",", "\n", "#                     help=\"Add residual connections between RNN layers.\")", "\n", "\n", "group", ".", "add", "(", "'--brnn'", ",", "'-brnn'", ",", "action", "=", "DeprecateAction", ",", "\n", "help", "=", "\"Deprecated, use `encoder_type`.\"", ")", "\n", "\n", "group", ".", "add", "(", "'--context_gate'", ",", "'-context_gate'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "choices", "=", "[", "'source'", ",", "'target'", ",", "'both'", "]", ",", "\n", "help", "=", "\"Type of context gate to use. \"", "\n", "\"Do not select for no context gate.\"", ")", "\n", "\n", "# Attention options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model- Attention'", ")", "\n", "group", ".", "add", "(", "'--global_attention'", ",", "'-global_attention'", ",", "\n", "type", "=", "str", ",", "default", "=", "'general'", ",", "\n", "choices", "=", "[", "'dot'", ",", "'general'", ",", "'mlp'", ",", "'none'", "]", ",", "\n", "help", "=", "\"The attention type to use: \"", "\n", "\"dotprod or general (Luong) or MLP (Bahdanau)\"", ")", "\n", "group", ".", "add", "(", "'--global_attention_function'", ",", "'-global_attention_function'", ",", "\n", "type", "=", "str", ",", "default", "=", "\"softmax\"", ",", "choices", "=", "[", "\"softmax\"", ",", "\"sparsemax\"", "]", ")", "\n", "group", ".", "add", "(", "'--self_attn_type'", ",", "'-self_attn_type'", ",", "\n", "type", "=", "str", ",", "default", "=", "\"scaled-dot\"", ",", "\n", "help", "=", "'Self attention type in Transformer decoder '", "\n", "'layer -- currently \"scaled-dot\" or \"average\" '", ")", "\n", "group", ".", "add", "(", "'--max_relative_positions'", ",", "'-max_relative_positions'", ",", "\n", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Maximum distance between inputs in relative \"", "\n", "\"positions representations. \"", "\n", "\"For more detailed information, see: \"", "\n", "\"https://arxiv.org/pdf/1803.02155.pdf\"", ")", "\n", "group", ".", "add", "(", "'--heads'", ",", "'-heads'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Number of heads for transformer self-attention'", ")", "\n", "group", ".", "add", "(", "'--enc_heads'", ",", "'-enc_heads'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "'Number of heads for encoder transformer self-attention'", ")", "\n", "group", ".", "add", "(", "'--dec_heads'", ",", "'-dec_heads'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "'Number of heads for decoder transformer self-attention'", ")", "\n", "group", ".", "add", "(", "'--transformer_ff'", ",", "'-transformer_ff'", ",", "type", "=", "int", ",", "default", "=", "2048", ",", "\n", "help", "=", "'Size of hidden transformer feed-forward'", ")", "\n", "\n", "# Generator and loss options.", "\n", "group", ".", "add", "(", "'--copy_attn'", ",", "'-copy_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Train copy attention layer.'", ")", "\n", "group", ".", "add", "(", "'--copy_attn_type'", ",", "'-copy_attn_type'", ",", "\n", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "choices", "=", "[", "'dot'", ",", "'general'", ",", "'mlp'", ",", "'none'", "]", ",", "\n", "help", "=", "\"The copy attention type to use. Leave as None to use \"", "\n", "\"the same as -global_attention.\"", ")", "\n", "group", ".", "add", "(", "'--generator_function'", ",", "'-generator_function'", ",", "default", "=", "\"softmax\"", ",", "\n", "choices", "=", "[", "\"softmax\"", ",", "\"sparsemax\"", "]", ",", "\n", "help", "=", "\"Which function to use for generating \"", "\n", "\"probabilities over the target vocabulary (choices: \"", "\n", "\"softmax, sparsemax)\"", ")", "\n", "group", ".", "add", "(", "'--copy_attn_force'", ",", "'-copy_attn_force'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'When available, train to copy.'", ")", "\n", "group", ".", "add", "(", "'--reuse_copy_attn'", ",", "'-reuse_copy_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Reuse standard attention for copy\"", ")", "\n", "group", ".", "add", "(", "'--copy_loss_by_seqlength'", ",", "'-copy_loss_by_seqlength'", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Divide copy loss by length of sequence\"", ")", "\n", "group", ".", "add", "(", "'--coverage_attn'", ",", "'-coverage_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Train a coverage attention layer.'", ")", "\n", "group", ".", "add", "(", "'--lambda_coverage'", ",", "'-lambda_coverage'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n", "help", "=", "'Lambda value for coverage.'", ")", "\n", "group", ".", "add", "(", "'--loss_scale'", ",", "'-loss_scale'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"For FP16 training, the static loss scale to use. If not \"", "\n", "\"set, the loss scale is dynamically computed.\"", ")", "\n", "\n", "# Option most relevant to image input", "\n", "group", ".", "add", "(", "'--image_channel_size'", ",", "'-image_channel_size'", ",", "\n", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "\"Using grayscale image can training \"", "\n", "\"model faster and smaller\"", ")", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.opts.preprocess_opts": [[274, 409], ["parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add"], "function", ["None"], ["", "def", "preprocess_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\" Pre-procesing options \"\"\"", "\n", "# Data options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Data'", ")", "\n", "group", ".", "add", "(", "'--data_type'", ",", "'-data_type'", ",", "default", "=", "\"text\"", ",", "\n", "help", "=", "\"Type of the source input. \"", "\n", "\"Options are [text|img|audio|imgvec|none].\"", ")", "\n", "group", ".", "add", "(", "'--train_clf'", ",", "'-train_clf'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "group", ".", "add", "(", "'--train_src'", ",", "'-train_src'", ",", "\n", "help", "=", "\"Path to the training source data\"", ")", "\n", "\n", "group", ".", "add", "(", "'--train_label'", ",", "'-train_label'", ",", "\n", "help", "=", "\"Path to the human written label information\"", ")", "\n", "group", ".", "add", "(", "'--valid_label'", ",", "'-valid_label'", ",", "\n", "help", "=", "\"Path to the human written label information\"", ")", "\n", "group", ".", "add", "(", "'--train_tgt'", ",", "'-train_tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training target data\"", ")", "\n", "group", ".", "add", "(", "'--valid_src'", ",", "'-valid_src'", ",", "\n", "help", "=", "\"Path to the validation source data\"", ")", "\n", "group", ".", "add", "(", "'--valid_tgt'", ",", "'-valid_tgt'", ",", "\n", "help", "=", "\"Path to the validation target data\"", ")", "\n", "\n", "group", ".", "add", "(", "'--src_dir'", ",", "'-src_dir'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Source directory for image or audio files.\"", ")", "\n", "\n", "group", ".", "add", "(", "'--save_data'", ",", "'-save_data'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Output file for the prepared data\"", ")", "\n", "\n", "group", ".", "add", "(", "'--max_shard_size'", ",", "'-max_shard_size'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Deprecated use shard_size instead\"\"\"", ")", "\n", "\n", "group", ".", "add", "(", "'--shard_size'", ",", "'-shard_size'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "\"Divide src_corpus and tgt_corpus into \"", "\n", "\"smaller multiple src_copus and tgt corpus files, then \"", "\n", "\"build shards, each shard will have \"", "\n", "\"opt.shard_size samples except last shard. \"", "\n", "\"shard_size=0 means no segmentation \"", "\n", "\"shard_size>0 means segment dataset into multiple shards, \"", "\n", "\"each shard has shard_size samples\"", ")", "\n", "\n", "# Dictionary options, for text corpus", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Vocab'", ")", "\n", "group", ".", "add", "(", "'--src_vocab'", ",", "'-src_vocab'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Path to an existing source vocabulary. Format: \"", "\n", "\"one word per line.\"", ")", "\n", "group", ".", "add", "(", "'--tgt_vocab'", ",", "'-tgt_vocab'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Path to an existing target vocabulary. Format: \"", "\n", "\"one word per line.\"", ")", "\n", "group", ".", "add", "(", "'--features_vocabs_prefix'", ",", "'-features_vocabs_prefix'", ",", "\n", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "\"Path prefix to existing features vocabularies\"", ")", "\n", "group", ".", "add", "(", "'--src_vocab_size'", ",", "'-src_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "\"Size of the source vocabulary\"", ")", "\n", "group", ".", "add", "(", "'--tgt_vocab_size'", ",", "'-tgt_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "\"Size of the target vocabulary\"", ")", "\n", "group", ".", "add", "(", "'--vocab_size_multiple'", ",", "'-vocab_size_multiple'", ",", "\n", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Make the vocabulary size a multiple of this value\"", ")", "\n", "\n", "group", ".", "add", "(", "'--src_words_min_frequency'", ",", "\n", "'-src_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "group", ".", "add", "(", "'--tgt_words_min_frequency'", ",", "\n", "'-tgt_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "group", ".", "add", "(", "'--dynamic_dict'", ",", "'-dynamic_dict'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Create dynamic dictionaries\"", ")", "\n", "group", ".", "add", "(", "'--share_vocab'", ",", "'-share_vocab'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share source and target vocabulary\"", ")", "\n", "group", ".", "add", "(", "'--fixed_vocab'", ",", "'-fixed_vocab'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Do not modify the passed in vocab\"", ")", "\n", "group", ".", "add", "(", "'--free_src'", ",", "'-free_src'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Only modify the source vocab, keep the tgt fixed\"", ")", "\n", "group", ".", "add", "(", "'--free_tgt'", ",", "'-free_tgt'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Only modify the target vocab, keep the src fixed\"", ")", "\n", "group", ".", "add", "(", "'--no_spec_src'", ",", "'-no_spec_src'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Do not add any special source tokens.\"", ")", "\n", "group", ".", "add", "(", "'--no_spec_tgt'", ",", "'-no_spec_tgt'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Only extra bos tgt token\"", ")", "\n", "group", ".", "add", "(", "'--finetune_tokens'", ",", "'-finetune_tokens'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use a space as the bos token.\"", ")", "\n", "\n", "# Truncation options, for text corpus", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Pruning'", ")", "\n", "group", ".", "add", "(", "'--src_seq_length'", ",", "'-src_seq_length'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "\"Maximum source sequence length\"", ")", "\n", "group", ".", "add", "(", "'--src_seq_length_trunc'", ",", "'-src_seq_length_trunc'", ",", "\n", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Truncate source sequence length.\"", ")", "\n", "group", ".", "add", "(", "'--tgt_seq_length'", ",", "'-tgt_seq_length'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "\"Maximum target sequence length to keep.\"", ")", "\n", "group", ".", "add", "(", "'--tgt_seq_length_trunc'", ",", "'-tgt_seq_length_trunc'", ",", "\n", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Truncate target sequence length.\"", ")", "\n", "group", ".", "add", "(", "'--lower'", ",", "'-lower'", ",", "action", "=", "'store_true'", ",", "help", "=", "'lowercase data'", ")", "\n", "group", ".", "add", "(", "'--filter_valid'", ",", "'-filter_valid'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Filter validation data by src and/or tgt length'", ")", "\n", "\n", "# Data processing options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Random'", ")", "\n", "group", ".", "add", "(", "'--shuffle'", ",", "'-shuffle'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Shuffle data\"", ")", "\n", "group", ".", "add", "(", "'--seed'", ",", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "3435", ",", "\n", "help", "=", "\"Random seed\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add", "(", "'--report_every'", ",", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "\"Report status every this many sentences\"", ")", "\n", "group", ".", "add", "(", "'--log_file'", ",", "'-log_file'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Output logs to a file under this path.\"", ")", "\n", "group", ".", "add", "(", "'--log_file_level'", ",", "'-log_file_level'", ",", "type", "=", "str", ",", "\n", "action", "=", "StoreLoggingLevelAction", ",", "\n", "choices", "=", "StoreLoggingLevelAction", ".", "CHOICES", ",", "\n", "default", "=", "\"0\"", ")", "\n", "\n", "group", ".", "add", "(", "'--pointers_file'", ",", "'-pointers_file'", ",", "type", "=", "str", ",", "\n", "help", "=", "'path to file with pointer information'", ")", "\n", "\n", "# Options most relevant to speech", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "group", ".", "add", "(", "'--sample_rate'", ",", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add", "(", "'--window_size'", ",", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "\"Window size for spectrogram in seconds.\"", ")", "\n", "group", ".", "add", "(", "'--window_stride'", ",", "'-window_stride'", ",", "type", "=", "float", ",", "default", "=", ".01", ",", "\n", "help", "=", "\"Window stride for spectrogram in seconds.\"", ")", "\n", "group", ".", "add", "(", "'--window'", ",", "'-window'", ",", "default", "=", "'hamming'", ",", "\n", "help", "=", "\"Window type for spectrogram generation.\"", ")", "\n", "\n", "# Option most relevant to image input", "\n", "group", ".", "add", "(", "'--image_channel_size'", ",", "'-image_channel_size'", ",", "\n", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "choices", "=", "[", "3", ",", "1", "]", ",", "\n", "help", "=", "\"Using grayscale image can training \"", "\n", "\"model faster and smaller\"", ")", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.opts.train_opts": [[412, 660], ["parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add"], "function", ["None"], ["", "def", "train_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\" Training and saving options \"\"\"", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'General'", ")", "\n", "group", ".", "add", "(", "'--data'", ",", "'-data'", ",", "required", "=", "True", ",", "\n", "help", "=", "'Path prefix to the \".train.pt\" and '", "\n", "'\".valid.pt\" file path from preprocess.py'", ")", "\n", "\n", "group", ".", "add", "(", "'--save_model'", ",", "'-save_model'", ",", "default", "=", "'model'", ",", "\n", "help", "=", "\"Model filename (the model will be saved as \"", "\n", "\"<save_model>_N.pt where N is the number \"", "\n", "\"of steps\"", ")", "\n", "\n", "group", ".", "add", "(", "'--save_checkpoint_steps'", ",", "'-save_checkpoint_steps'", ",", "\n", "type", "=", "int", ",", "default", "=", "5000", ",", "\n", "help", "=", "\"\"\"Save a checkpoint every X steps\"\"\"", ")", "\n", "group", ".", "add", "(", "'--keep_checkpoint'", ",", "'-keep_checkpoint'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Keep X checkpoints (negative: keep all)\"", ")", "\n", "\n", "# GPU", "\n", "group", ".", "add", "(", "'--gpuid'", ",", "'-gpuid'", ",", "default", "=", "[", "]", ",", "nargs", "=", "'*'", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Deprecated see world_size and gpu_ranks.\"", ")", "\n", "group", ".", "add", "(", "'--gpu_ranks'", ",", "'-gpu_ranks'", ",", "default", "=", "[", "]", ",", "nargs", "=", "'*'", ",", "type", "=", "int", ",", "\n", "help", "=", "\"list of ranks of each process.\"", ")", "\n", "group", ".", "add", "(", "'--world_size'", ",", "'-world_size'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"total number of distributed processes.\"", ")", "\n", "group", ".", "add", "(", "'--gpu_backend'", ",", "'-gpu_backend'", ",", "\n", "default", "=", "\"nccl\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Type of torch distributed backend\"", ")", "\n", "group", ".", "add", "(", "'--gpu_verbose_level'", ",", "'-gpu_verbose_level'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Gives more info on each process per GPU.\"", ")", "\n", "group", ".", "add", "(", "'--master_ip'", ",", "'-master_ip'", ",", "default", "=", "\"localhost\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"IP of master for torch.distributed training.\"", ")", "\n", "group", ".", "add", "(", "'--master_port'", ",", "'-master_port'", ",", "default", "=", "10000", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Port of master for torch.distributed training.\"", ")", "\n", "\n", "group", ".", "add", "(", "'--seed'", ",", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Random seed used for the experiments \"", "\n", "\"reproducibility.\"", ")", "\n", "\n", "group", ".", "add", "(", "'--autorestart'", ",", "'-autorestart'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"If set, check for any saved checkpoints before starting.\"", ")", "\n", "\n", "# Init options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Initialization'", ")", "\n", "group", ".", "add", "(", "'--param_init'", ",", "'-param_init'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "\n", "help", "=", "\"Parameters are initialized over uniform distribution \"", "\n", "\"with support (-param_init, param_init). \"", "\n", "\"Use 0 to not use initialization\"", ")", "\n", "group", ".", "add", "(", "'--param_init_glorot'", ",", "'-param_init_glorot'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Init parameters with xavier_uniform. \"", "\n", "\"Required for transfomer.\"", ")", "\n", "\n", "group", ".", "add", "(", "'--train_from'", ",", "'-train_from'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"If training from a checkpoint then this is the \"", "\n", "\"path to the pretrained model's state_dict.\"", ")", "\n", "group", ".", "add", "(", "'--reset_optim'", ",", "'-reset_optim'", ",", "default", "=", "'none'", ",", "\n", "choices", "=", "[", "'none'", ",", "'all'", ",", "'states'", ",", "'keep_states'", "]", ",", "\n", "help", "=", "\"Optimization resetter when train_from.\"", ")", "\n", "group", ".", "add", "(", "'--load_uncond_from'", ",", "'-load_uncond_from'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"If training from a checkpoint then this is the \"", "\n", "\"path to the pretrained model's state_dict, for loading \"", "\n", "\"unconditional models into conditional models.\"", ")", "\n", "\n", "# Pretrained word vectors", "\n", "group", ".", "add", "(", "'--pre_word_vecs_enc'", ",", "'-pre_word_vecs_enc'", ",", "\n", "help", "=", "\"If a valid path is specified, then this will load \"", "\n", "\"pretrained word embeddings on the encoder side. \"", "\n", "\"See README for specific formatting instructions.\"", ")", "\n", "group", ".", "add", "(", "'--pre_word_vecs_dec'", ",", "'-pre_word_vecs_dec'", ",", "\n", "help", "=", "\"If a valid path is specified, then this will load \"", "\n", "\"pretrained word embeddings on the decoder side. \"", "\n", "\"See README for specific formatting instructions.\"", ")", "\n", "# Fixed word vectors", "\n", "group", ".", "add", "(", "'--fix_word_vecs_enc'", ",", "'-fix_word_vecs_enc'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the encoder side.\"", ")", "\n", "group", ".", "add", "(", "'--fix_word_vecs_dec'", ",", "'-fix_word_vecs_dec'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the decoder side.\"", ")", "\n", "\n", "# Optimization options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Optimization- Type'", ")", "\n", "group", ".", "add", "(", "'--batch_size'", ",", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "20", ",", "\n", "help", "=", "'Maximum batch size for training'", ")", "\n", "group", ".", "add", "(", "'--force_bs1'", ",", "'-force_bs1'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Force batch size multiple of 1.'", ")", "\n", "group", ".", "add", "(", "'--batch_type'", ",", "'-batch_type'", ",", "default", "=", "'sents'", ",", "\n", "choices", "=", "[", "\"sents\"", ",", "\"tokens\"", "]", ",", "\n", "help", "=", "\"Batch grouping for batch_size. Standard \"", "\n", "\"is sents. Tokens will do dynamic batching\"", ")", "\n", "group", ".", "add", "(", "'--normalization'", ",", "'-normalization'", ",", "default", "=", "'sents'", ",", "\n", "choices", "=", "[", "\"sents\"", ",", "\"tokens\"", "]", ",", "\n", "help", "=", "'Normalization method of the gradient.'", ")", "\n", "group", ".", "add", "(", "'--accum_count'", ",", "'-accum_count'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Accumulate gradient this many times. \"", "\n", "\"Approximately equivalent to updating \"", "\n", "\"batch_size * accum_count batches at once. \"", "\n", "\"Recommended for Transformer.\"", ")", "\n", "group", ".", "add", "(", "'--valid_steps'", ",", "'-valid_steps'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "'Perfom validation every X steps'", ")", "\n", "group", ".", "add", "(", "'--valid_batch_size'", ",", "'-valid_batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "'Maximum batch size for validation'", ")", "\n", "group", ".", "add", "(", "'--max_generator_batches'", ",", "'-max_generator_batches'", ",", "\n", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "\"Maximum batches of words in a sequence to run \"", "\n", "\"the generator on in parallel. Higher is faster, but \"", "\n", "\"uses more memory. Set to 0 to disable.\"", ")", "\n", "group", ".", "add", "(", "'--train_steps'", ",", "'-train_steps'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "'Number of training steps'", ")", "\n", "group", ".", "add", "(", "'--single_pass'", ",", "'-single_pass'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Make a single pass over the training dataset.\"", ")", "\n", "group", ".", "add", "(", "'--epochs'", ",", "'-epochs'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Deprecated epochs see train_steps'", ")", "\n", "group", ".", "add", "(", "'--optim'", ",", "'-optim'", ",", "default", "=", "'sgd'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "'adadelta'", ",", "'adam'", ",", "\n", "'sparseadam'", ",", "'adafactor'", ",", "'fusedadam'", "]", ",", "\n", "help", "=", "\"Optimization method.\"", ")", "\n", "group", ".", "add", "(", "'--adagrad_accumulator_init'", ",", "'-adagrad_accumulator_init'", ",", "\n", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Initializes the accumulator values in adagrad. \"", "\n", "\"Mirrors the initial_accumulator_value option \"", "\n", "\"in the tensorflow adagrad (use 0.1 for their default).\"", ")", "\n", "group", ".", "add", "(", "'--max_grad_norm'", ",", "'-max_grad_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "\n", "help", "=", "\"If the norm of the gradient vector exceeds this, \"", "\n", "\"renormalize it to have the norm equal to \"", "\n", "\"max_grad_norm\"", ")", "\n", "group", ".", "add", "(", "'--dropout'", ",", "'-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.3", ",", "\n", "help", "=", "\"Dropout probability; applied in LSTM stacks.\"", ")", "\n", "group", ".", "add", "(", "'--attn_dropout'", ",", "'-attn_dropout'", ",", "type", "=", "float", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Dropout probability applied to transformer attn blocks.\"", ")", "\n", "group", ".", "add", "(", "'--truncated_decoder'", ",", "'-truncated_decoder'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Truncated bptt.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--adam_beta1'", ",", "'-adam_beta1'", ",", "type", "=", "float", ",", "default", "=", "0.9", ",", "\n", "help", "=", "\"The beta1 parameter used by Adam. \"", "\n", "\"Almost without exception a value of 0.9 is used in \"", "\n", "\"the literature, seemingly giving good results, \"", "\n", "\"so we would discourage changing this value from \"", "\n", "\"the default without due consideration.\"", ")", "\n", "group", ".", "add", "(", "'--adam_beta2'", ",", "'-adam_beta2'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "\n", "help", "=", "'The beta2 parameter used by Adam. '", "\n", "'Typically a value of 0.999 is recommended, as this is '", "\n", "'the value suggested by the original paper describing '", "\n", "'Adam, and is also the value adopted in other frameworks '", "\n", "'such as Tensorflow and Kerras, i.e. see: '", "\n", "'https://www.tensorflow.org/api_docs/python/tf/train/Adam'", "\n", "'Optimizer or '", "\n", "'https://keras.io/optimizers/ . '", "\n", "'Whereas recently the paper \"Attention is All You Need\" '", "\n", "'suggested a value of 0.98 for beta2, this parameter may '", "\n", "'not work well for normal models / default '", "\n", "'baselines.'", ")", "\n", "group", ".", "add", "(", "'--label_smoothing'", ",", "'-label_smoothing'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "\"Label smoothing value epsilon. \"", "\n", "\"Probabilities of all non-true labels \"", "\n", "\"will be smoothed by epsilon / (vocab_size - 1). \"", "\n", "\"Set to zero to turn off label smoothing. \"", "\n", "\"For more detailed information, see: \"", "\n", "\"https://arxiv.org/abs/1512.00567\"", ")", "\n", "group", ".", "add", "(", "'--average_decay'", ",", "'-average_decay'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Moving average decay. \"", "\n", "\"Set to other than 0 (e.g. 1e-4) to activate. \"", "\n", "\"Similar to Marian NMT implementation: \"", "\n", "\"http://www.aclweb.org/anthology/P18-4020 \"", "\n", "\"For more detail on Exponential Moving Average: \"", "\n", "\"https://en.wikipedia.org/wiki/Moving_average\"", ")", "\n", "group", ".", "add", "(", "'--average_every'", ",", "'-average_every'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Step for moving average. \"", "\n", "\"Default is every update, \"", "\n", "\"if -average_decay is set.\"", ")", "\n", "\n", "# learning rate", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Optimization- Rate'", ")", "\n", "group", ".", "add", "(", "'--learning_rate'", ",", "'-learning_rate'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "\"Starting learning rate. \"", "\n", "\"Recommended settings: sgd = 1, adagrad = 0.1, \"", "\n", "\"adadelta = 1, adam = 0.001\"", ")", "\n", "group", ".", "add", "(", "'--learning_rate_decay'", ",", "'-learning_rate_decay'", ",", "\n", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "\"If update_learning_rate, decay learning rate by \"", "\n", "\"this much if steps have gone past \"", "\n", "\"start_decay_steps\"", ")", "\n", "group", ".", "add", "(", "'--start_decay_steps'", ",", "'-start_decay_steps'", ",", "\n", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"Start decaying every decay_steps after \"", "\n", "\"start_decay_steps\"", ")", "\n", "group", ".", "add", "(", "'--decay_steps'", ",", "'-decay_steps'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "\"Decay every decay_steps\"", ")", "\n", "\n", "group", ".", "add", "(", "'--decay_method'", ",", "'-decay_method'", ",", "type", "=", "str", ",", "default", "=", "\"none\"", ",", "\n", "choices", "=", "[", "'noam'", ",", "'rsqrt'", ",", "'none'", ",", "'stlr'", ",", "'invsq'", "]", ",", "\n", "help", "=", "\"Use a custom decay rate.\"", ")", "\n", "group", ".", "add", "(", "'--warmup_steps'", ",", "'-warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "4000", ",", "\n", "help", "=", "\"Number of warmup steps for custom decay.\"", ")", "\n", "group", ".", "add", "(", "'--warmup_init_factor'", ",", "'-warmup_init_factor'", ",", "type", "=", "int", ",", "default", "=", "5000", ",", "\n", "help", "=", "\"Ratio of max lr to initial lr for invsq decay scheme.\"", ")", "\n", "group", ".", "add", "(", "'--disc_ft'", ",", "'-disc_ft'", ",", "type", "=", "float", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Scale factor for discriminative fine-tuning.\"", ")", "\n", "group", ".", "add", "(", "'--dec_lr_factor'", ",", "'-dec_lr_factor'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "\"How much lower lr is for decoder, if using disc_ft.\"", ")", "\n", "group", ".", "add", "(", "'--full_gen_bias'", ",", "'-full_gen_bias'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"If true, train generator bias at full learning rate.\"", ")", "\n", "group", ".", "add", "(", "'--stlr_ratio'", ",", "'-stlr_ratio'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "\"Ratio of max learning rate to min learning rate for stlr.\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add", "(", "'--report_every'", ",", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Print stats at this interval.\"", ")", "\n", "group", ".", "add", "(", "'--log_file'", ",", "'-log_file'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Output logs to a file under this path.\"", ")", "\n", "group", ".", "add", "(", "'--log_file_level'", ",", "'-log_file_level'", ",", "type", "=", "str", ",", "\n", "action", "=", "StoreLoggingLevelAction", ",", "\n", "choices", "=", "StoreLoggingLevelAction", ".", "CHOICES", ",", "\n", "default", "=", "\"0\"", ")", "\n", "group", ".", "add", "(", "'--exp_host'", ",", "'-exp_host'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Send logs to this crayon server.\"", ")", "\n", "group", ".", "add", "(", "'--exp'", ",", "'-exp'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Name of the experiment for logging.\"", ")", "\n", "# Use TensorboardX for visualization during training", "\n", "group", ".", "add", "(", "'--tensorboard'", ",", "'-tensorboard'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Use tensorboardX for visualization during training. \"", "\n", "\"Must have the library tensorboardX.\"", ")", "\n", "group", ".", "add", "(", "\"--tensorboard_log_dir\"", ",", "\"-tensorboard_log_dir\"", ",", "\n", "type", "=", "str", ",", "default", "=", "\"runs/onmt\"", ",", "\n", "help", "=", "\"Log directory for Tensorboard. \"", "\n", "\"This is also the name of the run.\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "# Options most relevant to speech", "\n", "group", ".", "add", "(", "'--sample_rate'", ",", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add", "(", "'--window_size'", ",", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "\"Window size for spectrogram in seconds.\"", ")", "\n", "\n", "# Options for copy attn pointers", "\n", "group", ".", "add", "(", "'--use_copy_ptrs'", ",", "'-use_copy_ptrs'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'If set, train with GT copt pointers and switch loss'", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'MultiTask'", ")", "\n", "group", ".", "add", "(", "'--multi_task'", ",", "'-multi_task'", ",", "action", "=", "'store_true'", ")", "\n", "group", ".", "add", "(", "'--clf_task'", ",", "'-clf_task'", ",", "action", "=", "'store_true'", ")", "\n", "group", ".", "add", "(", "'--multi_task_lr'", ",", "'-multi_task_lr'", ",", "type", "=", "float", ",", "default", "=", "1e-3", ")", "\n", "group", ".", "add", "(", "'--multi_alpha'", ",", "'-multi_alpha'", ",", "type", "=", "float", ",", "default", "=", "1e-3", ")", "\n", "\n", "group", ".", "add", "(", "'--multi_task_finish'", ",", "'-multi_task_finish'", ",", "action", "=", "'store_true'", ")", "\n", "group", ".", "add", "(", "'--query_data'", ",", "'-query_data'", ",", "type", "=", "str", ")", "\n", "group", ".", "add", "(", "'--only_query'", ",", "'-only_query'", ",", "action", "=", "'store_true'", ")", "\n", "group", ".", "add", "(", "'--clf_path'", ",", "'-clf_path'", ",", "type", "=", "str", ",", "help", "=", "\"the path of fact reconstructor model\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.opts.translate_opts": [[663, 815], ["parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add"], "function", ["None"], ["", "def", "translate_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\" Translation / inference options \"\"\"", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model'", ")", "\n", "group", ".", "add", "(", "'--model'", ",", "'-model'", ",", "dest", "=", "'models'", ",", "metavar", "=", "'MODEL'", ",", "\n", "nargs", "=", "'+'", ",", "type", "=", "str", ",", "default", "=", "[", "]", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to model .pt file(s). \"", "\n", "\"Multiple models can be specified, \"", "\n", "\"for ensemble decoding.\"", ")", "\n", "group", ".", "add", "(", "'--fp32'", ",", "'-fp32'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Force the model to be in FP32 \"", "\n", "\"because FP16 is very slow on GTX1080(ti).\"", ")", "\n", "group", ".", "add", "(", "'--avg_raw_probs'", ",", "'-avg_raw_probs'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"If this is set, during ensembling scores from \"", "\n", "\"different models will be combined by averaging their \"", "\n", "\"raw probabilities and then taking the log. Otherwise, \"", "\n", "\"the log probabilities will be averaged directly. \"", "\n", "\"Necessary for models whose output layers can assign \"", "\n", "\"zero probability.\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Data'", ")", "\n", "group", ".", "add", "(", "'--data_type'", ",", "'-data_type'", ",", "default", "=", "\"text\"", ",", "\n", "help", "=", "\"Type of the source input. Options: [text|img|imgvec].\"", ")", "\n", "\n", "group", ".", "add", "(", "'--src'", ",", "'-src'", ",", "\n", "help", "=", "\"Source sequence to decode (one line per \"", "\n", "\"sequence)\"", ")", "\n", "group", ".", "add", "(", "'--src_dir'", ",", "'-src_dir'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'Source directory for image or audio files'", ")", "\n", "group", ".", "add", "(", "'--tgt'", ",", "'-tgt'", ",", "\n", "help", "=", "'True target sequence (optional)'", ")", "\n", "group", ".", "add", "(", "'--shard_size'", ",", "'-shard_size'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "\"Divide src and tgt (if applicable) into \"", "\n", "\"smaller multiple src and tgt files, then \"", "\n", "\"build shards, each shard will have \"", "\n", "\"opt.shard_size samples except last shard. \"", "\n", "\"shard_size=0 means no segmentation \"", "\n", "\"shard_size>0 means segment dataset into multiple shards, \"", "\n", "\"each shard has shard_size samples\"", ")", "\n", "group", ".", "add", "(", "'--output'", ",", "'-output'", ",", "\n", "help", "=", "\"Path to output the predictions (each line will \"", "\n", "\"be the decoded sequence\"", ")", "\n", "group", ".", "add", "(", "'--report_bleu'", ",", "'-report_bleu'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Report bleu score after translation, \"", "\n", "\"call tools/multi-bleu.perl on command line\"", ")", "\n", "group", ".", "add", "(", "'--report_rouge'", ",", "'-report_rouge'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Report rouge 1/2/3/L/SU4 score after translation \"", "\n", "\"call tools/test_rouge.py on command line\"", ")", "\n", "group", ".", "add", "(", "'--report_time'", ",", "'-report_time'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Report some translation time metrics\"", ")", "\n", "\n", "# Options most relevant to summarization.", "\n", "group", ".", "add", "(", "'--dynamic_dict'", ",", "'-dynamic_dict'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Create dynamic dictionaries\"", ")", "\n", "group", ".", "add", "(", "'--share_vocab'", ",", "'-share_vocab'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share source and target vocabulary\"", ")", "\n", "group", ".", "add", "(", "'--constraint_file'", ",", "'-constraint_file'", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path to allennlp output with copy attn constraints\"", ")", "\n", "group", ".", "add", "(", "'--bu_threshold'", ",", "'-bu_threshold'", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Threshold for bottom-up summarization external tags\"", ")", "\n", "group", ".", "add", "(", "'--extra_output_str'", ",", "'-extra_output_str'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Extra string to append to output\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Random Sampling'", ")", "\n", "group", ".", "add", "(", "'--random_sampling_topk'", ",", "'-random_sampling_topk'", ",", "\n", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Set this to -1 to do random sampling from full \"", "\n", "\"distribution. Set this to value k>1 to do random \"", "\n", "\"sampling restricted to the k most likely next tokens. \"", "\n", "\"Set this to 1 to use argmax or for doing beam \"", "\n", "\"search.\"", ")", "\n", "group", ".", "add", "(", "'--random_sampling_temp'", ",", "'-random_sampling_temp'", ",", "\n", "default", "=", "1.", ",", "type", "=", "float", ",", "\n", "help", "=", "\"If doing random sampling, divide the logits by \"", "\n", "\"this before computing softmax during decoding.\"", ")", "\n", "group", ".", "add", "(", "'--seed'", ",", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "829", ",", "\n", "help", "=", "\"Random seed\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Beam'", ")", "\n", "group", ".", "add", "(", "'--beam_size'", ",", "'-beam_size'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'Beam size'", ")", "\n", "group", ".", "add", "(", "'--min_length'", ",", "'-min_length'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Minimum prediction length'", ")", "\n", "group", ".", "add", "(", "'--max_length'", ",", "'-max_length'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "'Maximum prediction length.'", ")", "\n", "group", ".", "add", "(", "'--max_sent_length'", ",", "'-max_sent_length'", ",", "action", "=", "DeprecateAction", ",", "\n", "help", "=", "\"Deprecated, use `-max_length` instead\"", ")", "\n", "\n", "# Alpha and Beta values for Google Length + Coverage penalty", "\n", "# Described here: https://arxiv.org/pdf/1609.08144.pdf, Section 7", "\n", "group", ".", "add", "(", "'--stepwise_penalty'", ",", "'-stepwise_penalty'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Apply penalty at every decoding step. \"", "\n", "\"Helpful for summary penalty.\"", ")", "\n", "group", ".", "add", "(", "'--length_penalty'", ",", "'-length_penalty'", ",", "default", "=", "'none'", ",", "\n", "choices", "=", "[", "'none'", ",", "'wu'", ",", "'avg'", "]", ",", "\n", "help", "=", "\"Length Penalty to use.\"", ")", "\n", "group", ".", "add", "(", "'--coverage_penalty'", ",", "'-coverage_penalty'", ",", "default", "=", "'none'", ",", "\n", "choices", "=", "[", "'none'", ",", "'wu'", ",", "'summary'", "]", ",", "\n", "help", "=", "\"Coverage Penalty to use.\"", ")", "\n", "group", ".", "add", "(", "'--alpha'", ",", "'-alpha'", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "\n", "help", "=", "\"Google NMT length penalty parameter \"", "\n", "\"(higher = longer generation)\"", ")", "\n", "group", ".", "add", "(", "'--beta'", ",", "'-beta'", ",", "type", "=", "float", ",", "default", "=", "-", "0.", ",", "\n", "help", "=", "\"Coverage penalty parameter\"", ")", "\n", "group", ".", "add", "(", "'--block_ngram_repeat'", ",", "'-block_ngram_repeat'", ",", "\n", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Block repetition of ngrams during decoding.'", ")", "\n", "group", ".", "add", "(", "'--ignore_when_blocking'", ",", "'-ignore_when_blocking'", ",", "\n", "nargs", "=", "'+'", ",", "type", "=", "str", ",", "default", "=", "[", "]", ",", "\n", "help", "=", "\"Ignore these strings when blocking repeats. \"", "\n", "\"You want to block sentence delimiters.\"", ")", "\n", "group", ".", "add", "(", "'--replace_unk'", ",", "'-replace_unk'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Replace the generated UNK tokens with the \"", "\n", "\"source token that had highest attention weight. If \"", "\n", "\"phrase_table is provided, it will lookup the \"", "\n", "\"identified source token and give the corresponding \"", "\n", "\"target token. If it is not provided(or the identified \"", "\n", "\"source token does not exist in the table) then it \"", "\n", "\"will copy the source token\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add", "(", "'--verbose'", ",", "'-verbose'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Print scores and predictions for each sentence'", ")", "\n", "group", ".", "add", "(", "'--log_file'", ",", "'-log_file'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Output logs to a file under this path.\"", ")", "\n", "group", ".", "add", "(", "'--log_file_level'", ",", "'-log_file_level'", ",", "type", "=", "str", ",", "\n", "action", "=", "StoreLoggingLevelAction", ",", "\n", "choices", "=", "StoreLoggingLevelAction", ".", "CHOICES", ",", "\n", "default", "=", "\"0\"", ")", "\n", "group", ".", "add", "(", "'--attn_debug'", ",", "'-attn_debug'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Print best attn for each word'", ")", "\n", "group", ".", "add", "(", "'--dump_beam'", ",", "'-dump_beam'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'File to dump beam information to.'", ")", "\n", "group", ".", "add", "(", "'--n_best'", ",", "'-n_best'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"If verbose is set, will output the n_best \"", "\n", "\"decoded sentences\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Efficiency'", ")", "\n", "group", ".", "add", "(", "'--batch_size'", ",", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "'Batch size'", ")", "\n", "group", ".", "add", "(", "'--gpu'", ",", "'-gpu'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Device to run on\"", ")", "\n", "\n", "# Options most relevant to speech.", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "group", ".", "add", "(", "'--sample_rate'", ",", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add", "(", "'--window_size'", ",", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "'Window size for spectrogram in seconds'", ")", "\n", "group", ".", "add", "(", "'--window_stride'", ",", "'-window_stride'", ",", "type", "=", "float", ",", "default", "=", ".01", ",", "\n", "help", "=", "'Window stride for spectrogram in seconds'", ")", "\n", "group", ".", "add", "(", "'--window'", ",", "'-window'", ",", "default", "=", "'hamming'", ",", "\n", "help", "=", "'Window type for spectrogram generation'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.trainer.Trainer.__init__": [[95, 132], ["trainer.Trainer.model.train"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.NeuralGenerationDetection.RoBERTaDetect.train"], ["def", "__init__", "(", "self", ",", "model", ",", "train_loss", ",", "valid_loss", ",", "optim", ",", "\n", "trunc_size", "=", "0", ",", "shard_size", "=", "32", ",", "model_type", "=", "'text'", ",", "\n", "norm_method", "=", "\"sents\"", ",", "grad_accum_count", "=", "1", ",", "n_gpu", "=", "1", ",", "gpu_rank", "=", "1", ",", "\n", "gpu_verbose_level", "=", "0", ",", "report_manager", "=", "None", ",", "model_saver", "=", "None", ",", "\n", "average_decay", "=", "0", ",", "average_every", "=", "1", ",", "model_dtype", "=", "'fp32'", ",", "gpt2_params_std", "=", "-", "1", ",", "multi_alpha", "=", "0.001", ",", "multi_task", "=", "False", "\n", ")", ":", "\n", "# Basic attributes.", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "train_loss", "=", "train_loss", "\n", "self", ".", "valid_loss", "=", "valid_loss", "\n", "self", ".", "optim", "=", "optim", "\n", "self", ".", "trunc_size", "=", "trunc_size", "\n", "self", ".", "shard_size", "=", "shard_size", "\n", "self", ".", "model_type", "=", "model_type", "\n", "self", ".", "norm_method", "=", "norm_method", "\n", "self", ".", "grad_accum_count", "=", "grad_accum_count", "\n", "self", ".", "n_gpu", "=", "n_gpu", "\n", "self", ".", "gpu_rank", "=", "gpu_rank", "\n", "self", ".", "gpu_verbose_level", "=", "gpu_verbose_level", "\n", "self", ".", "report_manager", "=", "report_manager", "\n", "self", ".", "model_saver", "=", "model_saver", "\n", "self", ".", "average_decay", "=", "average_decay", "\n", "self", ".", "moving_average", "=", "None", "\n", "self", ".", "average_every", "=", "average_every", "\n", "self", ".", "model_dtype", "=", "model_dtype", "\n", "self", ".", "gpt2_params_std", "=", "gpt2_params_std", "\n", "self", ".", "multi_alpha", "=", "multi_alpha", "\n", "self", ".", "multi_task", "=", "multi_task", "\n", "\n", "assert", "grad_accum_count", ">", "0", "\n", "if", "grad_accum_count", ">", "1", ":", "\n", "            ", "assert", "self", ".", "trunc_size", "==", "0", ",", "\"\"\"To enable accumulated gradients,\n                   you must disable target sequence truncating.\"\"\"", "\n", "\n", "# Set model in training mode.", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.trainer.Trainer._accum_batches": [[133, 151], ["batches.append", "tgt[].ne().sum", "tgt[].ne().sum.item", "len", "isinstance", "tgt[].ne"], "methods", ["None"], ["", "def", "_accum_batches", "(", "self", ",", "iterator", ")", ":", "\n", "        ", "batches", "=", "[", "]", "\n", "normalization", "=", "0", "\n", "for", "batch", "in", "iterator", ":", "\n", "            ", "batches", ".", "append", "(", "batch", ")", "\n", "if", "self", ".", "norm_method", "==", "\"tokens\"", ":", "\n", "                ", "tgt", "=", "batch", ".", "tgt", "[", "0", "]", "if", "isinstance", "(", "batch", ".", "tgt", ",", "tuple", ")", "else", "batch", ".", "tgt", "\n", "num_tokens", "=", "tgt", "[", "1", ":", ",", ":", ",", "0", "]", ".", "ne", "(", "\n", "self", ".", "train_loss", ".", "padding_idx", ")", ".", "sum", "(", ")", "\n", "normalization", "+=", "num_tokens", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "                ", "normalization", "+=", "batch", ".", "batch_size", "\n", "", "if", "len", "(", "batches", ")", "==", "self", ".", "grad_accum_count", ":", "\n", "                ", "yield", "batches", ",", "normalization", "\n", "batches", "=", "[", "]", "\n", "normalization", "=", "0", "\n", "", "", "if", "batches", ":", "\n", "            ", "yield", "batches", ",", "normalization", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.trainer.Trainer._update_average": [[152, 165], ["max", "zip", "params.detach().float", "enumerate", "trainer.Trainer.model.parameters", "trainer.Trainer.model.parameters", "params.detach", "cpt.detach().float", "cpt.detach"], "methods", ["None"], ["", "", "def", "_update_average", "(", "self", ",", "step", ")", ":", "\n", "        ", "if", "self", ".", "moving_average", "is", "None", ":", "\n", "            ", "copy_params", "=", "[", "params", ".", "detach", "(", ")", ".", "float", "(", ")", "\n", "for", "params", "in", "self", ".", "model", ".", "parameters", "(", ")", "]", "\n", "self", ".", "moving_average", "=", "copy_params", "\n", "", "else", ":", "\n", "            ", "average_decay", "=", "max", "(", "self", ".", "average_decay", ",", "\n", "1", "-", "(", "step", "+", "1", ")", "/", "(", "step", "+", "10", ")", ")", "\n", "for", "(", "i", ",", "avg", ")", ",", "cpt", "in", "zip", "(", "enumerate", "(", "self", ".", "moving_average", ")", ",", "\n", "self", ".", "model", ".", "parameters", "(", ")", ")", ":", "\n", "                ", "self", ".", "moving_average", "[", "i", "]", "=", "(", "1", "-", "average_decay", ")", "*", "avg", "+", "cpt", ".", "detach", "(", ")", ".", "float", "(", ")", "*", "average_decay", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.trainer.Trainer.train": [[166, 272], ["onmt.utils.Statistics", "onmt.utils.Statistics", "trainer.Trainer._start_report_manager", "enumerate", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "itertools.islice", "trainer.Trainer._accum_batches", "trainer.Trainer._gradient_accumulation", "trainer.Trainer._maybe_report_training", "trainer.Trainer.model_saver.save", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "sum", "trainer.Trainer._update_average", "trainer.Trainer.optim.learning_rate", "trainer.Trainer.validate", "trainer.Trainer._maybe_gather_stats", "trainer.Trainer._report_step", "trainer.Trainer.model_saver.save", "onmt.utils.distributed.all_gather_list", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "trainer.Trainer.optim.learning_rate", "len"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.trainer.Trainer._start_report_manager", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.trainer.Trainer._accum_batches", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.trainer.Trainer._gradient_accumulation", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.trainer.Trainer._maybe_report_training", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.trainer.Trainer._update_average", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.learning_rate", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.trainer.Trainer.validate", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.trainer.Trainer._maybe_gather_stats", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.ReportMgr._report_step", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.learning_rate"], ["", "", "", "def", "train", "(", "self", ",", "\n", "train_iter", ",", "\n", "train_steps", ",", "\n", "\n", "save_checkpoint_steps", "=", "5000", ",", "\n", "valid_iter", "=", "None", ",", "\n", "valid_steps", "=", "10000", ")", ":", "\n", "        ", "\"\"\"\n        The main training loop by iterating over `train_iter` and possibly\n        running validation on `valid_iter`.\n\n        Args:\n            train_iter: A generator that returns the next training batch.\n            train_steps: Run training for this many iterations.\n            save_checkpoint_steps: Save a checkpoint every this many\n              iterations.\n            valid_iter: A generator that returns the next validation batch.\n            valid_steps: Run evaluation every this many iterations.\n\n        Returns:\n            The gathered statistics.\n        \"\"\"", "\n", "if", "valid_iter", "is", "None", ":", "\n", "            ", "logger", ".", "info", "(", "'Start training loop without validation...'", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "'Start training loop and validate every %d steps...'", ",", "\n", "valid_steps", ")", "\n", "\n", "", "total_stats", "=", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n", "report_stats", "=", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n", "self", ".", "_start_report_manager", "(", "start_time", "=", "total_stats", ".", "start_time", ")", "\n", "\n", "if", "self", ".", "gpt2_params_std", ">", "0", ":", "\n", "            ", "total_size", "=", "train_iter", ".", "total_size", "\n", "", "else", ":", "\n", "            ", "total_size", "=", "0", "\n", "\n", "", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "            ", "train_iter", "=", "itertools", ".", "islice", "(", "\n", "train_iter", ",", "self", ".", "gpu_rank", ",", "None", ",", "self", ".", "n_gpu", ")", "\n", "\n", "#torch.cuda.synchronize()", "\n", "#last_end_time = time.time()", "\n", "", "for", "i", ",", "(", "batches", ",", "normalization", ")", "in", "enumerate", "(", "\n", "self", ".", "_accum_batches", "(", "train_iter", ")", ")", ":", "\n", "#print('batch time: %0.5f' % (time.time() - last_end_time))", "\n", "            ", "step", "=", "self", ".", "optim", ".", "training_step", "\n", "\n", "if", "self", ".", "gpu_verbose_level", ">", "1", ":", "\n", "                ", "logger", ".", "info", "(", "\"GpuRank %d: index: %d\"", ",", "self", ".", "gpu_rank", ",", "i", ")", "\n", "", "if", "self", ".", "gpu_verbose_level", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"GpuRank %d: reduce_counter: %d \\\n                            n_minibatch %d\"", "\n", "%", "(", "self", ".", "gpu_rank", ",", "i", "+", "1", ",", "len", "(", "batches", ")", ")", ")", "\n", "\n", "", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "                ", "normalization", "=", "sum", "(", "onmt", ".", "utils", ".", "distributed", "\n", ".", "all_gather_list", "\n", "(", "normalization", ")", ")", "\n", "\n", "#torch.cuda.synchronize()", "\n", "#tt = time.time()", "\n", "", "self", ".", "_gradient_accumulation", "(", "\n", "batches", ",", "normalization", ",", "total_stats", ",", "\n", "report_stats", ",", "total_size", ",", "self", ".", "multi_alpha", ")", "\n", "#torch.cuda.synchronize()", "\n", "#print('grad time: %0.5f' % (time.time() - tt))", "\n", "\n", "if", "self", ".", "average_decay", ">", "0", "and", "i", "%", "self", ".", "average_every", "==", "0", ":", "\n", "                ", "self", ".", "_update_average", "(", "step", ")", "\n", "\n", "", "report_stats", "=", "self", ".", "_maybe_report_training", "(", "\n", "step", ",", "train_steps", ",", "\n", "self", ".", "optim", ".", "learning_rate", "(", ")", ",", "\n", "report_stats", ")", "\n", "\n", "if", "valid_iter", "is", "not", "None", "and", "step", "%", "valid_steps", "==", "0", ":", "\n", "                ", "if", "self", ".", "gpu_verbose_level", ">", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "'GpuRank %d: validate step %d'", "\n", "%", "(", "self", ".", "gpu_rank", ",", "step", ")", ")", "\n", "", "valid_stats", "=", "self", ".", "validate", "(", "\n", "valid_iter", ",", "moving_average", "=", "self", ".", "moving_average", ")", "\n", "if", "self", ".", "gpu_verbose_level", ">", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "'GpuRank %d: gather valid stat \\\n                                step %d'", "%", "(", "self", ".", "gpu_rank", ",", "step", ")", ")", "\n", "", "valid_stats", "=", "self", ".", "_maybe_gather_stats", "(", "valid_stats", ")", "\n", "if", "self", ".", "gpu_verbose_level", ">", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "'GpuRank %d: report stat step %d'", "\n", "%", "(", "self", ".", "gpu_rank", ",", "step", ")", ")", "\n", "", "self", ".", "_report_step", "(", "self", ".", "optim", ".", "learning_rate", "(", ")", ",", "\n", "step", ",", "valid_stats", "=", "valid_stats", ")", "\n", "\n", "", "if", "(", "self", ".", "model_saver", "is", "not", "None", "\n", "and", "(", "save_checkpoint_steps", "!=", "0", "\n", "and", "step", "%", "save_checkpoint_steps", "==", "0", ")", ")", ":", "\n", "                ", "self", ".", "model_saver", ".", "save", "(", "step", ",", "moving_average", "=", "self", ".", "moving_average", ")", "\n", "\n", "", "if", "train_steps", ">", "0", "and", "step", ">=", "train_steps", ":", "\n", "                ", "break", "\n", "\n", "#torch.cuda.synchronize()", "\n", "#last_end_time = time.time()", "\n", "\n", "", "", "if", "self", ".", "model_saver", "is", "not", "None", ":", "\n", "            ", "self", ".", "model_saver", ".", "save", "(", "step", ",", "moving_average", "=", "self", ".", "moving_average", ")", "\n", "", "return", "total_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.trainer.Trainer.validate": [[273, 323], ["copy.deepcopy.eval", "copy.deepcopy", "zip", "torch.no_grad", "onmt.utils.Statistics", "copy.deepcopy.train", "copy.deepcopy.parameters", "copy.deepcopy.", "trainer.Trainer.valid_loss", "onmt.utils.Statistics.update", "avg.data.half", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.NeuralGenerationDetection.RoBERTaDetect.eval", "home.repos.pwc.inspect_result.bigheiniu_FactGen.NeuralGenerationDetection.RoBERTaDetect.train", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.update"], ["", "def", "validate", "(", "self", ",", "valid_iter", ",", "moving_average", "=", "None", ")", ":", "\n", "        ", "\"\"\" Validate model.\n            valid_iter: validate data iterator\n        Returns:\n            :obj:`nmt.Statistics`: validation loss statistics\n        \"\"\"", "\n", "if", "moving_average", ":", "\n", "            ", "valid_model", "=", "deepcopy", "(", "self", ".", "model", ")", "\n", "for", "avg", ",", "param", "in", "zip", "(", "self", ".", "moving_average", ",", "\n", "valid_model", ".", "parameters", "(", ")", ")", ":", "\n", "                ", "param", ".", "data", "=", "avg", ".", "data", ".", "half", "(", ")", "if", "self", ".", "model_dtype", "==", "\"fp16\"", "else", "avg", ".", "data", "\n", "", "", "else", ":", "\n", "            ", "valid_model", "=", "self", ".", "model", "\n", "\n", "# Set model in validating mode.", "\n", "", "valid_model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "stats", "=", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n", "\n", "for", "batch", "in", "valid_iter", ":", "\n", "                ", "tgt", ",", "tgt_lengths", "=", "batch", ".", "tgt", "if", "isinstance", "(", "batch", ".", "tgt", ",", "tuple", ")", "else", "(", "batch", ".", "tgt", ",", "None", ")", "\n", "batch", ".", "tgt", "=", "tgt", "\n", "\n", "if", "self", ".", "model_type", "==", "'none'", ":", "\n", "                    ", "src", "=", "None", "\n", "src_lengths", "=", "None", "\n", "", "else", ":", "\n", "                    ", "src", ",", "src_lengths", "=", "batch", ".", "src", "if", "isinstance", "(", "batch", ".", "src", ",", "tuple", ")", "else", "(", "batch", ".", "src", ",", "None", ")", "\n", "\n", "# F-prop through the model.", "\n", "", "outputs", ",", "attns", "=", "valid_model", "(", "src", ",", "tgt", ",", "src_lengths", ",", "\n", "tgt_lengths", "=", "tgt_lengths", ")", "\n", "\n", "# Compute loss.", "\n", "_", ",", "batch_stats", "=", "self", ".", "valid_loss", "(", "batch", ",", "outputs", ",", "attns", ")", "\n", "\n", "# Update statistics.", "\n", "stats", ".", "update", "(", "batch_stats", ")", "\n", "\n", "", "", "if", "moving_average", ":", "\n", "            ", "del", "valid_model", "\n", "", "else", ":", "\n", "# Set model back to training mode.", "\n", "            ", "valid_model", ".", "train", "(", ")", "\n", "\n", "", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.trainer.Trainer._gradient_accumulation": [[324, 434], ["trainer.Trainer.optim.zero_grad", "tgt_outer.size", "hasattr", "range", "trainer.Trainer.optim.step", "isinstance", "trainer.Trainer.train_loss", "total_stats.update", "report_stats.update", "onmt.utils.distributed.all_reduce_and_rescale_tensors", "isinstance", "src_lengths.sum().item", "torch.clamp", "trainer.Trainer.optim.zero_grad", "trainer.Trainer.model", "trainer.Trainer.model.named_parameters", "trainer.Trainer.optim.step", "trainer.Trainer.model.decoder.detach_state", "float", "trainer.Trainer.model", "trainer.Trainer.model", "trainer.Trainer.optim.backward", "trainer.Trainer.optim.backward", "onmt.utils.distributed.all_reduce_and_rescale_tensors", "trainer.Trainer.model.parameters", "src_lengths.sum", "hasattr", "float", "trainer.Trainer.model.parameters"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.zero_grad", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor.step", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.update", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.update", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.zero_grad", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor.step", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerDecoder.detach_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.distributed.all_reduce_and_rescale_tensors"], ["", "def", "_gradient_accumulation", "(", "self", ",", "true_batches", ",", "normalization", ",", "total_stats", ",", "\n", "report_stats", ",", "N", ",", "multi_alpha", ")", ":", "\n", "        ", "if", "self", ".", "grad_accum_count", ">", "1", ":", "\n", "            ", "self", ".", "optim", ".", "zero_grad", "(", ")", "\n", "", "for", "batch", "in", "true_batches", ":", "\n", "\n", "            ", "tgt_outer", ",", "tgt_outer_lengths", "=", "batch", ".", "tgt", "if", "isinstance", "(", "batch", ".", "tgt", ",", "tuple", ")", "else", "(", "batch", ".", "tgt", ",", "None", ")", "\n", "batch", ".", "tgt", "=", "tgt_outer", "\n", "\n", "target_size", "=", "tgt_outer", ".", "size", "(", "0", ")", "\n", "# Truncated BPTT: reminder not compatible with accum > 1", "\n", "if", "self", ".", "trunc_size", ":", "\n", "                ", "trunc_size", "=", "self", ".", "trunc_size", "\n", "", "else", ":", "\n", "                ", "trunc_size", "=", "target_size", "\n", "\n", "", "if", "self", ".", "model_type", "==", "'none'", ":", "\n", "                ", "src", "=", "None", "\n", "src_lengths", "=", "None", "\n", "", "else", ":", "\n", "                ", "src", ",", "src_lengths", "=", "batch", ".", "src", "if", "isinstance", "(", "batch", ".", "src", ",", "tuple", ")", "else", "(", "batch", ".", "src", ",", "None", ")", "\n", "if", "src_lengths", "is", "not", "None", ":", "\n", "                    ", "report_stats", ".", "n_src_words", "+=", "src_lengths", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "", "bptt", "=", "False", "\n", "if", "hasattr", "(", "batch", ",", "'label'", ")", ":", "\n", "                ", "label", "=", "batch", ".", "label", "\n", "", "else", ":", "\n", "                ", "label", "=", "None", "\n", "\n", "", "for", "j", "in", "range", "(", "0", ",", "target_size", "-", "1", ",", "trunc_size", ")", ":", "\n", "# 1. Create truncated target.", "\n", "                ", "tgt", "=", "tgt_outer", "[", "j", ":", "j", "+", "trunc_size", "]", "\n", "if", "tgt_outer_lengths", "is", "not", "None", ":", "\n", "                    ", "tgt_lengths", "=", "torch", ".", "clamp", "(", "tgt_outer_lengths", "-", "j", ",", "0", ",", "trunc_size", ")", "\n", "", "else", ":", "\n", "                    ", "tgt_lengths", "=", "None", "\n", "\n", "# 2. F-prop all but generator.", "\n", "", "if", "self", ".", "grad_accum_count", "==", "1", ":", "\n", "                    ", "self", ".", "optim", ".", "zero_grad", "(", ")", "\n", "\n", "", "if", "self", ".", "multi_task", ":", "\n", "                    ", "if", "label", "!=", "None", ":", "\n", "                        ", "outputs", ",", "attns", ",", "multi_task_loss", "=", "self", ".", "model", "(", "src", ",", "tgt", ",", "src_lengths", ",", "bptt", "=", "bptt", ",", "tgt_lengths", "=", "tgt_lengths", ",", "facts", "=", "label", ")", "\n", "", "else", ":", "\n", "                        ", "outputs", ",", "attns", ",", "multi_task_loss", "=", "self", ".", "model", "(", "src", ",", "tgt", ",", "src_lengths", ",", "bptt", "=", "bptt", ",", "tgt_lengths", "=", "tgt_lengths", ",", "facts", "=", "src", ")", "\n", "\n", "", "", "else", ":", "\n", "                    ", "outputs", ",", "attns", "=", "self", ".", "model", "(", "src", ",", "tgt", ",", "src_lengths", ",", "bptt", "=", "bptt", ",", "tgt_lengths", "=", "tgt_lengths", ")", "\n", "# add specific loss here", "\n", "\n", "", "bptt", "=", "True", "\n", "\n", "# 3. Compute loss.", "\n", "loss", ",", "batch_stats", "=", "self", ".", "train_loss", "(", "\n", "batch", ",", "\n", "outputs", ",", "\n", "attns", ",", "\n", "normalization", "=", "normalization", ",", "\n", "shard_size", "=", "self", ".", "shard_size", ",", "\n", "trunc_start", "=", "j", ",", "\n", "trunc_size", "=", "trunc_size", ")", "\n", "\n", "# add specific loss here?", "\n", "\n", "if", "loss", "is", "not", "None", ":", "\n", "                    ", "if", "self", ".", "multi_task", ":", "\n", "                        ", "self", ".", "optim", ".", "backward", "(", "loss", "+", "multi_alpha", "*", "multi_task_loss", ")", "\n", "", "else", ":", "\n", "                        ", "self", ".", "optim", ".", "backward", "(", "loss", ")", "\n", "\n", "", "", "if", "self", ".", "gpt2_params_std", ">", "0", ":", "\n", "                    ", "for", "name", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                        ", "if", "p", ".", "requires_grad", "and", "p", ".", "grad", "is", "not", "None", "and", "hasattr", "(", "p", ",", "'orig'", ")", ":", "\n", "                            ", "p", ".", "grad", ".", "data", "+=", "(", "p", ".", "data", "-", "p", ".", "orig", ")", "/", "(", "N", "*", "self", ".", "gpt2_params_std", "**", "2", ")", "\n", "\n", "", "", "", "total_stats", ".", "update", "(", "batch_stats", ")", "\n", "report_stats", ".", "update", "(", "batch_stats", ")", "\n", "\n", "# 4. Update the parameters and statistics.", "\n", "if", "self", ".", "grad_accum_count", "==", "1", ":", "\n", "# Multi GPU gradient gather", "\n", "                    ", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "                        ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "\n", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "onmt", ".", "utils", ".", "distributed", ".", "all_reduce_and_rescale_tensors", "(", "\n", "grads", ",", "float", "(", "1", ")", ")", "\n", "", "self", ".", "optim", ".", "step", "(", ")", "\n", "\n", "# If truncated, don't backprop fully.", "\n", "# TO CHECK", "\n", "# if dec_state is not None:", "\n", "#    dec_state.detach()", "\n", "", "if", "self", ".", "model", ".", "decoder", ".", "state", "is", "not", "None", ":", "\n", "                    ", "self", ".", "model", ".", "decoder", ".", "detach_state", "(", ")", "\n", "\n", "# in case of multi step gradient accumulation,", "\n", "# update only after accum batches", "\n", "", "", "", "if", "self", ".", "grad_accum_count", ">", "1", ":", "\n", "            ", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "                ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "\n", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "onmt", ".", "utils", ".", "distributed", ".", "all_reduce_and_rescale_tensors", "(", "\n", "grads", ",", "float", "(", "1", ")", ")", "\n", "", "self", ".", "optim", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.trainer.Trainer._start_report_manager": [[435, 444], ["trainer.Trainer.report_manager.start"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.start"], ["", "", "def", "_start_report_manager", "(", "self", ",", "start_time", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Simple function to start report manager (if any)\n        \"\"\"", "\n", "if", "self", ".", "report_manager", "is", "not", "None", ":", "\n", "            ", "if", "start_time", "is", "None", ":", "\n", "                ", "self", ".", "report_manager", ".", "start", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "report_manager", ".", "start_time", "=", "start_time", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.trainer.Trainer._maybe_gather_stats": [[445, 459], ["onmt.utils.Statistics.all_gather_stats"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.all_gather_stats"], ["", "", "", "def", "_maybe_gather_stats", "(", "self", ",", "stat", ")", ":", "\n", "        ", "\"\"\"\n        Gather statistics in multi-processes cases\n\n        Args:\n            stat(:obj:onmt.utils.Statistics): a Statistics object to gather\n                or None (it returns None in this case)\n\n        Returns:\n            stat: the updated (or unchanged) stat object\n        \"\"\"", "\n", "if", "stat", "is", "not", "None", "and", "self", ".", "n_gpu", ">", "1", ":", "\n", "            ", "return", "onmt", ".", "utils", ".", "Statistics", ".", "all_gather_stats", "(", "stat", ")", "\n", "", "return", "stat", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.trainer.Trainer._maybe_report_training": [[460, 470], ["trainer.Trainer.report_manager.report_training"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.ReportMgrBase.report_training"], ["", "def", "_maybe_report_training", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "\n", "report_stats", ")", ":", "\n", "        ", "\"\"\"\n        Simple function to report training stats (if report_manager is set)\n        see `onmt.utils.ReportManagerBase.report_training` for doc\n        \"\"\"", "\n", "if", "self", ".", "report_manager", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "report_manager", ".", "report_training", "(", "\n", "step", ",", "num_steps", ",", "learning_rate", ",", "report_stats", ",", "\n", "multigpu", "=", "self", ".", "n_gpu", ">", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.trainer.Trainer._report_step": [[471, 481], ["trainer.Trainer.report_manager.report_step"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.ReportMgrBase.report_step"], ["", "", "def", "_report_step", "(", "self", ",", "learning_rate", ",", "step", ",", "train_stats", "=", "None", ",", "\n", "valid_stats", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Simple function to report stats (if report_manager is set)\n        see `onmt.utils.ReportManagerBase.report_step` for doc\n        \"\"\"", "\n", "if", "self", ".", "report_manager", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "report_manager", ".", "report_step", "(", "\n", "learning_rate", ",", "step", ",", "train_stats", "=", "train_stats", ",", "\n", "valid_stats", "=", "valid_stats", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.trainer.build_trainer": [[20, 68], ["onmt.utils.loss.build_loss_compute", "onmt.utils.loss.build_loss_compute", "onmt.utils.build_report_manager", "onmt.Trainer", "dict"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.build_loss_compute", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.build_loss_compute", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.build_report_manager"], ["def", "build_trainer", "(", "opt", ",", "device_id", ",", "model", ",", "fields", ",", "optim", ",", "model_saver", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Simplify `Trainer` creation based on user `opt`s*\n\n    Args:\n        opt (:obj:`Namespace`): user options (usually from argument parsing)\n        model (:obj:`onmt.models.NMTModel`): the model to train\n        fields (dict): dict of fields\n        optim (:obj:`onmt.utils.Optimizer`): optimizer used during training\n        data_type (str): string describing the type of data\n            e.g. \"text\", \"img\", \"audio\"\n        model_saver(:obj:`onmt.models.ModelSaverBase`): the utility object\n            used to save the model\n    \"\"\"", "\n", "\n", "tgt_field", "=", "dict", "(", "fields", ")", "[", "\"tgt\"", "]", ".", "base_field", "\n", "train_loss", "=", "onmt", ".", "utils", ".", "loss", ".", "build_loss_compute", "(", "model", ",", "tgt_field", ",", "opt", ")", "\n", "valid_loss", "=", "onmt", ".", "utils", ".", "loss", ".", "build_loss_compute", "(", "\n", "model", ",", "tgt_field", ",", "opt", ",", "train", "=", "False", ")", "\n", "\n", "trunc_size", "=", "opt", ".", "truncated_decoder", "# Badly named...", "\n", "shard_size", "=", "opt", ".", "max_generator_batches", "if", "opt", ".", "model_dtype", "==", "'fp32'", "else", "0", "\n", "norm_method", "=", "opt", ".", "normalization", "\n", "grad_accum_count", "=", "opt", ".", "accum_count", "\n", "n_gpu", "=", "opt", ".", "world_size", "\n", "average_decay", "=", "opt", ".", "average_decay", "\n", "average_every", "=", "opt", ".", "average_every", "\n", "if", "device_id", ">=", "0", ":", "\n", "        ", "gpu_rank", "=", "opt", ".", "gpu_ranks", "[", "device_id", "]", "\n", "", "else", ":", "\n", "        ", "gpu_rank", "=", "0", "\n", "n_gpu", "=", "0", "\n", "", "gpu_verbose_level", "=", "opt", ".", "gpu_verbose_level", "\n", "\n", "report_manager", "=", "onmt", ".", "utils", ".", "build_report_manager", "(", "opt", ")", "\n", "trainer", "=", "onmt", ".", "Trainer", "(", "model", ",", "train_loss", ",", "valid_loss", ",", "optim", ",", "trunc_size", ",", "\n", "shard_size", ",", "opt", ".", "model_type", ",", "norm_method", ",", "\n", "grad_accum_count", ",", "n_gpu", ",", "gpu_rank", ",", "\n", "gpu_verbose_level", ",", "report_manager", ",", "\n", "model_saver", "=", "model_saver", "if", "gpu_rank", "==", "0", "else", "None", ",", "\n", "average_decay", "=", "average_decay", ",", "\n", "average_every", "=", "average_every", ",", "\n", "model_dtype", "=", "opt", ".", "model_dtype", ",", "\n", "gpt2_params_std", "=", "opt", ".", "gpt2_params_std", ",", "\n", "multi_alpha", "=", "opt", ".", "multi_alpha", ",", "\n", "multi_task", "=", "opt", ".", "multi_task", "\n", ")", "\n", "return", "trainer", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.PadGen.__init__": [[121, 123], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "PadGen", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.PadGen.forward": [[124, 128], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "vals", ")", ":", "\n", "# Need to make this more general", "\n", "        ", "vals", "[", "...", ",", "50257", ":", "]", "=", "-", "1e10", "\n", "return", "vals", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings": [[28, 69], ["onmt.modules.Embeddings", "len"], "function", ["None"], ["def", "build_embeddings", "(", "opt", ",", "text_field", ",", "for_encoder", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        opt: the option in current environment.\n        text_field(TextMultiField): word and feats field.\n        for_encoder(bool): build Embeddings for encoder or decoder?\n    \"\"\"", "\n", "emb_dim", "=", "opt", ".", "src_word_vec_size", "if", "for_encoder", "else", "opt", ".", "tgt_word_vec_size", "\n", "\n", "pad_indices", "=", "[", "f", ".", "vocab", ".", "stoi", "[", "f", ".", "pad_token", "]", "for", "_", ",", "f", "in", "text_field", "]", "\n", "\n", "word_padding_idx", ",", "feat_pad_indices", "=", "pad_indices", "[", "0", "]", ",", "pad_indices", "[", "1", ":", "]", "\n", "\n", "num_embs", "=", "[", "len", "(", "f", ".", "vocab", ")", "for", "_", ",", "f", "in", "text_field", "]", "\n", "num_word_embeddings", ",", "num_feat_embeddings", "=", "num_embs", "[", "0", "]", ",", "num_embs", "[", "1", ":", "]", "\n", "\n", "fix_word_vecs", "=", "opt", ".", "fix_word_vecs_enc", "if", "for_encoder", "else", "opt", ".", "fix_word_vecs_dec", "\n", "\n", "pos_enc_learned", "=", "opt", ".", "position_encoding_learned_enc", "if", "for_encoder", "else", "opt", ".", "position_encoding_learned_dec", "\n", "GPT_representation_mode", "=", "opt", ".", "GPT_representation_mode", "if", "opt", ".", "GPT_representation_loc", "==", "'both'", "or", "(", "opt", ".", "GPT_representation_loc", "==", "'src'", "and", "for_encoder", ")", "or", "(", "opt", ".", "GPT_representation_loc", "==", "'tgt'", "and", "not", "for_encoder", ")", "else", "'none'", "\n", "\n", "emb", "=", "Embeddings", "(", "\n", "word_vec_size", "=", "emb_dim", ",", "\n", "position_encoding", "=", "opt", ".", "position_encoding", ",", "\n", "position_encoding_learned", "=", "pos_enc_learned", ",", "\n", "position_encoding_ctxsize", "=", "opt", ".", "position_encoding_ctxsize", ",", "\n", "feat_merge", "=", "opt", ".", "feat_merge", ",", "\n", "feat_vec_exponent", "=", "opt", ".", "feat_vec_exponent", ",", "\n", "feat_vec_size", "=", "opt", ".", "feat_vec_size", ",", "\n", "dropout", "=", "opt", ".", "dropout", ",", "\n", "word_padding_idx", "=", "word_padding_idx", ",", "\n", "feat_padding_idx", "=", "feat_pad_indices", ",", "\n", "word_vocab_size", "=", "num_word_embeddings", ",", "\n", "feat_vocab_sizes", "=", "num_feat_embeddings", ",", "\n", "sparse", "=", "opt", ".", "optim", "==", "\"sparseadam\"", ",", "\n", "fix_word_vecs", "=", "fix_word_vecs", ",", "\n", "GPT_representation_mode", "=", "GPT_representation_mode", ",", "\n", "GPT_representation_tgt", "=", "not", "for_encoder", "\n", ")", "\n", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_encoder": [[71, 80], ["str2enc[].from_opt"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt"], ["", "def", "build_encoder", "(", "opt", ",", "embeddings", ")", ":", "\n", "    ", "\"\"\"\n    Various encoder dispatcher function.\n    Args:\n        opt: the option in current environment.\n        embeddings (Embeddings): vocab embeddings for this encoder.\n    \"\"\"", "\n", "enc_type", "=", "opt", ".", "encoder_type", "if", "opt", ".", "model_type", "==", "\"text\"", "else", "opt", ".", "model_type", "\n", "return", "str2enc", "[", "enc_type", "]", ".", "from_opt", "(", "opt", ",", "embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_decoder": [[82, 92], ["str2dec[].from_opt"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt"], ["", "def", "build_decoder", "(", "opt", ",", "embeddings", ")", ":", "\n", "    ", "\"\"\"\n    Various decoder dispatcher function.\n    Args:\n        opt: the option in current environment.\n        embeddings (Embeddings): vocab embeddings for this decoder.\n    \"\"\"", "\n", "dec_type", "=", "\"ifrnn\"", "if", "opt", ".", "decoder_type", "==", "\"rnn\"", "and", "opt", ".", "input_feed", "else", "opt", ".", "decoder_type", "\n", "return", "str2dec", "[", "dec_type", "]", ".", "from_opt", "(", "opt", ",", "embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.load_test_model": [[94, 119], ["torch.load", "torch.load", "onmt.utils.parse.ArgumentParser.ckpt_model_opts", "onmt.utils.parse.ArgumentParser.update_model_opts", "onmt.utils.parse.ArgumentParser.validate_model_opts", "onmt.old_style_vocab", "model_builder.build_base_model", "build_base_model.eval", "build_base_model.generator.eval", "onmt.load_old_vocab", "onmt.utils.misc.use_gpu", "build_base_model.float"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.ckpt_model_opts", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.update_model_opts", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.validate_model_opts", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.old_style_vocab", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_base_model", "home.repos.pwc.inspect_result.bigheiniu_FactGen.NeuralGenerationDetection.RoBERTaDetect.eval", "home.repos.pwc.inspect_result.bigheiniu_FactGen.NeuralGenerationDetection.RoBERTaDetect.eval", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.load_old_vocab", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.use_gpu"], ["", "def", "load_test_model", "(", "opt", ",", "model_path", "=", "None", ")", ":", "\n", "    ", "if", "model_path", "is", "None", ":", "\n", "        ", "model_path", "=", "opt", ".", "models", "[", "0", "]", "\n", "", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "\n", "model_opt", "=", "ArgumentParser", ".", "ckpt_model_opts", "(", "checkpoint", "[", "'opt'", "]", ")", "\n", "ArgumentParser", ".", "update_model_opts", "(", "model_opt", ")", "\n", "ArgumentParser", ".", "validate_model_opts", "(", "model_opt", ")", "\n", "vocab", "=", "checkpoint", "[", "'vocab'", "]", "\n", "if", "inputters", ".", "old_style_vocab", "(", "vocab", ")", ":", "\n", "        ", "fields", "=", "inputters", ".", "load_old_vocab", "(", "\n", "vocab", ",", "opt", ".", "data_type", ",", "dynamic_dict", "=", "model_opt", ".", "copy_attn", "\n", ")", "\n", "", "else", ":", "\n", "        ", "fields", "=", "vocab", "\n", "\n", "", "model", "=", "build_base_model", "(", "model_opt", ",", "fields", ",", "use_gpu", "(", "opt", ")", ",", "checkpoint", ",", "\n", "opt", ".", "gpu", ")", "\n", "if", "opt", ".", "fp32", ":", "\n", "        ", "model", ".", "float", "(", ")", "\n", "\n", "", "model", ".", "eval", "(", ")", "\n", "model", ".", "generator", ".", "eval", "(", ")", "\n", "return", "fields", ",", "model", ",", "model_opt", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_base_model": [[130, 582], ["model_builder.build_encoder", "model_builder.build_embeddings", "model_builder.build_decoder", "onmt.models.NMTModel.to", "onmt.models.NMTModel.parameters", "model_builder.build_embeddings", "torch.device", "torch.device", "copy.deepcopy", "model_builder.build_embeddings", "onmt.utils.logging.logger.info", "model_builder.build_decoder", "onmt.models.SimpleFusionModel", "onmt.models.SimpleFusionModel", "onmt.modules.SimpleFusionGenerator", "build_decoder.named_parameters", "hasattr", "load_decoder.layer_norm.named_parameters", "load_decoder.transformer_layers.named_parameters", "onmt.models.NMTModel.decoder.named_parameters", "onmt.modules.CopyGenerator.parameters", "onmt.models.NMTModel.decoder.parameters", "build_decoder.parameters", "onmt.modules.CopyGenerator.lm_linear.parameters", "onmt.models.NMTModel.half", "hasattr", "torch.device", "torch.device", "len", "onmt.models.UncondModel", "onmt.models.UncondModel", "torch.Sequential", "len", "onmt.modules.CopyGenerator", "name.split.split", "setattr", "onmt.models.NMTModel.load_state_dict", "onmt.modules.CopyGenerator.load_state_dict", "torch.load", "torch.load", "onmt.models.NMTModel.multi_task_model.load_state_dict", "onmt.models.NMTModel.parameters", "onmt.modules.CopyGenerator.parameters", "onmt.models.NMTModel.parameters", "onmt.modules.CopyGenerator.parameters", "hasattr", "onmt.models.NMTModel.encoder.embeddings.load_pretrained_vectors", "onmt.models.NMTModel.decoder.embeddings.load_pretrained_vectors", "p.orig.to", "torch.device", "torch.device", "onmt.modules.clsAttention.SequenceSummary", "onmt.models.MultiTask.MultiTask", "onmt.modules.sparse_activations.LogSparsemax", "onmt.modules.sparse_activations.LogSparsemax", "torch.LogSoftmax", "torch.Sequential", "torch.Linear", "onmt.modules.util_class.Cast", "getattr", "re.sub", "re.sub", "model_builder.build_base_model.fix_key"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_encoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.load_state_dict", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.load_state_dict", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.load_state_dict", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.image_encoder.ImageEncoder.load_pretrained_vectors", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.image_encoder.ImageEncoder.load_pretrained_vectors"], ["", "", "def", "build_base_model", "(", "model_opt", ",", "fields", ",", "gpu", ",", "checkpoint", "=", "None", ",", "gpu_id", "=", "None", ")", ":", "\n", "    ", "\"\"\"Build a model from opts.\n\n    Args:\n        model_opt: the option loaded from checkpoint. It's important that\n            the opts have been updated and validated. See\n            :class:`onmt.utils.parse.ArgumentParser`.\n        fields (dict[str, torchtext.data.Field]):\n            `Field` objects for the model.\n        gpu (bool): whether to use gpu.\n        checkpoint: the model gnerated by train phase, or a resumed snapshot\n                    model from a stopped training.\n        gpu_id (int or NoneType): Which GPU to use.\n\n    Returns:\n        the NMTModel.\n    \"\"\"", "\n", "\n", "# Build embeddings.", "\n", "if", "model_opt", ".", "model_type", "==", "\"text\"", ":", "\n", "        ", "src_field", "=", "fields", "[", "\"src\"", "]", "\n", "src_emb", "=", "build_embeddings", "(", "model_opt", ",", "src_field", ")", "\n", "", "else", ":", "\n", "        ", "src_emb", "=", "None", "\n", "\n", "# Build encoder.", "\n", "", "encoder", "=", "build_encoder", "(", "model_opt", ",", "src_emb", ")", "\n", "\n", "# Build decoder.", "\n", "tgt_field", "=", "fields", "[", "\"tgt\"", "]", "\n", "tgt_emb", "=", "build_embeddings", "(", "model_opt", ",", "tgt_field", ",", "for_encoder", "=", "False", ")", "\n", "\n", "# Share the embedding matrix - preprocess with share_vocab required.", "\n", "if", "model_opt", ".", "share_embeddings", ":", "\n", "# src/tgt vocab should be the same if `-share_vocab` is specified.", "\n", "        ", "assert", "src_field", ".", "base_field", ".", "vocab", "==", "tgt_field", ".", "base_field", ".", "vocab", ",", "\"preprocess with -share_vocab if you use share_embeddings\"", "\n", "\n", "tgt_emb", ".", "word_lut", ".", "weight", "=", "src_emb", ".", "word_lut", ".", "weight", "\n", "\n", "", "if", "model_opt", ".", "share_position_embeddings", ":", "\n", "        ", "tgt_emb", ".", "make_embedding", ".", "pe", ".", "pe", ".", "weight", "=", "src_emb", ".", "make_embedding", ".", "pe", ".", "pe", ".", "weight", "\n", "\n", "", "decoder", "=", "build_decoder", "(", "model_opt", ",", "tgt_emb", ")", "\n", "\n", "# Build NMTModel(= encoder + decoder).", "\n", "if", "gpu", "and", "gpu_id", "is", "not", "None", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "gpu_id", ")", "\n", "", "elif", "gpu", "and", "not", "gpu_id", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "elif", "not", "gpu", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "# Build separate LM if doing simple fusion", "\n", "", "if", "model_opt", ".", "simple_fusion", ":", "\n", "        ", "layers", "=", "12", "\n", "size", "=", "768", "\n", "heads", "=", "12", "\n", "\n", "lm_decoder_opt", "=", "copy", ".", "deepcopy", "(", "model_opt", ")", "\n", "lm_decoder_opt", ".", "dec_layers", "=", "layers", "\n", "lm_decoder_opt", ".", "use_GPT_version_ctxattn", "=", "False", "\n", "lm_decoder_opt", ".", "use_GPT_version_psa", "=", "False", "\n", "lm_decoder_opt", ".", "use_GPT_version_unconditional", "=", "True", "\n", "lm_decoder_opt", ".", "tgt_word_vec_size", "=", "size", "\n", "lm_decoder_opt", ".", "rnn_size", "=", "size", "\n", "lm_decoder_opt", ".", "dec_rnn_size", "=", "size", "\n", "lm_decoder_opt", ".", "transformer_ff", "=", "size", "*", "4", "\n", "lm_decoder_opt", ".", "dec_heads", "=", "heads", "\n", "lm_decoder_opt", ".", "position_encoding_learned_dec", "=", "True", "\n", "lm_decoder_opt", ".", "share_decoder_embeddings", "=", "True", "\n", "lm_decoder_opt", ".", "dropout", "=", "0", "\n", "\n", "lm_decoder_emb", "=", "build_embeddings", "(", "lm_decoder_opt", ",", "tgt_field", ",", "for_encoder", "=", "False", ")", "\n", "logger", ".", "info", "(", "lm_decoder_emb", ")", "\n", "\n", "lm_decoder", "=", "build_decoder", "(", "lm_decoder_opt", ",", "lm_decoder_emb", ")", "\n", "load_decoder", "=", "lm_decoder", "\n", "\n", "model", "=", "onmt", ".", "models", ".", "SimpleFusionModel", "(", "encoder", ",", "decoder", ",", "lm_decoder", ")", "\n", "\n", "generator", "=", "SimpleFusionGenerator", "(", "model_opt", ".", "dec_rnn_size", ",", "\n", "lm_decoder_opt", ".", "dec_rnn_size", ",", "\n", "len", "(", "fields", "[", "\"tgt\"", "]", ".", "base_field", ".", "vocab", ")", ")", "\n", "generator", ".", "lm_linear", ".", "weight", "=", "lm_decoder", ".", "embeddings", ".", "word_lut", ".", "weight", "\n", "\n", "if", "model_opt", ".", "share_decoder_embeddings", ":", "\n", "            ", "generator", ".", "decoder_linear", ".", "weight", "=", "decoder", ".", "embeddings", ".", "word_lut", ".", "weight", "\n", "", "gen_linear", "=", "generator", ".", "lm_linear", "\n", "", "else", ":", "\n", "#", "\n", "        ", "load_decoder", "=", "decoder", "\n", "if", "model_opt", ".", "unconditional", ":", "\n", "            ", "model", "=", "onmt", ".", "models", ".", "UncondModel", "(", "decoder", ")", "\n", "", "elif", "model_opt", ".", "clf_task", ":", "\n", "            ", "clf_model", "=", "clsAttention", ".", "SequenceSummary", "(", ")", "\n", "model", "=", "MultiTask", ".", "MultiTask", "(", "encoder", ",", "decoder", ",", "clf_model", ")", "\n", "", "elif", "model_opt", ".", "multi_task", ":", "\n", "            ", "cls_model", "=", "clsAttention", ".", "CLSAtten", "(", ")", "\n", "model", "=", "MultiTask", ".", "MultiTask", "(", "encoder", ",", "decoder", ",", "cls_model", ")", "\n", "\n", "", "else", ":", "\n", "            ", "model", "=", "onmt", ".", "models", ".", "NMTModel", "(", "encoder", ",", "decoder", ")", "\n", "\n", "# Build Generator.", "\n", "", "if", "not", "model_opt", ".", "copy_attn", ":", "\n", "            ", "if", "model_opt", ".", "generator_function", "==", "\"sparsemax\"", ":", "\n", "                ", "gen_func", "=", "onmt", ".", "modules", ".", "sparse_activations", ".", "LogSparsemax", "(", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "gen_func", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "", "if", "model_opt", ".", "padded_vocab_fix_me_later", ":", "\n", "                ", "gen_func", "=", "nn", ".", "Sequential", "(", "PadGen", "(", ")", ",", "gen_func", ")", "\n", "\n", "", "generator", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "model_opt", ".", "dec_rnn_size", ",", "\n", "len", "(", "fields", "[", "\"tgt\"", "]", ".", "base_field", ".", "vocab", ")", ")", ",", "\n", "Cast", "(", "torch", ".", "float32", ")", ",", "\n", "gen_func", "\n", ")", "\n", "if", "model_opt", ".", "share_decoder_embeddings", ":", "\n", "                ", "generator", "[", "0", "]", ".", "weight", "=", "decoder", ".", "embeddings", ".", "word_lut", ".", "weight", "\n", "", "gen_linear", "=", "generator", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "tgt_base_field", "=", "fields", "[", "\"tgt\"", "]", ".", "base_field", "\n", "vocab_size", "=", "len", "(", "tgt_base_field", ".", "vocab", ")", "\n", "pad_idx", "=", "tgt_base_field", ".", "vocab", ".", "stoi", "[", "tgt_base_field", ".", "pad_token", "]", "\n", "generator", "=", "CopyGenerator", "(", "model_opt", ".", "dec_rnn_size", ",", "vocab_size", ",", "pad_idx", ")", "\n", "if", "model_opt", ".", "share_decoder_embeddings", ":", "\n", "                ", "generator", ".", "linear", ".", "weight", "=", "decoder", ".", "embeddings", ".", "word_lut", ".", "weight", "\n", "", "gen_linear", "=", "generator", ".", "linear", "\n", "\n", "", "", "if", "model_opt", ".", "encdec_share_params", ":", "\n", "# ATTENTION: copy the parameters from the decoder", "\n", "        ", "for", "name", ",", "p", "in", "decoder", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "'ctx'", "in", "name", "or", "'context'", "in", "name", ":", "\n", "                ", "continue", "\n", "", "pointer", "=", "encoder", "\n", "attrs", "=", "name", ".", "split", "(", "'.'", ")", "\n", "for", "attr_name", "in", "attrs", "[", ":", "-", "1", "]", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "attr_name", ")", "\n", "\n", "# pointer now has the encoder version of the parameter parent", "\n", "", "setattr", "(", "pointer", ",", "attrs", "[", "-", "1", "]", ",", "p", ")", "\n", "\n", "\n", "# Load the model states from checkpoint or initialize them.", "\n", "", "", "if", "checkpoint", "is", "not", "None", ":", "\n", "# Normally, just load the model parameters from checkpoint", "\n", "        ", "if", "'gpt2_params'", "not", "in", "checkpoint", "and", "'enc_model'", "not", "in", "checkpoint", ":", "\n", "# This preserves backward-compat for models using customed layernorm", "\n", "            ", "def", "fix_key", "(", "s", ")", ":", "\n", "                ", "s", "=", "re", ".", "sub", "(", "r'(.*)\\.layer_norm((_\\d+)?)\\.b_2'", ",", "\n", "r'\\1.layer_norm\\2.bias'", ",", "s", ")", "\n", "s", "=", "re", ".", "sub", "(", "r'(.*)\\.layer_norm((_\\d+)?)\\.a_2'", ",", "\n", "r'\\1.layer_norm\\2.weight'", ",", "s", ")", "\n", "return", "s", "\n", "\n", "", "checkpoint", "[", "'model'", "]", "=", "{", "fix_key", "(", "k", ")", ":", "v", "\n", "for", "k", ",", "v", "in", "checkpoint", "[", "'model'", "]", ".", "items", "(", ")", "}", "\n", "# end of patch for backward compatibility", "\n", "\n", "# Initialize rest of parameters normally", "\n", "if", "hasattr", "(", "model_opt", ",", "'load_uncond_from'", ")", "and", "model_opt", ".", "load_uncond_from", ":", "\n", "                ", "for", "p", "in", "decoder", ".", "parameters", "(", ")", ":", "\n", "                    ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                        ", "xavier_uniform_", "(", "p", ")", "\n", "\n", "# Always initialize encoder parameters normally", "\n", "", "", "for", "p", "in", "encoder", ".", "parameters", "(", ")", ":", "\n", "                    ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                        ", "xavier_uniform_", "(", "p", ")", "\n", "\n", "", "", "if", "model_opt", ".", "ctx_weight_param", ":", "\n", "                    ", "for", "name", ",", "p", "in", "decoder", ".", "named_parameters", "(", ")", ":", "\n", "                        ", "if", "'ctx_weight'", "in", "name", ":", "\n", "                            ", "p", ".", "data", ".", "zero_", "(", ")", "\n", "", "if", "'ctx_bias'", "in", "name", ":", "\n", "                            ", "p", ".", "data", ".", "fill_", "(", "-", "10", ")", "\n", "\n", "\n", "", "", "", "", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ",", "strict", "=", "False", ")", "\n", "generator", ".", "load_state_dict", "(", "checkpoint", "[", "'generator'", "]", ",", "strict", "=", "False", ")", "\n", "", "else", ":", "\n", "# load the gpt parameters", "\n", "            ", "if", "'gpt2_params'", "in", "checkpoint", ":", "\n", "                ", "init_something", "=", "model_opt", ".", "gpt2_init_embanddec", "or", "model_opt", ".", "simple_fusion", "or", "model_opt", ".", "gpt2_init_embandenc", "or", "model_opt", ".", "GPT_representation_mode", "!=", "'none'", "\n", "\n", "if", "init_something", ":", "\n", "# Initialize all the weights first", "\n", "                    ", "if", "model_opt", ".", "gpt2_init_zero", ":", "\n", "                        ", "for", "p", "in", "decoder", ".", "parameters", "(", ")", ":", "\n", "                            ", "p", ".", "data", ".", "zero_", "(", ")", "\n", "", "if", "model_opt", ".", "simple_fusion", ":", "\n", "                            ", "generator", ".", "decoder_linear", ".", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "generator", ".", "decoder_linear", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "else", ":", "\n", "                        ", "for", "p", "in", "decoder", ".", "parameters", "(", ")", ":", "\n", "                            ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                                ", "xavier_uniform_", "(", "p", ")", "\n", "\n", "# Always initialize encoder parameters normally", "\n", "", "", "", "if", "encoder", "is", "not", "None", ":", "\n", "                        ", "for", "p", "in", "encoder", ".", "parameters", "(", ")", ":", "\n", "                            ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                                ", "xavier_uniform_", "(", "p", ")", "\n", "", "", "", "for", "p", "in", "generator", ".", "parameters", "(", ")", ":", "\n", "                        ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                            ", "xavier_uniform_", "(", "p", ")", "\n", "", "", "if", "model_opt", ".", "zero_bias_init", ":", "\n", "                        ", "gen_linear", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n", "", "if", "model_opt", ".", "ctx_weight_param", ":", "\n", "                        ", "for", "name", ",", "p", "in", "decoder", ".", "named_parameters", "(", ")", ":", "\n", "                            ", "if", "'ctx_weight'", "in", "name", ":", "\n", "                                ", "p", ".", "data", ".", "zero_", "(", ")", "\n", "", "if", "'ctx_bias'", "in", "name", ":", "\n", "                                ", "p", ".", "data", ".", "fill_", "(", "-", "10", ")", "\n", "", "", "gen_linear", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n", "", "", "load_models", "=", "[", "]", "\n", "if", "model_opt", ".", "GPT_representation_mode", "!=", "'none'", ":", "\n", "                    ", "load_embs", "=", "[", "]", "\n", "if", "model_opt", ".", "GPT_representation_loc", "in", "[", "'both'", ",", "'src'", "]", ":", "\n", "                        ", "load_models", ".", "append", "(", "src_emb", ".", "gpt_model", ")", "\n", "load_embs", ".", "append", "(", "src_emb", ")", "\n", "", "if", "model_opt", ".", "GPT_representation_loc", "in", "[", "'both'", ",", "'tgt'", "]", ":", "\n", "                        ", "load_models", ".", "append", "(", "tgt_emb", ".", "gpt_model", ")", "\n", "load_embs", ".", "append", "(", "tgt_emb", ")", "\n", "\n", "", "", "else", ":", "\n", "                    ", "if", "model_opt", ".", "gpt2_init_embanddec", "or", "model_opt", ".", "simple_fusion", ":", "\n", "                        ", "load_models", "=", "[", "load_decoder", "]", "\n", "", "elif", "model_opt", ".", "gpt2_init_embandenc", ":", "\n", "                        ", "load_models", "=", "[", "encoder", "]", "\n", "\n", "", "", "it_list", "=", "list", "(", "checkpoint", "[", "'gpt2_params'", "]", ")", "\n", "for", "lm_idx", ",", "load_model", "in", "enumerate", "(", "load_models", ")", ":", "\n", "#print(lm_idx, load_model)", "\n", "                    ", "for", "name", ",", "array", "in", "it_list", ":", "\n", "                        ", "name", "=", "name", "[", "6", ":", "]", "# skip \"model/\"", "\n", "name", "=", "name", ".", "split", "(", "'/'", ")", "\n", "\n", "assigned", "=", "False", "\n", "if", "name", "[", "0", "]", "==", "'wpe'", ":", "\n", "                            ", "if", "model_opt", ".", "GPT_representation_mode", "!=", "'none'", ":", "\n", "                                ", "pointer", "=", "load_embs", "[", "lm_idx", "]", ".", "make_embedding", ".", "pe", ".", "pe", ".", "weight", "\n", "", "else", ":", "\n", "                                ", "pointer", "=", "load_model", ".", "embeddings", ".", "make_embedding", ".", "pe", ".", "pe", ".", "weight", "\n", "\n", "", "", "elif", "name", "[", "0", "]", "==", "'wte'", ":", "\n", "                            ", "if", "model_opt", ".", "GPT_representation_mode", "!=", "'none'", ":", "\n", "                                ", "pointer", "=", "[", "load_embs", "[", "lm_idx", "]", ".", "make_embedding", ".", "emb_luts", "[", "0", "]", ".", "weight", ",", "gen_linear", ".", "weight", "]", "\n", "", "else", ":", "\n", "                                ", "pointer", "=", "[", "load_model", ".", "embeddings", ".", "make_embedding", ".", "emb_luts", "[", "0", "]", ".", "weight", "]", "\n", "if", "not", "model_opt", ".", "nopretrain_decemb", ":", "\n", "                                    ", "pointer", ".", "append", "(", "gen_linear", ".", "weight", ")", "\n", "", "if", "model_opt", ".", "simple_fusion", "and", "model_opt", ".", "sf_pretrain_dec_emb", ":", "\n", "                                    ", "pointer", ".", "append", "(", "decoder", ".", "embeddings", ".", "make_embedding", ".", "emb_luts", "[", "0", "]", ".", "weight", ")", "\n", "\n", "", "", "", "elif", "name", "[", "0", "]", "==", "'ln_f'", ":", "\n", "                            ", "if", "name", "[", "1", "]", "==", "'g'", ":", "\n", "                                ", "pointer", "=", "load_model", ".", "layer_norm", ".", "weight", "\n", "", "elif", "name", "[", "1", "]", "==", "'b'", ":", "\n", "                                ", "pointer", "=", "load_model", ".", "layer_norm", ".", "bias", "\n", "", "else", ":", "\n", "                                ", "raise", "ValueError", "(", "'I am missing something here!'", ")", "\n", "\n", "", "", "elif", "name", "[", "0", "]", "[", "0", "]", "==", "'h'", ":", "\n", "                            ", "layer_num", "=", "name", "[", "0", "]", "[", "1", ":", "]", "\n", "pointer", "=", "getattr", "(", "load_model", ".", "transformer_layers", ",", "layer_num", ")", "\n", "if", "name", "[", "1", "]", "==", "'attn'", ":", "\n", "                                ", "assigned", "=", "True", "\n", "pointer", "=", "pointer", ".", "self_attn", "\n", "full_data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "if", "name", "[", "2", "]", "==", "'c_attn'", ":", "\n", "                                    ", "end_size", "=", "full_data", ".", "shape", "[", "-", "1", "]", "//", "3", "\n", "assert", "full_data", ".", "shape", "[", "-", "1", "]", "%", "3", "==", "0", "\n", "if", "name", "[", "3", "]", "==", "'b'", ":", "\n", "                                        ", "if", "init_something", ":", "\n", "                                            ", "pointer", ".", "linear_query", ".", "bias", ".", "data", "=", "full_data", "[", ":", "end_size", "]", "\n", "pointer", ".", "linear_keys", ".", "bias", ".", "data", "=", "full_data", "[", "end_size", ":", "end_size", "*", "2", "]", "\n", "pointer", ".", "linear_values", ".", "bias", ".", "data", "=", "full_data", "[", "end_size", "*", "2", ":", "]", "\n", "", "if", "model_opt", ".", "gpt2_params_std", ">", "0", ":", "\n", "                                            ", "pointer", ".", "linear_query", ".", "bias", ".", "orig", "=", "full_data", "[", ":", "end_size", "]", ".", "clone", "(", ")", "\n", "pointer", ".", "linear_keys", ".", "bias", ".", "orig", "=", "full_data", "[", "end_size", ":", "end_size", "*", "2", "]", ".", "clone", "(", ")", "\n", "pointer", ".", "linear_values", ".", "bias", ".", "orig", "=", "full_data", "[", "end_size", "*", "2", ":", "]", ".", "clone", "(", ")", "\n", "", "", "elif", "name", "[", "3", "]", "==", "'w'", ":", "\n", "                                        ", "if", "init_something", ":", "\n", "                                            ", "pointer", ".", "linear_query", ".", "weight", ".", "data", "=", "full_data", "[", ":", ",", ":", "end_size", "]", ".", "t", "(", ")", ".", "contiguous", "(", ")", "\n", "pointer", ".", "linear_keys", ".", "weight", ".", "data", "=", "full_data", "[", ":", ",", "end_size", ":", "end_size", "*", "2", "]", ".", "t", "(", ")", ".", "contiguous", "(", ")", "\n", "pointer", ".", "linear_values", ".", "weight", ".", "data", "=", "full_data", "[", ":", ",", "end_size", "*", "2", ":", "]", ".", "t", "(", ")", ".", "contiguous", "(", ")", "\n", "", "if", "model_opt", ".", "gpt2_params_std", ">", "0", ":", "\n", "                                            ", "pointer", ".", "linear_query", ".", "weight", ".", "orig", "=", "full_data", "[", ":", ",", ":", "end_size", "]", ".", "t", "(", ")", ".", "contiguous", "(", ")", ".", "clone", "(", ")", "\n", "pointer", ".", "linear_keys", ".", "weight", ".", "orig", "=", "full_data", "[", ":", ",", "end_size", ":", "end_size", "*", "2", "]", ".", "t", "(", ")", ".", "contiguous", "(", ")", ".", "clone", "(", ")", "\n", "pointer", ".", "linear_values", ".", "weight", ".", "orig", "=", "full_data", "[", ":", ",", "end_size", "*", "2", ":", "]", ".", "t", "(", ")", ".", "contiguous", "(", ")", ".", "clone", "(", ")", "\n", "", "", "else", ":", "\n", "                                        ", "raise", "ValueError", "(", "'I am missing something here!'", ")", "\n", "", "", "elif", "name", "[", "2", "]", "==", "'c_proj'", ":", "\n", "                                    ", "if", "name", "[", "3", "]", "==", "'b'", ":", "\n", "                                        ", "if", "init_something", ":", "\n", "                                            ", "pointer", ".", "final_linear", ".", "bias", ".", "data", "=", "full_data", "\n", "", "if", "model_opt", ".", "gpt2_params_std", ">", "0", ":", "\n", "                                            ", "pointer", ".", "final_linear", ".", "bias", ".", "orig", "=", "full_data", ".", "clone", "(", ")", "\n", "", "", "elif", "name", "[", "3", "]", "==", "'w'", ":", "\n", "                                        ", "if", "init_something", ":", "\n", "                                            ", "pointer", ".", "final_linear", ".", "weight", ".", "data", "=", "full_data", ".", "t", "(", ")", ".", "contiguous", "(", ")", "\n", "", "if", "model_opt", ".", "gpt2_params_std", ">", "0", ":", "\n", "                                            ", "pointer", ".", "final_linear", ".", "weight", ".", "orig", "=", "full_data", ".", "t", "(", ")", ".", "contiguous", "(", ")", ".", "clone", "(", ")", "\n", "\n", "", "", "else", ":", "\n", "                                        ", "raise", "ValueError", "(", "'I am missing something here!'", ")", "\n", "\n", "", "", "", "elif", "name", "[", "1", "]", "==", "'ln_1'", "or", "name", "[", "1", "]", "==", "'ln_2'", ":", "\n", "                                ", "num", "=", "name", "[", "1", "]", "[", "3", "]", "\n", "pointer", "=", "getattr", "(", "pointer", ",", "'layer_norm_'", "+", "num", ")", "\n", "if", "name", "[", "2", "]", "==", "'b'", ":", "\n", "                                    ", "pointer", "=", "pointer", ".", "bias", "\n", "", "elif", "name", "[", "2", "]", "==", "'g'", ":", "\n", "                                    ", "pointer", "=", "pointer", ".", "weight", "\n", "", "else", ":", "\n", "                                    ", "raise", "ValueError", "(", "'I am missing something here!'", ")", "\n", "", "", "elif", "name", "[", "1", "]", "==", "'mlp'", ":", "\n", "                                ", "pointer", "=", "pointer", ".", "feed_forward", "\n", "pointer", "=", "getattr", "(", "pointer", ",", "name", "[", "2", "]", ")", "\n", "if", "name", "[", "3", "]", "==", "'b'", ":", "\n", "                                    ", "pointer", "=", "pointer", ".", "bias", "\n", "", "elif", "name", "[", "3", "]", "==", "'w'", ":", "\n", "                                    ", "pointer", "=", "pointer", ".", "weight", "\n", "", "else", ":", "\n", "                                    ", "raise", "ValueError", "(", "'I am missing something here!'", ")", "\n", "", "", "else", ":", "\n", "                                ", "raise", "ValueError", "(", "'I am missing something here!'", ")", "\n", "", "", "else", ":", "\n", "                            ", "raise", "ValueError", "(", "'I am missing something here!'", ")", "\n", "\n", "", "if", "not", "assigned", ":", "\n", "                            ", "if", "name", "[", "-", "1", "]", "==", "'w'", "or", "name", "[", "-", "1", "]", "==", "'g'", ":", "\n", "                                ", "array", "=", "array", ".", "T", "\n", "\n", "", "if", "not", "isinstance", "(", "pointer", ",", "list", ")", ":", "\n", "                                ", "pointer", "=", "[", "pointer", "]", "\n", "", "for", "pointer_i", "in", "pointer", ":", "\n", "                                ", "target_size", "=", "int", "(", "math", ".", "ceil", "(", "array", ".", "shape", "[", "0", "]", "/", "8", ")", ")", "*", "8", "\n", "padded_vocab", "=", "name", "[", "0", "]", "==", "'wte'", "and", "pointer_i", ".", "shape", "[", "0", "]", "==", "target_size", "\n", "padded_vocab", "=", "padded_vocab", "and", "pointer_i", ".", "shape", "[", "1", ":", "]", "==", "array", ".", "shape", "[", "1", ":", "]", "\n", "try", ":", "\n", "                                    ", "assert", "pointer_i", ".", "shape", "==", "array", ".", "shape", "or", "padded_vocab", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                                    ", "e", ".", "args", "+=", "(", "pointer_i", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "if", "init_something", ":", "\n", "                                    ", "print", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "if", "padded_vocab", ":", "\n", "                                        ", "pointer_i", ".", "data", "[", ":", "array", ".", "shape", "[", "0", "]", "]", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "else", ":", "\n", "                                        ", "pointer_i", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "", "if", "model_opt", ".", "gpt2_params_std", ">", "0", ":", "\n", "                                    ", "if", "padded_vocab", ":", "\n", "                                        ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "                                        ", "pointer_i", ".", "orig", "=", "torch", ".", "from_numpy", "(", "array", ")", ".", "clone", "(", ")", "\n", "", "", "", "", "", "", "", "if", "'enc_model'", "in", "checkpoint", ":", "\n", "                ", "load_dict", "=", "{", "k", "[", "8", ":", "]", ":", "v", "for", "k", ",", "v", "in", "checkpoint", "[", "'enc_model'", "]", "if", "'encoder'", "in", "k", "}", "\n", "encoder", ".", "load_state_dict", "(", "load_dict", ",", "strict", "=", "True", ")", "\n", "\n", "", "", "if", "model_opt", ".", "multi_task", "and", "model_opt", ".", "multi_task_finish", "is", "False", "and", "model_opt", ".", "clf_task", "is", "False", ":", "\n", "            ", "fact_path", "=", "model_opt", ".", "clf_path", "\n", "state_dict", "=", "torch", ".", "load", "(", "fact_path", ")", "\n", "model", ".", "multi_task_model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "model_opt", ".", "param_init", "!=", "0.0", ":", "\n", "            ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "data", ".", "uniform_", "(", "-", "model_opt", ".", "param_init", ",", "model_opt", ".", "param_init", ")", "\n", "", "for", "p", "in", "generator", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "data", ".", "uniform_", "(", "-", "model_opt", ".", "param_init", ",", "model_opt", ".", "param_init", ")", "\n", "", "", "if", "model_opt", ".", "param_init_glorot", ":", "\n", "            ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "xavier_uniform_", "(", "p", ")", "\n", "", "", "for", "p", "in", "generator", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "xavier_uniform_", "(", "p", ")", "\n", "\n", "", "", "", "if", "not", "model_opt", ".", "unconditional", "and", "hasattr", "(", "model", ".", "encoder", ",", "'embeddings'", ")", "and", "model", ".", "encoder", ".", "embeddings", "is", "not", "None", ":", "\n", "            ", "model", ".", "encoder", ".", "embeddings", ".", "load_pretrained_vectors", "(", "\n", "model_opt", ".", "pre_word_vecs_enc", ")", "\n", "", "if", "hasattr", "(", "model", ".", "decoder", ",", "'embeddings'", ")", ":", "\n", "            ", "model", ".", "decoder", ".", "embeddings", ".", "load_pretrained_vectors", "(", "\n", "model_opt", ".", "pre_word_vecs_dec", ")", "\n", "# load the fact checker", "\n", "\n", "\n", "\n", "# remove requires_grad from params that are not trained:", "\n", "", "", "if", "model_opt", ".", "notrain_emb", "or", "model_opt", ".", "notrain_embanddec", ":", "\n", "        ", "if", "model_opt", ".", "position_encoding_learned_enc", "and", "model_opt", ".", "share_position_embeddings", ":", "\n", "            ", "model", ".", "encoder", ".", "embeddings", ".", "make_embedding", ".", "pe", ".", "pe", ".", "weight", ".", "requires_grad", "=", "False", "\n", "", "if", "model_opt", ".", "share_embeddings", ":", "\n", "            ", "model", ".", "encoder", ".", "embeddings", ".", "make_embedding", ".", "emb_luts", "[", "0", "]", ".", "weight", ".", "requires_grad", "=", "False", "\n", "", "model", ".", "decoder", ".", "embeddings", ".", "make_embedding", ".", "pe", ".", "pe", ".", "weight", ".", "requires_grad", "=", "False", "\n", "model", ".", "decoder", ".", "embeddings", ".", "make_embedding", ".", "emb_luts", "[", "0", "]", ".", "weight", ".", "requires_grad", "=", "False", "\n", "generator", "[", "0", "]", ".", "weight", ".", "requires_grad", "=", "False", "\n", "\n", "", "if", "model_opt", ".", "notrain_genbias", ":", "\n", "        ", "generator", "[", "0", "]", ".", "bias", ".", "requires_grad", "=", "False", "\n", "\n", "", "if", "model_opt", ".", "notrain_embanddec", ":", "\n", "        ", "for", "name", ",", "p", "in", "load_decoder", ".", "layer_norm", ".", "named_parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "", "for", "name", ",", "p", "in", "load_decoder", ".", "transformer_layers", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "'context'", "not", "in", "name", "and", "'ctx'", "not", "in", "name", ":", "# Takes care of normal and psa versions", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "", "if", "model_opt", ".", "onlytrainln", ":", "\n", "        ", "for", "name", ",", "p", "in", "model", ".", "decoder", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "'layer_norm'", "not", "in", "name", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "", "", "for", "p", "in", "generator", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "if", "model_opt", ".", "onlytrainoutp", ":", "\n", "        ", "if", "model_opt", ".", "share_decoder_embeddings", ":", "\n", "            ", "raise", "ValueError", "\n", "\n", "", "for", "p", "in", "model", ".", "decoder", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "if", "model_opt", ".", "simple_fusion", ":", "\n", "        ", "for", "p", "in", "lm_decoder", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "", "for", "p", "in", "generator", ".", "lm_linear", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "\n", "# fuse the language model and the multi_task", "\n", "\n", "\n", "", "", "model", ".", "generator", "=", "generator", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n", "if", "model_opt", ".", "model_dtype", "==", "'fp16'", ":", "\n", "        ", "model", ".", "half", "(", ")", "\n", "\n", "", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "if", "hasattr", "(", "p", ",", "'orig'", ")", ":", "\n", "            ", "p", ".", "orig", "=", "p", ".", "orig", ".", "to", "(", "device", ")", "\n", "if", "model_opt", ".", "model_dtype", "==", "'fp16'", ":", "\n", "                ", "p", ".", "orig", "=", "p", ".", "orig", ".", "half", "(", ")", "\n", "\n", "", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.linear_repr_patch": [[584, 588], ["None"], "function", ["None"], ["", "def", "linear_repr_patch", "(", "self", ")", ":", "\n", "    ", "return", "'in_features={}, out_features={}, bias={}, wgrad={}, bgrad={}'", ".", "format", "(", "\n", "self", ".", "in_features", ",", "self", ".", "out_features", ",", "self", ".", "bias", "is", "not", "None", ",", "\n", "self", ".", "weight", ".", "requires_grad", ",", "self", ".", "bias", ".", "requires_grad", "if", "self", ".", "bias", "is", "not", "None", "else", "'N/A'", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.ln_repr_patch": [[590, 596], ["None"], "function", ["None"], ["", "def", "ln_repr_patch", "(", "self", ")", ":", "\n", "    ", "string", "=", "'{normalized_shape}, eps={eps}, '", "'elementwise_affine={elementwise_affine}'", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "string", "+=", "', wgrad={}, bgrad={}'", ".", "format", "(", "self", ".", "weight", ".", "requires_grad", "if", "self", ".", "weight", "is", "not", "None", "else", "'N/A'", ",", "\n", "self", ".", "bias", ".", "requires_grad", "if", "self", ".", "bias", "is", "not", "None", "else", "'N/A'", ")", "\n", "return", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.emb_repr_patch": [[597, 612], ["s.format.format"], "function", ["None"], ["", "def", "emb_repr_patch", "(", "self", ")", ":", "\n", "    ", "s", "=", "'{num_embeddings}, {embedding_dim}'", "\n", "if", "self", ".", "padding_idx", "is", "not", "None", ":", "\n", "        ", "s", "+=", "', padding_idx={padding_idx}'", "\n", "", "if", "self", ".", "max_norm", "is", "not", "None", ":", "\n", "        ", "s", "+=", "', max_norm={max_norm}'", "\n", "", "if", "self", ".", "norm_type", "!=", "2", ":", "\n", "        ", "s", "+=", "', norm_type={norm_type}'", "\n", "", "if", "self", ".", "scale_grad_by_freq", "is", "not", "False", ":", "\n", "        ", "s", "+=", "', scale_grad_by_freq={scale_grad_by_freq}'", "\n", "", "if", "self", ".", "sparse", "is", "not", "False", ":", "\n", "        ", "s", "+=", "', sparse=True'", "\n", "", "s", "=", "s", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "s", "+=", "', grad={}'", ".", "format", "(", "self", ".", "weight", ".", "requires_grad", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_model": [[613, 624], ["onmt.utils.logging.logger.info", "model_builder.build_base_model", "onmt.utils.logging.logger.info", "onmt.utils.misc.use_gpu"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_base_model", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.use_gpu"], ["", "def", "build_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "checkpoint", ")", ":", "\n", "    ", "logger", ".", "info", "(", "'Building model...'", ")", "\n", "model", "=", "build_base_model", "(", "model_opt", ",", "fields", ",", "use_gpu", "(", "opt", ")", ",", "checkpoint", ")", "\n", "\n", "# Show which params will be updated", "\n", "nn", ".", "Linear", ".", "extra_repr", "=", "linear_repr_patch", "\n", "nn", ".", "LayerNorm", ".", "extra_repr", "=", "ln_repr_patch", "\n", "nn", ".", "Embedding", ".", "extra_repr", "=", "emb_repr_patch", "\n", "\n", "logger", ".", "info", "(", "model", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.train_single._check_save_model_path": [[18, 23], ["os.path.abspath", "os.path.dirname", "os.path.exists", "os.makedirs"], "function", ["None"], ["def", "_check_save_model_path", "(", "opt", ")", ":", "\n", "    ", "save_model_path", "=", "os", ".", "path", ".", "abspath", "(", "opt", ".", "save_model", ")", "\n", "model_dirname", "=", "os", ".", "path", ".", "dirname", "(", "save_model_path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "model_dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "model_dirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.train_single._tally_parameters": [[25, 39], ["model.named_parameters", "param.nelement", "param.nelement", "param.nelement"], "function", ["None"], ["", "", "def", "_tally_parameters", "(", "model", ",", "only_trainable", "=", "False", ")", ":", "\n", "    ", "enc", "=", "0", "\n", "dec", "=", "0", "\n", "lm_dec", "=", "0", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "only_trainable", "and", "not", "param", ".", "requires_grad", ":", "\n", "            ", "continue", "\n", "", "if", "'lm_decoder'", "in", "name", ":", "\n", "            ", "lm_dec", "+=", "param", ".", "nelement", "(", ")", "\n", "", "elif", "'encoder'", "in", "name", ":", "\n", "            ", "enc", "+=", "param", ".", "nelement", "(", ")", "\n", "", "else", ":", "\n", "            ", "dec", "+=", "param", ".", "nelement", "(", ")", "\n", "", "", "return", "enc", "+", "dec", "+", "lm_dec", ",", "enc", ",", "dec", ",", "lm_dec", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.train_single.configure_process": [[41, 45], ["onmt.utils.misc.set_random_seed", "torch.cuda.set_device"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.set_random_seed"], ["", "def", "configure_process", "(", "opt", ",", "device_id", ")", ":", "\n", "    ", "if", "device_id", ">=", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "device_id", ")", "\n", "", "set_random_seed", "(", "opt", ".", "seed", ",", "device_id", ">=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.train_single.main": [[47, 194], ["train_single.configure_process", "onmt.utils.logging.init_logger", "onmt.inputters.inputter.old_style_vocab", "onmt.model_builder.build_model", "train_single._tally_parameters", "train_single._tally_parameters", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "train_single._check_save_model_path", "onmt.utils.optimizers.Optimizer.from_opt", "onmt.models.build_model_saver", "onmt.trainer.build_trainer", "onmt.inputters.inputter.build_dataset_iter", "onmt.inputters.inputter.build_dataset_iter", "len", "onmt.trainer.build_trainer.train", "onmt.utils.logging.logger.info", "torch.load", "onmt.utils.logging.logger.info", "torch.load", "torch.load", "onmt.utils.logging.logger.info", "tf.train.list_variables", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "torch.load", "onmt.inputters.inputter.load_old_vocab", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.warning", "onmt.trainer.build_trainer.report_manager.tensorboard_writer.close", "onmt.utils.parse.ArgumentParser.ckpt_model_opts", "onmt.utils.parse.ArgumentParser.update_model_opts", "onmt.utils.parse.ArgumentParser.validate_model_opts", "tf.train.load_variable", "names.append", "arrays.append", "zip", "ValueError", "iter", "ArgumentParser.ckpt_model_opts.__setattr__", "ArgumentParser.ckpt_model_opts.__setattr__", "ArgumentParser.ckpt_model_opts.__setattr__", "ArgumentParser.ckpt_model_opts.__setattr__", "ArgumentParser.ckpt_model_opts.__setattr__", "ArgumentParser.ckpt_model_opts.__setattr__", "ArgumentParser.ckpt_model_opts.__setattr__", "ArgumentParser.ckpt_model_opts.__setattr__", "ArgumentParser.ckpt_model_opts.__setattr__", "ArgumentParser.ckpt_model_opts.__setattr__", "ArgumentParser.ckpt_model_opts.__setattr__", "tf.train.load_variable.squeeze", "zip", "onmt.utils.logging.logger.info", "len"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.train_single.configure_process", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.logging.init_logger", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.old_style_vocab", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_model", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.train_single._tally_parameters", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.train_single._tally_parameters", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.train_single._check_save_model_path", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.build_model_saver", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.trainer.build_trainer", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.build_dataset_iter", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.build_dataset_iter", "home.repos.pwc.inspect_result.bigheiniu_FactGen.NeuralGenerationDetection.RoBERTaDetect.train", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.load_old_vocab", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.ckpt_model_opts", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.update_model_opts", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.validate_model_opts", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "main", "(", "opt", ",", "device_id", ")", ":", "\n", "# NOTE: It's important that ``opt`` has been validated and updated", "\n", "# at this point.", "\n", "    ", "configure_process", "(", "opt", ",", "device_id", ")", "\n", "init_logger", "(", "opt", ".", "log_file", ")", "\n", "# Load checkpoint if we resume from a previous training.", "\n", "load_str", "=", "opt", ".", "train_from", "if", "opt", ".", "train_from", "else", "opt", ".", "load_uncond_from", "\n", "if", "load_str", ":", "\n", "        ", "logger", ".", "info", "(", "'Loading checkpoint from %s'", "%", "load_str", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "load_str", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "\n", "logger", ".", "info", "(", "'Loading vocab from checkpoint at %s.'", "%", "load_str", ")", "\n", "vocab", "=", "checkpoint", "[", "'vocab'", "]", "\n", "\n", "if", "opt", ".", "train_from", ":", "\n", "            ", "model_opt", "=", "ArgumentParser", ".", "ckpt_model_opts", "(", "checkpoint", "[", "\"opt\"", "]", ")", "\n", "ArgumentParser", ".", "update_model_opts", "(", "model_opt", ")", "\n", "ArgumentParser", ".", "validate_model_opts", "(", "model_opt", ")", "\n", "if", "opt", ".", "multi_task", ":", "\n", "# manually set up the learning rate", "\n", "                ", "model_opt", ".", "__setattr__", "(", "\"multi_task\"", ",", "opt", ".", "multi_task", ")", "\n", "model_opt", ".", "__setattr__", "(", "\"multi_task_lr\"", ",", "opt", ".", "multi_task_lr", ")", "\n", "model_opt", ".", "__setattr__", "(", "\"data\"", ",", "opt", ".", "data", ")", "\n", "model_opt", ".", "__setattr__", "(", "\"save_model\"", ",", "opt", ".", "save_model", ")", "\n", "model_opt", ".", "__setattr__", "(", "\"multi_task_finish\"", ",", "opt", ".", "multi_task_finish", ")", "\n", "model_opt", ".", "__setattr__", "(", "\"clf_task\"", ",", "opt", ".", "clf_task", ")", "\n", "model_opt", ".", "__setattr__", "(", "\"valid_steps\"", ",", "opt", ".", "valid_steps", ")", "\n", "model_opt", ".", "__setattr__", "(", "\"report_every\"", ",", "opt", ".", "report_every", ")", "\n", "model_opt", ".", "__setattr__", "(", "\"clf_task\"", ",", "opt", ".", "clf_task", ")", "\n", "\n", "", "if", "opt", ".", "multi_task_finish", ":", "\n", "                ", "model_opt", ".", "__setattr__", "(", "\"data\"", ",", "opt", ".", "query_data", ")", "\n", "", "if", "opt", ".", "only_query", ":", "\n", "                ", "model_opt", ".", "__setattr__", "(", "\"data\"", ",", "opt", ".", "query_data", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "model_opt", "=", "opt", "\n", "", "", "else", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "model_opt", "=", "opt", "\n", "vocab", "=", "torch", ".", "load", "(", "opt", ".", "data", "+", "'.vocab.pt'", ")", "\n", "\n", "", "if", "opt", ".", "clf_task", ":", "\n", "        ", "vocab", "=", "torch", ".", "load", "(", "opt", ".", "data", "+", "'.vocab.pt'", ")", "\n", "", "if", "opt", ".", "gpt2_params_path", "is", "not", "None", ":", "\n", "        ", "import", "tensorflow", "as", "tf", "\n", "import", "numpy", "as", "np", "\n", "# Taken from pytorch-pretrained-BERT:", "\n", "# Load weights from TF model", "\n", "logger", ".", "info", "(", "\"Loading TF GPT weights...\"", ")", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "opt", ".", "gpt2_params_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "            ", "if", "opt", ".", "gpt_emb_only", "and", "(", "'wpe'", "not", "in", "name", "and", "'wte'", "not", "in", "name", ")", ":", "\n", "                ", "continue", "\n", "", "if", "opt", ".", "gpt_wpe_only", "and", "'wpe'", "not", "in", "name", ":", "\n", "                ", "continue", "\n", "#print(\"Loading TF weight {} with shape {}\".format(name, shape))", "\n", "", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "opt", ".", "gpt2_params_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ".", "squeeze", "(", ")", ")", "\n", "", "logger", ".", "info", "(", "\"Done.\"", ")", "\n", "\n", "if", "checkpoint", "is", "None", ":", "\n", "            ", "checkpoint", "=", "{", "'gpt2_params'", ":", "zip", "(", "names", ",", "arrays", ")", "}", "\n", "", "else", ":", "\n", "            ", "checkpoint", "[", "'gpt2_params'", "]", "=", "zip", "(", "names", ",", "arrays", ")", "\n", "\n", "", "", "if", "opt", ".", "encoder_from", "is", "not", "None", ":", "\n", "        ", "logger", ".", "info", "(", "'Loading checkpoint with encoder from %s'", "%", "opt", ".", "encoder_from", ")", "\n", "enc_checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "encoder_from", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "enc_vocab", "=", "enc_checkpoint", "[", "'vocab'", "]", "\n", "if", "vocab", "[", "'src'", "]", ".", "base_field", ".", "vocab", "!=", "enc_vocab", "[", "'src'", "]", ".", "base_field", ".", "vocab", ":", "\n", "            ", "raise", "ValueError", "(", "'encoder vocab and model vocab need to be identical it using pretrained encoder'", ")", "\n", "", "if", "checkpoint", "is", "None", ":", "\n", "            ", "checkpoint", "=", "{", "}", "\n", "", "checkpoint", "[", "'enc_model'", "]", "=", "enc_checkpoint", "[", "'model'", "]", "\n", "\n", "\n", "# check for code where vocab is saved instead of fields", "\n", "# (in the future this will be done in a smarter way)", "\n", "", "if", "old_style_vocab", "(", "vocab", ")", ":", "\n", "        ", "fields", "=", "load_old_vocab", "(", "\n", "vocab", ",", "opt", ".", "model_type", ",", "dynamic_dict", "=", "opt", ".", "copy_attn", ")", "\n", "", "else", ":", "\n", "        ", "fields", "=", "vocab", "\n", "\n", "# Report src and tgt vocab sizes, including for features", "\n", "", "sides", "=", "[", "'tgt'", "]", "if", "opt", ".", "model_type", "==", "'none'", "else", "[", "'src'", ",", "'tgt'", "]", "\n", "for", "side", "in", "sides", ":", "\n", "        ", "f", "=", "fields", "[", "side", "]", "\n", "try", ":", "\n", "            ", "f_iter", "=", "iter", "(", "f", ")", "\n", "", "except", "TypeError", ":", "\n", "            ", "f_iter", "=", "[", "(", "side", ",", "f", ")", "]", "\n", "", "for", "sn", ",", "sf", "in", "f_iter", ":", "\n", "            ", "if", "sf", ".", "use_vocab", ":", "\n", "                ", "logger", ".", "info", "(", "' * %s vocab size = %d'", "%", "(", "sn", ",", "len", "(", "sf", ".", "vocab", ")", ")", ")", "\n", "\n", "# Build model.", "\n", "", "", "", "model", "=", "build_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "checkpoint", ")", "\n", "n_params", ",", "enc", ",", "dec", ",", "lm_dec", "=", "_tally_parameters", "(", "model", ")", "\n", "n_params_t", ",", "enc_t", ",", "dec_t", ",", "lm_dec_t", "=", "_tally_parameters", "(", "model", ",", "only_trainable", "=", "True", ")", "\n", "logger", ".", "info", "(", "'encoder: %d (%d)'", "%", "(", "enc", ",", "enc_t", ")", ")", "\n", "logger", ".", "info", "(", "'decoder: %d (%d)'", "%", "(", "dec", ",", "dec_t", ")", ")", "\n", "if", "opt", ".", "simple_fusion", ":", "\n", "        ", "logger", ".", "info", "(", "'lm decoder: %d (%d)'", "%", "(", "lm_dec", ",", "lm_dec_t", ")", ")", "\n", "\n", "", "logger", ".", "info", "(", "'* number of parameters: %d (%d)'", "%", "(", "n_params", ",", "n_params_t", ")", ")", "\n", "_check_save_model_path", "(", "opt", ")", "\n", "\n", "if", "not", "opt", ".", "train_from", "and", "opt", ".", "gpt2_params_path", "is", "not", "None", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "\n", "# Build optimizer.", "\n", "", "optim", "=", "Optimizer", ".", "from_opt", "(", "model", ",", "opt", ",", "checkpoint", "=", "checkpoint", ")", "\n", "\n", "# Build model saver", "\n", "model_saver", "=", "build_model_saver", "(", "model_opt", ",", "opt", ",", "model", ",", "fields", ",", "optim", ")", "\n", "\n", "trainer", "=", "build_trainer", "(", "\n", "opt", ",", "device_id", ",", "model", ",", "fields", ",", "optim", ",", "model_saver", "=", "model_saver", ")", "\n", "\n", "train_iter", "=", "build_dataset_iter", "(", "\"train\"", ",", "fields", ",", "opt", ")", "\n", "valid_iter", "=", "build_dataset_iter", "(", "\n", "\"valid\"", ",", "fields", ",", "opt", ",", "is_train", "=", "False", ")", "\n", "\n", "if", "len", "(", "opt", ".", "gpu_ranks", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Starting training on GPU: %s'", "%", "opt", ".", "gpu_ranks", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "'Starting training on CPU, could be very slow'", ")", "\n", "", "train_steps", "=", "opt", ".", "train_steps", "\n", "if", "opt", ".", "single_pass", "and", "train_steps", ">", "0", ":", "\n", "        ", "logger", ".", "warning", "(", "\"Option single_pass is enabled, ignoring train_steps.\"", ")", "\n", "train_steps", "=", "0", "\n", "", "trainer", ".", "train", "(", "\n", "train_iter", ",", "\n", "train_steps", ",", "\n", "save_checkpoint_steps", "=", "opt", ".", "save_checkpoint_steps", ",", "\n", "valid_iter", "=", "valid_iter", ",", "\n", "valid_steps", "=", "opt", ".", "valid_steps", ")", "\n", "\n", "if", "opt", ".", "tensorboard", ":", "\n", "        ", "trainer", ".", "report_manager", ".", "tensorboard_writer", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.__init__": [[20, 26], ["time.time"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "loss", "=", "0", ",", "n_words", "=", "0", ",", "n_correct", "=", "0", ")", ":", "\n", "        ", "self", ".", "loss", "=", "loss", "\n", "self", ".", "n_words", "=", "n_words", "\n", "self", ".", "n_correct", "=", "n_correct", "\n", "self", ".", "n_src_words", "=", "0", "\n", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.all_gather_stats": [[27, 42], ["statistics.Statistics.all_gather_stats_list"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.all_gather_stats_list"], ["", "@", "staticmethod", "\n", "def", "all_gather_stats", "(", "stat", ",", "max_size", "=", "4096", ")", ":", "\n", "        ", "\"\"\"\n        Gather a `Statistics` object accross multiple process/nodes\n\n        Args:\n            stat(:obj:Statistics): the statistics object to gather\n                accross all processes/nodes\n            max_size(int): max buffer size to use\n\n        Returns:\n            `Statistics`, the update stats object\n        \"\"\"", "\n", "stats", "=", "Statistics", ".", "all_gather_stats_list", "(", "[", "stat", "]", ",", "max_size", "=", "max_size", ")", "\n", "return", "stats", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.all_gather_stats_list": [[43, 70], ["all_gather_list", "get_rank", "enumerate", "enumerate", "our_stats[].update"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.update"], ["", "@", "staticmethod", "\n", "def", "all_gather_stats_list", "(", "stat_list", ",", "max_size", "=", "4096", ")", ":", "\n", "        ", "\"\"\"\n        Gather a `Statistics` list accross all processes/nodes\n\n        Args:\n            stat_list(list([`Statistics`])): list of statistics objects to\n                gather accross all processes/nodes\n            max_size(int): max buffer size to use\n\n        Returns:\n            our_stats(list([`Statistics`])): list of updated stats\n        \"\"\"", "\n", "from", "torch", ".", "distributed", "import", "get_rank", "\n", "from", "onmt", ".", "utils", ".", "distributed", "import", "all_gather_list", "\n", "\n", "# Get a list of world_size lists with len(stat_list) Statistics objects", "\n", "all_stats", "=", "all_gather_list", "(", "stat_list", ",", "max_size", "=", "max_size", ")", "\n", "\n", "our_rank", "=", "get_rank", "(", ")", "\n", "our_stats", "=", "all_stats", "[", "our_rank", "]", "\n", "for", "other_rank", ",", "stats", "in", "enumerate", "(", "all_stats", ")", ":", "\n", "            ", "if", "other_rank", "==", "our_rank", ":", "\n", "                ", "continue", "\n", "", "for", "i", ",", "stat", "in", "enumerate", "(", "stats", ")", ":", "\n", "                ", "our_stats", "[", "i", "]", ".", "update", "(", "stat", ",", "update_n_src_words", "=", "True", ")", "\n", "", "", "return", "our_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.update": [[71, 87], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "stat", ",", "update_n_src_words", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Update statistics by suming values with another `Statistics` object\n\n        Args:\n            stat: another statistic object\n            update_n_src_words(bool): whether to update (sum) `n_src_words`\n                or not\n\n        \"\"\"", "\n", "self", ".", "loss", "+=", "stat", ".", "loss", "\n", "self", ".", "n_words", "+=", "stat", ".", "n_words", "\n", "self", ".", "n_correct", "+=", "stat", ".", "n_correct", "\n", "\n", "if", "update_n_src_words", ":", "\n", "            ", "self", ".", "n_src_words", "+=", "stat", ".", "n_src_words", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.accuracy": [[88, 91], ["None"], "methods", ["None"], ["", "", "def", "accuracy", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute accuracy \"\"\"", "\n", "return", "100", "*", "(", "self", ".", "n_correct", "/", "self", ".", "n_words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.xent": [[92, 95], ["None"], "methods", ["None"], ["", "def", "xent", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute cross entropy \"\"\"", "\n", "return", "self", ".", "loss", "/", "self", ".", "n_words", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.ppl": [[96, 99], ["math.exp", "min"], "methods", ["None"], ["", "def", "ppl", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute perplexity \"\"\"", "\n", "return", "math", ".", "exp", "(", "min", "(", "self", ".", "loss", "/", "self", ".", "n_words", ",", "100", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.elapsed_time": [[100, 103], ["time.time"], "methods", ["None"], ["", "def", "elapsed_time", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute elapsed time \"\"\"", "\n", "return", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.output": [[104, 128], ["statistics.Statistics.elapsed_time", "onmt.utils.logging.logger.info", "sys.stdout.flush", "statistics.Statistics.accuracy", "statistics.Statistics.ppl", "statistics.Statistics.xent", "time.time"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.elapsed_time", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.accuracy", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.ppl", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.xent"], ["", "def", "output", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "start", ")", ":", "\n", "        ", "\"\"\"Write out statistics to stdout.\n\n        Args:\n           step (int): current step\n           n_batch (int): total batches\n           start (int): start time of step.\n        \"\"\"", "\n", "t", "=", "self", ".", "elapsed_time", "(", ")", "\n", "step_fmt", "=", "\"%2d\"", "%", "step", "\n", "if", "num_steps", ">", "0", ":", "\n", "            ", "step_fmt", "=", "\"%s/%5d\"", "%", "(", "step_fmt", ",", "num_steps", ")", "\n", "", "logger", ".", "info", "(", "\n", "(", "\"Step %s; acc: %6.2f; ppl: %5.2f; xent: %4.3f; \"", "+", "\n", "\"lr: %7.5f; %3.0f/%3.0f tok/s; %6.0f sec\"", ")", "\n", "%", "(", "step_fmt", ",", "\n", "self", ".", "accuracy", "(", ")", ",", "\n", "self", ".", "ppl", "(", ")", ",", "\n", "self", ".", "xent", "(", ")", ",", "\n", "learning_rate", ",", "\n", "self", ".", "n_src_words", "/", "(", "t", "+", "1e-5", ")", ",", "\n", "self", ".", "n_words", "/", "(", "t", "+", "1e-5", ")", ",", "\n", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.log_tensorboard": [[129, 137], ["statistics.Statistics.elapsed_time", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "statistics.Statistics.xent", "statistics.Statistics.ppl", "statistics.Statistics.accuracy"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.elapsed_time", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.xent", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.ppl", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.accuracy"], ["", "def", "log_tensorboard", "(", "self", ",", "prefix", ",", "writer", ",", "learning_rate", ",", "step", ")", ":", "\n", "        ", "\"\"\" display statistics to tensorboard \"\"\"", "\n", "t", "=", "self", ".", "elapsed_time", "(", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/xent\"", ",", "self", ".", "xent", "(", ")", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/ppl\"", ",", "self", ".", "ppl", "(", ")", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/accuracy\"", ",", "self", ".", "accuracy", "(", ")", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/tgtper\"", ",", "self", ".", "n_words", "/", "t", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/lr\"", ",", "learning_rate", ",", "step", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.logging.init_logger": [[9, 25], ["logging.Formatter", "logging.getLogger", "logging.getLogger.setLevel", "logging.StreamHandler", "logging.StreamHandler.setFormatter", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler"], "function", ["None"], ["def", "init_logger", "(", "log_file", "=", "None", ",", "log_file_level", "=", "logging", ".", "NOTSET", ")", ":", "\n", "    ", "log_format", "=", "logging", ".", "Formatter", "(", "\"[%(asctime)s %(levelname)s] %(message)s\"", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "\n", "console_handler", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "console_handler", ".", "setFormatter", "(", "log_format", ")", "\n", "logger", ".", "handlers", "=", "[", "console_handler", "]", "\n", "\n", "if", "log_file", "and", "log_file", "!=", "''", ":", "\n", "        ", "file_handler", "=", "logging", ".", "FileHandler", "(", "log_file", ")", "\n", "file_handler", ".", "setLevel", "(", "log_file_level", ")", "\n", "file_handler", ".", "setFormatter", "(", "log_format", ")", "\n", "logger", ".", "addHandler", "(", "file_handler", ")", "\n", "\n", "", "return", "logger", "\n", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.distributed.is_master": [[16, 18], ["None"], "function", ["None"], ["def", "is_master", "(", "opt", ",", "device_id", ")", ":", "\n", "    ", "return", "opt", ".", "gpu_ranks", "[", "device_id", "]", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.distributed.multi_init": [[20, 33], ["torch.distributed.init_process_group", "torch.distributed.get_rank", "distributed.is_master"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.distributed.is_master"], ["", "def", "multi_init", "(", "opt", ",", "device_id", ")", ":", "\n", "    ", "dist_init_method", "=", "'tcp://{master_ip}:{master_port}'", ".", "format", "(", "\n", "master_ip", "=", "opt", ".", "master_ip", ",", "\n", "master_port", "=", "opt", ".", "master_port", ")", "\n", "dist_world_size", "=", "opt", ".", "world_size", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "opt", ".", "gpu_backend", ",", "init_method", "=", "dist_init_method", ",", "\n", "world_size", "=", "dist_world_size", ",", "rank", "=", "opt", ".", "gpu_ranks", "[", "device_id", "]", ")", "\n", "gpu_rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "if", "not", "is_master", "(", "opt", ",", "device_id", ")", ":", "\n", "        ", "logger", ".", "disabled", "=", "True", "\n", "\n", "", "return", "gpu_rank", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.distributed.all_reduce_and_rescale_tensors": [[35, 87], ["tensors[].new().zero_", "torch.distributed.all_reduce", "tensors[].new().zero_.div_", "len", "distributed.all_reduce_and_rescale_tensors.all_reduce_buffer"], "function", ["None"], ["", "def", "all_reduce_and_rescale_tensors", "(", "tensors", ",", "rescale_denom", ",", "\n", "buffer_size", "=", "10485760", ")", ":", "\n", "    ", "\"\"\"All-reduce and rescale tensors in chunks of the specified size.\n\n    Args:\n        tensors: list of Tensors to all-reduce\n        rescale_denom: denominator for rescaling summed Tensors\n        buffer_size: all-reduce chunk size in bytes\n    \"\"\"", "\n", "# buffer size in bytes, determine equiv. # of elements based on data type", "\n", "buffer_t", "=", "tensors", "[", "0", "]", ".", "new", "(", "\n", "math", ".", "ceil", "(", "buffer_size", "/", "tensors", "[", "0", "]", ".", "element_size", "(", ")", ")", ")", ".", "zero_", "(", ")", "\n", "buffer", "=", "[", "]", "\n", "\n", "def", "all_reduce_buffer", "(", ")", ":", "\n", "# copy tensors into buffer_t", "\n", "        ", "offset", "=", "0", "\n", "for", "t", "in", "buffer", ":", "\n", "            ", "numel", "=", "t", ".", "numel", "(", ")", "\n", "buffer_t", "[", "offset", ":", "offset", "+", "numel", "]", ".", "copy_", "(", "t", ".", "view", "(", "-", "1", ")", ")", "\n", "offset", "+=", "numel", "\n", "\n", "# all-reduce and rescale", "\n", "", "torch", ".", "distributed", ".", "all_reduce", "(", "buffer_t", "[", ":", "offset", "]", ")", "\n", "buffer_t", ".", "div_", "(", "rescale_denom", ")", "\n", "\n", "# copy all-reduced buffer back into tensors", "\n", "offset", "=", "0", "\n", "for", "t", "in", "buffer", ":", "\n", "            ", "numel", "=", "t", ".", "numel", "(", ")", "\n", "t", ".", "view", "(", "-", "1", ")", ".", "copy_", "(", "buffer_t", "[", "offset", ":", "offset", "+", "numel", "]", ")", "\n", "offset", "+=", "numel", "\n", "\n", "", "", "filled", "=", "0", "\n", "for", "t", "in", "tensors", ":", "\n", "        ", "sz", "=", "t", ".", "numel", "(", ")", "*", "t", ".", "element_size", "(", ")", "\n", "if", "sz", ">", "buffer_size", ":", "\n", "# tensor is bigger than buffer, all-reduce and rescale directly", "\n", "            ", "torch", ".", "distributed", ".", "all_reduce", "(", "t", ")", "\n", "t", ".", "div_", "(", "rescale_denom", ")", "\n", "", "elif", "filled", "+", "sz", ">", "buffer_size", ":", "\n", "# buffer is full, all-reduce and replace buffer with grad", "\n", "            ", "all_reduce_buffer", "(", ")", "\n", "buffer", "=", "[", "t", "]", "\n", "filled", "=", "sz", "\n", "", "else", ":", "\n", "# add tensor to buffer", "\n", "            ", "buffer", ".", "append", "(", "t", ")", "\n", "filled", "+=", "sz", "\n", "\n", "", "", "if", "len", "(", "buffer", ")", ">", "0", ":", "\n", "        ", "all_reduce_buffer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.distributed.all_gather_list": [[89, 123], ["torch.distributed.get_world_size", "pickle.dumps", "len", "torch.ByteTensor", "torch.distributed.all_gather", "range", "torch.cuda.ByteTensor", "ValueError", "list", "in_buffer.cuda", "bytes", "pickle.loads", "results.append", "hasattr", "all_gather_list._in_buffer.size", "torch.cuda.ByteTensor", "out_buffer[].item", "out_buffer[].tolist", "range", "out_buffer[].item"], "function", ["None"], ["", "", "def", "all_gather_list", "(", "data", ",", "max_size", "=", "4096", ")", ":", "\n", "    ", "\"\"\"Gathers arbitrary data from all nodes into a list.\"\"\"", "\n", "world_size", "=", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "\n", "if", "not", "hasattr", "(", "all_gather_list", ",", "'_in_buffer'", ")", "or", "max_size", "!=", "all_gather_list", ".", "_in_buffer", ".", "size", "(", ")", ":", "\n", "        ", "all_gather_list", ".", "_in_buffer", "=", "torch", ".", "cuda", ".", "ByteTensor", "(", "max_size", ")", "\n", "all_gather_list", ".", "_out_buffers", "=", "[", "\n", "torch", ".", "cuda", ".", "ByteTensor", "(", "max_size", ")", "\n", "for", "i", "in", "range", "(", "world_size", ")", "\n", "]", "\n", "", "in_buffer", "=", "all_gather_list", ".", "_in_buffer", "\n", "out_buffers", "=", "all_gather_list", ".", "_out_buffers", "\n", "\n", "enc", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "enc_size", "=", "len", "(", "enc", ")", "\n", "if", "enc_size", "+", "2", ">", "max_size", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "'encoded data exceeds max_size: {}'", ".", "format", "(", "enc_size", "+", "2", ")", ")", "\n", "", "assert", "max_size", "<", "255", "*", "256", "\n", "in_buffer", "[", "0", "]", "=", "enc_size", "//", "255", "# this encoding works for max_size < 65k", "\n", "in_buffer", "[", "1", "]", "=", "enc_size", "%", "255", "\n", "in_buffer", "[", "2", ":", "enc_size", "+", "2", "]", "=", "torch", ".", "ByteTensor", "(", "list", "(", "enc", ")", ")", "\n", "\n", "torch", ".", "distributed", ".", "all_gather", "(", "out_buffers", ",", "in_buffer", ".", "cuda", "(", ")", ")", "\n", "\n", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "world_size", ")", ":", "\n", "        ", "out_buffer", "=", "out_buffers", "[", "i", "]", "\n", "size", "=", "(", "255", "*", "out_buffer", "[", "0", "]", ".", "item", "(", ")", ")", "+", "out_buffer", "[", "1", "]", ".", "item", "(", ")", "\n", "\n", "bytes_list", "=", "bytes", "(", "out_buffer", "[", "2", ":", "size", "+", "2", "]", ".", "tolist", "(", ")", ")", "\n", "result", "=", "pickle", ".", "loads", "(", "bytes_list", ")", "\n", "results", ".", "append", "(", "result", ")", "\n", "", "return", "results", "\n", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.ReportMgrBase.__init__": [[38, 48], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "report_every", ",", "start_time", "=", "-", "1.", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            report_every(int): Report status every this many sentences\n            start_time(float): manually set report start time. Negative values\n                means that you will need to set it later or use `start()`\n        \"\"\"", "\n", "self", ".", "report_every", "=", "report_every", "\n", "self", ".", "progress_step", "=", "0", "\n", "self", ".", "start_time", "=", "start_time", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.ReportMgrBase.start": [[49, 51], ["time.time"], "methods", ["None"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.ReportMgrBase.log": [[52, 54], ["onmt.utils.logging.logger.info"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "logger", ".", "info", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.ReportMgrBase.report_training": [[55, 83], ["ValueError", "report_manager.ReportMgrBase._report_training", "onmt.utils.Statistics", "onmt.utils.Statistics.all_gather_stats"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.ReportMgr._report_training", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.all_gather_stats"], ["", "def", "report_training", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "\n", "report_stats", ",", "multigpu", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        This is the user-defined batch-level traing progress\n        report function.\n\n        Args:\n            step(int): current step count.\n            num_steps(int): total number of batches.\n            learning_rate(float): current learning rate.\n            report_stats(Statistics): old Statistics instance.\n        Returns:\n            report_stats(Statistics): updated Statistics instance.\n        \"\"\"", "\n", "if", "self", ".", "start_time", "<", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"\"\"ReportMgr needs to be started\n                                (set 'start_time' or use 'start()'\"\"\"", ")", "\n", "\n", "", "if", "step", "%", "self", ".", "report_every", "==", "0", ":", "\n", "            ", "if", "multigpu", ":", "\n", "                ", "report_stats", "=", "onmt", ".", "utils", ".", "Statistics", ".", "all_gather_stats", "(", "report_stats", ")", "\n", "", "self", ".", "_report_training", "(", "\n", "step", ",", "num_steps", ",", "learning_rate", ",", "report_stats", ")", "\n", "self", ".", "progress_step", "+=", "1", "\n", "return", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "report_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.ReportMgrBase._report_training": [[84, 87], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "_report_training", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" To be overridden \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.ReportMgrBase.report_step": [[88, 99], ["report_manager.ReportMgrBase._report_step"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.ReportMgr._report_step"], ["", "def", "report_step", "(", "self", ",", "lr", ",", "step", ",", "train_stats", "=", "None", ",", "valid_stats", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Report stats of a step\n\n        Args:\n            train_stats(Statistics): training stats\n            valid_stats(Statistics): validation stats\n            lr(float): current learning rate\n        \"\"\"", "\n", "self", ".", "_report_step", "(", "\n", "lr", ",", "step", ",", "train_stats", "=", "train_stats", ",", "valid_stats", "=", "valid_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.ReportMgrBase._report_step": [[100, 102], ["NotImplementedError"], "methods", ["None"], ["", "def", "_report_step", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.ReportMgr.__init__": [[105, 117], ["report_manager.ReportMgrBase.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "report_every", ",", "start_time", "=", "-", "1.", ",", "tensorboard_writer", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        A report manager that writes statistics on standard output as well as\n        (optionally) TensorBoard\n\n        Args:\n            report_every(int): Report status every this many sentences\n            tensorboard_writer(:obj:`tensorboard.SummaryWriter`):\n                The TensorBoard Summary writer to use or None\n        \"\"\"", "\n", "super", "(", "ReportMgr", ",", "self", ")", ".", "__init__", "(", "report_every", ",", "start_time", ")", "\n", "self", ".", "tensorboard_writer", "=", "tensorboard_writer", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.ReportMgr.maybe_log_tensorboard": [[118, 122], ["stats.log_tensorboard"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.log_tensorboard"], ["", "def", "maybe_log_tensorboard", "(", "self", ",", "stats", ",", "prefix", ",", "learning_rate", ",", "step", ")", ":", "\n", "        ", "if", "self", ".", "tensorboard_writer", "is", "not", "None", ":", "\n", "            ", "stats", ".", "log_tensorboard", "(", "\n", "prefix", ",", "self", ".", "tensorboard_writer", ",", "learning_rate", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.ReportMgr._report_training": [[123, 139], ["onmt.utils.Statistics.output", "report_manager.ReportMgr.maybe_log_tensorboard", "onmt.utils.Statistics"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.output", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.ReportMgr.maybe_log_tensorboard"], ["", "", "def", "_report_training", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "\n", "report_stats", ")", ":", "\n", "        ", "\"\"\"\n        See base class method `ReportMgrBase.report_training`.\n        \"\"\"", "\n", "report_stats", ".", "output", "(", "step", ",", "num_steps", ",", "\n", "learning_rate", ",", "self", ".", "start_time", ")", "\n", "\n", "# Log the progress using the number of batches on the x-axis.", "\n", "self", ".", "maybe_log_tensorboard", "(", "report_stats", ",", "\n", "\"progress\"", ",", "\n", "learning_rate", ",", "\n", "self", ".", "progress_step", ")", "\n", "report_stats", "=", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n", "\n", "return", "report_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.ReportMgr._report_step": [[140, 162], ["report_manager.ReportMgr.log", "report_manager.ReportMgr.log", "report_manager.ReportMgr.maybe_log_tensorboard", "report_manager.ReportMgr.log", "report_manager.ReportMgr.log", "report_manager.ReportMgr.log", "report_manager.ReportMgr.maybe_log_tensorboard", "train_stats.ppl", "train_stats.accuracy", "valid_stats.ppl", "valid_stats.xent", "valid_stats.accuracy"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.ReportMgr.maybe_log_tensorboard", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.ReportMgr.maybe_log_tensorboard", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.ppl", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.accuracy", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.ppl", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.xent", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.accuracy"], ["", "def", "_report_step", "(", "self", ",", "lr", ",", "step", ",", "train_stats", "=", "None", ",", "valid_stats", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        See base class method `ReportMgrBase.report_step`.\n        \"\"\"", "\n", "if", "train_stats", "is", "not", "None", ":", "\n", "            ", "self", ".", "log", "(", "'Train perplexity: %g'", "%", "train_stats", ".", "ppl", "(", ")", ")", "\n", "self", ".", "log", "(", "'Train accuracy: %g'", "%", "train_stats", ".", "accuracy", "(", ")", ")", "\n", "\n", "self", ".", "maybe_log_tensorboard", "(", "train_stats", ",", "\n", "\"train\"", ",", "\n", "lr", ",", "\n", "step", ")", "\n", "\n", "", "if", "valid_stats", "is", "not", "None", ":", "\n", "            ", "self", ".", "log", "(", "'Validation perplexity: %g'", "%", "valid_stats", ".", "ppl", "(", ")", ")", "\n", "self", ".", "log", "(", "'Validation xent: %g'", "%", "valid_stats", ".", "xent", "(", ")", ")", "\n", "self", ".", "log", "(", "'Validation accuracy: %g'", "%", "valid_stats", ".", "accuracy", "(", ")", ")", "\n", "\n", "self", ".", "maybe_log_tensorboard", "(", "valid_stats", ",", "\n", "\"valid\"", ",", "\n", "lr", ",", "\n", "step", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.report_manager.build_report_manager": [[11, 28], ["report_manager.ReportMgr", "SummaryWriter"], "function", ["None"], ["def", "build_report_manager", "(", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "tensorboard", ":", "\n", "        ", "from", "tensorboardX", "import", "SummaryWriter", "\n", "tensorboard_log_dir", "=", "opt", ".", "tensorboard_log_dir", "\n", "\n", "#if not opt.train_from:", "\n", "#    tensorboard_log_dir += datetime.now().strftime(\"/%b-%d_%H-%M-%S\")", "\n", "#tensorboard_log_dir += opt.config+'_'+opt.run_name", "\n", "\n", "writer", "=", "SummaryWriter", "(", "tensorboard_log_dir", ",", "\n", "comment", "=", "\"Unmt\"", ")", "\n", "", "else", ":", "\n", "        ", "writer", "=", "None", "\n", "\n", "", "report_mgr", "=", "ReportMgr", "(", "opt", ".", "report_every", ",", "start_time", "=", "-", "1", ",", "\n", "tensorboard_writer", "=", "writer", ")", "\n", "return", "report_mgr", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.__init__": [[11, 20], ["configargparse.ArgumentParser.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "config_file_parser_class", "=", "cfargparse", ".", "YAMLConfigFileParser", ",", "\n", "formatter_class", "=", "cfargparse", ".", "ArgumentDefaultsHelpFormatter", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "ArgumentParser", ",", "self", ")", ".", "__init__", "(", "\n", "config_file_parser_class", "=", "config_file_parser_class", ",", "\n", "formatter_class", "=", "formatter_class", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.defaults": [[21, 29], ["cls", "callback", "cls.parse_known_args"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "defaults", "(", "cls", ",", "*", "args", ")", ":", "\n", "        ", "\"\"\"Get default arguments added to a parser by all ``*args``.\"\"\"", "\n", "dummy_parser", "=", "cls", "(", ")", "\n", "for", "callback", "in", "args", ":", "\n", "            ", "callback", "(", "dummy_parser", ")", "\n", "", "defaults", "=", "dummy_parser", ".", "parse_known_args", "(", "[", "]", ")", "[", "0", "]", "\n", "return", "defaults", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.update_model_opts": [[30, 56], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "update_model_opts", "(", "cls", ",", "model_opt", ")", ":", "\n", "        ", "if", "model_opt", ".", "word_vec_size", ">", "0", ":", "\n", "            ", "model_opt", ".", "src_word_vec_size", "=", "model_opt", ".", "word_vec_size", "\n", "model_opt", ".", "tgt_word_vec_size", "=", "model_opt", ".", "word_vec_size", "\n", "\n", "", "if", "model_opt", ".", "layers", ">", "0", ":", "\n", "            ", "model_opt", ".", "enc_layers", "=", "model_opt", ".", "layers", "\n", "model_opt", ".", "dec_layers", "=", "model_opt", ".", "layers", "\n", "\n", "", "if", "model_opt", ".", "rnn_size", ">", "0", ":", "\n", "            ", "model_opt", ".", "enc_rnn_size", "=", "model_opt", ".", "rnn_size", "\n", "model_opt", ".", "dec_rnn_size", "=", "model_opt", ".", "rnn_size", "\n", "\n", "", "if", "model_opt", ".", "heads", ">", "0", ":", "\n", "            ", "model_opt", ".", "enc_heads", "=", "model_opt", ".", "heads", "\n", "model_opt", ".", "dec_heads", "=", "model_opt", ".", "heads", "\n", "\n", "", "model_opt", ".", "brnn", "=", "model_opt", ".", "encoder_type", "==", "\"brnn\"", "\n", "\n", "if", "model_opt", ".", "copy_attn_type", "is", "None", ":", "\n", "            ", "model_opt", ".", "copy_attn_type", "=", "model_opt", ".", "global_attention", "\n", "\n", "", "if", "model_opt", ".", "position_encoding_learned", ":", "\n", "            ", "model_opt", ".", "position_encoding_learned_enc", "=", "True", "\n", "model_opt", ".", "position_encoding_learned_dec", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.validate_model_opts": [[57, 96], ["onmt.utils.logging.logger.warning", "AssertionError", "AssertionError", "AssertionError", "AssertionError", "AssertionError", "int", "int", "int"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "validate_model_opts", "(", "cls", ",", "model_opt", ")", ":", "\n", "        ", "assert", "model_opt", ".", "model_type", "in", "[", "\"text\"", ",", "\"img\"", ",", "\"audio\"", ",", "'imgvec'", ",", "'none'", "]", ",", "\"Unsupported model type %s\"", "%", "model_opt", ".", "model_type", "\n", "\n", "# this check is here because audio allows the encoder and decoder to", "\n", "# be different sizes, but other model types do not yet", "\n", "same_size", "=", "model_opt", ".", "enc_rnn_size", "==", "model_opt", ".", "dec_rnn_size", "\n", "assert", "model_opt", ".", "model_type", "==", "'audio'", "or", "same_size", ",", "\"The encoder and decoder rnns must be the same size for now\"", "\n", "\n", "assert", "model_opt", ".", "rnn_type", "!=", "\"SRU\"", "or", "model_opt", ".", "gpu_ranks", ",", "\"Using SRU requires -gpu_ranks set.\"", "\n", "if", "model_opt", ".", "share_embeddings", ":", "\n", "            ", "if", "model_opt", ".", "model_type", "!=", "\"text\"", ":", "\n", "                ", "raise", "AssertionError", "(", "\n", "\"--share_embeddings requires --model_type text.\"", ")", "\n", "", "", "if", "model_opt", ".", "model_dtype", "==", "\"fp16\"", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"FP16 is experimental, the generated checkpoints may \"", "\n", "\"be incompatible with a future version\"", ")", "\n", "\n", "", "if", "model_opt", ".", "share_position_embeddings", "and", "not", "model_opt", ".", "position_encoding_learned", ":", "\n", "            ", "raise", "AssertionError", "(", "'It does not make sense to share position embeddings if '", "\n", "'they are not learned'", ")", "\n", "", "if", "int", "(", "model_opt", ".", "use_GPT_version_psa", ")", "+", "int", "(", "model_opt", ".", "use_GPT_version_unconditional", ")", "+", "int", "(", "model_opt", ".", "use_GPT_version_ctxattn", ")", ">", "1", ":", "\n", "            ", "raise", "AssertionError", "(", "'At most one of use_GPT_version, use_GPT_version_alt, '", "\n", "'use_GPT_version_psa, use_GPT_version_unconditional, '", "\n", "'use_GPT_version_ctxattn can be true at the same time'", ")", "\n", "\n", "", "if", "model_opt", ".", "simple_fusion", "and", "model_opt", ".", "gpt2_params_path", "is", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "'Simple fusion requires setting the gpt2_params_path option'", ")", "\n", "\n", "", "if", "model_opt", ".", "attn_hidden", ">", "0", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "if", "model_opt", ".", "GPT_representation_mode", "!=", "'none'", "and", "(", "model_opt", ".", "gpt2_init_embanddec", "or", "model_opt", ".", "simple_fusion", "or", "model_opt", ".", "gpt2_init_embandenc", ")", ":", "\n", "            ", "raise", "AssertionError", "(", "'loading GPT weights for seq2seq initialization AND GPT '", "\n", "'probably does not make sense'", ")", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.ckpt_model_opts": [[98, 106], ["cls.defaults", "cls.defaults.__dict__.update"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.defaults", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.update"], ["", "", "@", "classmethod", "\n", "def", "ckpt_model_opts", "(", "cls", ",", "ckpt_opt", ")", ":", "\n", "# Load default opt values, then overwrite with the opts in", "\n", "# the checkpoint. That way, if there are new options added,", "\n", "# the defaults are used.", "\n", "        ", "opt", "=", "cls", ".", "defaults", "(", "opts", ".", "model_opts", ")", "\n", "opt", ".", "__dict__", ".", "update", "(", "ckpt_opt", ".", "__dict__", ")", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.validate_train_opts": [[107, 140], ["AssertionError", "AssertionError", "AssertionError", "torch.cuda.is_available", "onmt.utils.logging.logger.info", "AssertionError", "AssertionError", "AssertionError", "AssertionError", "AssertionError"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "validate_train_opts", "(", "cls", ",", "opt", ")", ":", "\n", "        ", "if", "opt", ".", "epochs", ":", "\n", "            ", "raise", "AssertionError", "(", "\n", "\"-epochs is deprecated please use -train_steps.\"", ")", "\n", "", "if", "opt", ".", "truncated_decoder", ">", "0", "and", "opt", ".", "accum_count", ">", "1", ":", "\n", "            ", "raise", "AssertionError", "(", "\"BPTT is not compatible with -accum > 1\"", ")", "\n", "", "if", "opt", ".", "gpuid", ":", "\n", "            ", "raise", "AssertionError", "(", "\"gpuid is deprecated \\\n                  see world_size and gpu_ranks\"", ")", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "opt", ".", "gpu_ranks", ":", "\n", "            ", "logger", ".", "info", "(", "\"WARNING: You have a CUDA device, \\\n                        should run with -gpu_ranks\"", ")", "\n", "\n", "", "if", "opt", ".", "gpt2_params_path", "is", "not", "None", "and", "not", "(", "opt", ".", "gpt2_init_embanddec", "or", "opt", ".", "gpt2_init_embandenc", ")", "and", "opt", ".", "gpt2_params_std", "<=", "0", "and", "not", "opt", ".", "simple_fusion", "and", "opt", ".", "GPT_representation_mode", "==", "'none'", ":", "\n", "            ", "raise", "AssertionError", "(", "'Loading GPT parameters but not doing anything with them!'", ")", "\n", "\n", "", "if", "(", "opt", ".", "gpt2_init_embanddec", "or", "opt", ".", "gpt2_params_std", ">", "0", ")", "and", "opt", ".", "gpt2_params_path", "is", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "'Trying to use gpt2 parameters, but gpt2_params_path is not given'", ")", "\n", "\n", "", "if", "opt", ".", "train_from", "and", "opt", ".", "gpt2_init_embanddec", ":", "\n", "            ", "raise", "AssertionError", "(", "'Trying to initialize gpt2 weights while also loading a save file. This is likely a mistake.'", ")", "\n", "\n", "", "if", "opt", ".", "train_from", "and", "opt", ".", "encoder_from", ":", "\n", "            ", "raise", "AssertionError", "(", "'Trying to initialize encoder weights while also loading a save file. This is likely a mistake.'", ")", "\n", "\n", "", "if", "opt", ".", "attn_dropout", "<", "0", ":", "\n", "            ", "opt", ".", "attn_dropout", "=", "opt", ".", "dropout", "\n", "\n", "", "if", "opt", ".", "train_from", "and", "opt", ".", "load_uncond_from", ":", "\n", "            ", "raise", "AssertionError", "(", "'Only one of train_from, load_uncond_from makes sense'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.validate_translate_opts": [[142, 146], ["ValueError"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "validate_translate_opts", "(", "cls", ",", "opt", ")", ":", "\n", "        ", "if", "opt", ".", "beam_size", "!=", "1", "and", "opt", ".", "random_sampling_topk", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "'Can either do beam search OR random sampling.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.validate_preprocess_args": [[147, 169], ["os.path.isfile", "os.path.isfile", "os.path.isfile", "ValueError", "os.path.isfile"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "validate_preprocess_args", "(", "cls", ",", "opt", ")", ":", "\n", "        ", "assert", "opt", ".", "max_shard_size", "==", "0", ",", "\"-max_shard_size is deprecated. Please use \\\n            -shard_size (number of examples) instead.\"", "\n", "assert", "opt", ".", "shuffle", "==", "0", ",", "\"-shuffle is not implemented. Please shuffle \\\n            your data before pre-processing.\"", "\n", "\n", "assert", "(", "opt", ".", "data_type", "==", "'none'", "or", "os", ".", "path", ".", "isfile", "(", "opt", ".", "train_src", ")", ")", "and", "os", ".", "path", ".", "isfile", "(", "opt", ".", "train_tgt", ")", ",", "\"Please check path of your train src and tgt files!\"", "\n", "\n", "assert", "not", "opt", ".", "valid_src", "or", "os", ".", "path", ".", "isfile", "(", "opt", ".", "valid_src", ")", ",", "\"Please check path of your valid src file!\"", "\n", "assert", "not", "opt", ".", "valid_tgt", "or", "os", ".", "path", ".", "isfile", "(", "opt", ".", "valid_tgt", ")", ",", "\"Please check path of your valid tgt file!\"", "\n", "\n", "if", "opt", ".", "free_src", "and", "not", "opt", ".", "fixed_vocab", ":", "\n", "            ", "raise", "ValueError", "(", "'free_src only makes sense when using fixed_vocab'", ")", "\n", "\n", "", "assert", "not", "(", "opt", ".", "data_type", "==", "'imgvec'", "and", "opt", ".", "shard_size", ">", "0", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LossComputeBase.__init__": [[87, 91], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "criterion", ",", "generator", ")", ":", "\n", "        ", "super", "(", "LossComputeBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "criterion", "=", "criterion", "\n", "self", ".", "generator", "=", "generator", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LossComputeBase.padding_idx": [[92, 95], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "padding_idx", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "criterion", ".", "ignore_index", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LossComputeBase._make_shard_state": [[96, 109], ["None"], "methods", ["None"], ["", "def", "_make_shard_state", "(", "self", ",", "batch", ",", "output", ",", "range_", ",", "attns", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Make shard state dictionary for shards() to return iterable\n        shards for efficient loss computation. Subclass must define\n        this method to match its own _compute_loss() interface.\n        Args:\n            batch: the current batch.\n            output: the predict output from the model.\n            range_: the range of examples for computing, the whole\n                    batch or a trunc of it?\n            attns: the attns dictionary returned from the model.\n        \"\"\"", "\n", "return", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LossComputeBase._compute_loss": [[110, 122], ["None"], "methods", ["None"], ["", "def", "_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "target", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Compute the loss. Subclass must define this method.\n\n        Args:\n\n            batch: the current batch.\n            output: the predict output from the model.\n            target: the validate target to compare output with.\n            **kwargs(optional): additional info for computing loss.\n        \"\"\"", "\n", "return", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LossComputeBase.__call__": [[123, 171], ["loss.LossComputeBase._make_shard_state", "onmt.utils.Statistics", "loss.shards", "loss.LossComputeBase._compute_loss", "loss.LossComputeBase._compute_loss", "loss.div().backward", "onmt.utils.Statistics.update", "batch.tgt.size", "float", "loss.div", "float"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.CopyGeneratorLossCompute._make_shard_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.shards", "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.CopyGeneratorLossCompute._compute_loss", "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.CopyGeneratorLossCompute._compute_loss", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.update"], ["", "def", "__call__", "(", "self", ",", "\n", "batch", ",", "\n", "output", ",", "\n", "attns", ",", "\n", "normalization", "=", "1.0", ",", "\n", "shard_size", "=", "0", ",", "\n", "trunc_start", "=", "0", ",", "\n", "trunc_size", "=", "None", ")", ":", "\n", "        ", "\"\"\"Compute the forward loss, possibly in shards in which case this\n        method also runs the backward pass and returns ``None`` as the loss\n        value.\n\n        Also supports truncated BPTT for long sequences by taking a\n        range in the decoder output sequence to back propagate in.\n        Range is from `(trunc_start, trunc_start + trunc_size)`.\n\n        Note sharding is an exact efficiency trick to relieve memory\n        required for the generation buffers. Truncation is an\n        approximate efficiency trick to relieve the memory required\n        in the RNN buffers.\n\n        Args:\n          batch (batch) : batch of labeled examples\n          output (:obj:`FloatTensor`) :\n              output of decoder model `[tgt_len x batch x hidden]`\n          attns (dict) : dictionary of attention distributions\n              `[tgt_len x batch x src_len]`\n          normalization: Optional normalization factor.\n          shard_size (int) : maximum number of examples in a shard\n          trunc_start (int) : starting position of truncation window\n          trunc_size (int) : length of truncation window\n\n        Returns:\n            A tuple with the loss and a :obj:`onmt.utils.Statistics` instance.\n        \"\"\"", "\n", "if", "trunc_size", "is", "None", ":", "\n", "            ", "trunc_size", "=", "batch", ".", "tgt", ".", "size", "(", "0", ")", "-", "trunc_start", "\n", "", "trunc_range", "=", "(", "trunc_start", ",", "trunc_start", "+", "trunc_size", ")", "\n", "shard_state", "=", "self", ".", "_make_shard_state", "(", "batch", ",", "output", ",", "trunc_range", ",", "attns", ")", "\n", "if", "shard_size", "==", "0", ":", "\n", "            ", "loss", ",", "stats", "=", "self", ".", "_compute_loss", "(", "batch", ",", "**", "shard_state", ")", "\n", "return", "loss", "/", "float", "(", "normalization", ")", ",", "stats", "\n", "", "batch_stats", "=", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n", "for", "shard", "in", "shards", "(", "shard_state", ",", "shard_size", ")", ":", "\n", "            ", "loss", ",", "stats", "=", "self", ".", "_compute_loss", "(", "batch", ",", "**", "shard", ")", "\n", "loss", ".", "div", "(", "float", "(", "normalization", ")", ")", ".", "backward", "(", ")", "\n", "batch_stats", ".", "update", "(", "stats", ")", "\n", "", "return", "None", ",", "batch_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LossComputeBase._stats": [[172, 187], ["target.ne", "pred.eq().masked_select().sum().item", "target.ne.sum().item", "onmt.utils.Statistics", "scores.max", "loss.item", "pred.eq().masked_select().sum", "target.ne.sum", "pred.eq().masked_select", "pred.eq"], "methods", ["None"], ["", "def", "_stats", "(", "self", ",", "loss", ",", "scores", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            loss (:obj:`FloatTensor`): the loss computed by the loss criterion.\n            scores (:obj:`FloatTensor`): a score for each possible output\n            target (:obj:`FloatTensor`): true targets\n\n        Returns:\n            :obj:`onmt.utils.Statistics` : statistics for this batch.\n        \"\"\"", "\n", "pred", "=", "scores", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "non_padding", "=", "target", ".", "ne", "(", "self", ".", "padding_idx", ")", "\n", "num_correct", "=", "pred", ".", "eq", "(", "target", ")", ".", "masked_select", "(", "non_padding", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "num_non_padding", "=", "non_padding", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "onmt", ".", "utils", ".", "Statistics", "(", "loss", ".", "item", "(", ")", ",", "num_non_padding", ",", "num_correct", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LossComputeBase._bottle": [[188, 190], ["_v.view", "_v.size"], "methods", ["None"], ["", "def", "_bottle", "(", "self", ",", "_v", ")", ":", "\n", "        ", "return", "_v", ".", "view", "(", "-", "1", ",", "_v", ".", "size", "(", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LossComputeBase._unbottle": [[191, 193], ["_v.view", "_v.size"], "methods", ["None"], ["", "def", "_unbottle", "(", "self", ",", "_v", ",", "batch_size", ")", ":", "\n", "        ", "return", "_v", ".", "view", "(", "-", "1", ",", "batch_size", ",", "_v", ".", "size", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LabelSmoothingLoss.__init__": [[201, 213], ["torch.Module.__init__", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "loss.LabelSmoothingLoss.register_buffer", "torch.full.unsqueeze", "torch.full.unsqueeze", "torch.full.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "label_smoothing", ",", "tgt_vocab_size", ",", "ignore_index", "=", "-", "100", ",", "reduction", "=", "'sum'", ")", ":", "\n", "        ", "assert", "0.0", "<", "label_smoothing", "<=", "1.0", "\n", "self", ".", "ignore_index", "=", "ignore_index", "\n", "super", "(", "LabelSmoothingLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "smoothing_value", "=", "label_smoothing", "/", "(", "tgt_vocab_size", "-", "2", ")", "\n", "one_hot", "=", "torch", ".", "full", "(", "(", "tgt_vocab_size", ",", ")", ",", "smoothing_value", ")", "\n", "one_hot", "[", "self", ".", "ignore_index", "]", "=", "0", "\n", "self", ".", "register_buffer", "(", "'one_hot'", ",", "one_hot", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "self", ".", "confidence", "=", "1.0", "-", "label_smoothing", "\n", "self", ".", "reduction", "=", "reduction", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LabelSmoothingLoss.forward": [[214, 224], ["loss.LabelSmoothingLoss.one_hot.repeat", "loss.LabelSmoothingLoss.scatter_", "loss.LabelSmoothingLoss.masked_fill_", "torch.kl_div", "torch.kl_div", "torch.kl_div", "target.size", "target.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "output", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        output (FloatTensor): batch_size x n_classes\n        target (LongTensor): batch_size\n        \"\"\"", "\n", "model_prob", "=", "self", ".", "one_hot", ".", "repeat", "(", "target", ".", "size", "(", "0", ")", ",", "1", ")", "\n", "model_prob", ".", "scatter_", "(", "1", ",", "target", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "confidence", ")", "\n", "model_prob", ".", "masked_fill_", "(", "(", "target", "==", "self", ".", "ignore_index", ")", ".", "unsqueeze", "(", "1", ")", ",", "0", ")", "\n", "\n", "return", "F", ".", "kl_div", "(", "output", ",", "model_prob", ",", "reduction", "=", "self", ".", "reduction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.NMTLossCompute.__init__": [[231, 233], ["loss.LossComputeBase.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "criterion", ",", "generator", ",", "normalization", "=", "\"sents\"", ")", ":", "\n", "        ", "super", "(", "NMTLossCompute", ",", "self", ")", ".", "__init__", "(", "criterion", ",", "generator", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.NMTLossCompute._make_shard_state": [[234, 238], ["None"], "methods", ["None"], ["", "def", "_make_shard_state", "(", "self", ",", "batch", ",", "output", ",", "range_", ",", "attns", "=", "None", ")", ":", "\n", "        ", "return", "{", "\n", "\"output\"", ":", "output", ",", "\n", "\"target\"", ":", "batch", ".", "tgt", "[", "range_", "[", "0", "]", "+", "1", ":", "range_", "[", "1", "]", ",", ":", ",", "0", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.NMTLossCompute._compute_loss": [[240, 262], ["loss.NMTLossCompute.NMTLossCompute._bottle", "loss.NMTLossCompute.NMTLossCompute.generator", "target.view", "loss.NMTLossCompute.NMTLossCompute.view", "torch.nll_loss", "torch.nll_loss", "torch.nll_loss", "selected_nlls.view.view.view", "loss.NMTLossCompute.NMTLossCompute.criterion", "loss.NMTLossCompute.NMTLossCompute._stats", "loss.NMTLossCompute.NMTLossCompute.clone"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LossComputeBase._bottle", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LossComputeBase._stats"], ["", "def", "_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "target", ")", ":", "\n", "        ", "bottled_output", "=", "self", ".", "_bottle", "(", "output", ")", "\n", "\n", "scores", "=", "self", ".", "generator", "(", "bottled_output", ")", "\n", "gtruth", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "\n", "scores_full", "=", "scores", ".", "view", "(", "output", ".", "shape", "[", "0", "]", ",", "output", ".", "shape", "[", "1", "]", ",", "scores", ".", "shape", "[", "-", "1", "]", ")", "\n", "#print(torch.exp(scores_full)[0])", "\n", "\n", "#scores2 = self._unbottle(scores, output.shape[1])", "\n", "selected_nlls", "=", "F", ".", "nll_loss", "(", "scores", ",", "gtruth", ",", "reduction", "=", "'none'", ")", "\n", "selected_nlls", "=", "selected_nlls", ".", "view", "(", "output", ".", "shape", "[", "0", "]", ",", "output", ".", "shape", "[", "1", "]", ")", "\n", "\n", "#print(target)", "\n", "#print(torch.exp(-selected_nlls))", "\n", "#print(selected_nlls.shape)", "\n", "#print(torch.exp(-selected_nlls.sum(0)))", "\n", "\n", "loss", "=", "self", ".", "criterion", "(", "scores", ",", "gtruth", ")", "\n", "stats", "=", "self", ".", "_stats", "(", "loss", ".", "clone", "(", ")", ",", "scores", ",", "gtruth", ")", "\n", "\n", "return", "loss", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.SimpleFusionLossCompute.__init__": [[269, 271], ["loss.LossComputeBase.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "criterion", ",", "generator", ",", "normalization", "=", "\"sents\"", ")", ":", "\n", "        ", "super", "(", "SimpleFusionLossCompute", ",", "self", ")", ".", "__init__", "(", "criterion", ",", "generator", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.SimpleFusionLossCompute._make_shard_state": [[272, 277], ["None"], "methods", ["None"], ["", "def", "_make_shard_state", "(", "self", ",", "batch", ",", "output", ",", "range_", ",", "attns", "=", "None", ")", ":", "\n", "        ", "return", "{", "\n", "\"output_decoder\"", ":", "output", "[", "0", "]", ",", "\n", "\"output_lm\"", ":", "output", "[", "1", "]", ",", "\n", "\"target\"", ":", "batch", ".", "tgt", "[", "range_", "[", "0", "]", "+", "1", ":", "range_", "[", "1", "]", ",", ":", ",", "0", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.SimpleFusionLossCompute._compute_loss": [[279, 290], ["loss.SimpleFusionLossCompute.SimpleFusionLossCompute._bottle", "loss.SimpleFusionLossCompute.SimpleFusionLossCompute._bottle", "loss.SimpleFusionLossCompute.SimpleFusionLossCompute.generator", "target.view", "loss.SimpleFusionLossCompute.SimpleFusionLossCompute.criterion", "loss.SimpleFusionLossCompute.SimpleFusionLossCompute._stats", "loss.SimpleFusionLossCompute.SimpleFusionLossCompute.clone"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LossComputeBase._bottle", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LossComputeBase._bottle", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LossComputeBase._stats"], ["", "def", "_compute_loss", "(", "self", ",", "batch", ",", "output_decoder", ",", "output_lm", ",", "target", ")", ":", "\n", "        ", "bottled_output_decoder", "=", "self", ".", "_bottle", "(", "output_decoder", ")", "\n", "bottled_output_lm", "=", "self", ".", "_bottle", "(", "output_lm", ")", "\n", "\n", "scores", "=", "self", ".", "generator", "(", "bottled_output_decoder", ",", "bottled_output_lm", ")", "\n", "gtruth", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "\n", "loss", "=", "self", ".", "criterion", "(", "scores", ",", "gtruth", ")", "\n", "stats", "=", "self", ".", "_stats", "(", "loss", ".", "clone", "(", ")", ",", "scores", ",", "gtruth", ")", "\n", "\n", "return", "loss", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.build_loss_compute": [[15, 66], ["torch.device", "torch.device", "torch.device", "print", "print", "print", "isinstance", "NMTLossCompute.to", "onmt.modules.CopyGeneratorLoss", "onmt.modules.CopyGeneratorLossCompute", "onmt.utils.misc.use_gpu", "len", "len", "loss.LabelSmoothingLoss", "loss.SimpleFusionLossCompute", "loss.NMTLossCompute", "len", "isinstance", "onmt.modules.sparse_losses.SparsemaxLoss", "torch.NLLLoss"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.use_gpu"], ["def", "build_loss_compute", "(", "model", ",", "tgt_field", ",", "opt", ",", "train", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Returns a LossCompute subclass which wraps around an nn.Module subclass\n    (such as nn.NLLLoss) which defines the loss criterion. The LossCompute\n    object allows this loss to be computed in shards and passes the relevant\n    data to a Statistics object which handles training/validation logging.\n    Currently, the NMTLossCompute class handles all loss computation except\n    for when using a copy mechanism.\n    \"\"\"", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "onmt", ".", "utils", ".", "misc", ".", "use_gpu", "(", "opt", ")", "else", "\"cpu\"", ")", "\n", "\n", "padding_idx", "=", "tgt_field", ".", "vocab", ".", "stoi", "[", "tgt_field", ".", "pad_token", "]", "\n", "unk_idx", "=", "tgt_field", ".", "vocab", ".", "stoi", "[", "tgt_field", ".", "unk_token", "]", "\n", "print", "(", "\"padding_idx is {}\"", ".", "format", "(", "padding_idx", ")", ")", "\n", "print", "(", "\"unk_idx is {}\"", ".", "format", "(", "unk_idx", ")", ")", "\n", "print", "(", "\"length of words is {}\"", ".", "format", "(", "len", "(", "tgt_field", ".", "vocab", ".", "stoi", ")", ")", ")", "\n", "reduction", "=", "'sum'", "\n", "\n", "if", "opt", ".", "copy_attn", ":", "\n", "        ", "criterion", "=", "onmt", ".", "modules", ".", "CopyGeneratorLoss", "(", "\n", "len", "(", "tgt_field", ".", "vocab", ")", ",", "opt", ".", "copy_attn_force", ",", "\n", "unk_index", "=", "unk_idx", ",", "ignore_index", "=", "padding_idx", "\n", ")", "\n", "", "elif", "opt", ".", "label_smoothing", ">", "0", "and", "train", ":", "\n", "        ", "criterion", "=", "LabelSmoothingLoss", "(", "\n", "opt", ".", "label_smoothing", ",", "len", "(", "tgt_field", ".", "vocab", ")", ",", "ignore_index", "=", "padding_idx", ",", "\n", "reduction", "=", "reduction", "\n", ")", "\n", "", "elif", "not", "opt", ".", "simple_fusion", "and", "isinstance", "(", "model", ".", "generator", "[", "-", "1", "]", ",", "LogSparsemax", ")", ":", "\n", "        ", "criterion", "=", "SparsemaxLoss", "(", "ignore_index", "=", "padding_idx", ",", "reduction", "=", "reduction", ")", "\n", "", "else", ":", "\n", "        ", "criterion", "=", "nn", ".", "NLLLoss", "(", "ignore_index", "=", "padding_idx", ",", "reduction", "=", "reduction", ")", "\n", "\n", "# if the loss function operates on vectors of raw logits instead of", "\n", "# probabilities, only the first part of the generator needs to be", "\n", "# passed to the NMTLossCompute. At the moment, the only supported", "\n", "# loss function of this kind is the sparsemax loss.", "\n", "", "use_raw_logits", "=", "isinstance", "(", "criterion", ",", "SparsemaxLoss", ")", "\n", "loss_gen", "=", "model", ".", "generator", "[", "0", "]", "if", "use_raw_logits", "else", "model", ".", "generator", "\n", "if", "opt", ".", "copy_attn", ":", "\n", "        ", "compute", "=", "onmt", ".", "modules", ".", "CopyGeneratorLossCompute", "(", "\n", "criterion", ",", "loss_gen", ",", "tgt_field", ".", "vocab", ",", "opt", ".", "copy_loss_by_seqlength", ",", "\n", "ptrs_loss", "=", "opt", ".", "use_copy_ptrs", "\n", ")", "\n", "", "elif", "opt", ".", "simple_fusion", ":", "\n", "        ", "compute", "=", "SimpleFusionLossCompute", "(", "criterion", ",", "loss_gen", ")", "\n", "", "else", ":", "\n", "        ", "compute", "=", "NMTLossCompute", "(", "criterion", ",", "loss_gen", ")", "\n", "", "compute", ".", "to", "(", "device", ")", "\n", "\n", "return", "compute", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.filter_shard_state": [[292, 305], ["state.items", "isinstance", "torch.split", "torch.split", "torch.split", "v_chunk.data.clone.data.clone", "v_split.append"], "function", ["None"], ["", "", "def", "filter_shard_state", "(", "state", ",", "shard_size", "=", "None", ")", ":", "\n", "    ", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", ":", "\n", "        ", "if", "shard_size", "is", "None", ":", "\n", "            ", "yield", "k", ",", "v", "\n", "\n", "", "if", "v", "is", "not", "None", ":", "\n", "            ", "v_split", "=", "[", "]", "\n", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "for", "v_chunk", "in", "torch", ".", "split", "(", "v", ",", "shard_size", ")", ":", "\n", "                    ", "v_chunk", "=", "v_chunk", ".", "data", ".", "clone", "(", ")", "\n", "v_chunk", ".", "requires_grad", "=", "v", ".", "requires_grad", "\n", "v_split", ".", "append", "(", "v_chunk", ")", "\n", "", "", "yield", "k", ",", "(", "v", ",", "v_split", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.shards": [[307, 355], ["dict", "zip", "zip", "dict.items", "zip", "torch.autograd.backward", "torch.autograd.backward", "torch.autograd.backward", "loss.filter_shard_state", "loss.filter_shard_state", "dict", "isinstance", "variables.extend", "zip", "zip", "dict.items", "torch.split", "torch.split", "torch.split"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.filter_shard_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.filter_shard_state"], ["", "", "", "def", "shards", "(", "state", ",", "shard_size", ",", "eval_only", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        state: A dictionary which corresponds to the output of\n               *LossCompute._make_shard_state(). The values for\n               those keys are Tensor-like or None.\n        shard_size: The maximum size of the shards yielded by the model.\n        eval_only: If True, only yield the state, nothing else.\n              Otherwise, yield shards.\n\n    Yields:\n        Each yielded shard is a dict.\n\n    Side effect:\n        After the last shard, this function does back-propagation.\n    \"\"\"", "\n", "if", "eval_only", ":", "\n", "        ", "yield", "filter_shard_state", "(", "state", ")", "\n", "", "else", ":", "\n", "# non_none: the subdict of the state dictionary where the values", "\n", "# are not None.", "\n", "        ", "non_none", "=", "dict", "(", "filter_shard_state", "(", "state", ",", "shard_size", ")", ")", "\n", "\n", "# Now, the iteration:", "\n", "# state is a dictionary of sequences of tensor-like but we", "\n", "# want a sequence of dictionaries of tensors.", "\n", "# First, unzip the dictionary into a sequence of keys and a", "\n", "# sequence of tensor-like sequences.", "\n", "keys", ",", "values", "=", "zip", "(", "*", "(", "(", "k", ",", "[", "v_chunk", "for", "v_chunk", "in", "v_split", "]", ")", "\n", "for", "k", ",", "(", "_", ",", "v_split", ")", "in", "non_none", ".", "items", "(", ")", ")", ")", "\n", "\n", "# Now, yield a dictionary for each shard. The keys are always", "\n", "# the same. values is a sequence of length #keys where each", "\n", "# element is a sequence of length #shards. We want to iterate", "\n", "# over the shards, not over the keys: therefore, the values need", "\n", "# to be re-zipped by shard and then each shard can be paired", "\n", "# with the keys.", "\n", "for", "shard_tensors", "in", "zip", "(", "*", "values", ")", ":", "\n", "            ", "yield", "dict", "(", "zip", "(", "keys", ",", "shard_tensors", ")", ")", "\n", "\n", "# Assumed backprop'd", "\n", "", "variables", "=", "[", "]", "\n", "for", "k", ",", "(", "v", ",", "v_split", ")", "in", "non_none", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", "and", "state", "[", "k", "]", ".", "requires_grad", ":", "\n", "                ", "variables", ".", "extend", "(", "zip", "(", "torch", ".", "split", "(", "state", "[", "k", "]", ",", "shard_size", ")", ",", "\n", "[", "v_chunk", ".", "grad", "for", "v_chunk", "in", "v_split", "]", ")", ")", "\n", "", "", "inputs", ",", "grads", "=", "zip", "(", "*", "variables", ")", "\n", "torch", ".", "autograd", ".", "backward", "(", "inputs", ",", "grads", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.cnn_factory.GatedConv.__init__": [[21, 28], ["torch.Module.__init__", "onmt.modules.WeightNormConv2d", "torch.xavier_uniform_", "torch.xavier_uniform_", "torch.xavier_uniform_", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "width", "=", "3", ",", "dropout", "=", "0.2", ",", "nopad", "=", "False", ")", ":", "\n", "        ", "super", "(", "GatedConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "onmt", ".", "modules", ".", "WeightNormConv2d", "(", "\n", "input_size", ",", "2", "*", "input_size", ",", "kernel_size", "=", "(", "width", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ",", "\n", "padding", "=", "(", "width", "//", "2", "*", "(", "1", "-", "nopad", ")", ",", "0", ")", ")", "\n", "init", ".", "xavier_uniform_", "(", "self", ".", "conv", ".", "weight", ",", "gain", "=", "(", "4", "*", "(", "1", "-", "dropout", ")", ")", "**", "0.5", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.cnn_factory.GatedConv.forward": [[29, 35], ["cnn_factory.GatedConv.dropout", "cnn_factory.GatedConv.conv", "cnn_factory.GatedConv.split", "int", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "cnn_factory.GatedConv.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_var", ")", ":", "\n", "        ", "x_var", "=", "self", ".", "dropout", "(", "x_var", ")", "\n", "x_var", "=", "self", ".", "conv", "(", "x_var", ")", "\n", "out", ",", "gate", "=", "x_var", ".", "split", "(", "int", "(", "x_var", ".", "size", "(", "1", ")", "/", "2", ")", ",", "1", ")", "\n", "out", "=", "out", "*", "torch", ".", "sigmoid", "(", "gate", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.cnn_factory.StackedCNN.__init__": [[40, 49], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "cnn_factory.StackedCNN.layers.append", "cnn_factory.GatedConv"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "cnn_kernel_width", "=", "3", ",", "\n", "dropout", "=", "0.2", ")", ":", "\n", "        ", "super", "(", "StackedCNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "\n", "GatedConv", "(", "input_size", ",", "cnn_kernel_width", ",", "dropout", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.cnn_factory.StackedCNN.forward": [[50, 55], ["conv"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "conv", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "x", "+", "conv", "(", "x", ")", "\n", "x", "*=", "SCALE_WEIGHT", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.cnn_factory.shape_transform": [[13, 16], ["torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.transpose", "torch.transpose", "torch.transpose"], "function", ["None"], ["def", "shape_transform", "(", "x", ")", ":", "\n", "    ", "\"\"\" Tranform the size of the tensors to fit for conv input. \"\"\"", "\n", "return", "torch", ".", "unsqueeze", "(", "torch", ".", "transpose", "(", "x", ",", "1", ",", "2", ")", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.rnn_factory.rnn_factory": [[8, 18], ["onmt.models.sru.SRU", "getattr"], "function", ["None"], ["def", "rnn_factory", "(", "rnn_type", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" rnn factory, Use pytorch version when available. \"\"\"", "\n", "no_pack_padded_seq", "=", "False", "\n", "if", "rnn_type", "==", "\"SRU\"", ":", "\n", "# SRU doesn't support PackedSequence.", "\n", "        ", "no_pack_padded_seq", "=", "True", "\n", "rnn", "=", "onmt", ".", "models", ".", "sru", ".", "SRU", "(", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "rnn", "=", "getattr", "(", "nn", ",", "rnn_type", ")", "(", "**", "kwargs", ")", "\n", "", "return", "rnn", ",", "no_pack_padded_seq", "\n", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.split_corpus": [[9, 28], ["open", "list", "iter_func", "f.readlines", "itertools.islice", "f.readlines", "iter_func"], "function", ["None"], ["def", "split_corpus", "(", "path", ",", "shard_size", ",", "iter_func", "=", "None", ",", "binary", "=", "True", ")", ":", "\n", "    ", "priv_str", "=", "\"r\"", "\n", "if", "binary", ":", "\n", "        ", "priv_str", "+=", "\"b\"", "\n", "", "with", "open", "(", "path", ",", "priv_str", ")", "as", "f", ":", "\n", "        ", "if", "shard_size", "<=", "0", ":", "\n", "            ", "if", "iter_func", "is", "not", "None", ":", "\n", "                ", "yield", "iter_func", "(", "f", ".", "readlines", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "yield", "f", ".", "readlines", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "shard", "=", "list", "(", "islice", "(", "f", ",", "shard_size", ")", ")", "\n", "if", "not", "shard", ":", "\n", "                    ", "break", "\n", "", "if", "iter_func", "is", "not", "None", ":", "\n", "                    ", "yield", "iter_func", "(", "shard", ")", "\n", "", "else", ":", "\n", "                    ", "yield", "shard", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.split_labels": [[29, 40], ["open", "list", "int", "itertools.islice", "i.strip", "f.readlines", "int", "i.strip"], "function", ["None"], ["", "", "", "", "", "def", "split_labels", "(", "path", ",", "shard_size", ",", "iter_func", "=", "None", ",", "binary", "=", "True", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "if", "shard_size", "<=", "0", ":", "\n", "            ", "yield", "[", "int", "(", "i", ".", "strip", "(", ")", ")", "for", "i", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "shard", "=", "list", "(", "islice", "(", "f", ",", "shard_size", ")", ")", "\n", "if", "not", "shard", ":", "\n", "                    ", "break", "\n", "", "else", ":", "\n", "                    ", "yield", "[", "int", "(", "i", ".", "strip", "(", ")", ")", "for", "i", "in", "shard", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq": [[41, 49], ["next", "all", "str"], "function", ["None"], ["", "", "", "", "", "def", "aeq", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    Assert all arguments have the same value\n    \"\"\"", "\n", "arguments", "=", "(", "arg", "for", "arg", "in", "args", ")", "\n", "first", "=", "next", "(", "arguments", ")", "\n", "assert", "all", "(", "arg", "==", "first", "for", "arg", "in", "arguments", ")", ",", "\"Not all arguments have the same value: \"", "+", "str", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.sequence_mask": [[51, 61], ["lengths.numel", "torch.arange().type_as().repeat().lt", "lengths.max", "lengths.unsqueeze", "torch.arange().type_as().repeat", "torch.arange().type_as", "torch.arange"], "function", ["None"], ["", "def", "sequence_mask", "(", "lengths", ",", "max_len", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Creates a boolean mask from sequence lengths.\n    \"\"\"", "\n", "batch_size", "=", "lengths", ".", "numel", "(", ")", "\n", "max_len", "=", "max_len", "or", "lengths", ".", "max", "(", ")", "\n", "return", "(", "torch", ".", "arange", "(", "0", ",", "max_len", ")", "\n", ".", "type_as", "(", "lengths", ")", "\n", ".", "repeat", "(", "batch_size", ",", "1", ")", "\n", ".", "lt", "(", "lengths", ".", "unsqueeze", "(", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile": [[63, 91], ["list", "list", "x.permute().contiguous.size", "x.permute().contiguous.contiguous().view", "x.permute().contiguous.transpose", "x.permute().contiguous.repeat", "x.permute().contiguous.transpose", "x.permute().contiguous.contiguous", "x.permute().contiguous.view", "range", "x.permute().contiguous.permute().contiguous", "x.permute().contiguous.size", "x.permute().contiguous.permute().contiguous", "len", "x.permute().contiguous.contiguous", "x.permute().contiguous.size", "x.permute().contiguous.permute", "x.permute().contiguous.permute"], "function", ["None"], ["", "def", "tile", "(", "x", ",", "count", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Tiles x on dimension dim count times.\n    \"\"\"", "\n", "perm", "=", "list", "(", "range", "(", "len", "(", "x", ".", "size", "(", ")", ")", ")", ")", "\n", "if", "dim", "!=", "0", ":", "\n", "        ", "perm", "[", "0", "]", ",", "perm", "[", "dim", "]", "=", "perm", "[", "dim", "]", ",", "perm", "[", "0", "]", "\n", "x", "=", "x", ".", "permute", "(", "perm", ")", ".", "contiguous", "(", ")", "\n", "", "out_size", "=", "list", "(", "x", ".", "size", "(", ")", ")", "\n", "out_size", "[", "0", "]", "*=", "count", "\n", "batch", "=", "x", ".", "size", "(", "0", ")", "\n", "'''\n    x = x.view(batch, -1) \\\n         .transpose(0, 1) \\\n         .repeat(count, 1) \\\n         .transpose(0, 1) \\\n         .contiguous() \\\n         .view(*out_size)\n    '''", "\n", "x", "=", "x", ".", "contiguous", "(", ")", ".", "view", "(", "batch", ",", "-", "1", ")", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "x", "=", "x", ".", "repeat", "(", "count", ",", "1", ")", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "x", "=", "x", ".", "contiguous", "(", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "out_size", ")", "\n", "if", "dim", "!=", "0", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "perm", ")", ".", "contiguous", "(", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.use_gpu": [[93, 99], ["hasattr", "hasattr", "len"], "function", ["None"], ["", "def", "use_gpu", "(", "opt", ")", ":", "\n", "    ", "\"\"\"\n    Creates a boolean if gpu used\n    \"\"\"", "\n", "return", "(", "hasattr", "(", "opt", ",", "'gpu_ranks'", ")", "and", "len", "(", "opt", ".", "gpu_ranks", ")", ">", "0", ")", "or", "(", "hasattr", "(", "opt", ",", "'gpu'", ")", "and", "opt", ".", "gpu", ">", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.set_random_seed": [[101, 115], ["torch.manual_seed", "random.seed", "torch.cuda.manual_seed"], "function", ["None"], ["", "def", "set_random_seed", "(", "seed", ",", "is_cuda", ")", ":", "\n", "    ", "\"\"\"Sets the random seed.\"\"\"", "\n", "if", "seed", ">", "0", ":", "\n", "        ", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "# this one is needed for torchtext random call (shuffled iterator)", "\n", "# in multi gpu it ensures datasets are read in the same order", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "# some cudnn methods can be random even after fixing the seed", "\n", "# unless you tell it to be deterministic", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n", "", "if", "is_cuda", "and", "seed", ">", "0", ":", "\n", "# These ensure same initialization in multi gpu mode", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.generate_relative_positions_matrix": [[117, 133], ["torch.clamp", "torch.arange().unsqueeze", "torch.arange", "torch.arange.unsqueeze().expand().transpose", "range_vec.unsqueeze().expand().transpose.transpose", "torch.arange", "torch.arange.unsqueeze().expand", "torch.arange.unsqueeze"], "function", ["None"], ["", "", "def", "generate_relative_positions_matrix", "(", "length", ",", "max_relative_positions", ",", "\n", "cache", "=", "False", ")", ":", "\n", "    ", "\"\"\"Generate the clipped relative positions matrix\n       for a given length and maximum relative positions\"\"\"", "\n", "if", "cache", ":", "\n", "        ", "distance_mat", "=", "torch", ".", "arange", "(", "-", "length", "+", "1", ",", "1", ",", "1", ")", ".", "unsqueeze", "(", "0", ")", "\n", "", "else", ":", "\n", "        ", "range_vec", "=", "torch", ".", "arange", "(", "length", ")", "\n", "range_mat", "=", "range_vec", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "length", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "distance_mat", "=", "range_mat", "-", "range_mat", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "distance_mat_clipped", "=", "torch", ".", "clamp", "(", "distance_mat", ",", "\n", "min", "=", "-", "max_relative_positions", ",", "\n", "max", "=", "max_relative_positions", ")", "\n", "# Shift values to be >= 0", "\n", "final_mat", "=", "distance_mat_clipped", "+", "max_relative_positions", "\n", "return", "final_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.relative_matmul": [[135, 150], ["x.permute", "x.permute.reshape", "torch.matmul.reshape", "x_tz_matmul.reshape.permute", "z.transpose", "torch.matmul", "torch.matmul"], "function", ["None"], ["", "def", "relative_matmul", "(", "x", ",", "z", ",", "transpose", ")", ":", "\n", "    ", "\"\"\"Helper function for relative positions attention.\"\"\"", "\n", "batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "heads", "=", "x", ".", "shape", "[", "1", "]", "\n", "length", "=", "x", ".", "shape", "[", "2", "]", "\n", "x_t", "=", "x", ".", "permute", "(", "2", ",", "0", ",", "1", ",", "3", ")", "\n", "x_t_r", "=", "x_t", ".", "reshape", "(", "length", ",", "heads", "*", "batch_size", ",", "-", "1", ")", "\n", "if", "transpose", ":", "\n", "        ", "z_t", "=", "z", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x_tz_matmul", "=", "torch", ".", "matmul", "(", "x_t_r", ",", "z_t", ")", "\n", "", "else", ":", "\n", "        ", "x_tz_matmul", "=", "torch", ".", "matmul", "(", "x_t_r", ",", "z", ")", "\n", "", "x_tz_matmul_r", "=", "x_tz_matmul", ".", "reshape", "(", "length", ",", "batch_size", ",", "heads", ",", "-", "1", ")", "\n", "x_tz_matmul_r_t", "=", "x_tz_matmul_r", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ")", "\n", "return", "x_tz_matmul_r_t", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.fn_args": [[152, 155], ["inspect.getfullargspec"], "function", ["None"], ["", "def", "fn_args", "(", "fun", ")", ":", "\n", "    ", "\"\"\"Returns the list of function arguments name.\"\"\"", "\n", "return", "inspect", ".", "getfullargspec", "(", "fun", ")", ".", "args", "\n", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.MultipleOptimizer.__init__": [[251, 254], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "op", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "self", ".", "optimizers", "=", "op", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.MultipleOptimizer.param_groups": [[255, 261], ["param_groups.extend"], "methods", ["None"], ["", "@", "property", "\n", "def", "param_groups", "(", "self", ")", ":", "\n", "        ", "param_groups", "=", "[", "]", "\n", "for", "optimizer", "in", "self", ".", "optimizers", ":", "\n", "            ", "param_groups", ".", "extend", "(", "optimizer", ".", "param_groups", ")", "\n", "", "return", "param_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.MultipleOptimizer.zero_grad": [[262, 266], ["op.zero_grad"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.zero_grad"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "for", "op", "in", "self", ".", "optimizers", ":", "\n", "            ", "op", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.MultipleOptimizer.step": [[267, 271], ["op.step"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor.step"], ["", "", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "for", "op", "in", "self", ".", "optimizers", ":", "\n", "            ", "op", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.MultipleOptimizer.state": [[272, 276], ["op.state.items"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "state", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "return", "{", "k", ":", "v", "for", "op", "in", "self", ".", "optimizers", "for", "k", ",", "v", "in", "op", ".", "state", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.MultipleOptimizer.state_dict": [[277, 280], ["op.state_dict"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "return", "[", "op", ".", "state_dict", "(", ")", "for", "op", "in", "self", ".", "optimizers", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.MultipleOptimizer.load_state_dict": [[281, 286], ["range", "len", "len", "len", "optimizers.MultipleOptimizer.optimizers[].load_state_dict"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dicts", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "assert", "len", "(", "state_dicts", ")", "==", "len", "(", "self", ".", "optimizers", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "state_dicts", ")", ")", ":", "\n", "            ", "self", ".", "optimizers", "[", "i", "]", ".", "load_state_dict", "(", "state_dicts", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.__init__": [[297, 319], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "optimizer", ",", "\n", "learning_rate", ",", "\n", "learning_rate_decay_fn", "=", "None", ",", "\n", "max_grad_norm", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initializes the controller.\n\n       Args:\n         optimizer: A ``torch.optim.Optimizer`` instance.\n         learning_rate: The initial learning rate.\n         learning_rate_decay_fn: An optional callable taking the current step\n           as argument and return a learning rate scaling factor.\n         max_grad_norm: Clip gradients to this global norm.\n        \"\"\"", "\n", "self", ".", "_optimizer", "=", "optimizer", "\n", "self", ".", "_learning_rate", "=", "learning_rate", "\n", "self", ".", "_learning_rate_decay_fn", "=", "learning_rate_decay_fn", "\n", "self", ".", "_max_grad_norm", "=", "max_grad_norm", "or", "0", "\n", "self", ".", "_training_step", "=", "1", "\n", "self", ".", "_decay_step", "=", "1", "\n", "self", ".", "_with_fp16_wrapper", "=", "(", "\n", "optimizer", ".", "__class__", ".", "__name__", "==", "\"FP16_Optimizer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.from_opt": [[320, 379], ["cls", "isinstance", "optimizers.build_torch_optimizer", "cls._optimizer.add_param_group", "cls.load_state_dict", "cls._optimizer.add_param_group", "torch.optimizer.state_dict", "torch.optimizer.state_dict", "optimizers.make_learning_rate_decay_fn", "model.multi_task_model.parameters", "model.multi_task_model.parameters"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.build_torch_optimizer", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.load_state_dict", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.state_dict", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.state_dict", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.make_learning_rate_decay_fn"], ["", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "model", ",", "opt", ",", "checkpoint", "=", "None", ")", ":", "\n", "        ", "\"\"\"Builds the optimizer from options.\n\n        Args:\n          cls: The ``Optimizer`` class to instantiate.\n          model: The model to optimize.\n          opt: The dict of user options.\n          checkpoint: An optional checkpoint to load states from.\n\n        Returns:\n          An ``Optimizer`` instance.\n        \"\"\"", "\n", "optim_opt", "=", "opt", "\n", "optim_state_dict", "=", "None", "\n", "\n", "if", "opt", ".", "train_from", "and", "checkpoint", "is", "not", "None", ":", "\n", "            ", "optim", "=", "checkpoint", "[", "'optim'", "]", "\n", "ckpt_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "ckpt_state_dict", "=", "{", "}", "\n", "if", "isinstance", "(", "optim", ",", "Optimizer", ")", ":", "# Backward compatibility.", "\n", "                ", "ckpt_state_dict", "[", "'training_step'", "]", "=", "optim", ".", "_step", "+", "1", "\n", "ckpt_state_dict", "[", "'decay_step'", "]", "=", "optim", ".", "_step", "+", "1", "\n", "ckpt_state_dict", "[", "'optimizer'", "]", "=", "optim", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "", "else", ":", "\n", "                ", "ckpt_state_dict", "=", "optim", "\n", "\n", "", "if", "opt", ".", "reset_optim", "==", "'none'", ":", "\n", "# Load everything from the checkpoint.", "\n", "                ", "optim_opt", "=", "ckpt_opt", "\n", "optim_state_dict", "=", "ckpt_state_dict", "\n", "", "elif", "opt", ".", "reset_optim", "==", "'all'", ":", "\n", "# Build everything from scratch.", "\n", "                ", "pass", "\n", "", "elif", "opt", ".", "reset_optim", "==", "'states'", ":", "\n", "# Reset optimizer, keep options.", "\n", "                ", "optim_opt", "=", "ckpt_opt", "\n", "optim_state_dict", "=", "ckpt_state_dict", "\n", "del", "optim_state_dict", "[", "'optimizer'", "]", "\n", "", "elif", "opt", ".", "reset_optim", "==", "'keep_states'", ":", "\n", "# Reset options, keep optimizer.", "\n", "                ", "optim_state_dict", "=", "ckpt_state_dict", "\n", "\n", "", "", "optimizer", "=", "cls", "(", "\n", "build_torch_optimizer", "(", "model", ",", "optim_opt", ")", ",", "\n", "optim_opt", ".", "learning_rate", ",", "\n", "learning_rate_decay_fn", "=", "make_learning_rate_decay_fn", "(", "optim_opt", ")", ",", "\n", "max_grad_norm", "=", "optim_opt", ".", "max_grad_norm", ")", "\n", "\n", "if", "opt", ".", "multi_task", "and", "opt", ".", "multi_task_finish", ":", "\n", "            ", "multi_task_params", "=", "[", "p", "for", "p", "in", "model", ".", "multi_task_model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "optimizer", ".", "_optimizer", ".", "add_param_group", "(", "{", "'params'", ":", "multi_task_params", ",", "'lr'", ":", "opt", ".", "multi_task_lr", "}", ")", "\n", "", "if", "optim_state_dict", "and", "opt", ".", "clf_task", "is", "False", ":", "\n", "# if the task is classification task then we do not use checkpoint of the optimizer", "\n", "            ", "optimizer", ".", "load_state_dict", "(", "optim_state_dict", ")", "\n", "", "if", "opt", ".", "multi_task", "and", "opt", ".", "multi_task_finish", "is", "False", ":", "\n", "            ", "multi_task_params", "=", "[", "p", "for", "p", "in", "model", ".", "multi_task_model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "optimizer", ".", "_optimizer", ".", "add_param_group", "(", "{", "'params'", ":", "multi_task_params", ",", "'lr'", ":", "opt", ".", "multi_task_lr", "}", ")", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.training_step": [[380, 384], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "training_step", "(", "self", ")", ":", "\n", "        ", "\"\"\"The current training step.\"\"\"", "\n", "return", "self", ".", "_training_step", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.learning_rate": [[385, 391], ["optimizers.Optimizer._learning_rate_decay_fn"], "methods", ["None"], ["", "def", "learning_rate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the current learning rate.\"\"\"", "\n", "if", "self", ".", "_learning_rate_decay_fn", "is", "None", ":", "\n", "            ", "return", "self", ".", "_learning_rate", "\n", "", "scale", "=", "self", ".", "_learning_rate_decay_fn", "(", "self", ".", "_decay_step", ")", "\n", "return", "scale", "*", "self", ".", "_learning_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.state_dict": [[392, 397], ["optimizers.Optimizer._optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "'training_step'", ":", "self", ".", "_training_step", ",", "\n", "'decay_step'", ":", "self", ".", "_decay_step", ",", "\n", "'optimizer'", ":", "self", ".", "_optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.load_state_dict": [[399, 408], ["print", "print", "optimizers.Optimizer._optimizer.load_state_dict", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "_training_step", "=", "state_dict", "[", "'training_step'", "]", "\n", "# State can be partially restored.", "\n", "if", "'decay_step'", "in", "state_dict", ":", "\n", "            ", "self", ".", "_decay_step", "=", "state_dict", "[", "'decay_step'", "]", "\n", "", "if", "'optimizer'", "in", "state_dict", ":", "\n", "            ", "print", "(", "len", "(", "state_dict", "[", "'optimizer'", "]", "[", "'param_groups'", "]", ")", ")", "\n", "print", "(", "len", "(", "self", ".", "_optimizer", ".", "param_groups", ")", ")", "\n", "self", ".", "_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "'optimizer'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.zero_grad": [[409, 412], ["optimizers.Optimizer._optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.zero_grad"], ["", "", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\"Zero the gradients of optimized parameters.\"\"\"", "\n", "self", ".", "_optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.backward": [[413, 423], ["optimizers.Optimizer._optimizer.backward", "loss.backward", "onmt.utils.misc.fn_args"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.fn_args"], ["", "def", "backward", "(", "self", ",", "loss", ")", ":", "\n", "        ", "\"\"\"Wrapper for backward pass. Some optimizer requires ownership of the\n        backward pass.\"\"\"", "\n", "if", "self", ".", "_with_fp16_wrapper", ":", "\n", "            ", "kwargs", "=", "{", "}", "\n", "if", "\"update_master_grads\"", "in", "fn_args", "(", "self", ".", "_optimizer", ".", "backward", ")", ":", "\n", "                ", "kwargs", "[", "\"update_master_grads\"", "]", "=", "True", "\n", "", "self", ".", "_optimizer", ".", "backward", "(", "loss", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "loss", ".", "backward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.step": [[424, 447], ["optimizers.Optimizer.learning_rate", "optimizers.Optimizer._optimizer.step", "hasattr", "optimizers.Optimizer._optimizer.update_master_grads", "hasattr", "optimizers.Optimizer._optimizer.clip_master_grads", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.learning_rate", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor.step"], ["", "", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\"Update the model parameters based on current gradients.\n\n        Optionally, will employ gradient modification or update learning\n        rate.\n        \"\"\"", "\n", "learning_rate", "=", "self", ".", "learning_rate", "(", ")", "\n", "if", "self", ".", "_with_fp16_wrapper", ":", "\n", "            ", "if", "hasattr", "(", "self", ".", "_optimizer", ",", "\"update_master_grads\"", ")", ":", "\n", "                ", "self", ".", "_optimizer", ".", "update_master_grads", "(", ")", "\n", "", "if", "hasattr", "(", "self", ".", "_optimizer", ",", "\"clip_master_grads\"", ")", "and", "self", ".", "_max_grad_norm", ">", "0", ":", "\n", "                ", "self", ".", "_optimizer", ".", "clip_master_grads", "(", "self", ".", "_max_grad_norm", ")", "\n", "", "", "for", "group", "in", "self", ".", "_optimizer", ".", "param_groups", ":", "\n", "            ", "if", "'factor'", "in", "group", ":", "\n", "                ", "group", "[", "'lr'", "]", "=", "group", "[", "'factor'", "]", "*", "learning_rate", "\n", "", "else", ":", "\n", "                ", "group", "[", "'lr'", "]", "=", "learning_rate", "\n", "", "if", "not", "self", ".", "_with_fp16_wrapper", "and", "self", ".", "_max_grad_norm", ">", "0", ":", "\n", "                ", "clip_grad_norm_", "(", "group", "[", "'params'", "]", ",", "self", ".", "_max_grad_norm", ")", "\n", "", "", "self", ".", "_optimizer", ".", "step", "(", ")", "\n", "self", ".", "_decay_step", "+=", "1", "\n", "self", ".", "_training_step", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor.__init__": [[454, 471], ["dict", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "None", ",", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "eps1", "=", "1e-30", ",", "\n", "eps2", "=", "1e-3", ",", "cliping_threshold", "=", "1", ",", "non_constant_decay", "=", "True", ",", "\n", "enable_factorization", "=", "True", ",", "ams_grad", "=", "True", ",", "weight_decay", "=", "0", ")", ":", "\n", "\n", "        ", "enable_momentum", "=", "beta1", "!=", "0", "\n", "\n", "if", "non_constant_decay", ":", "\n", "            ", "ams_grad", "=", "False", "\n", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "beta1", "=", "beta1", ",", "beta2", "=", "beta2", ",", "eps1", "=", "eps1", ",", "\n", "eps2", "=", "eps2", ",", "cliping_threshold", "=", "cliping_threshold", ",", "\n", "weight_decay", "=", "weight_decay", ",", "ams_grad", "=", "ams_grad", ",", "\n", "enable_factorization", "=", "enable_factorization", ",", "\n", "enable_momentum", "=", "enable_momentum", ",", "\n", "non_constant_decay", "=", "non_constant_decay", ")", "\n", "\n", "super", "(", "AdaFactor", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor.__setstate__": [[472, 474], ["super().__setstate__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", "AdaFactor", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor._experimental_reshape": [[475, 486], ["len", "copy.copy.copy", "len", "len", "functools.reduce", "functools.reduce"], "methods", ["None"], ["", "def", "_experimental_reshape", "(", "self", ",", "shape", ")", ":", "\n", "        ", "temp_shape", "=", "shape", "[", "2", ":", "]", "\n", "if", "len", "(", "temp_shape", ")", "==", "1", ":", "\n", "            ", "new_shape", "=", "(", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", "*", "shape", "[", "2", "]", ")", "\n", "", "else", ":", "\n", "            ", "tmp_div", "=", "len", "(", "temp_shape", ")", "//", "2", "+", "len", "(", "temp_shape", ")", "%", "2", "\n", "new_shape", "=", "(", "shape", "[", "0", "]", "*", "functools", ".", "reduce", "(", "operator", ".", "mul", ",", "\n", "temp_shape", "[", "tmp_div", ":", "]", ",", "1", ")", ",", "\n", "shape", "[", "1", "]", "*", "functools", ".", "reduce", "(", "operator", ".", "mul", ",", "\n", "temp_shape", "[", ":", "tmp_div", "]", ",", "1", ")", ")", "\n", "", "return", "new_shape", ",", "copy", "(", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor._check_shape": [[487, 500], ["len", "len", "len"], "methods", ["None"], ["", "def", "_check_shape", "(", "self", ",", "shape", ")", ":", "\n", "        ", "'''\n        output1 - True - algorithm for matrix, False - vector;\n        output2 - need reshape\n        '''", "\n", "if", "len", "(", "shape", ")", ">", "2", ":", "\n", "            ", "return", "True", ",", "True", "\n", "", "elif", "len", "(", "shape", ")", "==", "2", ":", "\n", "            ", "return", "True", ",", "False", "\n", "", "elif", "len", "(", "shape", ")", "==", "2", "and", "(", "shape", "[", "0", "]", "==", "1", "or", "shape", "[", "1", "]", "==", "1", ")", ":", "\n", "            ", "return", "False", ",", "False", "\n", "", "else", ":", "\n", "            ", "return", "False", ",", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor._rms": [[501, 503], ["math.sqrt", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "x.pow"], "methods", ["None"], ["", "", "def", "_rms", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "sqrt", "(", "torch", ".", "mean", "(", "x", ".", "pow", "(", "2", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor.step": [[504, 620], ["closure", "optimizers.AdaFactor._check_shape", "p.data.size", "max", "torch.div.div_", "torch.div.div_", "p.data.add_", "RuntimeError", "grad.view.view.size", "optimizers.AdaFactor._experimental_reshape", "grad.view.view.view", "len", "optimizers.AdaFactor._rms", "exp_avg.mul_().add_", "exp_avg_sq_r.mul_().add_", "exp_avg_sq_c.mul_().add_", "torch.mul().div_", "torch.mul().div_", "torch.mul().div_", "torch.mul().div_", "exp_avg_sq.mul_().addcmul_().add_", "torch.div", "torch.div", "torch.div", "torch.div", "torch.max", "torch.max", "torch.max", "torch.max", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "max", "p.data.add_", "p.data.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.div().sqrt().add_", "torch.div().sqrt().add_", "torch.div().sqrt().add_", "torch.div().sqrt().add_", "torch.mul().div_.sqrt", "torch.mul().div_.sqrt", "exp_avg.mul_", "exp_avg_sq_r.mul_", "torch.mul().add_", "torch.mul().add_", "torch.mul().add_", "torch.mul().add_", "exp_avg_sq_c.mul_", "torch.mul().add_", "torch.mul().add_", "torch.mul().add_", "torch.mul().add_", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "exp_avg_sq.mul_().addcmul_", "optimizers.AdaFactor._rms", "torch.div.view", "torch.div.view", "torch.div().sqrt", "torch.div().sqrt", "torch.div().sqrt", "torch.div().sqrt", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "exp_avg_sq.mul_", "torch.div", "torch.div", "torch.div", "torch.div"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor._check_shape", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor._experimental_reshape", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor._rms", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor._rms"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse \\\n                                       gradients, use SparseAdam instead'", ")", "\n", "\n", "", "is_matrix", ",", "is_need_reshape", "=", "self", ".", "_check_shape", "(", "grad", ".", "size", "(", ")", ")", "\n", "new_shape", "=", "p", ".", "data", ".", "size", "(", ")", "\n", "if", "is_need_reshape", "and", "group", "[", "'enable_factorization'", "]", ":", "\n", "                    ", "new_shape", ",", "old_shape", "=", "self", ".", "_experimental_reshape", "(", "p", ".", "data", ".", "size", "(", ")", ")", "\n", "grad", "=", "grad", ".", "view", "(", "new_shape", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "if", "group", "[", "'enable_momentum'", "]", ":", "\n", "                        ", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros", "(", "new_shape", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "\n", "device", "=", "p", ".", "grad", ".", "device", ")", "\n", "\n", "", "if", "is_matrix", "and", "group", "[", "'enable_factorization'", "]", ":", "\n", "                        ", "state", "[", "'exp_avg_sq_R'", "]", "=", "torch", ".", "zeros", "(", "(", "1", ",", "new_shape", "[", "1", "]", ")", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "\n", "device", "=", "p", ".", "grad", ".", "device", ")", "\n", "state", "[", "'exp_avg_sq_C'", "]", "=", "torch", ".", "zeros", "(", "(", "new_shape", "[", "0", "]", ",", "1", ")", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "\n", "device", "=", "p", ".", "grad", ".", "device", ")", "\n", "", "else", ":", "\n", "                        ", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros", "(", "new_shape", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "\n", "device", "=", "p", ".", "grad", ".", "device", ")", "\n", "", "if", "group", "[", "'ams_grad'", "]", ":", "\n", "                        ", "state", "[", "'exp_avg_sq_hat'", "]", "=", "torch", ".", "zeros", "(", "new_shape", ",", "dtype", "=", "torch", ".", "float32", ",", "\n", "device", "=", "p", ".", "grad", ".", "device", ")", "\n", "\n", "", "", "if", "group", "[", "'enable_momentum'", "]", ":", "\n", "                    ", "exp_avg", "=", "state", "[", "'exp_avg'", "]", "\n", "\n", "", "if", "is_matrix", "and", "group", "[", "'enable_factorization'", "]", ":", "\n", "                    ", "exp_avg_sq_r", "=", "state", "[", "'exp_avg_sq_R'", "]", "\n", "exp_avg_sq_c", "=", "state", "[", "'exp_avg_sq_C'", "]", "\n", "", "else", ":", "\n", "                    ", "exp_avg_sq", "=", "state", "[", "'exp_avg_sq'", "]", "\n", "\n", "", "if", "group", "[", "'ams_grad'", "]", ":", "\n", "                    ", "exp_avg_sq_hat", "=", "state", "[", "'exp_avg_sq_hat'", "]", "\n", "\n", "", "state", "[", "'step'", "]", "+=", "1", "\n", "lr_t", "=", "group", "[", "'lr'", "]", "\n", "lr_t", "*=", "max", "(", "group", "[", "'eps2'", "]", ",", "self", ".", "_rms", "(", "p", ".", "data", ")", ")", "\n", "\n", "if", "group", "[", "'enable_momentum'", "]", ":", "\n", "                    ", "if", "group", "[", "'non_constant_decay'", "]", ":", "\n", "                        ", "beta1_t", "=", "group", "[", "'beta1'", "]", "*", "(", "1", "-", "group", "[", "'beta1'", "]", "**", "(", "state", "[", "'step'", "]", "-", "1", ")", ")", "/", "(", "1", "-", "group", "[", "'beta1'", "]", "**", "state", "[", "'step'", "]", ")", "\n", "", "else", ":", "\n", "                        ", "beta1_t", "=", "group", "[", "'beta1'", "]", "\n", "", "exp_avg", ".", "mul_", "(", "beta1_t", ")", ".", "add_", "(", "1", "-", "beta1_t", ",", "grad", ")", "\n", "\n", "", "if", "group", "[", "'non_constant_decay'", "]", ":", "\n", "                    ", "beta2_t", "=", "group", "[", "'beta2'", "]", "*", "(", "1", "-", "group", "[", "'beta2'", "]", "**", "(", "state", "[", "'step'", "]", "-", "1", ")", ")", "/", "(", "1", "-", "group", "[", "'beta2'", "]", "**", "state", "[", "'step'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "beta2_t", "=", "group", "[", "'beta2'", "]", "\n", "\n", "", "if", "is_matrix", "and", "group", "[", "'enable_factorization'", "]", ":", "\n", "                    ", "exp_avg_sq_r", ".", "mul_", "(", "beta2_t", ")", ".", "add_", "(", "1", "-", "beta2_t", ",", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "grad", ",", "grad", ")", ".", "\n", "add_", "(", "group", "[", "'eps1'", "]", ")", ",", "\n", "dim", "=", "0", ",", "keepdim", "=", "True", ")", ")", "\n", "exp_avg_sq_c", ".", "mul_", "(", "beta2_t", ")", ".", "add_", "(", "1", "-", "beta2_t", ",", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "grad", ",", "grad", ")", ".", "\n", "add_", "(", "group", "[", "'eps1'", "]", ")", ",", "\n", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "v", "=", "torch", ".", "mul", "(", "exp_avg_sq_c", ",", "\n", "exp_avg_sq_r", ")", ".", "div_", "(", "torch", ".", "sum", "(", "exp_avg_sq_r", ")", ")", "\n", "", "else", ":", "\n", "                    ", "exp_avg_sq", ".", "mul_", "(", "beta2_t", ")", ".", "addcmul_", "(", "1", "-", "beta2_t", ",", "grad", ",", "grad", ")", ".", "add_", "(", "(", "1", "-", "beta2_t", ")", "*", "group", "[", "'eps1'", "]", ")", "\n", "v", "=", "exp_avg_sq", "\n", "\n", "", "g", "=", "grad", "\n", "if", "group", "[", "'enable_momentum'", "]", ":", "\n", "                    ", "g", "=", "torch", ".", "div", "(", "exp_avg", ",", "1", "-", "beta1_t", "**", "state", "[", "'step'", "]", ")", "\n", "\n", "", "if", "group", "[", "'ams_grad'", "]", ":", "\n", "                    ", "torch", ".", "max", "(", "exp_avg_sq_hat", ",", "v", ",", "out", "=", "exp_avg_sq_hat", ")", "\n", "v", "=", "exp_avg_sq_hat", "\n", "u", "=", "torch", ".", "div", "(", "g", ",", "(", "torch", ".", "div", "(", "v", ",", "1", "-", "beta2_t", "**", "\n", "state", "[", "'step'", "]", ")", ")", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps1'", "]", ")", ")", "\n", "", "else", ":", "\n", "                    ", "u", "=", "torch", ".", "div", "(", "g", ",", "v", ".", "sqrt", "(", ")", ")", "\n", "\n", "", "u", ".", "div_", "(", "max", "(", "1", ",", "self", ".", "_rms", "(", "u", ")", "/", "group", "[", "'cliping_threshold'", "]", ")", ")", "\n", "p", ".", "data", ".", "add_", "(", "-", "lr_t", "*", "(", "u", ".", "view", "(", "old_shape", ")", "if", "is_need_reshape", "and", "\n", "group", "[", "'enable_factorization'", "]", "else", "u", ")", ")", "\n", "\n", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "                    ", "p", ".", "data", ".", "add_", "(", "-", "group", "[", "'weight_decay'", "]", "*", "lr_t", ",", "p", ".", "data", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.build_torch_optimizer": [[13, 185], ["torch.SGD", "opt.optim.startswith", "namespace.FP16_Optimizer", "model.parameters", "torch.Adagrad", "torch.Adadelta", "optimizers.AdaFactor", "param_groups.append", "range", "param_groups.append", "print", "torch.Adam", "model.named_parameters", "optimizers.MultipleOptimizer", "ValueError", "hasattr", "model.generator.parameters", "param_groups.append", "apex.optimizers.FusedAdam", "decoder.layer_norm.parameters", "decoder.embeddings.parameters", "emb_params.append", "emb_params.append", "p.nelement", "sparse.append", "dense.append", "torch.Adam", "torch.SparseAdam", "decoder.named_parameters", "decoder.transformer_layers[].named_parameters", "decoder.transformer_layers[].parameters", "model.encoder.named_parameters", "model.encoder.parameters", "model.generator.linear_copy.parameters"], "function", ["None"], ["def", "build_torch_optimizer", "(", "model", ",", "opt", ")", ":", "\n", "    ", "\"\"\"Builds the PyTorch optimizer.\n\n    We use the default parameters for Adam that are suggested by\n    the original paper https://arxiv.org/pdf/1412.6980.pdf\n    These values are also used by other established implementations,\n    e.g. https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer\n    https://keras.io/optimizers/\n    Recently there are slightly different values used in the paper\n    \"Attention is all you need\"\n    https://arxiv.org/pdf/1706.03762.pdf, particularly the value beta2=0.98\n    was used there however, beta2=0.999 is still arguably the more\n    established value, so we use that here as well\n\n    Args:\n      model: The model to optimize.\n      opt. The dictionary of options.\n\n    Returns:\n      A ``torch.optim.Optimizer`` instance.\n    \"\"\"", "\n", "if", "opt", ".", "disc_ft", ">", "0", "and", "not", "(", "opt", ".", "optim", "==", "'adam'", "or", "opt", ".", "optim", "==", "'fusedadam'", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "if", "opt", ".", "disc_ft", ">", "0", "and", "opt", ".", "share_decoder_embeddings", "and", "(", "opt", ".", "simple_fusion", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "if", "opt", ".", "disc_ft", ">", "0", "and", "opt", ".", "share_decoder_embeddings", "and", "opt", ".", "copy_attn", "and", "opt", ".", "full_gen_bias", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "if", "opt", ".", "disc_ft", ">", "0", "and", "'transformer'", "not", "in", "opt", ".", "decoder_type", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "params", "=", "[", "p", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "betas", "=", "[", "opt", ".", "adam_beta1", ",", "opt", ".", "adam_beta2", "]", "\n", "if", "opt", ".", "optim", "==", "'sgd'", ":", "\n", "        ", "optimizer", "=", "optim", ".", "SGD", "(", "params", ",", "lr", "=", "opt", ".", "learning_rate", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'adagrad'", ":", "\n", "        ", "optimizer", "=", "optim", ".", "Adagrad", "(", "\n", "params", ",", "\n", "lr", "=", "opt", ".", "learning_rate", ",", "\n", "initial_accumulator_value", "=", "opt", ".", "adagrad_accumulator_init", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'adadelta'", ":", "\n", "        ", "optimizer", "=", "optim", ".", "Adadelta", "(", "params", ",", "lr", "=", "opt", ".", "learning_rate", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'adafactor'", ":", "\n", "        ", "optimizer", "=", "AdaFactor", "(", "\n", "params", ",", "\n", "non_constant_decay", "=", "True", ",", "\n", "enable_factorization", "=", "True", ",", "\n", "weight_decay", "=", "0", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'adam'", "or", "opt", ".", "optim", "==", "'fusedadam'", ":", "\n", "        ", "if", "opt", ".", "disc_ft", ">", "0", ":", "\n", "            ", "if", "opt", ".", "encdec_share_params", ":", "\n", "                ", "enc_params", "=", "[", "]", "\n", "", "else", ":", "\n", "                ", "if", "hasattr", "(", "model", ",", "'encoder'", ")", ":", "\n", "                    ", "if", "opt", ".", "share_embeddings", ":", "\n", "                        ", "enc_params", "=", "[", "p", "for", "name", ",", "p", "in", "model", ".", "encoder", ".", "named_parameters", "(", ")", "if", "'embeddings'", "not", "in", "name", "]", "\n", "", "else", ":", "\n", "                        ", "enc_params", "=", "[", "p", "for", "p", "in", "model", ".", "encoder", ".", "parameters", "(", ")", "]", "\n", "", "", "else", ":", "\n", "                    ", "enc_params", "=", "[", "]", "\n", "\n", "", "", "decoder", "=", "model", ".", "decoder", "\n", "if", "enc_params", ":", "\n", "                ", "param_groups", "=", "[", "{", "'params'", ":", "enc_params", ",", "'factor'", ":", "1.0", "}", "]", "\n", "", "else", ":", "\n", "                ", "param_groups", "=", "[", "]", "\n", "\n", "# Making a choice here to use smaller learning rate for generator weight if ", "\n", "# using shared decoder embeddings", "\n", "", "if", "opt", ".", "share_decoder_embeddings", ":", "\n", "                ", "if", "opt", ".", "full_gen_bias", ":", "\n", "                    ", "gen_params", "=", "[", "model", ".", "generator", "[", "0", "]", ".", "bias", "]", "\n", "", "else", ":", "\n", "                    ", "if", "opt", ".", "copy_attn", ":", "\n", "                        ", "gen_params", "=", "[", "p", "for", "p", "in", "model", ".", "generator", ".", "linear_copy", ".", "parameters", "(", ")", "]", "\n", "", "else", ":", "\n", "                        ", "gen_params", "=", "[", "]", "\n", "", "", "", "else", ":", "\n", "                ", "gen_params", "=", "model", ".", "generator", ".", "parameters", "(", ")", "\n", "\n", "", "params_end", "=", "[", "*", "gen_params", ",", "*", "decoder", ".", "layer_norm", ".", "parameters", "(", ")", "]", "\n", "\n", "if", "opt", ".", "full_context_lr", ":", "\n", "                ", "params_end", "+=", "[", "p", "for", "name", ",", "p", "in", "decoder", ".", "named_parameters", "(", ")", "if", "'context'", "in", "name", "or", "'ctx'", "in", "name", "]", "\n", "\n", "", "factor", "=", "1.0", "/", "opt", ".", "dec_lr_factor", "\n", "param_groups", ".", "append", "(", "{", "'params'", ":", "params_end", ",", "'factor'", ":", "factor", "}", ")", "\n", "for", "layer_num", "in", "range", "(", "opt", ".", "dec_layers", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "                ", "factor", "/=", "opt", ".", "disc_ft", "\n", "if", "opt", ".", "full_context_lr", ":", "\n", "                     ", "layer_params", "=", "[", "p", "for", "name", ",", "p", "in", "decoder", ".", "transformer_layers", "[", "layer_num", "]", ".", "named_parameters", "(", ")", "if", "'context'", "not", "in", "name", "and", "'ctx'", "not", "in", "name", "]", "\n", "", "else", ":", "\n", "                     ", "layer_params", "=", "[", "p", "for", "p", "in", "decoder", ".", "transformer_layers", "[", "layer_num", "]", ".", "parameters", "(", ")", "]", "\n", "\n", "", "param_groups", ".", "append", "(", "{", "'params'", ":", "layer_params", ",", "'factor'", ":", "factor", "}", ")", "\n", "\n", "", "factor", "/=", "opt", ".", "disc_ft", "\n", "emb_params", "=", "[", "p", "for", "p", "in", "decoder", ".", "embeddings", ".", "parameters", "(", ")", "]", "\n", "if", "opt", ".", "share_decoder_embeddings", "and", "not", "opt", ".", "full_gen_bias", ":", "\n", "                ", "if", "opt", ".", "copy_attn", ":", "\n", "                    ", "emb_params", ".", "append", "(", "model", ".", "generator", ".", "linear", ".", "bias", ")", "\n", "", "else", ":", "\n", "                    ", "emb_params", ".", "append", "(", "model", ".", "generator", "[", "0", "]", ".", "bias", ")", "\n", "", "", "param_groups", ".", "append", "(", "{", "'params'", ":", "emb_params", ",", "'factor'", ":", "factor", "}", ")", "\n", "\n", "num_params", "=", "0", "\n", "for", "group", "in", "param_groups", ":", "\n", "                ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                    ", "if", "not", "p", ".", "requires_grad", ":", "\n", "                        ", "continue", "\n", "", "num_params", "+=", "p", ".", "nelement", "(", ")", "\n", "\n", "", "", "print", "(", "'num params for optimizer: %d'", "%", "num_params", ")", "\n", "", "else", ":", "\n", "            ", "param_groups", "=", "params", "\n", "\n", "# add the multi-task parameters", "\n", "\n", "", "if", "opt", ".", "optim", "==", "'adam'", ":", "\n", "            ", "optimizer", "=", "optim", ".", "Adam", "(", "\n", "param_groups", ",", "\n", "lr", "=", "opt", ".", "learning_rate", ",", "\n", "betas", "=", "betas", ",", "\n", "eps", "=", "1e-9", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'fusedadam'", ":", "\n", "            ", "import", "apex", "\n", "optimizer", "=", "apex", ".", "optimizers", ".", "FusedAdam", "(", "\n", "param_groups", ",", "\n", "lr", "=", "opt", ".", "learning_rate", ",", "\n", "betas", "=", "betas", ")", "\n", "\n", "", "", "elif", "opt", ".", "optim", "==", "'sparseadam'", ":", "\n", "        ", "dense", "=", "[", "]", "\n", "sparse", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "not", "param", ".", "requires_grad", ":", "\n", "                ", "continue", "\n", "# TODO: Find a better way to check for sparse gradients.", "\n", "", "if", "'embed'", "in", "name", ":", "\n", "                ", "sparse", ".", "append", "(", "param", ")", "\n", "", "else", ":", "\n", "                ", "dense", ".", "append", "(", "param", ")", "\n", "", "", "optimizer", "=", "MultipleOptimizer", "(", "\n", "[", "optim", ".", "Adam", "(", "\n", "dense", ",", "\n", "lr", "=", "opt", ".", "learning_rate", ",", "\n", "betas", "=", "betas", ",", "\n", "eps", "=", "1e-8", ")", ",", "\n", "optim", ".", "SparseAdam", "(", "\n", "sparse", ",", "\n", "lr", "=", "opt", ".", "learning_rate", ",", "\n", "betas", "=", "betas", ",", "\n", "eps", "=", "1e-8", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid optimizer type: '", "+", "opt", ".", "optim", ")", "\n", "\n", "", "if", "opt", ".", "model_dtype", "==", "'fp16'", ":", "\n", "        ", "import", "apex", "\n", "static_loss_scale", "=", "opt", ".", "loss_scale", "\n", "dynamic_loss_scale", "=", "opt", ".", "loss_scale", "==", "0", "\n", "# TODO: clean this up when APEX unify its optimizer API.", "\n", "if", "opt", ".", "optim", ".", "startswith", "(", "'fused'", ")", ":", "\n", "            ", "namespace", "=", "apex", ".", "optimizers", "# Faster wrapper.", "\n", "", "else", ":", "\n", "            ", "namespace", "=", "apex", ".", "fp16_utils", "\n", "", "optimizer", "=", "namespace", ".", "FP16_Optimizer", "(", "\n", "optimizer", ",", "\n", "static_loss_scale", "=", "static_loss_scale", ",", "\n", "dynamic_loss_scale", "=", "dynamic_loss_scale", ")", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.make_learning_rate_decay_fn": [[187, 214], ["functools.partial", "functools.partial", "functools.partial", "ValueError", "functools.partial", "functools.partial"], "function", ["None"], ["", "def", "make_learning_rate_decay_fn", "(", "opt", ")", ":", "\n", "    ", "\"\"\"Returns the learning decay function from options.\"\"\"", "\n", "if", "opt", ".", "decay_method", "==", "'noam'", ":", "\n", "        ", "return", "functools", ".", "partial", "(", "\n", "noam_decay", ",", "\n", "warmup_steps", "=", "opt", ".", "warmup_steps", ",", "\n", "model_size", "=", "opt", ".", "rnn_size", ")", "\n", "", "elif", "opt", ".", "decay_method", "==", "'rsqrt'", ":", "\n", "        ", "return", "functools", ".", "partial", "(", "\n", "rsqrt_decay", ",", "warmup_steps", "=", "opt", ".", "warmup_steps", ")", "\n", "", "elif", "opt", ".", "decay_method", "==", "'stlr'", ":", "\n", "        ", "if", "opt", ".", "warmup_steps", ">", "opt", ".", "train_steps", ":", "\n", "            ", "raise", "ValueError", "(", "'warmup_steps should be smaller than train_steps'", ")", "\n", "", "return", "functools", ".", "partial", "(", "\n", "stlr_decay", ",", "warmup_steps", "=", "opt", ".", "warmup_steps", ",", "\n", "train_steps", "=", "opt", ".", "train_steps", ",", "ratio", "=", "opt", ".", "stlr_ratio", ")", "\n", "", "elif", "opt", ".", "decay_method", "==", "'invsq'", ":", "\n", "        ", "return", "functools", ".", "partial", "(", "\n", "invsq_decay", ",", "\n", "warmup_steps", "=", "opt", ".", "warmup_steps", ",", "\n", "warmup_init_factor", "=", "opt", ".", "warmup_init_factor", ")", "\n", "", "elif", "opt", ".", "start_decay_steps", "is", "not", "None", ":", "\n", "        ", "return", "functools", ".", "partial", "(", "\n", "exponential_decay", ",", "\n", "rate", "=", "opt", ".", "learning_rate_decay", ",", "\n", "decay_steps", "=", "opt", ".", "decay_steps", ",", "\n", "start_step", "=", "opt", ".", "start_decay_steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.invsq_decay": [[215, 220], ["None"], "function", ["None"], ["", "", "def", "invsq_decay", "(", "step", ",", "warmup_steps", ",", "warmup_init_factor", ")", ":", "\n", "    ", "if", "step", "<", "warmup_steps", ":", "\n", "        ", "return", "1.0", "/", "warmup_init_factor", "+", "(", "1", "-", "1.0", "/", "warmup_init_factor", ")", "/", "warmup_steps", "*", "step", "\n", "", "else", ":", "\n", "        ", "return", "(", "warmup_steps", "/", "step", ")", "**", "0.5", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.stlr_decay": [[221, 226], ["min"], "function", ["None"], ["", "", "def", "stlr_decay", "(", "step", ",", "warmup_steps", ",", "train_steps", ",", "ratio", ")", ":", "\n", "    ", "cut", "=", "warmup_steps", "\n", "cut_frac", "=", "warmup_steps", "/", "train_steps", "\n", "p", "=", "min", "(", "step", "/", "cut", ",", "1", "-", "(", "step", "-", "cut", ")", "/", "(", "cut", "*", "(", "1", "/", "cut_frac", "-", "1", ")", ")", ")", "\n", "return", "(", "1", "+", "p", "*", "(", "ratio", "-", "1", ")", ")", "/", "ratio", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.noam_decay": [[227, 234], ["min"], "function", ["None"], ["", "def", "noam_decay", "(", "step", ",", "warmup_steps", ",", "model_size", ")", ":", "\n", "    ", "\"\"\"Learning rate schedule described in\n    https://arxiv.org/pdf/1706.03762.pdf.\n    \"\"\"", "\n", "return", "(", "\n", "model_size", "**", "(", "-", "0.5", ")", "*", "\n", "min", "(", "step", "**", "(", "-", "0.5", ")", ",", "step", "*", "warmup_steps", "**", "(", "-", "1.5", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.exponential_decay": [[236, 241], ["max"], "function", ["None"], ["", "def", "exponential_decay", "(", "step", ",", "rate", ",", "decay_steps", ",", "start_step", "=", "0", ")", ":", "\n", "    ", "\"\"\"A standard exponential decay, scaling the learning rate by :obj:`rate`\n    every :obj:`decay_steps` steps.\n    \"\"\"", "\n", "return", "rate", "**", "(", "max", "(", "step", "-", "start_step", "+", "decay_steps", ",", "0", ")", "//", "decay_steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.rsqrt_decay": [[243, 246], ["math.sqrt", "max"], "function", ["None"], ["", "def", "rsqrt_decay", "(", "step", ",", "warmup_steps", ")", ":", "\n", "    ", "\"\"\"Decay based on the reciprocal of the step square root.\"\"\"", "\n", "return", "1.0", "/", "sqrt", "(", "max", "(", "step", ",", "warmup_steps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.image_dataset.ImageDataReader.__init__": [[32, 36], ["image_dataset.ImageDataReader._check_deps"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioDataReader._check_deps"], ["def", "__init__", "(", "self", ",", "truncate", "=", "None", ",", "channel_size", "=", "3", ")", ":", "\n", "        ", "self", ".", "_check_deps", "(", ")", "\n", "self", ".", "truncate", "=", "truncate", "\n", "self", ".", "channel_size", "=", "channel_size", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.image_dataset.ImageDataReader.from_opt": [[37, 40], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ")", ":", "\n", "        ", "return", "cls", "(", "channel_size", "=", "opt", ".", "image_channel_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.image_dataset.ImageDataReader._check_deps": [[41, 46], ["any", "cls._raise_missing_dep"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.datareader_base.DataReaderBase._raise_missing_dep"], ["", "@", "classmethod", "\n", "def", "_check_deps", "(", "cls", ")", ":", "\n", "        ", "if", "any", "(", "[", "Image", "is", "None", ",", "transforms", "is", "None", ",", "cv2", "is", "None", "]", ")", ":", "\n", "            ", "cls", ".", "_raise_missing_dep", "(", "\n", "\"PIL\"", ",", "\"torchvision\"", ",", "\"cv2\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.image_dataset.ImageDataReader.read": [[47, 84], ["isinstance", "enumerate", "onmt.inputters.datareader_base.DataReaderBase._read_file", "filename.decode().strip.decode().strip.decode().strip", "os.path.join", "os.path.exists", "os.path.exists", "filename.decode().strip.decode().strip.decode", "transforms.ToTensor", "Image.fromarray", "transforms.ToTensor", "Image.open", "cv2.imread", "img.size", "img.size"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.datareader_base.DataReaderBase._read_file"], ["", "", "def", "read", "(", "self", ",", "images", ",", "side", ",", "img_dir", "=", "None", ")", ":", "\n", "        ", "\"\"\"Read data into dicts.\n\n        Args:\n            images (str or Iterable[str]): Sequence of image paths or\n                path to file containing audio paths.\n                In either case, the filenames may be relative to ``src_dir``\n                (default behavior) or absolute.\n            side (str): Prefix used in return dict. Usually\n                ``\"src\"`` or ``\"tgt\"``.\n            img_dir (str): Location of source image files. See ``images``.\n\n        Yields:\n            a dictionary containing image data, path and index for each line.\n        \"\"\"", "\n", "if", "isinstance", "(", "images", ",", "str", ")", ":", "\n", "            ", "images", "=", "DataReaderBase", ".", "_read_file", "(", "images", ")", "\n", "\n", "", "for", "i", ",", "filename", "in", "enumerate", "(", "images", ")", ":", "\n", "            ", "filename", "=", "filename", ".", "decode", "(", "\"utf-8\"", ")", ".", "strip", "(", ")", "\n", "img_path", "=", "os", ".", "path", ".", "join", "(", "img_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "img_path", ")", ":", "\n", "                ", "img_path", "=", "filename", "\n", "\n", "", "assert", "os", ".", "path", ".", "exists", "(", "img_path", ")", ",", "'img path %s not found'", "%", "filename", "\n", "\n", "if", "self", ".", "channel_size", "==", "1", ":", "\n", "                ", "img", "=", "transforms", ".", "ToTensor", "(", ")", "(", "\n", "Image", ".", "fromarray", "(", "cv2", ".", "imread", "(", "img_path", ",", "0", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "img", "=", "transforms", ".", "ToTensor", "(", ")", "(", "Image", ".", "open", "(", "img_path", ")", ")", "\n", "", "if", "self", ".", "truncate", "and", "self", ".", "truncate", "!=", "(", "0", ",", "0", ")", ":", "\n", "                ", "if", "not", "(", "img", ".", "size", "(", "1", ")", "<=", "self", ".", "truncate", "[", "0", "]", "\n", "and", "img", ".", "size", "(", "2", ")", "<=", "self", ".", "truncate", "[", "1", "]", ")", ":", "\n", "                    ", "continue", "\n", "", "", "yield", "{", "side", ":", "img", ",", "side", "+", "'_path'", ":", "filename", ",", "'indices'", ":", "i", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.image_dataset.img_sort_key": [[86, 89], ["ex.src.size", "ex.src.size"], "function", ["None"], ["", "", "", "def", "img_sort_key", "(", "ex", ")", ":", "\n", "    ", "\"\"\"Sort using the size of the image: (width, height).\"\"\"", "\n", "return", "ex", ".", "src", ".", "size", "(", "2", ")", ",", "ex", ".", "src", ".", "size", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.image_dataset.batch_img": [[91, 100], ["data[].size", "max", "max", "torch.zeros().fill_", "enumerate", "t.size", "t.size", "torch.zeros", "len", "img.size", "img.size"], "function", ["None"], ["", "def", "batch_img", "(", "data", ",", "vocab", ")", ":", "\n", "    ", "\"\"\"Pad and batch a sequence of images.\"\"\"", "\n", "c", "=", "data", "[", "0", "]", ".", "size", "(", "0", ")", "\n", "h", "=", "max", "(", "[", "t", ".", "size", "(", "1", ")", "for", "t", "in", "data", "]", ")", "\n", "w", "=", "max", "(", "[", "t", ".", "size", "(", "2", ")", "for", "t", "in", "data", "]", ")", "\n", "imgs", "=", "torch", ".", "zeros", "(", "len", "(", "data", ")", ",", "c", ",", "h", ",", "w", ")", ".", "fill_", "(", "1", ")", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "data", ")", ":", "\n", "        ", "imgs", "[", "i", ",", ":", ",", "0", ":", "img", ".", "size", "(", "1", ")", ",", "0", ":", "img", ".", "size", "(", "2", ")", "]", "=", "img", "\n", "", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.image_dataset.image_fields": [[102, 107], ["torchtext.data.Field"], "function", ["None"], ["", "def", "image_fields", "(", "**", "kwargs", ")", ":", "\n", "    ", "img", "=", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "postprocessing", "=", "batch_img", ",", "sequential", "=", "False", ")", "\n", "return", "img", "\n", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.text_dataset.TextDataReader.read": [[12, 36], ["isinstance", "enumerate", "onmt.inputters.datareader_base.DataReaderBase._read_file", "isinstance", "seq.decode.decode.decode"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.datareader_base.DataReaderBase._read_file"], ["    ", "def", "read", "(", "self", ",", "sequences", ",", "side", ",", "_dir", "=", "None", ")", ":", "\n", "        ", "\"\"\"Read text data from disk.\n\n        Args:\n            sequences (str or Iterable[str]):\n                path to text file or iterable of the actual text data.\n            side (str): Prefix used in return dict. Usually\n                ``\"src\"`` or ``\"tgt\"``.\n            _dir (NoneType): Leave as ``None``. This parameter exists to\n                conform with the :func:`DataReaderBase.read()` signature.\n\n        Yields:\n            dictionaries whose keys are the names of fields and whose\n            values are more or less the result of tokenizing with those\n            fields.\n        \"\"\"", "\n", "assert", "_dir", "is", "None", "or", "_dir", "==", "\"\"", ",", "\"Cannot use _dir with TextDataReader.\"", "\n", "if", "isinstance", "(", "sequences", ",", "str", ")", ":", "\n", "            ", "sequences", "=", "DataReaderBase", ".", "_read_file", "(", "sequences", ")", "\n", "", "for", "i", ",", "seq", "in", "enumerate", "(", "sequences", ")", ":", "\n", "            ", "if", "isinstance", "(", "seq", ",", "six", ".", "binary_type", ")", ":", "\n", "                ", "seq", "=", "seq", ".", "decode", "(", "\"utf-8\"", ")", "\n", "", "yield", "{", "side", ":", "seq", ",", "\"indices\"", ":", "i", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.text_dataset.TextMultiField.__init__": [[97, 102], ["torchtext.data.RawField.__init__", "sorted", "text_dataset.TextMultiField.fields.append"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "base_name", ",", "base_field", ",", "feats_fields", ")", ":", "\n", "        ", "super", "(", "TextMultiField", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fields", "=", "[", "(", "base_name", ",", "base_field", ")", "]", "\n", "for", "name", ",", "ff", "in", "sorted", "(", "feats_fields", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "0", "]", ")", ":", "\n", "            ", "self", ".", "fields", ".", "append", "(", "(", "name", ",", "ff", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.text_dataset.TextMultiField.base_field": [[103, 106], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "base_field", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "fields", "[", "0", "]", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.text_dataset.TextMultiField.process": [[107, 141], ["list", "text_dataset.TextMultiField.base_field.process", "torch.stack", "zip", "ff.process", "enumerate"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.text_dataset.TextMultiField.process", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.text_dataset.TextMultiField.process"], ["", "def", "process", "(", "self", ",", "batch", ",", "device", "=", "None", ")", ":", "\n", "        ", "\"\"\"Convert outputs of preprocess into Tensors.\n\n        Args:\n            batch (List[List[List[str]]]): A list of length batch size.\n                Each element is a list of the preprocess results for each\n                field (which are lists of str \"words\" or feature tags.\n            device (torch.device or str): The device on which the tensor(s)\n                are built.\n\n        Returns:\n            torch.LongTensor or Tuple[LongTensor, LongTensor]:\n                A tensor of shape ``(seq_len, batch_size, len(self.fields))``\n                where the field features are ordered like ``self.fields``.\n                If the base field returns lengths, these are also returned\n                and have shape ``(batch_size,)``.\n        \"\"\"", "\n", "\n", "# batch (list(list(list))): batch_size x len(self.fields) x seq_len", "\n", "batch_by_feat", "=", "list", "(", "zip", "(", "*", "batch", ")", ")", "\n", "base_data", "=", "self", ".", "base_field", ".", "process", "(", "batch_by_feat", "[", "0", "]", ",", "device", "=", "device", ")", "\n", "if", "self", ".", "base_field", ".", "include_lengths", ":", "\n", "# lengths: batch_size", "\n", "            ", "base_data", ",", "lengths", "=", "base_data", "\n", "\n", "", "feats", "=", "[", "ff", ".", "process", "(", "batch_by_feat", "[", "i", "]", ",", "device", "=", "device", ")", "\n", "for", "i", ",", "(", "_", ",", "ff", ")", "in", "enumerate", "(", "self", ".", "fields", "[", "1", ":", "]", ",", "1", ")", "]", "\n", "levels", "=", "[", "base_data", "]", "+", "feats", "\n", "# data: seq_len x batch_size x len(self.fields)", "\n", "data", "=", "torch", ".", "stack", "(", "levels", ",", "2", ")", "\n", "if", "self", ".", "base_field", ".", "include_lengths", ":", "\n", "            ", "return", "data", ",", "lengths", "\n", "", "else", ":", "\n", "            ", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.text_dataset.TextMultiField.preprocess": [[142, 155], ["f.preprocess"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.text_dataset.TextMultiField.preprocess"], ["", "", "def", "preprocess", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Preprocess data.\n\n        Args:\n            x (str): A sentence string (words joined by whitespace).\n\n        Returns:\n            List[List[str]]: A list of length ``len(self.fields)`` containing\n                lists of tokens/feature tags for the sentence. The output\n                is ordered like ``self.fields``.\n        \"\"\"", "\n", "\n", "return", "[", "f", ".", "preprocess", "(", "x", ")", "for", "_", ",", "f", "in", "self", ".", "fields", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.text_dataset.TextMultiField.__getitem__": [[156, 158], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "self", ".", "fields", "[", "item", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.text_dataset.text_sort_key": [[39, 46], ["hasattr", "len", "hasattr", "hasattr", "len", "len", "len"], "function", ["None"], ["", "", "", "def", "text_sort_key", "(", "ex", ")", ":", "\n", "    ", "\"\"\"Sort using the number of tokens in the sequence.\"\"\"", "\n", "if", "hasattr", "(", "ex", ",", "\"src\"", ")", "and", "hasattr", "(", "ex", ",", "\"tgt\"", ")", ":", "\n", "        ", "return", "len", "(", "ex", ".", "src", "[", "0", "]", ")", ",", "len", "(", "ex", ".", "tgt", "[", "0", "]", ")", "\n", "", "if", "hasattr", "(", "ex", ",", "\"tgt\"", ")", ":", "\n", "        ", "return", "len", "(", "ex", ".", "tgt", "[", "0", "]", ")", "\n", "", "return", "len", "(", "ex", ".", "src", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.text_dataset._feature_tokenize": [[49, 76], ["string.split", "len", "t.split"], "function", ["None"], ["", "def", "_feature_tokenize", "(", "\n", "string", ",", "layer", "=", "0", ",", "tok_delim", "=", "None", ",", "feat_delim", "=", "None", ",", "truncate", "=", "None", ",", "truncated", "=", "None", ")", ":", "\n", "    ", "\"\"\"Split apart word features (like POS/NER tags) from the tokens.\n\n    Args:\n        string (str): A string with ``tok_delim`` joining tokens and\n            features joined by ``feat_delim``. For example,\n            ``\"hello|NOUN|'' Earth|NOUN|PLANET\"``.\n        layer (int): Which feature to extract. (Not used if there are no\n            features, indicated by ``feat_delim is None``). In the\n            example above, layer 2 is ``'' PLANET``.\n        truncate (int or NoneType): Restrict sequences to this length of\n            tokens.\n\n    Returns:\n        List[str] of tokens.\n    \"\"\"", "\n", "\n", "tokens", "=", "string", ".", "split", "(", "tok_delim", ")", "\n", "if", "truncate", "is", "not", "None", ":", "\n", "        ", "if", "truncated", "is", "not", "None", "and", "len", "(", "tokens", ")", ">", "truncate", ":", "\n", "            ", "truncated", "[", "0", "]", "+=", "1", "\n", "#print(truncated[0])", "\n", "", "tokens", "=", "tokens", "[", ":", "truncate", "]", "\n", "", "if", "feat_delim", "is", "not", "None", ":", "\n", "        ", "tokens", "=", "[", "t", ".", "split", "(", "feat_delim", ")", "[", "layer", "]", "for", "t", "in", "tokens", "]", "\n", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.text_dataset.text_fields": [[160, 204], ["kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "range", "text_dataset.TextMultiField", "functools.partial", "torchtext.data.Field", "fields_.append", "str"], "function", ["None"], ["", "", "def", "text_fields", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Create text fields.\n\n    Args:\n        base_name (str): Name associated with the field.\n        n_feats (int): Number of word level feats (not counting the tokens)\n        include_lengths (bool): Optionally return the sequence lengths.\n        pad (str, optional): Defaults to ``\"<blank>\"``.\n        bos (str or NoneType, optional): Defaults to ``\"<s>\"``.\n        eos (str or NoneType, optional): Defaults to ``\"</s>\"``.\n        truncate (bool or NoneType, optional): Defaults to ``None``.\n\n    Returns:\n        TextMultiField\n    \"\"\"", "\n", "\n", "n_feats", "=", "kwargs", "[", "\"n_feats\"", "]", "+", "1", "\n", "include_lengths", "=", "kwargs", "[", "\"include_lengths\"", "]", "\n", "base_name", "=", "kwargs", "[", "\"base_name\"", "]", "\n", "pad", "=", "kwargs", ".", "get", "(", "\"pad\"", ",", "\"<blank>\"", ")", "\n", "bos", "=", "kwargs", ".", "get", "(", "\"bos\"", ",", "\"<s>\"", ")", "\n", "eos", "=", "kwargs", ".", "get", "(", "\"eos\"", ",", "\"</s>\"", ")", "\n", "unk", "=", "kwargs", ".", "get", "(", "\"unk\"", ",", "\"<unk>\"", ")", "\n", "truncate", "=", "kwargs", ".", "get", "(", "\"truncate\"", ",", "None", ")", "\n", "fields_", "=", "[", "]", "\n", "feat_delim", "=", "u\"\uffe8\"", "if", "n_feats", ">", "0", "else", "None", "\n", "for", "i", "in", "range", "(", "n_feats", "+", "1", ")", ":", "\n", "        ", "name", "=", "base_name", "+", "\"_feat_\"", "+", "str", "(", "i", "-", "1", ")", "if", "i", ">", "0", "else", "base_name", "\n", "truncated", "=", "[", "0", "]", "\n", "tokenize", "=", "partial", "(", "\n", "_feature_tokenize", ",", "\n", "layer", "=", "i", ",", "\n", "truncate", "=", "truncate", ",", "\n", "feat_delim", "=", "feat_delim", ",", "\n", "truncated", "=", "truncated", ")", "\n", "use_len", "=", "i", "==", "0", "and", "include_lengths", "\n", "feat", "=", "Field", "(", "\n", "init_token", "=", "bos", ",", "eos_token", "=", "eos", ",", "\n", "pad_token", "=", "pad", ",", "unk_token", "=", "unk", ",", "\n", "tokenize", "=", "tokenize", ",", "include_lengths", "=", "use_len", ")", "\n", "fields_", ".", "append", "(", "(", "name", ",", "feat", ")", ")", "\n", "", "assert", "fields_", "[", "0", "]", "[", "0", "]", "==", "base_name", "# sanity check", "\n", "field", "=", "TextMultiField", "(", "fields_", "[", "0", "]", "[", "0", "]", ",", "fields_", "[", "0", "]", "[", "1", "]", ",", "fields_", "[", "1", ":", "]", ")", "\n", "return", "field", "\n", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.none_dataset.NoneDataReader.read": [[18, 34], ["range", "torch.tensor"], "methods", ["None"], ["def", "read", "(", "self", ",", "path", ",", "side", ",", "img_dir", "=", "None", ")", ":", "\n", "        ", "\"\"\"Read data into dicts.\n\n        Args:\n            path (str): Path to npy file with saved image vectors\n                The filenames may be relative to ``src_dir``\n                (default behavior) or absolute.\n            side (str): Prefix used in return dict. Usually\n                ``\"src\"`` or ``\"tgt\"``.\n\n        Yields:\n            a dictionary containing image data and index for each line.\n        \"\"\"", "\n", "\n", "for", "i", "in", "range", "(", "features", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "yield", "{", "side", ":", "torch", ".", "tensor", "(", "features", "[", "i", "]", ")", ",", "'indices'", ":", "i", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.none_dataset.img_vec_sort_key": [[35, 38], ["ex.src.size"], "function", ["None"], ["", "", "", "def", "img_vec_sort_key", "(", "ex", ")", ":", "\n", "    ", "\"\"\"Sort using the number of image box features.\"\"\"", "\n", "return", "ex", ".", "src", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.none_dataset.batch_img_vec": [[39, 43], ["torch.stack"], "function", ["None"], ["", "def", "batch_img_vec", "(", "data", ",", "vocab", ")", ":", "\n", "    ", "\"\"\"Batch a sequence of image vectors.\"\"\"", "\n", "imgs", "=", "torch", ".", "stack", "(", "data", ",", "dim", "=", "1", ")", "# [K, B, dim]", "\n", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.none_dataset.image_vec_fields": [[44, 49], ["torchtext.data.Field"], "function", ["None"], ["", "def", "image_vec_fields", "(", "**", "kwargs", ")", ":", "\n", "    ", "img", "=", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "postprocessing", "=", "batch_img_vec", ",", "sequential", "=", "False", ")", "\n", "return", "img", "\n", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.OrderedIterator.__init__": [[529, 536], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "dataset", ",", "\n", "batch_size", ",", "\n", "batch_size_multiple", "=", "1", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "OrderedIterator", ",", "self", ")", ".", "__init__", "(", "dataset", ",", "batch_size", ",", "**", "kwargs", ")", "\n", "self", ".", "batch_size_multiple", "=", "batch_size_multiple", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.OrderedIterator.create_batches": [[537, 558], ["inputter.OrderedIterator.create_batches._pool"], "methods", ["None"], ["", "def", "create_batches", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "train", ":", "\n", "            ", "def", "_pool", "(", "data", ",", "random_shuffler", ")", ":", "\n", "                ", "for", "p", "in", "torchtext", ".", "data", ".", "batch", "(", "data", ",", "self", ".", "batch_size", "*", "100", ")", ":", "\n", "                    ", "p_batch", "=", "batch_iter", "(", "\n", "sorted", "(", "p", ",", "key", "=", "self", ".", "sort_key", ")", ",", "\n", "self", ".", "batch_size", ",", "\n", "batch_size_fn", "=", "self", ".", "batch_size_fn", ",", "\n", "batch_size_multiple", "=", "self", ".", "batch_size_multiple", ")", "\n", "for", "b", "in", "random_shuffler", "(", "list", "(", "p_batch", ")", ")", ":", "\n", "                        ", "yield", "b", "\n", "\n", "", "", "", "self", ".", "batches", "=", "_pool", "(", "self", ".", "data", "(", ")", ",", "self", ".", "random_shuffler", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "batches", "=", "[", "]", "\n", "for", "b", "in", "batch_iter", "(", "\n", "self", ".", "data", "(", ")", ",", "\n", "self", ".", "batch_size", ",", "\n", "batch_size_fn", "=", "self", ".", "batch_size_fn", ",", "\n", "batch_size_multiple", "=", "self", ".", "batch_size_multiple", ")", ":", "\n", "                ", "self", ".", "batches", ".", "append", "(", "sorted", "(", "b", ",", "key", "=", "self", ".", "sort_key", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.DatasetLazyIter.__init__": [[573, 596], ["onmt.utils.logging.logger.info", "torch.load", "len", "gc.collect", "gc.collect"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load"], ["def", "__init__", "(", "self", ",", "dataset_paths", ",", "fields", ",", "batch_size", ",", "batch_size_fn", ",", "\n", "batch_size_multiple", ",", "device", ",", "is_train", ",", "repeat", "=", "True", ",", "\n", "num_batches_multiple", "=", "1", ",", "count", "=", "False", ")", ":", "\n", "        ", "self", ".", "_paths", "=", "dataset_paths", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "batch_size_fn", "=", "batch_size_fn", "\n", "self", ".", "batch_size_multiple", "=", "batch_size_multiple", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "is_train", "=", "is_train", "\n", "self", ".", "repeat", "=", "repeat", "\n", "self", ".", "num_batches_multiple", "=", "num_batches_multiple", "\n", "\n", "if", "count", ":", "\n", "            ", "self", ".", "total_size", "=", "0", "\n", "logger", ".", "info", "(", "'Counting examples...'", ")", "\n", "for", "path", "in", "self", ".", "_paths", ":", "\n", "                ", "cur_dataset", "=", "torch", ".", "load", "(", "path", ")", "\n", "self", ".", "total_size", "+=", "len", "(", "cur_dataset", ")", "\n", "cur_dataset", ".", "examples", "=", "None", "\n", "gc", ".", "collect", "(", ")", "\n", "del", "cur_dataset", "\n", "gc", ".", "collect", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.DatasetLazyIter._iter_dataset": [[597, 621], ["torch.load", "onmt.utils.logging.logger.info", "inputter.OrderedIterator", "gc.collect", "gc.collect", "len"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load"], ["", "", "", "def", "_iter_dataset", "(", "self", ",", "path", ")", ":", "\n", "\n", "        ", "cur_dataset", "=", "torch", ".", "load", "(", "path", ")", "\n", "logger", ".", "info", "(", "'Loading dataset from %s, number of examples: %d'", "%", "\n", "(", "path", ",", "len", "(", "cur_dataset", ")", ")", ")", "\n", "cur_dataset", ".", "fields", "=", "self", ".", "fields", "\n", "cur_iter", "=", "OrderedIterator", "(", "\n", "dataset", "=", "cur_dataset", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "batch_size_multiple", "=", "self", ".", "batch_size_multiple", ",", "\n", "batch_size_fn", "=", "self", ".", "batch_size_fn", ",", "\n", "device", "=", "self", ".", "device", ",", "\n", "train", "=", "self", ".", "is_train", ",", "\n", "sort", "=", "False", ",", "\n", "sort_within_batch", "=", "True", ",", "\n", "repeat", "=", "False", "\n", ")", "\n", "for", "batch", "in", "cur_iter", ":", "\n", "            ", "yield", "batch", "\n", "\n", "", "cur_dataset", ".", "examples", "=", "None", "\n", "gc", ".", "collect", "(", ")", "\n", "del", "cur_dataset", "\n", "gc", ".", "collect", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.DatasetLazyIter.__iter__": [[622, 644], ["itertools.cycle", "inputter.DatasetLazyIter._iter_dataset", "inputter.DatasetLazyIter._iter_dataset"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.DatasetLazyIter._iter_dataset", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.DatasetLazyIter._iter_dataset"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "num_batches", "=", "0", "\n", "paths", "=", "self", ".", "_paths", "\n", "if", "self", ".", "is_train", "and", "self", ".", "repeat", ":", "\n", "# Cycle through the shards indefinitely.", "\n", "            ", "paths", "=", "cycle", "(", "paths", ")", "\n", "", "for", "path", "in", "paths", ":", "\n", "            ", "for", "batch", "in", "self", ".", "_iter_dataset", "(", "path", ")", ":", "\n", "                ", "yield", "batch", "\n", "num_batches", "+=", "1", "\n", "", "", "if", "self", ".", "is_train", "and", "not", "self", ".", "repeat", "and", "num_batches", "%", "self", ".", "num_batches_multiple", "!=", "0", ":", "\n", "# When the dataset is not repeated, we might need to ensure that", "\n", "# the number of returned batches is the multiple of a given value.", "\n", "# This is important for multi GPU training to ensure that all", "\n", "# workers have the same number of batches to process.", "\n", "            ", "for", "path", "in", "paths", ":", "\n", "                ", "for", "batch", "in", "self", ".", "_iter_dataset", "(", "path", ")", ":", "\n", "                    ", "yield", "batch", "\n", "num_batches", "+=", "1", "\n", "if", "num_batches", "%", "self", ".", "num_batches_multiple", "==", "0", ":", "\n", "                        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._getstate": [[28, 30], ["dict", "dict"], "function", ["None"], ["def", "_getstate", "(", "self", ")", ":", "\n", "    ", "return", "dict", "(", "self", ".", "__dict__", ",", "stoi", "=", "dict", "(", "self", ".", "stoi", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._setstate": [[32, 35], ["inputter..__dict__.update", "collections.defaultdict"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.update"], ["", "def", "_setstate", "(", "self", ",", "state", ")", ":", "\n", "    ", "self", ".", "__dict__", ".", "update", "(", "state", ")", "\n", "self", ".", "stoi", "=", "defaultdict", "(", "lambda", ":", "0", ",", "self", ".", "stoi", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.make_src": [[41, 48], ["max", "torch.zeros", "enumerate", "max", "len", "alignment[].scatter_", "t.size", "sent.unsqueeze", "t.max", "len"], "function", ["None"], ["def", "make_src", "(", "data", ",", "vocab", ")", ":", "\n", "    ", "src_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "src_vocab_size", "=", "max", "(", "[", "t", ".", "max", "(", ")", "for", "t", "in", "data", "]", ")", "+", "1", "\n", "alignment", "=", "torch", ".", "zeros", "(", "src_size", ",", "len", "(", "data", ")", ",", "src_vocab_size", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "        ", "alignment", "[", ":", "len", "(", "sent", ")", ",", "i", ",", ":", "]", ".", "scatter_", "(", "1", ",", "sent", ".", "unsqueeze", "(", "1", ")", ",", "1", ")", "\n", "", "return", "alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.make_tgt": [[50, 56], ["max", "torch.zeros().long", "enumerate", "t.size", "torch.zeros", "len", "sent.size"], "function", ["None"], ["", "def", "make_tgt", "(", "data", ",", "vocab", ")", ":", "\n", "    ", "tgt_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "alignment", "=", "torch", ".", "zeros", "(", "tgt_size", ",", "len", "(", "data", ")", ")", ".", "long", "(", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "        ", "alignment", "[", ":", "sent", ".", "size", "(", "0", ")", ",", "i", "]", "=", "sent", "\n", "", "return", "alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.make_pointer": [[57, 71], ["max", "max", "torch.zeros().long", "enumerate", "enumerate", "torch.ones", "torch.zeros", "range", "len", "t.size"], "function", ["None"], ["", "def", "make_pointer", "(", "data", ",", "vocab", ")", ":", "\n", "    ", "if", "data", "[", "0", "]", "is", "None", ":", "# valid data", "\n", "        ", "return", "torch", ".", "ones", "(", "1", ",", "2", ",", "3", ",", "4", ",", "5", ")", "*", "99999999", "# will probably cause error if used", "\n", "\n", "", "src_size", "=", "max", "(", "[", "t", "[", "-", "2", "]", "[", "0", "]", "for", "t", "in", "data", "]", ")", "\n", "tgt_size", "=", "max", "(", "[", "t", "[", "-", "1", "]", "[", "0", "]", "for", "t", "in", "data", "]", ")", "\n", "#format of data is tgt_len, batch, src_len", "\n", "alignment", "=", "torch", ".", "zeros", "(", "tgt_size", "+", "2", ",", "len", "(", "data", ")", ",", "src_size", ")", ".", "long", "(", ")", "#+2 for bos and eos", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "        ", "for", "j", ",", "t", "in", "enumerate", "(", "sent", "[", ":", "-", "2", "]", ")", ":", "#only iterate till the third-last row", "\n", "# as the last two rows contains lengths of src and tgt", "\n", "            ", "for", "k", "in", "range", "(", "1", ",", "t", "[", "t", ".", "size", "(", "0", ")", "-", "1", "]", ")", ":", "#iterate from index 1 as index 0 is tgt position", "\n", "                ", "alignment", "[", "t", "[", "0", "]", "+", "1", "]", "[", "i", "]", "[", "t", "[", "k", "]", "]", "=", "1", "#+1 to accommodate bos", "\n", "", "", "", "return", "alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields": [[73, 159], ["torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field"], "function", ["None"], ["", "def", "get_fields", "(", "\n", "src_data_type", ",", "\n", "n_src_feats", ",", "\n", "n_tgt_feats", ",", "\n", "src_pad", "=", "'<blank>'", ",", "\n", "src_unk", "=", "'<unk>'", ",", "\n", "tgt_pad", "=", "'<blank>'", ",", "\n", "tgt_unk", "=", "'<unk>'", ",", "\n", "tgt_bos", "=", "'<s>'", ",", "\n", "tgt_eos", "=", "'</s>'", ",", "\n", "dynamic_dict", "=", "False", ",", "\n", "src_truncate", "=", "None", ",", "\n", "tgt_truncate", "=", "None", ",", "\n", "include_ptrs", "=", "False", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        src_data_type: type of the source input. Options are [text|img|audio].\n        n_src_feats (int): the number of source features (not counting tokens)\n            to create a :class:`torchtext.data.Field` for. (If\n            ``src_data_type==\"text\"``, these fields are stored together\n            as a ``TextMultiField``).\n        n_tgt_feats (int): See above.\n        pad (str): Special pad symbol. Used on src and tgt side.\n        bos (str): Special beginning of sequence symbol. Only relevant\n            for tgt.\n        eos (str): Special end of sequence symbol. Only relevant\n            for tgt.\n        dynamic_dict (bool): Whether or not to include source map and\n            alignment fields.\n        src_truncate: Cut off src sequences beyond this (passed to\n            ``src_data_type``'s data reader - see there for more details).\n        tgt_truncate: Cut off tgt sequences beyond this (passed to\n            :class:`TextDataReader` - see there for more details).\n\n    Returns:\n        A dict mapping names to fields. These names need to match\n        the dataset example attributes.\n    \"\"\"", "\n", "\n", "assert", "src_data_type", "in", "[", "'text'", ",", "'img'", ",", "'audio'", ",", "'imgvec'", ",", "'none'", "]", ",", "\"Data type not implemented\"", "\n", "assert", "not", "dynamic_dict", "or", "src_data_type", "==", "'text'", ",", "'it is not possible to use dynamic_dict with non-text input'", "\n", "fields", "=", "{", "}", "\n", "\n", "fields_getters", "=", "{", "\"text\"", ":", "text_fields", ",", "\n", "# \"audio\": audio_fields,", "\n", "# \"imgvec\": image_vec_fields", "\n", "}", "\n", "\n", "if", "src_data_type", "!=", "'none'", ":", "\n", "        ", "src_field_kwargs", "=", "{", "\"n_feats\"", ":", "n_src_feats", ",", "\n", "\"include_lengths\"", ":", "True", ",", "\n", "\"pad\"", ":", "src_pad", ",", "\"bos\"", ":", "None", ",", "\"eos\"", ":", "None", ",", "\"unk\"", ":", "src_unk", ",", "\n", "\"truncate\"", ":", "src_truncate", ",", "\n", "\"base_name\"", ":", "\"src\"", "}", "\n", "fields", "[", "\"src\"", "]", "=", "fields_getters", "[", "src_data_type", "]", "(", "**", "src_field_kwargs", ")", "\n", "\n", "", "tgt_field_kwargs", "=", "{", "\"n_feats\"", ":", "n_tgt_feats", ",", "\n", "\"include_lengths\"", ":", "True", ",", "\n", "\"pad\"", ":", "tgt_pad", ",", "\"bos\"", ":", "tgt_bos", ",", "\"eos\"", ":", "tgt_eos", ",", "\"unk\"", ":", "tgt_unk", ",", "\n", "\"truncate\"", ":", "tgt_truncate", ",", "\n", "\"base_name\"", ":", "\"tgt\"", "}", "\n", "fields", "[", "\"tgt\"", "]", "=", "fields_getters", "[", "\"text\"", "]", "(", "**", "tgt_field_kwargs", ")", "\n", "\n", "indices", "=", "Field", "(", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "long", ",", "sequential", "=", "False", ")", "\n", "fields", "[", "\"indices\"", "]", "=", "indices", "\n", "\n", "if", "dynamic_dict", ":", "\n", "        ", "src_map", "=", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "postprocessing", "=", "make_src", ",", "sequential", "=", "False", ")", "\n", "fields", "[", "\"src_map\"", "]", "=", "src_map", "\n", "\n", "align", "=", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "postprocessing", "=", "make_tgt", ",", "sequential", "=", "False", ")", "\n", "fields", "[", "\"alignment\"", "]", "=", "align", "\n", "\n", "", "if", "include_ptrs", ":", "\n", "        ", "fields", "[", "\"ptrs\"", "]", "=", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "postprocessing", "=", "make_pointer", ",", "sequential", "=", "False", ")", "\n", "\n", "", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.load_old_vocab": [[161, 211], ["inputter._old_style_vocab", "inputter._old_style_field_list", "inputter._old_style_nesting", "dict", "sum", "sum", "inputter.get_fields", "dict.items", "dict.items", "dict", "list", "iter", "itertools.chain.from_iterable", "isinstance", "dict.values", "onmt.inputters.text_dataset.TextMultiField"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._old_style_vocab", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._old_style_field_list", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._old_style_nesting", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields"], ["", "def", "load_old_vocab", "(", "vocab", ",", "data_type", "=", "\"text\"", ",", "dynamic_dict", "=", "False", ")", ":", "\n", "    ", "\"\"\"Update a legacy vocab/field format.\n\n    Args:\n        vocab: a list of (field name, torchtext.vocab.Vocab) pairs. This is the\n            format formerly saved in *.vocab.pt files. Or, text data\n            not using a :class:`TextMultiField`.\n        data_type (str): text, img, or audio\n        dynamic_dict (bool): Used for copy attention.\n\n    Returns:\n        a dictionary whose keys are the field names and whose values Fields.\n    \"\"\"", "\n", "\n", "if", "_old_style_vocab", "(", "vocab", ")", ":", "\n", "# List[Tuple[str, Vocab]] -> List[Tuple[str, Field]]", "\n", "# -> dict[str, Field]", "\n", "        ", "vocab", "=", "dict", "(", "vocab", ")", "\n", "n_src_features", "=", "sum", "(", "'src_feat_'", "in", "k", "for", "k", "in", "vocab", ")", "\n", "n_tgt_features", "=", "sum", "(", "'tgt_feat_'", "in", "k", "for", "k", "in", "vocab", ")", "\n", "fields", "=", "get_fields", "(", "\n", "data_type", ",", "n_src_features", ",", "n_tgt_features", ",", "\n", "dynamic_dict", "=", "dynamic_dict", ")", "\n", "for", "n", ",", "f", "in", "fields", ".", "items", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "f_iter", "=", "iter", "(", "f", ")", "\n", "", "except", "TypeError", ":", "\n", "                ", "f_iter", "=", "[", "(", "n", ",", "f", ")", "]", "\n", "", "for", "sub_n", ",", "sub_f", "in", "f_iter", ":", "\n", "                ", "if", "sub_n", "in", "vocab", ":", "\n", "                    ", "sub_f", ".", "vocab", "=", "vocab", "[", "sub_n", "]", "\n", "", "", "", "return", "fields", "\n", "\n", "", "if", "_old_style_field_list", "(", "vocab", ")", ":", "# upgrade to multifield", "\n", "# Dict[str, List[Tuple[str, Field]]]", "\n", "# doesn't change structure - don't return early.", "\n", "        ", "fields", "=", "vocab", "\n", "for", "base_name", ",", "vals", "in", "fields", ".", "items", "(", ")", ":", "\n", "            ", "if", "(", "(", "base_name", "==", "'src'", "and", "data_type", "==", "'text'", ")", "or", "\n", "base_name", "==", "'tgt'", ")", ":", "\n", "                ", "assert", "not", "isinstance", "(", "vals", "[", "0", "]", "[", "1", "]", ",", "TextMultiField", ")", "\n", "fields", "[", "base_name", "]", "=", "[", "(", "base_name", ",", "TextMultiField", "(", "\n", "vals", "[", "0", "]", "[", "0", "]", ",", "vals", "[", "0", "]", "[", "1", "]", ",", "vals", "[", "1", ":", "]", ")", ")", "]", "\n", "\n", "", "", "", "if", "_old_style_nesting", "(", "vocab", ")", ":", "\n", "# Dict[str, List[Tuple[str, Field]]] -> List[Tuple[str, Field]]", "\n", "# -> dict[str, Field]", "\n", "        ", "fields", "=", "dict", "(", "list", "(", "chain", ".", "from_iterable", "(", "vocab", ".", "values", "(", ")", ")", ")", ")", "\n", "\n", "", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._old_style_vocab": [[213, 230], ["isinstance", "any", "isinstance"], "function", ["None"], ["", "def", "_old_style_vocab", "(", "vocab", ")", ":", "\n", "    ", "\"\"\"Detect old-style vocabs (``List[Tuple[str, torchtext.data.Vocab]]``).\n\n    Args:\n        vocab: some object loaded from a *.vocab.pt file\n\n    Returns:\n        Whether ``vocab`` is a list of pairs where the second object\n        is a :class:`torchtext.vocab.Vocab` object.\n\n    This exists because previously only the vocab objects from the fields\n    were saved directly, not the fields themselves, and the fields needed to\n    be reconstructed at training and translation time.\n    \"\"\"", "\n", "\n", "return", "isinstance", "(", "vocab", ",", "list", ")", "and", "any", "(", "isinstance", "(", "v", "[", "1", "]", ",", "Vocab", ")", "for", "v", "in", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._old_style_nesting": [[232, 236], ["isinstance", "any", "isinstance", "vocab.values"], "function", ["None"], ["", "def", "_old_style_nesting", "(", "vocab", ")", ":", "\n", "    ", "\"\"\"Detect old-style nesting (``dict[str, List[Tuple[str, Field]]]``).\"\"\"", "\n", "return", "isinstance", "(", "vocab", ",", "dict", ")", "and", "any", "(", "isinstance", "(", "v", ",", "list", ")", "for", "v", "in", "vocab", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._old_style_field_list": [[238, 255], ["inputter._old_style_nesting", "inputter._old_style_vocab", "isinstance"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._old_style_nesting", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._old_style_vocab"], ["", "def", "_old_style_field_list", "(", "vocab", ")", ":", "\n", "    ", "\"\"\"Detect old-style text fields.\n\n    Not old style vocab, old nesting, and text-type fields not using\n    ``TextMultiField``.\n\n    Args:\n        vocab: some object loaded from a *.vocab.pt file\n\n    Returns:\n        Whether ``vocab`` is not an :func:`_old_style_vocab` and not\n        a :class:`TextMultiField` (using an old-style text representation).\n    \"\"\"", "\n", "\n", "# if tgt isn't using TextMultiField, then no text field is.", "\n", "return", "(", "not", "_old_style_vocab", "(", "vocab", ")", ")", "and", "_old_style_nesting", "(", "vocab", ")", "and", "(", "not", "isinstance", "(", "vocab", "[", "'tgt'", "]", "[", "0", "]", "[", "1", "]", ",", "TextMultiField", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.old_style_vocab": [[257, 261], ["inputter._old_style_vocab", "inputter._old_style_field_list", "inputter._old_style_nesting"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._old_style_vocab", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._old_style_field_list", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._old_style_nesting"], ["", "def", "old_style_vocab", "(", "vocab", ")", ":", "\n", "    ", "\"\"\"The vocab/fields need updated.\"\"\"", "\n", "return", "_old_style_vocab", "(", "vocab", ")", "or", "_old_style_field_list", "(", "vocab", ")", "or", "_old_style_nesting", "(", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.filter_example": [[263, 294], ["float", "float", "hasattr", "len", "len"], "function", ["None"], ["", "def", "filter_example", "(", "ex", ",", "use_src_len", "=", "True", ",", "use_tgt_len", "=", "True", ",", "\n", "min_src_len", "=", "1", ",", "max_src_len", "=", "float", "(", "'inf'", ")", ",", "\n", "min_tgt_len", "=", "1", ",", "max_tgt_len", "=", "float", "(", "'inf'", ")", ")", ":", "\n", "    ", "\"\"\"Return whether an example is an acceptable length.\n\n    If used with a dataset as ``filter_pred``, use :func:`partial()`\n    for all keyword arguments.\n\n    Args:\n        ex (torchtext.data.Example): An object with a ``src`` and ``tgt``\n            property.\n        use_src_len (bool): Filter based on the length of ``ex.src``.\n        use_tgt_len (bool): Similar to above.\n        min_src_len (int): A non-negative minimally acceptable length\n            (examples of exactly this length will be included).\n        min_tgt_len (int): Similar to above.\n        max_src_len (int or float): A non-negative (possibly infinite)\n            maximally acceptable length (examples of exactly this length\n            will be included).\n        max_tgt_len (int or float): Similar to above.\n    \"\"\"", "\n", "\n", "if", "hasattr", "(", "ex", ",", "'src'", ")", ":", "\n", "        ", "src_len", "=", "len", "(", "ex", ".", "src", "[", "0", "]", ")", "\n", "src_no_filter", "=", "not", "use_src_len", "or", "min_src_len", "<=", "src_len", "<=", "max_src_len", "\n", "", "else", ":", "\n", "        ", "src_no_filter", "=", "True", "\n", "\n", "", "tgt_len", "=", "len", "(", "ex", ".", "tgt", "[", "0", "]", ")", "\n", "tgt_no_filter", "=", "not", "use_tgt_len", "or", "min_tgt_len", "<=", "tgt_len", "<=", "max_tgt_len", "\n", "return", "src_no_filter", "and", "tgt_no_filter", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._pad_vocab_to_multiple": [[296, 305], ["len", "vocab.extend", "int", "torchtext.vocab.Vocab", "math.ceil", "range", "collections.Counter"], "function", ["None"], ["", "def", "_pad_vocab_to_multiple", "(", "vocab", ",", "multiple", ")", ":", "\n", "    ", "vocab_size", "=", "len", "(", "vocab", ")", "\n", "if", "vocab_size", "%", "multiple", "==", "0", ":", "\n", "        ", "return", "\n", "", "target_size", "=", "int", "(", "math", ".", "ceil", "(", "vocab_size", "/", "multiple", ")", ")", "*", "multiple", "\n", "padding_tokens", "=", "[", "\n", "\"averyunlikelytoken%d\"", "%", "i", "for", "i", "in", "range", "(", "target_size", "-", "vocab_size", ")", "]", "\n", "vocab", ".", "extend", "(", "Vocab", "(", "Counter", "(", ")", ",", "specials", "=", "padding_tokens", ")", ")", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._build_field_vocab": [[307, 317], ["field.vocab_cls", "inputter._pad_vocab_to_multiple"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._pad_vocab_to_multiple"], ["", "def", "_build_field_vocab", "(", "field", ",", "counter", ",", "fixed_vocab", "=", "False", ",", "size_multiple", "=", "1", ",", "**", "kwargs", ")", ":", "\n", "# this is basically copy-pasted from torchtext.", "\n", "    ", "all_specials", "=", "[", "\n", "field", ".", "unk_token", ",", "field", ".", "pad_token", ",", "field", ".", "init_token", ",", "field", ".", "eos_token", "\n", "]", "\n", "specials", "=", "[", "tok", "for", "tok", "in", "all_specials", "if", "tok", "is", "not", "None", "]", "\n", "specials", "=", "[", "]", "if", "fixed_vocab", "else", "specials", "\n", "field", ".", "vocab", "=", "field", ".", "vocab_cls", "(", "counter", ",", "specials", "=", "specials", ",", "**", "kwargs", ")", "\n", "if", "size_multiple", ">", "1", ":", "\n", "        ", "_pad_vocab_to_multiple", "(", "field", ".", "vocab", ",", "size_multiple", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._load_vocab": [[319, 329], ["inputter._read_vocab_file", "len", "onmt.utils.logging.logger.info", "enumerate"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._read_vocab_file"], ["", "", "def", "_load_vocab", "(", "vocab_path", ",", "name", ",", "counters", ")", ":", "\n", "# counters changes in place", "\n", "    ", "vocab", "=", "_read_vocab_file", "(", "vocab_path", ",", "name", ")", "\n", "vocab_size", "=", "len", "(", "vocab", ")", "\n", "logger", ".", "info", "(", "'Loaded %s vocab has %d tokens.'", "%", "(", "name", ",", "vocab_size", ")", ")", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "vocab", ")", ":", "\n", "# keep the order of tokens specified in the vocab file by", "\n", "# adding them to the counter with decreasing counting values", "\n", "        ", "counters", "[", "name", "]", "[", "token", "]", "=", "vocab_size", "-", "i", "\n", "", "return", "vocab", ",", "vocab_size", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._build_fv_from_multifield": [[331, 341], ["inputter._build_field_vocab", "onmt.utils.logging.logger.info", "len"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._build_field_vocab"], ["", "def", "_build_fv_from_multifield", "(", "multifield", ",", "counters", ",", "build_fv_args", ",", "\n", "fixed_vocab", "=", "False", ",", "size_multiple", "=", "1", ")", ":", "\n", "    ", "for", "name", ",", "field", "in", "multifield", ":", "\n", "        ", "_build_field_vocab", "(", "\n", "field", ",", "\n", "counters", "[", "name", "]", ",", "\n", "fixed_vocab", "=", "fixed_vocab", ",", "\n", "size_multiple", "=", "size_multiple", ",", "\n", "**", "build_fv_args", "[", "name", "]", ")", "\n", "logger", ".", "info", "(", "\" * %s vocab size: %d.\"", "%", "(", "name", ",", "len", "(", "field", ".", "vocab", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.build_vocab": [[343, 450], ["collections.defaultdict", "collections.defaultdict", "dict", "dict", "inputter._build_fv_from_multifield", "inputter._load_vocab", "inputter._load_vocab", "enumerate", "inputter._build_fv_from_multifield", "torch.load", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "inputter._merge_field_vocabs", "onmt.utils.logging.logger.info", "fields.items", "gc.collect", "gc.collect", "gc.collect", "zip", "len", "len", "iter", "getattr", "counters[].update", "getattr"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._build_fv_from_multifield", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._load_vocab", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._load_vocab", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._build_fv_from_multifield", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._merge_field_vocabs", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.statistics.Statistics.update"], ["", "", "def", "build_vocab", "(", "train_dataset_files", ",", "fields", ",", "data_type", ",", "share_vocab", ",", "\n", "src_vocab_path", ",", "src_vocab_size", ",", "src_words_min_frequency", ",", "\n", "tgt_vocab_path", ",", "tgt_vocab_size", ",", "tgt_words_min_frequency", ",", "\n", "fixed_vocab", "=", "False", ",", "free_src", "=", "False", ",", "free_tgt", "=", "False", ",", "vocab_size_multiple", "=", "1", ")", ":", "\n", "    ", "\"\"\"Build the fields for all data sides.\n\n    Args:\n        train_dataset_files: a list of train dataset pt file.\n        fields (dict[str, Field]): fields to build vocab for.\n        data_type (str): A supported data type string.\n        share_vocab (bool): share source and target vocabulary?\n        src_vocab_path (str): Path to src vocabulary file.\n        src_vocab_size (int): size of the source vocabulary.\n        src_words_min_frequency (int): the minimum frequency needed to\n            include a source word in the vocabulary.\n        tgt_vocab_path (str): Path to tgt vocabulary file.\n        tgt_vocab_size (int): size of the target vocabulary.\n        tgt_words_min_frequency (int): the minimum frequency needed to\n            include a target word in the vocabulary.\n        fixed_vocab (bool): do not modify the loaded vocabs\n        free_src (bool): only hold the target vocab fixed\n        free_tgt (bool): only hold the source vocab fixed\n        vocab_size_multiple (int): ensure that the vocabulary size is a\n            multiple of this value.\n\n    Returns:\n        Dict of Fields\n    \"\"\"", "\n", "\n", "counters", "=", "defaultdict", "(", "Counter", ")", "\n", "\n", "# Load vocabulary", "\n", "if", "src_vocab_path", ":", "\n", "        ", "src_vocab", ",", "src_vocab_size", "=", "_load_vocab", "(", "\n", "src_vocab_path", ",", "\"src\"", ",", "counters", ")", "\n", "", "else", ":", "\n", "        ", "src_vocab", "=", "None", "\n", "\n", "", "if", "tgt_vocab_path", ":", "\n", "        ", "tgt_vocab", ",", "tgt_vocab_size", "=", "_load_vocab", "(", "\n", "tgt_vocab_path", ",", "\"tgt\"", ",", "counters", ")", "\n", "", "else", ":", "\n", "        ", "tgt_vocab", "=", "None", "\n", "\n", "", "if", "not", "fixed_vocab", "or", "free_src", "or", "free_tgt", ":", "\n", "        ", "for", "i", ",", "path", "in", "enumerate", "(", "train_dataset_files", ")", ":", "\n", "            ", "dataset", "=", "torch", ".", "load", "(", "path", ")", "\n", "logger", ".", "info", "(", "\" * reloading %s.\"", "%", "path", ")", "\n", "for", "ex", "in", "dataset", ".", "examples", ":", "\n", "                ", "for", "name", ",", "field", "in", "fields", ".", "items", "(", ")", ":", "\n", "                    ", "try", ":", "\n", "                        ", "f_iter", "=", "iter", "(", "field", ")", "\n", "", "except", "TypeError", ":", "\n", "                        ", "f_iter", "=", "[", "(", "name", ",", "field", ")", "]", "\n", "all_data", "=", "[", "getattr", "(", "ex", ",", "name", ",", "None", ")", "]", "\n", "", "else", ":", "\n", "                        ", "all_data", "=", "getattr", "(", "ex", ",", "name", ")", "\n", "", "for", "(", "sub_n", ",", "sub_f", ")", ",", "fd", "in", "zip", "(", "\n", "f_iter", ",", "all_data", ")", ":", "\n", "                        ", "has_vocab", "=", "(", "sub_n", "==", "'src'", "and", "src_vocab", ")", "or", "(", "sub_n", "==", "'src'", "and", "fixed_vocab", "and", "free_tgt", ")", "or", "(", "sub_n", "==", "'tgt'", "and", "tgt_vocab", ")", "or", "(", "sub_n", "==", "'tgt'", "and", "fixed_vocab", "and", "free_src", ")", "\n", "if", "sub_f", ".", "sequential", "and", "not", "has_vocab", ":", "\n", "                            ", "val", "=", "fd", "\n", "counters", "[", "sub_n", "]", ".", "update", "(", "val", ")", "\n", "\n", "# Drop the none-using from memory but keep the last", "\n", "", "", "", "", "if", "i", "<", "len", "(", "train_dataset_files", ")", "-", "1", ":", "\n", "                ", "dataset", ".", "examples", "=", "None", "\n", "gc", ".", "collect", "(", ")", "\n", "del", "dataset", ".", "examples", "\n", "gc", ".", "collect", "(", ")", "\n", "del", "dataset", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "", "", "", "build_fv_args", "=", "defaultdict", "(", "dict", ")", "\n", "build_fv_args", "[", "\"src\"", "]", "=", "dict", "(", "\n", "max_size", "=", "src_vocab_size", ",", "min_freq", "=", "src_words_min_frequency", ")", "\n", "build_fv_args", "[", "\"tgt\"", "]", "=", "dict", "(", "\n", "max_size", "=", "tgt_vocab_size", ",", "min_freq", "=", "tgt_words_min_frequency", ")", "\n", "tgt_multifield", "=", "fields", "[", "\"tgt\"", "]", "\n", "_build_fv_from_multifield", "(", "\n", "tgt_multifield", ",", "\n", "counters", ",", "\n", "build_fv_args", ",", "\n", "fixed_vocab", "=", "fixed_vocab", "and", "not", "free_tgt", ",", "\n", "size_multiple", "=", "vocab_size_multiple", "if", "not", "share_vocab", "else", "1", ")", "\n", "if", "data_type", "==", "'text'", ":", "\n", "        ", "src_multifield", "=", "fields", "[", "\"src\"", "]", "\n", "_build_fv_from_multifield", "(", "\n", "src_multifield", ",", "\n", "counters", ",", "\n", "build_fv_args", ",", "\n", "fixed_vocab", "=", "fixed_vocab", "and", "not", "free_src", ",", "\n", "size_multiple", "=", "vocab_size_multiple", "if", "not", "share_vocab", "else", "1", ")", "\n", "if", "share_vocab", ":", "\n", "# `tgt_vocab_size` is ignored when sharing vocabularies", "\n", "            ", "logger", ".", "info", "(", "\" * merging src and tgt vocab...\"", ")", "\n", "src_field", "=", "src_multifield", ".", "base_field", "\n", "tgt_field", "=", "tgt_multifield", ".", "base_field", "\n", "_merge_field_vocabs", "(", "\n", "src_field", ",", "tgt_field", ",", "vocab_size", "=", "src_vocab_size", ",", "\n", "min_freq", "=", "src_words_min_frequency", ",", "\n", "vocab_size_multiple", "=", "vocab_size_multiple", ")", "\n", "logger", ".", "info", "(", "\" * merged vocab size: %d.\"", "%", "len", "(", "src_field", ".", "vocab", ")", ")", "\n", "", "", "return", "fields", "# is the return necessary?", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._merge_field_vocabs": [[452, 470], ["sum", "torchtext.vocab.Vocab", "collections.Counter", "inputter._pad_vocab_to_multiple", "len", "len"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._pad_vocab_to_multiple"], ["", "def", "_merge_field_vocabs", "(", "src_field", ",", "tgt_field", ",", "vocab_size", ",", "min_freq", ",", "\n", "vocab_size_multiple", ")", ":", "\n", "# in the long run, shouldn't it be possible to do this by calling", "\n", "# build_vocab with both the src and tgt data?", "\n", "    ", "specials", "=", "[", "tgt_field", ".", "unk_token", ",", "tgt_field", ".", "pad_token", ",", "\n", "tgt_field", ".", "init_token", ",", "tgt_field", ".", "eos_token", "]", "\n", "merged", "=", "sum", "(", "\n", "[", "src_field", ".", "vocab", ".", "freqs", ",", "tgt_field", ".", "vocab", ".", "freqs", "]", ",", "Counter", "(", ")", "\n", ")", "\n", "merged_vocab", "=", "Vocab", "(", "\n", "merged", ",", "specials", "=", "specials", ",", "\n", "max_size", "=", "vocab_size", ",", "min_freq", "=", "min_freq", "\n", ")", "\n", "if", "vocab_size_multiple", ">", "1", ":", "\n", "        ", "_pad_vocab_to_multiple", "(", "merged_vocab", ",", "vocab_size_multiple", ")", "\n", "", "src_field", ".", "vocab", "=", "merged_vocab", "\n", "tgt_field", ".", "vocab", "=", "merged_vocab", "\n", "assert", "len", "(", "src_field", ".", "vocab", ")", "==", "len", "(", "tgt_field", ".", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter._read_vocab_file": [[472, 491], ["onmt.utils.logging.logger.info", "os.path.exists", "RuntimeError", "codecs.open", "line.strip().split", "line.strip", "line.strip"], "function", ["None"], ["", "def", "_read_vocab_file", "(", "vocab_path", ",", "tag", ")", ":", "\n", "    ", "\"\"\"Loads a vocabulary from the given path.\n\n    Args:\n        vocab_path (str): Path to utf-8 text file containing vocabulary.\n            Each token should be on a line by itself. Tokens must not\n            contain whitespace (else only before the whitespace\n            is considered).\n        tag (str): Used for logging which vocab is being read.\n    \"\"\"", "\n", "\n", "logger", ".", "info", "(", "\"Loading {} vocabulary from {}\"", ".", "format", "(", "tag", ",", "vocab_path", ")", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "vocab_path", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "\n", "\"{} vocabulary not found at {}\"", ".", "format", "(", "tag", ",", "vocab_path", ")", ")", "\n", "", "else", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "vocab_path", ",", "'r'", ",", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "return", "[", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "0", "]", "for", "line", "in", "f", "if", "line", ".", "strip", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.batch_iter": [[493, 525], ["minibatch.append", "inputter.batch_iter.batch_size_fn"], "function", ["None"], ["", "", "", "def", "batch_iter", "(", "data", ",", "batch_size", ",", "batch_size_fn", "=", "None", ",", "batch_size_multiple", "=", "1", ")", ":", "\n", "    ", "\"\"\"Yield elements from data in chunks of batch_size, where each chunk size\n    is a multiple of batch_size_multiple.\n\n    This is an extended version of torchtext.data.batch.\n    \"\"\"", "\n", "if", "batch_size_fn", "is", "None", ":", "\n", "        ", "def", "batch_size_fn", "(", "new", ",", "count", ",", "sofar", ")", ":", "\n", "            ", "return", "count", "\n", "", "", "minibatch", ",", "size_so_far", "=", "[", "]", ",", "0", "\n", "for", "ex", "in", "data", ":", "\n", "#print(ex, len(ex.tgt[0]), batch_size_multiple)", "\n", "        ", "minibatch", ".", "append", "(", "ex", ")", "\n", "size_so_far", "=", "batch_size_fn", "(", "ex", ",", "len", "(", "minibatch", ")", ",", "size_so_far", ")", "\n", "if", "size_so_far", ">=", "batch_size", ":", "\n", "            ", "overflowed", "=", "0", "\n", "if", "size_so_far", ">", "batch_size", ":", "\n", "                ", "overflowed", "+=", "1", "\n", "", "if", "batch_size_multiple", ">", "1", ":", "\n", "                ", "overflowed", "+=", "(", "\n", "(", "len", "(", "minibatch", ")", "-", "overflowed", ")", "%", "batch_size_multiple", ")", "\n", "", "if", "overflowed", "==", "0", ":", "\n", "                ", "yield", "minibatch", "\n", "minibatch", ",", "size_so_far", "=", "[", "]", ",", "0", "\n", "", "else", ":", "\n", "                ", "yield", "minibatch", "[", ":", "-", "overflowed", "]", "\n", "minibatch", "=", "minibatch", "[", "-", "overflowed", ":", "]", "\n", "size_so_far", "=", "0", "\n", "for", "i", ",", "ex", "in", "enumerate", "(", "minibatch", ")", ":", "\n", "                    ", "size_so_far", "=", "batch_size_fn", "(", "ex", ",", "i", "+", "1", ",", "size_so_far", ")", "\n", "", "", "", "", "if", "minibatch", ":", "\n", "        ", "yield", "minibatch", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.max_tok_len": [[646, 672], ["hasattr", "max", "max", "max", "len", "len"], "function", ["None"], ["", "", "", "", "", "", "def", "max_tok_len", "(", "new", ",", "count", ",", "sofar", ",", "tgt_only", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    In token batching scheme, the number of sequences is limited\n    such that the total number of src/tgt tokens (including padding)\n    in a batch <= batch_size\n    \"\"\"", "\n", "# Maintains the longest src and tgt length in the current batch", "\n", "global", "max_src_in_batch", ",", "max_tgt_in_batch", "# this is a hack", "\n", "# Reset current longest length at a new batch (count=1)", "\n", "if", "count", "==", "1", ":", "\n", "        ", "max_src_in_batch", "=", "0", "\n", "max_tgt_in_batch", "=", "0", "\n", "# Src: [<bos> w1 ... wN <eos>]", "\n", "", "if", "hasattr", "(", "new", ",", "'src'", ")", ":", "\n", "        ", "max_src_in_batch", "=", "max", "(", "max_src_in_batch", ",", "len", "(", "new", ".", "src", "[", "0", "]", ")", "+", "2", ")", "\n", "", "else", ":", "\n", "        ", "max_src_in_batch", "=", "0", "\n", "# Tgt: [w1 ... wM <eos>]", "\n", "", "max_tgt_in_batch", "=", "max", "(", "max_tgt_in_batch", ",", "len", "(", "new", ".", "tgt", "[", "0", "]", ")", "+", "1", ")", "\n", "src_elements", "=", "count", "*", "max_src_in_batch", "\n", "tgt_elements", "=", "count", "*", "max_tgt_in_batch", "\n", "\n", "if", "tgt_only", ":", "\n", "        ", "return", "tgt_elements", "\n", "", "else", ":", "\n", "        ", "return", "max", "(", "src_elements", ",", "tgt_elements", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.build_dataset_iter": [[674, 709], ["list", "inputter.DatasetLazyIter", "sorted", "glob.glob", "functools.partial"], "function", ["None"], ["", "", "def", "build_dataset_iter", "(", "corpus_type", ",", "fields", ",", "opt", ",", "is_train", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    This returns user-defined train/validate data iterator for the trainer\n    to iterate over. We implement simple ordered iterator strategy here,\n    but more sophisticated strategy like curriculum learning is ok too.\n    \"\"\"", "\n", "dataset_paths", "=", "list", "(", "sorted", "(", "\n", "glob", ".", "glob", "(", "opt", ".", "data", "+", "'.'", "+", "corpus_type", "+", "'*.pt'", ")", ")", ")", "\n", "if", "not", "dataset_paths", ":", "\n", "        ", "return", "None", "\n", "", "batch_size", "=", "opt", ".", "batch_size", "if", "is_train", "else", "opt", ".", "valid_batch_size", "\n", "\n", "if", "is_train", "and", "opt", ".", "batch_type", "==", "\"tokens\"", ":", "\n", "        ", "if", "opt", ".", "model_type", "==", "'imgvec'", ":", "\n", "            ", "batch_fn", "=", "partial", "(", "max_tok_len", ",", "tgt_only", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "batch_fn", "=", "max_tok_len", "\n", "", "", "else", ":", "\n", "        ", "batch_fn", "=", "None", "\n", "\n", "", "batch_size_multiple", "=", "8", "if", "opt", ".", "model_dtype", "==", "\"fp16\"", "and", "not", "opt", ".", "force_bs1", "else", "1", "\n", "\n", "device", "=", "\"cuda\"", "if", "opt", ".", "gpu_ranks", "else", "\"cpu\"", "\n", "\n", "return", "DatasetLazyIter", "(", "\n", "dataset_paths", ",", "\n", "fields", ",", "\n", "batch_size", ",", "\n", "batch_fn", ",", "\n", "batch_size_multiple", ",", "\n", "device", ",", "\n", "is_train", ",", "\n", "repeat", "=", "not", "opt", ".", "single_pass", ",", "\n", "num_batches_multiple", "=", "opt", ".", "accum_count", "*", "opt", ".", "world_size", ",", "\n", "count", "=", "opt", ".", "gpt2_params_std", ">", "0", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.datareader_base.DataReaderBase.from_opt": [[19, 28], ["cls"], "methods", ["None"], ["@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Alternative constructor.\n\n        Args:\n            opt (argparse.Namespace): The parsed arguments.\n        \"\"\"", "\n", "\n", "return", "cls", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.datareader_base.DataReaderBase._read_file": [[29, 35], ["open"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_read_file", "(", "cls", ",", "path", ")", ":", "\n", "        ", "\"\"\"Line-by-line read a file as bytes.\"\"\"", "\n", "with", "open", "(", "path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "yield", "line", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.datareader_base.DataReaderBase._raise_missing_dep": [[36, 42], ["datareader_base.MissingDependencyException"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "_raise_missing_dep", "(", "*", "missing_deps", ")", ":", "\n", "        ", "\"\"\"Raise missing dep exception with standard error message.\"\"\"", "\n", "raise", "MissingDependencyException", "(", "\n", "\"Could not create reader. Be sure to install \"", "\n", "\"the following dependencies: \"", "+", "\", \"", ".", "join", "(", "missing_deps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.datareader_base.DataReaderBase.read": [[43, 46], ["NotImplementedError"], "methods", ["None"], ["", "def", "read", "(", "self", ",", "data", ",", "side", ",", "src_dir", ")", ":", "\n", "        ", "\"\"\"Read data from file system and yield as dicts.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.image_vec_dataset.ImageVecDataReader.read": [[18, 35], ["range", "numpy.load", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load"], ["def", "read", "(", "self", ",", "path", ",", "side", ",", "img_dir", "=", "None", ")", ":", "\n", "        ", "\"\"\"Read data into dicts.\n\n        Args:\n            path (str): Path to npy file with saved image vectors\n                The filenames may be relative to ``src_dir``\n                (default behavior) or absolute.\n            side (str): Prefix used in return dict. Usually\n                ``\"src\"`` or ``\"tgt\"``.\n\n        Yields:\n            a dictionary containing image data and index for each line.\n        \"\"\"", "\n", "features", "=", "np", ".", "load", "(", "path", ",", "encoding", "=", "'latin1'", ")", "[", "'vec_list'", "]", "\n", "\n", "for", "i", "in", "range", "(", "features", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "yield", "{", "side", ":", "torch", ".", "tensor", "(", "features", "[", "i", "]", ")", ",", "'indices'", ":", "i", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.image_vec_dataset.img_vec_sort_key": [[36, 39], ["ex.src.size"], "function", ["None"], ["", "", "", "def", "img_vec_sort_key", "(", "ex", ")", ":", "\n", "    ", "\"\"\"Sort using the number of image box features.\"\"\"", "\n", "return", "ex", ".", "src", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.image_vec_dataset.batch_img_vec": [[40, 44], ["torch.stack"], "function", ["None"], ["", "def", "batch_img_vec", "(", "data", ",", "vocab", ")", ":", "\n", "    ", "\"\"\"Batch a sequence of image vectors.\"\"\"", "\n", "imgs", "=", "torch", ".", "stack", "(", "data", ",", "dim", "=", "1", ")", "# [K, B, dim]", "\n", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.image_vec_dataset.image_vec_fields": [[45, 50], ["torchtext.data.Field"], "function", ["None"], ["", "def", "image_vec_fields", "(", "**", "kwargs", ")", ":", "\n", "    ", "img", "=", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "postprocessing", "=", "batch_img_vec", ",", "sequential", "=", "False", ")", "\n", "return", "img", "\n", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.__init__.none_sort": [[22, 24], ["hasattr", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.dataset_base.Dataset.__init__": [[151, 197], ["enumerate", "ex_fields.items", "torchtext.data.Dataset.__init__", "r.read", "len", "itertools.starmap", "torchtext.data.Example.fromdict", "examples.append", "fields.append", "zip", "open", "zip", "dataset_base._dynamic_dict", "dataset_base.Dataset.src_vocabs.append", "len", "line.strip", "fields.items"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioDataReader.read", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.dataset_base._dynamic_dict"], ["def", "__init__", "(", "self", ",", "fields", ",", "readers", ",", "data", ",", "dirs", ",", "sort_key", ",", "\n", "filter_pred", "=", "None", ",", "pointers_file", "=", "None", ")", ":", "\n", "        ", "self", ".", "sort_key", "=", "sort_key", "\n", "can_copy", "=", "'src_map'", "in", "fields", "and", "'alignment'", "in", "fields", "\n", "\n", "read_iters", "=", "[", "r", ".", "read", "(", "dat", "[", "1", "]", ",", "dat", "[", "0", "]", ",", "dir_", ")", "for", "r", ",", "dat", ",", "dir_", "\n", "in", "zip", "(", "readers", "[", ":", "2", "]", ",", "data", "[", ":", "2", "]", ",", "dirs", "[", ":", "2", "]", ")", "]", "\n", "# for the label we can directly read the element", "\n", "if", "len", "(", "readers", ")", "==", "3", ":", "\n", "            ", "read_iters", "+=", "[", "[", "{", "'label'", ":", "i", "}", "for", "i", "in", "data", "[", "2", "]", "[", "1", "]", "]", "]", "\n", "\n", "", "if", "pointers_file", "is", "not", "None", ":", "\n", "            ", "with", "open", "(", "pointers_file", ")", "as", "f", ":", "\n", "                ", "pointers", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", "]", "\n", "\n", "# self.src_vocabs is used in collapse_copy_scores and Translator.py", "\n", "", "", "self", ".", "src_vocabs", "=", "[", "]", "\n", "examples", "=", "[", "]", "\n", "for", "i", ",", "ex_dict", "in", "enumerate", "(", "starmap", "(", "_join_dicts", ",", "zip", "(", "*", "read_iters", ")", ")", ")", ":", "\n", "            ", "if", "can_copy", ":", "\n", "                ", "ex_pointers", "=", "pointers", "[", "i", "]", "if", "pointers_file", "is", "not", "None", "else", "None", "\n", "\n", "src_field", "=", "fields", "[", "'src'", "]", "\n", "tgt_field", "=", "fields", "[", "'tgt'", "]", "\n", "# this assumes src_field and tgt_field are both text", "\n", "src_ex_vocab", ",", "ex_dict", "=", "_dynamic_dict", "(", "\n", "ex_dict", ",", "src_field", ".", "base_field", ",", "tgt_field", ".", "base_field", ",", "\n", "pointers", "=", "ex_pointers", ")", "\n", "self", ".", "src_vocabs", ".", "append", "(", "src_ex_vocab", ")", "\n", "", "ex_fields", "=", "{", "k", ":", "[", "(", "k", ",", "v", ")", "]", "for", "k", ",", "v", "in", "fields", ".", "items", "(", ")", "if", "\n", "k", "in", "ex_dict", "}", "\n", "#print(ex_fields)", "\n", "ex", "=", "Example", ".", "fromdict", "(", "ex_dict", ",", "ex_fields", ")", "\n", "#print(ex.src)", "\n", "#import sys", "\n", "#sys.exit()", "\n", "#print(ex.src_map.shape)", "\n", "examples", ".", "append", "(", "ex", ")", "\n", "\n", "# fields needs to have only keys that examples have as attrs", "\n", "", "fields", "=", "[", "]", "\n", "for", "_", ",", "nf_list", "in", "ex_fields", ".", "items", "(", ")", ":", "\n", "            ", "assert", "len", "(", "nf_list", ")", "==", "1", "\n", "fields", ".", "append", "(", "nf_list", "[", "0", "]", ")", "\n", "\n", "", "super", "(", "Dataset", ",", "self", ")", ".", "__init__", "(", "examples", ",", "fields", ",", "filter_pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.dataset_base.Dataset.__getattr__": [[198, 206], ["vars", "getattr"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "attr", ")", ":", "\n", "# avoid infinite recursion when fields isn't defined", "\n", "        ", "if", "'fields'", "not", "in", "vars", "(", "self", ")", ":", "\n", "            ", "raise", "AttributeError", "\n", "", "if", "attr", "in", "self", ".", "fields", ":", "\n", "            ", "return", "(", "getattr", "(", "x", ",", "attr", ")", "for", "x", "in", "self", ".", "examples", ")", "\n", "", "else", ":", "\n", "            ", "raise", "AttributeError", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.dataset_base.Dataset.save": [[207, 211], ["torch.save"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.save"], ["", "", "def", "save", "(", "self", ",", "path", ",", "remove_fields", "=", "True", ")", ":", "\n", "        ", "if", "remove_fields", ":", "\n", "            ", "self", ".", "fields", "=", "[", "]", "\n", "", "torch", ".", "save", "(", "self", ",", "path", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.dataset_base._join_dicts": [[12, 22], ["dict", "itertools.chain", "d.items"], "function", ["None"], ["def", "_join_dicts", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        dictionaries with disjoint keys.\n\n    Returns:\n        a single dictionary that has the union of these keys.\n    \"\"\"", "\n", "\n", "return", "dict", "(", "chain", "(", "*", "[", "d", ".", "items", "(", ")", "for", "d", "in", "args", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.dataset_base._dynamic_dict": [[24, 97], ["src_field.tokenize", "torchtext.vocab.Vocab", "torch.LongTensor", "collections.Counter", "tgt_field.tokenize", "mask_indices.append", "torch.LongTensor", "pointers.split", "torch.LongTensor", "pointers.split", "torch.zeros().long", "range", "len", "len", "mask_indices.append", "mask_indices.append", "int", "line_tuples.append", "len", "range", "len", "int", "len", "len", "torch.zeros", "torch.zeros().long.size", "len", "entry.split", "pointer.split", "torch.zeros().long.size", "torch.zeros().long.size", "enumerate"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.tokenize", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.tokenize"], ["", "def", "_dynamic_dict", "(", "example", ",", "src_field", ",", "tgt_field", ",", "pointers", "=", "None", ")", ":", "\n", "    ", "\"\"\"Create copy-vocab and numericalize with it.\n\n    In-place adds ``\"src_map\"`` to ``example``. That is the copy-vocab\n    numericalization of the tokenized ``example[\"src\"]``. If ``example``\n    has a ``\"tgt\"`` key, adds ``\"alignment\"`` to example. That is the\n    copy-vocab numericalization of the tokenized ``example[\"tgt\"]``. The\n    alignment has an initial and final UNK token to match the BOS and EOS\n    tokens.\n\n    Args:\n        example (dict): An example dictionary with a ``\"src\"`` key and\n            maybe a ``\"tgt\"`` key. (This argument changes in place!)\n        src_field (torchtext.data.Field): Field object.\n        tgt_field (torchtext.data.Field): Field object.\n\n    Returns:\n        torchtext.data.Vocab and ``example``, changed as described.\n    \"\"\"", "\n", "\n", "src", "=", "src_field", ".", "tokenize", "(", "example", "[", "\"src\"", "]", ")", "\n", "# make a small vocab containing just the tokens in the source sequence", "\n", "unk", "=", "src_field", ".", "unk_token", "\n", "pad", "=", "src_field", ".", "pad_token", "\n", "src_ex_vocab", "=", "Vocab", "(", "Counter", "(", "src", ")", ",", "specials", "=", "[", "unk", ",", "pad", "]", ")", "\n", "unk_idx", "=", "src_ex_vocab", ".", "stoi", "[", "unk", "]", "\n", "# Map source tokens to indices in the dynamic dict.", "\n", "src_map", "=", "torch", ".", "LongTensor", "(", "[", "src_ex_vocab", ".", "stoi", "[", "w", "]", "for", "w", "in", "src", "]", ")", "\n", "example", "[", "\"src_map\"", "]", "=", "src_map", "\n", "\n", "if", "\"tgt\"", "in", "example", ":", "\n", "        ", "tgt", "=", "tgt_field", ".", "tokenize", "(", "example", "[", "\"tgt\"", "]", ")", "\n", "\n", "# Needed because src_ex_vocab does not have a default_factory if unk is", "\n", "# not exactly <unk>, for some reason...", "\n", "mask_indices", "=", "[", "unk_idx", "]", "\n", "for", "w", "in", "tgt", ":", "\n", "            ", "if", "w", "in", "src_ex_vocab", ".", "stoi", ":", "\n", "                ", "mask_indices", ".", "append", "(", "src_ex_vocab", ".", "stoi", "[", "w", "]", ")", "\n", "", "else", ":", "\n", "                ", "mask_indices", ".", "append", "(", "unk_idx", ")", "\n", "", "", "mask_indices", ".", "append", "(", "unk_idx", ")", "\n", "mask", "=", "torch", ".", "LongTensor", "(", "mask_indices", ")", "\n", "#mask = torch.LongTensor(", "\n", "#        [unk_idx] + [src_ex_vocab.stoi[w] for w in tgt] + [unk_idx])", "\n", "example", "[", "\"alignment\"", "]", "=", "mask", "\n", "\n", "if", "pointers", "is", "not", "None", ":", "\n", "            ", "pointer_entries", "=", "pointers", ".", "split", "(", ")", "\n", "pointer_entries", "=", "[", "int", "(", "entry", ".", "split", "(", "\",\"", ")", "[", "0", "]", ")", "for", "entry", "in", "pointer_entries", "]", "\n", "mask", "=", "torch", ".", "LongTensor", "(", "[", "unk_idx", "]", "+", "[", "src_ex_vocab", ".", "stoi", "[", "w", "]", "if", "i", "in", "pointer_entries", "\n", "else", "unk_idx", "for", "i", ",", "w", "in", "enumerate", "(", "tgt", ")", "]", "+", "[", "unk_idx", "]", ")", "\n", "example", "[", "\"alignment\"", "]", "=", "mask", "\n", "max_len", "=", "0", "\n", "line_tuples", "=", "[", "]", "\n", "for", "pointer", "in", "pointers", ".", "split", "(", ")", ":", "\n", "                ", "val", "=", "[", "int", "(", "entry", ")", "for", "entry", "in", "pointer", ".", "split", "(", "\",\"", ")", "]", "\n", "if", "len", "(", "val", ")", ">", "max_len", ":", "\n", "                    ", "max_len", "=", "len", "(", "val", ")", "\n", "", "line_tuples", ".", "append", "(", "val", ")", "\n", "", "num_rows", "=", "len", "(", "line_tuples", ")", "+", "2", "#+2 for storing the length of the source and target sentence", "\n", "ptrs", "=", "torch", ".", "zeros", "(", "num_rows", ",", "max_len", "+", "1", ")", ".", "long", "(", ")", "#last col is for storing the size of the row", "\n", "for", "j", "in", "range", "(", "ptrs", ".", "size", "(", "0", ")", "-", "2", ")", ":", "#iterating until row-1 as row contains the length of the sentence", "\n", "                ", "for", "k", "in", "range", "(", "len", "(", "line_tuples", "[", "j", "]", ")", ")", ":", "\n", "                    ", "ptrs", "[", "j", "]", "[", "k", "]", "=", "line_tuples", "[", "j", "]", "[", "k", "]", "\n", "", "ptrs", "[", "j", "]", "[", "max_len", "]", "=", "len", "(", "line_tuples", "[", "j", "]", ")", "\n", "", "ptrs", "[", "ptrs", ".", "size", "(", "0", ")", "-", "2", "]", "[", "0", "]", "=", "len", "(", "src", ")", "\n", "ptrs", "[", "ptrs", ".", "size", "(", "0", ")", "-", "1", "]", "[", "0", "]", "=", "len", "(", "tgt", ")", "\n", "\n", "example", "[", "\"ptrs\"", "]", "=", "ptrs", "\n", "", "else", ":", "\n", "            ", "example", "[", "\"ptrs\"", "]", "=", "None", "\n", "", "", "return", "src_ex_vocab", ",", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.dataset_base.read_label": [[99, 103], ["open().readlines", "open"], "function", ["None"], ["", "def", "read_label", "(", "file_name", ")", ":", "\n", "    ", "data", "=", "open", "(", "file_name", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "data", "=", "[", "{", "'label'", ":", "i", "}", "for", "i", "in", "data", "]", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioDataReader.__init__": [[38, 47], ["audio_dataset.AudioDataReader._check_deps"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioDataReader._check_deps"], ["def", "__init__", "(", "self", ",", "sample_rate", "=", "0", ",", "window_size", "=", "0", ",", "window_stride", "=", "0", ",", "\n", "window", "=", "None", ",", "normalize_audio", "=", "True", ",", "truncate", "=", "None", ")", ":", "\n", "        ", "self", ".", "_check_deps", "(", ")", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "window_stride", "=", "window_stride", "\n", "self", ".", "window", "=", "window", "\n", "self", ".", "normalize_audio", "=", "normalize_audio", "\n", "self", ".", "truncate", "=", "truncate", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioDataReader.from_opt": [[48, 52], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ")", ":", "\n", "        ", "return", "cls", "(", "sample_rate", "=", "opt", ".", "sample_rate", ",", "window_size", "=", "opt", ".", "window_size", ",", "\n", "window_stride", "=", "opt", ".", "window_stride", ",", "window", "=", "opt", ".", "window", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioDataReader._check_deps": [[53, 58], ["any", "cls._raise_missing_dep"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.datareader_base.DataReaderBase._raise_missing_dep"], ["", "@", "classmethod", "\n", "def", "_check_deps", "(", "cls", ")", ":", "\n", "        ", "if", "any", "(", "[", "torchaudio", "is", "None", ",", "librosa", "is", "None", ",", "np", "is", "None", "]", ")", ":", "\n", "            ", "cls", ".", "_raise_missing_dep", "(", "\n", "\"torchaudio\"", ",", "\"librosa\"", ",", "\"numpy\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioDataReader.extract_features": [[59, 95], ["torchaudio.legacy.load", "sound.mean.mean.numpy", "int", "int", "librosa.stft", "librosa.magphase", "np.log1p", "torch.FloatTensor", "len", "torch.FloatTensor.mean", "torch.FloatTensor.std", "torch.FloatTensor.add_", "torch.FloatTensor.div_", "sound.mean.mean.size", "sound.mean.mean.squeeze", "sound.mean.mean.mean"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "", "def", "extract_features", "(", "self", ",", "audio_path", ")", ":", "\n", "# torchaudio loading options recently changed. It's probably", "\n", "# straightforward to rewrite the audio handling to make use of", "\n", "# up-to-date torchaudio, but in the meantime there is a legacy", "\n", "# method which uses the old defaults", "\n", "        ", "sound", ",", "sample_rate_", "=", "torchaudio", ".", "legacy", ".", "load", "(", "audio_path", ")", "\n", "if", "self", ".", "truncate", "and", "self", ".", "truncate", ">", "0", ":", "\n", "            ", "if", "sound", ".", "size", "(", "0", ")", ">", "self", ".", "truncate", ":", "\n", "                ", "sound", "=", "sound", "[", ":", "self", ".", "truncate", "]", "\n", "\n", "", "", "assert", "sample_rate_", "==", "self", ".", "sample_rate", ",", "'Sample rate of %s != -sample_rate (%d vs %d)'", "%", "(", "audio_path", ",", "sample_rate_", ",", "self", ".", "sample_rate", ")", "\n", "\n", "sound", "=", "sound", ".", "numpy", "(", ")", "\n", "if", "len", "(", "sound", ".", "shape", ")", ">", "1", ":", "\n", "            ", "if", "sound", ".", "shape", "[", "1", "]", "==", "1", ":", "\n", "                ", "sound", "=", "sound", ".", "squeeze", "(", ")", "\n", "", "else", ":", "\n", "                ", "sound", "=", "sound", ".", "mean", "(", "axis", "=", "1", ")", "# average multiple channels", "\n", "\n", "", "", "n_fft", "=", "int", "(", "self", ".", "sample_rate", "*", "self", ".", "window_size", ")", "\n", "win_length", "=", "n_fft", "\n", "hop_length", "=", "int", "(", "self", ".", "sample_rate", "*", "self", ".", "window_stride", ")", "\n", "# STFT", "\n", "d", "=", "librosa", ".", "stft", "(", "sound", ",", "n_fft", "=", "n_fft", ",", "hop_length", "=", "hop_length", ",", "\n", "win_length", "=", "win_length", ",", "window", "=", "self", ".", "window", ")", "\n", "spect", ",", "_", "=", "librosa", ".", "magphase", "(", "d", ")", "\n", "spect", "=", "np", ".", "log1p", "(", "spect", ")", "\n", "spect", "=", "torch", ".", "FloatTensor", "(", "spect", ")", "\n", "if", "self", ".", "normalize_audio", ":", "\n", "            ", "mean", "=", "spect", ".", "mean", "(", ")", "\n", "std", "=", "spect", ".", "std", "(", ")", "\n", "spect", ".", "add_", "(", "-", "mean", ")", "\n", "spect", ".", "div_", "(", "std", ")", "\n", "", "return", "spect", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioDataReader.read": [[96, 129], ["isinstance", "enumerate", "os.path.exists", "onmt.inputters.datareader_base.DataReaderBase._read_file", "tqdm.tqdm.tqdm", "line.decode().strip.decode().strip.decode().strip", "os.path.join", "os.path.exists", "audio_dataset.AudioDataReader.extract_features", "os.path.exists", "line.decode().strip.decode().strip.decode"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.datareader_base.DataReaderBase._read_file", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioDataReader.extract_features"], ["", "def", "read", "(", "self", ",", "data", ",", "side", ",", "src_dir", "=", "None", ")", ":", "\n", "        ", "\"\"\"Read data into dicts.\n\n        Args:\n            data (str or Iterable[str]): Sequence of audio paths or\n                path to file containing audio paths.\n                In either case, the filenames may be relative to ``src_dir``\n                (default behavior) or absolute.\n            side (str): Prefix used in return dict. Usually\n                ``\"src\"`` or ``\"tgt\"``.\n            src_dir (str): Location of source audio files. See ``data``.\n\n        Yields:\n            A dictionary containing audio data for each line.\n        \"\"\"", "\n", "\n", "assert", "src_dir", "is", "not", "None", "and", "os", ".", "path", ".", "exists", "(", "src_dir", ")", ",", "\"src_dir must be a valid directory if data_type is audio\"", "\n", "\n", "if", "isinstance", "(", "data", ",", "str", ")", ":", "\n", "            ", "data", "=", "DataReaderBase", ".", "_read_file", "(", "data", ")", "\n", "\n", "", "for", "i", ",", "line", "in", "enumerate", "(", "tqdm", "(", "data", ")", ")", ":", "\n", "            ", "line", "=", "line", ".", "decode", "(", "\"utf-8\"", ")", ".", "strip", "(", ")", "\n", "audio_path", "=", "os", ".", "path", ".", "join", "(", "src_dir", ",", "line", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "audio_path", ")", ":", "\n", "                ", "audio_path", "=", "line", "\n", "\n", "", "assert", "os", ".", "path", ".", "exists", "(", "audio_path", ")", ",", "'audio path %s not found'", "%", "line", "\n", "\n", "spect", "=", "self", ".", "extract_features", "(", "audio_path", ")", "\n", "yield", "{", "side", ":", "spect", ",", "side", "+", "'_path'", ":", "line", ",", "'indices'", ":", "i", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioSeqField.__init__": [[142, 153], ["torchtext.data.Field.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "preprocessing", "=", "None", ",", "postprocessing", "=", "None", ",", "\n", "include_lengths", "=", "False", ",", "batch_first", "=", "False", ",", "pad_index", "=", "0", ",", "\n", "is_target", "=", "False", ")", ":", "\n", "        ", "super", "(", "AudioSeqField", ",", "self", ")", ".", "__init__", "(", "\n", "sequential", "=", "True", ",", "use_vocab", "=", "False", ",", "init_token", "=", "None", ",", "\n", "eos_token", "=", "None", ",", "fix_length", "=", "False", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "preprocessing", "=", "preprocessing", ",", "postprocessing", "=", "postprocessing", ",", "\n", "lower", "=", "False", ",", "tokenize", "=", "None", ",", "include_lengths", "=", "include_lengths", ",", "\n", "batch_first", "=", "batch_first", ",", "pad_token", "=", "pad_index", ",", "unk_token", "=", "None", ",", "\n", "pad_first", "=", "False", ",", "truncate_first", "=", "False", ",", "stop_words", "=", "None", ",", "\n", "is_target", "=", "is_target", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioSeqField.pad": [[155, 181], ["list", "max", "minibatch[].size", "torch.full", "enumerate", "x.size", "zip", "len"], "methods", ["None"], ["", "def", "pad", "(", "self", ",", "minibatch", ")", ":", "\n", "        ", "\"\"\"Pad a batch of examples to the length of the longest example.\n\n        Args:\n            minibatch (List[torch.FloatTensor]): A list of audio data,\n                each having shape 1 x n_feats x len where len is variable.\n\n        Returns:\n            torch.FloatTensor or Tuple[torch.FloatTensor, List[int]]: The\n                padded tensor of shape ``(batch_size, 1, n_feats, max_len)``.\n                and a list of the lengths if `self.include_lengths` is `True`\n                else just returns the padded tensor.\n        \"\"\"", "\n", "\n", "assert", "not", "self", ".", "pad_first", "and", "not", "self", ".", "truncate_first", "and", "not", "self", ".", "fix_length", "and", "self", ".", "sequential", "\n", "minibatch", "=", "list", "(", "minibatch", ")", "\n", "lengths", "=", "[", "x", ".", "size", "(", "1", ")", "for", "x", "in", "minibatch", "]", "\n", "max_len", "=", "max", "(", "lengths", ")", "\n", "nfft", "=", "minibatch", "[", "0", "]", ".", "size", "(", "0", ")", "\n", "sounds", "=", "torch", ".", "full", "(", "(", "len", "(", "minibatch", ")", ",", "1", ",", "nfft", ",", "max_len", ")", ",", "self", ".", "pad_token", ")", "\n", "for", "i", ",", "(", "spect", ",", "len_", ")", "in", "enumerate", "(", "zip", "(", "minibatch", ",", "lengths", ")", ")", ":", "\n", "            ", "sounds", "[", "i", ",", ":", ",", ":", ",", "0", ":", "len_", "]", "=", "spect", "\n", "", "if", "self", ".", "include_lengths", ":", "\n", "            ", "return", "(", "sounds", ",", "lengths", ")", "\n", "", "return", "sounds", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioSeqField.numericalize": [[182, 218], ["isinstance", "arr.contiguous.contiguous.to", "ValueError", "torch.tensor", "audio_dataset.AudioSeqField.postprocessing", "arr.contiguous.contiguous.permute", "arr.contiguous.contiguous.contiguous", "isinstance"], "methods", ["None"], ["", "def", "numericalize", "(", "self", ",", "arr", ",", "device", "=", "None", ")", ":", "\n", "        ", "\"\"\"Turn a batch of examples that use this field into a Variable.\n\n        If the field has ``include_lengths=True``, a tensor of lengths will be\n        included in the return value.\n\n        Args:\n            arr (torch.FloatTensor or Tuple(torch.FloatTensor, List[int])):\n                List of tokenized and padded examples, or tuple of List of\n                tokenized and padded examples and List of lengths of each\n                example if self.include_lengths is True. Examples have shape\n                ``(batch_size, 1, n_feats, max_len)`` if `self.batch_first`\n                else ``(max_len, batch_size, 1, n_feats)``.\n            device (str or torch.device): See `Field.numericalize`.\n        \"\"\"", "\n", "\n", "assert", "self", ".", "use_vocab", "is", "False", "\n", "if", "self", ".", "include_lengths", "and", "not", "isinstance", "(", "arr", ",", "tuple", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Field has include_lengths set to True, but \"", "\n", "\"input data is not a tuple of \"", "\n", "\"(data batch, batch lengths).\"", ")", "\n", "", "if", "isinstance", "(", "arr", ",", "tuple", ")", ":", "\n", "            ", "arr", ",", "lengths", "=", "arr", "\n", "lengths", "=", "torch", ".", "tensor", "(", "lengths", ",", "dtype", "=", "torch", ".", "int", ",", "device", "=", "device", ")", "\n", "\n", "", "if", "self", ".", "postprocessing", "is", "not", "None", ":", "\n", "            ", "arr", "=", "self", ".", "postprocessing", "(", "arr", ",", "None", ")", "\n", "\n", "", "if", "self", ".", "sequential", "and", "not", "self", ".", "batch_first", ":", "\n", "            ", "arr", "=", "arr", ".", "permute", "(", "3", ",", "0", ",", "1", ",", "2", ")", "\n", "", "if", "self", ".", "sequential", ":", "\n", "            ", "arr", "=", "arr", ".", "contiguous", "(", ")", "\n", "", "arr", "=", "arr", ".", "to", "(", "device", ")", "\n", "if", "self", ".", "include_lengths", ":", "\n", "            ", "return", "arr", ",", "lengths", "\n", "", "return", "arr", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.audio_sort_key": [[131, 134], ["ex.src.size"], "function", ["None"], ["", "", "", "def", "audio_sort_key", "(", "ex", ")", ":", "\n", "    ", "\"\"\"Sort using duration time of the sound spectrogram.\"\"\"", "\n", "return", "ex", ".", "src", ".", "size", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.audio_fields": [[220, 223], ["audio_dataset.AudioSeqField"], "function", ["None"], ["", "", "def", "audio_fields", "(", "**", "kwargs", ")", ":", "\n", "    ", "audio", "=", "AudioSeqField", "(", "pad_index", "=", "0", ",", "batch_first", "=", "True", ",", "include_lengths", "=", "True", ")", "\n", "return", "audio", "\n", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.util_class.Elementwise.__init__": [[18, 22], ["torch.ModuleList.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "merge", "=", "None", ",", "*", "args", ")", ":", "\n", "        ", "assert", "merge", "in", "[", "None", ",", "'first'", ",", "'concat'", ",", "'sum'", ",", "'mlp'", "]", "\n", "self", ".", "merge", "=", "merge", "\n", "super", "(", "Elementwise", ",", "self", ")", ".", "__init__", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.util_class.Elementwise.forward": [[23, 35], ["feat.squeeze", "len", "len", "f", "inputs.split", "zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sum"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "inputs_", "=", "[", "feat", ".", "squeeze", "(", "2", ")", "for", "feat", "in", "inputs", ".", "split", "(", "1", ",", "dim", "=", "2", ")", "]", "\n", "assert", "len", "(", "self", ")", "==", "len", "(", "inputs_", ")", "\n", "outputs", "=", "[", "f", "(", "x", ")", "for", "f", ",", "x", "in", "zip", "(", "self", ",", "inputs_", ")", "]", "\n", "if", "self", ".", "merge", "==", "'first'", ":", "\n", "            ", "return", "outputs", "[", "0", "]", "\n", "", "elif", "self", ".", "merge", "==", "'concat'", "or", "self", ".", "merge", "==", "'mlp'", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "outputs", ",", "2", ")", "\n", "", "elif", "self", ".", "merge", "==", "'sum'", ":", "\n", "            ", "return", "sum", "(", "outputs", ")", "\n", "", "else", ":", "\n", "            ", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.util_class.Cast.__init__": [[43, 46], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "dtype", ")", ":", "\n", "        ", "super", "(", "Cast", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_dtype", "=", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.util_class.Cast.forward": [[47, 49], ["x.to"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", ".", "to", "(", "self", ".", "_dtype", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.SequenceSummary.__init__": [[12, 18], ["torch.Module.__init__", "torch.Tanh", "torch.Tanh", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["     ", "def", "__init__", "(", "self", ",", "hidden_size", "=", "768", ",", "num_labels", "=", "2", ",", "dropout_ratio", "=", "0.1", ")", ":", "\n", "         ", "super", "(", "SequenceSummary", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "act", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout_ratio", ")", "\n", "self", ".", "clf_head", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "num_labels", ")", "\n", "self", ".", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "", "def", "forward", "(", "self", ",", "labels", "=", "None", ",", "hidden", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.SequenceSummary.forward": [[18, 27], ["clsAttention.SequenceSummary.clf_head", "clsAttention.SequenceSummary.act", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "clsAttention.SequenceSummary.loss_fn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "labels", "=", "None", ",", "hidden", "=", "None", ")", ":", "\n", "         ", "hidden", "=", "self", ".", "clf_head", "(", "hidden", ")", "\n", "hidden", "=", "self", ".", "act", "(", "hidden", ")", "\n", "if", "labels", "is", "None", ":", "\n", "            ", "predict", "=", "torch", ".", "argmax", "(", "hidden", ",", "dim", "=", "-", "1", ")", "\n", "return", "predict", "\n", "", "else", ":", "\n", "            ", "loss", "=", "self", ".", "loss_fn", "(", "hidden", ",", "labels", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.FactReconstructor.__init__": [[30, 38], ["torch.Module.__init__", "transformers.BertConfig", "transformers.BertForMaskedLM", "clsAttention.FactReconstructor.bert.get_input_embeddings", "clsAttention.FactReconstructor.bert.set_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "word_embedding", "=", "None", ")", ":", "\n", "        ", "super", "(", "FactReconstructor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# tiny bert for masked language", "\n", "config", "=", "BertConfig", "(", "num_hidden_layers", "=", "2", ",", "num_attention_heads", "=", "4", ",", "intermediate_size", "=", "256", ",", "pad_token_id", "=", "50163", ",", "vocab_size", "=", "50257", ")", "\n", "self", ".", "bert", "=", "BertForMaskedLM", "(", "config", ")", "\n", "if", "word_embedding", "is", "not", "None", ":", "\n", "            ", "self", ".", "bert", ".", "set_input_embeddings", "(", "word_embedding", ")", "\n", "", "self", ".", "word_embeddings", "=", "self", ".", "bert", ".", "get_input_embeddings", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.FactReconstructor.forward": [[40, 66], ["torch.transpose.squeeze_", "torch.transpose.squeeze_", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "clsAttention.FactReconstructor.word_embeddings", "torch.where", "torch.where", "torch.where", "torch.where", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.ones_like().float", "torch.ones_like().float", "torch.ones_like().float", "torch.ones_like().float", "torch.zeros_like().float", "torch.zeros_like().float", "torch.zeros_like().float", "torch.zeros_like().float", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "cls_hidden.unsqueeze.unsqueeze.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "clsAttention.FactReconstructor.bert", "torch.transpose.new_ones", "torch.transpose.new_ones", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.cat.new_ones", "torch.cat.new_ones", "torch.cat.new_ones", "torch.cat.new_ones", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "cls_hidden", "=", "None", ")", ":", "\n", "# other_hidden_list batch_size * k * 30", "\n", "# mask several tokens from the encoder", "\n", "# TODO: mask the name entity", "\n", "# padding_idx 50163, unkown_index 49968", "\n", "        ", "input_ids", ".", "squeeze_", "(", "-", "1", ")", "\n", "input_ids", "=", "torch", ".", "transpose", "(", "input_ids", ",", "1", ",", "0", ")", "\n", "not_include_mask", "=", "torch", ".", "where", "(", "(", "input_ids", "==", "50163", ")", "*", "(", "input_ids", "==", "49968", ")", ",", "torch", ".", "ones_like", "(", "input_ids", ")", ",", "torch", ".", "zeros_like", "(", "input_ids", ")", ")", "\n", "\n", "mask_prob", "=", "(", "torch", ".", "FloatTensor", "(", "input_ids", ".", "shape", ")", ".", "uniform_", "(", ")", ">", "0.8", ")", ".", "to", "(", "input_ids", ".", "device", ")", "\n", "# Also Get rid of the padded index", "\n", "attention_mask", "=", "torch", ".", "where", "(", "mask_prob", ",", "torch", ".", "ones_like", "(", "input_ids", ")", ".", "float", "(", ")", ",", "torch", ".", "zeros_like", "(", "input_ids", ")", ".", "float", "(", ")", ")", "\n", "attention_mask", "=", "torch", ".", "where", "(", "not_include_mask", "==", "1", ",", "torch", ".", "zeros_like", "(", "attention_mask", ")", ",", "attention_mask", ")", "\n", "\n", "input_embeddings", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "masked_lm_labels", "=", "torch", ".", "where", "(", "attention_mask", ">", "0", ",", "input_ids", ",", "input_ids", ".", "new_ones", "(", "input_ids", ".", "shape", ")", "*", "-", "100", ")", "\n", "if", "cls_hidden", "is", "not", "None", ":", "\n", "            ", "cls_hidden", "=", "cls_hidden", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "input_embeddings", "=", "torch", ".", "cat", "(", "[", "cls_hidden", ",", "input_embeddings", "]", ",", "dim", "=", "1", ")", "\n", "attention_mask", "=", "torch", ".", "cat", "(", "[", "attention_mask", ".", "new_ones", "(", "attention_mask", ".", "shape", "[", "0", "]", ",", "1", ")", ",", "attention_mask", "]", ",", "dim", "=", "1", ")", "\n", "masked_lm_labels", "=", "torch", ".", "cat", "(", "\n", "[", "masked_lm_labels", ".", "new_ones", "(", "masked_lm_labels", ".", "shape", "[", "0", "]", ",", "1", ")", "*", "-", "100", ",", "masked_lm_labels", "]", ",", "dim", "=", "1", ")", "\n", "\n", "\n", "", "return", "self", ".", "bert", "(", "inputs_embeds", "=", "input_embeddings", ",", "attention_mask", "=", "attention_mask", ",", "masked_lm_labels", "=", "masked_lm_labels", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsDataset.__init__": [[70, 88], ["os.path.exists", "torch.load", "torch.load", "torch.load", "torch.load", "transformers.GPT2Tokenizer.from_pretrained", "torch.save", "torch.save", "torch.save", "torch.save", "pandas.read_csv", "data[].values.tolist", "open().readlines", "i.strip", "transformers.GPT2Tokenizer.from_pretrained.encode", "open", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.save"], ["    ", "def", "__init__", "(", "self", ",", "file_path", ",", "overwrite_cache", "=", "False", ")", ":", "\n", "        ", "catched_path", "=", "file_path", "+", "\".torch\"", "\n", "if", "os", ".", "path", ".", "exists", "(", "catched_path", ")", "and", "overwrite_cache", "is", "False", ":", "\n", "            ", "self", ".", "example", "=", "torch", ".", "load", "(", "catched_path", ")", "\n", "", "else", ":", "\n", "            ", "tokenizer", "=", "GPT2Tokenizer", ".", "from_pretrained", "(", "\"gpt2\"", ")", "\n", "if", "\"tsv\"", "in", "file_path", ":", "\n", "                ", "data", "=", "pd", ".", "read_csv", "(", "file_path", ",", "sep", "=", "\"\\t\"", ")", "\n", "data", "=", "data", "[", "'title'", "]", ".", "values", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "                ", "data", "=", "open", "(", "file_path", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "", "data", "=", "[", "i", ".", "strip", "(", ")", "for", "i", "in", "data", "]", "\n", "data", "=", "[", "tokenizer", ".", "encode", "(", "i", ")", "for", "i", "in", "data", "]", "\n", "# pad idx is 50163", "\n", "data", "=", "[", "i", "[", ":", "100", "]", "if", "len", "(", "i", ")", ">", "100", "else", "i", "+", "[", "50163", "]", "*", "(", "100", "-", "len", "(", "i", ")", ")", "for", "i", "in", "data", "]", "\n", "self", ".", "example", "=", "data", "\n", "torch", ".", "save", "(", "\n", "data", ",", "catched_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsDataset.__len__": [[89, 91], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsDataset.__getitem__": [[92, 94], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "self", ".", "example", "[", "item", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.__init__": [[98, 104], ["pytorch_lightning.LightningModule.__init__", "clsAttention.FactReconstructor"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "super", "(", "clsAttenTrain", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hparams", "=", "hparams", "\n", "# cache_dir = self.hparams.cache_dir if self.hparams.cache_dir else None", "\n", "# load the vocab file from the encoder and the embeddings from other file", "\n", "self", ".", "model", "=", "FactReconstructor", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.forward": [[105, 107], ["clsAttention.clsAttenTrain.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ")", ":", "\n", "        ", "return", "self", ".", "model", "(", "input_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.training_step": [[108, 112], ["clsAttention.clsAttenTrain."], "methods", ["None"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "loss", "=", "self", "(", "batch", ")", "\n", "tensorboard_logs", "=", "{", "\"train_loss\"", ":", "loss", "}", "\n", "return", "{", "\"loss\"", ":", "loss", ",", "\"log\"", ":", "tensorboard_logs", "}", "\n", "", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.validation_step": [[112, 115], ["clsAttention.clsAttenTrain."], "methods", ["None"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "loss", "=", "self", "(", "batch", ")", "\n", "return", "{", "\"val_loss\"", ":", "loss", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.validation_end": [[116, 120], ["torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "validation_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "avg_loss", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"val_loss\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "tensorboard_logs", "=", "{", "\"val_loss\"", ":", "avg_loss", "}", "\n", "return", "{", "\"avg_val_loss\"", ":", "avg_loss", ",", "\"log\"", ":", "tensorboard_logs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.load_dataset": [[121, 133], ["clsAttention.clsAttenTrain.hparams.file_path.format", "clsAttention.clsDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "load_dataset", "(", "self", ",", "type", ",", "batch_size", ")", ":", "\n", "        ", "if", "type", "==", "\"trian\"", ":", "\n", "            ", "shuffle", "=", "True", "\n", "", "else", ":", "\n", "            ", "shuffle", "=", "False", "\n", "\n", "", "file_path", "=", "self", ".", "hparams", ".", "file_path", ".", "format", "(", "type", ")", "\n", "\n", "dataset", "=", "clsDataset", "(", "file_path", ")", "\n", "data_loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "shuffle", ")", "\n", "\n", "return", "data_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.configure_optimizers": [[135, 151], ["transformers.AdamW", "model.named_parameters", "model.named_parameters", "any", "any"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "model", "=", "self", ".", "model", "\n", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "self", ".", "hparams", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "self", ".", "hparams", ".", "learning_rate", ",", "eps", "=", "self", ".", "hparams", ".", "adam_epsilon", ")", "\n", "self", ".", "opt", "=", "optimizer", "\n", "return", "[", "optimizer", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.optimizer_step": [[152, 163], ["optimizer.step", "optimizer.zero_grad", "clsAttention.clsAttenTrain.lr_scheduler.step"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor.step", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.zero_grad", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor.step"], ["", "def", "optimizer_step", "(", "\n", "self", ",", "\n", "epoch", ",", "\n", "batch_idx", ",", "\n", "optimizer", ",", "\n", "optimizer_idx", ",", "\n", "second_order_closure", "=", "None", ",", "\n", ")", ":", "\n", "        ", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.get_tqdm_dict": [[164, 168], ["getattr", "clsAttention.clsAttenTrain.lr_scheduler.get_last_lr"], "methods", ["None"], ["", "def", "get_tqdm_dict", "(", "self", ")", ":", "\n", "        ", "avg_loss", "=", "getattr", "(", "self", ".", "trainer", ",", "\"avg_loss\"", ",", "0.0", ")", "\n", "tqdm_dict", "=", "{", "\"loss\"", ":", "\"{:.3f}\"", ".", "format", "(", "avg_loss", ")", ",", "\"lr\"", ":", "self", ".", "lr_scheduler", ".", "get_last_lr", "(", ")", "[", "-", "1", "]", "}", "\n", "return", "tqdm_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.test_step": [[169, 171], ["clsAttention.clsAttenTrain.validation_step"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.validation_step"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "return", "self", ".", "validation_step", "(", "batch", ",", "batch_nb", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.test_end": [[172, 174], ["clsAttention.clsAttenTrain.validation_end"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.validation_end"], ["", "def", "test_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "return", "self", ".", "validation_end", "(", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.train_dataloader": [[175, 189], ["clsAttention.clsAttenTrain.load_dataset", "transformers.get_linear_schedule_with_warmup", "float", "len", "max"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.load_dataset"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "train_batch_size", "=", "self", ".", "hparams", ".", "train_batch_size", "\n", "dataloader", "=", "self", ".", "load_dataset", "(", "\"train\"", ",", "train_batch_size", ")", "\n", "\n", "t_total", "=", "(", "\n", "(", "len", "(", "dataloader", ".", "dataset", ")", "//", "(", "train_batch_size", "*", "max", "(", "1", ",", "self", ".", "hparams", ".", "n_gpu", ")", ")", ")", "\n", "//", "self", ".", "hparams", ".", "gradient_accumulation_steps", "\n", "*", "float", "(", "self", ".", "hparams", ".", "num_train_epochs", ")", "\n", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "self", ".", "opt", ",", "num_warmup_steps", "=", "self", ".", "hparams", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "self", ".", "lr_scheduler", "=", "scheduler", "\n", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.val_dataloader": [[190, 192], ["clsAttention.clsAttenTrain.load_dataset"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.load_dataset"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "load_dataset", "(", "\"val\"", ",", "self", ".", "hparams", ".", "eval_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.test_dataloader": [[193, 195], ["clsAttention.clsAttenTrain.load_dataset"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.load_dataset"], ["", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "load_dataset", "(", "\"test\"", ",", "self", ".", "hparams", ".", "eval_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain._feature_file": [[196, 203], ["os.path.join", "list().pop", "str", "list", "filter", "clsAttention.clsAttenTrain.hparams.model_name_or_path.split"], "methods", ["None"], ["", "def", "_feature_file", "(", "self", ",", "mode", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "hparams", ".", "data_dir", ",", "\n", "\"cached_{}_{}_{}\"", ".", "format", "(", "\n", "mode", ",", "\n", "list", "(", "filter", "(", "None", ",", "self", ".", "hparams", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "self", ".", "hparams", ".", "max_seq_length", ")", ",", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.clsAttenTrain.add_model_specific_args": [[206, 246], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parser", ",", "root_dir", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "\"fact_clf\"", ",", "\n", "type", "=", "str", ",", "\n", "# required=True,", "\n", "help", "=", "\"Path to pretrained model or model identifier from huggingface.co/models\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--file_path\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite_cache\"", ",", "action", "=", "'store_true'", ")", "\n", "\n", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "1e-4", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "1000", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "\"Total number of training epochs to perform.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--train_batch_size\"", ",", "default", "=", "100", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_batch_size\"", ",", "default", "=", "100", ",", "type", "=", "int", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.add_generic_args": [[249, 284], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "", "def", "add_generic_args", "(", "parser", ",", "root_dir", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "type", "=", "str", ",", "\n", "# required=True,", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--n_gpu\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_tpu_cores\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_predict\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run predictions on the test set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "3", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"-seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.generic_train": [[287, 319], ["pytorch_lightning.callbacks.ModelCheckpoint", "dict", "pytorch_lightning.Trainer", "pl.Trainer.fit"], "function", ["None"], ["", "def", "generic_train", "(", "model", ",", "args", ")", ":", "\n", "# init model", "\n", "#", "\n", "# if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train:", "\n", "#     raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(args.output_dir))", "\n", "\n", "    ", "checkpoint_callback", "=", "pl", ".", "callbacks", ".", "ModelCheckpoint", "(", "\n", "filepath", "=", "args", ".", "output_dir", ",", "prefix", "=", "\"checkpoint\"", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", "\n", ")", "\n", "\n", "train_params", "=", "dict", "(", "\n", "accumulate_grad_batches", "=", "args", ".", "gradient_accumulation_steps", ",", "\n", "gpus", "=", "args", ".", "n_gpu", ",", "\n", "max_epochs", "=", "args", ".", "num_train_epochs", ",", "\n", "early_stop_callback", "=", "False", ",", "\n", "gradient_clip_val", "=", "args", ".", "max_grad_norm", ",", "\n", "checkpoint_callback", "=", "checkpoint_callback", "\n", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "train_params", "[", "\"use_amp\"", "]", "=", "args", ".", "fp16", "\n", "train_params", "[", "\"amp_level\"", "]", "=", "args", ".", "fp16_opt_level", "\n", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "train_params", "[", "\"distributed_backend\"", "]", "=", "\"ddp\"", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "**", "train_params", ")", "\n", "\n", "# if args.do_train:", "\n", "trainer", ".", "fit", "(", "model", ")", "\n", "\n", "return", "trainer", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.trainFactReconstructor": [[321, 327], ["clsAttention.clsAttenTrain", "clsAttention.generic_train", "os.path.join", "os.makedirs", "time.strftime"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.clsAttention.generic_train"], ["", "def", "trainFactReconstructor", "(", "args", ")", ":", "\n", "    ", "if", "not", "args", ".", "output_dir", ":", "\n", "        ", "args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "\"./results\"", ",", "f\"{args.task}_{time.strftime('%Y%m%d_%H%M%S')}\"", ",", ")", "\n", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "", "model", "=", "clsAttenTrain", "(", "args", ")", "\n", "trainer", "=", "generic_train", "(", "model", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.conv_multi_step_attention.ConvMultiStepAttention.__init__": [[27, 31], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ")", ":", "\n", "        ", "super", "(", "ConvMultiStepAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear_in", "=", "nn", ".", "Linear", "(", "input_size", ",", "input_size", ")", "\n", "self", ".", "mask", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.conv_multi_step_attention.ConvMultiStepAttention.apply_mask": [[32, 35], ["None"], "methods", ["None"], ["", "def", "apply_mask", "(", "self", ",", "mask", ")", ":", "\n", "        ", "\"\"\" Apply mask \"\"\"", "\n", "self", ".", "mask", "=", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.conv_multi_step_attention.ConvMultiStepAttention.forward": [[36, 81], ["base_target_emb.size", "input_from_dec.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "encoder_out_top.size", "encoder_out_combine.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "conv_multi_step_attention.seq_linear", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.bmm.data.masked_fill_", "torch.bmm.data.masked_fill_", "torch.bmm.data.masked_fill_", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "float"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.conv_multi_step_attention.seq_linear", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "forward", "(", "self", ",", "base_target_emb", ",", "input_from_dec", ",", "encoder_out_top", ",", "\n", "encoder_out_combine", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            base_target_emb: target emb tensor\n            input_from_dec: output of decode conv\n            encoder_out_top: the key matrix for calculation of attetion weight,\n                which is the top output of encode conv\n            encoder_out_combine:\n                the value matrix for the attention-weighted sum,\n                which is the combination of base emb and top output of encode\n        \"\"\"", "\n", "\n", "# checks", "\n", "# batch, channel, height, width = base_target_emb.size()", "\n", "batch", ",", "_", ",", "height", ",", "_", "=", "base_target_emb", ".", "size", "(", ")", "\n", "# batch_, channel_, height_, width_ = input_from_dec.size()", "\n", "batch_", ",", "_", ",", "height_", ",", "_", "=", "input_from_dec", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "height", ",", "height_", ")", "\n", "\n", "# enc_batch, enc_channel, enc_height = encoder_out_top.size()", "\n", "enc_batch", ",", "_", ",", "enc_height", "=", "encoder_out_top", ".", "size", "(", ")", "\n", "# enc_batch_, enc_channel_, enc_height_ = encoder_out_combine.size()", "\n", "enc_batch_", ",", "_", ",", "enc_height_", "=", "encoder_out_combine", ".", "size", "(", ")", "\n", "\n", "aeq", "(", "enc_batch", ",", "enc_batch_", ")", "\n", "aeq", "(", "enc_height", ",", "enc_height_", ")", "\n", "\n", "preatt", "=", "seq_linear", "(", "self", ".", "linear_in", ",", "input_from_dec", ")", "\n", "target", "=", "(", "base_target_emb", "+", "preatt", ")", "*", "SCALE_WEIGHT", "\n", "target", "=", "torch", ".", "squeeze", "(", "target", ",", "3", ")", "\n", "target", "=", "torch", ".", "transpose", "(", "target", ",", "1", ",", "2", ")", "\n", "pre_attn", "=", "torch", ".", "bmm", "(", "target", ",", "encoder_out_top", ")", "\n", "\n", "if", "self", ".", "mask", "is", "not", "None", ":", "\n", "            ", "pre_attn", ".", "data", ".", "masked_fill_", "(", "self", ".", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "", "attn", "=", "F", ".", "softmax", "(", "pre_attn", ",", "dim", "=", "2", ")", "\n", "\n", "context_output", "=", "torch", ".", "bmm", "(", "\n", "attn", ",", "torch", ".", "transpose", "(", "encoder_out_combine", ",", "1", ",", "2", ")", ")", "\n", "context_output", "=", "torch", ".", "transpose", "(", "\n", "torch", ".", "unsqueeze", "(", "context_output", ",", "3", ")", ",", "1", ",", "2", ")", "\n", "return", "context_output", ",", "attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.conv_multi_step_attention.seq_linear": [[11, 17], ["x.size", "linear", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "linear.view", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose", "torch.transpose", "torch.transpose"], "function", ["None"], ["def", "seq_linear", "(", "linear", ",", "x", ")", ":", "\n", "    ", "\"\"\" linear transform for 3-d tensor \"\"\"", "\n", "batch", ",", "hidden_size", ",", "length", ",", "_", "=", "x", ".", "size", "(", ")", "\n", "h", "=", "linear", "(", "torch", ".", "transpose", "(", "x", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "batch", "*", "length", ",", "hidden_size", ")", ")", "\n", "return", "torch", ".", "transpose", "(", "h", ".", "view", "(", "batch", ",", "length", ",", "hidden_size", ",", "1", ")", ",", "1", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.multi_headed_attn.MultiHeadedAttention.__init__": [[52, 77], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "head_count", ",", "model_dim", ",", "dropout", "=", "0.1", ",", "\n", "max_relative_positions", "=", "0", ")", ":", "\n", "        ", "assert", "model_dim", "%", "head_count", "==", "0", "\n", "self", ".", "dim_per_head", "=", "model_dim", "//", "head_count", "\n", "self", ".", "model_dim", "=", "model_dim", "\n", "\n", "super", "(", "MultiHeadedAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "head_count", "=", "head_count", "\n", "\n", "self", ".", "linear_keys", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "linear_values", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "linear_query", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "final_linear", "=", "nn", ".", "Linear", "(", "model_dim", ",", "model_dim", ")", "\n", "\n", "self", ".", "max_relative_positions", "=", "max_relative_positions", "\n", "\n", "if", "max_relative_positions", ">", "0", ":", "\n", "            ", "vocab_size", "=", "max_relative_positions", "*", "2", "+", "1", "\n", "self", ".", "relative_positions_embeddings", "=", "nn", ".", "Embedding", "(", "\n", "vocab_size", ",", "self", ".", "dim_per_head", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.multi_headed_attn.MultiHeadedAttention.forward": [[78, 231], ["shape.size", "shape.size", "multi_headed_attn.MultiHeadedAttention.size", "multi_headed_attn.MultiHeadedAttention.forward.shape"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "key", ",", "value", ",", "query", ",", "mask", "=", "None", ",", "\n", "layer_cache", "=", "None", ",", "type", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Compute the context vector and the attention vectors.\n\n        Args:\n           key (FloatTensor): set of `key_len`\n               key vectors ``(batch, key_len, dim)``\n           value (FloatTensor): set of `key_len`\n               value vectors ``(batch, key_len, dim)``\n           query (FloatTensor): set of `query_len`\n               query vectors  ``(batch, query_len, dim)``\n           mask: binary mask indicating which keys have\n               non-zero attention ``(batch, query_len, key_len)``\n        Returns:\n           (FloatTensor, FloatTensor):\n\n           * output context vectors ``(batch, query_len, dim)``\n           * one of the attention vectors ``(batch, query_len, key_len)``\n        \"\"\"", "\n", "\n", "# CHECKS", "\n", "# batch, k_len, d = key.size()", "\n", "# batch_, k_len_, d_ = value.size()", "\n", "# aeq(batch, batch_)", "\n", "# aeq(k_len, k_len_)", "\n", "# aeq(d, d_)", "\n", "# batch_, q_len, d_ = query.size()", "\n", "# aeq(batch, batch_)", "\n", "# aeq(d, d_)", "\n", "# aeq(self.model_dim % 8, 0)", "\n", "# if mask is not None:", "\n", "#    batch_, q_len_, k_len_ = mask.size()", "\n", "#    aeq(batch_, batch)", "\n", "#    aeq(k_len_, k_len)", "\n", "#    aeq(q_len_ == q_len)", "\n", "# END CHECKS", "\n", "\n", "batch_size", "=", "key", ".", "size", "(", "0", ")", "\n", "dim_per_head", "=", "self", ".", "dim_per_head", "\n", "head_count", "=", "self", ".", "head_count", "\n", "key_len", "=", "key", ".", "size", "(", "1", ")", "\n", "query_len", "=", "query", ".", "size", "(", "1", ")", "\n", "device", "=", "key", ".", "device", "\n", "\n", "def", "shape", "(", "x", ")", ":", "\n", "            ", "\"\"\"Projection.\"\"\"", "\n", "return", "x", ".", "view", "(", "batch_size", ",", "-", "1", ",", "head_count", ",", "dim_per_head", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "def", "unshape", "(", "x", ")", ":", "\n", "            ", "\"\"\"Compute context.\"\"\"", "\n", "return", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ",", "head_count", "*", "dim_per_head", ")", "\n", "\n", "# 1) Project key, value, and query.", "\n", "", "if", "layer_cache", "is", "not", "None", ":", "\n", "            ", "if", "type", "==", "\"self\"", ":", "\n", "                ", "query", ",", "key", ",", "value", "=", "self", ".", "linear_query", "(", "query", ")", ",", "self", ".", "linear_keys", "(", "query", ")", ",", "self", ".", "linear_values", "(", "query", ")", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "if", "layer_cache", "[", "\"self_keys\"", "]", "is", "not", "None", ":", "\n", "                    ", "key", "=", "torch", ".", "cat", "(", "\n", "(", "layer_cache", "[", "\"self_keys\"", "]", ".", "to", "(", "device", ")", ",", "key", ")", ",", "\n", "dim", "=", "2", ")", "\n", "", "if", "layer_cache", "[", "\"self_values\"", "]", "is", "not", "None", ":", "\n", "                    ", "value", "=", "torch", ".", "cat", "(", "\n", "(", "layer_cache", "[", "\"self_values\"", "]", ".", "to", "(", "device", ")", ",", "value", ")", ",", "\n", "dim", "=", "2", ")", "\n", "", "layer_cache", "[", "\"self_keys\"", "]", "=", "key", "\n", "layer_cache", "[", "\"self_values\"", "]", "=", "value", "\n", "", "elif", "type", "==", "\"context\"", ":", "\n", "                ", "query", "=", "self", ".", "linear_query", "(", "query", ")", "\n", "if", "layer_cache", "[", "\"memory_keys\"", "]", "is", "None", ":", "\n", "                    ", "key", ",", "value", "=", "self", ".", "linear_keys", "(", "key", ")", ",", "self", ".", "linear_values", "(", "value", ")", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "", "else", ":", "\n", "                    ", "key", ",", "value", "=", "layer_cache", "[", "\"memory_keys\"", "]", ",", "layer_cache", "[", "\"memory_values\"", "]", "\n", "", "layer_cache", "[", "\"memory_keys\"", "]", "=", "key", "\n", "layer_cache", "[", "\"memory_values\"", "]", "=", "value", "\n", "", "", "else", ":", "\n", "            ", "key", "=", "self", ".", "linear_keys", "(", "key", ")", "\n", "value", "=", "self", ".", "linear_values", "(", "value", ")", "\n", "query", "=", "self", ".", "linear_query", "(", "query", ")", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "\n", "", "if", "self", ".", "max_relative_positions", ">", "0", "and", "type", "==", "\"self\"", ":", "\n", "            ", "key_len", "=", "key", ".", "size", "(", "2", ")", "\n", "# 1 or key_len x key_len", "\n", "relative_positions_matrix", "=", "generate_relative_positions_matrix", "(", "\n", "key_len", ",", "self", ".", "max_relative_positions", ",", "\n", "cache", "=", "True", "if", "layer_cache", "is", "not", "None", "else", "False", ")", "\n", "#  1 or key_len x key_len x dim_per_head", "\n", "relations_keys", "=", "self", ".", "relative_positions_embeddings", "(", "\n", "relative_positions_matrix", ".", "to", "(", "device", ")", ")", "\n", "#  1 or key_len x key_len x dim_per_head", "\n", "relations_values", "=", "self", ".", "relative_positions_embeddings", "(", "\n", "relative_positions_matrix", ".", "to", "(", "device", ")", ")", "\n", "\n", "", "query", "=", "shape", "(", "query", ")", "\n", "\n", "key_len", "=", "key", ".", "size", "(", "2", ")", "\n", "query_len", "=", "query", ".", "size", "(", "2", ")", "\n", "\n", "# 2) Calculate and scale scores.", "\n", "query", "=", "query", "/", "math", ".", "sqrt", "(", "dim_per_head", ")", "\n", "# batch x num_heads x query_len x key_len", "\n", "query_key", "=", "torch", ".", "matmul", "(", "query", ",", "key", ".", "transpose", "(", "2", ",", "3", ")", ")", "\n", "\n", "if", "self", ".", "max_relative_positions", ">", "0", "and", "type", "==", "\"self\"", ":", "\n", "            ", "scores", "=", "query_key", "+", "relative_matmul", "(", "query", ",", "relations_keys", ",", "True", ")", "\n", "", "else", ":", "\n", "            ", "scores", "=", "query_key", "\n", "", "scores", "=", "scores", ".", "float", "(", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "# [B, 1, 1, T_values]", "\n", "scores", "=", "scores", ".", "masked_fill", "(", "mask", ",", "-", "1e18", ")", "\n", "\n", "# 3) Apply attention dropout and compute context vectors.", "\n", "", "attn", "=", "self", ".", "softmax", "(", "scores", ")", ".", "to", "(", "query", ".", "dtype", ")", "\n", "drop_attn", "=", "self", ".", "dropout", "(", "attn", ")", "\n", "\n", "context_original", "=", "torch", ".", "matmul", "(", "drop_attn", ",", "value", ")", "\n", "\n", "if", "self", ".", "max_relative_positions", ">", "0", "and", "type", "==", "\"self\"", ":", "\n", "            ", "context", "=", "unshape", "(", "context_original", "\n", "+", "relative_matmul", "(", "drop_attn", ",", "\n", "relations_values", ",", "\n", "False", ")", ")", "\n", "", "else", ":", "\n", "            ", "context", "=", "unshape", "(", "context_original", ")", "\n", "\n", "", "output", "=", "self", ".", "final_linear", "(", "context", ")", "\n", "# CHECK", "\n", "# batch_, q_len_, d_ = output.size()", "\n", "# aeq(q_len, q_len_)", "\n", "# aeq(batch, batch_)", "\n", "# aeq(d, d_)", "\n", "\n", "# Return one attn", "\n", "top_attn", "=", "attn", ".", "view", "(", "batch_size", ",", "head_count", ",", "\n", "query_len", ",", "key_len", ")", "[", ":", ",", "0", ",", ":", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "\n", "return", "output", ",", "top_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.multi_headed_attn.JointMultiHeadedAttention.__init__": [[272, 306], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.Embedding", "torch.Embedding", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "head_count", ",", "model_dim", ",", "dropout", "=", "0.1", ",", "\n", "max_relative_positions", "=", "0", ",", "ctx_weight_param", "=", "False", ")", ":", "\n", "        ", "assert", "model_dim", "%", "head_count", "==", "0", "\n", "self", ".", "dim_per_head", "=", "model_dim", "//", "head_count", "\n", "self", ".", "model_dim", "=", "model_dim", "\n", "\n", "super", "(", "JointMultiHeadedAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "head_count", "=", "head_count", "\n", "\n", "self", ".", "linear_keys", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "linear_values", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "ctx_linear_keys", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "ctx_linear_values", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "linear_query", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "\n", "if", "ctx_weight_param", ":", "\n", "            ", "self", ".", "ctx_bias", "=", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", "*", "-", "10", ")", "\n", "", "self", ".", "ctx_weight_param", "=", "ctx_weight_param", "\n", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "final_linear", "=", "nn", ".", "Linear", "(", "model_dim", ",", "model_dim", ")", "\n", "\n", "self", ".", "max_relative_positions", "=", "max_relative_positions", "\n", "\n", "if", "max_relative_positions", ">", "0", ":", "\n", "            ", "vocab_size", "=", "max_relative_positions", "*", "2", "+", "1", "\n", "self", ".", "relative_positions_embeddings", "=", "nn", ".", "Embedding", "(", "\n", "vocab_size", ",", "self", ".", "dim_per_head", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.multi_headed_attn.JointMultiHeadedAttention.forward": [[307, 475], ["multi_headed_attn.JointMultiHeadedAttention.size", "multi_headed_attn.JointMultiHeadedAttention.size", "ctx_kv.size", "torch.cat.size", "torch.cat.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "multi_headed_attn.JointMultiHeadedAttention.forward.shape"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "self_kvq", ",", "ctx_kv", ",", "self_mask", "=", "None", ",", "ctx_mask", "=", "None", ",", "\n", "layer_cache", "=", "None", ",", "type", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Compute the context vector and the attention vectors.\n\n        Args:\n           self_kvq (FloatTensor): set of `self_len`\n               key vectors ``(batch, self_len, dim)``\n           ctz_kv (FloatTensor): set of `ctx_len`\n               value vectors ``(batch, ctx_len, dim)``\n           mask: binary mask indicating which keys have\n               non-zero attention ``(batch, self_len, self_len)``\n        Returns:\n           (FloatTensor, FloatTensor):\n\n           * output context vectors ``(batch, self_len, dim)``\n           * one of the attention vectors ``(batch, self_len, ctx_len)``\n        \"\"\"", "\n", "\n", "# CHECKS", "\n", "# batch, k_len, d = key.size()", "\n", "# batch_, k_len_, d_ = value.size()", "\n", "# aeq(batch, batch_)", "\n", "# aeq(k_len, k_len_)", "\n", "# aeq(d, d_)", "\n", "# batch_, q_len, d_ = query.size()", "\n", "# aeq(batch, batch_)", "\n", "# aeq(d, d_)", "\n", "# aeq(self.model_dim % 8, 0)", "\n", "# if mask is not None:", "\n", "#    batch_, q_len_, k_len_ = mask.size()", "\n", "#    aeq(batch_, batch)", "\n", "#    aeq(k_len_, k_len)", "\n", "#    aeq(q_len_ == q_len)", "\n", "# END CHECKS", "\n", "\n", "batch_size", "=", "self_kvq", ".", "size", "(", "0", ")", "\n", "dim_per_head", "=", "self", ".", "dim_per_head", "\n", "head_count", "=", "self", ".", "head_count", "\n", "self_len", "=", "self_kvq", ".", "size", "(", "1", ")", "\n", "ctx_len", "=", "ctx_kv", ".", "size", "(", "1", ")", "\n", "device", "=", "self_kvq", ".", "device", "\n", "\n", "def", "shape", "(", "x", ")", ":", "\n", "            ", "\"\"\"Projection.\"\"\"", "\n", "return", "x", ".", "view", "(", "batch_size", ",", "-", "1", ",", "head_count", ",", "dim_per_head", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "def", "unshape", "(", "x", ")", ":", "\n", "            ", "\"\"\"Compute context.\"\"\"", "\n", "return", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ",", "head_count", "*", "dim_per_head", ")", "\n", "\n", "# 1) Project key, value, and query.", "\n", "", "if", "layer_cache", "is", "not", "None", ":", "\n", "            ", "query", ",", "self_key", ",", "self_value", "=", "self", ".", "linear_query", "(", "self_kvq", ")", ",", "self", ".", "linear_keys", "(", "self_kvq", ")", ",", "self", ".", "linear_values", "(", "self_kvq", ")", "\n", "#self_key = shape(self_key)", "\n", "#self_value = shape(self_value)", "\n", "if", "layer_cache", "[", "\"self_keys\"", "]", "is", "not", "None", ":", "\n", "                ", "self_key", "=", "torch", ".", "cat", "(", "\n", "(", "layer_cache", "[", "\"self_keys\"", "]", ".", "to", "(", "device", ")", ",", "self_key", ")", ",", "\n", "dim", "=", "1", ")", "\n", "", "if", "layer_cache", "[", "\"self_values\"", "]", "is", "not", "None", ":", "\n", "                ", "self_value", "=", "torch", ".", "cat", "(", "\n", "(", "layer_cache", "[", "\"self_values\"", "]", ".", "to", "(", "device", ")", ",", "self_value", ")", ",", "\n", "dim", "=", "1", ")", "\n", "", "layer_cache", "[", "\"self_keys\"", "]", "=", "self_key", "\n", "layer_cache", "[", "\"self_values\"", "]", "=", "self_value", "\n", "\n", "if", "layer_cache", "[", "\"memory_keys\"", "]", "is", "None", ":", "\n", "                ", "ctx_key", "=", "self", ".", "ctx_linear_keys", "(", "ctx_kv", ")", "# [batch, ctx_len, dim]", "\n", "ctx_value", "=", "self", ".", "ctx_linear_values", "(", "ctx_kv", ")", "\n", "layer_cache", "[", "\"memory_keys\"", "]", "=", "ctx_key", "\n", "layer_cache", "[", "\"memory_values\"", "]", "=", "ctx_value", "\n", "", "else", ":", "\n", "                ", "ctx_key", "=", "layer_cache", "[", "\"memory_keys\"", "]", "\n", "ctx_value", "=", "layer_cache", "[", "\"memory_values\"", "]", "\n", "", "", "else", ":", "\n", "            ", "self_key", "=", "self", ".", "linear_keys", "(", "self_kvq", ")", "# [batch, self_len, dim]", "\n", "self_value", "=", "self", ".", "linear_values", "(", "self_kvq", ")", "\n", "query", "=", "self", ".", "linear_query", "(", "self_kvq", ")", "\n", "\n", "ctx_key", "=", "self", ".", "ctx_linear_keys", "(", "ctx_kv", ")", "# [batch, ctx_len, dim]", "\n", "ctx_value", "=", "self", ".", "ctx_linear_values", "(", "ctx_kv", ")", "\n", "\n", "", "self_len", "=", "self_key", ".", "size", "(", "1", ")", "# Need to do this again to include the layer_cache length ", "\n", "ctx_len", "=", "ctx_key", ".", "shape", "[", "1", "]", "\n", "\n", "key", "=", "torch", ".", "cat", "(", "(", "self_key", ",", "ctx_key", ")", ",", "dim", "=", "1", ")", "\n", "value", "=", "torch", ".", "cat", "(", "(", "self_value", ",", "ctx_value", ")", ",", "dim", "=", "1", ")", "\n", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "\n", "if", "self", ".", "max_relative_positions", ">", "0", "and", "type", "==", "\"self\"", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "key_len", "=", "key", ".", "size", "(", "2", ")", "\n", "# 1 or key_len x key_len", "\n", "relative_positions_matrix", "=", "generate_relative_positions_matrix", "(", "\n", "key_len", ",", "self", ".", "max_relative_positions", ",", "\n", "cache", "=", "True", "if", "layer_cache", "is", "not", "None", "else", "False", ")", "\n", "#  1 or key_len x key_len x dim_per_head", "\n", "relations_keys", "=", "self", ".", "relative_positions_embeddings", "(", "\n", "relative_positions_matrix", ".", "to", "(", "device", ")", ")", "\n", "#  1 or key_len x key_len x dim_per_head", "\n", "relations_values", "=", "self", ".", "relative_positions_embeddings", "(", "\n", "relative_positions_matrix", ".", "to", "(", "device", ")", ")", "\n", "\n", "", "query", "=", "shape", "(", "query", ")", "\n", "\n", "key_len", "=", "key", ".", "size", "(", "2", ")", "# self_len+ctx_len", "\n", "query_len", "=", "query", ".", "size", "(", "2", ")", "# self_len", "\n", "\n", "# 2) Calculate and scale scores.", "\n", "query", "=", "query", "/", "math", ".", "sqrt", "(", "dim_per_head", ")", "\n", "# batch x num_heads x query_len x key_len", "\n", "query_key", "=", "torch", ".", "matmul", "(", "query", ",", "key", ".", "transpose", "(", "2", ",", "3", ")", ")", "# [batch, head, self_len, self_len+ctx_len]", "\n", "\n", "if", "self", ".", "ctx_weight_param", ":", "\n", "            ", "query_key", "[", "...", ",", "self_len", ":", "]", "+=", "self", ".", "ctx_bias", "\n", "#print(query_key.mean(), query_key.std())", "\n", "\n", "", "if", "self", ".", "max_relative_positions", ">", "0", "and", "type", "==", "\"self\"", ":", "\n", "            ", "scores", "=", "query_key", "+", "relative_matmul", "(", "query", ",", "relations_keys", ",", "True", ")", "\n", "", "else", ":", "\n", "            ", "scores", "=", "query_key", "\n", "", "scores", "=", "scores", ".", "float", "(", ")", "\n", "\n", "if", "self_mask", "is", "not", "None", ":", "\n", "            ", "self_mask", "=", "self_mask", ".", "unsqueeze", "(", "1", ")", "# [B, 1, self_len, self_len]", "\n", "scores", "[", ":", ",", ":", ",", ":", ",", ":", "self_len", "]", "=", "scores", "[", ":", ",", ":", ",", ":", ",", ":", "self_len", "]", ".", "masked_fill", "(", "self_mask", ",", "-", "1e18", ")", "\n", "", "if", "ctx_mask", "is", "not", "None", ":", "\n", "            ", "ctx_mask", "=", "ctx_mask", ".", "unsqueeze", "(", "1", ")", "# [B, 1, 1, ctx_len]", "\n", "scores", "[", ":", ",", ":", ",", ":", ",", "self_len", ":", "]", "=", "scores", "[", ":", ",", ":", ",", ":", ",", "self_len", ":", "]", ".", "masked_fill", "(", "ctx_mask", ",", "-", "1e18", ")", "\n", "\n", "# 3) Apply attention dropout and compute context vectors.", "\n", "", "attn", "=", "self", ".", "softmax", "(", "scores", ")", ".", "to", "(", "query", ".", "dtype", ")", "\n", "drop_attn", "=", "self", ".", "dropout", "(", "attn", ")", "\n", "\n", "context_original", "=", "torch", ".", "matmul", "(", "drop_attn", ",", "value", ")", "# [batch, head, self_len, dim]", "\n", "\n", "if", "self", ".", "max_relative_positions", ">", "0", "and", "type", "==", "\"self\"", ":", "\n", "            ", "context", "=", "unshape", "(", "context_original", "\n", "+", "relative_matmul", "(", "drop_attn", ",", "\n", "relations_values", ",", "\n", "False", ")", ")", "\n", "", "else", ":", "\n", "            ", "context", "=", "unshape", "(", "context_original", ")", "\n", "\n", "", "output", "=", "self", ".", "final_linear", "(", "context", ")", "\n", "# CHECK", "\n", "# batch_, q_len_, d_ = output.size()", "\n", "# aeq(q_len, q_len_)", "\n", "# aeq(batch, batch_)", "\n", "# aeq(d, d_)", "\n", "\n", "# Return one attn (to context)", "\n", "ctx_attn_probs", "=", "attn", "[", ":", ",", ":", ",", ":", ",", "self_len", ":", "]", "\n", "ctx_attn_probs", "=", "ctx_attn_probs", "/", "ctx_attn_probs", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "top_attn", "=", "ctx_attn_probs", ".", "view", "(", "batch_size", ",", "head_count", ",", "\n", "query_len", ",", "ctx_len", ")", "[", ":", ",", "0", ",", ":", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "\n", "return", "output", ",", "top_attn", ",", "attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.structured_attention.MatrixTree.__init__": [[13, 16], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "eps", "=", "1e-5", ")", ":", "\n", "        ", "self", ".", "eps", "=", "eps", "\n", "super", "(", "MatrixTree", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.structured_attention.MatrixTree.forward": [[17, 39], ["input.clone", "range", "input.exp", "input.size", "laplacian[].masked_fill", "input[].diag().exp", "laplacian[].masked_fill.inverse", "laplacian[].masked_fill.inverse.diag().unsqueeze().expand_as().transpose", "input[].exp().mul().clone", "input[].exp().mul().clone", "input[].diag().exp().mul", "torch.eye().ne", "torch.eye().ne", "torch.eye().ne", "torch.eye().ne", "torch.eye().ne", "torch.eye().ne", "torch.eye().ne", "torch.eye().ne", "torch.eye().ne", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "laplacian[].masked_fill.sum", "input[].diag", "laplacian[].masked_fill.inverse.diag().unsqueeze().expand_as", "input[].exp().mul", "input[].exp().mul", "input[].diag().exp", "laplacian[].masked_fill.inverse.transpose", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "laplacian[].masked_fill.inverse.transpose", "input.size", "laplacian[].masked_fill.inverse.diag().unsqueeze", "input[].exp", "input[].exp", "input[].diag", "laplacian[].masked_fill.inverse.diag"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "laplacian", "=", "input", ".", "exp", "(", ")", "+", "self", ".", "eps", "\n", "output", "=", "input", ".", "clone", "(", ")", "\n", "for", "b", "in", "range", "(", "input", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "lap", "=", "laplacian", "[", "b", "]", ".", "masked_fill", "(", "\n", "torch", ".", "eye", "(", "input", ".", "size", "(", "1", ")", ",", "device", "=", "input", ".", "device", ")", ".", "ne", "(", "0", ")", ",", "0", ")", "\n", "lap", "=", "-", "lap", "+", "torch", ".", "diag", "(", "lap", ".", "sum", "(", "0", ")", ")", "\n", "# store roots on diagonal", "\n", "lap", "[", "0", "]", "=", "input", "[", "b", "]", ".", "diag", "(", ")", ".", "exp", "(", ")", "\n", "inv_laplacian", "=", "lap", ".", "inverse", "(", ")", "\n", "\n", "factor", "=", "inv_laplacian", ".", "diag", "(", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "input", "[", "b", "]", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "term1", "=", "input", "[", "b", "]", ".", "exp", "(", ")", ".", "mul", "(", "factor", ")", ".", "clone", "(", ")", "\n", "term2", "=", "input", "[", "b", "]", ".", "exp", "(", ")", ".", "mul", "(", "inv_laplacian", ".", "transpose", "(", "0", ",", "1", ")", ")", ".", "clone", "(", ")", "\n", "term1", "[", ":", ",", "0", "]", "=", "0", "\n", "term2", "[", "0", "]", "=", "0", "\n", "output", "[", "b", "]", "=", "term1", "-", "term2", "\n", "roots_output", "=", "input", "[", "b", "]", ".", "diag", "(", ")", ".", "exp", "(", ")", ".", "mul", "(", "\n", "inv_laplacian", ".", "transpose", "(", "0", ",", "1", ")", "[", "0", "]", ")", "\n", "output", "[", "b", "]", "=", "output", "[", "b", "]", "+", "torch", ".", "diag", "(", "roots_output", ")", "\n", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.simple_fusion_generator.SimpleFusionGenerator.__init__": [[4, 9], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.LogSoftmax"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "decoder_input_size", ",", "lm_input_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "SimpleFusionGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "decoder_linear", "=", "nn", ".", "Linear", "(", "decoder_input_size", ",", "output_size", ")", "\n", "self", ".", "lm_linear", "=", "nn", ".", "Linear", "(", "lm_input_size", ",", "output_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "gen_func", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.simple_fusion_generator.SimpleFusionGenerator.forward": [[10, 28], ["simple_fusion_generator.SimpleFusionGenerator.decoder_linear", "simple_fusion_generator.SimpleFusionGenerator.lm_linear", "simple_fusion_generator.SimpleFusionGenerator.gen_func"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "decoder_hidden", ",", "lm_hidden", ")", ":", "\n", "        ", "\"\"\"\n        Compute a distribution over the target dictionary\n        extended by the dynamic dictionary implied by copying\n        source words.\n\n        Args:\n           decoder_hidden (FloatTensor): hidden outputs ``(batch x tlen, input_size)``\n           lm_hidden (FloatTensor): hidden outputs ``(batch x tlen, input_size)``\n        \"\"\"", "\n", "\n", "# Original probabilities.", "\n", "decoder_logits", "=", "self", ".", "decoder_linear", "(", "decoder_hidden", ")", "\n", "lm_logits", "=", "self", ".", "lm_linear", "(", "lm_hidden", ")", "\n", "logits", "=", "(", "decoder_logits", "+", "lm_logits", ")", ".", "float", "(", ")", "\n", "log_probs", "=", "self", ".", "gen_func", "(", "logits", ")", "\n", "\n", "return", "log_probs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.gpt_mlp.MLP.__init__": [[9, 18], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "gpt_mlp.MLP.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__", "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.weight_norm.WeightNormConvTranspose2d.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "n_embd", ",", "n_state", ",", "dropout", ")", ":", "# in MLP: n_state=3072 (4 * n_embd)", "\n", "        ", "super", "(", "MLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "c_fc", "=", "nn", ".", "Linear", "(", "n_embd", ",", "n_state", ")", "\n", "self", ".", "c_proj", "=", "nn", ".", "Linear", "(", "n_state", ",", "n_embd", ")", "\n", "self", ".", "act", "=", "gelu", "\n", "self", ".", "dropout_1", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropout_2", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.gpt_mlp.MLP.reset_parameters": [[19, 24], ["gpt_mlp.MLP.c_fc.weight.data.normal_", "gpt_mlp.MLP.c_fc.bias.data.zero_", "gpt_mlp.MLP.c_proj.weight.data.normal_", "gpt_mlp.MLP.c_proj.bias.data.zero_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "c_fc", ".", "weight", ".", "data", ".", "normal_", "(", "std", "=", "0.02", ")", "\n", "self", ".", "c_fc", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "c_proj", ".", "weight", ".", "data", ".", "normal_", "(", "std", "=", "0.02", ")", "\n", "self", ".", "c_proj", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.gpt_mlp.MLP.forward": [[25, 32], ["gpt_mlp.MLP.dropout_1", "gpt_mlp.MLP.dropout_2", "gpt_mlp.MLP.act", "gpt_mlp.MLP.c_proj", "gpt_mlp.MLP.c_fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n            x is input, [T, B, n_state]\n        \"\"\"", "\n", "h", "=", "self", ".", "dropout_1", "(", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", ")", "\n", "h2", "=", "self", ".", "dropout_2", "(", "self", ".", "c_proj", "(", "h", ")", ")", "\n", "return", "h2", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.gpt_mlp.gelu": [[5, 7], ["torch.tanh", "torch.tanh", "math.sqrt", "torch.pow", "torch.pow"], "function", ["None"], ["def", "gelu", "(", "x", ")", ":", "\n", "    ", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.average_attn.AverageAttention.__init__": [[22, 30], ["torch.Module.__init__", "onmt.modules.position_ffn.PositionwiseFeedForward", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "model_dim", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "model_dim", "=", "model_dim", "\n", "\n", "super", "(", "AverageAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "average_layer", "=", "PositionwiseFeedForward", "(", "model_dim", ",", "model_dim", ",", "\n", "dropout", ")", "\n", "self", ".", "gating_layer", "=", "nn", ".", "Linear", "(", "model_dim", "*", "2", ",", "model_dim", "*", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.average_attn.AverageAttention.cumulative_average_mask": [[31, 52], ["torch.tril", "torch.tril", "torch.tril", "torch.tril", "mask.unsqueeze().expand", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "weights.transpose", "mask.unsqueeze"], "methods", ["None"], ["", "def", "cumulative_average_mask", "(", "self", ",", "batch_size", ",", "inputs_len", ")", ":", "\n", "        ", "\"\"\"\n        Builds the mask to compute the cumulative average as described in\n        :cite:`DBLP:journals/corr/abs-1805-00631` -- Figure 3\n\n        Args:\n            batch_size (int): batch size\n            inputs_len (int): length of the inputs\n\n        Returns:\n            (FloatTensor):\n\n            * A Tensor of shape ``(batch_size, input_len, input_len)``\n        \"\"\"", "\n", "\n", "triangle", "=", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "inputs_len", ",", "inputs_len", ")", ")", "\n", "weights", "=", "torch", ".", "ones", "(", "1", ",", "inputs_len", ")", "/", "torch", ".", "arange", "(", "\n", "1", ",", "inputs_len", "+", "1", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "mask", "=", "triangle", "*", "weights", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "return", "mask", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_size", ",", "inputs_len", ",", "inputs_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.average_attn.AverageAttention.cumulative_average": [[53, 83], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "layer_cache[].to"], "methods", ["None"], ["", "def", "cumulative_average", "(", "self", ",", "inputs", ",", "mask_or_step", ",", "\n", "layer_cache", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Computes the cumulative average as described in\n        :cite:`DBLP:journals/corr/abs-1805-00631` -- Equations (1) (5) (6)\n\n        Args:\n            inputs (FloatTensor): sequence to average\n                ``(batch_size, input_len, dimension)``\n            mask_or_step: if cache is set, this is assumed\n                to be the current step of the\n                dynamic decoding. Otherwise, it is the mask matrix\n                used to compute the cumulative average.\n            layer_cache: a dictionary containing the cumulative average\n                of the previous step.\n\n        Returns:\n            a tensor of the same shape and type as ``inputs``.\n        \"\"\"", "\n", "\n", "if", "layer_cache", "is", "not", "None", ":", "\n", "            ", "step", "=", "mask_or_step", "\n", "device", "=", "inputs", ".", "device", "\n", "average_attention", "=", "(", "inputs", "+", "step", "*", "\n", "layer_cache", "[", "\"prev_g\"", "]", ".", "to", "(", "device", ")", ")", "/", "(", "step", "+", "1", ")", "\n", "layer_cache", "[", "\"prev_g\"", "]", "=", "average_attention", "\n", "return", "average_attention", "\n", "", "else", ":", "\n", "            ", "mask", "=", "mask_or_step", "\n", "return", "torch", ".", "matmul", "(", "mask", ",", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.average_attn.AverageAttention.forward": [[84, 113], ["inputs.size", "inputs.size", "average_attn.AverageAttention.cumulative_average", "average_attn.AverageAttention.average_layer", "average_attn.AverageAttention.gating_layer", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "average_attn.AverageAttention.cumulative_average_mask().to().float", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "average_attn.AverageAttention.cumulative_average_mask().to", "average_attn.AverageAttention.cumulative_average_mask"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.average_attn.AverageAttention.cumulative_average", "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.average_attn.AverageAttention.cumulative_average_mask"], ["", "", "def", "forward", "(", "self", ",", "inputs", ",", "mask", "=", "None", ",", "layer_cache", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (FloatTensor): ``(batch_size, input_len, model_dim)``\n\n        Returns:\n            (FloatTensor, FloatTensor):\n\n            * gating_outputs ``(batch_size, input_len, model_dim)``\n            * average_outputs average attention\n                ``(batch_size, input_len, model_dim)``\n        \"\"\"", "\n", "\n", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", "\n", "inputs_len", "=", "inputs", ".", "size", "(", "1", ")", "\n", "\n", "device", "=", "inputs", ".", "device", "\n", "average_outputs", "=", "self", ".", "cumulative_average", "(", "\n", "inputs", ",", "self", ".", "cumulative_average_mask", "(", "batch_size", ",", "\n", "inputs_len", ")", ".", "to", "(", "device", ")", ".", "float", "(", ")", "\n", "if", "layer_cache", "is", "None", "else", "step", ",", "layer_cache", "=", "layer_cache", ")", "\n", "average_outputs", "=", "self", ".", "average_layer", "(", "average_outputs", ")", "\n", "gating_outputs", "=", "self", ".", "gating_layer", "(", "torch", ".", "cat", "(", "(", "inputs", ",", "\n", "average_outputs", ")", ",", "-", "1", ")", ")", "\n", "input_gate", ",", "forget_gate", "=", "torch", ".", "chunk", "(", "gating_outputs", ",", "2", ",", "dim", "=", "2", ")", "\n", "gating_outputs", "=", "torch", ".", "sigmoid", "(", "input_gate", ")", "*", "inputs", "+", "torch", ".", "sigmoid", "(", "forget_gate", ")", "*", "average_outputs", "\n", "\n", "return", "gating_outputs", ",", "average_outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.sparse_losses.SparsemaxLossFunction.forward": [[10, 32], ["input.size", "target.size", "onmt.utils.misc.aeq", "input.gather().squeeze", "onmt.modules.sparse_activations._threshold_and_support", "torch.where().sum", "torch.where().sum", "torch.where().sum", "torch.where().sum", "ctx.save_for_backward", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "input.gather", "torch.where", "torch.where", "torch.where", "torch.where", "target.unsqueeze", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.sparse_activations._threshold_and_support"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        input (FloatTensor): ``(n, num_classes)``.\n        target (LongTensor): ``(n,)``, the indices of the target classes\n        \"\"\"", "\n", "input_batch", ",", "classes", "=", "input", ".", "size", "(", ")", "\n", "target_batch", "=", "target", ".", "size", "(", "0", ")", "\n", "aeq", "(", "input_batch", ",", "target_batch", ")", "\n", "\n", "z_k", "=", "input", ".", "gather", "(", "1", ",", "target", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", ")", "\n", "tau_z", ",", "support_size", "=", "_threshold_and_support", "(", "input", ",", "dim", "=", "1", ")", "\n", "support", "=", "input", ">", "tau_z", "\n", "x", "=", "torch", ".", "where", "(", "\n", "support", ",", "input", "**", "2", "-", "tau_z", "**", "2", ",", "\n", "torch", ".", "tensor", "(", "0.0", ",", "device", "=", "input", ".", "device", ")", "\n", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "ctx", ".", "save_for_backward", "(", "input", ",", "target", ",", "tau_z", ")", "\n", "# clamping necessary because of numerical errors: loss should be lower", "\n", "# bounded by zero, but negative values near zero are possible without", "\n", "# the clamp", "\n", "return", "torch", ".", "clamp", "(", "x", "/", "2", "-", "z_k", "+", "0.5", ",", "min", "=", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.sparse_losses.SparsemaxLossFunction.backward": [[33, 40], ["torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like.scatter_", "torch.zeros_like.scatter_", "target.unsqueeze"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "input", ",", "target", ",", "tau_z", "=", "ctx", ".", "saved_tensors", "\n", "sparsemax_out", "=", "torch", ".", "clamp", "(", "input", "-", "tau_z", ",", "min", "=", "0", ")", "\n", "delta", "=", "torch", ".", "zeros_like", "(", "sparsemax_out", ")", "\n", "delta", ".", "scatter_", "(", "1", ",", "target", ".", "unsqueeze", "(", "1", ")", ",", "1", ")", "\n", "return", "sparsemax_out", "-", "delta", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.sparse_losses.SparsemaxLoss.__init__": [[56, 63], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "weight", "=", "None", ",", "ignore_index", "=", "-", "100", ",", "\n", "reduction", "=", "'elementwise_mean'", ")", ":", "\n", "        ", "assert", "reduction", "in", "[", "'elementwise_mean'", ",", "'sum'", ",", "'none'", "]", "\n", "self", ".", "reduction", "=", "reduction", "\n", "self", ".", "weight", "=", "weight", "\n", "self", ".", "ignore_index", "=", "ignore_index", "\n", "super", "(", "SparsemaxLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.sparse_losses.SparsemaxLoss.forward": [[64, 77], ["sparsemax_loss", "float", "loss.sum.sum.masked_fill_", "float", "loss.sum.sum.sum", "target.size", "loss.sum.sum.sum", "target.size", "ignored_positions.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "loss", "=", "sparsemax_loss", "(", "input", ",", "target", ")", "\n", "if", "self", ".", "ignore_index", ">=", "0", ":", "\n", "            ", "ignored_positions", "=", "target", "==", "self", ".", "ignore_index", "\n", "size", "=", "float", "(", "(", "target", ".", "size", "(", "0", ")", "-", "ignored_positions", ".", "sum", "(", ")", ")", ".", "item", "(", ")", ")", "\n", "loss", ".", "masked_fill_", "(", "ignored_positions", ",", "0.0", ")", "\n", "", "else", ":", "\n", "            ", "size", "=", "float", "(", "target", ".", "size", "(", "0", ")", ")", "\n", "", "if", "self", ".", "reduction", "==", "'sum'", ":", "\n", "            ", "loss", "=", "loss", ".", "sum", "(", ")", "\n", "", "elif", "self", ".", "reduction", "==", "'elementwise_mean'", ":", "\n", "            ", "loss", "=", "loss", ".", "sum", "(", ")", "/", "size", "\n", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.position_ffn.PositionwiseFeedForward.__init__": [[16, 24], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.Dropout", "torch.ReLU", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "d_ff", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "PositionwiseFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w_1", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_ff", ")", "\n", "self", ".", "w_2", "=", "nn", ".", "Linear", "(", "d_ff", ",", "d_model", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "dropout_1", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "dropout_2", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.position_ffn.PositionwiseFeedForward.forward": [[25, 38], ["position_ffn.PositionwiseFeedForward.dropout_1", "position_ffn.PositionwiseFeedForward.dropout_2", "position_ffn.PositionwiseFeedForward.relu", "position_ffn.PositionwiseFeedForward.w_2", "position_ffn.PositionwiseFeedForward.w_1", "position_ffn.PositionwiseFeedForward.layer_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Layer definition.\n\n        Args:\n            x: ``(batch_size, input_len, model_dim)``\n\n        Returns:\n            (FloatTensor): Output ``(batch_size, input_len, model_dim)``.\n        \"\"\"", "\n", "\n", "inter", "=", "self", ".", "dropout_1", "(", "self", ".", "relu", "(", "self", ".", "w_1", "(", "self", ".", "layer_norm", "(", "x", ")", ")", ")", ")", "\n", "output", "=", "self", ".", "dropout_2", "(", "self", ".", "w_2", "(", "inter", ")", ")", "\n", "return", "output", "+", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.CopyGenerator.__init__": [[84, 89], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "output_size", ",", "pad_idx", ")", ":", "\n", "        ", "super", "(", "CopyGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "output_size", ")", "\n", "self", ".", "linear_copy", "=", "nn", ".", "Linear", "(", "input_size", ",", "1", ")", "\n", "self", ".", "pad_idx", "=", "pad_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.CopyGenerator.forward": [[90, 145], ["hidden.size", "attn.size", "src_map.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "copy_generator.CopyGenerator.linear", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "copy_prob.contiguous().view.contiguous().view.contiguous().view", "float", "copy_generator.CopyGenerator.linear_copy", "align.eq().float().view", "align.ne().float().view", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ptrs.view().float", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "copy_prob.contiguous().view.contiguous().view.contiguous", "align.eq().float", "align.ne().float", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul.view().transpose", "torch.mul.view().transpose", "src_map.transpose", "ptrs.view", "tags.t", "align.eq", "align.ne", "torch.mul.view", "torch.mul.view"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq"], ["", "def", "forward", "(", "self", ",", "hidden", ",", "attn", ",", "src_map", ",", "align", "=", "None", ",", "ptrs", "=", "None", ",", "tags", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Compute a distribution over the target dictionary\n        extended by the dynamic dictionary implied by copying\n        source words.\n\n        Args:\n           hidden (FloatTensor): hidden outputs ``(batch x tlen, input_size)``\n           attn (FloatTensor): attn for each ``(batch x tlen, input_size)``\n           src_map (FloatTensor):\n               A sparse indicator matrix mapping each source word to\n               its index in the \"extended\" vocab containing.\n               ``(src_len, batch, extra_words)``\n        \"\"\"", "\n", "\n", "# CHECKS", "\n", "batch_by_tlen", ",", "_", "=", "hidden", ".", "size", "(", ")", "\n", "batch_by_tlen_", ",", "slen", "=", "attn", ".", "size", "(", ")", "\n", "slen_", ",", "batch", ",", "cvocab", "=", "src_map", ".", "size", "(", ")", "\n", "aeq", "(", "batch_by_tlen", ",", "batch_by_tlen_", ")", "\n", "aeq", "(", "slen", ",", "slen_", ")", "\n", "\n", "# Original probabilities.", "\n", "logits", "=", "self", ".", "linear", "(", "hidden", ")", "\n", "logits", "[", ":", ",", "self", ".", "pad_idx", "]", "=", "-", "float", "(", "'inf'", ")", "\n", "prob", "=", "torch", ".", "softmax", "(", "logits", ",", "1", ")", "\n", "\n", "# Probability of copying p(z=1) batch.", "\n", "p_copy", "=", "torch", ".", "sigmoid", "(", "self", ".", "linear_copy", "(", "hidden", ")", ")", "\n", "# Probability of not copying: p_{word}(w) * (1 - p(z))", "\n", "\n", "if", "self", ".", "training", "and", "ptrs", "is", "not", "None", ":", "\n", "            ", "align_unk", "=", "align", ".", "eq", "(", "0", ")", ".", "float", "(", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "align_not_unk", "=", "align", ".", "ne", "(", "0", ")", ".", "float", "(", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "out_prob", "=", "torch", ".", "mul", "(", "prob", ",", "align_unk", ")", "\n", "mul_attn", "=", "torch", ".", "mul", "(", "attn", ",", "align_not_unk", ")", "\n", "mul_attn", "=", "torch", ".", "mul", "(", "mul_attn", ",", "ptrs", ".", "view", "(", "-", "1", ",", "slen_", ")", ".", "float", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "out_prob", "=", "torch", ".", "mul", "(", "prob", ",", "1", "-", "p_copy", ")", "\n", "\n", "# Mask disallowed copys", "\n", "if", "tags", "is", "not", "None", ":", "\n", "                ", "mul_attn", "=", "torch", ".", "mul", "(", "attn", ",", "tags", ".", "t", "(", ")", ")", "*", "2", "\n", "", "else", ":", "\n", "                ", "mul_attn", "=", "attn", "\n", "\n", "", "mul_attn", "=", "torch", ".", "mul", "(", "mul_attn", ",", "p_copy", ")", "\n", "\n", "", "copy_prob", "=", "torch", ".", "bmm", "(", "\n", "mul_attn", ".", "view", "(", "-", "1", ",", "batch", ",", "slen", ")", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "src_map", ".", "transpose", "(", "0", ",", "1", ")", "\n", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# The P_copy actual contain the importance of the word from the training decision.", "\n", "copy_prob", "=", "copy_prob", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "cvocab", ")", "\n", "return", "torch", ".", "cat", "(", "[", "out_prob", ",", "copy_prob", "]", ",", "1", ")", ",", "p_copy", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.CopyGeneratorLoss.__init__": [[149, 157], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "vocab_size", ",", "force_copy", ",", "unk_index", "=", "0", ",", "\n", "ignore_index", "=", "-", "100", ",", "eps", "=", "1e-20", ")", ":", "\n", "        ", "super", "(", "CopyGeneratorLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "force_copy", "=", "force_copy", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "ignore_index", "=", "ignore_index", "\n", "self", ".", "unk_index", "=", "unk_index", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.CopyGeneratorLoss.forward": [[158, 190], ["scores.gather().squeeze", "scores.gather().squeeze", "torch.where", "torch.where", "torch.where", "torch.where", "align.unsqueeze", "torch.where.log", "torch.where.log", "scores.gather", "scores.gather", "target.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log"], ["", "def", "forward", "(", "self", ",", "scores", ",", "align", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            scores (FloatTensor): ``(batch_size*tgt_len)`` x dynamic vocab size\n                whose sum along dim 1 is less than or equal to 1, i.e. cols\n                softmaxed.\n            align (LongTensor): ``(batch_size x tgt_len)``\n            target (LongTensor): ``(batch_size x tgt_len)``\n        \"\"\"", "\n", "# probabilities assigned by the model to the gold targets", "\n", "vocab_probs", "=", "scores", ".", "gather", "(", "1", ",", "target", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "# probability of tokens copied from source", "\n", "copy_ix", "=", "align", ".", "unsqueeze", "(", "1", ")", "+", "self", ".", "vocab_size", "\n", "copy_tok_probs", "=", "scores", ".", "gather", "(", "1", ",", "copy_ix", ")", ".", "squeeze", "(", "1", ")", "\n", "# Set scores for unk to 0 and add eps", "\n", "copy_tok_probs", "[", "align", "==", "self", ".", "unk_index", "]", "=", "0", "\n", "copy_tok_probs", "+=", "self", ".", "eps", "# to avoid -inf logs", "\n", "\n", "# find the indices in which you do not use the copy mechanism", "\n", "non_copy", "=", "align", "==", "self", ".", "unk_index", "\n", "if", "not", "self", ".", "force_copy", ":", "\n", "            ", "non_copy", "=", "non_copy", "|", "(", "target", "!=", "self", ".", "unk_index", ")", "\n", "\n", "", "probs", "=", "torch", ".", "where", "(", "\n", "non_copy", ",", "copy_tok_probs", "+", "vocab_probs", ",", "copy_tok_probs", "\n", ")", "\n", "\n", "loss", "=", "-", "probs", ".", "log", "(", ")", "# just NLLLoss; can the module be incorporated?", "\n", "# Drop padding.", "\n", "loss", "[", "target", "==", "self", ".", "ignore_index", "]", "=", "0", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.CopyGeneratorLossCompute.__init__": [[194, 202], ["onmt.utils.loss.LossComputeBase.__init__", "torch.BCELoss", "torch.BCELoss"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "criterion", ",", "generator", ",", "tgt_vocab", ",", "normalize_by_length", ",", "ptrs_loss", "=", "False", ")", ":", "\n", "        ", "super", "(", "CopyGeneratorLossCompute", ",", "self", ")", ".", "__init__", "(", "criterion", ",", "generator", ")", "\n", "self", ".", "tgt_vocab", "=", "tgt_vocab", "\n", "self", ".", "normalize_by_length", "=", "normalize_by_length", "\n", "\n", "self", ".", "ptrs_loss", "=", "ptrs_loss", "\n", "if", "ptrs_loss", ":", "\n", "            ", "self", ".", "switch_loss_criterion", "=", "nn", ".", "BCELoss", "(", "reduction", "=", "'sum'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.CopyGeneratorLossCompute._make_shard_state": [[203, 220], ["getattr", "AssertionError", "attns.get"], "methods", ["None"], ["", "", "def", "_make_shard_state", "(", "self", ",", "batch", ",", "output", ",", "range_", ",", "attns", ")", ":", "\n", "        ", "\"\"\"See base class for args description.\"\"\"", "\n", "if", "getattr", "(", "batch", ",", "\"alignment\"", ",", "None", ")", "is", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "\"using -copy_attn you need to pass in \"", "\n", "\"-dynamic_dict during preprocess stage.\"", ")", "\n", "\n", "", "ptrs", "=", "batch", ".", "ptrs", "[", "range_", "[", "0", "]", "+", "1", ":", "range_", "[", "1", "]", "]", "if", "self", ".", "ptrs_loss", "else", "None", "\n", "\n", "ret_dict", "=", "{", "\n", "\"output\"", ":", "output", ",", "\n", "\"target\"", ":", "batch", ".", "tgt", "[", "range_", "[", "0", "]", "+", "1", ":", "range_", "[", "1", "]", ",", ":", ",", "0", "]", ",", "\n", "\"copy_attn\"", ":", "attns", ".", "get", "(", "\"copy\"", ")", ",", "\n", "\"align\"", ":", "batch", ".", "alignment", "[", "range_", "[", "0", "]", "+", "1", ":", "range_", "[", "1", "]", "]", ",", "\n", "\"ptrs\"", ":", "ptrs", "\n", "}", "\n", "\n", "return", "ret_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.CopyGeneratorLossCompute._compute_loss": [[221, 284], ["target.view.view.view", "align.view.view.view", "batch.src_map.to", "copy_generator.CopyGeneratorLossCompute.generator", "copy_generator.CopyGeneratorLossCompute.criterion", "copy_generator.collapse_copy_scores", "copy_generator.CopyGeneratorLossCompute._bottle", "target.view.view.clone", "copy_generator.CopyGeneratorLossCompute._stats", "copy_generator.CopyGeneratorLossCompute._bottle", "copy_generator.CopyGeneratorLossCompute._bottle", "copy_generator.CopyGeneratorLossCompute.switch_loss_criterion", "copy_generator.CopyGeneratorLossCompute._unbottle", "len", "loss.sum.sum.sum().clone", "batch.tgt[].ne().sum().float", "loss.sum.sum.view().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "loss.sum.sum.sum", "align.view.view.ne().float().view", "scores.clone", "loss.sum.sum.sum", "batch.tgt[].ne().sum", "loss.sum.sum.view", "torch.div", "torch.div", "torch.div", "torch.div", "align.view.view.ne().float", "batch.tgt[].ne", "align.view.view.ne"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.collapse_copy_scores", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LossComputeBase._bottle", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LossComputeBase._stats", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LossComputeBase._bottle", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LossComputeBase._bottle", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.loss.LossComputeBase._unbottle"], ["", "def", "_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "target", ",", "copy_attn", ",", "align", ",", "ptrs", ")", ":", "\n", "        ", "\"\"\"Compute the loss.\n\n        The args must match :func:`self._make_shard_state()`.\n\n        Args:\n            batch: the current batch.\n            output: the predict output from the model.\n            target: the validate target to compare output with.\n            copy_attn: the copy attention value.\n            align: the align info.\n        \"\"\"", "\n", "\n", "target", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "align", "=", "align", ".", "view", "(", "-", "1", ")", "\n", "src_map", "=", "batch", ".", "src_map", ".", "to", "(", "dtype", "=", "output", ".", "dtype", ")", "\n", "\n", "scores", ",", "p_copy", "=", "self", ".", "generator", "(", "\n", "self", ".", "_bottle", "(", "output", ")", ",", "self", ".", "_bottle", "(", "copy_attn", ")", ",", "src_map", ",", "\n", "align", "=", "align", ",", "ptrs", "=", "ptrs", "\n", ")", "\n", "loss", "=", "self", ".", "criterion", "(", "scores", ",", "align", ",", "target", ")", "\n", "\n", "# ptr stuff", "\n", "if", "self", ".", "ptrs_loss", ":", "\n", "            ", "switch_loss", "=", "self", ".", "switch_loss_criterion", "(", "p_copy", ",", "align", ".", "ne", "(", "0", ")", ".", "float", "(", ")", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "\n", "# this block does not depend on the loss value computed above", "\n", "# and is used only for stats", "\n", "", "scores_data", "=", "collapse_copy_scores", "(", "\n", "self", ".", "_unbottle", "(", "scores", ".", "clone", "(", ")", ",", "batch", ".", "batch_size", ")", ",", "\n", "batch", ",", "self", ".", "tgt_vocab", ",", "batch", ".", "dataset", ".", "src_vocabs", ")", "\n", "scores_data", "=", "self", ".", "_bottle", "(", "scores_data", ")", "\n", "\n", "# this block does not depend on the loss value computed above", "\n", "# and is used only for stats", "\n", "# Correct target copy token instead of <unk>", "\n", "# tgt[i] = align[i] + len(tgt_vocab)", "\n", "# for i such that tgt[i] == 0 and align[i] != 0", "\n", "target_data", "=", "target", ".", "clone", "(", ")", "\n", "unk", "=", "self", ".", "criterion", ".", "unk_index", "\n", "correct_mask", "=", "(", "target_data", "==", "unk", ")", "&", "(", "align", "!=", "unk", ")", "\n", "offset_align", "=", "align", "[", "correct_mask", "]", "+", "len", "(", "self", ".", "tgt_vocab", ")", "\n", "target_data", "[", "correct_mask", "]", "+=", "offset_align", "\n", "\n", "# Compute sum of perplexities for stats", "\n", "stats", "=", "self", ".", "_stats", "(", "loss", ".", "sum", "(", ")", ".", "clone", "(", ")", ",", "scores_data", ",", "target_data", ")", "\n", "\n", "# this part looks like it belongs in CopyGeneratorLoss", "\n", "if", "self", ".", "normalize_by_length", ":", "\n", "# Compute Loss as NLL divided by seq length", "\n", "            ", "tgt_lens", "=", "batch", ".", "tgt", "[", ":", ",", ":", ",", "0", "]", ".", "ne", "(", "self", ".", "padding_idx", ")", ".", "sum", "(", "0", ")", ".", "float", "(", ")", "\n", "# Compute Total Loss per sequence in batch", "\n", "loss", "=", "loss", ".", "view", "(", "-", "1", ",", "batch", ".", "batch_size", ")", ".", "sum", "(", "0", ")", "\n", "# Divide by length of each sequence and sum", "\n", "loss", "=", "torch", ".", "div", "(", "loss", ",", "tgt_lens", ")", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "loss", ".", "sum", "(", ")", "\n", "\n", "", "if", "self", ".", "ptrs_loss", ":", "\n", "            ", "loss", "=", "loss", "+", "switch_loss", "\n", "\n", "", "return", "loss", ",", "stats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.collapse_copy_scores": [[8, 35], ["len", "range", "scores.size", "range", "len", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "score.index_add_", "score.index_fill_", "torch.Tensor().type_as.append", "torch.Tensor().type_as.append", "score.index_select", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "function", ["None"], ["def", "collapse_copy_scores", "(", "scores", ",", "batch", ",", "tgt_vocab", ",", "src_vocabs", ",", "\n", "batch_dim", "=", "1", ",", "batch_offset", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given scores from an expanded dictionary\n    corresponeding to a batch, sums together copies,\n    with a dictionary word when it is ambiguous.\n    \"\"\"", "\n", "offset", "=", "len", "(", "tgt_vocab", ")", "\n", "for", "b", "in", "range", "(", "scores", ".", "size", "(", "batch_dim", ")", ")", ":", "\n", "        ", "blank", "=", "[", "]", "\n", "fill", "=", "[", "]", "\n", "batch_id", "=", "batch_offset", "[", "b", "]", "if", "batch_offset", "is", "not", "None", "else", "b", "\n", "index", "=", "batch", ".", "indices", ".", "data", "[", "batch_id", "]", "\n", "src_vocab", "=", "src_vocabs", "[", "index", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "src_vocab", ")", ")", ":", "\n", "            ", "sw", "=", "src_vocab", ".", "itos", "[", "i", "]", "\n", "ti", "=", "tgt_vocab", ".", "stoi", "[", "sw", "]", "\n", "if", "ti", "!=", "0", ":", "\n", "                ", "blank", ".", "append", "(", "offset", "+", "i", ")", "\n", "fill", ".", "append", "(", "ti", ")", "\n", "", "", "if", "blank", ":", "\n", "            ", "blank", "=", "torch", ".", "Tensor", "(", "blank", ")", ".", "type_as", "(", "batch", ".", "indices", ".", "data", ")", "\n", "fill", "=", "torch", ".", "Tensor", "(", "fill", ")", ".", "type_as", "(", "batch", ".", "indices", ".", "data", ")", "\n", "score", "=", "scores", "[", ":", ",", "b", "]", "if", "batch_dim", "==", "1", "else", "scores", "[", "b", "]", "\n", "score", ".", "index_add_", "(", "1", ",", "fill", ",", "score", ".", "index_select", "(", "1", ",", "blank", ")", ")", "\n", "score", ".", "index_fill_", "(", "1", ",", "blank", ",", "1e-10", ")", "\n", "", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.embeddings.PositionalEncoding.__init__": [[25, 40], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "pe.unsqueeze.unsqueeze.unsqueeze", "torch.Module.__init__", "embeddings.PositionalEncoding.register_buffer", "torch.Dropout", "torch.Dropout", "ValueError", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "math.log"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log"], ["def", "__init__", "(", "self", ",", "dropout", ",", "dim", ",", "max_len", "=", "5000", ")", ":", "\n", "        ", "if", "dim", "%", "2", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot use sin/cos positional encoding with \"", "\n", "\"odd dim (got dim={:d})\"", ".", "format", "(", "dim", ")", ")", "\n", "", "pe", "=", "torch", ".", "zeros", "(", "max_len", ",", "dim", ")", "\n", "position", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "unsqueeze", "(", "1", ")", "\n", "div_term", "=", "torch", ".", "exp", "(", "(", "torch", ".", "arange", "(", "0", ",", "dim", ",", "2", ",", "dtype", "=", "torch", ".", "float", ")", "*", "\n", "-", "(", "math", ".", "log", "(", "10000.0", ")", "/", "dim", ")", ")", ")", "\n", "pe", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "sin", "(", "position", ".", "float", "(", ")", "*", "div_term", ")", "\n", "pe", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "cos", "(", "position", ".", "float", "(", ")", "*", "div_term", ")", "\n", "pe", "=", "pe", ".", "unsqueeze", "(", "1", ")", "# [max_len, 1, dim]", "\n", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "register_buffer", "(", "'pe'", ",", "pe", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.embeddings.PositionalEncoding.forward": [[41, 62], ["embeddings.PositionalEncoding.dropout", "math.sqrt", "embeddings.PositionalEncoding.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "emb", ",", "step", "=", "None", ",", "offset", "=", "None", ")", ":", "\n", "        ", "\"\"\"Embed inputs.\n\n        Args:\n            emb (FloatTensor): Sequence of word vectors\n                ``(seq_len, batch_size, self.dim)``\n            step (int or NoneType): If stepwise (``seq_len = 1``), use\n                the encoding for this position.\n        \"\"\"", "\n", "\n", "if", "offset", "is", "not", "None", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "emb", "=", "emb", "*", "math", ".", "sqrt", "(", "self", ".", "dim", ")", "\n", "\n", "if", "step", "is", "None", ":", "\n", "            ", "emb", "=", "emb", "+", "self", ".", "pe", "[", ":", "emb", ".", "size", "(", "0", ")", "]", "\n", "", "else", ":", "\n", "            ", "emb", "=", "emb", "+", "self", ".", "pe", "[", "step", "]", "\n", "", "emb", "=", "self", ".", "dropout", "(", "emb", ")", "\n", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.embeddings.LearnedPositionalEncoding.__init__": [[64, 68], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "context_size", ",", "embedding_dim", ",", "dropout", "=", "0", ")", ":", "\n", "        ", "super", "(", "LearnedPositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pe", "=", "nn", ".", "Embedding", "(", "context_size", ",", "embedding_dim", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.embeddings.LearnedPositionalEncoding.forward": [[69, 92], ["torch.arange.unsqueeze().repeat", "torch.arange.unsqueeze().repeat", "embeddings.LearnedPositionalEncoding.pe", "embeddings.LearnedPositionalEncoding.dropout", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "offset.unsqueeze.unsqueeze.unsqueeze", "torch.arange.unsqueeze", "torch.arange.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "emb", ",", "step", "=", "None", ",", "offset", "=", "None", ")", ":", "\n", "        ", "\"\"\"Embed inputs.\n\n        Args:\n            emb (FloatTensor): Sequence of word vectors\n                ``(seq_len, batch_size, self.dim)``\n            step (int or NoneType): If stepwise (``seq_len = 1``), use\n                the encoding for this position.\n        \"\"\"", "\n", "if", "step", "is", "None", ":", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "0", ",", "emb", ".", "shape", "[", "0", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "emb", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "step", ",", "step", "+", "1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "emb", ".", "device", ")", "\n", "", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "emb", ".", "shape", "[", "1", "]", ")", "# [seq_len, batch_size]", "\n", "\n", "if", "offset", "is", "not", "None", ":", "\n", "            ", "offset", "=", "offset", ".", "unsqueeze", "(", "0", ")", "# [1, batch_size]", "\n", "position_ids", "+=", "offset", "\n", "\n", "", "pe_vals", "=", "self", ".", "pe", "(", "position_ids", ")", "# [seq_len, batch_size, self.dim]", "\n", "emb", "=", "emb", "+", "pe_vals", "\n", "emb", "=", "self", ".", "dropout", "(", "emb", ")", "\n", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.embeddings.NothingEncoding.__init__": [[94, 96], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "NothingEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "", "def", "set_return", "(", "self", ",", "input_embeds", ")", ":", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.embeddings.NothingEncoding.set_return": [[96, 98], ["None"], "methods", ["None"], ["", "def", "set_return", "(", "self", ",", "input_embeds", ")", ":", "\n", "        ", "self", ".", "input_embeds", "=", "input_embeds", "\n", "", "def", "forward", "(", "self", ",", "source", ")", ":", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.embeddings.NothingEncoding.forward": [[98, 100], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "source", ")", ":", "\n", "        ", "return", "self", ".", "input_embeds", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.embeddings.Embeddings.__init__": [[141, 240], ["embeddings.Embeddings._validate_args", "vocab_sizes.extend", "emb_dims.extend", "pad_indices.extend", "zip", "onmt.modules.util_class.Elementwise", "torch.Module.__init__", "torch.Sequential", "torch.Sequential", "embeddings.Embeddings.make_embedding.add_module", "torch.Embedding", "torch.Embedding", "sum", "sum", "torch.Sequential", "torch.Sequential", "embeddings.Embeddings.make_embedding.add_module", "embeddings.Embeddings.make_embedding.add_module", "len", "len", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "embeddings.LearnedPositionalEncoding", "embeddings.PositionalEncoding", "onmt.decoders.TransformerDecoder", "onmt.encoders.TransformerEncoder", "embeddings.Embeddings.gpt_model.parameters", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "len", "int", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.full", "torch.full", "torch.full", "torch.full"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.embeddings.Embeddings._validate_args", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "word_vec_size", ",", "\n", "word_vocab_size", ",", "\n", "word_padding_idx", ",", "\n", "position_encoding", "=", "False", ",", "\n", "position_encoding_learned", "=", "False", ",", "\n", "position_encoding_ctxsize", "=", "1024", ",", "\n", "feat_merge", "=", "\"concat\"", ",", "\n", "feat_vec_exponent", "=", "0.7", ",", "\n", "feat_vec_size", "=", "-", "1", ",", "\n", "feat_padding_idx", "=", "[", "]", ",", "\n", "feat_vocab_sizes", "=", "[", "]", ",", "\n", "dropout", "=", "0", ",", "\n", "sparse", "=", "False", ",", "\n", "fix_word_vecs", "=", "False", ",", "\n", "GPT_representation_mode", "=", "'none'", ",", "\n", "GPT_representation_tgt", "=", "False", ")", ":", "\n", "        ", "self", ".", "_validate_args", "(", "feat_merge", ",", "feat_vocab_sizes", ",", "feat_vec_exponent", ",", "\n", "feat_vec_size", ",", "feat_padding_idx", ")", "\n", "\n", "if", "feat_padding_idx", "is", "None", ":", "\n", "            ", "feat_padding_idx", "=", "[", "]", "\n", "", "self", ".", "word_padding_idx", "=", "word_padding_idx", "\n", "\n", "self", ".", "word_vec_size", "=", "word_vec_size", "\n", "\n", "# Dimensions and padding for constructing the word embedding matrix", "\n", "vocab_sizes", "=", "[", "word_vocab_size", "]", "\n", "emb_dims", "=", "[", "word_vec_size", "]", "\n", "pad_indices", "=", "[", "word_padding_idx", "]", "\n", "\n", "# Dimensions and padding for feature embedding matrices", "\n", "# (these have no effect if feat_vocab_sizes is empty)", "\n", "if", "feat_merge", "==", "'sum'", ":", "\n", "            ", "feat_dims", "=", "[", "word_vec_size", "]", "*", "len", "(", "feat_vocab_sizes", ")", "\n", "", "elif", "feat_vec_size", ">", "0", ":", "\n", "            ", "feat_dims", "=", "[", "feat_vec_size", "]", "*", "len", "(", "feat_vocab_sizes", ")", "\n", "", "else", ":", "\n", "            ", "feat_dims", "=", "[", "int", "(", "vocab", "**", "feat_vec_exponent", ")", "\n", "for", "vocab", "in", "feat_vocab_sizes", "]", "\n", "", "vocab_sizes", ".", "extend", "(", "feat_vocab_sizes", ")", "\n", "emb_dims", ".", "extend", "(", "feat_dims", ")", "\n", "pad_indices", ".", "extend", "(", "feat_padding_idx", ")", "\n", "\n", "# The embedding matrix look-up tables. The first look-up table", "\n", "# is for words. Subsequent ones are for features, if any exist.", "\n", "emb_params", "=", "zip", "(", "vocab_sizes", ",", "emb_dims", ",", "pad_indices", ")", "\n", "embeddings", "=", "[", "nn", ".", "Embedding", "(", "vocab", ",", "dim", ",", "padding_idx", "=", "pad", ",", "sparse", "=", "sparse", ")", "\n", "for", "vocab", ",", "dim", ",", "pad", "in", "emb_params", "]", "\n", "\n", "emb_luts", "=", "Elementwise", "(", "feat_merge", ",", "embeddings", ")", "\n", "\n", "# The final output size of word + feature vectors. This can vary", "\n", "# from the word vector size if and only if features are defined.", "\n", "# This is the attribute you should access if you need to know", "\n", "# how big your embeddings are going to be.", "\n", "self", ".", "embedding_size", "=", "(", "sum", "(", "emb_dims", ")", "if", "feat_merge", "==", "'concat'", "\n", "else", "word_vec_size", ")", "\n", "\n", "# The sequence of operations that converts the input sequence", "\n", "# into a sequence of embeddings. At minimum this consists of", "\n", "# looking up the embeddings for each word and feature in the", "\n", "# input. Model parameters may require the sequence to contain", "\n", "# additional operations as well.", "\n", "super", "(", "Embeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "make_embedding", "=", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "make_embedding", ".", "add_module", "(", "'emb_luts'", ",", "emb_luts", ")", "\n", "\n", "if", "feat_merge", "==", "'mlp'", "and", "len", "(", "feat_vocab_sizes", ")", ">", "0", ":", "\n", "            ", "in_dim", "=", "sum", "(", "emb_dims", ")", "\n", "mlp", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "in_dim", ",", "word_vec_size", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "self", ".", "make_embedding", ".", "add_module", "(", "'mlp'", ",", "mlp", ")", "\n", "\n", "", "self", ".", "position_encoding", "=", "position_encoding", "\n", "\n", "if", "self", ".", "position_encoding", ":", "\n", "            ", "if", "position_encoding_learned", ":", "\n", "                ", "pe", "=", "LearnedPositionalEncoding", "(", "position_encoding_ctxsize", ",", "self", ".", "embedding_size", ",", "dropout", "=", "dropout", ")", "\n", "if", "fix_word_vecs", ":", "\n", "                    ", "pe", ".", "pe", ".", "weight", ".", "requires_grad", "=", "False", "\n", "", "", "else", ":", "\n", "                ", "pe", "=", "PositionalEncoding", "(", "dropout", ",", "self", ".", "embedding_size", ")", "\n", "", "self", ".", "make_embedding", ".", "add_module", "(", "'pe'", ",", "pe", ")", "\n", "\n", "", "if", "fix_word_vecs", ":", "\n", "            ", "self", ".", "word_lut", ".", "weight", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "GPT_representation_mode", "=", "GPT_representation_mode", "\n", "self", ".", "GPT_representation_tgt", "=", "GPT_representation_tgt", "\n", "if", "self", ".", "GPT_representation_mode", "!=", "'none'", ":", "\n", "            ", "gpt_dropout", "=", "0", "if", "self", ".", "GPT_representation_mode", "==", "'elmo'", "else", "dropout", "\n", "if", "self", ".", "GPT_representation_tgt", ":", "\n", "                ", "self", ".", "gpt_model", "=", "onmt", ".", "decoders", ".", "TransformerDecoder", "(", "12", ",", "768", ",", "12", ",", "3072", ",", "False", ",", "'scaled-dot'", ",", "gpt_dropout", ",", "gpt_dropout", ",", "None", ",", "0", ",", "False", ",", "True", ",", "False", ",", "False", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "gpt_model", "=", "onmt", ".", "encoders", ".", "TransformerEncoder", "(", "12", ",", "768", ",", "12", ",", "3072", ",", "gpt_dropout", ",", "gpt_dropout", ",", "None", ",", "0", ",", "True", ")", "\n", "", "if", "self", ".", "GPT_representation_mode", "==", "'elmo'", ":", "\n", "                ", "for", "p", "in", "self", ".", "gpt_model", ".", "parameters", "(", ")", ":", "\n", "                    ", "p", ".", "requires_grad", "=", "False", "\n", "", "self", ".", "elmo_scale_params", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "13", ")", ")", "\n", "self", ".", "elmo_gamma_param", "=", "nn", ".", "Parameter", "(", "torch", ".", "full", "(", "(", "1", ",", ")", ",", "1.0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.embeddings.Embeddings._validate_args": [[242, 268], ["len", "len", "ValueError", "warnings.warn", "warnings.warn", "warnings.warn", "ValueError", "len"], "methods", ["None"], ["", "", "", "def", "_validate_args", "(", "self", ",", "feat_merge", ",", "feat_vocab_sizes", ",", "feat_vec_exponent", ",", "\n", "feat_vec_size", ",", "feat_padding_idx", ")", ":", "\n", "        ", "if", "feat_merge", "==", "\"sum\"", ":", "\n", "# features must use word_vec_size", "\n", "            ", "if", "feat_vec_exponent", "!=", "0.7", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"Merging with sum, but got non-default \"", "\n", "\"feat_vec_exponent. It will be unused.\"", ")", "\n", "", "if", "feat_vec_size", "!=", "-", "1", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"Merging with sum, but got non-default \"", "\n", "\"feat_vec_size. It will be unused.\"", ")", "\n", "", "", "elif", "feat_vec_size", ">", "0", ":", "\n", "# features will use feat_vec_size", "\n", "            ", "if", "feat_vec_exponent", "!=", "-", "1", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"Not merging with sum and positive \"", "\n", "\"feat_vec_size, but got non-default \"", "\n", "\"feat_vec_exponent. It will be unused.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "feat_vec_exponent", "<=", "0", ":", "\n", "                ", "raise", "ValueError", "(", "\"Using feat_vec_exponent to determine \"", "\n", "\"feature vec size, but got feat_vec_exponent \"", "\n", "\"less than or equal to 0.\"", ")", "\n", "", "", "n_feats", "=", "len", "(", "feat_vocab_sizes", ")", "\n", "if", "n_feats", "!=", "len", "(", "feat_padding_idx", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Got unequal number of feat_vocab_sizes and \"", "\n", "\"feat_padding_idx ({:d} != {:d})\"", ".", "format", "(", "\n", "n_feats", ",", "len", "(", "feat_padding_idx", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.embeddings.Embeddings.word_lut": [[269, 273], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "word_lut", "(", "self", ")", ":", "\n", "        ", "\"\"\"Word look-up table.\"\"\"", "\n", "return", "self", ".", "make_embedding", "[", "0", "]", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.embeddings.Embeddings.emb_luts": [[274, 278], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "emb_luts", "(", "self", ")", ":", "\n", "        ", "\"\"\"Embedding look-up table.\"\"\"", "\n", "return", "self", ".", "make_embedding", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.embeddings.Embeddings.change_word_lut": [[279, 283], ["embeddings.NothingEncoding", "[].set_return"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.embeddings.NothingEncoding.set_return"], ["", "def", "change_word_lut", "(", "self", ",", "input_embeds", ")", ":", "\n", "        ", "self", ".", "old_word_lut", "=", "self", ".", "word_lut", "\n", "self", ".", "make_embedding", "[", "0", "]", "[", "0", "]", "=", "NothingEncoding", "(", ")", "\n", "self", ".", "make_embedding", "[", "0", "]", "[", "0", "]", ".", "set_return", "(", "input_embeds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.embeddings.Embeddings.reset_word_lut": [[284, 286], ["None"], "methods", ["None"], ["", "def", "reset_word_lut", "(", "self", ")", ":", "\n", "        ", "self", ".", "make_embedding", "[", "0", "]", "[", "0", "]", "=", "self", ".", "old_word_lut", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.embeddings.Embeddings.load_pretrained_vectors": [[287, 304], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load.size", "torch.load.size", "embeddings.Embeddings.word_lut.weight.data.copy_", "embeddings.Embeddings.word_lut.weight.data.copy_"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "emb_file", ")", ":", "\n", "        ", "\"\"\"Load in pretrained embeddings.\n\n        Args:\n          emb_file (str) : path to torch serialized embeddings\n        \"\"\"", "\n", "\n", "if", "emb_file", ":", "\n", "            ", "pretrained", "=", "torch", ".", "load", "(", "emb_file", ")", "\n", "pretrained_vec_size", "=", "pretrained", ".", "size", "(", "1", ")", "\n", "if", "self", ".", "word_vec_size", ">", "pretrained_vec_size", ":", "\n", "                ", "self", ".", "word_lut", ".", "weight", ".", "data", "[", ":", ",", ":", "pretrained_vec_size", "]", "=", "pretrained", "\n", "", "elif", "self", ".", "word_vec_size", "<", "pretrained_vec_size", ":", "\n", "                ", "self", ".", "word_lut", ".", "weight", ".", "data", ".", "copy_", "(", "pretrained", "[", ":", ",", ":", "self", ".", "word_vec_size", "]", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "word_lut", ".", "weight", ".", "data", ".", "copy_", "(", "pretrained", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.embeddings.Embeddings.forward": [[305, 363], ["embeddings.Embeddings.change_word_lut", "enumerate", "embeddings.Embeddings.make_embedding", "source[].transpose", "source[].transpose.size", "source[].transpose.data.eq().unsqueeze", "module.transpose().contiguous", "enumerate", "embeddings.Embeddings.reset_word_lut", "embeddings.Embeddings.make_embedding._modules.values", "embeddings.Embeddings.gpt_model._init_cache", "torch.functional.softmax", "torch.functional.softmax", "layer.transpose().contiguous", "module", "module", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "source[].transpose.data.eq", "module.transpose().contiguous", "module.transpose", "layer", "layer", "elmo_representation.transpose().contiguous", "len", "layer.transpose", "embeddings.Embeddings.make_embedding._modules.values", "module.transpose", "elmo_representation.transpose"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.embeddings.Embeddings.change_word_lut", "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.embeddings.Embeddings.reset_word_lut", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerDecoder._init_cache"], ["", "", "", "def", "forward", "(", "self", ",", "source", ",", "step", "=", "None", ",", "offset", "=", "None", ",", "input_embeds", "=", "None", ")", ":", "\n", "        ", "\"\"\"Computes the embeddings for words and features.\n\n        Args:\n            source (LongTensor): index tensor ``(len, batch, nfeat)``\n\n        Returns:\n            FloatTensor: Word embeddings ``(len, batch, embedding_size)``\n        \"\"\"", "\n", "\n", "emb", "=", "source", "\n", "if", "input_embeds", "is", "not", "None", ":", "\n", "            ", "self", ".", "change_word_lut", "(", "input_embeds", ")", "\n", "\n", "", "if", "self", ".", "position_encoding", ":", "\n", "            ", "for", "i", ",", "module", "in", "enumerate", "(", "self", ".", "make_embedding", ".", "_modules", ".", "values", "(", ")", ")", ":", "\n", "                ", "if", "i", "==", "len", "(", "self", ".", "make_embedding", ".", "_modules", ".", "values", "(", ")", ")", "-", "1", ":", "\n", "                    ", "emb", "=", "module", "(", "emb", ",", "step", "=", "step", ",", "offset", "=", "offset", ")", "\n", "", "else", ":", "\n", "                    ", "emb", "=", "module", "(", "emb", ")", "\n", "", "", "", "else", ":", "\n", "            ", "emb", "=", "self", ".", "make_embedding", "(", "emb", ")", "\n", "\n", "", "if", "self", ".", "GPT_representation_mode", "!=", "'none'", ":", "\n", "            ", "if", "self", ".", "GPT_representation_tgt", "and", "step", "==", "0", ":", "\n", "# Need to initialize cache for self attn layers", "\n", "                ", "self", ".", "gpt_model", ".", "_init_cache", "(", "torch", ".", "zeros", "(", "(", "source", ".", "shape", "[", "0", "]", ",", "source", ".", "shape", "[", "1", "]", ",", "1", ")", ",", "dtype", "=", "emb", ".", "dtype", ",", "device", "=", "emb", ".", "device", ")", ")", "\n", "self", ".", "gpt_model", ".", "state", "[", "'src'", "]", "=", "None", "\n", "\n", "", "words", "=", "source", "[", ":", ",", ":", ",", "0", "]", ".", "transpose", "(", "0", ",", "1", ")", "\n", "w_batch", ",", "w_len", "=", "words", ".", "size", "(", ")", "\n", "mask", "=", "words", ".", "data", ".", "eq", "(", "self", ".", "word_padding_idx", ")", ".", "unsqueeze", "(", "1", ")", "# [B, 1, T]", "\n", "\n", "if", "self", ".", "GPT_representation_mode", "==", "'elmo'", ":", "\n", "                ", "layer_weights", "=", "nn", ".", "functional", ".", "softmax", "(", "self", ".", "elmo_scale_params", ",", "dim", "=", "0", ")", "\n", "elmo_representation", "=", "layer_weights", "[", "0", "]", "*", "emb", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Run the forward pass of every layer of the tranformer.", "\n", "", "out", "=", "emb", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "for", "layer_num", ",", "layer", "in", "enumerate", "(", "self", ".", "gpt_model", ".", "transformer_layers", ")", ":", "\n", "                ", "if", "self", ".", "GPT_representation_tgt", ":", "\n", "                    ", "layer_cache", "=", "self", ".", "gpt_model", ".", "state", "[", "\"cache\"", "]", "[", "\"layer_{}\"", ".", "format", "(", "layer_num", ")", "]", "if", "step", "is", "not", "None", "else", "None", "\n", "out", ",", "_", "=", "layer", "(", "out", ",", "None", ",", "None", ",", "mask", ",", "layer_cache", "=", "layer_cache", ",", "step", "=", "step", ")", "\n", "", "else", ":", "\n", "                    ", "out", "=", "layer", "(", "out", ",", "mask", ")", "\n", "\n", "", "if", "self", ".", "GPT_representation_mode", "==", "'elmo'", ":", "\n", "                    ", "elmo_representation", "+=", "layer_weights", "[", "layer_num", "+", "1", "]", "*", "out", "\n", "\n", "", "", "if", "self", ".", "GPT_representation_mode", "==", "'elmo'", ":", "\n", "                ", "emb", "=", "self", ".", "elmo_gamma_param", "*", "elmo_representation", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "                ", "emb", "=", "out", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "", "", "if", "input_embeds", "is", "not", "None", ":", "\n", "            ", "self", ".", "reset_word_lut", "(", ")", "\n", "", "return", "emb", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.weight_norm.WeightNormLinear.__init__": [[44, 61], ["torch.Linear.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "weight_norm.WeightNormLinear.register_buffer", "weight_norm.WeightNormLinear.register_buffer", "weight_norm.WeightNormLinear.register_buffer", "weight_norm.WeightNormLinear.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__", "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.weight_norm.WeightNormConvTranspose2d.reset_parameters"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "\n", "init_scale", "=", "1.", ",", "polyak_decay", "=", "0.9995", ")", ":", "\n", "        ", "super", "(", "WeightNormLinear", ",", "self", ")", ".", "__init__", "(", "\n", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "V", "=", "self", ".", "weight", "\n", "self", ".", "g", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ")", ")", "\n", "self", ".", "b", "=", "self", ".", "bias", "\n", "\n", "self", ".", "register_buffer", "(", "\n", "'V_avg'", ",", "torch", ".", "zeros", "(", "out_features", ",", "in_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'g_avg'", ",", "torch", ".", "zeros", "(", "out_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'b_avg'", ",", "torch", ".", "zeros", "(", "out_features", ")", ")", "\n", "\n", "self", ".", "init_scale", "=", "init_scale", "\n", "self", ".", "polyak_decay", "=", "polyak_decay", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.weight_norm.WeightNormLinear.reset_parameters": [[62, 64], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.weight_norm.WeightNormLinear.forward": [[65, 99], ["weight_norm.WeightNormLinear.V.data.copy_", "weight_norm.WeightNormLinear.g.data.copy_", "weight_norm.WeightNormLinear.b.data.copy_", "weight_norm.WeightNormLinear.V_avg.copy_", "weight_norm.WeightNormLinear.g_avg.copy_", "weight_norm.WeightNormLinear.b_avg.copy_", "weight_norm.get_vars_maybe_avg", "torch.linear", "torch.linear", "torch.linear", "weight_norm.WeightNormLinear.V.data.norm().expand_as", "torch.linear", "torch.linear", "torch.linear", "x_init.mean().squeeze", "x_init.var().squeeze", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "scale_init.view().expand_as", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "b.view().expand_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "m_init.view().expand_as", "scalar.view().expand_as", "weight_norm.WeightNormLinear.V.data.norm", "x_init.mean", "x_init.var", "scale_init.view", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "b.view", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "m_init.view", "scalar.view", "weight_norm.WeightNormLinear.V.data.size"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.weight_norm.get_vars_maybe_avg", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "forward", "(", "self", ",", "x", ",", "init", "=", "False", ")", ":", "\n", "        ", "if", "init", "is", "True", ":", "\n", "# out_features * in_features", "\n", "            ", "self", ".", "V", ".", "data", ".", "copy_", "(", "torch", ".", "randn", "(", "self", ".", "V", ".", "data", ".", "size", "(", ")", ")", ".", "type_as", "(", "\n", "self", ".", "V", ".", "data", ")", "*", "0.05", ")", "\n", "# norm is out_features * 1", "\n", "v_norm", "=", "self", ".", "V", ".", "data", "/", "self", ".", "V", ".", "data", ".", "norm", "(", "2", ",", "1", ")", ".", "expand_as", "(", "self", ".", "V", ".", "data", ")", "\n", "# batch_size * out_features", "\n", "x_init", "=", "F", ".", "linear", "(", "x", ",", "v_norm", ")", ".", "data", "\n", "# out_features", "\n", "m_init", ",", "v_init", "=", "x_init", ".", "mean", "(", "0", ")", ".", "squeeze", "(", "\n", "0", ")", ",", "x_init", ".", "var", "(", "0", ")", ".", "squeeze", "(", "0", ")", "\n", "# out_features", "\n", "scale_init", "=", "self", ".", "init_scale", "/", "torch", ".", "sqrt", "(", "v_init", "+", "1e-10", ")", "\n", "self", ".", "g", ".", "data", ".", "copy_", "(", "scale_init", ")", "\n", "self", ".", "b", ".", "data", ".", "copy_", "(", "-", "m_init", "*", "scale_init", ")", "\n", "x_init", "=", "scale_init", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x_init", ")", "*", "(", "x_init", "-", "m_init", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x_init", ")", ")", "\n", "self", ".", "V_avg", ".", "copy_", "(", "self", ".", "V", ".", "data", ")", "\n", "self", ".", "g_avg", ".", "copy_", "(", "self", ".", "g", ".", "data", ")", "\n", "self", ".", "b_avg", ".", "copy_", "(", "self", ".", "b", ".", "data", ")", "\n", "return", "x_init", "\n", "", "else", ":", "\n", "            ", "v", ",", "g", ",", "b", "=", "get_vars_maybe_avg", "(", "self", ",", "[", "'V'", ",", "'g'", ",", "'b'", "]", ",", "\n", "self", ".", "training", ",", "\n", "polyak_decay", "=", "self", ".", "polyak_decay", ")", "\n", "# batch_size * out_features", "\n", "x", "=", "F", ".", "linear", "(", "x", ",", "v", ")", "\n", "scalar", "=", "g", "/", "torch", ".", "norm", "(", "v", ",", "2", ",", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "x", "=", "scalar", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x", ")", "*", "x", "+", "b", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.weight_norm.WeightNormConv2d.__init__": [[102, 120], ["torch.Conv2d.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "weight_norm.WeightNormConv2d.register_buffer", "weight_norm.WeightNormConv2d.register_buffer", "weight_norm.WeightNormConv2d.register_buffer", "weight_norm.WeightNormConv2d.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "weight_norm.WeightNormConv2d.V.size"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__", "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.weight_norm.WeightNormConvTranspose2d.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "init_scale", "=", "1.", ",", "\n", "polyak_decay", "=", "0.9995", ")", ":", "\n", "        ", "super", "(", "WeightNormConv2d", ",", "self", ")", ".", "__init__", "(", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", ",", "stride", ",", "padding", ",", "\n", "dilation", ",", "groups", ")", "\n", "\n", "self", ".", "V", "=", "self", ".", "weight", "\n", "self", ".", "g", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "self", ".", "b", "=", "self", ".", "bias", "\n", "\n", "self", ".", "register_buffer", "(", "'V_avg'", ",", "torch", ".", "zeros", "(", "self", ".", "V", ".", "size", "(", ")", ")", ")", "\n", "self", ".", "register_buffer", "(", "'g_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "self", ".", "register_buffer", "(", "'b_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "\n", "self", ".", "init_scale", "=", "init_scale", "\n", "self", ".", "polyak_decay", "=", "polyak_decay", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.weight_norm.WeightNormConv2d.reset_parameters": [[121, 123], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.weight_norm.WeightNormConv2d.forward": [[124, 170], ["weight_norm.WeightNormConv2d.V.data.copy_", "x_init.transpose().contiguous().view", "weight_norm.WeightNormConv2d.g.data.copy_", "weight_norm.WeightNormConv2d.b.data.copy_", "scale_init.view", "m_init.view", "weight_norm.WeightNormConv2d.V_avg.copy_", "weight_norm.WeightNormConv2d.g_avg.copy_", "weight_norm.WeightNormConv2d.b_avg.copy_", "weight_norm.get_vars_maybe_avg", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.conv2d", "torch.conv2d", "torch.conv2d", "weight_norm.WeightNormConv2d.V.data.view().norm().view().expand_as", "torch.conv2d", "torch.conv2d", "torch.conv2d", "x_init.transpose().contiguous().view.mean().squeeze", "x_init.transpose().contiguous().view.var().squeeze", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "scale_init.view.expand_as", "v.view", "len", "torch.norm.view().expand_as", "torch.norm.view().expand_as", "torch.norm.view().expand_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "x_init.transpose().contiguous", "m_init.view.expand_as", "torch.norm.size", "torch.norm.size", "torch.norm.size", "torch.norm.squeeze", "torch.norm.squeeze", "torch.norm.squeeze", "weight_norm.WeightNormConv2d.V.data.view().norm().view", "x_init.transpose().contiguous().view.mean", "x_init.transpose().contiguous().view.var", "torch.norm.view", "torch.norm.view", "torch.norm.view", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "x_init.transpose", "len", "len", "weight_norm.WeightNormConv2d.V.data.size", "weight_norm.WeightNormConv2d.V.data.view().norm", "x_init.size", "x_init.size", "weight_norm.WeightNormConv2d.V.data.view", "len", "len", "v.size"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.weight_norm.get_vars_maybe_avg", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "forward", "(", "self", ",", "x", ",", "init", "=", "False", ")", ":", "\n", "        ", "if", "init", "is", "True", ":", "\n", "# out_channels, in_channels // groups, * kernel_size", "\n", "            ", "self", ".", "V", ".", "data", ".", "copy_", "(", "torch", ".", "randn", "(", "self", ".", "V", ".", "data", ".", "size", "(", ")", "\n", ")", ".", "type_as", "(", "self", ".", "V", ".", "data", ")", "*", "0.05", ")", "\n", "v_norm", "=", "self", ".", "V", ".", "data", "/", "self", ".", "V", ".", "data", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", ".", "norm", "(", "2", ",", "1", ")", ".", "view", "(", "self", ".", "out_channels", ",", "*", "(", "\n", "[", "1", "]", "*", "(", "len", "(", "self", ".", "kernel_size", ")", "+", "1", ")", ")", ")", ".", "expand_as", "(", "self", ".", "V", ".", "data", ")", "\n", "x_init", "=", "F", ".", "conv2d", "(", "x", ",", "v_norm", ",", "None", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", ".", "data", "\n", "t_x_init", "=", "x_init", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "out_channels", ",", "-", "1", ")", "\n", "m_init", ",", "v_init", "=", "t_x_init", ".", "mean", "(", "1", ")", ".", "squeeze", "(", "\n", "1", ")", ",", "t_x_init", ".", "var", "(", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "# out_features", "\n", "scale_init", "=", "self", ".", "init_scale", "/", "torch", ".", "sqrt", "(", "v_init", "+", "1e-10", ")", "\n", "self", ".", "g", ".", "data", ".", "copy_", "(", "scale_init", ")", "\n", "self", ".", "b", ".", "data", ".", "copy_", "(", "-", "m_init", "*", "scale_init", ")", "\n", "scale_init_shape", "=", "scale_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "m_init_shape", "=", "m_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "x_init", "=", "scale_init_shape", ".", "expand_as", "(", "\n", "x_init", ")", "*", "(", "x_init", "-", "m_init_shape", ".", "expand_as", "(", "x_init", ")", ")", "\n", "self", ".", "V_avg", ".", "copy_", "(", "self", ".", "V", ".", "data", ")", "\n", "self", ".", "g_avg", ".", "copy_", "(", "self", ".", "g", ".", "data", ")", "\n", "self", ".", "b_avg", ".", "copy_", "(", "self", ".", "b", ".", "data", ")", "\n", "return", "x_init", "\n", "", "else", ":", "\n", "            ", "v", ",", "g", ",", "b", "=", "get_vars_maybe_avg", "(", "\n", "self", ",", "[", "'V'", ",", "'g'", ",", "'b'", "]", ",", "self", ".", "training", ",", "\n", "polyak_decay", "=", "self", ".", "polyak_decay", ")", "\n", "\n", "scalar", "=", "torch", ".", "norm", "(", "v", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", ",", "2", ",", "1", ")", "\n", "if", "len", "(", "scalar", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "                ", "scalar", "=", "g", "/", "scalar", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "scalar", "=", "g", "/", "scalar", "\n", "\n", "", "w", "=", "scalar", ".", "view", "(", "self", ".", "out_channels", ",", "*", "\n", "(", "[", "1", "]", "*", "(", "len", "(", "v", ".", "size", "(", ")", ")", "-", "1", ")", ")", ")", ".", "expand_as", "(", "v", ")", "*", "v", "\n", "\n", "x", "=", "F", ".", "conv2d", "(", "x", ",", "w", ",", "b", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.weight_norm.WeightNormConvTranspose2d.__init__": [[175, 195], ["torch.ConvTranspose2d.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "weight_norm.WeightNormConvTranspose2d.register_buffer", "weight_norm.WeightNormConvTranspose2d.register_buffer", "weight_norm.WeightNormConvTranspose2d.register_buffer", "weight_norm.WeightNormConvTranspose2d.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "weight_norm.WeightNormConvTranspose2d.V.size"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__", "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.weight_norm.WeightNormConvTranspose2d.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "output_padding", "=", "0", ",", "groups", "=", "1", ",", "init_scale", "=", "1.", ",", "\n", "polyak_decay", "=", "0.9995", ")", ":", "\n", "        ", "super", "(", "WeightNormConvTranspose2d", ",", "self", ")", ".", "__init__", "(", "\n", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", ",", "stride", ",", "\n", "padding", ",", "output_padding", ",", "\n", "groups", ")", "\n", "# in_channels, out_channels, *kernel_size", "\n", "self", ".", "V", "=", "self", ".", "weight", "\n", "self", ".", "g", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "self", ".", "b", "=", "self", ".", "bias", "\n", "\n", "self", ".", "register_buffer", "(", "'V_avg'", ",", "torch", ".", "zeros", "(", "self", ".", "V", ".", "size", "(", ")", ")", ")", "\n", "self", ".", "register_buffer", "(", "'g_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "self", ".", "register_buffer", "(", "'b_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "\n", "self", ".", "init_scale", "=", "init_scale", "\n", "self", ".", "polyak_decay", "=", "polyak_decay", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.weight_norm.WeightNormConvTranspose2d.reset_parameters": [[196, 198], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.weight_norm.WeightNormConvTranspose2d.forward": [[199, 247], ["weight_norm.WeightNormConvTranspose2d.V.data.copy_", "x_init.tranpose().contiguous().view", "weight_norm.WeightNormConvTranspose2d.g.data.copy_", "weight_norm.WeightNormConvTranspose2d.b.data.copy_", "scale_init.view", "m_init.view", "weight_norm.WeightNormConvTranspose2d.V_avg.copy_", "weight_norm.WeightNormConvTranspose2d.g_avg.copy_", "weight_norm.WeightNormConvTranspose2d.b_avg.copy_", "weight_norm.get_vars_maybe_avg", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view().norm().view().expand_as", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "x_init.tranpose().contiguous().view.mean().squeeze", "x_init.tranpose().contiguous().view.var().squeeze", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "scale_init.view.expand_as", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "scalar.view().expand_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "x_init.tranpose().contiguous", "m_init.view.expand_as", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view().norm().view", "x_init.tranpose().contiguous().view.mean", "x_init.tranpose().contiguous().view.var", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "scalar.view", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "x_init.tranpose", "len", "len", "v.transpose().contiguous().view", "weight_norm.WeightNormConvTranspose2d.V.data.size", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view().norm", "x_init.size", "x_init.size", "len", "v.transpose().contiguous", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view", "len", "v.transpose", "v.size", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous", "weight_norm.WeightNormConvTranspose2d.V.data.transpose"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.weight_norm.get_vars_maybe_avg", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "forward", "(", "self", ",", "x", ",", "init", "=", "False", ")", ":", "\n", "        ", "if", "init", "is", "True", ":", "\n", "# in_channels, out_channels, *kernel_size", "\n", "            ", "self", ".", "V", ".", "data", ".", "copy_", "(", "torch", ".", "randn", "(", "self", ".", "V", ".", "data", ".", "size", "(", ")", ")", ".", "type_as", "(", "\n", "self", ".", "V", ".", "data", ")", "*", "0.05", ")", "\n", "v_norm", "=", "self", ".", "V", ".", "data", "/", "self", ".", "V", ".", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", ".", "norm", "(", "2", ",", "1", ")", ".", "view", "(", "\n", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "\n", "*", "(", "[", "1", "]", "*", "len", "(", "self", ".", "kernel_size", ")", ")", ")", ".", "expand_as", "(", "self", ".", "V", ".", "data", ")", "\n", "x_init", "=", "F", ".", "conv_transpose2d", "(", "\n", "x", ",", "v_norm", ",", "None", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "output_padding", ",", "self", ".", "groups", ")", ".", "data", "\n", "# self.out_channels, 1", "\n", "t_x_init", "=", "x_init", ".", "tranpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "out_channels", ",", "-", "1", ")", "\n", "# out_features", "\n", "m_init", ",", "v_init", "=", "t_x_init", ".", "mean", "(", "1", ")", ".", "squeeze", "(", "\n", "1", ")", ",", "t_x_init", ".", "var", "(", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "# out_features", "\n", "scale_init", "=", "self", ".", "init_scale", "/", "torch", ".", "sqrt", "(", "v_init", "+", "1e-10", ")", "\n", "self", ".", "g", ".", "data", ".", "copy_", "(", "scale_init", ")", "\n", "self", ".", "b", ".", "data", ".", "copy_", "(", "-", "m_init", "*", "scale_init", ")", "\n", "scale_init_shape", "=", "scale_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "m_init_shape", "=", "m_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "\n", "x_init", "=", "scale_init_shape", ".", "expand_as", "(", "x_init", ")", "*", "(", "x_init", "-", "m_init_shape", ".", "expand_as", "(", "x_init", ")", ")", "\n", "self", ".", "V_avg", ".", "copy_", "(", "self", ".", "V", ".", "data", ")", "\n", "self", ".", "g_avg", ".", "copy_", "(", "self", ".", "g", ".", "data", ")", "\n", "self", ".", "b_avg", ".", "copy_", "(", "self", ".", "b", ".", "data", ")", "\n", "return", "x_init", "\n", "", "else", ":", "\n", "            ", "v", ",", "g", ",", "b", "=", "get_vars_maybe_avg", "(", "\n", "self", ",", "[", "'V'", ",", "'g'", ",", "'b'", "]", ",", "self", ".", "training", ",", "\n", "polyak_decay", "=", "self", ".", "polyak_decay", ")", "\n", "scalar", "=", "g", "/", "torch", ".", "norm", "(", "v", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "out_channels", ",", "-", "1", ")", ",", "2", ",", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "w", "=", "scalar", ".", "view", "(", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "\n", "*", "(", "[", "1", "]", "*", "(", "len", "(", "v", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", ".", "expand_as", "(", "v", ")", "*", "v", "\n", "\n", "x", "=", "F", ".", "conv_transpose2d", "(", "x", ",", "w", ",", "b", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "output_padding", ",", "\n", "self", ".", "groups", ")", "\n", "return", "x", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.weight_norm.get_var_maybe_avg": [[8, 20], ["getattr", "getattr"], "function", ["None"], ["def", "get_var_maybe_avg", "(", "namespace", ",", "var_name", ",", "training", ",", "polyak_decay", ")", ":", "\n", "    ", "\"\"\" utility for retrieving polyak averaged params\n        Update average\n    \"\"\"", "\n", "v", "=", "getattr", "(", "namespace", ",", "var_name", ")", "\n", "v_avg", "=", "getattr", "(", "namespace", ",", "var_name", "+", "'_avg'", ")", "\n", "v_avg", "-=", "(", "1", "-", "polyak_decay", ")", "*", "(", "v_avg", "-", "v", ".", "data", ")", "\n", "\n", "if", "training", ":", "\n", "        ", "return", "v", "\n", "", "else", ":", "\n", "        ", "return", "v_avg", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.weight_norm.get_vars_maybe_avg": [[22, 29], ["vars.append", "weight_norm.get_var_maybe_avg"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.weight_norm.get_var_maybe_avg"], ["", "", "def", "get_vars_maybe_avg", "(", "namespace", ",", "var_names", ",", "training", ",", "polyak_decay", ")", ":", "\n", "    ", "\"\"\" utility for retrieving polyak averaged params \"\"\"", "\n", "vars", "=", "[", "]", "\n", "for", "vn", "in", "var_names", ":", "\n", "        ", "vars", ".", "append", "(", "get_var_maybe_avg", "(", "\n", "namespace", ",", "vn", ",", "training", ",", "polyak_decay", ")", ")", "\n", "", "return", "vars", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.sparse_activations.SparsemaxFunction.forward": [[45, 63], ["input.max", "sparse_activations._threshold_and_support", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "ctx.save_for_backward"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.sparse_activations._threshold_and_support"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "dim", "=", "0", ")", ":", "\n", "        ", "\"\"\"sparsemax: normalizing sparse transform (a la softmax)\n\n        Parameters:\n            input (Tensor): any shape\n            dim: dimension along which to apply sparsemax\n\n        Returns:\n            output (Tensor): same shape as input\n        \"\"\"", "\n", "ctx", ".", "dim", "=", "dim", "\n", "max_val", ",", "_", "=", "input", ".", "max", "(", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "\n", "input", "-=", "max_val", "# same numerical stability trick as for softmax", "\n", "tau", ",", "supp_size", "=", "_threshold_and_support", "(", "input", ",", "dim", "=", "dim", ")", "\n", "output", "=", "torch", ".", "clamp", "(", "input", "-", "tau", ",", "min", "=", "0", ")", "\n", "ctx", ".", "save_for_backward", "(", "supp_size", ",", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.sparse_activations.SparsemaxFunction.backward": [[64, 75], ["grad_output.clone", "v_hat.unsqueeze.unsqueeze.unsqueeze", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where.sum", "torch.where.sum", "supp_size.to().squeeze", "supp_size.to"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "supp_size", ",", "output", "=", "ctx", ".", "saved_tensors", "\n", "dim", "=", "ctx", ".", "dim", "\n", "grad_input", "=", "grad_output", ".", "clone", "(", ")", "\n", "grad_input", "[", "output", "==", "0", "]", "=", "0", "\n", "\n", "v_hat", "=", "grad_input", ".", "sum", "(", "dim", "=", "dim", ")", "/", "supp_size", ".", "to", "(", "output", ".", "dtype", ")", ".", "squeeze", "(", ")", "\n", "v_hat", "=", "v_hat", ".", "unsqueeze", "(", "dim", ")", "\n", "grad_input", "=", "torch", ".", "where", "(", "output", "!=", "0", ",", "grad_input", "-", "v_hat", ",", "grad_input", ")", "\n", "return", "grad_input", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.sparse_activations.Sparsemax.__init__": [[82, 85], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", "=", "0", ")", ":", "\n", "        ", "self", ".", "dim", "=", "dim", "\n", "super", "(", "Sparsemax", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.sparse_activations.Sparsemax.forward": [[86, 88], ["sparsemax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "sparsemax", "(", "input", ",", "self", ".", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.sparse_activations.LogSparsemax.__init__": [[92, 95], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", "=", "0", ")", ":", "\n", "        ", "self", ".", "dim", "=", "dim", "\n", "super", "(", "LogSparsemax", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.sparse_activations.LogSparsemax.forward": [[96, 98], ["torch.log", "torch.log", "torch.log", "torch.log", "sparsemax"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "torch", ".", "log", "(", "sparsemax", "(", "input", ",", "self", ".", "dim", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.sparse_activations._make_ix_like": [[13, 19], ["input.size", "torch.arange", "torch.arange", "torch.arange.view().transpose", "input.dim", "torch.arange.view"], "function", ["None"], ["def", "_make_ix_like", "(", "input", ",", "dim", "=", "0", ")", ":", "\n", "    ", "d", "=", "input", ".", "size", "(", "dim", ")", "\n", "rho", "=", "torch", ".", "arange", "(", "1", ",", "d", "+", "1", ",", "device", "=", "input", ".", "device", ",", "dtype", "=", "input", ".", "dtype", ")", "\n", "view", "=", "[", "1", "]", "*", "input", ".", "dim", "(", ")", "\n", "view", "[", "0", "]", "=", "-", "1", "\n", "return", "rho", ".", "view", "(", "view", ")", ".", "transpose", "(", "0", ",", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.sparse_activations._threshold_and_support": [[21, 41], ["torch.sort", "torch.sort", "sparse_activations._make_ix_like", "support.sum().unsqueeze", "input_cumsum.gather", "support.sum().unsqueeze.to", "input_srt.cumsum", "support.sum"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.sparse_activations._make_ix_like"], ["", "def", "_threshold_and_support", "(", "input", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\"Sparsemax building block: compute the threshold\n\n    Args:\n        input: any dimension\n        dim: dimension along which to apply the sparsemax\n\n    Returns:\n        the threshold value\n    \"\"\"", "\n", "\n", "input_srt", ",", "_", "=", "torch", ".", "sort", "(", "input", ",", "descending", "=", "True", ",", "dim", "=", "dim", ")", "\n", "input_cumsum", "=", "input_srt", ".", "cumsum", "(", "dim", ")", "-", "1", "\n", "rhos", "=", "_make_ix_like", "(", "input", ",", "dim", ")", "\n", "support", "=", "rhos", "*", "input_srt", ">", "input_cumsum", "\n", "\n", "support_size", "=", "support", ".", "sum", "(", "dim", "=", "dim", ")", ".", "unsqueeze", "(", "dim", ")", "\n", "tau", "=", "input_cumsum", ".", "gather", "(", "dim", ",", "support_size", "-", "1", ")", "\n", "tau", "/=", "support_size", ".", "to", "(", "input", ".", "dtype", ")", "\n", "return", "tau", ",", "support_size", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.global_attention.GlobalAttention.__init__": [[71, 96], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "coverage", "=", "False", ",", "attn_type", "=", "\"dot\"", ",", "\n", "attn_func", "=", "\"softmax\"", ")", ":", "\n", "        ", "super", "(", "GlobalAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dim", "=", "dim", "\n", "assert", "attn_type", "in", "[", "\"dot\"", ",", "\"general\"", ",", "\"mlp\"", "]", ",", "(", "\n", "\"Please select a valid attention type (got {:s}).\"", ".", "format", "(", "\n", "attn_type", ")", ")", "\n", "self", ".", "attn_type", "=", "attn_type", "\n", "assert", "attn_func", "in", "[", "\"softmax\"", ",", "\"sparsemax\"", "]", ",", "(", "\n", "\"Please select a valid attention function.\"", ")", "\n", "self", ".", "attn_func", "=", "attn_func", "\n", "\n", "if", "self", ".", "attn_type", "==", "\"general\"", ":", "\n", "            ", "self", ".", "linear_in", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "", "elif", "self", ".", "attn_type", "==", "\"mlp\"", ":", "\n", "            ", "self", ".", "linear_context", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_query", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "v", "=", "nn", ".", "Linear", "(", "dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "# mlp wants it with bias", "\n", "", "out_bias", "=", "self", ".", "attn_type", "==", "\"mlp\"", "\n", "self", ".", "linear_out", "=", "nn", ".", "Linear", "(", "dim", "*", "2", ",", "dim", ",", "bias", "=", "out_bias", ")", "\n", "\n", "if", "coverage", ":", "\n", "            ", "self", ".", "linear_cover", "=", "nn", ".", "Linear", "(", "1", ",", "dim", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.global_attention.GlobalAttention.score": [[97, 137], ["h_s.size", "global_attention.GlobalAttention.view.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "h_s.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "global_attention.GlobalAttention.linear_query", "wq.expand.expand.view", "wq.expand.expand.expand", "global_attention.GlobalAttention.linear_context", "uh.expand.expand.view", "uh.expand.expand.expand", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "global_attention.GlobalAttention.v().view", "global_attention.GlobalAttention.view.view", "global_attention.GlobalAttention.linear_in", "global_attention.GlobalAttention.view", "global_attention.GlobalAttention.view.view", "h_s.contiguous().view", "global_attention.GlobalAttention.v", "h_s.contiguous", "torch.tanh.view", "torch.tanh.view", "torch.tanh.view"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq"], ["", "", "def", "score", "(", "self", ",", "h_t", ",", "h_s", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n          h_t (FloatTensor): sequence of queries ``(batch, tgt_len, dim)``\n          h_s (FloatTensor): sequence of sources ``(batch, src_len, dim``\n\n        Returns:\n          FloatTensor: raw attention scores (unnormalized) for each src index\n            ``(batch, tgt_len, src_len)``\n        \"\"\"", "\n", "\n", "# Check input sizes", "\n", "src_batch", ",", "src_len", ",", "src_dim", "=", "h_s", ".", "size", "(", ")", "\n", "tgt_batch", ",", "tgt_len", ",", "tgt_dim", "=", "h_t", ".", "size", "(", ")", "\n", "aeq", "(", "src_batch", ",", "tgt_batch", ")", "\n", "aeq", "(", "src_dim", ",", "tgt_dim", ")", "\n", "aeq", "(", "self", ".", "dim", ",", "src_dim", ")", "\n", "\n", "if", "self", ".", "attn_type", "in", "[", "\"general\"", ",", "\"dot\"", "]", ":", "\n", "            ", "if", "self", ".", "attn_type", "==", "\"general\"", ":", "\n", "                ", "h_t_", "=", "h_t", ".", "view", "(", "tgt_batch", "*", "tgt_len", ",", "tgt_dim", ")", "\n", "h_t_", "=", "self", ".", "linear_in", "(", "h_t_", ")", "\n", "h_t", "=", "h_t_", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "tgt_dim", ")", "\n", "", "h_s_", "=", "h_s", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# (batch, t_len, d) x (batch, d, s_len) --> (batch, t_len, s_len)", "\n", "return", "torch", ".", "bmm", "(", "h_t", ",", "h_s_", ")", "\n", "", "else", ":", "\n", "            ", "dim", "=", "self", ".", "dim", "\n", "wq", "=", "self", ".", "linear_query", "(", "h_t", ".", "view", "(", "-", "1", ",", "dim", ")", ")", "\n", "wq", "=", "wq", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "1", ",", "dim", ")", "\n", "wq", "=", "wq", ".", "expand", "(", "tgt_batch", ",", "tgt_len", ",", "src_len", ",", "dim", ")", "\n", "\n", "uh", "=", "self", ".", "linear_context", "(", "h_s", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "dim", ")", ")", "\n", "uh", "=", "uh", ".", "view", "(", "src_batch", ",", "1", ",", "src_len", ",", "dim", ")", "\n", "uh", "=", "uh", ".", "expand", "(", "src_batch", ",", "tgt_len", ",", "src_len", ",", "dim", ")", "\n", "\n", "# (batch, t_len, s_len, d)", "\n", "wquh", "=", "torch", ".", "tanh", "(", "wq", "+", "uh", ")", "\n", "\n", "return", "self", ".", "v", "(", "wquh", ".", "view", "(", "-", "1", ",", "dim", ")", ")", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "src_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.global_attention.GlobalAttention.forward": [[138, 228], ["torch.tanh.size", "torch.tanh.size", "torch.tanh.size", "source.unsqueeze.unsqueeze.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "global_attention.GlobalAttention.score", "align_vectors.transpose().contiguous.transpose().contiguous.view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "global_attention.GlobalAttention.linear_out().view", "source.unsqueeze.unsqueeze.dim", "source.unsqueeze.unsqueeze.unsqueeze", "coverage.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "coverage.view().unsqueeze", "global_attention.GlobalAttention.linear_cover().view_as", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "onmt.utils.misc.sequence_mask", "mask.unsqueeze.unsqueeze.unsqueeze", "global_attention.GlobalAttention.masked_fill_", "torch.softmax", "torch.softmax", "torch.softmax", "onmt.modules.sparse_activations.sparsemax", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "attn_h.transpose().contiguous.transpose().contiguous.squeeze", "align_vectors.transpose().contiguous.transpose().contiguous.squeeze", "attn_h.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "align_vectors.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "attn_h.transpose().contiguous.transpose().contiguous.transpose().contiguous", "align_vectors.transpose().contiguous.transpose().contiguous.transpose().contiguous", "attn_h.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "align_vectors.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "global_attention.GlobalAttention.view", "global_attention.GlobalAttention.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "global_attention.GlobalAttention.linear_out", "coverage.view", "global_attention.GlobalAttention.linear_cover", "global_attention.GlobalAttention.size", "float", "attn_h.transpose().contiguous.transpose().contiguous.transpose", "align_vectors.transpose().contiguous.transpose().contiguous.transpose"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.GlobalScorerStub.score", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.sequence_mask", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq"], ["", "", "def", "forward", "(", "self", ",", "source", ",", "memory_bank", ",", "memory_lengths", "=", "None", ",", "coverage", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n          source (FloatTensor): query vectors ``(batch, tgt_len, dim)``\n          memory_bank (FloatTensor): source vectors ``(batch, src_len, dim)``\n          memory_lengths (LongTensor): the source context lengths ``(batch,)``\n          coverage (FloatTensor): None (not supported yet)\n\n        Returns:\n          (FloatTensor, FloatTensor):\n\n          * Computed vector ``(tgt_len, batch, dim)``\n          * Attention distribtutions for each query\n            ``(tgt_len, batch, src_len)``\n        \"\"\"", "\n", "\n", "# one step input", "\n", "if", "source", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "one_step", "=", "True", "\n", "source", "=", "source", ".", "unsqueeze", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "one_step", "=", "False", "\n", "\n", "", "batch", ",", "source_l", ",", "dim", "=", "memory_bank", ".", "size", "(", ")", "\n", "batch_", ",", "target_l", ",", "dim_", "=", "source", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "dim", ",", "dim_", ")", "\n", "aeq", "(", "self", ".", "dim", ",", "dim", ")", "\n", "if", "coverage", "is", "not", "None", ":", "\n", "            ", "batch_", ",", "source_l_", "=", "coverage", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "source_l", ",", "source_l_", ")", "\n", "\n", "", "if", "coverage", "is", "not", "None", ":", "\n", "            ", "cover", "=", "coverage", ".", "view", "(", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "memory_bank", "+=", "self", ".", "linear_cover", "(", "cover", ")", ".", "view_as", "(", "memory_bank", ")", "\n", "memory_bank", "=", "torch", ".", "tanh", "(", "memory_bank", ")", "\n", "\n", "# compute attention scores, as in Luong et al.", "\n", "", "align", "=", "self", ".", "score", "(", "source", ",", "memory_bank", ")", "\n", "\n", "if", "memory_lengths", "is", "not", "None", ":", "\n", "            ", "mask", "=", "sequence_mask", "(", "memory_lengths", ",", "max_len", "=", "align", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "# Make it broadcastable.", "\n", "align", ".", "masked_fill_", "(", "1", "-", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "# Softmax or sparsemax to normalize attention weights", "\n", "", "if", "self", ".", "attn_func", "==", "\"softmax\"", ":", "\n", "            ", "align_vectors", "=", "F", ".", "softmax", "(", "align", ".", "view", "(", "batch", "*", "target_l", ",", "source_l", ")", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "align_vectors", "=", "sparsemax", "(", "align", ".", "view", "(", "batch", "*", "target_l", ",", "source_l", ")", ",", "-", "1", ")", "\n", "", "align_vectors", "=", "align_vectors", ".", "view", "(", "batch", ",", "target_l", ",", "source_l", ")", "\n", "\n", "# each context vector c_t is the weighted average", "\n", "# over all the source hidden states", "\n", "c", "=", "torch", ".", "bmm", "(", "align_vectors", ",", "memory_bank", ")", "\n", "\n", "# concatenate", "\n", "concat_c", "=", "torch", ".", "cat", "(", "[", "c", ",", "source", "]", ",", "2", ")", ".", "view", "(", "batch", "*", "target_l", ",", "dim", "*", "2", ")", "\n", "attn_h", "=", "self", ".", "linear_out", "(", "concat_c", ")", ".", "view", "(", "batch", ",", "target_l", ",", "dim", ")", "\n", "if", "self", ".", "attn_type", "in", "[", "\"general\"", ",", "\"dot\"", "]", ":", "\n", "            ", "attn_h", "=", "torch", ".", "tanh", "(", "attn_h", ")", "\n", "\n", "", "if", "one_step", ":", "\n", "            ", "attn_h", "=", "attn_h", ".", "squeeze", "(", "1", ")", "\n", "align_vectors", "=", "align_vectors", ".", "squeeze", "(", "1", ")", "\n", "\n", "# Check output sizes", "\n", "batch_", ",", "dim_", "=", "attn_h", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "dim", ",", "dim_", ")", "\n", "batch_", ",", "source_l_", "=", "align_vectors", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "source_l", ",", "source_l_", ")", "\n", "\n", "", "else", ":", "\n", "            ", "attn_h", "=", "attn_h", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "align_vectors", "=", "align_vectors", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# Check output sizes", "\n", "target_l_", ",", "batch_", ",", "dim_", "=", "attn_h", ".", "size", "(", ")", "\n", "aeq", "(", "target_l", ",", "target_l_", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "dim", ",", "dim_", ")", "\n", "target_l_", ",", "batch_", ",", "source_l_", "=", "align_vectors", ".", "size", "(", ")", "\n", "aeq", "(", "target_l", ",", "target_l_", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "source_l", ",", "source_l_", ")", "\n", "\n", "", "return", "attn_h", ",", "align_vectors", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.gate.ContextGate.__init__": [[29, 38], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "ContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "input_size", "=", "embeddings_size", "+", "decoder_size", "+", "attention_size", "\n", "self", ".", "gate", "=", "nn", ".", "Linear", "(", "input_size", ",", "output_size", ",", "bias", "=", "True", ")", "\n", "self", ".", "sig", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "source_proj", "=", "nn", ".", "Linear", "(", "attention_size", ",", "output_size", ")", "\n", "self", ".", "target_proj", "=", "nn", ".", "Linear", "(", "embeddings_size", "+", "decoder_size", ",", "\n", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.gate.ContextGate.forward": [[39, 46], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "gate.ContextGate.sig", "gate.ContextGate.source_proj", "gate.ContextGate.target_proj", "gate.ContextGate.gate", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "input_tensor", "=", "torch", ".", "cat", "(", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ",", "dim", "=", "1", ")", "\n", "z", "=", "self", ".", "sig", "(", "self", ".", "gate", "(", "input_tensor", ")", ")", "\n", "proj_source", "=", "self", ".", "source_proj", "(", "attn_state", ")", "\n", "proj_target", "=", "self", ".", "target_proj", "(", "\n", "torch", ".", "cat", "(", "(", "prev_emb", ",", "dec_state", ")", ",", "dim", "=", "1", ")", ")", "\n", "return", "z", ",", "proj_source", ",", "proj_target", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.gate.SourceContextGate.__init__": [[51, 57], ["torch.Module.__init__", "gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "SourceContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.gate.SourceContextGate.forward": [[58, 62], ["gate.SourceContextGate.context_gate", "gate.SourceContextGate.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "\n", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "self", ".", "tanh", "(", "target", "+", "z", "*", "source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.gate.TargetContextGate.__init__": [[67, 73], ["torch.Module.__init__", "gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "TargetContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.gate.TargetContextGate.forward": [[74, 77], ["gate.TargetContextGate.context_gate", "gate.TargetContextGate.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "self", ".", "tanh", "(", "z", "*", "target", "+", "source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.gate.BothContextGate.__init__": [[82, 88], ["torch.Module.__init__", "gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "BothContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.gate.BothContextGate.forward": [[89, 92], ["gate.BothContextGate.context_gate", "gate.BothContextGate.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "self", ".", "tanh", "(", "(", "1.", "-", "z", ")", "*", "target", "+", "z", "*", "source", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.gate.context_gate_factory": [[6, 18], ["None"], "function", ["None"], ["def", "context_gate_factory", "(", "gate_type", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "    ", "\"\"\"Returns the correct ContextGate class\"\"\"", "\n", "\n", "gate_types", "=", "{", "'source'", ":", "SourceContextGate", ",", "\n", "'target'", ":", "TargetContextGate", ",", "\n", "'both'", ":", "BothContextGate", "}", "\n", "\n", "assert", "gate_type", "in", "gate_types", ",", "\"Not valid ContextGate type: {0}\"", ".", "format", "(", "\n", "gate_type", ")", "\n", "return", "gate_types", "[", "gate_type", "]", "(", "embeddings_size", ",", "decoder_size", ",", "attention_size", ",", "\n", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.rnn_uncond.RNNUncondDecoder.__init__": [[58, 78], ["onmt.decoders.decoder.DecoderBase.__init__", "torch.Dropout", "torch.Dropout", "rnn_uncond.RNNUncondDecoder._build_rnn"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.decoder.InputFeedRNNDecoder._build_rnn"], ["def", "__init__", "(", "self", ",", "rnn_type", ",", "num_layers", ",", "\n", "hidden_size", ",", "dropout", "=", "0.0", ",", "embeddings", "=", "None", ")", ":", "\n", "        ", "super", "(", "RNNUncondDecoder", ",", "self", ")", ".", "__init__", "(", "attentional", "=", "False", ")", "\n", "if", "rnn_type", "==", "'GRU'", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "# Decoder state", "\n", "self", ".", "state", "=", "{", "}", "\n", "\n", "# Build the RNN.", "\n", "self", ".", "rnn", "=", "self", ".", "_build_rnn", "(", "rnn_type", ",", "\n", "input_size", "=", "self", ".", "_input_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.rnn_uncond.RNNUncondDecoder.from_opt": [[79, 88], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ",", "embeddings", ")", ":", "\n", "        ", "\"\"\"Alternate constructor.\"\"\"", "\n", "return", "cls", "(", "\n", "opt", ".", "rnn_type", ",", "\n", "opt", ".", "dec_layers", ",", "\n", "opt", ".", "dec_rnn_size", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.rnn_uncond.RNNUncondDecoder.init_state": [[89, 96], ["next", "next.new_zeros", "next.new_zeros", "rnn_uncond.RNNUncondDecoder.parameters"], "methods", ["None"], ["", "def", "init_state", "(", "self", ",", "src", ",", "memory_bank", ",", "encoder_final", ")", ":", "\n", "        ", "\"\"\"Initialize decoder state with last state of the encoder.\"\"\"", "\n", "batch_size", "=", "memory_bank", ".", "shape", "[", "1", "]", "\n", "weight", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "h", "=", "weight", ".", "new_zeros", "(", "self", ".", "num_layers", ",", "batch_size", ",", "self", ".", "hidden_size", ")", "\n", "c", "=", "weight", ".", "new_zeros", "(", "self", ".", "num_layers", ",", "batch_size", ",", "self", ".", "hidden_size", ")", "\n", "self", ".", "state", "[", "\"hidden\"", "]", "=", "(", "h", ",", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.rnn_uncond.RNNUncondDecoder.map_state": [[97, 99], ["tuple", "fn"], "methods", ["None"], ["", "def", "map_state", "(", "self", ",", "fn", ")", ":", "\n", "        ", "self", ".", "state", "[", "\"hidden\"", "]", "=", "tuple", "(", "fn", "(", "h", ",", "1", ")", "for", "h", "in", "self", ".", "state", "[", "\"hidden\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.rnn_uncond.RNNUncondDecoder.detach_state": [[100, 102], ["tuple", "h.detach"], "methods", ["None"], ["", "def", "detach_state", "(", "self", ")", ":", "\n", "        ", "self", ".", "state", "[", "\"hidden\"", "]", "=", "tuple", "(", "h", ".", "detach", "(", ")", "for", "h", "in", "self", ".", "state", "[", "\"hidden\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.rnn_uncond.RNNUncondDecoder.forward": [[103, 137], ["rnn_uncond.RNNUncondDecoder.embeddings", "rnn_uncond.RNNUncondDecoder.rnn", "rnn_uncond.RNNUncondDecoder.dropout", "type", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tgt", ",", "memory_bank", ",", "memory_lengths", "=", "None", ",", "step", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tgt (LongTensor): sequences of padded tokens\n                 ``(tgt_len, batch, nfeats)``.\n            memory_bank (FloatTensor): vectors from the encoder\n                 ``(src_len, batch, hidden)``.\n            memory_lengths (LongTensor): the padded source lengths\n                ``(batch,)``.\n\n        Returns:\n            (FloatTensor, dict[str, FloatTensor]):\n\n            * dec_outs: output from the decoder (after attn)\n              ``(tgt_len, batch, hidden)``.\n            * attns: distribution over src at each tgt\n              ``(tgt_len, batch, src_len)``.\n        \"\"\"", "\n", "\n", "emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "dec_outs", ",", "dec_state", "=", "self", ".", "rnn", "(", "emb", ",", "self", ".", "state", "[", "\"hidden\"", "]", ")", "\n", "dec_outs", "=", "self", ".", "dropout", "(", "dec_outs", ")", "\n", "\n", "self", ".", "state", "[", "\"hidden\"", "]", "=", "dec_state", "\n", "\n", "# Concatenates sequence of tensors along a new dimension.", "\n", "# NOTE: v0.3 to 0.4: dec_outs / attns[*] may not be list", "\n", "#       (in particular in case of SRU) it was not raising error in 0.3", "\n", "#       since stack(Variable) was allowed.", "\n", "#       In 0.4, SRU returns a tensor that shouldn't be stacke", "\n", "if", "type", "(", "dec_outs", ")", "==", "list", ":", "\n", "            ", "dec_outs", "=", "torch", ".", "stack", "(", "dec_outs", ")", "\n", "\n", "", "return", "dec_outs", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.rnn_uncond.RNNUncondDecoder._build_rnn": [[138, 141], ["onmt.utils.rnn_factory.rnn_factory"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.rnn_factory.rnn_factory"], ["", "def", "_build_rnn", "(", "self", ",", "rnn_type", ",", "**", "kwargs", ")", ":", "\n", "        ", "rnn", ",", "_", "=", "rnn_factory", "(", "rnn_type", ",", "**", "kwargs", ")", "\n", "return", "rnn", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.rnn_uncond.RNNUncondDecoder._input_size": [[142, 145], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_input_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", ".", "embedding_size", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.cnn_decoder.CNNDecoder.__init__": [[21, 50], ["onmt.decoders.decoder.DecoderBase.__init__", "torch.Linear", "torch.Linear", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "onmt.modules.GlobalAttention", "onmt.utils.cnn_factory.GatedConv", "onmt.modules.ConvMultiStepAttention", "range", "range"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "hidden_size", ",", "attn_type", ",", "\n", "copy_attn", ",", "cnn_kernel_width", ",", "dropout", ",", "embeddings", ",", "\n", "copy_attn_type", ")", ":", "\n", "        ", "super", "(", "CNNDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "cnn_kernel_width", "=", "cnn_kernel_width", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "\n", "# Decoder State", "\n", "self", ".", "state", "=", "{", "}", "\n", "\n", "input_size", "=", "self", ".", "embeddings", ".", "embedding_size", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ")", "\n", "self", ".", "conv_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "GatedConv", "(", "hidden_size", ",", "cnn_kernel_width", ",", "dropout", ",", "True", ")", "\n", "for", "i", "in", "range", "(", "num_layers", ")", "]", "\n", ")", "\n", "self", ".", "attn_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "ConvMultiStepAttention", "(", "hidden_size", ")", "for", "i", "in", "range", "(", "num_layers", ")", "]", "\n", ")", "\n", "\n", "# CNNDecoder has its own attention mechanism.", "\n", "# Set up a separate copy attention layer if needed.", "\n", "assert", "not", "copy_attn", ",", "\"Copy mechanism not yet tested in conv2conv\"", "\n", "if", "copy_attn", ":", "\n", "            ", "self", ".", "copy_attn", "=", "GlobalAttention", "(", "\n", "hidden_size", ",", "attn_type", "=", "copy_attn_type", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "copy_attn", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.cnn_decoder.CNNDecoder.from_opt": [[51, 63], ["cls"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ",", "embeddings", ")", ":", "\n", "        ", "\"\"\"Alternate constructor.\"\"\"", "\n", "return", "cls", "(", "\n", "opt", ".", "dec_layers", ",", "\n", "opt", ".", "dec_rnn_size", ",", "\n", "opt", ".", "global_attention", ",", "\n", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "cnn_kernel_width", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", ",", "\n", "opt", ".", "copy_attn_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.cnn_decoder.CNNDecoder.init_state": [[64, 68], ["None"], "methods", ["None"], ["", "def", "init_state", "(", "self", ",", "_", ",", "memory_bank", ",", "enc_hidden", ")", ":", "\n", "        ", "\"\"\"Init decoder state.\"\"\"", "\n", "self", ".", "state", "[", "\"src\"", "]", "=", "(", "memory_bank", "+", "enc_hidden", ")", "*", "SCALE_WEIGHT", "\n", "self", ".", "state", "[", "\"previous_input\"", "]", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.cnn_decoder.CNNDecoder.map_state": [[69, 73], ["fn", "fn"], "methods", ["None"], ["", "def", "map_state", "(", "self", ",", "fn", ")", ":", "\n", "        ", "self", ".", "state", "[", "\"src\"", "]", "=", "fn", "(", "self", ".", "state", "[", "\"src\"", "]", ",", "1", ")", "\n", "if", "self", ".", "state", "[", "\"previous_input\"", "]", "is", "not", "None", ":", "\n", "            ", "self", ".", "state", "[", "\"previous_input\"", "]", "=", "fn", "(", "self", ".", "state", "[", "\"previous_input\"", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.cnn_decoder.CNNDecoder.detach_state": [[74, 76], ["cnn_decoder.CNNDecoder.state[].detach"], "methods", ["None"], ["", "", "def", "detach_state", "(", "self", ")", ":", "\n", "        ", "self", ".", "state", "[", "\"previous_input\"", "]", "=", "self", ".", "state", "[", "\"previous_input\"", "]", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.cnn_decoder.CNNDecoder.forward": [[77, 130], ["cnn_decoder.CNNDecoder.embeddings", "cnn_decoder.CNNDecoder.transpose().contiguous", "memory_bank.transpose().contiguous", "cnn_decoder.CNNDecoder.state[].transpose().contiguous", "cnn_decoder.CNNDecoder.transpose().contiguous.contiguous().view", "cnn_decoder.CNNDecoder.linear", "cnn_decoder.CNNDecoder.view", "onmt.utils.cnn_factory.shape_transform", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "pad.type_as.type_as.type_as", "zip", "onmt.utils.cnn_factory.shape_transform.squeeze().transpose", "onmt.utils.cnn_factory.shape_transform.squeeze().transpose.transpose().contiguous", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "cnn_decoder.CNNDecoder.dim", "cnn_decoder.CNNDecoder.transpose().contiguous.size", "cnn_decoder.CNNDecoder.transpose().contiguous.size", "onmt.utils.cnn_factory.shape_transform.size", "onmt.utils.cnn_factory.shape_transform.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "conv", "attention", "attn[].squeeze", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "cnn_decoder.CNNDecoder.transpose", "memory_bank.transpose", "cnn_decoder.CNNDecoder.state[].transpose", "cnn_decoder.CNNDecoder.transpose().contiguous.contiguous", "cnn_decoder.CNNDecoder.transpose().contiguous.size", "cnn_decoder.CNNDecoder.transpose().contiguous.size", "onmt.utils.cnn_factory.shape_transform.squeeze", "onmt.utils.cnn_factory.shape_transform.squeeze().transpose.transpose", "cnn_decoder.CNNDecoder.state[].size", "cnn_decoder.CNNDecoder.state[].size"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.cnn_factory.shape_transform", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "forward", "(", "self", ",", "tgt", ",", "memory_bank", ",", "step", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" See :obj:`onmt.modules.RNNDecoderBase.forward()`\"\"\"", "\n", "\n", "if", "self", ".", "state", "[", "\"previous_input\"", "]", "is", "not", "None", ":", "\n", "            ", "tgt", "=", "torch", ".", "cat", "(", "[", "self", ".", "state", "[", "\"previous_input\"", "]", ",", "tgt", "]", ",", "0", ")", "\n", "\n", "", "dec_outs", "=", "[", "]", "\n", "attns", "=", "{", "\"std\"", ":", "[", "]", "}", "\n", "if", "self", ".", "copy_attn", "is", "not", "None", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "[", "]", "\n", "\n", "", "emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "assert", "emb", ".", "dim", "(", ")", "==", "3", "# len x batch x embedding_dim", "\n", "\n", "tgt_emb", "=", "emb", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# The output of CNNEncoder.", "\n", "src_memory_bank_t", "=", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# The combination of output of CNNEncoder and source embeddings.", "\n", "src_memory_bank_c", "=", "self", ".", "state", "[", "\"src\"", "]", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "emb_reshape", "=", "tgt_emb", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "tgt_emb", ".", "size", "(", "0", ")", "*", "tgt_emb", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "linear_out", "=", "self", ".", "linear", "(", "emb_reshape", ")", "\n", "x", "=", "linear_out", ".", "view", "(", "tgt_emb", ".", "size", "(", "0", ")", ",", "tgt_emb", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "x", "=", "shape_transform", "(", "x", ")", "\n", "\n", "pad", "=", "torch", ".", "zeros", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "self", ".", "cnn_kernel_width", "-", "1", ",", "1", ")", "\n", "\n", "pad", "=", "pad", ".", "type_as", "(", "x", ")", "\n", "base_target_emb", "=", "x", "\n", "\n", "for", "conv", ",", "attention", "in", "zip", "(", "self", ".", "conv_layers", ",", "self", ".", "attn_layers", ")", ":", "\n", "            ", "new_target_input", "=", "torch", ".", "cat", "(", "[", "pad", ",", "x", "]", ",", "2", ")", "\n", "out", "=", "conv", "(", "new_target_input", ")", "\n", "c", ",", "attn", "=", "attention", "(", "base_target_emb", ",", "out", ",", "\n", "src_memory_bank_t", ",", "src_memory_bank_c", ")", "\n", "x", "=", "(", "x", "+", "(", "c", "+", "out", ")", "*", "SCALE_WEIGHT", ")", "*", "SCALE_WEIGHT", "\n", "", "output", "=", "x", ".", "squeeze", "(", "3", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "# Process the result and update the attentions.", "\n", "dec_outs", "=", "output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "if", "self", ".", "state", "[", "\"previous_input\"", "]", "is", "not", "None", ":", "\n", "            ", "dec_outs", "=", "dec_outs", "[", "self", ".", "state", "[", "\"previous_input\"", "]", ".", "size", "(", "0", ")", ":", "]", "\n", "attn", "=", "attn", "[", ":", ",", "self", ".", "state", "[", "\"previous_input\"", "]", ".", "size", "(", "0", ")", ":", "]", ".", "squeeze", "(", ")", "\n", "attn", "=", "torch", ".", "stack", "(", "[", "attn", "]", ")", "\n", "", "attns", "[", "\"std\"", "]", "=", "attn", "\n", "if", "self", ".", "copy_attn", "is", "not", "None", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "attn", "\n", "\n", "# Update the state.", "\n", "", "self", ".", "state", "[", "\"previous_input\"", "]", "=", "tgt", "\n", "# TODO change the way attns is returned dict => list or tuple (onnx)", "\n", "return", "dec_outs", ",", "attns", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.decoder.DecoderBase.__init__": [[18, 21], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "attentional", "=", "True", ")", ":", "\n", "        ", "super", "(", "DecoderBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attentional", "=", "attentional", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.decoder.DecoderBase.from_opt": [[22, 30], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ",", "embeddings", ")", ":", "\n", "        ", "\"\"\"Alternate constructor.\n\n        Subclasses should override this method.\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.decoder.RNNDecoderBase.__init__": [[83, 140], ["decoder.DecoderBase.__init__", "torch.Dropout", "torch.Dropout", "decoder.RNNDecoderBase._build_rnn", "onmt.modules.context_gate_factory", "onmt.modules.GlobalAttention", "onmt.modules.GlobalAttention", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.decoder.InputFeedRNNDecoder._build_rnn", "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.gate.context_gate_factory"], ["def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional_encoder", ",", "num_layers", ",", "\n", "hidden_size", ",", "attn_type", "=", "\"general\"", ",", "attn_func", "=", "\"softmax\"", ",", "\n", "coverage_attn", "=", "False", ",", "context_gate", "=", "None", ",", "\n", "copy_attn", "=", "False", ",", "dropout", "=", "0.0", ",", "embeddings", "=", "None", ",", "\n", "reuse_copy_attn", "=", "False", ",", "copy_attn_type", "=", "\"general\"", ")", ":", "\n", "        ", "super", "(", "RNNDecoderBase", ",", "self", ")", ".", "__init__", "(", "\n", "attentional", "=", "attn_type", "!=", "\"none\"", "and", "attn_type", "is", "not", "None", ")", "\n", "\n", "self", ".", "bidirectional_encoder", "=", "bidirectional_encoder", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "# Decoder state", "\n", "self", ".", "state", "=", "{", "}", "\n", "\n", "# Build the RNN.", "\n", "self", ".", "rnn", "=", "self", ".", "_build_rnn", "(", "rnn_type", ",", "\n", "input_size", "=", "self", ".", "_input_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ")", "\n", "\n", "# Set up the context gate.", "\n", "self", ".", "context_gate", "=", "None", "\n", "if", "context_gate", "is", "not", "None", ":", "\n", "            ", "self", ".", "context_gate", "=", "context_gate_factory", "(", "\n", "context_gate", ",", "self", ".", "_input_size", ",", "\n", "hidden_size", ",", "hidden_size", ",", "hidden_size", "\n", ")", "\n", "\n", "# Set up the standard attention.", "\n", "", "self", ".", "_coverage", "=", "coverage_attn", "\n", "if", "not", "self", ".", "attentional", ":", "\n", "            ", "if", "self", ".", "_coverage", ":", "\n", "                ", "raise", "ValueError", "(", "\"Cannot use coverage term with no attention.\"", ")", "\n", "", "self", ".", "attn", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "attn", "=", "GlobalAttention", "(", "\n", "hidden_size", ",", "coverage", "=", "coverage_attn", ",", "\n", "attn_type", "=", "attn_type", ",", "attn_func", "=", "attn_func", "\n", ")", "\n", "\n", "", "if", "copy_attn", "and", "not", "reuse_copy_attn", ":", "\n", "            ", "if", "copy_attn_type", "==", "\"none\"", "or", "copy_attn_type", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Cannot use copy_attn with copy_attn_type none\"", ")", "\n", "", "self", ".", "copy_attn", "=", "GlobalAttention", "(", "\n", "hidden_size", ",", "attn_type", "=", "copy_attn_type", ",", "attn_func", "=", "attn_func", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "copy_attn", "=", "None", "\n", "\n", "", "self", ".", "_reuse_copy_attn", "=", "reuse_copy_attn", "and", "copy_attn", "\n", "if", "self", ".", "_reuse_copy_attn", "and", "not", "self", ".", "attentional", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot reuse copy attention with no attention.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.decoder.RNNDecoderBase.from_opt": [[141, 158], ["cls"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ",", "embeddings", ")", ":", "\n", "        ", "\"\"\"Alternate constructor.\"\"\"", "\n", "return", "cls", "(", "\n", "opt", ".", "rnn_type", ",", "\n", "opt", ".", "brnn", ",", "\n", "opt", ".", "dec_layers", ",", "\n", "opt", ".", "dec_rnn_size", ",", "\n", "opt", ".", "global_attention", ",", "\n", "opt", ".", "global_attention_function", ",", "\n", "opt", ".", "coverage_attn", ",", "\n", "opt", ".", "context_gate", ",", "\n", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", ",", "\n", "opt", ".", "reuse_copy_attn", ",", "\n", "opt", ".", "copy_attn_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.decoder.RNNDecoderBase.init_state": [[159, 181], ["isinstance", "[].size", "[].data.new().zero_().unsqueeze", "tuple", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "decoder.RNNDecoderBase.init_state._fix_enc_hidden"], "methods", ["None"], ["", "def", "init_state", "(", "self", ",", "src", ",", "memory_bank", ",", "encoder_final", ")", ":", "\n", "        ", "\"\"\"Initialize decoder state with last state of the encoder.\"\"\"", "\n", "def", "_fix_enc_hidden", "(", "hidden", ")", ":", "\n", "# The encoder hidden is  (layers*directions) x batch x dim.", "\n", "# We need to convert it to layers x batch x (directions*dim).", "\n", "            ", "if", "self", ".", "bidirectional_encoder", ":", "\n", "                ", "hidden", "=", "torch", ".", "cat", "(", "[", "hidden", "[", "0", ":", "hidden", ".", "size", "(", "0", ")", ":", "2", "]", ",", "\n", "hidden", "[", "1", ":", "hidden", ".", "size", "(", "0", ")", ":", "2", "]", "]", ",", "2", ")", "\n", "", "return", "hidden", "\n", "\n", "", "if", "isinstance", "(", "encoder_final", ",", "tuple", ")", ":", "# LSTM", "\n", "            ", "self", ".", "state", "[", "\"hidden\"", "]", "=", "tuple", "(", "_fix_enc_hidden", "(", "enc_hid", ")", "\n", "for", "enc_hid", "in", "encoder_final", ")", "\n", "", "else", ":", "# GRU", "\n", "            ", "self", ".", "state", "[", "\"hidden\"", "]", "=", "(", "_fix_enc_hidden", "(", "encoder_final", ")", ",", ")", "\n", "\n", "# Init the input feed.", "\n", "", "batch_size", "=", "self", ".", "state", "[", "\"hidden\"", "]", "[", "0", "]", ".", "size", "(", "1", ")", "\n", "h_size", "=", "(", "batch_size", ",", "self", ".", "hidden_size", ")", "\n", "self", ".", "state", "[", "\"input_feed\"", "]", "=", "self", ".", "state", "[", "\"hidden\"", "]", "[", "0", "]", ".", "data", ".", "new", "(", "*", "h_size", ")", ".", "zero_", "(", ")", ".", "unsqueeze", "(", "0", ")", "\n", "self", ".", "state", "[", "\"coverage\"", "]", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.decoder.RNNDecoderBase.map_state": [[182, 185], ["tuple", "fn", "fn"], "methods", ["None"], ["", "def", "map_state", "(", "self", ",", "fn", ")", ":", "\n", "        ", "self", ".", "state", "[", "\"hidden\"", "]", "=", "tuple", "(", "fn", "(", "h", ",", "1", ")", "for", "h", "in", "self", ".", "state", "[", "\"hidden\"", "]", ")", "\n", "self", ".", "state", "[", "\"input_feed\"", "]", "=", "fn", "(", "self", ".", "state", "[", "\"input_feed\"", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.decoder.RNNDecoderBase.detach_state": [[186, 189], ["tuple", "decoder.RNNDecoderBase.state[].detach", "h.detach"], "methods", ["None"], ["", "def", "detach_state", "(", "self", ")", ":", "\n", "        ", "self", ".", "state", "[", "\"hidden\"", "]", "=", "tuple", "(", "h", ".", "detach", "(", ")", "for", "h", "in", "self", ".", "state", "[", "\"hidden\"", "]", ")", "\n", "self", ".", "state", "[", "\"input_feed\"", "]", "=", "self", ".", "state", "[", "\"input_feed\"", "]", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.decoder.RNNDecoderBase.forward": [[190, 233], ["decoder.RNNDecoderBase._run_forward_pass", "dec_outs[].unsqueeze", "isinstance", "[].unsqueeze", "type", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "type", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.decoder.InputFeedRNNDecoder._run_forward_pass"], ["", "def", "forward", "(", "self", ",", "tgt", ",", "memory_bank", ",", "memory_lengths", "=", "None", ",", "step", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tgt (LongTensor): sequences of padded tokens\n                 ``(tgt_len, batch, nfeats)``.\n            memory_bank (FloatTensor): vectors from the encoder\n                 ``(src_len, batch, hidden)``.\n            memory_lengths (LongTensor): the padded source lengths\n                ``(batch,)``.\n\n        Returns:\n            (FloatTensor, dict[str, FloatTensor]):\n\n            * dec_outs: output from the decoder (after attn)\n              ``(tgt_len, batch, hidden)``.\n            * attns: distribution over src at each tgt\n              ``(tgt_len, batch, src_len)``.\n        \"\"\"", "\n", "\n", "dec_state", ",", "dec_outs", ",", "attns", "=", "self", ".", "_run_forward_pass", "(", "\n", "tgt", ",", "memory_bank", ",", "memory_lengths", "=", "memory_lengths", ")", "\n", "\n", "# Update the state with the result.", "\n", "if", "not", "isinstance", "(", "dec_state", ",", "tuple", ")", ":", "\n", "            ", "dec_state", "=", "(", "dec_state", ",", ")", "\n", "", "self", ".", "state", "[", "\"hidden\"", "]", "=", "dec_state", "\n", "self", ".", "state", "[", "\"input_feed\"", "]", "=", "dec_outs", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", "\n", "self", ".", "state", "[", "\"coverage\"", "]", "=", "None", "\n", "if", "\"coverage\"", "in", "attns", ":", "\n", "            ", "self", ".", "state", "[", "\"coverage\"", "]", "=", "attns", "[", "\"coverage\"", "]", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "# Concatenates sequence of tensors along a new dimension.", "\n", "# NOTE: v0.3 to 0.4: dec_outs / attns[*] may not be list", "\n", "#       (in particular in case of SRU) it was not raising error in 0.3", "\n", "#       since stack(Variable) was allowed.", "\n", "#       In 0.4, SRU returns a tensor that shouldn't be stacke", "\n", "", "if", "type", "(", "dec_outs", ")", "==", "list", ":", "\n", "            ", "dec_outs", "=", "torch", ".", "stack", "(", "dec_outs", ")", "\n", "\n", "for", "k", "in", "attns", ":", "\n", "                ", "if", "type", "(", "attns", "[", "k", "]", ")", "==", "list", ":", "\n", "                    ", "attns", "[", "k", "]", "=", "torch", ".", "stack", "(", "attns", "[", "k", "]", ")", "\n", "", "", "", "return", "dec_outs", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.decoder.StdRNNDecoder._run_forward_pass": [[251, 313], ["decoder.StdRNNDecoder.embeddings", "isinstance", "tgt.size", "rnn_output.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "decoder.StdRNNDecoder.dropout", "decoder.StdRNNDecoder.rnn", "decoder.StdRNNDecoder.rnn", "decoder.StdRNNDecoder.attn", "decoder.StdRNNDecoder.context_gate", "dec_outs.view.view.view", "rnn_output.transpose().contiguous", "memory_bank.transpose", "decoder.StdRNNDecoder.view", "rnn_output.view", "dec_outs.view.view.view", "decoder.StdRNNDecoder.size", "rnn_output.size", "dec_outs.view.view.size", "rnn_output.transpose"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq"], ["def", "_run_forward_pass", "(", "self", ",", "tgt", ",", "memory_bank", ",", "memory_lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Private helper for running the specific RNN forward pass.\n        Must be overriden by all subclasses.\n\n        Args:\n            tgt (LongTensor): a sequence of input tokens tensors\n                ``(len, batch, nfeats)``.\n            memory_bank (FloatTensor): output(tensor sequence) from the\n                encoder RNN of size ``(src_len, batch, hidden_size)``.\n            memory_lengths (LongTensor): the source memory_bank lengths.\n\n        Returns:\n            (Tensor, List[FloatTensor], Dict[str, List[FloatTensor]):\n\n            * dec_state: final hidden state from the decoder.\n            * dec_outs: an array of output of every time\n              step from the decoder.\n            * attns: a dictionary of different\n              type of attention Tensor array of every time\n              step from the decoder.\n        \"\"\"", "\n", "\n", "assert", "self", ".", "copy_attn", "is", "None", "# TODO, no support yet.", "\n", "assert", "not", "self", ".", "_coverage", "# TODO, no support yet.", "\n", "\n", "attns", "=", "{", "}", "\n", "emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "\n", "if", "isinstance", "(", "self", ".", "rnn", ",", "nn", ".", "GRU", ")", ":", "\n", "            ", "rnn_output", ",", "dec_state", "=", "self", ".", "rnn", "(", "emb", ",", "self", ".", "state", "[", "\"hidden\"", "]", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "rnn_output", ",", "dec_state", "=", "self", ".", "rnn", "(", "emb", ",", "self", ".", "state", "[", "\"hidden\"", "]", ")", "\n", "\n", "# Check", "\n", "", "tgt_len", ",", "tgt_batch", ",", "_", "=", "tgt", ".", "size", "(", ")", "\n", "output_len", ",", "output_batch", ",", "_", "=", "rnn_output", ".", "size", "(", ")", "\n", "aeq", "(", "tgt_len", ",", "output_len", ")", "\n", "aeq", "(", "tgt_batch", ",", "output_batch", ")", "\n", "\n", "# Calculate the attention.", "\n", "if", "not", "self", ".", "attentional", ":", "\n", "            ", "dec_outs", "=", "rnn_output", "\n", "", "else", ":", "\n", "            ", "dec_outs", ",", "p_attn", "=", "self", ".", "attn", "(", "\n", "rnn_output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "\n", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "memory_lengths", "=", "memory_lengths", "\n", ")", "\n", "attns", "[", "\"std\"", "]", "=", "p_attn", "\n", "\n", "# Calculate the context gate.", "\n", "", "if", "self", ".", "context_gate", "is", "not", "None", ":", "\n", "            ", "dec_outs", "=", "self", ".", "context_gate", "(", "\n", "emb", ".", "view", "(", "-", "1", ",", "emb", ".", "size", "(", "2", ")", ")", ",", "\n", "rnn_output", ".", "view", "(", "-", "1", ",", "rnn_output", ".", "size", "(", "2", ")", ")", ",", "\n", "dec_outs", ".", "view", "(", "-", "1", ",", "dec_outs", ".", "size", "(", "2", ")", ")", "\n", ")", "\n", "dec_outs", "=", "dec_outs", ".", "view", "(", "tgt_len", ",", "tgt_batch", ",", "self", ".", "hidden_size", ")", "\n", "\n", "", "dec_outs", "=", "self", ".", "dropout", "(", "dec_outs", ")", "\n", "return", "dec_state", ",", "dec_outs", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.decoder.StdRNNDecoder._build_rnn": [[314, 317], ["onmt.utils.rnn_factory.rnn_factory"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.rnn_factory.rnn_factory"], ["", "def", "_build_rnn", "(", "self", ",", "rnn_type", ",", "**", "kwargs", ")", ":", "\n", "        ", "rnn", ",", "_", "=", "rnn_factory", "(", "rnn_type", ",", "**", "kwargs", ")", "\n", "return", "rnn", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.decoder.StdRNNDecoder._input_size": [[318, 321], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_input_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", ".", "embedding_size", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.decoder.InputFeedRNNDecoder._run_forward_pass": [[351, 416], ["decoder.InputFeedRNNDecoder.state[].squeeze", "decoder.InputFeedRNNDecoder.size", "tgt.size", "onmt.utils.misc.aeq", "decoder.InputFeedRNNDecoder.embeddings", "decoder.InputFeedRNNDecoder.split", "decoder.InputFeedRNNDecoder.dim", "decoder.InputFeedRNNDecoder.state[].squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "decoder.InputFeedRNNDecoder.rnn", "decoder.InputFeedRNNDecoder.dropout", "decoder.InputFeedRNNDecoder.attn", "attns[].append", "decoder.InputFeedRNNDecoder.context_gate", "decoder.InputFeedRNNDecoder.copy_attn", "emb_t.squeeze", "memory_bank.transpose", "memory_bank.transpose"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["def", "_run_forward_pass", "(", "self", ",", "tgt", ",", "memory_bank", ",", "memory_lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        See StdRNNDecoder._run_forward_pass() for description\n        of arguments and return values.\n        \"\"\"", "\n", "# Additional args check.", "\n", "input_feed", "=", "self", ".", "state", "[", "\"input_feed\"", "]", ".", "squeeze", "(", "0", ")", "\n", "input_feed_batch", ",", "_", "=", "input_feed", ".", "size", "(", ")", "\n", "_", ",", "tgt_batch", ",", "_", "=", "tgt", ".", "size", "(", ")", "\n", "aeq", "(", "tgt_batch", ",", "input_feed_batch", ")", "\n", "# END Additional args check.", "\n", "\n", "dec_outs", "=", "[", "]", "\n", "attns", "=", "{", "}", "\n", "if", "self", ".", "attn", "is", "not", "None", ":", "\n", "            ", "attns", "[", "\"std\"", "]", "=", "[", "]", "\n", "", "if", "self", ".", "copy_attn", "is", "not", "None", "or", "self", ".", "_reuse_copy_attn", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "[", "]", "\n", "", "if", "self", ".", "_coverage", ":", "\n", "            ", "attns", "[", "\"coverage\"", "]", "=", "[", "]", "\n", "\n", "", "emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "assert", "emb", ".", "dim", "(", ")", "==", "3", "# len x batch x embedding_dim", "\n", "\n", "dec_state", "=", "self", ".", "state", "[", "\"hidden\"", "]", "\n", "coverage", "=", "self", ".", "state", "[", "\"coverage\"", "]", ".", "squeeze", "(", "0", ")", "if", "self", ".", "state", "[", "\"coverage\"", "]", "is", "not", "None", "else", "None", "\n", "\n", "# Input feed concatenates hidden state with", "\n", "# input at every time step.", "\n", "for", "emb_t", "in", "emb", ".", "split", "(", "1", ")", ":", "\n", "            ", "decoder_input", "=", "torch", ".", "cat", "(", "[", "emb_t", ".", "squeeze", "(", "0", ")", ",", "input_feed", "]", ",", "1", ")", "\n", "rnn_output", ",", "dec_state", "=", "self", ".", "rnn", "(", "decoder_input", ",", "dec_state", ")", "\n", "if", "self", ".", "attentional", ":", "\n", "                ", "decoder_output", ",", "p_attn", "=", "self", ".", "attn", "(", "\n", "rnn_output", ",", "\n", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "memory_lengths", "=", "memory_lengths", ")", "\n", "attns", "[", "\"std\"", "]", ".", "append", "(", "p_attn", ")", "\n", "", "else", ":", "\n", "                ", "decoder_output", "=", "rnn_output", "\n", "", "if", "self", ".", "context_gate", "is", "not", "None", ":", "\n", "# TODO: context gate should be employed", "\n", "# instead of second RNN transform.", "\n", "                ", "decoder_output", "=", "self", ".", "context_gate", "(", "\n", "decoder_input", ",", "rnn_output", ",", "decoder_output", "\n", ")", "\n", "", "decoder_output", "=", "self", ".", "dropout", "(", "decoder_output", ")", "\n", "input_feed", "=", "decoder_output", "\n", "\n", "dec_outs", "+=", "[", "decoder_output", "]", "\n", "\n", "# Update the coverage attention.", "\n", "if", "self", ".", "_coverage", ":", "\n", "                ", "coverage", "=", "p_attn", "if", "coverage", "is", "None", "else", "p_attn", "+", "coverage", "\n", "attns", "[", "\"coverage\"", "]", "+=", "[", "coverage", "]", "\n", "\n", "", "if", "self", ".", "copy_attn", "is", "not", "None", ":", "\n", "                ", "_", ",", "copy_attn", "=", "self", ".", "copy_attn", "(", "\n", "decoder_output", ",", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "attns", "[", "\"copy\"", "]", "+=", "[", "copy_attn", "]", "\n", "", "elif", "self", ".", "_reuse_copy_attn", ":", "\n", "                ", "attns", "[", "\"copy\"", "]", "=", "attns", "[", "\"std\"", "]", "\n", "\n", "", "", "return", "dec_state", ",", "dec_outs", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.decoder.InputFeedRNNDecoder._build_rnn": [[417, 423], ["stacked_cell"], "methods", ["None"], ["", "def", "_build_rnn", "(", "self", ",", "rnn_type", ",", "input_size", ",", "\n", "hidden_size", ",", "num_layers", ",", "dropout", ")", ":", "\n", "        ", "assert", "rnn_type", "!=", "\"SRU\"", ",", "\"SRU doesn't support input feed! \"", "\"Please set -input_feed 0!\"", "\n", "stacked_cell", "=", "StackedLSTM", "if", "rnn_type", "==", "\"LSTM\"", "else", "StackedGRU", "\n", "return", "stacked_cell", "(", "num_layers", ",", "input_size", ",", "hidden_size", ",", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.decoder.InputFeedRNNDecoder._input_size": [[424, 428], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_input_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"Using input feed by concatenating input with attention vectors.\"\"\"", "\n", "return", "self", ".", "embeddings", ".", "embedding_size", "+", "self", ".", "hidden_size", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerGPTUnconditionalDecoderLayer.__init__": [[28, 43], ["torch.Module.__init__", "onmt.modules.gpt_mlp.MLP", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout", "onmt.modules.MultiHeadedAttention", "onmt.modules.AverageAttention"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "heads", ",", "d_ff", ",", "dropout", ",", "attn_dropout", ",", "\n", "self_attn_type", "=", "\"scaled-dot\"", ",", "max_relative_positions", "=", "0", ")", ":", "\n", "        ", "super", "(", "TransformerGPTUnconditionalDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "self_attn_type", "==", "\"scaled-dot\"", ":", "\n", "            ", "self", ".", "self_attn", "=", "MultiHeadedAttention", "(", "\n", "heads", ",", "d_model", ",", "dropout", "=", "attn_dropout", ",", "\n", "max_relative_positions", "=", "max_relative_positions", ")", "\n", "", "elif", "self_attn_type", "==", "\"average\"", ":", "\n", "            ", "self", ".", "self_attn", "=", "AverageAttention", "(", "d_model", ",", "dropout", "=", "attn_dropout", ")", "\n", "\n", "", "self", ".", "feed_forward", "=", "MLP", "(", "d_model", ",", "d_model", "*", "4", ",", "dropout", ")", "\n", "self", ".", "layer_norm_1", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-5", ")", "\n", "self", ".", "layer_norm_2", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-5", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerGPTUnconditionalDecoderLayer.forward": [[44, 88], ["transformer.TransformerGPTUnconditionalDecoderLayer.layer_norm_1", "isinstance", "transformer.TransformerGPTUnconditionalDecoderLayer.layer_norm_2", "transformer.TransformerGPTUnconditionalDecoderLayer.feed_forward", "tgt_pad_mask.size", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "future_mask.triu_().view.triu_().view.triu_().view", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "transformer.TransformerGPTUnconditionalDecoderLayer.self_attn", "isinstance", "transformer.TransformerGPTUnconditionalDecoderLayer.drop", "transformer.TransformerGPTUnconditionalDecoderLayer.self_attn", "future_mask.triu_().view.triu_().view.triu_"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "memory_bank", ",", "src_pad_mask", ",", "tgt_pad_mask", ",", "\n", "layer_cache", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (FloatTensor): ``(batch_size, 1, model_dim)``\n            memory_bank (FloatTensor): ``(batch_size, src_len, model_dim)``\n            src_pad_mask (LongTensor): ``(batch_size, 1, src_len)``\n            tgt_pad_mask (LongTensor): ``(batch_size, 1, 1)``\n\n        Returns:\n            (FloatTensor, FloatTensor):\n\n            * output ``(batch_size, 1, model_dim)``\n            * attn ``(batch_size, 1, src_len)``\n\n        \"\"\"", "\n", "dec_mask", "=", "None", "\n", "if", "step", "is", "None", ":", "\n", "            ", "tgt_len", "=", "tgt_pad_mask", ".", "size", "(", "-", "1", ")", "\n", "future_mask", "=", "torch", ".", "ones", "(", "\n", "[", "tgt_len", ",", "tgt_len", "]", ",", "\n", "device", "=", "tgt_pad_mask", ".", "device", ",", "\n", "dtype", "=", "torch", ".", "uint8", ")", "\n", "future_mask", "=", "future_mask", ".", "triu_", "(", "1", ")", ".", "view", "(", "1", ",", "tgt_len", ",", "tgt_len", ")", "\n", "dec_mask", "=", "torch", ".", "gt", "(", "tgt_pad_mask", "+", "future_mask", ",", "0", ")", "\n", "\n", "", "input_norm", "=", "self", ".", "layer_norm_1", "(", "inputs", ")", "\n", "\n", "if", "isinstance", "(", "self", ".", "self_attn", ",", "MultiHeadedAttention", ")", ":", "\n", "            ", "query", ",", "attn", "=", "self", ".", "self_attn", "(", "input_norm", ",", "input_norm", ",", "input_norm", ",", "\n", "mask", "=", "dec_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "\n", "type", "=", "\"self\"", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "self_attn", ",", "AverageAttention", ")", ":", "\n", "            ", "query", ",", "attn", "=", "self", ".", "self_attn", "(", "input_norm", ",", "mask", "=", "dec_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "step", "=", "step", ")", "\n", "\n", "", "query", "=", "self", ".", "drop", "(", "query", ")", "+", "inputs", "\n", "query_norm", "=", "self", ".", "layer_norm_2", "(", "query", ")", "\n", "\n", "output", "=", "self", ".", "feed_forward", "(", "query_norm", ")", "\n", "output", "=", "output", "+", "query", "\n", "\n", "return", "output", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerGPTDecoderLayerCtxattn.__init__": [[102, 126], ["torch.Module.__init__", "onmt.modules.MultiHeadedAttention", "onmt.modules.gpt_mlp.MLP", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout", "onmt.modules.MultiHeadedAttention", "print", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "onmt.modules.AverageAttention", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "heads", ",", "d_ff", ",", "dropout", ",", "attn_dropout", ",", "\n", "self_attn_type", "=", "\"scaled-dot\"", ",", "max_relative_positions", "=", "0", ",", "\n", "ctx_weight_param", "=", "False", ")", ":", "\n", "        ", "super", "(", "TransformerGPTDecoderLayerCtxattn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "self_attn_type", "==", "\"scaled-dot\"", ":", "\n", "            ", "self", ".", "self_attn", "=", "MultiHeadedAttention", "(", "\n", "heads", ",", "d_model", ",", "dropout", "=", "attn_dropout", ",", "\n", "max_relative_positions", "=", "max_relative_positions", ")", "\n", "", "elif", "self_attn_type", "==", "\"average\"", ":", "\n", "            ", "self", ".", "self_attn", "=", "AverageAttention", "(", "d_model", ",", "dropout", "=", "attn_dropout", ")", "\n", "\n", "", "self", ".", "context_attn", "=", "MultiHeadedAttention", "(", "\n", "heads", ",", "d_model", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "feed_forward", "=", "MLP", "(", "d_model", ",", "d_model", "*", "4", ",", "dropout", ")", "\n", "self", ".", "layer_norm_1", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-5", ")", "\n", "self", ".", "layer_norm_2", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-5", ")", "\n", "self", ".", "context_layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-5", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "if", "ctx_weight_param", ":", "\n", "            ", "print", "(", "'using ctx_weight_param'", ")", "\n", "self", ".", "ctx_weight", "=", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", ")", "\n", "", "self", ".", "ctx_weight_param", "=", "ctx_weight_param", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerGPTDecoderLayerCtxattn.forward": [[127, 183], ["transformer.TransformerGPTDecoderLayerCtxattn.layer_norm_1", "isinstance", "transformer.TransformerGPTDecoderLayerCtxattn.layer_norm_2", "transformer.TransformerGPTDecoderLayerCtxattn.context_attn", "transformer.TransformerGPTDecoderLayerCtxattn.drop", "transformer.TransformerGPTDecoderLayerCtxattn.context_layer_norm", "transformer.TransformerGPTDecoderLayerCtxattn.feed_forward", "tgt_pad_mask.size", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "future_mask.triu_().view.triu_().view.triu_().view", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "transformer.TransformerGPTDecoderLayerCtxattn.self_attn", "isinstance", "transformer.TransformerGPTDecoderLayerCtxattn.drop", "transformer.TransformerGPTDecoderLayerCtxattn.self_attn", "future_mask.triu_().view.triu_().view.triu_"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "memory_bank", ",", "src_pad_mask", ",", "tgt_pad_mask", ",", "\n", "layer_cache", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (FloatTensor): ``(batch_size, 1, model_dim)``\n            memory_bank (FloatTensor): ``(batch_size, src_len, model_dim)``\n            src_pad_mask (LongTensor): ``(batch_size, 1, src_len)``\n            tgt_pad_mask (LongTensor): ``(batch_size, 1, 1)``\n\n        Returns:\n            (FloatTensor, FloatTensor):\n\n            * output ``(batch_size, 1, model_dim)``\n            * attn ``(batch_size, 1, src_len)``\n\n        \"\"\"", "\n", "dec_mask", "=", "None", "\n", "if", "step", "is", "None", ":", "\n", "            ", "tgt_len", "=", "tgt_pad_mask", ".", "size", "(", "-", "1", ")", "\n", "future_mask", "=", "torch", ".", "ones", "(", "\n", "[", "tgt_len", ",", "tgt_len", "]", ",", "\n", "device", "=", "tgt_pad_mask", ".", "device", ",", "\n", "dtype", "=", "torch", ".", "uint8", ")", "\n", "future_mask", "=", "future_mask", ".", "triu_", "(", "1", ")", ".", "view", "(", "1", ",", "tgt_len", ",", "tgt_len", ")", "\n", "dec_mask", "=", "torch", ".", "gt", "(", "tgt_pad_mask", "+", "future_mask", ",", "0", ")", "\n", "\n", "", "input_norm", "=", "self", ".", "layer_norm_1", "(", "inputs", ")", "\n", "\n", "if", "isinstance", "(", "self", ".", "self_attn", ",", "MultiHeadedAttention", ")", ":", "\n", "            ", "query", ",", "attn", "=", "self", ".", "self_attn", "(", "input_norm", ",", "input_norm", ",", "input_norm", ",", "\n", "mask", "=", "dec_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "\n", "type", "=", "\"self\"", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "self_attn", ",", "AverageAttention", ")", ":", "\n", "            ", "query", ",", "attn", "=", "self", ".", "self_attn", "(", "input_norm", ",", "mask", "=", "dec_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "step", "=", "step", ")", "\n", "\n", "", "query", "=", "self", ".", "drop", "(", "query", ")", "+", "inputs", "\n", "\n", "query_norm", "=", "self", ".", "layer_norm_2", "(", "query", ")", "\n", "\n", "mid", ",", "attn", "=", "self", ".", "context_attn", "(", "memory_bank", ",", "memory_bank", ",", "query_norm", ",", "\n", "mask", "=", "src_pad_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "\n", "type", "=", "\"context\"", ")", "\n", "mid", "=", "self", ".", "drop", "(", "mid", ")", "\n", "if", "self", ".", "ctx_weight_param", ":", "\n", "            ", "mid", "=", "mid", "*", "self", ".", "ctx_weight", "\n", "", "mid", "+=", "query", "\n", "mid_norm", "=", "self", ".", "context_layer_norm", "(", "mid", ")", "\n", "\n", "output", "=", "self", ".", "feed_forward", "(", "mid_norm", ")", "\n", "#output = self.feed_forward(query_norm)", "\n", "output", "=", "output", "+", "mid", "\n", "\n", "return", "output", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerGPTDecoderLayerPSA.__init__": [[196, 211], ["torch.Module.__init__", "onmt.modules.JointMultiHeadedAttention", "onmt.modules.gpt_mlp.MLP", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "heads", ",", "d_ff", ",", "dropout", ",", "attn_dropout", ",", "\n", "self_attn_type", "=", "\"scaled-dot\"", ",", "max_relative_positions", "=", "0", ",", "\n", "ctx_weight_param", "=", "False", ")", ":", "\n", "        ", "super", "(", "TransformerGPTDecoderLayerPSA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# This is called self for easier loading of gpt params", "\n", "self", ".", "self_attn", "=", "JointMultiHeadedAttention", "(", "\n", "heads", ",", "d_model", ",", "dropout", "=", "attn_dropout", ",", "\n", "max_relative_positions", "=", "max_relative_positions", ",", "\n", "ctx_weight_param", "=", "ctx_weight_param", ")", "\n", "\n", "self", ".", "feed_forward", "=", "MLP", "(", "d_model", ",", "d_model", "*", "4", ",", "dropout", ")", "\n", "self", ".", "layer_norm_1", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-5", ")", "\n", "self", ".", "layer_norm_2", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-5", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "#self.ctx_weight = Parameter(torch.zeros(1))", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerGPTDecoderLayerPSA.forward": [[213, 255], ["transformer.TransformerGPTDecoderLayerPSA.layer_norm_1", "transformer.TransformerGPTDecoderLayerPSA.self_attn", "transformer.TransformerGPTDecoderLayerPSA.layer_norm_2", "transformer.TransformerGPTDecoderLayerPSA.feed_forward", "tgt_pad_mask.size", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "future_mask.triu_().view.triu_().view.triu_().view", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "transformer.TransformerGPTDecoderLayerPSA.drop", "future_mask.triu_().view.triu_().view.triu_"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "memory_bank", ",", "src_pad_mask", ",", "tgt_pad_mask", ",", "\n", "layer_cache", "=", "None", ",", "step", "=", "None", ",", "evaluate_attns", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (FloatTensor): ``(batch_size, 1, model_dim)``\n            memory_bank (FloatTensor): ``(batch_size, src_len, model_dim)``\n            src_pad_mask (LongTensor): ``(batch_size, 1, src_len)``\n            tgt_pad_mask (LongTensor): ``(batch_size, 1, 1)``\n\n        Returns:\n            (FloatTensor, FloatTensor):\n\n            * output ``(batch_size, 1, model_dim)``\n            * attn ``(batch_size, 1, src_len)``\n\n        \"\"\"", "\n", "dec_mask", "=", "None", "\n", "if", "step", "is", "None", ":", "\n", "            ", "tgt_len", "=", "tgt_pad_mask", ".", "size", "(", "-", "1", ")", "\n", "future_mask", "=", "torch", ".", "ones", "(", "\n", "[", "tgt_len", ",", "tgt_len", "]", ",", "\n", "device", "=", "tgt_pad_mask", ".", "device", ",", "\n", "dtype", "=", "torch", ".", "uint8", ")", "\n", "future_mask", "=", "future_mask", ".", "triu_", "(", "1", ")", ".", "view", "(", "1", ",", "tgt_len", ",", "tgt_len", ")", "\n", "dec_mask", "=", "torch", ".", "gt", "(", "tgt_pad_mask", "+", "future_mask", ",", "0", ")", "\n", "\n", "", "input_norm", "=", "self", ".", "layer_norm_1", "(", "inputs", ")", "\n", "\n", "query", ",", "attn", ",", "all_attn_probs", "=", "self", ".", "self_attn", "(", "input_norm", ",", "memory_bank", ",", "self_mask", "=", "dec_mask", ",", "\n", "ctx_mask", "=", "src_pad_mask", ",", "layer_cache", "=", "layer_cache", ")", "\n", "\n", "query", "=", "self", ".", "drop", "(", "query", ")", "+", "inputs", "\n", "\n", "query_norm", "=", "self", ".", "layer_norm_2", "(", "query", ")", "\n", "\n", "output", "=", "self", ".", "feed_forward", "(", "query_norm", ")", "\n", "output", "=", "output", "+", "query", "\n", "\n", "if", "evaluate_attns", ":", "\n", "            ", "return", "output", ",", "attn", ",", "all_attn_probs", "\n", "", "else", ":", "\n", "            ", "return", "output", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerDecoderLayer.__init__": [[269, 286], ["torch.Module.__init__", "onmt.modules.MultiHeadedAttention", "onmt.modules.position_ffn.PositionwiseFeedForward", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout", "onmt.modules.MultiHeadedAttention", "onmt.modules.AverageAttention"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "heads", ",", "d_ff", ",", "dropout", ",", "attn_dropout", ",", "\n", "self_attn_type", "=", "\"scaled-dot\"", ",", "max_relative_positions", "=", "0", ")", ":", "\n", "        ", "super", "(", "TransformerDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "self_attn_type", "==", "\"scaled-dot\"", ":", "\n", "            ", "self", ".", "self_attn", "=", "MultiHeadedAttention", "(", "\n", "heads", ",", "d_model", ",", "dropout", "=", "attn_dropout", ",", "\n", "max_relative_positions", "=", "max_relative_positions", ")", "\n", "", "elif", "self_attn_type", "==", "\"average\"", ":", "\n", "            ", "self", ".", "self_attn", "=", "AverageAttention", "(", "d_model", ",", "dropout", "=", "attn_dropout", ")", "\n", "\n", "", "self", ".", "context_attn", "=", "MultiHeadedAttention", "(", "\n", "heads", ",", "d_model", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "feed_forward", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_ff", ",", "dropout", ")", "\n", "self", ".", "layer_norm_1", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "layer_norm_2", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerDecoderLayer.forward": [[287, 334], ["transformer.TransformerDecoderLayer.layer_norm_1", "isinstance", "transformer.TransformerDecoderLayer.layer_norm_2", "transformer.TransformerDecoderLayer.context_attn", "transformer.TransformerDecoderLayer.feed_forward", "tgt_pad_mask.size", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "future_mask.triu_().view.triu_().view.triu_().view", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "transformer.TransformerDecoderLayer.self_attn", "isinstance", "transformer.TransformerDecoderLayer.drop", "transformer.TransformerDecoderLayer.self_attn", "transformer.TransformerDecoderLayer.drop", "future_mask.triu_().view.triu_().view.triu_"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "memory_bank", ",", "src_pad_mask", ",", "tgt_pad_mask", ",", "\n", "layer_cache", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (FloatTensor): ``(batch_size, 1, model_dim)``\n            memory_bank (FloatTensor): ``(batch_size, src_len, model_dim)``\n            src_pad_mask (LongTensor): ``(batch_size, 1, src_len)``\n            tgt_pad_mask (LongTensor): ``(batch_size, 1, 1)``\n\n        Returns:\n            (FloatTensor, FloatTensor):\n\n            * output ``(batch_size, 1, model_dim)``\n            * attn ``(batch_size, 1, src_len)``\n\n        \"\"\"", "\n", "dec_mask", "=", "None", "\n", "if", "step", "is", "None", ":", "\n", "            ", "tgt_len", "=", "tgt_pad_mask", ".", "size", "(", "-", "1", ")", "\n", "future_mask", "=", "torch", ".", "ones", "(", "\n", "[", "tgt_len", ",", "tgt_len", "]", ",", "\n", "device", "=", "tgt_pad_mask", ".", "device", ",", "\n", "dtype", "=", "torch", ".", "uint8", ")", "\n", "future_mask", "=", "future_mask", ".", "triu_", "(", "1", ")", ".", "view", "(", "1", ",", "tgt_len", ",", "tgt_len", ")", "\n", "dec_mask", "=", "torch", ".", "gt", "(", "tgt_pad_mask", "+", "future_mask", ",", "0", ")", "\n", "\n", "", "input_norm", "=", "self", ".", "layer_norm_1", "(", "inputs", ")", "\n", "\n", "if", "isinstance", "(", "self", ".", "self_attn", ",", "MultiHeadedAttention", ")", ":", "\n", "            ", "query", ",", "attn", "=", "self", ".", "self_attn", "(", "input_norm", ",", "input_norm", ",", "input_norm", ",", "\n", "mask", "=", "dec_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "\n", "type", "=", "\"self\"", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "self_attn", ",", "AverageAttention", ")", ":", "\n", "            ", "query", ",", "attn", "=", "self", ".", "self_attn", "(", "input_norm", ",", "mask", "=", "dec_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "step", "=", "step", ")", "\n", "\n", "", "query", "=", "self", ".", "drop", "(", "query", ")", "+", "inputs", "\n", "\n", "query_norm", "=", "self", ".", "layer_norm_2", "(", "query", ")", "\n", "mid", ",", "attn", "=", "self", ".", "context_attn", "(", "memory_bank", ",", "memory_bank", ",", "query_norm", ",", "\n", "mask", "=", "src_pad_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "\n", "type", "=", "\"context\"", ")", "\n", "output", "=", "self", ".", "feed_forward", "(", "self", ".", "drop", "(", "mid", ")", "+", "query", ")", "\n", "\n", "return", "output", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerDecoder.__init__": [[366, 401], ["onmt.decoders.decoder.DecoderBase.__init__", "torch.ModuleList", "torch.ModuleList", "torch.LayerNorm", "torch.LayerNorm", "layer_cls", "range"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "d_model", ",", "heads", ",", "d_ff", ",", "\n", "copy_attn", ",", "self_attn_type", ",", "dropout", ",", "attn_dropout", ",", "embeddings", ",", "\n", "max_relative_positions", ",", "use_GPT_version_psa", ",", "\n", "use_GPT_version_unconditional", ",", "use_GPT_version_ctxattn", ",", "\n", "ctx_weight_param", ")", ":", "\n", "        ", "super", "(", "TransformerDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "\n", "# Decoder State", "\n", "self", ".", "state", "=", "{", "}", "\n", "\n", "kwargs", "=", "{", "}", "\n", "if", "use_GPT_version_ctxattn", ":", "\n", "            ", "layer_cls", "=", "TransformerGPTDecoderLayerCtxattn", "\n", "", "elif", "use_GPT_version_psa", ":", "\n", "            ", "layer_cls", "=", "TransformerGPTDecoderLayerPSA", "\n", "kwargs", "[", "'ctx_weight_param'", "]", "=", "ctx_weight_param", "\n", "", "elif", "use_GPT_version_unconditional", ":", "\n", "            ", "layer_cls", "=", "TransformerGPTUnconditionalDecoderLayer", "\n", "", "else", ":", "\n", "            ", "layer_cls", "=", "TransformerDecoderLayer", "\n", "\n", "", "self", ".", "transformer_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "layer_cls", "(", "d_model", ",", "heads", ",", "d_ff", ",", "dropout", ",", "attn_dropout", ",", "\n", "self_attn_type", "=", "self_attn_type", ",", "\n", "max_relative_positions", "=", "max_relative_positions", ",", "\n", "**", "kwargs", ")", "\n", "for", "i", "in", "range", "(", "num_layers", ")", "]", ")", "\n", "\n", "# previously, there was a GlobalAttention module here for copy", "\n", "# attention. But it was never actually used -- the \"copy\" attention", "\n", "# just reuses the context attention.", "\n", "self", ".", "_copy", "=", "copy_attn", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerDecoder.from_opt": [[402, 420], ["cls", "hasattr"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ",", "embeddings", ")", ":", "\n", "        ", "\"\"\"Alternate constructor.\"\"\"", "\n", "return", "cls", "(", "\n", "opt", ".", "dec_layers", ",", "\n", "opt", ".", "dec_rnn_size", ",", "\n", "opt", ".", "dec_heads", ",", "\n", "opt", ".", "transformer_ff", ",", "\n", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "self_attn_type", ",", "\n", "opt", ".", "dropout", ",", "\n", "opt", ".", "attn_dropout", "if", "hasattr", "(", "opt", ",", "'attn_dropout'", ")", "else", "opt", ".", "dropout", ",", "\n", "embeddings", ",", "\n", "opt", ".", "max_relative_positions", ",", "\n", "opt", ".", "use_GPT_version_psa", ",", "\n", "opt", ".", "use_GPT_version_unconditional", ",", "\n", "opt", ".", "use_GPT_version_ctxattn", ",", "\n", "opt", ".", "ctx_weight_param", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerDecoder.init_state": [[421, 425], ["None"], "methods", ["None"], ["", "def", "init_state", "(", "self", ",", "src", ",", "memory_bank", ",", "enc_hidden", ")", ":", "\n", "        ", "\"\"\"Initialize decoder state.\"\"\"", "\n", "self", ".", "state", "[", "\"src\"", "]", "=", "src", "\n", "self", ".", "state", "[", "\"cache\"", "]", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerDecoder.c": [[426, 439], ["struct.items", "fn", "transformer.TransformerDecoder.c._recursive_map"], "methods", ["None"], ["", "def", "c", "(", "self", ",", "fn", ")", ":", "\n", "        ", "def", "_recursive_map", "(", "struct", ",", "batch_dim", "=", "0", ")", ":", "\n", "            ", "for", "k", ",", "v", "in", "struct", ".", "items", "(", ")", ":", "\n", "                ", "if", "v", "is", "not", "None", ":", "\n", "                    ", "if", "isinstance", "(", "v", ",", "dict", ")", ":", "\n", "                        ", "_recursive_map", "(", "v", ")", "\n", "", "else", ":", "\n", "                        ", "struct", "[", "k", "]", "=", "fn", "(", "v", ",", "batch_dim", ")", "\n", "\n", "", "", "", "", "if", "self", ".", "state", "[", "\"src\"", "]", "is", "not", "None", ":", "\n", "            ", "self", ".", "state", "[", "\"src\"", "]", "=", "fn", "(", "self", ".", "state", "[", "\"src\"", "]", ",", "1", ")", "\n", "", "if", "self", ".", "state", "[", "\"cache\"", "]", "is", "not", "None", ":", "\n", "            ", "_recursive_map", "(", "self", ".", "state", "[", "\"cache\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerDecoder.detach_state": [[440, 442], ["transformer.TransformerDecoder.state[].detach"], "methods", ["None"], ["", "", "def", "detach_state", "(", "self", ")", ":", "\n", "        ", "self", ".", "state", "[", "\"src\"", "]", "=", "self", ".", "state", "[", "\"src\"", "]", ".", "detach", "(", ")", "if", "self", ".", "state", "[", "\"src\"", "]", "is", "not", "None", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerDecoder.forward": [[444, 527], ["transformer.TransformerDecoder.embeddings", "transformer.TransformerDecoder.transpose().contiguous", "memory_bank.transpose().contiguous", "tgt[].transpose", "tgt[].transpose.size", "tgt[].transpose.data.eq().unsqueeze", "kwargs.get", "enumerate", "transformer.TransformerDecoder.layer_norm", "transformer.TransformerDecoder.transpose().contiguous", "attn.transpose().contiguous.transpose().contiguous.transpose().contiguous", "transformer.TransformerDecoder._init_cache", "transformer.TransformerDecoder._set_cache", "len", "tgt.unsqueeze.unsqueeze.unsqueeze", "transformer.TransformerDecoder.dim", "src[].transpose", "src[].transpose.size", "src[].transpose.data.eq().unsqueeze", "transformer.TransformerDecoder._group_cache", "transformer.TransformerDecoder.transpose", "memory_bank.transpose", "tgt[].transpose.data.eq", "layer", "all_attns_full.append", "layer", "transformer.TransformerDecoder.transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "attn.transpose().contiguous.transpose().contiguous.transpose", "src[].transpose.data.eq"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerDecoder._init_cache", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerDecoder._set_cache", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerDecoder._group_cache"], ["", "def", "forward", "(", "self", ",", "tgt", ",", "memory_bank", "=", "None", ",", "step", "=", "None", ",", "past", "=", "None", ",", "pplm_return", "=", "False", ",", "input_embeds", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Decode, possibly stepwise.\"\"\"", "\n", "\n", "if", "step", "==", "0", ":", "\n", "            ", "self", ".", "_init_cache", "(", "memory_bank", ")", "\n", "", "if", "past", "is", "not", "None", "and", "pplm_return", ":", "\n", "            ", "self", ".", "_set_cache", "(", "past", ")", "\n", "\n", "", "while", "(", "len", "(", "tgt", ".", "shape", ")", "<", "3", ")", ":", "\n", "            ", "tgt", "=", "tgt", ".", "unsqueeze", "(", "0", ")", "\n", "", "emb", "=", "self", ".", "embeddings", "(", "tgt", ",", "step", "=", "step", ",", "input_embeds", "=", "input_embeds", ")", "\n", "assert", "emb", ".", "dim", "(", ")", "==", "3", "# len x batch x embedding_dim", "\n", "\n", "output", "=", "emb", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "pad_idx", "=", "self", ".", "embeddings", ".", "word_padding_idx", "\n", "\n", "src", "=", "self", ".", "state", "[", "\"src\"", "]", "\n", "if", "src", "is", "not", "None", ":", "\n", "            ", "src_words", "=", "src", "[", ":", ",", ":", ",", "0", "]", ".", "transpose", "(", "0", ",", "1", ")", "\n", "src_batch", ",", "src_len", "=", "src_words", ".", "size", "(", ")", "\n", "src_pad_mask", "=", "src_words", ".", "data", ".", "eq", "(", "pad_idx", ")", ".", "unsqueeze", "(", "1", ")", "# [B, 1, T_src]", "\n", "", "else", ":", "\n", "            ", "src_pad_mask", "=", "None", "\n", "\n", "", "src_memory_bank", "=", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "tgt_words", "=", "tgt", "[", ":", ",", ":", ",", "0", "]", ".", "transpose", "(", "0", ",", "1", ")", "\n", "tgt_batch", ",", "tgt_len", "=", "tgt_words", ".", "size", "(", ")", "\n", "tgt_pad_mask", "=", "tgt_words", ".", "data", ".", "eq", "(", "pad_idx", ")", ".", "unsqueeze", "(", "1", ")", "# [B, 1, T_tgt]", "\n", "\n", "save_all_attns", "=", "kwargs", ".", "get", "(", "'evaluate_attns'", ",", "False", ")", "\n", "all_attns_full", "=", "[", "]", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "transformer_layers", ")", ":", "\n", "# if layer_cache is None:", "\n", "            ", "layer_cache", "=", "self", ".", "state", "[", "\"cache\"", "]", "[", "\"layer_{}\"", ".", "format", "(", "i", ")", "]", "if", "step", "is", "not", "None", "else", "None", "\n", "\n", "if", "save_all_attns", ":", "\n", "                ", "output", ",", "attn", ",", "all_attns", "=", "layer", "(", "\n", "output", ",", "\n", "src_memory_bank", ",", "\n", "src_pad_mask", ",", "\n", "tgt_pad_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "\n", "step", "=", "step", ",", "\n", "evaluate_attns", "=", "True", ")", "\n", "all_attns_full", ".", "append", "(", "all_attns", ")", "\n", "", "else", ":", "\n", "                ", "output", ",", "attn", "=", "layer", "(", "\n", "output", ",", "\n", "src_memory_bank", ",", "\n", "src_pad_mask", ",", "\n", "tgt_pad_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "\n", "step", "=", "step", ")", "\n", "\n", "", "", "output", "=", "self", ".", "layer_norm", "(", "output", ")", "\n", "dec_outs", "=", "output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "if", "pplm_return", ":", "\n", "            ", "if", "self", ".", "state", "[", "'last_hidden'", "]", "is", "not", "None", ":", "\n", "                ", "all_hidden_outs", "=", "torch", ".", "cat", "(", "\n", "[", "self", ".", "state", "[", "'last_hidden'", "]", ",", "dec_outs", "]", ",", "dim", "=", "1", "\n", ")", "\n", "", "else", ":", "\n", "                ", "all_hidden_outs", "=", "dec_outs", "\n", "\n", "", "self", ".", "state", "[", "'last_hidden'", "]", "=", "all_hidden_outs", "\n", "\n", "", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "attns", "=", "{", "\"std\"", ":", "attn", "}", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "attn", "\n", "", "if", "save_all_attns", ":", "\n", "            ", "attns", "[", "'full_all_layers'", "]", "=", "all_attns_full", "\n", "\n", "# TODO change the way attns is returned dict => list or tuple (onnx)", "\n", "# return logits, past, all_hidden", "\n", "", "if", "pplm_return", ":", "\n", "            ", "past", "=", "self", ".", "_group_cache", "(", ")", "\n", "return", "dec_outs", ",", "self", ".", "state", "[", "'last_hidden'", "]", ",", "past", ",", "attns", "\n", "", "return", "dec_outs", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerDecoder.map_state": [[528, 541], ["struct.items", "fn", "transformer.TransformerDecoder.c._recursive_map"], "methods", ["None"], ["", "def", "map_state", "(", "self", ",", "fn", ")", ":", "\n", "        ", "def", "_recursive_map", "(", "struct", ",", "batch_dim", "=", "0", ")", ":", "\n", "            ", "for", "k", ",", "v", "in", "struct", ".", "items", "(", ")", ":", "\n", "                ", "if", "v", "is", "not", "None", ":", "\n", "                    ", "if", "isinstance", "(", "v", ",", "dict", ")", ":", "\n", "                        ", "_recursive_map", "(", "v", ")", "\n", "", "else", ":", "\n", "                        ", "struct", "[", "k", "]", "=", "fn", "(", "v", ",", "batch_dim", ")", "\n", "\n", "", "", "", "", "if", "self", ".", "state", "[", "\"src\"", "]", "is", "not", "None", ":", "\n", "            ", "self", ".", "state", "[", "\"src\"", "]", "=", "fn", "(", "self", ".", "state", "[", "\"src\"", "]", ",", "1", ")", "\n", "", "if", "self", ".", "state", "[", "\"cache\"", "]", "is", "not", "None", ":", "\n", "            ", "_recursive_map", "(", "self", ".", "state", "[", "\"cache\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerDecoder._init_cache": [[542, 557], ["memory_bank.size", "memory_bank.size", "enumerate", "isinstance", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "", "def", "_init_cache", "(", "self", ",", "memory_bank", ")", ":", "\n", "        ", "self", ".", "state", "[", "\"cache\"", "]", "=", "{", "}", "\n", "batch_size", "=", "memory_bank", ".", "size", "(", "1", ")", "\n", "depth", "=", "memory_bank", ".", "size", "(", "-", "1", ")", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "transformer_layers", ")", ":", "\n", "            ", "layer_cache", "=", "{", "\"memory_keys\"", ":", "None", ",", "\"memory_values\"", ":", "None", "}", "\n", "if", "isinstance", "(", "layer", ".", "self_attn", ",", "AverageAttention", ")", ":", "\n", "                ", "layer_cache", "[", "\"prev_g\"", "]", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "1", ",", "depth", ")", ")", "\n", "", "else", ":", "\n", "# ATTENTION: We should make intervention on the self_keys and self_values", "\n", "                ", "layer_cache", "[", "\"self_keys\"", "]", "=", "None", "\n", "layer_cache", "[", "\"self_values\"", "]", "=", "None", "\n", "", "self", ".", "state", "[", "\"cache\"", "]", "[", "\"layer_{}\"", ".", "format", "(", "i", ")", "]", "=", "layer_cache", "\n", "", "self", ".", "state", "[", "'last_hidden'", "]", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerDecoder._set_cache": [[558, 563], ["range", "len"], "methods", ["None"], ["", "def", "_set_cache", "(", "self", ",", "past", ")", ":", "\n", "# past is the shape 2 * batch.size * num_heads * sequence_length * embed_size", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "state", "[", "\"cache\"", "]", ")", ")", ":", "\n", "            ", "self", ".", "state", "[", "'cache'", "]", "[", "\"layer_{}\"", ".", "format", "(", "i", ")", "]", "[", "\"self_keys\"", "]", "=", "past", "[", "i", "]", "[", "[", "0", "]", "]", "\n", "self", ".", "state", "[", "'cache'", "]", "[", "\"layer_{}\"", ".", "format", "(", "i", ")", "]", "[", "\"self_values\"", "]", "=", "past", "[", "i", "]", "[", "[", "1", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.transformer.TransformerDecoder._group_cache": [[564, 571], ["range", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "", "def", "_group_cache", "(", "self", ")", ":", "\n", "        ", "past", "=", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "state", "[", "'cache'", "]", ")", ")", ":", "\n", "            ", "value", "=", "self", ".", "state", "[", "'cache'", "]", "[", "\"layer_{}\"", ".", "format", "(", "i", ")", "]", "[", "\"self_values\"", "]", "\n", "key", "=", "self", ".", "state", "[", "'cache'", "]", "[", "\"layer_{}\"", ".", "format", "(", "i", ")", "]", "[", "\"self_keys\"", "]", "\n", "past", "=", "past", "+", "(", "torch", ".", "cat", "(", "(", "key", ",", "value", ")", ",", "dim", "=", "0", ")", ",", ")", "\n", "", "return", "past", "", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.__init__": [[18, 20], ["tuple"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model_dec_outs", ")", ":", "\n", "        ", "self", ".", "model_dec_outs", "=", "tuple", "(", "model_dec_outs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze": [[21, 27], ["ensemble.EnsembleDecoderOutput", "x.squeeze"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "squeeze", "(", "self", ",", "dim", "=", "None", ")", ":", "\n", "        ", "\"\"\"Delegate squeeze to avoid modifying\n        :func:`onmt.translate.translator.Translator.translate_batch()`\n        \"\"\"", "\n", "return", "EnsembleDecoderOutput", "(", "[", "\n", "x", ".", "squeeze", "(", "dim", ")", "for", "x", "in", "self", ".", "model_dec_outs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.__getitem__": [[28, 30], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "model_dec_outs", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleEncoder.__init__": [[34, 37], ["onmt.encoders.encoder.EncoderBase.__init__", "torch.ModuleList", "torch.ModuleList"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "model_encoders", ")", ":", "\n", "        ", "super", "(", "EnsembleEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model_encoders", "=", "nn", ".", "ModuleList", "(", "model_encoders", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleEncoder.forward": [[38, 43], ["zip", "model_encoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "enc_hidden", ",", "memory_bank", ",", "_", "=", "zip", "(", "*", "[", "\n", "model_encoder", "(", "src", ",", "lengths", ")", "\n", "for", "model_encoder", "in", "self", ".", "model_encoders", "]", ")", "\n", "return", "enc_hidden", ",", "memory_bank", ",", "lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.__init__": [[47, 50], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "model_decoders", ")", ":", "\n", "        ", "super", "(", "EnsembleDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model_decoders", "=", "nn", ".", "ModuleList", "(", "model_decoders", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.forward": [[51, 64], ["zip", "ensemble.EnsembleDecoder.combine_attns", "ensemble.EnsembleDecoderOutput", "model_decoder", "enumerate"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.combine_attns"], ["", "def", "forward", "(", "self", ",", "tgt", ",", "memory_bank", ",", "memory_lengths", "=", "None", ",", "step", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"See :func:`onmt.decoders.decoder.DecoderBase.forward()`.\"\"\"", "\n", "# Memory_lengths is a single tensor shared between all models.", "\n", "# This assumption will not hold if Translator is modified", "\n", "# to calculate memory_lengths as something other than the length", "\n", "# of the input.", "\n", "dec_outs", ",", "attns", "=", "zip", "(", "*", "[", "\n", "model_decoder", "(", "\n", "tgt", ",", "memory_bank", "[", "i", "]", ",", "\n", "memory_lengths", "=", "memory_lengths", ",", "step", "=", "step", ")", "\n", "for", "i", ",", "model_decoder", "in", "enumerate", "(", "self", ".", "model_decoders", ")", "]", ")", "\n", "mean_attns", "=", "self", ".", "combine_attns", "(", "attns", ")", "\n", "return", "EnsembleDecoderOutput", "(", "dec_outs", ")", ",", "mean_attns", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.combine_attns": [[65, 70], ["attns[].keys", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "combine_attns", "(", "self", ",", "attns", ")", ":", "\n", "        ", "result", "=", "{", "}", "\n", "for", "key", "in", "attns", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "result", "[", "key", "]", "=", "torch", ".", "stack", "(", "[", "attn", "[", "key", "]", "for", "attn", "in", "attns", "]", ")", ".", "mean", "(", "0", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.init_state": [[71, 75], ["enumerate", "model_decoder.init_state"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.init_state"], ["", "def", "init_state", "(", "self", ",", "src", ",", "memory_bank", ",", "enc_hidden", ")", ":", "\n", "        ", "\"\"\" See :obj:`RNNDecoderBase.init_state()` \"\"\"", "\n", "for", "i", ",", "model_decoder", "in", "enumerate", "(", "self", ".", "model_decoders", ")", ":", "\n", "            ", "model_decoder", ".", "init_state", "(", "src", ",", "memory_bank", "[", "i", "]", ",", "enc_hidden", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.map_state": [[76, 79], ["model_decoder.map_state"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.map_state"], ["", "", "def", "map_state", "(", "self", ",", "fn", ")", ":", "\n", "        ", "for", "model_decoder", "in", "self", ".", "model_decoders", ":", "\n", "            ", "model_decoder", ".", "map_state", "(", "fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleGenerator.__init__": [[86, 90], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "model_generators", ",", "raw_probs", "=", "False", ")", ":", "\n", "        ", "super", "(", "EnsembleGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model_generators", "=", "nn", ".", "ModuleList", "(", "model_generators", ")", "\n", "self", ".", "_raw_probs", "=", "raw_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleGenerator.forward": [[91, 105], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.log", "torch.log", "torch.log", "torch.log", "torch.stack.mean", "torch.stack.mean", "torch.exp().mean", "torch.exp().mean", "torch.exp().mean", "torch.exp().mean", "mg", "mg", "zip", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log"], ["", "def", "forward", "(", "self", ",", "hidden", ",", "attn", "=", "None", ",", "src_map", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Compute a distribution over the target dictionary\n        by averaging distributions from models in the ensemble.\n        All models in the ensemble must share a target vocabulary.\n        \"\"\"", "\n", "distributions", "=", "torch", ".", "stack", "(", "\n", "[", "mg", "(", "h", ")", "if", "attn", "is", "None", "else", "mg", "(", "h", ",", "attn", ",", "src_map", ")", "\n", "for", "h", ",", "mg", "in", "zip", "(", "hidden", ",", "self", ".", "model_generators", ")", "]", "\n", ")", "\n", "if", "self", ".", "_raw_probs", ":", "\n", "            ", "return", "torch", ".", "log", "(", "torch", ".", "exp", "(", "distributions", ")", ".", "mean", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "distributions", ".", "mean", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleModel.__init__": [[109, 116], ["ensemble.EnsembleEncoder", "ensemble.EnsembleDecoder", "onmt.models.NMTModel.__init__", "ensemble.EnsembleGenerator", "torch.ModuleList", "torch.ModuleList"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "models", ",", "raw_probs", "=", "False", ")", ":", "\n", "        ", "encoder", "=", "EnsembleEncoder", "(", "model", ".", "encoder", "for", "model", "in", "models", ")", "\n", "decoder", "=", "EnsembleDecoder", "(", "model", ".", "decoder", "for", "model", "in", "models", ")", "\n", "super", "(", "EnsembleModel", ",", "self", ")", ".", "__init__", "(", "encoder", ",", "decoder", ")", "\n", "self", ".", "generator", "=", "EnsembleGenerator", "(", "\n", "[", "model", ".", "generator", "for", "model", "in", "models", "]", ",", "raw_probs", ")", "\n", "self", ".", "models", "=", "nn", ".", "ModuleList", "(", "models", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.load_test_model": [[118, 150], ["ensemble.EnsembleModel", "onmt.model_builder.load_test_model", "models.append", "fields.items", "iter", "dict", "iter"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.load_test_model"], ["", "", "def", "load_test_model", "(", "opt", ")", ":", "\n", "    ", "\"\"\"Read in multiple models for ensemble.\"\"\"", "\n", "shared_fields", "=", "None", "\n", "shared_model_opt", "=", "None", "\n", "models", "=", "[", "]", "\n", "for", "model_path", "in", "opt", ".", "models", ":", "\n", "        ", "fields", ",", "model", ",", "model_opt", "=", "onmt", ".", "model_builder", ".", "load_test_model", "(", "opt", ",", "model_path", "=", "model_path", ")", "\n", "if", "shared_fields", "is", "None", ":", "\n", "            ", "shared_fields", "=", "fields", "\n", "", "else", ":", "\n", "            ", "for", "key", ",", "field", "in", "fields", ".", "items", "(", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "f_iter", "=", "iter", "(", "field", ")", "\n", "", "except", "TypeError", ":", "\n", "                    ", "f_iter", "=", "[", "(", "key", ",", "field", ")", "]", "\n", "", "for", "sn", ",", "sf", "in", "f_iter", ":", "\n", "                    ", "if", "sf", "is", "not", "None", "and", "'vocab'", "in", "sf", ".", "__dict__", ":", "\n", "                        ", "sh_field", "=", "shared_fields", "[", "key", "]", "\n", "try", ":", "\n", "                            ", "sh_f_iter", "=", "iter", "(", "sh_field", ")", "\n", "", "except", "TypeError", ":", "\n", "                            ", "sh_f_iter", "=", "[", "(", "key", ",", "sh_field", ")", "]", "\n", "", "sh_f_dict", "=", "dict", "(", "sh_f_iter", ")", "\n", "assert", "sf", ".", "vocab", ".", "stoi", "==", "sh_f_dict", "[", "sn", "]", ".", "vocab", ".", "stoi", ",", "\"Ensemble models must use the same \"", "\"preprocessed data\"", "\n", "", "", "", "", "models", ".", "append", "(", "model", ")", "\n", "if", "shared_model_opt", "is", "None", ":", "\n", "            ", "shared_model_opt", "=", "model_opt", "\n", "", "", "ensemble_model", "=", "EnsembleModel", "(", "models", ",", "opt", ".", "avg_raw_probs", ")", "\n", "return", "shared_fields", ",", "ensemble_model", ",", "shared_model_opt", "\n", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam_search.BeamSearch.__init__": [[56, 102], ["onmt.translate.decode_strategy.DecodeStrategy.__init__", "torch.zeros", "torch.arange", "torch.arange", "torch.tensor().repeat", "torch.empty", "torch.empty", "torch.empty", "range", "torch.tensor", "float"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "beam_size", ",", "batch_size", ",", "pad", ",", "bos", ",", "eos", ",", "n_best", ",", "mb_device", ",", "\n", "global_scorer", ",", "min_length", ",", "max_length", ",", "return_attention", ",", "\n", "block_ngram_repeat", ",", "exclusion_tokens", ",", "memory_lengths", ",", "\n", "stepwise_penalty", ")", ":", "\n", "        ", "super", "(", "BeamSearch", ",", "self", ")", ".", "__init__", "(", "\n", "pad", ",", "bos", ",", "eos", ",", "batch_size", ",", "mb_device", ",", "beam_size", ",", "min_length", ",", "\n", "block_ngram_repeat", ",", "exclusion_tokens", ",", "return_attention", ",", "\n", "max_length", ")", "\n", "# beam parameters", "\n", "self", ".", "global_scorer", "=", "global_scorer", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "self", ".", "n_best", "=", "n_best", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n", "# result caching", "\n", "self", ".", "hypotheses", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "# beam state", "\n", "self", ".", "top_beam_finished", "=", "torch", ".", "zeros", "(", "[", "batch_size", "]", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "self", ".", "_batch_offset", "=", "torch", ".", "arange", "(", "batch_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "self", ".", "_beam_offset", "=", "torch", ".", "arange", "(", "\n", "0", ",", "batch_size", "*", "beam_size", ",", "step", "=", "beam_size", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "mb_device", ")", "\n", "self", ".", "topk_log_probs", "=", "torch", ".", "tensor", "(", "\n", "[", "0.0", "]", "+", "[", "float", "(", "\"-inf\"", ")", "]", "*", "(", "beam_size", "-", "1", ")", ",", "device", "=", "mb_device", "\n", ")", ".", "repeat", "(", "batch_size", ")", "\n", "self", ".", "select_indices", "=", "None", "\n", "self", ".", "_memory_lengths", "=", "memory_lengths", "\n", "\n", "# buffers for the topk scores and 'backpointer'", "\n", "self", ".", "topk_scores", "=", "torch", ".", "empty", "(", "(", "batch_size", ",", "beam_size", ")", ",", "\n", "dtype", "=", "torch", ".", "float", ",", "device", "=", "mb_device", ")", "\n", "self", ".", "topk_ids", "=", "torch", ".", "empty", "(", "(", "batch_size", ",", "beam_size", ")", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "mb_device", ")", "\n", "self", ".", "_batch_index", "=", "torch", ".", "empty", "(", "[", "batch_size", ",", "beam_size", "]", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "device", "=", "mb_device", ")", "\n", "self", ".", "done", "=", "False", "\n", "# \"global state\" of the old beam", "\n", "self", ".", "_prev_penalty", "=", "None", "\n", "self", ".", "_coverage", "=", "None", "\n", "\n", "self", ".", "_stepwise_cov_pen", "=", "(", "\n", "stepwise_penalty", "and", "self", ".", "global_scorer", ".", "has_cov_pen", ")", "\n", "self", ".", "_vanilla_cov_pen", "=", "(", "\n", "not", "stepwise_penalty", "and", "self", ".", "global_scorer", ".", "has_cov_pen", ")", "\n", "self", ".", "_cov_pen", "=", "self", ".", "global_scorer", ".", "has_cov_pen", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam_search.BeamSearch.current_predictions": [[103, 106], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "current_predictions", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "alive_seq", "[", ":", ",", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam_search.BeamSearch.current_origin": [[107, 110], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "current_origin", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "select_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam_search.BeamSearch.current_backptr": [[111, 116], ["beam_search.BeamSearch.select_indices.view().fmod", "beam_search.BeamSearch.select_indices.view"], "methods", ["None"], ["", "@", "property", "\n", "def", "current_backptr", "(", "self", ")", ":", "\n", "# for testing", "\n", "        ", "return", "self", ".", "select_indices", ".", "view", "(", "self", ".", "batch_size", ",", "self", ".", "beam_size", ")", ".", "fmod", "(", "self", ".", "beam_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam_search.BeamSearch.advance": [[117, 195], ["log_probs.size", "len", "beam_search.BeamSearch.ensure_min_length", "beam_search.BeamSearch.topk_log_probs.view", "beam_search.BeamSearch.block_ngram_repeats", "beam_search.BeamSearch.global_scorer.length_penalty", "curr_scores.reshape.reshape.reshape", "torch.topk", "torch.mul", "torch.div", "beam_search.BeamSearch._beam_offset[].unsqueeze", "beam_search.BeamSearch._batch_index.view", "beam_search.BeamSearch.topk_ids.fmod_", "torch.cat", "beam_search.BeamSearch.topk_ids.eq", "beam_search.BeamSearch.ensure_max_length", "beam_search.BeamSearch.global_scorer.cov_penalty().view", "attn.index_select", "beam_search.BeamSearch.global_scorer.cov_penalty", "beam_search.BeamSearch.view", "beam_search.BeamSearch.alive_seq.index_select", "beam_search.BeamSearch.topk_ids.view", "beam_search.BeamSearch.alive_attn.index_select", "torch.cat", "beam_search.BeamSearch.global_scorer.cov_penalty", "torch.zeros_like", "beam_search.BeamSearch._coverage.index_select", "beam_search.BeamSearch.global_scorer.cov_penalty().view", "beam_search.BeamSearch.global_scorer.cov_penalty"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.ensure_min_length", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.block_ngram_repeats", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.ensure_max_length"], ["", "def", "advance", "(", "self", ",", "log_probs", ",", "attn", ")", ":", "\n", "        ", "vocab_size", "=", "log_probs", ".", "size", "(", "-", "1", ")", "\n", "\n", "# using integer division to get an integer _B without casting", "\n", "_B", "=", "log_probs", ".", "shape", "[", "0", "]", "//", "self", ".", "beam_size", "\n", "\n", "if", "self", ".", "_stepwise_cov_pen", "and", "self", ".", "_prev_penalty", "is", "not", "None", ":", "\n", "            ", "self", ".", "topk_log_probs", "+=", "self", ".", "_prev_penalty", "\n", "self", ".", "topk_log_probs", "-=", "self", ".", "global_scorer", ".", "cov_penalty", "(", "\n", "self", ".", "_coverage", "+", "attn", ",", "self", ".", "global_scorer", ".", "beta", ")", ".", "view", "(", "\n", "_B", ",", "self", ".", "beam_size", ")", "\n", "\n", "# force the output to be longer than self.min_length", "\n", "", "step", "=", "len", "(", "self", ")", "\n", "self", ".", "ensure_min_length", "(", "log_probs", ")", "\n", "\n", "# Multiply probs by the beam probability.", "\n", "log_probs", "+=", "self", ".", "topk_log_probs", ".", "view", "(", "_B", "*", "self", ".", "beam_size", ",", "1", ")", "\n", "\n", "self", ".", "block_ngram_repeats", "(", "log_probs", ")", "\n", "\n", "# if the sequence ends now, then the penalty is the current", "\n", "# length + 1, to include the EOS token", "\n", "length_penalty", "=", "self", ".", "global_scorer", ".", "length_penalty", "(", "\n", "step", "+", "1", ",", "alpha", "=", "self", ".", "global_scorer", ".", "alpha", ")", "\n", "\n", "# Flatten probs into a list of possibilities.", "\n", "curr_scores", "=", "log_probs", "/", "length_penalty", "\n", "curr_scores", "=", "curr_scores", ".", "reshape", "(", "_B", ",", "self", ".", "beam_size", "*", "vocab_size", ")", "\n", "torch", ".", "topk", "(", "curr_scores", ",", "self", ".", "beam_size", ",", "dim", "=", "-", "1", ",", "\n", "out", "=", "(", "self", ".", "topk_scores", ",", "self", ".", "topk_ids", ")", ")", "\n", "\n", "# Recover log probs.", "\n", "# Length penalty is just a scalar. It doesn't matter if it's applied", "\n", "# before or after the topk.", "\n", "torch", ".", "mul", "(", "self", ".", "topk_scores", ",", "length_penalty", ",", "out", "=", "self", ".", "topk_log_probs", ")", "\n", "\n", "# Resolve beam origin and map to batch index flat representation.", "\n", "torch", ".", "div", "(", "self", ".", "topk_ids", ",", "vocab_size", ",", "out", "=", "self", ".", "_batch_index", ")", "\n", "self", ".", "_batch_index", "+=", "self", ".", "_beam_offset", "[", ":", "_B", "]", ".", "unsqueeze", "(", "1", ")", "\n", "self", ".", "select_indices", "=", "self", ".", "_batch_index", ".", "view", "(", "_B", "*", "self", ".", "beam_size", ")", "\n", "\n", "self", ".", "topk_ids", ".", "fmod_", "(", "vocab_size", ")", "# resolve true word ids", "\n", "\n", "# Append last prediction.", "\n", "self", ".", "alive_seq", "=", "torch", ".", "cat", "(", "\n", "[", "self", ".", "alive_seq", ".", "index_select", "(", "0", ",", "self", ".", "select_indices", ")", ",", "\n", "self", ".", "topk_ids", ".", "view", "(", "_B", "*", "self", ".", "beam_size", ",", "1", ")", "]", ",", "-", "1", ")", "\n", "if", "self", ".", "return_attention", "or", "self", ".", "_cov_pen", ":", "\n", "            ", "current_attn", "=", "attn", ".", "index_select", "(", "1", ",", "self", ".", "select_indices", ")", "\n", "if", "step", "==", "1", ":", "\n", "                ", "self", ".", "alive_attn", "=", "current_attn", "\n", "# update global state (step == 1)", "\n", "if", "self", ".", "_cov_pen", ":", "# coverage penalty", "\n", "                    ", "self", ".", "_prev_penalty", "=", "torch", ".", "zeros_like", "(", "self", ".", "topk_log_probs", ")", "\n", "self", ".", "_coverage", "=", "current_attn", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "alive_attn", "=", "self", ".", "alive_attn", ".", "index_select", "(", "\n", "1", ",", "self", ".", "select_indices", ")", "\n", "self", ".", "alive_attn", "=", "torch", ".", "cat", "(", "[", "self", ".", "alive_attn", ",", "current_attn", "]", ",", "0", ")", "\n", "# update global state (step > 1)", "\n", "if", "self", ".", "_cov_pen", ":", "\n", "                    ", "self", ".", "_coverage", "=", "self", ".", "_coverage", ".", "index_select", "(", "\n", "1", ",", "self", ".", "select_indices", ")", "\n", "self", ".", "_coverage", "+=", "current_attn", "\n", "self", ".", "_prev_penalty", "=", "self", ".", "global_scorer", ".", "cov_penalty", "(", "\n", "self", ".", "_coverage", ",", "beta", "=", "self", ".", "global_scorer", ".", "beta", ")", ".", "view", "(", "\n", "_B", ",", "self", ".", "beam_size", ")", "\n", "\n", "", "", "", "if", "self", ".", "_vanilla_cov_pen", ":", "\n", "# shape: (batch_size x beam_size, 1)", "\n", "            ", "cov_penalty", "=", "self", ".", "global_scorer", ".", "cov_penalty", "(", "\n", "self", ".", "_coverage", ",", "\n", "beta", "=", "self", ".", "global_scorer", ".", "beta", ")", "\n", "self", ".", "topk_scores", "-=", "cov_penalty", ".", "view", "(", "_B", ",", "self", ".", "beam_size", ")", "\n", "\n", "", "self", ".", "is_finished", "=", "self", ".", "topk_ids", ".", "eq", "(", "self", ".", "eos", ")", "\n", "self", ".", "ensure_max_length", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam_search.BeamSearch.update_finished": [[196, 269], ["beam_search.BeamSearch.topk_log_probs.masked_fill_", "beam_search.BeamSearch.is_finished.to", "beam_search.BeamSearch.is_finished[].eq", "beam_search.BeamSearch.is_finished[].eq().type", "beam_search.BeamSearch.alive_seq.view", "range", "torch.tensor", "beam_search.BeamSearch.top_beam_finished.index_select", "beam_search.BeamSearch._batch_offset.index_select", "non_finished.to.to.to", "beam_search.BeamSearch.topk_log_probs.index_select", "beam_search.BeamSearch._batch_index.index_select", "beam_search.BeamSearch._batch_index.view", "beam_search.BeamSearch.index_select().view", "beam_search.BeamSearch.topk_scores.index_select", "beam_search.BeamSearch.topk_ids.index_select", "beam_search.BeamSearch.alive_attn.view", "beam_search.BeamSearch.is_finished.size", "beam_search.BeamSearch.is_finished[].nonzero().view", "len", "beam_search.BeamSearch.alive_seq.size", "beam_search.BeamSearch.alive_attn.size", "attention.index_select().view", "beam_search.BeamSearch.is_finished[].eq", "beam_search.BeamSearch.alive_attn.size", "beam_search.BeamSearch.hypotheses[].append", "sorted", "enumerate", "non_finished_batch.append", "beam_search.BeamSearch.index_select", "beam_search.BeamSearch._coverage.view().index_select().view", "beam_search.BeamSearch.is_finished[].nonzero", "len", "beam_search.BeamSearch.scores[].append", "beam_search.BeamSearch.predictions[].append", "beam_search.BeamSearch.attention[].append", "attention.index_select", "beam_search.BeamSearch._prev_penalty.index_select", "beam_search.BeamSearch._coverage.view().index_select", "beam_search.BeamSearch._coverage.view"], "methods", ["None"], ["", "def", "update_finished", "(", "self", ")", ":", "\n", "# Penalize beams that finished.", "\n", "        ", "_B_old", "=", "self", ".", "topk_log_probs", ".", "shape", "[", "0", "]", "\n", "step", "=", "self", ".", "alive_seq", ".", "shape", "[", "-", "1", "]", "# 1 greater than the step in advance", "\n", "self", ".", "topk_log_probs", ".", "masked_fill_", "(", "self", ".", "is_finished", ",", "-", "1e10", ")", "\n", "# on real data (newstest2017) with the pretrained transformer,", "\n", "# it's faster to not move this back to the original device", "\n", "self", ".", "is_finished", "=", "self", ".", "is_finished", ".", "to", "(", "'cpu'", ")", "\n", "th", "=", "self", ".", "is_finished", "[", ":", ",", "0", "]", ".", "eq", "(", "1", ")", "\n", "self", ".", "top_beam_finished", "|=", "self", ".", "is_finished", "[", ":", ",", "0", "]", ".", "eq", "(", "1", ")", ".", "type", "(", "torch", ".", "ByteTensor", ")", "\n", "predictions", "=", "self", ".", "alive_seq", ".", "view", "(", "_B_old", ",", "self", ".", "beam_size", ",", "step", ")", "\n", "attention", "=", "(", "\n", "self", ".", "alive_attn", ".", "view", "(", "\n", "step", "-", "1", ",", "_B_old", ",", "self", ".", "beam_size", ",", "self", ".", "alive_attn", ".", "size", "(", "-", "1", ")", ")", "\n", "if", "self", ".", "alive_attn", "is", "not", "None", "else", "None", ")", "\n", "non_finished_batch", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "is_finished", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "b", "=", "self", ".", "_batch_offset", "[", "i", "]", "\n", "finished_hyp", "=", "self", ".", "is_finished", "[", "i", "]", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "# Store finished hypotheses for this batch.", "\n", "for", "j", "in", "finished_hyp", ":", "\n", "                ", "self", ".", "hypotheses", "[", "b", "]", ".", "append", "(", "(", "\n", "self", ".", "topk_scores", "[", "i", ",", "j", "]", ",", "\n", "predictions", "[", "i", ",", "j", ",", "1", ":", "]", ",", "# Ignore start_token.", "\n", "attention", "[", ":", ",", "i", ",", "j", ",", ":", "self", ".", "_memory_lengths", "[", "i", "]", "]", "\n", "if", "attention", "is", "not", "None", "else", "None", ")", ")", "\n", "# End condition is the top beam finished and we can return", "\n", "# n_best hypotheses.", "\n", "", "if", "self", ".", "top_beam_finished", "[", "i", "]", "and", "len", "(", "\n", "self", ".", "hypotheses", "[", "b", "]", ")", ">=", "self", ".", "n_best", ":", "\n", "                ", "best_hyp", "=", "sorted", "(", "\n", "self", ".", "hypotheses", "[", "b", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "for", "n", ",", "(", "score", ",", "pred", ",", "attn", ")", "in", "enumerate", "(", "best_hyp", ")", ":", "\n", "                    ", "if", "n", ">=", "self", ".", "n_best", ":", "\n", "                        ", "break", "\n", "", "self", ".", "scores", "[", "b", "]", ".", "append", "(", "score", ")", "\n", "self", ".", "predictions", "[", "b", "]", ".", "append", "(", "pred", ")", "\n", "self", ".", "attention", "[", "b", "]", ".", "append", "(", "\n", "attn", "if", "attn", "is", "not", "None", "else", "[", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "non_finished_batch", ".", "append", "(", "i", ")", "\n", "", "", "non_finished", "=", "torch", ".", "tensor", "(", "non_finished_batch", ")", "\n", "# If all sentences are translated, no need to go further.", "\n", "if", "len", "(", "non_finished", ")", "==", "0", ":", "\n", "            ", "self", ".", "done", "=", "True", "\n", "return", "\n", "\n", "", "_B_new", "=", "non_finished", ".", "shape", "[", "0", "]", "\n", "# Remove finished batches for the next step.", "\n", "self", ".", "top_beam_finished", "=", "self", ".", "top_beam_finished", ".", "index_select", "(", "\n", "0", ",", "non_finished", ")", "\n", "self", ".", "_batch_offset", "=", "self", ".", "_batch_offset", ".", "index_select", "(", "0", ",", "non_finished", ")", "\n", "non_finished", "=", "non_finished", ".", "to", "(", "self", ".", "topk_ids", ".", "device", ")", "\n", "self", ".", "topk_log_probs", "=", "self", ".", "topk_log_probs", ".", "index_select", "(", "0", ",", "\n", "non_finished", ")", "\n", "self", ".", "_batch_index", "=", "self", ".", "_batch_index", ".", "index_select", "(", "0", ",", "non_finished", ")", "\n", "self", ".", "select_indices", "=", "self", ".", "_batch_index", ".", "view", "(", "_B_new", "*", "self", ".", "beam_size", ")", "\n", "self", ".", "alive_seq", "=", "predictions", ".", "index_select", "(", "0", ",", "non_finished", ")", ".", "view", "(", "-", "1", ",", "self", ".", "alive_seq", ".", "size", "(", "-", "1", ")", ")", "\n", "self", ".", "topk_scores", "=", "self", ".", "topk_scores", ".", "index_select", "(", "0", ",", "non_finished", ")", "\n", "self", ".", "topk_ids", "=", "self", ".", "topk_ids", ".", "index_select", "(", "0", ",", "non_finished", ")", "\n", "if", "self", ".", "alive_attn", "is", "not", "None", ":", "\n", "            ", "inp_seq_len", "=", "self", ".", "alive_attn", ".", "size", "(", "-", "1", ")", "\n", "self", ".", "alive_attn", "=", "attention", ".", "index_select", "(", "1", ",", "non_finished", ")", ".", "view", "(", "step", "-", "1", ",", "_B_new", "*", "self", ".", "beam_size", ",", "inp_seq_len", ")", "\n", "if", "self", ".", "_cov_pen", ":", "\n", "                ", "self", ".", "_coverage", "=", "self", ".", "_coverage", ".", "view", "(", "1", ",", "_B_old", ",", "self", ".", "beam_size", ",", "inp_seq_len", ")", ".", "index_select", "(", "1", ",", "non_finished", ")", ".", "view", "(", "1", ",", "_B_new", "*", "self", ".", "beam_size", ",", "inp_seq_len", ")", "\n", "if", "self", ".", "_stepwise_cov_pen", ":", "\n", "                    ", "self", ".", "_prev_penalty", "=", "self", ".", "_prev_penalty", ".", "index_select", "(", "\n", "0", ",", "non_finished", ")", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.TranslationBuilder.__init__": [[24, 33], ["isinstance", "dict"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ",", "fields", ",", "n_best", "=", "1", ",", "replace_unk", "=", "False", ",", "\n", "has_tgt", "=", "False", ")", ":", "\n", "        ", "self", ".", "data", "=", "data", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "_has_text_src", "=", "'src'", "in", "self", ".", "fields", "and", "isinstance", "(", "\n", "dict", "(", "self", ".", "fields", ")", "[", "\"src\"", "]", ",", "TextMultiField", ")", "\n", "self", ".", "n_best", "=", "n_best", "\n", "self", ".", "replace_unk", "=", "replace_unk", "\n", "self", ".", "has_tgt", "=", "has_tgt", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.TranslationBuilder._build_target_tokens": [[34, 52], ["range", "dict", "len", "tokens.append", "tokens.append", "len", "attn[].max", "max_index.item", "len"], "methods", ["None"], ["", "def", "_build_target_tokens", "(", "self", ",", "src", ",", "src_vocab", ",", "src_raw", ",", "pred", ",", "attn", ")", ":", "\n", "        ", "tgt_field", "=", "dict", "(", "self", ".", "fields", ")", "[", "\"tgt\"", "]", ".", "base_field", "\n", "vocab", "=", "tgt_field", ".", "vocab", "\n", "tokens", "=", "[", "]", "\n", "for", "tok", "in", "pred", ":", "\n", "            ", "if", "tok", "<", "len", "(", "vocab", ")", ":", "\n", "                ", "tokens", ".", "append", "(", "vocab", ".", "itos", "[", "tok", "]", ")", "\n", "", "else", ":", "\n", "                ", "tokens", ".", "append", "(", "src_vocab", ".", "itos", "[", "tok", "-", "len", "(", "vocab", ")", "]", ")", "\n", "", "if", "tokens", "[", "-", "1", "]", "==", "tgt_field", ".", "eos_token", ":", "\n", "                ", "tokens", "=", "tokens", "[", ":", "-", "1", "]", "\n", "break", "\n", "", "", "if", "self", ".", "replace_unk", "and", "attn", "is", "not", "None", "and", "src", "is", "not", "None", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "tokens", ")", ")", ":", "\n", "                ", "if", "tokens", "[", "i", "]", "==", "tgt_field", ".", "unk_token", ":", "\n", "                    ", "_", ",", "max_index", "=", "attn", "[", "i", "]", ".", "max", "(", "0", ")", "\n", "tokens", "[", "i", "]", "=", "src_raw", "[", "max_index", ".", "item", "(", ")", "]", "\n", "", "", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.TranslationBuilder.from_batch": [[53, 109], ["list", "torch.sort", "range", "len", "len", "zip", "[].index_select", "tgt[].index_select", "Translation.Translation", "translations.append", "isinstance", "Translation.TranslationBuilder._build_target_tokens", "Translation.TranslationBuilder._build_target_tokens", "sorted", "range", "zip"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.TranslationBuilder._build_target_tokens", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.TranslationBuilder._build_target_tokens"], ["", "def", "from_batch", "(", "self", ",", "translation_batch", ")", ":", "\n", "        ", "batch", "=", "translation_batch", "[", "\"batch\"", "]", "\n", "assert", "(", "len", "(", "translation_batch", "[", "\"gold_score\"", "]", ")", "==", "\n", "len", "(", "translation_batch", "[", "\"predictions\"", "]", ")", ")", "\n", "batch_size", "=", "batch", ".", "batch_size", "\n", "\n", "preds", ",", "pred_score", ",", "attn", ",", "gold_score", ",", "indices", "=", "list", "(", "zip", "(", "\n", "*", "sorted", "(", "zip", "(", "translation_batch", "[", "\"predictions\"", "]", ",", "\n", "translation_batch", "[", "\"scores\"", "]", ",", "\n", "translation_batch", "[", "\"attention\"", "]", ",", "\n", "translation_batch", "[", "\"gold_score\"", "]", ",", "\n", "batch", ".", "indices", ".", "data", ")", ",", "\n", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ")", ")", ")", "\n", "\n", "# Sorting", "\n", "inds", ",", "perm", "=", "torch", ".", "sort", "(", "batch", ".", "indices", ")", "\n", "if", "self", ".", "_has_text_src", ":", "\n", "            ", "src", "=", "batch", ".", "src", "[", "0", "]", "[", ":", ",", ":", ",", "0", "]", ".", "index_select", "(", "1", ",", "perm", ")", "\n", "", "else", ":", "\n", "            ", "src", "=", "None", "\n", "\n", "", "if", "self", ".", "has_tgt", ":", "\n", "            ", "tgt", ",", "_", "=", "batch", ".", "tgt", "if", "isinstance", "(", "batch", ".", "tgt", ",", "tuple", ")", "else", "(", "batch", ".", "tgt", ",", "None", ")", "\n", "tgt", "=", "tgt", "[", ":", ",", ":", ",", "0", "]", ".", "index_select", "(", "1", ",", "perm", ")", "\n", "", "else", ":", "\n", "            ", "tgt", "=", "None", "\n", "\n", "", "translations", "=", "[", "]", "\n", "for", "b", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "if", "self", ".", "_has_text_src", ":", "\n", "                ", "src_vocab", "=", "self", ".", "data", ".", "src_vocabs", "[", "inds", "[", "b", "]", "]", "if", "self", ".", "data", ".", "src_vocabs", "else", "None", "\n", "src_raw", "=", "self", ".", "data", ".", "examples", "[", "inds", "[", "b", "]", "]", ".", "src", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "src_vocab", "=", "None", "\n", "src_raw", "=", "None", "\n", "", "pred_sents", "=", "[", "self", ".", "_build_target_tokens", "(", "\n", "src", "[", ":", ",", "b", "]", "if", "src", "is", "not", "None", "else", "None", ",", "\n", "src_vocab", ",", "src_raw", ",", "\n", "preds", "[", "b", "]", "[", "n", "]", ",", "attn", "[", "b", "]", "[", "n", "]", ")", "\n", "for", "n", "in", "range", "(", "self", ".", "n_best", ")", "]", "\n", "gold_sent", "=", "None", "\n", "if", "tgt", "is", "not", "None", ":", "\n", "                ", "gold_sent", "=", "self", ".", "_build_target_tokens", "(", "\n", "src", "[", ":", ",", "b", "]", "if", "src", "is", "not", "None", "else", "None", ",", "\n", "src_vocab", ",", "src_raw", ",", "\n", "tgt", "[", "1", ":", ",", "b", "]", "if", "tgt", "is", "not", "None", "else", "None", ",", "None", ")", "\n", "\n", "", "translation", "=", "Translation", "(", "\n", "src", "[", ":", ",", "b", "]", "if", "src", "is", "not", "None", "else", "None", ",", "\n", "src_raw", ",", "pred_sents", ",", "attn", "[", "b", "]", ",", "pred_score", "[", "b", "]", ",", "\n", "gold_sent", ",", "gold_score", "[", "b", "]", "\n", ")", "\n", "translations", ".", "append", "(", "translation", ")", "\n", "\n", "", "return", "translations", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.__init__": [[128, 137], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "src", ",", "src_raw", ",", "pred_sents", ",", "\n", "attn", ",", "pred_scores", ",", "tgt_sent", ",", "gold_score", ")", ":", "\n", "        ", "self", ".", "src", "=", "src", "\n", "self", ".", "src_raw", "=", "src_raw", "\n", "self", ".", "pred_sents", "=", "pred_sents", "\n", "self", ".", "attns", "=", "attn", "\n", "self", ".", "pred_scores", "=", "pred_scores", "\n", "self", ".", "gold_sent", "=", "tgt_sent", "\n", "self", ".", "gold_score", "=", "gold_score", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log": [[138, 161], ["msg.append", "msg.append", "msg.append", "msg.append", "len", "msg.append", "zip", "msg.append"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "sent_number", ")", ":", "\n", "        ", "\"\"\"\n        Log translation.\n        \"\"\"", "\n", "\n", "msg", "=", "[", "'\\nSENT {}: {}\\n'", ".", "format", "(", "sent_number", ",", "self", ".", "src_raw", ")", "]", "\n", "\n", "best_pred", "=", "self", ".", "pred_sents", "[", "0", "]", "\n", "best_score", "=", "self", ".", "pred_scores", "[", "0", "]", "\n", "pred_sent", "=", "' '", ".", "join", "(", "best_pred", ")", "\n", "msg", ".", "append", "(", "'PRED {}: {}\\n'", ".", "format", "(", "sent_number", ",", "pred_sent", ")", ")", "\n", "msg", ".", "append", "(", "\"PRED SCORE: {:.4f}\\n\"", ".", "format", "(", "best_score", ")", ")", "\n", "\n", "if", "self", ".", "gold_sent", "is", "not", "None", ":", "\n", "            ", "tgt_sent", "=", "' '", ".", "join", "(", "self", ".", "gold_sent", ")", "\n", "msg", ".", "append", "(", "'GOLD {}: {}\\n'", ".", "format", "(", "sent_number", ",", "tgt_sent", ")", ")", "\n", "msg", ".", "append", "(", "(", "\"GOLD SCORE: {:.4f}\\n\"", ".", "format", "(", "self", ".", "gold_score", ")", ")", ")", "\n", "", "if", "len", "(", "self", ".", "pred_sents", ")", ">", "1", ":", "\n", "            ", "msg", ".", "append", "(", "'\\nBEST HYP:\\n'", ")", "\n", "for", "score", ",", "sent", "in", "zip", "(", "self", ".", "pred_scores", ",", "self", ".", "pred_sents", ")", ":", "\n", "                ", "msg", ".", "append", "(", "\"[{:.4f}] {}\\n\"", ".", "format", "(", "score", ",", "sent", ")", ")", "\n", "\n", "", "", "return", "\"\"", ".", "join", "(", "msg", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator.__init__": [[87, 188], ["frozenset", "print", "len", "onmt.utils.misc.set_random_seed", "onmt.utils.misc.set_random_seed", "onmt.utils.misc.set_random_seed", "onmt.utils.misc.set_random_seed", "torch.device", "torch.device", "ValueError", "ValueError", "dict"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.set_random_seed", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.set_random_seed", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.set_random_seed", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.set_random_seed"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "fields", ",", "\n", "src_reader", ",", "\n", "tgt_reader", ",", "\n", "gpu", "=", "-", "1", ",", "\n", "n_best", "=", "1", ",", "\n", "min_length", "=", "0", ",", "\n", "max_length", "=", "100", ",", "\n", "beam_size", "=", "30", ",", "\n", "random_sampling_topk", "=", "1", ",", "\n", "random_sampling_temp", "=", "1", ",", "\n", "stepwise_penalty", "=", "None", ",", "\n", "dump_beam", "=", "False", ",", "\n", "block_ngram_repeat", "=", "0", ",", "\n", "ignore_when_blocking", "=", "frozenset", "(", ")", ",", "\n", "replace_unk", "=", "False", ",", "\n", "data_type", "=", "\"text\"", ",", "\n", "verbose", "=", "False", ",", "\n", "report_bleu", "=", "False", ",", "\n", "report_rouge", "=", "False", ",", "\n", "report_time", "=", "False", ",", "\n", "copy_attn", "=", "False", ",", "\n", "simple_fusion", "=", "False", ",", "\n", "gpt_tgt", "=", "False", ",", "\n", "global_scorer", "=", "None", ",", "\n", "out_file", "=", "None", ",", "\n", "report_score", "=", "True", ",", "\n", "logger", "=", "None", ",", "\n", "seed", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "fields", "=", "fields", "\n", "tgt_field", "=", "dict", "(", "self", ".", "fields", ")", "[", "\"tgt\"", "]", ".", "base_field", "\n", "self", ".", "_tgt_vocab", "=", "tgt_field", ".", "vocab", "\n", "self", ".", "_tgt_eos_idx", "=", "self", ".", "_tgt_vocab", ".", "stoi", "[", "tgt_field", ".", "eos_token", "]", "\n", "self", ".", "_tgt_pad_idx", "=", "self", ".", "_tgt_vocab", ".", "stoi", "[", "tgt_field", ".", "pad_token", "]", "\n", "self", ".", "_tgt_bos_idx", "=", "self", ".", "_tgt_vocab", ".", "stoi", "[", "tgt_field", ".", "init_token", "]", "\n", "#self._tgt_bos_idx = self._tgt_vocab.stoi['\u0120see']", "\n", "print", "(", "self", ".", "_tgt_bos_idx", ")", "\n", "self", ".", "_tgt_unk_idx", "=", "self", ".", "_tgt_vocab", ".", "stoi", "[", "tgt_field", ".", "unk_token", "]", "\n", "self", ".", "_tgt_vocab_len", "=", "len", "(", "self", ".", "_tgt_vocab", ")", "\n", "\n", "self", ".", "_gpu", "=", "gpu", "\n", "self", ".", "_use_cuda", "=", "gpu", ">", "-", "1", "\n", "self", ".", "_dev", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "self", ".", "_gpu", ")", "if", "self", ".", "_use_cuda", "else", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "self", ".", "n_best", "=", "n_best", "\n", "self", ".", "max_length", "=", "max_length", "\n", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "self", ".", "random_sampling_temp", "=", "random_sampling_temp", "\n", "self", ".", "sample_from_topk", "=", "random_sampling_topk", "\n", "\n", "self", ".", "min_length", "=", "min_length", "\n", "self", ".", "stepwise_penalty", "=", "stepwise_penalty", "\n", "self", ".", "dump_beam", "=", "dump_beam", "\n", "self", ".", "block_ngram_repeat", "=", "block_ngram_repeat", "\n", "self", ".", "ignore_when_blocking", "=", "ignore_when_blocking", "\n", "self", ".", "_exclusion_idxs", "=", "{", "\n", "self", ".", "_tgt_vocab", ".", "stoi", "[", "t", "]", "for", "t", "in", "self", ".", "ignore_when_blocking", "}", "\n", "self", ".", "src_reader", "=", "src_reader", "\n", "self", ".", "tgt_reader", "=", "tgt_reader", "\n", "self", ".", "replace_unk", "=", "replace_unk", "\n", "if", "self", ".", "replace_unk", "and", "not", "self", ".", "model", ".", "decoder", ".", "attentional", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"replace_unk requires an attentional decoder.\"", ")", "\n", "", "self", ".", "data_type", "=", "data_type", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "report_bleu", "=", "report_bleu", "\n", "self", ".", "report_rouge", "=", "report_rouge", "\n", "self", ".", "report_time", "=", "report_time", "\n", "\n", "self", ".", "copy_attn", "=", "copy_attn", "\n", "self", ".", "simple_fusion", "=", "simple_fusion", "\n", "self", ".", "gpt_tgt", "=", "gpt_tgt", "\n", "\n", "self", ".", "global_scorer", "=", "global_scorer", "\n", "if", "self", ".", "global_scorer", ".", "has_cov_pen", "and", "not", "self", ".", "model", ".", "decoder", ".", "attentional", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Coverage penalty requires an attentional decoder.\"", ")", "\n", "", "self", ".", "out_file", "=", "out_file", "\n", "self", ".", "report_score", "=", "report_score", "\n", "self", ".", "logger", "=", "logger", "\n", "\n", "self", ".", "use_filter_pred", "=", "False", "\n", "self", ".", "_filter_pred", "=", "None", "\n", "\n", "# for debugging", "\n", "self", ".", "beam_trace", "=", "self", ".", "dump_beam", "!=", "\"\"", "\n", "self", ".", "beam_accum", "=", "None", "\n", "if", "self", ".", "beam_trace", ":", "\n", "            ", "self", ".", "beam_accum", "=", "{", "\n", "\"predicted_ids\"", ":", "[", "]", ",", "\n", "\"beam_parent_ids\"", ":", "[", "]", ",", "\n", "\"scores\"", ":", "[", "]", ",", "\n", "\"log_probs\"", ":", "[", "]", "}", "\n", "\n", "", "set_random_seed", "(", "seed", ",", "self", ".", "_use_cuda", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator.from_opt": [[189, 252], ["onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "cls", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "set"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt"], ["", "@", "classmethod", "\n", "def", "from_opt", "(", "\n", "cls", ",", "\n", "model", ",", "\n", "fields", ",", "\n", "opt", ",", "\n", "model_opt", ",", "\n", "global_scorer", "=", "None", ",", "\n", "out_file", "=", "None", ",", "\n", "report_score", "=", "True", ",", "\n", "logger", "=", "None", ")", ":", "\n", "        ", "\"\"\"Alternate constructor.\n\n        Args:\n            model (onmt.modules.NMTModel): See :func:`__init__()`.\n            fields (dict[str, torchtext.data.Field]): See\n                :func:`__init__()`.\n            opt (argparse.Namespace): Command line options\n            model_opt (argparse.Namespace): Command line options saved with\n                the model checkpoint.\n            global_scorer (onmt.translate.GNMTGlobalScorer): See\n                :func:`__init__()`..\n            out_file (TextIO or codecs.StreamReaderWriter): See\n                :func:`__init__()`.\n            report_score (bool) : See :func:`__init__()`.\n            logger (logging.Logger or NoneType): See :func:`__init__()`.\n        \"\"\"", "\n", "\n", "if", "opt", ".", "data_type", "==", "'none'", ":", "\n", "            ", "src_reader", "=", "None", "\n", "", "else", ":", "\n", "            ", "src_reader", "=", "inputters", ".", "str2reader", "[", "opt", ".", "data_type", "]", ".", "from_opt", "(", "opt", ")", "\n", "", "tgt_reader", "=", "inputters", ".", "str2reader", "[", "\"text\"", "]", ".", "from_opt", "(", "opt", ")", "\n", "return", "cls", "(", "\n", "model", ",", "\n", "fields", ",", "\n", "src_reader", ",", "\n", "tgt_reader", ",", "\n", "gpu", "=", "opt", ".", "gpu", ",", "\n", "n_best", "=", "opt", ".", "n_best", ",", "\n", "min_length", "=", "opt", ".", "min_length", ",", "\n", "max_length", "=", "opt", ".", "max_length", ",", "\n", "beam_size", "=", "opt", ".", "beam_size", ",", "\n", "random_sampling_topk", "=", "opt", ".", "random_sampling_topk", ",", "\n", "random_sampling_temp", "=", "opt", ".", "random_sampling_temp", ",", "\n", "stepwise_penalty", "=", "opt", ".", "stepwise_penalty", ",", "\n", "dump_beam", "=", "opt", ".", "dump_beam", ",", "\n", "block_ngram_repeat", "=", "opt", ".", "block_ngram_repeat", ",", "\n", "ignore_when_blocking", "=", "set", "(", "opt", ".", "ignore_when_blocking", ")", ",", "\n", "replace_unk", "=", "opt", ".", "replace_unk", ",", "\n", "data_type", "=", "opt", ".", "data_type", ",", "\n", "verbose", "=", "opt", ".", "verbose", ",", "\n", "report_bleu", "=", "opt", ".", "report_bleu", ",", "\n", "report_rouge", "=", "opt", ".", "report_rouge", ",", "\n", "report_time", "=", "opt", ".", "report_time", ",", "\n", "copy_attn", "=", "model_opt", ".", "copy_attn", ",", "\n", "simple_fusion", "=", "model_opt", ".", "simple_fusion", ",", "\n", "gpt_tgt", "=", "model_opt", ".", "GPT_representation_mode", "!=", "'none'", "and", "model_opt", ".", "GPT_representation_loc", "in", "[", "'tgt'", ",", "'both'", "]", ",", "\n", "global_scorer", "=", "global_scorer", ",", "\n", "out_file", "=", "out_file", ",", "\n", "report_score", "=", "report_score", ",", "\n", "logger", "=", "logger", ",", "\n", "seed", "=", "opt", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._log": [[253, 258], ["translator.Translator.logger.info", "print"], "methods", ["None"], ["", "def", "_log", "(", "self", ",", "msg", ")", ":", "\n", "        ", "if", "self", ".", "logger", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "msg", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._gold_score": [[259, 271], ["translator.Translator._score_target", "translator.Translator.model.decoder.init_state", "translator.Translator.model.lm_decoder.init_state"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._score_target", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.init_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.init_state"], ["", "", "def", "_gold_score", "(", "self", ",", "batch", ",", "memory_bank", ",", "src_lengths", ",", "src_vocabs", ",", "\n", "use_src_map", ",", "enc_states", ",", "batch_size", ",", "src", ")", ":", "\n", "        ", "if", "\"tgt\"", "in", "batch", ".", "__dict__", ":", "\n", "            ", "gs", "=", "self", ".", "_score_target", "(", "\n", "batch", ",", "memory_bank", ",", "src_lengths", ",", "src_vocabs", ",", "\n", "batch", ".", "src_map", "if", "use_src_map", "else", "None", ")", "\n", "self", ".", "model", ".", "decoder", ".", "init_state", "(", "src", ",", "memory_bank", ",", "enc_states", ")", "\n", "if", "self", ".", "simple_fusion", ":", "\n", "                ", "self", ".", "model", ".", "lm_decoder", ".", "init_state", "(", "src", ",", "None", ",", "None", ")", "\n", "", "", "else", ":", "\n", "            ", "gs", "=", "[", "0", "]", "*", "batch_size", "\n", "", "return", "gs", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator.translate": [[272, 441], ["onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "onmt.OrderedIterator", "onmt.OrderedIterator", "onmt.OrderedIterator", "onmt.OrderedIterator", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "itertools.count", "time.time", "time.time", "ValueError", "translator.Translator.translate_batch", "onmt.translate.TranslationBuilder.from_batch", "onmt.translate.TranslationBuilder.from_batch", "onmt.translate.TranslationBuilder.from_batch", "onmt.translate.TranslationBuilder.from_batch", "translator.Translator._report_score", "translator.Translator._log", "translator.Translator._log", "translator.Translator._log", "translator.Translator._log", "json.dump", "max", "torch.nn.utils.rnn.pad_sequence", "len", "translator.Translator.out_file.write", "translator.Translator.out_file.flush", "translator.Translator._report_score", "translator.Translator._log", "codecs.open", "torch.tensor", "print", "next", "trans.log", "preds.append", "trans.attns[].tolist", "zip", "os.write", "translator.Translator._report_bleu", "translator.Translator._log", "translator.Translator._report_rouge", "translator.Translator._log", "len", "batch.src[].max().item", "batch.src[].max().item", "batch.src[].max().item", "len", "translator.Translator.logger.info", "os.write", "header_format.format", "row.index", "row_format.replace.replace.replace", "row_format.replace.replace.replace", "trans.log.encode", "len", "trans.log.encode", "str", "len", "len", "max", "row_format.replace.replace.format", "batch.src[].max", "batch.src[].max", "batch.src[].max", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator.translate_batch", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.TranslationBuilder.from_batch", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.TranslationBuilder.from_batch", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.TranslationBuilder.from_batch", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.TranslationBuilder.from_batch", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._report_score", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._report_score", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._report_bleu", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._report_rouge", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write"], ["", "def", "translate", "(", "\n", "self", ",", "\n", "src", ",", "\n", "tgt", "=", "None", ",", "\n", "src_dir", "=", "None", ",", "\n", "batch_size", "=", "None", ",", "\n", "attn_debug", "=", "False", ",", "\n", "tag_shard", "=", "None", ")", ":", "\n", "        ", "\"\"\"Translate content of ``src`` and get gold scores from ``tgt``.\n\n        Args:\n            src: See :func:`self.src_reader.read()`.\n            tgt: See :func:`self.tgt_reader.read()`.\n            src_dir: See :func:`self.src_reader.read()` (only relevant\n                for certain types of data).\n            batch_size (int): size of examples per mini-batch\n            attn_debug (bool): enables the attention logging\n\n        Returns:\n            (`list`, `list`)\n\n            * all_scores is a list of `batch_size` lists of `n_best` scores\n            * all_predictions is a list of `batch_size` lists\n                of `n_best` predictions\n        \"\"\"", "\n", "\n", "if", "batch_size", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"batch_size must be set\"", ")", "\n", "\n", "", "readers", ",", "data", ",", "dirs", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "if", "self", ".", "src_reader", ":", "\n", "            ", "readers", "+=", "[", "self", ".", "src_reader", "]", "\n", "data", "+=", "[", "(", "\"src\"", ",", "src", ")", "]", "\n", "dirs", "+=", "[", "src_dir", "]", "\n", "", "if", "tgt", ":", "\n", "            ", "readers", "+=", "[", "self", ".", "tgt_reader", "]", "\n", "data", "+=", "[", "(", "\"tgt\"", ",", "tgt", ")", "]", "\n", "dirs", "+=", "[", "None", "]", "\n", "\n", "", "data", "=", "inputters", ".", "Dataset", "(", "\n", "self", ".", "fields", ",", "\n", "readers", "=", "readers", ",", "\n", "data", "=", "data", ",", "\n", "dirs", "=", "dirs", ",", "\n", "sort_key", "=", "inputters", ".", "str2sortkey", "[", "self", ".", "data_type", "]", ",", "\n", "filter_pred", "=", "self", ".", "_filter_pred", "\n", ")", "\n", "\n", "data_iter", "=", "inputters", ".", "OrderedIterator", "(", "\n", "dataset", "=", "data", ",", "\n", "device", "=", "self", ".", "_dev", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "train", "=", "False", ",", "\n", "sort", "=", "False", ",", "\n", "sort_within_batch", "=", "True", ",", "\n", "shuffle", "=", "False", "\n", ")", "\n", "\n", "xlation_builder", "=", "onmt", ".", "translate", ".", "TranslationBuilder", "(", "\n", "data", ",", "self", ".", "fields", ",", "self", ".", "n_best", ",", "self", ".", "replace_unk", ",", "tgt", "\n", ")", "\n", "\n", "# Statistics", "\n", "counter", "=", "count", "(", "1", ")", "\n", "pred_score_total", ",", "pred_words_total", "=", "0", ",", "0", "\n", "gold_score_total", ",", "gold_words_total", "=", "0", ",", "0", "\n", "\n", "all_scores", "=", "[", "]", "\n", "all_predictions", "=", "[", "]", "\n", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "batch", "in", "data_iter", ":", "\n", "#tagss = [tag_shard[i] for i in batch.indices]", "\n", "\n", "#print('----------------------')", "\n", "#print(batch.indices[4])", "\n", "#print(words[4][:5])", "\n", "#print(batch.src[0][:5, 4, 0].cpu().numpy())", "\n", "#print(len(words[4]), batch.src[0].shape)", "\n", "\n", "            ", "if", "tag_shard", "is", "not", "None", ":", "\n", "                ", "max_len", "=", "max", "(", "[", "len", "(", "tag_shard", "[", "i", "]", ")", "for", "i", "in", "batch", ".", "indices", "]", ")", "\n", "cur_tags", "=", "[", "torch", ".", "tensor", "(", "tag_shard", "[", "i", "]", ",", "device", "=", "batch", ".", "src", "[", "0", "]", ".", "device", ",", "dtype", "=", "torch", ".", "float", ")", "for", "i", "in", "batch", ".", "indices", "]", "\n", "cur_tags_padded", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "cur_tags", ",", "padding_value", "=", "0", ")", "\n", "if", "batch", ".", "src", "[", "0", "]", ".", "shape", "[", "0", "]", "!=", "batch", ".", "src", "[", "1", "]", ".", "max", "(", ")", ".", "item", "(", ")", "or", "cur_tags_padded", ".", "shape", "[", "0", "]", "!=", "max_len", "or", "max_len", "!=", "batch", ".", "src", "[", "1", "]", ".", "max", "(", ")", ".", "item", "(", ")", ":", "\n", "                    ", "print", "(", "batch", ".", "src", "[", "0", "]", ".", "shape", ",", "batch", ".", "src", "[", "1", "]", ".", "max", "(", ")", ".", "item", "(", ")", ",", "cur_tags_padded", ".", "shape", ",", "max_len", ")", "\n", "raise", "ValueError", "\n", "", "", "else", ":", "\n", "                ", "cur_tags_padded", "=", "None", "\n", "\n", "", "batch_data", "=", "self", ".", "translate_batch", "(", "\n", "batch", ",", "data", ".", "src_vocabs", ",", "attn_debug", ",", "tags", "=", "cur_tags_padded", "\n", ")", "\n", "translations", "=", "xlation_builder", ".", "from_batch", "(", "batch_data", ")", "\n", "\n", "for", "trans", "in", "translations", ":", "\n", "                ", "all_scores", "+=", "[", "trans", ".", "pred_scores", "[", ":", "self", ".", "n_best", "]", "]", "\n", "pred_score_total", "+=", "trans", ".", "pred_scores", "[", "0", "]", "\n", "pred_words_total", "+=", "len", "(", "trans", ".", "pred_sents", "[", "0", "]", ")", "\n", "if", "tgt", "is", "not", "None", ":", "\n", "                    ", "gold_score_total", "+=", "trans", ".", "gold_score", "\n", "gold_words_total", "+=", "len", "(", "trans", ".", "gold_sent", ")", "+", "1", "\n", "\n", "", "n_best_preds", "=", "[", "\" \"", ".", "join", "(", "pred", ")", "\n", "for", "pred", "in", "trans", ".", "pred_sents", "[", ":", "self", ".", "n_best", "]", "]", "\n", "all_predictions", "+=", "[", "n_best_preds", "]", "\n", "self", ".", "out_file", ".", "write", "(", "'\\n'", ".", "join", "(", "n_best_preds", ")", "+", "'\\n'", ")", "\n", "self", ".", "out_file", ".", "flush", "(", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "                    ", "sent_number", "=", "next", "(", "counter", ")", "\n", "output", "=", "trans", ".", "log", "(", "sent_number", ")", "\n", "if", "self", ".", "logger", ":", "\n", "                        ", "self", ".", "logger", ".", "info", "(", "output", ")", "\n", "", "else", ":", "\n", "                        ", "os", ".", "write", "(", "1", ",", "output", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "\n", "", "", "if", "attn_debug", ":", "\n", "                    ", "preds", "=", "trans", ".", "pred_sents", "[", "0", "]", "\n", "preds", ".", "append", "(", "'</s>'", ")", "\n", "attns", "=", "trans", ".", "attns", "[", "0", "]", ".", "tolist", "(", ")", "\n", "if", "self", ".", "data_type", "==", "'text'", ":", "\n", "                        ", "srcs", "=", "trans", ".", "src_raw", "\n", "", "else", ":", "\n", "                        ", "srcs", "=", "[", "str", "(", "item", ")", "for", "item", "in", "range", "(", "len", "(", "attns", "[", "0", "]", ")", ")", "]", "\n", "", "header_format", "=", "\"{:>10.10} \"", "+", "\"{:>10.7} \"", "*", "len", "(", "srcs", ")", "\n", "row_format", "=", "\"{:>10.10} \"", "+", "\"{:>10.7f} \"", "*", "len", "(", "srcs", ")", "\n", "output", "=", "header_format", ".", "format", "(", "\"\"", ",", "*", "srcs", ")", "+", "'\\n'", "\n", "for", "word", ",", "row", "in", "zip", "(", "preds", ",", "attns", ")", ":", "\n", "                        ", "max_index", "=", "row", ".", "index", "(", "max", "(", "row", ")", ")", "\n", "row_format", "=", "row_format", ".", "replace", "(", "\n", "\"{:>10.7f} \"", ",", "\"{:*>10.7f} \"", ",", "max_index", "+", "1", ")", "\n", "row_format", "=", "row_format", ".", "replace", "(", "\n", "\"{:*>10.7f} \"", ",", "\"{:>10.7f} \"", ",", "max_index", ")", "\n", "output", "+=", "row_format", ".", "format", "(", "word", ",", "*", "row", ")", "+", "'\\n'", "\n", "row_format", "=", "\"{:>10.10} \"", "+", "\"{:>10.7f} \"", "*", "len", "(", "srcs", ")", "\n", "", "os", ".", "write", "(", "1", ",", "output", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "\n", "", "", "", "end_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "self", ".", "report_score", ":", "\n", "            ", "msg", "=", "self", ".", "_report_score", "(", "'PRED'", ",", "pred_score_total", ",", "\n", "pred_words_total", ")", "\n", "self", ".", "_log", "(", "msg", ")", "\n", "if", "tgt", "is", "not", "None", ":", "\n", "                ", "msg", "=", "self", ".", "_report_score", "(", "'GOLD'", ",", "gold_score_total", ",", "\n", "gold_words_total", ")", "\n", "self", ".", "_log", "(", "msg", ")", "\n", "if", "self", ".", "report_bleu", ":", "\n", "                    ", "msg", "=", "self", ".", "_report_bleu", "(", "tgt", ")", "\n", "self", ".", "_log", "(", "msg", ")", "\n", "", "if", "self", ".", "report_rouge", ":", "\n", "                    ", "msg", "=", "self", ".", "_report_rouge", "(", "tgt", ")", "\n", "self", ".", "_log", "(", "msg", ")", "\n", "\n", "", "", "", "if", "self", ".", "report_time", ":", "\n", "            ", "total_time", "=", "end_time", "-", "start_time", "\n", "self", ".", "_log", "(", "\"Total translation time (s): %f\"", "%", "total_time", ")", "\n", "self", ".", "_log", "(", "\"Average translation time (s): %f\"", "%", "(", "\n", "total_time", "/", "len", "(", "all_predictions", ")", ")", ")", "\n", "self", ".", "_log", "(", "\"Tokens per second: %f\"", "%", "(", "\n", "pred_words_total", "/", "total_time", ")", ")", "\n", "\n", "", "if", "self", ".", "dump_beam", ":", "\n", "            ", "import", "json", "\n", "json", ".", "dump", "(", "self", ".", "translator", ".", "beam_accum", ",", "\n", "codecs", ".", "open", "(", "self", ".", "dump_beam", ",", "'w'", ",", "'utf-8'", ")", ")", "\n", "", "return", "all_scores", ",", "all_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._translate_random_sampling": [[444, 559], ["translator.Translator._run_encoder", "translator.Translator.model.decoder.init_state", "onmt.translate.random_sampling.RandomSampling", "onmt.translate.random_sampling.RandomSampling", "onmt.translate.random_sampling.RandomSampling", "onmt.translate.random_sampling.RandomSampling", "range", "translator.Translator.model.lm_decoder.init_state", "translator.Translator._gold_score", "isinstance", "isinstance", "isinstance", "onmt.translate.random_sampling.RandomSampling.alive_seq[].view", "onmt.translate.random_sampling.RandomSampling.alive_seq[].view", "onmt.translate.random_sampling.RandomSampling.alive_seq[].view", "onmt.translate.random_sampling.RandomSampling.alive_seq[].view", "translator.Translator._decode_and_generate", "onmt.translate.random_sampling.RandomSampling.advance", "onmt.translate.random_sampling.RandomSampling.advance", "onmt.translate.random_sampling.RandomSampling.advance", "onmt.translate.random_sampling.RandomSampling.advance", "onmt.translate.random_sampling.RandomSampling.is_finished.any", "onmt.translate.random_sampling.RandomSampling.is_finished.any", "onmt.translate.random_sampling.RandomSampling.is_finished.any", "onmt.translate.random_sampling.RandomSampling.is_finished.any", "onmt.translate.random_sampling.RandomSampling.update_finished", "onmt.translate.random_sampling.RandomSampling.update_finished", "onmt.translate.random_sampling.RandomSampling.update_finished", "onmt.translate.random_sampling.RandomSampling.update_finished", "memory_lengths.index_select.index_select.index_select", "translator.Translator.model.decoder.map_state", "isinstance", "isinstance", "isinstance", "tuple.index_select", "src_map.index_select.index_select.index_select", "translator.Translator.model.lm_decoder.map_state", "translator.Translator.model.decoder.embeddings.gpt_model.map_state", "tuple", "tuple", "state.index_select", "state.index_select", "state.index_select", "list", "x.index_select", "memory_bank[].keys", "v.index_select", "x.items"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator._run_encoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.init_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.init_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator._gold_score", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._decode_and_generate", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.map_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.map_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.map_state"], ["", "def", "_translate_random_sampling", "(", "\n", "self", ",", "\n", "batch", ",", "\n", "src_vocabs", ",", "\n", "max_length", ",", "\n", "min_length", "=", "0", ",", "\n", "sampling_temp", "=", "1.0", ",", "\n", "keep_topk", "=", "-", "1", ",", "\n", "return_attention", "=", "False", ",", "\n", "tags", "=", "None", ")", ":", "\n", "        ", "\"\"\"Alternative to beam search. Do random sampling at each step.\"\"\"", "\n", "\n", "if", "tags", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "assert", "self", ".", "beam_size", "==", "1", "\n", "\n", "assert", "self", ".", "block_ngram_repeat", "==", "0", "\n", "\n", "batch_size", "=", "batch", ".", "batch_size", "\n", "\n", "# Encoder forward.", "\n", "src", ",", "enc_states", ",", "memory_bank", ",", "src_lengths", "=", "self", ".", "_run_encoder", "(", "batch", ")", "\n", "self", ".", "model", ".", "decoder", ".", "init_state", "(", "src", ",", "memory_bank", ",", "enc_states", ")", "\n", "if", "self", ".", "simple_fusion", ":", "\n", "            ", "self", ".", "model", ".", "lm_decoder", ".", "init_state", "(", "src", ",", "None", ",", "None", ")", "\n", "\n", "", "use_src_map", "=", "self", ".", "copy_attn", "\n", "\n", "results", "=", "{", "\n", "\"predictions\"", ":", "None", ",", "\n", "\"scores\"", ":", "None", ",", "\n", "\"attention\"", ":", "None", ",", "\n", "\"batch\"", ":", "batch", ",", "\n", "\"gold_score\"", ":", "self", ".", "_gold_score", "(", "\n", "batch", ",", "memory_bank", ",", "src_lengths", ",", "src_vocabs", ",", "use_src_map", ",", "\n", "enc_states", ",", "batch_size", ",", "src", ")", "}", "\n", "\n", "memory_lengths", "=", "src_lengths", "\n", "src_map", "=", "batch", ".", "src_map", "if", "use_src_map", "else", "None", "\n", "\n", "if", "isinstance", "(", "memory_bank", ",", "tuple", ")", "or", "isinstance", "(", "memory_bank", ",", "list", ")", ":", "\n", "            ", "if", "isinstance", "(", "memory_bank", "[", "0", "]", ",", "dict", ")", ":", "\n", "                ", "mb_device", "=", "memory_bank", "[", "0", "]", "[", "list", "(", "memory_bank", "[", "0", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "device", "\n", "", "else", ":", "\n", "                ", "mb_device", "=", "memory_bank", "[", "0", "]", ".", "device", "\n", "", "", "else", ":", "\n", "            ", "mb_device", "=", "memory_bank", ".", "device", "\n", "\n", "", "random_sampler", "=", "RandomSampling", "(", "\n", "self", ".", "_tgt_pad_idx", ",", "self", ".", "_tgt_bos_idx", ",", "self", ".", "_tgt_eos_idx", ",", "\n", "batch_size", ",", "mb_device", ",", "min_length", ",", "self", ".", "block_ngram_repeat", ",", "\n", "self", ".", "_exclusion_idxs", ",", "return_attention", ",", "self", ".", "max_length", ",", "\n", "sampling_temp", ",", "keep_topk", ",", "memory_lengths", ")", "\n", "\n", "\n", "\n", "for", "step", "in", "range", "(", "max_length", ")", ":", "\n", "# Shape: (1, B, 1)", "\n", "            ", "decoder_input", "=", "random_sampler", ".", "alive_seq", "[", ":", ",", "-", "1", "]", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", "\n", "\n", "log_probs", ",", "attn", "=", "self", ".", "_decode_and_generate", "(", "\n", "decoder_input", ",", "\n", "memory_bank", ",", "\n", "batch", ",", "\n", "src_vocabs", ",", "\n", "memory_lengths", "=", "memory_lengths", ",", "\n", "src_map", "=", "src_map", ",", "\n", "step", "=", "step", ",", "\n", "batch_offset", "=", "random_sampler", ".", "select_indices", "\n", ")", "\n", "\n", "random_sampler", ".", "advance", "(", "log_probs", ",", "attn", ")", "\n", "any_batch_is_finished", "=", "random_sampler", ".", "is_finished", ".", "any", "(", ")", "\n", "if", "any_batch_is_finished", ":", "\n", "                ", "random_sampler", ".", "update_finished", "(", ")", "\n", "if", "random_sampler", ".", "done", ":", "\n", "                    ", "break", "\n", "\n", "", "", "if", "any_batch_is_finished", ":", "\n", "                ", "select_indices", "=", "random_sampler", ".", "select_indices", "\n", "\n", "# Reorder states.", "\n", "if", "isinstance", "(", "memory_bank", ",", "tuple", ")", "or", "isinstance", "(", "memory_bank", ",", "list", ")", ":", "\n", "                    ", "if", "isinstance", "(", "memory_bank", "[", "0", "]", ",", "dict", ")", ":", "\n", "                        ", "memory_bank", "=", "tuple", "(", "{", "k", ":", "v", ".", "index_select", "(", "0", ",", "select_indices", ")", "for", "k", ",", "v", "in", "x", ".", "items", "(", ")", "}", "\n", "for", "x", "in", "memory_bank", ")", "\n", "", "else", ":", "\n", "                        ", "memory_bank", "=", "tuple", "(", "x", ".", "index_select", "(", "1", ",", "select_indices", ")", "\n", "for", "x", "in", "memory_bank", ")", "\n", "", "", "else", ":", "\n", "                    ", "memory_bank", "=", "memory_bank", ".", "index_select", "(", "1", ",", "select_indices", ")", "\n", "\n", "", "memory_lengths", "=", "memory_lengths", ".", "index_select", "(", "0", ",", "select_indices", ")", "\n", "\n", "if", "src_map", "is", "not", "None", ":", "\n", "                    ", "src_map", "=", "src_map", ".", "index_select", "(", "1", ",", "select_indices", ")", "\n", "\n", "", "self", ".", "model", ".", "decoder", ".", "map_state", "(", "\n", "lambda", "state", ",", "dim", ":", "state", ".", "index_select", "(", "dim", ",", "select_indices", ")", ")", "\n", "\n", "if", "self", ".", "simple_fusion", ":", "\n", "                    ", "self", ".", "model", ".", "lm_decoder", ".", "map_state", "(", "\n", "lambda", "state", ",", "dim", ":", "state", ".", "index_select", "(", "dim", ",", "select_indices", ")", ")", "\n", "\n", "", "if", "self", ".", "gpt_tgt", ":", "\n", "                    ", "self", ".", "model", ".", "decoder", ".", "embeddings", ".", "gpt_model", ".", "map_state", "(", "\n", "lambda", "state", ",", "dim", ":", "state", ".", "index_select", "(", "dim", ",", "select_indices", ")", ")", "\n", "\n", "\n", "\n", "", "", "", "results", "[", "\"scores\"", "]", "=", "random_sampler", ".", "scores", "\n", "results", "[", "\"predictions\"", "]", "=", "random_sampler", ".", "predictions", "\n", "results", "[", "\"attention\"", "]", "=", "random_sampler", ".", "attention", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator.translate_batch": [[561, 583], ["torch.no_grad", "translator.Translator._translate_random_sampling", "translator.Translator._translate_batch"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._translate_random_sampling", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._translate_batch"], ["", "def", "translate_batch", "(", "self", ",", "batch", ",", "src_vocabs", ",", "attn_debug", ",", "tags", "=", "None", ")", ":", "\n", "        ", "\"\"\"Translate a batch of sentences.\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "self", ".", "beam_size", "==", "1", ":", "\n", "                ", "return", "self", ".", "_translate_random_sampling", "(", "\n", "batch", ",", "\n", "src_vocabs", ",", "\n", "self", ".", "max_length", ",", "\n", "min_length", "=", "self", ".", "min_length", ",", "\n", "sampling_temp", "=", "self", ".", "random_sampling_temp", ",", "\n", "keep_topk", "=", "self", ".", "sample_from_topk", ",", "\n", "return_attention", "=", "attn_debug", "or", "self", ".", "replace_unk", ",", "\n", "tags", "=", "tags", ")", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "_translate_batch", "(", "\n", "batch", ",", "\n", "src_vocabs", ",", "\n", "self", ".", "max_length", ",", "\n", "min_length", "=", "self", ".", "min_length", ",", "\n", "n_best", "=", "self", ".", "n_best", ",", "\n", "return_attention", "=", "attn_debug", "or", "self", ".", "replace_unk", ",", "\n", "tags", "=", "tags", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._run_encoder": [[584, 605], ["hasattr", "translator.Translator.model.encoder", "torch.zeros", "torch.ones", "isinstance", "torch.Tensor().type_as().long().fill_", "isinstance", "torch.zeros.size", "torch.Tensor().type_as().long", "torch.Tensor().type_as", "torch.Tensor"], "methods", ["None"], ["", "", "", "def", "_run_encoder", "(", "self", ",", "batch", ")", ":", "\n", "        ", "if", "hasattr", "(", "batch", ",", "'src'", ")", ":", "\n", "            ", "src", ",", "src_lengths", "=", "batch", ".", "src", "if", "isinstance", "(", "batch", ".", "src", ",", "tuple", ")", "else", "(", "batch", ".", "src", ",", "None", ")", "\n", "\n", "enc_states", ",", "memory_bank", ",", "src_lengths", "=", "self", ".", "model", ".", "encoder", "(", "\n", "src", ",", "src_lengths", ")", "\n", "if", "src_lengths", "is", "None", ":", "\n", "                ", "assert", "not", "isinstance", "(", "memory_bank", ",", "tuple", ")", ",", "'Ensemble decoding only supported for text data'", "\n", "src_lengths", "=", "torch", ".", "Tensor", "(", "batch", ".", "batch_size", ")", ".", "type_as", "(", "memory_bank", ")", ".", "long", "(", ")", ".", "fill_", "(", "memory_bank", ".", "size", "(", "0", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "src", "=", "None", "\n", "enc_states", "=", "None", "\n", "memory_bank", "=", "torch", ".", "zeros", "(", "(", "1", ",", "batch", ".", "tgt", "[", "0", "]", ".", "shape", "[", "1", "]", ",", "1", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "batch", ".", "tgt", "[", "0", "]", ".", "device", ")", "\n", "src_lengths", "=", "torch", ".", "ones", "(", "(", "batch", ".", "tgt", "[", "0", "]", ".", "shape", "[", "1", "]", ",", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "batch", ".", "tgt", "[", "0", "]", ".", "device", ")", "\n", "#src_lengths = None", "\n", "", "return", "src", ",", "enc_states", ",", "memory_bank", ",", "src_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._decode_and_generate": [[606, 678], ["decoder", "decoder_in.masked_fill.masked_fill.masked_fill", "translator.Translator.model.generator", "onmt.modules.copy_generator.collapse_copy_scores", "onmt.modules.copy_generator.collapse_copy_scores", "onmt.modules.copy_generator.collapse_copy_scores", "onmt.modules.copy_generator.collapse_copy_scores", "scores.view.view.view", "scores.view.view.squeeze().log", "decoder_in.masked_fill.masked_fill.gt", "translator.Translator.model.lm_decoder", "translator.Translator.model.generator", "translator.Translator.model.generator", "dec_out.view", "attn.view", "scores.view.view.view", "scores.view.view.view", "decoder_in.masked_fill.masked_fill.size", "scores.view.view.size", "memory_bank.new_zeros", "dec_out.squeeze", "lm_dec_out.squeeze", "dec_out.squeeze", "dec_out.size", "attn.size", "scores.view.view.size", "scores.view.view.size", "scores.view.view.squeeze"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.collapse_copy_scores", "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.collapse_copy_scores", "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.collapse_copy_scores", "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.collapse_copy_scores", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "_decode_and_generate", "(", "\n", "self", ",", "\n", "decoder_in", ",", "\n", "memory_bank", ",", "\n", "batch", ",", "\n", "src_vocabs", ",", "\n", "memory_lengths", ",", "\n", "src_map", "=", "None", ",", "\n", "step", "=", "None", ",", "\n", "batch_offset", "=", "None", ",", "\n", "tags", "=", "None", ",", "\n", "pplm_return", "=", "False", ",", "\n", "past", "=", "None", "\n", ")", ":", "\n", "        ", "if", "self", ".", "copy_attn", ":", "\n", "# Turn any copied words into UNKs.", "\n", "            ", "decoder_in", "=", "decoder_in", ".", "masked_fill", "(", "\n", "decoder_in", ".", "gt", "(", "self", ".", "_tgt_vocab_len", "-", "1", ")", ",", "self", ".", "_tgt_unk_idx", "\n", ")", "\n", "\n", "# Decoder forward, takes [tgt_len, batch, nfeats] as input", "\n", "# and [src_len, batch, hidden] as memory_bank", "\n", "# in case of inference tgt_len = 1, batch = beam times batch_size", "\n", "# in case of Gold Scoring tgt_len = actual length, batch = 1 batch", "\n", "", "decoder", "=", "self", ".", "model", ".", "decoder", "\n", "# The simple mechanism is to do the gradient ascent", "\n", "\n", "dec_out", ",", "dec_attn", "=", "decoder", "(", "\n", "decoder_in", ",", "memory_bank", ",", "memory_lengths", "=", "memory_lengths", ",", "step", "=", "step", ",", "\n", ")", "\n", "\n", "# Generator forward.", "\n", "if", "not", "self", ".", "copy_attn", ":", "\n", "            ", "if", "\"std\"", "in", "dec_attn", ":", "\n", "                ", "attn", "=", "dec_attn", "[", "\"std\"", "]", "\n", "", "else", ":", "\n", "                ", "attn", "=", "None", "\n", "\n", "", "if", "self", ".", "simple_fusion", ":", "\n", "                ", "lm_dec_out", ",", "_", "=", "self", ".", "model", ".", "lm_decoder", "(", "decoder_in", ",", "memory_bank", ".", "new_zeros", "(", "1", ",", "1", ",", "1", ")", ",", "step", "=", "step", ")", "\n", "log_probs", "=", "self", ".", "model", ".", "generator", "(", "dec_out", ".", "squeeze", "(", "0", ")", ",", "lm_dec_out", ".", "squeeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "log_probs", "=", "self", ".", "model", ".", "generator", "(", "dec_out", ".", "squeeze", "(", "0", ")", ")", "\n", "#print(log_probs)", "\n", "# returns [(batch_size x beam_size) , vocab ] when 1 step", "\n", "# or [ tgt_len, batch_size, vocab ] when full sentence", "\n", "", "", "else", ":", "\n", "            ", "attn", "=", "dec_attn", "[", "\"copy\"", "]", "\n", "\n", "scores", ",", "_", "=", "self", ".", "model", ".", "generator", "(", "dec_out", ".", "view", "(", "-", "1", ",", "dec_out", ".", "size", "(", "2", ")", ")", ",", "\n", "attn", ".", "view", "(", "-", "1", ",", "attn", ".", "size", "(", "2", ")", ")", ",", "\n", "src_map", ",", "tags", "=", "tags", ")", "\n", "# here we have scores [tgt_lenxbatch, vocab] or [beamxbatch, vocab]", "\n", "if", "batch_offset", "is", "None", ":", "\n", "                ", "scores", "=", "scores", ".", "view", "(", "batch", ".", "batch_size", ",", "-", "1", ",", "scores", ".", "size", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "scores", "=", "scores", ".", "view", "(", "-", "1", ",", "self", ".", "beam_size", ",", "scores", ".", "size", "(", "-", "1", ")", ")", "\n", "", "scores", "=", "collapse_copy_scores", "(", "\n", "scores", ",", "\n", "batch", ",", "\n", "self", ".", "_tgt_vocab", ",", "\n", "src_vocabs", ",", "\n", "batch_dim", "=", "0", ",", "\n", "batch_offset", "=", "batch_offset", "\n", ")", "\n", "scores", "=", "scores", ".", "view", "(", "decoder_in", ".", "size", "(", "0", ")", ",", "-", "1", ",", "scores", ".", "size", "(", "-", "1", ")", ")", "\n", "log_probs", "=", "scores", ".", "squeeze", "(", "0", ")", ".", "log", "(", ")", "\n", "# returns [(batch_size x beam_size) , vocab ] when 1 step", "\n", "# or [ tgt_len, batch_size, vocab ] when full sentence", "\n", "\n", "\n", "", "return", "log_probs", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._translate_batch": [[679, 806], ["translator.Translator._run_encoder", "translator.Translator.model.decoder.init_state", "translator.Translator.model.decoder.map_state", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.translate.beam_search.BeamSearch", "onmt.translate.beam_search.BeamSearch", "onmt.translate.beam_search.BeamSearch", "onmt.translate.beam_search.BeamSearch", "range", "translator.Translator.model.lm_decoder.init_state", "translator.Translator._gold_score", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "isinstance", "isinstance", "isinstance", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.translate.beam_search.BeamSearch.current_predictions.view", "onmt.translate.beam_search.BeamSearch.current_predictions.view", "onmt.translate.beam_search.BeamSearch.current_predictions.view", "onmt.translate.beam_search.BeamSearch.current_predictions.view", "translator.Translator._decode_and_generate", "onmt.translate.beam_search.BeamSearch.advance", "onmt.translate.beam_search.BeamSearch.advance", "onmt.translate.beam_search.BeamSearch.advance", "onmt.translate.beam_search.BeamSearch.advance", "onmt.translate.beam_search.BeamSearch.is_finished.any", "onmt.translate.beam_search.BeamSearch.is_finished.any", "onmt.translate.beam_search.BeamSearch.is_finished.any", "onmt.translate.beam_search.BeamSearch.is_finished.any", "translator.Translator.model.decoder.map_state", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "tuple", "tuple", "onmt.translate.beam_search.BeamSearch.update_finished", "onmt.translate.beam_search.BeamSearch.update_finished", "onmt.translate.beam_search.BeamSearch.update_finished", "onmt.translate.beam_search.BeamSearch.update_finished", "isinstance", "memory_lengths.index_select.index_select.index_select", "translator.Translator.model.decoder.embeddings.gpt_model.map_state", "isinstance", "tuple.index_select", "tags.index_select.index_select.index_select", "src_map.index_select.index_select.index_select", "state.index_select", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "tuple", "tuple", "state.index_select", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "x.items", "list", "x.index_select", "memory_bank[].keys", "v.index_select", "x.items"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator._run_encoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.init_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.map_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.init_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator._gold_score", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._decode_and_generate", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.map_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.map_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile"], ["", "def", "_translate_batch", "(", "\n", "self", ",", "\n", "batch", ",", "\n", "src_vocabs", ",", "\n", "max_length", ",", "\n", "min_length", "=", "0", ",", "\n", "n_best", "=", "1", ",", "\n", "return_attention", "=", "False", ",", "\n", "tags", "=", "None", ")", ":", "\n", "# TODO: support these blacklisted features.", "\n", "        ", "assert", "not", "self", ".", "dump_beam", "\n", "\n", "# (0) Prep the components of the search.", "\n", "use_src_map", "=", "self", ".", "copy_attn", "\n", "beam_size", "=", "self", ".", "beam_size", "\n", "batch_size", "=", "batch", ".", "batch_size", "\n", "\n", "# (1) Run the encoder on the src.", "\n", "src", ",", "enc_states", ",", "memory_bank", ",", "src_lengths", "=", "self", ".", "_run_encoder", "(", "batch", ")", "\n", "self", ".", "model", ".", "decoder", ".", "init_state", "(", "src", ",", "memory_bank", ",", "enc_states", ")", "\n", "if", "self", ".", "simple_fusion", ":", "\n", "            ", "self", ".", "model", ".", "lm_decoder", ".", "init_state", "(", "src", ",", "None", ",", "None", ")", "\n", "\n", "", "results", "=", "{", "\n", "\"predictions\"", ":", "None", ",", "\n", "\"scores\"", ":", "None", ",", "\n", "\"attention\"", ":", "None", ",", "\n", "\"batch\"", ":", "batch", ",", "\n", "\"gold_score\"", ":", "self", ".", "_gold_score", "(", "\n", "batch", ",", "memory_bank", ",", "src_lengths", ",", "src_vocabs", ",", "use_src_map", ",", "\n", "enc_states", ",", "batch_size", ",", "src", ")", "}", "\n", "\n", "# (2) Repeat src objects `beam_size` times.", "\n", "# We use batch_size x beam_size", "\n", "src_map", "=", "(", "tile", "(", "batch", ".", "src_map", ",", "beam_size", ",", "dim", "=", "1", ")", "\n", "if", "use_src_map", "else", "None", ")", "\n", "self", ".", "model", ".", "decoder", ".", "map_state", "(", "\n", "lambda", "state", ",", "dim", ":", "tile", "(", "state", ",", "beam_size", ",", "dim", "=", "dim", ")", ")", "\n", "\n", "if", "isinstance", "(", "memory_bank", ",", "tuple", ")", "or", "isinstance", "(", "memory_bank", ",", "list", ")", ":", "\n", "            ", "if", "isinstance", "(", "memory_bank", "[", "0", "]", ",", "dict", ")", ":", "\n", "                ", "memory_bank", "=", "tuple", "(", "{", "k", ":", "tile", "(", "v", ",", "beam_size", ",", "dim", "=", "0", ")", "for", "k", ",", "v", "in", "x", ".", "items", "(", ")", "}", "for", "x", "in", "memory_bank", ")", "\n", "mb_device", "=", "memory_bank", "[", "0", "]", "[", "list", "(", "memory_bank", "[", "0", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "device", "\n", "", "else", ":", "\n", "                ", "memory_bank", "=", "tuple", "(", "tile", "(", "x", ",", "beam_size", ",", "dim", "=", "1", ")", "for", "x", "in", "memory_bank", ")", "\n", "mb_device", "=", "memory_bank", "[", "0", "]", ".", "device", "\n", "", "", "else", ":", "\n", "            ", "memory_bank", "=", "tile", "(", "memory_bank", ",", "beam_size", ",", "dim", "=", "1", ")", "\n", "mb_device", "=", "memory_bank", ".", "device", "\n", "\n", "", "if", "tags", "is", "not", "None", ":", "\n", "            ", "tags", "=", "tile", "(", "tags", ",", "beam_size", ",", "dim", "=", "1", ")", "\n", "\n", "", "memory_lengths", "=", "tile", "(", "src_lengths", ",", "beam_size", ")", "\n", "\n", "# (0) pt 2, prep the beam object", "\n", "beam", "=", "BeamSearch", "(", "\n", "beam_size", ",", "\n", "n_best", "=", "n_best", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "global_scorer", "=", "self", ".", "global_scorer", ",", "\n", "pad", "=", "self", ".", "_tgt_pad_idx", ",", "\n", "eos", "=", "self", ".", "_tgt_eos_idx", ",", "\n", "bos", "=", "self", ".", "_tgt_bos_idx", ",", "\n", "min_length", "=", "min_length", ",", "\n", "max_length", "=", "max_length", ",", "\n", "mb_device", "=", "mb_device", ",", "\n", "return_attention", "=", "return_attention", ",", "\n", "stepwise_penalty", "=", "self", ".", "stepwise_penalty", ",", "\n", "block_ngram_repeat", "=", "self", ".", "block_ngram_repeat", ",", "\n", "exclusion_tokens", "=", "self", ".", "_exclusion_idxs", ",", "\n", "memory_lengths", "=", "memory_lengths", ")", "\n", "\n", "for", "step", "in", "range", "(", "max_length", ")", ":", "\n", "            ", "decoder_input", "=", "beam", ".", "current_predictions", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", "\n", "\n", "log_probs", ",", "attn", "=", "self", ".", "_decode_and_generate", "(", "\n", "decoder_input", ",", "\n", "memory_bank", ",", "\n", "batch", ",", "\n", "src_vocabs", ",", "\n", "memory_lengths", "=", "memory_lengths", ",", "\n", "src_map", "=", "src_map", ",", "\n", "step", "=", "step", ",", "\n", "batch_offset", "=", "beam", ".", "_batch_offset", ",", "\n", "tags", "=", "tags", ")", "\n", "\n", "beam", ".", "advance", "(", "log_probs", ",", "attn", ")", "\n", "any_beam_is_finished", "=", "beam", ".", "is_finished", ".", "any", "(", ")", "\n", "if", "any_beam_is_finished", ":", "\n", "                ", "beam", ".", "update_finished", "(", ")", "\n", "if", "beam", ".", "done", ":", "\n", "                    ", "break", "\n", "\n", "", "", "select_indices", "=", "beam", ".", "current_origin", "\n", "\n", "if", "any_beam_is_finished", ":", "\n", "# Reorder states.", "\n", "                ", "if", "isinstance", "(", "memory_bank", ",", "tuple", ")", ":", "\n", "                    ", "if", "isinstance", "(", "memory_bank", "[", "0", "]", ",", "dict", ")", ":", "\n", "                        ", "memory_bank", "=", "tuple", "(", "{", "k", ":", "v", ".", "index_select", "(", "0", ",", "select_indices", ")", "for", "k", ",", "v", "in", "x", ".", "items", "(", ")", "}", "\n", "for", "x", "in", "memory_bank", ")", "\n", "", "else", ":", "\n", "                        ", "memory_bank", "=", "tuple", "(", "x", ".", "index_select", "(", "1", ",", "select_indices", ")", "\n", "for", "x", "in", "memory_bank", ")", "\n", "", "", "else", ":", "\n", "                    ", "memory_bank", "=", "memory_bank", ".", "index_select", "(", "1", ",", "select_indices", ")", "\n", "\n", "", "if", "tags", "is", "not", "None", ":", "\n", "                    ", "tags", "=", "tags", ".", "index_select", "(", "1", ",", "select_indices", ")", "\n", "\n", "", "memory_lengths", "=", "memory_lengths", ".", "index_select", "(", "0", ",", "select_indices", ")", "\n", "\n", "if", "src_map", "is", "not", "None", ":", "\n", "                    ", "src_map", "=", "src_map", ".", "index_select", "(", "1", ",", "select_indices", ")", "\n", "\n", "", "", "self", ".", "model", ".", "decoder", ".", "map_state", "(", "\n", "lambda", "state", ",", "dim", ":", "state", ".", "index_select", "(", "dim", ",", "select_indices", ")", ")", "\n", "\n", "if", "self", ".", "gpt_tgt", ":", "\n", "                ", "self", ".", "model", ".", "decoder", ".", "embeddings", ".", "gpt_model", ".", "map_state", "(", "\n", "lambda", "state", ",", "dim", ":", "state", ".", "index_select", "(", "dim", ",", "select_indices", ")", ")", "\n", "\n", "", "", "results", "[", "\"scores\"", "]", "=", "beam", ".", "scores", "\n", "results", "[", "\"predictions\"", "]", "=", "beam", ".", "predictions", "\n", "results", "[", "\"attention\"", "]", "=", "beam", ".", "attention", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._translate_batch_deprecated": [[808, 903], ["translator.Translator._run_encoder", "translator.Translator.model.decoder.init_state", "translator.Translator.model.decoder.map_state", "isinstance", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "range", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "translator.Translator.model.lm_decoder.init_state", "translator.Translator._gold_score", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "tuple", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "all", "torch.stack", "inp.view.view.view", "translator.Translator._decode_and_generate", "out.view.view.view", "beam_attn.view.view.view", "enumerate", "torch.cat", "translator.Translator.model.decoder.map_state", "b.sort_finished", "results[].append", "results[].append", "results[].append", "range", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "select_indices_array.append", "b.get_hyp", "hyps.append", "attn.append", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "b.advance", "state.index_select"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator._run_encoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.init_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.map_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.init_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator._gold_score", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._decode_and_generate", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.map_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam.Beam.sort_finished", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam.Beam.get_hyp", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.tile", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance"], ["", "def", "_translate_batch_deprecated", "(", "self", ",", "batch", ",", "src_vocabs", ")", ":", "\n", "# (0) Prep each of the components of the search.", "\n", "# And helper method for reducing verbosity.", "\n", "        ", "use_src_map", "=", "self", ".", "copy_attn", "\n", "beam_size", "=", "self", ".", "beam_size", "\n", "batch_size", "=", "batch", ".", "batch_size", "\n", "\n", "beam", "=", "[", "onmt", ".", "translate", ".", "Beam", "(", "\n", "beam_size", ",", "\n", "n_best", "=", "self", ".", "n_best", ",", "\n", "cuda", "=", "self", ".", "cuda", ",", "\n", "global_scorer", "=", "self", ".", "global_scorer", ",", "\n", "pad", "=", "self", ".", "_tgt_pad_idx", ",", "\n", "eos", "=", "self", ".", "_tgt_eos_idx", ",", "\n", "bos", "=", "self", ".", "_tgt_bos_idx", ",", "\n", "min_length", "=", "self", ".", "min_length", ",", "\n", "stepwise_penalty", "=", "self", ".", "stepwise_penalty", ",", "\n", "block_ngram_repeat", "=", "self", ".", "block_ngram_repeat", ",", "\n", "exclusion_tokens", "=", "self", ".", "_exclusion_idxs", ")", "\n", "for", "__", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "# (1) Run the encoder on the src.", "\n", "src", ",", "enc_states", ",", "memory_bank", ",", "src_lengths", "=", "self", ".", "_run_encoder", "(", "batch", ")", "\n", "self", ".", "model", ".", "decoder", ".", "init_state", "(", "src", ",", "memory_bank", ",", "enc_states", ")", "\n", "if", "self", ".", "simple_fusion", ":", "\n", "            ", "self", ".", "model", ".", "lm_decoder", ".", "init_state", "(", "src", ",", "None", ",", "None", ")", "\n", "\n", "", "results", "=", "{", "\n", "\"predictions\"", ":", "[", "]", ",", "\n", "\"scores\"", ":", "[", "]", ",", "\n", "\"attention\"", ":", "[", "]", ",", "\n", "\"batch\"", ":", "batch", ",", "\n", "\"gold_score\"", ":", "self", ".", "_gold_score", "(", "\n", "batch", ",", "memory_bank", ",", "src_lengths", ",", "src_vocabs", ",", "use_src_map", ",", "\n", "enc_states", ",", "batch_size", ",", "src", ")", "}", "\n", "\n", "# (2) Repeat src objects `beam_size` times.", "\n", "# We use now  batch_size x beam_size (same as fast mode)", "\n", "src_map", "=", "(", "tile", "(", "batch", ".", "src_map", ",", "beam_size", ",", "dim", "=", "1", ")", "\n", "if", "use_src_map", "else", "None", ")", "\n", "self", ".", "model", ".", "decoder", ".", "map_state", "(", "\n", "lambda", "state", ",", "dim", ":", "tile", "(", "state", ",", "beam_size", ",", "dim", "=", "dim", ")", ")", "\n", "\n", "if", "isinstance", "(", "memory_bank", ",", "tuple", ")", ":", "\n", "            ", "memory_bank", "=", "tuple", "(", "tile", "(", "x", ",", "beam_size", ",", "dim", "=", "1", ")", "for", "x", "in", "memory_bank", ")", "\n", "", "else", ":", "\n", "            ", "memory_bank", "=", "tile", "(", "memory_bank", ",", "beam_size", ",", "dim", "=", "1", ")", "\n", "", "memory_lengths", "=", "tile", "(", "src_lengths", ",", "beam_size", ")", "\n", "\n", "# (3) run the decoder to generate sentences, using beam search.", "\n", "for", "i", "in", "range", "(", "self", ".", "max_length", ")", ":", "\n", "            ", "if", "all", "(", "(", "b", ".", "done", "for", "b", "in", "beam", ")", ")", ":", "\n", "                ", "break", "\n", "\n", "# (a) Construct batch x beam_size nxt words.", "\n", "# Get all the pending current beam words and arrange for forward.", "\n", "\n", "", "inp", "=", "torch", ".", "stack", "(", "[", "b", ".", "current_predictions", "for", "b", "in", "beam", "]", ")", "\n", "inp", "=", "inp", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", "\n", "\n", "# (b) Decode and forward", "\n", "out", ",", "beam_attn", "=", "self", ".", "_decode_and_generate", "(", "\n", "inp", ",", "memory_bank", ",", "batch", ",", "src_vocabs", ",", "\n", "memory_lengths", "=", "memory_lengths", ",", "src_map", "=", "src_map", ",", "step", "=", "i", "\n", ")", "\n", "out", "=", "out", ".", "view", "(", "batch_size", ",", "beam_size", ",", "-", "1", ")", "\n", "beam_attn", "=", "beam_attn", ".", "view", "(", "batch_size", ",", "beam_size", ",", "-", "1", ")", "\n", "\n", "# (c) Advance each beam.", "\n", "select_indices_array", "=", "[", "]", "\n", "# Loop over the batch_size number of beam", "\n", "for", "j", ",", "b", "in", "enumerate", "(", "beam", ")", ":", "\n", "                ", "if", "not", "b", ".", "done", ":", "\n", "                    ", "b", ".", "advance", "(", "out", "[", "j", ",", ":", "]", ",", "\n", "beam_attn", ".", "data", "[", "j", ",", ":", ",", ":", "memory_lengths", "[", "j", "]", "]", ")", "\n", "", "select_indices_array", ".", "append", "(", "\n", "b", ".", "current_origin", "+", "j", "*", "beam_size", ")", "\n", "", "select_indices", "=", "torch", ".", "cat", "(", "select_indices_array", ")", "\n", "\n", "self", ".", "model", ".", "decoder", ".", "map_state", "(", "\n", "lambda", "state", ",", "dim", ":", "state", ".", "index_select", "(", "dim", ",", "select_indices", ")", ")", "\n", "\n", "# (4) Extract sentences from beam.", "\n", "", "for", "b", "in", "beam", ":", "\n", "            ", "scores", ",", "ks", "=", "b", ".", "sort_finished", "(", "minimum", "=", "self", ".", "n_best", ")", "\n", "hyps", ",", "attn", "=", "[", "]", ",", "[", "]", "\n", "for", "times", ",", "k", "in", "ks", "[", ":", "self", ".", "n_best", "]", ":", "\n", "                ", "hyp", ",", "att", "=", "b", ".", "get_hyp", "(", "times", ",", "k", ")", "\n", "hyps", ".", "append", "(", "hyp", ")", "\n", "attn", ".", "append", "(", "att", ")", "\n", "", "results", "[", "\"predictions\"", "]", ".", "append", "(", "hyps", ")", "\n", "results", "[", "\"scores\"", "]", ".", "append", "(", "scores", ")", "\n", "results", "[", "\"attention\"", "]", ".", "append", "(", "attn", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._score_target": [[904, 919], ["translator.Translator._decode_and_generate", "log_probs.gather", "gold_scores.sum().view.sum().view.sum().view", "isinstance", "gold_scores.sum().view.sum().view.sum"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._decode_and_generate"], ["", "def", "_score_target", "(", "self", ",", "batch", ",", "memory_bank", ",", "src_lengths", ",", "\n", "src_vocabs", ",", "src_map", ")", ":", "\n", "        ", "tgt", ",", "tgt_lengths", "=", "batch", ".", "tgt", "if", "isinstance", "(", "batch", ".", "tgt", ",", "tuple", ")", "else", "(", "batch", ".", "tgt", ",", "None", ")", "\n", "tgt_in", "=", "tgt", "[", ":", "-", "1", "]", "\n", "\n", "log_probs", ",", "attn", "=", "self", ".", "_decode_and_generate", "(", "\n", "tgt_in", ",", "memory_bank", ",", "batch", ",", "src_vocabs", ",", "\n", "memory_lengths", "=", "src_lengths", ",", "src_map", "=", "src_map", ")", "\n", "\n", "log_probs", "[", ":", ",", ":", ",", "self", ".", "_tgt_pad_idx", "]", "=", "0", "\n", "gold", "=", "tgt_in", "\n", "gold_scores", "=", "log_probs", ".", "gather", "(", "2", ",", "gold", ")", "\n", "gold_scores", "=", "gold_scores", ".", "sum", "(", "dim", "=", "0", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "return", "gold_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._report_score": [[920, 931], ["math.exp"], "methods", ["None"], ["", "def", "_report_score", "(", "self", ",", "name", ",", "score_total", ",", "words_total", ")", ":", "\n", "        ", "if", "words_total", "==", "0", ":", "\n", "            ", "msg", "=", "\"%s No words predicted\"", "%", "(", "name", ",", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "msg", "=", "(", "\"%s AVG SCORE: %.4f, %s PPL: %.4f\"", "%", "(", "\n", "name", ",", "score_total", "/", "words_total", ",", "\n", "name", ",", "math", ".", "exp", "(", "-", "score_total", "/", "words_total", ")", ")", ")", "\n", "", "except", ":", "\n", "                ", "msg", "=", "\"%s overflow problem. score_total: %.4f, words_total: %.4f\"", "%", "(", "name", ",", "score_total", ",", "words_total", ")", "\n", "", "", "return", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._report_bleu": [[932, 946], ["os.path.abspath", "translator.Translator.out_file.seek", "print", "subprocess.check_output().decode", "subprocess.check_output().decode.strip", "subprocess.check_output"], "methods", ["None"], ["", "def", "_report_bleu", "(", "self", ",", "tgt_path", ")", ":", "\n", "        ", "import", "subprocess", "\n", "base_dir", "=", "os", ".", "path", ".", "abspath", "(", "__file__", "+", "\"/../../..\"", ")", "\n", "# Rollback pointer to the beginning.", "\n", "self", ".", "out_file", ".", "seek", "(", "0", ")", "\n", "print", "(", ")", "\n", "\n", "res", "=", "subprocess", ".", "check_output", "(", "\n", "\"perl %s/tools/multi-bleu.perl %s\"", "%", "(", "base_dir", ",", "tgt_path", ")", ",", "\n", "stdin", "=", "self", ".", "out_file", ",", "shell", "=", "True", "\n", ")", ".", "decode", "(", "\"utf-8\"", ")", "\n", "\n", "msg", "=", "\">> \"", "+", "res", ".", "strip", "(", ")", "\n", "return", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._report_rouge": [[947, 955], ["subprocess.check_output().decode().strip", "os.path.split", "os.path.realpath", "subprocess.check_output().decode", "subprocess.check_output"], "methods", ["None"], ["", "def", "_report_rouge", "(", "self", ",", "tgt_path", ")", ":", "\n", "        ", "import", "subprocess", "\n", "path", "=", "os", ".", "path", ".", "split", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", "[", "0", "]", "\n", "msg", "=", "subprocess", ".", "check_output", "(", "\n", "\"python %s/tools/test_rouge.py -r %s -c STDIN\"", "%", "(", "path", ",", "tgt_path", ")", ",", "\n", "shell", "=", "True", ",", "stdin", "=", "self", ".", "out_file", "\n", ")", ".", "decode", "(", "\"utf-8\"", ")", ".", "strip", "(", ")", "\n", "return", "msg", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.build_translator": [[23, 44], ["load_test_model", "onmt.translate.GNMTGlobalScorer.from_opt", "onmt.translate.GNMTGlobalScorer.from_opt", "onmt.translate.GNMTGlobalScorer.from_opt", "onmt.translate.GNMTGlobalScorer.from_opt", "translator.Translator.from_opt", "codecs.open", "len"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.load_test_model", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt"], ["def", "build_translator", "(", "opt", ",", "report_score", "=", "True", ",", "logger", "=", "None", ",", "out_file", "=", "None", ")", ":", "\n", "    ", "if", "out_file", "is", "None", ":", "\n", "        ", "out_file", "=", "codecs", ".", "open", "(", "opt", ".", "output", ",", "'w+'", ",", "'utf-8'", ")", "\n", "\n", "", "load_test_model", "=", "onmt", ".", "decoders", ".", "ensemble", ".", "load_test_model", "if", "len", "(", "opt", ".", "models", ")", ">", "1", "else", "onmt", ".", "model_builder", ".", "load_test_model", "\n", "fields", ",", "model", ",", "model_opt", "=", "load_test_model", "(", "opt", ")", "\n", "\n", "scorer", "=", "onmt", ".", "translate", ".", "GNMTGlobalScorer", ".", "from_opt", "(", "opt", ")", "\n", "\n", "translator", "=", "Translator", ".", "from_opt", "(", "\n", "model", ",", "\n", "fields", ",", "\n", "opt", ",", "\n", "model_opt", ",", "\n", "global_scorer", "=", "scorer", ",", "\n", "out_file", "=", "out_file", ",", "\n", "report_score", "=", "report_score", ",", "\n", "logger", "=", "logger", "\n", ")", "\n", "return", "translator", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.Timer.__init__": [[42, 48], ["translation_server.Timer.start"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.start"], ["    ", "def", "__init__", "(", "self", ",", "start", "=", "False", ")", ":", "\n", "        ", "self", ".", "stime", "=", "-", "1", "\n", "self", ".", "prev", "=", "-", "1", "\n", "self", ".", "times", "=", "{", "}", "\n", "if", "start", ":", "\n", "            ", "self", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.Timer.start": [[49, 53], ["time.time"], "methods", ["None"], ["", "", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "stime", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "prev", "=", "self", ".", "stime", "\n", "self", ".", "times", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.Timer.tick": [[54, 65], ["time.time"], "methods", ["None"], ["", "def", "tick", "(", "self", ",", "name", "=", "None", ",", "tot", "=", "False", ")", ":", "\n", "        ", "t", "=", "time", ".", "time", "(", ")", "\n", "if", "not", "tot", ":", "\n", "            ", "elapsed", "=", "t", "-", "self", ".", "prev", "\n", "", "else", ":", "\n", "            ", "elapsed", "=", "t", "-", "self", ".", "stime", "\n", "", "self", ".", "prev", "=", "t", "\n", "\n", "if", "name", "is", "not", "None", ":", "\n", "            ", "self", ".", "times", "[", "name", "]", "=", "elapsed", "\n", "", "return", "elapsed", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.__init__": [[72, 75], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "models", "=", "{", "}", "\n", "self", ".", "next_id", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.start": [[76, 102], ["translation_server.TranslationServer.confs.get", "enumerate", "open", "json.load", "conf.get", "translation_server.TranslationServer.preload_model", "conf.get", "conf.get", "conf.get", "conf.get", "conf.get", "ValueError", "kwargs.items"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.preload_model"], ["", "def", "start", "(", "self", ",", "config_file", ")", ":", "\n", "        ", "\"\"\"Read the config file and pre-/load the models.\"\"\"", "\n", "self", ".", "config_file", "=", "config_file", "\n", "with", "open", "(", "self", ".", "config_file", ")", "as", "f", ":", "\n", "            ", "self", ".", "confs", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "self", ".", "models_root", "=", "self", ".", "confs", ".", "get", "(", "'models_root'", ",", "'./available_models'", ")", "\n", "for", "i", ",", "conf", "in", "enumerate", "(", "self", ".", "confs", "[", "\"models\"", "]", ")", ":", "\n", "            ", "if", "\"models\"", "not", "in", "conf", ":", "\n", "                ", "if", "\"model\"", "in", "conf", ":", "\n", "# backwards compatibility for confs", "\n", "                    ", "conf", "[", "\"models\"", "]", "=", "[", "conf", "[", "\"model\"", "]", "]", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\"\"\"Incorrect config file: missing 'models'\n                                        parameter for model #%d\"\"\"", "%", "i", ")", "\n", "", "", "kwargs", "=", "{", "'timeout'", ":", "conf", ".", "get", "(", "'timeout'", ",", "None", ")", ",", "\n", "'load'", ":", "conf", ".", "get", "(", "'load'", ",", "None", ")", ",", "\n", "'tokenizer_opt'", ":", "conf", ".", "get", "(", "'tokenizer'", ",", "None", ")", ",", "\n", "'on_timeout'", ":", "conf", ".", "get", "(", "'on_timeout'", ",", "None", ")", ",", "\n", "'model_root'", ":", "conf", ".", "get", "(", "'model_root'", ",", "self", ".", "models_root", ")", "\n", "}", "\n", "kwargs", "=", "{", "k", ":", "v", "for", "(", "k", ",", "v", ")", "in", "kwargs", ".", "items", "(", ")", "if", "v", "is", "not", "None", "}", "\n", "model_id", "=", "conf", ".", "get", "(", "\"id\"", ",", "None", ")", "\n", "opt", "=", "conf", "[", "\"opt\"", "]", "\n", "opt", "[", "\"models\"", "]", "=", "conf", "[", "\"models\"", "]", "\n", "self", ".", "preload_model", "(", "opt", ",", "model_id", "=", "model_id", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.clone_model": [[103, 116], ["translation_server.TranslationServer.load_model", "translation_server.ServerModelError", "str"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.load_model"], ["", "", "def", "clone_model", "(", "self", ",", "model_id", ",", "opt", ",", "timeout", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"Clone a model `model_id`.\n\n        Different options may be passed. If `opt` is None, it will use the\n        same set of options\n        \"\"\"", "\n", "if", "model_id", "in", "self", ".", "models", ":", "\n", "            ", "if", "opt", "is", "None", ":", "\n", "                ", "opt", "=", "self", ".", "models", "[", "model_id", "]", ".", "user_opt", "\n", "", "opt", "[", "\"models\"", "]", "=", "self", ".", "models", "[", "model_id", "]", ".", "opt", ".", "models", "\n", "return", "self", ".", "load_model", "(", "opt", ",", "timeout", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ServerModelError", "(", "\"No such model '%s'\"", "%", "str", "(", "model_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.load_model": [[117, 124], ["translation_server.TranslationServer.preload_model"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.preload_model"], ["", "", "def", "load_model", "(", "self", ",", "opt", ",", "model_id", "=", "None", ",", "**", "model_kwargs", ")", ":", "\n", "        ", "\"\"\"Load a model given a set of options\n        \"\"\"", "\n", "model_id", "=", "self", ".", "preload_model", "(", "opt", ",", "model_id", "=", "model_id", ",", "**", "model_kwargs", ")", "\n", "load_time", "=", "self", ".", "models", "[", "model_id", "]", ".", "load_time", "\n", "\n", "return", "model_id", ",", "load_time", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.preload_model": [[125, 143], ["print", "translation_server.ServerModel", "translation_server.TranslationServer.models.keys", "ValueError", "translation_server.TranslationServer.models.keys"], "methods", ["None"], ["", "def", "preload_model", "(", "self", ",", "opt", ",", "model_id", "=", "None", ",", "**", "model_kwargs", ")", ":", "\n", "        ", "\"\"\"Preloading the model: updating internal datastructure\n\n        It will effectively load the model if `load` is set\n        \"\"\"", "\n", "if", "model_id", "is", "not", "None", ":", "\n", "            ", "if", "model_id", "in", "self", ".", "models", ".", "keys", "(", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"Model ID %d already exists\"", "%", "model_id", ")", "\n", "", "", "else", ":", "\n", "            ", "model_id", "=", "self", ".", "next_id", "\n", "while", "model_id", "in", "self", ".", "models", ".", "keys", "(", ")", ":", "\n", "                ", "model_id", "+=", "1", "\n", "", "self", ".", "next_id", "=", "model_id", "+", "1", "\n", "", "print", "(", "\"Pre-loading model %d\"", "%", "model_id", ")", "\n", "model", "=", "ServerModel", "(", "opt", ",", "model_id", ",", "**", "model_kwargs", ")", "\n", "self", ".", "models", "[", "model_id", "]", "=", "model", "\n", "\n", "return", "model_id", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.run": [[144, 159], ["inputs[].get", "translation_server.TranslationServer.models[].run", "print", "translation_server.ServerModelError", "str", "str"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.run"], ["", "def", "run", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Translate `inputs`\n\n        We keep the same format as the Lua version i.e.\n        ``[{\"id\": model_id, \"src\": \"sequence to translate\"},{ ...}]``\n\n        We use inputs[0][\"id\"] as the model id\n        \"\"\"", "\n", "\n", "model_id", "=", "inputs", "[", "0", "]", ".", "get", "(", "\"id\"", ",", "0", ")", "\n", "if", "model_id", "in", "self", ".", "models", "and", "self", ".", "models", "[", "model_id", "]", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "models", "[", "model_id", "]", ".", "run", "(", "inputs", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Error No such model '%s'\"", "%", "str", "(", "model_id", ")", ")", "\n", "raise", "ServerModelError", "(", "\"No such model '%s'\"", "%", "str", "(", "model_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.unload_model": [[160, 170], ["translation_server.TranslationServer.models[].unload", "translation_server.ServerModelError", "str"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.unload"], ["", "", "def", "unload_model", "(", "self", ",", "model_id", ")", ":", "\n", "        ", "\"\"\"Manually unload a model.\n\n        It will free the memory and cancel the timer\n        \"\"\"", "\n", "\n", "if", "model_id", "in", "self", ".", "models", "and", "self", ".", "models", "[", "model_id", "]", "is", "not", "None", ":", "\n", "            ", "self", ".", "models", "[", "model_id", "]", ".", "unload", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ServerModelError", "(", "\"No such model '%s'\"", "%", "str", "(", "model_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.list_models": [[171, 178], ["translation_server.TranslationServer.models.items", "model.to_dict"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.to_dict"], ["", "", "def", "list_models", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the list of available models\n        \"\"\"", "\n", "models", "=", "[", "]", "\n", "for", "_", ",", "model", "in", "self", ".", "models", ".", "items", "(", ")", ":", "\n", "            ", "models", "+=", "[", "model", ".", "to_dict", "(", ")", "]", "\n", "", "return", "models", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.__init__": [[196, 227], ["translation_server.ServerModel.parse_opt", "onmt.utils.logging.init_logger", "threading.Event", "translation_server.ServerModel.loading_lock.set", "threading.Semaphore", "onmt.utils.misc.set_random_seed", "ValueError", "len", "os.path.join", "translation_server.ServerModel.load"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.parse_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.logging.init_logger", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.set_random_seed", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load"], ["def", "__init__", "(", "self", ",", "opt", ",", "model_id", ",", "tokenizer_opt", "=", "None", ",", "load", "=", "False", ",", "\n", "timeout", "=", "-", "1", ",", "on_timeout", "=", "\"to_cpu\"", ",", "model_root", "=", "\"./\"", ")", ":", "\n", "        ", "self", ".", "model_root", "=", "model_root", "\n", "self", ".", "opt", "=", "self", ".", "parse_opt", "(", "opt", ")", "\n", "if", "self", ".", "opt", ".", "n_best", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Values of n_best > 1 are not supported\"", ")", "\n", "\n", "", "self", ".", "model_id", "=", "model_id", "\n", "self", ".", "tokenizer_opt", "=", "tokenizer_opt", "\n", "self", ".", "timeout", "=", "timeout", "\n", "self", ".", "on_timeout", "=", "on_timeout", "\n", "\n", "self", ".", "unload_timer", "=", "None", "\n", "self", ".", "user_opt", "=", "opt", "\n", "self", ".", "tokenizer", "=", "None", "\n", "\n", "if", "len", "(", "self", ".", "opt", ".", "log_file", ")", ">", "0", ":", "\n", "            ", "log_file", "=", "os", ".", "path", ".", "join", "(", "model_root", ",", "self", ".", "opt", ".", "log_file", ")", "\n", "", "else", ":", "\n", "            ", "log_file", "=", "None", "\n", "", "self", ".", "logger", "=", "init_logger", "(", "log_file", "=", "log_file", ",", "\n", "log_file_level", "=", "self", ".", "opt", ".", "log_file_level", ")", "\n", "\n", "self", ".", "loading_lock", "=", "threading", ".", "Event", "(", ")", "\n", "self", ".", "loading_lock", ".", "set", "(", ")", "\n", "self", ".", "running_lock", "=", "threading", ".", "Semaphore", "(", "value", "=", "1", ")", "\n", "\n", "set_random_seed", "(", "self", ".", "opt", ".", "seed", ",", "self", ".", "opt", ".", "cuda", ")", "\n", "\n", "if", "load", ":", "\n", "            ", "self", ".", "load", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.parse_opt": [[228, 265], ["onmt.utils.parse.ArgumentParser", "onmt.opts.translate_opts", "onmt.utils.parse.ArgumentParser.parse_args.items", "onmt.utils.parse.ArgumentParser.parse_args", "onmt.utils.parse.ArgumentParser.validate_translate_opts", "isinstance", "os.path.join", "str", "type", "str"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.opts.translate_opts", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.validate_translate_opts"], ["", "", "def", "parse_opt", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Parse the option set passed by the user using `onmt.opts`\n\n       Args:\n           opt (dict): Options passed by the user\n\n       Returns:\n           opt (argparse.Namespace): full set of options for the Translator\n        \"\"\"", "\n", "\n", "prec_argv", "=", "sys", ".", "argv", "\n", "sys", ".", "argv", "=", "sys", ".", "argv", "[", ":", "1", "]", "\n", "parser", "=", "ArgumentParser", "(", ")", "\n", "onmt", ".", "opts", ".", "translate_opts", "(", "parser", ")", "\n", "\n", "models", "=", "opt", "[", "'models'", "]", "\n", "if", "not", "isinstance", "(", "models", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "models", "=", "[", "models", "]", "\n", "", "opt", "[", "'models'", "]", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "model_root", ",", "model", ")", "\n", "for", "model", "in", "models", "]", "\n", "opt", "[", "'src'", "]", "=", "\"dummy_src\"", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "opt", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "==", "'models'", ":", "\n", "                ", "sys", ".", "argv", "+=", "[", "'-model'", "]", "\n", "sys", ".", "argv", "+=", "[", "str", "(", "model", ")", "for", "model", "in", "v", "]", "\n", "", "elif", "type", "(", "v", ")", "==", "bool", ":", "\n", "                ", "sys", ".", "argv", "+=", "[", "'-%s'", "%", "k", "]", "\n", "", "else", ":", "\n", "                ", "sys", ".", "argv", "+=", "[", "'-%s'", "%", "k", ",", "str", "(", "v", ")", "]", "\n", "\n", "", "", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "ArgumentParser", ".", "validate_translate_opts", "(", "opt", ")", "\n", "opt", ".", "cuda", "=", "opt", ".", "gpu", ">", "-", "1", "\n", "\n", "sys", ".", "argv", "=", "prec_argv", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.loaded": [[266, 269], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "loaded", "(", "self", ")", ":", "\n", "        ", "return", "hasattr", "(", "self", ",", "'translator'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load": [[270, 326], ["translation_server.ServerModel.loading_lock.clear", "translation_server.Timer", "translation_server.ServerModel.logger.info", "translation_server.Timer.start", "translation_server.Timer.tick", "translation_server.Timer.tick", "translation_server.ServerModel.reset_unload_timer", "translation_server.ServerModel.loading_lock.set", "onmt.translate.translator.build_translator", "translation_server.ServerModel.logger.info", "translation_server.ServerModelError", "ValueError", "spm.SentencePieceProcessor", "os.path.join", "spm.SentencePieceProcessor.Load", "open", "ValueError", "dict", "translation_server.ServerModel.tokenizer_opt[].items", "pyonmttok.Tokenizer", "ValueError", "str", "ValueError", "key.endswith", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.start", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.Timer.tick", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.Timer.tick", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.reset_unload_timer", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.build_translator"], ["", "def", "load", "(", "self", ")", ":", "\n", "        ", "self", ".", "loading_lock", ".", "clear", "(", ")", "\n", "\n", "timer", "=", "Timer", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Loading model %d\"", "%", "self", ".", "model_id", ")", "\n", "timer", ".", "start", "(", ")", "\n", "\n", "try", ":", "\n", "            ", "self", ".", "translator", "=", "build_translator", "(", "self", ".", "opt", ",", "\n", "report_score", "=", "False", ",", "\n", "out_file", "=", "open", "(", "os", ".", "devnull", ",", "\"w\"", ")", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "            ", "raise", "ServerModelError", "(", "\"Runtime Error: %s\"", "%", "str", "(", "e", ")", ")", "\n", "\n", "", "timer", ".", "tick", "(", "\"model_loading\"", ")", "\n", "if", "self", ".", "tokenizer_opt", "is", "not", "None", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Loading tokenizer\"", ")", "\n", "\n", "if", "\"type\"", "not", "in", "self", ".", "tokenizer_opt", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Missing mandatory tokenizer option 'type'\"", ")", "\n", "\n", "", "if", "self", ".", "tokenizer_opt", "[", "'type'", "]", "==", "'sentencepiece'", ":", "\n", "                ", "if", "\"model\"", "not", "in", "self", ".", "tokenizer_opt", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Missing mandatory tokenizer option 'model'\"", ")", "\n", "", "import", "sentencepiece", "as", "spm", "\n", "sp", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "model_root", ",", "\n", "self", ".", "tokenizer_opt", "[", "'model'", "]", ")", "\n", "sp", ".", "Load", "(", "model_path", ")", "\n", "self", ".", "tokenizer", "=", "sp", "\n", "", "elif", "self", ".", "tokenizer_opt", "[", "'type'", "]", "==", "'pyonmttok'", ":", "\n", "                ", "if", "\"params\"", "not", "in", "self", ".", "tokenizer_opt", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Missing mandatory tokenizer option 'params'\"", ")", "\n", "", "import", "pyonmttok", "\n", "if", "self", ".", "tokenizer_opt", "[", "\"mode\"", "]", "is", "not", "None", ":", "\n", "                    ", "mode", "=", "self", ".", "tokenizer_opt", "[", "\"mode\"", "]", "\n", "", "else", ":", "\n", "                    ", "mode", "=", "None", "\n", "# load can be called multiple times: modify copy", "\n", "", "tokenizer_params", "=", "dict", "(", "self", ".", "tokenizer_opt", "[", "\"params\"", "]", ")", "\n", "for", "key", ",", "value", "in", "self", ".", "tokenizer_opt", "[", "\"params\"", "]", ".", "items", "(", ")", ":", "\n", "                    ", "if", "key", ".", "endswith", "(", "\"path\"", ")", ":", "\n", "                        ", "tokenizer_params", "[", "key", "]", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "model_root", ",", "value", ")", "\n", "", "", "tokenizer", "=", "pyonmttok", ".", "Tokenizer", "(", "mode", ",", "\n", "**", "tokenizer_params", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Invalid value for tokenizer type\"", ")", "\n", "\n", "", "", "self", ".", "load_time", "=", "timer", ".", "tick", "(", ")", "\n", "self", ".", "reset_unload_timer", "(", ")", "\n", "self", ".", "loading_lock", ".", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.run": [[327, 434], ["translation_server.ServerModel.stop_unload_timer", "translation_server.Timer", "translation_server.Timer.start", "translation_server.ServerModel.logger.info", "enumerate", "translation_server.Timer.tick", "translation_server.ServerModel.logger.info", "translation_server.ServerModel.reset_unload_timer", "translation_server.ServerModel.run.flatten_list"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.stop_unload_timer", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.start", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.Timer.tick", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.reset_unload_timer"], ["", "@", "critical", "\n", "def", "run", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Translate `inputs` using this model\n\n        Args:\n            inputs (List[dict[str, str]]): [{\"src\": \"...\"},{\"src\": ...}]\n\n        Returns:\n            result (list): translations\n            times (dict): containing times\n        \"\"\"", "\n", "\n", "self", ".", "stop_unload_timer", "(", ")", "\n", "\n", "timer", "=", "Timer", "(", ")", "\n", "timer", ".", "start", "(", ")", "\n", "\n", "self", ".", "logger", ".", "info", "(", "\"Running translation using %d\"", "%", "self", ".", "model_id", ")", "\n", "\n", "if", "not", "self", ".", "loading_lock", ".", "is_set", "(", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\n", "\"Model #%d is being loaded by another thread, waiting\"", "\n", "%", "self", ".", "model_id", ")", "\n", "if", "not", "self", ".", "loading_lock", ".", "wait", "(", "timeout", "=", "30", ")", ":", "\n", "                ", "raise", "ServerModelError", "(", "\"Model %d loading timeout\"", "\n", "%", "self", ".", "model_id", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "not", "self", ".", "loaded", ":", "\n", "                ", "self", ".", "load", "(", ")", "\n", "timer", ".", "tick", "(", "name", "=", "\"load\"", ")", "\n", "", "elif", "self", ".", "opt", ".", "cuda", ":", "\n", "                ", "self", ".", "to_gpu", "(", ")", "\n", "timer", ".", "tick", "(", "name", "=", "\"to_gpu\"", ")", "\n", "\n", "", "", "texts", "=", "[", "]", "\n", "head_spaces", "=", "[", "]", "\n", "tail_spaces", "=", "[", "]", "\n", "sslength", "=", "[", "]", "\n", "for", "i", ",", "inp", "in", "enumerate", "(", "inputs", ")", ":", "\n", "            ", "src", "=", "inp", "[", "'src'", "]", "\n", "if", "src", ".", "strip", "(", ")", "==", "\"\"", ":", "\n", "                ", "head_spaces", ".", "append", "(", "src", ")", "\n", "texts", ".", "append", "(", "\"\"", ")", "\n", "tail_spaces", ".", "append", "(", "\"\"", ")", "\n", "", "else", ":", "\n", "                ", "whitespaces_before", ",", "whitespaces_after", "=", "\"\"", ",", "\"\"", "\n", "match_before", "=", "re", ".", "search", "(", "r'^\\s+'", ",", "src", ")", "\n", "match_after", "=", "re", ".", "search", "(", "r'\\s+$'", ",", "src", ")", "\n", "if", "match_before", "is", "not", "None", ":", "\n", "                    ", "whitespaces_before", "=", "match_before", ".", "group", "(", "0", ")", "\n", "", "if", "match_after", "is", "not", "None", ":", "\n", "                    ", "whitespaces_after", "=", "match_after", ".", "group", "(", "0", ")", "\n", "", "head_spaces", ".", "append", "(", "whitespaces_before", ")", "\n", "tok", "=", "self", ".", "maybe_tokenize", "(", "src", ".", "strip", "(", ")", ")", "\n", "texts", ".", "append", "(", "tok", ")", "\n", "sslength", ".", "append", "(", "len", "(", "tok", ".", "split", "(", ")", ")", ")", "\n", "tail_spaces", ".", "append", "(", "whitespaces_after", ")", "\n", "\n", "", "", "empty_indices", "=", "[", "i", "for", "i", ",", "x", "in", "enumerate", "(", "texts", ")", "if", "x", "==", "\"\"", "]", "\n", "texts_to_translate", "=", "[", "x", "for", "x", "in", "texts", "if", "x", "!=", "\"\"", "]", "\n", "\n", "scores", "=", "[", "]", "\n", "predictions", "=", "[", "]", "\n", "if", "len", "(", "texts_to_translate", ")", ">", "0", ":", "\n", "            ", "try", ":", "\n", "                ", "scores", ",", "predictions", "=", "self", ".", "translator", ".", "translate", "(", "\n", "texts_to_translate", ",", "\n", "batch_size", "=", "self", ".", "opt", ".", "batch_size", ")", "\n", "", "except", "(", "RuntimeError", ",", "Exception", ")", "as", "e", ":", "\n", "                ", "err", "=", "\"Error: %s\"", "%", "str", "(", "e", ")", "\n", "self", ".", "logger", ".", "error", "(", "err", ")", "\n", "self", ".", "logger", ".", "error", "(", "\"repr(text_to_translate): \"", "\n", "+", "repr", "(", "texts_to_translate", ")", ")", "\n", "self", ".", "logger", ".", "error", "(", "\"model: #%s\"", "%", "self", ".", "model_id", ")", "\n", "self", ".", "logger", ".", "error", "(", "\"model opt: \"", "+", "str", "(", "self", ".", "opt", ".", "__dict__", ")", ")", "\n", "self", ".", "logger", ".", "error", "(", "traceback", ".", "format_exc", "(", ")", ")", "\n", "\n", "raise", "ServerModelError", "(", "err", ")", "\n", "\n", "", "", "timer", ".", "tick", "(", "name", "=", "\"translation\"", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"\"\"Using model #%d\\t%d inputs\n               \\ttranslation time: %f\"\"\"", "%", "(", "self", ".", "model_id", ",", "len", "(", "texts", ")", ",", "\n", "timer", ".", "times", "[", "'translation'", "]", ")", ")", "\n", "self", ".", "reset_unload_timer", "(", ")", "\n", "\n", "# NOTE: translator returns lists of `n_best` list", "\n", "#       we can ignore that (i.e. flatten lists) only because", "\n", "#       we restrict `n_best=1`", "\n", "def", "flatten_list", "(", "_list", ")", ":", "return", "sum", "(", "_list", ",", "[", "]", ")", "\n", "results", "=", "flatten_list", "(", "predictions", ")", "\n", "scores", "=", "[", "score_tensor", ".", "item", "(", ")", "\n", "for", "score_tensor", "in", "flatten_list", "(", "scores", ")", "]", "\n", "\n", "results", "=", "[", "self", ".", "maybe_detokenize", "(", "item", ")", "\n", "for", "item", "in", "results", "]", "\n", "\n", "# build back results with empty texts", "\n", "for", "i", "in", "empty_indices", ":", "\n", "            ", "results", ".", "insert", "(", "i", ",", "\"\"", ")", "\n", "scores", ".", "insert", "(", "i", ",", "0", ")", "\n", "\n", "", "results", "=", "[", "\"\"", ".", "join", "(", "items", ")", "\n", "for", "items", "in", "zip", "(", "head_spaces", ",", "results", ",", "tail_spaces", ")", "]", "\n", "\n", "self", ".", "logger", ".", "info", "(", "\"Translation Results: %d\"", ",", "len", "(", "results", ")", ")", "\n", "return", "results", ",", "scores", ",", "self", ".", "opt", ".", "n_best", ",", "timer", ".", "times", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.do_timeout": [[435, 449], ["translation_server.ServerModel.logger.info", "translation_server.ServerModel.unload", "translation_server.ServerModel.logger.info", "translation_server.ServerModel.to_cpu"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.unload", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.to_cpu"], ["", "def", "do_timeout", "(", "self", ")", ":", "\n", "        ", "\"\"\"Timeout function that frees GPU memory.\n\n        Moves the model to CPU or unloads it; depending on\n        attr`self.on_timemout` value\n        \"\"\"", "\n", "\n", "if", "self", ".", "on_timeout", "==", "\"unload\"", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Timeout: unloading model %d\"", "%", "self", ".", "model_id", ")", "\n", "self", ".", "unload", "(", ")", "\n", "", "if", "self", ".", "on_timeout", "==", "\"to_cpu\"", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Timeout: sending model %d to CPU\"", "\n", "%", "self", ".", "model_id", ")", "\n", "self", ".", "to_cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.unload": [[450, 457], ["translation_server.ServerModel.logger.info", "torch.cuda.empty_cache"], "methods", ["None"], ["", "", "@", "critical", "\n", "def", "unload", "(", "self", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"Unloading model %d\"", "%", "self", ".", "model_id", ")", "\n", "del", "self", ".", "translator", "\n", "if", "self", ".", "opt", ".", "cuda", ":", "\n", "            ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "self", ".", "unload_timer", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.stop_unload_timer": [[458, 461], ["translation_server.ServerModel.unload_timer.cancel"], "methods", ["None"], ["", "def", "stop_unload_timer", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "unload_timer", "is", "not", "None", ":", "\n", "            ", "self", ".", "unload_timer", ".", "cancel", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.reset_unload_timer": [[462, 469], ["translation_server.ServerModel.stop_unload_timer", "threading.Timer", "translation_server.ServerModel.unload_timer.start"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.stop_unload_timer", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.start"], ["", "", "def", "reset_unload_timer", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "timeout", "<", "0", ":", "\n", "            ", "return", "\n", "\n", "", "self", ".", "stop_unload_timer", "(", ")", "\n", "self", ".", "unload_timer", "=", "threading", ".", "Timer", "(", "self", ".", "timeout", ",", "self", ".", "do_timeout", ")", "\n", "self", ".", "unload_timer", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.to_dict": [[470, 482], ["translation_server.ServerModel.user_opt.keys"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "hide_opt", "=", "[", "\"models\"", ",", "\"src\"", "]", "\n", "d", "=", "{", "\"model_id\"", ":", "self", ".", "model_id", ",", "\n", "\"opt\"", ":", "{", "k", ":", "self", ".", "user_opt", "[", "k", "]", "for", "k", "in", "self", ".", "user_opt", ".", "keys", "(", ")", "\n", "if", "k", "not", "in", "hide_opt", "}", ",", "\n", "\"models\"", ":", "self", ".", "user_opt", "[", "\"models\"", "]", ",", "\n", "\"loaded\"", ":", "self", ".", "loaded", ",", "\n", "\"timeout\"", ":", "self", ".", "timeout", ",", "\n", "}", "\n", "if", "self", ".", "tokenizer_opt", "is", "not", "None", ":", "\n", "            ", "d", "[", "\"tokenizer\"", "]", "=", "self", ".", "tokenizer_opt", "\n", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.to_cpu": [[483, 489], ["translation_server.ServerModel.translator.model.cpu", "torch.cuda.empty_cache"], "methods", ["None"], ["", "@", "critical", "\n", "def", "to_cpu", "(", "self", ")", ":", "\n", "        ", "\"\"\"Move the model to CPU and clear CUDA cache.\"\"\"", "\n", "self", ".", "translator", ".", "model", ".", "cpu", "(", ")", "\n", "if", "self", ".", "opt", ".", "cuda", ":", "\n", "            ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.to_gpu": [[490, 494], ["torch.cuda.set_device", "translation_server.ServerModel.translator.model.cuda"], "methods", ["None"], ["", "", "def", "to_gpu", "(", "self", ")", ":", "\n", "        ", "\"\"\"Move the model to GPU.\"\"\"", "\n", "torch", ".", "cuda", ".", "set_device", "(", "self", ".", "opt", ".", "gpu", ")", "\n", "self", ".", "translator", ".", "model", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.maybe_tokenize": [[495, 504], ["translation_server.ServerModel.tokenize"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.tokenize"], ["", "def", "maybe_tokenize", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"Tokenize the sequence (or not).\n\n        Same args/returns as `tokenize`\n        \"\"\"", "\n", "\n", "if", "self", ".", "tokenizer_opt", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "tokenize", "(", "sequence", ")", "\n", "", "return", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.tokenize": [[505, 525], ["ValueError", "translation_server.ServerModel.tokenizer.EncodeAsPieces", "translation_server.ServerModel.tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.tokenize"], ["", "def", "tokenize", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"Tokenize a single sequence.\n\n        Args:\n            sequence (str): The sequence to tokenize.\n\n        Returns:\n            tok (str): The tokenized sequence.\n        \"\"\"", "\n", "\n", "if", "self", ".", "tokenizer", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"No tokenizer loaded\"", ")", "\n", "\n", "", "if", "self", ".", "tokenizer_opt", "[", "\"type\"", "]", "==", "\"sentencepiece\"", ":", "\n", "            ", "tok", "=", "self", ".", "tokenizer", ".", "EncodeAsPieces", "(", "sequence", ")", "\n", "tok", "=", "\" \"", ".", "join", "(", "tok", ")", "\n", "", "elif", "self", ".", "tokenizer_opt", "[", "\"type\"", "]", "==", "\"pyonmttok\"", ":", "\n", "            ", "tok", ",", "_", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "sequence", ")", "\n", "tok", "=", "\" \"", ".", "join", "(", "tok", ")", "\n", "", "return", "tok", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.maybe_detokenize": [[526, 535], ["translation_server.ServerModel.detokenize", "sequence.split"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.detokenize"], ["", "def", "maybe_detokenize", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"De-tokenize the sequence (or not)\n\n        Same args/returns as :func:`tokenize()`\n        \"\"\"", "\n", "\n", "if", "self", ".", "tokenizer_opt", "is", "not", "None", "and", "''", ".", "join", "(", "sequence", ".", "split", "(", ")", ")", "!=", "''", ":", "\n", "            ", "return", "self", ".", "detokenize", "(", "sequence", ")", "\n", "", "return", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.detokenize": [[536, 551], ["ValueError", "translation_server.ServerModel.tokenizer.DecodePieces", "sequence.split", "translation_server.ServerModel.tokenizer.detokenize", "sequence.split"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.detokenize"], ["", "def", "detokenize", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"Detokenize a single sequence\n\n        Same args/returns as :func:`tokenize()`\n        \"\"\"", "\n", "\n", "if", "self", ".", "tokenizer", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"No tokenizer loaded\"", ")", "\n", "\n", "", "if", "self", ".", "tokenizer_opt", "[", "\"type\"", "]", "==", "\"sentencepiece\"", ":", "\n", "            ", "detok", "=", "self", ".", "tokenizer", ".", "DecodePieces", "(", "sequence", ".", "split", "(", ")", ")", "\n", "", "elif", "self", ".", "tokenizer_opt", "[", "\"type\"", "]", "==", "\"pyonmttok\"", ":", "\n", "            ", "detok", "=", "self", ".", "tokenizer", ".", "detokenize", "(", "sequence", ".", "split", "(", ")", ")", "\n", "\n", "", "return", "detok", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.critical": [[21, 39], ["server_model.running_lock.release", "server_model.running_lock.acquire", "func", "server_model.running_lock.acquire", "translation_server.ServerModelError", "server_model.running_lock.release"], "function", ["None"], ["def", "critical", "(", "func", ")", ":", "\n", "    ", "\"\"\"Decorator for critical section (mutually exclusive code)\"\"\"", "\n", "def", "wrapper", "(", "server_model", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", ":", "\n", "            ", "if", "not", "server_model", ".", "running_lock", ".", "acquire", "(", "True", ",", "120", ")", ":", "\n", "                ", "raise", "ServerModelError", "(", "\"Model %d running lock timeout\"", "\n", "%", "server_model", ".", "model_id", ")", "\n", "", "", "else", ":", "\n", "# semaphore doesn't have a timeout arg in Python 2.7", "\n", "            ", "server_model", ".", "running_lock", ".", "acquire", "(", "True", ")", "\n", "", "try", ":", "\n", "            ", "o", "=", "func", "(", "server_model", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "(", "Exception", ",", "RuntimeError", ")", ":", "\n", "            ", "server_model", ".", "running_lock", ".", "release", "(", ")", "\n", "raise", "\n", "", "server_model", ".", "running_lock", ".", "release", "(", ")", "\n", "return", "o", "\n", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam.Beam.__init__": [[31, 76], ["set", "beam.Beam.tt.FloatTensor().zero_", "beam.Beam.tt.LongTensor().fill_", "beam.Beam.tt.FloatTensor", "beam.Beam.tt.LongTensor"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "pad", ",", "bos", ",", "eos", ",", "\n", "n_best", "=", "1", ",", "cuda", "=", "False", ",", "\n", "global_scorer", "=", "None", ",", "\n", "min_length", "=", "0", ",", "\n", "stepwise_penalty", "=", "False", ",", "\n", "block_ngram_repeat", "=", "0", ",", "\n", "exclusion_tokens", "=", "set", "(", ")", ")", ":", "\n", "\n", "        ", "self", ".", "size", "=", "size", "\n", "self", ".", "tt", "=", "torch", ".", "cuda", "if", "cuda", "else", "torch", "\n", "\n", "# The score for each translation on the beam.", "\n", "self", ".", "scores", "=", "self", ".", "tt", ".", "FloatTensor", "(", "size", ")", ".", "zero_", "(", ")", "\n", "self", ".", "all_scores", "=", "[", "]", "\n", "\n", "# The backpointers at each time-step.", "\n", "self", ".", "prev_ks", "=", "[", "]", "\n", "\n", "# The outputs at each time-step.", "\n", "self", ".", "next_ys", "=", "[", "self", ".", "tt", ".", "LongTensor", "(", "size", ")", "\n", ".", "fill_", "(", "pad", ")", "]", "\n", "self", ".", "next_ys", "[", "0", "]", "[", "0", "]", "=", "bos", "\n", "\n", "# Has EOS topped the beam yet.", "\n", "self", ".", "_eos", "=", "eos", "\n", "self", ".", "eos_top", "=", "False", "\n", "\n", "# The attentions (matrix) for each time.", "\n", "self", ".", "attn", "=", "[", "]", "\n", "\n", "# Time and k pair for finished.", "\n", "self", ".", "finished", "=", "[", "]", "\n", "self", ".", "n_best", "=", "n_best", "\n", "\n", "# Information for global scoring.", "\n", "self", ".", "global_scorer", "=", "global_scorer", "\n", "self", ".", "global_state", "=", "{", "}", "\n", "\n", "# Minimum prediction length", "\n", "self", ".", "min_length", "=", "min_length", "\n", "\n", "# Apply Penalty at every step", "\n", "self", ".", "stepwise_penalty", "=", "stepwise_penalty", "\n", "self", ".", "block_ngram_repeat", "=", "block_ngram_repeat", "\n", "self", ".", "exclusion_tokens", "=", "exclusion_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam.Beam.current_predictions": [[77, 80], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "current_predictions", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "next_ys", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam.Beam.current_origin": [[81, 85], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "current_origin", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the backpointers for the current timestep.\"\"\"", "\n", "return", "self", ".", "prev_ks", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam.Beam.advance": [[86, 166], ["word_probs.size", "len", "beam_scores.view", "beam_scores.view.topk", "beam.Beam.all_scores.append", "beam.Beam.prev_ks.append", "beam.Beam.next_ys.append", "beam.Beam.attn.append", "beam.Beam.global_scorer.update_global_state", "range", "beam.Beam.global_scorer.update_score", "range", "len", "range", "attn_out.index_select", "beam.Beam.next_ys[].size", "beam.Beam.all_scores.append", "len", "beam.Beam.scores.unsqueeze", "beam.Beam.next_ys[].size", "len", "range", "beam.Beam.global_scorer.score", "beam.Beam.finished.append", "beam.Beam.next_ys[].size", "beam.Beam.get_hyp", "set", "range", "set.add", "set", "tuple", "tuple", "len", "hyp[].item"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.GlobalScorerStub.update_global_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam.GNMTGlobalScorer.update_score", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.GlobalScorerStub.score", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam.Beam.get_hyp"], ["", "def", "advance", "(", "self", ",", "word_probs", ",", "attn_out", ")", ":", "\n", "        ", "\"\"\"\n        Given prob over words for every last beam `wordLk` and attention\n        `attn_out`: Compute and update the beam search.\n\n        Args:\n            word_probs (FloatTensor): probs of advancing from the last step\n                ``(K, words)``\n            attn_out (FloatTensor): attention at the last step\n\n        Returns:\n            bool: True if beam search is complete.\n        \"\"\"", "\n", "\n", "num_words", "=", "word_probs", ".", "size", "(", "1", ")", "\n", "if", "self", ".", "stepwise_penalty", ":", "\n", "            ", "self", ".", "global_scorer", ".", "update_score", "(", "self", ",", "attn_out", ")", "\n", "# force the output to be longer than self.min_length", "\n", "", "cur_len", "=", "len", "(", "self", ".", "next_ys", ")", "\n", "if", "cur_len", "<=", "self", ".", "min_length", ":", "\n", "# assumes there are len(word_probs) predictions OTHER", "\n", "# than EOS that are greater than -1e20", "\n", "            ", "for", "k", "in", "range", "(", "len", "(", "word_probs", ")", ")", ":", "\n", "                ", "word_probs", "[", "k", "]", "[", "self", ".", "_eos", "]", "=", "-", "1e20", "\n", "\n", "# Sum the previous scores.", "\n", "", "", "if", "len", "(", "self", ".", "prev_ks", ")", ">", "0", ":", "\n", "            ", "beam_scores", "=", "word_probs", "+", "self", ".", "scores", ".", "unsqueeze", "(", "1", ")", "\n", "# Don't let EOS have children.", "\n", "for", "i", "in", "range", "(", "self", ".", "next_ys", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "                ", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "i", "]", "==", "self", ".", "_eos", ":", "\n", "                    ", "beam_scores", "[", "i", "]", "=", "-", "1e20", "\n", "\n", "# Block ngram repeats", "\n", "", "", "if", "self", ".", "block_ngram_repeat", ">", "0", ":", "\n", "                ", "le", "=", "len", "(", "self", ".", "next_ys", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "next_ys", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "                    ", "hyp", ",", "_", "=", "self", ".", "get_hyp", "(", "le", "-", "1", ",", "j", ")", "\n", "ngrams", "=", "set", "(", ")", "\n", "fail", "=", "False", "\n", "gram", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "le", "-", "1", ")", ":", "\n", "# Last n tokens, n = block_ngram_repeat", "\n", "                        ", "gram", "=", "(", "gram", "+", "\n", "[", "hyp", "[", "i", "]", ".", "item", "(", ")", "]", ")", "[", "-", "self", ".", "block_ngram_repeat", ":", "]", "\n", "# Skip the blocking if it is in the exclusion list", "\n", "if", "set", "(", "gram", ")", "&", "self", ".", "exclusion_tokens", ":", "\n", "                            ", "continue", "\n", "", "if", "tuple", "(", "gram", ")", "in", "ngrams", ":", "\n", "                            ", "fail", "=", "True", "\n", "", "ngrams", ".", "add", "(", "tuple", "(", "gram", ")", ")", "\n", "", "if", "fail", ":", "\n", "                        ", "beam_scores", "[", "j", "]", "=", "-", "10e20", "\n", "", "", "", "", "else", ":", "\n", "            ", "beam_scores", "=", "word_probs", "[", "0", "]", "\n", "", "flat_beam_scores", "=", "beam_scores", ".", "view", "(", "-", "1", ")", "\n", "best_scores", ",", "best_scores_id", "=", "flat_beam_scores", ".", "topk", "(", "self", ".", "size", ",", "0", ",", "\n", "True", ",", "True", ")", "\n", "\n", "self", ".", "all_scores", ".", "append", "(", "self", ".", "scores", ")", "\n", "self", ".", "scores", "=", "best_scores", "\n", "\n", "# best_scores_id is flattened beam x word array, so calculate which", "\n", "# word and beam each score came from", "\n", "prev_k", "=", "best_scores_id", "/", "num_words", "\n", "self", ".", "prev_ks", ".", "append", "(", "prev_k", ")", "\n", "self", ".", "next_ys", ".", "append", "(", "(", "best_scores_id", "-", "prev_k", "*", "num_words", ")", ")", "\n", "self", ".", "attn", ".", "append", "(", "attn_out", ".", "index_select", "(", "0", ",", "prev_k", ")", ")", "\n", "self", ".", "global_scorer", ".", "update_global_state", "(", "self", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "next_ys", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "i", "]", "==", "self", ".", "_eos", ":", "\n", "                ", "global_scores", "=", "self", ".", "global_scorer", ".", "score", "(", "self", ",", "self", ".", "scores", ")", "\n", "s", "=", "global_scores", "[", "i", "]", "\n", "self", ".", "finished", ".", "append", "(", "(", "s", ",", "len", "(", "self", ".", "next_ys", ")", "-", "1", ",", "i", ")", ")", "\n", "\n", "# End condition is when top-of-beam is EOS and no global score.", "\n", "", "", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "0", "]", "==", "self", ".", "_eos", ":", "\n", "            ", "self", ".", "all_scores", ".", "append", "(", "self", ".", "scores", ")", "\n", "self", ".", "eos_top", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam.Beam.done": [[167, 170], ["len"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "done", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "eos_top", "and", "len", "(", "self", ".", "finished", ")", ">=", "self", ".", "n_best", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam.Beam.sort_finished": [[171, 185], ["beam.Beam.finished.sort", "len", "beam.Beam.global_scorer.score", "beam.Beam.finished.append", "len"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.GlobalScorerStub.score"], ["", "def", "sort_finished", "(", "self", ",", "minimum", "=", "None", ")", ":", "\n", "        ", "if", "minimum", "is", "not", "None", ":", "\n", "            ", "i", "=", "0", "\n", "# Add from beam until we have minimum outputs.", "\n", "while", "len", "(", "self", ".", "finished", ")", "<", "minimum", ":", "\n", "                ", "global_scores", "=", "self", ".", "global_scorer", ".", "score", "(", "self", ",", "self", ".", "scores", ")", "\n", "s", "=", "global_scores", "[", "i", "]", "\n", "self", ".", "finished", ".", "append", "(", "(", "s", ",", "len", "(", "self", ".", "next_ys", ")", "-", "1", ",", "i", ")", ")", "\n", "i", "+=", "1", "\n", "\n", "", "", "self", ".", "finished", ".", "sort", "(", "key", "=", "lambda", "a", ":", "-", "a", "[", "0", "]", ")", "\n", "scores", "=", "[", "sc", "for", "sc", ",", "_", ",", "_", "in", "self", ".", "finished", "]", "\n", "ks", "=", "[", "(", "t", ",", "k", ")", "for", "_", ",", "t", ",", "k", "in", "self", ".", "finished", "]", "\n", "return", "scores", ",", "ks", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam.Beam.get_hyp": [[186, 194], ["range", "hyp.append", "attn.append", "torch.stack", "len"], "methods", ["None"], ["", "def", "get_hyp", "(", "self", ",", "timestep", ",", "k", ")", ":", "\n", "        ", "\"\"\"Walk back to construct the full hypothesis.\"\"\"", "\n", "hyp", ",", "attn", "=", "[", "]", ",", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "self", ".", "prev_ks", "[", ":", "timestep", "]", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "hyp", ".", "append", "(", "self", ".", "next_ys", "[", "j", "+", "1", "]", "[", "k", "]", ")", "\n", "attn", ".", "append", "(", "self", ".", "attn", "[", "j", "]", "[", "k", "]", ")", "\n", "k", "=", "self", ".", "prev_ks", "[", "j", "]", "[", "k", "]", "\n", "", "return", "hyp", "[", ":", ":", "-", "1", "]", ",", "torch", ".", "stack", "(", "attn", "[", ":", ":", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam.GNMTGlobalScorer.from_opt": [[214, 221], ["cls"], "methods", ["None"], ["@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ")", ":", "\n", "        ", "return", "cls", "(", "\n", "opt", ".", "alpha", ",", "\n", "opt", ".", "beta", ",", "\n", "opt", ".", "length_penalty", ",", "\n", "opt", ".", "coverage_penalty", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam.GNMTGlobalScorer.__init__": [[222, 235], ["beam.GNMTGlobalScorer._validate", "onmt.translate.penalties.PenaltyBuilder"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam.GNMTGlobalScorer._validate"], ["", "def", "__init__", "(", "self", ",", "alpha", ",", "beta", ",", "length_penalty", ",", "coverage_penalty", ")", ":", "\n", "        ", "self", ".", "_validate", "(", "alpha", ",", "beta", ",", "length_penalty", ",", "coverage_penalty", ")", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "beta", "=", "beta", "\n", "penalty_builder", "=", "penalties", ".", "PenaltyBuilder", "(", "coverage_penalty", ",", "\n", "length_penalty", ")", "\n", "self", ".", "has_cov_pen", "=", "penalty_builder", ".", "has_cov_pen", "\n", "# Term will be subtracted from probability", "\n", "self", ".", "cov_penalty", "=", "penalty_builder", ".", "coverage_penalty", "\n", "\n", "self", ".", "has_len_pen", "=", "penalty_builder", ".", "has_len_pen", "\n", "# Probability will be divided by this", "\n", "self", ".", "length_penalty", "=", "penalty_builder", ".", "length_penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam.GNMTGlobalScorer._validate": [[236, 258], ["warnings.warn", "warnings.warn", "warnings.warn", "warnings.warn"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_validate", "(", "cls", ",", "alpha", ",", "beta", ",", "length_penalty", ",", "coverage_penalty", ")", ":", "\n", "# these warnings indicate that either the alpha/beta", "\n", "# forces a penalty to be a no-op, or a penalty is a no-op but", "\n", "# the alpha/beta would suggest otherwise.", "\n", "        ", "if", "length_penalty", "is", "None", "or", "length_penalty", "==", "\"none\"", ":", "\n", "            ", "if", "alpha", "!=", "0", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"Non-default `alpha` with no length penalty. \"", "\n", "\"`alpha` has no effect.\"", ")", "\n", "", "", "else", ":", "\n", "# using some length penalty", "\n", "            ", "if", "length_penalty", "==", "\"wu\"", "and", "alpha", "==", "0.", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"Using length penalty Wu with alpha==0 \"", "\n", "\"is equivalent to using length penalty none.\"", ")", "\n", "", "", "if", "coverage_penalty", "is", "None", "or", "coverage_penalty", "==", "\"none\"", ":", "\n", "            ", "if", "beta", "!=", "0", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"Non-default `beta` with no coverage penalty. \"", "\n", "\"`beta` has no effect.\"", ")", "\n", "", "", "else", ":", "\n", "# using some coverage penalty", "\n", "            ", "if", "beta", "==", "0.", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"Non-default coverage penalty with beta==0 \"", "\n", "\"is equivalent to using coverage penalty none.\"", ")", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam.GNMTGlobalScorer.score": [[260, 270], ["beam.GNMTGlobalScorer.length_penalty", "len", "beam.GNMTGlobalScorer.cov_penalty"], "methods", ["None"], ["", "", "", "def", "score", "(", "self", ",", "beam", ",", "logprobs", ")", ":", "\n", "        ", "\"\"\"Rescore a prediction based on penalty functions.\"\"\"", "\n", "len_pen", "=", "self", ".", "length_penalty", "(", "len", "(", "beam", ".", "next_ys", ")", ",", "self", ".", "alpha", ")", "\n", "normalized_probs", "=", "logprobs", "/", "len_pen", "\n", "if", "not", "beam", ".", "stepwise_penalty", ":", "\n", "            ", "penalty", "=", "self", ".", "cov_penalty", "(", "beam", ".", "global_state", "[", "\"coverage\"", "]", ",", "\n", "self", ".", "beta", ")", "\n", "normalized_probs", "-=", "penalty", "\n", "\n", "", "return", "normalized_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam.GNMTGlobalScorer.update_score": [[271, 278], ["beam.global_state.keys", "beam.scores.add_", "beam.GNMTGlobalScorer.cov_penalty", "beam.scores.sub_"], "methods", ["None"], ["", "def", "update_score", "(", "self", ",", "beam", ",", "attn", ")", ":", "\n", "        ", "\"\"\"Update scores of a Beam that is not finished.\"\"\"", "\n", "if", "\"prev_penalty\"", "in", "beam", ".", "global_state", ".", "keys", "(", ")", ":", "\n", "            ", "beam", ".", "scores", ".", "add_", "(", "beam", ".", "global_state", "[", "\"prev_penalty\"", "]", ")", "\n", "penalty", "=", "self", ".", "cov_penalty", "(", "beam", ".", "global_state", "[", "\"coverage\"", "]", "+", "attn", ",", "\n", "self", ".", "beta", ")", "\n", "beam", ".", "scores", ".", "sub_", "(", "penalty", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.beam.GNMTGlobalScorer.update_global_state": [[279, 294], ["len", "beam.scores.clone().fill_", "beam.attn[].sum", "torch.min().sum", "beam.global_state[].index_select().add", "beam.GNMTGlobalScorer.cov_penalty", "beam.scores.clone", "torch.min", "beam.global_state[].index_select"], "methods", ["None"], ["", "", "def", "update_global_state", "(", "self", ",", "beam", ")", ":", "\n", "        ", "\"\"\"Keeps the coverage vector as sum of attentions.\"\"\"", "\n", "if", "len", "(", "beam", ".", "prev_ks", ")", "==", "1", ":", "\n", "            ", "beam", ".", "global_state", "[", "\"prev_penalty\"", "]", "=", "beam", ".", "scores", ".", "clone", "(", ")", ".", "fill_", "(", "0.0", ")", "\n", "beam", ".", "global_state", "[", "\"coverage\"", "]", "=", "beam", ".", "attn", "[", "-", "1", "]", "\n", "self", ".", "cov_total", "=", "beam", ".", "attn", "[", "-", "1", "]", ".", "sum", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "cov_total", "+=", "torch", ".", "min", "(", "beam", ".", "attn", "[", "-", "1", "]", ",", "\n", "beam", ".", "global_state", "[", "'coverage'", "]", ")", ".", "sum", "(", "1", ")", "\n", "beam", ".", "global_state", "[", "\"coverage\"", "]", "=", "beam", ".", "global_state", "[", "\"coverage\"", "]", ".", "index_select", "(", "0", ",", "beam", ".", "prev_ks", "[", "-", "1", "]", ")", ".", "add", "(", "beam", ".", "attn", "[", "-", "1", "]", ")", "\n", "\n", "prev_penalty", "=", "self", ".", "cov_penalty", "(", "beam", ".", "global_state", "[", "\"coverage\"", "]", ",", "\n", "self", ".", "beta", ")", "\n", "beam", ".", "global_state", "[", "\"prev_penalty\"", "]", "=", "prev_penalty", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.random_sampling.RandomSampling.__init__": [[86, 103], ["onmt.translate.decode_strategy.DecodeStrategy.__init__", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "pad", ",", "bos", ",", "eos", ",", "batch_size", ",", "device", ",", "\n", "min_length", ",", "block_ngram_repeat", ",", "exclusion_tokens", ",", "\n", "return_attention", ",", "max_length", ",", "sampling_temp", ",", "keep_topk", ",", "\n", "memory_length", ")", ":", "\n", "        ", "super", "(", "RandomSampling", ",", "self", ")", ".", "__init__", "(", "\n", "pad", ",", "bos", ",", "eos", ",", "batch_size", ",", "device", ",", "1", ",", "\n", "min_length", ",", "block_ngram_repeat", ",", "exclusion_tokens", ",", "\n", "return_attention", ",", "max_length", ")", "\n", "self", ".", "sampling_temp", "=", "sampling_temp", "\n", "self", ".", "keep_topk", "=", "keep_topk", "\n", "self", ".", "topk_scores", "=", "None", "\n", "self", ".", "memory_length", "=", "memory_length", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "select_indices", "=", "torch", ".", "arange", "(", "self", ".", "batch_size", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "self", ".", "original_batch_idx", "=", "torch", ".", "arange", "(", "self", ".", "batch_size", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.random_sampling.RandomSampling.set_random_temperature": [[104, 106], ["None"], "methods", ["None"], ["", "def", "set_random_temperature", "(", "self", ",", "temp", ")", ":", "\n", "        ", "self", ".", "sampling_temp", "=", "temp", "\n", "", "def", "advance", "(", "self", ",", "log_probs", ",", "attn", ")", ":", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.random_sampling.RandomSampling.advance": [[106, 133], ["random_sampling.RandomSampling.ensure_min_length", "random_sampling.RandomSampling.block_ngram_repeats", "random_sampling.sample_with_temperature", "topk_ids.eq", "torch.cat", "random_sampling.RandomSampling.ensure_max_length", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.ensure_min_length", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.block_ngram_repeats", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.random_sampling.sample_with_temperature", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.ensure_max_length"], ["", "def", "advance", "(", "self", ",", "log_probs", ",", "attn", ")", ":", "\n", "        ", "\"\"\"Select next tokens randomly from the top k possible next tokens.\n\n        Args:\n            log_probs (FloatTensor): Shaped ``(batch_size, vocab_size)``.\n                These can be logits (``(-inf, inf)``) or log-probs\n                (``(-inf, 0]``). (The distribution actually uses the\n                log-probabilities ``logits - logits.logsumexp(-1)``,\n                which equals the logits if they are log-probabilities summing\n                to 1.)\n            attn (FloatTensor): Shaped ``(1, B, inp_seq_len)``.\n        \"\"\"", "\n", "\n", "self", ".", "ensure_min_length", "(", "log_probs", ")", "\n", "self", ".", "block_ngram_repeats", "(", "log_probs", ")", "\n", "topk_ids", ",", "self", ".", "topk_scores", "=", "sample_with_temperature", "(", "\n", "log_probs", ",", "self", ".", "sampling_temp", ",", "self", ".", "keep_topk", ")", "\n", "\n", "self", ".", "is_finished", "=", "topk_ids", ".", "eq", "(", "self", ".", "eos", ")", "\n", "\n", "self", ".", "alive_seq", "=", "torch", ".", "cat", "(", "[", "self", ".", "alive_seq", ",", "topk_ids", "]", ",", "-", "1", ")", "\n", "if", "self", ".", "return_attention", ":", "\n", "            ", "if", "self", ".", "alive_attn", "is", "None", ":", "\n", "                ", "self", ".", "alive_attn", "=", "attn", "\n", "", "else", ":", "\n", "                ", "self", ".", "alive_attn", "=", "torch", ".", "cat", "(", "[", "self", ".", "alive_attn", ",", "attn", "]", ",", "0", ")", "\n", "", "", "self", ".", "ensure_max_length", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.random_sampling.RandomSampling.update_finished": [[134, 154], ["random_sampling.RandomSampling.is_finished.view().nonzero", "random_sampling.RandomSampling.view", "random_sampling.RandomSampling.is_finished.all", "is_alive.nonzero().view", "random_sampling.RandomSampling.scores[].append", "random_sampling.RandomSampling.predictions[].append", "random_sampling.RandomSampling.attention[].append", "random_sampling.RandomSampling.is_finished.view", "random_sampling.RandomSampling.is_finished.view", "is_alive.nonzero"], "methods", ["None"], ["", "def", "update_finished", "(", "self", ")", ":", "\n", "        ", "\"\"\"Finalize scores and predictions.\"\"\"", "\n", "# shape: (sum(~ self.is_finished), 1)", "\n", "finished_batches", "=", "self", ".", "is_finished", ".", "view", "(", "-", "1", ")", ".", "nonzero", "(", ")", "\n", "for", "b", "in", "finished_batches", ".", "view", "(", "-", "1", ")", ":", "\n", "            ", "b_orig", "=", "self", ".", "original_batch_idx", "[", "b", "]", "\n", "self", ".", "scores", "[", "b_orig", "]", ".", "append", "(", "self", ".", "topk_scores", "[", "b", ",", "0", "]", ")", "\n", "self", ".", "predictions", "[", "b_orig", "]", ".", "append", "(", "self", ".", "alive_seq", "[", "b", ",", "1", ":", "]", ")", "\n", "self", ".", "attention", "[", "b_orig", "]", ".", "append", "(", "\n", "self", ".", "alive_attn", "[", ":", ",", "b", ",", ":", "self", ".", "memory_length", "[", "b", "]", "]", "\n", "if", "self", ".", "alive_attn", "is", "not", "None", "else", "[", "]", ")", "\n", "", "self", ".", "done", "=", "self", ".", "is_finished", ".", "all", "(", ")", "\n", "if", "self", ".", "done", ":", "\n", "            ", "return", "\n", "", "is_alive", "=", "~", "self", ".", "is_finished", ".", "view", "(", "-", "1", ")", "\n", "self", ".", "alive_seq", "=", "self", ".", "alive_seq", "[", "is_alive", "]", "\n", "if", "self", ".", "alive_attn", "is", "not", "None", ":", "\n", "            ", "self", ".", "alive_attn", "=", "self", ".", "alive_attn", "[", ":", ",", "is_alive", "]", "\n", "", "self", ".", "select_indices", "=", "is_alive", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "self", ".", "original_batch_idx", "=", "self", ".", "original_batch_idx", "[", "is_alive", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.random_sampling.sample_with_temperature": [[6, 57], ["logits.masked_fill.topk", "torch.div", "torch.distributions.Multinomial", "torch.argmax", "logits.masked_fill.gather", "torch.topk", "top_values[].view", "kth_best.repeat().float.repeat().float", "torch.lt", "logits.masked_fill.masked_fill", "torch.distributions.Multinomial.sample", "kth_best.repeat().float.repeat"], "function", ["None"], ["def", "sample_with_temperature", "(", "logits", ",", "sampling_temp", ",", "keep_topk", ")", ":", "\n", "    ", "\"\"\"Select next tokens randomly from the top k possible next tokens.\n\n    Samples from a categorical distribution over the ``keep_topk`` words using\n    the category probabilities ``logits / sampling_temp``.\n\n    Args:\n        logits (FloatTensor): Shaped ``(batch_size, vocab_size)``.\n            These can be logits (``(-inf, inf)``) or log-probs (``(-inf, 0]``).\n            (The distribution actually uses the log-probabilities\n            ``logits - logits.logsumexp(-1)``, which equals the logits if\n            they are log-probabilities summing to 1.)\n        sampling_temp (float): Used to scale down logits. The higher the\n            value, the more likely it is that a non-max word will be\n            sampled.\n        keep_topk (int): This many words could potentially be chosen. The\n            other logits are set to have probability 0.\n\n    Returns:\n        (LongTensor, FloatTensor):\n\n        * topk_ids: Shaped ``(batch_size, 1)``. These are\n          the sampled word indices in the output vocab.\n        * topk_scores: Shaped ``(batch_size, 1)``. These\n          are essentially ``(logits / sampling_temp)[topk_ids]``.\n    \"\"\"", "\n", "\n", "if", "sampling_temp", "==", "0.0", "or", "keep_topk", "==", "1", ":", "\n", "# For temp=0.0, take the argmax to avoid divide-by-zero errors.", "\n", "# keep_topk=1 is also equivalent to argmax.", "\n", "        ", "topk_scores", ",", "topk_ids", "=", "logits", ".", "topk", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "if", "sampling_temp", ">", "0", ":", "\n", "            ", "topk_scores", "/=", "sampling_temp", "\n", "", "", "else", ":", "\n", "        ", "logits", "=", "torch", ".", "div", "(", "logits", ",", "sampling_temp", ")", "\n", "\n", "if", "keep_topk", ">", "0", ":", "\n", "            ", "top_values", ",", "top_indices", "=", "torch", ".", "topk", "(", "logits", ",", "keep_topk", ",", "dim", "=", "1", ")", "\n", "kth_best", "=", "top_values", "[", ":", ",", "-", "1", "]", ".", "view", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "kth_best", "=", "kth_best", ".", "repeat", "(", "[", "1", ",", "logits", ".", "shape", "[", "1", "]", "]", ")", ".", "float", "(", ")", "\n", "\n", "# Set all logits that are not in the top-k to -10000.", "\n", "# This puts the probabilities close to 0.", "\n", "ignore", "=", "torch", ".", "lt", "(", "logits", ",", "kth_best", ")", "\n", "logits", "=", "logits", ".", "masked_fill", "(", "ignore", ",", "-", "10000", ")", "\n", "\n", "", "dist", "=", "torch", ".", "distributions", ".", "Multinomial", "(", "\n", "logits", "=", "logits", ",", "total_count", "=", "1", ")", "\n", "topk_ids", "=", "torch", ".", "argmax", "(", "dist", ".", "sample", "(", ")", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "topk_scores", "=", "logits", ".", "gather", "(", "dim", "=", "1", ",", "index", "=", "topk_ids", ")", "\n", "", "return", "topk_ids", ",", "topk_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.penalties.PenaltyBuilder.__init__": [[25, 30], ["penalties.PenaltyBuilder._coverage_penalty", "penalties.PenaltyBuilder._length_penalty", "penalties.PenaltyBuilder._pen_is_none", "penalties.PenaltyBuilder._pen_is_none"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.penalties.PenaltyBuilder._coverage_penalty", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.penalties.PenaltyBuilder._length_penalty", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.penalties.PenaltyBuilder._pen_is_none", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.penalties.PenaltyBuilder._pen_is_none"], ["def", "__init__", "(", "self", ",", "cov_pen", ",", "length_pen", ")", ":", "\n", "        ", "self", ".", "has_cov_pen", "=", "not", "self", ".", "_pen_is_none", "(", "cov_pen", ")", "\n", "self", ".", "coverage_penalty", "=", "self", ".", "_coverage_penalty", "(", "cov_pen", ")", "\n", "self", ".", "has_len_pen", "=", "not", "self", ".", "_pen_is_none", "(", "length_pen", ")", "\n", "self", ".", "length_penalty", "=", "self", ".", "_length_penalty", "(", "length_pen", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.penalties.PenaltyBuilder._pen_is_none": [[31, 34], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_pen_is_none", "(", "pen", ")", ":", "\n", "        ", "return", "pen", "==", "\"none\"", "or", "pen", "is", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.penalties.PenaltyBuilder._coverage_penalty": [[35, 45], ["penalties.PenaltyBuilder._pen_is_none", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.penalties.PenaltyBuilder._pen_is_none"], ["", "def", "_coverage_penalty", "(", "self", ",", "cov_pen", ")", ":", "\n", "        ", "if", "cov_pen", "==", "\"wu\"", ":", "\n", "            ", "return", "self", ".", "coverage_wu", "\n", "", "elif", "cov_pen", "==", "\"summary\"", ":", "\n", "            ", "return", "self", ".", "coverage_summary", "\n", "", "elif", "self", ".", "_pen_is_none", "(", "cov_pen", ")", ":", "\n", "            ", "return", "self", ".", "coverage_none", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"No '{:s}' coverage penalty.\"", ".", "format", "(", "\n", "cov_pen", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.penalties.PenaltyBuilder._length_penalty": [[46, 56], ["penalties.PenaltyBuilder._pen_is_none", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.penalties.PenaltyBuilder._pen_is_none"], ["", "", "def", "_length_penalty", "(", "self", ",", "length_pen", ")", ":", "\n", "        ", "if", "length_pen", "==", "\"wu\"", ":", "\n", "            ", "return", "self", ".", "length_wu", "\n", "", "elif", "length_pen", "==", "\"avg\"", ":", "\n", "            ", "return", "self", ".", "length_average", "\n", "", "elif", "self", ".", "_pen_is_none", "(", "length_pen", ")", ":", "\n", "            ", "return", "self", ".", "length_none", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"No '{:s}' length penalty.\"", ".", "format", "(", "\n", "length_pen", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.penalties.PenaltyBuilder.coverage_wu": [[61, 73], ["torch.min().log().sum", "torch.min().log", "torch.min", "cov.clone().fill_", "cov.clone"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log"], ["", "", "def", "coverage_wu", "(", "self", ",", "cov", ",", "beta", "=", "0.", ")", ":", "\n", "        ", "\"\"\"GNMT coverage re-ranking score.\n\n        See \"Google's Neural Machine Translation System\" :cite:`wu2016google`.\n        ``cov`` is expected to be sized ``(*, seq_len)``, where ``*`` is\n        probably ``batch_size x beam_size`` but could be several\n        dimensions like ``(batch_size, beam_size)``. If ``cov`` is attention,\n        then the ``seq_len`` axis probably sums to (almost) 1.\n        \"\"\"", "\n", "\n", "penalty", "=", "-", "torch", ".", "min", "(", "cov", ",", "cov", ".", "clone", "(", ")", ".", "fill_", "(", "1.0", ")", ")", ".", "log", "(", ")", ".", "sum", "(", "-", "1", ")", "\n", "return", "beta", "*", "penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.penalties.PenaltyBuilder.coverage_summary": [[74, 79], ["torch.max().sum", "cov.size", "torch.max", "cov.clone().fill_", "cov.clone"], "methods", ["None"], ["", "def", "coverage_summary", "(", "self", ",", "cov", ",", "beta", "=", "0.", ")", ":", "\n", "        ", "\"\"\"Our summary penalty.\"\"\"", "\n", "penalty", "=", "torch", ".", "max", "(", "cov", ",", "cov", ".", "clone", "(", ")", ".", "fill_", "(", "1.0", ")", ")", ".", "sum", "(", "-", "1", ")", "\n", "penalty", "-=", "cov", ".", "size", "(", "-", "1", ")", "\n", "return", "beta", "*", "penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.penalties.PenaltyBuilder.coverage_none": [[80, 87], ["torch.zeros", "cov.dim", "none.unsqueeze.unsqueeze.unsqueeze"], "methods", ["None"], ["", "def", "coverage_none", "(", "self", ",", "cov", ",", "beta", "=", "0.", ")", ":", "\n", "        ", "\"\"\"Returns zero as penalty\"\"\"", "\n", "none", "=", "torch", ".", "zeros", "(", "(", "1", ",", ")", ",", "device", "=", "cov", ".", "device", ",", "\n", "dtype", "=", "torch", ".", "float", ")", "\n", "if", "cov", ".", "dim", "(", ")", "==", "3", ":", "\n", "            ", "none", "=", "none", ".", "unsqueeze", "(", "0", ")", "\n", "", "return", "none", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.penalties.PenaltyBuilder.length_wu": [[88, 95], ["None"], "methods", ["None"], ["", "def", "length_wu", "(", "self", ",", "cur_len", ",", "alpha", "=", "0.", ")", ":", "\n", "        ", "\"\"\"GNMT length re-ranking score.\n\n        See \"Google's Neural Machine Translation System\" :cite:`wu2016google`.\n        \"\"\"", "\n", "\n", "return", "(", "(", "5", "+", "cur_len", ")", "/", "6.0", ")", "**", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.penalties.PenaltyBuilder.length_average": [[96, 99], ["None"], "methods", ["None"], ["", "def", "length_average", "(", "self", ",", "cur_len", ",", "alpha", "=", "0.", ")", ":", "\n", "        ", "\"\"\"Returns the current sequence length.\"\"\"", "\n", "return", "cur_len", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.penalties.PenaltyBuilder.length_none": [[100, 103], ["None"], "methods", ["None"], ["", "def", "length_none", "(", "self", ",", "cur_len", ",", "alpha", "=", "0.", ")", ":", "\n", "        ", "\"\"\"Returns unmodified scores.\"\"\"", "\n", "return", "1.0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.__init__": [[57, 86], ["torch.full", "torch.zeros", "range", "range", "range"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "pad", ",", "bos", ",", "eos", ",", "batch_size", ",", "device", ",", "parallel_paths", ",", "\n", "min_length", ",", "block_ngram_repeat", ",", "exclusion_tokens", ",", "\n", "return_attention", ",", "max_length", ")", ":", "\n", "\n", "# magic indices", "\n", "        ", "self", ".", "pad", "=", "pad", "\n", "self", ".", "bos", "=", "bos", "\n", "self", ".", "eos", "=", "eos", "\n", "\n", "# result caching", "\n", "self", ".", "predictions", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "self", ".", "scores", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "self", ".", "attention", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "self", ".", "alive_seq", "=", "torch", ".", "full", "(", "\n", "[", "batch_size", "*", "parallel_paths", ",", "1", "]", ",", "self", ".", "bos", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "self", ".", "is_finished", "=", "torch", ".", "zeros", "(", "\n", "[", "batch_size", ",", "parallel_paths", "]", ",", "\n", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "device", ")", "\n", "self", ".", "alive_attn", "=", "None", "\n", "\n", "self", ".", "min_length", "=", "min_length", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "block_ngram_repeat", "=", "block_ngram_repeat", "\n", "self", ".", "exclusion_tokens", "=", "exclusion_tokens", "\n", "self", ".", "return_attention", "=", "return_attention", "\n", "\n", "self", ".", "done", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.__len__": [[87, 89], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "alive_seq", ".", "shape", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.ensure_min_length": [[90, 93], ["len"], "methods", ["None"], ["", "def", "ensure_min_length", "(", "self", ",", "log_probs", ")", ":", "\n", "        ", "if", "len", "(", "self", ")", "<=", "self", ".", "min_length", ":", "\n", "            ", "log_probs", "[", ":", ",", "self", ".", "eos", "]", "=", "-", "1e20", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.ensure_max_length": [[94, 99], ["len", "decode_strategy.DecodeStrategy.is_finished.fill_"], "methods", ["None"], ["", "", "def", "ensure_max_length", "(", "self", ")", ":", "\n", "# add one to account for BOS. Don't account for EOS because hitting", "\n", "# this implies it hasn't been found.", "\n", "        ", "if", "len", "(", "self", ")", "==", "self", ".", "max_length", "+", "1", ":", "\n", "            ", "self", ".", "is_finished", ".", "fill_", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.block_ngram_repeats": [[100, 124], ["len", "range", "tuple", "tuple", "hyp[].tolist", "hyp[].tolist", "range", "blocked_tokens.append", "any", "len", "len"], "methods", ["None"], ["", "", "def", "block_ngram_repeats", "(", "self", ",", "log_probs", ")", ":", "\n", "        ", "cur_len", "=", "len", "(", "self", ")", "\n", "block_ngram_size", "=", "self", ".", "block_ngram_repeat", "\n", "if", "block_ngram_size", ">", "0", "and", "cur_len", ">", "block_ngram_size", ":", "\n", "\n", "# Loop over alive generated sentences", "\n", "            ", "num_alive_seqs", "=", "self", ".", "alive_seq", ".", "shape", "[", "0", "]", "\n", "##ngrams = [defaultdict(list) for _ in range(num_alive_seqs)] ", "\n", "for", "idx", "in", "range", "(", "num_alive_seqs", ")", ":", "\n", "                ", "hyp", "=", "self", ".", "alive_seq", "[", "idx", ",", "1", ":", "]", "\n", "\n", "\n", "# Create list of all ngrams", "\n", "ngrams", "=", "[", "tuple", "(", "hyp", "[", "i", ":", "i", "+", "block_ngram_size", "]", ".", "tolist", "(", ")", ")", "for", "i", "in", "range", "(", "cur_len", "-", "1", "-", "block_ngram_size", ")", "]", "\n", "ngrams", "=", "[", "ngram", "for", "ngram", "in", "ngrams", "if", "not", "any", "(", "tok", "in", "ngram", "for", "tok", "in", "self", ".", "exclusion_tokens", ")", "]", "\n", "current_n_minus_1_gram", "=", "tuple", "(", "hyp", "[", "len", "(", "hyp", ")", "-", "block_ngram_size", "+", "1", ":", "len", "(", "hyp", ")", "]", ".", "tolist", "(", ")", ")", "\n", "blocked_tokens", "=", "[", "]", "\n", "for", "ngram", "in", "ngrams", ":", "\n", "                    ", "if", "ngram", "[", ":", "block_ngram_size", "-", "1", "]", "==", "current_n_minus_1_gram", ":", "\n", "                        ", "blocked_tokens", ".", "append", "(", "ngram", "[", "-", "1", "]", ")", "\n", "\n", "# Block the corresponding entries in logprobs", "\n", "", "", "for", "blocked_token", "in", "blocked_tokens", ":", "\n", "                    ", "log_probs", "[", "idx", "]", "[", "blocked_token", "]", "=", "-", "1e10", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance": [[148, 156], ["NotImplementedError"], "methods", ["None"], ["def", "advance", "(", "self", ",", "log_probs", ",", "attn", ")", ":", "\n", "        ", "\"\"\"DecodeStrategy subclasses should override :func:`advance()`.\n\n        Advance is used to update ``self.alive_seq``, ``self.is_finished``,\n        and, when appropriate, ``self.alive_attn``.\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished": [[157, 165], ["NotImplementedError"], "methods", ["None"], ["", "def", "update_finished", "(", "self", ")", ":", "\n", "        ", "\"\"\"DecodeStrategy subclasses should override :func:`update_finished()`.\n\n        ``update_finished`` is used to update ``self.predictions``,\n        ``self.scores``, and other \"output\" attributes.\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator.__init__": [[89, 190], ["frozenset", "print", "len", "onmt.utils.misc.set_random_seed", "onmt.utils.misc.set_random_seed", "onmt.utils.misc.set_random_seed", "onmt.utils.misc.set_random_seed", "torch.device", "torch.device", "ValueError", "ValueError", "dict"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.set_random_seed", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.set_random_seed", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.set_random_seed", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.set_random_seed"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "fields", ",", "\n", "src_reader", ",", "\n", "tgt_reader", ",", "\n", "gpu", "=", "-", "1", ",", "\n", "n_best", "=", "1", ",", "\n", "min_length", "=", "0", ",", "\n", "max_length", "=", "100", ",", "\n", "beam_size", "=", "30", ",", "\n", "random_sampling_topk", "=", "1", ",", "\n", "random_sampling_temp", "=", "1", ",", "\n", "stepwise_penalty", "=", "None", ",", "\n", "dump_beam", "=", "False", ",", "\n", "block_ngram_repeat", "=", "0", ",", "\n", "ignore_when_blocking", "=", "frozenset", "(", ")", ",", "\n", "replace_unk", "=", "False", ",", "\n", "data_type", "=", "\"text\"", ",", "\n", "verbose", "=", "False", ",", "\n", "report_bleu", "=", "False", ",", "\n", "report_rouge", "=", "False", ",", "\n", "report_time", "=", "False", ",", "\n", "copy_attn", "=", "False", ",", "\n", "simple_fusion", "=", "False", ",", "\n", "gpt_tgt", "=", "False", ",", "\n", "global_scorer", "=", "None", ",", "\n", "out_file", "=", "None", ",", "\n", "report_score", "=", "True", ",", "\n", "logger", "=", "None", ",", "\n", "seed", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "fields", "=", "fields", "\n", "tgt_field", "=", "dict", "(", "self", ".", "fields", ")", "[", "\"tgt\"", "]", ".", "base_field", "\n", "self", ".", "_tgt_vocab", "=", "tgt_field", ".", "vocab", "\n", "self", ".", "_tgt_eos_idx", "=", "self", ".", "_tgt_vocab", ".", "stoi", "[", "tgt_field", ".", "eos_token", "]", "\n", "self", ".", "_tgt_pad_idx", "=", "self", ".", "_tgt_vocab", ".", "stoi", "[", "tgt_field", ".", "pad_token", "]", "\n", "self", ".", "_tgt_bos_idx", "=", "self", ".", "_tgt_vocab", ".", "stoi", "[", "tgt_field", ".", "init_token", "]", "\n", "# self._tgt_bos_idx = self._tgt_vocab.stoi['\u0120see']", "\n", "print", "(", "self", ".", "_tgt_bos_idx", ")", "\n", "self", ".", "_tgt_unk_idx", "=", "self", ".", "_tgt_vocab", ".", "stoi", "[", "tgt_field", ".", "unk_token", "]", "\n", "self", ".", "_tgt_vocab_len", "=", "len", "(", "self", ".", "_tgt_vocab", ")", "\n", "\n", "self", ".", "_gpu", "=", "gpu", "\n", "self", ".", "_use_cuda", "=", "gpu", ">", "-", "1", "\n", "self", ".", "_dev", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "self", ".", "_gpu", ")", "if", "self", ".", "_use_cuda", "else", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "self", ".", "n_best", "=", "n_best", "\n", "self", ".", "max_length", "=", "max_length", "\n", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "self", ".", "random_sampling_temp", "=", "random_sampling_temp", "\n", "self", ".", "sample_from_topk", "=", "random_sampling_topk", "\n", "\n", "self", ".", "min_length", "=", "min_length", "\n", "self", ".", "stepwise_penalty", "=", "stepwise_penalty", "\n", "self", ".", "dump_beam", "=", "dump_beam", "\n", "self", ".", "block_ngram_repeat", "=", "block_ngram_repeat", "\n", "self", ".", "ignore_when_blocking", "=", "ignore_when_blocking", "\n", "self", ".", "_exclusion_idxs", "=", "{", "\n", "self", ".", "_tgt_vocab", ".", "stoi", "[", "t", "]", "for", "t", "in", "self", ".", "ignore_when_blocking", "}", "\n", "self", ".", "src_reader", "=", "src_reader", "\n", "self", ".", "tgt_reader", "=", "tgt_reader", "\n", "self", ".", "replace_unk", "=", "replace_unk", "\n", "if", "self", ".", "replace_unk", "and", "not", "self", ".", "model", ".", "decoder", ".", "attentional", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"replace_unk requires an attentional decoder.\"", ")", "\n", "", "self", ".", "data_type", "=", "data_type", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "report_bleu", "=", "report_bleu", "\n", "self", ".", "report_rouge", "=", "report_rouge", "\n", "self", ".", "report_time", "=", "report_time", "\n", "\n", "self", ".", "copy_attn", "=", "copy_attn", "\n", "self", ".", "simple_fusion", "=", "simple_fusion", "\n", "self", ".", "gpt_tgt", "=", "gpt_tgt", "\n", "\n", "self", ".", "global_scorer", "=", "global_scorer", "\n", "if", "self", ".", "global_scorer", ".", "has_cov_pen", "and", "not", "self", ".", "model", ".", "decoder", ".", "attentional", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Coverage penalty requires an attentional decoder.\"", ")", "\n", "", "self", ".", "out_file", "=", "out_file", "\n", "self", ".", "report_score", "=", "report_score", "\n", "self", ".", "logger", "=", "logger", "\n", "\n", "self", ".", "use_filter_pred", "=", "False", "\n", "self", ".", "_filter_pred", "=", "None", "\n", "\n", "# for debugging", "\n", "self", ".", "beam_trace", "=", "self", ".", "dump_beam", "!=", "\"\"", "\n", "self", ".", "beam_accum", "=", "None", "\n", "if", "self", ".", "beam_trace", ":", "\n", "            ", "self", ".", "beam_accum", "=", "{", "\n", "\"predicted_ids\"", ":", "[", "]", ",", "\n", "\"beam_parent_ids\"", ":", "[", "]", ",", "\n", "\"scores\"", ":", "[", "]", ",", "\n", "\"log_probs\"", ":", "[", "]", "}", "\n", "\n", "", "set_random_seed", "(", "seed", ",", "self", ".", "_use_cuda", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator.from_opt": [[191, 254], ["onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "cls", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "set"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt"], ["", "@", "classmethod", "\n", "def", "from_opt", "(", "\n", "cls", ",", "\n", "model", ",", "\n", "fields", ",", "\n", "opt", ",", "\n", "model_opt", ",", "\n", "global_scorer", "=", "None", ",", "\n", "out_file", "=", "None", ",", "\n", "report_score", "=", "True", ",", "\n", "logger", "=", "None", ")", ":", "\n", "        ", "\"\"\"Alternate constructor.\n\n        Args:\n            model (onmt.modules.NMTModel): See :func:`__init__()`.\n            fields (dict[str, torchtext.data.Field]): See\n                :func:`__init__()`.\n            opt (argparse.Namespace): Command line options\n            model_opt (argparse.Namespace): Command line options saved with\n                the model checkpoint.\n            global_scorer (onmt.translate.GNMTGlobalScorer): See\n                :func:`__init__()`..\n            out_file (TextIO or codecs.StreamReaderWriter): See\n                :func:`__init__()`.\n            report_score (bool) : See :func:`__init__()`.\n            logger (logging.Logger or NoneType): See :func:`__init__()`.\n        \"\"\"", "\n", "\n", "if", "opt", ".", "data_type", "==", "'none'", ":", "\n", "            ", "src_reader", "=", "None", "\n", "", "else", ":", "\n", "            ", "src_reader", "=", "inputters", ".", "str2reader", "[", "opt", ".", "data_type", "]", ".", "from_opt", "(", "opt", ")", "\n", "", "tgt_reader", "=", "inputters", ".", "str2reader", "[", "\"text\"", "]", ".", "from_opt", "(", "opt", ")", "\n", "return", "cls", "(", "\n", "model", ",", "\n", "fields", ",", "\n", "src_reader", ",", "\n", "tgt_reader", ",", "\n", "gpu", "=", "opt", ".", "gpu", ",", "\n", "n_best", "=", "opt", ".", "n_best", ",", "\n", "min_length", "=", "opt", ".", "min_length", ",", "\n", "max_length", "=", "opt", ".", "max_length", ",", "\n", "beam_size", "=", "opt", ".", "beam_size", ",", "\n", "random_sampling_topk", "=", "opt", ".", "random_sampling_topk", ",", "\n", "random_sampling_temp", "=", "opt", ".", "random_sampling_temp", ",", "\n", "stepwise_penalty", "=", "opt", ".", "stepwise_penalty", ",", "\n", "dump_beam", "=", "opt", ".", "dump_beam", ",", "\n", "block_ngram_repeat", "=", "opt", ".", "block_ngram_repeat", ",", "\n", "ignore_when_blocking", "=", "set", "(", "opt", ".", "ignore_when_blocking", ")", ",", "\n", "replace_unk", "=", "opt", ".", "replace_unk", ",", "\n", "data_type", "=", "opt", ".", "data_type", ",", "\n", "verbose", "=", "opt", ".", "verbose", ",", "\n", "report_bleu", "=", "opt", ".", "report_bleu", ",", "\n", "report_rouge", "=", "opt", ".", "report_rouge", ",", "\n", "report_time", "=", "opt", ".", "report_time", ",", "\n", "copy_attn", "=", "model_opt", ".", "copy_attn", ",", "\n", "simple_fusion", "=", "model_opt", ".", "simple_fusion", ",", "\n", "gpt_tgt", "=", "model_opt", ".", "GPT_representation_mode", "!=", "'none'", "and", "model_opt", ".", "GPT_representation_loc", "in", "[", "'tgt'", ",", "'both'", "]", ",", "\n", "global_scorer", "=", "global_scorer", ",", "\n", "out_file", "=", "out_file", ",", "\n", "report_score", "=", "report_score", ",", "\n", "logger", "=", "logger", ",", "\n", "seed", "=", "opt", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator._gold_score": [[255, 267], ["pplm_translator.Translator._score_target", "pplm_translator.Translator.model.decoder.init_state", "pplm_translator.Translator.model.lm_decoder.init_state"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translator.Translator._score_target", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.init_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.init_state"], ["", "def", "_gold_score", "(", "self", ",", "batch", ",", "memory_bank", ",", "src_lengths", ",", "src_vocabs", ",", "\n", "use_src_map", ",", "enc_states", ",", "batch_size", ",", "src", ")", ":", "\n", "        ", "if", "\"tgt\"", "in", "batch", ".", "__dict__", ":", "\n", "            ", "gs", "=", "self", ".", "_score_target", "(", "\n", "batch", ",", "memory_bank", ",", "src_lengths", ",", "src_vocabs", ",", "\n", "batch", ".", "src_map", "if", "use_src_map", "else", "None", ")", "\n", "self", ".", "model", ".", "decoder", ".", "init_state", "(", "src", ",", "memory_bank", ",", "enc_states", ")", "\n", "if", "self", ".", "simple_fusion", ":", "\n", "                ", "self", ".", "model", ".", "lm_decoder", ".", "init_state", "(", "src", ",", "None", ",", "None", ")", "\n", "", "", "else", ":", "\n", "            ", "gs", "=", "[", "0", "]", "*", "batch_size", "\n", "", "return", "gs", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator.build_data_iter": [[268, 324], ["pplm_translator.Translator.build_data_iter.read_file"], "methods", ["None"], ["", "def", "build_data_iter", "(", "self", ",", "\n", "opt", ",", "\n", "batch_size", "=", "1", "\n", ")", ":", "\n", "        ", "if", "batch_size", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"batch_size must be set\"", ")", "\n", "\n", "\n", "", "def", "read_file", "(", "path", ")", ":", "\n", "            ", "priv_str", "=", "\"r\"", "\n", "priv_str", "+=", "\"b\"", "\n", "with", "open", "(", "path", ",", "priv_str", ")", "as", "f", ":", "\n", "                ", "return", "f", ".", "readlines", "(", ")", "\n", "", "", "src", "=", "read_file", "(", "opt", ".", "src", ")", "\n", "tgt", "=", "read_file", "(", "opt", ".", "tgt", ")", "if", "opt", ".", "tgt", "is", "not", "None", "else", "None", "\n", "\n", "\n", "readers", ",", "data", ",", "dirs", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "if", "self", ".", "src_reader", ":", "\n", "            ", "readers", "+=", "[", "self", ".", "src_reader", "]", "\n", "data", "+=", "[", "(", "\"src\"", ",", "src", ")", "]", "\n", "dirs", "+=", "[", "None", "]", "\n", "", "if", "tgt", ":", "\n", "            ", "readers", "+=", "[", "self", ".", "tgt_reader", "]", "\n", "data", "+=", "[", "(", "\"tgt\"", ",", "tgt", ")", "]", "\n", "dirs", "+=", "[", "None", "]", "\n", "\n", "", "data", "=", "inputters", ".", "Dataset", "(", "\n", "self", ".", "fields", ",", "\n", "readers", "=", "readers", ",", "\n", "data", "=", "data", ",", "\n", "dirs", "=", "dirs", ",", "\n", "sort_key", "=", "inputters", ".", "str2sortkey", "[", "self", ".", "data_type", "]", ",", "\n", "filter_pred", "=", "self", ".", "_filter_pred", "\n", ")", "\n", "\n", "data_iter", "=", "inputters", ".", "OrderedIterator", "(", "\n", "dataset", "=", "data", ",", "\n", "device", "=", "self", ".", "_dev", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "train", "=", "False", ",", "\n", "sort", "=", "False", ",", "\n", "sort_within_batch", "=", "True", ",", "\n", "shuffle", "=", "False", "\n", ")", "\n", "\n", "self", ".", "src_vocabs", "=", "data", ".", "src_vocabs", "\n", "\n", "self", ".", "_build_xlation", "(", "data", ",", "tgt", ")", "\n", "self", ".", "all_scores", "=", "[", "]", "\n", "self", ".", "all_predictions", "=", "[", "]", "\n", "\n", "self", ".", "pred_score_total", ",", "self", ".", "pred_words_total", "=", "0", ",", "0", "\n", "self", ".", "gold_score_total", ",", "self", ".", "gold_words_total", "=", "0", ",", "0", "\n", "self", ".", "counter", "=", "count", "(", "1", ")", "\n", "return", "data_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator.set_encoder_state": [[326, 358], ["pplm_translator.Translator._run_encoder", "pplm_translator.Translator.model.decoder.init_state", "pplm_translator.Translator.set_random_sampler", "pplm_translator.Translator._build_result", "pplm_translator.Translator.model.lm_decoder.init_state"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator._run_encoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.init_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator.set_random_sampler", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator._build_result", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.init_state"], ["", "def", "set_encoder_state", "(", "self", ",", "\n", "batch", ",", "\n", "tags", "=", "None", ",", "\n", "temperature", "=", "1.0", "\n", ")", ":", "\n", "\n", "        ", "if", "self", ".", "beam_size", "!=", "1", ":", "\n", "            ", "self", ".", "beam_size", "=", "1", "\n", "", "if", "self", ".", "block_ngram_repeat", "!=", "0", ":", "\n", "            ", "self", ".", "block_ngram_repeat", "=", "0", "\n", "\n", "# Encoder forward.", "\n", "", "src", ",", "enc_states", ",", "memory_bank", ",", "src_lengths", "=", "self", ".", "_run_encoder", "(", "batch", ")", "\n", "self", ".", "model", ".", "decoder", ".", "init_state", "(", "src", ",", "memory_bank", ",", "enc_states", ")", "\n", "if", "self", ".", "simple_fusion", ":", "\n", "            ", "self", ".", "model", ".", "lm_decoder", ".", "init_state", "(", "src", ",", "None", ",", "None", ")", "\n", "\n", "", "use_src_map", "=", "self", ".", "copy_attn", "\n", "memory_lengths", "=", "src_lengths", "\n", "src_map", "=", "batch", ".", "src_map", "if", "use_src_map", "else", "None", "\n", "\n", "# set for the decoder usage", "\n", "self", ".", "enc_states", "=", "enc_states", "\n", "self", ".", "src", "=", "src", "\n", "self", ".", "src_lengths", "=", "src_lengths", "\n", "self", ".", "memory_bank", "=", "memory_bank", "\n", "self", ".", "memory_lengths", "=", "memory_lengths", "\n", "self", ".", "src_map", "=", "src_map", "\n", "self", ".", "batch", "=", "batch", "\n", "self", ".", "batch_size", "=", "batch", ".", "batch_size", "\n", "self", ".", "set_random_sampler", "(", "temperature", "=", "temperature", ")", "\n", "self", ".", "_build_result", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator.forward_pass": [[360, 428], ["decoder", "decoder_in.masked_fill.masked_fill.masked_fill", "pplm_translator.Translator.model.generator", "scores.view.view.view", "onmt.modules.copy_generator.collapse_copy_scores", "onmt.modules.copy_generator.collapse_copy_scores", "onmt.modules.copy_generator.collapse_copy_scores", "onmt.modules.copy_generator.collapse_copy_scores", "scores.view.view.view", "scores.view.view.squeeze", "decoder_in.masked_fill.masked_fill.gt", "pplm_translator.Translator.model.lm_decoder", "pplm_translator.Translator.model.generator", "pplm_translator.Translator.model.generator", "dec_out.view", "attn.view", "scores.view.view.size", "decoder_in.masked_fill.masked_fill.size", "scores.view.view.size", "memory_bank.new_zeros", "dec_out.squeeze", "lm_dec_out.squeeze", "dec_out.squeeze", "dec_out.size", "attn.size"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.collapse_copy_scores", "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.collapse_copy_scores", "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.collapse_copy_scores", "home.repos.pwc.inspect_result.bigheiniu_FactGen.modules.copy_generator.collapse_copy_scores", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "forward_pass", "(", "\n", "self", ",", "\n", "decoder_in", ",", "\n", "step", ",", "\n", "past", "=", "None", ",", "\n", "input_embeds", "=", "None", ",", "\n", "tags", "=", "None", ",", "\n", "use_copy", "=", "True", "\n", "\n", ")", ":", "\n", "        ", "memory_bank", "=", "self", ".", "memory_bank", "\n", "src_vocabs", "=", "self", ".", "src_vocabs", "\n", "memory_lengths", "=", "self", ".", "memory_lengths", "\n", "src_map", "=", "self", ".", "src_map", "\n", "batch", "=", "self", ".", "batch", "\n", "if", "self", ".", "copy_attn", ":", "\n", "# Turn any copied words into UNKs.", "\n", "            ", "decoder_in", "=", "decoder_in", ".", "masked_fill", "(", "\n", "decoder_in", ".", "gt", "(", "self", ".", "_tgt_vocab_len", "-", "1", ")", ",", "self", ".", "_tgt_unk_idx", "\n", ")", "\n", "\n", "", "decoder", "=", "self", ".", "model", ".", "decoder", "\n", "\n", "\n", "dec_out", ",", "all_hidden_states", ",", "past", ",", "dec_attn", "=", "decoder", "(", "\n", "decoder_in", ",", "memory_bank", ",", "memory_lengths", "=", "memory_lengths", ",", "step", "=", "step", ",", "past", "=", "past", ",", "input_embeds", "=", "input_embeds", ",", "pplm_return", "=", "True", "\n", ")", "\n", "\n", "# Generator forward.", "\n", "if", "not", "self", ".", "copy_attn", ":", "\n", "            ", "if", "\"std\"", "in", "dec_attn", ":", "\n", "                ", "attn", "=", "dec_attn", "[", "\"std\"", "]", "\n", "", "else", ":", "\n", "                ", "attn", "=", "None", "\n", "\n", "", "if", "self", ".", "simple_fusion", ":", "\n", "                ", "lm_dec_out", ",", "_", "=", "self", ".", "model", ".", "lm_decoder", "(", "decoder_in", ",", "memory_bank", ".", "new_zeros", "(", "1", ",", "1", ",", "1", ")", ",", "step", "=", "step", ")", "\n", "probs", "=", "self", ".", "model", ".", "generator", "(", "dec_out", ".", "squeeze", "(", "0", ")", ",", "lm_dec_out", ".", "squeeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "probs", "=", "self", ".", "model", ".", "generator", "(", "dec_out", ".", "squeeze", "(", "0", ")", ")", "\n", "# print(log_probs)", "\n", "# returns [(batch_size x beam_size) , vocab ] when 1 step", "\n", "# or [ tgt_len, batch_size, vocab ] when full sentence", "\n", "", "", "else", ":", "\n", "            ", "attn", "=", "dec_attn", "[", "\"copy\"", "]", "\n", "\n", "scores", ",", "p_copy", "=", "self", ".", "model", ".", "generator", "(", "dec_out", ".", "view", "(", "-", "1", ",", "dec_out", ".", "size", "(", "2", ")", ")", ",", "\n", "attn", ".", "view", "(", "-", "1", ",", "attn", ".", "size", "(", "2", ")", ")", ",", "\n", "src_map", ",", "tags", "=", "tags", ")", "\n", "\n", "\n", "scores", "=", "scores", ".", "view", "(", "batch", ".", "batch_size", ",", "-", "1", ",", "scores", ".", "size", "(", "-", "1", ")", ")", "\n", "scores", "=", "collapse_copy_scores", "(", "\n", "scores", ",", "\n", "batch", ",", "\n", "self", ".", "_tgt_vocab", ",", "\n", "src_vocabs", ",", "\n", "batch_dim", "=", "0", ",", "\n", "batch_offset", "=", "None", "\n", ")", "\n", "scores", "=", "scores", ".", "view", "(", "decoder_in", ".", "size", "(", "0", ")", ",", "-", "1", ",", "scores", ".", "size", "(", "-", "1", ")", ")", "\n", "# log_probs = scores.squeeze(0).log()", "\n", "probs", "=", "scores", ".", "squeeze", "(", "0", ")", "\n", "if", "use_copy", "is", "False", ":", "\n", "                ", "probs", "=", "probs", "[", ":", ",", ":", "50257", "]", "\n", "return", "probs", ",", "attn", ",", "all_hidden_states", ",", "past", "\n", "", "return", "probs", ",", "attn", ",", "all_hidden_states", ",", "past", ",", "p_copy", "\n", "", "return", "probs", ",", "attn", ",", "all_hidden_states", ",", "past", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator.set_random_sampler": [[429, 450], ["onmt.translate.random_sampling.RandomSampling", "onmt.translate.random_sampling.RandomSampling", "onmt.translate.random_sampling.RandomSampling", "onmt.translate.random_sampling.RandomSampling", "isinstance", "isinstance", "isinstance", "list", "pplm_translator.Translator.memory_bank[].keys"], "methods", ["None"], ["", "def", "set_random_sampler", "(", "self", ",", "\n", "return_attention", "=", "False", ",", "\n", "temperature", "=", "1.0", "\n", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "memory_bank", ",", "tuple", ")", "or", "isinstance", "(", "self", ".", "memory_bank", ",", "list", ")", ":", "\n", "            ", "if", "isinstance", "(", "self", ".", "memory_bank", "[", "0", "]", ",", "dict", ")", ":", "\n", "                ", "mb_device", "=", "self", ".", "memory_bank", "[", "0", "]", "[", "list", "(", "self", ".", "memory_bank", "[", "0", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "device", "\n", "", "else", ":", "\n", "                ", "mb_device", "=", "self", ".", "memory_bank", "[", "0", "]", ".", "device", "\n", "", "", "else", ":", "\n", "            ", "mb_device", "=", "self", ".", "memory_bank", ".", "device", "\n", "\n", "", "if", "self", ".", "max_length", "<", "400", ":", "\n", "            ", "self", ".", "max_length", "=", "400", "\n", "", "if", "self", ".", "min_length", "<", "300", ":", "\n", "            ", "self", ".", "min_length", "=", "300", "\n", "", "self", ".", "random_sampler", "=", "RandomSampling", "(", "\n", "self", ".", "_tgt_pad_idx", ",", "self", ".", "_tgt_bos_idx", ",", "self", ".", "_tgt_eos_idx", ",", "\n", "self", ".", "batch_size", ",", "mb_device", ",", "self", ".", "min_length", ",", "self", ".", "block_ngram_repeat", ",", "\n", "self", ".", "_exclusion_idxs", ",", "return_attention", ",", "self", ".", "max_length", ",", "\n", "temperature", ",", "self", ".", "sample_from_topk", ",", "self", ".", "memory_lengths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator.generate_tokens": [[451, 465], ["pplm_translator.Translator.random_sampler.advance", "pplm_translator.Translator.random_sampler.is_finished.any", "pplm_translator.Translator.random_sampler.update_finished", "pplm_translator.Translator.random_sampler.alive_seq[].view", "pplm_translator.Translator._finalize_result", "pplm_translator.Translator.generate_sentence_batch"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator._finalize_result", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator.generate_sentence_batch"], ["", "def", "generate_tokens", "(", "self", ",", "log_probs", ",", "attn", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "random_sampler", ".", "advance", "(", "log_probs", ",", "attn", ")", "\n", "any_batch_is_finished", "=", "self", ".", "random_sampler", ".", "is_finished", ".", "any", "(", ")", "\n", "# ATTENTION: The batch size is one", "\n", "if", "any_batch_is_finished", ":", "\n", "            ", "self", ".", "random_sampler", ".", "update_finished", "(", ")", "\n", "if", "self", ".", "random_sampler", ".", "done", ":", "\n", "# Finish the generation, set the resulf for generation", "\n", "                ", "self", ".", "_finalize_result", "(", ")", "\n", "self", ".", "generate_sentence_batch", "(", ")", "\n", "return", "False", "\n", "", "", "else", ":", "\n", "            ", "return", "self", ".", "random_sampler", ".", "alive_seq", "[", ":", ",", "-", "1", "]", ".", "view", "(", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator.generate_sentence_batch": [[466, 487], ["pplm_translator.Translator.xlation_builder.from_batch", "len", "pplm_translator.Translator.out_file.write", "pplm_translator.Translator.out_file.flush", "next", "trans.log", "pplm_translator.Translator.logger.info", "os.write", "trans.log.encode"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.TranslationBuilder.from_batch", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation.Translation.log", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write"], ["", "", "def", "generate_sentence_batch", "(", "self", ")", ":", "\n", "        ", "batch", "=", "self", ".", "results", "\n", "translations", "=", "self", ".", "xlation_builder", ".", "from_batch", "(", "batch", ")", "\n", "for", "trans", "in", "translations", ":", "\n", "            ", "self", ".", "all_scores", "+=", "[", "trans", ".", "pred_scores", "[", ":", "self", ".", "n_best", "]", "]", "\n", "self", ".", "pred_score_total", "+=", "trans", ".", "pred_scores", "[", "0", "]", "\n", "self", ".", "pred_words_total", "+=", "len", "(", "trans", ".", "pred_sents", "[", "0", "]", ")", "\n", "\n", "n_best_preds", "=", "[", "\" \"", ".", "join", "(", "pred", ")", "\n", "for", "pred", "in", "trans", ".", "pred_sents", "[", ":", "self", ".", "n_best", "]", "]", "\n", "self", ".", "all_predictions", "+=", "[", "n_best_preds", "]", "\n", "self", ".", "out_file", ".", "write", "(", "'\\n'", ".", "join", "(", "n_best_preds", ")", "+", "'\\n'", ")", "\n", "self", ".", "out_file", ".", "flush", "(", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "sent_number", "=", "next", "(", "self", ".", "counter", ")", "\n", "output", "=", "trans", ".", "log", "(", "sent_number", ")", "\n", "if", "self", ".", "logger", ":", "\n", "                    ", "self", ".", "logger", ".", "info", "(", "output", ")", "\n", "", "else", ":", "\n", "                    ", "os", ".", "write", "(", "1", ",", "output", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator._build_result": [[490, 500], ["pplm_translator.Translator._gold_score"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator._gold_score"], ["", "", "", "", "def", "_build_result", "(", "self", ")", ":", "\n", "        ", "use_src_map", "=", "self", ".", "copy_attn", "\n", "self", ".", "results", "=", "{", "\n", "\"predictions\"", ":", "None", ",", "\n", "\"scores\"", ":", "None", ",", "\n", "\"attention\"", ":", "None", ",", "\n", "\"batch\"", ":", "self", ".", "batch", ",", "\n", "\"gold_score\"", ":", "self", ".", "_gold_score", "(", "\n", "self", ".", "batch", ",", "self", ".", "memory_bank", ",", "self", ".", "src_lengths", ",", "self", ".", "src_vocabs", ",", "use_src_map", ",", "\n", "self", ".", "enc_states", ",", "self", ".", "batch_size", ",", "self", ".", "src", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator._build_xlation": [[501, 504], ["onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder"], "methods", ["None"], ["", "def", "_build_xlation", "(", "self", ",", "data", ",", "tgt", ")", ":", "\n", "        ", "self", ".", "xlation_builder", "=", "onmt", ".", "translate", ".", "TranslationBuilder", "(", "\n", "data", ",", "self", ".", "fields", ",", "self", ".", "n_best", ",", "self", ".", "replace_unk", ",", "tgt", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator._finalize_result": [[507, 511], ["None"], "methods", ["None"], ["", "def", "_finalize_result", "(", "self", ")", ":", "\n", "        ", "self", ".", "results", "[", "\"scores\"", "]", "=", "self", ".", "random_sampler", ".", "scores", "\n", "self", ".", "results", "[", "\"predictions\"", "]", "=", "self", ".", "random_sampler", ".", "predictions", "\n", "self", ".", "results", "[", "\"attention\"", "]", "=", "self", ".", "random_sampler", ".", "attention", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator._run_encoder": [[512, 533], ["hasattr", "pplm_translator.Translator.model.encoder", "torch.zeros", "torch.ones", "isinstance", "torch.Tensor().type_as().long().fill_", "isinstance", "torch.zeros.size", "torch.Tensor().type_as().long", "torch.Tensor().type_as", "torch.Tensor"], "methods", ["None"], ["", "def", "_run_encoder", "(", "self", ",", "batch", ")", ":", "\n", "        ", "if", "hasattr", "(", "batch", ",", "'src'", ")", ":", "\n", "            ", "src", ",", "src_lengths", "=", "batch", ".", "src", "if", "isinstance", "(", "batch", ".", "src", ",", "tuple", ")", "else", "(", "batch", ".", "src", ",", "None", ")", "\n", "\n", "enc_states", ",", "memory_bank", ",", "src_lengths", "=", "self", ".", "model", ".", "encoder", "(", "\n", "src", ",", "src_lengths", ")", "\n", "if", "src_lengths", "is", "None", ":", "\n", "                ", "assert", "not", "isinstance", "(", "memory_bank", ",", "tuple", ")", ",", "'Ensemble decoding only supported for text data'", "\n", "src_lengths", "=", "torch", ".", "Tensor", "(", "batch", ".", "batch_size", ")", ".", "type_as", "(", "memory_bank", ")", ".", "long", "(", ")", ".", "fill_", "(", "memory_bank", ".", "size", "(", "0", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "src", "=", "None", "\n", "enc_states", "=", "None", "\n", "memory_bank", "=", "torch", ".", "zeros", "(", "(", "1", ",", "batch", ".", "tgt", "[", "0", "]", ".", "shape", "[", "1", "]", ",", "1", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "batch", ".", "tgt", "[", "0", "]", ".", "device", ")", "\n", "src_lengths", "=", "torch", ".", "ones", "(", "(", "batch", ".", "tgt", "[", "0", "]", ".", "shape", "[", "1", "]", ",", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "batch", ".", "tgt", "[", "0", "]", ".", "device", ")", "\n", "# src_lengths = None", "\n", "", "return", "src", ",", "enc_states", ",", "memory_bank", ",", "src_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.Translator.freeze_parameter": [[534, 541], ["pplm_translator.Translator.model.encoder.parameters", "pplm_translator.Translator.model.decoder.parameters", "pplm_translator.Translator.model.generator.parameters"], "methods", ["None"], ["", "def", "freeze_parameter", "(", "self", ")", ":", "\n", "        ", "for", "parameter", "in", "self", ".", "model", ".", "encoder", ".", "parameters", "(", ")", ":", "\n", "            ", "parameter", ".", "requires_grad", "=", "False", "\n", "", "for", "parameter", "in", "self", ".", "model", ".", "decoder", ".", "parameters", "(", ")", ":", "\n", "            ", "parameter", ".", "requires_grad", "=", "False", "\n", "", "for", "parameter", "in", "self", ".", "model", ".", "generator", ".", "parameters", "(", ")", ":", "\n", "            ", "parameter", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.pplm_translator.build_translator": [[24, 46], ["load_test_model", "onmt.translate.GNMTGlobalScorer.from_opt", "onmt.translate.GNMTGlobalScorer.from_opt", "onmt.translate.GNMTGlobalScorer.from_opt", "onmt.translate.GNMTGlobalScorer.from_opt", "pplm_translator.Translator.from_opt", "codecs.open", "len"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.load_test_model", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt"], ["def", "build_translator", "(", "opt", ",", "report_score", "=", "False", ",", "logger", "=", "None", ",", "out_file", "=", "None", ")", ":", "\n", "    ", "if", "out_file", "is", "None", ":", "\n", "        ", "out_file", "=", "codecs", ".", "open", "(", "opt", ".", "output", ",", "'w+'", ",", "'utf-8'", ")", "\n", "# out_file = codecs.open(\"./result.output\", 'w+', 'utf-8')", "\n", "\n", "", "load_test_model", "=", "onmt", ".", "decoders", ".", "ensemble", ".", "load_test_model", "if", "len", "(", "opt", ".", "models", ")", ">", "1", "else", "onmt", ".", "model_builder", ".", "load_test_model", "\n", "fields", ",", "model", ",", "model_opt", "=", "load_test_model", "(", "opt", ")", "\n", "\n", "scorer", "=", "onmt", ".", "translate", ".", "GNMTGlobalScorer", ".", "from_opt", "(", "opt", ")", "\n", "\n", "translator", "=", "Translator", ".", "from_opt", "(", "\n", "model", ",", "\n", "fields", ",", "\n", "opt", ",", "\n", "model_opt", ",", "\n", "global_scorer", "=", "scorer", ",", "\n", "out_file", "=", "out_file", ",", "\n", "report_score", "=", "report_score", ",", "\n", "logger", "=", "logger", "\n", ")", "\n", "return", "translator", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.stacked_rnn.StackedLSTM.__init__": [[12, 21], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "range", "stacked_rnn.StackedLSTM.layers.append", "torch.LSTMCell", "torch.LSTMCell"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "rnn_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "StackedLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "_", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "LSTMCell", "(", "input_size", ",", "rnn_size", ")", ")", "\n", "input_size", "=", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.stacked_rnn.StackedLSTM.forward": [[22, 37], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer", "stacked_rnn.StackedLSTM.dropout"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_feed", ",", "hidden", ")", ":", "\n", "        ", "h_0", ",", "c_0", "=", "hidden", "\n", "h_1", ",", "c_1", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "h_1_i", ",", "c_1_i", "=", "layer", "(", "input_feed", ",", "(", "h_0", "[", "i", "]", ",", "c_0", "[", "i", "]", ")", ")", "\n", "input_feed", "=", "h_1_i", "\n", "if", "i", "+", "1", "!=", "self", ".", "num_layers", ":", "\n", "                ", "input_feed", "=", "self", ".", "dropout", "(", "input_feed", ")", "\n", "", "h_1", "+=", "[", "h_1_i", "]", "\n", "c_1", "+=", "[", "c_1_i", "]", "\n", "\n", "", "h_1", "=", "torch", ".", "stack", "(", "h_1", ")", "\n", "c_1", "=", "torch", ".", "stack", "(", "c_1", ")", "\n", "\n", "return", "input_feed", ",", "(", "h_1", ",", "c_1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.stacked_rnn.StackedGRU.__init__": [[45, 54], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "range", "stacked_rnn.StackedGRU.layers.append", "torch.GRUCell", "torch.GRUCell"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "rnn_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "StackedGRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "_", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "GRUCell", "(", "input_size", ",", "rnn_size", ")", ")", "\n", "input_size", "=", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.stacked_rnn.StackedGRU.forward": [[55, 66], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer", "stacked_rnn.StackedGRU.dropout"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_feed", ",", "hidden", ")", ":", "\n", "        ", "h_1", "=", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "h_1_i", "=", "layer", "(", "input_feed", ",", "hidden", "[", "0", "]", "[", "i", "]", ")", "\n", "input_feed", "=", "h_1_i", "\n", "if", "i", "+", "1", "!=", "self", ".", "num_layers", ":", "\n", "                ", "input_feed", "=", "self", ".", "dropout", "(", "input_feed", ")", "\n", "", "h_1", "+=", "[", "h_1_i", "]", "\n", "\n", "", "h_1", "=", "torch", ".", "stack", "(", "h_1", ")", "\n", "return", "input_feed", ",", "(", "h_1", ",", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.uncond_model.UncondModel.__init__": [[15, 18], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "decoder", ")", ":", "\n", "        ", "super", "(", "UncondModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "decoder", "=", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.uncond_model.UncondModel.forward": [[19, 48], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "uncond_model.UncondModel.decoder", "uncond_model.UncondModel.decoder.init_state"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.init_state"], ["", "def", "forward", "(", "self", ",", "src", ",", "tgt", ",", "lengths", ",", "bptt", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Forward propagate a `src` and `tgt` pair for training.\n        Possible initialized with a beginning decoder state.\n\n        Args:\n            src (Tensor): A source sequence passed to encoder.\n                typically for inputs this will be a padded `LongTensor`\n                of size ``(len, batch, features)``. However, may be an\n                image or other generic input depending on encoder.\n            tgt (LongTensor): A target sequence of size ``(tgt_len, batch)``.\n            lengths(LongTensor): The src lengths, pre-padding ``(batch,)``.\n            bptt (Boolean): A flag indicating if truncated bptt is set.\n                If reset then init_state\n\n        Returns:\n            (FloatTensor, dict[str, FloatTensor]):\n\n            * decoder output ``(tgt_len, batch, hidden)``\n            * dictionary attention dists of ``(tgt_len, batch, src_len)``\n        \"\"\"", "\n", "tgt", "=", "tgt", "[", ":", "-", "1", "]", "# exclude last target from inputs", "\n", "\n", "memory_bank", "=", "torch", ".", "zeros", "(", "(", "1", ",", "tgt", ".", "shape", "[", "1", "]", ",", "1", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "tgt", ".", "device", ")", "\n", "\n", "if", "bptt", "is", "False", ":", "\n", "            ", "self", ".", "decoder", ".", "init_state", "(", "src", ",", "memory_bank", ",", "None", ")", "\n", "", "dec_out", ",", "attns", "=", "self", ".", "decoder", "(", "tgt", ",", "memory_bank", ",", "\n", "memory_lengths", "=", "lengths", ",", "**", "kwargs", ")", "\n", "return", "dec_out", ",", "attns", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.simple_fusion_model.SimpleFusionModel.__init__": [[15, 20], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ",", "lm_decoder", ")", ":", "\n", "        ", "super", "(", "SimpleFusionModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "lm_decoder", "=", "lm_decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.simple_fusion_model.SimpleFusionModel.forward": [[21, 53], ["simple_fusion_model.SimpleFusionModel.encoder", "simple_fusion_model.SimpleFusionModel.decoder", "simple_fusion_model.SimpleFusionModel.lm_decoder", "simple_fusion_model.SimpleFusionModel.decoder.init_state", "simple_fusion_model.SimpleFusionModel.lm_decoder.init_state", "memory_bank.new_zeros"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.init_state", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.init_state"], ["", "def", "forward", "(", "self", ",", "src", ",", "tgt", ",", "lengths", ",", "bptt", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Forward propagate a `src` and `tgt` pair for training.\n        Possible initialized with a beginning decoder state.\n\n        Args:\n            src (Tensor): A source sequence passed to encoder.\n                typically for inputs this will be a padded `LongTensor`\n                of size ``(len, batch, features)``. However, may be an\n                image or other generic input depending on encoder.\n            tgt (LongTensor): A target sequence of size ``(tgt_len, batch)``.\n            lengths(LongTensor): The src lengths, pre-padding ``(batch,)``.\n            bptt (Boolean): A flag indicating if truncated bptt is set.\n                If reset then init_state\n\n        Returns:\n            (FloatTensor, dict[str, FloatTensor]):\n\n            * decoder output ``(tgt_len, batch, hidden)``\n            * dictionary attention dists of ``(tgt_len, batch, src_len)``\n        \"\"\"", "\n", "tgt", "=", "tgt", "[", ":", "-", "1", "]", "# exclude last target from inputs", "\n", "\n", "enc_state", ",", "memory_bank", ",", "lengths", "=", "self", ".", "encoder", "(", "src", ",", "lengths", ")", "\n", "if", "bptt", "is", "False", ":", "\n", "            ", "self", ".", "decoder", ".", "init_state", "(", "src", ",", "memory_bank", ",", "enc_state", ")", "\n", "", "dec_out", ",", "attns", "=", "self", ".", "decoder", "(", "tgt", ",", "memory_bank", ",", "\n", "memory_lengths", "=", "lengths", ",", "**", "kwargs", ")", "\n", "\n", "if", "bptt", "is", "False", ":", "\n", "            ", "self", ".", "lm_decoder", ".", "init_state", "(", "src", ",", "None", ",", "None", ")", "\n", "", "lm_dec_out", ",", "_", "=", "self", ".", "lm_decoder", "(", "tgt", ",", "memory_bank", ".", "new_zeros", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "return", "[", "dec_out", ",", "lm_dec_out", "]", ",", "attns", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model.NMTModel.__init__": [[15, 19], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", "NMTModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model.NMTModel.forward": [[20, 48], ["model.NMTModel.encoder", "model.NMTModel.decoder", "model.NMTModel.decoder.init_state"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.init_state"], ["", "def", "forward", "(", "self", ",", "src", ",", "tgt", ",", "lengths", ",", "bptt", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Forward propagate a `src` and `tgt` pair for training.\n        Possible initialized with a beginning decoder state.\n\n        Args:\n            src (Tensor): A source sequence passed to encoder.\n                typically for inputs this will be a padded `LongTensor`\n                of size ``(len, batch, features)``. However, may be an\n                image or other generic input depending on encoder.\n            tgt (LongTensor): A target sequence of size ``(tgt_len, batch)``.\n            lengths(LongTensor): The src lengths, pre-padding ``(batch,)``.\n            bptt (Boolean): A flag indicating if truncated bptt is set.\n                If reset then init_state\n\n        Returns:\n            (FloatTensor, dict[str, FloatTensor]):\n\n            * decoder output ``(tgt_len, batch, hidden)``\n            * dictionary attention dists of ``(tgt_len, batch, src_len)``\n        \"\"\"", "\n", "tgt", "=", "tgt", "[", ":", "-", "1", "]", "# exclude last target from inputs", "\n", "\n", "enc_state", ",", "memory_bank", ",", "lengths", "=", "self", ".", "encoder", "(", "src", ",", "lengths", ")", "\n", "if", "bptt", "is", "False", ":", "\n", "            ", "self", ".", "decoder", ".", "init_state", "(", "src", ",", "memory_bank", ",", "enc_state", ")", "\n", "", "dec_out", ",", "attns", "=", "self", ".", "decoder", "(", "tgt", ",", "memory_bank", ",", "\n", "memory_lengths", "=", "lengths", ",", "**", "kwargs", ")", "\n", "return", "dec_out", ",", "attns", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.CheckSRU.__init__": [[17, 19], ["configargparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "CheckSRU", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.CheckSRU.__call__": [[20, 25], ["setattr", "sru.check_sru_requirement"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.check_sru_requirement"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "if", "values", "==", "'SRU'", ":", "\n", "            ", "check_sru_requirement", "(", "abort", "=", "True", ")", "\n", "# Check pass, set the args.", "\n", "", "setattr", "(", "namespace", ",", "self", ".", "dest", ",", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU_Compute.__init__": [[381, 387], ["SRU_Compute.maybe_load_sru_mod", "torch.autograd.Function.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU_Compute.maybe_load_sru_mod", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "activation_type", ",", "d_out", ",", "bidirectional", "=", "False", ")", ":", "\n", "        ", "SRU_Compute", ".", "maybe_load_sru_mod", "(", ")", "\n", "super", "(", "SRU_Compute", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "activation_type", "=", "activation_type", "\n", "self", ".", "d_out", "=", "d_out", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU_Compute.maybe_load_sru_mod": [[388, 394], ["sru.load_sru_mod"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.load_sru_mod"], ["", "@", "staticmethod", "\n", "def", "maybe_load_sru_mod", "(", ")", ":", "\n", "        ", "global", "SRU_FWD_FUNC", "\n", "\n", "if", "SRU_FWD_FUNC", "is", "None", ":", "\n", "            ", "load_sru_mod", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU_Compute.forward": [[395, 439], ["x.size", "min", "x.new", "x.new", "FUNC", "sru.SRU_Compute.save_for_backward", "x.size", "u.size", "x.new().zero_", "x.dim", "x.dim", "x.dim", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "x.new", "u.contiguous().data_ptr", "bias.data_ptr", "init_.contiguous().data_ptr", "x.new.data_ptr", "x.new.data_ptr", "x.contiguous().data_ptr", "mask_h.data_ptr", "u.contiguous", "init_.contiguous", "x.contiguous"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "u", ",", "x", ",", "bias", ",", "init", "=", "None", ",", "mask_h", "=", "None", ")", ":", "\n", "        ", "bidir", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "length", "=", "x", ".", "size", "(", "0", ")", "if", "x", ".", "dim", "(", ")", "==", "3", "else", "1", "\n", "batch", "=", "x", ".", "size", "(", "-", "2", ")", "\n", "d", "=", "self", ".", "d_out", "\n", "k", "=", "u", ".", "size", "(", "-", "1", ")", "//", "d", "\n", "k_", "=", "k", "//", "2", "if", "self", ".", "bidirectional", "else", "k", "\n", "ncols", "=", "batch", "*", "d", "*", "bidir", "\n", "thread_per_block", "=", "min", "(", "512", ",", "ncols", ")", "\n", "num_block", "=", "(", "ncols", "-", "1", ")", "//", "thread_per_block", "+", "1", "\n", "\n", "init_", "=", "x", ".", "new", "(", "ncols", ")", ".", "zero_", "(", ")", "if", "init", "is", "None", "else", "init", "\n", "size", "=", "(", "length", ",", "batch", ",", "d", "*", "bidir", ")", "if", "x", ".", "dim", "(", ")", "==", "3", "else", "(", "batch", ",", "d", "*", "bidir", ")", "\n", "c", "=", "x", ".", "new", "(", "*", "size", ")", "\n", "h", "=", "x", ".", "new", "(", "*", "size", ")", "\n", "\n", "FUNC", "=", "SRU_FWD_FUNC", "if", "not", "self", ".", "bidirectional", "else", "SRU_BiFWD_FUNC", "\n", "FUNC", "(", "args", "=", "[", "\n", "u", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "x", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", "if", "k_", "==", "3", "else", "0", ",", "\n", "bias", ".", "data_ptr", "(", ")", ",", "\n", "init_", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "mask_h", ".", "data_ptr", "(", ")", "if", "mask_h", "is", "not", "None", "else", "0", ",", "\n", "length", ",", "\n", "batch", ",", "\n", "d", ",", "\n", "k_", ",", "\n", "h", ".", "data_ptr", "(", ")", ",", "\n", "c", ".", "data_ptr", "(", ")", ",", "\n", "self", ".", "activation_type", "]", ",", "\n", "block", "=", "(", "thread_per_block", ",", "1", ",", "1", ")", ",", "grid", "=", "(", "num_block", ",", "1", ",", "1", ")", ",", "\n", "stream", "=", "SRU_STREAM", "\n", ")", "\n", "\n", "self", ".", "save_for_backward", "(", "u", ",", "x", ",", "bias", ",", "init", ",", "mask_h", ")", "\n", "self", ".", "intermediate", "=", "c", "\n", "if", "x", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "last_hidden", "=", "c", "\n", "", "elif", "self", ".", "bidirectional", ":", "\n", "# -> directions x batch x dim", "\n", "            ", "last_hidden", "=", "torch", ".", "stack", "(", "(", "c", "[", "-", "1", ",", ":", ",", ":", "d", "]", ",", "c", "[", "0", ",", ":", ",", "d", ":", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "last_hidden", "=", "c", "[", "-", "1", "]", "\n", "", "return", "h", ",", "last_hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU_Compute.backward": [[440, 491], ["x.size", "min", "u.new", "x.new", "x.new", "FUNC", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x.size", "u.size", "x.new().zero_", "x.new", "x.new.sum().view", "x.dim", "u.size", "x.new", "x.size", "u.contiguous().data_ptr", "bias.data_ptr", "init_.contiguous().data_ptr", "c.data_ptr", "grad_h.contiguous().data_ptr", "torch.cat.contiguous().data_ptr", "torch.cat.contiguous().data_ptr", "u.new.data_ptr", "x.new.data_ptr", "x.new.data_ptr", "x.new.sum", "x.contiguous().data_ptr", "mask_h.data_ptr", "grad_x.data_ptr", "u.contiguous", "init_.contiguous", "grad_h.contiguous", "torch.cat.contiguous", "torch.cat.contiguous", "x.contiguous"], "methods", ["None"], ["", "def", "backward", "(", "self", ",", "grad_h", ",", "grad_last", ")", ":", "\n", "        ", "if", "self", ".", "bidirectional", ":", "\n", "            ", "grad_last", "=", "torch", ".", "cat", "(", "(", "grad_last", "[", "0", "]", ",", "grad_last", "[", "1", "]", ")", ",", "1", ")", "\n", "", "bidir", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "u", ",", "x", ",", "bias", ",", "init", ",", "mask_h", "=", "self", ".", "saved_tensors", "\n", "c", "=", "self", ".", "intermediate", "\n", "length", "=", "x", ".", "size", "(", "0", ")", "if", "x", ".", "dim", "(", ")", "==", "3", "else", "1", "\n", "batch", "=", "x", ".", "size", "(", "-", "2", ")", "\n", "d", "=", "self", ".", "d_out", "\n", "k", "=", "u", ".", "size", "(", "-", "1", ")", "//", "d", "\n", "k_", "=", "k", "//", "2", "if", "self", ".", "bidirectional", "else", "k", "\n", "ncols", "=", "batch", "*", "d", "*", "bidir", "\n", "thread_per_block", "=", "min", "(", "512", ",", "ncols", ")", "\n", "num_block", "=", "(", "ncols", "-", "1", ")", "//", "thread_per_block", "+", "1", "\n", "\n", "init_", "=", "x", ".", "new", "(", "ncols", ")", ".", "zero_", "(", ")", "if", "init", "is", "None", "else", "init", "\n", "grad_u", "=", "u", ".", "new", "(", "*", "u", ".", "size", "(", ")", ")", "\n", "grad_bias", "=", "x", ".", "new", "(", "2", ",", "batch", ",", "d", "*", "bidir", ")", "\n", "grad_init", "=", "x", ".", "new", "(", "batch", ",", "d", "*", "bidir", ")", "\n", "\n", "# For DEBUG", "\n", "# size = (length, batch, x.size(-1)) \\", "\n", "#         if x.dim() == 3 else (batch, x.size(-1))", "\n", "# grad_x = x.new(*x.size()) if k_ == 3 else x.new(*size).zero_()", "\n", "\n", "# Normal use", "\n", "grad_x", "=", "x", ".", "new", "(", "*", "x", ".", "size", "(", ")", ")", "if", "k_", "==", "3", "else", "None", "\n", "\n", "FUNC", "=", "SRU_BWD_FUNC", "if", "not", "self", ".", "bidirectional", "else", "SRU_BiBWD_FUNC", "\n", "FUNC", "(", "args", "=", "[", "\n", "u", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "x", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", "if", "k_", "==", "3", "else", "0", ",", "\n", "bias", ".", "data_ptr", "(", ")", ",", "\n", "init_", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "mask_h", ".", "data_ptr", "(", ")", "if", "mask_h", "is", "not", "None", "else", "0", ",", "\n", "c", ".", "data_ptr", "(", ")", ",", "\n", "grad_h", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "grad_last", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "length", ",", "\n", "batch", ",", "\n", "d", ",", "\n", "k_", ",", "\n", "grad_u", ".", "data_ptr", "(", ")", ",", "\n", "grad_x", ".", "data_ptr", "(", ")", "if", "k_", "==", "3", "else", "0", ",", "\n", "grad_bias", ".", "data_ptr", "(", ")", ",", "\n", "grad_init", ".", "data_ptr", "(", ")", ",", "\n", "self", ".", "activation_type", "]", ",", "\n", "block", "=", "(", "thread_per_block", ",", "1", ",", "1", ")", ",", "grid", "=", "(", "num_block", ",", "1", ",", "1", ")", ",", "\n", "stream", "=", "SRU_STREAM", "\n", ")", "\n", "return", "grad_u", ",", "grad_x", ",", "grad_bias", ".", "sum", "(", "1", ")", ".", "view", "(", "-", "1", ")", ",", "grad_init", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRUCell.__init__": [[494, 515], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "sru.SRUCell.init_weight", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRUCell.init_weight"], ["    ", "def", "__init__", "(", "self", ",", "n_in", ",", "n_out", ",", "dropout", "=", "0", ",", "rnn_dropout", "=", "0", ",", "\n", "bidirectional", "=", "False", ",", "use_tanh", "=", "1", ",", "use_relu", "=", "0", ")", ":", "\n", "        ", "super", "(", "SRUCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_in", "=", "n_in", "\n", "self", ".", "n_out", "=", "n_out", "\n", "self", ".", "rnn_dropout", "=", "rnn_dropout", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "activation_type", "=", "2", "if", "use_relu", "else", "(", "1", "if", "use_tanh", "else", "0", ")", "\n", "\n", "out_size", "=", "n_out", "*", "2", "if", "bidirectional", "else", "n_out", "\n", "k", "=", "4", "if", "n_in", "!=", "out_size", "else", "3", "\n", "self", ".", "size_per_dir", "=", "n_out", "*", "k", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "\n", "n_in", ",", "\n", "self", ".", "size_per_dir", "*", "2", "if", "bidirectional", "else", "self", ".", "size_per_dir", "\n", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "\n", "n_out", "*", "4", "if", "bidirectional", "else", "n_out", "*", "2", "\n", ")", ")", "\n", "self", ".", "init_weight", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRUCell.init_weight": [[516, 520], ["sru.SRUCell.weight.data.uniform_", "sru.SRUCell.bias.data.zero_"], "methods", ["None"], ["", "def", "init_weight", "(", "self", ")", ":", "\n", "        ", "val_range", "=", "(", "3.0", "/", "self", ".", "n_in", ")", "**", "0.5", "\n", "self", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "val_range", ",", "val_range", ")", "\n", "self", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRUCell.set_bias": [[521, 527], ["sru.SRUCell.bias.data[].zero_().add_", "sru.SRUCell.bias.data[].zero_().add_", "sru.SRUCell.bias.data[].zero_", "sru.SRUCell.bias.data[].zero_"], "methods", ["None"], ["", "def", "set_bias", "(", "self", ",", "bias_val", "=", "0", ")", ":", "\n", "        ", "n_out", "=", "self", ".", "n_out", "\n", "if", "self", ".", "bidirectional", ":", "\n", "            ", "self", ".", "bias", ".", "data", "[", "n_out", "*", "2", ":", "]", ".", "zero_", "(", ")", ".", "add_", "(", "bias_val", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", ".", "data", "[", "n_out", ":", "]", ".", "zero_", "(", ")", ".", "add_", "(", "bias_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRUCell.forward": [[528, 561], ["input.size", "x_2d.mm", "input.data.new().zero_", "sru.SRUCell.get_dropout_mask_", "x.contiguous().view", "sru.SRUCell.get_dropout_mask_", "input.dim", "input.dim", "sru.SRUCell.expand_as", "x.dim", "sru.SRU_Compute", "sru.SRU_Compute", "input.data.new", "x.contiguous"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRUCell.get_dropout_mask_", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRUCell.get_dropout_mask_"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "c0", "=", "None", ")", ":", "\n", "        ", "assert", "input", ".", "dim", "(", ")", "==", "2", "or", "input", ".", "dim", "(", ")", "==", "3", "\n", "n_in", ",", "n_out", "=", "self", ".", "n_in", ",", "self", ".", "n_out", "\n", "batch", "=", "input", ".", "size", "(", "-", "2", ")", "\n", "if", "c0", "is", "None", ":", "\n", "            ", "c0", "=", "input", ".", "data", ".", "new", "(", "\n", "batch", ",", "n_out", "if", "not", "self", ".", "bidirectional", "else", "n_out", "*", "2", "\n", ")", ".", "zero_", "(", ")", "\n", "\n", "", "if", "self", ".", "training", "and", "(", "self", ".", "rnn_dropout", ">", "0", ")", ":", "\n", "            ", "mask", "=", "self", ".", "get_dropout_mask_", "(", "(", "batch", ",", "n_in", ")", ",", "self", ".", "rnn_dropout", ")", "\n", "x", "=", "input", "*", "mask", ".", "expand_as", "(", "input", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "input", "\n", "\n", "", "x_2d", "=", "x", "if", "x", ".", "dim", "(", ")", "==", "2", "else", "x", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "n_in", ")", "\n", "u", "=", "x_2d", ".", "mm", "(", "self", ".", "weight", ")", "\n", "\n", "if", "self", ".", "training", "and", "(", "self", ".", "dropout", ">", "0", ")", ":", "\n", "            ", "bidir", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "mask_h", "=", "self", ".", "get_dropout_mask_", "(", "\n", "(", "batch", ",", "n_out", "*", "bidir", ")", ",", "self", ".", "dropout", ")", "\n", "h", ",", "c", "=", "SRU_Compute", "(", "self", ".", "activation_type", ",", "n_out", ",", "\n", "self", ".", "bidirectional", ")", "(", "\n", "u", ",", "input", ",", "self", ".", "bias", ",", "c0", ",", "mask_h", "\n", ")", "\n", "", "else", ":", "\n", "            ", "h", ",", "c", "=", "SRU_Compute", "(", "self", ".", "activation_type", ",", "n_out", ",", "\n", "self", ".", "bidirectional", ")", "(", "\n", "u", ",", "input", ",", "self", ".", "bias", ",", "c0", "\n", ")", "\n", "\n", "", "return", "h", ",", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRUCell.get_dropout_mask_": [[562, 565], ["w.new().bernoulli_().div_", "w.new().bernoulli_", "w.new"], "methods", ["None"], ["", "def", "get_dropout_mask_", "(", "self", ",", "size", ",", "p", ")", ":", "\n", "        ", "w", "=", "self", ".", "weight", ".", "data", "\n", "return", "w", ".", "new", "(", "*", "size", ")", ".", "bernoulli_", "(", "1", "-", "p", ")", ".", "div_", "(", "1", "-", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU.__init__": [[588, 615], ["sru.check_sru_requirement", "torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "range", "sru.SRUCell", "sru.SRU.rnn_lst.append"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.check_sru_requirement", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "\n", "num_layers", "=", "2", ",", "dropout", "=", "0", ",", "rnn_dropout", "=", "0", ",", "\n", "bidirectional", "=", "False", ",", "use_tanh", "=", "1", ",", "use_relu", "=", "0", ")", ":", "\n", "# An entry check here, will catch on train side and translate side", "\n", "# if requirements are not satisfied.", "\n", "        ", "check_sru_requirement", "(", "abort", "=", "True", ")", "\n", "super", "(", "SRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_in", "=", "input_size", "\n", "self", ".", "n_out", "=", "hidden_size", "\n", "self", ".", "depth", "=", "num_layers", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "rnn_dropout", "=", "rnn_dropout", "\n", "self", ".", "rnn_lst", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "out_size", "=", "hidden_size", "*", "2", "if", "bidirectional", "else", "hidden_size", "\n", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "sru_cell", "=", "SRUCell", "(", "\n", "n_in", "=", "self", ".", "n_in", "if", "i", "==", "0", "else", "self", ".", "out_size", ",", "\n", "n_out", "=", "self", ".", "n_out", ",", "\n", "dropout", "=", "dropout", "if", "i", "+", "1", "!=", "num_layers", "else", "0", ",", "\n", "rnn_dropout", "=", "rnn_dropout", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", "use_tanh", "=", "use_tanh", ",", "\n", "use_relu", "=", "use_relu", ",", "\n", ")", "\n", "self", ".", "rnn_lst", ".", "append", "(", "sru_cell", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU.set_bias": [[616, 619], ["l.set_bias"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU.set_bias"], ["", "", "def", "set_bias", "(", "self", ",", "bias_val", "=", "0", ")", ":", "\n", "        ", "for", "l", "in", "self", ".", "rnn_lst", ":", "\n", "            ", "l", ".", "set_bias", "(", "bias_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU.forward": [[620, 652], ["enumerate", "input.dim", "input.data.new().zero_", "isinstance", "rnn", "lstc.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "c0.dim", "h.squeeze", "input.data.new", "range", "c0.chunk", "input.size"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "c0", "=", "None", ",", "return_hidden", "=", "True", ")", ":", "\n", "        ", "assert", "input", ".", "dim", "(", ")", "==", "3", "# (len, batch, n_in)", "\n", "dir_", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "if", "c0", "is", "None", ":", "\n", "            ", "zeros", "=", "input", ".", "data", ".", "new", "(", "\n", "input", ".", "size", "(", "1", ")", ",", "self", ".", "n_out", "*", "dir_", "\n", ")", ".", "zero_", "(", ")", "\n", "c0", "=", "[", "zeros", "for", "i", "in", "range", "(", "self", ".", "depth", ")", "]", "\n", "", "else", ":", "\n", "            ", "if", "isinstance", "(", "c0", ",", "tuple", ")", ":", "\n", "# RNNDecoderState wraps hidden as a tuple.", "\n", "                ", "c0", "=", "c0", "[", "0", "]", "\n", "", "assert", "c0", ".", "dim", "(", ")", "==", "3", "# (depth, batch, dir_*n_out)", "\n", "c0", "=", "[", "h", ".", "squeeze", "(", "0", ")", "for", "h", "in", "c0", ".", "chunk", "(", "self", ".", "depth", ",", "0", ")", "]", "\n", "\n", "", "prevx", "=", "input", "\n", "lstc", "=", "[", "]", "\n", "for", "i", ",", "rnn", "in", "enumerate", "(", "self", ".", "rnn_lst", ")", ":", "\n", "            ", "h", ",", "c", "=", "rnn", "(", "prevx", ",", "c0", "[", "i", "]", ")", "\n", "prevx", "=", "h", "\n", "lstc", ".", "append", "(", "c", ")", "\n", "\n", "", "if", "self", ".", "bidirectional", ":", "\n", "# fh -> (layers*directions) x batch x dim", "\n", "            ", "fh", "=", "torch", ".", "cat", "(", "lstc", ")", "\n", "", "else", ":", "\n", "            ", "fh", "=", "torch", ".", "stack", "(", "lstc", ")", "\n", "\n", "", "if", "return_hidden", ":", "\n", "            ", "return", "prevx", ",", "fh", "\n", "", "else", ":", "\n", "            ", "return", "prevx", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.check_sru_requirement": [[32, 70], ["re.compile", "os.getenv", "torch.cuda.is_available", "torch.cuda.is_available", "AssertionError", "re.match", "AssertionError", "platform.system", "subprocess.check_output", "subprocess.check_output", "subprocess.check_output", "subprocess.check_output", "AssertionError"], "function", ["None"], ["", "", "def", "check_sru_requirement", "(", "abort", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Return True if check pass; if check fails and abort is True,\n    raise an Exception, othereise return False.\n    \"\"\"", "\n", "\n", "# Check 1.", "\n", "try", ":", "\n", "        ", "if", "platform", ".", "system", "(", ")", "==", "'Windows'", ":", "\n", "            ", "subprocess", ".", "check_output", "(", "'pip freeze | findstr cupy'", ",", "shell", "=", "True", ")", "\n", "subprocess", ".", "check_output", "(", "'pip freeze | findstr pynvrtc'", ",", "\n", "shell", "=", "True", ")", "\n", "", "else", ":", "# Unix-like systems", "\n", "            ", "subprocess", ".", "check_output", "(", "'pip freeze | grep -w cupy'", ",", "shell", "=", "True", ")", "\n", "subprocess", ".", "check_output", "(", "'pip freeze | grep -w pynvrtc'", ",", "\n", "shell", "=", "True", ")", "\n", "", "", "except", "subprocess", ".", "CalledProcessError", ":", "\n", "        ", "if", "not", "abort", ":", "\n", "            ", "return", "False", "\n", "", "raise", "AssertionError", "(", "\"Using SRU requires 'cupy' and 'pynvrtc' \"", "\n", "\"python packages installed.\"", ")", "\n", "\n", "# Check 2.", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "is", "False", ":", "\n", "        ", "if", "not", "abort", ":", "\n", "            ", "return", "False", "\n", "", "raise", "AssertionError", "(", "\"Using SRU requires pytorch built with cuda.\"", ")", "\n", "\n", "# Check 3.", "\n", "", "pattern", "=", "re", ".", "compile", "(", "\".*cuda/lib.*\"", ")", "\n", "ld_path", "=", "os", ".", "getenv", "(", "'LD_LIBRARY_PATH'", ",", "\"\"", ")", "\n", "if", "re", ".", "match", "(", "pattern", ",", "ld_path", ")", "is", "None", ":", "\n", "        ", "if", "not", "abort", ":", "\n", "            ", "return", "False", "\n", "", "raise", "AssertionError", "(", "\"Using SRU requires setting cuda lib path, e.g. \"", "\n", "\"export LD_LIBRARY_PATH=/usr/local/cuda/lib64.\"", ")", "\n", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.load_sru_mod": [[353, 377], ["sru.check_sru_requirement", "torch.device", "torch.device", "torch.rand().to", "torch.rand().to", "Program", "Program.compile", "function.Module", "function.Module.load", "function.Module.get_function", "function.Module.get_function", "function.Module.get_function", "function.Module.get_function", "collections.namedtuple", "collections.namedtuple.", "SRU_CODE.encode", "bytes", "torch.rand", "torch.rand", "sru_prog.compile.encode", "torch.cuda.current_stream", "torch.cuda.current_stream"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.check_sru_requirement", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load"], ["def", "load_sru_mod", "(", ")", ":", "\n", "    ", "global", "SRU_FWD_FUNC", ",", "SRU_BWD_FUNC", ",", "SRU_BiFWD_FUNC", ",", "SRU_BiBWD_FUNC", "\n", "global", "SRU_STREAM", "\n", "if", "check_sru_requirement", "(", ")", ":", "\n", "        ", "from", "cupy", ".", "cuda", "import", "function", "\n", "from", "pynvrtc", ".", "compiler", "import", "Program", "\n", "\n", "# This sets up device to use.", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "tmp_", "=", "torch", ".", "rand", "(", "1", ",", "1", ")", ".", "to", "(", "device", ")", "\n", "\n", "sru_prog", "=", "Program", "(", "SRU_CODE", ".", "encode", "(", "'utf-8'", ")", ",", "\n", "'sru_prog.cu'", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "sru_ptx", "=", "sru_prog", ".", "compile", "(", ")", "\n", "sru_mod", "=", "function", ".", "Module", "(", ")", "\n", "sru_mod", ".", "load", "(", "bytes", "(", "sru_ptx", ".", "encode", "(", ")", ")", ")", "\n", "\n", "SRU_FWD_FUNC", "=", "sru_mod", ".", "get_function", "(", "'sru_fwd'", ")", "\n", "SRU_BWD_FUNC", "=", "sru_mod", ".", "get_function", "(", "'sru_bwd'", ")", "\n", "SRU_BiFWD_FUNC", "=", "sru_mod", ".", "get_function", "(", "'sru_bi_fwd'", ")", "\n", "SRU_BiBWD_FUNC", "=", "sru_mod", ".", "get_function", "(", "'sru_bi_bwd'", ")", "\n", "\n", "stream", "=", "namedtuple", "(", "'Stream'", ",", "[", "'ptr'", "]", ")", "\n", "SRU_STREAM", "=", "stream", "(", "ptr", "=", "torch", ".", "cuda", ".", "current_stream", "(", ")", ".", "cuda_stream", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.MultiTask.MultiTask.__init__": [[15, 20], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ",", "multi_task_model", ")", ":", "\n", "        ", "super", "(", "MultiTask", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "multi_task_model", "=", "multi_task_model", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.MultiTask.MultiTask.forward": [[21, 53], ["MultiTask.MultiTask.encoder", "MultiTask.MultiTask.decoder", "MultiTask.MultiTask.decoder.init_state", "kwargs.keys", "MultiTask.MultiTask.multi_task_model", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoder.init_state"], ["", "def", "forward", "(", "self", ",", "src", ",", "tgt", ",", "lengths", ",", "bptt", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Forward propagate a `src` and `tgt` pair for training.\n        Possible initialized with a beginning decoder state.\n\n        Args:\n            src (Tensor): A source sequence passed to encoder.\n                typically for inputs this will be a padded `LongTensor`\n                of size ``(len, batch, features)``. However, may be an\n                image or other generic input depending on encoder.\n            tgt (LongTensor): A target sequence of size ``(tgt_len, batch)``.\n            lengths(LongTensor): The src lengths, pre-padding ``(batch,)``.\n            bptt (Boolean): A flag indicating if truncated bptt is set.\n                If reset then init_state\n\n        Returns:\n            (FloatTensor, dict[str, FloatTensor]):\n\n            * decoder output ``(tgt_len, batch, hidden)``\n            * dictionary attention dists of ``(tgt_len, batch, src_len)``\n        \"\"\"", "\n", "tgt", "=", "tgt", "[", ":", "-", "1", "]", "# exclude last target from inputs", "\n", "\n", "enc_state", ",", "memory_bank", ",", "lengths", "=", "self", ".", "encoder", "(", "src", ",", "lengths", ")", "\n", "if", "bptt", "is", "False", ":", "\n", "            ", "self", ".", "decoder", ".", "init_state", "(", "src", ",", "memory_bank", ",", "enc_state", ")", "\n", "", "dec_out", ",", "attns", "=", "self", ".", "decoder", "(", "tgt", ",", "memory_bank", ",", "\n", "memory_lengths", "=", "lengths", ",", "**", "kwargs", ")", "\n", "if", "\"facts\"", "in", "kwargs", ".", "keys", "(", ")", ":", "\n", "            ", "multi_task_loss", "=", "self", ".", "multi_task_model", "(", "kwargs", "[", "'facts'", "]", ",", "torch", ".", "mean", "(", "dec_out", ",", "dim", "=", "0", ")", ")", "\n", "return", "dec_out", ",", "attns", ",", "multi_task_loss", "\n", "\n", "", "return", "dec_out", ",", "attns", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.__init__": [[29, 40], ["collections.deque"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "base_path", ",", "model", ",", "model_opt", ",", "fields", ",", "optim", ",", "\n", "keep_checkpoint", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "base_path", "=", "base_path", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model_opt", "=", "model_opt", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "optim", "=", "optim", "\n", "self", ".", "last_saved_step", "=", "None", "\n", "self", ".", "keep_checkpoint", "=", "keep_checkpoint", "\n", "if", "keep_checkpoint", ">", "0", ":", "\n", "            ", "self", ".", "checkpoint_queue", "=", "deque", "(", "[", "]", ",", "maxlen", "=", "keep_checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.save": [[41, 69], ["model_saver.ModelSaverBase._save", "copy.deepcopy", "zip", "model_saver.ModelSaverBase.checkpoint_queue.append", "copy.deepcopy.parameters", "param.data.copy_", "len", "model_saver.ModelSaverBase.checkpoint_queue.popleft", "model_saver.ModelSaverBase._rm_checkpoint"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaver._save", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaver._rm_checkpoint"], ["", "", "def", "save", "(", "self", ",", "step", ",", "moving_average", "=", "None", ")", ":", "\n", "        ", "\"\"\"Main entry point for model saver\n\n        It wraps the `_save` method with checks and apply `keep_checkpoint`\n        related logic\n        \"\"\"", "\n", "\n", "if", "self", ".", "keep_checkpoint", "==", "0", "or", "step", "==", "self", ".", "last_saved_step", ":", "\n", "            ", "return", "\n", "\n", "", "if", "moving_average", ":", "\n", "            ", "save_model", "=", "deepcopy", "(", "self", ".", "model", ")", "\n", "for", "avg", ",", "param", "in", "zip", "(", "moving_average", ",", "save_model", ".", "parameters", "(", ")", ")", ":", "\n", "                ", "param", ".", "data", ".", "copy_", "(", "avg", ".", "data", ")", "\n", "", "", "else", ":", "\n", "            ", "save_model", "=", "self", ".", "model", "\n", "\n", "", "chkpt", ",", "chkpt_name", "=", "self", ".", "_save", "(", "step", ",", "save_model", ")", "\n", "self", ".", "last_saved_step", "=", "step", "\n", "\n", "if", "moving_average", ":", "\n", "            ", "del", "save_model", "\n", "\n", "", "if", "self", ".", "keep_checkpoint", ">", "0", ":", "\n", "            ", "if", "len", "(", "self", ".", "checkpoint_queue", ")", "==", "self", ".", "checkpoint_queue", ".", "maxlen", ":", "\n", "                ", "todel", "=", "self", ".", "checkpoint_queue", ".", "popleft", "(", ")", "\n", "self", ".", "_rm_checkpoint", "(", "todel", ")", "\n", "", "self", ".", "checkpoint_queue", ".", "append", "(", "chkpt_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase._save": [[70, 84], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "_save", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Save a resumable checkpoint.\n\n        Args:\n            step (int): step number\n\n        Returns:\n            (object, str):\n\n            * checkpoint: the saved object\n            * checkpoint_name: name (or path) of the saved checkpoint\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase._rm_checkpoint": [[85, 94], ["NotImplementedError"], "methods", ["None"], ["", "def", "_rm_checkpoint", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"Remove a checkpoint\n\n        Args:\n            name(str): name that indentifies the checkpoint\n                (it may be a filepath)\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaver._save": [[99, 123], ["real_model.state_dict", "real_generator.state_dict", "onmt.utils.logging.logger.info", "torch.save", "torch.save", "torch.save", "torch.save", "isinstance", "isinstance", "model_saver.ModelSaver.optim.state_dict", "real_model.state_dict.items"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.state_dict", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.state_dict", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.state_dict"], ["def", "_save", "(", "self", ",", "step", ",", "model", ")", ":", "\n", "        ", "real_model", "=", "(", "model", ".", "module", "\n", "if", "isinstance", "(", "model", ",", "nn", ".", "DataParallel", ")", "\n", "else", "model", ")", "\n", "real_generator", "=", "(", "real_model", ".", "generator", ".", "module", "\n", "if", "isinstance", "(", "real_model", ".", "generator", ",", "nn", ".", "DataParallel", ")", "\n", "else", "real_model", ".", "generator", ")", "\n", "\n", "model_state_dict", "=", "real_model", ".", "state_dict", "(", ")", "\n", "model_state_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "model_state_dict", ".", "items", "(", ")", "\n", "if", "'generator'", "not", "in", "k", "}", "\n", "generator_state_dict", "=", "real_generator", ".", "state_dict", "(", ")", "\n", "checkpoint", "=", "{", "\n", "'model'", ":", "model_state_dict", ",", "\n", "'generator'", ":", "generator_state_dict", ",", "\n", "'vocab'", ":", "self", ".", "fields", ",", "\n", "'opt'", ":", "self", ".", "model_opt", ",", "\n", "'optim'", ":", "self", ".", "optim", ".", "state_dict", "(", ")", ",", "\n", "}", "\n", "\n", "logger", ".", "info", "(", "\"Saving checkpoint %s_step_%d.pt\"", "%", "(", "self", ".", "base_path", ",", "step", ")", ")", "\n", "checkpoint_path", "=", "'%s_step_%d.pt'", "%", "(", "self", ".", "base_path", ",", "step", ")", "\n", "torch", ".", "save", "(", "checkpoint", ",", "checkpoint_path", ")", "\n", "return", "checkpoint", ",", "checkpoint_path", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaver._rm_checkpoint": [[124, 126], ["os.remove"], "methods", ["None"], ["", "def", "_rm_checkpoint", "(", "self", ",", "name", ")", ":", "\n", "        ", "os", ".", "remove", "(", "name", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.build_model_saver": [[11, 19], ["model_saver.ModelSaver"], "function", ["None"], ["def", "build_model_saver", "(", "model_opt", ",", "opt", ",", "model", ",", "fields", ",", "optim", ")", ":", "\n", "    ", "model_saver", "=", "ModelSaver", "(", "opt", ".", "save_model", ",", "\n", "model", ",", "\n", "model_opt", ",", "\n", "fields", ",", "\n", "optim", ",", "\n", "opt", ".", "keep_checkpoint", ")", "\n", "return", "model_saver", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.__init__": [[26, 29], ["unittest.TestCase.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TestModel", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.get_field": [[30, 34], ["src.base_field.build_vocab", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.build_vocab", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields"], ["", "def", "get_field", "(", "self", ")", ":", "\n", "        ", "src", "=", "onmt", ".", "inputters", ".", "get_fields", "(", "\"text\"", ",", "0", ",", "0", ")", "[", "\"src\"", "]", "\n", "src", ".", "base_field", ".", "build_vocab", "(", "[", "]", ")", "\n", "return", "src", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.get_batch": [[35, 41], ["torch.ones().long", "torch.ones().long", "torch.ones().fill_().long", "torch.ones", "torch.ones", "torch.ones().fill_", "torch.ones"], "methods", ["None"], ["", "def", "get_batch", "(", "self", ",", "source_l", "=", "3", ",", "bsize", "=", "1", ")", ":", "\n", "# len x batch x nfeat", "\n", "        ", "test_src", "=", "torch", ".", "ones", "(", "source_l", ",", "bsize", ",", "1", ")", ".", "long", "(", ")", "\n", "test_tgt", "=", "torch", ".", "ones", "(", "source_l", ",", "bsize", ",", "1", ")", ".", "long", "(", ")", "\n", "test_length", "=", "torch", ".", "ones", "(", "bsize", ")", ".", "fill_", "(", "source_l", ")", ".", "long", "(", ")", "\n", "return", "test_src", ",", "test_tgt", ",", "test_length", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.get_batch_image": [[42, 48], ["torch.ones().float", "torch.ones().long", "torch.ones", "torch.ones"], "methods", ["None"], ["", "def", "get_batch_image", "(", "self", ",", "tgt_l", "=", "3", ",", "bsize", "=", "1", ",", "h", "=", "15", ",", "w", "=", "17", ")", ":", "\n", "# batch x c x h x w", "\n", "        ", "test_src", "=", "torch", ".", "ones", "(", "bsize", ",", "3", ",", "h", ",", "w", ")", ".", "float", "(", ")", "\n", "test_tgt", "=", "torch", ".", "ones", "(", "tgt_l", ",", "bsize", ",", "1", ")", ".", "long", "(", ")", "\n", "test_length", "=", "None", "\n", "return", "test_src", ",", "test_tgt", ",", "test_length", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.get_batch_audio": [[49, 57], ["int", "torch.ones().float", "torch.ones().long", "torch.ones().long().fill_", "math.floor", "torch.ones", "torch.ones", "torch.ones().long", "torch.ones"], "methods", ["None"], ["", "def", "get_batch_audio", "(", "self", ",", "tgt_l", "=", "7", ",", "bsize", "=", "3", ",", "sample_rate", "=", "5500", ",", "\n", "window_size", "=", "0.03", ",", "t", "=", "37", ")", ":", "\n", "# batch x 1 x nfft x t", "\n", "        ", "nfft", "=", "int", "(", "math", ".", "floor", "(", "(", "sample_rate", "*", "window_size", ")", "/", "2", ")", "+", "1", ")", "\n", "test_src", "=", "torch", ".", "ones", "(", "bsize", ",", "1", ",", "nfft", ",", "t", ")", ".", "float", "(", ")", "\n", "test_tgt", "=", "torch", ".", "ones", "(", "tgt_l", ",", "bsize", ",", "1", ")", ".", "long", "(", ")", "\n", "test_length", "=", "torch", ".", "ones", "(", "bsize", ")", ".", "long", "(", ")", ".", "fill_", "(", "tgt_l", ")", "\n", "return", "test_src", ",", "test_tgt", ",", "test_length", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.embeddings_forward": [[58, 80], ["test_models.TestModel.get_field", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "test_models.TestModel.get_batch", "test_models.TestModel.assertEqual", "torch.cat", "onmt.model_builder.build_embeddings.", "onmt.model_builder.build_embeddings.", "onmt.model_builder.build_embeddings.", "torch.zeros", "onmt.model_builder.build_embeddings.", "onmt.model_builder.build_embeddings.", "onmt.model_builder.build_embeddings.", "torch.zeros", "onmt.model_builder.build_embeddings.size", "torch.zeros.size"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.get_field", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.get_batch"], ["", "def", "embeddings_forward", "(", "self", ",", "opt", ",", "source_l", "=", "3", ",", "bsize", "=", "1", ")", ":", "\n", "        ", "'''\n        Tests if the embeddings works as expected\n\n        args:\n            opt: set of options\n            source_l: Length of generated input sentence\n            bsize: Batchsize of generated input\n        '''", "\n", "word_field", "=", "self", ".", "get_field", "(", ")", "\n", "emb", "=", "build_embeddings", "(", "opt", ",", "word_field", ")", "\n", "test_src", ",", "_", ",", "__", "=", "self", ".", "get_batch", "(", "source_l", "=", "source_l", ",", "bsize", "=", "bsize", ")", "\n", "if", "opt", ".", "decoder_type", "==", "'transformer'", ":", "\n", "            ", "input", "=", "torch", ".", "cat", "(", "[", "test_src", ",", "test_src", "]", ",", "0", ")", "\n", "res", "=", "emb", "(", "input", ")", "\n", "compare_to", "=", "torch", ".", "zeros", "(", "source_l", "*", "2", ",", "bsize", ",", "\n", "opt", ".", "src_word_vec_size", ")", "\n", "", "else", ":", "\n", "            ", "res", "=", "emb", "(", "test_src", ")", "\n", "compare_to", "=", "torch", ".", "zeros", "(", "source_l", ",", "bsize", ",", "opt", ".", "src_word_vec_size", ")", "\n", "\n", "", "self", ".", "assertEqual", "(", "res", ".", "size", "(", ")", ",", "compare_to", ".", "size", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.encoder_forward": [[81, 111], ["test_models.TestModel.get_field", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_encoder", "onmt.model_builder.build_encoder", "onmt.model_builder.build_encoder", "test_models.TestModel.get_batch", "onmt.model_builder.build_encoder.", "onmt.model_builder.build_encoder.", "onmt.model_builder.build_encoder.", "torch.zeros", "torch.zeros", "test_models.TestModel.assertEqual", "test_models.TestModel.assertEqual", "test_models.TestModel.assertEqual", "torch.zeros.size", "hidden_t[].size", "hidden_t[].size", "torch.zeros.size", "outputs.size", "type"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.get_field", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_encoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_encoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_encoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.get_batch"], ["", "def", "encoder_forward", "(", "self", ",", "opt", ",", "source_l", "=", "3", ",", "bsize", "=", "1", ")", ":", "\n", "        ", "'''\n        Tests if the encoder works as expected\n\n        args:\n            opt: set of options\n            source_l: Length of generated input sentence\n            bsize: Batchsize of generated input\n        '''", "\n", "if", "opt", ".", "rnn_size", ">", "0", ":", "\n", "            ", "opt", ".", "enc_rnn_size", "=", "opt", ".", "rnn_size", "\n", "", "word_field", "=", "self", ".", "get_field", "(", ")", "\n", "embeddings", "=", "build_embeddings", "(", "opt", ",", "word_field", ")", "\n", "enc", "=", "build_encoder", "(", "opt", ",", "embeddings", ")", "\n", "\n", "test_src", ",", "test_tgt", ",", "test_length", "=", "self", ".", "get_batch", "(", "source_l", "=", "source_l", ",", "\n", "bsize", "=", "bsize", ")", "\n", "\n", "hidden_t", ",", "outputs", ",", "test_length", "=", "enc", "(", "test_src", ",", "test_length", ")", "\n", "\n", "# Initialize vectors to compare size with", "\n", "test_hid", "=", "torch", ".", "zeros", "(", "self", ".", "opt", ".", "enc_layers", ",", "bsize", ",", "opt", ".", "enc_rnn_size", ")", "\n", "test_out", "=", "torch", ".", "zeros", "(", "source_l", ",", "bsize", ",", "opt", ".", "dec_rnn_size", ")", "\n", "\n", "# Ensure correct sizes and types", "\n", "self", ".", "assertEqual", "(", "test_hid", ".", "size", "(", ")", ",", "\n", "hidden_t", "[", "0", "]", ".", "size", "(", ")", ",", "\n", "hidden_t", "[", "1", "]", ".", "size", "(", ")", ")", "\n", "self", ".", "assertEqual", "(", "test_out", ".", "size", "(", ")", ",", "outputs", ".", "size", "(", ")", ")", "\n", "self", ".", "assertEqual", "(", "type", "(", "outputs", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.nmtmodel_forward": [[112, 142], ["test_models.TestModel.get_field", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_encoder", "onmt.model_builder.build_encoder", "onmt.model_builder.build_encoder", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_decoder", "onmt.model_builder.build_decoder", "onmt.model_builder.build_decoder", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "test_models.TestModel.get_batch", "onmt.models.model.NMTModel.", "onmt.models.model.NMTModel.", "onmt.models.model.NMTModel.", "torch.zeros", "test_models.TestModel.assertEqual", "test_models.TestModel.assertEqual", "outputs.size", "torch.zeros.size", "type"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.get_field", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_encoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_encoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_encoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.get_batch"], ["", "def", "nmtmodel_forward", "(", "self", ",", "opt", ",", "source_l", "=", "3", ",", "bsize", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Creates a nmtmodel with a custom opt function.\n        Forwards a testbatch and checks output size.\n\n        Args:\n            opt: Namespace with options\n            source_l: length of input sequence\n            bsize: batchsize\n        \"\"\"", "\n", "if", "opt", ".", "rnn_size", ">", "0", ":", "\n", "            ", "opt", ".", "enc_rnn_size", "=", "opt", ".", "rnn_size", "\n", "opt", ".", "dec_rnn_size", "=", "opt", ".", "rnn_size", "\n", "", "word_field", "=", "self", ".", "get_field", "(", ")", "\n", "\n", "embeddings", "=", "build_embeddings", "(", "opt", ",", "word_field", ")", "\n", "enc", "=", "build_encoder", "(", "opt", ",", "embeddings", ")", "\n", "\n", "embeddings", "=", "build_embeddings", "(", "opt", ",", "word_field", ",", "for_encoder", "=", "False", ")", "\n", "dec", "=", "build_decoder", "(", "opt", ",", "embeddings", ")", "\n", "\n", "model", "=", "onmt", ".", "models", ".", "model", ".", "NMTModel", "(", "enc", ",", "dec", ")", "\n", "\n", "test_src", ",", "test_tgt", ",", "test_length", "=", "self", ".", "get_batch", "(", "source_l", "=", "source_l", ",", "\n", "bsize", "=", "bsize", ")", "\n", "outputs", ",", "attn", "=", "model", "(", "test_src", ",", "test_tgt", ",", "test_length", ")", "\n", "outputsize", "=", "torch", ".", "zeros", "(", "source_l", "-", "1", ",", "bsize", ",", "opt", ".", "dec_rnn_size", ")", "\n", "# Make sure that output has the correct size and type", "\n", "self", ".", "assertEqual", "(", "outputs", ".", "size", "(", ")", ",", "outputsize", ".", "size", "(", ")", ")", "\n", "self", ".", "assertEqual", "(", "type", "(", "outputs", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.imagemodel_forward": [[143, 175], ["test_models.TestModel.get_field", "onmt.encoders.image_encoder.ImageEncoder", "onmt.encoders.image_encoder.ImageEncoder", "onmt.encoders.image_encoder.ImageEncoder", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_decoder", "onmt.model_builder.build_decoder", "onmt.model_builder.build_decoder", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "test_models.TestModel.get_batch_image", "onmt.models.model.NMTModel.", "onmt.models.model.NMTModel.", "onmt.models.model.NMTModel.", "torch.zeros", "test_models.TestModel.assertEqual", "test_models.TestModel.assertEqual", "outputs.size", "torch.zeros.size", "type"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.get_field", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.get_batch_image"], ["", "def", "imagemodel_forward", "(", "self", ",", "opt", ",", "tgt_l", "=", "2", ",", "bsize", "=", "1", ",", "h", "=", "15", ",", "w", "=", "17", ")", ":", "\n", "        ", "\"\"\"\n        Creates an image-to-text nmtmodel with a custom opt function.\n        Forwards a testbatch and checks output size.\n\n        Args:\n            opt: Namespace with options\n            source_l: length of input sequence\n            bsize: batchsize\n        \"\"\"", "\n", "if", "opt", ".", "encoder_type", "==", "'transformer'", "or", "opt", ".", "encoder_type", "==", "'cnn'", ":", "\n", "            ", "return", "\n", "\n", "", "word_field", "=", "self", ".", "get_field", "(", ")", "\n", "\n", "enc", "=", "ImageEncoder", "(", "\n", "opt", ".", "enc_layers", ",", "opt", ".", "brnn", ",", "opt", ".", "enc_rnn_size", ",", "opt", ".", "dropout", ")", "\n", "\n", "embeddings", "=", "build_embeddings", "(", "opt", ",", "word_field", ",", "for_encoder", "=", "False", ")", "\n", "dec", "=", "build_decoder", "(", "opt", ",", "embeddings", ")", "\n", "\n", "model", "=", "onmt", ".", "models", ".", "model", ".", "NMTModel", "(", "enc", ",", "dec", ")", "\n", "\n", "test_src", ",", "test_tgt", ",", "test_length", "=", "self", ".", "get_batch_image", "(", "\n", "h", "=", "h", ",", "w", "=", "w", ",", "\n", "bsize", "=", "bsize", ",", "\n", "tgt_l", "=", "tgt_l", ")", "\n", "outputs", ",", "attn", "=", "model", "(", "test_src", ",", "test_tgt", ",", "test_length", ")", "\n", "outputsize", "=", "torch", ".", "zeros", "(", "tgt_l", "-", "1", ",", "bsize", ",", "opt", ".", "dec_rnn_size", ")", "\n", "# Make sure that output has the correct size and type", "\n", "self", ".", "assertEqual", "(", "outputs", ".", "size", "(", ")", ",", "outputsize", ".", "size", "(", ")", ")", "\n", "self", ".", "assertEqual", "(", "type", "(", "outputs", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.audiomodel_forward": [[176, 213], ["test_models.TestModel.get_field", "onmt.encoders.audio_encoder.AudioEncoder", "onmt.encoders.audio_encoder.AudioEncoder", "onmt.encoders.audio_encoder.AudioEncoder", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_decoder", "onmt.model_builder.build_decoder", "onmt.model_builder.build_decoder", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "test_models.TestModel.get_batch_audio", "onmt.models.model.NMTModel.", "onmt.models.model.NMTModel.", "onmt.models.model.NMTModel.", "torch.zeros", "test_models.TestModel.assertEqual", "test_models.TestModel.assertEqual", "outputs.size", "torch.zeros.size", "type"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.get_field", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models.TestModel.get_batch_audio"], ["", "def", "audiomodel_forward", "(", "self", ",", "opt", ",", "tgt_l", "=", "7", ",", "bsize", "=", "3", ",", "t", "=", "37", ")", ":", "\n", "        ", "\"\"\"\n        Creates a speech-to-text nmtmodel with a custom opt function.\n        Forwards a testbatch and checks output size.\n\n        Args:\n            opt: Namespace with options\n            source_l: length of input sequence\n            bsize: batchsize\n        \"\"\"", "\n", "if", "opt", ".", "encoder_type", "==", "'transformer'", "or", "opt", ".", "encoder_type", "==", "'cnn'", ":", "\n", "            ", "return", "\n", "", "if", "opt", ".", "rnn_type", "==", "'SRU'", ":", "\n", "            ", "return", "\n", "\n", "", "word_field", "=", "self", ".", "get_field", "(", ")", "\n", "\n", "enc", "=", "AudioEncoder", "(", "opt", ".", "rnn_type", ",", "opt", ".", "enc_layers", ",", "opt", ".", "dec_layers", ",", "\n", "opt", ".", "brnn", ",", "opt", ".", "enc_rnn_size", ",", "opt", ".", "dec_rnn_size", ",", "\n", "opt", ".", "audio_enc_pooling", ",", "opt", ".", "dropout", ",", "\n", "opt", ".", "sample_rate", ",", "opt", ".", "window_size", ")", "\n", "\n", "embeddings", "=", "build_embeddings", "(", "opt", ",", "word_field", ",", "for_encoder", "=", "False", ")", "\n", "dec", "=", "build_decoder", "(", "opt", ",", "embeddings", ")", "\n", "\n", "model", "=", "onmt", ".", "models", ".", "model", ".", "NMTModel", "(", "enc", ",", "dec", ")", "\n", "\n", "test_src", ",", "test_tgt", ",", "test_length", "=", "self", ".", "get_batch_audio", "(", "\n", "bsize", "=", "bsize", ",", "\n", "sample_rate", "=", "opt", ".", "sample_rate", ",", "\n", "window_size", "=", "opt", ".", "window_size", ",", "\n", "t", "=", "t", ",", "tgt_l", "=", "tgt_l", ")", "\n", "outputs", ",", "attn", "=", "model", "(", "test_src", ",", "test_tgt", ",", "test_length", ")", "\n", "outputsize", "=", "torch", ".", "zeros", "(", "tgt_l", "-", "1", ",", "bsize", ",", "opt", ".", "dec_rnn_size", ")", "\n", "# Make sure that output has the correct size and type", "\n", "self", ".", "assertEqual", "(", "outputs", ".", "size", "(", ")", ",", "outputsize", ".", "size", "(", ")", ")", "\n", "self", ".", "assertEqual", "(", "type", "(", "outputs", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_models._add_test": [[215, 238], ["setattr", "copy.deepcopy", "onmt.utils.parse.ArgumentParser.update_model_opts", "getattr", "setattr", "str().split", "str"], "function", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.parse.ArgumentParser.update_model_opts"], ["", "", "def", "_add_test", "(", "param_setting", ",", "methodname", ")", ":", "\n", "    ", "\"\"\"\n    Adds a Test to TestModel according to settings\n\n    Args:\n        param_setting: list of tuples of (param, setting)\n        methodname: name of the method that gets called\n    \"\"\"", "\n", "\n", "def", "test_method", "(", "self", ")", ":", "\n", "        ", "opt", "=", "copy", ".", "deepcopy", "(", "self", ".", "opt", ")", "\n", "if", "param_setting", ":", "\n", "            ", "for", "param", ",", "setting", "in", "param_setting", ":", "\n", "                ", "setattr", "(", "opt", ",", "param", ",", "setting", ")", "\n", "", "", "ArgumentParser", ".", "update_model_opts", "(", "opt", ")", "\n", "getattr", "(", "self", ",", "methodname", ")", "(", "opt", ")", "\n", "", "if", "param_setting", ":", "\n", "        ", "name", "=", "'test_'", "+", "methodname", "+", "\"_\"", "+", "\"_\"", ".", "join", "(", "\n", "str", "(", "param_setting", ")", ".", "split", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "name", "=", "'test_'", "+", "methodname", "+", "'_standard'", "\n", "", "setattr", "(", "TestModel", ",", "name", ",", "test_method", ")", "\n", "test_method", ".", "__name__", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.degenerate_case": [[27, 32], ["None"], "methods", ["None"], ["@", "classmethod", "\n", "def", "degenerate_case", "(", "cls", ",", "init_case", ",", "params", ")", ":", "\n", "        ", "if", "params", "[", "\"batch_size\"", "]", "<", "params", "[", "\"full_length_seq\"", "]", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.pad_inputs": [[33, 42], ["torch.randint().tolist", "torch.randn", "torch.randint", "range"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "pad_inputs", "(", "cls", ",", "params", ")", ":", "\n", "        ", "lengths", "=", "torch", ".", "randint", "(", "1", ",", "params", "[", "\"max_len\"", "]", ",", "\n", "(", "params", "[", "\"batch_size\"", "]", ",", ")", ")", ".", "tolist", "(", ")", "\n", "lengths", "[", "params", "[", "\"full_length_seq\"", "]", "]", "=", "params", "[", "\"max_len\"", "]", "\n", "fake_input", "=", "[", "\n", "torch", ".", "randn", "(", "(", "params", "[", "\"nfeats\"", "]", ",", "lengths", "[", "b", "]", ")", ")", "\n", "for", "b", "in", "range", "(", "params", "[", "\"batch_size\"", "]", ")", "]", "\n", "return", "fake_input", ",", "lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.numericalize_inputs": [[43, 58], ["torch.randint", "torch.full", "range", "torch.randn"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "numericalize_inputs", "(", "cls", ",", "init_case", ",", "params", ")", ":", "\n", "        ", "bs", "=", "params", "[", "\"batch_size\"", "]", "\n", "max_len", "=", "params", "[", "\"max_len\"", "]", "\n", "lengths", "=", "torch", ".", "randint", "(", "1", ",", "max_len", ",", "(", "bs", ",", ")", ")", "\n", "lengths", "[", "params", "[", "\"full_length_seq\"", "]", "]", "=", "max_len", "\n", "nfeats", "=", "params", "[", "\"nfeats\"", "]", "\n", "fake_input", "=", "torch", ".", "full", "(", "\n", "(", "bs", ",", "1", ",", "nfeats", ",", "max_len", ")", ",", "init_case", "[", "\"pad_index\"", "]", ")", "\n", "for", "b", "in", "range", "(", "bs", ")", ":", "\n", "            ", "fake_input", "[", "b", ",", ":", ",", ":", ",", ":", "lengths", "[", "b", "]", "]", "=", "torch", ".", "randn", "(", "\n", "(", "1", ",", "nfeats", ",", "lengths", "[", "b", "]", ")", ")", "\n", "", "if", "init_case", "[", "\"include_lengths\"", "]", ":", "\n", "            ", "fake_input", "=", "(", "fake_input", ",", "lengths", ")", "\n", "", "return", "fake_input", ",", "lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.test_pad_shape_and_lengths": [[59, 72], ["itertools.product", "test_audio_dataset.TestAudioField.degenerate_case", "onmt.inputters.audio_dataset.AudioSeqField", "test_audio_dataset.TestAudioField.pad_inputs", "onmt.inputters.audio_dataset.AudioSeqField.pad", "test_audio_dataset.TestAudioField.assertEqual"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.degenerate_case", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.pad_inputs", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioSeqField.pad"], ["", "def", "test_pad_shape_and_lengths", "(", "self", ")", ":", "\n", "        ", "for", "init_case", ",", "params", "in", "itertools", ".", "product", "(", "\n", "self", ".", "INIT_CASES", ",", "self", ".", "PARAMS", ")", ":", "\n", "            ", "if", "not", "self", ".", "degenerate_case", "(", "init_case", ",", "params", ")", ":", "\n", "                ", "field", "=", "AudioSeqField", "(", "**", "init_case", ")", "\n", "fake_input", ",", "lengths", "=", "self", ".", "pad_inputs", "(", "params", ")", "\n", "outp", "=", "field", ".", "pad", "(", "fake_input", ")", "\n", "if", "init_case", "[", "\"include_lengths\"", "]", ":", "\n", "                    ", "outp", ",", "_", "=", "outp", "\n", "", "expected_shape", "=", "(", "\n", "params", "[", "\"batch_size\"", "]", ",", "1", ",", "params", "[", "\"nfeats\"", "]", ",", "\n", "params", "[", "\"max_len\"", "]", ")", "\n", "self", ".", "assertEqual", "(", "outp", ".", "shape", ",", "expected_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.test_pad_returns_correct_lengths": [[73, 82], ["itertools.product", "onmt.inputters.audio_dataset.AudioSeqField", "test_audio_dataset.TestAudioField.pad_inputs", "onmt.inputters.audio_dataset.AudioSeqField.pad", "test_audio_dataset.TestAudioField.assertEqual", "test_audio_dataset.TestAudioField.degenerate_case"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.pad_inputs", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioSeqField.pad", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.degenerate_case"], ["", "", "", "def", "test_pad_returns_correct_lengths", "(", "self", ")", ":", "\n", "        ", "for", "init_case", ",", "params", "in", "itertools", ".", "product", "(", "\n", "self", ".", "INIT_CASES", ",", "self", ".", "PARAMS", ")", ":", "\n", "            ", "if", "not", "self", ".", "degenerate_case", "(", "init_case", ",", "params", ")", "and", "init_case", "[", "\"include_lengths\"", "]", ":", "\n", "                ", "field", "=", "AudioSeqField", "(", "**", "init_case", ")", "\n", "fake_input", ",", "lengths", "=", "self", ".", "pad_inputs", "(", "params", ")", "\n", "_", ",", "outp_lengths", "=", "field", ".", "pad", "(", "fake_input", ")", "\n", "self", ".", "assertEqual", "(", "outp_lengths", ",", "lengths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.test_pad_pads_right_places_and_uses_correct_index": [[83, 97], ["itertools.product", "test_audio_dataset.TestAudioField.degenerate_case", "onmt.inputters.audio_dataset.AudioSeqField", "test_audio_dataset.TestAudioField.pad_inputs", "onmt.inputters.audio_dataset.AudioSeqField.pad", "range", "range", "test_audio_dataset.TestAudioField.assertTrue", "outp[].allclose", "torch.tensor", "float"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.degenerate_case", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.pad_inputs", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioSeqField.pad"], ["", "", "", "def", "test_pad_pads_right_places_and_uses_correct_index", "(", "self", ")", ":", "\n", "        ", "for", "init_case", ",", "params", "in", "itertools", ".", "product", "(", "\n", "self", ".", "INIT_CASES", ",", "self", ".", "PARAMS", ")", ":", "\n", "            ", "if", "not", "self", ".", "degenerate_case", "(", "init_case", ",", "params", ")", ":", "\n", "                ", "field", "=", "AudioSeqField", "(", "**", "init_case", ")", "\n", "fake_input", ",", "lengths", "=", "self", ".", "pad_inputs", "(", "params", ")", "\n", "outp", "=", "field", ".", "pad", "(", "fake_input", ")", "\n", "if", "init_case", "[", "\"include_lengths\"", "]", ":", "\n", "                    ", "outp", ",", "_", "=", "outp", "\n", "", "for", "b", "in", "range", "(", "params", "[", "\"batch_size\"", "]", ")", ":", "\n", "                    ", "for", "s", "in", "range", "(", "lengths", "[", "b", "]", ",", "params", "[", "\"max_len\"", "]", ")", ":", "\n", "                        ", "self", ".", "assertTrue", "(", "\n", "outp", "[", "b", ",", ":", ",", ":", ",", "s", "]", ".", "allclose", "(", "\n", "torch", ".", "tensor", "(", "float", "(", "init_case", "[", "\"pad_index\"", "]", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.test_numericalize_shape": [[98, 118], ["itertools.product", "test_audio_dataset.TestAudioField.degenerate_case", "onmt.inputters.audio_dataset.AudioSeqField", "test_audio_dataset.TestAudioField.numericalize_inputs", "onmt.inputters.audio_dataset.AudioSeqField.numericalize", "test_audio_dataset.TestAudioField.assertEqual", "init_case.__str__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.degenerate_case", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.numericalize_inputs", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioSeqField.numericalize"], ["", "", "", "", "", "def", "test_numericalize_shape", "(", "self", ")", ":", "\n", "        ", "for", "init_case", ",", "params", "in", "itertools", ".", "product", "(", "\n", "self", ".", "INIT_CASES", ",", "self", ".", "PARAMS", ")", ":", "\n", "            ", "if", "not", "self", ".", "degenerate_case", "(", "init_case", ",", "params", ")", ":", "\n", "                ", "field", "=", "AudioSeqField", "(", "**", "init_case", ")", "\n", "fake_input", ",", "lengths", "=", "self", ".", "numericalize_inputs", "(", "\n", "init_case", ",", "params", ")", "\n", "outp", "=", "field", ".", "numericalize", "(", "fake_input", ")", "\n", "if", "init_case", "[", "\"include_lengths\"", "]", ":", "\n", "                    ", "outp", ",", "_", "=", "outp", "\n", "", "if", "init_case", "[", "\"batch_first\"", "]", ":", "\n", "                    ", "expected_shape", "=", "(", "\n", "params", "[", "\"batch_size\"", "]", ",", "1", ",", "\n", "params", "[", "\"nfeats\"", "]", ",", "params", "[", "\"max_len\"", "]", ")", "\n", "", "else", ":", "\n", "                    ", "expected_shape", "=", "(", "\n", "params", "[", "\"max_len\"", "]", ",", "params", "[", "\"batch_size\"", "]", ",", "\n", "1", ",", "params", "[", "\"nfeats\"", "]", ")", "\n", "", "self", ".", "assertEqual", "(", "expected_shape", ",", "outp", ".", "shape", ",", "\n", "init_case", ".", "__str__", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.test_process_shape": [[119, 139], ["itertools.product", "test_audio_dataset.TestAudioField.degenerate_case", "onmt.inputters.audio_dataset.AudioSeqField", "test_audio_dataset.TestAudioField.pad_inputs", "onmt.inputters.audio_dataset.AudioSeqField.process", "test_audio_dataset.TestAudioField.assertEqual", "init_case.__str__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.degenerate_case", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.pad_inputs", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.text_dataset.TextMultiField.process"], ["", "", "", "def", "test_process_shape", "(", "self", ")", ":", "\n", "# tests pad and numericalize integration", "\n", "        ", "for", "init_case", ",", "params", "in", "itertools", ".", "product", "(", "\n", "self", ".", "INIT_CASES", ",", "self", ".", "PARAMS", ")", ":", "\n", "            ", "if", "not", "self", ".", "degenerate_case", "(", "init_case", ",", "params", ")", ":", "\n", "                ", "field", "=", "AudioSeqField", "(", "**", "init_case", ")", "\n", "fake_input", ",", "lengths", "=", "self", ".", "pad_inputs", "(", "params", ")", "\n", "outp", "=", "field", ".", "process", "(", "fake_input", ")", "\n", "if", "init_case", "[", "\"include_lengths\"", "]", ":", "\n", "                    ", "outp", ",", "_", "=", "outp", "\n", "", "if", "init_case", "[", "\"batch_first\"", "]", ":", "\n", "                    ", "expected_shape", "=", "(", "\n", "params", "[", "\"batch_size\"", "]", ",", "1", ",", "\n", "params", "[", "\"nfeats\"", "]", ",", "params", "[", "\"max_len\"", "]", ")", "\n", "", "else", ":", "\n", "                    ", "expected_shape", "=", "(", "\n", "params", "[", "\"max_len\"", "]", ",", "params", "[", "\"batch_size\"", "]", ",", "\n", "1", ",", "params", "[", "\"nfeats\"", "]", ")", "\n", "", "self", ".", "assertEqual", "(", "expected_shape", ",", "outp", ".", "shape", ",", "\n", "init_case", ".", "__str__", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.test_process_lengths": [[140, 151], ["itertools.product", "test_audio_dataset.TestAudioField.degenerate_case", "onmt.inputters.audio_dataset.AudioSeqField", "test_audio_dataset.TestAudioField.pad_inputs", "torch.tensor", "onmt.inputters.audio_dataset.AudioSeqField.process", "test_audio_dataset.TestAudioField.assertTrue", "outp_lengths.eq().all", "outp_lengths.eq"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.degenerate_case", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioField.pad_inputs", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.text_dataset.TextMultiField.process"], ["", "", "", "def", "test_process_lengths", "(", "self", ")", ":", "\n", "# tests pad and numericalize integration", "\n", "        ", "for", "init_case", ",", "params", "in", "itertools", ".", "product", "(", "\n", "self", ".", "INIT_CASES", ",", "self", ".", "PARAMS", ")", ":", "\n", "            ", "if", "not", "self", ".", "degenerate_case", "(", "init_case", ",", "params", ")", ":", "\n", "                ", "if", "init_case", "[", "\"include_lengths\"", "]", ":", "\n", "                    ", "field", "=", "AudioSeqField", "(", "**", "init_case", ")", "\n", "fake_input", ",", "lengths", "=", "self", ".", "pad_inputs", "(", "params", ")", "\n", "lengths", "=", "torch", ".", "tensor", "(", "lengths", ",", "dtype", "=", "torch", ".", "int", ")", "\n", "_", ",", "outp_lengths", "=", "field", ".", "process", "(", "fake_input", ")", "\n", "self", ".", "assertTrue", "(", "outp_lengths", ".", "eq", "(", "lengths", ")", ".", "all", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioDataReader.setUpClass": [[180, 201], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "open", "f.write", "open", "open", "torch.randint", "range", "int", "int", "cls._AUDIO_DATA_PATH_FMT.format", "torchaudio.save", "cls._AUDIO_DATA_FMT.format", "f_list_fnames.write", "f_list_paths.write", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write"], ["@", "classmethod", "\n", "def", "setUpClass", "(", "cls", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "cls", ".", "_AUDIO_DATA_DIR", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "cls", ".", "_AUDIO_DATA_DIR", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cls", ".", "_AUDIO_LIST_DIR", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "cls", ".", "_AUDIO_LIST_DIR", ")", "\n", "\n", "", "with", "open", "(", "cls", ".", "_JUNK_FILE", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "\"this is some garbage\\nShould have no impact.\"", ")", "\n", "\n", "", "with", "open", "(", "cls", ".", "_AUDIO_LIST_PATHS_PATH", ",", "\"w\"", ")", "as", "f_list_fnames", ",", "open", "(", "cls", ".", "_AUDIO_LIST_FNAMES_PATH", ",", "\"w\"", ")", "as", "f_list_paths", ":", "\n", "            ", "lengths", "=", "torch", ".", "randint", "(", "int", "(", ".5e5", ")", ",", "int", "(", "1.5e6", ")", ",", "(", "cls", ".", "_N_EXAMPLES", ",", ")", ")", "\n", "for", "i", "in", "range", "(", "cls", ".", "_N_EXAMPLES", ")", ":", "\n", "# dividing gets the noise in [-1, 1]", "\n", "                ", "white_noise", "=", "torch", ".", "randn", "(", "(", "cls", ".", "_N_CHANNELS", ",", "lengths", "[", "i", "]", ")", ")", "/", "10", "\n", "f_path", "=", "cls", ".", "_AUDIO_DATA_PATH_FMT", ".", "format", "(", "i", ")", "\n", "torchaudio", ".", "save", "(", "f_path", ",", "white_noise", ",", "cls", ".", "_SAMPLE_RATE", ")", "\n", "f_name_short", "=", "cls", ".", "_AUDIO_DATA_FMT", ".", "format", "(", "i", ")", "\n", "f_list_fnames", ".", "write", "(", "f_name_short", "+", "\"\\n\"", ")", "\n", "f_list_paths", ".", "write", "(", "f_path", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioDataReader.tearDownClass": [[202, 206], ["shutil.rmtree", "shutil.rmtree"], "methods", ["None"], ["", "", "", "@", "classmethod", "\n", "def", "tearDownClass", "(", "cls", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "cls", ".", "_AUDIO_DATA_DIR", ")", "\n", "shutil", ".", "rmtree", "(", "cls", ".", "_AUDIO_LIST_DIR", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioDataReader.test_read_from_dir_and_data_file_containing_filenames": [[207, 217], ["onmt.inputters.audio_dataset.AudioDataReader", "enumerate", "test_audio_dataset.TestAudioDataReader.assertGreater", "onmt.inputters.audio_dataset.AudioDataReader.read", "test_audio_dataset.TestAudioDataReader.assertEqual", "test_audio_dataset.TestAudioDataReader.assertEqual", "test_audio_dataset.TestAudioDataReader._AUDIO_DATA_PATH_FMT.format"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioDataReader.read"], ["", "def", "test_read_from_dir_and_data_file_containing_filenames", "(", "self", ")", ":", "\n", "        ", "rdr", "=", "AudioDataReader", "(", "self", ".", "_SAMPLE_RATE", ",", "window", "=", "\"hamming\"", ",", "\n", "window_size", "=", "0.02", ",", "window_stride", "=", "0.01", ")", "\n", "i", "=", "0", "# initialize since there's a sanity check on i", "\n", "for", "i", ",", "aud", "in", "enumerate", "(", "rdr", ".", "read", "(", "\n", "self", ".", "_AUDIO_LIST_FNAMES_PATH", ",", "\"src\"", ",", "self", ".", "_AUDIO_DATA_DIR", ")", ")", ":", "\n", "            ", "self", ".", "assertEqual", "(", "aud", "[", "\"src\"", "]", ".", "shape", "[", "0", "]", ",", "481", ")", "\n", "self", ".", "assertEqual", "(", "aud", "[", "\"src_path\"", "]", ",", "\n", "self", ".", "_AUDIO_DATA_PATH_FMT", ".", "format", "(", "i", ")", ")", "\n", "", "self", ".", "assertGreater", "(", "i", ",", "0", ",", "\"No audio data was read.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_audio_dataset.TestAudioDataReader.test_read_from_dir_and_data_file_containing_paths": [[218, 228], ["onmt.inputters.audio_dataset.AudioDataReader", "enumerate", "test_audio_dataset.TestAudioDataReader.assertGreater", "onmt.inputters.audio_dataset.AudioDataReader.read", "test_audio_dataset.TestAudioDataReader.assertEqual", "test_audio_dataset.TestAudioDataReader.assertEqual", "test_audio_dataset.TestAudioDataReader._AUDIO_DATA_FMT.format"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioDataReader.read"], ["", "def", "test_read_from_dir_and_data_file_containing_paths", "(", "self", ")", ":", "\n", "        ", "rdr", "=", "AudioDataReader", "(", "self", ".", "_SAMPLE_RATE", ",", "window", "=", "\"hamming\"", ",", "\n", "window_size", "=", "0.02", ",", "window_stride", "=", "0.01", ")", "\n", "i", "=", "0", "# initialize since there's a sanity check on i", "\n", "for", "i", ",", "aud", "in", "enumerate", "(", "rdr", ".", "read", "(", "\n", "self", ".", "_AUDIO_LIST_PATHS_PATH", ",", "\"src\"", ",", "self", ".", "_AUDIO_DATA_DIR", ")", ")", ":", "\n", "            ", "self", ".", "assertEqual", "(", "aud", "[", "\"src\"", "]", ".", "shape", "[", "0", "]", ",", "481", ")", "\n", "self", ".", "assertEqual", "(", "aud", "[", "\"src_path\"", "]", ",", "\n", "self", ".", "_AUDIO_DATA_FMT", ".", "format", "(", "i", ")", ")", "\n", "", "self", ".", "assertGreater", "(", "i", ",", "0", ",", "\"No audio data was read.\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.GlobalScorerStub.__init__": [[14, 20], ["torch.zeros"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "length_penalty", "=", "lambda", "x", ",", "alpha", ":", "1.", "\n", "self", ".", "cov_penalty", "=", "lambda", "cov", ",", "beta", ":", "torch", ".", "zeros", "(", "\n", "(", "1", ",", "cov", ".", "shape", "[", "-", "2", "]", ")", ",", "device", "=", "cov", ".", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "self", ".", "has_cov_pen", "=", "False", "\n", "self", ".", "has_len_pen", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.GlobalScorerStub.update_global_state": [[21, 23], ["None"], "methods", ["None"], ["", "def", "update_global_state", "(", "self", ",", "beam", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.GlobalScorerStub.score": [[24, 26], ["None"], "methods", ["None"], ["", "def", "score", "(", "self", ",", "beam", ",", "scores", ")", ":", "\n", "        ", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.TestBeamSearch.test_advance_with_all_repeats_gets_blocked": [[31, 60], ["onmt.translate.beam_search.BeamSearch", "range", "torch.device", "test_beam_search.GlobalScorerStub", "set", "torch.randint", "torch.full", "torch.randn", "onmt.translate.beam_search.BeamSearch.advance", "torch.tensor().repeat", "test_beam_search.TestBeamSearch.assertTrue", "test_beam_search.TestBeamSearch.assertTrue", "float", "onmt.translate.beam_search.BeamSearch.topk_log_probs.equal", "onmt.translate.beam_search.BeamSearch.topk_log_probs.equal", "torch.tensor", "torch.tensor().repeat", "torch.tensor", "float"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance"], ["def", "test_advance_with_all_repeats_gets_blocked", "(", "self", ")", ":", "\n", "# all beams repeat (beam >= 1 repeat dummy scores)", "\n", "        ", "beam_sz", "=", "5", "\n", "n_words", "=", "100", "\n", "repeat_idx", "=", "47", "\n", "ngram_repeat", "=", "3", "\n", "for", "batch_sz", "in", "[", "1", ",", "3", "]", ":", "\n", "            ", "beam", "=", "BeamSearch", "(", "\n", "beam_sz", ",", "batch_sz", ",", "0", ",", "1", ",", "2", ",", "2", ",", "\n", "torch", ".", "device", "(", "\"cpu\"", ")", ",", "GlobalScorerStub", "(", ")", ",", "0", ",", "30", ",", "\n", "False", ",", "ngram_repeat", ",", "set", "(", ")", ",", "\n", "torch", ".", "randint", "(", "0", ",", "30", ",", "(", "batch_sz", ",", ")", ")", ",", "False", ")", "\n", "for", "i", "in", "range", "(", "ngram_repeat", "+", "4", ")", ":", "\n", "# predict repeat_idx over and over again", "\n", "                ", "word_probs", "=", "torch", ".", "full", "(", "\n", "(", "batch_sz", "*", "beam_sz", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "word_probs", "[", "0", ":", ":", "beam_sz", ",", "repeat_idx", "]", "=", "0", "\n", "attns", "=", "torch", ".", "randn", "(", "1", ",", "batch_sz", "*", "beam_sz", ",", "53", ")", "\n", "beam", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "if", "i", "<=", "ngram_repeat", ":", "\n", "                    ", "expected_scores", "=", "torch", ".", "tensor", "(", "\n", "[", "0", "]", "+", "[", "-", "float", "(", "'inf'", ")", "]", "*", "(", "beam_sz", "-", "1", ")", ")", ".", "repeat", "(", "batch_sz", ",", "1", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "topk_log_probs", ".", "equal", "(", "expected_scores", ")", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "assertTrue", "(", "\n", "beam", ".", "topk_log_probs", ".", "equal", "(", "\n", "torch", ".", "tensor", "(", "self", ".", "BLOCKED_SCORE", ")", "\n", ".", "repeat", "(", "batch_sz", ",", "beam_sz", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.TestBeamSearch.test_advance_with_some_repeats_gets_blocked": [[61, 106], ["onmt.translate.beam_search.BeamSearch", "range", "torch.device", "test_beam_search.GlobalScorerStub", "set", "torch.randint", "torch.full", "torch.randn", "onmt.translate.beam_search.BeamSearch.advance", "test_beam_search.TestBeamSearch.assertFalse", "test_beam_search.TestBeamSearch.assertFalse", "test_beam_search.TestBeamSearch.assertFalse", "test_beam_search.TestBeamSearch.assertTrue", "float", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq().any", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq().any", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq().any", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].equal", "torch.tensor().repeat", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance"], ["", "", "", "", "def", "test_advance_with_some_repeats_gets_blocked", "(", "self", ")", ":", "\n", "# beam 0 and beam >=2 will repeat (beam >= 2 repeat dummy scores)", "\n", "        ", "beam_sz", "=", "5", "\n", "n_words", "=", "100", "\n", "repeat_idx", "=", "47", "\n", "ngram_repeat", "=", "3", "\n", "for", "batch_sz", "in", "[", "1", ",", "3", "]", ":", "\n", "            ", "beam", "=", "BeamSearch", "(", "\n", "beam_sz", ",", "batch_sz", ",", "0", ",", "1", ",", "2", ",", "2", ",", "\n", "torch", ".", "device", "(", "\"cpu\"", ")", ",", "GlobalScorerStub", "(", ")", ",", "0", ",", "30", ",", "\n", "False", ",", "ngram_repeat", ",", "set", "(", ")", ",", "\n", "torch", ".", "randint", "(", "0", ",", "30", ",", "(", "batch_sz", ",", ")", ")", ",", "False", ")", "\n", "for", "i", "in", "range", "(", "ngram_repeat", "+", "4", ")", ":", "\n", "# non-interesting beams are going to get dummy values", "\n", "                ", "word_probs", "=", "torch", ".", "full", "(", "\n", "(", "batch_sz", "*", "beam_sz", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "if", "i", "==", "0", ":", "\n", "# on initial round, only predicted scores for beam 0", "\n", "# matter. Make two predictions. Top one will be repeated", "\n", "# in beam zero, second one will live on in beam 1.", "\n", "                    ", "word_probs", "[", "0", ":", ":", "beam_sz", ",", "repeat_idx", "]", "=", "-", "0.1", "\n", "word_probs", "[", "0", ":", ":", "beam_sz", ",", "repeat_idx", "+", "i", "+", "1", "]", "=", "-", "2.3", "\n", "", "else", ":", "\n", "# predict the same thing in beam 0", "\n", "                    ", "word_probs", "[", "0", ":", ":", "beam_sz", ",", "repeat_idx", "]", "=", "0", "\n", "# continue pushing around what beam 1 predicts", "\n", "word_probs", "[", "1", ":", ":", "beam_sz", ",", "repeat_idx", "+", "i", "+", "1", "]", "=", "0", "\n", "", "attns", "=", "torch", ".", "randn", "(", "1", ",", "batch_sz", "*", "beam_sz", ",", "53", ")", "\n", "beam", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "if", "i", "<=", "ngram_repeat", ":", "\n", "                    ", "self", ".", "assertFalse", "(", "\n", "beam", ".", "topk_log_probs", "[", "0", ":", ":", "beam_sz", "]", ".", "eq", "(", "\n", "self", ".", "BLOCKED_SCORE", ")", ".", "any", "(", ")", ")", "\n", "self", ".", "assertFalse", "(", "\n", "beam", ".", "topk_log_probs", "[", "1", ":", ":", "beam_sz", "]", ".", "eq", "(", "\n", "self", ".", "BLOCKED_SCORE", ")", ".", "any", "(", ")", ")", "\n", "", "else", ":", "\n", "# now beam 0 dies (along with the others), beam 1 -> beam 0", "\n", "                    ", "self", ".", "assertFalse", "(", "\n", "beam", ".", "topk_log_probs", "[", ":", ",", "0", "]", ".", "eq", "(", "\n", "self", ".", "BLOCKED_SCORE", ")", ".", "any", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "\n", "beam", ".", "topk_log_probs", "[", ":", ",", "1", ":", "]", ".", "equal", "(", "\n", "torch", ".", "tensor", "(", "self", ".", "BLOCKED_SCORE", ")", "\n", ".", "repeat", "(", "batch_sz", ",", "beam_sz", "-", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.TestBeamSearch.test_repeating_excluded_index_does_not_die": [[107, 160], ["onmt.translate.beam_search.BeamSearch", "range", "torch.device", "test_beam_search.GlobalScorerStub", "torch.randint", "torch.full", "torch.randn", "onmt.translate.beam_search.BeamSearch.advance", "test_beam_search.TestBeamSearch.assertFalse", "test_beam_search.TestBeamSearch.assertFalse", "test_beam_search.TestBeamSearch.assertFalse", "test_beam_search.TestBeamSearch.assertFalse", "test_beam_search.TestBeamSearch.assertTrue", "test_beam_search.TestBeamSearch.assertFalse", "test_beam_search.TestBeamSearch.assertTrue", "test_beam_search.TestBeamSearch.assertTrue", "float", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq().any", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq().any", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq().any", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq().any", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq().all", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq().all", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq().all", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].equal", "torch.tensor().repeat", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq", "onmt.translate.beam_search.BeamSearch.topk_log_probs[].eq", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance"], ["", "", "", "", "def", "test_repeating_excluded_index_does_not_die", "(", "self", ")", ":", "\n", "# beam 0 and beam >= 2 will repeat (beam 2 repeats excluded idx)", "\n", "        ", "beam_sz", "=", "5", "\n", "n_words", "=", "100", "\n", "repeat_idx", "=", "47", "# will be repeated and should be blocked", "\n", "repeat_idx_ignored", "=", "7", "# will be repeated and should not be blocked", "\n", "ngram_repeat", "=", "3", "\n", "for", "batch_sz", "in", "[", "1", ",", "3", "]", ":", "\n", "            ", "beam", "=", "BeamSearch", "(", "\n", "beam_sz", ",", "batch_sz", ",", "0", ",", "1", ",", "2", ",", "2", ",", "\n", "torch", ".", "device", "(", "\"cpu\"", ")", ",", "GlobalScorerStub", "(", ")", ",", "0", ",", "30", ",", "\n", "False", ",", "ngram_repeat", ",", "{", "repeat_idx_ignored", "}", ",", "\n", "torch", ".", "randint", "(", "0", ",", "30", ",", "(", "batch_sz", ",", ")", ")", ",", "False", ")", "\n", "for", "i", "in", "range", "(", "ngram_repeat", "+", "4", ")", ":", "\n", "# non-interesting beams are going to get dummy values", "\n", "                ", "word_probs", "=", "torch", ".", "full", "(", "\n", "(", "batch_sz", "*", "beam_sz", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "if", "i", "==", "0", ":", "\n", "                    ", "word_probs", "[", "0", ":", ":", "beam_sz", ",", "repeat_idx", "]", "=", "-", "0.1", "\n", "word_probs", "[", "0", ":", ":", "beam_sz", ",", "repeat_idx", "+", "i", "+", "1", "]", "=", "-", "2.3", "\n", "word_probs", "[", "0", ":", ":", "beam_sz", ",", "repeat_idx_ignored", "]", "=", "-", "5.0", "\n", "", "else", ":", "\n", "# predict the same thing in beam 0", "\n", "                    ", "word_probs", "[", "0", ":", ":", "beam_sz", ",", "repeat_idx", "]", "=", "0", "\n", "# continue pushing around what beam 1 predicts", "\n", "word_probs", "[", "1", ":", ":", "beam_sz", ",", "repeat_idx", "+", "i", "+", "1", "]", "=", "0", "\n", "# predict the allowed-repeat again in beam 2", "\n", "word_probs", "[", "2", ":", ":", "beam_sz", ",", "repeat_idx_ignored", "]", "=", "0", "\n", "", "attns", "=", "torch", ".", "randn", "(", "1", ",", "batch_sz", "*", "beam_sz", ",", "53", ")", "\n", "beam", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "if", "i", "<=", "ngram_repeat", ":", "\n", "                    ", "self", ".", "assertFalse", "(", "beam", ".", "topk_log_probs", "[", ":", ",", "0", "]", ".", "eq", "(", "\n", "self", ".", "BLOCKED_SCORE", ")", ".", "any", "(", ")", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "topk_log_probs", "[", ":", ",", "1", "]", ".", "eq", "(", "\n", "self", ".", "BLOCKED_SCORE", ")", ".", "any", "(", ")", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "topk_log_probs", "[", ":", ",", "2", "]", ".", "eq", "(", "\n", "self", ".", "BLOCKED_SCORE", ")", ".", "any", "(", ")", ")", "\n", "", "else", ":", "\n", "# now beam 0 dies, beam 1 -> beam 0, beam 2 -> beam 1", "\n", "# and the rest die", "\n", "                    ", "self", ".", "assertFalse", "(", "beam", ".", "topk_log_probs", "[", ":", ",", "0", "]", ".", "eq", "(", "\n", "self", ".", "BLOCKED_SCORE", ")", ".", "any", "(", ")", ")", "\n", "# since all preds after i=0 are 0, we can check", "\n", "# that the beam is the correct idx by checking that", "\n", "# the curr score is the initial score", "\n", "self", ".", "assertTrue", "(", "beam", ".", "topk_log_probs", "[", ":", ",", "0", "]", ".", "eq", "(", "-", "2.3", ")", ".", "all", "(", ")", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "topk_log_probs", "[", ":", ",", "1", "]", ".", "eq", "(", "\n", "self", ".", "BLOCKED_SCORE", ")", ".", "all", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "topk_log_probs", "[", ":", ",", "1", "]", ".", "eq", "(", "-", "5.0", ")", ".", "all", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "\n", "beam", ".", "topk_log_probs", "[", ":", ",", "2", ":", "]", ".", "equal", "(", "\n", "torch", ".", "tensor", "(", "self", ".", "BLOCKED_SCORE", ")", "\n", ".", "repeat", "(", "batch_sz", ",", "beam_sz", "-", "2", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.TestBeamSearch.test_doesnt_predict_eos_if_shorter_than_min_len": [[161, 215], ["torch.log_softmax", "torch.randint", "onmt.translate.beam_search.BeamSearch", "range", "torch.tensor", "torch.device", "test_beam_search.GlobalScorerStub", "set", "torch.full", "torch.randn", "all_attns.append", "onmt.translate.beam_search.BeamSearch.advance", "zip", "enumerate", "test_beam_search.TestBeamSearch.assertTrue", "float", "zip", "min", "valid_score_dist[].unsqueeze", "onmt.translate.beam_search.BeamSearch.topk_log_probs.allclose", "test_beam_search.TestBeamSearch.assertTrue", "test_beam_search.TestBeamSearch.assertTrue", "onmt.translate.beam_search.BeamSearch.is_finished[].eq().all", "onmt.translate.beam_search.BeamSearch.is_finished[].eq().all", "onmt.translate.beam_search.BeamSearch.is_finished[].eq", "onmt.translate.beam_search.BeamSearch.is_finished[].eq"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance"], ["", "", "", "", "def", "test_doesnt_predict_eos_if_shorter_than_min_len", "(", "self", ")", ":", "\n", "# beam 0 will always predict EOS. The other beams will predict", "\n", "# non-eos scores.", "\n", "        ", "for", "batch_sz", "in", "[", "1", ",", "3", "]", ":", "\n", "            ", "beam_sz", "=", "5", "\n", "n_words", "=", "100", "\n", "_non_eos_idxs", "=", "[", "47", ",", "51", ",", "13", ",", "88", ",", "99", "]", "\n", "valid_score_dist", "=", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "\n", "[", "6.", ",", "5.", ",", "4.", ",", "3.", ",", "2.", ",", "1.", "]", ")", ",", "dim", "=", "0", ")", "\n", "min_length", "=", "5", "\n", "eos_idx", "=", "2", "\n", "lengths", "=", "torch", ".", "randint", "(", "0", ",", "30", ",", "(", "batch_sz", ",", ")", ")", "\n", "beam", "=", "BeamSearch", "(", "beam_sz", ",", "batch_sz", ",", "0", ",", "1", ",", "2", ",", "2", ",", "\n", "torch", ".", "device", "(", "\"cpu\"", ")", ",", "GlobalScorerStub", "(", ")", ",", "\n", "min_length", ",", "30", ",", "False", ",", "0", ",", "set", "(", ")", ",", "\n", "lengths", ",", "False", ")", "\n", "all_attns", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "min_length", "+", "4", ")", ":", "\n", "# non-interesting beams are going to get dummy values", "\n", "                ", "word_probs", "=", "torch", ".", "full", "(", "\n", "(", "batch_sz", "*", "beam_sz", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "if", "i", "==", "0", ":", "\n", "# \"best\" prediction is eos - that should be blocked", "\n", "                    ", "word_probs", "[", "0", ":", ":", "beam_sz", ",", "eos_idx", "]", "=", "valid_score_dist", "[", "0", "]", "\n", "# include at least beam_sz predictions OTHER than EOS", "\n", "# that are greater than -1e20", "\n", "for", "j", ",", "score", "in", "zip", "(", "_non_eos_idxs", ",", "valid_score_dist", "[", "1", ":", "]", ")", ":", "\n", "                        ", "word_probs", "[", "0", ":", ":", "beam_sz", ",", "j", "]", "=", "score", "\n", "", "", "else", ":", "\n", "# predict eos in beam 0", "\n", "                    ", "word_probs", "[", "0", ":", ":", "beam_sz", ",", "eos_idx", "]", "=", "valid_score_dist", "[", "0", "]", "\n", "# provide beam_sz other good predictions", "\n", "for", "k", ",", "(", "j", ",", "score", ")", "in", "enumerate", "(", "\n", "zip", "(", "_non_eos_idxs", ",", "valid_score_dist", "[", "1", ":", "]", ")", ")", ":", "\n", "                        ", "beam_idx", "=", "min", "(", "beam_sz", "-", "1", ",", "k", ")", "\n", "word_probs", "[", "beam_idx", ":", ":", "beam_sz", ",", "j", "]", "=", "score", "\n", "\n", "", "", "attns", "=", "torch", ".", "randn", "(", "1", ",", "batch_sz", "*", "beam_sz", ",", "53", ")", "\n", "all_attns", ".", "append", "(", "attns", ")", "\n", "beam", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "if", "i", "<", "min_length", ":", "\n", "                    ", "expected_score_dist", "=", "(", "i", "+", "1", ")", "*", "valid_score_dist", "[", "1", ":", "]", ".", "unsqueeze", "(", "0", ")", "\n", "self", ".", "assertTrue", "(", "\n", "beam", ".", "topk_log_probs", ".", "allclose", "(", "\n", "expected_score_dist", ")", ")", "\n", "", "elif", "i", "==", "min_length", ":", "\n", "# now the top beam has ended and no others have", "\n", "                    ", "self", ".", "assertTrue", "(", "beam", ".", "is_finished", "[", ":", ",", "0", "]", ".", "eq", "(", "1", ")", ".", "all", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "is_finished", "[", ":", ",", "1", ":", "]", ".", "eq", "(", "0", ")", ".", "all", "(", ")", ")", "\n", "", "else", ":", "# i > min_length", "\n", "# not of interest, but want to make sure it keeps running", "\n", "# since only beam 0 terminates and n_best = 2", "\n", "                    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.TestBeamSearch.test_beam_is_done_when_n_best_beams_eos_using_min_length": [[216, 274], ["torch.log_softmax", "onmt.translate.beam_search.BeamSearch", "range", "torch.tensor", "torch.device", "test_beam_search.GlobalScorerStub", "set", "torch.randint", "torch.full", "torch.randn", "onmt.translate.beam_search.BeamSearch.advance", "zip", "test_beam_search.TestBeamSearch.assertFalse", "float", "enumerate", "enumerate", "test_beam_search.TestBeamSearch.assertTrue", "onmt.translate.beam_search.BeamSearch.update_finished", "test_beam_search.TestBeamSearch.assertFalse", "test_beam_search.TestBeamSearch.assertTrue", "onmt.translate.beam_search.BeamSearch.update_finished", "test_beam_search.TestBeamSearch.assertTrue", "zip", "min", "zip", "min", "onmt.translate.beam_search.BeamSearch.is_finished[].all", "onmt.translate.beam_search.BeamSearch.is_finished[].all"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished"], ["", "", "", "", "def", "test_beam_is_done_when_n_best_beams_eos_using_min_length", "(", "self", ")", ":", "\n", "# this is also a test that when block_ngram_repeat=0,", "\n", "# repeating is acceptable", "\n", "        ", "beam_sz", "=", "5", "\n", "batch_sz", "=", "3", "\n", "n_words", "=", "100", "\n", "_non_eos_idxs", "=", "[", "47", ",", "51", ",", "13", ",", "88", ",", "99", "]", "\n", "valid_score_dist", "=", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "\n", "[", "6.", ",", "5.", ",", "4.", ",", "3.", ",", "2.", ",", "1.", "]", ")", ",", "dim", "=", "0", ")", "\n", "min_length", "=", "5", "\n", "eos_idx", "=", "2", "\n", "beam", "=", "BeamSearch", "(", "\n", "beam_sz", ",", "batch_sz", ",", "0", ",", "1", ",", "2", ",", "2", ",", "\n", "torch", ".", "device", "(", "\"cpu\"", ")", ",", "GlobalScorerStub", "(", ")", ",", "\n", "min_length", ",", "30", ",", "False", ",", "0", ",", "set", "(", ")", ",", "\n", "torch", ".", "randint", "(", "0", ",", "30", ",", "(", "batch_sz", ",", ")", ")", ",", "False", ")", "\n", "for", "i", "in", "range", "(", "min_length", "+", "4", ")", ":", "\n", "# non-interesting beams are going to get dummy values", "\n", "            ", "word_probs", "=", "torch", ".", "full", "(", "\n", "(", "batch_sz", "*", "beam_sz", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "if", "i", "==", "0", ":", "\n", "# \"best\" prediction is eos - that should be blocked", "\n", "                ", "word_probs", "[", "0", ":", ":", "beam_sz", ",", "eos_idx", "]", "=", "valid_score_dist", "[", "0", "]", "\n", "# include at least beam_sz predictions OTHER than EOS", "\n", "# that are greater than -1e20", "\n", "for", "j", ",", "score", "in", "zip", "(", "_non_eos_idxs", ",", "valid_score_dist", "[", "1", ":", "]", ")", ":", "\n", "                    ", "word_probs", "[", "0", ":", ":", "beam_sz", ",", "j", "]", "=", "score", "\n", "", "", "elif", "i", "<=", "min_length", ":", "\n", "# predict eos in beam 1", "\n", "                ", "word_probs", "[", "1", ":", ":", "beam_sz", ",", "eos_idx", "]", "=", "valid_score_dist", "[", "0", "]", "\n", "# provide beam_sz other good predictions in other beams", "\n", "for", "k", ",", "(", "j", ",", "score", ")", "in", "enumerate", "(", "\n", "zip", "(", "_non_eos_idxs", ",", "valid_score_dist", "[", "1", ":", "]", ")", ")", ":", "\n", "                    ", "beam_idx", "=", "min", "(", "beam_sz", "-", "1", ",", "k", ")", "\n", "word_probs", "[", "beam_idx", ":", ":", "beam_sz", ",", "j", "]", "=", "score", "\n", "", "", "else", ":", "\n", "                ", "word_probs", "[", "0", ":", ":", "beam_sz", ",", "eos_idx", "]", "=", "valid_score_dist", "[", "0", "]", "\n", "word_probs", "[", "1", ":", ":", "beam_sz", ",", "eos_idx", "]", "=", "valid_score_dist", "[", "0", "]", "\n", "# provide beam_sz other good predictions in other beams", "\n", "for", "k", ",", "(", "j", ",", "score", ")", "in", "enumerate", "(", "\n", "zip", "(", "_non_eos_idxs", ",", "valid_score_dist", "[", "1", ":", "]", ")", ")", ":", "\n", "                    ", "beam_idx", "=", "min", "(", "beam_sz", "-", "1", ",", "k", ")", "\n", "word_probs", "[", "beam_idx", ":", ":", "beam_sz", ",", "j", "]", "=", "score", "\n", "\n", "", "", "attns", "=", "torch", ".", "randn", "(", "1", ",", "batch_sz", "*", "beam_sz", ",", "53", ")", "\n", "beam", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "if", "i", "<", "min_length", ":", "\n", "                ", "self", ".", "assertFalse", "(", "beam", ".", "done", ")", "\n", "", "elif", "i", "==", "min_length", ":", "\n", "# beam 1 dies on min_length", "\n", "                ", "self", ".", "assertTrue", "(", "beam", ".", "is_finished", "[", ":", ",", "1", "]", ".", "all", "(", ")", ")", "\n", "beam", ".", "update_finished", "(", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "done", ")", "\n", "", "else", ":", "# i > min_length", "\n", "# beam 0 dies on the step after beam 1 dies", "\n", "                ", "self", ".", "assertTrue", "(", "beam", ".", "is_finished", "[", ":", ",", "0", "]", ".", "all", "(", ")", ")", "\n", "beam", ".", "update_finished", "(", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "done", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.TestBeamSearch.test_beam_returns_attn_with_correct_length": [[275, 353], ["torch.log_softmax", "torch.randint", "onmt.translate.beam_search.BeamSearch", "range", "torch.tensor", "torch.device", "test_beam_search.GlobalScorerStub", "set", "torch.full", "torch.randn", "onmt.translate.beam_search.BeamSearch.advance", "zip", "test_beam_search.TestBeamSearch.assertFalse", "range", "float", "enumerate", "enumerate", "test_beam_search.TestBeamSearch.assertEqual", "test_beam_search.TestBeamSearch.assertTrue", "onmt.translate.beam_search.BeamSearch.update_finished", "test_beam_search.TestBeamSearch.assertFalse", "range", "test_beam_search.TestBeamSearch.assertTrue", "onmt.translate.beam_search.BeamSearch.update_finished", "test_beam_search.TestBeamSearch.assertTrue", "range", "zip", "min", "zip", "min", "onmt.translate.beam_search.BeamSearch.is_finished[].all", "test_beam_search.TestBeamSearch.assertEqual", "onmt.translate.beam_search.BeamSearch.is_finished[].all", "test_beam_search.TestBeamSearch.assertEqual", "range", "test_beam_search.TestBeamSearch.assertEqual", "test_beam_search.TestBeamSearch.assertEqual", "len", "test_beam_search.TestBeamSearch.assertEqual"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished"], ["", "", "", "def", "test_beam_returns_attn_with_correct_length", "(", "self", ")", ":", "\n", "        ", "beam_sz", "=", "5", "\n", "batch_sz", "=", "3", "\n", "n_words", "=", "100", "\n", "_non_eos_idxs", "=", "[", "47", ",", "51", ",", "13", ",", "88", ",", "99", "]", "\n", "valid_score_dist", "=", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "\n", "[", "6.", ",", "5.", ",", "4.", ",", "3.", ",", "2.", ",", "1.", "]", ")", ",", "dim", "=", "0", ")", "\n", "min_length", "=", "5", "\n", "eos_idx", "=", "2", "\n", "inp_lens", "=", "torch", ".", "randint", "(", "1", ",", "30", ",", "(", "batch_sz", ",", ")", ")", "\n", "beam", "=", "BeamSearch", "(", "\n", "beam_sz", ",", "batch_sz", ",", "0", ",", "1", ",", "2", ",", "2", ",", "\n", "torch", ".", "device", "(", "\"cpu\"", ")", ",", "GlobalScorerStub", "(", ")", ",", "\n", "min_length", ",", "30", ",", "True", ",", "0", ",", "set", "(", ")", ",", "\n", "inp_lens", ",", "False", ")", "\n", "for", "i", "in", "range", "(", "min_length", "+", "2", ")", ":", "\n", "# non-interesting beams are going to get dummy values", "\n", "            ", "word_probs", "=", "torch", ".", "full", "(", "\n", "(", "batch_sz", "*", "beam_sz", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "if", "i", "==", "0", ":", "\n", "# \"best\" prediction is eos - that should be blocked", "\n", "                ", "word_probs", "[", "0", ":", ":", "beam_sz", ",", "eos_idx", "]", "=", "valid_score_dist", "[", "0", "]", "\n", "# include at least beam_sz predictions OTHER than EOS", "\n", "# that are greater than -1e20", "\n", "for", "j", ",", "score", "in", "zip", "(", "_non_eos_idxs", ",", "valid_score_dist", "[", "1", ":", "]", ")", ":", "\n", "                    ", "word_probs", "[", "0", ":", ":", "beam_sz", ",", "j", "]", "=", "score", "\n", "", "", "elif", "i", "<=", "min_length", ":", "\n", "# predict eos in beam 1", "\n", "                ", "word_probs", "[", "1", ":", ":", "beam_sz", ",", "eos_idx", "]", "=", "valid_score_dist", "[", "0", "]", "\n", "# provide beam_sz other good predictions in other beams", "\n", "for", "k", ",", "(", "j", ",", "score", ")", "in", "enumerate", "(", "\n", "zip", "(", "_non_eos_idxs", ",", "valid_score_dist", "[", "1", ":", "]", ")", ")", ":", "\n", "                    ", "beam_idx", "=", "min", "(", "beam_sz", "-", "1", ",", "k", ")", "\n", "word_probs", "[", "beam_idx", ":", ":", "beam_sz", ",", "j", "]", "=", "score", "\n", "", "", "else", ":", "\n", "                ", "word_probs", "[", "0", ":", ":", "beam_sz", ",", "eos_idx", "]", "=", "valid_score_dist", "[", "0", "]", "\n", "word_probs", "[", "1", ":", ":", "beam_sz", ",", "eos_idx", "]", "=", "valid_score_dist", "[", "0", "]", "\n", "# provide beam_sz other good predictions in other beams", "\n", "for", "k", ",", "(", "j", ",", "score", ")", "in", "enumerate", "(", "\n", "zip", "(", "_non_eos_idxs", ",", "valid_score_dist", "[", "1", ":", "]", ")", ")", ":", "\n", "                    ", "beam_idx", "=", "min", "(", "beam_sz", "-", "1", ",", "k", ")", "\n", "word_probs", "[", "beam_idx", ":", ":", "beam_sz", ",", "j", "]", "=", "score", "\n", "\n", "", "", "attns", "=", "torch", ".", "randn", "(", "1", ",", "batch_sz", "*", "beam_sz", ",", "53", ")", "\n", "beam", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "if", "i", "<", "min_length", ":", "\n", "                ", "self", ".", "assertFalse", "(", "beam", ".", "done", ")", "\n", "# no top beams are finished yet", "\n", "for", "b", "in", "range", "(", "batch_sz", ")", ":", "\n", "                    ", "self", ".", "assertEqual", "(", "beam", ".", "attention", "[", "b", "]", ",", "[", "]", ")", "\n", "", "", "elif", "i", "==", "min_length", ":", "\n", "# beam 1 dies on min_length", "\n", "                ", "self", ".", "assertTrue", "(", "beam", ".", "is_finished", "[", ":", ",", "1", "]", ".", "all", "(", ")", ")", "\n", "beam", ".", "update_finished", "(", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "done", ")", "\n", "# no top beams are finished yet", "\n", "for", "b", "in", "range", "(", "batch_sz", ")", ":", "\n", "                    ", "self", ".", "assertEqual", "(", "beam", ".", "attention", "[", "b", "]", ",", "[", "]", ")", "\n", "", "", "else", ":", "# i > min_length", "\n", "# beam 0 dies on the step after beam 1 dies", "\n", "                ", "self", ".", "assertTrue", "(", "beam", ".", "is_finished", "[", ":", ",", "0", "]", ".", "all", "(", ")", ")", "\n", "beam", ".", "update_finished", "(", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "done", ")", "\n", "# top beam is finished now so there are attentions", "\n", "for", "b", "in", "range", "(", "batch_sz", ")", ":", "\n", "# two beams are finished in each batch", "\n", "                    ", "self", ".", "assertEqual", "(", "len", "(", "beam", ".", "attention", "[", "b", "]", ")", ",", "2", ")", "\n", "for", "k", "in", "range", "(", "2", ")", ":", "\n", "# second dim is cut down to the non-padded src length", "\n", "                        ", "self", ".", "assertEqual", "(", "beam", ".", "attention", "[", "b", "]", "[", "k", "]", ".", "shape", "[", "-", "1", "]", ",", "\n", "inp_lens", "[", "b", "]", ")", "\n", "# first dim is equal to the time of death", "\n", "# (beam 0 died at current step - adjust for SOS)", "\n", "", "self", ".", "assertEqual", "(", "beam", ".", "attention", "[", "b", "]", "[", "0", "]", ".", "shape", "[", "0", "]", ",", "i", "+", "1", ")", "\n", "# (beam 1 died at last step - adjust for SOS)", "\n", "self", ".", "assertEqual", "(", "beam", ".", "attention", "[", "b", "]", "[", "1", "]", ".", "shape", "[", "0", "]", ",", "i", ")", "\n", "# behavior gets weird when beam is already done so just stop", "\n", "", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.TestBeamSearchAgainstReferenceCase.random_attn": [[366, 368], ["torch.randn"], "methods", ["None"], ["def", "random_attn", "(", "self", ")", ":", "\n", "        ", "return", "torch", ".", "randn", "(", "1", ",", "self", ".", "BATCH_SZ", "*", "self", ".", "BEAM_SZ", ",", "self", ".", "INP_SEQ_LEN", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.TestBeamSearchAgainstReferenceCase.init_step": [[369, 385], ["torch.log_softmax", "copy.deepcopy", "new_scores.view().topk", "beam.advance", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertFalse", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertFalse", "torch.tensor", "copy.deepcopy.repeat", "beam.topk_log_probs.view().unsqueeze", "copy.deepcopy", "test_beam_search.TestBeamSearchAgainstReferenceCase.random_attn", "beam.topk_log_probs.allclose", "beam.topk_ids.equal", "beam.is_finished.any", "new_scores.view", "beam.topk_log_probs.view"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.TestBeamSearchAgainstReferenceCase.random_attn"], ["", "def", "init_step", "(", "self", ",", "beam", ",", "expected_len_pen", ")", ":", "\n", "# init_preds: [4, 3, 5, 6, 7] - no EOS's", "\n", "        ", "init_scores", "=", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "\n", "[", "[", "0", ",", "0", ",", "0", ",", "4", ",", "5", ",", "3", ",", "2", ",", "1", "]", "]", ",", "dtype", "=", "torch", ".", "float", ")", ",", "dim", "=", "1", ")", "\n", "init_scores", "=", "deepcopy", "(", "init_scores", ".", "repeat", "(", "\n", "self", ".", "BATCH_SZ", "*", "self", ".", "BEAM_SZ", ",", "1", ")", ")", "\n", "new_scores", "=", "init_scores", "+", "beam", ".", "topk_log_probs", ".", "view", "(", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "expected_beam_scores", ",", "expected_preds_0", "=", "new_scores", ".", "view", "(", "self", ".", "BATCH_SZ", ",", "self", ".", "BEAM_SZ", "*", "self", ".", "N_WORDS", ")", ".", "topk", "(", "self", ".", "BEAM_SZ", ",", "dim", "=", "-", "1", ")", "\n", "beam", ".", "advance", "(", "deepcopy", "(", "init_scores", ")", ",", "self", ".", "random_attn", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "topk_log_probs", ".", "allclose", "(", "expected_beam_scores", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "topk_ids", ".", "equal", "(", "expected_preds_0", ")", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "is_finished", ".", "any", "(", ")", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "done", ")", "\n", "return", "expected_beam_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.TestBeamSearchAgainstReferenceCase.first_step": [[386, 418], ["torch.log_softmax", "scores_1.repeat.repeat.repeat", "beam.advance", "new_scores.view().topk", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertEqual", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "beam.update_finished", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertFalse", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertFalse", "beam.is_finished.sum", "torch.tensor", "copy.deepcopy", "test_beam_search.TestBeamSearchAgainstReferenceCase.random_attn", "expected_beam_scores.view().unsqueeze", "beam.topk_log_probs.allclose", "beam.topk_scores.allclose", "beam.topk_ids.equal", "beam.current_backptr.equal", "beam.is_finished.sum", "beam.is_finished[].all", "beam.top_beam_finished.any", "new_scores.view", "expected_beam_scores.view"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.TestBeamSearchAgainstReferenceCase.random_attn"], ["", "def", "first_step", "(", "self", ",", "beam", ",", "expected_beam_scores", ",", "expected_len_pen", ")", ":", "\n", "# no EOS's yet", "\n", "        ", "assert", "beam", ".", "is_finished", ".", "sum", "(", ")", "==", "0", "\n", "scores_1", "=", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "\n", "[", "[", "0", ",", "0", ",", "0", ",", ".3", ",", "0", ",", ".51", ",", ".2", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "1.5", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", ".49", ",", ".48", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", ".2", ",", ".2", ",", ".2", ",", ".2", ",", ".2", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", ".2", ",", ".2", ",", ".2", ",", ".2", ",", ".2", "]", "]", "\n", ")", ",", "dim", "=", "1", ")", "\n", "scores_1", "=", "scores_1", ".", "repeat", "(", "self", ".", "BATCH_SZ", ",", "1", ")", "\n", "\n", "beam", ".", "advance", "(", "deepcopy", "(", "scores_1", ")", ",", "self", ".", "random_attn", "(", ")", ")", "\n", "\n", "new_scores", "=", "scores_1", "+", "expected_beam_scores", ".", "view", "(", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "expected_beam_scores", ",", "unreduced_preds", "=", "new_scores", ".", "view", "(", "self", ".", "BATCH_SZ", ",", "self", ".", "BEAM_SZ", "*", "self", ".", "N_WORDS", ")", ".", "topk", "(", "self", ".", "BEAM_SZ", ",", "-", "1", ")", "\n", "expected_bptr_1", "=", "unreduced_preds", "/", "self", ".", "N_WORDS", "\n", "# [5, 3, 2, 6, 0], so beam 2 predicts EOS!", "\n", "expected_preds_1", "=", "unreduced_preds", "-", "expected_bptr_1", "*", "self", ".", "N_WORDS", "\n", "self", ".", "assertTrue", "(", "beam", ".", "topk_log_probs", ".", "allclose", "(", "expected_beam_scores", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "topk_scores", ".", "allclose", "(", "\n", "expected_beam_scores", "/", "expected_len_pen", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "topk_ids", ".", "equal", "(", "expected_preds_1", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "current_backptr", ".", "equal", "(", "expected_bptr_1", ")", ")", "\n", "self", ".", "assertEqual", "(", "beam", ".", "is_finished", ".", "sum", "(", ")", ",", "self", ".", "BATCH_SZ", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "is_finished", "[", ":", ",", "2", "]", ".", "all", "(", ")", ")", "# beam 2 finished", "\n", "beam", ".", "update_finished", "(", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "top_beam_finished", ".", "any", "(", ")", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "done", ")", "\n", "return", "expected_beam_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.TestBeamSearchAgainstReferenceCase.second_step": [[419, 457], ["torch.log_softmax", "scores_2.repeat.repeat.repeat", "beam.advance", "new_scores.view().topk", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertEqual", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "beam.update_finished", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertFalse", "torch.tensor", "copy.deepcopy", "test_beam_search.TestBeamSearchAgainstReferenceCase.random_attn", "expected_beam_scores.view().unsqueeze", "beam.topk_log_probs.allclose", "beam.topk_scores.allclose", "beam.topk_ids.equal", "beam.current_backptr.equal", "beam.is_finished.sum", "beam.is_finished[].all", "expected_bptr_2[].eq().all", "beam.top_beam_finished.all", "new_scores.view", "expected_beam_scores.view", "expected_bptr_2[].eq"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.TestBeamSearchAgainstReferenceCase.random_attn"], ["", "def", "second_step", "(", "self", ",", "beam", ",", "expected_beam_scores", ",", "expected_len_pen", ")", ":", "\n", "# assumes beam 2 finished on last step", "\n", "        ", "scores_2", "=", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "\n", "[", "[", "0", ",", "0", ",", "0", ",", ".3", ",", "0", ",", ".51", ",", ".2", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "5000", ",", ".48", ",", "0", ",", "0", "]", ",", "# beam 2 shouldn't continue", "\n", "[", "0", ",", "0", ",", "50", ",", ".2", ",", ".2", ",", ".2", ",", ".2", ",", ".2", "]", ",", "# beam 3 -> beam 0 should die", "\n", "[", "0", ",", "0", ",", "0", ",", ".2", ",", ".2", ",", ".2", ",", ".2", ",", ".2", "]", "]", "\n", ")", ",", "dim", "=", "1", ")", "\n", "scores_2", "=", "scores_2", ".", "repeat", "(", "self", ".", "BATCH_SZ", ",", "1", ")", "\n", "\n", "beam", ".", "advance", "(", "deepcopy", "(", "scores_2", ")", ",", "self", ".", "random_attn", "(", ")", ")", "\n", "\n", "# ended beam 2 shouldn't continue", "\n", "expected_beam_scores", "[", ":", ",", "2", ":", ":", "self", ".", "BEAM_SZ", "]", "=", "self", ".", "DEAD_SCORE", "\n", "new_scores", "=", "scores_2", "+", "expected_beam_scores", ".", "view", "(", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "expected_beam_scores", ",", "unreduced_preds", "=", "new_scores", ".", "view", "(", "self", ".", "BATCH_SZ", ",", "self", ".", "BEAM_SZ", "*", "self", ".", "N_WORDS", ")", ".", "topk", "(", "self", ".", "BEAM_SZ", ",", "-", "1", ")", "\n", "expected_bptr_2", "=", "unreduced_preds", "/", "self", ".", "N_WORDS", "\n", "# [2, 5, 3, 6, 0] repeat self.BATCH_SZ, so beam 0 predicts EOS!", "\n", "expected_preds_2", "=", "unreduced_preds", "-", "expected_bptr_2", "*", "self", ".", "N_WORDS", "\n", "# [-2.4879, -3.8910, -4.1010, -4.2010, -4.4010] repeat self.BATCH_SZ", "\n", "self", ".", "assertTrue", "(", "beam", ".", "topk_log_probs", ".", "allclose", "(", "expected_beam_scores", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "topk_scores", ".", "allclose", "(", "\n", "expected_beam_scores", "/", "expected_len_pen", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "topk_ids", ".", "equal", "(", "expected_preds_2", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "current_backptr", ".", "equal", "(", "expected_bptr_2", ")", ")", "\n", "# another beam is finished in all batches", "\n", "self", ".", "assertEqual", "(", "beam", ".", "is_finished", ".", "sum", "(", ")", ",", "self", ".", "BATCH_SZ", ")", "\n", "# new beam 0 finished", "\n", "self", ".", "assertTrue", "(", "beam", ".", "is_finished", "[", ":", ",", "0", "]", ".", "all", "(", ")", ")", "\n", "# new beam 0 is old beam 3", "\n", "self", ".", "assertTrue", "(", "expected_bptr_2", "[", ":", ",", "0", "]", ".", "eq", "(", "3", ")", ".", "all", "(", ")", ")", "\n", "beam", ".", "update_finished", "(", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "top_beam_finished", ".", "all", "(", ")", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "done", ")", "\n", "return", "expected_beam_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.TestBeamSearchAgainstReferenceCase.third_step": [[458, 494], ["torch.log_softmax", "scores_3.repeat.repeat.repeat", "beam.advance", "new_scores.view().topk", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertEqual", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "beam.update_finished", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "test_beam_search.TestBeamSearchAgainstReferenceCase.assertTrue", "torch.tensor", "copy.deepcopy", "test_beam_search.TestBeamSearchAgainstReferenceCase.random_attn", "expected_beam_scores.view().unsqueeze", "beam.topk_log_probs.allclose", "beam.topk_scores.allclose", "beam.topk_ids.equal", "beam.current_backptr.equal", "beam.is_finished.sum", "beam.is_finished[].all", "expected_bptr_3[].eq().all", "beam.top_beam_finished.all", "new_scores.view", "expected_beam_scores.view", "expected_bptr_3[].eq"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.TestBeamSearchAgainstReferenceCase.random_attn"], ["", "def", "third_step", "(", "self", ",", "beam", ",", "expected_beam_scores", ",", "expected_len_pen", ")", ":", "\n", "# assumes beam 0 finished on last step", "\n", "        ", "scores_3", "=", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "\n", "[", "[", "0", ",", "0", ",", "5000", ",", "0", ",", "5000", ",", ".51", ",", ".2", ",", "0", "]", ",", "# beam 0 shouldn't cont", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "5000", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", ".2", ",", ".2", ",", ".2", ",", ".2", ",", ".2", "]", ",", "\n", "[", "0", ",", "0", ",", "50", ",", "0", ",", ".2", ",", ".2", ",", ".2", ",", ".2", "]", "]", "# beam 4 -> beam 1 should die", "\n", ")", ",", "dim", "=", "1", ")", "\n", "scores_3", "=", "scores_3", ".", "repeat", "(", "self", ".", "BATCH_SZ", ",", "1", ")", "\n", "\n", "beam", ".", "advance", "(", "deepcopy", "(", "scores_3", ")", ",", "self", ".", "random_attn", "(", ")", ")", "\n", "\n", "expected_beam_scores", "[", ":", ",", "0", ":", ":", "self", ".", "BEAM_SZ", "]", "=", "self", ".", "DEAD_SCORE", "\n", "new_scores", "=", "scores_3", "+", "expected_beam_scores", ".", "view", "(", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "expected_beam_scores", ",", "unreduced_preds", "=", "new_scores", ".", "view", "(", "self", ".", "BATCH_SZ", ",", "self", ".", "BEAM_SZ", "*", "self", ".", "N_WORDS", ")", ".", "topk", "(", "self", ".", "BEAM_SZ", ",", "-", "1", ")", "\n", "expected_bptr_3", "=", "unreduced_preds", "/", "self", ".", "N_WORDS", "\n", "# [5, 2, 6, 1, 0] repeat self.BATCH_SZ, so beam 1 predicts EOS!", "\n", "expected_preds_3", "=", "unreduced_preds", "-", "expected_bptr_3", "*", "self", ".", "N_WORDS", "\n", "self", ".", "assertTrue", "(", "beam", ".", "topk_log_probs", ".", "allclose", "(", "\n", "expected_beam_scores", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "topk_scores", ".", "allclose", "(", "\n", "expected_beam_scores", "/", "expected_len_pen", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "topk_ids", ".", "equal", "(", "expected_preds_3", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "current_backptr", ".", "equal", "(", "expected_bptr_3", ")", ")", "\n", "self", ".", "assertEqual", "(", "beam", ".", "is_finished", ".", "sum", "(", ")", ",", "self", ".", "BATCH_SZ", ")", "\n", "# new beam 1 finished", "\n", "self", ".", "assertTrue", "(", "beam", ".", "is_finished", "[", ":", ",", "1", "]", ".", "all", "(", ")", ")", "\n", "# new beam 1 is old beam 4", "\n", "self", ".", "assertTrue", "(", "expected_bptr_3", "[", ":", ",", "1", "]", ".", "eq", "(", "4", ")", ".", "all", "(", ")", ")", "\n", "beam", ".", "update_finished", "(", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "top_beam_finished", ".", "all", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "done", ")", "\n", "return", "expected_beam_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.TestBeamSearchAgainstReferenceCase.test_beam_advance_against_known_reference": [[495, 506], ["onmt.translate.beam_search.BeamSearch", "test_beam_search.TestBeamSearchAgainstReferenceCase.init_step", "test_beam_search.TestBeamSearchAgainstReferenceCase.first_step", "test_beam_search.TestBeamSearchAgainstReferenceCase.second_step", "test_beam_search.TestBeamSearchAgainstReferenceCase.third_step", "torch.device", "test_beam_search.GlobalScorerStub", "set", "torch.randint"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.init_step", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.first_step", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.second_step", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.third_step"], ["", "def", "test_beam_advance_against_known_reference", "(", "self", ")", ":", "\n", "        ", "beam", "=", "BeamSearch", "(", "\n", "self", ".", "BEAM_SZ", ",", "self", ".", "BATCH_SZ", ",", "0", ",", "1", ",", "2", ",", "self", ".", "N_BEST", ",", "\n", "torch", ".", "device", "(", "\"cpu\"", ")", ",", "GlobalScorerStub", "(", ")", ",", "\n", "0", ",", "30", ",", "False", ",", "0", ",", "set", "(", ")", ",", "\n", "torch", ".", "randint", "(", "0", ",", "30", ",", "(", "self", ".", "BATCH_SZ", ",", ")", ")", ",", "False", ")", "\n", "\n", "expected_beam_scores", "=", "self", ".", "init_step", "(", "beam", ",", "1", ")", "\n", "expected_beam_scores", "=", "self", ".", "first_step", "(", "beam", ",", "expected_beam_scores", ",", "1", ")", "\n", "expected_beam_scores", "=", "self", ".", "second_step", "(", "beam", ",", "expected_beam_scores", ",", "1", ")", "\n", "self", ".", "third_step", "(", "beam", ",", "expected_beam_scores", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam_search.TestBeamWithLengthPenalty.test_beam_advance_against_known_reference": [[512, 523], ["onmt.translate.beam.GNMTGlobalScorer", "onmt.translate.beam_search.BeamSearch", "test_beam_search.TestBeamWithLengthPenalty.init_step", "test_beam_search.TestBeamWithLengthPenalty.first_step", "test_beam_search.TestBeamWithLengthPenalty.second_step", "test_beam_search.TestBeamWithLengthPenalty.third_step", "torch.device", "set", "torch.randint"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.init_step", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.first_step", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.second_step", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.third_step"], ["    ", "def", "test_beam_advance_against_known_reference", "(", "self", ")", ":", "\n", "        ", "scorer", "=", "GNMTGlobalScorer", "(", "0.7", ",", "0.", ",", "\"avg\"", ",", "\"none\"", ")", "\n", "beam", "=", "BeamSearch", "(", "\n", "self", ".", "BEAM_SZ", ",", "self", ".", "BATCH_SZ", ",", "0", ",", "1", ",", "2", ",", "self", ".", "N_BEST", ",", "\n", "torch", ".", "device", "(", "\"cpu\"", ")", ",", "scorer", ",", "\n", "0", ",", "30", ",", "False", ",", "0", ",", "set", "(", ")", ",", "\n", "torch", ".", "randint", "(", "0", ",", "30", ",", "(", "self", ".", "BATCH_SZ", ",", ")", ")", ",", "False", ")", "\n", "expected_beam_scores", "=", "self", ".", "init_step", "(", "beam", ",", "1.", ")", "\n", "expected_beam_scores", "=", "self", ".", "first_step", "(", "beam", ",", "expected_beam_scores", ",", "3", ")", "\n", "expected_beam_scores", "=", "self", ".", "second_step", "(", "beam", ",", "expected_beam_scores", ",", "4", ")", "\n", "self", ".", "third_step", "(", "beam", ",", "expected_beam_scores", ",", "5", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_embeddings.TestEmbeddings.case_is_degenerate": [[31, 54], ["len", "len", "len"], "methods", ["None"], ["@", "classmethod", "\n", "def", "case_is_degenerate", "(", "cls", ",", "case", ")", ":", "\n", "        ", "no_feats", "=", "len", "(", "case", "[", "\"feat_vocab_sizes\"", "]", ")", "==", "0", "\n", "if", "case", "[", "\"feat_merge\"", "]", "!=", "\"first\"", "and", "no_feats", ":", "\n", "            ", "return", "True", "\n", "", "if", "case", "[", "\"feat_merge\"", "]", "==", "\"first\"", "and", "not", "no_feats", ":", "\n", "            ", "return", "True", "\n", "", "if", "case", "[", "\"feat_merge\"", "]", "==", "\"concat\"", "and", "case", "[", "\"feat_vec_exponent\"", "]", "!=", "-", "1", ":", "\n", "            ", "return", "True", "\n", "", "if", "no_feats", "and", "case", "[", "\"feat_vec_exponent\"", "]", "!=", "-", "1", ":", "\n", "            ", "return", "True", "\n", "", "if", "len", "(", "case", "[", "\"feat_vocab_sizes\"", "]", ")", "!=", "len", "(", "case", "[", "\"feat_padding_idx\"", "]", ")", ":", "\n", "            ", "return", "True", "\n", "", "if", "case", "[", "\"feat_vec_size\"", "]", "==", "0", "and", "case", "[", "\"feat_vec_exponent\"", "]", "<=", "0", ":", "\n", "            ", "return", "True", "\n", "", "if", "case", "[", "\"feat_merge\"", "]", "==", "\"sum\"", ":", "\n", "            ", "if", "case", "[", "\"feat_vec_exponent\"", "]", "!=", "-", "1", ":", "\n", "                ", "return", "True", "\n", "", "if", "case", "[", "\"feat_vec_size\"", "]", "!=", "0", ":", "\n", "                ", "return", "True", "\n", "", "", "if", "case", "[", "\"feat_vec_size\"", "]", "!=", "0", "and", "case", "[", "\"feat_vec_exponent\"", "]", "!=", "-", "1", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_embeddings.TestEmbeddings.cases": [[55, 60], ["cls.case_is_degenerate"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_embeddings.TestEmbeddings.case_is_degenerate"], ["", "@", "classmethod", "\n", "def", "cases", "(", "cls", ")", ":", "\n", "        ", "for", "case", "in", "cls", ".", "INIT_CASES", ":", "\n", "            ", "if", "not", "cls", ".", "case_is_degenerate", "(", "case", ")", ":", "\n", "                ", "yield", "case", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_embeddings.TestEmbeddings.dummy_inputs": [[61, 79], ["torch.randint", "torch.empty", "enumerate", "zip", "enumerate", "len", "torch.randint"], "methods", ["None"], ["", "", "", "@", "classmethod", "\n", "def", "dummy_inputs", "(", "cls", ",", "params", ",", "init_case", ")", ":", "\n", "        ", "max_seq_len", "=", "params", "[", "\"max_seq_len\"", "]", "\n", "batch_size", "=", "params", "[", "\"batch_size\"", "]", "\n", "fv_sizes", "=", "init_case", "[", "\"feat_vocab_sizes\"", "]", "\n", "n_words", "=", "init_case", "[", "\"word_vocab_size\"", "]", "\n", "voc_sizes", "=", "[", "n_words", "]", "+", "fv_sizes", "\n", "pad_idxs", "=", "[", "init_case", "[", "\"word_padding_idx\"", "]", "]", "+", "init_case", "[", "\"feat_padding_idx\"", "]", "\n", "lengths", "=", "torch", ".", "randint", "(", "0", ",", "max_seq_len", ",", "(", "batch_size", ",", ")", ")", "\n", "lengths", "[", "0", "]", "=", "max_seq_len", "\n", "inps", "=", "torch", ".", "empty", "(", "(", "max_seq_len", ",", "batch_size", ",", "len", "(", "voc_sizes", ")", ")", ",", "\n", "dtype", "=", "torch", ".", "long", ")", "\n", "for", "f", ",", "(", "voc_size", ",", "pad_idx", ")", "in", "enumerate", "(", "zip", "(", "voc_sizes", ",", "pad_idxs", ")", ")", ":", "\n", "            ", "for", "b", ",", "len_", "in", "enumerate", "(", "lengths", ")", ":", "\n", "                ", "inps", "[", ":", "len_", ",", "b", ",", "f", "]", "=", "torch", ".", "randint", "(", "0", ",", "voc_size", "-", "1", ",", "(", "len_", ",", ")", ")", "\n", "inps", "[", "len_", ":", ",", "b", ",", "f", "]", "=", "pad_idx", "\n", "", "", "return", "inps", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_embeddings.TestEmbeddings.expected_shape": [[80, 89], ["len"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "expected_shape", "(", "cls", ",", "params", ",", "init_case", ")", ":", "\n", "        ", "wvs", "=", "init_case", "[", "\"word_vec_size\"", "]", "\n", "fvs", "=", "init_case", "[", "\"feat_vec_size\"", "]", "\n", "nf", "=", "len", "(", "init_case", "[", "\"feat_vocab_sizes\"", "]", ")", "\n", "size", "=", "wvs", "\n", "if", "init_case", "[", "\"feat_merge\"", "]", "not", "in", "{", "\"sum\"", ",", "\"mlp\"", "}", ":", "\n", "            ", "size", "+=", "nf", "*", "fvs", "\n", "", "return", "params", "[", "\"max_seq_len\"", "]", ",", "params", "[", "\"batch_size\"", "]", ",", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_embeddings.TestEmbeddings.test_embeddings_forward_shape": [[90, 97], ["itertools.product", "test_embeddings.TestEmbeddings.cases", "onmt.modules.embeddings.Embeddings", "test_embeddings.TestEmbeddings.dummy_inputs", "onmt.modules.embeddings.Embeddings.", "test_embeddings.TestEmbeddings.expected_shape", "test_embeddings.TestEmbeddings.assertEqual", "init_case.__str__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_embeddings.TestEmbeddings.cases", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGeneratorLoss.dummy_inputs", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGeneratorLoss.expected_shape"], ["", "def", "test_embeddings_forward_shape", "(", "self", ")", ":", "\n", "        ", "for", "params", ",", "init_case", "in", "itertools", ".", "product", "(", "self", ".", "PARAMS", ",", "self", ".", "cases", "(", ")", ")", ":", "\n", "            ", "emb", "=", "Embeddings", "(", "**", "init_case", ")", "\n", "dummy_in", "=", "self", ".", "dummy_inputs", "(", "params", ",", "init_case", ")", "\n", "res", "=", "emb", "(", "dummy_in", ")", "\n", "expected_shape", "=", "self", ".", "expected_shape", "(", "params", ",", "init_case", ")", "\n", "self", ".", "assertEqual", "(", "res", ".", "shape", ",", "expected_shape", ",", "init_case", ".", "__str__", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_embeddings.TestEmbeddings.test_embeddings_trainable_params": [[98, 130], ["itertools.product", "test_embeddings.TestEmbeddings.cases", "onmt.modules.embeddings.Embeddings", "onmt.modules.embeddings.Embeddings.state_dict", "test_embeddings.TestEmbeddings.assertFalse", "test_embeddings.TestEmbeddings.assertFalse", "onmt.modules.embeddings.Embeddings.named_parameters", "key.endswith", "any", "any", "key.endswith", "test_embeddings.TestEmbeddings.fail", "trainable_param.endswith", "trainable_p.endswith"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_embeddings.TestEmbeddings.cases", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.Optimizer.state_dict"], ["", "", "def", "test_embeddings_trainable_params", "(", "self", ")", ":", "\n", "        ", "for", "params", ",", "init_case", "in", "itertools", ".", "product", "(", "self", ".", "PARAMS", ",", "\n", "self", ".", "cases", "(", ")", ")", ":", "\n", "            ", "emb", "=", "Embeddings", "(", "**", "init_case", ")", "\n", "trainable_params", "=", "{", "n", ":", "p", "for", "n", ",", "p", "in", "emb", ".", "named_parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "}", "\n", "# first check there's nothing unexpectedly not trainable", "\n", "for", "key", "in", "emb", ".", "state_dict", "(", ")", ":", "\n", "                ", "if", "key", "not", "in", "trainable_params", ":", "\n", "                    ", "if", "key", ".", "endswith", "(", "\"emb_luts.0.weight\"", ")", "and", "init_case", "[", "\"fix_word_vecs\"", "]", ":", "\n", "# ok: word embeddings shouldn't be trainable", "\n", "# if word vecs are fixed", "\n", "                        ", "continue", "\n", "", "if", "key", ".", "endswith", "(", "\".pe.pe\"", ")", ":", "\n", "# ok: positional encodings shouldn't be trainable", "\n", "                        ", "assert", "init_case", "[", "\"position_encoding\"", "]", "\n", "continue", "\n", "", "else", ":", "\n", "                        ", "self", ".", "fail", "(", "\"Param {:s} is unexpectedly not \"", "\n", "\"trainable.\"", ".", "format", "(", "key", ")", ")", "\n", "# then check nothing unexpectedly trainable", "\n", "", "", "", "if", "init_case", "[", "\"fix_word_vecs\"", "]", ":", "\n", "                ", "self", ".", "assertFalse", "(", "\n", "any", "(", "trainable_param", ".", "endswith", "(", "\"emb_luts.0.weight\"", ")", "\n", "for", "trainable_param", "in", "trainable_params", ")", ",", "\n", "\"Word embedding is trainable but word vecs are fixed.\"", ")", "\n", "", "if", "init_case", "[", "\"position_encoding\"", "]", ":", "\n", "                ", "self", ".", "assertFalse", "(", "\n", "any", "(", "trainable_p", ".", "endswith", "(", "\".pe.pe\"", ")", "\n", "for", "trainable_p", "in", "trainable_params", ")", ",", "\n", "\"Positional encoding is trainable.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_embeddings.TestEmbeddings.test_embeddings_trainable_params_update": [[131, 149], ["itertools.product", "test_embeddings.TestEmbeddings.cases", "onmt.modules.embeddings.Embeddings", "len", "copy.deepcopy", "test_embeddings.TestEmbeddings.dummy_inputs", "onmt.modules.embeddings.Embeddings.", "onmt.modules.embeddings.Embeddings.sum", "emb.sum.backward", "torch.optim.SGD", "torch.optim.SGD.step", "copy.deepcopy.keys", "onmt.modules.embeddings.Embeddings.named_parameters", "trainable_params.values", "test_embeddings.TestEmbeddings.assertTrue", "trainable_params[].ne().any", "init_case.__str__", "trainable_params[].ne"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_embeddings.TestEmbeddings.cases", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGeneratorLoss.dummy_inputs", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor.step"], ["", "", "", "def", "test_embeddings_trainable_params_update", "(", "self", ")", ":", "\n", "        ", "for", "params", ",", "init_case", "in", "itertools", ".", "product", "(", "self", ".", "PARAMS", ",", "self", ".", "cases", "(", ")", ")", ":", "\n", "            ", "emb", "=", "Embeddings", "(", "**", "init_case", ")", "\n", "trainable_params", "=", "{", "n", ":", "p", "for", "n", ",", "p", "in", "emb", ".", "named_parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "}", "\n", "if", "len", "(", "trainable_params", ")", ">", "0", ":", "\n", "                ", "old_weights", "=", "deepcopy", "(", "trainable_params", ")", "\n", "dummy_in", "=", "self", ".", "dummy_inputs", "(", "params", ",", "init_case", ")", "\n", "res", "=", "emb", "(", "dummy_in", ")", "\n", "pretend_loss", "=", "res", ".", "sum", "(", ")", "\n", "pretend_loss", ".", "backward", "(", ")", "\n", "dummy_optim", "=", "torch", ".", "optim", ".", "SGD", "(", "trainable_params", ".", "values", "(", ")", ",", "1", ")", "\n", "dummy_optim", ".", "step", "(", ")", "\n", "for", "param_name", "in", "old_weights", ".", "keys", "(", ")", ":", "\n", "                    ", "self", ".", "assertTrue", "(", "\n", "trainable_params", "[", "param_name", "]", "\n", ".", "ne", "(", "old_weights", "[", "param_name", "]", ")", ".", "any", "(", ")", ",", "\n", "param_name", "+", "\" \"", "+", "init_case", ".", "__str__", "(", ")", ")", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_preprocess.TestData.__init__": [[36, 39], ["unittest.TestCase.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TestData", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_preprocess.TestData.dataset_build": [[40, 67], ["onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.str2reader[].from_opt", "onmt.inputters.str2reader[].from_opt", "onmt.inputters.str2reader[].from_opt", "onmt.inputters.str2reader[].from_opt", "onmt.inputters.str2reader[].from_opt", "onmt.inputters.str2reader[].from_opt", "onmt.inputters.str2reader[].from_opt", "onmt.inputters.str2reader[].from_opt", "onmt.inputters.str2reader[].from_opt", "onmt.inputters.str2reader[].from_opt", "onmt.inputters.str2reader[].from_opt", "onmt.inputters.str2reader[].from_opt", "onmt.inputters.str2reader[].from_opt", "onmt.inputters.str2reader[].from_opt", "onmt.inputters.str2reader[].from_opt", "onmt.inputters.str2reader[].from_opt", "onmt.inputters.str2reader[].from_opt", "onmt.inputters.str2reader[].from_opt", "preprocess.build_save_dataset", "preprocess.build_save_vocab", "preprocess.build_save_dataset", "glob.glob", "hasattr", "hasattr", "os.remove", "hasattr", "os.path.exists", "os.remove", "hasattr", "os.path.exists", "os.remove", "len", "codecs.open", "f.write", "len", "codecs.open", "f.write"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.get_fields", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt", "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.preprocess.build_save_dataset", "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.preprocess.build_save_vocab", "home.repos.pwc.inspect_result.bigheiniu_FactGen.FactGen.preprocess.build_save_dataset", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write"], ["", "def", "dataset_build", "(", "self", ",", "opt", ")", ":", "\n", "        ", "fields", "=", "onmt", ".", "inputters", ".", "get_fields", "(", "\"text\"", ",", "0", ",", "0", ")", "\n", "\n", "if", "hasattr", "(", "opt", ",", "'src_vocab'", ")", "and", "len", "(", "opt", ".", "src_vocab", ")", ">", "0", ":", "\n", "            ", "with", "codecs", ".", "open", "(", "opt", ".", "src_vocab", ",", "'w'", ",", "'utf-8'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "'a\\nb\\nc\\nd\\ne\\nf\\n'", ")", "\n", "", "", "if", "hasattr", "(", "opt", ",", "'tgt_vocab'", ")", "and", "len", "(", "opt", ".", "tgt_vocab", ")", ">", "0", ":", "\n", "            ", "with", "codecs", ".", "open", "(", "opt", ".", "tgt_vocab", ",", "'w'", ",", "'utf-8'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "'a\\nb\\nc\\nd\\ne\\nf\\n'", ")", "\n", "\n", "", "", "src_reader", "=", "onmt", ".", "inputters", ".", "str2reader", "[", "opt", ".", "data_type", "]", ".", "from_opt", "(", "opt", ")", "\n", "tgt_reader", "=", "onmt", ".", "inputters", ".", "str2reader", "[", "\"text\"", "]", ".", "from_opt", "(", "opt", ")", "\n", "train_data_files", "=", "preprocess", ".", "build_save_dataset", "(", "\n", "'train'", ",", "fields", ",", "src_reader", ",", "tgt_reader", ",", "opt", ")", "\n", "\n", "preprocess", ".", "build_save_vocab", "(", "train_data_files", ",", "fields", ",", "opt", ")", "\n", "\n", "preprocess", ".", "build_save_dataset", "(", "\n", "'valid'", ",", "fields", ",", "src_reader", ",", "tgt_reader", ",", "opt", ")", "\n", "\n", "# Remove the generated *pt files.", "\n", "for", "pt", "in", "glob", ".", "glob", "(", "SAVE_DATA_PREFIX", "+", "'*.pt'", ")", ":", "\n", "            ", "os", ".", "remove", "(", "pt", ")", "\n", "", "if", "hasattr", "(", "opt", ",", "'src_vocab'", ")", "and", "os", ".", "path", ".", "exists", "(", "opt", ".", "src_vocab", ")", ":", "\n", "            ", "os", ".", "remove", "(", "opt", ".", "src_vocab", ")", "\n", "", "if", "hasattr", "(", "opt", ",", "'tgt_vocab'", ")", "and", "os", ".", "path", ".", "exists", "(", "opt", ".", "tgt_vocab", ")", ":", "\n", "            ", "os", ".", "remove", "(", "opt", ".", "tgt_vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_preprocess._add_test": [[69, 93], ["setattr", "copy.deepcopy", "getattr", "setattr", "str().split", "str"], "function", ["None"], ["", "", "", "def", "_add_test", "(", "param_setting", ",", "methodname", ")", ":", "\n", "    ", "\"\"\"\n    Adds a Test to TestData according to settings\n\n    Args:\n        param_setting: list of tuples of (param, setting)\n        methodname: name of the method that gets called\n    \"\"\"", "\n", "\n", "def", "test_method", "(", "self", ")", ":", "\n", "        ", "if", "param_setting", ":", "\n", "            ", "opt", "=", "copy", ".", "deepcopy", "(", "self", ".", "opt", ")", "\n", "for", "param", ",", "setting", "in", "param_setting", ":", "\n", "                ", "setattr", "(", "opt", ",", "param", ",", "setting", ")", "\n", "", "", "else", ":", "\n", "            ", "opt", "=", "self", ".", "opt", "\n", "", "getattr", "(", "self", ",", "methodname", ")", "(", "opt", ")", "\n", "", "if", "param_setting", ":", "\n", "        ", "name", "=", "'test_'", "+", "methodname", "+", "\"_\"", "+", "\"_\"", ".", "join", "(", "\n", "str", "(", "param_setting", ")", ".", "split", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "name", "=", "'test_'", "+", "methodname", "+", "'_standard'", "\n", "", "setattr", "(", "TestData", ",", "name", ",", "test_method", ")", "\n", "test_method", ".", "__name__", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_random_sampling.TestRandomSampling.test_advance_with_repeats_gets_blocked": [[14, 37], ["onmt.translate.random_sampling.RandomSampling", "range", "torch.device", "set", "torch.randint", "torch.full", "torch.randn", "onmt.translate.random_sampling.RandomSampling.advance", "torch.zeros", "test_random_sampling.TestRandomSampling.assertTrue", "test_random_sampling.TestRandomSampling.assertTrue", "float", "onmt.translate.random_sampling.RandomSampling.topk_scores.equal", "onmt.translate.random_sampling.RandomSampling.topk_scores.equal", "torch.tensor().repeat", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance"], ["def", "test_advance_with_repeats_gets_blocked", "(", "self", ")", ":", "\n", "        ", "n_words", "=", "100", "\n", "repeat_idx", "=", "47", "\n", "ngram_repeat", "=", "3", "\n", "for", "batch_sz", "in", "[", "1", ",", "3", "]", ":", "\n", "            ", "samp", "=", "RandomSampling", "(", "\n", "0", ",", "1", ",", "2", ",", "batch_sz", ",", "torch", ".", "device", "(", "\"cpu\"", ")", ",", "0", ",", "ngram_repeat", ",", "set", "(", ")", ",", "\n", "False", ",", "30", ",", "1.", ",", "5", ",", "torch", ".", "randint", "(", "0", ",", "30", ",", "(", "batch_sz", ",", ")", ")", ")", "\n", "for", "i", "in", "range", "(", "ngram_repeat", "+", "4", ")", ":", "\n", "# predict repeat_idx over and over again", "\n", "                ", "word_probs", "=", "torch", ".", "full", "(", "\n", "(", "batch_sz", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "word_probs", "[", ":", ",", "repeat_idx", "]", "=", "0", "\n", "attns", "=", "torch", ".", "randn", "(", "1", ",", "batch_sz", ",", "53", ")", "\n", "samp", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "if", "i", "<=", "ngram_repeat", ":", "\n", "                    ", "expected_scores", "=", "torch", ".", "zeros", "(", "(", "batch_sz", ",", "1", ")", ")", "\n", "self", ".", "assertTrue", "(", "samp", ".", "topk_scores", ".", "equal", "(", "expected_scores", ")", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "assertTrue", "(", "\n", "samp", ".", "topk_scores", ".", "equal", "(", "\n", "torch", ".", "tensor", "(", "self", ".", "BLOCKED_SCORE", ")", "\n", ".", "repeat", "(", "batch_sz", ",", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_random_sampling.TestRandomSampling.test_advance_with_some_repeats_gets_blocked": [[38, 78], ["onmt.translate.random_sampling.RandomSampling", "range", "torch.device", "set", "torch.randint", "torch.full", "torch.randn", "onmt.translate.random_sampling.RandomSampling.advance", "test_random_sampling.TestRandomSampling.assertFalse", "test_random_sampling.TestRandomSampling.assertTrue", "test_random_sampling.TestRandomSampling.assertFalse", "float", "onmt.translate.random_sampling.RandomSampling.topk_scores.eq().any", "onmt.translate.random_sampling.RandomSampling.topk_scores[].eq", "test_random_sampling.TestRandomSampling.assertTrue", "onmt.translate.random_sampling.RandomSampling.topk_scores[].eq().any", "test_random_sampling.TestRandomSampling.assertFalse", "onmt.translate.random_sampling.RandomSampling.topk_scores[].eq", "onmt.translate.random_sampling.RandomSampling.topk_scores[].eq().any", "onmt.translate.random_sampling.RandomSampling.topk_scores.eq", "onmt.translate.random_sampling.RandomSampling.topk_scores[].eq", "onmt.translate.random_sampling.RandomSampling.topk_scores[].eq"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance"], ["", "", "", "", "def", "test_advance_with_some_repeats_gets_blocked", "(", "self", ")", ":", "\n", "# batch 0 and 7 will repeat, the rest will advance", "\n", "        ", "n_words", "=", "100", "\n", "repeat_idx", "=", "47", "\n", "other_repeat_idx", "=", "12", "\n", "ngram_repeat", "=", "3", "\n", "for", "batch_sz", "in", "[", "1", ",", "3", ",", "13", "]", ":", "\n", "            ", "samp", "=", "RandomSampling", "(", "\n", "0", ",", "1", ",", "2", ",", "batch_sz", ",", "torch", ".", "device", "(", "\"cpu\"", ")", ",", "0", ",", "ngram_repeat", ",", "set", "(", ")", ",", "\n", "False", ",", "30", ",", "1.", ",", "5", ",", "torch", ".", "randint", "(", "0", ",", "30", ",", "(", "batch_sz", ",", ")", ")", ")", "\n", "for", "i", "in", "range", "(", "ngram_repeat", "+", "4", ")", ":", "\n", "                ", "word_probs", "=", "torch", ".", "full", "(", "\n", "(", "batch_sz", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "# predict the same thing in batch 0 and 7 every i", "\n", "word_probs", "[", "0", ",", "repeat_idx", "]", "=", "0", "\n", "if", "batch_sz", ">", "7", ":", "\n", "                    ", "word_probs", "[", "7", ",", "other_repeat_idx", "]", "=", "0", "\n", "# push around what the other batches predict", "\n", "", "word_probs", "[", "1", ":", "7", ",", "repeat_idx", "+", "i", "]", "=", "0", "\n", "if", "batch_sz", ">", "7", ":", "\n", "                    ", "word_probs", "[", "8", ":", ",", "repeat_idx", "+", "i", "]", "=", "0", "\n", "", "attns", "=", "torch", ".", "randn", "(", "1", ",", "batch_sz", ",", "53", ")", "\n", "samp", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "if", "i", "<=", "ngram_repeat", ":", "\n", "                    ", "self", ".", "assertFalse", "(", "\n", "samp", ".", "topk_scores", ".", "eq", "(", "\n", "self", ".", "BLOCKED_SCORE", ")", ".", "any", "(", ")", ")", "\n", "", "else", ":", "\n", "# now batch 0 and 7 die", "\n", "                    ", "self", ".", "assertTrue", "(", "samp", ".", "topk_scores", "[", "0", "]", ".", "eq", "(", "self", ".", "BLOCKED_SCORE", ")", ")", "\n", "if", "batch_sz", ">", "7", ":", "\n", "                        ", "self", ".", "assertTrue", "(", "samp", ".", "topk_scores", "[", "7", "]", ".", "eq", "(", "\n", "self", ".", "BLOCKED_SCORE", ")", ")", "\n", "", "self", ".", "assertFalse", "(", "\n", "samp", ".", "topk_scores", "[", "1", ":", "7", "]", ".", "eq", "(", "\n", "self", ".", "BLOCKED_SCORE", ")", ".", "any", "(", ")", ")", "\n", "if", "batch_sz", ">", "7", ":", "\n", "                        ", "self", ".", "assertFalse", "(", "\n", "samp", ".", "topk_scores", "[", "8", ":", "]", ".", "eq", "(", "\n", "self", ".", "BLOCKED_SCORE", ")", ".", "any", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_random_sampling.TestRandomSampling.test_repeating_excluded_index_does_not_die": [[79, 111], ["onmt.translate.random_sampling.RandomSampling", "range", "torch.device", "torch.randint", "torch.full", "torch.randn", "onmt.translate.random_sampling.RandomSampling.advance", "test_random_sampling.TestRandomSampling.assertFalse", "test_random_sampling.TestRandomSampling.assertFalse", "float", "onmt.translate.random_sampling.RandomSampling.topk_scores.eq().any", "onmt.translate.random_sampling.RandomSampling.topk_scores[].eq().any", "test_random_sampling.TestRandomSampling.assertTrue", "test_random_sampling.TestRandomSampling.assertFalse", "onmt.translate.random_sampling.RandomSampling.topk_scores[].eq().all", "onmt.translate.random_sampling.RandomSampling.topk_scores[].eq().any", "onmt.translate.random_sampling.RandomSampling.topk_scores.eq", "onmt.translate.random_sampling.RandomSampling.topk_scores[].eq", "onmt.translate.random_sampling.RandomSampling.topk_scores[].eq", "onmt.translate.random_sampling.RandomSampling.topk_scores[].eq"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance"], ["", "", "", "", "", "def", "test_repeating_excluded_index_does_not_die", "(", "self", ")", ":", "\n", "# batch 0 will repeat excluded idx, batch 1 will repeat", "\n", "        ", "n_words", "=", "100", "\n", "repeat_idx", "=", "47", "# will be repeated and should be blocked", "\n", "repeat_idx_ignored", "=", "7", "# will be repeated and should not be blocked", "\n", "ngram_repeat", "=", "3", "\n", "for", "batch_sz", "in", "[", "1", ",", "3", ",", "17", "]", ":", "\n", "            ", "samp", "=", "RandomSampling", "(", "\n", "0", ",", "1", ",", "2", ",", "batch_sz", ",", "torch", ".", "device", "(", "\"cpu\"", ")", ",", "0", ",", "ngram_repeat", ",", "\n", "{", "repeat_idx_ignored", "}", ",", "False", ",", "30", ",", "1.", ",", "5", ",", "\n", "torch", ".", "randint", "(", "0", ",", "30", ",", "(", "batch_sz", ",", ")", ")", ")", "\n", "for", "i", "in", "range", "(", "ngram_repeat", "+", "4", ")", ":", "\n", "                ", "word_probs", "=", "torch", ".", "full", "(", "\n", "(", "batch_sz", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "word_probs", "[", "0", ",", "repeat_idx_ignored", "]", "=", "0", "\n", "if", "batch_sz", ">", "1", ":", "\n", "                    ", "word_probs", "[", "1", ",", "repeat_idx", "]", "=", "0", "\n", "word_probs", "[", "2", ":", ",", "repeat_idx", "+", "i", "]", "=", "0", "\n", "", "attns", "=", "torch", ".", "randn", "(", "1", ",", "batch_sz", ",", "53", ")", "\n", "samp", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "if", "i", "<=", "ngram_repeat", ":", "\n", "                    ", "self", ".", "assertFalse", "(", "samp", ".", "topk_scores", ".", "eq", "(", "\n", "self", ".", "BLOCKED_SCORE", ")", ".", "any", "(", ")", ")", "\n", "", "else", ":", "\n", "# now batch 1 dies", "\n", "                    ", "self", ".", "assertFalse", "(", "samp", ".", "topk_scores", "[", "0", "]", ".", "eq", "(", "\n", "self", ".", "BLOCKED_SCORE", ")", ".", "any", "(", ")", ")", "\n", "if", "batch_sz", ">", "1", ":", "\n", "                        ", "self", ".", "assertTrue", "(", "samp", ".", "topk_scores", "[", "1", "]", ".", "eq", "(", "\n", "self", ".", "BLOCKED_SCORE", ")", ".", "all", "(", ")", ")", "\n", "self", ".", "assertFalse", "(", "samp", ".", "topk_scores", "[", "2", ":", "]", ".", "eq", "(", "\n", "self", ".", "BLOCKED_SCORE", ")", ".", "any", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_random_sampling.TestRandomSampling.test_doesnt_predict_eos_if_shorter_than_min_len": [[112, 151], ["torch.log_softmax", "torch.randint", "onmt.translate.random_sampling.RandomSampling", "range", "torch.tensor", "torch.device", "set", "torch.full", "torch.randn", "all_attns.append", "onmt.translate.random_sampling.RandomSampling.advance", "test_random_sampling.TestRandomSampling.assertTrue", "test_random_sampling.TestRandomSampling.assertTrue", "float", "onmt.translate.random_sampling.RandomSampling.topk_scores[].allclose", "onmt.translate.random_sampling.RandomSampling.topk_scores[].eq().all", "test_random_sampling.TestRandomSampling.assertTrue", "test_random_sampling.TestRandomSampling.assertTrue", "onmt.translate.random_sampling.RandomSampling.is_finished[].eq().all", "onmt.translate.random_sampling.RandomSampling.is_finished[].eq().all", "onmt.translate.random_sampling.RandomSampling.topk_scores[].eq", "onmt.translate.random_sampling.RandomSampling.is_finished[].eq", "onmt.translate.random_sampling.RandomSampling.is_finished[].eq"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance"], ["", "", "", "", "", "def", "test_doesnt_predict_eos_if_shorter_than_min_len", "(", "self", ")", ":", "\n", "# batch 0 will always predict EOS. The other batches will predict", "\n", "# non-eos scores.", "\n", "        ", "for", "batch_sz", "in", "[", "1", ",", "3", "]", ":", "\n", "            ", "n_words", "=", "100", "\n", "_non_eos_idxs", "=", "[", "47", "]", "\n", "valid_score_dist", "=", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "\n", "[", "6.", ",", "5.", "]", ")", ",", "dim", "=", "0", ")", "\n", "min_length", "=", "5", "\n", "eos_idx", "=", "2", "\n", "lengths", "=", "torch", ".", "randint", "(", "0", ",", "30", ",", "(", "batch_sz", ",", ")", ")", "\n", "samp", "=", "RandomSampling", "(", "\n", "0", ",", "1", ",", "2", ",", "batch_sz", ",", "torch", ".", "device", "(", "\"cpu\"", ")", ",", "min_length", ",", "\n", "False", ",", "set", "(", ")", ",", "False", ",", "30", ",", "1.", ",", "1", ",", "lengths", ")", "\n", "all_attns", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "min_length", "+", "4", ")", ":", "\n", "                ", "word_probs", "=", "torch", ".", "full", "(", "\n", "(", "batch_sz", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "# \"best\" prediction is eos - that should be blocked", "\n", "word_probs", "[", "0", ",", "eos_idx", "]", "=", "valid_score_dist", "[", "0", "]", "\n", "# include at least one prediction OTHER than EOS", "\n", "# that is greater than -1e20", "\n", "word_probs", "[", "0", ",", "_non_eos_idxs", "[", "0", "]", "]", "=", "valid_score_dist", "[", "1", "]", "\n", "word_probs", "[", "1", ":", ",", "_non_eos_idxs", "[", "0", "]", "+", "i", "]", "=", "0", "\n", "\n", "attns", "=", "torch", ".", "randn", "(", "1", ",", "batch_sz", ",", "53", ")", "\n", "all_attns", ".", "append", "(", "attns", ")", "\n", "samp", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "if", "i", "<", "min_length", ":", "\n", "                    ", "self", ".", "assertTrue", "(", "\n", "samp", ".", "topk_scores", "[", "0", "]", ".", "allclose", "(", "valid_score_dist", "[", "1", "]", ")", ")", "\n", "self", ".", "assertTrue", "(", "\n", "samp", ".", "topk_scores", "[", "1", ":", "]", ".", "eq", "(", "0", ")", ".", "all", "(", ")", ")", "\n", "", "elif", "i", "==", "min_length", ":", "\n", "# now batch 0 has ended and no others have", "\n", "                    ", "self", ".", "assertTrue", "(", "samp", ".", "is_finished", "[", "0", ",", ":", "]", ".", "eq", "(", "1", ")", ".", "all", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "samp", ".", "is_finished", "[", "1", ":", ",", "1", ":", "]", ".", "eq", "(", "0", ")", ".", "all", "(", ")", ")", "\n", "", "else", ":", "# i > min_length", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_random_sampling.TestRandomSampling.test_returns_correct_scores_deterministic": [[152, 223], ["torch.log_softmax", "torch.log_softmax", "torch.randint", "onmt.translate.random_sampling.RandomSampling", "torch.full", "torch.randn", "onmt.translate.random_sampling.RandomSampling.advance", "test_random_sampling.TestRandomSampling.assertTrue", "onmt.translate.random_sampling.RandomSampling.update_finished", "test_random_sampling.TestRandomSampling.assertEqual", "torch.full", "torch.randn", "onmt.translate.random_sampling.RandomSampling.advance", "test_random_sampling.TestRandomSampling.assertTrue", "onmt.translate.random_sampling.RandomSampling.update_finished", "test_random_sampling.TestRandomSampling.assertEqual", "torch.full", "torch.randn", "onmt.translate.random_sampling.RandomSampling.advance", "test_random_sampling.TestRandomSampling.assertTrue", "onmt.translate.random_sampling.RandomSampling.update_finished", "range", "test_random_sampling.TestRandomSampling.assertTrue", "torch.tensor", "torch.tensor", "torch.device", "set", "onmt.translate.random_sampling.RandomSampling.is_finished[].eq().all", "test_random_sampling.TestRandomSampling.assertTrue", "test_random_sampling.TestRandomSampling.assertFalse", "onmt.translate.random_sampling.RandomSampling.is_finished[].eq().all", "onmt.translate.random_sampling.RandomSampling.is_finished.eq().all", "float", "float", "float", "test_random_sampling.TestRandomSampling.assertEqual", "onmt.translate.random_sampling.RandomSampling.is_finished[].eq", "onmt.translate.random_sampling.RandomSampling.is_finished[].eq", "onmt.translate.random_sampling.RandomSampling.is_finished.eq"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished"], ["", "", "", "", "def", "test_returns_correct_scores_deterministic", "(", "self", ")", ":", "\n", "        ", "for", "batch_sz", "in", "[", "1", ",", "13", "]", ":", "\n", "            ", "for", "temp", "in", "[", "1.", ",", "3.", "]", ":", "\n", "                ", "n_words", "=", "100", "\n", "_non_eos_idxs", "=", "[", "47", ",", "51", ",", "13", ",", "88", ",", "99", "]", "\n", "valid_score_dist_1", "=", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "\n", "[", "6.", ",", "5.", ",", "4.", ",", "3.", ",", "2.", ",", "1.", "]", ")", ",", "dim", "=", "0", ")", "\n", "valid_score_dist_2", "=", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "\n", "[", "6.", ",", "1.", "]", ")", ",", "dim", "=", "0", ")", "\n", "eos_idx", "=", "2", "\n", "lengths", "=", "torch", ".", "randint", "(", "0", ",", "30", ",", "(", "batch_sz", ",", ")", ")", "\n", "samp", "=", "RandomSampling", "(", "\n", "0", ",", "1", ",", "2", ",", "batch_sz", ",", "torch", ".", "device", "(", "\"cpu\"", ")", ",", "0", ",", "\n", "False", ",", "set", "(", ")", ",", "False", ",", "30", ",", "temp", ",", "1", ",", "lengths", ")", "\n", "\n", "# initial step", "\n", "i", "=", "0", "\n", "word_probs", "=", "torch", ".", "full", "(", "\n", "(", "batch_sz", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "# batch 0 dies on step 0", "\n", "word_probs", "[", "0", ",", "eos_idx", "]", "=", "valid_score_dist_1", "[", "0", "]", "\n", "# include at least one prediction OTHER than EOS", "\n", "# that is greater than -1e20", "\n", "word_probs", "[", "0", ",", "_non_eos_idxs", "]", "=", "valid_score_dist_1", "[", "1", ":", "]", "\n", "word_probs", "[", "1", ":", ",", "_non_eos_idxs", "[", "0", "]", "+", "i", "]", "=", "0", "\n", "\n", "attns", "=", "torch", ".", "randn", "(", "1", ",", "batch_sz", ",", "53", ")", "\n", "samp", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "self", ".", "assertTrue", "(", "samp", ".", "is_finished", "[", "0", "]", ".", "eq", "(", "1", ")", ".", "all", "(", ")", ")", "\n", "samp", ".", "update_finished", "(", ")", "\n", "self", ".", "assertEqual", "(", "\n", "samp", ".", "scores", "[", "0", "]", ",", "[", "valid_score_dist_1", "[", "0", "]", "/", "temp", "]", ")", "\n", "if", "batch_sz", "==", "1", ":", "\n", "                    ", "self", ".", "assertTrue", "(", "samp", ".", "done", ")", "\n", "continue", "\n", "", "else", ":", "\n", "                    ", "self", ".", "assertFalse", "(", "samp", ".", "done", ")", "\n", "\n", "# step 2", "\n", "", "i", "=", "1", "\n", "word_probs", "=", "torch", ".", "full", "(", "\n", "(", "batch_sz", "-", "1", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "# (old) batch 8 dies on step 1", "\n", "word_probs", "[", "7", ",", "eos_idx", "]", "=", "valid_score_dist_2", "[", "0", "]", "\n", "word_probs", "[", "0", ":", "7", ",", "_non_eos_idxs", "[", ":", "2", "]", "]", "=", "valid_score_dist_2", "\n", "word_probs", "[", "8", ":", ",", "_non_eos_idxs", "[", ":", "2", "]", "]", "=", "valid_score_dist_2", "\n", "\n", "attns", "=", "torch", ".", "randn", "(", "1", ",", "batch_sz", ",", "53", ")", "\n", "samp", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "\n", "self", ".", "assertTrue", "(", "samp", ".", "is_finished", "[", "7", "]", ".", "eq", "(", "1", ")", ".", "all", "(", ")", ")", "\n", "samp", ".", "update_finished", "(", ")", "\n", "self", ".", "assertEqual", "(", "\n", "samp", ".", "scores", "[", "8", "]", ",", "[", "valid_score_dist_2", "[", "0", "]", "/", "temp", "]", ")", "\n", "\n", "# step 3", "\n", "i", "=", "2", "\n", "word_probs", "=", "torch", ".", "full", "(", "\n", "(", "batch_sz", "-", "2", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "# everything dies", "\n", "word_probs", "[", ":", ",", "eos_idx", "]", "=", "0", "\n", "\n", "attns", "=", "torch", ".", "randn", "(", "1", ",", "batch_sz", ",", "53", ")", "\n", "samp", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "\n", "self", ".", "assertTrue", "(", "samp", ".", "is_finished", ".", "eq", "(", "1", ")", ".", "all", "(", ")", ")", "\n", "samp", ".", "update_finished", "(", ")", "\n", "for", "b", "in", "range", "(", "batch_sz", ")", ":", "\n", "                    ", "if", "b", "!=", "0", "and", "b", "!=", "8", ":", "\n", "                        ", "self", ".", "assertEqual", "(", "samp", ".", "scores", "[", "b", "]", ",", "[", "0", "]", ")", "\n", "", "", "self", ".", "assertTrue", "(", "samp", ".", "done", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_random_sampling.TestRandomSampling.test_returns_correct_scores_non_deterministic": [[224, 314], ["torch.log_softmax", "torch.log_softmax", "torch.randint", "onmt.translate.random_sampling.RandomSampling", "range", "onmt.translate.random_sampling.RandomSampling.update_finished", "test_random_sampling.TestRandomSampling.assertEqual", "range", "onmt.translate.random_sampling.RandomSampling.update_finished", "test_random_sampling.TestRandomSampling.assertEqual", "range", "range", "test_random_sampling.TestRandomSampling.assertTrue", "torch.tensor", "torch.tensor", "torch.device", "set", "torch.full", "torch.randn", "onmt.translate.random_sampling.RandomSampling.advance", "onmt.translate.random_sampling.RandomSampling.is_finished[].eq().all", "test_random_sampling.TestRandomSampling.fail", "test_random_sampling.TestRandomSampling.assertTrue", "test_random_sampling.TestRandomSampling.assertFalse", "torch.full", "torch.randn", "onmt.translate.random_sampling.RandomSampling.advance", "onmt.translate.random_sampling.RandomSampling.is_finished[].eq().all", "test_random_sampling.TestRandomSampling.fail", "torch.full", "torch.randn", "onmt.translate.random_sampling.RandomSampling.advance", "onmt.translate.random_sampling.RandomSampling.is_finished.any", "onmt.translate.random_sampling.RandomSampling.is_finished.eq().all", "test_random_sampling.TestRandomSampling.fail", "onmt.translate.random_sampling.RandomSampling.update_finished", "test_random_sampling.TestRandomSampling.assertEqual", "float", "onmt.translate.random_sampling.RandomSampling.is_finished[].eq", "float", "onmt.translate.random_sampling.RandomSampling.is_finished[].eq", "float", "onmt.translate.random_sampling.RandomSampling.is_finished.eq"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.update_finished"], ["", "", "", "def", "test_returns_correct_scores_non_deterministic", "(", "self", ")", ":", "\n", "        ", "for", "batch_sz", "in", "[", "1", ",", "13", "]", ":", "\n", "            ", "for", "temp", "in", "[", "1.", ",", "3.", "]", ":", "\n", "                ", "n_words", "=", "100", "\n", "_non_eos_idxs", "=", "[", "47", ",", "51", ",", "13", ",", "88", ",", "99", "]", "\n", "valid_score_dist_1", "=", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "\n", "[", "6.", ",", "5.", ",", "4.", ",", "3.", ",", "2.", ",", "1.", "]", ")", ",", "dim", "=", "0", ")", "\n", "valid_score_dist_2", "=", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "\n", "[", "6.", ",", "1.", "]", ")", ",", "dim", "=", "0", ")", "\n", "eos_idx", "=", "2", "\n", "lengths", "=", "torch", ".", "randint", "(", "0", ",", "30", ",", "(", "batch_sz", ",", ")", ")", "\n", "samp", "=", "RandomSampling", "(", "\n", "0", ",", "1", ",", "2", ",", "batch_sz", ",", "torch", ".", "device", "(", "\"cpu\"", ")", ",", "0", ",", "\n", "False", ",", "set", "(", ")", ",", "False", ",", "30", ",", "temp", ",", "2", ",", "lengths", ")", "\n", "\n", "# initial step", "\n", "i", "=", "0", "\n", "for", "_", "in", "range", "(", "100", ")", ":", "\n", "                    ", "word_probs", "=", "torch", ".", "full", "(", "\n", "(", "batch_sz", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "# batch 0 dies on step 0", "\n", "word_probs", "[", "0", ",", "eos_idx", "]", "=", "valid_score_dist_1", "[", "0", "]", "\n", "# include at least one prediction OTHER than EOS", "\n", "# that is greater than -1e20", "\n", "word_probs", "[", "0", ",", "_non_eos_idxs", "]", "=", "valid_score_dist_1", "[", "1", ":", "]", "\n", "word_probs", "[", "1", ":", ",", "_non_eos_idxs", "[", "0", "]", "+", "i", "]", "=", "0", "\n", "\n", "attns", "=", "torch", ".", "randn", "(", "1", ",", "batch_sz", ",", "53", ")", "\n", "samp", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "if", "samp", ".", "is_finished", "[", "0", "]", ".", "eq", "(", "1", ")", ".", "all", "(", ")", ":", "\n", "                        ", "break", "\n", "", "", "else", ":", "\n", "                    ", "self", ".", "fail", "(", "\"Batch 0 never ended (very unlikely but maybe \"", "\n", "\"due to stochasticisty. If so, please increase \"", "\n", "\"the range of the for-loop.\"", ")", "\n", "", "samp", ".", "update_finished", "(", ")", "\n", "self", ".", "assertEqual", "(", "\n", "samp", ".", "scores", "[", "0", "]", ",", "[", "valid_score_dist_1", "[", "0", "]", "/", "temp", "]", ")", "\n", "if", "batch_sz", "==", "1", ":", "\n", "                    ", "self", ".", "assertTrue", "(", "samp", ".", "done", ")", "\n", "continue", "\n", "", "else", ":", "\n", "                    ", "self", ".", "assertFalse", "(", "samp", ".", "done", ")", "\n", "\n", "# step 2", "\n", "", "i", "=", "1", "\n", "for", "_", "in", "range", "(", "100", ")", ":", "\n", "                    ", "word_probs", "=", "torch", ".", "full", "(", "\n", "(", "batch_sz", "-", "1", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "# (old) batch 8 dies on step 1", "\n", "word_probs", "[", "7", ",", "eos_idx", "]", "=", "valid_score_dist_2", "[", "0", "]", "\n", "word_probs", "[", "0", ":", "7", ",", "_non_eos_idxs", "[", ":", "2", "]", "]", "=", "valid_score_dist_2", "\n", "word_probs", "[", "8", ":", ",", "_non_eos_idxs", "[", ":", "2", "]", "]", "=", "valid_score_dist_2", "\n", "\n", "attns", "=", "torch", ".", "randn", "(", "1", ",", "batch_sz", ",", "53", ")", "\n", "samp", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "if", "samp", ".", "is_finished", "[", "7", "]", ".", "eq", "(", "1", ")", ".", "all", "(", ")", ":", "\n", "                        ", "break", "\n", "", "", "else", ":", "\n", "                    ", "self", ".", "fail", "(", "\"Batch 8 never ended (very unlikely but maybe \"", "\n", "\"due to stochasticisty. If so, please increase \"", "\n", "\"the range of the for-loop.\"", ")", "\n", "\n", "", "samp", ".", "update_finished", "(", ")", "\n", "self", ".", "assertEqual", "(", "\n", "samp", ".", "scores", "[", "8", "]", ",", "[", "valid_score_dist_2", "[", "0", "]", "/", "temp", "]", ")", "\n", "\n", "# step 3", "\n", "i", "=", "2", "\n", "for", "_", "in", "range", "(", "250", ")", ":", "\n", "                    ", "word_probs", "=", "torch", ".", "full", "(", "\n", "(", "samp", ".", "alive_seq", ".", "shape", "[", "0", "]", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "# everything dies", "\n", "word_probs", "[", ":", ",", "eos_idx", "]", "=", "0", "\n", "\n", "attns", "=", "torch", ".", "randn", "(", "1", ",", "batch_sz", ",", "53", ")", "\n", "samp", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "if", "samp", ".", "is_finished", ".", "any", "(", ")", ":", "\n", "                        ", "samp", ".", "update_finished", "(", ")", "\n", "", "if", "samp", ".", "is_finished", ".", "eq", "(", "1", ")", ".", "all", "(", ")", ":", "\n", "                        ", "break", "\n", "", "", "else", ":", "\n", "                    ", "self", ".", "fail", "(", "\"All batches never ended (very unlikely but \"", "\n", "\"maybe due to stochasticisty. If so, please \"", "\n", "\"increase the range of the for-loop.\"", ")", "\n", "\n", "", "for", "b", "in", "range", "(", "batch_sz", ")", ":", "\n", "                    ", "if", "b", "!=", "0", "and", "b", "!=", "8", ":", "\n", "                        ", "self", ".", "assertEqual", "(", "samp", ".", "scores", "[", "b", "]", ",", "[", "0", "]", ")", "\n", "", "", "self", ".", "assertTrue", "(", "samp", ".", "done", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGenerator.dummy_inputs": [[26, 35], ["torch.randn", "torch.randn", "torch.randn"], "methods", ["None"], ["@", "classmethod", "\n", "def", "dummy_inputs", "(", "cls", ",", "params", ",", "init_case", ")", ":", "\n", "        ", "hidden", "=", "torch", ".", "randn", "(", "(", "params", "[", "\"batch_size\"", "]", "*", "params", "[", "\"tgt_max_len\"", "]", ",", "\n", "init_case", "[", "\"input_size\"", "]", ")", ")", "\n", "attn", "=", "torch", ".", "randn", "(", "(", "params", "[", "\"batch_size\"", "]", "*", "params", "[", "\"tgt_max_len\"", "]", ",", "\n", "params", "[", "\"max_seq_len\"", "]", ")", ")", "\n", "src_map", "=", "torch", ".", "randn", "(", "(", "params", "[", "\"max_seq_len\"", "]", ",", "params", "[", "\"batch_size\"", "]", ",", "\n", "params", "[", "\"n_extra_words\"", "]", ")", ")", "\n", "return", "hidden", ",", "attn", ",", "src_map", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGenerator.expected_shape": [[36, 40], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "expected_shape", "(", "cls", ",", "params", ",", "init_case", ")", ":", "\n", "        ", "return", "params", "[", "\"tgt_max_len\"", "]", "*", "params", "[", "\"batch_size\"", "]", ",", "init_case", "[", "\"output_size\"", "]", "+", "params", "[", "\"n_extra_words\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGenerator.test_copy_gen_forward_shape": [[41, 49], ["itertools.product", "onmt.modules.copy_generator.CopyGenerator", "test_copy_generator.TestCopyGenerator.dummy_inputs", "onmt.modules.copy_generator.CopyGenerator.", "test_copy_generator.TestCopyGenerator.expected_shape", "test_copy_generator.TestCopyGenerator.assertEqual", "init_case.__str__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGeneratorLoss.dummy_inputs", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGeneratorLoss.expected_shape"], ["", "def", "test_copy_gen_forward_shape", "(", "self", ")", ":", "\n", "        ", "for", "params", ",", "init_case", "in", "itertools", ".", "product", "(", "\n", "self", ".", "PARAMS", ",", "self", ".", "INIT_CASES", ")", ":", "\n", "            ", "cgen", "=", "CopyGenerator", "(", "**", "init_case", ")", "\n", "dummy_in", "=", "self", ".", "dummy_inputs", "(", "params", ",", "init_case", ")", "\n", "res", "=", "cgen", "(", "*", "dummy_in", ")", "\n", "expected_shape", "=", "self", ".", "expected_shape", "(", "params", ",", "init_case", ")", "\n", "self", ".", "assertEqual", "(", "res", ".", "shape", ",", "expected_shape", ",", "init_case", ".", "__str__", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGenerator.test_copy_gen_outp_has_no_prob_of_pad": [[50, 58], ["itertools.product", "onmt.modules.copy_generator.CopyGenerator", "test_copy_generator.TestCopyGenerator.dummy_inputs", "onmt.modules.copy_generator.CopyGenerator.", "test_copy_generator.TestCopyGenerator.assertTrue", "res[].allclose", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGeneratorLoss.dummy_inputs"], ["", "", "def", "test_copy_gen_outp_has_no_prob_of_pad", "(", "self", ")", ":", "\n", "        ", "for", "params", ",", "init_case", "in", "itertools", ".", "product", "(", "\n", "self", ".", "PARAMS", ",", "self", ".", "INIT_CASES", ")", ":", "\n", "            ", "cgen", "=", "CopyGenerator", "(", "**", "init_case", ")", "\n", "dummy_in", "=", "self", ".", "dummy_inputs", "(", "params", ",", "init_case", ")", "\n", "res", "=", "cgen", "(", "*", "dummy_in", ")", "\n", "self", ".", "assertTrue", "(", "\n", "res", "[", ":", ",", "init_case", "[", "\"pad_idx\"", "]", "]", ".", "allclose", "(", "torch", ".", "tensor", "(", "0.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGenerator.test_copy_gen_trainable_params_update": [[59, 78], ["itertools.product", "onmt.modules.copy_generator.CopyGenerator", "copy.deepcopy", "test_copy_generator.TestCopyGenerator.dummy_inputs", "onmt.modules.copy_generator.CopyGenerator.", "onmt.modules.copy_generator.CopyGenerator.sum", "cgen.sum.backward", "torch.optim.SGD", "torch.optim.SGD.step", "copy.deepcopy.keys", "len", "trainable_params.values", "test_copy_generator.TestCopyGenerator.assertTrue", "onmt.modules.copy_generator.CopyGenerator.named_parameters", "trainable_params[].ne().any", "init_case.__str__", "trainable_params[].ne"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGeneratorLoss.dummy_inputs", "home.repos.pwc.inspect_result.bigheiniu_FactGen.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.optimizers.AdaFactor.step"], ["", "", "def", "test_copy_gen_trainable_params_update", "(", "self", ")", ":", "\n", "        ", "for", "params", ",", "init_case", "in", "itertools", ".", "product", "(", "\n", "self", ".", "PARAMS", ",", "self", ".", "INIT_CASES", ")", ":", "\n", "            ", "cgen", "=", "CopyGenerator", "(", "**", "init_case", ")", "\n", "trainable_params", "=", "{", "n", ":", "p", "for", "n", ",", "p", "in", "cgen", ".", "named_parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "}", "\n", "assert", "len", "(", "trainable_params", ")", ">", "0", "# sanity check", "\n", "old_weights", "=", "deepcopy", "(", "trainable_params", ")", "\n", "dummy_in", "=", "self", ".", "dummy_inputs", "(", "params", ",", "init_case", ")", "\n", "res", "=", "cgen", "(", "*", "dummy_in", ")", "\n", "pretend_loss", "=", "res", ".", "sum", "(", ")", "\n", "pretend_loss", ".", "backward", "(", ")", "\n", "dummy_optim", "=", "torch", ".", "optim", ".", "SGD", "(", "trainable_params", ".", "values", "(", ")", ",", "1", ")", "\n", "dummy_optim", ".", "step", "(", ")", "\n", "for", "param_name", "in", "old_weights", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "assertTrue", "(", "\n", "trainable_params", "[", "param_name", "]", "\n", ".", "ne", "(", "old_weights", "[", "param_name", "]", ")", ".", "any", "(", ")", ",", "\n", "param_name", "+", "\" \"", "+", "init_case", ".", "__str__", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGeneratorLoss.dummy_inputs": [[93, 106], ["torch.randn", "torch.nn.functional.softmax", "torch.randint", "torch.randint"], "methods", ["None"], ["@", "classmethod", "\n", "def", "dummy_inputs", "(", "cls", ",", "params", ",", "init_case", ")", ":", "\n", "        ", "n_unique_src_words", "=", "13", "\n", "scores", "=", "torch", ".", "randn", "(", "(", "params", "[", "\"batch_size\"", "]", "*", "params", "[", "\"tgt_max_len\"", "]", ",", "\n", "init_case", "[", "\"vocab_size\"", "]", "+", "n_unique_src_words", ")", ")", "\n", "scores", "=", "softmax", "(", "scores", ",", "dim", "=", "1", ")", "\n", "align", "=", "torch", ".", "randint", "(", "0", ",", "n_unique_src_words", ",", "\n", "(", "params", "[", "\"batch_size\"", "]", "*", "params", "[", "\"tgt_max_len\"", "]", ",", ")", ")", "\n", "target", "=", "torch", ".", "randint", "(", "0", ",", "init_case", "[", "\"vocab_size\"", "]", ",", "\n", "(", "params", "[", "\"batch_size\"", "]", "*", "params", "[", "\"tgt_max_len\"", "]", ",", ")", ")", "\n", "target", "[", "0", "]", "=", "init_case", "[", "\"unk_index\"", "]", "\n", "target", "[", "1", "]", "=", "init_case", "[", "\"ignore_index\"", "]", "\n", "return", "scores", ",", "align", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGeneratorLoss.expected_shape": [[107, 110], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "expected_shape", "(", "cls", ",", "params", ",", "init_case", ")", ":", "\n", "        ", "return", "(", "params", "[", "\"batch_size\"", "]", "*", "params", "[", "\"tgt_max_len\"", "]", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGeneratorLoss.test_copy_loss_forward_shape": [[111, 119], ["itertools.product", "onmt.modules.copy_generator.CopyGeneratorLoss", "test_copy_generator.TestCopyGeneratorLoss.dummy_inputs", "onmt.modules.copy_generator.CopyGeneratorLoss.", "test_copy_generator.TestCopyGeneratorLoss.expected_shape", "test_copy_generator.TestCopyGeneratorLoss.assertEqual", "init_case.__str__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGeneratorLoss.dummy_inputs", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGeneratorLoss.expected_shape"], ["", "def", "test_copy_loss_forward_shape", "(", "self", ")", ":", "\n", "        ", "for", "params", ",", "init_case", "in", "itertools", ".", "product", "(", "\n", "self", ".", "PARAMS", ",", "self", ".", "INIT_CASES", ")", ":", "\n", "            ", "loss", "=", "CopyGeneratorLoss", "(", "**", "init_case", ")", "\n", "dummy_in", "=", "self", ".", "dummy_inputs", "(", "params", ",", "init_case", ")", "\n", "res", "=", "loss", "(", "*", "dummy_in", ")", "\n", "expected_shape", "=", "self", ".", "expected_shape", "(", "params", ",", "init_case", ")", "\n", "self", ".", "assertEqual", "(", "res", ".", "shape", ",", "expected_shape", ",", "init_case", ".", "__str__", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGeneratorLoss.test_copy_loss_ignore_index_is_ignored": [[120, 129], ["itertools.product", "onmt.modules.copy_generator.CopyGeneratorLoss", "test_copy_generator.TestCopyGeneratorLoss.dummy_inputs", "onmt.modules.copy_generator.CopyGeneratorLoss.", "test_copy_generator.TestCopyGeneratorLoss.assertTrue", "len", "res[].allclose", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGeneratorLoss.dummy_inputs"], ["", "", "def", "test_copy_loss_ignore_index_is_ignored", "(", "self", ")", ":", "\n", "        ", "for", "params", ",", "init_case", "in", "itertools", ".", "product", "(", "\n", "self", ".", "PARAMS", ",", "self", ".", "INIT_CASES", ")", ":", "\n", "            ", "loss", "=", "CopyGeneratorLoss", "(", "**", "init_case", ")", "\n", "scores", ",", "align", ",", "target", "=", "self", ".", "dummy_inputs", "(", "params", ",", "init_case", ")", "\n", "res", "=", "loss", "(", "scores", ",", "align", ",", "target", ")", "\n", "should_be_ignored", "=", "(", "target", "==", "init_case", "[", "\"ignore_index\"", "]", ")", ".", "nonzero", "(", ")", "\n", "assert", "len", "(", "should_be_ignored", ")", ">", "0", "# otherwise not testing anything", "\n", "self", ".", "assertTrue", "(", "res", "[", "should_be_ignored", "]", ".", "allclose", "(", "torch", ".", "tensor", "(", "0.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGeneratorLoss.test_copy_loss_output_range_is_positive": [[130, 137], ["itertools.product", "onmt.modules.copy_generator.CopyGeneratorLoss", "test_copy_generator.TestCopyGeneratorLoss.dummy_inputs", "onmt.modules.copy_generator.CopyGeneratorLoss.", "test_copy_generator.TestCopyGeneratorLoss.assertTrue"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_copy_generator.TestCopyGeneratorLoss.dummy_inputs"], ["", "", "def", "test_copy_loss_output_range_is_positive", "(", "self", ")", ":", "\n", "        ", "for", "params", ",", "init_case", "in", "itertools", ".", "product", "(", "\n", "self", ".", "PARAMS", ",", "self", ".", "INIT_CASES", ")", ":", "\n", "            ", "loss", "=", "CopyGeneratorLoss", "(", "**", "init_case", ")", "\n", "dummy_in", "=", "self", ".", "dummy_inputs", "(", "params", ",", "init_case", ")", "\n", "res", "=", "loss", "(", "*", "dummy_in", ")", "\n", "self", ".", "assertTrue", "(", "(", "res", ">=", "0", ")", ".", "all", "(", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.utils_for_tests.product_dict": [[4, 9], ["kwargs.keys", "kwargs.values", "itertools.product", "dict", "zip"], "function", ["None"], ["def", "product_dict", "(", "**", "kwargs", ")", ":", "\n", "    ", "keys", "=", "kwargs", ".", "keys", "(", ")", "\n", "vals", "=", "kwargs", ".", "values", "(", ")", "\n", "for", "instance", "in", "itertools", ".", "product", "(", "*", "vals", ")", ":", "\n", "        ", "yield", "dict", "(", "zip", "(", "keys", ",", "instance", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_structured_attention.TestStructuredAttention.test_matrix_tree_marg_pdfs_sum_to_1": [[8, 14], ["onmt.modules.structured_attention.MatrixTree", "torch.rand", "onmt.modules.structured_attention.MatrixTree.forward", "test_structured_attention.TestStructuredAttention.assertTrue", "onmt.modules.structured_attention.MatrixTree.forward.sum().allclose", "torch.tensor", "onmt.modules.structured_attention.MatrixTree.forward.sum"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.forward"], ["    ", "def", "test_matrix_tree_marg_pdfs_sum_to_1", "(", "self", ")", ":", "\n", "        ", "dtree", "=", "MatrixTree", "(", ")", "\n", "q", "=", "torch", ".", "rand", "(", "1", ",", "5", ",", "5", ")", "\n", "marg", "=", "dtree", ".", "forward", "(", "q", ")", "\n", "self", ".", "assertTrue", "(", "\n", "marg", ".", "sum", "(", "1", ")", ".", "allclose", "(", "torch", ".", "tensor", "(", "1.0", ")", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_image_dataset.TestImageDataReader.setUpClass": [[38, 60], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "open", "f.write", "open", "open", "torch.randint", "torch.randint", "range", "numpy.random.randint", "cls._IMG_DATA_PATH_FMT.format", "cv2.imwrite", "cls._IMG_DATA_FMT.format", "f_list_fnames.write", "f_list_paths.write"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write"], ["@", "classmethod", "\n", "def", "setUpClass", "(", "cls", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "cls", ".", "_IMG_DATA_DIR", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "cls", ".", "_IMG_DATA_DIR", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cls", ".", "_IMG_LIST_DIR", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "cls", ".", "_IMG_LIST_DIR", ")", "\n", "\n", "", "with", "open", "(", "cls", ".", "_JUNK_FILE", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "\"this is some garbage\\nShould have no impact.\"", ")", "\n", "\n", "", "with", "open", "(", "cls", ".", "_IMG_LIST_PATHS_PATH", ",", "\"w\"", ")", "as", "f_list_fnames", ",", "open", "(", "cls", ".", "_IMG_LIST_FNAMES_PATH", ",", "\"w\"", ")", "as", "f_list_paths", ":", "\n", "            ", "cls", ".", "n_rows", "=", "torch", ".", "randint", "(", "30", ",", "314", ",", "(", "cls", ".", "_N_EXAMPLES", ",", ")", ")", "\n", "cls", ".", "n_cols", "=", "torch", ".", "randint", "(", "30", ",", "314", ",", "(", "cls", ".", "_N_EXAMPLES", ",", ")", ")", "\n", "for", "i", "in", "range", "(", "cls", ".", "_N_EXAMPLES", ")", ":", "\n", "                ", "img", "=", "np", ".", "random", ".", "randint", "(", "\n", "0", ",", "255", ",", "(", "cls", ".", "n_rows", "[", "i", "]", ",", "cls", ".", "n_cols", "[", "i", "]", ",", "cls", ".", "_N_CHANNELS", ")", ")", "\n", "f_path", "=", "cls", ".", "_IMG_DATA_PATH_FMT", ".", "format", "(", "i", ")", "\n", "cv2", ".", "imwrite", "(", "f_path", ",", "img", ")", "\n", "f_name_short", "=", "cls", ".", "_IMG_DATA_FMT", ".", "format", "(", "i", ")", "\n", "f_list_fnames", ".", "write", "(", "f_name_short", "+", "\"\\n\"", ")", "\n", "f_list_paths", ".", "write", "(", "f_path", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_image_dataset.TestImageDataReader.tearDownClass": [[61, 65], ["shutil.rmtree", "shutil.rmtree"], "methods", ["None"], ["", "", "", "@", "classmethod", "\n", "def", "tearDownClass", "(", "cls", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "cls", ".", "_IMG_DATA_DIR", ")", "\n", "shutil", ".", "rmtree", "(", "cls", ".", "_IMG_LIST_DIR", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_image_dataset.TestImageDataReader.test_read_from_dir_and_data_file_containing_filenames": [[66, 77], ["onmt.inputters.image_dataset.ImageDataReader", "enumerate", "test_image_dataset.TestImageDataReader.assertGreater", "onmt.inputters.image_dataset.ImageDataReader.read", "test_image_dataset.TestImageDataReader.assertEqual", "test_image_dataset.TestImageDataReader.assertEqual", "test_image_dataset.TestImageDataReader._IMG_DATA_PATH_FMT.format"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioDataReader.read"], ["", "def", "test_read_from_dir_and_data_file_containing_filenames", "(", "self", ")", ":", "\n", "        ", "rdr", "=", "ImageDataReader", "(", "channel_size", "=", "self", ".", "_N_CHANNELS", ")", "\n", "i", "=", "0", "# initialize since there's a sanity check on i", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "rdr", ".", "read", "(", "\n", "self", ".", "_IMG_LIST_FNAMES_PATH", ",", "\"src\"", ",", "self", ".", "_IMG_DATA_DIR", ")", ")", ":", "\n", "            ", "self", ".", "assertEqual", "(", "\n", "img", "[", "\"src\"", "]", ".", "shape", ",", "\n", "(", "self", ".", "_N_CHANNELS", ",", "self", ".", "n_rows", "[", "i", "]", ",", "self", ".", "n_cols", "[", "i", "]", ")", ")", "\n", "self", ".", "assertEqual", "(", "img", "[", "\"src_path\"", "]", ",", "\n", "self", ".", "_IMG_DATA_PATH_FMT", ".", "format", "(", "i", ")", ")", "\n", "", "self", ".", "assertGreater", "(", "i", ",", "0", ",", "\"No image data was read.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_image_dataset.TestImageDataReader.test_read_from_dir_and_data_file_containing_paths": [[78, 89], ["onmt.inputters.image_dataset.ImageDataReader", "enumerate", "test_image_dataset.TestImageDataReader.assertGreater", "onmt.inputters.image_dataset.ImageDataReader.read", "test_image_dataset.TestImageDataReader.assertEqual", "test_image_dataset.TestImageDataReader.assertEqual", "test_image_dataset.TestImageDataReader._IMG_DATA_FMT.format"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioDataReader.read"], ["", "def", "test_read_from_dir_and_data_file_containing_paths", "(", "self", ")", ":", "\n", "        ", "rdr", "=", "ImageDataReader", "(", "channel_size", "=", "self", ".", "_N_CHANNELS", ")", "\n", "i", "=", "0", "# initialize since there's a sanity check on i", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "rdr", ".", "read", "(", "\n", "self", ".", "_IMG_LIST_PATHS_PATH", ",", "\"src\"", ",", "self", ".", "_IMG_DATA_DIR", ")", ")", ":", "\n", "            ", "self", ".", "assertEqual", "(", "\n", "img", "[", "\"src\"", "]", ".", "shape", ",", "\n", "(", "self", ".", "_N_CHANNELS", ",", "self", ".", "n_rows", "[", "i", "]", ",", "self", ".", "n_cols", "[", "i", "]", ")", ")", "\n", "self", ".", "assertEqual", "(", "img", "[", "\"src_path\"", "]", ",", "\n", "self", ".", "_IMG_DATA_FMT", ".", "format", "(", "i", ")", ")", "\n", "", "self", ".", "assertGreater", "(", "i", ",", "0", ",", "\"No image data was read.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestServerModel.test_deferred_loading_model_and_unload": [[17, 28], ["onmt.translate.translation_server.ServerModel", "test_translation_server.TestServerModel.assertFalse", "onmt.translate.translation_server.ServerModel.load", "test_translation_server.TestServerModel.assertTrue", "test_translation_server.TestServerModel.assertIsInstance", "onmt.translate.translation_server.ServerModel.unload", "test_translation_server.TestServerModel.assertFalse"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.unload"], ["    ", "def", "test_deferred_loading_model_and_unload", "(", "self", ")", ":", "\n", "        ", "model_id", "=", "0", "\n", "opt", "=", "{", "\"models\"", ":", "[", "\"test_model.pt\"", "]", "}", "\n", "model_root", "=", "TEST_DIR", "\n", "sm", "=", "ServerModel", "(", "opt", ",", "model_id", ",", "model_root", "=", "model_root", ",", "load", "=", "False", ")", "\n", "self", ".", "assertFalse", "(", "sm", ".", "loaded", ")", "\n", "sm", ".", "load", "(", ")", "\n", "self", ".", "assertTrue", "(", "sm", ".", "loaded", ")", "\n", "self", ".", "assertIsInstance", "(", "sm", ".", "translator", ",", "Translator", ")", "\n", "sm", ".", "unload", "(", ")", "\n", "self", ".", "assertFalse", "(", "sm", ".", "loaded", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestServerModel.test_load_model_on_init_and_unload": [[29, 38], ["onmt.translate.translation_server.ServerModel", "test_translation_server.TestServerModel.assertTrue", "test_translation_server.TestServerModel.assertIsInstance", "onmt.translate.translation_server.ServerModel.unload", "test_translation_server.TestServerModel.assertFalse"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.unload"], ["", "def", "test_load_model_on_init_and_unload", "(", "self", ")", ":", "\n", "        ", "model_id", "=", "0", "\n", "opt", "=", "{", "\"models\"", ":", "[", "\"test_model.pt\"", "]", "}", "\n", "model_root", "=", "TEST_DIR", "\n", "sm", "=", "ServerModel", "(", "opt", ",", "model_id", ",", "model_root", "=", "model_root", ",", "load", "=", "True", ")", "\n", "self", ".", "assertTrue", "(", "sm", ".", "loaded", ")", "\n", "self", ".", "assertIsInstance", "(", "sm", ".", "translator", ",", "Translator", ")", "\n", "sm", ".", "unload", "(", ")", "\n", "self", ".", "assertFalse", "(", "sm", ".", "loaded", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestServerModel.test_tokenizing_with_no_tokenizer_fails": [[39, 46], ["onmt.translate.translation_server.ServerModel", "test_translation_server.TestServerModel.assertRaises", "onmt.translate.translation_server.ServerModel.tokenize"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.tokenize"], ["", "def", "test_tokenizing_with_no_tokenizer_fails", "(", "self", ")", ":", "\n", "        ", "model_id", "=", "0", "\n", "opt", "=", "{", "\"models\"", ":", "[", "\"test_model.pt\"", "]", "}", "\n", "model_root", "=", "TEST_DIR", "\n", "sm", "=", "ServerModel", "(", "opt", ",", "model_id", ",", "model_root", "=", "model_root", ",", "load", "=", "True", ")", "\n", "with", "self", ".", "assertRaises", "(", "ValueError", ")", ":", "\n", "            ", "sm", ".", "tokenize", "(", "\"hello world\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestServerModel.test_detokenizing_with_no_tokenizer_fails": [[47, 54], ["onmt.translate.translation_server.ServerModel", "test_translation_server.TestServerModel.assertRaises", "onmt.translate.translation_server.ServerModel.detokenize"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.detokenize"], ["", "", "def", "test_detokenizing_with_no_tokenizer_fails", "(", "self", ")", ":", "\n", "        ", "model_id", "=", "0", "\n", "opt", "=", "{", "\"models\"", ":", "[", "\"test_model.pt\"", "]", "}", "\n", "model_root", "=", "TEST_DIR", "\n", "sm", "=", "ServerModel", "(", "opt", ",", "model_id", ",", "model_root", "=", "model_root", ",", "load", "=", "True", ")", "\n", "with", "self", ".", "assertRaises", "(", "ValueError", ")", ":", "\n", "            ", "sm", ".", "detokenize", "(", "\"hello world\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestServerModel.test_run": [[108, 128], ["onmt.translate.translation_server.ServerModel", "onmt.translate.translation_server.ServerModel.run", "test_translation_server.TestServerModel.assertIsInstance", "test_translation_server.TestServerModel.assertIsInstance", "test_translation_server.TestServerModel.assertEqual", "test_translation_server.TestServerModel.assertEqual", "test_translation_server.TestServerModel.assertEqual", "test_translation_server.TestServerModel.assertEqual", "test_translation_server.TestServerModel.assertIsInstance", "test_translation_server.TestServerModel.assertIn", "test_translation_server.TestServerModel.assertIsInstance", "test_translation_server.TestServerModel.assertIsInstance", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.ServerModel.run"], ["", "", "", "", "def", "test_run", "(", "self", ")", ":", "\n", "        ", "model_id", "=", "0", "\n", "opt", "=", "{", "\"models\"", ":", "[", "\"test_model.pt\"", "]", "}", "\n", "model_root", "=", "TEST_DIR", "\n", "sm", "=", "ServerModel", "(", "opt", ",", "model_id", ",", "model_root", "=", "model_root", ",", "load", "=", "True", ")", "\n", "inp", "=", "[", "{", "\"src\"", ":", "\"hello how are you today\"", "}", ",", "\n", "{", "\"src\"", ":", "\"good morning to you .\"", "}", "]", "\n", "results", ",", "scores", ",", "n_best", ",", "time", "=", "sm", ".", "run", "(", "inp", ")", "\n", "self", ".", "assertIsInstance", "(", "results", ",", "list", ")", "\n", "for", "sentence_string", "in", "results", ":", "\n", "            ", "self", ".", "assertIsInstance", "(", "sentence_string", ",", "string_types", ")", "\n", "", "self", ".", "assertIsInstance", "(", "scores", ",", "list", ")", "\n", "for", "elem", "in", "scores", ":", "\n", "            ", "self", ".", "assertIsInstance", "(", "elem", ",", "float", ")", "\n", "", "self", ".", "assertEqual", "(", "len", "(", "results", ")", ",", "len", "(", "scores", ")", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "scores", ")", ",", "len", "(", "inp", ")", ")", "\n", "self", ".", "assertEqual", "(", "n_best", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "time", ")", ",", "1", ")", "\n", "self", ".", "assertIsInstance", "(", "time", ",", "dict", ")", "\n", "self", ".", "assertIn", "(", "\"translation\"", ",", "time", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestServerModel.test_nbest_init_fails": [[129, 135], ["test_translation_server.TestServerModel.assertRaises", "onmt.translate.translation_server.ServerModel"], "methods", ["None"], ["", "def", "test_nbest_init_fails", "(", "self", ")", ":", "\n", "        ", "model_id", "=", "0", "\n", "opt", "=", "{", "\"models\"", ":", "[", "\"test_model.pt\"", "]", ",", "\"n_best\"", ":", "2", "}", "\n", "model_root", "=", "TEST_DIR", "\n", "with", "self", ".", "assertRaises", "(", "ValueError", ")", ":", "\n", "            ", "ServerModel", "(", "opt", ",", "model_id", ",", "model_root", "=", "model_root", ",", "load", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.tearDown": [[144, 147], ["os.path.exists", "os.remove"], "methods", ["None"], ["def", "tearDown", "(", "self", ")", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "CFG_F", ")", ":", "\n", "            ", "os", ".", "remove", "(", "self", ".", "CFG_F", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write": [[148, 151], ["open", "f.write"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write"], ["", "", "def", "write", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "CFG_F", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.test_start_without_initial_loading": [[170, 176], ["test_translation_server.TestTranslationServer.write", "onmt.translate.translation_server.TranslationServer", "onmt.translate.translation_server.TranslationServer.start", "test_translation_server.TestTranslationServer.assertFalse", "test_translation_server.TestTranslationServer.assertEqual", "set", "onmt.translate.translation_server.TranslationServer.models.keys"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.start"], ["def", "test_start_without_initial_loading", "(", "self", ")", ":", "\n", "        ", "self", ".", "write", "(", "self", ".", "CFG_NO_LOAD", ")", "\n", "sv", "=", "TranslationServer", "(", ")", "\n", "sv", ".", "start", "(", "self", ".", "CFG_F", ")", "\n", "self", ".", "assertFalse", "(", "sv", ".", "models", "[", "100", "]", ".", "loaded", ")", "\n", "self", ".", "assertEqual", "(", "set", "(", "sv", ".", "models", ".", "keys", "(", ")", ")", ",", "{", "100", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.test_start_with_initial_loading": [[195, 201], ["test_translation_server.TestTranslationServer.write", "onmt.translate.translation_server.TranslationServer", "onmt.translate.translation_server.TranslationServer.start", "test_translation_server.TestTranslationServer.assertTrue", "test_translation_server.TestTranslationServer.assertEqual", "set", "onmt.translate.translation_server.TranslationServer.models.keys"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.start"], ["def", "test_start_with_initial_loading", "(", "self", ")", ":", "\n", "        ", "self", ".", "write", "(", "self", ".", "CFG_LOAD", ")", "\n", "sv", "=", "TranslationServer", "(", ")", "\n", "sv", ".", "start", "(", "self", ".", "CFG_F", ")", "\n", "self", ".", "assertTrue", "(", "sv", ".", "models", "[", "100", "]", ".", "loaded", ")", "\n", "self", ".", "assertEqual", "(", "set", "(", "sv", ".", "models", ".", "keys", "(", ")", ")", ",", "{", "100", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.test_start_with_two_models": [[230, 237], ["test_translation_server.TestTranslationServer.write", "onmt.translate.translation_server.TranslationServer", "onmt.translate.translation_server.TranslationServer.start", "test_translation_server.TestTranslationServer.assertTrue", "test_translation_server.TestTranslationServer.assertFalse", "test_translation_server.TestTranslationServer.assertEqual", "set", "onmt.translate.translation_server.TranslationServer.models.keys"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write", "home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.translation_server.TranslationServer.start"], ["def", "test_start_with_two_models", "(", "self", ")", ":", "\n", "        ", "self", ".", "write", "(", "self", ".", "CFG_2_MODELS", ")", "\n", "sv", "=", "TranslationServer", "(", ")", "\n", "sv", ".", "start", "(", "self", ".", "CFG_F", ")", "\n", "self", ".", "assertTrue", "(", "sv", ".", "models", "[", "100", "]", ".", "loaded", ")", "\n", "self", ".", "assertFalse", "(", "sv", ".", "models", "[", "1000", "]", ".", "loaded", ")", "\n", "self", ".", "assertEqual", "(", "set", "(", "sv", ".", "models", ".", "keys", "(", ")", ")", ",", "{", "100", ",", "1000", "}", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_simple.test_load": [[4, 7], ["None"], "function", ["None"], ["def", "test_load", "(", ")", ":", "\n", "    ", "onmt", "\n", "pass", "\n", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextMultiField.initialize_case": [[25, 35], ["copy.deepcopy", "enumerate", "f_cls"], "methods", ["None"], ["@", "classmethod", "\n", "def", "initialize_case", "(", "cls", ",", "init_case", ",", "params", ")", ":", "\n", "# initialize fields at the top of each unit test to prevent", "\n", "# any undesired stateful effects", "\n", "        ", "case", "=", "deepcopy", "(", "init_case", ")", "\n", "case", "[", "\"base_field\"", "]", "=", "case", "[", "\"base_field\"", "]", "(", "\n", "include_lengths", "=", "params", "[", "\"include_lengths\"", "]", ")", "\n", "for", "i", ",", "(", "n", ",", "f_cls", ")", "in", "enumerate", "(", "case", "[", "\"feats_fields\"", "]", ")", ":", "\n", "            ", "case", "[", "\"feats_fields\"", "]", "[", "i", "]", "=", "(", "n", ",", "f_cls", "(", "sequential", "=", "True", ")", ")", "\n", "", "return", "case", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextMultiField.test_process_shape": [[36, 76], ["itertools.product", "test_text_dataset.TestTextMultiField.initialize_case", "onmt.inputters.text_dataset.TextMultiField", "len", "enumerate", "onmt.inputters.text_dataset.TextMultiField.process", "test_text_dataset.TestTextMultiField.assertEqual", "f.build_vocab", "test_text_dataset.TestTextMultiField.assertEqual"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextMultiField.initialize_case", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.text_dataset.TextMultiField.process", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.inputter.build_vocab"], ["", "def", "test_process_shape", "(", "self", ")", ":", "\n", "        ", "dummy_input_bs_1", "=", "[", "[", "\n", "[", "\"this\"", ",", "\"is\"", ",", "\"for\"", ",", "\"the\"", ",", "\"unittest\"", "]", ",", "\n", "[", "\"NOUN\"", ",", "\"VERB\"", ",", "\"PREP\"", ",", "\"ART\"", ",", "\"NOUN\"", "]", ",", "\n", "[", "\"\"", ",", "\"\"", ",", "\"\"", ",", "\"\"", ",", "\"MODULE\"", "]", "]", "]", "\n", "dummy_input_bs_5", "=", "[", "\n", "[", "[", "\"this\"", ",", "\"is\"", ",", "\"for\"", ",", "\"the\"", ",", "\"unittest\"", "]", ",", "\n", "[", "\"NOUN\"", ",", "\"VERB\"", ",", "\"PREP\"", ",", "\"ART\"", ",", "\"NOUN\"", "]", ",", "\n", "[", "\"\"", ",", "\"\"", ",", "\"\"", ",", "\"\"", ",", "\"MODULE\"", "]", "]", ",", "\n", "[", "[", "\"batch\"", ",", "\"2\"", "]", ",", "\n", "[", "\"NOUN\"", ",", "\"NUM\"", "]", ",", "\n", "[", "\"\"", ",", "\"\"", "]", "]", ",", "\n", "[", "[", "\"batch\"", ",", "\"3\"", ",", "\"is\"", ",", "\"the\"", ",", "\"longest\"", ",", "\"batch\"", "]", ",", "\n", "[", "\"NOUN\"", ",", "\"NUM\"", ",", "\"VERB\"", ",", "\"ART\"", ",", "\"ADJ\"", ",", "\"NOUN\"", "]", ",", "\n", "[", "\"\"", ",", "\"\"", ",", "\"\"", ",", "\"\"", ",", "\"\"", ",", "\"\"", "]", "]", ",", "\n", "[", "[", "\"fourth\"", ",", "\"batch\"", "]", ",", "\n", "[", "\"ORD\"", ",", "\"NOUN\"", "]", ",", "\n", "[", "\"\"", ",", "\"\"", "]", "]", ",", "\n", "[", "[", "\"and\"", ",", "\"another\"", ",", "\"one\"", "]", ",", "\n", "[", "\"CONJ\"", ",", "\"?\"", ",", "\"NUM\"", "]", ",", "\n", "[", "\"\"", ",", "\"\"", ",", "\"\"", "]", "]", "]", "\n", "for", "bs", ",", "max_len", ",", "dummy_input", "in", "[", "\n", "(", "1", ",", "5", ",", "dummy_input_bs_1", ")", ",", "(", "5", ",", "6", ",", "dummy_input_bs_5", ")", "]", ":", "\n", "            ", "for", "init_case", ",", "params", "in", "itertools", ".", "product", "(", "\n", "self", ".", "INIT_CASES", ",", "self", ".", "PARAMS", ")", ":", "\n", "                ", "init_case", "=", "self", ".", "initialize_case", "(", "init_case", ",", "params", ")", "\n", "mf", "=", "TextMultiField", "(", "**", "init_case", ")", "\n", "fields", "=", "[", "init_case", "[", "\"base_field\"", "]", "]", "+", "[", "f", "for", "_", ",", "f", "in", "init_case", "[", "\"feats_fields\"", "]", "]", "\n", "nfields", "=", "len", "(", "fields", ")", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "fields", ")", ":", "\n", "                    ", "all_sents", "=", "[", "b", "[", "i", "]", "for", "b", "in", "dummy_input", "]", "\n", "f", ".", "build_vocab", "(", "all_sents", ")", "\n", "", "inp_only_desired_fields", "=", "[", "b", "[", ":", "nfields", "]", "for", "b", "in", "dummy_input", "]", "\n", "data", "=", "mf", ".", "process", "(", "inp_only_desired_fields", ")", "\n", "if", "params", "[", "\"include_lengths\"", "]", ":", "\n", "                    ", "data", ",", "lengths", "=", "data", "\n", "self", ".", "assertEqual", "(", "lengths", ".", "shape", ",", "(", "bs", ",", ")", ")", "\n", "", "expected_shape", "=", "(", "max_len", ",", "bs", ",", "nfields", ")", "\n", "self", ".", "assertEqual", "(", "data", ".", "shape", ",", "expected_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextMultiField.test_preprocess_shape": [[77, 85], ["itertools.product", "test_text_dataset.TestTextMultiField.initialize_case", "onmt.inputters.text_dataset.TextMultiField", "onmt.inputters.text_dataset.TextMultiField.preprocess", "test_text_dataset.TestTextMultiField.assertEqual", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextMultiField.initialize_case", "home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.text_dataset.TextMultiField.preprocess"], ["", "", "", "def", "test_preprocess_shape", "(", "self", ")", ":", "\n", "        ", "for", "init_case", ",", "params", "in", "itertools", ".", "product", "(", "\n", "self", ".", "INIT_CASES", ",", "self", ".", "PARAMS", ")", ":", "\n", "            ", "init_case", "=", "self", ".", "initialize_case", "(", "init_case", ",", "params", ")", "\n", "mf", "=", "TextMultiField", "(", "**", "init_case", ")", "\n", "sample_str", "=", "\"dummy input here .\"", "\n", "proc", "=", "mf", ".", "preprocess", "(", "sample_str", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "proc", ")", ",", "len", "(", "init_case", "[", "\"feats_fields\"", "]", ")", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextMultiField.test_base_field": [[86, 92], ["itertools.product", "test_text_dataset.TestTextMultiField.initialize_case", "onmt.inputters.text_dataset.TextMultiField", "test_text_dataset.TestTextMultiField.assertIs"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextMultiField.initialize_case"], ["", "", "def", "test_base_field", "(", "self", ")", ":", "\n", "        ", "for", "init_case", ",", "params", "in", "itertools", ".", "product", "(", "\n", "self", ".", "INIT_CASES", ",", "self", ".", "PARAMS", ")", ":", "\n", "            ", "init_case", "=", "self", ".", "initialize_case", "(", "init_case", ",", "params", ")", "\n", "mf", "=", "TextMultiField", "(", "**", "init_case", ")", "\n", "self", ".", "assertIs", "(", "mf", ".", "base_field", ",", "init_case", "[", "\"base_field\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextMultiField.test_correct_n_fields": [[93, 100], ["itertools.product", "test_text_dataset.TestTextMultiField.initialize_case", "onmt.inputters.text_dataset.TextMultiField", "test_text_dataset.TestTextMultiField.assertEqual", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextMultiField.initialize_case"], ["", "", "def", "test_correct_n_fields", "(", "self", ")", ":", "\n", "        ", "for", "init_case", ",", "params", "in", "itertools", ".", "product", "(", "\n", "self", ".", "INIT_CASES", ",", "self", ".", "PARAMS", ")", ":", "\n", "            ", "init_case", "=", "self", ".", "initialize_case", "(", "init_case", ",", "params", ")", "\n", "mf", "=", "TextMultiField", "(", "**", "init_case", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "mf", ".", "fields", ")", ",", "\n", "len", "(", "init_case", "[", "\"feats_fields\"", "]", ")", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextMultiField.test_fields_order_correct": [[101, 109], ["itertools.product", "test_text_dataset.TestTextMultiField.initialize_case", "onmt.inputters.text_dataset.TextMultiField", "test_text_dataset.TestTextMultiField.assertEqual", "list", "sorted"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextMultiField.initialize_case"], ["", "", "def", "test_fields_order_correct", "(", "self", ")", ":", "\n", "        ", "for", "init_case", ",", "params", "in", "itertools", ".", "product", "(", "\n", "self", ".", "INIT_CASES", ",", "self", ".", "PARAMS", ")", ":", "\n", "            ", "init_case", "=", "self", ".", "initialize_case", "(", "init_case", ",", "params", ")", "\n", "mf", "=", "TextMultiField", "(", "**", "init_case", ")", "\n", "fnames", "=", "[", "name", "for", "name", ",", "_", "in", "init_case", "[", "\"feats_fields\"", "]", "]", "\n", "correct_order", "=", "[", "init_case", "[", "\"base_name\"", "]", "]", "+", "list", "(", "sorted", "(", "fnames", ")", ")", "\n", "self", ".", "assertEqual", "(", "[", "name", "for", "name", ",", "_", "in", "mf", ".", "fields", "]", ",", "correct_order", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextMultiField.test_getitem_0_returns_correct_field": [[110, 117], ["itertools.product", "test_text_dataset.TestTextMultiField.initialize_case", "onmt.inputters.text_dataset.TextMultiField", "test_text_dataset.TestTextMultiField.assertEqual", "test_text_dataset.TestTextMultiField.assertIs"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextMultiField.initialize_case"], ["", "", "def", "test_getitem_0_returns_correct_field", "(", "self", ")", ":", "\n", "        ", "for", "init_case", ",", "params", "in", "itertools", ".", "product", "(", "\n", "self", ".", "INIT_CASES", ",", "self", ".", "PARAMS", ")", ":", "\n", "            ", "init_case", "=", "self", ".", "initialize_case", "(", "init_case", ",", "params", ")", "\n", "mf", "=", "TextMultiField", "(", "**", "init_case", ")", "\n", "self", ".", "assertEqual", "(", "mf", "[", "0", "]", "[", "0", "]", ",", "init_case", "[", "\"base_name\"", "]", ")", "\n", "self", ".", "assertIs", "(", "mf", "[", "0", "]", "[", "1", "]", ",", "init_case", "[", "\"base_field\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextMultiField.test_getitem_nonzero_returns_correct_field": [[118, 130], ["itertools.product", "test_text_dataset.TestTextMultiField.initialize_case", "onmt.inputters.text_dataset.TextMultiField", "len", "list", "dict", "enumerate", "sorted", "test_text_dataset.TestTextMultiField.assertIs"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextMultiField.initialize_case"], ["", "", "def", "test_getitem_nonzero_returns_correct_field", "(", "self", ")", ":", "\n", "        ", "for", "init_case", ",", "params", "in", "itertools", ".", "product", "(", "\n", "self", ".", "INIT_CASES", ",", "self", ".", "PARAMS", ")", ":", "\n", "            ", "init_case", "=", "self", ".", "initialize_case", "(", "init_case", ",", "params", ")", "\n", "mf", "=", "TextMultiField", "(", "**", "init_case", ")", "\n", "fnames", "=", "[", "name", "for", "name", ",", "_", "in", "init_case", "[", "\"feats_fields\"", "]", "]", "\n", "if", "len", "(", "fnames", ")", ">", "0", ":", "\n", "                ", "ordered_names", "=", "list", "(", "sorted", "(", "fnames", ")", ")", "\n", "name2field", "=", "dict", "(", "init_case", "[", "\"feats_fields\"", "]", ")", "\n", "for", "i", ",", "name", "in", "enumerate", "(", "ordered_names", ",", "1", ")", ":", "\n", "                    ", "expected_field", "=", "name2field", "[", "name", "]", "\n", "self", ".", "assertIs", "(", "mf", "[", "i", "]", "[", "1", "]", ",", "expected_field", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextMultiField.test_getitem_has_correct_number_of_indexes": [[131, 139], ["itertools.product", "test_text_dataset.TestTextMultiField.initialize_case", "onmt.inputters.text_dataset.TextMultiField", "len", "test_text_dataset.TestTextMultiField.assertRaises"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextMultiField.initialize_case"], ["", "", "", "", "def", "test_getitem_has_correct_number_of_indexes", "(", "self", ")", ":", "\n", "        ", "for", "init_case", ",", "params", "in", "itertools", ".", "product", "(", "\n", "self", ".", "INIT_CASES", ",", "self", ".", "PARAMS", ")", ":", "\n", "            ", "init_case", "=", "self", ".", "initialize_case", "(", "init_case", ",", "params", ")", "\n", "mf", "=", "TextMultiField", "(", "**", "init_case", ")", "\n", "nfields", "=", "len", "(", "init_case", "[", "\"feats_fields\"", "]", ")", "+", "1", "\n", "with", "self", ".", "assertRaises", "(", "IndexError", ")", ":", "\n", "                ", "mf", "[", "nfields", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextDataReader.test_read": [[142, 151], ["onmt.inputters.text_dataset.TextDataReader", "enumerate", "onmt.inputters.text_dataset.TextDataReader.read", "test_text_dataset.TestTextDataReader.assertEqual", "strings[].decode"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioDataReader.read"], ["    ", "def", "test_read", "(", "self", ")", ":", "\n", "        ", "strings", "=", "[", "\n", "\"hello world\"", ".", "encode", "(", "\"utf-8\"", ")", ",", "\n", "\"this's a string with punctuation .\"", ".", "encode", "(", "\"utf-8\"", ")", ",", "\n", "\"ThIs Is A sTrInG wItH oDD CapitALIZAtion\"", ".", "encode", "(", "\"utf-8\"", ")", "\n", "]", "\n", "rdr", "=", "TextDataReader", "(", ")", "\n", "for", "i", ",", "ex", "in", "enumerate", "(", "rdr", ".", "read", "(", "strings", ",", "\"src\"", ")", ")", ":", "\n", "            ", "self", ".", "assertEqual", "(", "ex", "[", "\"src\"", "]", ",", "strings", "[", "i", "]", ".", "decode", "(", "\"utf-8\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextDataReaderFromFS.setUpClass": [[163, 169], ["open", "f.write"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_translation_server.TestTranslationServer.write"], ["@", "classmethod", "\n", "def", "setUpClass", "(", "cls", ")", ":", "\n", "# write utf-8 bytes", "\n", "        ", "with", "open", "(", "cls", ".", "FILE_NAME", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "for", "str_", "in", "cls", ".", "STRINGS", ":", "\n", "                ", "f", ".", "write", "(", "str_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextDataReaderFromFS.tearDownClass": [[170, 173], ["os.remove"], "methods", ["None"], ["", "", "", "@", "classmethod", "\n", "def", "tearDownClass", "(", "cls", ")", ":", "\n", "        ", "os", ".", "remove", "(", "cls", ".", "FILE_NAME", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_text_dataset.TestTextDataReaderFromFS.test_read": [[174, 178], ["onmt.inputters.text_dataset.TextDataReader", "enumerate", "onmt.inputters.text_dataset.TextDataReader.read", "test_text_dataset.TestTextDataReaderFromFS.assertEqual", "test_text_dataset.TestTextDataReaderFromFS.STRINGS[].decode"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.inputters.audio_dataset.AudioDataReader.read"], ["", "def", "test_read", "(", "self", ")", ":", "\n", "        ", "rdr", "=", "TextDataReader", "(", ")", "\n", "for", "i", ",", "ex", "in", "enumerate", "(", "rdr", ".", "read", "(", "self", ".", "FILE_NAME", ",", "\"src\"", ")", ")", ":", "\n", "            ", "self", ".", "assertEqual", "(", "ex", "[", "\"src\"", "]", ",", "self", ".", "STRINGS", "[", "i", "]", ".", "decode", "(", "\"utf-8\"", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_attention.TestAttention.test_masked_global_attention": [[13, 33], ["torch.IntTensor", "torch.IntTensor.size", "torch.autograd.Variable", "torch.autograd.Variable", "onmt.modules.GlobalAttention", "onmt.modules.GlobalAttention.", "torch.randn", "torch.randn", "torch.IntTensor.max"], "methods", ["None"], ["    ", "def", "test_masked_global_attention", "(", "self", ")", ":", "\n", "\n", "        ", "source_lengths", "=", "torch", ".", "IntTensor", "(", "[", "7", ",", "3", ",", "5", ",", "2", "]", ")", "\n", "# illegal_weights_mask = torch.ByteTensor([", "\n", "#     [0, 0, 0, 0, 0, 0, 0],", "\n", "#     [0, 0, 0, 1, 1, 1, 1],", "\n", "#     [0, 0, 0, 0, 0, 1, 1],", "\n", "#     [0, 0, 1, 1, 1, 1, 1]])", "\n", "\n", "batch_size", "=", "source_lengths", ".", "size", "(", "0", ")", "\n", "dim", "=", "20", "\n", "\n", "memory_bank", "=", "Variable", "(", "torch", ".", "randn", "(", "batch_size", ",", "\n", "source_lengths", ".", "max", "(", ")", ",", "dim", ")", ")", "\n", "hidden", "=", "Variable", "(", "torch", ".", "randn", "(", "batch_size", ",", "dim", ")", ")", "\n", "\n", "attn", "=", "onmt", ".", "modules", ".", "GlobalAttention", "(", "dim", ")", "\n", "\n", "_", ",", "alignments", "=", "attn", "(", "hidden", ",", "memory_bank", ",", "\n", "memory_lengths", "=", "source_lengths", ")", "\n", "# TODO: fix for pytorch 0.3", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.GlobalScorerStub.update_global_state": [[8, 10], ["None"], "methods", ["None"], ["    ", "def", "update_global_state", "(", "self", ",", "beam", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.GlobalScorerStub.score": [[11, 13], ["None"], "methods", ["None"], ["", "def", "score", "(", "self", ",", "beam", ",", "scores", ")", ":", "\n", "        ", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeam.test_advance_with_all_repeats_gets_blocked": [[18, 43], ["onmt.translate.beam.Beam", "range", "torch.full", "torch.randn", "onmt.translate.beam.Beam.advance", "set", "test_beam.GlobalScorerStub", "test_beam.TestBeam.assertTrue", "test_beam.TestBeam.assertTrue", "float", "onmt.translate.beam.Beam.scores.equal", "onmt.translate.beam.Beam.scores.equal", "torch.tensor", "torch.tensor", "float"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance"], ["def", "test_advance_with_all_repeats_gets_blocked", "(", "self", ")", ":", "\n", "# all beams repeat (beam >= 1 repeat dummy scores)", "\n", "        ", "beam_sz", "=", "5", "\n", "n_words", "=", "100", "\n", "repeat_idx", "=", "47", "\n", "ngram_repeat", "=", "3", "\n", "beam", "=", "Beam", "(", "beam_sz", ",", "0", ",", "1", ",", "2", ",", "n_best", "=", "2", ",", "\n", "exclusion_tokens", "=", "set", "(", ")", ",", "\n", "global_scorer", "=", "GlobalScorerStub", "(", ")", ",", "\n", "block_ngram_repeat", "=", "ngram_repeat", ")", "\n", "for", "i", "in", "range", "(", "ngram_repeat", "+", "4", ")", ":", "\n", "# predict repeat_idx over and over again", "\n", "            ", "word_probs", "=", "torch", ".", "full", "(", "(", "beam_sz", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "word_probs", "[", "0", ",", "repeat_idx", "]", "=", "0", "\n", "attns", "=", "torch", ".", "randn", "(", "beam_sz", ")", "\n", "beam", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "if", "i", "<=", "ngram_repeat", ":", "\n", "                ", "self", ".", "assertTrue", "(", "\n", "beam", ".", "scores", ".", "equal", "(", "\n", "torch", ".", "tensor", "(", "\n", "[", "0", "]", "+", "[", "-", "float", "(", "'inf'", ")", "]", "*", "(", "beam_sz", "-", "1", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "assertTrue", "(", "\n", "beam", ".", "scores", ".", "equal", "(", "torch", ".", "tensor", "(", "\n", "[", "self", ".", "BLOCKED_SCORE", "]", "*", "beam_sz", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeam.test_advance_with_some_repeats_gets_blocked": [[44, 79], ["onmt.translate.beam.Beam", "range", "torch.full", "torch.randn", "onmt.translate.beam.Beam.advance", "set", "test_beam.GlobalScorerStub", "test_beam.TestBeam.assertFalse", "test_beam.TestBeam.assertFalse", "test_beam.TestBeam.assertFalse", "test_beam.TestBeam.assertTrue", "float", "onmt.translate.beam.Beam.scores[].eq", "onmt.translate.beam.Beam.scores[].eq", "onmt.translate.beam.Beam.scores[].eq", "onmt.translate.beam.Beam.scores[].equal", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance"], ["", "", "", "def", "test_advance_with_some_repeats_gets_blocked", "(", "self", ")", ":", "\n", "# beam 0 and beam >=2 will repeat (beam >= 2 repeat dummy scores)", "\n", "        ", "beam_sz", "=", "5", "\n", "n_words", "=", "100", "\n", "repeat_idx", "=", "47", "\n", "ngram_repeat", "=", "3", "\n", "beam", "=", "Beam", "(", "beam_sz", ",", "0", ",", "1", ",", "2", ",", "n_best", "=", "2", ",", "\n", "exclusion_tokens", "=", "set", "(", ")", ",", "\n", "global_scorer", "=", "GlobalScorerStub", "(", ")", ",", "\n", "block_ngram_repeat", "=", "ngram_repeat", ")", "\n", "for", "i", "in", "range", "(", "ngram_repeat", "+", "4", ")", ":", "\n", "# non-interesting beams are going to get dummy values", "\n", "            ", "word_probs", "=", "torch", ".", "full", "(", "(", "beam_sz", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "if", "i", "==", "0", ":", "\n", "# on initial round, only predicted scores for beam 0", "\n", "# matter. Make two predictions. Top one will be repeated", "\n", "# in beam zero, second one will live on in beam 1.", "\n", "                ", "word_probs", "[", "0", ",", "repeat_idx", "]", "=", "-", "0.1", "\n", "word_probs", "[", "0", ",", "repeat_idx", "+", "i", "+", "1", "]", "=", "-", "2.3", "\n", "", "else", ":", "\n", "# predict the same thing in beam 0", "\n", "                ", "word_probs", "[", "0", ",", "repeat_idx", "]", "=", "0", "\n", "# continue pushing around what beam 1 predicts", "\n", "word_probs", "[", "1", ",", "repeat_idx", "+", "i", "+", "1", "]", "=", "0", "\n", "", "attns", "=", "torch", ".", "randn", "(", "beam_sz", ")", "\n", "beam", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "if", "i", "<=", "ngram_repeat", ":", "\n", "                ", "self", ".", "assertFalse", "(", "beam", ".", "scores", "[", "0", "]", ".", "eq", "(", "self", ".", "BLOCKED_SCORE", ")", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "scores", "[", "1", "]", ".", "eq", "(", "self", ".", "BLOCKED_SCORE", ")", ")", "\n", "", "else", ":", "\n", "# now beam 0 dies (along with the others), beam 1 -> beam 0", "\n", "                ", "self", ".", "assertFalse", "(", "beam", ".", "scores", "[", "0", "]", ".", "eq", "(", "self", ".", "BLOCKED_SCORE", ")", ")", "\n", "self", ".", "assertTrue", "(", "\n", "beam", ".", "scores", "[", "1", ":", "]", ".", "equal", "(", "torch", ".", "tensor", "(", "\n", "[", "self", ".", "BLOCKED_SCORE", "]", "*", "(", "beam_sz", "-", "1", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeam.test_repeating_excluded_index_does_not_die": [[80, 124], ["onmt.translate.beam.Beam", "range", "torch.full", "torch.randn", "onmt.translate.beam.Beam.advance", "set", "test_beam.GlobalScorerStub", "test_beam.TestBeam.assertFalse", "test_beam.TestBeam.assertFalse", "test_beam.TestBeam.assertFalse", "test_beam.TestBeam.assertFalse", "test_beam.TestBeam.assertTrue", "test_beam.TestBeam.assertFalse", "test_beam.TestBeam.assertTrue", "test_beam.TestBeam.assertTrue", "float", "onmt.translate.beam.Beam.scores[].eq", "onmt.translate.beam.Beam.scores[].eq", "onmt.translate.beam.Beam.scores[].eq", "onmt.translate.beam.Beam.scores[].eq", "onmt.translate.beam.Beam.scores[].eq", "onmt.translate.beam.Beam.scores[].eq", "onmt.translate.beam.Beam.scores[].eq", "onmt.translate.beam.Beam.scores[].equal", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance"], ["", "", "", "def", "test_repeating_excluded_index_does_not_die", "(", "self", ")", ":", "\n", "# beam 0 and beam >= 2 will repeat (beam 2 repeats excluded idx)", "\n", "        ", "beam_sz", "=", "5", "\n", "n_words", "=", "100", "\n", "repeat_idx", "=", "47", "# will be repeated and should be blocked", "\n", "repeat_idx_ignored", "=", "7", "# will be repeated and should not be blocked", "\n", "ngram_repeat", "=", "3", "\n", "beam", "=", "Beam", "(", "beam_sz", ",", "0", ",", "1", ",", "2", ",", "n_best", "=", "2", ",", "\n", "exclusion_tokens", "=", "set", "(", "[", "repeat_idx_ignored", "]", ")", ",", "\n", "global_scorer", "=", "GlobalScorerStub", "(", ")", ",", "\n", "block_ngram_repeat", "=", "ngram_repeat", ")", "\n", "for", "i", "in", "range", "(", "ngram_repeat", "+", "4", ")", ":", "\n", "# non-interesting beams are going to get dummy values", "\n", "            ", "word_probs", "=", "torch", ".", "full", "(", "(", "beam_sz", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "if", "i", "==", "0", ":", "\n", "                ", "word_probs", "[", "0", ",", "repeat_idx", "]", "=", "-", "0.1", "\n", "word_probs", "[", "0", ",", "repeat_idx", "+", "i", "+", "1", "]", "=", "-", "2.3", "\n", "word_probs", "[", "0", ",", "repeat_idx_ignored", "]", "=", "-", "5.0", "\n", "", "else", ":", "\n", "# predict the same thing in beam 0", "\n", "                ", "word_probs", "[", "0", ",", "repeat_idx", "]", "=", "0", "\n", "# continue pushing around what beam 1 predicts", "\n", "word_probs", "[", "1", ",", "repeat_idx", "+", "i", "+", "1", "]", "=", "0", "\n", "# predict the allowed-repeat again in beam 2", "\n", "word_probs", "[", "2", ",", "repeat_idx_ignored", "]", "=", "0", "\n", "", "attns", "=", "torch", ".", "randn", "(", "beam_sz", ")", "\n", "beam", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "if", "i", "<=", "ngram_repeat", ":", "\n", "                ", "self", ".", "assertFalse", "(", "beam", ".", "scores", "[", "0", "]", ".", "eq", "(", "self", ".", "BLOCKED_SCORE", ")", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "scores", "[", "1", "]", ".", "eq", "(", "self", ".", "BLOCKED_SCORE", ")", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "scores", "[", "2", "]", ".", "eq", "(", "self", ".", "BLOCKED_SCORE", ")", ")", "\n", "", "else", ":", "\n", "# now beam 0 dies, beam 1 -> beam 0, beam 2 -> beam 1", "\n", "# and the rest die", "\n", "                ", "self", ".", "assertFalse", "(", "beam", ".", "scores", "[", "0", "]", ".", "eq", "(", "self", ".", "BLOCKED_SCORE", ")", ")", "\n", "# since all preds after i=0 are 0, we can check", "\n", "# that the beam is the correct idx by checking that", "\n", "# the curr score is the initial score", "\n", "self", ".", "assertTrue", "(", "beam", ".", "scores", "[", "0", "]", ".", "eq", "(", "-", "2.3", ")", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "scores", "[", "1", "]", ".", "eq", "(", "self", ".", "BLOCKED_SCORE", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "scores", "[", "1", "]", ".", "eq", "(", "-", "5.0", ")", ")", "\n", "self", ".", "assertTrue", "(", "\n", "beam", ".", "scores", "[", "2", ":", "]", ".", "equal", "(", "torch", ".", "tensor", "(", "\n", "[", "self", ".", "BLOCKED_SCORE", "]", "*", "(", "beam_sz", "-", "2", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeam.test_doesnt_predict_eos_if_shorter_than_min_len": [[125, 176], ["torch.log_softmax", "onmt.translate.beam.Beam", "range", "torch.tensor", "torch.full", "torch.randn", "onmt.translate.beam.Beam.advance", "set", "test_beam.GlobalScorerStub", "zip", "enumerate", "test_beam.TestBeam.assertTrue", "float", "zip", "min", "onmt.translate.beam.Beam.scores.allclose", "test_beam.TestBeam.assertEqual", "test_beam.TestBeam.assertEqual"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance"], ["", "", "", "def", "test_doesnt_predict_eos_if_shorter_than_min_len", "(", "self", ")", ":", "\n", "# beam 0 will always predict EOS. The other beams will predict", "\n", "# non-eos scores.", "\n", "# this is also a test that when block_ngram_repeat=0,", "\n", "# repeating is acceptable", "\n", "        ", "beam_sz", "=", "5", "\n", "n_words", "=", "100", "\n", "_non_eos_idxs", "=", "[", "47", ",", "51", ",", "13", ",", "88", ",", "99", "]", "\n", "valid_score_dist", "=", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "\n", "[", "6.", ",", "5.", ",", "4.", ",", "3.", ",", "2.", ",", "1.", "]", ")", ",", "dim", "=", "0", ")", "\n", "min_length", "=", "5", "\n", "eos_idx", "=", "2", "\n", "beam", "=", "Beam", "(", "beam_sz", ",", "0", ",", "1", ",", "eos_idx", ",", "n_best", "=", "2", ",", "\n", "exclusion_tokens", "=", "set", "(", ")", ",", "\n", "min_length", "=", "min_length", ",", "\n", "global_scorer", "=", "GlobalScorerStub", "(", ")", ",", "\n", "block_ngram_repeat", "=", "0", ")", "\n", "for", "i", "in", "range", "(", "min_length", "+", "4", ")", ":", "\n", "# non-interesting beams are going to get dummy values", "\n", "            ", "word_probs", "=", "torch", ".", "full", "(", "(", "beam_sz", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "if", "i", "==", "0", ":", "\n", "# \"best\" prediction is eos - that should be blocked", "\n", "                ", "word_probs", "[", "0", ",", "eos_idx", "]", "=", "valid_score_dist", "[", "0", "]", "\n", "# include at least beam_sz predictions OTHER than EOS", "\n", "# that are greater than -1e20", "\n", "for", "j", ",", "score", "in", "zip", "(", "_non_eos_idxs", ",", "valid_score_dist", "[", "1", ":", "]", ")", ":", "\n", "                    ", "word_probs", "[", "0", ",", "j", "]", "=", "score", "\n", "", "", "else", ":", "\n", "# predict eos in beam 0", "\n", "                ", "word_probs", "[", "0", ",", "eos_idx", "]", "=", "valid_score_dist", "[", "0", "]", "\n", "# provide beam_sz other good predictions", "\n", "for", "k", ",", "(", "j", ",", "score", ")", "in", "enumerate", "(", "\n", "zip", "(", "_non_eos_idxs", ",", "valid_score_dist", "[", "1", ":", "]", ")", ")", ":", "\n", "                    ", "beam_idx", "=", "min", "(", "beam_sz", "-", "1", ",", "k", ")", "\n", "word_probs", "[", "beam_idx", ",", "j", "]", "=", "score", "\n", "\n", "", "", "attns", "=", "torch", ".", "randn", "(", "beam_sz", ")", "\n", "beam", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "if", "i", "<", "min_length", ":", "\n", "                ", "expected_score_dist", "=", "(", "i", "+", "1", ")", "*", "valid_score_dist", "[", "1", ":", "]", "\n", "self", ".", "assertTrue", "(", "beam", ".", "scores", ".", "allclose", "(", "expected_score_dist", ")", ")", "\n", "", "elif", "i", "==", "min_length", ":", "\n", "# now the top beam has ended and no others have", "\n", "# first beam finished had length beam.min_length", "\n", "                ", "self", ".", "assertEqual", "(", "beam", ".", "finished", "[", "0", "]", "[", "1", "]", ",", "beam", ".", "min_length", "+", "1", ")", "\n", "# first beam finished was 0", "\n", "self", ".", "assertEqual", "(", "beam", ".", "finished", "[", "0", "]", "[", "2", "]", ",", "0", ")", "\n", "", "else", ":", "# i > min_length", "\n", "# not of interest, but want to make sure it keeps running", "\n", "# since only beam 0 terminates and n_best = 2", "\n", "                ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeam.test_beam_is_done_when_n_best_beams_eos_using_min_length": [[177, 233], ["torch.log_softmax", "onmt.translate.beam.Beam", "range", "torch.tensor", "torch.full", "torch.randn", "onmt.translate.beam.Beam.advance", "set", "test_beam.GlobalScorerStub", "zip", "test_beam.TestBeam.assertFalse", "float", "enumerate", "enumerate", "test_beam.TestBeam.assertEqual", "test_beam.TestBeam.assertEqual", "test_beam.TestBeam.assertFalse", "test_beam.TestBeam.assertEqual", "test_beam.TestBeam.assertEqual", "test_beam.TestBeam.assertTrue", "zip", "min", "zip", "min"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance"], ["", "", "", "def", "test_beam_is_done_when_n_best_beams_eos_using_min_length", "(", "self", ")", ":", "\n", "# this is also a test that when block_ngram_repeat=0,", "\n", "# repeating is acceptable", "\n", "        ", "beam_sz", "=", "5", "\n", "n_words", "=", "100", "\n", "_non_eos_idxs", "=", "[", "47", ",", "51", ",", "13", ",", "88", ",", "99", "]", "\n", "valid_score_dist", "=", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "\n", "[", "6.", ",", "5.", ",", "4.", ",", "3.", ",", "2.", ",", "1.", "]", ")", ",", "dim", "=", "0", ")", "\n", "min_length", "=", "5", "\n", "eos_idx", "=", "2", "\n", "beam", "=", "Beam", "(", "beam_sz", ",", "0", ",", "1", ",", "eos_idx", ",", "n_best", "=", "2", ",", "\n", "exclusion_tokens", "=", "set", "(", ")", ",", "\n", "min_length", "=", "min_length", ",", "\n", "global_scorer", "=", "GlobalScorerStub", "(", ")", ",", "\n", "block_ngram_repeat", "=", "0", ")", "\n", "for", "i", "in", "range", "(", "min_length", "+", "4", ")", ":", "\n", "# non-interesting beams are going to get dummy values", "\n", "            ", "word_probs", "=", "torch", ".", "full", "(", "(", "beam_sz", ",", "n_words", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "if", "i", "==", "0", ":", "\n", "# \"best\" prediction is eos - that should be blocked", "\n", "                ", "word_probs", "[", "0", ",", "eos_idx", "]", "=", "valid_score_dist", "[", "0", "]", "\n", "# include at least beam_sz predictions OTHER than EOS", "\n", "# that are greater than -1e20", "\n", "for", "j", ",", "score", "in", "zip", "(", "_non_eos_idxs", ",", "valid_score_dist", "[", "1", ":", "]", ")", ":", "\n", "                    ", "word_probs", "[", "0", ",", "j", "]", "=", "score", "\n", "", "", "elif", "i", "<=", "min_length", ":", "\n", "# predict eos in beam 1", "\n", "                ", "word_probs", "[", "1", ",", "eos_idx", "]", "=", "valid_score_dist", "[", "0", "]", "\n", "# provide beam_sz other good predictions in other beams", "\n", "for", "k", ",", "(", "j", ",", "score", ")", "in", "enumerate", "(", "\n", "zip", "(", "_non_eos_idxs", ",", "valid_score_dist", "[", "1", ":", "]", ")", ")", ":", "\n", "                    ", "beam_idx", "=", "min", "(", "beam_sz", "-", "1", ",", "k", ")", "\n", "word_probs", "[", "beam_idx", ",", "j", "]", "=", "score", "\n", "", "", "else", ":", "\n", "                ", "word_probs", "[", "0", ",", "eos_idx", "]", "=", "valid_score_dist", "[", "0", "]", "\n", "word_probs", "[", "1", ",", "eos_idx", "]", "=", "valid_score_dist", "[", "0", "]", "\n", "# provide beam_sz other good predictions in other beams", "\n", "for", "k", ",", "(", "j", ",", "score", ")", "in", "enumerate", "(", "\n", "zip", "(", "_non_eos_idxs", ",", "valid_score_dist", "[", "1", ":", "]", ")", ")", ":", "\n", "                    ", "beam_idx", "=", "min", "(", "beam_sz", "-", "1", ",", "k", ")", "\n", "word_probs", "[", "beam_idx", ",", "j", "]", "=", "score", "\n", "\n", "", "", "attns", "=", "torch", ".", "randn", "(", "beam_sz", ")", "\n", "beam", ".", "advance", "(", "word_probs", ",", "attns", ")", "\n", "if", "i", "<", "min_length", ":", "\n", "                ", "self", ".", "assertFalse", "(", "beam", ".", "done", ")", "\n", "", "elif", "i", "==", "min_length", ":", "\n", "# beam 1 dies on min_length", "\n", "                ", "self", ".", "assertEqual", "(", "beam", ".", "finished", "[", "0", "]", "[", "1", "]", ",", "beam", ".", "min_length", "+", "1", ")", "\n", "self", ".", "assertEqual", "(", "beam", ".", "finished", "[", "0", "]", "[", "2", "]", ",", "1", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "done", ")", "\n", "", "else", ":", "# i > min_length", "\n", "# beam 0 dies on the step after beam 1 dies", "\n", "                ", "self", ".", "assertEqual", "(", "beam", ".", "finished", "[", "1", "]", "[", "1", "]", ",", "beam", ".", "min_length", "+", "2", ")", "\n", "self", ".", "assertEqual", "(", "beam", ".", "finished", "[", "1", "]", "[", "2", "]", ",", "0", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "done", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.init_step": [[243, 254], ["torch.log_softmax", "torch.log_softmax.topk", "beam.advance", "test_beam.TestBeamAgainstReferenceCase.assertTrue", "test_beam.TestBeamAgainstReferenceCase.assertTrue", "test_beam.TestBeamAgainstReferenceCase.assertFalse", "test_beam.TestBeamAgainstReferenceCase.assertFalse", "torch.tensor", "torch.randn", "beam.scores.allclose", "beam.next_ys[].equal"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance"], ["def", "init_step", "(", "self", ",", "beam", ")", ":", "\n", "# init_preds: [4, 3, 5, 6, 7] - no EOS's", "\n", "        ", "init_scores", "=", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "\n", "[", "[", "0", ",", "0", ",", "0", ",", "4", ",", "5", ",", "3", ",", "2", ",", "1", "]", "]", ",", "dtype", "=", "torch", ".", "float", ")", ",", "dim", "=", "1", ")", "\n", "expected_beam_scores", ",", "expected_preds_0", "=", "init_scores", ".", "topk", "(", "self", ".", "BEAM_SZ", ")", "\n", "beam", ".", "advance", "(", "init_scores", ",", "torch", ".", "randn", "(", "self", ".", "BEAM_SZ", ",", "self", ".", "INP_SEQ_LEN", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "scores", ".", "allclose", "(", "expected_beam_scores", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "next_ys", "[", "-", "1", "]", ".", "equal", "(", "expected_preds_0", "[", "0", "]", ")", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "eos_top", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "done", ")", "\n", "return", "expected_beam_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.first_step": [[255, 286], ["torch.log_softmax", "beam.advance", "new_scores.view().topk", "test_beam.TestBeamAgainstReferenceCase.assertTrue", "test_beam.TestBeamAgainstReferenceCase.assertTrue", "test_beam.TestBeamAgainstReferenceCase.assertTrue", "test_beam.TestBeamAgainstReferenceCase.assertEqual", "test_beam.TestBeamAgainstReferenceCase.assertEqual", "test_beam.TestBeamAgainstReferenceCase.assertEqual", "test_beam.TestBeamAgainstReferenceCase.assertEqual", "test_beam.TestBeamAgainstReferenceCase.assertFalse", "test_beam.TestBeamAgainstReferenceCase.assertFalse", "len", "torch.tensor", "torch.randn", "expected_beam_scores.t", "beam.scores.allclose", "beam.next_ys[].equal", "beam.prev_ks[].equal", "len", "new_scores.view"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance"], ["", "def", "first_step", "(", "self", ",", "beam", ",", "expected_beam_scores", ",", "expected_len_pen", ")", ":", "\n", "# no EOS's yet", "\n", "        ", "assert", "len", "(", "beam", ".", "finished", ")", "==", "0", "\n", "scores_1", "=", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "\n", "[", "[", "0", ",", "0", ",", "0", ",", ".3", ",", "0", ",", ".51", ",", ".2", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "1.5", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", ".49", ",", ".48", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", ".2", ",", ".2", ",", ".2", ",", ".2", ",", ".2", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", ".2", ",", ".2", ",", ".2", ",", ".2", ",", ".2", "]", "]", "\n", ")", ",", "dim", "=", "1", ")", "\n", "\n", "beam", ".", "advance", "(", "scores_1", ",", "torch", ".", "randn", "(", "self", ".", "BEAM_SZ", ",", "self", ".", "INP_SEQ_LEN", ")", ")", "\n", "\n", "new_scores", "=", "scores_1", "+", "expected_beam_scores", ".", "t", "(", ")", "\n", "expected_beam_scores", ",", "unreduced_preds", "=", "new_scores", ".", "view", "(", "-", "1", ")", ".", "topk", "(", "\n", "self", ".", "BEAM_SZ", ",", "0", ",", "True", ",", "True", ")", "\n", "expected_bptr_1", "=", "unreduced_preds", "/", "self", ".", "N_WORDS", "\n", "# [5, 3, 2, 6, 0], so beam 2 predicts EOS!", "\n", "expected_preds_1", "=", "unreduced_preds", "-", "expected_bptr_1", "*", "self", ".", "N_WORDS", "\n", "\n", "self", ".", "assertTrue", "(", "beam", ".", "scores", ".", "allclose", "(", "expected_beam_scores", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "next_ys", "[", "-", "1", "]", ".", "equal", "(", "expected_preds_1", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "prev_ks", "[", "-", "1", "]", ".", "equal", "(", "expected_bptr_1", ")", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "beam", ".", "finished", ")", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "beam", ".", "finished", "[", "0", "]", "[", "2", "]", ",", "2", ")", "# beam 2 finished", "\n", "self", ".", "assertEqual", "(", "beam", ".", "finished", "[", "0", "]", "[", "1", "]", ",", "2", ")", "# finished on second step", "\n", "self", ".", "assertEqual", "(", "beam", ".", "finished", "[", "0", "]", "[", "0", "]", ",", "# finished with correct score", "\n", "expected_beam_scores", "[", "2", "]", "/", "expected_len_pen", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "eos_top", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "done", ")", "\n", "return", "expected_beam_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.second_step": [[287, 321], ["torch.log_softmax", "beam.advance", "new_scores.view().topk", "test_beam.TestBeamAgainstReferenceCase.assertTrue", "test_beam.TestBeamAgainstReferenceCase.assertTrue", "test_beam.TestBeamAgainstReferenceCase.assertTrue", "test_beam.TestBeamAgainstReferenceCase.assertEqual", "test_beam.TestBeamAgainstReferenceCase.assertEqual", "test_beam.TestBeamAgainstReferenceCase.assertEqual", "test_beam.TestBeamAgainstReferenceCase.assertEqual", "test_beam.TestBeamAgainstReferenceCase.assertEqual", "test_beam.TestBeamAgainstReferenceCase.assertTrue", "test_beam.TestBeamAgainstReferenceCase.assertFalse", "torch.tensor", "torch.randn", "expected_beam_scores.unsqueeze", "beam.scores.allclose", "beam.next_ys[].equal", "beam.prev_ks[].equal", "len", "new_scores.view"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance"], ["", "def", "second_step", "(", "self", ",", "beam", ",", "expected_beam_scores", ",", "expected_len_pen", ")", ":", "\n", "# assumes beam 2 finished on last step", "\n", "        ", "scores_2", "=", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "\n", "[", "[", "0", ",", "0", ",", "0", ",", ".3", ",", "0", ",", ".51", ",", ".2", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "5000", ",", ".48", ",", "0", ",", "0", "]", ",", "# beam 2 shouldn't continue", "\n", "[", "0", ",", "0", ",", "50", ",", ".2", ",", ".2", ",", ".2", ",", ".2", ",", ".2", "]", ",", "# beam 3 -> beam 0 should die", "\n", "[", "0", ",", "0", ",", "0", ",", ".2", ",", ".2", ",", ".2", ",", ".2", ",", ".2", "]", "]", "\n", ")", ",", "dim", "=", "1", ")", "\n", "\n", "beam", ".", "advance", "(", "scores_2", ",", "torch", ".", "randn", "(", "self", ".", "BEAM_SZ", ",", "self", ".", "INP_SEQ_LEN", ")", ")", "\n", "\n", "new_scores", "=", "scores_2", "+", "expected_beam_scores", ".", "unsqueeze", "(", "1", ")", "\n", "new_scores", "[", "2", "]", "=", "self", ".", "DEAD_SCORE", "# ended beam 2 shouldn't continue", "\n", "expected_beam_scores", ",", "unreduced_preds", "=", "new_scores", ".", "view", "(", "-", "1", ")", ".", "topk", "(", "\n", "self", ".", "BEAM_SZ", ",", "0", ",", "True", ",", "True", ")", "\n", "expected_bptr_2", "=", "unreduced_preds", "/", "self", ".", "N_WORDS", "\n", "# [2, 5, 3, 6, 0], so beam 0 predicts EOS!", "\n", "expected_preds_2", "=", "unreduced_preds", "-", "expected_bptr_2", "*", "self", ".", "N_WORDS", "\n", "# [-2.4879, -3.8910, -4.1010, -4.2010, -4.4010]", "\n", "self", ".", "assertTrue", "(", "beam", ".", "scores", ".", "allclose", "(", "expected_beam_scores", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "next_ys", "[", "-", "1", "]", ".", "equal", "(", "expected_preds_2", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "prev_ks", "[", "-", "1", "]", ".", "equal", "(", "expected_bptr_2", ")", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "beam", ".", "finished", ")", ",", "2", ")", "\n", "# new beam 0 finished", "\n", "self", ".", "assertEqual", "(", "beam", ".", "finished", "[", "1", "]", "[", "2", "]", ",", "0", ")", "\n", "# new beam 0 is old beam 3", "\n", "self", ".", "assertEqual", "(", "expected_bptr_2", "[", "0", "]", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "beam", ".", "finished", "[", "1", "]", "[", "1", "]", ",", "3", ")", "# finished on third step", "\n", "self", ".", "assertEqual", "(", "beam", ".", "finished", "[", "1", "]", "[", "0", "]", ",", "# finished with correct score", "\n", "expected_beam_scores", "[", "0", "]", "/", "expected_len_pen", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "eos_top", ")", "\n", "self", ".", "assertFalse", "(", "beam", ".", "done", ")", "\n", "return", "expected_beam_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.third_step": [[322, 355], ["torch.log_softmax", "beam.advance", "new_scores.view().topk", "test_beam.TestBeamAgainstReferenceCase.assertTrue", "test_beam.TestBeamAgainstReferenceCase.assertTrue", "test_beam.TestBeamAgainstReferenceCase.assertTrue", "test_beam.TestBeamAgainstReferenceCase.assertEqual", "test_beam.TestBeamAgainstReferenceCase.assertEqual", "test_beam.TestBeamAgainstReferenceCase.assertEqual", "test_beam.TestBeamAgainstReferenceCase.assertEqual", "test_beam.TestBeamAgainstReferenceCase.assertEqual", "test_beam.TestBeamAgainstReferenceCase.assertTrue", "test_beam.TestBeamAgainstReferenceCase.assertTrue", "torch.tensor", "torch.randn", "expected_beam_scores.unsqueeze", "beam.scores.allclose", "beam.next_ys[].equal", "beam.prev_ks[].equal", "len", "new_scores.view"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.translate.decode_strategy.DecodeStrategy.advance"], ["", "def", "third_step", "(", "self", ",", "beam", ",", "expected_beam_scores", ",", "expected_len_pen", ")", ":", "\n", "# assumes beam 0 finished on last step", "\n", "        ", "scores_3", "=", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "\n", "[", "[", "0", ",", "0", ",", "5000", ",", "0", ",", "5000", ",", ".51", ",", ".2", ",", "0", "]", ",", "# beam 0 shouldn't cont", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "5000", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", ".2", ",", ".2", ",", ".2", ",", ".2", ",", ".2", "]", ",", "\n", "[", "0", ",", "0", ",", "50", ",", "0", ",", ".2", ",", ".2", ",", ".2", ",", ".2", "]", "]", "# beam 4 -> beam 1 should die", "\n", ")", ",", "dim", "=", "1", ")", "\n", "\n", "beam", ".", "advance", "(", "scores_3", ",", "torch", ".", "randn", "(", "self", ".", "BEAM_SZ", ",", "self", ".", "INP_SEQ_LEN", ")", ")", "\n", "\n", "new_scores", "=", "scores_3", "+", "expected_beam_scores", ".", "unsqueeze", "(", "1", ")", "\n", "new_scores", "[", "0", "]", "=", "self", ".", "DEAD_SCORE", "# ended beam 2 shouldn't continue", "\n", "expected_beam_scores", ",", "unreduced_preds", "=", "new_scores", ".", "view", "(", "-", "1", ")", ".", "topk", "(", "\n", "self", ".", "BEAM_SZ", ",", "0", ",", "True", ",", "True", ")", "\n", "expected_bptr_3", "=", "unreduced_preds", "/", "self", ".", "N_WORDS", "\n", "# [5, 2, 6, 1, 0], so beam 1 predicts EOS!", "\n", "expected_preds_3", "=", "unreduced_preds", "-", "expected_bptr_3", "*", "self", ".", "N_WORDS", "\n", "self", ".", "assertTrue", "(", "beam", ".", "scores", ".", "allclose", "(", "expected_beam_scores", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "next_ys", "[", "-", "1", "]", ".", "equal", "(", "expected_preds_3", ")", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "prev_ks", "[", "-", "1", "]", ".", "equal", "(", "expected_bptr_3", ")", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "beam", ".", "finished", ")", ",", "3", ")", "\n", "# new beam 1 finished", "\n", "self", ".", "assertEqual", "(", "beam", ".", "finished", "[", "2", "]", "[", "2", "]", ",", "1", ")", "\n", "# new beam 1 is old beam 4", "\n", "self", ".", "assertEqual", "(", "expected_bptr_3", "[", "1", "]", ",", "4", ")", "\n", "self", ".", "assertEqual", "(", "beam", ".", "finished", "[", "2", "]", "[", "1", "]", ",", "4", ")", "# finished on fourth step", "\n", "self", ".", "assertEqual", "(", "beam", ".", "finished", "[", "2", "]", "[", "0", "]", ",", "# finished with correct score", "\n", "expected_beam_scores", "[", "1", "]", "/", "expected_len_pen", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "eos_top", ")", "\n", "self", ".", "assertTrue", "(", "beam", ".", "done", ")", "\n", "return", "expected_beam_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.test_beam_advance_against_known_reference": [[356, 367], ["onmt.translate.beam.Beam", "test_beam.TestBeamAgainstReferenceCase.init_step", "test_beam.TestBeamAgainstReferenceCase.first_step", "test_beam.TestBeamAgainstReferenceCase.second_step", "test_beam.TestBeamAgainstReferenceCase.third_step", "set", "test_beam.GlobalScorerStub"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.init_step", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.first_step", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.second_step", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.third_step"], ["", "def", "test_beam_advance_against_known_reference", "(", "self", ")", ":", "\n", "        ", "beam", "=", "Beam", "(", "self", ".", "BEAM_SZ", ",", "0", ",", "1", ",", "self", ".", "EOS_IDX", ",", "n_best", "=", "self", ".", "N_BEST", ",", "\n", "exclusion_tokens", "=", "set", "(", ")", ",", "\n", "min_length", "=", "0", ",", "\n", "global_scorer", "=", "GlobalScorerStub", "(", ")", ",", "\n", "block_ngram_repeat", "=", "0", ")", "\n", "\n", "expected_beam_scores", "=", "self", ".", "init_step", "(", "beam", ")", "\n", "expected_beam_scores", "=", "self", ".", "first_step", "(", "beam", ",", "expected_beam_scores", ",", "1", ")", "\n", "expected_beam_scores", "=", "self", ".", "second_step", "(", "beam", ",", "expected_beam_scores", ",", "1", ")", "\n", "self", ".", "third_step", "(", "beam", ",", "expected_beam_scores", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamWithLengthPenalty.test_beam_advance_against_known_reference": [[373, 384], ["onmt.translate.beam.GNMTGlobalScorer", "onmt.translate.beam.Beam", "test_beam.TestBeamWithLengthPenalty.init_step", "test_beam.TestBeamWithLengthPenalty.first_step", "test_beam.TestBeamWithLengthPenalty.second_step", "test_beam.TestBeamWithLengthPenalty.third_step", "set"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.init_step", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.first_step", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.second_step", "home.repos.pwc.inspect_result.bigheiniu_FactGen.tests.test_beam.TestBeamAgainstReferenceCase.third_step"], ["    ", "def", "test_beam_advance_against_known_reference", "(", "self", ")", ":", "\n", "        ", "scorer", "=", "GNMTGlobalScorer", "(", "0.7", ",", "0.", ",", "\"avg\"", ",", "\"none\"", ")", "\n", "beam", "=", "Beam", "(", "self", ".", "BEAM_SZ", ",", "0", ",", "1", ",", "self", ".", "EOS_IDX", ",", "n_best", "=", "self", ".", "N_BEST", ",", "\n", "exclusion_tokens", "=", "set", "(", ")", ",", "\n", "min_length", "=", "0", ",", "\n", "global_scorer", "=", "scorer", ",", "\n", "block_ngram_repeat", "=", "0", ")", "\n", "expected_beam_scores", "=", "self", ".", "init_step", "(", "beam", ")", "\n", "expected_beam_scores", "=", "self", ".", "first_step", "(", "beam", ",", "expected_beam_scores", ",", "3", ")", "\n", "expected_beam_scores", "=", "self", ".", "second_step", "(", "beam", ",", "expected_beam_scores", ",", "4", ")", "\n", "self", ".", "third_step", "(", "beam", ",", "expected_beam_scores", ",", "5", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.cnn_encoder.CNNEncoder.__init__": [[17, 26], ["onmt.encoders.encoder.EncoderBase.__init__", "torch.Linear", "onmt.utils.cnn_factory.StackedCNN"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "hidden_size", ",", "\n", "cnn_kernel_width", ",", "dropout", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", "CNNEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "input_size", "=", "embeddings", ".", "embedding_size", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ")", "\n", "self", ".", "cnn", "=", "StackedCNN", "(", "num_layers", ",", "hidden_size", ",", "\n", "cnn_kernel_width", ",", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.cnn_encoder.CNNEncoder.from_opt": [[27, 36], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ",", "embeddings", ")", ":", "\n", "        ", "\"\"\"Alternate constructor.\"\"\"", "\n", "return", "cls", "(", "\n", "opt", ".", "enc_layers", ",", "\n", "opt", ".", "enc_rnn_size", ",", "\n", "opt", ".", "cnn_kernel_width", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.cnn_encoder.CNNEncoder.forward": [[37, 53], ["cnn_encoder.CNNEncoder._check_args", "cnn_encoder.CNNEncoder.embeddings", "emb.transpose().contiguous.transpose().contiguous.transpose().contiguous", "emb.transpose().contiguous.transpose().contiguous.view", "cnn_encoder.CNNEncoder.linear", "onmt.utils.cnn_factory.shape_transform.view", "onmt.utils.cnn_factory.shape_transform", "cnn_encoder.CNNEncoder.cnn", "emb.transpose().contiguous.transpose().contiguous.size", "emb.transpose().contiguous.transpose().contiguous.size", "onmt.utils.cnn_factory.shape_transform.squeeze().transpose().contiguous", "cnn_encoder.CNNEncoder.squeeze().transpose().contiguous", "emb.transpose().contiguous.transpose().contiguous.transpose", "emb.transpose().contiguous.transpose().contiguous.size", "emb.transpose().contiguous.transpose().contiguous.size", "onmt.utils.cnn_factory.shape_transform.squeeze().transpose", "cnn_encoder.CNNEncoder.squeeze().transpose", "onmt.utils.cnn_factory.shape_transform.squeeze", "cnn_encoder.CNNEncoder.squeeze"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.encoder.EncoderBase._check_args", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.cnn_factory.shape_transform", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.bigheiniu_FactGen.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "forward", "(", "self", ",", "input", ",", "lengths", "=", "None", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "\"\"\"See :class:`onmt.modules.EncoderBase.forward()`\"\"\"", "\n", "self", ".", "_check_args", "(", "input", ",", "lengths", ",", "hidden", ")", "\n", "\n", "emb", "=", "self", ".", "embeddings", "(", "input", ")", "\n", "# s_len, batch, emb_dim = emb.size()", "\n", "\n", "emb", "=", "emb", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "emb_reshape", "=", "emb", ".", "view", "(", "emb", ".", "size", "(", "0", ")", "*", "emb", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "emb_remap", "=", "self", ".", "linear", "(", "emb_reshape", ")", "\n", "emb_remap", "=", "emb_remap", ".", "view", "(", "emb", ".", "size", "(", "0", ")", ",", "emb", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "emb_remap", "=", "shape_transform", "(", "emb_remap", ")", "\n", "out", "=", "self", ".", "cnn", "(", "emb_remap", ")", "\n", "\n", "return", "emb_remap", ".", "squeeze", "(", "3", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "out", ".", "squeeze", "(", "3", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "lengths", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.encoder.EncoderBase.from_opt": [[33, 36], ["None"], "methods", ["None"], ["@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ",", "embeddings", "=", "None", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.encoder.EncoderBase._check_args": [[37, 42], ["src.size", "lengths.size", "onmt.utils.misc.aeq"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.misc.aeq"], ["", "def", "_check_args", "(", "self", ",", "src", ",", "lengths", "=", "None", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "_", ",", "n_batch", ",", "_", "=", "src", ".", "size", "(", ")", "\n", "if", "lengths", "is", "not", "None", ":", "\n", "            ", "n_batch_", ",", "=", "lengths", ".", "size", "(", ")", "\n", "aeq", "(", "n_batch", ",", "n_batch_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.encoder.EncoderBase.forward": [[43, 59], ["None"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src (LongTensor):\n               padded sequences of sparse indices ``(src_len, batch, nfeat)``\n            lengths (LongTensor): length of each sequence ``(batch,)``\n\n\n        Returns:\n            (FloatTensor, FloatTensor):\n\n            * final encoder state, used to initialize decoder\n            * memory bank for attention, ``(src_len, batch, hidden)``\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.rnn_encoder.RNNEncoder.__init__": [[25, 50], ["onmt.encoders.encoder.EncoderBase.__init__", "onmt.utils.rnn_factory.rnn_factory", "rnn_encoder.RNNEncoder._initialize_bridge"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.rnn_factory.rnn_factory", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.rnn_encoder.RNNEncoder._initialize_bridge"], ["def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional", ",", "num_layers", ",", "\n", "hidden_size", ",", "dropout", "=", "0.0", ",", "embeddings", "=", "None", ",", "\n", "use_bridge", "=", "False", ")", ":", "\n", "        ", "super", "(", "RNNEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "embeddings", "is", "not", "None", "\n", "\n", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "assert", "hidden_size", "%", "num_directions", "==", "0", "\n", "hidden_size", "=", "hidden_size", "//", "num_directions", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "\n", "self", ".", "rnn", ",", "self", ".", "no_pack_padded_seq", "=", "rnn_factory", "(", "rnn_type", ",", "\n", "input_size", "=", "embeddings", ".", "embedding_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "bidirectional", ")", "\n", "\n", "# Initialize the bridge layer", "\n", "self", ".", "use_bridge", "=", "use_bridge", "\n", "if", "self", ".", "use_bridge", ":", "\n", "            ", "self", ".", "_initialize_bridge", "(", "rnn_type", ",", "\n", "hidden_size", ",", "\n", "num_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.rnn_encoder.RNNEncoder.from_opt": [[51, 62], ["cls"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ",", "embeddings", ")", ":", "\n", "        ", "\"\"\"Alternate constructor.\"\"\"", "\n", "return", "cls", "(", "\n", "opt", ".", "rnn_type", ",", "\n", "opt", ".", "brnn", ",", "\n", "opt", ".", "enc_layers", ",", "\n", "opt", ".", "enc_rnn_size", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", ",", "\n", "opt", ".", "bridge", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.rnn_encoder.RNNEncoder.forward": [[63, 84], ["rnn_encoder.RNNEncoder._check_args", "rnn_encoder.RNNEncoder.embeddings", "rnn_encoder.RNNEncoder.rnn", "lengths.view().tolist", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "rnn_encoder.RNNEncoder._bridge", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "lengths.view"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.encoder.EncoderBase._check_args", "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.rnn_encoder.RNNEncoder._bridge"], ["", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"See :func:`EncoderBase.forward()`\"\"\"", "\n", "self", ".", "_check_args", "(", "src", ",", "lengths", ")", "\n", "\n", "emb", "=", "self", ".", "embeddings", "(", "src", ")", "\n", "# s_len, batch, emb_dim = emb.size()", "\n", "\n", "packed_emb", "=", "emb", "\n", "if", "lengths", "is", "not", "None", "and", "not", "self", ".", "no_pack_padded_seq", ":", "\n", "# Lengths data is wrapped inside a Tensor.", "\n", "            ", "lengths_list", "=", "lengths", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "packed_emb", "=", "pack", "(", "emb", ",", "lengths_list", ")", "\n", "\n", "", "memory_bank", ",", "encoder_final", "=", "self", ".", "rnn", "(", "packed_emb", ")", "\n", "\n", "if", "lengths", "is", "not", "None", "and", "not", "self", ".", "no_pack_padded_seq", ":", "\n", "            ", "memory_bank", "=", "unpack", "(", "memory_bank", ")", "[", "0", "]", "\n", "\n", "", "if", "self", ".", "use_bridge", ":", "\n", "            ", "encoder_final", "=", "self", ".", "_bridge", "(", "encoder_final", ")", "\n", "", "return", "encoder_final", ",", "memory_bank", ",", "lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.rnn_encoder.RNNEncoder._initialize_bridge": [[85, 99], ["torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "range"], "methods", ["None"], ["", "def", "_initialize_bridge", "(", "self", ",", "rnn_type", ",", "\n", "hidden_size", ",", "\n", "num_layers", ")", ":", "\n", "\n", "# LSTM has hidden and cell state, other only one", "\n", "        ", "number_of_states", "=", "2", "if", "rnn_type", "==", "\"LSTM\"", "else", "1", "\n", "# Total number of states", "\n", "self", ".", "total_hidden_dim", "=", "hidden_size", "*", "num_layers", "\n", "\n", "# Build a linear layer for each", "\n", "self", ".", "bridge", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "self", ".", "total_hidden_dim", ",", "\n", "self", ".", "total_hidden_dim", ",", "\n", "bias", "=", "True", ")", "\n", "for", "_", "in", "range", "(", "number_of_states", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.rnn_encoder.RNNEncoder._bridge": [[100, 116], ["isinstance", "states.size", "linear", "torch.relu().view", "torch.relu().view", "tuple", "rnn_encoder.RNNEncoder._bridge.bottle_hidden"], "methods", ["None"], ["", "def", "_bridge", "(", "self", ",", "hidden", ")", ":", "\n", "        ", "\"\"\"Forward hidden state through bridge.\"\"\"", "\n", "def", "bottle_hidden", "(", "linear", ",", "states", ")", ":", "\n", "            ", "\"\"\"\n            Transform from 3D to 2D, apply linear and return initial size\n            \"\"\"", "\n", "size", "=", "states", ".", "size", "(", ")", "\n", "result", "=", "linear", "(", "states", ".", "view", "(", "-", "1", ",", "self", ".", "total_hidden_dim", ")", ")", "\n", "return", "F", ".", "relu", "(", "result", ")", ".", "view", "(", "size", ")", "\n", "\n", "", "if", "isinstance", "(", "hidden", ",", "tuple", ")", ":", "# LSTM", "\n", "            ", "outs", "=", "tuple", "(", "[", "bottle_hidden", "(", "layer", ",", "hidden", "[", "ix", "]", ")", "\n", "for", "ix", ",", "layer", "in", "enumerate", "(", "self", ".", "bridge", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "outs", "=", "bottle_hidden", "(", "self", ".", "bridge", "[", "0", "]", ",", "hidden", ")", "\n", "", "return", "outs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.audio_encoder.AudioEncoder.__init__": [[30, 81], ["onmt.encoders.encoder.EncoderBase.__init__", "int", "enc_pooling.split.split.split", "torch.Linear", "torch.BatchNorm1d", "onmt.utils.rnn_factory.rnn_factory", "torch.MaxPool1d", "range", "len", "int", "torch.Dropout", "torch.BatchNorm1d", "onmt.utils.rnn_factory.rnn_factory", "setattr", "setattr", "setattr", "math.floor", "len", "len", "torch.MaxPool1d"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.rnn_factory.rnn_factory", "home.repos.pwc.inspect_result.bigheiniu_FactGen.utils.rnn_factory.rnn_factory"], ["def", "__init__", "(", "self", ",", "rnn_type", ",", "enc_layers", ",", "dec_layers", ",", "brnn", ",", "\n", "enc_rnn_size", ",", "dec_rnn_size", ",", "enc_pooling", ",", "dropout", ",", "\n", "sample_rate", ",", "window_size", ")", ":", "\n", "        ", "super", "(", "AudioEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "enc_layers", "=", "enc_layers", "\n", "self", ".", "rnn_type", "=", "rnn_type", "\n", "self", ".", "dec_layers", "=", "dec_layers", "\n", "num_directions", "=", "2", "if", "brnn", "else", "1", "\n", "self", ".", "num_directions", "=", "num_directions", "\n", "assert", "enc_rnn_size", "%", "num_directions", "==", "0", "\n", "enc_rnn_size_real", "=", "enc_rnn_size", "//", "num_directions", "\n", "assert", "dec_rnn_size", "%", "num_directions", "==", "0", "\n", "self", ".", "dec_rnn_size", "=", "dec_rnn_size", "\n", "dec_rnn_size_real", "=", "dec_rnn_size", "//", "num_directions", "\n", "self", ".", "dec_rnn_size_real", "=", "dec_rnn_size_real", "\n", "self", ".", "dec_rnn_size", "=", "dec_rnn_size", "\n", "input_size", "=", "int", "(", "math", ".", "floor", "(", "(", "sample_rate", "*", "window_size", ")", "/", "2", ")", "+", "1", ")", "\n", "enc_pooling", "=", "enc_pooling", ".", "split", "(", "','", ")", "\n", "assert", "len", "(", "enc_pooling", ")", "==", "enc_layers", "or", "len", "(", "enc_pooling", ")", "==", "1", "\n", "if", "len", "(", "enc_pooling", ")", "==", "1", ":", "\n", "            ", "enc_pooling", "=", "enc_pooling", "*", "enc_layers", "\n", "", "enc_pooling", "=", "[", "int", "(", "p", ")", "for", "p", "in", "enc_pooling", "]", "\n", "self", ".", "enc_pooling", "=", "enc_pooling", "\n", "\n", "if", "dropout", ">", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "None", "\n", "", "self", ".", "W", "=", "nn", ".", "Linear", "(", "enc_rnn_size", ",", "dec_rnn_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "batchnorm_0", "=", "nn", ".", "BatchNorm1d", "(", "enc_rnn_size", ",", "affine", "=", "True", ")", "\n", "self", ".", "rnn_0", ",", "self", ".", "no_pack_padded_seq", "=", "rnn_factory", "(", "rnn_type", ",", "\n", "input_size", "=", "input_size", ",", "\n", "hidden_size", "=", "enc_rnn_size_real", ",", "\n", "num_layers", "=", "1", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "brnn", ")", "\n", "self", ".", "pool_0", "=", "nn", ".", "MaxPool1d", "(", "enc_pooling", "[", "0", "]", ")", "\n", "for", "l", "in", "range", "(", "enc_layers", "-", "1", ")", ":", "\n", "            ", "batchnorm", "=", "nn", ".", "BatchNorm1d", "(", "enc_rnn_size", ",", "affine", "=", "True", ")", "\n", "rnn", ",", "_", "=", "rnn_factory", "(", "rnn_type", ",", "\n", "input_size", "=", "enc_rnn_size", ",", "\n", "hidden_size", "=", "enc_rnn_size_real", ",", "\n", "num_layers", "=", "1", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "brnn", ")", "\n", "setattr", "(", "self", ",", "'rnn_%d'", "%", "(", "l", "+", "1", ")", ",", "rnn", ")", "\n", "setattr", "(", "self", ",", "'pool_%d'", "%", "(", "l", "+", "1", ")", ",", "\n", "nn", ".", "MaxPool1d", "(", "enc_pooling", "[", "l", "+", "1", "]", ")", ")", "\n", "setattr", "(", "self", ",", "'batchnorm_%d'", "%", "(", "l", "+", "1", ")", ",", "batchnorm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.audio_encoder.AudioEncoder.from_opt": [[82, 98], ["cls", "ValueError"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ",", "embeddings", "=", "None", ")", ":", "\n", "        ", "\"\"\"Alternate constructor.\"\"\"", "\n", "if", "embeddings", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot use embeddings with AudioEncoder.\"", ")", "\n", "", "return", "cls", "(", "\n", "opt", ".", "rnn_type", ",", "\n", "opt", ".", "enc_layers", ",", "\n", "opt", ".", "dec_layers", ",", "\n", "opt", ".", "brnn", ",", "\n", "opt", ".", "enc_rnn_size", ",", "\n", "opt", ".", "dec_rnn_size", ",", "\n", "opt", ".", "audio_enc_pooling", ",", "\n", "opt", ".", "dropout", ",", "\n", "opt", ".", "sample_rate", ",", "\n", "opt", ".", "window_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.audio_encoder.AudioEncoder.forward": [[99, 140], ["audio_encoder.AudioEncoder.size", "audio_encoder.AudioEncoder.transpose().transpose().contiguous().view", "lengths.view().tolist.view().tolist.view().tolist", "range", "memory_bank.transpose.transpose.contiguous().view", "audio_encoder.AudioEncoder.W().view", "memory_bank.transpose.transpose.new_full", "getattr", "getattr", "getattr", "torch.nn.utils.rnn.pack_padded_sequence", "getattr.", "memory_bank.transpose.transpose.size", "memory_bank.transpose.transpose.transpose", "getattr.", "memory_bank.transpose.transpose.transpose", "audio_encoder.AudioEncoder.size", "getattr.", "audio_encoder.AudioEncoder.view", "memory_bank.transpose.transpose.size", "orig_lengths.new_tensor", "audio_encoder.AudioEncoder.transpose().transpose().contiguous", "lengths.view().tolist.view().tolist.view", "torch.nn.utils.rnn.pad_packed_sequence", "int", "audio_encoder.AudioEncoder.contiguous().view", "audio_encoder.AudioEncoder.dropout", "memory_bank.transpose.transpose.contiguous", "audio_encoder.AudioEncoder.W", "math.floor", "audio_encoder.AudioEncoder.transpose().transpose", "audio_encoder.AudioEncoder.contiguous", "audio_encoder.AudioEncoder.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"See :func:`onmt.encoders.encoder.EncoderBase.forward()`\"\"\"", "\n", "batch_size", ",", "_", ",", "nfft", ",", "t", "=", "src", ".", "size", "(", ")", "\n", "src", "=", "src", ".", "transpose", "(", "0", ",", "1", ")", ".", "transpose", "(", "0", ",", "3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "t", ",", "batch_size", ",", "nfft", ")", "\n", "orig_lengths", "=", "lengths", "\n", "lengths", "=", "lengths", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "\n", "for", "l", "in", "range", "(", "self", ".", "enc_layers", ")", ":", "\n", "            ", "rnn", "=", "getattr", "(", "self", ",", "'rnn_%d'", "%", "l", ")", "\n", "pool", "=", "getattr", "(", "self", ",", "'pool_%d'", "%", "l", ")", "\n", "batchnorm", "=", "getattr", "(", "self", ",", "'batchnorm_%d'", "%", "l", ")", "\n", "stride", "=", "self", ".", "enc_pooling", "[", "l", "]", "\n", "packed_emb", "=", "pack", "(", "src", ",", "lengths", ")", "\n", "memory_bank", ",", "tmp", "=", "rnn", "(", "packed_emb", ")", "\n", "memory_bank", "=", "unpack", "(", "memory_bank", ")", "[", "0", "]", "\n", "t", ",", "_", ",", "_", "=", "memory_bank", ".", "size", "(", ")", "\n", "memory_bank", "=", "memory_bank", ".", "transpose", "(", "0", ",", "2", ")", "\n", "memory_bank", "=", "pool", "(", "memory_bank", ")", "\n", "lengths", "=", "[", "int", "(", "math", ".", "floor", "(", "(", "length", "-", "stride", ")", "/", "stride", "+", "1", ")", ")", "\n", "for", "length", "in", "lengths", "]", "\n", "memory_bank", "=", "memory_bank", ".", "transpose", "(", "0", ",", "2", ")", "\n", "src", "=", "memory_bank", "\n", "t", ",", "_", ",", "num_feat", "=", "src", ".", "size", "(", ")", "\n", "src", "=", "batchnorm", "(", "src", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "num_feat", ")", ")", "\n", "src", "=", "src", ".", "view", "(", "t", ",", "-", "1", ",", "num_feat", ")", "\n", "if", "self", ".", "dropout", "and", "l", "+", "1", "!=", "self", ".", "enc_layers", ":", "\n", "                ", "src", "=", "self", ".", "dropout", "(", "src", ")", "\n", "\n", "", "", "memory_bank", "=", "memory_bank", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "memory_bank", ".", "size", "(", "2", ")", ")", "\n", "memory_bank", "=", "self", ".", "W", "(", "memory_bank", ")", ".", "view", "(", "-", "1", ",", "batch_size", ",", "\n", "self", ".", "dec_rnn_size", ")", "\n", "\n", "state", "=", "memory_bank", ".", "new_full", "(", "(", "self", ".", "dec_layers", "*", "self", ".", "num_directions", ",", "\n", "batch_size", ",", "self", ".", "dec_rnn_size_real", ")", ",", "0", ")", "\n", "if", "self", ".", "rnn_type", "==", "'LSTM'", ":", "\n", "# The encoder hidden is  (layers*directions) x batch x dim.", "\n", "            ", "encoder_final", "=", "(", "state", ",", "state", ")", "\n", "", "else", ":", "\n", "            ", "encoder_final", "=", "state", "\n", "", "return", "encoder_final", ",", "memory_bank", ",", "orig_lengths", ".", "new_tensor", "(", "lengths", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.mean_encoder.MeanEncoder.__init__": [[13, 17], ["onmt.encoders.encoder.EncoderBase.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", "MeanEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.mean_encoder.MeanEncoder.from_opt": [[18, 24], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ",", "embeddings", ")", ":", "\n", "        ", "\"\"\"Alternate constructor.\"\"\"", "\n", "return", "cls", "(", "\n", "opt", ".", "enc_layers", ",", "\n", "embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.mean_encoder.MeanEncoder.forward": [[25, 35], ["mean_encoder.MeanEncoder._check_args", "mean_encoder.MeanEncoder.embeddings", "mean_encoder.MeanEncoder.size", "mean_encoder.MeanEncoder.mean().expand", "mean_encoder.MeanEncoder.mean"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.encoder.EncoderBase._check_args"], ["", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"See :func:`EncoderBase.forward()`\"\"\"", "\n", "self", ".", "_check_args", "(", "src", ",", "lengths", ")", "\n", "\n", "emb", "=", "self", ".", "embeddings", "(", "src", ")", "\n", "_", ",", "batch", ",", "emb_dim", "=", "emb", ".", "size", "(", ")", "\n", "mean", "=", "emb", ".", "mean", "(", "0", ")", ".", "expand", "(", "self", ".", "num_layers", ",", "batch", ",", "emb_dim", ")", "\n", "memory_bank", "=", "emb", "\n", "encoder_final", "=", "(", "mean", ",", "mean", ")", "\n", "return", "encoder_final", ",", "memory_bank", ",", "lengths", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.imgvec_encoder.ImgVecEncoder.__init__": [[14, 18], ["onmt.encoders.encoder.EncoderBase.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "emb_dim", ",", "outp_dim", ")", ":", "\n", "        ", "super", "(", "ImgVecEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "emb_dim", ",", "outp_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.imgvec_encoder.ImgVecEncoder.from_opt": [[19, 26], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ",", "embeddings", ")", ":", "\n", "        ", "\"\"\"Alternate constructor.\"\"\"", "\n", "return", "cls", "(", "\n", "opt", ".", "enc_layers", ",", "\n", "opt", ".", "image_channel_size", ",", "\n", "opt", ".", "word_vec_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.imgvec_encoder.ImgVecEncoder.forward": [[27, 38], ["imgvec_encoder.ImgVecEncoder._check_args", "imgvec_encoder.ImgVecEncoder.proj", "imgvec_encoder.ImgVecEncoder.size", "imgvec_encoder.ImgVecEncoder.mean().expand", "imgvec_encoder.ImgVecEncoder.mean"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.encoder.EncoderBase._check_args"], ["", "def", "forward", "(", "self", ",", "emb", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"See :func:`EncoderBase.forward()`\"\"\"", "\n", "self", ".", "_check_args", "(", "emb", ",", "lengths", ")", "\n", "\n", "emb", "=", "self", ".", "proj", "(", "emb", ")", "\n", "_", ",", "batch", ",", "emb_dim", "=", "emb", ".", "size", "(", ")", "\n", "\n", "mean", "=", "emb", ".", "mean", "(", "0", ")", ".", "expand", "(", "self", ".", "num_layers", ",", "batch", ",", "emb_dim", ")", "\n", "memory_bank", "=", "emb", "\n", "encoder_final", "=", "(", "mean", ",", "mean", ")", "\n", "return", "encoder_final", ",", "memory_bank", ",", "lengths", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.embonly.EmbOnlyEncoder.__init__": [[4, 7], ["onmt.encoders.encoder.EncoderBase.__init__"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", "EmbOnlyEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.embonly.EmbOnlyEncoder.from_opt": [[8, 12], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ",", "embeddings", ")", ":", "\n", "        ", "\"\"\"Alternate constructor.\"\"\"", "\n", "return", "cls", "(", "embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.embonly.EmbOnlyEncoder.forward": [[13, 18], ["embonly.EmbOnlyEncoder._check_args", "embonly.EmbOnlyEncoder.embeddings"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.encoder.EncoderBase._check_args"], ["", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"See :func:`EncoderBase.forward()`\"\"\"", "\n", "self", ".", "_check_args", "(", "src", ",", "lengths", ")", "\n", "emb", "=", "self", ".", "embeddings", "(", "src", ")", "\n", "return", "emb", ",", "emb", ",", "lengths", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.image_encoder.ImageEncoder.__init__": [[19, 49], ["onmt.encoders.encoder.EncoderBase.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Embedding", "torch.Embedding", "torch.Embedding", "int"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "bidirectional", ",", "rnn_size", ",", "dropout", ",", "\n", "image_chanel_size", "=", "3", ")", ":", "\n", "        ", "super", "(", "ImageEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "self", ".", "hidden_size", "=", "rnn_size", "\n", "\n", "self", ".", "layer1", "=", "nn", ".", "Conv2d", "(", "image_chanel_size", ",", "64", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer2", "=", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer3", "=", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer4", "=", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer5", "=", "nn", ".", "Conv2d", "(", "256", ",", "512", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer6", "=", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "\n", "self", ".", "batch_norm1", "=", "nn", ".", "BatchNorm2d", "(", "256", ")", "\n", "self", ".", "batch_norm2", "=", "nn", ".", "BatchNorm2d", "(", "512", ")", "\n", "self", ".", "batch_norm3", "=", "nn", ".", "BatchNorm2d", "(", "512", ")", "\n", "\n", "src_size", "=", "512", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "src_size", ",", "int", "(", "rnn_size", "/", "self", ".", "num_directions", ")", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "bidirectional", ")", "\n", "self", ".", "pos_lut", "=", "nn", ".", "Embedding", "(", "1000", ",", "src_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.image_encoder.ImageEncoder.from_opt": [[50, 66], ["cls", "ValueError"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ",", "embeddings", "=", "None", ")", ":", "\n", "        ", "\"\"\"Alternate constructor.\"\"\"", "\n", "if", "embeddings", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot use embeddings with ImageEncoder.\"", ")", "\n", "# why is the model_opt.__dict__ check necessary?", "\n", "", "if", "\"image_channel_size\"", "not", "in", "opt", ".", "__dict__", ":", "\n", "            ", "image_channel_size", "=", "3", "\n", "", "else", ":", "\n", "            ", "image_channel_size", "=", "opt", ".", "image_channel_size", "\n", "", "return", "cls", "(", "\n", "opt", ".", "enc_layers", ",", "\n", "opt", ".", "brnn", ",", "\n", "opt", ".", "enc_rnn_size", ",", "\n", "opt", ".", "dropout", ",", "\n", "image_channel_size", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.image_encoder.ImageEncoder.load_pretrained_vectors": [[68, 71], ["None"], "methods", ["None"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Pass in needed options only when modify function definition.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.image_encoder.ImageEncoder.forward": [[72, 128], ["torch.relu.size", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "image_encoder.ImageEncoder.layer1", "image_encoder.ImageEncoder.layer2", "image_encoder.ImageEncoder.batch_norm1", "image_encoder.ImageEncoder.layer4", "image_encoder.ImageEncoder.batch_norm2", "image_encoder.ImageEncoder.batch_norm3", "torch.relu.size", "src[].transpose().transpose", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "image_encoder.ImageEncoder.pos_lut", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "image_encoder.ImageEncoder.rnn", "all_outputs.append", "image_encoder.ImageEncoder.layer3", "image_encoder.ImageEncoder.layer5", "image_encoder.ImageEncoder.layer6", "src[].transpose", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "image_encoder.ImageEncoder.view", "image_encoder.ImageEncoder.size", "image_encoder.ImageEncoder.size", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"See :func:`onmt.encoders.encoder.EncoderBase.forward()`\"\"\"", "\n", "\n", "batch_size", "=", "src", ".", "size", "(", "0", ")", "\n", "# (batch_size, 64, imgH, imgW)", "\n", "# layer 1", "\n", "src", "=", "F", ".", "relu", "(", "self", ".", "layer1", "(", "src", "[", ":", ",", ":", ",", ":", ",", ":", "]", "-", "0.5", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 64, imgH/2, imgW/2)", "\n", "src", "=", "F", ".", "max_pool2d", "(", "src", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "\n", "# (batch_size, 128, imgH/2, imgW/2)", "\n", "# layer 2", "\n", "src", "=", "F", ".", "relu", "(", "self", ".", "layer2", "(", "src", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 128, imgH/2/2, imgW/2/2)", "\n", "src", "=", "F", ".", "max_pool2d", "(", "src", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "\n", "#  (batch_size, 256, imgH/2/2, imgW/2/2)", "\n", "# layer 3", "\n", "# batch norm 1", "\n", "src", "=", "F", ".", "relu", "(", "self", ".", "batch_norm1", "(", "self", ".", "layer3", "(", "src", ")", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 256, imgH/2/2, imgW/2/2)", "\n", "# layer4", "\n", "src", "=", "F", ".", "relu", "(", "self", ".", "layer4", "(", "src", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 256, imgH/2/2/2, imgW/2/2)", "\n", "src", "=", "F", ".", "max_pool2d", "(", "src", ",", "kernel_size", "=", "(", "1", ",", "2", ")", ",", "stride", "=", "(", "1", ",", "2", ")", ")", "\n", "\n", "# (batch_size, 512, imgH/2/2/2, imgW/2/2)", "\n", "# layer 5", "\n", "# batch norm 2", "\n", "src", "=", "F", ".", "relu", "(", "self", ".", "batch_norm2", "(", "self", ".", "layer5", "(", "src", ")", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 512, imgH/2/2/2, imgW/2/2/2)", "\n", "src", "=", "F", ".", "max_pool2d", "(", "src", ",", "kernel_size", "=", "(", "2", ",", "1", ")", ",", "stride", "=", "(", "2", ",", "1", ")", ")", "\n", "\n", "# (batch_size, 512, imgH/2/2/2, imgW/2/2/2)", "\n", "src", "=", "F", ".", "relu", "(", "self", ".", "batch_norm3", "(", "self", ".", "layer6", "(", "src", ")", ")", ",", "True", ")", "\n", "\n", "# # (batch_size, 512, H, W)", "\n", "all_outputs", "=", "[", "]", "\n", "for", "row", "in", "range", "(", "src", ".", "size", "(", "2", ")", ")", ":", "\n", "            ", "inp", "=", "src", "[", ":", ",", ":", ",", "row", ",", ":", "]", ".", "transpose", "(", "0", ",", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "row_vec", "=", "torch", ".", "Tensor", "(", "batch_size", ")", ".", "type_as", "(", "inp", ".", "data", ")", ".", "long", "(", ")", ".", "fill_", "(", "row", ")", "\n", "pos_emb", "=", "self", ".", "pos_lut", "(", "row_vec", ")", "\n", "with_pos", "=", "torch", ".", "cat", "(", "\n", "(", "pos_emb", ".", "view", "(", "1", ",", "pos_emb", ".", "size", "(", "0", ")", ",", "pos_emb", ".", "size", "(", "1", ")", ")", ",", "inp", ")", ",", "0", ")", "\n", "outputs", ",", "hidden_t", "=", "self", ".", "rnn", "(", "with_pos", ")", "\n", "all_outputs", ".", "append", "(", "outputs", ")", "\n", "", "out", "=", "torch", ".", "cat", "(", "all_outputs", ",", "0", ")", "\n", "\n", "return", "hidden_t", ",", "out", ",", "lengths", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.__init__.NoneEncoder.from_opt": [[13, 16], ["None"], "methods", ["None"], ["onmt", ".", "utils", ".", "optimizers", ".", "Optim", "=", "onmt", ".", "utils", ".", "optimizers", ".", "Optimizer", "\n", "sys", ".", "modules", "[", "\"onmt.Optim\"", "]", "=", "onmt", ".", "utils", ".", "optimizers", "\n", "\n", "# For Flake", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerGPTEncoderLayer.__init__": [[26, 37], ["torch.Module.__init__", "onmt.modules.MultiHeadedAttention", "onmt.modules.gpt_mlp.MLP", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["\n", "\n", "def", "__init__", "(", "self", ",", "d_model", ",", "heads", ",", "d_ff", ",", "dropout", ",", "attn_dropout", ",", "\n", "self_attn_type", "=", "\"scaled-dot\"", ",", "max_relative_positions", "=", "0", ")", ":", "\n", "        ", "super", "(", "TransformerGPTUnconditionalDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "self_attn_type", "==", "\"scaled-dot\"", ":", "\n", "            ", "self", ".", "self_attn", "=", "MultiHeadedAttention", "(", "\n", "heads", ",", "d_model", ",", "dropout", "=", "attn_dropout", ",", "\n", "max_relative_positions", "=", "max_relative_positions", ")", "\n", "", "elif", "self_attn_type", "==", "\"average\"", ":", "\n", "            ", "self", ".", "self_attn", "=", "AverageAttention", "(", "d_model", ",", "dropout", "=", "attn_dropout", ")", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerGPTEncoderLayer.forward": [[38, 69], ["mask.size", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "future_mask.triu_().view.triu_().view.triu_().view", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "transformer.TransformerGPTEncoderLayer.layer_norm_1", "transformer.TransformerGPTEncoderLayer.self_attn", "transformer.TransformerGPTEncoderLayer.layer_norm_2", "transformer.TransformerGPTEncoderLayer.feed_forward", "transformer.TransformerGPTEncoderLayer.dropout", "future_mask.triu_().view.triu_().view.triu_"], "methods", ["None"], ["\n", "", "self", ".", "feed_forward", "=", "MLP", "(", "d_model", ",", "d_model", "*", "4", ",", "dropout", ")", "\n", "self", ".", "layer_norm_1", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-5", ")", "\n", "self", ".", "layer_norm_2", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-5", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "inputs", ",", "memory_bank", ",", "src_pad_mask", ",", "tgt_pad_mask", ",", "\n", "layer_cache", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (FloatTensor): ``(batch_size, 1, model_dim)``\n            memory_bank (FloatTensor): ``(batch_size, src_len, model_dim)``\n            src_pad_mask (LongTensor): ``(batch_size, 1, src_len)``\n            tgt_pad_mask (LongTensor): ``(batch_size, 1, 1)``\n\n        Returns:\n            (FloatTensor, FloatTensor):\n\n            * output ``(batch_size, 1, model_dim)``\n            * attn ``(batch_size, 1, src_len)``\n\n        \"\"\"", "\n", "dec_mask", "=", "None", "\n", "if", "step", "is", "None", ":", "\n", "            ", "tgt_len", "=", "tgt_pad_mask", ".", "size", "(", "-", "1", ")", "\n", "future_mask", "=", "torch", ".", "ones", "(", "\n", "[", "tgt_len", ",", "tgt_len", "]", ",", "\n", "device", "=", "tgt_pad_mask", ".", "device", ",", "\n", "dtype", "=", "torch", ".", "uint8", ")", "\n", "future_mask", "=", "future_mask", ".", "triu_", "(", "1", ")", ".", "view", "(", "1", ",", "tgt_len", ",", "tgt_len", ")", "\n", "dec_mask", "=", "torch", ".", "gt", "(", "tgt_pad_mask", "+", "future_mask", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoderLayer.__init__": [[83, 93], ["torch.Module.__init__", "onmt.modules.MultiHeadedAttention", "onmt.modules.position_ffn.PositionwiseFeedForward", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["\n", "output", "=", "self", ".", "feed_forward", "(", "query_norm", ")", "\n", "output", "=", "output", "+", "query", "\n", "\n", "return", "output", ",", "attn", "\n", "\n", "\n", "", "", "class", "TransformerGPTDecoderLayerCtxattn", "(", "nn", ".", "Module", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoderLayer.forward": [[94, 110], ["transformer.TransformerEncoderLayer.layer_norm", "transformer.TransformerEncoderLayer.self_attn", "transformer.TransformerEncoderLayer.feed_forward", "transformer.TransformerEncoderLayer.dropout"], "methods", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "d_model", ",", "heads", ",", "d_ff", ",", "dropout", ",", "attn_dropout", ",", "\n", "self_attn_type", "=", "\"scaled-dot\"", ",", "max_relative_positions", "=", "0", ",", "\n", "ctx_weight_param", "=", "False", ")", ":", "\n", "        ", "super", "(", "TransformerGPTDecoderLayerCtxattn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "self_attn_type", "==", "\"scaled-dot\"", ":", "\n", "            ", "self", ".", "self_attn", "=", "MultiHeadedAttention", "(", "\n", "heads", ",", "d_model", ",", "dropout", "=", "attn_dropout", ",", "\n", "max_relative_positions", "=", "max_relative_positions", ")", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__": [[143, 161], ["onmt.encoders.encoder.EncoderBase.__init__", "torch.ModuleList", "torch.ModuleList", "torch.LayerNorm", "torch.LayerNorm", "layer_cls", "range"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.__init__"], ["dec_mask", "=", "None", "\n", "if", "step", "is", "None", ":", "\n", "            ", "tgt_len", "=", "tgt_pad_mask", ".", "size", "(", "-", "1", ")", "\n", "future_mask", "=", "torch", ".", "ones", "(", "\n", "[", "tgt_len", ",", "tgt_len", "]", ",", "\n", "device", "=", "tgt_pad_mask", ".", "device", ",", "\n", "dtype", "=", "torch", ".", "uint8", ")", "\n", "future_mask", "=", "future_mask", ".", "triu_", "(", "1", ")", ".", "view", "(", "1", ",", "tgt_len", ",", "tgt_len", ")", "\n", "dec_mask", "=", "torch", ".", "gt", "(", "tgt_pad_mask", "+", "future_mask", ",", "0", ")", "\n", "\n", "", "input_norm", "=", "self", ".", "layer_norm_1", "(", "inputs", ")", "\n", "\n", "if", "isinstance", "(", "self", ".", "self_attn", ",", "MultiHeadedAttention", ")", ":", "\n", "            ", "query", ",", "attn", "=", "self", ".", "self_attn", "(", "input_norm", ",", "input_norm", ",", "input_norm", ",", "\n", "mask", "=", "dec_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "\n", "type", "=", "\"self\"", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "self_attn", ",", "AverageAttention", ")", ":", "\n", "            ", "query", ",", "attn", "=", "self", ".", "self_attn", "(", "input_norm", ",", "mask", "=", "dec_mask", ",", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.from_opt": [[162, 175], ["cls", "hasattr"], "methods", ["None"], ["layer_cache", "=", "layer_cache", ",", "step", "=", "step", ")", "\n", "\n", "", "query", "=", "self", ".", "drop", "(", "query", ")", "+", "inputs", "\n", "\n", "query_norm", "=", "self", ".", "layer_norm_2", "(", "query", ")", "\n", "\n", "mid", ",", "attn", "=", "self", ".", "context_attn", "(", "memory_bank", ",", "memory_bank", ",", "query_norm", ",", "\n", "mask", "=", "src_pad_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "\n", "type", "=", "\"context\"", ")", "\n", "mid", "=", "self", ".", "drop", "(", "mid", ")", "\n", "if", "self", ".", "ctx_weight_param", ":", "\n", "            ", "mid", "=", "mid", "*", "self", ".", "ctx_weight", "\n", "", "mid", "+=", "query", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.transformer.TransformerEncoder.forward": [[176, 193], ["transformer.TransformerEncoder._check_args", "transformer.TransformerEncoder.embeddings", "transformer.TransformerEncoder.transpose().contiguous", "src[].transpose", "src[].transpose.size", "src[].transpose.data.eq().unsqueeze", "transformer.TransformerEncoder.layer_norm", "layer", "layer.transpose().contiguous", "transformer.TransformerEncoder.transpose", "src[].transpose.data.eq", "layer.transpose"], "methods", ["home.repos.pwc.inspect_result.bigheiniu_FactGen.encoders.encoder.EncoderBase._check_args"], ["mid_norm", "=", "self", ".", "context_layer_norm", "(", "mid", ")", "\n", "\n", "output", "=", "self", ".", "feed_forward", "(", "mid_norm", ")", "\n", "#output = self.feed_forward(query_norm)", "\n", "output", "=", "output", "+", "mid", "\n", "\n", "return", "output", ",", "attn", "\n", "\n", "", "", "class", "TransformerGPTDecoderLayerPSA", "(", "nn", ".", "Module", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.source.conf.setup": [[210, 216], ["print", "app.add_config_value", "app.add_transform"], "function", ["None"], ["def", "setup", "(", "app", ")", ":", "\n", "    ", "print", "(", "\"hello\"", ")", "\n", "app", ".", "add_config_value", "(", "'recommonmark_config'", ",", "{", "\n", "'enable_eval_rst'", ":", "True", "\n", "}", ",", "True", ")", "\n", "app", ".", "add_transform", "(", "AutoStructify", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.NeuralGenerationDetection.RoBERTaDetect.train": [[9, 41], ["pandas.DataFrame", "simpletransformers.classification.ClassificationModel", "simpletransformers.classification.ClassificationModel.train_model", "print", "i.strip", "open().readlines", "i.strip", "open().readlines", "i.strip", "open().readlines", "open", "open", "open"], "function", ["None"], ["def", "train", "(", "human_file", ",", "gen_file", ",", "our_gen_file", ",", "output_dir", ")", ":", "\n", "    ", "data", "=", "[", "]", "\n", "data", "+=", "[", "(", "i", ".", "strip", "(", ")", ",", "1", ")", "for", "i", "in", "open", "(", "human_file", ",", "'r'", ")", ".", "readlines", "(", ")", "]", "\n", "data", "+=", "[", "(", "i", ".", "strip", "(", ")", ",", "0", ")", "for", "i", "in", "open", "(", "gen_file", ",", "'r'", ")", ".", "readlines", "(", ")", "]", "\n", "data", "+=", "[", "(", "i", ".", "strip", "(", ")", ",", "0", ")", "for", "i", "in", "open", "(", "our_gen_file", ",", "'r'", ")", ".", "readlines", "(", ")", "]", "\n", "\n", "all_df", "=", "pd", ".", "DataFrame", "(", "data", ")", "\n", "\n", "train_args", "=", "{", "\n", "'overwrite_output_dir'", ":", "True", ",", "\n", "'num_train_epochs'", ":", "10", ",", "\n", "'process_count'", ":", "10", ",", "\n", "'train_batch_size'", ":", "10", ",", "\n", "'eval_batch_size'", ":", "20", ",", "\n", "'max_seq_length'", ":", "300", ",", "\n", "'reprocess_input_data'", ":", "True", ",", "\n", "'learning_rate'", ":", "1e-5", ",", "\n", "\"evaluate_during_training\"", ":", "True", ",", "\n", "\"use_early_stopping\"", ":", "True", ",", "\n", "'early_stopping_patience'", ":", "3", ",", "\n", "\"early_stopping_metric\"", ":", "\"eval_loss\"", ",", "\n", "\"early_stopping_metric_minimize\"", ":", "True", ",", "\n", "\"no_cache\"", ":", "True", ",", "\n", "'output_dir'", ":", "output_dir", "\n", "}", "\n", "\n", "model", "=", "ClassificationModel", "(", "'roberta'", ",", "\"roberta-base\"", ",", "args", "=", "train_args", ")", "# You can set class weights by using the optional weight argument", "\n", "\n", "# Train the model", "\n", "\n", "model", ".", "train_model", "(", "all_df", ")", "\n", "print", "(", "\"finish the training\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bigheiniu_FactGen.NeuralGenerationDetection.RoBERTaDetect.eval": [[43, 70], ["open().readlines", "open().readlines", "pandas.DataFrame", "pd.DataFrame.sample", "simpletransformers.classification.ClassificationModel", "simpletransformers.classification.ClassificationModel.eval_model", "print", "i.strip", "i.strip", "open", "open", "len", "len"], "function", ["None"], ["", "def", "eval", "(", "model_path", ",", "our_gen_file", ",", "human_file", ")", ":", "\n", "    ", "gen", "=", "open", "(", "our_gen_file", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "gen", "=", "[", "i", ".", "strip", "(", ")", "for", "i", "in", "gen", "]", "\n", "human", "=", "open", "(", "human_file", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "human", "=", "[", "i", ".", "strip", "(", ")", "for", "i", "in", "human", "]", "\n", "\n", "assert", "len", "(", "human", ")", "-", "len", "(", "gen", ")", "==", "0", ",", "\"please balance the eval file\"", "\n", "\n", "test_df", "=", "pd", ".", "DataFrame", "(", "gen", "+", "human", ")", "\n", "test_input", "=", "test_df", ".", "sample", "(", "frac", "=", "1", ",", "random_state", "=", "123", ")", "\n", "\n", "train_args", "=", "{", "\n", "'learning_rate'", ":", "3e-5", ",", "\n", "'num_train_epochs'", ":", "5", ",", "\n", "'reprocess_input_data'", ":", "True", ",", "\n", "'overwrite_output_dir'", ":", "False", ",", "\n", "'process_count'", ":", "10", ",", "\n", "'train_batch_size'", ":", "4", ",", "\n", "'eval_batch_size'", ":", "400", ",", "\n", "'max_seq_length'", ":", "300", ",", "\n", "\"fp16\"", ":", "False", "\n", "}", "\n", "\n", "model", "=", "ClassificationModel", "(", "'roberta'", ",", "model_path", ",", "num_labels", "=", "4", ",", "use_cuda", "=", "True", ",", "cuda_device", "=", "0", ",", "args", "=", "train_args", ")", "\n", "\n", "result", ",", "model_outputs", ",", "wrong_predictions", "=", "model", ".", "eval_model", "(", "test_input", ")", "\n", "print", "(", "result", ")", "\n", "\n"]]}