{"home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.Dataset.__init__": [[69, 87], ["functools.partial"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "task", ",", "context_features", ",", "sequence_features", ",", "batch_size", ",", "\n", "eval_batch_size", ",", "feature_engineering_fn", ",", "seed", ")", ":", "\n", "    ", "\"\"\"Stores all info needed to generate the dataset.\"\"\"", "\n", "self", ".", "_train_dataset", "=", "None", "\n", "self", ".", "_train_eval_dataset", "=", "None", "\n", "self", ".", "_val_dataset", "=", "None", "\n", "self", ".", "_test_dataset", "=", "None", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "eval_batch_size", "=", "eval_batch_size", "\n", "self", ".", "_create_dataset", "=", "functools", ".", "partial", "(", "\n", "input_fn", ".", "create_dataset", ",", "\n", "context_features", "=", "context_features", ",", "\n", "sequence_features", "=", "sequence_features", ",", "\n", "task", "=", "task", ",", "\n", "buffer_size", "=", "256", ",", "\n", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ",", "\n", "feature_engineering_fn", "=", "feature_engineering_fn", ",", "\n", "seed", "=", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.Dataset.train_dataset": [[88, 98], ["bayesian_rnn_eager_main.Dataset._create_dataset().prefetch", "bayesian_rnn_eager_main.Dataset._create_dataset"], "methods", ["None"], ["", "@", "property", "\n", "def", "train_dataset", "(", "self", ")", ":", "\n", "    ", "\"\"\"Training dataset split for use during training.\"\"\"", "\n", "if", "self", ".", "_train_dataset", "is", "None", ":", "\n", "      ", "self", ".", "_train_dataset", "=", "self", ".", "_create_dataset", "(", "\n", "mode", "=", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ",", "\n", "dataset_type", "=", "constants", ".", "DatasetType", ".", "TRAIN", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ")", ".", "prefetch", "(", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "", "return", "self", ".", "_train_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.Dataset.train_eval_dataset": [[99, 109], ["bayesian_rnn_eager_main.Dataset._create_dataset().prefetch", "bayesian_rnn_eager_main.Dataset._create_dataset"], "methods", ["None"], ["", "@", "property", "\n", "def", "train_eval_dataset", "(", "self", ")", ":", "\n", "    ", "\"\"\"Training dataset split for use during evaluation with no shuffling.\"\"\"", "\n", "if", "self", ".", "_train_eval_dataset", "is", "None", ":", "\n", "      ", "self", ".", "_train_eval_dataset", "=", "self", ".", "_create_dataset", "(", "\n", "mode", "=", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ",", "\n", "dataset_type", "=", "constants", ".", "DatasetType", ".", "TRAIN", ",", "\n", "batch_size", "=", "self", ".", "eval_batch_size", ",", "\n", "shuffle", "=", "False", ")", ".", "prefetch", "(", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "", "return", "self", ".", "_train_eval_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.Dataset.val_dataset": [[110, 120], ["bayesian_rnn_eager_main.Dataset._create_dataset().prefetch", "bayesian_rnn_eager_main.Dataset._create_dataset"], "methods", ["None"], ["", "@", "property", "\n", "def", "val_dataset", "(", "self", ")", ":", "\n", "    ", "\"\"\"Validation dataset split.\"\"\"", "\n", "if", "self", ".", "_val_dataset", "is", "None", ":", "\n", "      ", "self", ".", "_val_dataset", "=", "self", ".", "_create_dataset", "(", "\n", "mode", "=", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ",", "\n", "dataset_type", "=", "constants", ".", "DatasetType", ".", "VALIDATION", ",", "\n", "batch_size", "=", "self", ".", "eval_batch_size", ",", "\n", "shuffle", "=", "False", ")", ".", "prefetch", "(", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "", "return", "self", ".", "_val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.Dataset.test_dataset": [[121, 131], ["bayesian_rnn_eager_main.Dataset._create_dataset().prefetch", "bayesian_rnn_eager_main.Dataset._create_dataset"], "methods", ["None"], ["", "@", "property", "\n", "def", "test_dataset", "(", "self", ")", ":", "\n", "    ", "\"\"\"Testing dataset split.\"\"\"", "\n", "if", "self", ".", "_test_dataset", "is", "None", ":", "\n", "      ", "self", ".", "_test_dataset", "=", "self", ".", "_create_dataset", "(", "\n", "mode", "=", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ",", "\n", "dataset_type", "=", "constants", ".", "DatasetType", ".", "TEST", ",", "\n", "batch_size", "=", "self", ".", "eval_batch_size", ",", "\n", "shuffle", "=", "False", ")", ".", "prefetch", "(", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "", "return", "self", ".", "_test_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.MetricReporter.__init__": [[231, 245], ["get_work_unit_for_tracker"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "\"\"\"Initializes a metric reporter.\n\n    Args:\n      prefix: A string to prepend to each metric name.\n    \"\"\"", "\n", "try", ":", "\n", "# TODO(dusenberrymw): Open-source an experiment tracker.", "\n", "      ", "self", ".", "work_unit", "=", "get_work_unit_for_tracker", "(", ")", "\n", "", "except", "RuntimeError", ":", "# local runs don't use metric reporting", "\n", "      ", "self", ".", "work_unit", "=", "None", "\n", "", "self", ".", "measurements", "=", "{", "}", "\n", "self", ".", "prefix", "=", "prefix", "\n", "self", ".", "built", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.MetricReporter._build": [[246, 252], ["metrics.keys", "bayesian_rnn_eager_main.MetricReporter.work_unit.get_measurement_series"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "metrics", ")", ":", "\n", "    ", "for", "k", "in", "metrics", ".", "keys", "(", ")", ":", "\n", "      ", "name", "=", "f\"{self.prefix}_{k}\"", "\n", "self", ".", "measurements", "[", "name", "]", "=", "self", ".", "work_unit", ".", "get_measurement_series", "(", "\n", "label", "=", "name", ")", "\n", "", "self", ".", "built", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.MetricReporter.maybe_report_metrics": [[253, 266], ["metrics.items", "bayesian_rnn_eager_main.MetricReporter._build", "bayesian_rnn_eager_main.MetricReporter.measurements[].create_measurement", "int"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.MetricReporter._build"], ["", "def", "maybe_report_metrics", "(", "self", ",", "metrics", ",", "global_step", ")", ":", "\n", "    ", "\"\"\"Reports metrics if this job was started remotely.\n\n    Args:\n      metrics: A dictionary mapping string names to metric values.\n      global_step: An integer global step value.\n    \"\"\"", "\n", "if", "self", ".", "work_unit", "is", "not", "None", ":", "\n", "      ", "if", "not", "self", ".", "built", ":", "\n", "        ", "self", ".", "_build", "(", "metrics", ")", "\n", "", "for", "k", ",", "v", "in", "metrics", ".", "items", "(", ")", ":", "\n", "        ", "name", "=", "f\"{self.prefix}_{k}\"", "\n", "self", ".", "measurements", "[", "name", "]", ".", "create_measurement", "(", "v", ",", "step", "=", "int", "(", "global_step", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.BestExporter.__init__": [[271, 298], ["os.path.join", "os.path.join", "tensorflow.io.gfile.exists", "tensorflow.io.gfile.makedirs", "tensorflow.Variable", "tensorflow.train.Checkpoint", "bayesian_rnn_eager_main.BestExporter.state_checkpoint.restore"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "checkpoint", ",", "directory", ",", "goal", ",", "filename", "=", "\"ckpt\"", ")", ":", "\n", "    ", "\"\"\"Set up a best model exporter.\n\n    Args:\n      checkpoint: A tf.train.Checkpoint object.\n      directory: The path to a directory in which to write checkpoints. This\n        object will also save a special file with the name \"checkpoint_state\" to\n        maintain the best metric seen so far.\n      goal: The metric optimization goal. Either \"max\" or \"min\".\n      filename: A string prefix for saved checkpoint filenames.\n    \"\"\"", "\n", "self", ".", "checkpoint", "=", "checkpoint", "\n", "if", "goal", "==", "\"max\"", ":", "\n", "      ", "self", ".", "compare_fn", "=", "lambda", "a", ",", "b", ":", "a", ">=", "b", "\n", "", "else", ":", "\n", "      ", "self", ".", "compare_fn", "=", "lambda", "a", ",", "b", ":", "a", "<=", "b", "\n", "", "if", "not", "tf", ".", "io", ".", "gfile", ".", "exists", "(", "directory", ")", ":", "\n", "      ", "tf", ".", "io", ".", "gfile", ".", "makedirs", "(", "directory", ")", "\n", "", "self", ".", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "filename", ")", "\n", "self", ".", "state_path", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "\"checkpoint_state\"", ")", "\n", "try", ":", "\n", "      ", "self", ".", "best_metric", "=", "tf", ".", "Variable", "(", "0.", ",", "name", "=", "\"best_metric\"", ")", "\n", "self", ".", "state_checkpoint", "=", "tf", ".", "train", ".", "Checkpoint", "(", "best_metric", "=", "self", ".", "best_metric", ")", "\n", "self", ".", "state_checkpoint", ".", "restore", "(", "self", ".", "state_path", ")", "\n", "", "except", "tf", ".", "errors", ".", "NotFoundError", ":", "\n", "      ", "self", ".", "best_metric", "=", "None", "\n", "self", ".", "state_checkpoint", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.BestExporter.maybe_export_model": [[299, 312], ["bayesian_rnn_eager_main.BestExporter.compare_fn", "tensorflow.Variable", "tensorflow.train.Checkpoint", "bayesian_rnn_eager_main.BestExporter.best_metric.numpy", "bayesian_rnn_eager_main.BestExporter.best_metric.assign", "bayesian_rnn_eager_main.BestExporter.state_checkpoint.write", "bayesian_rnn_eager_main.BestExporter.checkpoint.write"], "methods", ["None"], ["", "", "def", "maybe_export_model", "(", "self", ",", "current_metric", ")", ":", "\n", "    ", "\"\"\"Exports the model if it is the best seen thus far.\n\n    Args:\n      current_metric: A scalar metric value.\n    \"\"\"", "\n", "if", "self", ".", "best_metric", "is", "None", ":", "\n", "      ", "self", ".", "best_metric", "=", "tf", ".", "Variable", "(", "current_metric", ",", "name", "=", "\"best_metric\"", ")", "\n", "self", ".", "state_checkpoint", "=", "tf", ".", "train", ".", "Checkpoint", "(", "best_metric", "=", "self", ".", "best_metric", ")", "\n", "", "if", "self", ".", "compare_fn", "(", "current_metric", ",", "self", ".", "best_metric", ".", "numpy", "(", ")", ")", ":", "\n", "      ", "self", ".", "best_metric", ".", "assign", "(", "current_metric", ")", "\n", "self", ".", "state_checkpoint", ".", "write", "(", "self", ".", "state_path", ")", "\n", "self", ".", "checkpoint", ".", "write", "(", "self", ".", "checkpoint_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.evaluate": [[133, 199], ["tensorflow.keras.metrics.Mean", "edward2.metrics.ExpectedCalibrationError", "tensorflow.keras.metrics.AUC", "tensorflow.keras.metrics.AUC", "tensorflow.keras.metrics.Accuracy", "tensorflow.keras.metrics.Recall", "tensorflow.keras.metrics.Precision", "dataset.take", "tf.keras.metrics.Mean.result", "sum", "ed.metrics.ExpectedCalibrationError.result", "tf.keras.metrics.AUC.result", "tf.keras.metrics.AUC.result", "tf.keras.metrics.Recall.result", "tf.keras.metrics.Precision.result", "tf.keras.metrics.Accuracy.result", "sorted", "absl.logging.info", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.math.reduce_mean", "tf.keras.metrics.Mean.", "ed.metrics.ExpectedCalibrationError.", "tf.keras.metrics.AUC.", "tf.keras.metrics.AUC.", "tf.keras.metrics.Recall.", "tf.keras.metrics.Precision.", "tf.keras.metrics.Accuracy.", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow_probability.distributions.Bernoulli", "tensorflow.sigmoid", "tensorflow_probability.distributions.Multinomial", "tensorflow.math.argmax", "tensorflow.nn.softmax", "tensorflow.cast", "tensorflow.math.argmax", "set", "set", "int", "model", "tensorflow.math.log", "range", "tensorflow.reduce_logsumexp", "float", "tfp.distributions.Multinomial.log_prob"], "function", ["None"], ["", "", "def", "evaluate", "(", "model", ",", "dataset", ",", "task", ",", "global_step", ",", "num_ece_bins", ",", "num_samples", ",", "\n", "ensemble_size", ",", "name", ",", "steps", "=", "-", "1", ")", ":", "\n", "  ", "\"\"\"Evaluates the model on a dataset.\"\"\"", "\n", "nll_metric", "=", "tf", ".", "keras", ".", "metrics", ".", "Mean", "(", ")", "\n", "ece_metric", "=", "ed", ".", "metrics", ".", "ExpectedCalibrationError", "(", "num_bins", "=", "num_ece_bins", ")", "\n", "aucpr_metric", "=", "tf", ".", "keras", ".", "metrics", ".", "AUC", "(", "curve", "=", "\"PR\"", ")", "\n", "aucroc_metric", "=", "tf", ".", "keras", ".", "metrics", ".", "AUC", "(", "curve", "=", "\"ROC\"", ")", "\n", "acc_metric", "=", "tf", ".", "keras", ".", "metrics", ".", "Accuracy", "(", ")", "\n", "top_k", "=", "5", "if", "task", ".", "logits_dimension", ">=", "5", "else", "None", "\n", "sensitivity_metric", "=", "tf", ".", "keras", ".", "metrics", ".", "Recall", "(", "top_k", "=", "top_k", ")", "\n", "ppv_metric", "=", "tf", ".", "keras", ".", "metrics", ".", "Precision", "(", "top_k", "=", "top_k", ")", "\n", "\n", "for", "inputs", ",", "labels", "in", "dataset", ".", "take", "(", "steps", ")", ":", "\n", "    ", "logits", "=", "tf", ".", "reshape", "(", "\n", "[", "model", "(", "inputs", ",", "training", "=", "False", ")", "for", "_", "in", "range", "(", "num_samples", ")", "]", ",", "\n", "[", "num_samples", ",", "ensemble_size", ",", "-", "1", ",", "task", ".", "logits_dimension", "]", ")", "\n", "if", "task", ".", "logits_dimension", "==", "1", ":", "\n", "      ", "label_dist", "=", "tfp", ".", "distributions", ".", "Bernoulli", "(", "logits", ")", "\n", "labels_1d", "=", "labels", "\n", "probs", "=", "tf", ".", "sigmoid", "(", "logits", ")", "\n", "", "else", ":", "\n", "      ", "label_dist", "=", "tfp", ".", "distributions", ".", "Multinomial", "(", "1", ",", "logits", ")", "\n", "labels_1d", "=", "tf", ".", "math", ".", "argmax", "(", "labels", ",", "axis", "=", "-", "1", ")", "\n", "probs", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", "", "nll", "=", "tf", ".", "reduce_mean", "(", "\n", "-", "tf", ".", "reduce_logsumexp", "(", "label_dist", ".", "log_prob", "(", "labels", ")", ",", "axis", "=", "[", "0", ",", "1", "]", ")", "+", "\n", "tf", ".", "math", ".", "log", "(", "float", "(", "num_samples", "*", "ensemble_size", ")", ")", ")", "\n", "probs", "=", "tf", ".", "math", ".", "reduce_mean", "(", "probs", ",", "axis", "=", "[", "0", ",", "1", "]", ")", "# marginalize", "\n", "if", "task", ".", "logits_dimension", "==", "1", ":", "\n", "      ", "preds", "=", "tf", ".", "cast", "(", "probs", ">=", "0.5", ",", "labels", ".", "dtype", ")", "\n", "", "else", ":", "\n", "      ", "preds", "=", "tf", ".", "math", ".", "argmax", "(", "probs", ",", "axis", "=", "-", "1", ")", "\n", "", "nll_metric", "(", "nll", ")", "\n", "ece_metric", "(", "labels_1d", ",", "probs", ")", "\n", "aucpr_metric", "(", "labels", ",", "probs", ")", "\n", "aucroc_metric", "(", "labels", ",", "probs", ")", "\n", "sensitivity_metric", "(", "labels", ",", "probs", ")", "\n", "ppv_metric", "(", "labels", ",", "probs", ")", "\n", "acc_metric", "(", "labels_1d", ",", "preds", ")", "\n", "\n", "", "nll", "=", "nll_metric", ".", "result", "(", ")", "\n", "kl", "=", "sum", "(", "model", ".", "losses", ")", "\n", "loss", "=", "nll", "+", "kl", "/", "acc_metric", ".", "count", "\n", "ece", "=", "ece_metric", ".", "result", "(", ")", "\n", "aucpr", "=", "aucpr_metric", ".", "result", "(", ")", "\n", "aucroc", "=", "aucroc_metric", ".", "result", "(", ")", "\n", "sens", "=", "sensitivity_metric", ".", "result", "(", ")", "\n", "ppv", "=", "ppv_metric", ".", "result", "(", ")", "\n", "f1", "=", "(", "2", "*", "ppv", "*", "sens", ")", "/", "(", "ppv", "+", "sens", ")", "\n", "acc", "=", "acc_metric", ".", "result", "(", ")", "\n", "top_k_suffix", "=", "f\"@{top_k}\"", "if", "top_k", "is", "not", "None", "else", "\"\"", "\n", "metrics", "=", "{", "\"loss\"", ":", "loss", ",", "\"nll\"", ":", "nll", ",", "\"kl\"", ":", "kl", ",", "\"ece\"", ":", "ece", ",", "\"aucpr\"", ":", "aucpr", ",", "\n", "\"aucroc\"", ":", "aucroc", ",", "f\"sensitivity{top_k_suffix}\"", ":", "sens", ",", "\n", "f\"ppv{top_k_suffix}\"", ":", "ppv", ",", "f\"f1{top_k_suffix}\"", ":", "f1", ",", "\n", "\"accuracy\"", ":", "acc", "}", "\n", "loss_metric_names", "=", "[", "\"loss\"", ",", "\"nll\"", ",", "\"kl\"", "]", "\n", "other_metric_names", "=", "sorted", "(", "set", "(", "metrics", ")", "-", "set", "(", "loss_metric_names", ")", ")", "\n", "logging_string", "=", "f\"(Eval {name} @ step {int(global_step)})\"", "\n", "for", "k", "in", "loss_metric_names", "+", "other_metric_names", ":", "# preferred order", "\n", "    ", "logging_string", "+=", "f\", {k}: {metrics[k]:.4f}\"", "\n", "", "logging", ".", "info", "(", "logging_string", ")", "\n", "for", "k", "in", "loss_metric_names", ":", "\n", "    ", "tf", ".", "summary", ".", "scalar", "(", "f\"loss/{k}\"", ",", "metrics", "[", "k", "]", ",", "step", "=", "global_step", ")", "\n", "", "for", "k", "in", "other_metric_names", ":", "\n", "    ", "tf", ".", "summary", ".", "scalar", "(", "f\"metrics/{k}\"", ",", "metrics", "[", "k", "]", ",", "step", "=", "global_step", ")", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.predict": [[201, 217], ["dataset.take", "tensorflow.concat", "tensorflow.split", "tf.concat.append", "tensorflow.concat", "model", "all_labels.append", "range"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat"], ["", "def", "predict", "(", "model", ",", "dataset", ",", "num_samples", ",", "ensemble_size", ",", "steps", "=", "-", "1", ")", ":", "\n", "  ", "\"\"\"Makes logit predictions with the model.\"\"\"", "\n", "all_logits", "=", "[", "]", "\n", "all_labels", "=", "[", "]", "\n", "for", "inputs", ",", "labels", "in", "dataset", ".", "take", "(", "steps", ")", ":", "\n", "    ", "logits", "=", "[", "model", "(", "inputs", ",", "training", "=", "False", ")", "for", "_", "in", "range", "(", "num_samples", ")", "]", "\n", "# Reshape from [num_samples, batch_size*ensemble_size, logits_dim] to", "\n", "# [ensemble_size, num_samples, batch_size, logits_dim].", "\n", "logits", "=", "tf", ".", "split", "(", "logits", ",", "num_or_size_splits", "=", "ensemble_size", ",", "axis", "=", "1", ")", "\n", "all_logits", ".", "append", "(", "logits", ")", "\n", "if", "labels", "is", "not", "None", ":", "\n", "      ", "all_labels", ".", "append", "(", "labels", ")", "\n", "# Yield logits of shape [ensemble_size, num_samples, N, logits_dim].", "\n", "", "", "all_logits", "=", "tf", ".", "concat", "(", "all_logits", ",", "2", ")", "\n", "all_labels", "=", "tf", ".", "concat", "(", "all_labels", ",", "0", ")", "if", "all_labels", "else", "None", "\n", "return", "all_logits", ",", "all_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.get_device_and_data_format": [[219, 226], ["tensorflow.test.is_gpu_available", "tensorflow.test.is_gpu_available"], "function", ["None"], ["", "def", "get_device_and_data_format", "(", ")", ":", "\n", "  ", "device", "=", "\"/gpu:0\"", "if", "tf", ".", "test", ".", "is_gpu_available", "(", ")", "else", "\"/cpu:0\"", "\n", "if", "tf", ".", "test", ".", "is_gpu_available", "(", ")", ":", "\n", "    ", "data_format", "=", "\"channels_first\"", "\n", "", "else", ":", "\n", "    ", "data_format", "=", "\"channels_last\"", "\n", "", "return", "device", ",", "data_format", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.convert_flags_list_to_string": [[314, 323], ["sorted", "flag.serialize"], "function", ["None"], ["", "", "", "def", "convert_flags_list_to_string", "(", "flags_list", ")", ":", "\n", "  ", "\"\"\"Converts a list of flags into a string with --name=value per line.\"\"\"", "\n", "# Based on the absl.flags.FlagValues.flags_into_string method.", "\n", "s", "=", "\"\"", "\n", "sorted_flags", "=", "sorted", "(", "flags_list", ",", "key", "=", "lambda", "f", ":", "f", ".", "name", ")", "\n", "for", "flag", "in", "sorted_flags", ":", "\n", "    ", "if", "flag", ".", "value", "is", "not", "None", ":", "\n", "      ", "s", "+=", "flag", ".", "serialize", "(", ")", "+", "\"\\n\"", "\n", "", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.setup_and_save_flags": [[325, 344], ["datetime.datetime.strftime", "FLAGS.timestamp.format", "FLAGS.logdir.format", "FLAGS.model_dir.format", "FLAGS.predict_dir.format", "bayesian_rnn_eager_main.convert_flags_list_to_string", "os.path.join", "datetime.datetime.today", "tensorflow.io.gfile.exists", "tensorflow.io.gfile.makedirs", "FLAGS.get_key_flags_for_module", "tensorflow.io.gfile.exists", "tensorflow.io.gfile.GFile", "f.write"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.convert_flags_list_to_string"], ["", "def", "setup_and_save_flags", "(", ")", ":", "\n", "  ", "\"\"\"Sets defaults for placeholders and saves the resulting flags.\"\"\"", "\n", "timestamp", "=", "datetime", ".", "datetime", ".", "strftime", "(", "datetime", ".", "datetime", ".", "today", "(", ")", ",", "\n", "\"%y%m%d_%H%M%S\"", ")", "\n", "FLAGS", ".", "timestamp", "=", "FLAGS", ".", "timestamp", ".", "format", "(", "timestamp", "=", "timestamp", ")", "\n", "FLAGS", ".", "logdir", "=", "FLAGS", ".", "logdir", ".", "format", "(", "timestamp", "=", "FLAGS", ".", "timestamp", ")", "\n", "FLAGS", ".", "model_dir", "=", "FLAGS", ".", "model_dir", ".", "format", "(", "timestamp", "=", "FLAGS", ".", "timestamp", ")", "\n", "FLAGS", ".", "predict_dir", "=", "FLAGS", ".", "predict_dir", ".", "format", "(", "timestamp", "=", "FLAGS", ".", "timestamp", ")", "\n", "if", "not", "tf", ".", "io", ".", "gfile", ".", "exists", "(", "FLAGS", ".", "model_dir", ")", ":", "\n", "    ", "tf", ".", "io", ".", "gfile", ".", "makedirs", "(", "FLAGS", ".", "model_dir", ")", "\n", "# NOTE: This saved flags file can be reused in the future via", "\n", "# --flagfile=path/to/flags.cfg. Any overrides must be listed after this flag.", "\n", "", "flags_string", "=", "convert_flags_list_to_string", "(", "\n", "FLAGS", ".", "get_key_flags_for_module", "(", "bayesian_rnn_flags", ")", ")", "\n", "flag_file", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "model_dir", ",", "\"flags.cfg\"", ")", "\n", "if", "(", "FLAGS", ".", "job", "in", "(", "\"train\"", ",", "\"train_and_eval\"", ")", "and", "\n", "not", "tf", ".", "io", ".", "gfile", ".", "exists", "(", "flag_file", ")", ")", ":", "\n", "    ", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "flag_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "      ", "f", ".", "write", "(", "flags_string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.main": [[347, 677], ["bayesian_rnn_eager_main.setup_and_save_flags", "tensorflow.enable_v2_behavior", "tensorflow.random.set_seed", "bayesian_rnn_eager_main.get_device_and_data_format", "absl.logging.info", "prediction_task.get_prediction_task", "create_feature_engineering_fn", "absl.logging.info", "util.get_num_examples", "bayesian_rnn_eager_main.Dataset", "tensorflow.Variable", "tensorflow.keras.optimizers.Adam", "tensorflow.train.Checkpoint", "tensorflow.train.CheckpointManager", "bayesian_rnn_eager_main.MetricReporter", "bayesian_rnn_eager_main.MetricReporter", "bayesian_rnn_eager_main.MetricReporter", "bayesian_rnn_eager_main.BestExporter", "len", "absl.app.UsageError", "prediction_task.get_prediction_task.data_file_pattern", "create_feature_engineering_fn.", "bayesian_rnn_model.BayesianRNNWithEmbeddings", "bayesian_rnn_model.Rank1BayesianRNNWithEmbeddings", "learning_rate_fn", "absl.logging.info", "tf.train.Checkpoint.restore", "os.path.join", "tensorflow.summary.create_file_writer", "tf.summary.create_file_writer.flush", "absl.logging.info", "tensorflow.summary.create_file_writer", "tf.train.CheckpointManager.save", "feature_engineering_fn.items", "tf.train.CheckpointManager.save", "tensorflow.device", "tf.summary.create_file_writer.as_default", "bayesian_rnn_eager_main.evaluate", "bayesian_rnn_eager_main.main.eval_dataset"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.setup_and_save_flags", "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.get_device_and_data_format", "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.evaluate"], ["", "", "", "def", "main", "(", "argv", ")", ":", "\n", "  ", "if", "len", "(", "argv", ")", ">", "1", ":", "\n", "    ", "raise", "app", ".", "UsageError", "(", "\"Too many command-line arguments.\"", ")", "\n", "", "setup_and_save_flags", "(", ")", "\n", "tf", ".", "enable_v2_behavior", "(", ")", "\n", "tf", ".", "random", ".", "set_seed", "(", "FLAGS", ".", "seed", ")", "\n", "device", ",", "_", "=", "get_device_and_data_format", "(", ")", "\n", "logging", ".", "info", "(", "f\"{FLAGS.logdir}, {FLAGS.model_dir}, {FLAGS.predict_dir}, \"", "\n", "f\"{device}\"", ")", "\n", "\n", "# TODO(dusenberrymw): Expose open-source versions of these functions.", "\n", "task", "=", "prediction_task", ".", "get_prediction_task", "(", "FLAGS", ".", "prediction_task", ")", "\n", "feature_engineering_fn", "=", "create_feature_engineering_fn", "(", "None", ")", "\n", "\n", "logging", ".", "info", "(", "\"Loading data...\"", ")", "\n", "if", "FLAGS", ".", "model", "==", "\"rank1_bayesian_rnn\"", ":", "\n", "    ", "ensemble_size", "=", "FLAGS", ".", "ensemble_size", "\n", "", "else", ":", "\n", "    ", "ensemble_size", "=", "1", "\n", "", "batch_size", "=", "FLAGS", ".", "batch_size", "//", "ensemble_size", "\n", "if", "FLAGS", ".", "eval_batch_size", ":", "\n", "    ", "eval_batch_size", "=", "FLAGS", ".", "eval_batch_size", "//", "ensemble_size", "\n", "", "else", ":", "\n", "    ", "eval_batch_size", "=", "batch_size", "\n", "\n", "", "num_train_examples", "=", "util", ".", "get_num_examples", "(", "\n", "task", ".", "data_file_pattern", "(", "constants", ".", "DatasetType", ".", "TRAIN", ")", ")", "\n", "if", "FLAGS", ".", "eval_train_steps", "==", "-", "1", ":", "\n", "    ", "eval_train_steps", "=", "num_train_examples", "//", "eval_batch_size", "\n", "", "else", ":", "\n", "    ", "eval_train_steps", "=", "FLAGS", ".", "eval_train_steps", "\n", "\n", "", "def", "preprocess", "(", "inputs", ")", ":", "\n", "    ", "\"\"\"Preprocesses examples.\"\"\"", "\n", "inputs", "=", "feature_engineering_fn", "(", "inputs", ")", "\n", "try", ":", "\n", "      ", "labels", "=", "task", ".", "extract_labels", "(", "inputs", ")", "[", "task", ".", "label_key", "]", "\n", "", "except", "ValueError", ":", "\n", "      ", "labels", "=", "None", "\n", "", "if", "ensemble_size", ">", "1", ":", "\n", "# Rank-1 models require the inputs to be tiled along the batch dimension.", "\n", "      ", "new_inputs", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "inputs", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "v", ",", "tf", ".", "SparseTensor", ")", ":", "\n", "          ", "new_inputs", "[", "k", "]", "=", "tf", ".", "sparse", ".", "concat", "(", "\n", "sp_inputs", "=", "[", "v", "]", "*", "ensemble_size", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "          ", "new_inputs", "[", "k", "]", "=", "tf", ".", "concat", "(", "[", "v", "]", "*", "ensemble_size", ",", "axis", "=", "0", ")", "\n", "", "", "inputs", "=", "new_inputs", "\n", "", "return", "inputs", ",", "labels", "\n", "\n", "", "dataset", "=", "Dataset", "(", "\n", "task", "=", "task", ",", "\n", "context_features", "=", "FLAGS", ".", "context_features", ",", "\n", "sequence_features", "=", "FLAGS", ".", "sequence_features", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "eval_batch_size", "=", "eval_batch_size", ",", "\n", "feature_engineering_fn", "=", "preprocess", ",", "\n", "seed", "=", "FLAGS", ".", "seed", ")", "\n", "\n", "if", "FLAGS", ".", "model", "==", "\"bayesian_rnn\"", ":", "\n", "    ", "model", "=", "bayesian_rnn_model", ".", "BayesianRNNWithEmbeddings", "(", "\n", "embedding_config", "=", "task", ".", "embedding_config", "(", ")", ",", "\n", "sequence_features", "=", "FLAGS", ".", "sequence_features", ",", "\n", "context_features", "=", "FLAGS", ".", "context_features", ",", "\n", "rnn_dim", "=", "FLAGS", ".", "rnn_dim", ",", "\n", "num_rnn_layers", "=", "FLAGS", ".", "num_rnn_layers", ",", "\n", "hidden_layer_dim", "=", "FLAGS", ".", "hidden_layer_dim", ",", "\n", "output_layer_dim", "=", "task", ".", "logits_dimension", ",", "\n", "rnn_uncertainty", "=", "FLAGS", ".", "uncertainty_rnn", ",", "\n", "hidden_uncertainty", "=", "FLAGS", ".", "uncertainty_hidden", ",", "\n", "output_uncertainty", "=", "FLAGS", ".", "uncertainty_output", ",", "\n", "bias_uncertainty", "=", "FLAGS", ".", "uncertainty_biases", ",", "\n", "embeddings_uncertainty", "=", "FLAGS", ".", "uncertainty_embeddings", ",", "\n", "prior_stddev", "=", "FLAGS", ".", "prior_stddev", ",", "\n", "l2", "=", "float", "(", "FLAGS", ".", "l2", ")", ",", "\n", "clip_norm", "=", "FLAGS", ".", "clip_norm", ",", "\n", "bagging_time_precision", "=", "FLAGS", ".", "bagging_time_precision", ",", "\n", "bagging_aggregate_older_than", "=", "FLAGS", ".", "bagging_aggregate_older_than", ",", "\n", "embedding_dimension_multiplier", "=", "FLAGS", ".", "embedding_dimension_multiplier", ",", "\n", "dense_feature_name", "=", "FLAGS", ".", "dense_feature_name", ",", "\n", "dense_feature_value", "=", "FLAGS", ".", "dense_feature_value", ",", "\n", "dense_feature_unit", "=", "FLAGS", ".", "dense_feature_unit", ",", "\n", "dense_embedding_dimension", "=", "FLAGS", ".", "dense_embedding_dimension", ",", "\n", "top_n_dense", "=", "FLAGS", ".", "top_n_dense", ",", "\n", "num_ids_per_dense_feature", "=", "FLAGS", ".", "num_ids_per_dense_feature", ",", "\n", "dense_stats_config_path", "=", "FLAGS", ".", "stats_config_path", ")", "\n", "", "else", ":", "# rank1_bayesian_rnn", "\n", "    ", "model", "=", "bayesian_rnn_model", ".", "Rank1BayesianRNNWithEmbeddings", "(", "\n", "embedding_config", "=", "task", ".", "embedding_config", "(", ")", ",", "\n", "sequence_features", "=", "FLAGS", ".", "sequence_features", ",", "\n", "context_features", "=", "FLAGS", ".", "context_features", ",", "\n", "rnn_dim", "=", "FLAGS", ".", "rnn_dim", ",", "\n", "num_rnn_layers", "=", "FLAGS", ".", "num_rnn_layers", ",", "\n", "hidden_layer_dim", "=", "FLAGS", ".", "hidden_layer_dim", ",", "\n", "output_layer_dim", "=", "task", ".", "logits_dimension", ",", "\n", "embeddings_initializer", "=", "FLAGS", ".", "embeddings_initializer", ",", "\n", "embeddings_regularizer", "=", "FLAGS", ".", "embeddings_regularizer", ",", "\n", "alpha_initializer", "=", "FLAGS", ".", "alpha_initializer", ",", "\n", "gamma_initializer", "=", "FLAGS", ".", "gamma_initializer", ",", "\n", "alpha_regularizer", "=", "FLAGS", ".", "alpha_regularizer", ",", "\n", "gamma_regularizer", "=", "FLAGS", ".", "gamma_regularizer", ",", "\n", "use_additive_perturbation", "=", "FLAGS", ".", "use_additive_perturbation", ",", "\n", "ensemble_size", "=", "ensemble_size", ",", "\n", "random_sign_init", "=", "float", "(", "FLAGS", ".", "random_sign_init", ")", ",", "\n", "dropout_rate", "=", "float", "(", "FLAGS", ".", "dropout_rate", ")", ",", "\n", "prior_mean", "=", "float", "(", "FLAGS", ".", "prior_mean", ")", ",", "\n", "prior_stddev", "=", "float", "(", "FLAGS", ".", "prior_stddev", ")", ",", "\n", "l2", "=", "float", "(", "FLAGS", ".", "l2", ")", ",", "\n", "clip_norm", "=", "float", "(", "FLAGS", ".", "clip_norm", ")", ",", "\n", "bagging_time_precision", "=", "FLAGS", ".", "bagging_time_precision", ",", "\n", "bagging_aggregate_older_than", "=", "FLAGS", ".", "bagging_aggregate_older_than", ",", "\n", "embedding_dimension_multiplier", "=", "FLAGS", ".", "embedding_dimension_multiplier", ",", "\n", "dense_feature_name", "=", "FLAGS", ".", "dense_feature_name", ",", "\n", "dense_feature_value", "=", "FLAGS", ".", "dense_feature_value", ",", "\n", "dense_feature_unit", "=", "FLAGS", ".", "dense_feature_unit", ",", "\n", "dense_embedding_dimension", "=", "FLAGS", ".", "dense_embedding_dimension", ",", "\n", "top_n_dense", "=", "FLAGS", ".", "top_n_dense", ",", "\n", "num_ids_per_dense_feature", "=", "FLAGS", ".", "num_ids_per_dense_feature", ",", "\n", "dense_stats_config_path", "=", "FLAGS", ".", "stats_config_path", ")", "\n", "\n", "# TODO(dusenberrymw): Autograph currently can only be used on the inner", "\n", "# `model.bayesian_rnn` and only with `experimental_relax_shapes=True` enabled.", "\n", "# Even with this, it results in a memory leak leading to OOM errors.", "\n", "# model.bayesian_rnn.call = tf.function(model.bayesian_rnn.call,", "\n", "#                                       experimental_relax_shapes=True)", "\n", "", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "name", "=", "\"global_step\"", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "learning_rate_fn", "=", "lambda", "x", ":", "FLAGS", ".", "learning_rate", "\n", "optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "learning_rate_fn", "(", "global_step", ")", ")", "\n", "\n", "checkpoint", "=", "tf", ".", "train", ".", "Checkpoint", "(", "\n", "model", "=", "model", ",", "global_step", "=", "global_step", ",", "optimizer", "=", "optimizer", ")", "\n", "checkpoint_manager", "=", "tf", ".", "train", ".", "CheckpointManager", "(", "\n", "checkpoint", ",", "\n", "directory", "=", "FLAGS", ".", "model_dir", ",", "\n", "max_to_keep", "=", "FLAGS", ".", "max_to_keep", "if", "FLAGS", ".", "max_to_keep", ">", "0", "else", "None", ")", "\n", "if", "checkpoint_manager", ".", "latest_checkpoint", ":", "\n", "    ", "logging", ".", "info", "(", "\"Loading existing model...\"", ")", "\n", "checkpoint", ".", "restore", "(", "checkpoint_manager", ".", "latest_checkpoint", ")", "\n", "", "elif", "FLAGS", ".", "job", "in", "(", "\"train\"", ",", "\"train_and_eval\"", ")", ":", "\n", "    ", "checkpoint_manager", ".", "save", "(", ")", "\n", "\n", "", "train_reporter", "=", "MetricReporter", "(", "\"train\"", ")", "\n", "val_reporter", "=", "MetricReporter", "(", "\"val\"", ")", "\n", "test_reporter", "=", "MetricReporter", "(", "\"test\"", ")", "\n", "exporter", "=", "BestExporter", "(", "checkpoint", ",", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "model_dir", ",", "\"best\"", ")", ",", "\n", "FLAGS", ".", "metric_goal", ")", "\n", "\n", "def", "eval_dataset", "(", "dataset", ",", "name", ",", "steps", "=", "-", "1", ")", ":", "\n", "    ", "\"\"\"Evaluates the model on a dataset.\"\"\"", "\n", "writer", "=", "tf", ".", "summary", ".", "create_file_writer", "(", "f\"{FLAGS.logdir}/{name}_eval\"", ")", "\n", "with", "tf", ".", "device", "(", "device", ")", ",", "writer", ".", "as_default", "(", ")", ":", "\n", "      ", "metrics", "=", "evaluate", "(", "\n", "model", ",", "dataset", "=", "dataset", ",", "task", "=", "task", ",", "global_step", "=", "global_step", ",", "\n", "num_ece_bins", "=", "FLAGS", ".", "num_ece_bins", ",", "num_samples", "=", "FLAGS", ".", "num_eval_samples", ",", "\n", "ensemble_size", "=", "ensemble_size", ",", "name", "=", "name", ",", "steps", "=", "steps", ")", "\n", "", "writer", ".", "flush", "(", ")", "\n", "return", "metrics", "\n", "\n", "", "if", "FLAGS", ".", "job", "in", "(", "\"train\"", ",", "\"train_and_eval\"", ")", ":", "\n", "# TODO(dusenberrymw): Consider converting to a function outside of main.", "\n", "    ", "logging", ".", "info", "(", "\"Training...\"", ")", "\n", "\n", "def", "eval_and_export", "(", ")", ":", "\n", "      ", "train_metrics", "=", "eval_dataset", "(", "\n", "dataset", ".", "train_eval_dataset", ",", "\"train\"", ",", "eval_train_steps", ")", "\n", "train_reporter", ".", "maybe_report_metrics", "(", "train_metrics", ",", "global_step", ")", "\n", "val_metrics", "=", "eval_dataset", "(", "dataset", ".", "val_dataset", ",", "\"val\"", ")", "\n", "val_reporter", ".", "maybe_report_metrics", "(", "val_metrics", ",", "global_step", ")", "\n", "exporter", ".", "maybe_export_model", "(", "val_metrics", "[", "FLAGS", ".", "metric", "]", ")", "\n", "if", "FLAGS", ".", "eval_test_in_loop", ":", "\n", "        ", "test_metrics", "=", "eval_dataset", "(", "dataset", ".", "test_dataset", ",", "\"test\"", ")", "\n", "test_reporter", ".", "maybe_report_metrics", "(", "test_metrics", ",", "global_step", ")", "\n", "\n", "", "", "train_writer", "=", "tf", ".", "summary", ".", "create_file_writer", "(", "f\"{FLAGS.logdir}/train\"", ")", "\n", "with", "tf", ".", "device", "(", "device", ")", ",", "train_writer", ".", "as_default", "(", ")", ":", "\n", "      ", "for", "inputs", ",", "labels", "in", "(", "dataset", ".", "train_dataset", ".", "skip", "(", "\n", "global_step", ")", ".", "take", "(", "FLAGS", ".", "max_steps", "-", "global_step", ")", ")", ":", "\n", "        ", "with", "tf", ".", "GradientTape", "(", ")", "as", "tape", ":", "\n", "          ", "logits", "=", "tf", ".", "reshape", "(", "\n", "[", "model", "(", "inputs", ")", "for", "_", "in", "range", "(", "FLAGS", ".", "num_train_samples", ")", "]", ",", "\n", "[", "FLAGS", ".", "num_train_samples", ",", "ensemble_size", ",", "-", "1", ",", "\n", "task", ".", "logits_dimension", "]", ")", "\n", "if", "task", ".", "logits_dimension", "==", "1", ":", "\n", "            ", "label_dist", "=", "tfp", ".", "distributions", ".", "Bernoulli", "(", "logits", ")", "\n", "", "else", ":", "\n", "            ", "label_dist", "=", "tfp", ".", "distributions", ".", "Multinomial", "(", "1", ",", "logits", ")", "\n", "\n", "", "if", "FLAGS", ".", "nll", "==", "\"mixture\"", ":", "\n", "            ", "nll", "=", "tf", ".", "reduce_mean", "(", "\n", "-", "tf", ".", "reduce_logsumexp", "(", "label_dist", ".", "log_prob", "(", "labels", ")", ",", "axis", "=", "[", "0", ",", "1", "]", ")", "+", "\n", "tf", ".", "math", ".", "log", "(", "float", "(", "FLAGS", ".", "num_train_samples", "*", "ensemble_size", ")", ")", ")", "\n", "", "else", ":", "# average NLL", "\n", "            ", "nll", "=", "-", "tf", ".", "reduce_mean", "(", "label_dist", ".", "log_prob", "(", "labels", ")", ")", "\n", "\n", "", "kl", "=", "sum", "(", "model", ".", "losses", ")", "\n", "kl", "=", "kl", "/", "num_train_examples", "*", "FLAGS", ".", "kl_scale", "*", "tf", ".", "minimum", "(", "\n", "1.", ",", "\n", "tf", ".", "cast", "(", "global_step", "+", "1", ",", "tf", ".", "float32", ")", "/", "FLAGS", ".", "kl_annealing_steps", ")", "\n", "loss", "=", "nll", "+", "kl", "\n", "\n", "", "if", "int", "(", "global_step", ")", "%", "FLAGS", ".", "log_steps", "==", "0", ":", "\n", "          ", "checkpoint_manager", ".", "save", "(", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"loss/nll\"", ",", "nll", ",", "step", "=", "global_step", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"loss/kl\"", ",", "kl", ",", "step", "=", "global_step", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"loss/loss\"", ",", "loss", ",", "step", "=", "global_step", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\n", "\"loss/learning_rate\"", ",", "optimizer", ".", "learning_rate", ",", "step", "=", "global_step", ")", "\n", "logging", ".", "info", "(", "f\"(Train @ step {int(global_step)}/{FLAGS.max_steps}) \"", "\n", "f\"loss: {loss:.4f}, nll: {nll:.4f}, kl: {kl:.4f}\"", ")", "\n", "if", "FLAGS", ".", "job", "==", "\"train_and_eval\"", ":", "\n", "            ", "eval_and_export", "(", ")", "\n", "", "train_writer", ".", "flush", "(", ")", "\n", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "model", ".", "trainable_variables", ")", "\n", "grads", ",", "global_norm", "=", "tf", ".", "clip_by_global_norm", "(", "grads", ",", "FLAGS", ".", "clip_norm", ")", "\n", "if", "int", "(", "global_step", ")", "%", "FLAGS", ".", "log_steps", "==", "0", ":", "\n", "          ", "tf", ".", "summary", ".", "scalar", "(", "\n", "\"loss/grads/global_norm\"", ",", "global_norm", ",", "step", "=", "global_step", ")", "\n", "# Separate learning rate implementation.", "\n", "", "if", "(", "FLAGS", ".", "model", "==", "\"rank1_bayesian_rnn\"", "and", "\n", "FLAGS", ".", "fast_weight_lr_multiplier", "!=", "1.0", ")", ":", "\n", "          ", "grads_and_vars", "=", "[", "]", "\n", "for", "grad", ",", "var", "in", "zip", "(", "grads", ",", "model", ".", "trainable_variables", ")", ":", "\n", "# Apply different learning rate on the fast weight approximate", "\n", "# posterior/prior parameters.", "\n", "            ", "if", "(", "\"kernel\"", "not", "in", "var", ".", "name", "and", "\n", "\"recurrent_kernel\"", "not", "in", "var", ".", "name", "and", "\n", "\"bias\"", "not", "in", "var", ".", "name", ")", ":", "\n", "              ", "grads_and_vars", ".", "append", "(", "\n", "(", "grad", "*", "FLAGS", ".", "fast_weight_lr_multiplier", ",", "var", ")", ")", "\n", "", "else", ":", "\n", "              ", "grads_and_vars", ".", "append", "(", "(", "grad", ",", "var", ")", ")", "\n", "", "", "", "else", ":", "\n", "          ", "grads_and_vars", "=", "list", "(", "zip", "(", "grads", ",", "model", ".", "trainable_variables", ")", ")", "\n", "", "optimizer", ".", "learning_rate", "=", "learning_rate_fn", "(", "global_step", ")", "\n", "optimizer", ".", "apply_gradients", "(", "grads_and_vars", ")", "\n", "global_step", ".", "assign_add", "(", "1", ")", "\n", "del", "grads", ",", "grads_and_vars", ",", "logits", "# reduces memory pressure", "\n", "\n", "", "", "checkpoint_manager", ".", "save", "(", ")", "\n", "if", "FLAGS", ".", "job", "==", "\"train_and_eval\"", ":", "\n", "# Final step evaluation.", "\n", "      ", "eval_and_export", "(", ")", "\n", "\n", "# Best checkpoint evaluation.", "\n", "checkpoint", ".", "restore", "(", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "model_dir", ",", "\"best\"", ",", "\"ckpt\"", ")", ")", "\n", "train_metrics", "=", "eval_dataset", "(", "\n", "dataset", ".", "train_eval_dataset", ",", "\"train-best\"", ",", "eval_train_steps", ")", "\n", "MetricReporter", "(", "\"train-best\"", ")", ".", "maybe_report_metrics", "(", "train_metrics", ",", "\n", "FLAGS", ".", "max_steps", ")", "\n", "val_metrics", "=", "eval_dataset", "(", "dataset", ".", "val_dataset", ",", "\"val-best\"", ")", "\n", "MetricReporter", "(", "\"val-best\"", ")", ".", "maybe_report_metrics", "(", "val_metrics", ",", "\n", "FLAGS", ".", "max_steps", ")", "\n", "if", "FLAGS", ".", "eval_test_in_loop", ":", "\n", "        ", "test_metrics", "=", "eval_dataset", "(", "dataset", ".", "test_dataset", ",", "\"test-best\"", ")", "\n", "MetricReporter", "(", "\"test-best\"", ")", ".", "maybe_report_metrics", "(", "test_metrics", ",", "\n", "FLAGS", ".", "max_steps", ")", "\n", "\n", "", "", "", "elif", "(", "FLAGS", ".", "job", "in", "(", "\"eval_train\"", ",", "\"eval_val\"", ")", "or", "\n", "(", "FLAGS", ".", "job", "==", "\"eval_test\"", "and", "FLAGS", ".", "eval_test_in_loop", ")", ")", ":", "\n", "# TODO(dusenberrymw): Consider converting to a function outside of main.", "\n", "    ", "logging", ".", "info", "(", "\"Evaluating...\"", ")", "\n", "prev_global_step", "=", "-", "1", "\n", "while", "global_step", "<=", "FLAGS", ".", "max_steps", ":", "\n", "      ", "try", ":", "\n", "        ", "checkpoint", ".", "restore", "(", "tf", ".", "train", ".", "latest_checkpoint", "(", "FLAGS", ".", "model_dir", ")", ")", "\n", "", "except", "tf", ".", "errors", ".", "NotFoundError", ":", "\n", "        ", "continue", "\n", "", "if", "int", "(", "global_step", ")", ">", "prev_global_step", ":", "\n", "        ", "if", "FLAGS", ".", "job", "==", "\"eval_train\"", ":", "\n", "          ", "metrics", "=", "eval_dataset", "(", "dataset", ".", "train_eval_dataset", ",", "\"train\"", ",", "\n", "eval_train_steps", ")", "\n", "train_reporter", ".", "maybe_report_metrics", "(", "metrics", ",", "global_step", ")", "\n", "", "elif", "FLAGS", ".", "job", "==", "\"eval_val\"", ":", "\n", "          ", "metrics", "=", "eval_dataset", "(", "dataset", ".", "val_dataset", ",", "\"val\"", ")", "\n", "val_reporter", ".", "maybe_report_metrics", "(", "metrics", ",", "global_step", ")", "\n", "exporter", ".", "maybe_export_model", "(", "metrics", "[", "FLAGS", ".", "metric", "]", ")", "\n", "", "else", ":", "# \"eval_test\"", "\n", "          ", "metrics", "=", "eval_dataset", "(", "dataset", ".", "test_dataset", ",", "\"test\"", ")", "\n", "test_reporter", ".", "maybe_report_metrics", "(", "metrics", ",", "global_step", ")", "\n", "", "prev_global_step", "=", "int", "(", "global_step", ")", "\n", "", "if", "global_step", "==", "FLAGS", ".", "max_steps", ":", "\n", "        ", "break", "\n", "\n", "# Final best checkpoint evaluation.", "\n", "", "", "checkpoint", ".", "restore", "(", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "model_dir", ",", "\"best\"", ",", "\"ckpt\"", ")", ")", "\n", "if", "FLAGS", ".", "job", "==", "\"eval_train\"", ":", "\n", "      ", "metrics", "=", "eval_dataset", "(", "dataset", ".", "train_eval_dataset", ",", "\"train-best\"", ",", "\n", "eval_train_steps", ")", "\n", "MetricReporter", "(", "\"train-best\"", ")", ".", "maybe_report_metrics", "(", "metrics", ",", "\n", "FLAGS", ".", "max_steps", ")", "\n", "", "elif", "FLAGS", ".", "job", "==", "\"eval_val\"", ":", "\n", "      ", "metrics", "=", "eval_dataset", "(", "dataset", ".", "val_dataset", ",", "\"val-best\"", ")", "\n", "MetricReporter", "(", "\"val-best\"", ")", ".", "maybe_report_metrics", "(", "metrics", ",", "FLAGS", ".", "max_steps", ")", "\n", "", "else", ":", "# \"eval_test\"", "\n", "      ", "metrics", "=", "eval_dataset", "(", "dataset", ".", "test_dataset", ",", "\"test-best\"", ")", "\n", "MetricReporter", "(", "\"test-best\"", ")", ".", "maybe_report_metrics", "(", "metrics", ",", "FLAGS", ".", "max_steps", ")", "\n", "\n", "", "", "elif", "FLAGS", ".", "job", "in", "(", "\"predict_train\"", ",", "\"predict_val\"", ",", "\"predict_test\"", ")", ":", "\n", "# TODO(dusenberrymw): Consider converting to a function outside of main.", "\n", "    ", "logging", ".", "info", "(", "\"Predicting...\"", ")", "\n", "checkpoint", ".", "restore", "(", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "model_dir", ",", "\"best\"", ",", "\"ckpt\"", ")", ")", "\n", "pred_fn", "=", "functools", ".", "partial", "(", "\n", "predict", ",", "model", "=", "model", ",", "num_samples", "=", "FLAGS", ".", "num_eval_samples", ",", "\n", "ensemble_size", "=", "ensemble_size", ")", "\n", "with", "tf", ".", "device", "(", "device", ")", ":", "\n", "      ", "if", "FLAGS", ".", "job", "==", "\"predict_train\"", ":", "\n", "        ", "all_logits", ",", "all_labels", "=", "pred_fn", "(", "\n", "dataset", "=", "dataset", ".", "train_eval_dataset", ")", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "predict_dir", ",", "\"train\"", ")", "\n", "", "elif", "FLAGS", ".", "job", "==", "\"predict_val\"", ":", "\n", "        ", "all_logits", ",", "all_labels", "=", "pred_fn", "(", "dataset", "=", "dataset", ".", "val_dataset", ")", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "predict_dir", ",", "\"val\"", ")", "\n", "", "else", ":", "# \"predict_test\"", "\n", "        ", "all_logits", ",", "all_labels", "=", "pred_fn", "(", "dataset", "=", "dataset", ".", "test_dataset", ")", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "predict_dir", ",", "\"test\"", ")", "\n", "", "", "if", "not", "tf", ".", "io", ".", "gfile", ".", "exists", "(", "save_dir", ")", ":", "\n", "      ", "tf", ".", "io", ".", "gfile", ".", "makedirs", "(", "save_dir", ")", "\n", "", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"global_step.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "      ", "f", ".", "write", "(", "f\"{int(global_step)}\"", ")", "\n", "", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"logits.npy\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "      ", "np", ".", "save", "(", "f", ",", "all_logits", ")", "\n", "", "if", "all_labels", "is", "not", "None", ":", "\n", "      ", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"labels.npy\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "np", ".", "save", "(", "f", ",", "all_labels", ")", "\n", "\n", "", "", "", "else", ":", "# \"eval_test\"", "\n", "    ", "logging", ".", "info", "(", "\"Evaluating...\"", ")", "\n", "eval_dataset", "(", "dataset", ".", "test_dataset", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main_test.BayesianRnnEagerMainTest.setUp": [[40, 65], ["super().setUp", "test_input.create_input_data_dir", "tempfile.mkdtemp", "tempfile.mkdtemp", "tempfile.mkdtemp", "os.path.join", "test_input.read_seqex_ascii", "resources.GetRunfilesDir", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main_test.BayesianRnnEagerMainTest.setUp"], ["  ", "def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "setUp", "(", ")", "\n", "seqex_list", "=", "[", "\n", "test_input", ".", "read_seqex_ascii", "(", "\"example-0.ascii\"", ",", "\n", "os", ".", "path", ".", "join", "(", "TESTDATA_DIR", ",", "\"seqex\"", ")", ")", "\n", "]", "\n", "input_data_dir", "=", "test_input", ".", "create_input_data_dir", "(", "\n", "seqex_list", ",", "\"inpatient_at_24hrs\"", ",", "TESTDATA_DIR", ",", "sharded", "=", "True", ")", "\n", "FLAGS", ".", "logdir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "FLAGS", ".", "model_dir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "FLAGS", ".", "predict_dir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "FLAGS", ".", "input_dir", "=", "input_data_dir", "\n", "FLAGS", ".", "stats_config_path", "=", "os", ".", "path", ".", "join", "(", "\n", "resources", ".", "GetRunfilesDir", "(", ")", ",", "TESTDATA_DIR", ",", "\"VOCAB/dense_stats_config\"", ")", "\n", "FLAGS", ".", "batch_size", "=", "6", "\n", "FLAGS", ".", "ensemble_size", "=", "3", "\n", "FLAGS", ".", "rnn_dim", "=", "32", "\n", "FLAGS", ".", "log_steps", "=", "2", "\n", "FLAGS", ".", "max_steps", "=", "5", "\n", "FLAGS", ".", "eval_train_steps", "=", "2", "\n", "FLAGS", ".", "uncertainty_embeddings", "=", "True", "\n", "FLAGS", ".", "uncertainty_rnn", "=", "True", "\n", "FLAGS", ".", "uncertainty_hidden", "=", "True", "\n", "FLAGS", ".", "uncertainty_output", "=", "True", "\n", "FLAGS", ".", "uncertainty_biases", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main_test.BayesianRnnEagerMainTest.testBayesianRNNEagerMain": [[66, 74], ["absl.testing.parameterized.parameters", "bayesian_rnn_eager_main.main", "bayesian_rnn_eager_main_test.BayesianRnnEagerMainTest.assertNotEmpty", "bayesian_rnn_eager_main_test.BayesianRnnEagerMainTest.assertNotEmpty", "bayesian_rnn_eager_main_test.BayesianRnnEagerMainTest.assertEmpty", "os.listdir", "os.listdir", "os.listdir"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.experimental_main.main"], ["", "@", "parameterized", ".", "parameters", "(", "[", "\"bayesian_rnn\"", ",", "\"rank1_bayesian_rnn\"", "]", ")", "\n", "@", "flagsaver", ".", "flagsaver", "\n", "def", "testBayesianRNNEagerMain", "(", "self", ",", "model", ")", ":", "\n", "    ", "FLAGS", ".", "model", "=", "model", "\n", "bayesian_rnn_eager_main", ".", "main", "(", "[", "]", ")", "\n", "self", ".", "assertNotEmpty", "(", "os", ".", "listdir", "(", "FLAGS", ".", "logdir", ")", ")", "\n", "self", ".", "assertNotEmpty", "(", "os", ".", "listdir", "(", "FLAGS", ".", "model_dir", ")", ")", "\n", "self", ".", "assertEmpty", "(", "os", ".", "listdir", "(", "FLAGS", ".", "predict_dir", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main_test.BayesianRnnEagerMainTest.testBayesianRNNEagerMainTrainEvalPredict": [[75, 93], ["absl.testing.parameterized.parameters", "bayesian_rnn_eager_main.main", "bayesian_rnn_eager_main_test.BayesianRnnEagerMainTest.assertNotEmpty", "bayesian_rnn_eager_main_test.BayesianRnnEagerMainTest.assertNotEmpty", "bayesian_rnn_eager_main_test.BayesianRnnEagerMainTest.assertEmpty", "tempfile.mkdtemp", "bayesian_rnn_eager_main.main", "bayesian_rnn_eager_main_test.BayesianRnnEagerMainTest.assertNotEmpty", "bayesian_rnn_eager_main.main", "bayesian_rnn_eager_main_test.BayesianRnnEagerMainTest.assertNotEmpty", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "os.listdir"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.experimental_main.main", "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.experimental_main.main", "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.experimental_main.main"], ["", "@", "parameterized", ".", "parameters", "(", "[", "\"bayesian_rnn\"", ",", "\"rank1_bayesian_rnn\"", "]", ")", "\n", "@", "flagsaver", ".", "flagsaver", "\n", "def", "testBayesianRNNEagerMainTrainEvalPredict", "(", "self", ",", "model", ")", ":", "\n", "    ", "FLAGS", ".", "model", "=", "model", "\n", "FLAGS", ".", "job", "=", "\"train\"", "\n", "bayesian_rnn_eager_main", ".", "main", "(", "[", "]", ")", "\n", "self", ".", "assertNotEmpty", "(", "os", ".", "listdir", "(", "FLAGS", ".", "logdir", ")", ")", "\n", "self", ".", "assertNotEmpty", "(", "os", ".", "listdir", "(", "FLAGS", ".", "model_dir", ")", ")", "\n", "self", ".", "assertEmpty", "(", "os", ".", "listdir", "(", "FLAGS", ".", "predict_dir", ")", ")", "\n", "\n", "FLAGS", ".", "job", "=", "\"eval_val\"", "\n", "FLAGS", ".", "logdir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "bayesian_rnn_eager_main", ".", "main", "(", "[", "]", ")", "\n", "self", ".", "assertNotEmpty", "(", "os", ".", "listdir", "(", "FLAGS", ".", "logdir", ")", ")", "\n", "\n", "FLAGS", ".", "job", "=", "\"predict_val\"", "\n", "bayesian_rnn_eager_main", ".", "main", "(", "[", "]", ")", "\n", "self", ".", "assertNotEmpty", "(", "os", ".", "listdir", "(", "FLAGS", ".", "predict_dir", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main_test.BayesianRnnEagerMainTest.testBayesianRNNEagerMainDeterministic": [[94, 106], ["bayesian_rnn_eager_main.main", "bayesian_rnn_eager_main_test.BayesianRnnEagerMainTest.assertNotEmpty", "bayesian_rnn_eager_main_test.BayesianRnnEagerMainTest.assertNotEmpty", "bayesian_rnn_eager_main_test.BayesianRnnEagerMainTest.assertEmpty", "os.listdir", "os.listdir", "os.listdir"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.experimental_main.main"], ["", "@", "flagsaver", ".", "flagsaver", "\n", "def", "testBayesianRNNEagerMainDeterministic", "(", "self", ")", ":", "\n", "    ", "FLAGS", ".", "uncertainty_embeddings", "=", "False", "\n", "FLAGS", ".", "uncertainty_rnn", "=", "False", "\n", "FLAGS", ".", "uncertainty_hidden", "=", "False", "\n", "FLAGS", ".", "uncertainty_output", "=", "False", "\n", "FLAGS", ".", "uncertainty_biases", "=", "False", "\n", "\n", "bayesian_rnn_eager_main", ".", "main", "(", "[", "]", ")", "\n", "self", ".", "assertNotEmpty", "(", "os", ".", "listdir", "(", "FLAGS", ".", "logdir", ")", ")", "\n", "self", ".", "assertNotEmpty", "(", "os", ".", "listdir", "(", "FLAGS", ".", "model_dir", ")", ")", "\n", "self", ".", "assertEmpty", "(", "os", ".", "listdir", "(", "FLAGS", ".", "predict_dir", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_model.LSTMCellReparameterizationGradClipped.__init__": [[64, 67], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__"], ["def", "__init__", "(", "self", ",", "clip_norm", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "self", ".", "clip_norm", "=", "clip_norm", "\n", "super", "(", "LSTMCellReparameterizationGradClipped", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_model.LSTMCellReparameterizationGradClipped.call": [[68, 74], ["super().call", "tensorflow.name_scope", "bayesian_rnn_model._clip_gradient", "bayesian_rnn_model._clip_gradient"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.GraphConvolutionalTransformer.call", "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_model._clip_gradient", "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_model._clip_gradient"], ["", "def", "call", "(", "self", ",", "inputs", ",", "states", ",", "training", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"clip_gradient\"", ")", ":", "\n", "      ", "inputs", "=", "_clip_gradient", "(", "inputs", ",", "self", ".", "clip_norm", ")", "\n", "states", "=", "[", "_clip_gradient", "(", "x", ",", "self", ".", "clip_norm", ")", "for", "x", "in", "states", "]", "\n", "", "return", "super", "(", "LSTMCellReparameterizationGradClipped", ",", "self", ")", ".", "call", "(", "\n", "inputs", ",", "states", ",", "training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_model.BayesianRNN.__init__": [[79, 172], ["super().__init__", "range", "tensorflow.keras.layers.RNN", "cells.append", "edward2.layers.DenseReparameterization", "tensorflow.keras.layers.Dense", "edward2.regularizers.normal_kl_divergence", "bayesian_rnn_model.LSTMCellReparameterizationGradClipped", "tensorflow.keras.layers.LSTMCell", "edward2.layers.DenseReparameterization", "tensorflow.keras.layers.Dense", "bayesian_rnn_model.BayesianRNN.__init__.make_regularizer"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__"], ["def", "__init__", "(", "self", ",", "\n", "rnn_dim", ",", "\n", "num_rnn_layers", ",", "\n", "hidden_layer_dim", ",", "\n", "output_layer_dim", ",", "\n", "rnn_uncertainty", ",", "\n", "hidden_uncertainty", ",", "\n", "output_uncertainty", ",", "\n", "bias_uncertainty", ",", "\n", "prior_stddev", ",", "\n", "l2", ",", "\n", "clip_norm", "=", "1.0", ",", "\n", "return_sequences", "=", "False", ")", ":", "\n", "    ", "\"\"\"Initializes the model.\n\n    Args:\n      rnn_dim: RNN cell output dimensionality.\n      num_rnn_layers: Number of stacked RNN cells.\n      hidden_layer_dim: Hidden layer output dimensionality.\n      output_layer_dim: Output layer output dimensionality.\n      rnn_uncertainty: Whether or not to use a Bayesian RNN layer.\n      hidden_uncertainty: Whether or not to use a Bayesian hidden dense layer.\n      output_uncertainty: Whether or not to use a Bayesian output dense layer.\n      bias_uncertainty: Whether or not to use Bayesian bias terms in all of the\n        Bayesian layers.\n      prior_stddev: The standard deviation for the Normal prior.\n      l2: Amount of L2 regularization to apply to the deterministic weights.\n      clip_norm: Gradient clipping norm value for per-time step clipping within\n        the LSTM cell, and for clipping of all aggregated gradients.\n      return_sequences: Whether or not to return outputs at each time step from\n        the LSTM, rather than just the final time step.\n    \"\"\"", "\n", "super", "(", "BayesianRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_layer_dim", "=", "hidden_layer_dim", "\n", "\n", "def", "make_regularizer", "(", "uncertainty", "=", "True", ")", ":", "\n", "      ", "if", "uncertainty", ":", "\n", "        ", "return", "ed", ".", "regularizers", ".", "normal_kl_divergence", "(", "stddev", "=", "prior_stddev", ")", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "\n", "", "", "bias_initializer", "=", "\"trainable_normal\"", "if", "bias_uncertainty", "else", "\"zeros\"", "\n", "\n", "# 1. RNN layer.", "\n", "cells", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "num_rnn_layers", ")", ":", "\n", "      ", "if", "rnn_uncertainty", ":", "\n", "        ", "lstm_cell", "=", "LSTMCellReparameterizationGradClipped", "(", "\n", "clip_norm", ",", "\n", "rnn_dim", ",", "\n", "kernel_regularizer", "=", "make_regularizer", "(", ")", ",", "\n", "recurrent_regularizer", "=", "make_regularizer", "(", ")", ",", "\n", "bias_initializer", "=", "bias_initializer", ",", "\n", "bias_regularizer", "=", "make_regularizer", "(", "bias_uncertainty", ")", ")", "\n", "", "else", ":", "\n", "        ", "lstm_cell", "=", "tf", ".", "keras", ".", "layers", ".", "LSTMCell", "(", "\n", "rnn_dim", ",", "\n", "kernel_regularizer", "=", "tf", ".", "keras", ".", "regularizers", ".", "l2", "(", "l2", ")", ",", "\n", "recurrent_regularizer", "=", "tf", ".", "keras", ".", "regularizers", ".", "l2", "(", "l2", ")", ",", "\n", "bias_regularizer", "=", "tf", ".", "keras", ".", "regularizers", ".", "l2", "(", "l2", ")", ")", "\n", "", "cells", ".", "append", "(", "lstm_cell", ")", "\n", "", "self", ".", "rnn_layer", "=", "tf", ".", "keras", ".", "layers", ".", "RNN", "(", "cells", ",", "return_sequences", "=", "False", ")", "\n", "\n", "# 2. Affine layer on combination of RNN output and context features.", "\n", "if", "self", ".", "hidden_layer_dim", ">", "0", ":", "\n", "      ", "if", "hidden_uncertainty", ":", "\n", "        ", "self", ".", "hidden_layer", "=", "ed", ".", "layers", ".", "DenseReparameterization", "(", "\n", "self", ".", "hidden_layer_dim", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu6", ",", "\n", "kernel_initializer", "=", "\"trainable_he_normal\"", ",", "\n", "kernel_regularizer", "=", "make_regularizer", "(", ")", ",", "\n", "bias_initializer", "=", "bias_initializer", ",", "\n", "bias_regularizer", "=", "make_regularizer", "(", "bias_uncertainty", ")", ")", "\n", "", "else", ":", "\n", "        ", "self", ".", "hidden_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "self", ".", "hidden_layer_dim", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu6", ",", "\n", "kernel_regularizer", "=", "tf", ".", "keras", ".", "regularizers", ".", "l2", "(", "l2", ")", ",", "\n", "bias_regularizer", "=", "tf", ".", "keras", ".", "regularizers", ".", "l2", "(", "l2", ")", ")", "\n", "\n", "# 3. Output layer.", "\n", "", "", "self", ".", "output_uncertainty", "=", "output_uncertainty", "\n", "if", "self", ".", "output_uncertainty", ":", "\n", "      ", "self", ".", "output_layer", "=", "ed", ".", "layers", ".", "DenseReparameterization", "(", "\n", "output_layer_dim", ",", "\n", "kernel_regularizer", "=", "make_regularizer", "(", ")", ",", "\n", "bias_initializer", "=", "bias_initializer", ",", "\n", "bias_regularizer", "=", "make_regularizer", "(", "bias_uncertainty", ")", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "output_layer_dim", ",", "\n", "kernel_regularizer", "=", "tf", ".", "keras", ".", "regularizers", ".", "l2", "(", "l2", ")", ",", "\n", "bias_regularizer", "=", "tf", ".", "keras", ".", "regularizers", ".", "l2", "(", "l2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_model.BayesianRNN.call": [[173, 206], ["tensorflow.sequence_mask", "tensorflow.reshape", "bayesian_rnn_model.BayesianRNN.rnn_layer", "bayesian_rnn_model.BayesianRNN.output_layer", "tensorflow.concat", "tensorflow.concat", "bayesian_rnn_model.BayesianRNN.hidden_layer", "tensorflow.shape", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat"], ["", "", "def", "call", "(", "self", ",", "sequence_embeddings", ",", "context_embeddings", ",", "sequence_length", ")", ":", "\n", "    ", "\"\"\"Runs the model.\n\n    Args:\n      sequence_embeddings: Tensor of shape [batch_size, bagged_seq_length,\n        sum(embed_dim)]. The embeddings for all categorical sequence features,\n        concatenated along the embedding axis. If dense features are used, the\n        embeddings or normalized values are also concatenated.\n      context_embeddings: Tensor of shape [batch_size, sum(embed_dim)]. The\n        concatenated embeddings for all context features. Includes the patient's\n        age if birthdate and prediction time are available in inputs.\n      sequence_length: Tensor of shape [batch]. The lengths of the sequences\n        after bagging.\n\n    Returns:\n      A Tensor of logits of shape (batch_size, output_layer_dim).\n    \"\"\"", "\n", "mask", "=", "tf", ".", "sequence_mask", "(", "sequence_length", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "sequence_embeddings", ")", "[", "1", "]", ",", "\n", "dtype", "=", "sequence_embeddings", ".", "dtype", ")", "\n", "mask", "=", "tf", ".", "reshape", "(", "mask", ",", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "shape", "(", "sequence_embeddings", ")", "[", ":", "-", "1", "]", ",", "[", "1", "]", "]", ",", "axis", "=", "-", "1", ")", ")", "\n", "last_output", "=", "self", ".", "rnn_layer", "(", "sequence_embeddings", ",", "mask", "=", "mask", ")", "\n", "\n", "if", "context_embeddings", "is", "not", "None", ":", "\n", "      ", "combined_features", "=", "tf", ".", "concat", "(", "[", "last_output", ",", "context_embeddings", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "      ", "combined_features", "=", "last_output", "\n", "\n", "", "if", "self", ".", "hidden_layer_dim", ">", "0", ":", "\n", "      ", "combined_features", "=", "self", ".", "hidden_layer", "(", "combined_features", ")", "\n", "\n", "", "return", "self", ".", "output_layer", "(", "combined_features", ")", "# shape (n, d)", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_model.BayesianRNNWithEmbeddings.__init__": [[216, 328], ["super().__init__", "embedding.SequenceEmbedding", "bayesian_rnn_model.BayesianRNN"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__"], ["def", "__init__", "(", "self", ",", "\n", "embedding_config", ",", "\n", "sequence_features", ",", "\n", "context_features", ",", "\n", "rnn_dim", ",", "\n", "num_rnn_layers", ",", "\n", "hidden_layer_dim", ",", "\n", "output_layer_dim", ",", "\n", "rnn_uncertainty", ",", "\n", "hidden_uncertainty", ",", "\n", "output_uncertainty", ",", "\n", "bias_uncertainty", ",", "\n", "embeddings_uncertainty", ",", "\n", "prior_stddev", ",", "\n", "l2", ",", "\n", "clip_norm", "=", "1.0", ",", "\n", "return_sequences", "=", "False", ",", "\n", "bagging_time_precision", "=", "86400", ",", "\n", "bagging_aggregate_older_than", "=", "-", "1", ",", "\n", "embedding_dimension_multiplier", "=", "1.0", ",", "\n", "dense_feature_name", "=", "None", ",", "\n", "dense_feature_value", "=", "None", ",", "\n", "dense_feature_unit", "=", "None", ",", "\n", "dense_embedding_dimension", "=", "128", ",", "\n", "top_n_dense", "=", "10000", ",", "\n", "num_ids_per_dense_feature", "=", "5", ",", "\n", "dense_stats_config_path", "=", "\"\"", ")", ":", "\n", "    ", "\"\"\"Initializes the model.\n\n    Aside from `embeddings_uncertainty`, all parameters come from\n    `embedding.SequenceEmbedding` and `BayesianRNN`.\n\n    Args:\n      embedding_config: An embedding config proto.\n      sequence_features: List of the sequential features to process.\n      context_features: List of the context (per-sequence) features to process.\n      rnn_dim: RNN cell output dimensionality.\n      num_rnn_layers: Number of stacked RNN cells.\n      hidden_layer_dim: Hidden layer output dimensionality.\n      output_layer_dim: Output layer output dimensionality.\n      rnn_uncertainty: Whether or not to use a Bayesian RNN layer.\n      hidden_uncertainty: Whether or not to use a Bayesian hidden dense layer.\n      output_uncertainty: Whether or not to use a Bayesian output dense layer.\n      bias_uncertainty: Whether or not to use Bayesian bias terms in all of the\n        Bayesian layers.\n      embeddings_uncertainty: Whether or not to use a Bayesian embedding layer.\n      prior_stddev: The standard deviation for the Normal prior.\n      l2: Amount of L2 regularization to apply to the deterministic weights.\n      clip_norm: Gradient clipping norm value for per-time step clipping within\n        the LSTM cell, and for clipping of all aggregated gradients.\n      return_sequences: Whether or not to return outputs at each time step from\n        the LSTM, rather than just the final time step.\n      bagging_time_precision: Precision for bagging in seconds. For example,\n        86400 represents day-level bagging.\n      bagging_aggregate_older_than: Events older than this (in seconds) will all\n        be aggregated into the same bag. `-1` indicates no aggregation.\n      embedding_dimension_multiplier: Multiplier for the default embedding\n        dimension specified in embedding_config. Applied to all categorical\n        features.\n      dense_feature_name: A feature in sequence_features representing the names\n        of all continuous inputs. Used for dense embedding or normalization.\n      dense_feature_value: A feature in sequence_features representing the\n        values of all continuous inputs. Used for dense embedding or\n        normalization.\n      dense_feature_unit: A feature in sequence_features representing the units\n        of all continuous input values. Used for dense embedding or\n        normalization.\n      dense_embedding_dimension: If embed_dense, size of embeddings to use.\n      top_n_dense: Number of top dense features (by frequency) to retain for\n        model input.\n      num_ids_per_dense_feature: If embed_dense, number of embedding IDs per\n        feature.\n      dense_stats_config_path: Path to stats config for dense features.\n    \"\"\"", "\n", "super", "(", "BayesianRNNWithEmbeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "embeddings_uncertainty", ":", "\n", "      ", "embeddings_initializer", "=", "\"trainable_normal\"", "\n", "embeddings_regularizer", "=", "\"normal_kl_divergence\"", "\n", "", "else", ":", "\n", "      ", "embeddings_initializer", "=", "\"uniform\"", "\n", "embeddings_regularizer", "=", "None", "\n", "\n", "", "self", ".", "embedding_layer", "=", "embedding", ".", "SequenceEmbedding", "(", "\n", "embedding_config", "=", "embedding_config", ",", "\n", "sequence_features", "=", "sequence_features", ",", "\n", "context_features", "=", "context_features", ",", "\n", "bagging_time_precision", "=", "bagging_time_precision", ",", "\n", "bagging_aggregate_older_than", "=", "bagging_aggregate_older_than", ",", "\n", "embedding_dimension_multiplier", "=", "embedding_dimension_multiplier", ",", "\n", "dense_feature_name", "=", "dense_feature_name", ",", "\n", "dense_feature_value", "=", "dense_feature_value", ",", "\n", "dense_feature_unit", "=", "dense_feature_unit", ",", "\n", "dense_embedding_dimension", "=", "dense_embedding_dimension", ",", "\n", "top_n_dense", "=", "top_n_dense", ",", "\n", "num_ids_per_dense_feature", "=", "num_ids_per_dense_feature", ",", "\n", "dense_stats_config_path", "=", "dense_stats_config_path", ",", "\n", "embeddings_initializer", "=", "embeddings_initializer", ",", "\n", "embeddings_regularizer", "=", "embeddings_regularizer", ")", "\n", "self", ".", "bayesian_rnn", "=", "BayesianRNN", "(", "\n", "rnn_dim", "=", "rnn_dim", ",", "\n", "num_rnn_layers", "=", "num_rnn_layers", ",", "\n", "hidden_layer_dim", "=", "hidden_layer_dim", ",", "\n", "output_layer_dim", "=", "output_layer_dim", ",", "\n", "rnn_uncertainty", "=", "rnn_uncertainty", ",", "\n", "hidden_uncertainty", "=", "hidden_uncertainty", ",", "\n", "output_uncertainty", "=", "output_uncertainty", ",", "\n", "bias_uncertainty", "=", "bias_uncertainty", ",", "\n", "prior_stddev", "=", "prior_stddev", ",", "\n", "l2", "=", "l2", ",", "\n", "clip_norm", "=", "clip_norm", ",", "\n", "return_sequences", "=", "return_sequences", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_model.BayesianRNNWithEmbeddings.call": [[329, 347], ["bayesian_rnn_model.BayesianRNNWithEmbeddings.embedding_layer", "bayesian_rnn_model.BayesianRNNWithEmbeddings.bayesian_rnn"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "    ", "\"\"\"Runs the model.\n\n    Args:\n      inputs: The features to process. A dict of feature names to Tensors or\n        SparseTensors. At minimum, must include the features specified in\n        self.sequence_features and self.context_features, as well as deltaTime\n        and sequenceLength.\n\n    Returns:\n      A Tensor of logits of shape (batch_size, output_layer_dim).\n    \"\"\"", "\n", "(", "sequence_embeddings", ",", "context_embeddings", ",", "\n", "return_dict", ")", "=", "self", ".", "embedding_layer", "(", "inputs", ")", "\n", "sequence_length", "=", "return_dict", "[", "constants", ".", "C_SEQUENCE_LENGTH_KEY", "]", "\n", "logits", "=", "self", ".", "bayesian_rnn", "(", "sequence_embeddings", ",", "context_embeddings", ",", "\n", "sequence_length", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_model.Rank1BayesianRNN.__init__": [[352, 467], ["super().__init__", "range", "tensorflow.keras.layers.RNN", "edward2.experimental.rank1_bnns.rank1_bnn_layers.DenseRank1", "edward2.experimental.rank1_bnns.rank1_bnn_layers.LSTMCellRank1", "cells.append", "edward2.experimental.rank1_bnns.rank1_bnn_layers.DenseRank1", "edward2.experimental.rank1_bnns.utils.make_initializer", "edward2.experimental.rank1_bnns.utils.make_initializer", "edward2.experimental.rank1_bnns.utils.make_regularizer", "edward2.experimental.rank1_bnns.utils.make_regularizer", "tensorflow.keras.regularizers.l2", "tensorflow.keras.regularizers.l2", "edward2.experimental.rank1_bnns.utils.make_initializer", "edward2.experimental.rank1_bnns.utils.make_initializer", "edward2.experimental.rank1_bnns.utils.make_initializer", "edward2.experimental.rank1_bnns.utils.make_initializer", "edward2.experimental.rank1_bnns.utils.make_regularizer", "edward2.experimental.rank1_bnns.utils.make_regularizer", "edward2.experimental.rank1_bnns.utils.make_regularizer", "edward2.experimental.rank1_bnns.utils.make_regularizer", "tensorflow.keras.regularizers.l2", "tensorflow.keras.regularizers.l2", "tensorflow.keras.regularizers.l2", "edward2.experimental.rank1_bnns.utils.make_initializer", "edward2.experimental.rank1_bnns.utils.make_initializer", "edward2.experimental.rank1_bnns.utils.make_regularizer", "edward2.experimental.rank1_bnns.utils.make_regularizer", "tensorflow.keras.regularizers.l2", "tensorflow.keras.regularizers.l2"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__"], ["def", "__init__", "(", "self", ",", "\n", "rnn_dim", ",", "\n", "num_rnn_layers", ",", "\n", "hidden_layer_dim", ",", "\n", "output_layer_dim", ",", "\n", "alpha_initializer", ",", "\n", "gamma_initializer", ",", "\n", "alpha_regularizer", ",", "\n", "gamma_regularizer", ",", "\n", "use_additive_perturbation", ",", "\n", "ensemble_size", ",", "\n", "random_sign_init", ",", "\n", "dropout_rate", ",", "\n", "prior_mean", ",", "\n", "prior_stddev", ",", "\n", "l2", ",", "\n", "clip_norm", "=", "1.0", ",", "\n", "return_sequences", "=", "False", ")", ":", "\n", "    ", "\"\"\"Initializes the model.\n\n    Args:\n      rnn_dim: RNN cell output dimensionality.\n      num_rnn_layers: Number of stacked RNN cells.\n      hidden_layer_dim: Hidden layer output dimensionality.\n      output_layer_dim: Output layer output dimensionality.\n      alpha_initializer: The initializer for the alpha parameters.\n      gamma_initializer: The initializer for the gamma parameters.\n      alpha_regularizer: The regularizer for the alpha parameters.\n      gamma_regularizer: The regularizer for the gamma parameters.\n      use_additive_perturbation: Whether or not to use additive perturbations\n        instead of multiplicative perturbations.\n      ensemble_size: Number of ensemble members.\n      random_sign_init: Value used to initialize trainable deterministic\n        initializers, as applicable. Values greater than zero result in\n        initialization to a random sign vector, where random_sign_init is the\n        probability of a 1 value. Values less than zero result in initialization\n        from a Gaussian with mean 1 and standard deviation equal to\n        -random_sign_init.\n      dropout_rate: Dropout rate.\n      prior_mean: Mean of the prior.\n      prior_stddev: Standard deviation of the prior.\n      l2: Amount of L2 regularization to apply to the deterministic weights.\n      clip_norm: Gradient clipping norm value for per-time step clipping within\n        the LSTM cell, and for clipping of all aggregated gradients.\n      return_sequences: Whether or not to return outputs at each time step from\n        the LSTM, rather than just the final time step.\n    \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_layer_dim", "=", "hidden_layer_dim", "\n", "\n", "# 1. RNN layer.", "\n", "cells", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "num_rnn_layers", ")", ":", "\n", "# TODO(dusenberrymw): Determine if a grad-clipped version is needed.", "\n", "      ", "lstm_cell", "=", "rank1_bnn_layers", ".", "LSTMCellRank1", "(", "\n", "rnn_dim", ",", "\n", "alpha_initializer", "=", "rank1_utils", ".", "make_initializer", "(", "\n", "alpha_initializer", ",", "random_sign_init", ",", "dropout_rate", ")", ",", "\n", "gamma_initializer", "=", "rank1_utils", ".", "make_initializer", "(", "\n", "gamma_initializer", ",", "random_sign_init", ",", "dropout_rate", ")", ",", "\n", "recurrent_alpha_initializer", "=", "rank1_utils", ".", "make_initializer", "(", "\n", "alpha_initializer", ",", "random_sign_init", ",", "dropout_rate", ")", ",", "\n", "recurrent_gamma_initializer", "=", "rank1_utils", ".", "make_initializer", "(", "\n", "gamma_initializer", ",", "random_sign_init", ",", "dropout_rate", ")", ",", "\n", "alpha_regularizer", "=", "rank1_utils", ".", "make_regularizer", "(", "\n", "alpha_regularizer", ",", "prior_mean", ",", "prior_stddev", ")", ",", "\n", "gamma_regularizer", "=", "rank1_utils", ".", "make_regularizer", "(", "\n", "gamma_regularizer", ",", "prior_mean", ",", "prior_stddev", ")", ",", "\n", "recurrent_alpha_regularizer", "=", "rank1_utils", ".", "make_regularizer", "(", "\n", "alpha_regularizer", ",", "prior_mean", ",", "prior_stddev", ")", ",", "\n", "recurrent_gamma_regularizer", "=", "rank1_utils", ".", "make_regularizer", "(", "\n", "gamma_regularizer", ",", "prior_mean", ",", "prior_stddev", ")", ",", "\n", "kernel_regularizer", "=", "tf", ".", "keras", ".", "regularizers", ".", "l2", "(", "l2", ")", ",", "\n", "recurrent_regularizer", "=", "tf", ".", "keras", ".", "regularizers", ".", "l2", "(", "l2", ")", ",", "\n", "bias_regularizer", "=", "tf", ".", "keras", ".", "regularizers", ".", "l2", "(", "l2", ")", ",", "\n", "use_additive_perturbation", "=", "use_additive_perturbation", ",", "\n", "ensemble_size", "=", "ensemble_size", ")", "\n", "cells", ".", "append", "(", "lstm_cell", ")", "\n", "", "self", ".", "rnn_layer", "=", "tf", ".", "keras", ".", "layers", ".", "RNN", "(", "cells", ",", "return_sequences", "=", "False", ")", "\n", "\n", "# 2. Affine layer on combination of RNN output and context features.", "\n", "if", "self", ".", "hidden_layer_dim", ">", "0", ":", "\n", "      ", "self", ".", "hidden_layer", "=", "rank1_bnn_layers", ".", "DenseRank1", "(", "\n", "self", ".", "hidden_layer_dim", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu6", ",", "\n", "alpha_initializer", "=", "rank1_utils", ".", "make_initializer", "(", "\n", "alpha_initializer", ",", "random_sign_init", ",", "dropout_rate", ")", ",", "\n", "gamma_initializer", "=", "rank1_utils", ".", "make_initializer", "(", "\n", "gamma_initializer", ",", "random_sign_init", ",", "dropout_rate", ")", ",", "\n", "kernel_initializer", "=", "\"he_normal\"", ",", "\n", "alpha_regularizer", "=", "rank1_utils", ".", "make_regularizer", "(", "\n", "alpha_regularizer", ",", "prior_mean", ",", "prior_stddev", ")", ",", "\n", "gamma_regularizer", "=", "rank1_utils", ".", "make_regularizer", "(", "\n", "gamma_regularizer", ",", "prior_mean", ",", "prior_stddev", ")", ",", "\n", "kernel_regularizer", "=", "tf", ".", "keras", ".", "regularizers", ".", "l2", "(", "l2", ")", ",", "\n", "bias_regularizer", "=", "tf", ".", "keras", ".", "regularizers", ".", "l2", "(", "l2", ")", ",", "\n", "use_additive_perturbation", "=", "use_additive_perturbation", ",", "\n", "ensemble_size", "=", "ensemble_size", ")", "\n", "\n", "# 3. Output affine layer.", "\n", "", "self", ".", "output_layer", "=", "rank1_bnn_layers", ".", "DenseRank1", "(", "\n", "output_layer_dim", ",", "\n", "alpha_initializer", "=", "rank1_utils", ".", "make_initializer", "(", "\n", "alpha_initializer", ",", "random_sign_init", ",", "dropout_rate", ")", ",", "\n", "gamma_initializer", "=", "rank1_utils", ".", "make_initializer", "(", "\n", "gamma_initializer", ",", "random_sign_init", ",", "dropout_rate", ")", ",", "\n", "kernel_initializer", "=", "\"he_normal\"", ",", "\n", "alpha_regularizer", "=", "rank1_utils", ".", "make_regularizer", "(", "\n", "alpha_regularizer", ",", "prior_mean", ",", "prior_stddev", ")", ",", "\n", "gamma_regularizer", "=", "rank1_utils", ".", "make_regularizer", "(", "\n", "gamma_regularizer", ",", "prior_mean", ",", "prior_stddev", ")", ",", "\n", "kernel_regularizer", "=", "tf", ".", "keras", ".", "regularizers", ".", "l2", "(", "l2", ")", ",", "\n", "bias_regularizer", "=", "tf", ".", "keras", ".", "regularizers", ".", "l2", "(", "l2", ")", ",", "\n", "use_additive_perturbation", "=", "use_additive_perturbation", ",", "\n", "ensemble_size", "=", "ensemble_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_model.Rank1BayesianRNN.call": [[468, 501], ["tensorflow.sequence_mask", "tensorflow.reshape", "bayesian_rnn_model.Rank1BayesianRNN.rnn_layer", "bayesian_rnn_model.Rank1BayesianRNN.output_layer", "tensorflow.concat", "tensorflow.concat", "bayesian_rnn_model.Rank1BayesianRNN.hidden_layer", "tensorflow.shape", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat"], ["", "def", "call", "(", "self", ",", "sequence_embeddings", ",", "context_embeddings", ",", "sequence_length", ")", ":", "\n", "    ", "\"\"\"Runs the model.\n\n    Args:\n      sequence_embeddings: Tensor of shape [batch_size, bagged_seq_length,\n        sum(embed_dim)]. The embeddings for all categorical sequence features,\n        concatenated along the embedding axis. If dense features are used, the\n        embeddings or normalized values are also concatenated.\n      context_embeddings: Tensor of shape [batch_size, sum(embed_dim)]. The\n        concatenated embeddings for all context features. Includes the patient's\n        age if birthdate and prediction time are available in inputs.\n      sequence_length: Tensor of shape [batch]. The lengths of the sequences\n        after bagging.\n\n    Returns:\n      A Tensor of logits of shape (batch_size, output_layer_dim).\n    \"\"\"", "\n", "mask", "=", "tf", ".", "sequence_mask", "(", "sequence_length", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "sequence_embeddings", ")", "[", "1", "]", ",", "\n", "dtype", "=", "sequence_embeddings", ".", "dtype", ")", "\n", "mask", "=", "tf", ".", "reshape", "(", "mask", ",", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "shape", "(", "sequence_embeddings", ")", "[", ":", "-", "1", "]", ",", "[", "1", "]", "]", ",", "axis", "=", "-", "1", ")", ")", "\n", "last_output", "=", "self", ".", "rnn_layer", "(", "sequence_embeddings", ",", "mask", "=", "mask", ")", "\n", "\n", "if", "context_embeddings", "is", "not", "None", ":", "\n", "      ", "combined_features", "=", "tf", ".", "concat", "(", "[", "last_output", ",", "context_embeddings", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "      ", "combined_features", "=", "last_output", "\n", "\n", "", "if", "self", ".", "hidden_layer_dim", ">", "0", ":", "\n", "      ", "combined_features", "=", "self", ".", "hidden_layer", "(", "combined_features", ")", "\n", "\n", "", "return", "self", ".", "output_layer", "(", "combined_features", ")", "# shape (n, d)", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_model.Rank1BayesianRNNWithEmbeddings.__init__": [[511, 638], ["super().__init__", "embedding.SequenceEmbedding", "bayesian_rnn_model.Rank1BayesianRNN"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__"], ["def", "__init__", "(", "self", ",", "\n", "embedding_config", ",", "\n", "sequence_features", ",", "\n", "context_features", ",", "\n", "rnn_dim", ",", "\n", "num_rnn_layers", ",", "\n", "hidden_layer_dim", ",", "\n", "output_layer_dim", ",", "\n", "embeddings_initializer", ",", "\n", "embeddings_regularizer", ",", "\n", "alpha_initializer", ",", "\n", "gamma_initializer", ",", "\n", "alpha_regularizer", ",", "\n", "gamma_regularizer", ",", "\n", "use_additive_perturbation", ",", "\n", "ensemble_size", ",", "\n", "random_sign_init", ",", "\n", "dropout_rate", ",", "\n", "prior_mean", ",", "\n", "prior_stddev", ",", "\n", "l2", ",", "\n", "clip_norm", "=", "1.0", ",", "\n", "return_sequences", "=", "False", ",", "\n", "bagging_time_precision", "=", "86400", ",", "\n", "bagging_aggregate_older_than", "=", "-", "1", ",", "\n", "embedding_dimension_multiplier", "=", "1.0", ",", "\n", "dense_feature_name", "=", "None", ",", "\n", "dense_feature_value", "=", "None", ",", "\n", "dense_feature_unit", "=", "None", ",", "\n", "dense_embedding_dimension", "=", "128", ",", "\n", "top_n_dense", "=", "10000", ",", "\n", "num_ids_per_dense_feature", "=", "5", ",", "\n", "dense_stats_config_path", "=", "\"\"", ")", ":", "\n", "    ", "\"\"\"Initializes the model.\n\n    All parameters come from `embedding.SequenceEmbedding` and\n    `Rank1BayesianRNN`.\n\n    Args:\n      embedding_config: An embedding config proto.\n      sequence_features: List of the sequential features to process.\n      context_features: List of the context (per-sequence) features to process.\n      rnn_dim: RNN cell output dimensionality.\n      num_rnn_layers: Number of stacked RNN cells.\n      hidden_layer_dim: Hidden layer output dimensionality.\n      output_layer_dim: Output layer output dimensionality.\n      embeddings_initializer: The initializer for the embedding parameters.\n      embeddings_regularizer: The regularizer for the embedding parameters.\n      alpha_initializer: The initializer for the alpha parameters.\n      gamma_initializer: The initializer for the gamma parameters.\n      alpha_regularizer: The regularizer for the alpha parameters.\n      gamma_regularizer: The regularizer for the gamma parameters.\n      use_additive_perturbation: Whether or not to use additive perturbations\n        instead of multiplicative perturbations.\n      ensemble_size: Number of ensemble members.\n      random_sign_init: Value used to initialize trainable deterministic\n        initializers, as applicable. Values greater than zero result in\n        initialization to a random sign vector, where random_sign_init is the\n        probability of a 1 value. Values less than zero result in initialization\n        from a Gaussian with mean 1 and standard deviation equal to\n        -random_sign_init.\n      dropout_rate: Dropout rate.\n      prior_mean: Mean of the prior.\n      prior_stddev: Standard deviation of the prior.\n      l2: Amount of L2 regularization to apply to the deterministic weights.\n      clip_norm: Gradient clipping norm value for per-time step clipping within\n        the LSTM cell, and for clipping of all aggregated gradients.\n      return_sequences: Whether or not to return outputs at each time step from\n        the LSTM, rather than just the final time step.\n      bagging_time_precision: Precision for bagging in seconds. For example,\n        86400 represents day-level bagging.\n      bagging_aggregate_older_than: Events older than this (in seconds) will all\n        be aggregated into the same bag. `-1` indicates no aggregation.\n      embedding_dimension_multiplier: Multiplier for the default embedding\n        dimension specified in embedding_config. Applied to all categorical\n        features.\n      dense_feature_name: A feature in sequence_features representing the names\n        of all continuous inputs. Used for dense embedding or normalization.\n      dense_feature_value: A feature in sequence_features representing the\n        values of all continuous inputs. Used for dense embedding or\n        normalization.\n      dense_feature_unit: A feature in sequence_features representing the units\n        of all continuous input values. Used for dense embedding or\n        normalization.\n      dense_embedding_dimension: If embed_dense, size of embeddings to use.\n      top_n_dense: Number of top dense features (by frequency) to retain for\n        model input.\n      num_ids_per_dense_feature: If embed_dense, number of embedding IDs per\n        feature.\n      dense_stats_config_path: Path to stats config for dense features.\n    \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "embedding_layer", "=", "embedding", ".", "SequenceEmbedding", "(", "\n", "embedding_config", "=", "embedding_config", ",", "\n", "sequence_features", "=", "sequence_features", ",", "\n", "context_features", "=", "context_features", ",", "\n", "bagging_time_precision", "=", "bagging_time_precision", ",", "\n", "bagging_aggregate_older_than", "=", "bagging_aggregate_older_than", ",", "\n", "embedding_dimension_multiplier", "=", "embedding_dimension_multiplier", ",", "\n", "dense_feature_name", "=", "dense_feature_name", ",", "\n", "dense_feature_value", "=", "dense_feature_value", ",", "\n", "dense_feature_unit", "=", "dense_feature_unit", ",", "\n", "dense_embedding_dimension", "=", "dense_embedding_dimension", ",", "\n", "top_n_dense", "=", "top_n_dense", ",", "\n", "num_ids_per_dense_feature", "=", "num_ids_per_dense_feature", ",", "\n", "dense_stats_config_path", "=", "dense_stats_config_path", ",", "\n", "embeddings_initializer", "=", "embeddings_initializer", ",", "\n", "embeddings_regularizer", "=", "embeddings_regularizer", ")", "\n", "self", ".", "bayesian_rnn", "=", "Rank1BayesianRNN", "(", "\n", "rnn_dim", "=", "rnn_dim", ",", "\n", "num_rnn_layers", "=", "num_rnn_layers", ",", "\n", "hidden_layer_dim", "=", "hidden_layer_dim", ",", "\n", "output_layer_dim", "=", "output_layer_dim", ",", "\n", "alpha_initializer", "=", "alpha_initializer", ",", "\n", "gamma_initializer", "=", "gamma_initializer", ",", "\n", "alpha_regularizer", "=", "alpha_regularizer", ",", "\n", "gamma_regularizer", "=", "gamma_regularizer", ",", "\n", "use_additive_perturbation", "=", "use_additive_perturbation", ",", "\n", "ensemble_size", "=", "ensemble_size", ",", "\n", "random_sign_init", "=", "random_sign_init", ",", "\n", "dropout_rate", "=", "dropout_rate", ",", "\n", "prior_mean", "=", "prior_mean", ",", "\n", "prior_stddev", "=", "prior_stddev", ",", "\n", "clip_norm", "=", "clip_norm", ",", "\n", "l2", "=", "l2", ",", "\n", "return_sequences", "=", "return_sequences", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_model.Rank1BayesianRNNWithEmbeddings.call": [[639, 657], ["bayesian_rnn_model.Rank1BayesianRNNWithEmbeddings.embedding_layer", "bayesian_rnn_model.Rank1BayesianRNNWithEmbeddings.bayesian_rnn"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "    ", "\"\"\"Runs the model.\n\n    Args:\n      inputs: The features to process. A dict of feature names to Tensors or\n        SparseTensors. At minimum, must include the features specified in\n        self.sequence_features and self.context_features, as well as deltaTime\n        and sequenceLength.\n\n    Returns:\n      A Tensor of logits of shape (batch_size, output_layer_dim).\n    \"\"\"", "\n", "(", "sequence_embeddings", ",", "context_embeddings", ",", "\n", "return_dict", ")", "=", "self", ".", "embedding_layer", "(", "inputs", ")", "\n", "sequence_length", "=", "return_dict", "[", "constants", ".", "C_SEQUENCE_LENGTH_KEY", "]", "\n", "logits", "=", "self", ".", "bayesian_rnn", "(", "sequence_embeddings", ",", "context_embeddings", ",", "\n", "sequence_length", ")", "\n", "return", "logits", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_model._clip_gradient": [[51, 58], ["tensorflow.constant", "tensorflow.clip_by_global_norm"], "function", ["None"], ["@", "tf", ".", "custom_gradient", "\n", "def", "_clip_gradient", "(", "x", ",", "clip_norm", ")", ":", "\n", "  ", "\"\"\"Identity function that performs gradient clipping.\"\"\"", "\n", "def", "grad", "(", "dy", ")", ":", "\n", "# NOTE: Must return a gradient for all inputs to `clip_gradient`.", "\n", "    ", "return", "tf", ".", "clip_by_global_norm", "(", "[", "dy", "]", ",", "clip_norm", ")", "[", "0", "]", "[", "0", "]", ",", "tf", ".", "constant", "(", "0.", ")", "\n", "", "return", "x", ",", "grad", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_model_test.BayesianRNNTest.testClipGradient": [[26, 51], ["bayesian_rnn_model_test.BayesianRNNTest.assertAllEqual", "tape.gradient", "tape.gradient", "tensorflow.constant", "bayesian_rnn_model_test.BayesianRNNTest.assertEqual", "bayesian_rnn_model_test.BayesianRNNTest.assertAllEqual", "bayesian_rnn_model_test.BayesianRNNTest.assertAllClose", "tensorflow.constant", "tape.gradient", "bayesian_rnn_model_test.BayesianRNNTest.assertAllClose", "tensorflow.GradientTape", "tensorflow.zeros", "tape.watch", "tensorflow.identity", "bayesian_rnn_model._clip_gradient", "bayesian_rnn_model_test.BayesianRNNTest.evaluate", "bayesian_rnn_model_test.BayesianRNNTest.evaluate", "tensorflow.maximum", "list", "bayesian_rnn_model_test.BayesianRNNTest.evaluate", "bayesian_rnn_model_test.BayesianRNNTest.evaluate", "bayesian_rnn_model_test.BayesianRNNTest.evaluate", "bayesian_rnn_model_test.BayesianRNNTest.evaluate", "bayesian_rnn_model_test.BayesianRNNTest.evaluate", "tensorflow.linalg.global_norm"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_model._clip_gradient", "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.evaluate", "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.evaluate", "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.evaluate", "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.evaluate", "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.evaluate", "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.evaluate", "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.evaluate"], ["  ", "@", "test_util", ".", "run_in_graph_and_eager_modes", "\n", "def", "testClipGradient", "(", "self", ")", ":", "\n", "    ", "shape", "=", "(", "2", ",", "3", ")", "\n", "clip_norm", "=", "1e-3", "\n", "with", "tf", ".", "GradientTape", "(", "persistent", "=", "True", ")", "as", "tape", ":", "\n", "      ", "x", "=", "tf", ".", "zeros", "(", "shape", ")", "\n", "tape", ".", "watch", "(", "x", ")", "\n", "y1", "=", "tf", ".", "identity", "(", "x", ")", "\n", "y2", "=", "bayesian_rnn_model", ".", "_clip_gradient", "(", "x", ",", "clip_norm", ")", "\n", "", "self", ".", "assertAllEqual", "(", "self", ".", "evaluate", "(", "x", ")", ",", "self", ".", "evaluate", "(", "y2", ")", ")", "\n", "\n", "dy1dx", "=", "tape", ".", "gradient", "(", "y1", ",", "x", ")", "\n", "dy2dx", "=", "tape", ".", "gradient", "(", "y2", ",", "x", ")", "\n", "dx_unclipped", "=", "tf", ".", "constant", "(", "1.0", ",", "shape", "=", "shape", ")", "\n", "dx_clipped", "=", "(", "dx_unclipped", "*", "clip_norm", "/", "\n", "tf", ".", "maximum", "(", "tf", ".", "linalg", ".", "global_norm", "(", "[", "dx_unclipped", "]", ")", ",", "clip_norm", ")", ")", "\n", "self", ".", "assertEqual", "(", "dy2dx", ".", "shape", ",", "list", "(", "shape", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "self", ".", "evaluate", "(", "dy1dx", ")", ",", "self", ".", "evaluate", "(", "dx_unclipped", ")", ")", "\n", "self", ".", "assertAllClose", "(", "self", ".", "evaluate", "(", "dy2dx", ")", ",", "dx_clipped", ")", "\n", "\n", "grad_ys", "=", "tf", ".", "constant", "(", "1e-4", ",", "shape", "=", "shape", ")", "\n", "dy2dx", "=", "tape", ".", "gradient", "(", "y2", ",", "x", ",", "output_gradients", "=", "grad_ys", ")", "\n", "# The l2 norm is sqrt(6 * (1e-4)^2) = 2.44e-4, which is less than 1e-3, so", "\n", "# no clipping should occur.", "\n", "self", ".", "assertAllClose", "(", "self", ".", "evaluate", "(", "dy2dx", ")", ",", "self", ".", "evaluate", "(", "grad_ys", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_model_test.BayesianRNNTest.testLSTMCellReparameterizationGradClipped": [[52, 95], ["bayesian_rnn_model_test.BayesianRNNTest.evaluate", "tensorflow.constant", "tape.gradient", "tape.gradient", "bayesian_rnn_model_test.BayesianRNNTest.evaluate", "bayesian_rnn_model_test.BayesianRNNTest.evaluate", "bayesian_rnn_model_test.BayesianRNNTest.assertNotAllClose", "bayesian_rnn_model_test.BayesianRNNTest.assertGreater", "bayesian_rnn_model_test.BayesianRNNTest.assertAllClose", "tape.gradient", "tape.gradient", "bayesian_rnn_model_test.BayesianRNNTest.evaluate", "bayesian_rnn_model_test.BayesianRNNTest.evaluate", "bayesian_rnn_model_test.BayesianRNNTest.assertNotAllClose", "bayesian_rnn_model_test.BayesianRNNTest.assertGreater", "bayesian_rnn_model_test.BayesianRNNTest.assertAllClose", "tape.gradient", "tape.gradient", "bayesian_rnn_model_test.BayesianRNNTest.evaluate", "bayesian_rnn_model_test.BayesianRNNTest.evaluate", "bayesian_rnn_model_test.BayesianRNNTest.assertNotAllClose", "bayesian_rnn_model_test.BayesianRNNTest.assertGreater", "bayesian_rnn_model_test.BayesianRNNTest.assertAllClose", "tensorflow.GradientTape", "tensorflow.zeros", "tape.watch", "edward2.layers.LSTMCellReparameterization", "bayesian_rnn_model.LSTMCellReparameterizationGradClipped", "edward2.layers.LSTMCellReparameterization.get_initial_state", "tape.watch", "tape.watch", "edward2.layers.LSTMCellReparameterization.", "bayesian_rnn_model.LSTMCellReparameterizationGradClipped.", "tf1.global_variables_initializer", "tensorflow.linalg.norm", "tensorflow.linalg.norm", "tensorflow.linalg.norm", "tensorflow.linalg.norm", "tensorflow.linalg.norm", "tensorflow.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.evaluate", "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.evaluate", "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.evaluate", "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.evaluate", "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.evaluate", "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.evaluate", "home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.evaluate"], ["", "@", "test_util", ".", "run_in_graph_and_eager_modes", "\n", "def", "testLSTMCellReparameterizationGradClipped", "(", "self", ")", ":", "\n", "    ", "clip_norm", "=", "1e-3", "\n", "shape", "=", "(", "2", ",", "4", ")", "\n", "with", "tf", ".", "GradientTape", "(", "persistent", "=", "True", ")", "as", "tape", ":", "\n", "      ", "x", "=", "tf", ".", "zeros", "(", "shape", ")", "\n", "tape", ".", "watch", "(", "x", ")", "\n", "cell1", "=", "ed", ".", "layers", ".", "LSTMCellReparameterization", "(", "10", ")", "\n", "cell2", "=", "bayesian_rnn_model", ".", "LSTMCellReparameterizationGradClipped", "(", "\n", "clip_norm", ",", "10", ")", "\n", "h0", ",", "c0", "=", "cell1", ".", "get_initial_state", "(", "x", ")", "\n", "tape", ".", "watch", "(", "h0", ")", "\n", "tape", ".", "watch", "(", "c0", ")", "\n", "state", "=", "(", "h0", ",", "c0", ")", "\n", "y1", ",", "_", "=", "cell1", "(", "x", ",", "state", ")", "\n", "y2", ",", "_", "=", "cell2", "(", "x", ",", "state", ")", "\n", "\n", "", "self", ".", "evaluate", "(", "tf1", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "grad_ys", "=", "tf", ".", "constant", "(", "1e6", ",", "shape", "=", "y1", ".", "shape", ")", "\n", "dy1dx", "=", "tape", ".", "gradient", "(", "y1", ",", "x", ",", "output_gradients", "=", "grad_ys", ")", "\n", "dy2dx", "=", "tape", ".", "gradient", "(", "y2", ",", "x", ",", "output_gradients", "=", "grad_ys", ")", "\n", "res1", "=", "self", ".", "evaluate", "(", "tf", ".", "linalg", ".", "norm", "(", "dy1dx", ")", ")", "\n", "res2", "=", "self", ".", "evaluate", "(", "tf", ".", "linalg", ".", "norm", "(", "dy2dx", ")", ")", "\n", "self", ".", "assertNotAllClose", "(", "res1", ",", "res2", ")", "\n", "self", ".", "assertGreater", "(", "res1", ",", "clip_norm", ")", "\n", "self", ".", "assertAllClose", "(", "res2", ",", "clip_norm", ")", "\n", "\n", "dy1dh0", "=", "tape", ".", "gradient", "(", "y1", ",", "h0", ",", "output_gradients", "=", "grad_ys", ")", "\n", "dy2dh0", "=", "tape", ".", "gradient", "(", "y2", ",", "h0", ",", "output_gradients", "=", "grad_ys", ")", "\n", "res1", "=", "self", ".", "evaluate", "(", "tf", ".", "linalg", ".", "norm", "(", "dy1dh0", ")", ")", "\n", "res2", "=", "self", ".", "evaluate", "(", "tf", ".", "linalg", ".", "norm", "(", "dy2dh0", ")", ")", "\n", "self", ".", "assertNotAllClose", "(", "res1", ",", "res2", ")", "\n", "self", ".", "assertGreater", "(", "res1", ",", "clip_norm", ")", "\n", "self", ".", "assertAllClose", "(", "res2", ",", "clip_norm", ")", "\n", "\n", "dy1dc0", "=", "tape", ".", "gradient", "(", "y1", ",", "c0", ",", "output_gradients", "=", "grad_ys", ")", "\n", "dy2dc0", "=", "tape", ".", "gradient", "(", "y2", ",", "c0", ",", "output_gradients", "=", "grad_ys", ")", "\n", "res1", "=", "self", ".", "evaluate", "(", "tf", ".", "linalg", ".", "norm", "(", "dy1dc0", ")", ")", "\n", "res2", "=", "self", ".", "evaluate", "(", "tf", ".", "linalg", ".", "norm", "(", "dy2dc0", ")", ")", "\n", "self", ".", "assertNotAllClose", "(", "res1", ",", "res2", ")", "\n", "self", ".", "assertGreater", "(", "res1", ",", "clip_norm", ")", "\n", "self", ".", "assertAllClose", "(", "res2", ",", "clip_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.Model.__init__": [[33, 44], ["models.Model._parse_config"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.Model._parse_config"], ["def", "__init__", "(", "self", ",", "\n", "mode", ":", "tf", ".", "Estimator", ".", "ModeKeys", ",", "\n", "config", ":", "experiment_config_pb2", ".", "ModelConfig", "=", "None", ")", ":", "\n", "    ", "\"\"\"Initialize model and parse config.\n\n    Args:\n      mode: One of {TRAIN,EVAL}.\n      config: Model config.\n    \"\"\"", "\n", "self", ".", "_mode", "=", "mode", "\n", "self", ".", "_config", "=", "self", ".", "_parse_config", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.Model._parse_config": [[45, 51], ["experiment_config_pb2.ModelConfig", "experiment_config_pb2.ModelConfig.MergeFrom"], "methods", ["None"], ["", "def", "_parse_config", "(", "self", ",", "config", ":", "experiment_config_pb2", ".", "ModelConfig", "=", "None", ")", ":", "\n", "    ", "\"\"\"Update default config based on the supplied model configuration.\"\"\"", "\n", "default_config", "=", "experiment_config_pb2", ".", "ModelConfig", "(", ")", "\n", "if", "config", ":", "\n", "      ", "default_config", ".", "MergeFrom", "(", "config", ")", "\n", "", "return", "default_config", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.Model.config": [[52, 55], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "config", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_config", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.Model._feature_to_tensor": [[56, 125], ["tensorflow.logging.info", "tensorflow.concat", "tensorflow.slice", "features.keys", "tensorflow.concat", "tensorflow.slice", "tensorflow.concat", "tensorflow.slice", "tensorflow.stack", "tensorflow.constant", "tensorflow.expand_dims", "obs.endswith", "tensorflow.expand_dims", "biomarker_mask_list.append", "biomarker_mask_list.append", "tensorflow.expand_dims", "len"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat"], ["", "def", "_feature_to_tensor", "(", "self", ",", "features", ":", "Dict", "[", "bytes", ",", "tf", ".", "Tensor", "]", ")", ":", "\n", "    ", "\"\"\"Convert input features into dense tensors.\n\n    Args:\n      features: Mapping of feature names to tensors. Each training tensor has\n        shape [batch_size, context_len_to_trigger]. Each pretrain tensor has\n        shape [batch_size, context_window_size].\n\n    Returns:\n      A dict of the following tensors:\n        obs_full_tensor of shape [batch_size, context_window_size, num_obs]\n        obs_full_mask_tensor of shape [batch_size, context_window_size, num_obs]\n        obs_to_trigger_tensor of shape [bs, context_len_to_trigger, num_obs]\n        obs_to_trigger_mask_tensor shape [bs, context_len_to_trigger, num_obs]\n        intervention_full_tensor of shape [bs, context_window_size, num_int]\n        intervention_to_trigger_tensor : [bs, context_len_to_trigger, num_int]\n    \"\"\"", "\n", "config", "=", "self", ".", "_config", "\n", "tensor_dict", "=", "{", "}", "\n", "tf", ".", "logging", ".", "info", "(", "features", ".", "keys", "(", ")", ")", "\n", "tensor_dict", "[", "'obs_full_tensor'", "]", "=", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "expand_dims", "(", "features", "[", "obs", "]", ",", "2", ")", "for", "obs", "in", "config", ".", "observation_codes", "]", ",", "\n", "axis", "=", "2", ")", "\n", "if", "config", ".", "has_mask", ":", "\n", "      ", "mask_list", "=", "[", "]", "\n", "for", "obs", "in", "config", ".", "observation_codes", ":", "\n", "        ", "if", "obs", ".", "endswith", "(", "'_raw'", ")", ":", "\n", "          ", "obs", "=", "obs", "[", ":", "-", "4", "]", "\n", "", "mask_list", "=", "mask_list", "+", "[", "tf", ".", "expand_dims", "(", "features", "[", "obs", "+", "'_mask'", "]", ",", "2", ")", "]", "\n", "", "tensor_dict", "[", "'obs_full_mask_tensor'", "]", "=", "tf", ".", "concat", "(", "mask_list", ",", "axis", "=", "2", ")", "\n", "\n", "", "tensor_dict", "[", "'obs_to_trigger_tensor'", "]", "=", "tf", ".", "slice", "(", "\n", "tensor_dict", "[", "'obs_full_tensor'", "]", ",", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "-", "1", ",", "self", ".", "_config", ".", "context_len_to_trigger", ",", "-", "1", "]", ")", "\n", "\n", "if", "config", ".", "has_mask", ":", "\n", "      ", "tensor_dict", "[", "'obs_to_trigger_mask_tensor'", "]", "=", "tf", ".", "slice", "(", "\n", "tensor_dict", "[", "'obs_full_mask_tensor'", "]", ",", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "-", "1", ",", "self", ".", "_config", ".", "context_len_to_trigger", ",", "-", "1", "]", ")", "\n", "\n", "", "if", "config", ".", "intervention_codes", ":", "\n", "      ", "tensor_dict", "[", "'intervention_full_tensor'", "]", "=", "tf", ".", "concat", "(", "[", "\n", "tf", ".", "expand_dims", "(", "features", "[", "intv", "]", ",", "2", ")", "\n", "for", "intv", "in", "config", ".", "intervention_codes", "\n", "]", ",", "\n", "axis", "=", "2", ")", "\n", "tensor_dict", "[", "'intervention_to_trigger_tensor'", "]", "=", "tf", ".", "slice", "(", "\n", "tensor_dict", "[", "'intervention_full_tensor'", "]", ",", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "-", "1", ",", "self", ".", "_config", ".", "context_len_to_trigger", ",", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "      ", "tensor_dict", "[", "'intervention_full_tensor'", "]", "=", "None", "\n", "tensor_dict", "[", "'intervention_to_trigger_tensor'", "]", "=", "None", "\n", "\n", "", "if", "config", ".", "forecast_biomarkers", ":", "\n", "      ", "biomarker_mask_list", "=", "[", "]", "\n", "for", "obs", "in", "config", ".", "observation_codes", ":", "\n", "        ", "if", "obs", "in", "config", ".", "forecast_biomarkers", ":", "\n", "          ", "biomarker_mask_list", ".", "append", "(", "True", ")", "\n", "", "else", ":", "\n", "          ", "biomarker_mask_list", ".", "append", "(", "False", ")", "\n", "", "", "tensor_dict", "[", "'biomarker_boolean_mask'", "]", "=", "tf", ".", "stack", "(", "\n", "biomarker_mask_list", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "      ", "tensor_dict", "[", "'biomarker_boolean_mask'", "]", "=", "tf", ".", "constant", "(", "\n", "True", ",", "shape", "=", "[", "len", "(", "config", ".", "observation_codes", ")", "]", ")", "\n", "\n", "", "if", "'true_length_hr'", "in", "features", ":", "\n", "      ", "tensor_dict", "[", "'true_length_hr'", "]", "=", "features", "[", "'true_length_hr'", "]", "\n", "", "return", "tensor_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.Model._get_train_and_predict_tensors": [[126, 162], ["tensorflow.cast", "tensorflow.ones_like", "tensorflow.slice", "tensorflow.slice", "tensorflow.slice", "tensorflow.cast", "tensorflow.ones_like", "tensorflow.constant", "len"], "methods", ["None"], ["", "def", "_get_train_and_predict_tensors", "(", "self", ",", "tensor_dict", ",", "train_len", ")", ":", "\n", "    ", "obs_full_tensor", "=", "tensor_dict", "[", "'obs_full_tensor'", "]", "\n", "intervention_full_tensor", "=", "tensor_dict", "[", "'intervention_full_tensor'", "]", "\n", "if", "self", ".", "_config", ".", "has_mask", ":", "\n", "      ", "obs_full_mask_tensor", "=", "tf", ".", "cast", "(", "tensor_dict", "[", "'obs_full_mask_tensor'", "]", ",", "\n", "tf", ".", "float32", ")", "\n", "", "else", ":", "\n", "      ", "obs_full_mask_tensor", "=", "tf", ".", "ones_like", "(", "obs_full_tensor", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "", "if", "train_len", ">", "0", ":", "\n", "      ", "obs_full_tensor", "=", "tf", ".", "slice", "(", "obs_full_tensor", ",", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "-", "1", ",", "train_len", ",", "-", "1", "]", ")", "\n", "intervention_full_tensor", "=", "tf", ".", "slice", "(", "intervention_full_tensor", ",", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "-", "1", ",", "train_len", ",", "-", "1", "]", ")", "\n", "obs_full_mask_tensor", "=", "tf", ".", "slice", "(", "obs_full_mask_tensor", ",", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "-", "1", ",", "train_len", ",", "-", "1", "]", ")", "\n", "\n", "", "obs_to_trigger_tensor", "=", "tensor_dict", "[", "'obs_to_trigger_tensor'", "]", "\n", "intervention_to_trigger_tensor", "=", "tensor_dict", "[", "\n", "'intervention_to_trigger_tensor'", "]", "\n", "if", "self", ".", "_config", ".", "has_mask", ":", "\n", "      ", "obs_to_trigger_mask_tensor", "=", "tf", ".", "cast", "(", "\n", "tensor_dict", "[", "'obs_to_trigger_mask_tensor'", "]", ",", "tf", ".", "float32", ")", "\n", "", "else", ":", "\n", "      ", "obs_to_trigger_mask_tensor", "=", "tf", ".", "ones_like", "(", "\n", "obs_to_trigger_tensor", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "", "if", "self", ".", "_config", ".", "forecast_biomarkers", ":", "\n", "      ", "biomarker_boolean_mask_tensor", "=", "tensor_dict", "[", "'biomarker_boolean_mask'", "]", "\n", "", "else", ":", "\n", "      ", "biomarker_boolean_mask_tensor", "=", "tf", ".", "constant", "(", "\n", "True", ",", "shape", "=", "[", "len", "(", "self", ".", "_config", ".", "observation_codes", ")", "]", ")", "\n", "\n", "", "return", "(", "obs_full_tensor", ",", "obs_full_mask_tensor", ",", "intervention_full_tensor", ",", "\n", "obs_to_trigger_tensor", ",", "obs_to_trigger_mask_tensor", ",", "\n", "intervention_to_trigger_tensor", ",", "biomarker_boolean_mask_tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.Model._encode": [[163, 189], ["NotImplementedError"], "methods", ["None"], ["", "def", "_encode", "(", "self", ",", "tensor_dict", ":", "Dict", "[", "bytes", ",", "tf", ".", "Tensor", "]", ")", "->", "tf", ".", "Tensor", ":", "\n", "    ", "\"\"\"Encode input features into a fixed length representation.\n\n    This method will be implemented in subclasses based different models.\n\n    Args:\n      tensor_dict: dict of the following tensors:\n      * obs_full_tensor of shape [batch_size, context_window_size, num_obs]\n        representing the input observation features. This is the feature for\n        pretraining.\n      * obs_full_mask_tensor of shape [batch_size, context_window_size, num_obs]\n      * obs_to_trigger_tensor of shape [bs, context_len_to_trigger, num_obs]\n        representing the input observation features up to trigger time. This is\n        the feature used for training.\n      * obs_to_trigger_mask_tensor shape [bs, context_len_to_trigger, num_obs]\n      * intervention_full_tensor of shape [bs, context_window_size, num_int]\n        representing the input interv features. This is the feature for\n        pretraining.\n      * intervention_to_trigger_tensor : [bs, context_len_to_trigger, num_int]\n        representing the input interv features up to trigger time. This is\n        the feature used for training.\n    Returns:\n      A tensor of shape [batch_size, output_dimension] where output_dimension is\n      the output dimension depending on the model config.\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.Model.generate_output": [[190, 198], ["tensorflow.logging.info", "tensorflow.name_scope", "models.Model._feature_to_tensor", "tensorflow.name_scope", "models.Model._encode"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.Model._feature_to_tensor", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem._encode"], ["", "def", "generate_output", "(", "self", ",", "features", ":", "Dict", "[", "bytes", ",", "tf", ".", "Tensor", "]", ")", ":", "\n", "    ", "\"\"\"Generate model output.\"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "'Feature_to_tensor'", ")", ":", "\n", "      ", "tensor_dict", "=", "self", ".", "_feature_to_tensor", "(", "features", ")", "\n", "\n", "", "tf", ".", "logging", ".", "info", "(", "tensor_dict", ")", "\n", "with", "tf", ".", "name_scope", "(", "self", ".", "__class__", ".", "__name__", ")", ":", "\n", "      ", "return", "self", ".", "_encode", "(", "tensor_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.MultiLayerPerceptron.__init__": [[203, 206], ["models.Model.__init__"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__"], ["def", "__init__", "(", "self", ",", "mode", ",", "config", "=", "None", ")", ":", "\n", "    ", "\"\"\"Initialize an MLP model.\"\"\"", "\n", "super", "(", "MultiLayerPerceptron", ",", "self", ")", ".", "__init__", "(", "mode", ",", "config", "=", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.MultiLayerPerceptron._encode": [[207, 233], ["modules._recent_input_module", "modules._fully_connected_module"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._recent_input_module", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._fully_connected_module"], ["", "def", "_encode", "(", "self", ",", "tensor_dict", ":", "Dict", "[", "bytes", ",", "tf", ".", "Tensor", "]", ")", "->", "tf", ".", "Tensor", ":", "\n", "    ", "\"\"\"Encode the most recent inputs of the input tensor based on MLP model.\n\n    Args:\n      tensor_dict: A dict of tensor.\n    Returns:\n      dict of network output tensor with shape [batch_size, self._config.sdl].\n    \"\"\"", "\n", "obs_tensor", "=", "tensor_dict", "[", "'obs_to_trigger_tensor'", "]", "\n", "config", "=", "self", ".", "_config", "\n", "is_training", "=", "self", ".", "_mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", "\n", "network_input", "=", "modules", ".", "_recent_input_module", "(", "obs_tensor", ")", "\n", "\n", "output", "=", "modules", ".", "_fully_connected_module", "(", "\n", "input_tensor", "=", "network_input", ",", "\n", "num_dense_layers", "=", "config", ".", "ndl", ",", "\n", "dense_layer_size", "=", "config", ".", "sdl", ",", "\n", "output_layer_size", "=", "config", ".", "sdl", ",", "\n", "output_activation", "=", "tf", ".", "nn", ".", "sigmoid", ",", "\n", "is_training", "=", "is_training", ",", "\n", "drop_rate", "=", "config", ".", "drdl", ",", "\n", "name", "=", "'MLP'", ",", "\n", ")", "\n", "output_dict", "=", "{", "}", "\n", "output_dict", "[", "'state_encoding'", "]", "=", "output", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.MostRecentInput.__init__": [[238, 241], ["models.Model.__init__"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__"], ["def", "__init__", "(", "self", ",", "mode", ",", "config", "=", "None", ")", ":", "\n", "    ", "\"\"\"Initialize a MRI model.\"\"\"", "\n", "super", "(", "MostRecentInput", ",", "self", ")", ".", "__init__", "(", "mode", ",", "config", "=", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.MostRecentInput._encode": [[242, 257], ["tensorflow.logging.info", "modules._recent_input_module"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._recent_input_module"], ["", "def", "_encode", "(", "self", ",", "tensor_dict", ":", "Dict", "[", "bytes", ",", "tf", ".", "Tensor", "]", ")", "->", "tf", ".", "Tensor", ":", "\n", "    ", "\"\"\"Encode the most recent inputs of the input tensor.\n\n    Args:\n      tensor_dict: A dict of tensor.\n\n    Returns:\n      dict of network output tensor with shape [batch_size, self._config.sdl].\n    \"\"\"", "\n", "tf", ".", "logging", ".", "info", "(", "tensor_dict", ")", "\n", "obs_tensor", "=", "tensor_dict", "[", "'obs_to_trigger_tensor'", "]", "\n", "\n", "output", "=", "{", "}", "\n", "output", "[", "'state_encoding'", "]", "=", "modules", ".", "_recent_input_module", "(", "obs_tensor", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.LSTMDynamicSystem.__init__": [[262, 273], ["models.Model.__init__", "len", "len"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__"], ["def", "__init__", "(", "self", ",", "mode", ",", "config", "=", "None", ")", ":", "\n", "    ", "\"\"\"Initialize a LSTM DS model.\"\"\"", "\n", "super", "(", "LSTMDynamicSystem", ",", "self", ")", ".", "__init__", "(", "mode", ",", "config", "=", "config", ")", "\n", "if", "self", ".", "_config", ".", "forecast_biomarkers", ":", "\n", "      ", "self", ".", "_out_obs_dim", "=", "len", "(", "self", ".", "_config", ".", "forecast_biomarkers", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "_out_obs_dim", "=", "len", "(", "self", ".", "_config", ".", "observation_codes", ")", "\n", "", "if", "self", ".", "_config", ".", "reuse_encoding", ":", "\n", "      ", "self", ".", "_tag", "=", "''", "\n", "", "else", ":", "\n", "      ", "self", ".", "_tag", "=", "'encode'", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.LSTMDynamicSystem.lstm_output_state": [[274, 292], ["input_tensor.get_shape().as_list", "tensorflow.variable_scope", "tensorflow.nn.rnn_cell.LSTMCell", "tensorflow.nn.rnn_cell.MultiRNNCell", "tensorflow.nn.rnn_cell.MultiRNNCell.zero_state", "tensorflow.nn.dynamic_rnn", "input_tensor.get_shape"], "methods", ["None"], ["", "", "def", "lstm_output_state", "(", "self", ",", "input_tensor", ",", "seqlen", ")", ":", "\n", "    ", "\"\"\"Get output and state from LSTM.\"\"\"", "\n", "config", "=", "self", ".", "_config", "\n", "batch_size", "=", "input_tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'lstm_ds'", "+", "self", ".", "_tag", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "      ", "cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "LSTMCell", "(", "config", ".", "ds_state", ")", "\n", "rnn_cells", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "(", "[", "cell", "]", "*", "config", ".", "ds_nrl", ")", "\n", "initial_state", "=", "rnn_cells", ".", "zero_state", "(", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "outputs", ",", "state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "\n", "rnn_cells", ",", "\n", "input_tensor", ",", "\n", "initial_state", "=", "initial_state", ",", "\n", "sequence_length", "=", "seqlen", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "# 'outputs' is a tensor of shape [batch_size, max_time, cell_state_size]", "\n", "# 'state' is a tensor of shape [batch_size, tuple<hidden, cell_state_size>]", "\n", "", "return", "outputs", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.LSTMDynamicSystem.lstm_obs_emit_step": [[293, 303], ["tensorflow.variable_scope", "tensorflow.layers.dense"], "methods", ["None"], ["", "def", "lstm_obs_emit_step", "(", "self", ",", "previous_output", ",", "current_input", ")", ":", "\n", "    ", "del", "previous_output", "\n", "lstm_output", "=", "current_input", "\n", "with", "tf", ".", "variable_scope", "(", "'lstm_ds_obs_emit'", "+", "self", ".", "_tag", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "      ", "obs_estimation", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "lstm_output", ",", "\n", "units", "=", "self", ".", "_out_obs_dim", ",", "\n", "activation", "=", "None", ",", "\n", "name", "=", "'obs_dense'", ")", "\n", "", "return", "obs_estimation", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.LSTMDynamicSystem.lstm_emit_obs": [[304, 318], ["tensorflow.transpose", "tensorflow.zeros", "tensorflow.scan", "tensorflow.transpose", "seq_output.get_shape().as_list", "seq_output.get_shape"], "methods", ["None"], ["", "def", "lstm_emit_obs", "(", "self", ",", "seq_output", ")", ":", "\n", "    ", "\"\"\"Emit observations based on seq output from lstm.\"\"\"", "\n", "# seq_output shape [bs, tlen, lstm_state]", "\n", "batch_size", "=", "seq_output", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "time_first_input", "=", "tf", ".", "transpose", "(", "seq_output", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "init_obs", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "self", ".", "_out_obs_dim", "]", ")", "\n", "current_obs", "=", "tf", ".", "scan", "(", "\n", "self", ".", "lstm_obs_emit_step", ",", "\n", "time_first_input", ",", "\n", "initializer", "=", "(", "init_obs", ")", ",", "\n", "parallel_iterations", "=", "PARALLEL_ITER_SCAN", ",", "\n", "name", "=", "'lstm_emit_obs_scan'", ")", "\n", "# switch batch, tlen dimension back.", "\n", "return", "tf", ".", "transpose", "(", "current_obs", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.LSTMDynamicSystem._encode": [[319, 389], ["models.LSTMDynamicSystem._get_train_and_predict_tensors", "tensorflow.constant", "tensorflow.logging.info", "tensorflow.logging.info", "models.LSTMDynamicSystem.lstm_output_state", "models.LSTMDynamicSystem.lstm_emit_obs", "dict", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "tensorflow.stack", "tensorflow.logging.info", "tensorflow.squeeze", "obs_to_trigger_tensor.get_shape().as_list", "obs_to_trigger_tensor.get_shape().as_list", "obs_to_trigger_tensor.get_shape().as_list", "tensorflow.slice", "tensorflow.boolean_mask", "tensorflow.transpose", "tensorflow.concat", "tensorflow.concat", "tensorflow.transpose", "obs_to_trigger_tensor.get_shape", "obs_to_trigger_tensor.get_shape", "obs_to_trigger_tensor.get_shape"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.Model._get_train_and_predict_tensors", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.LSTMDynamicSystem.lstm_output_state", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.LSTMDynamicSystem.lstm_emit_obs", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat"], ["", "def", "_encode", "(", "self", ",", "tensor_dict", ":", "Dict", "[", "bytes", ",", "tf", ".", "Tensor", "]", ")", "->", "tf", ".", "Tensor", ":", "\n", "    ", "\"\"\"Encode an input tensor based on LSTM model.\n\n    Args:\n      tensor_dict: A dict of tensor.\n\n    Returns:\n      dict of network output tensor.\n    \"\"\"", "\n", "config", "=", "self", ".", "_config", "\n", "\n", "train_and_predict_tensors", "=", "self", ".", "_get_train_and_predict_tensors", "(", "\n", "tensor_dict", ",", "config", ".", "sys_id_len", ")", "\n", "_", ",", "_", ",", "_", ",", "obs_to_trigger_tensor", ",", "obs_to_trigger_mask_tensor", ",", "intervention_to_trigger_tensor", ",", "biomarker_boolean_mask_tensor", "=", "train_and_predict_tensors", "# pylint:", "\n", "\n", "batch_size", "=", "obs_to_trigger_tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "context_size", "=", "obs_to_trigger_tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "num_obs", "=", "obs_to_trigger_tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "2", "]", "\n", "\n", "seqlen", "=", "tf", ".", "constant", "(", "context_size", ",", "shape", "=", "[", "batch_size", "]", ")", "\n", "\n", "tf", ".", "logging", ".", "info", "(", "obs_to_trigger_tensor", ")", "\n", "tf", ".", "logging", ".", "info", "(", "intervention_to_trigger_tensor", ")", "\n", "if", "intervention_to_trigger_tensor", "is", "not", "None", ":", "\n", "      ", "if", "config", ".", "lstm_interv_delay", "==", "0", ":", "\n", "        ", "input_tensor", "=", "tf", ".", "concat", "(", "[", "\n", "obs_to_trigger_tensor", ",", "\n", "intervention_to_trigger_tensor", "]", ",", "\n", "axis", "=", "2", ")", "\n", "", "else", ":", "\n", "        ", "input_tensor", "=", "tf", ".", "concat", "(", "[", "\n", "obs_to_trigger_tensor", "[", ":", ",", "config", ".", "lstm_interv_delay", ":", ",", ":", "]", ",", "\n", "intervention_to_trigger_tensor", "[", ":", ",", ":", "-", "config", ".", "lstm_interv_delay", ",", ":", "]", "\n", "]", ",", "\n", "axis", "=", "2", ")", "\n", "", "", "else", ":", "\n", "      ", "input_tensor", "=", "obs_to_trigger_tensor", "\n", "\n", "# 'seq_output' is a tensor of shape [batch_size, seq_len, cell_state_size]", "\n", "# 'state' is a tuple of", "\n", "# (LSTMStateTuple(c=<tf.Tensor shape=(batch_size, cell_state_size)>,", "\n", "#                 h=<tf.Tensor shape=(batch_size, cell_state_size)>),)", "\n", "", "seq_output", ",", "state", "=", "self", ".", "lstm_output_state", "(", "input_tensor", ",", "seqlen", ")", "\n", "obs_estimation", "=", "self", ".", "lstm_emit_obs", "(", "seq_output", ")", "\n", "\n", "output", "=", "dict", "(", ")", "\n", "# obs estimation time series shape [bs, context_size, num_obs]", "\n", "output", "[", "'obs_est'", "]", "=", "tf", ".", "clip_by_value", "(", "\n", "obs_estimation", ",", "-", "99999", ",", "99999", ",", "name", "=", "None", ")", "\n", "\n", "# final state_encoding shape [bs, ds_state]", "\n", "state_encoding", "=", "seq_output", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "output", "[", "'state_encoding'", "]", "=", "tf", ".", "clip_by_value", "(", "\n", "state_encoding", ",", "-", "99999", ",", "99999", ",", "name", "=", "None", ")", "\n", "# output['lstm_forecast_state'] shape [bs, 2, cell_state_size]", "\n", "output", "[", "'lstm_forecast_state'", "]", "=", "tf", ".", "stack", "(", "[", "state", "[", "0", "]", ".", "c", ",", "state", "[", "0", "]", ".", "h", "]", ",", "axis", "=", "1", ")", "\n", "tf", ".", "logging", ".", "info", "(", "output", "[", "'lstm_forecast_state'", "]", ")", "\n", "\n", "# output['last_obs']  shape [bs, _a_dim]", "\n", "output", "[", "'last_obs'", "]", "=", "tf", ".", "squeeze", "(", "\n", "tf", ".", "slice", "(", "obs_to_trigger_tensor", ",", "\n", "[", "0", ",", "self", ".", "_config", ".", "context_len_to_trigger", "-", "1", ",", "0", "]", ",", "[", "-", "1", ",", "1", ",", "-", "1", "]", ")", ")", "\n", "if", "self", ".", "_config", ".", "forecast_biomarkers", ":", "\n", "# switch shape to [_a_dim, bs] for applying mask.", "\n", "      ", "output", "[", "'last_obs'", "]", "=", "tf", ".", "boolean_mask", "(", "\n", "tf", ".", "transpose", "(", "output", "[", "'last_obs'", "]", ")", ",", "biomarker_boolean_mask_tensor", ")", "\n", "# transpose shape back.", "\n", "output", "[", "'last_obs'", "]", "=", "tf", ".", "transpose", "(", "output", "[", "'last_obs'", "]", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.__init__": [[399, 434], ["models.Model.__init__", "len", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "len", "len", "ValueError", "len", "tensorflow.eye", "tensorflow.eye", "tensorflow.eye"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__"], ["def", "__init__", "(", "self", ",", "mode", ",", "config", "=", "None", ")", ":", "\n", "    ", "super", "(", "DKFDynamicSystem", ",", "self", ")", ".", "__init__", "(", "mode", ",", "config", "=", "config", ")", "\n", "self", ".", "_z_dim", "=", "config", ".", "ds_state", "\n", "if", "self", ".", "_config", ".", "reuse_encoding", ":", "\n", "      ", "self", ".", "_tag", "=", "''", "\n", "", "else", ":", "\n", "      ", "self", ".", "_tag", "=", "'encode'", "\n", "\n", "", "self", ".", "_a_dim", "=", "len", "(", "config", ".", "observation_codes", ")", "\n", "if", "self", ".", "_config", ".", "forecast_biomarkers", ":", "\n", "      ", "self", ".", "_out_obs_dim", "=", "len", "(", "self", ".", "_config", ".", "forecast_biomarkers", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "_out_obs_dim", "=", "len", "(", "self", ".", "_config", ".", "observation_codes", ")", "\n", "\n", "", "if", "not", "config", ".", "intervention_codes", ":", "\n", "      ", "raise", "ValueError", "(", "'missing intervention_codes'", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "_u_dim", "=", "len", "(", "config", ".", "intervention_codes", ")", "\n", "# state noise.", "\n", "", "self", ".", "state_noise", "=", "tf", ".", "get_variable", "(", "\n", "'state_noise'", ",", "\n", "initializer", "=", "tf", ".", "eye", "(", "self", ".", "_z_dim", ",", "num_columns", "=", "self", ".", "_z_dim", ")", ",", "\n", "trainable", "=", "config", ".", "noise_trainable", ")", "\n", "\n", "# observation noise.", "\n", "self", ".", "obs_noise", "=", "tf", ".", "get_variable", "(", "\n", "'obs_noise'", ",", "\n", "initializer", "=", "tf", ".", "eye", "(", "self", ".", "_out_obs_dim", ",", "num_columns", "=", "self", ".", "_out_obs_dim", ")", ",", "\n", "trainable", "=", "config", ".", "noise_trainable", ")", "# state uncertainty", "\n", "\n", "# intervention forecast noise.", "\n", "self", ".", "interv_noise", "=", "tf", ".", "get_variable", "(", "\n", "'interv_noise'", ",", "\n", "initializer", "=", "tf", ".", "eye", "(", "self", ".", "_u_dim", ",", "num_columns", "=", "self", ".", "_u_dim", ")", ",", "\n", "trainable", "=", "config", ".", "noise_trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.inference_network": [[435, 443], ["models.DKFDynamicSystem.inference_network_basic", "models.DKFDynamicSystem.inference_network_struct"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.inference_network_basic", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.inference_network_struct"], ["", "def", "inference_network", "(", "self", ",", "obs_tensor", ",", "intervention_tensor", ",", "mask_tensor", ",", "\n", "infer_model", ")", ":", "\n", "    ", "if", "infer_model", "==", "'basic'", ":", "\n", "      ", "return", "self", ".", "inference_network_basic", "(", "obs_tensor", ",", "intervention_tensor", ",", "\n", "mask_tensor", ")", "\n", "", "else", ":", "\n", "      ", "return", "self", ".", "inference_network_struct", "(", "obs_tensor", ",", "intervention_tensor", ",", "\n", "mask_tensor", ",", "infer_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.get_mu_sigma_sq": [[444, 468], ["tensorflow.reshape", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.reshape", "tensorflow.math.softplus", "tensorflow.reshape", "tensorflow.layers.dense"], "methods", ["None"], ["", "", "def", "get_mu_sigma_sq", "(", "self", ",", "outputs", ",", "batch_size", ",", "context_size", ",", "name", ")", ":", "\n", "# Pass RNN output to a linear layer then reshape to match.", "\n", "# mu_smooth shape [bs, tlen, _z_dim]", "\n", "    ", "outputs", "=", "tf", ".", "reshape", "(", "outputs", ",", "(", "batch_size", "*", "context_size", ",", "-", "1", ")", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'get_mu_sigma_sq'", "+", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "      ", "mu_smooth", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "outputs", ",", "\n", "units", "=", "self", ".", "_z_dim", ",", "\n", "activation", "=", "None", ",", "\n", "name", "=", "'mu_smooth'", "+", "name", ")", "\n", "mu_smooth", "=", "tf", ".", "reshape", "(", "mu_smooth", ",", "[", "batch_size", ",", "context_size", ",", "self", ".", "_z_dim", "]", ")", "\n", "\n", "# shape [tlen, bs,  _z_dim, _z_dim]", "\n", "sigma_smooth", "=", "tf", ".", "math", ".", "softplus", "(", "\n", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "outputs", ",", "\n", "units", "=", "self", ".", "_z_dim", "*", "self", ".", "_z_dim", ",", "\n", "activation", "=", "None", ",", "\n", "name", "=", "'sigma_smooth'", "+", "name", ")", ")", "\n", "sigma_smooth", "=", "tf", ".", "reshape", "(", "\n", "sigma_smooth", ",", "[", "batch_size", ",", "context_size", ",", "self", ".", "_z_dim", ",", "self", ".", "_z_dim", "]", ")", "\n", "\n", "", "states", "=", "(", "mu_smooth", ",", "sigma_smooth", ")", "\n", "return", "states", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.get_mu_sigma": [[469, 493], ["tensorflow.reshape", "tensorflow.reshape", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.reshape", "tensorflow.math.softplus", "tensorflow.layers.dense"], "methods", ["None"], ["", "def", "get_mu_sigma", "(", "self", ",", "outputs", ",", "batch_size", ",", "context_size", ",", "name", ")", ":", "\n", "# Pass RNN output to a linear layer then reshape to match.", "\n", "# mu_smooth shape [bs, tlen, _z_dim]", "\n", "    ", "outputs", "=", "tf", ".", "reshape", "(", "outputs", ",", "(", "batch_size", "*", "context_size", ",", "-", "1", ")", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'get_mu_sigma'", "+", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "      ", "mu_smooth", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "outputs", ",", "\n", "units", "=", "self", ".", "_z_dim", ",", "\n", "activation", "=", "None", ",", "\n", "name", "=", "'mu_smooth'", "+", "name", ")", "\n", "mu_smooth", "=", "tf", ".", "reshape", "(", "mu_smooth", ",", "[", "batch_size", ",", "context_size", ",", "self", ".", "_z_dim", "]", ")", "\n", "\n", "# shape [tlen, bs,  _z_dim]", "\n", "sigma_smooth", "=", "tf", ".", "math", ".", "softplus", "(", "\n", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "outputs", ",", "\n", "units", "=", "self", ".", "_z_dim", ",", "\n", "activation", "=", "None", ",", "\n", "name", "=", "'sigma_smooth'", "+", "name", ")", ")", "\n", "", "sigma_smooth", "=", "tf", ".", "reshape", "(", "sigma_smooth", ",", "\n", "[", "batch_size", ",", "context_size", ",", "self", ".", "_z_dim", "]", ")", "\n", "\n", "states", "=", "(", "mu_smooth", ",", "sigma_smooth", ")", "\n", "return", "states", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.inference_network_struct": [[494, 628], ["tensorflow.constant", "ValueError", "obs_tensor.get_shape().as_list", "obs_tensor.get_shape().as_list", "tensorflow.concat", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.zeros", "tensorflow.transpose", "models.DKFDynamicSystem.get_mu_sigma_sq", "tensorflow.logging.info", "tensorflow.divide", "tensorflow.divide", "tensorflow.reshape", "tensorflow.logging.info", "tensorflow.variable_scope", "tensorflow.nn.rnn_cell.LSTMCell", "tensorflow.nn.rnn_cell.MultiRNNCell", "tensorflow.nn.rnn_cell.MultiRNNCell.zero_state", "tensorflow.nn.dynamic_rnn", "tensorflow.variable_scope", "tensorflow.nn.rnn_cell.LSTMCell", "tensorflow.nn.rnn_cell.MultiRNNCell", "tensorflow.nn.rnn_cell.MultiRNNCell.zero_state", "tensorflow.nn.dynamic_rnn", "tensorflow.slice", "tensorflow.slice", "tensorflow.zeros", "modules._fully_connected_module", "tensorflow.multiply", "models.DKFDynamicSystem.get_mu_sigma_sq", "tensorflow.squeeze", "tensorflow.squeeze", "tensorflow_probability.distributions.MultivariateNormalTriL", "tensorflow_probability.distributions.MultivariateNormalTriL.sample", "models.DKFDynamicSystem.get_mu_sigma", "models.DKFDynamicSystem.get_mu_sigma", "tensorflow.multiply", "tensorflow.tile", "obs_tensor.get_shape", "obs_tensor.get_shape", "tensorflow.reverse", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.squeeze", "tensorflow.squeeze", "tensorflow.slice", "tensorflow.slice"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.get_mu_sigma_sq", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._fully_connected_module", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.get_mu_sigma_sq", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.get_mu_sigma", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.get_mu_sigma"], ["", "def", "inference_network_struct", "(", "self", ",", "obs_tensor", ",", "intervention_tensor", ",", "\n", "mask_tensor", ",", "infer_model", ")", ":", "\n", "    ", "\"\"\"Inference/Recognition network for encoding obs/interv to states.\n\n    Args:\n      obs_tensor: tensor with shape [bs, tlen, _a_dim].\n      intervention_tensor: tensor with shape [bs, tlen, _u_dim].\n      mask_tensor: tensor with shape [bs, tlen, _a_dim].\n      infer_model:\n\n    Returns:\n      states: a tuple with mu_smooth, sigma_smooth.\n      states[0] is mu_smooth with shape [bs, tlen, _z_dim]\n      states[1] is sigma_smooth with shape [bs, tlen, _z_dim, _z_dim]\n    \"\"\"", "\n", "if", "'l'", "not", "in", "infer_model", "and", "'r'", "not", "in", "infer_model", ":", "\n", "      ", "raise", "ValueError", "(", "'model name missing direction %s'", "%", "infer_model", ")", "\n", "\n", "", "del", "mask_tensor", "\n", "config", "=", "self", ".", "_config", "\n", "batch_size", "=", "obs_tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "context_size", "=", "obs_tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "\n", "if", "intervention_tensor", "is", "not", "None", ":", "\n", "      ", "input_tensor", "=", "tf", ".", "concat", "(", "[", "obs_tensor", ",", "intervention_tensor", "]", ",", "axis", "=", "2", ")", "\n", "", "else", ":", "\n", "      ", "input_tensor", "=", "obs_tensor", "\n", "", "seqlen", "=", "tf", ".", "constant", "(", "context_size", ",", "shape", "=", "[", "batch_size", "]", ")", "\n", "\n", "if", "'l'", "in", "infer_model", ":", "\n", "# 'outputs' is a tensor of shape [batch_size, max_time, cell_state_size]", "\n", "# 'state' is a tensor of shape [batch_size, cell_state_size]", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "'dkf_ds_strl_forward'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "LSTMCell", "(", "config", ".", "ds_state", ")", "\n", "rnn_cells", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "(", "[", "cell", "]", "*", "config", ".", "ds_nrl", ")", "\n", "initial_state", "=", "rnn_cells", ".", "zero_state", "(", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "forward_outputs", ",", "_", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "\n", "rnn_cells", ",", "\n", "input_tensor", ",", "\n", "initial_state", "=", "initial_state", ",", "\n", "sequence_length", "=", "seqlen", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "", "", "if", "'r'", "in", "infer_model", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "'dkf_ds_strl_backward'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "LSTMCell", "(", "config", ".", "ds_state", ")", "\n", "rnn_cells", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "(", "[", "cell", "]", "*", "config", ".", "ds_nrl", ")", "\n", "initial_state", "=", "rnn_cells", ".", "zero_state", "(", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "backward_outputs", ",", "_", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "\n", "rnn_cells", ",", "\n", "tf", ".", "reverse", "(", "input_tensor", ",", "axis", "=", "[", "1", "]", ")", ",", "\n", "initial_state", "=", "initial_state", ",", "\n", "sequence_length", "=", "seqlen", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "", "", "if", "'st'", "in", "infer_model", ":", "\n", "      ", "def", "combine_step_fn", "(", "params", ",", "inputs", ")", ":", "\n", "# z_tm1 shape [bs, self._z_dim]", "\n", "        ", "t", ",", "z_tm1", "=", "params", "\n", "forward_outputs", "=", "tf", ".", "slice", "(", "inputs", ",", "[", "0", ",", "0", ",", "0", "]", ",", "[", "-", "1", ",", "-", "1", ",", "self", ".", "_z_dim", "]", ")", "\n", "backward_outputs", "=", "tf", ".", "slice", "(", "inputs", ",", "[", "0", ",", "0", ",", "self", ".", "_z_dim", "]", ",", "\n", "[", "-", "1", ",", "-", "1", ",", "self", ".", "_z_dim", "]", ")", "\n", "\n", "h_comb", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "self", ".", "_z_dim", "]", ")", "\n", "count", "=", "1", "\n", "if", "'l'", "in", "infer_model", ":", "\n", "          ", "h_comb", "=", "h_comb", "+", "tf", ".", "squeeze", "(", "\n", "tf", ".", "slice", "(", "forward_outputs", ",", "[", "0", ",", "0", ",", "0", "]", ",", "[", "-", "1", ",", "t", ",", "-", "1", "]", ")", ",", "axis", "=", "1", ")", "\n", "count", "=", "count", "+", "1", "\n", "", "if", "'r'", "in", "infer_model", ":", "\n", "          ", "h_comb", "=", "h_comb", "+", "tf", ".", "squeeze", "(", "\n", "tf", ".", "slice", "(", "backward_outputs", ",", "[", "0", ",", "0", ",", "0", "]", ",", "[", "-", "1", ",", "t", ",", "-", "1", "]", ")", ",", "axis", "=", "1", ")", "\n", "count", "=", "count", "+", "1", "\n", "", "z_transform", "=", "modules", ".", "_fully_connected_module", "(", "\n", "input_tensor", "=", "z_tm1", ",", "\n", "num_dense_layers", "=", "1", ",", "\n", "dense_layer_size", "=", "self", ".", "_config", ".", "obs_smlp", ",", "\n", "output_layer_size", "=", "self", ".", "_z_dim", ",", "\n", "output_activation", "=", "tf", ".", "nn", ".", "sigmoid", ",", "\n", "is_training", "=", "True", ",", "\n", "drop_rate", "=", "0", ",", "\n", "name", "=", "'z_transform'", ")", "\n", "\n", "h_comb", "=", "tf", ".", "multiply", "(", "1.0", "/", "count", ",", "z_transform", "+", "h_comb", ")", "\n", "mu_combine", ",", "sigma_combine", "=", "self", ".", "get_mu_sigma_sq", "(", "\n", "h_comb", ",", "batch_size", ",", "1", ",", "'st_scan'", ")", "\n", "mu_combine", "=", "tf", ".", "squeeze", "(", "mu_combine", ",", "axis", "=", "1", ")", "\n", "sigma_combine", "=", "tf", ".", "squeeze", "(", "sigma_combine", ",", "axis", "=", "1", ")", "\n", "\n", "#jitter = 1e-2 * tf.eye(", "\n", "#    tf.shape(sigma_combine)[-1],", "\n", "#    batch_shape=tf.shape(sigma_combine)[0:-2])", "\n", "mvn_combine", "=", "tfp", ".", "distributions", ".", "MultivariateNormalTriL", "(", "\n", "mu_combine", ",", "sigma_combine", ")", "# + jitter)", "\n", "z_t", "=", "mvn_combine", ".", "sample", "(", ")", "\n", "return", "t", ",", "z_t", "\n", "\n", "", "time_first_forward_outputs", "=", "tf", ".", "transpose", "(", "forward_outputs", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "time_first_backward_outputs", "=", "tf", ".", "transpose", "(", "backward_outputs", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "z_0", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "self", ".", "_z_dim", "]", ")", "\n", "#combined_output = tf.scan(", "\n", "#    combine_step_fn,", "\n", "#    (time_first_forward_outputs, time_first_backward_outputs),", "\n", "#    initializer=(0, z_0),", "\n", "#    parallel_iterations=PARALLEL_ITER_SCAN,", "\n", "#    name='combine')", "\n", "combined_output", "=", "forward_outputs", "+", "backward_outputs", "\n", "# time, state = combined_output", "\n", "state", "=", "tf", ".", "transpose", "(", "combined_output", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "combined_states", "=", "self", ".", "get_mu_sigma_sq", "(", "state", ",", "batch_size", ",", "context_size", ",", "\n", "'st'", ")", "\n", "tf", ".", "logging", ".", "info", "(", "combined_states", ")", "\n", "return", "combined_states", "\n", "", "else", ":", "\n", "      ", "if", "'l'", "in", "infer_model", ":", "\n", "        ", "l_state", "=", "self", ".", "get_mu_sigma", "(", "forward_outputs", ",", "batch_size", ",", "context_size", ",", "\n", "'l'", ")", "\n", "if", "'r'", "not", "in", "infer_model", ":", "\n", "          ", "return", "l_state", "\n", "", "", "if", "'r'", "in", "infer_model", ":", "\n", "        ", "r_state", "=", "self", ".", "get_mu_sigma", "(", "backward_outputs", ",", "batch_size", ",", "context_size", ",", "\n", "'r'", ")", "\n", "if", "'l'", "not", "in", "infer_model", ":", "\n", "          ", "return", "r_state", "\n", "", "", "mu_combine", "=", "tf", ".", "divide", "(", "\n", "tf", ".", "multiply", "(", "l_state", "[", "0", "]", ",", "r_state", "[", "1", "]", ")", "+", "\n", "tf", ".", "multiply", "(", "r_state", "[", "0", "]", ",", "l_state", "[", "1", "]", ")", ",", "l_state", "[", "1", "]", "+", "r_state", "[", "1", "]", ")", "\n", "sigma_combine", "=", "tf", ".", "divide", "(", "\n", "tf", ".", "multiply", "(", "l_state", "[", "1", "]", ",", "r_state", "[", "1", "]", ")", ",", "l_state", "[", "1", "]", "+", "r_state", "[", "1", "]", ")", "\n", "sigma_combine_exp", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "tile", "(", "sigma_combine", ",", "[", "1", ",", "1", ",", "self", ".", "_z_dim", "]", ")", ",", "\n", "[", "batch_size", ",", "context_size", ",", "self", ".", "_z_dim", ",", "self", ".", "_z_dim", "]", ")", "\n", "tf", ".", "logging", ".", "info", "(", "mu_combine", ",", "sigma_combine_exp", ")", "\n", "return", "(", "mu_combine", ",", "sigma_combine_exp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.inference_network_basic": [[629, 668], ["tensorflow.constant", "models.DKFDynamicSystem.get_mu_sigma_sq", "obs_tensor.get_shape().as_list", "obs_tensor.get_shape().as_list", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.nn.rnn_cell.LSTMCell", "tensorflow.nn.rnn_cell.MultiRNNCell", "tensorflow.nn.rnn_cell.MultiRNNCell.zero_state", "tensorflow.nn.dynamic_rnn", "obs_tensor.get_shape", "obs_tensor.get_shape"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.get_mu_sigma_sq", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat"], ["", "", "def", "inference_network_basic", "(", "self", ",", "obs_tensor", ",", "intervention_tensor", ",", "\n", "mask_tensor", ")", ":", "\n", "    ", "\"\"\"Inference/Recognition network for encoding obs/interv to states.\n\n    Args:\n      obs_tensor: tensor with shape [bs, tlen, _a_dim].\n      intervention_tensor: tensor with shape [bs, tlen, _u_dim].\n      mask_tensor: tensor with shape [bs, tlen, _a_dim].\n\n    Returns:\n      states: a tuple with mu_smooth, sigma_smooth.\n      states[0] is mu_smooth with shape [bs, tlen, _z_dim]\n      states[1] is sigma_smooth with shape [bs, tlen, _z_dim, _z_dim]\n    \"\"\"", "\n", "del", "mask_tensor", "\n", "config", "=", "self", ".", "_config", "\n", "batch_size", "=", "obs_tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "context_size", "=", "obs_tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "\n", "if", "intervention_tensor", "is", "not", "None", ":", "\n", "      ", "input_tensor", "=", "tf", ".", "concat", "(", "[", "obs_tensor", ",", "intervention_tensor", "]", ",", "axis", "=", "2", ")", "\n", "", "else", ":", "\n", "      ", "input_tensor", "=", "obs_tensor", "\n", "", "seqlen", "=", "tf", ".", "constant", "(", "context_size", ",", "shape", "=", "[", "batch_size", "]", ")", "\n", "\n", "# 'outputs' is a tensor of shape [batch_size, max_time, cell_state_size]", "\n", "# 'state' is a tensor of shape [batch_size, cell_state_size]", "\n", "with", "tf", ".", "variable_scope", "(", "'dkf_ds_encode'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "      ", "cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "LSTMCell", "(", "config", ".", "ds_state", ")", "\n", "rnn_cells", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "(", "[", "cell", "]", "*", "config", ".", "ds_nrl", ")", "\n", "initial_state", "=", "rnn_cells", ".", "zero_state", "(", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "outputs", ",", "_", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "\n", "rnn_cells", ",", "\n", "input_tensor", ",", "\n", "initial_state", "=", "initial_state", ",", "\n", "sequence_length", "=", "seqlen", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "", "return", "self", ".", "get_mu_sigma_sq", "(", "outputs", ",", "batch_size", ",", "context_size", ",", "'basic'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.interv_forecast": [[669, 702], ["tensorflow.zeros", "tensorflow.transpose", "tensorflow.scan", "tensorflow.transpose", "tensorflow.logging.info", "modules._interv_forecast_module", "state.get_shape().as_list", "state.get_shape"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._interv_forecast_module"], ["", "def", "interv_forecast", "(", "self", ",", "state", ")", ":", "\n", "    ", "\"\"\"Intervention forecast function.\n\n    Args:\n      state: state sample with shape [bs, tlen, self._z_dim].\n\n    Returns:\n      interv: interv mean at shape [bs, tlen, self._u_dim].\n    \"\"\"", "\n", "\n", "def", "interv_forecast_step_fn", "(", "previous_output", ",", "current_input", ")", ":", "\n", "      ", "del", "previous_output", "\n", "current_state", "=", "current_input", "\n", "tf", ".", "logging", ".", "info", "(", "current_state", ")", "\n", "next_interv", "=", "modules", ".", "_interv_forecast_module", "(", "current_state", ",", "self", ".", "_u_dim", ",", "\n", "self", ".", "_config", ".", "interv_nmlp", ",", "\n", "self", ".", "_config", ".", "interv_smlp", ",", "\n", "self", ".", "_tag", ")", "\n", "return", "next_interv", "\n", "\n", "", "batch_size", "=", "state", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "init_interv", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "self", ".", "_u_dim", "]", ")", "\n", "# switch batch, tlen dimension for tf.scan.", "\n", "time_first_state", "=", "tf", ".", "transpose", "(", "state", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "next_interv", "=", "tf", ".", "scan", "(", "\n", "interv_forecast_step_fn", ",", "\n", "time_first_state", ",", "\n", "initializer", "=", "(", "init_interv", ")", ",", "\n", "parallel_iterations", "=", "PARALLEL_ITER_SCAN", ",", "\n", "name", "=", "'interv_forecast_scan'", ")", "\n", "# switch batch, tlen dimension back.", "\n", "return", "tf", ".", "transpose", "(", "next_interv", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.obs_emission": [[703, 742], ["tensorflow.zeros", "tensorflow.transpose", "tensorflow.scan", "tensorflow.transpose", "tensorflow.logging.info", "modules._obs_emission_module", "state.get_shape().as_list", "state.get_shape"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._obs_emission_module"], ["", "def", "obs_emission", "(", "self", ",", "state", ")", ":", "\n", "    ", "\"\"\"Observation emission function.\n\n    Args:\n      state: state sample with shape [bs, tlen, self._z_dim].\n\n    Returns:\n      obs: obs mean at shape [bs, tlen, self._a_dim].\n    \"\"\"", "\n", "\n", "def", "obs_emission_step_fn", "(", "previous_output", ",", "current_input", ")", ":", "\n", "      ", "del", "previous_output", "\n", "current_state", "=", "current_input", "\n", "tf", ".", "logging", ".", "info", "(", "current_state", ")", "\n", "if", "self", ".", "_config", ".", "em_act", "==", "'sigmoid'", ":", "\n", "        ", "emission_activation", "=", "tf", ".", "nn", ".", "sigmoid", "\n", "", "else", ":", "\n", "        ", "emission_activation", "=", "None", "\n", "\n", "", "current_obs", "=", "modules", ".", "_obs_emission_module", "(", "current_state", ",", "\n", "self", ".", "_out_obs_dim", ",", "\n", "self", ".", "_config", ".", "obs_nmlp", ",", "\n", "self", ".", "_config", ".", "obs_smlp", ",", "\n", "self", ".", "_tag", ",", "emission_activation", ")", "\n", "return", "current_obs", "\n", "\n", "", "batch_size", "=", "state", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "init_obs", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "self", ".", "_out_obs_dim", "]", ")", "\n", "# switch batch, tlen dimension for tf.scan.", "\n", "time_first_state", "=", "tf", ".", "transpose", "(", "state", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "current_obs", "=", "tf", ".", "scan", "(", "\n", "obs_emission_step_fn", ",", "\n", "time_first_state", ",", "\n", "initializer", "=", "(", "init_obs", ")", ",", "\n", "parallel_iterations", "=", "PARALLEL_ITER_SCAN", ",", "\n", "name", "=", "'obs_emission_scan'", ")", "\n", "# switch batch, tlen dimension back.", "\n", "return", "tf", ".", "transpose", "(", "current_obs", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.state_tran": [[743, 775], ["tensorflow.zeros", "tensorflow.transpose", "tensorflow.scan", "tensorflow.transpose", "modules._state_tran_module", "state.get_shape().as_list", "state.get_shape"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._state_tran_module"], ["", "def", "state_tran", "(", "self", ",", "state", ")", ":", "\n", "    ", "\"\"\"State transition function.\n\n    Args:\n      state: state sample at t-1 shape [bs, (tlen-1), self._z_dim].\n\n    Returns:\n      state: state mean at t  shape [bs, (tlen-1), self._z_dim].\n    \"\"\"", "\n", "\n", "def", "state_tran_step_fn", "(", "previous_output", ",", "current_input", ")", ":", "\n", "      ", "del", "previous_output", "\n", "current_state", "=", "current_input", "\n", "next_state", "=", "modules", ".", "_state_tran_module", "(", "current_state", ",", "self", ".", "_z_dim", ",", "\n", "self", ".", "_config", ".", "stran_nmlp", ",", "\n", "self", ".", "_config", ".", "stran_smlp", ",", "\n", "self", ".", "_tag", ")", "\n", "return", "next_state", "\n", "\n", "", "batch_size", "=", "state", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "init_mu", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "self", ".", "_z_dim", "]", ")", "\n", "# switch batch, tlen dimension for tf.scan.", "\n", "time_first_state", "=", "tf", ".", "transpose", "(", "state", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "next_state", "=", "tf", ".", "scan", "(", "\n", "state_tran_step_fn", ",", "\n", "time_first_state", ",", "\n", "initializer", "=", "(", "init_mu", ")", ",", "\n", "parallel_iterations", "=", "PARALLEL_ITER_SCAN", ",", "\n", "name", "=", "'state_tran_scan'", ")", "\n", "# switch batch, tlen dimension back.", "\n", "return", "tf", ".", "transpose", "(", "next_state", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.control_tran": [[776, 810], ["tensorflow.zeros", "tensorflow.transpose", "tensorflow.scan", "tensorflow.transpose", "modules._control_tran_module", "interv.get_shape().as_list", "interv.get_shape"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._control_tran_module"], ["", "def", "control_tran", "(", "self", ",", "interv", ")", ":", "\n", "    ", "\"\"\"Control transition function.\n\n    Args:\n      interv: interv at t shape [bs, (tlen-1), self._u_dim].\n\n    Returns:\n      state: flattened state mean at t  shape [bs, (tlen-1), self._z_dim].\n    \"\"\"", "\n", "\n", "def", "control_tran_step_fn", "(", "previous_output", ",", "current_input", ")", ":", "\n", "      ", "del", "previous_output", "\n", "current_interv", "=", "current_input", "\n", "# pylint: disable=protected-access", "\n", "next_state", "=", "modules", ".", "_control_tran_module", "(", "\n", "current_interv", ",", "self", ".", "_z_dim", ",", "\n", "self", ".", "_config", ".", "ctran_nmlp", ",", "\n", "self", ".", "_config", ".", "ctran_smlp", ",", "\n", "self", ".", "_tag", ")", "\n", "return", "next_state", "\n", "\n", "", "batch_size", "=", "interv", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "init_mu", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "self", ".", "_z_dim", "]", ")", "\n", "# switch batch, tlen dimension for tf.scan.", "\n", "time_first_interv", "=", "tf", ".", "transpose", "(", "interv", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "next_state", "=", "tf", ".", "scan", "(", "\n", "control_tran_step_fn", ",", "\n", "time_first_interv", ",", "\n", "initializer", "=", "(", "init_mu", ")", ",", "\n", "parallel_iterations", "=", "PARALLEL_ITER_SCAN", ",", "\n", "name", "=", "'control_tran_scan'", ")", "\n", "# switch batch, tlen dimension back.", "\n", "return", "tf", ".", "transpose", "(", "next_state", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.deep_smooth": [[811, 818], ["tensorflow.logging.info", "models.DKFDynamicSystem.inference_network", "tensorflow.logging.info", "tuple"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.inference_network"], ["", "def", "deep_smooth", "(", "self", ",", "obs_tensor", ",", "intervention_tensor", ",", "mask_tensor", ")", ":", "\n", "    ", "\"\"\"Similar to KF smooth, derive state posterior based on observation.\"\"\"", "\n", "tf", ".", "logging", ".", "info", "(", "'deep_smooth'", ")", "\n", "states", "=", "self", ".", "inference_network", "(", "obs_tensor", ",", "intervention_tensor", ",", "\n", "mask_tensor", ",", "self", ".", "_config", ".", "infer_model", ")", "\n", "tf", ".", "logging", ".", "info", "(", "'states'", ")", "\n", "return", "tuple", "(", "states", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem._encode": [[819, 1018], ["models.DKFDynamicSystem._get_train_and_predict_tensors", "models.DKFDynamicSystem.deep_smooth", "models.DKFDynamicSystem.deep_smooth", "tensorflow_probability.distributions.MultivariateNormalTriL.sample", "tensorflow.logging.info", "tensorflow.reshape", "tensorflow.reshape", "MultivariateNormalTriL", "MultivariateNormalTriL.log_prob", "models.DKFDynamicSystem.obs_emission", "tensorflow.reshape", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.multiply", "MultivariateNormalTriL", "MultivariateNormalTriL.log_prob", "tensorflow.zeros", "tensorflow.reshape", "MultivariateNormalTriL", "MultivariateNormalTriL.log_prob", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "dict", "tensorflow.reshape", "tensorflow.concat", "tensorflow.squeeze", "tensorflow.logging.info", "obs_train_tensor.get_shape().as_list", "tensorflow_probability.distributions.MultivariateNormalTriL", "tensorflow_probability.distributions.MultivariateNormalTriL", "tensorflow.zeros", "tensorflow.cholesky", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.zeros", "tensorflow.cholesky", "models.DKFDynamicSystem.interv_forecast", "tensorflow.reshape", "tensorflow.reshape", "MultivariateNormalTriL", "MultivariateNormalTriL.log_prob", "tensorflow.tile", "tensorflow.cholesky", "tensorflow_probability.distributions.MultivariateNormalTriL.log_prob", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.slice", "tensorflow.boolean_mask", "tensorflow.transpose", "tensorflow.eye", "models.DKFDynamicSystem.state_tran", "models.DKFDynamicSystem.control_tran", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tensorflow.zeros", "tensorflow.cholesky", "tensorflow.eye", "tensorflow.constant", "tensorflow.expand_dims", "tensorflow.transpose", "obs_train_tensor.get_shape", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.reduce_mean", "tensorflow.shape", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.Model._get_train_and_predict_tensors", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.deep_smooth", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.deep_smooth", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.obs_emission", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.interv_forecast", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.state_tran", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.control_tran"], ["", "def", "_encode", "(", "self", ",", "tensor_dict", ":", "Dict", "[", "bytes", ",", "tf", ".", "Tensor", "]", ")", "->", "tf", ".", "Tensor", ":", "\n", "    ", "\"\"\"Encode an input tensor based on DKF model.\n\n    Args:\n      tensor_dict: A dict of tensor.\n\n    Returns:\n      dict of network output tensor.\n    \"\"\"", "\n", "train_and_predict_tensors", "=", "self", ".", "_get_train_and_predict_tensors", "(", "\n", "tensor_dict", ",", "self", ".", "_config", ".", "sys_id_len", ")", "\n", "obs_train_tensor", ",", "obs_train_mask_tensor", ",", "intervention_train_tensor", ",", "obs_to_trigger_tensor", ",", "obs_to_trigger_mask_tensor", ",", "intervention_to_trigger_tensor", ",", "biomarker_boolean_mask_tensor", "=", "train_and_predict_tensors", "# pylint:", "\n", "\n", "batch_size", "=", "obs_train_tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "\n", "states", "=", "self", ".", "deep_smooth", "(", "obs_train_tensor", ",", "intervention_train_tensor", ",", "\n", "obs_train_mask_tensor", ")", "\n", "\n", "state_for_prediction", "=", "self", ".", "deep_smooth", "(", "obs_to_trigger_tensor", ",", "\n", "intervention_to_trigger_tensor", ",", "\n", "obs_to_trigger_mask_tensor", ")", "\n", "\n", "# mu_smooth shape [bs, tlen, _z_dim]", "\n", "mu_smooth", "=", "states", "[", "0", "]", "\n", "mu_prediction", "=", "state_for_prediction", "[", "0", "]", "\n", "\n", "# mu_smooth shape [bs, tlen, _z_dim, _z_dim]", "\n", "sigma_smooth", "=", "states", "[", "1", "]", "\n", "sigma_prediction", "=", "state_for_prediction", "[", "1", "]", "\n", "\n", "# Sample from smoothing distribution", "\n", "if", "self", ".", "_config", ".", "use_jitter", ":", "\n", "      ", "jitter", "=", "1e-2", "*", "tf", ".", "eye", "(", "\n", "tf", ".", "shape", "(", "sigma_smooth", ")", "[", "-", "1", "]", ",", "batch_shape", "=", "tf", ".", "shape", "(", "sigma_smooth", ")", "[", "0", ":", "-", "2", "]", ")", "\n", "mvn_smooth", "=", "tfp", ".", "distributions", ".", "MultivariateNormalTriL", "(", "\n", "mu_smooth", ",", "sigma_smooth", "+", "jitter", ")", "\n", "", "else", ":", "\n", "      ", "mvn_smooth", "=", "tfp", ".", "distributions", ".", "MultivariateNormalTriL", "(", "\n", "mu_smooth", ",", "sigma_smooth", ")", "\n", "\n", "# Note the following method is not stable on cholesky op.", "\n", "# mvn_smooth = MultivariateNormalTriL(mu_smooth, tf.cholesky(Sigma_smooth))", "\n", "# z_smooth shape [bs, tlen, _z_dim];", "\n", "", "z_smooth", "=", "mvn_smooth", ".", "sample", "(", ")", "\n", "\n", "# Transition distribution \\prod_{t=2}^T p(z_t|z_{t-1}, u_{t})", "\n", "# We use tm1 to denote t-1;", "\n", "# state_tran_z_tm1 to denote state_tran(z_{t-1}).", "\n", "# control_tran_u_t to denote control_tran(u_t).", "\n", "# We need to evaluate N(z_t; state_tran_z_tm1 + control_tran_u_t, Q)", "\n", "# Roll left to remove the first input", "\n", "# intervention_tensor: [bs, tlen, _u_dim]", "\n", "z_tm1", "=", "z_smooth", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", "u_t", "=", "intervention_train_tensor", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "tf", ".", "logging", ".", "info", "(", "u_t", ")", "\n", "# mu_transition shape [bs * (tlen - 1), _z_dim]", "\n", "mu_transition", "=", "tf", ".", "reshape", "(", "\n", "self", ".", "state_tran", "(", "z_tm1", ")", "+", "self", ".", "control_tran", "(", "u_t", ")", ",", "[", "-", "1", ",", "self", ".", "_z_dim", "]", ")", "\n", "\n", "# z_t_transition [bs * (tlen - 1), _z_dim]", "\n", "z_t_transition", "=", "tf", ".", "reshape", "(", "z_smooth", "[", ":", ",", "1", ":", ",", ":", "]", ",", "[", "-", "1", ",", "self", ".", "_z_dim", "]", ")", "\n", "\n", "# We transform the rand var to be zero-mean:", "\n", "# N(z_t; Az_tm1 + Bu_t, Q) as N(z_t - Az_tm1 - Bu_t; 0, Q)", "\n", "trans_centered", "=", "z_t_transition", "-", "mu_transition", "\n", "# mvn_transition [bs * (tlen - 1), self._z_dim]", "\n", "mvn_transition", "=", "MultivariateNormalTriL", "(", "\n", "tf", ".", "zeros", "(", "self", ".", "_z_dim", ")", ",", "tf", ".", "cholesky", "(", "self", ".", "state_noise", ")", ")", "\n", "# log_prob_transition [bs * (tlen - 1)]", "\n", "log_prob_transition", "=", "mvn_transition", ".", "log_prob", "(", "trans_centered", ")", "\n", "\n", "## Emission distribution \\prod_{t=1}^T p(obs_t|z_t)", "\n", "# We need to evaluate N(y_t; Cz_t, R). We write it as N(y_t - Cz_t; 0, R)", "\n", "# z_smooth shape [bs, tlen, z_dim];", "\n", "# self.obs_emission shape [a_dim, z_dim];", "\n", "# obs_emission_z_t shape [bs, tlen, _a_dim]", "\n", "obs_emission_z_t", "=", "self", ".", "obs_emission", "(", "z_smooth", ")", "\n", "obs_emission_z_t_resh", "=", "tf", ".", "reshape", "(", "obs_emission_z_t", ",", "\n", "[", "-", "1", ",", "self", ".", "_out_obs_dim", "]", ")", "\n", "\n", "# observation tensor reshaped.", "\n", "tf", ".", "logging", ".", "info", "(", "biomarker_boolean_mask_tensor", ")", "# [num_obs]", "\n", "tf", ".", "logging", ".", "info", "(", "obs_train_tensor", ")", "# [bs, tlen, num_obs]", "\n", "y_t_resh", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "transpose", "(", "\n", "tf", ".", "boolean_mask", "(", "\n", "tf", ".", "transpose", "(", "obs_train_tensor", ",", "[", "2", ",", "0", ",", "1", "]", ")", ",", "\n", "biomarker_boolean_mask_tensor", ")", ",", "[", "1", ",", "2", ",", "0", "]", ")", ",", "\n", "[", "-", "1", ",", "self", ".", "_out_obs_dim", "]", ")", "\n", "emiss_centered", "=", "y_t_resh", "-", "obs_emission_z_t_resh", "\n", "mask_flat", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "transpose", "(", "\n", "tf", ".", "boolean_mask", "(", "\n", "tf", ".", "transpose", "(", "obs_train_mask_tensor", ",", "[", "2", ",", "0", ",", "1", "]", ")", ",", "\n", "biomarker_boolean_mask_tensor", ")", ",", "[", "1", ",", "2", ",", "0", "]", ")", ",", "\n", "[", "-", "1", ",", "self", ".", "_out_obs_dim", "]", ")", "\n", "# set missing obs emission center to be zero.", "\n", "# emiss_centered shape [bs * tlen, _a_dim]", "\n", "emiss_centered", "=", "tf", ".", "multiply", "(", "mask_flat", ",", "emiss_centered", ")", "\n", "\n", "mvn_emission", "=", "MultivariateNormalTriL", "(", "\n", "tf", ".", "zeros", "(", "self", ".", "_out_obs_dim", ")", ",", "tf", ".", "cholesky", "(", "self", ".", "obs_noise", ")", ")", "\n", "\n", "# log_prob_emission shape [bs * tlen].", "\n", "log_prob_emission", "=", "mvn_emission", ".", "log_prob", "(", "emiss_centered", ")", "\n", "\n", "if", "self", ".", "_config", ".", "pretrain_interv", ":", "\n", "# Interv distribution \\prod_{t=0}^T-1 p(interv_t+1|z_t)", "\n", "      ", "interv_forecast_z_t", "=", "self", ".", "interv_forecast", "(", "z_tm1", ")", "\n", "interv_forecast_z_t_resh", "=", "tf", ".", "reshape", "(", "interv_forecast_z_t", ",", "\n", "[", "-", "1", ",", "self", ".", "_u_dim", "]", ")", "\n", "u_t_resh", "=", "tf", ".", "reshape", "(", "u_t", ",", "[", "-", "1", ",", "self", ".", "_u_dim", "]", ")", "\n", "\n", "interv_centered", "=", "u_t_resh", "-", "interv_forecast_z_t_resh", "\n", "mvn_interv", "=", "MultivariateNormalTriL", "(", "\n", "tf", ".", "zeros", "(", "self", ".", "_u_dim", ")", ",", "tf", ".", "cholesky", "(", "self", ".", "interv_noise", ")", ")", "\n", "\n", "# log_prob_interv shape [bs * tlen].", "\n", "log_prob_interv", "=", "mvn_interv", ".", "log_prob", "(", "interv_centered", ")", "\n", "\n", "## Distribution of the initial state p(z_1|z_0)", "\n", "", "z_0", "=", "z_smooth", "[", ":", ",", "0", ",", ":", "]", "\n", "init_mu", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "self", ".", "_z_dim", "]", ")", "\n", "init_sigma", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "tile", "(", "\n", "tf", ".", "eye", "(", "self", ".", "_z_dim", ",", "num_columns", "=", "self", ".", "_z_dim", ")", ",", "\n", "tf", ".", "constant", "(", "[", "batch_size", ",", "1", "]", ")", ")", ",", "\n", "[", "batch_size", ",", "self", ".", "_z_dim", ",", "self", ".", "_z_dim", "]", ")", "\n", "mvn_0", "=", "MultivariateNormalTriL", "(", "init_mu", ",", "tf", ".", "cholesky", "(", "init_sigma", ")", ")", "\n", "log_prob_0", "=", "mvn_0", ".", "log_prob", "(", "z_0", ")", "\n", "\n", "# Entropy log(\\prod_{t=1}^T p(z_t|y_{1:T}, u_{1:T}))", "\n", "entropy", "=", "-", "mvn_smooth", ".", "log_prob", "(", "z_smooth", ")", "\n", "entropy", "=", "tf", ".", "reshape", "(", "entropy", ",", "[", "-", "1", "]", ")", "\n", "# entropy = tf.zeros(())", "\n", "\n", "log_probs", "=", "[", "\n", "tf", ".", "reduce_mean", "(", "log_prob_transition", ")", ",", "\n", "tf", ".", "reduce_mean", "(", "log_prob_emission", ")", ",", "\n", "tf", ".", "reduce_mean", "(", "log_prob_0", ")", ",", "\n", "tf", ".", "reduce_mean", "(", "entropy", ")", "\n", "]", "\n", "if", "self", ".", "_config", ".", "pretrain_interv", ":", "\n", "      ", "log_probs", "=", "log_probs", "+", "[", "tf", ".", "reduce_mean", "(", "log_prob_interv", ")", "]", "\n", "\n", "", "kf_elbo", "=", "tf", ".", "reduce_sum", "(", "log_probs", ")", "\n", "\n", "state_loss", "=", "[", "\n", "tf", ".", "reduce_mean", "(", "log_prob_transition", ")", ",", "\n", "tf", ".", "reduce_mean", "(", "log_prob_0", ")", ",", "\n", "tf", ".", "reduce_mean", "(", "entropy", ")", "\n", "]", "\n", "state_only_loss", "=", "tf", ".", "reduce_sum", "(", "state_loss", ")", "\n", "\n", "output", "=", "dict", "(", ")", "\n", "# loss and obs prediction.", "\n", "if", "self", ".", "_config", ".", "sys_id_len", ">", "0", ":", "\n", "      ", "tlen", "=", "self", ".", "_config", ".", "sys_id_len", "\n", "", "else", ":", "\n", "      ", "tlen", "=", "self", ".", "_config", ".", "context_window_size", "\n", "# obs_est starting from t=2", "\n", "# obs_est only for output prediction, not used for loss computation.", "\n", "", "output", "[", "'obs_est'", "]", "=", "tf", ".", "reshape", "(", "obs_emission_z_t", ",", "\n", "[", "-", "1", ",", "tlen", ",", "self", ".", "_out_obs_dim", "]", ")", "\n", "\n", "# mu_smooth shape [bs, tlen, z_dim];", "\n", "# final state_encoding shape [bs, z_dim]", "\n", "output", "[", "'state_encoding'", "]", "=", "mu_prediction", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "\n", "# final state_traj_encoding shape [bs, tlen, z_dim]", "\n", "output", "[", "'state_traj_encoding'", "]", "=", "mu_prediction", "[", ":", ",", ":", ",", ":", "]", "\n", "\n", "# full_state_encoding carries mu_smooth[:, -1, :] and", "\n", "# sigma_smooth [:, -1, :, :] to reconstruct the full distribution.", "\n", "# Its shape is [bs, z_dim, z_dim + 1]", "\n", "output", "[", "'full_state_encoding'", "]", "=", "tf", ".", "concat", "(", "[", "\n", "tf", ".", "expand_dims", "(", "mu_prediction", "[", ":", ",", "-", "1", ",", ":", "]", ",", "axis", "=", "-", "1", ")", ",", "\n", "sigma_prediction", "[", ":", ",", "-", "1", ",", ":", ",", ":", "]", "\n", "]", ",", "\n", "axis", "=", "2", ")", "\n", "if", "self", ".", "_config", ".", "state_only_loss", ":", "\n", "      ", "output", "[", "'loss'", "]", "=", "-", "state_only_loss", "\n", "", "else", ":", "\n", "      ", "output", "[", "'loss'", "]", "=", "-", "kf_elbo", "\n", "# output['last_obs']  shape [bs, _out_obs_dim]", "\n", "", "output", "[", "'last_obs'", "]", "=", "tf", ".", "squeeze", "(", "\n", "tf", ".", "slice", "(", "obs_to_trigger_tensor", ",", "\n", "[", "0", ",", "self", ".", "_config", ".", "context_len_to_trigger", "-", "1", ",", "0", "]", ",", "[", "-", "1", ",", "1", ",", "-", "1", "]", ")", ")", "\n", "if", "self", ".", "_config", ".", "forecast_biomarkers", ":", "\n", "# switch shape to [_out_obs_dim, bs] for applying mask.", "\n", "      ", "output", "[", "'last_obs'", "]", "=", "tf", ".", "boolean_mask", "(", "\n", "tf", ".", "transpose", "(", "output", "[", "'last_obs'", "]", ")", ",", "biomarker_boolean_mask_tensor", ")", "\n", "# transpose shape back.", "\n", "output", "[", "'last_obs'", "]", "=", "tf", ".", "transpose", "(", "output", "[", "'last_obs'", "]", ")", "\n", "\n", "", "output", "[", "'state_loss'", "]", "=", "state_loss", "\n", "\n", "tf", ".", "logging", ".", "info", "(", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.build_model_ops": [[1020, 1123], ["models._build_model", "_build_model.generate_output", "tf.contrib.estimator.multi_head.create_estimator_spec", "sequence_heads.ObservationHead", "output_heads.append", "weights.append", "output_heads.append", "weights.append", "multi_head_for_survival.SurvivalMultiHead", "tensorflow.contrib.estimator.multi_head", "models._get_optimizer", "tensorflow.contrib.slim.learning.create_train_op", "model.generate_output.keys", "tensorflow.layers.dense", "len", "survival_heads.SurvivalHead", "survival_heads.SurvivalHead", "tensorflow.contrib.estimator.binary_classification_head", "tensorflow.contrib.estimator.multi_class_head", "network_output[].get_shape"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models._build_model", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.Model.generate_output", "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel.create_estimator_spec", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models._get_optimizer"], ["", "", "def", "build_model_ops", "(", "features", ":", "Dict", "[", "bytes", ",", "tf", ".", "Tensor", "]", ",", "\n", "labels", ":", "Dict", "[", "bytes", ",", "tf", ".", "Tensor", "]", ",", "\n", "mode", ":", "tf", ".", "contrib", ".", "learn", ".", "ModeKeys", ",", "\n", "params", ":", "experiment_config_pb2", ".", "ModelConfig", "=", "None", ")", ":", "\n", "  ", "\"\"\"Create a model for use with a tf.contrib.learn.Estimator.\n\n  Args:\n    features: Dictionary with keys as feature codes, values representing feature\n      tensor with shape [batch_size, context_window_size].\n    labels: Dictionary with keys as label names, values representing tensor with\n      shape [batch_size].\n    mode: One of {TRAIN,EVAL}.\n    params: ModelConfig that specifies the\n        * model_name: .\n        * labels: a list of Label objects.\n\n  Returns:\n    An instance of tf.contrib.learn.ModelFnOps.\n  \"\"\"", "\n", "model", "=", "_build_model", "(", "params", ".", "model_name", ",", "mode", ",", "config", "=", "params", ")", "\n", "network_output", "=", "model", ".", "generate_output", "(", "features", ")", "\n", "output_heads", "=", "[", "]", "\n", "logits_dict", "=", "{", "}", "\n", "logits_dimension", "=", "params", ".", "logits_dimension", "\n", "weights", "=", "[", "]", "\n", "\n", "if", "params", ".", "is_dynamic_system_model", ":", "\n", "    ", "head", "=", "sequence_heads", ".", "ObservationHead", "(", "\n", "name", "=", "'system_id'", ",", "model_hparams", "=", "params", ")", "\n", "output_heads", ".", "append", "(", "head", ")", "\n", "# loss", "\n", "logits_dict", "[", "'system_id'", "]", "=", "network_output", "[", "'obs_est'", "]", "\n", "if", "'loss'", "in", "network_output", ".", "keys", "(", ")", ":", "\n", "# loss is passed to network output in KF encoder.", "\n", "      ", "logits_dict", "[", "'system_id'", "]", "=", "(", "logits_dict", "[", "'system_id'", "]", ",", "\n", "network_output", "[", "'loss'", "]", ")", "\n", "", "if", "labels", "is", "not", "None", ":", "\n", "      ", "labels", "[", "'system_id'", "]", "=", "features", "\n", "", "weights", ".", "append", "(", "params", ".", "sys_id_weight", ")", "\n", "\n", "", "for", "label", "in", "params", ".", "labels", ":", "\n", "    ", "if", "params", ".", "is_survival_model", ":", "\n", "      ", "if", "params", ".", "model_name", "==", "'mri'", ":", "\n", "        ", "logits_dimension", "=", "network_output", "[", "'state_encoding'", "]", ".", "get_shape", "(", ")", "[", "1", "]", "\n", "", "if", "label", ".", "survival_model_name", "==", "'correlated'", ":", "\n", "# logits_dimension for each head is the same as number of events", "\n", "# for correlated events, as all event rates will be used to compute", "\n", "# loss and prediction. The logits for each head are transformed from", "\n", "# raw network output logits, which have the same dimension as number of", "\n", "# relations.", "\n", "        ", "logits_dimension", "=", "len", "(", "params", ".", "labels", ")", "\n", "head", "=", "survival_heads", ".", "SurvivalHead", "(", "\n", "name", "=", "label", ".", "name", ",", "\n", "survival_model_name", "=", "label", ".", "survival_model_name", ",", "\n", "label_dimension", "=", "logits_dimension", ",", "\n", "model_hparams", "=", "params", ",", "\n", "all_event_list", "=", "[", "l", ".", "name", "for", "l", "in", "params", ".", "labels", "]", ")", "\n", "", "else", ":", "\n", "        ", "head", "=", "survival_heads", ".", "SurvivalHead", "(", "\n", "name", "=", "label", ".", "name", ",", "\n", "survival_model_name", "=", "label", ".", "survival_model_name", ",", "\n", "label_dimension", "=", "logits_dimension", ",", "\n", "model_hparams", "=", "params", ",", "\n", "all_event_list", "=", "None", ")", "\n", "", "", "elif", "label", ".", "num_classes", "==", "2", ":", "\n", "      ", "head", "=", "tf", ".", "contrib", ".", "estimator", ".", "binary_classification_head", "(", "name", "=", "label", ".", "name", ")", "\n", "", "else", ":", "\n", "      ", "head", "=", "tf", ".", "contrib", ".", "estimator", ".", "multi_class_head", "(", "\n", "n_classes", "=", "label", ".", "num_classes", ",", "name", "=", "label", ".", "name", ")", "\n", "logits_dimension", "=", "label", ".", "num_classes", "\n", "", "output_heads", ".", "append", "(", "head", ")", "\n", "\n", "if", "params", ".", "model_name", "==", "'mri'", "and", "params", ".", "is_survival_model", ":", "\n", "      ", "logits", "=", "network_output", "[", "'state_encoding'", "]", "\n", "", "else", ":", "\n", "      ", "logits", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "network_output", "[", "'state_encoding'", "]", ",", "\n", "units", "=", "logits_dimension", ",", "\n", "activation", "=", "None", ")", "\n", "", "logits_dict", "[", "label", ".", "name", "]", "=", "logits", "\n", "weights", ".", "append", "(", "label", ".", "weight", ")", "\n", "\n", "# collect all_heads.", "\n", "", "if", "params", ".", "is_survival_model", ":", "\n", "    ", "all_heads", "=", "multi_head", ".", "SurvivalMultiHead", "(", "\n", "heads", "=", "output_heads", ",", "head_weights", "=", "weights", ")", "\n", "", "else", ":", "\n", "    ", "all_heads", "=", "tf", ".", "contrib", ".", "estimator", ".", "multi_head", "(", "output_heads", ",", "weights", ")", "\n", "\n", "", "def", "train_op_fn", "(", "loss", ")", ":", "\n", "    ", "optimizer", "=", "_get_optimizer", "(", "\n", "params", ".", "optimizer", ".", "name", ",", "\n", "learning_rate", "=", "params", ".", "learning_rate", ",", "\n", "momentum", "=", "params", ".", "optimizer", ".", "momentum", ")", "\n", "\n", "return", "slim", ".", "learning", ".", "create_train_op", "(", "loss", ",", "optimizer", ")", "\n", "\n", "", "return", "all_heads", ".", "create_estimator_spec", "(", "\n", "features", "=", "features", ",", "\n", "mode", "=", "mode", ",", "\n", "logits", "=", "logits_dict", ",", "\n", "labels", "=", "labels", ",", "\n", "train_op_fn", "=", "train_op_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models._build_model": [[1133, 1151], ["model_obj", "ValueError", "name.lower"], "function", ["None"], ["def", "_build_model", "(", "name", ":", "bytes", ",", "\n", "mode", ":", "tf", ".", "contrib", ".", "learn", ".", "ModeKeys", ",", "\n", "config", ":", "experiment_config_pb2", ".", "ModelConfig", "=", "None", ")", ":", "\n", "  ", "\"\"\"Constructs a model by name.\n\n  Args:\n    name: Model name.\n    mode: One of {TRAIN,EVAL}.\n    config: Model config.\n\n  Returns:\n    An instance of the Encoder class, created with `config`.\n  \"\"\"", "\n", "try", ":", "\n", "    ", "model_obj", "=", "MODEL_MAP", "[", "name", ".", "lower", "(", ")", "]", "\n", "return", "model_obj", "(", "mode", ",", "config", "=", "config", ")", "\n", "", "except", "KeyError", ":", "\n", "    ", "raise", "ValueError", "(", "'Unrecognized model name %s'", "%", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models._get_optimizer": [[1153, 1178], ["name.lower", "tensorflow.train.GradientDescentOptimizer", "tensorflow.train.MomentumOptimizer", "tensorflow.train.RMSPropOptimizer", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdagradOptimizer", "ValueError"], "function", ["None"], ["", "", "def", "_get_optimizer", "(", "name", ",", "learning_rate", ",", "momentum", "=", "None", ")", ":", "\n", "  ", "\"\"\"Constructs an optimizer by name.\n\n  Args:\n    name: Optimizer name.\n    learning_rate: learning rate.\n    momentum: Default to None. Only used when optimizer name is 'momentum' or\n      'rmsprop'\n\n  Returns:\n    An optimizer with the given name and learning rate.\n  \"\"\"", "\n", "optimizer_name", "=", "name", ".", "lower", "(", ")", "\n", "if", "optimizer_name", "==", "'sgd'", ":", "\n", "    ", "return", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "learning_rate", ")", "\n", "", "elif", "optimizer_name", "==", "'momentum'", ":", "\n", "    ", "return", "tf", ".", "train", ".", "MomentumOptimizer", "(", "learning_rate", ",", "momentum", "=", "momentum", ")", "\n", "", "elif", "optimizer_name", "==", "'rmsprop'", ":", "\n", "    ", "return", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "learning_rate", ",", "momentum", "=", "momentum", ")", "\n", "", "elif", "optimizer_name", "==", "'adam'", ":", "\n", "    ", "return", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", ")", "\n", "", "elif", "optimizer_name", "==", "'adagrad'", ":", "\n", "    ", "return", "tf", ".", "train", ".", "AdagradOptimizer", "(", "learning_rate", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "'Unrecognized optimizer \"%s\"!'", "%", "name", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.sequence_heads.ObservationHead.__init__": [[35, 55], ["tensorflow.logging.info", "tensorflow.logging.info", "sequence_heads.ObservationHead._summary_key", "sequence_heads.ObservationHead._summary_key", "sequence_heads.ObservationHead._summary_key", "sequence_heads.ObservationHead._summary_key", "sequence_heads.ObservationHead._summary_key"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "weight_column", "=", "None", ",", "\n", "label_dimension", "=", "1", ",", "\n", "loss_reduction", "=", "tf", ".", "losses", ".", "Reduction", ".", "SUM_OVER_BATCH_SIZE", ",", "\n", "name", "=", "None", ",", "\n", "model_hparams", "=", "None", ")", ":", "\n", "    ", "self", ".", "_weight_column", "=", "weight_column", "\n", "self", ".", "_logits_dimension", "=", "label_dimension", "\n", "tf", ".", "logging", ".", "info", "(", "self", ".", "_logits_dimension", ")", "\n", "self", ".", "_loss_reduction", "=", "loss_reduction", "\n", "self", ".", "_name", "=", "name", "\n", "self", ".", "_model_hparams", "=", "model_hparams", "\n", "tf", ".", "logging", ".", "info", "(", "self", ".", "_model_hparams", ")", "\n", "# Metric keys.", "\n", "keys", "=", "metric_keys", ".", "MetricKeys", "\n", "self", ".", "_loss_mean_key", "=", "self", ".", "_summary_key", "(", "keys", ".", "LOSS_MEAN", ")", "\n", "self", ".", "_prediction_mean_key", "=", "self", ".", "_summary_key", "(", "keys", ".", "PREDICTION_MEAN", ")", "\n", "self", ".", "_label_mean_key", "=", "self", ".", "_summary_key", "(", "keys", ".", "LABEL_MEAN", ")", "\n", "self", ".", "_loss_regularization_key", "=", "self", ".", "_summary_key", "(", "keys", ".", "LOSS_REGULARIZATION", ")", "\n", "self", ".", "_mean_abs_error", "=", "self", ".", "_summary_key", "(", "MEAN_ABS_ERROR", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.sequence_heads.ObservationHead.name": [[56, 60], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "    ", "\"\"\"See `base_head.Head` for details.\"\"\"", "\n", "return", "self", ".", "_name", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.sequence_heads.ObservationHead.logits_dimension": [[61, 65], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "logits_dimension", "(", "self", ")", ":", "\n", "    ", "\"\"\"See `base_head.Head` for details.\"\"\"", "\n", "return", "self", ".", "_logits_dimension", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.sequence_heads.ObservationHead.loss_reduction": [[66, 70], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "loss_reduction", "(", "self", ")", ":", "\n", "    ", "\"\"\"See `base_head.Head` for details.\"\"\"", "\n", "return", "self", ".", "_loss_reduction", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.sequence_heads.ObservationHead._processed_labels": [[71, 95], ["tensorflow.concat", "tensorflow.roll", "ValueError", "tensorflow.expand_dims"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat"], ["", "def", "_processed_labels", "(", "self", ",", "logits", ",", "labels", ",", "features", ")", ":", "\n", "    ", "\"\"\"Converts labels to ground truth observation sequence.\n\n    Args:\n      logits: estimated obs. value, [batch, time_len, num_obs] tensor.\n      labels: dict with obs and interv. code as keys and tensor with shape\n        [batch, context_window_size] as value.\n      features: dict from feature names to tensors.\n\n    Returns:\n      tensor for obs with shape [batch, context_window_size -1, num_obs], which\n      rolls the input obs left for one time slot. Note that the last obs label\n      comes from the first obs, which is invalid as label.\n    \"\"\"", "\n", "del", "logits", "\n", "if", "labels", "is", "None", ":", "\n", "      ", "raise", "ValueError", "(", "base_head", ".", "_LABEL_NONE_ERR_MSG", ")", "# pylint: disable=protected-access", "\n", "", "obs_tensor", "=", "tf", ".", "concat", "(", "[", "\n", "tf", ".", "expand_dims", "(", "labels", "[", "obs", "]", ",", "2", ")", "\n", "for", "obs", "in", "self", ".", "_model_hparams", ".", "observation_codes", "\n", "]", ",", "\n", "axis", "=", "2", ")", "\n", "# Shift the label observation tensor towards left for one time slot.", "\n", "return", "tf", ".", "roll", "(", "obs_tensor", ",", "shift", "=", "-", "1", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.sequence_heads.ObservationHead._unweighted_loss_and_weights": [[96, 166], ["tensorflow.slice", "tensorflow.slice", "tensorflow.multiply", "tensorflow.reduce_mean", "tensorflow.sequence_mask", "tensorflow.multiply", "tensorflow.div_no_nan", "tensorflow.python.ops.math_ops.reduce_mean", "tensorflow_estimator.python.estimator.head.base_head.get_weights_and_check_match_logits", "tensorflow.concat", "tensorflow.ones_like", "tensorflow.reduce_max", "tensorflow.fill", "tensorflow.square", "tensorflow.cast", "tensorflow.sequence_mask", "tensorflow.cast", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "logits.get_shape().as_list", "tensorflow.logical_xor", "tensorflow.expand_dims", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat"], ["", "def", "_unweighted_loss_and_weights", "(", "self", ",", "logits", ",", "processed_labels", ",", "features", ",", "\n", "mode", ")", ":", "\n", "    ", "\"\"\"Computes loss spec.\"\"\"", "\n", "if", "self", ".", "_model_hparams", ".", "model_name", "in", "STATE_SPACE_MODELS", ":", "\n", "      ", "_", ",", "loss", "=", "logits", "\n", "return", "loss", ",", "1", "\n", "\n", "", "if", "self", ".", "_model_hparams", ".", "has_mask", ":", "\n", "      ", "mask_obs_tensor", "=", "tf", ".", "concat", "(", "[", "\n", "tf", ".", "expand_dims", "(", "features", "[", "obs", "+", "'_mask'", "]", ",", "2", ")", "\n", "for", "obs", "in", "self", ".", "_model_hparams", ".", "observation_codes", "\n", "]", ",", "\n", "axis", "=", "2", ")", "\n", "", "else", ":", "\n", "      ", "mask_obs_tensor", "=", "tf", ".", "ones_like", "(", "processed_labels", ")", "\n", "\n", "", "if", "self", ".", "_model_hparams", ".", "has_mask", ":", "\n", "      ", "true_len_hr", "=", "features", "[", "'true_length_hr'", "]", "\n", "seqlen", "=", "tf", ".", "reduce_max", "(", "true_len_hr", ")", "\n", "", "else", ":", "\n", "      ", "batch_size", "=", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "true_len_hr", "=", "tf", ".", "fill", "(", "[", "batch_size", "]", ",", "\n", "self", ".", "_model_hparams", ".", "context_window_size", ")", "\n", "seqlen", "=", "self", ".", "_model_hparams", ".", "context_window_size", "\n", "", "if", "self", ".", "_model_hparams", ".", "model_name", "==", "'lstm_ds'", ":", "\n", "      ", "seqlen", "=", "seqlen", "-", "1", "\n", "\n", "# processed_labels is not trimmed with true len with", "\n", "# [batch, context_window_size -1, num_obs]", "\n", "# logit is trimmed with seqlen with shape [batch, seqlen, num_obs]", "\n", "# batch_time_value_loss shape [batch, seqlen]", "\n", "# seqlen is #values, if seqlen = 5, there are 5 values for each feature.", "\n", "# trimmed_processed_labels shape [batch, seqlen, num_obs]", "\n", "", "trimmed_processed_labels", "=", "tf", ".", "slice", "(", "processed_labels", ",", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "-", "1", ",", "seqlen", ",", "-", "1", "]", ")", "\n", "trimmed_mask_obs_tensor", "=", "tf", ".", "slice", "(", "mask_obs_tensor", ",", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "-", "1", ",", "seqlen", ",", "-", "1", "]", ")", "\n", "\n", "# Compute L2 value loss based on true sequence len/windown size and obs val.", "\n", "batch_time_feature_loss", "=", "tf", ".", "multiply", "(", "\n", "tf", ".", "square", "(", "trimmed_processed_labels", "-", "logits", ")", ",", "trimmed_mask_obs_tensor", ")", "\n", "batch_time_value_loss", "=", "tf", ".", "reduce_mean", "(", "batch_time_feature_loss", ",", "axis", "=", "2", ")", "\n", "\n", "# self._model_hparams.last_obs_len is the num of most recent observations", "\n", "# used for computing loss.", "\n", "# batch_value_loss shape [batch, 1].", "\n", "last_obs_len", "=", "self", ".", "_model_hparams", ".", "last_obs_len", "\n", "assert", "last_obs_len", "<", "self", ".", "_model_hparams", ".", "context_window_size", "\n", "\n", "# zero out the loss outside [seqlen-last_obs_len, seqlen].", "\n", "true_len_mask", "=", "tf", ".", "sequence_mask", "(", "true_len_hr", ",", "seqlen", ")", "\n", "if", "last_obs_len", "==", "-", "1", ":", "\n", "# all obs up to true len are included.", "\n", "      ", "selection_mask", "=", "tf", ".", "cast", "(", "true_len_mask", ",", "tf", ".", "float32", ")", "\n", "", "else", ":", "\n", "      ", "last_obs_len_mask", "=", "tf", ".", "sequence_mask", "(", "true_len_hr", "-", "last_obs_len", ",", "seqlen", ")", "\n", "selection_mask", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "logical_xor", "(", "true_len_mask", ",", "last_obs_len_mask", ")", ",", "tf", ".", "float32", ")", "\n", "\n", "", "trimmed_batch_time_value_loss", "=", "tf", ".", "multiply", "(", "batch_time_value_loss", ",", "\n", "selection_mask", ")", "\n", "batch_value_loss", "=", "tf", ".", "div_no_nan", "(", "\n", "tf", ".", "reduce_sum", "(", "trimmed_batch_time_value_loss", ",", "axis", "=", "1", ")", ",", "\n", "tf", ".", "reduce_sum", "(", "selection_mask", ",", "axis", "=", "1", ")", ")", "\n", "\n", "scalar_loss", "=", "math_ops", ".", "reduce_mean", "(", "batch_value_loss", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "\n", "weights", "=", "base_head", ".", "get_weights_and_check_match_logits", "(", "\n", "features", "=", "features", ",", "weight_column", "=", "self", ".", "_weight_column", ",", "logits", "=", "logits", ")", "\n", "return", "scalar_loss", ",", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.sequence_heads.ObservationHead.loss": [[167, 205], ["tensorflow.python.framework.ops.name_scope", "sequence_heads.ObservationHead._processed_labels", "sequence_heads.ObservationHead._unweighted_loss_and_weights", "tensorflow.losses.compute_weighted_loss", "tensorflow.python.ops.math_ops.add_n"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._processed_labels", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._unweighted_loss_and_weights"], ["", "def", "loss", "(", "self", ",", "\n", "logits", ",", "\n", "labels", ",", "\n", "features", "=", "None", ",", "\n", "mode", "=", "None", ",", "\n", "regularization_losses", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute Loss.\n\n    Args:\n      logits: estimated obs. value, [batch, context_window_size, num_obs]\n        tensor.\n      labels: ground truth observation, feature dict with obs. and interv. codes\n        as keys, values tensor with shape [batch_size, context_window_size].\n      features: dict with feature name strings as key, tensor as value.\n      mode: see base_head.Head.\n      regularization_losses: see base_head.Head.\n\n    Returns:\n      regularized_training_loss: see base_head.Head.\n    \"\"\"", "\n", "with", "ops", ".", "name_scope", "(", "\n", "'losses'", ",", "values", "=", "(", "logits", ",", "labels", ",", "regularization_losses", ",", "features", ")", ")", ":", "\n", "# processed_labels is a [batch, time_len, num_obs] tensor.", "\n", "      ", "processed_labels", "=", "self", ".", "_processed_labels", "(", "logits", ",", "labels", ",", "features", ")", "\n", "unweighted_loss", ",", "weights", "=", "self", ".", "_unweighted_loss_and_weights", "(", "\n", "logits", ",", "processed_labels", ",", "features", ",", "mode", ")", "\n", "training_loss", "=", "tf", ".", "losses", ".", "compute_weighted_loss", "(", "\n", "unweighted_loss", ",", "weights", "=", "weights", ",", "reduction", "=", "self", ".", "_loss_reduction", ")", "\n", "if", "regularization_losses", "is", "None", ":", "\n", "        ", "regularization_loss", "=", "None", "\n", "", "else", ":", "\n", "        ", "regularization_loss", "=", "math_ops", ".", "add_n", "(", "regularization_losses", ")", "\n", "", "if", "regularization_loss", "is", "None", ":", "\n", "        ", "regularized_training_loss", "=", "training_loss", "\n", "", "else", ":", "\n", "        ", "regularized_training_loss", "=", "training_loss", "+", "regularization_loss", "\n", "\n", "", "", "return", "regularized_training_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.sequence_heads.ObservationHead.predictions": [[206, 235], ["tensorflow_estimator.python.estimator.head.base_head.check_prediction_keys", "tensorflow.python.framework.ops.name_scope"], "methods", ["None"], ["", "def", "predictions", "(", "self", ",", "logits", ",", "keys", "=", "None", ")", ":", "\n", "    ", "\"\"\"Return predictions based on keys.\n\n    Args:\n      logits: estimated obs. value, [batch, time_len, num_obs] tensor.\n      keys: a list of prediction keys. Key can be either the class variable\n        of prediction_keys.PredictionKeys or its string value, such as:\n          prediction_keys.PredictionKeys.LOGITS or 'logits'.\n\n    Returns:\n      predictions: the predicted values for the last_obs_len number of obs.\n    \"\"\"", "\n", "pred_keys", "=", "prediction_keys", ".", "PredictionKeys", "\n", "valid_keys", "=", "[", "pred_keys", ".", "LOGITS", ",", "pred_keys", ".", "PROBABILITIES", "]", "\n", "if", "keys", ":", "\n", "      ", "base_head", ".", "check_prediction_keys", "(", "keys", ",", "valid_keys", ")", "\n", "", "else", ":", "\n", "      ", "keys", "=", "valid_keys", "\n", "# pred shape [bs, self._config.context_window_size, self._a_dim]", "\n", "", "if", "self", ".", "_model_hparams", ".", "model_name", "in", "STATE_SPACE_MODELS", ":", "\n", "      ", "obs_est", ",", "_", "=", "logits", "\n", "", "else", ":", "\n", "      ", "obs_est", "=", "logits", "\n", "", "predictions", "=", "{", "}", "\n", "with", "ops", ".", "name_scope", "(", "'predictions'", ",", "values", "=", "(", "logits", ",", ")", ")", ":", "\n", "      ", "if", "pred_keys", ".", "LOGITS", "in", "keys", ":", "\n", "        ", "predictions", "[", "pred_keys", ".", "LOGITS", "]", "=", "obs_est", "[", ":", ",", "(", "\n", "-", "1", "-", "self", ".", "_model_hparams", ".", "last_obs_len", ")", ":", "-", "1", ",", ":", "]", "\n", "", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.sequence_heads.ObservationHead.metrics": [[236, 253], ["tensorflow.python.framework.ops.name_scope", "tensorflow.python.keras.metrics.Mean", "tensorflow.python.keras.metrics.Mean", "tensorflow.python.keras.metrics.Mean", "tensorflow.python.keras.metrics.MeanAbsoluteError", "tensorflow.python.keras.metrics.Mean"], "methods", ["None"], ["", "", "def", "metrics", "(", "self", ",", "regularization_losses", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates metrics. See `base_head.Head` for details.\"\"\"", "\n", "keys", "=", "metric_keys", ".", "MetricKeys", "\n", "with", "ops", ".", "name_scope", "(", "'metrics'", ",", "values", "=", "(", "regularization_losses", ",", ")", ")", ":", "\n", "# Mean metric.", "\n", "      ", "eval_metrics", "=", "{", "}", "\n", "eval_metrics", "[", "self", ".", "_loss_mean_key", "]", "=", "metrics", ".", "Mean", "(", "name", "=", "keys", ".", "LOSS_MEAN", ")", "\n", "eval_metrics", "[", "self", ".", "_prediction_mean_key", "]", "=", "metrics", ".", "Mean", "(", "\n", "name", "=", "keys", ".", "PREDICTION_MEAN", ")", "\n", "eval_metrics", "[", "self", ".", "_label_mean_key", "]", "=", "metrics", ".", "Mean", "(", "name", "=", "keys", ".", "LABEL_MEAN", ")", "\n", "if", "regularization_losses", "is", "not", "None", ":", "\n", "        ", "eval_metrics", "[", "self", ".", "_loss_regularization_key", "]", "=", "metrics", ".", "Mean", "(", "\n", "name", "=", "keys", ".", "LOSS_REGULARIZATION", ")", "\n", "", "eval_metrics", "[", "self", ".", "_mean_abs_error", "]", "=", "metrics", ".", "MeanAbsoluteError", "(", "\n", "name", "=", "MEAN_ABS_ERROR", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "", "return", "eval_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.sequence_heads.ObservationHead.update_metrics": [[254, 299], ["sequence_heads.ObservationHead._processed_labels", "sequence_heads.ObservationHead._unweighted_loss_and_weights", "eval_metrics[].update_state", "sequence_heads.ObservationHead.predictions", "tensorflow_estimator.python.estimator.head.base_head.update_metric_with_broadcast_weights", "eval_metrics[].update_state", "tensorflow_estimator.python.estimator.head.base_head.update_metric_with_broadcast_weights", "tensorflow.python.ops.math_ops.add_n", "eval_metrics[].update_state"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._processed_labels", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._unweighted_loss_and_weights", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead.predictions"], ["", "def", "update_metrics", "(", "self", ",", "\n", "eval_metrics", ",", "\n", "features", ",", "\n", "logits", ",", "\n", "labels", ",", "\n", "regularization_losses", "=", "None", ")", ":", "\n", "    ", "\"\"\"Updates eval metrics.\n\n    Args:\n      eval_metrics: See `base_head.Head` for details.\n      features: dict with feature name strings as key, tensor as value.\n      logits: estimated obs. value, [batch, time_len, num_obs] tensor.\n      labels: ground truth observation, feature dict with obs. and interv. codes\n        as keys, values tensor with shape [batch_size, context_window_size].\n      regularization_losses: See `base_head.Head` for details.\n\n    Returns:\n      eval_metrics: See `base_head.Head` for details.\n    \"\"\"", "\n", "processed_labels", "=", "self", ".", "_processed_labels", "(", "logits", ",", "labels", ",", "features", ")", "\n", "unweighted_loss", ",", "weights", "=", "self", ".", "_unweighted_loss_and_weights", "(", "\n", "logits", ",", "processed_labels", ",", "features", ",", "mode", "=", "model_fn", ".", "ModeKeys", ".", "EVAL", ")", "\n", "# Update metrics.", "\n", "eval_metrics", "[", "self", ".", "_loss_mean_key", "]", ".", "update_state", "(", "\n", "values", "=", "unweighted_loss", ",", "sample_weight", "=", "weights", ")", "\n", "value_key", "=", "prediction_keys", ".", "PredictionKeys", ".", "LOGITS", "\n", "predictions", "=", "self", ".", "predictions", "(", "logits", ",", "[", "value_key", "]", ")", "\n", "value_predictions", "=", "predictions", "[", "value_key", "]", "\n", "\n", "base_head", ".", "update_metric_with_broadcast_weights", "(", "\n", "eval_metrics", "[", "self", ".", "_prediction_mean_key", "]", ",", "value_predictions", ",", "weights", ")", "\n", "eval_metrics", "[", "self", ".", "_mean_abs_error", "]", ".", "update_state", "(", "\n", "processed_labels", "[", ":", ",", "(", "-", "1", "-", "self", ".", "_model_hparams", ".", "last_obs_len", ")", ":", "-", "1", ",", ":", "]", ",", "\n", "value_predictions", ")", "\n", "\n", "# label_mean represents the percentage of censored events. In case of", "\n", "# mortality, it is the percentage of survived patients.", "\n", "base_head", ".", "update_metric_with_broadcast_weights", "(", "\n", "eval_metrics", "[", "self", ".", "_label_mean_key", "]", ",", "processed_labels", ",", "weights", ")", "\n", "\n", "if", "regularization_losses", "is", "not", "None", ":", "\n", "      ", "regularization_loss", "=", "math_ops", ".", "add_n", "(", "regularization_losses", ")", "\n", "eval_metrics", "[", "self", ".", "_loss_regularization_key", "]", ".", "update_state", "(", "\n", "values", "=", "regularization_loss", ")", "\n", "", "return", "eval_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.sequence_heads.ObservationHead._create_tpu_estimator_spec": [[300, 399], ["tensorflow_estimator.python.estimator.head.base_head.create_estimator_spec_summary", "tensorflow_estimator.python.estimator.model_fn._TPUEstimatorSpec", "tensorflow.python.framework.ops.name_scope", "sequence_heads.ObservationHead.predictions", "sequence_heads.ObservationHead.loss", "tensorflow_estimator.python.estimator.head.base_head.create_estimator_spec_train_op", "tensorflow_estimator.python.estimator.model_fn._TPUEstimatorSpec", "sequence_heads.ObservationHead.metrics", "tensorflow_estimator.python.estimator.model_fn._TPUEstimatorSpec", "tensorflow_estimator.python.estimator.head.base_head.create_eval_metrics_tuple", "tensorflow_estimator.python.estimator.export.export_output.PredictOutput", "tensorflow_estimator.python.estimator.export.export_output.PredictOutput"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead.predictions", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.multi_head_for_survival.SurvivalMultiHead.loss", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead.metrics"], ["", "def", "_create_tpu_estimator_spec", "(", "self", ",", "\n", "features", ",", "\n", "mode", ",", "\n", "logits", ",", "\n", "labels", "=", "None", ",", "\n", "optimizer", "=", "None", ",", "\n", "trainable_variables", "=", "None", ",", "\n", "train_op_fn", "=", "None", ",", "\n", "update_ops", "=", "None", ",", "\n", "regularization_losses", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns an `model_fn._TPUEstimatorSpec`.\n\n    Args:\n      features: Input `dict` of `Tensor` or `SparseTensor` objects.\n      mode: Estimator's `ModeKeys`.\n      logits: estimated obs. value, [batch, time_len, num_obs] tensor.\n      labels: ground truth observation, feature dict with obs. and interv. codes\n        as keys, values tensor with shape [batch_size, context_window_size].\n      optimizer: An `tf.keras.optimizers.Optimizer` instance to optimize the\n        loss in TRAIN mode. Namely, sets `train_op = optimizer.get_updates(loss,\n        trainable_variables)`, which updates variables to minimize `loss`.\n      trainable_variables: A list or tuple of `Variable` objects to update to\n        minimize `loss`. In Tensorflow 1.x, by default these are the list of\n        variables collected in the graph under the key\n        `GraphKeys.TRAINABLE_VARIABLES`. As Tensorflow 2.x doesn't have\n        collections and GraphKeys, trainable_variables need to be passed\n        explicitly here.\n      train_op_fn: Function that takes a scalar loss `Tensor` and returns\n        `train_op`. Used if `optimizer` is `None`.\n      update_ops: A list or tuple of update ops to be run at training time. For\n        example, layers such as BatchNormalization create mean and variance\n        update ops that need to be run at training time. In Tensorflow 1.x,\n        these are thrown into an UPDATE_OPS collection. As Tensorflow 2.x\n        doesn't have collections, update_ops need to be passed explicitly here.\n      regularization_losses: A list of additional scalar losses to be added to\n        the training loss, such as regularization losses. These losses are\n        usually expressed as a batch average, so for best results users need to\n        set `loss_reduction=SUM_OVER_BATCH_SIZE` or\n        `loss_reduction=SUM_OVER_NONZERO_WEIGHTS` when creating the head to\n        avoid scaling errors.\n\n    Returns:\n      `model_fn._TPUEstimatorSpec`.\n    Raises:\n      ValueError: If both `train_op_fn` and `optimizer` are `None` in TRAIN\n        mode, or if both are set.\n    \"\"\"", "\n", "with", "ops", ".", "name_scope", "(", "self", ".", "_name", ",", "'sequence_head'", ")", ":", "\n", "# Predict.", "\n", "      ", "predictions", "=", "self", ".", "predictions", "(", "logits", ")", "\n", "if", "mode", "==", "model_fn", ".", "ModeKeys", ".", "PREDICT", ":", "\n", "        ", "return", "model_fn", ".", "_TPUEstimatorSpec", "(", "# pylint:disable=protected-access", "\n", "mode", "=", "model_fn", ".", "ModeKeys", ".", "PREDICT", ",", "\n", "predictions", "=", "predictions", ",", "\n", "export_outputs", "=", "{", "\n", "base_head", ".", "DEFAULT_SERVING_KEY", ":", "\n", "export_output", ".", "PredictOutput", "(", "predictions", ")", ",", "\n", "base_head", ".", "PREDICT_SERVING_KEY", ":", "(", "\n", "export_output", ".", "PredictOutput", "(", "predictions", ")", ")", "\n", "}", ")", "\n", "\n", "", "regularized_training_loss", "=", "self", ".", "loss", "(", "\n", "logits", "=", "logits", ",", "\n", "labels", "=", "labels", ",", "\n", "features", "=", "features", ",", "\n", "mode", "=", "mode", ",", "\n", "regularization_losses", "=", "regularization_losses", ")", "\n", "# Eval.", "\n", "if", "mode", "==", "model_fn", ".", "ModeKeys", ".", "EVAL", ":", "\n", "        ", "eval_metrics", "=", "self", ".", "metrics", "(", "regularization_losses", "=", "regularization_losses", ")", "\n", "return", "model_fn", ".", "_TPUEstimatorSpec", "(", "# pylint: disable=protected-access", "\n", "mode", "=", "model_fn", ".", "ModeKeys", ".", "EVAL", ",", "\n", "predictions", "=", "predictions", ",", "\n", "loss", "=", "regularized_training_loss", ",", "\n", "eval_metrics", "=", "base_head", ".", "create_eval_metrics_tuple", "(", "\n", "self", ".", "update_metrics", ",", "{", "\n", "'eval_metrics'", ":", "eval_metrics", ",", "\n", "'features'", ":", "features", ",", "\n", "'logits'", ":", "logits", ",", "\n", "'labels'", ":", "labels", ",", "\n", "'regularization_losses'", ":", "regularization_losses", "\n", "}", ")", ")", "\n", "# Train.", "\n", "", "train_op", "=", "base_head", ".", "create_estimator_spec_train_op", "(", "\n", "self", ".", "_name", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "trainable_variables", "=", "trainable_variables", ",", "\n", "train_op_fn", "=", "train_op_fn", ",", "\n", "update_ops", "=", "update_ops", ",", "\n", "regularized_training_loss", "=", "regularized_training_loss", ")", "\n", "# Create summary.", "\n", "", "base_head", ".", "create_estimator_spec_summary", "(", "regularized_training_loss", ",", "\n", "regularization_losses", ",", "\n", "self", ".", "_summary_key", ")", "\n", "return", "model_fn", ".", "_TPUEstimatorSpec", "(", "# pylint: disable=protected-access", "\n", "mode", "=", "model_fn", ".", "ModeKeys", ".", "TRAIN", ",", "\n", "predictions", "=", "predictions", ",", "\n", "loss", "=", "regularized_training_loss", ",", "\n", "train_op", "=", "train_op", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalOutput.__init__": [[41, 54], ["ValueError", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "value", ")", ":", "\n", "    ", "\"\"\"Initializer for `SurvivalOutput`.\n\n    Args:\n      value: a float `Tensor` with shape [time_len] giving the hazard values.\n\n    Raises:\n      ValueError: if the value is not a `Tensor` with dtype tf.float32.\n    \"\"\"", "\n", "if", "not", "(", "isinstance", "(", "value", ",", "ops", ".", "Tensor", ")", "and", "value", ".", "dtype", ".", "is_floating", ")", ":", "\n", "      ", "raise", "ValueError", "(", "'Survival output value must be a float32 Tensor; '", "\n", "'got {}'", ".", "format", "(", "value", ")", ")", "\n", "", "self", ".", "_value", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalOutput.value": [[55, 58], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "value", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_value", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalOutput.as_signature_def": [[59, 68], ["tensorflow.python.saved_model.signature_def_utils.regression_signature_def", "len", "ValueError", "tensorflow.python.framework.dtypes.as_dtype", "ValueError"], "methods", ["None"], ["", "def", "as_signature_def", "(", "self", ",", "receiver_tensors", ")", ":", "\n", "    ", "if", "len", "(", "receiver_tensors", ")", "!=", "2", ":", "\n", "      ", "raise", "ValueError", "(", "'Survival input must be dict with two entry; '", "\n", "'got {}'", ".", "format", "(", "receiver_tensors", ")", ")", "\n", "", "examples", "=", "receiver_tensors", "[", "'input_examples'", "]", "\n", "if", "dtypes", ".", "as_dtype", "(", "examples", ".", "dtype", ")", "!=", "dtypes", ".", "string", ":", "\n", "      ", "raise", "ValueError", "(", "'Survival input must be a single string Tensor; '", "\n", "'got {}'", ".", "format", "(", "receiver_tensors", ")", ")", "\n", "", "return", "signature_def_utils", ".", "regression_signature_def", "(", "examples", ",", "self", ".", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead.__init__": [[79, 131], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "enumerate", "tensorflow.logging.info", "tensorflow.logging.info", "survival_heads.SurvivalHead._summary_key", "survival_heads.SurvivalHead._summary_key", "survival_heads.SurvivalHead._summary_key", "survival_heads.SurvivalHead._summary_key", "survival_heads.SurvivalHead._summary_key", "survival_heads.SurvivalHead._summary_key", "survival_heads.SurvivalHead._summary_key", "survival_heads.SurvivalHead._summary_key", "survival_heads.SurvivalHead._summary_key", "range", "survival_heads.SurvivalHead._probablity_within_window_list.append", "int", "survival_heads.SurvivalHead._summary_key"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "weight_column", "=", "None", ",", "\n", "label_dimension", "=", "1", ",", "\n", "all_event_list", "=", "None", ",", "\n", "loss_reduction", "=", "losses", ".", "Reduction", ".", "SUM_OVER_BATCH_SIZE", ",", "\n", "survival_model_name", "=", "'exponential'", ",", "\n", "name", "=", "None", ",", "\n", "model_hparams", "=", "None", ")", ":", "\n", "    ", "self", ".", "_weight_column", "=", "weight_column", "\n", "self", ".", "_survival_model_name", "=", "survival_model_name", "\n", "tf", ".", "logging", ".", "info", "(", "survival_model_name", ")", "\n", "self", ".", "_survival_model", "=", "survival_util", ".", "REGISTERED_SURVIVAL_MODEL", "[", "\n", "self", ".", "_survival_model_name", "]", "\n", "# For independent events, label_dimension == 1", "\n", "# For correlated events, label_dimension == num_labels == num_events", "\n", "self", ".", "_logits_dimension", "=", "label_dimension", "\n", "tf", ".", "logging", ".", "info", "(", "self", ".", "_logits_dimension", ")", "\n", "self", ".", "_loss_reduction", "=", "loss_reduction", "\n", "self", ".", "_name", "=", "name", "\n", "self", ".", "_model_hparams", "=", "model_hparams", "\n", "if", "all_event_list", "is", "None", ":", "\n", "# For single event, independent events.", "\n", "      ", "self", ".", "_all_event_list", "=", "[", "name", "]", "\n", "", "else", ":", "\n", "      ", "self", ".", "_all_event_list", "=", "all_event_list", "\n", "", "tf", ".", "logging", ".", "info", "(", "self", ".", "_all_event_list", ")", "\n", "\n", "self", ".", "_event_index", "=", "0", "\n", "for", "i", ",", "event", "in", "enumerate", "(", "self", ".", "_all_event_list", ")", ":", "\n", "      ", "if", "event", "==", "self", ".", "_name", ":", "\n", "        ", "self", ".", "_event_index", "=", "i", "\n", "break", "\n", "", "", "tf", ".", "logging", ".", "info", "(", "self", ".", "_name", ")", "\n", "tf", ".", "logging", ".", "info", "(", "self", ".", "_event_index", ")", "\n", "# Metric keys.", "\n", "keys", "=", "metric_keys", ".", "MetricKeys", "\n", "self", ".", "_loss_mean_key", "=", "self", ".", "_summary_key", "(", "keys", ".", "LOSS_MEAN", ")", "\n", "self", ".", "_prediction_mean_key", "=", "self", ".", "_summary_key", "(", "keys", ".", "PREDICTION_MEAN", ")", "\n", "self", ".", "_label_mean_key", "=", "self", ".", "_summary_key", "(", "keys", ".", "LABEL_MEAN", ")", "\n", "self", ".", "_loss_regularization_key", "=", "self", ".", "_summary_key", "(", "keys", ".", "LOSS_REGULARIZATION", ")", "\n", "self", ".", "_auc_roc_24", "=", "self", ".", "_summary_key", "(", "AUC_ROC", "%", "'24'", ")", "\n", "self", ".", "_auc_roc_48", "=", "self", ".", "_summary_key", "(", "AUC_ROC", "%", "'48'", ")", "\n", "\n", "if", "self", ".", "_model_hparams", ".", "da_tlen", ">", "0", ":", "\n", "      ", "self", ".", "_auc_pr", "=", "self", ".", "_summary_key", "(", "AUC_PR", "%", "'avg'", ")", "\n", "self", ".", "_auc_roc", "=", "self", ".", "_summary_key", "(", "AUC_ROC", "%", "'avg'", ")", "\n", "self", ".", "_mean_abs_error", "=", "self", ".", "_summary_key", "(", "MEAN_ABS_ERROR", "%", "'avg'", ")", "\n", "\n", "self", ".", "_probablity_within_window_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "int", "(", "self", ".", "_model_hparams", ".", "da_tlen", "/", "SLOT_TO_WINDOW", ")", "+", "1", ")", ":", "\n", "        ", "self", ".", "_probablity_within_window_list", ".", "append", "(", "\n", "self", ".", "_summary_key", "(", "PROBABILITY_AT_WINDOW", "%", "i", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead.name": [[132, 136], ["None"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "    ", "\"\"\"See `base_head.Head` for details.\"\"\"", "\n", "return", "self", ".", "_name", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead.logits_dimension": [[137, 141], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "logits_dimension", "(", "self", ")", ":", "\n", "    ", "\"\"\"See `base_head.Head` for details.\"\"\"", "\n", "return", "self", ".", "_logits_dimension", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead.loss_reduction": [[142, 146], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "loss_reduction", "(", "self", ")", ":", "\n", "    ", "\"\"\"See `base_head.Head` for details.\"\"\"", "\n", "return", "self", ".", "_loss_reduction", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._processed_logits": [[147, 175], ["tensorflow.logging.info", "isinstance", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow_estimator.python.estimator.head.base_head.check_logits_final_dim", "tensorflow.concat", "all_event_logits_list.append"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat"], ["", "def", "_processed_logits", "(", "self", ",", "logits", ")", ":", "\n", "    ", "\"\"\"Process logits.\n\n    Args:\n      logits: for single event or independent event, a tensor of shape\n        [batch_size, 1]; for correlated event, a dict with event_name as key,\n        value as tensor of shape [batch_size, 1].\n\n    Returns:\n      logits: tensor of shape [batch_size, logits_dimension]. For correlated\n        event, logits_dimension == num_events, value arranged based on\n        the order in _all_event_list; otherwise, logits_dimension == 1.\n    \"\"\"", "\n", "tf", ".", "logging", ".", "info", "(", "logits", ")", "\n", "if", "isinstance", "(", "logits", ",", "dict", ")", ":", "\n", "      ", "all_event_logits_list", "=", "[", "]", "\n", "for", "event", "in", "self", ".", "_all_event_list", ":", "\n", "        ", "all_event_logits_list", ".", "append", "(", "logits", "[", "event", "]", ")", "\n", "# shape of all_event_logits is [batch_size, num_events]", "\n", "", "all_event_logits", "=", "tf", ".", "concat", "(", "all_event_logits_list", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "      ", "all_event_logits", "=", "logits", "\n", "", "tf", ".", "logging", ".", "info", "(", "self", ".", "logits_dimension", ")", "\n", "tf", ".", "logging", ".", "info", "(", "all_event_logits", ")", "\n", "logits", "=", "base_head", ".", "check_logits_final_dim", "(", "all_event_logits", ",", "\n", "self", ".", "logits_dimension", ")", "\n", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._processed_labels": [[176, 231], ["dict", "dict", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.concat", "tensorflow.equal", "tensorflow.concat", "ValueError", "len", "tensorflow.logging.info", "event_observed_list.append", "time_to_event_list.append", "tensorflow.constant", "key.endswith", "tensorflow.cast", "ValueError"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat"], ["", "def", "_processed_labels", "(", "self", ",", "logits", ",", "labels", ")", ":", "\n", "    ", "\"\"\"Converts labels to time_to_event, ~censored.\n\n    Args:\n      logits: logits `Tensor` with shape `[batch_size, _logits_dimension]`.\n      labels: dict with [event_name] and [event_name].time_to_event as keys. The\n        value for [event_name] key is a Tensor of shape `[batch_size, 1]` of\n        type int64, indicating whether the event is observed. The value for\n        [event_name].time_to_event key is a Tensor of shape\n        `[batch_size, 1]` of type float32. Here is one example label:\n        {u'respiration_failure.time_to_event':\n         <tf.Tensor 'Cast:0' shape=(32, 1) dtype=float32>,\n         u'respiration_failure':\n        <tf.Tensor 'Batch/batch:110' shape=(32, 1) dtype=int64>}\n\n    Returns:\n      Tuple of two tensors, time_to_event, event_censored.\n      For single event or independent events, each tensor has shape\n        [batch_size, 1]; for correlated events, each tensor has shape\n        [batch_size, num_events], value arranged based on the order in\n        _all_event_list.\n    \"\"\"", "\n", "del", "logits", "\n", "\n", "if", "labels", "is", "None", ":", "\n", "      ", "raise", "ValueError", "(", "base_head", ".", "_LABEL_NONE_ERR_MSG", ")", "# pylint:disable=protected-access", "\n", "", "if", "len", "(", "labels", ")", ">", "2", ":", "\n", "# For correlated events, labels for all events are provided.", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "'correlated event labels'", ")", "\n", "", "event_observed_dict", "=", "dict", "(", ")", "\n", "time_to_event_dict", "=", "dict", "(", ")", "\n", "for", "key", "in", "labels", ":", "\n", "      ", "if", "not", "key", ".", "endswith", "(", "'.time_to_event'", ")", ":", "\n", "        ", "event_observed_dict", "[", "key", "]", "=", "labels", "[", "key", "]", "\n", "if", "key", "+", "'.time_to_event'", "in", "labels", ":", "\n", "          ", "time_to_event_dict", "[", "key", "]", "=", "tf", ".", "cast", "(", "\n", "labels", "[", "key", "+", "'.time_to_event'", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "else", ":", "\n", "          ", "raise", "ValueError", "(", "key", "+", "'.time_to_event should be in labels.'", ")", "\n", "\n", "", "", "", "event_observed_list", "=", "[", "]", "\n", "time_to_event_list", "=", "[", "]", "\n", "tf", ".", "logging", ".", "info", "(", "self", ".", "_all_event_list", ")", "\n", "for", "event", "in", "self", ".", "_all_event_list", ":", "\n", "      ", "event_observed_list", ".", "append", "(", "event_observed_dict", "[", "event", "]", ")", "\n", "time_to_event_list", ".", "append", "(", "time_to_event_dict", "[", "event", "]", ")", "\n", "\n", "# event_observed_list is a list of tensor with shape [batch_size, 1]", "\n", "", "tf", ".", "logging", ".", "info", "(", "event_observed_list", ")", "\n", "# event_observed has shape [batch_size, num_events] for correlated event.", "\n", "# event_observed has shape [batch_size, 1] for single/independent event.", "\n", "event_observed", "=", "tf", ".", "concat", "(", "event_observed_list", ",", "axis", "=", "-", "1", ")", "\n", "event_censored", "=", "tf", ".", "equal", "(", "event_observed", ",", "tf", ".", "constant", "(", "[", "0", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ")", "\n", "time_to_event", "=", "tf", ".", "concat", "(", "time_to_event_list", ",", "axis", "=", "-", "1", ")", "\n", "return", "time_to_event", ",", "event_censored", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._unweighted_loss_and_weights": [[232, 260], ["time_to_event.shape.assert_is_compatible_with", "tensorflow.control_dependencies", "survival_heads.SurvivalHead._survival_model", "tensorflow.logging.info", "survival_heads.SurvivalHead.log_pdf", "survival_heads.SurvivalHead.log_survival_func", "survival_util.negative_log_likelihood_loss", "tensorflow.logging.info", "tensorflow.python.ops.math_ops.reduce_mean", "tensorflow_estimator.python.estimator.head.base_head.get_weights_and_check_match_logits", "survival_heads.SurvivalHead.params", "tensorflow.assert_positive"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.log_pdf", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.log_survival_func", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.negative_log_likelihood_loss", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.params"], ["", "def", "_unweighted_loss_and_weights", "(", "self", ",", "logits", ",", "processed_labels", ",", "features", ")", ":", "\n", "    ", "\"\"\"Computes loss spec.\"\"\"", "\n", "time_to_event", ",", "censored", "=", "processed_labels", "\n", "\n", "time_to_event", ".", "shape", ".", "assert_is_compatible_with", "(", "censored", ".", "shape", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "\n", "tf", ".", "assert_positive", "(", "time_to_event", ")", ",", "\n", "]", ")", ":", "\n", "      ", "model", "=", "self", ".", "_survival_model", "(", "\n", "params", "=", "logits", ",", "\n", "labels", "=", "processed_labels", ",", "\n", "event_index", "=", "self", ".", "_event_index", ",", "\n", "model_hparams", "=", "self", ".", "_model_hparams", ")", "\n", "\n", "tf", ".", "logging", ".", "info", "(", "model", ".", "params", "(", ")", ")", "\n", "log_pdf_value", "=", "model", ".", "log_pdf", "(", "time_to_event", ")", "\n", "log_survival_value", "=", "model", ".", "log_survival_func", "(", "time_to_event", ")", "\n", "batch_loss", "=", "survival_util", ".", "negative_log_likelihood_loss", "(", "\n", "censored", "=", "censored", ",", "\n", "log_pdf_value", "=", "log_pdf_value", ",", "\n", "log_survival_value", "=", "log_survival_value", ")", "\n", "# batch_loss has shape [batch_size,1]", "\n", "tf", ".", "logging", ".", "info", "(", "batch_loss", ")", "\n", "\n", "scalar_loss", "=", "math_ops", ".", "reduce_mean", "(", "batch_loss", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "weights", "=", "base_head", ".", "get_weights_and_check_match_logits", "(", "\n", "features", "=", "features", ",", "weight_column", "=", "self", ".", "_weight_column", ",", "logits", "=", "logits", ")", "\n", "return", "scalar_loss", ",", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead.loss": [[261, 313], ["tensorflow.python.framework.ops.name_scope", "tensorflow.logging.info", "survival_heads.SurvivalHead._processed_logits", "tensorflow.logging.info", "survival_heads.SurvivalHead._processed_labels", "survival_heads.SurvivalHead._unweighted_loss_and_weights", "tensorflow.python.ops.losses.losses.compute_weighted_loss", "tensorflow.python.ops.math_ops.add_n"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._processed_logits", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._processed_labels", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._unweighted_loss_and_weights"], ["", "", "def", "loss", "(", "self", ",", "\n", "logits", ",", "\n", "labels", ",", "\n", "features", "=", "None", ",", "\n", "mode", "=", "None", ",", "\n", "regularization_losses", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute Loss.\n\n    Args:\n      logits: for single event, indepdent event, logits is a tensor of shape\n        [batch_size, 1]; for correlated event, a dict with event_name as key,\n        value as tensor of shape [batch_size, 1].\n      labels: dict keyed by 'event_name' and 'event_name.time_of_event' with\n        value as tensors of shape [batch_size] or [batch_size, 1]. For\n        correlated events, labels for all events are provided. Otherwise, only\n        the event associated with this head is provided.\n      features: see base_head.Head.\n      mode: see base_head.Head.\n      regularization_losses: see base_head.Head.\n\n    Returns:\n      regularized_training_loss: see base_head.Head.\n    \"\"\"", "\n", "\n", "del", "mode", "# Unused for this head.", "\n", "with", "ops", ".", "name_scope", "(", "\n", "'losses'", ",", "values", "=", "(", "logits", ",", "labels", ",", "regularization_losses", ",", "features", ")", ")", ":", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "logits", ")", "\n", "# processed_logits shape is [batch_size, num_events] for correlated events", "\n", "# or [batch_size, 1] for single event.", "\n", "processed_logits", "=", "self", ".", "_processed_logits", "(", "logits", ")", "\n", "\n", "tf", ".", "logging", ".", "info", "(", "labels", ")", "\n", "# processed_labels is a tuple with two tensors of shape", "\n", "# [batch_size, num_events] for correlated events, or [batch_size, 1]", "\n", "# for single event.", "\n", "processed_labels", "=", "self", ".", "_processed_labels", "(", "logits", ",", "labels", ")", "\n", "\n", "unweighted_loss", ",", "weights", "=", "self", ".", "_unweighted_loss_and_weights", "(", "\n", "processed_logits", ",", "processed_labels", ",", "features", ")", "\n", "training_loss", "=", "losses", ".", "compute_weighted_loss", "(", "\n", "unweighted_loss", ",", "weights", "=", "weights", ",", "reduction", "=", "self", ".", "_loss_reduction", ")", "\n", "if", "regularization_losses", "is", "None", ":", "\n", "        ", "regularization_loss", "=", "None", "\n", "", "else", ":", "\n", "        ", "regularization_loss", "=", "math_ops", ".", "add_n", "(", "regularization_losses", ")", "\n", "", "if", "regularization_loss", "is", "None", ":", "\n", "        ", "regularized_training_loss", "=", "training_loss", "\n", "", "else", ":", "\n", "        ", "regularized_training_loss", "=", "training_loss", "+", "regularization_loss", "\n", "\n", "", "", "return", "regularized_training_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead.predictions": [[314, 350], ["survival_heads.SurvivalHead._processed_logits", "tensorflow_estimator.python.estimator.head.base_head.check_prediction_keys", "tensorflow.python.framework.ops.name_scope", "survival_heads.SurvivalHead.params", "survival_heads.SurvivalHead.predicted_time", "survival_heads.SurvivalHead._survival_model", "survival_heads.SurvivalHead.probability"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._processed_logits", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.params", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.predicted_time", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.probability"], ["", "def", "predictions", "(", "self", ",", "logits", ",", "keys", "=", "None", ")", ":", "\n", "    ", "\"\"\"Return predictions based on keys..\n\n    Args:\n      logits: for single event, indepdent event, logits is a tensor of shape\n        [batch_size, 1]; for correlated event, a dict with event_name as key,\n        value as tensor of shape [batch_size, 1].\n      keys: a list of prediction keys. Key can be either the class variable\n        of prediction_keys.PredictionKeys or its string value, such as:\n          prediction_keys.PredictionKeys.LOGITS or 'logits'.\n\n    Returns:\n      predictions: see base_head.Head.\n    \"\"\"", "\n", "pred_keys", "=", "prediction_keys", ".", "PredictionKeys", "\n", "valid_keys", "=", "[", "pred_keys", ".", "LOGITS", ",", "pred_keys", ".", "PROBABILITIES", "]", "\n", "if", "keys", ":", "\n", "      ", "base_head", ".", "check_prediction_keys", "(", "keys", ",", "valid_keys", ")", "\n", "", "else", ":", "\n", "      ", "keys", "=", "valid_keys", "\n", "\n", "", "processed_logits", "=", "self", ".", "_processed_logits", "(", "logits", ")", "\n", "predictions", "=", "{", "}", "\n", "with", "ops", ".", "name_scope", "(", "'predictions'", ",", "values", "=", "(", "processed_logits", ",", ")", ")", ":", "\n", "      ", "if", "pred_keys", ".", "LOGITS", "in", "keys", ":", "\n", "        ", "predictions", "[", "pred_keys", ".", "LOGITS", "]", "=", "processed_logits", "\n", "", "if", "pred_keys", ".", "PROBABILITIES", "in", "keys", ":", "\n", "        ", "model", "=", "self", ".", "_survival_model", "(", "\n", "params", "=", "processed_logits", ",", "\n", "labels", "=", "None", ",", "\n", "event_index", "=", "self", ".", "_event_index", ",", "\n", "model_hparams", "=", "self", ".", "_model_hparams", ")", "\n", "predictions", "[", "pred_keys", ".", "PROBABILITIES", "]", "=", "model", ".", "probability", "(", ")", "\n", "", "predictions", "[", "HAZARD_RATE", "]", "=", "model", ".", "params", "(", ")", "\n", "predictions", "[", "PREDICTED_TIME", "]", "=", "model", ".", "predicted_time", "(", ")", "\n", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead.hazard_rates": [[351, 374], ["survival_heads.SurvivalHead._processed_logits", "tensorflow.python.framework.ops.name_scope", "survival_heads.SurvivalHead._survival_model", "survival_heads.SurvivalHead.params", "tensorflow.logging.info"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._processed_logits", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.params"], ["", "", "def", "hazard_rates", "(", "self", ",", "logits", ",", "keys", "=", "None", ")", ":", "\n", "    ", "\"\"\"Return hazard_rates based on keys..\n\n    Args:\n      logits: logits `Tensor` with shape `[D0, D1, ... DN, logits_dimension]`.\n        For many applications, the shape is `[batch_size, logits_dimension]`.\n      keys: a list of prediction keys. Key can be either the class variable\n        of prediction_keys.PredictionKeys or its string value, such as:\n          prediction_keys.PredictionKeys.LOGITS or 'logits'.\n\n    Returns:\n      hazard_rates: tensor of shape [batch_size, 1]\n    \"\"\"", "\n", "processed_logits", "=", "self", ".", "_processed_logits", "(", "logits", ")", "\n", "with", "ops", ".", "name_scope", "(", "'hazard_rates'", ",", "values", "=", "(", "logits", ",", ")", ")", ":", "\n", "      ", "model", "=", "self", ".", "_survival_model", "(", "\n", "params", "=", "processed_logits", ",", "\n", "labels", "=", "None", ",", "\n", "event_index", "=", "self", ".", "_event_index", ",", "\n", "model_hparams", "=", "self", ".", "_model_hparams", ")", "\n", "hazard_rates", "=", "model", ".", "params", "(", ")", "\n", "tf", ".", "logging", ".", "info", "(", "hazard_rates", ")", "\n", "return", "hazard_rates", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead.metrics": [[375, 402], ["tensorflow.python.framework.ops.name_scope", "tensorflow.python.keras.metrics.Mean", "tensorflow.python.keras.metrics.Mean", "tensorflow.python.keras.metrics.Mean", "tensorflow.python.keras.metrics.Mean", "tensorflow.python.keras.metrics.AUC", "tensorflow.python.keras.metrics.AUC", "tensorflow.python.keras.metrics.AUC", "tensorflow.python.keras.metrics.AUC", "tensorflow.python.keras.metrics.MeanAbsoluteError", "range", "tensorflow.python.keras.metrics.Mean", "int"], "methods", ["None"], ["", "", "def", "metrics", "(", "self", ",", "regularization_losses", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates metrics. See `base_head.Head` for details.\"\"\"", "\n", "keys", "=", "metric_keys", ".", "MetricKeys", "\n", "with", "ops", ".", "name_scope", "(", "'metrics'", ",", "values", "=", "(", "regularization_losses", ",", ")", ")", ":", "\n", "# Mean metric.", "\n", "      ", "eval_metrics", "=", "{", "}", "\n", "eval_metrics", "[", "self", ".", "_loss_mean_key", "]", "=", "metrics", ".", "Mean", "(", "name", "=", "keys", ".", "LOSS_MEAN", ")", "\n", "eval_metrics", "[", "self", ".", "_prediction_mean_key", "]", "=", "metrics", ".", "Mean", "(", "\n", "name", "=", "keys", ".", "PREDICTION_MEAN", ")", "\n", "eval_metrics", "[", "self", ".", "_label_mean_key", "]", "=", "metrics", ".", "Mean", "(", "name", "=", "keys", ".", "LABEL_MEAN", ")", "\n", "if", "regularization_losses", "is", "not", "None", ":", "\n", "        ", "eval_metrics", "[", "self", ".", "_loss_regularization_key", "]", "=", "metrics", ".", "Mean", "(", "\n", "name", "=", "keys", ".", "LOSS_REGULARIZATION", ")", "\n", "", "if", "self", ".", "_model_hparams", ".", "da_tlen", ">", "0", "and", "not", "self", ".", "_model_hparams", ".", "event_relation", ":", "\n", "        ", "eval_metrics", "[", "self", ".", "_auc_roc_24", "]", "=", "metrics", ".", "AUC", "(", "name", "=", "AUC_ROC", "%", "'24'", ")", "\n", "eval_metrics", "[", "self", ".", "_auc_roc_48", "]", "=", "metrics", ".", "AUC", "(", "name", "=", "AUC_ROC", "%", "'48'", ")", "\n", "eval_metrics", "[", "self", ".", "_auc_pr", "]", "=", "metrics", ".", "AUC", "(", "\n", "curve", "=", "'PR'", ",", "name", "=", "AUC_PR", "%", "'avg'", ")", "\n", "eval_metrics", "[", "self", ".", "_auc_roc", "]", "=", "metrics", ".", "AUC", "(", "name", "=", "AUC_ROC", "%", "'avg'", ")", "\n", "eval_metrics", "[", "self", ".", "_mean_abs_error", "]", "=", "metrics", ".", "MeanAbsoluteError", "(", "\n", "name", "=", "MEAN_ABS_ERROR", "%", "'avg'", ")", "\n", "\n", "for", "i", "in", "range", "(", "int", "(", "self", ".", "_model_hparams", ".", "da_tlen", "/", "SLOT_TO_WINDOW", ")", "+", "1", ")", ":", "\n", "          ", "eval_metrics", "[", "self", ".", "_probablity_within_window_list", "[", "i", "]", "]", "=", "metrics", ".", "Mean", "(", "\n", "name", "=", "PROBABILITY_AT_WINDOW", "%", "i", ")", "\n", "\n", "", "", "", "return", "eval_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._true_and_predict_within_window": [[403, 427], ["tensorflow.logical_and", "tensorflow.logical_and", "tensorflow.logical_and", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tensorflow.logging.info", "tensorflow.greater_equal", "tensorflow.less_equal", "tensorflow.logical_not", "tensorflow.logical_not", "tensorflow.logical_not", "tensorflow.squeeze"], "methods", ["None"], ["", "def", "_true_and_predict_within_window", "(", "self", ",", "time_to_event", ",", "censored", ",", "\n", "probabilities_at_window", ",", "window_start_t", ",", "\n", "window_end_t", ")", ":", "\n", "    ", "time_to_event_within_window", "=", "tf", ".", "logical_and", "(", "\n", "tf", ".", "greater_equal", "(", "time_to_event", ",", "window_start_t", ")", ",", "\n", "tf", ".", "less_equal", "(", "time_to_event", ",", "window_end_t", ")", ")", "\n", "event_within_window", "=", "tf", ".", "logical_and", "(", "\n", "tf", ".", "logical_not", "(", "censored", ")", ",", "time_to_event_within_window", ")", "\n", "# Excluded from computation.", "\n", "# censored_within_window shape [batch_size, 1].", "\n", "censored_within_window", "=", "tf", ".", "logical_and", "(", "censored", ",", "\n", "time_to_event_within_window", ")", "\n", "# Excluding the events that are censored within the window.", "\n", "# true/1, if the event is observed within the window.", "\n", "# false/0, if the event is observed or censored outside of the window.", "\n", "y_true", "=", "tf", ".", "boolean_mask", "(", "event_within_window", ",", "\n", "tf", ".", "logical_not", "(", "censored_within_window", ")", ")", "\n", "# probabilities_at_window shape [batch_size, 1]", "\n", "y_pred", "=", "tf", ".", "boolean_mask", "(", "probabilities_at_window", ",", "\n", "tf", ".", "logical_not", "(", "censored_within_window", ")", ")", "\n", "tf", ".", "logging", ".", "info", "(", "y_pred", ")", "\n", "if", "y_pred", ".", "shape", ".", "ndims", ">", "1", ":", "\n", "      ", "y_pred", "=", "tf", ".", "squeeze", "(", "y_pred", ",", "axis", "=", "-", "1", ")", "\n", "", "return", "y_true", ",", "y_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead.update_metrics": [[428, 533], ["survival_heads.SurvivalHead._processed_logits", "survival_heads.SurvivalHead._processed_labels", "survival_heads.SurvivalHead._unweighted_loss_and_weights", "eval_metrics[].update_state", "survival_heads.SurvivalHead.predictions", "tensorflow_estimator.python.estimator.head.base_head.update_metric_with_broadcast_weights", "tensorflow_estimator.python.estimator.head.base_head.update_metric_with_broadcast_weights", "range", "eval_metrics[].update_state", "eval_metrics[].update_state", "survival_heads.SurvivalHead.probability_within_window", "survival_heads.SurvivalHead._true_and_predict_within_window", "eval_metrics[].update_state", "survival_heads.SurvivalHead.probability_within_window", "survival_heads.SurvivalHead._true_and_predict_within_window", "eval_metrics[].update_state", "tensorflow.boolean_mask", "survival_heads.SurvivalHead.predicted_time", "tensorflow.boolean_mask", "eval_metrics[].update_state", "tensorflow.python.ops.math_ops.add_n", "eval_metrics[].update_state", "survival_heads.SurvivalHead._survival_model", "survival_heads.SurvivalHead.probability_within_window", "tensorflow_estimator.python.estimator.head.base_head.update_metric_with_broadcast_weights", "survival_heads.SurvivalHead._true_and_predict_within_window", "y_true_list.append", "y_pred_list.append", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.logical_not", "tensorflow.logical_not", "int"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._processed_logits", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._processed_labels", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._unweighted_loss_and_weights", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead.predictions", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.probability_within_window", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._true_and_predict_within_window", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.probability_within_window", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._true_and_predict_within_window", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.predicted_time", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.probability_within_window", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._true_and_predict_within_window", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat"], ["", "def", "update_metrics", "(", "self", ",", "\n", "eval_metrics", ",", "\n", "features", ",", "\n", "logits", ",", "\n", "labels", ",", "\n", "regularization_losses", "=", "None", ")", ":", "\n", "    ", "\"\"\"Updates eval metrics.\n\n    Args:\n      eval_metrics: See `base_head.Head` for details.\n      features: See `base_head.Head` for details.\n      logits: for single event, indepdent event, logits is a tensor of shape\n        [batch_size, 1], for correlated event, a dict with event_name as key,\n        value as tensor of shape [batch_size, 1].\n      labels: dict keyed by 'event_name' and 'event_name.time_of_event' with\n        value as tensors of shape [batch_size] or [batch_size, 1]. For\n        correlated events, labels for all events are provided. Otherwise, only\n        the event associated with this head is provided.\n      regularization_losses: See `base_head.Head` for details.\n\n    Returns:\n      eval_metrics: See `base_head.Head` for details.\n    \"\"\"", "\n", "processed_logits", "=", "self", ".", "_processed_logits", "(", "logits", ")", "\n", "processed_labels", "=", "self", ".", "_processed_labels", "(", "logits", ",", "labels", ")", "\n", "time_to_event", ",", "censored", "=", "processed_labels", "\n", "\n", "unweighted_loss", ",", "weights", "=", "self", ".", "_unweighted_loss_and_weights", "(", "\n", "processed_logits", ",", "processed_labels", ",", "features", ")", "\n", "\n", "# Update metrics.", "\n", "eval_metrics", "[", "self", ".", "_loss_mean_key", "]", ".", "update_state", "(", "\n", "values", "=", "unweighted_loss", ",", "sample_weight", "=", "weights", ")", "\n", "prob_key", "=", "prediction_keys", ".", "PredictionKeys", ".", "PROBABILITIES", "\n", "predictions", "=", "self", ".", "predictions", "(", "logits", ",", "[", "prob_key", "]", ")", "\n", "probabilities", "=", "predictions", "[", "prob_key", "]", "\n", "\n", "base_head", ".", "update_metric_with_broadcast_weights", "(", "\n", "eval_metrics", "[", "self", ".", "_prediction_mean_key", "]", ",", "probabilities", ",", "weights", ")", "\n", "\n", "if", "self", ".", "_model_hparams", ".", "da_tlen", ">", "0", "and", "not", "self", ".", "_model_hparams", ".", "event_relation", ":", "\n", "      ", "y_true_list", "=", "[", "]", "\n", "y_pred_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "int", "(", "self", ".", "_model_hparams", ".", "da_tlen", "/", "SLOT_TO_WINDOW", ")", "+", "1", ")", ":", "\n", "        ", "model", "=", "self", ".", "_survival_model", "(", "\n", "params", "=", "processed_logits", ",", "\n", "labels", "=", "processed_labels", ",", "\n", "event_index", "=", "self", ".", "_event_index", ",", "\n", "model_hparams", "=", "self", ".", "_model_hparams", ")", "\n", "window_start_t", "=", "i", "*", "UNITS_IN_HR", "*", "self", ".", "_model_hparams", ".", "da_sslot", "*", "SLOT_TO_WINDOW", "# pylint: disable=line-too-long", "\n", "window_end_t", "=", "(", "\n", "i", "+", "1", ")", "*", "UNITS_IN_HR", "*", "self", ".", "_model_hparams", ".", "da_sslot", "*", "SLOT_TO_WINDOW", "\n", "# probabilities_at_window shape [batch_size, 1].", "\n", "probabilities_at_window", "=", "model", ".", "probability_within_window", "(", "\n", "window_start_t", "=", "window_start_t", ",", "window_end_t", "=", "window_end_t", ")", "\n", "base_head", ".", "update_metric_with_broadcast_weights", "(", "\n", "eval_metrics", "[", "self", ".", "_probablity_within_window_list", "[", "i", "]", "]", ",", "\n", "probabilities_at_window", ",", "weights", ")", "\n", "y_true", ",", "y_pred", "=", "self", ".", "_true_and_predict_within_window", "(", "\n", "time_to_event", ",", "censored", ",", "probabilities_at_window", ",", "window_start_t", ",", "\n", "window_end_t", ")", "\n", "# y_true, y_pred shape [batch_size]", "\n", "y_true_list", ".", "append", "(", "y_true", ")", "\n", "y_pred_list", ".", "append", "(", "y_pred", ")", "\n", "tf", ".", "logging", ".", "info", "(", "y_true", ")", "\n", "tf", ".", "logging", ".", "info", "(", "y_pred", ")", "\n", "\n", "", "eval_metrics", "[", "self", ".", "_auc_pr", "]", ".", "update_state", "(", "\n", "tf", ".", "concat", "(", "y_true_list", ",", "axis", "=", "0", ")", ",", "tf", ".", "concat", "(", "y_pred_list", ",", "axis", "=", "0", ")", ")", "\n", "eval_metrics", "[", "self", ".", "_auc_roc", "]", ".", "update_state", "(", "\n", "tf", ".", "concat", "(", "y_true_list", ",", "axis", "=", "0", ")", ",", "tf", ".", "concat", "(", "y_pred_list", ",", "axis", "=", "0", ")", ")", "\n", "\n", "# 24hr and 48hr window AUC.", "\n", "probabilities_at_24", "=", "model", ".", "probability_within_window", "(", "\n", "window_start_t", "=", "0", ",", "window_end_t", "=", "UNITS_IN_HR", "*", "24", ")", "\n", "y_true_24", ",", "y_pred_24", "=", "self", ".", "_true_and_predict_within_window", "(", "\n", "time_to_event", ",", "censored", ",", "probabilities_at_24", ",", "0", ",", "UNITS_IN_HR", "*", "24", ")", "\n", "eval_metrics", "[", "self", ".", "_auc_roc_24", "]", ".", "update_state", "(", "y_true_24", ",", "y_pred_24", ")", "\n", "\n", "probabilities_at_48", "=", "model", ".", "probability_within_window", "(", "\n", "window_start_t", "=", "0", ",", "window_end_t", "=", "UNITS_IN_HR", "*", "48", ")", "\n", "y_true_48", ",", "y_pred_48", "=", "self", ".", "_true_and_predict_within_window", "(", "\n", "time_to_event", ",", "censored", ",", "probabilities_at_48", ",", "0", ",", "UNITS_IN_HR", "*", "48", ")", "\n", "eval_metrics", "[", "self", ".", "_auc_roc_48", "]", ".", "update_state", "(", "y_true_48", ",", "y_pred_48", ")", "\n", "\n", "observed_time", "=", "tf", ".", "boolean_mask", "(", "\n", "time_to_event", "[", ":", ",", "self", ".", "_event_index", "]", "/", "UNITS_IN_HR", ",", "\n", "tf", ".", "logical_not", "(", "censored", "[", ":", ",", "self", ".", "_event_index", "]", ")", ")", "\n", "\n", "predicted_time", "=", "model", ".", "predicted_time", "(", ")", "\n", "predicted_time", "=", "tf", ".", "boolean_mask", "(", "\n", "predicted_time", ",", "tf", ".", "logical_not", "(", "censored", "[", ":", ",", "self", ".", "_event_index", "]", ")", ")", "\n", "eval_metrics", "[", "self", ".", "_mean_abs_error", "]", ".", "update_state", "(", "observed_time", ",", "\n", "predicted_time", ")", "\n", "\n", "# label_mean represents the percentage of censored events. In case of", "\n", "# mortality, it is the percentage of survived patients.", "\n", "", "base_head", ".", "update_metric_with_broadcast_weights", "(", "\n", "eval_metrics", "[", "self", ".", "_label_mean_key", "]", ",", "censored", ",", "weights", ")", "\n", "\n", "if", "regularization_losses", "is", "not", "None", ":", "\n", "      ", "regularization_loss", "=", "math_ops", ".", "add_n", "(", "regularization_losses", ")", "\n", "eval_metrics", "[", "self", ".", "_loss_regularization_key", "]", ".", "update_state", "(", "\n", "values", "=", "regularization_loss", ")", "\n", "", "return", "eval_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead._create_tpu_estimator_spec": [[534, 648], ["tensorflow.logging.info", "tensorflow_estimator.python.estimator.head.base_head.create_estimator_spec_summary", "tensorflow_estimator.python.estimator.model_fn._TPUEstimatorSpec", "tensorflow.python.framework.ops.name_scope", "survival_heads.SurvivalHead.predictions", "survival_heads.SurvivalHead.loss", "tensorflow_estimator.python.estimator.head.base_head.create_estimator_spec_train_op", "tensorflow_estimator.python.estimator.model_fn._TPUEstimatorSpec", "survival_heads.SurvivalHead.metrics", "tensorflow_estimator.python.estimator.model_fn._TPUEstimatorSpec", "tensorflow_estimator.python.estimator.head.base_head.create_eval_metrics_tuple", "tensorflow_estimator.python.estimator.export.export_output.PredictOutput", "tensorflow_estimator.python.estimator.export.export_output.PredictOutput"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead.predictions", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.multi_head_for_survival.SurvivalMultiHead.loss", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead.metrics"], ["", "def", "_create_tpu_estimator_spec", "(", "self", ",", "\n", "features", ",", "\n", "mode", ",", "\n", "logits", ",", "\n", "labels", "=", "None", ",", "\n", "optimizer", "=", "None", ",", "\n", "trainable_variables", "=", "None", ",", "\n", "train_op_fn", "=", "None", ",", "\n", "update_ops", "=", "None", ",", "\n", "regularization_losses", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns an `model_fn._TPUEstimatorSpec`.\n\n    Args:\n      features: Input `dict` of `Tensor` or `SparseTensor` objects.\n      mode: Estimator's `ModeKeys`.\n      logits: for single event, indepdent event, logits is a tensor of shape\n        [batch_size, 1], for correlated event, a dict with event_name as key,\n        value as tensor of shape [batch_size, 1].\n      labels: dict keyed by 'event_name' and 'event_name.time_of_event' with\n        value as tensors of shape [batch_size] or [batch_size, 1]. For\n        correlated events, labels for all events are provided. Otherwise, only\n        the event associated with this head is provided.\n        Here is one example label:\n        {u'respiration_failure.time_to_event':\n         <tf.Tensor 'Cast:0' shape=(32,) dtype=float32>,\n         u'respiration_failure':\n        <tf.Tensor 'Batch/batch:110' shape=(32,) dtype=int64>} `labels` is\n          required argument when `mode` equals `TRAIN` or `EVAL`.\n      optimizer: An `tf.keras.optimizers.Optimizer` instance to optimize the\n        loss in TRAIN mode. Namely, sets `train_op = optimizer.get_updates(loss,\n        trainable_variables)`, which updates variables to minimize `loss`.\n      trainable_variables: A list or tuple of `Variable` objects to update to\n        minimize `loss`. In Tensorflow 1.x, by default these are the list of\n        variables collected in the graph under the key\n        `GraphKeys.TRAINABLE_VARIABLES`. As Tensorflow 2.x doesn't have\n        collections and GraphKeys, trainable_variables need to be passed\n        explicitly here.\n      train_op_fn: Function that takes a scalar loss `Tensor` and returns\n        `train_op`. Used if `optimizer` is `None`.\n      update_ops: A list or tuple of update ops to be run at training time. For\n        example, layers such as BatchNormalization create mean and variance\n        update ops that need to be run at training time. In Tensorflow 1.x,\n        these are thrown into an UPDATE_OPS collection. As Tensorflow 2.x\n        doesn't have collections, update_ops need to be passed explicitly here.\n      regularization_losses: A list of additional scalar losses to be added to\n        the training loss, such as regularization losses. These losses are\n        usually expressed as a batch average, so for best results users need to\n        set `loss_reduction=SUM_OVER_BATCH_SIZE` or\n        `loss_reduction=SUM_OVER_NONZERO_WEIGHTS` when creating the head to\n        avoid scaling errors.\n\n    Returns:\n      `model_fn._TPUEstimatorSpec`.\n    Raises:\n      ValueError: If both `train_op_fn` and `optimizer` are `None` in TRAIN\n        mode, or if both are set.\n    \"\"\"", "\n", "tf", ".", "logging", ".", "info", "(", "mode", ")", "\n", "\n", "with", "ops", ".", "name_scope", "(", "self", ".", "_name", ",", "'survival_head'", ")", ":", "\n", "# Predict.", "\n", "      ", "predictions", "=", "self", ".", "predictions", "(", "logits", ")", "\n", "# hazard_rates = self.hazard_rates(logits)", "\n", "\n", "if", "mode", "==", "model_fn", ".", "ModeKeys", ".", "PREDICT", ":", "\n", "# survival_output = SurvivalOutput(value=hazard_rates)", "\n", "\n", "        ", "return", "model_fn", ".", "_TPUEstimatorSpec", "(", "# pylint:disable=protected-access", "\n", "mode", "=", "model_fn", ".", "ModeKeys", ".", "PREDICT", ",", "\n", "predictions", "=", "predictions", ",", "\n", "export_outputs", "=", "{", "\n", "base_head", ".", "DEFAULT_SERVING_KEY", ":", "(", "\n", "export_output", ".", "PredictOutput", "(", "predictions", ")", ")", ",", "\n", "base_head", ".", "PREDICT_SERVING_KEY", ":", "(", "\n", "export_output", ".", "PredictOutput", "(", "predictions", ")", ")", "\n", "}", ")", "\n", "\n", "", "regularized_training_loss", "=", "self", ".", "loss", "(", "\n", "logits", "=", "logits", ",", "\n", "labels", "=", "labels", ",", "\n", "features", "=", "features", ",", "\n", "mode", "=", "mode", ",", "\n", "regularization_losses", "=", "regularization_losses", ")", "\n", "# Eval.", "\n", "if", "mode", "==", "model_fn", ".", "ModeKeys", ".", "EVAL", ":", "\n", "        ", "eval_metrics", "=", "self", ".", "metrics", "(", "regularization_losses", "=", "regularization_losses", ")", "\n", "return", "model_fn", ".", "_TPUEstimatorSpec", "(", "# pylint: disable=protected-access", "\n", "mode", "=", "model_fn", ".", "ModeKeys", ".", "EVAL", ",", "\n", "predictions", "=", "predictions", ",", "\n", "loss", "=", "regularized_training_loss", ",", "\n", "eval_metrics", "=", "base_head", ".", "create_eval_metrics_tuple", "(", "\n", "self", ".", "update_metrics", ",", "{", "\n", "'eval_metrics'", ":", "eval_metrics", ",", "\n", "'features'", ":", "features", ",", "\n", "'logits'", ":", "logits", ",", "\n", "'labels'", ":", "labels", ",", "\n", "'regularization_losses'", ":", "regularization_losses", "\n", "}", ")", ")", "\n", "# Train.", "\n", "", "train_op", "=", "base_head", ".", "create_estimator_spec_train_op", "(", "\n", "self", ".", "_name", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "trainable_variables", "=", "trainable_variables", ",", "\n", "train_op_fn", "=", "train_op_fn", ",", "\n", "update_ops", "=", "update_ops", ",", "\n", "regularized_training_loss", "=", "regularized_training_loss", ")", "\n", "# Create summary.", "\n", "", "base_head", ".", "create_estimator_spec_summary", "(", "\n", "regularized_training_loss", ",", "regularization_losses", ",", "self", ".", "_summary_key", ")", "\n", "return", "model_fn", ".", "_TPUEstimatorSpec", "(", "# pylint: disable=protected-access", "\n", "mode", "=", "model_fn", ".", "ModeKeys", ".", "TRAIN", ",", "\n", "predictions", "=", "predictions", ",", "\n", "loss", "=", "regularized_training_loss", ",", "\n", "train_op", "=", "train_op", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.multi_head_for_survival.SurvivalMultiHead.loss": [[90, 135], ["multi_head_for_survival.SurvivalMultiHead._check_logits_and_labels", "multi_head_for_survival._get_per_head_label", "tuple", "tensorflow.logging.info", "tensorflow.logging.info", "head.loss", "tuple.append", "tensorflow.python.framework.ops.name_scope", "tensorflow.python.ops.math_ops.add_n", "zip", "tensorflow.python.ops.math_ops.add_n", "head_weighted_training_losses.append", "tensorflow.python.ops.math_ops.multiply", "tuple"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.multi_head_for_survival._get_per_head_label", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.multi_head_for_survival.SurvivalMultiHead.loss"], ["def", "loss", "(", "self", ",", "\n", "logits", ",", "\n", "labels", ",", "\n", "features", "=", "None", ",", "\n", "mode", "=", "None", ",", "\n", "regularization_losses", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns training loss. See `multi_head.MultiHead` for details.\"\"\"", "\n", "logits_dict", "=", "self", ".", "_check_logits_and_labels", "(", "logits", ",", "labels", ")", "\n", "per_head_label_map", "=", "_get_per_head_label", "(", "labels", ")", "\n", "\n", "training_losses", "=", "[", "]", "\n", "for", "head", "in", "self", ".", "_heads", ":", "\n", "# Each head is either a classification task or an event in survival", "\n", "# analysis.", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "head", ".", "name", ")", "\n", "tf", ".", "logging", ".", "info", "(", "per_head_label_map", "[", "head", ".", "name", "]", ")", "\n", "training_loss", "=", "head", ".", "loss", "(", "\n", "logits", "=", "logits_dict", "[", "head", ".", "name", "]", ",", "\n", "labels", "=", "per_head_label_map", "[", "head", ".", "name", "]", ",", "\n", "features", "=", "features", ",", "\n", "mode", "=", "mode", ")", "\n", "training_losses", ".", "append", "(", "training_loss", ")", "\n", "\n", "", "training_losses", "=", "tuple", "(", "training_losses", ")", "\n", "with", "ops", ".", "name_scope", "(", "\n", "'merge_losses'", ",", "\n", "values", "=", "training_losses", "+", "(", "self", ".", "_head_weights", "or", "tuple", "(", ")", ")", ")", ":", "\n", "      ", "if", "self", ".", "_head_weights", ":", "\n", "        ", "head_weighted_training_losses", "=", "[", "]", "\n", "for", "training_loss", ",", "head_weight", "in", "zip", "(", "training_losses", ",", "\n", "self", ".", "_head_weights", ")", ":", "\n", "          ", "head_weighted_training_losses", ".", "append", "(", "\n", "math_ops", ".", "multiply", "(", "training_loss", ",", "head_weight", ")", ")", "\n", "", "training_losses", "=", "head_weighted_training_losses", "\n", "", "merged_training_loss", "=", "math_ops", ".", "add_n", "(", "training_losses", ")", "\n", "\n", "if", "regularization_losses", "is", "None", ":", "\n", "        ", "regularization_loss", "=", "None", "\n", "", "else", ":", "\n", "        ", "regularization_loss", "=", "math_ops", ".", "add_n", "(", "regularization_losses", ")", "\n", "", "if", "regularization_loss", "is", "None", ":", "\n", "        ", "regularized_training_loss", "=", "merged_training_loss", "\n", "", "else", ":", "\n", "        ", "regularized_training_loss", "=", "merged_training_loss", "+", "regularization_loss", "\n", "", "", "return", "regularized_training_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.multi_head_for_survival.SurvivalMultiHead.update_metrics": [[136, 166], ["multi_head_for_survival.SurvivalMultiHead._check_logits_and_labels", "multi_head_for_survival._get_per_head_label", "enumerate", "tensorflow.python.ops.math_ops.add_n", "eval_metrics[].update_state", "head.loss", "eval_metrics[].update_state", "head.metrics", "head.update_metrics", "eval_metrics.update"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.multi_head_for_survival._get_per_head_label", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.multi_head_for_survival.SurvivalMultiHead.loss", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead.metrics", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.RegressionTask.update_metrics"], ["", "def", "update_metrics", "(", "self", ",", "\n", "eval_metrics", ",", "\n", "features", ",", "\n", "logits", ",", "\n", "labels", ",", "\n", "regularization_losses", "=", "None", ")", ":", "\n", "    ", "\"\"\"Updates eval metrics. See `multi_head.MultiHead` for details.\"\"\"", "\n", "logits_dict", "=", "self", ".", "_check_logits_and_labels", "(", "logits", ",", "labels", ")", "\n", "\n", "per_head_label_map", "=", "_get_per_head_label", "(", "labels", ")", "\n", "\n", "# Update regularization loss metric", "\n", "if", "regularization_losses", "is", "not", "None", ":", "\n", "      ", "regularization_loss", "=", "math_ops", ".", "add_n", "(", "regularization_losses", ")", "\n", "eval_metrics", "[", "self", ".", "_loss_regularization_key", "]", ".", "update_state", "(", "\n", "values", "=", "regularization_loss", ")", "\n", "# Update metrics for each head", "\n", "", "for", "i", ",", "head", "in", "enumerate", "(", "self", ".", "_heads", ")", ":", "\n", "      ", "head_logits", "=", "logits_dict", "[", "head", ".", "name", "]", "\n", "head_labels", "=", "per_head_label_map", "[", "head", ".", "name", "]", "\n", "# Update loss metrics", "\n", "training_loss", "=", "head", ".", "loss", "(", "\n", "logits", "=", "head_logits", ",", "labels", "=", "head_labels", ",", "features", "=", "features", ")", "\n", "eval_metrics", "[", "self", ".", "_loss_keys", "[", "i", "]", "]", ".", "update_state", "(", "values", "=", "training_loss", ")", "\n", "# Update existing metrics in each head", "\n", "head_metrics", "=", "head", ".", "metrics", "(", ")", "\n", "updated_metrics", "=", "head", ".", "update_metrics", "(", "head_metrics", ",", "features", ",", "head_logits", ",", "\n", "head_labels", ")", "\n", "eval_metrics", ".", "update", "(", "updated_metrics", "or", "{", "}", ")", "\n", "", "return", "eval_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.multi_head_for_survival.SurvivalMultiHead.create_estimator_spec": [[167, 295], ["multi_head_for_survival._get_per_head_label", "tensorflow.python.framework.ops.name_scope", "multi_head_for_survival.SurvivalMultiHead._check_logits_and_labels", "multi_head_for_survival.SurvivalMultiHead.predictions", "multi_head_for_survival.SurvivalMultiHead.loss", "ValueError", "tensorflow.logging.info", "all_estimator_spec.append", "multi_head_for_survival.SurvivalMultiHead._merge_predict_export_outputs", "tensorflow_estimator.python.estimator.model_fn.EstimatorSpec", "multi_head_for_survival.SurvivalMultiHead.metrics", "multi_head_for_survival.SurvivalMultiHead.update_metrics", "tensorflow_estimator.python.estimator.model_fn.EstimatorSpec", "tensorflow_estimator.python.estimator.head.base_head.create_estimator_spec_summary", "tensorflow_estimator.python.estimator.model_fn.EstimatorSpec", "head.create_estimator_spec", "isinstance", "multi_head_for_survival.SurvivalMultiHead.update", "ValueError", "tensorflow_estimator.python.estimator.head.base_head.validate_trainable_variables", "optimizer.get_updates", "optimizer.minimize", "train_op_fn", "ValueError", "tensorflow.python.training.training_util.get_global_step"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.multi_head_for_survival._get_per_head_label", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead.predictions", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.multi_head_for_survival.SurvivalMultiHead.loss", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_heads.SurvivalHead.metrics", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.RegressionTask.update_metrics", "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel.create_estimator_spec"], ["", "def", "create_estimator_spec", "(", "self", ",", "\n", "features", ",", "\n", "mode", ",", "\n", "logits", ",", "\n", "labels", "=", "None", ",", "\n", "optimizer", "=", "None", ",", "\n", "trainable_variables", "=", "None", ",", "\n", "train_op_fn", "=", "None", ",", "\n", "update_ops", "=", "None", ",", "\n", "regularization_losses", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns a `model_fn.EstimatorSpec`.\n\n    Args:\n      features: Input `dict` of `Tensor` or `SparseTensor` objects.\n      mode: Estimator's `ModeKeys`.\n      logits: Input `dict` keyed by head name, or logits `Tensor` with shape\n        `[D0, D1, ... DN, logits_dimension]`. For many applications, the\n        `Tensor` shape is `[batch_size, logits_dimension]`. If logits is a\n        `Tensor`, it  will split the `Tensor` along the last dimension and\n        distribute it appropriately among the heads. Check `MultiHead` for\n        examples.\n      labels: Input `dict` keyed by head name. For each head, the label value\n        can be integer or string `Tensor` with shape matching its corresponding\n        `logits`.`labels` is a required argument when `mode` equals `TRAIN` or\n        `EVAL`.\n      optimizer: An `tf.keras.optimizers.Optimizer` instance to optimize the\n        loss in TRAIN mode. Namely, sets `train_op = optimizer.get_updates(loss,\n        trainable_variables)`, which updates variables to minimize `loss`.\n      trainable_variables: A list or tuple of `Variable` objects to update to\n        minimize `loss`. In Tensorflow 1.x, by default these are the list of\n        variables collected in the graph under the key\n        `GraphKeys.TRAINABLE_VARIABLES`. As Tensorflow 2.x doesn't have\n        collections and GraphKeys, trainable_variables need to be passed\n        explicitly here.\n      train_op_fn: Function that takes a scalar loss `Tensor` and returns\n        `train_op`. Used if `optimizer` is `None`.\n      update_ops: A list or tuple of update ops to be run at training time. For\n        example, layers such as BatchNormalization create mean and variance\n        update ops that need to be run at training time. In Tensorflow 1.x,\n        these are thrown into an UPDATE_OPS collection. As Tensorflow 2.x\n        doesn't have collections, update_ops need to be passed explicitly here.\n      regularization_losses: A list of additional scalar losses to be added to\n        the training loss, such as regularization losses. These losses are\n        usually expressed as a batch average, so for best results, in each head,\n        users need to use the default `loss_reduction=SUM_OVER_BATCH_SIZE` or\n        set `loss_reduction=SUM_OVER_NONZERO_WEIGHTS` to avoid scaling errors.\n        Compared to the regularization losses for each head, this loss is to\n        regularize the merged loss of all heads in multi head, and will be added\n        to the overall training loss of multi head.\n\n    Returns:\n      A `model_fn.EstimatorSpec` instance.\n\n    Raises:\n      ValueError: If both `train_op_fn` and `optimizer` are `None` in TRAIN\n      mode, or if both are set.\n      If `mode` is not in Estimator's `ModeKeys`.\n    \"\"\"", "\n", "per_head_label_map", "=", "_get_per_head_label", "(", "labels", ")", "if", "labels", "else", "None", "\n", "\n", "with", "ops", ".", "name_scope", "(", "self", ".", "name", ",", "'multi_survival_head'", ")", ":", "\n", "      ", "logits_dict", "=", "self", ".", "_check_logits_and_labels", "(", "logits", ",", "labels", ")", "\n", "# Get all estimator spec.", "\n", "all_estimator_spec", "=", "[", "]", "\n", "for", "head", "in", "self", ".", "_heads", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "head", ".", "name", ")", "\n", "all_estimator_spec", ".", "append", "(", "\n", "head", ".", "create_estimator_spec", "(", "\n", "features", "=", "features", ",", "\n", "mode", "=", "mode", ",", "\n", "logits", "=", "logits_dict", "[", "head", ".", "name", "]", ",", "\n", "labels", "=", "per_head_label_map", "[", "head", ".", "name", "]", "if", "labels", "else", "None", ",", "\n", "train_op_fn", "=", "_no_op_train_fn", ")", ")", "\n", "# Predict.", "\n", "", "predictions", "=", "self", ".", "predictions", "(", "logits", ")", "\n", "if", "mode", "==", "model_fn", ".", "ModeKeys", ".", "PREDICT", ":", "\n", "        ", "export_outputs", "=", "self", ".", "_merge_predict_export_outputs", "(", "all_estimator_spec", ")", "\n", "return", "model_fn", ".", "EstimatorSpec", "(", "\n", "mode", "=", "model_fn", ".", "ModeKeys", ".", "PREDICT", ",", "\n", "predictions", "=", "predictions", ",", "\n", "export_outputs", "=", "export_outputs", ")", "\n", "", "loss", "=", "self", ".", "loss", "(", "logits", ",", "labels", ",", "features", ",", "mode", ",", "regularization_losses", ")", "\n", "# Eval.", "\n", "if", "mode", "==", "model_fn", ".", "ModeKeys", ".", "EVAL", ":", "\n", "        ", "eval_metrics", "=", "self", ".", "metrics", "(", "regularization_losses", "=", "regularization_losses", ")", "\n", "updated_metrics", "=", "self", ".", "update_metrics", "(", "\n", "eval_metrics", ",", "\n", "features", ",", "\n", "logits", ",", "\n", "labels", ",", "\n", "regularization_losses", "=", "regularization_losses", ")", "\n", "return", "model_fn", ".", "EstimatorSpec", "(", "\n", "mode", "=", "model_fn", ".", "ModeKeys", ".", "EVAL", ",", "\n", "predictions", "=", "predictions", ",", "\n", "loss", "=", "loss", ",", "\n", "eval_metric_ops", "=", "updated_metrics", ")", "\n", "# Train.", "\n", "", "if", "mode", "==", "model_fn", ".", "ModeKeys", ".", "TRAIN", ":", "\n", "# train_op.", "\n", "        ", "if", "optimizer", "is", "not", "None", ":", "\n", "          ", "if", "train_op_fn", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "'train_op_fn and optimizer cannot both be set.'", ")", "\n", "", "if", "isinstance", "(", "optimizer", ",", "optimizer_v2", ".", "OptimizerV2", ")", ":", "\n", "            ", "base_head", ".", "validate_trainable_variables", "(", "trainable_variables", ")", "\n", "train_op", "=", "optimizer", ".", "get_updates", "(", "\n", "loss", ",", "trainable_variables", ")", "\n", "", "else", ":", "\n", "            ", "train_op", "=", "optimizer", ".", "minimize", "(", "\n", "loss", ",", "\n", "global_step", "=", "training_util", ".", "get_global_step", "(", ")", ")", "\n", "", "", "elif", "train_op_fn", "is", "not", "None", ":", "\n", "          ", "train_op", "=", "train_op_fn", "(", "loss", ")", "\n", "", "else", ":", "\n", "          ", "raise", "ValueError", "(", "'train_op_fn and optimizer cannot both be None.'", ")", "\n", "# Create summary.", "\n", "", "base_head", ".", "create_estimator_spec_summary", "(", "loss", ",", "regularization_losses", ")", "\n", "# eval_metrics.", "\n", "eval_metrics", "=", "{", "}", "\n", "for", "spec", "in", "all_estimator_spec", ":", "\n", "          ", "eval_metrics", ".", "update", "(", "spec", ".", "eval_metric_ops", "or", "{", "}", ")", "\n", "# predictions can be used to access the logits in `TRAIN` mode", "\n", "", "return", "model_fn", ".", "EstimatorSpec", "(", "\n", "mode", "=", "model_fn", ".", "ModeKeys", ".", "TRAIN", ",", "\n", "loss", "=", "loss", ",", "\n", "train_op", "=", "train_op", ",", "\n", "predictions", "=", "predictions", ",", "\n", "eval_metric_ops", "=", "eval_metrics", ")", "\n", "", "raise", "ValueError", "(", "'mode={} unrecognized'", ".", "format", "(", "mode", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.multi_head_for_survival._no_op_train_fn": [[29, 32], ["tensorflow.python.ops.control_flow_ops.no_op"], "function", ["None"], ["def", "_no_op_train_fn", "(", "loss", ")", ":", "\n", "  ", "del", "loss", "\n", "return", "control_flow_ops", ".", "no_op", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.multi_head_for_survival._default_export_output": [[34, 47], ["len", "next", "six.itervalues", "ValueError"], "function", ["None"], ["", "def", "_default_export_output", "(", "export_outputs", ",", "head_name", ")", ":", "\n", "  ", "\"\"\"Extracts the default export output from the given export_outputs dict.\"\"\"", "\n", "if", "len", "(", "export_outputs", ")", "==", "1", ":", "\n", "    ", "return", "next", "(", "six", ".", "itervalues", "(", "export_outputs", ")", ")", "\n", "", "try", ":", "\n", "    ", "return", "export_outputs", "[", "base_head", ".", "DEFAULT_SERVING_KEY", "]", "\n", "", "except", "KeyError", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "'{} did not specify default export_outputs. '", "\n", "'Given: {} '", "\n", "'Suggested fix: Use one of the heads in tf.estimator, or include '", "\n", "'key {} in export_outputs.'", ".", "format", "(", "head_name", ",", "export_outputs", ",", "\n", "base_head", ".", "DEFAULT_SERVING_KEY", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.multi_head_for_survival._get_per_head_label": [[49, 85], ["dict", "tensorflow.cast", "key.endswith", "len", "ValueError"], "function", ["None"], ["", "", "def", "_get_per_head_label", "(", "labels", ")", ":", "\n", "  ", "\"\"\"Merge survival event labels and return a map keyed by head name.\n\n    For classification labels, the map values are label values.\n    For survival labels, the label values are maps with keys as [event_name] and\n      '[event_name].time_to_event'.\n\n  Args:\n    labels: Dict keyed by 'event_name' and 'event_name.time_of_event' with value\n      as tensors of shape [batch_size, 1].\n\n  Returns:\n    per_head_label_map: keyed by head name with value as label values.\n      For survival labels, the value is a dict holding both event censor tensor\n      and time_to_event tensor. For classification labels, the value is the\n      label class. The tensor shapes are both [batch_size, 1].\n  \"\"\"", "\n", "per_head_label_map", "=", "{", "}", "\n", "for", "key", "in", "labels", ":", "\n", "    ", "if", "key", "+", "'.time_to_event'", "in", "labels", ":", "\n", "# key is a survival label.", "\n", "      ", "per_head_label_map", "[", "key", "]", "=", "dict", "(", ")", "\n", "if", "len", "(", "labels", "[", "key", "]", ".", "shape", ")", "==", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "'expected_labels_shape: [batch_size,1]. labels_shape: {}.'", ".", "format", "(", "\n", "labels", "[", "key", "]", ".", "shape", ")", ")", "\n", "", "per_head_label_map", "[", "key", "]", "[", "key", "]", "=", "labels", "[", "key", "]", "\n", "per_head_label_map", "[", "key", "]", "[", "key", "+", "'.time_to_event'", "]", "=", "tf", ".", "cast", "(", "\n", "labels", "[", "key", "+", "'.time_to_event'", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "elif", "key", ".", "endswith", "(", "'.time_to_event'", ")", ":", "\n", "# this label is a time_to_event label, which is paired with the event.", "\n", "      ", "continue", "\n", "", "else", ":", "\n", "# key is a non-survival label.", "\n", "      ", "per_head_label_map", "[", "key", "]", "=", "labels", "[", "key", "]", "\n", "", "", "return", "per_head_label_map", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._recent_input_module": [[19, 29], ["None"], "function", ["None"], ["def", "_recent_input_module", "(", "input_tensor", ":", "tf", ".", "Tensor", ")", "->", "tf", ".", "Tensor", ":", "\n", "  ", "\"\"\"Create a module of that takes the most recent input.\n\n  Args:\n    input_tensor: input tensor of shape [batch_size, window_size, num_features].\n\n  Returns:\n    A Tensor of shape [batch_size, num_features].\n  \"\"\"", "\n", "return", "input_tensor", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._fully_connected_module": [[31, 75], ["tensorflow.variable_scope", "range", "tensorflow.layers.dense", "tensorflow.layers.dropout", "tensorflow.layers.dense", "str", "str"], "function", ["None"], ["", "def", "_fully_connected_module", "(", "input_tensor", ":", "tf", ".", "Tensor", ",", "num_dense_layers", ":", "int", ",", "\n", "dense_layer_size", ":", "int", ",", "output_layer_size", ":", "int", ",", "\n", "output_activation", ",", "is_training", ":", "bool", ",", "\n", "drop_rate", ":", "float", ",", "\n", "name", ":", "bytes", ",", "\n", "trainable", ":", "bool", "=", "True", ")", "->", "tf", ".", "Tensor", ":", "\n", "  ", "\"\"\"Create a module of multiple connected dense layers.\n\n  Args:\n    input_tensor: input tensor of shape [batch_size, input_dimension].\n    num_dense_layers: number of dense layers in this module.\n    dense_layer_size: number of hidden units for each dense layer.\n    output_layer_size: number of units for output layer.\n    output_activation: output layer activation function.\n    is_training: whether being used in training mode.\n    drop_rate: dropout probability. Dropout is applied to each dense layer under\n      training mode.\n    name: module name.\n    trainable: whether vars in this module are trainable.\n\n  Returns:\n    A Tensor of shape [batch_size, output_dimension].\n  \"\"\"", "\n", "net_output", "=", "input_tensor", "\n", "with", "tf", ".", "variable_scope", "(", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "    ", "for", "layer_num", "in", "range", "(", "num_dense_layers", "-", "1", ")", ":", "\n", "      ", "net_output", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "net_output", ",", "\n", "dense_layer_size", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "trainable", "=", "trainable", ",", "\n", "name", "=", "name", "+", "'_'", "+", "str", "(", "layer_num", ")", ")", "\n", "\n", "", "net_output", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "net_output", ",", "\n", "output_layer_size", ",", "\n", "activation", "=", "output_activation", ",", "\n", "trainable", "=", "trainable", ",", "\n", "name", "=", "name", "+", "'_'", "+", "str", "(", "num_dense_layers", "-", "1", ")", ")", "\n", "\n", "net_output", "=", "tf", ".", "layers", ".", "dropout", "(", "\n", "net_output", ",", "rate", "=", "drop_rate", ",", "training", "=", "is_training", ")", "\n", "\n", "", "return", "net_output", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._interv_forecast_module": [[78, 91], ["modules._fully_connected_module"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._fully_connected_module"], ["", "def", "_interv_forecast_module", "(", "state", ",", "interv_size", ",", "interv_nmlp", ",", "interv_smlp", ",", "\n", "name_tag", ",", "trainable", "=", "True", ")", ":", "\n", "# state shape [batch_size, state_size]", "\n", "  ", "return", "_fully_connected_module", "(", "\n", "input_tensor", "=", "state", ",", "\n", "num_dense_layers", "=", "interv_nmlp", ",", "\n", "dense_layer_size", "=", "interv_smlp", ",", "\n", "output_layer_size", "=", "interv_size", ",", "\n", "output_activation", "=", "tf", ".", "nn", ".", "sigmoid", ",", "\n", "is_training", "=", "True", ",", "\n", "drop_rate", "=", "0", ",", "\n", "name", "=", "'interv_forecast'", "+", "name_tag", ",", "\n", "trainable", "=", "trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._hazard_emission_module": [[93, 105], ["modules._fully_connected_module"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._fully_connected_module"], ["", "def", "_hazard_emission_module", "(", "state", ",", "hazard_nmlp", ",", "hazard_smlp", ",", "name_tag", ")", ":", "\n", "# state shape [batch_size, state_size]", "\n", "  ", "return", "_fully_connected_module", "(", "\n", "input_tensor", "=", "state", ",", "\n", "num_dense_layers", "=", "hazard_nmlp", ",", "\n", "dense_layer_size", "=", "hazard_smlp", ",", "\n", "output_layer_size", "=", "1", ",", "\n", "output_activation", "=", "tf", ".", "nn", ".", "sigmoid", ",", "\n", "is_training", "=", "True", ",", "\n", "drop_rate", "=", "0", ",", "\n", "name", "=", "'hazard_emission'", "+", "name_tag", ",", "\n", "trainable", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._obs_emission_module": [[107, 120], ["modules._fully_connected_module"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._fully_connected_module"], ["", "def", "_obs_emission_module", "(", "state", ",", "obs_size", ",", "obs_nmlp", ",", "obs_smlp", ",", "name_tag", ",", "\n", "emission_activation", ")", ":", "\n", "# state shape [batch_size, state_size]", "\n", "  ", "return", "_fully_connected_module", "(", "\n", "input_tensor", "=", "state", ",", "\n", "num_dense_layers", "=", "obs_nmlp", ",", "\n", "dense_layer_size", "=", "obs_smlp", ",", "\n", "output_layer_size", "=", "obs_size", ",", "\n", "output_activation", "=", "emission_activation", ",", "\n", "is_training", "=", "True", ",", "\n", "drop_rate", "=", "0", ",", "\n", "name", "=", "'obs_emission'", "+", "name_tag", ",", "\n", "trainable", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._state_tran_module": [[122, 175], ["tensorflow.logging.info", "modules._fully_connected_module", "modules._fully_connected_module", "modules._fully_connected_module", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.ones_like"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._fully_connected_module", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._fully_connected_module", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._fully_connected_module"], ["", "def", "_state_tran_module", "(", "state", ",", "state_size", ",", "stran_nmlp", ",", "stran_smlp", ",", "name_tag", ",", "\n", "trainable", "=", "True", ")", ":", "\n", "  ", "\"\"\"Create a module for state transition.\n\n  Args:\n    state: input tensor of shape [batch_size, state_size].\n    state_size: size of output layer.\n    stran_nmlp: number of layers.\n    stran_smlp: number of hidden units for each dense layer.\n    name_tag: name tag to differentiate different.\n    trainable: whether vars in this module are trainable.\n\n  Returns:\n    state_mean: mean value tensor of state shape [batch_size, state_size].\n  \"\"\"", "\n", "\n", "# state shape [batch_size, state_size]", "\n", "tf", ".", "logging", ".", "info", "(", "state", ")", "\n", "gate", "=", "_fully_connected_module", "(", "\n", "input_tensor", "=", "state", ",", "\n", "num_dense_layers", "=", "stran_nmlp", ",", "\n", "dense_layer_size", "=", "stran_smlp", ",", "\n", "output_layer_size", "=", "state_size", ",", "\n", "output_activation", "=", "tf", ".", "nn", ".", "sigmoid", ",", "\n", "is_training", "=", "True", ",", "\n", "drop_rate", "=", "0", ",", "\n", "name", "=", "'state_tran_gate'", "+", "name_tag", ",", "\n", "trainable", "=", "trainable", ")", "\n", "nonlinear_state_candidate", "=", "_fully_connected_module", "(", "\n", "input_tensor", "=", "state", ",", "\n", "num_dense_layers", "=", "stran_nmlp", ",", "\n", "dense_layer_size", "=", "stran_smlp", ",", "\n", "output_layer_size", "=", "state_size", ",", "\n", "output_activation", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "drop_rate", "=", "0", ",", "\n", "name", "=", "'nonlinear_state_candidate'", "+", "name_tag", ",", "\n", "trainable", "=", "trainable", ")", "\n", "linear_state_candidate", "=", "_fully_connected_module", "(", "\n", "input_tensor", "=", "state", ",", "\n", "num_dense_layers", "=", "1", ",", "\n", "dense_layer_size", "=", "stran_smlp", ",", "\n", "output_layer_size", "=", "state_size", ",", "\n", "output_activation", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "drop_rate", "=", "0", ",", "\n", "name", "=", "'linear_state_candidate'", "+", "name_tag", ",", "\n", "trainable", "=", "trainable", ")", "\n", "\n", "state_mean", "=", "tf", ".", "multiply", "(", "tf", ".", "ones_like", "(", "gate", ")", "-", "gate", ",", "\n", "linear_state_candidate", ")", "+", "tf", ".", "multiply", "(", "\n", "gate", ",", "nonlinear_state_candidate", ")", "\n", "return", "state_mean", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._control_tran_module": [[177, 229], ["modules._fully_connected_module", "modules._fully_connected_module", "modules._fully_connected_module", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.ones_like"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._fully_connected_module", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._fully_connected_module", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._fully_connected_module"], ["", "def", "_control_tran_module", "(", "interv", ",", "state_size", ",", "ctran_nmlp", ",", "ctran_smlp", ",", "name_tag", ",", "\n", "trainable", "=", "True", ")", ":", "\n", "  ", "\"\"\"Create a module for control transition.\n\n  Args:\n    interv: input tensor of shape [batch_size, interv_size].\n    state_size: size of output layer.\n    ctran_nmlp: number of layers.\n    ctran_smlp: number of hidden units for each dense layer.\n    name_tag: name tag to differentiate different.\n    trainable: whether vars in this module are trainable.\n\n  Returns:\n    state_mean: mean value tensor of state shape [batch_size, state_size].\n  \"\"\"", "\n", "\n", "control_gate", "=", "_fully_connected_module", "(", "\n", "input_tensor", "=", "interv", ",", "\n", "num_dense_layers", "=", "ctran_nmlp", ",", "\n", "dense_layer_size", "=", "ctran_smlp", ",", "\n", "output_layer_size", "=", "state_size", ",", "\n", "output_activation", "=", "tf", ".", "nn", ".", "sigmoid", ",", "\n", "is_training", "=", "True", ",", "\n", "drop_rate", "=", "0", ",", "\n", "name", "=", "'control_tran_gate'", "+", "name_tag", ",", "\n", "trainable", "=", "trainable", ")", "\n", "control_nonlinear_state_candidate", "=", "_fully_connected_module", "(", "\n", "input_tensor", "=", "interv", ",", "\n", "num_dense_layers", "=", "ctran_nmlp", ",", "\n", "dense_layer_size", "=", "ctran_smlp", ",", "\n", "output_layer_size", "=", "state_size", ",", "\n", "output_activation", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "drop_rate", "=", "0", ",", "\n", "name", "=", "'control_nonlinear_state_candidate'", "+", "name_tag", ",", "\n", "trainable", "=", "trainable", ")", "\n", "control_linear_state_candidate", "=", "_fully_connected_module", "(", "\n", "input_tensor", "=", "interv", ",", "\n", "num_dense_layers", "=", "1", ",", "\n", "dense_layer_size", "=", "ctran_smlp", ",", "\n", "output_layer_size", "=", "state_size", ",", "\n", "output_activation", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "drop_rate", "=", "0", ",", "\n", "name", "=", "'control_linear_state_candidate'", "+", "name_tag", ",", "\n", "trainable", "=", "trainable", ")", "\n", "\n", "state_mean", "=", "tf", ".", "multiply", "(", "\n", "tf", ".", "ones_like", "(", "control_gate", ")", "-", "control_gate", ",", "\n", "control_linear_state_candidate", ")", "+", "tf", ".", "multiply", "(", "\n", "control_gate", ",", "control_nonlinear_state_candidate", ")", "\n", "return", "state_mean", "\n", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.train.default_hparams": [[57, 76], ["tensorflow.HParams"], "function", ["None"], ["def", "default_hparams", "(", ")", ":", "\n", "  ", "\"\"\"Define default Hparams.\"\"\"", "\n", "\n", "hparam_kwargs", "=", "{", "\n", "'model__learning_rate'", ":", "0.001", ",", "\n", "'model__da_state'", ":", "100", ",", "\n", "'model__da_tlen'", ":", "240", ",", "\n", "'model__da_sslot'", ":", "12", ",", "\n", "'model__da_unit'", ":", "32", ",", "\n", "'model__da_psi_mlpl'", ":", "1", ",", "\n", "'model__da_phi_mlpl'", ":", "3", ",", "\n", "'model__ds_state'", ":", "30", ",", "\n", "'model__ds_nrl'", ":", "1", ",", "\n", "'model__rnn_type'", ":", "'basic'", ",", "\n", "'model__rnn_cell_type'", ":", "'lstm'", ",", "\n", "'model__last_obs_len'", ":", "30", ",", "\n", "'model__sys_id_weight'", ":", "1.0", ",", "\n", "}", "\n", "return", "tf", ".", "HParams", "(", "**", "hparam_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.train.get_best_model_dir": [[78, 94], ["os.listdir", "int", "re.fullmatch", "max"], "function", ["None"], ["", "def", "get_best_model_dir", "(", "model_dir", ")", ":", "\n", "  ", "\"\"\"Get the best model dir from model_dir.\n\n  Args:\n    model_dir: Model dir.\n\n  Returns:\n    A string for best model dir.\n  \"\"\"", "\n", "if", "model_dir", "is", "None", ":", "\n", "    ", "return", "None", "\n", "", "paths", "=", "os", ".", "listdir", "(", "model_dir", ")", "\n", "\n", "versions", "=", "[", "int", "(", "p", ")", "for", "p", "in", "paths", "if", "re", ".", "fullmatch", "(", "r'\\d+'", ",", "p", ")", "]", "\n", "best_model_dir", "=", "'%s/%d'", "%", "(", "model_dir", ",", "max", "(", "versions", ")", ")", "\n", "return", "best_model_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.train.main": [[96, 123], ["default_hparams().parse", "config_utils.load_experiment_config", "train.get_best_model_dir", "experiment.get_experiment_fn", "tensorflow.contrib.learn.python.learn.learn_runner.EstimatorConfig", "tensorflow.contrib.learn.python.learn.learn_runner.run", "train.default_hparams"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.config_utils.load_experiment_config", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.train.get_best_model_dir", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.experiment.get_experiment_fn", "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.experiment.run", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.train.default_hparams"], ["", "def", "main", "(", "_", ")", ":", "\n", "# Parse hparams from FLAGs. Format example is provided below.", "\n", "# --hparams=\"model__optimizer__learning_rate=0.1,model__min_kernel_size=3\"", "\n", "  ", "hparams", "=", "default_hparams", "(", ")", ".", "parse", "(", "FLAGS", ".", "hparams", ")", "\n", "experiment_config", "=", "config_utils", ".", "load_experiment_config", "(", "\n", "FLAGS", ".", "experiment_config", ")", "\n", "if", "FLAGS", ".", "train_path", "is", "not", "None", ":", "\n", "    ", "experiment_config", ".", "train_sources", "[", "0", "]", "=", "FLAGS", ".", "train_path", "\n", "", "if", "FLAGS", ".", "eval_path", "is", "not", "None", ":", "\n", "    ", "experiment_config", ".", "eval_sources", "[", "0", "]", "=", "FLAGS", ".", "eval_path", "\n", "\n", "", "best_model_dir", "=", "get_best_model_dir", "(", "FLAGS", ".", "warm_start_from", ")", "\n", "experiment_fn", "=", "experiment", ".", "get_experiment_fn", "(", "\n", "experiment_config", ",", "\n", "warm_start_from", "=", "best_model_dir", ",", "\n", "train_steps", "=", "FLAGS", ".", "num_train_steps", ",", "\n", "eval_steps", "=", "FLAGS", ".", "num_eval_steps", ",", "\n", "continuous_eval_throttle_secs", "=", "FLAGS", ".", "continuous_eval_throttle_secs", ",", "\n", "eval_delay_secs", "=", "0", ")", "\n", "# To migrate to tf.estimator.RunConfig.", "\n", "run_config", "=", "learn_runner", ".", "EstimatorConfig", "(", "\n", "model_dir", "=", "FLAGS", ".", "output_dir", ",", "\n", "save_checkpoints_steps", "=", "FLAGS", ".", "save_checkpoints_steps", ",", "\n", "save_summary_steps", "=", "FLAGS", ".", "save_checkpoints_steps", ",", "\n", "keep_checkpoint_max", "=", "FLAGS", ".", "keep_checkpoint_max", ")", "\n", "learn_runner", ".", "run", "(", "\n", "experiment_fn", "=", "experiment_fn", ",", "run_config", "=", "run_config", ",", "hparams", "=", "hparams", ")", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.experiment.get_experiment_fn": [[24, 76], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.estimator.Estimator", "data_provider.DataProvider.from_config", "tensorflow.contrib.learn.Experiment", "tensorflow.logging.info", "config_utils.merge_from_hparams", "google.protobuf.text_format.MessageToString", "google.protobuf.text_format.MessageToString", "data_provider.DataProvider.from_config.get_input_fn", "data_provider.DataProvider.from_config.get_input_fn"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.data_provider.DataProvider.from_config", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.config_utils.merge_from_hparams", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.data_provider.DataProvider.get_input_fn", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.data_provider.DataProvider.get_input_fn"], ["def", "get_experiment_fn", "(", "experiment_config", ":", "experiment_config_pb2", ".", "ExperimentConfig", ",", "\n", "warm_start_from", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "  ", "\"\"\"Creates a function which builds a tf.contrib.learn.Experiment object.\n\n  Args:\n    experiment_config: experiment configuration.\n    warm_start_from: Optional string filepath to a checkpoint or SavedModel to\n      warm-start from.\n    **kwargs: Additional keyword arguments passed to experiment.\n\n  Returns:\n    A function of two arguments, `run_config` and `hparams`, which builds a\n    tf.contrib.learn.Experiment object.\n  \"\"\"", "\n", "\n", "def", "experiment_fn", "(", "run_config", ",", "hparams", ":", "tf", ".", "HParams", "=", "None", ")", ":", "\n", "    ", "\"\"\"Create a tf.contrib.learn.Experiment object.\n\n    Args:\n      run_config: An instance of learn_runner.EstimatorConfig.\n      hparams: hparams passed from FLAGs.hparams which will be used to override\n        the values from experiment_config.\n\n    Returns:\n      A tf.contrib.learn.Experiment object.\n    \"\"\"", "\n", "config", "=", "experiment_config", "\n", "if", "hparams", "is", "not", "None", ":", "\n", "# Populate command-line hparams to config.", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "'Using command-line hyperparameters %s'", ",", "hparams", ")", "\n", "config", "=", "config_utils", ".", "merge_from_hparams", "(", "\n", "experiment_config", ",", "hparams", ",", "delimiter", "=", "'__'", ")", "\n", "", "config", ".", "experiment_dir", "=", "run_config", ".", "model_dir", "\n", "tf", ".", "logging", ".", "info", "(", "'experiment config: '", "+", "text_format", ".", "MessageToString", "(", "config", ")", ")", "\n", "tf", ".", "logging", ".", "info", "(", "'run config:'", "+", "\n", "text_format", ".", "MessageToString", "(", "run_config", ".", "tf_config", ")", ")", "\n", "estimator", "=", "tf", ".", "estimator", ".", "Estimator", "(", "\n", "model_fn", "=", "models", ".", "build_model_ops", ",", "\n", "params", "=", "config", ".", "model", ",", "\n", "config", "=", "run_config", ",", "\n", "warm_start_from", "=", "warm_start_from", ")", "\n", "provider", "=", "data_provider", ".", "DataProvider", ".", "from_config", "(", "config", ")", "\n", "export_strategies", "=", "[", "]", "\n", "return", "tf", ".", "contrib", ".", "learn", ".", "Experiment", "(", "\n", "estimator", "=", "estimator", ",", "\n", "train_input_fn", "=", "provider", ".", "get_input_fn", "(", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", ",", "\n", "eval_input_fn", "=", "provider", ".", "get_input_fn", "(", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ")", ",", "\n", "export_strategies", "=", "export_strategies", ",", "\n", "**", "kwargs", ")", "\n", "\n", "", "return", "experiment_fn", "\n", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.LeakyReLU.__init__": [[37, 44], ["tfb.Bijector.__init__"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__"], ["def", "__init__", "(", "self", ",", "alpha", "=", "0.5", ",", "validate_args", "=", "False", ",", "name", "=", "'leaky_relu'", ")", ":", "\n", "    ", "super", "(", "LeakyReLU", ",", "self", ")", ".", "__init__", "(", "\n", "forward_min_event_ndims", "=", "0", ",", "\n", "validate_args", "=", "validate_args", ",", "\n", "name", "=", "name", ",", "\n", "is_constant_jacobian", "=", "True", ")", "\n", "self", ".", "alpha", "=", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.LeakyReLU._forward": [[45, 47], ["tensorflow.where", "tensorflow.greater_equal"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "tf", ".", "where", "(", "tf", ".", "greater_equal", "(", "x", ",", "0", ")", ",", "x", ",", "self", ".", "alpha", "*", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.LeakyReLU._inverse": [[48, 50], ["tensorflow.where", "tensorflow.greater_equal"], "methods", ["None"], ["", "def", "_inverse", "(", "self", ",", "y", ")", ":", "\n", "    ", "return", "tf", ".", "where", "(", "tf", ".", "greater_equal", "(", "y", ",", "0", ")", ",", "y", ",", "1.", "/", "self", ".", "alpha", "*", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.LeakyReLU._inverse_log_det_jacobian": [[51, 56], ["tensorflow.ones_like", "tensorflow.where", "tensorflow.log", "tensorflow.greater_equal", "tensorflow.abs"], "methods", ["None"], ["", "def", "_inverse_log_det_jacobian", "(", "self", ",", "y", ")", ":", "\n", "    ", "idt", "=", "tf", ".", "ones_like", "(", "y", ")", "\n", "jacobian_inv", "=", "tf", ".", "where", "(", "tf", ".", "greater_equal", "(", "y", ",", "0", ")", ",", "idt", ",", "1.0", "/", "self", ".", "alpha", "*", "idt", ")", "\n", "log_abs_det_jacobian_inv", "=", "tf", ".", "log", "(", "tf", ".", "abs", "(", "jacobian_inv", ")", ")", "\n", "return", "log_abs_det_jacobian_inv", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.SurvivalModel.params": [[61, 65], ["NotImplementedError"], "methods", ["None"], ["@", "abc", ".", "abstractproperty", "\n", "def", "params", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns the parameters of this model.\"\"\"", "\n", "raise", "NotImplementedError", "(", "'Calling an abstract method.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.SurvivalModel.log_pdf": [[66, 70], ["NotImplementedError"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "log_pdf", "(", "self", ",", "t", ")", ":", "\n", "    ", "\"\"\"Returns the log of probablity density function.\"\"\"", "\n", "raise", "NotImplementedError", "(", "'Calling an abstract method.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.SurvivalModel.log_survival_func": [[71, 75], ["NotImplementedError"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "log_survival_func", "(", "self", ",", "t", ")", ":", "\n", "    ", "\"\"\"Returns the log of survival function.\"\"\"", "\n", "raise", "NotImplementedError", "(", "'Calling an abstract method.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.SurvivalModel.cdf": [[76, 80], ["NotImplementedError"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "cdf", "(", "self", ",", "t", ")", ":", "\n", "    ", "\"\"\"Cumulative incidence/density functions.\"\"\"", "\n", "raise", "NotImplementedError", "(", "'Calling an abstract method.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.SurvivalModel.hazard_rate": [[81, 85], ["NotImplementedError"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "hazard_rate", "(", "self", ",", "t", ")", ":", "\n", "    ", "\"\"\"Instantaneous rate of event occurrence in 1/sec .\"\"\"", "\n", "raise", "NotImplementedError", "(", "'Calling an abstract method.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.SurvivalModel.probability": [[86, 90], ["NotImplementedError"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "probability", "(", "self", ")", ":", "\n", "    ", "\"\"\"Expected incidence probability.\"\"\"", "\n", "raise", "NotImplementedError", "(", "'Calling an abstract method.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.SurvivalModel.predicted_time": [[91, 95], ["NotImplementedError"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "predicted_time", "(", "self", ")", ":", "\n", "    ", "\"\"\"Predicted Event Time in sec.\"\"\"", "\n", "raise", "NotImplementedError", "(", "'Calling an abstract method.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.SurvivalModel.probability_within_window": [[96, 100], ["NotImplementedError"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "probability_within_window", "(", "self", ",", "window_start_t", ",", "window_end_t", ")", ":", "\n", "    ", "\"\"\"Predicted Event Probability within window.\"\"\"", "\n", "raise", "NotImplementedError", "(", "'Calling an abstract method.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.ParametricExponentialSurvivalModel.__init__": [[105, 120], ["tensorflow.python.ops.array_ops.shape", "tensorflow.python.ops.check_ops.assert_rank_at_least", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.exp", "tensorflow_probability.distributions.Exponential"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "params", ",", "labels", ",", "event_index", ",", "model_hparams", "=", "None", ")", ":", "\n", "    ", "del", "model_hparams", "\n", "del", "labels", "\n", "del", "event_index", "\n", "params_shape", "=", "array_ops", ".", "shape", "(", "params", ")", "\n", "assert_rank", "=", "check_ops", ".", "assert_rank_at_least", "(", "\n", "params", ",", "\n", "2", ",", "\n", "data", "=", "[", "params_shape", "]", ",", "\n", "message", "=", "'Exponential model params shape must be [batch_size, 1]'", ")", "\n", "\n", "with", "ops", ".", "control_dependencies", "(", "[", "assert_rank", "]", ")", ":", "\n", "# TODO(yuanxue,gafm): Experiment with tf.softplus.", "\n", "      ", "self", ".", "_rate_param", "=", "tf", ".", "exp", "(", "params", "+", "INITIAL_LN_RATE", ")", "\n", "self", ".", "_distribution", "=", "tfp", ".", "distributions", ".", "Exponential", "(", "rate", "=", "self", ".", "_rate_param", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.ParametricExponentialSurvivalModel.params": [[121, 124], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "params", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_rate_param", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.ParametricExponentialSurvivalModel.log_pdf": [[125, 138], ["survival_util.ParametricExponentialSurvivalModel._distribution.log_prob"], "methods", ["None"], ["", "def", "log_pdf", "(", "self", ",", "t", ")", ":", "\n", "    ", "\"\"\"Log of PDF of exponential distribution.\n\n       PDF(t, lambda) = lambda * exp(-lambda * t)\n       log(PDF(t, lambda)) = log(lambda) - lambda * t\n    Args:\n      t: time instance where the function is evaluated: scalar or tensor of\n        [batch_size, 1]\n\n    Returns:\n      Value of log of PDF of exponential distribution: tensor of [batch_size, 1]\n    \"\"\"", "\n", "return", "self", ".", "_distribution", ".", "log_prob", "(", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.ParametricExponentialSurvivalModel.log_survival_func": [[139, 152], ["survival_util.ParametricExponentialSurvivalModel._distribution.log_prob", "tensorflow.log"], "methods", ["None"], ["", "def", "log_survival_func", "(", "self", ",", "t", ")", ":", "\n", "    ", "\"\"\"Log of survival function of exponential distribution.\n\n       S(t, lambda) = 1- CDF(t, lambda) = exp(-lambda * t)\n       log(S(t, lambda)) = - lambda*t\n    Args:\n      t: time instance where the function is evaluated.\n    Returns:\n      Value of log of survival function of exponential distribution.\n    \"\"\"", "\n", "# Note that in the tfp implementation of Exponential distribution,", "\n", "# log_prob is more stable than log_survival_function.", "\n", "return", "self", ".", "_distribution", ".", "log_prob", "(", "t", ")", "-", "tf", ".", "log", "(", "self", ".", "_rate_param", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.ParametricExponentialSurvivalModel.cdf": [[153, 164], ["tensorflow.exp"], "methods", ["None"], ["", "def", "cdf", "(", "self", ",", "t", ")", ":", "\n", "    ", "\"\"\"Cumulative incidence functions: probablity of event happening before t.\n\n       F(t, lambda) = CDF(t, lambda)  = 1- exp(-lambda * t)\n    Args:\n      t: time instance where the function is evaluated.\n\n    Returns:\n      Value of log of survival function of exponential distribution.\n    \"\"\"", "\n", "return", "1", "-", "tf", ".", "exp", "(", "-", "self", ".", "_rate_param", "*", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.ParametricExponentialSurvivalModel.hazard_rate": [[165, 168], ["None"], "methods", ["None"], ["", "def", "hazard_rate", "(", "self", ",", "t", ")", ":", "\n", "    ", "\"\"\"Instantaneous rate of event occurrence.\"\"\"", "\n", "return", "self", ".", "_rate_param", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.ParametricExponentialSurvivalModel.probability": [[169, 172], ["None"], "methods", ["None"], ["", "def", "probability", "(", "self", ")", ":", "\n", "    ", "\"\"\"Expected incidence probability.\"\"\"", "\n", "return", "self", ".", "_rate_param", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.ParametricExponentialSurvivalModel.predicted_time": [[173, 175], ["tensorflow.div", "tensorflow.reciprocal"], "methods", ["None"], ["", "def", "predicted_time", "(", "self", ")", ":", "\n", "    ", "return", "tf", ".", "div", "(", "tf", ".", "reciprocal", "(", "self", ".", "_rate_param", ")", ",", "UNITS_IN_HR", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.ParametricExponentialSurvivalModel.probability_within_window": [[176, 179], ["tensorflow.exp", "tensorflow.exp"], "methods", ["None"], ["", "def", "probability_within_window", "(", "self", ",", "window_start_t", ",", "window_end_t", ")", ":", "\n", "    ", "return", "tf", ".", "exp", "(", "-", "self", ".", "_rate_param", "*", "window_start_t", ")", "-", "tf", ".", "exp", "(", "\n", "-", "self", ".", "_rate_param", "*", "window_end_t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.CoxSurvivalModel.__init__": [[184, 210], ["tensorflow.python.ops.array_ops.shape", "tensorflow.python.ops.check_ops.assert_rank_at_least", "tensorflow.python.framework.ops.control_dependencies", "params.get_shape", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.exp", "tensorflow_probability.distributions.Exponential", "tensorflow.matmul", "tensorflow.initializers.truncated_normal", "tensorflow.initializers.truncated_normal"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "params", ",", "labels", ",", "event_index", ",", "model_hparams", "=", "None", ")", ":", "\n", "    ", "del", "model_hparams", "\n", "del", "labels", "\n", "del", "event_index", "\n", "params_shape", "=", "array_ops", ".", "shape", "(", "params", ")", "\n", "assert_rank", "=", "check_ops", ".", "assert_rank_at_least", "(", "\n", "params", ",", "\n", "2", ",", "\n", "data", "=", "[", "params_shape", "]", ",", "\n", "message", "=", "'Cox model params shape must be [batch_size, num_feature]'", ")", "\n", "\n", "with", "ops", ".", "control_dependencies", "(", "[", "assert_rank", "]", ")", ":", "\n", "      ", "logits_shape", "=", "params", ".", "get_shape", "(", ")", "[", "1", "]", "\n", "# We assume the base rate is constant in this implementation:", "\n", "# lambda = lambda_0 * exp(X * weights) = exp (bias + logits * weights)", "\n", "with", "tf", ".", "variable_scope", "(", "'logit_to_parameter'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "self", ".", "_weights", "=", "tf", ".", "get_variable", "(", "\n", "'weights'", ",", "[", "logits_shape", ",", "1", "]", ",", "\n", "initializer", "=", "tf", ".", "initializers", ".", "truncated_normal", "(", "0", ",", "0.01", ")", ")", "\n", "self", ".", "_bias", "=", "tf", ".", "get_variable", "(", "\n", "'bias'", ",", "[", "1", "]", ",", "\n", "initializer", "=", "tf", ".", "initializers", ".", "truncated_normal", "(", "0.01", ",", "0.01", ")", ")", "\n", "weighted_logits", "=", "tf", ".", "matmul", "(", "params", ",", "self", ".", "_weights", ")", "+", "self", ".", "_bias", "\n", "self", ".", "_rate_param", "=", "tf", ".", "exp", "(", "weighted_logits", ")", "\n", "self", ".", "_distribution", "=", "tfp", ".", "distributions", ".", "Exponential", "(", "\n", "rate", "=", "self", ".", "_rate_param", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.CoxSurvivalModel.params": [[211, 214], ["None"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "params", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_rate_param", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.CoxSurvivalModel.log_pdf": [[215, 227], ["survival_util.CoxSurvivalModel._distribution.log_prob"], "methods", ["None"], ["", "def", "log_pdf", "(", "self", ",", "t", ")", ":", "\n", "    ", "\"\"\"Log of PDF of exponential distribution.\n\n       PDF(t, lambda) = lambda * exp(-lambda * t)\n       log(PDF(t, lambda)) = log(lambda) - lambda * t\n    Args:\n      t: time instance where the function is evaluated.\n\n    Returns:\n      Value of log of PDF of exponential distribution.\n    \"\"\"", "\n", "return", "self", ".", "_distribution", ".", "log_prob", "(", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.CoxSurvivalModel.log_survival_func": [[228, 242], ["survival_util.CoxSurvivalModel._distribution.log_prob", "tensorflow.log"], "methods", ["None"], ["", "def", "log_survival_func", "(", "self", ",", "t", ")", ":", "\n", "    ", "\"\"\"Log of survival function of exponential distribution.\n\n       S(t, lambda) = 1- CDF(t, lambda) = exp(-lambda * t)\n       log(S(t, lambda)) = - lambda*t\n    Args:\n      t: time instance where the function is evaluated.\n\n    Returns:\n      Value of log of survival function of exponential distribution.\n    \"\"\"", "\n", "# Note that in the tfp implementation of Exponential distribution,", "\n", "# log_prob is more stable than log_survival_function.", "\n", "return", "self", ".", "_distribution", ".", "log_prob", "(", "t", ")", "-", "tf", ".", "log", "(", "self", ".", "_rate_param", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.CoxSurvivalModel.cdf": [[243, 254], ["tensorflow.exp"], "methods", ["None"], ["", "def", "cdf", "(", "self", ",", "t", ")", ":", "\n", "    ", "\"\"\"Cumulative incidence functions: probablity of event happening before t.\n\n       F(t, lambda) = CDF(t, lambda)  = 1- exp(-lambda * t)\n    Args:\n      t: time instance where the function is evaluated.\n\n    Returns:\n      Value of log of survival function of exponential distribution.\n    \"\"\"", "\n", "return", "1", "-", "tf", ".", "exp", "(", "-", "self", ".", "_rate_param", "*", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.CoxSurvivalModel.hazard_rate": [[255, 258], ["None"], "methods", ["None"], ["", "def", "hazard_rate", "(", "self", ",", "t", ")", ":", "\n", "    ", "\"\"\"Instantaneous rate of event occurrence.\"\"\"", "\n", "return", "self", ".", "_rate_param", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.CoxSurvivalModel.probability": [[259, 262], ["None"], "methods", ["None"], ["", "def", "probability", "(", "self", ")", ":", "\n", "    ", "\"\"\"Expected incidence probability.\"\"\"", "\n", "return", "self", ".", "_rate_param", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.CoxSurvivalModel.predicted_time": [[263, 265], ["tensorflow.reciprocal"], "methods", ["None"], ["", "def", "predicted_time", "(", "self", ")", ":", "\n", "    ", "return", "tf", ".", "reciprocal", "(", "self", ".", "_rate_param", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.CoxSurvivalModel.probability_within_window": [[266, 269], ["tensorflow.exp", "tensorflow.exp"], "methods", ["None"], ["", "def", "probability_within_window", "(", "self", ",", "window_start_t", ",", "window_end_t", ")", ":", "\n", "    ", "return", "tf", ".", "exp", "(", "-", "self", ".", "_rate_param", "*", "window_start_t", ")", "-", "tf", ".", "exp", "(", "\n", "-", "self", ".", "_rate_param", "*", "window_end_t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.__init__": [[274, 295], ["tensorflow.zeros", "survival_util.StateSpaceSurvivalModel._forecast_hazard", "tensorflow.squeeze", "tensorflow.clip_by_value", "init_state.get_shape().as_list", "init_state.get_shape"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel._forecast_hazard"], ["def", "__init__", "(", "self", ",", "params", ",", "labels", ",", "event_index", ",", "model_hparams", "=", "None", ")", ":", "\n", "    ", "del", "labels", "\n", "del", "event_index", "\n", "self", ".", "_model_hparams", "=", "model_hparams", "\n", "# init_state is encoded state at trigger time passed from params(logits).", "\n", "init_state", "=", "params", "\n", "self", ".", "_slot_size_hr", "=", "model_hparams", ".", "da_sslot", "\n", "self", ".", "_time_len", "=", "model_hparams", ".", "da_tlen", "\n", "batch_size", "=", "init_state", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "# params is the input x with shape [batch_size, num_features]", "\n", "if", "model_hparams", ".", "reuse_encoding", ":", "\n", "      ", "self", ".", "_tag", "=", "''", "\n", "", "else", ":", "\n", "      ", "self", ".", "_tag", "=", "'encode'", "\n", "", "hazard_at_trigger", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "1", "]", ")", "\n", "# forecast_hazard shape [da_tlen, batch_size, 1]", "\n", "forecast_hazard", "=", "self", ".", "_forecast_hazard", "(", "init_state", ",", "hazard_at_trigger", ")", "\n", "# self._hazard_tensor shape shape [TIME_LEN, batch_size]", "\n", "self", ".", "_hazard_tensor", "=", "tf", ".", "squeeze", "(", "forecast_hazard", ",", "axis", "=", "-", "1", ")", "\n", "self", ".", "_hazard_tensor", "=", "tf", ".", "clip_by_value", "(", "\n", "self", ".", "_hazard_tensor", ",", "1e-20", ",", "0.99999", ",", "name", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel._forecast_hazard": [[298, 314], ["tensorflow.logging.info", "tensorflow.zeros", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.scan"], "methods", ["None"], ["", "def", "_forecast_hazard", "(", "self", ",", "init_state", ",", "hazard_at_trigger", ")", ":", "\n", "    ", "\"\"\"Forecast hazard.\"\"\"", "\n", "tf", ".", "logging", ".", "info", "(", "init_state", ")", "\n", "dummy_input", "=", "tf", ".", "zeros", "(", "[", "self", ".", "_model_hparams", ".", "da_tlen", "]", ")", "\n", "tf", ".", "logging", ".", "info", "(", "dummy_input", ")", "\n", "tf", ".", "logging", ".", "info", "(", "hazard_at_trigger", ")", "\n", "\n", "# Get obs values at trigger time as base for delta prediction.", "\n", "forecast_hazard", ",", "_", "=", "tf", ".", "scan", "(", "\n", "self", ".", "_state_tran_and_hazard_emission_step_fn", ",", "\n", "dummy_input", ",", "# not used just control the steps.", "\n", "initializer", "=", "(", "hazard_at_trigger", ",", "init_state", ")", ",", "# state at trigger time", "\n", "parallel_iterations", "=", "10", ",", "\n", "name", "=", "'hazard_forecast_scan'", ")", "\n", "# forecast_hazard shape [da_tlen, batch_size, 1]", "\n", "return", "forecast_hazard", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel._state_tran_and_hazard_emission_step_fn": [[315, 349], ["modules._state_tran_module", "modules._hazard_emission_module", "tensorflow.logging.info", "tensorflow.logging.info", "modules._interv_forecast_module", "len", "modules._control_tran_module"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._state_tran_module", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._hazard_emission_module", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._interv_forecast_module", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.modules._control_tran_module"], ["", "def", "_state_tran_and_hazard_emission_step_fn", "(", "\n", "self", ",", "previous_output", ",", "current_input", ")", ":", "\n", "    ", "\"\"\"State transition and hazard rate emission in a single step.\"\"\"", "\n", "del", "current_input", "\n", "previous_hazard", ",", "previous_state", "=", "previous_output", "\n", "current_state", "=", "modules", ".", "_state_tran_module", "(", "# pylint: disable=protected-access", "\n", "previous_state", ",", "self", ".", "_model_hparams", ".", "ds_state", ",", "\n", "self", ".", "_model_hparams", ".", "stran_nmlp", ",", "self", ".", "_model_hparams", ".", "stran_smlp", ",", "\n", "self", ".", "_tag", ")", "\n", "\n", "if", "self", ".", "_model_hparams", ".", "forecast_interv", ":", "\n", "# interv forecast is performed and needs to be incorporated into state", "\n", "# transiention.", "\n", "      ", "current_interv", "=", "modules", ".", "_interv_forecast_module", "(", "# pylint: disable=protected-access", "\n", "previous_state", ",", "len", "(", "self", ".", "_model_hparams", ".", "intervention_codes", ")", ",", "\n", "self", ".", "_model_hparams", ".", "interv_nmlp", ",", "self", ".", "_model_hparams", ".", "interv_smlp", ",", "\n", "self", ".", "_tag", ")", "\n", "# next_interv is applied to next_state.", "\n", "current_state", "=", "current_state", "+", "modules", ".", "_control_tran_module", "(", "# pylint: disable=protected-access", "\n", "current_interv", ",", "self", ".", "_model_hparams", ".", "ds_state", ",", "\n", "self", ".", "_model_hparams", ".", "ctran_nmlp", ",", "self", ".", "_model_hparams", ".", "ctran_smlp", ",", "\n", "self", ".", "_tag", ")", "\n", "\n", "", "current_emission", "=", "modules", ".", "_hazard_emission_module", "(", "# pylint: disable=protected-access", "\n", "current_state", ",", "self", ".", "_model_hparams", ".", "hazard_nmlp", ",", "\n", "self", ".", "_model_hparams", ".", "hazard_smlp", ",", "self", ".", "_tag", ")", "\n", "if", "self", ".", "_model_hparams", ".", "forecast_delta", ":", "\n", "      ", "current_hazard", "=", "current_emission", "+", "previous_hazard", "\n", "", "else", ":", "\n", "      ", "current_hazard", "=", "current_emission", "\n", "", "tf", ".", "logging", ".", "info", "(", "current_hazard", ")", "\n", "tf", ".", "logging", ".", "info", "(", "current_state", ")", "\n", "\n", "return", "(", "current_hazard", ",", "current_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel._bucketize_t": [[350, 366], ["tensorflow.cast", "tensorflow.where", "tensorflow.where", "tensorflow.div", "tensorflow.greater_equal", "tensorflow.fill", "tensorflow.add", "tensorflow.greater_equal", "tensorflow.zeros_like", "tensorflow.shape", "tensorflow.ones_like"], "methods", ["None"], ["", "def", "_bucketize_t", "(", "self", ",", "t", ")", ":", "\n", "    ", "\"\"\"Turn time instance tensor t in sec to a time slot.\"\"\"", "\n", "# t shape [batch_size]", "\n", "time_slot", "=", "tf", ".", "cast", "(", "tf", ".", "div", "(", "t", ",", "self", ".", "_slot_size_hr", "*", "UNITS_IN_HR", ")", ",", "tf", ".", "int32", ")", "\n", "\n", "capped_time_slot", "=", "tf", ".", "where", "(", "\n", "tf", ".", "greater_equal", "(", "time_slot", ",", "self", ".", "_time_len", ")", ",", "\n", "tf", ".", "fill", "(", "tf", ".", "shape", "(", "time_slot", ")", ",", "self", ".", "_time_len", ")", ",", "\n", "tf", ".", "add", "(", "time_slot", ",", "tf", ".", "ones_like", "(", "time_slot", ")", ")", ")", "\n", "# position in #hrs in the last time slot.", "\n", "last_slot_hr", "=", "tf", ".", "where", "(", "\n", "tf", ".", "greater_equal", "(", "time_slot", ",", "self", ".", "_time_len", ")", ",", "\n", "time_slot", "-", "self", ".", "_time_len", "+", "1", ",", "\n", "tf", ".", "zeros_like", "(", "(", "time_slot", ")", ")", ")", "\n", "# capped_time_slot shape [batch_size], each value range [1, self._time_len]", "\n", "return", "capped_time_slot", ",", "last_slot_hr", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel._from_slot_to_time_range": [[367, 372], ["None"], "methods", ["None"], ["", "def", "_from_slot_to_time_range", "(", "self", ",", "slot", ")", ":", "\n", "    ", "\"\"\"Turn time slot slot (scalar) to a time range [t_start, t_end).\"\"\"", "\n", "t_start", "=", "slot", "*", "self", ".", "_slot_size_hr", "*", "UNITS_IN_HR", "\n", "t_end", "=", "(", "slot", "+", "1", ")", "*", "self", ".", "_slot_size_hr", "*", "UNITS_IN_HR", "\n", "return", "t_start", ",", "t_end", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.params": [[373, 375], ["tensorflow.transpose"], "methods", ["None"], ["", "def", "params", "(", "self", ")", ":", "\n", "    ", "return", "tf", ".", "transpose", "(", "self", ".", "_hazard_tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.log_pdf": [[376, 426], ["tensorflow.squeeze", "survival_util.StateSpaceSurvivalModel._bucketize_t", "tensorflow.fill", "tensorflow.sequence_mask", "tensorflow.multiply", "tensorflow.sequence_mask", "tensorflow.logical_xor", "tensorflow.boolean_mask", "tensorflow.shape", "tensorflow.cast", "tensorflow.transpose", "tensorflow.cast", "tensorflow.cast", "tensorflow.transpose", "tensorflow.reduce_sum", "tensorflow.log", "tensorflow.log", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.multiply", "tensorflow.log", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel._bucketize_t"], ["", "def", "log_pdf", "(", "self", ",", "t", ")", ":", "\n", "    ", "\"\"\"Log of PDF of the distribution.\n\n    Args:\n      t: time instance. Tensor of shape [batch_size]. TODO--> [batch_size, 1]\n\n    Returns:\n      Value of log of PDF. Tensor of shape [batch_size, 1].\n    \"\"\"", "\n", "t", "=", "tf", ".", "squeeze", "(", "t", ")", "\n", "t", ",", "last_slot_hr", "=", "self", ".", "_bucketize_t", "(", "t", ")", "\n", "\n", "ones", "=", "tf", ".", "fill", "(", "tf", ".", "shape", "(", "t", ")", ",", "1", ")", "\n", "# shape [batch_size, TIME_LEN]", "\n", "seq_mask_t_1", "=", "tf", ".", "sequence_mask", "(", "\n", "tf", ".", "cast", "(", "t", "-", "ones", ",", "tf", ".", "int32", ")", ",", "maxlen", "=", "self", ".", "_time_len", ")", "\n", "# shape [TIME_LEN, batch_size]", "\n", "lambda_tensor", "=", "self", ".", "_hazard_tensor", "\n", "\n", "# shape [batch_size, TIME_LEN], multiply supports broadcast.", "\n", "lambda_tensor_t_1", "=", "tf", ".", "multiply", "(", "\n", "tf", ".", "transpose", "(", "lambda_tensor", ")", ",", "tf", ".", "cast", "(", "seq_mask_t_1", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "# shape [batch_size, TIME_LEN]", "\n", "seq_mask_t", "=", "tf", ".", "sequence_mask", "(", "tf", ".", "cast", "(", "t", ",", "tf", ".", "int32", ")", ",", "maxlen", "=", "self", ".", "_time_len", ")", "\n", "# shape [batch_size, TIME_LEN]", "\n", "mask_at_t", "=", "tf", ".", "logical_xor", "(", "seq_mask_t", ",", "seq_mask_t_1", ")", "\n", "\n", "# shape [batch_size]", "\n", "selected_lambda_tensor_at_t", "=", "tf", ".", "boolean_mask", "(", "\n", "tf", ".", "transpose", "(", "lambda_tensor", ")", ",", "mask_at_t", ")", "\n", "# selected_lambda_tensor_at_t = tf.Print(", "\n", "#    selected_lambda_tensor_at_t, [selected_lambda_tensor_at_t],", "\n", "#    'selected_lambda_tensor_at_t',", "\n", "#    summarize=self._time_len)", "\n", "\n", "# shape [batch_size, 1]", "\n", "result", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "log", "(", "1", "-", "lambda_tensor_t_1", ")", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "+", "tf", ".", "log", "(", "\n", "tf", ".", "reshape", "(", "selected_lambda_tensor_at_t", ",", "[", "-", "1", ",", "1", "]", ")", ")", "\n", "\n", "if", "self", ".", "_model_hparams", ".", "last_slot_loss", ":", "\n", "# last_slot_hr is the position of t in terms of #hrs in the last slot.", "\n", "# tf.multiply performs element-wise multiplication along batch dimension.", "\n", "      ", "result", "=", "result", "+", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "multiply", "(", "tf", ".", "log", "(", "1", "-", "lambda_tensor", "[", "self", ".", "_time_len", "-", "1", "]", ")", ",", "\n", "tf", ".", "cast", "(", "last_slot_hr", ",", "tf", ".", "float32", ")", ")", ",", "\n", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.log_survival_func": [[427, 462], ["tensorflow.squeeze", "survival_util.StateSpaceSurvivalModel._bucketize_t", "tensorflow.sequence_mask", "tensorflow.multiply", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.transpose", "tensorflow.cast", "tensorflow.log", "tensorflow.reduce_sum", "tensorflow.multiply", "tensorflow.log", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel._bucketize_t"], ["", "def", "log_survival_func", "(", "self", ",", "t", ")", ":", "\n", "    ", "\"\"\"Log of survival function.\n\n       log S(t, lambda(k)) = sum_{k=1}^{t} log(1 -lambda(k))\n    Args:\n      t: time instance in sec. scalar or Tensor of shape [batch_size].\n\n    Returns:\n      Value of log of survival function. Tensor of shape [batch_size, 1].\n    \"\"\"", "\n", "# shape [batch_size, TIME_LEN]", "\n", "t", "=", "tf", ".", "squeeze", "(", "t", ")", "\n", "t", ",", "last_slot_hr", "=", "self", ".", "_bucketize_t", "(", "t", ")", "\n", "\n", "seq_mask", "=", "tf", ".", "sequence_mask", "(", "tf", ".", "cast", "(", "t", ",", "tf", ".", "int32", ")", ",", "maxlen", "=", "self", ".", "_time_len", ")", "\n", "# tf.logging.info(seq_mask)", "\n", "# shape [TIME_LEN, batch_size]", "\n", "lambda_tensor", "=", "self", ".", "_hazard_tensor", "\n", "# tf.logging.info(lambda_tensor)", "\n", "# shape [batch_size, TIME_LEN], multiply supports broadcast.", "\n", "active_lambda_tensor", "=", "tf", ".", "multiply", "(", "\n", "tf", ".", "transpose", "(", "lambda_tensor", ")", ",", "tf", ".", "cast", "(", "seq_mask", ",", "tf", ".", "float32", ")", ")", "\n", "# tf.logging.info(active_lambda_tensor)", "\n", "result", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "log", "(", "1", "-", "active_lambda_tensor", ")", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "\n", "if", "self", ".", "_model_hparams", ".", "last_slot_loss", ":", "\n", "# last_slot_hr is the position of t in terms of #hrs in the last slot.", "\n", "# tf.multiply performs element-wise multiplication along batch dimension.", "\n", "      ", "result", "=", "result", "+", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "multiply", "(", "tf", ".", "log", "(", "1", "-", "lambda_tensor", "[", "self", ".", "_time_len", "-", "1", "]", ")", ",", "\n", "tf", ".", "cast", "(", "last_slot_hr", ",", "tf", ".", "float32", ")", ")", ",", "\n", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.cdf": [[463, 474], ["tensorflow.exp", "survival_util.StateSpaceSurvivalModel.log_survival_func"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.log_survival_func"], ["", "def", "cdf", "(", "self", ",", "t", ")", ":", "\n", "    ", "\"\"\"Cumulative incidence functions: probablity of event happening before t.\n\n       F(t, lambda) = CDF(t, lambda)  = 1- S(t, lambda)\n    Args:\n      t: time instance. Tensor of shape [batch_size.\n\n    Returns:\n      Value of CDF.\n    \"\"\"", "\n", "return", "1", "-", "tf", ".", "exp", "(", "self", ".", "log_survival_func", "(", "t", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.hazard_rate": [[475, 496], ["survival_util.StateSpaceSurvivalModel._bucketize_t", "tensorflow.sequence_mask", "tensorflow.fill", "tensorflow.sequence_mask", "tensorflow.logical_xor", "tensorflow.boolean_mask", "tensorflow.reshape", "tensorflow.cast", "tensorflow.shape", "tensorflow.cast", "tensorflow.transpose"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel._bucketize_t"], ["", "def", "hazard_rate", "(", "self", ",", "t", ")", ":", "\n", "    ", "\"\"\"Hazard rate at time t.\"\"\"", "\n", "# t is a scalar.", "\n", "t", "=", "self", ".", "_bucketize_t", "(", "t", ")", "\n", "seq_mask_t", "=", "tf", ".", "sequence_mask", "(", "tf", ".", "cast", "(", "t", ",", "tf", ".", "int32", ")", ",", "maxlen", "=", "self", ".", "_time_len", ")", "\n", "ones", "=", "tf", ".", "fill", "(", "tf", ".", "shape", "(", "t", ")", ",", "1", ")", "\n", "seq_mask_t_1", "=", "tf", ".", "sequence_mask", "(", "\n", "tf", ".", "cast", "(", "t", "-", "ones", ",", "tf", ".", "int32", ")", ",", "maxlen", "=", "self", ".", "_time_len", ")", "\n", "mask_at_t", "=", "tf", ".", "logical_xor", "(", "seq_mask_t", ",", "seq_mask_t_1", ")", "\n", "\n", "# shape [TIME_LEN, batch_size]", "\n", "lambda_tensor", "=", "self", ".", "_hazard_tensor", "\n", "# tf.logging.info(lambda_tensor)", "\n", "\n", "# shape [batch_size]", "\n", "selected_lambda_tensor_at_t", "=", "tf", ".", "boolean_mask", "(", "\n", "tf", ".", "transpose", "(", "lambda_tensor", ")", ",", "mask_at_t", ")", "\n", "# tf.logging.info(selected_lambda_tensor_at_t)", "\n", "\n", "# shape [batch_size, 1]", "\n", "return", "tf", ".", "reshape", "(", "selected_lambda_tensor_at_t", ",", "[", "-", "1", ",", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.probability_within_window": [[497, 520], ["survival_util.StateSpaceSurvivalModel.log_survival_func", "tensorflow.fill", "tensorflow.exp", "tensorflow.fill", "tensorflow.exp", "tensorflow.shape", "survival_util.StateSpaceSurvivalModel.log_survival_func", "tensorflow.shape", "survival_util.StateSpaceSurvivalModel.log_survival_func"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.log_survival_func", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.log_survival_func", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.log_survival_func"], ["", "def", "probability_within_window", "(", "self", ",", "window_start_t", ",", "window_end_t", ")", ":", "\n", "    ", "\"\"\"Predicted event probablity within the time window.\n\n    Args:\n      window_start_t: time instance of time window.\n      window_end_t: time instance of time window.\n\n    Returns:\n      Value of Predicted event probablity within window.\n    \"\"\"", "\n", "shape_tensor", "=", "self", ".", "log_survival_func", "(", "window_end_t", ")", "\n", "if", "window_start_t", "==", "0", ":", "\n", "      ", "window_survival_start", "=", "tf", ".", "fill", "(", "tf", ".", "shape", "(", "shape_tensor", ")", ",", "1.0", ")", "\n", "", "else", ":", "\n", "      ", "window_survival_start", "=", "tf", ".", "exp", "(", "self", ".", "log_survival_func", "(", "window_start_t", ")", ")", "\n", "\n", "", "if", "window_end_t", ">", "self", ".", "_time_len", "*", "self", ".", "_slot_size_hr", "*", "UNITS_IN_HR", ":", "\n", "      ", "window_survival_end", "=", "tf", ".", "fill", "(", "tf", ".", "shape", "(", "shape_tensor", ")", ",", "0.0", ")", "\n", "", "else", ":", "\n", "      ", "window_survival_end", "=", "tf", ".", "exp", "(", "self", ".", "log_survival_func", "(", "window_end_t", ")", ")", "\n", "\n", "", "window_p", "=", "window_survival_start", "-", "window_survival_end", "\n", "return", "window_p", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.probability": [[521, 528], ["tensorflow.reciprocal", "survival_util.StateSpaceSurvivalModel.predicted_time"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.predicted_time"], ["", "def", "probability", "(", "self", ")", ":", "\n", "    ", "\"\"\"Predicted event probablity, will be used for C-Index computation.\n\n    Returns:\n      Value of inverse of expected event time.\n    \"\"\"", "\n", "return", "tf", ".", "reciprocal", "(", "self", ".", "predicted_time", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.predicted_time": [[529, 544], ["tensorflow.reduce_sum", "tensorflow.concat", "tensorflow.exp", "range", "survival_util.StateSpaceSurvivalModel.log_survival_func", "survival_util.StateSpaceSurvivalModel._from_slot_to_time_range"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel.log_survival_func", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.StateSpaceSurvivalModel._from_slot_to_time_range"], ["", "def", "predicted_time", "(", "self", ")", ":", "\n", "    ", "\"\"\"Predicted event time in hr.\"\"\"", "\n", "# TODO(yuanxue): need a close form for MAX_SLOT-> infinity.", "\n", "survival_list", "=", "[", "\n", "tf", ".", "exp", "(", "\n", "self", ".", "log_survival_func", "(", "self", ".", "_from_slot_to_time_range", "(", "time_slot", ")", "[", "1", "]", ")", ")", "\n", "*", "self", ".", "_slot_size_hr", "for", "time_slot", "in", "range", "(", "MAX_SLOT", ")", "\n", "]", "\n", "survival_time_hr", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "concat", "(", "survival_list", ",", "axis", "=", "1", ")", ",", "axis", "=", "-", "1", ",", "keep_dims", "=", "True", ")", "\n", "#    survival_time_hr = tf.Print(", "\n", "#        survival_time_hr, [survival_time_hr],", "\n", "#        'survival_time_hr',", "\n", "#        summarize=32)", "\n", "return", "survival_time_hr", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.survival_util.negative_log_likelihood_loss": [[546, 559], ["tensorflow.where"], "function", ["None"], ["", "", "def", "negative_log_likelihood_loss", "(", "censored", ",", "log_pdf_value", ",", "log_survival_value", ")", ":", "\n", "  ", "\"\"\"Compute Negative log likelihood, which can be used for training loss.\n\n  Args:\n    censored: True, if the event is censored (i.e., not observed).\n    log_pdf_value: Log of pdf, representing the likelihood of event observed.\n    log_survival_value: Log of survival function, representing the likelihood of\n      event censored.\n\n  Returns:\n    Value of Negative log likelihood.\n  \"\"\"", "\n", "return", "-", "tf", ".", "where", "(", "censored", ",", "log_survival_value", ",", "log_pdf_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.config_utils.load_experiment_config": [[27, 39], ["open", "google.protobuf.text_format.Parse", "open.read", "experiment_config_pb2.ExperimentConfig"], "function", ["None"], ["def", "load_experiment_config", "(", "\n", "filename", ":", "bytes", ")", "->", "experiment_config_pb2", ".", "ExperimentConfig", ":", "\n", "  ", "\"\"\"Loads ExperimentConfig from a CNS pbtxt file.\n\n  Args:\n    filename: Pathname to config file.\n\n  Returns:\n    An ExperimentConfig proto.\n  \"\"\"", "\n", "f", "=", "open", "(", "filename", ")", "\n", "return", "text_format", ".", "Parse", "(", "f", ".", "read", "(", ")", ",", "experiment_config_pb2", ".", "ExperimentConfig", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.config_utils.merge_from_hparams": [[41, 88], ["copy.deepcopy", "hparams.values().items", "str().split", "getattr.ClearField", "hparams.values", "getattr", "AttributeError", "getattr().extend", "setattr", "str", "getattr", "type"], "function", ["None"], ["", "def", "merge_from_hparams", "(", "original_message", ":", "proto2", ".", "Message", ",", "\n", "hparams", ":", "tf", ".", "HParams", ",", "\n", "delimiter", "=", "'.'", ")", ":", "\n", "  ", "\"\"\"Merge hparams with the original_message and return the new proto.\n\n  Args:\n    original_message: Original proto message.\n    hparams: Fields to be updated. The attribute names can point to\n      nested messages using a delimiter. For example,\n      if the delimiter is '.', then\n        'tf.HParams(**{'model.batch_size': 12})' points to the 'batch_size'\n        attribute of the field 'model' in the 'original_message'.\n    delimiter: The separator used to delimit nested fields. The default is a dot\n      ('.') meaning that 'foo.bar' will point to `foo.bar`.\n\n  Returns:\n    Merged proto with the fields present in the hparams object overridden.\n\n  Raises:\n    AttributeError: If 'hparams' points to a nonexistent field in\n      'original_message'.\n  \"\"\"", "\n", "\n", "message", "=", "copy", ".", "deepcopy", "(", "original_message", ")", "\n", "\n", "for", "name", ",", "value", "in", "hparams", ".", "values", "(", ")", ".", "items", "(", ")", ":", "\n", "    ", "sub_fields", "=", "str", "(", "name", ")", ".", "split", "(", "delimiter", ")", "\n", "# Descend to the leaf node.", "\n", "sub_message", "=", "message", "\n", "for", "sub_field", "in", "sub_fields", "[", ":", "-", "1", "]", ":", "\n", "      ", "sub_message", "=", "getattr", "(", "sub_message", ",", "sub_field", ")", "\n", "\n", "", "leaf_field", "=", "sub_fields", "[", "-", "1", "]", "\n", "if", "leaf_field", "in", "sub_message", ".", "DESCRIPTOR", ".", "fields_by_name", ":", "\n", "      ", "field_descriptor", "=", "sub_message", ".", "DESCRIPTOR", ".", "fields_by_name", "[", "leaf_field", "]", "\n", "is_repeated", "=", "(", "\n", "field_descriptor", ".", "label", "==", "descriptor", ".", "FieldDescriptor", ".", "LABEL_REPEATED", ")", "\n", "", "else", ":", "\n", "      ", "raise", "AttributeError", "(", "'Message %s has no field %r'", "%", "(", "type", "(", "message", ")", ",", "name", ")", ")", "\n", "\n", "", "sub_message", ".", "ClearField", "(", "leaf_field", ")", "\n", "if", "is_repeated", ":", "\n", "      ", "getattr", "(", "sub_message", ",", "leaf_field", ")", ".", "extend", "(", "value", ")", "\n", "", "else", ":", "\n", "      ", "setattr", "(", "sub_message", ",", "leaf_field", ",", "value", ")", "\n", "\n", "", "", "return", "message", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.config_utils.sanitize_parameter_names": [[90, 109], ["pconfig.name.replace"], "function", ["None"], ["", "def", "sanitize_parameter_names", "(", "study_config", ")", ":", "\n", "  ", "\"\"\"Replaces dots with double underscores in `study_config`'s parameter names.\n\n  If dots ('.') are used as field delimiters in the parameter names, we replace\n  them with double underscores ('__') to accommodate the regex used by the\n  tf.StudyConfiguration to parse multidimensional hyperparameter names.\n\n  Args:\n    study_config: (vizier.StudyConfiguration) A study configuration with\n      a repeated field `parameter_configs` containing vizier.ParameterConfig\n      proto messages.\n\n  Returns:\n    A modified study configuration, with the parameter name scrubbed of dots\n    and replaced with double underscores.\n  \"\"\"", "\n", "for", "pconfig", "in", "study_config", ".", "parameter_configs", ":", "\n", "    ", "pconfig", ".", "name", "=", "pconfig", ".", "name", ".", "replace", "(", "'.'", ",", "'__'", ")", "\n", "", "return", "study_config", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.config_utils.sanitize": [[111, 123], ["re.compile", "re.compile.findall", "text.lower"], "function", ["None"], ["", "def", "sanitize", "(", "text", ")", ":", "\n", "  ", "\"\"\"Makes a string suitable for a directory name.\n\n  Args:\n    text: (string) The input string to be cleaned up.\n\n  Returns:\n    (string) A sanitized version, possibly empty.\n  \"\"\"", "\n", "word_regex", "=", "re", ".", "compile", "(", "r'[a-zA-Z0-9]+'", ")", "\n", "\n", "return", "'_'", ".", "join", "(", "word_regex", ".", "findall", "(", "text", ".", "lower", "(", ")", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.data_provider.DataProvider.__init__": [[44, 81], ["data_provider._data_zip", "ValueError"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.data_provider._data_zip"], ["def", "__init__", "(", "self", ",", "\n", "train_data", ":", "tf", ".", "contrib", ".", "slim", ".", "dataset", ".", "Dataset", "=", "None", ",", "\n", "eval_data", ":", "tf", ".", "contrib", ".", "slim", ".", "dataset", ".", "Dataset", "=", "None", ",", "\n", "test_data", ":", "tf", ".", "contrib", ".", "slim", ".", "dataset", ".", "Dataset", "=", "None", ",", "\n", "feature_keys", ":", "List", "[", "bytes", "]", "=", "None", ",", "\n", "label_keys", ":", "List", "[", "bytes", "]", "=", "None", ",", "\n", "batch_size", ":", "int", "=", "32", ",", "\n", "queue_capacity", ":", "int", "=", "256", ",", "\n", "queue_min", ":", "int", "=", "128", ",", "\n", "num_readers", ":", "int", "=", "1", ")", ":", "\n", "    ", "\"\"\"Construct a data provider.\n\n    Args:\n      train_data: Training data.\n      eval_data: Evaluation data.\n      test_data: Test data.\n      feature_keys: List of tensorflow.Example feature keys.\n      label_keys: List of tensorflow.Example feature keys which are labels for\n        training.\n      batch_size: Batch size.\n      queue_capacity: Capacity of the queue.\n      queue_min: The minimum number of records after dequeue.\n      num_readers: The number of parallel readers.\n\n    Raises:\n      ValueError: If `feature_keys` is not supplied.\n    \"\"\"", "\n", "if", "feature_keys", "is", "None", ":", "\n", "      ", "raise", "ValueError", "(", "'`feature_keys` must be supplied.'", ")", "\n", "\n", "", "self", ".", "_feature_keys", "=", "feature_keys", "\n", "self", ".", "_label_keys", "=", "label_keys", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_queue_capacity", "=", "queue_capacity", "\n", "self", ".", "_queue_min", "=", "queue_min", "\n", "self", ".", "_num_readers", "=", "num_readers", "\n", "self", ".", "_data", "=", "_data_zip", "(", "train_data", ",", "eval_data", ",", "test_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.data_provider.DataProvider.from_config": [[82, 138], ["datasets.ClinicalSeriesDataset", "datasets.ClinicalSeriesDataset", "datasets.ClinicalSeriesDataset", "list", "cls", "list", "list", "list", "list", "datasets.strip_raw_feature"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.datasets.strip_raw_feature"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "config", ":", "experiment_config_pb2", ".", "ExperimentConfig", ")", ":", "\n", "    ", "\"\"\"Constructs a data provider from an experiment config.\n\n    Args:\n      config: Experiment configuration.\n\n    Returns:\n      An instance of data provider.\n    \"\"\"", "\n", "labels", "=", "[", "\n", "(", "label", ".", "name", ",", "label", ".", "is_survival_event", ")", "for", "label", "in", "config", ".", "model", ".", "labels", "\n", "]", "\n", "\n", "train_data", "=", "datasets", ".", "ClinicalSeriesDataset", "(", "\n", "data_sources", "=", "list", "(", "config", ".", "train_sources", ")", ",", "\n", "has_mask", "=", "config", ".", "model", ".", "has_mask", ",", "\n", "labels", "=", "labels", ",", "\n", "context_window_size", "=", "config", ".", "model", ".", "context_window_size", ",", "\n", "observation_codes", "=", "config", ".", "model", ".", "observation_codes", ",", "\n", "intervention_codes", "=", "config", ".", "model", ".", "intervention_codes", ")", "\n", "\n", "eval_data", "=", "datasets", ".", "ClinicalSeriesDataset", "(", "\n", "data_sources", "=", "list", "(", "config", ".", "eval_sources", ")", ",", "\n", "has_mask", "=", "config", ".", "model", ".", "has_mask", ",", "\n", "labels", "=", "labels", ",", "\n", "context_window_size", "=", "config", ".", "model", ".", "context_window_size", ",", "\n", "observation_codes", "=", "config", ".", "model", ".", "observation_codes", ",", "\n", "intervention_codes", "=", "config", ".", "model", ".", "intervention_codes", ")", "\n", "\n", "test_data", "=", "datasets", ".", "ClinicalSeriesDataset", "(", "\n", "data_sources", "=", "list", "(", "config", ".", "test_sources", ")", ",", "\n", "has_mask", "=", "config", ".", "model", ".", "has_mask", ",", "\n", "labels", "=", "labels", ",", "\n", "context_window_size", "=", "config", ".", "model", ".", "context_window_size", ",", "\n", "observation_codes", "=", "config", ".", "model", ".", "observation_codes", ",", "\n", "intervention_codes", "=", "config", ".", "model", ".", "intervention_codes", ")", "\n", "\n", "feature_keys", "=", "list", "(", "config", ".", "model", ".", "observation_codes", ")", "\n", "feature_keys", "=", "feature_keys", "+", "list", "(", "config", ".", "model", ".", "intervention_codes", ")", "\n", "if", "config", ".", "model", ".", "has_mask", ":", "\n", "      ", "for", "code", "in", "feature_keys", ":", "\n", "        ", "code", "=", "datasets", ".", "strip_raw_feature", "(", "code", ")", "\n", "feature_keys", "=", "feature_keys", "+", "[", "code", "+", "'_mask'", "]", "\n", "", "feature_keys", "=", "feature_keys", "+", "[", "'true_length_hr'", "]", "\n", "\n", "", "feature_keys", "=", "feature_keys", "+", "[", "'context_window_size'", "]", "\n", "feature_keys", "=", "feature_keys", "+", "[", "'context_window_start_time_sec'", "]", "\n", "\n", "return", "cls", "(", "\n", "train_data", "=", "train_data", ",", "\n", "eval_data", "=", "eval_data", ",", "\n", "test_data", "=", "test_data", ",", "\n", "batch_size", "=", "config", ".", "model", ".", "batch_size", ",", "\n", "feature_keys", "=", "feature_keys", ",", "\n", "label_keys", "=", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.data_provider.DataProvider._get_tensor_and_example": [[139, 174], ["dataset.decoder.list_items", "dataset.decoder.decode", "tensorflow.placeholder", "tensorflow.contrib.slim.python.slim.data.parallel_reader.parallel_read", "dict", "zip"], "methods", ["None"], ["", "def", "_get_tensor_and_example", "(", "\n", "self", ",", "\n", "mode", ":", "tf", ".", "estimator", ".", "ModeKeys", ",", "\n", "shuffle", ":", "bool", "=", "False", ",", "\n", "num_epochs", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "Tuple", "[", "Dict", "[", "bytes", ",", "tf", ".", "Tensor", "]", ",", "bytes", "]", ":", "\n", "    ", "\"\"\"Read and decode the serialized tf.Example into tensors.\n\n    Args:\n      mode: One of tf.estimator.ModeKeys {TRAIN,EVAL,INFER}.\n      shuffle: Whether to shuffle the input.\n      num_epochs: Number of times a tf.Example will be visited in generating the\n        input. If set to None, each Example will be cycled indefinitely.\n\n    Returns:\n      Tuple with:\n      A dictionary that maps tensorflow.Example feature names to tensors.\n      serialized_example: bytes, a serialized example.\n    \"\"\"", "\n", "dataset", "=", "self", ".", "_data", "[", "mode", "]", "\n", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "INFER", ":", "\n", "      ", "serialized_example", "=", "tf", ".", "placeholder", "(", "\n", "dtype", "=", "tf", ".", "string", ",", "shape", "=", "[", "]", ",", "name", "=", "'input_serialized_examples'", ")", "\n", "", "else", ":", "\n", "      ", "_", ",", "serialized_example", "=", "parallel_reader", ".", "parallel_read", "(", "\n", "dataset", ".", "data_sources", ",", "\n", "reader_class", "=", "dataset", ".", "reader", ",", "\n", "num_epochs", "=", "num_epochs", ",", "\n", "num_readers", "=", "self", ".", "_num_readers", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "capacity", "=", "self", ".", "_queue_capacity", ",", "\n", "min_after_dequeue", "=", "self", ".", "_queue_min", ")", "\n", "", "items", "=", "dataset", ".", "decoder", ".", "list_items", "(", ")", "\n", "tensors", "=", "dataset", ".", "decoder", ".", "decode", "(", "serialized_example", ",", "items", ")", "\n", "\n", "return", "dict", "(", "zip", "(", "items", ",", "tensors", ")", ")", ",", "serialized_example", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.data_provider.DataProvider.get_input_fn": [[175, 258], ["ValueError", "tensorflow.placeholder", "six.iteritems", "tensorflow.logging.info", "tensorflow.estimator.export.ServingInputReceiver", "tensorflow.name_scope", "data_provider.DataProvider._get_tensor_and_example", "tensorflow.name_scope", "tensorflow.train.batch", "tensorflow.expand_dims", "tensorflow.name_scope", "data_provider.DataProvider._get_tensor_and_example", "tensorflow.expand_dims", "tensorflow.logging.info", "tensorflow.expand_dims"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.data_provider.DataProvider._get_tensor_and_example", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.data_provider.DataProvider._get_tensor_and_example"], ["", "def", "get_input_fn", "(", "self", ",", "\n", "mode", ":", "tf", ".", "estimator", ".", "ModeKeys", ",", "\n", "shuffle", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "num_epochs", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"Get an input function for the given mode.\n\n    Args:\n      mode: One of tf.estimator.ModeKeys {TRAIN,EVAL,INFER}.\n      shuffle: Whether shuffle the input. If shuffle is None, only data under\n        TRAIN mode is shuffled.\n      num_epochs: Number of times a tensorflow.Example will be visited in\n        generating the input. If set to None, each Example will be cycled\n        indefinitely.\n\n    Returns:\n      A callable that returns a pair of dictionaries containing\n      the batched tensors for 'features' and 'labels', respectively.\n      labels tensors have shape [batch_size, 1]\n      features tensors have shape [batch_size]\n\n    Raises:\n      ValueError: A 'mode' is supplied for which there is no data.\n    \"\"\"", "\n", "if", "not", "self", ".", "_data", "[", "mode", "]", ":", "\n", "      ", "raise", "ValueError", "(", "'No data provided for mode %s'", "%", "mode", ")", "\n", "\n", "", "def", "input_fn", "(", ")", ":", "\n", "      ", "\"\"\"An input function under training/eval mode.\"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "'ReadData'", ")", ":", "\n", "        ", "tensor", ",", "_", "=", "self", ".", "_get_tensor_and_example", "(", "\n", "mode", ",", "shuffle", "=", "shuffle", ",", "num_epochs", "=", "num_epochs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "'Batch'", ")", ":", "\n", "        ", "batched", "=", "tf", ".", "train", ".", "batch", "(", "\n", "tensor", ",", "\n", "batch_size", "=", "self", ".", "_batch_size", ",", "\n", "dynamic_pad", "=", "True", ",", "\n", "capacity", "=", "QUEUE_SCALING_FACTOR", "*", "self", ".", "_batch_size", ")", "\n", "\n", "", "features", "=", "{", "key", ":", "batched", "[", "key", "]", "for", "key", "in", "self", ".", "_feature_keys", "}", "\n", "labels", "=", "{", "}", "\n", "for", "label_tuple", "in", "self", ".", "_label_keys", ":", "\n", "        ", "labels", "[", "label_tuple", "[", "0", "]", "]", "=", "tf", ".", "expand_dims", "(", "\n", "batched", "[", "label_tuple", "[", "0", "]", "]", ",", "axis", "=", "-", "1", ")", "\n", "if", "label_tuple", "[", "1", "]", ":", "\n", "          ", "labels", "[", "label_tuple", "[", "0", "]", "+", "'.time_to_event'", "]", "=", "tf", ".", "expand_dims", "(", "\n", "batched", "[", "label_tuple", "[", "0", "]", "+", "'.time_of_event'", "]", "-", "\n", "batched", "[", "'trigger_time_sec'", "]", ",", "\n", "axis", "=", "-", "1", ")", "\n", "\n", "", "", "return", "features", ",", "labels", "\n", "\n", "", "def", "serving_input_fn", "(", ")", ":", "\n", "      ", "\"\"\"Construct a ServingInputReceiver function under infer mode.\"\"\"", "\n", "input_keys", "=", "tf", ".", "placeholder", "(", "\n", "dtype", "=", "tf", ".", "string", ",", "shape", "=", "[", "None", "]", ",", "name", "=", "'input_keys'", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "'ReadInferenceData'", ")", ":", "\n", "        ", "feature_dict", ",", "serialized_example", "=", "self", ".", "_get_tensor_and_example", "(", "\n", "mode", ",", "shuffle", "=", "shuffle", ",", "num_epochs", "=", "num_epochs", ")", "\n", "\n", "# At serving time, the batch size will be 1. We need to reshape the", "\n", "# features to account for this.", "\n", "", "features", "=", "{", "}", "\n", "for", "key", ",", "tensor", "in", "iteritems", "(", "feature_dict", ")", ":", "\n", "        ", "features", "[", "key", "]", "=", "tf", ".", "expand_dims", "(", "tensor", ",", "0", ")", "\n", "tf", ".", "logging", ".", "info", "(", "key", ")", "\n", "", "tf", ".", "logging", ".", "info", "(", "features", ")", "\n", "\n", "inputs", "=", "{", "\n", "'input_keys'", ":", "input_keys", ",", "\n", "'input_examples'", ":", "serialized_example", ",", "\n", "}", "\n", "\n", "return", "tf", ".", "estimator", ".", "export", ".", "ServingInputReceiver", "(", "\n", "features", "=", "features", ",", "receiver_tensors", "=", "inputs", ")", "\n", "\n", "", "if", "shuffle", "is", "None", ":", "\n", "      ", "shuffle", "=", "(", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", "\n", "", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "INFER", ":", "\n", "      ", "return", "serving_input_fn", "\n", "", "else", ":", "\n", "      ", "return", "input_fn", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.data_provider._data_zip": [[26, 32], ["None"], "function", ["None"], ["def", "_data_zip", "(", "train_data", ",", "eval_data", ",", "test_data", ")", ":", "\n", "  ", "\"\"\"Zip train, eval, test data.\"\"\"", "\n", "return", "{", "\n", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ":", "train_data", ",", "\n", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ":", "eval_data", ",", "\n", "tf", ".", "estimator", ".", "ModeKeys", ".", "INFER", ":", "test_data", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.datasets.ClinicalSeriesDataset.__init__": [[31, 131], ["tensorflow.FixedLenFeature", "tensorflow.contrib.slim.python.slim.data.tfexample_decoder.Tensor", "tensorflow.FixedLenFeature", "tensorflow.contrib.slim.python.slim.data.tfexample_decoder.Tensor", "tensorflow.FixedLenFeature", "tensorflow.contrib.slim.python.slim.data.tfexample_decoder.Tensor", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.contrib.slim.python.slim.data.tfexample_decoder.TFExampleDecoder", "dataset.Dataset.__init__", "tensorflow.FixedLenFeature", "tensorflow.contrib.slim.python.slim.data.tfexample_decoder.Tensor", "tensorflow.logging.info", "tensorflow.FixedLenFeature", "tensorflow.contrib.slim.python.slim.data.tfexample_decoder.Tensor", "tensorflow.logging.info", "tensorflow.FixedLenFeature", "tensorflow.contrib.slim.python.slim.data.tfexample_decoder.Tensor", "tensorflow.logging.info", "tensorflow.FixedLenFeature", "tensorflow.contrib.slim.python.slim.data.tfexample_decoder.Tensor", "tensorflow.logging.info", "tensorflow.FixedLenFeature", "tensorflow.contrib.slim.python.slim.data.tfexample_decoder.Tensor", "datasets.strip_raw_feature", "tensorflow.FixedLenFeature", "tensorflow.contrib.slim.python.slim.data.tfexample_decoder.Tensor", "datasets.strip_raw_feature", "tensorflow.FixedLenFeature", "tensorflow.contrib.slim.python.slim.data.tfexample_decoder.Tensor"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.datasets.strip_raw_feature", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.datasets.strip_raw_feature"], ["def", "__init__", "(", "self", ",", "data_sources", ",", "has_mask", ",", "labels", ",", "context_window_size", ",", "\n", "observation_codes", ",", "intervention_codes", ")", ":", "\n", "    ", "\"\"\"Creates a dataset for clinical time series dense feature lab data.\n\n    Args:\n      data_sources: A list of files/patterns for the slim Dataset.\n      has_mask: Whether the dataset has obs_mask and true_length_hr feature.\n      labels: A list of labels in string, corresponding to labels in\n        ModelConfig.\n      context_window_size: size of the context window, i.e, the length of the\n        time series.\n      observation_codes: A list of features corresponding to the observation\n        time series data.\n      intervention_codes: A list of features corresponding to the intervention\n        time series data.\n\n    Returns:\n      A slim dataset with proper reader and decoders.\n    \"\"\"", "\n", "\n", "keys_to_features", "=", "{", "}", "\n", "items_to_handlers", "=", "{", "}", "\n", "\n", "keys_to_features", "[", "'context_window_size'", "]", "=", "tf", ".", "FixedLenFeature", "(", "\n", "[", "]", ",", "dtype", "=", "tf", ".", "int64", ",", "default_value", "=", "0", ")", "\n", "items_to_handlers", "[", "\n", "'context_window_size'", "]", "=", "tfexample_decoder", ".", "Tensor", "(", "\n", "'context_window_size'", ",", "default_value", "=", "0", ")", "\n", "\n", "keys_to_features", "[", "'context_window_start_time_sec'", "]", "=", "tf", ".", "FixedLenFeature", "(", "\n", "[", "]", ",", "dtype", "=", "tf", ".", "int64", ",", "default_value", "=", "0", ")", "\n", "items_to_handlers", "[", "\n", "'context_window_start_time_sec'", "]", "=", "tfexample_decoder", ".", "Tensor", "(", "\n", "'context_window_start_time_sec'", ",", "default_value", "=", "0", ")", "\n", "\n", "keys_to_features", "[", "'trigger_time_sec'", "]", "=", "tf", ".", "FixedLenFeature", "(", "\n", "[", "]", ",", "dtype", "=", "tf", ".", "int64", ",", "default_value", "=", "0", ")", "\n", "items_to_handlers", "[", "'trigger_time_sec'", "]", "=", "tfexample_decoder", ".", "Tensor", "(", "\n", "'trigger_time_sec'", ",", "default_value", "=", "0", ")", "\n", "\n", "if", "has_mask", ":", "\n", "      ", "keys_to_features", "[", "'true_length_hr'", "]", "=", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "\n", "dtype", "=", "tf", ".", "int64", ",", "\n", "default_value", "=", "0", ")", "\n", "items_to_handlers", "[", "'true_length_hr'", "]", "=", "tfexample_decoder", ".", "Tensor", "(", "\n", "'true_length_hr'", ",", "default_value", "=", "0", ")", "\n", "\n", "", "tf", ".", "logging", ".", "info", "(", "'Labels are:'", ")", "\n", "for", "label", "in", "labels", ":", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "label", ")", "\n", "keys_to_features", "[", "label", "[", "0", "]", "]", "=", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "\n", "dtype", "=", "tf", ".", "int64", ",", "\n", "default_value", "=", "-", "1", ")", "\n", "items_to_handlers", "[", "label", "[", "0", "]", "]", "=", "tfexample_decoder", ".", "Tensor", "(", "label", "[", "0", "]", ")", "\n", "# This label is for a survival analysis event.", "\n", "if", "label", "[", "1", "]", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "label", "[", "0", "]", "+", "'.time_of_event'", ")", "\n", "keys_to_features", "[", "label", "[", "0", "]", "+", "'.time_of_event'", "]", "=", "tf", ".", "FixedLenFeature", "(", "\n", "[", "]", ",", "dtype", "=", "tf", ".", "int64", ",", "default_value", "=", "0", ")", "\n", "items_to_handlers", "[", "label", "[", "0", "]", "+", "\n", "'.time_of_event'", "]", "=", "tfexample_decoder", ".", "Tensor", "(", "\n", "label", "[", "0", "]", "+", "'.time_of_event'", ")", "\n", "\n", "", "", "tf", ".", "logging", ".", "info", "(", "'Features are:'", ")", "\n", "for", "observation", "in", "observation_codes", ":", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "observation", ")", "\n", "keys_to_features", "[", "observation", "]", "=", "tf", ".", "FixedLenFeature", "(", "\n", "shape", "=", "[", "context_window_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "items_to_handlers", "[", "observation", "]", "=", "tfexample_decoder", ".", "Tensor", "(", "\n", "observation", ",", "default_value", "=", "-", "1", ")", "\n", "if", "has_mask", ":", "\n", "        ", "observation", "=", "strip_raw_feature", "(", "observation", ")", "\n", "keys_to_features", "[", "observation", "+", "'_mask'", "]", "=", "tf", ".", "FixedLenFeature", "(", "\n", "shape", "=", "[", "context_window_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "items_to_handlers", "[", "observation", "+", "'_mask'", "]", "=", "tfexample_decoder", ".", "Tensor", "(", "\n", "observation", "+", "'_mask'", ",", "default_value", "=", "0", ")", "\n", "\n", "", "", "for", "intervention", "in", "intervention_codes", ":", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "intervention", ")", "\n", "keys_to_features", "[", "intervention", "]", "=", "tf", ".", "FixedLenFeature", "(", "\n", "shape", "=", "[", "context_window_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "items_to_handlers", "[", "intervention", "]", "=", "tfexample_decoder", ".", "Tensor", "(", "\n", "intervention", ",", "default_value", "=", "-", "1", ")", "\n", "if", "has_mask", ":", "\n", "        ", "intervention", "=", "strip_raw_feature", "(", "intervention", ")", "\n", "\n", "keys_to_features", "[", "intervention", "+", "'_mask'", "]", "=", "tf", ".", "FixedLenFeature", "(", "\n", "shape", "=", "[", "context_window_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "items_to_handlers", "[", "intervention", "+", "'_mask'", "]", "=", "tfexample_decoder", ".", "Tensor", "(", "\n", "intervention", "+", "'_mask'", ",", "default_value", "=", "0", ")", "\n", "\n", "", "", "decoder", "=", "tfexample_decoder", ".", "TFExampleDecoder", "(", "keys_to_features", ",", "\n", "items_to_handlers", ")", "\n", "\n", "super", "(", "ClinicalSeriesDataset", ",", "self", ")", ".", "__init__", "(", "\n", "data_sources", "=", "data_sources", ",", "\n", "reader", "=", "tf", ".", "compat", ".", "v1", ".", "TFRecordReader", ",", "\n", "decoder", "=", "decoder", ",", "\n", "num_samples", "=", "None", ",", "\n", "items_to_descriptions", "=", "{", "}", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.datasets.strip_raw_feature": [[22, 26], ["code.endswith"], "function", ["None"], ["def", "strip_raw_feature", "(", "code", ")", ":", "\n", "  ", "if", "code", ".", "endswith", "(", "'_raw'", ")", ":", "\n", "    ", "code", "=", "code", "[", ":", "-", "4", "]", "\n", "", "return", "code", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.config_get": [[37, 39], ["json.load", "open", "os.path.join"], "function", ["None"], ["def", "config_get", "(", "name", ")", ":", "\n", "    ", "return", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "FILEDIR", ",", "CONFIG_JSON", ")", ")", ")", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.sub2pid": [[67, 73], ["PID_REG.pop"], "function", ["None"], ["def", "sub2pid", "(", "sub", ",", "dbname", ")", ":", "\n", "    ", "if", "(", "sub", ",", "dbname", ")", "in", "SUB2PID", ":", "\n", "        ", "return", "SUB2PID", "[", "(", "sub", ",", "dbname", ")", "]", "\n", "", "pid", "=", "PID_REG", ".", "pop", "(", ")", "\n", "SUB2PID", "[", "(", "sub", ",", "dbname", ")", "]", "=", "pid", "\n", "return", "pid", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.had2enc": [[74, 80], ["ENC_REG.pop"], "function", ["None"], ["", "def", "had2enc", "(", "had", ",", "dbname", ")", ":", "\n", "    ", "if", "(", "had", ",", "dbname", ")", "in", "HAD2ENC", ":", "\n", "        ", "return", "HAD2ENC", "[", "(", "had", ",", "dbname", ")", "]", "\n", "", "enc", "=", "ENC_REG", ".", "pop", "(", ")", "\n", "HAD2ENC", "[", "(", "had", ",", "dbname", ")", "]", "=", "enc", "\n", "return", "enc", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.CSVReader": [[81, 87], ["csv.DictReader", "open", "gzip.open"], "function", ["None"], ["", "def", "CSVReader", "(", "dirname", ",", "tname", ",", "cols", "=", "None", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "fd", "=", "open", "(", "'%s/%s.csv'", "%", "(", "dirname", ",", "tname", ")", ")", "\n", "", "except", ":", "\n", "        ", "fd", "=", "gzip", ".", "open", "(", "'%s/%s.csv.gz'", "%", "(", "dirname", ",", "tname", ")", ",", "'rt'", ")", "\n", "", "return", "csv", ".", "DictReader", "(", "fd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.HANDLE_PATIENTS": [[92, 104], ["tqdm.tqdm", "prepare.CSVReader", "prepare.sub2pid", "int", "ALL_PATIENTS.append", "int"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.CSVReader", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.sub2pid"], ["def", "HANDLE_PATIENTS", "(", "dirname", ",", "tname", ",", "dbname", ",", "size", ")", ":", "\n", "    ", "for", "rec", "in", "tqdm", "(", "CSVReader", "(", "dirname", ",", "tname", ")", ",", "total", "=", "size", ")", ":", "\n", "        ", "pid", "=", "sub2pid", "(", "int", "(", "rec", "[", "'SUBJECT_ID'", "]", ")", ",", "dbname", ")", "\n", "sex", "=", "rec", "[", "'GENDER'", "]", "\n", "#dob = date_parse(rec['DOB'])", "\n", "dob", "=", "rec", "[", "'DOB'", "]", "\n", "exp", "=", "int", "(", "rec", "[", "'EXPIRE_FLAG'", "]", ")", "\n", "#dod = None if exp == 0 else date_parse(rec['DOD'])", "\n", "dod", "=", "rec", "[", "'DOD'", "]", "\n", "\n", "ALL_PATIENTS", ".", "append", "(", "(", "pid", ",", "sex", ",", "dob", ",", "dod", ",", "exp", ")", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.HANDLE_ADMISSIONS": [[112, 130], ["tqdm.tqdm", "prepare.CSVReader", "prepare.sub2pid", "prepare.had2enc", "int", "ALL_ADMISSIONS.append", "int", "int", "prepare.HANDLE_ADMISSIONS.picdb_ethnic"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.CSVReader", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.sub2pid", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.had2enc"], ["def", "HANDLE_ADMISSIONS", "(", "dirname", ",", "tname", ",", "dbname", ",", "size", ")", ":", "\n", "    ", "def", "picdb_ethnic", "(", "eth", ")", ":", "\n", "        ", "if", "eth", "==", "'Other'", ":", "\n", "            ", "return", "'OTHER'", "\n", "", "return", "'ASIAN - CHINESE'", "\n", "\n", "", "for", "rec", "in", "tqdm", "(", "CSVReader", "(", "dirname", ",", "tname", ")", ",", "total", "=", "size", ")", ":", "\n", "        ", "pid", "=", "sub2pid", "(", "int", "(", "rec", "[", "'SUBJECT_ID'", "]", ")", ",", "dbname", ")", "\n", "enc", "=", "had2enc", "(", "int", "(", "rec", "[", "'HADM_ID'", "]", ")", ",", "dbname", ")", "\n", "#adm = date_parse(rec['ADMITTIME'])", "\n", "adm", "=", "rec", "[", "'ADMITTIME'", "]", "\n", "#dis = date_parse(rec['DISCHTIME'])", "\n", "dis", "=", "rec", "[", "'DISCHTIME'", "]", "\n", "eth", "=", "rec", "[", "'ETHNICITY'", "]", "if", "dbname", "==", "'MIMIC'", "else", "picdb_ethnic", "(", "rec", "[", "'ETHNICITY'", "]", ")", "\n", "exp", "=", "int", "(", "rec", "[", "'HOSPITAL_EXPIRE_FLAG'", "]", ")", "\n", "\n", "ALL_ADMISSIONS", ".", "append", "(", "(", "pid", ",", "enc", ",", "adm", ",", "dis", ",", "eth", ",", "exp", ")", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.HANDLE_CHARTEVENTS": [[175, 196], ["tqdm.tqdm", "prepare.CSVReader", "int", "float", "prepare.sub2pid", "prepare.had2enc", "ALL_CHARTEVENTS.append", "int", "int"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.CSVReader", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.sub2pid", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.had2enc"], ["def", "HANDLE_CHARTEVENTS", "(", "dirname", ",", "tname", ",", "dbname", ",", "size", ")", ":", "\n", "    ", "items", "=", "PICDB_CHART_ITEMS", "if", "dbname", "==", "'PICDB'", "else", "MIMIC_CHART_ITEMS", "\n", "\n", "for", "rec", "in", "tqdm", "(", "CSVReader", "(", "dirname", ",", "tname", ")", ",", "total", "=", "size", ")", ":", "\n", "        ", "itm_raw", "=", "int", "(", "rec", "[", "'ITEMID'", "]", ")", "\n", "if", "not", "itm_raw", "in", "items", ":", "\n", "            ", "continue", "\n", "", "itm", "=", "items", "[", "itm_raw", "]", "\n", "if", "rec", "[", "'VALUENUM'", "]", "==", "''", ":", "\n", "            ", "continue", "\n", "", "val", "=", "float", "(", "rec", "[", "'VALUENUM'", "]", ")", "\n", "pid", "=", "sub2pid", "(", "int", "(", "rec", "[", "'SUBJECT_ID'", "]", ")", ",", "dbname", ")", "\n", "enc", "=", "had2enc", "(", "int", "(", "rec", "[", "'HADM_ID'", "]", ")", ",", "dbname", ")", "\n", "#ctm = date_parse(rec['CHARTTIME'])", "\n", "ctm", "=", "rec", "[", "'CHARTTIME'", "]", "\n", "#stm = date_parse(rec['STORETIME']) if rec['STORETIME'] != '' else None", "\n", "stm", "=", "rec", "[", "'STORETIME'", "]", "\n", "uom", "=", "rec", "[", "'VALUEUOM'", "]", "\n", "\n", "ALL_CHARTEVENTS", ".", "append", "(", "(", "pid", ",", "enc", ",", "itm", ",", "ctm", ",", "stm", ",", "val", ",", "uom", ")", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.MIMIC_DIAGNOSES_ICD": [[204, 215], ["tqdm.tqdm", "prepare.CSVReader", "prepare.sub2pid", "prepare.had2enc", "ALL_DIAGNOSES_ICD.append", "int", "int", "int"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.CSVReader", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.sub2pid", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.had2enc"], ["def", "MIMIC_DIAGNOSES_ICD", "(", "dirname", ",", "tname", ",", "dbname", ",", "size", ")", ":", "\n", "    ", "for", "rec", "in", "tqdm", "(", "CSVReader", "(", "dirname", ",", "tname", ")", ",", "total", "=", "size", ")", ":", "\n", "        ", "pid", "=", "sub2pid", "(", "int", "(", "rec", "[", "'SUBJECT_ID'", "]", ")", ",", "dbname", ")", "\n", "enc", "=", "had2enc", "(", "int", "(", "rec", "[", "'HADM_ID'", "]", ")", ",", "dbname", ")", "\n", "seq", "=", "int", "(", "rec", "[", "'SEQ_NUM'", "]", ")", "if", "rec", "[", "'SEQ_NUM'", "]", "!=", "''", "else", "None", "\n", "if", "not", "seq", ":", "\n", "            ", "continue", "\n", "", "icd", "=", "rec", "[", "'ICD9_CODE'", "]", "\n", "\n", "ALL_DIAGNOSES_ICD", ".", "append", "(", "(", "pid", ",", "enc", ",", "seq", ",", "icd", ")", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.PICDB_DIAGNOSES_ICD": [[216, 270], ["prepare.CSVReader", "open", "open", "open", "set", "tqdm.tqdm", "rec[].replace", "line.split", "line.strip().split", "icd9s.split.split", "line.strip().split", "icd10.replace.replace", "icd9.replace.replace", "icd10_9.items", "prepare.CSVReader", "prepare.sub2pid", "prepare.had2enc", "int", "prepare.PICDB_DIAGNOSES_ICD.icd10cn_to_icd9"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.CSVReader", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.CSVReader", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.sub2pid", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.had2enc"], ["", "def", "PICDB_DIAGNOSES_ICD", "(", "dirname", ",", "tname", ",", "dbname", ",", "size", ")", ":", "\n", "    ", "cn_en", "=", "{", "}", "\n", "for", "rec", "in", "CSVReader", "(", "dirname", ",", "'D_ICD_DIAGNOSES'", ")", ":", "\n", "        ", "cn", "=", "rec", "[", "'ICD10_CODE_CN'", "]", "\n", "en", "=", "rec", "[", "'ICD10_CODE'", "]", ".", "replace", "(", "'.'", ",", "''", ")", "\n", "cn_en", "[", "cn", "]", "=", "en", "\n", "\n", "", "icd10_9", "=", "{", "}", "\n", "for", "line", "in", "open", "(", "'%s/res/2018_I10gem.txt'", "%", "FILEDIR", ")", ":", "\n", "        ", "icd10", ",", "icd9", ",", "flags", "=", "line", ".", "split", "(", ")", "\n", "if", "icd10", "in", "icd10_9", ":", "\n", "            ", "continue", "\n", "", "icd10_9", "[", "icd10", "]", "=", "icd9", "\n", "\n", "", "for", "line", "in", "open", "(", "'%s/res/icd9_10.txt'", "%", "FILEDIR", ")", ":", "\n", "        ", "icd10", ",", "icd9s", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "':'", ")", "\n", "icd9s", "=", "icd9s", ".", "split", "(", "','", ")", "\n", "if", "icd10", "in", "icd10_9", ":", "\n", "            ", "continue", "\n", "", "for", "icd9", "in", "icd9s", ":", "\n", "            ", "icd10_9", "[", "icd10", "]", "=", "icd9", "\n", "\n", "", "", "for", "line", "in", "open", "(", "'%s/res/icd910cn.txt'", "%", "FILEDIR", ")", ":", "\n", "        ", "_", ",", "icd9", ",", "icd10", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "icd10", "=", "icd10", ".", "replace", "(", "'.'", ",", "''", ")", "\n", "icd9", "=", "icd9", ".", "replace", "(", "'.'", ",", "''", ")", "\n", "if", "icd10", "in", "icd10_9", ":", "\n", "            ", "continue", "\n", "", "icd10_9", "[", "icd10", "]", "=", "icd9", "\n", "\n", "", "def", "icd10cn_to_icd9", "(", "icd10cn", ")", ":", "\n", "        ", "icd10", "=", "cn_en", "[", "icd10cn", "]", "\n", "if", "icd10", "in", "icd10_9", ":", "\n", "            ", "return", "icd10_9", "[", "icd10", "]", "\n", "", "for", "k", ",", "v", "in", "icd10_9", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", ".", "startswith", "(", "icd10", ")", "or", "icd10", ".", "startswith", "(", "k", ")", ":", "\n", "                ", "icd10_9", "[", "icd10", "]", "=", "v", "\n", "return", "v", "\n", "\n", "", "", "", "unmapped", "=", "set", "(", ")", "\n", "for", "rec", "in", "tqdm", "(", "CSVReader", "(", "dirname", ",", "tname", ")", ",", "total", "=", "size", ")", ":", "\n", "        ", "pid", "=", "sub2pid", "(", "int", "(", "rec", "[", "'SUBJECT_ID'", "]", ")", ",", "dbname", ")", "\n", "enc", "=", "had2enc", "(", "int", "(", "rec", "[", "'HADM_ID'", "]", ")", ",", "dbname", ")", "\n", "seq", "=", "int", "(", "rec", "[", "'SEQ_NUM'", "]", ")", "\n", "icd", "=", "icd10cn_to_icd9", "(", "rec", "[", "'ICD10_CODE_CN'", "]", ")", "\n", "if", "not", "icd", ":", "\n", "            ", "unmapped", ".", "add", "(", "rec", "[", "'ICD10_CODE_CN'", "]", ")", "\n", "continue", "\n", "\n", "", "ALL_DIAGNOSES_ICD", ".", "append", "(", "(", "pid", ",", "enc", ",", "seq", ",", "icd", ")", ")", "\n", "\n", "", "if", "len", "(", "unmapped", ")", ">", "0", ":", "\n", "        ", "print", "(", "'Unampped ICD10:'", ",", "sorted", "(", "unmapped", ")", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.HANDLE_LABEVENTS": [[277, 303], ["prepare.CSVReader", "tqdm.tqdm", "int", "prepare.CSVReader", "int", "prepare.sub2pid", "float", "ALL_LABEVENTS.append", "int", "prepare.had2enc", "len", "int"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.CSVReader", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.CSVReader", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.sub2pid", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.had2enc"], ["def", "HANDLE_LABEVENTS", "(", "dirname", ",", "tname", ",", "dbname", ",", "size", ")", ":", "\n", "    ", "item_loinc", "=", "{", "}", "\n", "for", "rec", "in", "CSVReader", "(", "dirname", ",", "'D_LABITEMS'", ")", ":", "\n", "        ", "item", "=", "int", "(", "rec", "[", "'ITEMID'", "]", ")", "\n", "loinc", "=", "rec", "[", "'LOINC_CODE'", "]", "\n", "if", "loinc", "and", "len", "(", "loinc", ")", ">", "2", ":", "\n", "            ", "item_loinc", "[", "item", "]", "=", "loinc", "\n", "\n", "", "", "for", "rec", "in", "tqdm", "(", "CSVReader", "(", "dirname", ",", "tname", ")", ",", "total", "=", "size", ")", ":", "\n", "        ", "item", "=", "int", "(", "rec", "[", "'ITEMID'", "]", ")", "\n", "if", "item", "not", "in", "item_loinc", ":", "\n", "            ", "continue", "\n", "", "loi", "=", "item_loinc", "[", "item", "]", "\n", "flg", "=", "rec", "[", "'FLAG'", "]", "\n", "if", "rec", "[", "'FLAG'", "]", "!=", "''", "and", "dbname", "==", "'PICDB'", ":", "\n", "            ", "flg", "=", "''", "if", "rec", "[", "'FLAG'", "]", "==", "'z'", "else", "'abnormal'", "\n", "", "pid", "=", "sub2pid", "(", "int", "(", "rec", "[", "'SUBJECT_ID'", "]", ")", ",", "dbname", ")", "\n", "enc", "=", "had2enc", "(", "int", "(", "rec", "[", "'HADM_ID'", "]", ")", ",", "dbname", ")", "if", "rec", "[", "'HADM_ID'", "]", "!=", "''", "else", "None", "\n", "ctm", "=", "rec", "[", "'CHARTTIME'", "]", "\n", "if", "rec", "[", "'VALUENUM'", "]", "==", "''", ":", "\n", "            ", "continue", "\n", "", "val", "=", "float", "(", "rec", "[", "'VALUENUM'", "]", ")", "\n", "uom", "=", "rec", "[", "'VALUEUOM'", "]", "\n", "\n", "ALL_LABEVENTS", ".", "append", "(", "(", "pid", ",", "enc", ",", "loi", ",", "ctm", ",", "val", ",", "uom", ",", "flg", ")", ")", "\n", "", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.MIMIC_PRESCRIPTIONS": [[313, 335], ["collections.defaultdict", "csv.DictReader", "tqdm.tqdm", "open", "ndc_rxcui[].add", "prepare.CSVReader", "prepare.sub2pid", "int", "prepare.had2enc", "ALL_PRESCRIPTIONS.append", "int"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.CSVReader", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.sub2pid", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.had2enc"], ["def", "MIMIC_PRESCRIPTIONS", "(", "dirname", ",", "tname", ",", "dbname", ",", "size", ")", ":", "\n", "    ", "ndc_rxcui", "=", "defaultdict", "(", "set", ")", "\n", "for", "rec", "in", "csv", ".", "DictReader", "(", "open", "(", "'%s/res/ndcrxcui.csv'", "%", "FILEDIR", ")", ")", ":", "\n", "        ", "ndc", "=", "rec", "[", "'NDC'", "]", "\n", "rxcui", "=", "rec", "[", "'RXCUI'", "]", "\n", "ndc_rxcui", "[", "ndc", "]", ".", "add", "(", "rxcui", ")", "\n", "\n", "", "for", "rec", "in", "tqdm", "(", "CSVReader", "(", "dirname", ",", "tname", ")", ",", "total", "=", "size", ")", ":", "\n", "        ", "ndc", "=", "rec", "[", "'NDC'", "]", "\n", "if", "ndc", "==", "''", "or", "ndc", "==", "'0'", ":", "\n", "            ", "continue", "\n", "", "rxcuis", "=", "ndc_rxcui", "[", "ndc", "]", "\n", "pid", "=", "sub2pid", "(", "int", "(", "rec", "[", "'SUBJECT_ID'", "]", ")", ",", "dbname", ")", "\n", "enc", "=", "had2enc", "(", "int", "(", "rec", "[", "'HADM_ID'", "]", ")", ",", "dbname", ")", "if", "rec", "[", "'HADM_ID'", "]", "!=", "''", "else", "None", "\n", "std", "=", "rec", "[", "'STARTDATE'", "]", "\n", "end", "=", "rec", "[", "'ENDDATE'", "]", "\n", "val", "=", "rec", "[", "'DOSE_VAL_RX'", "]", "\n", "unt", "=", "rec", "[", "'DOSE_UNIT_RX'", "]", "\n", "\n", "for", "rxcui", "in", "rxcuis", ":", "\n", "            ", "ALL_PRESCRIPTIONS", ".", "append", "(", "(", "pid", ",", "enc", ",", "std", ",", "end", ",", "rxcui", ",", "val", ",", "unt", ")", ")", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.PICDB_PRESCRIPTIONS": [[336, 363], ["collections.defaultdict", "open", "tqdm.tqdm", "line.split", "out.split", "prepare.CSVReader", "prepare.sub2pid", "words[].replace", "name_rxcui[].add", "name_rxcui[].add", "int", "prepare.had2enc", "ALL_PRESCRIPTIONS.append", "int"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.CSVReader", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.sub2pid", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.had2enc"], ["", "def", "PICDB_PRESCRIPTIONS", "(", "dirname", ",", "tname", ",", "dbname", ",", "size", ")", ":", "\n", "    ", "name_rxcui", "=", "defaultdict", "(", "set", ")", "\n", "for", "line", "in", "open", "(", "'%s/res/medex-output.txt'", "%", "FILEDIR", ")", ":", "\n", "        ", "idx", ",", "out", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "words", "=", "out", ".", "split", "(", "'|'", ")", "\n", "name", ",", "rxcui", ",", "rxcui_gen", "=", "words", "[", "0", "]", ".", "replace", "(", "'.'", ",", "''", ")", ",", "words", "[", "11", "]", ",", "words", "[", "12", "]", "\n", "if", "rxcui", "!=", "''", ":", "\n", "            ", "name_rxcui", "[", "name", "]", ".", "add", "(", "rxcui", ")", "\n", "", "if", "rxcui_gen", "!=", "''", ":", "\n", "            ", "name_rxcui", "[", "name", "]", ".", "add", "(", "rxcui_gen", ")", "\n", "\n", "", "", "for", "rec", "in", "tqdm", "(", "CSVReader", "(", "dirname", ",", "tname", ")", ",", "total", "=", "size", ")", ":", "\n", "        ", "name", "=", "rec", "[", "'DRUG_NAME_EN'", "]", "\n", "if", "name", "not", "in", "name_rxcui", ":", "\n", "# TBD record missing codes and counts", "\n", "            ", "continue", "\n", "", "rxcuis", "=", "name_rxcui", "[", "name", "]", "\n", "pid", "=", "sub2pid", "(", "int", "(", "rec", "[", "'SUBJECT_ID'", "]", ")", ",", "dbname", ")", "\n", "enc", "=", "had2enc", "(", "int", "(", "rec", "[", "'HADM_ID'", "]", ")", ",", "dbname", ")", "if", "rec", "[", "'HADM_ID'", "]", "!=", "''", "else", "None", "\n", "std", "=", "rec", "[", "'STARTDATE'", "]", "\n", "end", "=", "rec", "[", "'ENDDATE'", "]", "\n", "val", "=", "rec", "[", "'DOSE_VAL_RX'", "]", "\n", "unt", "=", "rec", "[", "'DOSE_UNIT_RX'", "]", "\n", "\n", "for", "rxcui", "in", "rxcuis", ":", "\n", "            ", "ALL_PRESCRIPTIONS", ".", "append", "(", "(", "pid", ",", "enc", ",", "std", ",", "end", ",", "rxcui", ",", "val", ",", "unt", ")", ")", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat": [[367, 371], ["None"], "function", ["None"], ["", "def", "concat", "(", "*", "iterables", ")", ":", "\n", "    ", "for", "iterable", "in", "iterables", ":", "\n", "        ", "yield", "from", "iterable", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.MIMIC_INPUTEVENTS": [[374, 389], ["prepare.concat", "tqdm.tqdm", "prepare.CSVReader", "prepare.CSVReader", "prepare.sub2pid", "float", "ALL_INPUTEVENTS.append", "int", "prepare.had2enc", "int"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.CSVReader", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.CSVReader", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.sub2pid", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.had2enc"], ["def", "MIMIC_INPUTEVENTS", "(", "dirname", ",", "tname", ",", "dbname", ",", "size", ")", ":", "\n", "    ", "rdr", "=", "concat", "(", "CSVReader", "(", "dirname", ",", "tname", "+", "'_MV'", ")", ",", "\n", "CSVReader", "(", "dirname", ",", "tname", "+", "'_CV'", ")", ")", "\n", "\n", "for", "rec", "in", "tqdm", "(", "rdr", ",", "total", "=", "size", ")", ":", "\n", "        ", "pid", "=", "sub2pid", "(", "int", "(", "rec", "[", "'SUBJECT_ID'", "]", ")", ",", "dbname", ")", "\n", "enc", "=", "had2enc", "(", "int", "(", "rec", "[", "'HADM_ID'", "]", ")", ",", "dbname", ")", "if", "rec", "[", "'HADM_ID'", "]", "!=", "''", "else", "None", "\n", "ctm", "=", "rec", "[", "'CHARTTIME'", "]", "if", "'CHARTTIME'", "in", "rec", "else", "rec", "[", "'ENDTIME'", "]", "\n", "if", "rec", "[", "'AMOUNT'", "]", "==", "''", ":", "\n", "            ", "continue", "\n", "", "amt", "=", "float", "(", "rec", "[", "'AMOUNT'", "]", ")", "\n", "uom", "=", "rec", "[", "'AMOUNTUOM'", "]", "\n", "\n", "ALL_INPUTEVENTS", ".", "append", "(", "(", "pid", ",", "enc", ",", "ctm", ",", "amt", ",", "uom", ")", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.PICDB_INPUTEVENTS": [[390, 402], ["tqdm.tqdm", "prepare.CSVReader", "prepare.sub2pid", "float", "ALL_INPUTEVENTS.append", "int", "prepare.had2enc", "int"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.CSVReader", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.sub2pid", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.had2enc"], ["", "def", "PICDB_INPUTEVENTS", "(", "dirname", ",", "tname", ",", "dbname", ",", "size", ")", ":", "\n", "    ", "for", "rec", "in", "tqdm", "(", "CSVReader", "(", "dirname", ",", "tname", ")", ",", "total", "=", "size", ")", ":", "\n", "        ", "pid", "=", "sub2pid", "(", "int", "(", "rec", "[", "'SUBJECT_ID'", "]", ")", ",", "dbname", ")", "\n", "enc", "=", "had2enc", "(", "int", "(", "rec", "[", "'HADM_ID'", "]", ")", ",", "dbname", ")", "if", "rec", "[", "'HADM_ID'", "]", "!=", "''", "else", "None", "\n", "ctm", "=", "rec", "[", "'CHARTTIME'", "]", "\n", "if", "rec", "[", "'AMOUNT'", "]", "==", "''", ":", "\n", "            ", "continue", "\n", "", "amt", "=", "float", "(", "rec", "[", "'AMOUNT'", "]", ")", "\n", "uom", "=", "rec", "[", "'AMOUNTUOM'", "]", "\n", "\n", "ALL_INPUTEVENTS", ".", "append", "(", "(", "pid", ",", "enc", ",", "ctm", ",", "amt", ",", "uom", ")", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.HANDLE_OUTPUTEVENTS": [[408, 420], ["tqdm.tqdm", "prepare.CSVReader", "prepare.sub2pid", "float", "ALL_OUTPUTEVENTS.append", "int", "prepare.had2enc", "int"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.CSVReader", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.sub2pid", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.had2enc"], ["def", "HANDLE_OUTPUTEVENTS", "(", "dirname", ",", "tname", ",", "dbname", ",", "size", ")", ":", "\n", "    ", "for", "rec", "in", "tqdm", "(", "CSVReader", "(", "dirname", ",", "tname", ")", ",", "total", "=", "size", ")", ":", "\n", "        ", "pid", "=", "sub2pid", "(", "int", "(", "rec", "[", "'SUBJECT_ID'", "]", ")", ",", "dbname", ")", "\n", "enc", "=", "had2enc", "(", "int", "(", "rec", "[", "'HADM_ID'", "]", ")", ",", "dbname", ")", "if", "rec", "[", "'HADM_ID'", "]", "!=", "''", "else", "None", "\n", "ctm", "=", "rec", "[", "'CHARTTIME'", "]", "\n", "if", "rec", "[", "'VALUE'", "]", "==", "''", ":", "\n", "            ", "continue", "\n", "", "amt", "=", "float", "(", "rec", "[", "'VALUE'", "]", ")", "\n", "uom", "=", "rec", "[", "'VALUEUOM'", "]", "\n", "\n", "ALL_OUTPUTEVENTS", ".", "append", "(", "(", "pid", ",", "enc", ",", "ctm", ",", "amt", ",", "uom", ")", ")", "\n", "", "return", "\n", "", "MIMIC_OUTPUTEVENTS", "=", "HANDLE_OUTPUTEVENTS", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.dump_csv": [[444, 449], ["csv.writer", "csv.writer.writerow", "open", "csv.writer.writerow"], "function", ["None"], ["def", "dump_csv", "(", "table", ",", "cols", ",", "rows", ")", ":", "\n", "    ", "wrt", "=", "csv", ".", "writer", "(", "open", "(", "'%s/full/%s.csv'", "%", "(", "DATADIR", ",", "table", ")", ",", "'w'", ")", ",", "quotechar", "=", "'\"'", ")", "\n", "wrt", ".", "writerow", "(", "cols", ")", "\n", "for", "row", "in", "rows", ":", "\n", "        ", "wrt", ".", "writerow", "(", "row", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.dump_metadata": [[450, 519], ["SUB2PID.items", "print", "csv.writer", "csv.writer.writerow", "METADATA.items", "csv.writer", "csv.writer.writerow", "COL_PATIENTS.index", "COL_PATIENTS.index", "COL_PATIENTS.index", "dateutil.parser.parse", "COL_ADMISSIONS.index", "COL_ADMISSIONS.index", "COL_ADMISSIONS.index", "COL_ADMISSIONS.index", "COL_ADMISSIONS.index", "dateutil.parser.parse", "dateutil.parser.parse", "open", "list", "csv.writer.writerow", "open", "csv.writer.writerow", "datetime.timedelta", "datetime.timedelta", "datetime.timedelta", "str", "str", "md_pid.keys", "METADATA.items", "list", "md_pid.values", "eval", "datetime.timedelta"], "function", ["None"], ["", "", "def", "dump_metadata", "(", ")", ":", "\n", "    ", "METADATA", "=", "{", "}", "\n", "for", "(", "sub", ",", "dbname", ")", ",", "pid", "in", "SUB2PID", ".", "items", "(", ")", ":", "\n", "        ", "METADATA", "[", "pid", "]", "=", "{", "'DB'", ":", "dbname", ",", "\n", "'SUBJECT_ID'", ":", "sub", "}", "\n", "", "print", "(", "'Dumping METADATA ...'", ")", "\n", "DOB", "=", "{", "}", "\n", "for", "row", "in", "ALL_PATIENTS", ":", "\n", "        ", "gender_idx", "=", "COL_PATIENTS", ".", "index", "(", "'GENDER'", ")", "\n", "subject_idx", "=", "COL_PATIENTS", ".", "index", "(", "'SUBJECT_ID'", ")", "\n", "dob_idx", "=", "COL_PATIENTS", ".", "index", "(", "'DOB'", ")", "\n", "METADATA", "[", "pid", "]", "[", "'GENDER'", "]", "=", "row", "[", "gender_idx", "]", "\n", "pid", "=", "row", "[", "subject_idx", "]", "\n", "dob", "=", "date_parse", "(", "row", "[", "dob_idx", "]", ")", "\n", "DOB", "[", "pid", "]", "=", "dob", "\n", "\n", "", "for", "row", "in", "ALL_ADMISSIONS", ":", "\n", "        ", "adtime_idx", "=", "COL_ADMISSIONS", ".", "index", "(", "'ADMITTIME'", ")", "\n", "dstime_idx", "=", "COL_ADMISSIONS", ".", "index", "(", "'DISCHTIME'", ")", "\n", "subject_idx", "=", "COL_ADMISSIONS", ".", "index", "(", "'SUBJECT_ID'", ")", "\n", "ethnicity_idx", "=", "COL_ADMISSIONS", ".", "index", "(", "'ETHNICITY'", ")", "\n", "expire_idx", "=", "COL_ADMISSIONS", ".", "index", "(", "'HOSPITAL_EXPIRE_FLAG'", ")", "\n", "adtime", "=", "date_parse", "(", "row", "[", "adtime_idx", "]", ")", "\n", "dstime", "=", "date_parse", "(", "row", "[", "dstime_idx", "]", ")", "\n", "los_timedelta", "=", "dstime", "-", "adtime", "\n", "\n", "if", "los_timedelta", "<", "datetime", ".", "timedelta", "(", "days", "=", "1", ",", "hours", "=", "6", ")", ":", "\n", "# Too short gap time for the label not to leak info", "\n", "            ", "continue", "\n", "", "remain_los_3", "=", "los_timedelta", ">", "datetime", ".", "timedelta", "(", "days", "=", "3", "+", "1", ")", "\n", "remain_los_7", "=", "los_timedelta", ">", "datetime", ".", "timedelta", "(", "days", "=", "7", "+", "1", ")", "\n", "\n", "pid", "=", "row", "[", "subject_idx", "]", "\n", "eth", "=", "row", "[", "ethnicity_idx", "]", "\n", "dob", "=", "DOB", "[", "pid", "]", "\n", "age_days", "=", "(", "adtime", "-", "dob", ")", ".", "days", "\n", "replace_eth", "=", "[", "'UNKNOWN/NOT SPECIFIED'", ",", "'PATIENT DECLINED TO ANSWER'", ",", "'OTHER'", ",", "'UNABLE TO OBTAIN'", "]", "\n", "md_pid", "=", "METADATA", "[", "pid", "]", "\n", "#if 'ETHNICITY' in md_pid and md_pid['ETHNICITY'] in replace_eth and eth not in replace_eth:", "\n", "#    print('Replacing %s with %s' % (md_pid['ETHNICITY'], eth))", "\n", "md_pid", "[", "'HOSPITAL_EXPIRE_FLAG'", "]", "=", "row", "[", "expire_idx", "]", "\n", "md_pid", "[", "'REMAINING_LOS_3'", "]", "=", "remain_los_3", "\n", "md_pid", "[", "'REMAINING_LOS_7'", "]", "=", "remain_los_7", "\n", "if", "not", "'ETHNICITY'", "in", "md_pid", "or", "md_pid", "[", "'ETHNICITY'", "]", "in", "replace_eth", ":", "\n", "            ", "md_pid", "[", "'ETHNICITY'", "]", "=", "eth", "\n", "", "if", "not", "'AGE_IN_DAYS'", "in", "md_pid", "or", "md_pid", "[", "'AGE_IN_DAYS'", "]", ">", "age_days", ":", "\n", "            ", "md_pid", "[", "'AGE_IN_DAYS'", "]", "=", "age_days", "\n", "md_pid", "[", "'DATA_START'", "]", "=", "str", "(", "adtime", ")", "\n", "md_pid", "[", "'DATA_END'", "]", "=", "str", "(", "adtime", "+", "datetime", ".", "timedelta", "(", "days", "=", "1", ")", ")", "\n", "\n", "", "", "csvw", "=", "csv", ".", "writer", "(", "open", "(", "'%s/METADATA.csv'", "%", "DATADIR", ",", "'w'", ")", ")", "\n", "COLS", "=", "[", "'SUBJECT_ID'", "]", "+", "list", "(", "md_pid", ".", "keys", "(", ")", ")", "\n", "csvw", ".", "writerow", "(", "COLS", ")", "\n", "\n", "# Only those patients having an admission that was sufficiently long (> 30hrs)", "\n", "METADATA", "=", "{", "pid", ":", "md_pid", "for", "pid", ",", "md_pid", "in", "METADATA", ".", "items", "(", ")", "if", "'AGE_IN_DAYS'", "in", "md_pid", "}", "\n", "\n", "for", "pid", ",", "md_pid", "in", "METADATA", ".", "items", "(", ")", ":", "\n", "        ", "row", "=", "[", "pid", "]", "+", "list", "(", "md_pid", ".", "values", "(", ")", ")", "\n", "csvw", ".", "writerow", "(", "row", ")", "\n", "\n", "", "dw", "=", "csv", ".", "writer", "(", "open", "(", "'%s/full/D_ITEMS.csv'", "%", "DATADIR", ",", "'w'", ")", ")", "\n", "dw", ".", "writerow", "(", "[", "'ITEMID'", ",", "'DESCRIPTION'", "]", ")", "\n", "for", "item", "in", "[", "'TEMPERATURE'", ",", "'HEARTRATE'", ",", "'RESPIRATORYRATE'", ",", "'OXYGENSATURATION'", ",", "\n", "'GLUCOSE'", ",", "'HEIGHT'", ",", "'WEIGHT'", ",", "'DIASTOLICPRESSURE'", ",", "\n", "'SYSTOLICPRESSURE'", "]", ":", "\n", "        ", "dw", ".", "writerow", "(", "[", "eval", "(", "item", ")", ",", "item", "]", ")", "\n", "\n", "", "return", "METADATA", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.extract_table": [[520, 546], ["os.makedirs", "open", "csv.writer", "ALL_COLS.index", "print", "csv.writer.writerow", "enumerate", "ALL_COLS.index", "ALL_COLS.index", "dateutil.parser.parse", "csv.writer.writerow", "csv.writer.writerow"], "function", ["None"], ["", "def", "extract_table", "(", "tname", ",", "slice_name", ",", "split_name", ",", "dates", ",", "ALL_ROWS", ",", "ALL_COLS", ",", "COLS", ",", "date_col", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "'%s/slices/%s/%s'", "%", "(", "DATADIR", ",", "slice_name", ",", "split_name", ")", ",", "exist_ok", "=", "True", ")", "\n", "fd", "=", "open", "(", "'%s/slices/%s/%s/%s.csv'", "%", "(", "DATADIR", ",", "slice_name", ",", "split_name", ",", "tname", ")", ",", "'w'", ")", "\n", "tw", "=", "csv", ".", "writer", "(", "fd", ")", "\n", "idxs", "=", "[", "ALL_COLS", ".", "index", "(", "name", ")", "for", "name", "in", "COLS", "]", "if", "COLS", "else", "None", "\n", "pid_idx", "=", "ALL_COLS", ".", "index", "(", "'SUBJECT_ID'", ")", "\n", "date_idx", "=", "ALL_COLS", ".", "index", "(", "date_col", ")", "if", "date_col", "else", "None", "\n", "EXT_ROWS", "=", "[", "]", "\n", "print", "(", "'Dumping to %s.%s (%s) ...'", "%", "(", "slice_name", ",", "tname", ",", "split_name", ")", ")", "\n", "tw", ".", "writerow", "(", "COLS", "if", "COLS", "else", "ALL_COLS", ")", "\n", "for", "r", ",", "row", "in", "enumerate", "(", "ALL_ROWS", ")", ":", "\n", "        ", "pid", "=", "row", "[", "pid_idx", "]", "\n", "if", "pid", "not", "in", "dates", ":", "\n", "            ", "continue", "\n", "", "if", "date_idx", ":", "\n", "            ", "start", ",", "end", "=", "dates", "[", "pid", "]", "\n", "if", "row", "[", "date_idx", "]", "==", "''", ":", "\n", "                ", "continue", "\n", "", "date", "=", "date_parse", "(", "row", "[", "date_idx", "]", ")", "\n", "if", "date", "<", "start", "or", "date", ">", "end", ":", "\n", "                ", "continue", "\n", "", "", "if", "idxs", ":", "\n", "            ", "tw", ".", "writerow", "(", "[", "row", "[", "i", "]", "for", "i", "in", "idxs", "]", ")", "\n", "", "else", ":", "\n", "            ", "tw", ".", "writerow", "(", "row", ")", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.extract_labels": [[547, 554], ["os.makedirs", "csv.writer", "csv.writer.writerow", "labels.items", "open", "csv.writer.writerow"], "function", ["None"], ["", "def", "extract_labels", "(", "slice_name", ",", "split_name", ",", "labels", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "'%s/slices/%s/%s'", "%", "(", "DATADIR", ",", "slice_name", ",", "split_name", ")", ",", "exist_ok", "=", "True", ")", "\n", "lw", "=", "csv", ".", "writer", "(", "open", "(", "'%s/slices/%s/%s/LABELS.csv'", "%", "(", "DATADIR", ",", "slice_name", ",", "split_name", ")", ",", "'w'", ")", ")", "\n", "lw", ".", "writerow", "(", "[", "'SUBJECT_ID'", ",", "'HOSPITAL_EXPIRE_FLAG'", ",", "'REMAINING_LOS_3'", ",", "'REMAINING_LOS_7'", "]", ")", "\n", "for", "pid", ",", "(", "exp", ",", "los3", ",", "los7", ")", "in", "labels", ".", "items", "(", ")", ":", "\n", "        ", "lw", ".", "writerow", "(", "[", "pid", ",", "exp", ",", "los3", ",", "los7", "]", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.train_test_split": [[555, 567], ["numpy.random.shuffle", "numpy.random.shuffle", "set", "set", "labels.items", "labels.items", "dates.items", "labels.items", "dates.items", "labels.items", "int", "int", "int", "int", "len", "len", "len", "len"], "function", ["None"], ["", "def", "train_test_split", "(", "dates", ",", "labels", ",", "p", "=", "0.8", ")", ":", "\n", "    ", "pid_0", "=", "[", "pid", "for", "pid", ",", "row", "in", "labels", ".", "items", "(", ")", "if", "row", "[", "0", "]", "==", "0", "]", "\n", "pid_1", "=", "[", "pid", "for", "pid", ",", "row", "in", "labels", ".", "items", "(", ")", "if", "row", "[", "0", "]", "==", "1", "]", "\n", "np", ".", "random", ".", "shuffle", "(", "pid_0", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "pid_1", ")", "\n", "train_pids", "=", "set", "(", "pid_0", "[", ":", "int", "(", "len", "(", "pid_0", ")", "*", "p", ")", "]", "+", "pid_1", "[", ":", "int", "(", "len", "(", "pid_1", ")", "*", "p", ")", "]", ")", "\n", "test_pids", "=", "set", "(", "pid_0", "[", "int", "(", "len", "(", "pid_0", ")", "*", "p", ")", ":", "]", "+", "pid_1", "[", "int", "(", "len", "(", "pid_1", ")", "*", "p", ")", ":", "]", ")", "\n", "train_dates", "=", "{", "pid", ":", "row", "for", "pid", ",", "row", "in", "dates", ".", "items", "(", ")", "if", "pid", "in", "train_pids", "}", "\n", "train_labels", "=", "{", "pid", ":", "row", "for", "pid", ",", "row", "in", "labels", ".", "items", "(", ")", "if", "pid", "in", "train_pids", "}", "\n", "test_dates", "=", "{", "pid", ":", "row", "for", "pid", ",", "row", "in", "dates", ".", "items", "(", ")", "if", "pid", "in", "test_pids", "}", "\n", "test_labels", "=", "{", "pid", ":", "row", "for", "pid", ",", "row", "in", "labels", ".", "items", "(", ")", "if", "pid", "in", "test_pids", "}", "\n", "return", "train_dates", ",", "train_labels", ",", "test_dates", ",", "test_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.create_slice": [[568, 600], ["MD.query", "print", "prepare.train_test_split", "prepare.extract_labels", "prepare.extract_table", "prepare.extract_table", "prepare.extract_table", "prepare.extract_table", "prepare.extract_table", "prepare.extract_table", "prepare.extract_table", "dateutil.parser.parse", "dateutil.parser.parse", "MD.query.iterrows", "int", "int", "int", "MD.query.iterrows"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.train_test_split", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.extract_labels", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.extract_table", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.extract_table", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.extract_table", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.extract_table", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.extract_table", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.extract_table", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.extract_table"], ["", "def", "create_slice", "(", "MD", ",", "slice_name", ",", "condition", ")", ":", "\n", "    ", "slice", "=", "MD", ".", "query", "(", "condition", ")", "\n", "all_dates", "=", "{", "pid", ":", "(", "date_parse", "(", "row", "[", "'DATA_START'", "]", ")", ",", "date_parse", "(", "row", "[", "'DATA_END'", "]", ")", ")", "\n", "for", "pid", ",", "row", "in", "slice", ".", "iterrows", "(", ")", "}", "\n", "all_labels", "=", "{", "pid", ":", "(", "int", "(", "row", "[", "'HOSPITAL_EXPIRE_FLAG'", "]", ")", ",", "int", "(", "row", "[", "'REMAINING_LOS_3'", "]", ")", ",", "\n", "int", "(", "row", "[", "'REMAINING_LOS_7'", "]", ")", ")", "for", "pid", ",", "row", "in", "slice", ".", "iterrows", "(", ")", "}", "\n", "print", "(", "'Creating slice \"%s\" ...'", "%", "slice_name", ")", "\n", "\n", "train_dates", ",", "train_labels", ",", "test_dates", ",", "test_labels", "=", "train_test_split", "(", "all_dates", ",", "all_labels", ")", "\n", "\n", "for", "(", "split_name", ",", "labels", ",", "dates", ")", "in", "[", "(", "'train'", ",", "train_labels", ",", "train_dates", ")", ",", "\n", "(", "'test'", ",", "test_labels", ",", "test_dates", ")", "]", ":", "\n", "        ", "extract_labels", "(", "slice_name", ",", "split_name", ",", "labels", ")", "\n", "extract_table", "(", "'PATIENTS'", ",", "slice_name", ",", "split_name", ",", "dates", ",", "\n", "ALL_PATIENTS", ",", "COL_PATIENTS", ",", "\n", "[", "'SUBJECT_ID'", ",", "'GENDER'", ",", "'DOB'", "]", ",", "None", ")", "\n", "extract_table", "(", "'ADMISSIONS'", ",", "slice_name", ",", "split_name", ",", "dates", ",", "\n", "ALL_ADMISSIONS", ",", "COL_ADMISSIONS", ",", "\n", "[", "'SUBJECT_ID'", ",", "'HADM_ID'", ",", "'ADMITTIME'", ",", "'ETHNICITY'", "]", ",", "\n", "'ADMITTIME'", ")", "\n", "extract_table", "(", "'CHARTEVENTS'", ",", "slice_name", ",", "split_name", ",", "dates", ",", "\n", "ALL_CHARTEVENTS", ",", "COL_CHARTEVENTS", ",", "COL_CHARTEVENTS", ",", "'CHARTTIME'", ")", "\n", "extract_table", "(", "'LABEVENTS'", ",", "slice_name", ",", "split_name", ",", "dates", ",", "\n", "ALL_LABEVENTS", ",", "COL_LABEVENTS", ",", "None", ",", "'CHARTTIME'", ")", "\n", "extract_table", "(", "'INPUTEVENTS'", ",", "slice_name", ",", "split_name", ",", "dates", ",", "\n", "ALL_INPUTEVENTS", ",", "COL_INPUTEVENTS", ",", "None", ",", "'CHARTTIME'", ")", "\n", "extract_table", "(", "'OUTPUTEVENTS'", ",", "slice_name", ",", "split_name", ",", "dates", ",", "\n", "ALL_OUTPUTEVENTS", ",", "COL_OUTPUTEVENTS", ",", "None", ",", "'CHARTTIME'", ")", "\n", "extract_table", "(", "'PRESCRIPTIONS'", ",", "slice_name", ",", "split_name", ",", "dates", ",", "\n", "ALL_PRESCRIPTIONS", ",", "COL_PRESCRIPTIONS", ",", "None", ",", "'STARTDATE'", ")", "\n", "# TODO: add D_ITEMS into slice", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.create_slices": [[601, 607], ["pandas.DataFrame.from_dict", "prepare.config_get", "config_get.items", "prepare.create_slice"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.config_get", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.create_slice"], ["", "def", "create_slices", "(", "METADATA", ")", ":", "\n", "    ", "MD", "=", "pd", ".", "DataFrame", ".", "from_dict", "(", "METADATA", ",", "orient", "=", "'index'", ")", "\n", "sliceinfo", "=", "config_get", "(", "'partition-slices'", ")", "\n", "for", "slice_name", ",", "condition", "in", "sliceinfo", ".", "items", "(", ")", ":", "\n", "        ", "create_slice", "(", "MD", ",", "slice_name", ",", "condition", ")", "\n", "", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.main": [[608, 633], ["prepare.dump_metadata", "prepare.create_slices", "os.path.isdir", "os.makedirs", "eval", "eval", "print", "prepare.dump_csv", "len", "len", "eval", "print", "eval.", "eval"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.dump_metadata", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.create_slices", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.dump_csv"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "bmark_full", "=", "'%s/full'", "%", "DATADIR", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "bmark_full", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "bmark_full", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "for", "table", "in", "TABLES", ":", "\n", "        ", "for", "dbname", "in", "[", "'MIMIC'", ",", "'PICDB'", "]", ":", "\n", "            ", "dirname", "=", "'%s/%s'", "%", "(", "WORKDIR", ",", "eval", "(", "'DEFAULT_'", "+", "dbname", "+", "'_DIR'", ")", ")", "\n", "fn", "=", "eval", "(", "dbname", "+", "'_'", "+", "table", ")", "\n", "print", "(", "'Loading %s.%s ...'", "%", "(", "dbname", ",", "table", ")", ")", "\n", "fn", "(", "dirname", ",", "table", ",", "dbname", ",", "TABLE_SIZE", "[", "dbname", "]", "[", "table", "]", ")", "\n", "\n", "", "cols", "=", "eval", "(", "'COL_'", "+", "table", ")", "\n", "rows", "=", "eval", "(", "'ALL_'", "+", "table", ")", "\n", "print", "(", "'Dumping CSV for %s'", "%", "table", ")", "\n", "dump_csv", "(", "table", ",", "cols", ",", "rows", ")", "\n", "\n", "", "assert", "len", "(", "PID_REG", ")", "==", "0", "\n", "assert", "len", "(", "ENC_REG", ")", "==", "0", "\n", "\n", "METADATA", "=", "dump_metadata", "(", ")", "\n", "\n", "create_slices", "(", "METADATA", ")", "\n", "\n", "return", "METADATA", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.benchmark.config_get": [[24, 28], ["os.path.dirname", "os.path.realpath", "json.load", "open", "os.path.join"], "function", ["None"], ["def", "config_get", "(", "name", ")", ":", "\n", "    ", "FILEDIR", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", "\n", "CONFIG_JSON", "=", "'config.json'", "\n", "return", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "FILEDIR", ",", "CONFIG_JSON", ")", ")", ")", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.benchmark.fit_model": [[38, 47], ["importlib.import_module", "importlib.import_module.fit", "print"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.models.GP.fit"], ["def", "fit_model", "(", "mname", ",", "train_sl", ",", "task", ",", "X", ",", "Y", ",", "Xv", ",", "Yv", ")", ":", "\n", "    ", "if", "(", "mname", ",", "train_sl", ",", "task", ")", "in", "cached_models", ":", "\n", "        ", "print", "(", "'Returning cached model'", ")", "\n", "return", "cached_models", "[", "(", "train_sl", ",", "task", ")", "]", "\n", "\n", "", "module", "=", "importlib", ".", "import_module", "(", "'models.%s'", "%", "mname", ")", "\n", "model", "=", "module", ".", "fit", "(", "train_sl", ",", "task", ",", "X", ",", "Y", ",", "Xv", ",", "Yv", ")", "\n", "cached_models", "[", "(", "train_sl", ",", "task", ")", "]", "=", "model", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.benchmark.calc_train_size": [[48, 52], ["pandas.read_csv"], "function", ["None"], ["", "def", "calc_train_size", "(", "train_sl", ")", ":", "\n", "    ", "Y_train_file", "=", "'%s/train-%s/train_Y.csv'", "%", "(", "FEATDIR", ",", "train_sl", ")", "\n", "Ys", "=", "pd", ".", "read_csv", "(", "Y_train_file", ")", "\n", "return", "Ys", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.benchmark.work_slice": [[53, 95], ["print", "pandas.read_csv().fillna", "print", "pandas.read_csv().fillna", "print", "pandas.read_csv", "print", "pandas.read_csv", "print", "sklearn.preprocessing.StandardScaler().fit", "numpy.random.choice", "print", "pandas.read_csv().fillna", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "os.makedirs", "pd.DataFrame.to_csv", "pd.DataFrame.to_csv", "pd.DataFrame.to_csv", "pandas.read_csv", "pandas.read_csv", "range", "sklearn.preprocessing.StandardScaler", "numpy.zeros", "numpy.zeros", "numpy.zeros", "benchmark.fit_model", "print", "pandas.read_csv", "preprocessing.StandardScaler().fit.transform", "preprocessing.StandardScaler().fit.transform", "fit_model.predict_proba", "fit_model.predict_proba", "fit_model.predict_proba", "len", "len", "len", "preprocessing.StandardScaler().fit.transform", "preprocessing.StandardScaler().fit.transform", "preprocessing.StandardScaler().fit.transform"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.models.GP.fit", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.benchmark.fit_model", "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.SNGPDNN.predict_proba", "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.SNGPDNN.predict_proba", "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.SNGPDNN.predict_proba"], ["", "def", "work_slice", "(", "mname", ",", "train_sl", ",", "TEST_SLICES", ",", "train_size", ")", ":", "\n", "    ", "X_train_file", "=", "'%s/train-%s/train_X.csv'", "%", "(", "FEATDIR", ",", "train_sl", ")", "\n", "Y_train_file", "=", "'%s/train-%s/train_Y.csv'", "%", "(", "FEATDIR", ",", "train_sl", ")", "\n", "X_val_file", "=", "'%s/train-%s/val_X.csv'", "%", "(", "FEATDIR", ",", "train_sl", ")", "\n", "Y_val_file", "=", "'%s/train-%s/val_Y.csv'", "%", "(", "FEATDIR", ",", "train_sl", ")", "\n", "\n", "print", "(", "'Loading %s ...'", "%", "X_train_file", ")", "\n", "X", "=", "pd", ".", "read_csv", "(", "X_train_file", ",", "low_memory", "=", "False", ")", ".", "fillna", "(", "0", ")", "\n", "print", "(", "'Loading %s ...'", "%", "X_val_file", ")", "\n", "Xv", "=", "pd", ".", "read_csv", "(", "X_val_file", ",", "low_memory", "=", "False", ")", ".", "fillna", "(", "0", ")", "\n", "print", "(", "'Loading %s ...'", "%", "Y_train_file", ")", "\n", "Ys", "=", "pd", ".", "read_csv", "(", "Y_train_file", ",", "low_memory", "=", "False", ")", "\n", "print", "(", "'Loading %s ...'", "%", "Y_val_file", ")", "\n", "Yvs", "=", "pd", ".", "read_csv", "(", "Y_val_file", ",", "low_memory", "=", "False", ")", "\n", "\n", "total_train_size", "=", "X", ".", "shape", "[", "0", "]", "\n", "if", "train_size", "<", "total_train_size", ":", "\n", "        ", "train_idxs", "=", "np", ".", "random", ".", "choice", "(", "range", "(", "total_train_size", ")", ",", "train_size", ",", "replace", "=", "False", ")", "\n", "X", "=", "X", ".", "iloc", "[", "train_idxs", "]", "\n", "Ys", "=", "Ys", ".", "iloc", "[", "train_idxs", "]", "\n", "\n", "", "print", "(", "'Scaling X ...'", ")", "\n", "scaler", "=", "preprocessing", ".", "StandardScaler", "(", ")", ".", "fit", "(", "X", ")", "\n", "for", "test_sl", "in", "TEST_SLICES", ":", "\n", "        ", "X_test_file", "=", "'%s/train-%s/test/%s_X.csv'", "%", "(", "FEATDIR", ",", "train_sl", ",", "test_sl", ")", "\n", "print", "(", "'Loading %s ...'", "%", "X_test_file", ")", "\n", "X_test", "=", "pd", ".", "read_csv", "(", "X_test_file", ",", "low_memory", "=", "False", ")", ".", "fillna", "(", "0", ")", "\n", "\n", "P", "=", "pd", ".", "DataFrame", "(", "np", ".", "zeros", "(", "(", "X_test", ".", "shape", "[", "0", "]", ",", "len", "(", "TASKS", ")", ")", ")", ",", "index", "=", "X_test", ".", "index", ",", "columns", "=", "TASKS", ")", "\n", "Pt", "=", "pd", ".", "DataFrame", "(", "np", ".", "zeros", "(", "(", "X", ".", "shape", "[", "0", "]", ",", "len", "(", "TASKS", ")", ")", ")", ",", "index", "=", "X", ".", "index", ",", "columns", "=", "TASKS", ")", "\n", "Pv", "=", "pd", ".", "DataFrame", "(", "np", ".", "zeros", "(", "(", "Xv", ".", "shape", "[", "0", "]", ",", "len", "(", "TASKS", ")", ")", ")", ",", "index", "=", "Xv", ".", "index", ",", "columns", "=", "TASKS", ")", "\n", "for", "task", "in", "TASKS", ":", "\n", "            ", "Y", ",", "Yv", "=", "Ys", "[", "task", "]", ",", "Yvs", "[", "task", "]", "\n", "m", "=", "fit_model", "(", "mname", ",", "train_sl", ",", "task", ",", "scaler", ".", "transform", "(", "X", ")", ",", "Y", ",", "scaler", ".", "transform", "(", "Xv", ")", ",", "Yv", ")", "\n", "print", "(", "'Predicting on %s ...'", "%", "X_test_file", ")", "\n", "P", "[", "task", "]", "=", "m", ".", "predict_proba", "(", "scaler", ".", "transform", "(", "X_test", ")", ")", "[", ":", ",", "1", "]", "\n", "Pv", "[", "task", "]", "=", "m", ".", "predict_proba", "(", "scaler", ".", "transform", "(", "Xv", ")", ")", "[", ":", ",", "1", "]", "\n", "Pt", "[", "task", "]", "=", "m", ".", "predict_proba", "(", "scaler", ".", "transform", "(", "X", ")", ")", "[", ":", ",", "1", "]", "\n", "", "os", ".", "makedirs", "(", "'%s/%s/train-%s/test'", "%", "(", "PREDDIR", ",", "mname", ",", "train_sl", ")", ",", "exist_ok", "=", "True", ")", "\n", "P", ".", "to_csv", "(", "'%s/%s/train-%s/test/%s_P.csv'", "%", "(", "PREDDIR", ",", "mname", ",", "train_sl", ",", "test_sl", ")", ")", "\n", "Pv", ".", "to_csv", "(", "'%s/%s/train-%s/val_P.csv'", "%", "(", "PREDDIR", ",", "mname", ",", "train_sl", ")", ")", "\n", "P", ".", "to_csv", "(", "'%s/%s/train-%s/train_P.csv'", "%", "(", "PREDDIR", ",", "mname", ",", "train_sl", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.benchmark.work_model": [[96, 106], ["print", "numpy.random.seed", "min", "benchmark.work_slice", "benchmark.calc_train_size"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.benchmark.work_slice", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.benchmark.calc_train_size"], ["", "", "def", "work_model", "(", "mname", ")", ":", "\n", "    ", "print", "(", "'Working with model: %s'", "%", "mname", ")", "\n", "\n", "# Make runs reproducible", "\n", "np", ".", "random", ".", "seed", "(", "2020", ")", "\n", "\n", "for", "SLICES", "in", "SLICE_SETS", ":", "\n", "        ", "train_size", "=", "min", "(", "[", "calc_train_size", "(", "sl", ")", "for", "sl", "in", "SLICES", "]", ")", "\n", "for", "sl", "in", "SLICES", ":", "\n", "            ", "work_slice", "(", "mname", ",", "sl", ",", "SLICES", ",", "train_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.benchmark.main": [[107, 113], ["benchmark.work_model", "gc.collect"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.benchmark.work_model", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.collect"], ["", "", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "for", "mname", "in", "MODELS", ":", "\n", "        ", "work_model", "(", "mname", ")", "\n", "cached_models", "=", "{", "}", "\n", "import", "gc", "\n", "gc", ".", "collect", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.config_get": [[26, 30], ["os.path.dirname", "os.path.realpath", "json.load", "open", "os.path.join"], "function", ["None"], ["def", "config_get", "(", "name", ")", ":", "\n", "    ", "FILEDIR", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", "\n", "CONFIG_JSON", "=", "'config.json'", "\n", "return", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "FILEDIR", ",", "CONFIG_JSON", ")", ")", ")", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.ECE": [[55, 71], ["zip", "sum", "list", "list", "len", "int", "Y_buckets[].append", "P_buckets[].append", "abs", "zip", "len", "len", "numpy.mean", "numpy.mean"], "function", ["None"], ["def", "ECE", "(", "Y", ",", "P", ",", "n_bins", "=", "10", ")", ":", "\n", "#return brier_score_loss(Y, P)", "\n", "    ", "P", ",", "Y", "=", "list", "(", "Y", ")", ",", "list", "(", "P", ")", "\n", "l", "=", "1.", "*", "len", "(", "Y", ")", "\n", "Y_buckets", "=", "[", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "]", "\n", "P_buckets", "=", "[", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "]", "\n", "for", "y", ",", "p", "in", "zip", "(", "Y", ",", "P", ")", ":", "\n", "        ", "idx", "=", "int", "(", "p", "*", "10", ")", "\n", "if", "idx", "==", "10", ":", "\n", "            ", "idx", "=", "9", "\n", "", "Y_buckets", "[", "idx", "]", ".", "append", "(", "y", ")", "\n", "P_buckets", "[", "idx", "]", ".", "append", "(", "p", ")", "\n", "\n", "", "ece", "=", "sum", "(", "[", "(", "len", "(", "y_l", ")", "/", "l", ")", "*", "abs", "(", "np", ".", "mean", "(", "y_l", ")", "-", "np", ".", "mean", "(", "p_l", ")", ")", "\n", "for", "y_l", ",", "p_l", "in", "zip", "(", "Y_buckets", ",", "P_buckets", ")", "if", "len", "(", "y_l", ")", ">", "0", "]", ")", "\n", "return", "ece", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.bootstrap": [[72, 95], ["len", "len", "len", "numpy.random.choice", "numpy.random.choice", "numpy.mean", "Y.flatten.flatten", "P.flatten.flatten", "range", "range", "range", "range", "numpy.concatenate", "numpy.concatenate", "zip", "numpy.std", "sklearn.metrics.roc_auc_score", "results.ECE", "sklearn.metrics.roc_auc_score", "sklearn.metrics.roc_auc_score", "results.ECE", "sklearn.metrics.roc_auc_score"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.ECE", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.ECE"], ["", "def", "bootstrap", "(", "Y", ",", "P", ",", "scorefn", ")", ":", "\n", "    ", "B", "=", "100", "\n", "l", "=", "len", "(", "Y", ")", "\n", "try", ":", "\n", "        ", "Y0", "=", "Y", "[", "Y", "==", "0", "]", ".", "values", "\n", "P0", "=", "P", "[", "Y", "==", "0", "]", ".", "values", "\n", "Y1", "=", "Y", "[", "Y", "==", "1", "]", ".", "values", "\n", "P1", "=", "P", "[", "Y", "==", "1", "]", ".", "values", "\n", "", "except", ":", "\n", "        ", "Y", "=", "Y", ".", "flatten", "(", ")", "\n", "P", "=", "P", ".", "flatten", "(", ")", "\n", "Y0", "=", "Y", "[", "Y", "==", "0", "]", "\n", "P0", "=", "P", "[", "Y", "==", "0", "]", "\n", "Y1", "=", "Y", "[", "Y", "==", "1", "]", "\n", "P1", "=", "P", "[", "Y", "==", "1", "]", "\n", "", "l0", "=", "len", "(", "Y0", ")", "\n", "l1", "=", "len", "(", "Y1", ")", "\n", "choices0", "=", "[", "np", ".", "random", ".", "choice", "(", "range", "(", "l0", ")", ",", "l0", ",", "replace", "=", "True", ")", "for", "_", "in", "range", "(", "B", ")", "]", "\n", "choices1", "=", "[", "np", ".", "random", ".", "choice", "(", "range", "(", "l1", ")", ",", "l1", ",", "replace", "=", "True", ")", "for", "_", "in", "range", "(", "B", ")", "]", "\n", "scores", "=", "[", "scorefn", "(", "np", ".", "concatenate", "(", "[", "Y0", "[", "choice0", "]", ",", "Y1", "[", "choice1", "]", "]", ")", ",", "\n", "np", ".", "concatenate", "(", "[", "P0", "[", "choice0", "]", ",", "P1", "[", "choice1", "]", "]", ")", ")", "\n", "for", "choice0", ",", "choice1", "in", "zip", "(", "choices0", ",", "choices1", ")", "]", "\n", "return", "np", ".", "mean", "(", "scores", ")", ",", "2", "*", "np", ".", "std", "(", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.task_print": [[96, 103], ["None"], "function", ["None"], ["", "def", "task_print", "(", "task", ")", ":", "\n", "    ", "d", "=", "{", "'HOSPITAL_EXPIRE_FLAG'", ":", "'Mortality'", ",", "\n", "'REMAINING_LOS_3'", ":", "'LoS 3+'", ",", "\n", "'REMAINING_LOS_7'", ":", "'LoS 7+'", "}", "\n", "if", "task", "in", "d", ":", "\n", "        ", "return", "d", "[", "task", "]", "\n", "", "return", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.task_desc": [[104, 111], ["None"], "function", ["None"], ["", "def", "task_desc", "(", "task", ")", ":", "\n", "    ", "d", "=", "{", "'Mortality'", ":", "'In Hospital Mortality'", ",", "\n", "'LoS 3+'", ":", "'Length of Stay 3+ days'", ",", "\n", "'LoS 7+'", ":", "'Length of Stay 7+ days'", "}", "\n", "if", "task", "in", "d", ":", "\n", "        ", "return", "d", "[", "task", "]", "\n", "", "return", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.task_BRNN": [[112, 119], ["None"], "function", ["None"], ["", "def", "task_BRNN", "(", "task", ")", ":", "\n", "    ", "d", "=", "{", "'HOSPITAL_EXPIRE_FLAG'", ":", "'mortality'", ",", "\n", "'REMAINING_LOS_3'", ":", "'los3'", ",", "\n", "'REMAINING_LOS_7'", ":", "'los7'", "}", "\n", "if", "task", "in", "d", ":", "\n", "        ", "return", "d", "[", "task", "]", "\n", "", "return", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.collect": [[120, 154], ["pandas.read_csv", "pandas.read_csv", "results.bootstrap", "results.bootstrap", "Y[].mean", "pd.read_csv.append", "pd.read_csv.append", "results.bootstrap", "results.bootstrap", "print", "fd.write", "pandas.read_csv", "pandas.read_csv", "sklearn.metrics.roc_auc_score", "results.task_print"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.bootstrap", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.bootstrap", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.bootstrap", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.bootstrap", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.task_print"], ["", "def", "collect", "(", "fd", ",", "mname", ")", ":", "\n", "    ", "for", "SLICES", "in", "SLICE_SETS", ":", "\n", "        ", "for", "train_sl", "in", "SLICES", ":", "\n", "            ", "try", ":", "\n", "                ", "Y_in", "=", "pd", ".", "read_csv", "(", "'%s/train-%s/test/%s_Y.csv'", "%", "(", "FEATDIR", ",", "train_sl", ",", "train_sl", ")", ")", "\n", "P_in", "=", "pd", ".", "read_csv", "(", "'%s/%s/train-%s/test/%s_P.csv'", "%", "(", "PREDDIR", ",", "mname", ",", "train_sl", ",", "train_sl", ")", ")", "\n", "", "except", ":", "\n", "                ", "continue", "\n", "", "Y_in", "[", "'IO'", "]", "=", "0", "\n", "for", "task", "in", "TASKS", ":", "\n", "                ", "for", "test_sl", "in", "SLICES", ":", "\n", "                    ", "try", ":", "\n", "                        ", "Y", "=", "pd", ".", "read_csv", "(", "'%s/train-%s/test/%s_Y.csv'", "%", "(", "FEATDIR", ",", "train_sl", ",", "test_sl", ")", ")", "\n", "P", "=", "pd", ".", "read_csv", "(", "'%s/%s/train-%s/test/%s_P.csv'", "%", "(", "PREDDIR", ",", "mname", ",", "train_sl", ",", "test_sl", ")", ")", "\n", "", "except", ":", "\n", "                        ", "continue", "\n", "", "Y", "[", "'IO'", "]", "=", "1", "\n", "auc", ",", "abar", "=", "bootstrap", "(", "Y", "[", "task", "]", ",", "P", "[", "task", "]", ",", "roc_auc_score", ")", "\n", "ece", ",", "ebar", "=", "bootstrap", "(", "Y", "[", "task", "]", ",", "P", "[", "task", "]", ",", "ECE", ")", "\n", "\n", "prev", "=", "Y", "[", "task", "]", ".", "mean", "(", ")", "\n", "def", "ood_auroc", "(", "Y", ",", "P", ")", ":", "\n", "                        ", "Pfix", "=", "P", "*", "(", "1", "-", "prev", ")", "/", "(", "P", "+", "prev", "-", "2", "*", "prev", "*", "P", ")", "\n", "return", "roc_auc_score", "(", "Y", ",", "Pfix", "*", "(", "1", "-", "Pfix", ")", ")", "\n", "\n", "", "Y_io", "=", "Y_in", ".", "append", "(", "Y", ")", "\n", "P_io", "=", "P_in", ".", "append", "(", "P", ")", "\n", "ood", ",", "obar", "=", "bootstrap", "(", "Y_io", "[", "'IO'", "]", ",", "P_io", "[", "task", "]", "*", "(", "1", "-", "P_io", "[", "task", "]", ")", ",", "roc_auc_score", ")", "\n", "pood", ",", "pobar", "=", "bootstrap", "(", "Y_io", "[", "'IO'", "]", ",", "P_io", "[", "task", "]", ",", "ood_auroc", ")", "\n", "row", "=", "'%s,%s,%s,%s,%0.3f,%0.3f,%0.3f,%0.3f,%0.3f,%0.3f,%0.3f,%0.3f'", "%", "(", "mname", ",", "train_sl", ",", "test_sl", ",", "task_print", "(", "task", ")", ",", "auc", ",", "abar", ",", "ece", ",", "ebar", ",", "ood", ",", "obar", ",", "pood", ",", "pobar", ")", "\n", "print", "(", "row", ")", "\n", "fd", ".", "write", "(", "row", "+", "'\\n'", ")", "\n", "", "", "", "", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.collect_BRNN": [[155, 195], ["numpy.load", "numpy.load", "results.bootstrap", "results.bootstrap", "np.load.mean", "numpy.append", "numpy.append", "results.bootstrap", "results.bootstrap", "print", "fd.write", "numpy.exp", "numpy.load", "numpy.load", "sklearn.metrics.roc_auc_score", "numpy.zeros", "numpy.ones", "numpy.exp", "len", "len", "results.task_print", "results.task_BRNN", "results.task_BRNN", "results.task_BRNN", "results.task_BRNN"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.bootstrap", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.bootstrap", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.bootstrap", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.bootstrap", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.task_print", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.task_BRNN", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.task_BRNN", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.task_BRNN", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.task_BRNN"], ["", "def", "collect_BRNN", "(", "fd", ",", "basedir", ",", "ts", "=", "'20201210_192808'", ")", ":", "\n", "    ", "for", "SLICES", "in", "SLICE_SETS", ":", "\n", "        ", "for", "train_sl", "in", "SLICES", ":", "\n", "            ", "for", "task", "in", "TASKS", ":", "\n", "                ", "try", ":", "\n", "                    ", "Y_in", "=", "np", ".", "load", "(", "'%s/%s/predictions/train-%s/test-%s/%s/test/labels.npy'", "%", "(", "basedir", ",", "task_BRNN", "(", "task", ")", ",", "train_sl", ",", "train_sl", ",", "ts", ")", ")", "\n", "L_in", "=", "np", ".", "load", "(", "'%s/%s/predictions/train-%s/test-%s/%s/test/logits.npy'", "%", "(", "basedir", ",", "task_BRNN", "(", "task", ")", ",", "train_sl", ",", "train_sl", ",", "ts", ")", ")", "\n", "", "except", ":", "\n", "                    ", "continue", "\n", "\n", "", "P_in", "=", "1", "/", "(", "1", "+", "np", ".", "exp", "(", "-", "L_in", ")", ")", "\n", "for", "test_sl", "in", "SLICES", ":", "\n", "                    ", "try", ":", "\n", "                        ", "Y", "=", "np", ".", "load", "(", "'%s/%s/predictions/train-%s/test-%s/%s/test/labels.npy'", "%", "(", "basedir", ",", "task_BRNN", "(", "task", ")", ",", "train_sl", ",", "test_sl", ",", "ts", ")", ")", "\n", "L", "=", "np", ".", "load", "(", "'%s/%s/predictions/train-%s/test-%s/%s/test/logits.npy'", "%", "(", "basedir", ",", "task_BRNN", "(", "task", ")", ",", "train_sl", ",", "test_sl", ",", "ts", ")", ")", "\n", "", "except", ":", "\n", "                        ", "continue", "\n", "", "P", "=", "1", "/", "(", "1", "+", "np", ".", "exp", "(", "-", "L", ")", ")", "\n", "\n", "auc", ",", "abar", "=", "bootstrap", "(", "Y", ",", "P", ",", "roc_auc_score", ")", "\n", "ece", ",", "ebar", "=", "bootstrap", "(", "Y", ",", "P", ",", "ECE", ")", "\n", "\n", "prev", "=", "Y", ".", "mean", "(", ")", "\n", "def", "ood_auroc", "(", "Y", ",", "P", ")", ":", "\n", "                        ", "Pfix", "=", "P", "*", "(", "1", "-", "prev", ")", "/", "(", "P", "+", "prev", "-", "2", "*", "prev", "*", "P", ")", "\n", "return", "roc_auc_score", "(", "Y", ",", "Pfix", "*", "(", "1", "-", "Pfix", ")", ")", "\n", "\n", "", "Y_io", "=", "np", ".", "append", "(", "np", ".", "zeros", "(", "len", "(", "Y_in", ")", ")", ",", "np", ".", "ones", "(", "len", "(", "Y", ")", ")", ")", "\n", "P_io", "=", "np", ".", "append", "(", "P_in", ",", "P", ")", "\n", "ood", ",", "obar", "=", "bootstrap", "(", "Y_io", ",", "P_io", "*", "(", "1", "-", "P_io", ")", ",", "roc_auc_score", ")", "\n", "pood", ",", "pobar", "=", "bootstrap", "(", "Y_io", ",", "P_io", ",", "ood_auroc", ")", "\n", "row", "=", "'%s,%s,%s,%s,%0.3f,%0.3f,%0.3f,%0.3f,%0.3f,%0.3f,%0.3f,%0.3f'", "%", "(", "'BRNN'", ",", "train_sl", ",", "test_sl", ",", "task_print", "(", "task", ")", ",", "auc", ",", "abar", ",", "ece", ",", "ebar", ",", "ood", ",", "obar", ",", "pood", ",", "pobar", ")", "\n", "print", "(", "row", ")", "\n", "fd", ".", "write", "(", "row", "+", "'\\n'", ")", "\n", "", "", "", "", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.create_results_df": [[196, 218], ["pandas.read_csv", "open", "open.write", "print", "results.collect_BRNN", "open.close", "pandas.read_csv", "stats.append.append", "os.path.exists", "open", "open.write", "print", "results.collect", "open.close", "os.stat", "os.path.exists", "os.stat"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.collect_BRNN", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.collect"], ["", "def", "create_results_df", "(", ")", ":", "\n", "    ", "brnn_dpath", "=", "'/tmp/medical_uncertainty/bayesian_rnn'", "\n", "brnn_rpath", "=", "'%s/BRNN.csv'", "%", "RESDIR", "\n", "TS", "=", "'20201210_192808'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "brnn_rpath", ")", "or", "os", ".", "stat", "(", "brnn_rpath", ")", ".", "st_size", "<", "100", ":", "\n", "        ", "fd", "=", "open", "(", "brnn_rpath", ",", "'w'", ")", "\n", "fd", ".", "write", "(", "'Model,Train,Test,Task,AUC,ABAR,ECE,EBAR,OOD,OBAR,POOD,POBAR\\n'", ")", "\n", "print", "(", "'Collecting BRNN...'", ")", "\n", "collect_BRNN", "(", "fd", ",", "brnn_dpath", ",", "TS", ")", "\n", "fd", ".", "close", "(", ")", "\n", "", "stats", "=", "pd", ".", "read_csv", "(", "brnn_rpath", ")", "\n", "for", "mname", "in", "MODELS", ":", "\n", "        ", "rpath", "=", "'%s/%s.csv'", "%", "(", "RESDIR", ",", "mname", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "rpath", ")", "or", "os", ".", "stat", "(", "rpath", ")", ".", "st_size", "<", "100", ":", "\n", "            ", "fd", "=", "open", "(", "rpath", ",", "'w'", ")", "\n", "fd", ".", "write", "(", "'Model,Train,Test,Task,AUC,ABAR,ECE,EBAR,OOD,OBAR,POOD,POBAR\\n'", ")", "\n", "print", "(", "'Collecting %s...'", "%", "mname", ")", "\n", "collect", "(", "fd", ",", "mname", ")", "\n", "fd", ".", "close", "(", ")", "\n", "", "df", "=", "pd", ".", "read_csv", "(", "rpath", ")", "\n", "stats", "=", "stats", ".", "append", "(", "df", ")", "\n", "", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.gen_latex": [[220, 295], ["os.makedirs", "open", "df[].unique", "results.gen_latex.P"], "function", ["None"], ["", "def", "gen_latex", "(", "df", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "RESDIR", ",", "'latex'", ")", ",", "exist_ok", "=", "True", ")", "\n", "fd", "=", "open", "(", "os", ".", "path", ".", "join", "(", "RESDIR", ",", "'latex'", ",", "'results.tex'", ")", ",", "'w'", ")", "\n", "TASKNAMES", "=", "df", "[", "'Task'", "]", ".", "unique", "(", ")", "\n", "\n", "def", "P", "(", "*", "args", ")", ":", "\n", "        ", "line", "=", "' '", ".", "join", "(", "str", "(", "w", ")", "for", "w", "in", "args", ")", "+", "'\\n'", "\n", "fd", ".", "write", "(", "line", ")", "\n", "\n", "\n", "", "hdr", "=", "r'''\\documentclass{article}\n%%\\usepackage[landscape]{geometry}\n\\usepackage{xcolor}\n\\usepackage{graphicx}\n\\usepackage{fullpage}\n\\usepackage{diagbox}\n\\usepackage{multirow}\n\n\\begin{document}\n\\centering\n\\tiny\n\n'''", "\n", "P", "(", "hdr", ")", "\n", "\n", "for", "task", "in", "TASKNAMES", ":", "\n", "        ", "P", "(", "r'\\section*{'", ",", "task_desc", "(", "task", ")", ",", "'}'", ")", "\n", "P", "(", "r\"\\begin{tabular}{|l|l|l|\"", "+", "''", ".", "join", "(", "[", "'c|'", "for", "_", "in", "MODELS", "]", ")", "+", "\"}\"", ")", "\n", "P", "(", "r\"\\hline\"", ")", "\n", "P", "(", "r\"Train & Test & Metric & \"", "+", "' & '", ".", "join", "(", "MODELS", ")", "+", "r'\\\\'", ")", "\n", "P", "(", "r\"\\hline\"", ")", "\n", "\n", "for", "sl", ",", "SLICES", "in", "SLICE_TESTS", ".", "items", "(", ")", ":", "\n", "            ", "P", "(", "r\"\\multirow{\"", ",", "len", "(", "METRICS", ")", "*", "len", "(", "SLICES", ")", ",", "\"}{*}{\\\\rotatebox{90}{\"", ",", "SLICE_NAMES", "[", "sl", "]", ",", "\"}}\"", ")", "\n", "for", "test_sl", "in", "SLICES", ":", "\n", "\n", "                ", "P", "(", "r\"& \\multirow{\"", ",", "len", "(", "METRICS", ")", ",", "\"}{*}{\"", ",", "SLICE_NAMES", "[", "test_sl", "]", ",", "\"}\"", ")", "\n", "for", "i", ",", "(", "metric", ",", "bar", ",", "color", ")", "in", "enumerate", "(", "METRICS", ")", ":", "\n", "                    ", "if", "(", "i", ">", "0", ")", ":", "\n", "                        ", "P", "(", "'&'", ")", "\n", "", "P", "(", "r'& \\color{%s}{%s}'", "%", "(", "color", ",", "metric", ")", ")", "\n", "\n", "# All stats (across models) to decide which model \"wins\" the row", "\n", "all_stats", "=", "[", "]", "\n", "for", "model", "in", "MODELS", ":", "\n", "                        ", "stats", "=", "df", ".", "query", "(", "'Train==\"%s\" and Test==\"%s\" and Task==\"%s\" and Model==\"%s\"'", "%", "(", "sl", ",", "test_sl", ",", "task", ",", "model", ")", ")", "\n", "if", "stats", ".", "shape", "[", "0", "]", "!=", "1", ":", "\n", "                            ", "continue", "\n", "", "all_stats", ".", "append", "(", "stats", ".", "iloc", "[", "0", "]", "[", "metric", "]", ")", "\n", "\n", "", "for", "model", "in", "MODELS", ":", "\n", "                        ", "stats", "=", "df", ".", "query", "(", "'Train==\"%s\" and Test==\"%s\" and Task==\"%s\" and Model==\"%s\"'", "%", "(", "sl", ",", "test_sl", ",", "task", ",", "model", ")", ")", "\n", "if", "stats", ".", "shape", "[", "0", "]", "!=", "1", ":", "\n", "                            ", "P", "(", "'& NA'", ")", "\n", "", "elif", "sl", "==", "test_sl", "and", "(", "metric", "==", "'OOD'", "or", "metric", "==", "'POOD'", ")", ":", "\n", "                            ", "P", "(", "'& NA'", ")", "\n", "", "else", ":", "\n", "                            ", "val", "=", "stats", ".", "iloc", "[", "0", "]", "[", "metric", "]", "\n", "valbar", "=", "stats", ".", "iloc", "[", "0", "]", "[", "bar", "]", "\n", "if", "metric", "==", "'ECE'", ":", "\n", "                                ", "best", "=", "min", "(", "all_stats", ")", "\n", "", "else", ":", "\n", "                                ", "best", "=", "max", "(", "all_stats", ")", "\n", "", "if", "val", "!=", "best", ":", "\n", "                                ", "P", "(", "r'& \\color{%s}{%0.3f $\\pm$ %0.3f}'", "%", "(", "color", ",", "val", ",", "valbar", ")", ")", "\n", "", "else", ":", "\n", "                                ", "P", "(", "r'& \\textbf{\\color{%s}{%0.3f $\\pm$ %0.3f}}'", "%", "(", "color", ",", "val", ",", "valbar", ")", ")", "\n", "", "", "", "P", "(", "r\"\\\\\"", ")", "\n", "", "P", "(", "r\"\\cline{2-\"", ",", "len", "(", "MODELS", ")", "+", "3", ",", "\"}\"", ")", "\n", "", "P", "(", "r\"\\hline\"", ")", "\n", "P", "(", "r\"\\hline\"", ")", "\n", "", "P", "(", "r\"\\end{tabular}\"", ")", "\n", "", "P", "(", "r\"\\end{document}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.main": [[297, 303], ["os.makedirs", "results.create_results_df", "create_results_df.to_csv", "results.gen_latex"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.create_results_df", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.results.gen_latex"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "RESDIR", ",", "exist_ok", "=", "True", ")", "\n", "\n", "df", "=", "create_results_df", "(", ")", "\n", "df", ".", "to_csv", "(", "'%s/results.csv'", "%", "RESDIR", ")", "\n", "gen_latex", "(", "df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.PatInfo.__init__": [[89, 96], ["int", "collections.defaultdict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dob", "=", "0", ",", "gender", "=", "\"female\"", ",", "in_hospital_expire", "=", "0", ",", "pid", "=", "0", ",", "enc", "=", "0", ")", ":", "\n", "        ", "self", ".", "dob", "=", "int", "(", "dob", ")", "\n", "self", ".", "gender", "=", "gender", "\n", "self", ".", "in_hospital_expire", "=", "in_hospital_expire", "\n", "self", ".", "pid", "=", "pid", "\n", "self", ".", "enc", "=", "enc", "\n", "self", ".", "seqs", "=", "{", "c", ":", "defaultdict", "(", "list", ")", "for", "c", "in", "CODE_TABLES", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.config_get": [[32, 34], ["json.load", "open", "os.path.join"], "function", ["None"], ["def", "config_get", "(", "name", ")", ":", "\n", "    ", "return", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "FILEDIR", ",", "CONFIG_JSON", ")", ")", ")", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.val_pids": [[43, 49], ["pandas.read_csv", "list", "numpy.random.shuffle", "set", "int", "len"], "function", ["None"], ["def", "val_pids", "(", "sl", ")", ":", "\n", "    ", "pat_df", "=", "pd", ".", "read_csv", "(", "DATADIR", "+", "'/slices/%s/train/PATIENTS.csv'", "%", "sl", ",", "low_memory", "=", "False", ",", "parse_dates", "=", "[", "'DOB'", "]", ")", "\n", "pids_all", "=", "list", "(", "pat_df", "[", "'SUBJECT_ID'", "]", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "pids_all", ")", "\n", "pids_val", "=", "set", "(", "pids_all", "[", ":", "int", "(", "len", "(", "pids_all", ")", "*", "0.2", ")", "]", ")", "\n", "return", "pids_val", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.load_train_tables": [[50, 58], ["print", "pandas.read_csv", "full_df[].isin", "full_df[].isin"], "function", ["None"], ["", "def", "load_train_tables", "(", "sl", ",", "pids_val", ")", ":", "\n", "    ", "train_tables", ",", "val_tables", "=", "{", "}", ",", "{", "}", "\n", "for", "table", "in", "TABLES", ":", "\n", "        ", "print", "(", "'Loading %s.%s ...'", "%", "(", "sl", ",", "table", ")", ")", "\n", "full_df", "=", "pd", ".", "read_csv", "(", "'%s/slices/%s/train/%s.csv'", "%", "(", "DATADIR", ",", "sl", ",", "table", ")", ",", "low_memory", "=", "False", ")", "\n", "train_tables", "[", "table", "]", "=", "full_df", "[", "~", "full_df", "[", "'SUBJECT_ID'", "]", ".", "isin", "(", "pids_val", ")", "]", "\n", "val_tables", "[", "table", "]", "=", "full_df", "[", "full_df", "[", "'SUBJECT_ID'", "]", ".", "isin", "(", "pids_val", ")", "]", "\n", "", "return", "train_tables", ",", "val_tables", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.load_test_tables": [[59, 66], ["pandas.read_csv"], "function", ["None"], ["", "def", "load_test_tables", "(", "SLICES", ")", ":", "\n", "    ", "test_tables", "=", "{", "}", "\n", "for", "s", "in", "SLICES", ":", "\n", "        ", "test_tables", "[", "s", "]", "=", "{", "}", "\n", "for", "t", "in", "TABLES", ":", "\n", "            ", "test_tables", "[", "s", "]", "[", "t", "]", "=", "pd", ".", "read_csv", "(", "'%s/slices/%s/test/%s.csv'", "%", "(", "DATADIR", ",", "s", ",", "t", ")", ",", "low_memory", "=", "False", ")", "\n", "", "", "return", "test_tables", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.calc_vocab": [[67, 81], ["set", "print", "[].unique", "print", "print", "[].unique", "print", "print", "[].unique", "print", "len", "len", "len", "float", "set", "set", "set"], "function", ["None"], ["", "def", "calc_vocab", "(", "tables", ")", ":", "\n", "    ", "na", "=", "set", "(", "[", "np", ".", "nan", ",", "float", "(", "'nan'", ")", "]", ")", "\n", "print", "(", "'Calculating LOINC vocab ...'", ")", "\n", "lx", "=", "tables", "[", "'LABEVENTS'", "]", "[", "'LOINC_CODE'", "]", ".", "unique", "(", ")", "\n", "print", "(", "'LOINC vocab size:'", ",", "len", "(", "lx", ")", ")", "\n", "print", "(", "'Calculating CHARTS vocab ...'", ")", "\n", "cx", "=", "tables", "[", "'CHARTEVENTS'", "]", "[", "'ITEMID'", "]", ".", "unique", "(", ")", "\n", "print", "(", "'CHARTS vocab size:'", ",", "len", "(", "cx", ")", ")", "\n", "print", "(", "'Calculating RX vocab ...'", ")", "\n", "rx", "=", "tables", "[", "'PRESCRIPTIONS'", "]", "[", "'RXCUI'", "]", ".", "unique", "(", ")", "\n", "print", "(", "'RX vocab size:'", ",", "len", "(", "rx", ")", ")", "\n", "return", "{", "'LABEVENTS'", ":", "set", "(", "lx", ")", "-", "na", ",", "\n", "'CHARTEVENTS'", ":", "set", "(", "cx", ")", "-", "na", ",", "\n", "'PRESCRIPTIONS'", ":", "set", "(", "rx", ")", "-", "na", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.to_date": [[82, 86], ["pandas.to_datetime"], "function", ["None"], ["", "def", "to_date", "(", "df", ",", "cols", ")", ":", "\n", "    ", "for", "col", "in", "cols", ":", "\n", "        ", "df", "[", "col", "]", "=", "pd", ".", "to_datetime", "(", "df", "[", "col", "]", ")", "\n", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.process_patients": [[98, 108], ["feat_seqex.to_date", "to_date.iterrows", "str", "row[].timestamp", "feat_seqex.PatInfo", "pandas.Timestamp().timestamp", "pandas.Timestamp"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.to_date"], ["", "", "def", "process_patients", "(", "tables", ",", "d", ")", ":", "\n", "    ", "pats", "=", "to_date", "(", "tables", "[", "'PATIENTS'", "]", ",", "[", "'DOB'", "]", ")", "\n", "for", "i", ",", "row", "in", "pats", ".", "iterrows", "(", ")", ":", "\n", "        ", "pid", "=", "str", "(", "row", "[", "'SUBJECT_ID'", "]", ")", "\n", "gender", "=", "\"female\"", "if", "row", "[", "'GENDER'", "]", "==", "'F'", "else", "\"male\"", "\n", "dob", "=", "row", "[", "'DOB'", "]", ".", "timestamp", "(", ")", "\n", "if", "dob", "<", "pd", ".", "Timestamp", "(", "1900", ",", "1", ",", "1", ")", ".", "timestamp", "(", ")", ":", "\n", "            ", "dob", "+=", "(", "300", "-", "89", ")", "*", "(", "365.25", "*", "24", "*", "3600", ")", "\n", "", "d", "[", "pid", "]", "=", "PatInfo", "(", "dob", "=", "dob", ",", "pid", "=", "pid", ",", "gender", "=", "gender", ")", "\n", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.process_admissions": [[109, 117], ["feat_seqex.to_date", "to_date.iterrows", "str", "str", "row[].timestamp"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.to_date"], ["", "def", "process_admissions", "(", "tables", ",", "d", ")", ":", "\n", "    ", "adms", "=", "to_date", "(", "tables", "[", "'ADMISSIONS'", "]", ",", "[", "'ADMITTIME'", "]", ")", "\n", "for", "i", ",", "row", "in", "adms", ".", "iterrows", "(", ")", ":", "\n", "        ", "pid", "=", "str", "(", "row", "[", "'SUBJECT_ID'", "]", ")", "\n", "pi", "=", "d", "[", "pid", "]", "\n", "pi", ".", "enc", "=", "str", "(", "row", "[", "'HADM_ID'", "]", ")", "\n", "pi", ".", "timestamp", "=", "row", "[", "'ADMITTIME'", "]", ".", "timestamp", "(", ")", "+", "HOURS_24", "\n", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.process_ioevents": [[118, 131], ["feat_seqex.to_date", "to_date.iterrows", "str", "row[].timestamp"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.to_date"], ["", "def", "process_ioevents", "(", "tables", ",", "d", ",", "tname", ")", ":", "\n", "    ", "inp", "=", "to_date", "(", "tables", "[", "tname", "]", ",", "[", "'CHARTTIME'", "]", ")", "\n", "for", "i", ",", "row", "in", "inp", ".", "iterrows", "(", ")", ":", "\n", "        ", "pid", "=", "str", "(", "row", "[", "'SUBJECT_ID'", "]", ")", "\n", "unit", "=", "row", "[", "'AMOUNTUOM'", "]", "\n", "val", "=", "row", "[", "'AMOUNT'", "]", "\n", "ts", "=", "row", "[", "'CHARTTIME'", "]", ".", "timestamp", "(", ")", "\n", "\n", "if", "val", "!=", "'ml'", ":", "\n", "            ", "continue", "\n", "", "pi", "=", "d", "[", "pid", "]", "\n", "pi", ".", "seqs", "[", "tname", "]", "[", "ts", "]", "+=", "val", "\n", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.process_codes": [[132, 147], ["feat_seqex.to_date", "to_date.iterrows", "str", "row[].timestamp", "[].append", "type"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.to_date"], ["", "def", "process_codes", "(", "tables", ",", "d", ",", "tname", ",", "cname", ",", "dname", ",", "fname", "=", "None", ")", ":", "\n", "    ", "labs", "=", "to_date", "(", "tables", "[", "tname", "]", ",", "[", "dname", "]", ")", "\n", "for", "i", ",", "row", "in", "labs", ".", "iterrows", "(", ")", ":", "\n", "        ", "pid", "=", "str", "(", "row", "[", "'SUBJECT_ID'", "]", ")", "\n", "code", "=", "row", "[", "cname", "]", "\n", "if", "fname", ":", "\n", "            ", "flg", "=", "row", "[", "fname", "]", "\n", "if", "type", "(", "flg", ")", "==", "str", ":", "\n", "                ", "code", "=", "code", "+", "'_'", "+", "flg", "\n", "", "", "ts", "=", "row", "[", "dname", "]", ".", "timestamp", "(", ")", "\n", "\n", "pi", "=", "d", "[", "pid", "]", "\n", "pi", ".", "seqs", "[", "tname", "]", "[", "ts", "]", ".", "append", "(", "code", ")", "\n", "\n", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.process_labels": [[148, 162], ["tables[].iterrows", "str", "int", "int", "int"], "function", ["None"], ["", "def", "process_labels", "(", "tables", ",", "d", ")", ":", "\n", "    ", "for", "i", ",", "row", "in", "tables", "[", "'LABELS'", "]", ".", "iterrows", "(", ")", ":", "\n", "        ", "pid", "=", "str", "(", "row", "[", "'SUBJECT_ID'", "]", ")", "\n", "\n", "mort", "=", "int", "(", "row", "[", "'HOSPITAL_EXPIRE_FLAG'", "]", ")", "\n", "los3", "=", "int", "(", "row", "[", "'REMAINING_LOS_3'", "]", ")", "\n", "los7", "=", "int", "(", "row", "[", "'REMAINING_LOS_7'", "]", ")", "\n", "\n", "pi", "=", "d", "[", "pid", "]", "\n", "pi", ".", "labels_mortality", "=", "mort", "\n", "pi", ".", "labels_los3", "=", "los3", "\n", "pi", ".", "labels_los7", "=", "los7", "\n", "\n", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.tables_to_dict": [[163, 176], ["feat_seqex.process_patients", "feat_seqex.process_admissions", "feat_seqex.process_ioevents", "feat_seqex.process_ioevents", "feat_seqex.process_codes", "feat_seqex.process_codes", "feat_seqex.process_codes", "feat_seqex.process_labels"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.process_patients", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.process_admissions", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.process_ioevents", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.process_ioevents", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.process_codes", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.process_codes", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.process_codes", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.process_labels"], ["", "def", "tables_to_dict", "(", "tables", ")", ":", "\n", "    ", "d", "=", "{", "}", "\n", "\n", "process_patients", "(", "tables", ",", "d", ")", "\n", "process_admissions", "(", "tables", ",", "d", ")", "\n", "process_ioevents", "(", "tables", ",", "d", ",", "'INPUTEVENTS'", ")", "\n", "process_ioevents", "(", "tables", ",", "d", ",", "'OUTPUTEVENTS'", ")", "\n", "process_codes", "(", "tables", ",", "d", ",", "'LABEVENTS'", ",", "'LOINC_CODE'", ",", "'CHARTTIME'", ",", "'FLAG'", ")", "\n", "process_codes", "(", "tables", ",", "d", ",", "'CHARTEVENTS'", ",", "'ITEMID'", ",", "'CHARTTIME'", ")", "\n", "process_codes", "(", "tables", ",", "d", ",", "'PRESCRIPTIONS'", ",", "'RXCUI'", ",", "'STARTDATE'", ")", "\n", "process_labels", "(", "tables", ",", "d", ")", "\n", "\n", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.dict_to_seqex_list": [[177, 223], ["d.values", "tensorflow.train.SequenceExample", "tf.train.SequenceExample.context.feature[].bytes_list.value.append", "tf.train.SequenceExample.context.feature[].int64_list.value.append", "tf.train.SequenceExample.context.feature[].int64_list.value.append", "tf.train.SequenceExample.context.feature[].bytes_list.value.append", "tf.train.SequenceExample.context.feature[].int64_list.value.append", "sorted", "tf.train.SequenceExample.context.feature[].int64_list.value.append", "seqex_list.append", "str().encode", "int", "int", "pi.gender.encode", "int", "tf.train.SequenceExample.context.feature[].bytes_list.value.append", "tf.train.SequenceExample.context.feature[].bytes_list.value.append", "tf.train.SequenceExample.context.feature[].bytes_list.value.append", "set", "len", "len", "tf.train.SequenceExample.feature_lists.feature_list[].feature.add().int64_list.value.append", "tf.train.SequenceExample.feature_lists.feature_list[].feature.add().int64_list.value.append", "int", "int", "tf.train.SequenceExample.feature_lists.feature_list[].feature.add", "str", "pi.seqs.values", "v.keys", "sum", "seq.feature_lists.feature_list[].feature.add.float_list.value.append", "seq.feature_lists.feature_list[].feature.add.float_list.value.append", "seq.feature_lists.feature_list[].feature.add.float_list.value.remove", "seq.feature_lists.feature_list[].feature.add.bytes_list.value.append", "seq.feature_lists.feature_list[].feature.add.bytes_list.value.remove", "tf.train.SequenceExample.feature_lists.feature_list[].feature.add", "tf.train.SequenceExample.feature_lists.feature_list[].feature.add", "seq.feature_lists.feature_list[].feature.add.bytes_list.value.append", "str().encode", "str"], "function", ["None"], ["", "def", "dict_to_seqex_list", "(", "d", ")", ":", "\n", "    ", "seqex_list", "=", "[", "]", "\n", "for", "pi", "in", "d", ".", "values", "(", ")", ":", "\n", "        ", "seq", "=", "tf", ".", "train", ".", "SequenceExample", "(", ")", "\n", "seq", ".", "context", ".", "feature", "[", "'patientId'", "]", ".", "bytes_list", ".", "value", ".", "append", "(", "str", "(", "pi", ".", "pid", ")", ".", "encode", "(", "'utf8'", ")", ")", "\n", "seq", ".", "context", ".", "feature", "[", "'currentEncounterId'", "]", ".", "int64_list", ".", "value", ".", "append", "(", "int", "(", "pi", ".", "enc", ")", ")", "\n", "seq", ".", "context", ".", "feature", "[", "'Patient.birthDate'", "]", ".", "int64_list", ".", "value", ".", "append", "(", "int", "(", "pi", ".", "dob", ")", ")", "\n", "seq", ".", "context", ".", "feature", "[", "'Patient.gender'", "]", ".", "bytes_list", ".", "value", ".", "append", "(", "pi", ".", "gender", ".", "encode", "(", "'utf8'", ")", ")", "\n", "seq", ".", "context", ".", "feature", "[", "'timestamp'", "]", ".", "int64_list", ".", "value", ".", "append", "(", "int", "(", "pi", ".", "timestamp", ")", ")", "\n", "seq", ".", "context", ".", "feature", "[", "'label.in_hospital_death.class'", "]", "\n", "if", "pi", ".", "labels_mortality", ":", "\n", "            ", "seq", ".", "context", ".", "feature", "[", "'label.in_hospital_death.class'", "]", ".", "bytes_list", ".", "value", ".", "append", "(", "'expired'", ".", "encode", "(", "'utf8'", ")", ")", "\n", "\n", "", "seq", ".", "context", ".", "feature", "[", "'label.length_of_stay_3plus.class'", "]", "\n", "if", "pi", ".", "labels_los3", ":", "\n", "            ", "seq", ".", "context", ".", "feature", "[", "'label.length_of_stay_3plus.class'", "]", ".", "bytes_list", ".", "value", ".", "append", "(", "'positive'", ".", "encode", "(", "'utf8'", ")", ")", "\n", "\n", "", "seq", ".", "context", ".", "feature", "[", "'label.length_of_stay_7plus.class'", "]", "\n", "if", "pi", ".", "labels_los7", ":", "\n", "            ", "seq", ".", "context", ".", "feature", "[", "'label.length_of_stay_7plus.class'", "]", ".", "bytes_list", ".", "value", ".", "append", "(", "'positive'", ".", "encode", "(", "'utf8'", ")", ")", "\n", "\n", "", "unique_ts", "=", "sorted", "(", "set", "(", "[", "ts", "for", "v", "in", "pi", ".", "seqs", ".", "values", "(", ")", "for", "ts", "in", "v", ".", "keys", "(", ")", "]", ")", ")", "\n", "if", "len", "(", "unique_ts", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "", "seq", ".", "context", ".", "feature", "[", "'sequenceLength'", "]", ".", "int64_list", ".", "value", ".", "append", "(", "len", "(", "unique_ts", ")", ")", "\n", "for", "ts", "in", "unique_ts", ":", "\n", "            ", "seq", ".", "feature_lists", ".", "feature_list", "[", "'deltaTime'", "]", ".", "feature", ".", "add", "(", ")", ".", "int64_list", ".", "value", ".", "append", "(", "int", "(", "pi", ".", "timestamp", "-", "ts", ")", ")", "\n", "seq", ".", "feature_lists", ".", "feature_list", "[", "'eventId'", "]", ".", "feature", ".", "add", "(", ")", ".", "int64_list", ".", "value", ".", "append", "(", "int", "(", "ts", ")", ")", "\n", "for", "ct", "in", "CODE_TABLES", ":", "\n", "                ", "feat", "=", "seq", ".", "feature_lists", ".", "feature_list", "[", "ct", "]", ".", "feature", ".", "add", "(", ")", "\n", "if", "ts", "in", "pi", ".", "seqs", "[", "ct", "]", ":", "\n", "                    ", "if", "ct", "in", "[", "'INPUTEVENTS'", ",", "'OUTPUTEVENTS'", "]", ":", "\n", "                        ", "val", "=", "sum", "(", "pi", ".", "seqs", "[", "ct", "]", "[", "ts", "]", ")", "\n", "feat", ".", "float_list", ".", "value", ".", "append", "(", "val", ")", "\n", "", "else", ":", "\n", "                        ", "for", "code", "in", "pi", ".", "seqs", "[", "ct", "]", "[", "ts", "]", ":", "\n", "                            ", "feat", ".", "bytes_list", ".", "value", ".", "append", "(", "str", "(", "code", ")", ".", "encode", "(", "'utf8'", ")", ")", "\n", "", "", "", "else", ":", "\n", "                    ", "if", "ct", "in", "[", "'INPUTEVENTS'", ",", "'OUTPUTEVENTS'", "]", ":", "\n", "                        ", "feat", ".", "float_list", ".", "value", ".", "append", "(", "0.", ")", "\n", "feat", ".", "float_list", ".", "value", ".", "remove", "(", "0.", ")", "\n", "", "else", ":", "\n", "                        ", "feat", ".", "bytes_list", ".", "value", ".", "append", "(", "b''", ")", "\n", "feat", ".", "bytes_list", ".", "value", ".", "remove", "(", "b''", ")", "\n", "", "", "", "", "seqex_list", ".", "append", "(", "seq", ")", "\n", "", "return", "seqex_list", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.dump_seqex_list": [[225, 236], ["print", "tensorflow.io.TFRecordWriter", "enumerate", "writer.write", "seqex.SerializeToString"], "function", ["None"], ["", "def", "dump_seqex_list", "(", "seqex_list", ",", "filename", ")", ":", "\n", "    ", "print", "(", "'Dumping to %s ...'", "%", "filename", ")", "\n", "\n", "with", "tf", ".", "io", ".", "TFRecordWriter", "(", "filename", ")", "as", "writer", ":", "\n", "        ", "for", "i", ",", "seqex", "in", "enumerate", "(", "seqex_list", ")", ":", "\n", "            ", "patient_id", "=", "seqex", ".", "context", ".", "feature", "[", "'patientId'", "]", ".", "bytes_list", ".", "value", "[", "0", "]", "\n", "encounter_id", "=", "seqex", ".", "context", ".", "feature", "[", "'currentEncounterId'", "]", ".", "int64_list", ".", "value", "[", "0", "]", "\n", "seq_length", "=", "seqex", ".", "context", ".", "feature", "[", "'sequenceLength'", "]", ".", "int64_list", ".", "value", "[", "0", "]", "\n", "#key = 'Pos-%05d/PatientID-%s/%d/EncounterID-%s' % (i, str(patient_id), seq_length, (encounter_id))", "\n", "writer", ".", "write", "(", "seqex", ".", "SerializeToString", "(", ")", ")", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.dump_vocab": [[237, 270], ["collections.defaultdict", "enumerate", "collections.defaultdict.items", "tensorflow.io.gfile.GFile", "collections.defaultdict.items", "seq.context.feature.items", "seq.feature_lists.feature_list.items", "tensorflow.io.gfile.GFile", "tf.io.gfile.GFile.write", "tf.io.gfile.GFile.write", "vocab[].add", "vocab[].add", "val.decode", "len"], "function", ["None"], ["", "def", "dump_vocab", "(", "seqex_list", ",", "sl", ")", ":", "\n", "    ", "vocab", "=", "defaultdict", "(", "set", ")", "\n", "for", "i", ",", "seq", "in", "enumerate", "(", "seqex_list", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "seq", ".", "context", ".", "feature", ".", "items", "(", ")", ":", "\n", "            ", "for", "b", "in", "v", ".", "bytes_list", ".", "value", ":", "\n", "                ", "vocab", "[", "k", "]", ".", "add", "(", "b", ")", "\n", "", "", "for", "k", ",", "vs", "in", "seq", ".", "feature_lists", ".", "feature_list", ".", "items", "(", ")", ":", "\n", "            ", "for", "v", "in", "vs", ".", "feature", ":", "\n", "                ", "for", "b", "in", "v", ".", "bytes_list", ".", "value", ":", "\n", "                    ", "vocab", "[", "k", "]", ".", "add", "(", "b", ")", "\n", "\n", "", "", "", "", "for", "key", ",", "vals", "in", "vocab", ".", "items", "(", ")", ":", "\n", "        ", "fd", "=", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "'%s/seqex/%s/VOCAB/%s.txt'", "%", "(", "DATADIR", ",", "sl", ",", "key", ")", ",", "'w'", ")", "\n", "for", "val", "in", "vals", ":", "\n", "            ", "fd", ".", "write", "(", "val", ".", "decode", "(", ")", "+", "'\\n'", ")", "\n", "\n", "", "", "fd", "=", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "'%s/seqex/%s/VOCAB/EmbedConfigFile.pbtxt'", "%", "(", "DATADIR", ",", "sl", ")", ",", "'w'", ")", "\n", "for", "k", ",", "vals", "in", "vocab", ".", "items", "(", ")", ":", "\n", "        ", "rec", "=", "\"\"\"\nfeatures {\n  key: \"%s\"\n  value: {\n    vocabulary {\n      filename: \"%s.txt\"\n      vocabulary_size: %d\n    }\n    num_oov_buckets: 1\n    embedding_dimension: %d\n  }\n}\n\"\"\"", "\n", "fd", ".", "write", "(", "rec", "%", "(", "k", ",", "k", ",", "len", "(", "vals", ")", ",", "32", ")", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.dump_seqex": [[271, 283], ["print", "feat_seqex.tables_to_dict", "print", "feat_seqex.dict_to_seqex_list", "feat_seqex.dump_seqex_list", "feat_seqex.dump_vocab"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.tables_to_dict", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.dict_to_seqex_list", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.dump_seqex_list", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.dump_vocab"], ["", "def", "dump_seqex", "(", "sl", ",", "train_tables", ",", "val_tables", ",", "test_tables", ")", ":", "\n", "    ", "for", "name", ",", "tables", "in", "[", "(", "'train'", ",", "train_tables", ")", ",", "(", "'validation'", ",", "val_tables", ")", ",", "(", "'test'", ",", "test_tables", ")", "]", ":", "\n", "        ", "print", "(", "'[%s=%s] Creating dict ...'", "%", "(", "name", ",", "sl", ")", ")", "\n", "d", "=", "tables_to_dict", "(", "tables", ")", "\n", "print", "(", "'[%s=%s] Creating SeqEx list ...'", "%", "(", "name", ",", "sl", ")", ")", "\n", "seqex_list", "=", "dict_to_seqex_list", "(", "d", ")", "\n", "\n", "dump_seqex_list", "(", "seqex_list", ",", "'%s/seqex/%s/%s-00000-of-00001'", "%", "(", "DATADIR", ",", "sl", ",", "name", ")", ")", "\n", "if", "name", "==", "'train'", ":", "\n", "          ", "dump_vocab", "(", "seqex_list", ",", "sl", ")", "\n", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.featurize": [[284, 297], ["print", "tensorflow.io.gfile.makedirs", "feat_seqex.val_pids", "feat_seqex.load_train_tables", "feat_seqex.load_test_tables", "feat_seqex.dump_seqex"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.val_pids", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.load_train_tables", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.load_test_tables", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.dump_seqex"], ["", "def", "featurize", "(", "sl", ",", "SLICES", ")", ":", "\n", "    ", "print", "(", "'SeqExing %s'", "%", "sl", ")", "\n", "\n", "tf", ".", "io", ".", "gfile", ".", "makedirs", "(", "'%s/seqex/%s/VOCAB'", "%", "(", "DATADIR", ",", "sl", ")", ")", "\n", "\n", "pids_val", "=", "val_pids", "(", "sl", ")", "\n", "\n", "train_tables", ",", "val_tables", "=", "load_train_tables", "(", "sl", ",", "pids_val", ")", "\n", "\n", "test_tables", "=", "load_test_tables", "(", "SLICES", ")", "\n", "\n", "dump_seqex", "(", "sl", ",", "train_tables", ",", "val_tables", ",", "test_tables", "[", "sl", "]", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_seqex.main": [[298, 303], ["feat_seqex.featurize"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.featurize"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "for", "SLICES", "in", "SLICE_SETS", ":", "\n", "        ", "for", "sl", "in", "SLICES", ":", "\n", "            ", "featurize", "(", "sl", ",", "SLICES", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.config_get": [[24, 26], ["json.load", "open", "os.path.join"], "function", ["None"], ["def", "config_get", "(", "name", ")", ":", "\n", "    ", "return", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "FILEDIR", ",", "CONFIG_JSON", ")", ")", ")", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.val_pids": [[33, 40], ["os.path.join", "pandas.read_csv", "list", "numpy.random.shuffle", "set", "int", "len"], "function", ["None"], ["def", "val_pids", "(", "sl", ")", ":", "\n", "    ", "csv_file", "=", "os", ".", "path", ".", "join", "(", "DATADIR", ",", "'slices'", ",", "sl", ",", "'train'", ",", "'PATIENTS.csv'", ")", "\n", "pat_df", "=", "pd", ".", "read_csv", "(", "csv_file", ",", "low_memory", "=", "False", ",", "parse_dates", "=", "[", "'DOB'", "]", ")", "\n", "pids_all", "=", "list", "(", "pat_df", "[", "'SUBJECT_ID'", "]", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "pids_all", ")", "\n", "pids_val", "=", "set", "(", "pids_all", "[", ":", "int", "(", "len", "(", "pids_all", ")", "*", "0.2", ")", "]", ")", "\n", "return", "pids_val", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.load_train_tables": [[41, 50], ["print", "os.path.join", "pandas.read_csv", "full_df[].isin", "full_df[].isin"], "function", ["None"], ["", "def", "load_train_tables", "(", "sl", ",", "pids_val", ")", ":", "\n", "    ", "train_tables", ",", "val_tables", "=", "{", "}", ",", "{", "}", "\n", "for", "table", "in", "TABLES", ":", "\n", "        ", "print", "(", "'Loading %s.%s ...'", "%", "(", "sl", ",", "table", ")", ")", "\n", "csv_file", "=", "os", ".", "path", ".", "join", "(", "DATADIR", ",", "'slices'", ",", "sl", ",", "'train'", ",", "table", "+", "'.csv'", ")", "\n", "full_df", "=", "pd", ".", "read_csv", "(", "csv_file", ",", "low_memory", "=", "False", ")", "\n", "train_tables", "[", "table", "]", "=", "full_df", "[", "~", "full_df", "[", "'SUBJECT_ID'", "]", ".", "isin", "(", "pids_val", ")", "]", "\n", "val_tables", "[", "table", "]", "=", "full_df", "[", "full_df", "[", "'SUBJECT_ID'", "]", ".", "isin", "(", "pids_val", ")", "]", "\n", "", "return", "train_tables", ",", "val_tables", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.load_test_tables": [[51, 59], ["os.path.join", "pandas.read_csv"], "function", ["None"], ["", "def", "load_test_tables", "(", "SLICES", ")", ":", "\n", "    ", "test_tables", "=", "{", "}", "\n", "for", "s", "in", "SLICES", ":", "\n", "        ", "test_tables", "[", "s", "]", "=", "{", "}", "\n", "for", "t", "in", "TABLES", ":", "\n", "            ", "csv_file", "=", "os", ".", "path", ".", "join", "(", "DATADIR", ",", "'slices'", ",", "s", ",", "'test'", ",", "t", "+", "'.csv'", ")", "\n", "test_tables", "[", "s", "]", "[", "t", "]", "=", "pd", ".", "read_csv", "(", "csv_file", ",", "low_memory", "=", "False", ")", "\n", "", "", "return", "test_tables", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.calc_vocab": [[60, 74], ["set", "print", "[].unique", "print", "print", "[].unique", "print", "print", "[].unique", "print", "len", "len", "len", "float", "set", "set", "set"], "function", ["None"], ["", "def", "calc_vocab", "(", "tables", ")", ":", "\n", "    ", "na", "=", "set", "(", "[", "np", ".", "nan", ",", "float", "(", "'nan'", ")", "]", ")", "\n", "print", "(", "'Calculating LOINC vocab ...'", ")", "\n", "lx", "=", "tables", "[", "'LABEVENTS'", "]", "[", "'LOINC_CODE'", "]", ".", "unique", "(", ")", "\n", "print", "(", "'LOINC vocab size:'", ",", "len", "(", "lx", ")", ")", "\n", "print", "(", "'Calculating CHARTS vocab ...'", ")", "\n", "cx", "=", "tables", "[", "'CHARTEVENTS'", "]", "[", "'ITEMID'", "]", ".", "unique", "(", ")", "\n", "print", "(", "'CHARTS vocab size:'", ",", "len", "(", "cx", ")", ")", "\n", "print", "(", "'Calculating RX vocab ...'", ")", "\n", "rx", "=", "tables", "[", "'PRESCRIPTIONS'", "]", "[", "'RXCUI'", "]", ".", "unique", "(", ")", "\n", "print", "(", "'RX vocab size:'", ",", "len", "(", "rx", ")", ")", "\n", "return", "{", "'LABEVENTS'", ":", "set", "(", "lx", ")", "-", "na", ",", "\n", "'CHARTEVENTS'", ":", "set", "(", "cx", ")", "-", "na", ",", "\n", "'PRESCRIPTIONS'", ":", "set", "(", "rx", ")", "-", "na", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.vols": [[75, 77], ["[].groupby().sum", "[].groupby", "table.query"], "function", ["None"], ["", "def", "vols", "(", "table", ",", "unit", ")", ":", "\n", "    ", "return", "table", ".", "query", "(", "'AMOUNTUOM == \"%s\"'", "%", "unit", ")", "[", "[", "'SUBJECT_ID'", ",", "'AMOUNT'", "]", "]", ".", "groupby", "(", "'SUBJECT_ID'", ")", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.to_date": [[78, 82], ["pandas.to_datetime"], "function", ["None"], ["", "def", "to_date", "(", "df", ",", "cols", ")", ":", "\n", "    ", "for", "col", "in", "cols", ":", "\n", "        ", "df", "[", "col", "]", "=", "pd", ".", "to_datetime", "(", "df", "[", "col", "]", ")", "\n", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.get_inout": [[83, 95], ["print", "pandas.DataFrame", "feat_fixedlen.vols", "feat_fixedlen.vols", "feat_fixedlen.vols", "feat_fixedlen.vols", "numpy.zeros", "len"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.vols", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.vols", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.vols", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.vols"], ["", "def", "get_inout", "(", "pids", ",", "tables", ")", ":", "\n", "    ", "print", "(", "'Loading {IN,OUT}PUTEVENTS into matrix ...'", ")", "\n", "df", "=", "pd", ".", "DataFrame", "(", "np", ".", "zeros", "(", "(", "len", "(", "pids", ")", ",", "4", ")", ")", ",", "columns", "=", "[", "'INP_ML'", ",", "'INP_MG'", ",", "'OUT_ML'", ",", "'OUT_MG'", "]", ")", "\n", "ix_ml", "=", "vols", "(", "tables", "[", "'INPUTEVENTS'", "]", ",", "'ml'", ")", "\n", "ix_mg", "=", "vols", "(", "tables", "[", "'INPUTEVENTS'", "]", ",", "'mg'", ")", "\n", "ox_ml", "=", "vols", "(", "tables", "[", "'OUTPUTEVENTS'", "]", ",", "'ml'", ")", "\n", "ox_mg", "=", "vols", "(", "tables", "[", "'OUTPUTEVENTS'", "]", ",", "'mg'", ")", "\n", "df", "[", "'INP_ML'", "]", "=", "ix_ml", "[", "'AMOUNT'", "]", "\n", "df", "[", "'INP_MG'", "]", "=", "ix_mg", "[", "'AMOUNT'", "]", "\n", "df", "[", "'OUT_ML'", "]", "=", "ox_ml", "[", "'AMOUNT'", "]", "\n", "df", "[", "'OUT_MG'", "]", "=", "ox_mg", "[", "'AMOUNT'", "]", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.get_demographics": [[96, 110], ["print", "pandas.DataFrame", "df.set_index.set_index", "patients.merge", "join.set_index.set_index", "feat_fixedlen.to_date", "numpy.zeros", "len", "join[].astype", "join[].astype"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.to_date"], ["", "def", "get_demographics", "(", "pids", ",", "tables", ")", ":", "\n", "    ", "print", "(", "'Loading demographics into matrix ...'", ")", "\n", "df", "=", "pd", ".", "DataFrame", "(", "np", ".", "zeros", "(", "(", "len", "(", "pids", ")", ",", "2", ")", ")", ",", "columns", "=", "[", "'AGE'", ",", "'GENDER'", "]", ")", "\n", "df", "=", "df", ".", "set_index", "(", "pids", ")", "\n", "patients", ",", "admissions", "=", "tables", "[", "'PATIENTS'", "]", ",", "tables", "[", "'ADMISSIONS'", "]", "[", "[", "'SUBJECT_ID'", ",", "'ADMITTIME'", "]", "]", "\n", "join", "=", "patients", ".", "merge", "(", "admissions", ",", "on", "=", "'SUBJECT_ID'", ")", "\n", "join", "=", "join", ".", "set_index", "(", "'SUBJECT_ID'", ")", "\n", "to_date", "(", "join", ",", "[", "'DOB'", ",", "'ADMITTIME'", "]", ")", "\n", "NANO", "=", "10", "**", "9", "\n", "SECS_PER_100YEAR", "=", "3600", "*", "24", "*", "365.25", "*", "100", "\n", "df", "[", "'AGE'", "]", "=", "(", "join", "[", "'ADMITTIME'", "]", ".", "astype", "(", "np", ".", "int64", ")", "/", "NANO", "-", "join", "[", "'DOB'", "]", ".", "astype", "(", "np", ".", "int64", ")", "/", "NANO", ")", "/", "SECS_PER_100YEAR", "\n", "df", "[", "'AGE'", "]", "[", "df", "[", "'AGE'", "]", ">", "300", "]", "-=", "(", "300", "-", "89", ")", "# see https://mimic.physionet.org/mimictables/patients/", "\n", "df", "[", "'GENDER'", "]", "=", "(", "patients", "[", "'GENDER'", "]", "==", "'F'", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.get_labs": [[111, 123], ["print", "numpy.zeros", "tables[].iterrows", "pandas.DataFrame", "enumerate", "enumerate", "len", "len", "list", "loinc.keys"], "function", ["None"], ["", "def", "get_labs", "(", "pids", ",", "tables", ",", "vocab", ")", ":", "\n", "    ", "print", "(", "'Loading LABEVENTS into matrix ...'", ")", "\n", "loinc", "=", "{", "l", ":", "i", "for", "i", ",", "l", "in", "enumerate", "(", "vocab", "[", "'LABEVENTS'", "]", ")", "}", "\n", "pid", "=", "{", "p", ":", "i", "for", "i", ",", "p", "in", "enumerate", "(", "pids", ")", "}", "\n", "data", "=", "np", ".", "zeros", "(", "(", "len", "(", "pid", ")", ",", "len", "(", "loinc", ")", ")", ")", "\n", "for", "_", ",", "row", "in", "tables", "[", "'LABEVENTS'", "]", ".", "iterrows", "(", ")", ":", "\n", "        ", "p", "=", "row", "[", "'SUBJECT_ID'", "]", "\n", "c", "=", "row", "[", "'LOINC_CODE'", "]", "\n", "if", "c", "not", "in", "loinc", ":", "\n", "            ", "continue", "\n", "", "data", "[", "pid", "[", "p", "]", ",", "loinc", "[", "c", "]", "]", "+=", "1", "\n", "", "return", "pd", ".", "DataFrame", "(", "data", ",", "index", "=", "pids", ",", "columns", "=", "list", "(", "loinc", ".", "keys", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.get_rx": [[124, 136], ["print", "numpy.zeros", "tables[].iterrows", "pandas.DataFrame", "enumerate", "enumerate", "len", "len", "list", "rxcui.keys"], "function", ["None"], ["", "def", "get_rx", "(", "pids", ",", "tables", ",", "vocab", ")", ":", "\n", "    ", "print", "(", "'Loading PRESCRIPTIONS into matrix ...'", ")", "\n", "rxcui", "=", "{", "l", ":", "i", "for", "i", ",", "l", "in", "enumerate", "(", "vocab", "[", "'PRESCRIPTIONS'", "]", ")", "}", "\n", "pid", "=", "{", "p", ":", "i", "for", "i", ",", "p", "in", "enumerate", "(", "pids", ")", "}", "\n", "data", "=", "np", ".", "zeros", "(", "(", "len", "(", "pid", ")", ",", "len", "(", "rxcui", ")", ")", ")", "\n", "for", "_", ",", "row", "in", "tables", "[", "'PRESCRIPTIONS'", "]", ".", "iterrows", "(", ")", ":", "\n", "        ", "p", "=", "row", "[", "'SUBJECT_ID'", "]", "\n", "c", "=", "row", "[", "'RXCUI'", "]", "\n", "if", "c", "not", "in", "rxcui", ":", "\n", "            ", "continue", "\n", "", "data", "[", "pid", "[", "p", "]", ",", "rxcui", "[", "c", "]", "]", "+=", "1", "\n", "", "return", "pd", ".", "DataFrame", "(", "data", ",", "index", "=", "pids", ",", "columns", "=", "list", "(", "rxcui", ".", "keys", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.get_charts": [[137, 149], ["print", "numpy.zeros", "tables[].iterrows", "pandas.DataFrame", "enumerate", "enumerate", "len", "len", "list", "itemids.keys"], "function", ["None"], ["", "def", "get_charts", "(", "pids", ",", "tables", ",", "vocab", ")", ":", "\n", "    ", "print", "(", "'Loading CHARTS into matrix ...'", ")", "\n", "itemids", "=", "{", "l", ":", "i", "for", "i", ",", "l", "in", "enumerate", "(", "vocab", "[", "'CHARTEVENTS'", "]", ")", "}", "\n", "pid", "=", "{", "p", ":", "i", "for", "i", ",", "p", "in", "enumerate", "(", "pids", ")", "}", "\n", "data", "=", "np", ".", "zeros", "(", "(", "len", "(", "pid", ")", ",", "len", "(", "itemids", ")", ")", ")", "\n", "for", "_", ",", "row", "in", "tables", "[", "'CHARTEVENTS'", "]", ".", "iterrows", "(", ")", ":", "\n", "        ", "p", "=", "row", "[", "'SUBJECT_ID'", "]", "\n", "c", "=", "row", "[", "'ITEMID'", "]", "\n", "if", "c", "not", "in", "itemids", ":", "\n", "            ", "continue", "\n", "", "data", "[", "pid", "[", "p", "]", ",", "itemids", "[", "c", "]", "]", "+=", "1", "\n", "", "return", "pd", ".", "DataFrame", "(", "data", ",", "index", "=", "pids", ",", "columns", "=", "list", "(", "itemids", ".", "keys", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.dump_XY": [[150, 177], ["tables[].set_index", "feat_fixedlen.get_demographics", "feat_fixedlen.get_inout", "feat_fixedlen.get_labs", "feat_fixedlen.get_charts", "feat_fixedlen.get_rx", "get_demographics.join", "os.path.join", "os.path.join", "demographics.join.to_csv", "Y.to_csv", "sum", "len", "vocab.values"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.get_demographics", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.get_inout", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.get_labs", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.get_charts", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.get_rx"], ["", "def", "dump_XY", "(", "sl", ",", "pfx", ",", "tables", ",", "vocab", ")", ":", "\n", "# Count of rows", "\n", "    ", "M", "=", "tables", "[", "'PATIENTS'", "]", ".", "shape", "[", "0", "]", "\n", "# Count of columns", "\n", "# 2 for demographics (age, gender)", "\n", "# 4 for Input and Output event totals (in ml, mg)", "\n", "# Vocab sizes across rx, lx, cx", "\n", "\n", "N", "=", "2", "+", "4", "+", "sum", "(", "[", "len", "(", "v", ")", "for", "v", "in", "vocab", ".", "values", "(", ")", "]", ")", "\n", "\n", "pats", "=", "tables", "[", "'PATIENTS'", "]", ".", "set_index", "(", "'SUBJECT_ID'", ")", "\n", "pids", "=", "pats", ".", "index", "\n", "\n", "demographics", "=", "get_demographics", "(", "pids", ",", "tables", ")", "\n", "inout", "=", "get_inout", "(", "pids", ",", "tables", ")", "\n", "labs", "=", "get_labs", "(", "pids", ",", "tables", ",", "vocab", ")", "\n", "cx", "=", "get_charts", "(", "pids", ",", "tables", ",", "vocab", ")", "\n", "rx", "=", "get_rx", "(", "pids", ",", "tables", ",", "vocab", ")", "\n", "\n", "X", "=", "demographics", ".", "join", "(", "[", "cx", ",", "inout", ",", "labs", ",", "rx", "]", ")", "\n", "Y", "=", "tables", "[", "'LABELS'", "]", "\n", "\n", "csv_x", "=", "os", ".", "path", ".", "join", "(", "DATADIR", ",", "'fixedlen'", ",", "'train-'", "+", "sl", ",", "pfx", "+", "'_X.csv'", ")", "\n", "csv_y", "=", "os", ".", "path", ".", "join", "(", "DATADIR", ",", "'fixedlen'", ",", "'train-'", "+", "sl", ",", "pfx", "+", "'_Y.csv'", ")", "\n", "X", ".", "to_csv", "(", "csv_x", ")", "\n", "Y", ".", "to_csv", "(", "csv_y", ")", "\n", "return", "X", ",", "Y", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.dump_matrices": [[179, 189], ["feat_fixedlen.calc_vocab", "print", "feat_fixedlen.dump_XY", "print", "feat_fixedlen.dump_XY", "test_tables.items", "print", "feat_fixedlen.dump_XY"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.calc_vocab", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.dump_XY", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.dump_XY", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.dump_XY"], ["", "def", "dump_matrices", "(", "sl", ",", "train_tables", ",", "val_tables", ",", "test_tables", ")", ":", "\n", "    ", "vocab", "=", "calc_vocab", "(", "train_tables", ")", "\n", "print", "(", "'Train=%s'", "%", "sl", ")", "\n", "dump_XY", "(", "sl", ",", "'train'", ",", "train_tables", ",", "vocab", ")", "\n", "print", "(", "'Val=%s'", "%", "sl", ")", "\n", "dump_XY", "(", "sl", ",", "'val'", ",", "val_tables", ",", "vocab", ")", "\n", "for", "name", ",", "tables", "in", "test_tables", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "'Train=%s, Test=%s'", "%", "(", "sl", ",", "name", ")", ")", "\n", "dump_XY", "(", "sl", ",", "'test/%s'", "%", "name", ",", "tables", ",", "vocab", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.featurize": [[190, 202], ["print", "os.makedirs", "os.makedirs", "feat_fixedlen.val_pids", "feat_fixedlen.load_train_tables", "feat_fixedlen.load_test_tables", "feat_fixedlen.dump_matrices"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.val_pids", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.load_train_tables", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.load_test_tables", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.dump_matrices"], ["", "def", "featurize", "(", "sl", ",", "SLICES", ")", ":", "\n", "    ", "print", "(", "'Featurizing %s'", "%", "sl", ")", "\n", "os", ".", "makedirs", "(", "'%s/fixedlen/train-%s'", "%", "(", "DATADIR", ",", "sl", ")", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "'%s/fixedlen/train-%s/test'", "%", "(", "DATADIR", ",", "sl", ")", ",", "exist_ok", "=", "True", ")", "\n", "\n", "pids_val", "=", "val_pids", "(", "sl", ")", "\n", "train_tables", ",", "val_tables", "=", "load_train_tables", "(", "sl", ",", "pids_val", ")", "\n", "\n", "test_tables", "=", "load_test_tables", "(", "SLICES", ")", "\n", "\n", "dump_matrices", "(", "sl", ",", "train_tables", ",", "val_tables", ",", "test_tables", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.main": [[204, 209], ["feat_fixedlen.featurize"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.feat_fixedlen.featurize"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "for", "SLICES", "in", "SLICE_SETS", ":", "\n", "        ", "for", "sl", "in", "SLICES", ":", "\n", "            ", "featurize", "(", "sl", ",", "SLICES", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.models.RandomForest.fit": [[18, 35], ["print", "sklearn.ensemble.RandomForestClassifier", "print", "sklearn.ensemble.RandomForestClassifier.fit", "sklearn.metrics.roc_auc_score", "sklearn.ensemble.RandomForestClassifier.predict_proba"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.models.GP.fit", "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.SNGPDNN.predict_proba"], ["def", "fit", "(", "train_sl", ",", "task", ",", "X", ",", "Y", ",", "Xv", ",", "Yv", ")", ":", "\n", "    ", "best_n", "=", "None", "\n", "best_score", "=", "0", "\n", "best_model", "=", "None", "\n", "for", "n", "in", "[", "10", ",", "50", ",", "100", ",", "500", ",", "1000", ",", "2000", ",", "5000", "]", ":", "\n", "        ", "m", "=", "RF", "(", "n_estimators", "=", "n", ",", "n_jobs", "=", "-", "1", ")", "\n", "print", "(", "'Fitting model with n:'", ",", "n", ")", "\n", "m", ".", "fit", "(", "X", ",", "Y", ")", "\n", "Pv", "=", "m", ".", "predict_proba", "(", "Xv", ")", "[", ":", ",", "1", "]", "\n", "score", "=", "roc_auc_score", "(", "Yv", ",", "Pv", ")", "\n", "if", "score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "score", "\n", "best_model", "=", "m", "\n", "best_n", "=", "n", "\n", "\n", "", "", "print", "(", "'Best n:'", ",", "best_n", ")", "\n", "return", "best_model", "\n", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.GetBest.__init__": [[56, 84], ["tensorflow.keras.callbacks.Callback.__init__", "print", "SNGP.GetBest.monitor.startswith"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__"], ["def", "__init__", "(", "self", ",", "monitor", "=", "'val_loss'", ",", "verbose", "=", "0", ",", "\n", "mode", "=", "'auto'", ",", "period", "=", "1", ")", ":", "\n", "        ", "super", "(", "GetBest", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "monitor", "=", "monitor", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "period", "=", "period", "\n", "self", ".", "best_epochs", "=", "0", "\n", "self", ".", "epochs_since_last_save", "=", "0", "\n", "\n", "if", "mode", "not", "in", "[", "'auto'", ",", "'min'", ",", "'max'", "]", ":", "\n", "            ", "print", "(", "'GetBest mode %s is unknown, '", "\n", "'fallback to auto mode.'", "%", "(", "mode", ")", ",", "\n", "RuntimeWarning", ")", "\n", "mode", "=", "'auto'", "\n", "\n", "", "if", "mode", "==", "'min'", ":", "\n", "            ", "self", ".", "monitor_op", "=", "np", ".", "less", "\n", "self", ".", "best", "=", "np", ".", "Inf", "\n", "", "elif", "mode", "==", "'max'", ":", "\n", "            ", "self", ".", "monitor_op", "=", "np", ".", "greater", "\n", "self", ".", "best", "=", "-", "np", ".", "Inf", "\n", "", "else", ":", "\n", "            ", "if", "'acc'", "in", "self", ".", "monitor", "or", "self", ".", "monitor", ".", "startswith", "(", "'fmeasure'", ")", ":", "\n", "                ", "self", ".", "monitor_op", "=", "np", ".", "greater", "\n", "self", ".", "best", "=", "-", "np", ".", "Inf", "\n", "", "else", ":", "\n", "                ", "self", ".", "monitor_op", "=", "np", ".", "less", "\n", "self", ".", "best", "=", "np", ".", "Inf", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.GetBest.on_train_begin": [[85, 88], ["None"], "methods", ["None"], ["", "", "", "def", "on_train_begin", "(", "self", ",", "logs", "=", "None", ")", ":", "\n", "#self.best_weights = self.model.get_weights()", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.GetBest.on_epoch_end": [[89, 116], ["logs.items", "key.startswith", "print", "SNGP.GetBest.monitor_op", "SNGP.GetBest.model.get_weights", "print", "print"], "methods", ["None"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "logs", "=", "logs", "or", "{", "}", "\n", "self", ".", "epochs_since_last_save", "+=", "1", "\n", "if", "self", ".", "epochs_since_last_save", ">=", "self", ".", "period", ":", "\n", "            ", "self", ".", "epochs_since_last_save", "=", "0", "\n", "#filepath = self.filepath.format(epoch=epoch + 1, **logs)", "\n", "for", "key", ",", "val", "in", "logs", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", ".", "startswith", "(", "self", ".", "monitor", ")", ":", "\n", "                    ", "current", "=", "val", "\n", "break", "\n", "", "", "if", "current", "is", "None", ":", "\n", "                ", "print", "(", "'Can pick best model only with %s available, '", "\n", "'skipping.'", "%", "(", "self", ".", "monitor", ")", ",", "RuntimeWarning", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "monitor_op", "(", "current", ",", "self", ".", "best", ")", ":", "\n", "                    ", "if", "self", ".", "verbose", ">", "1", ":", "\n", "                        ", "print", "(", "'Epoch %05d: %s improved from %0.5f to %0.5f,'", "\n", "' storing weights.'", "\n", "%", "(", "epoch", "+", "1", ",", "self", ".", "monitor", ",", "self", ".", "best", ",", "\n", "current", ")", ")", "\n", "", "self", ".", "best", "=", "current", "\n", "self", ".", "best_epochs", "=", "epoch", "+", "1", "\n", "self", ".", "best_weights", "=", "self", ".", "model", ".", "get_weights", "(", ")", "\n", "", "else", ":", "\n", "                    ", "if", "self", ".", "verbose", ">", "1", ":", "\n", "                        ", "print", "(", "'Epoch %05d: %s did not improve'", "%", "\n", "(", "epoch", "+", "1", ",", "self", ".", "monitor", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.GetBest.on_train_end": [[117, 122], ["SNGP.GetBest.model.set_weights", "print"], "methods", ["None"], ["", "", "", "", "", "def", "on_train_end", "(", "self", ",", "logs", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "verbose", ">", "0", ":", "\n", "            ", "print", "(", "'Using epoch %05d with %s: %0.5f'", "%", "(", "self", ".", "best_epochs", ",", "self", ".", "monitor", ",", "\n", "self", ".", "best", ")", ")", "\n", "", "self", ".", "model", ".", "set_weights", "(", "self", ".", "best_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.SNGPDNN.__init__": [[124, 166], ["super().__init__", "tensorflow.keras.models.Sequential", "tensorflow.keras.layers.Dense", "edward2.layers.RandomFeatureGaussianProcess", "tensorflow.keras.layers.Dense", "GP", "tensorflow.keras.layers.Dense", "edward2.layers.SpectralNormalization", "D", "block", "tensorflow.keras.layers.Activation", "tensorflow.keras.regularizers.l2", "D", "range"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "depth", "=", "8", ",", "\n", "width", "=", "256", ",", "\n", "activation", "=", "'relu'", ",", "\n", "l2", "=", "5e-2", ",", "\n", "gp_input_dim", "=", "128", ",", "\n", "gp_hidden_dim", "=", "1024", ",", "\n", "gp_scale", "=", "2", ",", "\n", "gp_bias", "=", "0", ",", "\n", "gp_input_normalization", "=", "True", ",", "\n", "gp_cov_discount_factor", "=", "0.999", ",", "\n", "gp_cov_ridge_penalty", "=", "1e-3", ",", "\n", "use_spec_norm", "=", "True", ",", "\n", "spec_norm_iteration", "=", "5", ",", "\n", "spec_norm_bound", "=", "0.95", ",", "\n", "use_gp_layer", "=", "True", ")", ":", "\n", "        ", "super", "(", "SNGPDNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "D", "=", "lambda", ":", "Dense", "(", "width", ",", "\n", "activation", "=", "Activation", "(", "activation", ")", ",", "\n", "kernel_regularizer", "=", "tf", ".", "keras", ".", "regularizers", ".", "l2", "(", "l2", ")", ")", "\n", "GP", "=", "lambda", ":", "ed", ".", "layers", ".", "RandomFeatureGaussianProcess", "(", "1", ",", "num_inducing", "=", "gp_hidden_dim", ",", "\n", "gp_kernel_scale", "=", "gp_scale", ",", "\n", "gp_output_bias", "=", "gp_bias", ",", "\n", "normalize_input", "=", "gp_input_normalization", ",", "\n", "gp_cov_momentum", "=", "gp_cov_discount_factor", ",", "\n", "gp_cov_ridge_penalty", "=", "gp_cov_ridge_penalty", ")", "\n", "\n", "block", "=", "lambda", ":", "ed", ".", "layers", ".", "SpectralNormalization", "(", "D", "(", ")", ",", "\n", "iteration", "=", "spec_norm_iteration", ",", "\n", "norm_multiplier", "=", "spec_norm_bound", ")", "if", "use_spec_norm", "else", "D", "(", ")", "\n", "self", ".", "dnn", "=", "Sequential", "(", "[", "block", "(", ")", "for", "_", "in", "range", "(", "depth", ")", "]", ")", "\n", "self", ".", "use_gp_layer", "=", "use_gp_layer", "\n", "if", "use_gp_layer", ":", "\n", "            ", "self", ".", "proj_layer", "=", "Dense", "(", "gp_input_dim", ",", "\n", "kernel_initializer", "=", "'random_normal'", ",", "\n", "use_bias", "=", "False", ",", "\n", "trainable", "=", "False", ")", "\n", "self", ".", "gp_layer", "=", "GP", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "last_layer", "=", "Dense", "(", "1", ")", "\n", "", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.SNGPDNN.call": [[167, 174], ["SNGP.SNGPDNN.dnn", "tensorflow.keras.activations.sigmoid", "SNGP.SNGPDNN.gp_layer", "SNGP.SNGPDNN.last_layer", "SNGP.SNGPDNN.proj_layer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "x", "=", "self", ".", "dnn", "(", "inputs", ")", "\n", "if", "self", ".", "use_gp_layer", ":", "\n", "            ", "logits", ",", "_", "=", "self", ".", "gp_layer", "(", "self", ".", "proj_layer", "(", "x", ")", ")", "\n", "", "else", ":", "\n", "            ", "logits", "=", "self", ".", "last_layer", "(", "x", ")", "\n", "", "return", "tf", ".", "keras", ".", "activations", ".", "sigmoid", "(", "logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.SNGPDNN.predict_proba": [[175, 178], ["SNGP.SNGPDNN.call().numpy", "numpy.append", "SNGP.SNGPDNN.call"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.GraphConvolutionalTransformer.call"], ["", "def", "predict_proba", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "probs", "=", "self", ".", "call", "(", "inputs", ")", ".", "numpy", "(", ")", "\n", "return", "np", ".", "append", "(", "1", "-", "probs", ",", "probs", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.SNGPDNN.fit": [[179, 184], ["super().fit", "SNGP.GetBest", "tensorflow.keras.callbacks.EarlyStopping"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.models.GP.fit"], ["", "def", "fit", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "callbacks", "=", "[", "GetBest", "(", "monitor", "=", "'val_auc'", ",", "verbose", "=", "0", ",", "mode", "=", "'max'", ")", ",", "\n", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "min_delta", "=", "1e-3", ",", "\n", "patience", "=", "5", ",", "verbose", "=", "0", ")", "]", "\n", "return", "super", "(", ")", ".", "fit", "(", "*", "args", ",", "callbacks", "=", "callbacks", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.KerasClassifierLOSS.nll": [[186, 190], ["SNGP.KerasClassifierLOSS.model().numpy().flatten", "numpy.mean", "SNGP.KerasClassifierLOSS.model().numpy", "numpy.log", "numpy.log", "SNGP.KerasClassifierLOSS.model"], "methods", ["None"], ["    ", "def", "nll", "(", "self", ",", "X", ",", "Y", ")", ":", "\n", "        ", "probs", "=", "self", ".", "model", "(", "X", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "loss", "=", "Y", "*", "np", ".", "log", "(", "probs", ")", "+", "(", "1", "-", "Y", ")", "*", "np", ".", "log", "(", "1", "-", "probs", ")", "\n", "return", "-", "np", ".", "mean", "(", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.KerasClassifierLOSS.score": [[192, 195], ["SNGP.KerasClassifierLOSS.model().numpy().flatten", "sklearn.metrics.roc_auc_score", "SNGP.KerasClassifierLOSS.model().numpy", "SNGP.KerasClassifierLOSS.model"], "methods", ["None"], ["", "def", "score", "(", "self", ",", "X", ",", "Y", ")", ":", "\n", "        ", "probs", "=", "self", ".", "model", "(", "X", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "return", "roc_auc_score", "(", "Y", ",", "probs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.KerasClassifierLOSS.fit": [[196, 198], ["super().fit"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.models.GP.fit"], ["", "def", "fit", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "KerasClassifierLOSS", ",", "self", ")", ".", "fit", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.create_model": [[199, 205], ["SNGP.SNGPDNN", "SNGPDNN.compile", "tensorflow.keras.metrics.AUC"], "function", ["None"], ["", "", "def", "create_model", "(", "depth", ",", "l2", ",", "width", ",", "activation", ")", ":", "\n", "    ", "model", "=", "SNGPDNN", "(", "depth", "=", "depth", ",", "width", "=", "width", ",", "l2", "=", "l2", ",", "activation", "=", "activation", ")", "\n", "model", ".", "compile", "(", "optimizer", "=", "'adam'", ",", "\n", "loss", "=", "'binary_crossentropy'", ",", "\n", "metrics", "=", "[", "tf", ".", "keras", ".", "metrics", ".", "AUC", "(", ")", "]", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.fit": [[206, 220], ["dict", "SNGP.KerasClassifierLOSS", "sklearn.model_selection.RandomizedSearchCV", "sklearn.model_selection.RandomizedSearchCV.fit", "print", "print", "sklearn.metrics.roc_auc_score", "sklearn.model_selection.RandomizedSearchCV.predict_proba"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.models.GP.fit", "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.SNGPDNN.predict_proba"], ["", "def", "fit", "(", "train_sl", ",", "task", ",", "X", ",", "Y", ",", "Xv", ",", "Yv", ")", ":", "\n", "    ", "param_grid", "=", "dict", "(", "l2", "=", "[", "1e-1", ",", "3e-2", ",", "1e-2", ",", "3e-3", ",", "1e-3", "]", ",", "\n", "depth", "=", "[", "2", ",", "3", ",", "4", ",", "5", "]", ",", "\n", "width", "=", "[", "64", ",", "128", ",", "256", ",", "512", "]", ",", "\n", "batch_size", "=", "[", "32", ",", "64", ",", "128", ",", "256", "]", ",", "\n", "activation", "=", "[", "'tanh'", ",", "'relu'", ",", "'sigmoid'", "]", ",", "\n", "epochs", "=", "[", "40", "]", ")", "\n", "builder", "=", "KerasClassifierLOSS", "(", "create_model", ",", "verbose", "=", "0", ")", "\n", "best_model", "=", "RandomizedSearchCV", "(", "builder", ",", "param_grid", ",", "cv", "=", "2", ",", "n_jobs", "=", "10", ",", "n_iter", "=", "128", ",", "random_state", "=", "2020", ")", "\n", "config", "=", "best_model", ".", "fit", "(", "X", ",", "Y", ",", "validation_data", "=", "(", "Xv", ",", "Yv", ")", ")", "\n", "\n", "print", "(", "'Best AUC:'", ",", "roc_auc_score", "(", "Yv", ",", "best_model", ".", "predict_proba", "(", "Xv", ")", "[", ":", ",", "1", "]", ")", ")", "\n", "print", "(", "'Best config:'", ",", "best_model", ".", "best_params_", ")", "\n", "return", "best_model", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.models.MondrianForest.fit": [[18, 36], ["print", "skgarden.MondrianForestClassifier", "print", "skgarden.MondrianForestClassifier.fit", "sklearn.metrics.roc_auc_score", "print", "skgarden.MondrianForestClassifier.predict_proba"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.models.GP.fit", "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.SNGPDNN.predict_proba"], ["def", "fit", "(", "train_sl", ",", "task", ",", "X", ",", "Y", ",", "Xv", ",", "Yv", ")", ":", "\n", "    ", "best_n", "=", "None", "\n", "best_score", "=", "0", "\n", "best_model", "=", "None", "\n", "for", "n", "in", "[", "10", "]", ":", "#, 50, 100]:", "\n", "        ", "m", "=", "MF", "(", "n_estimators", "=", "n", ",", "n_jobs", "=", "-", "1", ")", "\n", "print", "(", "'[%s, %s] Fitting model with n:'", "%", "(", "train_sl", ",", "task", ")", ",", "n", ")", "\n", "m", ".", "fit", "(", "X", ",", "Y", ")", "\n", "Pv", "=", "m", ".", "predict_proba", "(", "Xv", ")", "[", ":", ",", "1", "]", "\n", "score", "=", "roc_auc_score", "(", "Yv", ",", "Pv", ")", "\n", "print", "(", "'Fitted with n:'", ",", "n", ",", "'AUC:'", ",", "score", ")", "\n", "if", "score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "score", "\n", "best_model", "=", "m", "\n", "best_n", "=", "n", "\n", "\n", "", "", "print", "(", "'Best n:'", ",", "best_n", ")", "\n", "return", "best_model", "\n", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.models.LogReg.fit": [[18, 35], ["print", "sklearn.linear_model.LogisticRegression", "print", "sklearn.linear_model.LogisticRegression.fit", "sklearn.metrics.roc_auc_score", "sklearn.linear_model.LogisticRegression.predict_proba"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.models.GP.fit", "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.SNGPDNN.predict_proba"], ["def", "fit", "(", "sname", ",", "task", ",", "X", ",", "Y", ",", "Xv", ",", "Yv", ")", ":", "\n", "    ", "best_c", "=", "None", "\n", "best_score", "=", "0", "\n", "best_model", "=", "None", "\n", "for", "c", "in", "[", "1e-1", ",", "1e-2", ",", "1e-3", ",", "1e-4", ",", "1e-5", ",", "1e-6", ",", "1e-7", "]", ":", "\n", "        ", "m", "=", "LR", "(", "C", "=", "c", ")", "\n", "print", "(", "'Fitting model with C:'", ",", "c", ")", "\n", "m", ".", "fit", "(", "X", ",", "Y", ")", "\n", "Pv", "=", "m", ".", "predict_proba", "(", "Xv", ")", "[", ":", ",", "1", "]", "\n", "score", "=", "roc_auc_score", "(", "Yv", ",", "Pv", ")", "\n", "if", "score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "score", "\n", "best_model", "=", "m", "\n", "best_c", "=", "c", "\n", "\n", "", "", "print", "(", "'Best C:'", ",", "best_c", ")", "\n", "return", "best_model", "\n", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.models.MLP.fit": [[18, 38], ["print", "sklearn.neural_network.MLPClassifier", "sklearn.neural_network.MLPClassifier.fit", "sklearn.metrics.roc_auc_score", "print", "sklearn.neural_network.MLPClassifier.predict_proba"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.models.GP.fit", "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.SNGPDNN.predict_proba"], ["def", "fit", "(", "train_sl", ",", "task", ",", "X", ",", "Y", ",", "Xv", ",", "Yv", ")", ":", "\n", "    ", "best_c", "=", "None", "\n", "best_score", "=", "0", "\n", "best_model", "=", "None", "\n", "for", "c", "in", "[", "1e-1", ",", "1e-2", ",", "1e-3", ",", "1e-4", ",", "1e-5", ",", "1e-6", ",", "1e-7", "]", ":", "\n", "        ", "m", "=", "MLP", "(", "hidden_layer_sizes", "=", "(", "256", ",", "256", ",", "256", ",", "256", ")", ",", "alpha", "=", "c", ",", "\n", "early_stopping", "=", "True", ",", "\n", "learning_rate", "=", "'adaptive'", ",", "\n", "batch_size", "=", "128", ")", "\n", "m", ".", "fit", "(", "X", ",", "Y", ")", "\n", "Pv", "=", "m", ".", "predict_proba", "(", "Xv", ")", "[", ":", ",", "1", "]", "\n", "score", "=", "roc_auc_score", "(", "Yv", ",", "Pv", ")", "\n", "print", "(", "'Fitted model with C:'", ",", "c", ",", "'AUC:'", ",", "score", ")", "\n", "if", "score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "score", "\n", "best_model", "=", "m", "\n", "best_c", "=", "c", "\n", "\n", "", "", "print", "(", "'Best C:'", ",", "best_c", ",", "'AUC:'", ",", "best_score", ")", "\n", "return", "best_model", "\n", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.models.GP.fit": [[20, 39], ["print", "sklearn.gaussian_process.GaussianProcessClassifier", "sklearn.gaussian_process.GaussianProcessClassifier.fit", "sklearn.metrics.roc_auc_score", "print", "sklearn.gaussian_process.kernels.RationalQuadratic", "sklearn.gaussian_process.GaussianProcessClassifier.predict_proba"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.models.GP.fit", "home.repos.pwc.inspect_result.google-health_records-research.models.SNGP.SNGPDNN.predict_proba"], ["def", "fit", "(", "train_sl", ",", "task", ",", "X", ",", "Y", ",", "Xv", ",", "Yv", ")", ":", "\n", "    ", "best_c", "=", "None", "\n", "best_score", "=", "0", "\n", "best_model", "=", "None", "\n", "\n", "#for K in [1*RBF(), 1*DotProduct(), 1*Matern(), 1*RationalQuadratic(), 1*WhiteKernel()]:", "\n", "for", "K", "in", "[", "1", "*", "RationalQuadratic", "(", ")", "]", ":", "\n", "        ", "m", "=", "GPC", "(", "kernel", "=", "K", ",", "n_jobs", "=", "-", "1", ")", "\n", "m", ".", "fit", "(", "X", ",", "Y", ")", "\n", "Pv", "=", "m", ".", "predict_proba", "(", "Xv", ")", "[", ":", ",", "1", "]", "\n", "score", "=", "roc_auc_score", "(", "Yv", ",", "Pv", ")", "\n", "print", "(", "'Fitted GPC with K:'", ",", "K", ",", "'AUC:'", ",", "score", ")", "\n", "if", "score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "score", "\n", "best_model", "=", "m", "\n", "best_c", "=", "K", "\n", "\n", "", "", "print", "(", "'Best K:'", ",", "best_c", ")", "\n", "return", "best_model", "\n", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.clinical-notes-prediction.lstm.LSTM.__init__": [[65, 97], ["None"], "methods", ["None"], ["", "", "def", "__init__", "(", "self", ",", "\n", "model_dim", ",", "\n", "bidirectional", "=", "False", ",", "\n", "input_dropout_keep_prob", "=", "1.0", ",", "\n", "hidden_dropout_keep_prob", "=", "1.0", ",", "\n", "variational_input_keep_prob", "=", "1.0", ",", "\n", "variational_output_keep_prob", "=", "1.0", ",", "\n", "zoneout_keep_prob", "=", "1.0", ",", "\n", "is_training", "=", "True", ",", "\n", "trainable", "=", "True", ")", ":", "\n", "        ", "\"\"\"Params:\n\n        model_dim: dimension of the LSTM hidden state.\n        bidirectional: whether to use a bidirectional LSTM.\n        input_dropout_keep_prob: dropout rate for model inputs.\n        hidden_dropout_keep_prob: dropout rate for model hidden state.\n        variational_input_keep_prob: variational dropout rate for model inputs.\n        variational_output_keep_prob: variational dropout rate for model hidden\n          state.\n        zoneout_keep_prob: rate to apply Zoneout across timesteps.\n        is_training: whether model is in training or eval mode.\n        trainable: whether LSTM weights should be updated during training.\n        \"\"\"", "\n", "self", ".", "_is_training", "=", "is_training", "\n", "self", ".", "_trainable", "=", "trainable", "\n", "self", ".", "_model_dim", "=", "model_dim", "\n", "self", ".", "_bidirectional", "=", "bidirectional", "\n", "self", ".", "_input_dropout_keep_prob", "=", "input_dropout_keep_prob", "\n", "self", ".", "_hidden_dropout_keep_prob", "=", "hidden_dropout_keep_prob", "\n", "self", ".", "_variational_input_keep_prob", "=", "variational_input_keep_prob", "\n", "self", ".", "_variational_output_keep_prob", "=", "variational_output_keep_prob", "\n", "self", ".", "_zoneout_keep_prob", "=", "zoneout_keep_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.clinical-notes-prediction.lstm.LSTM._LSTMCell": [[98, 110], ["tensorflow.nn.rnn_cell.LSTMCell", "lstm.LSTM._ZoneoutWrapper", "tensorflow.nn.rnn_cell.DropoutWrapper"], "methods", ["None"], ["", "def", "_LSTMCell", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initializes the LSTM cell with dropout and Zoneout applied.\"\"\"", "\n", "cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "LSTMCell", "(", "self", ".", "_model_dim", ",", "trainable", "=", "self", ".", "_trainable", ")", "\n", "if", "self", ".", "_zoneout_keep_prob", "<", "1.0", ":", "\n", "            ", "cell", "=", "self", ".", "_ZoneoutWrapper", "(", "\n", "cell", ",", "1.0", "-", "self", ".", "_zoneout_keep_prob", ",", "self", ".", "_is_training", ")", "\n", "", "if", "self", ".", "_is_training", ":", "\n", "            ", "cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "(", "\n", "cell", ",", "\n", "input_keep_prob", "=", "self", ".", "_input_dropout_keep_prob", ",", "\n", "output_keep_prob", "=", "self", ".", "_hidden_dropout_keep_prob", ")", "\n", "", "return", "cell", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.clinical-notes-prediction.lstm.LSTM._VariationalDropout": [[111, 122], ["tensorflow.nn.rnn_cell.DropoutWrapper"], "methods", ["None"], ["", "def", "_VariationalDropout", "(", "self", ",", "cell", ",", "input_size", ")", ":", "\n", "        ", "\"\"\"Adds variational dropout to the LSTM cell.\n\n        Applied separately from _LSTMCell, as this wrapper depends on input depth.\n        \"\"\"", "\n", "return", "tf", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "(", "\n", "cell", ",", "\n", "input_keep_prob", "=", "self", ".", "_variational_input_keep_prob", ",", "\n", "output_keep_prob", "=", "self", ".", "_variational_output_keep_prob", ",", "\n", "variational_recurrent", "=", "True", ",", "\n", "input_size", "=", "input_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.clinical-notes-prediction.lstm.LSTM.Forward": [[123, 154], ["lstm.LSTM._LSTMCell", "lstm.LSTM._LSTMCell", "lstm.LSTM._VariationalDropout", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.concat", "tensorflow.concat", "tensorflow.nn.dynamic_rnn", "lstm.LSTM._VariationalDropout"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.clinical-notes-prediction.lstm.LSTM._LSTMCell", "home.repos.pwc.inspect_result.google-health_records-research.clinical-notes-prediction.lstm.LSTM._LSTMCell", "home.repos.pwc.inspect_result.google-health_records-research.clinical-notes-prediction.lstm.LSTM._VariationalDropout", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.clinical-notes-prediction.lstm.LSTM._VariationalDropout"], ["", "def", "Forward", "(", "self", ",", "inputs", ",", "sequence_length", ")", ":", "\n", "        ", "\"\"\"Constructs the forward graph and returns the LSTM output tensors.\"\"\"", "\n", "fw_cell", "=", "self", ".", "_LSTMCell", "(", ")", "\n", "if", "self", ".", "_bidirectional", ":", "\n", "            ", "bw_cell", "=", "self", ".", "_LSTMCell", "(", ")", "\n", "\n", "", "if", "self", ".", "_is_training", ":", "\n", "            ", "input_size", "=", "inputs", ".", "shape", "[", "2", "]", "\n", "fw_cell", "=", "self", ".", "_VariationalDropout", "(", "fw_cell", ",", "input_size", ")", "\n", "if", "self", ".", "_bidirectional", ":", "\n", "                ", "bw_cell", "=", "self", ".", "_VariationalDropout", "(", "bw_cell", ",", "input_size", ")", "\n", "\n", "", "", "if", "self", ".", "_bidirectional", ":", "\n", "            ", "outputs", ",", "final_state", "=", "tf", ".", "nn", ".", "bidirectional_dynamic_rnn", "(", "\n", "fw_cell", ",", "\n", "bw_cell", ",", "\n", "inputs", ",", "\n", "sequence_length", "=", "sequence_length", ")", "\n", "final_state_fw", ",", "final_state_bw", "=", "final_state", "\n", "last_output_fw", "=", "final_state_fw", "[", "-", "1", "]", ".", "h", "\n", "last_output_bw", "=", "final_state_bw", "[", "-", "1", "]", ".", "h", "\n", "outputs", "=", "tf", ".", "concat", "(", "outputs", ",", "2", ")", "\n", "last_outputs", "=", "tf", ".", "concat", "(", "[", "last_output_fw", ",", "last_output_bw", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "outputs", ",", "final_state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "\n", "fw_cell", ",", "\n", "inputs", ",", "\n", "sequence_length", "=", "sequence_length", ")", "\n", "last_outputs", "=", "final_state", "[", "-", "1", "]", ".", "h", "\n", "\n", "", "return", "outputs", ",", "last_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.customized_layers.MLPLayer.__init__": [[21, 28], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__"], ["def", "__init__", "(", "self", ",", "num_layer", ",", "num_hidden_unit", ",", "num_output_unit", ",", "\n", "output_activation", ")", ":", "\n", "    ", "super", "(", "MLPLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_layer", "=", "num_layer", "\n", "self", ".", "num_hidden_unit", "=", "num_hidden_unit", "\n", "self", ".", "num_output_unit", "=", "num_output_unit", "\n", "self", ".", "output_activation", "=", "output_activation", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.customized_layers.MLPLayer.build": [[29, 36], ["dict", "range", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense"], "methods", ["None"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "    ", "self", ".", "hidden_layers", "=", "dict", "(", ")", "\n", "for", "layer", "in", "range", "(", "self", ".", "num_layer", "-", "1", ")", ":", "\n", "      ", "self", ".", "hidden_layers", "[", "layer", "]", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "self", ".", "num_hidden_unit", ",", "input_shape", "=", "input_shape", ",", "activation", "=", "'relu'", ")", "\n", "", "self", ".", "out_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "self", ".", "num_output_unit", ",", "activation", "=", "self", ".", "output_activation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.customized_layers.MLPLayer.call": [[37, 43], ["range", "customized_layers.MLPLayer.out_layer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "    ", "x", "=", "inputs", "\n", "for", "layer", "in", "range", "(", "self", ".", "num_layer", "-", "1", ")", ":", "\n", "      ", "x", "=", "self", ".", "hidden_layers", "[", "layer", "]", "(", "x", ")", "\n", "", "x", "=", "self", ".", "out_layer", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.customized_layers.AttentionLayer.__init__": [[48, 56], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__"], ["def", "__init__", "(", "self", ",", "\n", "num_predict", ",", "\n", "normalization_model", "=", "'softmax'", ",", "\n", "attention_init_value", "=", "None", ")", ":", "\n", "    ", "super", "(", "AttentionLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_predict", "=", "num_predict", "\n", "self", ".", "attention_init_value", "=", "attention_init_value", "\n", "self", ".", "normalization_model", "=", "normalization_model", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.customized_layers.AttentionLayer.build": [[57, 74], ["super().build", "customized_layers.AttentionLayer.attention_init_value.split", "customized_layers.AttentionLayer.add_weight", "customized_layers.AttentionLayer.add_weight", "float", "tensorflow.keras.initializers.Constant", "int", "int", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.customized_layers.AttentionLayer.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "# kernel with shape [num_feature]", "\n", "    ", "if", "self", ".", "attention_init_value", "is", "not", "None", ":", "\n", "      ", "val_str_list", "=", "self", ".", "attention_init_value", ".", "split", "(", "','", ")", "\n", "val_list", "=", "[", "float", "(", "val_str", ")", "for", "val_str", "in", "val_str_list", "]", "\n", "self", ".", "kernel", "=", "self", ".", "add_weight", "(", "\n", "'kernel'", ",", "\n", "shape", "=", "[", "int", "(", "input_shape", "[", "2", "]", ")", "]", ",", "\n", "initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "Constant", "(", "\n", "value", "=", "tf", ".", "constant", "(", "val_list", ")", ")", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "kernel", "=", "self", ".", "add_weight", "(", "\n", "'kernel'", ",", "\n", "shape", "=", "[", "int", "(", "input_shape", "[", "2", "]", ")", "]", ",", "\n", "initializer", "=", "'uniform'", ",", "\n", "dtype", "=", "'float32'", ")", "\n", "", "super", "(", "AttentionLayer", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.customized_layers.AttentionLayer.call": [[75, 90], ["tensorflow.repeat", "tensorflow.multiply", "tensorflow.nn.softmax", "tensorflow.math.softplus", "tensorflow.reduce_sum", "tensorflow.math.divide_no_nan", "tensorflow.expand_dims"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "# softmax is taken along feature dim.", "\n", "    ", "if", "self", ".", "normalization_model", "==", "'softmax'", ":", "\n", "      ", "self", ".", "attention_tensor", "=", "tf", ".", "nn", ".", "softmax", "(", "self", ".", "kernel", ")", "\n", "", "if", "self", ".", "normalization_model", "==", "'linear'", ":", "\n", "      ", "positive_kernel", "=", "tf", ".", "math", ".", "softplus", "(", "self", ".", "kernel", ")", "\n", "kernel_sum", "=", "tf", ".", "reduce_sum", "(", "positive_kernel", ")", "\n", "self", ".", "attention_tensor", "=", "tf", ".", "math", ".", "divide_no_nan", "(", "positive_kernel", ",", "kernel_sum", ")", "\n", "\n", "# attention_tensor shape [batch_size, num_predict, num_feature]", "\n", "", "self", ".", "attention_tensor", "=", "tf", ".", "repeat", "(", "\n", "tf", ".", "expand_dims", "(", "self", ".", "attention_tensor", ",", "axis", "=", "0", ")", ",", "\n", "repeats", "=", "[", "self", ".", "num_predict", "]", ",", "\n", "axis", "=", "0", ")", "\n", "return", "tf", ".", "multiply", "(", "inputs", ",", "self", ".", "attention_tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.customized_layers.AttentionLayer.attention_outputs": [[91, 94], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "attention_outputs", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "attention_tensor", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.ClassificationTask.__init__": [[56, 89], ["object.__init__", "os.path.join", "tensorflow.keras.metrics.AUC", "tensorflow.keras.metrics.AUC", "tensorflow.keras.metrics.AUC", "tensorflow.keras.metrics.AUC", "tensorflow.keras.metrics.AUC", "tensorflow.keras.metrics.AUC", "tasks._get_tensorboard_writer"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks._get_tensorboard_writer"], ["def", "__init__", "(", "self", ",", "log_steps", ",", "export_to_tensorboard", ",", "experiment_log_path", ",", "\n", "job_prefix", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "name", "=", "'classification'", "\n", "self", ".", "log_steps", "=", "log_steps", "\n", "\n", "self", ".", "export_to_tensorboard", "=", "export_to_tensorboard", "\n", "self", ".", "experiment_log_path", "=", "os", ".", "path", ".", "join", "(", "experiment_log_path", ")", "\n", "\n", "self", ".", "job_prefix", "=", "job_prefix", "\n", "\n", "self", ".", "positive", "=", "{", "'train'", ":", "0", ",", "'eval'", ":", "0", ",", "'test'", ":", "0", "}", "\n", "self", ".", "total", "=", "{", "'train'", ":", "0", ",", "'eval'", ":", "0", ",", "'test'", ":", "0", "}", "\n", "self", ".", "loss", "=", "{", "'train'", ":", "0", ",", "'eval'", ":", "0", ",", "'test'", ":", "0", "}", "\n", "self", ".", "auc", "=", "{", "\n", "'train'", ":", "tf", ".", "keras", ".", "metrics", ".", "AUC", "(", ")", ",", "\n", "'eval'", ":", "tf", ".", "keras", ".", "metrics", ".", "AUC", "(", ")", ",", "\n", "'test'", ":", "tf", ".", "keras", ".", "metrics", ".", "AUC", "(", ")", "\n", "}", "\n", "self", ".", "aucpr", "=", "{", "\n", "'train'", ":", "tf", ".", "keras", ".", "metrics", ".", "AUC", "(", "curve", "=", "'PR'", ")", ",", "\n", "'eval'", ":", "tf", ".", "keras", ".", "metrics", ".", "AUC", "(", "curve", "=", "'PR'", ")", ",", "\n", "'test'", ":", "tf", ".", "keras", ".", "metrics", ".", "AUC", "(", "curve", "=", "'PR'", ")", "\n", "}", "\n", "\n", "self", ".", "best_eval_loss", "=", "10.0", "\n", "self", ".", "best_eval_auc", "=", "0", "\n", "self", ".", "best_eval_aucpr", "=", "0", "\n", "\n", "self", ".", "writer", "=", "{", "\n", "k", ":", "_get_tensorboard_writer", "(", "self", ".", "experiment_log_path", ",", "self", ".", "job_prefix", ",", "k", ",", "\n", "self", ".", "name", ")", "\n", "for", "k", "in", "[", "'train'", ",", "'eval'", ",", "'test'", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.ClassificationTask.process_label": [[91, 95], ["tensorflow.expand_dims"], "methods", ["None"], ["", "def", "process_label", "(", "self", ",", "label", ")", ":", "\n", "    ", "supervised_label", ",", "_", "=", "label", "\n", "supervised_label", "=", "tf", ".", "expand_dims", "(", "supervised_label", ",", "axis", "=", "1", ")", "\n", "return", "supervised_label", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.ClassificationTask.get_loss": [[96, 103], ["tasks.ClassificationTask.process_label", "tensorflow.math.reduce_mean", "tensorflow.keras.losses.binary_crossentropy"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.RegressionTask.process_label"], ["", "def", "get_loss", "(", "self", ",", "label", ",", "prediction", ",", "mode", ")", ":", "\n", "    ", "label", "=", "self", ".", "process_label", "(", "label", ")", "\n", "self", ".", "loss", "[", "mode", "]", "=", "tf", ".", "math", ".", "reduce_mean", "(", "\n", "tf", ".", "keras", ".", "losses", ".", "binary_crossentropy", "(", "\n", "y_true", "=", "label", ",", "y_pred", "=", "prediction", ",", "from_logits", "=", "False", ")", ")", "\n", "\n", "return", "self", ".", "loss", "[", "mode", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.ClassificationTask.update_metrics": [[104, 155], ["tasks.ClassificationTask.process_label", "tasks.ClassificationTask.auc[].update_state", "tasks.ClassificationTask.aucpr[].update_state", "tensorflow.math.count_nonzero", "tasks.ClassificationTask.auc[].result().numpy", "tasks.ClassificationTask.aucpr[].result().numpy", "tasks.ClassificationTask.auc[].reset_states", "tasks.ClassificationTask.aucpr[].reset_states", "logging.info", "tasks.output_best_eval_csv", "tasks.ClassificationTask.auc[].result", "tasks.ClassificationTask.aucpr[].result", "tasks.ClassificationTask.writer[].as_default", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tasks.ClassificationTask.writer[].flush", "tasks.output_best_eval_csv", "tasks.output_best_eval_csv", "tasks.output_best_eval_csv"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.RegressionTask.process_label", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.output_best_eval_csv", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.output_best_eval_csv", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.output_best_eval_csv", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.output_best_eval_csv"], ["", "def", "update_metrics", "(", "self", ",", "label", ",", "prediction", ",", "mode", ",", "global_step", ",", "reset", ")", ":", "\n", "    ", "\"\"\"Update metrics for the task at global_step.\"\"\"", "\n", "label", "=", "self", ".", "process_label", "(", "label", ")", "\n", "if", "reset", ":", "\n", "      ", "self", ".", "auc", "[", "mode", "]", ".", "reset_states", "(", ")", "\n", "self", ".", "aucpr", "[", "mode", "]", ".", "reset_states", "(", ")", "\n", "self", ".", "positive", "[", "mode", "]", "=", "0", "\n", "self", ".", "total", "[", "mode", "]", "=", "0", "\n", "\n", "", "self", ".", "auc", "[", "mode", "]", ".", "update_state", "(", "y_true", "=", "label", ",", "y_pred", "=", "prediction", ")", "\n", "self", ".", "aucpr", "[", "mode", "]", ".", "update_state", "(", "y_true", "=", "label", ",", "y_pred", "=", "prediction", ")", "\n", "self", ".", "positive", "[", "mode", "]", "+=", "tf", ".", "math", ".", "count_nonzero", "(", "label", ")", "\n", "self", ".", "total", "[", "mode", "]", "+=", "label", ".", "shape", "[", "0", "]", "\n", "pos_ratio", "=", "self", ".", "positive", "[", "mode", "]", "/", "self", ".", "total", "[", "mode", "]", "\n", "auc", "=", "self", ".", "auc", "[", "mode", "]", ".", "result", "(", ")", ".", "numpy", "(", ")", "\n", "aucpr", "=", "self", ".", "aucpr", "[", "mode", "]", ".", "result", "(", ")", ".", "numpy", "(", ")", "\n", "loss", "=", "self", ".", "loss", "[", "mode", "]", "\n", "\n", "if", "self", ".", "export_to_tensorboard", ":", "\n", "      ", "with", "self", ".", "writer", "[", "mode", "]", ".", "as_default", "(", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "scalar", "(", "mode", "+", "'/classification/loss'", ",", "loss", ",", "global_step", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "mode", "+", "'/classification/auc'", ",", "auc", ",", "global_step", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "mode", "+", "'/classification/aucpr'", ",", "aucpr", ",", "global_step", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "mode", "+", "'/classification/positive'", ",", "pos_ratio", ",", "\n", "global_step", ")", "\n", "self", ".", "writer", "[", "mode", "]", ".", "flush", "(", ")", "\n", "\n", "", "", "if", "global_step", "%", "self", ".", "log_steps", "==", "0", "or", "mode", "==", "'eval'", "or", "mode", "==", "'test'", ":", "\n", "      ", "logging", ".", "info", "(", "\n", "'%s : Step %d: loss = %f, auc = %f aucpr = %f pos_ratio = %f '", ",", "mode", ",", "\n", "global_step", ",", "loss", ",", "auc", ",", "aucpr", ",", "pos_ratio", ")", "\n", "\n", "", "if", "mode", "==", "'eval'", ":", "\n", "      ", "if", "self", ".", "loss", "[", "mode", "]", "<", "self", ".", "best_eval_loss", ":", "\n", "        ", "self", ".", "best_eval_loss", "=", "loss", "\n", "output_best_eval_csv", "(", "'loss'", ",", "loss", ",", "auc", ",", "aucpr", ",", "mode", ",", "global_step", ",", "\n", "self", ".", "experiment_log_path", ",", "self", ".", "job_prefix", ")", "\n", "", "if", "auc", ">", "self", ".", "best_eval_auc", ":", "\n", "        ", "self", ".", "best_eval_auc", "=", "auc", "\n", "output_best_eval_csv", "(", "'auc'", ",", "loss", ",", "auc", ",", "aucpr", ",", "mode", ",", "global_step", ",", "\n", "self", ".", "experiment_log_path", ",", "self", ".", "job_prefix", ")", "\n", "", "if", "aucpr", ">", "self", ".", "best_eval_aucpr", ":", "\n", "        ", "self", ".", "best_eval_aucpr", "=", "aucpr", "\n", "output_best_eval_csv", "(", "'aucpr'", ",", "loss", ",", "auc", ",", "aucpr", ",", "mode", ",", "global_step", ",", "\n", "self", ".", "experiment_log_path", ",", "self", ".", "job_prefix", ")", "\n", "\n", "", "", "if", "mode", "==", "'test'", ":", "\n", "      ", "output_best_eval_csv", "(", "''", ",", "loss", ",", "auc", ",", "aucpr", ",", "mode", ",", "global_step", ",", "\n", "self", ".", "experiment_log_path", ",", "self", ".", "job_prefix", ")", "\n", "\n", "", "return", "auc", ",", "aucpr", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.RegressionTask.__init__": [[160, 223], ["object.__init__", "tasks.RegressionTask._parse_feature_index_str", "os.path.join", "customized_layers.AttentionLayer", "logging.info", "logging.info", "tensorflow.keras.metrics.MeanSquaredError", "tensorflow.keras.metrics.MeanSquaredError", "tensorflow.keras.metrics.MeanSquaredError", "tensorflow.keras.metrics.MeanAbsoluteError", "tensorflow.keras.metrics.MeanAbsoluteError", "tensorflow.keras.metrics.MeanAbsoluteError", "tasks._get_tensorboard_writer", "logging.info"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.RegressionTask._parse_feature_index_str", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks._get_tensorboard_writer"], ["def", "__init__", "(", "self", ",", "num_feature", ",", "num_predict", ",", "target_feature_index", ",", "\n", "feature_indice_included_str", ",", "feature_indice_excluded_str", ",", "\n", "feature_keys", ",", "log_steps", ",", "export_to_tensorboard", ",", "\n", "experiment_log_path", ",", "job_prefix", ",", "forecast_only_nonmask_values", ",", "\n", "forecast_loss_func", ",", "use_attention", ",", "normalization_model", ",", "\n", "attention_init_value", ",", "use_attn_output", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "name", "=", "'regression'", "\n", "self", ".", "use_attention", "=", "use_attention", "\n", "if", "self", ".", "use_attention", ":", "\n", "      ", "self", ".", "attention", "=", "customized_layers", ".", "AttentionLayer", "(", "num_predict", ",", "\n", "normalization_model", ",", "\n", "attention_init_value", ")", "\n", "", "self", ".", "use_attn_output", "=", "use_attn_output", "\n", "self", ".", "num_feature", "=", "num_feature", "\n", "self", ".", "num_predict", "=", "num_predict", "\n", "self", ".", "target_feature_index", "=", "target_feature_index", "\n", "# Only one list can be nonempty.", "\n", "self", ".", "feature_keys", "=", "feature_keys", "\n", "self", ".", "feature_index_included", "=", "self", ".", "_parse_feature_index_str", "(", "\n", "feature_indice_included_str", ",", "feature_indice_excluded_str", ")", "\n", "if", "self", ".", "feature_index_included", ":", "\n", "      ", "logging", ".", "info", "(", "'selected features:'", ")", "\n", "for", "f_index", "in", "self", ".", "feature_index_included", ":", "\n", "        ", "logging", ".", "info", "(", "feature_keys", "[", "f_index", "]", ")", "\n", "", "", "else", ":", "\n", "      ", "logging", ".", "info", "(", "'all feature included.'", ")", "\n", "\n", "", "self", ".", "log_steps", "=", "log_steps", "\n", "\n", "self", ".", "export_to_tensorboard", "=", "export_to_tensorboard", "\n", "self", ".", "experiment_log_path", "=", "os", ".", "path", ".", "join", "(", "experiment_log_path", ")", "\n", "self", ".", "job_prefix", "=", "job_prefix", "\n", "\n", "self", ".", "forecast_only_nonmask_values", "=", "forecast_only_nonmask_values", "\n", "self", ".", "forecast_loss_func", "=", "forecast_loss_func", "\n", "\n", "self", ".", "label_val", "=", "{", "'train'", ":", "0", ",", "'eval'", ":", "0", ",", "'test'", ":", "0", "}", "\n", "self", ".", "total", "=", "{", "'train'", ":", "0", ",", "'eval'", ":", "0", ",", "'test'", ":", "0", "}", "\n", "self", ".", "loss", "=", "{", "'train'", ":", "0", ",", "'eval'", ":", "0", ",", "'test'", ":", "0", "}", "\n", "self", ".", "mse", "=", "{", "\n", "'train'", ":", "tf", ".", "keras", ".", "metrics", ".", "MeanSquaredError", "(", ")", ",", "\n", "'eval'", ":", "tf", ".", "keras", ".", "metrics", ".", "MeanSquaredError", "(", ")", ",", "\n", "'test'", ":", "tf", ".", "keras", ".", "metrics", ".", "MeanSquaredError", "(", ")", "\n", "}", "\n", "self", ".", "mae", "=", "{", "\n", "'train'", ":", "tf", ".", "keras", ".", "metrics", ".", "MeanAbsoluteError", "(", ")", ",", "\n", "'eval'", ":", "tf", ".", "keras", ".", "metrics", ".", "MeanAbsoluteError", "(", ")", ",", "\n", "'test'", ":", "tf", ".", "keras", ".", "metrics", ".", "MeanAbsoluteError", "(", ")", "\n", "}", "\n", "\n", "self", ".", "best_eval_loss", "=", "10.0", "\n", "self", ".", "best_eval_mse", "=", "10.0", "\n", "self", ".", "best_eval_mae", "=", "10.0", "\n", "\n", "if", "self", ".", "use_attention", ":", "\n", "      ", "for", "f", "in", "self", ".", "feature_keys", ":", "\n", "        ", "key", "=", "'attention/'", "+", "f", "\n", "\n", "", "", "self", ".", "writer", "=", "{", "\n", "k", ":", "_get_tensorboard_writer", "(", "self", ".", "experiment_log_path", ",", "self", ".", "job_prefix", ",", "k", ",", "\n", "self", ".", "name", ")", "\n", "for", "k", "in", "[", "'train'", ",", "'eval'", ",", "'test'", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.RegressionTask.process_label": [[225, 228], ["None"], "methods", ["None"], ["", "def", "process_label", "(", "self", ",", "label", ")", ":", "\n", "    ", "_", ",", "unsupervised_label", "=", "label", "\n", "return", "unsupervised_label", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.RegressionTask.get_loss": [[229, 261], ["tasks.RegressionTask.process_label", "tensorflow.boolean_mask", "tensorflow.reduce_mean", "tensorflow.gather", "tensorflow.gather", "tensorflow.gather", "tensorflow.ones_like", "tasks.RegressionTask.attention", "tasks.RegressionTask.attention", "loss_func", "logging.fatal"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.RegressionTask.process_label"], ["", "def", "get_loss", "(", "self", ",", "label", ",", "prediction", ",", "mode", ")", ":", "\n", "    ", "\"\"\"Loss for regression task.\"\"\"", "\n", "future_obs", ",", "future_mask", "=", "self", ".", "process_label", "(", "label", ")", "\n", "\n", "if", "self", ".", "target_feature_index", "<", "self", ".", "num_feature", ":", "\n", "# target_feature_index [0, num_feature) for single feature forecast task.", "\n", "      ", "future_obs", "=", "future_obs", "[", ":", ",", ":", ",", "self", ".", "target_feature_index", "]", "\n", "prediction", "=", "prediction", "[", ":", ",", ":", ",", "self", ".", "target_feature_index", "]", "\n", "future_mask", "=", "future_mask", "[", ":", ",", ":", ",", "self", ".", "target_feature_index", "]", "\n", "\n", "", "if", "self", ".", "feature_index_included", ":", "\n", "      ", "future_obs", "=", "tf", ".", "gather", "(", "future_obs", ",", "self", ".", "feature_index_included", ",", "axis", "=", "2", ")", "\n", "prediction", "=", "tf", ".", "gather", "(", "prediction", ",", "self", ".", "feature_index_included", ",", "axis", "=", "2", ")", "\n", "future_mask", "=", "tf", ".", "gather", "(", "future_mask", ",", "self", ".", "feature_index_included", ",", "axis", "=", "2", ")", "\n", "\n", "", "loss_func", "=", "tf", ".", "abs", "if", "self", ".", "forecast_loss_func", "==", "'abs'", "else", "tf", ".", "square", "\n", "if", "not", "self", ".", "forecast_only_nonmask_values", ":", "\n", "      ", "future_mask", "=", "tf", ".", "ones_like", "(", "future_mask", ")", "\n", "\n", "", "if", "self", ".", "use_attention", ":", "\n", "      ", "if", "self", ".", "feature_index_included", ":", "\n", "        ", "logging", ".", "fatal", "(", "'use_attention can not work with feature_index_included'", ")", "\n", "", "future_obs", "=", "self", ".", "attention", "(", "future_obs", ")", "\n", "prediction", "=", "self", ".", "attention", "(", "prediction", ")", "\n", "\n", "# shape is (?,), where ? is within [0, num_predict * num_feature]", "\n", "# depending on the number of masks.", "\n", "", "batch_loss_with_mask", "=", "tf", ".", "boolean_mask", "(", "\n", "loss_func", "(", "future_obs", "-", "prediction", ")", ",", "future_mask", ")", "\n", "self", ".", "loss", "[", "mode", "]", "=", "tf", ".", "reduce_mean", "(", "batch_loss_with_mask", ")", "\n", "\n", "return", "self", ".", "loss", "[", "mode", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.RegressionTask.update_metrics": [[262, 349], ["tasks.RegressionTask.process_label", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tasks.RegressionTask.mse[].update_state", "tasks.RegressionTask.mae[].update_state", "tensorflow.reduce_sum", "tasks.RegressionTask.mse[].result().numpy", "tasks.RegressionTask.mae[].result().numpy", "tensorflow.ones_like", "tasks.RegressionTask.mse[].reset_states", "tasks.RegressionTask.mae[].reset_states", "tasks.RegressionTask.writer[].flush", "logging.info", "tasks.output_best_eval_csv", "tasks.RegressionTask.mse[].result", "tasks.RegressionTask.mae[].result", "tasks.RegressionTask.writer[].as_default", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tasks.output_attention_variable", "tasks.output_best_eval_csv", "tasks.output_best_eval_csv", "tasks.output_best_eval_csv", "enumerate", "logging.info", "enumerate", "atten_w.numpy().tolist", "atten_w.numpy().tolist", "tensorflow.summary.scalar", "str", "enumerate", "atten_w.numpy", "atten_w.numpy().tolist", "atten_w.numpy", "atten_w.numpy"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.RegressionTask.process_label", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.output_best_eval_csv", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.output_attention_variable", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.output_best_eval_csv", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.output_best_eval_csv", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.output_best_eval_csv"], ["", "def", "update_metrics", "(", "self", ",", "label", ",", "prediction", ",", "mode", ",", "global_step", ",", "reset", ")", ":", "\n", "    ", "\"\"\"Update metrics for the task at global_step.\"\"\"", "\n", "future_obs", ",", "future_mask", "=", "self", ".", "process_label", "(", "label", ")", "\n", "\n", "if", "self", ".", "target_feature_index", "<", "self", ".", "num_feature", ":", "\n", "# target_feature_index [0, num_feature) for single feature forecast task.", "\n", "      ", "future_obs", "=", "future_obs", "[", ":", ",", ":", ",", "self", ".", "target_feature_index", "]", "\n", "prediction", "=", "prediction", "[", ":", ",", ":", ",", "self", ".", "target_feature_index", "]", "\n", "future_mask", "=", "future_mask", "[", ":", ",", ":", ",", "self", ".", "target_feature_index", "]", "\n", "\n", "", "if", "not", "self", ".", "forecast_only_nonmask_values", ":", "\n", "      ", "future_mask", "=", "tf", ".", "ones_like", "(", "future_mask", ")", "\n", "\n", "", "future_obs", "=", "tf", ".", "boolean_mask", "(", "future_obs", ",", "future_mask", ")", "\n", "prediction", "=", "tf", ".", "boolean_mask", "(", "prediction", ",", "future_mask", ")", "\n", "\n", "if", "reset", ":", "\n", "      ", "self", ".", "mse", "[", "mode", "]", ".", "reset_states", "(", ")", "\n", "self", ".", "mae", "[", "mode", "]", ".", "reset_states", "(", ")", "\n", "self", ".", "label_val", "[", "mode", "]", "=", "0", "\n", "self", ".", "total", "[", "mode", "]", "=", "0", "\n", "\n", "", "self", ".", "mse", "[", "mode", "]", ".", "update_state", "(", "y_true", "=", "future_obs", ",", "y_pred", "=", "prediction", ")", "\n", "self", ".", "mae", "[", "mode", "]", ".", "update_state", "(", "y_true", "=", "future_obs", ",", "y_pred", "=", "prediction", ")", "\n", "self", ".", "total", "[", "mode", "]", "+=", "future_obs", ".", "shape", "[", "0", "]", "\n", "self", ".", "label_val", "[", "mode", "]", "+=", "tf", ".", "reduce_sum", "(", "future_obs", ")", "\n", "avg_feature_label_value", "=", "self", ".", "label_val", "[", "mode", "]", "/", "self", ".", "total", "[", "\n", "mode", "]", "/", "self", ".", "num_predict", "/", "self", ".", "num_feature", "\n", "mse", "=", "self", ".", "mse", "[", "mode", "]", ".", "result", "(", ")", ".", "numpy", "(", ")", "\n", "mae", "=", "self", ".", "mae", "[", "mode", "]", ".", "result", "(", ")", ".", "numpy", "(", ")", "\n", "loss", "=", "self", ".", "loss", "[", "mode", "]", "\n", "\n", "if", "self", ".", "export_to_tensorboard", ":", "\n", "      ", "with", "self", ".", "writer", "[", "mode", "]", ".", "as_default", "(", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "scalar", "(", "mode", "+", "'/regression/loss'", ",", "loss", ",", "global_step", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "mode", "+", "'/regression/mse'", ",", "mse", ",", "global_step", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "mode", "+", "'/regression/mae'", ",", "mae", ",", "global_step", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "mode", "+", "'/regression/label_val'", ",", "\n", "avg_feature_label_value", ",", "global_step", ")", "\n", "if", "self", ".", "use_attention", ":", "\n", "          ", "attn_list", "=", "self", ".", "attention_outputs", "if", "self", ".", "use_attn_output", "else", "self", ".", "attention_variables", "\n", "for", "atten_w", "in", "attn_list", ":", "\n", "            ", "for", "j", ",", "feature_w", "in", "enumerate", "(", "atten_w", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", ":", "\n", "              ", "tf", ".", "summary", ".", "scalar", "(", "'attention/'", "+", "self", ".", "feature_keys", "[", "j", "]", ",", "feature_w", ",", "\n", "global_step", ")", "\n", "", "", "", "", "self", ".", "writer", "[", "mode", "]", ".", "flush", "(", ")", "\n", "\n", "", "if", "global_step", "%", "self", ".", "log_steps", "==", "0", "or", "mode", "==", "'eval'", "or", "mode", "==", "'test'", ":", "\n", "      ", "logging", ".", "info", "(", "\n", "'%s : Step %d: loss = %f, mse = %f, mae = %f, label_val = %f '", ",", "mode", ",", "\n", "global_step", ",", "loss", ",", "mse", ",", "mae", ",", "avg_feature_label_value", ")", "\n", "\n", "", "if", "mode", "==", "'eval'", ":", "\n", "      ", "if", "self", ".", "use_attention", ":", "\n", "        ", "attn_list", "=", "self", ".", "attention_outputs", "if", "self", ".", "use_attn_output", "else", "self", ".", "attention_variables", "\n", "for", "atten_w", "in", "attn_list", ":", "\n", "          ", "for", "j", ",", "feature_w", "in", "enumerate", "(", "atten_w", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", ":", "\n", "            ", "key", "=", "'attention/'", "+", "self", ".", "feature_keys", "[", "j", "]", "\n", "\n", "", "", "for", "atten_w", "in", "attn_list", ":", "\n", "          ", "attention_log_str", "=", "[", "\n", "'attn/'", "+", "self", ".", "feature_keys", "[", "j", "]", "+", "':'", "+", "str", "(", "feature_w", ")", "\n", "for", "j", ",", "feature_w", "in", "enumerate", "(", "atten_w", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "]", "\n", "logging", ".", "info", "(", "attention_log_str", ")", "\n", "", "output_attention_variable", "(", "attn_list", ",", "self", ".", "feature_keys", ",", "global_step", ",", "\n", "self", ".", "experiment_log_path", ",", "self", ".", "job_prefix", ")", "\n", "\n", "", "", "if", "mode", "==", "'eval'", ":", "\n", "      ", "if", "loss", "<", "self", ".", "best_eval_loss", ":", "\n", "        ", "self", ".", "best_eval_loss", "=", "loss", "\n", "output_best_eval_csv", "(", "'loss'", ",", "loss", ",", "mse", ",", "mae", ",", "mode", ",", "global_step", ",", "\n", "self", ".", "experiment_log_path", ",", "self", ".", "job_prefix", ")", "\n", "", "if", "mse", "<", "self", ".", "best_eval_mse", ":", "\n", "        ", "self", ".", "best_eval_mse", "=", "mse", "\n", "output_best_eval_csv", "(", "'mse'", ",", "loss", ",", "mse", ",", "mae", ",", "mode", ",", "global_step", ",", "\n", "self", ".", "experiment_log_path", ",", "self", ".", "job_prefix", ")", "\n", "", "if", "mae", "<", "self", ".", "best_eval_mae", ":", "\n", "        ", "self", ".", "best_eval_mae", "=", "mae", "\n", "output_best_eval_csv", "(", "'mae'", ",", "loss", ",", "mse", ",", "mae", ",", "mode", ",", "global_step", ",", "\n", "self", ".", "experiment_log_path", ",", "self", ".", "job_prefix", ")", "\n", "\n", "", "", "if", "mode", "==", "'test'", ":", "\n", "      ", "output_best_eval_csv", "(", "''", ",", "loss", ",", "mse", ",", "mae", ",", "mode", ",", "global_step", ",", "\n", "self", ".", "experiment_log_path", ",", "self", ".", "job_prefix", ")", "\n", "\n", "", "return", "mse", ",", "mae", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.RegressionTask._parse_feature_index_str": [[350, 385], ["ValueError", "logging.info", "feature_indice_included_str.split", "feature_indice_excluded_str.split", "all", "ValueError", "int", "all", "ValueError", "range", "str", "int", "int", "int", "int"], "methods", ["None"], ["", "def", "_parse_feature_index_str", "(", "self", ",", "feature_indice_included_str", ",", "\n", "feature_indice_excluded_str", ")", ":", "\n", "    ", "\"\"\"Parse feature index string to list.\"\"\"", "\n", "feature_index_included", "=", "[", "]", "\n", "if", "feature_indice_included_str", "and", "feature_indice_excluded_str", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "'Only one of feature_indice_included_str and feature_indice_excluded_str can be non-empty.'", "\n", ")", "\n", "", "if", "not", "feature_indice_included_str", "and", "not", "feature_indice_excluded_str", ":", "\n", "      ", "logging", ".", "info", "(", "'No manual feature selection. All feature included.'", ")", "\n", "return", "feature_index_included", "\n", "\n", "", "if", "feature_indice_included_str", ":", "\n", "      ", "feature_index_included", "=", "feature_indice_included_str", ".", "split", "(", "','", ")", "\n", "if", "not", "all", "(", "\n", "int", "(", "i", ")", ">=", "0", "and", "int", "(", "i", ")", "<", "self", ".", "num_feature", "\n", "for", "i", "in", "feature_index_included", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f'values in feature_indice_included_str needs to be within [0, {self.num_feature}).'", "\n", ")", "\n", "", "feature_index_included", "=", "[", "int", "(", "i", ")", "for", "i", "in", "feature_index_included", "]", "\n", "", "if", "feature_indice_excluded_str", ":", "\n", "      ", "feature_index_excluded", "=", "feature_indice_excluded_str", ".", "split", "(", "','", ")", "\n", "if", "not", "all", "(", "\n", "int", "(", "i", ")", ">=", "0", "and", "int", "(", "i", ")", "<", "self", ".", "num_feature", "\n", "for", "i", "in", "feature_index_excluded", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f'values in  feature_indice_excluded_str needs to be within [0, {self.num_feature}).'", "\n", ")", "\n", "", "feature_index_included", "=", "[", "\n", "f", "for", "f", "in", "range", "(", "self", ".", "num_feature", ")", "\n", "if", "str", "(", "f", ")", "not", "in", "feature_index_excluded", "\n", "]", "\n", "\n", "", "return", "feature_index_included", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.RegressionTask.attention_variables": [[386, 393], ["ValueError"], "methods", ["None"], ["", "@", "property", "\n", "def", "attention_variables", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "use_attention", ":", "\n", "      ", "return", "self", ".", "attention", ".", "trainable_variables", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "'use pretrain_attention mode to access attention_variables'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.RegressionTask.attention_outputs": [[394, 400], ["ValueError"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "attention_outputs", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "use_attention", ":", "\n", "      ", "return", "self", ".", "attention", ".", "attention_outputs", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "'use attn_* mode to access attention_output'", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks._get_tensorboard_writer": [[23, 26], ["os.path.join", "tensorflow.summary.create_file_writer"], "function", ["None"], ["def", "_get_tensorboard_writer", "(", "experiment_log_path", ",", "job_prefix", ",", "mode", ",", "task", ")", ":", "\n", "  ", "path", "=", "os", ".", "path", ".", "join", "(", "experiment_log_path", ",", "job_prefix", ",", "'scalars'", ",", "task", ",", "mode", ")", "\n", "return", "tf", ".", "summary", ".", "create_file_writer", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.output_attention_variable": [[28, 44], ["file.Open", "csvfile.write", "str", "zip", "str", "atten_w.numpy().tolist", "atten_w.numpy"], "function", ["None"], ["", "def", "output_attention_variable", "(", "attention_list", ",", "feature_keys", ",", "step", ",", "\n", "experiment_log_path", ",", "job_prefix", ")", ":", "\n", "  ", "\"\"\"Ouptput attention var values to CSV file.\"\"\"", "\n", "csvfile", "=", "f'{experiment_log_path}/attention_{job_prefix}.csv'", "\n", "attention_val_str", "=", "''", "\n", "for", "atten_w", "in", "attention_list", ":", "\n", "# Note: there is only one layer in the attention layer definition.", "\n", "# Thus it only loops once here.", "\n", "    ", "attention_val_str", "=", "attention_val_str", "+", "','", ".", "join", "(", "[", "\n", "str", "(", "feature_key", ")", "+", "':'", "+", "str", "(", "feature_w", ")", "\n", "for", "feature_key", ",", "feature_w", "in", "zip", "(", "feature_keys", ",", "\n", "atten_w", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "]", ")", "\n", "\n", "", "with", "file", ".", "Open", "(", "csvfile", ",", "'w+'", ")", "as", "csvfile", ":", "\n", "    ", "csvfile", ".", "write", "(", "f'{step}:{attention_val_str}\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.output_best_eval_csv": [[46, 51], ["file.Open", "csvfile.write"], "function", ["None"], ["", "", "def", "output_best_eval_csv", "(", "export_metrics", ",", "loss", ",", "metrics1", ",", "metrics2", ",", "mode", ",", "step", ",", "\n", "experiment_log_path", ",", "job_prefix", ")", ":", "\n", "  ", "csvfile", "=", "f'{experiment_log_path}/best_{mode}_{export_metrics}_{job_prefix}.csv'", "\n", "with", "file", ".", "Open", "(", "csvfile", ",", "'wt'", ")", "as", "csvfile", ":", "\n", "    ", "csvfile", ".", "write", "(", "f'{loss},{metrics1},{metrics2},{step}\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.encoder_decoder.LSTMDecoder.__init__": [[23, 32], ["super().__init__", "kwargs.pop", "kwargs.pop", "kwargs.pop", "tensorflow.keras.layers.LSTM", "tensorflow.keras.layers.Dense"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_feature", "=", "kwargs", ".", "pop", "(", "'num_feature'", ")", "\n", "self", ".", "num_predict", "=", "kwargs", ".", "pop", "(", "'num_predict'", ")", "\n", "self", ".", "state_size", "=", "kwargs", ".", "pop", "(", "'state_size'", ")", "\n", "self", ".", "lstm_layer", "=", "tf", ".", "keras", ".", "layers", ".", "LSTM", "(", "\n", "units", "=", "self", ".", "state_size", ",", "return_state", "=", "True", ",", "name", "=", "'decoder'", ")", "\n", "self", ".", "obs_emission", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "self", ".", "num_feature", ",", "input_shape", "=", "(", "self", ".", "state_size", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.encoder_decoder.LSTMDecoder.lstm_one_step": [[33, 38], ["encoder_decoder.LSTMDecoder.lstm_layer", "tensorflow.expand_dims"], "methods", ["None"], ["", "def", "lstm_one_step", "(", "self", ",", "previous_output", ",", "previous_state", ")", ":", "\n", "    ", "current_output", ",", "current_state_h", ",", "current_state_c", "=", "self", ".", "lstm_layer", "(", "\n", "tf", ".", "expand_dims", "(", "previous_output", ",", "axis", "=", "1", ")", ",", "initial_state", "=", "previous_state", ")", "\n", "\n", "return", "current_output", ",", "[", "current_state_h", ",", "current_state_c", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.encoder_decoder.LSTMDecoder.state_tran_step_fn": [[39, 46], ["encoder_decoder.LSTMDecoder.lstm_one_step"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.encoder_decoder.LSTMDecoder.lstm_one_step"], ["", "def", "state_tran_step_fn", "(", "self", ",", "previous_tuple", ",", "dummy_input_elem", ")", ":", "\n", "    ", "del", "dummy_input_elem", "\n", "previous_output", ",", "previous_state", "=", "previous_tuple", "\n", "current_output", ",", "current_state", "=", "self", ".", "lstm_one_step", "(", "previous_output", ",", "\n", "previous_state", ")", "\n", "\n", "return", "(", "current_output", ",", "current_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.encoder_decoder.LSTMDecoder.forecast_value": [[47, 62], ["tensorflow.zeros", "tensorflow.scan", "tensorflow.transpose", "encoder_decoder.LSTMDecoder.obs_emission"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.models.DKFDynamicSystem.obs_emission"], ["", "def", "forecast_value", "(", "self", ",", "inputs", ")", ":", "\n", "    ", "dummy_input_sequence", "=", "tf", ".", "zeros", "(", "[", "self", ".", "num_predict", "]", ")", "\n", "# [state_h, state_c] = state", "\n", "forecast_output", ",", "_", "=", "tf", ".", "scan", "(", "\n", "self", ".", "state_tran_step_fn", ",", "\n", "elems", "=", "dummy_input_sequence", ",", "# just control the forecast length.", "\n", "initializer", "=", "inputs", ",", "# output, state from encoder", "\n", "parallel_iterations", "=", "10", ",", "\n", "name", "=", "'obs_forecast_scan'", ")", "\n", "# switch batch, tlen dimension back.", "\n", "# forecast_output shape [batch_size, num_predict, num_feature]", "\n", "forecast_output", "=", "tf", ".", "transpose", "(", "forecast_output", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "forecast_obs", "=", "self", ".", "obs_emission", "(", "forecast_output", ")", "\n", "# remove the last prediction from forecast_obs.", "\n", "return", "forecast_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.encoder_decoder.LSTMDecoder.call": [[63, 67], ["encoder_decoder.LSTMDecoder.forecast_value"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.encoder_decoder.LSTMDecoder.forecast_value"], ["", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "    ", "forecast_obs", "=", "self", ".", "forecast_value", "(", "inputs", ")", "\n", "# forecast_obs.shape (None, predict_horizon, num_feature)", "\n", "return", "forecast_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.encoder_decoder.MLPDecoder.__init__": [[72, 79], ["super().__init__", "customized_layers.MLPLayer"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "out", "=", "customized_layers", ".", "MLPLayer", "(", "\n", "num_layer", "=", "1", ",", "\n", "num_output_unit", "=", "1", ",", "\n", "num_hidden_unit", "=", "None", ",", "\n", "output_activation", "=", "'sigmoid'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.encoder_decoder.MLPDecoder.call": [[80, 84], ["encoder_decoder.MLPDecoder.out"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "    ", "output", ",", "_", "=", "inputs", "\n", "output", "=", "self", ".", "out", "(", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.encoder_decoder.LSTMEncoder.__init__": [[89, 94], ["super().__init__", "kwargs.pop", "tensorflow.keras.layers.LSTM"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "state_size", "=", "kwargs", ".", "pop", "(", "'state_size'", ")", "\n", "self", ".", "hidden_lstm", "=", "tf", ".", "keras", ".", "layers", ".", "LSTM", "(", "\n", "self", ".", "state_size", ",", "return_state", "=", "True", ",", "name", "=", "'LSTM_encoder'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.encoder_decoder.LSTMEncoder.call": [[95, 100], ["encoder_decoder.LSTMEncoder.hidden_lstm"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "x", ")", ":", "\n", "    ", "output", ",", "state_h", ",", "state_c", "=", "self", ".", "hidden_lstm", "(", "x", ")", "\n", "encoder_state", "=", "[", "state_h", ",", "state_c", "]", "\n", "\n", "return", "output", ",", "encoder_state", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.EncoderDecoderModel.__init__": [[517, 521], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ",", "**", "kwargs", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.EncoderDecoderModel.call": [[522, 532], ["meta_trainer.EncoderDecoderModel.decoder", "tensorflow.cast", "tensorflow.concat", "meta_trainer.EncoderDecoderModel.encoder", "meta_trainer.EncoderDecoderModel.encoder"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat"], ["", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "    ", "feature_value", ",", "feature_mask", "=", "inputs", "\n", "if", "FLAGS", ".", "use_mask_feature", ":", "\n", "      ", "feature_mask", "=", "tf", ".", "cast", "(", "feature_mask", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "feature_value_with_mask", "=", "tf", ".", "concat", "(", "[", "feature_value", ",", "feature_mask", "]", ",", "axis", "=", "2", ")", "\n", "output", ",", "state", "=", "self", ".", "encoder", "(", "feature_value_with_mask", ")", "\n", "", "else", ":", "\n", "      ", "output", ",", "state", "=", "self", ".", "encoder", "(", "feature_value", ")", "\n", "", "prediction", "=", "self", ".", "decoder", "(", "(", "output", ",", "state", ")", ")", "\n", "return", "prediction", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.EncoderDecoderModel.get_encoder": [[533, 535], ["None"], "methods", ["None"], ["", "def", "get_encoder", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.get_num_element": [[166, 170], ["sum", "int"], "function", ["None"], ["def", "get_num_element", "(", "dataset", ",", "data_percentage", ")", ":", "\n", "  ", "\"\"\"Get the num of elements in the dataset when data_percentage is used.\"\"\"", "\n", "total_num", "=", "sum", "(", "1", "for", "_", "in", "dataset", ")", "\n", "return", "int", "(", "total_num", "*", "data_percentage", "/", "100", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.get_datasets": [[172, 183], ["logging.info", "meta_trainer.generate_mimic_datasets", "ValueError"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.generate_mimic_datasets"], ["", "def", "get_datasets", "(", "dataset_name", ",", "data_path", ")", ":", "\n", "  ", "\"\"\"Get train, eval, test datasets and their config from the given dataset_name.\"\"\"", "\n", "if", "dataset_name", "==", "'mimic3'", ":", "\n", "    ", "logging", ".", "info", "(", "data_path", ")", "\n", "train_dataset", ",", "eval_dataset", ",", "test_dataset", ",", "dataset_config", "=", "generate_mimic_datasets", "(", "\n", "data_path", "=", "data_path", ",", "\n", "experiment_config_path", "=", "FLAGS", ".", "experiment_config", ",", "\n", "predict_horizon", "=", "FLAGS", ".", "predict_horizon", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "'dataset_name must be mimic3.'", ")", "\n", "", "return", "train_dataset", ",", "eval_dataset", ",", "test_dataset", ",", "dataset_config", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.generate_mimic_datasets": [[185, 207], ["mimic_data_gen.MIMIC3DataGenerator.from_config", "mimic_data_gen.MIMIC3DataGenerator.from_config.get_dataset", "mimic_data_gen.MIMIC3DataGenerator.from_config.get_dataset", "mimic_data_gen.MIMIC3DataGenerator.from_config.get_dataset", "mimic_data_gen.MIMIC3DataGenerator.from_config.get_config"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.state-space-model.data_provider.DataProvider.from_config"], ["", "def", "generate_mimic_datasets", "(", "data_path", ",", "experiment_config_path", ",", "predict_horizon", ")", ":", "\n", "  ", "\"\"\"Generate tf.dataset(s) with MIMIC3 data at given data_path.\n\n  Args:\n    data_path: Path to TF examples from mimic3 dataset.\n    experiment_config_path: Path to the experiment config for parse the TF\n      Example features.\n    predict_horizon: The length of time units for self-supervised prediction\n      task labels.\n\n  Returns:\n    Three tf.datasets for train, eval, test and a dataset_config.\n  \"\"\"", "\n", "gen", "=", "mimic_data_gen", ".", "MIMIC3DataGenerator", ".", "from_config", "(", "\n", "experiment_config", "=", "experiment_config_path", ",", "predict_horizon", "=", "predict_horizon", ")", "\n", "train_dataset", "=", "gen", ".", "get_dataset", "(", "data_path", "=", "data_path", ",", "mode", "=", "'train'", ")", "\n", "eval_dataset", "=", "gen", ".", "get_dataset", "(", "data_path", "=", "data_path", ",", "mode", "=", "'eval'", ")", "\n", "test_dataset", "=", "gen", ".", "get_dataset", "(", "data_path", "=", "data_path", ",", "mode", "=", "'test'", ")", "\n", "\n", "dataset_config", "=", "gen", ".", "get_config", "(", ")", "\n", "\n", "return", "train_dataset", ",", "eval_dataset", ",", "test_dataset", ",", "dataset_config", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._flatten_gradient": [[209, 213], ["tensorflow.concat", "tensorflow.reshape"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat"], ["", "def", "_flatten_gradient", "(", "grad_list", ")", ":", "\n", "  ", "flatten_gradient", "=", "tf", ".", "concat", "(", "[", "tf", ".", "reshape", "(", "var", ",", "[", "-", "1", "]", ")", "for", "var", "in", "grad_list", "]", ",", "\n", "axis", "=", "0", ")", "\n", "return", "flatten_gradient", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._flatten_hessian": [[215, 220], ["tensorflow.concat", "tensorflow.reshape"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat"], ["", "def", "_flatten_hessian", "(", "hessian_list", ")", ":", "\n", "  ", "flattened_hessians", "=", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "reshape", "(", "hess", ",", "[", "hess", ".", "shape", "[", "0", "]", ",", "-", "1", "]", ")", "for", "hess", "in", "hessian_list", "]", ",", "1", ")", "\n", "\n", "return", "flattened_hessians", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._apply_gradients": [[222, 224], ["optimizer.apply_gradients", "zip"], "function", ["None"], ["", "def", "_apply_gradients", "(", "optimizer", ",", "gradients", ",", "variables", ")", ":", "\n", "  ", "optimizer", ".", "apply_gradients", "(", "zip", "(", "gradients", ",", "variables", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.compute_loss": [[226, 251], ["decoder.call", "task.get_loss", "tensorflow.cast", "tensorflow.concat", "encoder.call", "encoder.call", "task.update_metrics"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.GraphConvolutionalTransformer.call", "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.EHRTransformer.get_loss", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.GraphConvolutionalTransformer.call", "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.GraphConvolutionalTransformer.call", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.tasks.RegressionTask.update_metrics"], ["", "def", "compute_loss", "(", "feature", ",", "\n", "label", ",", "\n", "encoder", ",", "\n", "decoder", ",", "\n", "task", ",", "\n", "mode", ",", "\n", "step", ",", "\n", "reset_metrics", "=", "False", ",", "\n", "update_metrics", "=", "True", ")", ":", "\n", "  ", "\"\"\"Compute loss and update the task metrics.\"\"\"", "\n", "feature_value", ",", "feature_mask", "=", "feature", "\n", "if", "FLAGS", ".", "use_mask_feature", ":", "\n", "    ", "feature_mask", "=", "tf", ".", "cast", "(", "feature_mask", ",", "dtype", "=", "feature_value", ".", "dtype", ")", "\n", "feature_value_with_mask", "=", "tf", ".", "concat", "(", "[", "feature_value", ",", "feature_mask", "]", ",", "axis", "=", "2", ")", "\n", "output", ",", "state", "=", "encoder", ".", "call", "(", "feature_value_with_mask", ")", "\n", "", "else", ":", "\n", "    ", "output", ",", "state", "=", "encoder", ".", "call", "(", "feature_value", ")", "\n", "", "prediction", "=", "decoder", ".", "call", "(", "(", "output", ",", "state", ")", ")", "\n", "\n", "loss", "=", "task", ".", "get_loss", "(", "label", ",", "prediction", ",", "mode", ")", "\n", "metrics", "=", "None", "\n", "if", "update_metrics", ":", "\n", "    ", "metrics", "=", "task", ".", "update_metrics", "(", "label", ",", "prediction", ",", "mode", ",", "step", ",", "reset_metrics", ")", "\n", "\n", "", "return", "state", ",", "prediction", ",", "loss", ",", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_batch_inner_unsupervised_hessian": [[253, 304], ["outer_tape.jacobian", "meta_trainer._flatten_hessian", "outer_tape.jacobian", "tensorflow.GradientTape", "inner_tape.gradient", "inner_tape.gradient", "meta_trainer._apply_gradients", "meta_trainer._apply_gradients", "meta_trainer._flatten_gradient", "tensorflow.GradientTape", "meta_trainer.compute_loss"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._flatten_hessian", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._apply_gradients", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._apply_gradients", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._flatten_gradient", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.compute_loss"], ["", "def", "train_batch_inner_unsupervised_hessian", "(", "batch_index", ",", "train_feature_batch", ",", "\n", "train_label_batch", ",", "encoder", ",", "\n", "unsupervised_decoder", ",", "\n", "regression_task", ",", "optimizer", ",", "\n", "global_train_step", ")", ":", "\n", "  ", "\"\"\"One self-supervised training step in meta learning with Hessian.\"\"\"", "\n", "with", "tf", ".", "GradientTape", "(", "persistent", "=", "True", ")", "as", "outer_tape", ":", "\n", "    ", "with", "tf", ".", "GradientTape", "(", "persistent", "=", "True", ")", "as", "inner_tape", ":", "\n", "      ", "_", ",", "_", ",", "unsupervised_loss", ",", "_", "=", "compute_loss", "(", "\n", "train_feature_batch", ",", "\n", "train_label_batch", ",", "\n", "encoder", ",", "\n", "unsupervised_decoder", ",", "\n", "regression_task", ",", "\n", "'train'", ",", "\n", "global_train_step", ",", "\n", "reset_metrics", "=", "batch_index", "==", "0", ",", "\n", "update_metrics", "=", "FLAGS", ".", "update_metrics_during_training", ")", "\n", "", "encoder_grad", "=", "inner_tape", ".", "gradient", "(", "unsupervised_loss", ",", "\n", "encoder", ".", "trainable_variables", ")", "\n", "decoder_grad", "=", "inner_tape", ".", "gradient", "(", "unsupervised_loss", ",", "\n", "unsupervised_decoder", ".", "trainable_variables", ")", "\n", "_apply_gradients", "(", "optimizer", ",", "encoder_grad", ",", "encoder", ".", "trainable_variables", ")", "\n", "_apply_gradients", "(", "optimizer", ",", "decoder_grad", ",", "\n", "unsupervised_decoder", ".", "trainable_variables", ")", "\n", "\n", "# with state_size = 10, encoder_grad (same as encoder.trainable_variables)", "\n", "# is a list of three tensors with shape (96, 40), (10, 40), (40,).", "\n", "# After flattenning, shape=(4280,)", "\n", "# Note that tf.hessian. tf.gradients is not supported when eager execution", "\n", "# is enabled.", "\n", "flattened_encoder_grad", "=", "_flatten_gradient", "(", "encoder_grad", ")", "\n", "\n", "# Note outer_tape.gradient only provides the diag vector of the hessian.", "\n", "# Need to use outer_tape.jacobian here.", "\n", "# hessian_encoder is a list of three tensors with shape", "\n", "# (4280, 96, 40),  (4280, 10, 40), (4280, 40),", "\n", "", "hessian_encoder", "=", "outer_tape", ".", "jacobian", "(", "flattened_encoder_grad", ",", "\n", "encoder", ".", "trainable_variables", ")", "\n", "\n", "flattened_hessians", "=", "_flatten_hessian", "(", "hessian_encoder", ")", "\n", "\n", "# j_encoder is a list of one tensors [(4280, 96)]", "\n", "j_encoder", "=", "outer_tape", ".", "jacobian", "(", "flattened_encoder_grad", ",", "\n", "regression_task", ".", "attention_variables", ")", "\n", "flattened_j_encoder", "=", "j_encoder", "[", "0", "]", "\n", "\n", "del", "inner_tape", "\n", "del", "outer_tape", "\n", "\n", "return", "flattened_hessians", ",", "flattened_j_encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_batch_inner_supervised_hessian": [[306, 342], ["outer_tape.jacobian", "meta_trainer._flatten_hessian", "tensorflow.GradientTape", "inner_tape.gradient", "inner_tape.gradient", "meta_trainer._apply_gradients", "meta_trainer._apply_gradients", "meta_trainer._flatten_gradient", "tensorflow.GradientTape", "meta_trainer.compute_loss"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._flatten_hessian", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._apply_gradients", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._apply_gradients", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._flatten_gradient", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.compute_loss"], ["", "def", "train_batch_inner_supervised_hessian", "(", "batch_index", ",", "train_feature_batch", ",", "\n", "train_label_batch", ",", "encoder", ",", "\n", "supervised_decoder", ",", "\n", "classification_task", ",", "optimizer", ",", "\n", "global_train_step", ")", ":", "\n", "  ", "\"\"\"One supervised training step in meta learning with Hessian.\"\"\"", "\n", "with", "tf", ".", "GradientTape", "(", "persistent", "=", "True", ")", "as", "outer_tape", ":", "\n", "    ", "with", "tf", ".", "GradientTape", "(", "persistent", "=", "True", ")", "as", "inner_tape", ":", "\n", "      ", "_", ",", "_", ",", "supervised_loss", ",", "_", "=", "compute_loss", "(", "\n", "train_feature_batch", ",", "\n", "train_label_batch", ",", "\n", "encoder", ",", "\n", "supervised_decoder", ",", "\n", "classification_task", ",", "\n", "'train'", ",", "\n", "global_train_step", ",", "\n", "reset_metrics", "=", "batch_index", "==", "0", ",", "\n", "update_metrics", "=", "FLAGS", ".", "update_metrics_during_training", ")", "\n", "\n", "", "encoder_grad", "=", "inner_tape", ".", "gradient", "(", "supervised_loss", ",", "\n", "encoder", ".", "trainable_variables", ")", "\n", "decoder_grad", "=", "inner_tape", ".", "gradient", "(", "supervised_loss", ",", "\n", "supervised_decoder", ".", "trainable_variables", ")", "\n", "_apply_gradients", "(", "optimizer", ",", "encoder_grad", ",", "encoder", ".", "trainable_variables", ")", "\n", "_apply_gradients", "(", "optimizer", ",", "decoder_grad", ",", "\n", "supervised_decoder", ".", "trainable_variables", ")", "\n", "flattened_encoder_grad", "=", "_flatten_gradient", "(", "encoder_grad", ")", "\n", "\n", "", "hessian_encoder", "=", "outer_tape", ".", "jacobian", "(", "flattened_encoder_grad", ",", "\n", "encoder", ".", "trainable_variables", ")", "\n", "flattened_hessians", "=", "_flatten_hessian", "(", "hessian_encoder", ")", "\n", "\n", "del", "inner_tape", "\n", "del", "outer_tape", "\n", "\n", "return", "flattened_hessians", ",", "encoder_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_batch_inner_unsupervised_approx": [[344, 370], ["inner_tape.gradient", "meta_trainer._apply_gradients", "inner_tape.gradient", "inner_tape.gradient", "tensorflow.GradientTape", "meta_trainer.compute_loss"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._apply_gradients", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.compute_loss"], ["", "def", "train_batch_inner_unsupervised_approx", "(", "batch_index", ",", "train_feature_batch", ",", "\n", "train_label_batch", ",", "encoder", ",", "\n", "unsupervised_decoder", ",", "regression_task", ",", "\n", "optimizer", ",", "global_train_step", ")", ":", "\n", "  ", "\"\"\"One unsupervised training step in meta learning with approximation.\"\"\"", "\n", "with", "tf", ".", "GradientTape", "(", "persistent", "=", "True", ")", "as", "inner_tape", ":", "\n", "    ", "_", ",", "_", ",", "unsupervised_loss", ",", "_", "=", "compute_loss", "(", "\n", "train_feature_batch", ",", "\n", "train_label_batch", ",", "\n", "encoder", ",", "\n", "unsupervised_decoder", ",", "\n", "regression_task", ",", "\n", "'train'", ",", "\n", "global_train_step", ",", "\n", "reset_metrics", "=", "batch_index", "==", "0", ")", "\n", "", "innner_grad", "=", "inner_tape", ".", "gradient", "(", "\n", "unsupervised_loss", ",", "\n", "encoder", ".", "trainable_variables", "+", "unsupervised_decoder", ".", "trainable_variables", ")", "\n", "_apply_gradients", "(", "\n", "optimizer", ",", "innner_grad", ",", "\n", "encoder", ".", "trainable_variables", "+", "unsupervised_decoder", ".", "trainable_variables", ")", "\n", "dLu_dphi", "=", "inner_tape", ".", "gradient", "(", "unsupervised_loss", ",", "encoder", ".", "trainable_variables", ")", "# pylint: disable=invalid-name", "\n", "dLu_dlambda", "=", "inner_tape", ".", "gradient", "(", "# pylint: disable=invalid-name", "\n", "unsupervised_loss", ",", "regression_task", ".", "attention_variables", ")", "\n", "del", "inner_tape", "\n", "return", "dLu_dphi", ",", "dLu_dlambda", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_batch_inner_supervised_approx": [[372, 422], ["inner_tape_train.gradient", "meta_trainer._apply_gradients", "inner_tape_eval.gradient", "tensorflow.GradientTape", "meta_trainer.compute_loss", "tensorflow.GradientTape", "meta_trainer.compute_loss"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._apply_gradients", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.compute_loss", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.compute_loss"], ["", "def", "train_batch_inner_supervised_approx", "(", "batch_index", ",", "train_feature_batch", ",", "\n", "train_label_batch", ",", "eval_dataset", ",", "\n", "encoder", ",", "supervised_decoder", ",", "\n", "classification_task", ",", "optimizer", ",", "\n", "global_train_step", ")", ":", "\n", "  ", "\"\"\"One supervised training step in meta learning with approximation.\"\"\"", "\n", "\n", "with", "tf", ".", "GradientTape", "(", "persistent", "=", "True", ")", "as", "inner_tape_train", ":", "\n", "# Loss on train dataset for gradient update to simulate fine tuning of", "\n", "# classification head.", "\n", "    ", "_", ",", "_", ",", "supervised_train_loss", ",", "_", "=", "compute_loss", "(", "\n", "train_feature_batch", ",", "\n", "train_label_batch", ",", "\n", "encoder", ",", "\n", "supervised_decoder", ",", "\n", "classification_task", ",", "\n", "'train'", ",", "\n", "global_train_step", ",", "\n", "reset_metrics", "=", "batch_index", "==", "0", ",", "\n", "update_metrics", "=", "False", ")", "\n", "\n", "# fine tuning classification head.", "\n", "", "supervised_head_grad", "=", "inner_tape_train", ".", "gradient", "(", "\n", "supervised_train_loss", ",", "supervised_decoder", ".", "trainable_variables", ")", "\n", "_apply_gradients", "(", "optimizer", ",", "supervised_head_grad", ",", "\n", "supervised_decoder", ".", "trainable_variables", ")", "\n", "\n", "with", "tf", ".", "GradientTape", "(", "persistent", "=", "True", ")", "as", "inner_tape_eval", ":", "\n", "# Only one step as eval_batch_size is the same/larger than eval datasize.", "\n", "    ", "for", "(", "eval_feature_batch", ",", "eval_supervised_label_batch", ",", "\n", "eval_unsupervised_label_batch", ")", "in", "eval_dataset", ":", "\n", "      ", "eval_label_batch", "=", "(", "eval_supervised_label_batch", ",", "\n", "eval_unsupervised_label_batch", ")", "\n", "_", ",", "_", ",", "supervised_eval_loss", ",", "_", "=", "compute_loss", "(", "\n", "eval_feature_batch", ",", "\n", "eval_label_batch", ",", "\n", "encoder", ",", "\n", "supervised_decoder", ",", "\n", "classification_task", ",", "\n", "'train'", ",", "\n", "global_train_step", ",", "\n", "reset_metrics", "=", "False", ",", "\n", "update_metrics", "=", "False", ")", "\n", "\n", "# Compute hyper-gradient.", "\n", "", "", "dLs_dphi", "=", "inner_tape_eval", ".", "gradient", "(", "# pylint: disable=invalid-name", "\n", "supervised_eval_loss", ",", "encoder", ".", "trainable_variables", ")", "\n", "del", "inner_tape_eval", "\n", "del", "inner_tape_train", "\n", "return", "dLs_dphi", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_batch_cotrain": [[424, 457], ["tape.gradient", "tape.gradient", "tape.gradient", "meta_trainer._apply_gradients", "meta_trainer._apply_gradients", "meta_trainer._apply_gradients", "tensorflow.GradientTape", "meta_trainer.compute_loss", "meta_trainer.compute_loss"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._apply_gradients", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._apply_gradients", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._apply_gradients", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.compute_loss", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.compute_loss"], ["", "def", "train_batch_cotrain", "(", "\n", "unsupervised_train_feature_batch", ",", "unsupervised_train_label_batch", ",", "\n", "supervised_train_feature_batch", ",", "supervised_train_supervised_label_batch", ",", "\n", "encoder", ",", "unsupervised_decoder", ",", "supervised_decoder", ",", "regression_task", ",", "\n", "classification_task", ",", "unsupervised_optimizer", ",", "supervised_optimizer", ",", "step", ")", ":", "\n", "  ", "\"\"\"One training step.\"\"\"", "\n", "with", "tf", ".", "GradientTape", "(", "persistent", "=", "True", ")", "as", "tape", ":", "\n", "    ", "_", ",", "_", ",", "regression_loss", ",", "_", "=", "compute_loss", "(", "unsupervised_train_feature_batch", ",", "\n", "unsupervised_train_label_batch", ",", "\n", "encoder", ",", "unsupervised_decoder", ",", "\n", "regression_task", ",", "'train'", ",", "step", ")", "\n", "_", ",", "_", ",", "classification_loss", ",", "_", "=", "compute_loss", "(", "\n", "supervised_train_feature_batch", ",", "supervised_train_supervised_label_batch", ",", "\n", "encoder", ",", "supervised_decoder", ",", "classification_task", ",", "'train'", ",", "step", ")", "\n", "\n", "aggregated_loss", "=", "regression_loss", "+", "(", "\n", "FLAGS", ".", "cotrain_classification_loss_factor", "*", "classification_loss", ")", "\n", "\n", "", "encoder_gradients", "=", "tape", ".", "gradient", "(", "aggregated_loss", ",", "\n", "encoder", ".", "trainable_variables", ")", "\n", "unsupervised_decoder_gradients", "=", "tape", ".", "gradient", "(", "\n", "aggregated_loss", ",", "unsupervised_decoder", ".", "trainable_variables", ")", "\n", "supervised_decoder_gradients", "=", "tape", ".", "gradient", "(", "\n", "aggregated_loss", ",", "supervised_decoder", ".", "trainable_variables", ")", "\n", "\n", "_apply_gradients", "(", "unsupervised_optimizer", ",", "encoder_gradients", ",", "\n", "encoder", ".", "trainable_variables", ")", "\n", "_apply_gradients", "(", "unsupervised_optimizer", ",", "unsupervised_decoder_gradients", ",", "\n", "unsupervised_decoder", ".", "trainable_variables", ")", "\n", "_apply_gradients", "(", "supervised_optimizer", ",", "supervised_decoder_gradients", ",", "\n", "supervised_decoder", ".", "trainable_variables", ")", "\n", "\n", "del", "tape", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_batch": [[459, 474], ["tape.gradient", "tape.gradient", "tensorflow.GradientTape", "meta_trainer.compute_loss", "meta_trainer._apply_gradients", "meta_trainer._apply_gradients"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.compute_loss", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._apply_gradients", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._apply_gradients"], ["", "def", "train_batch", "(", "feature", ",", "label", ",", "encoder", ",", "decoder", ",", "task", ",", "optimizer", ",", "step", ",", "\n", "freeze_encoder", ")", ":", "\n", "  ", "\"\"\"One training step.\"\"\"", "\n", "with", "tf", ".", "GradientTape", "(", "persistent", "=", "True", ")", "as", "tape", ":", "\n", "    ", "_", ",", "_", ",", "loss", ",", "_", "=", "compute_loss", "(", "feature", ",", "label", ",", "encoder", ",", "decoder", ",", "task", ",", "\n", "'train'", ",", "step", ")", "\n", "", "encoder_gradients", "=", "tape", ".", "gradient", "(", "loss", ",", "encoder", ".", "trainable_variables", ")", "\n", "decoder_gradients", "=", "tape", ".", "gradient", "(", "loss", ",", "decoder", ".", "trainable_variables", ")", "\n", "\n", "if", "freeze_encoder", ":", "\n", "    ", "_apply_gradients", "(", "optimizer", ",", "decoder_gradients", ",", "decoder", ".", "trainable_variables", ")", "\n", "", "else", ":", "\n", "    ", "_apply_gradients", "(", "optimizer", ",", "encoder_gradients", "+", "decoder_gradients", ",", "\n", "encoder", ".", "trainable_variables", "+", "decoder", ".", "trainable_variables", ")", "\n", "", "del", "tape", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.eval_all": [[476, 492], ["enumerate", "meta_trainer.compute_loss"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.compute_loss"], ["", "def", "eval_all", "(", "eval_dataset", ",", "encoder", ",", "decoder", ",", "task", ",", "mode", ",", "train_step", ")", ":", "\n", "  ", "\"\"\"Eval the entire eval_dataset.\"\"\"", "\n", "for", "eval_step", ",", "(", "eval_feature_batch", ",", "eval_supervised_label_batch", ",", "\n", "eval_unsupervised_label_batch", ")", "in", "enumerate", "(", "eval_dataset", ")", ":", "\n", "    ", "eval_label_batch", "=", "(", "eval_supervised_label_batch", ",", "\n", "eval_unsupervised_label_batch", ")", "\n", "state", ",", "prediction", ",", "loss", ",", "metrics", "=", "compute_loss", "(", "\n", "eval_feature_batch", ",", "\n", "eval_label_batch", ",", "\n", "encoder", ",", "\n", "decoder", ",", "\n", "task", ",", "\n", "mode", ",", "\n", "train_step", "+", "eval_step", ",", "\n", "reset_metrics", "=", "eval_step", "==", "0", ")", "\n", "", "return", "state", ",", "prediction", ",", "loss", ",", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.continuous_eval": [[494, 512], ["meta_trainer.eval_all", "meta_trainer.eval_all", "meta_trainer.copy_encoder", "meta_trainer.eval_all"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.eval_all", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.eval_all", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.copy_encoder", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.eval_all"], ["", "def", "continuous_eval", "(", "eval_dataset", ",", "test_dataset", ",", "train_feature_batch", ",", "encoder", ",", "\n", "best_encoder", ",", "unsupervised_decoder", ",", "supervised_decoder", ",", "\n", "regression_task", ",", "classification_task", ",", "best_metrics", ",", "\n", "global_train_step", ")", ":", "\n", "  ", "\"\"\"Check and run eval at global_train_step.\"\"\"", "\n", "if", "global_train_step", "%", "FLAGS", ".", "eval_unsupervised_every_nsteps", "==", "0", ":", "\n", "    ", "eval_all", "(", "eval_dataset", ",", "encoder", ",", "unsupervised_decoder", ",", "regression_task", ",", "\n", "'eval'", ",", "global_train_step", ")", "\n", "", "if", "global_train_step", "%", "FLAGS", ".", "eval_supervised_every_nsteps", "==", "0", ":", "\n", "    ", "_", ",", "_", ",", "_", ",", "metrics", "=", "eval_all", "(", "eval_dataset", ",", "encoder", ",", "supervised_decoder", ",", "\n", "classification_task", ",", "'eval'", ",", "global_train_step", ")", "\n", "auc", ",", "_", "=", "metrics", "\n", "if", "auc", ">", "best_metrics", ":", "\n", "      ", "best_metrics", "=", "auc", "\n", "best_encoder", "=", "copy_encoder", "(", "encoder", ",", "train_feature_batch", ")", "\n", "eval_all", "(", "test_dataset", ",", "encoder", ",", "supervised_decoder", ",", "classification_task", ",", "\n", "'test'", ",", "global_train_step", ")", "\n", "", "", "return", "best_metrics", ",", "best_encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.copy_encoder": [[537, 563], ["encoder_model", "encoder_model.set_weights", "tensorflow.cast", "tensorflow.concat", "encoder_model.call", "encoder_model.call", "encoder.get_weights"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.GraphConvolutionalTransformer.call", "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.GraphConvolutionalTransformer.call"], ["", "", "def", "copy_encoder", "(", "encoder", ",", "x", ")", ":", "\n", "  ", "\"\"\"Copy model weights to a new model.\n\n  Args:\n    encoder: encoder model to be copied.\n    x: An input example. This is used to run a forward pass in order to add the\n      weights of the graph as variables.\n\n  Returns:\n      A copy of the model.\n  \"\"\"", "\n", "encoder_model", "=", "ENCODER_MAP", "[", "FLAGS", ".", "encoder_name", "]", "\n", "copied_encoder", "=", "encoder_model", "(", "state_size", "=", "FLAGS", ".", "state_size", ")", "\n", "\n", "# If we don't run this step the weights are not \"initialized\"", "\n", "# and the gradients will not be computed.", "\n", "feature_value", ",", "feature_mask", "=", "x", "\n", "\n", "if", "FLAGS", ".", "use_mask_feature", ":", "\n", "    ", "feature_mask", "=", "tf", ".", "cast", "(", "feature_mask", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "feature_value_with_mask", "=", "tf", ".", "concat", "(", "[", "feature_value", ",", "feature_mask", "]", ",", "axis", "=", "2", ")", "\n", "_", ",", "_", "=", "copied_encoder", ".", "call", "(", "feature_value_with_mask", ")", "\n", "", "else", ":", "\n", "    ", "copied_encoder", ".", "call", "(", "feature_value", ")", "\n", "", "copied_encoder", ".", "set_weights", "(", "encoder", ".", "get_weights", "(", ")", ")", "\n", "return", "copied_encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_supervising_unsupervised_model_attn_hessian": [[565, 706], ["len", "print", "encoder_model", "print", "unsupervised_decoder_model", "print", "supervised_decoder_model", "train_dataset.batch.batch", "eval_dataset.batch.batch", "test_dataset.batch.batch", "tensorflow.keras.optimizers.Adam", "tensorflow.keras.optimizers.Adam", "tensorflow.keras.optimizers.Adam", "tasks.RegressionTask", "tasks.ClassificationTask", "meta_trainer.get_num_element", "meta_trainer.get_num_element", "train_dataset.batch.take", "iter", "iter", "range", "ValueError", "range", "range", "tensorflow.expand_dims", "range", "tensorflow.Variable", "range", "meta_trainer._apply_gradients", "meta_trainer.continuous_eval", "next", "meta_trainer.train_batch_inner_unsupervised_hessian", "hessian_encoder_list.append", "j_encoder_list.append", "next", "meta_trainer.train_batch_inner_supervised_hessian", "hessian_encoder_list.append", "meta_trainer._flatten_gradient", "tensorflow.matmul", "tensorflow.matmul", "iter", "iter", "tensorflow.zeros_initializer", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.get_num_element", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.get_num_element", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._apply_gradients", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.continuous_eval", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_batch_inner_unsupervised_hessian", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_batch_inner_supervised_hessian", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._flatten_gradient"], ["", "def", "train_supervising_unsupervised_model_attn_hessian", "(", "train_dataset", ",", "\n", "eval_dataset", ",", "\n", "test_dataset", ",", "\n", "dataset_config", ")", ":", "\n", "  ", "\"\"\"Targeted unsupervised learning to optimize given supervised objective.\"\"\"", "\n", "# In this method, the hessian matrix is implemented directly.", "\n", "feature_keys", ",", "num_predict", "=", "dataset_config", "\n", "num_feature", "=", "len", "(", "feature_keys", ")", "\n", "\n", "encoder_model", "=", "ENCODER_MAP", "[", "FLAGS", ".", "encoder_name", "]", "\n", "print", "(", "'create new encoder: '", "+", "FLAGS", ".", "encoder_name", ")", "\n", "encoder", "=", "encoder_model", "(", "state_size", "=", "FLAGS", ".", "state_size", ")", "\n", "\n", "unsupervised_decoder_model", "=", "DECODER_MAP", "[", "FLAGS", ".", "unsupervised_decoder_name", "]", "\n", "print", "(", "'create new decoder: '", "+", "FLAGS", ".", "unsupervised_decoder_name", ")", "\n", "unsupervised_decoder", "=", "unsupervised_decoder_model", "(", "\n", "num_feature", "=", "num_feature", ",", "\n", "num_predict", "=", "num_predict", ",", "\n", "state_size", "=", "FLAGS", ".", "state_size", ")", "\n", "\n", "supervised_decoder_model", "=", "DECODER_MAP", "[", "FLAGS", ".", "supervised_decoder_name", "]", "\n", "print", "(", "'create new decoder: '", "+", "FLAGS", ".", "supervised_decoder_name", ")", "\n", "supervised_decoder", "=", "supervised_decoder_model", "(", ")", "\n", "\n", "train_dataset", "=", "train_dataset", ".", "batch", "(", "FLAGS", ".", "train_batch_size", ")", "\n", "eval_dataset", "=", "eval_dataset", ".", "batch", "(", "FLAGS", ".", "eval_batch_size", ")", "\n", "test_dataset", "=", "test_dataset", ".", "batch", "(", "FLAGS", ".", "eval_batch_size", ")", "\n", "\n", "unsupervised_optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "\n", "learning_rate", "=", "FLAGS", ".", "unsupervised_learning_rate", ",", "\n", "clipvalue", "=", "_GRADIENT_CLIP_VALUE", ")", "\n", "supervised_optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "\n", "learning_rate", "=", "FLAGS", ".", "supervised_learning_rate", ",", "\n", "clipvalue", "=", "_GRADIENT_CLIP_VALUE", ")", "\n", "attention_optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "\n", "learning_rate", "=", "FLAGS", ".", "attention_learning_rate", ",", "\n", "clipvalue", "=", "_GRADIENT_CLIP_VALUE", ")", "\n", "\n", "if", "FLAGS", ".", "unsupervised_train_with_keras_model_fit", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "'unsupervised_train_with_keras_model_fit not supported under attn_hessian'", "\n", ")", "\n", "\n", "", "regression_task", "=", "tasks", ".", "RegressionTask", "(", "\n", "num_feature", ",", "num_predict", ",", "FLAGS", ".", "target_feature_index", ",", "\n", "FLAGS", ".", "feature_indice_included_str", ",", "FLAGS", ".", "feature_indice_excluded_str", ",", "\n", "feature_keys", ",", "FLAGS", ".", "log_steps", ",", "FLAGS", ".", "export_to_tensorboard", ",", "\n", "FLAGS", ".", "experiment_log_path", ",", "FLAGS", ".", "job_prefix", ",", "\n", "FLAGS", ".", "forecast_only_nonmask_values", ",", "FLAGS", ".", "forecast_loss_func", ",", "\n", "FLAGS", ".", "use_attention", ",", "FLAGS", ".", "normalization_model", ",", "\n", "FLAGS", ".", "attention_init_value", ",", "FLAGS", ".", "use_attn_output", ")", "\n", "\n", "classification_task", "=", "tasks", ".", "ClassificationTask", "(", "FLAGS", ".", "log_steps", ",", "\n", "FLAGS", ".", "export_to_tensorboard", ",", "\n", "FLAGS", ".", "experiment_log_path", ",", "\n", "FLAGS", ".", "job_prefix", ")", "\n", "global_train_step", "=", "0", "\n", "best_metrics", "=", "0", "\n", "best_encoder", "=", "encoder", "\n", "num_batch_supervised_train_dataset", "=", "get_num_element", "(", "\n", "train_dataset", ",", "FLAGS", ".", "train_data_percentage", ")", "\n", "num_batch_unsupervised_train_dataset", "=", "get_num_element", "(", "train_dataset", ",", "100", ")", "\n", "\n", "supervised_train_dataset", "=", "train_dataset", ".", "take", "(", "\n", "num_batch_supervised_train_dataset", ")", "\n", "unsupervised_iter", "=", "iter", "(", "train_dataset", ")", "\n", "supervised_iter", "=", "iter", "(", "supervised_train_dataset", ")", "\n", "unsupervised_batch_index", "=", "0", "\n", "supervised_batch_index", "=", "0", "\n", "\n", "for", "_", "in", "range", "(", "FLAGS", ".", "num_epochs_outer_attention", ")", ":", "\n", "    ", "hessian_encoder_list", "=", "[", "]", "\n", "j_encoder_list", "=", "[", "]", "\n", "\n", "for", "_", "in", "range", "(", "FLAGS", ".", "num_steps_unsupervised", ")", ":", "\n", "      ", "(", "unsupervised_train_feature_batch", ",", "\n", "unsupervised_train_supervised_label_batch", ",", "\n", "unsupervised_train_unsupervised_label_batch", ")", "=", "next", "(", "unsupervised_iter", ")", "\n", "unsupervised_batch_index", "+=", "1", "\n", "unsupervised_train_label_batch", "=", "(", "\n", "unsupervised_train_supervised_label_batch", ",", "\n", "unsupervised_train_unsupervised_label_batch", ")", "\n", "hessian_encoder", ",", "j_encoder", "=", "train_batch_inner_unsupervised_hessian", "(", "\n", "unsupervised_batch_index", ",", "unsupervised_train_feature_batch", ",", "\n", "unsupervised_train_label_batch", ",", "encoder", ",", "unsupervised_decoder", ",", "\n", "regression_task", ",", "unsupervised_optimizer", ",", "global_train_step", ")", "\n", "\n", "if", "unsupervised_batch_index", ">=", "num_batch_unsupervised_train_dataset", ":", "\n", "        ", "unsupervised_iter", "=", "iter", "(", "train_dataset", ")", "\n", "unsupervised_batch_index", "=", "0", "\n", "# hessian_encoder_reshape shape [num_encoder_weights, num_encoder_weights]", "\n", "", "hessian_encoder_list", ".", "append", "(", "FLAGS", ".", "unsupervised_learning_rate", "*", "\n", "hessian_encoder", ")", "\n", "# j_encoder matrix with shape num_attention_weights * num_encoder_weights.", "\n", "j_encoder_list", ".", "append", "(", "FLAGS", ".", "unsupervised_learning_rate", "*", "j_encoder", ")", "\n", "global_train_step", "+=", "1", "\n", "\n", "", "for", "_", "in", "range", "(", "FLAGS", ".", "num_steps_supervised", ")", ":", "\n", "      ", "(", "supervised_train_feature_batch", ",", "supervised_train_supervised_label_batch", ",", "\n", "supervised_train_unsupervised_label_batch", ")", "=", "next", "(", "supervised_iter", ")", "\n", "supervised_batch_index", "+=", "1", "\n", "supervised_train_label_batch", "=", "(", "supervised_train_supervised_label_batch", ",", "\n", "supervised_train_unsupervised_label_batch", ")", "\n", "hessian_encoder", ",", "encoder_grad", "=", "train_batch_inner_supervised_hessian", "(", "\n", "supervised_batch_index", ",", "supervised_train_feature_batch", ",", "\n", "supervised_train_label_batch", ",", "encoder", ",", "supervised_decoder", ",", "\n", "classification_task", ",", "supervised_optimizer", ",", "global_train_step", ")", "\n", "if", "supervised_batch_index", ">=", "num_batch_supervised_train_dataset", ":", "\n", "        ", "supervised_iter", "=", "iter", "(", "supervised_train_dataset", ")", "\n", "supervised_batch_index", "=", "0", "\n", "", "hessian_encoder_list", ".", "append", "(", "FLAGS", ".", "supervised_learning_rate", "*", "\n", "hessian_encoder", ")", "\n", "# list with len num_encoder_weights (4280,)", "\n", "", "beta", "=", "encoder_grad", "\n", "# beta_reshape shape=(1, 4280)", "\n", "beta_reshape", "=", "tf", ".", "expand_dims", "(", "_flatten_gradient", "(", "beta", ")", ",", "axis", "=", "0", ")", "\n", "\n", "for", "index", "in", "range", "(", "FLAGS", ".", "num_steps_supervised", ")", ":", "\n", "# hessian_encoder [num_encoder_weights, num_encoder_weights]", "\n", "      ", "beta_reshape", "=", "tf", ".", "matmul", "(", "beta_reshape", ",", "\n", "(", "1", "-", "hessian_encoder_list", "[", "-", "(", "index", "+", "1", ")", "]", ")", ")", "\n", "", "alpha", "=", "beta_reshape", "\n", "attention_grad", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros_initializer", "(", ")", "(", "\n", "shape", "=", "[", "num_feature", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "\n", "for", "index", "in", "range", "(", "FLAGS", ".", "num_steps_unsupervised", ")", ":", "\n", "      ", "attention_grad", "=", "attention_grad", "-", "(", "\n", "tf", ".", "matmul", "(", "alpha", ",", "j_encoder_list", "[", "-", "(", "index", "+", "1", ")", "]", ")", ")", "\n", "hessian_encoder_reshape", "=", "hessian_encoder_list", "[", "-", "(", "\n", "FLAGS", ".", "num_steps_supervised", "+", "index", "+", "1", ")", "]", "\n", "alpha", "=", "tf", ".", "matmul", "(", "alpha", ",", "(", "1", "-", "hessian_encoder_reshape", ")", ")", "\n", "", "_apply_gradients", "(", "attention_optimizer", ",", "attention_grad", ",", "\n", "regression_task", ".", "attention_variables", ")", "\n", "\n", "# continuous eval.", "\n", "best_metrics", ",", "best_encoder", "=", "continuous_eval", "(", "\n", "eval_dataset", ",", "test_dataset", ",", "unsupervised_train_feature_batch", ",", "encoder", ",", "\n", "best_encoder", ",", "unsupervised_decoder", ",", "supervised_decoder", ",", "regression_task", ",", "\n", "classification_task", ",", "best_metrics", ",", "global_train_step", ")", "\n", "\n", "", "return", "encoder", ",", "best_encoder", ",", "global_train_step", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_supervising_unsupervised_model_attn_approx": [[708, 847], ["len", "print", "encoder_model", "print", "unsupervised_decoder_model", "print", "supervised_decoder_model", "tensorflow.keras.optimizers.Adam", "tensorflow.keras.optimizers.Adam", "tensorflow.keras.optimizers.Adam", "tasks.RegressionTask", "tasks.ClassificationTask", "train_dataset.batch.batch", "eval_dataset.batch.batch", "test_dataset.batch.batch", "meta_trainer.get_num_element", "meta_trainer.get_num_element", "train_dataset.batch.take", "iter", "iter", "range", "ValueError", "range", "range", "next", "meta_trainer.train_batch_inner_unsupervised_approx", "meta_trainer.continuous_eval", "next", "meta_trainer.train_batch_inner_supervised_approx", "meta_trainer.continuous_eval", "meta_trainer._flatten_gradient", "meta_trainer._flatten_gradient", "meta_trainer._flatten_gradient", "tensorflow.matmul", "tensorflow.clip_by_value", "tensorflow.squeeze", "tensorflow.clip_by_value", "meta_trainer._apply_gradients", "iter", "iter", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.matmul", "tensorflow.math.reciprocal", "tensorflow.expand_dims", "tf.clip_by_value.numpy"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.get_num_element", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.get_num_element", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_batch_inner_unsupervised_approx", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.continuous_eval", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_batch_inner_supervised_approx", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.continuous_eval", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._flatten_gradient", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._flatten_gradient", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._flatten_gradient", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer._apply_gradients"], ["", "def", "train_supervising_unsupervised_model_attn_approx", "(", "train_dataset", ",", "\n", "train_data_percentage", ",", "\n", "eval_dataset", ",", "test_dataset", ",", "\n", "dataset_config", ")", ":", "\n", "  ", "\"\"\"Train a baseline supervised model based on binary label.\"\"\"", "\n", "feature_keys", ",", "num_predict", "=", "dataset_config", "\n", "num_feature", "=", "len", "(", "feature_keys", ")", "\n", "\n", "encoder_model", "=", "ENCODER_MAP", "[", "FLAGS", ".", "encoder_name", "]", "\n", "print", "(", "'create new encoder: '", "+", "FLAGS", ".", "encoder_name", ")", "\n", "encoder", "=", "encoder_model", "(", "state_size", "=", "FLAGS", ".", "state_size", ")", "\n", "\n", "unsupervised_decoder_model", "=", "DECODER_MAP", "[", "FLAGS", ".", "unsupervised_decoder_name", "]", "\n", "print", "(", "'create new decoder: '", "+", "FLAGS", ".", "unsupervised_decoder_name", ")", "\n", "unsupervised_decoder", "=", "unsupervised_decoder_model", "(", "\n", "num_feature", "=", "num_feature", ",", "\n", "num_predict", "=", "num_predict", ",", "\n", "state_size", "=", "FLAGS", ".", "state_size", ")", "\n", "\n", "supervised_decoder_model", "=", "DECODER_MAP", "[", "FLAGS", ".", "supervised_decoder_name", "]", "\n", "print", "(", "'create new decoder: '", "+", "FLAGS", ".", "supervised_decoder_name", ")", "\n", "supervised_decoder", "=", "supervised_decoder_model", "(", ")", "\n", "\n", "unsupervised_optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "\n", "learning_rate", "=", "FLAGS", ".", "unsupervised_learning_rate", ",", "\n", "clipvalue", "=", "_GRADIENT_CLIP_VALUE", ")", "\n", "supervised_optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "\n", "learning_rate", "=", "FLAGS", ".", "supervised_learning_rate", ",", "\n", "clipvalue", "=", "_GRADIENT_CLIP_VALUE", ")", "\n", "attention_optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "\n", "learning_rate", "=", "FLAGS", ".", "attention_learning_rate", ",", "\n", "clipvalue", "=", "_GRADIENT_CLIP_VALUE", ")", "\n", "\n", "if", "FLAGS", ".", "unsupervised_train_with_keras_model_fit", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "'unsupervised_train_with_keras_model_fit not supported under attn_approx'", "\n", ")", "\n", "\n", "", "regression_task", "=", "tasks", ".", "RegressionTask", "(", "\n", "num_feature", ",", "num_predict", ",", "FLAGS", ".", "target_feature_index", ",", "\n", "FLAGS", ".", "feature_indice_included_str", ",", "FLAGS", ".", "feature_indice_excluded_str", ",", "\n", "feature_keys", ",", "FLAGS", ".", "log_steps", ",", "FLAGS", ".", "export_to_tensorboard", ",", "\n", "FLAGS", ".", "experiment_log_path", ",", "FLAGS", ".", "job_prefix", ",", "\n", "FLAGS", ".", "forecast_only_nonmask_values", ",", "FLAGS", ".", "forecast_loss_func", ",", "\n", "FLAGS", ".", "use_attention", ",", "FLAGS", ".", "normalization_model", ",", "\n", "FLAGS", ".", "attention_init_value", ",", "FLAGS", ".", "use_attn_output", ")", "\n", "\n", "classification_task", "=", "tasks", ".", "ClassificationTask", "(", "FLAGS", ".", "log_steps", ",", "\n", "FLAGS", ".", "export_to_tensorboard", ",", "\n", "FLAGS", ".", "experiment_log_path", ",", "\n", "FLAGS", ".", "job_prefix", ")", "\n", "\n", "train_dataset", "=", "train_dataset", ".", "batch", "(", "FLAGS", ".", "train_batch_size", ")", "\n", "eval_dataset", "=", "eval_dataset", ".", "batch", "(", "FLAGS", ".", "eval_batch_size", ")", "\n", "test_dataset", "=", "test_dataset", ".", "batch", "(", "FLAGS", ".", "eval_batch_size", ")", "\n", "\n", "num_batch_supervised_train_dataset", "=", "get_num_element", "(", "train_dataset", ",", "\n", "train_data_percentage", ")", "\n", "num_batch_unsupervised_train_dataset", "=", "get_num_element", "(", "train_dataset", ",", "100", ")", "\n", "supervised_train_dataset", "=", "train_dataset", ".", "take", "(", "\n", "num_batch_supervised_train_dataset", ")", "\n", "\n", "unsupervised_iter", "=", "iter", "(", "train_dataset", ")", "\n", "supervised_iter", "=", "iter", "(", "supervised_train_dataset", ")", "\n", "\n", "unsupervised_batch_index", "=", "0", "\n", "supervised_batch_index", "=", "0", "\n", "\n", "global_train_step", "=", "0", "\n", "best_metrics", "=", "0", "\n", "best_encoder", "=", "encoder", "\n", "for", "_", "in", "range", "(", "FLAGS", ".", "num_epochs_outer_attention", ")", ":", "\n", "    ", "for", "_", "in", "range", "(", "FLAGS", ".", "num_steps_unsupervised", ")", ":", "\n", "      ", "(", "unsupervised_train_feature_batch", ",", "\n", "unsupervised_train_supervised_label_batch", ",", "\n", "unsupervised_train_unsupervised_label_batch", ")", "=", "next", "(", "unsupervised_iter", ")", "\n", "unsupervised_batch_index", "+=", "1", "\n", "unsupervised_train_label_batch", "=", "(", "\n", "unsupervised_train_supervised_label_batch", ",", "\n", "unsupervised_train_unsupervised_label_batch", ")", "\n", "\n", "dLu_dphi", ",", "dLu_dlambda", "=", "train_batch_inner_unsupervised_approx", "(", "# pylint: disable=invalid-name", "\n", "unsupervised_batch_index", ",", "unsupervised_train_feature_batch", ",", "\n", "unsupervised_train_label_batch", ",", "encoder", ",", "unsupervised_decoder", ",", "\n", "regression_task", ",", "unsupervised_optimizer", ",", "global_train_step", ")", "\n", "if", "unsupervised_batch_index", ">=", "num_batch_unsupervised_train_dataset", ":", "\n", "        ", "unsupervised_iter", "=", "iter", "(", "train_dataset", ")", "\n", "unsupervised_batch_index", "=", "0", "\n", "", "global_train_step", "+=", "1", "\n", "\n", "best_metrics", ",", "best_encoder", "=", "continuous_eval", "(", "\n", "eval_dataset", ",", "test_dataset", ",", "unsupervised_train_feature_batch", ",", "encoder", ",", "\n", "best_encoder", ",", "unsupervised_decoder", ",", "supervised_decoder", ",", "\n", "regression_task", ",", "classification_task", ",", "best_metrics", ",", "global_train_step", ")", "\n", "\n", "", "for", "_", "in", "range", "(", "FLAGS", ".", "num_steps_supervised", ")", ":", "\n", "      ", "(", "supervised_train_feature_batch", ",", "supervised_train_supervised_label_batch", ",", "\n", "supervised_train_unsupervised_label_batch", ")", "=", "next", "(", "supervised_iter", ")", "\n", "supervised_batch_index", "+=", "1", "\n", "supervised_train_label_batch", "=", "(", "supervised_train_supervised_label_batch", ",", "\n", "supervised_train_unsupervised_label_batch", ")", "\n", "\n", "dLs_dphi", "=", "train_batch_inner_supervised_approx", "(", "# pylint: disable=invalid-name", "\n", "supervised_batch_index", ",", "supervised_train_feature_batch", ",", "\n", "supervised_train_label_batch", ",", "eval_dataset", ",", "encoder", ",", "\n", "supervised_decoder", ",", "classification_task", ",", "supervised_optimizer", ",", "\n", "global_train_step", ")", "\n", "if", "supervised_batch_index", ">=", "num_batch_supervised_train_dataset", ":", "\n", "        ", "supervised_iter", "=", "iter", "(", "supervised_train_dataset", ")", "\n", "supervised_batch_index", "=", "0", "\n", "", "global_train_step", "+=", "1", "\n", "\n", "best_metrics", ",", "best_encoder", "=", "continuous_eval", "(", "\n", "eval_dataset", ",", "test_dataset", ",", "unsupervised_train_feature_batch", ",", "encoder", ",", "\n", "best_encoder", ",", "unsupervised_decoder", ",", "supervised_decoder", ",", "\n", "regression_task", ",", "classification_task", ",", "best_metrics", ",", "global_train_step", ")", "\n", "\n", "", "if", "FLAGS", ".", "use_attention", ":", "\n", "# dLs_dlambda = dLs_dphi * dphi_dlambda", "\n", "# dphi_dlambda = dphi_dLu * dLu_dlambda = dLu_dphi^-1 * dLu_dlambda", "\n", "\n", "      ", "dLs_dphi_reshape", "=", "_flatten_gradient", "(", "dLs_dphi", ")", "# pylint: disable=invalid-name", "\n", "dLu_dphi_reshape", "=", "_flatten_gradient", "(", "dLu_dphi", ")", "# pylint: disable=invalid-name", "\n", "dLu_dlambda_reshape", "=", "_flatten_gradient", "(", "dLu_dlambda", ")", "# pylint: disable=invalid-name", "\n", "\n", "dphi_dlambda", "=", "tf", ".", "matmul", "(", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "math", ".", "reciprocal", "(", "dLu_dphi_reshape", ")", ",", "axis", "=", "1", ")", ",", "\n", "tf", ".", "expand_dims", "(", "dLu_dlambda_reshape", ",", "axis", "=", "0", ")", ")", "# [phi, lambda]", "\n", "dphi_dlambda", "=", "tf", ".", "clip_by_value", "(", "dphi_dlambda", ",", "-", "10000", ",", "10000", ",", "name", "=", "None", ")", "\n", "\n", "attention_grad_tensor", "=", "tf", ".", "squeeze", "(", "\n", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "dLs_dphi_reshape", ",", "axis", "=", "0", ")", ",", "dphi_dlambda", ")", ",", "\n", "axis", "=", "0", ")", "# [lambda]", "\n", "attention_grad_tensor", "=", "tf", ".", "clip_by_value", "(", "\n", "attention_grad_tensor", ",", "-", "10000", ",", "10000", ",", "name", "=", "None", ")", "\n", "\n", "_apply_gradients", "(", "attention_optimizer", ",", "[", "attention_grad_tensor", ".", "numpy", "(", ")", "]", ",", "\n", "regression_task", ".", "attention_variables", ")", "\n", "", "", "return", "encoder", ",", "best_encoder", ",", "global_train_step", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_cotrain_unsupervised_model": [[849, 952], ["len", "print", "encoder_model", "print", "unsupervised_decoder_model", "print", "supervised_decoder_model", "tensorflow.keras.optimizers.Adam", "tensorflow.keras.optimizers.Adam", "tasks.RegressionTask", "tasks.ClassificationTask", "train_dataset.batch.batch", "eval_dataset.batch.batch", "test_dataset.batch.batch", "meta_trainer.get_num_element", "train_dataset.batch.take", "iter", "range", "ValueError", "next", "meta_trainer.train_batch_cotrain", "meta_trainer.continuous_eval", "iter"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.get_num_element", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_batch_cotrain", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.continuous_eval"], ["", "def", "train_cotrain_unsupervised_model", "(", "train_dataset", ",", "train_data_percentage", ",", "\n", "eval_dataset", ",", "test_dataset", ",", "\n", "dataset_config", ")", ":", "\n", "  ", "\"\"\"Train a baseline supervised model based on binary label.\"\"\"", "\n", "feature_keys", ",", "num_predict", "=", "dataset_config", "\n", "num_feature", "=", "len", "(", "feature_keys", ")", "\n", "\n", "encoder_model", "=", "ENCODER_MAP", "[", "FLAGS", ".", "encoder_name", "]", "\n", "print", "(", "'create new encoder: '", "+", "FLAGS", ".", "encoder_name", ")", "\n", "encoder", "=", "encoder_model", "(", "state_size", "=", "FLAGS", ".", "state_size", ")", "\n", "\n", "unsupervised_decoder_model", "=", "DECODER_MAP", "[", "FLAGS", ".", "unsupervised_decoder_name", "]", "\n", "print", "(", "'create new decoder: '", "+", "FLAGS", ".", "unsupervised_decoder_name", ")", "\n", "unsupervised_decoder", "=", "unsupervised_decoder_model", "(", "\n", "num_feature", "=", "num_feature", ",", "\n", "num_predict", "=", "num_predict", ",", "\n", "state_size", "=", "FLAGS", ".", "state_size", ")", "\n", "\n", "supervised_decoder_model", "=", "DECODER_MAP", "[", "FLAGS", ".", "supervised_decoder_name", "]", "\n", "print", "(", "'create new decoder: '", "+", "FLAGS", ".", "supervised_decoder_name", ")", "\n", "supervised_decoder", "=", "supervised_decoder_model", "(", ")", "\n", "\n", "unsupervised_optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "\n", "learning_rate", "=", "FLAGS", ".", "unsupervised_learning_rate", ",", "\n", "clipvalue", "=", "_GRADIENT_CLIP_VALUE", ")", "\n", "supervised_optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "\n", "learning_rate", "=", "FLAGS", ".", "supervised_learning_rate", ",", "\n", "clipvalue", "=", "_GRADIENT_CLIP_VALUE", ")", "\n", "\n", "if", "FLAGS", ".", "unsupervised_train_with_keras_model_fit", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "'unsupervised_train_with_keras_model_fit not supported under cotrain_pretrain'", "\n", ")", "\n", "\n", "", "regression_task", "=", "tasks", ".", "RegressionTask", "(", "\n", "num_feature", "=", "num_feature", ",", "\n", "num_predict", "=", "num_predict", ",", "\n", "target_feature_index", "=", "FLAGS", ".", "target_feature_index", ",", "\n", "feature_indice_included_str", "=", "FLAGS", ".", "feature_indice_included_str", ",", "\n", "feature_indice_excluded_str", "=", "FLAGS", ".", "feature_indice_excluded_str", ",", "\n", "feature_keys", "=", "feature_keys", ",", "\n", "log_steps", "=", "FLAGS", ".", "log_steps", ",", "\n", "export_to_tensorboard", "=", "FLAGS", ".", "export_to_tensorboard", ",", "\n", "experiment_log_path", "=", "FLAGS", ".", "experiment_log_path", ",", "\n", "job_prefix", "=", "FLAGS", ".", "job_prefix", ",", "\n", "forecast_only_nonmask_values", "=", "FLAGS", ".", "forecast_only_nonmask_values", ",", "\n", "forecast_loss_func", "=", "FLAGS", ".", "forecast_loss_func", ",", "\n", "use_attention", "=", "FLAGS", ".", "use_attention", ",", "\n", "normalization_model", "=", "FLAGS", ".", "normalization_model", ",", "\n", "attention_init_value", "=", "FLAGS", ".", "attention_init_value", ",", "\n", "use_attn_output", "=", "FLAGS", ".", "use_attn_output", ")", "\n", "\n", "classification_task", "=", "tasks", ".", "ClassificationTask", "(", "FLAGS", ".", "log_steps", ",", "\n", "FLAGS", ".", "export_to_tensorboard", ",", "\n", "FLAGS", ".", "experiment_log_path", ",", "\n", "FLAGS", ".", "job_prefix", ")", "\n", "\n", "train_dataset", "=", "train_dataset", ".", "batch", "(", "FLAGS", ".", "train_batch_size", ")", "\n", "eval_dataset", "=", "eval_dataset", ".", "batch", "(", "FLAGS", ".", "eval_batch_size", ")", "\n", "test_dataset", "=", "test_dataset", ".", "batch", "(", "FLAGS", ".", "eval_batch_size", ")", "\n", "\n", "num_batch_supervised_train_dataset", "=", "get_num_element", "(", "train_dataset", ",", "\n", "train_data_percentage", ")", "\n", "supervised_train_dataset", "=", "train_dataset", ".", "take", "(", "\n", "num_batch_supervised_train_dataset", ")", "\n", "supervised_iter", "=", "iter", "(", "supervised_train_dataset", ")", "\n", "supervised_batch_index", "=", "0", "\n", "\n", "global_train_step", "=", "0", "\n", "best_metrics", "=", "0", "\n", "best_encoder", "=", "encoder", "\n", "\n", "for", "_", "in", "range", "(", "FLAGS", ".", "num_epochs_unsupervised", ")", ":", "\n", "    ", "for", "(", "unsupervised_train_feature_batch", ",", "\n", "unsupervised_train_supervised_label_batch", ",", "\n", "unsupervised_train_unsupervised_label_batch", ")", "in", "train_dataset", ":", "\n", "      ", "global_train_step", "+=", "1", "\n", "unsupervised_train_label_batch", "=", "(", "\n", "unsupervised_train_supervised_label_batch", ",", "\n", "unsupervised_train_unsupervised_label_batch", ")", "\n", "(", "supervised_train_feature_batch", ",", "supervised_train_supervised_label_batch", ",", "\n", "supervised_train_unsupervised_label_batch", ")", "=", "next", "(", "supervised_iter", ")", "\n", "supervised_batch_index", "+=", "1", "\n", "supervised_train_label_batch", "=", "(", "supervised_train_supervised_label_batch", ",", "\n", "supervised_train_unsupervised_label_batch", ")", "\n", "\n", "if", "supervised_batch_index", ">=", "num_batch_supervised_train_dataset", ":", "\n", "        ", "supervised_iter", "=", "iter", "(", "supervised_train_dataset", ")", "\n", "supervised_batch_index", "=", "0", "\n", "\n", "", "train_batch_cotrain", "(", "\n", "unsupervised_train_feature_batch", ",", "unsupervised_train_label_batch", ",", "\n", "supervised_train_feature_batch", ",", "supervised_train_label_batch", ",", "encoder", ",", "\n", "unsupervised_decoder", ",", "supervised_decoder", ",", "regression_task", ",", "\n", "classification_task", ",", "unsupervised_optimizer", ",", "supervised_optimizer", ",", "\n", "global_train_step", ")", "\n", "\n", "best_metrics", ",", "best_encoder", "=", "continuous_eval", "(", "\n", "eval_dataset", ",", "test_dataset", ",", "supervised_train_feature_batch", ",", "encoder", ",", "\n", "best_encoder", ",", "unsupervised_decoder", ",", "supervised_decoder", ",", "\n", "regression_task", ",", "classification_task", ",", "best_metrics", ",", "global_train_step", ")", "\n", "\n", "", "", "return", "encoder", ",", "best_encoder", ",", "global_train_step", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_unsupervised_model": [[954, 1044], ["enumerate", "len", "logging.info", "encoder_model", "logging.info", "decoder_model", "train_dataset.map.batch", "eval_dataset.map.batch", "tensorflow.keras.optimizers.Adam", "logging.info", "meta_trainer.EncoderDecoderModel", "EncoderDecoderModel.compile", "train_dataset.map.map", "eval_dataset.map.map", "logging.info", "EncoderDecoderModel.fit", "tasks.RegressionTask", "range", "ValueError", "ValueError", "meta_trainer.EncoderDecoderModel.get_encoder", "meta_trainer.EncoderDecoderModel.get_encoder", "tensorflow.keras.losses.MeanSquaredError", "meta_trainer.train_batch", "tensorflow.keras.metrics.MeanSquaredError", "meta_trainer.eval_all", "meta_trainer.copy_encoder"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.models.GP.fit", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.EncoderDecoderModel.get_encoder", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.EncoderDecoderModel.get_encoder", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_batch", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.eval_all", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.copy_encoder"], ["", "def", "train_unsupervised_model", "(", "train_dataset", ",", "eval_dataset", ",", "dataset_config", ")", ":", "\n", "  ", "\"\"\"Train a baseline supervised model based on binary label.\"\"\"", "\n", "feature_keys", ",", "num_predict", "=", "dataset_config", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "feature_keys", ")", ":", "\n", "    ", "logging", ".", "info", "(", "'%d: %s'", ",", "i", ",", "f", ")", "\n", "", "num_feature", "=", "len", "(", "feature_keys", ")", "\n", "\n", "encoder_model", "=", "ENCODER_MAP", "[", "FLAGS", ".", "encoder_name", "]", "\n", "logging", ".", "info", "(", "'create new encoder: %s'", ",", "FLAGS", ".", "encoder_name", ")", "\n", "encoder", "=", "encoder_model", "(", "state_size", "=", "FLAGS", ".", "state_size", ")", "\n", "\n", "decoder_model", "=", "DECODER_MAP", "[", "FLAGS", ".", "unsupervised_decoder_name", "]", "\n", "logging", ".", "info", "(", "'create new decoder: %s'", ",", "FLAGS", ".", "unsupervised_decoder_name", ")", "\n", "decoder", "=", "decoder_model", "(", "\n", "num_feature", "=", "num_feature", ",", "\n", "num_predict", "=", "num_predict", ",", "\n", "state_size", "=", "FLAGS", ".", "state_size", ")", "\n", "\n", "train_dataset", "=", "train_dataset", ".", "batch", "(", "FLAGS", ".", "train_batch_size", ")", "\n", "eval_dataset", "=", "eval_dataset", ".", "batch", "(", "FLAGS", ".", "eval_batch_size", ")", "\n", "\n", "optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "\n", "learning_rate", "=", "FLAGS", ".", "unsupervised_learning_rate", ")", "\n", "\n", "### using keras.Model and model fit.", "\n", "if", "FLAGS", ".", "unsupervised_train_with_keras_model_fit", ":", "\n", "    ", "model", "=", "EncoderDecoderModel", "(", "encoder", ",", "decoder", ")", "\n", "model", ".", "compile", "(", "\n", "optimizer", "=", "optimizer", ",", "\n", "loss", "=", "tf", ".", "keras", ".", "losses", ".", "MeanSquaredError", "(", ")", ",", "\n", "metrics", "=", "[", "tf", ".", "keras", ".", "metrics", ".", "MeanSquaredError", "(", ")", "]", ")", "\n", "if", "FLAGS", ".", "forecast_only_nonmask_values", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "'forecast_only_nonmask_values is not supported under unsupervised_train_with_keras_model_fit.'", "\n", ")", "\n", "\n", "", "train_dataset", "=", "train_dataset", ".", "map", "(", "lambda", "f", ",", "sl", ",", "ul", ":", "(", "f", ",", "ul", "[", "0", "]", ")", ")", "\n", "eval_dataset", "=", "eval_dataset", ".", "map", "(", "lambda", "f", ",", "sl", ",", "ul", ":", "(", "f", ",", "ul", "[", "0", "]", ")", ")", "\n", "\n", "logging", ".", "info", "(", "'# Fit model on training data'", ")", "\n", "model", ".", "fit", "(", "\n", "train_dataset", ",", "\n", "epochs", "=", "FLAGS", ".", "num_epochs_unsupervised", ",", "\n", "validation_data", "=", "eval_dataset", ")", "\n", "\n", "if", "FLAGS", ".", "use_best_encoder", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "'use_best_encoder is not supported under unsupervised_train_with_keras_model_fit.'", "\n", ")", "\n", "", "return", "model", ".", "get_encoder", "(", ")", ",", "model", ".", "get_encoder", "(", ")", ",", "0", "\n", "", "else", ":", "\n", "### Customized Training Loop.", "\n", "    ", "task", "=", "tasks", ".", "RegressionTask", "(", "\n", "num_feature", ",", "\n", "num_predict", ",", "\n", "FLAGS", ".", "target_feature_index", ",", "\n", "FLAGS", ".", "feature_indice_included_str", ",", "\n", "FLAGS", ".", "feature_indice_excluded_str", ",", "\n", "feature_keys", ",", "\n", "FLAGS", ".", "log_steps", ",", "\n", "FLAGS", ".", "export_to_tensorboard", ",", "\n", "FLAGS", ".", "experiment_log_path", ",", "\n", "FLAGS", ".", "job_prefix", ",", "\n", "FLAGS", ".", "forecast_only_nonmask_values", ",", "\n", "FLAGS", ".", "forecast_loss_func", ",", "\n", "use_attention", "=", "False", ",", "\n", "normalization_model", "=", "FLAGS", ".", "normalization_model", ",", "\n", "attention_init_value", "=", "FLAGS", ".", "attention_init_value", ",", "\n", "use_attn_output", "=", "FLAGS", ".", "use_attn_output", ")", "\n", "train_step", "=", "0", "\n", "best_metrics", "=", "np", ".", "inf", "\n", "\n", "for", "_", "in", "range", "(", "FLAGS", ".", "num_epochs_unsupervised", ")", ":", "\n", "      ", "for", "(", "train_feature_batch", ",", "train_supervised_label_batch", ",", "\n", "train_unsupervised_label_batch", ")", "in", "train_dataset", ":", "\n", "        ", "train_label_batch", "=", "(", "train_supervised_label_batch", ",", "\n", "train_unsupervised_label_batch", ")", "\n", "train_batch", "(", "train_feature_batch", ",", "train_label_batch", ",", "encoder", ",", "decoder", ",", "\n", "task", ",", "optimizer", ",", "train_step", ",", "False", ")", "\n", "train_step", "+=", "1", "\n", "# continuous eval.", "\n", "if", "train_step", "%", "FLAGS", ".", "eval_unsupervised_every_nsteps", "==", "0", ":", "\n", "          ", "_", ",", "_", ",", "_", ",", "metrics", "=", "eval_all", "(", "eval_dataset", ",", "encoder", ",", "decoder", ",", "task", ",", "\n", "'eval'", ",", "train_step", ")", "\n", "mse", ",", "_", "=", "metrics", "\n", "if", "mse", "<", "best_metrics", ":", "\n", "            ", "best_metrics", "=", "mse", "\n", "best_encoder", "=", "copy_encoder", "(", "encoder", ",", "train_feature_batch", ")", "\n", "\n", "", "", "", "", "return", "encoder", ",", "best_encoder", ",", "train_step", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_supervised_model": [[1046, 1128], ["logging.info", "decoder_model", "meta_trainer.get_num_element", "train_dataset.map.take", "train_dataset.map.shuffle", "train_dataset.map.batch", "eval_dataset.map.batch", "test_dataset.batch.batch", "tensorflow.keras.optimizers.Adam", "logging.info", "encoder_model", "logging.info", "meta_trainer.EncoderDecoderModel", "EncoderDecoderModel.compile", "logging.info", "train_dataset.map.map", "eval_dataset.map.map", "EncoderDecoderModel.fit", "tasks.ClassificationTask", "range", "ValueError", "enumerate", "tensorflow.keras.losses.BinaryCrossentropy", "meta_trainer.train_batch", "tensorflow.keras.metrics.AUC", "tensorflow.keras.metrics.AUC", "meta_trainer.eval_all", "meta_trainer.eval_all"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.get_num_element", "home.repos.pwc.inspect_result.google-health_records-research.models.GP.fit", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_batch", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.eval_all", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.eval_all"], ["", "", "def", "train_supervised_model", "(", "train_dataset", ",", "\n", "train_data_percentage", ",", "\n", "eval_dataset", ",", "\n", "test_dataset", ",", "\n", "dataset_config", ",", "\n", "pretrained_encoder", "=", "None", ",", "\n", "freeze_pretrained_encoder", "=", "True", ",", "\n", "init_train_step", "=", "0", ")", ":", "\n", "  ", "\"\"\"Train a baseline supervised model based on binary label.\"\"\"", "\n", "del", "dataset_config", "\n", "if", "pretrained_encoder", "is", "None", ":", "\n", "    ", "encoder_model", "=", "ENCODER_MAP", "[", "FLAGS", ".", "encoder_name", "]", "\n", "logging", ".", "info", "(", "'create new encoder: %s'", ",", "FLAGS", ".", "encoder_name", ")", "\n", "encoder", "=", "encoder_model", "(", "state_size", "=", "FLAGS", ".", "state_size", ")", "\n", "", "else", ":", "\n", "    ", "logging", ".", "info", "(", "'load pretrained encoder'", ")", "\n", "encoder", "=", "pretrained_encoder", "\n", "", "lr", "=", "FLAGS", ".", "supervised_learning_rate", "\n", "\n", "decoder_model", "=", "DECODER_MAP", "[", "FLAGS", ".", "supervised_decoder_name", "]", "\n", "logging", ".", "info", "(", "'create new decoder: %s'", ",", "FLAGS", ".", "supervised_decoder_name", ")", "\n", "decoder", "=", "decoder_model", "(", ")", "\n", "\n", "num_train_dataset", "=", "get_num_element", "(", "train_dataset", ",", "train_data_percentage", ")", "\n", "train_dataset", "=", "train_dataset", ".", "take", "(", "num_train_dataset", ")", "\n", "train_dataset", ".", "shuffle", "(", "1000", ")", "\n", "\n", "train_dataset", "=", "train_dataset", ".", "batch", "(", "FLAGS", ".", "train_batch_size", ")", "\n", "eval_dataset", "=", "eval_dataset", ".", "batch", "(", "FLAGS", ".", "eval_batch_size", ")", "\n", "test_dataset", "=", "test_dataset", ".", "batch", "(", "FLAGS", ".", "eval_batch_size", ")", "\n", "\n", "optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "learning_rate", "=", "lr", ")", "\n", "\n", "### using keras.Model and model fit.", "\n", "if", "FLAGS", ".", "supervised_train_with_keras_model_fit", ":", "\n", "    ", "if", "freeze_pretrained_encoder", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "'freeze_pretrained_encoder is not supported under unsupervised_train_with_keras_model_fit.'", "\n", ")", "\n", "\n", "", "model", "=", "EncoderDecoderModel", "(", "encoder", ",", "decoder", ")", "\n", "model", ".", "compile", "(", "\n", "optimizer", "=", "optimizer", ",", "\n", "loss", "=", "tf", ".", "keras", ".", "losses", ".", "BinaryCrossentropy", "(", "\n", "from_logits", "=", "False", ")", ",", "# Note this needs to be False.", "\n", "metrics", "=", "[", "tf", ".", "keras", ".", "metrics", ".", "AUC", "(", ")", ",", "\n", "tf", ".", "keras", ".", "metrics", ".", "AUC", "(", "curve", "=", "'PR'", ")", "]", ")", "\n", "logging", ".", "info", "(", "'# Fit model on training data'", ")", "\n", "train_dataset", "=", "train_dataset", ".", "map", "(", "lambda", "f", ",", "sl", ",", "ul", ":", "(", "f", ",", "sl", ")", ")", "\n", "eval_dataset", "=", "eval_dataset", ".", "map", "(", "lambda", "f", ",", "sl", ",", "ul", ":", "(", "f", ",", "sl", ")", ")", "\n", "model", ".", "fit", "(", "\n", "train_dataset", ",", "\n", "epochs", "=", "FLAGS", ".", "num_epochs_supervised", ",", "\n", "validation_data", "=", "eval_dataset", ")", "\n", "", "else", ":", "\n", "### Customized Training Loop.", "\n", "\n", "    ", "task", "=", "tasks", ".", "ClassificationTask", "(", "FLAGS", ".", "log_steps", ",", "\n", "FLAGS", ".", "export_to_tensorboard", ",", "\n", "FLAGS", ".", "experiment_log_path", ",", "FLAGS", ".", "job_prefix", ")", "\n", "train_step", "=", "init_train_step", "\n", "best_metrics", "=", "0", "\n", "\n", "for", "epoch", "in", "range", "(", "FLAGS", ".", "num_epochs_supervised", ")", ":", "\n", "      ", "for", "batch_index", ",", "(", "\n", "train_feature_batch", ",", "train_supervised_label_batch", ",", "\n", "train_unsupervised_label_batch", ")", "in", "enumerate", "(", "train_dataset", ")", ":", "\n", "        ", "train_label_batch", "=", "(", "train_supervised_label_batch", ",", "\n", "train_unsupervised_label_batch", ")", "\n", "train_batch", "(", "train_feature_batch", ",", "train_label_batch", ",", "encoder", ",", "decoder", ",", "\n", "task", ",", "optimizer", ",", "train_step", ",", "freeze_pretrained_encoder", ")", "\n", "train_step", "+=", "1", "\n", "# continuous eval.", "\n", "if", "train_step", "%", "FLAGS", ".", "eval_supervised_every_nsteps", "==", "0", ":", "\n", "          ", "_", ",", "_", ",", "_", ",", "metrics", "=", "eval_all", "(", "eval_dataset", ",", "encoder", ",", "decoder", ",", "task", ",", "\n", "'eval'", ",", "train_step", ")", "\n", "auc", ",", "aucpr", "=", "metrics", "\n", "if", "auc", ">", "best_metrics", ":", "\n", "# Select the best model based on eval dataset AUC and generate final", "\n", "# eval result over test dataset.", "\n", "            ", "best_metrics", "=", "auc", "\n", "eval_all", "(", "test_dataset", ",", "encoder", ",", "decoder", ",", "task", ",", "'test'", ",", "train_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.main": [[1130, 1239], ["meta_trainer.get_datasets", "meta_trainer.train_supervised_model", "meta_trainer.train_unsupervised_model", "next", "meta_trainer.train_unsupervised_model", "next", "meta_trainer.train_cotrain_unsupervised_model", "meta_trainer.train_supervised_model", "next", "meta_trainer.train_supervising_unsupervised_model_attn_approx", "next", "meta_trainer.train_supervising_unsupervised_model_attn_hessian", "meta_trainer.train_supervised_model", "iter", "meta_trainer.copy_encoder", "meta_trainer.copy_encoder", "logging.info", "meta_trainer.get_datasets", "meta_trainer.train_supervised_model", "logging.info", "meta_trainer.train_supervised_model", "iter", "meta_trainer.copy_encoder", "meta_trainer.copy_encoder", "iter", "meta_trainer.copy_encoder", "meta_trainer.copy_encoder", "logging.info", "meta_trainer.get_datasets", "meta_trainer.train_supervised_model", "logging.info", "meta_trainer.train_supervised_model", "iter", "meta_trainer.copy_encoder", "meta_trainer.copy_encoder", "str", "train_dataset.batch", "train_dataset.batch", "train_dataset.batch", "train_dataset.batch"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.get_datasets", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_supervised_model", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_unsupervised_model", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_unsupervised_model", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_cotrain_unsupervised_model", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_supervised_model", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_supervising_unsupervised_model_attn_approx", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_supervising_unsupervised_model_attn_hessian", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_supervised_model", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.copy_encoder", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.copy_encoder", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.get_datasets", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_supervised_model", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_supervised_model", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.copy_encoder", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.copy_encoder", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.copy_encoder", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.copy_encoder", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.get_datasets", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_supervised_model", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.train_supervised_model", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.copy_encoder", "home.repos.pwc.inspect_result.google-health_records-research.meta-learn-forecast-task.meta_trainer.copy_encoder"], ["", "", "", "", "", "", "def", "main", "(", "argv", ")", ":", "\n", "  ", "del", "argv", "\n", "if", "FLAGS", ".", "fold", ">=", "1", ":", "\n", "    ", "mimic_data_path", "=", "FLAGS", ".", "mimic_data_path", "+", "str", "(", "FLAGS", ".", "fold", ")", "+", "'/'", "\n", "", "else", ":", "\n", "    ", "mimic_data_path", "=", "FLAGS", ".", "mimic_data_path", "\n", "", "train_dataset", ",", "eval_dataset", ",", "test_dataset", ",", "dataset_config", "=", "get_datasets", "(", "\n", "FLAGS", ".", "dataset_name", ",", "mimic_data_path", ")", "\n", "\n", "if", "FLAGS", ".", "train_mode", "==", "'supervised'", ":", "\n", "    ", "train_supervised_model", "(", "train_dataset", ",", "FLAGS", ".", "train_data_percentage", ",", "\n", "eval_dataset", ",", "test_dataset", ",", "dataset_config", ",", "None", ",", "\n", "False", ")", "\n", "", "if", "FLAGS", ".", "train_mode", "==", "'unsupervised'", ":", "\n", "    ", "train_unsupervised_model", "(", "train_dataset", ",", "eval_dataset", ",", "dataset_config", ")", "\n", "\n", "", "if", "FLAGS", ".", "train_mode", "==", "'pretrain'", ":", "\n", "    ", "dummy_feature", ",", "dummy_supervised_label", ",", "dummy_unsupervised_label", "=", "next", "(", "\n", "iter", "(", "train_dataset", ".", "batch", "(", "FLAGS", ".", "train_batch_size", ")", ")", ")", "\n", "\n", "last_encoder", ",", "best_encoder", ",", "global_step", "=", "train_unsupervised_model", "(", "\n", "train_dataset", ",", "eval_dataset", ",", "dataset_config", ")", "\n", "\n", "if", "FLAGS", ".", "use_best_encoder", ":", "\n", "      ", "pretrained_encoder", "=", "copy_encoder", "(", "best_encoder", ",", "dummy_feature", ")", "\n", "", "else", ":", "\n", "      ", "pretrained_encoder", "=", "copy_encoder", "(", "last_encoder", ",", "dummy_feature", ")", "\n", "\n", "", "if", "FLAGS", ".", "transfer_data_path", ":", "\n", "      ", "logging", ".", "info", "(", "'end pretraining, start transfer to new task.'", ")", "\n", "transfer_train_dataset", ",", "transfer_eval_dataset", ",", "transfer_test_dataset", ",", "transfer_dataset_config", "=", "get_datasets", "(", "\n", "FLAGS", ".", "dataset_name", ",", "FLAGS", ".", "transfer_data_path", ")", "\n", "train_supervised_model", "(", "transfer_train_dataset", ",", "\n", "FLAGS", ".", "train_data_percentage", ",", "transfer_eval_dataset", ",", "\n", "transfer_test_dataset", ",", "transfer_dataset_config", ",", "\n", "pretrained_encoder", ",", "\n", "FLAGS", ".", "freeze_encoder_after_pretrain", ",", "global_step", ")", "\n", "\n", "", "else", ":", "\n", "      ", "logging", ".", "info", "(", "'end pretraining, start supervised training.'", ")", "\n", "train_supervised_model", "(", "train_dataset", ",", "FLAGS", ".", "train_data_percentage", ",", "\n", "eval_dataset", ",", "test_dataset", ",", "dataset_config", ",", "\n", "pretrained_encoder", ",", "\n", "FLAGS", ".", "freeze_encoder_after_pretrain", ",", "global_step", ")", "\n", "\n", "", "", "if", "FLAGS", ".", "train_mode", "==", "'cotrain_pretrain'", ":", "\n", "    ", "dummy_feature", ",", "_", ",", "_", "=", "next", "(", "\n", "iter", "(", "train_dataset", ".", "batch", "(", "FLAGS", ".", "train_batch_size", ")", ")", ")", "\n", "\n", "last_encoder", ",", "best_encoder", ",", "global_step", "=", "train_cotrain_unsupervised_model", "(", "\n", "train_dataset", ",", "FLAGS", ".", "train_data_percentage", ",", "eval_dataset", ",", "test_dataset", ",", "\n", "dataset_config", ")", "\n", "\n", "if", "FLAGS", ".", "use_best_encoder", ":", "\n", "      ", "pretrained_encoder", "=", "copy_encoder", "(", "best_encoder", ",", "dummy_feature", ")", "\n", "", "else", ":", "\n", "      ", "pretrained_encoder", "=", "copy_encoder", "(", "last_encoder", ",", "dummy_feature", ")", "\n", "\n", "", "train_supervised_model", "(", "train_dataset", ",", "FLAGS", ".", "train_data_percentage", ",", "\n", "eval_dataset", ",", "test_dataset", ",", "dataset_config", ",", "\n", "pretrained_encoder", ",", "\n", "FLAGS", ".", "freeze_encoder_after_pretrain", ",", "global_step", ")", "\n", "\n", "", "if", "FLAGS", ".", "train_mode", "==", "'attn_approx'", ":", "\n", "    ", "dummy_feature", ",", "_", ",", "_", "=", "next", "(", "\n", "iter", "(", "train_dataset", ".", "batch", "(", "FLAGS", ".", "train_batch_size", ")", ")", ")", "\n", "\n", "last_encoder", ",", "best_encoder", ",", "global_step", "=", "train_supervising_unsupervised_model_attn_approx", "(", "\n", "train_dataset", ",", "FLAGS", ".", "train_data_percentage", ",", "eval_dataset", ",", "test_dataset", ",", "\n", "dataset_config", ")", "\n", "\n", "if", "FLAGS", ".", "use_best_encoder", ":", "\n", "      ", "pretrained_encoder", "=", "copy_encoder", "(", "best_encoder", ",", "dummy_feature", ")", "\n", "", "else", ":", "\n", "      ", "pretrained_encoder", "=", "copy_encoder", "(", "last_encoder", ",", "dummy_feature", ")", "\n", "\n", "", "if", "FLAGS", ".", "transfer_data_path", ":", "\n", "      ", "logging", ".", "info", "(", "'end pretraining, start transfer to new task.'", ")", "\n", "transfer_train_dataset", ",", "transfer_eval_dataset", ",", "transfer_test_dataset", ",", "transfer_dataset_config", "=", "get_datasets", "(", "\n", "FLAGS", ".", "dataset_name", ",", "FLAGS", ".", "transfer_data_path", ")", "\n", "train_supervised_model", "(", "transfer_train_dataset", ",", "\n", "FLAGS", ".", "train_data_percentage", ",", "transfer_eval_dataset", ",", "\n", "transfer_test_dataset", ",", "transfer_dataset_config", ",", "\n", "pretrained_encoder", ",", "\n", "FLAGS", ".", "freeze_encoder_after_pretrain", ",", "global_step", ")", "\n", "\n", "", "else", ":", "\n", "      ", "logging", ".", "info", "(", "'end pretraining, start supervised training.'", ")", "\n", "train_supervised_model", "(", "train_dataset", ",", "FLAGS", ".", "train_data_percentage", ",", "\n", "eval_dataset", ",", "test_dataset", ",", "dataset_config", ",", "\n", "pretrained_encoder", ",", "\n", "FLAGS", ".", "freeze_encoder_after_pretrain", ",", "global_step", ")", "\n", "\n", "", "", "if", "FLAGS", ".", "train_mode", "==", "'attn_hessian'", ":", "\n", "    ", "dummy_feature", ",", "_", ",", "_", "=", "next", "(", "\n", "iter", "(", "train_dataset", ".", "batch", "(", "FLAGS", ".", "train_batch_size", ")", ")", ")", "\n", "\n", "last_encoder", ",", "best_encoder", ",", "global_step", "=", "train_supervising_unsupervised_model_attn_hessian", "(", "\n", "train_dataset", ",", "eval_dataset", ",", "test_dataset", ",", "dataset_config", ")", "\n", "\n", "if", "FLAGS", ".", "use_best_encoder", ":", "\n", "      ", "pretrained_encoder", "=", "copy_encoder", "(", "best_encoder", ",", "dummy_feature", ")", "\n", "", "else", ":", "\n", "      ", "pretrained_encoder", "=", "copy_encoder", "(", "last_encoder", ",", "dummy_feature", ")", "\n", "\n", "", "train_supervised_model", "(", "train_dataset", ",", "FLAGS", ".", "train_data_percentage", ",", "\n", "eval_dataset", ",", "test_dataset", ",", "dataset_config", ",", "\n", "pretrained_encoder", ",", "\n", "FLAGS", ".", "freeze_encoder_after_pretrain", ",", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.train.main": [[23, 63], ["graph_convolutional_transformer.EHRTransformer", "tensorflow.estimator.RunConfig", "tensorflow.estimator.Estimator", "tensorflow.estimator.TrainSpec", "tensorflow.estimator.EvalSpec", "tensorflow.estimator.train_and_evaluate", "tf.estimator.Estimator.evaluate", "gct.EHRTransformer.input_fn", "gct.EHRTransformer.input_fn", "gct.EHRTransformer.input_fn"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.model-uncertainty.bayesian_rnn_eager_main.evaluate", "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.EHRTransformer.input_fn", "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.EHRTransformer.input_fn", "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.EHRTransformer.input_fn"], ["from", "tensorflow", ".", "contrib", ".", "learn", ".", "python", ".", "learn", "import", "learn_runner", "\n", "\n", "flags", ".", "DEFINE_string", "(", "'hparams'", ",", "''", ",", "'hparams'", ")", "\n", "\n", "flags", ".", "DEFINE_string", "(", "'experiment_config'", ",", "None", ",", "\n", "'pbtxt file containing ExperimentConfig.'", ")", "\n", "\n", "flags", ".", "DEFINE_string", "(", "'train_path'", ",", "None", ",", "'path to train data'", ")", "\n", "\n", "flags", ".", "DEFINE_string", "(", "'eval_path'", ",", "None", ",", "'path to eval data'", ")", "\n", "flags", ".", "DEFINE_string", "(", "'warm_start_from'", ",", "None", ",", "\n", "'Optional string filepath to a checkpoint or SavedModel to '", "\n", "'warm-start from.'", ")", "\n", "\n", "flags", ".", "DEFINE_integer", "(", "\n", "'num_train_steps'", ",", "None", ",", "\n", "'The number of steps to run training for. None means continuous training.'", ")", "\n", "\n", "flags", ".", "DEFINE_integer", "(", "'num_eval_steps'", ",", "200", ",", "\n", "'The number of steps to run evaluation for.'", ")", "\n", "\n", "flags", ".", "DEFINE_integer", "(", "'save_checkpoints_steps'", ",", "1000", ",", "\n", "'The number of training steps to save a checkpoint for.'", ")", "\n", "\n", "flags", ".", "DEFINE_integer", "(", "'keep_checkpoint_max'", ",", "50", ",", "\n", "'The number of training steps to save a checkpoint for.'", ")", "\n", "\n", "flags", ".", "DEFINE_integer", "(", "\n", "'continuous_eval_throttle_secs'", ",", "20", ",", "\n", "'Number of seconds between evaluations during a continuous eval job.'", ")", "\n", "\n", "FLAGS", "=", "flags", ".", "FLAGS", "\n", "\n", "\n", "def", "default_hparams", "(", ")", ":", "\n", "  ", "\"\"\"Define default Hparams.\"\"\"", "\n", "\n", "hparam_kwargs", "=", "{", "\n", "'model__learning_rate'", ":", "0.001", ",", "\n", "'model__da_state'", ":", "100", ",", "\n", "'model__da_tlen'", ":", "240", ",", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.FeatureEmbedder.__init__": [[32, 53], ["tensorflow.zeros", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat"], ["def", "__init__", "(", "self", ",", "vocab_sizes", ",", "feature_keys", ",", "embedding_size", ")", ":", "\n", "    ", "\"\"\"Init function.\n\n    Args:\n      vocab_sizes: A dictionary of vocabularize sizes for each feature.\n      feature_keys: A list of feature names you want to use.\n      embedding_size: The dimension size of the feature representation vector.\n    \"\"\"", "\n", "self", ".", "_params", "=", "{", "}", "\n", "self", ".", "_feature_keys", "=", "feature_keys", "\n", "self", ".", "_vocab_sizes", "=", "vocab_sizes", "\n", "dummy_emb", "=", "tf", ".", "zeros", "(", "[", "1", ",", "embedding_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "for", "feature_key", "in", "feature_keys", ":", "\n", "      ", "vocab_size", "=", "self", ".", "_vocab_sizes", "[", "feature_key", "]", "\n", "emb", "=", "tf", ".", "get_variable", "(", "\n", "feature_key", ",", "shape", "=", "(", "vocab_size", ",", "embedding_size", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "_params", "[", "feature_key", "]", "=", "tf", ".", "concat", "(", "[", "emb", ",", "dummy_emb", "]", ",", "axis", "=", "0", ")", "\n", "\n", "", "self", ".", "_params", "[", "'visit'", "]", "=", "tf", ".", "get_variable", "(", "\n", "'visit'", ",", "shape", "=", "(", "1", ",", "embedding_size", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.FeatureEmbedder.lookup": [[54, 103], ["tensorflow.tile", "tensorflow.sparse.to_dense", "tensorflow.squeeze", "tensorflow.nn.embedding_lookup", "tensorflow.SparseTensor", "tensorflow.squeeze", "tensorflow.shape", "tensorflow.ones", "tensorflow.SparseTensor", "tensorflow.sparse.to_dense", "tensorflow.ones", "embeddings.values", "tensorflow.shape"], "methods", ["None"], ["", "def", "lookup", "(", "self", ",", "feature_map", ",", "max_num_codes", ")", ":", "\n", "    ", "\"\"\"Look-up function.\n\n    This function converts the SparseTensor of integers to a dense Tensor of\n    tf.float32.\n\n    Args:\n      feature_map: A dictionary of SparseTensors for each feature.\n      max_num_codes: The maximum number of how many feature there can be inside\n        a single visit, per feature. For example, if this is set to 50, then we\n        are assuming there can be up to 50 diagnosis codes, 50 treatment codes,\n        and 50 lab codes. This will be used for creating the prior matrix.\n\n    Returns:\n      embeddings: A dictionary of dense representation Tensors for each feature.\n      masks: A dictionary of dense float32 Tensors for each feature, that will\n        be used as a mask in the downstream tasks.\n    \"\"\"", "\n", "masks", "=", "{", "}", "\n", "embeddings", "=", "{", "}", "\n", "for", "key", "in", "self", ".", "_feature_keys", ":", "\n", "      ", "if", "max_num_codes", ">", "0", ":", "\n", "        ", "feature", "=", "tf", ".", "SparseTensor", "(", "\n", "indices", "=", "feature_map", "[", "key", "]", ".", "indices", ",", "\n", "values", "=", "feature_map", "[", "key", "]", ".", "values", ",", "\n", "dense_shape", "=", "[", "\n", "feature_map", "[", "key", "]", ".", "dense_shape", "[", "0", "]", ",", "\n", "feature_map", "[", "key", "]", ".", "dense_shape", "[", "1", "]", ",", "max_num_codes", "\n", "]", ")", "\n", "", "else", ":", "\n", "        ", "feature", "=", "feature_map", "[", "key", "]", "\n", "", "feature_ids", "=", "tf", ".", "sparse", ".", "to_dense", "(", "\n", "feature", ",", "default_value", "=", "self", ".", "_vocab_sizes", "[", "key", "]", ")", "\n", "feature_ids", "=", "tf", ".", "squeeze", "(", "feature_ids", ",", "axis", "=", "1", ")", "\n", "embeddings", "[", "key", "]", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "_params", "[", "key", "]", ",", "feature_ids", ")", "\n", "\n", "mask", "=", "tf", ".", "SparseTensor", "(", "\n", "indices", "=", "feature", ".", "indices", ",", "\n", "values", "=", "tf", ".", "ones", "(", "tf", ".", "shape", "(", "feature", ".", "values", ")", ")", ",", "\n", "dense_shape", "=", "feature", ".", "dense_shape", ")", "\n", "masks", "[", "key", "]", "=", "tf", ".", "squeeze", "(", "tf", ".", "sparse", ".", "to_dense", "(", "mask", ")", ",", "axis", "=", "1", ")", "\n", "\n", "", "batch_size", "=", "tf", ".", "shape", "(", "embeddings", ".", "values", "(", ")", "[", "0", "]", ")", "[", "0", "]", "\n", "embeddings", "[", "'visit'", "]", "=", "tf", ".", "tile", "(", "self", ".", "_params", "[", "'visit'", "]", "[", "None", ",", ":", ",", ":", "]", ",", "\n", "[", "batch_size", ",", "1", ",", "1", "]", ")", "\n", "\n", "masks", "[", "'visit'", "]", "=", "tf", ".", "ones", "(", "batch_size", ")", "[", ":", ",", "None", "]", "\n", "\n", "return", "embeddings", ",", "masks", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.GraphConvolutionalTransformer.__init__": [[112, 186], ["super().__init__", "range", "graph_convolutional_transformer.GraphConvolutionalTransformer._layers[].append", "graph_convolutional_transformer.GraphConvolutionalTransformer._layers[].append", "graph_convolutional_transformer.GraphConvolutionalTransformer._layers[].append", "graph_convolutional_transformer.GraphConvolutionalTransformer._layers[].append", "range", "[].append", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "graph_convolutional_transformer.GraphConvolutionalTransformer._layers[].append", "[].append", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__"], ["def", "__init__", "(", "self", ",", "\n", "embedding_size", "=", "128", ",", "\n", "num_transformer_stack", "=", "3", ",", "\n", "num_feedforward", "=", "2", ",", "\n", "num_attention_heads", "=", "1", ",", "\n", "ffn_dropout", "=", "0.1", ",", "\n", "attention_normalizer", "=", "'softmax'", ",", "\n", "multihead_attention_aggregation", "=", "'concat'", ",", "\n", "directed_attention", "=", "False", ",", "\n", "use_inf_mask", "=", "True", ",", "\n", "use_prior", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Init function.\n\n    Args:\n      embedding_size: The size of the dimension for hidden layers.\n      num_transformer_stack: The number of Transformer blocks.\n      num_feedforward: The number of layers in the feedforward part of\n        Transformer.\n      num_attention_heads: The number of attention heads.\n      ffn_dropout: Dropout rate used inside the feedforward part.\n      attention_normalizer: Use either 'softmax' or 'sigmoid' to normalize the\n        attention values.\n      multihead_attention_aggregation: Use either 'concat' or 'sum' to handle\n        the outputs from multiple attention heads.\n      directed_attention: Decide whether you want to use the unidirectional\n        attention, where information accumulates inside the dummy visit node.\n      use_inf_mask: Decide whether you want to use the guide matrix. Currently\n        unused.\n      use_prior: Decide whether you want to use the conditional probablility\n        information. Currently unused.\n      **kwargs: Other arguments to tf.keras.layers.Layer init.\n    \"\"\"", "\n", "\n", "super", "(", "GraphConvolutionalTransformer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "_hidden_size", "=", "embedding_size", "\n", "self", ".", "_num_stack", "=", "num_transformer_stack", "\n", "self", ".", "_num_feedforward", "=", "num_feedforward", "\n", "self", ".", "_num_heads", "=", "num_attention_heads", "\n", "self", ".", "_ffn_dropout", "=", "ffn_dropout", "\n", "self", ".", "_attention_normalizer", "=", "attention_normalizer", "\n", "self", ".", "_multihead_aggregation", "=", "multihead_attention_aggregation", "\n", "self", ".", "_directed_attention", "=", "directed_attention", "\n", "self", ".", "_use_inf_mask", "=", "use_inf_mask", "\n", "self", ".", "_use_prior", "=", "use_prior", "\n", "\n", "self", ".", "_layers", "=", "{", "}", "\n", "self", ".", "_layers", "[", "'Q'", "]", "=", "[", "]", "\n", "self", ".", "_layers", "[", "'K'", "]", "=", "[", "]", "\n", "self", ".", "_layers", "[", "'V'", "]", "=", "[", "]", "\n", "self", ".", "_layers", "[", "'ffn'", "]", "=", "[", "]", "\n", "self", ".", "_layers", "[", "'head_agg'", "]", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_stack", ")", ":", "\n", "      ", "self", ".", "_layers", "[", "'Q'", "]", ".", "append", "(", "\n", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "self", ".", "_hidden_size", "*", "self", ".", "_num_heads", ",", "use_bias", "=", "False", ")", ")", "\n", "self", ".", "_layers", "[", "'K'", "]", ".", "append", "(", "\n", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "self", ".", "_hidden_size", "*", "self", ".", "_num_heads", ",", "use_bias", "=", "False", ")", ")", "\n", "self", ".", "_layers", "[", "'V'", "]", ".", "append", "(", "\n", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "self", ".", "_hidden_size", "*", "self", ".", "_num_heads", ",", "use_bias", "=", "False", ")", ")", "\n", "\n", "if", "self", ".", "_multihead_aggregation", "==", "'concat'", ":", "\n", "        ", "self", ".", "_layers", "[", "'head_agg'", "]", ".", "append", "(", "\n", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "_hidden_size", ",", "use_bias", "=", "False", ")", ")", "\n", "\n", "", "self", ".", "_layers", "[", "'ffn'", "]", ".", "append", "(", "[", "]", ")", "\n", "# Don't need relu for the last feedforward.", "\n", "for", "_", "in", "range", "(", "self", ".", "_num_feedforward", "-", "1", ")", ":", "\n", "        ", "self", ".", "_layers", "[", "'ffn'", "]", "[", "i", "]", ".", "append", "(", "\n", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "_hidden_size", ",", "activation", "=", "'relu'", ")", ")", "\n", "", "self", ".", "_layers", "[", "'ffn'", "]", "[", "i", "]", ".", "append", "(", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "_hidden_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.GraphConvolutionalTransformer.feedforward": [[187, 205], ["range", "tensorflow.nn.dropout"], "methods", ["None"], ["", "", "def", "feedforward", "(", "self", ",", "features", ",", "stack_index", ",", "training", "=", "None", ")", ":", "\n", "    ", "\"\"\"Feedforward component of Transformer.\n\n    Args:\n      features: 3D float Tensor of size (batch_size, num_features,\n        embedding_size). This is the input embedding to GCT.\n      stack_index: An integer to indicate which Transformer block we are in.\n      training: Whether to run in training or eval mode.\n\n    Returns:\n      Latent representations derived from this feedforward network.\n    \"\"\"", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_feedforward", ")", ":", "\n", "      ", "features", "=", "self", ".", "_layers", "[", "'ffn'", "]", "[", "stack_index", "]", "[", "i", "]", "(", "features", ")", "\n", "if", "training", ":", "\n", "        ", "features", "=", "tf", ".", "nn", ".", "dropout", "(", "features", ",", "rate", "=", "self", ".", "_ffn_dropout", ")", "\n", "\n", "", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.GraphConvolutionalTransformer.qk_op": [[206, 262], ["tensorflow.reshape", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.sqrt", "tensorflow.nn.softmax", "tensorflow.nn.sigmoid", "tensorflow.cast"], "methods", ["None"], ["", "def", "qk_op", "(", "self", ",", "\n", "features", ",", "\n", "stack_index", ",", "\n", "batch_size", ",", "\n", "num_codes", ",", "\n", "attention_mask", ",", "\n", "inf_mask", "=", "None", ",", "\n", "directed_mask", "=", "None", ")", ":", "\n", "    ", "\"\"\"Attention generation part of Transformer.\n\n    Args:\n      features: 3D float Tensor of size (batch_size, num_features,\n        embedding_size). This is the input embedding to GCT.\n      stack_index: An integer to indicate which Transformer block we are in.\n      batch_size: The size of the mini batch.\n      num_codes: The number of features (i.e. codes) given as input.\n      attention_mask: A Tensor for suppressing the attention on the padded\n        tokens.\n      inf_mask: The guide matrix to suppress the attention values to zeros for\n        certain parts of the attention matrix (e.g. diagnosis codes cannot\n        attend to other diagnosis codes).\n      directed_mask: If the user wants to only use the upper-triangle of the\n        attention for uni-directional attention flow, we use this strictly lower\n        triangular matrix filled with infinity.\n\n    Returns:\n      The attention distribution derived from the QK operation.\n    \"\"\"", "\n", "\n", "q", "=", "self", ".", "_layers", "[", "'Q'", "]", "[", "stack_index", "]", "(", "features", ")", "\n", "q", "=", "tf", ".", "reshape", "(", "q", ",", "\n", "[", "batch_size", ",", "num_codes", ",", "self", ".", "_hidden_size", ",", "self", ".", "_num_heads", "]", ")", "\n", "\n", "k", "=", "self", ".", "_layers", "[", "'K'", "]", "[", "stack_index", "]", "(", "features", ")", "\n", "k", "=", "tf", ".", "reshape", "(", "k", ",", "\n", "[", "batch_size", ",", "num_codes", ",", "self", ".", "_hidden_size", ",", "self", ".", "_num_heads", "]", ")", "\n", "\n", "# Need to transpose q and k to (2, 0, 1)", "\n", "q", "=", "tf", ".", "transpose", "(", "q", ",", "perm", "=", "[", "0", ",", "3", ",", "1", ",", "2", "]", ")", "\n", "k", "=", "tf", ".", "transpose", "(", "k", ",", "perm", "=", "[", "0", ",", "3", ",", "2", ",", "1", "]", ")", "\n", "pre_softmax", "=", "tf", ".", "matmul", "(", "q", ",", "k", ")", "/", "tf", ".", "sqrt", "(", "\n", "tf", ".", "cast", "(", "self", ".", "_hidden_size", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "pre_softmax", "-=", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "\n", "if", "inf_mask", "is", "not", "None", ":", "\n", "      ", "pre_softmax", "-=", "inf_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "\n", "", "if", "directed_mask", "is", "not", "None", ":", "\n", "      ", "pre_softmax", "-=", "directed_mask", "\n", "\n", "", "if", "self", ".", "_attention_normalizer", "==", "'softmax'", ":", "\n", "      ", "attention", "=", "tf", ".", "nn", ".", "softmax", "(", "pre_softmax", ",", "axis", "=", "3", ")", "\n", "", "else", ":", "\n", "      ", "attention", "=", "tf", ".", "nn", ".", "sigmoid", "(", "pre_softmax", ")", "\n", "", "return", "attention", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.GraphConvolutionalTransformer.call": [[263, 357], ["tensorflow.cast", "tensorflow.fill", "tensorflow.scatter_nd", "range", "tensorflow.shape", "tensorflow.shape", "tensorflow.where", "tensorflow.cast", "tensorflow.fill", "tensorflow.scatter_nd", "tensorflow.fill", "tensorflow.matrix_set_diag", "attentions.append", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.contrib.layers.layer_norm", "graph_convolutional_transformer.GraphConvolutionalTransformer.feedforward", "tensorflow.contrib.layers.layer_norm", "tensorflow.equal", "tensorflow.shape", "tensorflow.where", "tensorflow.zeros", "tensorflow.matrix_band_part", "tensorflow.tile", "graph_convolutional_transformer.GraphConvolutionalTransformer.qk_op", "tensorflow.squeeze", "tensorflow.shape", "tensorflow.equal", "tensorflow.shape", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.GraphConvolutionalTransformer.feedforward", "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.GraphConvolutionalTransformer.qk_op"], ["", "def", "call", "(", "self", ",", "features", ",", "masks", ",", "guide", "=", "None", ",", "prior_guide", "=", "None", ",", "training", "=", "None", ")", ":", "\n", "    ", "\"\"\"This function transforms the input embeddings.\n\n    This function converts the SparseTensor of integers to a dense Tensor of\n    tf.float32.\n\n    Args:\n      features: 3D float Tensor of size (batch_size, num_features,\n        embedding_size). This is the input embedding to GCT.\n      masks: 3D float Tensor of size (batch_size, num_features, 1). This holds\n        binary values to indicate which parts are padded and which are not.\n      guide: 3D float Tensor of size (batch_size, num_features, num_features).\n        This is the guide matrix.\n      prior_guide: 3D float Tensor of size (batch_size, num_features,\n        num_features). This is the conditional probability matrix.\n      training: Whether to run in training or eval mode.\n\n    Returns:\n      features: The final layer of GCT.\n      attentions: List of attention values from all layers of GCT. This will be\n        used later to regularize the self-attention process.\n    \"\"\"", "\n", "\n", "batch_size", "=", "tf", ".", "shape", "(", "features", ")", "[", "0", "]", "\n", "num_codes", "=", "tf", ".", "shape", "(", "features", ")", "[", "1", "]", "\n", "\n", "# Use the given masks to create a negative infinity Tensor to suppress the", "\n", "# attention weights of the padded tokens. Note that the given masks has", "\n", "# the shape (batch_size, num_codes, 1), so we remove the last dimension", "\n", "# during the process.", "\n", "mask_idx", "=", "tf", ".", "cast", "(", "tf", ".", "where", "(", "tf", ".", "equal", "(", "masks", "[", ":", ",", ":", ",", "0", "]", ",", "0.", ")", ")", ",", "tf", ".", "int32", ")", "\n", "mask_matrix", "=", "tf", ".", "fill", "(", "[", "tf", ".", "shape", "(", "mask_idx", ")", "[", "0", "]", "]", ",", "tf", ".", "float32", ".", "max", ")", "\n", "attention_mask", "=", "tf", ".", "scatter_nd", "(", "\n", "indices", "=", "mask_idx", ",", "updates", "=", "mask_matrix", ",", "shape", "=", "tf", ".", "shape", "(", "masks", "[", ":", ",", ":", ",", "0", "]", ")", ")", "\n", "\n", "inf_mask", "=", "None", "\n", "if", "self", ".", "_use_inf_mask", ":", "\n", "      ", "guide_idx", "=", "tf", ".", "cast", "(", "tf", ".", "where", "(", "tf", ".", "equal", "(", "guide", ",", "0.", ")", ")", ",", "tf", ".", "int32", ")", "\n", "inf_matrix", "=", "tf", ".", "fill", "(", "[", "tf", ".", "shape", "(", "guide_idx", ")", "[", "0", "]", "]", ",", "tf", ".", "float32", ".", "max", ")", "\n", "inf_mask", "=", "tf", ".", "scatter_nd", "(", "\n", "indices", "=", "guide_idx", ",", "updates", "=", "inf_matrix", ",", "shape", "=", "tf", ".", "shape", "(", "guide", ")", ")", "\n", "\n", "", "directed_mask", "=", "None", "\n", "if", "self", ".", "_directed_attention", ":", "\n", "      ", "inf_matrix", "=", "tf", ".", "fill", "(", "[", "num_codes", ",", "num_codes", "]", ",", "tf", ".", "float32", ".", "max", ")", "\n", "inf_matrix", "=", "tf", ".", "matrix_set_diag", "(", "inf_matrix", ",", "tf", ".", "zeros", "(", "num_codes", ")", ")", "\n", "directed_mask", "=", "tf", ".", "matrix_band_part", "(", "inf_matrix", ",", "-", "1", ",", "0", ")", "[", "None", ",", "None", ",", ":", ",", ":", "]", "\n", "\n", "", "attention", "=", "None", "\n", "attentions", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_stack", ")", ":", "\n", "      ", "features", "=", "masks", "*", "features", "\n", "\n", "if", "self", ".", "_use_prior", "and", "i", "==", "0", ":", "\n", "        ", "attention", "=", "tf", ".", "tile", "(", "prior_guide", "[", ":", ",", "None", ",", ":", ",", ":", "]", ",", "\n", "[", "1", ",", "self", ".", "_num_heads", ",", "1", ",", "1", "]", ")", "\n", "", "else", ":", "\n", "        ", "attention", "=", "self", ".", "qk_op", "(", "features", ",", "i", ",", "batch_size", ",", "num_codes", ",", "\n", "attention_mask", ",", "inf_mask", ",", "directed_mask", ")", "\n", "\n", "", "attentions", ".", "append", "(", "attention", ")", "\n", "\n", "v", "=", "self", ".", "_layers", "[", "'V'", "]", "[", "i", "]", "(", "features", ")", "\n", "v", "=", "tf", ".", "reshape", "(", "\n", "v", ",", "[", "batch_size", ",", "num_codes", ",", "self", ".", "_hidden_size", ",", "self", ".", "_num_heads", "]", ")", "\n", "v", "=", "tf", ".", "transpose", "(", "v", ",", "perm", "=", "[", "0", ",", "3", ",", "1", ",", "2", "]", ")", "\n", "# post_attention is (batch, num_heads, num_codes, hidden_size)", "\n", "post_attention", "=", "tf", ".", "matmul", "(", "attention", ",", "v", ")", "\n", "\n", "if", "self", ".", "_num_heads", "==", "1", ":", "\n", "        ", "post_attention", "=", "tf", ".", "squeeze", "(", "post_attention", ",", "axis", "=", "1", ")", "\n", "", "elif", "self", ".", "_multihead_aggregation", "==", "'concat'", ":", "\n", "# post_attention is (batch, num_codes, num_heads, hidden_size)", "\n", "        ", "post_attention", "=", "tf", ".", "transpose", "(", "post_attention", ",", "perm", "=", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "# post_attention is (batch, num_codes, num_heads*hidden_size)", "\n", "post_attention", "=", "tf", ".", "reshape", "(", "post_attention", ",", "[", "batch_size", ",", "num_codes", ",", "-", "1", "]", ")", "\n", "# post attention is (batch, num_codes, hidden_size)", "\n", "post_attention", "=", "self", ".", "_layers", "[", "'head_agg'", "]", "[", "i", "]", "(", "post_attention", ")", "\n", "", "else", ":", "\n", "        ", "post_attention", "=", "tf", ".", "reduce_sum", "(", "post_attention", ",", "axis", "=", "1", ")", "\n", "\n", "# Residual connection + layer normalization", "\n", "", "post_attention", "+=", "features", "\n", "post_attention", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "\n", "post_attention", ",", "begin_norm_axis", "=", "2", ")", "\n", "\n", "# Feedforward component + residual connection + layer normalization", "\n", "post_ffn", "=", "self", ".", "feedforward", "(", "post_attention", ",", "i", ",", "training", ")", "\n", "post_ffn", "+=", "post_attention", "\n", "post_ffn", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "post_ffn", ",", "begin_norm_axis", "=", "2", ")", "\n", "\n", "features", "=", "post_ffn", "\n", "\n", "", "return", "features", "*", "masks", ",", "attentions", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.SequenceExampleParser.__init__": [[569, 586], ["tensorflow.VarLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "num_map_threads", "=", "4", ")", ":", "\n", "    ", "\"\"\"Init function.\"\"\"", "\n", "self", ".", "context_features_config", "=", "{", "\n", "'patientId'", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "string", ")", ",", "\n", "'label.readmission'", ":", "tf", ".", "FixedLenFeature", "(", "[", "1", "]", ",", "tf", ".", "int64", ")", ",", "\n", "'label.expired'", ":", "tf", ".", "FixedLenFeature", "(", "[", "1", "]", ",", "tf", ".", "int64", ")", "\n", "}", "\n", "\n", "self", ".", "sequence_features_config", "=", "{", "\n", "'dx_ints'", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", ",", "\n", "'proc_ints'", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", ",", "\n", "'prior_indices'", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", ",", "\n", "'prior_values'", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "float32", ")", "\n", "}", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "num_map_threads", "=", "num_map_threads", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.SequenceExampleParser.__call__": [[587, 616], ["tensorflow.data.TFRecordDataset", "dataset.prefetch.prefetch.shuffle", "dataset.prefetch.prefetch.repeat", "dataset.prefetch.prefetch.map", "dataset.prefetch.prefetch.batch", "dataset.prefetch.prefetch.prefetch", "dataset.prefetch.prefetch.make_one_shot_iterator().get_next", "tensorflow.io.parse_single_sequence_example", "tensorflow.squeeze", "tensorflow.cast", "dataset.prefetch.prefetch.make_one_shot_iterator"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "tfrecord_path", ",", "label_key", ",", "training", ")", ":", "\n", "    ", "\"\"\"Parse function.\n\n    Args:\n      tfrecord_path: Path to TFRecord of SequenceExamples.\n      training: Boolean value to indicate whether the model if training.\n\n    Returns:\n      Dataset iterator.\n    \"\"\"", "\n", "\n", "def", "parser_fn", "(", "serialized_example", ")", ":", "\n", "      ", "(", "batch_context", ",", "batch_sequence", ")", "=", "tf", ".", "io", ".", "parse_single_sequence_example", "(", "\n", "serialized_example", ",", "\n", "context_features", "=", "self", ".", "context_features_config", ",", "\n", "sequence_features", "=", "self", ".", "sequence_features_config", ")", "\n", "labels", "=", "tf", ".", "squeeze", "(", "tf", ".", "cast", "(", "batch_context", "[", "label_key", "]", ",", "tf", ".", "float32", ")", ")", "\n", "return", "batch_sequence", ",", "labels", "\n", "\n", "", "num_epochs", "=", "None", "if", "training", "else", "1", "\n", "buffer_size", "=", "self", ".", "batch_size", "*", "32", "\n", "dataset", "=", "tf", ".", "data", ".", "TFRecordDataset", "(", "tfrecord_path", ")", "\n", "dataset", "=", "dataset", ".", "shuffle", "(", "buffer_size", ")", "\n", "dataset", "=", "dataset", ".", "repeat", "(", "num_epochs", ")", "\n", "dataset", "=", "dataset", ".", "map", "(", "parser_fn", ",", "num_parallel_calls", "=", "self", ".", "num_map_threads", ")", "\n", "dataset", "=", "dataset", ".", "batch", "(", "self", ".", "batch_size", ")", "\n", "dataset", "=", "dataset", ".", "prefetch", "(", "1", ")", "\n", "\n", "return", "dataset", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.EHRTransformer.__init__": [[626, 681], ["graph_convolutional_transformer.SequenceExampleParser"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "gct_params", ",", "\n", "feature_keys", "=", "[", "'dx_ints'", ",", "'proc_ints'", "]", ",", "\n", "label_key", "=", "'label.readmission'", ",", "\n", "vocab_sizes", "=", "{", "'dx_ints'", ":", "3249", ",", "'proc_ints'", ":", "2210", "}", ",", "\n", "feature_set", "=", "'vdp'", ",", "\n", "max_num_codes", "=", "50", ",", "\n", "prior_scalar", "=", "0.5", ",", "\n", "reg_coef", "=", "0.1", ",", "\n", "num_classes", "=", "1", ",", "\n", "learning_rate", "=", "1e-3", ",", "\n", "batch_size", "=", "32", ")", ":", "\n", "    ", "\"\"\"Init function.\n\n    Args:\n      gct_params: A dictionary parameteres to be used inside GCT class. See GCT\n        comments for more information.\n      feature_keys: A list of feature names you want to use. (e.g. ['dx_ints,\n        'proc_ints', 'lab_ints'])\n      vocab_sizes: A dictionary of vocabularize sizes for each feature. (e.g.\n        {'dx_ints': 1001, 'proc_ints': 1001, 'lab_ints': 1001})\n      feature_set: Use 'vdpl' to indicate your features are diagnosis codes,\n        treatment codes, and lab codes. Use 'vdp' to indicate your features are\n        diagnosis codes and treatment codes.\n      max_num_codes: The maximum number of how many feature there can be inside\n        a single visit, per feature. For example, if this is set to 50, then we\n        are assuming there can be up to 50 diagnosis codes, 50 treatment codes,\n        and 50 lab codes. This will be used for creating the prior matrix.\n      prior_scalar: A float value between 0.0 and 1.0 to be used to hard-code\n        the diagnoal elements of the prior matrix.\n      reg_coef: A coefficient to decide the KL regularization balance when\n        training GCT.\n      num_classes: This is set to 1, because this implementation only supports\n        graph-level binary classification.\n      learning_rate: Learning rate for Adam optimizer.\n      batch_size: Batch size.\n    \"\"\"", "\n", "self", ".", "_feature_keys", "=", "feature_keys", "\n", "self", ".", "_label_key", "=", "label_key", "\n", "self", ".", "_vocab_sizes", "=", "vocab_sizes", "\n", "self", ".", "_feature_set", "=", "feature_set", "\n", "self", ".", "_max_num_codes", "=", "max_num_codes", "\n", "self", ".", "_prior_scalar", "=", "prior_scalar", "\n", "self", ".", "_reg_coef", "=", "reg_coef", "\n", "self", ".", "_num_classes", "=", "num_classes", "\n", "self", ".", "_learning_rate", "=", "learning_rate", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "\n", "self", ".", "_gct_params", "=", "gct_params", "\n", "self", ".", "_embedding_size", "=", "gct_params", "[", "'embedding_size'", "]", "\n", "self", ".", "_num_transformer_stack", "=", "gct_params", "[", "'num_transformer_stack'", "]", "\n", "self", ".", "_use_inf_mask", "=", "gct_params", "[", "'use_inf_mask'", "]", "\n", "self", ".", "_use_prior", "=", "gct_params", "[", "'use_prior'", "]", "\n", "\n", "self", ".", "_seqex_reader", "=", "SequenceExampleParser", "(", "self", ".", "_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.EHRTransformer.get_prediction": [[682, 729], ["feature_embedder.lookup", "tensorflow.concat", "tensorflow.concat", "model", "tensorflow.reshape", "tensorflow.layers.dense", "tensorflow.squeeze", "graph_convolutional_transformer.create_matrix_vdpl", "graph_convolutional_transformer.create_matrix_vdp", "sys.exit"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.FeatureEmbedder.lookup", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.create_matrix_vdpl", "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.create_matrix_vdp"], ["", "def", "get_prediction", "(", "self", ",", "model", ",", "feature_embedder", ",", "features", ",", "training", "=", "False", ")", ":", "\n", "    ", "\"\"\"Accepts features and produces logits and attention values.\n\n    Args:\n      features: A dictionary of SparseTensors for each sequence feature.\n      training: A boolean value to indicate whether the predictions are for\n        training or inference. If set to True, dropouts will take effect.\n\n    Returns:\n      logits: Logits for prediction.\n      attentions: List of attention values from all layers of GCT. Pass this to\n        get_loss to regularize the attention generation mechanism.\n    \"\"\"", "\n", "# 1. Embedding lookup", "\n", "embedding_dict", ",", "mask_dict", "=", "feature_embedder", ".", "lookup", "(", "\n", "features", ",", "self", ".", "_max_num_codes", ")", "\n", "\n", "# 2. Concatenate embeddings and masks into a single tensor.", "\n", "keys", "=", "[", "'visit'", "]", "+", "self", ".", "_feature_keys", "\n", "embeddings", "=", "tf", ".", "concat", "(", "[", "embedding_dict", "[", "key", "]", "for", "key", "in", "keys", "]", ",", "axis", "=", "1", ")", "\n", "masks", "=", "tf", ".", "concat", "(", "[", "mask_dict", "[", "key", "]", "for", "key", "in", "keys", "]", ",", "axis", "=", "1", ")", "\n", "\n", "# 2-1. Create the guide matrix and the prior matrix.", "\n", "if", "self", ".", "_feature_set", "==", "'vdpl'", ":", "\n", "      ", "guide", ",", "prior_guide", "=", "create_matrix_vdpl", "(", "features", ",", "masks", ",", "self", ".", "_use_prior", ",", "\n", "self", ".", "_use_inf_mask", ",", "\n", "self", ".", "_max_num_codes", ",", "\n", "self", ".", "_prior_scalar", ")", "\n", "", "elif", "self", ".", "_feature_set", "==", "'vdp'", ":", "\n", "      ", "guide", ",", "prior_guide", "=", "create_matrix_vdp", "(", "features", ",", "masks", ",", "self", ".", "_use_prior", ",", "\n", "self", ".", "_use_inf_mask", ",", "\n", "self", ".", "_max_num_codes", ",", "\n", "self", ".", "_prior_scalar", ")", "\n", "", "else", ":", "\n", "      ", "sys", ".", "exit", "(", "0", ")", "\n", "\n", "# 3. Process embeddings with GCT", "\n", "", "hidden", ",", "attentions", "=", "model", "(", "\n", "embeddings", ",", "masks", "[", ":", ",", ":", ",", "None", "]", ",", "guide", ",", "prior_guide", ",", "training", ")", "\n", "\n", "# 4. Generate logits", "\n", "pre_logit", "=", "hidden", "[", ":", ",", "0", ",", ":", "]", "\n", "pre_logit", "=", "tf", ".", "reshape", "(", "pre_logit", ",", "[", "-", "1", ",", "self", ".", "_embedding_size", "]", ")", "\n", "logits", "=", "tf", ".", "layers", ".", "dense", "(", "pre_logit", ",", "self", ".", "_num_classes", ",", "activation", "=", "None", ")", "\n", "logits", "=", "tf", ".", "squeeze", "(", "logits", ")", "\n", "\n", "return", "logits", ",", "attentions", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.EHRTransformer.get_loss": [[730, 761], ["tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.convert_to_tensor", "range", "tensorflow.reduce_mean", "tensorflow.log", "tensorflow.log", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "kl_terms.append"], "methods", ["None"], ["", "def", "get_loss", "(", "self", ",", "logits", ",", "labels", ",", "attentions", ")", ":", "\n", "    ", "\"\"\"Creates a loss tensor.\n\n    Args:\n      logits: Logits for prediction. This is obtained by calling get_prediction.\n      labels: Labels for prediction.\n      attentions: List of attention values from all layers of GCT. This is\n        obtained by calling get_prediction.\n\n    Returns:\n      Loss tensor. If we use the conditional probability matrix, then GCT's\n      attention mechanism will be regularized using KL divergence.\n    \"\"\"", "\n", "loss", "=", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "labels", "=", "labels", ",", "logits", "=", "logits", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "\n", "if", "self", ".", "_use_prior", ":", "\n", "      ", "kl_terms", "=", "[", "]", "\n", "attention_tensor", "=", "tf", ".", "convert_to_tensor", "(", "attentions", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "self", ".", "_num_transformer_stack", ")", ":", "\n", "        ", "log_p", "=", "tf", ".", "log", "(", "attention_tensor", "[", "i", "-", "1", "]", "+", "1e-12", ")", "\n", "log_q", "=", "tf", ".", "log", "(", "attention_tensor", "[", "i", "]", "+", "1e-12", ")", "\n", "kl_term", "=", "attention_tensor", "[", "i", "-", "1", "]", "*", "(", "log_p", "-", "log_q", ")", "\n", "kl_term", "=", "tf", ".", "reduce_sum", "(", "kl_term", ",", "axis", "=", "-", "1", ")", "\n", "kl_term", "=", "tf", ".", "reduce_mean", "(", "kl_term", ")", "\n", "kl_terms", ".", "append", "(", "kl_term", ")", "\n", "\n", "", "reg_term", "=", "tf", ".", "reduce_mean", "(", "kl_terms", ")", "\n", "loss", "+=", "self", ".", "_reg_coef", "*", "reg_term", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.EHRTransformer.input_fn": [[762, 773], ["graph_convolutional_transformer.EHRTransformer._seqex_reader"], "methods", ["None"], ["", "def", "input_fn", "(", "self", ",", "tfrecord_path", ",", "training", ")", ":", "\n", "    ", "\"\"\"Input function to be used by TensorFlow Estimator.\n\n    Args:\n      tfrecord_path: Path to TFRecord of SequenceExamples.\n      training: Boolean value to indicate whether the model if training.\n\n    Return:\n      Input generator.\n    \"\"\"", "\n", "return", "self", ".", "_seqex_reader", "(", "tfrecord_path", ",", "self", ".", "_label_key", ",", "training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.EHRTransformer.model_fn": [[774, 833], ["graph_convolutional_transformer.GraphConvolutionalTransformer", "graph_convolutional_transformer.FeatureEmbedder", "graph_convolutional_transformer.EHRTransformer.get_prediction", "tensorflow.nn.sigmoid", "graph_convolutional_transformer.EHRTransformer.get_loss", "tensorflow.estimator.EstimatorSpec", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer.minimize", "tensorflow.train.get_global_step", "tensorflow.assign", "tensorflow.estimator.EstimatorSpec", "tensorflow.estimator.EstimatorSpec", "tensorflow.metrics.auc", "tensorflow.metrics.auc", "tensorflow.group"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.EHRTransformer.get_prediction", "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.EHRTransformer.get_loss"], ["", "def", "model_fn", "(", "self", ",", "features", ",", "labels", ",", "mode", ")", ":", "\n", "    ", "\"\"\"Model function to be used by TensorFlow Estimator.\n\n    Args:\n      features: Dictionary of features.\n      labels: True labels for training.\n      mode: The mode the model is in tf.estimator.ModeKeys.\n\n    Return:\n      Train/Eval/Prediction op depending on the mode.\n    \"\"\"", "\n", "training", "=", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", "\n", "\n", "model", "=", "GraphConvolutionalTransformer", "(", "**", "self", ".", "_gct_params", ")", "\n", "feature_embedder", "=", "FeatureEmbedder", "(", "\n", "self", ".", "_vocab_sizes", ",", "self", ".", "_feature_keys", ",", "self", ".", "_embedding_size", ")", "\n", "\n", "logits", ",", "attentions", "=", "self", ".", "get_prediction", "(", "\n", "model", ",", "feature_embedder", ",", "features", ",", "training", ")", "\n", "probs", "=", "tf", ".", "nn", ".", "sigmoid", "(", "logits", ")", "\n", "predictions", "=", "{", "\n", "'probabilities'", ":", "probs", ",", "\n", "'logits'", ":", "logits", ",", "\n", "}", "\n", "\n", "# output predictions", "\n", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "PREDICT", ":", "\n", "      ", "return", "tf", ".", "estimator", ".", "EstimatorSpec", "(", "mode", ",", "predictions", "=", "predictions", ")", "\n", "\n", "# create loss (should be equal to caffe softmaxwithloss)", "\n", "", "loss", "=", "self", ".", "get_loss", "(", "logits", ",", "labels", ",", "attentions", ")", "\n", "\n", "if", "training", ":", "\n", "      ", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "self", ".", "_learning_rate", ",", "\n", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "epsilon", "=", "1e-8", ")", "\n", "train_op", "=", "optimizer", ".", "minimize", "(", "loss", ")", "\n", "global_step", "=", "tf", ".", "train", ".", "get_global_step", "(", ")", "\n", "update_global_step", "=", "tf", ".", "assign", "(", "\n", "global_step", ",", "global_step", "+", "1", ",", "name", "=", "'update_global_step'", ")", "\n", "\n", "# create estimator training spec.", "\n", "return", "tf", ".", "estimator", ".", "EstimatorSpec", "(", "\n", "mode", ",", "\n", "loss", "=", "loss", ",", "\n", "train_op", "=", "tf", ".", "group", "(", "train_op", ",", "update_global_step", ")", ",", "\n", "predictions", "=", "predictions", ")", "\n", "\n", "", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ":", "\n", "# Define the metrics:", "\n", "      ", "metrics_dict", "=", "{", "\n", "'AUC-PR'", ":", "tf", ".", "metrics", ".", "auc", "(", "labels", ",", "probs", ",", "curve", "=", "'PR'", ",", "\n", "summation_method", "=", "'careful_interpolation'", ")", ",", "\n", "'AUC-ROC'", ":", "tf", ".", "metrics", ".", "auc", "(", "labels", ",", "probs", ",", "curve", "=", "'ROC'", ",", "\n", "summation_method", "=", "'careful_interpolation'", ")", "\n", "}", "\n", "\n", "#return eval spec", "\n", "return", "tf", ".", "estimator", ".", "EstimatorSpec", "(", "\n", "mode", ",", "loss", "=", "loss", ",", "eval_metric_ops", "=", "metrics_dict", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.create_matrix_vdpl": [[359, 462], ["tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.zeros", "tensorflow.concat", "tensorflow.tile", "tensorflow.reshape", "tensorflow.concat", "tensorflow.contrib.framework.argsort", "tensorflow.gather", "tensorflow.SparseTensor", "tensorflow.sparse.to_dense", "tensorflow.convert_to_tensor", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.reduce_sum", "tensorflow.transpose", "tensorflow.zeros", "tensorflow.ones", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.ones", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.ones", "tensorflow.eye", "tensorflow.tile", "tensorflow.tile", "tensorflow.eye"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat"], ["", "", "def", "create_matrix_vdpl", "(", "features", ",", "mask", ",", "use_prior", ",", "use_inf_mask", ",", "max_num_codes", ",", "\n", "prior_scalar", ")", ":", "\n", "  ", "\"\"\"Creates guide matrix and prior matrix when feature_set='vdpl'.\n\n  This function creates the guide matrix and the prior matrix when visits\n  include diagnosis codes, treatment codes, and lab codes.\n\n  Args:\n    features: A dictionary of SparseTensors for each feature.\n    mask: 3D float Tensor of size (batch_size, num_features, 1). This holds\n      binary values to indicate which parts are padded and which are not.\n    use_prior: Whether to create the prior matrix.\n    use_inf_mask : Whether to create the guide matrix.\n    max_num_codes: The maximum number of how many feature there can be inside a\n      single visit, per feature. For example, if this is set to 50, then we are\n      assuming there can be up to 50 diagnosis codes, 50 treatment codes, and 50\n      lab codes. This will be used for creating the prior matrix.\n    prior_scalar: A float value between 0.0 and 1.0 to be used to hard-code the\n      diagnoal elements of the prior matrix.\n\n  Returns:\n    guide: The guide matrix.\n    prior_guide: The conditional probablity matrix.\n  \"\"\"", "\n", "dx_ids", "=", "features", "[", "'dx_ints'", "]", "\n", "proc_ids", "=", "features", "[", "'proc_ints'", "]", "\n", "lab_ids", "=", "features", "[", "'loinc_bucketized_ints'", "]", "\n", "\n", "batch_size", "=", "dx_ids", ".", "dense_shape", "[", "0", "]", "\n", "num_dx_ids", "=", "max_num_codes", "if", "use_prior", "else", "dx_ids", ".", "dense_shape", "[", "-", "1", "]", "\n", "num_proc_ids", "=", "max_num_codes", "if", "use_prior", "else", "proc_ids", ".", "dense_shape", "[", "-", "1", "]", "\n", "num_lab_ids", "=", "max_num_codes", "if", "use_prior", "else", "lab_ids", ".", "dense_shape", "[", "-", "1", "]", "\n", "num_codes", "=", "1", "+", "num_dx_ids", "+", "num_proc_ids", "+", "num_lab_ids", "\n", "\n", "guide", "=", "None", "\n", "if", "use_inf_mask", ":", "\n", "    ", "row0", "=", "tf", ".", "concat", "(", "[", "\n", "tf", ".", "zeros", "(", "[", "1", ",", "1", "]", ")", ",", "\n", "tf", ".", "ones", "(", "[", "1", ",", "num_dx_ids", "]", ")", ",", "\n", "tf", ".", "zeros", "(", "[", "1", ",", "num_proc_ids", "+", "num_lab_ids", "]", ")", "\n", "]", ",", "\n", "axis", "=", "1", ")", "\n", "\n", "row1", "=", "tf", ".", "concat", "(", "[", "\n", "tf", ".", "zeros", "(", "[", "num_dx_ids", ",", "1", "+", "num_dx_ids", "]", ")", ",", "\n", "tf", ".", "ones", "(", "[", "num_dx_ids", ",", "num_proc_ids", "]", ")", ",", "\n", "tf", ".", "zeros", "(", "[", "num_dx_ids", ",", "num_lab_ids", "]", ")", "\n", "]", ",", "\n", "axis", "=", "1", ")", "\n", "\n", "row2", "=", "tf", ".", "concat", "(", "[", "\n", "tf", ".", "zeros", "(", "[", "num_proc_ids", ",", "1", "+", "num_dx_ids", "+", "num_proc_ids", "]", ")", ",", "\n", "tf", ".", "ones", "(", "[", "num_proc_ids", ",", "num_lab_ids", "]", ")", "\n", "]", ",", "\n", "axis", "=", "1", ")", "\n", "\n", "row3", "=", "tf", ".", "zeros", "(", "[", "num_lab_ids", ",", "num_codes", "]", ")", "\n", "\n", "guide", "=", "tf", ".", "concat", "(", "[", "row0", ",", "row1", ",", "row2", ",", "row3", "]", ",", "axis", "=", "0", ")", "\n", "guide", "=", "guide", "+", "tf", ".", "transpose", "(", "guide", ")", "\n", "guide", "=", "tf", ".", "tile", "(", "guide", "[", "None", ",", ":", ",", ":", "]", ",", "[", "batch_size", ",", "1", ",", "1", "]", ")", "\n", "guide", "=", "(", "\n", "guide", "*", "mask", "[", ":", ",", ":", ",", "None", "]", "*", "mask", "[", ":", ",", "None", ",", ":", "]", "+", "\n", "tf", ".", "eye", "(", "num_codes", ")", "[", "None", ",", ":", ",", ":", "]", ")", "\n", "\n", "", "prior_guide", "=", "None", "\n", "if", "use_prior", ":", "\n", "    ", "prior_values", "=", "features", "[", "'prior_values'", "]", "\n", "prior_idx_values", "=", "prior_values", ".", "values", "\n", "\n", "prior_indices", "=", "features", "[", "'prior_indices'", "]", "\n", "prior_batch_idx", "=", "prior_indices", ".", "indices", "[", ":", ",", "0", "]", "[", ":", ":", "2", "]", "\n", "prior_idx", "=", "tf", ".", "reshape", "(", "prior_indices", ".", "values", ",", "[", "-", "1", ",", "2", "]", ")", "\n", "prior_idx", "=", "tf", ".", "concat", "(", "\n", "[", "prior_batch_idx", "[", ":", ",", "None", "]", ",", "prior_idx", "[", ":", ",", ":", "1", "]", ",", "prior_idx", "[", ":", ",", "1", ":", "]", "]", ",", "axis", "=", "1", ")", "\n", "\n", "temp_idx", "=", "(", "\n", "prior_idx", "[", ":", ",", "0", "]", "*", "1000000", "+", "prior_idx", "[", ":", ",", "1", "]", "*", "1000", "+", "prior_idx", "[", ":", ",", "2", "]", ")", "\n", "sorted_idx", "=", "tf", ".", "contrib", ".", "framework", ".", "argsort", "(", "temp_idx", ")", "\n", "prior_idx", "=", "tf", ".", "gather", "(", "prior_idx", ",", "sorted_idx", ")", "\n", "\n", "prior_idx_shape", "=", "[", "batch_size", ",", "max_num_codes", "*", "3", ",", "max_num_codes", "*", "3", "]", "\n", "sparse_prior", "=", "tf", ".", "SparseTensor", "(", "\n", "indices", "=", "prior_idx", ",", "values", "=", "prior_idx_values", ",", "dense_shape", "=", "prior_idx_shape", ")", "\n", "prior_guide", "=", "tf", ".", "sparse", ".", "to_dense", "(", "sparse_prior", ",", "validate_indices", "=", "True", ")", "\n", "\n", "visit_guide", "=", "tf", ".", "convert_to_tensor", "(", "\n", "[", "prior_scalar", "]", "*", "max_num_codes", "+", "[", "0.0", "]", "*", "max_num_codes", "*", "2", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "prior_guide", "=", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "tile", "(", "visit_guide", "[", "None", ",", "None", ",", ":", "]", ",", "[", "batch_size", ",", "1", ",", "1", "]", ")", ",", "prior_guide", "]", ",", "\n", "axis", "=", "1", ")", "\n", "visit_guide", "=", "tf", ".", "concat", "(", "[", "[", "0.0", "]", ",", "visit_guide", "]", ",", "axis", "=", "0", ")", "\n", "prior_guide", "=", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "tile", "(", "visit_guide", "[", "None", ",", ":", ",", "None", "]", ",", "[", "batch_size", ",", "1", ",", "1", "]", ")", ",", "prior_guide", "]", ",", "\n", "axis", "=", "2", ")", "\n", "prior_guide", "=", "(", "\n", "prior_guide", "*", "mask", "[", ":", ",", ":", ",", "None", "]", "*", "mask", "[", ":", ",", "None", ",", ":", "]", "+", "\n", "prior_scalar", "*", "tf", ".", "eye", "(", "num_codes", ")", "[", "None", ",", ":", ",", ":", "]", ")", "\n", "degrees", "=", "tf", ".", "reduce_sum", "(", "prior_guide", ",", "axis", "=", "2", ")", "\n", "prior_guide", "=", "prior_guide", "/", "degrees", "[", ":", ",", ":", ",", "None", "]", "\n", "\n", "", "return", "guide", ",", "prior_guide", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.graph-convolutional-transformer.graph_convolutional_transformer.create_matrix_vdp": [[464, 558], ["tensorflow.concat", "tensorflow.concat", "tensorflow.zeros", "tensorflow.concat", "tensorflow.tile", "tensorflow.reshape", "tensorflow.concat", "tensorflow.contrib.framework.argsort", "tensorflow.gather", "tensorflow.SparseTensor", "tensorflow.sparse.to_dense", "tensorflow.convert_to_tensor", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.reduce_sum", "tensorflow.transpose", "tensorflow.zeros", "tensorflow.ones", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.ones", "tensorflow.eye", "tensorflow.tile", "tensorflow.tile", "tensorflow.eye"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat"], ["", "def", "create_matrix_vdp", "(", "features", ",", "mask", ",", "use_prior", ",", "use_inf_mask", ",", "max_num_codes", ",", "\n", "prior_scalar", ")", ":", "\n", "  ", "\"\"\"Creates guide matrix and prior matrix when feature_set='vdp'.\n\n  This function creates the guide matrix and the prior matrix when visits\n  include diagnosis codes, treatment codes, but not lab codes.\n\n  Args:\n    features: A dictionary of SparseTensors for each feature.\n    mask: 3D float Tensor of size (batch_size, num_features, 1). This holds\n      binary values to indicate which parts are padded and which are not.\n    use_prior: Whether to create the prior matrix.\n    use_inf_mask : Whether to create the guide matrix.\n    max_num_codes: The maximum number of how many feature there can be inside a\n      single visit, per feature. For example, if this is set to 50, then we are\n      assuming there can be up to 50 diagnosis codes and 50 treatment codes.\n      This will be used for creating the prior matrix.\n    prior_scalar: A float value between 0.0 and 1.0 to be used to hard-code the\n      diagnoal elements of the prior matrix.\n\n  Returns:\n    guide: The guide matrix.\n    prior_guide: The conditional probablity matrix.\n  \"\"\"", "\n", "dx_ids", "=", "features", "[", "'dx_ints'", "]", "\n", "proc_ids", "=", "features", "[", "'proc_ints'", "]", "\n", "\n", "batch_size", "=", "dx_ids", ".", "dense_shape", "[", "0", "]", "\n", "num_dx_ids", "=", "max_num_codes", "if", "use_prior", "else", "dx_ids", ".", "dense_shape", "[", "-", "1", "]", "\n", "num_proc_ids", "=", "max_num_codes", "if", "use_prior", "else", "proc_ids", ".", "dense_shape", "[", "-", "1", "]", "\n", "num_codes", "=", "1", "+", "num_dx_ids", "+", "num_proc_ids", "\n", "\n", "guide", "=", "None", "\n", "if", "use_inf_mask", ":", "\n", "    ", "row0", "=", "tf", ".", "concat", "(", "[", "\n", "tf", ".", "zeros", "(", "[", "1", ",", "1", "]", ")", ",", "\n", "tf", ".", "ones", "(", "[", "1", ",", "num_dx_ids", "]", ")", ",", "\n", "tf", ".", "zeros", "(", "[", "1", ",", "num_proc_ids", "]", ")", "\n", "]", ",", "\n", "axis", "=", "1", ")", "\n", "\n", "row1", "=", "tf", ".", "concat", "(", "[", "\n", "tf", ".", "zeros", "(", "[", "num_dx_ids", ",", "1", "+", "num_dx_ids", "]", ")", ",", "\n", "tf", ".", "ones", "(", "[", "num_dx_ids", ",", "num_proc_ids", "]", ")", "\n", "]", ",", "\n", "axis", "=", "1", ")", "\n", "\n", "row2", "=", "tf", ".", "zeros", "(", "[", "num_proc_ids", ",", "num_codes", "]", ")", "\n", "\n", "guide", "=", "tf", ".", "concat", "(", "[", "row0", ",", "row1", ",", "row2", "]", ",", "axis", "=", "0", ")", "\n", "guide", "=", "guide", "+", "tf", ".", "transpose", "(", "guide", ")", "\n", "guide", "=", "tf", ".", "tile", "(", "guide", "[", "None", ",", ":", ",", ":", "]", ",", "[", "batch_size", ",", "1", ",", "1", "]", ")", "\n", "guide", "=", "(", "\n", "guide", "*", "mask", "[", ":", ",", ":", ",", "None", "]", "*", "mask", "[", ":", ",", "None", ",", ":", "]", "+", "\n", "tf", ".", "eye", "(", "num_codes", ")", "[", "None", ",", ":", ",", ":", "]", ")", "\n", "\n", "", "prior_guide", "=", "None", "\n", "if", "use_prior", ":", "\n", "    ", "prior_values", "=", "features", "[", "'prior_values'", "]", "\n", "prior_idx_values", "=", "prior_values", ".", "values", "\n", "\n", "prior_indices", "=", "features", "[", "'prior_indices'", "]", "\n", "prior_batch_idx", "=", "prior_indices", ".", "indices", "[", ":", ",", "0", "]", "[", ":", ":", "2", "]", "\n", "prior_idx", "=", "tf", ".", "reshape", "(", "prior_indices", ".", "values", ",", "[", "-", "1", ",", "2", "]", ")", "\n", "prior_idx", "=", "tf", ".", "concat", "(", "\n", "[", "prior_batch_idx", "[", ":", ",", "None", "]", ",", "prior_idx", "[", ":", ",", ":", "1", "]", ",", "prior_idx", "[", ":", ",", "1", ":", "]", "]", ",", "axis", "=", "1", ")", "\n", "\n", "temp_idx", "=", "(", "\n", "prior_idx", "[", ":", ",", "0", "]", "*", "1000000", "+", "prior_idx", "[", ":", ",", "1", "]", "*", "1000", "+", "prior_idx", "[", ":", ",", "2", "]", ")", "\n", "sorted_idx", "=", "tf", ".", "contrib", ".", "framework", ".", "argsort", "(", "temp_idx", ")", "\n", "prior_idx", "=", "tf", ".", "gather", "(", "prior_idx", ",", "sorted_idx", ")", "\n", "\n", "prior_idx_shape", "=", "[", "batch_size", ",", "max_num_codes", "*", "2", ",", "max_num_codes", "*", "2", "]", "\n", "sparse_prior", "=", "tf", ".", "SparseTensor", "(", "\n", "indices", "=", "prior_idx", ",", "values", "=", "prior_idx_values", ",", "dense_shape", "=", "prior_idx_shape", ")", "\n", "prior_guide", "=", "tf", ".", "sparse", ".", "to_dense", "(", "sparse_prior", ",", "validate_indices", "=", "True", ")", "\n", "\n", "visit_guide", "=", "tf", ".", "convert_to_tensor", "(", "\n", "[", "prior_scalar", "]", "*", "max_num_codes", "+", "[", "0.0", "]", "*", "max_num_codes", "*", "1", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "prior_guide", "=", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "tile", "(", "visit_guide", "[", "None", ",", "None", ",", ":", "]", ",", "[", "batch_size", ",", "1", ",", "1", "]", ")", ",", "prior_guide", "]", ",", "\n", "axis", "=", "1", ")", "\n", "visit_guide", "=", "tf", ".", "concat", "(", "[", "[", "0.0", "]", ",", "visit_guide", "]", ",", "axis", "=", "0", ")", "\n", "prior_guide", "=", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "tile", "(", "visit_guide", "[", "None", ",", ":", ",", "None", "]", ",", "[", "batch_size", ",", "1", ",", "1", "]", ")", ",", "prior_guide", "]", ",", "\n", "axis", "=", "2", ")", "\n", "prior_guide", "=", "(", "\n", "prior_guide", "*", "mask", "[", ":", ",", ":", ",", "None", "]", "*", "mask", "[", ":", ",", "None", ",", ":", "]", "+", "\n", "prior_scalar", "*", "tf", ".", "eye", "(", "num_codes", ")", "[", "None", ",", ":", ",", ":", "]", ")", "\n", "degrees", "=", "tf", ".", "reduce_sum", "(", "prior_guide", ",", "axis", "=", "2", ")", "\n", "prior_guide", "=", "prior_guide", "/", "degrees", "[", ":", ",", ":", ",", "None", "]", "\n", "\n", "", "return", "guide", ",", "prior_guide", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.init_dx_probs": [[27, 42], ["numpy.random.pareto", "range", "numpy.array", "range", "np.random.pareto.sum", "numpy.random.pareto", "np.array.append", "numpy.random.permutation", "np.array.sum"], "function", ["None"], ["def", "init_dx_probs", "(", "dx_vocab_size", ",", "pareto_prior", "=", "2.", ",", "pareto_prior2", "=", "1.5", ")", ":", "\n", "  ", "dx_logits", "=", "np", ".", "random", ".", "pareto", "(", "pareto_prior", ",", "dx_vocab_size", ")", "\n", "dx_probs", "=", "dx_logits", "/", "dx_logits", ".", "sum", "(", ")", "\n", "\n", "dx_cond_logits", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "dx_vocab_size", ")", ":", "\n", "    ", "logits", "=", "np", ".", "random", ".", "pareto", "(", "pareto_prior2", ",", "dx_vocab_size", ")", "\n", "dx_cond_logits", ".", "append", "(", "np", ".", "random", ".", "permutation", "(", "logits", ")", ")", "\n", "\n", "", "dx_cond_logits", "=", "np", ".", "array", "(", "dx_cond_logits", ")", "\n", "for", "i", "in", "range", "(", "dx_vocab_size", ")", ":", "\n", "    ", "dx_cond_logits", "[", "i", ",", "i", "]", "=", "0.", "\n", "", "dx_cond_probs", "=", "dx_cond_logits", "/", "dx_cond_logits", ".", "sum", "(", "axis", "=", "1", ")", "[", ":", ",", "None", "]", "\n", "\n", "return", "dx_probs", ",", "dx_cond_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.init_dx_proc_probs": [[44, 54], ["range", "numpy.array", "numpy.random.pareto", "np.array.append", "numpy.random.permutation", "np.array.sum"], "function", ["None"], ["", "def", "init_dx_proc_probs", "(", "dx_vocab_size", ",", "proc_vocab_size", ",", "pareto_prior", "=", "1.5", ")", ":", "\n", "  ", "dx_proc_logits", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "dx_vocab_size", ")", ":", "\n", "    ", "logits", "=", "np", ".", "random", ".", "pareto", "(", "pareto_prior", ",", "proc_vocab_size", ")", "\n", "dx_proc_logits", ".", "append", "(", "np", ".", "random", ".", "permutation", "(", "logits", ")", ")", "\n", "\n", "", "dx_proc_logits", "=", "np", ".", "array", "(", "dx_proc_logits", ")", "\n", "dx_proc_probs", "=", "dx_proc_logits", "/", "dx_proc_logits", ".", "sum", "(", "axis", "=", "1", ")", "[", ":", ",", "None", "]", "\n", "\n", "return", "dx_proc_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.init_dx_proc_lab_probs": [[56, 73], ["range", "numpy.array", "range", "np.array.append", "proc_lab_logits.append", "numpy.random.pareto", "proc_lab_logits.append", "np.array.sum", "numpy.zeros", "numpy.random.permutation"], "function", ["None"], ["", "def", "init_dx_proc_lab_probs", "(", "dx_vocab_size", ",", "proc_vocab_size", ",", "lab_vocab_size", ",", "\n", "dx_proc_cond_probs", ",", "pareto_prior", "=", "1.5", ")", ":", "\n", "  ", "dx_proc_lab_logits", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "dx_vocab_size", ")", ":", "\n", "    ", "proc_lab_logits", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "proc_vocab_size", ")", ":", "\n", "      ", "if", "dx_proc_cond_probs", "[", "i", ",", "j", "]", "==", "0.0", ":", "\n", "        ", "proc_lab_logits", ".", "append", "(", "np", ".", "zeros", "(", "lab_vocab_size", ")", ")", "\n", "", "else", ":", "\n", "        ", "logits", "=", "np", ".", "random", ".", "pareto", "(", "pareto_prior", ",", "lab_vocab_size", ")", "\n", "proc_lab_logits", ".", "append", "(", "np", ".", "random", ".", "permutation", "(", "logits", ")", ")", "\n", "", "", "dx_proc_lab_logits", ".", "append", "(", "proc_lab_logits", ")", "\n", "", "dx_proc_lab_logits", "=", "np", ".", "array", "(", "dx_proc_lab_logits", ")", "\n", "dx_proc_lab_probs", "=", "(", "\n", "dx_proc_lab_logits", "/", "(", "dx_proc_lab_logits", ".", "sum", "(", "axis", "=", "2", ")", "[", ":", ",", ":", ",", "None", "]", "+", "1e-12", ")", ")", "\n", "\n", "return", "dx_proc_lab_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.generate_dx": [[75, 86], ["list", "numpy.argmax", "dx_list.append", "set", "numpy.random.uniform", "len", "numpy.random.multinomial", "numpy.random.uniform", "numpy.argmax", "dx_list.append", "numpy.random.multinomial"], "function", ["None"], ["", "def", "generate_dx", "(", "dx_probs", ",", "dx_dx_cond_probs", ",", "multi_dx_prob", ",", "dx_dx_probs", ")", ":", "\n", "  ", "dx_list", "=", "[", "]", "\n", "while", "np", ".", "random", ".", "uniform", "(", "0.", ",", "1.", ")", "<", "multi_dx_prob", "or", "len", "(", "dx_list", ")", "<", "2", ":", "\n", "    ", "new_dx", "=", "np", ".", "argmax", "(", "np", ".", "random", ".", "multinomial", "(", "1", ",", "dx_probs", ")", ")", "\n", "dx_list", ".", "append", "(", "new_dx", ")", "\n", "prev_dx", "=", "new_dx", "\n", "while", "np", ".", "random", ".", "uniform", "(", "0.", ",", "1.", ")", "<", "dx_dx_probs", "[", "prev_dx", "]", ":", "\n", "      ", "new_dx", "=", "np", ".", "argmax", "(", "np", ".", "random", ".", "multinomial", "(", "1", ",", "dx_dx_cond_probs", "[", "prev_dx", "]", ")", ")", "\n", "dx_list", ".", "append", "(", "new_dx", ")", "\n", "prev_dx", "=", "new_dx", "\n", "", "", "return", "list", "(", "set", "(", "dx_list", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.generate_procs": [[88, 100], ["set", "numpy.random.uniform", "numpy.argmax", "set.add", "process_synthetic.generate_labs", "proc_list.append", "numpy.random.multinomial"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.generate_labs"], ["", "def", "generate_procs", "(", "dx", ",", "dx_proc_cond_probs", ",", "multi_proc_probs", ",", "\n", "dx_proc_lab_cond_probs", ",", "multi_lab_probs", ")", ":", "\n", "  ", "proc_list", "=", "[", "]", "\n", "proc_set", "=", "set", "(", ")", "\n", "while", "np", ".", "random", ".", "uniform", "(", "0.", ",", "1.", ")", "<", "multi_proc_probs", "[", "dx", "]", ":", "\n", "    ", "proc", "=", "np", ".", "argmax", "(", "np", ".", "random", ".", "multinomial", "(", "1", ",", "dx_proc_cond_probs", "[", "dx", "]", ")", ")", "\n", "if", "proc", "in", "proc_set", ":", "\n", "      ", "continue", "\n", "", "proc_set", ".", "add", "(", "proc", ")", "\n", "labs", "=", "generate_labs", "(", "dx", ",", "proc", ",", "dx_proc_lab_cond_probs", ",", "multi_lab_probs", ")", "\n", "proc_list", ".", "append", "(", "[", "proc", ",", "labs", "]", ")", "\n", "", "return", "proc_list", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.generate_labs": [[102, 112], ["set", "numpy.random.uniform", "numpy.argmax", "set.add", "lab_list.append", "numpy.random.multinomial"], "function", ["None"], ["", "def", "generate_labs", "(", "dx", ",", "proc", ",", "dx_proc_lab_cond_probs", ",", "multi_lab_probs", ")", ":", "\n", "  ", "lab_list", "=", "[", "]", "\n", "lab_set", "=", "set", "(", ")", "\n", "while", "np", ".", "random", ".", "uniform", "(", "0.", ",", "1.", ")", "<", "multi_lab_probs", "[", "dx", ",", "proc", "]", ":", "\n", "    ", "lab", "=", "np", ".", "argmax", "(", "np", ".", "random", ".", "multinomial", "(", "1", ",", "dx_proc_lab_cond_probs", "[", "dx", ",", "proc", "]", ")", ")", "\n", "if", "lab", "in", "lab_set", ":", "\n", "      ", "continue", "\n", "", "lab_set", ".", "add", "(", "lab", ")", "\n", "lab_list", ".", "append", "(", "lab", ")", "\n", "", "return", "lab_list", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.generate_visit": [[114, 131], ["process_synthetic.generate_dx", "process_synthetic.generate_procs", "visit.append"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.generate_dx", "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.generate_procs"], ["", "def", "generate_visit", "(", "\n", "dx_probs", ",", "\n", "dx_dx_cond_probs", ",", "\n", "dx_proc_cond_probs", ",", "\n", "dx_proc_lab_cond_probs", ",", "\n", "multi_dx_prob", ",", "\n", "dx_dx_probs", ",", "\n", "multi_proc_probs", ",", "\n", "multi_lab_probs", ")", ":", "\n", "  ", "visit", "=", "[", "]", "\n", "dx_list", "=", "generate_dx", "(", "dx_probs", ",", "dx_dx_cond_probs", ",", "multi_dx_prob", ",", "dx_dx_probs", ")", "\n", "for", "dx", "in", "dx_list", ":", "\n", "    ", "proc_labs", "=", "generate_procs", "(", "dx", ",", "dx_proc_cond_probs", ",", "multi_proc_probs", ",", "\n", "dx_proc_lab_cond_probs", ",", "multi_lab_probs", ")", "\n", "visit", ".", "append", "(", "[", "dx", ",", "proc_labs", "]", ")", "\n", "\n", "", "return", "visit", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.build_seqex": [[133, 250], ["enumerate", "print", "tensorflow.train.SequenceExample", "str", "tf.train.SequenceExample.context.feature[].bytes_list.value.append", "tf.train.SequenceExample.context.feature[].int64_list.value.append", "dx_ids.feature.add().bytes_list.value.extend", "dx_ints.feature.add().int64_list.value.extend", "proc_ids.feature.add().bytes_list.value.extend", "proc_ints.feature.add().int64_list.value.extend", "lab_ids.feature.add().bytes_list.value.extend", "lab_ints.feature.add().int64_list.value.extend", "list", "numpy.array().reshape", "vd_pair_feature.feature.add().int64_list.value.extend", "list", "numpy.array().reshape", "dp_pair_feature.feature.add().int64_list.value.extend", "list", "numpy.array().reshape", "pl_pair_feature.feature.add().int64_list.value.extend", "key_list.append", "seqex_list.append", "len", "dx_list.append", "np.array().reshape.append", "len", "tf.train.SequenceExample.context.feature[].bytes_list.value.extend", "tf.train.SequenceExample.context.feature[].bytes_list.value.append", "set", "set", "set", "str", "len", "np.array().reshape.append", "len", "len", "len", "len", "len", "len", "list", "numpy.array", "numpy.array", "numpy.array", "str", "len", "len", "proc_list.append", "dp_chain_label_list.append", "np.array().reshape.append", "set", "str", "len", "len", "lab_list.append", "dx_ids.feature.add", "dx_ints.feature.add", "proc_ids.feature.add", "proc_ints.feature.add", "lab_ids.feature.add", "lab_ints.feature.add", "vd_pair_feature.feature.add", "dp_pair_feature.feature.add", "pl_pair_feature.feature.add"], "function", ["None"], ["", "def", "build_seqex", "(", "\n", "visits", ",", "\n", "dp_chains", "=", "[", "'dx_199,proc_939'", ",", "'dx_133,proc_939'", "]", ",", "\n", "easy_labels", "=", "[", "'dx_199'", ",", "'dx_134'", "]", ",", "\n", "min_num_codes", "=", "5", ",", "\n", "max_num_codes", "=", "50", ")", ":", "\n", "  ", "key_list", "=", "[", "]", "\n", "seqex_list", "=", "[", "]", "\n", "dx_str2int", "=", "{", "}", "\n", "proc_str2int", "=", "{", "}", "\n", "lab_str2int", "=", "{", "}", "\n", "easy_label_count", "=", "0", "\n", "\n", "for", "i", ",", "visit", "in", "enumerate", "(", "visits", ")", ":", "\n", "    ", "seqex", "=", "tf", ".", "train", ".", "SequenceExample", "(", ")", "\n", "patient_id", "=", "str", "(", "i", ")", "\n", "seqex", ".", "context", ".", "feature", "[", "'patientId'", "]", ".", "bytes_list", ".", "value", ".", "append", "(", "patient_id", ")", "\n", "seqex", ".", "context", ".", "feature", "[", "'sequenceLength'", "]", ".", "int64_list", ".", "value", ".", "append", "(", "1", ")", "\n", "key", "=", "(", "'Patient/%s:0-1@0:Encounter/0'", "%", "patient_id", ")", "\n", "\n", "vd_pair", "=", "[", "]", "\n", "dp_pair", "=", "[", "]", "\n", "pl_pair", "=", "[", "]", "\n", "\n", "dx_list", "=", "[", "]", "\n", "proc_list", "=", "[", "]", "\n", "lab_list", "=", "[", "]", "\n", "dp_chain_label_list", "=", "[", "]", "\n", "\n", "dx_map", "=", "{", "}", "\n", "proc_map", "=", "{", "}", "\n", "lab_map", "=", "{", "}", "\n", "\n", "for", "dx_obj", "in", "visit", ":", "\n", "      ", "dx", "=", "'dx_'", "+", "str", "(", "dx_obj", "[", "0", "]", ")", "\n", "if", "dx", "not", "in", "dx_str2int", ":", "dx_str2int", "[", "dx", "]", "=", "len", "(", "dx_str2int", ")", "\n", "dx_map", "[", "dx", "]", "=", "len", "(", "dx_map", ")", "\n", "dx_list", ".", "append", "(", "dx", ")", "\n", "vd_pair", ".", "append", "(", "(", "0", ",", "dx_map", "[", "dx", "]", ")", ")", "\n", "\n", "\n", "for", "proc_obj", "in", "dx_obj", "[", "1", "]", ":", "\n", "        ", "proc", "=", "'proc_'", "+", "str", "(", "proc_obj", "[", "0", "]", ")", "\n", "if", "proc", "not", "in", "proc_str2int", ":", "proc_str2int", "[", "proc", "]", "=", "len", "(", "proc_str2int", ")", "\n", "if", "proc", "not", "in", "proc_map", ":", "\n", "          ", "proc_map", "[", "proc", "]", "=", "len", "(", "proc_map", ")", "\n", "proc_list", ".", "append", "(", "proc", ")", "\n", "", "dp_pair", ".", "append", "(", "(", "dx_map", "[", "dx", "]", ",", "proc_map", "[", "proc", "]", ")", ")", "\n", "\n", "dp_chain", "=", "dx", "+", "','", "+", "proc", "\n", "if", "dp_chain", "in", "dp_chains", ":", "\n", "          ", "dp_chain_label_list", ".", "append", "(", "dp_chain", ")", "\n", "\n", "", "for", "lab_obj", "in", "proc_obj", "[", "1", "]", ":", "\n", "          ", "lab", "=", "'loinc_'", "+", "str", "(", "lab_obj", ")", "\n", "if", "lab", "not", "in", "lab_str2int", ":", "lab_str2int", "[", "lab", "]", "=", "len", "(", "lab_str2int", ")", "\n", "if", "lab", "not", "in", "lab_map", ":", "\n", "            ", "lab_map", "[", "lab", "]", "=", "len", "(", "lab_map", ")", "\n", "lab_list", ".", "append", "(", "lab", ")", "\n", "", "pl_pair", ".", "append", "(", "(", "proc_map", "[", "proc", "]", ",", "lab_map", "[", "lab", "]", ")", ")", "\n", "\n", "", "", "", "if", "(", "len", "(", "dx_list", ")", "<", "min_num_codes", "or", "len", "(", "proc_list", ")", "<", "min_num_codes", "or", "\n", "len", "(", "lab_list", ")", "<", "min_num_codes", ")", ":", "\n", "      ", "continue", "\n", "\n", "", "if", "(", "len", "(", "dx_list", ")", ">", "max_num_codes", "or", "len", "(", "proc_list", ")", ">", "max_num_codes", "or", "\n", "len", "(", "lab_list", ")", ">", "max_num_codes", ")", ":", "\n", "      ", "continue", "\n", "\n", "", "dx_ids", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'dx_ids'", "]", "\n", "dx_ids", ".", "feature", ".", "add", "(", ")", ".", "bytes_list", ".", "value", ".", "extend", "(", "dx_list", ")", "\n", "\n", "dx_int_list", "=", "[", "dx_str2int", "[", "item", "]", "for", "item", "in", "dx_list", "]", "\n", "dx_ints", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'dx_ints'", "]", "\n", "dx_ints", ".", "feature", ".", "add", "(", ")", ".", "int64_list", ".", "value", ".", "extend", "(", "dx_int_list", ")", "\n", "\n", "proc_ids", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'proc_ids'", "]", "\n", "proc_ids", ".", "feature", ".", "add", "(", ")", ".", "bytes_list", ".", "value", ".", "extend", "(", "proc_list", ")", "\n", "\n", "proc_int_list", "=", "[", "proc_str2int", "[", "item", "]", "for", "item", "in", "proc_list", "]", "\n", "proc_ints", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'proc_ints'", "]", "\n", "proc_ints", ".", "feature", ".", "add", "(", ")", ".", "int64_list", ".", "value", ".", "extend", "(", "proc_int_list", ")", "\n", "\n", "lab_ids", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'loinc_bucketized_values'", "]", "\n", "lab_ids", ".", "feature", ".", "add", "(", ")", ".", "bytes_list", ".", "value", ".", "extend", "(", "lab_list", ")", "\n", "\n", "lab_int_list", "=", "[", "lab_str2int", "[", "item", "]", "for", "item", "in", "lab_list", "]", "\n", "lab_ints", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'loinc_bucketized_ints'", "]", "\n", "lab_ints", ".", "feature", ".", "add", "(", ")", ".", "int64_list", ".", "value", ".", "extend", "(", "lab_int_list", ")", "\n", "\n", "if", "len", "(", "dp_chain_label_list", ")", ">", "0", ":", "\n", "      ", "seqex", ".", "context", ".", "feature", "[", "'label.medication.class'", "]", ".", "bytes_list", ".", "value", ".", "extend", "(", "list", "(", "set", "(", "dp_chain_label_list", ")", ")", ")", "\n", "\n", "", "if", "easy_labels", "[", "0", "]", "in", "dx_map", "and", "easy_labels", "[", "1", "]", "in", "dx_map", ":", "\n", "      ", "seqex", ".", "context", ".", "feature", "[", "'label.expired.class'", "]", ".", "bytes_list", ".", "value", ".", "append", "(", "'expired'", ")", "\n", "easy_label_count", "+=", "1", "\n", "\n", "", "vd_pair", "=", "list", "(", "set", "(", "vd_pair", ")", ")", "\n", "vd_pair", "=", "np", ".", "array", "(", "vd_pair", ")", ".", "reshape", "(", "(", "-", "1", ")", ")", "\n", "vd_pair_feature", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'vd_pair'", "]", "\n", "vd_pair_feature", ".", "feature", ".", "add", "(", ")", ".", "int64_list", ".", "value", ".", "extend", "(", "vd_pair", ")", "\n", "\n", "dp_pair", "=", "list", "(", "set", "(", "dp_pair", ")", ")", "\n", "dp_pair", "=", "np", ".", "array", "(", "dp_pair", ")", ".", "reshape", "(", "(", "-", "1", ")", ")", "\n", "dp_pair_feature", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'dp_pair'", "]", "\n", "dp_pair_feature", ".", "feature", ".", "add", "(", ")", ".", "int64_list", ".", "value", ".", "extend", "(", "dp_pair", ")", "\n", "\n", "pl_pair", "=", "list", "(", "set", "(", "pl_pair", ")", ")", "\n", "pl_pair", "=", "np", ".", "array", "(", "pl_pair", ")", ".", "reshape", "(", "(", "-", "1", ")", ")", "\n", "pl_pair_feature", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'pl_pair'", "]", "\n", "pl_pair_feature", ".", "feature", ".", "add", "(", ")", ".", "int64_list", ".", "value", ".", "extend", "(", "pl_pair", ")", "\n", "\n", "key_list", ".", "append", "(", "key", ")", "\n", "seqex_list", ".", "append", "(", "seqex", ")", "\n", "\n", "", "print", "(", "'Number of visits with easy labels: %d'", "%", "easy_label_count", ")", "\n", "return", "key_list", ",", "seqex_list", ",", "dx_str2int", ",", "proc_str2int", ",", "lab_str2int", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.count_conditional_prob_dpl": [[252, 345], ["zip", "dict", "dict", "dict", "dict", "dict", "dict.keys", "dict.keys", "cPickle.dump", "cPickle.dump", "cPickle.dump", "cPickle.dump", "cPickle.dump", "cPickle.dump", "cPickle.dump", "cPickle.dump", "cPickle.dump", "dict.keys", "dict.keys", "open", "open", "open", "open", "open", "open", "open", "open", "open", "sys.stdout.write", "sys.stdout.flush", "dx_freqs.iteritems", "proc_freqs.iteritems", "lab_freqs.iteritems", "dp_freqs.iteritems", "pl_freqs.iteritems", "float", "float", "float", "float", "float"], "function", ["None"], ["", "def", "count_conditional_prob_dpl", "(", "key_list", ",", "seqex_list", ",", "output_path", ",", "train_key_set", "=", "None", ")", ":", "\n", "  ", "dx_freqs", "=", "{", "}", "\n", "proc_freqs", "=", "{", "}", "\n", "lab_freqs", "=", "{", "}", "\n", "dp_freqs", "=", "{", "}", "\n", "pl_freqs", "=", "{", "}", "\n", "total_visit", "=", "0", "\n", "\n", "for", "key", ",", "seqex", "in", "zip", "(", "key_list", ",", "seqex_list", ")", ":", "\n", "    ", "if", "total_visit", "%", "1000", "==", "0", ":", "\n", "      ", "sys", ".", "stdout", ".", "write", "(", "'Visit count: %d\\r'", "%", "total_visit", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "if", "train_key_set", "is", "not", "None", "and", "key", "not", "in", "train_key_set", ":", "\n", "      ", "total_visit", "+=", "1", "\n", "continue", "\n", "\n", "", "dx_ids", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'dx_ids'", "]", ".", "feature", "[", "0", "]", ".", "bytes_list", ".", "value", "\n", "proc_ids", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'proc_ids'", "]", ".", "feature", "[", "0", "]", ".", "bytes_list", ".", "value", "\n", "lab_ids", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'loinc_bucketized_values'", "]", ".", "feature", "[", "0", "]", ".", "bytes_list", ".", "value", "\n", "\n", "for", "dx", "in", "dx_ids", ":", "\n", "      ", "if", "dx", "not", "in", "dx_freqs", ":", "\n", "        ", "dx_freqs", "[", "dx", "]", "=", "0", "\n", "", "dx_freqs", "[", "dx", "]", "+=", "1", "\n", "\n", "", "for", "proc", "in", "proc_ids", ":", "\n", "      ", "if", "proc", "not", "in", "proc_freqs", ":", "\n", "        ", "proc_freqs", "[", "proc", "]", "=", "0", "\n", "", "proc_freqs", "[", "proc", "]", "+=", "1", "\n", "\n", "", "for", "lab", "in", "lab_ids", ":", "\n", "      ", "if", "lab", "not", "in", "lab_freqs", ":", "\n", "        ", "lab_freqs", "[", "lab", "]", "=", "0", "\n", "", "lab_freqs", "[", "lab", "]", "+=", "1", "\n", "\n", "", "for", "dx", "in", "dx_ids", ":", "\n", "      ", "for", "proc", "in", "proc_ids", ":", "\n", "        ", "dp", "=", "dx", "+", "','", "+", "proc", "\n", "if", "dp", "not", "in", "dp_freqs", ":", "\n", "          ", "dp_freqs", "[", "dp", "]", "=", "0", "\n", "", "dp_freqs", "[", "dp", "]", "+=", "1", "\n", "\n", "", "", "for", "proc", "in", "proc_ids", ":", "\n", "      ", "for", "lab", "in", "lab_ids", ":", "\n", "        ", "pl", "=", "proc", "+", "','", "+", "lab", "\n", "if", "pl", "not", "in", "pl_freqs", ":", "\n", "          ", "pl_freqs", "[", "pl", "]", "=", "0", "\n", "", "pl_freqs", "[", "pl", "]", "+=", "1", "\n", "\n", "", "", "total_visit", "+=", "1", "\n", "\n", "", "dx_probs", "=", "dict", "(", "[", "(", "k", ",", "v", "/", "float", "(", "total_visit", ")", ")", "for", "k", ",", "v", "in", "dx_freqs", ".", "iteritems", "(", ")", "]", ")", "\n", "proc_probs", "=", "dict", "(", "[", "(", "k", ",", "v", "/", "float", "(", "total_visit", ")", ")", "for", "k", ",", "v", "in", "proc_freqs", ".", "iteritems", "(", ")", "]", ")", "\n", "lab_probs", "=", "dict", "(", "[", "(", "k", ",", "v", "/", "float", "(", "total_visit", ")", ")", "for", "k", ",", "v", "in", "lab_freqs", ".", "iteritems", "(", ")", "]", ")", "\n", "dp_probs", "=", "dict", "(", "[", "(", "k", ",", "v", "/", "float", "(", "total_visit", ")", ")", "for", "k", ",", "v", "in", "dp_freqs", ".", "iteritems", "(", ")", "]", ")", "\n", "pl_probs", "=", "dict", "(", "[", "(", "k", ",", "v", "/", "float", "(", "total_visit", ")", ")", "for", "k", ",", "v", "in", "pl_freqs", ".", "iteritems", "(", ")", "]", ")", "\n", "\n", "dp_cond_probs", "=", "{", "}", "\n", "pd_cond_probs", "=", "{", "}", "\n", "for", "dx", "in", "dx_probs", ".", "keys", "(", ")", ":", "\n", "    ", "for", "proc", "in", "proc_probs", ".", "keys", "(", ")", ":", "\n", "      ", "dp", "=", "dx", "+", "','", "+", "proc", "\n", "pd", "=", "proc", "+", "','", "+", "dx", "\n", "if", "dp", "in", "dp_probs", ":", "\n", "        ", "dp_cond_probs", "[", "dp", "]", "=", "dp_probs", "[", "dp", "]", "/", "dx_probs", "[", "dx", "]", "\n", "pd_cond_probs", "[", "pd", "]", "=", "dp_probs", "[", "dp", "]", "/", "proc_probs", "[", "proc", "]", "\n", "", "else", ":", "\n", "        ", "dp_cond_probs", "[", "dp", "]", "=", "0.0", "\n", "pd_cond_probs", "[", "pd", "]", "=", "0.0", "\n", "\n", "", "", "", "pl_cond_probs", "=", "{", "}", "\n", "lp_cond_probs", "=", "{", "}", "\n", "for", "proc", "in", "proc_probs", ".", "keys", "(", ")", ":", "\n", "    ", "for", "lab", "in", "lab_probs", ".", "keys", "(", ")", ":", "\n", "      ", "pl", "=", "proc", "+", "','", "+", "lab", "\n", "lp", "=", "lab", "+", "','", "+", "proc", "\n", "if", "pl", "in", "pl_probs", ":", "\n", "        ", "pl_cond_probs", "[", "pl", "]", "=", "pl_probs", "[", "pl", "]", "/", "proc_probs", "[", "proc", "]", "\n", "lp_cond_probs", "[", "lp", "]", "=", "pl_probs", "[", "pl", "]", "/", "lab_probs", "[", "lab", "]", "\n", "", "else", ":", "\n", "        ", "pl_cond_probs", "[", "pl", "]", "=", "0.0", "\n", "pl_cond_probs", "[", "lp", "]", "=", "0.0", "\n", "\n", "", "", "", "pickle", ".", "dump", "(", "dx_probs", ",", "open", "(", "output_path", "+", "'/dx_probs.empirical.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "pickle", ".", "dump", "(", "proc_probs", ",", "open", "(", "output_path", "+", "'/proc_probs.empirical.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "pickle", ".", "dump", "(", "lab_probs", ",", "open", "(", "output_path", "+", "'/lab_probs.empirical.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "pickle", ".", "dump", "(", "dp_probs", ",", "open", "(", "output_path", "+", "'/dp_probs.empirical.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "pickle", ".", "dump", "(", "pl_probs", ",", "open", "(", "output_path", "+", "'/pl_probs.empirical.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "pickle", ".", "dump", "(", "dp_cond_probs", ",", "open", "(", "output_path", "+", "'/dp_cond_probs.empirical.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "pickle", ".", "dump", "(", "pd_cond_probs", ",", "open", "(", "output_path", "+", "'/pd_cond_probs.empirical.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "pickle", ".", "dump", "(", "pl_cond_probs", ",", "open", "(", "output_path", "+", "'/pl_cond_probs.empirical.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "pickle", ".", "dump", "(", "lp_cond_probs", ",", "open", "(", "output_path", "+", "'/lp_cond_probs.empirical.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.add_sparse_prior_guide_dpl": [[347, 410], ["print", "cPickle.load", "cPickle.load", "cPickle.load", "cPickle.load", "print", "zip", "open", "open", "open", "open", "enumerate", "enumerate", "enumerate", "enumerate", "list", "indices_feature.feature.add().int64_list.value.extend", "values_feature.feature.add().float_list.value.extend", "new_seqex_list.append", "sys.stdout.write", "sys.stdout.flush", "enumerate", "enumerate", "enumerate", "enumerate", "numpy.array().reshape", "list.append", "values.append", "list.append", "values.append", "list.append", "values.append", "list.append", "values.append", "numpy.array", "indices_feature.feature.add", "values_feature.feature.add"], "function", ["None"], ["", "def", "add_sparse_prior_guide_dpl", "(", "key_list", ",", "seqex_list", ",", "stats_path", ",", "key_set", "=", "None", ",", "max_num_codes", "=", "50", ")", ":", "\n", "  ", "print", "(", "'Loading conditional probabilities.'", ")", "\n", "dp_cond_probs", "=", "pickle", ".", "load", "(", "open", "(", "stats_path", "+", "'/dp_cond_probs.empirical.p'", ",", "'rb'", ")", ")", "\n", "pd_cond_probs", "=", "pickle", ".", "load", "(", "open", "(", "stats_path", "+", "'/pd_cond_probs.empirical.p'", ",", "'rb'", ")", ")", "\n", "pl_cond_probs", "=", "pickle", ".", "load", "(", "open", "(", "stats_path", "+", "'/pl_cond_probs.empirical.p'", ",", "'rb'", ")", ")", "\n", "lp_cond_probs", "=", "pickle", ".", "load", "(", "open", "(", "stats_path", "+", "'/lp_cond_probs.empirical.p'", ",", "'rb'", ")", ")", "\n", "\n", "print", "(", "'Adding prior guide.'", ")", "\n", "total_visit", "=", "0", "\n", "new_seqex_list", "=", "[", "]", "\n", "for", "key", ",", "seqex", "in", "zip", "(", "key_list", ",", "seqex_list", ")", ":", "\n", "    ", "if", "total_visit", "%", "1000", "==", "0", ":", "\n", "      ", "sys", ".", "stdout", ".", "write", "(", "'Visit count: %d\\r'", "%", "total_visit", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "if", "key_set", "is", "not", "None", "and", "key", "not", "in", "key_set", ":", "\n", "      ", "total_visit", "+=", "1", "\n", "continue", "\n", "\n", "", "dx_ids", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'dx_ids'", "]", ".", "feature", "[", "0", "]", ".", "bytes_list", ".", "value", "\n", "proc_ids", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'proc_ids'", "]", ".", "feature", "[", "0", "]", ".", "bytes_list", ".", "value", "\n", "lab_ids", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'loinc_bucketized_values'", "]", ".", "feature", "[", "0", "]", ".", "bytes_list", ".", "value", "\n", "\n", "indices", "=", "[", "]", "\n", "values", "=", "[", "]", "\n", "for", "i", ",", "dx", "in", "enumerate", "(", "dx_ids", ")", ":", "\n", "      ", "for", "j", ",", "proc", "in", "enumerate", "(", "proc_ids", ")", ":", "\n", "        ", "dp", "=", "dx", "+", "','", "+", "proc", "\n", "indices", ".", "append", "(", "(", "i", ",", "max_num_codes", "+", "j", ")", ")", "\n", "prob", "=", "0.0", "if", "dp", "not", "in", "dp_cond_probs", "else", "dp_cond_probs", "[", "dp", "]", "\n", "values", ".", "append", "(", "prob", ")", "\n", "\n", "", "", "for", "i", ",", "proc", "in", "enumerate", "(", "proc_ids", ")", ":", "\n", "      ", "for", "j", ",", "dx", "in", "enumerate", "(", "dx_ids", ")", ":", "\n", "        ", "pd", "=", "proc", "+", "','", "+", "dx", "\n", "indices", ".", "append", "(", "(", "max_num_codes", "+", "i", ",", "j", ")", ")", "\n", "prob", "=", "0.0", "if", "pd", "not", "in", "pd_cond_probs", "else", "pd_cond_probs", "[", "pd", "]", "\n", "values", ".", "append", "(", "prob", ")", "\n", "\n", "", "", "for", "i", ",", "proc", "in", "enumerate", "(", "proc_ids", ")", ":", "\n", "      ", "for", "j", ",", "lab", "in", "enumerate", "(", "lab_ids", ")", ":", "\n", "        ", "pl", "=", "proc", "+", "','", "+", "lab", "\n", "indices", ".", "append", "(", "(", "max_num_codes", "+", "i", ",", "max_num_codes", "*", "2", "+", "j", ")", ")", "\n", "prob", "=", "0.0", "if", "pl", "not", "in", "pl_cond_probs", "else", "pl_cond_probs", "[", "pl", "]", "\n", "values", ".", "append", "(", "prob", ")", "\n", "\n", "", "", "for", "i", ",", "lab", "in", "enumerate", "(", "lab_ids", ")", ":", "\n", "      ", "for", "j", ",", "proc", "in", "enumerate", "(", "proc_ids", ")", ":", "\n", "        ", "lp", "=", "lab", "+", "','", "+", "proc", "\n", "indices", ".", "append", "(", "(", "max_num_codes", "*", "2", "+", "i", ",", "max_num_codes", "+", "j", ")", ")", "\n", "prob", "=", "0.0", "if", "lp", "not", "in", "lp_cond_probs", "else", "lp_cond_probs", "[", "lp", "]", "\n", "values", ".", "append", "(", "prob", ")", "\n", "\n", "", "", "indices", "=", "list", "(", "np", ".", "array", "(", "indices", ")", ".", "reshape", "(", "[", "-", "1", "]", ")", ")", "\n", "indices_feature", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'prior_indices'", "]", "\n", "indices_feature", ".", "feature", ".", "add", "(", ")", ".", "int64_list", ".", "value", ".", "extend", "(", "indices", ")", "\n", "values_feature", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'prior_values'", "]", "\n", "values_feature", ".", "feature", ".", "add", "(", ")", ".", "float_list", ".", "value", ".", "extend", "(", "values", ")", "\n", "\n", "new_seqex_list", ".", "append", "(", "seqex", ")", "\n", "total_visit", "+=", "1", "\n", "\n", "", "return", "new_seqex_list", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.select_train_valid_test": [[412, 416], ["sklearn.model_selection.train_test_split", "sklearn.model_selection.train_test_split"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.train_test_split", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.train_test_split"], ["", "def", "select_train_valid_test", "(", "key_list", ",", "random_seed", "=", "1234", ")", ":", "\n", "  ", "key_train", ",", "key_temp", "=", "train_test_split", "(", "key_list", ",", "test_size", "=", "0.2", ",", "random_state", "=", "random_seed", ")", "\n", "key_valid", ",", "key_test", "=", "train_test_split", "(", "key_temp", ",", "test_size", "=", "0.5", ",", "random_state", "=", "random_seed", ")", "\n", "return", "key_train", ",", "key_valid", ",", "key_test", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.sample_simulated": [[418, 481], ["print", "numpy.random.normal", "numpy.random.normal", "numpy.random.normal", "print", "process_synthetic.init_dx_probs", "process_synthetic.init_dx_proc_probs", "process_synthetic.init_dx_proc_lab_probs", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "print", "range", "process_synthetic.generate_visit", "visit_list.append", "sys.stdout.write", "sys.stdout.flush"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.init_dx_probs", "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.init_dx_proc_probs", "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.init_dx_proc_lab_probs", "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.generate_visit"], ["", "def", "sample_simulated", "(", "argv", ")", ":", "\n", "  ", "output_path", "=", "argv", "[", "1", "]", "\n", "num_visits", "=", "2000000", "\n", "dx_vocab_size", "=", "1000", "\n", "proc_vocab_size", "=", "1000", "\n", "lab_vocab_size", "=", "1000", "\n", "\n", "print", "(", "'Intializing code occurrence probabilities.'", ")", "\n", "# How likely independent Dx codes occur?", "\n", "multi_dx_prob", "=", "0.5", "\n", "\n", "# How likely is one Dx to lead to another Dx?", "\n", "dx_dx_probs", "=", "np", ".", "random", ".", "normal", "(", "0.5", ",", "0.1", ",", "size", "=", "dx_vocab_size", ")", "\n", "dx_dx_probs", "[", "dx_dx_probs", "<", "0.", "]", "=", "0.", "\n", "dx_dx_probs", "[", "dx_dx_probs", ">", "0.99", "]", "=", "0.5", "\n", "\n", "# How many procedures are likely to occur based on Dx?", "\n", "multi_proc_probs", "=", "np", ".", "random", ".", "normal", "(", "0.5", ",", "0.25", ",", "size", "=", "dx_vocab_size", ")", "\n", "multi_proc_probs", "[", "multi_proc_probs", "<", "0.", "]", "=", "0.", "\n", "multi_proc_probs", "[", "multi_proc_probs", ">", "0.99", "]", "=", "0.5", "\n", "\n", "# How many labs are likely to occur based on Dx and Proc?", "\n", "multi_lab_probs", "=", "np", ".", "random", ".", "normal", "(", "\n", "0.5", ",", "0.25", ",", "size", "=", "[", "dx_vocab_size", ",", "proc_vocab_size", "]", ")", "\n", "multi_lab_probs", "[", "multi_lab_probs", "<", "0.", "]", "=", "0.", "\n", "multi_lab_probs", "[", "multi_lab_probs", ">", "0.99", "]", "=", "0.5", "\n", "\n", "print", "(", "'Intializing conditional code probabilities.'", ")", "\n", "dx_probs", ",", "dx_dx_cond_probs", "=", "init_dx_probs", "(", "\n", "dx_vocab_size", ",", "pareto_prior", "=", "2.", ",", "pareto_prior2", "=", "1.5", ")", "\n", "dx_proc_cond_probs", "=", "init_dx_proc_probs", "(", "\n", "dx_vocab_size", ",", "proc_vocab_size", ",", "pareto_prior", "=", "1.5", ")", "\n", "dx_proc_lab_cond_probs", "=", "init_dx_proc_lab_probs", "(", "\n", "dx_vocab_size", ",", "proc_vocab_size", ",", "lab_vocab_size", ",", "dx_proc_cond_probs", ",", "\n", "pareto_prior", "=", "1.5", ")", "\n", "\n", "np", ".", "save", "(", "output_path", "+", "'/dx_dx_probs'", ",", "dx_dx_probs", ")", "\n", "np", ".", "save", "(", "output_path", "+", "'/multi_proc_probs'", ",", "multi_proc_probs", ")", "\n", "np", ".", "save", "(", "output_path", "+", "'/multi_lab_probs'", ",", "multi_lab_probs", ")", "\n", "np", ".", "save", "(", "output_path", "+", "'/dx_probs'", ",", "dx_probs", ")", "\n", "np", ".", "save", "(", "output_path", "+", "'/dx_dx_cond_probs'", ",", "dx_dx_cond_probs", ")", "\n", "np", ".", "save", "(", "output_path", "+", "'/dx_proc_cond_probs'", ",", "dx_proc_cond_probs", ")", "\n", "np", ".", "save", "(", "output_path", "+", "'/dx_proc_lab_cond_probs'", ",", "dx_proc_lab_cond_probs", ")", "\n", "\n", "print", "(", "'Generating visits.'", ")", "\n", "visit_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_visits", ")", ":", "\n", "    ", "if", "i", "%", "100", "==", "0", ":", "\n", "      ", "sys", ".", "stdout", ".", "write", "(", "'%d\\r'", "%", "i", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "visit", "=", "generate_visit", "(", "\n", "dx_probs", ",", "\n", "dx_dx_cond_probs", ",", "\n", "dx_proc_cond_probs", ",", "\n", "dx_proc_lab_cond_probs", ",", "\n", "multi_dx_prob", ",", "\n", "dx_dx_probs", ",", "\n", "multi_proc_probs", ",", "\n", "multi_lab_probs", ")", "\n", "visit_list", ".", "append", "(", "visit", ")", "\n", "i", "+=", "1", "\n", "\n", "", "return", "visit_list", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.seqex_main": [[487, 529], ["print", "cPickle.load", "print", "process_synthetic.build_seqex", "cPickle.dump", "cPickle.dump", "cPickle.dump", "range", "open", "open", "open", "open", "print", "os.makedirs", "process_synthetic.select_train_valid_test", "cPickle.dump", "cPickle.dump", "cPickle.dump", "process_synthetic.count_conditional_prob_dpl", "process_synthetic.add_sparse_prior_guide_dpl", "process_synthetic.add_sparse_prior_guide_dpl", "process_synthetic.add_sparse_prior_guide_dpl", "str", "open", "open", "open", "set", "set", "set", "set", "tensorflow.io.TFRecordWriter", "tensorflow.io.TFRecordWriter", "tensorflow.io.TFRecordWriter", "writer.write", "writer.write", "writer.write", "seqex.SerializeToString", "seqex.SerializeToString", "seqex.SerializeToString"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.build_seqex", "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.select_train_valid_test", "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.count_conditional_prob_dpl", "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.add_sparse_prior_guide_dpl", "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.add_sparse_prior_guide_dpl", "home.repos.pwc.inspect_result.google-health_records-research.synthetic_samples.process_synthetic.add_sparse_prior_guide_dpl"], ["def", "seqex_main", "(", "argv", ")", ":", "\n", "  ", "input_path", "=", "argv", "[", "1", "]", "\n", "output_path", "=", "argv", "[", "2", "]", "\n", "num_fold", "=", "5", "\n", "data_size", "=", "50000", "\n", "\n", "print", "(", "'Reading visit_list.'", ")", "\n", "visit_list", "=", "pickle", ".", "load", "(", "open", "(", "input_path", "+", "'/visit_list.p'", ",", "'rb'", ")", ")", "\n", "\n", "print", "(", "'Converting to SequenceExamples.'", ")", "\n", "key_list", ",", "seqex_list", ",", "dx_map", ",", "proc_map", ",", "lab_map", "=", "build_seqex", "(", "visit_list", ")", "\n", "pickle", ".", "dump", "(", "dx_map", ",", "open", "(", "output_path", "+", "'/dx_map.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "pickle", ".", "dump", "(", "proc_map", ",", "open", "(", "output_path", "+", "'/proc_map.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "pickle", ".", "dump", "(", "lab_map", ",", "open", "(", "output_path", "+", "'/lab_map.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_fold", ")", ":", "\n", "    ", "print", "(", "'Creating fold %d/%d.'", "%", "(", "i", ",", "num_fold", ")", ")", "\n", "fold_path", "=", "output_path", "+", "'/fold_'", "+", "str", "(", "i", ")", "\n", "stats_path", "=", "fold_path", "+", "'/train_stats'", "\n", "os", ".", "makedirs", "(", "stats_path", ")", "\n", "\n", "key_train", ",", "key_valid", ",", "key_test", "=", "select_train_valid_test", "(", "key_list", "[", ":", "data_size", "]", ",", "random_seed", "=", "i", ")", "\n", "pickle", ".", "dump", "(", "key_train", ",", "open", "(", "fold_path", "+", "'/train_key_list.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "pickle", ".", "dump", "(", "key_valid", ",", "open", "(", "fold_path", "+", "'/validation_key_list.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "pickle", ".", "dump", "(", "key_test", ",", "open", "(", "fold_path", "+", "'/test_key_list.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "\n", "count_conditional_prob_dpl", "(", "key_list", ",", "seqex_list", ",", "stats_path", ",", "set", "(", "key_train", ")", ")", "\n", "train_seqex", "=", "add_sparse_prior_guide_dpl", "(", "key_list", ",", "seqex_list", ",", "stats_path", ",", "set", "(", "key_train", ")", ",", "max_num_codes", "=", "50", ")", "\n", "validation_seqex", "=", "add_sparse_prior_guide_dpl", "(", "key_list", ",", "seqex_list", ",", "stats_path", ",", "set", "(", "key_valid", ")", ",", "max_num_codes", "=", "50", ")", "\n", "test_seqex", "=", "add_sparse_prior_guide_dpl", "(", "key_list", ",", "seqex_list", ",", "stats_path", ",", "set", "(", "key_test", ")", ",", "max_num_codes", "=", "50", ")", "\n", "\n", "with", "tf", ".", "io", ".", "TFRecordWriter", "(", "fold_path", "+", "'/train.tfrecord'", ")", "as", "writer", ":", "\n", "      ", "for", "seqex", "in", "train_seqex", ":", "\n", "        ", "writer", ".", "write", "(", "seqex", ".", "SerializeToString", "(", ")", ")", "\n", "\n", "", "", "with", "tf", ".", "io", ".", "TFRecordWriter", "(", "fold_path", "+", "'/validation.tfrecord'", ")", "as", "writer", ":", "\n", "      ", "for", "seqex", "in", "validation_seqex", ":", "\n", "        ", "writer", ".", "write", "(", "seqex", ".", "SerializeToString", "(", ")", ")", "\n", "\n", "", "", "with", "tf", ".", "io", ".", "TFRecordWriter", "(", "fold_path", "+", "'/test.tfrecord'", ")", "as", "writer", ":", "\n", "      ", "for", "seqex", "in", "test_seqex", ":", "\n", "        ", "writer", ".", "write", "(", "seqex", ".", "SerializeToString", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.EncounterInfo.__init__": [[30, 42], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "patient_id", ",", "encounter_id", ",", "encounter_timestamp", ",", "expired", ",", "\n", "readmission", ")", ":", "\n", "    ", "self", ".", "patient_id", "=", "patient_id", "\n", "self", ".", "encounter_id", "=", "encounter_id", "\n", "self", ".", "encounter_timestamp", "=", "encounter_timestamp", "\n", "self", ".", "expired", "=", "expired", "\n", "self", ".", "readmission", "=", "readmission", "\n", "self", ".", "dx_ids", "=", "[", "]", "\n", "self", ".", "rx_ids", "=", "[", "]", "\n", "self", ".", "labs", "=", "{", "}", "\n", "self", ".", "physicals", "=", "[", "]", "\n", "self", ".", "treatments", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.process_patient": [[44, 104], ["open", "csv.DictReader", "open.close", "print", "patient_dict.iteritems", "patient_dict_sorted.iteritems", "open", "csv.DictReader", "open.close", "print", "patient_dict[].append", "sorted", "float", "process_eicu.EncounterInfo", "sys.stdout.write", "sys.stdout.flush", "int", "sys.stdout.write", "sys.stdout.flush", "int", "print", "sys.exit"], "function", ["None"], ["", "", "def", "process_patient", "(", "infile", ",", "encounter_dict", ",", "hour_threshold", "=", "24", ")", ":", "\n", "  ", "inff", "=", "open", "(", "infile", ",", "'r'", ")", "\n", "count", "=", "0", "\n", "patient_dict", "=", "{", "}", "\n", "for", "line", "in", "csv", ".", "DictReader", "(", "inff", ")", ":", "\n", "    ", "if", "count", "%", "10000", "==", "0", ":", "\n", "      ", "sys", ".", "stdout", ".", "write", "(", "'%d\\r'", "%", "count", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "patient_id", "=", "line", "[", "'patienthealthsystemstayid'", "]", "\n", "encounter_id", "=", "line", "[", "'patientunitstayid'", "]", "\n", "encounter_timestamp", "=", "-", "int", "(", "line", "[", "'hospitaladmitoffset'", "]", ")", "\n", "if", "patient_id", "not", "in", "patient_dict", ":", "\n", "      ", "patient_dict", "[", "patient_id", "]", "=", "[", "]", "\n", "", "patient_dict", "[", "patient_id", "]", ".", "append", "(", "(", "encounter_timestamp", ",", "encounter_id", ")", ")", "\n", "", "inff", ".", "close", "(", ")", "\n", "print", "(", "''", ")", "\n", "\n", "patient_dict_sorted", "=", "{", "}", "\n", "for", "patient_id", ",", "time_enc_tuples", "in", "patient_dict", ".", "iteritems", "(", ")", ":", "\n", "    ", "patient_dict_sorted", "[", "patient_id", "]", "=", "sorted", "(", "time_enc_tuples", ")", "\n", "\n", "", "enc_readmission_dict", "=", "{", "}", "\n", "for", "patient_id", ",", "time_enc_tuples", "in", "patient_dict_sorted", ".", "iteritems", "(", ")", ":", "\n", "    ", "for", "time_enc_tuple", "in", "time_enc_tuples", "[", ":", "-", "1", "]", ":", "\n", "      ", "enc_id", "=", "time_enc_tuple", "[", "1", "]", "\n", "enc_readmission_dict", "[", "enc_id", "]", "=", "True", "\n", "", "last_enc_id", "=", "time_enc_tuples", "[", "-", "1", "]", "[", "1", "]", "\n", "enc_readmission_dict", "[", "last_enc_id", "]", "=", "False", "\n", "\n", "", "inff", "=", "open", "(", "infile", ",", "'r'", ")", "\n", "count", "=", "0", "\n", "for", "line", "in", "csv", ".", "DictReader", "(", "inff", ")", ":", "\n", "    ", "if", "count", "%", "10000", "==", "0", ":", "\n", "      ", "sys", ".", "stdout", ".", "write", "(", "'%d\\r'", "%", "count", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "patient_id", "=", "line", "[", "'patienthealthsystemstayid'", "]", "\n", "encounter_id", "=", "line", "[", "'patientunitstayid'", "]", "\n", "encounter_timestamp", "=", "-", "int", "(", "line", "[", "'hospitaladmitoffset'", "]", ")", "\n", "discharge_status", "=", "line", "[", "'unitdischargestatus'", "]", "\n", "duration_minute", "=", "float", "(", "line", "[", "'unitdischargeoffset'", "]", ")", "\n", "expired", "=", "True", "if", "discharge_status", "==", "'Expired'", "else", "False", "\n", "readmission", "=", "enc_readmission_dict", "[", "encounter_id", "]", "\n", "\n", "if", "duration_minute", ">", "60.", "*", "hour_threshold", ":", "\n", "      ", "continue", "\n", "\n", "", "ei", "=", "EncounterInfo", "(", "patient_id", ",", "encounter_id", ",", "encounter_timestamp", ",", "expired", ",", "\n", "readmission", ")", "\n", "if", "encounter_id", "in", "encounter_dict", ":", "\n", "      ", "print", "(", "'Duplicate encounter ID!!'", ")", "\n", "sys", ".", "exit", "(", "0", ")", "\n", "", "encounter_dict", "[", "encounter_id", "]", "=", "ei", "\n", "count", "+=", "1", "\n", "\n", "", "inff", ".", "close", "(", ")", "\n", "print", "(", "''", ")", "\n", "\n", "return", "encounter_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.process_admission_dx": [[106, 128], ["open", "csv.DictReader", "open.close", "print", "print", "line[].lower", "encounter_dict[].dx_ids.append", "sys.stdout.write", "sys.stdout.flush"], "function", ["None"], ["", "def", "process_admission_dx", "(", "infile", ",", "encounter_dict", ")", ":", "\n", "  ", "inff", "=", "open", "(", "infile", ",", "'r'", ")", "\n", "count", "=", "0", "\n", "missing_eid", "=", "0", "\n", "for", "line", "in", "csv", ".", "DictReader", "(", "inff", ")", ":", "\n", "    ", "if", "count", "%", "10000", "==", "0", ":", "\n", "      ", "sys", ".", "stdout", ".", "write", "(", "'%d\\r'", "%", "count", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "encounter_id", "=", "line", "[", "'patientunitstayid'", "]", "\n", "dx_id", "=", "line", "[", "'admitdxpath'", "]", ".", "lower", "(", ")", "\n", "\n", "if", "encounter_id", "not", "in", "encounter_dict", ":", "\n", "      ", "missing_eid", "+=", "1", "\n", "continue", "\n", "", "encounter_dict", "[", "encounter_id", "]", ".", "dx_ids", ".", "append", "(", "dx_id", ")", "\n", "count", "+=", "1", "\n", "", "inff", ".", "close", "(", ")", "\n", "print", "(", "''", ")", "\n", "print", "(", "'Admission Diagnosis without Encounter ID: %d'", "%", "missing_eid", ")", "\n", "\n", "return", "encounter_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.process_diagnosis": [[130, 152], ["open", "csv.DictReader", "open.close", "print", "print", "line[].lower", "encounter_dict[].dx_ids.append", "sys.stdout.write", "sys.stdout.flush"], "function", ["None"], ["", "def", "process_diagnosis", "(", "infile", ",", "encounter_dict", ")", ":", "\n", "  ", "inff", "=", "open", "(", "infile", ",", "'r'", ")", "\n", "count", "=", "0", "\n", "missing_eid", "=", "0", "\n", "for", "line", "in", "csv", ".", "DictReader", "(", "inff", ")", ":", "\n", "    ", "if", "count", "%", "10000", "==", "0", ":", "\n", "      ", "sys", ".", "stdout", ".", "write", "(", "'%d\\r'", "%", "count", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "encounter_id", "=", "line", "[", "'patientunitstayid'", "]", "\n", "dx_id", "=", "line", "[", "'diagnosisstring'", "]", ".", "lower", "(", ")", "\n", "\n", "if", "encounter_id", "not", "in", "encounter_dict", ":", "\n", "      ", "missing_eid", "+=", "1", "\n", "continue", "\n", "", "encounter_dict", "[", "encounter_id", "]", ".", "dx_ids", ".", "append", "(", "dx_id", ")", "\n", "count", "+=", "1", "\n", "", "inff", ".", "close", "(", ")", "\n", "print", "(", "''", ")", "\n", "print", "(", "'Diagnosis without Encounter ID: %d'", "%", "missing_eid", ")", "\n", "\n", "return", "encounter_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.process_treatment": [[154, 178], ["open", "csv.DictReader", "open.close", "print", "print", "print", "line[].lower", "encounter_dict[].treatments.append", "sys.stdout.write", "sys.stdout.flush"], "function", ["None"], ["", "def", "process_treatment", "(", "infile", ",", "encounter_dict", ")", ":", "\n", "  ", "inff", "=", "open", "(", "infile", ",", "'r'", ")", "\n", "count", "=", "0", "\n", "missing_eid", "=", "0", "\n", "\n", "for", "line", "in", "csv", ".", "DictReader", "(", "inff", ")", ":", "\n", "    ", "if", "count", "%", "10000", "==", "0", ":", "\n", "      ", "sys", ".", "stdout", ".", "write", "(", "'%d\\r'", "%", "count", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "encounter_id", "=", "line", "[", "'patientunitstayid'", "]", "\n", "treatment_id", "=", "line", "[", "'treatmentstring'", "]", ".", "lower", "(", ")", "\n", "\n", "if", "encounter_id", "not", "in", "encounter_dict", ":", "\n", "      ", "missing_eid", "+=", "1", "\n", "continue", "\n", "", "encounter_dict", "[", "encounter_id", "]", ".", "treatments", ".", "append", "(", "treatment_id", ")", "\n", "count", "+=", "1", "\n", "", "inff", ".", "close", "(", ")", "\n", "print", "(", "''", ")", "\n", "print", "(", "'Treatment without Encounter ID: %d'", "%", "missing_eid", ")", "\n", "print", "(", "'Accepted treatments: %d'", "%", "count", ")", "\n", "\n", "return", "encounter_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.build_seqex": [[180, 287], ["enc_dict.iteritems", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "len", "len", "len", "len", "tensorflow.train.SequenceExample", "tf.train.SequenceExample.context.feature[].bytes_list.value.append", "dx_ids.feature.add().bytes_list.value.extend", "dx_ints.feature.add().int64_list.value.extend", "proc_ids.feature.add().bytes_list.value.extend", "proc_ints.feature.add().int64_list.value.extend", "seqex_list.append", "key_list.append", "len", "len", "len", "len", "set", "set", "tf.train.SequenceExample.context.feature[].int64_list.value.append", "tf.train.SequenceExample.context.feature[].int64_list.value.append", "tf.train.SequenceExample.context.feature[].int64_list.value.append", "tf.train.SequenceExample.context.feature[].int64_list.value.append", "list", "list", "set", "set", "set", "set", "len", "len", "set", "list", "set", "list", "len", "len", "len", "len", "set", "set", "set", "set", "dx_ids.feature.add", "dx_ints.feature.add", "proc_ids.feature.add", "proc_ints.feature.add"], "function", ["None"], ["", "def", "build_seqex", "(", "enc_dict", ",", "\n", "skip_duplicate", "=", "False", ",", "\n", "min_num_codes", "=", "1", ",", "\n", "max_num_codes", "=", "50", ")", ":", "\n", "  ", "key_list", "=", "[", "]", "\n", "seqex_list", "=", "[", "]", "\n", "dx_str2int", "=", "{", "}", "\n", "treat_str2int", "=", "{", "}", "\n", "num_cut", "=", "0", "\n", "num_duplicate", "=", "0", "\n", "count", "=", "0", "\n", "num_dx_ids", "=", "0", "\n", "num_treatments", "=", "0", "\n", "num_unique_dx_ids", "=", "0", "\n", "num_unique_treatments", "=", "0", "\n", "min_dx_cut", "=", "0", "\n", "min_treatment_cut", "=", "0", "\n", "max_dx_cut", "=", "0", "\n", "max_treatment_cut", "=", "0", "\n", "num_expired", "=", "0", "\n", "num_readmission", "=", "0", "\n", "\n", "for", "_", ",", "enc", "in", "enc_dict", ".", "iteritems", "(", ")", ":", "\n", "    ", "if", "skip_duplicate", ":", "\n", "      ", "if", "(", "len", "(", "enc", ".", "dx_ids", ")", ">", "len", "(", "set", "(", "enc", ".", "dx_ids", ")", ")", "or", "\n", "len", "(", "enc", ".", "treatments", ")", ">", "len", "(", "set", "(", "enc", ".", "treatments", ")", ")", ")", ":", "\n", "        ", "num_duplicate", "+=", "1", "\n", "continue", "\n", "\n", "", "", "if", "len", "(", "set", "(", "enc", ".", "dx_ids", ")", ")", "<", "min_num_codes", ":", "\n", "      ", "min_dx_cut", "+=", "1", "\n", "continue", "\n", "\n", "", "if", "len", "(", "set", "(", "enc", ".", "treatments", ")", ")", "<", "min_num_codes", ":", "\n", "      ", "min_treatment_cut", "+=", "1", "\n", "continue", "\n", "\n", "", "if", "len", "(", "set", "(", "enc", ".", "dx_ids", ")", ")", ">", "max_num_codes", ":", "\n", "      ", "max_dx_cut", "+=", "1", "\n", "continue", "\n", "\n", "", "if", "len", "(", "set", "(", "enc", ".", "treatments", ")", ")", ">", "max_num_codes", ":", "\n", "      ", "max_treatment_cut", "+=", "1", "\n", "continue", "\n", "\n", "", "count", "+=", "1", "\n", "num_dx_ids", "+=", "len", "(", "enc", ".", "dx_ids", ")", "\n", "num_treatments", "+=", "len", "(", "enc", ".", "treatments", ")", "\n", "num_unique_dx_ids", "+=", "len", "(", "set", "(", "enc", ".", "dx_ids", ")", ")", "\n", "num_unique_treatments", "+=", "len", "(", "set", "(", "enc", ".", "treatments", ")", ")", "\n", "\n", "for", "dx_id", "in", "enc", ".", "dx_ids", ":", "\n", "      ", "if", "dx_id", "not", "in", "dx_str2int", ":", "\n", "        ", "dx_str2int", "[", "dx_id", "]", "=", "len", "(", "dx_str2int", ")", "\n", "\n", "", "", "for", "treat_id", "in", "enc", ".", "treatments", ":", "\n", "      ", "if", "treat_id", "not", "in", "treat_str2int", ":", "\n", "        ", "treat_str2int", "[", "treat_id", "]", "=", "len", "(", "treat_str2int", ")", "\n", "\n", "", "", "seqex", "=", "tf", ".", "train", ".", "SequenceExample", "(", ")", "\n", "seqex", ".", "context", ".", "feature", "[", "'patientId'", "]", ".", "bytes_list", ".", "value", ".", "append", "(", "enc", ".", "patient_id", "+", "\n", "':'", "+", "\n", "enc", ".", "encounter_id", ")", "\n", "if", "enc", ".", "expired", ":", "\n", "      ", "seqex", ".", "context", ".", "feature", "[", "'label.expired'", "]", ".", "int64_list", ".", "value", ".", "append", "(", "1", ")", "\n", "num_expired", "+=", "1", "\n", "", "else", ":", "\n", "      ", "seqex", ".", "context", ".", "feature", "[", "'label.expired'", "]", ".", "int64_list", ".", "value", ".", "append", "(", "0", ")", "\n", "\n", "", "if", "enc", ".", "readmission", ":", "\n", "      ", "seqex", ".", "context", ".", "feature", "[", "'label.readmission'", "]", ".", "int64_list", ".", "value", ".", "append", "(", "1", ")", "\n", "num_readmission", "+=", "1", "\n", "", "else", ":", "\n", "      ", "seqex", ".", "context", ".", "feature", "[", "'label.readmission'", "]", ".", "int64_list", ".", "value", ".", "append", "(", "0", ")", "\n", "\n", "", "dx_ids", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'dx_ids'", "]", "\n", "dx_ids", ".", "feature", ".", "add", "(", ")", ".", "bytes_list", ".", "value", ".", "extend", "(", "list", "(", "set", "(", "enc", ".", "dx_ids", ")", ")", ")", "\n", "\n", "dx_int_list", "=", "[", "dx_str2int", "[", "item", "]", "for", "item", "in", "list", "(", "set", "(", "enc", ".", "dx_ids", ")", ")", "]", "\n", "dx_ints", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'dx_ints'", "]", "\n", "dx_ints", ".", "feature", ".", "add", "(", ")", ".", "int64_list", ".", "value", ".", "extend", "(", "dx_int_list", ")", "\n", "\n", "proc_ids", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'proc_ids'", "]", "\n", "proc_ids", ".", "feature", ".", "add", "(", ")", ".", "bytes_list", ".", "value", ".", "extend", "(", "list", "(", "set", "(", "enc", ".", "treatments", ")", ")", ")", "\n", "\n", "proc_int_list", "=", "[", "treat_str2int", "[", "item", "]", "for", "item", "in", "list", "(", "set", "(", "enc", ".", "treatments", ")", ")", "]", "\n", "proc_ints", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'proc_ints'", "]", "\n", "proc_ints", ".", "feature", ".", "add", "(", ")", ".", "int64_list", ".", "value", ".", "extend", "(", "proc_int_list", ")", "\n", "\n", "seqex_list", ".", "append", "(", "seqex", ")", "\n", "key", "=", "seqex", ".", "context", ".", "feature", "[", "'patientId'", "]", ".", "bytes_list", ".", "value", "[", "0", "]", "\n", "key_list", ".", "append", "(", "key", ")", "\n", "\n", "", "print", "(", "'Filtered encounters due to duplicate codes: %d'", "%", "num_duplicate", ")", "\n", "print", "(", "'Filtered encounters due to thresholding: %d'", "%", "num_cut", ")", "\n", "print", "(", "'Average num_dx_ids: %f'", "%", "(", "num_dx_ids", "/", "count", ")", ")", "\n", "print", "(", "'Average num_treatments: %f'", "%", "(", "num_treatments", "/", "count", ")", ")", "\n", "print", "(", "'Average num_unique_dx_ids: %f'", "%", "(", "num_unique_dx_ids", "/", "count", ")", ")", "\n", "print", "(", "'Average num_unique_treatments: %f'", "%", "(", "num_unique_treatments", "/", "count", ")", ")", "\n", "print", "(", "'Min dx cut: %d'", "%", "min_dx_cut", ")", "\n", "print", "(", "'Min treatment cut: %d'", "%", "min_treatment_cut", ")", "\n", "print", "(", "'Max dx cut: %d'", "%", "max_dx_cut", ")", "\n", "print", "(", "'Max treatment cut: %d'", "%", "max_treatment_cut", ")", "\n", "print", "(", "'Number of expired: %d'", "%", "num_expired", ")", "\n", "print", "(", "'Number of readmission: %d'", "%", "num_readmission", ")", "\n", "\n", "return", "key_list", ",", "seqex_list", ",", "dx_str2int", ",", "treat_str2int", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.select_train_valid_test": [[289, 295], ["sklearn.train_test_split", "sklearn.train_test_split"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.train_test_split", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.train_test_split"], ["", "def", "select_train_valid_test", "(", "key_list", ",", "random_seed", "=", "1234", ")", ":", "\n", "  ", "key_train", ",", "key_temp", "=", "ms", ".", "train_test_split", "(", "\n", "key_list", ",", "test_size", "=", "0.2", ",", "random_state", "=", "random_seed", ")", "\n", "key_valid", ",", "key_test", "=", "ms", ".", "train_test_split", "(", "\n", "key_temp", ",", "test_size", "=", "0.5", ",", "random_state", "=", "random_seed", ")", "\n", "return", "key_train", ",", "key_valid", ",", "key_test", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.count_conditional_prob_dp": [[297, 365], ["dict", "dict", "dict", "dict.iteritems", "cPickle.dump", "cPickle.dump", "cPickle.dump", "cPickle.dump", "cPickle.dump", "dict.iteritems", "open", "open", "open", "open", "open", "sys.stdout.write", "sys.stdout.flush", "dx_freqs.iteritems", "proc_freqs.iteritems", "dp_freqs.iteritems", "float", "float", "float"], "function", ["None"], ["", "def", "count_conditional_prob_dp", "(", "seqex_list", ",", "output_path", ",", "train_key_set", "=", "None", ")", ":", "\n", "  ", "dx_freqs", "=", "{", "}", "\n", "proc_freqs", "=", "{", "}", "\n", "dp_freqs", "=", "{", "}", "\n", "total_visit", "=", "0", "\n", "for", "seqex", "in", "seqex_list", ":", "\n", "    ", "if", "total_visit", "%", "1000", "==", "0", ":", "\n", "      ", "sys", ".", "stdout", ".", "write", "(", "'Visit count: %d\\r'", "%", "total_visit", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "key", "=", "seqex", ".", "context", ".", "feature", "[", "'patientId'", "]", ".", "bytes_list", ".", "value", "[", "0", "]", "\n", "if", "(", "train_key_set", "is", "not", "None", "and", "key", "not", "in", "train_key_set", ")", ":", "\n", "      ", "total_visit", "+=", "1", "\n", "continue", "\n", "\n", "", "dx_ids", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'dx_ids'", "]", ".", "feature", "[", "\n", "0", "]", ".", "bytes_list", ".", "value", "\n", "proc_ids", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'proc_ids'", "]", ".", "feature", "[", "\n", "0", "]", ".", "bytes_list", ".", "value", "\n", "\n", "for", "dx", "in", "dx_ids", ":", "\n", "      ", "if", "dx", "not", "in", "dx_freqs", ":", "\n", "        ", "dx_freqs", "[", "dx", "]", "=", "0", "\n", "", "dx_freqs", "[", "dx", "]", "+=", "1", "\n", "\n", "", "for", "proc", "in", "proc_ids", ":", "\n", "      ", "if", "proc", "not", "in", "proc_freqs", ":", "\n", "        ", "proc_freqs", "[", "proc", "]", "=", "0", "\n", "", "proc_freqs", "[", "proc", "]", "+=", "1", "\n", "\n", "", "for", "dx", "in", "dx_ids", ":", "\n", "      ", "for", "proc", "in", "proc_ids", ":", "\n", "        ", "dp", "=", "dx", "+", "','", "+", "proc", "\n", "if", "dp", "not", "in", "dp_freqs", ":", "\n", "          ", "dp_freqs", "[", "dp", "]", "=", "0", "\n", "", "dp_freqs", "[", "dp", "]", "+=", "1", "\n", "\n", "", "", "total_visit", "+=", "1", "\n", "\n", "", "dx_probs", "=", "dict", "(", "[", "(", "k", ",", "v", "/", "float", "(", "total_visit", ")", ")", "for", "k", ",", "v", "in", "dx_freqs", ".", "iteritems", "(", ")", "\n", "]", ")", "\n", "proc_probs", "=", "dict", "(", "[", "\n", "(", "k", ",", "v", "/", "float", "(", "total_visit", ")", ")", "for", "k", ",", "v", "in", "proc_freqs", ".", "iteritems", "(", ")", "\n", "]", ")", "\n", "dp_probs", "=", "dict", "(", "[", "(", "k", ",", "v", "/", "float", "(", "total_visit", ")", ")", "for", "k", ",", "v", "in", "dp_freqs", ".", "iteritems", "(", ")", "\n", "]", ")", "\n", "\n", "dp_cond_probs", "=", "{", "}", "\n", "pd_cond_probs", "=", "{", "}", "\n", "for", "dx", ",", "dx_prob", "in", "dx_probs", ".", "iteritems", "(", ")", ":", "\n", "    ", "for", "proc", ",", "proc_prob", "in", "proc_probs", ".", "iteritems", "(", ")", ":", "\n", "      ", "dp", "=", "dx", "+", "','", "+", "proc", "\n", "pd", "=", "proc", "+", "','", "+", "dx", "\n", "if", "dp", "in", "dp_probs", ":", "\n", "        ", "dp_cond_probs", "[", "dp", "]", "=", "dp_probs", "[", "dp", "]", "/", "dx_prob", "\n", "pd_cond_probs", "[", "pd", "]", "=", "dp_probs", "[", "dp", "]", "/", "proc_prob", "\n", "", "else", ":", "\n", "        ", "dp_cond_probs", "[", "dp", "]", "=", "0.0", "\n", "pd_cond_probs", "[", "pd", "]", "=", "0.0", "\n", "\n", "", "", "", "pickle", ".", "dump", "(", "dx_probs", ",", "open", "(", "output_path", "+", "'/dx_probs.empirical.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "pickle", ".", "dump", "(", "proc_probs", ",", "open", "(", "output_path", "+", "'/proc_probs.empirical.p'", ",", "'wb'", ")", ",", "\n", "-", "1", ")", "\n", "pickle", ".", "dump", "(", "dp_probs", ",", "open", "(", "output_path", "+", "'/dp_probs.empirical.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "pickle", ".", "dump", "(", "dp_cond_probs", ",", "\n", "open", "(", "output_path", "+", "'/dp_cond_probs.empirical.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "pickle", ".", "dump", "(", "pd_cond_probs", ",", "\n", "open", "(", "output_path", "+", "'/pd_cond_probs.empirical.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.add_sparse_prior_guide_dp": [[367, 421], ["print", "cPickle.load", "cPickle.load", "print", "open", "open", "enumerate", "enumerate", "list", "indices_feature.feature.add().int64_list.value.extend", "values_feature.feature.add().float_list.value.extend", "new_seqex_list.append", "sys.stdout.write", "sys.stdout.flush", "enumerate", "enumerate", "numpy.array().reshape", "list.append", "values.append", "list.append", "values.append", "numpy.array", "indices_feature.feature.add", "values_feature.feature.add"], "function", ["None"], ["", "def", "add_sparse_prior_guide_dp", "(", "seqex_list", ",", "\n", "stats_path", ",", "\n", "key_set", "=", "None", ",", "\n", "max_num_codes", "=", "50", ")", ":", "\n", "  ", "print", "(", "'Loading conditional probabilities.'", ")", "\n", "dp_cond_probs", "=", "pickle", ".", "load", "(", "\n", "open", "(", "stats_path", "+", "'/dp_cond_probs.empirical.p'", ",", "'rb'", ")", ")", "\n", "pd_cond_probs", "=", "pickle", ".", "load", "(", "\n", "open", "(", "stats_path", "+", "'/pd_cond_probs.empirical.p'", ",", "'rb'", ")", ")", "\n", "\n", "print", "(", "'Adding prior guide.'", ")", "\n", "total_visit", "=", "0", "\n", "new_seqex_list", "=", "[", "]", "\n", "for", "seqex", "in", "seqex_list", ":", "\n", "    ", "if", "total_visit", "%", "1000", "==", "0", ":", "\n", "      ", "sys", ".", "stdout", ".", "write", "(", "'Visit count: %d\\r'", "%", "total_visit", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "key", "=", "seqex", ".", "context", ".", "feature", "[", "'patientId'", "]", ".", "bytes_list", ".", "value", "[", "0", "]", "\n", "if", "(", "key_set", "is", "not", "None", "and", "key", "not", "in", "key_set", ")", ":", "\n", "      ", "total_visit", "+=", "1", "\n", "continue", "\n", "\n", "", "dx_ids", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'dx_ids'", "]", ".", "feature", "[", "\n", "0", "]", ".", "bytes_list", ".", "value", "\n", "proc_ids", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'proc_ids'", "]", ".", "feature", "[", "\n", "0", "]", ".", "bytes_list", ".", "value", "\n", "\n", "indices", "=", "[", "]", "\n", "values", "=", "[", "]", "\n", "for", "i", ",", "dx", "in", "enumerate", "(", "dx_ids", ")", ":", "\n", "      ", "for", "j", ",", "proc", "in", "enumerate", "(", "proc_ids", ")", ":", "\n", "        ", "dp", "=", "dx", "+", "','", "+", "proc", "\n", "indices", ".", "append", "(", "(", "i", ",", "max_num_codes", "+", "j", ")", ")", "\n", "prob", "=", "0.0", "if", "dp", "not", "in", "dp_cond_probs", "else", "dp_cond_probs", "[", "dp", "]", "\n", "values", ".", "append", "(", "prob", ")", "\n", "\n", "", "", "for", "i", ",", "proc", "in", "enumerate", "(", "proc_ids", ")", ":", "\n", "      ", "for", "j", ",", "dx", "in", "enumerate", "(", "dx_ids", ")", ":", "\n", "        ", "pd", "=", "proc", "+", "','", "+", "dx", "\n", "indices", ".", "append", "(", "(", "max_num_codes", "+", "i", ",", "j", ")", ")", "\n", "prob", "=", "0.0", "if", "pd", "not", "in", "pd_cond_probs", "else", "pd_cond_probs", "[", "pd", "]", "\n", "values", ".", "append", "(", "prob", ")", "\n", "\n", "", "", "indices", "=", "list", "(", "np", ".", "array", "(", "indices", ")", ".", "reshape", "(", "[", "-", "1", "]", ")", ")", "\n", "indices_feature", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'prior_indices'", "]", "\n", "indices_feature", ".", "feature", ".", "add", "(", ")", ".", "int64_list", ".", "value", ".", "extend", "(", "indices", ")", "\n", "values_feature", "=", "seqex", ".", "feature_lists", ".", "feature_list", "[", "'prior_values'", "]", "\n", "values_feature", ".", "feature", ".", "add", "(", ")", ".", "float_list", ".", "value", ".", "extend", "(", "values", ")", "\n", "\n", "new_seqex_list", ".", "append", "(", "seqex", ")", "\n", "total_visit", "+=", "1", "\n", "\n", "", "return", "new_seqex_list", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.main": [[426, 480], ["print", "process_eicu.process_patient", "print", "process_eicu.process_admission_dx", "print", "process_eicu.process_diagnosis", "print", "process_eicu.process_treatment", "process_eicu.build_seqex", "cPickle.dump", "cPickle.dump", "range", "open", "open", "os.makedirs", "process_eicu.select_train_valid_test", "process_eicu.count_conditional_prob_dp", "process_eicu.add_sparse_prior_guide_dp", "process_eicu.add_sparse_prior_guide_dp", "process_eicu.add_sparse_prior_guide_dp", "str", "set", "set", "set", "set", "tensorflow.io.TFRecordWriter", "tensorflow.io.TFRecordWriter", "tensorflow.io.TFRecordWriter", "writer.write", "writer.write", "writer.write", "seqex.SerializeToString", "seqex.SerializeToString", "seqex.SerializeToString"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.process_patient", "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.process_admission_dx", "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.process_diagnosis", "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.process_treatment", "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.build_seqex", "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.select_train_valid_test", "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.count_conditional_prob_dp", "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.add_sparse_prior_guide_dp", "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.add_sparse_prior_guide_dp", "home.repos.pwc.inspect_result.google-health_records-research.eicu_samples.process_eicu.add_sparse_prior_guide_dp"], ["def", "main", "(", "argv", ")", ":", "\n", "  ", "input_path", "=", "argv", "[", "1", "]", "\n", "output_path", "=", "argv", "[", "2", "]", "\n", "num_fold", "=", "5", "\n", "\n", "patient_file", "=", "input_path", "+", "'/patient.csv'", "\n", "admission_dx_file", "=", "input_path", "+", "'/admissionDx.csv'", "\n", "diagnosis_file", "=", "input_path", "+", "'/diagnosis.csv'", "\n", "treatment_file", "=", "input_path", "+", "'/treatment.csv'", "\n", "\n", "encounter_dict", "=", "{", "}", "\n", "print", "(", "'Processing patient.csv'", ")", "\n", "encounter_dict", "=", "process_patient", "(", "\n", "patient_file", ",", "encounter_dict", ",", "hour_threshold", "=", "24", ")", "\n", "print", "(", "'Processing admission diagnosis.csv'", ")", "\n", "encounter_dict", "=", "process_admission_dx", "(", "admission_dx_file", ",", "encounter_dict", ")", "\n", "print", "(", "'Processing diagnosis.csv'", ")", "\n", "encounter_dict", "=", "process_diagnosis", "(", "diagnosis_file", ",", "encounter_dict", ")", "\n", "print", "(", "'Processing treatment.csv'", ")", "\n", "encounter_dict", "=", "process_treatment", "(", "treatment_file", ",", "encounter_dict", ")", "\n", "\n", "key_list", ",", "seqex_list", ",", "dx_map", ",", "proc_map", "=", "build_seqex", "(", "\n", "encounter_dict", ",", "skip_duplicate", "=", "False", ",", "min_num_codes", "=", "1", ",", "max_num_codes", "=", "50", ")", "\n", "\n", "pickle", ".", "dump", "(", "dx_map", ",", "open", "(", "output_path", "+", "'/dx_map.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "pickle", ".", "dump", "(", "proc_map", ",", "open", "(", "output_path", "+", "'/proc_map.p'", ",", "'wb'", ")", ",", "-", "1", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_fold", ")", ":", "\n", "    ", "fold_path", "=", "output_path", "+", "'/fold_'", "+", "str", "(", "i", ")", "\n", "stats_path", "=", "fold_path", "+", "'/train_stats'", "\n", "os", ".", "makedirs", "(", "stats_path", ")", "\n", "\n", "key_train", ",", "key_valid", ",", "key_test", "=", "select_train_valid_test", "(", "\n", "key_list", ",", "random_seed", "=", "i", ")", "\n", "\n", "count_conditional_prob_dp", "(", "seqex_list", ",", "stats_path", ",", "set", "(", "key_train", ")", ")", "\n", "train_seqex", "=", "add_sparse_prior_guide_dp", "(", "\n", "seqex_list", ",", "stats_path", ",", "set", "(", "key_train", ")", ",", "max_num_codes", "=", "50", ")", "\n", "validation_seqex", "=", "add_sparse_prior_guide_dp", "(", "\n", "seqex_list", ",", "stats_path", ",", "set", "(", "key_valid", ")", ",", "max_num_codes", "=", "50", ")", "\n", "test_seqex", "=", "add_sparse_prior_guide_dp", "(", "\n", "seqex_list", ",", "stats_path", ",", "set", "(", "key_test", ")", ",", "max_num_codes", "=", "50", ")", "\n", "\n", "with", "tf", ".", "io", ".", "TFRecordWriter", "(", "fold_path", "+", "'/train.tfrecord'", ")", "as", "writer", ":", "\n", "      ", "for", "seqex", "in", "train_seqex", ":", "\n", "        ", "writer", ".", "write", "(", "seqex", ".", "SerializeToString", "(", ")", ")", "\n", "\n", "", "", "with", "tf", ".", "io", ".", "TFRecordWriter", "(", "fold_path", "+", "'/validation.tfrecord'", ")", "as", "writer", ":", "\n", "      ", "for", "seqex", "in", "validation_seqex", ":", "\n", "        ", "writer", ".", "write", "(", "seqex", ".", "SerializeToString", "(", ")", ")", "\n", "\n", "", "", "with", "tf", ".", "io", ".", "TFRecordWriter", "(", "fold_path", "+", "'/test.tfrecord'", ")", "as", "writer", ":", "\n", "      ", "for", "seqex", "in", "test_seqex", ":", "\n", "        ", "writer", ".", "write", "(", "seqex", ".", "SerializeToString", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.experimental_main.main": [[22, 29], ["multimodal_transformer_model.MultimodalTransformerModel", "experiment.run"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.experiment.run"], ["def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "model_instance", "=", "MultimodalTransformerModel", "(", ")", "\n", "experiment", ".", "run", "(", "\n", "model_instance", "=", "model_instance", ",", "\n", "num_train_steps", "=", "100", ",", "\n", "num_eval_steps", "=", "10", ",", "\n", "save_checkpoints_secs", "=", "100", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel.create_model_hparams": [[186, 218], ["tensor2tensor.utils.hparam.HParams"], "methods", ["None"], ["def", "create_model_hparams", "(", "self", ")", ":", "\n", "    ", "return", "hparam", ".", "HParams", "(", "\n", "batch_size", "=", "2", ",", "\n", "clip_norm", "=", "1.0", ",", "\n", "hidden_size", "=", "256", ",", "\n", "use_padding", "=", "False", ",", "\n", "hidden_layer_dim", "=", "32", ",", "\n", "hidden_layer_keep_prob", "=", "1.0", ",", "\n", "output_bias", "=", "0.0", ",", "\n", "\n", "# All this stuff is internal to tensor2tensor transformer layer.", "\n", "ffn_layer", "=", "'dense_relu_dense'", ",", "\n", "layer_postprocess_sequence", "=", "'da'", ",", "\n", "attention_dropout", "=", ".25", ",", "\n", "block_length", "=", "40", ",", "\n", "max_length", "=", "256", ",", "\n", "num_encoder_layers", "=", "2", ",", "\n", "num_heads", "=", "2", ",", "\n", "num_hidden_layers", "=", "1", ",", "\n", "pos", "=", "''", ",", "\n", "proximity_bias", "=", "False", ",", "\n", "self_attention_type", "=", "'dot_product'", ",", "\n", "unidirectional_encoder", "=", "True", ",", "\n", "use_target_space_embedding", "=", "False", ",", "\n", "\n", "# All this stuff is internal to tensor2tensor learning rate schedule.", "\n", "learning_rate_decay_rate", "=", ".96", ",", "\n", "learning_rate_decay_staircase", "=", "False", ",", "\n", "learning_rate_decay_steps", "=", "4000", ",", "\n", "learning_rate_schedule", "=", "'constant'", ",", "\n", "learning_rate_warmup_steps", "=", "6000", ",", "\n", "train_steps", "=", "10", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel.create_hparams": [[220, 244], ["multimodal_transformer_model.MultimodalTransformerModel.create_model_hparams", "tensorflow.training.merge_hparam"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel.create_model_hparams"], ["", "def", "create_hparams", "(", "self", ",", "hparams_overrides", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns hyperparameters, including any flag value overrides.\n\n    In order to allow for automated hyperparameter tuning, model hyperparameters\n    are aggregated within a tf.HParams object.\n    If the hparams_override FLAG is set, then it will use any values specified\n    in hparams_override to override any individually-set hyperparameter.\n    This logic allows tuners to override hyperparameter settings to find optimal\n    values.\n\n    Args:\n      hparams_overrides: Hparams overriding existing ones. The priority of\n        conflicting hparams: Lowest are the defaults defined in the model's\n        create_params() function, then the ones from the file from hparam_path,\n        and then the ones from this arg (e.g. through vizier),\n        and highest priority are the flag hparams.\n\n    Returns:\n      The hyperparameters as a tf.HParams object.\n    \"\"\"", "\n", "hparams", "=", "self", ".", "create_model_hparams", "(", ")", "\n", "if", "hparams_overrides", ":", "\n", "      ", "hparams", "=", "tf", ".", "training", ".", "merge_hparam", "(", "hparams", ",", "hparams_overrides", ")", "\n", "", "return", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel.reduce_sequence": [[245, 282], ["tensor2tensor.models.transformer.transformer_base_v2", "six.iteritems", "tensorflow.logging.info", "multimodal_transformer_model.mufasa_model", "tensorflow.range", "tensorflow.stack", "tensorflow.gather_nd", "hparams.values", "len", "len", "tensorflow.cast", "tensor2tensor.models.transformer.transformer_base_v2.set_hparam", "tensor2tensor.models.transformer.transformer_base_v2.add_hparam", "tensorflow.keras.layers.Conv1D", "zip", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.mufasa_model"], ["", "def", "reduce_sequence", "(", "self", ",", "hparams", ",", "all_sequence_embeddings_list", ",", "\n", "sequence_length", ")", ":", "\n", "    ", "\"\"\"Process sequence inpus.\"\"\"", "\n", "\n", "params", "=", "transformer", ".", "transformer_base_v2", "(", ")", "\n", "for", "k", ",", "v", "in", "six", ".", "iteritems", "(", "hparams", ".", "values", "(", ")", ")", ":", "\n", "      ", "if", "k", "in", "params", ":", "\n", "        ", "params", ".", "set_hparam", "(", "k", ",", "v", ")", "\n", "", "else", ":", "\n", "        ", "params", ".", "add_hparam", "(", "k", ",", "v", ")", "\n", "\n", "# Here we project input feature dimensions into the customized dimensions.", "\n", "# It is optional.", "\n", "", "", "hidden_size_for_all_modalities", "=", "[", "8", ",", "16", ",", "32", "]", "\n", "assert", "len", "(", "hidden_size_for_all_modalities", ")", "==", "len", "(", "\n", "all_sequence_embeddings_list", ")", "\n", "all_sequence_embeddings_list", "=", "[", "\n", "tf", ".", "keras", ".", "layers", ".", "Conv1D", "(", "\n", "filters", "=", "single_hidden_size", ",", "\n", "padding", "=", "'valid'", ",", "\n", "kernel_size", "=", "1", ",", "\n", ")", "(", "sequence_embeddings", ")", "\n", "for", "single_hidden_size", ",", "sequence_embeddings", "in", "zip", "(", "\n", "hidden_size_for_all_modalities", ",", "all_sequence_embeddings_list", ")", "\n", "]", "\n", "tf", ".", "logging", ".", "info", "(", "'Projected all_sequence_embeddings_list:\\n%s'", ",", "\n", "all_sequence_embeddings_list", ")", "\n", "\n", "encoder_output", "=", "mufasa_model", "(", "\n", "input_tensors", "=", "all_sequence_embeddings_list", ",", "\n", "hparams", "=", "params", ")", "\n", "\n", "# sequence_length is a vector containing sequence lengths in a batch.", "\n", "indices", "=", "tf", ".", "range", "(", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "sequence_length", ")", "[", "0", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ")", "\n", "indices", "=", "tf", ".", "stack", "(", "[", "indices", ",", "sequence_length", "-", "1", "]", ",", "axis", "=", "1", ")", "\n", "last_output", "=", "tf", ".", "gather_nd", "(", "encoder_output", ",", "indices", ")", "\n", "return", "encoder_output", ",", "last_output", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel.get_2d_and_3d_prelogits": [[283, 328], ["tensorflow.constant", "multimodal_transformer_model.MultimodalTransformerModel.reduce_sequence", "tensorflow.random.normal", "tensorflow.concat", "tensorflow.layers.dense", "tensorflow.layers.dropout"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel.reduce_sequence", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat"], ["", "def", "get_2d_and_3d_prelogits", "(", "self", ",", "hparams", ",", "features", ",", "mode", ")", ":", "\n", "    ", "\"\"\"Returns processed features and feature_columns according to hparams.\n\n    Args:\n      hparams: The hyperparameters.\n      features: A dictionary of tensors keyed by the feature name.\n      mode: The execution mode, as defined in tf.estimator.ModeKeys.\n\n    Returns:\n      A tuple (2d_prelogits, 3d_prelogits).\n      - 2d_prelogits is the prelogits based on the last sequence output combined\n        with context features.\n      - 3d_prelogits is the prelogits at each bag in the sequence.\n    \"\"\"", "\n", "# This is the simulated data in the shape [batch_size, seq_len, hidden_dim].", "\n", "# Here we assume dimensions [0:8] are for categorical features;", "\n", "# Dimensions [8:24] are for continuous feature; Dimensions [24:56] are", "\n", "# for the clinical notes. They are for the exemplified purpose.", "\n", "all_sequence_embeddings", "=", "[", "\n", "features", "[", ":", ",", ":", ",", "0", ":", "8", "]", ",", "features", "[", ":", ",", ":", ",", "8", ":", "24", "]", ",", "features", "[", ":", ",", ":", ",", "24", ":", "56", "]", "\n", "]", "\n", "# Here we assume all sequences have the same sequence length, which is 10.", "\n", "# In the real EHR data, the sequence length could be very different for", "\n", "# different patients. We need to do paddings.", "\n", "sequence_length", "=", "tf", ".", "constant", "(", "hparams", ".", "batch_size", "*", "[", "10", "]", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "seq_output", ",", "last_output", "=", "self", ".", "reduce_sequence", "(", "\n", "hparams", ",", "all_sequence_embeddings", ",", "sequence_length", ")", "\n", "\n", "# 4. Combine the results of the sequence model with context features.", "\n", "context_output", "=", "tf", ".", "random", ".", "normal", "(", "[", "hparams", ".", "batch_size", ",", "2", "]", ")", "\n", "combined_features", "=", "tf", ".", "concat", "(", "\n", "[", "last_output", ",", "context_output", "]", ",", "\n", "axis", "=", "-", "1", ")", "\n", "\n", "# 5. Maybe add a final hidden layer with optional dropout.", "\n", "if", "hparams", ".", "hidden_layer_dim", ">", "0", ":", "\n", "      ", "combined_features", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "combined_features", ",", "hparams", ".", "hidden_layer_dim", ",", "activation", "=", "tf", ".", "nn", ".", "relu6", ")", "\n", "if", "hparams", ".", "hidden_layer_keep_prob", "<", "1.0", ":", "\n", "        ", "combined_features", "=", "tf", ".", "layers", ".", "dropout", "(", "\n", "combined_features", ",", "\n", "rate", "=", "1.0", "-", "hparams", ".", "hidden_layer_keep_prob", ",", "\n", "training", "=", "(", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", ")", "\n", "\n", "", "", "return", "combined_features", ",", "seq_output", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel.create_logits_fn": [[329, 350], ["multimodal_transformer_model.MultimodalTransformerModel.get_2d_and_3d_prelogits", "tensorflow.layers.dense", "tensorflow.constant_initializer"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel.get_2d_and_3d_prelogits"], ["", "def", "create_logits_fn", "(", "self", ",", "hparams", ",", "logits_dimension", "=", "1", ")", ":", "\n", "    ", "\"\"\"Return logits function.\"\"\"", "\n", "\n", "def", "logits_fn", "(", "features", ",", "mode", ")", ":", "\n", "      ", "\"\"\"Creates the logits.\n\n      Args:\n        features: A dictionary of tensors keyed by the feature name.\n        mode: The execution mode, as defined in tf.estimator.ModeKeys.\n\n      Returns:\n        logits: 2d logits based on the last sequence output combined with\n          context features.\n      \"\"\"", "\n", "prelogits_2d", ",", "_", "=", "self", ".", "get_2d_and_3d_prelogits", "(", "hparams", ",", "features", ",", "mode", ")", "\n", "return", "tf", ".", "layers", ".", "dense", "(", "\n", "prelogits_2d", ",", "\n", "logits_dimension", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "hparams", ".", "output_bias", ")", ")", "\n", "\n", "", "return", "logits_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel.create_model_fn": [[351, 373], ["multimodal_transformer_model.MultimodalTransformerModel.create_logits_fn", "multimodal_transformer_model.MultimodalTransformerModel.", "tensorflow.train.AdamOptimizer", "multimodal_transformer_model.MultimodalTransformerModel.create_estimator_spec"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel.create_logits_fn", "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel.create_estimator_spec"], ["", "def", "create_model_fn", "(", "self", ",", "hparams", ")", ":", "\n", "    ", "\"\"\"Returns a function to build the model.\n\n    Args:\n      hparams: The hyperparameters.\n\n    Returns:\n      A function to build the model's graph. This function is called by\n      the Estimator object to construct the graph.\n    \"\"\"", "\n", "logits_fn", "=", "self", ".", "create_logits_fn", "(", "hparams", ",", "1", ")", "\n", "\n", "def", "model_fn", "(", "features", ",", "labels", ",", "mode", ")", ":", "\n", "      ", "logits", "=", "logits_fn", "(", "features", ",", "mode", ")", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "\n", "learning_rate", "=", "0.01", ",", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "epsilon", "=", "1e-8", ")", "\n", "return", "self", ".", "create_estimator_spec", "(", "\n", "logits", "=", "logits", ",", "\n", "labels", "=", "labels", ",", "\n", "mode", "=", "mode", ",", "\n", "optimizer", "=", "optimizer", ")", "\n", "", "return", "model_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel._compute_loss": [[374, 391], ["tensorflow.nn.sigmoid_cross_entropy_with_logits"], "methods", ["None"], ["", "def", "_compute_loss", "(", "self", ",", "labels", ",", "predictions", ")", ":", "\n", "    ", "\"\"\"Computes the cross entropy loss.\n\n    Args:\n      labels: Tensor of shape [batch_size, logits_dimension] target integer\n        labels in {0,1}.\n      predictions: Dictionary of tensors with model predictions needed to\n        compute metrics. Keys must be in constants.PredictionKeys. Particularly,\n        predictions[constants.PredictionKeys.LOGITS] is a a Tensor of shape\n        [batch_size, logits_dimension] with logits produced by the model.\n\n    Returns:\n      A Tensor of the same shape as labels with cross entropy loss.\n    \"\"\"", "\n", "logits", "=", "predictions", "[", "'logits'", "]", "\n", "return", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "\n", "labels", "=", "labels", ",", "logits", "=", "logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel._create_prediction_dict": [[392, 411], ["tensorflow.nn.softmax", "tensorflow.argmax"], "methods", ["None"], ["", "def", "_create_prediction_dict", "(", "self", ",", "logits", ")", ":", "\n", "    ", "\"\"\"Creates the prediction dict from logits.\n\n    Args:\n      logits: Tensor of shape [batch_size, logits_dimension] with logits\n        produced by the model.\n\n    Returns:\n      A dict of Tensor that maps constants.PredictionKeys to the correspoinding\n      predictions.\n    \"\"\"", "\n", "probabilities", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", "classes", "=", "tf", ".", "argmax", "(", "probabilities", ",", "axis", "=", "1", ")", "\n", "predictions", "=", "{", "\n", "'logits'", ":", "logits", ",", "\n", "'probabilities'", ":", "probabilities", ",", "\n", "'classes'", ":", "classes", ",", "\n", "}", "\n", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel.create_estimator_spec": [[412, 483], ["multimodal_transformer_model.MultimodalTransformerModel._create_prediction_dict", "tensorflow.summary.merge_all", "tensorflow.estimator.EstimatorSpec", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_losses", "tensorflow.summary.scalar", "optimizer.minimize", "multimodal_transformer_model.MultimodalTransformerModel.accuracy_fn", "training_hooks.append", "multimodal_transformer_model.MultimodalTransformerModel._compute_loss", "tensorflow.summary.scalar", "tensorflow.add_n", "tensorflow.summary.scalar", "tensorflow.train.get_or_create_global_step", "tensorflow.train.SummarySaverHook"], "methods", ["home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel._create_prediction_dict", "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel.accuracy_fn", "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel._compute_loss"], ["", "def", "create_estimator_spec", "(", "self", ",", "\n", "logits", ",", "\n", "labels", ",", "\n", "mode", ",", "\n", "mask", "=", "None", ",", "\n", "loss", "=", "None", ",", "\n", "optimizer", "=", "None", ",", "\n", "extra_eval_metrics", "=", "None", ")", ":", "\n", "    ", "\"\"\"Create EstimatorSpec for the prediction task.\n\n    Args:\n      logits: Tensor of shape [batch_size, logits_dimension].\n      labels: A dict of dense label tensors. The key is label_key. The value is\n        a tensor of shape [batch_size, logits_dimension] with 0/1 class labels\n        for classification tasks, or shape [batch_size, 1] with numeric labels\n        for regression.\n      mode: The execution mode, as defined in tf.estimator.ModeKeys.\n      mask: Tensor of type float32 that will be multiplied with the loss.\n      loss: If provided, loss Tensor with shape [batch_size, 1]. If not\n        provided, sigmoid cross entropy is used with given logits and labels.\n      optimizer: tf.Optimizer instance. If not provided, defaults to Adam.\n      extra_eval_metrics: If provided, a dictionary of `\"name\": tf.metrics.*\n        object` entries to add to the existing evaluation metrics.\n\n    Returns:\n      EstimatorSpec with the mode, prediction, loss, train_op and\n      export_outputs a dictionary specifying the output for a\n      servo request during serving.\n    \"\"\"", "\n", "predictions", "=", "self", ".", "_create_prediction_dict", "(", "logits", ")", "\n", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "PREDICT", ":", "\n", "      ", "loss", "=", "None", "\n", "", "else", ":", "\n", "      ", "if", "loss", "is", "None", ":", "\n", "        ", "label_tensor", "=", "labels", "\n", "loss", "=", "self", ".", "_compute_loss", "(", "label_tensor", ",", "predictions", ")", "\n", "", "if", "mask", "is", "not", "None", ":", "\n", "        ", "loss", "*=", "mask", "\n", "", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "regularization_losses", "=", "tf", ".", "losses", ".", "get_regularization_losses", "(", ")", "\n", "if", "regularization_losses", ":", "\n", "        ", "tf", ".", "summary", ".", "scalar", "(", "'loss/prior_regularization'", ",", "loss", ")", "\n", "regularization_loss", "=", "tf", ".", "add_n", "(", "regularization_losses", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'loss/regularization_loss'", ",", "regularization_loss", ")", "\n", "loss", "+=", "regularization_loss", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "'loss/train/'", ",", "loss", ")", "\n", "\n", "", "train_op", "=", "None", "\n", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ":", "\n", "      ", "train_op", "=", "optimizer", ".", "minimize", "(", "loss", ",", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", ")", "\n", "\n", "", "if", "not", "extra_eval_metrics", ":", "\n", "      ", "eval_metric_ops", "=", "{", "}", "\n", "", "else", ":", "\n", "      ", "eval_metric_ops", "=", "extra_eval_metrics", "\n", "", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ":", "\n", "      ", "label_tensor", "=", "labels", "\n", "eval_metric_ops", "[", "'accuracy'", "]", "=", "self", ".", "accuracy_fn", "(", "label_tensor", ",", "predictions", ")", "\n", "", "merged", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "training_hooks", "=", "[", "]", "\n", "if", "merged", "is", "not", "None", ":", "\n", "      ", "training_hooks", ".", "append", "(", "\n", "tf", ".", "train", ".", "SummarySaverHook", "(", "save_steps", "=", "100", ",", "summary_op", "=", "merged", ")", ")", "\n", "\n", "", "return", "tf", ".", "estimator", ".", "EstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "predictions", "=", "predictions", ",", "\n", "loss", "=", "loss", ",", "\n", "train_op", "=", "train_op", ",", "\n", "eval_metric_ops", "=", "eval_metric_ops", ",", "\n", "training_hooks", "=", "training_hooks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel.accuracy_fn": [[484, 488], ["tensorflow.metrics.accuracy"], "methods", ["None"], ["", "def", "accuracy_fn", "(", "self", ",", "labels", ",", "predictions", ")", ":", "\n", "    ", "\"\"\"Helper function for calculating the accuracy on uncensored examples.\"\"\"", "\n", "return", "tf", ".", "metrics", ".", "accuracy", "(", "\n", "labels", "=", "labels", ",", "predictions", "=", "predictions", "[", "'classes'", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.mufasa_model": [[31, 181], ["tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensor2tensor.layers.common_layers.comma_separated_string_to_integer_list", "tensor2tensor.layers.common_layers.layer_preprocess", "tensorflow.nn.leaky_relu", "tensor2tensor.layers.common_layers.layer_preprocess", "tensorflow.layers.dense", "tensorflow.nn.relu", "tensor2tensor.layers.common_layers.layer_preprocess", "tensorflow.layers.dense", "tensor2tensor.layers.common_layers.layer_preprocess", "tensor2tensor.layers.common_layers.layer_preprocess", "tensorflow.layers.dense", "tensorflow.nn.relu", "tensor2tensor.layers.common_layers.layer_preprocess", "tensorflow.layers.dense", "tensor2tensor.layers.common_layers.layer_preprocess", "tensorflow.concat", "tensorflow.layers.dense", "tensorflow.nn.relu", "tensor2tensor.layers.common_layers.layer_preprocess", "tensorflow.layers.dense", "tensorflow.nn.relu", "tensorflow.concat", "tensor2tensor.layers.common_layers.layer_preprocess", "tensorflow.layers.SeparableConv1D", "tf.layers.SeparableConv1D.apply", "tensorflow.layers.dense", "tensorflow.nn.relu", "tensorflow.layers.dense", "tensor2tensor.layers.common_layers.layer_preprocess", "getattr", "tensorflow.variable_scope", "tensor2tensor.layers.common_attention.multihead_attention", "tensorflow.variable_scope", "tensor2tensor.layers.common_attention.multihead_attention", "tensorflow.variable_scope", "tensor2tensor.layers.common_attention.multihead_attention", "tensorflow.pad", "tensorflow.pad", "tensorflow.pad", "tensorflow.pad", "tensorflow.pad"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat", "home.repos.pwc.inspect_result.google-health_records-research.beds-bench.prepare.concat"], ["def", "mufasa_model", "(", "input_tensors", ",", "hparams", ")", ":", "\n", "  ", "\"\"\"MUFASA model architecture code.\n\n  Args:\n    input_tensors: A list of input tensors. The first tensor is categorical\n    features, the second tensor is ocntunous features and the third tensor is\n    clinical notes. All tensors in shape of [batch_size, seq_len, hidden_dim].\n    hparams: A tf.HParams object with model hyperparameters.\n\n  Returns:\n    A model processed output with shape [batch_size, seq_len, hidden_dim].\n  \"\"\"", "\n", "categorical_data", "=", "tf", ".", "layers", ".", "dense", "(", "input_tensors", "[", "0", "]", ",", "128", ")", "\n", "continuous_features", "=", "tf", ".", "layers", ".", "dense", "(", "input_tensors", "[", "1", "]", ",", "128", ")", "\n", "clinical_notes", "=", "tf", ".", "layers", ".", "dense", "(", "input_tensors", "[", "2", "]", ",", "128", ")", "\n", "dropout_broadcast_dims", "=", "(", "\n", "common_layers", ".", "comma_separated_string_to_integer_list", "(", "\n", "getattr", "(", "hparams", ",", "'attention_dropout_broadcast_dims'", ",", "''", ")", ")", ")", "\n", "hparams", ".", "norm_type", "=", "'layer'", "\n", "\n", "# Continuous Features Branch.", "\n", "continuous_res", "=", "continuous_features", "\n", "# Layer Norm.", "\n", "continuous_hs", "=", "common_layers", ".", "layer_preprocess", "(", "continuous_features", ",", "hparams", ")", "\n", "# Self Attention.", "\n", "with", "tf", ".", "variable_scope", "(", "'continuous_attention'", ")", ":", "\n", "    ", "continuous_hs", "=", "common_attention", ".", "multihead_attention", "(", "\n", "query_antecedent", "=", "continuous_hs", ",", "\n", "memory_antecedent", "=", "None", ",", "\n", "bias", "=", "None", ",", "\n", "total_key_depth", "=", "128", ",", "\n", "total_value_depth", "=", "128", ",", "\n", "output_depth", "=", "128", ",", "\n", "num_heads", "=", "8", ",", "\n", "dropout_rate", "=", "hparams", ".", "attention_dropout", ",", "\n", "attention_type", "=", "hparams", ".", "self_attention_type", ",", "\n", "max_relative_position", "=", "hparams", ".", "max_relative_position", ",", "\n", "dropout_broadcast_dims", "=", "dropout_broadcast_dims", ")", "\n", "# Leaky Relu.", "\n", "", "continuous_hs", "=", "tf", ".", "nn", ".", "leaky_relu", "(", "continuous_hs", ")", "\n", "# Residul.", "\n", "continuous_hs", "+=", "continuous_res", "\n", "continuous_res", "=", "continuous_hs", "\n", "# Layer Norm.", "\n", "continuous_hs", "=", "common_layers", ".", "layer_preprocess", "(", "continuous_hs", ",", "hparams", ")", "\n", "# 1x1 Conv.", "\n", "continuous_hs", "=", "tf", ".", "layers", ".", "dense", "(", "continuous_hs", ",", "512", ")", "\n", "# Relu.", "\n", "continuous_hs", "=", "tf", ".", "nn", ".", "relu", "(", "continuous_hs", ")", "\n", "# Layer Norm.", "\n", "continuous_hs", "=", "common_layers", ".", "layer_preprocess", "(", "continuous_hs", ",", "hparams", ")", "\n", "# 1x1 Conv.", "\n", "continuous_hs", "=", "tf", ".", "layers", ".", "dense", "(", "continuous_hs", ",", "128", ")", "\n", "# Residul.", "\n", "continuous_hs", "+=", "continuous_res", "\n", "# Continuous is now complete.", "\n", "\n", "# Clinical Notes Branch.", "\n", "clinical_res", "=", "clinical_notes", "\n", "# Layer Norm.", "\n", "clinical_hs", "=", "common_layers", ".", "layer_preprocess", "(", "clinical_notes", ",", "hparams", ")", "\n", "# Self Attention.", "\n", "with", "tf", ".", "variable_scope", "(", "'clinical_attention'", ")", ":", "\n", "    ", "clinical_hs", "=", "common_attention", ".", "multihead_attention", "(", "\n", "query_antecedent", "=", "clinical_hs", ",", "\n", "memory_antecedent", "=", "None", ",", "\n", "bias", "=", "None", ",", "\n", "total_key_depth", "=", "128", ",", "\n", "total_value_depth", "=", "128", ",", "\n", "output_depth", "=", "128", ",", "\n", "num_heads", "=", "8", ",", "\n", "dropout_rate", "=", "hparams", ".", "attention_dropout", ",", "\n", "attention_type", "=", "hparams", ".", "self_attention_type", ",", "\n", "max_relative_position", "=", "hparams", ".", "max_relative_position", ",", "\n", "dropout_broadcast_dims", "=", "dropout_broadcast_dims", ")", "\n", "# Residul.", "\n", "", "clinical_hs", "+=", "clinical_res", "\n", "# Layer Norm.", "\n", "clinical_hs", "=", "common_layers", ".", "layer_preprocess", "(", "clinical_hs", ",", "hparams", ")", "\n", "clinical_res", "=", "clinical_hs", "\n", "# 1x1 Conv.", "\n", "clinical_hs", "=", "tf", ".", "layers", ".", "dense", "(", "clinical_hs", ",", "512", ")", "\n", "# Relu.", "\n", "clinical_hs", "=", "tf", ".", "nn", ".", "relu", "(", "clinical_hs", ")", "\n", "# Layer Norm.", "\n", "clinical_hs", "=", "common_layers", ".", "layer_preprocess", "(", "clinical_hs", ",", "hparams", ")", "\n", "# 1x1 Conv.", "\n", "clinical_hs", "=", "tf", ".", "layers", ".", "dense", "(", "clinical_hs", ",", "128", ")", "\n", "# Residul.", "\n", "clinical_hs", "+=", "clinical_hs", "\n", "# Clinical is now complete.", "\n", "\n", "# Categorical Data Branch.", "\n", "categorical_res", "=", "categorical_data", "\n", "# Layer Norm.", "\n", "categorical_hs", "=", "common_layers", ".", "layer_preprocess", "(", "categorical_data", ",", "hparams", ")", "\n", "# Self Attention.", "\n", "with", "tf", ".", "variable_scope", "(", "'categorical_attention'", ")", ":", "\n", "    ", "categorical_hs", "=", "common_attention", ".", "multihead_attention", "(", "\n", "query_antecedent", "=", "categorical_hs", ",", "\n", "memory_antecedent", "=", "None", ",", "\n", "bias", "=", "None", ",", "\n", "total_key_depth", "=", "128", ",", "\n", "total_value_depth", "=", "128", ",", "\n", "output_depth", "=", "128", ",", "\n", "num_heads", "=", "8", ",", "\n", "dropout_rate", "=", "hparams", ".", "attention_dropout", ",", "\n", "attention_type", "=", "hparams", ".", "self_attention_type", ",", "\n", "max_relative_position", "=", "hparams", ".", "max_relative_position", ",", "\n", "dropout_broadcast_dims", "=", "dropout_broadcast_dims", ")", "\n", "# Concatenation.", "\n", "", "categorical_hs", "=", "tf", ".", "concat", "(", "[", "categorical_hs", ",", "categorical_res", "]", ",", "axis", "=", "-", "1", ")", "\n", "categorical_res", "=", "categorical_hs", "\n", "# 1x1 Conv.", "\n", "categorical_hs", "=", "tf", ".", "layers", ".", "dense", "(", "categorical_hs", ",", "512", ")", "\n", "# Relu.", "\n", "categorical_hs", "=", "tf", ".", "nn", ".", "relu", "(", "categorical_hs", ")", "\n", "# Right Path - Layer Norm.", "\n", "categorical_res", "=", "common_layers", ".", "layer_preprocess", "(", "categorical_res", ",", "hparams", ")", "\n", "# Hybrid Fusion Point.", "\n", "categorical_hybrid_point", "=", "categorical_hs", "+", "tf", ".", "pad", "(", "categorical_res", ",", "\n", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "256", "]", "]", ")", "\n", "# Right Path - Dense.", "\n", "categorical_res", "=", "tf", ".", "layers", ".", "dense", "(", "categorical_res", ",", "512", ")", "\n", "# Right Path - Relu. Late Fusion Point.", "\n", "categorical_late_point", "=", "tf", ".", "nn", ".", "relu", "(", "categorical_res", ")", "\n", "\n", "# Fusion Architecture.", "\n", "fusion_hs", "=", "tf", ".", "concat", "(", "[", "clinical_hs", ",", "categorical_hybrid_point", "]", ",", "axis", "=", "-", "1", ")", "\n", "fusion_res", "=", "fusion_hs", "\n", "# Layer Norm.", "\n", "fusion_hs", "=", "common_layers", ".", "layer_preprocess", "(", "fusion_hs", ",", "hparams", ")", "\n", "# Side Branch.", "\n", "separable_conv_1d", "=", "tf", ".", "layers", ".", "SeparableConv1D", "(", "\n", "384", ",", "3", ",", "name", "=", "'separable_conv_3x1'", ",", "padding", "=", "'SAME'", ")", "\n", "fusion_sepconv_branch", "=", "separable_conv_1d", ".", "apply", "(", "fusion_hs", ")", "\n", "# Dense.", "\n", "fusion_hs", "=", "tf", ".", "layers", ".", "dense", "(", "fusion_hs", ",", "1536", ")", "\n", "# Relu.", "\n", "fusion_hs", "=", "tf", ".", "nn", ".", "relu", "(", "fusion_hs", ")", "\n", "# Dense.", "\n", "fusion_hs", "=", "tf", ".", "layers", ".", "dense", "(", "fusion_hs", ",", "384", ")", "\n", "\n", "output", "=", "fusion_res", "+", "tf", ".", "pad", "(", "fusion_hs", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "256", "]", "]", ")", "+", "tf", ".", "pad", "(", "\n", "fusion_sepconv_branch", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "256", "]", "]", ")", "+", "tf", ".", "pad", "(", "\n", "categorical_late_point", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "128", "]", "]", ")", "+", "tf", ".", "pad", "(", "\n", "continuous_hs", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "512", "]", "]", ")", "\n", "\n", "output", "=", "common_layers", ".", "layer_preprocess", "(", "output", ",", "hparams", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.experiment.make_training_spec_fn": [[25, 129], ["tensorflow.estimator.RunConfig", "tensorflow.logging.info", "model_instance.create_hparams", "get_input_fn"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.multimodal_transformer_model.MultimodalTransformerModel.create_hparams", "home.repos.pwc.inspect_result.google-health_records-research.state-space-model.data_provider.DataProvider.get_input_fn"], ["warm_start_from", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "  ", "\"\"\"Creates a function which builds a tf.contrib.learn.Experiment object.\n\n  Args:\n    experiment_config: experiment configuration.\n    warm_start_from: Optional string filepath to a checkpoint or SavedModel to\n      warm-start from.\n    **kwargs: Additional keyword arguments passed to experiment.\n\n  Returns:\n    A function of two arguments, `run_config` and `hparams`, which builds a\n    tf.contrib.learn.Experiment object.\n  \"\"\"", "\n", "\n", "def", "experiment_fn", "(", "run_config", ",", "hparams", ":", "tf", ".", "HParams", "=", "None", ")", ":", "\n", "    ", "\"\"\"Create a tf.contrib.learn.Experiment object.\n\n    Args:\n      run_config: An instance of learn_runner.EstimatorConfig.\n      hparams: hparams passed from FLAGs.hparams which will be used to override\n        the values from experiment_config.\n\n    Returns:\n      A tf.contrib.learn.Experiment object.\n    \"\"\"", "\n", "config", "=", "experiment_config", "\n", "if", "hparams", "is", "not", "None", ":", "\n", "# Populate command-line hparams to config.", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "'Using command-line hyperparameters %s'", ",", "hparams", ")", "\n", "config", "=", "config_utils", ".", "merge_from_hparams", "(", "\n", "experiment_config", ",", "hparams", ",", "delimiter", "=", "'__'", ")", "\n", "", "config", ".", "experiment_dir", "=", "run_config", ".", "model_dir", "\n", "tf", ".", "logging", ".", "info", "(", "'experiment config: '", "+", "text_format", ".", "MessageToString", "(", "config", ")", ")", "\n", "tf", ".", "logging", ".", "info", "(", "'run config:'", "+", "\n", "text_format", ".", "MessageToString", "(", "run_config", ".", "tf_config", ")", ")", "\n", "estimator", "=", "tf", ".", "estimator", ".", "Estimator", "(", "\n", "model_fn", "=", "models", ".", "build_model_ops", ",", "\n", "params", "=", "config", ".", "model", ",", "\n", "config", "=", "run_config", ",", "\n", "warm_start_from", "=", "warm_start_from", ")", "\n", "provider", "=", "data_provider", ".", "DataProvider", ".", "from_config", "(", "config", ")", "\n", "export_strategies", "=", "[", "]", "\n", "return", "tf", ".", "contrib", ".", "learn", ".", "Experiment", "(", "\n", "estimator", "=", "estimator", ",", "\n", "train_input_fn", "=", "provider", ".", "get_input_fn", "(", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", ",", "\n", "eval_input_fn", "=", "provider", ".", "get_input_fn", "(", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ")", ",", "\n", "export_strategies", "=", "export_strategies", ",", "\n", "**", "kwargs", ")", "\n", "\n", "", "return", "experiment_fn", "\n", "", ""]], "home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.experiment.run": [[131, 167], ["experiment.make_training_spec_fn", "make_training_spec_fn.", "tensorflow.estimator.train_and_evaluate", "tensorflow.logging.info"], "function", ["home.repos.pwc.inspect_result.google-health_records-research.multimodal-architecture-search.experiment.make_training_spec_fn"], []]}