{"home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.models.CNN_Text.__init__": [[8, 18], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Conv2d", "torch.nn.Conv2d", "len"], "methods", ["home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.models.CNNBert.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embed_size", ",", "max_features", ")", ":", "\n", "        ", "super", "(", "CNN_Text", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "filter_sizes", "=", "[", "1", ",", "2", ",", "3", ",", "5", "]", "\n", "num_filters", "=", "36", "\n", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "max_features", ",", "embed_size", ")", "\n", "self", ".", "convs1", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv2d", "(", "1", ",", "num_filters", ",", "(", "K", ",", "embed_size", ")", ")", "for", "K", "in", "filter_sizes", "]", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.1", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "len", "(", "filter_sizes", ")", "*", "num_filters", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.models.CNN_Text.forward": [[19, 28], ["models.CNN_Text.embedding", "models.CNN_Text.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.CNN_Text.dropout", "models.CNN_Text.fc1", "torch.relu().squeeze", "torch.relu().squeeze", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "torch.relu", "torch.relu", "torch.max_pool1d", "torch.max_pool1d", "conv", "i.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "embedding", "(", "x", ")", "\n", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "x", "=", "[", "F", ".", "relu", "(", "conv", "(", "x", ")", ")", ".", "squeeze", "(", "3", ")", "for", "conv", "in", "self", ".", "convs1", "]", "\n", "x", "=", "[", "F", ".", "max_pool1d", "(", "i", ",", "i", ".", "size", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "for", "i", "in", "x", "]", "\n", "x", "=", "torch", ".", "cat", "(", "x", ",", "1", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "logit", "=", "self", ".", "fc1", "(", "x", ")", "\n", "return", "logit", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.models.BiLSTM.__init__": [[32, 42], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.models.CNNBert.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embed_size", ",", "max_features", ")", ":", "\n", "        ", "super", "(", "BiLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "drp", "=", "0.1", "\n", "self", ".", "hidden_size", "=", "128", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "max_features", ",", "embed_size", ")", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "embed_size", ",", "self", ".", "hidden_size", ",", "bidirectional", "=", "True", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_size", "*", "4", ",", "128", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "drp", ")", "\n", "self", ".", "out", "=", "nn", ".", "Linear", "(", "128", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.models.BiLSTM.forward": [[44, 55], ["models.BiLSTM.embedding", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "models.BiLSTM.lstm", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.max", "torch.max", "torch.max", "torch.max", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.BiLSTM.relu", "models.BiLSTM.dropout", "models.BiLSTM.out", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "models.BiLSTM.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h_embedding", "=", "self", ".", "embedding", "(", "x", ")", "\n", "h_embedding", "=", "torch", ".", "squeeze", "(", "torch", ".", "unsqueeze", "(", "h_embedding", ",", "0", ")", ")", "\n", "h_lstm", ",", "_", "=", "self", ".", "lstm", "(", "h_embedding", ")", "\n", "avg_pool", "=", "torch", ".", "mean", "(", "h_lstm", ",", "1", ")", "\n", "max_pool", ",", "_", "=", "torch", ".", "max", "(", "h_lstm", ",", "1", ")", "\n", "conc", "=", "torch", ".", "cat", "(", "(", "avg_pool", ",", "max_pool", ")", ",", "1", ")", "\n", "conc", "=", "self", ".", "relu", "(", "self", ".", "linear", "(", "conc", ")", ")", "\n", "conc", "=", "self", ".", "dropout", "(", "conc", ")", "\n", "out", "=", "self", ".", "out", "(", "conc", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.models.CNNBert.__init__": [[59, 68], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Conv2d", "torch.nn.Conv2d", "len"], "methods", ["home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.models.CNNBert.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embed_size", ",", "bert_model", ")", ":", "\n", "        ", "super", "(", "CNNBert", ",", "self", ")", ".", "__init__", "(", ")", "\n", "filter_sizes", "=", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", "\n", "num_filters", "=", "32", "\n", "self", ".", "convs1", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv2d", "(", "4", ",", "num_filters", ",", "(", "K", ",", "embed_size", ")", ")", "for", "K", "in", "filter_sizes", "]", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.1", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "len", "(", "filter_sizes", ")", "*", "num_filters", ",", "1", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "bert_model", "=", "bert_model", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.models.CNNBert.forward": [[69, 78], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.CNNBert.dropout", "models.CNNBert.fc1", "models.CNNBert.sigmoid", "torch.relu().squeeze", "torch.relu().squeeze", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "models.CNNBert.bert_model", "torch.relu", "torch.relu", "torch.max_pool1d", "torch.max_pool1d", "conv", "i.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "input_masks", ",", "token_type_ids", ")", ":", "\n", "        ", "x", "=", "self", ".", "bert_model", "(", "x", ",", "attention_mask", "=", "input_masks", ",", "token_type_ids", "=", "token_type_ids", ")", "[", "2", "]", "[", "-", "4", ":", "]", "\n", "x", "=", "torch", ".", "stack", "(", "x", ",", "dim", "=", "1", ")", "\n", "x", "=", "[", "F", ".", "relu", "(", "conv", "(", "x", ")", ")", ".", "squeeze", "(", "3", ")", "for", "conv", "in", "self", ".", "convs1", "]", "\n", "x", "=", "[", "F", ".", "max_pool1d", "(", "i", ",", "i", ".", "size", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "for", "i", "in", "x", "]", "\n", "x", "=", "torch", ".", "cat", "(", "x", ",", "1", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "logit", "=", "self", ".", "fc1", "(", "x", ")", "\n", "return", "self", ".", "sigmoid", "(", "logit", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert.preprocess_text": [[40, 44], ["re.finditer", "identifier.replace", "m.group"], "function", ["None"], ["def", "preprocess_text", "(", "identifier", ")", ":", "\n", "# https://stackoverflow.com/a/29920015/5909675", "\n", "    ", "matches", "=", "re", ".", "finditer", "(", "'.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)'", ",", "identifier", ".", "replace", "(", "\"#\"", ",", "\" \"", ")", ")", "\n", "return", "\" \"", ".", "join", "(", "[", "m", ".", "group", "(", "0", ")", "for", "m", "in", "matches", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert.strip_accents_and_lowercase": [[45, 48], ["unicodedata.normalize", "unicodedata.category"], "function", ["None"], ["", "def", "strip_accents_and_lowercase", "(", "s", ")", ":", "\n", "   ", "return", "''", ".", "join", "(", "c", "for", "c", "in", "unicodedata", ".", "normalize", "(", "'NFD'", ",", "s", ")", "\n", "if", "unicodedata", ".", "category", "(", "c", ")", "!=", "'Mn'", ")", ".", "lower", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert.prepare_set": [[49, 61], ["tokenizer.batch_encode_plus", "bert.preprocess_text", "bert.strip_accents_and_lowercase", "bert.preprocess_text"], "function", ["home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.preprocess_text", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.strip_accents_and_lowercase", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.preprocess_text"], ["", "def", "prepare_set", "(", "text", ",", "max_length", "=", "64", ")", ":", "\n", "    ", "\"\"\"returns input_ids, attention_mask, token_type_ids for set of data ready in BERT format\"\"\"", "\n", "global", "tokenizer", "\n", "\n", "text", "=", "[", "preprocess_text", "(", "t", ")", "if", "set_id", "!=", "\"gr\"", "else", "strip_accents_and_lowercase", "(", "preprocess_text", "(", "t", ")", ")", "for", "t", "in", "text", "]", "\n", "t", "=", "tokenizer", ".", "batch_encode_plus", "(", "text", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "add_special_tokens", "=", "True", ",", "\n", "max_length", "=", "max_length", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "\n", "return", "t", "[", "\"input_ids\"", "]", ",", "t", "[", "\"attention_mask\"", "]", ",", "t", "[", "\"token_type_ids\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert.predict": [[62, 80], ["bert.prepare_set", "torch.utils.data.TensorDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "bert..eval", "torch.no_grad", "torch.no_grad", "tuple", "bert..", "output[].detach().cpu", "list", "[].numpy", "t.to", "output[].detach", "torch.nn.functional.softmax", "torch.nn.functional.softmax"], "function", ["home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.prepare_set"], ["", "def", "predict", "(", "self", ",", "test_set", ",", "batch_size", "=", "batch_size", ")", ":", "\n", "    ", "test_inputs", ",", "test_masks", ",", "test_type_ids", "=", "prepare_set", "(", "test_set", ")", "\n", "test_data", "=", "TensorDataset", "(", "test_inputs", ",", "test_masks", ",", "test_type_ids", ")", "\n", "test_sampler", "=", "SequentialSampler", "(", "test_data", ")", "\n", "test_dataloader", "=", "DataLoader", "(", "test_data", ",", "sampler", "=", "test_sampler", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "self", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "preds", "=", "[", "]", "\n", "for", "batch", "in", "test_dataloader", ":", "\n", "            ", "b_input_ids", ",", "b_input_mask", ",", "b_token_type_ids", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", ")", "\n", "output", "=", "self", "(", "b_input_ids", ",", "\n", "attention_mask", "=", "b_input_mask", ",", "\n", "token_type_ids", "=", "b_token_type_ids", ")", "\n", "logits", "=", "output", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "preds", "+=", "list", "(", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "logits", ",", "dim", "=", "1", ")", "[", ":", ",", "1", "]", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert.train_bert": [[81, 176], ["BertTokenizer.from_pretrained", "BertForSequenceClassification.from_pretrained", "print", "bert.prepare_set", "torch.utils.data.TensorDataset", "torch.utils.data.RandomSampler", "torch.utils.data.DataLoader", "bert.prepare_set", "torch.utils.data.TensorDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "nn.DataParallel.to", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "AdamW", "get_linear_schedule_with_warmup", "nn.DataParallel.zero_grad", "range", "nn.DataParallel.load_state_dict", "nn.DataParallel.to", "predict.__get__", "os.remove", "torch.tensor", "torch.tensor", "torch.nn.DataParallel", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "len", "nn.DataParallel.parameters", "time.time", "nn.DataParallel.train", "len", "get_linear_schedule_with_warmup.step", "nn.DataParallel.eval", "len", "sklearn.metrics.f1_score", "print", "torch.load", "torch.load", "len", "len", "tuple", "nn.DataParallel.", "output[].sum", "output[].sum.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "AdamW.step", "output[].sum.item", "nn.DataParallel.zero_grad", "time.time", "torch.no_grad", "torch.no_grad", "torch.save", "torch.save", "print", "nn.DataParallel.parameters", "tuple", "nn.DataParallel.", "output[].sum", "output[].sum.item", "output[].detach().cpu().numpy", "list", "nn.DataParallel.zero_grad", "nn.DataParallel.state_dict", "sklearn.metrics.classification_report", "t.to", "numpy.argmax().flatten", "t.to", "output[].detach().cpu", "numpy.argmax", "output[].detach"], "function", ["home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.prepare_set", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.prepare_set", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.cnn-lstm.train"], ["", "def", "train_bert", "(", "x_train", ",", "x_dev", ",", "y_train", ",", "y_dev", ",", "pretrained_model", ",", "n_epochs", "=", "10", ",", "model_path", "=", "\"temp.pt\"", ",", "batch_size", "=", "batch_size", ")", ":", "\n", "    ", "global", "tokenizer", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "pretrained_model", ")", "\n", "model", "=", "BertForSequenceClassification", ".", "from_pretrained", "(", "pretrained_model", ")", "\n", "\n", "print", "(", "[", "len", "(", "x", ")", "for", "x", "in", "(", "y_train", ",", "y_dev", ")", "]", ")", "\n", "y_train", ",", "y_dev", "=", "(", "torch", ".", "tensor", "(", "t", ")", "for", "t", "in", "(", "y_train", ",", "y_dev", ")", ")", "\n", "\n", "# Create the DataLoader for training set.", "\n", "train_inputs", ",", "train_masks", ",", "train_type_ids", "=", "prepare_set", "(", "x_train", ")", "\n", "train_data", "=", "TensorDataset", "(", "train_inputs", ",", "train_masks", ",", "train_type_ids", ",", "y_train", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_data", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "# Create the DataLoader for dev set.", "\n", "dev_inputs", ",", "dev_masks", ",", "dev_type_ids", "=", "prepare_set", "(", "x_dev", ")", "\n", "dev_data", "=", "TensorDataset", "(", "dev_inputs", ",", "dev_masks", ",", "dev_type_ids", ",", "y_dev", ")", "\n", "dev_sampler", "=", "SequentialSampler", "(", "dev_data", ")", "\n", "dev_dataloader", "=", "DataLoader", "(", "dev_data", ",", "sampler", "=", "dev_sampler", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "if", "len", "(", "device_ids", ")", ">", "1", "and", "device", ".", "type", "==", "\"cuda\"", ":", "\n", "        ", "model", "=", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "device_ids", ")", "\n", "", "model", ".", "to", "(", "device", ")", "\n", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "device", ".", "type", "==", "\"cuda\"", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n", "", "total_steps", "=", "len", "(", "train_dataloader", ")", "*", "n_epochs", "\n", "optimizer", "=", "AdamW", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "\n", "num_warmup_steps", "=", "0", ",", "\n", "num_training_steps", "=", "total_steps", ")", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "best_score", "=", "0", "\n", "best_loss", "=", "1e6", "\n", "\n", "for", "epoch", "in", "range", "(", "n_epochs", ")", ":", "\n", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "train_loss", "=", "0", "\n", "model", ".", "train", "(", ")", "\n", "\n", "for", "batch", "in", "train_dataloader", ":", "\n", "            ", "b_input_ids", ",", "b_input_mask", ",", "b_token_type_ids", ",", "b_labels", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", ")", "\n", "output", "=", "model", "(", "b_input_ids", ",", "\n", "attention_mask", "=", "b_input_mask", ",", "\n", "token_type_ids", "=", "b_token_type_ids", ",", "\n", "labels", "=", "b_labels", ")", "\n", "\n", "loss", "=", "output", "[", "0", "]", ".", "sum", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "1.0", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "train_loss", "/=", "len", "(", "train_dataloader", ")", "\n", "\n", "scheduler", ".", "step", "(", ")", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "model", ".", "eval", "(", ")", "\n", "val_preds", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "val_loss", ",", "batch", "=", "0", ",", "1", "\n", "for", "batch", "in", "dev_dataloader", ":", "\n", "                ", "b_input_ids", ",", "b_input_mask", ",", "b_token_type_ids", ",", "b_labels", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", ")", "\n", "output", "=", "model", "(", "b_input_ids", ",", "\n", "attention_mask", "=", "b_input_mask", ",", "\n", "token_type_ids", "=", "b_token_type_ids", ",", "\n", "labels", "=", "b_labels", ")", "\n", "\n", "loss", "=", "output", "[", "0", "]", ".", "sum", "(", ")", "\n", "val_loss", "+=", "loss", ".", "item", "(", ")", "\n", "logits", "=", "output", "[", "1", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "val_preds", "+=", "list", "(", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "", "val_loss", "/=", "len", "(", "dev_dataloader", ")", "\n", "val_score", "=", "f1_score", "(", "y_dev", ",", "val_preds", ",", "average", "=", "\"macro\"", ")", "\n", "print", "(", "\"Epoch %d Train loss: %.4f. Validation F1-Score: %.4f  Validation loss: %.4f. Elapsed time: %.2fs.\"", "%", "(", "epoch", "+", "1", ",", "train_loss", ",", "val_score", ",", "val_loss", ",", "elapsed", ")", ")", "\n", "\n", "if", "val_score", ">", "best_score", ":", "\n", "            ", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "model_path", ")", "\n", "print", "(", "classification_report", "(", "y_dev", ",", "val_preds", ",", "digits", "=", "4", ")", ")", "\n", "best_score", "=", "val_score", "\n", "\n", "", "", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "model_path", ")", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "predict", "=", "predict", ".", "__get__", "(", "model", ")", "\n", "os", ".", "remove", "(", "model_path", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert.evaluate": [[178, 190], ["data.read_file", "int", "bert.train_bert", "data.read_file", "train_bert.predict", "print", "sklearn.metrics.classification_report", "len", "int"], "function", ["home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.data.read_file", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert.train_bert", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.data.read_file", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.predict"], ["", "def", "evaluate", "(", ")", ":", "\n", "    ", "train_samples", "=", "read_file", "(", "set_id", "+", "\".train\"", ")", "\n", "x", ",", "y", "=", "[", "x", "[", "\"text\"", "]", "for", "x", "in", "train_samples", "]", ",", "[", "x", "[", "\"label\"", "]", "for", "x", "in", "train_samples", "]", "\n", "dev_size", "=", "int", "(", "len", "(", "x", ")", "*", "0.10", ")", "\n", "x_train", ",", "x_dev", ",", "y_train", ",", "y_dev", "=", "x", "[", "dev_size", ":", "]", ",", "x", "[", ":", "dev_size", "]", ",", "y", "[", "dev_size", ":", "]", ",", "y", "[", ":", "dev_size", "]", "\n", "model", "=", "train_bert", "(", "x_train", ",", "x_dev", ",", "y_train", ",", "y_dev", ",", "pretrained_model", ",", "n_epochs", "=", "5", ")", "\n", "\n", "# Testing", "\n", "test_samples", "=", "read_file", "(", "set_id", "+", "\".test\"", ")", "\n", "x_test", ",", "y_test", "=", "[", "x", "[", "\"text\"", "]", "for", "x", "in", "test_samples", "]", ",", "[", "x", "[", "\"label\"", "]", "for", "x", "in", "test_samples", "]", "\n", "predictions", "=", "model", ".", "predict", "(", "x_test", ")", "\n", "print", "(", "'Test data\\n'", ",", "classification_report", "(", "y_test", ",", "[", "int", "(", "x", ">=", "0.5", ")", "for", "x", "in", "predictions", "]", ",", "digits", "=", "3", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.tfidfsvm.evaluate_baseline": [[9, 37], ["print", "data.read_file", "sklearn.feature_extraction.text.CountVectorizer", "sklearn.feature_extraction.text.TfidfTransformer", "sklearn.svm.SVC", "sklearn.pipeline.Pipeline", "print", "sklearn.pipeline.Pipeline.fit", "sklearn.pipeline.Pipeline.predict", "print", "print", "data.read_file", "sklearn.pipeline.Pipeline.predict", "print", "len", "sklearn.metrics.classification_report", "sklearn.metrics.classification_report"], "function", ["home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.data.read_file", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.predict", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.data.read_file", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.predict"], ["def", "evaluate_baseline", "(", "_set", ")", ":", "\n", "    ", "print", "(", "\"Building baseline for:\"", ",", "_set", ")", "\n", "\n", "train_samples", "=", "read_file", "(", "_set", "+", "\".train\"", ")", "\n", "X", ",", "y", "=", "[", "x", "[", "\"text\"", "]", "for", "x", "in", "train_samples", "]", ",", "[", "x", "[", "\"label\"", "]", "for", "x", "in", "train_samples", "]", "\n", "\n", "bow", "=", "CountVectorizer", "(", "max_features", "=", "3000", ")", "\n", "tfidf", "=", "TfidfTransformer", "(", ")", "\n", "\n", "svm_clf", "=", "SVC", "(", "C", "=", "10", ",", "gamma", "=", "'scale'", ",", "kernel", "=", "'linear'", ")", "\n", "\n", "pipeline", "=", "Pipeline", "(", "[", "(", "'bow'", ",", "bow", ")", ",", "\n", "(", "'tfidf'", ",", "tfidf", ")", ",", "\n", "(", "'clf'", ",", "svm_clf", ")", ",", "]", ")", "\n", "\n", "print", "(", "'\\tTraining on'", ",", "len", "(", "X", ")", ",", "'samples'", ")", "\n", "pipeline", ".", "fit", "(", "X", ",", "y", ")", "\n", "\n", "predictions", "=", "pipeline", ".", "predict", "(", "X", ")", "\n", "print", "(", "'-'", "*", "40", ",", "'\\nTraining data\\n'", ",", "classification_report", "(", "y", ",", "predictions", ",", "digits", "=", "3", ")", ")", "\n", "\n", "# Testing", "\n", "print", "(", "\"Evaluating SVM classifier\"", ")", "\n", "test_samples", "=", "read_file", "(", "_set", "+", "\".test\"", ")", "\n", "X", ",", "y", "=", "[", "x", "[", "\"text\"", "]", "for", "x", "in", "test_samples", "]", ",", "[", "x", "[", "\"label\"", "]", "for", "x", "in", "test_samples", "]", "\n", "\n", "predictions", "=", "pipeline", ".", "predict", "(", "X", ")", "\n", "print", "(", "'Test data\\n'", ",", "classification_report", "(", "y", ",", "predictions", ",", "digits", "=", "3", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.tfidfsvm.main": [[38, 41], ["tfidfsvm.evaluate_baseline"], "function", ["home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.tfidfsvm.evaluate_baseline"], ["", "def", "main", "(", ")", ":", "\n", "    ", "for", "_set", "in", "(", "\"ar\"", ",", "\"gr\"", ",", "\"tr\"", ")", ":", "\n", "        ", "evaluate_baseline", "(", "_set", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.cnn-lstm.initialize_tokenizer": [[17, 27], ["transformers.BertTokenizer.from_pretrained"], "function", ["None"], ["def", "initialize_tokenizer", "(", "_set", ")", ":", "\n", "    ", "global", "tokenizer", "\n", "\n", "if", "_set", "==", "\"tr\"", ":", "\n", "        ", "tokenizer_id", "=", "'dbmdz/bert-base-turkish-cased'", "\n", "", "elif", "_set", "==", "\"gr\"", ":", "\n", "        ", "tokenizer_id", "=", "'nlpaueb/bert-base-greek-uncased-v1'", "\n", "", "elif", "_set", "==", "\"ar\"", ":", "\n", "        ", "tokenizer_id", "=", "'asafaya/bert-base-arabic'", "\n", "", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "tokenizer_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.cnn-lstm.preprocess_text": [[28, 32], ["re.finditer", "identifier.replace", "m.group"], "function", ["None"], ["", "def", "preprocess_text", "(", "identifier", ")", ":", "\n", "# https://stackoverflow.com/a/29920015/5909675", "\n", "    ", "matches", "=", "re", ".", "finditer", "(", "'.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)'", ",", "identifier", ".", "replace", "(", "\"#\"", ",", "\" \"", ")", ")", "\n", "return", "\" \"", ".", "join", "(", "[", "m", ".", "group", "(", "0", ")", "for", "m", "in", "matches", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.cnn-lstm.strip_accents_and_lowercase": [[34, 37], ["unicodedata.normalize", "unicodedata.category"], "function", ["None"], ["", "def", "strip_accents_and_lowercase", "(", "s", ")", ":", "\n", "   ", "return", "''", ".", "join", "(", "c", "for", "c", "in", "unicodedata", ".", "normalize", "(", "'NFD'", ",", "s", ")", "\n", "if", "unicodedata", ".", "category", "(", "c", ")", "!=", "'Mn'", ")", ".", "lower", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.cnn-lstm.prepare_set": [[39, 51], ["torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "input_ids.append", "torch.FloatTensor().unsqueeze.append", "tokenizer.batch_encode_plus", "torch.FloatTensor", "torch.FloatTensor", "cnn-lstm.preprocess_text", "cnn-lstm.strip_accents_and_lowercase", "cnn-lstm.preprocess_text"], "function", ["home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.preprocess_text", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.strip_accents_and_lowercase", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.preprocess_text"], ["", "def", "prepare_set", "(", "dataset", ",", "_set", ",", "max_length", "=", "64", ")", ":", "\n", "    ", "\"\"\"returns input_ids, input_masks, labels for set of data ready in BERT format\"\"\"", "\n", "global", "tokenizer", "\n", "input_ids", ",", "labels", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "dataset", ":", "\n", "        ", "input_ids", ".", "append", "(", "preprocess_text", "(", "i", "[", "\"text\"", "]", ")", "if", "_set", "!=", "\"gr\"", "else", "strip_accents_and_lowercase", "(", "preprocess_text", "(", "i", "[", "\"text\"", "]", ")", ")", ")", "\n", "labels", ".", "append", "(", "1", "if", "i", "[", "\"label\"", "]", "==", "1", "else", "0", ")", "\n", "\n", "", "tokenized", "=", "tokenizer", ".", "batch_encode_plus", "(", "input_ids", ",", "pad_to_max_length", "=", "True", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "max_length", ",", "return_tensors", "=", "\"pt\"", ")", "[", "\"input_ids\"", "]", "\n", "labels", "=", "torch", ".", "FloatTensor", "(", "labels", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "return", "tokenized", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.cnn-lstm.train": [[53, 127], ["data.read_file", "cnn-lstm.prepare_set", "int", "torch.utils.data.TensorDataset", "torch.utils.data.RandomSampler", "torch.utils.data.DataLoader", "torch.utils.data.TensorDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "model.to", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.optim.Adam", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss", "model.zero_grad", "range", "model.load_state_dict", "model.to", "predict.__get__", "os.remove", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "model.parameters", "time.time", "model.train", "len", "model.eval", "len", "sklearn.metrics.f1_score", "torch.load", "torch.load", "len", "tuple", "model", "torch.nn.BCEWithLogitsLoss.", "criterion.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.optim.Adam.step", "criterion.item", "model.zero_grad", "time.time", "torch.no_grad", "torch.no_grad", "int", "torch.save", "torch.save", "model.parameters", "tuple", "model", "torch.nn.BCEWithLogitsLoss.", "criterion.item", "torch.sigmoid().detach().cpu().numpy().flatten", "torch.sigmoid().detach().cpu().numpy().flatten", "list", "model.zero_grad", "model.state_dict", "t.to", "t.to", "torch.sigmoid().detach().cpu().numpy", "torch.sigmoid().detach().cpu().numpy", "torch.sigmoid().detach().cpu", "torch.sigmoid().detach().cpu", "torch.sigmoid().detach", "torch.sigmoid().detach", "torch.sigmoid", "torch.sigmoid"], "function", ["home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.data.read_file", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.prepare_set", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.cnn-lstm.train"], ["", "def", "train", "(", "_set", ",", "model", ")", ":", "\n", "    ", "train_samples", "=", "read_file", "(", "_set", "+", "\".train\"", ")", "\n", "x", ",", "y", "=", "prepare_set", "(", "train_samples", ",", "_set", ",", "max_length", "=", "max_length", ")", "\n", "dev_size", "=", "int", "(", "len", "(", "x", ")", "*", "0.10", ")", "\n", "x_train", ",", "x_dev", ",", "y_train", ",", "y_dev", "=", "x", "[", "dev_size", ":", "]", ",", "x", "[", ":", "dev_size", "]", ",", "y", "[", "dev_size", ":", "]", ",", "y", "[", ":", "dev_size", "]", "\n", "\n", "# Create the DataLoader for training set.", "\n", "train_data", "=", "TensorDataset", "(", "x_train", ",", "y_train", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_data", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "# Create the DataLoader for dev set.", "\n", "dev_data", "=", "TensorDataset", "(", "x_dev", ",", "y_dev", ")", "\n", "dev_sampler", "=", "SequentialSampler", "(", "dev_data", ")", "\n", "dev_dataloader", "=", "DataLoader", "(", "dev_data", ",", "sampler", "=", "dev_sampler", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "model", ".", "to", "(", "device", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "device", ".", "type", "==", "\"cuda\"", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n", "", "optimizer", "=", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "criterion", "=", "torch", ".", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "best_score", "=", "0", "\n", "best_loss", "=", "1e6", "\n", "for", "epoch", "in", "range", "(", "n_epochs", ")", ":", "\n", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "train_loss", "=", "0", "\n", "model", ".", "train", "(", ")", "\n", "\n", "for", "batch", "in", "train_dataloader", ":", "\n", "            ", "b_input_ids", ",", "b_labels", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", ")", "\n", "output", "=", "model", "(", "b_input_ids", ")", "\n", "loss", "=", "criterion", "(", "output", ",", "b_labels", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "1.0", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "train_loss", "/=", "len", "(", "train_dataloader", ")", "\n", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "model", ".", "eval", "(", ")", "\n", "val_preds", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "val_loss", "=", "0", "\n", "for", "batch", "in", "dev_dataloader", ":", "\n", "                ", "b_input_ids", ",", "b_labels", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", ")", "\n", "output", "=", "model", "(", "b_input_ids", ")", "\n", "loss", "=", "criterion", "(", "output", ",", "b_labels", ")", "\n", "val_loss", "+=", "loss", ".", "item", "(", ")", "\n", "preds", "=", "torch", ".", "sigmoid", "(", "output", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "val_preds", "+=", "list", "(", "preds", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "", "val_loss", "/=", "len", "(", "dev_dataloader", ")", "\n", "val_preds", "=", "[", "int", "(", "x", ">=", "0.5", ")", "for", "x", "in", "val_preds", "]", "\n", "val_score", "=", "f1_score", "(", "y_dev", ",", "val_preds", ",", "average", "=", "\"macro\"", ")", "\n", "# print(\"Epoch %d Train loss: %.4f. Validation F1-Score: %.4f  Validation loss: %.4f. Elapsed time: %.2fs.\"% (epoch + 1, train_loss, val_score, val_loss, elapsed))", "\n", "\n", "if", "val_score", ">", "best_score", ":", "\n", "            ", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "model_path", ")", "\n", "# print(classification_report(y_dev, val_preds, digits=3))", "\n", "best_score", "=", "val_score", "\n", "\n", "", "", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "model_path", ")", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "predict", "=", "predict", ".", "__get__", "(", "model", ")", "\n", "os", ".", "remove", "(", "model_path", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.cnn-lstm.predict": [[129, 146], ["torch.utils.data.TensorDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "model.eval", "torch.no_grad", "torch.no_grad", "int", "b_input_ids[].to", "model", "torch.sigmoid().detach().cpu().numpy().flatten", "torch.sigmoid().detach().cpu().numpy().flatten", "list", "model.zero_grad", "torch.sigmoid().detach().cpu().numpy", "torch.sigmoid().detach().cpu().numpy", "torch.sigmoid().detach().cpu", "torch.sigmoid().detach().cpu", "torch.sigmoid().detach", "torch.sigmoid().detach", "torch.sigmoid", "torch.sigmoid"], "function", ["None"], ["", "def", "predict", "(", "model", ",", "x", ")", ":", "\n", "# Create the DataLoader for dev set.", "\n", "\n", "    ", "data", "=", "TensorDataset", "(", "x", ")", "\n", "sampler", "=", "SequentialSampler", "(", "data", ")", "\n", "dataloader", "=", "DataLoader", "(", "data", ",", "sampler", "=", "sampler", ",", "batch_size", "=", "batch_size", ")", "\n", "model", ".", "eval", "(", ")", "\n", "preds", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "b_input_ids", "in", "dataloader", ":", "\n", "            ", "b_input_ids", "=", "b_input_ids", "[", "0", "]", ".", "to", "(", "device", ")", "\n", "output", "=", "model", "(", "b_input_ids", ")", "\n", "probs", "=", "torch", ".", "sigmoid", "(", "output", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "preds", "+=", "list", "(", "probs", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "", "return", "[", "int", "(", "x", ">=", "0.5", ")", "for", "x", "in", "preds", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.cnn-lstm.evaluate": [[148, 165], ["print", "cnn-lstm.initialize_tokenizer", "M", "cnn-lstm.train", "print", "data.read_file", "cnn-lstm.prepare_set", "train.predict", "print", "sklearn.metrics.classification_report"], "function", ["home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.cnn-lstm.initialize_tokenizer", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.cnn-lstm.train", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.data.read_file", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.prepare_set", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.predict"], ["", "def", "evaluate", "(", "_set", ",", "M", ")", ":", "\n", "# Preprocessing", "\n", "    ", "print", "(", "\"Training\"", ",", "M", ",", "\"for:\"", ",", "_set", ")", "\n", "initialize_tokenizer", "(", "_set", ")", "\n", "\n", "model", "=", "M", "(", "embed_size", ",", "tokenizer", ".", "vocab_size", ")", "\n", "model", "=", "train", "(", "_set", ",", "model", ")", "\n", "\n", "# Testing", "\n", "print", "(", "\"Testing\"", ",", "M", ",", "\"for:\"", ",", "_set", ")", "\n", "test_samples", "=", "read_file", "(", "_set", "+", "\".test\"", ")", "\n", "x", ",", "_", "=", "prepare_set", "(", "test_samples", ",", "_set", ",", "max_length", "=", "max_length", ")", "\n", "y_test", "=", "[", "x", "[", "\"label\"", "]", "for", "x", "in", "test_samples", "]", "\n", "predictions", "=", "model", ".", "predict", "(", "x", ")", "\n", "print", "(", "'Test data\\n'", ",", "classification_report", "(", "y_test", ",", "predictions", ",", "digits", "=", "3", ")", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.data.parse_line": [[5, 8], ["line.split.split", "int"], "function", ["None"], ["def", "parse_line", "(", "line", ")", ":", "\n", "    ", "line", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "return", "line", "[", "0", "]", ",", "line", "[", "1", "]", ",", "int", "(", "line", "[", "2", "]", "==", "\"OFF\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.data.read_file": [[9, 15], ["open", "fi.read().splitlines", "zip", "zip", "fi.read", "list", "map", "data.parse_line"], "function", ["home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.data.parse_line"], ["", "def", "read_file", "(", "_set", ")", ":", "\n", "    ", "with", "open", "(", "\"OffensEval/\"", "+", "_set", "+", "\".tsv\"", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fi", ":", "\n", "        ", "lines", "=", "fi", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "ids", ",", "x_train", ",", "y_train", "=", "zip", "(", "*", "list", "(", "map", "(", "lambda", "x", ":", "parse_line", "(", "x", ")", ",", "lines", "[", "1", ":", "]", ")", ")", ")", "\n", "\n", "", "return", "[", "{", "\"id\"", ":", "i", ",", "\"text\"", ":", "x", ",", "\"label\"", ":", "y", "}", "for", "i", ",", "x", ",", "y", "in", "zip", "(", "ids", ",", "x_train", ",", "y_train", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.data.fold_iterator_sklearn": [[16, 29], ["random.seed", "random.shuffle", "numpy.array", "sklearn.model_selection.StratifiedKFold", "sklearn.model_selection.StratifiedKFold.get_n_splits", "sklearn.model_selection.StratifiedKFold.split", "sklearn.model_selection.train_test_split"], "function", ["None"], ["", "def", "fold_iterator_sklearn", "(", "all_samples", ",", "K", "=", "10", ",", "dev_ratio", "=", "0.10", ",", "random_seed", "=", "1234", ")", ":", "\n", "    ", "\"\"\"yields K tuples of shape (train, dev, test) \"\"\"", "\n", "random", ".", "seed", "(", "random_seed", ")", "\n", "random", ".", "shuffle", "(", "all_samples", ")", "# initial shuffle", "\n", "_all", "=", "np", ".", "array", "(", "all_samples", ")", "# convert to numpy for list indexing", "\n", "\n", "skf", "=", "StratifiedKFold", "(", "n_splits", "=", "K", ")", "\n", "skf", ".", "get_n_splits", "(", "_all", ",", "[", "y", "[", "\"label\"", "]", "for", "y", "in", "_all", "]", ")", "\n", "\n", "for", "train_index", ",", "test_index", "in", "skf", ".", "split", "(", "_all", ",", "[", "y", "[", "\"label\"", "]", "for", "y", "in", "_all", "]", ")", ":", "\n", "        ", "trn", ",", "dev", "=", "train_test_split", "(", "_all", "[", "train_index", "]", ",", "test_size", "=", "dev_ratio", ",", "random_state", "=", "random_seed", ")", "\n", "yield", "(", "trn", ",", "dev", ",", "_all", "[", "test_index", "]", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.preprocess_text": [[40, 44], ["re.finditer", "identifier.replace", "m.group"], "function", ["None"], ["", "def", "preprocess_text", "(", "identifier", ")", ":", "\n", "# https://stackoverflow.com/a/29920015/5909675", "\n", "    ", "matches", "=", "re", ".", "finditer", "(", "'.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)'", ",", "identifier", ".", "replace", "(", "\"#\"", ",", "\" \"", ")", ")", "\n", "return", "\" \"", ".", "join", "(", "[", "m", ".", "group", "(", "0", ")", "for", "m", "in", "matches", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.strip_accents_and_lowercase": [[45, 48], ["unicodedata.normalize", "unicodedata.category"], "function", ["None"], ["", "def", "strip_accents_and_lowercase", "(", "s", ")", ":", "\n", "   ", "return", "''", ".", "join", "(", "c", "for", "c", "in", "unicodedata", ".", "normalize", "(", "'NFD'", ",", "s", ")", "\n", "if", "unicodedata", ".", "category", "(", "c", ")", "!=", "'Mn'", ")", ".", "lower", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.prepare_set": [[49, 61], ["tokenizer.batch_encode_plus", "bert-cnn.preprocess_text", "bert-cnn.strip_accents_and_lowercase", "bert-cnn.preprocess_text"], "function", ["home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.preprocess_text", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.strip_accents_and_lowercase", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.preprocess_text"], ["", "def", "prepare_set", "(", "text", ",", "max_length", "=", "64", ")", ":", "\n", "    ", "\"\"\"returns input_ids, attention_mask, token_type_ids for set of data ready in BERT format\"\"\"", "\n", "global", "tokenizer", "\n", "\n", "text", "=", "[", "preprocess_text", "(", "t", ")", "if", "set_id", "!=", "\"gr\"", "else", "strip_accents_and_lowercase", "(", "preprocess_text", "(", "t", ")", ")", "for", "t", "in", "text", "]", "\n", "t", "=", "tokenizer", ".", "batch_encode_plus", "(", "text", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "add_special_tokens", "=", "True", ",", "\n", "max_length", "=", "max_length", ",", "\n", "return_tensors", "=", "'pt'", ")", "\n", "\n", "return", "t", "[", "\"input_ids\"", "]", ",", "t", "[", "\"attention_mask\"", "]", ",", "t", "[", "\"token_type_ids\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.predict": [[62, 77], ["bert-cnn.prepare_set", "torch.utils.data.TensorDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "model.eval", "torch.no_grad", "torch.no_grad", "tuple", "model", "list", "model.cpu().numpy().flatten", "t.to", "model.cpu().numpy", "model.cpu"], "function", ["home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.prepare_set"], ["", "def", "predict", "(", "model", ",", "test_set", ",", "batch_size", "=", "batch_size", ")", ":", "\n", "    ", "test_inputs", ",", "test_masks", ",", "test_type_ids", "=", "prepare_set", "(", "test_set", ")", "\n", "test_data", "=", "TensorDataset", "(", "test_inputs", ",", "test_masks", ",", "test_type_ids", ")", "\n", "test_sampler", "=", "SequentialSampler", "(", "test_data", ")", "\n", "test_dataloader", "=", "DataLoader", "(", "test_data", ",", "sampler", "=", "test_sampler", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "preds", "=", "[", "]", "\n", "for", "batch", "in", "test_dataloader", ":", "\n", "            ", "b_input_ids", ",", "b_input_mask", ",", "b_token_type_ids", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", ")", "\n", "y_pred", "=", "model", "(", "b_input_ids", ",", "b_input_mask", ",", "b_token_type_ids", ")", "\n", "preds", "+=", "list", "(", "y_pred", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", ")", "\n", "\n", "", "", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.train_bert_cnn": [[78, 164], ["BertModel.from_pretrained", "print", "bert-cnn.prepare_set", "torch.utils.data.TensorDataset", "torch.utils.data.RandomSampler", "torch.utils.data.DataLoader", "bert-cnn.prepare_set", "torch.utils.data.TensorDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "models.CNNBert", "nn.DataParallel.to", "AdamW", "torch.nn.BCELoss", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "get_linear_schedule_with_warmup", "nn.DataParallel.zero_grad", "range", "nn.DataParallel.load_state_dict", "nn.DataParallel.to", "predict.__get__", "nn.DataParallel.eval", "os.remove", "torch.FloatTensor", "torch.FloatTensor", "torch.nn.DataParallel", "nn.DataParallel.parameters", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "len", "time.time", "nn.DataParallel.train", "train_losses.append", "nn.DataParallel.eval", "sklearn.metrics.f1_score", "val_losses.append", "print", "torch.load", "torch.load", "len", "len", "tuple", "nn.DataParallel.", "nn.BCELoss.", "loss_fn.backward", "AdamW.step", "loss_fn.item", "get_linear_schedule_with_warmup.step", "nn.DataParallel.zero_grad", "time.time", "torch.no_grad", "torch.no_grad", "y_dev.cpu().numpy().tolist", "torch.save", "torch.save", "print", "b_labels.unsqueeze", "tuple", "nn.DataParallel.", "nn.BCELoss.", "loss_fn.item", "y_pred.cpu().numpy().flatten.cpu().numpy().flatten", "nn.DataParallel.zero_grad", "nn.DataParallel.state_dict", "sklearn.metrics.classification_report", "t.to", "b_labels.unsqueeze", "int", "y_dev.cpu().numpy", "y_dev.cpu().numpy().tolist", "t.to", "y_pred.cpu().numpy().flatten.cpu().numpy", "y_dev.cpu", "y_dev.cpu().numpy", "y_pred.cpu().numpy().flatten.cpu", "y_dev.cpu"], "function", ["home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.prepare_set", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.prepare_set", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.cnn-lstm.train"], ["", "def", "train_bert_cnn", "(", "x_train", ",", "x_dev", ",", "y_train", ",", "y_dev", ",", "pretrained_model", ",", "n_epochs", "=", "10", ",", "model_path", "=", "\"temp.pt\"", ",", "batch_size", "=", "batch_size", ")", ":", "\n", "    ", "bert_model", "=", "BertModel", ".", "from_pretrained", "(", "pretrained_model", ",", "output_hidden_states", "=", "True", ")", "\n", "\n", "print", "(", "[", "len", "(", "x", ")", "for", "x", "in", "(", "y_train", ",", "y_dev", ")", "]", ")", "\n", "y_train", ",", "y_dev", "=", "(", "torch", ".", "FloatTensor", "(", "t", ")", "for", "t", "in", "(", "y_train", ",", "y_dev", ")", ")", "\n", "\n", "train_inputs", ",", "train_masks", ",", "train_type_ids", "=", "prepare_set", "(", "x_train", ",", "max_length", "=", "max_length", ")", "\n", "train_data", "=", "TensorDataset", "(", "train_inputs", ",", "train_masks", ",", "train_type_ids", ",", "y_train", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_data", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "# Create the DataLoader for our dev set.", "\n", "dev_inputs", ",", "dev_masks", ",", "dev_type_ids", "=", "prepare_set", "(", "x_dev", ",", "max_length", "=", "max_length", ")", "\n", "dev_data", "=", "TensorDataset", "(", "dev_inputs", ",", "dev_masks", ",", "dev_type_ids", ",", "y_dev", ")", "\n", "dev_sampler", "=", "SequentialSampler", "(", "dev_data", ")", "\n", "dev_dataloader", "=", "DataLoader", "(", "dev_data", ",", "sampler", "=", "dev_sampler", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "model", "=", "CNNBert", "(", "768", ",", "bert_model", ")", "\n", "if", "len", "(", "device_ids", ")", ">", "1", "and", "device", ".", "type", "==", "\"cuda\"", ":", "\n", "        ", "model", "=", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "device_ids", ")", "\n", "", "model", ".", "to", "(", "device", ")", "\n", "\n", "optimizer", "=", "AdamW", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "weight_decay", "=", "0.9", ")", "\n", "loss_fn", "=", "nn", ".", "BCELoss", "(", ")", "\n", "train_losses", ",", "val_losses", "=", "[", "]", ",", "[", "]", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "device", ".", "type", "==", "\"cuda\"", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n", "", "total_steps", "=", "len", "(", "train_dataloader", ")", "*", "n_epochs", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "\n", "num_warmup_steps", "=", "0", ",", "\n", "num_training_steps", "=", "total_steps", ")", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "best_score", "=", "0", "\n", "best_loss", "=", "1e6", "\n", "\n", "for", "epoch", "in", "range", "(", "n_epochs", ")", ":", "\n", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "train_loss", "=", "0", "\n", "model", ".", "train", "(", "True", ")", "\n", "\n", "for", "batch", "in", "train_dataloader", ":", "\n", "            ", "b_input_ids", ",", "b_input_mask", ",", "b_token_type_ids", ",", "b_labels", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", ")", "\n", "y_pred", "=", "model", "(", "b_input_ids", ",", "b_input_mask", ",", "b_token_type_ids", ")", "\n", "loss", "=", "loss_fn", "(", "y_pred", ",", "b_labels", ".", "unsqueeze", "(", "1", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "train_losses", ".", "append", "(", "train_loss", ")", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "model", ".", "eval", "(", ")", "\n", "val_preds", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "val_loss", "=", "0", "\n", "for", "batch", "in", "dev_dataloader", ":", "\n", "                ", "b_input_ids", ",", "b_input_mask", ",", "b_token_type_ids", ",", "b_labels", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", ")", "\n", "y_pred", "=", "model", "(", "b_input_ids", ",", "b_input_mask", ",", "b_token_type_ids", ")", "\n", "loss", "=", "loss_fn", "(", "y_pred", ",", "b_labels", ".", "unsqueeze", "(", "1", ")", ")", "\n", "val_loss", "+=", "loss", ".", "item", "(", ")", "\n", "y_pred", "=", "y_pred", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "val_preds", "+=", "[", "int", "(", "p", ">=", "0.5", ")", "for", "p", "in", "y_pred", "]", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "", "val_score", "=", "f1_score", "(", "y_dev", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ",", "val_preds", ")", "\n", "val_losses", ".", "append", "(", "val_loss", ")", "\n", "print", "(", "\"Epoch %d Train loss: %.4f. Validation F1-Macro: %.4f  Validation loss: %.4f. Elapsed time: %.2fs.\"", "%", "(", "epoch", "+", "1", ",", "train_losses", "[", "-", "1", "]", ",", "val_score", ",", "val_losses", "[", "-", "1", "]", ",", "elapsed", ")", ")", "\n", "\n", "if", "val_score", ">", "best_score", ":", "\n", "            ", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "\"temp.pt\"", ")", "\n", "print", "(", "classification_report", "(", "y_dev", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ",", "val_preds", ",", "digits", "=", "4", ")", ")", "\n", "best_score", "=", "val_score", "\n", "\n", "", "", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\"temp.pt\"", ")", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "predict", "=", "predict", ".", "__get__", "(", "model", ")", "\n", "model", ".", "eval", "(", ")", "\n", "os", ".", "remove", "(", "\"temp.pt\"", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.evaluate": [[165, 177], ["data.read_file", "int", "bert-cnn.train_bert_cnn", "data.read_file", "train_bert_cnn.predict", "print", "sklearn.metrics.classification_report", "len", "int"], "function", ["home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.data.read_file", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.train_bert_cnn", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.data.read_file", "home.repos.pwc.inspect_result.alisafaya_OffensEval2020.None.bert-cnn.predict"], ["", "def", "evaluate", "(", ")", ":", "\n", "    ", "train_samples", "=", "read_file", "(", "set_id", "+", "\".train\"", ")", "\n", "x", ",", "y", "=", "[", "x", "[", "\"text\"", "]", "for", "x", "in", "train_samples", "]", ",", "[", "x", "[", "\"label\"", "]", "for", "x", "in", "train_samples", "]", "\n", "dev_size", "=", "int", "(", "len", "(", "x", ")", "*", "0.10", ")", "\n", "x_train", ",", "x_dev", ",", "y_train", ",", "y_dev", "=", "x", "[", "dev_size", ":", "]", ",", "x", "[", ":", "dev_size", "]", ",", "y", "[", "dev_size", ":", "]", ",", "y", "[", ":", "dev_size", "]", "\n", "model", "=", "train_bert_cnn", "(", "x_train", ",", "x_dev", ",", "y_train", ",", "y_dev", ",", "pretrained_model", ",", "n_epochs", "=", "6", ")", "\n", "\n", "# Testing", "\n", "test_samples", "=", "read_file", "(", "set_id", "+", "\".test\"", ")", "\n", "x_test", ",", "y_test", "=", "[", "x", "[", "\"text\"", "]", "for", "x", "in", "test_samples", "]", ",", "[", "x", "[", "\"label\"", "]", "for", "x", "in", "test_samples", "]", "\n", "predictions", "=", "model", ".", "predict", "(", "x_test", ")", "\n", "print", "(", "'Test data\\n'", ",", "classification_report", "(", "y_test", ",", "[", "int", "(", "x", ">=", "0.5", ")", "for", "x", "in", "predictions", "]", ",", "digits", "=", "3", ")", ")", "\n", "\n"]]}