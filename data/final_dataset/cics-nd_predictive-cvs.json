{"home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.ARDprior.__init__": [[40, 46], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "a0", ",", "paramlist", ",", "model", ",", "gpu", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "paramlist", "=", "paramlist", "\n", "self", ".", "a0", "=", "a0", "\n", "self", ".", "b0", "=", "a0", "\n", "self", ".", "gpu", "=", "gpu", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.ARDprior.getlogpiorARD": [[47, 69], ["torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "par.pow", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like.fill_", "torch.zeros_like.fill_", "torch.zeros_like.fill_", "torch.zeros_like.fill_", "torch.zeros_like.div", "torch.zeros_like.div", "torch.zeros_like.div", "torch.zeros_like.div", "torch.zeros_like.div.mul", "nominator.div.mul.mul_", "nominator.div.mul.sum", "torch.autograd.Variable.add_", "torch.autograd.Variable.add_", "torch.autograd.Variable.add_", "torch.autograd.Variable.add_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "par.pow.mul", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "getlogpiorARD", "(", "self", ")", ":", "\n", "        ", "i", "=", "0", "\n", "if", "self", ".", "gpu", ":", "\n", "            ", "totalsumlogptheta", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "zeros", "(", "1", ")", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "totalsumlogptheta", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "zeros", "(", "1", ")", ")", "\n", "\n", "", "for", "paramitem", "in", "self", ".", "paramlist", ":", "\n", "            ", "par", "=", "paramitem", "[", "'params'", "]", "\n", "\n", "psqu", "=", "par", ".", "pow", "(", "2.", ")", "\n", "denominator", "=", "psqu", ".", "mul", "(", "0.5", ")", "+", "self", ".", "b0", "\n", "nominator", "=", "torch", ".", "zeros_like", "(", "denominator", ")", "\n", "nominator", ".", "fill_", "(", "self", ".", "a0", "+", "0.5", ")", "\n", "expectau", "=", "nominator", ".", "div", "(", "denominator", ")", "\n", "logptheta", "=", "expectau", ".", "mul", "(", "psqu", ")", "\n", "logptheta", ".", "mul_", "(", "-", "0.5", ")", "\n", "sumlogptheta", "=", "logptheta", ".", "sum", "(", ")", "\n", "\n", "totalsumlogptheta", ".", "add_", "(", "sumlogptheta", ")", "\n", "\n", "", "return", "totalsumlogptheta", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.PseudoGibbs.__init__": [[77, 85], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "x_init", ",", "z_init", ",", "model", ")", ":", "\n", "        ", "self", ".", "x_init", "=", "x_init", "\n", "self", ".", "z_init", "=", "z_init", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "bgetlogvar", "=", "True", "\n", "\n", "self", ".", "n_skip", "=", "10", "\n", "self", ".", "n_init", "=", "5000", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.PseudoGibbs.sampleposterior": [[86, 92], ["VAE_up.PseudoGibbs.model.encode", "logvar.mul().exp_", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal.sample", "torch.distributions.Normal.sample", "torch.distributions.Normal.sample", "torch.distributions.Normal.sample", "logvar.mul"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.encode", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample"], ["", "def", "sampleposterior", "(", "self", ",", "x", ")", ":", "\n", "        ", "mu", ",", "logvar", "=", "self", ".", "model", ".", "encode", "(", "x", ")", "\n", "std", "=", "logvar", ".", "mul", "(", "0.5", ")", ".", "exp_", "(", ")", "\n", "post", "=", "torch", ".", "distributions", ".", "Normal", "(", "mu", ",", "std", ")", "\n", "sample", "=", "post", ".", "sample", "(", ")", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.PseudoGibbs.samplepredictive": [[93, 105], ["VAE_up.PseudoGibbs.model.decode", "logvar.mul().exp_", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal.sample", "torch.distributions.Normal.sample", "torch.distributions.Normal.sample", "torch.distributions.Normal.sample", "VAE_up.PseudoGibbs.model.encode", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal.sample", "torch.distributions.Normal.sample", "torch.distributions.Normal.sample", "torch.distributions.Normal.sample", "logvar.exp_", "logvar.mul"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.decode", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.encode", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample"], ["", "def", "samplepredictive", "(", "self", ",", "z", ")", ":", "\n", "        ", "self", ".", "model", ".", "bgetlogvar", "=", "True", "\n", "mu", ",", "logvar", "=", "self", ".", "model", ".", "decode", "(", "z", ")", "\n", "std", "=", "logvar", ".", "mul", "(", "0.5", ")", ".", "exp_", "(", ")", "\n", "pred", "=", "torch", ".", "distributions", ".", "Normal", "(", "mu", ",", "std", ")", "\n", "x", "=", "pred", ".", "sample", "(", ")", "\n", "return", "x", "\n", "\n", "mu", ",", "logvar", "=", "self", ".", "model", ".", "encode", "(", "x", ")", "\n", "post", "=", "torch", ".", "distributions", ".", "Normal", "(", "mu", ",", "logvar", ".", "exp_", "(", ")", ")", "\n", "sample", "=", "post", ".", "sample", "(", ")", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.PseudoGibbs.evallogprobposterior": [[106, 112], ["VAE_up.PseudoGibbs.model.encode", "logvar.mul().exp_", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal.log_prob().sum", "torch.distributions.Normal.log_prob().sum", "torch.distributions.Normal.log_prob().sum", "torch.distributions.Normal.log_prob().sum", "logvar.mul", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.encode"], ["", "def", "evallogprobposterior", "(", "self", ",", "x", ",", "z", ")", ":", "\n", "        ", "mu", ",", "logvar", "=", "self", ".", "model", ".", "encode", "(", "x", ")", "\n", "std", "=", "logvar", ".", "mul", "(", "0.5", ")", ".", "exp_", "(", ")", "\n", "post", "=", "torch", ".", "distributions", ".", "Normal", "(", "mu", ",", "std", ")", "\n", "logprob", "=", "post", ".", "log_prob", "(", "z", ")", ".", "sum", "(", ")", "\n", "return", "logprob", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.PseudoGibbs.evallogprobcondpred": [[113, 120], ["VAE_up.PseudoGibbs.model.decode", "logvar.mul().exp_", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal.log_prob().sum", "torch.distributions.Normal.log_prob().sum", "torch.distributions.Normal.log_prob().sum", "torch.distributions.Normal.log_prob().sum", "logvar.mul", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.decode"], ["", "def", "evallogprobcondpred", "(", "self", ",", "x", ",", "z", ")", ":", "\n", "        ", "self", ".", "model", ".", "bgetlogvar", "=", "True", "\n", "mu", ",", "logvar", "=", "self", ".", "model", ".", "decode", "(", "z", ")", "\n", "std", "=", "logvar", ".", "mul", "(", "0.5", ")", ".", "exp_", "(", ")", "\n", "post", "=", "torch", ".", "distributions", ".", "Normal", "(", "mu", ",", "std", ")", "\n", "logprob", "=", "post", ".", "log_prob", "(", "x", ")", ".", "sum", "(", ")", "\n", "return", "logprob", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.PseudoGibbs.evallogprobprior": [[121, 127], ["torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal.log_prob().sum", "torch.distributions.Normal.log_prob().sum", "torch.distributions.Normal.log_prob().sum", "torch.distributions.Normal.log_prob().sum", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob"], "methods", ["None"], ["", "def", "evallogprobprior", "(", "self", ",", "z", ")", ":", "\n", "        ", "mu", "=", "torch", ".", "zeros_like", "(", "z", ")", "\n", "scale", "=", "torch", ".", "ones_like", "(", "z", ")", "\n", "prior", "=", "torch", ".", "distributions", ".", "Normal", "(", "mu", ",", "scale", ")", "\n", "logprob", "=", "prior", ".", "log_prob", "(", "z", ")", ".", "sum", "(", ")", "\n", "return", "logprob", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.PseudoGibbs.calcacceptanceratio": [[128, 146], ["VAE_up.PseudoGibbs.evallogprobcondpred", "VAE_up.PseudoGibbs.evallogprobcondpred", "VAE_up.PseudoGibbs.evallogprobprior", "VAE_up.PseudoGibbs.evallogprobprior", "VAE_up.PseudoGibbs.evallogprobposterior", "VAE_up.PseudoGibbs.evallogprobposterior", "logroh.exp"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.PseudoGibbs.evallogprobcondpred", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.PseudoGibbs.evallogprobcondpred", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.PseudoGibbs.evallogprobprior", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.PseudoGibbs.evallogprobprior", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.PseudoGibbs.evallogprobposterior", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.PseudoGibbs.evallogprobposterior"], ["", "def", "calcacceptanceratio", "(", "self", ",", "ztm1", ",", "ztprop", ",", "xtm1", ")", ":", "\n", "\n", "        ", "p_xtm1_given_ztprop", "=", "self", ".", "evallogprobcondpred", "(", "xtm1", ",", "ztprop", ")", "\n", "p_xtm1_given_ztm1", "=", "self", ".", "evallogprobcondpred", "(", "xtm1", ",", "ztm1", ")", "\n", "\n", "p_ztprop", "=", "self", ".", "evallogprobprior", "(", "ztprop", ")", "\n", "p_ztm1", "=", "self", ".", "evallogprobprior", "(", "ztm1", ")", "\n", "\n", "q_ztm1_given_xtm1", "=", "self", ".", "evallogprobposterior", "(", "xtm1", ",", "ztm1", ")", "\n", "q_ztprop_given_xtm1", "=", "self", ".", "evallogprobposterior", "(", "xtm1", ",", "ztprop", ")", "\n", "\n", "ratio_pxgz", "=", "p_xtm1_given_ztprop", "-", "p_xtm1_given_ztm1", "\n", "ratio_pz", "=", "p_ztprop", "-", "p_ztm1", "\n", "ratio_qzgx", "=", "q_ztm1_given_xtm1", "-", "q_ztprop_given_xtm1", "\n", "\n", "logroh", "=", "ratio_pxgz", "+", "ratio_pz", "+", "ratio_qzgx", "\n", "\n", "return", "logroh", ".", "exp", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.PseudoGibbs.getboolofvariable": [[147, 150], ["bool"], "methods", ["None"], ["", "def", "getboolofvariable", "(", "self", ",", "bytetensor", ")", ":", "\n", "        ", "res", "=", "bool", "(", "bytetensor", "[", "0", "]", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.PseudoGibbs.sample": [[151, 190], ["range", "print", "VAE_up.PseudoGibbs.sampleposterior", "VAE_up.PseudoGibbs.calcacceptanceratio", "VAE_up.PseudoGibbs.samplepredictive", "float", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.PseudoGibbs.sampleposterior", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.PseudoGibbs.calcacceptanceratio", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.PseudoGibbs.samplepredictive"], ["", "def", "sample", "(", "self", ",", "N", ")", ":", "\n", "\n", "        ", "n_tot", "=", "self", ".", "n_init", "+", "N", "*", "self", ".", "n_skip", "\n", "n_accepted", "=", "0", "\n", "\n", "xtm1", "=", "self", ".", "x_init", "\n", "ztm1", "=", "self", ".", "z_init", "\n", "\n", "x_samples", "=", "xtm1", "\n", "\n", "for", "i", "in", "range", "(", "n_tot", ")", ":", "\n", "            ", "ztprop", "=", "self", ".", "sampleposterior", "(", "xtm1", ")", "\n", "rhot", "=", "self", ".", "calcacceptanceratio", "(", "ztm1", ",", "ztprop", ",", "xtm1", ")", "\n", "rhottensor", "=", "rhot", ".", "data", "[", "0", "]", "\n", "\n", "if", "rhottensor", ">", "1.", ":", "\n", "                ", "zt", "=", "ztprop", "\n", "n_accepted", "+=", "1", "\n", "", "else", ":", "\n", "                ", "r", "=", "torch", ".", "rand", "(", "1", ")", "\n", "if", "rhottensor", ">", "r", "[", "0", "]", ":", "\n", "                    ", "zt", "=", "ztprop", "\n", "n_accepted", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "zt", "=", "ztm1", "\n", "\n", "", "", "xt", "=", "self", ".", "samplepredictive", "(", "zt", ")", "\n", "\n", "s", "=", "i", "-", "self", ".", "n_init", "\n", "if", "s", ">", "1", "and", "s", "%", "self", ".", "n_skip", "==", "0", ":", "\n", "                ", "x_samples", "=", "torch", ".", "cat", "(", "(", "x_samples", ",", "xt", ")", ",", "0", ")", "\n", "\n", "", "ztm1", "=", "zt", "\n", "xtm1", "=", "xt", "\n", "\n", "", "accept_ratio", "=", "n_accepted", "/", "float", "(", "n_tot", ")", "\n", "print", "(", "accept_ratio", ")", "\n", "\n", "return", "x_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.__init__": [[195, 198], ["mean.copy", "cov.copy"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mean", ",", "cov", ")", ":", "\n", "        ", "self", ".", "mean", "=", "mean", ".", "copy", "(", ")", "\n", "self", ".", "cov", "=", "cov", ".", "copy", "(", ")", "\n", "", "def", "sample", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample": [[198, 200], ["numpy.random.multivariate_normal"], "methods", ["None"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "random", ".", "multivariate_normal", "(", "self", ".", "mean", ",", "self", ".", "cov", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.UQ.__init__": [[205, 211], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "bdouq", "=", "False", ",", "bcalchess", "=", "False", ",", "blayercov", "=", "False", ",", "buqbias", "=", "False", ")", ":", "\n", "        ", "self", ".", "bdouq", "=", "bdouq", "\n", "self", ".", "npostsamples", "=", "100", "\n", "self", ".", "bhessavailable", "=", "bcalchess", "\n", "self", ".", "blayercov", "=", "blayercov", "\n", "self", ".", "buqbias", "=", "buqbias", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.TensorDatasetDataOnly.__init__": [[245, 247], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_tensor", ")", ":", "\n", "        ", "self", ".", "data_tensor", "=", "data_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.TensorDatasetDataOnly.__getitem__": [[248, 250], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "data_tensor", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.TensorDatasetDataOnly.__len__": [[251, 253], ["VAE_up.TensorDatasetDataOnly.data_tensor.size"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "data_tensor", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.__init__": [[255, 376], ["bool", "bool", "bool", "bool", "VAE_up.UQ", "bool", "bool", "VAE_up.VAEpeptide.selectdataset", "os.getcwd", "os.path.join", "VAE_up.checkandcreatefolder", "VAEmod", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "bool", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "print", "quit", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "bool", "str", "VAE_up.VAEpeptide.vaemodel.cuda", "VAE_up.VAEpeptide.vaemodel.parameters", "VAE_up.ARDprior", "bool", "print", "quit", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "VAE_up.VAEpeptide.getdecweightlist", "str", "print", "quit", "print", "quit", "str"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.selectdataset", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.checkandcreatefolder", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.getdecweightlist"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "'''Initialize the VAE object.\n        :param args: Arguments containing settings.\n        '''", "\n", "\n", "# parameters", "\n", "self", ".", "epoch", "=", "args", ".", "epoch", "\n", "self", ".", "sample_num", "=", "64", "\n", "self", ".", "batch_size", "=", "args", ".", "batch_size", "\n", "self", ".", "save_dir", "=", "args", ".", "save_dir", "\n", "self", ".", "result_dir", "=", "args", ".", "result_dir", "\n", "self", ".", "dataset", "=", "args", ".", "dataset", "\n", "self", ".", "log_dir", "=", "args", ".", "log_dir", "\n", "self", ".", "gpu_mode", "=", "bool", "(", "args", ".", "gpu_mode", ")", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "\n", "self", ".", "model_name", "=", "args", ".", "mod_type", "\n", "self", ".", "c", "=", "args", ".", "clipping", "# clipping value", "\n", "self", ".", "n_critic", "=", "args", ".", "n_critic", "# the number of iterations of the critic per generator iteration", "\n", "self", ".", "z_dim", "=", "args", ".", "z_dim", "\n", "self", ".", "n_samples", "=", "args", ".", "samples_pred", "\n", "self", ".", "bClusterND", "=", "bool", "(", "args", ".", "clusterND", ")", "\n", "self", ".", "output_postfix", "=", "args", ".", "outPostFix", "\n", "self", ".", "angulardata", "=", "args", ".", "useangulardat", "\n", "self", ".", "autoencvarbayes", "=", "bool", "(", "args", ".", "AEVB", ")", "\n", "self", ".", "L", "=", "args", ".", "L", "# amount of eps ~ p(eps) = N(0,1)", "\n", "self", ".", "n_samples_per_mu", "=", "args", ".", "samples_per_mean", "# if 0, just use mean prediction: x = mu(z)", "\n", "self", ".", "lambdaexpprior", "=", "args", ".", "exppriorvar", "\n", "\n", "# Employ Metropolis-within-Gibbs Sampler", "\n", "self", ".", "exactlikeli", "=", "bool", "(", "args", ".", "exactlikeli", ")", "\n", "\n", "# perform UQ", "\n", "bqu", "=", "bool", "(", "args", ".", "npostS", ")", "\n", "self", ".", "uqoptions", "=", "UQ", "(", "bdouq", "=", "bqu", ",", "bcalchess", "=", "True", ",", "blayercov", "=", "False", ",", "buqbias", "=", "bool", "(", "args", ".", "uqbias", ")", ")", "\n", "self", ".", "uqoptions", ".", "npostsamples", "=", "args", ".", "npostS", "\n", "# \\sigma_\\theta depending on z or not. If not, optimized as parameter", "\n", "self", ".", "bfixlogvar", "=", "bool", "(", "args", ".", "sharedlogvar", ")", "\n", "\n", "# Check if a trained model should be loaded", "\n", "self", ".", "filemodel", "=", "args", ".", "loadtrainedmodel", "\n", "self", ".", "bloadmodel", "=", "bool", "(", "self", ".", "filemodel", ")", "\n", "\n", "# Visualize training process?", "\n", "self", ".", "bvislatent_training", "=", "True", "\n", "self", ".", "bvismean_and_samples", "=", "False", "\n", "\n", "# ARD prior", "\n", "if", "args", ".", "ard", ">", "0.", ":", "\n", "            ", "self", ".", "bard", "=", "True", "\n", "self", ".", "arda0", "=", "args", ".", "ard", "\n", "", "else", ":", "\n", "            ", "self", ".", "bard", "=", "False", "\n", "self", ".", "arda0", "=", "0.", "\n", "\n", "# We can only sample if p(x|z) is defined like in Autoencoding Var. Bayes.", "\n", "", "if", "not", "self", ".", "autoencvarbayes", ":", "\n", "            ", "self", ".", "n_samples_per_mu", "=", "0", "\n", "\n", "# Specify input data for e.g. angular. This is not scope of the work **paper_link** and therefore not content of the code.", "\n", "", "if", "False", ":", "\n", "            ", "self", ".", "x_dim", "=", "(", "22", "-", "1", ")", "*", "3", "\n", "print", "(", "'Error: Model for %s not implemented yet.'", "%", "self", ".", "angulardata", ")", "\n", "quit", "(", ")", "\n", "", "elif", "self", ".", "angulardata", "==", "'ang_augmented'", ":", "\n", "            ", "self", ".", "x_dim", "=", "(", "22", "-", "1", ")", "*", "5", "\n", "print", "(", "'Error: Model for %s not implemented yet.'", "%", "self", ".", "angulardata", ")", "\n", "quit", "(", ")", "\n", "", "elif", "self", ".", "angulardata", "==", "'ang_auggrouped'", ":", "\n", "            ", "self", ".", "x_dim", "=", "(", "22", "-", "1", ")", "*", "5", "\n", "\n", "if", "self", ".", "autoencvarbayes", ":", "\n", "                ", "from", "VAEmodel", "import", "VAEmodauggrouped", "as", "VAEmod", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Not covered in **paper**.'", ")", "\n", "quit", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "'ala_15'", "in", "self", ".", "dataset", ":", "\n", "                ", "self", ".", "x_dim", "=", "162", "*", "3", "\n", "", "else", ":", "\n", "                ", "self", ".", "x_dim", "=", "66", "\n", "", "if", "self", ".", "autoencvarbayes", ":", "\n", "                ", "from", "VAEmodel", "import", "VAEmod", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Not covered in **paper**.'", ")", "\n", "quit", "(", ")", "\n", "\n", "# seed the calculation for testing", "\n", "", "", "if", "not", "args", ".", "seed", "==", "0", ":", "\n", "            ", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "bool", "(", "args", ".", "gpu_mode", ")", ":", "\n", "                ", "torch", ".", "cuda", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "\n", "# pre-sepcify foldername variable for dataset", "\n", "", "", "foldername", "=", "self", ".", "dataset", "\n", "predictprefix", "=", "''", "\n", "\n", "# Select dataset", "\n", "self", ".", "selectdataset", "(", ")", "\n", "\n", "# Specify as model_name the general kind of dataset: mixed or separate", "\n", "self", ".", "postfix_setting", "=", "self", ".", "dataset", "+", "'_z_'", "+", "str", "(", "self", ".", "z_dim", ")", "+", "'_'", "+", "str", "(", "self", ".", "batch_size", ")", "+", "'_'", "+", "str", "(", "self", ".", "epoch", ")", "\n", "self", ".", "predprefix", "=", "predictprefix", "\n", "\n", "# Saving directory", "\n", "working_dir", "=", "os", ".", "getcwd", "(", ")", "\n", "tempdir", "=", "os", ".", "path", ".", "join", "(", "working_dir", ",", "self", ".", "result_dir", ",", "self", ".", "model_name", ",", "foldername", ",", "self", ".", "output_postfix", ")", "\n", "self", ".", "output_dir", "=", "checkandcreatefolder", "(", "dir", "=", "tempdir", ")", "\n", "\n", "# Initialize VAE model", "\n", "self", ".", "vaemodel", "=", "VAEmod", "(", "args", ",", "self", ".", "x_dim", ",", "self", ".", "bfixlogvar", ")", "\n", "\n", "# This should be changed for later versions of PyTorch", "\n", "if", "self", ".", "gpu_mode", ":", "\n", "            ", "self", ".", "vaemodel", ".", "cuda", "(", ")", "\n", "\n", "# Initialize optimizer", "\n", "", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "vaemodel", ".", "parameters", "(", ")", ",", "lr", "=", "1e-3", ")", "\n", "\n", "# Initialize ARD prior", "\n", "if", "self", ".", "bard", ":", "\n", "            ", "self", ".", "ardprior", "=", "ARDprior", "(", "self", ".", "arda0", ",", "self", ".", "getdecweightlist", "(", ")", ",", "self", ".", "vaemodel", ",", "self", ".", "gpu_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.getweightlist": [[377, 392], ["VAE_up.VAEpeptide.vaemodel.named_parameters", "weight_list.append", "print"], "methods", ["None"], ["", "", "def", "getweightlist", "(", "self", ")", ":", "\n", "        ", "'''This function obtains a parameter list of the model.\n        :return: Dict list of parameters.\n        '''", "\n", "\n", "weight_list", "=", "[", "]", "\n", "id", "=", "0", "\n", "for", "name", ",", "param", "in", "self", ".", "vaemodel", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "param", ".", "requires_grad", ":", "\n", "                ", "weight_list", ".", "append", "(", "{", "'name'", ":", "name", ",", "'id'", ":", "id", ",", "'params'", ":", "param", "}", ")", "\n", "#pclone = param.clone()", "\n", "#params_dec_copy.append({'name': name, 'id': id, 'params': pclone})", "\n", "print", "(", "name", ")", "# , param.data", "\n", "", "id", "=", "id", "+", "1", "\n", "", "return", "weight_list", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.getdecweightlist": [[393, 410], ["VAE_up.VAEpeptide.vaemodel.named_parameters", "decoding_weight_list.append", "print"], "methods", ["None"], ["", "def", "getdecweightlist", "(", "self", ")", ":", "\n", "        ", "'''This function obtains a parameter list of the decoding part of the model.\n        :return: Dict list of parameters.\n        '''", "\n", "\n", "decoding_weight_list", "=", "[", "]", "\n", "id", "=", "0", "\n", "for", "name", ",", "param", "in", "self", ".", "vaemodel", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "param", ".", "requires_grad", ":", "\n", "# UQ only for decoding network", "\n", "                ", "if", "'dec_'", "in", "name", ":", "\n", "# check if we want to uq bias uncertainty", "\n", "                    ", "if", "not", "(", "'.bias'", "in", "name", ")", "and", "not", "(", "'logvar'", "in", "name", ")", ":", "\n", "                        ", "decoding_weight_list", ".", "append", "(", "{", "'name'", ":", "name", ",", "'id'", ":", "id", ",", "'params'", ":", "param", "}", ")", "\n", "print", "(", "name", ")", "# , param.data", "\n", "", "id", "=", "id", "+", "1", "\n", "", "", "", "return", "decoding_weight_list", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.loss_function_autoencvarbayes": [[411, 479], ["recon_logvar.exp", "recon_logvar.exp.reciprocal", "pointwiseMSEloss.mul", "pointwiseMSEloss.mul.sum", "VAE_up.VAEpeptide.train_hist[].append", "loss.data.cpu().numpy", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "recon_logvar.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor.fill_", "torch.FloatTensor.fill_", "torch.FloatTensor.fill_", "torch.FloatTensor.fill_", "torch.autograd.Variable.log", "torch.autograd.Variable.log", "torch.autograd.Variable.log", "torch.autograd.Variable.log", "logpriorpvarexpanded.sum", "logpriorpvarexpanded.sum.div", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "VAE_up.VAEpeptide.ardprior.getlogpiorARD", "VAE_up.VAEpeptide.mul_", "loss.add_", "print", "x.view", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "loss.data.cpu", "logvar.exp", "torch.FloatTensor.cuda", "torch.FloatTensor.cuda", "torch.FloatTensor.cuda", "torch.FloatTensor.cuda", "torch.autograd.Variable.log.expand_as", "recon_logvar.exp.mul", "float", "mu.pow"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.ARDprior.getlogpiorARD"], ["", "def", "loss_function_autoencvarbayes", "(", "self", ",", "recon_mu", ",", "recon_logvar", ",", "x", ",", "mu", ",", "logvar", ",", "x_dim", "=", "784", ")", ":", "\n", "        ", "''' This function computes the objective according Autoencoding Variational Bayes of D. Kingma and M. Welling, 2014.\n\n        :param recon_mu: Reconstructed mean of p(x|z) with z is the encoded data.\n        :param recon_logvar: Reconstructed variance of p(x|z) with z is the encoded data.\n        :param x: Data.\n        :param mu: Mean of encoded x (data).\n        :param logvar: Variance of encoded x (data).\n        :param x_dim: Dim(x_i) of a single datum.\n        :return:\n        '''", "\n", "\n", "pointwiseMSEloss", "=", "0.5", "*", "F", ".", "mse_loss", "(", "recon_mu", ",", "x", ".", "view", "(", "-", "1", ",", "x_dim", ")", ",", "size_average", "=", "False", ",", "reduce", "=", "False", ")", "\n", "\n", "# Maug is here the augmentet bacht size: explicitly: M*L while L indicates the sample for reparametrization \\epsilon ~ p(\\epsilon)", "\n", "Maug", "=", "pointwiseMSEloss", ".", "shape", "[", "0", "]", "\n", "\n", "sigsq", "=", "recon_logvar", ".", "exp", "(", ")", "\n", "weight", "=", "sigsq", ".", "reciprocal", "(", ")", "\n", "logvarobjective", "=", "0.5", "*", "recon_logvar", ".", "sum", "(", ")", "\n", "pointwiseWeightedMSEloss", "=", "pointwiseMSEloss", ".", "mul", "(", "weight", ")", "\n", "# This implies the contribution from a Gaussian p(x|z) with the diagonal covariance entries sigsq.", "\n", "WeightedMSEloss", "=", "pointwiseWeightedMSEloss", ".", "sum", "(", ")", "\n", "\n", "# see Appendix B from VAE paper:", "\n", "# Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014", "\n", "# https://arxiv.org/abs/1312.6114", "\n", "# 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)", "\n", "KLD", "=", "-", "0.5", "*", "torch", ".", "sum", "(", "1", "+", "logvar", "-", "mu", ".", "pow", "(", "2", ")", "-", "logvar", ".", "exp", "(", ")", ")", "\n", "\n", "self", ".", "train_hist", "[", "'kl_qp'", "]", ".", "append", "(", "KLD", ")", "\n", "\n", "# Prior on predictive variance", "\n", "# This is not used in the **paper_link**, thus not relevant.", "\n", "psigsqlamb", "=", "self", ".", "lambdaexpprior", "\n", "# employ prior if desired", "\n", "if", "psigsqlamb", ">", "0.", ":", "\n", "            ", "lamb", "=", "torch", ".", "FloatTensor", "(", "1", ")", "\n", "lamb", ".", "fill_", "(", "psigsqlamb", ")", "\n", "\n", "if", "self", ".", "gpu_mode", ":", "\n", "                ", "lambvariable", "=", "Variable", "(", "lamb", ".", "cuda", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "lambvariable", "=", "Variable", "(", "lamb", ")", "\n", "", "loglamb", "=", "lambvariable", ".", "log", "(", ")", "\n", "\n", "# minus here becuase of minimization; expression stems from max log-likelihood", "\n", "logpriorpvarexpanded", "=", "-", "(", "loglamb", ".", "expand_as", "(", "sigsq", ")", "-", "sigsq", ".", "mul", "(", "psigsqlamb", ")", ")", "\n", "\n", "logpriorvarsum", "=", "logpriorpvarexpanded", ".", "sum", "(", ")", "\n", "logpriorvar", "=", "logpriorvarsum", ".", "div", "(", "Maug", ")", "\n", "", "else", ":", "\n", "            ", "logpriorvar", "=", "torch", ".", "zeros_like", "(", "KLD", ")", "\n", "\n", "# return (WeightedMSEloss + KLD); logpriorvar is zero - since inactive for the paper.", "\n", "", "loss", "=", "(", "logvarobjective", "+", "WeightedMSEloss", "+", "KLD", "+", "logpriorvar", ")", "\n", "\n", "# chekc if ARD prior is active, if so, add its contribution to the loss.", "\n", "if", "self", ".", "bard", ":", "\n", "            ", "ardcontrib", "=", "self", ".", "ardprior", ".", "getlogpiorARD", "(", ")", "\n", "ardcontrib", ".", "mul_", "(", "float", "(", "Maug", ")", "/", "self", ".", "N", ")", "\n", "loss", ".", "add_", "(", "-", "ardcontrib", "[", "0", "]", ")", "\n", "\n", "# Can be removed since it runs stable.", "\n", "", "lossnp", "=", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "lossnp", "!=", "lossnp", ":", "\n", "            ", "print", "(", "'Error: Loss is NaN'", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.trainepoch": [[480, 532], ["VAE_up.VAEpeptide.vaemodel.train", "enumerate", "VAE_up.VAEpeptide.train_hist[].append", "data.cuda.cuda.clone", "range", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "VAE_up.VAEpeptide.optimizer.zero_grad", "VAE_up.VAEpeptide.backward", "VAE_up.VAEpeptide.optimizer.step", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "data.cuda.cuda.cuda", "VAE_up.VAEpeptide.vaemodel", "VAE_up.VAEpeptide.loss_function_autoencvarbayes", "print", "quit", "print", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.train", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.loss_function_autoencvarbayes"], ["", "def", "trainepoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "'''Train one epoch.\n\n        :param epoch: Epoch number\n        '''", "\n", "\n", "self", ".", "vaemodel", ".", "train", "(", ")", "\n", "train_loss", "=", "0", "\n", "\n", "for", "batch_idx", ",", "data", "in", "enumerate", "(", "self", ".", "data_loader", ")", ":", "\n", "\n", "# Copy the data tensor for using more eps ~ p(eps) samples Eq. (7) in AEVB paper", "\n", "            ", "L", "=", "self", ".", "L", "\n", "dataaug", "=", "data", ".", "clone", "(", ")", "\n", "for", "l", "in", "range", "(", "L", "-", "1", ")", ":", "\n", "                ", "dataaug", "=", "torch", ".", "cat", "(", "(", "dataaug", ",", "data", ")", ",", "0", ")", "\n", "\n", "", "data", "=", "Variable", "(", "dataaug", ")", "\n", "# can be removed for newer PyTorch versions", "\n", "if", "self", ".", "gpu_mode", ":", "\n", "                ", "data", "=", "data", ".", "cuda", "(", ")", "\n", "\n", "# Set gradient to zero.", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# This is actually the only version used in the **paper**: self.autoencvarbayes is True.", "\n", "if", "self", ".", "autoencvarbayes", ":", "\n", "                ", "recon_batch", ",", "mu", ",", "logvar", "=", "self", ".", "vaemodel", "(", "data", ")", "\n", "recon_mu", "=", "recon_batch", "[", "0", "]", "\n", "recon_logvar", "=", "recon_batch", "[", "1", "]", "\n", "\n", "loss", "=", "self", ".", "loss_function_autoencvarbayes", "(", "recon_mu", ",", "recon_logvar", ",", "data", ",", "mu", ",", "logvar", ",", "x_dim", "=", "self", ".", "x_dim", ")", "\n", "", "else", ":", "\n", "## Other options not considered", "\n", "                ", "print", "(", "'Use self.autoencvarbayes = True, other options are not in accordance with the paper and thus not included here.'", ")", "\n", "quit", "(", ")", "\n", "\n", "# loss.backward(retain_graph=True)", "\n", "", "loss", ".", "backward", "(", ")", "\n", "train_loss", "+=", "loss", ".", "data", "[", "0", "]", "\n", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Just some monitoring options.", "\n", "log_interval", "=", "20", "\n", "if", "batch_idx", "%", "log_interval", "==", "0", ":", "\n", "                ", "print", "(", "'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'", ".", "format", "(", "\n", "epoch", ",", "batch_idx", "*", "len", "(", "data", ")", ",", "len", "(", "self", ".", "data_loader", ".", "dataset", ")", ",", "\n", "100.", "*", "batch_idx", "/", "len", "(", "self", ".", "data_loader", ")", ",", "\n", "loss", ".", "data", "[", "0", "]", "/", "len", "(", "data", ")", ")", ")", "\n", "\n", "", "", "self", ".", "train_hist", "[", "'Total_loss'", "]", ".", "append", "(", "loss", ".", "data", "[", "0", "]", "/", "len", "(", "data", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.samplePosterior": [[533, 596], ["VAE_up.VAEpeptide.getHessian", "range", "VAE_up.VAEpeptide.gen_samples", "hess[].reciprocal", "hess[].reciprocal.sqrt", "list_normals.append", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "[].shape", "[].reshape", "hess[].inverse", "[].reshape.data.cpu().numpy", "hess[].inverse.cpu().numpy", "list_normals.append", "hess[].inverse", "[].reshape.data.cpu().numpy", "hess[].inverse.cpu().numpy", "list_normals.append", "VAE_up.MVN", "VAE_up.MVN", "list_normals[].sample", "parlistitem[].data.set_", "[].reshape.data.cpu", "hess[].inverse.cpu", "[].reshape.data.cpu", "hess[].inverse.cpu", "[].shape", "list_normals[].sample", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy.resize", "torch.from_numpy.resize", "torch.from_numpy.resize", "torch.from_numpy.resize", "parlistitem[].data.set_", "list_normals[].sample", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "parlistitem[].data.set_", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.getHessian", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.gen_samples", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample"], ["", "def", "samplePosterior", "(", "self", ",", "npostsamples", ")", ":", "\n", "        ", "''' This function samples p(\\theta|X)\n        and produces a trajectory for every \\theta_i by sampling the generative model p(x|\\theta_i).\n        :param npostsamples: Amount of posterior samples p(\\theta|X) and thus trajectories stored.\n        '''", "\n", "\n", "# Compute the Hessian based on the converged MAP estimate.", "\n", "pert_param_list", ",", "params_dec_copy", ",", "hess_list", "=", "self", ".", "getHessian", "(", ")", "\n", "\n", "# Obtain p(\\theta|X)", "\n", "list_normals", "=", "[", "]", "\n", "id", "=", "0", "\n", "for", "hess", "in", "hess_list", ":", "\n", "            ", "if", "not", "hess", "[", "'fullcov'", "]", ":", "\n", "                ", "var", "=", "hess", "[", "'diaghessian'", "]", ".", "reciprocal", "(", ")", "\n", "scale", "=", "var", ".", "sqrt", "(", ")", "\n", "mean", "=", "params_dec_copy", "[", "id", "]", "[", "'params'", "]", "\n", "list_normals", ".", "append", "(", "torch", ".", "distributions", ".", "Normal", "(", "mean", ".", "data", ",", "scale", ")", ")", "\n", "", "else", ":", "\n", "                ", "if", "not", "hess", "[", "'parisvector'", "]", ":", "\n", "                    ", "shape", "=", "params_dec_copy", "[", "id", "]", "[", "'params'", "]", ".", "shape", "(", ")", "\n", "elements", "=", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", "\n", "mean", "=", "params_dec_copy", "[", "id", "]", "[", "'params'", "]", ".", "reshape", "(", "elements", ")", "\n", "cov", "=", "hess", "[", "'diaghessian'", "]", ".", "inverse", "(", ")", "\n", "meannp", "=", "mean", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "covnp", "=", "cov", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "list_normals", ".", "append", "(", "MVN", "(", "meannp", ",", "covnp", ")", ")", "\n", "", "else", ":", "\n", "                    ", "mean", "=", "params_dec_copy", "[", "id", "]", "[", "'params'", "]", "\n", "cov", "=", "hess", "[", "'diaghessian'", "]", ".", "inverse", "(", ")", "\n", "meannp", "=", "mean", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "covnp", "=", "cov", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "list_normals", ".", "append", "(", "MVN", "(", "meannp", ",", "covnp", ")", ")", "\n", "", "", "id", "+=", "1", "\n", "\n", "# Perform the actual sampling process.", "\n", "", "for", "i", "in", "range", "(", "npostsamples", ")", ":", "\n", "            ", "id", "=", "0", "\n", "for", "parlistitem", "in", "pert_param_list", ":", "\n", "                ", "hess", "=", "hess_list", "[", "id", "]", "\n", "if", "not", "(", "parlistitem", "[", "'name'", "]", "==", "'dec_logvar'", ")", ":", "\n", "                    ", "if", "not", "hess", "[", "'fullcov'", "]", ":", "\n", "                        ", "sample", "=", "list_normals", "[", "id", "]", ".", "sample", "(", ")", "\n", "parlistitem", "[", "'params'", "]", ".", "data", ".", "set_", "(", "sample", ")", "\n", "", "else", ":", "\n", "                        ", "if", "not", "hess", "[", "'parisvector'", "]", ":", "\n", "                            ", "shape", "=", "params_dec_copy", "[", "id", "]", "[", "'params'", "]", ".", "shape", "(", ")", "\n", "\n", "samplenp", "=", "list_normals", "[", "id", "]", ".", "sample", "(", ")", "\n", "samplevec", "=", "torch", ".", "from_numpy", "(", "samplenp", ")", "\n", "sample", "=", "samplevec", ".", "resize", "(", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ")", "\n", "parlistitem", "[", "'params'", "]", ".", "data", ".", "set_", "(", "sample", ")", "\n", "\n", "", "else", ":", "\n", "                            ", "samplenp", "=", "list_normals", "[", "id", "]", ".", "sample", "(", ")", "\n", "sample", "=", "torch", ".", "from_numpy", "(", "samplenp", ")", ".", "float", "(", ")", "\n", "parlistitem", "[", "'params'", "]", ".", "data", ".", "set_", "(", "sample", ")", "\n", "\n", "", "", "", "id", "+=", "1", "\n", "\n", "# Make predictions given the current posterior sample \\theta ~ p(\\theta|X)", "\n", "# and store it in a file.", "\n", "", "self", ".", "gen_samples", "(", "n_samples", "=", "self", ".", "n_samples", ",", "postsampid", "=", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.getHessian": [[597, 722], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "enumerate", "VAE_up.VAEpeptide.vaemodel.named_parameters", "VAE_up.TensorDatasetDataOnly", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "VAE_up.VAEpeptide.optimizer.zero_grad", "VAE_up.VAEpeptide.backward", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "grad_params[].dim", "hess_list.append", "numpy.savetxt", "data.cuda.cuda.cuda", "VAE_up.VAEpeptide.vaemodel", "VAE_up.VAEpeptide.loss_function_autoencvarbayes", "VAE_up.VAEpeptide.vaemodel", "VAE_up.VAEpeptide.loss_function", "os.path.join", "torch.autograd.Variable.data.cpu().numpy", "torch.autograd.Variable.data.cpu().numpy", "torch.autograd.Variable.data.cpu().numpy", "torch.autograd.Variable.data.cpu().numpy", "grad_params[].size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "range", "range", "grad_params[].size", "grad_params[].resize", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "range", "range", "pert_param_list.append", "param.clone", "params_dec_copy.append", "print", "pert_param_list.append", "param.clone", "params_dec_copy.append", "print", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "[].resize", "grad_params[].size", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "torch.torch.zeros", "[].resize", "grad_params[].size", "range", "torch.autograd.Variable.data.cpu", "torch.autograd.Variable.data.cpu", "torch.autograd.Variable.data.cpu", "torch.autograd.Variable.data.cpu", "grad_params[].size", "str", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.loss_function_autoencvarbayes"], ["", "", "def", "getHessian", "(", "self", ")", ":", "\n", "        ", "'''This function computes the diagonal entries of the Hessian matrix of the\n        decoding NN parameters.\n        :return pert_param_list, params_dec_copy, hess_list\n        '''", "\n", "\n", "blayercov", "=", "self", ".", "uqoptions", ".", "blayercov", "\n", "self", ".", "uqoptions", ".", "bhessavailable", "=", "True", "\n", "\n", "bvartemp", "=", "self", ".", "vaemodel", ".", "bgetlogvar", "\n", "self", ".", "vaemodel", ".", "bgetlogvar", "=", "True", "\n", "\n", "data_loader_hessian_approx", "=", "DataLoader", "(", "TensorDatasetDataOnly", "(", "self", ".", "data_tensor", ")", ",", "batch_size", "=", "self", ".", "N", ",", "\n", "batch_sampler", "=", "None", ",", "\n", "shuffle", "=", "False", ",", "**", "self", ".", "kwargsdatloader", ")", "\n", "\n", "for", "index", ",", "data", "in", "enumerate", "(", "data_loader_hessian_approx", ")", ":", "\n", "            ", "data", "=", "Variable", "(", "data", ")", "\n", "if", "self", ".", "gpu_mode", ":", "\n", "                ", "data", "=", "data", ".", "cuda", "(", ")", "\n", "\n", "# Resetting any gradient", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "self", ".", "autoencvarbayes", ":", "\n", "                ", "recon_batch", ",", "mu", ",", "logvar", "=", "self", ".", "vaemodel", "(", "data", ")", "\n", "recon_mu", "=", "recon_batch", "[", "0", "]", "\n", "recon_logvar", "=", "recon_batch", "[", "1", "]", "\n", "\n", "# print(np.exp(recon_logvar.data.cpu().numpy()))", "\n", "loss", "=", "self", ".", "loss_function_autoencvarbayes", "(", "recon_mu", ",", "recon_logvar", ",", "data", ",", "mu", ",", "logvar", ",", "x_dim", "=", "self", ".", "x_dim", ")", "\n", "", "else", ":", "\n", "                ", "recon_batch", ",", "mu", ",", "logvar", "=", "self", ".", "vaemodel", "(", "data", ")", "\n", "loss", "=", "self", ".", "loss_function", "(", "recon_batch", ",", "data", ",", "mu", ",", "logvar", ",", "x_dim", "=", "self", ".", "x_dim", ")", "\n", "\n", "# Calculate gradient", "\n", "", "loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "\n", "# Identify the parameters the second derivative is required", "\n", "", "pert_param_list", "=", "[", "]", "\n", "params_dec_copy", "=", "[", "]", "\n", "id", "=", "0", "\n", "for", "name", ",", "param", "in", "self", ".", "vaemodel", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "param", ".", "requires_grad", ":", "\n", "# UQ only for decoding network", "\n", "                ", "if", "'dec_'", "in", "name", ":", "\n", "# check if we want to uq bias uncertainty", "\n", "                    ", "if", "'.bias'", "in", "name", "and", "self", ".", "uqoptions", ".", "buqbias", ":", "\n", "                        ", "pert_param_list", ".", "append", "(", "{", "'name'", ":", "name", ",", "'id'", ":", "id", ",", "'params'", ":", "param", "}", ")", "\n", "pclone", "=", "param", ".", "clone", "(", ")", "\n", "params_dec_copy", ".", "append", "(", "{", "'name'", ":", "name", ",", "'id'", ":", "id", ",", "'params'", ":", "pclone", "}", ")", "\n", "print", "(", "name", ")", "# , param.data", "\n", "", "else", ":", "\n", "                        ", "pert_param_list", ".", "append", "(", "{", "'name'", ":", "name", ",", "'id'", ":", "id", ",", "'params'", ":", "param", "}", ")", "\n", "pclone", "=", "param", ".", "clone", "(", ")", "\n", "params_dec_copy", ".", "append", "(", "{", "'name'", ":", "name", ",", "'id'", ":", "id", ",", "'params'", ":", "pclone", "}", ")", "\n", "print", "(", "name", ")", "# , param.data", "\n", "", "id", "=", "id", "+", "1", "\n", "\n", "", "", "", "hess_list", "=", "[", "]", "\n", "\n", "# for group in param_groups:", "\n", "#    for p in group['params'][2*nLayerEnc:]:", "\n", "for", "parentry", "in", "pert_param_list", ":", "\n", "            ", "p", "=", "parentry", "[", "'params'", "]", "\n", "\n", "if", "parentry", "[", "'name'", "]", "==", "'dec_logvar'", ":", "\n", "                ", "blayercov", "=", "False", "\n", "", "else", ":", "\n", "                ", "blayercov", "=", "self", ".", "uqoptions", ".", "blayercov", "\n", "\n", "", "grad_params", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "p", ",", "create_graph", "=", "True", ")", "\n", "# hv = torch.autograd.grad(g000, p, create_graph=True)", "\n", "hess_params", "=", "torch", ".", "zeros_like", "(", "grad_params", "[", "0", "]", ")", "\n", "\n", "# print(hess_params.size())", "\n", "bfullcov", "=", "False", "\n", "bparisvector", "=", "False", "\n", "dim_grad", "=", "grad_params", "[", "0", "]", ".", "dim", "(", ")", "\n", "if", "dim_grad", "==", "1", ":", "\n", "                ", "bparisvector", "=", "True", "\n", "if", "blayercov", ":", "\n", "                    ", "bfullcov", "=", "True", "\n", "size", "=", "grad_params", "[", "0", "]", ".", "size", "(", ")", "\n", "elements", "=", "size", "[", "0", "]", "\n", "unrolled_grad_params", "=", "grad_params", "[", "0", "]", "\n", "\n", "hess_params", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "torch", ".", "zeros", "(", "elements", ",", "elements", ")", ")", "\n", "for", "i", "in", "range", "(", "elements", ")", ":", "\n", "# gives the row of the hessian", "\n", "                        ", "hessrow", "=", "torch", ".", "autograd", ".", "grad", "(", "unrolled_grad_params", "[", "i", "]", ",", "p", ",", "retain_graph", "=", "True", ")", "[", "0", "]", ".", "resize", "(", "elements", ")", "\n", "hess_params", "[", "i", ",", ":", "]", "=", "hessrow", "\n", "", "", "else", ":", "\n", "                    ", "bfullcov", "=", "False", "\n", "for", "i", "in", "range", "(", "grad_params", "[", "0", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "                        ", "hess_params", "[", "i", "]", "=", "torch", ".", "autograd", ".", "grad", "(", "grad_params", "[", "0", "]", "[", "i", "]", ",", "p", ",", "retain_graph", "=", "True", ")", "[", "0", "]", "[", "i", "]", "\n", "", "", "", "else", ":", "\n", "                ", "bparisvector", "=", "False", "\n", "#if blayercov:", "\n", "# TODO sparse storage of matrix required needed", "\n", "if", "False", ":", "\n", "                    ", "bfullcov", "=", "True", "\n", "size", "=", "grad_params", "[", "0", "]", ".", "size", "(", ")", "\n", "elements", "=", "size", "[", "0", "]", "*", "size", "[", "1", "]", "\n", "unrolled_grad_params", "=", "grad_params", "[", "0", "]", ".", "resize", "(", "elements", ")", "\n", "\n", "hess_params", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "torch", ".", "zeros", "(", "elements", ",", "elements", ")", ")", "\n", "for", "i", "in", "range", "(", "elements", ")", ":", "\n", "# gives the row of the hessian", "\n", "                        ", "hessrow", "=", "torch", ".", "autograd", ".", "grad", "(", "unrolled_grad_params", "[", "i", "]", ",", "p", ",", "retain_graph", "=", "True", ")", "[", "0", "]", ".", "resize", "(", "elements", ")", "\n", "hess_params", "[", "i", ",", ":", "]", "=", "hessrow", "\n", "", "", "else", ":", "\n", "                    ", "bfullcov", "=", "False", "\n", "for", "i", "in", "range", "(", "grad_params", "[", "0", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "                        ", "for", "j", "in", "range", "(", "grad_params", "[", "0", "]", ".", "size", "(", "1", ")", ")", ":", "\n", "                            ", "hess_params", "[", "i", ",", "j", "]", "=", "torch", ".", "autograd", ".", "grad", "(", "grad_params", "[", "0", "]", "[", "i", "]", "[", "j", "]", ",", "p", ",", "retain_graph", "=", "True", ")", "[", "0", "]", "[", "i", ",", "j", "]", "\n", "\n", "", "", "", "", "if", "not", "bfullcov", ":", "\n", "                ", "hess_params", "[", "hess_params", "<", "0.5", "]", "=", "10.", "*", "self", ".", "N", "#1.e5", "\n", "", "hess_list", ".", "append", "(", "{", "'name'", ":", "parentry", "[", "'name'", "]", ",", "'id'", ":", "parentry", "[", "'id'", "]", ",", "'diaghessian'", ":", "hess_params", ".", "data", ",", "'fullcov'", ":", "bfullcov", ",", "'parisvector'", ":", "bparisvector", "}", ")", "\n", "np", ".", "savetxt", "(", "os", ".", "path", ".", "join", "(", "self", ".", "output_dir", ",", "parentry", "[", "'name'", "]", "+", "'_'", "+", "str", "(", "self", ".", "N", ")", "+", "'.txt'", ")", ",", "hess_params", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "self", ".", "vaemodel", ".", "bgetlogvar", "=", "bvartemp", "\n", "\n", "return", "pert_param_list", ",", "params_dec_copy", ",", "hess_list", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.train": [[724, 807], ["numpy.savetxt", "VAE_up.VAEpeptide.vaemodel.eval", "VAE_up.VAEpeptide.gen_samples", "print", "time.time", "range", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "VAE_up.VAEpeptide.train_hist[].append", "print", "print", "print", "utils.loss_plot", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "VAE_up.VAEpeptide.countzeroweights", "VAE_up.VAEpeptide.countzeroweights", "numpy.ones", "VAE_up.VAEpeptide.samplePosterior", "time.time", "VAE_up.VAEpeptide.trainepoch", "VAE_up.VAEpeptide.visLatentTraining", "VAE_up.VAEpeptide.train_hist[].append", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "VAE_up.VAEpeptide.vaemodel.decode().cpu", "utils_peptide.convert_given_representation", "numpy.savetxt", "time.time", "VAE_up.VAEpeptide.getdecweightlist", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "sample.cuda.cuda.cuda", "time.time", "numpy.mean", "VAE_up.VAEpeptide.vaemodel.decode"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.gen_samples", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils.loss_plot", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.countzeroweights", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.countzeroweights", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.samplePosterior", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.trainepoch", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.visLatentTraining", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.convert_given_representation", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.getdecweightlist", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.decode"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "'''This functions is the main training function.\n        '''", "\n", "\n", "self", ".", "train_hist", "=", "{", "}", "\n", "self", ".", "train_hist", "[", "'Total_loss'", "]", "=", "[", "]", "\n", "self", ".", "train_hist", "[", "'per_epoch_time'", "]", "=", "[", "]", "\n", "self", ".", "train_hist", "[", "'total_time'", "]", "=", "[", "]", "\n", "self", ".", "train_hist", "[", "'kl_qp'", "]", "=", "[", "]", "\n", "\n", "# Store intermediate steps", "\n", "intermediate", "=", "False", "\n", "\n", "# If the model from previous training process is loaded, no need to train it.", "\n", "if", "not", "self", ".", "bloadmodel", ":", "\n", "            ", "print", "(", "'Training started.'", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "1", ",", "self", ".", "epoch", "+", "1", ")", ":", "\n", "                ", "epoch_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Train single epoch", "\n", "self", ".", "trainepoch", "(", "epoch", ")", "\n", "\n", "# visualize intermediate latent space", "\n", "self", ".", "visLatentTraining", "(", "epoch", ")", "\n", "\n", "# Make intermediate predictions during the training procedure", "\n", "if", "intermediate", ":", "\n", "# sample the prior", "\n", "                    ", "sample", "=", "Variable", "(", "torch", ".", "randn", "(", "64", ",", "self", ".", "z_dim", ")", ")", "\n", "# This can be removed in newer PyTorch versions.", "\n", "if", "self", ".", "gpu_mode", ":", "\n", "                        ", "sample", "=", "sample", ".", "cuda", "(", ")", "\n", "# Decode the samples", "\n", "", "sample", "=", "self", ".", "vaemodel", ".", "decode", "(", "sample", ")", ".", "cpu", "(", ")", "\n", "# The step below does not affect the prediction, but in case of providing Cartesian", "\n", "# coordinates as done in the **paper**.", "\n", "sampleout", "=", "convert_given_representation", "(", "samples", "=", "sample", ",", "coordrep", "=", "self", ".", "angulardata", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "output_dir", "+", "'/samples'", "+", "self", ".", "predprefix", "+", "'.txt'", ",", "sampleout", ")", "\n", "\n", "# store training time for one epoch", "\n", "", "self", ".", "train_hist", "[", "'per_epoch_time'", "]", ".", "append", "(", "time", ".", "time", "(", ")", "-", "epoch_start_time", ")", "\n", "\n", "# Training has been completed, save the trained model.", "\n", "", "torch", ".", "save", "(", "self", ".", "vaemodel", ",", "self", ".", "output_dir", "+", "'/model.pth'", ")", "\n", "\n", "# Store total training data", "\n", "self", ".", "train_hist", "[", "'total_time'", "]", ".", "append", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", "\n", "print", "(", "\"Avg one epoch time: %.2f, total %d epochs time: %.2f\"", "%", "(", "np", ".", "mean", "(", "self", ".", "train_hist", "[", "'per_epoch_time'", "]", ")", ",", "\n", "self", ".", "epoch", ",", "\n", "self", ".", "train_hist", "[", "'total_time'", "]", "[", "0", "]", ")", ")", "\n", "print", "(", "\"Training finish!... save training results\"", ")", "\n", "print", "(", "\"Final KLD loss %.3f\"", "%", "(", "self", ".", "train_hist", "[", "'kl_qp'", "]", "[", "-", "1", "]", ")", ")", "\n", "\n", "# utils.generate_animation(self.result_dir + '/' + self.dataset + '/' + self.model_name + '/' + self.model_name,", "\n", "#                          self.epoch)", "\n", "\n", "utils", ".", "loss_plot", "(", "self", ".", "train_hist", ",", "\n", "self", ".", "output_dir", ",", "\n", "self", ".", "model_name", "+", "self", ".", "predprefix", ",", "bvae", "=", "True", ")", "\n", "\n", "", "else", ":", "\n", "# Load the vae model which was trained before for making predictions", "\n", "            ", "self", ".", "vaemodel", "=", "torch", ".", "load", "(", "self", ".", "filemodel", ")", "\n", "\n", "# Count active parameters", "\n", "", "if", "self", ".", "bard", ":", "\n", "            ", "nonactiveparams", "=", "self", ".", "countzeroweights", "(", "paramlist", "=", "self", ".", "ardprior", ".", "paramlist", ",", "threshold", "=", "0.0001", ")", "\n", "", "else", ":", "\n", "            ", "nonactiveparams", "=", "self", ".", "countzeroweights", "(", "paramlist", "=", "self", ".", "getdecweightlist", "(", ")", ",", "threshold", "=", "0.0001", ")", "\n", "", "nap", "=", "np", ".", "ones", "(", "1", ")", "*", "nonactiveparams", "\n", "np", ".", "savetxt", "(", "self", ".", "output_dir", "+", "'/nonactiveparams.txt'", ",", "nap", ")", "\n", "\n", "# Model has been trained", "\n", "self", ".", "vaemodel", ".", "eval", "(", ")", "\n", "\n", "# Generate samples for predictions (MAP estimate)", "\n", "self", ".", "gen_samples", "(", "self", ".", "n_samples", ")", "\n", "\n", "# Calculate the hessian if we require UQ", "\n", "if", "self", ".", "uqoptions", ".", "bdouq", ":", "\n", "            ", "self", ".", "samplePosterior", "(", "self", ".", "uqoptions", ".", "npostsamples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.vis_phipsilatent": [[809, 843], ["numpy.linspace", "numpy.linspace", "numpy.meshgrid", "X.flatten", "Y.flatten", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float.unsqueeze_", "torch.from_numpy().float.unsqueeze_", "torch.from_numpy().float.unsqueeze_", "torch.from_numpy().float.unsqueeze_", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float.unsqueeze", "torch.from_numpy().float.unsqueeze", "torch.from_numpy().float.unsqueeze", "torch.from_numpy().float.unsqueeze", "VAE_up.VAEpeptide.vaemodel.decode", "torchsamples[].data.cpu().numpy", "utils_peptide.convert_given_representation", "numpy.savetxt", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torchsamples[].data.cpu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.decode", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.convert_given_representation"], ["", "", "def", "vis_phipsilatent", "(", "self", ",", "path", ")", ":", "\n", "        ", "'''Visualize the phi and psi landscape for the learned latent representation.\n        This function creates a grid and corresponding to the CVs make predictions x.\n        :param path: string, provide path where to save the prediction.\n        :return:\n        '''", "\n", "\n", "# Create grid with numpy", "\n", "x", "=", "np", ".", "linspace", "(", "-", "4.", ",", "4.", ",", "101", ")", "\n", "y", "=", "np", ".", "linspace", "(", "-", "4.", ",", "4.", ",", "101", ")", "\n", "X", ",", "Y", "=", "np", ".", "meshgrid", "(", "x", ",", "y", ")", "\n", "Xvec", "=", "X", ".", "flatten", "(", ")", "\n", "Yvec", "=", "Y", ".", "flatten", "(", ")", "\n", "\n", "# Convert numpy array to torch", "\n", "Xtorch", "=", "torch", ".", "from_numpy", "(", "Xvec", ")", ".", "float", "(", ")", "\n", "Xtorch", ".", "unsqueeze_", "(", "1", ")", "\n", "Ytorch", "=", "torch", ".", "from_numpy", "(", "Yvec", ")", ".", "float", "(", ")", "\n", "Ytorch", ".", "unsqueeze", "(", "1", ")", "\n", "# Not required for newer PyTorch", "\n", "if", "self", ".", "gpu_mode", ":", "\n", "            ", "samples_z", "=", "Variable", "(", "torch", ".", "cat", "(", "(", "Xtorch", ",", "Ytorch", ")", ",", "1", ")", ".", "cuda", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "samples_z", "=", "Variable", "(", "torch", ".", "cat", "(", "(", "Xtorch", ",", "Ytorch", ")", ",", "1", ")", ")", "\n", "\n", "# Decode the CVs z to x", "\n", "", "torchsamples", "=", "self", ".", "vaemodel", ".", "decode", "(", "samples_z", ")", "\n", "# Convert to numpy", "\n", "samples", "=", "torchsamples", "[", "0", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Convert the samples if they are in the angular format - this function", "\n", "# does not show any effect when using a Cartesian representation as in the **paper**.", "\n", "samplesout", "=", "convert_given_representation", "(", "samples", "=", "samples", ",", "coordrep", "=", "self", ".", "angulardata", ")", "\n", "np", ".", "savetxt", "(", "path", "+", "'/samples_vis_phipsi'", "+", "self", ".", "predprefix", "+", "'.txt'", ",", "samplesout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.countzeroweights": [[844, 861], ["par.abs", "smaller.dim", "int", "smaller.size"], "methods", ["None"], ["", "def", "countzeroweights", "(", "self", ",", "paramlist", ",", "threshold", "=", "0.0001", ")", ":", "\n", "        ", "'''This function counts the inactive weights of the decoding neural network.\n        :param paramlist: Torch parameter list of parameters which should be considered.\n        :param threshold: Threshold considering parameter as inactive.\n        :return: Amount of inactive parameters.\n        '''", "\n", "counter", "=", "0", "\n", "for", "paramitem", "in", "paramlist", ":", "\n", "            ", "par", "=", "paramitem", "[", "'params'", "]", "\n", "\n", "abspar", "=", "par", ".", "abs", "(", ")", "\n", "abspardat", "=", "abspar", ".", "data", "\n", "smaller", "=", "abspardat", "[", "abspardat", "<", "threshold", "]", "\n", "if", "smaller", ".", "dim", "(", ")", ">", "0", ":", "\n", "                ", "counter", "=", "counter", "+", "int", "(", "smaller", ".", "size", "(", ")", "[", "0", "]", ")", "\n", "\n", "", "", "return", "counter", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.vis_realizations": [[862, 906], ["enumerate", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "VAE_up.VAEpeptide.vaemodel.encode", "samplesTorchmu.data.cpu().numpy", "samplesTorchlogvar.exp", "samplesTorchlogvar.exp.data.cpu().numpy", "numpy.zeros", "range", "utils_peptide.convert_given_representation", "numpy.savetxt", "VAE_up.VAEpeptide.vaemodel.decode().gpu", "VAE_up.VAEpeptide.vaemodel.decode", "numpy.random.multivariate_normal", "samplesTorchmu.data.cpu", "samplesTorchlogvar.exp.data.cpu", "numpy.diag", "VAE_up.VAEpeptide.vaemodel.decode"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.encode", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.convert_given_representation", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.decode", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.decode"], ["", "def", "vis_realizations", "(", "self", ")", ":", "\n", "        ", "'''This function visualizes a specific amount of realizations per prediction of the decoded data points.\n        For showing that the variance of p(x|z) captures outer Hydrogen atoms as noise.\n        :return:\n        '''", "\n", "\n", "ic", "=", "0", "\n", "# load the", "\n", "for", "batch_idx", ",", "data", "in", "enumerate", "(", "self", ".", "data_loader", ")", ":", "\n", "            ", "if", "ic", "==", "0", ":", "\n", "                ", "data_vis", "=", "data", "\n", "\n", "", "", "x", "=", "Variable", "(", "data_vis", ")", "\n", "n_samples", "=", "x", ".", "shape", "[", "0", "]", "\n", "# Encode the data set into latent space", "\n", "muenc", ",", "log", "=", "self", ".", "vaemodel", ".", "encode", "(", "x", ")", "\n", "\n", "# Decode to mean and variance of predictions", "\n", "self", ".", "vaemodel", ".", "bgetlogvar", "=", "True", "\n", "if", "self", ".", "gpu_mode", ":", "\n", "            ", "samplesTorchmu", ",", "samplesTorchlogvar", "=", "self", ".", "vaemodel", ".", "decode", "(", "muenc", ")", ".", "gpu", "(", ")", "\n", "", "else", ":", "\n", "            ", "samplesTorchmu", ",", "samplesTorchlogvar", "=", "self", ".", "vaemodel", ".", "decode", "(", "muenc", ")", "\n", "\n", "", "mu", "=", "samplesTorchmu", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "vartorch", "=", "samplesTorchlogvar", ".", "exp", "(", ")", "\n", "var", "=", "vartorch", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Init storage for total amount of samples.", "\n", "nsamples_per_dp", "=", "300", "\n", "nsamples_per_dp_tot", "=", "nsamples_per_dp", "+", "1", "\n", "n_samples_tot", "=", "n_samples", "*", "nsamples_per_dp_tot", "\n", "samples_aevb", "=", "np", ".", "zeros", "(", "[", "n_samples_tot", ",", "self", ".", "x_dim", "]", ")", "\n", "\n", "for", "n", "in", "range", "(", "n_samples", ")", ":", "\n", "            ", "samples_aevb", "[", "n", "*", "nsamples_per_dp_tot", ",", ":", "]", "=", "mu", "[", "n", ",", ":", "]", "\n", "\n", "samples_aevb", "[", "n", "*", "nsamples_per_dp_tot", "+", "1", ":", "(", "n", "+", "1", ")", "*", "nsamples_per_dp_tot", ",", ":", "]", "=", "np", ".", "random", ".", "multivariate_normal", "(", "\n", "mu", "[", "n", ",", ":", "]", ",", "np", ".", "diag", "(", "var", "[", "n", ",", ":", "]", ")", ",", "nsamples_per_dp", ")", "\n", "", "self", ".", "vaemodel", ".", "bgetlogvar", "=", "False", "\n", "\n", "# Only takes action when non Cartesian coordinates are used - not the case here.", "\n", "samplesoutaevb", "=", "convert_given_representation", "(", "samples", "=", "samples_aevb", ",", "coordrep", "=", "self", ".", "angulardata", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "output_dir", "+", "'/samples_aevb'", "+", "self", ".", "predprefix", "+", "'_vis_mean_samples_'", "+", "'.txt'", ",", "samplesoutaevb", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.vis_latentpredictions": [[907, 979], ["torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "y.cuda.cuda.unsqueeze", "x.cuda.cuda.unsqueeze", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "VAE_up.VAEpeptide.vaemodel.decode", "torchsamples[].data.cpu().numpy", "utils_peptide.convert_given_representation", "numpy.savetxt", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "y.cuda.cuda.copy_", "y.cuda.cuda.cuda", "x.cuda.cuda.cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "samples_z[].data.numpy", "samples_z[].data.numpy", "torchsamples[].data.cpu", "VAE_up.VAEpeptide.vaemodel.plotlatentrep", "VAE_up.VAEpeptide.vaemodel.plotlatentrep", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.decode", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.convert_given_representation", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEparent.plotlatentrep", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEparent.plotlatentrep"], ["", "def", "vis_latentpredictions", "(", "self", ",", "yb", ",", "ny", ",", "path", ")", ":", "\n", "        ", "'''This function predicts atomistic configurations along a provided path in the CV space. Those z are mapped\n        to full atomistic configurations. Currently just ny and path are required. Only visualization.\n        :param ny: Number of points in y direction.\n        :param path: String of path for storing the prediction.\n        :return:\n        '''", "\n", "\n", "# This allows to plot the latent representation and augment it with an indicator at the current position in the latent space", "\n", "# This is only valid for ALA2", "\n", "bVisualizeStar", "=", "False", "\n", "if", "bVisualizeStar", "==", "True", ":", "\n", "            ", "ny", "=", "251", "\n", "", "bShowTraining", "=", "True", "\n", "if", "bShowTraining", ":", "\n", "            ", "xt", "=", "Variable", "(", "self", ".", "data_tensor", ")", "\n", "", "else", ":", "\n", "            ", "xt", "=", "None", "\n", "", "bRnd", "=", "False", "\n", "\n", "#y = torch.linspace(yb[0], yb[1], ny)", "\n", "\n", "# y coordinates", "\n", "y", "=", "torch", ".", "linspace", "(", "-", "4", ",", "4", ",", "ny", ")", "\n", "#y1 = torch.linspace(-4, 0, ny*3)", "\n", "#y2 = torch.linspace(0, 4, ny*2)", "\n", "#nges =  5*ny", "\n", "#y = torch.cat((y1,y2))", "\n", "\n", "# x coordinates", "\n", "x", "=", "torch", ".", "zeros", "(", "ny", ")", "\n", "\n", "# For different plots experiments visualizing a path defined in the latent space.", "\n", "# This path was used for ALA15 path in Fig. 14 in **paper**.", "\n", "if", "False", ":", "\n", "            ", "x", "=", "torch", ".", "linspace", "(", "-", "1", ",", "3", ",", "ny", ")", "\n", "y12", "=", "-", "2.", "*", "x", "\n", "y13", "=", "-", "2.", "/", "3.", "*", "x", "\n", "y", "=", "torch", ".", "zeros_like", "(", "y12", ")", "\n", "y", ".", "copy_", "(", "y12", ")", "\n", "y", "[", "20", ":", "]", "=", "y13", "[", "20", ":", "]", "\n", "\n", "# Check if gpu mode is active - drop for newer PyTorch.", "\n", "", "if", "self", ".", "gpu_mode", ":", "\n", "            ", "y", "=", "y", ".", "cuda", "(", ")", "\n", "x", "=", "x", ".", "cuda", "(", ")", "\n", "\n", "# summarize x and y in torch variable", "\n", "", "y", "=", "y", ".", "unsqueeze", "(", "1", ")", "\n", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "samples_z", "=", "Variable", "(", "torch", ".", "cat", "(", "(", "y", ",", "x", ")", ",", "1", ")", ")", "\n", "\n", "# This is for showing a marker at the current position in the latent space.", "\n", "# E.g. for visualizing atomistic configurations for given CVs.", "\n", "if", "bVisualizeStar", ":", "\n", "            ", "for", "i", "in", "range", "(", "0", ",", "ny", ")", ":", "\n", "                ", "xnp_curr", "=", "samples_z", "[", "i", ",", "0", "]", ".", "data", ".", "numpy", "(", ")", "\n", "ynp_curr", "=", "samples_z", "[", "i", ",", "1", "]", ".", "data", ".", "numpy", "(", ")", "\n", "if", "i", "==", "0", ":", "\n", "                    ", "n", "=", "self", ".", "vaemodel", ".", "plotlatentrep", "(", "x", "=", "Variable", "(", "self", ".", "data_tensor_vis_1527", ")", ",", "z_dim", "=", "self", ".", "z_dim", ",", "path", "=", "self", ".", "output_dir", ",", "\n", "iter", "=", "i", ",", "x_curr", "=", "xnp_curr", ",", "y_curr", "=", "ynp_curr", ",", "nprov", "=", "False", ",", "x_train", "=", "xt", ")", "\n", "", "else", ":", "\n", "                    ", "n", "=", "self", ".", "vaemodel", ".", "plotlatentrep", "(", "x", "=", "Variable", "(", "self", ".", "data_tensor_vis_1527", ")", ",", "z_dim", "=", "self", ".", "z_dim", ",", "path", "=", "self", ".", "output_dir", ",", "\n", "iter", "=", "i", ",", "x_curr", "=", "xnp_curr", ",", "y_curr", "=", "ynp_curr", ",", "nprov", "=", "True", ",", "normaltemp", "=", "n", ",", "x_train", "=", "xt", ")", "\n", "\n", "", "", "", "torchsamples", "=", "self", ".", "vaemodel", ".", "decode", "(", "samples_z", ")", "\n", "samples", "=", "torchsamples", "[", "0", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Convert the samples if they are in the angular format - not relevant for this **paper**", "\n", "samplesout", "=", "convert_given_representation", "(", "samples", "=", "samples", ",", "coordrep", "=", "self", ".", "angulardata", ")", "\n", "np", ".", "savetxt", "(", "path", "+", "'/samples_vis_latent'", "+", "self", ".", "predprefix", "+", "'.txt'", ",", "samplesout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.gen_samples": [[980, 1090], ["VAE_up.VAEpeptide.postprocessing", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "VAE_up.VAEpeptide.vaemodel.decode", "initlogvar.mul().exp_", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal.sample", "torch.distributions.Normal.sample", "torch.distributions.Normal.sample", "torch.distributions.Normal.sample", "VAE_up.PseudoGibbs", "VAE_up.PseudoGibbs.sample", "VAE_up.PseudoGibbs.sample", "VAE_up.VAEpeptide.data.cpu().numpy", "utils_peptide.convert_given_representation", "numpy.savetxt", "VAE_up.VAEpeptide.data.cpu().numpy", "samplesTorchlogvar.exp", "samplesTorchlogvar.exp.data.cpu().numpy", "numpy.zeros", "range", "utils_peptide.convert_given_representation", "numpy.savetxt", "utils_peptide.estimateProperties", "VAE_up.VAEpeptide.postprocessingALA15", "str", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "utils_peptide.convert_given_representation", "numpy.savetxt", "VAE_up.VAEpeptide.vaemodel.decode", "VAE_up.VAEpeptide.vaemodel.decode", "VAE_up.VAEpeptide.vaemodel.decode", "VAE_up.VAEpeptide.vaemodel.decode", "numpy.random.multivariate_normal", "initlogvar.mul", "VAE_up.PseudoGibbs.sample", "VAE_up.VAEpeptide.data.cpu", "VAE_up.VAEpeptide.data.cpu", "samplesTorchlogvar.exp.data.cpu", "numpy.diag", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.postprocessing", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.decode", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.convert_given_representation", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.convert_given_representation", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.estimateProperties", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.postprocessingALA15", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.convert_given_representation", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.decode", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.decode", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.decode", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.decode", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.MVN.sample"], ["", "def", "gen_samples", "(", "self", ",", "n_samples", "=", "4000", ",", "postsampid", "=", "None", ")", ":", "\n", "        ", "'''This function samples predicted atomistic configurations involving the\n        generative part in p(z) and p(x|z) while the variance is considererd.\n        :param n_samples: Amount of required samples.\n        :param postsampid: This parameter is automatically set in case UQ tasks are performed.\n        :return:\n        '''", "\n", "if", "postsampid", "==", "None", "and", "'ala_15'", "not", "in", "self", ".", "dataset", ":", "\n", "            ", "self", ".", "postprocessing", "(", "n_samples", "=", "4000", ",", "postsampid", "=", "None", ")", "\n", "", "elif", "postsampid", "==", "None", "and", "'ala_15'", "in", "self", ".", "dataset", ":", "\n", "            ", "self", ".", "postprocessingALA15", "(", "postsampid", "=", "None", ")", "\n", "\n", "# Saving samples with postfix - important for UQ", "\n", "", "if", "postsampid", "==", "None", ":", "\n", "            ", "postsamplepostfix", "=", "''", "\n", "", "else", ":", "\n", "            ", "postsamplepostfix", "=", "'_postS_'", "+", "str", "(", "postsampid", ")", "\n", "\n", "# Convert the samples if GPU mode is active - deprecated for more", "\n", "# recent PyTorch versions", "\n", "", "if", "self", ".", "gpu_mode", ":", "\n", "            ", "sample_z_", "=", "Variable", "(", "\n", "torch", ".", "randn", "(", "(", "n_samples", ",", "self", ".", "z_dim", ")", ")", ".", "cuda", "(", ")", ",", "volatile", "=", "True", ")", "\n", "z_init", "=", "Variable", "(", "\n", "torch", ".", "randn", "(", "(", "1", ",", "self", ".", "z_dim", ")", ")", ".", "cuda", "(", ")", ",", "volatile", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "sample_z_", "=", "Variable", "(", "torch", ".", "randn", "(", "(", "n_samples", ",", "self", ".", "z_dim", ")", ")", ",", "\n", "volatile", "=", "True", ")", "\n", "z_init", "=", "Variable", "(", "torch", ".", "randn", "(", "(", "1", ",", "self", ".", "z_dim", ")", ")", ",", "\n", "volatile", "=", "True", ")", "\n", "\n", "# Utilize pseudo gibbs algorithm as provided in Mattei, 2018. This algorithm corrects for the approximate", "\n", "# posterior", "\n", "", "if", "self", ".", "exactlikeli", ":", "\n", "            ", "self", ".", "vaemodel", ".", "bgetlogvar", "=", "True", "\n", "initmu", ",", "initlogvar", "=", "self", ".", "vaemodel", ".", "decode", "(", "z_init", ")", "\n", "initstd", "=", "initlogvar", ".", "mul", "(", "0.5", ")", ".", "exp_", "(", ")", "\n", "pinit", "=", "torch", ".", "distributions", ".", "Normal", "(", "initmu", ",", "initstd", ")", "\n", "x_init", "=", "pinit", ".", "sample", "(", ")", "\n", "\n", "pgibs", "=", "PseudoGibbs", "(", "x_init", ",", "z_init", ",", "self", ".", "vaemodel", ")", "\n", "samples_aevb_gibbs", "=", "pgibs", ".", "sample", "(", "n_samples", "*", "self", ".", "n_samples_per_mu", ")", "\n", "samplesnp_aevb_gibbs", "=", "samples_aevb_gibbs", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "self", ".", "autoencvarbayes", ":", "\n", "                ", "samplesoutaevbgibbs", "=", "convert_given_representation", "(", "samples", "=", "samplesnp_aevb_gibbs", ",", "\n", "coordrep", "=", "self", ".", "angulardata", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "output_dir", "+", "'/samples_aevb_gibbs'", "+", "self", ".", "predprefix", "+", "'_'", "+", "self", ".", "postfix_setting", "+", "postsamplepostfix", "+", "'.txt'", ",", "\n", "samplesoutaevbgibbs", ")", "\n", "del", "samplesoutaevbgibbs", "\n", "", "self", ".", "vaemodel", ".", "bgetlogvar", "=", "False", "\n", "\n", "# Prediction for Variational Autoencoder. I.e. sample p(z), and project to x directly with \\mu(z).", "\n", "# No probabilistic model employed for the mapping in this case.", "\n", "# This does not apply for the **paper**", "\n", "", "if", "not", "self", ".", "autoencvarbayes", "or", "self", ".", "n_samples_per_mu", "==", "0", ":", "\n", "            ", "if", "self", ".", "gpu_mode", ":", "\n", "                ", "samplesTorchmu", "=", "self", ".", "vaemodel", ".", "decode", "(", "sample_z_", ")", "#.gpu()", "\n", "", "else", ":", "\n", "                ", "samplesTorchmu", "=", "self", ".", "vaemodel", ".", "decode", "(", "sample_z_", ")", "# .cpu()", "\n", "\n", "# Samples are the means directly", "\n", "", "samples", "=", "samplesTorchmu", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "# convert the samples if they are in the angular format", "\n", "samplesout", "=", "convert_given_representation", "(", "samples", "=", "samples", ",", "coordrep", "=", "self", ".", "angulardata", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "output_dir", "+", "'/samples'", "+", "self", ".", "predprefix", "+", "'_'", "+", "self", ".", "postfix_setting", "+", "postsamplepostfix", "+", "'.txt'", ",", "samplesout", ")", "\n", "\n", "# Prediction for Auto-Encoding Variational Bayes. I.e. sample p(z),", "\n", "# given those SAMPLE p(x|z) = N(\\mu, \\sigma^2). This corresponds to the actual AEVB algorithm and is Bayesian.", "\n", "", "else", ":", "\n", "# Provide at least one sample per mean prediction.", "\n", "            ", "if", "self", ".", "n_samples_per_mu", "==", "0", ":", "\n", "                ", "aevb_samples_per_mu", "=", "1", "\n", "", "else", ":", "\n", "                ", "aevb_samples_per_mu", "=", "self", ".", "n_samples_per_mu", "\n", "\n", "# In case of AEVB one requires the mean and variance of the predictive model p(x|z). Enable this here.", "\n", "", "self", ".", "vaemodel", ".", "bgetlogvar", "=", "True", "# This was incorrect in the original VAE implementation of Kingma,", "\n", "# one needs to account for the variance in p(x|z) in the predictions.", "\n", "if", "self", ".", "gpu_mode", ":", "\n", "                ", "samplesTorchmu", ",", "samplesTorchlogvar", "=", "self", ".", "vaemodel", ".", "decode", "(", "sample_z_", ")", "#.gpu()", "\n", "", "else", ":", "\n", "                ", "samplesTorchmu", ",", "samplesTorchlogvar", "=", "self", ".", "vaemodel", ".", "decode", "(", "sample_z_", ")", "# .cpu()", "\n", "\n", "# TODO do not convert here to numpy for sampling from gaussian but use instead the torch implementation", "\n", "# of the Normal distribution. Those should be inculded in PyTorch version >=0.4.1", "\n", "# but not in 0.3.0", "\n", "", "mu", "=", "samplesTorchmu", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "vartorch", "=", "samplesTorchlogvar", ".", "exp", "(", ")", "\n", "var", "=", "vartorch", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Initialize storage of samples.", "\n", "n_samples_tot", "=", "n_samples", "*", "aevb_samples_per_mu", "\n", "samples_aevb", "=", "np", ".", "zeros", "(", "[", "n_samples_tot", ",", "self", ".", "x_dim", "]", ")", "\n", "\n", "# sample the p(x|z) for different CVs z and its corresponding \\mu(z), \\sigma(z).", "\n", "for", "n", "in", "range", "(", "n_samples", ")", ":", "\n", "                ", "samples_aevb", "[", "n", "*", "aevb_samples_per_mu", ":", "(", "n", "+", "1", ")", "*", "aevb_samples_per_mu", ",", ":", "]", "=", "np", ".", "random", ".", "multivariate_normal", "(", "\n", "mu", "[", "n", ",", ":", "]", ",", "np", ".", "diag", "(", "var", "[", "n", ",", ":", "]", ")", ",", "aevb_samples_per_mu", ")", "\n", "", "self", ".", "vaemodel", ".", "bgetlogvar", "=", "False", "\n", "\n", "# Store the predictions", "\n", "# The following does not has any effect for Cartesian coordinates.", "\n", "samplesoutaevb", "=", "convert_given_representation", "(", "samples", "=", "samples_aevb", ",", "coordrep", "=", "self", ".", "angulardata", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "output_dir", "+", "'/samples_aevb'", "+", "self", ".", "predprefix", "+", "'_'", "+", "self", ".", "postfix_setting", "+", "postsamplepostfix", "+", "'.txt'", ",", "\n", "samplesoutaevb", ")", "\n", "\n", "# On local machine only: Estimate properties directly.", "\n", "", "if", "postsamplepostfix", "==", "''", ":", "\n", "            ", "samples_name", "=", "'samples_aevb'", "+", "self", ".", "predprefix", "+", "'_'", "+", "self", ".", "postfix_setting", "+", "postsamplepostfix", "\n", "estimateProperties", "(", "samples_name", "=", "samples_name", ",", "cluster", "=", "self", ".", "bClusterND", ",", "datasetN", "=", "self", ".", "N", ",", "pathofsamples", "=", "self", ".", "output_dir", ",", "postS", "=", "self", ".", "uqoptions", ".", "npostsamples", ",", "peptide", "=", "self", ".", "name_peptide", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.visLatentTraining": [[1091, 1113], ["hasattr", "utils.loss_plot", "VAE_up.VAEpeptide.vaemodel.plotlatentrep", "VAE_up.VAEpeptide.vaemodel.plotlatentrep", "VAE_up.VAEpeptide.vaemodel.plotlatentrep", "VAE_up.VAEpeptide.vaemodel.plotlatentrep", "str", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "str", "str", "str", "str", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils.loss_plot", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEparent.plotlatentrep", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEparent.plotlatentrep", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEparent.plotlatentrep", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEparent.plotlatentrep"], ["", "", "def", "visLatentTraining", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "'''This visualizes the training process\n        :param epoch: Epoch just for labelling required.\n        :return:\n        '''", "\n", "# Visualize intermediate steps, i.e. the latent embedding and the ELBO", "\n", "if", "self", ".", "bvislatent_training", "and", "not", "epoch", "%", "200", ":", "\n", "            ", "if", "hasattr", "(", "self", ".", "vaemodel", ",", "'plotlatentrep'", ")", ":", "\n", "                ", "if", "self", ".", "gpu_mode", ":", "\n", "                    ", "self", ".", "vaemodel", ".", "plotlatentrep", "(", "x", "=", "Variable", "(", "self", ".", "data_tensor_vis_1527", ")", ".", "cuda", "(", ")", ",", "z_dim", "=", "self", ".", "z_dim", ",", "\n", "path", "=", "self", ".", "output_dir", ",", "postfix", "=", "'_'", "+", "str", "(", "epoch", ")", ",", "data_dir", "=", "self", ".", "data_dir", ",", "peptide", "=", "self", ".", "name_peptide", ")", "\n", "self", ".", "vaemodel", ".", "plotlatentrep", "(", "x", "=", "Variable", "(", "self", ".", "data_tensor_vis_1527", ")", ".", "cuda", "(", ")", ",", "z_dim", "=", "self", ".", "z_dim", ",", "\n", "path", "=", "self", ".", "output_dir", ",", "postfix", "=", "'_dat_'", "+", "str", "(", "epoch", ")", ",", "data_dir", "=", "self", ".", "data_dir", ",", "peptide", "=", "self", ".", "name_peptide", ",", "x_train", "=", "Variable", "(", "self", ".", "data_tensor", ")", ".", "cuda", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "vaemodel", ".", "plotlatentrep", "(", "x", "=", "Variable", "(", "self", ".", "data_tensor_vis_1527", ")", ",", "z_dim", "=", "self", ".", "z_dim", ",", "\n", "path", "=", "self", ".", "output_dir", ",", "postfix", "=", "'_'", "+", "str", "(", "epoch", ")", ",", "data_dir", "=", "self", ".", "data_dir", ",", "peptide", "=", "self", ".", "name_peptide", ")", "\n", "self", ".", "vaemodel", ".", "plotlatentrep", "(", "x", "=", "Variable", "(", "self", ".", "data_tensor_vis_1527", ")", ",", "z_dim", "=", "self", ".", "z_dim", ",", "\n", "path", "=", "self", ".", "output_dir", ",", "postfix", "=", "'_dat_'", "+", "str", "(", "epoch", ")", ",", "data_dir", "=", "self", ".", "data_dir", ",", "peptide", "=", "self", ".", "name_peptide", ",", "x_train", "=", "Variable", "(", "self", ".", "data_tensor", ")", ")", "\n", "\n", "", "utils", ".", "loss_plot", "(", "self", ".", "train_hist", ",", "\n", "self", ".", "output_dir", ",", "\n", "self", ".", "model_name", "+", "self", ".", "predprefix", "+", "'_'", "+", "str", "(", "epoch", ")", ",", "bvae", "=", "True", ",", "bintermediate", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.postprocessingALA15": [[1114, 1134], ["hasattr", "numpy.array", "VAE_up.VAEpeptide.vis_latentpredictions", "VAE_up.VAEpeptide.vaemodel.plotlatentrep", "VAE_up.VAEpeptide.vaemodel.plotlatentrep", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.vis_latentpredictions", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEparent.plotlatentrep", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEparent.plotlatentrep"], ["", "", "", "def", "postprocessingALA15", "(", "self", ",", "postsampid", "=", "None", ")", ":", "\n", "        ", "'''This function provides predictions given the trained model. In the case of \\dim(z) = 2,\n        further visualizations are issued automatically.\n        :param n_samples: Amount of requred samples of z \\sim p(z)\n        :param postsampid: Do no specify this, it is just required internally for sampling the posterior of the decoding\n        parametrization.\n        :return:\n        '''", "\n", "if", "hasattr", "(", "self", ".", "vaemodel", ",", "'plotlatentrep'", ")", "and", "postsampid", "==", "None", ":", "\n", "            ", "if", "self", ".", "gpu_mode", ":", "\n", "                ", "self", ".", "vaemodel", ".", "plotlatentrep", "(", "x", "=", "Variable", "(", "self", ".", "data_tensor_vis_1527", ")", ".", "cuda", "(", ")", ",", "z_dim", "=", "self", ".", "z_dim", ",", "\n", "path", "=", "self", ".", "output_dir", ",", "data_dir", "=", "self", ".", "data_dir", ",", "peptide", "=", "self", ".", "name_peptide", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "vaemodel", ".", "plotlatentrep", "(", "x", "=", "Variable", "(", "self", ".", "data_tensor_vis_1527", ")", ",", "z_dim", "=", "self", ".", "z_dim", ",", "path", "=", "self", ".", "output_dir", ",", "x_train", "=", "Variable", "(", "self", ".", "data_tensor", ")", ",", "data_dir", "=", "self", ".", "data_dir", ",", "peptide", "=", "self", ".", "name_peptide", ")", "\n", "\n", "# Visualize latent representation if and only if z_dim = 2", "\n", "", "", "if", "True", "and", "self", ".", "z_dim", "==", "2", "and", "postsampid", "==", "None", ":", "\n", "            ", "yborder", "=", "np", ".", "array", "(", "[", "4.", ",", "-", "4.", "]", ")", "\n", "# Create predictions for the latent representation", "\n", "self", ".", "vis_latentpredictions", "(", "yb", "=", "yborder", ",", "ny", "=", "81", ",", "path", "=", "self", ".", "output_dir", ")", "\n", "# Visualize the phi-psi landscape given the CVs - so for not possible", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.postprocessing": [[1139, 1193], ["numpy.array", "VAE_up.VAEpeptide.vis_latentpredictions", "VAE_up.VAEpeptide.vis_phipsilatent", "hasattr", "VAE_up.VAEpeptide.vaemodel.plotdecoder", "print", "hasattr", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "enumerate", "hasattr", "VAE_up.VAEpeptide.vaemodel.get_encoding_decoding_variance", "numpy.append", "numpy.savetxt", "VAE_up.VAEpeptide.vis_realizations", "VAE_up.TensorDatasetDataOnly", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "VAE_up.VAEpeptide.vaemodel.plotencoder", "print", "VAE_up.VAEpeptide.vaemodel.plotlatentrep", "VAE_up.VAEpeptide.vaemodel.plotlatentrep", "data.cuda.cuda.cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "str", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.vis_latentpredictions", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.vis_phipsilatent", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEparent.get_encoding_decoding_variance", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.vis_realizations", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEparent.plotlatentrep", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEparent.plotlatentrep"], ["", "", "def", "postprocessing", "(", "self", ",", "n_samples", "=", "4000", ",", "postsampid", "=", "None", ")", ":", "\n", "        ", "'''This function provides predictions given the trained model. In the case of \\dim(z) = 2,\n        further visualizations are issued automatically.\n        :param n_samples: Amount of required samples of z \\sim p(z)\n        :param postsampid: Do no specify this, it is just required internally for sampling the posterior of the decoding\n        parametrization.\n        :return:\n        '''", "\n", "\n", "# Visualize latent representation if and only if z_dim = 2", "\n", "if", "True", "and", "self", ".", "z_dim", "==", "2", "and", "postsampid", "==", "None", "and", "self", ".", "name_peptide", "==", "'ala_2'", ":", "\n", "            ", "yborder", "=", "np", ".", "array", "(", "[", "4.", ",", "-", "4.", "]", ")", "\n", "# create predictions for the latent representation", "\n", "self", ".", "vis_latentpredictions", "(", "yb", "=", "yborder", ",", "ny", "=", "81", ",", "path", "=", "self", ".", "output_dir", ")", "\n", "# Visualize the phi-psi landscape given the CVs", "\n", "self", ".", "vis_phipsilatent", "(", "path", "=", "self", ".", "output_dir", ")", "\n", "\n", "# Visualize mapping between the different layers", "\n", "# TODO Potentially also for VAE not only GAN.", "\n", "", "if", "hasattr", "(", "self", ".", "vaemodel", ",", "'plotdecoder'", ")", "and", "postsampid", "==", "None", "and", "self", ".", "name_peptide", "==", "'ala_2'", ":", "\n", "            ", "self", ".", "vaemodel", ".", "plotdecoder", "(", "n_samples", "=", "500", ",", "z_dim", "=", "self", ".", "z_dim", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'No visualization for decoder available.'", ")", "\n", "\n", "# Visualize the mapping from input to latent space", "\n", "# Not available for VAE.", "\n", "", "if", "False", "and", "hasattr", "(", "self", ".", "vaemodel", ",", "'plotencoder'", ")", "and", "postsampid", "==", "None", ":", "\n", "            ", "data_loader_visualization", "=", "DataLoader", "(", "TensorDatasetDataOnly", "(", "self", ".", "data_tensor", ")", ",", "\n", "batch_size", "=", "1527", ",", "\n", "shuffle", "=", "False", ",", "**", "self", ".", "kwargsdatloader", ")", "\n", "\n", "for", "index", ",", "data", "in", "enumerate", "(", "data_loader_visualization", ")", ":", "\n", "                ", "data", "=", "Variable", "(", "data", ")", "\n", "if", "self", ".", "gpu_mode", ":", "\n", "                    ", "data", "=", "data", ".", "cuda", "(", ")", "\n", "", "self", ".", "vaemodel", ".", "plotencoder", "(", "x", "=", "data", ",", "z_dim", "=", "self", ".", "z_dim", ",", "strindex", "=", "str", "(", "index", ")", ")", "\n", "", "", "elif", "postsampid", "==", "None", ":", "\n", "            ", "print", "(", "'No visualization for encoder available.'", ")", "\n", "\n", "", "if", "hasattr", "(", "self", ".", "vaemodel", ",", "'plotlatentrep'", ")", "and", "postsampid", "==", "None", ":", "\n", "            ", "if", "self", ".", "gpu_mode", ":", "\n", "                ", "self", ".", "vaemodel", ".", "plotlatentrep", "(", "x", "=", "Variable", "(", "self", ".", "data_tensor_vis_1527", ")", ".", "cuda", "(", ")", ",", "z_dim", "=", "self", ".", "z_dim", ",", "\n", "path", "=", "self", ".", "output_dir", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "vaemodel", ".", "plotlatentrep", "(", "x", "=", "Variable", "(", "self", ".", "data_tensor_vis_1527", ")", ",", "z_dim", "=", "self", ".", "z_dim", ",", "path", "=", "self", ".", "output_dir", ",", "x_train", "=", "Variable", "(", "self", ".", "data_tensor", ")", ")", "\n", "\n", "# store the variances of the test dataset", "\n", "", "varout", "=", "self", ".", "vaemodel", ".", "get_encoding_decoding_variance", "(", "x", "=", "Variable", "(", "self", ".", "data_tensor_vis_1527", ")", ")", "\n", "temp_norm", "=", "np", ".", "append", "(", "varout", "[", "'norm_enc'", "]", ",", "varout", "[", "'norm_dec'", "]", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "output_dir", "+", "'/normvar_enc_dec.txt'", ",", "temp_norm", ")", "\n", "\n", "# visualize realizations along the z_1 or z_2 axis to show that the variance captures", "\n", "", "if", "False", ":", "\n", "            ", "self", ".", "vis_realizations", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.selectdataset": [[1194, 1462], ["print", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "os.getcwd", "os.path.join", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "VAE_up.TensorDatasetDataOnly", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor.size", "torch.Tensor.size", "torch.Tensor.size", "torch.Tensor.size", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.loadtxt", "numpy.loadtxt"], "methods", ["None"], ["", "", "def", "selectdataset", "(", "self", ")", ":", "\n", "        ", "'''This function is a helper function for loading the desired dataset.\n        :return:\n        '''", "\n", "\n", "# Initialize peptide name - will be adjusted according dataset. This is the default value.", "\n", "self", ".", "name_peptide", "=", "'ala_2'", "\n", "\n", "# Data path", "\n", "if", "self", ".", "bClusterND", ":", "\n", "            ", "data_dir", "=", "'---'", "\n", "", "else", ":", "\n", "            ", "scwd", "=", "os", ".", "getcwd", "(", ")", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "scwd", ",", "'data_peptide'", ")", "\n", "#data_dir = '---'", "\n", "", "self", ".", "data_dir", "=", "data_dir", "\n", "\n", "# Is using angular data set, add postfix of the data", "\n", "# This is not scope of the work **paper_link** and therefore not content of the code.", "\n", "if", "self", ".", "angulardata", "==", "'ang'", ":", "\n", "            ", "angpostfix", "=", "'_ang'", "\n", "", "elif", "self", ".", "angulardata", "==", "'ang_augmented'", ":", "\n", "            ", "angpostfix", "=", "'_ang_augmented'", "\n", "", "elif", "self", ".", "angulardata", "==", "'ang_auggrouped'", ":", "\n", "            ", "angpostfix", "=", "'_ang_auggrouped'", "\n", "", "else", ":", "\n", "            ", "angpostfix", "=", "''", "\n", "\n", "", "if", "self", ".", "dataset", "==", "'m_1527'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_mixed_1527'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "1527", "\n", "", "elif", "self", ".", "dataset", "==", "'b1b2_1527'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_b1b2_1527'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'ab1_1527'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_ab1_1527'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'ab2_1527'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_ab2_1527'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'m_4004'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_mixed_4004'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "4004", "\n", "", "elif", "self", ".", "dataset", "==", "'m_102'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_mixed_102'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "102", "\n", "", "elif", "self", ".", "dataset", "==", "'m_262'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_mixed_262'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "262", "\n", "", "elif", "self", ".", "dataset", "==", "'m_52'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_mixed_52'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "52", "\n", "", "elif", "self", ".", "dataset", "==", "'ma_10'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_10'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "10", "\n", "", "elif", "self", ".", "dataset", "==", "'ma_50'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_50'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "50", "\n", "", "elif", "self", ".", "dataset", "==", "'ma_100'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_100'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "100", "\n", "", "elif", "self", ".", "dataset", "==", "'ma_200'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_200'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "200", "\n", "", "elif", "self", ".", "dataset", "==", "'ma_500'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_500'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "500", "\n", "", "elif", "self", ".", "dataset", "==", "'ma_1000'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_1000'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "1000", "\n", "", "elif", "self", ".", "dataset", "==", "'ma_1500'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_1500'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "1500", "\n", "", "elif", "self", ".", "dataset", "==", "'ma_4000'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_4000'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "4000", "\n", "", "elif", "self", ".", "dataset", "==", "'ma_13334'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_13334'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "13334", "\n", "", "elif", "self", ".", "dataset", "==", "'b1b2_4004'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_b1b2_4004'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'ab1_4004'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_ab1_4004'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'ab2_4004'", ":", "\n", "# 1527 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_ab2_4004'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'samples'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_samples'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'m_526'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_mixed_526'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "526", "\n", "", "elif", "self", ".", "dataset", "==", "'m_1001'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_mixed_1001'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "1001", "\n", "", "elif", "self", ".", "dataset", "==", "'m_10437'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_mixed_10537'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'a_1000'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_alpha_10000_sub_1000'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "foldername", "=", "'separate_1000'", "\n", "predictprefix", "=", "'_a'", "\n", "", "elif", "self", ".", "dataset", "==", "'a_10000'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_alpha_10000'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "foldername", "=", "'separate_10000'", "\n", "predictprefix", "=", "'_a'", "\n", "", "elif", "self", ".", "dataset", "==", "'b1_1000'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_beta1_10000_sub_1000'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "foldername", "=", "'separate_1000'", "\n", "predictprefix", "=", "'_b1'", "\n", "", "elif", "self", ".", "dataset", "==", "'b1_10000'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_beta1_10000'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "foldername", "=", "'separate_10000'", "\n", "predictprefix", "=", "'_b1'", "\n", "", "elif", "self", ".", "dataset", "==", "'b2_1000'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_beta2_10000_sub_1000'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "foldername", "=", "'separate_1000'", "\n", "predictprefix", "=", "'_b2'", "\n", "", "elif", "self", ".", "dataset", "==", "'b2_10000'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_beta2_10000'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "foldername", "=", "'separate_10000'", "\n", "predictprefix", "=", "'_b2'", "\n", "", "elif", "self", ".", "dataset", "==", "'a_500'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_alpha_10000_sub_500'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "foldername", "=", "'separate_500'", "\n", "predictprefix", "=", "'_a'", "\n", "", "elif", "self", ".", "dataset", "==", "'b1_500'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_beta1_10000_sub_500'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "foldername", "=", "'separate_500'", "\n", "predictprefix", "=", "'_b1'", "\n", "", "elif", "self", ".", "dataset", "==", "'b2_500'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-2/dataset_beta2_10000_sub_500'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "foldername", "=", "'separate_500'", "\n", "predictprefix", "=", "'_b2'", "\n", "", "elif", "self", ".", "dataset", "==", "'m_ala_15'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-15/dataset_ala_15'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "2000", "\n", "self", ".", "name_peptide", "=", "'ala_15'", "\n", "", "elif", "self", ".", "dataset", "==", "'m_100_ala_15'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-15/dataset_ala_15_100'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "100", "\n", "self", ".", "name_peptide", "=", "'ala_15'", "\n", "", "elif", "self", ".", "dataset", "==", "'m_200_ala_15'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-15/dataset_ala_15_200'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "200", "\n", "self", ".", "name_peptide", "=", "'ala_15'", "\n", "", "elif", "self", ".", "dataset", "==", "'m_300_ala_15'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-15/dataset_ala_15_300'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "300", "\n", "self", ".", "name_peptide", "=", "'ala_15'", "\n", "", "elif", "self", ".", "dataset", "==", "'m_500_ala_15'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-15/dataset_ala_15_500'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "500", "\n", "self", ".", "name_peptide", "=", "'ala_15'", "\n", "", "elif", "self", ".", "dataset", "==", "'m_1500_ala_15'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-15/dataset_ala_15_1500'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "1500", "\n", "self", ".", "name_peptide", "=", "'ala_15'", "\n", "", "elif", "self", ".", "dataset", "==", "'m_3000_ala_15'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-15/dataset_ala_15_3000'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "3000", "\n", "self", ".", "name_peptide", "=", "'ala_15'", "\n", "", "elif", "self", ".", "dataset", "==", "'m_5000_ala_15'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-15/dataset_ala_15_5000'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "5000", "\n", "self", ".", "name_peptide", "=", "'ala_15'", "\n", "", "elif", "self", ".", "dataset", "==", "'m_10000_ala_15'", ":", "\n", "# 526 x 66", "\n", "            ", "data_tensor", "=", "torch", ".", "Tensor", "(", "np", ".", "loadtxt", "(", "\n", "data_dir", "+", "'/ala-15/dataset_ala_15_10000'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "self", ".", "N", "=", "10000", "\n", "self", ".", "name_peptide", "=", "'ala_15'", "\n", "\n", "", "print", "(", "'dataset size: {}'", ".", "format", "(", "data_tensor", ".", "size", "(", ")", ")", ")", "\n", "\n", "self", ".", "kwargsdatloader", "=", "{", "'num_workers'", ":", "2", ",", "\n", "'pin_memory'", ":", "True", "}", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "{", "}", "\n", "\n", "self", ".", "data_tensor", "=", "data_tensor", "\n", "self", ".", "data_loader", "=", "DataLoader", "(", "TensorDatasetDataOnly", "(", "data_tensor", ")", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "**", "self", ".", "kwargsdatloader", ")", "\n", "\n", "# for visualization purposes", "\n", "if", "self", ".", "dataset", "==", "'m_1527'", ":", "\n", "            ", "self", ".", "data_tensor_vis_1527", "=", "self", ".", "data_tensor", "\n", "", "elif", "'ala_15'", "not", "in", "self", ".", "dataset", ":", "\n", "            ", "self", ".", "data_tensor_vis_1527", "=", "torch", ".", "Tensor", "(", "\n", "np", ".", "loadtxt", "(", "data_dir", "+", "'/ala-2/dataset_mixed_1527'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "", "elif", "'ala_15'", "in", "self", ".", "dataset", ":", "\n", "            ", "self", ".", "data_tensor_vis_1527", "=", "torch", ".", "Tensor", "(", "\n", "np", ".", "loadtxt", "(", "data_dir", "+", "'/ala-15/dataset_ala_15_1500'", "+", "angpostfix", "+", "'.txt'", ")", ".", "T", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.checkandcreatefolder": [[212, 226], ["os.path.exists", "os.makedirs", "datetime.datetime.now().strftime", "os.path.join", "os.makedirs", "datetime.datetime.now"], "function", ["None"], ["", "", "def", "checkandcreatefolder", "(", "dir", ")", ":", "\n", "    ", "'''This function checks if a directory exists, if not it is created augmented by a date and time dependent postfix.\n\n    :param dir: Complete path of the directory\n    :return: Actual directory created.\n    '''", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dir", ")", "\n", "diraug", "=", "dir", "\n", "", "else", ":", "\n", "        ", "datetimepostfix", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y-%m-%d_%H-%M-%S'", ")", "\n", "diraug", "=", "os", ".", "path", ".", "join", "(", "dir", ",", "datetimepostfix", ")", "\n", "os", ".", "makedirs", "(", "diraug", ")", "\n", "", "return", "diraug", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.count_parameters": [[227, 234], ["sum", "p.numel", "model.parameters"], "function", ["None"], ["", "def", "count_parameters", "(", "model", ")", ":", "\n", "    ", "'''This function counts the parameters of a PyTorch model.\n\n    :param model: PyTorch model.\n    :return: Number of parameters requiring gradient.\n    '''", "\n", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEparent.__init__": [[49, 66], ["torch.nn.Module.__init__", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.SELU", "torch.nn.SELU", "torch.nn.Tanh", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "x_dim", ",", "bfixlogvar", ")", ":", "\n", "        ", "super", "(", "VAEparent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "bplotdecoder", "=", "False", "\n", "self", ".", "bplotencoder", "=", "False", "\n", "self", ".", "bgetlogvar", "=", "False", "\n", "\n", "self", ".", "bfixlogvar", "=", "bfixlogvar", "\n", "\n", "self", ".", "x_dim", "=", "x_dim", "\n", "self", ".", "z_dim", "=", "args", ".", "z_dim", "\n", "\n", "self", ".", "listenc", "=", "[", "]", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "selu", "=", "nn", ".", "SELU", "(", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEparent.get_encoding_decoding_variance": [[67, 81], ["VAEmodel.VAEparent.encode", "VAEmodel.VAEparent.decode", "logvar_pred.exp", "logvar.exp", "logvar_pred.exp.norm", "logvar.exp.norm", "logvar.exp.norm.data.numpy", "logvar_pred.exp.norm.data.numpy"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.encode", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.decode"], ["", "def", "get_encoding_decoding_variance", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "mu", ",", "logvar", "=", "self", ".", "encode", "(", "x", ")", "\n", "btemp", "=", "self", ".", "bgetlogvar", "\n", "self", ".", "bgetlogvar", "=", "True", "\n", "mu_pred", ",", "logvar_pred", "=", "self", ".", "decode", "(", "mu", ")", "\n", "self", ".", "bgetlogvar", "=", "btemp", "\n", "\n", "var_decoder", "=", "logvar_pred", ".", "exp", "(", ")", "\n", "var_encoder", "=", "logvar", ".", "exp", "(", ")", "\n", "l2norm_var_dec", "=", "var_decoder", ".", "norm", "(", ")", "\n", "l2norm_var_enc", "=", "var_encoder", ".", "norm", "(", ")", "\n", "\n", "return", "{", "'var_encoder'", ":", "var_encoder", ",", "'var_decoder'", ":", "var_decoder", ",", "'norm_enc'", ":", "l2norm_var_enc", ".", "data", ".", "numpy", "(", ")", ",", "'norm_dec'", ":", "l2norm_var_dec", ".", "data", ".", "numpy", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEparent.plotlatentrep": [[82, 321], ["VAEmodel.VAEparent.encode", "mu.data.cpu().numpy", "getcolorcode1527", "getcolorcodeALA15", "matplotlib.figure", "matplotlib.figure", "matplotlib.subplots", "matplotlib.subplots", "ax.set_xlabel", "ax.set_ylabel", "ax.grid", "ax.set_axisbelow", "matplotlib.close", "matplotlib.close", "mu.data.cpu", "numpy.random.randn", "ax.scatter", "patchlist.append", "ax.scatter", "ax.scatter", "ax.scatter", "an.append", "an.append", "range", "VAEmodel.VAEparent.encode", "mu_train.data.cpu().numpy", "ax.scatter", "patchlist.append", "ax.legend", "ax.legend", "ax.set_ylim", "ax.set_xlim", "numpy.arange", "ax.xaxis.set_ticks", "ax.yaxis.set_ticks", "f.savefig", "matplotlib.subplots", "matplotlib.subplots", "range", "matplotlib.close", "matplotlib.close", "print", "os.path.join", "ax.scatter", "ax.annotate", "ax.annotate", "len", "an.append", "ax.scatter", "ax.set_ylim", "ax.set_xlim", "numpy.arange", "ax.xaxis.set_ticks", "ax.yaxis.set_ticks", "f.savefig", "ax.set_ylim", "ax.set_xlim", "f.savefig", "f.suptitle", "numpy.random.randn", "range", "patchlist.append", "ax.scatter", "ax.scatter", "ax.scatter", "range", "an.append", "an.append", "range", "range", "f.savefig", "range", "ax.annotate", "mu_train.data.cpu", "range", "range", "ax.annotate", "ax.annotate", "len", "an.append", "f.savefig", "f.savefig", "dict", "ax.annotate", "ax[].set_xlabel", "ax[].set_ylabel", "ax[].set_xlim", "ax[].set_ylim", "ax[].grid", "dict", "dict", "str", "ax[].scatter", "dict", "ax[].scatter", "dict", "dict", "str", "ax[].scatter", "range"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.encode", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.getcolorcode1527", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.getcolorcodeALA15", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.encode"], ["", "def", "plotlatentrep", "(", "self", ",", "x", ",", "z_dim", ",", "path", ",", "postfix", "=", "''", ",", "iter", "=", "-", "1", ",", "x_curr", "=", "0", ",", "y_curr", "=", "0", ",", "nprov", "=", "False", ",", "normaltemp", "=", "0", ",", "x_train", "=", "None", ",", "peptide", "=", "'ala_2'", ",", "data_dir", "=", "None", ")", ":", "\n", "\n", "        ", "baddactfctannotation", "=", "False", "\n", "sizedataset", "=", "x", ".", "shape", "[", "0", "]", "\n", "\n", "mu", ",", "logvar", "=", "self", ".", "encode", "(", "x", ")", "\n", "\n", "munp", "=", "mu", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "ssize", "=", "20", "\n", "\n", "# get the color code, markers, and legend addons", "\n", "if", "peptide", "is", "'ala_2'", ":", "\n", "            ", "from", "utils_peptide", "import", "getcolorcode1527", "\n", "colcode", ",", "markers", ",", "patchlist", "=", "getcolorcode1527", "(", "ssize", "=", "ssize", ")", "\n", "", "else", ":", "\n", "            ", "from", "utils_peptide", "import", "getcolorcodeALA15", "\n", "colcode", ",", "markers", ",", "patchlist", ",", "alphaPerSample", "=", "getcolorcodeALA15", "(", "ramapath", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'ala-15'", ")", ",", "\n", "ssize", "=", "ssize", ",", "N", "=", "sizedataset", ")", "\n", "\n", "", "if", "z_dim", "==", "2", ":", "\n", "\n", "#fontloc = {'weight': 'normal', 'size': 10}", "\n", "#matplotlib.rc('font', **fontloc)", "\n", "\n", "            ", "plt", ".", "figure", "(", "1", ")", "\n", "f", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "\n", "iA", "=", "29", "\n", "iB1", "=", "932", "\n", "iB2", "=", "566", "\n", "\n", "# plot N(0,I)", "\n", "#n_samples_normal = iA + iB1 + iB2", "\n", "n_samples_normal", "=", "4000", "\n", "# Plot some samples from p(z)?", "\n", "if", "not", "nprov", ":", "\n", "                ", "normal", "=", "np", ".", "random", ".", "randn", "(", "n_samples_normal", ",", "2", ")", "\n", "", "else", ":", "\n", "                ", "normal", "=", "normaltemp", "\n", "\n", "# This is deprecated.", "\n", "", "if", "False", ":", "\n", "                ", "normalpatch", "=", "ax", ".", "scatter", "(", "normal", "[", ":", ",", "0", "]", ",", "normal", "[", ":", ",", "1", "]", ",", "c", "=", "'g'", ",", "marker", "=", "'.'", ",", "s", "=", "ssize", ",", "alpha", "=", "alpha", ",", "\n", "label", "=", "r'$\\boldsymbol{z} \\sim \\mathcal N (\\boldsymbol{0},\\boldsymbol{I})$'", ")", "\n", "#h,l= ax.get_legend_handles_labels()", "\n", "patchlist", ".", "append", "(", "normalpatch", ")", "\n", "\n", "", "if", "peptide", "is", "'ala_2'", ":", "\n", "# Modify scatter points according their atomistic conformation vor visualization purposes.", "\n", "                ", "x", ",", "y", "=", "munp", "[", "0", ":", "iA", ",", "0", "]", ",", "munp", "[", "0", ":", "iA", ",", "1", "]", "\n", "ax", ".", "scatter", "(", "x", ",", "y", ",", "c", "=", "colcode", "[", "0", ":", "iA", "]", ",", "marker", "=", "markers", "[", "0", "]", ",", "s", "=", "ssize", ")", "\n", "x", ",", "y", "=", "munp", "[", "iA", ":", "iA", "+", "iB1", ",", "0", "]", ",", "munp", "[", "iA", ":", "iA", "+", "iB1", ",", "1", "]", "\n", "ax", ".", "scatter", "(", "x", ",", "y", ",", "c", "=", "colcode", "[", "iA", ":", "iA", "+", "iB1", "]", ",", "marker", "=", "markers", "[", "1", "]", ",", "s", "=", "ssize", ")", "\n", "x", ",", "y", "=", "munp", "[", "iA", "+", "iB1", ":", "iA", "+", "iB1", "+", "iB2", ",", "0", "]", ",", "munp", "[", "iA", "+", "iB1", ":", "iA", "+", "iB1", "+", "iB2", ",", "1", "]", "\n", "ax", ".", "scatter", "(", "x", ",", "y", ",", "c", "=", "colcode", "[", "iA", "+", "iB1", ":", "iA", "+", "iB1", "+", "iB2", "]", ",", "marker", "=", "markers", "[", "2", "]", ",", "s", "=", "ssize", ")", "\n", "", "else", ":", "\n", "# In case of ALA15 the color coding is obtained according remarks in **paper**.", "\n", "                ", "x", ",", "y", "=", "munp", "[", ":", ",", "0", "]", ",", "munp", "[", ":", ",", "1", "]", "\n", "[", "ax", ".", "scatter", "(", "x", "[", "i", "]", ",", "y", "[", "i", "]", ",", "c", "=", "colcode", "[", "i", ",", ":", "]", ",", "s", "=", "10", ",", "alpha", "=", "alphaPerSample", "[", "i", "]", ")", "for", "i", "in", "range", "(", "sizedataset", ")", "]", "\n", "\n", "", "if", "baddactfctannotation", ":", "\n", "# This would add a text field with activation functions used.", "\n", "\n", "# List of encoder activation functions", "\n", "                ", "an", "=", "[", "]", "\n", "an", ".", "append", "(", "ax", ".", "annotate", "(", "'Encoder activations:'", ",", "xy", "=", "(", "-", "2.", ",", "2.7", ")", ",", "xycoords", "=", "\"data\"", ",", "\n", "va", "=", "\"center\"", ",", "ha", "=", "\"center\"", ")", ")", "\n", "an", ".", "append", "(", "ax", ".", "annotate", "(", "self", ".", "listenc", "[", "0", "]", ",", "xy", "=", "(", "1", ",", "0.5", ")", ",", "xycoords", "=", "an", "[", "0", "]", ",", "# (1,0.5) of the an1's bbox", "\n", "xytext", "=", "(", "20", ",", "0", ")", ",", "textcoords", "=", "\"offset points\"", ",", "\n", "va", "=", "\"center\"", ",", "ha", "=", "\"left\"", ",", "\n", "bbox", "=", "dict", "(", "boxstyle", "=", "\"round\"", ",", "fc", "=", "\"None\"", ")", ")", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "self", ".", "listenc", ")", ")", ":", "\n", "                    ", "an", ".", "append", "(", "ax", ".", "annotate", "(", "self", ".", "listenc", "[", "i", "]", ",", "xy", "=", "(", "1", ",", "0.5", ")", ",", "xycoords", "=", "an", "[", "i", "]", ",", "# (1,0.5) of the an1's bbox", "\n", "xytext", "=", "(", "20", ",", "0", ")", ",", "textcoords", "=", "\"offset points\"", ",", "\n", "va", "=", "\"center\"", ",", "ha", "=", "\"left\"", ",", "\n", "bbox", "=", "dict", "(", "boxstyle", "=", "\"round\"", ",", "fc", "=", "\"None\"", ")", ",", "\n", "arrowprops", "=", "dict", "(", "arrowstyle", "=", "\"<-\"", ")", ")", ")", "\n", "\n", "", "", "if", "x_train", "is", "not", "None", ":", "\n", "\n", "# encode the training data", "\n", "                ", "mu_train", ",", "logvar_train", "=", "self", ".", "encode", "(", "x_train", ")", "\n", "munp_train", "=", "mu_train", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "leng_train", "=", "munp_train", ".", "shape", "[", "0", "]", "\n", "# plot the training data", "\n", "if", "iter", ">=", "0", ":", "\n", "                    ", "rnd", "=", "False", "\n", "a_training_data", "=", "0.6", "\n", "col_training_data", "=", "'C4'", "\n", "", "else", ":", "\n", "                    ", "rnd", "=", "True", "\n", "a_training_data", "=", "0.7", "\n", "col_training_data", "=", "'y'", "\n", "\n", "", "train_patch", "=", "ax", ".", "scatter", "(", "munp_train", "[", ":", ",", "0", "]", ",", "munp_train", "[", ":", ",", "1", "]", ",", "\n", "c", "=", "col_training_data", ",", "marker", "=", "'d'", ",", "s", "=", "ssize", "*", "0.9", ",", "alpha", "=", "a_training_data", ",", "\n", "label", "=", "r'Training Data'", ")", "\n", "patchlist", ".", "append", "(", "train_patch", ")", "\n", "\n", "#ax.set_ylim([-3, 3])", "\n", "#ax.set_xlim([-3, 3])", "\n", "", "ax", ".", "set_xlabel", "(", "r'$z_1$'", ")", "\n", "ax", ".", "set_ylabel", "(", "r'$z_2$'", ")", "\n", "ax", ".", "grid", "(", "ls", "=", "'dashed'", ")", "\n", "ax", ".", "set_axisbelow", "(", "True", ")", "\n", "#ax.legend(handles=patchlist, loc=1)", "\n", "if", "x_train", "is", "None", ":", "\n", "                ", "ax", ".", "legend", "(", "handles", "=", "patchlist", ",", "loc", "=", "'upper center'", ",", "bbox_to_anchor", "=", "(", "0.5", ",", "-", "0.15", ")", ",", "\n", "fancybox", "=", "False", ",", "shadow", "=", "False", ",", "ncol", "=", "4", ")", "\n", "", "else", ":", "\n", "                ", "ax", ".", "legend", "(", "handles", "=", "patchlist", ",", "loc", "=", "'upper center'", ",", "bbox_to_anchor", "=", "(", "0.5", ",", "-", "0.15", ")", ",", "\n", "fancybox", "=", "False", ",", "shadow", "=", "False", ",", "ncol", "=", "3", ")", "\n", "\n", "", "if", "postfix", "==", "''", "and", "iter", "<", "0", ":", "\n", "                ", "ax", ".", "set_ylim", "(", "[", "-", "4", ",", "4", "]", ")", "\n", "ax", ".", "set_xlim", "(", "[", "-", "4", ",", "4", "]", ")", "\n", "\n", "ticksstep", "=", "1.", "\n", "ticks", "=", "np", ".", "arange", "(", "-", "4", ",", "4", "+", "ticksstep", ",", "step", "=", "ticksstep", ")", "\n", "ax", ".", "xaxis", ".", "set_ticks", "(", "ticks", ")", "\n", "ax", ".", "yaxis", ".", "set_ticks", "(", "ticks", ")", "\n", "\n", "f", ".", "savefig", "(", "path", "+", "'/lat_rep.pdf'", ",", "bbox_inches", "=", "'tight'", ")", "#, transparent=True)", "\n", "", "elif", "postfix", "==", "''", "and", "iter", ">=", "0", ":", "\n", "                ", "ax", ".", "scatter", "(", "x_curr", ",", "y_curr", ",", "c", "=", "'y'", ",", "marker", "=", "'*'", ",", "s", "=", "ssize", "*", "35", ")", "\n", "ax", ".", "set_ylim", "(", "[", "-", "4", ",", "4", "]", ")", "\n", "ax", ".", "set_xlim", "(", "[", "-", "4", ",", "4", "]", ")", "\n", "\n", "ticksstep", "=", "1.", "\n", "ticks", "=", "np", ".", "arange", "(", "-", "4", ",", "4", "+", "ticksstep", ",", "step", "=", "ticksstep", ")", "\n", "ax", ".", "xaxis", ".", "set_ticks", "(", "ticks", ")", "\n", "ax", ".", "yaxis", ".", "set_ticks", "(", "ticks", ")", "\n", "\n", "f", ".", "savefig", "(", "path", "+", "'/lat_rep_vis_'", "+", "str", "(", "iter", ")", "+", "'.png'", ",", "bbox_inches", "=", "'tight'", ")", "# , transparent=True)", "\n", "return", "normal", "\n", "", "else", ":", "\n", "                ", "ax", ".", "set_ylim", "(", "[", "-", "3.5", ",", "3.5", "]", ")", "\n", "ax", ".", "set_xlim", "(", "[", "-", "3.5", ",", "3.5", "]", ")", "\n", "f", ".", "savefig", "(", "path", "+", "'/lat_rep'", "+", "postfix", "+", "'.png'", ",", "bbox_inches", "=", "'tight'", ")", "# , transparent=True)", "\n", "", "plt", ".", "close", "(", ")", "\n", "", "elif", "peptide", "is", "'ala_15'", ":", "\n", "\n", "            ", "f", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "z_dim", "-", "1", ",", "ncols", "=", "z_dim", "-", "1", ",", "sharey", "=", "True", ",", "sharex", "=", "True", ")", "\n", "\n", "# This title is just valid if we use no training data different from the test data.", "\n", "if", "x_train", "is", "None", ":", "\n", "                ", "f", ".", "suptitle", "(", "r'AEVB: Encoded representation of training data: $\\boldsymbol{\\mu}(\\boldsymbol{x}^{(i)})$'", ")", "\n", "\n", "", "iA", "=", "29", "\n", "iB1", "=", "932", "\n", "iB2", "=", "566", "\n", "\n", "# plot N(0,I)", "\n", "n_samples_normal", "=", "4000", "\n", "if", "not", "nprov", ":", "\n", "                ", "normal", "=", "np", ".", "random", ".", "randn", "(", "n_samples_normal", ",", "z_dim", ")", "\n", "", "else", ":", "\n", "                ", "normal", "=", "normaltemp", "\n", "\n", "#if x_train is None:", "\n", "# deprecated", "\n", "", "if", "False", ":", "\n", "                ", "for", "i", "in", "range", "(", "z_dim", "-", "1", ")", ":", "\n", "                    ", "for", "j", "in", "range", "(", "i", ",", "z_dim", "-", "1", ")", ":", "\n", "                        ", "if", "not", "i", "==", "(", "j", "+", "1", ")", ":", "\n", "                            ", "normalpatch", "=", "ax", "[", "i", ",", "j", "]", ".", "scatter", "(", "normal", "[", ":", ",", "i", "]", ",", "normal", "[", ":", ",", "j", "+", "1", "]", ",", "c", "=", "'g'", ",", "marker", "=", "'.'", ",", "s", "=", "ssize", ",", "alpha", "=", "alpha", ",", "\n", "label", "=", "r'$\\boldsymbol{z} \\sim \\mathcal N (\\boldsymbol{0},\\boldsymbol{I})$'", ")", "\n", "#h,l= ax.get_legend_handles_labels()", "\n", "", "", "", "patchlist", ".", "append", "(", "normalpatch", ")", "\n", "\n", "", "if", "peptide", "is", "'ala_2'", ":", "\n", "                ", "x", ",", "y", "=", "munp", "[", "0", ":", "iA", ",", "0", "]", ",", "munp", "[", "0", ":", "iA", ",", "1", "]", "\n", "ax", ".", "scatter", "(", "x", ",", "y", ",", "c", "=", "colcode", "[", "0", ":", "iA", "]", ",", "marker", "=", "markers", "[", "0", "]", ",", "s", "=", "ssize", ")", "\n", "x", ",", "y", "=", "munp", "[", "iA", ":", "iA", "+", "iB1", ",", "0", "]", ",", "munp", "[", "iA", ":", "iA", "+", "iB1", ",", "1", "]", "\n", "ax", ".", "scatter", "(", "x", ",", "y", ",", "c", "=", "colcode", "[", "iA", ":", "iA", "+", "iB1", "]", ",", "marker", "=", "markers", "[", "1", "]", ",", "s", "=", "ssize", ")", "\n", "x", ",", "y", "=", "munp", "[", "iA", "+", "iB1", ":", "iA", "+", "iB1", "+", "iB2", ",", "0", "]", ",", "munp", "[", "iA", "+", "iB1", ":", "iA", "+", "iB1", "+", "iB2", ",", "1", "]", "\n", "ax", ".", "scatter", "(", "x", ",", "y", ",", "c", "=", "colcode", "[", "iA", "+", "iB1", ":", "iA", "+", "iB1", "+", "iB2", "]", ",", "marker", "=", "markers", "[", "2", "]", ",", "s", "=", "ssize", ")", "\n", "", "else", ":", "\n", "                ", "for", "i", "in", "range", "(", "z_dim", "-", "1", ")", ":", "\n", "                    ", "for", "j", "in", "range", "(", "i", ",", "z_dim", "-", "1", ")", ":", "\n", "                        ", "if", "not", "i", "==", "(", "j", "+", "1", ")", ":", "\n", "                            ", "x", ",", "y", "=", "munp", "[", ":", ",", "i", "]", ",", "munp", "[", ":", ",", "j", "+", "1", "]", "\n", "#[(x * 1.0 / N, 1., 1.) for x in range(N)]", "\n", "if", "z_dim", ">", "4", ":", "\n", "                                ", "ax", "[", "i", ",", "j", "]", ".", "scatter", "(", "x", ",", "y", ",", "c", "=", "colcode", ",", "s", "=", "10", ")", "\n", "", "else", ":", "\n", "                                ", "[", "ax", "[", "i", ",", "j", "]", ".", "scatter", "(", "x", "[", "l", "]", ",", "y", "[", "l", "]", ",", "c", "=", "colcode", "[", "l", ",", ":", "]", ",", "s", "=", "10", ",", "alpha", "=", "alphaPerSample", "[", "l", "]", ")", "for", "l", "in", "range", "(", "sizedataset", ")", "]", "\n", "#ax.scatter(x, y, c=colcode, s=10)", "\n", "# TODO IMPLEMENT THIS FOR VAE", "\n", "", "", "", "", "", "if", "False", "and", "baddactfctannotation", ":", "\n", "# list of encoder activation functions", "\n", "                ", "an", "=", "[", "]", "\n", "an", ".", "append", "(", "ax", ".", "annotate", "(", "'Encoder activations:'", ",", "xy", "=", "(", "-", "2.", ",", "2.7", ")", ",", "xycoords", "=", "\"data\"", ",", "\n", "va", "=", "\"center\"", ",", "ha", "=", "\"center\"", ")", ")", "\n", "an", ".", "append", "(", "ax", ".", "annotate", "(", "self", ".", "listenc", "[", "0", "]", ",", "xy", "=", "(", "1", ",", "0.5", ")", ",", "xycoords", "=", "an", "[", "0", "]", ",", "# (1,0.5) of the an1's bbox", "\n", "xytext", "=", "(", "20", ",", "0", ")", ",", "textcoords", "=", "\"offset points\"", ",", "\n", "va", "=", "\"center\"", ",", "ha", "=", "\"left\"", ",", "\n", "bbox", "=", "dict", "(", "boxstyle", "=", "\"round\"", ",", "fc", "=", "\"None\"", ")", ")", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "self", ".", "listenc", ")", ")", ":", "\n", "                    ", "an", ".", "append", "(", "ax", ".", "annotate", "(", "self", ".", "listenc", "[", "i", "]", ",", "xy", "=", "(", "1", ",", "0.5", ")", ",", "xycoords", "=", "an", "[", "i", "]", ",", "# (1,0.5) of the an1's bbox", "\n", "xytext", "=", "(", "20", ",", "0", ")", ",", "textcoords", "=", "\"offset points\"", ",", "\n", "va", "=", "\"center\"", ",", "ha", "=", "\"left\"", ",", "\n", "bbox", "=", "dict", "(", "boxstyle", "=", "\"round\"", ",", "fc", "=", "\"None\"", ")", ",", "\n", "arrowprops", "=", "dict", "(", "arrowstyle", "=", "\"<-\"", ")", ")", ")", "\n", "# va=\"center\", ha=\"left\",", "\n", "\n", "#ax.set_ylim([-3, 3])", "\n", "#ax.set_xlim([-3, 3])", "\n", "", "", "for", "i", "in", "range", "(", "z_dim", "-", "1", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "z_dim", "-", "1", ")", ":", "\n", "                    ", "if", "not", "i", "==", "(", "j", "+", "1", ")", ":", "\n", "                        ", "ax", "[", "i", ",", "j", "]", ".", "set_xlabel", "(", "r'$z_%d$'", "%", "i", ")", "\n", "ax", "[", "i", ",", "j", "]", ".", "set_ylabel", "(", "r'$z_%d$'", "%", "j", ")", "\n", "ax", "[", "i", ",", "j", "]", ".", "set_xlim", "(", "[", "-", "5", ",", "5", "]", ")", "\n", "ax", "[", "i", ",", "j", "]", ".", "set_ylim", "(", "[", "-", "5", ",", "5", "]", ")", "\n", "ax", "[", "i", ",", "j", "]", ".", "grid", "(", "ls", "=", "'dashed'", ")", "\n", "\n", "", "", "", "if", "postfix", "==", "''", "and", "iter", "<", "0", ":", "\n", "#ax.set_ylim([-4, 4])", "\n", "#ax.set_xlim([-4, 4])", "\n", "#ticksstep = 1.", "\n", "#ticks = np.arange(-4, 4 + ticksstep, step=ticksstep)", "\n", "#ax.xaxis.set_ticks(ticks)", "\n", "#ax.yaxis.set_ticks(ticks)", "\n", "                ", "f", ".", "savefig", "(", "path", "+", "'/lat_rep.pdf'", ",", "bbox_inches", "=", "'tight'", ")", "#, transparent=True)", "\n", "", "elif", "postfix", "==", "''", "and", "iter", ">=", "0", ":", "\n", "#ax.scatter(x_curr, y_curr, c='y', marker='*', s=ssize*35)", "\n", "#ax.set_ylim([-4, 4])", "\n", "#ax.set_xlim([-4, 4])", "\n", "                ", "f", ".", "savefig", "(", "path", "+", "'/lat_rep_vis_'", "+", "str", "(", "iter", ")", "+", "'.png'", ",", "bbox_inches", "=", "'tight'", ")", "# , transparent=True)", "\n", "return", "normal", "\n", "", "else", ":", "\n", "#ax.set_ylim([-3.5, 3.5])", "\n", "#ax.set_xlim([-3.5, 3.5])", "\n", "                ", "f", ".", "savefig", "(", "path", "+", "'/lat_rep'", "+", "postfix", "+", "'.png'", ",", "bbox_inches", "=", "'tight'", ")", "# , transparent=True)", "\n", "", "plt", ".", "close", "(", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Warining: Representation of data in latent space not possible: z_dim is no 2'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.__init__": [[324, 350], ["VAEmodel.VAEparent.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "hasattr", "torch.nn.Linear", "torch.nn.Linear", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "x_dim", ",", "bfixlogvar", ")", ":", "\n", "        ", "super", "(", "VAEmod", ",", "self", ")", ".", "__init__", "(", "args", ",", "x_dim", ",", "bfixlogvar", ")", "\n", "\n", "# work with independent variance of predictive model", "\n", "if", "self", ".", "bfixlogvar", ":", "\n", "            ", "self", ".", "dec_logvar", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "x_dim", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n", "", "h1_dim", "=", "50", "\n", "h11_dim", "=", "100", "\n", "h12_dim", "=", "100", "\n", "\n", "# encoder", "\n", "self", ".", "enc_fc10", "=", "nn", ".", "Linear", "(", "x_dim", ",", "h12_dim", ")", "\n", "self", ".", "enc_fc11", "=", "nn", ".", "Linear", "(", "h12_dim", ",", "h11_dim", ")", "\n", "self", ".", "enc_fc12", "=", "nn", ".", "Linear", "(", "h11_dim", ",", "h1_dim", ")", "\n", "self", ".", "enc_fc21", "=", "nn", ".", "Linear", "(", "h1_dim", ",", "self", ".", "z_dim", ")", "\n", "self", ".", "enc_fc22", "=", "nn", ".", "Linear", "(", "h1_dim", ",", "self", ".", "z_dim", ")", "\n", "\n", "# decoder", "\n", "self", ".", "dec_fc30", "=", "nn", ".", "Linear", "(", "self", ".", "z_dim", ",", "h1_dim", ")", "\n", "self", ".", "dec_fc31", "=", "nn", ".", "Linear", "(", "h1_dim", ",", "h11_dim", ")", "\n", "self", ".", "dec_fc32", "=", "nn", ".", "Linear", "(", "h11_dim", ",", "h12_dim", ")", "\n", "self", ".", "dec_fc4", "=", "nn", ".", "Linear", "(", "h12_dim", ",", "x_dim", ")", "\n", "\n", "if", "not", "hasattr", "(", "self", ",", "'dec_logvar'", ")", ":", "\n", "            ", "self", ".", "dec_fc5", "=", "nn", ".", "Linear", "(", "h12_dim", ",", "x_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.encode": [[351, 361], ["VAEmodel.VAEmod.selu", "VAEmodel.VAEmod.selu", "torch.logsigmoid", "torch.logsigmoid", "VAEmodel.VAEmod.enc_fc21", "VAEmodel.VAEmod.enc_fc22", "VAEmodel.VAEmod.enc_fc10", "VAEmodel.VAEmod.enc_fc11", "VAEmodel.VAEmod.enc_fc12"], "methods", ["None"], ["", "", "def", "encode", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "self", ".", "listenc", "=", "[", "'selu'", ",", "'selu'", ",", "'logsig'", "]", "\n", "\n", "if", "True", ":", "\n", "            ", "h10", "=", "self", ".", "selu", "(", "self", ".", "enc_fc10", "(", "x", ")", ")", "\n", "h11", "=", "self", ".", "selu", "(", "self", ".", "enc_fc11", "(", "h10", ")", ")", "\n", "h1", "=", "F", ".", "logsigmoid", "(", "self", ".", "enc_fc12", "(", "h11", ")", ")", "\n", "\n", "", "return", "self", ".", "enc_fc21", "(", "h1", ")", ",", "self", ".", "enc_fc22", "(", "h1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.reparameterize": [[362, 369], ["logvar.mul().exp_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.mul().add_", "torch.autograd.Variable.mul().add_", "logvar.mul().exp_.data.new().normal_", "logvar.mul", "torch.autograd.Variable.mul", "torch.autograd.Variable.mul", "logvar.mul().exp_.data.new", "logvar.mul().exp_.size"], "methods", ["None"], ["", "def", "reparameterize", "(", "self", ",", "mu", ",", "logvar", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "std", "=", "logvar", ".", "mul", "(", "0.5", ")", ".", "exp_", "(", ")", "\n", "eps", "=", "Variable", "(", "std", ".", "data", ".", "new", "(", "std", ".", "size", "(", ")", ")", ".", "normal_", "(", ")", ")", "\n", "return", "eps", ".", "mul", "(", "std", ")", ".", "add_", "(", "mu", ")", "\n", "", "else", ":", "\n", "            ", "return", "mu", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.decode": [[370, 385], ["VAEmodel.VAEmod.tanh", "VAEmodel.VAEmod.tanh", "VAEmodel.VAEmod.tanh", "VAEmodel.VAEmod.dec_fc4", "VAEmodel.VAEmod.dec_fc30", "VAEmodel.VAEmod.dec_fc31", "VAEmodel.VAEmod.dec_fc32", "VAEmodel.VAEmod.size", "VAEmodel.VAEmod.dec_logvar.repeat", "VAEmodel.VAEmod.dec_fc5"], "methods", ["None"], ["", "", "def", "decode", "(", "self", ",", "z", ")", ":", "\n", "\n", "        ", "h30", "=", "self", ".", "tanh", "(", "self", ".", "dec_fc30", "(", "z", ")", ")", "\n", "h31", "=", "self", ".", "tanh", "(", "self", ".", "dec_fc31", "(", "h30", ")", ")", "\n", "h32", "=", "self", ".", "tanh", "(", "self", ".", "dec_fc32", "(", "h31", ")", ")", "\n", "\n", "mu", "=", "self", ".", "dec_fc4", "(", "h32", ")", "\n", "\n", "if", "self", ".", "bfixlogvar", ":", "\n", "            ", "batch_size", "=", "mu", ".", "size", "(", "0", ")", "\n", "logvar", "=", "self", ".", "dec_logvar", ".", "repeat", "(", "batch_size", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "logvar", "=", "self", ".", "dec_fc5", "(", "h32", ")", "\n", "\n", "", "return", "mu", ",", "logvar", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.forward": [[386, 390], ["VAEmodel.VAEmod.encode", "VAEmodel.VAEmod.reparameterize", "x.view", "VAEmodel.VAEmod.decode"], "methods", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.encode", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.reparameterize", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.VAEmod.decode"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "mu", ",", "logvar", "=", "self", ".", "encode", "(", "x", ".", "view", "(", "-", "1", ",", "self", ".", "x_dim", ")", ")", "\n", "z", "=", "self", ".", "reparameterize", "(", "mu", ",", "logvar", ")", "\n", "return", "self", ".", "decode", "(", "z", ")", ",", "mu", ",", "logvar", "", "", "", ""]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAEmodel.colorpointsgaussian": [[30, 46], ["multivariate_normal", "multivariate_normal.pdf", "var.pdf.min", "var.pdf.max", "getattr", "getattr.", "numpy.zeros", "numpy.eye"], "function", ["None"], ["def", "colorpointsgaussian", "(", "x", ",", "nsamples", ",", "name_colmap", "=", "''", ")", ":", "\n", "\n", "    ", "from", "scipy", ".", "stats", "import", "multivariate_normal", "\n", "x_dim", "=", "x", ".", "shape", "[", "1", "]", "\n", "var", "=", "multivariate_normal", "(", "mean", "=", "np", ".", "zeros", "(", "x_dim", ")", ",", "cov", "=", "np", ".", "eye", "(", "x_dim", ")", ")", "\n", "p", "=", "var", ".", "pdf", "(", "x", ")", "\n", "\n", "pmin", "=", "p", ".", "min", "(", ")", "\n", "pmax", "=", "p", ".", "max", "(", ")", "\n", "\n", "pscaled", "=", "(", "p", "-", "pmin", ")", "/", "(", "pmax", "-", "pmin", ")", "\n", "\n", "cm", "=", "getattr", "(", "matplotlib", ".", "cm", ",", "name_colmap", ")", "\n", "cmap", "=", "cm", "(", "pscaled", ")", "\n", "\n", "return", "cmap", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.main.get_choices": [[10, 42], ["choice_list.append", "choice_list.append", "choice_list.append", "choice_list.append", "choice_list.append", "choice_list.append", "choice_list.append", "choice_list.append"], "function", ["None"], ["def", "get_choices", "(", ")", ":", "\n", "\n", "    ", "choice_list", "=", "[", "]", "\n", "#['mnist', 'fashion-mnist', 'celebA', 'samples', 'm_526', 'm_10437',", "\n", "#               'a_500', 'b1_500', 'b2_500', 'a_1000', 'b1_1000', 'b2_1000',", "\n", "#               'a_10000', 'b1_10000', 'b2_10000', 'var_gauss', 'ala_2']", "\n", "\n", "choice_list", ".", "append", "(", "'ma_50'", ")", "\n", "choice_list", ".", "append", "(", "'ma_100'", ")", "\n", "choice_list", ".", "append", "(", "'ma_200'", ")", "\n", "choice_list", ".", "append", "(", "'ma_500'", ")", "\n", "#choice_list.append('ma_1500')", "\n", "#choice_list.append('ma_4000')", "\n", "#choice_list.append('ma_13334')", "\n", "#choice_list.append('m_ala_15')", "\n", "#choice_list.append('m_100_ala_15')", "\n", "#choice_list.append('m_200_ala_15')", "\n", "choice_list", ".", "append", "(", "'m_300_ala_15'", ")", "\n", "#choice_list.append('m_500_ala_15')", "\n", "choice_list", ".", "append", "(", "'m_1500_ala_15'", ")", "\n", "choice_list", ".", "append", "(", "'m_3000_ala_15'", ")", "\n", "choice_list", ".", "append", "(", "'m_5000_ala_15'", ")", "\n", "#choice_list.append('m_10000_ala_15')", "\n", "#choice_list.append('m_20000_ala_15')", "\n", "\n", "\n", "#for strN in ['1527', '4004']:", "\n", "#    choice_list.append('m_'+strN)", "\n", "#    choice_list.append('b1b2_' + strN)", "\n", "#    choice_list.append('ab1_' + strN)", "\n", "#    choice_list.append('ab2_' + strN)", "\n", "return", "choice_list", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.main.parse_args": [[44, 109], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "main.check_args", "argparse.ArgumentParser.parse_args", "main.get_choices"], "function", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.main.check_args", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.main.parse_args", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.main.get_choices"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "desc", "=", "\"Pytorch implementation of Predictive Collective Variable Discovery with Deep Bayesian Models\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "desc", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--mod_type'", ",", "type", "=", "str", ",", "default", "=", "'VAE'", ",", "\n", "choices", "=", "[", "'GAN'", ",", "'CGAN'", ",", "'infoGAN'", ",", "'ACGAN'", ",", "'EBGAN'", ",", "'BEGAN'", ",", "'WGAN'", ",", "'WGAN_GP'", ",", "\n", "'DRAGAN'", ",", "'LSGAN'", ",", "'WGAN_peptide'", ",", "'GAN_peptide'", ",", "'VAE'", ",", "'VARjoint'", "]", ",", "\n", "help", "=", "'The type of model to be trained.'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "type", "=", "str", ",", "default", "=", "'mnist'", ",", "\n", "choices", "=", "get_choices", "(", ")", ",", "\n", "help", "=", "'The name of dataset. For PCVs, ma_* for ALA2 and m_*_ala_15 for ALA15 works.'", ")", "\n", "parser", ".", "add_argument", "(", "'--epoch'", ",", "type", "=", "int", ",", "default", "=", "2000", ",", "help", "=", "'The number of epochs to run.'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "'The size of batch'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_dir'", ",", "type", "=", "str", ",", "default", "=", "'models'", ",", "\n", "help", "=", "'Directory name to save the model'", ")", "\n", "parser", ".", "add_argument", "(", "'--result_dir'", ",", "type", "=", "str", ",", "default", "=", "'results'", ",", "\n", "help", "=", "'Directory name to save the generated images'", ")", "\n", "parser", ".", "add_argument", "(", "'--log_dir'", ",", "type", "=", "str", ",", "default", "=", "'logs'", ",", "\n", "help", "=", "'Directory name to save training logs'", ")", "\n", "parser", ".", "add_argument", "(", "'--lrG'", ",", "type", "=", "float", ",", "default", "=", "0.0001", ")", "\n", "parser", ".", "add_argument", "(", "'--lrD'", ",", "type", "=", "float", ",", "default", "=", "0.0001", ")", "\n", "parser", ".", "add_argument", "(", "'--beta1'", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "parser", ".", "add_argument", "(", "'--beta2'", ",", "type", "=", "float", ",", "default", "=", "0.999", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_mode'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--clusterND'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Irrelevant option for pubilc.'", ")", "\n", "parser", ".", "add_argument", "(", "'--outPostFix'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--n_critic'", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "parser", ".", "add_argument", "(", "'--clipping'", ",", "type", "=", "float", ",", "default", "=", "0.01", ")", "\n", "parser", ".", "add_argument", "(", "'--z_dim'", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "parser", ".", "add_argument", "(", "'--samples_pred'", ",", "type", "=", "int", ",", "default", "=", "4000", ")", "\n", "parser", ".", "add_argument", "(", "'--useangulardat'", ",", "type", "=", "str", ",", "default", "=", "'no'", ",", "\n", "choices", "=", "[", "'no'", ",", "'ang'", ",", "'ang_augmented'", ",", "'ang_auggrouped'", "]", ",", "help", "=", "'Irrelevant for PCVs since not applied.'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "3251", ",", "\n", "help", "=", "'random seed (default: 0), 0 for no seed.'", ")", "\n", "parser", ".", "add_argument", "(", "'--AEVB'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Use Auto-Encoding Variational Bayes. If not, formulation relates to adversarial learning.'", ")", "\n", "parser", ".", "add_argument", "(", "'--Z'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Relevant for variational approach. Amount of samples from p(z).'", ")", "\n", "parser", ".", "add_argument", "(", "'--L'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Samples from eps ~ p(eps) for VAE.'", ")", "\n", "parser", ".", "add_argument", "(", "'--samples_per_mean'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "'Amount of predictive samples for p(x|z) = N(mu(z), sigma(z)). If 0, mean prediction is used: mu(z).'", ")", "\n", "parser", ".", "add_argument", "(", "'--npostS'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Amount of posterior samples.'", ")", "\n", "parser", ".", "add_argument", "(", "'--uqbias'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'Quantify uncertainty of bias terms in network.'", ")", "\n", "parser", ".", "add_argument", "(", "'--exppriorvar'", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "help", "=", "'lambda of exp(-lambda theta. If 0, no prior employed'", ")", "\n", "parser", ".", "add_argument", "(", "'--sharedlogvar'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Sharing the logvariance instead of cosidering a variance dpendent on the decoding network.'", ")", "\n", "parser", ".", "add_argument", "(", "'--sharedencoderlogvar'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Sharing the logvariance of the ENCODER, instead of cosidering a variance dpendent on the encoding network. This only applies for VARJ not VAE.'", ")", "\n", "parser", ".", "add_argument", "(", "'--loadtrainedmodel'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'Provide the path including file of an already trained model for doing predictions.'", ")", "\n", "parser", ".", "add_argument", "(", "'--ard'", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "help", "=", "'Value of a0 for ARD prior. If 0. then no ARD prior is applyed.'", ")", "\n", "parser", ".", "add_argument", "(", "'--exactlikeli'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Perform leveraging the likelihood.'", ")", "\n", "parser", ".", "add_argument", "(", "'--outputfreq'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "'Output frequency during the optimization process.'", ")", "\n", "parser", ".", "add_argument", "(", "'--x_dim'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "'Just for variational approach - not for PCVs since not applied. Test to predict gaussian of dim x_dim.'", ")", "\n", "parser", ".", "add_argument", "(", "'--assignrandW'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Just for variational approach. Assign uniformly random variables to reference W.'", ")", "\n", "parser", ".", "add_argument", "(", "'--freeMemory'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Just for variational approach. Free memory during estimation of the loss function.'", ")", "\n", "parser", ".", "add_argument", "(", "'--stepSched'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'Use step scheduler module druing optimization. No effect for PCVs since not applied.'", ")", "\n", "parser", ".", "add_argument", "(", "'--betaVAE'", ",", "type", "=", "float", ",", "default", "=", "1.", ",", "help", "=", "'Beta value for enforcing beta * KL(q(z|x) || p(z)). See https://openreview.net/pdf?id=Sy2fzU9gl. No effect for PCVs since not applied.'", ")", "\n", "parser", ".", "add_argument", "(", "'--separateLearningRate'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'This applies to separate learning rates between NN parameters and the parameters for the variances. Applies only if en- or decoding variance is modeled as parameter. No effect for PCVs since not applied.'", ")", "\n", "parser", ".", "add_argument", "(", "'--redDescription'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Only relevant for reverse var. approach. This removes 6 DOFs from x to implicitly remove the rigid body motion. No effect for PCVs since not applied.'", ")", "\n", "\n", "return", "check_args", "(", "parser", ".", "parse_args", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.main.check_args": [[111, 125], ["print", "print"], "function", ["None"], ["def", "check_args", "(", "args", ")", ":", "\n", "# --epoch", "\n", "    ", "try", ":", "\n", "        ", "assert", "args", ".", "epoch", ">=", "1", "\n", "", "except", ":", "\n", "        ", "print", "(", "'number of epochs must be larger than or equal to one'", ")", "\n", "\n", "# --batch_size", "\n", "", "try", ":", "\n", "        ", "assert", "args", ".", "batch_size", ">=", "1", "\n", "", "except", ":", "\n", "        ", "print", "(", "'batch size must be larger than or equal to one'", ")", "\n", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.main.main": [[128, 173], ["main.parse_args", "VAE_up.VAEpeptide.train", "print", "print", "exit", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "VAE_up.VAEpeptide", "print", "Exception"], "function", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.main.parse_args", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.VAE_up.VAEpeptide.train"], ["def", "main", "(", ")", ":", "\n", "# parse arguments", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "if", "args", "is", "None", ":", "\n", "        ", "exit", "(", ")", "\n", "\n", "# declare instance for model", "\n", "", "if", "args", ".", "mod_type", "==", "'GAN'", ":", "\n", "        ", "print", "(", "'Not content of Predictive CV Discovery.'", ")", "\n", "", "elif", "args", ".", "mod_type", "==", "'CGAN'", ":", "\n", "        ", "print", "(", "'Not content of Predictive CV Discovery.'", ")", "\n", "", "elif", "args", ".", "mod_type", "==", "'ACGAN'", ":", "\n", "        ", "print", "(", "'Not content of Predictive CV Discovery.'", ")", "\n", "", "elif", "args", ".", "mod_type", "==", "'infoGAN'", ":", "\n", "        ", "print", "(", "'Not content of Predictive CV Discovery.'", ")", "\n", "", "elif", "args", ".", "mod_type", "==", "'EBGAN'", ":", "\n", "        ", "print", "(", "'Not content of Predictive CV Discovery.'", ")", "\n", "", "elif", "args", ".", "mod_type", "==", "'WGAN'", ":", "\n", "        ", "print", "(", "'Not content of Predictive CV Discovery.'", ")", "\n", "", "elif", "args", ".", "mod_type", "==", "'WGAN_peptide'", ":", "\n", "        ", "print", "(", "'Not content of Predictive CV Discovery.'", ")", "\n", "", "elif", "args", ".", "mod_type", "==", "'GAN_peptide'", ":", "\n", "        ", "print", "(", "'Not content of Predictive CV Discovery.'", ")", "\n", "", "elif", "args", ".", "mod_type", "==", "'WGAN_GP'", ":", "\n", "        ", "print", "(", "'Not content of Predictive CV Discovery.'", ")", "\n", "", "elif", "args", ".", "mod_type", "==", "'DRAGAN'", ":", "\n", "        ", "print", "(", "'Not content of Predictive CV Discovery.'", ")", "\n", "", "elif", "args", ".", "mod_type", "==", "'LSGAN'", ":", "\n", "        ", "print", "(", "'Not content of Predictive CV Discovery.'", ")", "\n", "", "elif", "args", ".", "mod_type", "==", "'BEGAN'", ":", "\n", "        ", "print", "(", "'Not content of Predictive CV Discovery.'", ")", "\n", "", "elif", "args", ".", "mod_type", "==", "'VAE'", ":", "\n", "        ", "modt", "=", "VAEpeptide", "(", "args", ")", "\n", "", "elif", "args", ".", "mod_type", "==", "'VARjoint'", ":", "\n", "        ", "print", "(", "'Not content of Predictive CV Discovery.'", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"[!] There is no option for \"", "+", "args", ".", "mod_type", ")", "\n", "\n", "# launch the graph in a session", "\n", "", "modt", ".", "train", "(", ")", "\n", "print", "(", "\" [*] Training finished!\"", ")", "\n", "\n", "# visualize learned generator", "\n", "# gan.visualize_results(args.epoch)", "\n", "print", "(", "\" [*] Testing finished!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.convertToFullCartersianCoordinates": [[11, 24], ["numpy.array", "numpy.zeros"], "function", ["None"], ["def", "convertToFullCartersianCoordinates", "(", "data", ",", "dofsnp", "=", "np", ".", "array", "(", "[", "18", ",", "19", ",", "20", ",", "24", ",", "25", ",", "43", "]", ")", ",", "dtype", "=", "int", ",", "x_dim_red", "=", "60", ",", "x_dim_original", "=", "66", ")", ":", "\n", "\n", "    ", "dofs", "=", "dofsnp", "\n", "\n", "batch_size", "=", "data", ".", "shape", "[", "0", "]", "\n", "data_ext", "=", "np", ".", "zeros", "(", "[", "batch_size", ",", "x_dim_original", "]", ")", "\n", "\n", "data_ext", "[", ":", ",", "0", ":", "dofs", "[", "0", "]", "]", "=", "data", "[", ":", ",", "0", ":", "dofs", "[", "0", "]", "]", "\n", "data_ext", "[", ":", ",", "dofs", "[", "2", "]", "+", "1", ":", "dofs", "[", "3", "]", "]", "=", "data", "[", ":", ",", "dofs", "[", "0", "]", ":", "dofs", "[", "0", "]", "+", "3", "]", "\n", "data_ext", "[", ":", ",", "dofs", "[", "4", "]", "+", "1", ":", "dofs", "[", "5", "]", "]", "=", "data", "[", ":", ",", "dofs", "[", "0", "]", "+", "3", ":", "dofs", "[", "0", "]", "+", "3", "+", "(", "dofs", "[", "5", "]", "-", "dofs", "[", "4", "]", "-", "1", ")", "]", "\n", "data_ext", "[", ":", ",", "dofs", "[", "5", "]", "+", "1", ":", "]", "=", "data", "[", ":", ",", "dofs", "[", "0", "]", "+", "3", "+", "(", "dofs", "[", "5", "]", "-", "dofs", "[", "4", "]", "-", "1", ")", ":", "]", "\n", "\n", "return", "data_ext", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.convert_given_representation": [[25, 41], ["utils_peptide.convertangulardataset", "utils_peptide.convertangularaugmenteddataset", "utils_peptide.convertangularaugmenteddataset", "utils_peptide.convertToFullCartersianCoordinates"], "function", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.convertangulardataset", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.convertangularaugmenteddataset", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.convertangularaugmenteddataset", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.convertToFullCartersianCoordinates"], ["", "def", "convert_given_representation", "(", "samples", ",", "coordrep", ",", "unitgiven", "=", "1.", ",", "bredcoord", "=", "False", ")", ":", "\n", "\n", "    ", "convertfactor", "=", "unitgiven", "\n", "\n", "if", "coordrep", "==", "'ang'", ":", "\n", "        ", "samplesout", "=", "convertangulardataset", "(", "samples", ".", "T", ")", "\n", "", "elif", "coordrep", "==", "'ang_augmented'", ":", "\n", "        ", "samplesout", "=", "convertangularaugmenteddataset", "(", "samples", ".", "T", ")", "\n", "", "elif", "coordrep", "==", "'ang_auggrouped'", ":", "\n", "        ", "samplesout", "=", "convertangularaugmenteddataset", "(", "samples", ".", "T", ",", "bgrouped", "=", "True", ",", "convertfactor", "=", "convertfactor", ")", "\n", "", "else", ":", "\n", "        ", "if", "bredcoord", ":", "\n", "            ", "samples", "=", "convertToFullCartersianCoordinates", "(", "data", "=", "samples", ")", "\n", "", "samplesout", "=", "samples", ".", "T", "/", "convertfactor", "\n", "\n", "", "return", "samplesout", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.getcolorcodeALA15": [[42, 78], ["numpy.loadtxt", "np.loadtxt.resize", "AngleCategorizer", "AngleCategorizer.categorize", "AngleCategorizer.countConfigurations", "AngleCategorizer.getColorMatrix", "AngleCategorizer.getAlphaVals", "list", "list", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "matplotlib.scatter", "matplotlib.scatter", "matplotlib.scatter", "matplotlib.close", "os.path.join", "mpatches.Patch", "mpatches.Patch", "mpatches.Patch", "range"], "function", ["None"], ["", "def", "getcolorcodeALA15", "(", "ramapath", ",", "N", ",", "ssize", "=", "5", ")", ":", "\n", "    ", "\"\"\" Get color coding for ALA-15 1527 dataset. \"\"\"", "\n", "\n", "from", "analyse_ala_15", "import", "AngleCategorizer", "\n", "\n", "nResidues", "=", "15", "\n", "#angles = np.loadtxt('rama_dataset_ala_15.xvg', skiprows=32, usecols=range(0, 2), delimiter='  ')", "\n", "angles", "=", "np", ".", "loadtxt", "(", "os", ".", "path", ".", "join", "(", "ramapath", ",", "'rama_dataset_ala_15_1500.xvg'", ")", ",", "skiprows", "=", "32", ",", "usecols", "=", "range", "(", "0", ",", "2", ")", ",", "delimiter", "=", "'  '", ")", "\n", "nSamples", "=", "angles", ".", "shape", "[", "0", "]", "/", "15", "\n", "angles", ".", "resize", "(", "nSamples", ",", "nResidues", ",", "2", ")", "\n", "angCat", "=", "AngleCategorizer", "(", "angles", ")", "\n", "angCat", ".", "categorize", "(", ")", "\n", "angCat", ".", "countConfigurations", "(", ")", "\n", "colInd", "=", "angCat", ".", "getColorMatrix", "(", ")", "\n", "alphaInd", "=", "angCat", ".", "getAlphaVals", "(", ")", "\n", "\n", "marker", "=", "list", "(", ")", "\n", "patchlist", "=", "list", "(", ")", "\n", "\n", "marker", ".", "append", "(", "'o'", ")", "\n", "marker", ".", "append", "(", "'o'", ")", "\n", "marker", ".", "append", "(", "'o'", ")", "\n", "\n", "import", "matplotlib", ".", "patches", "as", "mpatches", "\n", "patchlist", ".", "append", "(", "mpatches", ".", "Patch", "(", "color", "=", "'black'", ",", "label", "=", "r'$\\alpha$'", ")", ")", "\n", "patchlist", ".", "append", "(", "mpatches", ".", "Patch", "(", "color", "=", "'blue'", ",", "label", "=", "r'$\\beta$-1'", ")", ")", "\n", "patchlist", ".", "append", "(", "mpatches", ".", "Patch", "(", "color", "=", "'red'", ",", "label", "=", "r'$\\beta$-2'", ")", ")", "\n", "\n", "alpha", "=", "plt", ".", "scatter", "(", "0", ",", "1", ",", "c", "=", "'k'", ",", "marker", "=", "marker", "[", "0", "]", ",", "s", "=", "ssize", ",", "label", "=", "r'$\\alpha$'", ")", "\n", "beta1", "=", "plt", ".", "scatter", "(", "0", ",", "1", ",", "c", "=", "'b'", ",", "marker", "=", "marker", "[", "1", "]", ",", "s", "=", "ssize", ",", "label", "=", "r'$\\beta\\textnormal{-}1$'", ")", "\n", "beta2", "=", "plt", ".", "scatter", "(", "0", ",", "1", ",", "c", "=", "'r'", ",", "marker", "=", "marker", "[", "2", "]", ",", "s", "=", "ssize", ",", "label", "=", "r'$\\beta\\textnormal{-}2$'", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "patchlist", "=", "[", "alpha", ",", "beta1", ",", "beta2", "]", "\n", "\n", "return", "colInd", ",", "marker", ",", "patchlist", ",", "alphaInd", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.getcolorcode1527": [[80, 115], ["list", "list", "list", "list.append", "list.append", "list.append", "range", "range", "range", "list.append", "list.append", "list.append", "matplotlib.scatter", "matplotlib.scatter", "matplotlib.scatter", "matplotlib.close", "list.append", "list.append", "list.append", "mpatches.Patch", "mpatches.Patch", "mpatches.Patch"], "function", ["None"], ["", "def", "getcolorcode1527", "(", "ssize", "=", "5", ")", ":", "\n", "    ", "\"\"\" Get color coding for ALA-2 1527 dataset. \"\"\"", "\n", "\n", "iA", "=", "29", "\n", "iB1", "=", "932", "\n", "iB2", "=", "566", "\n", "colInd", "=", "list", "(", ")", "\n", "marker", "=", "list", "(", ")", "\n", "patchlist", "=", "list", "(", ")", "\n", "\n", "marker", ".", "append", "(", "'o'", ")", "\n", "marker", ".", "append", "(", "'v'", ")", "\n", "marker", ".", "append", "(", "'x'", ")", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "iA", ")", ":", "\n", "        ", "colInd", ".", "append", "(", "'k'", ")", "\n", "", "for", "i", "in", "range", "(", "0", ",", "iB1", ")", ":", "\n", "        ", "colInd", ".", "append", "(", "'b'", ")", "\n", "", "for", "i", "in", "range", "(", "0", ",", "iB2", ")", ":", "\n", "        ", "colInd", ".", "append", "(", "'r'", ")", "\n", "\n", "\n", "", "import", "matplotlib", ".", "patches", "as", "mpatches", "\n", "patchlist", ".", "append", "(", "mpatches", ".", "Patch", "(", "color", "=", "'black'", ",", "label", "=", "r'$\\alpha$'", ")", ")", "\n", "patchlist", ".", "append", "(", "mpatches", ".", "Patch", "(", "color", "=", "'blue'", ",", "label", "=", "r'$\\beta$-1'", ")", ")", "\n", "patchlist", ".", "append", "(", "mpatches", ".", "Patch", "(", "color", "=", "'red'", ",", "label", "=", "r'$\\beta$-2'", ")", ")", "\n", "\n", "alpha", "=", "plt", ".", "scatter", "(", "0", ",", "1", ",", "c", "=", "'k'", ",", "marker", "=", "marker", "[", "0", "]", ",", "s", "=", "ssize", ",", "label", "=", "r'$\\alpha$'", ")", "\n", "beta1", "=", "plt", ".", "scatter", "(", "0", ",", "1", ",", "c", "=", "'b'", ",", "marker", "=", "marker", "[", "1", "]", ",", "s", "=", "ssize", ",", "label", "=", "r'$\\beta\\textnormal{-}1$'", ")", "\n", "beta2", "=", "plt", ".", "scatter", "(", "0", ",", "1", ",", "c", "=", "'r'", ",", "marker", "=", "marker", "[", "2", "]", ",", "s", "=", "ssize", ",", "label", "=", "r'$\\beta\\textnormal{-}2$'", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "patchlist", "=", "[", "alpha", ",", "beta1", ",", "beta2", "]", "\n", "\n", "return", "colInd", ",", "marker", ",", "patchlist", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.estimateProperties": [[117, 197], ["open", "open.write", "open.close", "os.chmod", "open", "open.write", "open.close", "os.chmod", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "str", "str", "str", "str", "str", "str"], "function", ["None"], ["", "def", "estimateProperties", "(", "samples_name", ",", "cluster", ",", "datasetN", ",", "pathofsamples", "=", "None", ",", "postS", "=", "0", ",", "nCores", "=", "2", ",", "peptide", "=", "'ala_2'", ")", ":", "\n", "\n", "    ", "command", "=", "''", "\n", "\n", "if", "cluster", "==", "True", ":", "\n", "        ", "command", "+=", "'python /afs/crc.nd.edu/user/m/mschoebe/Private/projects/ganpepvae/estimate_properties.py'", "\n", "command", "+=", "' --referenceDirectory '", "+", "'/afs/crc.nd.edu/user/m/mschoebe/Private/data/data_peptide/'", "\n", "command", "+=", "' --cluster '", "+", "'2'", "\n", "command", "+=", "' --postS '", "+", "str", "(", "postS", ")", "\n", "command", "+=", "' --nCores '", "+", "str", "(", "nCores", ")", "\n", "", "else", ":", "\n", "#command += 'pyenv activate work; '", "\n", "        ", "command", "+=", "'python /home/schoeberl/predictive_cvs/prediction/propteinpropcal/estimate_properties.py'", "\n", "command", "+=", "' --referenceDirectory '", "+", "'/home/schoeberl/predictive_cvs/prediction/propteinpropcal/'", "\n", "\n", "", "if", "pathofsamples", "is", "not", "None", ":", "\n", "        ", "command", "+=", "' --predFilePath '", "+", "pathofsamples", "+", "'/'", "\n", "\n", "", "command", "+=", "' --dataCollected random'", "\n", "\n", "command", "+=", "' --fileNamePred '", "+", "samples_name", "\n", "command", "+=", "' --conformation '", "+", "'m'", "\n", "command", "+=", "' --peptide '", "+", "peptide", "\n", "#--cluster 2 --postS 500 --nCores 24", "\n", "#os.system(command)", "\n", "#os.system(command)", "\n", "#call(['bash','pyenv activate work', command], shell=True)", "\n", "\n", "f", "=", "open", "(", "pathofsamples", "+", "'/est_prop.sh'", ",", "'w'", ")", "\n", "#f.write('#!/bin/bash')", "\n", "\n", "if", "cluster", "==", "True", ":", "\n", "        ", "f", ".", "write", "(", "'#!/bin/bash\\n'", ")", "\n", "f", ".", "write", "(", "'#$ -N est_prop_'", "+", "samples_name", "+", "'\\n'", ")", "\n", "f", ".", "write", "(", "'#$ -pe smp '", "+", "str", "(", "nCores", ")", "+", "'\\n'", ")", "\n", "f", ".", "write", "(", "'#$ -q debug\\n\\n'", ")", "\n", "f", ".", "write", "(", "'source activate work\\n'", ")", "\n", "f", ".", "write", "(", "'module load gromacs\\n\\n'", ")", "\n", "# $ -N est_prop", "\n", "# $ -pe smp 24", "\n", "# $ -q debug", "\n", "", "f", ".", "write", "(", "command", ")", "\n", "f", ".", "close", "(", ")", "\n", "os", ".", "chmod", "(", "pathofsamples", "+", "'/est_prop.sh'", ",", "0o777", ")", "\n", "\n", "# this is for comparison with real dataset", "\n", "\n", "command", "=", "''", "\n", "\n", "if", "cluster", "==", "True", ":", "\n", "        ", "command", "+=", "'python /afs/crc.nd.edu/user/m/mschoebe/Private/projects/ganpepvae/estimate_properties_compare.py'", "\n", "command", "+=", "' --referenceDirectory '", "+", "'/afs/crc.nd.edu/user/m/mschoebe/Private/data/data_peptide/'", "\n", "command", "+=", "' --cluster '", "+", "'2'", "\n", "command", "+=", "' --postS '", "+", "str", "(", "postS", ")", "\n", "command", "+=", "' --nCores '", "+", "str", "(", "nCores", ")", "\n", "", "else", ":", "\n", "#command += 'pyenv activate work; '", "\n", "        ", "command", "+=", "'python /home/schoeberl/predictive_cvs/prediction/propteinpropcal/estimate_properties_compare.py'", "\n", "command", "+=", "' --referenceDirectory '", "+", "'/home/schoeberl/predictive_cvs/prediction/propteinpropcal/'", "\n", "\n", "", "if", "pathofsamples", "is", "not", "None", ":", "\n", "        ", "command", "+=", "' --predFilePath '", "+", "pathofsamples", "+", "'/'", "\n", "\n", "", "command", "+=", "' --dataCollected random'", "\n", "\n", "command", "+=", "' --compareRefData dataset_'", "+", "str", "(", "datasetN", ")", "\n", "\n", "command", "+=", "' --fileNamePred '", "+", "samples_name", "\n", "command", "+=", "' --conformation '", "+", "'m'", "\n", "command", "+=", "' --peptide '", "+", "peptide", "\n", "#--cluster 2 --postS 500 --nCores 24", "\n", "#os.system(command)", "\n", "#os.system(command)", "\n", "#call(['bash','pyenv activate work', command], shell=True)", "\n", "\n", "f", "=", "open", "(", "pathofsamples", "+", "'/est_prop_compare.sh'", ",", "'w'", ")", "\n", "#f.write('#!/bin/bash')", "\n", "f", ".", "write", "(", "command", ")", "\n", "f", ".", "close", "(", ")", "\n", "os", ".", "chmod", "(", "pathofsamples", "+", "'/est_prop_compare.sh'", ",", "0o777", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.getAbsCoordinates": [[199, 274], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range"], "function", ["None"], ["", "def", "getAbsCoordinates", "(", "xyz", ")", ":", "\n", "    ", "_xyzAbs", "=", "np", ".", "zeros", "(", "[", "xyz", ".", "shape", "[", "0", "]", "+", "1", ",", "xyz", ".", "shape", "[", "1", "]", "]", ")", "\n", "\n", "# number of residues", "\n", "nACE", "=", "1", "\n", "nALA", "=", "1", "\n", "nNME", "=", "1", "\n", "\n", "ACEleng", "=", "6", "\n", "ALAleng", "=", "10", "\n", "NMEleng", "=", "6", "\n", "\n", "# go through every residue", "\n", "aACE", "=", "np", ".", "zeros", "(", "[", "nACE", "*", "ACEleng", ",", "3", "]", ")", "\n", "aALA", "=", "np", ".", "zeros", "(", "[", "nALA", "*", "ALAleng", ",", "3", "]", ")", "\n", "aNME", "=", "np", ".", "zeros", "(", "[", "nNME", "*", "NMEleng", ",", "3", "]", ")", "\n", "\n", "# 1HH3 = CH3 + (1HH3 - CH3)", "\n", "aACE", "[", "0", ",", ":", "]", "=", "xyz", "[", "0", ",", ":", "]", "\n", "# CH3 = 0", "\n", "# aACE[1,:] = 0", "\n", "# 2HH3 = CH3 + (2HH3 - CH3)", "\n", "aACE", "[", "2", ",", ":", "]", "=", "xyz", "[", "1", ",", ":", "]", "\n", "# 3HH3 = CH3 + (3HH3 - CH3)", "\n", "aACE", "[", "3", ",", ":", "]", "=", "xyz", "[", "2", ",", ":", "]", "\n", "# C = CH3 + (C - CH3)", "\n", "aACE", "[", "4", ",", ":", "]", "=", "xyz", "[", "3", ",", ":", "]", "\n", "# O = C + (O - C)", "\n", "aACE", "[", "5", ",", ":", "]", "=", "aACE", "[", "4", ",", ":", "]", "+", "xyz", "[", "4", ",", ":", "]", "\n", "\n", "# first N coordinate", "\n", "aALA", "[", "0", ",", ":", "]", "=", "aACE", "[", "4", ",", ":", "]", "+", "xyz", "[", "5", ",", ":", "]", "\n", "\n", "for", "iALA", "in", "range", "(", "0", ",", "nALA", ")", ":", "\n", "# N = C + (N - C)", "\n", "        ", "if", "iALA", ">", "0", ":", "\n", "            ", "aALA", "[", "iALA", "*", "ALAleng", "+", "0", ",", ":", "]", "=", "aALA", "[", "iALA", "*", "ALAleng", "-", "2", ",", ":", "]", "+", "xyz", "[", "ACEleng", "+", "iALA", "*", "ALAleng", "-", "1", ",", ":", "]", "\n", "# H = N + (H - N)", "\n", "", "aALA", "[", "iALA", "*", "ALAleng", "+", "1", ",", ":", "]", "=", "aALA", "[", "iALA", "*", "ALAleng", "+", "0", ",", ":", "]", "+", "xyz", "[", "ACEleng", "+", "iALA", "*", "ALAleng", "+", "0", ",", ":", "]", "\n", "# CA = N + (CA - N)", "\n", "aALA", "[", "iALA", "*", "ALAleng", "+", "2", ",", ":", "]", "=", "aALA", "[", "iALA", "*", "ALAleng", "+", "0", ",", ":", "]", "+", "xyz", "[", "ACEleng", "+", "iALA", "*", "ALAleng", "+", "1", ",", ":", "]", "\n", "# HA = CA + (HA - CA)", "\n", "aALA", "[", "iALA", "*", "ALAleng", "+", "3", ",", ":", "]", "=", "aALA", "[", "iALA", "*", "ALAleng", "+", "2", ",", ":", "]", "+", "xyz", "[", "ACEleng", "+", "iALA", "*", "ALAleng", "+", "2", ",", ":", "]", "\n", "# CB = CA + (CB - CA)", "\n", "aALA", "[", "iALA", "*", "ALAleng", "+", "4", ",", ":", "]", "=", "aALA", "[", "iALA", "*", "ALAleng", "+", "2", ",", ":", "]", "+", "xyz", "[", "ACEleng", "+", "iALA", "*", "ALAleng", "+", "3", ",", ":", "]", "\n", "# HB1 = CB + (HB1 - CB)", "\n", "aALA", "[", "iALA", "*", "ALAleng", "+", "5", ",", ":", "]", "=", "aALA", "[", "iALA", "*", "ALAleng", "+", "4", ",", ":", "]", "+", "xyz", "[", "ACEleng", "+", "iALA", "*", "ALAleng", "+", "4", ",", ":", "]", "\n", "# HB2 = CB + (HB2 - CB)", "\n", "aALA", "[", "iALA", "*", "ALAleng", "+", "6", ",", ":", "]", "=", "aALA", "[", "iALA", "*", "ALAleng", "+", "4", ",", ":", "]", "+", "xyz", "[", "ACEleng", "+", "iALA", "*", "ALAleng", "+", "5", ",", ":", "]", "\n", "# HB3 = CB + (HB3 - CB)", "\n", "aALA", "[", "iALA", "*", "ALAleng", "+", "7", ",", ":", "]", "=", "aALA", "[", "iALA", "*", "ALAleng", "+", "4", ",", ":", "]", "+", "xyz", "[", "ACEleng", "+", "iALA", "*", "ALAleng", "+", "6", ",", ":", "]", "\n", "# C = CA + (C - CA)", "\n", "aALA", "[", "iALA", "*", "ALAleng", "+", "8", ",", ":", "]", "=", "aALA", "[", "iALA", "*", "ALAleng", "+", "2", ",", ":", "]", "+", "xyz", "[", "ACEleng", "+", "iALA", "*", "ALAleng", "+", "7", ",", ":", "]", "\n", "# O = C + (O - C)", "\n", "aALA", "[", "iALA", "*", "ALAleng", "+", "9", ",", ":", "]", "=", "aALA", "[", "iALA", "*", "ALAleng", "+", "8", ",", ":", "]", "+", "xyz", "[", "ACEleng", "+", "iALA", "*", "ALAleng", "+", "8", ",", ":", "]", "\n", "\n", "# Last part", "\n", "# N = C + (N - C)", "\n", "", "aNME", "[", "0", ",", ":", "]", "=", "aALA", "[", "nALA", "*", "ALAleng", "-", "2", ",", ":", "]", "+", "xyz", "[", "ACEleng", "+", "nALA", "*", "ALAleng", "-", "1", ",", ":", "]", "\n", "# H = N + (H - N)", "\n", "aNME", "[", "1", ",", ":", "]", "=", "aNME", "[", "0", ",", ":", "]", "+", "xyz", "[", "ACEleng", "+", "nALA", "*", "ALAleng", "+", "0", ",", ":", "]", "\n", "# CH3 = N + (CH3 - N)", "\n", "aNME", "[", "2", ",", ":", "]", "=", "aNME", "[", "0", ",", ":", "]", "+", "xyz", "[", "ACEleng", "+", "nALA", "*", "ALAleng", "+", "1", ",", ":", "]", "\n", "# 1HH3 = CH3 + (1HH3 - CH3)", "\n", "aNME", "[", "3", ",", ":", "]", "=", "aNME", "[", "2", ",", ":", "]", "+", "xyz", "[", "ACEleng", "+", "nALA", "*", "ALAleng", "+", "2", ",", ":", "]", "\n", "# 2HH3 = CH3 + (2HH3 - CH3)", "\n", "aNME", "[", "4", ",", ":", "]", "=", "aNME", "[", "2", ",", ":", "]", "+", "xyz", "[", "ACEleng", "+", "nALA", "*", "ALAleng", "+", "3", ",", ":", "]", "\n", "# 3HH3 = CH3 + (2HH3 - CH3)", "\n", "aNME", "[", "5", ",", ":", "]", "=", "aNME", "[", "2", ",", ":", "]", "+", "xyz", "[", "ACEleng", "+", "nALA", "*", "ALAleng", "+", "4", ",", ":", "]", "\n", "\n", "_xyzAbs", "[", "0", ":", "(", "ACEleng", ")", ",", ":", "]", "=", "aACE", "\n", "_xyzAbs", "[", "ACEleng", ":", "(", "ACEleng", "+", "nALA", "*", "ALAleng", ")", ",", ":", "]", "=", "aALA", "\n", "_xyzAbs", "[", "(", "ACEleng", "+", "nALA", "*", "ALAleng", ")", ":", ",", ":", "]", "=", "aNME", "\n", "\n", "return", "_xyzAbs", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.getCartesian": [[276, 298], ["utils_peptide.getAbsCoordinates", "numpy.zeros", "numpy.zeros", "numpy.sin", "numpy.sin", "numpy.cos", "numpy.cos", "numpy.sin"], "function", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.getAbsCoordinates"], ["", "def", "getCartesian", "(", "rphitheta", ",", "dataaugmented", "=", "False", ")", ":", "\n", "    ", "rphithetaShape", "=", "rphitheta", ".", "shape", "\n", "\n", "if", "dataaugmented", ":", "\n", "        ", "_xyz", "=", "np", ".", "zeros", "(", "[", "rphithetaShape", "[", "0", "]", ",", "3", "]", ")", "\n", "r", "=", "rphitheta", "[", ":", ",", "0", "]", "\n", "sinphi", "=", "rphitheta", "[", ":", ",", "1", "]", "\n", "cosphi", "=", "rphitheta", "[", ":", ",", "2", "]", "\n", "sintheta", "=", "rphitheta", "[", ":", ",", "3", "]", "\n", "costheta", "=", "rphitheta", "[", ":", ",", "4", "]", "\n", "_xyz", "[", ":", ",", "0", "]", "=", "r", "*", "costheta", "*", "sinphi", "\n", "_xyz", "[", ":", ",", "1", "]", "=", "r", "*", "sintheta", "*", "sinphi", "\n", "_xyz", "[", ":", ",", "2", "]", "=", "r", "*", "cosphi", "\n", "", "else", ":", "\n", "        ", "_xyz", "=", "np", ".", "zeros", "(", "rphithetaShape", ")", "\n", "_xyz", "[", ":", ",", "0", "]", "=", "rphitheta", "[", ":", ",", "0", "]", "*", "np", ".", "cos", "(", "rphitheta", "[", ":", ",", "2", "]", ")", "*", "np", ".", "sin", "(", "rphitheta", "[", ":", ",", "1", "]", ")", "\n", "_xyz", "[", ":", ",", "1", "]", "=", "rphitheta", "[", ":", ",", "0", "]", "*", "np", ".", "sin", "(", "rphitheta", "[", ":", ",", "2", "]", ")", "*", "np", ".", "sin", "(", "rphitheta", "[", ":", ",", "1", "]", ")", "\n", "_xyz", "[", ":", ",", "2", "]", "=", "rphitheta", "[", ":", ",", "0", "]", "*", "np", ".", "cos", "(", "rphitheta", "[", ":", ",", "1", "]", ")", "\n", "\n", "", "xyzAbs", "=", "getAbsCoordinates", "(", "xyz", "=", "_xyz", ")", "\n", "\n", "return", "xyzAbs", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.convertangulardataset": [[299, 322], ["numpy.zeros", "range", "numpy.zeros", "range", "utils_peptide.getCartesian", "numpy.reshape", "numpy.copy"], "function", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.getCartesian"], ["", "def", "convertangulardataset", "(", "data", ")", ":", "\n", "\n", "#outname = 'samples.txt'", "\n", "#data = np.loadtxt('dataset_mixed_1527_ang.txt')", "\n", "\n", "    ", "dim", "=", "data", ".", "shape", "[", "0", "]", "\n", "n", "=", "data", ".", "shape", "[", "1", "]", "\n", "\n", "datacatout", "=", "np", ".", "zeros", "(", "[", "dim", "+", "3", ",", "n", "]", ")", "\n", "\n", "for", "j", "in", "range", "(", "0", ",", "n", ")", ":", "\n", "        ", "sample", "=", "data", "[", ":", ",", "j", "]", "\n", "rphitheta", "=", "np", ".", "zeros", "(", "[", "dim", "/", "3", ",", "3", "]", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "rphitheta", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "rphitheta", "[", "i", ",", "0", "]", "=", "sample", "[", "i", "*", "3", "+", "0", "]", "\n", "rphitheta", "[", "i", ",", "1", "]", "=", "sample", "[", "i", "*", "3", "+", "1", "]", "\n", "rphitheta", "[", "i", ",", "2", "]", "=", "sample", "[", "i", "*", "3", "+", "2", "]", "\n", "\n", "", "datacoord", "=", "getCartesian", "(", "rphitheta", "=", "rphitheta", ")", "\n", "datacoordvec", "=", "np", ".", "reshape", "(", "datacoord", ",", "sample", ".", "shape", "[", "0", "]", "+", "3", ")", "\n", "datacatout", "[", ":", ",", "j", "]", "=", "np", ".", "copy", "(", "datacoordvec", ")", "\n", "\n", "", "return", "datacatout", "\n", "#np.savetxt(outname, datacatout)", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.convertangularaugmenteddataset": [[324, 372], ["int", "numpy.zeros", "range", "numpy.zeros", "range", "numpy.copy", "numpy.zeros", "range", "utils_peptide.getCartesian", "numpy.reshape", "numpy.copy", "int"], "function", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils_peptide.getCartesian"], ["", "def", "convertangularaugmenteddataset", "(", "data", ",", "bgrouped", "=", "False", ",", "convertfactor", "=", "1.", ")", ":", "\n", "\n", "#outname = 'samples.txt'", "\n", "#data = np.loadtxt('dataset_mixed_1527_ang.txt')", "\n", "\n", "    ", "dim", "=", "data", ".", "shape", "[", "0", "]", "\n", "n", "=", "data", ".", "shape", "[", "1", "]", "\n", "\n", "# specify the size of one coordinate point: here (r, sin \\theta, cos \\theta, sin \\psi, cos \\psi)", "\n", "sizeofcoord", "=", "5", "\n", "nparticles", "=", "int", "(", "dim", "/", "sizeofcoord", "+", "1", ")", "\n", "ncoordtuples", "=", "nparticles", "-", "1", "\n", "\n", "datacatout", "=", "np", ".", "zeros", "(", "[", "nparticles", "*", "3", ",", "n", "]", ")", "\n", "\n", "if", "bgrouped", ":", "\n", "        ", "dataUse", "=", "np", ".", "zeros", "(", "data", ".", "shape", ")", "\n", "# sorted dataset r1 r2 r3 r4 , sin sin sin", "\n", "# temporary dataset for", "\n", "r", "=", "data", "[", "0", "*", "ncoordtuples", ":", "1", "*", "ncoordtuples", ",", ":", "]", "\n", "sinphi", "=", "data", "[", "1", "*", "ncoordtuples", ":", "2", "*", "ncoordtuples", ",", ":", "]", "\n", "cosphi", "=", "data", "[", "2", "*", "ncoordtuples", ":", "3", "*", "ncoordtuples", ",", ":", "]", "\n", "sintheta", "=", "data", "[", "3", "*", "ncoordtuples", ":", "4", "*", "ncoordtuples", ",", ":", "]", "\n", "costheta", "=", "data", "[", "4", "*", "ncoordtuples", ":", "5", "*", "ncoordtuples", ",", ":", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "ncoordtuples", ")", ":", "\n", "            ", "dataUse", "[", "i", "*", "sizeofcoord", "+", "0", ",", ":", "]", "=", "r", "[", "i", ",", ":", "]", "/", "convertfactor", "\n", "dataUse", "[", "i", "*", "sizeofcoord", "+", "1", ",", ":", "]", "=", "sinphi", "[", "i", ",", ":", "]", "\n", "dataUse", "[", "i", "*", "sizeofcoord", "+", "2", ",", ":", "]", "=", "cosphi", "[", "i", ",", ":", "]", "\n", "dataUse", "[", "i", "*", "sizeofcoord", "+", "3", ",", ":", "]", "=", "sintheta", "[", "i", ",", ":", "]", "\n", "dataUse", "[", "i", "*", "sizeofcoord", "+", "4", ",", ":", "]", "=", "costheta", "[", "i", ",", ":", "]", "\n", "", "", "else", ":", "\n", "        ", "dataUse", "=", "np", ".", "copy", "(", "data", ")", "\n", "\n", "", "for", "j", "in", "range", "(", "0", ",", "n", ")", ":", "\n", "        ", "sample", "=", "dataUse", "[", ":", ",", "j", "]", "\n", "rphithetaaugmented", "=", "np", ".", "zeros", "(", "[", "int", "(", "dim", "/", "sizeofcoord", ")", ",", "sizeofcoord", "]", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "rphithetaaugmented", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "rphithetaaugmented", "[", "i", ",", "0", "]", "=", "sample", "[", "i", "*", "sizeofcoord", "+", "0", "]", "\n", "rphithetaaugmented", "[", "i", ",", "1", "]", "=", "sample", "[", "i", "*", "sizeofcoord", "+", "1", "]", "\n", "rphithetaaugmented", "[", "i", ",", "2", "]", "=", "sample", "[", "i", "*", "sizeofcoord", "+", "2", "]", "\n", "rphithetaaugmented", "[", "i", ",", "3", "]", "=", "sample", "[", "i", "*", "sizeofcoord", "+", "3", "]", "\n", "rphithetaaugmented", "[", "i", ",", "4", "]", "=", "sample", "[", "i", "*", "sizeofcoord", "+", "4", "]", "\n", "\n", "", "datacoord", "=", "getCartesian", "(", "rphitheta", "=", "rphithetaaugmented", ",", "dataaugmented", "=", "True", ")", "\n", "datacoordvec", "=", "np", ".", "reshape", "(", "datacoord", ",", "nparticles", "*", "3", ")", "\n", "datacatout", "[", ":", ",", "j", "]", "=", "np", ".", "copy", "(", "datacoordvec", ")", "\n", "\n", "", "return", "datacatout", "\n", "#np.savetxt(outname, datacatout)", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils.plotmvn": [[15, 64], ["numpy.linspace", "numpy.linspace", "numpy.meshgrid", "numpy.empty", "utils.plotmvn.multivariate_gaussian"], "function", ["None"], ["def", "plotmvn", "(", "fname", ",", "mu", ",", "Sigma", ")", ":", "\n", "\n", "# Our 2-dimensional distribution will be over variables X and Y", "\n", "    ", "N", "=", "150", "\n", "X", "=", "np", ".", "linspace", "(", "-", "1", ",", "1", ",", "N", ")", "\n", "Y", "=", "np", ".", "linspace", "(", "-", "1", ",", "1", ",", "N", ")", "\n", "X", ",", "Y", "=", "np", ".", "meshgrid", "(", "X", ",", "Y", ")", "\n", "\n", "# Pack X and Y into a single 3-dimensional array", "\n", "pos", "=", "np", ".", "empty", "(", "X", ".", "shape", "+", "(", "2", ",", ")", ")", "\n", "pos", "[", ":", ",", ":", ",", "0", "]", "=", "X", "\n", "pos", "[", ":", ",", ":", ",", "1", "]", "=", "Y", "\n", "\n", "def", "multivariate_gaussian", "(", "pos", ",", "mu", ",", "Sigma", ")", ":", "\n", "        ", "\"\"\"Return the multivariate Gaussian distribution on array pos.\n\n        pos is an array constructed by packing the meshed arrays of variables\n        x_1, x_2, x_3, ..., x_k into its _last_ dimension.\n\n        \"\"\"", "\n", "\n", "n", "=", "mu", ".", "shape", "[", "0", "]", "\n", "Sigma_det", "=", "np", ".", "linalg", ".", "det", "(", "Sigma", ")", "\n", "Sigma_inv", "=", "np", ".", "linalg", ".", "inv", "(", "Sigma", ")", "\n", "N", "=", "np", ".", "sqrt", "(", "(", "2", "*", "np", ".", "pi", ")", "**", "n", "*", "Sigma_det", ")", "\n", "# This einsum call calculates (x-mu)T.Sigma-1.(x-mu) in a vectorized", "\n", "# way across all the input variables.", "\n", "fac", "=", "np", ".", "einsum", "(", "'...k,kl,...l->...'", ",", "pos", "-", "mu", ",", "Sigma_inv", ",", "pos", "-", "mu", ")", "\n", "\n", "return", "np", ".", "exp", "(", "-", "fac", "/", "2", ")", "/", "N", "\n", "\n", "# The distribution on the variables X, Y packed into pos.", "\n", "", "Z", "=", "multivariate_gaussian", "(", "pos", ",", "mu", ",", "Sigma", ")", "\n", "\n", "# Create a surface plot and projected filled contour plot under it.", "\n", "f", ",", "ax", "=", "plt", ".", "subplots", "(", "1", ")", "\n", "#ax = fig.gca(projection='3d')", "\n", "#ax.plot_surface(X, Y, Z, rstride=3, cstride=3, linewidth=1, antialiased=True, cmap=cm.viridis)", "\n", "\n", "#cset = ax.contourf(X, Y, Z, zdir='z', offset=-0.15, norm=colors.LogNorm(), cmap=cm.viridis)", "\n", "cset", "=", "ax", ".", "contourf", "(", "X", ",", "Y", ",", "Z", ")", "\n", "\n", "# Adjust the limits, ticks and view angle", "\n", "#ax.set_zlim(-0.15, 0.2)", "\n", "#ax.set_zticks(np.linspace(0, 0.2, 5))", "\n", "#ax.view_init(27, -21)", "\n", "\n", "f", ".", "savefig", "(", "fname", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils.load_mnist": [[66, 110], ["os.path.join", "utils.load_mnist.extract_data"], "function", ["None"], ["", "def", "load_mnist", "(", "dataset", ")", ":", "\n", "    ", "data_dir", "=", "os", ".", "path", ".", "join", "(", "\"./data\"", ",", "dataset", ")", "\n", "\n", "def", "extract_data", "(", "filename", ",", "num_data", ",", "head_size", ",", "data_size", ")", ":", "\n", "        ", "with", "gzip", ".", "open", "(", "filename", ")", "as", "bytestream", ":", "\n", "            ", "bytestream", ".", "read", "(", "head_size", ")", "\n", "buf", "=", "bytestream", ".", "read", "(", "data_size", "*", "num_data", ")", "\n", "data", "=", "np", ".", "frombuffer", "(", "buf", ",", "dtype", "=", "np", ".", "uint8", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "", "return", "data", "\n", "\n", "", "data", "=", "extract_data", "(", "data_dir", "+", "'/train-images-idx3-ubyte.gz'", ",", "60000", ",", "16", ",", "28", "*", "28", ")", "\n", "trX", "=", "data", ".", "reshape", "(", "(", "60000", ",", "28", ",", "28", ",", "1", ")", ")", "\n", "\n", "data", "=", "extract_data", "(", "data_dir", "+", "'/train-labels-idx1-ubyte.gz'", ",", "60000", ",", "8", ",", "1", ")", "\n", "trY", "=", "data", ".", "reshape", "(", "(", "60000", ")", ")", "\n", "\n", "data", "=", "extract_data", "(", "data_dir", "+", "'/t10k-images-idx3-ubyte.gz'", ",", "10000", ",", "16", ",", "28", "*", "28", ")", "\n", "teX", "=", "data", ".", "reshape", "(", "(", "10000", ",", "28", ",", "28", ",", "1", ")", ")", "\n", "\n", "data", "=", "extract_data", "(", "data_dir", "+", "'/t10k-labels-idx1-ubyte.gz'", ",", "10000", ",", "8", ",", "1", ")", "\n", "teY", "=", "data", ".", "reshape", "(", "(", "10000", ")", ")", "\n", "\n", "trY", "=", "np", ".", "asarray", "(", "trY", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "teY", "=", "np", ".", "asarray", "(", "teY", ")", "\n", "\n", "X", "=", "np", ".", "concatenate", "(", "(", "trX", ",", "teX", ")", ",", "axis", "=", "0", ")", "\n", "y", "=", "np", ".", "concatenate", "(", "(", "trY", ",", "teY", ")", ",", "axis", "=", "0", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "seed", "=", "547", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "X", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "y", ")", "\n", "\n", "y_vec", "=", "np", ".", "zeros", "(", "(", "len", "(", "y", ")", ",", "10", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "y", ")", ":", "\n", "        ", "y_vec", "[", "i", ",", "y", "[", "i", "]", "]", "=", "1", "\n", "\n", "", "X", "=", "X", ".", "transpose", "(", "0", ",", "3", ",", "1", ",", "2", ")", "/", "255.", "\n", "# y_vec = y_vec.transpose(0, 3, 1, 2)", "\n", "\n", "X", "=", "torch", ".", "from_numpy", "(", "X", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "y_vec", "=", "torch", ".", "from_numpy", "(", "y_vec", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "return", "X", ",", "y_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils.load_celebA": [[111, 124], ["datasets.ImageFolder", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "function", ["None"], ["", "def", "load_celebA", "(", "dir", ",", "transform", ",", "batch_size", ",", "shuffle", ")", ":", "\n", "# transform = transforms.Compose([", "\n", "#     transforms.CenterCrop(160),", "\n", "#     transform.Scale(64)", "\n", "#     transforms.ToTensor(),", "\n", "#     transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))", "\n", "# ])", "\n", "\n", "# data_dir = 'data/celebA'  # this path depends on your computer", "\n", "    ", "dset", "=", "datasets", ".", "ImageFolder", "(", "dir", ",", "transform", ")", "\n", "data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dset", ",", "batch_size", ",", "shuffle", ")", "\n", "\n", "return", "data_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils.print_network": [[126, 132], ["net.parameters", "print", "print", "param.numel"], "function", ["None"], ["", "def", "print_network", "(", "net", ")", ":", "\n", "    ", "num_params", "=", "0", "\n", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "        ", "num_params", "+=", "param", ".", "numel", "(", ")", "\n", "", "print", "(", "net", ")", "\n", "print", "(", "'Total number of parameters: %d'", "%", "num_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils.save_images": [[133, 135], ["utils.imsave"], "function", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils.imsave"], ["", "def", "save_images", "(", "images", ",", "size", ",", "image_path", ")", ":", "\n", "    ", "return", "imsave", "(", "images", ",", "size", ",", "image_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils.imsave": [[136, 139], ["numpy.squeeze", "scipy.misc.imsave", "utils.merge"], "function", ["home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils.imsave", "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils.merge"], ["", "def", "imsave", "(", "images", ",", "size", ",", "path", ")", ":", "\n", "    ", "image", "=", "np", ".", "squeeze", "(", "merge", "(", "images", ",", "size", ")", ")", "\n", "return", "scipy", ".", "misc", ".", "imsave", "(", "path", ",", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils.merge": [[140, 159], ["numpy.zeros", "enumerate", "numpy.zeros", "enumerate", "ValueError"], "function", ["None"], ["", "def", "merge", "(", "images", ",", "size", ")", ":", "\n", "    ", "h", ",", "w", "=", "images", ".", "shape", "[", "1", "]", ",", "images", ".", "shape", "[", "2", "]", "\n", "if", "(", "images", ".", "shape", "[", "3", "]", "in", "(", "3", ",", "4", ")", ")", ":", "\n", "        ", "c", "=", "images", ".", "shape", "[", "3", "]", "\n", "img", "=", "np", ".", "zeros", "(", "(", "h", "*", "size", "[", "0", "]", ",", "w", "*", "size", "[", "1", "]", ",", "c", ")", ")", "\n", "for", "idx", ",", "image", "in", "enumerate", "(", "images", ")", ":", "\n", "            ", "i", "=", "idx", "%", "size", "[", "1", "]", "\n", "j", "=", "idx", "//", "size", "[", "1", "]", "\n", "img", "[", "j", "*", "h", ":", "j", "*", "h", "+", "h", ",", "i", "*", "w", ":", "i", "*", "w", "+", "w", ",", ":", "]", "=", "image", "\n", "", "return", "img", "\n", "", "elif", "images", ".", "shape", "[", "3", "]", "==", "1", ":", "\n", "        ", "img", "=", "np", ".", "zeros", "(", "(", "h", "*", "size", "[", "0", "]", ",", "w", "*", "size", "[", "1", "]", ")", ")", "\n", "for", "idx", ",", "image", "in", "enumerate", "(", "images", ")", ":", "\n", "            ", "i", "=", "idx", "%", "size", "[", "1", "]", "\n", "j", "=", "idx", "//", "size", "[", "1", "]", "\n", "img", "[", "j", "*", "h", ":", "j", "*", "h", "+", "h", ",", "i", "*", "w", ":", "i", "*", "w", "+", "w", "]", "=", "image", "[", ":", ",", ":", ",", "0", "]", "\n", "", "return", "img", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'in merge(images,size) images parameter '", "'must have dimensions: HxW or HxWx3 or HxWx4'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils.generate_animation": [[160, 166], ["range", "imageio.mimsave", "images.append", "imageio.imread"], "function", ["None"], ["", "", "def", "generate_animation", "(", "path", ",", "num", ")", ":", "\n", "    ", "images", "=", "[", "]", "\n", "for", "e", "in", "range", "(", "num", ")", ":", "\n", "        ", "img_name", "=", "path", "+", "'_epoch%03d'", "%", "(", "e", "+", "1", ")", "+", "'.png'", "\n", "images", ".", "append", "(", "imageio", ".", "imread", "(", "img_name", ")", ")", "\n", "", "imageio", ".", "mimsave", "(", "path", "+", "'_generate_animation.gif'", ",", "images", ",", "fps", "=", "5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils.plt_kldiv": [[167, 177], ["matplotlib.subplots", "ax.semilogy", "ax.set_ylabel", "ax.set_xlabel", "ax.grid", "ax.legend", "f.savefig", "matplotlib.close", "os.path.join"], "function", ["None"], ["", "def", "plt_kldiv", "(", "x", ",", "y", ",", "path", ",", "filename", ")", ":", "\n", "\n", "    ", "f", ",", "ax", "=", "plt", ".", "subplots", "(", "1", ")", "\n", "ax", ".", "semilogy", "(", "x", ",", "y", ",", "label", "=", "r'$KL( p(x) || \\bar p_{\\theta}(x) )$'", ")", "\n", "ax", ".", "set_ylabel", "(", "'KL-divergence'", ")", "\n", "ax", ".", "set_xlabel", "(", "'Iteration'", ")", "\n", "ax", ".", "grid", "(", ")", "\n", "ax", ".", "legend", "(", ")", "\n", "f", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "path", ",", "filename", ")", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils.loss_plot": [[178, 232], ["range", "matplotlib.plot", "matplotlib.plot", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.legend", "matplotlib.grid", "matplotlib.tight_layout", "os.path.join", "matplotlib.savefig", "matplotlib.close", "range", "numpy.array", "matplotlib.plot", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.legend", "matplotlib.grid", "matplotlib.tight_layout", "matplotlib.savefig", "matplotlib.close", "len", "len", "numpy.array", "numpy.stack", "matplotlib.xlim", "matplotlib.ylim", "os.path.join", "os.path.join", "numpy.savetxt", "os.path.join"], "function", ["None"], ["", "def", "loss_plot", "(", "hist", ",", "path", "=", "'Train_hist.png'", ",", "model_name", "=", "''", ",", "bvae", "=", "False", ",", "bintermediate", "=", "False", ")", ":", "\n", "\n", "    ", "if", "not", "bvae", ":", "\n", "\n", "        ", "x", "=", "range", "(", "len", "(", "hist", "[", "'D_loss'", "]", ")", ")", "\n", "\n", "y1", "=", "hist", "[", "'D_loss'", "]", "\n", "y2", "=", "hist", "[", "'G_loss'", "]", "\n", "\n", "plt", ".", "plot", "(", "x", ",", "y1", ",", "label", "=", "'D_loss'", ")", "\n", "plt", ".", "plot", "(", "x", ",", "y2", ",", "label", "=", "'G_loss'", ")", "\n", "\n", "plt", ".", "xlabel", "(", "'Iter'", ")", "\n", "plt", ".", "ylabel", "(", "'Loss'", ")", "\n", "\n", "plt", ".", "legend", "(", "loc", "=", "4", ")", "\n", "plt", ".", "grid", "(", "True", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "model_name", "+", "'_loss.png'", ")", "\n", "\n", "plt", ".", "savefig", "(", "path", ")", "\n", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "", "if", "bvae", ":", "\n", "        ", "x", "=", "range", "(", "len", "(", "hist", "[", "'Total_loss'", "]", ")", ")", "\n", "y1", "=", "hist", "[", "'Total_loss'", "]", "\n", "\n", "xnp", "=", "np", ".", "array", "(", "x", ")", "\n", "ynp", "=", "-", "np", ".", "array", "(", "y1", ")", "\n", "\n", "plt", ".", "plot", "(", "xnp", ",", "ynp", "-", "110.", ",", "label", "=", "'ELBO'", ")", "\n", "\n", "plt", ".", "xlabel", "(", "'Iteration'", ")", "\n", "plt", ".", "ylabel", "(", "'ELBO'", ")", "\n", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "grid", "(", "True", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "\n", "l_store", "=", "np", ".", "stack", "(", "(", "xnp", ",", "ynp", ")", ")", ".", "T", "\n", "\n", "if", "bintermediate", ":", "\n", "            ", "plt", ".", "xlim", "(", "0", ",", "4000", ")", "\n", "plt", ".", "ylim", "(", "-", "180", ",", "0", ")", "\n", "pathpng", "=", "os", ".", "path", ".", "join", "(", "path", ",", "model_name", "+", "'.png'", ")", "\n", "", "else", ":", "\n", "            ", "pathpng", "=", "os", ".", "path", ".", "join", "(", "path", ",", "model_name", "+", "'_loss.pdf'", ")", "\n", "np", ".", "savetxt", "(", "os", ".", "path", ".", "join", "(", "path", ",", "model_name", "+", "'_loss.txt'", ")", ",", "l_store", ")", "\n", "\n", "", "plt", ".", "savefig", "(", "pathpng", ",", "bbox_inches", "=", "'tight'", ")", "\n", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cics-nd_predictive-cvs.None.utils.initialize_weights": [[233, 246], ["net.modules", "net.modules", "isinstance", "m.weight.data.normal_", "m.bias.data.zero_", "isinstance", "m.weight.data.normal_", "m.bias.data.zero_", "isinstance", "m.weight.data.normal_", "m.bias.data.zero_"], "function", ["None"], ["", "", "def", "initialize_weights", "(", "net", ")", ":", "\n", "    ", "_mod", "=", "net", ".", "modules", "(", ")", "\n", "\n", "for", "m", "in", "net", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "            ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "ConvTranspose2d", ")", ":", "\n", "            ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "", "", "", "", ""]]}