{"home.repos.pwc.inspect_result.cciiplab_dpt.Oscar.setup.readme": [[20, 24], ["open().read", "open", "os.join"], "function", ["None"], ["def", "readme", "(", "fname", ")", ":", "\n", "    ", "\"\"\"Read text out of a file in the same directory as setup.py.\n    \"\"\"", "\n", "return", "open", "(", "op", ".", "join", "(", "script_dir", ",", "fname", ")", ")", ".", "read", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.Oscar.setup.find_version": [[26, 33], ["setup.readme", "re.search", "RuntimeError", "re.search.group"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.Oscar.setup.readme", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.ConstrainedBeamSearch.search"], ["", "def", "find_version", "(", "fname", ")", ":", "\n", "    ", "version_file", "=", "readme", "(", "fname", ")", "\n", "version_match", "=", "re", ".", "search", "(", "r\"^__version__ = ['\\\"]([^'\\\"]*)['\\\"]\"", ",", "\n", "version_file", ",", "re", ".", "M", ")", "\n", "if", "version_match", ":", "\n", "        ", "return", "version_match", ".", "group", "(", "1", ")", "\n", "", "raise", "RuntimeError", "(", "\"Unable to find version string.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_oscarplus_pretrain.main": [[41, 546], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "random.seed", "numpy.random.seed", "torch.manual_seed", "os.path.exists", "config_class.from_pretrained", "sum", "logger.info", "vars().items", "torch.nn.DataParallel.to", "logger.info", "os.path.join", "oscar.utils.metric_logger.TensorboardLogger", "list", "transformers.pytorch_transformers.AdamW", "transformers.pytorch_transformers.WarmupLinearSchedule", "oscar.datasets.build.make_data_loader", "isinstance", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.train", "torch.nn.DataParallel.zero_grad", "enumerate", "str", "logger.info", "oscar.utils.metric_logger.TensorboardLogger.close", "int", "os.path.exists", "os.listdir", "logger.info", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "ValueError", "torch.cuda.manual_seed_all", "ValueError", "os.path.exists", "oscar.utils.misc.mkdir", "os.path.join", "oscar.utils.misc.get_rank", "torch.distributed.barrier", "logger.info", "setattr", "torch.distributed.barrier", "torch.nn.DataParallel.named_parameters", "os.path.isfile", "logger.info", "torch.load", "transformers.pytorch_transformers.AdamW.load_state_dict", "transformers.pytorch_transformers.WarmupLinearSchedule.load_state_dict", "torch.nn.parallel.DistributedDataParallel", "len", "isinstance", "logger.info", "zip", "run_oscarplus_pretrain.main.data_process"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.build.make_data_loader", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.TensorboardLogger.close", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.mkdir", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "help", "=", "\"The input data dir. \"", "\n", "\"Should contain the .yaml files for the task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The training dataset yaml file.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--extra_dataset_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "help", "=", "\"The extra training dataset yaml file.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--bert_model\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Bert pre-trained model selected in the list: bert-base-uncased, \"", "\n", "\"bert-large-uncased, bert-base-cased, bert-base-multilingual, bert-base-chinese.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model checkpoints will be written.\"", ")", "\n", "\n", "# image chunks", "\n", "parser", ".", "add_argument", "(", "\"--chunk_start_id\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Image Chunk Start ID\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--chunk_end_id\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Image Chunk End ID\"", ")", "\n", "\n", "## Image parameters", "\n", "parser", ".", "add_argument", "(", "\"--max_img_seq_length\"", ",", "default", "=", "50", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input image sequence length.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_dim\"", ",", "default", "=", "2054", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The Image Feature Dimension.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_type\"", ",", "default", "=", "'faster_r-cnn'", ",", "type", "=", "str", ",", "\n", "help", "=", "\"faster_r-cnn or mask_r-cnn\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_layernorm\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"use_layernorm\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--drop_out\"", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Drop out for BERT.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--use_b\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"use_b\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--textb_sample_mode\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"0: sample from both texta&textb, \"", "\n", "\"1: sample from textb, \"", "\n", "\"2: sample from QA answers\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--extra_textb_sample_mode\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--texta_false_prob\"", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "\"the probality that we sample wrong texta, should in [0.0, 0.5]\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name selected in the list: \"", "+", "\", \"", ".", "join", "(", "\n", "ALL_MODELS", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "default", "=", "35", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after WordPiece tokenization. \\n\"", "\n", "\"Sequences longer than this will be truncated, and sequences shorter than this will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_iters\"", ",", "default", "=", "2000000", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Maximal number of training iterations.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_batch_size\"", ",", "default", "=", "1024", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_workers\"", ",", "default", "=", "6", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Number of workers for dataset.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--optim\"", ",", "default", "=", "'adamw'", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The optimizer used for Bert, [adamw, lamb], default: adamw\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "-", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether not to use CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--on_memory\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to load train samples into memory or use disk\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to lower case the input text. True for uncased models, False for cased models.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"local_rank for distributed training on gpus\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumualte before performing a backward/update pass.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--from_scratch\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"train from scratch\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_img_layernorm\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Normalize image features with bertlayernorm\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_layer_norm_eps\"", ",", "default", "=", "1e-12", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The eps in image feature laynorm layer\"", ")", "\n", "# distributed", "\n", "parser", ".", "add_argument", "(", "'--gpu_ids'", ",", "type", "=", "str", ",", "default", "=", "'-1'", ")", "\n", "parser", ".", "add_argument", "(", "\"--mask_loss_for_unmatched\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"masked language model loss for unmatched triplets\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--extra_loss_weight\"", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "\"the loss weight for the extra train data batch (should be in [0,1])\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--use_gtlabels\"", ",", "\n", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"use groundtruth labels for text b or not\"", "\n", ")", "\n", "# logging", "\n", "parser", ".", "add_argument", "(", "'--ckpt_period'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "\"Period for saving checkpoint\"", ")", "\n", "parser", ".", "add_argument", "(", "'--log_period'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "\"Period for saving logging info\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "gpu_ids", "!=", "'-1'", ":", "\n", "        ", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", "=", "args", ".", "gpu_ids", "\n", "\n", "", "args", ".", "num_gpus", "=", "int", "(", "\n", "os", ".", "environ", "[", "\"WORLD_SIZE\"", "]", ")", "if", "\"WORLD_SIZE\"", "in", "os", ".", "environ", "else", "1", "\n", "args", ".", "distributed", "=", "args", ".", "num_gpus", ">", "1", "\n", "\n", "if", "args", ".", "gpu_ids", "!=", "'-1'", ":", "\n", "        ", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", "=", "args", ".", "gpu_ids", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", ":", "\n", "        ", "logger", ".", "info", "(", "\"Output Directory Exists.\"", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\n", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "'nccl'", ",", "init_method", "=", "\"env://\"", "\n", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s - %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", "\n", ")", "\n", "\n", "if", "args", ".", "gradient_accumulation_steps", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\"", ".", "format", "(", "\n", "args", ".", "gradient_accumulation_steps", ")", ")", "\n", "\n", "", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n", "", "if", "not", "args", ".", "do_train", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Training is currently the only implemented execution option. Please set `do_train`.\"", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", ":", "\n", "        ", "mkdir", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "last_checkpoint_dir", "=", "None", "\n", "arguments", "=", "{", "\"iteration\"", ":", "0", "}", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", ":", "\n", "        ", "save_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"last_checkpoint\"", ")", "\n", "try", ":", "\n", "            ", "with", "open", "(", "save_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "last_saved", "=", "f", ".", "read", "(", ")", "\n", "last_saved", "=", "last_saved", ".", "strip", "(", ")", "\n", "", "", "except", "IOError", ":", "\n", "# if file doesn't exist, maybe because it has just been", "\n", "# deleted by a separate process", "\n", "            ", "last_saved", "=", "\"\"", "\n", "", "if", "last_saved", ":", "\n", "            ", "folder_name", "=", "os", ".", "path", ".", "splitext", "(", "last_saved", ".", "split", "(", "'/'", ")", "[", "0", "]", ")", "[", "0", "]", "# in the form of checkpoint-00001 or checkpoint-00001/pytorch_model.bin", "\n", "last_checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "folder_name", ")", "\n", "arguments", "[", "\"iteration\"", "]", "=", "int", "(", "folder_name", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "last_checkpoint_dir", ",", "WEIGHTS_NAME", ")", ")", ",", "\"Last_checkpoint detected, but file not found!\"", "\n", "\n", "# model first", "\n", "", "", "if", "get_rank", "(", ")", "!=", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "bert_model", "]", "\n", "if", "last_checkpoint_dir", "is", "not", "None", ":", "# recovery", "\n", "        ", "args", ".", "model_name_or_path", "=", "last_checkpoint_dir", "\n", "logger", ".", "info", "(", "\" -> Recovering model from {}\"", ".", "format", "(", "last_checkpoint_dir", ")", ")", "\n", "\n", "", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", ")", "\n", "config", ".", "img_layer_norm_eps", "=", "args", ".", "img_layer_norm_eps", "\n", "config", ".", "use_img_layernorm", "=", "args", ".", "use_img_layernorm", "\n", "\n", "# discrete code", "\n", "config", ".", "img_feature_dim", "=", "args", ".", "img_feature_dim", "\n", "config", ".", "img_feature_type", "=", "args", ".", "img_feature_type", "\n", "config", ".", "hidden_dropout_prob", "=", "args", ".", "drop_out", "\n", "if", "args", ".", "texta_false_prob", "<", "0.5", "and", "(", "args", ".", "texta_false_prob", ">", "0", "or", "not", "args", ".", "use_b", ")", ":", "\n", "        ", "args", ".", "num_contrast_classes", "=", "3", "\n", "", "else", ":", "\n", "        ", "args", ".", "num_contrast_classes", "=", "2", "\n", "", "config", ".", "num_contrast_classes", "=", "args", ".", "num_contrast_classes", "\n", "\n", "# Prepare model", "\n", "# model = BertForPreTraining.from_pretrained(args.bert_model)", "\n", "load_num", "=", "0", "\n", "while", "load_num", "<", "10", ":", "\n", "        ", "try", ":", "\n", "            ", "model", "=", "BertImgForPreTraining", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "'.ckpt'", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ")", "\n", "break", "\n", "", "except", ":", "\n", "            ", "load_num", "+=", "1", "\n", "\n", "# train from scratch", "\n", "", "", "if", "args", ".", "from_scratch", ":", "\n", "        ", "if", "last_checkpoint_dir", "is", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\"Training from scratch ... \"", ")", "\n", "model", ".", "apply", "(", "model", ".", "init_weights", ")", "\n", "", "", "total_params", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", ")", "\n", "logger", ".", "info", "(", "\n", "'Total Parameters: {}'", ".", "format", "(", "total_params", ")", ")", "\n", "\n", "for", "key", ",", "val", "in", "vars", "(", "config", ")", ".", "items", "(", ")", ":", "\n", "        ", "setattr", "(", "args", ",", "key", ",", "val", ")", "\n", "\n", "", "if", "get_rank", "(", ")", "==", "0", "and", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "tb_log_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'train_logs'", ")", "\n", "meters", "=", "TensorboardLogger", "(", "\n", "log_dir", "=", "tb_log_dir", ",", "\n", "delimiter", "=", "\"  \"", ",", "\n", ")", "\n", "\n", "# Prepare optimizer", "\n", "param_optimizer", "=", "list", "(", "model", ".", "named_parameters", "(", ")", ")", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "\n", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "0.01", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "\n", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "WarmupLinearSchedule", "(", "optimizer", ",", "\n", "warmup_steps", "=", "args", ".", "warmup_steps", ",", "\n", "t_total", "=", "args", ".", "max_iters", ")", "\n", "\n", "if", "arguments", "[", "'iteration'", "]", ">", "0", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "last_checkpoint_dir", ",", "'optimizer.pth'", ")", ")", ":", "# recovery", "\n", "        ", "logger", ".", "info", "(", "\n", "\"Load BERT optimizer from {}\"", ".", "format", "(", "last_checkpoint_dir", ")", ")", "\n", "optimizer_to_load", "=", "torch", ".", "load", "(", "\n", "os", ".", "path", ".", "join", "(", "last_checkpoint_dir", ",", "'optimizer.pth'", ")", ",", "\n", "map_location", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "optimizer", ".", "load_state_dict", "(", "optimizer_to_load", ".", "pop", "(", "\"optimizer\"", ")", ")", "\n", "scheduler", ".", "load_state_dict", "(", "optimizer_to_load", ".", "pop", "(", "\"scheduler\"", ")", ")", "\n", "\n", "", "if", "args", ".", "distributed", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ")", "\n", "", "elif", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# train_examples = None", "\n", "", "train_dataloaders", "=", "make_data_loader", "(", "\n", "args", ",", "is_distributed", "=", "args", ".", "distributed", ",", "arguments", "=", "arguments", "\n", ")", "\n", "\n", "if", "isinstance", "(", "train_dataloaders", ",", "list", ")", ":", "\n", "        ", "train_dataloader", "=", "train_dataloaders", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "train_dataloader", "=", "train_dataloaders", "\n", "", "train_dataloader_extra", "=", "[", "None", "]", "*", "len", "(", "train_dataloader", ")", "\n", "if", "isinstance", "(", "train_dataloaders", ",", "list", ")", "and", "len", "(", "train_dataloaders", ")", ">", "1", ":", "\n", "        ", "logger", ".", "info", "(", "\"Having two train dataloaders!\"", ")", "\n", "train_dataloader_extra", "=", "train_dataloaders", "[", "1", "]", "\n", "", "tokenizer", "=", "train_dataloader", ".", "dataset", ".", "tokenizer", "\n", "\n", "# torch.backends.cudnn.benchmark = True", "\n", "\n", "max_iter", "=", "len", "(", "train_dataloader", ")", "\n", "start_iter", "=", "arguments", "[", "\"iteration\"", "]", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\" Num examples = {}\"", ".", "format", "(", "len", "(", "train_dataloader", ".", "dataset", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size = %d\"", ",", "\n", "args", ".", "train_batch_size", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "\n", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "\n", "max_iter", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "\n", "log_json", "=", "{", "}", "\n", "\n", "model", ".", "train", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "clock_started", "=", "False", "\n", "# Every args.ckpt_period, report train_score and save model", "\n", "tr_loss", "=", "0", "\n", "nb_tr_examples", ",", "nb_tr_steps", "=", "0", ",", "0", "\n", "for", "step", ",", "(", "batch", ",", "batch_extra", ")", "in", "enumerate", "(", "zip", "(", "train_dataloader", ",", "train_dataloader_extra", ")", ",", "start_iter", ")", ":", "\n", "        ", "if", "not", "clock_started", ":", "\n", "            ", "start_training_time", "=", "time", ".", "time", "(", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "clock_started", "=", "True", "\n", "\n", "", "def", "data_process", "(", "mini_batch", ")", ":", "\n", "            ", "images", ",", "targets", ",", "qa_inds", "=", "mini_batch", "[", "0", "]", ",", "mini_batch", "[", "1", "]", ",", "mini_batch", "[", "2", "]", "\n", "targets_transposed", "=", "list", "(", "zip", "(", "*", "targets", ")", ")", "\n", "input_ids", "=", "torch", ".", "stack", "(", "targets_transposed", "[", "0", "]", ")", ".", "to", "(", "args", ".", "device", ",", "non_blocking", "=", "True", ")", "\n", "input_mask", "=", "torch", ".", "stack", "(", "targets_transposed", "[", "1", "]", ")", ".", "to", "(", "args", ".", "device", ",", "non_blocking", "=", "True", ")", "\n", "segment_ids", "=", "torch", ".", "stack", "(", "targets_transposed", "[", "2", "]", ")", ".", "to", "(", "args", ".", "device", ",", "non_blocking", "=", "True", ")", "\n", "lm_label_ids", "=", "torch", ".", "stack", "(", "targets_transposed", "[", "3", "]", ")", ".", "to", "(", "args", ".", "device", ",", "non_blocking", "=", "True", ")", "\n", "is_next", "=", "torch", ".", "stack", "(", "targets_transposed", "[", "4", "]", ")", ".", "to", "(", "args", ".", "device", ",", "non_blocking", "=", "True", ")", "\n", "is_img_match", "=", "torch", ".", "stack", "(", "targets_transposed", "[", "5", "]", ")", ".", "to", "(", "args", ".", "device", ",", "non_blocking", "=", "True", ")", "\n", "\n", "return", "images", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "lm_label_ids", ",", "is_next", "\n", "\n", "", "images1", ",", "input_ids1", ",", "input_mask1", ",", "segment_ids1", ",", "lm_label_ids1", ",", "is_next1", "=", "data_process", "(", "batch", ")", "\n", "if", "batch_extra", "is", "not", "None", ":", "\n", "            ", "images2", ",", "input_ids2", ",", "input_mask2", ",", "segment_ids2", ",", "lm_label_ids2", ",", "is_next2", "=", "data_process", "(", "batch_extra", ")", "\n", "\n", "", "data_time", "=", "time", ".", "time", "(", ")", "-", "end", "\n", "\n", "def", "forward_backward", "(", "images", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "\n", "lm_label_ids", ",", "is_next", ",", "loss_weight", "=", "1.0", ")", ":", "\n", "# feature as input", "\n", "            ", "image_features", "=", "torch", ".", "stack", "(", "images", ")", ".", "to", "(", "args", ".", "device", ",", "non_blocking", "=", "True", ")", "\n", "\n", "outputs", "=", "model", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "\n", "lm_label_ids", ",", "is_next", ",", "img_feats", "=", "image_features", ")", "\n", "\n", "loss", "=", "loss_weight", "*", "outputs", "[", "0", "]", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu.", "\n", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "return", "loss", ".", "item", "(", ")", ",", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "", "start1", "=", "time", ".", "time", "(", ")", "\n", "loss1", ",", "nb_tr_example1", "=", "forward_backward", "(", "\n", "images1", ",", "input_ids1", ",", "input_mask1", ",", "\n", "segment_ids1", ",", "lm_label_ids1", ",", "is_next1", ",", "\n", "loss_weight", "=", "1.0", "-", "args", ".", "extra_loss_weight", "\n", ")", "\n", "tr_loss", "+=", "loss1", "\n", "nb_tr_examples", "+=", "nb_tr_example1", "\n", "compute_time1", "=", "time", ".", "time", "(", ")", "-", "start1", "\n", "\n", "loss2", ",", "nb_tr_example2", "=", "0.0", ",", "0", "\n", "compute_time2", "=", "0.0", "\n", "if", "batch_extra", "is", "not", "None", ":", "\n", "            ", "start2", "=", "time", ".", "time", "(", ")", "\n", "loss2", ",", "nb_tr_example2", "=", "forward_backward", "(", "\n", "images2", ",", "input_ids2", ",", "input_mask2", ",", "\n", "segment_ids2", ",", "lm_label_ids2", ",", "is_next2", ",", "\n", "loss_weight", "=", "args", ".", "extra_loss_weight", "\n", ")", "\n", "tr_loss", "+=", "loss2", "\n", "nb_tr_examples", "+=", "nb_tr_example2", "\n", "compute_time2", "=", "time", ".", "time", "(", ")", "-", "start2", "\n", "\n", "", "nb_tr_steps", "+=", "1", "\n", "arguments", "[", "\"iteration\"", "]", "=", "step", "+", "1", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "# do gradient clipping", "\n", "            ", "if", "args", ".", "max_grad_norm", ">", "0", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "# do the optimization steps", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", "=", "time", ".", "time", "(", ")", "-", "end", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "metrics_to_log", "=", "{", "\n", "'time_info'", ":", "{", "'compute'", ":", "batch_time", ",", "'data'", ":", "data_time", ",", "\n", "'compute1'", ":", "compute_time1", ",", "\n", "'compute2'", ":", "compute_time2", "}", ",", "\n", "'batch_metrics'", ":", "{", "'loss'", ":", "loss1", "+", "loss2", "}", "\n", "}", "\n", "params_to_log", "=", "{", "'params'", ":", "{", "'bert_lr'", ":", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", "}", "}", "\n", "meters", ".", "update_metrics", "(", "metrics_to_log", ")", "\n", "meters", ".", "update_params", "(", "params_to_log", ")", "\n", "\n", "if", "args", ".", "log_period", ">", "0", "and", "(", "step", "+", "1", ")", "%", "args", ".", "log_period", "==", "0", ":", "\n", "                ", "avg_time", "=", "meters", ".", "meters", "[", "'time_info'", "]", "[", "'compute'", "]", ".", "global_avg", "\n", "eta_seconds", "=", "avg_time", "*", "(", "max_iter", "-", "step", "-", "1", ")", "\n", "eta_string", "=", "str", "(", "\n", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "eta_seconds", ")", ")", ")", "\n", "logger", ".", "info", "(", "\n", "meters", ".", "delimiter", ".", "join", "(", "\n", "[", "\n", "\"eta: {eta}\"", ",", "\n", "\"iter: {iter}\"", ",", "\n", "\"max mem: {memory:.0f}\"", ",", "\n", "]", "\n", ")", ".", "format", "(", "\n", "eta", "=", "eta_string", ",", "\n", "iter", "=", "step", "+", "1", ",", "\n", "memory", "=", "torch", ".", "cuda", ".", "max_memory_allocated", "(", ")", "/", "1024.0", "/", "1024.0", ",", "\n", ")", "+", "\"\\n    \"", "+", "meters", ".", "get_logs", "(", "step", "+", "1", ")", "\n", ")", "\n", "\n", "", "", "if", "(", "step", "+", "1", ")", "==", "max_iter", "or", "(", "step", "+", "1", ")", "%", "args", ".", "ckpt_period", "==", "0", ":", "# Save a trained model", "\n", "            ", "log_json", "[", "step", "+", "1", "]", "=", "tr_loss", "\n", "train_metrics_total", "=", "torch", ".", "Tensor", "(", "[", "tr_loss", ",", "nb_tr_examples", ",", "nb_tr_steps", "]", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "torch", ".", "distributed", ".", "all_reduce", "(", "train_metrics_total", ")", "\n", "# reset metrics", "\n", "tr_loss", "=", "0", "\n", "nb_tr_examples", ",", "nb_tr_steps", "=", "0", ",", "0", "\n", "\n", "if", "get_rank", "(", ")", "==", "0", ":", "\n", "# report metrics", "\n", "                ", "train_score_gathered", "=", "train_metrics_total", "[", "0", "]", "/", "train_metrics_total", "[", "2", "]", "\n", "logger", ".", "info", "(", "\"PROGRESS: {}%\"", ".", "format", "(", "\n", "round", "(", "100", "*", "(", "step", "+", "1", ")", "/", "max_iter", ",", "4", ")", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"EVALERR: {}%\"", ".", "format", "(", "train_score_gathered", ")", ")", "\n", "meters", ".", "update_metrics", "(", "\n", "{", "\n", "'epoch_metrics'", ":", "{", "'ex_cnt'", ":", "train_metrics_total", "[", "1", "]", ",", "\n", "'loss'", ":", "train_score_gathered", "}", "\n", "}", "\n", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'loss_logs.json'", ")", ",", "\n", "'w'", ")", "as", "fp", ":", "\n", "                    ", "json", ".", "dump", "(", "log_json", ",", "fp", ")", "\n", "\n", "# save checkpoint", "\n", "", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "'checkpoint-{:07d}'", ".", "format", "(", "\n", "step", "+", "1", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                    ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "\n", "model", ",", "\n", "'module'", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "optimizer_to_save", "=", "{", "\n", "\"optimizer\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"scheduler\"", ":", "scheduler", ".", "state_dict", "(", ")", "}", "\n", "\n", "save_num", "=", "0", "\n", "while", "save_num", "<", "10", ":", "\n", "                    ", "try", ":", "\n", "                        ", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\n", "'training_args.bin'", ")", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "optimizer_to_save", ",", "\n", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\n", "'optimizer.pth'", ")", ")", "\n", "save_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"last_checkpoint\"", ")", "\n", "with", "open", "(", "save_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "                            ", "f", ".", "write", "(", "'checkpoint-{:07d}/pytorch_model.bin'", ".", "format", "(", "step", "+", "1", ")", ")", "\n", "", "break", "\n", "", "except", ":", "\n", "                        ", "save_num", "+=", "1", "\n", "", "", "logger", ".", "info", "(", "\n", "\"Saving model checkpoint {0} to {1}\"", ".", "format", "(", "\n", "step", "+", "1", ",", "output_dir", ")", ")", "\n", "\n", "", "", "", "if", "clock_started", ":", "\n", "        ", "total_training_time", "=", "time", ".", "time", "(", ")", "-", "start_training_time", "\n", "", "else", ":", "\n", "        ", "total_training_time", "=", "0.0", "\n", "", "total_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "total_training_time", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"Total training time: {} ({:.4f} s / it)\"", ".", "format", "(", "\n", "total_time_str", ",", "total_training_time", "/", "max_iter", "\n", ")", "\n", ")", "\n", "# close the tb logger", "\n", "meters", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.ImageBertForSequenceClassificationPrompt.__init__": [[36, 57], ["oscar.modeling.modeling_bert.ImageBertForSequenceClassification.__init__", "transformers.pytorch_transformers.modeling_bert.BertPooler", "hasattr", "run_vqa_prompt_mlm.ImageBertForSequenceClassificationPrompt.apply", "torch.Linear", "torch.Linear", "hasattr", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "ImageBertForSequenceClassificationPrompt", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "mask_pooler", "=", "BertPooler", "(", "config", ")", "\n", "\n", "if", "hasattr", "(", "config", ",", "'classifier'", ")", ":", "\n", "            ", "if", "not", "hasattr", "(", "config", ",", "'cls_hidden_scale'", ")", ":", "\n", "                ", "config", ".", "cls_hidden_scale", "=", "2", "\n", "\n", "", "if", "config", ".", "classifier", "==", "'linear'", ":", "\n", "                ", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "\n", "self", ".", "config", ".", "num_labels", ")", "\n", "", "elif", "config", ".", "classifier", "==", "'mlp'", ":", "\n", "                ", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", "*", "config", ".", "cls_hidden_scale", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "config", ".", "cls_hidden_scale", ",", "self", ".", "config", ".", "num_labels", ")", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "self", ".", "config", ".", "num_labels", ")", "# original", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.ImageBertForSequenceClassificationPrompt.forward": [[58, 84], ["run_vqa_prompt_mlm.ImageBertForSequenceClassificationPrompt.bert", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "run_vqa_prompt_mlm.ImageBertForSequenceClassificationPrompt.mask_pooler", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "run_vqa_prompt_mlm.ImageBertForSequenceClassificationPrompt.dropout", "run_vqa_prompt_mlm.ImageBertForSequenceClassificationPrompt.classifier", "run_vqa_prompt_mlm.instance_bce_with_logits", "mask_index.unsqueeze().expand", "mask_index.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.instance_bce_with_logits"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "img_feats", "=", "None", ",", "mask_index", "=", "None", ")", ":", "\n", "# (batch_size, sequence_length, hidden_dim), (batch_size, hidden_dim), ...", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ",", "img_feats", "=", "img_feats", ")", "\n", "\n", "# (batch_size, hidden_dim)", "\n", "# pooled_output = outputs[1]", "\n", "seq_length", ",", "hidden_dim", "=", "outputs", "[", "0", "]", ".", "shape", "[", "1", ":", "]", "\n", "pooled_output", "=", "torch", ".", "gather", "(", "\n", "input", "=", "outputs", "[", "0", "]", ",", "\n", "dim", "=", "1", ",", "\n", "index", "=", "mask_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "(", "-", "1", ",", "-", "1", ",", "hidden_dim", ")", ")", "\n", ")", "# [batch_size, 1, hidden_dim]", "\n", "pooled_output", "=", "self", ".", "mask_pooler", "(", "pooled_output", ")", "# [batch_size, hidden_dim]", "\n", "pooled_output_cls", "=", "outputs", "[", "1", "]", "# [batch_size, hidden_dim]", "\n", "pooled_output", "=", "torch", ".", "cat", "(", "[", "pooled_output", ",", "pooled_output_cls", "]", ",", "dim", "=", "-", "1", ")", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss", "=", "instance_bce_with_logits", "(", "logits", ",", "labels", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.VQADataset.__init__": [[135, 185], ["torch.utils.data.Dataset.__init__", "time.time", "time.time", "logger.info", "run_vqa_prompt_mlm._load_dataset", "logger.info", "run_vqa_prompt_mlm.VQADataset.tensorize", "torch.load", "torch.load", "torch.load", "torch.load", "args.img_feature_type.startswith", "enumerate", "torch.load", "torch.load", "torch.load", "torch.load", "run_vqa_prompt_mlm.VQADataset.load_img_tsv_features", "os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "bool", "bool", "len", "os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few._load_dataset", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.load_img_tsv_features"], ["def", "__init__", "(", "self", ",", "args", ",", "name", ",", "tokenizer", ")", ":", "\n", "        ", "super", "(", "VQADataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "name", "in", "[", "'train'", ",", "'val'", ",", "'test-dev2015'", ",", "'test2015'", ",", "'train+val'", "]", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "name", "=", "name", "\n", "\n", "# load image features", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "img_feature_file", "=", "None", "\n", "self", ".", "img_feat_offset_map", "=", "None", "\n", "\n", "if", "args", ".", "img_feature_type", "==", "'faster_r-cnn'", ":", "\n", "            ", "if", "args", ".", "img_feat_format", "==", "'pt'", ":", "\n", "                ", "if", "args", ".", "img_feature_dim", "==", "2048", ":", "# object features", "\n", "                    ", "self", ".", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'{}_img_frcnn_obj_feats.pt'", ".", "format", "(", "name", ")", ")", ")", "\n", "", "else", ":", "# object + spatial features", "\n", "                    ", "if", "args", ".", "use_vg_dev", ":", "\n", "                        ", "self", ".", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'train+val_img_frcnn_feats.pt'", ")", ")", "\n", "", "else", ":", "\n", "                        ", "self", ".", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'{}_img_frcnn_feats.pt'", ".", "format", "(", "name", ")", ")", ")", "\n", "", "", "", "elif", "args", ".", "img_feat_format", "==", "'tsv'", ":", "\n", "                ", "self", ".", "load_img_tsv_features", "(", ")", "\n", "", "", "elif", "args", ".", "img_feature_type", "==", "'mask_r-cnn'", ":", "\n", "            ", "self", ".", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'{}_img_mask_rcnn_feats.pt'", ".", "format", "(", "name", ")", ")", ")", "\n", "", "elif", "args", ".", "img_feature_type", ".", "startswith", "(", "'dis_code'", ")", ":", "#in ['dis_code', 'dis_code_t']: # discrete code", "\n", "            ", "self", ".", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'vqvae'", ",", "'{}.pt'", ".", "format", "(", "name", ")", ")", ")", "[", "'feats_{}'", ".", "format", "(", "args", ".", "code_level", ")", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'{}_img_feats.pt'", ".", "format", "(", "name", ")", ")", ")", "\n", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: loading {0} features using {1:.2f} secs'", ".", "format", "(", "name", ",", "(", "t_end", "-", "t_start", ")", ")", ")", "\n", "\n", "# \"classification\"", "\n", "self", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n", "self", ".", "examples", ",", "self", ".", "labels", "=", "_load_dataset", "(", "args", ",", "name", ")", "\n", "self", ".", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "self", ".", "labels", ")", "}", "\n", "\n", "if", "self", ".", "args", ".", "load_fast", ":", "\n", "            ", "self", ".", "features", "=", "self", ".", "tensorize", "(", "args", ",", "cls_token_at_end", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "self", ".", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "\n", "", "logger", ".", "info", "(", "'%s Data Examples: %d'", "%", "(", "name", ",", "len", "(", "self", ".", "examples", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.VQADataset.tensorize": [[187, 293], ["enumerate", "run_vqa_prompt_mlm.VQADataset.tokenizer.tokenize", "run_vqa_prompt_mlm.VQADataset.tokenizer.convert_tokens_to_ids", "run_vqa_prompt_mlm.target_tensor", "features.append", "len", "logger.info", "run_vqa_prompt_mlm.VQADataset.tokenizer.tokenize", "oscar.utils.task_utils._truncate_seq_pair", "len", "len", "len", "len", "len", "len", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "len", "len", "float", "KeyError", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.target_tensor", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv._truncate_seq_pair"], ["", "def", "tensorize", "(", "self", ",", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "\n", "# debug:", "\n", "        ", "debug_size", "=", "500", "\n", "features", "=", "[", "]", "\n", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "self", ".", "examples", "[", "0", ":", "]", ")", ":", "\n", "            ", "if", "len", "(", "example", ".", "label", ")", "==", "0", ":", "continue", "\n", "if", "ex_index", "%", "10000", "==", "0", ":", "logger", ".", "info", "(", "\"Tensorizing example %d of %d\"", "%", "(", "ex_index", ",", "len", "(", "self", ".", "examples", ")", ")", ")", "\n", "\n", "tokens_a", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "                ", "tokens_b", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_b", ")", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "self", ".", "args", ".", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "                ", "if", "len", "(", "tokens_a", ")", ">", "self", ".", "args", ".", "max_seq_length", "-", "2", ":", "\n", "                    ", "tokens_a", "=", "tokens_a", "[", ":", "(", "self", ".", "args", ".", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "", "tokens", "=", "tokens_a", "+", "[", "sep_token", "]", "\n", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "                ", "tokens", "+=", "tokens_b", "+", "[", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "if", "cls_token_at_end", ":", "\n", "                ", "tokens", "=", "tokens", "+", "[", "cls_token", "]", "\n", "segment_ids", "=", "segment_ids", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "                ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "self", ".", "args", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "                ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "", "else", ":", "\n", "                ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "segment_ids", "=", "segment_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "\n", "# image features", "\n", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "# torch", "\n", "#img_feat = self.img_features.item().get(example.img_key)  # numpy", "\n", "if", "img_feat", ".", "shape", "[", "0", "]", ">", "self", ".", "args", ".", "max_img_seq_length", ":", "\n", "                ", "img_feat", "=", "img_feat", "[", "0", ":", "self", ".", "args", ".", "max_img_seq_length", ",", "]", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids += [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids = segment_ids + [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "self", ".", "args", ".", "max_img_seq_length", "-", "img_feat", ".", "shape", "[", "0", "]", ",", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_matrix", ".", "shape", "[", "0", "]", ")", "\n", "# segment_ids = segment_ids + [pad_token_segment_id] * padding_matrix.shape[0]", "\n", "\n", "", "", "if", "self", ".", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "                ", "label_id", "=", "[", "self", ".", "label_map", "[", "l", "]", "for", "l", "in", "example", ".", "label", "]", "\n", "score", "=", "example", ".", "score", "\n", "", "elif", "self", ".", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "                ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "else", ":", "\n", "                ", "raise", "KeyError", "(", "self", ".", "args", ".", "output_mode", ")", "\n", "\n", "", "if", "ex_index", "<", "5", ":", "\n", "                ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"segment_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label: %s (id = %s)\"", "%", "(", "example", ".", "label", ",", "label_id", ")", ")", "\n", "logger", ".", "info", "(", "\"score: %s (score = %s)\"", "%", "(", "example", ".", "score", ",", "score", ")", ")", "\n", "\n", "", "new_scores", "=", "target_tensor", "(", "len", "(", "self", ".", "labels", ")", ",", "label_id", ",", "score", ")", "\n", "#features.append(InputFeat(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label_id, score=score, img_feat=img_feat))", "\n", "features", ".", "append", "(", "(", "torch", ".", "tensor", "(", "input_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "label_id", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "new_scores", ",", "dtype", "=", "torch", ".", "float", ")", ",", "img_feat", ")", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.VQADataset.tensorize_example": [[294, 421], ["run_vqa_prompt_mlm.VQADataset.tokenizer.tokenize", "run_vqa_prompt_mlm.VQADataset.tokenizer.tokenize", "tokens.index", "run_vqa_prompt_mlm.VQADataset.tokenizer.convert_tokens_to_ids", "run_vqa_prompt_mlm.VQADataset.args.img_feature_type.startswith", "run_vqa_prompt_mlm.target_tensor", "run_vqa_prompt_mlm.VQADataset.tokenizer.tokenize", "run_vqa_prompt_mlm.VQADataset.tokenizer.tokenize", "oscar.utils.task_utils._truncate_seq_pair", "len", "len", "len", "len", "len", "len", "len", "torch.from_numpy.type", "torch.from_numpy.type", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "torch.from_numpy.reshape", "torch.from_numpy.reshape", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KeyError", "torch.from_numpy.type", "torch.from_numpy.type", "len", "run_vqa_prompt_mlm.VQADataset.get_img_feature", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "len", "len", "float", "str"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.target_tensor", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv._truncate_seq_pair", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.get_img_feature"], ["", "def", "tensorize_example", "(", "self", ",", "example", ",", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "\n", "        ", "tokens_a", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "tokens_c", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "\"Answer: \"", "+", "example", ".", "text_c", ")", "\n", "if", "\"[MASK]\"", "not", "in", "tokens_c", ":", "\n", "            ", "tokens_c", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "\"Answer: [MASK]\"", ")", "\n", "", "tokens_a", "=", "tokens_a", "+", "tokens_c", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "            ", "tokens_b", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_b", ")", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "self", ".", "args", ".", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "            ", "if", "len", "(", "tokens_a", ")", ">", "self", ".", "args", ".", "max_seq_length", "-", "2", ":", "\n", "                ", "tokens_a", "=", "tokens_a", "[", ":", "(", "self", ".", "args", ".", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "", "tokens", "=", "tokens_a", "+", "[", "sep_token", "]", "\n", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "            ", "tokens", "+=", "tokens_b", "+", "[", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "if", "cls_token_at_end", ":", "\n", "            ", "tokens", "=", "tokens", "+", "[", "cls_token", "]", "\n", "segment_ids", "=", "segment_ids", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "            ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "mask_index", "=", "tokens", ".", "index", "(", "\"[MASK]\"", ")", "\n", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "self", ".", "args", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "segment_ids", "=", "segment_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "\n", "# image features", "\n", "if", "self", ".", "args", ".", "img_feature_type", ".", "startswith", "(", "'dis_code'", ")", ":", "\n", "            ", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "\n", "\n", "if", "self", ".", "args", ".", "img_feature_type", "==", "'dis_code_ln'", ":", "# for discrete code image representation", "\n", "                ", "img_feat", "=", "img_feat", ".", "reshape", "(", "-", "1", ",", "img_feat", ".", "shape", "[", "0", "]", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "img_feature_type", "==", "'dis_code_t'", ":", "# transposed", "\n", "                ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "64", "\n", "", "else", ":", "\n", "                ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "args", ".", "img_feat_format", "==", "'pt'", ":", "\n", "                ", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "#[:, 0:self.args.img_feature_dim]  # torch", "\n", "", "elif", "self", ".", "args", ".", "img_feat_format", "==", "'tsv'", ":", "\n", "                ", "img_features", "=", "self", ".", "get_img_feature", "(", "str", "(", "example", ".", "img_key", ")", ")", "\n", "img_feat", "=", "torch", ".", "from_numpy", "(", "img_features", ")", "\n", "\n", "", "if", "img_feat", ".", "shape", "[", "0", "]", ">", "self", ".", "args", ".", "max_img_seq_length", ":", "\n", "                ", "img_feat", "=", "img_feat", "[", "0", ":", "self", ".", "args", ".", "max_img_seq_length", ",", "]", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids += [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids = segment_ids + [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "self", ".", "args", ".", "max_img_seq_length", "-", "img_feat", ".", "shape", "[", "0", "]", ",", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_matrix", ".", "shape", "[", "0", "]", ")", "\n", "# segment_ids = segment_ids + [pad_token_segment_id] * padding_matrix.shape[0]", "\n", "\n", "", "", "", "if", "self", ".", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "if", "(", "example", ".", "label", "is", "None", ")", ":", "\n", "                ", "label_id", "=", "[", "0", "]", "\n", "score", "=", "[", "0", "]", "\n", "", "elif", "len", "(", "example", ".", "label", ")", "==", "0", ":", "\n", "                ", "label_id", "=", "[", "0", "]", "\n", "score", "=", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "label_id", "=", "[", "self", ".", "label_map", "[", "l", "]", "for", "l", "in", "example", ".", "label", "]", "\n", "score", "=", "example", ".", "score", "\n", "", "", "elif", "self", ".", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "if", "len", "(", "example", ".", "label", ")", "==", "0", ":", "\n", "                ", "label_id", "=", "0", "\n", "", "else", ":", "\n", "                ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "self", ".", "args", ".", "output_mode", ")", "\n", "\n", "", "new_scores", "=", "target_tensor", "(", "len", "(", "self", ".", "labels", ")", ",", "label_id", ",", "score", ")", "\n", "\n", "# features.append(InputFeat(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label_id, score=score, img_feat=img_feat))", "\n", "if", "self", ".", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "            ", "img_feat", "=", "img_feat", ".", "type", "(", "torch", ".", "long", ")", "\n", "", "elif", "self", ".", "args", ".", "img_feature_type", "in", "[", "'dis_code_ln'", "]", ":", "\n", "#img_feat = img_feat.reshape(-1, img_feat.shape[0])", "\n", "            ", "img_feat", "=", "img_feat", ".", "type", "(", "torch", ".", "float", ")", "\n", "\n", "", "return", "(", "torch", ".", "tensor", "(", "input_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 0", "\n", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 1", "\n", "torch", ".", "tensor", "(", "segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 2", "\n", "torch", ".", "tensor", "(", "[", "label_id", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 3", "\n", "torch", ".", "tensor", "(", "new_scores", ",", "dtype", "=", "torch", ".", "float", ")", ",", "# 4", "\n", "img_feat", ",", "# 5", "\n", "torch", ".", "tensor", "(", "[", "example", ".", "q_id", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 6", "\n", "torch", ".", "tensor", "(", "[", "mask_index", "]", ",", "dtype", "=", "torch", ".", "long", ")", ")", "# 7", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.VQADataset.__getitem__": [[422, 435], ["run_vqa_prompt_mlm.VQADataset.tensorize_example", "bool", "bool"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize_example"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "load_fast", ":", "\n", "            ", "example", "=", "self", ".", "features", "[", "index", "]", "\n", "", "else", ":", "\n", "            ", "entry", "=", "self", ".", "examples", "[", "index", "]", "\n", "example", "=", "self", ".", "tensorize_example", "(", "entry", ",", "\n", "cls_token_at_end", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "self", ".", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.VQADataset.__len__": [[436, 438], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.VQADataset.load_img_tsv_features": [[440, 443], ["run_vqa_prompt_mlm.VQADataset.check_img_feature_file", "run_vqa_prompt_mlm.VQADataset.check_img_feature_offset_map"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_feature_file", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_feature_offset_map"], ["", "def", "load_img_tsv_features", "(", "self", ")", ":", "\n", "        ", "self", ".", "check_img_feature_file", "(", ")", "\n", "self", ".", "check_img_feature_offset_map", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.VQADataset.check_img_feature_file": [[444, 451], ["os.path.join", "time.time", "open", "time.time", "logger.info"], "methods", ["None"], ["", "def", "check_img_feature_file", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "img_feature_file", "is", "None", ":", "\n", "            ", "img_feature_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "img_feat_dir", ",", "'{}_img_frcnn_feats.tsv'", ".", "format", "(", "self", ".", "name", ")", ")", "\n", "t_s", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "img_feature_file", "=", "open", "(", "img_feature_path", ",", "'r'", ")", "\n", "t_e", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "\"Open {} image time: {}\"", ".", "format", "(", "self", ".", "name", ",", "(", "t_e", "-", "t_s", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.VQADataset.check_img_feature_offset_map": [[452, 460], ["os.path.join", "time.time", "json.load", "time.time", "logger.info", "open", "len"], "methods", ["None"], ["", "", "def", "check_img_feature_offset_map", "(", "self", ")", ":", "\n", "        ", "\"\"\" load the image feature offset map \"\"\"", "\n", "if", "self", ".", "img_feat_offset_map", "is", "None", ":", "\n", "            ", "img_feature_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "img_feat_dir", ",", "'{}_img_frcnn_feats_offset_map.json'", ".", "format", "(", "self", ".", "name", ")", ")", "\n", "t_s", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "img_feat_offset_map", "=", "json", ".", "load", "(", "open", "(", "img_feature_path", ")", ")", "\n", "t_e", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "\"Load {} images: {}, time: {}\"", ".", "format", "(", "self", ".", "name", ",", "len", "(", "self", ".", "img_feat_offset_map", ")", ",", "(", "t_e", "-", "t_s", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.VQADataset.get_img_feature": [[461, 475], ["run_vqa_prompt_mlm.VQADataset.check_img_feature_file", "run_vqa_prompt_mlm.VQADataset.check_img_feature_offset_map", "run_vqa_prompt_mlm.VQADataset.img_feature_file.seek", "int", "numpy.frombuffer().reshape", "s.strip", "run_vqa_prompt_mlm.VQADataset.img_feature_file.readline().split", "numpy.frombuffer", "base64.b64decode", "run_vqa_prompt_mlm.VQADataset.img_feature_file.readline"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_feature_file", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_feature_offset_map", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek"], ["", "", "def", "get_img_feature", "(", "self", ",", "image_id", ")", ":", "\n", "        ", "\"\"\" decode the image feature \"\"\"", "\n", "self", ".", "check_img_feature_file", "(", ")", "\n", "self", ".", "check_img_feature_offset_map", "(", ")", "\n", "\n", "if", "image_id", "in", "self", ".", "img_feat_offset_map", ":", "\n", "            ", "img_offset", "=", "self", ".", "img_feat_offset_map", "[", "image_id", "]", "\n", "self", ".", "img_feature_file", ".", "seek", "(", "img_offset", ",", "0", ")", "\n", "arr", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "self", ".", "img_feature_file", ".", "readline", "(", ")", ".", "split", "(", "'\\t'", ")", "]", "\n", "num_boxes", "=", "int", "(", "arr", "[", "1", "]", ")", "\n", "feat", "=", "np", ".", "frombuffer", "(", "base64", ".", "b64decode", "(", "arr", "[", "2", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "(", "-", "1", ",", "self", ".", "args", ".", "img_feature_dim", ")", ")", "\n", "return", "feat", "\n", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm._load_dataset": [[92, 131], ["processor.get_labels", "processor.get_train_examples", "processor.get_train_examples", "processor.get_train_examples", "processor.get_dev_examples", "processor.get_dev_examples", "processor.get_dev_examples", "processor.get_train_examples", "processor.get_train_examples", "processor.get_test_examples", "processor.get_test_examples", "processor.get_test_examples", "processor.get_test_examples"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples"], ["def", "_load_dataset", "(", "args", ",", "name", ")", ":", "\n", "    ", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "labels", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "\n", "if", "name", "==", "'train'", ":", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'mask'", ":", "\n", "            ", "if", "args", ".", "use_vg", ":", "\n", "#examples = processor.get_train_examples(args.data_dir, 'train2014_vg_qla_mrcnn.json')", "\n", "                ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "txt_data_dir", ",", "'train2014_vg_qla_mrcnn.json'", ")", "\n", "", "else", ":", "\n", "                ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "txt_data_dir", ",", "'train2014_qla_mrcnn.json'", ")", "\n", "", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "txt_data_dir", ",", "'train2014_qla.json'", ")", "\n", "", "", "elif", "name", "==", "'val'", ":", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'mask'", ":", "\n", "            ", "if", "args", ".", "use_vg_dev", ":", "\n", "                ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "txt_data_dir", ",", "'vg_qla_mrcnn.json'", ")", "\n", "", "else", ":", "\n", "                ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "txt_data_dir", ",", "'val2014_qla_mrcnn.json'", ")", "\n", "", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "txt_data_dir", ",", "'val2014_qla.json'", ")", "\n", "", "", "elif", "name", "==", "'train+val'", ":", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'mask'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "txt_data_dir", ",", "'train+val2014_qla_mrcnn.json'", ")", "\n", "#examples = processor.get_train_examples(args.data_dir, 'train+val2014_qla_mrcnn.json')", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "txt_data_dir", ",", "'train+val2014_qla.json'", ")", "\n", "", "", "elif", "name", "==", "'test2015'", ":", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'mask'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'test2015_qla_mrcnn.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'test2014_qla.json'", ")", "\n", "", "", "elif", "name", "==", "'test-dev2015'", ":", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'mask'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'test-dev2015_qla_mrcnn.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'test2014_qla.json'", ")", "\n", "\n", "", "", "return", "examples", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.instance_bce_with_logits": [[477, 484], ["torch.functional.binary_cross_entropy_with_logits", "logits.dim", "labels.size"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "", "def", "instance_bce_with_logits", "(", "logits", ",", "labels", ",", "reduction", "=", "'mean'", ")", ":", "\n", "    ", "assert", "logits", ".", "dim", "(", ")", "==", "2", "\n", "\n", "loss", "=", "nn", ".", "functional", ".", "binary_cross_entropy_with_logits", "(", "logits", ",", "labels", ",", "reduction", "=", "reduction", ")", "\n", "if", "reduction", "==", "'mean'", ":", "\n", "        ", "loss", "*=", "labels", ".", "size", "(", "1", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.compute_score_with_logits": [[486, 492], ["torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda.scatter_", "logits.view", "torch.max", "torch.max", "torch.zeros", "torch.zeros", "labels.size"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "compute_score_with_logits", "(", "logits", ",", "labels", ")", ":", "\n", "    ", "logits", "=", "torch", ".", "max", "(", "logits", ",", "1", ")", "[", "1", "]", ".", "data", "# argmax", "\n", "one_hots", "=", "torch", ".", "zeros", "(", "*", "labels", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", "\n", "one_hots", ".", "scatter_", "(", "1", ",", "logits", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", "\n", "scores", "=", "(", "one_hots", "*", "labels", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.trim_batch": [[494, 514], ["print", "len", "enumerate", "len", "print", "torch.zeros", "torch.zeros", "batch_tensors.append", "print", "enumerate", "ele.size", "len", "print", "list", "ele.size"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "trim_batch", "(", "batch", ")", ":", "\n", "    ", "\"\"\" new batch func\n    :param batch:\n    :return:\n    \"\"\"", "\n", "print", "(", "'batch size'", ",", "len", "(", "batch", ")", ")", "\n", "\n", "batch_size", "=", "len", "(", "batch", ")", "\n", "batch_tensors", "=", "[", "]", "\n", "for", "ele", "in", "batch", "[", "0", "]", ":", "\n", "        ", "print", "(", "ele", ".", "shape", ",", "ele", ".", "size", "(", ")", ")", "\n", "zero_tensor", "=", "torch", ".", "zeros", "(", "(", "[", "batch_size", "]", "+", "list", "(", "ele", ".", "size", "(", ")", ")", ")", ")", "\n", "batch_tensors", ".", "append", "(", "zero_tensor", ")", "\n", "\n", "", "for", "b_id", ",", "b", "in", "enumerate", "(", "batch", ")", ":", "\n", "        ", "print", "(", "b_id", ",", "len", "(", "b", ")", ")", "\n", "for", "ele_id", ",", "ele", "in", "enumerate", "(", "b", ")", ":", "\n", "            ", "print", "(", "ele_id", ",", "ele", ".", "shape", ")", "\n", "batch_tensors", "[", "ele_id", "]", "[", "b_id", "]", "=", "ele", "\n", "", "", "return", "batch_tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.train": [[516, 773], ["torch.utils.data.DataLoader", "transformers.pytorch_transformers.AdamW", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "oscar.utils.misc.set_seed", "range", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "transformers.pytorch_transformers.WarmupConstantSchedule", "amp.initialize", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "copy.deepcopy", "transformers.pytorch_transformers.AdamW.state_dict", "dict", "tqdm.tqdm", "run_vqa_prompt_mlm.evaluate", "exit", "int", "time.time", "enumerate", "logger.info", "run_vqa_prompt_mlm.evaluate", "log_json.append", "logger.info", "logger.info", "time.time", "logger.info", "os.path.join", "logger.info", "transformers.pytorch_transformers.WarmupLinearSchedule", "enumerate", "torch.nn.parallel.DistributedDataParallel.eval", "tuple", "open", "_pickle.dump", "logger.info", "hasattr", "logger.info", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "compute_score_with_logits().sum", "torch.sum.item", "loss.mean.item", "copy.deepcopy", "os.path.join", "logger.info", "open", "json.dump", "os.path.exists", "os.makedirs", "hasattr", "len", "ImportError", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.no_grad", "torch.no_grad", "torch.nn.parallel.DistributedDataParallel.", "torch.sum", "torch.sum", "torch.topk", "torch.topk", "values.detach().cpu().numpy.detach().cpu().numpy", "indices.detach().cpu().numpy.detach().cpu().numpy", "batch[].squeeze().detach().cpu().numpy", "zip", "os.path.join", "loss.mean.mean", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "transformers.pytorch_transformers.WarmupLinearSchedule.step", "transformers.pytorch_transformers.AdamW.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "os.path.exists", "os.makedirs", "hasattr", "open", "json.dump", "round", "model_to_save.save_pretrained", "torch.save", "torch.save", "tokenizer.save_pretrained", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "t.to", "run_vqa_prompt_mlm.compute_score_with_logits", "t.to", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "run_vqa_prompt_mlm.compute_score_with_logits", "logger.info", "model_to_save.save_pretrained", "torch.save", "torch.save", "tokenizer.save_pretrained", "os.path.join", "any", "values.detach().cpu().numpy.detach().cpu", "indices.detach().cpu().numpy.detach().cpu", "batch[].squeeze().detach().cpu", "ind.astype", "val.astype", "torch.distributed.barrier", "torch.distributed.barrier", "logger.info", "run_vqa_prompt_mlm.evaluate", "logger.info", "torch.distributed.barrier", "torch.distributed.barrier", "os.path.join", "int", "copy.deepcopy", "values.detach().cpu().numpy.detach", "indices.detach().cpu().numpy.detach", "batch[].squeeze().detach", "batch[].squeeze"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.compute_score_with_logits", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.compute_score_with_logits", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "#if args.local_rank in [-1, 0]: tb_writer = SummaryWriter()", "\n", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "num_workers", "=", "args", ".", "workers", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "#, collate_fn=trim_batch)", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "#scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args.warmup_steps, t_total=t_total) # original", "\n", "\n", "if", "args", ".", "scheduler", "==", "\"constant\"", ":", "\n", "        ", "scheduler", "=", "WarmupConstantSchedule", "(", "optimizer", ",", "warmup_steps", "=", "args", ".", "warmup_steps", ")", "\n", "", "elif", "args", ".", "scheduler", "==", "\"linear\"", ":", "\n", "        ", "scheduler", "=", "WarmupLinearSchedule", "(", "optimizer", ",", "warmup_steps", "=", "args", ".", "warmup_steps", ",", "t_total", "=", "t_total", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "#train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0])", "\n", "set_seed", "(", "args", ".", "seed", ",", "args", ".", "n_gpu", ")", "# Added here for reproductibility (even between python 2 and 3)", "\n", "\n", "best_score", "=", "0", "\n", "best_model", "=", "{", "\n", "'epoch'", ":", "0", ",", "\n", "'model'", ":", "copy", ".", "deepcopy", "(", "model", ")", ",", "#model.state_dict(),", "\n", "'optimizer_state'", ":", "optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n", "\n", "#eval_dataset = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=True)", "\n", "\n", "if", "args", ".", "do_generate", ":", "\n", "        ", "stage1_dict", "=", "dict", "(", ")", "\n", "for", "step", ",", "batch", "in", "tqdm", "(", "enumerate", "(", "train_dataloader", ")", ")", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "\n", "# XLM don't use segment_ids", "\n", "'labels'", ":", "batch", "[", "4", "]", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", ",", "\n", "'mask_index'", ":", "batch", "[", "7", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "# batch_score = compute_score_with_logits(logits, batch[4]).sum()", "\n", "batch_score", "=", "torch", ".", "sum", "(", "\n", "compute_score_with_logits", "(", "logits", ",", "batch", "[", "4", "]", ")", ",", "1", ")", "\n", "values", ",", "indices", "=", "torch", ".", "topk", "(", "logits", ",", "k", "=", "10", ",", "dim", "=", "-", "1", ")", "# [B, 10], [B, 10]", "\n", "values", "=", "values", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "indices", "=", "indices", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "qids", "=", "batch", "[", "6", "]", ".", "squeeze", "(", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "qid", ",", "val", ",", "ind", "in", "zip", "(", "qids", ",", "values", ",", "indices", ")", ":", "\n", "                    ", "stage1_dict", "[", "int", "(", "qid", ")", "]", "=", "(", "ind", ".", "astype", "(", "np", ".", "int16", ")", ",", "val", ".", "astype", "(", "np", ".", "float16", ")", ")", "\n", "\n", "", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"stage1.pkl\"", ")", ",", "\"wb\"", ")", "as", "fp", ":", "\n", "            ", "cPickle", ".", "dump", "(", "stage1_dict", ",", "fp", ")", "\n", "\n", "", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ")", "\n", "\n", "exit", "(", "0", ")", "\n", "\n", "", "for", "epoch", "in", "range", "(", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "#for epoch in train_iterator:", "\n", "#epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])", "\n", "        ", "total_loss", "=", "0", "\n", "train_score", "=", "0", "\n", "total_norm", "=", "0", "\n", "count_norm", "=", "0", "\n", "\n", "if", "args", ".", "adjust_dp", "and", "epoch", ">=", "3", ":", "\n", "            ", "logger", ".", "info", "(", "\"change droput ratio {} to 0.3\"", ".", "format", "(", "args", ".", "drop_out", ")", ")", "\n", "if", "hasattr", "(", "model", ",", "'module'", ")", ":", "\n", "                ", "model", ".", "module", ".", "dropout", ".", "p", "=", "0.3", "\n", "model", ".", "module", ".", "bert", ".", "dropout", ".", "p", "=", "0.3", "\n", "model", ".", "module", ".", "bert", ".", "embeddings", ".", "dropout", ".", "p", "=", "0.3", "\n", "", "else", ":", "\n", "                ", "model", ".", "dropout", ".", "p", "=", "0.3", "\n", "model", ".", "bert", ".", "dropout", ".", "p", "=", "0.3", "\n", "model", ".", "bert", ".", "embeddings", ".", "dropout", ".", "p", "=", "0.3", "\n", "\n", "", "", "if", "args", ".", "adjust_loss", "and", "epoch", ">=", "args", ".", "adjust_loss_epoch", ":", "\n", "            ", "logger", ".", "info", "(", "\"\\t change loss type from kl to bce\"", ")", "\n", "model", ".", "loss_type", "=", "'bce'", "\n", "\n", "# debug", "\n", "#epoch = 20", "\n", "#global_step = epoch*math.ceil(len(train_dataset)/(args.train_batch_size * args.gradient_accumulation_steps * (torch.distributed.get_world_size() if args.local_rank != -1 else 1)))", "\n", "\n", "", "t_start", "=", "time", ".", "time", "(", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "batch", "[", "4", "]", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", ",", "\n", "'mask_index'", ":", "batch", "[", "7", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "#loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)", "\n", "loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "#loss = instance_bce_with_logits(logits, batch[4])", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "\n", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "total_norm", "+=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "count_norm", "+=", "1", "\n", "\n", "", "batch_score", "=", "compute_score_with_logits", "(", "logits", ",", "batch", "[", "4", "]", ")", ".", "sum", "(", ")", "\n", "train_score", "+=", "batch_score", ".", "item", "(", ")", "\n", "\n", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "optimizer", ".", "step", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "# Log metrics", "\n", "                    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "                        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "evaluate_during_training", ":", "\n", "#if args.local_rank == -1 and args.evaluate_during_training:  # Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "logger", ".", "info", "(", "\"Epoch: %d, global_step: %d\"", "%", "(", "epoch", ",", "global_step", ")", ")", "\n", "eval_result", ",", "eval_score", ",", "upper_bound", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "                            ", "best_score", "=", "eval_score", "\n", "best_model", "[", "'epoch'", "]", "=", "epoch", "\n", "best_model", "[", "'model'", "]", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "best_score", ")", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "                        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "logging_loss", "=", "tr_loss", "\n", "\n", "#if args.max_steps > 0 and global_step > args.max_steps:", "\n", "#    epoch_iterator.close()", "\n", "#    break", "\n", "\n", "# evaluation", "\n", "", "", "", "logger", ".", "info", "(", "\"Epoch: %d, global_step: %d\"", "%", "(", "epoch", ",", "global_step", ")", ")", "\n", "eval_result", ",", "eval_score", ",", "upper_bound", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "eval_score", "\n", "best_model", "[", "'epoch'", "]", "=", "epoch", "\n", "best_model", "[", "'model'", "]", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "#best_model['optimizer'] = copy.deepcopy(optimizer.state_dict())", "\n", "\n", "# save checkpoints", "\n", "", "if", "(", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ")", "and", "(", "args", ".", "save_epoch", ">", "0", "and", "epoch", "%", "args", ".", "save_epoch", "==", "0", ")", "and", "(", "epoch", ">", "args", ".", "save_after_epoch", ")", ":", "\n", "            ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-{}-{}'", ".", "format", "(", "epoch", ",", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "model_to_save", "=", "best_model", "[", "'model'", "]", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "best_model", "[", "'model'", "]", "# Take care of distributed/parallel training", "\n", "\n", "save_num", "=", "0", "\n", "while", "(", "save_num", "<", "10", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Saving model attempt: {}\"", ".", "format", "(", "save_num", ")", ")", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "break", "\n", "", "except", ":", "\n", "                    ", "save_num", "+=", "1", "\n", "", "", "logger", ".", "info", "(", "\"Saving model checkpoint {0} to {1}\"", ".", "format", "(", "epoch", ",", "output_dir", ")", ")", "\n", "\n", "", "epoch_log", "=", "{", "'epoch'", ":", "epoch", ",", "'eval_score'", ":", "eval_score", ",", "'best_score'", ":", "best_score", "}", "\n", "log_json", ".", "append", "(", "epoch_log", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "with", "open", "(", "args", ".", "output_dir", "+", "'/eval_logs.json'", ",", "'w'", ")", "as", "fp", ":", "\n", "                ", "json", ".", "dump", "(", "log_json", ",", "fp", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"PROGRESS: {}%\"", ".", "format", "(", "round", "(", "100", "*", "(", "epoch", "+", "1", ")", "/", "args", ".", "num_train_epochs", ",", "4", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "best_score", ")", ")", "\n", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Epoch: %d, Train Time: %.3f'", "%", "(", "epoch", ",", "t_end", "-", "t_start", ")", ")", "\n", "\n", "#if args.max_steps > 0 and global_step > args.max_steps:", "\n", "#    train_iterator.close()", "\n", "#    break", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "# Save the final model checkpoint", "\n", "        ", "with", "open", "(", "args", ".", "output_dir", "+", "'/eval_logs.json'", ",", "'w'", ")", "as", "fp", ":", "\n", "            ", "json", ".", "dump", "(", "log_json", ",", "fp", ")", "\n", "\n", "", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'best-{}'", ".", "format", "(", "best_model", "[", "'epoch'", "]", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "model_to_save", "=", "best_model", "[", "'model'", "]", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "best_model", "[", "'model'", "]", "# Take care of distributed/parallel training", "\n", "\n", "save_num", "=", "0", "\n", "while", "(", "save_num", "<", "10", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "break", "\n", "", "except", ":", "\n", "                ", "save_num", "+=", "1", "\n", "", "", "logger", ".", "info", "(", "\"Saving the best model checkpoint epoch {} to {}\"", ".", "format", "(", "best_model", "[", "'epoch'", "]", ",", "output_dir", ")", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.evaluate": [[775, 893], ["time.time", "dict", "zip", "time.time", "logger.info", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "model.eval", "tuple", "len", "len", "open", "_pickle.dump", "os.path.exists", "torch.no_grad", "torch.no_grad", "model", "tmp_eval_loss.mean().item", "torch.sum", "torch.sum", "results_dict.update", "torch.sum.sum().item", "logits.size", "os.path.join", "t.to", "run_vqa_prompt_mlm.compute_score_with_logits", "torch.topk", "torch.topk", "values.detach().cpu().numpy.detach().cpu().numpy", "indices.detach().cpu().numpy.detach().cpu().numpy", "batch[].squeeze().detach().cpu().numpy", "zip", "tmp_eval_loss.mean", "torch.sum.sum", "zip", "values.detach().cpu().numpy.detach().cpu", "indices.detach().cpu().numpy.detach().cpu", "batch[].squeeze().detach().cpu", "ind.astype", "val.astype", "batch[].view().tolist", "torch.sum.tolist", "int", "values.detach().cpu().numpy.detach", "indices.detach().cpu().numpy.detach", "batch[].squeeze().detach", "batch[].view", "batch[].squeeze"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.SmoothedValue.update", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.compute_score_with_logits"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", "=", "None", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "'-MM'", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "#if args.n_gpu > 1: model = torch.nn.DataParallel(model) # debug: single-gpu or multi-gpus", "\n", "\n", "results", "=", "[", "]", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "\n", "stage1_dict", "=", "dict", "(", ")", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "num_workers", "=", "args", ".", "workers", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "num_data", "=", "0", "\n", "score", "=", "0", "\n", "upper_bound", "=", "0", "\n", "results_dict", "=", "{", "}", "\n", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "#for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "batch", "[", "4", "]", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", ",", "\n", "'mask_index'", ":", "batch", "[", "7", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n", "# batch_score = compute_score_with_logits(logits, batch[4]).sum()", "\n", "batch_score", "=", "torch", ".", "sum", "(", "\n", "compute_score_with_logits", "(", "logits", ",", "batch", "[", "4", "]", ")", ",", "1", ")", "\n", "# update results_dict", "\n", "results_dict", ".", "update", "(", "\n", "{", "qa_ind", ":", "score", "for", "qa_ind", ",", "score", "in", "\n", "zip", "(", "batch", "[", "6", "]", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", ",", "batch_score", ".", "tolist", "(", ")", ")", "}", "\n", ")", "\n", "score", "+=", "batch_score", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "#upper_bound += (batch[4].max(1)[0]).sum().item()", "\n", "num_data", "+=", "logits", ".", "size", "(", "0", ")", "\n", "\n", "if", "args", ".", "do_generate", ":", "\n", "                    ", "values", ",", "indices", "=", "torch", ".", "topk", "(", "logits", ",", "k", "=", "10", ",", "dim", "=", "-", "1", ")", "\n", "values", "=", "values", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "indices", "=", "indices", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "qids", "=", "batch", "[", "6", "]", ".", "squeeze", "(", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "qid", ",", "val", ",", "ind", "in", "zip", "(", "qids", ",", "values", ",", "indices", ")", ":", "\n", "                        ", "stage1_dict", "[", "int", "(", "qid", ")", "]", "=", "(", "ind", ".", "astype", "(", "np", ".", "int16", ")", ",", "val", ".", "astype", "(", "np", ".", "float16", ")", ")", "\n", "\n", "# debug", "\n", "#val, idx = logits.max(1)", "\n", "#logger.info('idx: %s, batch[4]: %s' % (str(idx.shape), str(batch[3].shape)))", "\n", "#for i in range(idx.size(0)):", "\n", "#    logger.info('idx: %d, pred: %d, real: %d' % (idx[i].item(), eval_dataset.labels[idx[i].item()], batch[3][i].item()))", "\n", "\n", "", "", "", "nb_eval_steps", "+=", "1", "\n", "\n", "#if preds is None:", "\n", "#    preds = logits.detach().cpu().numpy()", "\n", "#    out_label_ids = inputs['labels'].detach().cpu().numpy()", "\n", "#else:", "\n", "#    preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)", "\n", "#    out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)", "\n", "\n", "", "score", "=", "score", "/", "len", "(", "eval_dataloader", ".", "dataset", ")", "\n", "upper_bound", "=", "upper_bound", "/", "len", "(", "eval_dataloader", ".", "dataset", ")", "\n", "\n", "logger", ".", "info", "(", "\"Eval Results:\"", ")", "\n", "logger", ".", "info", "(", "\"Eval Score: %.3f\"", "%", "(", "100", "*", "score", ")", ")", "\n", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "score", ")", ")", "\n", "logger", ".", "info", "(", "\"Eval Upper Bound: %.3f\"", "%", "(", "100", "*", "upper_bound", ")", ")", "\n", "# with open(os.path.join(args.data_dir, 'val_results.json'),", "\n", "#           'w') as f:", "\n", "#     json.dump(results_dict, f)", "\n", "\n", "", "if", "args", ".", "do_generate", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"stage1_eval.pkl\"", ")", ",", "\"wb\"", ")", "as", "fp", ":", "\n", "            ", "cPickle", ".", "dump", "(", "stage1_dict", ",", "fp", ")", "\n", "\n", "", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Eva Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "#eval_loss = eval_loss / nb_eval_steps", "\n", "#if args.output_mode == \"classification\":", "\n", "#    preds = np.argmax(preds, axis=1)", "\n", "#elif args.output_mode == \"regression\":", "\n", "#    preds = np.squeeze(preds)", "\n", "#result = compute_metrics(eval_task, preds, out_label_ids)", "\n", "#results.update(result)", "\n", "\n", "#output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")", "\n", "#with open(output_eval_file, \"w\") as writer:", "\n", "#    logger.info(\"***** Eval results {} *****\".format(prefix))", "\n", "#    for key in sorted(result.keys()):", "\n", "#        logger.info(\"  %s = %s\", key, str(result[key]))", "\n", "#        writer.write(\"%s = %s\\n\" % (key, str(result[key])))", "\n", "\n", "return", "results", ",", "score", ",", "upper_bound", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.test": [[895, 953], ["_pickle.load", "logger.info", "time.time", "zip", "time.time", "logger.info", "logger.info", "open", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "open", "json.dump", "len", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "model.eval", "tuple", "len", "os.path.exists", "torch.no_grad", "torch.no_grad", "model", "logits.max", "range", "t.to", "idx.size", "[].item", "results.append", "logger.info", "len", "round", "idx[].item", "len", "len"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "test", "(", "args", ",", "model", ",", "eval_dataset", "=", "None", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "'-MM'", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "label2ans", "=", "cPickle", ".", "load", "(", "open", "(", "args", ".", "label2ans_file", ",", "'rb'", ")", ")", "\n", "logger", ".", "info", "(", "'label2ans: %d'", "%", "(", "len", "(", "label2ans", ")", ")", ")", "\n", "\n", "results", "=", "[", "]", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval", "\n", "logger", ".", "info", "(", "\"***** Running Test {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "#for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "None", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", ",", "\n", "'mask_index'", ":", "batch", "[", "7", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "logits", "=", "outputs", "[", "0", "]", "\n", "\n", "val", ",", "idx", "=", "logits", ".", "max", "(", "1", ")", "\n", "#logger.info('idx: %s, batch[6]: %s' % (str(idx.shape), str(batch[6].shape)))", "\n", "\n", "for", "i", "in", "range", "(", "idx", ".", "size", "(", "0", ")", ")", ":", "\n", "#logger.info('idx: %d, batch: %d' % (idx[i].item(), batch[6][i].item()))", "\n", "                    ", "result", "=", "{", "}", "\n", "result", "[", "'question_id'", "]", "=", "batch", "[", "6", "]", "[", "i", "]", ".", "item", "(", ")", "\n", "result", "[", "'answer'", "]", "=", "label2ans", "[", "eval_dataset", ".", "labels", "[", "idx", "[", "i", "]", ".", "item", "(", ")", "]", "]", "#label2ans[idx[i].item()]", "\n", "results", ".", "append", "(", "result", ")", "\n", "\n", "if", "len", "(", "results", ")", "%", "2000", "==", "0", ":", "\n", "                        ", "logger", ".", "info", "(", "\"PROGRESS: {}%\"", ".", "format", "(", "round", "(", "100", "*", "len", "(", "results", ")", "/", "len", "(", "eval_dataset", ")", ",", "4", ")", ")", ")", "\n", "#logger.info('q_id: {0}, answer: {1}'.format(result['question_id'], result['answer']))", "\n", "\n", "", "", "", "", "", "with", "open", "(", "args", ".", "output_dir", "+", "(", "'/{}_results.json'", ".", "format", "(", "eval_dataset", ".", "name", ")", ")", ",", "'w'", ")", "as", "fp", ":", "\n", "        ", "json", ".", "dump", "(", "results", ",", "fp", ")", "\n", "\n", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'# questions: %d'", "%", "(", "len", "(", "results", ")", ")", ")", "\n", "logger", ".", "info", "(", "'Test Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.load_and_cache_examples": [[955, 1021], ["processor.get_labels", "time.time", "numpy.load", "oscar.utils.task_utils.convert_examples_to_features_vqa", "time.time", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "processor.get_dev_examples", "processor.get_train_examples", "os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "print", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "bool", "bool", "time.time", "numpy.zeros", "enumerate", "torch.from_numpy", "torch.from_numpy", "time.time", "logger.info", "torch.tensor", "torch.tensor", "run_vqa_prompt_mlm.target_tensor", "len"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.convert_examples_to_features_vqa", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.target_tensor"], ["", "def", "load_and_cache_examples", "(", "args", ",", "task", ",", "tokenizer", ",", "evaluate", "=", "False", ")", ":", "\n", "    ", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "output_mode", "=", "output_modes", "[", "task", "]", "\n", "\n", "label_list", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ")", "if", "evaluate", "else", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ")", "\n", "\n", "#img_features = torch.load(os.path.join(args.data_dir, 'val_img_feats.pt' if evaluate else 'train_img_feats.pt'))", "\n", "#img_features = torch.load(os.path.join(args.data_dir, 'val_img_frcnn_feats.pt' if evaluate else 'train_img_frcnn_feats.pt'))", "\n", "img_features", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'val_img_frcnn_feats.npy'", "if", "evaluate", "else", "'train_img_frcnn_feats.npy'", ")", ")", "\n", "\n", "features", "=", "convert_examples_to_features_vqa", "(", "examples", ",", "img_features", ",", "label_list", ",", "args", ".", "max_img_seq_length", ",", "args", ".", "max_seq_length", ",", "\n", "tokenizer", ",", "output_mode", ",", "\n", "cls_token_at_end", "=", "bool", "(", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "\n", "#if args.local_rank in [-1, 0]:", "\n", "#    logger.info(\"Saving features into cached file %s\", cached_features_file)", "\n", "#    torch.save(features, cached_features_file)", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: loading features using %.5f secs'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "# batch*max_seq_len", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "        ", "labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "[", "0", "]", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "targets", "=", "torch", ".", "tensor", "(", "[", "target_tensor", "(", "len", "(", "label_list", ")", ",", "f", ".", "label_id", ",", "f", ".", "score", ")", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "if", "args", ".", "img_feature_dim", ">", "0", ":", "# change here", "\n", "            ", "t_start", "=", "time", ".", "time", "(", ")", "\n", "img_feat_np", "=", "np", ".", "zeros", "(", "(", "labels", ".", "shape", "[", "0", "]", ",", "args", ".", "max_img_seq_length", ",", "args", ".", "img_feature_dim", ")", ")", "\n", "for", "f_id", ",", "f", "in", "enumerate", "(", "features", ")", ":", "\n", "                ", "img_feat_np", "[", "f_id", "]", "=", "f", ".", "img_feat", "\n", "\n", "", "img_feats", "=", "torch", ".", "from_numpy", "(", "img_feat_np", ")", "\n", "\n", "#img_feats = torch.empty((labels.shape[0], args.max_img_seq_length, args.img_feature_dim))", "\n", "#for f_id, f in enumerate(features):", "\n", "#   img_feats[f_id] = f.img_feat", "\n", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: convert image tensor features using %.5f secs'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "#img_feats = torch.stack([f.img_feat[:,-args.img_feature_dim:] for f in features])", "\n", "#img_feats = torch.stack([f.img_feat for f in features])", "\n", "#img_feats = img_feats.type(torch.long)", "\n", "\n", "#print('targets:', targets.shape)", "\n", "", "print", "(", "'img_feats:'", ",", "img_feats", ".", "shape", ")", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "        ", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "if", "args", ".", "img_feature_dim", "==", "-", "1", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "labels", ",", "targets", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "labels", ",", "targets", ",", "img_feats", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.target_tensor": [[1022, 1029], ["enumerate"], "function", ["None"], ["", "def", "target_tensor", "(", "len", ",", "labels", ",", "scores", ")", ":", "\n", "    ", "\"\"\" create the target by labels and scores \"\"\"", "\n", "target", "=", "[", "0", "]", "*", "len", "\n", "for", "id", ",", "l", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "target", "[", "l", "]", "=", "scores", "[", "id", "]", "\n", "\n", "", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_mlm.main": [[1031, 1337], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "oscar.utils.misc.set_seed", "parser.parse_args.task_name.lower", "processor.get_labels", "len", "logger.info", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "run_vqa_prompt_mlm.VQADataset", "logger.info", "os.path.join", "logger.info", "os.path.exists", "os.listdir", "logger.info", "logger.info", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.set_device", "torch.cuda.set_device", "torch.device", "torch.device", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "bool", "ValueError", "torch.distributed.barrier", "torch.distributed.barrier", "logger.info", "time.time", "torch.load", "torch.load", "time.time", "logger.info", "logger.info", "torch.distributed.barrier", "torch.distributed.barrier", "run_vqa_prompt_mlm.VQADataset", "run_vqa_prompt_mlm.VQADataset", "run_vqa_prompt_mlm.VQADataset", "run_vqa_prompt_mlm.train", "logger.info", "run_vqa_prompt_mlm.VQADataset", "run_vqa_prompt_mlm.train", "logger.info", "logger.info", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "torch.save", "logger.info", "logger.info", "logger.info", "os.getenv", "os.path.join", "bool", "model_class.from_pretrained.init_code_embedding", "os.makedirs", "os.path.join", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_vqa_prompt_mlm.evaluate", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_vqa_prompt_mlm.test", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_vqa_prompt_mlm.test", "train_code[].t", "model_class.from_pretrained.init_code_embedding", "torch.distributed.get_rank", "torch.distributed.get_rank", "os.path.exists", "MODEL_CLASSES.keys", "oscar.utils.task_utils.processors.keys", "torch.cuda.is_available", "torch.cuda.is_available", "train_code[].t", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "sorted", "sorted", "sorted", "glob.glob", "glob.glob", "glob.glob", "list", "train_code[].keys", "list", "train_code[].keys"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.ImageBertForSequenceClassification.init_code_embedding", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.test", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.test", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.ImageBertForSequenceClassification.init_code_embedding", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the .tsv files (or other data files) for the task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--txt_data_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input text data dir. Should contain the .json files (or other data files) for the task.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--task_name\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train selected in the list: \"", "+", "\", \"", ".", "join", "(", "processors", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--label_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Label Dictionary\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--label2ans_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Label to Answer Dictionary\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--img_feat_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"The input img_feat_dir.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feat_format\"", ",", "default", "=", "'pt'", ",", "type", "=", "str", ",", "help", "=", "\"img_feat_format: pt or tsv.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--data_label_type\"", ",", "default", "=", "'faster'", ",", "type", "=", "str", ",", "help", "=", "\"faster or mask\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--loss_type\"", ",", "default", "=", "'kl'", ",", "type", "=", "str", ",", "help", "=", "\"kl or xe\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_vg\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use VG-QA or not.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_vg_dev\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use VG-QA as validation.\"", ")", "\n", "#parser.add_argument(\"--use_img_layernorm\", action='store_true', help=\"use_img_layernorm\")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer than this will be truncated, sequences shorter will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train_val\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run test on the test set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test_dev\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run test on the test-dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_generate\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run test on the test-dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Rul evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--drop_out\"", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "\"Drop out for BERT.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adjust_dp\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Adjust Drop out for BERT.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--adjust_loss\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Adjust Loss Type for BERT.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adjust_loss_epoch\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "help", "=", "\"Adjust Loss Type for BERT.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--classifier\"", ",", "default", "=", "'linear'", ",", "type", "=", "str", ",", "help", "=", "\"linear or mlp\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cls_hidden_scale\"", ",", "default", "=", "2", ",", "type", "=", "int", ",", "help", "=", "\"cls_hidden_scale: for classifier\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--hard_label\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Soft Label or Hard Label.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_img_seq_length\"", ",", "default", "=", "30", ",", "type", "=", "int", ",", "help", "=", "\"The maximum total input image sequence length.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_dim\"", ",", "default", "=", "2054", ",", "type", "=", "int", ",", "help", "=", "\"The Image Feature Dimension.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_type\"", ",", "default", "=", "'faster_r-cnn'", ",", "type", "=", "str", ",", "help", "=", "\"faster_r-cnn or mask_r-cnn\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_voc\"", ",", "default", "=", "512", ",", "type", "=", "int", ",", "help", "=", "\"dis_code_voc: 256, 512\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_level\"", ",", "default", "=", "'top'", ",", "type", "=", "str", ",", "help", "=", "\"code level: top, botttom, both\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--scheduler\"", ",", "default", "=", "'linear'", ",", "type", "=", "str", ",", "help", "=", "\"constant or linear.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_epoch'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "\"Save checkpoint every X epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_after_epoch'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"Save checkpoint after epoch.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_output_dir'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_cache'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_ip'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_port'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--philly\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use Philly: reset the output dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--load_fast\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Load Tensor Fast\"", ")", "\n", "parser", ".", "add_argument", "(", "'-j'", ",", "'--workers'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "help", "=", "'number of data loading workers (default: 4)'", ")", "\n", "\n", "#args = '--data_dir ../vqa/ban-vqa/data/qal_pairs --model_type bert --model_name_or_path bert-base-uncased --task_name vqa_text ' \\", "\n", "#       '--do_train --do_eval --do_lower_case --max_seq_length 40 --per_gpu_eval_batch_size 16 --per_gpu_train_batch_size 16 --learning_rate 2e-5 ' \\", "\n", "#       '--num_train_epochs 20.0 --output_dir ./results/vqa_text --label_file ../vqa/ban-vqa/data/cache/trainval_ans2label.pkl ' \\", "\n", "#       '--save_steps 5000 --overwrite_output_dir --max_img_seq_length 1 --img_feature_dim 565 --img_feature_type dis_code '", "\n", "\n", "#args = '--data_dir ../vqa/ban-vqa/data/qal_pairs --model_type bert --model_name_or_path bert-base-uncased --task_name vqa_text ' \\", "\n", "#       '--do_train --do_eval --do_lower_case --max_seq_length 40 --per_gpu_eval_batch_size 16 --per_gpu_train_batch_size 16 --learning_rate 2e-5 ' \\", "\n", "#       '--num_train_epochs 20.0 --output_dir ./results/vqa_text --label_file ../vqa/ban-vqa/data/cache/trainval_ans2label.pkl ' \\", "\n", "#       '--save_steps 5000 --overwrite_output_dir --max_img_seq_length 10 --img_feature_dim 565 --img_feature_type other '", "\n", "\n", "#args = parser.parse_args(args.split())", "\n", "# \u89e3\u6790\u53c2\u6570", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "philly", ":", "# use philly", "\n", "        ", "logger", ".", "info", "(", "'Info: Use Philly, all the output folders are reset.'", ")", "\n", "args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "getenv", "(", "'PT_OUTPUT_DIR'", ")", ",", "args", ".", "output_dir", ")", "\n", "logger", ".", "info", "(", "'OUTPUT_DIR:'", ",", "args", ".", "output_dir", ")", "\n", "\n", "#if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train and not args.overwrite_output_dir:", "\n", "#    raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args.output_dir))", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", ":", "logger", ".", "info", "(", "\"Output Directory Exists.\"", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "logger", ".", "info", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# \u8bbe\u7f6ecuda", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s - %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "# Set seed", "\n", "# \u8bbe\u7f6e\u968f\u673a\u79cd\u5b50", "\n", "set_seed", "(", "args", ".", "seed", ",", "args", ".", "n_gpu", ")", "\n", "\n", "# Prepare GLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "\n", "# \u521d\u59cb\u5316\u6570\u636e\u96c6\u7684\u521d\u59cb\u5316\u5bf9\u8c61\uff0c\u8f7d\u5165\u7b54\u6848\u6620\u5c04\u5b57\u5178", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "args", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "# \"classification\"", "\n", "label_list", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "logger", ".", "info", "(", "'Task Name: {}, #Labels: {}'", ".", "format", "(", "args", ".", "task_name", ",", "num_labels", ")", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "\n", "# discrete code", "\n", "config", ".", "img_feature_dim", "=", "args", ".", "img_feature_dim", "# 2054", "\n", "config", ".", "img_feature_type", "=", "args", ".", "img_feature_type", "# faster_r-cnn", "\n", "config", ".", "code_voc", "=", "args", ".", "code_voc", "# 512", "\n", "config", ".", "hidden_dropout_prob", "=", "args", ".", "drop_out", "# 0.3", "\n", "config", ".", "loss_type", "=", "args", ".", "loss_type", "# bce", "\n", "config", ".", "classifier", "=", "args", ".", "classifier", "# linear", "\n", "config", ".", "cls_hidden_scale", "=", "args", ".", "cls_hidden_scale", "# 3", "\n", "#config.use_img_layernorm = args.use_img_layernorm", "\n", "\n", "# load discrete code", "\n", "if", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "'Load discrete code from: {}'", ".", "format", "(", "args", ".", "data_dir", ")", ")", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "train_code", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'vqvae'", ",", "'train.pt'", ")", ")", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Load time: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "if", "args", ".", "code_level", "==", "'top'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_t'", "]", ".", "shape", "[", "0", "]", "\n", "config", ".", "code_size", "=", "train_code", "[", "'feats_top'", "]", "[", "list", "(", "train_code", "[", "'feats_top'", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "shape", "[", "0", "]", "\n", "", "elif", "args", ".", "code_level", "==", "'bottom'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_b'", "]", ".", "shape", "[", "0", "]", "\n", "config", ".", "code_size", "=", "train_code", "[", "'feats_bottom'", "]", "[", "list", "(", "train_code", "[", "'feats_bottom'", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "shape", "[", "0", "]", "\n", "", "elif", "args", ".", "code_level", "==", "'both'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_t'", "]", ".", "shape", "[", "0", "]", "+", "train_code", "[", "'embeddings_b'", "]", ".", "shape", "[", "0", "]", "\n", "\n", "\n", "# \u4f7f\u7528\u9884\u8bad\u7ec3\u53c2\u6570\u521d\u59cb\u5316\u6a21\u578b", "\n", "", "", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "from_tf", "=", "bool", "(", "'.ckpt'", "in", "args", ".", "model_name_or_path", ")", ",", "config", "=", "config", ")", "\n", "if", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "'Initializing the code embedding with {}'", ".", "format", "(", "args", ".", "code_level", ")", ")", "\n", "if", "args", ".", "code_level", "==", "'top'", ":", "\n", "            ", "model", ".", "init_code_embedding", "(", "train_code", "[", "'embeddings_t'", "]", ".", "t", "(", ")", ")", "\n", "", "elif", "args", ".", "code_level", "==", "'bottom'", ":", "\n", "            ", "model", ".", "init_code_embedding", "(", "train_code", "[", "'embeddings_b'", "]", ".", "t", "(", ")", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# \u521d\u59cb\u5316\u6570\u636e\u96c6", "\n", "#if args.do_eval:", "\n", "eval_dataset", "=", "VQADataset", "(", "args", ",", "'val'", ",", "tokenizer", ")", "\n", "\n", "if", "args", ".", "do_test", ":", "\n", "        ", "test_dataset", "=", "VQADataset", "(", "args", ",", "'test2015'", ",", "tokenizer", ")", "\n", "\n", "", "if", "args", ".", "do_test_dev", ":", "\n", "        ", "test_dev_dataset", "=", "VQADataset", "(", "args", ",", "'test-dev2015'", ",", "tokenizer", ")", "\n", "\n", "# Training", "\n", "", "if", "args", ".", "do_train", ":", "\n", "#train_dataset = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False)", "\n", "        ", "train_dataset", "=", "VQADataset", "(", "args", ",", "'train'", ",", "tokenizer", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Training on train+val", "\n", "", "if", "args", ".", "do_train_val", ":", "\n", "        ", "train_dataset", "=", "VQADataset", "(", "args", ",", "'train+val'", ",", "tokenizer", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`. They can then be reloaded using `from_pretrained()`", "\n", "#model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training", "\n", "#model_to_save.save_pretrained(args.output_dir)", "\n", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "#model = model_class.from_pretrained(args.output_dir)", "\n", "#tokenizer = tokenizer_class.from_pretrained(args.output_dir)", "\n", "#model.to(args.device)", "\n", "\n", "\n", "# Evaluation", "\n", "#results = {}", "\n", "", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ",", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "score", ",", "upper_bound", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "#result = dict((k + '_{}'.format(global_step), v) for k, v in result.items())", "\n", "#results.update(result)", "\n", "\n", "# Test-Dev", "\n", "", "", "if", "args", ".", "do_test_dev", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "test", "(", "args", ",", "model", ",", "test_dev_dataset", ",", "prefix", "=", "global_step", ")", "\n", "\n", "# Test", "\n", "", "", "if", "args", ".", "do_test", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "test", "(", "args", ",", "model", ",", "test_dataset", ",", "prefix", "=", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa.GQADataset.__init__": [[91, 128], ["torch.utils.data.Dataset.__init__", "run_gqa._load_dataset", "logger.info", "run_gqa.GQADataset.tensorize", "enumerate", "bool", "bool", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few._load_dataset", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize"], ["def", "__init__", "(", "self", ",", "args", ",", "name", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", "=", "None", ")", ":", "\n", "        ", "super", "(", "GQADataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "name", "in", "[", "'train'", ",", "'val'", ",", "'test-dev'", ",", "'test'", ",", "'train+val'", "]", "\n", "\n", "#t_start = time.time()", "\n", "#if args.img_feature_type == 'faster_r-cnn':", "\n", "#    if args.img_feature_dim == 2048: # object features", "\n", "#        feat_file_name = 'gqa_img_frcnn_feats_obj_{}.pt'.format(name)", "\n", "#    else: # object + spatial features", "\n", "#        feat_file_name = 'gqa_img_frcnn_feats_{}.pt'.format(name)", "\n", "#else:", "\n", "#    feat_file_name = '{}_img_feats.pt'.format(name)", "\n", "#self.img_features = torch.load(os.path.join(args.data_dir, feat_file_name))", "\n", "#t_end = time.time()", "\n", "#logger.info('Info: loading {0:s} features using {1:.2f} secs'.format(feat_file_name, (t_end-t_start)))", "\n", "\n", "self", ".", "img_features", "=", "img_features", "\n", "self", ".", "label_pos_feats", "=", "label_pos_feats", "\n", "self", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "name", "=", "name", "\n", "\n", "self", ".", "examples", ",", "self", ".", "labels", "=", "_load_dataset", "(", "args", ",", "name", ")", "\n", "self", ".", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "self", ".", "labels", ")", "}", "\n", "\n", "if", "self", ".", "args", ".", "load_fast", ":", "\n", "            ", "self", ".", "features", "=", "self", ".", "tensorize", "(", "args", ",", "cls_token_at_end", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "self", ".", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "\n", "", "logger", ".", "info", "(", "'%s Data Examples: %d'", "%", "(", "name", ",", "len", "(", "self", ".", "examples", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa.GQADataset.tensorize": [[129, 235], ["enumerate", "run_gqa.GQADataset.tokenizer.tokenize", "run_gqa.GQADataset.tokenizer.convert_tokens_to_ids", "run_gqa.target_tensor", "features.append", "len", "logger.info", "run_gqa.GQADataset.tokenizer.tokenize", "oscar.utils.task_utils._truncate_seq_pair", "len", "len", "len", "len", "len", "len", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "len", "len", "float", "KeyError", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.target_tensor", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv._truncate_seq_pair"], ["", "def", "tensorize", "(", "self", ",", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "\n", "# debug:", "\n", "        ", "debug_size", "=", "500", "\n", "features", "=", "[", "]", "\n", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "self", ".", "examples", "[", "0", ":", "]", ")", ":", "\n", "            ", "if", "len", "(", "example", ".", "label", ")", "==", "0", ":", "continue", "\n", "if", "ex_index", "%", "10000", "==", "0", ":", "logger", ".", "info", "(", "\"Tensorizing example %d of %d\"", "%", "(", "ex_index", ",", "len", "(", "self", ".", "examples", ")", ")", ")", "\n", "\n", "tokens_a", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "                ", "tokens_b", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_b", ")", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "self", ".", "args", ".", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "                ", "if", "len", "(", "tokens_a", ")", ">", "self", ".", "args", ".", "max_seq_length", "-", "2", ":", "\n", "                    ", "tokens_a", "=", "tokens_a", "[", ":", "(", "self", ".", "args", ".", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "", "tokens", "=", "tokens_a", "+", "[", "sep_token", "]", "\n", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "                ", "tokens", "+=", "tokens_b", "+", "[", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "if", "cls_token_at_end", ":", "\n", "                ", "tokens", "=", "tokens", "+", "[", "cls_token", "]", "\n", "segment_ids", "=", "segment_ids", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "                ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "self", ".", "args", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "                ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "", "else", ":", "\n", "                ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "segment_ids", "=", "segment_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "\n", "# image features", "\n", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "# torch", "\n", "#img_feat = self.img_features.item().get(example.img_key)  # numpy", "\n", "if", "img_feat", ".", "shape", "[", "0", "]", ">", "self", ".", "args", ".", "max_img_seq_length", ":", "\n", "                ", "img_feat", "=", "img_feat", "[", "0", ":", "self", ".", "args", ".", "max_img_seq_length", ",", "]", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids += [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids = segment_ids + [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "self", ".", "args", ".", "max_img_seq_length", "-", "img_feat", ".", "shape", "[", "0", "]", ",", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_matrix", ".", "shape", "[", "0", "]", ")", "\n", "# segment_ids = segment_ids + [pad_token_segment_id] * padding_matrix.shape[0]", "\n", "\n", "", "", "if", "self", ".", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "                ", "label_id", "=", "[", "self", ".", "label_map", "[", "l", "]", "for", "l", "in", "example", ".", "label", "]", "\n", "score", "=", "example", ".", "score", "\n", "", "elif", "self", ".", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "                ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "else", ":", "\n", "                ", "raise", "KeyError", "(", "self", ".", "args", ".", "output_mode", ")", "\n", "\n", "", "if", "ex_index", "<", "5", ":", "\n", "                ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"segment_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label: %s (id = %s)\"", "%", "(", "example", ".", "label", ",", "label_id", ")", ")", "\n", "logger", ".", "info", "(", "\"score: %s (score = %s)\"", "%", "(", "example", ".", "score", ",", "score", ")", ")", "\n", "\n", "", "new_scores", "=", "target_tensor", "(", "len", "(", "self", ".", "labels", ")", ",", "label_id", ",", "score", ")", "\n", "#features.append(InputFeat(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label_id, score=score, img_feat=img_feat))", "\n", "features", ".", "append", "(", "(", "torch", ".", "tensor", "(", "input_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "label_id", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "new_scores", ",", "dtype", "=", "torch", ".", "float", ")", ",", "img_feat", ")", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa.GQADataset.tensorize_example": [[236, 363], ["run_gqa.GQADataset.tokenizer.tokenize", "run_gqa.GQADataset.tokenizer.convert_tokens_to_ids", "run_gqa.GQADataset.args.img_feature_type.startswith", "example.text_b.split", "enumerate", "example.text_b.replace().strip", "run_gqa.GQADataset.tokenizer.tokenize", "oscar.utils.task_utils._truncate_seq_pair", "len", "len", "len", "len", "len", "len", "img_feat.type.type.type", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "run_gqa.GQADataset.tokenizer.tokenize", "txt_label_ixs.extend", "len", "len", "len", "img_feat.type.type.reshape", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KeyError", "img_feat.type.type.type", "example.text_b.replace", "len", "len", "len", "len", "float", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv._truncate_seq_pair"], ["", "def", "tensorize_example", "(", "self", ",", "example", ",", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "\n", "        ", "tokens_a", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "            ", "txt_b_arr", "=", "example", ".", "text_b", ".", "split", "(", "';'", ")", "\n", "txt_label_ixs", "=", "[", "]", "\n", "for", "txt_b_ix", ",", "txt_b_ele", "in", "enumerate", "(", "txt_b_arr", ")", ":", "\n", "                ", "tokens_b_ele", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "txt_b_ele", ")", "\n", "txt_label_ixs", ".", "extend", "(", "[", "txt_b_ix", "]", "*", "len", "(", "tokens_b_ele", ")", ")", "\n", "", "txt_b", "=", "example", ".", "text_b", ".", "replace", "(", "';'", ",", "' '", ")", ".", "strip", "(", ")", "\n", "tokens_b", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "txt_b", ")", "\n", "assert", "len", "(", "tokens_b", ")", "==", "len", "(", "txt_label_ixs", ")", "\n", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "self", ".", "args", ".", "max_seq_length", "-", "3", ")", "\n", "txt_label_ixs", "=", "txt_label_ixs", "[", "0", ":", "len", "(", "tokens_b", ")", "]", "\n", "\n", "# original", "\n", "#if example.text_b:", "\n", "#    txt_b = example.text_b.replace(';', ' ').strip()", "\n", "#    tokens_b = self.tokenizer.tokenize(txt_b)", "\n", "#    _truncate_seq_pair(tokens_a, tokens_b, self.args.max_seq_length - 3)", "\n", "", "else", ":", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "            ", "if", "len", "(", "tokens_a", ")", ">", "self", ".", "args", ".", "max_seq_length", "-", "2", ":", "\n", "                ", "tokens_a", "=", "tokens_a", "[", ":", "(", "self", ".", "args", ".", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "", "tokens", "=", "tokens_a", "+", "[", "sep_token", "]", "\n", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "            ", "tokens", "+=", "tokens_b", "+", "[", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "if", "cls_token_at_end", ":", "\n", "            ", "tokens", "=", "tokens", "+", "[", "cls_token", "]", "\n", "segment_ids", "=", "segment_ids", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "            ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "self", ".", "args", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "segment_ids", "=", "segment_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "\n", "# image features", "\n", "if", "self", ".", "args", ".", "img_feature_type", ".", "startswith", "(", "'dis_code'", ")", ":", "\n", "            ", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "\n", "\n", "if", "self", ".", "args", ".", "img_feature_type", "==", "'dis_code_ln'", ":", "# for discrete code image representation", "\n", "                ", "img_feat", "=", "img_feat", ".", "reshape", "(", "-", "1", ",", "img_feat", ".", "shape", "[", "0", "]", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "img_feature_type", "==", "'dis_code_t'", ":", "# transposed", "\n", "                ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "64", "\n", "", "else", ":", "\n", "                ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "", "", "else", ":", "\n", "            ", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "#[:, 0:self.args.img_feature_dim]  # torch", "\n", "\n", "if", "img_feat", ".", "shape", "[", "0", "]", ">", "self", ".", "args", ".", "max_img_seq_length", ":", "\n", "                ", "img_feat", "=", "img_feat", "[", "0", ":", "self", ".", "args", ".", "max_img_seq_length", ",", "]", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids += [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids = segment_ids + [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "self", ".", "args", ".", "max_img_seq_length", "-", "img_feat", ".", "shape", "[", "0", "]", ",", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_matrix", ".", "shape", "[", "0", "]", ")", "\n", "# segment_ids = segment_ids + [pad_token_segment_id] * padding_matrix.shape[0]", "\n", "\n", "", "", "", "if", "self", ".", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "if", "(", "example", ".", "label", "is", "None", ")", ":", "\n", "                ", "label_id", "=", "[", "0", "]", "\n", "score", "=", "[", "0", "]", "\n", "", "elif", "len", "(", "example", ".", "label", ")", "==", "0", ":", "\n", "                ", "label_id", "=", "[", "0", "]", "\n", "score", "=", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "label_id", "=", "[", "self", ".", "label_map", "[", "l", "]", "for", "l", "in", "example", ".", "label", "]", "\n", "score", "=", "example", ".", "score", "\n", "", "", "elif", "self", ".", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "if", "len", "(", "example", ".", "label", ")", "==", "0", ":", "\n", "                ", "label_id", "=", "0", "\n", "", "else", ":", "\n", "                ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "self", ".", "args", ".", "output_mode", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "            ", "img_feat", "=", "img_feat", ".", "type", "(", "torch", ".", "long", ")", "\n", "", "elif", "self", ".", "args", ".", "img_feature_type", "in", "[", "'dis_code_ln'", "]", ":", "\n", "#img_feat = img_feat.reshape(-1, img_feat.shape[0])", "\n", "            ", "img_feat", "=", "img_feat", ".", "type", "(", "torch", ".", "float", ")", "\n", "\n", "", "return", "(", "torch", ".", "tensor", "(", "input_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "label_id", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "label_id", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "img_feat", ",", "\n", "torch", ".", "tensor", "(", "[", "example", ".", "q_id", "]", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa.GQADataset.__getitem__": [[364, 377], ["run_gqa.GQADataset.tensorize_example", "bool", "bool"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize_example"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "load_fast", ":", "\n", "            ", "example", "=", "self", ".", "features", "[", "index", "]", "\n", "", "else", ":", "\n", "            ", "entry", "=", "self", ".", "examples", "[", "index", "]", "\n", "example", "=", "self", ".", "tensorize_example", "(", "entry", ",", "\n", "cls_token_at_end", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "self", ".", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa.GQADataset.__len__": [[378, 380], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa._load_dataset": [[39, 70], ["processor.get_labels", "processor.get_train_examples", "processor.get_train_examples", "processor.get_dev_examples", "processor.get_dev_examples", "processor.get_train_examples", "processor.get_train_examples", "processor.get_test_examples", "processor.get_test_examples", "processor.get_dev_examples", "processor.get_dev_examples"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples"], ["def", "_load_dataset", "(", "args", ",", "name", ")", ":", "\n", "    ", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "labels", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "\n", "if", "name", "==", "'train'", ":", "\n", "        ", "if", "args", ".", "train_data_type", "==", "'bal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "'gqa_bal_qla_train.json'", ")", "#[0: debug_size]", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_train.json'", ")", "#[0: debug_size]", "\n", "", "", "elif", "name", "==", "'val'", ":", "\n", "        ", "if", "args", ".", "eval_data_type", "==", "'bal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "'gqa_bal_qla_val.json'", ")", "#[0: debug_size]", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_val.json'", ")", "#[0: debug_size]", "\n", "", "", "elif", "name", "==", "'train+val'", ":", "# depreciated", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'mask'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "'train+val2014_qla_mrcnn.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "'train+val2014_qla.json'", ")", "\n", "", "", "elif", "name", "==", "'test'", ":", "# test-submission", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'bal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_submission.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_submission.json'", ")", "\n", "", "", "elif", "name", "==", "'test-dev'", ":", "# test-dev set", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'bal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "'gqa_bal_qla_testdev.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_testdev.json'", ")", "\n", "\n", "", "", "return", "examples", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa._load_img_features": [[72, 86], ["time.time", "torch.load", "torch.load", "time.time", "logger.info", "os.path.join"], "function", ["None"], ["", "def", "_load_img_features", "(", "args", ")", ":", "\n", "    ", "t_start", "=", "time", ".", "time", "(", ")", "\n", "if", "args", ".", "img_feature_type", "==", "'faster_r-cnn'", ":", "\n", "        ", "if", "args", ".", "img_feature_dim", "==", "2048", ":", "# object features", "\n", "            ", "feat_file_name", "=", "'gqa_img_frcnn_feats_obj.pt'", "\n", "", "else", ":", "# object + spatial features", "\n", "            ", "feat_file_name", "=", "'gqa_img_frcnn_feats.pt'", "\n", "", "", "else", ":", "\n", "        ", "feat_file_name", "=", "'gqa_img_frcnn_feats.pt'", "\n", "", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "feat_file_name", ")", ")", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: loading {0:s} features using {1:.2f} secs'", ".", "format", "(", "feat_file_name", ",", "(", "t_end", "-", "t_start", ")", ")", ")", "\n", "\n", "return", "img_features", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa.trim_batch": [[382, 402], ["print", "len", "enumerate", "len", "print", "torch.zeros", "torch.zeros", "batch_tensors.append", "print", "enumerate", "ele.size", "len", "print", "list", "ele.size"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "", "def", "trim_batch", "(", "batch", ")", ":", "\n", "    ", "\"\"\" new batch func\n    :param batch:\n    :return:\n    \"\"\"", "\n", "print", "(", "'batch size'", ",", "len", "(", "batch", ")", ")", "\n", "\n", "batch_size", "=", "len", "(", "batch", ")", "\n", "batch_tensors", "=", "[", "]", "\n", "for", "ele", "in", "batch", "[", "0", "]", ":", "\n", "        ", "print", "(", "ele", ".", "shape", ",", "ele", ".", "size", "(", ")", ")", "\n", "zero_tensor", "=", "torch", ".", "zeros", "(", "(", "[", "batch_size", "]", "+", "list", "(", "ele", ".", "size", "(", ")", ")", ")", ")", "\n", "batch_tensors", ".", "append", "(", "zero_tensor", ")", "\n", "\n", "", "for", "b_id", ",", "b", "in", "enumerate", "(", "batch", ")", ":", "\n", "        ", "print", "(", "b_id", ",", "len", "(", "b", ")", ")", "\n", "for", "ele_id", ",", "ele", "in", "enumerate", "(", "b", ")", ":", "\n", "            ", "print", "(", "ele_id", ",", "ele", ".", "shape", ")", "\n", "batch_tensors", "[", "ele_id", "]", "[", "b_id", "]", "=", "ele", "\n", "", "", "return", "batch_tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa.train": [[404, 585], ["torch.utils.data.DataLoader", "transformers.pytorch_transformers.AdamW", "transformers.pytorch_transformers.WarmupLinearSchedule", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "oscar.utils.misc.set_seed", "range", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "torch.nn.parallel.DistributedDataParallel.state_dict", "transformers.pytorch_transformers.AdamW.state_dict", "int", "time.time", "enumerate", "time.time", "logger.info", "logger.info", "run_gqa.evaluate", "log_json.append", "logger.info", "logger.info", "logger.info", "open", "json.dump", "os.path.join", "logger.info", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "loss.mean.item", "copy.deepcopy", "os.path.join", "logger.info", "open", "json.dump", "os.path.exists", "os.makedirs", "hasattr", "len", "ImportError", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "loss.mean.mean", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "transformers.pytorch_transformers.WarmupLinearSchedule.step", "transformers.pytorch_transformers.AdamW.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "os.path.exists", "os.makedirs", "hasattr", "round", "model_to_save.save_pretrained", "torch.save", "torch.save", "tokenizer.save_pretrained", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "t.to", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "model_to_save.save_pretrained", "torch.save", "torch.save", "tokenizer.save_pretrained", "len", "os.path.join", "any", "logger.info", "run_gqa.evaluate", "logger.info", "os.path.join", "copy.deepcopy"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "num_workers", "=", "args", ".", "workers", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "#, collate_fn=trim_batch)", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "WarmupLinearSchedule", "(", "optimizer", ",", "warmup_steps", "=", "args", ".", "warmup_steps", ",", "t_total", "=", "t_total", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "#train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0])", "\n", "set_seed", "(", "args", ".", "seed", ",", "args", ".", "n_gpu", ")", "# Added here for reproductibility (even between python 2 and 3)", "\n", "\n", "best_score", "=", "0", "\n", "best_model", "=", "{", "\n", "'epoch'", ":", "0", ",", "\n", "'model_state'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_state'", ":", "optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n", "\n", "for", "epoch", "in", "range", "(", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "#for epoch in train_iterator:", "\n", "#epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])", "\n", "        ", "total_loss", "=", "0", "\n", "total_norm", "=", "0", "\n", "count_norm", "=", "0", "\n", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "#for step, batch in enumerate(epoch_iterator):", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "batch", "[", "3", "]", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "#loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)", "\n", "loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "\n", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "total_norm", "+=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "count_norm", "+=", "1", "\n", "\n", "#batch_score = compute_score_with_logits(logits, batch[4]).sum()", "\n", "#train_score += batch_score.item()", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "optimizer", ".", "step", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "# Log metrics", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "logger", ".", "info", "(", "\"Epoch: %d, global_step: %d\"", "%", "(", "epoch", ",", "global_step", ")", ")", "\n", "eval_result", ",", "eval_score", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "                            ", "best_score", "=", "eval_score", "\n", "best_model", "[", "'epoch'", "]", "=", "epoch", "\n", "best_model", "[", "'model'", "]", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "best_score", ")", ")", "\n", "", "logging_loss", "=", "tr_loss", "\n", "\n", "#if args.max_steps > 0 and global_step > args.max_steps:", "\n", "#    epoch_iterator.close()", "\n", "#    break", "\n", "\n", "", "", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Train Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "# evaluation", "\n", "logger", ".", "info", "(", "\"Epoch: %d\"", "%", "(", "epoch", ")", ")", "\n", "eval_result", ",", "eval_score", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "eval_score", "\n", "best_model", "[", "'epoch'", "]", "=", "epoch", "\n", "best_model", "[", "'model'", "]", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "#best_model['optimizer'] = copy.deepcopy(optimizer.state_dict())", "\n", "\n", "# save checkpoints", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_epoch", ">", "0", "and", "epoch", "%", "args", ".", "save_epoch", "==", "0", ":", "# Save model checkpoint", "\n", "            ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-{}'", ".", "format", "(", "epoch", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "model_to_save", "=", "best_model", "[", "'model'", "]", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "best_model", "[", "'model'", "]", "# Take care of distributed/parallel training", "\n", "\n", "save_num", "=", "0", "\n", "while", "(", "save_num", "<", "10", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "break", "\n", "", "except", ":", "\n", "                    ", "save_num", "+=", "1", "\n", "", "", "logger", ".", "info", "(", "\"Saving model checkpoint {0} to {1}\"", ".", "format", "(", "epoch", ",", "output_dir", ")", ")", "\n", "\n", "", "epoch_log", "=", "{", "'epoch'", ":", "epoch", ",", "'eval_score'", ":", "eval_score", ",", "'best_score'", ":", "best_score", "}", "\n", "log_json", ".", "append", "(", "epoch_log", ")", "\n", "\n", "with", "open", "(", "args", ".", "output_dir", "+", "'/eval_logs.json'", ",", "'w'", ")", "as", "fp", ":", "\n", "            ", "json", ".", "dump", "(", "log_json", ",", "fp", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"PROGRESS: {}%\"", ".", "format", "(", "round", "(", "100", "*", "(", "epoch", "+", "1", ")", "/", "args", ".", "num_train_epochs", ",", "4", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "best_score", ")", ")", "\n", "logger", ".", "info", "(", "\"LOSS: {}%\"", ".", "format", "(", "total_loss", "/", "len", "(", "train_dataset", ")", ")", ")", "\n", "\n", "", "with", "open", "(", "args", ".", "output_dir", "+", "'/eval_logs.json'", ",", "'w'", ")", "as", "fp", ":", "\n", "        ", "json", ".", "dump", "(", "log_json", ",", "fp", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "# Save the final model checkpoint", "\n", "        ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'best-{}'", ".", "format", "(", "best_model", "[", "'epoch'", "]", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "model_to_save", "=", "best_model", "[", "'model'", "]", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "best_model", "[", "'model'", "]", "# Take care of distributed/parallel training", "\n", "\n", "save_num", "=", "0", "\n", "while", "(", "save_num", "<", "10", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "break", "\n", "", "except", ":", "\n", "                ", "save_num", "+=", "1", "\n", "", "", "logger", ".", "info", "(", "\"Saving the best model checkpoint epoch {} to {}\"", ".", "format", "(", "best_model", "[", "'epoch'", "]", ",", "output_dir", ")", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa.evaluate": [[586, 655], ["time.time", "zip", "time.time", "logger.info", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "model.eval", "tuple", "float", "len", "os.path.exists", "torch.no_grad", "torch.no_grad", "model", "tmp_eval_loss.mean().item", "correct.sum().item", "logits.size", "t.to", "logits.argmax", "batch[].view", "tmp_eval_loss.mean", "correct.sum"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", "=", "None", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "'-MM'", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "#if args.n_gpu > 1: model = torch.nn.DataParallel(model) # debug: single-gpu or multi-gpus", "\n", "\n", "results", "=", "[", "]", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "num_workers", "=", "args", ".", "workers", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "num_data", "=", "0", "\n", "correct_num", "=", "0", "\n", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "#for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "batch", "[", "3", "]", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n", "#logger.info('logits: %s, batch[3]: %s' % (str(logits.shape), str(batch[3].shape)))", "\n", "#logger.info('correct: %s' % (str(logits.argmax(1) == batch[3].view(-1))))", "\n", "\n", "correct", "=", "logits", ".", "argmax", "(", "1", ")", "==", "batch", "[", "3", "]", ".", "view", "(", "-", "1", ")", "\n", "correct_num", "+=", "correct", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "num_data", "+=", "logits", ".", "size", "(", "0", ")", "\n", "\n", "# debug", "\n", "#val, idx = logits.max(1)", "\n", "#logger.info('idx: %s, batch[4]: %s' % (str(idx.shape), str(batch[3].shape)))", "\n", "#for i in range(idx.size(0)):", "\n", "#    logger.info('idx: %d, pred: %d, real: %d' % (idx[i].item(), eval_dataset.labels[idx[i].item()], batch[3][i].item()))", "\n", "\n", "", "nb_eval_steps", "+=", "1", "\n", "\n", "", "acc", "=", "float", "(", "correct_num", ")", "/", "len", "(", "eval_dataloader", ".", "dataset", ")", "\n", "\n", "logger", ".", "info", "(", "\"Eval Results:\"", ")", "\n", "logger", ".", "info", "(", "\"Eval Accuracy: %.3f\"", "%", "(", "100", "*", "acc", ")", ")", "\n", "logger", ".", "info", "(", "\"Eval Loss: %.3f\"", "%", "(", "eval_loss", ")", ")", "\n", "\n", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Eva Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "return", "results", ",", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa.test": [[656, 710], ["_pickle.load", "logger.info", "time.time", "zip", "time.time", "logger.info", "logger.info", "open", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "open", "json.dump", "len", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "model.eval", "tuple", "len", "os.path.exists", "torch.no_grad", "torch.no_grad", "model", "logits.max", "range", "t.to", "idx.size", "str", "results.append", "[].item", "idx[].item"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "test", "(", "args", ",", "model", ",", "eval_dataset", "=", "None", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "'-MM'", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "label2ans", "=", "cPickle", ".", "load", "(", "open", "(", "args", ".", "label2ans_file", ",", "'rb'", ")", ")", "\n", "logger", ".", "info", "(", "'label2ans: %d'", "%", "(", "len", "(", "label2ans", ")", ")", ")", "\n", "\n", "results", "=", "[", "]", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval", "\n", "logger", ".", "info", "(", "\"***** Running Test {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "#for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "None", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "logits", "=", "outputs", "[", "0", "]", "\n", "\n", "val", ",", "idx", "=", "logits", ".", "max", "(", "1", ")", "\n", "#logger.info('idx: %s, batch[6]: %s' % (str(idx.shape), str(batch[6].shape)))", "\n", "\n", "for", "i", "in", "range", "(", "idx", ".", "size", "(", "0", ")", ")", ":", "\n", "                    ", "result", "=", "{", "}", "\n", "result", "[", "'questionId'", "]", "=", "str", "(", "batch", "[", "6", "]", "[", "i", "]", ".", "item", "(", ")", ")", "\n", "result", "[", "'prediction'", "]", "=", "label2ans", "[", "eval_dataset", ".", "labels", "[", "idx", "[", "i", "]", ".", "item", "(", ")", "]", "]", "\n", "results", ".", "append", "(", "result", ")", "\n", "\n", "#logger.info('q_id: {0}, answer: {1}'.format(result['question_id'], result['answer']))", "\n", "\n", "", "", "", "", "with", "open", "(", "args", ".", "output_dir", "+", "(", "'/{}_results.json'", ".", "format", "(", "eval_dataset", ".", "name", ")", ")", ",", "'w'", ")", "as", "fp", ":", "\n", "        ", "json", ".", "dump", "(", "results", ",", "fp", ")", "\n", "\n", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'# questions: %d'", "%", "(", "len", "(", "results", ")", ")", ")", "\n", "logger", ".", "info", "(", "'Test Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa.load_and_cache_examples": [[712, 778], ["processor.get_labels", "time.time", "numpy.load", "oscar.utils.task_utils.convert_examples_to_features_vqa", "time.time", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "processor.get_dev_examples", "processor.get_train_examples", "os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "print", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "bool", "bool", "time.time", "numpy.zeros", "enumerate", "torch.from_numpy", "torch.from_numpy", "time.time", "logger.info", "torch.tensor", "torch.tensor", "run_gqa.target_tensor", "len"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.convert_examples_to_features_vqa", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.target_tensor"], ["", "def", "load_and_cache_examples", "(", "args", ",", "task", ",", "tokenizer", ",", "evaluate", "=", "False", ")", ":", "\n", "    ", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "output_mode", "=", "output_modes", "[", "task", "]", "\n", "\n", "label_list", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ")", "if", "evaluate", "else", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ")", "\n", "\n", "#img_features = torch.load(os.path.join(args.data_dir, 'val_img_feats.pt' if evaluate else 'train_img_feats.pt'))", "\n", "#img_features = torch.load(os.path.join(args.data_dir, 'val_img_frcnn_feats.pt' if evaluate else 'train_img_frcnn_feats.pt'))", "\n", "img_features", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'val_img_frcnn_feats.npy'", "if", "evaluate", "else", "'train_img_frcnn_feats.npy'", ")", ")", "\n", "\n", "features", "=", "convert_examples_to_features_vqa", "(", "examples", ",", "img_features", ",", "label_list", ",", "args", ".", "max_img_seq_length", ",", "args", ".", "max_seq_length", ",", "\n", "tokenizer", ",", "output_mode", ",", "\n", "cls_token_at_end", "=", "bool", "(", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "\n", "#if args.local_rank in [-1, 0]:", "\n", "#    logger.info(\"Saving features into cached file %s\", cached_features_file)", "\n", "#    torch.save(features, cached_features_file)", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: loading features using %.5f secs'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "# batch*max_seq_len", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "        ", "labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "[", "0", "]", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "targets", "=", "torch", ".", "tensor", "(", "[", "target_tensor", "(", "len", "(", "label_list", ")", ",", "f", ".", "label_id", ",", "f", ".", "score", ")", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "if", "args", ".", "img_feature_dim", ">", "0", ":", "# change here", "\n", "            ", "t_start", "=", "time", ".", "time", "(", ")", "\n", "img_feat_np", "=", "np", ".", "zeros", "(", "(", "labels", ".", "shape", "[", "0", "]", ",", "args", ".", "max_img_seq_length", ",", "args", ".", "img_feature_dim", ")", ")", "\n", "for", "f_id", ",", "f", "in", "enumerate", "(", "features", ")", ":", "\n", "                ", "img_feat_np", "[", "f_id", "]", "=", "f", ".", "img_feat", "\n", "\n", "", "img_feats", "=", "torch", ".", "from_numpy", "(", "img_feat_np", ")", "\n", "\n", "#img_feats = torch.empty((labels.shape[0], args.max_img_seq_length, args.img_feature_dim))", "\n", "#for f_id, f in enumerate(features):", "\n", "#   img_feats[f_id] = f.img_feat", "\n", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: convert image tensor features using %.5f secs'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "#img_feats = torch.stack([f.img_feat[:,-args.img_feature_dim:] for f in features])", "\n", "#img_feats = torch.stack([f.img_feat for f in features])", "\n", "#img_feats = img_feats.type(torch.long)", "\n", "\n", "#print('targets:', targets.shape)", "\n", "", "print", "(", "'img_feats:'", ",", "img_feats", ".", "shape", ")", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "        ", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "if", "args", ".", "img_feature_dim", "==", "-", "1", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "labels", ",", "targets", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "labels", ",", "targets", ",", "img_feats", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa.target_tensor": [[779, 786], ["enumerate"], "function", ["None"], ["", "def", "target_tensor", "(", "len", ",", "labels", ",", "scores", ")", ":", "\n", "    ", "\"\"\" create the target by labels and scores \"\"\"", "\n", "target", "=", "[", "0", "]", "*", "len", "\n", "for", "id", ",", "l", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "target", "[", "l", "]", "=", "scores", "[", "id", "]", "\n", "\n", "", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa.main": [[788, 1081], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "oscar.utils.misc.set_seed", "parser.parse_args.task_name.lower", "processor.get_labels", "len", "logger.info", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "run_gqa._load_img_features", "run_gqa.GQADataset", "logger.info", "os.path.join", "logger.info", "os.path.exists", "os.listdir", "logger.info", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.set_device", "torch.cuda.set_device", "torch.device", "torch.device", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "bool", "ValueError", "torch.distributed.barrier", "torch.distributed.barrier", "logger.info", "time.time", "torch.load", "torch.load", "time.time", "logger.info", "logger.info", "torch.distributed.barrier", "torch.distributed.barrier", "run_gqa.GQADataset", "run_gqa.GQADataset", "run_gqa.GQADataset", "run_gqa.train", "logger.info", "run_gqa.GQADataset", "run_gqa.train", "logger.info", "logger.info", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "torch.save", "logger.info", "logger.info", "logger.info", "os.getenv", "os.path.join", "bool", "model_class.from_pretrained.init_code_embedding", "os.makedirs", "os.path.join", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_gqa.evaluate", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_gqa.evaluate", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_gqa.test", "train_code[].t", "model_class.from_pretrained.init_code_embedding", "torch.distributed.get_rank", "torch.distributed.get_rank", "os.path.exists", "MODEL_CLASSES.keys", "oscar.utils.task_utils.processors.keys", "torch.cuda.is_available", "torch.cuda.is_available", "train_code[].t", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "sorted", "sorted", "sorted", "glob.glob", "glob.glob", "glob.glob", "list", "train_code[].keys", "list", "train_code[].keys"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few._load_img_features", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.ImageBertForSequenceClassification.init_code_embedding", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.test", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.ImageBertForSequenceClassification.init_code_embedding", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the .tsv files (or other data files) for the task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--task_name\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train selected in the list: \"", "+", "\", \"", ".", "join", "(", "processors", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--label_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Label Dictionary\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--label2ans_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Label to Answer Dictionary\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--data_label_type\"", ",", "default", "=", "'bal'", ",", "type", "=", "str", ",", "help", "=", "\"bal or all\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_data_type\"", ",", "default", "=", "'bal'", ",", "type", "=", "str", ",", "help", "=", "\"bal or all\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_data_type\"", ",", "default", "=", "'bal'", ",", "type", "=", "str", ",", "help", "=", "\"bal or all\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--loss_type\"", ",", "default", "=", "'kl'", ",", "type", "=", "str", ",", "help", "=", "\"kl or xe\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--spatial_dim\"", ",", "default", "=", "6", ",", "type", "=", "int", ",", "help", "=", "\"spatial_dim\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_label_pos_length\"", ",", "default", "=", "45", ",", "type", "=", "int", ",", "help", "=", "\"The maximum total input label position sequence length.\"", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer than this will be truncated, sequences shorter will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train_val\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run test on the test set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test_dev\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run test on the test-dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Rul evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--drop_out\"", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "\"Drop out for BERT.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--classifier\"", ",", "default", "=", "'linear'", ",", "type", "=", "str", ",", "help", "=", "\"linear or mlp\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cls_hidden_scale\"", ",", "default", "=", "2", ",", "type", "=", "int", ",", "help", "=", "\"cls_hidden_scale: for classifier\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_img_seq_length\"", ",", "default", "=", "30", ",", "type", "=", "int", ",", "help", "=", "\"The maximum total input image sequence length.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_dim\"", ",", "default", "=", "2054", ",", "type", "=", "int", ",", "help", "=", "\"The Image Feature Dimension.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_type\"", ",", "default", "=", "'faster_r-cnn'", ",", "type", "=", "str", ",", "help", "=", "\"faster_r-cnn or mask_r-cnn\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_voc\"", ",", "default", "=", "512", ",", "type", "=", "int", ",", "help", "=", "\"dis_code_voc: 256, 512\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_level\"", ",", "default", "=", "'top'", ",", "type", "=", "str", ",", "help", "=", "\"code level: top, botttom, both\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_epoch'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "\"Save checkpoint every X epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_output_dir'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_cache'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_ip'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_port'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--philly\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use Philly: reset the output dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--load_fast\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Load Tensor Fast\"", ")", "\n", "parser", ".", "add_argument", "(", "'-j'", ",", "'--workers'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "help", "=", "'number of data loading workers (default: 4)'", ")", "\n", "\n", "#args = '--data_dir ../vqa/ban-vqa/data/qal_pairs --model_type bert --model_name_or_path bert-base-uncased --task_name vqa_text ' \\", "\n", "#       '--do_train --do_eval --do_lower_case --max_seq_length 40 --per_gpu_eval_batch_size 16 --per_gpu_train_batch_size 16 --learning_rate 2e-5 ' \\", "\n", "#       '--num_train_epochs 20.0 --output_dir ./results/vqa_text --label_file ../vqa/ban-vqa/data/cache/trainval_ans2label.pkl ' \\", "\n", "#       '--save_steps 5000 --overwrite_output_dir --max_img_seq_length 1 --img_feature_dim 565 --img_feature_type dis_code '", "\n", "\n", "#args = '--data_dir ../vqa/ban-vqa/data/qal_pairs --model_type bert --model_name_or_path bert-base-uncased --task_name vqa_text ' \\", "\n", "#       '--do_train --do_eval --do_lower_case --max_seq_length 40 --per_gpu_eval_batch_size 16 --per_gpu_train_batch_size 16 --learning_rate 2e-5 ' \\", "\n", "#       '--num_train_epochs 20.0 --output_dir ./results/vqa_text --label_file ../vqa/ban-vqa/data/cache/trainval_ans2label.pkl ' \\", "\n", "#       '--save_steps 5000 --overwrite_output_dir --max_img_seq_length 10 --img_feature_dim 565 --img_feature_type other '", "\n", "\n", "#args = parser.parse_args(args.split())", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "philly", ":", "# use philly", "\n", "        ", "logger", ".", "info", "(", "'Info: Use Philly, all the output folders are reset.'", ")", "\n", "args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "getenv", "(", "'PT_OUTPUT_DIR'", ")", ",", "args", ".", "output_dir", ")", "\n", "logger", ".", "info", "(", "'OUTPUT_DIR:'", ",", "args", ".", "output_dir", ")", "\n", "\n", "#if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train and not args.overwrite_output_dir:", "\n", "#    raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args.output_dir))", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", ":", "logger", ".", "info", "(", "\"Output Directory Exists.\"", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s - %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ".", "seed", ",", "args", ".", "n_gpu", ")", "\n", "\n", "# Prepare GLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "args", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "label_list", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "logger", ".", "info", "(", "'Task Name: {}, #Labels: {}'", ".", "format", "(", "args", ".", "task_name", ",", "num_labels", ")", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "\n", "# discrete code", "\n", "config", ".", "img_feature_dim", "=", "args", ".", "img_feature_dim", "\n", "config", ".", "img_feature_type", "=", "args", ".", "img_feature_type", "\n", "config", ".", "code_voc", "=", "args", ".", "code_voc", "\n", "config", ".", "hidden_dropout_prob", "=", "args", ".", "drop_out", "\n", "config", ".", "loss_type", "=", "args", ".", "loss_type", "\n", "config", ".", "classifier", "=", "args", ".", "classifier", "\n", "config", ".", "cls_hidden_scale", "=", "args", ".", "cls_hidden_scale", "\n", "config", ".", "spatial_dim", "=", "args", ".", "spatial_dim", "\n", "\n", "# load discrete code", "\n", "if", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "'Load discrete code from: {}'", ".", "format", "(", "args", ".", "data_dir", ")", ")", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "train_code", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'vqvae'", ",", "'train.pt'", ")", ")", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Load time: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "if", "args", ".", "code_level", "==", "'top'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_t'", "]", ".", "shape", "[", "0", "]", "\n", "config", ".", "code_size", "=", "train_code", "[", "'feats_top'", "]", "[", "list", "(", "train_code", "[", "'feats_top'", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "shape", "[", "0", "]", "\n", "", "elif", "args", ".", "code_level", "==", "'bottom'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_b'", "]", ".", "shape", "[", "0", "]", "\n", "config", ".", "code_size", "=", "train_code", "[", "'feats_bottom'", "]", "[", "list", "(", "train_code", "[", "'feats_bottom'", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "shape", "[", "0", "]", "\n", "", "elif", "args", ".", "code_level", "==", "'both'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_t'", "]", ".", "shape", "[", "0", "]", "+", "train_code", "[", "'embeddings_b'", "]", ".", "shape", "[", "0", "]", "\n", "\n", "", "", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "from_tf", "=", "bool", "(", "'.ckpt'", "in", "args", ".", "model_name_or_path", ")", ",", "config", "=", "config", ")", "\n", "if", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "'Initializing the code embedding with {}'", ".", "format", "(", "args", ".", "code_level", ")", ")", "\n", "if", "args", ".", "code_level", "==", "'top'", ":", "\n", "            ", "model", ".", "init_code_embedding", "(", "train_code", "[", "'embeddings_t'", "]", ".", "t", "(", ")", ")", "\n", "", "elif", "args", ".", "code_level", "==", "'bottom'", ":", "\n", "            ", "model", ".", "init_code_embedding", "(", "train_code", "[", "'embeddings_b'", "]", ".", "t", "(", ")", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# load image features", "\n", "img_features", "=", "_load_img_features", "(", "args", ")", "\n", "label_pos_feats", "=", "None", "\n", "\n", "#if args.do_eval:", "\n", "eval_dataset", "=", "GQADataset", "(", "args", ",", "'val'", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", ")", "\n", "#eval_dataset = GQADataset(args, 'test-dev', img_features, tokenizer) # test-dev as val", "\n", "\n", "if", "args", ".", "do_test", ":", "\n", "        ", "test_dataset", "=", "GQADataset", "(", "args", ",", "'test'", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", ")", "\n", "\n", "", "if", "args", ".", "do_test_dev", ":", "\n", "        ", "test_dev_dataset", "=", "GQADataset", "(", "args", ",", "'test-dev'", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", ")", "\n", "\n", "# Training", "\n", "", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "GQADataset", "(", "args", ",", "'train'", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Training on train+val", "\n", "", "if", "args", ".", "do_train_val", ":", "# depreciated", "\n", "        ", "train_dataset", "=", "GQADataset", "(", "args", ",", "'train+val'", ",", "img_features", ",", "tokenizer", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`. They can then be reloaded using `from_pretrained()`", "\n", "#model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training", "\n", "#model_to_save.save_pretrained(args.output_dir)", "\n", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "#model = model_class.from_pretrained(args.output_dir)", "\n", "#tokenizer = tokenizer_class.from_pretrained(args.output_dir)", "\n", "#model.to(args.device)", "\n", "\n", "\n", "# Evaluation", "\n", "#results = {}", "\n", "", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ",", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "score", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "#result = dict((k + '_{}'.format(global_step), v) for k, v in result.items())", "\n", "#results.update(result)", "\n", "\n", "# Test-Dev", "\n", "", "", "if", "args", ".", "do_test_dev", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ",", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "score", "=", "evaluate", "(", "args", ",", "model", ",", "test_dev_dataset", ",", "prefix", "=", "global_step", ")", "\n", "#test(args, model, test_dev_dataset, prefix=global_step)", "\n", "\n", "# Test-Submission", "\n", "", "", "if", "args", ".", "do_test", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "test", "(", "args", ",", "model", ",", "test_dataset", ",", "prefix", "=", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_mlm.ImageBertForSequenceClassificationPrompt.__init__": [[37, 60], ["oscar.modeling.modeling_bert.ImageBertForSequenceClassification.__init__", "transformers.pytorch_transformers.modeling_bert.BertPooler", "hasattr", "run_gqa_prompt_mlm.ImageBertForSequenceClassificationPrompt.apply", "torch.Linear", "torch.Linear", "hasattr", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "ImageBertForSequenceClassificationPrompt", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "# Used to project output mask embedding", "\n", "self", ".", "mask_pooler", "=", "BertPooler", "(", "config", ")", "\n", "\n", "if", "hasattr", "(", "config", ",", "'classifier'", ")", ":", "\n", "            ", "if", "not", "hasattr", "(", "config", ",", "'cls_hidden_scale'", ")", ":", "\n", "                ", "config", ".", "cls_hidden_scale", "=", "2", "\n", "\n", "", "if", "config", ".", "classifier", "==", "'linear'", ":", "\n", "                ", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "\n", "self", ".", "config", ".", "num_labels", ")", "\n", "", "elif", "config", ".", "classifier", "==", "'mlp'", ":", "\n", "                ", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", "*", "config", ".", "cls_hidden_scale", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "config", ".", "cls_hidden_scale", ",", "self", ".", "config", ".", "num_labels", ")", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "self", ".", "config", ".", "num_labels", ")", "# original", "\n", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_mlm.ImageBertForSequenceClassificationPrompt.forward": [[61, 89], ["run_gqa_prompt_mlm.ImageBertForSequenceClassificationPrompt.bert", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "run_gqa_prompt_mlm.ImageBertForSequenceClassificationPrompt.mask_pooler", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "run_gqa_prompt_mlm.ImageBertForSequenceClassificationPrompt.classifier", "run_gqa_prompt_mlm.ImageBertForSequenceClassificationPrompt.dropout", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "mask_index.unsqueeze().expand", "run_gqa_prompt_mlm.ImageBertForSequenceClassificationPrompt.view", "labels.view", "mask_index.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "img_feats", "=", "None", ",", "mask_index", "=", "None", ")", ":", "\n", "# (batch_size, sequence_length, hidden_dim), (batch_size, hidden_dim), ...", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ",", "img_feats", "=", "img_feats", ")", "\n", "\n", "# (batch_size, hidden_dim)", "\n", "# pooled_output = outputs[1]", "\n", "seq_length", ",", "hidden_dim", "=", "outputs", "[", "0", "]", ".", "shape", "[", "1", ":", "]", "\n", "pooled_output", "=", "torch", ".", "gather", "(", "\n", "input", "=", "outputs", "[", "0", "]", ",", "\n", "dim", "=", "1", ",", "\n", "index", "=", "mask_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "(", "-", "1", ",", "-", "1", ",", "hidden_dim", ")", ")", "\n", ")", "# [batch_size, 1, hidden_dim]", "\n", "pooled_output", "=", "self", ".", "mask_pooler", "(", "pooled_output", ")", "# [batch_size, hidden_dim]", "\n", "pooled_output_cls", "=", "outputs", "[", "1", "]", "# [batch_size, hidden_dim]", "\n", "\n", "# Concat [CLS] and [MASK] for prediction", "\n", "pooled_output", "=", "torch", ".", "cat", "(", "[", "pooled_output", ",", "pooled_output_cls", "]", ",", "dim", "=", "-", "1", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "self", ".", "dropout", "(", "pooled_output", ")", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_mlm.GQADataset.__init__": [[181, 207], ["torch.utils.data.Dataset.__init__", "run_gqa_prompt_mlm._load_dataset", "logger.info", "run_gqa_prompt_mlm.GQADataset.tensorize", "enumerate", "bool", "bool", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few._load_dataset", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize"], ["def", "__init__", "(", "self", ",", "args", ",", "name", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", "=", "None", ")", ":", "\n", "        ", "super", "(", "GQADataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "name", "in", "[", "'train'", ",", "'val'", ",", "'test-dev'", ",", "'test'", ",", "'train+val'", "]", "\n", "\n", "self", ".", "img_features", "=", "img_features", "\n", "self", ".", "label_pos_feats", "=", "label_pos_feats", "# None", "\n", "self", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "# classification", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "name", "=", "name", "\n", "\n", "self", ".", "examples", ",", "self", ".", "labels", "=", "_load_dataset", "(", "args", ",", "name", ")", "\n", "self", ".", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "self", ".", "labels", ")", "}", "\n", "\n", "# False", "\n", "if", "self", ".", "args", ".", "load_fast", ":", "\n", "            ", "self", ".", "features", "=", "self", ".", "tensorize", "(", "args", ",", "cls_token_at_end", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "self", ".", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "\n", "", "logger", ".", "info", "(", "'%s Data Examples: %d'", "%", "(", "name", ",", "len", "(", "self", ".", "examples", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_mlm.GQADataset.tensorize": [[208, 314], ["enumerate", "run_gqa_prompt_mlm.GQADataset.tokenizer.tokenize", "run_gqa_prompt_mlm.GQADataset.tokenizer.convert_tokens_to_ids", "run_gqa_prompt_mlm.target_tensor", "features.append", "len", "logger.info", "run_gqa_prompt_mlm.GQADataset.tokenizer.tokenize", "oscar.utils.task_utils._truncate_seq_pair", "len", "len", "len", "len", "len", "len", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "len", "len", "float", "KeyError", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.target_tensor", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv._truncate_seq_pair"], ["", "def", "tensorize", "(", "self", ",", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "\n", "# debug:", "\n", "        ", "debug_size", "=", "500", "\n", "features", "=", "[", "]", "\n", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "self", ".", "examples", "[", "0", ":", "]", ")", ":", "\n", "            ", "if", "len", "(", "example", ".", "label", ")", "==", "0", ":", "continue", "\n", "if", "ex_index", "%", "10000", "==", "0", ":", "logger", ".", "info", "(", "\"Tensorizing example %d of %d\"", "%", "(", "ex_index", ",", "len", "(", "self", ".", "examples", ")", ")", ")", "\n", "\n", "tokens_a", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "                ", "tokens_b", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_b", ")", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "self", ".", "args", ".", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "                ", "if", "len", "(", "tokens_a", ")", ">", "self", ".", "args", ".", "max_seq_length", "-", "2", ":", "\n", "                    ", "tokens_a", "=", "tokens_a", "[", ":", "(", "self", ".", "args", ".", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "", "tokens", "=", "tokens_a", "+", "[", "sep_token", "]", "\n", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "                ", "tokens", "+=", "tokens_b", "+", "[", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "if", "cls_token_at_end", ":", "\n", "                ", "tokens", "=", "tokens", "+", "[", "cls_token", "]", "\n", "segment_ids", "=", "segment_ids", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "                ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "self", ".", "args", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "                ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "", "else", ":", "\n", "                ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "segment_ids", "=", "segment_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "\n", "# image features", "\n", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "# torch", "\n", "#img_feat = self.img_features.item().get(example.img_key)  # numpy", "\n", "if", "img_feat", ".", "shape", "[", "0", "]", ">", "self", ".", "args", ".", "max_img_seq_length", ":", "\n", "                ", "img_feat", "=", "img_feat", "[", "0", ":", "self", ".", "args", ".", "max_img_seq_length", ",", "]", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids += [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids = segment_ids + [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "self", ".", "args", ".", "max_img_seq_length", "-", "img_feat", ".", "shape", "[", "0", "]", ",", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_matrix", ".", "shape", "[", "0", "]", ")", "\n", "# segment_ids = segment_ids + [pad_token_segment_id] * padding_matrix.shape[0]", "\n", "\n", "", "", "if", "self", ".", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "                ", "label_id", "=", "[", "self", ".", "label_map", "[", "l", "]", "for", "l", "in", "example", ".", "label", "]", "\n", "score", "=", "example", ".", "score", "\n", "", "elif", "self", ".", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "                ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "else", ":", "\n", "                ", "raise", "KeyError", "(", "self", ".", "args", ".", "output_mode", ")", "\n", "\n", "", "if", "ex_index", "<", "5", ":", "\n", "                ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"segment_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label: %s (id = %s)\"", "%", "(", "example", ".", "label", ",", "label_id", ")", ")", "\n", "logger", ".", "info", "(", "\"score: %s (score = %s)\"", "%", "(", "example", ".", "score", ",", "score", ")", ")", "\n", "\n", "", "new_scores", "=", "target_tensor", "(", "len", "(", "self", ".", "labels", ")", ",", "label_id", ",", "score", ")", "\n", "#features.append(InputFeat(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label_id, score=score, img_feat=img_feat))", "\n", "features", ".", "append", "(", "(", "torch", ".", "tensor", "(", "input_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "label_id", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "new_scores", ",", "dtype", "=", "torch", ".", "float", ")", ",", "img_feat", ")", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_mlm.GQADataset.tensorize_example": [[315, 465], ["run_gqa_prompt_mlm.GQADataset.tokenizer.tokenize", "run_gqa_prompt_mlm.GQADataset.tokenizer.tokenize", "run_gqa_prompt_mlm.GQADataset.tokenizer.convert_tokens_to_ids", "run_gqa_prompt_mlm.GQADataset.args.img_feature_type.startswith", "example.text_b.split", "enumerate", "example.text_b.replace().strip", "run_gqa_prompt_mlm.GQADataset.tokenizer.tokenize", "oscar.utils.task_utils._truncate_seq_pair", "len", "ValueError", "tokens.index", "print", "len", "len", "ValueError", "len", "len", "len", "img_feat.type.type.type", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "run_gqa_prompt_mlm.GQADataset.tokenizer.tokenize", "txt_label_ixs.extend", "len", "len", "len", "img_feat.type.type.reshape", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KeyError", "img_feat.type.type.type", "example.text_b.replace", "len", "len", "len", "len", "float", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv._truncate_seq_pair"], ["", "def", "tensorize_example", "(", "self", ",", "example", ",", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "\n", "        ", "tokens_a", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "# Add the declarative sentence", "\n", "tokens_c", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "\"Answer: \"", "+", "example", ".", "text_c", ")", "\n", "# tokens_c = self.tokenizer.tokenize(\"Answer: [MASK]\")", "\n", "# Please add [V1]-[V16] tokens to `added_tokens.json` file.", "\n", "# tokens_c = (\"answer : {} [MASK]\".format(\" \".join([\"[V{}]\".format(i) for i in range(1, 17)]))).split(\" \")", "\n", "tokens_a", "=", "tokens_a", "+", "tokens_c", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "            ", "txt_b_arr", "=", "example", ".", "text_b", ".", "split", "(", "';'", ")", "\n", "txt_label_ixs", "=", "[", "]", "\n", "for", "txt_b_ix", ",", "txt_b_ele", "in", "enumerate", "(", "txt_b_arr", ")", ":", "\n", "                ", "tokens_b_ele", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "txt_b_ele", ")", "\n", "txt_label_ixs", ".", "extend", "(", "[", "txt_b_ix", "]", "*", "len", "(", "tokens_b_ele", ")", ")", "\n", "", "txt_b", "=", "example", ".", "text_b", ".", "replace", "(", "';'", ",", "' '", ")", ".", "strip", "(", ")", "\n", "tokens_b", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "txt_b", ")", "\n", "assert", "len", "(", "tokens_b", ")", "==", "len", "(", "txt_label_ixs", ")", "\n", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "self", ".", "args", ".", "max_seq_length", "-", "3", ")", "\n", "txt_label_ixs", "=", "txt_label_ixs", "[", "0", ":", "len", "(", "tokens_b", ")", "]", "\n", "\n", "# original", "\n", "#if example.text_b:", "\n", "#    txt_b = example.text_b.replace(';', ' ').strip()", "\n", "#    tokens_b = self.tokenizer.tokenize(txt_b)", "\n", "#    _truncate_seq_pair(tokens_a, tokens_b, self.args.max_seq_length - 3)", "\n", "", "else", ":", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "            ", "if", "len", "(", "tokens_a", ")", ">", "self", ".", "args", ".", "max_seq_length", "-", "2", ":", "\n", "                ", "tokens_a", "=", "tokens_a", "[", ":", "(", "self", ".", "args", ".", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "# question + [SEP]", "\n", "", "", "tokens", "=", "tokens_a", "+", "[", "sep_token", "]", "\n", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "# question + [SEP] + tags + [SEP]", "\n", "            ", "tokens", "+=", "tokens_b", "+", "[", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "# False", "\n", "", "if", "cls_token_at_end", ":", "\n", "            ", "raise", "ValueError", "(", "\"No CLS at end.\"", ")", "\n", "tokens", "=", "tokens", "+", "[", "cls_token", "]", "\n", "segment_ids", "=", "segment_ids", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "# [CLS] + question + [SEP] + tags + [SEP]", "\n", "            ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "if", "\"[MASK]\"", "in", "tokens", ":", "\n", "            ", "mask_index", "=", "tokens", ".", "index", "(", "\"[MASK]\"", ")", "\n", "", "else", ":", "\n", "            ", "mask_index", "=", "0", "\n", "print", "(", "\"qid {} has no [MASK]\"", ".", "format", "(", "example", ".", "q_id", ")", ")", "\n", "", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "self", ".", "args", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "# False", "\n", "if", "pad_on_left", ":", "\n", "            ", "raise", "ValueError", "(", "\"No pad on left.\"", ")", "\n", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "", "else", ":", "\n", "# [..., 0, 0, 0, ...]", "\n", "            ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "# [1, 1, ..., 0, 0, 0, ...]", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "# [1, 0, 0, ..., 1, 1, ..., 0, 0, 0, ...]", "\n", "segment_ids", "=", "segment_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "\n", "# image features", "\n", "if", "self", ".", "args", ".", "img_feature_type", ".", "startswith", "(", "'dis_code'", ")", ":", "\n", "            ", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "\n", "\n", "if", "self", ".", "args", ".", "img_feature_type", "==", "'dis_code_ln'", ":", "# for discrete code image representation", "\n", "                ", "img_feat", "=", "img_feat", ".", "reshape", "(", "-", "1", ",", "img_feat", ".", "shape", "[", "0", "]", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "img_feature_type", "==", "'dis_code_t'", ":", "# transposed", "\n", "                ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "64", "\n", "", "else", ":", "\n", "                ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "", "", "else", ":", "\n", "            ", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "#[:, 0:self.args.img_feature_dim]  # torch", "\n", "\n", "if", "img_feat", ".", "shape", "[", "0", "]", ">", "self", ".", "args", ".", "max_img_seq_length", ":", "\n", "                ", "img_feat", "=", "img_feat", "[", "0", ":", "self", ".", "args", ".", "max_img_seq_length", ",", "]", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids += [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids = segment_ids + [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "self", ".", "args", ".", "max_img_seq_length", "-", "img_feat", ".", "shape", "[", "0", "]", ",", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_matrix", ".", "shape", "[", "0", "]", ")", "\n", "# segment_ids = segment_ids + [pad_token_segment_id] * padding_matrix.shape[0]", "\n", "\n", "", "", "", "if", "self", ".", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "if", "(", "example", ".", "label", "is", "None", ")", ":", "\n", "                ", "label_id", "=", "[", "0", "]", "\n", "score", "=", "[", "0", "]", "\n", "", "elif", "len", "(", "example", ".", "label", ")", "==", "0", ":", "\n", "                ", "label_id", "=", "[", "0", "]", "\n", "score", "=", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "label_id", "=", "[", "self", ".", "label_map", "[", "l", "]", "for", "l", "in", "example", ".", "label", "]", "\n", "score", "=", "example", ".", "score", "\n", "", "", "elif", "self", ".", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "if", "len", "(", "example", ".", "label", ")", "==", "0", ":", "\n", "                ", "label_id", "=", "0", "\n", "", "else", ":", "\n", "                ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "self", ".", "args", ".", "output_mode", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "            ", "img_feat", "=", "img_feat", ".", "type", "(", "torch", ".", "long", ")", "\n", "", "elif", "self", ".", "args", ".", "img_feature_type", "in", "[", "'dis_code_ln'", "]", ":", "\n", "#img_feat = img_feat.reshape(-1, img_feat.shape[0])", "\n", "            ", "img_feat", "=", "img_feat", ".", "type", "(", "torch", ".", "float", ")", "\n", "\n", "", "return", "(", "torch", ".", "tensor", "(", "input_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 0", "\n", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 1", "\n", "torch", ".", "tensor", "(", "segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 2", "\n", "torch", ".", "tensor", "(", "[", "label_id", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 3", "\n", "torch", ".", "tensor", "(", "[", "label_id", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 4", "\n", "img_feat", ",", "# 5", "\n", "torch", ".", "tensor", "(", "[", "example", ".", "q_id", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 6", "\n", "torch", ".", "tensor", "(", "[", "mask_index", "]", ",", "dtype", "=", "torch", ".", "long", ")", ")", "# 7", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_mlm.GQADataset.__getitem__": [[466, 479], ["run_gqa_prompt_mlm.GQADataset.tensorize_example", "bool", "bool"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize_example"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "load_fast", ":", "\n", "            ", "example", "=", "self", ".", "features", "[", "index", "]", "\n", "", "else", ":", "\n", "            ", "entry", "=", "self", ".", "examples", "[", "index", "]", "\n", "example", "=", "self", ".", "tensorize_example", "(", "entry", ",", "\n", "cls_token_at_end", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "self", ".", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_mlm.GQADataset.__len__": [[480, 482], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_mlm._load_dataset": [[96, 162], ["processor.get_labels", "processor.get_train_examples", "zip", "processor.get_train_examples", "zip", "open", "fp.read().split", "len", "len", "open", "fp.read().split", "len", "len", "processor.get_dev_examples", "zip", "processor.get_dev_examples", "zip", "os.path.join", "os.path.join", "open", "fp.read().split", "len", "len", "open", "fp.read().split", "len", "len", "processor.get_train_examples", "processor.get_train_examples", "zip", "fp.read", "fp.read", "os.path.join", "os.path.join", "processor.get_test_examples", "processor.get_test_examples", "open", "fp.read().split", "len", "len", "fp.read", "fp.read", "os.path.join", "processor.get_dev_examples", "processor.get_dev_examples", "fp.read"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples"], ["def", "_load_dataset", "(", "args", ",", "name", ")", ":", "\n", "    ", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "labels", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "\n", "if", "name", "==", "'train'", ":", "\n", "        ", "if", "args", ".", "train_data_type", "==", "'bal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "'gqa_bal_qla_train.json'", ")", "#[0: debug_size]", "\n", "\n", "# Loading the declarative sentences", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'gqa_bal_qla_train_declarative.json'", ")", ")", "as", "fp", ":", "\n", "                ", "lines", "=", "fp", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "", "assert", "len", "(", "examples", ")", "==", "len", "(", "lines", ")", "\n", "for", "example", ",", "line", "in", "zip", "(", "examples", ",", "lines", ")", ":", "\n", "                ", "example", ".", "text_c", "=", "line", "\n", "", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_train.json'", ")", "#[0: debug_size]", "\n", "\n", "# Loading the declarative sentences", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_train_declarative.json'", ")", ")", "as", "fp", ":", "\n", "                ", "lines", "=", "fp", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "", "assert", "len", "(", "examples", ")", "==", "len", "(", "lines", ")", "\n", "for", "example", ",", "line", "in", "zip", "(", "examples", ",", "lines", ")", ":", "\n", "                ", "example", ".", "text_c", "=", "line", "\n", "", "", "", "elif", "name", "==", "'val'", ":", "\n", "        ", "if", "args", ".", "eval_data_type", "==", "'bal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "'gqa_bal_qla_val.json'", ")", "#[0: debug_size]", "\n", "\n", "# Loading the declarative sentences", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'gqa_bal_qla_val_declarative.json'", ")", ")", "as", "fp", ":", "\n", "                ", "lines", "=", "fp", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "", "assert", "len", "(", "examples", ")", "==", "len", "(", "lines", ")", "\n", "for", "example", ",", "line", "in", "zip", "(", "examples", ",", "lines", ")", ":", "\n", "                ", "example", ".", "text_c", "=", "line", "\n", "", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_val.json'", ")", "#[0: debug_size]", "\n", "\n", "# Loading the declarative sentences", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_val_declarative.json'", ")", ")", "as", "fp", ":", "\n", "                ", "lines", "=", "fp", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "", "assert", "len", "(", "examples", ")", "==", "len", "(", "lines", ")", "\n", "for", "example", ",", "line", "in", "zip", "(", "examples", ",", "lines", ")", ":", "\n", "                ", "example", ".", "text_c", "=", "line", "\n", "", "", "", "elif", "name", "==", "'train+val'", ":", "# depreciated", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'mask'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "'train+val2014_qla_mrcnn.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "'train+val2014_qla.json'", ")", "\n", "", "", "elif", "name", "==", "'test'", ":", "# test-submission", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'bal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_submission.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_submission.json'", ")", "\n", "\n", "# Loading the declarative sentences", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_submission_declarative.json'", ")", ")", "as", "fp", ":", "\n", "            ", "lines", "=", "fp", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "", "assert", "len", "(", "examples", ")", "==", "len", "(", "lines", ")", "\n", "for", "example", ",", "line", "in", "zip", "(", "examples", ",", "lines", ")", ":", "\n", "            ", "example", ".", "text_c", "=", "line", "\n", "", "", "elif", "name", "==", "'test-dev'", ":", "# test-dev set", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'bal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "'gqa_bal_qla_testdev.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_testdev.json'", ")", "\n", "\n", "", "", "return", "examples", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_mlm._load_img_features": [[163, 177], ["time.time", "torch.load", "torch.load", "time.time", "logger.info", "os.path.join"], "function", ["None"], ["", "def", "_load_img_features", "(", "args", ")", ":", "\n", "    ", "t_start", "=", "time", ".", "time", "(", ")", "\n", "if", "args", ".", "img_feature_type", "==", "'faster_r-cnn'", ":", "\n", "        ", "if", "args", ".", "img_feature_dim", "==", "2048", ":", "# object features", "\n", "            ", "feat_file_name", "=", "'gqa_img_frcnn_feats_obj.pt'", "\n", "", "else", ":", "# object + spatial features", "\n", "            ", "feat_file_name", "=", "'gqa_img_frcnn_feats.pt'", "\n", "", "", "else", ":", "\n", "        ", "feat_file_name", "=", "'gqa_img_frcnn_feats.pt'", "\n", "", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "feat_file_name", ")", ")", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: loading {0:s} features using {1:.2f} secs'", ".", "format", "(", "feat_file_name", ",", "(", "t_end", "-", "t_start", ")", ")", ")", "\n", "\n", "return", "img_features", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_mlm.trim_batch": [[483, 503], ["print", "len", "enumerate", "len", "print", "torch.zeros", "torch.zeros", "batch_tensors.append", "print", "enumerate", "ele.size", "len", "print", "list", "ele.size"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "", "def", "trim_batch", "(", "batch", ")", ":", "\n", "    ", "\"\"\" new batch func\n    :param batch:\n    :return:\n    \"\"\"", "\n", "print", "(", "'batch size'", ",", "len", "(", "batch", ")", ")", "\n", "\n", "batch_size", "=", "len", "(", "batch", ")", "\n", "batch_tensors", "=", "[", "]", "\n", "for", "ele", "in", "batch", "[", "0", "]", ":", "\n", "        ", "print", "(", "ele", ".", "shape", ",", "ele", ".", "size", "(", ")", ")", "\n", "zero_tensor", "=", "torch", ".", "zeros", "(", "(", "[", "batch_size", "]", "+", "list", "(", "ele", ".", "size", "(", ")", ")", ")", ")", "\n", "batch_tensors", ".", "append", "(", "zero_tensor", ")", "\n", "\n", "", "for", "b_id", ",", "b", "in", "enumerate", "(", "batch", ")", ":", "\n", "        ", "print", "(", "b_id", ",", "len", "(", "b", ")", ")", "\n", "for", "ele_id", ",", "ele", "in", "enumerate", "(", "b", ")", ":", "\n", "            ", "print", "(", "ele_id", ",", "ele", ".", "shape", ")", "\n", "batch_tensors", "[", "ele_id", "]", "[", "b_id", "]", "=", "ele", "\n", "", "", "return", "batch_tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_mlm.train": [[504, 732], ["torch.utils.data.DataLoader", "transformers.pytorch_transformers.AdamW", "transformers.pytorch_transformers.WarmupLinearSchedule", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "oscar.utils.misc.set_seed", "range", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "torch.cuda.amp.GradScaler", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "torch.nn.parallel.DistributedDataParallel.state_dict", "transformers.pytorch_transformers.AdamW.state_dict", "dict", "enumerate", "os.path.join", "run_gqa_prompt_mlm.evaluate", "exit", "int", "time.time", "enumerate", "time.time", "logger.info", "logger.info", "run_gqa_prompt_mlm.evaluate", "log_json.append", "logger.info", "logger.info", "logger.info", "open", "json.dump", "os.path.join", "logger.info", "torch.nn.parallel.DistributedDataParallel.eval", "tuple", "batch[].squeeze().detach().cpu().numpy", "enumerate", "open", "_pickle.dump", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "loss.mean.item", "loss.mean.item", "copy.deepcopy", "os.path.join", "logger.info", "open", "json.dump", "os.path.exists", "os.makedirs", "hasattr", "len", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.no_grad", "torch.no_grad", "torch.nn.parallel.DistributedDataParallel.", "torch.topk", "torch.topk", "torch.cuda.amp.autocast", "torch.nn.parallel.DistributedDataParallel.", "torch.cuda.amp.GradScaler.scale().backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "transformers.pytorch_transformers.WarmupLinearSchedule.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "os.path.exists", "os.makedirs", "hasattr", "round", "model_to_save.save_pretrained", "torch.save", "torch.save", "tokenizer.save_pretrained", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "t.to", "batch[].squeeze().detach().cpu", "topk_indices.detach().cpu().numpy().astype", "topk_values.detach().cpu().numpy().astype", "t.to", "loss.mean.mean", "torch.nn.parallel.DistributedDataParallel.parameters", "torch.nn.parallel.DistributedDataParallel.parameters", "torch.cuda.amp.GradScaler.step", "torch.cuda.amp.GradScaler.update", "transformers.pytorch_transformers.AdamW.step", "model_to_save.save_pretrained", "torch.save", "torch.save", "tokenizer.save_pretrained", "len", "os.path.join", "any", "int", "torch.cuda.amp.GradScaler.scale", "logger.info", "run_gqa_prompt_mlm.evaluate", "logger.info", "os.path.join", "batch[].squeeze().detach", "topk_indices.detach().cpu().numpy", "topk_values.detach().cpu().numpy", "copy.deepcopy", "batch[].squeeze", "topk_indices.detach().cpu", "topk_values.detach().cpu", "topk_indices.detach", "topk_values.detach"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.SmoothedValue.update", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "args", ".", "train_batch_size", ")", "#, collate_fn=trim_batch)", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "WarmupLinearSchedule", "(", "optimizer", ",", "warmup_steps", "=", "args", ".", "warmup_steps", ",", "t_total", "=", "t_total", ")", "\n", "\n", "# if args.fp16:", "\n", "#     try:", "\n", "#         from apex import amp", "\n", "#     except ImportError:", "\n", "#         raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")", "\n", "#     model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "scaler", "=", "GradScaler", "(", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "#train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0])", "\n", "set_seed", "(", "args", ".", "seed", ",", "args", ".", "n_gpu", ")", "# Added here for reproductibility (even between python 2 and 3)", "\n", "\n", "best_score", "=", "0", "\n", "best_model", "=", "{", "\n", "'epoch'", ":", "0", ",", "\n", "'model_state'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_state'", ":", "optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n", "\n", "if", "args", ".", "do_generate", ":", "\n", "        ", "stage1_dict", "=", "dict", "(", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "\n", "# XLM don't use segment_ids", "\n", "'labels'", ":", "batch", "[", "3", "]", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", ",", "\n", "'mask_index'", ":", "batch", "[", "7", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "logits", "=", "outputs", "[", "1", "]", "\n", "", "q_ids", "=", "batch", "[", "6", "]", ".", "squeeze", "(", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "q_ids", ")", ":", "\n", "                ", "topk_values", ",", "topk_indices", "=", "torch", ".", "topk", "(", "logits", "[", "i", "]", ",", "k", "=", "10", ",", "dim", "=", "0", ")", "\n", "stage1_dict", "[", "int", "(", "qid", ")", "]", "=", "(", "topk_indices", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "int16", ")", ",", "\n", "topk_values", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "float16", ")", ")", "\n", "\n", "", "", "stage1_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"stage1.pkl\"", ")", "\n", "with", "open", "(", "stage1_file", ",", "\"wb\"", ")", "as", "fp", ":", "\n", "            ", "cPickle", ".", "dump", "(", "stage1_dict", ",", "fp", ")", "\n", "\n", "", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ")", "\n", "\n", "exit", "(", "0", ")", "\n", "\n", "", "for", "epoch", "in", "range", "(", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "#for epoch in train_iterator:", "\n", "#epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])", "\n", "        ", "total_loss", "=", "0", "\n", "total_norm", "=", "0", "\n", "count_norm", "=", "0", "\n", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "#for step, batch in enumerate(epoch_iterator):", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "batch", "[", "3", "]", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", ",", "\n", "'mask_index'", ":", "batch", "[", "7", "]", "}", "\n", "\n", "with", "autocast", "(", "enabled", "=", "args", ".", "fp16", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "#loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)", "\n", "loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "\n", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                    ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "", "if", "args", ".", "fp16", ":", "\n", "                ", "scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "# with amp.scale_loss(loss, optimizer) as scaled_loss:", "\n", "#     scaled_loss.backward()", "\n", "# torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "total_norm", "+=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "count_norm", "+=", "1", "\n", "\n", "#batch_score = compute_score_with_logits(logits, batch[4]).sum()", "\n", "#train_score += batch_score.item()", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "# scheduler.step()  # Update learning rate schedule", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "scaler", ".", "step", "(", "optimizer", ")", "\n", "scaler", ".", "update", "(", ")", "\n", "", "else", ":", "\n", "                    ", "optimizer", ".", "step", "(", ")", "\n", "", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "# Log metrics", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "logger", ".", "info", "(", "\"Epoch: %d, global_step: %d\"", "%", "(", "epoch", ",", "global_step", ")", ")", "\n", "eval_result", ",", "eval_score", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "                            ", "best_score", "=", "eval_score", "\n", "best_model", "[", "'epoch'", "]", "=", "epoch", "\n", "best_model", "[", "'model'", "]", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "best_score", ")", ")", "\n", "", "logging_loss", "=", "tr_loss", "\n", "\n", "#if args.max_steps > 0 and global_step > args.max_steps:", "\n", "#    epoch_iterator.close()", "\n", "#    break", "\n", "\n", "", "", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Train Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "# evaluation", "\n", "logger", ".", "info", "(", "\"Epoch: %d\"", "%", "(", "epoch", ")", ")", "\n", "eval_result", ",", "eval_score", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "eval_score", "\n", "best_model", "[", "'epoch'", "]", "=", "epoch", "\n", "best_model", "[", "'model'", "]", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "#best_model['optimizer'] = copy.deepcopy(optimizer.state_dict())", "\n", "\n", "# save checkpoints", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_epoch", ">", "0", "and", "epoch", "%", "args", ".", "save_epoch", "==", "0", ":", "# Save model checkpoint", "\n", "            ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-{}'", ".", "format", "(", "epoch", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "model_to_save", "=", "best_model", "[", "'model'", "]", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "best_model", "[", "'model'", "]", "# Take care of distributed/parallel training", "\n", "\n", "save_num", "=", "0", "\n", "while", "(", "save_num", "<", "10", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "break", "\n", "", "except", ":", "\n", "                    ", "save_num", "+=", "1", "\n", "", "", "logger", ".", "info", "(", "\"Saving model checkpoint {0} to {1}\"", ".", "format", "(", "epoch", ",", "output_dir", ")", ")", "\n", "\n", "", "epoch_log", "=", "{", "'epoch'", ":", "epoch", ",", "'eval_score'", ":", "eval_score", ",", "'best_score'", ":", "best_score", "}", "\n", "log_json", ".", "append", "(", "epoch_log", ")", "\n", "\n", "with", "open", "(", "args", ".", "output_dir", "+", "'/eval_logs.json'", ",", "'w'", ")", "as", "fp", ":", "\n", "            ", "json", ".", "dump", "(", "log_json", ",", "fp", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"PROGRESS: {}%\"", ".", "format", "(", "round", "(", "100", "*", "(", "epoch", "+", "1", ")", "/", "args", ".", "num_train_epochs", ",", "4", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "best_score", ")", ")", "\n", "logger", ".", "info", "(", "\"LOSS: {}%\"", ".", "format", "(", "total_loss", "/", "len", "(", "train_dataset", ")", ")", ")", "\n", "\n", "", "with", "open", "(", "args", ".", "output_dir", "+", "'/eval_logs.json'", ",", "'w'", ")", "as", "fp", ":", "\n", "        ", "json", ".", "dump", "(", "log_json", ",", "fp", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "# Save the final model checkpoint", "\n", "        ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'best-{}'", ".", "format", "(", "best_model", "[", "'epoch'", "]", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "model_to_save", "=", "best_model", "[", "'model'", "]", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "best_model", "[", "'model'", "]", "# Take care of distributed/parallel training", "\n", "\n", "save_num", "=", "0", "\n", "while", "(", "save_num", "<", "10", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "break", "\n", "", "except", ":", "\n", "                ", "save_num", "+=", "1", "\n", "", "", "logger", ".", "info", "(", "\"Saving the best model checkpoint epoch {} to {}\"", ".", "format", "(", "best_model", "[", "'epoch'", "]", ",", "output_dir", ")", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_mlm.evaluate": [[733, 817], ["time.time", "dict", "zip", "time.time", "logger.info", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "os.path.join", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "model.eval", "tuple", "float", "len", "open", "_pickle.dump", "os.path.exists", "torch.no_grad", "torch.no_grad", "model", "tmp_eval_loss.mean().item", "correct.sum().item", "logits.size", "batch[].squeeze().detach().cpu().numpy", "enumerate", "t.to", "logits.argmax", "batch[].view", "torch.topk", "torch.topk", "tmp_eval_loss.mean", "correct.sum", "batch[].squeeze().detach().cpu", "topk_indices.detach().cpu().numpy().astype", "topk_values.detach().cpu().numpy().astype", "int", "batch[].squeeze().detach", "topk_indices.detach().cpu().numpy", "topk_values.detach().cpu().numpy", "batch[].squeeze", "topk_indices.detach().cpu", "topk_values.detach().cpu", "topk_indices.detach", "topk_values.detach"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", "=", "None", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "'-MM'", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "#if args.n_gpu > 1: model = torch.nn.DataParallel(model) # debug: single-gpu or multi-gpus", "\n", "\n", "results", "=", "[", "]", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "stage1_dict", "=", "dict", "(", ")", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "num_workers", "=", "args", ".", "workers", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "num_data", "=", "0", "\n", "correct_num", "=", "0", "\n", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "#for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "batch", "[", "3", "]", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", ",", "\n", "'mask_index'", ":", "batch", "[", "7", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n", "#logger.info('logits: %s, batch[3]: %s' % (str(logits.shape), str(batch[3].shape)))", "\n", "#logger.info('correct: %s' % (str(logits.argmax(1) == batch[3].view(-1))))", "\n", "\n", "correct", "=", "logits", ".", "argmax", "(", "1", ")", "==", "batch", "[", "3", "]", ".", "view", "(", "-", "1", ")", "\n", "correct_num", "+=", "correct", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "num_data", "+=", "logits", ".", "size", "(", "0", ")", "\n", "\n", "# debug", "\n", "#val, idx = logits.max(1)", "\n", "#logger.info('idx: %s, batch[4]: %s' % (str(idx.shape), str(batch[3].shape)))", "\n", "#for i in range(idx.size(0)):", "\n", "#    logger.info('idx: %d, pred: %d, real: %d' % (idx[i].item(), eval_dataset.labels[idx[i].item()], batch[3][i].item()))", "\n", "\n", "", "nb_eval_steps", "+=", "1", "\n", "\n", "if", "args", ".", "do_generate", ":", "\n", "                ", "q_ids", "=", "batch", "[", "6", "]", ".", "squeeze", "(", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "q_ids", ")", ":", "\n", "                    ", "topk_values", ",", "topk_indices", "=", "torch", ".", "topk", "(", "logits", "[", "i", "]", ",", "k", "=", "10", ",", "dim", "=", "0", ")", "\n", "stage1_dict", "[", "int", "(", "qid", ")", "]", "=", "(", "topk_indices", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "int16", ")", ",", "\n", "topk_values", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "float16", ")", ")", "\n", "\n", "\n", "", "", "", "acc", "=", "float", "(", "correct_num", ")", "/", "len", "(", "eval_dataloader", ".", "dataset", ")", "\n", "\n", "logger", ".", "info", "(", "\"Eval Results:\"", ")", "\n", "logger", ".", "info", "(", "\"Eval Accuracy: %.3f\"", "%", "(", "100", "*", "acc", ")", ")", "\n", "logger", ".", "info", "(", "\"Eval Loss: %.3f\"", "%", "(", "eval_loss", ")", ")", "\n", "\n", "", "if", "args", ".", "do_generate", ":", "\n", "        ", "stage1_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"stage1_eval.pkl\"", ")", "\n", "with", "open", "(", "stage1_file", ",", "\"wb\"", ")", "as", "fp", ":", "\n", "            ", "cPickle", ".", "dump", "(", "stage1_dict", ",", "fp", ")", "\n", "\n", "", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Eva Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "return", "results", ",", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_mlm.test": [[818, 885], ["_pickle.load", "logger.info", "time.time", "dict", "zip", "time.time", "logger.info", "logger.info", "open", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "tqdm.tqdm", "os.path.join", "open", "json.dump", "len", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "model.eval", "tuple", "open", "_pickle.dump", "len", "os.path.exists", "torch.no_grad", "torch.no_grad", "model", "logits.max", "range", "batch[].squeeze().detach().cpu().numpy", "zip", "t.to", "idx.size", "str", "results.append", "torch.topk", "torch.topk", "[].item", "batch[].squeeze().detach().cpu", "topk_indices.detach().cpu().numpy().astype", "topk_values.detach().cpu().numpy().astype", "int", "batch[].squeeze().detach", "topk_indices.detach().cpu().numpy", "topk_values.detach().cpu().numpy", "idx[].item", "batch[].squeeze", "topk_indices.detach().cpu", "topk_values.detach().cpu", "topk_indices.detach", "topk_values.detach"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "test", "(", "args", ",", "model", ",", "eval_dataset", "=", "None", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "'-MM'", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "label2ans", "=", "cPickle", ".", "load", "(", "open", "(", "args", ".", "label2ans_file", ",", "'rb'", ")", ")", "\n", "logger", ".", "info", "(", "'label2ans: %d'", "%", "(", "len", "(", "label2ans", ")", ")", ")", "\n", "\n", "results", "=", "[", "]", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "stage1_dict", "=", "dict", "(", ")", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval", "\n", "logger", ".", "info", "(", "\"***** Running Test {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ")", ":", "\n", "#for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "None", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", ",", "\n", "'mask_index'", ":", "batch", "[", "7", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "logits", "=", "outputs", "[", "0", "]", "\n", "\n", "val", ",", "idx", "=", "logits", ".", "max", "(", "1", ")", "\n", "#logger.info('idx: %s, batch[6]: %s' % (str(idx.shape), str(batch[6].shape)))", "\n", "\n", "for", "i", "in", "range", "(", "idx", ".", "size", "(", "0", ")", ")", ":", "\n", "                    ", "result", "=", "{", "}", "\n", "result", "[", "'questionId'", "]", "=", "str", "(", "batch", "[", "6", "]", "[", "i", "]", ".", "item", "(", ")", ")", "\n", "result", "[", "'prediction'", "]", "=", "label2ans", "[", "eval_dataset", ".", "labels", "[", "idx", "[", "i", "]", ".", "item", "(", ")", "]", "]", "\n", "results", ".", "append", "(", "result", ")", "\n", "\n", "", "", "if", "args", ".", "do_generate", ":", "\n", "                ", "q_ids", "=", "batch", "[", "6", "]", ".", "squeeze", "(", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "qid", ",", "log", "in", "zip", "(", "q_ids", ",", "logits", ")", ":", "\n", "                    ", "topk_values", ",", "topk_indices", "=", "torch", ".", "topk", "(", "log", ",", "k", "=", "10", ",", "dim", "=", "0", ")", "\n", "stage1_dict", "[", "int", "(", "qid", ")", "]", "=", "(", "topk_indices", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "int16", ")", ",", "\n", "topk_values", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "float16", ")", ")", "\n", "\n", "", "", "", "", "if", "args", ".", "do_generate", ":", "\n", "        ", "stage1_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"stage1_submission.pkl\"", ")", "\n", "with", "open", "(", "stage1_file", ",", "\"wb\"", ")", "as", "fp", ":", "\n", "            ", "cPickle", ".", "dump", "(", "stage1_dict", ",", "fp", ")", "\n", "\n", "", "", "with", "open", "(", "args", ".", "output_dir", "+", "(", "'/{}_results.json'", ".", "format", "(", "eval_dataset", ".", "name", ")", ")", ",", "'w'", ")", "as", "fp", ":", "\n", "        ", "json", ".", "dump", "(", "results", ",", "fp", ")", "\n", "\n", "\n", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'# questions: %d'", "%", "(", "len", "(", "results", ")", ")", ")", "\n", "logger", ".", "info", "(", "'Test Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_mlm.load_and_cache_examples": [[886, 952], ["processor.get_labels", "time.time", "numpy.load", "oscar.utils.task_utils.convert_examples_to_features_vqa", "time.time", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "processor.get_dev_examples", "processor.get_train_examples", "os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "print", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "bool", "bool", "time.time", "numpy.zeros", "enumerate", "torch.from_numpy", "torch.from_numpy", "time.time", "logger.info", "torch.tensor", "torch.tensor", "run_gqa_prompt_mlm.target_tensor", "len"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.convert_examples_to_features_vqa", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.target_tensor"], ["", "def", "load_and_cache_examples", "(", "args", ",", "task", ",", "tokenizer", ",", "evaluate", "=", "False", ")", ":", "\n", "    ", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "output_mode", "=", "output_modes", "[", "task", "]", "\n", "\n", "label_list", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ")", "if", "evaluate", "else", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ")", "\n", "\n", "#img_features = torch.load(os.path.join(args.data_dir, 'val_img_feats.pt' if evaluate else 'train_img_feats.pt'))", "\n", "#img_features = torch.load(os.path.join(args.data_dir, 'val_img_frcnn_feats.pt' if evaluate else 'train_img_frcnn_feats.pt'))", "\n", "img_features", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'val_img_frcnn_feats.npy'", "if", "evaluate", "else", "'train_img_frcnn_feats.npy'", ")", ")", "\n", "\n", "features", "=", "convert_examples_to_features_vqa", "(", "examples", ",", "img_features", ",", "label_list", ",", "args", ".", "max_img_seq_length", ",", "args", ".", "max_seq_length", ",", "\n", "tokenizer", ",", "output_mode", ",", "\n", "cls_token_at_end", "=", "bool", "(", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "\n", "#if args.local_rank in [-1, 0]:", "\n", "#    logger.info(\"Saving features into cached file %s\", cached_features_file)", "\n", "#    torch.save(features, cached_features_file)", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: loading features using %.5f secs'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "# batch*max_seq_len", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "        ", "labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "[", "0", "]", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "targets", "=", "torch", ".", "tensor", "(", "[", "target_tensor", "(", "len", "(", "label_list", ")", ",", "f", ".", "label_id", ",", "f", ".", "score", ")", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "if", "args", ".", "img_feature_dim", ">", "0", ":", "# change here", "\n", "            ", "t_start", "=", "time", ".", "time", "(", ")", "\n", "img_feat_np", "=", "np", ".", "zeros", "(", "(", "labels", ".", "shape", "[", "0", "]", ",", "args", ".", "max_img_seq_length", ",", "args", ".", "img_feature_dim", ")", ")", "\n", "for", "f_id", ",", "f", "in", "enumerate", "(", "features", ")", ":", "\n", "                ", "img_feat_np", "[", "f_id", "]", "=", "f", ".", "img_feat", "\n", "\n", "", "img_feats", "=", "torch", ".", "from_numpy", "(", "img_feat_np", ")", "\n", "\n", "#img_feats = torch.empty((labels.shape[0], args.max_img_seq_length, args.img_feature_dim))", "\n", "#for f_id, f in enumerate(features):", "\n", "#   img_feats[f_id] = f.img_feat", "\n", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: convert image tensor features using %.5f secs'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "#img_feats = torch.stack([f.img_feat[:,-args.img_feature_dim:] for f in features])", "\n", "#img_feats = torch.stack([f.img_feat for f in features])", "\n", "#img_feats = img_feats.type(torch.long)", "\n", "\n", "#print('targets:', targets.shape)", "\n", "", "print", "(", "'img_feats:'", ",", "img_feats", ".", "shape", ")", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "        ", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "if", "args", ".", "img_feature_dim", "==", "-", "1", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "labels", ",", "targets", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "labels", ",", "targets", ",", "img_feats", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_mlm.target_tensor": [[953, 960], ["enumerate"], "function", ["None"], ["", "def", "target_tensor", "(", "len", ",", "labels", ",", "scores", ")", ":", "\n", "    ", "\"\"\" create the target by labels and scores \"\"\"", "\n", "target", "=", "[", "0", "]", "*", "len", "\n", "for", "id", ",", "l", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "target", "[", "l", "]", "=", "scores", "[", "id", "]", "\n", "\n", "", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_mlm.main": [[964, 1266], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "oscar.utils.misc.set_seed", "parser.parse_args.task_name.lower", "processor.get_labels", "len", "logger.info", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "run_gqa_prompt_mlm._load_img_features", "run_gqa_prompt_mlm.GQADataset", "logger.info", "os.path.join", "logger.info", "os.path.exists", "os.listdir", "logger.info", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.set_device", "torch.cuda.set_device", "torch.device", "torch.device", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "bool", "ValueError", "torch.distributed.barrier", "torch.distributed.barrier", "logger.info", "time.time", "torch.load", "torch.load", "time.time", "logger.info", "logger.info", "torch.distributed.barrier", "torch.distributed.barrier", "print", "run_gqa_prompt_mlm.evaluate", "exit", "run_gqa_prompt_mlm.GQADataset", "run_gqa_prompt_mlm.GQADataset", "run_gqa_prompt_mlm.GQADataset", "run_gqa_prompt_mlm.train", "logger.info", "run_gqa_prompt_mlm.GQADataset", "run_gqa_prompt_mlm.train", "logger.info", "logger.info", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "torch.save", "logger.info", "logger.info", "logger.info", "os.getenv", "os.path.join", "bool", "model_class.from_pretrained.init_code_embedding", "os.makedirs", "os.path.join", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_gqa_prompt_mlm.evaluate", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_gqa_prompt_mlm.evaluate", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_gqa_prompt_mlm.test", "train_code[].t", "model_class.from_pretrained.init_code_embedding", "torch.distributed.get_rank", "torch.distributed.get_rank", "os.path.exists", "MODEL_CLASSES.keys", "oscar.utils.task_utils.processors.keys", "torch.cuda.is_available", "torch.cuda.is_available", "train_code[].t", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "os.path.dirname", "logging.getLogger", "sorted", "sorted", "sorted", "glob.glob", "glob.glob", "glob.glob", "list", "train_code[].keys", "list", "train_code[].keys"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few._load_img_features", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.ImageBertForSequenceClassification.init_code_embedding", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.test", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.ImageBertForSequenceClassification.init_code_embedding", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the .tsv files (or other data files) for the task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--task_name\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train selected in the list: \"", "+", "\", \"", ".", "join", "(", "processors", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--label_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Label Dictionary\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--label2ans_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Label to Answer Dictionary\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--data_label_type\"", ",", "default", "=", "'bal'", ",", "type", "=", "str", ",", "help", "=", "\"bal or all\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_data_type\"", ",", "default", "=", "'bal'", ",", "type", "=", "str", ",", "help", "=", "\"bal or all\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_data_type\"", ",", "default", "=", "'bal'", ",", "type", "=", "str", ",", "help", "=", "\"bal or all\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--loss_type\"", ",", "default", "=", "'kl'", ",", "type", "=", "str", ",", "help", "=", "\"kl or xe\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--spatial_dim\"", ",", "default", "=", "6", ",", "type", "=", "int", ",", "help", "=", "\"spatial_dim\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_label_pos_length\"", ",", "default", "=", "45", ",", "type", "=", "int", ",", "help", "=", "\"The maximum total input label position sequence length.\"", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer than this will be truncated, sequences shorter will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_val\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train_val\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run test on the test set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test_dev\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run test on the test-dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_generate\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run test on the test-dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Rul evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--drop_out\"", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "\"Drop out for BERT.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--classifier\"", ",", "default", "=", "'linear'", ",", "type", "=", "str", ",", "help", "=", "\"linear or mlp\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cls_hidden_scale\"", ",", "default", "=", "2", ",", "type", "=", "int", ",", "help", "=", "\"cls_hidden_scale: for classifier\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_img_seq_length\"", ",", "default", "=", "30", ",", "type", "=", "int", ",", "help", "=", "\"The maximum total input image sequence length.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_dim\"", ",", "default", "=", "2054", ",", "type", "=", "int", ",", "help", "=", "\"The Image Feature Dimension.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_type\"", ",", "default", "=", "'faster_r-cnn'", ",", "type", "=", "str", ",", "help", "=", "\"faster_r-cnn or mask_r-cnn\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_voc\"", ",", "default", "=", "512", ",", "type", "=", "int", ",", "help", "=", "\"dis_code_voc: 256, 512\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_level\"", ",", "default", "=", "'top'", ",", "type", "=", "str", ",", "help", "=", "\"code level: top, botttom, both\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_epoch'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "\"Save checkpoint every X epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_output_dir'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_cache'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_ip'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_port'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--philly\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use Philly: reset the output dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--load_fast\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Load Tensor Fast\"", ")", "\n", "parser", ".", "add_argument", "(", "'-j'", ",", "'--workers'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "help", "=", "'number of data loading workers (default: 4)'", ")", "\n", "\n", "#args = '--data_dir ../vqa/ban-vqa/data/qal_pairs --model_type bert --model_name_or_path bert-base-uncased --task_name vqa_text ' \\", "\n", "#       '--do_train --do_eval --do_lower_case --max_seq_length 40 --per_gpu_eval_batch_size 16 --per_gpu_train_batch_size 16 --learning_rate 2e-5 ' \\", "\n", "#       '--num_train_epochs 20.0 --output_dir ./results/vqa_text --label_file ../vqa/ban-vqa/data/cache/trainval_ans2label.pkl ' \\", "\n", "#       '--save_steps 5000 --overwrite_output_dir --max_img_seq_length 1 --img_feature_dim 565 --img_feature_type dis_code '", "\n", "\n", "#args = '--data_dir ../vqa/ban-vqa/data/qal_pairs --model_type bert --model_name_or_path bert-base-uncased --task_name vqa_text ' \\", "\n", "#       '--do_train --do_eval --do_lower_case --max_seq_length 40 --per_gpu_eval_batch_size 16 --per_gpu_train_batch_size 16 --learning_rate 2e-5 ' \\", "\n", "#       '--num_train_epochs 20.0 --output_dir ./results/vqa_text --label_file ../vqa/ban-vqa/data/cache/trainval_ans2label.pkl ' \\", "\n", "#       '--save_steps 5000 --overwrite_output_dir --max_img_seq_length 10 --img_feature_dim 565 --img_feature_type other '", "\n", "\n", "#args = parser.parse_args(args.split())", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "philly", ":", "# use philly", "\n", "        ", "logger", ".", "info", "(", "'Info: Use Philly, all the output folders are reset.'", ")", "\n", "args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "getenv", "(", "'PT_OUTPUT_DIR'", ")", ",", "args", ".", "output_dir", ")", "\n", "logger", ".", "info", "(", "'OUTPUT_DIR:'", ",", "args", ".", "output_dir", ")", "\n", "\n", "#if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train and not args.overwrite_output_dir:", "\n", "#    raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args.output_dir))", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", ":", "\n", "        ", "logger", ".", "info", "(", "\"Output Directory Exists.\"", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s - %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ".", "seed", ",", "args", ".", "n_gpu", ")", "\n", "\n", "# Prepare GLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "args", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "\n", "label_list", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "logger", ".", "info", "(", "'Task Name: {}, #Labels: {}'", ".", "format", "(", "args", ".", "task_name", ",", "num_labels", ")", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "\n", "# discrete code", "\n", "config", ".", "img_feature_dim", "=", "args", ".", "img_feature_dim", "# 2054", "\n", "config", ".", "img_feature_type", "=", "args", ".", "img_feature_type", "# faster_r-cnn", "\n", "config", ".", "code_voc", "=", "args", ".", "code_voc", "# 512", "\n", "config", ".", "hidden_dropout_prob", "=", "args", ".", "drop_out", "# 0.3", "\n", "config", ".", "loss_type", "=", "args", ".", "loss_type", "# xe", "\n", "config", ".", "classifier", "=", "args", ".", "classifier", "# linear", "\n", "config", ".", "cls_hidden_scale", "=", "args", ".", "cls_hidden_scale", "# 2", "\n", "config", ".", "spatial_dim", "=", "args", ".", "spatial_dim", "# 6", "\n", "\n", "# load discrete code", "\n", "if", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "'Load discrete code from: {}'", ".", "format", "(", "args", ".", "data_dir", ")", ")", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "train_code", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'vqvae'", ",", "'train.pt'", ")", ")", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Load time: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "if", "args", ".", "code_level", "==", "'top'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_t'", "]", ".", "shape", "[", "0", "]", "\n", "config", ".", "code_size", "=", "train_code", "[", "'feats_top'", "]", "[", "list", "(", "train_code", "[", "'feats_top'", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "shape", "[", "0", "]", "\n", "", "elif", "args", ".", "code_level", "==", "'bottom'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_b'", "]", ".", "shape", "[", "0", "]", "\n", "config", ".", "code_size", "=", "train_code", "[", "'feats_bottom'", "]", "[", "list", "(", "train_code", "[", "'feats_bottom'", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "shape", "[", "0", "]", "\n", "", "elif", "args", ".", "code_level", "==", "'both'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_t'", "]", ".", "shape", "[", "0", "]", "+", "train_code", "[", "'embeddings_b'", "]", ".", "shape", "[", "0", "]", "\n", "\n", "", "", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "from_tf", "=", "bool", "(", "'.ckpt'", "in", "args", ".", "model_name_or_path", ")", ",", "config", "=", "config", ")", "\n", "if", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "'Initializing the code embedding with {}'", ".", "format", "(", "args", ".", "code_level", ")", ")", "\n", "if", "args", ".", "code_level", "==", "'top'", ":", "\n", "            ", "model", ".", "init_code_embedding", "(", "train_code", "[", "'embeddings_t'", "]", ".", "t", "(", ")", ")", "\n", "", "elif", "args", ".", "code_level", "==", "'bottom'", ":", "\n", "            ", "model", ".", "init_code_embedding", "(", "train_code", "[", "'embeddings_b'", "]", ".", "t", "(", ")", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# load image features", "\n", "img_features", "=", "_load_img_features", "(", "args", ")", "\n", "label_pos_feats", "=", "None", "\n", "\n", "#if args.do_eval:", "\n", "eval_dataset", "=", "GQADataset", "(", "args", ",", "'val'", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", ")", "\n", "#eval_dataset = GQADataset(args, 'test-dev', img_features, tokenizer) # test-dev as val", "\n", "if", "args", ".", "do_val", ":", "\n", "        ", "print", "(", "\"Do validation.\"", ")", "\n", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ")", "\n", "exit", "(", "0", ")", "\n", "\n", "", "if", "args", ".", "do_test", ":", "\n", "        ", "test_dataset", "=", "GQADataset", "(", "args", ",", "'test'", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", ")", "\n", "\n", "", "if", "args", ".", "do_test_dev", ":", "\n", "        ", "test_dev_dataset", "=", "GQADataset", "(", "args", ",", "'test-dev'", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", ")", "\n", "\n", "# Training", "\n", "", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "GQADataset", "(", "args", ",", "'train'", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Training on train+val", "\n", "", "if", "args", ".", "do_train_val", ":", "# depreciated", "\n", "        ", "train_dataset", "=", "GQADataset", "(", "args", ",", "'train+val'", ",", "img_features", ",", "tokenizer", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`. They can then be reloaded using `from_pretrained()`", "\n", "#model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training", "\n", "#model_to_save.save_pretrained(args.output_dir)", "\n", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "#model = model_class.from_pretrained(args.output_dir)", "\n", "#tokenizer = tokenizer_class.from_pretrained(args.output_dir)", "\n", "#model.to(args.device)", "\n", "\n", "\n", "# Evaluation", "\n", "#results = {}", "\n", "", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ",", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "score", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "#result = dict((k + '_{}'.format(global_step), v) for k, v in result.items())", "\n", "#results.update(result)", "\n", "\n", "# Test-Dev", "\n", "", "", "if", "args", ".", "do_test_dev", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ",", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "score", "=", "evaluate", "(", "args", ",", "model", ",", "test_dev_dataset", ",", "prefix", "=", "global_step", ")", "\n", "#test(args, model, test_dev_dataset, prefix=global_step)", "\n", "\n", "# Test-Submission", "\n", "", "", "if", "args", ".", "do_test", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "# global_step = checkpoint.split('-')[-1] if len(checkpoints) > 1 else \"\"", "\n", "            ", "global_step", "=", "\"submission\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "test", "(", "args", ",", "model", ",", "test_dataset", ",", "prefix", "=", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_itm.ImageBertForSequenceClassificationPrompt.__init__": [[39, 73], ["oscar.modeling.modeling_bert.ImageBertForSequenceClassification.__init__", "transformers.pytorch_transformers.modeling_bert.BertPooler", "hasattr", "run_gqa_prompt_itm.ImageBertForSequenceClassificationPrompt.apply", "run_gqa_prompt_itm.ImageBertForSequenceClassificationPrompt.parameters", "transformers.pytorch_transformers.modeling_bert.BertPooler", "transformers.pytorch_transformers.modeling_bert.BertPooler", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "hasattr", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "ImageBertForSequenceClassificationPrompt", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "mask_pooler", "=", "BertPooler", "(", "config", ")", "\n", "\n", "if", "hasattr", "(", "config", ",", "'classifier'", ")", ":", "\n", "            ", "if", "not", "hasattr", "(", "config", ",", "'cls_hidden_scale'", ")", ":", "\n", "                ", "config", ".", "cls_hidden_scale", "=", "2", "\n", "\n", "", "if", "config", ".", "classifier", "==", "'linear'", ":", "\n", "                ", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "\n", "self", ".", "config", ".", "num_labels", ")", "\n", "", "elif", "config", ".", "classifier", "==", "'mlp'", ":", "\n", "                ", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", "*", "config", ".", "cls_hidden_scale", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "config", ".", "cls_hidden_scale", ",", "self", ".", "config", ".", "num_labels", ")", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "self", ".", "config", ".", "num_labels", ")", "# original", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "matching_cls_pooler", "=", "BertPooler", "(", "config", ")", "\n", "self", ".", "matching_msk_pooler", "=", "BertPooler", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "self", ".", "matcher", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_itm.ImageBertForSequenceClassificationPrompt.forward": [[74, 106], ["run_gqa_prompt_itm.ImageBertForSequenceClassificationPrompt.matching_msk_pooler", "run_gqa_prompt_itm.ImageBertForSequenceClassificationPrompt.matching_cls_pooler", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "run_gqa_prompt_itm.ImageBertForSequenceClassificationPrompt.dropout", "run_gqa_prompt_itm.ImageBertForSequenceClassificationPrompt.matcher", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "run_gqa_prompt_itm.ImageBertForSequenceClassificationPrompt.bert", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "run_gqa_prompt_itm.ImageBertForSequenceClassificationPrompt.view", "mask_index.unsqueeze().expand", "labels.view", "predict_labels.view", "mask_index.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "img_feats", "=", "None", ",", "mask_index", "=", "None", ",", "predict_labels", "=", "None", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# (batch_size, sequence_length, hidden_dim), (batch_size, hidden_dim), ...", "\n", "            ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ",", "img_feats", "=", "img_feats", ")", "\n", "\n", "# (batch_size, hidden_dim)", "\n", "# pooled_output = outputs[1]", "\n", "seq_length", ",", "hidden_dim", "=", "outputs", "[", "0", "]", ".", "shape", "[", "1", ":", "]", "\n", "pooled_output", "=", "torch", ".", "gather", "(", "\n", "input", "=", "outputs", "[", "0", "]", ",", "\n", "dim", "=", "1", ",", "\n", "index", "=", "mask_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "(", "-", "1", ",", "-", "1", ",", "hidden_dim", ")", ")", "\n", ")", "# [batch_size, 1, hidden_dim]", "\n", "\n", "", "pooled_output", "=", "self", ".", "matching_msk_pooler", "(", "pooled_output", ")", "\n", "pooled_output_cls", "=", "self", ".", "matching_cls_pooler", "(", "outputs", "[", "0", "]", ")", "\n", "\n", "pooled_output", "=", "torch", ".", "cat", "(", "[", "pooled_output", ",", "pooled_output_cls", "]", ",", "dim", "=", "-", "1", ")", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "matcher", "(", "pooled_output", ")", "# [B, 1]", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# loss_fct = CrossEntropyLoss()", "\n", "# loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))", "\n", "            ", "target", "=", "(", "labels", ".", "view", "(", "-", "1", ")", "==", "predict_labels", ".", "view", "(", "-", "1", ")", ")", ".", "float", "(", ")", "\n", "loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "target", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_itm.GQADataset.__init__": [[182, 213], ["torch.utils.data.Dataset.__init__", "run_gqa_prompt_itm._load_dataset", "_pickle.load", "dict", "logger.info", "open", "run_gqa_prompt_itm.GQADataset.tensorize", "enumerate", "run_gqa_prompt_itm.GQADataset.label_map.items", "bool", "bool", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few._load_dataset", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize"], ["def", "__init__", "(", "self", ",", "args", ",", "name", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", "=", "None", ")", ":", "\n", "        ", "super", "(", "GQADataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "name", "in", "[", "'train'", ",", "'val'", ",", "'test-dev'", ",", "'test'", ",", "'train+val'", "]", "\n", "\n", "self", ".", "img_features", "=", "img_features", "\n", "self", ".", "label_pos_feats", "=", "label_pos_feats", "# None", "\n", "self", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "# classification", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "name", "=", "name", "\n", "\n", "self", ".", "examples", ",", "self", ".", "labels", "=", "_load_dataset", "(", "args", ",", "name", ")", "\n", "self", ".", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "self", ".", "labels", ")", "}", "\n", "\n", "# Record the topk results of MLM task", "\n", "self", ".", "idx2label", "=", "{", "k", ":", "v", "for", "v", ",", "k", "in", "self", ".", "label_map", ".", "items", "(", ")", "}", "# classification idx -> label idx", "\n", "self", ".", "label2ans", "=", "cPickle", ".", "load", "(", "open", "(", "args", ".", "label2ans_file", ",", "\"rb\"", ")", ")", "# label idx -> answer", "\n", "self", ".", "stage1_dict", "=", "dict", "(", ")", "# q_id -> (topk_logits, topk_scores)", "\n", "\n", "# False", "\n", "if", "self", ".", "args", ".", "load_fast", ":", "\n", "            ", "self", ".", "features", "=", "self", ".", "tensorize", "(", "args", ",", "cls_token_at_end", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "self", ".", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "\n", "", "logger", ".", "info", "(", "'%s Data Examples: %d'", "%", "(", "name", ",", "len", "(", "self", ".", "examples", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_itm.GQADataset.tensorize": [[214, 320], ["enumerate", "run_gqa_prompt_itm.GQADataset.tokenizer.tokenize", "run_gqa_prompt_itm.GQADataset.tokenizer.convert_tokens_to_ids", "run_gqa_prompt_itm.target_tensor", "features.append", "len", "logger.info", "run_gqa_prompt_itm.GQADataset.tokenizer.tokenize", "oscar.utils.task_utils._truncate_seq_pair", "len", "len", "len", "len", "len", "len", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "len", "len", "float", "KeyError", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.target_tensor", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv._truncate_seq_pair"], ["", "def", "tensorize", "(", "self", ",", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "\n", "# debug:", "\n", "        ", "debug_size", "=", "500", "\n", "features", "=", "[", "]", "\n", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "self", ".", "examples", "[", "0", ":", "]", ")", ":", "\n", "            ", "if", "len", "(", "example", ".", "label", ")", "==", "0", ":", "continue", "\n", "if", "ex_index", "%", "10000", "==", "0", ":", "logger", ".", "info", "(", "\"Tensorizing example %d of %d\"", "%", "(", "ex_index", ",", "len", "(", "self", ".", "examples", ")", ")", ")", "\n", "\n", "tokens_a", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "                ", "tokens_b", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_b", ")", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "self", ".", "args", ".", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "                ", "if", "len", "(", "tokens_a", ")", ">", "self", ".", "args", ".", "max_seq_length", "-", "2", ":", "\n", "                    ", "tokens_a", "=", "tokens_a", "[", ":", "(", "self", ".", "args", ".", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "", "tokens", "=", "tokens_a", "+", "[", "sep_token", "]", "\n", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "                ", "tokens", "+=", "tokens_b", "+", "[", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "if", "cls_token_at_end", ":", "\n", "                ", "tokens", "=", "tokens", "+", "[", "cls_token", "]", "\n", "segment_ids", "=", "segment_ids", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "                ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "self", ".", "args", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "                ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "", "else", ":", "\n", "                ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "segment_ids", "=", "segment_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "\n", "# image features", "\n", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "# torch", "\n", "#img_feat = self.img_features.item().get(example.img_key)  # numpy", "\n", "if", "img_feat", ".", "shape", "[", "0", "]", ">", "self", ".", "args", ".", "max_img_seq_length", ":", "\n", "                ", "img_feat", "=", "img_feat", "[", "0", ":", "self", ".", "args", ".", "max_img_seq_length", ",", "]", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids += [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids = segment_ids + [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "self", ".", "args", ".", "max_img_seq_length", "-", "img_feat", ".", "shape", "[", "0", "]", ",", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_matrix", ".", "shape", "[", "0", "]", ")", "\n", "# segment_ids = segment_ids + [pad_token_segment_id] * padding_matrix.shape[0]", "\n", "\n", "", "", "if", "self", ".", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "                ", "label_id", "=", "[", "self", ".", "label_map", "[", "l", "]", "for", "l", "in", "example", ".", "label", "]", "\n", "score", "=", "example", ".", "score", "\n", "", "elif", "self", ".", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "                ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "else", ":", "\n", "                ", "raise", "KeyError", "(", "self", ".", "args", ".", "output_mode", ")", "\n", "\n", "", "if", "ex_index", "<", "5", ":", "\n", "                ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"segment_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label: %s (id = %s)\"", "%", "(", "example", ".", "label", ",", "label_id", ")", ")", "\n", "logger", ".", "info", "(", "\"score: %s (score = %s)\"", "%", "(", "example", ".", "score", ",", "score", ")", ")", "\n", "\n", "", "new_scores", "=", "target_tensor", "(", "len", "(", "self", ".", "labels", ")", ",", "label_id", ",", "score", ")", "\n", "#features.append(InputFeat(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label_id, score=score, img_feat=img_feat))", "\n", "features", ".", "append", "(", "(", "torch", ".", "tensor", "(", "input_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "label_id", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "new_scores", ",", "dtype", "=", "torch", ".", "float", ")", ",", "img_feat", ")", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_itm.GQADataset.generate_sample": [[321, 344], ["copy.copy", "copy.copy", "copy.copy", "run_gqa_prompt_itm.GQADataset.tokenizer.convert_tokens_to_ids", "len", "run_gqa_prompt_itm.GQADataset.tokenizer.tokenize", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.copy", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.copy", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.copy"], ["", "def", "generate_sample", "(", "self", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_idx", ",", "mask_index", ")", ":", "\n", "        ", "template", "=", "copy", ".", "copy", "(", "input_ids", ")", "\n", "template_mask", "=", "copy", ".", "copy", "(", "input_mask", ")", "\n", "template_segment", "=", "copy", ".", "copy", "(", "segment_ids", ")", "\n", "\n", "# Transform to answer string", "\n", "template_label", "=", "self", ".", "idx2label", "[", "label_idx", "]", "\n", "template_answer", "=", "self", ".", "label2ans", "[", "template_label", "]", "\n", "tokens_ans", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "template_answer", ")", ")", "\n", "ans_length", "=", "len", "(", "tokens_ans", ")", "\n", "#", "\n", "template", "=", "(", "template", "[", ":", "mask_index", "]", "+", "tokens_ans", "+", "template", "[", "mask_index", "+", "1", ":", "]", ")", "[", ":", "len", "(", "input_ids", ")", "]", "\n", "template_mask", "=", "template_mask", "[", ":", "mask_index", "]", "+", "[", "1", "]", "*", "ans_length", "+", "template_mask", "[", "mask_index", "+", "1", ":", "len", "(", "\n", "input_mask", ")", "-", "ans_length", "+", "1", "]", "+", "template_mask", "[", "len", "(", "input_mask", ")", ":", "]", "\n", "template_segment", "=", "(", "template_segment", "[", ":", "mask_index", "]", "+", "[", "\n", "template_segment", "[", "mask_index", "]", "]", "*", "ans_length", "+", "template_segment", "[", "mask_index", "+", "1", ":", "]", ")", "[", ":", "len", "(", "segment_ids", ")", "]", "\n", "\n", "assert", "len", "(", "template", ")", "==", "len", "(", "input_ids", ")", "\n", "assert", "len", "(", "template_mask", ")", "==", "len", "(", "input_mask", ")", "\n", "assert", "len", "(", "template_segment", ")", "==", "len", "(", "segment_ids", ")", "\n", "\n", "return", "template", ",", "template_mask", ",", "template_segment", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_itm.GQADataset.tensorize_example": [[345, 521], ["run_gqa_prompt_itm.GQADataset.tokenizer.tokenize", "run_gqa_prompt_itm.GQADataset.tokenizer.tokenize", "run_gqa_prompt_itm.GQADataset.tokenizer.convert_tokens_to_ids", "run_gqa_prompt_itm.GQADataset.args.img_feature_type.startswith", "example.text_b.split", "enumerate", "example.text_b.replace().strip", "run_gqa_prompt_itm.GQADataset.tokenizer.tokenize", "oscar.utils.task_utils._truncate_seq_pair", "len", "ValueError", "tokens.index", "print", "len", "len", "ValueError", "len", "len", "len", "img_feat.type.type.type", "run_gqa_prompt_itm.GQADataset.generate_sample", "templates.append", "templates_mask.append", "templates_segment.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "run_gqa_prompt_itm.GQADataset.tokenizer.tokenize", "txt_label_ixs.extend", "len", "len", "len", "img_feat.type.type.reshape", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KeyError", "img_feat.type.type.type", "int", "len", "zip", "example.text_b.replace", "len", "len", "len", "len", "float", "random.random", "random.randint", "numpy.random.choice", "int", "run_gqa_prompt_itm.GQADataset.generate_sample", "templates.append", "templates_mask.append", "templates_segment.append", "len", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv._truncate_seq_pair", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.VQADataset.generate_sample", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.VQADataset.generate_sample"], ["", "def", "tensorize_example", "(", "self", ",", "example", ",", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "        ", "tokens_a", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "tokens_c", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "\"Answer: \"", "+", "example", ".", "text_c", ")", "\n", "tokens_a", "=", "tokens_a", "+", "tokens_c", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "            ", "txt_b_arr", "=", "example", ".", "text_b", ".", "split", "(", "';'", ")", "\n", "txt_label_ixs", "=", "[", "]", "\n", "for", "txt_b_ix", ",", "txt_b_ele", "in", "enumerate", "(", "txt_b_arr", ")", ":", "\n", "                ", "tokens_b_ele", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "txt_b_ele", ")", "\n", "txt_label_ixs", ".", "extend", "(", "[", "txt_b_ix", "]", "*", "len", "(", "tokens_b_ele", ")", ")", "\n", "", "txt_b", "=", "example", ".", "text_b", ".", "replace", "(", "';'", ",", "' '", ")", ".", "strip", "(", ")", "\n", "tokens_b", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "txt_b", ")", "\n", "assert", "len", "(", "tokens_b", ")", "==", "len", "(", "txt_label_ixs", ")", "\n", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "self", ".", "args", ".", "max_seq_length", "-", "3", ")", "\n", "txt_label_ixs", "=", "txt_label_ixs", "[", "0", ":", "len", "(", "tokens_b", ")", "]", "\n", "\n", "# original", "\n", "#if example.text_b:", "\n", "#    txt_b = example.text_b.replace(';', ' ').strip()", "\n", "#    tokens_b = self.tokenizer.tokenize(txt_b)", "\n", "#    _truncate_seq_pair(tokens_a, tokens_b, self.args.max_seq_length - 3)", "\n", "", "else", ":", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "            ", "if", "len", "(", "tokens_a", ")", ">", "self", ".", "args", ".", "max_seq_length", "-", "2", ":", "\n", "                ", "tokens_a", "=", "tokens_a", "[", ":", "(", "self", ".", "args", ".", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "# question + [SEP]", "\n", "", "", "tokens", "=", "tokens_a", "+", "[", "sep_token", "]", "\n", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "# question + [SEP] + tags + [SEP]", "\n", "            ", "tokens", "+=", "tokens_b", "+", "[", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "# False", "\n", "", "if", "cls_token_at_end", ":", "\n", "            ", "raise", "ValueError", "(", "\"No CLS at end.\"", ")", "\n", "tokens", "=", "tokens", "+", "[", "cls_token", "]", "\n", "segment_ids", "=", "segment_ids", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "# [CLS] + question + [SEP] + tags + [SEP]", "\n", "            ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "if", "\"[MASK]\"", "in", "tokens", ":", "\n", "            ", "mask_index", "=", "tokens", ".", "index", "(", "\"[MASK]\"", ")", "\n", "", "else", ":", "\n", "            ", "mask_index", "=", "0", "\n", "print", "(", "\"qid {} has no [MASK]\"", ".", "format", "(", "example", ".", "q_id", ")", ")", "\n", "", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "self", ".", "args", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "# False", "\n", "if", "pad_on_left", ":", "\n", "            ", "raise", "ValueError", "(", "\"No pad on left.\"", ")", "\n", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "", "else", ":", "\n", "# [..., 0, 0, 0, ...]", "\n", "            ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "# [1, 1, ..., 0, 0, 0, ...]", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "# [1, 0, 0, ..., 1, 1, ..., 0, 0, 0, ...]", "\n", "segment_ids", "=", "segment_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "\n", "# image features", "\n", "if", "self", ".", "args", ".", "img_feature_type", ".", "startswith", "(", "'dis_code'", ")", ":", "\n", "            ", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "\n", "\n", "if", "self", ".", "args", ".", "img_feature_type", "==", "'dis_code_ln'", ":", "# for discrete code image representation", "\n", "                ", "img_feat", "=", "img_feat", ".", "reshape", "(", "-", "1", ",", "img_feat", ".", "shape", "[", "0", "]", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "img_feature_type", "==", "'dis_code_t'", ":", "# transposed", "\n", "                ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "64", "\n", "", "else", ":", "\n", "                ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "", "", "else", ":", "\n", "            ", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "#[:, 0:self.args.img_feature_dim]  # torch", "\n", "\n", "if", "img_feat", ".", "shape", "[", "0", "]", ">", "self", ".", "args", ".", "max_img_seq_length", ":", "\n", "                ", "img_feat", "=", "img_feat", "[", "0", ":", "self", ".", "args", ".", "max_img_seq_length", ",", "]", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids += [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids = segment_ids + [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "self", ".", "args", ".", "max_img_seq_length", "-", "img_feat", ".", "shape", "[", "0", "]", ",", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_matrix", ".", "shape", "[", "0", "]", ")", "\n", "# segment_ids = segment_ids + [pad_token_segment_id] * padding_matrix.shape[0]", "\n", "\n", "", "", "", "if", "self", ".", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "if", "(", "example", ".", "label", "is", "None", ")", ":", "\n", "                ", "label_id", "=", "[", "0", "]", "\n", "score", "=", "[", "0", "]", "\n", "", "elif", "len", "(", "example", ".", "label", ")", "==", "0", ":", "\n", "                ", "label_id", "=", "[", "0", "]", "\n", "score", "=", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "label_id", "=", "[", "self", ".", "label_map", "[", "l", "]", "for", "l", "in", "example", ".", "label", "]", "\n", "score", "=", "example", ".", "score", "\n", "", "", "elif", "self", ".", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "if", "len", "(", "example", ".", "label", ")", "==", "0", ":", "\n", "                ", "label_id", "=", "0", "\n", "", "else", ":", "\n", "                ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "self", ".", "args", ".", "output_mode", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "            ", "img_feat", "=", "img_feat", ".", "type", "(", "torch", ".", "long", ")", "\n", "", "elif", "self", ".", "args", ".", "img_feature_type", "in", "[", "'dis_code_ln'", "]", ":", "\n", "#img_feat = img_feat.reshape(-1, img_feat.shape[0])", "\n", "            ", "img_feat", "=", "img_feat", ".", "type", "(", "torch", ".", "float", ")", "\n", "\n", "", "templates", "=", "[", "]", "\n", "templates_mask", "=", "[", "]", "\n", "templates_segment", "=", "[", "]", "\n", "if", "self", ".", "name", "==", "\"train\"", ":", "\n", "            ", "if", "example", ".", "q_id", "not", "in", "self", ".", "stage1_dict", ":", "\n", "                ", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "                    ", "template_idx", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "label_map", ")", "-", "1", ")", "\n", "", "else", ":", "\n", "                    ", "template_idx", "=", "label_id", "[", "0", "]", "\n", "", "", "else", ":", "\n", "                ", "indexes", ",", "scores", "=", "self", ".", "stage1_dict", "[", "example", ".", "q_id", "]", "\n", "template_idx", "=", "int", "(", "np", ".", "random", ".", "choice", "(", "a", "=", "indexes", ")", ")", "\n", "", "sample", "=", "self", ".", "generate_sample", "(", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "template_idx", ",", "mask_index", ")", "\n", "templates", ".", "append", "(", "sample", "[", "0", "]", ")", "\n", "templates_mask", ".", "append", "(", "sample", "[", "1", "]", ")", "\n", "templates_segment", ".", "append", "(", "sample", "[", "2", "]", ")", "\n", "", "else", ":", "\n", "            ", "template_idx", "=", "0", "\n", "if", "len", "(", "self", ".", "stage1_dict", ")", ">", "0", ":", "\n", "                ", "indexes", ",", "scores", "=", "self", ".", "stage1_dict", "[", "example", ".", "q_id", "]", "\n", "for", "ind", ",", "sco", "in", "zip", "(", "indexes", ",", "scores", ")", ":", "\n", "                    ", "ind", "=", "int", "(", "ind", ")", "\n", "sample", "=", "self", ".", "generate_sample", "(", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "ind", ",", "mask_index", ")", "\n", "templates", ".", "append", "(", "sample", "[", "0", "]", ")", "\n", "templates_mask", ".", "append", "(", "sample", "[", "1", "]", ")", "\n", "templates_segment", ".", "append", "(", "sample", "[", "2", "]", ")", "\n", "\n", "", "", "", "return", "(", "torch", ".", "tensor", "(", "input_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 0", "\n", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 1", "\n", "torch", ".", "tensor", "(", "segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 2", "\n", "torch", ".", "tensor", "(", "[", "label_id", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 3", "\n", "torch", ".", "tensor", "(", "[", "label_id", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 4", "\n", "img_feat", ",", "# 5", "\n", "torch", ".", "tensor", "(", "[", "example", ".", "q_id", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 6", "\n", "torch", ".", "tensor", "(", "[", "mask_index", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 7", "\n", "torch", ".", "tensor", "(", "templates", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 8", "\n", "torch", ".", "tensor", "(", "templates_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 9", "\n", "torch", ".", "tensor", "(", "templates_segment", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 10", "\n", "torch", ".", "tensor", "(", "[", "template_idx", "]", ",", "dtype", "=", "torch", ".", "long", ")", "# 11", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_itm.GQADataset.__getitem__": [[523, 536], ["run_gqa_prompt_itm.GQADataset.tensorize_example", "bool", "bool"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize_example"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "load_fast", ":", "\n", "            ", "example", "=", "self", ".", "features", "[", "index", "]", "\n", "", "else", ":", "\n", "            ", "entry", "=", "self", ".", "examples", "[", "index", "]", "\n", "example", "=", "self", ".", "tensorize_example", "(", "entry", ",", "\n", "cls_token_at_end", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "self", ".", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_itm.GQADataset.__len__": [[537, 539], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_itm._load_dataset": [[113, 163], ["processor.get_labels", "processor.get_train_examples", "zip", "processor.get_train_examples", "open", "fp.read().split", "len", "len", "processor.get_dev_examples", "zip", "processor.get_dev_examples", "os.path.join", "open", "fp.read().split", "len", "len", "processor.get_train_examples", "processor.get_train_examples", "zip", "fp.read", "os.path.join", "processor.get_test_examples", "processor.get_test_examples", "open", "fp.read().split", "len", "len", "fp.read", "os.path.join", "processor.get_dev_examples", "processor.get_dev_examples", "fp.read"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples"], ["def", "_load_dataset", "(", "args", ",", "name", ")", ":", "\n", "    ", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "\n", "labels", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "\n", "if", "name", "==", "'train'", ":", "\n", "        ", "if", "args", ".", "train_data_type", "==", "'bal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "'gqa_bal_qla_train.json'", ")", "#[0: debug_size]", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'gqa_bal_qla_train_declarative.json'", ")", ")", "as", "fp", ":", "\n", "                ", "lines", "=", "fp", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "", "assert", "len", "(", "examples", ")", "==", "len", "(", "lines", ")", "\n", "for", "example", ",", "line", "in", "zip", "(", "examples", ",", "lines", ")", ":", "\n", "                ", "example", ".", "text_c", "=", "line", "\n", "", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_train.json'", ")", "#[0: debug_size]", "\n", "", "", "elif", "name", "==", "'val'", ":", "\n", "        ", "if", "args", ".", "eval_data_type", "==", "'bal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "'gqa_bal_qla_val.json'", ")", "#[0: debug_size]", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'gqa_bal_qla_val_declarative.json'", ")", ")", "as", "fp", ":", "\n", "                ", "lines", "=", "fp", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "", "assert", "len", "(", "examples", ")", "==", "len", "(", "lines", ")", "\n", "for", "example", ",", "line", "in", "zip", "(", "examples", ",", "lines", ")", ":", "\n", "                ", "example", ".", "text_c", "=", "line", "\n", "", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_val.json'", ")", "#[0: debug_size]", "\n", "", "", "elif", "name", "==", "'train+val'", ":", "# depreciated", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'mask'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "'train+val2014_qla_mrcnn.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "'train+val2014_qla.json'", ")", "\n", "", "", "elif", "name", "==", "'test'", ":", "# test-submission", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'bal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_submission.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_submission.json'", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_submission_declarative.json'", ")", ")", "as", "fp", ":", "\n", "            ", "lines", "=", "fp", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "", "assert", "len", "(", "examples", ")", "==", "len", "(", "lines", ")", "\n", "for", "example", ",", "line", "in", "zip", "(", "examples", ",", "lines", ")", ":", "\n", "            ", "example", ".", "text_c", "=", "line", "\n", "", "", "elif", "name", "==", "'test-dev'", ":", "# test-dev set", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'bal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "'gqa_bal_qla_testdev.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_testdev.json'", ")", "\n", "\n", "", "", "return", "examples", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_itm._load_img_features": [[164, 178], ["time.time", "torch.load", "torch.load", "torch.load", "time.time", "logger.info", "os.path.join"], "function", ["None"], ["", "def", "_load_img_features", "(", "args", ")", ":", "\n", "    ", "t_start", "=", "time", ".", "time", "(", ")", "\n", "if", "args", ".", "img_feature_type", "==", "'faster_r-cnn'", ":", "\n", "        ", "if", "args", ".", "img_feature_dim", "==", "2048", ":", "# object features", "\n", "            ", "feat_file_name", "=", "'gqa_img_frcnn_feats_obj.pt'", "\n", "", "else", ":", "# object + spatial features", "\n", "            ", "feat_file_name", "=", "'gqa_img_frcnn_feats.pt'", "\n", "", "", "else", ":", "\n", "        ", "feat_file_name", "=", "'gqa_img_frcnn_feats.pt'", "\n", "", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "feat_file_name", ")", ")", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: loading {0:s} features using {1:.2f} secs'", ".", "format", "(", "feat_file_name", ",", "(", "t_end", "-", "t_start", ")", ")", ")", "\n", "\n", "return", "img_features", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_itm.trim_batch": [[540, 560], ["print", "len", "enumerate", "len", "print", "torch.zeros", "torch.zeros", "torch.zeros", "batch_tensors.append", "print", "enumerate", "ele.size", "len", "print", "list", "ele.size"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "", "def", "trim_batch", "(", "batch", ")", ":", "\n", "    ", "\"\"\" new batch func\n    :param batch:\n    :return:\n    \"\"\"", "\n", "print", "(", "'batch size'", ",", "len", "(", "batch", ")", ")", "\n", "\n", "batch_size", "=", "len", "(", "batch", ")", "\n", "batch_tensors", "=", "[", "]", "\n", "for", "ele", "in", "batch", "[", "0", "]", ":", "\n", "        ", "print", "(", "ele", ".", "shape", ",", "ele", ".", "size", "(", ")", ")", "\n", "zero_tensor", "=", "torch", ".", "zeros", "(", "(", "[", "batch_size", "]", "+", "list", "(", "ele", ".", "size", "(", ")", ")", ")", ")", "\n", "batch_tensors", ".", "append", "(", "zero_tensor", ")", "\n", "\n", "", "for", "b_id", ",", "b", "in", "enumerate", "(", "batch", ")", ":", "\n", "        ", "print", "(", "b_id", ",", "len", "(", "b", ")", ")", "\n", "for", "ele_id", ",", "ele", "in", "enumerate", "(", "b", ")", ":", "\n", "            ", "print", "(", "ele_id", ",", "ele", ".", "shape", ")", "\n", "batch_tensors", "[", "ele_id", "]", "[", "b_id", "]", "=", "ele", "\n", "", "", "return", "batch_tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_itm.train": [[561, 767], ["torch.utils.data.DataLoader", "transformers.pytorch_transformers.AdamW", "transformers.pytorch_transformers.WarmupLinearSchedule", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "oscar.utils.misc.set_seed", "os.path.join", "os.path.exists", "print", "dict", "range", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "torch.cuda.amp.GradScaler", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "torch.nn.parallel.DistributedDataParallel.state_dict", "transformers.pytorch_transformers.AdamW.state_dict", "int", "time.time", "enumerate", "time.time", "logger.info", "logger.info", "run_gqa_prompt_itm.evaluate", "log_json.append", "logger.info", "logger.info", "logger.info", "open", "json.dump", "os.path.join", "logger.info", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "loss.mean.item", "loss.mean.item", "copy.deepcopy", "os.path.join", "logger.info", "open", "json.dump", "os.path.exists", "os.makedirs", "hasattr", "len", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "_pickle.load().items", "batch[].squeeze", "batch[].squeeze", "torch.cuda.amp.autocast", "torch.nn.parallel.DistributedDataParallel.", "torch.cuda.amp.GradScaler.scale().backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "transformers.pytorch_transformers.WarmupLinearSchedule.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "os.path.exists", "os.makedirs", "hasattr", "round", "model_to_save.save_pretrained", "torch.save", "torch.save", "torch.save", "tokenizer.save_pretrained", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "t.to", "batch[].squeeze", "loss.mean.mean", "torch.nn.parallel.DistributedDataParallel.parameters", "torch.nn.parallel.DistributedDataParallel.parameters", "torch.cuda.amp.GradScaler.step", "torch.cuda.amp.GradScaler.update", "transformers.pytorch_transformers.AdamW.step", "model_to_save.save_pretrained", "torch.save", "torch.save", "torch.save", "tokenizer.save_pretrained", "len", "os.path.join", "any", "_pickle.load", "torch.cuda.amp.GradScaler.scale", "logger.info", "run_gqa_prompt_itm.evaluate", "logger.info", "os.path.join", "open", "copy.deepcopy"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.SmoothedValue.update", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "args", ".", "train_batch_size", ")", "#, collate_fn=trim_batch)", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "WarmupLinearSchedule", "(", "optimizer", ",", "warmup_steps", "=", "args", ".", "warmup_steps", ",", "t_total", "=", "t_total", ")", "\n", "\n", "# if args.fp16:", "\n", "#     try:", "\n", "#         from apex import amp", "\n", "#     except ImportError:", "\n", "#         raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")", "\n", "#     model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "scaler", "=", "GradScaler", "(", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "#train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0])", "\n", "set_seed", "(", "args", ".", "seed", ",", "args", ".", "n_gpu", ")", "# Added here for reproductibility (even between python 2 and 3)", "\n", "\n", "best_score", "=", "0", "\n", "best_model", "=", "{", "\n", "'epoch'", ":", "0", ",", "\n", "'model_state'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_state'", ":", "optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n", "\n", "# Predict labels from stage1", "\n", "stage1_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"stage1.pkl\"", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "stage1_file", ")", "\n", "print", "(", "\"loading labels from stage1 using top-{}\"", ".", "format", "(", "args", ".", "k", ")", ")", "\n", "train_dataset", ".", "stage1_dict", "=", "dict", "(", "[", "(", "k", ",", "(", "v", "[", "0", "]", "[", ":", "args", ".", "k", "]", ",", "v", "[", "1", "]", "[", ":", "args", ".", "k", "]", ")", ")", "for", "k", ",", "v", "in", "cPickle", ".", "load", "(", "open", "(", "stage1_file", ",", "\"rb\"", ")", ")", ".", "items", "(", ")", "]", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "#for epoch in train_iterator:", "\n", "#epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])", "\n", "        ", "total_loss", "=", "0", "\n", "total_norm", "=", "0", "\n", "count_norm", "=", "0", "\n", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "#for step, batch in enumerate(epoch_iterator):", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "8", "]", ".", "squeeze", "(", "1", ")", ",", "\n", "'attention_mask'", ":", "batch", "[", "9", "]", ".", "squeeze", "(", "1", ")", ",", "\n", "'token_type_ids'", ":", "batch", "[", "10", "]", ".", "squeeze", "(", "1", ")", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "batch", "[", "3", "]", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", ",", "\n", "'mask_index'", ":", "batch", "[", "7", "]", ",", "\n", "'predict_labels'", ":", "batch", "[", "11", "]", "}", "\n", "\n", "with", "autocast", "(", "enabled", "=", "args", ".", "fp16", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "#loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)", "\n", "loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "\n", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                    ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "", "if", "args", ".", "fp16", ":", "\n", "                ", "scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "# with amp.scale_loss(loss, optimizer) as scaled_loss:", "\n", "#     scaled_loss.backward()", "\n", "# torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "total_norm", "+=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "count_norm", "+=", "1", "\n", "\n", "#batch_score = compute_score_with_logits(logits, batch[4]).sum()", "\n", "#train_score += batch_score.item()", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "# scheduler.step()  # Update learning rate schedule", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "scaler", ".", "step", "(", "optimizer", ")", "\n", "scaler", ".", "update", "(", ")", "\n", "", "else", ":", "\n", "                    ", "optimizer", ".", "step", "(", ")", "\n", "", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "# Log metrics", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "logger", ".", "info", "(", "\"Epoch: %d, global_step: %d\"", "%", "(", "epoch", ",", "global_step", ")", ")", "\n", "eval_result", ",", "eval_score", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "                            ", "best_score", "=", "eval_score", "\n", "best_model", "[", "'epoch'", "]", "=", "epoch", "\n", "best_model", "[", "'model'", "]", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "best_score", ")", ")", "\n", "", "logging_loss", "=", "tr_loss", "\n", "\n", "#if args.max_steps > 0 and global_step > args.max_steps:", "\n", "#    epoch_iterator.close()", "\n", "#    break", "\n", "\n", "", "", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Train Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "# evaluation", "\n", "logger", ".", "info", "(", "\"Epoch: %d\"", "%", "(", "epoch", ")", ")", "\n", "eval_result", ",", "eval_score", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "eval_score", "\n", "best_model", "[", "'epoch'", "]", "=", "epoch", "\n", "best_model", "[", "'model'", "]", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "#best_model['optimizer'] = copy.deepcopy(optimizer.state_dict())", "\n", "\n", "# save checkpoints", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_epoch", ">", "0", "and", "epoch", "%", "args", ".", "save_epoch", "==", "0", ":", "# Save model checkpoint", "\n", "            ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-{}'", ".", "format", "(", "epoch", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "model_to_save", "=", "best_model", "[", "'model'", "]", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "best_model", "[", "'model'", "]", "# Take care of distributed/parallel training", "\n", "\n", "save_num", "=", "0", "\n", "while", "(", "save_num", "<", "10", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "break", "\n", "", "except", ":", "\n", "                    ", "save_num", "+=", "1", "\n", "", "", "logger", ".", "info", "(", "\"Saving model checkpoint {0} to {1}\"", ".", "format", "(", "epoch", ",", "output_dir", ")", ")", "\n", "\n", "", "epoch_log", "=", "{", "'epoch'", ":", "epoch", ",", "'eval_score'", ":", "eval_score", ",", "'best_score'", ":", "best_score", "}", "\n", "log_json", ".", "append", "(", "epoch_log", ")", "\n", "\n", "with", "open", "(", "args", ".", "output_dir", "+", "'/eval_logs.json'", ",", "'w'", ")", "as", "fp", ":", "\n", "            ", "json", ".", "dump", "(", "log_json", ",", "fp", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"PROGRESS: {}%\"", ".", "format", "(", "round", "(", "100", "*", "(", "epoch", "+", "1", ")", "/", "args", ".", "num_train_epochs", ",", "4", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "best_score", ")", ")", "\n", "logger", ".", "info", "(", "\"LOSS: {}%\"", ".", "format", "(", "total_loss", "/", "len", "(", "train_dataset", ")", ")", ")", "\n", "\n", "", "with", "open", "(", "args", ".", "output_dir", "+", "'/eval_logs.json'", ",", "'w'", ")", "as", "fp", ":", "\n", "        ", "json", ".", "dump", "(", "log_json", ",", "fp", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "# Save the final model checkpoint", "\n", "        ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'best-{}'", ".", "format", "(", "best_model", "[", "'epoch'", "]", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "model_to_save", "=", "best_model", "[", "'model'", "]", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "best_model", "[", "'model'", "]", "# Take care of distributed/parallel training", "\n", "\n", "save_num", "=", "0", "\n", "while", "(", "save_num", "<", "10", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "break", "\n", "", "except", ":", "\n", "                ", "save_num", "+=", "1", "\n", "", "", "logger", ".", "info", "(", "\"Saving the best model checkpoint epoch {} to {}\"", ".", "format", "(", "best_model", "[", "'epoch'", "]", ",", "output_dir", ")", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_itm.evaluate": [[768, 898], ["time.time", "zip", "time.time", "logger.info", "torch.utils.data.DataLoader", "os.path.join", "os.path.exists", "print", "dict", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "max", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "model.eval", "tuple", "range", "torch.stack", "torch.stack", "torch.stack", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "batch[].squeeze().detach().cpu().numpy", "enumerate", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "cls_logits.softmax.softmax", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "logits.size", "float", "len", "float", "len", "float", "len", "os.path.exists", "torch.from_numpy().to.append", "topk_scores.append", "_pickle.load().items", "t.to", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model", "torch.sigmoid.append", "tmp_eval_loss.mean().item", "torch.sigmoid.sum", "batch[].squeeze().detach().cpu", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "cls_logits.softmax.argmax().unsqueeze", "torch.sigmoid.argmax().unsqueeze", "logits.view().detach", "int", "numpy.stack", "numpy.stack", "_pickle.load", "tmp_eval_loss.mean", "batch[].squeeze().detach", "cls_logits.softmax.argmax", "torch.sigmoid.argmax", "open", "logits.view", "torch.gather.view", "batch[].view", "torch.gather.view", "batch[].view", "torch.gather.view", "batch[].view", "batch[].squeeze"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", "=", "None", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "'-MM'", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "#if args.n_gpu > 1: model = torch.nn.DataParallel(model) # debug: single-gpu or multi-gpus", "\n", "\n", "results", "=", "[", "]", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "num_workers", "=", "args", ".", "workers", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "stage1_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"stage1_eval.pkl\"", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "stage1_file", ")", "\n", "print", "(", "\"loading stage1 file and use top-{}.\"", ".", "format", "(", "args", ".", "k", ")", ")", "\n", "eval_dataset", ".", "stage1_dict", "=", "dict", "(", "[", "(", "k", ",", "(", "v", "[", "0", "]", "[", ":", "args", ".", "k", "]", ",", "v", "[", "1", "]", "[", ":", "args", ".", "k", "]", ")", ")", "for", "k", ",", "v", "in", "cPickle", ".", "load", "(", "open", "(", "stage1_file", ",", "\"rb\"", ")", ")", ".", "items", "(", ")", "]", ")", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "num_data", "=", "0", "\n", "correct_num", "=", "0", "\n", "correct_num_mat", "=", "0", "\n", "correct_num_all", "=", "0", "\n", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "#for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "templates", "=", "batch", "[", "8", "]", "\n", "templates_mask", "=", "batch", "[", "9", "]", "\n", "templates_segment", "=", "batch", "[", "10", "]", "\n", "mat_logits", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "templates", ".", "shape", "[", "1", "]", ")", ":", "\n", "                ", "temp", "=", "templates", "[", ":", ",", "i", "]", "\n", "temp_mask", "=", "templates_mask", "[", ":", ",", "i", "]", "\n", "temp_segment", "=", "templates_segment", "[", ":", ",", "i", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "inputs", "=", "{", "'input_ids'", ":", "temp", ",", "\n", "'attention_mask'", ":", "temp_mask", ",", "\n", "'token_type_ids'", ":", "temp_segment", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "batch", "[", "3", "]", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", ",", "\n", "'mask_index'", ":", "batch", "[", "7", "]", ",", "\n", "'predict_labels'", ":", "batch", "[", "11", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "mat_logits", ".", "append", "(", "logits", ".", "view", "(", "-", "1", ")", ".", "detach", "(", ")", ")", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n", "#logger.info('logits: %s, batch[3]: %s' % (str(logits.shape), str(batch[3].shape)))", "\n", "#logger.info('correct: %s' % (str(logits.argmax(1) == batch[3].view(-1))))", "\n", "\n", "", "", "mat_logits", "=", "torch", ".", "stack", "(", "mat_logits", ",", "dim", "=", "-", "1", ")", "# [B, K]", "\n", "mat_logits", "=", "torch", ".", "sigmoid", "(", "mat_logits", ")", "\n", "mat_logits", "=", "mat_logits", "/", "(", "mat_logits", ".", "sum", "(", "-", "1", ",", "keepdim", "=", "True", ")", "+", "1e-6", ")", "\n", "\n", "q_ids", "=", "batch", "[", "6", "]", ".", "squeeze", "(", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "topk_indexes", ",", "topk_scores", "=", "[", "]", ",", "[", "]", "\n", "for", "_i", ",", "q_id", "in", "enumerate", "(", "q_ids", ")", ":", "\n", "                ", "temp", "=", "eval_dataset", ".", "stage1_dict", "[", "int", "(", "q_id", ")", "]", "\n", "topk_indexes", ".", "append", "(", "temp", "[", "0", "]", ")", "\n", "topk_scores", ".", "append", "(", "temp", "[", "1", "]", ")", "\n", "\n", "", "topk_indexes", "=", "torch", ".", "from_numpy", "(", "np", ".", "stack", "(", "topk_indexes", ",", "axis", "=", "0", ")", ")", ".", "to", "(", "\"cuda\"", ")", "# [B, K]", "\n", "cls_logits", "=", "torch", ".", "from_numpy", "(", "np", ".", "stack", "(", "topk_scores", ",", "axis", "=", "0", ")", ")", ".", "to", "(", "\"cuda\"", ")", "# [B, K], normalized", "\n", "cls_logits", "=", "cls_logits", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "preds_cls", "=", "torch", ".", "gather", "(", "\n", "input", "=", "topk_indexes", ",", "\n", "dim", "=", "1", ",", "\n", "index", "=", "cls_logits", ".", "argmax", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "\n", "correct_num", "+=", "(", "preds_cls", ".", "view", "(", "-", "1", ")", "==", "batch", "[", "3", "]", ".", "view", "(", "-", "1", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "preds_mat", "=", "torch", ".", "gather", "(", "\n", "input", "=", "topk_indexes", ",", "\n", "dim", "=", "1", ",", "\n", "index", "=", "mat_logits", ".", "argmax", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# [B, 1]", "\n", "correct_num_mat", "+=", "(", "preds_mat", ".", "view", "(", "-", "1", ")", "==", "batch", "[", "3", "]", ".", "view", "(", "-", "1", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "preds_all", "=", "torch", ".", "gather", "(", "\n", "input", "=", "topk_indexes", ",", "\n", "dim", "=", "1", ",", "\n", "index", "=", "(", "mat_logits", "+", "cls_logits", ")", ".", "argmax", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "\n", "\n", "correct_num_all", "+=", "(", "preds_all", ".", "view", "(", "-", "1", ")", "==", "batch", "[", "3", "]", ".", "view", "(", "-", "1", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "num_data", "+=", "logits", ".", "size", "(", "0", ")", "\n", "\n", "# debug", "\n", "#val, idx = logits.max(1)", "\n", "#logger.info('idx: %s, batch[4]: %s' % (str(idx.shape), str(batch[3].shape)))", "\n", "#for i in range(idx.size(0)):", "\n", "#    logger.info('idx: %d, pred: %d, real: %d' % (idx[i].item(), eval_dataset.labels[idx[i].item()], batch[3][i].item()))", "\n", "\n", "nb_eval_steps", "+=", "1", "\n", "\n", "# with open(os.path.join(args.output_dir, \"stage2_eval.pkl\"), \"wb\") as fp:", "\n", "#     cPickle.dump(stage2_dict, fp)", "\n", "\n", "", "acc", "=", "float", "(", "correct_num", ")", "/", "len", "(", "eval_dataloader", ".", "dataset", ")", "\n", "acc_mat", "=", "float", "(", "correct_num_mat", ")", "/", "len", "(", "eval_dataloader", ".", "dataset", ")", "\n", "acc_all", "=", "float", "(", "correct_num_all", ")", "/", "len", "(", "eval_dataloader", ".", "dataset", ")", "\n", "\n", "logger", ".", "info", "(", "\"Eval Results:\"", ")", "\n", "logger", ".", "info", "(", "\"Eval Accuracy: %.3f\"", "%", "(", "100", "*", "acc", ")", ")", "\n", "logger", ".", "info", "(", "\"Eval MAT Accuracy: %.3f\"", "%", "(", "100", "*", "acc_mat", ")", ")", "\n", "logger", ".", "info", "(", "\"Eval ALL Accuracy: %.3f\"", "%", "(", "100", "*", "acc_all", ")", ")", "\n", "logger", ".", "info", "(", "\"Eval Loss: %.3f\"", "%", "(", "eval_loss", ")", ")", "\n", "\n", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Eva Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "return", "results", ",", "max", "(", "acc", ",", "acc_mat", ",", "acc_all", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_itm.test_stage2": [[899, 987], ["_pickle.load", "logger.info", "os.path.join", "os.path.exists", "print", "dict", "time.time", "zip", "time.time", "logger.info", "logger.info", "open", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "tqdm.tqdm", "open", "json.dump", "len", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "model.eval", "tuple", "range", "torch.stack", "torch.stack", "torch.stack", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "batch[].squeeze().detach().cpu().numpy", "enumerate", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "cls_logits.softmax.softmax", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "range", "len", "_pickle.load().items", "os.path.exists", "torch.from_numpy().to.append", "topk_scores.append", "torch.gather().squeeze.size", "str", "results.append", "t.to", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model", "torch.sigmoid.append", "torch.sigmoid.sum", "batch[].squeeze().detach().cpu", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.gather", "torch.gather", "torch.gather", "[].item", "_pickle.load", "logits.view().detach", "int", "numpy.stack", "numpy.stack", "open", "batch[].squeeze().detach", "logits.view", "preds_all[].item", "batch[].squeeze"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "test_stage2", "(", "args", ",", "model", ",", "eval_dataset", "=", "None", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "'-MM'", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "label2ans", "=", "cPickle", ".", "load", "(", "open", "(", "args", ".", "label2ans_file", ",", "'rb'", ")", ")", "\n", "logger", ".", "info", "(", "'label2ans: %d'", "%", "(", "len", "(", "label2ans", ")", ")", ")", "\n", "\n", "stage1_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"stage1_submission.pkl\"", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "stage1_file", ")", "\n", "print", "(", "\"loading stage1 file ...\"", ")", "\n", "eval_dataset", ".", "stage1_dict", "=", "dict", "(", "[", "(", "k", ",", "(", "v", "[", "0", "]", "[", ":", "args", ".", "k", "]", ",", "v", "[", "1", "]", "[", ":", "args", ".", "k", "]", ")", ")", "for", "k", ",", "v", "in", "cPickle", ".", "load", "(", "open", "(", "stage1_file", ",", "\"rb\"", ")", ")", ".", "items", "(", ")", "]", ")", "\n", "\n", "results", "=", "[", "]", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval", "\n", "logger", ".", "info", "(", "\"***** Running Test {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ")", ":", "\n", "#for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "templates", "=", "batch", "[", "8", "]", "\n", "templates_mask", "=", "batch", "[", "9", "]", "\n", "templates_segment", "=", "batch", "[", "10", "]", "\n", "mat_logits", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "templates", ".", "shape", "[", "1", "]", ")", ":", "\n", "                ", "temp", "=", "templates", "[", ":", ",", "i", "]", "\n", "temp_mask", "=", "templates_mask", "[", ":", ",", "i", "]", "\n", "temp_segment", "=", "templates_segment", "[", ":", ",", "i", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "inputs", "=", "{", "'input_ids'", ":", "temp", ",", "\n", "'attention_mask'", ":", "temp_mask", ",", "\n", "'token_type_ids'", ":", "temp_segment", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "\n", "# XLM don't use segment_ids", "\n", "'labels'", ":", "batch", "[", "3", "]", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", ",", "\n", "'mask_index'", ":", "batch", "[", "7", "]", ",", "\n", "'predict_labels'", ":", "batch", "[", "11", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "mat_logits", ".", "append", "(", "logits", ".", "view", "(", "-", "1", ")", ".", "detach", "(", ")", ")", "\n", "\n", "", "", "mat_logits", "=", "torch", ".", "stack", "(", "mat_logits", ",", "dim", "=", "-", "1", ")", "# [B, K]", "\n", "mat_logits", "=", "torch", ".", "sigmoid", "(", "mat_logits", ")", "\n", "mat_logits", "=", "mat_logits", "/", "(", "mat_logits", ".", "sum", "(", "-", "1", ",", "keepdim", "=", "True", ")", "+", "1e-6", ")", "\n", "\n", "q_ids", "=", "batch", "[", "6", "]", ".", "squeeze", "(", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "topk_indexes", ",", "topk_scores", "=", "[", "]", ",", "[", "]", "\n", "for", "_i", ",", "q_id", "in", "enumerate", "(", "q_ids", ")", ":", "\n", "                ", "temp", "=", "eval_dataset", ".", "stage1_dict", "[", "int", "(", "q_id", ")", "]", "\n", "topk_indexes", ".", "append", "(", "temp", "[", "0", "]", ")", "\n", "topk_scores", ".", "append", "(", "temp", "[", "1", "]", ")", "\n", "", "topk_indexes", "=", "torch", ".", "from_numpy", "(", "np", ".", "stack", "(", "topk_indexes", ",", "axis", "=", "0", ")", ")", ".", "to", "(", "\"cuda\"", ")", "# [B, K]", "\n", "cls_logits", "=", "torch", ".", "from_numpy", "(", "np", ".", "stack", "(", "topk_scores", ",", "axis", "=", "0", ")", ")", ".", "to", "(", "\"cuda\"", ")", "\n", "cls_logits", "=", "cls_logits", ".", "softmax", "(", "-", "1", ")", "\n", "\n", "preds_all", "=", "torch", ".", "gather", "(", "\n", "input", "=", "topk_indexes", ",", "\n", "dim", "=", "1", ",", "\n", "index", "=", "(", "mat_logits", "+", "cls_logits", ")", ".", "argmax", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", ".", "squeeze", "(", "-", "1", ")", "# [B, ]", "\n", "\n", "for", "i", "in", "range", "(", "preds_all", ".", "size", "(", "0", ")", ")", ":", "\n", "                ", "result", "=", "{", "}", "\n", "result", "[", "'questionId'", "]", "=", "str", "(", "batch", "[", "6", "]", "[", "i", "]", ".", "item", "(", ")", ")", "\n", "result", "[", "'prediction'", "]", "=", "label2ans", "[", "eval_dataset", ".", "labels", "[", "preds_all", "[", "i", "]", ".", "item", "(", ")", "]", "]", "\n", "results", ".", "append", "(", "result", ")", "\n", "\n", "", "", "", "with", "open", "(", "args", ".", "output_dir", "+", "(", "'/{}_results.json'", ".", "format", "(", "eval_dataset", ".", "name", ")", ")", ",", "'w'", ")", "as", "fp", ":", "\n", "        ", "json", ".", "dump", "(", "results", ",", "fp", ")", "\n", "\n", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'# questions: %d'", "%", "(", "len", "(", "results", ")", ")", ")", "\n", "logger", ".", "info", "(", "'Test Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_itm.test": [[988, 1043], ["_pickle.load", "logger.info", "time.time", "zip", "time.time", "logger.info", "logger.info", "open", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "open", "json.dump", "len", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "model.eval", "tuple", "len", "os.path.exists", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model", "logits.max", "range", "t.to", "idx.size", "str", "results.append", "[].item", "idx[].item"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "test", "(", "args", ",", "model", ",", "eval_dataset", "=", "None", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "'-MM'", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "label2ans", "=", "cPickle", ".", "load", "(", "open", "(", "args", ".", "label2ans_file", ",", "'rb'", ")", ")", "\n", "logger", ".", "info", "(", "'label2ans: %d'", "%", "(", "len", "(", "label2ans", ")", ")", ")", "\n", "\n", "results", "=", "[", "]", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval", "\n", "logger", ".", "info", "(", "\"***** Running Test {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "#for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "None", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", ",", "\n", "'mask_index'", ":", "batch", "[", "7", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "logits", "=", "outputs", "[", "0", "]", "\n", "\n", "val", ",", "idx", "=", "logits", ".", "max", "(", "1", ")", "\n", "#logger.info('idx: %s, batch[6]: %s' % (str(idx.shape), str(batch[6].shape)))", "\n", "\n", "for", "i", "in", "range", "(", "idx", ".", "size", "(", "0", ")", ")", ":", "\n", "                    ", "result", "=", "{", "}", "\n", "result", "[", "'questionId'", "]", "=", "str", "(", "batch", "[", "6", "]", "[", "i", "]", ".", "item", "(", ")", ")", "\n", "result", "[", "'prediction'", "]", "=", "label2ans", "[", "eval_dataset", ".", "labels", "[", "idx", "[", "i", "]", ".", "item", "(", ")", "]", "]", "\n", "results", ".", "append", "(", "result", ")", "\n", "\n", "#logger.info('q_id: {0}, answer: {1}'.format(result['question_id'], result['answer']))", "\n", "\n", "", "", "", "", "with", "open", "(", "args", ".", "output_dir", "+", "(", "'/{}_results.json'", ".", "format", "(", "eval_dataset", ".", "name", ")", ")", ",", "'w'", ")", "as", "fp", ":", "\n", "        ", "json", ".", "dump", "(", "results", ",", "fp", ")", "\n", "\n", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'# questions: %d'", "%", "(", "len", "(", "results", ")", ")", ")", "\n", "logger", ".", "info", "(", "'Test Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_itm.load_and_cache_examples": [[1044, 1110], ["processor.get_labels", "time.time", "numpy.load", "oscar.utils.task_utils.convert_examples_to_features_vqa", "time.time", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "processor.get_dev_examples", "processor.get_train_examples", "os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "print", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "bool", "bool", "time.time", "numpy.zeros", "enumerate", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "time.time", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "run_gqa_prompt_itm.target_tensor", "len"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.convert_examples_to_features_vqa", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.target_tensor"], ["", "def", "load_and_cache_examples", "(", "args", ",", "task", ",", "tokenizer", ",", "evaluate", "=", "False", ")", ":", "\n", "    ", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "output_mode", "=", "output_modes", "[", "task", "]", "\n", "\n", "label_list", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ")", "if", "evaluate", "else", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ")", "\n", "\n", "#img_features = torch.load(os.path.join(args.data_dir, 'val_img_feats.pt' if evaluate else 'train_img_feats.pt'))", "\n", "#img_features = torch.load(os.path.join(args.data_dir, 'val_img_frcnn_feats.pt' if evaluate else 'train_img_frcnn_feats.pt'))", "\n", "img_features", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'val_img_frcnn_feats.npy'", "if", "evaluate", "else", "'train_img_frcnn_feats.npy'", ")", ")", "\n", "\n", "features", "=", "convert_examples_to_features_vqa", "(", "examples", ",", "img_features", ",", "label_list", ",", "args", ".", "max_img_seq_length", ",", "args", ".", "max_seq_length", ",", "\n", "tokenizer", ",", "output_mode", ",", "\n", "cls_token_at_end", "=", "bool", "(", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "\n", "#if args.local_rank in [-1, 0]:", "\n", "#    logger.info(\"Saving features into cached file %s\", cached_features_file)", "\n", "#    torch.save(features, cached_features_file)", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: loading features using %.5f secs'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "# batch*max_seq_len", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "        ", "labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "[", "0", "]", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "targets", "=", "torch", ".", "tensor", "(", "[", "target_tensor", "(", "len", "(", "label_list", ")", ",", "f", ".", "label_id", ",", "f", ".", "score", ")", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "if", "args", ".", "img_feature_dim", ">", "0", ":", "# change here", "\n", "            ", "t_start", "=", "time", ".", "time", "(", ")", "\n", "img_feat_np", "=", "np", ".", "zeros", "(", "(", "labels", ".", "shape", "[", "0", "]", ",", "args", ".", "max_img_seq_length", ",", "args", ".", "img_feature_dim", ")", ")", "\n", "for", "f_id", ",", "f", "in", "enumerate", "(", "features", ")", ":", "\n", "                ", "img_feat_np", "[", "f_id", "]", "=", "f", ".", "img_feat", "\n", "\n", "", "img_feats", "=", "torch", ".", "from_numpy", "(", "img_feat_np", ")", "\n", "\n", "#img_feats = torch.empty((labels.shape[0], args.max_img_seq_length, args.img_feature_dim))", "\n", "#for f_id, f in enumerate(features):", "\n", "#   img_feats[f_id] = f.img_feat", "\n", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: convert image tensor features using %.5f secs'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "#img_feats = torch.stack([f.img_feat[:,-args.img_feature_dim:] for f in features])", "\n", "#img_feats = torch.stack([f.img_feat for f in features])", "\n", "#img_feats = img_feats.type(torch.long)", "\n", "\n", "#print('targets:', targets.shape)", "\n", "", "print", "(", "'img_feats:'", ",", "img_feats", ".", "shape", ")", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "        ", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "if", "args", ".", "img_feature_dim", "==", "-", "1", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "labels", ",", "targets", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "labels", ",", "targets", ",", "img_feats", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_itm.target_tensor": [[1111, 1118], ["enumerate"], "function", ["None"], ["", "def", "target_tensor", "(", "len", ",", "labels", ",", "scores", ")", ":", "\n", "    ", "\"\"\" create the target by labels and scores \"\"\"", "\n", "target", "=", "[", "0", "]", "*", "len", "\n", "for", "id", ",", "l", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "target", "[", "l", "]", "=", "scores", "[", "id", "]", "\n", "\n", "", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_itm.main": [[1122, 1427], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "oscar.utils.misc.set_seed", "parser.parse_args.task_name.lower", "processor.get_labels", "len", "logger.info", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "run_gqa_prompt_itm._load_img_features", "run_gqa_prompt_itm.GQADataset", "logger.info", "os.path.join", "logger.info", "os.path.exists", "os.listdir", "logger.info", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.device", "torch.device", "torch.device", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "bool", "ValueError", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "logger.info", "time.time", "torch.load", "torch.load", "torch.load", "time.time", "logger.info", "logger.info", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "run_gqa_prompt_itm.evaluate", "exit", "run_gqa_prompt_itm.GQADataset", "run_gqa_prompt_itm.GQADataset", "run_gqa_prompt_itm.GQADataset", "run_gqa_prompt_itm.train", "logger.info", "run_gqa_prompt_itm.GQADataset", "run_gqa_prompt_itm.train", "logger.info", "logger.info", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "torch.save", "torch.save", "logger.info", "logger.info", "logger.info", "os.getenv", "os.path.join", "bool", "model_class.from_pretrained.init_code_embedding", "os.makedirs", "os.path.join", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_gqa_prompt_itm.evaluate", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_gqa_prompt_itm.evaluate", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_gqa_prompt_itm.test_stage2", "train_code[].t", "model_class.from_pretrained.init_code_embedding", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.distributed.get_rank", "os.path.exists", "MODEL_CLASSES.keys", "oscar.utils.task_utils.processors.keys", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "train_code[].t", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "os.path.dirname", "logging.getLogger", "sorted", "sorted", "sorted", "glob.glob", "glob.glob", "glob.glob", "list", "train_code[].keys", "list", "train_code[].keys"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few._load_img_features", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.ImageBertForSequenceClassification.init_code_embedding", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_itm.test_stage2", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.ImageBertForSequenceClassification.init_code_embedding", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the .tsv files (or other data files) for the task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--task_name\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train selected in the list: \"", "+", "\", \"", ".", "join", "(", "processors", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--label_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Label Dictionary\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--label2ans_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Label to Answer Dictionary\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--data_label_type\"", ",", "default", "=", "'bal'", ",", "type", "=", "str", ",", "help", "=", "\"bal or all\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_data_type\"", ",", "default", "=", "'bal'", ",", "type", "=", "str", ",", "help", "=", "\"bal or all\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_data_type\"", ",", "default", "=", "'bal'", ",", "type", "=", "str", ",", "help", "=", "\"bal or all\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--loss_type\"", ",", "default", "=", "'kl'", ",", "type", "=", "str", ",", "help", "=", "\"kl or xe\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--spatial_dim\"", ",", "default", "=", "6", ",", "type", "=", "int", ",", "help", "=", "\"spatial_dim\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_label_pos_length\"", ",", "default", "=", "45", ",", "type", "=", "int", ",", "help", "=", "\"The maximum total input label position sequence length.\"", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer than this will be truncated, sequences shorter will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_val\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train_val\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run test on the test set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test_dev\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run test on the test-dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Rul evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--drop_out\"", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "\"Drop out for BERT.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--classifier\"", ",", "default", "=", "'linear'", ",", "type", "=", "str", ",", "help", "=", "\"linear or mlp\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cls_hidden_scale\"", ",", "default", "=", "2", ",", "type", "=", "int", ",", "help", "=", "\"cls_hidden_scale: for classifier\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_img_seq_length\"", ",", "default", "=", "30", ",", "type", "=", "int", ",", "help", "=", "\"The maximum total input image sequence length.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_dim\"", ",", "default", "=", "2054", ",", "type", "=", "int", ",", "help", "=", "\"The Image Feature Dimension.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_type\"", ",", "default", "=", "'faster_r-cnn'", ",", "type", "=", "str", ",", "help", "=", "\"faster_r-cnn or mask_r-cnn\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_voc\"", ",", "default", "=", "512", ",", "type", "=", "int", ",", "help", "=", "\"dis_code_voc: 256, 512\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_level\"", ",", "default", "=", "'top'", ",", "type", "=", "str", ",", "help", "=", "\"code level: top, botttom, both\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_epoch'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "\"Save checkpoint every X epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_output_dir'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_cache'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_ip'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_port'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--philly\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use Philly: reset the output dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--load_fast\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Load Tensor Fast\"", ")", "\n", "parser", ".", "add_argument", "(", "'-j'", ",", "'--workers'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "help", "=", "'number of data loading workers (default: 4)'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--k'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "help", "=", "\"Number of answers for ITM.\"", ")", "\n", "\n", "#args = '--data_dir ../vqa/ban-vqa/data/qal_pairs --model_type bert --model_name_or_path bert-base-uncased --task_name vqa_text ' \\", "\n", "#       '--do_train --do_eval --do_lower_case --max_seq_length 40 --per_gpu_eval_batch_size 16 --per_gpu_train_batch_size 16 --learning_rate 2e-5 ' \\", "\n", "#       '--num_train_epochs 20.0 --output_dir ./results/vqa_text --label_file ../vqa/ban-vqa/data/cache/trainval_ans2label.pkl ' \\", "\n", "#       '--save_steps 5000 --overwrite_output_dir --max_img_seq_length 1 --img_feature_dim 565 --img_feature_type dis_code '", "\n", "\n", "#args = '--data_dir ../vqa/ban-vqa/data/qal_pairs --model_type bert --model_name_or_path bert-base-uncased --task_name vqa_text ' \\", "\n", "#       '--do_train --do_eval --do_lower_case --max_seq_length 40 --per_gpu_eval_batch_size 16 --per_gpu_train_batch_size 16 --learning_rate 2e-5 ' \\", "\n", "#       '--num_train_epochs 20.0 --output_dir ./results/vqa_text --label_file ../vqa/ban-vqa/data/cache/trainval_ans2label.pkl ' \\", "\n", "#       '--save_steps 5000 --overwrite_output_dir --max_img_seq_length 10 --img_feature_dim 565 --img_feature_type other '", "\n", "\n", "#args = parser.parse_args(args.split())", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "philly", ":", "# use philly", "\n", "        ", "logger", ".", "info", "(", "'Info: Use Philly, all the output folders are reset.'", ")", "\n", "args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "getenv", "(", "'PT_OUTPUT_DIR'", ")", ",", "args", ".", "output_dir", ")", "\n", "logger", ".", "info", "(", "'OUTPUT_DIR:'", ",", "args", ".", "output_dir", ")", "\n", "\n", "#if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train and not args.overwrite_output_dir:", "\n", "#    raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args.output_dir))", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", ":", "\n", "        ", "logger", ".", "info", "(", "\"Output Directory Exists.\"", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s - %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ".", "seed", ",", "args", ".", "n_gpu", ")", "\n", "\n", "# Prepare GLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "args", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "\n", "label_list", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "logger", ".", "info", "(", "'Task Name: {}, #Labels: {}'", ".", "format", "(", "args", ".", "task_name", ",", "num_labels", ")", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "\n", "# discrete code", "\n", "config", ".", "img_feature_dim", "=", "args", ".", "img_feature_dim", "# 2054", "\n", "config", ".", "img_feature_type", "=", "args", ".", "img_feature_type", "# faster_r-cnn", "\n", "config", ".", "code_voc", "=", "args", ".", "code_voc", "# 512", "\n", "config", ".", "hidden_dropout_prob", "=", "args", ".", "drop_out", "# 0.3", "\n", "config", ".", "loss_type", "=", "args", ".", "loss_type", "# xe", "\n", "config", ".", "classifier", "=", "args", ".", "classifier", "# linear", "\n", "config", ".", "cls_hidden_scale", "=", "args", ".", "cls_hidden_scale", "# 2", "\n", "config", ".", "spatial_dim", "=", "args", ".", "spatial_dim", "# 6", "\n", "\n", "# load discrete code", "\n", "if", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "'Load discrete code from: {}'", ".", "format", "(", "args", ".", "data_dir", ")", ")", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "train_code", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'vqvae'", ",", "'train.pt'", ")", ")", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Load time: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "if", "args", ".", "code_level", "==", "'top'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_t'", "]", ".", "shape", "[", "0", "]", "\n", "config", ".", "code_size", "=", "train_code", "[", "'feats_top'", "]", "[", "list", "(", "train_code", "[", "'feats_top'", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "shape", "[", "0", "]", "\n", "", "elif", "args", ".", "code_level", "==", "'bottom'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_b'", "]", ".", "shape", "[", "0", "]", "\n", "config", ".", "code_size", "=", "train_code", "[", "'feats_bottom'", "]", "[", "list", "(", "train_code", "[", "'feats_bottom'", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "shape", "[", "0", "]", "\n", "", "elif", "args", ".", "code_level", "==", "'both'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_t'", "]", ".", "shape", "[", "0", "]", "+", "train_code", "[", "'embeddings_b'", "]", ".", "shape", "[", "0", "]", "\n", "\n", "# \u521d\u59cb\u5316\u6a21\u578b", "\n", "", "", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "'.ckpt'", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ")", "\n", "\n", "if", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "'Initializing the code embedding with {}'", ".", "format", "(", "args", ".", "code_level", ")", ")", "\n", "if", "args", ".", "code_level", "==", "'top'", ":", "\n", "            ", "model", ".", "init_code_embedding", "(", "train_code", "[", "'embeddings_t'", "]", ".", "t", "(", ")", ")", "\n", "", "elif", "args", ".", "code_level", "==", "'bottom'", ":", "\n", "            ", "model", ".", "init_code_embedding", "(", "train_code", "[", "'embeddings_b'", "]", ".", "t", "(", ")", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# load image features", "\n", "img_features", "=", "_load_img_features", "(", "args", ")", "\n", "label_pos_feats", "=", "None", "\n", "\n", "#if args.do_eval:", "\n", "eval_dataset", "=", "GQADataset", "(", "args", ",", "'val'", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", ")", "\n", "#eval_dataset = GQADataset(args, 'test-dev', img_features, tokenizer) # test-dev as val", "\n", "if", "args", ".", "do_val", ":", "\n", "        ", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ")", "\n", "exit", "(", "0", ")", "\n", "\n", "", "if", "args", ".", "do_test", ":", "\n", "        ", "test_dataset", "=", "GQADataset", "(", "args", ",", "'test'", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", ")", "\n", "\n", "", "if", "args", ".", "do_test_dev", ":", "\n", "        ", "test_dev_dataset", "=", "GQADataset", "(", "args", ",", "'test-dev'", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", ")", "\n", "\n", "# Training", "\n", "", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "GQADataset", "(", "args", ",", "'train'", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Training on train+val", "\n", "", "if", "args", ".", "do_train_val", ":", "# depreciated", "\n", "        ", "train_dataset", "=", "GQADataset", "(", "args", ",", "'train+val'", ",", "img_features", ",", "tokenizer", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`. They can then be reloaded using `from_pretrained()`", "\n", "#model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training", "\n", "#model_to_save.save_pretrained(args.output_dir)", "\n", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "#model = model_class.from_pretrained(args.output_dir)", "\n", "#tokenizer = tokenizer_class.from_pretrained(args.output_dir)", "\n", "#model.to(args.device)", "\n", "\n", "# Evaluation", "\n", "#results = {}", "\n", "", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ",", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "score", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "#result = dict((k + '_{}'.format(global_step), v) for k, v in result.items())", "\n", "#results.update(result)", "\n", "\n", "# Test-Dev", "\n", "", "", "if", "args", ".", "do_test_dev", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ",", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "score", "=", "evaluate", "(", "args", ",", "model", ",", "test_dev_dataset", ",", "prefix", "=", "global_step", ")", "\n", "#test(args, model, test_dev_dataset, prefix=global_step)", "\n", "\n", "# Test-Submission", "\n", "", "", "if", "args", ".", "do_test", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "# global_step = checkpoint.split('-')[-1] if len(checkpoints) > 1 else \"\"", "\n", "            ", "global_step", "=", "\"submission\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "test_stage2", "(", "args", ",", "model", ",", "test_dataset", ",", "prefix", "=", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.ImageBertForSequenceClassificationPromptStage2.__init__": [[38, 72], ["oscar.modeling.modeling_bert.ImageBertForSequenceClassification.__init__", "transformers.pytorch_transformers.modeling_bert.BertPooler", "hasattr", "run_vqa_prompt_itm.ImageBertForSequenceClassificationPromptStage2.apply", "run_vqa_prompt_itm.ImageBertForSequenceClassificationPromptStage2.parameters", "transformers.pytorch_transformers.modeling_bert.BertPooler", "transformers.pytorch_transformers.modeling_bert.BertPooler", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "hasattr", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "ImageBertForSequenceClassificationPromptStage2", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "mask_pooler", "=", "BertPooler", "(", "config", ")", "\n", "\n", "if", "hasattr", "(", "config", ",", "'classifier'", ")", ":", "\n", "            ", "if", "not", "hasattr", "(", "config", ",", "'cls_hidden_scale'", ")", ":", "\n", "                ", "config", ".", "cls_hidden_scale", "=", "2", "\n", "\n", "", "if", "config", ".", "classifier", "==", "'linear'", ":", "\n", "                ", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "\n", "self", ".", "config", ".", "num_labels", ")", "\n", "", "elif", "config", ".", "classifier", "==", "'mlp'", ":", "\n", "                ", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", "*", "config", ".", "cls_hidden_scale", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "config", ".", "cls_hidden_scale", ",", "self", ".", "config", ".", "num_labels", ")", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "self", ".", "config", ".", "num_labels", ")", "# original", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "matching_cls_pooler", "=", "BertPooler", "(", "config", ")", "\n", "self", ".", "matching_msk_pooler", "=", "BertPooler", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "self", ".", "matcher", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.ImageBertForSequenceClassificationPromptStage2.forward": [[73, 105], ["run_vqa_prompt_itm.ImageBertForSequenceClassificationPromptStage2.matching_msk_pooler", "run_vqa_prompt_itm.ImageBertForSequenceClassificationPromptStage2.matching_cls_pooler", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "run_vqa_prompt_itm.ImageBertForSequenceClassificationPromptStage2.dropout", "run_vqa_prompt_itm.ImageBertForSequenceClassificationPromptStage2.matcher", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "run_vqa_prompt_itm.ImageBertForSequenceClassificationPromptStage2.bert", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "run_vqa_prompt_itm.ImageBertForSequenceClassificationPromptStage2.sigmoid", "torch.binary_cross_entropy", "torch.binary_cross_entropy", "torch.binary_cross_entropy", "run_vqa_prompt_itm.ImageBertForSequenceClassificationPromptStage2.view", "predict_scores.view", "mask_index.unsqueeze().expand", "mask_index.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "img_feats", "=", "None", ",", "mask_index", "=", "None", ",", "predict_scores", "=", "None", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# (batch_size, sequence_length, hidden_dim), (batch_size, hidden_dim), ...", "\n", "            ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ",", "img_feats", "=", "img_feats", ")", "\n", "\n", "# (batch_size, hidden_dim)", "\n", "# pooled_output = outputs[1]", "\n", "seq_length", ",", "hidden_dim", "=", "outputs", "[", "0", "]", ".", "shape", "[", "1", ":", "]", "\n", "pooled_output", "=", "torch", ".", "gather", "(", "\n", "input", "=", "outputs", "[", "0", "]", ",", "\n", "dim", "=", "1", ",", "\n", "index", "=", "mask_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "(", "-", "1", ",", "-", "1", ",", "hidden_dim", ")", ")", "\n", ")", "# [batch_size, 1, hidden_dim]", "\n", "\n", "", "pooled_output", "=", "self", ".", "matching_msk_pooler", "(", "pooled_output", ")", "\n", "pooled_output_cls", "=", "self", ".", "matching_cls_pooler", "(", "outputs", "[", "0", "]", ")", "\n", "\n", "pooled_output", "=", "torch", ".", "cat", "(", "[", "pooled_output", ",", "pooled_output_cls", "]", ",", "dim", "=", "-", "1", ")", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "matcher", "(", "pooled_output", ")", "# [B, 1]", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# predict_scores are scores ranging from 0 ~ 1", "\n", "# loss = instance_bce_with_logits(logits, labels)", "\n", "            ", "logits", "=", "self", ".", "sigmoid", "(", "logits", ")", "\n", "loss", "=", "F", ".", "binary_cross_entropy", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "predict_scores", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.VQADataset.__init__": [[156, 209], ["torch.utils.data.Dataset.__init__", "time.time", "time.time", "logger.info", "run_vqa_prompt_itm._load_dataset", "_pickle.load", "dict", "logger.info", "open", "run_vqa_prompt_itm.VQADataset.tensorize", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "args.img_feature_type.startswith", "enumerate", "run_vqa_prompt_itm.VQADataset.label_map.items", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "run_vqa_prompt_itm.VQADataset.load_img_tsv_features", "os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "bool", "bool", "len", "os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few._load_dataset", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.load_img_tsv_features"], ["def", "__init__", "(", "self", ",", "args", ",", "name", ",", "tokenizer", ")", ":", "\n", "        ", "super", "(", "VQADataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "name", "in", "[", "'train'", ",", "'val'", ",", "'test-dev2015'", ",", "'test2015'", ",", "'train+val'", "]", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "name", "=", "name", "\n", "\n", "# load image features", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "img_feature_file", "=", "None", "\n", "self", ".", "img_feat_offset_map", "=", "None", "\n", "\n", "if", "args", ".", "img_feature_type", "==", "'faster_r-cnn'", ":", "\n", "            ", "if", "args", ".", "img_feat_format", "==", "'pt'", ":", "\n", "                ", "if", "args", ".", "img_feature_dim", "==", "2048", ":", "# object features", "\n", "                    ", "self", ".", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'{}_img_frcnn_obj_feats.pt'", ".", "format", "(", "name", ")", ")", ")", "\n", "", "else", ":", "# object + spatial features", "\n", "                    ", "if", "args", ".", "use_vg_dev", ":", "\n", "                        ", "self", ".", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'train+val_img_frcnn_feats.pt'", ")", ")", "\n", "", "else", ":", "\n", "                        ", "self", ".", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'{}_img_frcnn_feats.pt'", ".", "format", "(", "name", ")", ")", ")", "\n", "", "", "", "elif", "args", ".", "img_feat_format", "==", "'tsv'", ":", "\n", "                ", "self", ".", "load_img_tsv_features", "(", ")", "\n", "", "", "elif", "args", ".", "img_feature_type", "==", "'mask_r-cnn'", ":", "\n", "            ", "self", ".", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'{}_img_mask_rcnn_feats.pt'", ".", "format", "(", "name", ")", ")", ")", "\n", "", "elif", "args", ".", "img_feature_type", ".", "startswith", "(", "'dis_code'", ")", ":", "#in ['dis_code', 'dis_code_t']: # discrete code", "\n", "            ", "self", ".", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'vqvae'", ",", "'{}.pt'", ".", "format", "(", "name", ")", ")", ")", "[", "'feats_{}'", ".", "format", "(", "args", ".", "code_level", ")", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'{}_img_feats.pt'", ".", "format", "(", "name", ")", ")", ")", "\n", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: loading {0} features using {1:.2f} secs'", ".", "format", "(", "name", ",", "(", "t_end", "-", "t_start", ")", ")", ")", "\n", "\n", "# \"classification\"", "\n", "self", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "examples", ",", "self", ".", "labels", "=", "_load_dataset", "(", "args", ",", "name", ")", "\n", "self", ".", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "self", ".", "labels", ")", "}", "\n", "\n", "self", ".", "idx2label", "=", "{", "k", ":", "v", "for", "v", ",", "k", "in", "self", ".", "label_map", ".", "items", "(", ")", "}", "# classification idx -> label idx", "\n", "self", ".", "label2ans", "=", "cPickle", ".", "load", "(", "open", "(", "args", ".", "label2ans_file", ",", "\"rb\"", ")", ")", "# label idx -> answer", "\n", "self", ".", "stage1_dict", "=", "dict", "(", ")", "# q_id -> (topk_idxes, topk_scores)", "\n", "\n", "if", "self", ".", "args", ".", "load_fast", ":", "\n", "            ", "self", ".", "features", "=", "self", ".", "tensorize", "(", "args", ",", "cls_token_at_end", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "self", ".", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "\n", "", "logger", ".", "info", "(", "'%s Data Examples: %d'", "%", "(", "name", ",", "len", "(", "self", ".", "examples", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.VQADataset.generate_sample": [[210, 235], ["copy.copy", "copy.copy", "copy.copy", "run_vqa_prompt_itm.VQADataset.tokenizer.convert_tokens_to_ids", "len", "template_answer.strip", "run_vqa_prompt_itm.VQADataset.tokenizer.tokenize", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.copy", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.copy", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.copy"], ["", "def", "generate_sample", "(", "self", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_idx", ",", "mask_index", ")", ":", "\n", "        ", "template", "=", "copy", ".", "copy", "(", "input_ids", ")", "\n", "template_mask", "=", "copy", ".", "copy", "(", "input_mask", ")", "\n", "template_segment", "=", "copy", ".", "copy", "(", "segment_ids", ")", "\n", "\n", "# Transform to answer string", "\n", "template_label", "=", "self", ".", "idx2label", "[", "label_idx", "]", "\n", "template_answer", "=", "self", ".", "label2ans", "[", "template_label", "]", "\n", "# TODO: Skip the empty answer and replace with \"none\"", "\n", "if", "template_answer", ".", "strip", "(", ")", "==", "\"\"", ":", "\n", "            ", "template_answer", "=", "\"none\"", "\n", "", "tokens_ans", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "template_answer", ")", ")", "\n", "ans_length", "=", "len", "(", "tokens_ans", ")", "\n", "template", "=", "(", "template", "[", ":", "mask_index", "]", "+", "tokens_ans", "+", "template", "[", "mask_index", "+", "1", ":", "]", ")", "[", ":", "len", "(", "input_ids", ")", "]", "\n", "template_mask", "=", "template_mask", "[", ":", "mask_index", "]", "+", "[", "1", "]", "*", "ans_length", "+", "template_mask", "[", "mask_index", "+", "1", ":", "len", "(", "\n", "input_mask", ")", "-", "ans_length", "+", "1", "]", "+", "template_mask", "[", "len", "(", "input_mask", ")", ":", "]", "\n", "template_segment", "=", "(", "template_segment", "[", ":", "mask_index", "]", "+", "[", "\n", "template_segment", "[", "mask_index", "]", "]", "*", "ans_length", "+", "template_segment", "[", "mask_index", "+", "1", ":", "]", ")", "[", ":", "len", "(", "segment_ids", ")", "]", "\n", "\n", "assert", "len", "(", "template", ")", "==", "len", "(", "input_ids", ")", "\n", "assert", "len", "(", "template_mask", ")", "==", "len", "(", "input_mask", ")", "\n", "assert", "len", "(", "template_segment", ")", "==", "len", "(", "segment_ids", ")", "\n", "\n", "return", "template", ",", "template_mask", ",", "template_segment", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.VQADataset.tensorize": [[236, 342], ["enumerate", "run_vqa_prompt_itm.VQADataset.tokenizer.tokenize", "run_vqa_prompt_itm.VQADataset.tokenizer.convert_tokens_to_ids", "run_vqa_prompt_itm.target_tensor", "features.append", "len", "logger.info", "run_vqa_prompt_itm.VQADataset.tokenizer.tokenize", "oscar.utils.task_utils._truncate_seq_pair", "len", "len", "len", "len", "len", "len", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "len", "len", "float", "KeyError", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.target_tensor", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv._truncate_seq_pair"], ["", "def", "tensorize", "(", "self", ",", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "\n", "# debug:", "\n", "        ", "debug_size", "=", "500", "\n", "features", "=", "[", "]", "\n", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "self", ".", "examples", "[", "0", ":", "]", ")", ":", "\n", "            ", "if", "len", "(", "example", ".", "label", ")", "==", "0", ":", "continue", "\n", "if", "ex_index", "%", "10000", "==", "0", ":", "logger", ".", "info", "(", "\"Tensorizing example %d of %d\"", "%", "(", "ex_index", ",", "len", "(", "self", ".", "examples", ")", ")", ")", "\n", "\n", "tokens_a", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "                ", "tokens_b", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_b", ")", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "self", ".", "args", ".", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "                ", "if", "len", "(", "tokens_a", ")", ">", "self", ".", "args", ".", "max_seq_length", "-", "2", ":", "\n", "                    ", "tokens_a", "=", "tokens_a", "[", ":", "(", "self", ".", "args", ".", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "", "tokens", "=", "tokens_a", "+", "[", "sep_token", "]", "\n", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "                ", "tokens", "+=", "tokens_b", "+", "[", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "if", "cls_token_at_end", ":", "\n", "                ", "tokens", "=", "tokens", "+", "[", "cls_token", "]", "\n", "segment_ids", "=", "segment_ids", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "                ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "self", ".", "args", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "                ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "", "else", ":", "\n", "                ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "segment_ids", "=", "segment_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "\n", "# image features", "\n", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "# torch", "\n", "#img_feat = self.img_features.item().get(example.img_key)  # numpy", "\n", "if", "img_feat", ".", "shape", "[", "0", "]", ">", "self", ".", "args", ".", "max_img_seq_length", ":", "\n", "                ", "img_feat", "=", "img_feat", "[", "0", ":", "self", ".", "args", ".", "max_img_seq_length", ",", "]", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids += [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids = segment_ids + [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "self", ".", "args", ".", "max_img_seq_length", "-", "img_feat", ".", "shape", "[", "0", "]", ",", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_matrix", ".", "shape", "[", "0", "]", ")", "\n", "# segment_ids = segment_ids + [pad_token_segment_id] * padding_matrix.shape[0]", "\n", "\n", "", "", "if", "self", ".", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "                ", "label_id", "=", "[", "self", ".", "label_map", "[", "l", "]", "for", "l", "in", "example", ".", "label", "]", "\n", "score", "=", "example", ".", "score", "\n", "", "elif", "self", ".", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "                ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "else", ":", "\n", "                ", "raise", "KeyError", "(", "self", ".", "args", ".", "output_mode", ")", "\n", "\n", "", "if", "ex_index", "<", "5", ":", "\n", "                ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"segment_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label: %s (id = %s)\"", "%", "(", "example", ".", "label", ",", "label_id", ")", ")", "\n", "logger", ".", "info", "(", "\"score: %s (score = %s)\"", "%", "(", "example", ".", "score", ",", "score", ")", ")", "\n", "\n", "", "new_scores", "=", "target_tensor", "(", "len", "(", "self", ".", "labels", ")", ",", "label_id", ",", "score", ")", "\n", "#features.append(InputFeat(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label_id, score=score, img_feat=img_feat))", "\n", "features", ".", "append", "(", "(", "torch", ".", "tensor", "(", "input_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "label_id", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "new_scores", ",", "dtype", "=", "torch", ".", "float", ")", ",", "img_feat", ")", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.VQADataset.tensorize_example": [[343, 502], ["run_vqa_prompt_itm.VQADataset.tokenizer.tokenize", "run_vqa_prompt_itm.VQADataset.tokenizer.tokenize", "tokens.index", "run_vqa_prompt_itm.VQADataset.tokenizer.convert_tokens_to_ids", "run_vqa_prompt_itm.VQADataset.args.img_feature_type.startswith", "run_vqa_prompt_itm.target_tensor", "float", "run_vqa_prompt_itm.VQADataset.tokenizer.tokenize", "run_vqa_prompt_itm.VQADataset.tokenizer.tokenize", "oscar.utils.task_utils._truncate_seq_pair", "len", "len", "len", "len", "len", "len", "len", "torch.from_numpy.type", "torch.from_numpy.type", "torch.from_numpy.type", "run_vqa_prompt_itm.VQADataset.generate_sample", "templates.append", "templates_mask.append", "templates_segment.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "torch.from_numpy.reshape", "torch.from_numpy.reshape", "torch.from_numpy.reshape", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KeyError", "torch.from_numpy.type", "torch.from_numpy.type", "torch.from_numpy.type", "int", "len", "zip", "len", "run_vqa_prompt_itm.VQADataset.get_img_feature", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "len", "len", "float", "random.random", "random.randint", "random.choice", "numpy.random.choice", "int", "run_vqa_prompt_itm.VQADataset.generate_sample", "templates.append", "templates_mask.append", "templates_segment.append", "str", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.target_tensor", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv._truncate_seq_pair", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.VQADataset.generate_sample", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.get_img_feature", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.VQADataset.generate_sample"], ["", "def", "tensorize_example", "(", "self", ",", "example", ",", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "\n", "        ", "tokens_a", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "tokens_c", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "\"Answer: \"", "+", "example", ".", "text_c", ")", "\n", "if", "\"[MASK]\"", "not", "in", "tokens_c", ":", "\n", "            ", "tokens_c", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "\"Answer: [MASK]\"", ")", "\n", "", "tokens_a", "=", "tokens_a", "+", "tokens_c", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "            ", "tokens_b", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_b", ")", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "self", ".", "args", ".", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "            ", "if", "len", "(", "tokens_a", ")", ">", "self", ".", "args", ".", "max_seq_length", "-", "2", ":", "\n", "                ", "tokens_a", "=", "tokens_a", "[", ":", "(", "self", ".", "args", ".", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "", "tokens", "=", "tokens_a", "+", "[", "sep_token", "]", "\n", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "            ", "tokens", "+=", "tokens_b", "+", "[", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "if", "cls_token_at_end", ":", "\n", "            ", "tokens", "=", "tokens", "+", "[", "cls_token", "]", "\n", "segment_ids", "=", "segment_ids", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "            ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "mask_index", "=", "tokens", ".", "index", "(", "\"[MASK]\"", ")", "\n", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "self", ".", "args", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "segment_ids", "=", "segment_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "\n", "# image features", "\n", "if", "self", ".", "args", ".", "img_feature_type", ".", "startswith", "(", "'dis_code'", ")", ":", "\n", "            ", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "\n", "\n", "if", "self", ".", "args", ".", "img_feature_type", "==", "'dis_code_ln'", ":", "# for discrete code image representation", "\n", "                ", "img_feat", "=", "img_feat", ".", "reshape", "(", "-", "1", ",", "img_feat", ".", "shape", "[", "0", "]", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "img_feature_type", "==", "'dis_code_t'", ":", "# transposed", "\n", "                ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "64", "\n", "", "else", ":", "\n", "                ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "args", ".", "img_feat_format", "==", "'pt'", ":", "\n", "                ", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "#[:, 0:self.args.img_feature_dim]  # torch", "\n", "", "elif", "self", ".", "args", ".", "img_feat_format", "==", "'tsv'", ":", "\n", "                ", "img_features", "=", "self", ".", "get_img_feature", "(", "str", "(", "example", ".", "img_key", ")", ")", "\n", "img_feat", "=", "torch", ".", "from_numpy", "(", "img_features", ")", "\n", "\n", "", "if", "img_feat", ".", "shape", "[", "0", "]", ">", "self", ".", "args", ".", "max_img_seq_length", ":", "\n", "                ", "img_feat", "=", "img_feat", "[", "0", ":", "self", ".", "args", ".", "max_img_seq_length", ",", "]", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids += [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids = segment_ids + [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "self", ".", "args", ".", "max_img_seq_length", "-", "img_feat", ".", "shape", "[", "0", "]", ",", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_matrix", ".", "shape", "[", "0", "]", ")", "\n", "# segment_ids = segment_ids + [pad_token_segment_id] * padding_matrix.shape[0]", "\n", "\n", "", "", "", "if", "self", ".", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "if", "(", "example", ".", "label", "is", "None", ")", ":", "\n", "                ", "label_id", "=", "[", "0", "]", "\n", "score", "=", "[", "0", "]", "\n", "", "elif", "len", "(", "example", ".", "label", ")", "==", "0", ":", "\n", "                ", "label_id", "=", "[", "0", "]", "\n", "score", "=", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "label_id", "=", "[", "self", ".", "label_map", "[", "l", "]", "for", "l", "in", "example", ".", "label", "]", "\n", "score", "=", "example", ".", "score", "\n", "", "", "elif", "self", ".", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "if", "len", "(", "example", ".", "label", ")", "==", "0", ":", "\n", "                ", "label_id", "=", "0", "\n", "", "else", ":", "\n", "                ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "self", ".", "args", ".", "output_mode", ")", "\n", "\n", "", "new_scores", "=", "target_tensor", "(", "len", "(", "self", ".", "labels", ")", ",", "label_id", ",", "score", ")", "\n", "\n", "# features.append(InputFeat(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label_id, score=score, img_feat=img_feat))", "\n", "if", "self", ".", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "            ", "img_feat", "=", "img_feat", ".", "type", "(", "torch", ".", "long", ")", "\n", "", "elif", "self", ".", "args", ".", "img_feature_type", "in", "[", "'dis_code_ln'", "]", ":", "\n", "#img_feat = img_feat.reshape(-1, img_feat.shape[0])", "\n", "            ", "img_feat", "=", "img_feat", ".", "type", "(", "torch", ".", "float", ")", "\n", "\n", "", "templates", "=", "[", "]", "\n", "templates_mask", "=", "[", "]", "\n", "templates_segment", "=", "[", "]", "\n", "if", "self", ".", "name", "==", "\"train\"", ":", "\n", "            ", "if", "example", ".", "q_id", "not", "in", "self", ".", "stage1_dict", ":", "\n", "                ", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "                    ", "template_idx", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "label_map", ")", "-", "1", ")", "\n", "", "else", ":", "\n", "                    ", "template_idx", "=", "random", ".", "choice", "(", "label_id", ")", "\n", "", "", "else", ":", "\n", "                ", "indexes", ",", "scores", "=", "self", ".", "stage1_dict", "[", "example", ".", "q_id", "]", "\n", "template_idx", "=", "int", "(", "np", ".", "random", ".", "choice", "(", "a", "=", "indexes", ")", ")", "\n", "", "sample", "=", "self", ".", "generate_sample", "(", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "template_idx", ",", "mask_index", ")", "\n", "templates", ".", "append", "(", "sample", "[", "0", "]", ")", "\n", "templates_mask", ".", "append", "(", "sample", "[", "1", "]", ")", "\n", "templates_segment", ".", "append", "(", "sample", "[", "2", "]", ")", "\n", "", "else", ":", "\n", "            ", "template_idx", "=", "0", "\n", "if", "len", "(", "self", ".", "stage1_dict", ")", ">", "0", ":", "\n", "                ", "indexes", ",", "scores", "=", "self", ".", "stage1_dict", "[", "example", ".", "q_id", "]", "\n", "for", "ind", ",", "sco", "in", "zip", "(", "indexes", ",", "scores", ")", ":", "\n", "                    ", "ind", "=", "int", "(", "ind", ")", "\n", "sample", "=", "self", ".", "generate_sample", "(", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "ind", ",", "mask_index", ")", "\n", "templates", ".", "append", "(", "sample", "[", "0", "]", ")", "\n", "templates_mask", ".", "append", "(", "sample", "[", "1", "]", ")", "\n", "templates_segment", ".", "append", "(", "sample", "[", "2", "]", ")", "\n", "", "", "", "template_score", "=", "float", "(", "new_scores", "[", "template_idx", "]", ")", "\n", "\n", "return", "(", "torch", ".", "tensor", "(", "input_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 0", "\n", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 1", "\n", "torch", ".", "tensor", "(", "segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 2", "\n", "torch", ".", "tensor", "(", "[", "label_id", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 3", "\n", "torch", ".", "tensor", "(", "new_scores", ",", "dtype", "=", "torch", ".", "float", ")", ",", "# 4", "\n", "img_feat", ",", "# 5", "\n", "torch", ".", "tensor", "(", "[", "example", ".", "q_id", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 6", "\n", "torch", ".", "tensor", "(", "[", "mask_index", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 7", "\n", "torch", ".", "tensor", "(", "templates", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 8", "\n", "torch", ".", "tensor", "(", "templates_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 9", "\n", "torch", ".", "tensor", "(", "templates_segment", ",", "dtype", "=", "torch", ".", "long", ")", ",", "# 10", "\n", "torch", ".", "tensor", "(", "[", "template_score", "]", ",", "dtype", "=", "torch", ".", "float32", ")", "# 11", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.VQADataset.__getitem__": [[504, 517], ["run_vqa_prompt_itm.VQADataset.tensorize_example", "bool", "bool"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize_example"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "load_fast", ":", "\n", "            ", "example", "=", "self", ".", "features", "[", "index", "]", "\n", "", "else", ":", "\n", "            ", "entry", "=", "self", ".", "examples", "[", "index", "]", "\n", "example", "=", "self", ".", "tensorize_example", "(", "entry", ",", "\n", "cls_token_at_end", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "self", ".", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.VQADataset.__len__": [[518, 520], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.VQADataset.load_img_tsv_features": [[522, 525], ["run_vqa_prompt_itm.VQADataset.check_img_feature_file", "run_vqa_prompt_itm.VQADataset.check_img_feature_offset_map"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_feature_file", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_feature_offset_map"], ["", "def", "load_img_tsv_features", "(", "self", ")", ":", "\n", "        ", "self", ".", "check_img_feature_file", "(", ")", "\n", "self", ".", "check_img_feature_offset_map", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.VQADataset.check_img_feature_file": [[526, 533], ["os.path.join", "time.time", "open", "time.time", "logger.info"], "methods", ["None"], ["", "def", "check_img_feature_file", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "img_feature_file", "is", "None", ":", "\n", "            ", "img_feature_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "img_feat_dir", ",", "'{}_img_frcnn_feats.tsv'", ".", "format", "(", "self", ".", "name", ")", ")", "\n", "t_s", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "img_feature_file", "=", "open", "(", "img_feature_path", ",", "'r'", ")", "\n", "t_e", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "\"Open {} image time: {}\"", ".", "format", "(", "self", ".", "name", ",", "(", "t_e", "-", "t_s", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.VQADataset.check_img_feature_offset_map": [[534, 542], ["os.path.join", "time.time", "json.load", "time.time", "logger.info", "open", "len"], "methods", ["None"], ["", "", "def", "check_img_feature_offset_map", "(", "self", ")", ":", "\n", "        ", "\"\"\" load the image feature offset map \"\"\"", "\n", "if", "self", ".", "img_feat_offset_map", "is", "None", ":", "\n", "            ", "img_feature_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "img_feat_dir", ",", "'{}_img_frcnn_feats_offset_map.json'", ".", "format", "(", "self", ".", "name", ")", ")", "\n", "t_s", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "img_feat_offset_map", "=", "json", ".", "load", "(", "open", "(", "img_feature_path", ")", ")", "\n", "t_e", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "\"Load {} images: {}, time: {}\"", ".", "format", "(", "self", ".", "name", ",", "len", "(", "self", ".", "img_feat_offset_map", ")", ",", "(", "t_e", "-", "t_s", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.VQADataset.get_img_feature": [[543, 557], ["run_vqa_prompt_itm.VQADataset.check_img_feature_file", "run_vqa_prompt_itm.VQADataset.check_img_feature_offset_map", "run_vqa_prompt_itm.VQADataset.img_feature_file.seek", "int", "numpy.frombuffer().reshape", "s.strip", "run_vqa_prompt_itm.VQADataset.img_feature_file.readline().split", "numpy.frombuffer", "base64.b64decode", "run_vqa_prompt_itm.VQADataset.img_feature_file.readline"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_feature_file", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_feature_offset_map", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek"], ["", "", "def", "get_img_feature", "(", "self", ",", "image_id", ")", ":", "\n", "        ", "\"\"\" decode the image feature \"\"\"", "\n", "self", ".", "check_img_feature_file", "(", ")", "\n", "self", ".", "check_img_feature_offset_map", "(", ")", "\n", "\n", "if", "image_id", "in", "self", ".", "img_feat_offset_map", ":", "\n", "            ", "img_offset", "=", "self", ".", "img_feat_offset_map", "[", "image_id", "]", "\n", "self", ".", "img_feature_file", ".", "seek", "(", "img_offset", ",", "0", ")", "\n", "arr", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "self", ".", "img_feature_file", ".", "readline", "(", ")", ".", "split", "(", "'\\t'", ")", "]", "\n", "num_boxes", "=", "int", "(", "arr", "[", "1", "]", ")", "\n", "feat", "=", "np", ".", "frombuffer", "(", "base64", ".", "b64decode", "(", "arr", "[", "2", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "(", "-", "1", ",", "self", ".", "args", ".", "img_feature_dim", ")", ")", "\n", "return", "feat", "\n", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm._load_dataset": [[113, 152], ["processor.get_labels", "processor.get_train_examples", "processor.get_train_examples", "processor.get_train_examples", "processor.get_dev_examples", "processor.get_dev_examples", "processor.get_dev_examples", "processor.get_train_examples", "processor.get_train_examples", "processor.get_test_examples", "processor.get_test_examples", "processor.get_test_examples", "processor.get_test_examples"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples"], ["def", "_load_dataset", "(", "args", ",", "name", ")", ":", "\n", "    ", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "labels", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "\n", "if", "name", "==", "'train'", ":", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'mask'", ":", "\n", "            ", "if", "args", ".", "use_vg", ":", "\n", "#examples = processor.get_train_examples(args.data_dir, 'train2014_vg_qla_mrcnn.json')", "\n", "                ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "txt_data_dir", ",", "'train2014_vg_qla_mrcnn.json'", ")", "\n", "", "else", ":", "\n", "                ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "txt_data_dir", ",", "'train2014_qla_mrcnn.json'", ")", "\n", "", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "txt_data_dir", ",", "'train2014_qla.json'", ")", "\n", "", "", "elif", "name", "==", "'val'", ":", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'mask'", ":", "\n", "            ", "if", "args", ".", "use_vg_dev", ":", "\n", "                ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "txt_data_dir", ",", "'vg_qla_mrcnn.json'", ")", "\n", "", "else", ":", "\n", "                ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "txt_data_dir", ",", "'val2014_qla_mrcnn.json'", ")", "\n", "", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "txt_data_dir", ",", "'val2014_qla.json'", ")", "\n", "", "", "elif", "name", "==", "'train+val'", ":", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'mask'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "txt_data_dir", ",", "'train+val2014_qla_mrcnn.json'", ")", "\n", "#examples = processor.get_train_examples(args.data_dir, 'train+val2014_qla_mrcnn.json')", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "txt_data_dir", ",", "'train+val2014_qla.json'", ")", "\n", "", "", "elif", "name", "==", "'test2015'", ":", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'mask'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'test2015_qla_mrcnn.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'test2014_qla.json'", ")", "\n", "", "", "elif", "name", "==", "'test-dev2015'", ":", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'mask'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'test-dev2015_qla_mrcnn.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'test2014_qla.json'", ")", "\n", "\n", "", "", "return", "examples", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.instance_bce_with_logits": [[558, 565], ["torch.functional.binary_cross_entropy_with_logits", "logits.dim", "labels.size"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "", "def", "instance_bce_with_logits", "(", "logits", ",", "labels", ",", "reduction", "=", "'mean'", ")", ":", "\n", "    ", "assert", "logits", ".", "dim", "(", ")", "==", "2", "\n", "\n", "loss", "=", "nn", ".", "functional", ".", "binary_cross_entropy_with_logits", "(", "logits", ",", "labels", ",", "reduction", "=", "reduction", ")", "\n", "if", "reduction", "==", "'mean'", ":", "\n", "        ", "loss", "*=", "labels", ".", "size", "(", "1", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.compute_score_with_logits": [[567, 573], ["torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda.scatter_", "logits.view", "torch.max", "torch.max", "torch.max", "torch.zeros", "torch.zeros", "torch.zeros", "labels.size"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "compute_score_with_logits", "(", "logits", ",", "labels", ")", ":", "\n", "    ", "logits", "=", "torch", ".", "max", "(", "logits", ",", "1", ")", "[", "1", "]", ".", "data", "# argmax", "\n", "one_hots", "=", "torch", ".", "zeros", "(", "*", "labels", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", "\n", "one_hots", ".", "scatter_", "(", "1", ",", "logits", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", "\n", "scores", "=", "(", "one_hots", "*", "labels", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.compute_score_with_preds": [[574, 579], ["torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda.scatter_", "preds.view", "torch.zeros", "torch.zeros", "torch.zeros", "labels.size"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "compute_score_with_preds", "(", "preds", ",", "labels", ")", ":", "\n", "    ", "one_hots", "=", "torch", ".", "zeros", "(", "*", "labels", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", "\n", "one_hots", ".", "scatter_", "(", "1", ",", "preds", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", "\n", "scores", "=", "(", "one_hots", "*", "labels", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.trim_batch": [[581, 601], ["print", "len", "enumerate", "len", "print", "torch.zeros", "torch.zeros", "torch.zeros", "batch_tensors.append", "print", "enumerate", "ele.size", "len", "print", "list", "ele.size"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "trim_batch", "(", "batch", ")", ":", "\n", "    ", "\"\"\" new batch func\n    :param batch:\n    :return:\n    \"\"\"", "\n", "print", "(", "'batch size'", ",", "len", "(", "batch", ")", ")", "\n", "\n", "batch_size", "=", "len", "(", "batch", ")", "\n", "batch_tensors", "=", "[", "]", "\n", "for", "ele", "in", "batch", "[", "0", "]", ":", "\n", "        ", "print", "(", "ele", ".", "shape", ",", "ele", ".", "size", "(", ")", ")", "\n", "zero_tensor", "=", "torch", ".", "zeros", "(", "(", "[", "batch_size", "]", "+", "list", "(", "ele", ".", "size", "(", ")", ")", ")", ")", "\n", "batch_tensors", ".", "append", "(", "zero_tensor", ")", "\n", "\n", "", "for", "b_id", ",", "b", "in", "enumerate", "(", "batch", ")", ":", "\n", "        ", "print", "(", "b_id", ",", "len", "(", "b", ")", ")", "\n", "for", "ele_id", ",", "ele", "in", "enumerate", "(", "b", ")", ":", "\n", "            ", "print", "(", "ele_id", ",", "ele", ".", "shape", ")", "\n", "batch_tensors", "[", "ele_id", "]", "[", "b_id", "]", "=", "ele", "\n", "", "", "return", "batch_tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.train": [[603, 829], ["torch.utils.data.DataLoader", "transformers.pytorch_transformers.AdamW", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "oscar.utils.misc.set_seed", "os.path.join", "print", "_pickle.load", "range", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "transformers.pytorch_transformers.WarmupConstantSchedule", "amp.initialize", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "copy.deepcopy", "transformers.pytorch_transformers.AdamW.state_dict", "open", "int", "time.time", "enumerate", "logger.info", "run_vqa_prompt_itm.evaluate", "log_json.append", "logger.info", "logger.info", "time.time", "logger.info", "os.path.join", "logger.info", "transformers.pytorch_transformers.WarmupLinearSchedule", "logger.info", "hasattr", "logger.info", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "copy.deepcopy", "os.path.join", "logger.info", "open", "json.dump", "os.path.exists", "os.makedirs", "hasattr", "len", "ImportError", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "batch[].squeeze", "batch[].squeeze", "loss.mean.mean", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "transformers.pytorch_transformers.WarmupLinearSchedule.step", "transformers.pytorch_transformers.AdamW.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "os.path.exists", "os.makedirs", "hasattr", "open", "json.dump", "round", "model_to_save.save_pretrained", "torch.save", "torch.save", "torch.save", "tokenizer.save_pretrained", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "t.to", "batch[].squeeze", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "logger.info", "model_to_save.save_pretrained", "torch.save", "torch.save", "torch.save", "tokenizer.save_pretrained", "os.path.join", "any", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "logger.info", "run_vqa_prompt_itm.evaluate", "logger.info", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "os.path.join", "copy.deepcopy"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "#if args.local_rank in [-1, 0]: tb_writer = SummaryWriter()", "\n", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "num_workers", "=", "args", ".", "workers", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "#, collate_fn=trim_batch)", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "#scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args.warmup_steps, t_total=t_total) # original", "\n", "\n", "if", "args", ".", "scheduler", "==", "\"constant\"", ":", "\n", "        ", "scheduler", "=", "WarmupConstantSchedule", "(", "optimizer", ",", "warmup_steps", "=", "args", ".", "warmup_steps", ")", "\n", "", "elif", "args", ".", "scheduler", "==", "\"linear\"", ":", "\n", "        ", "scheduler", "=", "WarmupLinearSchedule", "(", "optimizer", ",", "warmup_steps", "=", "args", ".", "warmup_steps", ",", "t_total", "=", "t_total", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "#train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0])", "\n", "set_seed", "(", "args", ".", "seed", ",", "args", ".", "n_gpu", ")", "# Added here for reproductibility (even between python 2 and 3)", "\n", "\n", "best_score", "=", "0", "\n", "best_model", "=", "{", "\n", "'epoch'", ":", "0", ",", "\n", "'model'", ":", "copy", ".", "deepcopy", "(", "model", ")", ",", "#model.state_dict(),", "\n", "'optimizer_state'", ":", "optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n", "\n", "stage1_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"stage1.pkl\"", ")", "\n", "print", "(", "\"loading labels from stage1...\"", ")", "\n", "train_dataset", ".", "stage1_dict", "=", "cPickle", ".", "load", "(", "open", "(", "stage1_path", ",", "\"rb\"", ")", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "#for epoch in train_iterator:", "\n", "#epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])", "\n", "        ", "total_loss", "=", "0", "\n", "train_score", "=", "0", "\n", "total_norm", "=", "0", "\n", "count_norm", "=", "0", "\n", "\n", "if", "args", ".", "adjust_dp", "and", "epoch", ">=", "3", ":", "\n", "            ", "logger", ".", "info", "(", "\"change droput ratio {} to 0.3\"", ".", "format", "(", "args", ".", "drop_out", ")", ")", "\n", "if", "hasattr", "(", "model", ",", "'module'", ")", ":", "\n", "                ", "model", ".", "module", ".", "dropout", ".", "p", "=", "0.3", "\n", "model", ".", "module", ".", "bert", ".", "dropout", ".", "p", "=", "0.3", "\n", "model", ".", "module", ".", "bert", ".", "embeddings", ".", "dropout", ".", "p", "=", "0.3", "\n", "", "else", ":", "\n", "                ", "model", ".", "dropout", ".", "p", "=", "0.3", "\n", "model", ".", "bert", ".", "dropout", ".", "p", "=", "0.3", "\n", "model", ".", "bert", ".", "embeddings", ".", "dropout", ".", "p", "=", "0.3", "\n", "\n", "", "", "if", "args", ".", "adjust_loss", "and", "epoch", ">=", "args", ".", "adjust_loss_epoch", ":", "\n", "            ", "logger", ".", "info", "(", "\"\\t change loss type from kl to bce\"", ")", "\n", "model", ".", "loss_type", "=", "'bce'", "\n", "\n", "# debug", "\n", "#epoch = 20", "\n", "#global_step = epoch*math.ceil(len(train_dataset)/(args.train_batch_size * args.gradient_accumulation_steps * (torch.distributed.get_world_size() if args.local_rank != -1 else 1)))", "\n", "\n", "", "t_start", "=", "time", ".", "time", "(", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "8", "]", ".", "squeeze", "(", "1", ")", ",", "\n", "'attention_mask'", ":", "batch", "[", "9", "]", ".", "squeeze", "(", "1", ")", ",", "\n", "'token_type_ids'", ":", "batch", "[", "10", "]", ".", "squeeze", "(", "1", ")", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "batch", "[", "4", "]", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", ",", "\n", "'mask_index'", ":", "batch", "[", "7", "]", ",", "\n", "'predict_scores'", ":", "batch", "[", "11", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "#loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)", "\n", "loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "#loss = instance_bce_with_logits(logits, batch[4])", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "\n", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "total_norm", "+=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "count_norm", "+=", "1", "\n", "\n", "# batch_score = compute_score_with_logits(logits, batch[4]).sum()", "\n", "# train_score += batch_score.item()", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "optimizer", ".", "step", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "# Log metrics", "\n", "                    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "                        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "evaluate_during_training", ":", "\n", "#if args.local_rank == -1 and args.evaluate_during_training:  # Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "logger", ".", "info", "(", "\"Epoch: %d, global_step: %d\"", "%", "(", "epoch", ",", "global_step", ")", ")", "\n", "eval_result", ",", "eval_score", ",", "upper_bound", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "                            ", "best_score", "=", "eval_score", "\n", "best_model", "[", "'epoch'", "]", "=", "epoch", "\n", "best_model", "[", "'model'", "]", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "best_score", ")", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "                        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "logging_loss", "=", "tr_loss", "\n", "\n", "#if args.max_steps > 0 and global_step > args.max_steps:", "\n", "#    epoch_iterator.close()", "\n", "#    break", "\n", "\n", "# evaluation", "\n", "", "", "", "logger", ".", "info", "(", "\"Epoch: %d, global_step: %d\"", "%", "(", "epoch", ",", "global_step", ")", ")", "\n", "eval_result", ",", "eval_score", ",", "upper_bound", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "eval_score", "\n", "best_model", "[", "'epoch'", "]", "=", "epoch", "\n", "best_model", "[", "'model'", "]", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "#best_model['optimizer'] = copy.deepcopy(optimizer.state_dict())", "\n", "\n", "# save checkpoints", "\n", "", "if", "(", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ")", "and", "(", "args", ".", "save_epoch", ">", "0", "and", "epoch", "%", "args", ".", "save_epoch", "==", "0", ")", "and", "(", "epoch", ">", "args", ".", "save_after_epoch", ")", ":", "\n", "            ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-{}-{}'", ".", "format", "(", "epoch", ",", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "model_to_save", "=", "best_model", "[", "'model'", "]", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "best_model", "[", "'model'", "]", "# Take care of distributed/parallel training", "\n", "\n", "save_num", "=", "0", "\n", "while", "(", "save_num", "<", "10", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Saving model attempt: {}\"", ".", "format", "(", "save_num", ")", ")", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "break", "\n", "", "except", ":", "\n", "                    ", "save_num", "+=", "1", "\n", "", "", "logger", ".", "info", "(", "\"Saving model checkpoint {0} to {1}\"", ".", "format", "(", "epoch", ",", "output_dir", ")", ")", "\n", "\n", "", "epoch_log", "=", "{", "'epoch'", ":", "epoch", ",", "'eval_score'", ":", "eval_score", ",", "'best_score'", ":", "best_score", "}", "\n", "log_json", ".", "append", "(", "epoch_log", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "with", "open", "(", "args", ".", "output_dir", "+", "'/eval_logs.json'", ",", "'w'", ")", "as", "fp", ":", "\n", "                ", "json", ".", "dump", "(", "log_json", ",", "fp", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"PROGRESS: {}%\"", ".", "format", "(", "round", "(", "100", "*", "(", "epoch", "+", "1", ")", "/", "args", ".", "num_train_epochs", ",", "4", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "best_score", ")", ")", "\n", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Epoch: %d, Train Time: %.3f'", "%", "(", "epoch", ",", "t_end", "-", "t_start", ")", ")", "\n", "\n", "#if args.max_steps > 0 and global_step > args.max_steps:", "\n", "#    train_iterator.close()", "\n", "#    break", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "# Save the final model checkpoint", "\n", "        ", "with", "open", "(", "args", ".", "output_dir", "+", "'/eval_logs.json'", ",", "'w'", ")", "as", "fp", ":", "\n", "            ", "json", ".", "dump", "(", "log_json", ",", "fp", ")", "\n", "\n", "", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'best-{}'", ".", "format", "(", "best_model", "[", "'epoch'", "]", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "model_to_save", "=", "best_model", "[", "'model'", "]", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "best_model", "[", "'model'", "]", "# Take care of distributed/parallel training", "\n", "\n", "save_num", "=", "0", "\n", "while", "(", "save_num", "<", "10", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "break", "\n", "", "except", ":", "\n", "                ", "save_num", "+=", "1", "\n", "", "", "logger", ".", "info", "(", "\"Saving the best model checkpoint epoch {} to {}\"", ".", "format", "(", "best_model", "[", "'epoch'", "]", ",", "output_dir", ")", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.evaluate": [[831, 975], ["time.time", "zip", "time.time", "logger.info", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "os.path.join", "os.path.exists", "print", "_pickle.load", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "max", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "open", "model.eval", "tuple", "range", "torch.stack", "torch.stack", "torch.stack", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "batch[].squeeze().detach().cpu().numpy", "torch.from_numpy().long().to", "torch.from_numpy().long().to", "torch.from_numpy().long().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.gather", "torch.gather", "torch.gather", "torch.sum().item", "torch.sum().item", "torch.sum().item", "logits.size", "torch.gather", "torch.gather", "torch.gather", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.gather", "torch.gather", "torch.gather", "torch.sum().item", "torch.sum().item", "torch.sum().item", "len", "len", "len", "len", "os.path.exists", "torch.from_numpy().long().to.append", "topk_scores.append", "t.to", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model", "torch.sigmoid.append", "tmp_eval_loss.mean().item", "torch.sigmoid.sum", "batch[].squeeze().detach().cpu", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float().to.argmax().unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sigmoid.argmax().unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "logits.view().detach", "int", "run_vqa_prompt_itm.compute_score_with_preds", "run_vqa_prompt_itm.compute_score_with_preds", "run_vqa_prompt_itm.compute_score_with_preds", "tmp_eval_loss.mean", "batch[].squeeze().detach", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().float().to.argmax", "torch.sigmoid.argmax", "logits.view", "numpy.stack", "numpy.stack", "batch[].squeeze"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.compute_score_with_preds", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.compute_score_with_preds", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.compute_score_with_preds"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", "=", "None", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "'-MM'", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "#if args.n_gpu > 1: model = torch.nn.DataParallel(model) # debug: single-gpu or multi-gpus", "\n", "\n", "results", "=", "[", "]", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "num_workers", "=", "args", ".", "workers", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "num_data", "=", "0", "\n", "score", "=", "0", "\n", "score_mat", "=", "0", "\n", "score_all", "=", "0", "\n", "upper_bound", "=", "0", "\n", "results_dict", "=", "{", "}", "\n", "\n", "stage1_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"stage1_eval.pkl\"", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "stage1_path", ")", "\n", "print", "(", "\"loading labels from stage1...\"", ")", "\n", "eval_dataset", ".", "stage1_dict", "=", "cPickle", ".", "load", "(", "open", "(", "stage1_path", ",", "\"rb\"", ")", ")", "\n", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "templates", "=", "batch", "[", "8", "]", "\n", "templates_mask", "=", "batch", "[", "9", "]", "\n", "templates_segment", "=", "batch", "[", "10", "]", "\n", "mat_logits", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "templates", ".", "shape", "[", "1", "]", ")", ":", "\n", "                ", "temp", "=", "templates", "[", ":", ",", "i", "]", "\n", "temp_mask", "=", "templates_mask", "[", ":", ",", "i", "]", "\n", "temp_segment", "=", "templates_segment", "[", ":", ",", "i", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "inputs", "=", "{", "'input_ids'", ":", "temp", ",", "\n", "'attention_mask'", ":", "temp_mask", ",", "\n", "'token_type_ids'", ":", "temp_segment", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "batch", "[", "4", "]", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", ",", "\n", "'mask_index'", ":", "batch", "[", "7", "]", ",", "\n", "'predict_scores'", ":", "batch", "[", "11", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "mat_logits", ".", "append", "(", "logits", ".", "view", "(", "-", "1", ")", ".", "detach", "(", ")", ")", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "", "mat_logits", "=", "torch", ".", "stack", "(", "mat_logits", ",", "dim", "=", "-", "1", ")", "# [B, K]", "\n", "mat_logits", "=", "torch", ".", "sigmoid", "(", "mat_logits", ")", "\n", "mat_logits", "=", "mat_logits", "/", "(", "mat_logits", ".", "sum", "(", "-", "1", ",", "keepdim", "=", "True", ")", "+", "1e-6", ")", "\n", "\n", "q_ids", "=", "batch", "[", "6", "]", ".", "squeeze", "(", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "topk_indexes", ",", "topk_scores", "=", "[", "]", ",", "[", "]", "\n", "for", "q_id", "in", "q_ids", ":", "\n", "                ", "temp", "=", "eval_dataset", ".", "stage1_dict", "[", "int", "(", "q_id", ")", "]", "\n", "topk_indexes", ".", "append", "(", "temp", "[", "0", "]", ")", "\n", "topk_scores", ".", "append", "(", "temp", "[", "1", "]", ")", "\n", "", "topk_indexes", "=", "torch", ".", "from_numpy", "(", "np", ".", "stack", "(", "topk_indexes", ",", "axis", "=", "0", ")", ")", ".", "long", "(", ")", ".", "to", "(", "\"cuda\"", ")", "# [B, K]", "\n", "cls_logits", "=", "torch", ".", "from_numpy", "(", "np", ".", "stack", "(", "topk_scores", ",", "axis", "=", "0", ")", ")", ".", "float", "(", ")", ".", "to", "(", "\"cuda\"", ")", "# [B, K]", "\n", "\n", "preds_cls", "=", "torch", ".", "gather", "(", "\n", "input", "=", "topk_indexes", ",", "\n", "dim", "=", "1", ",", "\n", "index", "=", "cls_logits", ".", "argmax", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "\n", "score", "+=", "torch", ".", "sum", "(", "compute_score_with_preds", "(", "preds_cls", ",", "batch", "[", "4", "]", ")", ")", ".", "item", "(", ")", "\n", "num_data", "+=", "logits", ".", "size", "(", "0", ")", "\n", "\n", "preds_mat", "=", "torch", ".", "gather", "(", "\n", "input", "=", "topk_indexes", ",", "\n", "dim", "=", "1", ",", "\n", "index", "=", "mat_logits", ".", "argmax", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# [B, 1]", "\n", "score_mat", "+=", "torch", ".", "sum", "(", "compute_score_with_preds", "(", "preds_mat", ",", "batch", "[", "4", "]", ")", ")", ".", "item", "(", ")", "\n", "\n", "preds_all", "=", "torch", ".", "gather", "(", "\n", "input", "=", "topk_indexes", ",", "\n", "dim", "=", "1", ",", "\n", "index", "=", "(", "mat_logits", "+", "cls_logits", ")", ".", "argmax", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "\n", "score_all", "+=", "torch", ".", "sum", "(", "compute_score_with_preds", "(", "preds_all", ",", "batch", "[", "4", "]", ")", ")", ".", "item", "(", ")", "\n", "\n", "nb_eval_steps", "+=", "1", "\n", "\n", "#if preds is None:", "\n", "#    preds = logits.detach().cpu().numpy()", "\n", "#    out_label_ids = inputs['labels'].detach().cpu().numpy()", "\n", "#else:", "\n", "#    preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)", "\n", "#    out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)", "\n", "\n", "", "score", "=", "score", "/", "len", "(", "eval_dataloader", ".", "dataset", ")", "\n", "score_mat", "=", "score_mat", "/", "len", "(", "eval_dataloader", ".", "dataset", ")", "\n", "score_all", "=", "score_all", "/", "len", "(", "eval_dataloader", ".", "dataset", ")", "\n", "upper_bound", "=", "upper_bound", "/", "len", "(", "eval_dataloader", ".", "dataset", ")", "\n", "\n", "logger", ".", "info", "(", "\"Eval Results:\"", ")", "\n", "logger", ".", "info", "(", "\"Eval Score: %.3f\"", "%", "(", "100", "*", "score", ")", ")", "\n", "logger", ".", "info", "(", "\"Eval_mat Score: %.3f\"", "%", "(", "100", "*", "score_mat", ")", ")", "\n", "logger", ".", "info", "(", "\"Eval_all Score: %.3f\"", "%", "(", "100", "*", "score_all", ")", ")", "\n", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "score", ")", ")", "\n", "logger", ".", "info", "(", "\"Eval Upper Bound: %.3f\"", "%", "(", "100", "*", "upper_bound", ")", ")", "\n", "# with open(os.path.join(args.data_dir, 'val_results.json'),", "\n", "#           'w') as f:", "\n", "#     json.dump(results_dict, f)", "\n", "\n", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Eva Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "#eval_loss = eval_loss / nb_eval_steps", "\n", "#if args.output_mode == \"classification\":", "\n", "#    preds = np.argmax(preds, axis=1)", "\n", "#elif args.output_mode == \"regression\":", "\n", "#    preds = np.squeeze(preds)", "\n", "#result = compute_metrics(eval_task, preds, out_label_ids)", "\n", "#results.update(result)", "\n", "\n", "#output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")", "\n", "#with open(output_eval_file, \"w\") as writer:", "\n", "#    logger.info(\"***** Eval results {} *****\".format(prefix))", "\n", "#    for key in sorted(result.keys()):", "\n", "#        logger.info(\"  %s = %s\", key, str(result[key]))", "\n", "#        writer.write(\"%s = %s\\n\" % (key, str(result[key])))", "\n", "\n", "return", "results", ",", "max", "(", "score", ",", "score_mat", ",", "score_all", ")", ",", "upper_bound", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.test": [[977, 1035], ["_pickle.load", "logger.info", "time.time", "zip", "time.time", "logger.info", "logger.info", "open", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "open", "json.dump", "len", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "model.eval", "tuple", "len", "os.path.exists", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model", "logits.max", "range", "t.to", "idx.size", "[].item", "results.append", "logger.info", "len", "round", "idx[].item", "len", "len"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "test", "(", "args", ",", "model", ",", "eval_dataset", "=", "None", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "'-MM'", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "label2ans", "=", "cPickle", ".", "load", "(", "open", "(", "args", ".", "label2ans_file", ",", "'rb'", ")", ")", "\n", "logger", ".", "info", "(", "'label2ans: %d'", "%", "(", "len", "(", "label2ans", ")", ")", ")", "\n", "\n", "results", "=", "[", "]", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval", "\n", "logger", ".", "info", "(", "\"***** Running Test {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "#for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "None", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", ",", "\n", "'mask_index'", ":", "batch", "[", "7", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "logits", "=", "outputs", "[", "0", "]", "\n", "\n", "val", ",", "idx", "=", "logits", ".", "max", "(", "1", ")", "\n", "#logger.info('idx: %s, batch[6]: %s' % (str(idx.shape), str(batch[6].shape)))", "\n", "\n", "for", "i", "in", "range", "(", "idx", ".", "size", "(", "0", ")", ")", ":", "\n", "#logger.info('idx: %d, batch: %d' % (idx[i].item(), batch[6][i].item()))", "\n", "                    ", "result", "=", "{", "}", "\n", "result", "[", "'question_id'", "]", "=", "batch", "[", "6", "]", "[", "i", "]", ".", "item", "(", ")", "\n", "result", "[", "'answer'", "]", "=", "label2ans", "[", "eval_dataset", ".", "labels", "[", "idx", "[", "i", "]", ".", "item", "(", ")", "]", "]", "#label2ans[idx[i].item()]", "\n", "results", ".", "append", "(", "result", ")", "\n", "\n", "if", "len", "(", "results", ")", "%", "2000", "==", "0", ":", "\n", "                        ", "logger", ".", "info", "(", "\"PROGRESS: {}%\"", ".", "format", "(", "round", "(", "100", "*", "len", "(", "results", ")", "/", "len", "(", "eval_dataset", ")", ",", "4", ")", ")", ")", "\n", "#logger.info('q_id: {0}, answer: {1}'.format(result['question_id'], result['answer']))", "\n", "\n", "", "", "", "", "", "with", "open", "(", "args", ".", "output_dir", "+", "(", "'/{}_results.json'", ".", "format", "(", "eval_dataset", ".", "name", ")", ")", ",", "'w'", ")", "as", "fp", ":", "\n", "        ", "json", ".", "dump", "(", "results", ",", "fp", ")", "\n", "\n", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'# questions: %d'", "%", "(", "len", "(", "results", ")", ")", ")", "\n", "logger", ".", "info", "(", "'Test Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.load_and_cache_examples": [[1037, 1102], ["processor.get_labels", "time.time", "numpy.load", "oscar.utils.task_utils.convert_examples_to_features_vqa", "time.time", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "processor.get_dev_examples", "processor.get_train_examples", "os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "print", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "bool", "bool", "time.time", "numpy.zeros", "enumerate", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "time.time", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "run_vqa_prompt_itm.target_tensor", "len"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.convert_examples_to_features_vqa", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.target_tensor"], ["", "def", "load_and_cache_examples", "(", "args", ",", "task", ",", "tokenizer", ",", "evaluate", "=", "False", ")", ":", "\n", "    ", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "output_mode", "=", "output_modes", "[", "task", "]", "\n", "\n", "label_list", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ")", "if", "evaluate", "else", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ")", "\n", "\n", "#img_features = torch.load(os.path.join(args.data_dir, 'val_img_feats.pt' if evaluate else 'train_img_feats.pt'))", "\n", "#img_features = torch.load(os.path.join(args.data_dir, 'val_img_frcnn_feats.pt' if evaluate else 'train_img_frcnn_feats.pt'))", "\n", "img_features", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'val_img_frcnn_feats.npy'", "if", "evaluate", "else", "'train_img_frcnn_feats.npy'", ")", ")", "\n", "\n", "features", "=", "convert_examples_to_features_vqa", "(", "examples", ",", "img_features", ",", "label_list", ",", "args", ".", "max_img_seq_length", ",", "args", ".", "max_seq_length", ",", "\n", "tokenizer", ",", "output_mode", ",", "\n", "cls_token_at_end", "=", "bool", "(", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "\n", "#if args.local_rank in [-1, 0]:", "\n", "#    logger.info(\"Saving features into cached file %s\", cached_features_file)", "\n", "#    torch.save(features, cached_features_file)", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: loading features using %.5f secs'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "# batch*max_seq_len", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "        ", "labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "[", "0", "]", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "targets", "=", "torch", ".", "tensor", "(", "[", "target_tensor", "(", "len", "(", "label_list", ")", ",", "f", ".", "label_id", ",", "f", ".", "score", ")", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "if", "args", ".", "img_feature_dim", ">", "0", ":", "# change here", "\n", "            ", "t_start", "=", "time", ".", "time", "(", ")", "\n", "img_feat_np", "=", "np", ".", "zeros", "(", "(", "labels", ".", "shape", "[", "0", "]", ",", "args", ".", "max_img_seq_length", ",", "args", ".", "img_feature_dim", ")", ")", "\n", "for", "f_id", ",", "f", "in", "enumerate", "(", "features", ")", ":", "\n", "                ", "img_feat_np", "[", "f_id", "]", "=", "f", ".", "img_feat", "\n", "\n", "", "img_feats", "=", "torch", ".", "from_numpy", "(", "img_feat_np", ")", "\n", "\n", "#img_feats = torch.empty((labels.shape[0], args.max_img_seq_length, args.img_feature_dim))", "\n", "#for f_id, f in enumerate(features):", "\n", "#   img_feats[f_id] = f.img_feat", "\n", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: convert image tensor features using %.5f secs'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "#img_feats = torch.stack([f.img_feat[:,-args.img_feature_dim:] for f in features])", "\n", "#img_feats = torch.stack([f.img_feat for f in features])", "\n", "#img_feats = img_feats.type(torch.long)", "\n", "\n", "#print('targets:', targets.shape)", "\n", "", "print", "(", "'img_feats:'", ",", "img_feats", ".", "shape", ")", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "        ", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "if", "args", ".", "img_feature_dim", "==", "-", "1", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "labels", ",", "targets", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "labels", ",", "targets", ",", "img_feats", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.target_tensor": [[1103, 1110], ["enumerate"], "function", ["None"], ["", "def", "target_tensor", "(", "len", ",", "labels", ",", "scores", ")", ":", "\n", "    ", "\"\"\" create the target by labels and scores \"\"\"", "\n", "target", "=", "[", "0", "]", "*", "len", "\n", "for", "id", ",", "l", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "target", "[", "l", "]", "=", "scores", "[", "id", "]", "\n", "\n", "", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa_prompt_itm.main": [[1112, 1417], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "oscar.utils.misc.set_seed", "parser.parse_args.task_name.lower", "processor.get_labels", "len", "logger.info", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "run_vqa_prompt_itm.VQADataset", "logger.info", "os.path.join", "logger.info", "os.path.exists", "os.listdir", "logger.info", "logger.info", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.device", "torch.device", "torch.device", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "bool", "ValueError", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "logger.info", "time.time", "torch.load", "torch.load", "torch.load", "time.time", "logger.info", "logger.info", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "run_vqa_prompt_itm.VQADataset", "run_vqa_prompt_itm.VQADataset", "run_vqa_prompt_itm.VQADataset", "run_vqa_prompt_itm.train", "logger.info", "run_vqa_prompt_itm.VQADataset", "run_vqa_prompt_itm.train", "logger.info", "logger.info", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "torch.save", "torch.save", "logger.info", "logger.info", "logger.info", "os.getenv", "os.path.join", "bool", "model_class.from_pretrained.init_code_embedding", "os.makedirs", "os.path.join", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_vqa_prompt_itm.evaluate", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_vqa_prompt_itm.test", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_vqa_prompt_itm.test", "train_code[].t", "model_class.from_pretrained.init_code_embedding", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.distributed.get_rank", "os.path.exists", "MODEL_CLASSES.keys", "oscar.utils.task_utils.processors.keys", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "train_code[].t", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "sorted", "sorted", "sorted", "glob.glob", "glob.glob", "glob.glob", "list", "train_code[].keys", "list", "train_code[].keys"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.ImageBertForSequenceClassification.init_code_embedding", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.test", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.test", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.ImageBertForSequenceClassification.init_code_embedding", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the .tsv files (or other data files) for the task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--txt_data_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input text data dir. Should contain the .json files (or other data files) for the task.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--task_name\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train selected in the list: \"", "+", "\", \"", ".", "join", "(", "processors", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--label_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Label Dictionary\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--label2ans_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Label to Answer Dictionary\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--img_feat_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"The input img_feat_dir.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feat_format\"", ",", "default", "=", "'pt'", ",", "type", "=", "str", ",", "help", "=", "\"img_feat_format: pt or tsv.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--data_label_type\"", ",", "default", "=", "'faster'", ",", "type", "=", "str", ",", "help", "=", "\"faster or mask\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--loss_type\"", ",", "default", "=", "'kl'", ",", "type", "=", "str", ",", "help", "=", "\"kl or xe\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_vg\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use VG-QA or not.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_vg_dev\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use VG-QA as validation.\"", ")", "\n", "#parser.add_argument(\"--use_img_layernorm\", action='store_true', help=\"use_img_layernorm\")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer than this will be truncated, sequences shorter will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train_val\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run test on the test set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test_dev\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run test on the test-dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Rul evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--drop_out\"", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "\"Drop out for BERT.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adjust_dp\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Adjust Drop out for BERT.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--adjust_loss\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Adjust Loss Type for BERT.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adjust_loss_epoch\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "help", "=", "\"Adjust Loss Type for BERT.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--classifier\"", ",", "default", "=", "'linear'", ",", "type", "=", "str", ",", "help", "=", "\"linear or mlp\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cls_hidden_scale\"", ",", "default", "=", "2", ",", "type", "=", "int", ",", "help", "=", "\"cls_hidden_scale: for classifier\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--hard_label\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Soft Label or Hard Label.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_img_seq_length\"", ",", "default", "=", "30", ",", "type", "=", "int", ",", "help", "=", "\"The maximum total input image sequence length.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_dim\"", ",", "default", "=", "2054", ",", "type", "=", "int", ",", "help", "=", "\"The Image Feature Dimension.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_type\"", ",", "default", "=", "'faster_r-cnn'", ",", "type", "=", "str", ",", "help", "=", "\"faster_r-cnn or mask_r-cnn\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_voc\"", ",", "default", "=", "512", ",", "type", "=", "int", ",", "help", "=", "\"dis_code_voc: 256, 512\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_level\"", ",", "default", "=", "'top'", ",", "type", "=", "str", ",", "help", "=", "\"code level: top, botttom, both\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--scheduler\"", ",", "default", "=", "'linear'", ",", "type", "=", "str", ",", "help", "=", "\"constant or linear.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_epoch'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "\"Save checkpoint every X epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_after_epoch'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"Save checkpoint after epoch.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_output_dir'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_cache'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_ip'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_port'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--philly\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use Philly: reset the output dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--load_fast\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Load Tensor Fast\"", ")", "\n", "parser", ".", "add_argument", "(", "'-j'", ",", "'--workers'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "help", "=", "'number of data loading workers (default: 4)'", ")", "\n", "\n", "#args = '--data_dir ../vqa/ban-vqa/data/qal_pairs --model_type bert --model_name_or_path bert-base-uncased --task_name vqa_text ' \\", "\n", "#       '--do_train --do_eval --do_lower_case --max_seq_length 40 --per_gpu_eval_batch_size 16 --per_gpu_train_batch_size 16 --learning_rate 2e-5 ' \\", "\n", "#       '--num_train_epochs 20.0 --output_dir ./results/vqa_text --label_file ../vqa/ban-vqa/data/cache/trainval_ans2label.pkl ' \\", "\n", "#       '--save_steps 5000 --overwrite_output_dir --max_img_seq_length 1 --img_feature_dim 565 --img_feature_type dis_code '", "\n", "\n", "#args = '--data_dir ../vqa/ban-vqa/data/qal_pairs --model_type bert --model_name_or_path bert-base-uncased --task_name vqa_text ' \\", "\n", "#       '--do_train --do_eval --do_lower_case --max_seq_length 40 --per_gpu_eval_batch_size 16 --per_gpu_train_batch_size 16 --learning_rate 2e-5 ' \\", "\n", "#       '--num_train_epochs 20.0 --output_dir ./results/vqa_text --label_file ../vqa/ban-vqa/data/cache/trainval_ans2label.pkl ' \\", "\n", "#       '--save_steps 5000 --overwrite_output_dir --max_img_seq_length 10 --img_feature_dim 565 --img_feature_type other '", "\n", "\n", "#args = parser.parse_args(args.split())", "\n", "# \u89e3\u6790\u53c2\u6570", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "philly", ":", "# use philly", "\n", "        ", "logger", ".", "info", "(", "'Info: Use Philly, all the output folders are reset.'", ")", "\n", "args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "getenv", "(", "'PT_OUTPUT_DIR'", ")", ",", "args", ".", "output_dir", ")", "\n", "logger", ".", "info", "(", "'OUTPUT_DIR:'", ",", "args", ".", "output_dir", ")", "\n", "\n", "#if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train and not args.overwrite_output_dir:", "\n", "#    raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args.output_dir))", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", ":", "logger", ".", "info", "(", "\"Output Directory Exists.\"", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "logger", ".", "info", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# \u8bbe\u7f6ecuda", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s - %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "# Set seed", "\n", "# \u8bbe\u7f6e\u968f\u673a\u79cd\u5b50", "\n", "set_seed", "(", "args", ".", "seed", ",", "args", ".", "n_gpu", ")", "\n", "\n", "# Prepare GLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "\n", "# \u521d\u59cb\u5316\u6570\u636e\u96c6\u7684\u521d\u59cb\u5316\u5bf9\u8c61\uff0c\u8f7d\u5165\u7b54\u6848\u6620\u5c04\u5b57\u5178", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "args", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "# \"classification\"", "\n", "label_list", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "logger", ".", "info", "(", "'Task Name: {}, #Labels: {}'", ".", "format", "(", "args", ".", "task_name", ",", "num_labels", ")", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "\n", "# discrete code", "\n", "config", ".", "img_feature_dim", "=", "args", ".", "img_feature_dim", "# 2054", "\n", "config", ".", "img_feature_type", "=", "args", ".", "img_feature_type", "# faster_r-cnn", "\n", "config", ".", "code_voc", "=", "args", ".", "code_voc", "# 512", "\n", "config", ".", "hidden_dropout_prob", "=", "args", ".", "drop_out", "# 0.3", "\n", "config", ".", "loss_type", "=", "args", ".", "loss_type", "# bce", "\n", "config", ".", "classifier", "=", "args", ".", "classifier", "# linear", "\n", "config", ".", "cls_hidden_scale", "=", "args", ".", "cls_hidden_scale", "# 3", "\n", "#config.use_img_layernorm = args.use_img_layernorm", "\n", "\n", "# load discrete code", "\n", "if", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "'Load discrete code from: {}'", ".", "format", "(", "args", ".", "data_dir", ")", ")", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "train_code", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'vqvae'", ",", "'train.pt'", ")", ")", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Load time: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "if", "args", ".", "code_level", "==", "'top'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_t'", "]", ".", "shape", "[", "0", "]", "\n", "config", ".", "code_size", "=", "train_code", "[", "'feats_top'", "]", "[", "list", "(", "train_code", "[", "'feats_top'", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "shape", "[", "0", "]", "\n", "", "elif", "args", ".", "code_level", "==", "'bottom'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_b'", "]", ".", "shape", "[", "0", "]", "\n", "config", ".", "code_size", "=", "train_code", "[", "'feats_bottom'", "]", "[", "list", "(", "train_code", "[", "'feats_bottom'", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "shape", "[", "0", "]", "\n", "", "elif", "args", ".", "code_level", "==", "'both'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_t'", "]", ".", "shape", "[", "0", "]", "+", "train_code", "[", "'embeddings_b'", "]", ".", "shape", "[", "0", "]", "\n", "\n", "\n", "# \u4f7f\u7528\u9884\u8bad\u7ec3\u53c2\u6570\u521d\u59cb\u5316\u6a21\u578b", "\n", "", "", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "from_tf", "=", "bool", "(", "'.ckpt'", "in", "args", ".", "model_name_or_path", ")", ",", "config", "=", "config", ")", "\n", "if", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "'Initializing the code embedding with {}'", ".", "format", "(", "args", ".", "code_level", ")", ")", "\n", "if", "args", ".", "code_level", "==", "'top'", ":", "\n", "            ", "model", ".", "init_code_embedding", "(", "train_code", "[", "'embeddings_t'", "]", ".", "t", "(", ")", ")", "\n", "", "elif", "args", ".", "code_level", "==", "'bottom'", ":", "\n", "            ", "model", ".", "init_code_embedding", "(", "train_code", "[", "'embeddings_b'", "]", ".", "t", "(", ")", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# \u521d\u59cb\u5316\u6570\u636e\u96c6", "\n", "#if args.do_eval:", "\n", "eval_dataset", "=", "VQADataset", "(", "args", ",", "'val'", ",", "tokenizer", ")", "\n", "\n", "if", "args", ".", "do_test", ":", "\n", "        ", "test_dataset", "=", "VQADataset", "(", "args", ",", "'test2015'", ",", "tokenizer", ")", "\n", "\n", "", "if", "args", ".", "do_test_dev", ":", "\n", "        ", "test_dev_dataset", "=", "VQADataset", "(", "args", ",", "'test-dev2015'", ",", "tokenizer", ")", "\n", "\n", "# Training", "\n", "", "if", "args", ".", "do_train", ":", "\n", "#train_dataset = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False)", "\n", "        ", "train_dataset", "=", "VQADataset", "(", "args", ",", "'train'", ",", "tokenizer", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Training on train+val", "\n", "", "if", "args", ".", "do_train_val", ":", "\n", "        ", "train_dataset", "=", "VQADataset", "(", "args", ",", "'train+val'", ",", "tokenizer", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`. They can then be reloaded using `from_pretrained()`", "\n", "#model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training", "\n", "#model_to_save.save_pretrained(args.output_dir)", "\n", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "#model = model_class.from_pretrained(args.output_dir)", "\n", "#tokenizer = tokenizer_class.from_pretrained(args.output_dir)", "\n", "#model.to(args.device)", "\n", "\n", "\n", "# Evaluation", "\n", "#results = {}", "\n", "", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ",", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "score", ",", "upper_bound", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "#result = dict((k + '_{}'.format(global_step), v) for k, v in result.items())", "\n", "#results.update(result)", "\n", "\n", "# Test-Dev", "\n", "", "", "if", "args", ".", "do_test_dev", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "test", "(", "args", ",", "model", ",", "test_dev_dataset", ",", "prefix", "=", "global_step", ")", "\n", "\n", "# Test", "\n", "", "", "if", "args", ".", "do_test", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "test", "(", "args", ",", "model", ",", "test_dataset", ",", "prefix", "=", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_nlvr.NLVRDataset.__init__": [[117, 131], ["torch.utils.data.Dataset.__init__", "run_nlvr._load_dataset", "logger.info", "enumerate", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few._load_dataset"], ["def", "__init__", "(", "self", ",", "args", ",", "name", ",", "img_features", ",", "tokenizer", ")", ":", "\n", "        ", "super", "(", "NLVRDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "name", "in", "[", "'train'", ",", "'val'", ",", "'test1'", ",", "'val+test1'", "]", "\n", "\n", "self", ".", "img_features", "=", "img_features", "\n", "self", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "name", "=", "name", "\n", "\n", "self", ".", "examples", ",", "self", ".", "labels", "=", "_load_dataset", "(", "args", ",", "name", ")", "\n", "self", ".", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "self", ".", "labels", ")", "}", "\n", "\n", "logger", ".", "info", "(", "'%s Data Examples: %d'", "%", "(", "name", ",", "len", "(", "self", ".", "examples", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_nlvr.NLVRDataset.tensorize_example": [[132, 245], ["run_nlvr.NLVRDataset.tokenizer.tokenize", "run_nlvr.NLVRDataset.tokenizer.convert_tokens_to_ids", "run_nlvr.NLVRDataset.args.img_feature_type.startswith", "run_nlvr.NLVRDataset.tokenizer.tokenize", "oscar.utils.task_utils._truncate_seq_pair", "len", "len", "len", "len", "len", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "img_feat.type.type.type", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "img_feat.type.type.reshape", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KeyError", "img_feat.type.type.type", "len", "len", "float"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv._truncate_seq_pair"], ["", "def", "tensorize_example", "(", "self", ",", "example", ",", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "\n", "        ", "tokens_a", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "            ", "text_b", "=", "example", ".", "text_b", "[", "'left'", "]", "+", "' '", "+", "example", ".", "text_b", "[", "'right'", "]", "\n", "tokens_b", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "text_b", ")", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "self", ".", "args", ".", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "            ", "if", "len", "(", "tokens_a", ")", ">", "self", ".", "args", ".", "max_seq_length", "-", "2", ":", "\n", "                ", "tokens_a", "=", "tokens_a", "[", ":", "(", "self", ".", "args", ".", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "", "tokens", "=", "tokens_a", "+", "[", "sep_token", "]", "\n", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "            ", "tokens", "+=", "tokens_b", "+", "[", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "if", "cls_token_at_end", ":", "\n", "            ", "tokens", "=", "tokens", "+", "[", "cls_token", "]", "\n", "segment_ids", "=", "segment_ids", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "            ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "self", ".", "args", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "segment_ids", "=", "segment_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "\n", "# image features", "\n", "if", "self", ".", "args", ".", "img_feature_type", ".", "startswith", "(", "'dis_code'", ")", ":", "\n", "            ", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "\n", "\n", "if", "self", ".", "args", ".", "img_feature_type", "==", "'dis_code_ln'", ":", "# for discrete code image representation", "\n", "                ", "img_feat", "=", "img_feat", ".", "reshape", "(", "-", "1", ",", "img_feat", ".", "shape", "[", "0", "]", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "img_feature_type", "==", "'dis_code_t'", ":", "# transposed", "\n", "                ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "64", "\n", "", "else", ":", "\n", "                ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "", "", "else", ":", "\n", "            ", "img_key_left", "=", "example", ".", "img_key", "[", "'left'", "]", "\n", "img_key_right", "=", "example", ".", "img_key", "[", "'right'", "]", "\n", "img_feat_left", "=", "self", ".", "img_features", "[", "img_key_left", "]", "\n", "img_feat_right", "=", "self", ".", "img_features", "[", "img_key_right", "]", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat_left", ",", "img_feat_right", ")", ",", "0", ")", "\n", "if", "img_feat", ".", "shape", "[", "0", "]", ">", "2", "*", "self", ".", "args", ".", "max_img_seq_length", ":", "\n", "                ", "img_feat", "=", "img_feat", "[", "0", ":", "2", "*", "self", ".", "args", ".", "max_img_seq_length", ",", "]", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids += [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids = segment_ids + [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "2", "*", "self", ".", "args", ".", "max_img_seq_length", "-", "img_feat", ".", "shape", "[", "0", "]", ",", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_matrix", ".", "shape", "[", "0", "]", ")", "\n", "# segment_ids = segment_ids + [pad_token_segment_id] * padding_matrix.shape[0]", "\n", "\n", "", "", "", "if", "self", ".", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "if", "(", "example", ".", "label", "is", "None", ")", ":", "\n", "                ", "label_id", "=", "[", "0", "]", "\n", "score", "=", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "label_id", "=", "[", "example", ".", "label", "]", "#[self.label_map[l] for l in example.label]", "\n", "score", "=", "example", ".", "score", "\n", "", "", "elif", "self", ".", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "if", "len", "(", "example", ".", "label", ")", "==", "0", ":", "\n", "                ", "label_id", "=", "0", "\n", "", "else", ":", "\n", "                ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "self", ".", "args", ".", "output_mode", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "            ", "img_feat", "=", "img_feat", ".", "type", "(", "torch", ".", "long", ")", "\n", "", "elif", "self", ".", "args", ".", "img_feature_type", "in", "[", "'dis_code_ln'", "]", ":", "\n", "#img_feat = img_feat.reshape(-1, img_feat.shape[0])", "\n", "            ", "img_feat", "=", "img_feat", ".", "type", "(", "torch", ".", "float", ")", "\n", "\n", "", "return", "(", "torch", ".", "tensor", "(", "input_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "label_id", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "img_feat", ",", "\n", "torch", ".", "tensor", "(", "[", "example", ".", "q_id", "]", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_nlvr.NLVRDataset.tensorize_example_pair": [[246, 352], ["run_nlvr.NLVRDataset.tokenizer.tokenize", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "run_nlvr.NLVRDataset.tokenizer.convert_tokens_to_ids", "choices.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "run_nlvr.NLVRDataset.tokenizer.tokenize", "oscar.utils.task_utils._truncate_seq_pair", "len", "len", "len", "len", "len", "len", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KeyError", "len", "len", "float", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv._truncate_seq_pair"], ["", "def", "tensorize_example_pair", "(", "self", ",", "example", ",", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "\n", "        ", "tokens_a", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "choices", "=", "[", "]", "\n", "for", "choice_key", "in", "example", ".", "img_key", ":", "\n", "            ", "tokens_b", "=", "None", "\n", "\n", "if", "example", ".", "text_b", ":", "\n", "#tokens_b = self.tokenizer.tokenize(example.text_b[choice_key])", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "#_truncate_seq_pair(tokens_a, tokens_b, self.args.max_seq_length - 3)", "\n", "\n", "                ", "tokens_b", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_b", "[", "choice_key", "]", ")", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "self", ".", "args", ".", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "                ", "if", "len", "(", "tokens_a", ")", ">", "self", ".", "args", ".", "max_seq_length", "-", "2", ":", "\n", "                    ", "tokens_a", "=", "tokens_a", "[", ":", "(", "self", ".", "args", ".", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "", "tokens", "=", "tokens_a", "+", "[", "sep_token", "]", "\n", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "                ", "tokens", "+=", "tokens_b", "+", "[", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "if", "cls_token_at_end", ":", "\n", "                ", "tokens", "=", "tokens", "+", "[", "cls_token", "]", "\n", "segment_ids", "=", "segment_ids", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "                ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "self", ".", "args", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "                ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "", "else", ":", "\n", "                ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "segment_ids", "=", "segment_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "\n", "# img", "\n", "img_key", "=", "example", ".", "img_key", "[", "choice_key", "]", "\n", "img_feat", "=", "self", ".", "img_features", "[", "img_key", "]", "\n", "\n", "if", "img_feat", ".", "shape", "[", "0", "]", ">", "self", ".", "args", ".", "max_img_seq_length", ":", "\n", "                ", "img_feat", "=", "img_feat", "[", "0", ":", "self", ".", "args", ".", "max_img_seq_length", ",", "]", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids += [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids = segment_ids + [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "self", ".", "args", ".", "max_img_seq_length", "-", "img_feat", ".", "shape", "[", "0", "]", ",", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_matrix", ".", "shape", "[", "0", "]", ")", "\n", "# segment_ids = segment_ids + [pad_token_segment_id] * padding_matrix.shape[0]", "\n", "\n", "", "", "choices", ".", "append", "(", "(", "tokens", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "img_feat", ")", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "if", "example", ".", "label", "is", "None", ":", "\n", "                ", "label_id", "=", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "label_id", "=", "[", "example", ".", "label", "]", "#[self.label_map[l] for l in example.label]", "\n", "", "", "elif", "self", ".", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "if", "len", "(", "example", ".", "label", ")", "==", "0", ":", "\n", "                ", "label_id", "=", "0", "\n", "", "else", ":", "\n", "                ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "self", ".", "args", ".", "output_mode", ")", "\n", "\n", "", "choice_input_ids", "=", "[", "choice", "[", "1", "]", "for", "choice", "in", "choices", "]", "\n", "choice_input_mask", "=", "[", "choice", "[", "2", "]", "for", "choice", "in", "choices", "]", "\n", "choice_input_segs", "=", "[", "choice", "[", "3", "]", "for", "choice", "in", "choices", "]", "\n", "choice_input_imgs", "=", "[", "choice", "[", "4", "]", "for", "choice", "in", "choices", "]", "\n", "\n", "choice_img_feats", "=", "torch", ".", "stack", "(", "choice_input_imgs", ")", "\n", "\n", "return", "(", "torch", ".", "tensor", "(", "choice_input_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "choice_input_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "choice_input_segs", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "label_id", "[", "0", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "choice_img_feats", ",", "\n", "torch", ".", "tensor", "(", "[", "example", ".", "q_id", "]", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_nlvr.NLVRDataset.__getitem__": [[353, 372], ["run_nlvr.NLVRDataset.tensorize_example_pair", "run_nlvr.NLVRDataset.tensorize_example", "bool", "bool", "bool", "bool"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_nlvr.NLVRDataset.tensorize_example_pair", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize_example"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "entry", "=", "self", ".", "examples", "[", "index", "]", "\n", "if", "self", ".", "args", ".", "use_pair", ":", "\n", "            ", "example", "=", "self", ".", "tensorize_example_pair", "(", "entry", ",", "\n", "cls_token_at_end", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "self", ".", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "", "else", ":", "\n", "            ", "example", "=", "self", ".", "tensorize_example", "(", "entry", ",", "\n", "cls_token_at_end", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "self", ".", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_nlvr.NLVRDataset.__len__": [[373, 375], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_nlvr._load_dataset": [[68, 97], ["processor.get_labels", "processor.get_train_examples", "processor.get_dev_examples", "processor.get_dev_examples", "processor.get_dev_examples", "processor.get_test_examples", "processor.get_test_examples", "processor.get_test_examples", "processor.get_dev_examples", "processor.get_dev_examples", "processor.get_dev_examples"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples"], ["def", "_load_dataset", "(", "args", ",", "name", ")", ":", "\n", "    ", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "labels", "=", "processor", ".", "get_labels", "(", ")", "\n", "\n", "if", "name", "==", "'train'", ":", "\n", "        ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "args", ".", "use_label_seq", ",", "'nlvr2_train.json'", ")", "\n", "", "elif", "name", "==", "'val'", ":", "\n", "        ", "if", "args", ".", "eval_data_type", "==", "'bal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "args", ".", "use_label_seq", ",", "'nlvr2_balanced_dev.json'", ")", "\n", "", "elif", "args", ".", "eval_data_type", "==", "'unbal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "args", ".", "use_label_seq", ",", "'nlvr2_unbalanced_dev.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "args", ".", "use_label_seq", ",", "'nlvr2_dev.json'", ")", "\n", "", "", "elif", "name", "==", "'test1'", ":", "# test-submission", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'bal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "args", ".", "use_label_seq", ",", "'nlvr2_balanced_test1.json'", ")", "\n", "", "elif", "args", ".", "eval_data_type", "==", "'unbal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "args", ".", "use_label_seq", ",", "'nlvr2_unbalanced_test1.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "args", ".", "use_label_seq", ",", "'nlvr2_test1.json'", ")", "\n", "", "", "elif", "name", "==", "'val+test1'", ":", "\n", "        ", "if", "args", ".", "eval_data_type", "==", "'bal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "args", ".", "use_label_seq", ",", "'nlvr2_balanced_dev.json'", ")", "\n", "", "elif", "args", ".", "eval_data_type", "==", "'unbal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "args", ".", "use_label_seq", ",", "'nlvr2_unbalanced_dev.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "args", ".", "use_label_seq", ",", "'nlvr2_dev_test1.json'", ")", "\n", "\n", "", "", "return", "examples", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_nlvr._load_img_features": [[98, 112], ["time.time", "torch.load", "torch.load", "time.time", "logger.info", "os.path.join"], "function", ["None"], ["", "def", "_load_img_features", "(", "args", ")", ":", "\n", "    ", "t_start", "=", "time", ".", "time", "(", ")", "\n", "if", "args", ".", "img_feature_type", "==", "'faster_r-cnn'", ":", "\n", "        ", "if", "args", ".", "img_feature_dim", "==", "2048", ":", "# object features", "\n", "            ", "feat_file_name", "=", "'nlvr2_img_frcnn_feats.pt'", "\n", "", "else", ":", "# object + spatial features", "\n", "            ", "feat_file_name", "=", "'nlvr2_img_frcnn_feats.pt'", "\n", "", "", "else", ":", "\n", "        ", "feat_file_name", "=", "'nlvr2_img_frcnn_feats.pt'", "\n", "", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "feat_file_name", ")", ")", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: loading {0:s} features using {1:.2f} secs'", ".", "format", "(", "feat_file_name", ",", "(", "t_end", "-", "t_start", ")", ")", ")", "\n", "\n", "return", "img_features", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_nlvr.set_seed": [[377, 383], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_nlvr.train": [[384, 569], ["torch.utils.data.DataLoader", "transformers.pytorch_transformers.WarmupLinearSchedule", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "run_nlvr.set_seed", "range", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "transformers.pytorch_transformers.AdamW", "amp.initialize", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "torch.nn.parallel.DistributedDataParallel.state_dict", "torch.optim.Adamax.state_dict", "int", "time.time", "enumerate", "time.time", "logger.info", "logger.info", "run_nlvr.evaluate", "log_json.append", "logger.info", "logger.info", "logger.info", "open", "json.dump", "os.path.join", "logger.info", "torch.optim.Adamax", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "loss.mean.item", "copy.deepcopy", "os.path.join", "logger.info", "open", "json.dump", "os.path.exists", "os.makedirs", "hasattr", "len", "ImportError", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "loss.mean.mean", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "transformers.pytorch_transformers.WarmupLinearSchedule.step", "torch.optim.Adamax.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "os.path.exists", "os.makedirs", "hasattr", "round", "model_to_save.save_pretrained", "torch.save", "torch.save", "tokenizer.save_pretrained", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "t.to", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "model_to_save.save_pretrained", "torch.save", "torch.save", "tokenizer.save_pretrained", "len", "os.path.join", "any", "logger.info", "run_nlvr.evaluate", "logger.info", "os.path.join", "copy.deepcopy"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate"], ["", "", "def", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "num_workers", "=", "args", ".", "workers", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "if", "args", ".", "optim", "==", "'AdamW'", ":", "\n", "        ", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "", "elif", "args", ".", "optim", "==", "'Adamax'", ":", "\n", "        ", "optimizer", "=", "Adamax", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "", "scheduler", "=", "WarmupLinearSchedule", "(", "optimizer", ",", "warmup_steps", "=", "args", ".", "warmup_steps", ",", "t_total", "=", "t_total", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "#train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0])", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility (even between python 2 and 3)", "\n", "\n", "best_score", "=", "0", "\n", "best_model", "=", "{", "\n", "'epoch'", ":", "0", ",", "\n", "'model_state'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_state'", ":", "optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n", "\n", "for", "epoch", "in", "range", "(", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "#for epoch in train_iterator:", "\n", "#epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])", "\n", "        ", "total_loss", "=", "0", "\n", "total_norm", "=", "0", "\n", "count_norm", "=", "0", "\n", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "#for step, batch in enumerate(epoch_iterator):", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "batch", "[", "3", "]", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "4", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "#loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)", "\n", "loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "\n", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "total_norm", "+=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "count_norm", "+=", "1", "\n", "\n", "#batch_score = compute_score_with_logits(logits, batch[4]).sum()", "\n", "#train_score += batch_score.item()", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "optimizer", ".", "step", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "# Log metrics", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "logger", ".", "info", "(", "\"Epoch: %d, global_step: %d\"", "%", "(", "epoch", ",", "global_step", ")", ")", "\n", "eval_result", ",", "eval_score", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "                            ", "best_score", "=", "eval_score", "\n", "best_model", "[", "'epoch'", "]", "=", "epoch", "\n", "best_model", "[", "'model'", "]", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "best_score", ")", ")", "\n", "", "logging_loss", "=", "tr_loss", "\n", "\n", "#if args.max_steps > 0 and global_step > args.max_steps:", "\n", "#    epoch_iterator.close()", "\n", "#    break", "\n", "\n", "", "", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Train Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "# evaluation", "\n", "logger", ".", "info", "(", "\"Epoch: %d\"", "%", "(", "epoch", ")", ")", "\n", "eval_result", ",", "eval_score", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "eval_score", "\n", "best_model", "[", "'epoch'", "]", "=", "epoch", "\n", "best_model", "[", "'model'", "]", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "#best_model['optimizer'] = copy.deepcopy(optimizer.state_dict())", "\n", "\n", "# save checkpoints", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_epoch", ">", "0", "and", "epoch", "%", "args", ".", "save_epoch", "==", "0", ":", "# Save model checkpoint", "\n", "            ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-{}'", ".", "format", "(", "epoch", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "model_to_save", "=", "best_model", "[", "'model'", "]", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "best_model", "[", "'model'", "]", "# Take care of distributed/parallel training", "\n", "\n", "save_num", "=", "0", "\n", "while", "(", "save_num", "<", "10", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "break", "\n", "", "except", ":", "\n", "                    ", "save_num", "+=", "1", "\n", "", "", "logger", ".", "info", "(", "\"Saving model checkpoint {0} to {1}\"", ".", "format", "(", "epoch", ",", "output_dir", ")", ")", "\n", "\n", "", "epoch_log", "=", "{", "'epoch'", ":", "epoch", ",", "'eval_score'", ":", "eval_score", ",", "'best_score'", ":", "best_score", "}", "\n", "log_json", ".", "append", "(", "epoch_log", ")", "\n", "\n", "with", "open", "(", "args", ".", "output_dir", "+", "'/eval_logs.json'", ",", "'w'", ")", "as", "fp", ":", "\n", "            ", "json", ".", "dump", "(", "log_json", ",", "fp", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"PROGRESS: {}%\"", ".", "format", "(", "round", "(", "100", "*", "(", "epoch", "+", "1", ")", "/", "args", ".", "num_train_epochs", ",", "4", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "best_score", ")", ")", "\n", "logger", ".", "info", "(", "\"LOSS: {}%\"", ".", "format", "(", "total_loss", "/", "len", "(", "train_dataset", ")", ")", ")", "\n", "\n", "", "with", "open", "(", "args", ".", "output_dir", "+", "'/eval_logs.json'", ",", "'w'", ")", "as", "fp", ":", "\n", "        ", "json", ".", "dump", "(", "log_json", ",", "fp", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "# Save the final model checkpoint", "\n", "        ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'best-{}'", ".", "format", "(", "best_model", "[", "'epoch'", "]", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "model_to_save", "=", "best_model", "[", "'model'", "]", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "best_model", "[", "'model'", "]", "# Take care of distributed/parallel training", "\n", "\n", "save_num", "=", "0", "\n", "while", "(", "save_num", "<", "10", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "break", "\n", "", "except", ":", "\n", "                ", "save_num", "+=", "1", "\n", "", "", "logger", ".", "info", "(", "\"Saving the best model checkpoint epoch {} to {}\"", ".", "format", "(", "best_model", "[", "'epoch'", "]", ",", "output_dir", ")", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_nlvr.evaluate": [[570, 635], ["time.time", "zip", "time.time", "logger.info", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "model.eval", "tuple", "float", "len", "os.path.exists", "torch.no_grad", "torch.no_grad", "model", "tmp_eval_loss.mean().item", "logits.size", "logits.max", "torch.sum().item", "torch.sum().item", "t.to", "tmp_eval_loss.mean", "torch.sum", "torch.sum", "batch[].view"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", "=", "None", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "'-MM'", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "#if args.n_gpu > 1: model = torch.nn.DataParallel(model) # debug: single-gpu or multi-gpus", "\n", "\n", "results", "=", "[", "]", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "num_workers", "=", "args", ".", "workers", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "num_data", "=", "0", "\n", "correct_num", "=", "0", "\n", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "#for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "batch", "[", "3", "]", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "4", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "num_data", "+=", "logits", ".", "size", "(", "0", ")", "\n", "\n", "#logger.info('logits: {}, batch[3]: {}'.format(logits.shape, batch[3].shape))", "\n", "\n", "val", ",", "idx", "=", "logits", ".", "max", "(", "1", ")", "\n", "batch_acc", "=", "torch", ".", "sum", "(", "idx", "==", "batch", "[", "3", "]", ".", "view", "(", "-", "1", ")", ")", ".", "item", "(", ")", "\n", "#logger.info('idx: {}, batch[3].view(-1):{}, batch_acc: {}'.format(idx.shape, batch[3].view(-1).shape, batch_acc))", "\n", "correct_num", "+=", "batch_acc", "\n", "\n", "# correct = logits.argmax(1) == batch[3].view(-1)", "\n", "# correct_num += correct.sum().item()", "\n", "\n", "", "nb_eval_steps", "+=", "1", "\n", "\n", "", "acc", "=", "float", "(", "correct_num", ")", "/", "len", "(", "eval_dataloader", ".", "dataset", ")", "\n", "\n", "logger", ".", "info", "(", "\"Eval Results:\"", ")", "\n", "logger", ".", "info", "(", "\"Eval Accuracy: {}\"", ".", "format", "(", "100", "*", "acc", ")", ")", "\n", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "acc", ")", ")", "\n", "logger", ".", "info", "(", "\"Eval Loss: %.3f\"", "%", "(", "eval_loss", ")", ")", "\n", "\n", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Eva Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "return", "results", ",", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_nlvr.test": [[636, 690], ["_pickle.load", "logger.info", "time.time", "zip", "time.time", "logger.info", "logger.info", "open", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "open", "json.dump", "len", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "model.eval", "tuple", "len", "os.path.exists", "torch.no_grad", "torch.no_grad", "model", "logits.max", "range", "t.to", "idx.size", "str", "results.append", "[].item", "idx[].item"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "test", "(", "args", ",", "model", ",", "eval_dataset", "=", "None", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "'-MM'", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "label2ans", "=", "cPickle", ".", "load", "(", "open", "(", "args", ".", "label2ans_file", ",", "'rb'", ")", ")", "\n", "logger", ".", "info", "(", "'label2ans: %d'", "%", "(", "len", "(", "label2ans", ")", ")", ")", "\n", "\n", "results", "=", "[", "]", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval", "\n", "logger", ".", "info", "(", "\"***** Running Test {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "#for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "None", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "logits", "=", "outputs", "[", "0", "]", "\n", "\n", "val", ",", "idx", "=", "logits", ".", "max", "(", "1", ")", "\n", "#logger.info('idx: %s, batch[6]: %s' % (str(idx.shape), str(batch[6].shape)))", "\n", "\n", "for", "i", "in", "range", "(", "idx", ".", "size", "(", "0", ")", ")", ":", "\n", "                    ", "result", "=", "{", "}", "\n", "result", "[", "'questionId'", "]", "=", "str", "(", "batch", "[", "6", "]", "[", "i", "]", ".", "item", "(", ")", ")", "\n", "result", "[", "'prediction'", "]", "=", "label2ans", "[", "eval_dataset", ".", "labels", "[", "idx", "[", "i", "]", ".", "item", "(", ")", "]", "]", "\n", "results", ".", "append", "(", "result", ")", "\n", "\n", "#logger.info('q_id: {0}, answer: {1}'.format(result['question_id'], result['answer']))", "\n", "\n", "", "", "", "", "with", "open", "(", "args", ".", "output_dir", "+", "(", "'/{}_results.json'", ".", "format", "(", "eval_dataset", ".", "name", ")", ")", ",", "'w'", ")", "as", "fp", ":", "\n", "        ", "json", ".", "dump", "(", "results", ",", "fp", ")", "\n", "\n", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'# questions: %d'", "%", "(", "len", "(", "results", ")", ")", ")", "\n", "logger", ".", "info", "(", "'Test Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_nlvr.main": [[693, 922], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_nlvr.set_seed", "parser.parse_args.task_name.lower", "processor.get_labels", "len", "logger.info", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "sum", "logger.info", "model_class.from_pretrained.to", "logger.info", "run_nlvr._load_img_features", "run_nlvr.NLVRDataset", "logger.info", "os.path.join", "logger.info", "os.path.exists", "os.listdir", "logger.info", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.set_device", "torch.cuda.set_device", "torch.device", "torch.device", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "bool", "ValueError", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "run_nlvr.NLVRDataset", "run_nlvr.NLVRDataset", "run_nlvr.train", "logger.info", "logger.info", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "torch.save", "logger.info", "logger.info", "os.getenv", "bool", "p.numel", "os.makedirs", "os.path.join", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_nlvr.evaluate", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_nlvr.evaluate", "model_class.from_pretrained.parameters", "torch.distributed.get_rank", "torch.distributed.get_rank", "os.path.exists", "MODEL_CLASSES.keys", "oscar.utils.task_utils.processors.keys", "torch.cuda.is_available", "torch.cuda.is_available", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "sorted", "sorted", "glob.glob", "glob.glob"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few._load_img_features", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the .tsv files (or other data files) for the task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name selected in the list: \"", "+", "\", \"", ".", "join", "(", "ALL_MODELS", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--task_name\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train selected in the list: \"", "+", "\", \"", ".", "join", "(", "processors", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--data_label_type\"", ",", "default", "=", "'bal'", ",", "type", "=", "str", ",", "help", "=", "\"bal or all\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_data_type\"", ",", "default", "=", "'bal'", ",", "type", "=", "str", ",", "help", "=", "\"bal or all\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_data_type\"", ",", "default", "=", "'bal'", ",", "type", "=", "str", ",", "help", "=", "\"bal or all\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--loss_type\"", ",", "default", "=", "'kl'", ",", "type", "=", "str", ",", "help", "=", "\"kl or xe\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_layernorm\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"use_layernorm\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_label_seq\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"use_label_seq\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_pair\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"use_pair\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_choice\"", ",", "default", "=", "2", ",", "type", "=", "int", ",", "help", "=", "\"num_choice\"", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer than this will be truncated, sequences shorter will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run test on the test set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Rul evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--drop_out\"", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "\"Drop out for BERT.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--classifier\"", ",", "default", "=", "'linear'", ",", "type", "=", "str", ",", "help", "=", "\"linear or mlp\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cls_hidden_scale\"", ",", "default", "=", "2", ",", "type", "=", "int", ",", "help", "=", "\"cls_hidden_scale: for classifier\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_img_seq_length\"", ",", "default", "=", "30", ",", "type", "=", "int", ",", "help", "=", "\"The maximum total input image sequence length.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_dim\"", ",", "default", "=", "2054", ",", "type", "=", "int", ",", "help", "=", "\"The Image Feature Dimension.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_type\"", ",", "default", "=", "'faster_r-cnn'", ",", "type", "=", "str", ",", "help", "=", "\"faster_r-cnn or mask_r-cnn\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_voc\"", ",", "default", "=", "512", ",", "type", "=", "int", ",", "help", "=", "\"dis_code_voc: 256, 512\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_level\"", ",", "default", "=", "'top'", ",", "type", "=", "str", ",", "help", "=", "\"code level: top, botttom, both\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--optim\"", ",", "default", "=", "'AdamW'", ",", "type", "=", "str", ",", "help", "=", "\"optim: AdamW, Adamax\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_epoch'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "\"Save checkpoint every X epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_output_dir'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_cache'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_ip'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_port'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--philly\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use Philly: reset the output dir\"", ")", "\n", "parser", ".", "add_argument", "(", "'-j'", ",", "'--workers'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "help", "=", "'number of data loading workers (default: 4)'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "philly", ":", "# use philly", "\n", "        ", "logger", ".", "info", "(", "'Info: Use Philly, all the output folders are reset.'", ")", "\n", "args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "getenv", "(", "'PT_OUTPUT_DIR'", ")", ",", "args", ".", "output_dir", ")", "\n", "logger", ".", "info", "(", "'OUTPUT_DIR:'", ",", "args", ".", "output_dir", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", ":", "logger", ".", "info", "(", "\"Output Directory Exists.\"", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s - %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Prepare GLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "args", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "logger", ".", "info", "(", "'Task Name: {}, #Labels: {}'", ".", "format", "(", "args", ".", "task_name", ",", "num_labels", ")", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "if", "args", ".", "use_pair", ":", "\n", "        ", "model_class", "=", "ImageBertForMultipleChoice", "\n", "", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "num_labels", "=", "num_labels", ",", "finetuning_task", "=", "args", ".", "task_name", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "\n", "# new config: discrete code", "\n", "config", ".", "img_feature_dim", "=", "args", ".", "img_feature_dim", "\n", "config", ".", "img_feature_type", "=", "args", ".", "img_feature_type", "\n", "config", ".", "code_voc", "=", "args", ".", "code_voc", "\n", "config", ".", "hidden_dropout_prob", "=", "args", ".", "drop_out", "\n", "config", ".", "loss_type", "=", "args", ".", "loss_type", "\n", "config", ".", "use_layernorm", "=", "args", ".", "use_layernorm", "\n", "config", ".", "classifier", "=", "args", ".", "classifier", "\n", "config", ".", "cls_hidden_scale", "=", "args", ".", "cls_hidden_scale", "\n", "config", ".", "num_choice", "=", "args", ".", "num_choice", "\n", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "from_tf", "=", "bool", "(", "'.ckpt'", "in", "args", ".", "model_name_or_path", ")", ",", "config", "=", "config", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "total_params", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", ")", "\n", "logger", ".", "info", "(", "'Model Parameters: {}'", ".", "format", "(", "total_params", ")", ")", "\n", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/Evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# load image features", "\n", "img_features", "=", "_load_img_features", "(", "args", ")", "\n", "\n", "#if args.do_eval:", "\n", "eval_dataset", "=", "NLVRDataset", "(", "args", ",", "'val'", ",", "img_features", ",", "tokenizer", ")", "\n", "\n", "if", "args", ".", "do_test", ":", "\n", "        ", "test_dataset", "=", "NLVRDataset", "(", "args", ",", "'test1'", ",", "img_features", ",", "tokenizer", ")", "\n", "\n", "# Training", "\n", "", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "NLVRDataset", "(", "args", ",", "'train'", ",", "img_features", ",", "tokenizer", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`. They can then be reloaded using `from_pretrained()`", "\n", "#model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training", "\n", "#model_to_save.save_pretrained(args.output_dir)", "\n", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "#model = model_class.from_pretrained(args.output_dir)", "\n", "#tokenizer = tokenizer_class.from_pretrained(args.output_dir)", "\n", "#model.to(args.device)", "\n", "\n", "\n", "# Evaluation", "\n", "#results = {}", "\n", "", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ",", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "score", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "#result = dict((k + '_{}'.format(global_step), v) for k, v in result.items())", "\n", "#results.update(result)", "\n", "\n", "# Test-Submission", "\n", "", "", "if", "args", ".", "do_test", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "#test(args, model, test_dataset, prefix=global_step)", "\n", "result", ",", "score", "=", "evaluate", "(", "args", ",", "model", ",", "test_dataset", ",", "prefix", "=", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa.VQADataset.__init__": [[85, 134], ["torch.utils.data.Dataset.__init__", "time.time", "time.time", "logger.info", "run_vqa._load_dataset", "logger.info", "run_vqa.VQADataset.tensorize", "torch.load", "torch.load", "torch.load", "torch.load", "args.img_feature_type.startswith", "enumerate", "torch.load", "torch.load", "torch.load", "torch.load", "run_vqa.VQADataset.load_img_tsv_features", "os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "bool", "bool", "len", "os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few._load_dataset", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.load_img_tsv_features"], ["def", "__init__", "(", "self", ",", "args", ",", "name", ",", "tokenizer", ")", ":", "\n", "        ", "super", "(", "VQADataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "name", "in", "[", "'train'", ",", "'val'", ",", "'test-dev2015'", ",", "'test2015'", ",", "'train+val'", "]", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "name", "=", "name", "\n", "\n", "# load image features", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "img_feature_file", "=", "None", "\n", "self", ".", "img_feat_offset_map", "=", "None", "\n", "\n", "if", "args", ".", "img_feature_type", "==", "'faster_r-cnn'", ":", "\n", "            ", "if", "args", ".", "img_feat_format", "==", "'pt'", ":", "\n", "                ", "if", "args", ".", "img_feature_dim", "==", "2048", ":", "# object features", "\n", "                    ", "self", ".", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'{}_img_frcnn_obj_feats.pt'", ".", "format", "(", "name", ")", ")", ")", "\n", "", "else", ":", "# object + spatial features", "\n", "                    ", "if", "args", ".", "use_vg_dev", ":", "\n", "                        ", "self", ".", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'train+val_img_frcnn_feats.pt'", ")", ")", "\n", "", "else", ":", "\n", "                        ", "self", ".", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'{}_img_frcnn_feats.pt'", ".", "format", "(", "name", ")", ")", ")", "\n", "", "", "", "elif", "args", ".", "img_feat_format", "==", "'tsv'", ":", "\n", "                ", "self", ".", "load_img_tsv_features", "(", ")", "\n", "", "", "elif", "args", ".", "img_feature_type", "==", "'mask_r-cnn'", ":", "\n", "            ", "self", ".", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'{}_img_mask_rcnn_feats.pt'", ".", "format", "(", "name", ")", ")", ")", "\n", "", "elif", "args", ".", "img_feature_type", ".", "startswith", "(", "'dis_code'", ")", ":", "#in ['dis_code', 'dis_code_t']: # discrete code", "\n", "            ", "self", ".", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'vqvae'", ",", "'{}.pt'", ".", "format", "(", "name", ")", ")", ")", "[", "'feats_{}'", ".", "format", "(", "args", ".", "code_level", ")", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'{}_img_feats.pt'", ".", "format", "(", "name", ")", ")", ")", "\n", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: loading {0} features using {1:.2f} secs'", ".", "format", "(", "name", ",", "(", "t_end", "-", "t_start", ")", ")", ")", "\n", "\n", "self", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n", "self", ".", "examples", ",", "self", ".", "labels", "=", "_load_dataset", "(", "args", ",", "name", ")", "\n", "self", ".", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "self", ".", "labels", ")", "}", "\n", "\n", "if", "self", ".", "args", ".", "load_fast", ":", "\n", "            ", "self", ".", "features", "=", "self", ".", "tensorize", "(", "args", ",", "cls_token_at_end", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "self", ".", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "\n", "", "logger", ".", "info", "(", "'%s Data Examples: %d'", "%", "(", "name", ",", "len", "(", "self", ".", "examples", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa.VQADataset.tensorize": [[136, 242], ["enumerate", "run_vqa.VQADataset.tokenizer.tokenize", "run_vqa.VQADataset.tokenizer.convert_tokens_to_ids", "run_vqa.target_tensor", "features.append", "len", "logger.info", "run_vqa.VQADataset.tokenizer.tokenize", "oscar.utils.task_utils._truncate_seq_pair", "len", "len", "len", "len", "len", "len", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "len", "len", "float", "KeyError", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.target_tensor", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv._truncate_seq_pair"], ["", "def", "tensorize", "(", "self", ",", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "\n", "# debug:", "\n", "        ", "debug_size", "=", "500", "\n", "features", "=", "[", "]", "\n", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "self", ".", "examples", "[", "0", ":", "]", ")", ":", "\n", "            ", "if", "len", "(", "example", ".", "label", ")", "==", "0", ":", "continue", "\n", "if", "ex_index", "%", "10000", "==", "0", ":", "logger", ".", "info", "(", "\"Tensorizing example %d of %d\"", "%", "(", "ex_index", ",", "len", "(", "self", ".", "examples", ")", ")", ")", "\n", "\n", "tokens_a", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "                ", "tokens_b", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_b", ")", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "self", ".", "args", ".", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "                ", "if", "len", "(", "tokens_a", ")", ">", "self", ".", "args", ".", "max_seq_length", "-", "2", ":", "\n", "                    ", "tokens_a", "=", "tokens_a", "[", ":", "(", "self", ".", "args", ".", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "", "tokens", "=", "tokens_a", "+", "[", "sep_token", "]", "\n", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "                ", "tokens", "+=", "tokens_b", "+", "[", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "if", "cls_token_at_end", ":", "\n", "                ", "tokens", "=", "tokens", "+", "[", "cls_token", "]", "\n", "segment_ids", "=", "segment_ids", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "                ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "self", ".", "args", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "                ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "", "else", ":", "\n", "                ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "segment_ids", "=", "segment_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "\n", "# image features", "\n", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "# torch", "\n", "#img_feat = self.img_features.item().get(example.img_key)  # numpy", "\n", "if", "img_feat", ".", "shape", "[", "0", "]", ">", "self", ".", "args", ".", "max_img_seq_length", ":", "\n", "                ", "img_feat", "=", "img_feat", "[", "0", ":", "self", ".", "args", ".", "max_img_seq_length", ",", "]", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids += [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids = segment_ids + [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "self", ".", "args", ".", "max_img_seq_length", "-", "img_feat", ".", "shape", "[", "0", "]", ",", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_matrix", ".", "shape", "[", "0", "]", ")", "\n", "# segment_ids = segment_ids + [pad_token_segment_id] * padding_matrix.shape[0]", "\n", "\n", "", "", "if", "self", ".", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "                ", "label_id", "=", "[", "self", ".", "label_map", "[", "l", "]", "for", "l", "in", "example", ".", "label", "]", "\n", "score", "=", "example", ".", "score", "\n", "", "elif", "self", ".", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "                ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "else", ":", "\n", "                ", "raise", "KeyError", "(", "self", ".", "args", ".", "output_mode", ")", "\n", "\n", "", "if", "ex_index", "<", "5", ":", "\n", "                ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"segment_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label: %s (id = %s)\"", "%", "(", "example", ".", "label", ",", "label_id", ")", ")", "\n", "logger", ".", "info", "(", "\"score: %s (score = %s)\"", "%", "(", "example", ".", "score", ",", "score", ")", ")", "\n", "\n", "", "new_scores", "=", "target_tensor", "(", "len", "(", "self", ".", "labels", ")", ",", "label_id", ",", "score", ")", "\n", "#features.append(InputFeat(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label_id, score=score, img_feat=img_feat))", "\n", "features", ".", "append", "(", "(", "torch", ".", "tensor", "(", "input_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "label_id", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "new_scores", ",", "dtype", "=", "torch", ".", "float", ")", ",", "img_feat", ")", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa.VQADataset.tensorize_example": [[243, 363], ["run_vqa.VQADataset.tokenizer.tokenize", "run_vqa.VQADataset.tokenizer.convert_tokens_to_ids", "run_vqa.VQADataset.args.img_feature_type.startswith", "run_vqa.target_tensor", "run_vqa.VQADataset.tokenizer.tokenize", "oscar.utils.task_utils._truncate_seq_pair", "len", "len", "len", "len", "len", "len", "len", "torch.from_numpy.type", "torch.from_numpy.type", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "torch.from_numpy.reshape", "torch.from_numpy.reshape", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KeyError", "torch.from_numpy.type", "torch.from_numpy.type", "len", "run_vqa.VQADataset.get_img_feature", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "len", "len", "float", "str"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.target_tensor", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv._truncate_seq_pair", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.get_img_feature"], ["", "def", "tensorize_example", "(", "self", ",", "example", ",", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "\n", "        ", "tokens_a", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "            ", "tokens_b", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_b", ")", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "self", ".", "args", ".", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "            ", "if", "len", "(", "tokens_a", ")", ">", "self", ".", "args", ".", "max_seq_length", "-", "2", ":", "\n", "                ", "tokens_a", "=", "tokens_a", "[", ":", "(", "self", ".", "args", ".", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "", "tokens", "=", "tokens_a", "+", "[", "sep_token", "]", "\n", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "            ", "tokens", "+=", "tokens_b", "+", "[", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "if", "cls_token_at_end", ":", "\n", "            ", "tokens", "=", "tokens", "+", "[", "cls_token", "]", "\n", "segment_ids", "=", "segment_ids", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "            ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "self", ".", "args", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "segment_ids", "=", "segment_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "\n", "# image features", "\n", "if", "self", ".", "args", ".", "img_feature_type", ".", "startswith", "(", "'dis_code'", ")", ":", "\n", "            ", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "\n", "\n", "if", "self", ".", "args", ".", "img_feature_type", "==", "'dis_code_ln'", ":", "# for discrete code image representation", "\n", "                ", "img_feat", "=", "img_feat", ".", "reshape", "(", "-", "1", ",", "img_feat", ".", "shape", "[", "0", "]", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "img_feature_type", "==", "'dis_code_t'", ":", "# transposed", "\n", "                ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "64", "\n", "", "else", ":", "\n", "                ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "args", ".", "img_feat_format", "==", "'pt'", ":", "\n", "                ", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "#[:, 0:self.args.img_feature_dim]  # torch", "\n", "", "elif", "self", ".", "args", ".", "img_feat_format", "==", "'tsv'", ":", "\n", "                ", "img_features", "=", "self", ".", "get_img_feature", "(", "str", "(", "example", ".", "img_key", ")", ")", "\n", "img_feat", "=", "torch", ".", "from_numpy", "(", "img_features", ")", "\n", "\n", "", "if", "img_feat", ".", "shape", "[", "0", "]", ">", "self", ".", "args", ".", "max_img_seq_length", ":", "\n", "                ", "img_feat", "=", "img_feat", "[", "0", ":", "self", ".", "args", ".", "max_img_seq_length", ",", "]", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids += [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids = segment_ids + [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "self", ".", "args", ".", "max_img_seq_length", "-", "img_feat", ".", "shape", "[", "0", "]", ",", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_matrix", ".", "shape", "[", "0", "]", ")", "\n", "# segment_ids = segment_ids + [pad_token_segment_id] * padding_matrix.shape[0]", "\n", "\n", "", "", "", "if", "self", ".", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "if", "(", "example", ".", "label", "is", "None", ")", ":", "\n", "                ", "label_id", "=", "[", "0", "]", "\n", "score", "=", "[", "0", "]", "\n", "", "elif", "len", "(", "example", ".", "label", ")", "==", "0", ":", "\n", "                ", "label_id", "=", "[", "0", "]", "\n", "score", "=", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "label_id", "=", "[", "self", ".", "label_map", "[", "l", "]", "for", "l", "in", "example", ".", "label", "]", "\n", "score", "=", "example", ".", "score", "\n", "", "", "elif", "self", ".", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "if", "len", "(", "example", ".", "label", ")", "==", "0", ":", "\n", "                ", "label_id", "=", "0", "\n", "", "else", ":", "\n", "                ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "self", ".", "args", ".", "output_mode", ")", "\n", "\n", "", "new_scores", "=", "target_tensor", "(", "len", "(", "self", ".", "labels", ")", ",", "label_id", ",", "score", ")", "\n", "\n", "# features.append(InputFeat(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label_id, score=score, img_feat=img_feat))", "\n", "if", "self", ".", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "            ", "img_feat", "=", "img_feat", ".", "type", "(", "torch", ".", "long", ")", "\n", "", "elif", "self", ".", "args", ".", "img_feature_type", "in", "[", "'dis_code_ln'", "]", ":", "\n", "#img_feat = img_feat.reshape(-1, img_feat.shape[0])", "\n", "            ", "img_feat", "=", "img_feat", ".", "type", "(", "torch", ".", "float", ")", "\n", "\n", "", "return", "(", "torch", ".", "tensor", "(", "input_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "label_id", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "new_scores", ",", "dtype", "=", "torch", ".", "float", ")", ",", "\n", "img_feat", ",", "\n", "torch", ".", "tensor", "(", "[", "example", ".", "q_id", "]", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa.VQADataset.__getitem__": [[364, 377], ["run_vqa.VQADataset.tensorize_example", "bool", "bool"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize_example"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "load_fast", ":", "\n", "            ", "example", "=", "self", ".", "features", "[", "index", "]", "\n", "", "else", ":", "\n", "            ", "entry", "=", "self", ".", "examples", "[", "index", "]", "\n", "example", "=", "self", ".", "tensorize_example", "(", "entry", ",", "\n", "cls_token_at_end", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "self", ".", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa.VQADataset.__len__": [[378, 380], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa.VQADataset.load_img_tsv_features": [[382, 385], ["run_vqa.VQADataset.check_img_feature_file", "run_vqa.VQADataset.check_img_feature_offset_map"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_feature_file", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_feature_offset_map"], ["", "def", "load_img_tsv_features", "(", "self", ")", ":", "\n", "        ", "self", ".", "check_img_feature_file", "(", ")", "\n", "self", ".", "check_img_feature_offset_map", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa.VQADataset.check_img_feature_file": [[386, 393], ["os.path.join", "time.time", "open", "time.time", "logger.info"], "methods", ["None"], ["", "def", "check_img_feature_file", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "img_feature_file", "is", "None", ":", "\n", "            ", "img_feature_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "img_feat_dir", ",", "'{}_img_frcnn_feats.tsv'", ".", "format", "(", "self", ".", "name", ")", ")", "\n", "t_s", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "img_feature_file", "=", "open", "(", "img_feature_path", ",", "'r'", ")", "\n", "t_e", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "\"Open {} image time: {}\"", ".", "format", "(", "self", ".", "name", ",", "(", "t_e", "-", "t_s", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa.VQADataset.check_img_feature_offset_map": [[394, 402], ["os.path.join", "time.time", "json.load", "time.time", "logger.info", "open", "len"], "methods", ["None"], ["", "", "def", "check_img_feature_offset_map", "(", "self", ")", ":", "\n", "        ", "\"\"\" load the image feature offset map \"\"\"", "\n", "if", "self", ".", "img_feat_offset_map", "is", "None", ":", "\n", "            ", "img_feature_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "img_feat_dir", ",", "'{}_img_frcnn_feats_offset_map.json'", ".", "format", "(", "self", ".", "name", ")", ")", "\n", "t_s", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "img_feat_offset_map", "=", "json", ".", "load", "(", "open", "(", "img_feature_path", ")", ")", "\n", "t_e", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "\"Load {} images: {}, time: {}\"", ".", "format", "(", "self", ".", "name", ",", "len", "(", "self", ".", "img_feat_offset_map", ")", ",", "(", "t_e", "-", "t_s", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa.VQADataset.get_img_feature": [[403, 417], ["run_vqa.VQADataset.check_img_feature_file", "run_vqa.VQADataset.check_img_feature_offset_map", "run_vqa.VQADataset.img_feature_file.seek", "int", "numpy.frombuffer().reshape", "s.strip", "run_vqa.VQADataset.img_feature_file.readline().split", "numpy.frombuffer", "base64.b64decode", "run_vqa.VQADataset.img_feature_file.readline"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_feature_file", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_feature_offset_map", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek"], ["", "", "def", "get_img_feature", "(", "self", ",", "image_id", ")", ":", "\n", "        ", "\"\"\" decode the image feature \"\"\"", "\n", "self", ".", "check_img_feature_file", "(", ")", "\n", "self", ".", "check_img_feature_offset_map", "(", ")", "\n", "\n", "if", "image_id", "in", "self", ".", "img_feat_offset_map", ":", "\n", "            ", "img_offset", "=", "self", ".", "img_feat_offset_map", "[", "image_id", "]", "\n", "self", ".", "img_feature_file", ".", "seek", "(", "img_offset", ",", "0", ")", "\n", "arr", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "self", ".", "img_feature_file", ".", "readline", "(", ")", ".", "split", "(", "'\\t'", ")", "]", "\n", "num_boxes", "=", "int", "(", "arr", "[", "1", "]", ")", "\n", "feat", "=", "np", ".", "frombuffer", "(", "base64", ".", "b64decode", "(", "arr", "[", "2", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "(", "-", "1", ",", "self", ".", "args", ".", "img_feature_dim", ")", ")", "\n", "return", "feat", "\n", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa._load_dataset": [[41, 80], ["processor.get_labels", "processor.get_train_examples", "processor.get_train_examples", "processor.get_train_examples", "processor.get_dev_examples", "processor.get_dev_examples", "processor.get_dev_examples", "processor.get_train_examples", "processor.get_train_examples", "processor.get_test_examples", "processor.get_test_examples", "processor.get_test_examples", "processor.get_test_examples"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples"], ["def", "_load_dataset", "(", "args", ",", "name", ")", ":", "\n", "    ", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "labels", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "\n", "if", "name", "==", "'train'", ":", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'mask'", ":", "\n", "            ", "if", "args", ".", "use_vg", ":", "\n", "#examples = processor.get_train_examples(args.data_dir, 'train2014_vg_qla_mrcnn.json')", "\n", "                ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "txt_data_dir", ",", "'train2014_vg_qla_mrcnn.json'", ")", "\n", "", "else", ":", "\n", "                ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "txt_data_dir", ",", "'train2014_qla_mrcnn.json'", ")", "\n", "", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "txt_data_dir", ",", "'train2014_qla.json'", ")", "\n", "", "", "elif", "name", "==", "'val'", ":", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'mask'", ":", "\n", "            ", "if", "args", ".", "use_vg_dev", ":", "\n", "                ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "txt_data_dir", ",", "'vg_qla_mrcnn.json'", ")", "\n", "", "else", ":", "\n", "                ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "txt_data_dir", ",", "'val2014_qla_mrcnn.json'", ")", "\n", "", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "txt_data_dir", ",", "'val2014_qla.json'", ")", "\n", "", "", "elif", "name", "==", "'train+val'", ":", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'mask'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "txt_data_dir", ",", "'train+val2014_qla_mrcnn.json'", ")", "\n", "#examples = processor.get_train_examples(args.data_dir, 'train+val2014_qla_mrcnn.json')", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "txt_data_dir", ",", "'train+val2014_qla.json'", ")", "\n", "", "", "elif", "name", "==", "'test2015'", ":", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'mask'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'test2015_qla_mrcnn.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'test2014_qla.json'", ")", "\n", "", "", "elif", "name", "==", "'test-dev2015'", ":", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'mask'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'test-dev2015_qla_mrcnn.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'test2014_qla.json'", ")", "\n", "\n", "", "", "return", "examples", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa.instance_bce_with_logits": [[419, 426], ["torch.functional.binary_cross_entropy_with_logits", "logits.dim", "labels.size"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "", "def", "instance_bce_with_logits", "(", "logits", ",", "labels", ",", "reduction", "=", "'mean'", ")", ":", "\n", "    ", "assert", "logits", ".", "dim", "(", ")", "==", "2", "\n", "\n", "loss", "=", "nn", ".", "functional", ".", "binary_cross_entropy_with_logits", "(", "logits", ",", "labels", ",", "reduction", "=", "reduction", ")", "\n", "if", "reduction", "==", "'mean'", ":", "\n", "        ", "loss", "*=", "labels", ".", "size", "(", "1", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa.compute_score_with_logits": [[428, 434], ["torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda.scatter_", "logits.view", "torch.max", "torch.max", "torch.zeros", "torch.zeros", "labels.size"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "compute_score_with_logits", "(", "logits", ",", "labels", ")", ":", "\n", "    ", "logits", "=", "torch", ".", "max", "(", "logits", ",", "1", ")", "[", "1", "]", ".", "data", "# argmax", "\n", "one_hots", "=", "torch", ".", "zeros", "(", "*", "labels", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", "\n", "one_hots", ".", "scatter_", "(", "1", ",", "logits", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", "\n", "scores", "=", "(", "one_hots", "*", "labels", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa.trim_batch": [[436, 456], ["print", "len", "enumerate", "len", "print", "torch.zeros", "torch.zeros", "batch_tensors.append", "print", "enumerate", "ele.size", "len", "print", "list", "ele.size"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "trim_batch", "(", "batch", ")", ":", "\n", "    ", "\"\"\" new batch func\n    :param batch:\n    :return:\n    \"\"\"", "\n", "print", "(", "'batch size'", ",", "len", "(", "batch", ")", ")", "\n", "\n", "batch_size", "=", "len", "(", "batch", ")", "\n", "batch_tensors", "=", "[", "]", "\n", "for", "ele", "in", "batch", "[", "0", "]", ":", "\n", "        ", "print", "(", "ele", ".", "shape", ",", "ele", ".", "size", "(", ")", ")", "\n", "zero_tensor", "=", "torch", ".", "zeros", "(", "(", "[", "batch_size", "]", "+", "list", "(", "ele", ".", "size", "(", ")", ")", ")", ")", "\n", "batch_tensors", ".", "append", "(", "zero_tensor", ")", "\n", "\n", "", "for", "b_id", ",", "b", "in", "enumerate", "(", "batch", ")", ":", "\n", "        ", "print", "(", "b_id", ",", "len", "(", "b", ")", ")", "\n", "for", "ele_id", ",", "ele", "in", "enumerate", "(", "b", ")", ":", "\n", "            ", "print", "(", "ele_id", ",", "ele", ".", "shape", ")", "\n", "batch_tensors", "[", "ele_id", "]", "[", "b_id", "]", "=", "ele", "\n", "", "", "return", "batch_tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa.train": [[458, 680], ["torch.utils.data.DataLoader", "transformers.pytorch_transformers.AdamW", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "oscar.utils.misc.set_seed", "range", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "transformers.pytorch_transformers.WarmupConstantSchedule", "amp.initialize", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "copy.deepcopy", "transformers.pytorch_transformers.AdamW.state_dict", "int", "time.time", "enumerate", "logger.info", "run_vqa.evaluate", "log_json.append", "logger.info", "logger.info", "time.time", "logger.info", "os.path.join", "logger.info", "transformers.pytorch_transformers.WarmupLinearSchedule", "logger.info", "hasattr", "logger.info", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "compute_score_with_logits().sum", "compute_score_with_logits().sum.item", "loss.mean.item", "copy.deepcopy", "os.path.join", "logger.info", "open", "json.dump", "os.path.exists", "os.makedirs", "hasattr", "len", "ImportError", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "loss.mean.mean", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "transformers.pytorch_transformers.WarmupLinearSchedule.step", "transformers.pytorch_transformers.AdamW.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "os.path.exists", "os.makedirs", "hasattr", "open", "json.dump", "round", "model_to_save.save_pretrained", "torch.save", "torch.save", "tokenizer.save_pretrained", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "t.to", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "run_vqa.compute_score_with_logits", "logger.info", "model_to_save.save_pretrained", "torch.save", "torch.save", "tokenizer.save_pretrained", "os.path.join", "any", "torch.distributed.barrier", "torch.distributed.barrier", "logger.info", "run_vqa.evaluate", "logger.info", "torch.distributed.barrier", "torch.distributed.barrier", "os.path.join", "copy.deepcopy"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.compute_score_with_logits", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "#if args.local_rank in [-1, 0]: tb_writer = SummaryWriter()", "\n", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "num_workers", "=", "args", ".", "workers", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "#, collate_fn=trim_batch)", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "#scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args.warmup_steps, t_total=t_total) # original", "\n", "\n", "if", "args", ".", "scheduler", "==", "\"constant\"", ":", "\n", "        ", "scheduler", "=", "WarmupConstantSchedule", "(", "optimizer", ",", "warmup_steps", "=", "args", ".", "warmup_steps", ")", "\n", "", "elif", "args", ".", "scheduler", "==", "\"linear\"", ":", "\n", "        ", "scheduler", "=", "WarmupLinearSchedule", "(", "optimizer", ",", "warmup_steps", "=", "args", ".", "warmup_steps", ",", "t_total", "=", "t_total", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "#train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0])", "\n", "set_seed", "(", "args", ".", "seed", ",", "args", ".", "n_gpu", ")", "# Added here for reproductibility (even between python 2 and 3)", "\n", "\n", "best_score", "=", "0", "\n", "best_model", "=", "{", "\n", "'epoch'", ":", "0", ",", "\n", "'model'", ":", "copy", ".", "deepcopy", "(", "model", ")", ",", "#model.state_dict(),", "\n", "'optimizer_state'", ":", "optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n", "\n", "#eval_dataset = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=True)", "\n", "\n", "for", "epoch", "in", "range", "(", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "#for epoch in train_iterator:", "\n", "#epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])", "\n", "        ", "total_loss", "=", "0", "\n", "train_score", "=", "0", "\n", "total_norm", "=", "0", "\n", "count_norm", "=", "0", "\n", "\n", "if", "args", ".", "adjust_dp", "and", "epoch", ">=", "3", ":", "\n", "            ", "logger", ".", "info", "(", "\"change droput ratio {} to 0.3\"", ".", "format", "(", "args", ".", "drop_out", ")", ")", "\n", "if", "hasattr", "(", "model", ",", "'module'", ")", ":", "\n", "                ", "model", ".", "module", ".", "dropout", ".", "p", "=", "0.3", "\n", "model", ".", "module", ".", "bert", ".", "dropout", ".", "p", "=", "0.3", "\n", "model", ".", "module", ".", "bert", ".", "embeddings", ".", "dropout", ".", "p", "=", "0.3", "\n", "", "else", ":", "\n", "                ", "model", ".", "dropout", ".", "p", "=", "0.3", "\n", "model", ".", "bert", ".", "dropout", ".", "p", "=", "0.3", "\n", "model", ".", "bert", ".", "embeddings", ".", "dropout", ".", "p", "=", "0.3", "\n", "\n", "", "", "if", "args", ".", "adjust_loss", "and", "epoch", ">=", "args", ".", "adjust_loss_epoch", ":", "\n", "            ", "logger", ".", "info", "(", "\"\\t change loss type from kl to bce\"", ")", "\n", "model", ".", "loss_type", "=", "'bce'", "\n", "\n", "# debug", "\n", "#epoch = 20", "\n", "#global_step = epoch*math.ceil(len(train_dataset)/(args.train_batch_size * args.gradient_accumulation_steps * (torch.distributed.get_world_size() if args.local_rank != -1 else 1)))", "\n", "\n", "", "t_start", "=", "time", ".", "time", "(", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "batch", "[", "4", "]", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "#loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)", "\n", "loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "#loss = instance_bce_with_logits(logits, batch[4])", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "\n", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "total_norm", "+=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "count_norm", "+=", "1", "\n", "\n", "", "batch_score", "=", "compute_score_with_logits", "(", "logits", ",", "batch", "[", "4", "]", ")", ".", "sum", "(", ")", "\n", "train_score", "+=", "batch_score", ".", "item", "(", ")", "\n", "\n", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "optimizer", ".", "step", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "# Log metrics", "\n", "                    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "                        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "evaluate_during_training", ":", "\n", "#if args.local_rank == -1 and args.evaluate_during_training:  # Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "logger", ".", "info", "(", "\"Epoch: %d, global_step: %d\"", "%", "(", "epoch", ",", "global_step", ")", ")", "\n", "eval_result", ",", "eval_score", ",", "upper_bound", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "                            ", "best_score", "=", "eval_score", "\n", "best_model", "[", "'epoch'", "]", "=", "epoch", "\n", "best_model", "[", "'model'", "]", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "best_score", ")", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "                        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "logging_loss", "=", "tr_loss", "\n", "\n", "#if args.max_steps > 0 and global_step > args.max_steps:", "\n", "#    epoch_iterator.close()", "\n", "#    break", "\n", "\n", "# evaluation", "\n", "", "", "", "logger", ".", "info", "(", "\"Epoch: %d, global_step: %d\"", "%", "(", "epoch", ",", "global_step", ")", ")", "\n", "eval_result", ",", "eval_score", ",", "upper_bound", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "eval_score", "\n", "best_model", "[", "'epoch'", "]", "=", "epoch", "\n", "best_model", "[", "'model'", "]", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "#best_model['optimizer'] = copy.deepcopy(optimizer.state_dict())", "\n", "\n", "# save checkpoints", "\n", "", "if", "(", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ")", "and", "(", "args", ".", "save_epoch", ">", "0", "and", "epoch", "%", "args", ".", "save_epoch", "==", "0", ")", "and", "(", "epoch", ">", "args", ".", "save_after_epoch", ")", ":", "\n", "            ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-{}-{}'", ".", "format", "(", "epoch", ",", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "model_to_save", "=", "best_model", "[", "'model'", "]", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "best_model", "[", "'model'", "]", "# Take care of distributed/parallel training", "\n", "\n", "save_num", "=", "0", "\n", "while", "(", "save_num", "<", "10", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Saving model attempt: {}\"", ".", "format", "(", "save_num", ")", ")", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "break", "\n", "", "except", ":", "\n", "                    ", "save_num", "+=", "1", "\n", "", "", "logger", ".", "info", "(", "\"Saving model checkpoint {0} to {1}\"", ".", "format", "(", "epoch", ",", "output_dir", ")", ")", "\n", "\n", "", "epoch_log", "=", "{", "'epoch'", ":", "epoch", ",", "'eval_score'", ":", "eval_score", ",", "'best_score'", ":", "best_score", "}", "\n", "log_json", ".", "append", "(", "epoch_log", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "with", "open", "(", "args", ".", "output_dir", "+", "'/eval_logs.json'", ",", "'w'", ")", "as", "fp", ":", "\n", "                ", "json", ".", "dump", "(", "log_json", ",", "fp", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"PROGRESS: {}%\"", ".", "format", "(", "round", "(", "100", "*", "(", "epoch", "+", "1", ")", "/", "args", ".", "num_train_epochs", ",", "4", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "best_score", ")", ")", "\n", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Epoch: %d, Train Time: %.3f'", "%", "(", "epoch", ",", "t_end", "-", "t_start", ")", ")", "\n", "\n", "#if args.max_steps > 0 and global_step > args.max_steps:", "\n", "#    train_iterator.close()", "\n", "#    break", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "# Save the final model checkpoint", "\n", "        ", "with", "open", "(", "args", ".", "output_dir", "+", "'/eval_logs.json'", ",", "'w'", ")", "as", "fp", ":", "\n", "            ", "json", ".", "dump", "(", "log_json", ",", "fp", ")", "\n", "\n", "", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'best-{}'", ".", "format", "(", "best_model", "[", "'epoch'", "]", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "model_to_save", "=", "best_model", "[", "'model'", "]", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "best_model", "[", "'model'", "]", "# Take care of distributed/parallel training", "\n", "\n", "save_num", "=", "0", "\n", "while", "(", "save_num", "<", "10", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "break", "\n", "", "except", ":", "\n", "                ", "save_num", "+=", "1", "\n", "", "", "logger", ".", "info", "(", "\"Saving the best model checkpoint epoch {} to {}\"", ".", "format", "(", "best_model", "[", "'epoch'", "]", ",", "output_dir", ")", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa.evaluate": [[682, 785], ["time.time", "zip", "time.time", "logger.info", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "model.eval", "tuple", "len", "len", "os.path.exists", "torch.no_grad", "torch.no_grad", "model", "tmp_eval_loss.mean().item", "torch.sum", "torch.sum", "results_dict.update", "torch.sum.sum().item", "logits.size", "t.to", "run_vqa.compute_score_with_logits", "tmp_eval_loss.mean", "torch.sum.sum", "zip", "batch[].view().tolist", "torch.sum.tolist", "batch[].view"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.SmoothedValue.update", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.compute_score_with_logits"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", "=", "None", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "'-MM'", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "#if args.n_gpu > 1: model = torch.nn.DataParallel(model) # debug: single-gpu or multi-gpus", "\n", "\n", "results", "=", "[", "]", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "num_workers", "=", "args", ".", "workers", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "num_data", "=", "0", "\n", "score", "=", "0", "\n", "upper_bound", "=", "0", "\n", "results_dict", "=", "{", "}", "\n", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "#for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "batch", "[", "4", "]", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n", "# batch_score = compute_score_with_logits(logits, batch[4]).sum()", "\n", "batch_score", "=", "torch", ".", "sum", "(", "\n", "compute_score_with_logits", "(", "logits", ",", "batch", "[", "4", "]", ")", ",", "1", ")", "\n", "# update results_dict", "\n", "results_dict", ".", "update", "(", "\n", "{", "qa_ind", ":", "score", "for", "qa_ind", ",", "score", "in", "\n", "zip", "(", "batch", "[", "6", "]", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", ",", "batch_score", ".", "tolist", "(", ")", ")", "}", "\n", ")", "\n", "score", "+=", "batch_score", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "#upper_bound += (batch[4].max(1)[0]).sum().item()", "\n", "num_data", "+=", "logits", ".", "size", "(", "0", ")", "\n", "\n", "# debug", "\n", "#val, idx = logits.max(1)", "\n", "#logger.info('idx: %s, batch[4]: %s' % (str(idx.shape), str(batch[3].shape)))", "\n", "#for i in range(idx.size(0)):", "\n", "#    logger.info('idx: %d, pred: %d, real: %d' % (idx[i].item(), eval_dataset.labels[idx[i].item()], batch[3][i].item()))", "\n", "\n", "", "nb_eval_steps", "+=", "1", "\n", "\n", "#if preds is None:", "\n", "#    preds = logits.detach().cpu().numpy()", "\n", "#    out_label_ids = inputs['labels'].detach().cpu().numpy()", "\n", "#else:", "\n", "#    preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)", "\n", "#    out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)", "\n", "\n", "", "score", "=", "score", "/", "len", "(", "eval_dataloader", ".", "dataset", ")", "\n", "upper_bound", "=", "upper_bound", "/", "len", "(", "eval_dataloader", ".", "dataset", ")", "\n", "\n", "logger", ".", "info", "(", "\"Eval Results:\"", ")", "\n", "logger", ".", "info", "(", "\"Eval Score: %.3f\"", "%", "(", "100", "*", "score", ")", ")", "\n", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "score", ")", ")", "\n", "logger", ".", "info", "(", "\"Eval Upper Bound: %.3f\"", "%", "(", "100", "*", "upper_bound", ")", ")", "\n", "# with open(os.path.join(args.data_dir, 'val_results.json'),", "\n", "#           'w') as f:", "\n", "#     json.dump(results_dict, f)", "\n", "\n", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Eva Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "#eval_loss = eval_loss / nb_eval_steps", "\n", "#if args.output_mode == \"classification\":", "\n", "#    preds = np.argmax(preds, axis=1)", "\n", "#elif args.output_mode == \"regression\":", "\n", "#    preds = np.squeeze(preds)", "\n", "#result = compute_metrics(eval_task, preds, out_label_ids)", "\n", "#results.update(result)", "\n", "\n", "#output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")", "\n", "#with open(output_eval_file, \"w\") as writer:", "\n", "#    logger.info(\"***** Eval results {} *****\".format(prefix))", "\n", "#    for key in sorted(result.keys()):", "\n", "#        logger.info(\"  %s = %s\", key, str(result[key]))", "\n", "#        writer.write(\"%s = %s\\n\" % (key, str(result[key])))", "\n", "\n", "return", "results", ",", "score", ",", "upper_bound", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa.test": [[787, 844], ["_pickle.load", "logger.info", "time.time", "zip", "time.time", "logger.info", "logger.info", "open", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "open", "json.dump", "len", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "model.eval", "tuple", "len", "os.path.exists", "torch.no_grad", "torch.no_grad", "model", "logits.max", "range", "t.to", "idx.size", "[].item", "results.append", "logger.info", "len", "round", "idx[].item", "len", "len"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "test", "(", "args", ",", "model", ",", "eval_dataset", "=", "None", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "'-MM'", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "label2ans", "=", "cPickle", ".", "load", "(", "open", "(", "args", ".", "label2ans_file", ",", "'rb'", ")", ")", "\n", "logger", ".", "info", "(", "'label2ans: %d'", "%", "(", "len", "(", "label2ans", ")", ")", ")", "\n", "\n", "results", "=", "[", "]", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval", "\n", "logger", ".", "info", "(", "\"***** Running Test {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "#for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "None", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "logits", "=", "outputs", "[", "0", "]", "\n", "\n", "val", ",", "idx", "=", "logits", ".", "max", "(", "1", ")", "\n", "#logger.info('idx: %s, batch[6]: %s' % (str(idx.shape), str(batch[6].shape)))", "\n", "\n", "for", "i", "in", "range", "(", "idx", ".", "size", "(", "0", ")", ")", ":", "\n", "#logger.info('idx: %d, batch: %d' % (idx[i].item(), batch[6][i].item()))", "\n", "                    ", "result", "=", "{", "}", "\n", "result", "[", "'question_id'", "]", "=", "batch", "[", "6", "]", "[", "i", "]", ".", "item", "(", ")", "\n", "result", "[", "'answer'", "]", "=", "label2ans", "[", "eval_dataset", ".", "labels", "[", "idx", "[", "i", "]", ".", "item", "(", ")", "]", "]", "#label2ans[idx[i].item()]", "\n", "results", ".", "append", "(", "result", ")", "\n", "\n", "if", "len", "(", "results", ")", "%", "2000", "==", "0", ":", "\n", "                        ", "logger", ".", "info", "(", "\"PROGRESS: {}%\"", ".", "format", "(", "round", "(", "100", "*", "len", "(", "results", ")", "/", "len", "(", "eval_dataset", ")", ",", "4", ")", ")", ")", "\n", "#logger.info('q_id: {0}, answer: {1}'.format(result['question_id'], result['answer']))", "\n", "\n", "", "", "", "", "", "with", "open", "(", "args", ".", "output_dir", "+", "(", "'/{}_results.json'", ".", "format", "(", "eval_dataset", ".", "name", ")", ")", ",", "'w'", ")", "as", "fp", ":", "\n", "        ", "json", ".", "dump", "(", "results", ",", "fp", ")", "\n", "\n", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'# questions: %d'", "%", "(", "len", "(", "results", ")", ")", ")", "\n", "logger", ".", "info", "(", "'Test Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa.load_and_cache_examples": [[846, 912], ["processor.get_labels", "time.time", "numpy.load", "oscar.utils.task_utils.convert_examples_to_features_vqa", "time.time", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "processor.get_dev_examples", "processor.get_train_examples", "os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "print", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "bool", "bool", "time.time", "numpy.zeros", "enumerate", "torch.from_numpy", "torch.from_numpy", "time.time", "logger.info", "torch.tensor", "torch.tensor", "run_vqa.target_tensor", "len"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.convert_examples_to_features_vqa", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.target_tensor"], ["", "def", "load_and_cache_examples", "(", "args", ",", "task", ",", "tokenizer", ",", "evaluate", "=", "False", ")", ":", "\n", "    ", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "output_mode", "=", "output_modes", "[", "task", "]", "\n", "\n", "label_list", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ")", "if", "evaluate", "else", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ")", "\n", "\n", "#img_features = torch.load(os.path.join(args.data_dir, 'val_img_feats.pt' if evaluate else 'train_img_feats.pt'))", "\n", "#img_features = torch.load(os.path.join(args.data_dir, 'val_img_frcnn_feats.pt' if evaluate else 'train_img_frcnn_feats.pt'))", "\n", "img_features", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'val_img_frcnn_feats.npy'", "if", "evaluate", "else", "'train_img_frcnn_feats.npy'", ")", ")", "\n", "\n", "features", "=", "convert_examples_to_features_vqa", "(", "examples", ",", "img_features", ",", "label_list", ",", "args", ".", "max_img_seq_length", ",", "args", ".", "max_seq_length", ",", "\n", "tokenizer", ",", "output_mode", ",", "\n", "cls_token_at_end", "=", "bool", "(", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "\n", "#if args.local_rank in [-1, 0]:", "\n", "#    logger.info(\"Saving features into cached file %s\", cached_features_file)", "\n", "#    torch.save(features, cached_features_file)", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: loading features using %.5f secs'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "# batch*max_seq_len", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "        ", "labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "[", "0", "]", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "targets", "=", "torch", ".", "tensor", "(", "[", "target_tensor", "(", "len", "(", "label_list", ")", ",", "f", ".", "label_id", ",", "f", ".", "score", ")", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "if", "args", ".", "img_feature_dim", ">", "0", ":", "# change here", "\n", "            ", "t_start", "=", "time", ".", "time", "(", ")", "\n", "img_feat_np", "=", "np", ".", "zeros", "(", "(", "labels", ".", "shape", "[", "0", "]", ",", "args", ".", "max_img_seq_length", ",", "args", ".", "img_feature_dim", ")", ")", "\n", "for", "f_id", ",", "f", "in", "enumerate", "(", "features", ")", ":", "\n", "                ", "img_feat_np", "[", "f_id", "]", "=", "f", ".", "img_feat", "\n", "\n", "", "img_feats", "=", "torch", ".", "from_numpy", "(", "img_feat_np", ")", "\n", "\n", "#img_feats = torch.empty((labels.shape[0], args.max_img_seq_length, args.img_feature_dim))", "\n", "#for f_id, f in enumerate(features):", "\n", "#   img_feats[f_id] = f.img_feat", "\n", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: convert image tensor features using %.5f secs'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "#img_feats = torch.stack([f.img_feat[:,-args.img_feature_dim:] for f in features])", "\n", "#img_feats = torch.stack([f.img_feat for f in features])", "\n", "#img_feats = img_feats.type(torch.long)", "\n", "\n", "#print('targets:', targets.shape)", "\n", "", "print", "(", "'img_feats:'", ",", "img_feats", ".", "shape", ")", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "        ", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "if", "args", ".", "img_feature_dim", "==", "-", "1", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "labels", ",", "targets", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "labels", ",", "targets", ",", "img_feats", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa.target_tensor": [[913, 920], ["enumerate"], "function", ["None"], ["", "def", "target_tensor", "(", "len", ",", "labels", ",", "scores", ")", ":", "\n", "    ", "\"\"\" create the target by labels and scores \"\"\"", "\n", "target", "=", "[", "0", "]", "*", "len", "\n", "for", "id", ",", "l", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "target", "[", "l", "]", "=", "scores", "[", "id", "]", "\n", "\n", "", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_vqa.main": [[922, 1221], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "oscar.utils.misc.set_seed", "parser.parse_args.task_name.lower", "processor.get_labels", "len", "logger.info", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "run_vqa.VQADataset", "logger.info", "os.path.join", "logger.info", "os.path.exists", "os.listdir", "logger.info", "logger.info", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.set_device", "torch.cuda.set_device", "torch.device", "torch.device", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "bool", "ValueError", "torch.distributed.barrier", "torch.distributed.barrier", "logger.info", "time.time", "torch.load", "torch.load", "time.time", "logger.info", "logger.info", "torch.distributed.barrier", "torch.distributed.barrier", "run_vqa.VQADataset", "run_vqa.VQADataset", "run_vqa.VQADataset", "run_vqa.train", "logger.info", "run_vqa.VQADataset", "run_vqa.train", "logger.info", "logger.info", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "torch.save", "logger.info", "logger.info", "logger.info", "os.getenv", "os.path.join", "bool", "model_class.from_pretrained.init_code_embedding", "os.makedirs", "os.path.join", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_vqa.evaluate", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_vqa.test", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_vqa.test", "train_code[].t", "model_class.from_pretrained.init_code_embedding", "torch.distributed.get_rank", "torch.distributed.get_rank", "os.path.exists", "MODEL_CLASSES.keys", "oscar.utils.task_utils.processors.keys", "torch.cuda.is_available", "torch.cuda.is_available", "train_code[].t", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "sorted", "sorted", "sorted", "glob.glob", "glob.glob", "glob.glob", "list", "train_code[].keys", "list", "train_code[].keys"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.ImageBertForSequenceClassification.init_code_embedding", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.test", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.test", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.ImageBertForSequenceClassification.init_code_embedding", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the .tsv files (or other data files) for the task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--txt_data_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input text data dir. Should contain the .json files (or other data files) for the task.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--task_name\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train selected in the list: \"", "+", "\", \"", ".", "join", "(", "processors", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--label_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Label Dictionary\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--label2ans_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Label to Answer Dictionary\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--img_feat_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"The input img_feat_dir.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feat_format\"", ",", "default", "=", "'pt'", ",", "type", "=", "str", ",", "help", "=", "\"img_feat_format: pt or tsv.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--data_label_type\"", ",", "default", "=", "'faster'", ",", "type", "=", "str", ",", "help", "=", "\"faster or mask\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--loss_type\"", ",", "default", "=", "'kl'", ",", "type", "=", "str", ",", "help", "=", "\"kl or xe\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_vg\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use VG-QA or not.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_vg_dev\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use VG-QA as validation.\"", ")", "\n", "#parser.add_argument(\"--use_img_layernorm\", action='store_true', help=\"use_img_layernorm\")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer than this will be truncated, sequences shorter will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train_val\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run test on the test set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test_dev\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run test on the test-dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Rul evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--drop_out\"", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "\"Drop out for BERT.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adjust_dp\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Adjust Drop out for BERT.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--adjust_loss\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Adjust Loss Type for BERT.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adjust_loss_epoch\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "help", "=", "\"Adjust Loss Type for BERT.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--classifier\"", ",", "default", "=", "'linear'", ",", "type", "=", "str", ",", "help", "=", "\"linear or mlp\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cls_hidden_scale\"", ",", "default", "=", "2", ",", "type", "=", "int", ",", "help", "=", "\"cls_hidden_scale: for classifier\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--hard_label\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Soft Label or Hard Label.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_img_seq_length\"", ",", "default", "=", "30", ",", "type", "=", "int", ",", "help", "=", "\"The maximum total input image sequence length.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_dim\"", ",", "default", "=", "2054", ",", "type", "=", "int", ",", "help", "=", "\"The Image Feature Dimension.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_type\"", ",", "default", "=", "'faster_r-cnn'", ",", "type", "=", "str", ",", "help", "=", "\"faster_r-cnn or mask_r-cnn\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_voc\"", ",", "default", "=", "512", ",", "type", "=", "int", ",", "help", "=", "\"dis_code_voc: 256, 512\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_level\"", ",", "default", "=", "'top'", ",", "type", "=", "str", ",", "help", "=", "\"code level: top, botttom, both\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--scheduler\"", ",", "default", "=", "'linear'", ",", "type", "=", "str", ",", "help", "=", "\"constant or linear.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_epoch'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "\"Save checkpoint every X epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_after_epoch'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"Save checkpoint after epoch.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_output_dir'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_cache'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_ip'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_port'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--philly\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use Philly: reset the output dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--load_fast\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Load Tensor Fast\"", ")", "\n", "parser", ".", "add_argument", "(", "'-j'", ",", "'--workers'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "help", "=", "'number of data loading workers (default: 4)'", ")", "\n", "\n", "#args = '--data_dir ../vqa/ban-vqa/data/qal_pairs --model_type bert --model_name_or_path bert-base-uncased --task_name vqa_text ' \\", "\n", "#       '--do_train --do_eval --do_lower_case --max_seq_length 40 --per_gpu_eval_batch_size 16 --per_gpu_train_batch_size 16 --learning_rate 2e-5 ' \\", "\n", "#       '--num_train_epochs 20.0 --output_dir ./results/vqa_text --label_file ../vqa/ban-vqa/data/cache/trainval_ans2label.pkl ' \\", "\n", "#       '--save_steps 5000 --overwrite_output_dir --max_img_seq_length 1 --img_feature_dim 565 --img_feature_type dis_code '", "\n", "\n", "#args = '--data_dir ../vqa/ban-vqa/data/qal_pairs --model_type bert --model_name_or_path bert-base-uncased --task_name vqa_text ' \\", "\n", "#       '--do_train --do_eval --do_lower_case --max_seq_length 40 --per_gpu_eval_batch_size 16 --per_gpu_train_batch_size 16 --learning_rate 2e-5 ' \\", "\n", "#       '--num_train_epochs 20.0 --output_dir ./results/vqa_text --label_file ../vqa/ban-vqa/data/cache/trainval_ans2label.pkl ' \\", "\n", "#       '--save_steps 5000 --overwrite_output_dir --max_img_seq_length 10 --img_feature_dim 565 --img_feature_type other '", "\n", "\n", "#args = parser.parse_args(args.split())", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "philly", ":", "# use philly", "\n", "        ", "logger", ".", "info", "(", "'Info: Use Philly, all the output folders are reset.'", ")", "\n", "args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "getenv", "(", "'PT_OUTPUT_DIR'", ")", ",", "args", ".", "output_dir", ")", "\n", "logger", ".", "info", "(", "'OUTPUT_DIR:'", ",", "args", ".", "output_dir", ")", "\n", "\n", "#if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train and not args.overwrite_output_dir:", "\n", "#    raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args.output_dir))", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", ":", "logger", ".", "info", "(", "\"Output Directory Exists.\"", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "logger", ".", "info", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s - %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ".", "seed", ",", "args", ".", "n_gpu", ")", "\n", "\n", "# Prepare GLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "args", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "label_list", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "logger", ".", "info", "(", "'Task Name: {}, #Labels: {}'", ".", "format", "(", "args", ".", "task_name", ",", "num_labels", ")", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "\n", "# discrete code", "\n", "config", ".", "img_feature_dim", "=", "args", ".", "img_feature_dim", "\n", "config", ".", "img_feature_type", "=", "args", ".", "img_feature_type", "\n", "config", ".", "code_voc", "=", "args", ".", "code_voc", "\n", "config", ".", "hidden_dropout_prob", "=", "args", ".", "drop_out", "\n", "config", ".", "loss_type", "=", "args", ".", "loss_type", "\n", "config", ".", "classifier", "=", "args", ".", "classifier", "\n", "config", ".", "cls_hidden_scale", "=", "args", ".", "cls_hidden_scale", "\n", "#config.use_img_layernorm = args.use_img_layernorm", "\n", "\n", "# load discrete code", "\n", "if", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "'Load discrete code from: {}'", ".", "format", "(", "args", ".", "data_dir", ")", ")", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "train_code", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'vqvae'", ",", "'train.pt'", ")", ")", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Load time: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "if", "args", ".", "code_level", "==", "'top'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_t'", "]", ".", "shape", "[", "0", "]", "\n", "config", ".", "code_size", "=", "train_code", "[", "'feats_top'", "]", "[", "list", "(", "train_code", "[", "'feats_top'", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "shape", "[", "0", "]", "\n", "", "elif", "args", ".", "code_level", "==", "'bottom'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_b'", "]", ".", "shape", "[", "0", "]", "\n", "config", ".", "code_size", "=", "train_code", "[", "'feats_bottom'", "]", "[", "list", "(", "train_code", "[", "'feats_bottom'", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "shape", "[", "0", "]", "\n", "", "elif", "args", ".", "code_level", "==", "'both'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_t'", "]", ".", "shape", "[", "0", "]", "+", "train_code", "[", "'embeddings_b'", "]", ".", "shape", "[", "0", "]", "\n", "\n", "", "", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "from_tf", "=", "bool", "(", "'.ckpt'", "in", "args", ".", "model_name_or_path", ")", ",", "config", "=", "config", ")", "\n", "if", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "'Initializing the code embedding with {}'", ".", "format", "(", "args", ".", "code_level", ")", ")", "\n", "if", "args", ".", "code_level", "==", "'top'", ":", "\n", "            ", "model", ".", "init_code_embedding", "(", "train_code", "[", "'embeddings_t'", "]", ".", "t", "(", ")", ")", "\n", "", "elif", "args", ".", "code_level", "==", "'bottom'", ":", "\n", "            ", "model", ".", "init_code_embedding", "(", "train_code", "[", "'embeddings_b'", "]", ".", "t", "(", ")", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "#if args.do_eval:", "\n", "eval_dataset", "=", "VQADataset", "(", "args", ",", "'val'", ",", "tokenizer", ")", "\n", "\n", "if", "args", ".", "do_test", ":", "\n", "        ", "test_dataset", "=", "VQADataset", "(", "args", ",", "'test2015'", ",", "tokenizer", ")", "\n", "\n", "", "if", "args", ".", "do_test_dev", ":", "\n", "        ", "test_dev_dataset", "=", "VQADataset", "(", "args", ",", "'test-dev2015'", ",", "tokenizer", ")", "\n", "\n", "# Training", "\n", "", "if", "args", ".", "do_train", ":", "\n", "#train_dataset = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False)", "\n", "        ", "train_dataset", "=", "VQADataset", "(", "args", ",", "'train'", ",", "tokenizer", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Training on train+val", "\n", "", "if", "args", ".", "do_train_val", ":", "\n", "        ", "train_dataset", "=", "VQADataset", "(", "args", ",", "'train+val'", ",", "tokenizer", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`. They can then be reloaded using `from_pretrained()`", "\n", "#model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training", "\n", "#model_to_save.save_pretrained(args.output_dir)", "\n", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "#model = model_class.from_pretrained(args.output_dir)", "\n", "#tokenizer = tokenizer_class.from_pretrained(args.output_dir)", "\n", "#model.to(args.device)", "\n", "\n", "\n", "# Evaluation", "\n", "#results = {}", "\n", "", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ",", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "score", ",", "upper_bound", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "#result = dict((k + '_{}'.format(global_step), v) for k, v in result.items())", "\n", "#results.update(result)", "\n", "\n", "# Test-Dev", "\n", "", "", "if", "args", ".", "do_test_dev", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "test", "(", "args", ",", "model", ",", "test_dev_dataset", ",", "prefix", "=", "global_step", ")", "\n", "\n", "# Test", "\n", "", "", "if", "args", ".", "do_test", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "test", "(", "args", ",", "model", ",", "test_dataset", ",", "prefix", "=", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.RetrievalDataset.__init__": [[25, 104], ["torch.utils.data.Dataset.__init__", "os.join", "os.join", "oscar.utils.tsv_file.TSVFile", "torch.load", "torch.load", "torch.load", "torch.load", "list", "os.join", "os.join", "json.load", "run_retrieval.RetrievalDataset.captions.keys", "os.dirname", "os.dirname", "open", "os.dirname", "os.dirname", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "oscar.utils.tsv_file.TSVFile", "range", "run_retrieval.RetrievalDataset.label_tsv._fp.close", "type", "json.loads", "run_retrieval.RetrievalDataset.label_tsv.num_rows", "run_retrieval.RetrievalDataset.label_tsv.seek", "os.join", "os.join", "torch.load", "torch.load", "torch.load", "torch.load", "int", "json.loads", "open", "f.readlines", "int", "numpy.array", "os.join", "os.join", "k.strip", "type", "json.loads", "type", "int", "type", "type"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.TensorboardLogger.close", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.num_rows", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek"], ["def", "__init__", "(", "self", ",", "tokenizer", ",", "args", ",", "split", "=", "'train'", ",", "is_train", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        tokenizer: tokenizer to process caption text.\n        args: configureation parameters including max_seq_length, etc.\n        split: used to infer the data used for training or testing. \n             All files are in .pt format of a dictionary with image keys and \n             image features (pytorch tensors), captions (list of str, support multiple\n             captions per image), labels (list of dictionary or str of all labels),\n\n        \"\"\"", "\n", "super", "(", "RetrievalDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "img_file", "=", "args", ".", "img_feat_file", "\n", "caption_file", "=", "op", ".", "join", "(", "args", ".", "data_dir", ",", "'{}_captions.pt'", ".", "format", "(", "split", ")", ")", "\n", "self", ".", "img_tsv", "=", "TSVFile", "(", "self", ".", "img_file", ")", "\n", "self", ".", "captions", "=", "torch", ".", "load", "(", "caption_file", ")", "\n", "self", ".", "img_keys", "=", "list", "(", "self", ".", "captions", ".", "keys", "(", ")", ")", "# img_id as int", "\n", "if", "not", "type", "(", "self", ".", "captions", "[", "self", ".", "img_keys", "[", "0", "]", "]", ")", "==", "list", ":", "\n", "            ", "self", ".", "captions", "=", "{", "k", ":", "json", ".", "loads", "(", "self", ".", "captions", "[", "k", "]", ")", "for", "k", "in", "self", ".", "img_keys", "}", "\n", "\n", "# get the image image_id to index map", "\n", "", "imgid2idx_file", "=", "op", ".", "join", "(", "op", ".", "dirname", "(", "self", ".", "img_file", ")", ",", "'imageid2idx.json'", ")", "\n", "self", ".", "image_id2idx", "=", "json", ".", "load", "(", "open", "(", "imgid2idx_file", ")", ")", "# img_id as string", "\n", "\n", "if", "args", ".", "add_od_labels", ":", "\n", "            ", "label_data_dir", "=", "op", ".", "dirname", "(", "self", ".", "img_file", ")", "\n", "label_file", "=", "os", ".", "path", ".", "join", "(", "label_data_dir", ",", "\"predictions.tsv\"", ")", "\n", "self", ".", "label_tsv", "=", "TSVFile", "(", "label_file", ")", "\n", "self", ".", "labels", "=", "{", "}", "\n", "for", "line_no", "in", "range", "(", "self", ".", "label_tsv", ".", "num_rows", "(", ")", ")", ":", "\n", "                ", "row", "=", "self", ".", "label_tsv", ".", "seek", "(", "line_no", ")", "\n", "image_id", "=", "row", "[", "0", "]", "\n", "if", "int", "(", "image_id", ")", "in", "self", ".", "img_keys", ":", "\n", "                    ", "results", "=", "json", ".", "loads", "(", "row", "[", "1", "]", ")", "\n", "objects", "=", "results", "[", "'objects'", "]", "if", "type", "(", "\n", "results", ")", "==", "dict", "else", "results", "\n", "self", ".", "labels", "[", "int", "(", "image_id", ")", "]", "=", "{", "\n", "\"image_h\"", ":", "results", "[", "\"image_h\"", "]", "if", "type", "(", "\n", "results", ")", "==", "dict", "else", "600", ",", "\n", "\"image_w\"", ":", "results", "[", "\"image_w\"", "]", "if", "type", "(", "\n", "results", ")", "==", "dict", "else", "800", ",", "\n", "\"class\"", ":", "[", "cur_d", "[", "'class'", "]", "for", "cur_d", "in", "objects", "]", ",", "\n", "\"boxes\"", ":", "np", ".", "array", "(", "[", "cur_d", "[", "'rect'", "]", "for", "cur_d", "in", "objects", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "}", "\n", "", "", "self", ".", "label_tsv", ".", "_fp", ".", "close", "(", ")", "\n", "self", ".", "label_tsv", ".", "_fp", "=", "None", "\n", "\n", "", "if", "is_train", ":", "\n", "            ", "self", ".", "num_captions_per_img", "=", "args", ".", "num_captions_per_img_train", "\n", "", "else", ":", "\n", "            ", "self", ".", "num_captions_per_img", "=", "args", ".", "num_captions_per_img_val", "\n", "if", "args", ".", "eval_img_keys_file", ":", "\n", "# select a subset of image keys for evaluation. eg. COCO 1k and 5k", "\n", "# eval_img_keys_file is a list of image keys saved in tsv file", "\n", "                ", "with", "open", "(", "op", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "eval_img_keys_file", ")", ",", "'r'", ")", "as", "f", ":", "\n", "                    ", "img_keys", "=", "f", ".", "readlines", "(", ")", "\n", "", "self", ".", "img_keys", "=", "[", "int", "(", "k", ".", "strip", "(", ")", ")", "for", "k", "in", "img_keys", "]", "\n", "self", ".", "captions", "=", "{", "k", ":", "self", ".", "captions", "[", "k", "]", "for", "k", "in", "self", ".", "img_keys", "}", "\n", "if", "args", ".", "add_od_labels", ":", "\n", "                    ", "self", ".", "labels", "=", "{", "k", ":", "self", ".", "labels", "[", "k", "]", "for", "k", "in", "self", ".", "img_keys", "}", "\n", "\n", "", "", "if", "args", ".", "eval_caption_index_file", ":", "\n", "# hard negative image/caption indexs for retrieval re-rank setting.", "\n", "# useful for mini val set to monitor the performance during training.", "\n", "# However, it cannot be used together with cross image evaluation.", "\n", "                ", "self", ".", "has_caption_indexs", "=", "True", "\n", "assert", "not", "args", ".", "cross_image_eval", "\n", "caption_index_file", "=", "op", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "eval_caption_index_file", ")", "\n", "self", ".", "caption_indexs", "=", "torch", ".", "load", "(", "caption_index_file", ")", "\n", "if", "not", "type", "(", "self", ".", "caption_indexs", "[", "self", ".", "img_keys", "[", "0", "]", "]", ")", "==", "list", ":", "\n", "                    ", "self", ".", "caption_indexs", "=", "{", "k", ":", "json", ".", "loads", "(", "self", ".", "caption_indexs", "[", "k", "]", ")", "for", "k", "in", "self", ".", "img_keys", "}", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "has_caption_indexs", "=", "False", "\n", "", "", "self", ".", "is_train", "=", "is_train", "\n", "self", ".", "output_mode", "=", "args", ".", "output_mode", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_seq_len", "=", "args", ".", "max_seq_length", "\n", "self", ".", "max_img_seq_len", "=", "args", ".", "max_img_seq_length", "\n", "self", ".", "args", "=", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.RetrievalDataset.get_image_caption_index": [[105, 121], ["len", "len"], "methods", ["None"], ["", "def", "get_image_caption_index", "(", "self", ",", "index", ")", ":", "\n", "# return img_idx to access features and [img_key, cap_idx] to access caption", "\n", "        ", "if", "not", "self", ".", "is_train", "and", "self", ".", "args", ".", "cross_image_eval", ":", "\n", "            ", "img_idx", "=", "index", "//", "(", "self", ".", "num_captions_per_img", "*", "len", "(", "self", ".", "img_keys", ")", ")", "\n", "cap_idx", "=", "index", "%", "(", "self", ".", "num_captions_per_img", "*", "len", "(", "self", ".", "img_keys", ")", ")", "\n", "img_idx1", "=", "cap_idx", "//", "self", ".", "num_captions_per_img", "\n", "cap_idx1", "=", "cap_idx", "%", "self", ".", "num_captions_per_img", "\n", "return", "img_idx", ",", "[", "self", ".", "img_keys", "[", "img_idx1", "]", ",", "cap_idx1", "]", "\n", "", "if", "not", "self", ".", "is_train", "and", "self", ".", "has_caption_indexs", ":", "\n", "            ", "img_idx", "=", "index", "//", "self", ".", "num_captions_per_img", "\n", "cap_idx", "=", "index", "%", "self", ".", "num_captions_per_img", "\n", "img_key1", ",", "cap_idx1", "=", "self", ".", "caption_indexs", "[", "self", ".", "img_keys", "[", "img_idx", "]", "]", "[", "cap_idx", "]", "\n", "return", "img_idx", ",", "[", "img_key1", ",", "cap_idx1", "]", "\n", "", "img_idx", "=", "index", "//", "self", ".", "num_captions_per_img", "\n", "cap_idx", "=", "index", "%", "self", ".", "num_captions_per_img", "\n", "return", "img_idx", ",", "[", "self", ".", "img_keys", "[", "img_idx", "]", ",", "cap_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.RetrievalDataset.get_label": [[122, 125], ["run_retrieval.RetrievalDataset.get_image_caption_index"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.RetrievalDataset.get_image_caption_index"], ["", "def", "get_label", "(", "self", ",", "index", ")", ":", "\n", "        ", "img_idx", ",", "cap_idx", "=", "self", ".", "get_image_caption_index", "(", "index", ")", "\n", "return", "1", "if", "self", ".", "img_keys", "[", "img_idx", "]", "==", "cap_idx", "[", "0", "]", "else", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.RetrievalDataset.get_od_labels": [[126, 133], ["type"], "methods", ["None"], ["", "def", "get_od_labels", "(", "self", ",", "img_key", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "add_od_labels", ":", "\n", "            ", "if", "type", "(", "self", ".", "labels", "[", "img_key", "]", ")", "==", "str", ":", "\n", "                ", "od_labels", "=", "self", ".", "labels", "[", "img_key", "]", "\n", "", "else", ":", "\n", "                ", "od_labels", "=", "' '", ".", "join", "(", "self", ".", "labels", "[", "img_key", "]", "[", "'class'", "]", ")", "\n", "", "return", "od_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.RetrievalDataset.tensorize_example": [[134, 200], ["run_retrieval.RetrievalDataset.tokenizer.tokenize", "len", "len", "run_retrieval.RetrievalDataset.tokenizer.convert_tokens_to_ids", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "run_retrieval.RetrievalDataset.tokenizer.tokenize", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len", "len", "len", "len", "ValueError", "len"], "methods", ["None"], ["", "", "def", "tensorize_example", "(", "self", ",", "text_a", ",", "img_feat", ",", "text_b", "=", "None", ",", "\n", "cls_token_segment_id", "=", "0", ",", "pad_token_segment_id", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ")", ":", "\n", "        ", "tokens_a", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "text_a", ")", "\n", "if", "len", "(", "tokens_a", ")", ">", "self", ".", "args", ".", "max_seq_length", "-", "2", ":", "\n", "            ", "tokens_a", "=", "tokens_a", "[", ":", "(", "self", ".", "args", ".", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "tokens", "=", "[", "self", ".", "tokenizer", ".", "cls_token", "]", "+", "tokens_a", "+", "[", "self", ".", "tokenizer", ".", "sep_token", "]", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "[", "sequence_a_segment_id", "]", "*", "(", "len", "(", "tokens_a", ")", "+", "1", ")", "\n", "seq_a_len", "=", "len", "(", "tokens", ")", "\n", "if", "text_b", ":", "\n", "            ", "tokens_b", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "text_b", ")", "\n", "if", "len", "(", "tokens_b", ")", ">", "self", ".", "max_seq_len", "-", "len", "(", "tokens", ")", "-", "1", ":", "\n", "                ", "tokens_b", "=", "tokens_b", "[", ":", "(", "self", ".", "max_seq_len", "-", "len", "(", "tokens", ")", "-", "1", ")", "]", "\n", "", "tokens", "+=", "tokens_b", "+", "[", "self", ".", "tokenizer", ".", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "seq_len", "=", "len", "(", "tokens", ")", "\n", "seq_padding_len", "=", "self", ".", "max_seq_len", "-", "seq_len", "\n", "tokens", "+=", "[", "self", ".", "tokenizer", ".", "pad_token", "]", "*", "seq_padding_len", "\n", "segment_ids", "+=", "[", "pad_token_segment_id", "]", "*", "seq_padding_len", "\n", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# image features", "\n", "img_len", "=", "img_feat", ".", "shape", "[", "0", "]", "\n", "if", "img_len", ">", "self", ".", "max_img_seq_len", ":", "\n", "            ", "img_feat", "=", "img_feat", "[", "0", ":", "self", ".", "max_img_seq_len", ",", ":", "]", "\n", "img_len", "=", "img_feat", ".", "shape", "[", "0", "]", "\n", "img_padding_len", "=", "0", "\n", "", "else", ":", "\n", "            ", "img_padding_len", "=", "self", ".", "max_img_seq_len", "-", "img_len", "\n", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "img_padding_len", ",", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "\n", "# generate attention_mask", "\n", "", "att_mask_type", "=", "self", ".", "args", ".", "att_mask_type", "\n", "if", "att_mask_type", "==", "\"CLR\"", ":", "\n", "            ", "attention_mask", "=", "[", "1", "]", "*", "seq_len", "+", "[", "0", "]", "*", "seq_padding_len", "+", "[", "1", "]", "*", "img_len", "+", "[", "0", "]", "*", "img_padding_len", "\n", "", "else", ":", "\n", "# use 2D mask to represent the attention", "\n", "            ", "max_len", "=", "self", ".", "max_seq_len", "+", "self", ".", "max_img_seq_len", "\n", "attention_mask", "=", "torch", ".", "zeros", "(", "(", "max_len", ",", "max_len", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "# full attention of C-C, L-L, R-R", "\n", "c_start", ",", "c_end", "=", "0", ",", "seq_a_len", "\n", "l_start", ",", "l_end", "=", "seq_a_len", ",", "seq_len", "\n", "r_start", ",", "r_end", "=", "self", ".", "max_seq_len", ",", "self", ".", "max_seq_len", "+", "img_len", "\n", "attention_mask", "[", "c_start", ":", "c_end", ",", "c_start", ":", "c_end", "]", "=", "1", "\n", "attention_mask", "[", "l_start", ":", "l_end", ",", "l_start", ":", "l_end", "]", "=", "1", "\n", "attention_mask", "[", "r_start", ":", "r_end", ",", "r_start", ":", "r_end", "]", "=", "1", "\n", "if", "att_mask_type", "==", "'CL'", ":", "\n", "                ", "attention_mask", "[", "c_start", ":", "c_end", ",", "l_start", ":", "l_end", "]", "=", "1", "\n", "attention_mask", "[", "l_start", ":", "l_end", ",", "c_start", ":", "c_end", "]", "=", "1", "\n", "", "elif", "att_mask_type", "==", "'CR'", ":", "\n", "                ", "attention_mask", "[", "c_start", ":", "c_end", ",", "r_start", ":", "r_end", "]", "=", "1", "\n", "attention_mask", "[", "r_start", ":", "r_end", ",", "c_start", ":", "c_end", "]", "=", "1", "\n", "", "elif", "att_mask_type", "==", "'LR'", ":", "\n", "                ", "attention_mask", "[", "l_start", ":", "l_end", ",", "r_start", ":", "r_end", "]", "=", "1", "\n", "attention_mask", "[", "r_start", ":", "r_end", ",", "l_start", ":", "l_end", "]", "=", "1", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unsupported attention mask type {}\"", ".", "format", "(", "att_mask_type", ")", ")", "\n", "\n", "", "", "input_ids", "=", "torch", ".", "tensor", "(", "input_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "attention_mask", "=", "torch", ".", "tensor", "(", "attention_mask", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "segment_ids", "=", "torch", ".", "tensor", "(", "segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "return", "(", "input_ids", ",", "attention_mask", ",", "segment_ids", ",", "img_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.RetrievalDataset.__getitem__": [[201, 235], ["run_retrieval.RetrievalDataset.get_image_caption_index", "run_retrieval.RetrievalDataset.get_image", "run_retrieval.RetrievalDataset.get_od_labels", "run_retrieval.RetrievalDataset.tensorize_example", "random.choice", "tuple", "run_retrieval.RetrievalDataset.get_image_caption_index", "run_retrieval.RetrievalDataset.get_image", "run_retrieval.RetrievalDataset.get_od_labels", "run_retrieval.RetrievalDataset.tensorize_example", "list", "list", "random.random", "random.randint", "run_retrieval.RetrievalDataset.tensorize_example", "run_retrieval.RetrievalDataset.get_image", "run_retrieval.RetrievalDataset.get_od_labels", "run_retrieval.RetrievalDataset.tensorize_example", "tuple", "range", "range", "len", "list", "list", "list"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.RetrievalDataset.get_image_caption_index", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.RetrievalDataset.get_image", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_od_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize_example", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.RetrievalDataset.get_image_caption_index", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.RetrievalDataset.get_image", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_od_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize_example", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize_example", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.RetrievalDataset.get_image", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_od_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize_example"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "self", ".", "is_train", ":", "\n", "            ", "img_idx", ",", "cap_idxs", "=", "self", ".", "get_image_caption_index", "(", "index", ")", "\n", "img_key", "=", "self", ".", "img_keys", "[", "img_idx", "]", "\n", "feature", "=", "self", ".", "get_image", "(", "img_key", ")", "\n", "caption", "=", "self", ".", "captions", "[", "cap_idxs", "[", "0", "]", "]", "[", "cap_idxs", "[", "1", "]", "]", "\n", "od_labels", "=", "self", ".", "get_od_labels", "(", "img_key", ")", "\n", "example", "=", "self", ".", "tensorize_example", "(", "caption", ",", "feature", ",", "text_b", "=", "od_labels", ")", "\n", "\n", "# select a negative pair", "\n", "neg_img_indexs", "=", "list", "(", "range", "(", "0", ",", "img_idx", ")", ")", "+", "list", "(", "range", "(", "img_idx", "+", "1", ",", "len", "(", "self", ".", "img_keys", ")", ")", ")", "\n", "img_idx_neg", "=", "random", ".", "choice", "(", "neg_img_indexs", ")", "\n", "if", "random", ".", "random", "(", ")", "<=", "0.5", ":", "\n", "# randomly select a negative caption from a different image.", "\n", "                ", "cap_idx_neg", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "num_captions_per_img", "-", "1", ")", "\n", "caption_neg", "=", "self", ".", "captions", "[", "self", ".", "img_keys", "[", "img_idx_neg", "]", "]", "[", "cap_idx_neg", "]", "\n", "example_neg", "=", "self", ".", "tensorize_example", "(", "caption_neg", ",", "feature", ",", "text_b", "=", "od_labels", ")", "\n", "", "else", ":", "\n", "# randomly select a negative image ", "\n", "                ", "feature_neg", "=", "self", ".", "get_image", "(", "self", ".", "img_keys", "[", "img_idx_neg", "]", ")", "\n", "od_labels_neg", "=", "self", ".", "get_od_labels", "(", "self", ".", "img_keys", "[", "img_idx_neg", "]", ")", "\n", "example_neg", "=", "self", ".", "tensorize_example", "(", "caption", ",", "feature_neg", ",", "text_b", "=", "od_labels_neg", ")", "\n", "\n", "", "example_pair", "=", "tuple", "(", "list", "(", "example", ")", "+", "[", "1", "]", "+", "list", "(", "example_neg", ")", "+", "[", "0", "]", ")", "\n", "return", "index", ",", "example_pair", "\n", "", "else", ":", "\n", "            ", "img_idx", ",", "cap_idxs", "=", "self", ".", "get_image_caption_index", "(", "index", ")", "\n", "img_key", "=", "self", ".", "img_keys", "[", "img_idx", "]", "\n", "feature", "=", "self", ".", "get_image", "(", "img_key", ")", "\n", "caption", "=", "self", ".", "captions", "[", "cap_idxs", "[", "0", "]", "]", "[", "cap_idxs", "[", "1", "]", "]", "\n", "od_labels", "=", "self", ".", "get_od_labels", "(", "img_key", ")", "\n", "example", "=", "self", ".", "tensorize_example", "(", "caption", ",", "feature", ",", "text_b", "=", "od_labels", ")", "\n", "label", "=", "1", "if", "img_key", "==", "cap_idxs", "[", "0", "]", "else", "0", "\n", "return", "index", ",", "tuple", "(", "list", "(", "example", ")", "+", "[", "label", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.RetrievalDataset.get_image": [[236, 244], ["run_retrieval.RetrievalDataset.img_tsv.seek", "int", "numpy.frombuffer().reshape", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "str", "numpy.frombuffer", "base64.b64decode"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek"], ["", "", "def", "get_image", "(", "self", ",", "image_id", ")", ":", "\n", "        ", "image_idx", "=", "self", ".", "image_id2idx", "[", "str", "(", "image_id", ")", "]", "\n", "row", "=", "self", ".", "img_tsv", ".", "seek", "(", "image_idx", ")", "\n", "num_boxes", "=", "int", "(", "row", "[", "1", "]", ")", "\n", "features", "=", "np", ".", "frombuffer", "(", "base64", ".", "b64decode", "(", "row", "[", "-", "1", "]", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "(", "num_boxes", ",", "-", "1", ")", ")", "\n", "t_features", "=", "torch", ".", "from_numpy", "(", "features", ")", "\n", "return", "t_features", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.RetrievalDataset.__len__": [[245, 249], ["len", "len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "is_train", "and", "self", ".", "args", ".", "cross_image_eval", ":", "\n", "            ", "return", "len", "(", "self", ".", "img_keys", ")", "**", "2", "*", "self", ".", "num_captions_per_img", "\n", "", "return", "len", "(", "self", ".", "img_keys", ")", "*", "self", ".", "num_captions_per_img", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.compute_score_with_logits": [[251, 262], ["torch.zeros_like().cuda", "torch.zeros_like().cuda", "enumerate", "zip", "torch.sigmoid", "torch.sigmoid", "torch.max", "torch.max", "torch.zeros_like", "torch.zeros_like"], "function", ["None"], ["", "", "def", "compute_score_with_logits", "(", "logits", ",", "labels", ")", ":", "\n", "    ", "if", "logits", ".", "shape", "[", "1", "]", ">", "1", ":", "\n", "        ", "logits", "=", "torch", ".", "max", "(", "logits", ",", "1", ")", "[", "1", "]", ".", "data", "# argmax", "\n", "scores", "=", "logits", "==", "labels", "\n", "", "else", ":", "\n", "        ", "scores", "=", "torch", ".", "zeros_like", "(", "labels", ")", ".", "cuda", "(", ")", "\n", "for", "i", ",", "(", "logit", ",", "label", ")", "in", "enumerate", "(", "zip", "(", "logits", ",", "labels", ")", ")", ":", "\n", "            ", "logit_", "=", "torch", ".", "sigmoid", "(", "logit", ")", "\n", "if", "(", "logit_", ">=", "0.5", "and", "label", "==", "1", ")", "or", "(", "logit_", "<", "0.5", "and", "label", "==", "0", ")", ":", "\n", "                ", "scores", "[", "i", "]", "=", "1", "\n", "", "", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.compute_ranks": [[264, 294], ["numpy.array", "numpy.array", "numpy.reshape", "numpy.reshape", "zip", "enumerate", "i2t_ranks.append", "numpy.swapaxes", "numpy.swapaxes", "zip", "dataset.get_label", "len", "numpy.argsort", "enumerate", "t2i_ranks.append", "range", "range", "numpy.argsort", "len", "len"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.RetrievalDataset.get_label"], ["", "def", "compute_ranks", "(", "dataset", ",", "results", ")", ":", "\n", "    ", "labels", "=", "np", ".", "array", "(", "[", "dataset", ".", "get_label", "(", "i", ")", "for", "i", "in", "range", "(", "len", "(", "dataset", ")", ")", "]", ")", "\n", "similarities", "=", "np", ".", "array", "(", "[", "results", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "dataset", ")", ")", "]", ")", "\n", "if", "dataset", ".", "has_caption_indexs", ":", "\n", "        ", "num_captions_per_img", "=", "dataset", ".", "num_captions_per_img", "\n", "", "else", ":", "\n", "        ", "num_captions_per_img", "=", "len", "(", "dataset", ".", "img_keys", ")", "*", "dataset", ".", "num_captions_per_img", "\n", "", "labels", "=", "np", ".", "reshape", "(", "labels", ",", "[", "-", "1", ",", "num_captions_per_img", "]", ")", "\n", "similarities", "=", "np", ".", "reshape", "(", "similarities", ",", "[", "-", "1", ",", "num_captions_per_img", "]", ")", "\n", "i2t_ranks", ",", "t2i_ranks", "=", "[", "]", ",", "[", "]", "\n", "for", "lab", ",", "sim", "in", "zip", "(", "labels", ",", "similarities", ")", ":", "\n", "        ", "inds", "=", "np", ".", "argsort", "(", "sim", ")", "[", ":", ":", "-", "1", "]", "\n", "rank", "=", "num_captions_per_img", "\n", "for", "r", ",", "ind", "in", "enumerate", "(", "inds", ")", ":", "\n", "            ", "if", "lab", "[", "ind", "]", "==", "1", ":", "\n", "                ", "rank", "=", "r", "\n", "break", "\n", "", "", "i2t_ranks", ".", "append", "(", "rank", ")", "\n", "", "if", "not", "dataset", ".", "has_caption_indexs", ":", "\n", "        ", "labels", "=", "np", ".", "swapaxes", "(", "labels", ",", "0", ",", "1", ")", "\n", "similarities", "=", "np", ".", "swapaxes", "(", "similarities", ",", "0", ",", "1", ")", "\n", "for", "lab", ",", "sim", "in", "zip", "(", "labels", ",", "similarities", ")", ":", "\n", "            ", "inds", "=", "np", ".", "argsort", "(", "sim", ")", "[", ":", ":", "-", "1", "]", "\n", "rank", "=", "num_captions_per_img", "\n", "for", "r", ",", "ind", "in", "enumerate", "(", "inds", ")", ":", "\n", "                ", "if", "lab", "[", "ind", "]", "==", "1", ":", "\n", "                    ", "rank", "=", "r", "\n", "break", "\n", "", "", "t2i_ranks", ".", "append", "(", "rank", ")", "\n", "", "", "return", "i2t_ranks", ",", "t2i_ranks", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.save_checkpoint": [[296, 314], ["os.join", "oscar.utils.misc.mkdir", "hasattr", "logger.info", "model_to_save.save_pretrained", "torch.save", "torch.save", "tokenizer.save_pretrained", "logger.info", "os.join"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.mkdir"], ["", "def", "save_checkpoint", "(", "model", ",", "tokenizer", ",", "args", ",", "epoch", ",", "global_step", ")", ":", "\n", "    ", "checkpoint_dir", "=", "op", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-{}-{}'", ".", "format", "(", "\n", "epoch", ",", "global_step", ")", ")", "\n", "mkdir", "(", "checkpoint_dir", ")", "\n", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "\n", "save_num", "=", "0", "\n", "while", "(", "save_num", "<", "10", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "model_to_save", ".", "save_pretrained", "(", "checkpoint_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "op", ".", "join", "(", "checkpoint_dir", ",", "'training_args.bin'", ")", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "checkpoint_dir", ")", "\n", "logger", ".", "info", "(", "\"Save checkpoint to {}\"", ".", "format", "(", "checkpoint_dir", ")", ")", "\n", "break", "\n", "", "except", ":", "\n", "            ", "save_num", "+=", "1", "\n", "", "", "if", "save_num", "==", "10", ":", "\n", "        ", "logger", ".", "info", "(", "\"Failed to save checkpoint after 10 trails.\"", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.train": [[316, 417], ["torch.utils.data.RandomSampler", "torch.utils.data.DataLoader", "transformers.pytorch_transformers.AdamW", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.zero_grad", "range", "max", "transformers.pytorch_transformers.WarmupConstantSchedule", "torch.nn.DataParallel", "torch.nn.DataParallel", "len", "int", "enumerate", "transformers.pytorch_transformers.WarmupLinearSchedule", "ValueError", "torch.nn.DataParallel.train", "tuple", "torch.nn.DataParallel.", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "compute_score_with_logits().sum", "loss.mean.item", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "loss.mean.mean", "torch.nn.DataParallel.parameters", "compute_score_with_logits().sum.item", "transformers.pytorch_transformers.WarmupLinearSchedule.step", "transformers.pytorch_transformers.AdamW.step", "torch.nn.DataParallel.zero_grad", "len", "torch.nn.DataParallel.named_parameters", "torch.nn.DataParallel.named_parameters", "any", "t.to", "run_retrieval.compute_score_with_logits", "logger.info", "run_retrieval.save_checkpoint", "any", "logger.info", "run_retrieval.test", "run_retrieval.evaluate", "log_json.append", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.compute_score_with_logits", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.save_checkpoint", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.test", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "val_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "args", ".", "train_batch_size", ",", "num_workers", "=", "args", ".", "num_workers", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and scheduler", "\n", "", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "if", "args", ".", "scheduler", "==", "\"constant\"", ":", "\n", "        ", "scheduler", "=", "WarmupConstantSchedule", "(", "\n", "optimizer", ",", "warmup_steps", "=", "args", ".", "warmup_steps", ")", "\n", "", "elif", "args", ".", "scheduler", "==", "\"linear\"", ":", "\n", "        ", "scheduler", "=", "WarmupLinearSchedule", "(", "\n", "optimizer", ",", "warmup_steps", "=", "args", ".", "warmup_steps", ",", "t_total", "=", "t_total", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown scheduler type: {}\"", ".", "format", "(", "args", ".", "scheduler", ")", ")", "\n", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", ",", "global_loss", ",", "global_acc", "=", "0", ",", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "log_json", "=", "[", "]", "\n", "best_score", "=", "0", "\n", "for", "epoch", "in", "range", "(", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "        ", "for", "step", ",", "(", "_", ",", "batch", ")", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "\n", "'input_ids'", ":", "torch", ".", "cat", "(", "(", "batch", "[", "0", "]", ",", "batch", "[", "5", "]", ")", ",", "dim", "=", "0", ")", ",", "\n", "'attention_mask'", ":", "torch", ".", "cat", "(", "(", "batch", "[", "1", "]", ",", "batch", "[", "6", "]", ")", ",", "dim", "=", "0", ")", ",", "\n", "'token_type_ids'", ":", "torch", ".", "cat", "(", "(", "batch", "[", "2", "]", ",", "batch", "[", "7", "]", ")", ",", "dim", "=", "0", ")", ",", "\n", "'img_feats'", ":", "torch", ".", "cat", "(", "(", "batch", "[", "3", "]", ",", "batch", "[", "8", "]", ")", ",", "dim", "=", "0", ")", ",", "\n", "'labels'", ":", "torch", ".", "cat", "(", "(", "batch", "[", "4", "]", ",", "batch", "[", "9", "]", ")", ",", "dim", "=", "0", ")", "\n", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "batch_score", "=", "compute_score_with_logits", "(", "logits", ",", "inputs", "[", "'labels'", "]", ")", ".", "sum", "(", ")", "\n", "batch_acc", "=", "batch_score", ".", "item", "(", ")", "/", "(", "args", ".", "train_batch_size", "*", "2", ")", "\n", "global_loss", "+=", "loss", ".", "item", "(", ")", "\n", "global_acc", "+=", "batch_acc", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "global_step", "+=", "1", "\n", "scheduler", ".", "step", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "if", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Epoch: {}, global_step: {}, lr: {:.6f}, loss: {:.4f} ({:.4f}), \"", "\"score: {:.4f} ({:.4f})\"", ".", "format", "(", "epoch", ",", "global_step", ",", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", ",", "loss", ",", "global_loss", "/", "global_step", ",", "\n", "batch_acc", ",", "global_acc", "/", "global_step", ")", "\n", ")", "\n", "\n", "", "if", "(", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ")", "or", "global_step", "==", "t_total", ":", "\n", "                    ", "save_checkpoint", "(", "model", ",", "tokenizer", ",", "args", ",", "epoch", ",", "global_step", ")", "\n", "# evaluation", "\n", "if", "args", ".", "evaluate_during_training", ":", "\n", "                        ", "logger", ".", "info", "(", "\"Perform evaluation at step: %d\"", "%", "(", "global_step", ")", ")", "\n", "test_result", "=", "test", "(", "args", ",", "model", ",", "val_dataset", ")", "\n", "eval_result", "=", "evaluate", "(", "val_dataset", ",", "test_result", ")", "\n", "rank_accs", "=", "eval_result", "[", "'i2t_retrieval'", "]", "\n", "if", "rank_accs", "[", "'R@1'", "]", ">", "best_score", ":", "\n", "                            ", "best_score", "=", "rank_accs", "[", "'R@1'", "]", "\n", "", "epoch_log", "=", "{", "'epoch'", ":", "epoch", ",", "'global_step'", ":", "global_step", ",", "\n", "'R1'", ":", "rank_accs", "[", "'R@1'", "]", ",", "'R5'", ":", "rank_accs", "[", "'R@5'", "]", ",", "\n", "'R10'", ":", "rank_accs", "[", "'R@10'", "]", ",", "'best_R1'", ":", "best_score", "}", "\n", "log_json", ".", "append", "(", "epoch_log", ")", "\n", "with", "open", "(", "args", ".", "output_dir", "+", "'/eval_logs.json'", ",", "'w'", ")", "as", "fp", ":", "\n", "                            ", "json", ".", "dump", "(", "log_json", ",", "fp", ")", "\n", "", "", "", "", "", "", "return", "global_step", ",", "global_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.test": [[419, 449], ["torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "model.eval", "torch.Softmax", "tqdm.tqdm", "max", "tuple", "len", "torch.no_grad", "torch.no_grad", "results.update", "t.to", "model", "nn.Softmax.", "_.to", "torch.device", "torch.device", "idx.item", "res.item", "zip"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.SmoothedValue.update"], ["", "def", "test", "(", "args", ",", "model", ",", "eval_dataset", ")", ":", "\n", "    ", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "\n", "batch_size", "=", "args", ".", "eval_batch_size", ",", "num_workers", "=", "args", ".", "num_workers", ")", "\n", "\n", "logger", ".", "info", "(", "\"Num examples = {}\"", ".", "format", "(", "len", "(", "eval_dataset", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Evaluation batch size = {}\"", ".", "format", "(", "args", ".", "eval_batch_size", ")", ")", "\n", "model", ".", "eval", "(", ")", "\n", "results", "=", "{", "}", "\n", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "for", "indexs", ",", "batch", "in", "tqdm", "(", "eval_dataloader", ")", ":", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "\n", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", ",", "\n", "'img_feats'", ":", "batch", "[", "3", "]", ",", "\n", "'labels'", ":", "batch", "[", "4", "]", "\n", "}", "\n", "_", ",", "logits", "=", "model", "(", "**", "inputs", ")", "[", ":", "2", "]", "\n", "if", "args", ".", "num_labels", "==", "2", ":", "\n", "                ", "probs", "=", "softmax", "(", "logits", ")", "\n", "result", "=", "probs", "[", ":", ",", "1", "]", "# the confidence to be a matched pair", "\n", "", "else", ":", "\n", "                ", "result", "=", "logits", "\n", "", "result", "=", "[", "_", ".", "to", "(", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "for", "_", "in", "result", "]", "\n", "results", ".", "update", "(", "{", "idx", ".", "item", "(", ")", ":", "res", ".", "item", "(", ")", "for", "idx", ",", "res", "in", "zip", "(", "indexs", ",", "result", ")", "}", ")", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.evaluate": [[451, 464], ["run_retrieval.compute_ranks", "logger.info", "logger.info", "sum", "len", "sum", "len"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.compute_ranks"], ["", "def", "evaluate", "(", "eval_dataset", ",", "test_results", ")", ":", "\n", "    ", "i2t_ranks", ",", "t2i_ranks", "=", "compute_ranks", "(", "eval_dataset", ",", "test_results", ")", "\n", "rank", "=", "[", "1", ",", "5", ",", "10", "]", "\n", "i2t_accs", "=", "[", "sum", "(", "[", "_", "<", "r", "for", "_", "in", "i2t_ranks", "]", ")", "/", "len", "(", "i2t_ranks", ")", "for", "r", "in", "rank", "]", "\n", "logger", ".", "info", "(", "\"I2T Retrieval: {:.4f} @ R1, {:.4f} @ R5, {:.4f} @ R10\"", ".", "format", "(", "\n", "i2t_accs", "[", "0", "]", ",", "i2t_accs", "[", "1", "]", ",", "i2t_accs", "[", "2", "]", ")", ")", "\n", "eval_result", "=", "{", "\"i2t_retrieval\"", ":", "{", "\"R@1\"", ":", "i2t_accs", "[", "0", "]", ",", "\"R@5\"", ":", "i2t_accs", "[", "1", "]", ",", "\"R@10\"", ":", "i2t_accs", "[", "2", "]", "}", "}", "\n", "if", "t2i_ranks", ":", "\n", "        ", "t2i_accs", "=", "[", "sum", "(", "[", "_", "<", "r", "for", "_", "in", "t2i_ranks", "]", ")", "/", "len", "(", "t2i_ranks", ")", "for", "r", "in", "rank", "]", "\n", "logger", ".", "info", "(", "\"T2I Retrieval: {:.4f} @ R1, {:.4f} @ R5, {:.4f} @ R10\"", ".", "format", "(", "\n", "t2i_accs", "[", "0", "]", ",", "t2i_accs", "[", "1", "]", ",", "t2i_accs", "[", "2", "]", ")", ")", "\n", "eval_result", "[", "\"t2i_retrieval\"", "]", "=", "{", "\"R@1\"", ":", "t2i_accs", "[", "0", "]", ",", "\"R@5\"", ":", "t2i_accs", "[", "1", "]", ",", "\"R@10\"", ":", "t2i_accs", "[", "2", "]", "}", "\n", "", "return", "eval_result", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.get_predict_file": [[466, 475], ["os.basename", "cc.append", "os.join", "cc.append", "cc.append", "os.join"], "function", ["None"], ["", "def", "get_predict_file", "(", "args", ")", ":", "\n", "    ", "cc", "=", "[", "]", "\n", "data", "=", "op", ".", "basename", "(", "op", ".", "join", "(", "args", ".", "data_dir", ",", "''", ")", "[", ":", "-", "1", "]", ")", "\n", "if", "data", "!=", "'coco_ir'", ":", "\n", "        ", "cc", ".", "append", "(", "data", ")", "\n", "", "cc", ".", "append", "(", "args", ".", "test_split", ")", "\n", "if", "args", ".", "add_od_labels", ":", "\n", "        ", "cc", ".", "append", "(", "'wlabels{}'", ".", "format", "(", "args", ".", "od_label_type", ")", ")", "\n", "", "return", "op", ".", "join", "(", "args", ".", "eval_model_dir", ",", "'{}.results.pt'", ".", "format", "(", "'.'", ".", "join", "(", "cc", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.restore_training_settings": [[477, 492], ["torch.load", "torch.load", "os.join", "hasattr", "getattr", "getattr", "logger.warning", "setattr"], "function", ["None"], ["", "def", "restore_training_settings", "(", "args", ")", ":", "\n", "    ", "assert", "not", "args", ".", "do_train", "and", "(", "args", ".", "do_test", "or", "args", ".", "do_eval", ")", "\n", "train_args", "=", "torch", ".", "load", "(", "op", ".", "join", "(", "args", ".", "eval_model_dir", ",", "'training_args.bin'", ")", ")", "\n", "override_params", "=", "[", "'do_lower_case'", ",", "'img_feature_type'", ",", "'max_seq_length'", ",", "\n", "'max_img_seq_length'", ",", "'add_od_labels'", ",", "'od_label_type'", ",", "\n", "'use_img_layernorm'", ",", "'img_layer_norm_eps'", "]", "\n", "for", "param", "in", "override_params", ":", "\n", "        ", "if", "hasattr", "(", "train_args", ",", "param", ")", ":", "\n", "            ", "train_v", "=", "getattr", "(", "train_args", ",", "param", ")", "\n", "test_v", "=", "getattr", "(", "args", ",", "param", ")", "\n", "if", "train_v", "!=", "test_v", ":", "\n", "                ", "logger", ".", "warning", "(", "'Override {} with train args: {} -> {}'", ".", "format", "(", "param", ",", "\n", "test_v", ",", "train_v", ")", ")", "\n", "setattr", "(", "args", ",", "param", ",", "train_v", ")", "\n", "", "", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_retrieval.main": [[494, 661], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "oscar.utils.misc.mkdir", "oscar.utils.logger.setup_logger", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "oscar.utils.misc.set_seed", "oscar.utils.logger.setup_logger.warning", "oscar.utils.logger.setup_logger.info", "torch.nn.DataParallel.to", "oscar.utils.logger.setup_logger.info", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "os.isdir", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "oscar.utils.logger.setup_logger.info", "model_class.from_pretrained", "run_retrieval.RetrievalDataset", "run_retrieval.train", "oscar.utils.logger.setup_logger.info", "run_retrieval.restore_training_settings", "run_retrieval.RetrievalDataset", "os.isdir", "oscar.utils.logger.setup_logger.info", "model_class.from_pretrained", "torch.nn.DataParallel.to", "run_retrieval.get_predict_file", "os.isfile", "run_retrieval.RetrievalDataset", "torch.nn.DataParallel", "torch.nn.DataParallel", "oscar.utils.logger.setup_logger.info", "run_retrieval.test", "torch.save", "torch.save", "oscar.utils.logger.setup_logger.info", "run_retrieval.evaluate", "oscar.utils.logger.setup_logger.info", "torch.cuda.is_available", "torch.cuda.is_available", "bool", "torch.load", "torch.load", "open", "json.dump", "os.splitext"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.mkdir", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.logger.setup_logger", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.restore_training_settings", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.get_predict_file", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.test", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "default", "=", "'datasets/coco_ir'", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "help", "=", "\"The input data dir with all required files.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feat_file\"", ",", "default", "=", "'datasets/coco_ir/features.tsv'", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "help", "=", "\"The absolute address of the image feature file.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "help", "=", "\"Path to pre-trained model or model type. required for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "'output/'", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "help", "=", "\"The output directory to save checkpoint and test results.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--loss_type\"", ",", "default", "=", "'sfmx'", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Loss function types: support kl, sfmx\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained config name or path if not the same as model_name.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "default", "=", "70", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. \"", "\n", "\"Sequences longer than this will be truncated, \"", "\n", "\"sequences shorter will be padded.\"", "\n", "\"This number is calculated on COCO dataset\"", "\n", "\"If add object detection labels, the suggested length should be 70.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run inference.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run performance valuation.\"", "\n", "\"do not activate if we want to inference on dataset without gt labels.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_split\"", ",", "default", "=", "'test'", ",", "type", "=", "str", ",", "help", "=", "'data split name.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_img_keys_file\"", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"image key tsv to select a subset of images for evaluation. \"", "\n", "\"This is useful in 5-folds evaluation. The topn index file is not \"", "\n", "\"needed in this case.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_caption_index_file\"", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"index of a list of (img_key, cap_idx) for each image.\"", "\n", "\"this is used to perform re-rank using hard negative samples.\"", "\n", "\"useful for validation set to monitor the performance during training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cross_image_eval\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"perform cross image inference, ie. each image with all texts from other images.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--add_od_labels\"", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to add object detection labels or not.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--od_label_type\"", ",", "default", "=", "'vg'", ",", "type", "=", "str", ",", "\n", "help", "=", "\"label type, support vg, gt, oid\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--att_mask_type\"", ",", "default", "=", "'CLR'", ",", "type", "=", "str", ",", "\n", "help", "=", "\"attention mask type, support ['CL', 'CR', 'LR', 'CLR']\"", "\n", "\"C: caption, L: labels, R: image regions; CLR is full attention by default.\"", "\n", "\"CL means attention between caption and labels.\"", "\n", "\"please pay attention to the order CLR, which is the default concat order.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--drop_out\"", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "\"Drop out in BERT.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_img_seq_length\"", ",", "default", "=", "50", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input image sequence length.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_dim\"", ",", "default", "=", "2054", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The Image Feature Dimension.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_type\"", ",", "default", "=", "'frcnn'", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Image feature type.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_img_layernorm\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Normalize image features with bertlayernorm\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_layer_norm_eps\"", ",", "default", "=", "1e-12", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The eps in image feature laynorm layer\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "32", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "64", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_mode\"", ",", "default", "=", "'classification'", ",", "type", "=", "str", ",", "\n", "help", "=", "\"output mode, support classification or regression.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_labels\"", ",", "default", "=", "2", ",", "type", "=", "int", ",", "\n", "help", "=", "\"num_labels is 2 for classification and 1 for regression.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_captions_per_img_train\"", ",", "default", "=", "5", ",", "type", "=", "int", ",", "\n", "help", "=", "\"number of positive matched captions for each training image.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_captions_per_img_val\"", ",", "default", "=", "5", ",", "type", "=", "int", ",", "\n", "help", "=", "\"number of captions for each testing image.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before backward.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "2e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial lr.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.05", ",", "type", "=", "float", ",", "help", "=", "\"Weight deay.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--scheduler\"", ",", "default", "=", "'linear'", ",", "type", "=", "str", ",", "help", "=", "\"constant or linear.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_workers\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Workers in dataloader.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "20", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Total number of training steps. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "20", ",", "help", "=", "\"Log every X steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Save checkpoint every X steps. Will also perform evaluatin.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Run evaluation during training at each save_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_model_dir\"", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "\"Model directory for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Avoid using CUDA.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "88", ",", "help", "=", "\"random seed for initialization.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "global", "logger", "\n", "mkdir", "(", "args", ".", "output_dir", ")", "\n", "logger", "=", "setup_logger", "(", "\"vlpretrain\"", ",", "args", ".", "output_dir", ",", "0", ")", "\n", "\n", "args", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "set_seed", "(", "args", ".", "seed", ",", "args", ".", "n_gpu", ")", "\n", "logger", ".", "warning", "(", "\"Device: %s, n_gpu: %s\"", ",", "args", ".", "device", ",", "args", ".", "n_gpu", ")", "\n", "logger", ".", "info", "(", "'output_mode: {}, #Labels: {}'", ".", "format", "(", "args", ".", "output_mode", ",", "args", ".", "num_labels", ")", ")", "\n", "\n", "config_class", ",", "tokenizer_class", "=", "BertConfig", ",", "BertTokenizer", "\n", "model_class", "=", "ImageBertForSequenceClassification", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "num_labels", "=", "args", ".", "num_labels", ",", "finetuning_task", "=", "'ir'", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "config", ".", "img_feature_dim", "=", "args", ".", "img_feature_dim", "\n", "config", ".", "img_feature_type", "=", "args", ".", "img_feature_type", "\n", "config", ".", "hidden_dropout_prob", "=", "args", ".", "drop_out", "\n", "config", ".", "loss_type", "=", "args", ".", "loss_type", "\n", "config", ".", "img_layer_norm_eps", "=", "args", ".", "img_layer_norm_eps", "\n", "config", ".", "use_img_layernorm", "=", "args", ".", "use_img_layernorm", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "'.ckpt'", "in", "args", ".", "model_name_or_path", ")", ",", "config", "=", "config", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "args", ".", "eval_model_dir", "\n", "assert", "op", ".", "isdir", "(", "checkpoint", ")", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "logger", ".", "info", "(", "\"Evaluate the following checkpoint: %s\"", ",", "checkpoint", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ",", "config", "=", "config", ")", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "RetrievalDataset", "(", "tokenizer", ",", "args", ",", "'train'", ",", "is_train", "=", "True", ")", "\n", "if", "args", ".", "evaluate_during_training", ":", "\n", "            ", "val_dataset", "=", "RetrievalDataset", "(", "tokenizer", ",", "args", ",", "'minival'", ",", "is_train", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "val_dataset", "=", "None", "\n", "", "global_step", ",", "avg_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "val_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\"Training done: total_step = %s, avg loss = %s\"", ",", "global_step", ",", "avg_loss", ")", "\n", "\n", "# inference and evaluation", "\n", "", "if", "args", ".", "do_test", "or", "args", ".", "do_eval", ":", "\n", "        ", "args", "=", "restore_training_settings", "(", "args", ")", "\n", "test_dataset", "=", "RetrievalDataset", "(", "tokenizer", ",", "args", ",", "args", ".", "test_split", ",", "is_train", "=", "False", ")", "\n", "checkpoint", "=", "args", ".", "eval_model_dir", "\n", "assert", "op", ".", "isdir", "(", "checkpoint", ")", "\n", "logger", ".", "info", "(", "\"Evaluate the following checkpoint: %s\"", ",", "checkpoint", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ",", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "", "pred_file", "=", "get_predict_file", "(", "args", ")", "\n", "if", "op", ".", "isfile", "(", "pred_file", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"Prediction file exist, skip inference.\"", ")", "\n", "if", "args", ".", "do_eval", ":", "\n", "                ", "test_result", "=", "torch", ".", "load", "(", "pred_file", ")", "\n", "", "", "else", ":", "\n", "            ", "test_result", "=", "test", "(", "args", ",", "model", ",", "test_dataset", ")", "\n", "torch", ".", "save", "(", "test_result", ",", "pred_file", ")", "\n", "logger", ".", "info", "(", "\"Prediction results saved to {}.\"", ".", "format", "(", "pred_file", ")", ")", "\n", "\n", "", "if", "args", ".", "do_eval", ":", "\n", "            ", "eval_result", "=", "evaluate", "(", "test_dataset", ",", "test_result", ")", "\n", "result_file", "=", "op", ".", "splitext", "(", "pred_file", ")", "[", "0", "]", "+", "'.eval.json'", "\n", "with", "open", "(", "result_file", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "eval_result", ",", "f", ")", "\n", "", "logger", ".", "info", "(", "\"Evaluation results saved to {}.\"", ".", "format", "(", "result_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.__init__": [[30, 74], ["oscar.utils.misc.load_from_yaml_file", "os.dirname", "os.dirname", "oscar.utils.misc.find_file_path_in_yaml", "oscar.utils.misc.find_file_path_in_yaml", "oscar.utils.misc.find_file_path_in_yaml", "os.isfile", "os.isfile", "oscar.utils.tsv_file.TSVFile", "run_captioning.CaptionTensorizer", "run_captioning.CaptionTSVDataset.prepare_image_keys", "run_captioning.CaptionTSVDataset.prepare_image_key_to_index", "run_captioning.CaptionTSVDataset.prepare_image_key_to_captions", "run_captioning.CaptionTSVDataset.cfg.get", "os.isfile", "os.isfile", "oscar.utils.tsv_file.TSVFile", "os.isfile", "os.isfile", "os.isfile", "os.isfile", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.load_from_yaml_file", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.find_file_path_in_yaml", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.find_file_path_in_yaml", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.find_file_path_in_yaml", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.prepare_image_keys", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.prepare_image_key_to_index", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.prepare_image_key_to_captions"], ["    ", "def", "__init__", "(", "self", ",", "yaml_file", ",", "tokenizer", "=", "None", ",", "add_od_labels", "=", "True", ",", "\n", "max_img_seq_length", "=", "50", ",", "max_seq_length", "=", "70", ",", "max_seq_a_length", "=", "40", ",", "\n", "is_train", "=", "True", ",", "mask_prob", "=", "0.15", ",", "max_masked_tokens", "=", "3", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Constructor.\n        Args:\n            yaml file with all required data (image feature, caption, labels, etc)\n            tokenizer: tokenizer for text processing.\n            add_od_labels: whether to add labels from yaml file to BERT. \n            max_img_seq_length: max image sequence length.\n            max_seq_length: max text sequence length.\n            max_seq_a_length: max caption sequence length.\n            is_train: train or test mode.\n            mask_prob: probability to mask a input token.\n            max_masked_tokens: maximum number of tokens to be masked in one sentence.\n            kwargs: other arguments.\n        \"\"\"", "\n", "self", ".", "yaml_file", "=", "yaml_file", "\n", "self", ".", "cfg", "=", "load_from_yaml_file", "(", "yaml_file", ")", "\n", "self", ".", "root", "=", "op", ".", "dirname", "(", "yaml_file", ")", "\n", "self", ".", "label_file", "=", "find_file_path_in_yaml", "(", "self", ".", "cfg", "[", "'label'", "]", ",", "self", ".", "root", ")", "\n", "self", ".", "feat_file", "=", "find_file_path_in_yaml", "(", "self", ".", "cfg", "[", "'feature'", "]", ",", "self", ".", "root", ")", "\n", "self", ".", "caption_file", "=", "find_file_path_in_yaml", "(", "self", ".", "cfg", ".", "get", "(", "'caption'", ")", ",", "self", ".", "root", ")", "\n", "\n", "assert", "op", ".", "isfile", "(", "self", ".", "feat_file", ")", "\n", "if", "add_od_labels", ":", "assert", "op", ".", "isfile", "(", "self", ".", "label_file", ")", "\n", "if", "is_train", ":", "assert", "op", ".", "isfile", "(", "self", ".", "caption_file", ")", "and", "tokenizer", "is", "not", "None", "\n", "\n", "self", ".", "label_tsv", "=", "None", "if", "not", "self", ".", "label_file", "else", "TSVFile", "(", "self", ".", "label_file", ")", "\n", "self", ".", "feat_tsv", "=", "TSVFile", "(", "self", ".", "feat_file", ")", "\n", "self", ".", "captions", "=", "[", "]", "\n", "if", "self", ".", "caption_file", "and", "op", ".", "isfile", "(", "self", ".", "caption_file", ")", ":", "\n", "            ", "with", "open", "(", "self", ".", "caption_file", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "self", ".", "captions", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "tensorizer", "=", "CaptionTensorizer", "(", "self", ".", "tokenizer", ",", "max_img_seq_length", ",", "\n", "max_seq_length", ",", "max_seq_a_length", ",", "mask_prob", ",", "max_masked_tokens", ",", "\n", "is_train", "=", "is_train", ")", "\n", "self", ".", "add_od_labels", "=", "add_od_labels", "\n", "self", ".", "is_train", "=", "is_train", "\n", "self", ".", "kwargs", "=", "kwargs", "\n", "self", ".", "image_keys", "=", "self", ".", "prepare_image_keys", "(", ")", "\n", "self", ".", "key2index", "=", "self", ".", "prepare_image_key_to_index", "(", ")", "\n", "self", ".", "key2captions", "=", "self", ".", "prepare_image_key_to_captions", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_valid_tsv": [[75, 81], ["None"], "methods", ["None"], ["", "def", "get_valid_tsv", "(", "self", ")", ":", "\n", "# based on the order of file size", "\n", "        ", "if", "self", ".", "label_tsv", ":", "\n", "            ", "return", "self", ".", "label_tsv", "\n", "", "if", "self", ".", "feat_tsv", ":", "\n", "            ", "return", "self", ".", "feat_tsv", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.prepare_image_keys": [[82, 85], ["run_captioning.CaptionTSVDataset.get_valid_tsv", "run_captioning.CaptionTSVDataset.seek", "range", "run_captioning.CaptionTSVDataset.num_rows"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_valid_tsv", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.num_rows"], ["", "", "def", "prepare_image_keys", "(", "self", ")", ":", "\n", "        ", "tsv", "=", "self", ".", "get_valid_tsv", "(", ")", "\n", "return", "[", "tsv", ".", "seek", "(", "i", ")", "[", "0", "]", "for", "i", "in", "range", "(", "tsv", ".", "num_rows", "(", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.prepare_image_key_to_index": [[86, 89], ["run_captioning.CaptionTSVDataset.get_valid_tsv", "run_captioning.CaptionTSVDataset.seek", "range", "run_captioning.CaptionTSVDataset.num_rows"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_valid_tsv", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.num_rows"], ["", "def", "prepare_image_key_to_index", "(", "self", ")", ":", "\n", "        ", "tsv", "=", "self", ".", "get_valid_tsv", "(", ")", "\n", "return", "{", "tsv", ".", "seek", "(", "i", ")", "[", "0", "]", ":", "i", "for", "i", "in", "range", "(", "tsv", ".", "num_rows", "(", ")", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.prepare_image_key_to_captions": [[90, 96], ["key2captions[].append"], "methods", ["None"], ["", "def", "prepare_image_key_to_captions", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "captions", ":", "\n", "            ", "key2captions", "=", "{", "key", ":", "[", "]", "for", "key", "in", "self", ".", "image_keys", "}", "\n", "for", "cap", "in", "self", ".", "captions", ":", "\n", "                ", "key2captions", "[", "cap", "[", "'image_id'", "]", "]", ".", "append", "(", "cap", "[", "'caption'", "]", ")", "\n", "", "return", "key2captions", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_image_index": [[97, 103], ["None"], "methods", ["None"], ["", "", "def", "get_image_index", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "self", ".", "is_train", ":", "\n", "            ", "img_cap_pair", "=", "self", ".", "captions", "[", "idx", "]", "\n", "img_key", "=", "img_cap_pair", "[", "'image_id'", "]", "\n", "return", "self", ".", "key2index", "[", "img_key", "]", "\n", "", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_image_key": [[104, 107], ["run_captioning.CaptionTSVDataset.get_image_index"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_image_index"], ["", "def", "get_image_key", "(", "self", ",", "idx", ")", ":", "\n", "        ", "img_idx", "=", "self", ".", "get_image_index", "(", "idx", ")", "\n", "return", "self", ".", "image_keys", "[", "img_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_image_features": [[108, 114], ["json.loads", "numpy.frombuffer().reshape", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "run_captioning.CaptionTSVDataset.feat_tsv.seek", "numpy.frombuffer", "base64.b64decode"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek"], ["", "def", "get_image_features", "(", "self", ",", "img_idx", ")", ":", "\n", "        ", "feat_info", "=", "json", ".", "loads", "(", "self", ".", "feat_tsv", ".", "seek", "(", "img_idx", ")", "[", "1", "]", ")", "\n", "num_boxes", "=", "feat_info", "[", "'num_boxes'", "]", "\n", "features", "=", "np", ".", "frombuffer", "(", "base64", ".", "b64decode", "(", "feat_info", "[", "'features'", "]", ")", ",", "np", ".", "float32", "\n", ")", ".", "reshape", "(", "(", "num_boxes", ",", "-", "1", ")", ")", "\n", "return", "torch", ".", "Tensor", "(", "features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_caption": [[115, 120], ["None"], "methods", ["None"], ["", "def", "get_caption", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "self", ".", "is_train", ":", "\n", "            ", "img_cap_pair", "=", "self", ".", "captions", "[", "idx", "]", "\n", "return", "img_cap_pair", "[", "'caption'", "]", "\n", "", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_od_labels": [[121, 127], ["json.loads", "run_captioning.CaptionTSVDataset.label_tsv.seek"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek"], ["", "def", "get_od_labels", "(", "self", ",", "img_idx", ")", ":", "\n", "        ", "od_labels", "=", "None", "\n", "if", "self", ".", "add_od_labels", ":", "\n", "            ", "label_info", "=", "json", ".", "loads", "(", "self", ".", "label_tsv", ".", "seek", "(", "img_idx", ")", "[", "1", "]", ")", "\n", "od_labels", "=", "\" \"", ".", "join", "(", "[", "l", "[", "'class'", "]", "for", "l", "in", "label_info", "]", ")", "\n", "", "return", "od_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_caption_file_in_coco_format": [[128, 131], ["os.splitext", "os.splitext"], "methods", ["None"], ["", "def", "get_caption_file_in_coco_format", "(", "self", ")", ":", "\n", "        ", "cap_file", "=", "op", ".", "splitext", "(", "self", ".", "caption_file", ")", "[", "0", "]", "+", "'_coco_format.json'", "\n", "return", "cap_file", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_captions_by_key": [[132, 134], ["None"], "methods", ["None"], ["", "def", "get_captions_by_key", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "key2captions", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.__getitem__": [[135, 143], ["run_captioning.CaptionTSVDataset.get_image_index", "run_captioning.CaptionTSVDataset.get_image_features", "run_captioning.CaptionTSVDataset.get_caption", "run_captioning.CaptionTSVDataset.get_od_labels", "run_captioning.CaptionTSVDataset.tensorizer.tensorize_example"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_image_index", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_image_features", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_caption", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_od_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize_example"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "img_idx", "=", "self", ".", "get_image_index", "(", "idx", ")", "\n", "img_key", "=", "self", ".", "image_keys", "[", "img_idx", "]", "\n", "features", "=", "self", ".", "get_image_features", "(", "img_idx", ")", "\n", "caption", "=", "self", ".", "get_caption", "(", "idx", ")", "\n", "od_labels", "=", "self", ".", "get_od_labels", "(", "img_idx", ")", "\n", "example", "=", "self", ".", "tensorizer", ".", "tensorize_example", "(", "caption", ",", "features", ",", "text_b", "=", "od_labels", ")", "\n", "return", "img_key", ",", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.__len__": [[144, 148], ["run_captioning.CaptionTSVDataset.get_valid_tsv().num_rows", "len", "run_captioning.CaptionTSVDataset.get_valid_tsv"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.num_rows", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_valid_tsv"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "is_train", ":", "\n", "            ", "return", "len", "(", "self", ".", "captions", ")", "\n", "", "return", "self", ".", "get_valid_tsv", "(", ")", ".", "num_rows", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDatasetWithConstraints.__init__": [[162, 180], ["run_captioning.CaptionTSVDataset.__init__", "oscar.utils.misc.find_file_path_in_yaml", "oscar.utils.misc.find_file_path_in_yaml", "oscar.utils.misc.find_file_path_in_yaml", "oscar.utils.misc.find_file_path_in_yaml", "oscar.utils.cbs.ConstraintBoxesReader", "oscar.utils.cbs.ConstraintFilter", "oscar.utils.cbs.FiniteStateMachineBuilder"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.find_file_path_in_yaml", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.find_file_path_in_yaml", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.find_file_path_in_yaml", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.find_file_path_in_yaml"], ["def", "__init__", "(", "\n", "self", ",", "yaml_file", ",", "\n", "nms_threshold", "=", "0.85", ",", "\n", "max_given_constraints", "=", "3", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "yaml_file", ",", "**", "kwargs", ")", "\n", "boxes_tsvpath", "=", "find_file_path_in_yaml", "(", "self", ".", "cfg", "[", "'cbs_box'", "]", ",", "self", ".", "root", ")", "\n", "constraint2tokens_tsvpath", "=", "find_file_path_in_yaml", "(", "self", ".", "cfg", "[", "'cbs_constraint'", "]", ",", "self", ".", "root", ")", "\n", "tokenforms_tsvpath", "=", "find_file_path_in_yaml", "(", "self", ".", "cfg", "[", "'cbs_tokenforms'", "]", ",", "self", ".", "root", ")", "\n", "hierarchy_jsonpath", "=", "find_file_path_in_yaml", "(", "self", ".", "cfg", "[", "'cbs_hierarchy'", "]", ",", "self", ".", "root", ")", "\n", "\n", "self", ".", "_boxes_reader", "=", "ConstraintBoxesReader", "(", "boxes_tsvpath", ")", "\n", "self", ".", "_constraint_filter", "=", "ConstraintFilter", "(", "\n", "hierarchy_jsonpath", ",", "nms_threshold", ",", "max_given_constraints", "\n", ")", "\n", "self", ".", "_fsm_builder", "=", "FiniteStateMachineBuilder", "(", "self", ".", "tokenizer", ",", "\n", "constraint2tokens_tsvpath", ",", "tokenforms_tsvpath", ",", "\n", "max_given_constraints", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDatasetWithConstraints.__getitem__": [[181, 194], ["run_captioning.CaptionTSVDataset.__getitem__", "run_captioning.CaptionTSVDatasetWithConstraints._constraint_filter", "len", "run_captioning.CaptionTSVDatasetWithConstraints._fsm_builder.build"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.__getitem__", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.FiniteStateMachineBuilder.build"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "img_key", ",", "example", "=", "super", "(", ")", ".", "__getitem__", "(", "index", ")", "\n", "\n", "# Apply constraint filtering to object class names.", "\n", "constraint_boxes", "=", "self", ".", "_boxes_reader", "[", "img_key", "]", "\n", "\n", "candidates", "=", "self", ".", "_constraint_filter", "(", "\n", "constraint_boxes", "[", "\"boxes\"", "]", ",", "constraint_boxes", "[", "\"class_names\"", "]", ",", "constraint_boxes", "[", "\"scores\"", "]", "\n", ")", "\n", "num_constraints", "=", "len", "(", "candidates", ")", "\n", "fsm", ",", "nstates", "=", "self", ".", "_fsm_builder", ".", "build", "(", "candidates", ")", "\n", "\n", "return", "img_key", ",", "example", "+", "(", "fsm", ",", "num_constraints", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTensorizer.__init__": [[197, 219], ["torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "max_img_seq_length", "=", "50", ",", "max_seq_length", "=", "70", ",", "\n", "max_seq_a_length", "=", "40", ",", "mask_prob", "=", "0.15", ",", "max_masked_tokens", "=", "3", ",", "\n", "is_train", "=", "True", ")", ":", "\n", "        ", "\"\"\"Constructor.\n        Args:\n            tokenizer: tokenizer for text processing.\n            max_img_seq_length: max image sequence length.\n            max_seq_length: max text sequence length.\n            max_seq_a_length: max caption sequence length.\n            is_train: train or test mode.\n            mask_prob: probability to mask a input token.\n            max_masked_tokens: maximum number of tokens to be masked in one sentence.\n        \"\"\"", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "is_train", "=", "is_train", "\n", "self", ".", "max_img_seq_len", "=", "max_img_seq_length", "\n", "self", ".", "max_seq_len", "=", "max_seq_length", "\n", "self", ".", "max_seq_a_len", "=", "max_seq_a_length", "\n", "self", ".", "mask_prob", "=", "mask_prob", "\n", "self", ".", "max_masked_tokens", "=", "max_masked_tokens", "\n", "self", ".", "_triangle_mask", "=", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "(", "self", ".", "max_seq_len", ",", "\n", "self", ".", "max_seq_len", ")", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTensorizer.tensorize_example": [[220, 325], ["len", "len", "run_captioning.CaptionTensorizer.tokenizer.convert_tokens_to_ids", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "attention_mask[].copy_", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "run_captioning.CaptionTensorizer.tokenizer.tokenize", "len", "run_captioning.CaptionTensorizer.tokenizer.tokenize", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "list", "random.shuffle", "min", "int", "sorted", "run_captioning.CaptionTensorizer.tokenizer.convert_tokens_to_ids", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "range", "max", "len", "len", "round", "random.random", "len", "random.random", "randint", "run_captioning.CaptionTensorizer.tokenizer._convert_id_to_token", "run_captioning.CaptionTensorizer.tokenizer._convert_id_to_token", "len", "len"], "methods", ["None"], ["", "def", "tensorize_example", "(", "self", ",", "text_a", ",", "img_feat", ",", "text_b", "=", "None", ",", "\n", "cls_token_segment_id", "=", "0", ",", "pad_token_segment_id", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ")", ":", "\n", "        ", "if", "self", ".", "is_train", ":", "\n", "            ", "tokens_a", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "text_a", ")", "\n", "", "else", ":", "\n", "# fake tokens to generate masks", "\n", "            ", "tokens_a", "=", "[", "self", ".", "tokenizer", ".", "mask_token", "]", "*", "(", "self", ".", "max_seq_a_len", "-", "2", ")", "\n", "", "if", "len", "(", "tokens_a", ")", ">", "self", ".", "max_seq_a_len", "-", "2", ":", "\n", "            ", "tokens_a", "=", "tokens_a", "[", ":", "(", "self", ".", "max_seq_a_len", "-", "2", ")", "]", "\n", "\n", "", "tokens", "=", "[", "self", ".", "tokenizer", ".", "cls_token", "]", "+", "tokens_a", "+", "[", "self", ".", "tokenizer", ".", "sep_token", "]", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "[", "sequence_a_segment_id", "]", "*", "(", "len", "(", "tokens", ")", "-", "1", ")", "\n", "seq_a_len", "=", "len", "(", "tokens", ")", "\n", "if", "text_b", ":", "\n", "# pad text_a to keep it in fixed length for better inference.", "\n", "            ", "padding_a_len", "=", "self", ".", "max_seq_a_len", "-", "seq_a_len", "\n", "tokens", "+=", "[", "self", ".", "tokenizer", ".", "pad_token", "]", "*", "padding_a_len", "\n", "segment_ids", "+=", "(", "[", "pad_token_segment_id", "]", "*", "padding_a_len", ")", "\n", "\n", "tokens_b", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "text_b", ")", "\n", "if", "len", "(", "tokens_b", ")", ">", "self", ".", "max_seq_len", "-", "len", "(", "tokens", ")", "-", "1", ":", "\n", "                ", "tokens_b", "=", "tokens_b", "[", ":", "(", "self", ".", "max_seq_len", "-", "len", "(", "tokens", ")", "-", "1", ")", "]", "\n", "", "tokens", "+=", "tokens_b", "+", "[", "self", ".", "tokenizer", ".", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "seq_len", "=", "len", "(", "tokens", ")", "\n", "if", "self", ".", "is_train", ":", "\n", "            ", "masked_pos", "=", "torch", ".", "zeros", "(", "self", ".", "max_seq_len", ",", "dtype", "=", "torch", ".", "int", ")", "\n", "# randomly mask words for prediction, ignore [CLS]", "\n", "candidate_masked_idx", "=", "list", "(", "range", "(", "1", ",", "seq_a_len", ")", ")", "# only mask text_a", "\n", "random", ".", "shuffle", "(", "candidate_masked_idx", ")", "\n", "num_masked", "=", "min", "(", "max", "(", "round", "(", "self", ".", "mask_prob", "*", "seq_a_len", ")", ",", "1", ")", ",", "self", ".", "max_masked_tokens", ")", "\n", "num_masked", "=", "int", "(", "num_masked", ")", "\n", "masked_idx", "=", "candidate_masked_idx", "[", ":", "num_masked", "]", "\n", "masked_idx", "=", "sorted", "(", "masked_idx", ")", "\n", "masked_token", "=", "[", "tokens", "[", "i", "]", "for", "i", "in", "masked_idx", "]", "\n", "for", "pos", "in", "masked_idx", ":", "\n", "                ", "if", "random", ".", "random", "(", ")", "<=", "0.8", ":", "\n", "# 80% chance to be a ['MASK'] token", "\n", "                    ", "tokens", "[", "pos", "]", "=", "self", ".", "tokenizer", ".", "mask_token", "\n", "", "elif", "random", ".", "random", "(", ")", "<=", "0.5", ":", "\n", "# 10% chance to be a random word ((1-0.8)*0.5)", "\n", "                    ", "from", "random", "import", "randint", "\n", "i", "=", "randint", "(", "0", ",", "len", "(", "self", ".", "tokenizer", ".", "vocab", ")", ")", "\n", "self", ".", "tokenizer", ".", "_convert_id_to_token", "(", "i", ")", "\n", "tokens", "[", "pos", "]", "=", "self", ".", "tokenizer", ".", "_convert_id_to_token", "(", "i", ")", "\n", "", "else", ":", "\n", "# 10% chance to remain the same (1-0.8-0.1)", "\n", "                    ", "pass", "\n", "\n", "", "", "masked_pos", "[", "masked_idx", "]", "=", "1", "\n", "# pad masked tokens to the same length", "\n", "if", "num_masked", "<", "self", ".", "max_masked_tokens", ":", "\n", "                ", "masked_token", "=", "masked_token", "+", "(", "[", "self", ".", "tokenizer", ".", "pad_token", "]", "*", "\n", "(", "self", ".", "max_masked_tokens", "-", "num_masked", ")", ")", "\n", "", "masked_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "masked_token", ")", "\n", "", "else", ":", "\n", "            ", "masked_pos", "=", "torch", ".", "ones", "(", "self", ".", "max_seq_len", ",", "dtype", "=", "torch", ".", "int", ")", "\n", "\n", "# pad on the right for image captioning", "\n", "", "padding_len", "=", "self", ".", "max_seq_len", "-", "seq_len", "\n", "tokens", "=", "tokens", "+", "(", "[", "self", ".", "tokenizer", ".", "pad_token", "]", "*", "padding_len", ")", "\n", "segment_ids", "+=", "(", "[", "pad_token_segment_id", "]", "*", "padding_len", ")", "\n", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# image features", "\n", "img_len", "=", "img_feat", ".", "shape", "[", "0", "]", "\n", "if", "img_len", ">", "self", ".", "max_img_seq_len", ":", "\n", "            ", "img_feat", "=", "img_feat", "[", "0", ":", "self", ".", "max_img_seq_len", ",", "]", "\n", "img_len", "=", "img_feat", ".", "shape", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "self", ".", "max_img_seq_len", "-", "img_len", ",", "\n", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "\n", "# prepare attention mask:", "\n", "# note that there is no attention from caption to image", "\n", "# because otherwise it will violate the triangle attention ", "\n", "# for caption as caption will have full attention on image. ", "\n", "", "max_len", "=", "self", ".", "max_seq_len", "+", "self", ".", "max_img_seq_len", "\n", "attention_mask", "=", "torch", ".", "zeros", "(", "(", "max_len", ",", "max_len", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "# C: caption, L: label, R: image region", "\n", "c_start", ",", "c_end", "=", "0", ",", "seq_a_len", "\n", "l_start", ",", "l_end", "=", "self", ".", "max_seq_a_len", ",", "seq_len", "\n", "r_start", ",", "r_end", "=", "self", ".", "max_seq_len", ",", "self", ".", "max_seq_len", "+", "img_len", "\n", "# triangle mask for caption to caption", "\n", "attention_mask", "[", "c_start", ":", "c_end", ",", "c_start", ":", "c_end", "]", ".", "copy_", "(", "self", ".", "_triangle_mask", "[", "0", ":", "seq_a_len", ",", "0", ":", "seq_a_len", "]", ")", "\n", "# full attention for L-L, R-R", "\n", "attention_mask", "[", "l_start", ":", "l_end", ",", "l_start", ":", "l_end", "]", "=", "1", "\n", "attention_mask", "[", "r_start", ":", "r_end", ",", "r_start", ":", "r_end", "]", "=", "1", "\n", "# full attention for C-L, C-R", "\n", "attention_mask", "[", "c_start", ":", "c_end", ",", "l_start", ":", "l_end", "]", "=", "1", "\n", "attention_mask", "[", "c_start", ":", "c_end", ",", "r_start", ":", "r_end", "]", "=", "1", "\n", "# full attention for L-R:", "\n", "attention_mask", "[", "l_start", ":", "l_end", ",", "r_start", ":", "r_end", "]", "=", "1", "\n", "attention_mask", "[", "r_start", ":", "r_end", ",", "l_start", ":", "l_end", "]", "=", "1", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "input_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "segment_ids", "=", "torch", ".", "tensor", "(", "segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "if", "self", ".", "is_train", ":", "\n", "            ", "masked_ids", "=", "torch", ".", "tensor", "(", "masked_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "return", "(", "input_ids", ",", "attention_mask", ",", "segment_ids", ",", "img_feat", ",", "masked_pos", ",", "masked_ids", ")", "\n", "", "return", "(", "input_ids", ",", "attention_mask", ",", "segment_ids", ",", "img_feat", ",", "masked_pos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.build_dataset": [[327, 345], ["dataset_class", "os.isfile", "os.join", "os.isfile", "run_captioning.CaptionTSVDataset"], "function", ["None"], ["", "", "def", "build_dataset", "(", "yaml_file", ",", "tokenizer", ",", "args", ",", "is_train", "=", "True", ")", ":", "\n", "    ", "if", "not", "op", ".", "isfile", "(", "yaml_file", ")", ":", "\n", "        ", "yaml_file", "=", "op", ".", "join", "(", "args", ".", "data_dir", ",", "yaml_file", ")", "\n", "assert", "op", ".", "isfile", "(", "yaml_file", ")", "\n", "\n", "", "if", "is_train", ":", "\n", "        ", "return", "CaptionTSVDataset", "(", "yaml_file", ",", "tokenizer", "=", "tokenizer", ",", "\n", "add_od_labels", "=", "args", ".", "add_od_labels", ",", "max_img_seq_length", "=", "args", ".", "max_img_seq_length", ",", "\n", "max_seq_length", "=", "args", ".", "max_seq_length", ",", "max_seq_a_length", "=", "args", ".", "max_seq_a_length", ",", "\n", "is_train", "=", "True", ",", "mask_prob", "=", "args", ".", "mask_prob", ",", "max_masked_tokens", "=", "args", ".", "max_masked_tokens", ")", "\n", "", "if", "args", ".", "use_cbs", ":", "\n", "        ", "dataset_class", "=", "CaptionTSVDatasetWithConstraints", "\n", "", "else", ":", "\n", "        ", "dataset_class", "=", "CaptionTSVDataset", "\n", "", "return", "dataset_class", "(", "yaml_file", ",", "tokenizer", "=", "tokenizer", ",", "\n", "add_od_labels", "=", "args", ".", "add_od_labels", ",", "max_img_seq_length", "=", "args", ".", "max_img_seq_length", ",", "\n", "max_seq_length", "=", "args", ".", "max_seq_length", ",", "max_seq_a_length", "=", "args", ".", "max_gen_length", ",", "\n", "is_train", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.make_data_sampler": [[347, 355], ["torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.sampler.RandomSampler", "torch.utils.data.sampler.RandomSampler", "torch.utils.data.sampler.SequentialSampler", "torch.utils.data.sampler.SequentialSampler"], "function", ["None"], ["", "def", "make_data_sampler", "(", "dataset", ",", "shuffle", ",", "distributed", ")", ":", "\n", "    ", "if", "distributed", ":", "\n", "        ", "return", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "dataset", ",", "shuffle", "=", "shuffle", ")", "\n", "", "if", "shuffle", ":", "\n", "        ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "RandomSampler", "(", "dataset", ")", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "SequentialSampler", "(", "dataset", ")", "\n", "", "return", "sampler", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.make_data_loader": [[357, 381], ["run_captioning.build_dataset", "run_captioning.make_data_sampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "run_captioning.get_world_size", "len"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.build.build_dataset", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.build.make_data_sampler", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size"], ["", "def", "make_data_loader", "(", "args", ",", "yaml_file", ",", "tokenizer", ",", "is_distributed", "=", "True", ",", "\n", "is_train", "=", "True", ")", ":", "\n", "    ", "dataset", "=", "build_dataset", "(", "yaml_file", ",", "tokenizer", ",", "args", ",", "\n", "is_train", "=", "(", "is_train", "and", "not", "args", ".", "scst", ")", ")", "\n", "if", "is_train", ":", "\n", "        ", "shuffle", "=", "True", "\n", "images_per_gpu", "=", "args", ".", "per_gpu_train_batch_size", "\n", "images_per_batch", "=", "images_per_gpu", "*", "get_world_size", "(", ")", "\n", "iters_per_batch", "=", "len", "(", "dataset", ")", "//", "images_per_batch", "\n", "num_iters", "=", "iters_per_batch", "*", "args", ".", "num_train_epochs", "\n", "logger", ".", "info", "(", "\"Train with {} images per GPU.\"", ".", "format", "(", "images_per_gpu", ")", ")", "\n", "logger", ".", "info", "(", "\"Total batch size {}\"", ".", "format", "(", "images_per_batch", ")", ")", "\n", "logger", ".", "info", "(", "\"Total training steps {}\"", ".", "format", "(", "num_iters", ")", ")", "\n", "", "else", ":", "\n", "        ", "shuffle", "=", "False", "\n", "images_per_gpu", "=", "args", ".", "per_gpu_eval_batch_size", "\n", "\n", "", "sampler", "=", "make_data_sampler", "(", "dataset", ",", "shuffle", ",", "is_distributed", ")", "\n", "data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "num_workers", "=", "args", ".", "num_workers", ",", "sampler", "=", "sampler", ",", "\n", "batch_size", "=", "images_per_gpu", ",", "\n", "pin_memory", "=", "True", ",", "\n", ")", "\n", "return", "data_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.save_checkpoint": [[383, 402], ["os.join", "oscar.utils.misc.mkdir", "range", "run_captioning.is_main_process", "hasattr", "logger.info", "model_to_save.save_pretrained", "torch.save", "torch.save", "tokenizer.save_pretrained", "logger.info", "os.join"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.mkdir", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.is_main_process"], ["", "def", "save_checkpoint", "(", "model", ",", "tokenizer", ",", "args", ",", "epoch", ",", "iteration", ",", "num_trial", "=", "10", ")", ":", "\n", "    ", "checkpoint_dir", "=", "op", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-{}-{}'", ".", "format", "(", "\n", "epoch", ",", "iteration", ")", ")", "\n", "if", "not", "is_main_process", "(", ")", ":", "\n", "        ", "return", "checkpoint_dir", "\n", "", "mkdir", "(", "checkpoint_dir", ")", "\n", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "\n", "for", "i", "in", "range", "(", "num_trial", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "model_to_save", ".", "save_pretrained", "(", "checkpoint_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "op", ".", "join", "(", "checkpoint_dir", ",", "'training_args.bin'", ")", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "checkpoint_dir", ")", "\n", "logger", ".", "info", "(", "\"Save checkpoint to {}\"", ".", "format", "(", "checkpoint_dir", ")", ")", "\n", "break", "\n", "", "except", ":", "\n", "            ", "pass", "\n", "", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Failed to save checkpoint after {} trails.\"", ".", "format", "(", "num_trial", ")", ")", "\n", "", "return", "checkpoint_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.compute_score_with_logits": [[404, 408], ["torch.max", "torch.max"], "function", ["None"], ["", "def", "compute_score_with_logits", "(", "logits", ",", "labels", ")", ":", "\n", "    ", "logits", "=", "torch", ".", "max", "(", "logits", ",", "-", "1", ")", "[", "1", "]", ".", "data", "# argmax", "\n", "scores", "=", "logits", "==", "labels", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.train": [[410, 520], ["transformers.pytorch_transformers.AdamW", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "range", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "transformers.pytorch_transformers.WarmupConstantSchedule", "oscar.utils.caption_evaluate.ScstRewardCriterion", "logger.info", "int", "enumerate", "transformers.pytorch_transformers.WarmupLinearSchedule", "ValueError", "tuple", "scst_train_iter.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "scst_train_iter.item", "len", "run_captioning.get_world_size", "os.join", "torch.nn.parallel.DistributedDataParallel.train", "torch.nn.parallel.DistributedDataParallel.", "run_captioning.compute_score_with_logits", "run_captioning.scst_train_iter", "oscar.utils.caption_evaluate.ScstRewardCriterion.get_score", "torch.nn.parallel.DistributedDataParallel.parameters", "transformers.pytorch_transformers.WarmupLinearSchedule.step", "transformers.pytorch_transformers.AdamW.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "t.to", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "logger.info", "run_captioning.save_checkpoint", "any", "compute_score_with_logits.float", "logger.info", "run_captioning.evaluate", "max", "eval_log.append", "open", "json.load", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.compute_score_with_logits", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.scst_train_iter", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.ScstRewardCriterion.get_score", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.save_checkpoint", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataloader", ",", "val_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "if", "args", ".", "distributed", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ",", "\n", ")", "\n", "\n", "", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and scheduler", "\n", "", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "if", "args", ".", "scheduler", "==", "\"constant\"", ":", "\n", "        ", "scheduler", "=", "WarmupConstantSchedule", "(", "\n", "optimizer", ",", "warmup_steps", "=", "args", ".", "warmup_steps", ")", "\n", "", "elif", "args", ".", "scheduler", "==", "\"linear\"", ":", "\n", "        ", "scheduler", "=", "WarmupLinearSchedule", "(", "\n", "optimizer", ",", "warmup_steps", "=", "args", ".", "warmup_steps", ",", "t_total", "=", "t_total", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown scheduler type: {}\"", ".", "format", "(", "args", ".", "scheduler", ")", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, & accumulation) = %d\"", ",", "\n", "args", ".", "per_gpu_train_batch_size", "*", "get_world_size", "(", ")", "*", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "if", "args", ".", "scst", ":", "\n", "        ", "scst_criterion", "=", "ScstRewardCriterion", "(", "\n", "cider_cached_tokens", "=", "op", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "cider_cached_tokens", ")", ",", "\n", "baseline_type", "=", "args", ".", "sc_baseline_type", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  SCST training...\"", ")", "\n", "\n", "\n", "", "global_step", ",", "global_loss", ",", "global_acc", "=", "0", ",", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "eval_log", "=", "[", "]", "\n", "best_score", "=", "0", "\n", "for", "epoch", "in", "range", "(", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "        ", "for", "step", ",", "(", "img_keys", ",", "batch", ")", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "if", "not", "args", ".", "scst", ":", "\n", "                ", "model", ".", "train", "(", ")", "\n", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", ",", "'img_feats'", ":", "batch", "[", "3", "]", ",", "\n", "'masked_pos'", ":", "batch", "[", "4", "]", ",", "'masked_ids'", ":", "batch", "[", "5", "]", "\n", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "masked_ids", "=", "inputs", "[", "'masked_ids'", "]", "\n", "masked_ids", "=", "masked_ids", "[", "masked_ids", "!=", "0", "]", "\n", "batch_score", "=", "compute_score_with_logits", "(", "logits", ",", "masked_ids", ")", "\n", "batch_acc", "=", "torch", ".", "sum", "(", "batch_score", ".", "float", "(", ")", ")", "/", "torch", ".", "sum", "(", "inputs", "[", "'masked_pos'", "]", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "scst_train_iter", "(", "args", ",", "train_dataloader", ",", "model", ",", "scst_criterion", ",", "img_keys", ",", "batch", ",", "tokenizer", ")", "\n", "batch_acc", "=", "scst_criterion", ".", "get_score", "(", ")", "\n", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "global_loss", "+=", "loss", ".", "item", "(", ")", "\n", "global_acc", "+=", "batch_acc", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "global_step", "+=", "1", "\n", "scheduler", ".", "step", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "if", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Epoch: {}, global_step: {}, lr: {:.6f}, loss: {:.4f} ({:.4f}), \"", "\"score: {:.4f} ({:.4f})\"", ".", "format", "(", "epoch", ",", "global_step", ",", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", ",", "loss", ",", "global_loss", "/", "global_step", ",", "\n", "batch_acc", ",", "global_acc", "/", "global_step", ")", "\n", ")", "\n", "\n", "", "if", "(", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ")", "or", "global_step", "==", "t_total", ":", "\n", "                    ", "checkpoint_dir", "=", "save_checkpoint", "(", "model", ",", "tokenizer", ",", "args", ",", "epoch", ",", "global_step", ")", "\n", "# evaluation", "\n", "if", "args", ".", "evaluate_during_training", ":", "\n", "                        ", "logger", ".", "info", "(", "\"Perform evaluation at step: %d\"", "%", "(", "global_step", ")", ")", "\n", "evaluate_file", "=", "evaluate", "(", "args", ",", "val_dataset", ",", "model", ",", "tokenizer", ",", "\n", "checkpoint_dir", ")", "\n", "with", "open", "(", "evaluate_file", ",", "'r'", ")", "as", "f", ":", "\n", "                            ", "res", "=", "json", ".", "load", "(", "f", ")", "\n", "", "best_score", "=", "max", "(", "best_score", ",", "res", "[", "'CIDEr'", "]", ")", "\n", "res", "[", "'epoch'", "]", "=", "epoch", "\n", "res", "[", "'global_step'", "]", "=", "step", "\n", "res", "[", "'best_CIDEr'", "]", "=", "best_score", "\n", "eval_log", ".", "append", "(", "res", ")", "\n", "with", "open", "(", "args", ".", "output_dir", "+", "'/eval_logs.json'", ",", "'w'", ")", "as", "f", ":", "\n", "                            ", "json", ".", "dump", "(", "eval_log", ",", "f", ")", "\n", "", "", "", "", "", "", "return", "checkpoint_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.scst_train_iter": [[522, 580], ["tokenizer.convert_tokens_to_ids", "model.train", "model", "sample_res_raw.squeeze_", "sample_logprobs.squeeze_", "run_captioning.scst_train_iter._ids_to_captions"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train"], ["", "def", "scst_train_iter", "(", "args", ",", "train_dataloader", ",", "model", ",", "scst_criterion", ",", "\n", "img_keys", ",", "batch", ",", "tokenizer", ")", ":", "\n", "    ", "cls_token_id", ",", "sep_token_id", ",", "pad_token_id", ",", "mask_token_id", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "tokenizer", ".", "cls_token", ",", "\n", "tokenizer", ".", "sep_token", ",", "tokenizer", ".", "pad_token", ",", "tokenizer", ".", "mask_token", "]", "\n", ")", "\n", "inputs", "=", "{", "'is_decode'", ":", "True", ",", "\n", "'input_ids'", ":", "batch", "[", "0", "]", ",", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", ",", "'img_feats'", ":", "batch", "[", "3", "]", ",", "\n", "'masked_pos'", ":", "batch", "[", "4", "]", ",", "\n", "'do_sample'", ":", "False", ",", "\n", "'bos_token_id'", ":", "cls_token_id", ",", "\n", "'pad_token_id'", ":", "pad_token_id", ",", "\n", "'eos_token_ids'", ":", "[", "sep_token_id", "]", ",", "\n", "'mask_token_id'", ":", "mask_token_id", ",", "\n", "# for adding od labels", "\n", "'add_od_labels'", ":", "args", ".", "add_od_labels", ",", "'od_labels_start_posid'", ":", "args", ".", "max_seq_a_length", ",", "\n", "# hyperparameters of beam search", "\n", "'max_length'", ":", "args", ".", "max_gen_length", ",", "\n", "'num_beams'", ":", "args", ".", "sc_beam_size", ",", "\n", "\"temperature\"", ":", "args", ".", "temperature", ",", "\n", "\"top_k\"", ":", "args", ".", "top_k", ",", "\n", "\"top_p\"", ":", "args", ".", "top_p", ",", "\n", "\"repetition_penalty\"", ":", "args", ".", "repetition_penalty", ",", "\n", "\"length_penalty\"", ":", "args", ".", "length_penalty", ",", "\n", "\"num_return_sequences\"", ":", "1", ",", "\n", "\"num_keep_best\"", ":", "1", ",", "\n", "}", "\n", "\n", "def", "_ids_to_captions", "(", "all_ids", ")", ":", "\n", "        ", "captions", "=", "[", "]", "\n", "for", "ids", "in", "all_ids", ":", "\n", "            ", "c", "=", "tokenizer", ".", "decode", "(", "ids", ".", "tolist", "(", ")", ",", "skip_special_tokens", "=", "True", ")", "\n", "captions", ".", "append", "(", "c", ")", "\n", "", "return", "captions", "\n", "\n", "", "if", "args", ".", "sc_baseline_type", "==", "'greedy'", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "greedy_res_raw", ",", "_", "=", "model", "(", "**", "inputs", ")", "\n", "greedy_res_raw", ".", "squeeze_", "(", "1", ")", "# batch_size * max_len", "\n", "", "greedy_res", "=", "_ids_to_captions", "(", "greedy_res_raw", ")", "\n", "", "else", ":", "\n", "        ", "greedy_res", "=", "None", "\n", "\n", "", "model", ".", "train", "(", ")", "\n", "inputs", "[", "'do_sample'", "]", "=", "True", "\n", "inputs", "[", "'num_return_sequences'", "]", "=", "args", ".", "sc_train_sample_n", "\n", "sample_res_raw", ",", "sample_logprobs", "=", "model", "(", "**", "inputs", ")", "\n", "sample_res_raw", ".", "squeeze_", "(", "1", ")", "\n", "sample_logprobs", ".", "squeeze_", "(", "1", ")", "\n", "assert", "sample_logprobs", ".", "requires_grad", "==", "True", "\n", "assert", "sample_res_raw", ".", "requires_grad", "==", "False", "\n", "sample_res", "=", "_ids_to_captions", "(", "sample_res_raw", ")", "\n", "\n", "gt_res", "=", "[", "train_dataloader", ".", "dataset", ".", "get_captions_by_key", "(", "k", ")", "for", "k", "in", "img_keys", "]", "\n", "loss", "=", "scst_criterion", "(", "gt_res", ",", "greedy_res", ",", "sample_res", ",", "sample_logprobs", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.get_predict_file": [[582, 602], ["os.basename", "os.basename", "op.basename.endswith", "cc.append", "cc.append", "cc.append", "cc.append", "os.join", "cc.append", "cc.append", "cc.append", "cc.append", "os.join"], "function", ["None"], ["", "def", "get_predict_file", "(", "output_dir", ",", "yaml_file", ",", "args", ")", ":", "\n", "    ", "cc", "=", "[", "'pred'", "]", "\n", "# make sure it works with/without / in end of the path.", "\n", "data", "=", "op", ".", "basename", "(", "op", ".", "join", "(", "args", ".", "data_dir", ",", "''", ")", "[", ":", "-", "1", "]", ")", "\n", "split", "=", "op", ".", "basename", "(", "yaml_file", ")", "\n", "assert", "split", ".", "endswith", "(", "'.yaml'", ")", "\n", "split", "=", "split", "[", ":", "-", "5", "]", "\n", "cc", ".", "append", "(", "data", ")", "\n", "cc", ".", "append", "(", "split", ")", "\n", "cc", ".", "append", "(", "'beam{}'", ".", "format", "(", "args", ".", "num_beams", ")", ")", "\n", "cc", ".", "append", "(", "'max{}'", ".", "format", "(", "args", ".", "max_gen_length", ")", ")", "\n", "if", "args", ".", "add_od_labels", ":", "\n", "        ", "cc", ".", "append", "(", "'odlabels'", ")", "\n", "", "if", "args", ".", "num_keep_best", "!=", "1", ":", "\n", "        ", "cc", ".", "append", "(", "'best{}'", ".", "format", "(", "args", ".", "num_keep_best", ")", ")", "\n", "", "if", "args", ".", "use_cbs", ":", "\n", "        ", "cc", ".", "append", "(", "'cbs{}'", ".", "format", "(", "args", ".", "min_constraints_to_satisfy", ")", ")", "\n", "", "if", "args", ".", "output_hidden_states", ":", "\n", "        ", "cc", ".", "append", "(", "'hidden'", ")", "\n", "", "return", "op", ".", "join", "(", "output_dir", ",", "'{}.tsv'", ".", "format", "(", "'.'", ".", "join", "(", "cc", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.get_evaluate_file": [[604, 608], ["predict_file.endswith", "os.splitext"], "function", ["None"], ["", "def", "get_evaluate_file", "(", "predict_file", ")", ":", "\n", "    ", "assert", "predict_file", ".", "endswith", "(", "'.tsv'", ")", "\n", "fpath", "=", "op", ".", "splitext", "(", "predict_file", ")", "[", "0", "]", "\n", "return", "fpath", "+", "'.eval.json'", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.get_evaluate_method": [[610, 615], ["os.basename"], "function", ["None"], ["", "def", "get_evaluate_method", "(", "predict_file", ")", ":", "\n", "    ", "if", "'nocaps'", "in", "op", ".", "basename", "(", "predict_file", ")", ":", "\n", "        ", "return", "'nocaps'", "\n", "", "else", ":", "\n", "        ", "return", "'coco'", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.evaluate": [[617, 635], ["run_captioning.get_predict_file", "run_captioning.test", "run_captioning.get_evaluate_file", "run_captioning.is_main_process", "run_captioning.get_world_size", "torch.distributed.barrier", "torch.distributed.barrier", "val_dataloader.dataset.get_caption_file_in_coco_format", "run_captioning.get_world_size", "torch.distributed.barrier", "torch.distributed.barrier", "val_dataloader.dataset.yaml_file.split", "oscar.utils.caption_evaluate.evaluate_on_coco_caption", "logger.info", "logger.info", "str"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.get_predict_file", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.test", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.get_evaluate_file", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.is_main_process", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.CaptionTSVDataset.get_caption_file_in_coco_format", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.evaluate_on_coco_caption"], ["", "", "def", "evaluate", "(", "args", ",", "val_dataloader", ",", "model", ",", "tokenizer", ",", "output_dir", ")", ":", "\n", "    ", "predict_file", "=", "get_predict_file", "(", "output_dir", ",", "\n", "val_dataloader", ".", "dataset", ".", "yaml_file", ",", "args", ")", "\n", "test", "(", "args", ",", "val_dataloader", ",", "model", ",", "tokenizer", ",", "predict_file", ")", "\n", "\n", "if", "get_world_size", "(", ")", ">", "1", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "", "evaluate_file", "=", "get_evaluate_file", "(", "predict_file", ")", "\n", "if", "is_main_process", "(", ")", ":", "\n", "        ", "caption_file", "=", "val_dataloader", ".", "dataset", ".", "get_caption_file_in_coco_format", "(", ")", "\n", "data", "=", "val_dataloader", ".", "dataset", ".", "yaml_file", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", "\n", "if", "'nocaps'", "not", "in", "data", ":", "\n", "            ", "result", "=", "evaluate_on_coco_caption", "(", "predict_file", ",", "caption_file", ",", "outfile", "=", "evaluate_file", ")", "\n", "logger", ".", "info", "(", "'evaluation result: {}'", ".", "format", "(", "str", "(", "result", ")", ")", ")", "\n", "logger", ".", "info", "(", "'evaluation result saved to {}'", ".", "format", "(", "evaluate_file", ")", ")", "\n", "", "", "if", "get_world_size", "(", ")", ">", "1", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "", "return", "evaluate_file", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.test": [[637, 719], ["tokenizer.convert_tokens_to_ids", "run_captioning.get_world_size", "model.eval", "oscar.utils.tsv_file_ops.tsv_writer", "inputs_param.update", "logger.info", "run_captioning.test.gen_rows"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file_ops.tsv_writer", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.SmoothedValue.update"], ["", "def", "test", "(", "args", ",", "test_dataloader", ",", "model", ",", "tokenizer", ",", "predict_file", ")", ":", "\n", "    ", "cls_token_id", ",", "sep_token_id", ",", "pad_token_id", ",", "mask_token_id", ",", "period_token_id", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "tokenizer", ".", "cls_token", ",", "tokenizer", ".", "sep_token", ",", "\n", "tokenizer", ".", "pad_token", ",", "tokenizer", ".", "mask_token", ",", "'.'", "]", ")", "\n", "world_size", "=", "get_world_size", "(", ")", "\n", "if", "world_size", "==", "1", ":", "\n", "        ", "cache_file", "=", "predict_file", "\n", "", "else", ":", "\n", "        ", "cache_file", "=", "op", ".", "splitext", "(", "predict_file", ")", "[", "0", "]", "+", "'_{}_{}'", ".", "format", "(", "get_rank", "(", ")", ",", "\n", "world_size", ")", "+", "op", ".", "splitext", "(", "predict_file", ")", "[", "1", "]", "\n", "\n", "", "model", ".", "eval", "(", ")", "\n", "inputs_param", "=", "{", "'is_decode'", ":", "True", ",", "\n", "'do_sample'", ":", "False", ",", "\n", "'bos_token_id'", ":", "cls_token_id", ",", "\n", "'pad_token_id'", ":", "pad_token_id", ",", "\n", "'eos_token_ids'", ":", "[", "sep_token_id", "]", ",", "\n", "'mask_token_id'", ":", "mask_token_id", ",", "\n", "# for adding od labels", "\n", "'add_od_labels'", ":", "args", ".", "add_od_labels", ",", "'od_labels_start_posid'", ":", "args", ".", "max_seq_a_length", ",", "\n", "\n", "# hyperparameters of beam search", "\n", "'max_length'", ":", "args", ".", "max_gen_length", ",", "\n", "'num_beams'", ":", "args", ".", "num_beams", ",", "\n", "\"temperature\"", ":", "args", ".", "temperature", ",", "\n", "\"top_k\"", ":", "args", ".", "top_k", ",", "\n", "\"top_p\"", ":", "args", ".", "top_p", ",", "\n", "\"repetition_penalty\"", ":", "args", ".", "repetition_penalty", ",", "\n", "\"length_penalty\"", ":", "args", ".", "length_penalty", ",", "\n", "\"num_return_sequences\"", ":", "args", ".", "num_return_sequences", ",", "\n", "\"num_keep_best\"", ":", "args", ".", "num_keep_best", ",", "\n", "}", "\n", "if", "args", ".", "use_cbs", ":", "\n", "        ", "inputs_param", ".", "update", "(", "{", "'use_cbs'", ":", "True", ",", "\n", "'min_constraints_to_satisfy'", ":", "args", ".", "min_constraints_to_satisfy", ",", "\n", "}", ")", "\n", "", "def", "gen_rows", "(", ")", ":", "\n", "        ", "time_meter", "=", "0", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "step", ",", "(", "img_keys", ",", "batch", ")", "in", "tqdm", "(", "enumerate", "(", "test_dataloader", ")", ")", ":", "\n", "                ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "\n", "'input_ids'", ":", "batch", "[", "0", "]", ",", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", ",", "'img_feats'", ":", "batch", "[", "3", "]", ",", "\n", "'masked_pos'", ":", "batch", "[", "4", "]", ",", "\n", "}", "\n", "if", "args", ".", "use_cbs", ":", "\n", "                    ", "inputs", ".", "update", "(", "{", "\n", "'fsm'", ":", "batch", "[", "5", "]", ",", "\n", "'num_constraints'", ":", "batch", "[", "6", "]", ",", "\n", "}", ")", "\n", "", "inputs", ".", "update", "(", "inputs_param", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "# captions, logprobs", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "time_meter", "+=", "time", ".", "time", "(", ")", "-", "tic", "\n", "all_caps", "=", "outputs", "[", "0", "]", "# batch_size * num_keep_best * max_len", "\n", "all_confs", "=", "torch", ".", "exp", "(", "outputs", "[", "1", "]", ")", "\n", "\n", "for", "img_key", ",", "caps", ",", "confs", "in", "zip", "(", "img_keys", ",", "all_caps", ",", "all_confs", ")", ":", "\n", "                    ", "res", "=", "[", "]", "\n", "for", "cap", ",", "conf", "in", "zip", "(", "caps", ",", "confs", ")", ":", "\n", "                        ", "cap", "=", "tokenizer", ".", "decode", "(", "cap", ".", "tolist", "(", ")", ",", "skip_special_tokens", "=", "True", ")", "\n", "res", ".", "append", "(", "{", "'caption'", ":", "cap", ",", "'conf'", ":", "conf", ".", "item", "(", ")", "}", ")", "\n", "", "if", "isinstance", "(", "img_key", ",", "torch", ".", "Tensor", ")", ":", "\n", "                        ", "img_key", "=", "img_key", ".", "item", "(", ")", "\n", "", "yield", "img_key", ",", "json", ".", "dumps", "(", "res", ")", "\n", "\n", "", "", "", "logger", ".", "info", "(", "\"Inference model computing time: {} seconds per batch\"", ".", "format", "(", "time_meter", "/", "(", "step", "+", "1", ")", ")", ")", "\n", "\n", "", "tsv_writer", "(", "gen_rows", "(", ")", ",", "cache_file", ")", "\n", "if", "world_size", ">", "1", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "", "if", "world_size", ">", "1", "and", "is_main_process", "(", ")", ":", "\n", "        ", "cache_files", "=", "[", "op", ".", "splitext", "(", "predict_file", ")", "[", "0", "]", "+", "'_{}_{}'", ".", "format", "(", "i", ",", "world_size", ")", "+", "op", ".", "splitext", "(", "predict_file", ")", "[", "1", "]", "for", "i", "in", "range", "(", "world_size", ")", "]", "\n", "concat_tsv_files", "(", "cache_files", ",", "predict_file", ")", "\n", "delete_tsv_files", "(", "cache_files", ")", "\n", "reorder_tsv_keys", "(", "predict_file", ",", "test_dataloader", ".", "dataset", ".", "image_keys", ",", "predict_file", ")", "\n", "", "if", "world_size", ">", "1", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.restore_training_settings": [[721, 753], ["torch.load", "torch.load", "hasattr", "os.join", "logger.warning", "hasattr", "hasattr", "getattr", "getattr", "logger.warning", "setattr"], "function", ["None"], ["", "", "def", "restore_training_settings", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "not", "args", ".", "scst", ":", "\n", "            ", "return", "args", "\n", "", "checkpoint", "=", "args", ".", "model_name_or_path", "\n", "", "else", ":", "\n", "        ", "assert", "args", ".", "do_test", "or", "args", ".", "do_eval", "\n", "checkpoint", "=", "args", ".", "eval_model_dir", "\n", "# restore training settings, check hasattr for backward compatibility", "\n", "", "train_args", "=", "torch", ".", "load", "(", "op", ".", "join", "(", "checkpoint", ",", "'training_args.bin'", ")", ")", "\n", "if", "hasattr", "(", "train_args", ",", "'max_seq_a_length'", ")", ":", "\n", "        ", "if", "hasattr", "(", "train_args", ",", "'scst'", ")", "and", "train_args", ".", "scst", ":", "\n", "            ", "max_od_labels_len", "=", "train_args", ".", "max_seq_length", "-", "train_args", ".", "max_gen_length", "\n", "", "else", ":", "\n", "            ", "max_od_labels_len", "=", "train_args", ".", "max_seq_length", "-", "train_args", ".", "max_seq_a_length", "\n", "", "max_seq_length", "=", "args", ".", "max_gen_length", "+", "max_od_labels_len", "\n", "args", ".", "max_seq_length", "=", "max_seq_length", "\n", "logger", ".", "warning", "(", "'Override max_seq_length to {} = max_gen_length:{} + od_labels_len:{}'", ".", "format", "(", "\n", "max_seq_length", ",", "args", ".", "max_gen_length", ",", "max_od_labels_len", ")", ")", "\n", "\n", "\n", "", "override_params", "=", "[", "'max_seq_a_length'", ",", "'do_lower_case'", ",", "'add_od_labels'", ",", "\n", "'max_img_seq_length'", "]", "\n", "for", "param", "in", "override_params", ":", "\n", "        ", "if", "hasattr", "(", "train_args", ",", "param", ")", ":", "\n", "            ", "train_v", "=", "getattr", "(", "train_args", ",", "param", ")", "\n", "test_v", "=", "getattr", "(", "args", ",", "param", ")", "\n", "if", "train_v", "!=", "test_v", ":", "\n", "                ", "logger", ".", "warning", "(", "'Override {} with train args: {} -> {}'", ".", "format", "(", "param", ",", "\n", "test_v", ",", "train_v", ")", ")", "\n", "setattr", "(", "args", ",", "param", ",", "train_v", ")", "\n", "", "", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.get_world_size": [[755, 761], ["torch.get_world_size", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size"], ["", "def", "get_world_size", "(", ")", ":", "\n", "    ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "return", "dist", ".", "get_world_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.get_rank": [[763, 769], ["torch.get_rank", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank"], ["", "def", "get_rank", "(", ")", ":", "\n", "    ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "return", "dist", ".", "get_rank", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.is_main_process": [[771, 773], ["run_captioning.get_rank"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank"], ["", "def", "is_main_process", "(", ")", ":", "\n", "    ", "return", "get_rank", "(", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.synchronize": [[775, 788], ["torch.get_world_size", "torch.barrier", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size"], ["", "def", "synchronize", "(", ")", ":", "\n", "    ", "\"\"\"\n    Helper function to synchronize (barrier) among all processes when\n    using distributed training\n    \"\"\"", "\n", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "\n", "", "world_size", "=", "dist", ".", "get_world_size", "(", ")", "\n", "if", "world_size", "==", "1", ":", "\n", "        ", "return", "\n", "", "dist", ".", "barrier", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.ensure_init_process_group": [[790, 801], ["int", "print", "torch.cuda.set_device", "torch.cuda.set_device", "torch.init_process_group", "torch.is_initialized"], "function", ["None"], ["", "def", "ensure_init_process_group", "(", "local_rank", "=", "None", ",", "port", "=", "12345", ")", ":", "\n", "# init with env", "\n", "    ", "world_size", "=", "int", "(", "os", ".", "environ", "[", "'WORLD_SIZE'", "]", ")", "if", "'WORLD_SIZE'", "in", "os", ".", "environ", "else", "1", "\n", "if", "world_size", ">", "1", "and", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "assert", "local_rank", "is", "not", "None", "\n", "print", "(", "\"Init distributed training on local rank {}\"", ".", "format", "(", "local_rank", ")", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "local_rank", ")", "\n", "dist", ".", "init_process_group", "(", "\n", "backend", "=", "'nccl'", ",", "init_method", "=", "'env://'", "\n", ")", "\n", "", "return", "local_rank", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.main": [[803, 1007], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "run_captioning.ensure_init_process_group", "run_captioning.get_world_size", "torch.device", "torch.device", "run_captioning.synchronize", "oscar.utils.misc.mkdir", "oscar.utils.logger.setup_logger", "oscar.utils.logger.setup_logger.warning", "oscar.utils.misc.set_seed", "run_captioning.restore_training_settings", "model_class.from_pretrained.to", "oscar.utils.logger.setup_logger.info", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "os.isdir", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "oscar.utils.logger.setup_logger.info", "model_class.from_pretrained", "run_captioning.make_data_loader", "run_captioning.train", "run_captioning.make_data_loader", "oscar.utils.logger.setup_logger.info", "run_captioning.make_data_loader", "run_captioning.evaluate", "oscar.utils.logger.setup_logger.info", "run_captioning.make_data_loader", "bool", "run_captioning.get_predict_file", "run_captioning.test", "oscar.utils.logger.setup_logger.info", "run_captioning.evaluate", "oscar.utils.logger.setup_logger.info"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.ensure_init_process_group", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.synchronize", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.mkdir", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.logger.setup_logger", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.restore_training_settings", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.build.make_data_loader", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.build.make_data_loader", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.build.make_data_loader", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.build.make_data_loader", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_captioning.get_predict_file", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.test", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "default", "=", "'datasets/coco_caption'", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "help", "=", "\"The input data dir with all required files.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_yaml\"", ",", "default", "=", "'train.yaml'", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "help", "=", "\"yaml file for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_yaml\"", ",", "default", "=", "'test.yaml'", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "help", "=", "\"yaml file for testing.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--val_yaml\"", ",", "default", "=", "'val.yaml'", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "help", "=", "\"yaml file used for validation during training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "help", "=", "\"Path to pre-trained model or model type.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "'output/'", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "help", "=", "\"The output directory to save checkpoint and test results.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--loss_type\"", ",", "default", "=", "'sfmx'", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Loss function types: support kl, x2, sfmx\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained config name or path if not the same as model_name.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "default", "=", "70", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. \"", "\n", "\"Sequences longer than this will be truncated, \"", "\n", "\"sequences shorter will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_a_length\"", ",", "default", "=", "40", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum sequence length for caption.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run inference.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--mask_prob\"", ",", "default", "=", "0.15", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Probability to mask input sentence during training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_masked_tokens\"", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "\"The max number of masked tokens per sentence.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--add_od_labels\"", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to add object detection labels or not\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--drop_out\"", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "\"Drop out in BERT.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_img_seq_length\"", ",", "default", "=", "50", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input image sequence length.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_dim\"", ",", "default", "=", "2054", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The Image Feature Dimension.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_type\"", ",", "default", "=", "'frcnn'", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Image feature type.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tie_weights\"", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to tie decoding weights to that of encoding\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--freeze_embedding\"", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to freeze word embeddings in Bert\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--label_smoothing\"", ",", "default", "=", "0", ",", "type", "=", "float", ",", "\n", "help", "=", "\".\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--drop_worst_ratio\"", ",", "default", "=", "0", ",", "type", "=", "float", ",", "\n", "help", "=", "\".\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--drop_worst_after\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\".\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "64", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "64", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_mode\"", ",", "default", "=", "'classification'", ",", "type", "=", "str", ",", "\n", "help", "=", "\"output mode, support classification or regression.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_labels\"", ",", "default", "=", "2", ",", "type", "=", "int", ",", "\n", "help", "=", "\"num_labels is 2 for classification and 1 for regression.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before backward.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "3e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial lr.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.05", ",", "type", "=", "float", ",", "help", "=", "\"Weight deay.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--scheduler\"", ",", "default", "=", "'linear'", ",", "type", "=", "str", ",", "help", "=", "\"constant or linear or\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_workers\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Workers in dataloader.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "40", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Total number of training steps. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "20", ",", "help", "=", "\"Log every X steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Save checkpoint every X steps. Will also perform evaluatin.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Run evaluation during training at each save_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Avoid using CUDA.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"For distributed training.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "88", ",", "help", "=", "\"random seed for initialization.\"", ")", "\n", "# for self-critical sequence training", "\n", "parser", ".", "add_argument", "(", "'--scst'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Self-critical sequence training'", ")", "\n", "parser", ".", "add_argument", "(", "'--sc_train_sample_n'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "\"number of sampled captions for sc training\"", ")", "\n", "parser", ".", "add_argument", "(", "'--sc_baseline_type'", ",", "type", "=", "str", ",", "default", "=", "'greedy'", ",", "\n", "help", "=", "\"baseline tyep of REINFORCE algorithm\"", ")", "\n", "parser", ".", "add_argument", "(", "'--sc_beam_size'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"beam size for scst training\"", ")", "\n", "parser", ".", "add_argument", "(", "'--cider_cached_tokens'", ",", "type", "=", "str", ",", "default", "=", "'coco-train-words.p'", ",", "\n", "help", "=", "\"path to cached cPickle file used to calculate CIDEr scores\"", ")", "\n", "# for generation", "\n", "parser", ".", "add_argument", "(", "\"--eval_model_dir\"", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "\"Model directory for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--max_gen_length'", ",", "type", "=", "int", ",", "default", "=", "20", ",", "\n", "help", "=", "\"max length of generated sentences\"", ")", "\n", "parser", ".", "add_argument", "(", "'--output_hidden_states'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Turn on for fast decoding\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num_return_sequences'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"repeating times per image\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num_beams'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"beam search width\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num_keep_best'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"number of hypotheses to keep in beam search\"", ")", "\n", "parser", ".", "add_argument", "(", "'--temperature'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n", "help", "=", "\"temperature in softmax for sampling\"", ")", "\n", "parser", ".", "add_argument", "(", "'--top_k'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"filter distribution for sampling\"", ")", "\n", "parser", ".", "add_argument", "(", "'--top_p'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n", "help", "=", "\"filter distribution for sampling\"", ")", "\n", "parser", ".", "add_argument", "(", "'--repetition_penalty'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"repetition penalty from CTRL paper (https://arxiv.org/abs/1909.05858)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--length_penalty'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"beam search length penalty\"", ")", "\n", "# for Constrained Beam Search", "\n", "parser", ".", "add_argument", "(", "'--use_cbs'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Use constrained beam search for decoding'", ")", "\n", "parser", ".", "add_argument", "(", "'--min_constraints_to_satisfy'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "\"minimum number of constraints to satisfy\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "global", "logger", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "local_rank", "=", "ensure_init_process_group", "(", "local_rank", "=", "args", ".", "local_rank", ")", "\n", "args", ".", "local_rank", "=", "local_rank", "\n", "args", ".", "num_gpus", "=", "get_world_size", "(", ")", "\n", "args", ".", "distributed", "=", "args", ".", "num_gpus", ">", "1", "\n", "args", ".", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "synchronize", "(", ")", "\n", "\n", "output_dir", "=", "args", ".", "output_dir", "\n", "mkdir", "(", "output_dir", ")", "\n", "\n", "logger", "=", "setup_logger", "(", "\"vlpretrain\"", ",", "output_dir", ",", "args", ".", "local_rank", ")", "\n", "logger", ".", "warning", "(", "\"Device: %s, n_gpu: %s\"", ",", "args", ".", "device", ",", "args", ".", "num_gpus", ")", "\n", "set_seed", "(", "args", ".", "seed", ",", "args", ".", "num_gpus", ")", "\n", "args", "=", "restore_training_settings", "(", "args", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "BertConfig", ",", "BertForImageCaptioning", ",", "BertTokenizer", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "assert", "args", ".", "model_name_or_path", "is", "not", "None", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "num_labels", "=", "args", ".", "num_labels", ",", "finetuning_task", "=", "'image_captioning'", ")", "\n", "if", "args", ".", "scst", ":", "\n", "# avoid using too much memory", "\n", "            ", "config", ".", "output_hidden_states", "=", "True", "\n", "", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "config", ".", "img_feature_dim", "=", "args", ".", "img_feature_dim", "\n", "config", ".", "img_feature_type", "=", "args", ".", "img_feature_type", "\n", "config", ".", "hidden_dropout_prob", "=", "args", ".", "drop_out", "\n", "config", ".", "loss_type", "=", "args", ".", "loss_type", "\n", "config", ".", "tie_weights", "=", "args", ".", "tie_weights", "\n", "config", ".", "freeze_embedding", "=", "args", ".", "freeze_embedding", "\n", "config", ".", "label_smoothing", "=", "args", ".", "label_smoothing", "\n", "config", ".", "drop_worst_ratio", "=", "args", ".", "drop_worst_ratio", "\n", "config", ".", "drop_worst_after", "=", "args", ".", "drop_worst_after", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "'.ckpt'", "in", "args", ".", "model_name_or_path", ")", ",", "config", "=", "config", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "args", ".", "eval_model_dir", "\n", "assert", "op", ".", "isdir", "(", "checkpoint", ")", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "config", ".", "output_hidden_states", "=", "args", ".", "output_hidden_states", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "logger", ".", "info", "(", "\"Evaluate the following checkpoint: %s\"", ",", "checkpoint", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ",", "config", "=", "config", ")", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataloader", "=", "make_data_loader", "(", "args", ",", "args", ".", "train_yaml", ",", "tokenizer", ",", "\n", "args", ".", "distributed", ",", "is_train", "=", "True", ")", "\n", "val_dataloader", "=", "None", "\n", "if", "args", ".", "evaluate_during_training", ":", "\n", "            ", "val_dataloader", "=", "make_data_loader", "(", "args", ",", "args", ".", "val_yaml", ",", "tokenizer", ",", "\n", "args", ".", "distributed", ",", "is_train", "=", "False", ")", "\n", "", "last_checkpoint", "=", "train", "(", "args", ",", "train_dataloader", ",", "val_dataloader", ",", "model", ",", "tokenizer", ")", "\n", "\n", "# test the last checkpoint after training", "\n", "if", "args", ".", "do_test", ":", "\n", "            ", "logger", ".", "info", "(", "\"Evaluate on dataset: \"", "+", "args", ".", "test_yaml", ")", "\n", "test_dataloader", "=", "make_data_loader", "(", "args", ",", "args", ".", "test_yaml", ",", "\n", "tokenizer", ",", "args", ".", "distributed", ",", "is_train", "=", "False", ")", "\n", "evaluate", "(", "args", ",", "test_dataloader", ",", "model", ",", "tokenizer", ",", "last_checkpoint", ")", "\n", "\n", "# inference and evaluation", "\n", "", "", "elif", "args", ".", "do_test", "or", "args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"Evaluate on dataset: \"", "+", "args", ".", "test_yaml", ")", "\n", "test_dataloader", "=", "make_data_loader", "(", "args", ",", "args", ".", "test_yaml", ",", "\n", "tokenizer", ",", "args", ".", "distributed", ",", "is_train", "=", "False", ")", "\n", "\n", "if", "not", "args", ".", "do_eval", ":", "\n", "            ", "predict_file", "=", "get_predict_file", "(", "checkpoint", ",", "test_dataloader", ".", "dataset", ".", "yaml_file", ",", "args", ")", "\n", "test", "(", "args", ",", "test_dataloader", ",", "model", ",", "tokenizer", ",", "predict_file", ")", "\n", "logger", ".", "info", "(", "\"Prediction results saved to: {}\"", ".", "format", "(", "predict_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "evaluate_file", "=", "evaluate", "(", "args", ",", "test_dataloader", ",", "model", ",", "tokenizer", ",", "\n", "checkpoint", ")", "\n", "logger", ".", "info", "(", "\"Evaluation results saved to: {}\"", ".", "format", "(", "evaluate_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.ImageBertForSequenceClassificationPromptSubset.__init__": [[38, 49], ["oscar.modeling.modeling_bert.BertImgForPreTraining.__init__", "oscar.modeling.modeling_bert.BertImgModel", "oscar.modeling.modeling_bert.BertPreTrainingHeads", "copy.deepcopy", "oscar.modeling.modeling_bert.BertPreTrainingHeads"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "ImageBertForSequenceClassificationPromptSubset", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "BertImgModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertPreTrainingHeads", "(", "config", ")", "\n", "\n", "config_new", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "config_new", ".", "vocab_size", "=", "config_new", ".", "num_labels", "\n", "self", ".", "cls_ans", "=", "BertPreTrainingHeads", "(", "config_new", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.ImageBertForSequenceClassificationPromptSubset.init_weights_with_pretrained_parameters": [[50, 94], ["run_gqa_prompt_zero_few.ImageBertForSequenceClassificationPromptSubset.cls_ans.seq_relationship.load_state_dict", "run_gqa_prompt_zero_few.ImageBertForSequenceClassificationPromptSubset.cls_ans.predictions.transform.load_state_dict", "dict", "_pickle.load", "set", "set", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "print", "print", "run_gqa_prompt_zero_few.ImageBertForSequenceClassificationPromptSubset.cls_ans.predictions.decoder.weight.data.copy_", "run_gqa_prompt_zero_few.ImageBertForSequenceClassificationPromptSubset.cls_ans.predictions.bias.data.copy_", "run_gqa_prompt_zero_few.ImageBertForSequenceClassificationPromptSubset.cls.seq_relationship.state_dict", "run_gqa_prompt_zero_few.ImageBertForSequenceClassificationPromptSubset.cls.predictions.transform.state_dict", "open().read().split", "open", "ans.split.split.split", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "len", "len", "range", "len", "len", "open().read", "enumerate", "len", "set.add", "set.add", "open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.BeamHypotheses.add", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.BeamHypotheses.add"], ["", "def", "init_weights_with_pretrained_parameters", "(", "self", ",", "config", ")", ":", "\n", "        ", "self", ".", "cls_ans", ".", "seq_relationship", ".", "load_state_dict", "(", "self", ".", "cls", ".", "seq_relationship", ".", "state_dict", "(", ")", ")", "\n", "self", ".", "cls_ans", ".", "predictions", ".", "transform", ".", "load_state_dict", "(", "self", ".", "cls", ".", "predictions", ".", "transform", ".", "state_dict", "(", ")", ")", "\n", "\n", "base_vocab", "=", "open", "(", "os", ".", "path", ".", "join", "(", "config", ".", "pretrained_model_name_or_path", ",", "\"vocab.txt\"", ")", ")", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "[", ":", "-", "1", "]", "\n", "vocab_str2id", "=", "dict", "(", "[", "(", "k", ",", "v", ")", "for", "v", ",", "k", "in", "enumerate", "(", "base_vocab", ")", "]", ")", "\n", "base_weight", "=", "self", ".", "cls", ".", "predictions", ".", "decoder", ".", "weight", ".", "data", "# [Nv, 768]", "\n", "base_bias", "=", "self", ".", "cls", ".", "predictions", ".", "bias", ".", "data", "# [Nv, ]", "\n", "assert", "len", "(", "base_vocab", ")", "==", "base_weight", ".", "shape", "[", "0", "]", "and", "config", ".", "num_labels", "==", "self", ".", "cls_ans", ".", "predictions", ".", "decoder", ".", "weight", ".", "data", ".", "shape", "[", "0", "]", "and", "len", "(", "base_vocab", ")", "==", "base_bias", ".", "shape", "[", "0", "]", "\n", "\n", "answer_vocab", "=", "cPickle", ".", "load", "(", "open", "(", "config", ".", "label2ans_file", ",", "\"rb\"", ")", ")", "\n", "answers", "=", "[", "answer_vocab", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "answer_vocab", ")", ")", "]", "\n", "answer_weights", "=", "[", "]", "\n", "answer_bias", "=", "[", "]", "\n", "exist_words", "=", "set", "(", ")", "\n", "inexist_words", "=", "set", "(", ")", "\n", "for", "ans", "in", "answers", ":", "\n", "            ", "tmp", "=", "0.", "\n", "tmp_bias", "=", "0.", "\n", "tmp_num", "=", "0", "\n", "ans", "=", "ans", ".", "split", "(", ")", "\n", "for", "w", "in", "ans", ":", "\n", "                ", "if", "w", "in", "vocab_str2id", ":", "\n", "                    ", "tmp", "+=", "base_weight", "[", "vocab_str2id", "[", "w", "]", "]", "\n", "tmp_bias", "+=", "base_bias", "[", "vocab_str2id", "[", "w", "]", "]", "\n", "tmp_num", "+=", "1", "\n", "exist_words", ".", "add", "(", "w", ")", "\n", "", "else", ":", "\n", "                    ", "tmp", "+=", "base_weight", "[", "vocab_str2id", "[", "\"[UNK]\"", "]", "]", "\n", "tmp_bias", "+=", "base_bias", "[", "vocab_str2id", "[", "\"[UNK]\"", "]", "]", "\n", "tmp_num", "+=", "1", "\n", "inexist_words", ".", "add", "(", "w", ")", "\n", "", "", "tmp", "=", "tmp", "/", "tmp_num", "\n", "answer_weights", ".", "append", "(", "tmp", ")", "\n", "answer_bias", ".", "append", "(", "tmp_bias", ")", "\n", "", "answer_weights", "=", "torch", ".", "stack", "(", "answer_weights", ",", "dim", "=", "0", ")", "# [num_labels, 768]", "\n", "answer_bias", "=", "torch", ".", "stack", "(", "answer_bias", ",", "dim", "=", "0", ")", "# [num_labels]", "\n", "print", "(", "\"There are {} existing words and {} inexisting words.\"", ".", "format", "(", "len", "(", "exist_words", ")", ",", "len", "(", "inexist_words", ")", ")", ")", "\n", "\n", "print", "(", "\"Init classification layer\"", ")", "\n", "self", ".", "cls_ans", ".", "predictions", ".", "decoder", ".", "weight", ".", "data", ".", "copy_", "(", "answer_weights", ")", "\n", "self", ".", "cls_ans", ".", "predictions", ".", "bias", ".", "data", ".", "copy_", "(", "answer_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.ImageBertForSequenceClassificationPromptSubset.forward": [[95, 117], ["run_gqa_prompt_zero_few.ImageBertForSequenceClassificationPromptSubset.bert", "run_gqa_prompt_zero_few.ImageBertForSequenceClassificationPromptSubset.cls_ans", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather().squeeze.view", "torch.gather().squeeze.view", "labels.view", "mask_index.unsqueeze().expand", "mask_index.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "img_feats", "=", "None", ",", "mask_index", "=", "None", ")", ":", "\n", "# (batch_size, sequence_length, hidden_dim), (batch_size, hidden_dim), ...", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ",", "img_feats", "=", "img_feats", ")", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "outputs", "[", ":", "2", "]", "\n", "# (B, L, Nc)", "\n", "prediction_scores", ",", "seq_relationship_score", "=", "self", ".", "cls_ans", "(", "sequence_output", ",", "pooled_output", ")", "\n", "mask_score", "=", "torch", ".", "gather", "(", "\n", "input", "=", "prediction_scores", ",", "\n", "dim", "=", "1", ",", "\n", "index", "=", "mask_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "(", "-", "1", ",", "-", "1", ",", "prediction_scores", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", ")", ".", "squeeze", "(", "1", ")", "# [B, num_classes]", "\n", "\n", "outputs", "=", "(", "mask_score", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "mask_score", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.__init__": [[200, 238], ["torch.utils.data.Dataset.__init__", "run_gqa_prompt_zero_few._load_dataset", "logger.info", "run_gqa_prompt_zero_few.GQADataset.tensorize", "enumerate", "bool", "bool", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few._load_dataset", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize"], ["def", "__init__", "(", "self", ",", "args", ",", "name", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", "=", "None", ")", ":", "\n", "        ", "super", "(", "GQADataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "name", "in", "[", "'train'", ",", "'val'", ",", "'test-dev'", ",", "'test'", ",", "'train+val'", "]", "\n", "\n", "#t_start = time.time()", "\n", "#if args.img_feature_type == 'faster_r-cnn':", "\n", "#    if args.img_feature_dim == 2048: # object features", "\n", "#        feat_file_name = 'gqa_img_frcnn_feats_obj_{}.pt'.format(name)", "\n", "#    else: # object + spatial features", "\n", "#        feat_file_name = 'gqa_img_frcnn_feats_{}.pt'.format(name)", "\n", "#else:", "\n", "#    feat_file_name = '{}_img_feats.pt'.format(name)", "\n", "#self.img_features = torch.load(os.path.join(args.data_dir, feat_file_name))", "\n", "#t_end = time.time()", "\n", "#logger.info('Info: loading {0:s} features using {1:.2f} secs'.format(feat_file_name, (t_end-t_start)))", "\n", "\n", "self", ".", "img_features", "=", "img_features", "\n", "self", ".", "label_pos_feats", "=", "label_pos_feats", "# None", "\n", "self", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "# classification", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "name", "=", "name", "\n", "\n", "self", ".", "examples", ",", "self", ".", "labels", "=", "_load_dataset", "(", "args", ",", "name", ")", "\n", "self", ".", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "self", ".", "labels", ")", "}", "\n", "\n", "# False", "\n", "if", "self", ".", "args", ".", "load_fast", ":", "\n", "            ", "self", ".", "features", "=", "self", ".", "tensorize", "(", "args", ",", "cls_token_at_end", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "self", ".", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "\n", "", "logger", ".", "info", "(", "'%s Data Examples: %d'", "%", "(", "name", ",", "len", "(", "self", ".", "examples", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize": [[239, 345], ["enumerate", "run_gqa_prompt_zero_few.GQADataset.tokenizer.tokenize", "run_gqa_prompt_zero_few.GQADataset.tokenizer.convert_tokens_to_ids", "run_gqa_prompt_zero_few.target_tensor", "features.append", "len", "logger.info", "run_gqa_prompt_zero_few.GQADataset.tokenizer.tokenize", "oscar.utils.task_utils._truncate_seq_pair", "len", "len", "len", "len", "len", "len", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "len", "len", "float", "KeyError", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.target_tensor", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv._truncate_seq_pair"], ["", "def", "tensorize", "(", "self", ",", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "\n", "# debug:", "\n", "        ", "debug_size", "=", "500", "\n", "features", "=", "[", "]", "\n", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "self", ".", "examples", "[", "0", ":", "]", ")", ":", "\n", "            ", "if", "len", "(", "example", ".", "label", ")", "==", "0", ":", "continue", "\n", "if", "ex_index", "%", "10000", "==", "0", ":", "logger", ".", "info", "(", "\"Tensorizing example %d of %d\"", "%", "(", "ex_index", ",", "len", "(", "self", ".", "examples", ")", ")", ")", "\n", "\n", "tokens_a", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "                ", "tokens_b", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_b", ")", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "self", ".", "args", ".", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "                ", "if", "len", "(", "tokens_a", ")", ">", "self", ".", "args", ".", "max_seq_length", "-", "2", ":", "\n", "                    ", "tokens_a", "=", "tokens_a", "[", ":", "(", "self", ".", "args", ".", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "", "tokens", "=", "tokens_a", "+", "[", "sep_token", "]", "\n", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "                ", "tokens", "+=", "tokens_b", "+", "[", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "if", "cls_token_at_end", ":", "\n", "                ", "tokens", "=", "tokens", "+", "[", "cls_token", "]", "\n", "segment_ids", "=", "segment_ids", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "                ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "self", ".", "args", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "                ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "", "else", ":", "\n", "                ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "segment_ids", "=", "segment_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "\n", "# image features", "\n", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "# torch", "\n", "#img_feat = self.img_features.item().get(example.img_key)  # numpy", "\n", "if", "img_feat", ".", "shape", "[", "0", "]", ">", "self", ".", "args", ".", "max_img_seq_length", ":", "\n", "                ", "img_feat", "=", "img_feat", "[", "0", ":", "self", ".", "args", ".", "max_img_seq_length", ",", "]", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids += [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids = segment_ids + [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "self", ".", "args", ".", "max_img_seq_length", "-", "img_feat", ".", "shape", "[", "0", "]", ",", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_matrix", ".", "shape", "[", "0", "]", ")", "\n", "# segment_ids = segment_ids + [pad_token_segment_id] * padding_matrix.shape[0]", "\n", "\n", "", "", "if", "self", ".", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "                ", "label_id", "=", "[", "self", ".", "label_map", "[", "l", "]", "for", "l", "in", "example", ".", "label", "]", "\n", "score", "=", "example", ".", "score", "\n", "", "elif", "self", ".", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "                ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "else", ":", "\n", "                ", "raise", "KeyError", "(", "self", ".", "args", ".", "output_mode", ")", "\n", "\n", "", "if", "ex_index", "<", "5", ":", "\n", "                ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"segment_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label: %s (id = %s)\"", "%", "(", "example", ".", "label", ",", "label_id", ")", ")", "\n", "logger", ".", "info", "(", "\"score: %s (score = %s)\"", "%", "(", "example", ".", "score", ",", "score", ")", ")", "\n", "\n", "", "new_scores", "=", "target_tensor", "(", "len", "(", "self", ".", "labels", ")", ",", "label_id", ",", "score", ")", "\n", "#features.append(InputFeat(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label_id, score=score, img_feat=img_feat))", "\n", "features", ".", "append", "(", "(", "torch", ".", "tensor", "(", "input_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "label_id", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "new_scores", ",", "dtype", "=", "torch", ".", "float", ")", ",", "img_feat", ")", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize_example": [[346, 487], ["run_gqa_prompt_zero_few.GQADataset.tokenizer.tokenize", "run_gqa_prompt_zero_few.GQADataset.tokenizer.tokenize", "tokens.index", "run_gqa_prompt_zero_few.GQADataset.tokenizer.convert_tokens_to_ids", "run_gqa_prompt_zero_few.GQADataset.args.img_feature_type.startswith", "example.text_b.split", "enumerate", "example.text_b.replace().strip", "run_gqa_prompt_zero_few.GQADataset.tokenizer.tokenize", "oscar.utils.task_utils._truncate_seq_pair", "len", "ValueError", "len", "len", "ValueError", "len", "len", "len", "img_feat.type.type.type", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "run_gqa_prompt_zero_few.GQADataset.tokenizer.tokenize", "txt_label_ixs.extend", "len", "len", "len", "img_feat.type.type.reshape", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KeyError", "img_feat.type.type.type", "example.text_b.replace", "len", "len", "len", "len", "float", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv._truncate_seq_pair"], ["", "def", "tensorize_example", "(", "self", ",", "example", ",", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "        ", "tokens_a", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "tokens_c", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "\"Answer: \"", "+", "example", ".", "text_c", ")", "\n", "tokens_a", "=", "tokens_a", "+", "tokens_c", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "            ", "txt_b_arr", "=", "example", ".", "text_b", ".", "split", "(", "';'", ")", "\n", "txt_label_ixs", "=", "[", "]", "\n", "for", "txt_b_ix", ",", "txt_b_ele", "in", "enumerate", "(", "txt_b_arr", ")", ":", "\n", "                ", "tokens_b_ele", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "txt_b_ele", ")", "\n", "txt_label_ixs", ".", "extend", "(", "[", "txt_b_ix", "]", "*", "len", "(", "tokens_b_ele", ")", ")", "\n", "", "txt_b", "=", "example", ".", "text_b", ".", "replace", "(", "';'", ",", "' '", ")", ".", "strip", "(", ")", "\n", "tokens_b", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "txt_b", ")", "\n", "assert", "len", "(", "tokens_b", ")", "==", "len", "(", "txt_label_ixs", ")", "\n", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "self", ".", "args", ".", "max_seq_length", "-", "3", ")", "\n", "txt_label_ixs", "=", "txt_label_ixs", "[", "0", ":", "len", "(", "tokens_b", ")", "]", "\n", "\n", "# original", "\n", "#if example.text_b:", "\n", "#    txt_b = example.text_b.replace(';', ' ').strip()", "\n", "#    tokens_b = self.tokenizer.tokenize(txt_b)", "\n", "#    _truncate_seq_pair(tokens_a, tokens_b, self.args.max_seq_length - 3)", "\n", "", "else", ":", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "            ", "if", "len", "(", "tokens_a", ")", ">", "self", ".", "args", ".", "max_seq_length", "-", "2", ":", "\n", "                ", "tokens_a", "=", "tokens_a", "[", ":", "(", "self", ".", "args", ".", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "# question + [SEP]", "\n", "", "", "tokens", "=", "tokens_a", "+", "[", "sep_token", "]", "\n", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "# question + [SEP] + tags + [SEP]", "\n", "            ", "tokens", "+=", "tokens_b", "+", "[", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "# False", "\n", "", "if", "cls_token_at_end", ":", "\n", "            ", "raise", "ValueError", "(", "\"No CLS at end.\"", ")", "\n", "tokens", "=", "tokens", "+", "[", "cls_token", "]", "\n", "segment_ids", "=", "segment_ids", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "# [CLS] + question + [SEP] + tags + [SEP]", "\n", "            ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "mask_index", "=", "tokens", ".", "index", "(", "\"[MASK]\"", ")", "\n", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "self", ".", "args", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "# False", "\n", "if", "pad_on_left", ":", "\n", "            ", "raise", "ValueError", "(", "\"No pad on left.\"", ")", "\n", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "", "else", ":", "\n", "# [..., 0, 0, 0, ...]", "\n", "            ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "# [1, 1, ..., 0, 0, 0, ...]", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "# [1, 0, 0, ..., 1, 1, ..., 0, 0, 0, ...]", "\n", "segment_ids", "=", "segment_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "self", ".", "args", ".", "max_seq_length", "\n", "\n", "# image features", "\n", "if", "self", ".", "args", ".", "img_feature_type", ".", "startswith", "(", "'dis_code'", ")", ":", "\n", "            ", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "\n", "\n", "if", "self", ".", "args", ".", "img_feature_type", "==", "'dis_code_ln'", ":", "# for discrete code image representation", "\n", "                ", "img_feat", "=", "img_feat", ".", "reshape", "(", "-", "1", ",", "img_feat", ".", "shape", "[", "0", "]", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "img_feature_type", "==", "'dis_code_t'", ":", "# transposed", "\n", "                ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "64", "\n", "", "else", ":", "\n", "                ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "", "", "else", ":", "\n", "            ", "img_feat", "=", "self", ".", "img_features", "[", "example", ".", "img_key", "]", "#[:, 0:self.args.img_feature_dim]  # torch", "\n", "\n", "if", "img_feat", ".", "shape", "[", "0", "]", ">", "self", ".", "args", ".", "max_img_seq_length", ":", "\n", "                ", "img_feat", "=", "img_feat", "[", "0", ":", "self", ".", "args", ".", "max_img_seq_length", ",", "]", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids += [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "# segment_ids = segment_ids + [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "self", ".", "args", ".", "max_img_seq_length", "-", "img_feat", ".", "shape", "[", "0", "]", ",", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "if", "self", ".", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "                    ", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_matrix", ".", "shape", "[", "0", "]", ")", "\n", "# segment_ids = segment_ids + [pad_token_segment_id] * padding_matrix.shape[0]", "\n", "\n", "", "", "", "if", "self", ".", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "if", "(", "example", ".", "label", "is", "None", ")", ":", "\n", "                ", "label_id", "=", "[", "0", "]", "\n", "score", "=", "[", "0", "]", "\n", "", "elif", "len", "(", "example", ".", "label", ")", "==", "0", ":", "\n", "                ", "label_id", "=", "[", "0", "]", "\n", "score", "=", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "label_id", "=", "[", "self", ".", "label_map", "[", "l", "]", "for", "l", "in", "example", ".", "label", "]", "\n", "score", "=", "example", ".", "score", "\n", "", "", "elif", "self", ".", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "if", "len", "(", "example", ".", "label", ")", "==", "0", ":", "\n", "                ", "label_id", "=", "0", "\n", "", "else", ":", "\n", "                ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "self", ".", "args", ".", "output_mode", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "            ", "img_feat", "=", "img_feat", ".", "type", "(", "torch", ".", "long", ")", "\n", "", "elif", "self", ".", "args", ".", "img_feature_type", "in", "[", "'dis_code_ln'", "]", ":", "\n", "#img_feat = img_feat.reshape(-1, img_feat.shape[0])", "\n", "            ", "img_feat", "=", "img_feat", ".", "type", "(", "torch", ".", "float", ")", "\n", "\n", "", "return", "(", "torch", ".", "tensor", "(", "input_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "label_id", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "label_id", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "img_feat", ",", "\n", "torch", ".", "tensor", "(", "[", "example", ".", "q_id", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "mask_index", "]", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.__getitem__": [[488, 501], ["run_gqa_prompt_zero_few.GQADataset.tensorize_example", "bool", "bool"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.tensorize_example"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "load_fast", ":", "\n", "            ", "example", "=", "self", ".", "features", "[", "index", "]", "\n", "", "else", ":", "\n", "            ", "entry", "=", "self", ".", "examples", "[", "index", "]", "\n", "example", "=", "self", ".", "tensorize_example", "(", "entry", ",", "\n", "cls_token_at_end", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "self", ".", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "self", ".", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.GQADataset.__len__": [[502, 504], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few._load_dataset": [[124, 181], ["processor.get_labels", "processor.get_train_examples", "zip", "print", "random.seed", "random.shuffle", "processor.get_train_examples", "open", "fp.read().split", "len", "len", "print", "list", "print", "int", "processor.get_dev_examples", "zip", "processor.get_dev_examples", "os.path.join", "filter", "int", "open", "fp.read().split", "len", "len", "processor.get_train_examples", "processor.get_train_examples", "fp.read", "os.path.join", "processor.get_test_examples", "processor.get_test_examples", "fp.read", "processor.get_dev_examples", "processor.get_dev_examples"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples"], ["def", "_load_dataset", "(", "args", ",", "name", ")", ":", "\n", "    ", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "\n", "labels", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "\n", "if", "name", "==", "'train'", ":", "\n", "        ", "if", "args", ".", "train_data_type", "==", "'bal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "'gqa_bal_qla_train.json'", ")", "#[0: debug_size]", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'gqa_bal_qla_train_declarative.json'", ")", ")", "as", "fp", ":", "\n", "                ", "lines", "=", "fp", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "", "assert", "len", "(", "examples", ")", "==", "len", "(", "lines", ")", "\n", "for", "example", ",", "line", "in", "zip", "(", "examples", ",", "lines", ")", ":", "\n", "                ", "example", ".", "text_c", "=", "line", "\n", "\n", "", "if", "not", "args", ".", "use_yn", ":", "\n", "                ", "print", "(", "\"Do not use yes/no questions.\"", ")", "\n", "wo_set", "=", "{", "0", ",", "1", "}", "\n", "examples", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", ".", "label", "[", "0", "]", "not", "in", "wo_set", ",", "examples", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"Using yes/no questions.\"", ")", "\n", "\n", "", "print", "(", "\"**** Using subset **** : {} samples\"", ".", "format", "(", "args", ".", "num_examples", ")", ")", "\n", "random", ".", "seed", "(", "int", "(", "args", ".", "subset_seed", ")", ")", "\n", "random", ".", "shuffle", "(", "examples", ")", "\n", "examples", "=", "examples", "[", ":", "int", "(", "args", ".", "num_examples", ")", "]", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_train.json'", ")", "#[0: debug_size]", "\n", "\n", "", "", "elif", "name", "==", "'val'", ":", "\n", "        ", "if", "args", ".", "eval_data_type", "==", "'bal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "'gqa_bal_qla_val.json'", ")", "#[0: debug_size]", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'gqa_bal_qla_val_declarative.json'", ")", ")", "as", "fp", ":", "\n", "                ", "lines", "=", "fp", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "", "assert", "len", "(", "examples", ")", "==", "len", "(", "lines", ")", "\n", "for", "example", ",", "line", "in", "zip", "(", "examples", ",", "lines", ")", ":", "\n", "                ", "example", ".", "text_c", "=", "line", "\n", "", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_val.json'", ")", "#[0: debug_size]", "\n", "", "", "elif", "name", "==", "'train+val'", ":", "# depreciated", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'mask'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "'train+val2014_qla_mrcnn.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "'train+val2014_qla.json'", ")", "\n", "", "", "elif", "name", "==", "'test'", ":", "# test-submission", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'bal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_submission.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_submission.json'", ")", "\n", "", "", "elif", "name", "==", "'test-dev'", ":", "# test-dev set", "\n", "        ", "if", "args", ".", "data_label_type", "==", "'bal'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "'gqa_bal_qla_testdev.json'", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "'gqa_all_qla_testdev.json'", ")", "\n", "\n", "", "", "return", "examples", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few._load_img_features": [[182, 196], ["time.time", "torch.load", "torch.load", "time.time", "logger.info", "os.path.join"], "function", ["None"], ["", "def", "_load_img_features", "(", "args", ")", ":", "\n", "    ", "t_start", "=", "time", ".", "time", "(", ")", "\n", "if", "args", ".", "img_feature_type", "==", "'faster_r-cnn'", ":", "\n", "        ", "if", "args", ".", "img_feature_dim", "==", "2048", ":", "# object features", "\n", "            ", "feat_file_name", "=", "'gqa_img_frcnn_feats_obj.pt'", "\n", "", "else", ":", "# object + spatial features", "\n", "            ", "feat_file_name", "=", "'gqa_img_frcnn_feats.pt'", "\n", "", "", "else", ":", "\n", "        ", "feat_file_name", "=", "'gqa_img_frcnn_feats.pt'", "\n", "", "img_features", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "feat_file_name", ")", ")", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: loading {0:s} features using {1:.2f} secs'", ".", "format", "(", "feat_file_name", ",", "(", "t_end", "-", "t_start", ")", ")", ")", "\n", "\n", "return", "img_features", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.trim_batch": [[505, 525], ["print", "len", "enumerate", "len", "print", "torch.zeros", "torch.zeros", "batch_tensors.append", "print", "enumerate", "ele.size", "len", "print", "list", "ele.size"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "", "def", "trim_batch", "(", "batch", ")", ":", "\n", "    ", "\"\"\" new batch func\n    :param batch:\n    :return:\n    \"\"\"", "\n", "print", "(", "'batch size'", ",", "len", "(", "batch", ")", ")", "\n", "\n", "batch_size", "=", "len", "(", "batch", ")", "\n", "batch_tensors", "=", "[", "]", "\n", "for", "ele", "in", "batch", "[", "0", "]", ":", "\n", "        ", "print", "(", "ele", ".", "shape", ",", "ele", ".", "size", "(", ")", ")", "\n", "zero_tensor", "=", "torch", ".", "zeros", "(", "(", "[", "batch_size", "]", "+", "list", "(", "ele", ".", "size", "(", ")", ")", ")", ")", "\n", "batch_tensors", ".", "append", "(", "zero_tensor", ")", "\n", "\n", "", "for", "b_id", ",", "b", "in", "enumerate", "(", "batch", ")", ":", "\n", "        ", "print", "(", "b_id", ",", "len", "(", "b", ")", ")", "\n", "for", "ele_id", ",", "ele", "in", "enumerate", "(", "b", ")", ":", "\n", "            ", "print", "(", "ele_id", ",", "ele", ".", "shape", ")", "\n", "batch_tensors", "[", "ele_id", "]", "[", "b_id", "]", "=", "ele", "\n", "", "", "return", "batch_tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train": [[526, 731], ["torch.utils.data.DataLoader", "transformers.pytorch_transformers.AdamW", "transformers.pytorch_transformers.WarmupLinearSchedule", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "oscar.utils.misc.set_seed", "range", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "torch.cuda.amp.GradScaler", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "torch.nn.parallel.DistributedDataParallel.state_dict", "transformers.pytorch_transformers.AdamW.state_dict", "int", "time.time", "enumerate", "time.time", "logger.info", "logger.info", "run_gqa_prompt_zero_few.evaluate", "log_json.append", "logger.info", "logger.info", "logger.info", "open", "json.dump", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "loss.mean.item", "loss.mean.item", "copy.deepcopy", "open", "json.dump", "len", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.cuda.amp.autocast", "torch.nn.parallel.DistributedDataParallel.", "torch.cuda.amp.GradScaler.scale().backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "transformers.pytorch_transformers.WarmupLinearSchedule.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "round", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "t.to", "loss.mean.mean", "torch.nn.parallel.DistributedDataParallel.parameters", "torch.nn.parallel.DistributedDataParallel.parameters", "torch.cuda.amp.GradScaler.step", "torch.cuda.amp.GradScaler.update", "transformers.pytorch_transformers.AdamW.step", "len", "any", "torch.cuda.amp.GradScaler.scale", "logger.info", "run_gqa_prompt_zero_few.evaluate", "logger.info", "copy.deepcopy"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.SmoothedValue.update", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "args", ".", "train_batch_size", ")", "#, collate_fn=trim_batch)", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "WarmupLinearSchedule", "(", "optimizer", ",", "warmup_steps", "=", "args", ".", "warmup_steps", ",", "t_total", "=", "t_total", ")", "\n", "\n", "# if args.fp16:", "\n", "#     try:", "\n", "#         from apex import amp", "\n", "#     except ImportError:", "\n", "#         raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")", "\n", "#     model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "scaler", "=", "GradScaler", "(", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "#train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0])", "\n", "set_seed", "(", "args", ".", "seed", ",", "args", ".", "n_gpu", ")", "# Added here for reproductibility (even between python 2 and 3)", "\n", "\n", "best_score", "=", "0", "\n", "best_model", "=", "{", "\n", "'epoch'", ":", "0", ",", "\n", "'model_state'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_state'", ":", "optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n", "\n", "for", "epoch", "in", "range", "(", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "#for epoch in train_iterator:", "\n", "#epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])", "\n", "        ", "total_loss", "=", "0", "\n", "total_norm", "=", "0", "\n", "count_norm", "=", "0", "\n", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "#for step, batch in enumerate(epoch_iterator):", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "batch", "[", "3", "]", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", ",", "\n", "'mask_index'", ":", "batch", "[", "7", "]", "}", "\n", "\n", "with", "autocast", "(", "enabled", "=", "args", ".", "fp16", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "#loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)", "\n", "loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "\n", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                    ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "", "if", "args", ".", "fp16", ":", "\n", "                ", "scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "# with amp.scale_loss(loss, optimizer) as scaled_loss:", "\n", "#     scaled_loss.backward()", "\n", "# torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "total_norm", "+=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "count_norm", "+=", "1", "\n", "\n", "#batch_score = compute_score_with_logits(logits, batch[4]).sum()", "\n", "#train_score += batch_score.item()", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "# scheduler.step()  # Update learning rate schedule", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "scaler", ".", "step", "(", "optimizer", ")", "\n", "scaler", ".", "update", "(", ")", "\n", "", "else", ":", "\n", "                    ", "optimizer", ".", "step", "(", ")", "\n", "", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "# Log metrics", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "logger", ".", "info", "(", "\"Epoch: %d, global_step: %d\"", "%", "(", "epoch", ",", "global_step", ")", ")", "\n", "eval_result", ",", "eval_score", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "                            ", "best_score", "=", "eval_score", "\n", "best_model", "[", "'epoch'", "]", "=", "epoch", "\n", "best_model", "[", "'model'", "]", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "best_score", ")", ")", "\n", "", "logging_loss", "=", "tr_loss", "\n", "\n", "#if args.max_steps > 0 and global_step > args.max_steps:", "\n", "#    epoch_iterator.close()", "\n", "#    break", "\n", "\n", "", "", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Train Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "# evaluation", "\n", "logger", ".", "info", "(", "\"Epoch: %d\"", "%", "(", "epoch", ")", ")", "\n", "eval_result", ",", "eval_score", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "eval_score", "\n", "best_model", "[", "'epoch'", "]", "=", "epoch", "\n", "best_model", "[", "'model'", "]", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "#best_model['optimizer'] = copy.deepcopy(optimizer.state_dict())", "\n", "", "elif", "eval_score", "<", "best_score", "and", "epoch", ">", "15", ":", "\n", "            ", "break", "\n", "\n", "# save checkpoints", "\n", "", "\"\"\"\n        if args.local_rank in [-1, 0] and args.save_epoch > 0 and epoch % args.save_epoch == 0: # Save model checkpoint\n            output_dir = os.path.join(args.output_dir, 'checkpoint-{}'.format(epoch))\n            if not os.path.exists(output_dir): os.makedirs(output_dir)\n            model_to_save = best_model['model'].module if hasattr(model, 'module') else best_model['model']  # Take care of distributed/parallel training\n\n            save_num = 0\n            while (save_num < 10):\n                try:\n                    model_to_save.save_pretrained(output_dir)\n                    torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n                    tokenizer.save_pretrained(output_dir)\n                    break\n                except:\n                    save_num += 1\n            logger.info(\"Saving model checkpoint {0} to {1}\".format(epoch, output_dir))\n        \"\"\"", "\n", "\n", "epoch_log", "=", "{", "'epoch'", ":", "epoch", ",", "'eval_score'", ":", "eval_score", ",", "'best_score'", ":", "best_score", "}", "\n", "log_json", ".", "append", "(", "epoch_log", ")", "\n", "\n", "yn_flag", "=", "\"\"", "if", "args", ".", "use_yn", "else", "\"_wo\"", "\n", "with", "open", "(", "args", ".", "output_dir", "+", "'/eval_logs{}_{}_{}.json'", ".", "format", "(", "yn_flag", ",", "args", ".", "num_examples", ",", "args", ".", "subset_seed", ")", ",", "'w'", ")", "as", "fp", ":", "\n", "            ", "json", ".", "dump", "(", "log_json", ",", "fp", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"PROGRESS: {}%\"", ".", "format", "(", "round", "(", "100", "*", "(", "epoch", "+", "1", ")", "/", "args", ".", "num_train_epochs", ",", "4", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"EVALERR: {}%\"", ".", "format", "(", "100", "*", "best_score", ")", ")", "\n", "logger", ".", "info", "(", "\"LOSS: {}%\"", ".", "format", "(", "total_loss", "/", "len", "(", "train_dataset", ")", ")", ")", "\n", "\n", "", "yn_flag", "=", "\"\"", "if", "args", ".", "use_yn", "else", "\"_wo\"", "\n", "with", "open", "(", "args", ".", "output_dir", "+", "'/eval_logs{}_{}_{}.json'", ".", "format", "(", "yn_flag", ",", "args", ".", "num_examples", ",", "args", ".", "subset_seed", ")", ",", "'w'", ")", "as", "fp", ":", "\n", "        ", "json", ".", "dump", "(", "log_json", ",", "fp", ")", "\n", "\n", "", "\"\"\"if args.local_rank in [-1, 0]: # Save the final model checkpoint\n        output_dir = os.path.join(args.output_dir, 'best-{}'.format(best_model['epoch']))\n        if not os.path.exists(output_dir): os.makedirs(output_dir)\n        model_to_save = best_model['model'].module if hasattr(model, 'module') else best_model['model']  # Take care of distributed/parallel training\n\n        save_num = 0\n        while (save_num < 10):\n            try:\n                model_to_save.save_pretrained(output_dir)\n                torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n                tokenizer.save_pretrained(output_dir)\n                break\n            except:\n                save_num += 1\n        logger.info(\"Saving the best model checkpoint epoch {} to {}\".format(best_model['epoch'], output_dir))\"\"\"", "\n", "\n", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.evaluate": [[732, 802], ["time.time", "zip", "time.time", "logger.info", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "model.eval", "tuple", "float", "len", "os.path.exists", "torch.no_grad", "torch.no_grad", "model", "tmp_eval_loss.mean().item", "correct.sum().item", "logits.size", "t.to", "logits.argmax", "batch[].view", "tmp_eval_loss.mean", "correct.sum"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", "=", "None", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "'-MM'", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "#if args.n_gpu > 1: model = torch.nn.DataParallel(model) # debug: single-gpu or multi-gpus", "\n", "\n", "results", "=", "[", "]", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "num_workers", "=", "args", ".", "workers", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "num_data", "=", "0", "\n", "correct_num", "=", "0", "\n", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "#for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "batch", "[", "3", "]", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", ",", "\n", "'mask_index'", ":", "batch", "[", "7", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n", "#logger.info('logits: %s, batch[3]: %s' % (str(logits.shape), str(batch[3].shape)))", "\n", "#logger.info('correct: %s' % (str(logits.argmax(1) == batch[3].view(-1))))", "\n", "\n", "correct", "=", "logits", ".", "argmax", "(", "1", ")", "==", "batch", "[", "3", "]", ".", "view", "(", "-", "1", ")", "\n", "correct_num", "+=", "correct", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "num_data", "+=", "logits", ".", "size", "(", "0", ")", "\n", "\n", "# debug", "\n", "#val, idx = logits.max(1)", "\n", "#logger.info('idx: %s, batch[4]: %s' % (str(idx.shape), str(batch[3].shape)))", "\n", "#for i in range(idx.size(0)):", "\n", "#    logger.info('idx: %d, pred: %d, real: %d' % (idx[i].item(), eval_dataset.labels[idx[i].item()], batch[3][i].item()))", "\n", "\n", "", "nb_eval_steps", "+=", "1", "\n", "\n", "", "acc", "=", "float", "(", "correct_num", ")", "/", "len", "(", "eval_dataloader", ".", "dataset", ")", "\n", "\n", "logger", ".", "info", "(", "\"Eval Results:\"", ")", "\n", "logger", ".", "info", "(", "\"Eval Accuracy: %.3f\"", "%", "(", "100", "*", "acc", ")", ")", "\n", "logger", ".", "info", "(", "\"Eval Loss: %.3f\"", "%", "(", "eval_loss", ")", ")", "\n", "\n", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Eva Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "return", "results", ",", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.test": [[803, 858], ["_pickle.load", "logger.info", "time.time", "zip", "time.time", "logger.info", "logger.info", "open", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "open", "json.dump", "len", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "model.eval", "tuple", "len", "os.path.exists", "torch.no_grad", "torch.no_grad", "model", "logits.max", "range", "t.to", "idx.size", "str", "results.append", "[].item", "idx[].item"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "test", "(", "args", ",", "model", ",", "eval_dataset", "=", "None", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "'-MM'", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "label2ans", "=", "cPickle", ".", "load", "(", "open", "(", "args", ".", "label2ans_file", ",", "'rb'", ")", ")", "\n", "logger", ".", "info", "(", "'label2ans: %d'", "%", "(", "len", "(", "label2ans", ")", ")", ")", "\n", "\n", "results", "=", "[", "]", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval", "\n", "logger", ".", "info", "(", "\"***** Running Test {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "#for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", ",", "# XLM don't use segment_ids", "\n", "'labels'", ":", "None", ",", "\n", "'img_feats'", ":", "None", "if", "args", ".", "img_feature_dim", "==", "-", "1", "else", "batch", "[", "5", "]", ",", "\n", "'mask_index'", ":", "batch", "[", "7", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "logits", "=", "outputs", "[", "0", "]", "\n", "\n", "val", ",", "idx", "=", "logits", ".", "max", "(", "1", ")", "\n", "#logger.info('idx: %s, batch[6]: %s' % (str(idx.shape), str(batch[6].shape)))", "\n", "\n", "for", "i", "in", "range", "(", "idx", ".", "size", "(", "0", ")", ")", ":", "\n", "                    ", "result", "=", "{", "}", "\n", "result", "[", "'questionId'", "]", "=", "str", "(", "batch", "[", "6", "]", "[", "i", "]", ".", "item", "(", ")", ")", "\n", "result", "[", "'prediction'", "]", "=", "label2ans", "[", "eval_dataset", ".", "labels", "[", "idx", "[", "i", "]", ".", "item", "(", ")", "]", "]", "\n", "results", ".", "append", "(", "result", ")", "\n", "\n", "#logger.info('q_id: {0}, answer: {1}'.format(result['question_id'], result['answer']))", "\n", "\n", "", "", "", "", "with", "open", "(", "args", ".", "output_dir", "+", "(", "'/{}_results.json'", ".", "format", "(", "eval_dataset", ".", "name", ")", ")", ",", "'w'", ")", "as", "fp", ":", "\n", "        ", "json", ".", "dump", "(", "results", ",", "fp", ")", "\n", "\n", "", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'# questions: %d'", "%", "(", "len", "(", "results", ")", ")", ")", "\n", "logger", ".", "info", "(", "'Test Time Cost: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.load_and_cache_examples": [[859, 925], ["processor.get_labels", "time.time", "numpy.load", "oscar.utils.task_utils.convert_examples_to_features_vqa", "time.time", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "processor.get_dev_examples", "processor.get_train_examples", "os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "print", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "bool", "bool", "time.time", "numpy.zeros", "enumerate", "torch.from_numpy", "torch.from_numpy", "time.time", "logger.info", "torch.tensor", "torch.tensor", "run_gqa_prompt_zero_few.target_tensor", "len"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.convert_examples_to_features_vqa", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.target_tensor"], ["", "def", "load_and_cache_examples", "(", "args", ",", "task", ",", "tokenizer", ",", "evaluate", "=", "False", ")", ":", "\n", "    ", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "output_mode", "=", "output_modes", "[", "task", "]", "\n", "\n", "label_list", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ")", "if", "evaluate", "else", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ")", "\n", "\n", "#img_features = torch.load(os.path.join(args.data_dir, 'val_img_feats.pt' if evaluate else 'train_img_feats.pt'))", "\n", "#img_features = torch.load(os.path.join(args.data_dir, 'val_img_frcnn_feats.pt' if evaluate else 'train_img_frcnn_feats.pt'))", "\n", "img_features", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'val_img_frcnn_feats.npy'", "if", "evaluate", "else", "'train_img_frcnn_feats.npy'", ")", ")", "\n", "\n", "features", "=", "convert_examples_to_features_vqa", "(", "examples", ",", "img_features", ",", "label_list", ",", "args", ".", "max_img_seq_length", ",", "args", ".", "max_seq_length", ",", "\n", "tokenizer", ",", "output_mode", ",", "\n", "cls_token_at_end", "=", "bool", "(", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ")", "\n", "\n", "#if args.local_rank in [-1, 0]:", "\n", "#    logger.info(\"Saving features into cached file %s\", cached_features_file)", "\n", "#    torch.save(features, cached_features_file)", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: loading features using %.5f secs'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "# batch*max_seq_len", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "        ", "labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "[", "0", "]", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "targets", "=", "torch", ".", "tensor", "(", "[", "target_tensor", "(", "len", "(", "label_list", ")", ",", "f", ".", "label_id", ",", "f", ".", "score", ")", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "if", "args", ".", "img_feature_dim", ">", "0", ":", "# change here", "\n", "            ", "t_start", "=", "time", ".", "time", "(", ")", "\n", "img_feat_np", "=", "np", ".", "zeros", "(", "(", "labels", ".", "shape", "[", "0", "]", ",", "args", ".", "max_img_seq_length", ",", "args", ".", "img_feature_dim", ")", ")", "\n", "for", "f_id", ",", "f", "in", "enumerate", "(", "features", ")", ":", "\n", "                ", "img_feat_np", "[", "f_id", "]", "=", "f", ".", "img_feat", "\n", "\n", "", "img_feats", "=", "torch", ".", "from_numpy", "(", "img_feat_np", ")", "\n", "\n", "#img_feats = torch.empty((labels.shape[0], args.max_img_seq_length, args.img_feature_dim))", "\n", "#for f_id, f in enumerate(features):", "\n", "#   img_feats[f_id] = f.img_feat", "\n", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Info: convert image tensor features using %.5f secs'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "#img_feats = torch.stack([f.img_feat[:,-args.img_feature_dim:] for f in features])", "\n", "#img_feats = torch.stack([f.img_feat for f in features])", "\n", "#img_feats = img_feats.type(torch.long)", "\n", "\n", "#print('targets:', targets.shape)", "\n", "", "print", "(", "'img_feats:'", ",", "img_feats", ".", "shape", ")", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "        ", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "if", "args", ".", "img_feature_dim", "==", "-", "1", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "labels", ",", "targets", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "labels", ",", "targets", ",", "img_feats", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.target_tensor": [[926, 933], ["enumerate"], "function", ["None"], ["", "def", "target_tensor", "(", "len", ",", "labels", ",", "scores", ")", ":", "\n", "    ", "\"\"\" create the target by labels and scores \"\"\"", "\n", "target", "=", "[", "0", "]", "*", "len", "\n", "for", "id", ",", "l", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "target", "[", "l", "]", "=", "scores", "[", "id", "]", "\n", "\n", "", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.main": [[937, 1244], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "oscar.utils.misc.set_seed", "parser.parse_args.task_name.lower", "processor.get_labels", "len", "logger.info", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.init_weights_with_pretrained_parameters", "model_class.from_pretrained.to", "logger.info", "run_gqa_prompt_zero_few._load_img_features", "run_gqa_prompt_zero_few.GQADataset", "logger.info", "os.path.join", "logger.info", "os.path.exists", "os.listdir", "logger.info", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.set_device", "torch.cuda.set_device", "torch.device", "torch.device", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "bool", "ValueError", "torch.distributed.barrier", "torch.distributed.barrier", "logger.info", "time.time", "torch.load", "torch.load", "time.time", "logger.info", "logger.info", "torch.distributed.barrier", "torch.distributed.barrier", "print", "run_gqa_prompt_zero_few.evaluate", "run_gqa_prompt_zero_few.GQADataset", "run_gqa_prompt_zero_few.GQADataset", "run_gqa_prompt_zero_few.GQADataset", "run_gqa_prompt_zero_few.train", "logger.info", "run_gqa_prompt_zero_few.GQADataset", "run_gqa_prompt_zero_few.train", "logger.info", "logger.info", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "torch.save", "logger.info", "logger.info", "logger.info", "os.getenv", "os.path.join", "bool", "model_class.from_pretrained.init_code_embedding", "os.makedirs", "os.path.join", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_gqa_prompt_zero_few.evaluate", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_gqa_prompt_zero_few.evaluate", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_gqa_prompt_zero_few.test", "train_code[].t", "model_class.from_pretrained.init_code_embedding", "torch.distributed.get_rank", "torch.distributed.get_rank", "os.path.exists", "MODEL_CLASSES.keys", "oscar.utils.task_utils.processors.keys", "torch.cuda.is_available", "torch.cuda.is_available", "train_code[].t", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "sorted", "sorted", "sorted", "glob.glob", "glob.glob", "glob.glob", "list", "train_code[].keys", "list", "train_code[].keys"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.ImageBertForSequenceClassificationPromptSubset.init_weights_with_pretrained_parameters", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few._load_img_features", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.train", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.ImageBertForSequenceClassification.init_code_embedding", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.oscar.run_gqa_prompt_zero_few.test", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.ImageBertForSequenceClassification.init_code_embedding", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the .tsv files (or other data files) for the task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--task_name\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train selected in the list: \"", "+", "\", \"", ".", "join", "(", "processors", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--label_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Label Dictionary\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--label2ans_file\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Label to Answer Dictionary\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--data_label_type\"", ",", "default", "=", "'bal'", ",", "type", "=", "str", ",", "help", "=", "\"bal or all\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_data_type\"", ",", "default", "=", "'bal'", ",", "type", "=", "str", ",", "help", "=", "\"bal or all\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_data_type\"", ",", "default", "=", "'bal'", ",", "type", "=", "str", ",", "help", "=", "\"bal or all\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--loss_type\"", ",", "default", "=", "'kl'", ",", "type", "=", "str", ",", "help", "=", "\"kl or xe\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--spatial_dim\"", ",", "default", "=", "6", ",", "type", "=", "int", ",", "help", "=", "\"spatial_dim\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_label_pos_length\"", ",", "default", "=", "45", ",", "type", "=", "int", ",", "help", "=", "\"The maximum total input label position sequence length.\"", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer than this will be truncated, sequences shorter will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train_val\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run test on the test set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test_dev\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to run test on the test-dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Rul evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--drop_out\"", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "\"Drop out for BERT.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--classifier\"", ",", "default", "=", "'linear'", ",", "type", "=", "str", ",", "help", "=", "\"linear or mlp\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cls_hidden_scale\"", ",", "default", "=", "2", ",", "type", "=", "int", ",", "help", "=", "\"cls_hidden_scale: for classifier\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_img_seq_length\"", ",", "default", "=", "30", ",", "type", "=", "int", ",", "help", "=", "\"The maximum total input image sequence length.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_dim\"", ",", "default", "=", "2054", ",", "type", "=", "int", ",", "help", "=", "\"The Image Feature Dimension.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--img_feature_type\"", ",", "default", "=", "'faster_r-cnn'", ",", "type", "=", "str", ",", "help", "=", "\"faster_r-cnn or mask_r-cnn\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_voc\"", ",", "default", "=", "512", ",", "type", "=", "int", ",", "help", "=", "\"dis_code_voc: 256, 512\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_level\"", ",", "default", "=", "'top'", ",", "type", "=", "str", ",", "help", "=", "\"code level: top, botttom, both\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_epoch'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "\"Save checkpoint every X epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_output_dir'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_cache'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_ip'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_port'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--philly\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use Philly: reset the output dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--load_fast\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Load Tensor Fast\"", ")", "\n", "parser", ".", "add_argument", "(", "'-j'", ",", "'--workers'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "help", "=", "'number of data loading workers (default: 4)'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--use_yn'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use yes/no questions in training set.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num_examples'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"Num exmaples for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--subset_seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"Random seed for sampling subset.\"", ")", "\n", "#args = '--data_dir ../vqa/ban-vqa/data/qal_pairs --model_type bert --model_name_or_path bert-base-uncased --task_name vqa_text ' \\", "\n", "#       '--do_train --do_eval --do_lower_case --max_seq_length 40 --per_gpu_eval_batch_size 16 --per_gpu_train_batch_size 16 --learning_rate 2e-5 ' \\", "\n", "#       '--num_train_epochs 20.0 --output_dir ./results/vqa_text --label_file ../vqa/ban-vqa/data/cache/trainval_ans2label.pkl ' \\", "\n", "#       '--save_steps 5000 --overwrite_output_dir --max_img_seq_length 1 --img_feature_dim 565 --img_feature_type dis_code '", "\n", "\n", "#args = '--data_dir ../vqa/ban-vqa/data/qal_pairs --model_type bert --model_name_or_path bert-base-uncased --task_name vqa_text ' \\", "\n", "#       '--do_train --do_eval --do_lower_case --max_seq_length 40 --per_gpu_eval_batch_size 16 --per_gpu_train_batch_size 16 --learning_rate 2e-5 ' \\", "\n", "#       '--num_train_epochs 20.0 --output_dir ./results/vqa_text --label_file ../vqa/ban-vqa/data/cache/trainval_ans2label.pkl ' \\", "\n", "#       '--save_steps 5000 --overwrite_output_dir --max_img_seq_length 10 --img_feature_dim 565 --img_feature_type other '", "\n", "\n", "#args = parser.parse_args(args.split())", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "num_examples", "==", "0", "and", "args", ".", "subset_seed", "!=", "0", ":", "return", "\n", "\n", "if", "args", ".", "philly", ":", "# use philly", "\n", "        ", "logger", ".", "info", "(", "'Info: Use Philly, all the output folders are reset.'", ")", "\n", "args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "getenv", "(", "'PT_OUTPUT_DIR'", ")", ",", "args", ".", "output_dir", ")", "\n", "logger", ".", "info", "(", "'OUTPUT_DIR:'", ",", "args", ".", "output_dir", ")", "\n", "\n", "#if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train and not args.overwrite_output_dir:", "\n", "#    raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args.output_dir))", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", ":", "\n", "        ", "logger", ".", "info", "(", "\"Output Directory Exists.\"", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s - %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ".", "seed", ",", "args", ".", "n_gpu", ")", "\n", "\n", "# Prepare GLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "args", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "\n", "label_list", "=", "processor", ".", "get_labels", "(", "args", ".", "label_file", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "logger", ".", "info", "(", "'Task Name: {}, #Labels: {}'", ".", "format", "(", "args", ".", "task_name", ",", "num_labels", ")", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "\n", "# discrete code", "\n", "config", ".", "img_feature_dim", "=", "args", ".", "img_feature_dim", "# 2054", "\n", "config", ".", "img_feature_type", "=", "args", ".", "img_feature_type", "# faster_r-cnn", "\n", "config", ".", "code_voc", "=", "args", ".", "code_voc", "# 512", "\n", "config", ".", "hidden_dropout_prob", "=", "args", ".", "drop_out", "# 0.3", "\n", "config", ".", "loss_type", "=", "args", ".", "loss_type", "# xe", "\n", "config", ".", "classifier", "=", "args", ".", "classifier", "# linear", "\n", "config", ".", "cls_hidden_scale", "=", "args", ".", "cls_hidden_scale", "# 2", "\n", "config", ".", "spatial_dim", "=", "args", ".", "spatial_dim", "# 6", "\n", "config", ".", "pretrained_model_name_or_path", "=", "args", ".", "model_name_or_path", "\n", "config", ".", "label2ans_file", "=", "args", ".", "label2ans_file", "\n", "\n", "# load discrete code", "\n", "if", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "'Load discrete code from: {}'", ".", "format", "(", "args", ".", "data_dir", ")", ")", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "train_code", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'vqvae'", ",", "'train.pt'", ")", ")", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "'Load time: %.3f'", "%", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "if", "args", ".", "code_level", "==", "'top'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_t'", "]", ".", "shape", "[", "0", "]", "\n", "config", ".", "code_size", "=", "train_code", "[", "'feats_top'", "]", "[", "list", "(", "train_code", "[", "'feats_top'", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "shape", "[", "0", "]", "\n", "", "elif", "args", ".", "code_level", "==", "'bottom'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_b'", "]", ".", "shape", "[", "0", "]", "\n", "config", ".", "code_size", "=", "train_code", "[", "'feats_bottom'", "]", "[", "list", "(", "train_code", "[", "'feats_bottom'", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "shape", "[", "0", "]", "\n", "", "elif", "args", ".", "code_level", "==", "'both'", ":", "\n", "            ", "config", ".", "code_dim", "=", "train_code", "[", "'embeddings_t'", "]", ".", "shape", "[", "0", "]", "+", "train_code", "[", "'embeddings_b'", "]", ".", "shape", "[", "0", "]", "\n", "\n", "", "", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "from_tf", "=", "bool", "(", "'.ckpt'", "in", "args", ".", "model_name_or_path", ")", ",", "config", "=", "config", ")", "\n", "model", ".", "init_weights_with_pretrained_parameters", "(", "config", ")", "\n", "if", "args", ".", "img_feature_type", "in", "[", "'dis_code'", ",", "'dis_code_t'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "'Initializing the code embedding with {}'", ".", "format", "(", "args", ".", "code_level", ")", ")", "\n", "if", "args", ".", "code_level", "==", "'top'", ":", "\n", "            ", "model", ".", "init_code_embedding", "(", "train_code", "[", "'embeddings_t'", "]", ".", "t", "(", ")", ")", "\n", "", "elif", "args", ".", "code_level", "==", "'bottom'", ":", "\n", "            ", "model", ".", "init_code_embedding", "(", "train_code", "[", "'embeddings_b'", "]", ".", "t", "(", ")", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# load image features", "\n", "img_features", "=", "_load_img_features", "(", "args", ")", "\n", "label_pos_feats", "=", "None", "\n", "\n", "#if args.do_eval:", "\n", "eval_dataset", "=", "GQADataset", "(", "args", ",", "'val'", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", ")", "\n", "#eval_dataset = GQADataset(args, 'test-dev', img_features, tokenizer) # test-dev as val", "\n", "if", "args", ".", "num_examples", "==", "0", ":", "\n", "        ", "print", "(", "\"Evaluating zero-shot performace.\"", ")", "\n", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ")", "\n", "return", "\n", "\n", "", "if", "args", ".", "do_test", ":", "\n", "        ", "test_dataset", "=", "GQADataset", "(", "args", ",", "'test'", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", ")", "\n", "\n", "", "if", "args", ".", "do_test_dev", ":", "\n", "        ", "test_dev_dataset", "=", "GQADataset", "(", "args", ",", "'test-dev'", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", ")", "\n", "\n", "# Training", "\n", "", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "GQADataset", "(", "args", ",", "'train'", ",", "img_features", ",", "tokenizer", ",", "label_pos_feats", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Training on train+val", "\n", "", "if", "args", ".", "do_train_val", ":", "# depreciated", "\n", "        ", "train_dataset", "=", "GQADataset", "(", "args", ",", "'train+val'", ",", "img_features", ",", "tokenizer", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`. They can then be reloaded using `from_pretrained()`", "\n", "#model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training", "\n", "#model_to_save.save_pretrained(args.output_dir)", "\n", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "#model = model_class.from_pretrained(args.output_dir)", "\n", "#tokenizer = tokenizer_class.from_pretrained(args.output_dir)", "\n", "#model.to(args.device)", "\n", "\n", "\n", "# Evaluation", "\n", "#results = {}", "\n", "", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ",", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "score", "=", "evaluate", "(", "args", ",", "model", ",", "eval_dataset", ",", "prefix", "=", "global_step", ")", "\n", "#result = dict((k + '_{}'.format(global_step), v) for k, v in result.items())", "\n", "#results.update(result)", "\n", "\n", "# Test-Dev", "\n", "", "", "if", "args", ".", "do_test_dev", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ",", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "score", "=", "evaluate", "(", "args", ",", "model", ",", "test_dev_dataset", ",", "prefix", "=", "global_step", ")", "\n", "#test(args, model, test_dev_dataset, prefix=global_step)", "\n", "\n", "# Test-Submission", "\n", "", "", "if", "args", ".", "do_test", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "test", "(", "args", ",", "model", ",", "test_dataset", ",", "prefix", "=", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.ScstRewardCriterion.__init__": [[118, 124], ["cider.pyciderevalcap.ciderD.ciderD.CiderD", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__"], ["def", "__init__", "(", "self", ",", "cider_cached_tokens", "=", "'corpus'", ",", "baseline_type", "=", "'greedy'", ")", ":", "\n", "        ", "self", ".", "CiderD_scorer", "=", "CiderD", "(", "df", "=", "cider_cached_tokens", ")", "\n", "assert", "baseline_type", "in", "[", "'greedy'", ",", "'sample'", "]", "\n", "self", ".", "baseline_type", "=", "baseline_type", "\n", "self", ".", "_cur_score", "=", "None", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.ScstRewardCriterion.forward": [[125, 156], ["len", "len", "gen_res.extend", "caption_evaluate.ScstRewardCriterion._calculate_eval_scores", "scores[].reshape", "torch.as_tensor.mean", "torch.as_tensor.reshape", "torch.as_tensor", "loss.mean.mean.mean", "gen_res.extend", "gt_idx.extend", "caption_evaluate.ScstRewardCriterion.reshape", "range", "len", "caption_evaluate.ScstRewardCriterion.reshape.sum", "range"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.ScstRewardCriterion._calculate_eval_scores"], ["", "def", "forward", "(", "self", ",", "gt_res", ",", "greedy_res", ",", "sample_res", ",", "sample_logprobs", ")", ":", "\n", "        ", "batch_size", "=", "len", "(", "gt_res", ")", "\n", "sample_res_size", "=", "len", "(", "sample_res", ")", "\n", "seq_per_img", "=", "sample_res_size", "//", "batch_size", "\n", "\n", "gen_res", "=", "[", "]", "\n", "gen_res", ".", "extend", "(", "sample_res", ")", "\n", "gt_idx", "=", "[", "i", "//", "seq_per_img", "for", "i", "in", "range", "(", "sample_res_size", ")", "]", "\n", "if", "self", ".", "baseline_type", "==", "'greedy'", ":", "\n", "            ", "assert", "len", "(", "greedy_res", ")", "==", "batch_size", "\n", "gen_res", ".", "extend", "(", "greedy_res", ")", "\n", "gt_idx", ".", "extend", "(", "[", "i", "for", "i", "in", "range", "(", "batch_size", ")", "]", ")", "\n", "\n", "", "scores", "=", "self", ".", "_calculate_eval_scores", "(", "gen_res", ",", "gt_idx", ",", "gt_res", ")", "\n", "\n", "if", "self", ".", "baseline_type", "==", "'greedy'", ":", "\n", "            ", "baseline", "=", "scores", "[", "-", "batch_size", ":", "]", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "", "else", ":", "\n", "            ", "sc_", "=", "scores", ".", "reshape", "(", "batch_size", ",", "seq_per_img", ")", "\n", "baseline", "=", "(", "sc_", ".", "sum", "(", "1", ",", "keepdims", "=", "True", ")", "-", "sc_", ")", "/", "(", "sc_", ".", "shape", "[", "1", "]", "-", "1", ")", "\n", "\n", "# sample - baseline", "\n", "", "reward", "=", "scores", "[", ":", "sample_res_size", "]", ".", "reshape", "(", "batch_size", ",", "seq_per_img", ")", "\n", "self", ".", "_cur_score", "=", "reward", ".", "mean", "(", ")", "\n", "reward", "=", "reward", "-", "baseline", "\n", "reward", "=", "reward", ".", "reshape", "(", "sample_res_size", ")", "\n", "\n", "reward", "=", "torch", ".", "as_tensor", "(", "reward", ",", "device", "=", "sample_logprobs", ".", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "loss", "=", "-", "sample_logprobs", "*", "reward", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.ScstRewardCriterion.get_score": [[157, 159], ["None"], "methods", ["None"], ["", "def", "get_score", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_cur_score", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.ScstRewardCriterion._calculate_eval_scores": [[160, 186], ["len", "collections.OrderedDict", "range", "collections.OrderedDict", "range", "caption_evaluate.ScstRewardCriterion.CiderD_scorer.compute_score", "caption_evaluate.ScstRewardCriterion._wrap_sentence", "caption_evaluate.ScstRewardCriterion._wrap_sentence", "range", "range", "range", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD.CiderD.compute_score", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.ScstRewardCriterion._wrap_sentence", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.ScstRewardCriterion._wrap_sentence"], ["", "def", "_calculate_eval_scores", "(", "self", ",", "gen_res", ",", "gt_idx", ",", "gt_res", ")", ":", "\n", "        ", "'''\n        gen_res: generated captions, list of str\n        gt_idx: list of int, of the same length as gen_res\n        gt_res: ground truth captions, list of list of str.\n            gen_res[i] corresponds to gt_res[gt_idx[i]]\n            Each image can have multiple ground truth captions\n        '''", "\n", "gen_res_size", "=", "len", "(", "gen_res", ")", "\n", "\n", "res", "=", "OrderedDict", "(", ")", "\n", "for", "i", "in", "range", "(", "gen_res_size", ")", ":", "\n", "            ", "res", "[", "i", "]", "=", "[", "self", ".", "_wrap_sentence", "(", "gen_res", "[", "i", "]", ")", "]", "\n", "\n", "", "gts", "=", "OrderedDict", "(", ")", "\n", "gt_res_", "=", "[", "\n", "[", "self", ".", "_wrap_sentence", "(", "gt_res", "[", "i", "]", "[", "j", "]", ")", "for", "j", "in", "range", "(", "len", "(", "gt_res", "[", "i", "]", ")", ")", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "gt_res", ")", ")", "\n", "]", "\n", "for", "i", "in", "range", "(", "gen_res_size", ")", ":", "\n", "            ", "gts", "[", "i", "]", "=", "gt_res_", "[", "gt_idx", "[", "i", "]", "]", "\n", "\n", "", "res_", "=", "[", "{", "'image_id'", ":", "i", ",", "'caption'", ":", "res", "[", "i", "]", "}", "for", "i", "in", "range", "(", "len", "(", "res", ")", ")", "]", "\n", "_", ",", "batch_cider_scores", "=", "self", ".", "CiderD_scorer", ".", "compute_score", "(", "gts", ",", "res_", ")", "\n", "scores", "=", "self", ".", "CIDER_REWARD_WEIGHT", "*", "batch_cider_scores", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.ScstRewardCriterion._wrap_sentence": [[187, 196], ["s.strip", "s.strip.endswith"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_wrap_sentence", "(", "self", ",", "s", ")", ":", "\n", "# ensure the sentence ends with <eos> token", "\n", "# in order to keep consisitent with cider_cached_tokens", "\n", "        ", "r", "=", "s", ".", "strip", "(", ")", "\n", "if", "r", ".", "endswith", "(", "'.'", ")", ":", "\n", "            ", "r", "=", "r", "[", ":", "-", "1", "]", "\n", "", "r", "+=", "' <eos>'", "\n", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.__init__": [[226, 231], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "phase", ":", "str", "=", "\"val\"", ")", ":", "\n", "\n", "# Constants specific to EvalAI.", "\n", "        ", "self", ".", "_challenge_id", "=", "355", "\n", "self", ".", "_phase_id", "=", "742", "if", "phase", "==", "\"val\"", "else", "743", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate": [[232, 337], ["tempfile.mkstemp", "subprocess.Popen", "[].decode", "re.search", "json.loads", "collections.defaultdict", "json.loads.items", "open", "json.dump", "submission_command.split", "print", "print", "time.sleep", "subprocess.check_output().decode", "val.items", "re.search.group().split", "caption_evaluate.NocapsEvaluator.evaluate", "ConnectionError", "subprocess.Popen.communicate", "subprocess.check_output", "re.search.group"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.ConstrainedBeamSearch.search", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate"], ["", "def", "evaluate", "(", "\n", "self", ",", "predictions", ",", "iteration", ":", "Optional", "[", "int", "]", "=", "None", "\n", ")", "->", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "float", "]", "]", ":", "\n", "        ", "r\"\"\"\n        Take the model predictions (in COCO format), submit them to EvalAI, and retrieve model\n        performance based on captioning metrics.\n\n        Parameters\n        ----------\n        predictions: List[Prediction]\n            Model predictions in COCO format. They are a list of dicts with keys\n            ``{\"image_id\": int, \"caption\": str}``.\n        iteration: int, optional (default = None)\n            Training iteration where the checkpoint was evaluated.\n\n        Returns\n        -------\n        Dict[str, Dict[str, float]]\n            Model performance based on all captioning metrics. Nested dict structure::\n\n                {\n                    \"B1\": {\"in-domain\", \"near-domain\", \"out-domain\", \"entire\"},  # BLEU-1\n                    \"B2\": {\"in-domain\", \"near-domain\", \"out-domain\", \"entire\"},  # BLEU-2\n                    \"B3\": {\"in-domain\", \"near-domain\", \"out-domain\", \"entire\"},  # BLEU-3\n                    \"B4\": {\"in-domain\", \"near-domain\", \"out-domain\", \"entire\"},  # BLEU-4\n                    \"METEOR\": {\"in-domain\", \"near-domain\", \"out-domain\", \"entire\"},\n                    \"ROUGE-L\": {\"in-domain\", \"near-domain\", \"out-domain\", \"entire\"},\n                    \"CIDEr\": {\"in-domain\", \"near-domain\", \"out-domain\", \"entire\"},\n                    \"SPICE\": {\"in-domain\", \"near-domain\", \"out-domain\", \"entire\"},\n                }\n\n        \"\"\"", "\n", "# Save predictions as a json file first.", "\n", "_", ",", "predictions_filename", "=", "tempfile", ".", "mkstemp", "(", "suffix", "=", "\".json\"", ",", "text", "=", "True", ")", "\n", "with", "open", "(", "predictions_filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "predictions", ",", "f", ")", "\n", "\n", "", "submission_command", "=", "(", "\n", "f\"evalai challenge {self._challenge_id} phase {self._phase_id} \"", "\n", "f\"submit --file {predictions_filename}\"", "\n", ")", "\n", "\n", "submission_command_subprocess", "=", "subprocess", ".", "Popen", "(", "\n", "submission_command", ".", "split", "(", ")", ",", "\n", "stdout", "=", "subprocess", ".", "PIPE", ",", "\n", "stdin", "=", "subprocess", ".", "PIPE", ",", "\n", "stderr", "=", "subprocess", ".", "STDOUT", ",", "\n", ")", "\n", "\n", "# This terminal output will have submission ID we need to check.", "\n", "submission_command_stdout", "=", "submission_command_subprocess", ".", "communicate", "(", "input", "=", "b\"N\\n\"", ")", "[", "\n", "0", "\n", "]", ".", "decode", "(", "\"utf-8\"", ")", "\n", "\n", "submission_id_regex", "=", "re", ".", "search", "(", "\"evalai submission ([0-9]+)\"", ",", "submission_command_stdout", ")", "\n", "try", ":", "\n", "# Get an integer submission ID (as a string).", "\n", "            ", "submission_id", "=", "submission_id_regex", ".", "group", "(", "0", ")", ".", "split", "(", ")", "[", "-", "1", "]", "# type: ignore", "\n", "", "except", ":", "\n", "# Very unlikely, but submission may fail because of some glitch. Retry for that.", "\n", "            ", "return", "self", ".", "evaluate", "(", "predictions", ")", "\n", "\n", "", "if", "iteration", "is", "not", "None", ":", "\n", "            ", "print", "(", "f\"Submitted predictions for iteration {iteration}, submission id: {submission_id}.\"", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "f\"Submitted predictions, submission_id: {submission_id}\"", ")", "\n", "\n", "# Placeholder stdout for a pending submission.", "\n", "", "result_stdout", ":", "str", "=", "\"The Submission is yet to be evaluated.\"", "\n", "num_tries", ":", "int", "=", "0", "\n", "\n", "# Query every 10 seconds for result until it appears.", "\n", "while", "\"CIDEr\"", "not", "in", "result_stdout", ":", "\n", "\n", "            ", "time", ".", "sleep", "(", "10", ")", "\n", "result_stdout", "=", "subprocess", ".", "check_output", "(", "\n", "[", "\"evalai\"", ",", "\"submission\"", ",", "submission_id", ",", "\"result\"", "]", "\n", ")", ".", "decode", "(", "\"utf-8\"", ")", "\n", "num_tries", "+=", "1", "\n", "\n", "# Raise error if it takes more than 5 minutes.", "\n", "if", "num_tries", "==", "30", ":", "\n", "                ", "raise", "ConnectionError", "(", "\"Unable to get results from EvalAI within 5 minutes!\"", ")", "\n", "\n", "# Convert result to json.", "\n", "", "", "metrics", "=", "json", ".", "loads", "(", "result_stdout", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "\n", "# keys: {\"in-domain\", \"near-domain\", \"out-domain\", \"entire\"}", "\n", "# In each of these, keys: {\"B1\", \"B2\", \"B3\", \"B4\", \"METEOR\", \"ROUGE-L\", \"CIDEr\", \"SPICE\"}", "\n", "metrics", "=", "{", "\n", "\"in-domain\"", ":", "metrics", "[", "0", "]", "[", "\"in-domain\"", "]", ",", "\n", "\"near-domain\"", ":", "metrics", "[", "1", "]", "[", "\"near-domain\"", "]", ",", "\n", "\"out-domain\"", ":", "metrics", "[", "2", "]", "[", "\"out-domain\"", "]", ",", "\n", "\"entire\"", ":", "metrics", "[", "3", "]", "[", "\"entire\"", "]", ",", "\n", "}", "\n", "\n", "# Restructure the metrics dict for better tensorboard logging.", "\n", "# keys: {\"B1\", \"B2\", \"B3\", \"B4\", \"METEOR\", \"ROUGE-L\", \"CIDEr\", \"SPICE\"}", "\n", "# In each of these, keys: keys: {\"in-domain\", \"near-domain\", \"out-domain\", \"entire\"}", "\n", "flipped_metrics", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "float", "]", "]", "=", "defaultdict", "(", "dict", ")", "\n", "for", "key", ",", "val", "in", "metrics", ".", "items", "(", ")", ":", "\n", "            ", "for", "subkey", ",", "subval", "in", "val", ".", "items", "(", ")", ":", "\n", "                ", "flipped_metrics", "[", "subkey", "]", "[", "key", "]", "=", "subval", "\n", "\n", "", "", "return", "flipped_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.evaluate_on_nocaps": [[20, 57], ["os.isfile", "os.join", "json.load", "caption_evaluate.NocapsEvaluator", "caption_evaluate.NocapsEvaluator.evaluate", "pprint.pprint", "print", "open", "open", "print", "ipdb.set_trace", "open", "json.dump", "open", "json.load", "line.strip().split", "predictions.append", "os.splitext", "line.strip", "json.loads"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate"], ["def", "evaluate_on_nocaps", "(", "split", ",", "predict_file", ",", "data_dir", "=", "'data/nocaps/'", ",", "evaluate_file", "=", "None", ")", ":", "\n", "    ", "'''\n    NOTE: Put the auth file in folder ~/.evalai/\n    '''", "\n", "if", "not", "evaluate_file", ":", "\n", "        ", "evaluate_file", "=", "op", ".", "splitext", "(", "predict_file", ")", "[", "0", "]", "+", "'.eval.json'", "\n", "", "if", "op", ".", "isfile", "(", "evaluate_file", ")", ":", "\n", "        ", "print", "(", "'{} already exists'", ".", "format", "(", "evaluate_file", ")", ")", "\n", "with", "open", "(", "evaluate_file", ",", "'r'", ")", "as", "fp", ":", "\n", "            ", "metrics", "=", "json", ".", "load", "(", "fp", ")", "\n", "", "return", "metrics", "\n", "\n", "", "image_info_file", "=", "op", ".", "join", "(", "data_dir", ",", "\n", "'nocaps_{}_image_info.json'", ".", "format", "(", "split", ")", ")", "\n", "image_info", "=", "json", ".", "load", "(", "open", "(", "image_info_file", ")", ")", "\n", "open_image_id2id", "=", "{", "}", "\n", "for", "it", "in", "image_info", "[", "'images'", "]", ":", "\n", "        ", "open_image_id2id", "[", "it", "[", "'open_images_id'", "]", "]", "=", "it", "[", "'id'", "]", "\n", "", "predictions", "=", "[", "]", "\n", "cap_id", "=", "0", "\n", "with", "open", "(", "predict_file", ",", "'r'", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "p", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "predictions", ".", "append", "(", "\n", "{", "'image_id'", ":", "open_image_id2id", "[", "p", "[", "0", "]", "]", ",", "\n", "'caption'", ":", "json", ".", "loads", "(", "p", "[", "1", "]", ")", "[", "0", "]", "[", "'caption'", "]", ",", "\n", "'id'", ":", "cap_id", "}", ")", "\n", "cap_id", "+=", "1", "\n", "", "", "if", "split", "==", "'test'", ":", "\n", "        ", "print", "(", "'Are you sure to submit test split result at: {}'", ".", "format", "(", "predict_file", ")", ")", "\n", "import", "ipdb", ";", "ipdb", ".", "set_trace", "(", ")", "\n", "", "nocapseval", "=", "NocapsEvaluator", "(", "phase", "=", "split", ")", "\n", "metrics", "=", "nocapseval", ".", "evaluate", "(", "predictions", ")", "\n", "pprint", "(", "metrics", ")", "\n", "with", "open", "(", "evaluate_file", ",", "'w'", ")", "as", "fp", ":", "\n", "        ", "json", ".", "dump", "(", "metrics", ",", "fp", ")", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.evaluate_on_coco_caption": [[59, 91], ["label_file.endswith", "res_file.endswith", "coco_caption.pycocotools.coco.COCO", "coco_caption.pycocotools.coco.COCO.loadRes", "coco_caption.pycocoevalcap.eval.COCOEvalCap", "coco.loadRes.getImgIds", "coco_caption.pycocoevalcap.eval.COCOEvalCap.evaluate", "caption_evaluate.convert_tsv_to_coco_format", "ValueError", "print", "open", "json.dump", "os.splitext"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.NocapsEvaluator.evaluate", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.convert_tsv_to_coco_format"], ["", "def", "evaluate_on_coco_caption", "(", "res_file", ",", "label_file", ",", "outfile", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    res_tsv: TSV file, each row is [image_key, json format list of captions].\n             Each caption is a dict, with fields \"caption\", \"conf\".\n    label_file: JSON file of ground truth captions in COCO format.\n    \"\"\"", "\n", "assert", "label_file", ".", "endswith", "(", "'.json'", ")", "\n", "if", "res_file", ".", "endswith", "(", "'.tsv'", ")", ":", "\n", "        ", "res_file_coco", "=", "op", ".", "splitext", "(", "res_file", ")", "[", "0", "]", "+", "'_coco_format.json'", "\n", "convert_tsv_to_coco_format", "(", "res_file", ",", "res_file_coco", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'unknown prediction result file format: {}'", ".", "format", "(", "res_file", ")", ")", "\n", "\n", "", "coco", "=", "COCO", "(", "label_file", ")", "\n", "cocoRes", "=", "coco", ".", "loadRes", "(", "res_file_coco", ")", "\n", "cocoEval", "=", "COCOEvalCap", "(", "coco", ",", "cocoRes", ",", "'corpus'", ")", "\n", "\n", "# evaluate on a subset of images by setting", "\n", "# cocoEval.params['image_id'] = cocoRes.getImgIds()", "\n", "# please remove this line when evaluating the full validation set", "\n", "cocoEval", ".", "params", "[", "'image_id'", "]", "=", "cocoRes", ".", "getImgIds", "(", ")", "\n", "\n", "# evaluate results", "\n", "# SPICE will take a few minutes the first time, but speeds up due to caching", "\n", "cocoEval", ".", "evaluate", "(", ")", "\n", "result", "=", "cocoEval", ".", "eval", "\n", "if", "not", "outfile", ":", "\n", "        ", "print", "(", "result", ")", "\n", "", "else", ":", "\n", "        ", "with", "open", "(", "outfile", ",", "'w'", ")", "as", "fp", ":", "\n", "            ", "json", ".", "dump", "(", "result", ",", "fp", ",", "indent", "=", "4", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.caption_evaluate.convert_tsv_to_coco_format": [[93, 113], ["open", "open", "json.dump", "line.strip().split", "results.append", "len", "json.loads", "caps[].get", "line.strip", "len"], "function", ["None"], ["", "def", "convert_tsv_to_coco_format", "(", "res_tsv", ",", "outfile", ",", "\n", "sep", "=", "'\\t'", ",", "key_col", "=", "0", ",", "cap_col", "=", "1", ")", ":", "\n", "    ", "results", "=", "[", "]", "\n", "with", "open", "(", "res_tsv", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "parts", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "sep", ")", "\n", "key", "=", "parts", "[", "key_col", "]", "\n", "if", "cap_col", "<", "len", "(", "parts", ")", ":", "\n", "                ", "caps", "=", "json", ".", "loads", "(", "parts", "[", "cap_col", "]", ")", "\n", "assert", "len", "(", "caps", ")", "==", "1", ",", "'cannot evaluate multiple captions per image'", "\n", "cap", "=", "caps", "[", "0", "]", ".", "get", "(", "'caption'", ",", "''", ")", "\n", "", "else", ":", "\n", "# empty caption generated", "\n", "                ", "cap", "=", "\"\"", "\n", "", "results", ".", "append", "(", "\n", "{", "'image_id'", ":", "key", ",", "\n", "'caption'", ":", "cap", "}", "\n", ")", "\n", "", "", "with", "open", "(", "outfile", ",", "'w'", ")", "as", "fp", ":", "\n", "        ", "json", ".", "dump", "(", "results", ",", "fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.ConstrainedBeamSearch.__init__": [[36, 53], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "eos_token_ids", ":", "List", "[", "int", "]", ",", "\n", "max_steps", ":", "int", "=", "20", ",", "\n", "beam_size", ":", "int", "=", "5", ",", "\n", "per_node_beam_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "use_hypo", ":", "bool", "=", "False", ",", "\n", "tokenizer", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "_eos_token_ids", "=", "eos_token_ids", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "self", ".", "per_node_beam_size", "=", "per_node_beam_size", "or", "self", ".", "beam_size", "\n", "self", ".", "num_keep_best", "=", "1", "\n", "self", ".", "length_penalty", "=", "1", "\n", "self", ".", "use_hypo", "=", "use_hypo", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.ConstrainedBeamSearch.search": [[54, 364], ["fsm.size", "start_predictions.expand().reshape", "step", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax.size", "torch.nn.functional.log_softmax.view().expand", "start_state_predictions.masked_fill.masked_fill.masked_fill", "start_state_predictions.masked_fill.masked_fill.topk", "predictions.append", "torch.full().to", "fsm.view().expand", "range", "predictions[].reshape", "torch.cat", "range", "predictions[].gather().unsqueeze", "reconstructed_predictions.append", "torch.cat", "torch.cat.view", "float", "start_predicted_classes.view", "predictions[].reshape", "cur_finished.all", "torch.cat", "step", "torch.nn.functional.log_softmax", "cur_finished.unsqueeze().expand", "torch.where", "cleaned_log_probabilities.view.view.view", "torch.LongTensor().to", "torch.FloatTensor().to", "torch.LongTensor().to", "torch.FloatTensor().to.view.view().expand", "range", "restricted_predicted_classes.view.view.view", "predictions.append", "backpointers.append", "torch.FloatTensor().to.view", "cbs.ConstrainedBeamSearch.search.track_back_state"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "search", "(", "\n", "self", ",", "\n", "start_predictions", ":", "torch", ".", "Tensor", ",", "\n", "start_state", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "step", ":", "StepFunctionType", ",", "\n", "fsm", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "r\"\"\"\n        Given a starting state, a step function, and an FSM adjacency matrix, apply Constrained\n        Beam Search to find most likely target sequences satisfying specified constraints in FSM.\n\n        .. note::\n\n            If your step function returns ``-inf`` for some log probabilities\n            (like if you're using a masked log-softmax) then some of the \"best\"\n            sequences returned may also have ``-inf`` log probability. Specifically\n            this happens when the beam size is smaller than the number of actions\n            with finite log probability (non-zero probability) returned by the step function.\n            Therefore if you're using a mask you may want to check the results from ``search``\n            and potentially discard sequences with non-finite log probability.\n\n        Parameters\n        ----------\n        start_predictions : torch.Tensor\n            A tensor containing the initial predictions with shape ``(batch_size, )``. These are\n            usually just ``@@BOUNDARY@@`` token indices.\n        start_state : ``Dict[str, torch.Tensor]``\n            The initial state passed to the ``step`` function. Each value of the state dict\n            should be a tensor of shape ``(batch_size, *)``, where ``*`` means any other\n            number of dimensions.\n        step : ``StepFunctionType``\n            A function that is responsible for computing the next most likely tokens, given the\n            current state and the predictions from the last time step. The function should accept\n            two arguments. The first being a tensor of shape ``(group_size,)``, representing the\n            index of the predicted tokens from the last time step, and the second being the\n            current state. The ``group_size`` will be ``batch_size * beam_size * num_fsm_states``\n            except in the initial step, for which it will just be ``batch_size``. The function is\n            expected to return a tuple, where the first element is a tensor of shape\n            ``(group_size, vocab_size)`` containing the log probabilities of the tokens for the\n            next step, and the second element is the updated state. The tensor in the state should\n            have shape ``(group_size, *)``, where ``*`` means any other number of dimensions.\n\n        Returns\n        -------\n        Tuple[torch.Tensor, torch.Tensor]\n            Tuple of ``(predictions, log_probabilities)``, where ``predictions``\n            has shape ``(batch_size, num_fsm_states, beam_size, max_steps)``\n            and ``log_probabilities`` has shape ``(batch_size, num_fsm_states, beam_size)``.\n        \"\"\"", "\n", "# shape: (batch_size, num_fsm_states, num_fsm_states, vocab_size)", "\n", "batch_size", ",", "num_fsm_states", ",", "_", ",", "vocab_size", "=", "fsm", ".", "size", "(", ")", "\n", "\n", "# generated hypotheses", "\n", "generated_hyps", "=", "[", "\n", "[", "BeamHypotheses", "(", "self", ".", "num_keep_best", ",", "self", ".", "max_steps", ",", "self", ".", "length_penalty", ",", "early_stopping", "=", "False", ")", "\n", "for", "_", "in", "range", "(", "num_fsm_states", ")", "]", "\n", "for", "bb", "in", "range", "(", "batch_size", ")", "\n", "]", "\n", "\n", "# List of (batch_size, num_fsm_states, beam_size) tensors. One for each time step. Does not", "\n", "# include the start symbols, which are implicit.", "\n", "predictions", ":", "List", "[", "torch", ".", "Tensor", "]", "=", "[", "]", "\n", "\n", "# List of (batch_size, num_fsm_states, beam_size) tensors. One for each time step. None for", "\n", "# the first. Stores the index n for the parent prediction.", "\n", "backpointers", ":", "List", "[", "torch", ".", "Tensor", "]", "=", "[", "]", "\n", "\n", "# Calculate the first timestep. This is done outside the main loop because we are going", "\n", "# from a single decoder input (the output from the encoder) to the top `beam_size`", "\n", "# decoder outputs per FSM state. On the other hand, within the main loop we are going", "\n", "# from the `beam_size` elements of the beam (per FSM state) to `beam_size`^2 candidates", "\n", "# from which we will select the top `beam_size` elements for the next iteration.", "\n", "\n", "curr_ids", "=", "(", "\n", "start_predictions", ".", "expand", "(", "batch_size", ",", "self", ".", "beam_size", "*", "num_fsm_states", ")", "\n", ".", "reshape", "(", "batch_size", "*", "self", ".", "beam_size", "*", "num_fsm_states", ",", "1", ")", "\n", ")", "\n", "# shape: start_class_log_probabilities (batch_size, vocab_size)", "\n", "start_class_logits", ",", "state", "=", "step", "(", "curr_ids", ",", "start_state", ")", "\n", "start_class_log_probabilities", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "start_class_logits", ",", "dim", "=", "-", "1", ")", "\n", "start_class_log_probabilities", "=", "start_class_log_probabilities", "[", ":", "batch_size", ",", ":", "]", "\n", "vocab_size", "=", "start_class_log_probabilities", ".", "size", "(", "-", "1", ")", "\n", "\n", "start_state_predictions", "=", "start_class_log_probabilities", ".", "view", "(", "\n", "batch_size", ",", "1", ",", "vocab_size", "\n", ")", ".", "expand", "(", "batch_size", ",", "num_fsm_states", ",", "vocab_size", ")", "\n", "\n", "start_state_predictions", "=", "start_state_predictions", ".", "masked_fill", "(", "\n", "(", "1", "-", "fsm", "[", ":", ",", "0", ",", ":", ",", ":", "]", ")", ".", "to", "(", "dtype", "=", "torch", ".", "bool", ")", ",", "float", "(", "\"-inf\"", ")", "\n", ")", "\n", "\n", "# (batch_size, num_fsm_states, beam_size)", "\n", "start_top_log_probabilities", ",", "start_predicted_classes", "=", "start_state_predictions", ".", "topk", "(", "\n", "self", ".", "beam_size", "\n", ")", "\n", "# shape: (batch_size, num_fsm_states, beam_size)", "\n", "last_log_probabilities", "=", "start_top_log_probabilities", "\n", "\n", "predictions", ".", "append", "(", "start_predicted_classes", ".", "view", "(", "batch_size", ",", "-", "1", ")", ")", "\n", "\n", "log_probs_after_end", "=", "torch", ".", "full", "(", "(", "1", ",", "vocab_size", ")", ",", "float", "(", "\"-inf\"", ")", ")", ".", "to", "(", "\n", "start_predictions", ".", "device", "\n", ")", "\n", "log_probs_after_end", "[", ":", ",", "self", ".", "_eos_token_ids", "]", "=", "0.0", "\n", "\n", "#state = {", "\n", "#key: _enlarge_single_tensor(value, batch_size, num_fsm_states, self.beam_size)", "\n", "#for (key, value) in state.items()", "\n", "#}", "\n", "\n", "step_state_mask", "=", "fsm", ".", "view", "(", "\n", "batch_size", ",", "num_fsm_states", ",", "num_fsm_states", ",", "1", ",", "vocab_size", "\n", ")", ".", "expand", "(", "batch_size", ",", "num_fsm_states", ",", "num_fsm_states", ",", "self", ".", "beam_size", ",", "vocab_size", ")", "\n", "\n", "curr_len", "=", "curr_ids", ".", "shape", "[", "1", "]", "\n", "for", "timestep", "in", "range", "(", "self", ".", "max_steps", "-", "curr_len", "-", "1", ")", ":", "\n", "# shape: (batch_size * beam_size * num_fsm_states, )", "\n", "            ", "last_predictions", "=", "predictions", "[", "-", "1", "]", ".", "reshape", "(", "\n", "batch_size", "*", "self", ".", "beam_size", "*", "num_fsm_states", "\n", ")", "\n", "cur_finished", "=", "(", "last_predictions", "==", "self", ".", "_eos_token_ids", "[", "0", "]", ")", "\n", "for", "eos_token", "in", "self", ".", "_eos_token_ids", "[", "1", ":", "]", ":", "\n", "                ", "cur_finished", "=", "(", "cur_finished", "|", "(", "last_predictions", "==", "eos_token", ")", ")", "\n", "", "if", "cur_finished", ".", "all", "(", ")", ":", "\n", "                ", "break", "\n", "\n", "", "curr_ids", "=", "torch", ".", "cat", "(", "[", "curr_ids", ",", "last_predictions", ".", "unsqueeze", "(", "-", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "class_logits", ",", "state", "=", "step", "(", "curr_ids", ",", "state", ")", "\n", "class_log_probabilities", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "class_logits", ",", "dim", "=", "-", "1", ")", "\n", "#last_predictions_expanded = (", "\n", "#last_predictions.view(-1)", "\n", "#.unsqueeze(-1)", "\n", "#.expand(batch_size * num_fsm_states * self.beam_size, vocab_size)", "\n", "#)", "\n", "cur_finished_expanded", "=", "(", "\n", "cur_finished", ".", "unsqueeze", "(", "-", "1", ")", "\n", ".", "expand", "(", "batch_size", "*", "num_fsm_states", "*", "self", ".", "beam_size", ",", "vocab_size", ")", "\n", ")", "\n", "\n", "cleaned_log_probabilities", "=", "torch", ".", "where", "(", "\n", "#last_predictions_expanded == self._eos_token_ids,", "\n", "cur_finished_expanded", ",", "\n", "log_probs_after_end", ",", "\n", "class_log_probabilities", ",", "\n", ")", "\n", "cleaned_log_probabilities", "=", "cleaned_log_probabilities", ".", "view", "(", "\n", "batch_size", ",", "num_fsm_states", ",", "self", ".", "beam_size", ",", "vocab_size", "\n", ")", "\n", "\n", "device", "=", "start_predictions", ".", "device", "\n", "restricted_predicted_classes", "=", "torch", ".", "LongTensor", "(", "\n", "batch_size", ",", "num_fsm_states", ",", "self", ".", "beam_size", "\n", ")", ".", "to", "(", "start_predictions", ".", "device", ")", "\n", "restricted_beam_log_probs", "=", "torch", ".", "FloatTensor", "(", "\n", "batch_size", ",", "num_fsm_states", ",", "self", ".", "beam_size", "\n", ")", ".", "to", "(", "start_predictions", ".", "device", ")", "\n", "restricted_beam_indices", "=", "torch", ".", "LongTensor", "(", "\n", "batch_size", ",", "num_fsm_states", ",", "self", ".", "beam_size", "\n", ")", ".", "to", "(", "start_predictions", ".", "device", ")", "\n", "\n", "expanded_last_log_probabilities", "=", "last_log_probabilities", ".", "view", "(", "\n", "batch_size", ",", "num_fsm_states", ",", "self", ".", "beam_size", ",", "1", "\n", ")", ".", "expand", "(", "batch_size", ",", "num_fsm_states", ",", "self", ".", "beam_size", ",", "self", ".", "per_node_beam_size", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_fsm_states", ")", ":", "\n", "# shape (batch_size, num_fsm_states, self.beam_size, vocab_size)", "\n", "                ", "state_log_probabilities", "=", "cleaned_log_probabilities", "\n", "\n", "state_log_probabilities", "=", "state_log_probabilities", ".", "masked_fill", "(", "\n", "(", "1", "-", "step_state_mask", "[", ":", ",", ":", ",", "i", ",", ":", ",", ":", "]", ")", ".", "to", "(", "dtype", "=", "torch", ".", "bool", ")", ",", "-", "1e20", "\n", ")", "\n", "top_log_probabilities", ",", "predicted_classes", "=", "state_log_probabilities", ".", "topk", "(", "\n", "self", ".", "per_node_beam_size", "\n", ")", "\n", "summed_top_log_probabilities", "=", "(", "\n", "top_log_probabilities", "+", "expanded_last_log_probabilities", "\n", ")", "\n", "# shape: (batch_size, old_num_fsm_states * beam_size * per_node_beam_size)", "\n", "reshaped_summed", "=", "summed_top_log_probabilities", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", "\n", "\n", "# shape: (batch_size, old_num_fsm_states * beam_size * per_node_beam_size)", "\n", "reshaped_predicted_classes", "=", "predicted_classes", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", "\n", "\n", "if", "not", "self", ".", "use_hypo", ":", "\n", "# shape (batch_size, beam_size)", "\n", "                    ", "state_beam_log_probs", ",", "state_beam_indices", "=", "reshaped_summed", ".", "topk", "(", "self", ".", "beam_size", ")", "\n", "# shape (batch_size, beam_size)", "\n", "state_predicted_classes", "=", "reshaped_predicted_classes", ".", "gather", "(", "1", ",", "state_beam_indices", ")", "\n", "", "else", ":", "\n", "# shape (batch_size, beam_size*per_node_beam_size)", "\n", "                    ", "candidate_beam_log_probs", ",", "candidate_beam_indices", "=", "reshaped_summed", ".", "topk", "(", "\n", "self", ".", "beam_size", "*", "self", ".", "per_node_beam_size", ",", "sorted", "=", "True", ",", "largest", "=", "True", ")", "\n", "# shape (batch_size, beam_size*per_node_beam_size)", "\n", "candidate_predicted_classes", "=", "reshaped_predicted_classes", ".", "gather", "(", "1", ",", "candidate_beam_indices", ")", "\n", "next_batch_beam", "=", "[", "]", "\n", "for", "batch_ex", "in", "range", "(", "batch_size", ")", ":", "\n", "                        ", "next_sent_beam", "=", "[", "]", "\n", "for", "word_id", ",", "beam_id", ",", "log_prob", "in", "zip", "(", "candidate_predicted_classes", "[", "batch_ex", "]", ",", "\n", "candidate_beam_indices", "[", "batch_ex", "]", ",", "\n", "candidate_beam_log_probs", "[", "batch_ex", "]", ")", ":", "\n", "                            ", "if", "word_id", ".", "item", "(", ")", "in", "self", ".", "_eos_token_ids", ":", "\n", "                                ", "generated_hyps", "[", "batch_ex", "]", "[", "i", "]", ".", "add", "(", "\n", "curr_ids", "[", "batch_ex", "*", "self", ".", "beam_size", "*", "num_fsm_states", "+", "beam_id", "/", "self", ".", "per_node_beam_size", ",", ":", "]", ".", "clone", "(", ")", ",", "\n", "log_prob", ".", "item", "(", ")", "\n", ")", "\n", "", "else", ":", "\n", "                                ", "next_sent_beam", ".", "append", "(", "(", "word_id", ",", "beam_id", ",", "log_prob", ")", ")", "\n", "", "if", "len", "(", "next_sent_beam", ")", "==", "self", ".", "beam_size", ":", "\n", "                                ", "break", "\n", "", "", "assert", "len", "(", "next_sent_beam", ")", "==", "self", ".", "beam_size", "\n", "next_batch_beam", ".", "extend", "(", "next_sent_beam", ")", "\n", "", "state_predicted_classes", "=", "torch", ".", "tensor", "(", "[", "x", "[", "0", "]", "for", "x", "in", "next_batch_beam", "]", ",", "\n", "device", "=", "device", ")", ".", "reshape", "(", "batch_size", ",", "self", ".", "beam_size", ")", "\n", "state_beam_indices", "=", "torch", ".", "tensor", "(", "[", "x", "[", "1", "]", "for", "x", "in", "next_batch_beam", "]", ",", "\n", "device", "=", "device", ")", ".", "reshape", "(", "batch_size", ",", "self", ".", "beam_size", ")", "\n", "state_beam_log_probs", "=", "torch", ".", "tensor", "(", "[", "x", "[", "2", "]", "for", "x", "in", "next_batch_beam", "]", ",", "\n", "device", "=", "device", ")", ".", "reshape", "(", "batch_size", ",", "self", ".", "beam_size", ")", "\n", "\n", "", "restricted_predicted_classes", "[", ":", ",", "i", ",", ":", "]", "=", "state_predicted_classes", "\n", "restricted_beam_indices", "[", ":", ",", "i", ",", ":", "]", "=", "state_beam_indices", "\n", "restricted_beam_log_probs", "[", ":", ",", "i", ",", ":", "]", "=", "state_beam_log_probs", "\n", "\n", "", "restricted_predicted_classes", "=", "restricted_predicted_classes", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "predictions", ".", "append", "(", "restricted_predicted_classes", ")", "\n", "\n", "backpointer", "=", "restricted_beam_indices", "//", "self", ".", "per_node_beam_size", "\n", "backpointers", ".", "append", "(", "backpointer", ".", "view", "(", "batch_size", ",", "-", "1", ")", ")", "\n", "\n", "last_log_probabilities", "=", "restricted_beam_log_probs", ".", "view", "(", "batch_size", ",", "num_fsm_states", ",", "-", "1", ")", "\n", "\n", "def", "track_back_state", "(", "state_tensor", ")", ":", "\n", "                ", "_", ",", "*", "last_dims", "=", "state_tensor", ".", "size", "(", ")", "\n", "# shape: (batch_size, beam_size, *)", "\n", "expanded_backpointer", "=", "backpointer", ".", "view", "(", "\n", "batch_size", ",", "num_fsm_states", "*", "self", ".", "beam_size", ",", "*", "(", "[", "1", "]", "*", "len", "(", "last_dims", ")", ")", "\n", ")", ".", "expand", "(", "batch_size", ",", "num_fsm_states", "*", "self", ".", "beam_size", ",", "*", "last_dims", ")", "\n", "\n", "# shape: (batch_size * beam_size, *)", "\n", "return", "(", "\n", "state_tensor", ".", "reshape", "(", "batch_size", ",", "num_fsm_states", "*", "self", ".", "beam_size", ",", "*", "last_dims", ")", "\n", ".", "gather", "(", "1", ",", "expanded_backpointer", ")", "\n", ".", "reshape", "(", "batch_size", "*", "num_fsm_states", "*", "self", ".", "beam_size", ",", "*", "last_dims", ")", "\n", ")", "\n", "# reorder states", "\n", "", "if", "state", "is", "not", "None", ":", "\n", "                ", "state", "=", "tuple", "(", "track_back_state", "(", "value", ")", "for", "value", "in", "state", ")", "\n", "", "curr_ids", "=", "track_back_state", "(", "curr_ids", ")", "\n", "\n", "", "last_predictions", "=", "predictions", "[", "-", "1", "]", ".", "reshape", "(", "\n", "batch_size", "*", "self", ".", "beam_size", "*", "num_fsm_states", "\n", ")", "\n", "curr_ids", "=", "torch", ".", "cat", "(", "[", "curr_ids", ",", "last_predictions", ".", "unsqueeze", "(", "-", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "# Reconstruct the sequences.", "\n", "# shape: [(batch_size, beam_size, 1)]", "\n", "reconstructed_predictions", "=", "[", "predictions", "[", "-", "1", "]", ".", "unsqueeze", "(", "2", ")", "]", "\n", "\n", "# shape: (batch_size, beam_size)", "\n", "cur_backpointers", "=", "backpointers", "[", "-", "1", "]", "\n", "\n", "for", "timestep", "in", "range", "(", "len", "(", "predictions", ")", "-", "2", ",", "0", ",", "-", "1", ")", ":", "\n", "# shape: (batch_size, beam_size, 1)", "\n", "            ", "cur_preds", "=", "predictions", "[", "timestep", "]", ".", "gather", "(", "1", ",", "cur_backpointers", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "reconstructed_predictions", ".", "append", "(", "cur_preds", ")", "\n", "\n", "# shape: (batch_size, beam_size)", "\n", "cur_backpointers", "=", "backpointers", "[", "timestep", "-", "1", "]", ".", "gather", "(", "1", ",", "cur_backpointers", ")", "\n", "\n", "# shape: (batch_size, beam_size, 1)", "\n", "", "final_preds", "=", "predictions", "[", "0", "]", ".", "gather", "(", "1", ",", "cur_backpointers", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "reconstructed_predictions", ".", "append", "(", "final_preds", ")", "\n", "\n", "# shape: (batch_size, beam_size, max_steps)", "\n", "all_predictions", "=", "torch", ".", "cat", "(", "list", "(", "reversed", "(", "reconstructed_predictions", ")", ")", ",", "2", ")", "\n", "all_predictions", "=", "all_predictions", ".", "view", "(", "batch_size", ",", "num_fsm_states", ",", "self", ".", "beam_size", ",", "-", "1", ")", "\n", "assert", "(", "all_predictions", "==", "curr_ids", ".", "reshape", "(", "batch_size", ",", "num_fsm_states", ",", "\n", "self", ".", "beam_size", ",", "-", "1", ")", "[", ":", ",", ":", ",", ":", ",", "1", ":", "]", ")", ".", "all", "(", ")", "\n", "\n", "if", "self", ".", "use_hypo", ":", "\n", "            ", "decoded", "=", "all_predictions", ".", "new", "(", "batch_size", ",", "num_fsm_states", ",", "1", ",", "\n", "self", ".", "max_steps", ")", ".", "fill_", "(", "self", ".", "_eos_token_ids", "[", "0", "]", ")", "\n", "scores", "=", "last_log_probabilities", ".", "new", "(", "batch_size", ",", "num_fsm_states", ",", "\n", "1", ")", ".", "fill_", "(", "-", "1e5", ")", "\n", "for", "batch_ex", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "num_fsm_states", ")", ":", "\n", "                    ", "beam", "=", "all_predictions", "[", "batch_ex", ",", "i", ",", "0", ",", ":", "]", "\n", "log_prob", "=", "last_log_probabilities", "[", "batch_ex", ",", "i", ",", "0", "]", "\n", "generated_hyps", "[", "batch_ex", "]", "[", "i", "]", ".", "add", "(", "\n", "beam", ".", "clone", "(", ")", ",", "\n", "log_prob", ".", "item", "(", ")", "\n", ")", "\n", "hyps", "=", "generated_hyps", "[", "batch_ex", "]", "[", "i", "]", ".", "hyp", "\n", "assert", "len", "(", "hyps", ")", "==", "1", "\n", "score", ",", "sent", "=", "hyps", "[", "0", "]", "\n", "decoded", "[", "batch_ex", ",", "i", ",", "0", ",", ":", "len", "(", "sent", ")", "]", "=", "sent", "\n", "scores", "[", "batch_ex", ",", "i", ",", "0", "]", "=", "score", "\n", "", "", "all_predictions", "=", "decoded", "\n", "last_log_probabilities", "=", "scores", "\n", "\n", "# pad to the same length, otherwise DataParallel will give error", "\n", "", "pad_len", "=", "self", ".", "max_steps", "-", "all_predictions", ".", "shape", "[", "-", "1", "]", "\n", "if", "pad_len", ">", "0", ":", "\n", "            ", "padding_ids", "=", "all_predictions", ".", "new", "(", "\n", "batch_size", ",", "num_fsm_states", ",", "self", ".", "beam_size", ",", "\n", "pad_len", ")", ".", "fill_", "(", "self", ".", "_eos_token_ids", "[", "0", "]", ")", "\n", "all_predictions", "=", "torch", ".", "cat", "(", "[", "all_predictions", ",", "padding_ids", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "return", "all_predictions", ",", "last_log_probabilities", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.ConstraintBoxesReader.__init__": [[449, 464], ["open", "line.strip().split", "json.loads", "numpy.array", "numpy.array", "numpy.array.append", "class_names.append", "numpy.array.append", "line.strip", "box[].lower"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "boxes_tsvpath", ")", ":", "\n", "        ", "self", ".", "_image_key_to_boxes", "=", "{", "}", "\n", "with", "open", "(", "boxes_tsvpath", ",", "'r'", ")", "as", "fp", ":", "\n", "            ", "for", "line", "in", "fp", ":", "\n", "                ", "parts", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "img_key", "=", "parts", "[", "0", "]", "\n", "labels", "=", "json", ".", "loads", "(", "parts", "[", "1", "]", ")", "\n", "boxes", ",", "class_names", ",", "scores", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "box", "in", "labels", ":", "\n", "                    ", "boxes", ".", "append", "(", "box", "[", "'rect'", "]", ")", "\n", "class_names", ".", "append", "(", "box", "[", "'class'", "]", ".", "lower", "(", ")", ")", "\n", "scores", ".", "append", "(", "box", "[", "'conf'", "]", ")", "\n", "", "boxes", "=", "np", ".", "array", "(", "boxes", ")", "\n", "scores", "=", "np", ".", "array", "(", "scores", ")", "\n", "self", ".", "_image_key_to_boxes", "[", "img_key", "]", "=", "{", "\"boxes\"", ":", "boxes", ",", "\"class_names\"", ":", "class_names", ",", "\"scores\"", ":", "scores", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.ConstraintBoxesReader.__len__": [[465, 467], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_image_key_to_boxes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.ConstraintBoxesReader.__getitem__": [[468, 475], ["numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "image_key", ")", ":", "\n", "# Some images may not have any boxes, handle that case too.", "\n", "        ", "if", "image_key", "not", "in", "self", ".", "_image_key_to_boxes", ":", "\n", "            ", "return", "{", "\"boxes\"", ":", "np", ".", "array", "(", "[", "]", ")", ",", "\"class_names\"", ":", "[", "]", ",", "\"scores\"", ":", "\n", "np", ".", "array", "(", "[", "]", ")", "}", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_image_key_to_boxes", "[", "image_key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.ConstraintFilter.__init__": [[526, 544], ["cbs.ConstraintFilter.__init__.__read_hierarchy"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "hierarchy_jsonpath", ",", "nms_threshold", ",", "max_given_constraints", "\n", ")", ":", "\n", "        ", "def", "__read_hierarchy", "(", "node", ",", "parent", "=", "None", ")", ":", "\n", "# Cast an ``anytree.AnyNode`` (after first level of recursion) to dict.", "\n", "            ", "attributes", "=", "dict", "(", "node", ")", "\n", "children", "=", "attributes", ".", "pop", "(", "\"Subcategory\"", ",", "[", "]", ")", "\n", "\n", "node", "=", "anytree", ".", "AnyNode", "(", "parent", "=", "parent", ",", "**", "attributes", ")", "\n", "for", "child", "in", "children", ":", "\n", "                ", "__read_hierarchy", "(", "child", ",", "parent", "=", "node", ")", "\n", "", "return", "node", "\n", "\n", "# Read the object class hierarchy as a tree, to make searching easier.", "\n", "", "self", ".", "_hierarchy", "=", "__read_hierarchy", "(", "json", ".", "load", "(", "open", "(", "hierarchy_jsonpath", ")", ")", ")", "\n", "\n", "self", ".", "_nms_threshold", "=", "nms_threshold", "\n", "self", ".", "_max_given_constraints", "=", "max_given_constraints", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.ConstraintFilter.__call__": [[545, 575], ["range", "cbs.ConstraintFilter._nms", "sorted", "list", "len", "list", "cbs.ConstraintFilter.REPLACEMENTS.get", "set", "cbs.ConstraintFilter.append", "zip"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.ConstraintFilter._nms"], ["", "def", "__call__", "(", "self", ",", "boxes", ":", "np", ".", "ndarray", ",", "class_names", ":", "List", "[", "str", "]", ",", "scores", ":", "np", ".", "ndarray", ")", "->", "List", "[", "str", "]", ":", "\n", "\n", "# Remove padding boxes (which have prediction confidence score = 0), and remove boxes", "\n", "# corresponding to all blacklisted classes. These will never become CBS constraints.", "\n", "        ", "keep_indices", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "class_names", ")", ")", ":", "\n", "            ", "if", "scores", "[", "i", "]", ">", "0", "and", "class_names", "[", "i", "]", "not", "in", "self", ".", "BLACKLIST", ":", "\n", "                ", "keep_indices", ".", "append", "(", "i", ")", "\n", "\n", "", "", "boxes", "=", "boxes", "[", "keep_indices", "]", "\n", "class_names", "=", "[", "class_names", "[", "i", "]", "for", "i", "in", "keep_indices", "]", "\n", "scores", "=", "scores", "[", "keep_indices", "]", "\n", "\n", "# Perform non-maximum suppression according to category hierarchy. For example, for highly", "\n", "# overlapping boxes on a dog, \"dog\" suppresses \"animal\".", "\n", "keep_indices", "=", "self", ".", "_nms", "(", "boxes", ",", "class_names", ")", "\n", "boxes", "=", "boxes", "[", "keep_indices", "]", "\n", "class_names", "=", "[", "class_names", "[", "i", "]", "for", "i", "in", "keep_indices", "]", "\n", "scores", "=", "scores", "[", "keep_indices", "]", "\n", "\n", "# Retain top-k constraints based on prediction confidence score.", "\n", "class_names_and_scores", "=", "sorted", "(", "list", "(", "zip", "(", "class_names", ",", "scores", ")", ")", ",", "key", "=", "lambda", "t", ":", "-", "t", "[", "1", "]", ")", "\n", "class_names_and_scores", "=", "class_names_and_scores", "[", ":", "self", ".", "_max_given_constraints", "]", "\n", "\n", "# Replace class name according to ``self.REPLACEMENTS``.", "\n", "class_names", "=", "[", "self", ".", "REPLACEMENTS", ".", "get", "(", "t", "[", "0", "]", ",", "t", "[", "0", "]", ")", "for", "t", "in", "class_names_and_scores", "]", "\n", "\n", "# Drop duplicates.", "\n", "class_names", "=", "list", "(", "set", "(", "class_names", ")", ")", "\n", "return", "class_names", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.ConstraintFilter._nms": [[576, 629], ["numpy.array", "numpy.array.argsort", "len", "keep_box_indices.append", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.logical_or", "numpy.maximum", "numpy.maximum", "anytree.search.findall", "numpy.where", "node.LabelName.lower"], "methods", ["None"], ["", "def", "_nms", "(", "self", ",", "boxes", ":", "np", ".", "ndarray", ",", "class_names", ":", "List", "[", "str", "]", ")", ":", "\n", "        ", "if", "len", "(", "class_names", ")", "==", "0", ":", "\n", "            ", "return", "[", "]", "\n", "\n", "# For object class, get the height of its corresponding node in the hierarchy tree.", "\n", "# Less height => finer-grained class name => higher score.", "\n", "", "heights", "=", "np", ".", "array", "(", "\n", "[", "\n", "anytree", ".", "search", ".", "findall", "(", "self", ".", "_hierarchy", ",", "lambda", "node", ":", "node", ".", "LabelName", ".", "lower", "(", ")", "in", "c", ")", "[", "0", "]", ".", "height", "\n", "for", "c", "in", "class_names", "\n", "]", "\n", ")", "\n", "# Get a sorting of the heights in ascending order, i.e. higher scores first.", "\n", "score_order", "=", "heights", ".", "argsort", "(", ")", "\n", "\n", "# Compute areas for calculating intersection over union. Add 1 to avoid division by zero", "\n", "# for zero area (padding/dummy) boxes.", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "boxes", "[", ":", ",", "0", "]", ",", "boxes", "[", ":", ",", "1", "]", ",", "boxes", "[", ":", ",", "2", "]", ",", "boxes", "[", ":", ",", "3", "]", "\n", "areas", "=", "(", "x2", "-", "x1", "+", "1", ")", "*", "(", "y2", "-", "y1", "+", "1", ")", "\n", "\n", "# Fill \"keep_boxes\" with indices of boxes to keep, move from left to right in", "\n", "# ``score_order``, keep current box index (score_order[0]) and suppress (discard) other", "\n", "# indices of boxes having lower IoU threshold with current box from ``score_order``.", "\n", "# list. Note the order is a sorting of indices according to scores.", "\n", "keep_box_indices", "=", "[", "]", "\n", "\n", "while", "score_order", ".", "size", ">", "0", ":", "\n", "# Keep the index of box under consideration.", "\n", "            ", "current_index", "=", "score_order", "[", "0", "]", "\n", "keep_box_indices", ".", "append", "(", "current_index", ")", "\n", "\n", "# For the box we just decided to keep (score_order[0]), compute its IoU with other", "\n", "# boxes (score_order[1:]).", "\n", "xx1", "=", "np", ".", "maximum", "(", "x1", "[", "score_order", "[", "0", "]", "]", ",", "x1", "[", "score_order", "[", "1", ":", "]", "]", ")", "\n", "yy1", "=", "np", ".", "maximum", "(", "y1", "[", "score_order", "[", "0", "]", "]", ",", "y1", "[", "score_order", "[", "1", ":", "]", "]", ")", "\n", "xx2", "=", "np", ".", "minimum", "(", "x2", "[", "score_order", "[", "0", "]", "]", ",", "x2", "[", "score_order", "[", "1", ":", "]", "]", ")", "\n", "yy2", "=", "np", ".", "minimum", "(", "y2", "[", "score_order", "[", "0", "]", "]", ",", "y2", "[", "score_order", "[", "1", ":", "]", "]", ")", "\n", "\n", "intersection", "=", "np", ".", "maximum", "(", "0.0", ",", "xx2", "-", "xx1", "+", "1", ")", "*", "np", ".", "maximum", "(", "0.0", ",", "yy2", "-", "yy1", "+", "1", ")", "\n", "union", "=", "areas", "[", "score_order", "[", "0", "]", "]", "+", "areas", "[", "score_order", "[", "1", ":", "]", "]", "-", "intersection", "\n", "\n", "# Perform NMS for IoU >= 0.85. Check score, boxes corresponding to object", "\n", "# classes with smaller/equal height in hierarchy cannot be suppressed.", "\n", "keep_condition", "=", "np", ".", "logical_or", "(", "\n", "heights", "[", "score_order", "[", "1", ":", "]", "]", ">=", "heights", "[", "score_order", "[", "0", "]", "]", ",", "\n", "intersection", "/", "union", "<=", "self", ".", "_nms_threshold", ",", "\n", ")", "\n", "\n", "# Only keep the boxes under consideration for next iteration.", "\n", "score_order", "=", "score_order", "[", "1", ":", "]", "\n", "score_order", "=", "score_order", "[", "np", ".", "where", "(", "keep_condition", ")", "[", "0", "]", "]", "\n", "\n", "", "return", "keep_box_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.FiniteStateMachineBuilder.__init__": [[700, 717], ["cbs.load_wordforms", "cbs.load_wordforms"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.load_wordforms", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.load_wordforms"], ["def", "__init__", "(", "\n", "self", ",", "\n", "tokenizer", ",", "\n", "constraint2tokens_tsvpath", ",", "\n", "tokenforms_tsvpath", ",", "\n", "max_given_constraints", ",", "\n", "max_words_per_constraint", "=", "4", ",", "\n", ")", ":", "\n", "        ", "self", ".", "_tokenizer", "=", "tokenizer", "\n", "self", ".", "_max_given_constraints", "=", "max_given_constraints", "\n", "self", ".", "_max_words_per_constraint", "=", "max_words_per_constraint", "\n", "\n", "self", ".", "_num_main_states", "=", "2", "**", "max_given_constraints", "\n", "self", ".", "_num_total_states", "=", "self", ".", "_num_main_states", "*", "max_words_per_constraint", "\n", "\n", "self", ".", "_wordforms", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "load_wordforms", "(", "tokenforms_tsvpath", ")", "\n", "self", ".", "_constraint2tokens", "=", "load_wordforms", "(", "constraint2tokens_tsvpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.FiniteStateMachineBuilder.build": [[718, 747], ["torch.zeros", "fsm.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "enumerate", "len", "cbs.FiniteStateMachineBuilder._add_nth_constraint", "fsm.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "range", "range"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.FiniteStateMachineBuilder._add_nth_constraint"], ["", "def", "build", "(", "self", ",", "constraints", ":", "List", "[", "str", "]", ")", ":", "\n", "        ", "r\"\"\"\n        Build a finite state machine given a list of constraints.\n\n        Parameters\n        ----------\n        constraints: List[str]\n            A list of up to three (possibly) multi-word constraints, in our use-case these are\n            Open Images object class names.\n\n        Returns\n        -------\n        Tuple[torch.Tensor, int]\n            A finite state machine as an adjacency matrix, index of the next available unused\n            sub-state. This is later used to trim the unused sub-states from FSM.\n        \"\"\"", "\n", "assert", "len", "(", "constraints", ")", "<=", "self", ".", "_max_given_constraints", "\n", "fsm", "=", "torch", ".", "zeros", "(", "self", ".", "_num_total_states", ",", "self", ".", "_num_total_states", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n", "# Self loops for all words on main states.", "\n", "fsm", "[", "range", "(", "self", ".", "_num_main_states", ")", ",", "range", "(", "self", ".", "_num_main_states", ")", "]", "=", "1", "\n", "\n", "fsm", "=", "fsm", ".", "unsqueeze", "(", "-", "1", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "_tokenizer", ".", "vocab_size", ")", "\n", "\n", "substate_idx", "=", "self", ".", "_num_main_states", "\n", "for", "i", ",", "constraint", "in", "enumerate", "(", "constraints", ")", ":", "\n", "            ", "fsm", ",", "substate_idx", "=", "self", ".", "_add_nth_constraint", "(", "fsm", ",", "i", "+", "1", ",", "substate_idx", ",", "constraint", ")", "\n", "\n", "", "return", "fsm", ",", "substate_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.FiniteStateMachineBuilder._add_nth_constraint": [[748, 806], ["constraint.split", "words.extend", "len", "range", "enumerate", "cbs.FiniteStateMachineBuilder._connect", "cbs.FiniteStateMachineBuilder._connect", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.FiniteStateMachineBuilder._connect", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.FiniteStateMachineBuilder._connect"], ["", "def", "_add_nth_constraint", "(", "self", ",", "fsm", ":", "torch", ".", "Tensor", ",", "n", ":", "int", ",", "substate_idx", ":", "int", ",", "constraint", ":", "str", ")", ":", "\n", "        ", "r\"\"\"\n        Given an (incomplete) FSM matrix with transitions for \"(n - 1)\" constraints added, add\n        all transitions for the \"n-th\" constraint.\n\n        Parameters\n        ----------\n        fsm: torch.Tensor\n            A tensor of shape ``(num_total_states, num_total_states, vocab_size)`` representing an\n            FSM under construction.\n        n: int\n            The cardinality of constraint to be added. Goes as 1, 2, 3... (not zero-indexed).\n        substate_idx: int\n            An index which points to the next unused position for a sub-state. It starts with\n            ``(2 ** num_main_states)`` and increases according to the number of multi-word\n            constraints added so far. The calling method, :meth:`build` keeps track of this.\n        constraint: str\n            A (possibly) multi-word constraint, in our use-case it is an Open Images object class\n            name.\n\n        Returns\n        -------\n        Tuple[torch.Tensor, int]\n            FSM with added connections for the constraint and updated ``substate_idx`` pointing to\n            the next unused sub-state.\n        \"\"\"", "\n", "#words = constraint.split()", "\n", "words", "=", "[", "]", "\n", "for", "w", "in", "constraint", ".", "split", "(", ")", ":", "\n", "            ", "words", ".", "extend", "(", "self", ".", "_constraint2tokens", "[", "w", "]", ")", "\n", "#TODO: set max_words_per_constraint", "\n", "#assert len(words) <= self._max_words_per_constraint", "\n", "", "if", "len", "(", "words", ")", ">", "self", ".", "_max_words_per_constraint", ":", "\n", "            ", "words", "=", "words", "[", ":", "self", ".", "_max_words_per_constraint", "]", "\n", "", "connection_stride", "=", "2", "**", "(", "n", "-", "1", ")", "\n", "\n", "from_state", "=", "0", "\n", "while", "from_state", "<", "self", ".", "_num_main_states", ":", "\n", "            ", "for", "_", "in", "range", "(", "connection_stride", ")", ":", "\n", "                ", "word_from_state", "=", "from_state", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "# fmt: off", "\n", "# Connect to a sub-state for all tokens in multi-word constraint except last.", "\n", "                    ", "if", "i", "!=", "len", "(", "words", ")", "-", "1", ":", "\n", "                        ", "fsm", "=", "self", ".", "_connect", "(", "\n", "fsm", ",", "word_from_state", ",", "substate_idx", ",", "word", ",", "reset_state", "=", "from_state", "\n", ")", "\n", "word_from_state", "=", "substate_idx", "\n", "substate_idx", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "fsm", "=", "self", ".", "_connect", "(", "\n", "fsm", ",", "word_from_state", ",", "from_state", "+", "connection_stride", ",", "word", ",", "\n", "reset_state", "=", "from_state", ",", "\n", ")", "\n", "# fmt: on", "\n", "", "", "from_state", "+=", "1", "\n", "", "from_state", "+=", "connection_stride", "\n", "", "return", "fsm", ",", "substate_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.FiniteStateMachineBuilder._connect": [[807, 857], ["cbs.FiniteStateMachineBuilder._wordforms.get", "cbs.FiniteStateMachineBuilder._tokenizer.convert_tokens_to_ids"], "methods", ["None"], ["", "def", "_connect", "(", "\n", "self", ",", "fsm", ":", "torch", ".", "Tensor", ",", "from_state", ":", "int", ",", "to_state", ":", "int", ",", "word", ":", "str", ",", "reset_state", ":", "int", "=", "None", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        Add a connection between two states for a particular word (and all its word-forms). This\n        means removing self-loop from ``from_state`` for all word-forms of ``word`` and connecting\n        them to ``to_state``.\n        \n        Extended Summary\n        ----------------\n        In case of multi-word constraints, we return back to the ``reset_state`` for any utterance\n        other than ``word``, to satisfy a multi-word constraint if all words are decoded\n        consecutively. For example: for \"fire hydrant\" as a constraint between Q0 and Q1, we reach\n        a sub-state \"Q8\" on decoding \"fire\". Go back to main state \"Q1\" on decoding \"hydrant\"\n        immediately after, else we reset back to main state \"Q0\".\n\n        Parameters\n        ----------\n        fsm: torch.Tensor\n            A tensor of shape ``(num_total_states, num_total_states, vocab_size)`` representing an\n            FSM under construction.\n        from_state: int\n            Origin state to make a state transition.\n        to_state: int\n            Destination state to make a state transition.\n        word: str\n            The word which serves as a constraint for transition between given two states.\n        reset_state: int, optional (default = None)\n           State to reset otherwise. This is only valid if ``from_state`` is a sub-state.\n\n        Returns\n        -------\n        torch.Tensor\n            FSM with the added connection.\n        \"\"\"", "\n", "wordforms", "=", "self", ".", "_wordforms", ".", "get", "(", "word", ",", "[", "word", "]", ")", "\n", "#wordform_indices = [self._vocabulary.get_token_index(w) for w in wordforms]", "\n", "wordform_indices", "=", "self", ".", "_tokenizer", ".", "convert_tokens_to_ids", "(", "wordforms", ")", "\n", "\n", "for", "wordform_index", "in", "wordform_indices", ":", "\n", "            ", "fsm", "[", "from_state", ",", "to_state", ",", "wordform_index", "]", "=", "1", "\n", "fsm", "[", "from_state", ",", "from_state", ",", "wordform_index", "]", "=", "0", "\n", "\n", "", "if", "reset_state", "is", "not", "None", ":", "\n", "            ", "fsm", "[", "from_state", ",", "from_state", ",", ":", "]", "=", "0", "\n", "fsm", "[", "from_state", ",", "reset_state", ",", ":", "]", "=", "1", "\n", "for", "wordform_index", "in", "wordform_indices", ":", "\n", "                ", "fsm", "[", "from_state", ",", "reset_state", ",", "wordform_index", "]", "=", "0", "\n", "\n", "", "", "return", "fsm", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs._enlarge_single_tensor": [[20, 27], ["t.size", "t.view().expand().reshape", "t.view().expand", "t.view"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["def", "_enlarge_single_tensor", "(", "t", ",", "batch_size", ",", "num_fsm_states", ",", "beam_size", ")", ":", "\n", "# shape: (batch_size * beam_size, *)", "\n", "    ", "_", ",", "*", "last_dims", "=", "t", ".", "size", "(", ")", "\n", "return", "(", "\n", "t", ".", "view", "(", "batch_size", ",", "1", ",", "1", ",", "*", "last_dims", ")", "\n", ".", "expand", "(", "batch_size", ",", "num_fsm_states", ",", "beam_size", ",", "*", "last_dims", ")", "\n", ".", "reshape", "(", "-", "1", ",", "*", "last_dims", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.select_best_beam_with_constraints": [[366, 433], ["beams.size", "range", "torch.ones_like", "torch.argmax", "best_beams.append", "best_beam_log_probabilities.append", "torch.stack().long().to", "torch.stack().to", "valid_length.mul.mul", "valid_length.mul.sum", "range", "valid_beams.ne().long", "torch.stack().long", "torch.stack", "bin().count", "min", "given_constraints[].item", "valid_beams.ne", "torch.stack", "bin"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "", "def", "select_best_beam_with_constraints", "(", "\n", "beams", ":", "torch", ".", "Tensor", ",", "\n", "beam_log_probabilities", ":", "torch", ".", "Tensor", ",", "\n", "given_constraints", ":", "torch", ".", "Tensor", ",", "\n", "min_constraints_to_satisfy", ":", "int", ",", "\n", "eos_token_ids", ":", "List", "[", "int", "]", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "r\"\"\"\n    Select the best beam which satisfies specified minimum constraints out of a total number of\n    given constraints.\n\n    .. note::\n\n        The implementation of this function goes hand-in-hand with the FSM building implementation\n        in :meth:`~updown.utils.constraints.FiniteStateMachineBuilder.build` - it defines which\n        state satisfies which (basically, how many) constraints. If the \"definition\" of states\n        change, then selection of beams also changes accordingly.\n\n    Parameters\n    ----------\n    beams: torch.Tensor\n        A tensor of shape ``(batch_size, num_states, beam_size, max_decoding_steps)`` containing\n        decoded beams by :class:`~updown.modules.cbs.ConstrainedBeamSearch`. These beams are\n        sorted according to their likelihood (descending) in ``beam_size`` dimension.\n    beam_log_probabilities: torch.Tensor\n        A tensor of shape ``(batch_size, num_states, beam_size)`` containing likelihood of decoded\n        beams.\n    given_constraints: torch.Tensor\n        A tensor of shape ``(batch_size, )`` containing number of constraints given at the start\n        of decoding.\n    min_constraints_to_satisfy: int\n        Minimum number of constraints to satisfy. This is either 2, or ``given_constraints`` if\n        they are less than 2. Beams corresponding to states not satisfying at least these number\n        of constraints will be dropped. Only up to 3 supported.\n\n    Returns\n    -------\n    Tuple[torch.Tensor, torch.Tensor]\n        Decoded sequence (beam) which has highest likelihood among beams satisfying constraints.\n    \"\"\"", "\n", "batch_size", ",", "num_states", ",", "beam_size", ",", "max_decoding_steps", "=", "beams", ".", "size", "(", ")", "\n", "\n", "best_beams", ":", "List", "[", "torch", ".", "Tensor", "]", "=", "[", "]", "\n", "best_beam_log_probabilities", ":", "List", "[", "torch", ".", "Tensor", "]", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "# fmt: off", "\n", "        ", "valid_states", "=", "[", "\n", "s", "for", "s", "in", "range", "(", "2", "**", "given_constraints", "[", "i", "]", ".", "item", "(", ")", ")", "\n", "if", "bin", "(", "s", ")", ".", "count", "(", "\"1\"", ")", ">=", "min", "(", "given_constraints", "[", "i", "]", ",", "min_constraints_to_satisfy", ")", "\n", "]", "\n", "# fmt: on", "\n", "\n", "valid_beams", "=", "beams", "[", "i", ",", "valid_states", ",", "0", ",", ":", "]", "\n", "valid_length", "=", "torch", ".", "ones_like", "(", "valid_beams", ")", "\n", "for", "eos_token_id", "in", "eos_token_ids", ":", "\n", "            ", "valid_length", "=", "valid_length", ".", "mul", "(", "valid_beams", ".", "ne", "(", "eos_token_id", ")", ".", "long", "(", ")", ")", "\n", "", "valid_length", "=", "valid_length", ".", "sum", "(", "1", ")", "+", "1", "\n", "valid_beam_log_probabilities", "=", "beam_log_probabilities", "[", "i", ",", "valid_states", ",", "0", "]", "/", "valid_length", "\n", "\n", "selected_index", "=", "torch", ".", "argmax", "(", "valid_beam_log_probabilities", ")", "\n", "best_beams", ".", "append", "(", "valid_beams", "[", "selected_index", ",", ":", "]", ")", "\n", "best_beam_log_probabilities", ".", "append", "(", "valid_beam_log_probabilities", "[", "selected_index", "]", ")", "\n", "\n", "# shape: (batch_size, max_decoding_steps)", "\n", "", "return", "(", "torch", ".", "stack", "(", "best_beams", ")", ".", "long", "(", ")", ".", "to", "(", "beams", ".", "device", ")", ",", "\n", "torch", ".", "stack", "(", "best_beam_log_probabilities", ")", ".", "to", "(", "beams", ".", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.load_wordforms": [[435, 442], ["open", "line.strip().split", "parts[].split", "line.strip"], "function", ["None"], ["", "def", "load_wordforms", "(", "wordforms_tsvpath", ")", ":", "\n", "    ", "wordforms", "=", "{", "}", "\n", "with", "open", "(", "wordforms_tsvpath", ",", "\"r\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "parts", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "wordforms", "[", "parts", "[", "0", "]", "]", "=", "parts", "[", "1", "]", ".", "split", "(", "','", ")", "\n", "", "", "return", "wordforms", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file_ops.tsv_writer": [[12, 23], ["misc.mkdir", "os.rename", "os.rename", "os.path.dirname", "os.path.dirname", "open", "v.encode.encode", "fp.write", "sep.join", "map", "v.encode.decode", "str", "type"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.mkdir"], ["def", "tsv_writer", "(", "values", ",", "tsv_file_name", ",", "sep", "=", "'\\t'", ")", ":", "\n", "    ", "mkdir", "(", "os", ".", "path", ".", "dirname", "(", "tsv_file_name", ")", ")", "\n", "tsv_file_name_tmp", "=", "tsv_file_name", "+", "'.tmp'", "\n", "with", "open", "(", "tsv_file_name_tmp", ",", "'wb'", ")", "as", "fp", ":", "\n", "        ", "assert", "values", "is", "not", "None", "\n", "for", "value", "in", "values", ":", "\n", "            ", "assert", "value", "is", "not", "None", "\n", "v", "=", "sep", ".", "join", "(", "map", "(", "lambda", "v", ":", "v", ".", "decode", "(", ")", "if", "type", "(", "v", ")", "==", "bytes", "else", "str", "(", "v", ")", ",", "value", ")", ")", "+", "'\\n'", "\n", "v", "=", "v", ".", "encode", "(", ")", "\n", "fp", ".", "write", "(", "v", ")", "\n", "", "", "os", ".", "rename", "(", "tsv_file_name_tmp", ",", "tsv_file_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file_ops.concat_files": [[25, 32], ["os.rename", "os.rename", "open", "enumerate", "open", "shutil.copyfileobj"], "function", ["None"], ["", "def", "concat_files", "(", "ins", ",", "out", ")", ":", "\n", "    ", "out_tmp", "=", "out", "+", "'.tmp'", "\n", "with", "open", "(", "out_tmp", ",", "'wb'", ")", "as", "fp_out", ":", "\n", "        ", "for", "i", ",", "f", "in", "enumerate", "(", "ins", ")", ":", "\n", "            ", "with", "open", "(", "f", ",", "'rb'", ")", "as", "fp_in", ":", "\n", "                ", "shutil", ".", "copyfileobj", "(", "fp_in", ",", "fp_out", ",", "1024", "*", "1024", "*", "10", ")", "\n", "", "", "", "os", ".", "rename", "(", "out_tmp", ",", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file_ops.concat_tsv_files": [[34, 48], ["tsv_file_ops.concat_files", "numpy.cumsum", "enumerate", "tsv_file_ops.load_list_file", "open", "f.write", "os.stat", "os.stat", "all_idx.append", "all_idx.append", "os.splitext", "str", "os.splitext", "int"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file_ops.concat_files", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file_ops.load_list_file"], ["", "def", "concat_tsv_files", "(", "tsvs", ",", "out_tsv", ",", "generate_lineidx", "=", "False", ")", ":", "\n", "    ", "concat_files", "(", "tsvs", ",", "out_tsv", ")", "\n", "if", "generate_lineidx", ":", "\n", "        ", "sizes", "=", "[", "os", ".", "stat", "(", "t", ")", ".", "st_size", "for", "t", "in", "tsvs", "]", "\n", "sizes", "=", "np", ".", "cumsum", "(", "sizes", ")", "\n", "all_idx", "=", "[", "]", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "tsvs", ")", ":", "\n", "            ", "for", "idx", "in", "load_list_file", "(", "op", ".", "splitext", "(", "t", ")", "[", "0", "]", "+", "'.lineidx'", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "\n", "                    ", "all_idx", ".", "append", "(", "idx", ")", "\n", "", "else", ":", "\n", "                    ", "all_idx", ".", "append", "(", "str", "(", "int", "(", "idx", ")", "+", "sizes", "[", "i", "-", "1", "]", ")", ")", "\n", "", "", "", "with", "open", "(", "op", ".", "splitext", "(", "out_tsv", ")", "[", "0", "]", "+", "'.lineidx'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "'\\n'", ".", "join", "(", "all_idx", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file_ops.load_list_file": [[50, 57], ["open", "fp.readlines", "line.strip", "len"], "function", ["None"], ["", "", "", "def", "load_list_file", "(", "fname", ")", ":", "\n", "    ", "with", "open", "(", "fname", ",", "'r'", ")", "as", "fp", ":", "\n", "        ", "lines", "=", "fp", ".", "readlines", "(", ")", "\n", "", "result", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "lines", "]", "\n", "if", "len", "(", "result", ")", ">", "0", "and", "result", "[", "-", "1", "]", "==", "''", ":", "\n", "        ", "result", "=", "result", "[", ":", "-", "1", "]", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file_ops.reorder_tsv_keys": [[59, 68], ["tsv_file.TSVFile", "tsv_file_ops.tsv_writer", "tsv_file_ops.reorder_tsv_keys.gen_rows"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file_ops.tsv_writer"], ["", "def", "reorder_tsv_keys", "(", "in_tsv_file", ",", "ordered_keys", ",", "out_tsv_file", ")", ":", "\n", "    ", "tsv", "=", "TSVFile", "(", "in_tsv_file", ",", "generate_lineidx", "=", "True", ")", "\n", "keys", "=", "[", "tsv", ".", "seek", "(", "i", ")", "[", "0", "]", "for", "i", "in", "range", "(", "len", "(", "tsv", ")", ")", "]", "\n", "key_to_idx", "=", "{", "key", ":", "i", "for", "i", ",", "key", "in", "enumerate", "(", "keys", ")", "}", "\n", "def", "gen_rows", "(", ")", ":", "\n", "        ", "for", "key", "in", "ordered_keys", ":", "\n", "            ", "idx", "=", "key_to_idx", "[", "key", "]", "\n", "yield", "tsv", ".", "seek", "(", "idx", ")", "\n", "", "", "tsv_writer", "(", "gen_rows", "(", ")", ",", "out_tsv_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file_ops.delete_tsv_files": [[70, 77], ["os.isfile", "os.isfile", "tsv_file_ops.try_delete", "tsv_file_ops.try_delete", "os.splitext"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file_ops.try_delete", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file_ops.try_delete"], ["", "def", "delete_tsv_files", "(", "tsvs", ")", ":", "\n", "    ", "for", "t", "in", "tsvs", ":", "\n", "        ", "if", "op", ".", "isfile", "(", "t", ")", ":", "\n", "            ", "try_delete", "(", "t", ")", "\n", "", "line", "=", "op", ".", "splitext", "(", "t", ")", "[", "0", "]", "+", "'.lineidx'", "\n", "if", "op", ".", "isfile", "(", "line", ")", ":", "\n", "            ", "try_delete", "(", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file_ops.try_once": [[79, 86], ["func", "logging.info", "str"], "function", ["None"], ["", "", "", "def", "try_once", "(", "func", ")", ":", "\n", "    ", "def", "func_wrapper", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "logging", ".", "info", "(", "'ignore error \\n{}'", ".", "format", "(", "str", "(", "e", ")", ")", ")", "\n", "", "", "return", "func_wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file_ops.try_delete": [[88, 91], ["os.remove", "os.remove"], "function", ["None"], ["", "@", "try_once", "\n", "def", "try_delete", "(", "f", ")", ":", "\n", "    ", "os", ".", "remove", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.logger.FileHandler.__init__": [[17, 36], ["os.fspath", "os.path.abspath", "logging.Handler.__init__", "logging.StreamHandler.__init__", "logger.FileHandler._open"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.logger.FileHandler._open"], ["def", "__init__", "(", "self", ",", "filename", ",", "mode", "=", "'a'", ",", "encoding", "=", "None", ",", "delay", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Open the specified file and use it as the stream for logging.\n        \"\"\"", "\n", "# Issue #27493: add support for Path objects to be passed in", "\n", "filename", "=", "os", ".", "fspath", "(", "filename", ")", "\n", "#keep the absolute path, otherwise derived classes which use this", "\n", "#may come a cropper when the current directory changes", "\n", "self", ".", "baseFilename", "=", "os", ".", "path", ".", "abspath", "(", "filename", ")", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "encoding", "=", "encoding", "\n", "self", ".", "delay", "=", "delay", "\n", "if", "delay", ":", "\n", "#We don't open the stream, but we still need to call the", "\n", "#Handler constructor to set level, formatter, lock etc.", "\n", "            ", "Handler", ".", "__init__", "(", "self", ")", "\n", "self", ".", "stream", "=", "None", "\n", "", "else", ":", "\n", "            ", "StreamHandler", ".", "__init__", "(", "self", ",", "self", ".", "_open", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.logger.FileHandler.close": [[37, 58], ["logger.FileHandler.acquire", "logger.FileHandler.release", "logging.StreamHandler.close", "logger.FileHandler.flush", "hasattr", "stream.close"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.TensorboardLogger.close", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.TensorboardLogger.close"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Closes the stream.\n        \"\"\"", "\n", "self", ".", "acquire", "(", ")", "\n", "try", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "self", ".", "stream", ":", "\n", "                    ", "try", ":", "\n", "                        ", "self", ".", "flush", "(", ")", "\n", "", "finally", ":", "\n", "                        ", "stream", "=", "self", ".", "stream", "\n", "self", ".", "stream", "=", "None", "\n", "if", "hasattr", "(", "stream", ",", "\"close\"", ")", ":", "\n", "                            ", "stream", ".", "close", "(", ")", "\n", "", "", "", "", "finally", ":", "\n", "# Issue #19523: call unconditionally to", "\n", "# prevent a handler leak when delay is set", "\n", "                ", "StreamHandler", ".", "close", "(", "self", ")", "\n", "", "", "finally", ":", "\n", "            ", "self", ".", "release", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.logger.FileHandler._open": [[59, 65], ["open"], "methods", ["None"], ["", "", "def", "_open", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Open the current base file with the (original) mode and encoding.\n        Return the resulting stream.\n        \"\"\"", "\n", "return", "open", "(", "self", ".", "baseFilename", ",", "self", ".", "mode", ",", "encoding", "=", "self", ".", "encoding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.logger.FileHandler.emit": [[66, 77], ["logging.StreamHandler.emit", "logger.FileHandler.close", "logger.FileHandler._open"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.logger.FileHandler.emit", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.TensorboardLogger.close", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.logger.FileHandler._open"], ["", "def", "emit", "(", "self", ",", "record", ")", ":", "\n", "        ", "\"\"\"\n        Emit a record.\n\n        If the stream was not opened because 'delay' was specified in the\n        constructor, open it before calling the superclass's emit.\n        \"\"\"", "\n", "if", "self", ".", "stream", "is", "None", ":", "\n", "            ", "self", ".", "stream", "=", "self", ".", "_open", "(", ")", "\n", "", "StreamHandler", ".", "emit", "(", "self", ",", "record", ")", "\n", "self", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.logger.FileHandler.__repr__": [[78, 81], ["logging.getLevelName"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "level", "=", "getLevelName", "(", "self", ".", "level", ")", "\n", "return", "'<%s %s (%s)>'", "%", "(", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "baseFilename", ",", "level", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.logger.setup_logger": [[83, 102], ["logging.getLogger", "logging.getLogger.setLevel", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.Formatter", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "logger.FileHandler", "FileHandler.setLevel", "FileHandler.setFormatter", "logging.getLogger.addHandler", "os.path.join"], "function", ["None"], ["", "", "def", "setup_logger", "(", "name", ",", "save_dir", ",", "distributed_rank", ",", "filename", "=", "\"log.txt\"", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "name", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "# don't log results for the non-master process", "\n", "if", "distributed_rank", ">", "0", ":", "\n", "        ", "return", "logger", "\n", "", "ch", "=", "logging", ".", "StreamHandler", "(", "stream", "=", "sys", ".", "stdout", ")", "\n", "ch", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "\"%(asctime)s %(name)s %(levelname)s: %(message)s\"", ")", "\n", "ch", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", ".", "addHandler", "(", "ch", ")", "\n", "\n", "if", "save_dir", ":", "\n", "        ", "fh", "=", "FileHandler", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "filename", ")", ")", "\n", "fh", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "fh", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", ".", "addHandler", "(", "fh", ")", "\n", "\n", "", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.__init__": [[21, 32], ["tsv_file.generate_lineidx_file", "os.splitext", "os.splitext", "os.isfile", "os.isfile"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.generate_lineidx_file"], ["    ", "def", "__init__", "(", "self", ",", "tsv_file", ",", "generate_lineidx", "=", "False", ")", ":", "\n", "        ", "self", ".", "tsv_file", "=", "tsv_file", "\n", "self", ".", "lineidx", "=", "op", ".", "splitext", "(", "tsv_file", ")", "[", "0", "]", "+", "'.lineidx'", "\n", "self", ".", "_fp", "=", "None", "\n", "self", ".", "_lineidx", "=", "None", "\n", "# the process always keeps the process which opens the file. ", "\n", "# If the pid is not equal to the currrent pid, we will re-open the file.", "\n", "self", ".", "pid", "=", "None", "\n", "# generate lineidx if not exist", "\n", "if", "not", "op", ".", "isfile", "(", "self", ".", "lineidx", ")", "and", "generate_lineidx", ":", "\n", "            ", "generate_lineidx_file", "(", "self", ".", "tsv_file", ",", "self", ".", "lineidx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.__del__": [[33, 36], ["tsv_file.TSVFile._fp.close"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.TensorboardLogger.close"], ["", "", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_fp", ":", "\n", "            ", "self", ".", "_fp", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.__str__": [[37, 39], ["None"], "methods", ["None"], ["", "", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"TSVFile(tsv_file='{}')\"", ".", "format", "(", "self", ".", "tsv_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.__repr__": [[40, 42], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.num_rows": [[43, 46], ["tsv_file.TSVFile._ensure_lineidx_loaded", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile._ensure_lineidx_loaded"], ["", "def", "num_rows", "(", "self", ")", ":", "\n", "        ", "self", ".", "_ensure_lineidx_loaded", "(", ")", "\n", "return", "len", "(", "self", ".", "_lineidx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek": [[47, 57], ["tsv_file.TSVFile._ensure_tsv_opened", "tsv_file.TSVFile._ensure_lineidx_loaded", "tsv_file.TSVFile._fp.seek", "s.strip", "logging.info", "tsv_file.TSVFile._fp.readline().split", "tsv_file.TSVFile._fp.readline"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile._ensure_tsv_opened", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile._ensure_lineidx_loaded", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek"], ["", "def", "seek", "(", "self", ",", "idx", ")", ":", "\n", "        ", "self", ".", "_ensure_tsv_opened", "(", ")", "\n", "self", ".", "_ensure_lineidx_loaded", "(", ")", "\n", "try", ":", "\n", "            ", "pos", "=", "self", ".", "_lineidx", "[", "idx", "]", "\n", "", "except", ":", "\n", "            ", "logging", ".", "info", "(", "'{}-{}'", ".", "format", "(", "self", ".", "tsv_file", ",", "idx", ")", ")", "\n", "raise", "\n", "", "self", ".", "_fp", ".", "seek", "(", "pos", ")", "\n", "return", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "self", ".", "_fp", ".", "readline", "(", ")", ".", "split", "(", "'\\t'", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek_first_column": [[58, 64], ["tsv_file.TSVFile._ensure_tsv_opened", "tsv_file.TSVFile._ensure_lineidx_loaded", "tsv_file.TSVFile._fp.seek", "read_to_character"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile._ensure_tsv_opened", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile._ensure_lineidx_loaded", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek"], ["", "def", "seek_first_column", "(", "self", ",", "idx", ")", ":", "\n", "        ", "self", ".", "_ensure_tsv_opened", "(", ")", "\n", "self", ".", "_ensure_lineidx_loaded", "(", ")", "\n", "pos", "=", "self", ".", "_lineidx", "[", "idx", "]", "\n", "self", ".", "_fp", ".", "seek", "(", "pos", ")", "\n", "return", "read_to_character", "(", "self", ".", "_fp", ",", "'\\t'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.__getitem__": [[65, 67], ["tsv_file.TSVFile.seek"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "seek", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.__len__": [[68, 70], ["tsv_file.TSVFile.num_rows"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.num_rows"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_rows", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile._ensure_lineidx_loaded": [[71, 76], ["logging.info", "open", "int", "i.strip", "fp.readlines"], "methods", ["None"], ["", "def", "_ensure_lineidx_loaded", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_lineidx", "is", "None", ":", "\n", "            ", "logging", ".", "info", "(", "'loading lineidx: {}'", ".", "format", "(", "self", ".", "lineidx", ")", ")", "\n", "with", "open", "(", "self", ".", "lineidx", ",", "'r'", ")", "as", "fp", ":", "\n", "                ", "self", ".", "_lineidx", "=", "[", "int", "(", "i", ".", "strip", "(", ")", ")", "for", "i", "in", "fp", ".", "readlines", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile._ensure_tsv_opened": [[77, 86], ["open", "os.getpid", "os.getpid", "os.getpid", "os.getpid", "os.getpid", "os.getpid", "os.getpid", "os.getpid", "logging.info", "open", "os.getpid", "os.getpid", "os.getpid", "os.getpid"], "methods", ["None"], ["", "", "", "def", "_ensure_tsv_opened", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_fp", "is", "None", ":", "\n", "            ", "self", ".", "_fp", "=", "open", "(", "self", ".", "tsv_file", ",", "'r'", ")", "\n", "self", ".", "pid", "=", "os", ".", "getpid", "(", ")", "\n", "\n", "", "if", "self", ".", "pid", "!=", "os", ".", "getpid", "(", ")", ":", "\n", "            ", "logging", ".", "info", "(", "'re-open {} because the process id changed'", ".", "format", "(", "self", ".", "tsv_file", ")", ")", "\n", "self", ".", "_fp", "=", "open", "(", "self", ".", "tsv_file", ",", "'r'", ")", "\n", "self", ".", "pid", "=", "os", ".", "getpid", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.generate_lineidx_file": [[8, 18], ["os.rename", "os.rename", "open", "open", "os.fstat", "os.fstat", "tsvout.write", "tsvin.readline", "tsvin.tell", "tsvin.fileno", "str"], "function", ["None"], ["def", "generate_lineidx_file", "(", "filein", ",", "idxout", ")", ":", "\n", "    ", "idxout_tmp", "=", "idxout", "+", "'.tmp'", "\n", "with", "open", "(", "filein", ",", "'r'", ")", "as", "tsvin", ",", "open", "(", "idxout_tmp", ",", "'w'", ")", "as", "tsvout", ":", "\n", "        ", "fsize", "=", "os", ".", "fstat", "(", "tsvin", ".", "fileno", "(", ")", ")", ".", "st_size", "\n", "fpos", "=", "0", "\n", "while", "fpos", "!=", "fsize", ":", "\n", "            ", "tsvout", ".", "write", "(", "str", "(", "fpos", ")", "+", "\"\\n\"", ")", "\n", "tsvin", ".", "readline", "(", ")", "\n", "fpos", "=", "tsvin", ".", "tell", "(", ")", "\n", "", "", "os", ".", "rename", "(", "idxout_tmp", ",", "idxout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.SmoothedValue.__init__": [[16, 21], ["collections.deque"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "window_size", "=", "20", ")", ":", "\n", "        ", "self", ".", "deque", "=", "deque", "(", "maxlen", "=", "window_size", ")", "\n", "# self.series = []", "\n", "self", ".", "total", "=", "0.0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.SmoothedValue.update": [[22, 27], ["metric_logger.SmoothedValue.deque.append"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "deque", ".", "append", "(", "value", ")", "\n", "# self.series.append(value)", "\n", "self", ".", "count", "+=", "1", "\n", "self", ".", "total", "+=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.SmoothedValue.median": [[28, 32], ["torch.tensor", "torch.tensor.median().item", "list", "torch.tensor.median"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.SmoothedValue.median"], ["", "@", "property", "\n", "def", "median", "(", "self", ")", ":", "\n", "        ", "d", "=", "torch", ".", "tensor", "(", "list", "(", "self", ".", "deque", ")", ")", "\n", "return", "d", ".", "median", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.SmoothedValue.avg": [[33, 37], ["torch.tensor", "torch.tensor.mean().item", "list", "torch.tensor.mean"], "methods", ["None"], ["", "@", "property", "\n", "def", "avg", "(", "self", ")", ":", "\n", "        ", "d", "=", "torch", ".", "tensor", "(", "list", "(", "self", ".", "deque", ")", ")", "\n", "return", "d", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.SmoothedValue.global_avg": [[38, 41], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "global_avg", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "total", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.SmoothedValue.last_value": [[42, 45], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "last_value", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "deque", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.MetricLogger.__init__": [[48, 52], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "delimiter", "=", "\"\\t\"", ")", ":", "\n", "        ", "self", ".", "meters", "=", "{", "}", "\n", "self", ".", "params", "=", "{", "}", "\n", "self", ".", "delimiter", "=", "delimiter", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.MetricLogger.update_params": [[53, 65], ["update_dict.items", "group_dict.items", "param_name.startswith", "isinstance", "isinstance", "param_value.item.item.item"], "methods", ["None"], ["", "def", "update_params", "(", "self", ",", "update_dict", ")", ":", "\n", "        ", "for", "param_group", ",", "group_dict", "in", "update_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "param_group", "not", "in", "self", ".", "params", ":", "\n", "                ", "self", ".", "params", "[", "param_group", "]", "=", "{", "}", "\n", "", "for", "param_name", ",", "param_value", "in", "group_dict", ".", "items", "(", ")", ":", "\n", "# skipping parameters if they start with '_'", "\n", "                ", "if", "param_name", ".", "startswith", "(", "'_'", ")", ":", "\n", "                    ", "continue", "\n", "", "if", "isinstance", "(", "param_value", ",", "torch", ".", "Tensor", ")", ":", "\n", "                    ", "param_value", "=", "param_value", ".", "item", "(", ")", "\n", "", "assert", "isinstance", "(", "param_value", ",", "(", "float", ",", "int", ")", ")", "\n", "self", ".", "params", "[", "param_group", "]", "[", "param_name", "]", "=", "param_value", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.MetricLogger.update_metrics": [[66, 78], ["update_dict.items", "group_dict.items", "collections.defaultdict", "metric_name.startswith", "isinstance", "isinstance", "[].update", "metric_value.item.item.item"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.SmoothedValue.update"], ["", "", "", "def", "update_metrics", "(", "self", ",", "update_dict", ")", ":", "\n", "        ", "for", "metric_group", ",", "group_dict", "in", "update_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "metric_group", "not", "in", "self", ".", "meters", ":", "\n", "                ", "self", ".", "meters", "[", "metric_group", "]", "=", "defaultdict", "(", "SmoothedValue", ")", "\n", "", "for", "metric_name", ",", "metric_value", "in", "group_dict", ".", "items", "(", ")", ":", "\n", "# skipping metrics if they start with '_'", "\n", "                ", "if", "metric_name", ".", "startswith", "(", "'_'", ")", ":", "\n", "                    ", "continue", "\n", "", "if", "isinstance", "(", "metric_value", ",", "torch", ".", "Tensor", ")", ":", "\n", "                    ", "metric_value", "=", "metric_value", ".", "item", "(", ")", "\n", "", "assert", "isinstance", "(", "metric_value", ",", "(", "float", ",", "int", ")", ")", "\n", "self", ".", "meters", "[", "metric_group", "]", "[", "metric_name", "]", ".", "update", "(", "metric_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.MetricLogger.get_logs": [[79, 113], ["max", "sorted", "metric_logger.MetricLogger.params.items", "len", "max", "len", "max", "metric_logger.MetricLogger.meters.items", "values.items", "return_str.append", "values.items", "return_str.append", "loss_str.append", "loss_str.append", "len", "len", "metric_logger.MetricLogger.delimiter.join", "metric_logger.MetricLogger.delimiter.join", "metric_logger.MetricLogger.meters.keys", "metric_logger.MetricLogger.params.keys"], "methods", ["None"], ["", "", "", "def", "get_logs", "(", "self", ",", "iteration", ")", ":", "\n", "        ", "return_str", "=", "[", "]", "\n", "if", "len", "(", "self", ".", "meters", ")", ">", "0", ":", "\n", "            ", "offset_m", "=", "max", "(", "[", "len", "(", "group_name", ")", "for", "group_name", "in", "self", ".", "meters", ".", "keys", "(", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "offset_m", "=", "0", "\n", "", "if", "len", "(", "self", ".", "params", ")", ">", "0", ":", "\n", "            ", "offset_p", "=", "max", "(", "[", "len", "(", "group_name", ")", "for", "group_name", "in", "self", ".", "params", ".", "keys", "(", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "offset_p", "=", "0", "\n", "", "offset", "=", "max", "(", "offset_m", ",", "offset_p", ")", "\n", "\n", "for", "group_name", ",", "values", "in", "sorted", "(", "self", ".", "meters", ".", "items", "(", ")", ",", "\n", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", ":", "\n", "            ", "loss_str", "=", "[", "]", "\n", "for", "name", ",", "meter", "in", "values", ".", "items", "(", ")", ":", "\n", "                ", "loss_str", ".", "append", "(", "\"{}: {:.4f} ({:.4f})\"", ".", "format", "(", "\n", "name", ",", "meter", ".", "median", ",", "meter", ".", "global_avg", ",", "\n", ")", ")", "\n", "", "return_str", ".", "append", "(", "\n", "\"{:{offset}s} - {}\"", ".", "format", "(", "\n", "group_name", ",", "self", ".", "delimiter", ".", "join", "(", "loss_str", ")", ",", "offset", "=", "offset", ",", "\n", ")", ",", "\n", ")", "\n", "", "for", "group_name", ",", "values", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "            ", "loss_str", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "values", ".", "items", "(", ")", ":", "\n", "                ", "loss_str", ".", "append", "(", "\"{}: {:.6f}\"", ".", "format", "(", "name", ",", "param", ")", ")", "\n", "", "return_str", ".", "append", "(", "\n", "\"{:{offset}s} - {}\"", ".", "format", "(", "\n", "group_name", ",", "self", ".", "delimiter", ".", "join", "(", "loss_str", ")", ",", "offset", "=", "offset", ",", "\n", ")", ",", "\n", ")", "\n", "", "return", "\"\\n    \"", ".", "join", "(", "return_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.TensorboardLogger.__init__": [[116, 138], ["metric_logger.MetricLogger.__init__", "misc.is_main_process", "SummaryWriter", "SummaryWriter", "SummaryWriter", "ImportError", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.is_main_process"], ["    ", "def", "__init__", "(", "self", ",", "\n", "log_dir", ",", "\n", "delimiter", "=", "'\\t'", ")", ":", "\n", "        ", "super", "(", "TensorboardLogger", ",", "self", ")", ".", "__init__", "(", "delimiter", ")", "\n", "try", ":", "\n", "            ", "from", "tensorboardX", "import", "SummaryWriter", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "'To use tensorboard please install tensorboardX '", "\n", "'[ pip install tensorboardx ].'", "\n", ")", "\n", "", "self", ".", "philly_tb_logger", "=", "None", "\n", "self", ".", "philly_tb_logger_avg", "=", "None", "\n", "self", ".", "philly_tb_logger_med", "=", "None", "\n", "if", "is_main_process", "(", ")", ":", "\n", "            ", "self", ".", "tb_logger", "=", "SummaryWriter", "(", "log_dir", ")", "\n", "self", ".", "tb_logger_avg", "=", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "'avg'", ")", ")", "\n", "self", ".", "tb_logger_med", "=", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "'med'", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tb_logger", "=", "None", "\n", "self", ".", "tb_logger_avg", "=", "None", "\n", "self", ".", "tb_logger_med", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.TensorboardLogger.get_logs": [[139, 180], ["metric_logger.MetricLogger.get_logs", "metric_logger.TensorboardLogger.meters.items", "metric_logger.TensorboardLogger.params.items", "values.items", "values.items", "metric_logger.TensorboardLogger.tb_logger.add_scalar", "metric_logger.TensorboardLogger.tb_logger_avg.add_scalar", "metric_logger.TensorboardLogger.tb_logger_med.add_scalar", "metric_logger.TensorboardLogger.tb_logger.add_scalar", "metric_logger.TensorboardLogger.philly_tb_logger.add_scalar", "metric_logger.TensorboardLogger.philly_tb_logger_avg.add_scalar", "metric_logger.TensorboardLogger.philly_tb_logger_med.add_scalar", "metric_logger.TensorboardLogger.philly_tb_logger.add_scalar"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.TensorboardLogger.get_logs"], ["", "", "def", "get_logs", "(", "self", ",", "iteration", ")", ":", "\n", "        ", "if", "self", ".", "tb_logger", ":", "\n", "            ", "for", "group_name", ",", "values", "in", "self", ".", "meters", ".", "items", "(", ")", ":", "\n", "                ", "for", "name", ",", "meter", "in", "values", ".", "items", "(", ")", ":", "\n", "                    ", "self", ".", "tb_logger", ".", "add_scalar", "(", "\n", "'{}/{}'", ".", "format", "(", "group_name", ",", "name", ")", ",", "\n", "meter", ".", "last_value", ",", "iteration", ",", "\n", ")", "\n", "self", ".", "tb_logger_avg", ".", "add_scalar", "(", "\n", "'{}/{}'", ".", "format", "(", "group_name", ",", "name", ")", ",", "\n", "meter", ".", "avg", ",", "iteration", ",", "\n", ")", "\n", "self", ".", "tb_logger_med", ".", "add_scalar", "(", "\n", "'{}/{}'", ".", "format", "(", "group_name", ",", "name", ")", ",", "\n", "meter", ".", "median", ",", "iteration", ",", "\n", ")", "\n", "if", "self", ".", "philly_tb_logger", ":", "\n", "                        ", "self", ".", "philly_tb_logger", ".", "add_scalar", "(", "\n", "'{}/{}'", ".", "format", "(", "group_name", ",", "name", ")", ",", "\n", "meter", ".", "last_value", ",", "iteration", ",", "\n", ")", "\n", "self", ".", "philly_tb_logger_avg", ".", "add_scalar", "(", "\n", "'{}/{}'", ".", "format", "(", "group_name", ",", "name", ")", ",", "\n", "meter", ".", "avg", ",", "iteration", ",", "\n", ")", "\n", "self", ".", "philly_tb_logger_med", ".", "add_scalar", "(", "\n", "'{}/{}'", ".", "format", "(", "group_name", ",", "name", ")", ",", "\n", "meter", ".", "median", ",", "iteration", ",", "\n", ")", "\n", "", "", "", "for", "group_name", ",", "values", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "                ", "for", "name", ",", "param", "in", "values", ".", "items", "(", ")", ":", "\n", "                    ", "self", ".", "tb_logger", ".", "add_scalar", "(", "\n", "'{}/{}'", ".", "format", "(", "group_name", ",", "name", ")", ",", "\n", "param", ",", "iteration", ",", "\n", ")", "\n", "if", "self", ".", "philly_tb_logger", ":", "\n", "                        ", "self", ".", "philly_tb_logger", ".", "add_scalar", "(", "\n", "'{}/{}'", ".", "format", "(", "group_name", ",", "name", ")", ",", "\n", "param", ",", "iteration", ",", "\n", ")", "\n", "", "", "", "", "return", "super", "(", "TensorboardLogger", ",", "self", ")", ".", "get_logs", "(", "iteration", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.TensorboardLogger.close": [[181, 186], ["misc.is_main_process", "metric_logger.TensorboardLogger.tb_logger.close", "metric_logger.TensorboardLogger.tb_logger_avg.close", "metric_logger.TensorboardLogger.tb_logger_med.close"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.is_main_process", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.TensorboardLogger.close", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.TensorboardLogger.close", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.metric_logger.TensorboardLogger.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "if", "is_main_process", "(", ")", ":", "\n", "            ", "self", ".", "tb_logger", ".", "close", "(", ")", "\n", "self", ".", "tb_logger_avg", ".", "close", "(", ")", "\n", "self", ".", "tb_logger_med", ".", "close", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.mkdir": [[13, 22], ["os.makedirs", "os.makedirs"], "function", ["None"], ["def", "mkdir", "(", "path", ")", ":", "\n", "# if it is the current folder, skip.", "\n", "    ", "if", "path", "==", "''", ":", "\n", "        ", "return", "\n", "", "try", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "", "except", "OSError", "as", "e", ":", "\n", "        ", "if", "e", ".", "errno", "!=", "errno", ".", "EEXIST", ":", "\n", "            ", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed": [[24, 30], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "", "", "def", "set_seed", "(", "seed", ",", "n_gpu", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.load_from_yaml_file": [[32, 35], ["open", "yaml.load"], "function", ["None"], ["", "", "def", "load_from_yaml_file", "(", "yaml_file", ")", ":", "\n", "    ", "with", "open", "(", "yaml_file", ",", "'r'", ")", "as", "fp", ":", "\n", "        ", "return", "yaml", ".", "load", "(", "fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.find_file_path_in_yaml": [[37, 46], ["os.isfile", "os.isfile", "os.join", "os.join", "FileNotFoundError", "os.strerror", "os.strerror", "os.join"], "function", ["None"], ["", "", "def", "find_file_path_in_yaml", "(", "fname", ",", "root", ")", ":", "\n", "    ", "if", "fname", "is", "not", "None", ":", "\n", "        ", "if", "op", ".", "isfile", "(", "fname", ")", ":", "\n", "            ", "return", "fname", "\n", "", "elif", "op", ".", "isfile", "(", "op", ".", "join", "(", "root", ",", "fname", ")", ")", ":", "\n", "            ", "return", "op", ".", "join", "(", "root", ",", "fname", ")", "\n", "", "else", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "\n", "errno", ".", "ENOENT", ",", "os", ".", "strerror", "(", "errno", ".", "ENOENT", ")", ",", "op", ".", "join", "(", "root", ",", "fname", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank": [[49, 55], ["torch.get_rank", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank"], ["", "", "", "def", "get_rank", "(", ")", ":", "\n", "    ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "return", "dist", ".", "get_rank", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.is_main_process": [[57, 59], ["misc.get_rank"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_rank"], ["", "def", "is_main_process", "(", ")", ":", "\n", "    ", "return", "get_rank", "(", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size": [[61, 67], ["torch.get_world_size", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size"], ["", "def", "get_world_size", "(", ")", ":", "\n", "    ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "return", "dist", ".", "get_world_size", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.InputInstance.__init__": [[19, 39], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ",", "score", "=", "None", ",", "img_key", "=", "None", ",", "q_id", "=", "None", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n\n        Args:\n            guid: Unique id for the example.\n            text_a: string. The untokenized text of the first sequence. For single\n            sequence tasks, only this sequence must be specified.\n            text_b: (Optional) string. The untokenized text of the second sequence.\n            Only must be specified for sequence pair tasks.\n            label: (Optional) string. The label of the example. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"", "\n", "\n", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n", "self", ".", "score", "=", "score", "\n", "self", ".", "img_key", "=", "img_key", "\n", "self", ".", "q_id", "=", "q_id", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.InputFeat.__init__": [[44, 51], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_id", ",", "score", ",", "img_feat", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "label_id", "=", "label_id", "\n", "self", ".", "score", "=", "score", "\n", "self", ".", "img_feat", "=", "img_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.DataProcessor.get_train_examples": [[56, 59], ["NotImplementedError"], "methods", ["None"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.DataProcessor.get_dev_examples": [[60, 63], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.DataProcessor.get_labels": [[64, 67], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.DataProcessor._read_tsv": [[68, 79], ["io.open", "csv.reader", "lines.append", "list", "unicode"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_read_tsv", "(", "cls", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8-sig\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "                    ", "line", "=", "list", "(", "unicode", "(", "cell", ",", "'utf-8'", ")", "for", "cell", "in", "line", ")", "\n", "", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VQATextProcessor.get_train_examples": [[84, 91], ["json.load", "io.open().read().split", "task_utils.VQATextProcessor._create_examples", "io.open", "len", "len", "os.path.join", "io.open().read", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ",", "file_name", "=", "'train2014_qla.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "declars", "=", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'train2014_declarative.json'", ")", ",", "\"r\"", ")", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "assert", "len", "(", "lines", ")", "==", "len", "(", "declars", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "declars", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VQATextProcessor.get_dev_examples": [[94, 101], ["json.load", "io.open().read().split", "task_utils.VQATextProcessor._create_examples", "io.open", "len", "len", "os.path.join", "io.open().read", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ",", "file_name", "=", "'val2014_qla.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "declars", "=", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'val2014_declarative.json'", ")", ",", "\"r\"", ")", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "assert", "len", "(", "lines", ")", "==", "len", "(", "declars", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "declars", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VQATextProcessor.get_test_examples": [[104, 109], ["json.load", "task_utils.VQATextProcessor._create_examples", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ",", "file_name", "=", "'test2015_qla.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VQATextProcessor.get_labels": [[110, 115], ["_pickle.load", "list", "io.open", "range", "len"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ",", "label_file", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "ans2label", "=", "cPickle", ".", "load", "(", "open", "(", "label_file", ",", "'rb'", ")", ")", "\n", "return", "list", "(", "range", "(", "len", "(", "ans2label", ")", ")", ")", "\n", "# return list(ans2label.values())", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VQATextProcessor._create_examples": [[118, 138], ["enumerate", "zip", "line[].replace().strip", "task_utils.InputInstance", "examples.append", "set_type.startswith", "set_type.startswith", "len", "str", "line[].replace"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "declars", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "(", "line", ",", "declar", ")", ")", "in", "enumerate", "(", "zip", "(", "lines", ",", "declars", ")", ")", ":", "\n", "            ", "if", "set_type", "!=", "'test'", "and", "len", "(", "line", "[", "'an'", "]", ")", "==", "0", ":", "continue", "\n", "\n", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "str", "(", "i", ")", ")", "\n", "text_a", "=", "line", "[", "'q'", "]", "\n", "text_b", "=", "line", "[", "'o'", "]", ".", "replace", "(", "';'", ",", "' '", ")", ".", "strip", "(", ")", "#line['o']", "\n", "label", "=", "None", "if", "set_type", ".", "startswith", "(", "'test'", ")", "else", "line", "[", "'an'", "]", "\n", "score", "=", "None", "if", "set_type", ".", "startswith", "(", "'test'", ")", "else", "line", "[", "'s'", "]", "\n", "img_key", "=", "line", "[", "'img_id'", "]", "\n", "q_id", "=", "i", "# int(line['q_id']) if set_type.startswith('test') else 0", "\n", "\n", "exam", "=", "InputInstance", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ",", "score", "=", "score", ",", "img_key", "=", "img_key", ",", "\n", "q_id", "=", "q_id", ")", "\n", "exam", ".", "text_c", "=", "declar", "\n", "examples", ".", "append", "(", "exam", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VQATextAProcessor.get_train_examples": [[142, 147], ["json.load", "task_utils.VQATextAProcessor._create_examples", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ",", "file_name", "=", "'train2014_qla.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VQATextAProcessor.get_dev_examples": [[150, 155], ["json.load", "task_utils.VQATextAProcessor._create_examples", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ",", "file_name", "=", "'val2014_qla.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VQATextAProcessor.get_test_examples": [[158, 163], ["json.load", "task_utils.VQATextAProcessor._create_examples", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ",", "file_name", "=", "'test2015_qla.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VQATextAProcessor.get_labels": [[164, 169], ["_pickle.load", "list", "io.open", "_pickle.load.values"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ",", "label_file", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "ans2label", "=", "cPickle", ".", "load", "(", "open", "(", "label_file", ",", "'rb'", ")", ")", "\n", "return", "list", "(", "ans2label", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VQATextAProcessor._create_examples": [[170, 186], ["enumerate", "examples.append", "set_type.startswith", "set_type.startswith", "set_type.startswith", "int", "task_utils.InputInstance", "len", "str"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "set_type", "!=", "'test'", "and", "len", "(", "line", "[", "'an'", "]", ")", "==", "0", ":", "continue", "\n", "\n", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "str", "(", "i", ")", ")", "\n", "text_a", "=", "line", "[", "'q'", "]", "\n", "text_b", "=", "None", "# line['o'] # or None", "\n", "label", "=", "None", "if", "set_type", ".", "startswith", "(", "'test'", ")", "else", "line", "[", "'an'", "]", "\n", "score", "=", "None", "if", "set_type", ".", "startswith", "(", "'test'", ")", "else", "line", "[", "'s'", "]", "\n", "img_key", "=", "line", "[", "'img_id'", "]", "\n", "q_id", "=", "int", "(", "line", "[", "'q_id'", "]", ")", "if", "set_type", ".", "startswith", "(", "'test'", ")", "else", "0", "\n", "examples", ".", "append", "(", "InputInstance", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ",", "score", "=", "score", ",", "img_key", "=", "img_key", ",", "q_id", "=", "q_id", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.GQAProcessor.get_train_examples": [[190, 195], ["json.load", "task_utils.GQAProcessor._create_examples", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ",", "file_name", "=", "'train2014_qla.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.GQAProcessor.get_dev_examples": [[198, 203], ["json.load", "task_utils.GQAProcessor._create_examples", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ",", "file_name", "=", "'val2014_qla.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.GQAProcessor.get_test_examples": [[206, 211], ["json.load", "task_utils.GQAProcessor._create_examples", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ",", "file_name", "=", "'test2015_qla.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.GQAProcessor.get_labels": [[212, 217], ["_pickle.load", "list", "io.open", "_pickle.load.values"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ",", "label_file", "=", "'trainval_testdev_all_ans2label.pkl'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "ans2label", "=", "cPickle", ".", "load", "(", "open", "(", "label_file", ",", "'rb'", ")", ")", "\n", "return", "list", "(", "ans2label", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.GQAProcessor._create_examples": [[218, 234], ["enumerate", "int", "examples.append", "set_type.startswith", "task_utils.InputInstance", "len", "str"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "set_type", "!=", "'test'", "and", "len", "(", "line", "[", "'an'", "]", ")", "==", "0", ":", "continue", "\n", "\n", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "str", "(", "i", ")", ")", "\n", "text_a", "=", "line", "[", "'q'", "]", "\n", "text_b", "=", "line", "[", "'o'", "]", "# or None", "\n", "label", "=", "None", "if", "set_type", ".", "startswith", "(", "'test'", ")", "else", "line", "[", "'an'", "]", "\n", "score", "=", "0", "\n", "img_key", "=", "line", "[", "'img_id'", "]", "\n", "q_id", "=", "int", "(", "line", "[", "'q_id'", "]", ")", "# if set_type.startswith('test') else 0", "\n", "examples", ".", "append", "(", "InputInstance", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ",", "score", "=", "score", ",", "img_key", "=", "img_key", ",", "q_id", "=", "q_id", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.NLVRProcessor.get_train_examples": [[238, 243], ["json.load", "task_utils.NLVRProcessor._create_examples", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ",", "use_label_seq", "=", "True", ",", "file_name", "=", "'nlvr2_train.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "\"train\"", ",", "use_label_seq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.NLVRProcessor.get_dev_examples": [[246, 251], ["json.load", "task_utils.NLVRProcessor._create_examples", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ",", "use_label_seq", "=", "True", ",", "file_name", "=", "'nlvr2_dev.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "\"dev\"", ",", "use_label_seq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.NLVRProcessor.get_test_examples": [[254, 259], ["json.load", "task_utils.NLVRProcessor._create_examples", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ",", "use_label_seq", "=", "True", ",", "file_name", "=", "'nlvr2_test1.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "\"test\"", ",", "use_label_seq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.NLVRProcessor.get_labels": [[260, 266], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ",", "label_file", "=", "None", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "#ans2label = cPickle.load(open(label_file, 'rb'))", "\n", "#return list(ans2label.values())", "\n", "return", "[", "0", ",", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.NLVRProcessor._create_examples": [[267, 281], ["enumerate", "examples.append", "task_utils.InputInstance", "str"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ",", "use_label_seq", "=", "True", ")", ":", "\n", "        ", "\"\"\" Creates examples for the training and dev sets. \"\"\"", "\n", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "str", "(", "i", ")", ")", "\n", "text_a", "=", "line", "[", "'q'", "]", "\n", "text_b", "=", "line", "[", "'o'", "]", "if", "use_label_seq", "else", "None", "\n", "label", "=", "line", "[", "'label'", "]", "#None if set_type.startswith('test') else line['label']", "\n", "score", "=", "0", "\n", "img_key", "=", "line", "[", "'img_id'", "]", "#[line['img_left'], line['img_left']]", "\n", "q_id", "=", "0", "#int(line['q_id']) if set_type.startswith('test') else 0", "\n", "examples", ".", "append", "(", "InputInstance", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ",", "score", "=", "score", ",", "img_key", "=", "img_key", ",", "q_id", "=", "q_id", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_Q_A_Processor.get_train_examples": [[285, 290], ["json.load", "task_utils.VCR_Q_A_Processor._create_examples", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ",", "file_name", "=", "'vcr_train.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_Q_A_Processor.get_dev_examples": [[291, 296], ["json.load", "task_utils.VCR_Q_A_Processor._create_examples", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ",", "file_name", "=", "'vcr_val.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_Q_A_Processor.get_test_examples": [[297, 302], ["json.load", "task_utils.VCR_Q_A_Processor._create_examples", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ",", "file_name", "=", "'vcr_test.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_Q_A_Processor.get_labels": [[303, 309], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ",", "label_file", "=", "None", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "#ans2label = cPickle.load(open(label_file, 'rb'))", "\n", "#return list(ans2label.values())", "\n", "return", "[", "0", ",", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_Q_A_Processor._create_examples": [[310, 326], ["enumerate", "int", "examples.append", "set_type.startswith", "task_utils.InputInstance", "str", "line[].split"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\" Creates examples for the training and dev sets. \"\"\"", "\n", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "#if set_type!='test': continue", "\n", "\n", "            ", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "str", "(", "i", ")", ")", "\n", "text_a", "=", "line", "[", "'q'", "]", "# question", "\n", "choices", "=", "line", "[", "'choices'", "]", "\n", "label", "=", "None", "if", "set_type", ".", "startswith", "(", "'test'", ")", "else", "line", "[", "'label'", "]", "\n", "img_key", "=", "line", "[", "'img_id'", "]", "\n", "q_id", "=", "int", "(", "line", "[", "'annot_id'", "]", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", ")", "#int(line['q_id']) if set_type.startswith('test') else 0", "\n", "score", "=", "line", "[", "'objects'", "]", "if", "'objects'", "in", "line", "else", "None", "\n", "examples", ".", "append", "(", "InputInstance", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "choices", ",", "label", "=", "label", ",", "score", "=", "score", ",", "img_key", "=", "img_key", ",", "q_id", "=", "q_id", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QA_R_Processor.get_train_examples": [[330, 335], ["json.load", "task_utils.VCR_QA_R_Processor._create_examples", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ",", "file_name", "=", "'vcr_train.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QA_R_Processor.get_dev_examples": [[336, 341], ["json.load", "task_utils.VCR_QA_R_Processor._create_examples", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ",", "file_name", "=", "'vcr_val.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QA_R_Processor.get_test_examples": [[342, 347], ["json.load", "task_utils.VCR_QA_R_Processor._create_examples", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ",", "file_name", "=", "'vcr_test.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QA_R_Processor.get_labels": [[348, 354], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ",", "label_file", "=", "None", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "#ans2label = cPickle.load(open(label_file, 'rb'))", "\n", "#return list(ans2label.values())", "\n", "return", "[", "0", ",", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QA_R_Processor._create_examples": [[355, 370], ["enumerate", "int", "examples.append", "set_type.startswith", "task_utils.InputInstance", "str", "line[].split"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\" Creates examples for the training and dev sets. \"\"\"", "\n", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "#if set_type!='test': continue", "\n", "\n", "            ", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "str", "(", "i", ")", ")", "\n", "text_a", "=", "line", "[", "'q'", "]", "+", "' '", "+", "line", "[", "'choices'", "]", "[", "line", "[", "'label'", "]", "]", "# question_choice", "\n", "choices", "=", "line", "[", "'rational_choices'", "]", "# rational_choice", "\n", "label", "=", "None", "if", "set_type", ".", "startswith", "(", "'test'", ")", "else", "line", "[", "'rational_label'", "]", "# rational_label", "\n", "img_key", "=", "line", "[", "'img_id'", "]", "\n", "q_id", "=", "int", "(", "line", "[", "'annot_id'", "]", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", ")", "#int(line['q_id']) if set_type.startswith('test') else 0", "\n", "examples", ".", "append", "(", "InputInstance", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "choices", ",", "label", "=", "label", ",", "score", "=", "None", ",", "img_key", "=", "img_key", ",", "q_id", "=", "q_id", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_train_examples": [[374, 379], ["json.load", "task_utils.VCR_QAR_Processor._create_examples", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ",", "file_name", "=", "'vcr_train.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_dev_examples": [[380, 385], ["json.load", "task_utils.VCR_QAR_Processor._create_examples", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ",", "file_name", "=", "'vcr_val.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_test_examples": [[386, 391], ["json.load", "task_utils.VCR_QAR_Processor._create_examples", "io.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ",", "file_name", "=", "'vcr_test.json'", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "lines", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "lines", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor.get_labels": [[392, 398], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ",", "label_file", "=", "None", ")", ":", "\n", "        ", "\"\"\" See base class.\"\"\"", "\n", "\n", "#ans2label = cPickle.load(open(label_file, 'rb'))", "\n", "#return list(ans2label.values())", "\n", "return", "[", "0", ",", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.VCR_QAR_Processor._create_examples": [[399, 425], ["enumerate", "int", "examples.append", "set_type.startswith", "task_utils.InputInstance", "int", "examples.append", "str", "line[].split", "set_type.startswith", "task_utils.InputInstance", "str", "line[].split"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\" Creates examples for the training and dev sets. \"\"\"", "\n", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "#if set_type!='test': continue", "\n", "\n", "            ", "guid", "=", "\"%s-%s-q-a\"", "%", "(", "set_type", ",", "str", "(", "i", ")", ")", "\n", "text_a", "=", "line", "[", "'q'", "]", "# question", "\n", "choices", "=", "line", "[", "'choices'", "]", "\n", "label", "=", "None", "if", "set_type", ".", "startswith", "(", "'test'", ")", "else", "line", "[", "'label'", "]", "\n", "img_key", "=", "line", "[", "'img_id'", "]", "\n", "q_id", "=", "int", "(", "line", "[", "'annot_id'", "]", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", ")", "#int(line['q_id']) if set_type.startswith('test') else 0", "\n", "score", "=", "line", "[", "'objects'", "]", "if", "'objects'", "in", "line", "else", "None", "\n", "examples", ".", "append", "(", "InputInstance", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "choices", ",", "label", "=", "label", ",", "score", "=", "score", ",", "img_key", "=", "img_key", ",", "q_id", "=", "q_id", ")", ")", "\n", "\n", "if", "set_type", "==", "'train'", ":", "# qa -> r", "\n", "                ", "guid", "=", "\"%s-%s-qa-r\"", "%", "(", "set_type", ",", "str", "(", "i", ")", ")", "\n", "text_a", "=", "line", "[", "'q'", "]", "+", "' '", "+", "line", "[", "'choices'", "]", "[", "line", "[", "'label'", "]", "]", "# question_choice", "\n", "choices", "=", "line", "[", "'rational_choices'", "]", "# rational_choice", "\n", "label", "=", "None", "if", "set_type", ".", "startswith", "(", "'test'", ")", "else", "line", "[", "'rational_label'", "]", "# rational_label", "\n", "img_key", "=", "line", "[", "'img_id'", "]", "\n", "q_id", "=", "int", "(", "line", "[", "'annot_id'", "]", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", ")", "# int(line['q_id']) if set_type.startswith('test') else 0", "\n", "score", "=", "line", "[", "'objects'", "]", "if", "'objects'", "in", "line", "else", "None", "\n", "examples", ".", "append", "(", "InputInstance", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "choices", ",", "label", "=", "label", ",", "score", "=", "score", ",", "img_key", "=", "img_key", ",", "q_id", "=", "q_id", ")", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils.convert_examples_to_features_vqa": [[427, 557], ["enumerate", "tokenizer.tokenize", "tokenizer.convert_tokens_to_ids", "img_feats.item().get", "features.append", "enumerate", "len", "logger.info", "tokenizer.tokenize", "task_utils._truncate_seq_pair", "len", "len", "len", "len", "len", "len", "torch.zeros", "torch.cat", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "task_utils.InputFeat", "len", "img_feats.item", "float", "KeyError", "len", "len", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv._truncate_seq_pair"], ["", "", "def", "convert_examples_to_features_vqa", "(", "examples", ",", "img_feats", ",", "label_list", ",", "max_img_seq_length", ",", "max_seq_length", ",", "\n", "tokenizer", ",", "output_mode", ",", "\n", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "    ", "\"\"\" Loads a data file into a list of `InputBatch`s\n        `cls_token_at_end` define the location of the CLS token:\n            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n    \"\"\"", "\n", "\n", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "features", "=", "[", "]", "\n", "#debug:", "\n", "debug_size", "=", "500", "\n", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", "[", "0", ":", "]", ")", ":", "\n", "        ", "if", "len", "(", "example", ".", "label", ")", "==", "0", ":", "continue", "\n", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing example %d of %d\"", "%", "(", "ex_index", ",", "len", "(", "examples", ")", ")", ")", "\n", "\n", "", "tokens_a", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "            ", "tokens_b", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "text_b", ")", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total", "\n", "# length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "            ", "if", "len", "(", "tokens_a", ")", ">", "max_seq_length", "-", "2", ":", "\n", "                ", "tokens_a", "=", "tokens_a", "[", ":", "(", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "# The convention in BERT is:", "\n", "# (a) For sequence pairs:", "\n", "#  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]", "\n", "#  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1", "\n", "# (b) For single sequences:", "\n", "#  tokens:   [CLS] the dog is hairy . [SEP]", "\n", "#  type_ids:   0   0   0   0  0     0   0", "\n", "#", "\n", "# Where \"type_ids\" are used to indicate whether this is the first", "\n", "# sequence or the second sequence. The embedding vectors for `type=0` and", "\n", "# `type=1` were learned during pre-training and are added to the wordpiece", "\n", "# embedding vector (and position vector). This is not *strictly* necessary", "\n", "# since the [SEP] token unambiguously separates the sequences, but it makes", "\n", "# it easier for the model to learn the concept of sequences.", "\n", "#", "\n", "# For classification tasks, the first vector (corresponding to [CLS]) is", "\n", "# used as as the \"sentence vector\". Note that this only makes sense because", "\n", "# the entire model is fine-tuned.", "\n", "", "", "tokens", "=", "tokens_a", "+", "[", "sep_token", "]", "\n", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "            ", "tokens", "+=", "tokens_b", "+", "[", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "if", "cls_token_at_end", ":", "\n", "            ", "tokens", "=", "tokens", "+", "[", "cls_token", "]", "\n", "segment_ids", "=", "segment_ids", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "            ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "segment_ids", "=", "segment_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "\n", "# image features", "\n", "#img_feat = img_feats[example.img_key] # torch", "\n", "img_feat", "=", "img_feats", ".", "item", "(", ")", ".", "get", "(", "example", ".", "img_key", ")", "# numpy", "\n", "if", "img_feat", ".", "shape", "[", "0", "]", ">", "max_img_seq_length", ":", "\n", "            ", "img_feat", "=", "img_feat", "[", "0", ":", "max_img_seq_length", ",", "]", "\n", "if", "max_img_seq_length", ">", "0", ":", "\n", "                ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "#segment_ids += [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "", "else", ":", "\n", "            ", "if", "max_img_seq_length", ">", "0", ":", "\n", "                ", "input_mask", "=", "input_mask", "+", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "img_feat", ".", "shape", "[", "0", "]", "\n", "#segment_ids = segment_ids + [sequence_b_segment_id] * img_feat.shape[0]", "\n", "", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "max_img_seq_length", "-", "img_feat", ".", "shape", "[", "0", "]", ",", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "if", "max_img_seq_length", ">", "0", ":", "\n", "                ", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_matrix", ".", "shape", "[", "0", "]", ")", "\n", "#segment_ids = segment_ids + [pad_token_segment_id] * padding_matrix.shape[0]", "\n", "\n", "", "", "if", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "label_id", "=", "[", "label_map", "[", "l", "]", "for", "l", "in", "example", ".", "label", "]", "\n", "score", "=", "example", ".", "score", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "output_mode", ")", "\n", "\n", "", "if", "ex_index", "<", "5", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"segment_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label: %s (id = %s)\"", "%", "(", "example", ".", "label", ",", "label_id", ")", ")", "\n", "logger", ".", "info", "(", "\"score: %s (score = %s)\"", "%", "(", "example", ".", "score", ",", "score", ")", ")", "\n", "\n", "", "features", ".", "append", "(", "InputFeat", "(", "input_ids", "=", "input_ids", ",", "input_mask", "=", "input_mask", ",", "segment_ids", "=", "segment_ids", ",", "label_id", "=", "label_id", ",", "score", "=", "score", ",", "img_feat", "=", "img_feat", ")", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.utils.task_utils._truncate_seq_pair": [[559, 574], ["len", "len", "len", "len", "tokens_a.pop", "tokens_b.pop"], "function", ["None"], ["", "def", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_length", ")", ":", "\n", "    ", "\"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"", "\n", "\n", "# This is a simple heuristic which will always truncate the longer sequence", "\n", "# one token at a time. This makes more sense than truncating an equal percent", "\n", "# of tokens from each, since if one sequence is very short then each token", "\n", "# that's truncated likely contains more information than a longer sequence.", "\n", "while", "True", ":", "\n", "        ", "total_length", "=", "len", "(", "tokens_a", ")", "+", "len", "(", "tokens_b", ")", "\n", "if", "total_length", "<=", "max_length", ":", "\n", "            ", "break", "\n", "", "if", "len", "(", "tokens_a", ")", ">", "len", "(", "tokens_b", ")", ":", "\n", "            ", "tokens_a", ".", "pop", "(", ")", "\n", "", "else", ":", "\n", "            ", "tokens_b", ".", "pop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.cider.cider_scorer.CiderScorer.copy": [[56, 62], ["cider_scorer.CiderScorer", "copy.copy", "copy.copy"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.copy", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.copy"], ["def", "copy", "(", "self", ")", ":", "\n", "        ", "''' copy the refs.'''", "\n", "new", "=", "CiderScorer", "(", "n", "=", "self", ".", "n", ")", "\n", "new", ".", "ctest", "=", "copy", ".", "copy", "(", "self", ".", "ctest", ")", "\n", "new", ".", "crefs", "=", "copy", ".", "copy", "(", "self", ".", "crefs", ")", "\n", "return", "new", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.cider.cider_scorer.CiderScorer.__init__": [[63, 76], ["cider_scorer.CiderScorer.cook_append", "six.moves.cPickle.load", "numpy.log", "open", "float", "os.path.join", "dict"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.cook_append"], ["", "def", "__init__", "(", "self", ",", "df_mode", "=", "\"corpus\"", ",", "test", "=", "None", ",", "refs", "=", "None", ",", "n", "=", "4", ",", "sigma", "=", "6.0", ")", ":", "\n", "        ", "''' singular instance '''", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "sigma", "=", "sigma", "\n", "self", ".", "crefs", "=", "[", "]", "\n", "self", ".", "ctest", "=", "[", "]", "\n", "self", ".", "df_mode", "=", "df_mode", "\n", "self", ".", "ref_len", "=", "None", "\n", "if", "self", ".", "df_mode", "!=", "\"corpus\"", ":", "\n", "            ", "pkl_file", "=", "cPickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "'data'", ",", "df_mode", "+", "'.p'", ")", ",", "'rb'", ")", ",", "**", "(", "dict", "(", "encoding", "=", "'latin1'", ")", "if", "six", ".", "PY3", "else", "{", "}", ")", ")", "\n", "self", ".", "ref_len", "=", "np", ".", "log", "(", "float", "(", "pkl_file", "[", "'ref_len'", "]", ")", ")", "\n", "self", ".", "document_frequency", "=", "pkl_file", "[", "'document_frequency'", "]", "\n", "", "self", ".", "cook_append", "(", "test", ",", "refs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.cider.cider_scorer.CiderScorer.clear": [[77, 80], ["None"], "methods", ["None"], ["", "def", "clear", "(", "self", ")", ":", "\n", "        ", "self", ".", "crefs", "=", "[", "]", "\n", "self", ".", "ctest", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.cider.cider_scorer.CiderScorer.cook_append": [[81, 90], ["cider_scorer.CiderScorer.crefs.append", "cider_scorer.cook_refs", "cider_scorer.CiderScorer.ctest.append", "cider_scorer.CiderScorer.ctest.append", "cider_scorer.cook_test"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.cook_refs", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.cook_test"], ["", "def", "cook_append", "(", "self", ",", "test", ",", "refs", ")", ":", "\n", "        ", "'''called by constructor and __iadd__ to avoid creating new instances.'''", "\n", "\n", "if", "refs", "is", "not", "None", ":", "\n", "            ", "self", ".", "crefs", ".", "append", "(", "cook_refs", "(", "refs", ")", ")", "\n", "if", "test", "is", "not", "None", ":", "\n", "                ", "self", ".", "ctest", ".", "append", "(", "cook_test", "(", "test", ")", ")", "## N.B.: -1", "\n", "", "else", ":", "\n", "                ", "self", ".", "ctest", ".", "append", "(", "None", ")", "# lens of crefs and ctest have to match", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.cider.cider_scorer.CiderScorer.size": [[91, 94], ["len", "len", "len", "len", "len"], "methods", ["None"], ["", "", "", "def", "size", "(", "self", ")", ":", "\n", "        ", "assert", "len", "(", "self", ".", "crefs", ")", "==", "len", "(", "self", ".", "ctest", ")", ",", "\"refs/test mismatch! %d<>%d\"", "%", "(", "len", "(", "self", ".", "crefs", ")", ",", "len", "(", "self", ".", "ctest", ")", ")", "\n", "return", "len", "(", "self", ".", "crefs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.cider.cider_scorer.CiderScorer.__iadd__": [[95, 106], ["type", "cider_scorer.CiderScorer.cook_append", "cider_scorer.CiderScorer.ctest.extend", "cider_scorer.CiderScorer.crefs.extend"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.cook_append"], ["", "def", "__iadd__", "(", "self", ",", "other", ")", ":", "\n", "        ", "'''add an instance (e.g., from another sentence).'''", "\n", "\n", "if", "type", "(", "other", ")", "is", "tuple", ":", "\n", "## avoid creating new CiderScorer instances", "\n", "            ", "self", ".", "cook_append", "(", "other", "[", "0", "]", ",", "other", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "ctest", ".", "extend", "(", "other", ".", "ctest", ")", "\n", "self", ".", "crefs", ".", "extend", "(", "other", ".", "crefs", ")", "\n", "\n", "", "return", "self", "\n", "", "def", "compute_doc_freq", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.cider.cider_scorer.CiderScorer.compute_doc_freq": [[106, 117], ["set", "ref.items"], "methods", ["None"], ["", "def", "compute_doc_freq", "(", "self", ")", ":", "\n", "        ", "'''\n        Compute term frequency for reference data.\n        This will be used to compute idf (inverse document frequency later)\n        The term frequency is stored in the object\n        :return: None\n        '''", "\n", "for", "refs", "in", "self", ".", "crefs", ":", "\n", "# refs, k ref captions of one image", "\n", "            ", "for", "ngram", "in", "set", "(", "[", "ngram", "for", "ref", "in", "refs", "for", "(", "ngram", ",", "count", ")", "in", "ref", ".", "items", "(", ")", "]", ")", ":", "\n", "                ", "self", ".", "document_frequency", "[", "ngram", "]", "+=", "1", "\n", "# maxcounts[ngram] = max(maxcounts.get(ngram,0), count)", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.cider.cider_scorer.CiderScorer.compute_cider": [[119, 194], ["zip", "cnts.items", "float", "numpy.array", "range", "numpy.log", "cider_scorer.CiderScorer.compute_cider.counts2vec"], "methods", ["None"], ["", "", "", "def", "compute_cider", "(", "self", ")", ":", "\n", "        ", "def", "counts2vec", "(", "cnts", ")", ":", "\n", "            ", "\"\"\"\n            Function maps counts of ngram to vector of tfidf weights.\n            The function returns vec, an array of dictionary that store mapping of n-gram and tf-idf weights.\n            The n-th entry of array denotes length of n-grams.\n            :param cnts:\n            :return: vec (array of dict), norm (array of float), length (int)\n            \"\"\"", "\n", "vec", "=", "[", "defaultdict", "(", "float", ")", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "length", "=", "0", "\n", "norm", "=", "[", "0.0", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "for", "(", "ngram", ",", "term_freq", ")", "in", "cnts", ".", "items", "(", ")", ":", "\n", "# give word count 1 if it doesn't appear in reference corpus", "\n", "                ", "df", "=", "np", ".", "log", "(", "max", "(", "1.0", ",", "self", ".", "document_frequency", "[", "ngram", "]", ")", ")", "\n", "# ngram index", "\n", "n", "=", "len", "(", "ngram", ")", "-", "1", "\n", "# tf (term_freq) * idf (precomputed idf) for n-grams", "\n", "vec", "[", "n", "]", "[", "ngram", "]", "=", "float", "(", "term_freq", ")", "*", "(", "self", ".", "ref_len", "-", "df", ")", "\n", "# compute norm for the vector.  the norm will be used for", "\n", "# computing similarity", "\n", "norm", "[", "n", "]", "+=", "pow", "(", "vec", "[", "n", "]", "[", "ngram", "]", ",", "2", ")", "\n", "\n", "if", "n", "==", "1", ":", "\n", "                    ", "length", "+=", "term_freq", "\n", "", "", "norm", "=", "[", "np", ".", "sqrt", "(", "n", ")", "for", "n", "in", "norm", "]", "\n", "return", "vec", ",", "norm", ",", "length", "\n", "\n", "", "def", "sim", "(", "vec_hyp", ",", "vec_ref", ",", "norm_hyp", ",", "norm_ref", ",", "length_hyp", ",", "length_ref", ")", ":", "\n", "            ", "'''\n            Compute the cosine similarity of two vectors.\n            :param vec_hyp: array of dictionary for vector corresponding to hypothesis\n            :param vec_ref: array of dictionary for vector corresponding to reference\n            :param norm_hyp: array of float for vector corresponding to hypothesis\n            :param norm_ref: array of float for vector corresponding to reference\n            :param length_hyp: int containing length of hypothesis\n            :param length_ref: int containing length of reference\n            :return: array of score for each n-grams cosine similarity\n            '''", "\n", "delta", "=", "float", "(", "length_hyp", "-", "length_ref", ")", "\n", "# measure consine similarity", "\n", "val", "=", "np", ".", "array", "(", "[", "0.0", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", ")", "\n", "for", "n", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "# ngram", "\n", "                ", "for", "(", "ngram", ",", "count", ")", "in", "vec_hyp", "[", "n", "]", ".", "items", "(", ")", ":", "\n", "                    ", "val", "[", "n", "]", "+=", "vec_hyp", "[", "n", "]", "[", "ngram", "]", "*", "vec_ref", "[", "n", "]", "[", "ngram", "]", "\n", "\n", "", "if", "(", "norm_hyp", "[", "n", "]", "!=", "0", ")", "and", "(", "norm_ref", "[", "n", "]", "!=", "0", ")", ":", "\n", "                    ", "val", "[", "n", "]", "/=", "(", "norm_hyp", "[", "n", "]", "*", "norm_ref", "[", "n", "]", ")", "\n", "\n", "", "assert", "(", "not", "math", ".", "isnan", "(", "val", "[", "n", "]", ")", ")", "\n", "", "return", "val", "\n", "\n", "# compute log reference length", "\n", "", "if", "self", ".", "df_mode", "==", "\"corpus\"", ":", "\n", "            ", "self", ".", "ref_len", "=", "np", ".", "log", "(", "float", "(", "len", "(", "self", ".", "crefs", ")", ")", ")", "\n", "\n", "", "scores", "=", "[", "]", "\n", "for", "test", ",", "refs", "in", "zip", "(", "self", ".", "ctest", ",", "self", ".", "crefs", ")", ":", "\n", "# compute vector for test captions", "\n", "            ", "vec", ",", "norm", ",", "length", "=", "counts2vec", "(", "test", ")", "\n", "# compute vector for ref captions", "\n", "score", "=", "np", ".", "array", "(", "[", "0.0", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", ")", "\n", "for", "ref", "in", "refs", ":", "\n", "                ", "vec_ref", ",", "norm_ref", ",", "length_ref", "=", "counts2vec", "(", "ref", ")", "\n", "score", "+=", "sim", "(", "vec", ",", "vec_ref", ",", "norm", ",", "norm_ref", ",", "length", ",", "length_ref", ")", "\n", "# change by vrama91 - mean of ngram scores, instead of sum", "\n", "", "score_avg", "=", "np", ".", "mean", "(", "score", ")", "\n", "# divide by number of references", "\n", "score_avg", "/=", "len", "(", "refs", ")", "\n", "# multiply score by 10", "\n", "score_avg", "*=", "10.0", "\n", "# append score of an image to the score list", "\n", "scores", ".", "append", "(", "score_avg", ")", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.cider.cider_scorer.CiderScorer.compute_score": [[195, 208], ["cider_scorer.CiderScorer.compute_cider", "collections.defaultdict", "cider_scorer.CiderScorer.compute_doc_freq", "numpy.mean", "numpy.array", "len", "max", "numpy.array", "cider_scorer.CiderScorer.document_frequency.values"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.compute_cider", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.compute_doc_freq"], ["", "def", "compute_score", "(", "self", ",", "option", "=", "None", ",", "verbose", "=", "0", ")", ":", "\n", "# compute idf", "\n", "        ", "if", "self", ".", "df_mode", "==", "\"corpus\"", ":", "\n", "            ", "self", ".", "document_frequency", "=", "defaultdict", "(", "float", ")", "\n", "self", ".", "compute_doc_freq", "(", ")", "\n", "# assert to check document frequency", "\n", "assert", "(", "len", "(", "self", ".", "ctest", ")", ">=", "max", "(", "self", ".", "document_frequency", ".", "values", "(", ")", ")", ")", "\n", "# import json for now and write the corresponding files", "\n", "# compute cider score", "\n", "", "score", "=", "self", ".", "compute_cider", "(", ")", "\n", "# debug", "\n", "# print score", "\n", "return", "np", ".", "mean", "(", "np", ".", "array", "(", "score", ")", ")", ",", "np", ".", "array", "(", "score", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cciiplab_dpt.cider.cider_scorer.precook": [[16, 32], ["s.split", "collections.defaultdict", "range", "range", "tuple", "len"], "function", ["None"], ["def", "precook", "(", "s", ",", "n", "=", "4", ",", "out", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Takes a string as input and returns an object that can be given to\n    either cook_refs or cook_test. This is optional: cook_refs and cook_test\n    can take string arguments as well.\n    :param s: string : sentence to be converted into ngrams\n    :param n: int    : number of ngrams for which representation is calculated\n    :return: term frequency vector for occuring ngrams\n    \"\"\"", "\n", "words", "=", "s", ".", "split", "(", ")", "\n", "counts", "=", "defaultdict", "(", "int", ")", "\n", "for", "k", "in", "range", "(", "1", ",", "n", "+", "1", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "words", ")", "-", "k", "+", "1", ")", ":", "\n", "            ", "ngram", "=", "tuple", "(", "words", "[", "i", ":", "i", "+", "k", "]", ")", "\n", "counts", "[", "ngram", "]", "+=", "1", "\n", "", "", "return", "counts", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.cider.cider_scorer.cook_refs": [[33, 42], ["cider_scorer.precook"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.precook"], ["", "def", "cook_refs", "(", "refs", ",", "n", "=", "4", ")", ":", "## lhuang: oracle will call with \"average\"", "\n", "    ", "'''Takes a list of reference sentences for a single segment\n    and returns an object that encapsulates everything that BLEU\n    needs to know about them.\n    :param refs: list of string : reference sentences for some image\n    :param n: int : number of ngrams for which (ngram) representation is calculated\n    :return: result (list of dict)\n    '''", "\n", "return", "[", "precook", "(", "ref", ",", "n", ")", "for", "ref", "in", "refs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.cider.cider_scorer.cook_test": [[43, 51], ["cider_scorer.precook"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.precook"], ["", "def", "cook_test", "(", "test", ",", "n", "=", "4", ")", ":", "\n", "    ", "'''Takes a test sentence and returns an object that\n    encapsulates everything that BLEU needs to know about it.\n    :param test: list of string : hypothesis sentence for some image\n    :param n: int : number of ngrams for which (ngram) representation is calculated\n    :return: result (dict)\n    '''", "\n", "return", "precook", "(", "test", ",", "n", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.cider.cider.Cider.__init__": [[24, 36], ["cider_scorer.CiderScorer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "n", "=", "4", ",", "df", "=", "\"corpus\"", ")", ":", "\n", "        ", "\"\"\"\n        Initialize the CIDEr scoring function\n        : param n (int): n-gram size\n        : param df (string): specifies where to get the IDF values from\n                    takes values 'corpus', 'coco-train'\n        : return: None\n        \"\"\"", "\n", "# set cider to sum over 1 to 4-grams", "\n", "self", ".", "_n", "=", "n", "\n", "self", ".", "_df", "=", "df", "\n", "self", ".", "cider_scorer", "=", "CiderScorer", "(", "n", "=", "self", ".", "_n", ",", "df_mode", "=", "self", ".", "_df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.cider.cider.Cider.compute_score": [[37, 63], ["cider.Cider.cider_scorer.clear", "cider.Cider.cider_scorer.compute_score", "type", "len", "type", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.clear", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD.CiderD.compute_score"], ["", "def", "compute_score", "(", "self", ",", "gts", ",", "res", ")", ":", "\n", "        ", "\"\"\"\n        Main function to compute CIDEr score\n        : param  gts (dict) : {image:tokenized reference sentence}\n        : param res (dict)  : {image:tokenized candidate sentence}\n        : return: cider (float) : computed CIDEr score for the corpus\n        \"\"\"", "\n", "\n", "# clear all the previous hypos and refs", "\n", "self", ".", "cider_scorer", ".", "clear", "(", ")", "\n", "\n", "for", "res_id", "in", "res", ":", "\n", "\n", "            ", "hypo", "=", "res_id", "[", "'caption'", "]", "\n", "ref", "=", "gts", "[", "res_id", "[", "'image_id'", "]", "]", "\n", "\n", "# Sanity check.", "\n", "assert", "(", "type", "(", "hypo", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "hypo", ")", "==", "1", ")", "\n", "assert", "(", "type", "(", "ref", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "ref", ")", ">", "0", ")", "\n", "self", ".", "cider_scorer", "+=", "(", "hypo", "[", "0", "]", ",", "ref", ")", "\n", "\n", "", "(", "score", ",", "scores", ")", "=", "self", ".", "cider_scorer", ".", "compute_score", "(", ")", "\n", "\n", "return", "score", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.cider.cider.Cider.method": [[64, 66], ["None"], "methods", ["None"], ["", "def", "method", "(", "self", ")", ":", "\n", "        ", "return", "\"CIDEr\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.copy": [[57, 63], ["ciderD_scorer.CiderScorer", "copy.copy", "copy.copy"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.copy", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.copy"], ["def", "copy", "(", "self", ")", ":", "\n", "        ", "''' copy the refs.'''", "\n", "new", "=", "CiderScorer", "(", "n", "=", "self", ".", "n", ")", "\n", "new", ".", "ctest", "=", "copy", ".", "copy", "(", "self", ".", "ctest", ")", "\n", "new", ".", "crefs", "=", "copy", ".", "copy", "(", "self", ".", "crefs", ")", "\n", "return", "new", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.copy_empty": [[64, 70], ["ciderD_scorer.CiderScorer"], "methods", ["None"], ["", "def", "copy_empty", "(", "self", ")", ":", "\n", "        ", "new", "=", "CiderScorer", "(", "df_mode", "=", "\"corpus\"", ",", "n", "=", "self", ".", "n", ",", "sigma", "=", "self", ".", "sigma", ")", "\n", "new", ".", "df_mode", "=", "self", ".", "df_mode", "\n", "new", ".", "ref_len", "=", "self", ".", "ref_len", "\n", "new", ".", "document_frequency", "=", "self", ".", "document_frequency", "\n", "return", "new", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.__init__": [[71, 86], ["ciderD_scorer.CiderScorer.cook_append", "six.moves.cPickle.load", "numpy.log", "open", "float", "dict"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.cook_append"], ["", "def", "__init__", "(", "self", ",", "df_mode", "=", "\"corpus\"", ",", "test", "=", "None", ",", "refs", "=", "None", ",", "n", "=", "4", ",", "sigma", "=", "6.0", ")", ":", "\n", "        ", "''' singular instance '''", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "sigma", "=", "sigma", "\n", "self", ".", "crefs", "=", "[", "]", "\n", "self", ".", "ctest", "=", "[", "]", "\n", "self", ".", "df_mode", "=", "df_mode", "\n", "self", ".", "ref_len", "=", "None", "\n", "if", "self", ".", "df_mode", "!=", "\"corpus\"", ":", "\n", "            ", "pkl_file", "=", "cPickle", ".", "load", "(", "open", "(", "df_mode", ",", "'rb'", ")", ",", "**", "(", "dict", "(", "encoding", "=", "'latin1'", ")", "if", "six", ".", "PY3", "else", "{", "}", ")", ")", "\n", "self", ".", "ref_len", "=", "np", ".", "log", "(", "float", "(", "pkl_file", "[", "'ref_len'", "]", ")", ")", "\n", "self", ".", "document_frequency", "=", "pkl_file", "[", "'document_frequency'", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "document_frequency", "=", "None", "\n", "", "self", ".", "cook_append", "(", "test", ",", "refs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.clear": [[87, 90], ["None"], "methods", ["None"], ["", "def", "clear", "(", "self", ")", ":", "\n", "        ", "self", ".", "crefs", "=", "[", "]", "\n", "self", ".", "ctest", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.cook_append": [[91, 100], ["ciderD_scorer.CiderScorer.crefs.append", "ciderD_scorer.cook_refs", "ciderD_scorer.CiderScorer.ctest.append", "ciderD_scorer.CiderScorer.ctest.append", "ciderD_scorer.cook_test"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.cook_refs", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.cook_test"], ["", "def", "cook_append", "(", "self", ",", "test", ",", "refs", ")", ":", "\n", "        ", "'''called by constructor and __iadd__ to avoid creating new instances.'''", "\n", "\n", "if", "refs", "is", "not", "None", ":", "\n", "            ", "self", ".", "crefs", ".", "append", "(", "cook_refs", "(", "refs", ")", ")", "\n", "if", "test", "is", "not", "None", ":", "\n", "                ", "self", ".", "ctest", ".", "append", "(", "cook_test", "(", "test", ")", ")", "## N.B.: -1", "\n", "", "else", ":", "\n", "                ", "self", ".", "ctest", ".", "append", "(", "None", ")", "# lens of crefs and ctest have to match", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size": [[101, 104], ["len", "len", "len", "len", "len"], "methods", ["None"], ["", "", "", "def", "size", "(", "self", ")", ":", "\n", "        ", "assert", "len", "(", "self", ".", "crefs", ")", "==", "len", "(", "self", ".", "ctest", ")", ",", "\"refs/test mismatch! %d<>%d\"", "%", "(", "len", "(", "self", ".", "crefs", ")", ",", "len", "(", "self", ".", "ctest", ")", ")", "\n", "return", "len", "(", "self", ".", "crefs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.__iadd__": [[105, 116], ["type", "ciderD_scorer.CiderScorer.cook_append", "ciderD_scorer.CiderScorer.ctest.extend", "ciderD_scorer.CiderScorer.crefs.extend"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.cook_append"], ["", "def", "__iadd__", "(", "self", ",", "other", ")", ":", "\n", "        ", "'''add an instance (e.g., from another sentence).'''", "\n", "\n", "if", "type", "(", "other", ")", "is", "tuple", ":", "\n", "## avoid creating new CiderScorer instances", "\n", "            ", "self", ".", "cook_append", "(", "other", "[", "0", "]", ",", "other", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "ctest", ".", "extend", "(", "other", ".", "ctest", ")", "\n", "self", ".", "crefs", ".", "extend", "(", "other", ".", "crefs", ")", "\n", "\n", "", "return", "self", "\n", "", "def", "compute_doc_freq", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.compute_doc_freq": [[116, 127], ["set", "ref.items"], "methods", ["None"], ["", "def", "compute_doc_freq", "(", "self", ")", ":", "\n", "        ", "'''\n        Compute term frequency for reference data.\n        This will be used to compute idf (inverse document frequency later)\n        The term frequency is stored in the object\n        :return: None\n        '''", "\n", "for", "refs", "in", "self", ".", "crefs", ":", "\n", "# refs, k ref captions of one image", "\n", "            ", "for", "ngram", "in", "set", "(", "[", "ngram", "for", "ref", "in", "refs", "for", "(", "ngram", ",", "count", ")", "in", "ref", ".", "items", "(", ")", "]", ")", ":", "\n", "                ", "self", ".", "document_frequency", "[", "ngram", "]", "+=", "1", "\n", "# maxcounts[ngram] = max(maxcounts.get(ngram,0), count)", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.compute_cider": [[129, 209], ["zip", "cnts.items", "float", "numpy.array", "range", "numpy.log", "ciderD_scorer.CiderScorer.compute_cider.counts2vec"], "methods", ["None"], ["", "", "", "def", "compute_cider", "(", "self", ")", ":", "\n", "        ", "def", "counts2vec", "(", "cnts", ")", ":", "\n", "            ", "\"\"\"\n            Function maps counts of ngram to vector of tfidf weights.\n            The function returns vec, an array of dictionary that store mapping of n-gram and tf-idf weights.\n            The n-th entry of array denotes length of n-grams.\n            :param cnts:\n            :return: vec (array of dict), norm (array of float), length (int)\n            \"\"\"", "\n", "vec", "=", "[", "defaultdict", "(", "float", ")", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "length", "=", "0", "\n", "norm", "=", "[", "0.0", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "for", "(", "ngram", ",", "term_freq", ")", "in", "cnts", ".", "items", "(", ")", ":", "\n", "# give word count 1 if it doesn't appear in reference corpus", "\n", "                ", "df", "=", "np", ".", "log", "(", "max", "(", "1.0", ",", "self", ".", "document_frequency", "[", "ngram", "]", ")", ")", "\n", "# ngram index", "\n", "n", "=", "len", "(", "ngram", ")", "-", "1", "\n", "# tf (term_freq) * idf (precomputed idf) for n-grams", "\n", "vec", "[", "n", "]", "[", "ngram", "]", "=", "float", "(", "term_freq", ")", "*", "(", "self", ".", "ref_len", "-", "df", ")", "\n", "# compute norm for the vector.  the norm will be used for computing similarity", "\n", "norm", "[", "n", "]", "+=", "pow", "(", "vec", "[", "n", "]", "[", "ngram", "]", ",", "2", ")", "\n", "\n", "if", "n", "==", "1", ":", "\n", "                    ", "length", "+=", "term_freq", "\n", "", "", "norm", "=", "[", "np", ".", "sqrt", "(", "n", ")", "for", "n", "in", "norm", "]", "\n", "return", "vec", ",", "norm", ",", "length", "\n", "\n", "", "def", "sim", "(", "vec_hyp", ",", "vec_ref", ",", "norm_hyp", ",", "norm_ref", ",", "length_hyp", ",", "length_ref", ")", ":", "\n", "            ", "'''\n            Compute the cosine similarity of two vectors.\n            :param vec_hyp: array of dictionary for vector corresponding to hypothesis\n            :param vec_ref: array of dictionary for vector corresponding to reference\n            :param norm_hyp: array of float for vector corresponding to hypothesis\n            :param norm_ref: array of float for vector corresponding to reference\n            :param length_hyp: int containing length of hypothesis\n            :param length_ref: int containing length of reference\n            :return: array of score for each n-grams cosine similarity\n            '''", "\n", "delta", "=", "float", "(", "length_hyp", "-", "length_ref", ")", "\n", "# measure consine similarity", "\n", "val", "=", "np", ".", "array", "(", "[", "0.0", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", ")", "\n", "for", "n", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "# ngram", "\n", "                ", "for", "(", "ngram", ",", "count", ")", "in", "vec_hyp", "[", "n", "]", ".", "items", "(", ")", ":", "\n", "# vrama91 : added clipping", "\n", "                    ", "val", "[", "n", "]", "+=", "min", "(", "vec_hyp", "[", "n", "]", "[", "ngram", "]", ",", "vec_ref", "[", "n", "]", "[", "ngram", "]", ")", "*", "vec_ref", "[", "n", "]", "[", "ngram", "]", "\n", "\n", "", "if", "(", "norm_hyp", "[", "n", "]", "!=", "0", ")", "and", "(", "norm_ref", "[", "n", "]", "!=", "0", ")", ":", "\n", "                    ", "val", "[", "n", "]", "/=", "(", "norm_hyp", "[", "n", "]", "*", "norm_ref", "[", "n", "]", ")", "\n", "\n", "", "assert", "(", "not", "math", ".", "isnan", "(", "val", "[", "n", "]", ")", ")", "\n", "# vrama91: added a length based gaussian penalty", "\n", "val", "[", "n", "]", "*=", "np", ".", "e", "**", "(", "-", "(", "delta", "**", "2", ")", "/", "(", "2", "*", "self", ".", "sigma", "**", "2", ")", ")", "\n", "", "return", "val", "\n", "\n", "# compute log reference length", "\n", "", "if", "self", ".", "df_mode", "==", "\"corpus\"", ":", "\n", "            ", "self", ".", "ref_len", "=", "np", ".", "log", "(", "float", "(", "len", "(", "self", ".", "crefs", ")", ")", ")", "\n", "#elif self.df_mode == \"coco-val-df\":", "\n", "# if coco option selected, use length of coco-val set", "\n", "#    self.ref_len = np.log(float(40504))", "\n", "\n", "", "scores", "=", "[", "]", "\n", "for", "test", ",", "refs", "in", "zip", "(", "self", ".", "ctest", ",", "self", ".", "crefs", ")", ":", "\n", "# compute vector for test captions", "\n", "            ", "vec", ",", "norm", ",", "length", "=", "counts2vec", "(", "test", ")", "\n", "# compute vector for ref captions", "\n", "score", "=", "np", ".", "array", "(", "[", "0.0", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", ")", "\n", "for", "ref", "in", "refs", ":", "\n", "                ", "vec_ref", ",", "norm_ref", ",", "length_ref", "=", "counts2vec", "(", "ref", ")", "\n", "score", "+=", "sim", "(", "vec", ",", "vec_ref", ",", "norm", ",", "norm_ref", ",", "length", ",", "length_ref", ")", "\n", "# change by vrama91 - mean of ngram scores, instead of sum", "\n", "", "score_avg", "=", "np", ".", "mean", "(", "score", ")", "\n", "# divide by number of references", "\n", "score_avg", "/=", "len", "(", "refs", ")", "\n", "# multiply score by 10", "\n", "score_avg", "*=", "10.0", "\n", "# append score of an image to the score list", "\n", "scores", ".", "append", "(", "score_avg", ")", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.compute_score": [[210, 223], ["ciderD_scorer.CiderScorer.compute_cider", "collections.defaultdict", "ciderD_scorer.CiderScorer.compute_doc_freq", "numpy.mean", "numpy.array", "len", "max", "numpy.array", "ciderD_scorer.CiderScorer.document_frequency.values"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.compute_cider", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.compute_doc_freq"], ["", "def", "compute_score", "(", "self", ",", "option", "=", "None", ",", "verbose", "=", "0", ")", ":", "\n", "# compute idf", "\n", "        ", "if", "self", ".", "df_mode", "==", "\"corpus\"", ":", "\n", "            ", "self", ".", "document_frequency", "=", "defaultdict", "(", "float", ")", "\n", "self", ".", "compute_doc_freq", "(", ")", "\n", "# assert to check document frequency", "\n", "assert", "(", "len", "(", "self", ".", "ctest", ")", ">=", "max", "(", "self", ".", "document_frequency", ".", "values", "(", ")", ")", ")", "\n", "# import json for now and write the corresponding files", "\n", "# compute cider score", "\n", "", "score", "=", "self", ".", "compute_cider", "(", ")", "\n", "# debug", "\n", "# print score", "\n", "return", "np", ".", "mean", "(", "np", ".", "array", "(", "score", ")", ")", ",", "np", ".", "array", "(", "score", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.precook": [[17, 33], ["s.split", "collections.defaultdict", "range", "range", "tuple", "len"], "function", ["None"], ["def", "precook", "(", "s", ",", "n", "=", "4", ",", "out", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Takes a string as input and returns an object that can be given to\n    either cook_refs or cook_test. This is optional: cook_refs and cook_test\n    can take string arguments as well.\n    :param s: string : sentence to be converted into ngrams\n    :param n: int    : number of ngrams for which representation is calculated\n    :return: term frequency vector for occuring ngrams\n    \"\"\"", "\n", "words", "=", "s", ".", "split", "(", ")", "\n", "counts", "=", "defaultdict", "(", "int", ")", "\n", "for", "k", "in", "range", "(", "1", ",", "n", "+", "1", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "words", ")", "-", "k", "+", "1", ")", ":", "\n", "            ", "ngram", "=", "tuple", "(", "words", "[", "i", ":", "i", "+", "k", "]", ")", "\n", "counts", "[", "ngram", "]", "+=", "1", "\n", "", "", "return", "counts", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.cook_refs": [[34, 43], ["ciderD_scorer.precook"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.precook"], ["", "def", "cook_refs", "(", "refs", ",", "n", "=", "4", ")", ":", "## lhuang: oracle will call with \"average\"", "\n", "    ", "'''Takes a list of reference sentences for a single segment\n    and returns an object that encapsulates everything that BLEU\n    needs to know about them.\n    :param refs: list of string : reference sentences for some image\n    :param n: int : number of ngrams for which (ngram) representation is calculated\n    :return: result (list of dict)\n    '''", "\n", "return", "[", "precook", "(", "ref", ",", "n", ")", "for", "ref", "in", "refs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.cook_test": [[44, 52], ["ciderD_scorer.precook"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.precook"], ["", "def", "cook_test", "(", "test", ",", "n", "=", "4", ")", ":", "\n", "    ", "'''Takes a test sentence and returns an object that\n    encapsulates everything that BLEU needs to know about it.\n    :param test: list of string : hypothesis sentence for some image\n    :param n: int : number of ngrams for which (ngram) representation is calculated\n    :return: result (dict)\n    '''", "\n", "return", "precook", "(", "test", ",", "n", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD.CiderD.__init__": [[21, 29], ["ciderD_scorer.CiderScorer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "n", "=", "4", ",", "sigma", "=", "6.0", ",", "df", "=", "\"corpus\"", ")", ":", "\n", "# set cider to sum over 1 to 4-grams", "\n", "        ", "self", ".", "_n", "=", "n", "\n", "# set the standard deviation parameter for gaussian penalty", "\n", "self", ".", "_sigma", "=", "sigma", "\n", "# set which where to compute document frequencies from", "\n", "self", ".", "_df", "=", "df", "\n", "self", ".", "cider_scorer", "=", "CiderScorer", "(", "n", "=", "self", ".", "_n", ",", "df_mode", "=", "self", ".", "_df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD.CiderD.compute_score": [[30, 56], ["ciderD.CiderD.cider_scorer.copy_empty", "ciderD.CiderD.clear", "ciderD.CiderD.compute_score", "type", "len", "type", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.copy_empty", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.clear", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD.CiderD.compute_score"], ["", "def", "compute_score", "(", "self", ",", "gts", ",", "res", ")", ":", "\n", "        ", "\"\"\"\n        Main function to compute CIDEr score\n        :param  hypo_for_image (dict) : dictionary with key <image> and value <tokenized hypothesis / candidate sentence>\n                ref_for_image (dict)  : dictionary with key <image> and value <tokenized reference sentence>\n        :return: cider (float) : computed CIDEr score for the corpus\n        \"\"\"", "\n", "\n", "# clear all the previous hypos and refs", "\n", "tmp_cider_scorer", "=", "self", ".", "cider_scorer", ".", "copy_empty", "(", ")", "\n", "tmp_cider_scorer", ".", "clear", "(", ")", "\n", "for", "res_id", "in", "res", ":", "\n", "\n", "            ", "hypo", "=", "res_id", "[", "'caption'", "]", "\n", "ref", "=", "gts", "[", "res_id", "[", "'image_id'", "]", "]", "\n", "\n", "# Sanity check.", "\n", "assert", "(", "type", "(", "hypo", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "hypo", ")", "==", "1", ")", "\n", "assert", "(", "type", "(", "ref", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "ref", ")", ">", "0", ")", "\n", "tmp_cider_scorer", "+=", "(", "hypo", "[", "0", "]", ",", "ref", ")", "\n", "\n", "", "(", "score", ",", "scores", ")", "=", "tmp_cider_scorer", ".", "compute_score", "(", ")", "\n", "\n", "return", "score", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD.CiderD.method": [[57, 59], ["None"], "methods", ["None"], ["", "def", "method", "(", "self", ")", ":", "\n", "        ", "return", "\"CIDEr-D\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.__init__": [[17, 196], ["oscar.utils.misc.load_from_yaml_file", "os.path.dirname", "oscar.utils.tsv_file.TSVFile", "oscar_tsv.OscarTSVDataset.cfg[].split", "logging.info", "oscar_tsv.OscarTSVDataset.image_label_path.items", "time.time", "oscar_tsv.OscarTSVDataset.load_img_labels", "oscar_tsv.OscarTSVDataset.load_img_tsv_features", "time.time", "logging.info", "logging.info", "logging.info", "os.path.join", "oscar_tsv.OscarTSVDataset.image_feature_path.items", "logging.info", "tqdm.tqdm.tqdm", "len", "logging.info", "ValueError", "os.path.join", "str", "range", "oscar_tsv.OscarTSVDataset.corpus_tsvfile.seek", "row[].split", "row[].split", "doc.append", "oscar_tsv.OscarTSVDataset.sample_to_doc.append", "doc.append", "json.loads", "doc.append", "max", "oscar_tsv.OscarTSVDataset.all_docs.append", "len", "os.path.join", "logging.info", "range", "len", "len", "len", "len", "oscar_tsv.OscarTSVDataset.img_qa_file[].seek", "oscar_tsv.OscarTSVDataset.img_label_file[].seek", "oscar_tsv.OscarTSVDataset.img_label_file[].seek", "json.loads", "len", "oscar_tsv.OscarTSVDataset.all_qa_docs.append", "len", "len", "doc[].split", "doc[].split", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.load_from_yaml_file", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.load_img_labels", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.load_img_tsv_features", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek"], ["    ", "def", "__init__", "(", "self", ",", "yaml_file", ",", "args", "=", "None", ",", "tokenizer", "=", "None", ",", "seq_len", "=", "35", ",", "\n", "encoding", "=", "\"utf-8\"", ",", "corpus_lines", "=", "None", ",", "on_memory", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "cfg", "=", "load_from_yaml_file", "(", "yaml_file", ")", "\n", "self", ".", "root", "=", "os", ".", "path", ".", "dirname", "(", "yaml_file", ")", "\n", "self", ".", "vocab", "=", "tokenizer", ".", "vocab", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "seq_len", "=", "seq_len", "\n", "self", ".", "on_memory", "=", "on_memory", "\n", "self", ".", "corpus_lines", "=", "corpus_lines", "# number of non-empty lines in input corpus", "\n", "self", ".", "corpus_tsvfile", "=", "TSVFile", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "cfg", "[", "'corpus_file'", "]", ")", ")", "\n", "if", "'textb_sample_mode'", "in", "kwargs", ":", "\n", "            ", "self", ".", "textb_sample_mode", "=", "kwargs", "[", "'textb_sample_mode'", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "textb_sample_mode", "=", "args", ".", "textb_sample_mode", "\n", "\n", "", "self", ".", "datasets_names", "=", "self", ".", "cfg", "[", "'corpus'", "]", ".", "split", "(", "'_'", ")", "\n", "self", ".", "datasets_with_splits", "=", "[", "'googlecc'", ",", "'sbu'", ",", "'oi'", ",", "'objects365'", ",", "'tagoi'", "]", "\n", "self", ".", "datasets_with_onesplit", "=", "[", "'coco'", ",", "'flickr30k'", ",", "'gqa'", "]", "\n", "logging", ".", "info", "(", "'Datasets: {}'", ".", "format", "(", "','", ".", "join", "(", "self", ".", "datasets_names", ")", ")", ")", "\n", "self", ".", "image_label_path", "=", "self", ".", "cfg", "[", "'image_label_path'", "]", "\n", "for", "key", ",", "val", "in", "self", ".", "image_label_path", ".", "items", "(", ")", ":", "\n", "# get the absolute path", "\n", "            ", "if", "key", "in", "self", ".", "datasets_names", ":", "\n", "                ", "self", ".", "image_label_path", "[", "key", "]", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "val", ")", "\n", "", "", "self", ".", "image_feature_path", "=", "self", ".", "cfg", "[", "'image_feature_path'", "]", "\n", "self", ".", "image_file_name", "=", "'features.tsv'", "\n", "if", "args", ".", "data_dir", "is", "not", "None", ":", "\n", "            ", "for", "key", ",", "val", "in", "self", ".", "image_feature_path", ".", "items", "(", ")", ":", "\n", "# get the absolute path", "\n", "                ", "if", "key", "in", "self", ".", "datasets_names", ":", "\n", "                    ", "self", ".", "image_feature_path", "[", "key", "]", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\n", "val", ")", "\n", "", "else", ":", "\n", "                    ", "logging", ".", "info", "(", "\"Data {} with path {} is not used in the \"", "\n", "\"training.\"", ".", "format", "(", "key", ",", "val", ")", ")", "\n", "", "", "", "self", ".", "encoding", "=", "encoding", "\n", "self", ".", "current_doc", "=", "0", "# to avoid random sentence from same doc", "\n", "self", ".", "current_img", "=", "''", "# to avoid random sentence from same image", "\n", "\n", "self", ".", "args", "=", "args", "\n", "\n", "# for loading samples directly from file", "\n", "self", ".", "sample_counter", "=", "0", "# used to keep track of full epochs on file", "\n", "self", ".", "line_buffer", "=", "None", "# keep second sentence of a pair in memory and use as first sentence in next pair", "\n", "\n", "# for loading samples in memory", "\n", "self", ".", "current_random_doc", "=", "0", "\n", "self", ".", "num_docs", "=", "0", "\n", "self", ".", "sample_to_doc", "=", "[", "]", "# map sample index to doc and line", "\n", "\n", "self", ".", "chunk_list", "=", "None", "\n", "if", "0", "<=", "args", ".", "chunk_start_id", "<=", "args", ".", "chunk_end_id", "and", "args", ".", "chunk_end_id", ">=", "0", ":", "\n", "            ", "self", ".", "chunk_list", "=", "[", "str", "(", "c_i", ")", "for", "c_i", "in", "range", "(", "args", ".", "chunk_start_id", ",", "\n", "args", ".", "chunk_end_id", ")", "]", "\n", "logging", ".", "info", "(", "'Chunk list: {}'", ".", "format", "(", "','", ".", "join", "(", "self", ".", "chunk_list", ")", ")", ")", "\n", "\n", "# load image tags and features", "\n", "", "t_start", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "img_label_file", "=", "None", "\n", "self", ".", "img_qa_file", "=", "None", "\n", "self", ".", "img_label_offset_map", "=", "None", "\n", "self", ".", "img_qa_offset_map", "=", "None", "\n", "self", ".", "img_feature_file", "=", "None", "\n", "self", ".", "img_feat_offset_map", "=", "None", "\n", "self", ".", "load_img_labels", "(", ")", "\n", "self", ".", "load_img_tsv_features", "(", ")", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "logging", ".", "info", "(", "'Info: loading img features using {} secs'", "\n", ".", "format", "(", "t_end", "-", "t_start", ")", ")", "\n", "\n", "# load samples into memory", "\n", "if", "on_memory", ":", "\n", "            ", "self", ".", "all_docs", "=", "[", "]", "\n", "self", ".", "all_qa_docs", "=", "[", "]", "\n", "self", ".", "imgid2labels", "=", "{", "}", "\n", "self", ".", "corpus_lines", "=", "0", "\n", "max_tokens", "=", "0", "\n", "for", "line_no", "in", "tqdm", "(", "range", "(", "len", "(", "self", ".", "corpus_tsvfile", ")", ")", ")", ":", "\n", "                ", "doc", "=", "[", "]", "\n", "row", "=", "self", ".", "corpus_tsvfile", ".", "seek", "(", "line_no", ")", "\n", "img_info", "=", "row", "[", "0", "]", ".", "split", "(", "'_'", ")", "\n", "label_info", "=", "row", "[", "1", "]", ".", "split", "(", "'_'", ")", "\n", "assert", "img_info", "[", "0", "]", "==", "label_info", "[", "\n", "0", "]", ",", "\"Dataset names for image and label do not match!\"", "\n", "dataset_name", "=", "label_info", "[", "0", "]", "\n", "if", "dataset_name", "==", "'cc'", ":", "\n", "                    ", "dataset_name", "=", "'googlecc'", "\n", "\n", "", "if", "dataset_name", "not", "in", "self", ".", "datasets_names", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "dataset_name", "in", "self", ".", "datasets_with_splits", ":", "\n", "                    ", "chunk_id", "=", "img_info", "[", "-", "2", "]", "\n", "if", "self", ".", "chunk_list", "is", "not", "None", "and", "chunk_id", "not", "in", "self", ".", "chunk_list", ":", "\n", "                        ", "continue", "\n", "", "else", ":", "\n", "                        ", "img_feat_offset_map", "=", "self", ".", "img_feat_offset_map", "[", "dataset_name", "]", "[", "chunk_id", "]", "\n", "", "", "else", ":", "\n", "                    ", "img_feat_offset_map", "=", "self", ".", "img_feat_offset_map", "[", "dataset_name", "]", "\n", "", "assert", "img_info", "[", "-", "1", "]", "in", "img_feat_offset_map", ",", "\"{}: Image id {} cannot be found in image feature imageid_to_index file!\"", ".", "format", "(", "row", "[", "0", "]", ",", "img_info", "[", "-", "1", "]", ")", "\n", "\n", "# append id info", "\n", "doc", ".", "append", "(", "'%s|%s'", "%", "(", "row", "[", "0", "]", ",", "row", "[", "1", "]", ")", ")", "\n", "# append text_a info", "\n", "self", ".", "corpus_lines", "=", "self", ".", "corpus_lines", "+", "1", "\n", "sample", "=", "{", "\"doc_id\"", ":", "len", "(", "self", ".", "all_docs", ")", ",", "\"line\"", ":", "len", "(", "doc", ")", "}", "\n", "self", ".", "sample_to_doc", ".", "append", "(", "sample", ")", "\n", "assert", "len", "(", "row", "[", "2", "]", ")", "!=", "0", ",", "\"Text_a is empty in {} : {}\"", ".", "format", "(", "dataset_name", ",", "row", "[", "0", "]", ")", "\n", "doc", ".", "append", "(", "row", "[", "2", "]", ")", "\n", "# append text_b info", "\n", "self", ".", "corpus_lines", "=", "self", ".", "corpus_lines", "+", "1", "\n", "label_id", "=", "label_info", "[", "-", "1", "]", "\n", "if", "'qa'", "in", "label_info", ":", "\n", "                    ", "assert", "img_info", "[", "-", "1", "]", "==", "label_info", "[", "\n", "-", "2", "]", ",", "\"Image ids for image and qa do not match!\"", "\n", "label_line_no", "=", "self", ".", "img_qa_offset_map", "[", "dataset_name", "]", "[", "label_id", "]", "\n", "rowb", "=", "self", ".", "img_qa_file", "[", "dataset_name", "]", ".", "seek", "(", "label_line_no", ")", "\n", "", "else", ":", "\n", "                    ", "assert", "img_info", "[", "-", "1", "]", "==", "label_info", "[", "\n", "-", "1", "]", ",", "\"Image ids for image and label do not match!\"", "\n", "label_line_no", "=", "self", ".", "img_label_offset_map", "[", "dataset_name", "]", "[", "label_id", "]", "\n", "rowb", "=", "self", ".", "img_label_file", "[", "dataset_name", "]", ".", "seek", "(", "label_line_no", ")", "\n", "", "assert", "label_id", "==", "rowb", "[", "0", "]", "\n", "results", "=", "json", ".", "loads", "(", "rowb", "[", "1", "]", ")", "\n", "if", "'qa'", "not", "in", "label_info", ":", "# more intuitively, should be if 'qa' not in label_info:", "\n", "                    ", "objects", "=", "results", "[", "'objects'", "]", "\n", "if", "row", "[", "0", "]", "not", "in", "self", ".", "imgid2labels", ":", "\n", "                        ", "self", ".", "imgid2labels", "[", "row", "[", "0", "]", "]", "=", "{", "\n", "\"image_h\"", ":", "results", "[", "\"image_h\"", "]", ",", "\"image_w\"", ":", "results", "[", "\"image_w\"", "]", ",", "\n", "\"boxes\"", ":", "None", "\n", "}", "\n", "", "else", ":", "\n", "                        ", "assert", "results", "[", "\"image_h\"", "]", "==", "self", ".", "imgid2labels", "[", "row", "[", "0", "]", "]", "[", "\n", "\"image_h\"", "]", ",", "\"Image_h does not match in image {}!\"", ".", "format", "(", "row", "[", "0", "]", ")", "\n", "assert", "results", "[", "\"image_w\"", "]", "==", "self", ".", "imgid2labels", "[", "row", "[", "0", "]", "]", "[", "\n", "\"image_w\"", "]", ",", "\"Image_w does not match in image {}!\"", ".", "format", "(", "row", "[", "0", "]", ")", "\n", "", "if", "args", ".", "use_gtlabels", "and", "'gt_objects'", "in", "results", ":", "\n", "# use ground-truth tags for text_b", "\n", "                        ", "textb", "=", "' '", ".", "join", "(", "[", "cur_d", "[", "'class'", "]", "for", "cur_d", "in", "results", "[", "\"gt_objects\"", "]", "]", ")", "\n", "", "else", ":", "\n", "                        ", "textb", "=", "' '", ".", "join", "(", "[", "cur_d", "[", "'class'", "]", "for", "cur_d", "in", "objects", "]", ")", "\n", "", "", "else", ":", "\n", "                    ", "tag_label_line_no", "=", "self", ".", "img_label_offset_map", "[", "dataset_name", "]", "[", "img_info", "[", "-", "1", "]", "]", "\n", "tag_rowb", "=", "self", ".", "img_label_file", "[", "dataset_name", "]", ".", "seek", "(", "tag_label_line_no", ")", "\n", "tag_results", "=", "json", ".", "loads", "(", "tag_rowb", "[", "1", "]", ")", "\n", "if", "row", "[", "0", "]", "not", "in", "self", ".", "imgid2labels", ":", "\n", "                        ", "self", ".", "imgid2labels", "[", "row", "[", "0", "]", "]", "=", "{", "\n", "\"image_h\"", ":", "tag_results", "[", "\"image_h\"", "]", ",", "\"image_w\"", ":", "tag_results", "[", "\"image_w\"", "]", ",", "\n", "\"boxes\"", ":", "None", "\n", "}", "\n", "", "else", ":", "\n", "                        ", "assert", "tag_results", "[", "\"image_h\"", "]", "==", "self", ".", "imgid2labels", "[", "row", "[", "0", "]", "]", "[", "\n", "\"image_h\"", "]", ",", "\"Image_h does not match in image {}!\"", ".", "format", "(", "row", "[", "0", "]", ")", "\n", "assert", "tag_results", "[", "\"image_w\"", "]", "==", "self", ".", "imgid2labels", "[", "row", "[", "0", "]", "]", "[", "\n", "\"image_w\"", "]", ",", "\"Image_w does not match in image {}!\"", ".", "format", "(", "row", "[", "0", "]", ")", "\n", "", "textb", "=", "' '", ".", "join", "(", "results", "[", "'labels'", "]", ")", "\n", "", "assert", "len", "(", "textb", ")", "!=", "0", ",", "\"Text_b is empty in {} : {}\"", ".", "format", "(", "dataset_name", ",", "row", "[", "1", "]", ")", "\n", "doc", ".", "append", "(", "textb", ")", "\n", "\n", "# add to all_docs", "\n", "max_tokens", "=", "max", "(", "max_tokens", ",", "len", "(", "doc", "[", "1", "]", ".", "split", "(", "' '", ")", ")", "\n", "+", "len", "(", "doc", "[", "2", "]", ".", "split", "(", "' '", ")", ")", ")", "\n", "if", "'qa'", "in", "label_info", ":", "\n", "                    ", "self", ".", "all_qa_docs", ".", "append", "(", "{", "\"doc\"", ":", "doc", ",", "\"doc_id\"", ":", "len", "(", "self", ".", "all_docs", ")", "}", ")", "\n", "", "self", ".", "all_docs", ".", "append", "(", "doc", ")", "\n", "\n", "", "self", ".", "num_docs", "=", "len", "(", "self", ".", "all_docs", ")", "\n", "logging", ".", "info", "(", "\"Max_tokens: {}\"", ".", "format", "(", "max_tokens", ")", ")", "\n", "# load samples later lazily from disk", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"on_memory = False Not supported yet!\"", ")", "\n", "\n", "", "logging", ".", "info", "(", "\n", "\"Total docs - Corpus_lines: {}-{}\"", ".", "format", "(", "self", ".", "num_docs", ",", "\n", "self", ".", "corpus_lines", ")", ")", "\n", "logging", ".", "info", "(", "\n", "\"Total QA docs - Corpus_lines: {}\"", ".", "format", "(", "len", "(", "self", ".", "all_qa_docs", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.__len__": [[198, 201], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "# last line of doc won't be used, because there's no \"nextSentence\".", "\n", "        ", "return", "self", ".", "corpus_lines", "-", "self", ".", "num_docs", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.get_img_info": [[202, 208], ["[].strip().split", "[].strip"], "methods", ["None"], ["", "def", "get_img_info", "(", "self", ",", "idx", ")", ":", "\n", "        ", "sample", "=", "self", ".", "sample_to_doc", "[", "idx", "]", "\n", "# img_id = self.all_docs[sample[\"doc_id\"]][0].strip() # original", "\n", "img_id", "=", "self", ".", "all_docs", "[", "sample", "[", "\"doc_id\"", "]", "]", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", "'|'", ")", "[", "0", "]", "\n", "imgid2labels", "=", "self", ".", "imgid2labels", "[", "img_id", "]", "\n", "return", "{", "\"height\"", ":", "imgid2labels", "[", "\"image_h\"", "]", ",", "\"width\"", ":", "imgid2labels", "[", "\"image_w\"", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.__getitem__": [[209, 254], ["oscar_tsv.OscarTSVDataset.random_sent", "oscar_tsv.OscarTSVDataset.tokenizer.tokenize", "oscar_tsv.InputExample", "oscar_tsv.OscarTSVDataset.get_img_feature", "oscar_tsv.convert_example_to_features", "oscar_tsv.OscarTSVDataset.tokenizer.tokenize", "torch.zeros", "torch.cat", "ValueError", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.random_sent", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.get_img_feature", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.convert_example_to_features"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "cur_id", "=", "self", ".", "sample_counter", "\n", "self", ".", "sample_counter", "+=", "1", "\n", "if", "not", "self", ".", "on_memory", ":", "\n", "# after one epoch we start again from beginning of file", "\n", "            ", "if", "cur_id", "!=", "0", "and", "(", "cur_id", "%", "len", "(", "self", ")", "==", "0", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"on_memory = False Not supported yet!\"", ")", "\n", "\n", "", "", "img_id", ",", "t1", ",", "t2", ",", "is_next_label", ",", "is_img_match", "=", "self", ".", "random_sent", "(", "item", ")", "\n", "\n", "# tokenize", "\n", "tokens_a", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "t1", ")", "\n", "if", "self", ".", "args", ".", "use_b", ":", "\n", "            ", "tokens_b", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "t2", ")", "\n", "", "else", ":", "\n", "            ", "tokens_b", "=", "None", "\n", "\n", "# combine to one sample", "\n", "", "cur_example", "=", "InputExample", "(", "guid", "=", "cur_id", ",", "tokens_a", "=", "tokens_a", ",", "\n", "tokens_b", "=", "tokens_b", ",", "is_next", "=", "is_next_label", ",", "\n", "img_id", "=", "img_id", ",", "is_img_match", "=", "is_img_match", ")", "\n", "\n", "# get image feature", "\n", "img_feat", "=", "self", ".", "get_img_feature", "(", "img_id", ")", "\n", "if", "img_feat", ".", "shape", "[", "0", "]", ">=", "self", ".", "args", ".", "max_img_seq_length", ":", "\n", "            ", "img_feat", "=", "img_feat", "[", "0", ":", "self", ".", "args", ".", "max_img_seq_length", ",", "]", "\n", "img_feat_len", "=", "img_feat", ".", "shape", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "img_feat_len", "=", "img_feat", ".", "shape", "[", "0", "]", "\n", "padding_matrix", "=", "torch", ".", "zeros", "(", "(", "self", ".", "args", ".", "max_img_seq_length", "-", "img_feat", ".", "shape", "[", "0", "]", ",", "img_feat", ".", "shape", "[", "1", "]", ")", ")", "\n", "img_feat", "=", "torch", ".", "cat", "(", "(", "img_feat", ",", "padding_matrix", ")", ",", "0", ")", "\n", "\n", "# transform sample to features", "\n", "", "cur_features", "=", "convert_example_to_features", "(", "self", ".", "args", ",", "cur_example", ",", "\n", "self", ".", "seq_len", ",", "self", ".", "tokenizer", ",", "\n", "img_feat_len", ")", "\n", "\n", "return", "img_feat", ",", "(", "\n", "torch", ".", "tensor", "(", "cur_features", ".", "input_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "cur_features", ".", "input_mask", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "cur_features", ".", "segment_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "cur_features", ".", "lm_label_ids", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "torch", ".", "tensor", "(", "cur_features", ".", "is_next", ")", ",", "\n", "torch", ".", "tensor", "(", "cur_features", ".", "is_img_match", ")", ",", "\n", ")", ",", "item", "\n", "# return cur_tensors", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.random_sent": [[256, 284], ["oscar_tsv.OscarTSVDataset.get_corpus_line", "random.random", "len", "oscar_tsv.OscarTSVDataset.get_random_line", "oscar_tsv.OscarTSVDataset.get_random_texta", "len"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.get_corpus_line", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.get_random_line", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.get_random_texta"], ["", "def", "random_sent", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Get one sample from corpus consisting of two sentences. With prob. 50% these are two subsequent sentences\n        from one doc. With 50% the second sentence will be a random one from another doc.\n        :param index: int, index of sample.\n        :return: (str, str, int), sentence 1, sentence 2, isNextSentence Label\n        \"\"\"", "\n", "img_id", ",", "t1", ",", "t2", "=", "self", ".", "get_corpus_line", "(", "index", ")", "\n", "rand_dice", "=", "random", ".", "random", "(", ")", "\n", "if", "rand_dice", ">", "0.5", ":", "\n", "            ", "label", "=", "0", "\n", "random_img_id", "=", "img_id", "\n", "", "elif", "rand_dice", ">", "self", ".", "args", ".", "texta_false_prob", "and", "t2", "!=", "\"\"", ":", "\n", "# wrong qa triplets", "\n", "            ", "random_img_id", ",", "t2", "=", "self", ".", "get_random_line", "(", ")", "\n", "label", "=", "1", "\n", "", "else", ":", "\n", "# wrong retrieval triplets", "\n", "            ", "random_img_id", ",", "t1", "=", "self", ".", "get_random_texta", "(", ")", "\n", "# args.num_contrast_classes = 3 if args.texta_false_prob<0.5 and (args.texta_false_prob>0 or not args.use_b) else 2", "\n", "label", "=", "self", ".", "args", ".", "num_contrast_classes", "-", "1", "\n", "\n", "", "img_match_label", "=", "0", "\n", "if", "img_id", "!=", "random_img_id", ":", "img_match_label", "=", "1", "\n", "\n", "assert", "len", "(", "t1", ")", ">", "0", "\n", "assert", "len", "(", "t2", ")", ">", "0", "or", "not", "self", ".", "args", ".", "use_b", "\n", "return", "img_id", ",", "t1", ",", "t2", ",", "label", ",", "img_match_label", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.get_corpus_line": [[285, 310], ["ValueError", "[].strip().split", "[].split", "[].strip"], "methods", ["None"], ["", "def", "get_corpus_line", "(", "self", ",", "item", ")", ":", "\n", "        ", "\"\"\"\n        Get one sample from corpus consisting of a pair of two subsequent lines from the same doc.\n        :param item: int, index of sample.\n        :return: (str, str), two subsequent sentences from corpus\n        \"\"\"", "\n", "assert", "item", "<", "self", ".", "corpus_lines", "\n", "if", "self", ".", "on_memory", ":", "\n", "            ", "sample", "=", "self", ".", "sample_to_doc", "[", "item", "]", "\n", "# img_id = self.all_docs[sample[\"doc_id\"]][0].strip() # original", "\n", "img_id", "=", "self", ".", "all_docs", "[", "sample", "[", "\"doc_id\"", "]", "]", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", "'|'", ")", "[", "0", "]", "\n", "t1", "=", "self", ".", "all_docs", "[", "sample", "[", "\"doc_id\"", "]", "]", "[", "sample", "[", "\"line\"", "]", "]", "\n", "t2", "=", "self", ".", "all_docs", "[", "sample", "[", "\"doc_id\"", "]", "]", "[", "sample", "[", "\"line\"", "]", "+", "1", "]", "\n", "# used later to avoid random nextSentence from same doc", "\n", "self", ".", "current_doc", "=", "sample", "[", "\"doc_id\"", "]", "\n", "self", ".", "current_img", "=", "img_id", "\n", "\n", "assert", "t1", "!=", "\"\"", "\n", "if", "self", ".", "args", ".", "use_b", "or", "'qa'", "in", "self", ".", "all_docs", "[", "sample", "[", "\"doc_id\"", "]", "]", "[", "0", "]", ".", "split", "(", "'_'", ")", ":", "\n", "                ", "assert", "t2", "!=", "\"\"", "\n", "", "else", ":", "\n", "                ", "t2", "=", "\"\"", "\n", "", "return", "img_id", ",", "t1", ",", "t2", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"on_memory = False Not supported yet!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.get_random_line": [[311, 348], ["ValueError", "range", "range", "rand_doc[].split", "random.randrange", "random.randrange", "len", "[].split", "len", "random.randrange", "len"], "methods", ["None"], ["", "", "def", "get_random_line", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get random line from another document for nextSentence task.\n        :return: str, content of one line\n        \"\"\"", "\n", "# Similar to original tf repo: This outer loop should rarely go for more than one iteration for large", "\n", "# corpora. However, just to be careful, we try to make sure that", "\n", "# the random document is not the same as the document we're processing.", "\n", "if", "self", ".", "on_memory", ":", "\n", "            ", "if", "self", ".", "textb_sample_mode", "in", "[", "0", ",", "1", "]", ":", "\n", "# sample from all docs", "\n", "                ", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "                    ", "rand_doc_idx", "=", "random", ".", "randrange", "(", "0", ",", "len", "(", "self", ".", "all_docs", ")", ")", "\n", "img_id", "=", "self", ".", "all_docs", "[", "rand_doc_idx", "]", "[", "0", "]", ".", "split", "(", "'|'", ")", "[", "0", "]", "\n", "# check if our picked random line is really from another image like we want it to be", "\n", "if", "img_id", "!=", "self", ".", "current_img", ":", "\n", "                        ", "break", "\n", "", "", "rand_doc", "=", "self", ".", "all_docs", "[", "rand_doc_idx", "]", "\n", "", "else", ":", "\n", "# sample from all qa docs", "\n", "                ", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "                    ", "rand_doc_idx", "=", "random", ".", "randrange", "(", "0", ",", "len", "(", "self", ".", "all_qa_docs", ")", ")", "\n", "# check if our picked random line is really from another doc like we want it to be % no need to be different image here", "\n", "if", "self", ".", "all_qa_docs", "[", "rand_doc_idx", "]", "[", "\"doc_id\"", "]", "!=", "self", ".", "current_doc", ":", "\n", "                        ", "break", "\n", "", "", "rand_doc", "=", "self", ".", "all_qa_docs", "[", "rand_doc_idx", "]", "[", "\"doc\"", "]", "\n", "# img_id = rand_doc[0] # original", "\n", "", "img_id", "=", "rand_doc", "[", "0", "]", ".", "split", "(", "'|'", ")", "[", "0", "]", "\n", "if", "self", ".", "textb_sample_mode", "==", "0", ":", "\n", "# default oscar sample mode", "\n", "                ", "line", "=", "rand_doc", "[", "random", ".", "randrange", "(", "1", ",", "len", "(", "rand_doc", ")", ")", "]", "\n", "", "else", ":", "\n", "# only sample text_b", "\n", "                ", "line", "=", "rand_doc", "[", "2", "]", "\n", "", "return", "img_id", ",", "line", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"on_memory = False Not supported yet!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.get_random_texta": [[349, 371], ["range", "ValueError", "random.randrange", "rand_doc[].split", "len", "[].split"], "methods", ["None"], ["", "", "def", "get_random_texta", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get random text_a from another document for nextSentence task.\n        :return: str, content of one line\n        \"\"\"", "\n", "# Similar to original tf repo: This outer loop should rarely go for more than one iteration for large", "\n", "# corpora. However, just to be careful, we try to make sure that", "\n", "# the random document is not the same as the document we're processing.", "\n", "if", "self", ".", "on_memory", ":", "\n", "            ", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "                ", "rand_doc_idx", "=", "random", ".", "randrange", "(", "0", ",", "len", "(", "self", ".", "all_docs", ")", ")", "\n", "img_id", "=", "self", ".", "all_docs", "[", "rand_doc_idx", "]", "[", "0", "]", ".", "split", "(", "'|'", ")", "[", "0", "]", "\n", "# check if our picked random line is really from another image like we want it to be", "\n", "if", "img_id", "!=", "self", ".", "current_img", ":", "\n", "                    ", "break", "\n", "", "", "rand_doc", "=", "self", ".", "all_docs", "[", "rand_doc_idx", "]", "\n", "# img_id = rand_doc[0] # original", "\n", "img_id", "=", "rand_doc", "[", "0", "]", ".", "split", "(", "'|'", ")", "[", "0", "]", "\n", "line", "=", "rand_doc", "[", "1", "]", "# we want the text_a", "\n", "return", "img_id", ",", "line", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"on_memory = False Not supported yet!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.load_img_labels": [[373, 376], ["oscar_tsv.OscarTSVDataset.check_img_label_file", "oscar_tsv.OscarTSVDataset.check_img_label_offset_map"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_label_file", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_label_offset_map"], ["", "", "def", "load_img_labels", "(", "self", ")", ":", "\n", "        ", "self", ".", "check_img_label_file", "(", ")", "\n", "self", ".", "check_img_label_offset_map", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_label_file": [[377, 394], ["os.path.join", "os.path.join", "time.time", "oscar.utils.tsv_file.TSVFile", "os.path.exists", "time.time", "logging.info", "oscar.utils.tsv_file.TSVFile"], "methods", ["None"], ["", "def", "check_img_label_file", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "img_label_file", "is", "None", ":", "\n", "            ", "self", ".", "img_label_file", "=", "{", "}", "\n", "self", ".", "img_qa_file", "=", "{", "}", "\n", "for", "dataset_name", "in", "self", ".", "datasets_names", ":", "\n", "                ", "img_label_file_path", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "image_label_path", "[", "dataset_name", "]", ",", "'predictions_gt.tsv'", ")", "\n", "img_qa_file_path", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "image_label_path", "[", "dataset_name", "]", ",", "'QA_fileB.tsv'", ")", "\n", "t_s", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "img_label_file", "[", "dataset_name", "]", "=", "TSVFile", "(", "img_label_file_path", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "img_qa_file_path", ")", ":", "\n", "                    ", "self", ".", "img_qa_file", "[", "dataset_name", "]", "=", "TSVFile", "(", "img_qa_file_path", ")", "\n", "", "t_e", "=", "time", ".", "time", "(", ")", "\n", "logging", ".", "info", "(", "\n", "\"Open image label file {}, time: {}\"", ".", "format", "(", "\n", "img_label_file_path", ",", "(", "t_e", "-", "t_s", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_label_offset_map": [[395, 414], ["os.path.join", "os.path.join", "time.time", "json.load", "os.path.exists", "time.time", "logging.info", "open", "json.load", "open"], "methods", ["None"], ["", "", "", "def", "check_img_label_offset_map", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "img_label_offset_map", "is", "None", ":", "\n", "            ", "self", ".", "img_label_offset_map", "=", "{", "}", "\n", "self", ".", "img_qa_offset_map", "=", "{", "}", "\n", "for", "dataset_name", "in", "self", ".", "datasets_names", ":", "\n", "                ", "img_label_offset_map_path", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "image_label_path", "[", "dataset_name", "]", ",", "'imageid2idx.json'", ")", "\n", "img_qa_offset_map_path", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "image_label_path", "[", "dataset_name", "]", ",", "'QA_qaid2idx.json'", ")", "\n", "t_s", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "img_label_offset_map", "[", "dataset_name", "]", "=", "json", ".", "load", "(", "\n", "open", "(", "img_label_offset_map_path", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "img_qa_offset_map_path", ")", ":", "\n", "                    ", "self", ".", "img_qa_offset_map", "[", "dataset_name", "]", "=", "json", ".", "load", "(", "\n", "open", "(", "img_qa_offset_map_path", ")", ")", "\n", "", "t_e", "=", "time", ".", "time", "(", ")", "\n", "logging", ".", "info", "(", "\n", "\"Load img label offset map: {}, time: {}\"", ".", "format", "(", "\n", "img_label_offset_map_path", ",", "(", "t_e", "-", "t_s", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.get_img_labels": [[415, 431], ["oscar_tsv.OscarTSVDataset.check_img_label_file", "oscar_tsv.OscarTSVDataset.check_img_label_offset_map", "oscar_tsv.OscarTSVDataset.img_label_file.seek", "json.loads", "s.strip", "oscar_tsv.OscarTSVDataset.img_label_file.readline().split", "oscar_tsv.OscarTSVDataset.img_label_file.readline"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_label_file", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_label_offset_map", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek"], ["", "", "", "def", "get_img_labels", "(", "self", ",", "image_id", ")", ":", "\n", "        ", "\"\"\" decode the image labels: read the image label from the img_label.tsv \"\"\"", "\n", "self", ".", "check_img_label_file", "(", ")", "\n", "self", ".", "check_img_label_offset_map", "(", ")", "\n", "\n", "if", "image_id", "in", "self", ".", "img_label_offset_map", ":", "\n", "            ", "img_offset", "=", "self", ".", "img_label_offset_map", "[", "image_id", "]", "\n", "\n", "self", ".", "img_label_file", ".", "seek", "(", "img_offset", ",", "0", ")", "\n", "arr", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "\n", "self", ".", "img_label_file", ".", "readline", "(", ")", ".", "split", "(", "'\\t'", ")", "]", "\n", "eles", "=", "json", ".", "loads", "(", "arr", "[", "1", "]", ")", "\n", "labels", "=", "eles", "[", "'labels'", "]", "\n", "return", "labels", "\n", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.load_img_tsv_features": [[433, 436], ["oscar_tsv.OscarTSVDataset.check_img_feature_file", "oscar_tsv.OscarTSVDataset.check_img_feature_offset_map"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_feature_file", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_feature_offset_map"], ["", "def", "load_img_tsv_features", "(", "self", ")", ":", "\n", "        ", "self", ".", "check_img_feature_file", "(", ")", "\n", "self", ".", "check_img_feature_offset_map", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_feature_file": [[437, 501], ["logging.info", "logging.info", "time.time", "time.time", "logging.info", "logging.info", "glob.glob", "time.time", "oscar.utils.tsv_file.TSVFile", "os.path.join", "os.path.isfile", "json.load", "time.time", "logging.info", "time.time", "os.path.join", "oscar.utils.tsv_file.TSVFile", "os.path.join", "os.path.isfile", "json.load", "time.time", "logging.info", "ValueError", "glob.glob.append", "enumerate", "chunk_list.append", "len", "os.path.join.split", "os.path.dirname", "open", "len", "os.path.dirname", "open", "os.path.join", "zip", "os.path.exists", "os.path.join.split"], "methods", ["None"], ["", "def", "check_img_feature_file", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "img_feature_file", "is", "None", ":", "\n", "# self.img_feature_file = [] # original", "\n", "            ", "self", ".", "img_feature_file", "=", "{", "}", "\n", "self", ".", "img_feat_offset_map", "=", "{", "}", "\n", "for", "dataset_name", "in", "self", ".", "datasets_names", ":", "\n", "                ", "logging", ".", "info", "(", "\"* Loading dataset {}\"", ".", "format", "(", "dataset_name", ")", ")", "\n", "if", "dataset_name", "in", "self", ".", "datasets_with_splits", ":", "\n", "                    ", "self", ".", "img_feature_file", "[", "dataset_name", "]", "=", "{", "}", "\n", "self", ".", "img_feat_offset_map", "[", "dataset_name", "]", "=", "{", "}", "\n", "chunk_list", "=", "[", "]", "\n", "if", "self", ".", "chunk_list", "is", "not", "None", ":", "\n", "                        ", "chunk_list", "=", "self", ".", "chunk_list", "\n", "chunk_file_list", "=", "[", "]", "\n", "for", "chunk_fp_id", "in", "chunk_list", ":", "\n", "                            ", "chunk_file_list", ".", "append", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "image_feature_path", "[", "dataset_name", "]", ",", "chunk_fp_id", ",", "self", ".", "image_file_name", ")", "\n", ")", "\n", "", "if", "dataset_name", "==", "'googlecc'", ":", "\n", "                            ", "for", "i", ",", "(", "chunk_fp_id", ",", "chunk_fp", ")", "in", "enumerate", "(", "zip", "(", "chunk_list", ",", "chunk_file_list", ")", ")", ":", "\n", "                                ", "assert", "os", ".", "path", ".", "exists", "(", "chunk_file_list", "[", "i", "]", ")", ",", "\"Chunk file {} does not exists!\"", ".", "format", "(", "chunk_fp", ")", "\n", "", "", "", "else", ":", "\n", "                        ", "chunk_file_list", "=", "glob", ".", "glob", "(", "\n", "self", ".", "image_feature_path", "[", "dataset_name", "]", "+", "\"/*/{}\"", ".", "format", "(", "self", ".", "image_file_name", ")", "\n", ")", "\n", "for", "chunk_fp", "in", "chunk_file_list", ":", "\n", "                            ", "chunk_fp_id", "=", "chunk_fp", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", "\n", "chunk_list", ".", "append", "(", "chunk_fp_id", ")", "\n", "", "", "logging", ".", "info", "(", "\n", "\"* Load Image Chunks {}\"", ".", "format", "(", "len", "(", "chunk_list", ")", ")", ")", "\n", "\n", "t_s_total", "=", "time", ".", "time", "(", ")", "\n", "for", "chunk_fp", "in", "chunk_file_list", ":", "\n", "                        ", "chunk_fp_id", "=", "chunk_fp", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", "\n", "t_s", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "img_feature_file", "[", "dataset_name", "]", "[", "chunk_fp_id", "]", "=", "TSVFile", "(", "chunk_fp", ")", "\n", "chunk_offsetmap", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "chunk_fp", ")", ",", "'imageid2idx.json'", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "chunk_offsetmap", ")", ",", "\"Imageid2idx file {} does not exists!\"", ".", "format", "(", "chunk_offsetmap", ")", "\n", "self", ".", "img_feat_offset_map", "[", "dataset_name", "]", "[", "\n", "chunk_fp_id", "]", "=", "json", ".", "load", "(", "open", "(", "chunk_offsetmap", ",", "'r'", ")", ")", "\n", "t_e", "=", "time", ".", "time", "(", ")", "\n", "logging", ".", "info", "(", "\n", "\"Open image chunk {}, time: {}\"", ".", "format", "(", "\n", "chunk_fp_id", ",", "(", "t_e", "-", "t_s", ")", ")", ")", "\n", "", "t_e_total", "=", "time", ".", "time", "(", ")", "\n", "logging", ".", "info", "(", "\n", "\"Open total {} image chunks, time: {}\"", ".", "format", "(", "\n", "len", "(", "chunk_list", ")", ",", "(", "t_e_total", "-", "t_s_total", ")", ")", ")", "\n", "logging", ".", "info", "(", "\n", "\"Image chunk info: {}\"", ".", "format", "(", "'\\n'", ".", "join", "(", "chunk_file_list", ")", ")", "\n", ")", "\n", "", "elif", "dataset_name", "in", "self", ".", "datasets_with_onesplit", ":", "\n", "                    ", "t_s", "=", "time", ".", "time", "(", ")", "\n", "chunk_fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "image_feature_path", "[", "dataset_name", "]", ",", "self", ".", "image_file_name", ")", "\n", "self", ".", "img_feature_file", "[", "dataset_name", "]", "=", "TSVFile", "(", "chunk_fp", ")", "\n", "chunk_offsetmap", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "chunk_fp", ")", ",", "'imageid2idx.json'", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "chunk_offsetmap", ")", ",", "\"Imageid2idx file {} does not exists!\"", ".", "format", "(", "chunk_offsetmap", ")", "\n", "self", ".", "img_feat_offset_map", "[", "dataset_name", "]", "=", "json", ".", "load", "(", "open", "(", "chunk_offsetmap", ",", "'r'", ")", ")", "\n", "t_e", "=", "time", ".", "time", "(", ")", "\n", "logging", ".", "info", "(", "\n", "\"Open dataset {}, time: {}\"", ".", "format", "(", "\n", "chunk_fp", ",", "(", "t_e", "-", "t_s", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\"Not supported dataset: {}\"", ".", "format", "(", "dataset_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_feature_offset_map": [[502, 547], ["logging.info", "glob.glob", "logging.info", "time.time", "time.time", "logging.info", "chunk_list.append", "time.time", "json.load", "time.time", "logging.info", "time.time", "json.load", "time.time", "logging.info", "ValueError", "chunk_fp.split", "len", "chunk_fp.split", "open", "len", "open"], "methods", ["None"], ["", "", "", "", "def", "check_img_feature_offset_map", "(", "self", ")", ":", "\n", "        ", "\"\"\" load the image feature offset map \"\"\"", "\n", "if", "self", ".", "img_feat_offset_map", "is", "None", ":", "\n", "            ", "self", ".", "img_feat_offset_map", "=", "{", "}", "\n", "for", "dataset_name", "in", "self", ".", "datasets_names", ":", "\n", "                ", "logging", ".", "info", "(", "\"* Loading imageid2idx_map {}\"", ".", "format", "(", "dataset_name", ")", ")", "\n", "if", "dataset_name", "in", "self", ".", "datasets_with_splits", ":", "\n", "                    ", "chunk_list", "=", "[", "]", "\n", "chunk_file_list", "=", "glob", ".", "glob", "(", "\n", "self", ".", "image_feature_path", "[", "\n", "dataset_name", "]", "+", "\"/*/imageid2idx.json\"", "\n", ")", "\n", "for", "chunk_fp", "in", "chunk_file_list", ":", "\n", "                        ", "chunk_fp_id", "=", "chunk_fp", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", "\n", "chunk_list", ".", "append", "(", "chunk_fp_id", ")", "\n", "", "logging", ".", "info", "(", "\n", "\"* Load Image Chunks {}\"", ".", "format", "(", "len", "(", "chunk_list", ")", ")", ")", "\n", "\n", "t_s_total", "=", "time", ".", "time", "(", ")", "\n", "for", "chunk_fp", "in", "chunk_file_list", ":", "\n", "                        ", "chunk_fp_id", "=", "chunk_fp", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", "\n", "t_s", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "img_feat_offset_map", "[", "dataset_name", "]", "[", "\n", "chunk_fp_id", "]", "=", "json", ".", "load", "(", "open", "(", "chunk_fp", ")", ")", "\n", "t_e", "=", "time", ".", "time", "(", ")", "\n", "logging", ".", "info", "(", "\n", "\"Open image chunk {}, time: {}\"", ".", "format", "(", "\n", "chunk_fp_id", ",", "(", "t_e", "-", "t_s", ")", ")", ")", "\n", "", "t_e_total", "=", "time", ".", "time", "(", ")", "\n", "logging", ".", "info", "(", "\n", "\"Open total {} image chunks, time: {}\"", ".", "format", "(", "\n", "len", "(", "chunk_list", ")", ",", "(", "t_e_total", "-", "t_s_total", ")", ")", ")", "\n", "", "elif", "dataset_name", "in", "self", ".", "datasets_with_onesplit", ":", "\n", "                    ", "t_s", "=", "time", ".", "time", "(", ")", "\n", "chunk_fp", "=", "self", ".", "image_feature_path", "[", "\n", "dataset_name", "]", "+", "\"/imageid2idx.json\"", "\n", "self", ".", "img_feat_offset_map", "[", "dataset_name", "]", "=", "json", ".", "load", "(", "\n", "open", "(", "chunk_fp", ")", ")", "\n", "t_e", "=", "time", ".", "time", "(", ")", "\n", "logging", ".", "info", "(", "\n", "\"Open dataset {}, time: {}\"", ".", "format", "(", "\n", "chunk_fp", ",", "(", "t_e", "-", "t_s", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Not supported dataset: {}\"", ".", "format", "(", "dataset_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.get_img_feature": [[548, 576], ["oscar_tsv.OscarTSVDataset.check_img_feature_file", "oscar_tsv.OscarTSVDataset.check_img_feature_offset_map", "image_id.split", "img_feature_file.seek", "int", "numpy.frombuffer().reshape", "torch.from_numpy", "numpy.frombuffer", "base64.b64decode"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_feature_file", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.OscarTSVDataset.check_img_feature_offset_map", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.tsv_file.TSVFile.seek"], ["", "", "", "", "def", "get_img_feature", "(", "self", ",", "image_id", ")", ":", "\n", "        ", "\"\"\" decode the image feature: read the image feature from the right chunk id \"\"\"", "\n", "self", ".", "check_img_feature_file", "(", ")", "\n", "self", ".", "check_img_feature_offset_map", "(", ")", "\n", "img_infos", "=", "image_id", ".", "split", "(", "'_'", ")", "\n", "dataset_name", "=", "img_infos", "[", "0", "]", "\n", "if", "dataset_name", "==", "'cc'", ":", "\n", "            ", "dataset_name", "=", "'googlecc'", "\n", "", "img_id", "=", "img_infos", "[", "-", "1", "]", "\n", "if", "dataset_name", "in", "self", ".", "datasets_with_splits", ":", "\n", "            ", "chunk_id", "=", "img_infos", "[", "-", "2", "]", "\n", "img_feat_offset_map", "=", "self", ".", "img_feat_offset_map", "[", "dataset_name", "]", "[", "chunk_id", "]", "\n", "img_feature_file", "=", "self", ".", "img_feature_file", "[", "dataset_name", "]", "[", "chunk_id", "]", "\n", "", "else", ":", "\n", "            ", "img_feat_offset_map", "=", "self", ".", "img_feat_offset_map", "[", "dataset_name", "]", "\n", "img_feature_file", "=", "self", ".", "img_feature_file", "[", "dataset_name", "]", "\n", "", "if", "img_id", "in", "img_feat_offset_map", ":", "\n", "            ", "img_offset", "=", "img_feat_offset_map", "[", "img_id", "]", "\n", "\n", "arr", "=", "img_feature_file", ".", "seek", "(", "img_offset", ")", "\n", "num_boxes", "=", "int", "(", "arr", "[", "1", "]", ")", "\n", "feat", "=", "np", ".", "frombuffer", "(", "base64", ".", "b64decode", "(", "arr", "[", "-", "1", "]", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "\n", "(", "num_boxes", ",", "self", ".", "args", ".", "img_feature_dim", ")", ")", "\n", "feat", "=", "torch", ".", "from_numpy", "(", "feat", ")", "\n", "return", "feat", "\n", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.InputExample.__init__": [[581, 602], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "tokens_a", ",", "tokens_b", "=", "None", ",", "is_next", "=", "None", ",", "\n", "lm_labels", "=", "None", ",", "img_id", "=", "None", ",", "is_img_match", "=", "None", ",", "\n", "img_label", "=", "None", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n\n        Args:\n            guid: Unique id for the example.\n            tokens_a: string. The untokenized text of the first sequence. For single\n            sequence tasks, only this sequence must be specified.\n            tokens_b: (Optional) string. The untokenized text of the second sequence.\n            Only must be specified for sequence pair tasks.\n        \"\"\"", "\n", "self", ".", "guid", "=", "guid", "\n", "self", ".", "tokens_a", "=", "tokens_a", "\n", "self", ".", "tokens_b", "=", "tokens_b", "\n", "self", ".", "is_next", "=", "is_next", "# nextSentence", "\n", "self", ".", "lm_labels", "=", "lm_labels", "# masked words for language model", "\n", "\n", "self", ".", "img_id", "=", "img_id", "\n", "self", ".", "is_img_match", "=", "is_img_match", "\n", "self", ".", "img_label", "=", "img_label", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.InputFeatures.__init__": [[607, 617], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "is_next", ",", "\n", "lm_label_ids", ",", "img_feat_len", ",", "is_img_match", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "is_next", "=", "is_next", "\n", "self", ".", "lm_label_ids", "=", "lm_label_ids", "\n", "\n", "self", ".", "img_feat_len", "=", "img_feat_len", "\n", "self", ".", "is_img_match", "=", "is_img_match", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.random_word": [[619, 658], ["enumerate", "random.random", "output_label.append", "output_label.append", "output_label.append", "logging.warning", "random.choice", "list", "tokenizer.vocab.items"], "function", ["None"], ["", "", "def", "random_word", "(", "tokens", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\"\n    Masking some random tokens for Language Model task with probabilities as in the original BERT paper.\n    :param tokens: list of str, tokenized sentence.\n    :param tokenizer: Tokenizer, object used for tokenization (we need it's vocab here)\n    :return: (list of str, list of int), masked tokens and related labels for LM prediction\n    \"\"\"", "\n", "output_label", "=", "[", "]", "\n", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "        ", "prob", "=", "random", ".", "random", "(", ")", "\n", "# mask token with 15% probability", "\n", "if", "prob", "<", "0.15", ":", "\n", "            ", "prob", "/=", "0.15", "\n", "\n", "# 80% randomly change token to mask token", "\n", "if", "prob", "<", "0.8", ":", "\n", "                ", "tokens", "[", "i", "]", "=", "\"[MASK]\"", "\n", "\n", "# 10% randomly change token to random token", "\n", "", "elif", "prob", "<", "0.9", ":", "\n", "                ", "tokens", "[", "i", "]", "=", "random", ".", "choice", "(", "list", "(", "tokenizer", ".", "vocab", ".", "items", "(", ")", ")", ")", "[", "0", "]", "\n", "\n", "# -> rest 10% randomly keep current token", "\n", "\n", "# append current token to output (we will predict these later)", "\n", "", "try", ":", "\n", "                ", "output_label", ".", "append", "(", "tokenizer", ".", "vocab", "[", "token", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "# For unknown words (should not occur with BPE vocab)", "\n", "                ", "output_label", ".", "append", "(", "tokenizer", ".", "vocab", "[", "\"[UNK]\"", "]", ")", "\n", "logging", ".", "warning", "(", "\n", "\"Cannot find token '{}' in vocab. Using [UNK] insetad\"", ".", "format", "(", "\n", "token", ")", ")", "\n", "", "", "else", ":", "\n", "# no masking token (will be ignored by loss function later)", "\n", "            ", "output_label", ".", "append", "(", "-", "1", ")", "\n", "\n", "", "", "return", "tokens", ",", "output_label", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.convert_example_to_features": [[660, 786], ["oscar_tsv.random_word", "tokens.append", "segment_ids.append", "tokens.append", "segment_ids.append", "tokenizer.convert_tokens_to_ids", "oscar_tsv.InputFeatures", "oscar_tsv._truncate_seq_pair", "tokens.append", "segment_ids.append", "tokens.append", "segment_ids.append", "len", "len", "tokenizer.convert_tokens_to_ids.append", "input_mask.append", "segment_ids.append", "lm_label_ids.append", "len", "len", "len", "len", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "len", "oscar_tsv.random_word", "len", "tokens.append", "segment_ids.append", "len", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.random_word", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv._truncate_seq_pair", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv.random_word"], ["", "def", "convert_example_to_features", "(", "args", ",", "example", ",", "max_seq_length", ",", "tokenizer", ",", "\n", "img_feat_len", ")", ":", "\n", "    ", "\"\"\"\n    Convert a raw sample (pair of sentences as tokenized strings) into a proper training sample with\n    IDs, LM labels, input_mask, CLS and SEP tokens etc.\n    :param args: parameter settings\n    :param img_feat_len: lens of actual img features\n    :param example: InputExample, containing sentence input as strings and is_next label\n    :param max_seq_length: int, maximum length of sequence.\n    :param tokenizer: Tokenizer\n    :return: InputFeatures, containing all inputs and labels of one sample as IDs (as used for model training)\n    \"\"\"", "\n", "\n", "tokens_a", "=", "example", ".", "tokens_a", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "tokens_b", ":", "\n", "        ", "tokens_b", "=", "example", ".", "tokens_b", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total", "\n", "# length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "        ", "if", "len", "(", "tokens_a", ")", ">", "max_seq_length", "-", "2", ":", "\n", "            ", "tokens_a", "=", "tokens_a", "[", ":", "(", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "", "is_next_type", "=", "example", ".", "is_next", "*", "example", ".", "is_img_match", "# is_img_match = 1 for mismatch images", "\n", "if", "args", ".", "num_contrast_classes", "==", "2", "and", "args", ".", "texta_false_prob", "==", "0.5", "and", "is_next_type", "==", "1", ":", "\n", "        ", "is_next_type", "=", "2", "# is_next_type 0: correct pair, 1: wrong text_b, 2: wrong text_a", "\n", "# if not args.mask_loss_for_unmatched and is_next_type == 2:", "\n", "#     t1_label = [-1]*len(tokens_a)", "\n", "# else:", "\n", "", "tokens_a", ",", "t1_label", "=", "random_word", "(", "tokens_a", ",", "tokenizer", ")", "\n", "if", "tokens_b", ":", "\n", "        ", "if", "not", "args", ".", "mask_loss_for_unmatched", "and", "is_next_type", "==", "1", ":", "\n", "            ", "t2_label", "=", "[", "-", "1", "]", "*", "len", "(", "tokens_b", ")", "\n", "", "else", ":", "\n", "            ", "tokens_b", ",", "t2_label", "=", "random_word", "(", "tokens_b", ",", "tokenizer", ")", "\n", "\n", "# concatenate lm labels and account for CLS, SEP, SEP", "\n", "", "", "if", "tokens_b", ":", "\n", "        ", "lm_label_ids", "=", "(", "[", "-", "1", "]", "+", "t1_label", "+", "[", "-", "1", "]", "+", "t2_label", "+", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "        ", "lm_label_ids", "=", "(", "[", "-", "1", "]", "+", "t1_label", "+", "[", "-", "1", "]", ")", "\n", "\n", "# The convention in BERT is:", "\n", "# (a) For sequence pairs:", "\n", "#  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]", "\n", "#  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1", "\n", "# (b) For single sequences:", "\n", "#  tokens:   [CLS] the dog is hairy . [SEP]", "\n", "#  type_ids: 0   0   0   0  0     0 0", "\n", "#", "\n", "# Where \"type_ids\" are used to indicate whether this is the first", "\n", "# sequence or the second sequence. The embedding vectors for `type=0` and", "\n", "# `type=1` were learned during pre-training and are added to the wordpiece", "\n", "# embedding vector (and position vector). This is not *strictly* necessary", "\n", "# since the [SEP] token unambigiously separates the sequences, but it makes", "\n", "# it easier for the model to learn the concept of sequences.", "\n", "#", "\n", "# For classification tasks, the first vector (corresponding to [CLS]) is", "\n", "# used as as the \"sentence vector\". Note that this only makes sense because", "\n", "# the entire model is fine-tuned.", "\n", "", "tokens", "=", "[", "]", "\n", "segment_ids", "=", "[", "]", "\n", "tokens", ".", "append", "(", "\"[CLS]\"", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "for", "token", "in", "tokens_a", ":", "\n", "        ", "tokens", ".", "append", "(", "token", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "", "tokens", ".", "append", "(", "\"[SEP]\"", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "        ", "assert", "len", "(", "tokens_b", ")", ">", "0", "\n", "for", "token", "in", "tokens_b", ":", "\n", "            ", "tokens", ".", "append", "(", "token", ")", "\n", "segment_ids", ".", "append", "(", "1", ")", "\n", "", "tokens", ".", "append", "(", "\"[SEP]\"", ")", "\n", "segment_ids", ".", "append", "(", "1", ")", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.", "\n", "input_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "while", "len", "(", "input_ids", ")", "<", "max_seq_length", ":", "\n", "        ", "input_ids", ".", "append", "(", "0", ")", "\n", "input_mask", ".", "append", "(", "0", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "lm_label_ids", ".", "append", "(", "-", "1", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "lm_label_ids", ")", "==", "max_seq_length", "\n", "\n", "# image features", "\n", "if", "args", ".", "max_img_seq_length", ">", "0", ":", "\n", "        ", "if", "img_feat_len", ">", "args", ".", "max_img_seq_length", ":", "\n", "            ", "input_mask", "=", "input_mask", "+", "[", "1", "]", "*", "img_feat_len", "\n", "", "else", ":", "\n", "            ", "input_mask", "=", "input_mask", "+", "[", "1", "]", "*", "img_feat_len", "\n", "pad_img_feat_len", "=", "args", ".", "max_img_seq_length", "-", "img_feat_len", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "]", "*", "pad_img_feat_len", ")", "\n", "\n", "", "", "lm_label_ids", "=", "lm_label_ids", "+", "[", "-", "1", "]", "*", "args", ".", "max_img_seq_length", "\n", "\n", "if", "example", ".", "guid", "<", "1", ":", "\n", "        ", "logging", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logging", ".", "info", "(", "\"guid: %s\"", "%", "example", ".", "guid", ")", "\n", "logging", ".", "info", "(", "\"tokens: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "logging", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logging", ".", "info", "(", "\"input_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logging", ".", "info", "(", "\"segment_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "logging", ".", "info", "(", "\"LM label: %s \"", "%", "lm_label_ids", ")", "\n", "logging", ".", "info", "(", "\"Is next sentence label: %s \"", "%", "example", ".", "is_next", ")", "\n", "\n", "", "features", "=", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "lm_label_ids", "=", "lm_label_ids", ",", "\n", "is_next", "=", "example", ".", "is_next", ",", "\n", "img_feat_len", "=", "img_feat_len", ",", "\n", "is_img_match", "=", "example", ".", "is_img_match", ")", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.oscar_tsv._truncate_seq_pair": [[788, 803], ["len", "len", "len", "len", "tokens_a.pop", "tokens_b.pop"], "function", ["None"], ["", "def", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_length", ")", ":", "\n", "    ", "\"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"", "\n", "\n", "# This is a simple heuristic which will always truncate the longer sequence", "\n", "# one token at a time. This makes more sense than truncating an equal percent", "\n", "# of tokens from each, since if one sequence is very short then each token", "\n", "# that's truncated likely contains more information than a longer sequence.", "\n", "while", "True", ":", "\n", "        ", "total_length", "=", "len", "(", "tokens_a", ")", "+", "len", "(", "tokens_b", ")", "\n", "if", "total_length", "<=", "max_length", ":", "\n", "            ", "break", "\n", "", "if", "len", "(", "tokens_a", ")", ">", "len", "(", "tokens_b", ")", ":", "\n", "            ", "tokens_a", ".", "pop", "(", ")", "\n", "", "else", ":", "\n", "            ", "tokens_b", ".", "pop", "(", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.build.BatchCollator.__call__": [[14, 16], ["list", "zip"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "batch", ")", ":", "\n", "        ", "return", "list", "(", "zip", "(", "*", "batch", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.build.IterationBasedBatchSampler.__init__": [[67, 71], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "batch_sampler", ",", "num_iterations", ",", "start_iter", "=", "0", ")", ":", "\n", "        ", "self", ".", "batch_sampler", "=", "batch_sampler", "\n", "self", ".", "num_iterations", "=", "num_iterations", "\n", "self", ".", "start_iter", "=", "start_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.build.IterationBasedBatchSampler.__iter__": [[72, 85], ["hasattr", "build.IterationBasedBatchSampler.batch_sampler.sampler.set_epoch"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "iteration", "=", "self", ".", "start_iter", "\n", "while", "iteration", "<=", "self", ".", "num_iterations", ":", "\n", "# if the underlying sampler has a set_epoch method, like", "\n", "# DistributedSampler, used for making each process see", "\n", "# a different split of the dataset, then set it", "\n", "            ", "if", "hasattr", "(", "self", ".", "batch_sampler", ".", "sampler", ",", "\"set_epoch\"", ")", ":", "\n", "                ", "self", ".", "batch_sampler", ".", "sampler", ".", "set_epoch", "(", "iteration", ")", "\n", "", "for", "batch", "in", "self", ".", "batch_sampler", ":", "\n", "                ", "iteration", "+=", "1", "\n", "if", "iteration", ">", "self", ".", "num_iterations", ":", "\n", "                    ", "break", "\n", "", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.build.IterationBasedBatchSampler.__len__": [[86, 88], ["None"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_iterations", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.build.build_dataset": [[18, 47], ["os.path.join", "os.path.isfile", "transformers.pytorch_transformers.BertTokenizer.from_pretrained", "dict", "oscar_tsv.OscarTSVDataset", "os.path.join", "os.path.isfile", "datasets.append", "oscar_tsv.OscarTSVDataset"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained"], ["", "", "def", "build_dataset", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        args: configuration.\n    \"\"\"", "\n", "full_yaml_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "dataset_file", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "full_yaml_file", ")", "\n", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "\n", "cfg", "=", "dict", "(", "\n", "yaml_file", "=", "full_yaml_file", ",", "\n", "args", "=", "args", ",", "\n", "seq_len", "=", "args", ".", "max_seq_length", ",", "\n", "on_memory", "=", "args", ".", "on_memory", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", ")", "\n", "# make dataset from factory", "\n", "datasets", "=", "[", "OscarTSVDataset", "(", "**", "cfg", ")", "]", "\n", "if", "args", ".", "extra_dataset_file", ":", "\n", "        ", "full_yaml_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "extra_dataset_file", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "full_yaml_file", ")", "\n", "cfg", "[", "'yaml_file'", "]", "=", "full_yaml_file", "\n", "cfg", "[", "'textb_sample_mode'", "]", "=", "args", ".", "extra_textb_sample_mode", "\n", "datasets", ".", "append", "(", "OscarTSVDataset", "(", "**", "cfg", ")", ")", "\n", "\n", "", "return", "datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.build.make_data_sampler": [[49, 59], ["torch.utils.data.distributed.DistributedSampler", "torch.utils.data.sampler.RandomSampler", "torch.utils.data.sampler.SequentialSampler"], "function", ["None"], ["", "def", "make_data_sampler", "(", "dataset", ",", "shuffle", ",", "distributed", ")", ":", "\n", "    ", "if", "distributed", ":", "\n", "        ", "return", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "\n", "dataset", ",", "shuffle", "=", "shuffle", "\n", ")", "\n", "", "if", "shuffle", ":", "\n", "        ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "RandomSampler", "(", "dataset", ")", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "SequentialSampler", "(", "dataset", ")", "\n", "", "return", "sampler", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.build.make_batch_data_sampler": [[90, 102], ["torch.utils.data.sampler.BatchSampler", "build.IterationBasedBatchSampler"], "function", ["None"], ["", "", "def", "make_batch_data_sampler", "(", "\n", "sampler", ",", "images_per_batch", ",", "num_iters", "=", "None", ",", "\n", "start_iter", "=", "0", "\n", ")", ":", "\n", "    ", "batch_sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "BatchSampler", "(", "\n", "sampler", ",", "images_per_batch", ",", "drop_last", "=", "False", "\n", ")", "\n", "if", "num_iters", "is", "not", "None", "and", "num_iters", ">=", "0", ":", "\n", "        ", "batch_sampler", "=", "IterationBasedBatchSampler", "(", "\n", "batch_sampler", ",", "num_iters", ",", "start_iter", "\n", ")", "\n", "", "return", "batch_sampler", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.build.make_data_loader": [[104, 151], ["oscar.utils.misc.get_world_size", "hasattr", "logging.getLogger", "logging.getLogger.info", "build.build_dataset", "enumerate", "build.make_data_sampler", "build.make_batch_data_sampler", "torch.utils.data.DataLoader", "data_loaders.append", "build.BatchCollator"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.get_world_size", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.build.build_dataset", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.build.make_data_sampler", "home.repos.pwc.inspect_result.cciiplab_dpt.datasets.build.make_batch_data_sampler"], ["", "def", "make_data_loader", "(", "args", ",", "is_distributed", "=", "False", ",", "arguments", "=", "None", ")", ":", "\n", "    ", "num_gpus", "=", "get_world_size", "(", ")", "\n", "# figure out start iteration", "\n", "if", "arguments", "is", "None", ":", "\n", "        ", "start_iter", "=", "0", "\n", "", "else", ":", "\n", "        ", "start_iter", "=", "arguments", "[", "'iteration'", "]", "\n", "# figure out the batchsize", "\n", "", "grad_accumulate_steps", "=", "1", "\n", "if", "hasattr", "(", "args", ",", "'gradient_accumulation_steps'", ")", ":", "\n", "        ", "grad_accumulate_steps", "=", "args", ".", "gradient_accumulation_steps", "\n", "", "assert", "(", "\n", "args", ".", "train_batch_size", "%", "grad_accumulate_steps", "==", "0", "\n", ")", ",", "\"train_batch_size ({}) must be divisible by the number \"", "\n", "\"of Gradient accumulation ({}) used.\"", ".", "format", "(", "args", ".", "train_batch_size", ",", "grad_accumulate_steps", ")", "\n", "images_per_batch", "=", "args", ".", "train_batch_size", "//", "grad_accumulate_steps", "\n", "assert", "(", "\n", "images_per_batch", "%", "num_gpus", "==", "0", "\n", ")", ",", "\"SOLVER.IMS_PER_BATCH ({}) must be divisible by the number \"", "\n", "\"of GPUs ({}) used.\"", ".", "format", "(", "images_per_batch", ",", "num_gpus", ")", "\n", "images_per_gpu", "=", "images_per_batch", "//", "num_gpus", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Train with {} images per GPU\"", ".", "format", "(", "images_per_gpu", ")", ")", "\n", "shuffle", "=", "True", "\n", "num_iters", "=", "args", ".", "max_iters", "*", "grad_accumulate_steps", "\n", "\n", "# build dataset", "\n", "datasets", "=", "build_dataset", "(", "args", ")", "\n", "\n", "data_loaders", "=", "[", "]", "\n", "for", "i", ",", "dataset", "in", "enumerate", "(", "datasets", ")", ":", "\n", "        ", "sampler", "=", "make_data_sampler", "(", "dataset", ",", "shuffle", ",", "is_distributed", ")", "\n", "\n", "batch_sampler", "=", "make_batch_data_sampler", "(", "\n", "sampler", ",", "images_per_gpu", ",", "num_iters", ",", "start_iter", "\n", ")", "\n", "num_workers", "=", "args", ".", "num_workers", "\n", "data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "batch_sampler", "=", "batch_sampler", ",", "\n", "collate_fn", "=", "BatchCollator", "(", ")", ",", "\n", "pin_memory", "=", "True", ",", "\n", ")", "\n", "data_loaders", ".", "append", "(", "data_loader", ")", "\n", "", "return", "data_loaders", "\n", "", ""]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.CaptionPreTrainedModel.__init__": [[29, 31], ["transformers.pytorch_transformers.modeling_bert.BertPreTrainedModel.__init__"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "CaptionPreTrainedModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.CaptionPreTrainedModel.prepare_inputs_for_generation": [[32, 34], ["None"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "input_ids", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "{", "\"input_ids\"", ":", "input_ids", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.CaptionPreTrainedModel._do_output_past": [[35, 45], ["hasattr", "hasattr", "len", "len"], "methods", ["None"], ["", "def", "_do_output_past", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "has_output_past", "=", "hasattr", "(", "self", ".", "config", ",", "\"output_past\"", ")", "and", "self", ".", "config", ".", "output_past", "\n", "has_mem_len", "=", "hasattr", "(", "self", ".", "config", ",", "\"mem_len\"", ")", "and", "self", ".", "config", ".", "mem_len", "\n", "\n", "if", "has_output_past", "and", "not", "has_mem_len", "and", "len", "(", "outputs", ")", ">", "1", ":", "\n", "            ", "return", "True", "\n", "", "elif", "has_mem_len", "and", "self", ".", "config", ".", "mem_len", ">", "0", "and", "len", "(", "outputs", ")", ">", "1", ":", "\n", "            ", "return", "True", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.CaptionPreTrainedModel.generate": [[46, 243], ["isinstance", "isinstance", "modeling_utils.CaptionPreTrainedModel.get_output_embeddings", "AttributeError", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "torch.full", "torch.full", "torch.full", "torch.full", "input_ids.contiguous().view.contiguous().view.unsqueeze().expand", "input_ids.contiguous().view.contiguous().view.contiguous().view", "modeling_utils.CaptionPreTrainedModel._generate_beam_search", "modeling_utils.CaptionPreTrainedModel._generate_no_beam_search", "range", "input_ids.contiguous().view.contiguous().view.dim", "len", "output[].view", "input_ids.contiguous().view.contiguous().view.unsqueeze", "input_ids.contiguous().view.contiguous().view.contiguous", "next", "modeling_utils.CaptionPreTrainedModel.parameters"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning.get_output_embeddings", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.CaptionPreTrainedModel._generate_beam_search", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.CaptionPreTrainedModel._generate_no_beam_search"], ["", "def", "generate", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "max_length", "=", "None", ",", "\n", "do_sample", "=", "None", ",", "\n", "num_beams", "=", "None", ",", "\n", "temperature", "=", "None", ",", "\n", "top_k", "=", "None", ",", "\n", "top_p", "=", "None", ",", "\n", "repetition_penalty", "=", "None", ",", "\n", "bos_token_id", "=", "None", ",", "\n", "pad_token_id", "=", "None", ",", "\n", "eos_token_ids", "=", "None", ",", "\n", "length_penalty", "=", "None", ",", "\n", "num_return_sequences", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\" Generates sequences for models with a LM head. The method currently supports greedy or penalized greedy decoding, sampling with top-k or nucleus sampling\n        and beam-search.\n\n        Adapted in part from `Facebook's XLM beam search code`_.\n\n        .. _`Facebook's XLM beam search code`:\n           https://github.com/facebookresearch/XLM/blob/9e6f6814d17be4fe5b15f2e6c43eb2b2d76daeb4/src/model/transformer.py#L529\n\n\n        Parameters:\n\n            input_ids: (`optional`) `torch.LongTensor` of shape `(batch_size, sequence_length)`\n                The sequence used as a prompt for the generation. If `None` the method initializes\n                it as an empty `torch.LongTensor` of shape `(1,)`.\n\n            max_length: (`optional`) int\n                The max length of the sequence to be generated.  Between 1 and infinity. Default to 20.\n\n            do_sample: (`optional`) bool\n                If set to `False` greedy decoding is used. Otherwise sampling is used. Default to greedy sampling.\n\n            num_beams: (`optional`) int\n                Number of beams for beam search. Must be between 1 and infinity. 1 means no beam search. Default to 1.\n\n            temperature: (`optional`) float\n                The value used to module the next token probabilities. Must be strictely positive. Default to 1.0.\n\n            top_k: (`optional`) int\n                The number of highest probability vocabulary tokens to keep for top-k-filtering. Between 1 and infinity. Default to 50.\n\n            top_p: (`optional`) float\n                The cumulative probability of parameter highest probability vocabulary tokens to keep for nucleus sampling. Must be between 0 and 1. Default to 1.\n\n            repetition_penalty: (`optional`) float\n                The parameter for repetition penalty. Between 1.0 and infinity. 1.0 means no penalty. Default to 1.0.\n\n            bos_token_id: (`optional`) int\n                Beginning of sentence token if no prompt is provided. Default to 0.\n\n            eos_token_ids: (`optional`) int or list of int\n                End of sequence token or list of tokens to stop the generation. Default to 0.\n            length_penalty: (`optional`) float\n                Exponential penalty to the length. Default to 1.\n\n            num_return_sequences: (`optional`) int\n                The number of independently computed returned sequences for each element in the batch. Default to 1.\n\n        Examples::\n\n            tokenizer = AutoTokenizer.from_pretrained('distilgpt2')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('distilgpt2')    # Download model and configuration from S3 and cache.\n            outputs = model.generate(max_length=40, bos_token_id=tokenizer.bos_token_id, eos_token_ids=tokenizer.eos_token_id)  # do greedy decoding without beam search\n            print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('openai-gpt')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('openai-gpt')    # Download model and configuration from S3 and cache.\n            input_context = 'The dog'\n            input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  # encode input context\n            outputs = model.generate(input_ids=input_ids, do_sample=True, num_beams=5, num_return_sequences=3, temperature=1.5)  # generate 3 independent sequences using beam search decoding (5 beams) with sampling from initial context 'The dog'\n            for i in range(3): #  3 output sequences were generated\n                print('Generated {}: {}'.format(i, tokenizer.decode(outputs[0][i], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('distilgpt2')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('distilgpt2')    # Download model and configuration from S3 and cache.\n            input_context = 'The dog'\n            input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  # encode input context\n            outputs = model.generate(input_ids=input_ids, max_length=40, temperature=0.7, bos_token_id=tokenizer.bos_token_id, eos_token_ids=tokenizer.eos_token_id, num_beams=3)  # generate sequences using greedy beam search decoding (3 beams)\n            print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('ctrl')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('ctrl')    # Download model and configuration from S3 and cache.\n            input_context = 'Legal My neighbor is'  # \"Legal\" is one of the control codes for ctrl\n            input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  # encode input context\n            outputs = model.generate(input_ids=input_ids, max_length=50, temperature=0.7, repetition_penalty=1.2)  # generate sequences using using greedy search\n            print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n\n        \"\"\"", "\n", "\n", "# We cannot generate if the model does not have a LM head", "\n", "if", "self", ".", "get_output_embeddings", "(", ")", "is", "None", ":", "\n", "            ", "raise", "AttributeError", "(", "\n", "\"You tried to generate sequences with a model that does not have a LM Head.\"", "\n", "\"Please use another model class (e.g. `OpenAIGPTLMHeadModel`, `XLNetLMHeadModel`, `GPT2LMHeadModel`, `CTRLLMHeadModel`, `T5WithLMHeadModel`, `TransfoXLLMHeadModel`)\"", "\n", ")", "\n", "\n", "", "max_length", "=", "max_length", "if", "max_length", "is", "not", "None", "else", "self", ".", "config", ".", "max_length", "\n", "do_sample", "=", "do_sample", "if", "do_sample", "is", "not", "None", "else", "self", ".", "config", ".", "do_sample", "\n", "num_beams", "=", "num_beams", "if", "num_beams", "is", "not", "None", "else", "self", ".", "config", ".", "num_beams", "\n", "temperature", "=", "temperature", "if", "temperature", "is", "not", "None", "else", "self", ".", "config", ".", "temperature", "\n", "top_k", "=", "top_k", "if", "top_k", "is", "not", "None", "else", "self", ".", "config", ".", "top_k", "\n", "top_p", "=", "top_p", "if", "top_p", "is", "not", "None", "else", "self", ".", "config", ".", "top_p", "\n", "repetition_penalty", "=", "repetition_penalty", "if", "repetition_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "repetition_penalty", "\n", "bos_token_id", "=", "bos_token_id", "if", "bos_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "bos_token_id", "\n", "pad_token_id", "=", "pad_token_id", "if", "pad_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "pad_token_id", "\n", "eos_token_ids", "=", "eos_token_ids", "if", "eos_token_ids", "is", "not", "None", "else", "self", ".", "config", ".", "eos_token_ids", "\n", "length_penalty", "=", "length_penalty", "if", "length_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "length_penalty", "\n", "num_return_sequences", "=", "(", "\n", "num_return_sequences", "if", "num_return_sequences", "is", "not", "None", "else", "self", ".", "config", ".", "num_return_sequences", "\n", ")", "\n", "\n", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "batch_size", "=", "input_ids", ".", "shape", "[", "0", "]", "# overriden by the input batch_size", "\n", "", "else", ":", "\n", "            ", "batch_size", "=", "1", "\n", "", "if", "isinstance", "(", "eos_token_ids", ",", "int", ")", ":", "\n", "            ", "eos_token_ids", "=", "[", "eos_token_ids", "]", "\n", "\n", "", "assert", "isinstance", "(", "max_length", ",", "int", ")", "and", "max_length", ">", "0", ",", "\"`max_length` should be a strictely positive integer.\"", "\n", "assert", "isinstance", "(", "do_sample", ",", "bool", ")", ",", "\"`do_sample` should be a boolean.\"", "\n", "assert", "isinstance", "(", "num_beams", ",", "int", ")", "and", "num_beams", ">", "0", ",", "\"`num_beams` should be a strictely positive integer.\"", "\n", "assert", "temperature", ">", "0", ",", "\"`temperature` should be strictely positive.\"", "\n", "assert", "isinstance", "(", "top_k", ",", "int", ")", "and", "top_k", ">=", "0", ",", "\"`top_k` should be a positive integer.\"", "\n", "assert", "0", "<=", "top_p", "<=", "1", ",", "\"`top_p` should be between 0 and 1.\"", "\n", "assert", "repetition_penalty", ">=", "1.0", ",", "\"`repetition_penalty` should be >= 1.\"", "\n", "assert", "isinstance", "(", "bos_token_id", ",", "int", ")", "and", "bos_token_id", ">=", "0", ",", "\"`bos_token_id` should be a positive integer.\"", "\n", "assert", "isinstance", "(", "pad_token_id", ",", "int", ")", "and", "pad_token_id", ">=", "0", ",", "\"`pad_token_id` should be a positive integer.\"", "\n", "assert", "isinstance", "(", "eos_token_ids", ",", "(", "list", ",", "tuple", ")", ")", "and", "(", "\n", "e", ">=", "0", "for", "e", "in", "eos_token_ids", "\n", ")", ",", "\"`eos_token_ids` should be a positive integer or a list/tuple of positive integers.\"", "\n", "assert", "length_penalty", ">", "0", ",", "\"`length_penalty` should be strictely positive.\"", "\n", "assert", "(", "\n", "isinstance", "(", "num_return_sequences", ",", "int", ")", "and", "num_return_sequences", ">", "0", "\n", ")", ",", "\"`num_return_sequences` should be a strictely positive integer.\"", "\n", "\n", "if", "input_ids", "is", "None", ":", "\n", "            ", "input_ids", "=", "torch", ".", "full", "(", "\n", "(", "batch_size", ",", "1", ")", ",", "bos_token_id", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", ")", "\n", "", "else", ":", "\n", "            ", "assert", "input_ids", ".", "dim", "(", ")", "==", "2", ",", "\"Input prompt should be of shape (batch_size, sequence length).\"", "\n", "\n", "# current position and vocab size", "\n", "", "cur_len", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "vocab_size", "=", "self", ".", "config", ".", "vocab_size", "\n", "\n", "if", "num_return_sequences", "!=", "1", ":", "\n", "# Expand input to num return sequences", "\n", "            ", "input_ids", "=", "input_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "num_return_sequences", ",", "cur_len", ")", "\n", "input_ids", "=", "input_ids", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "batch_size", "*", "num_return_sequences", ",", "cur_len", "\n", ")", "# (batch_size * num_return_sequences, cur_len)", "\n", "effective_batch_size", "=", "batch_size", "*", "num_return_sequences", "\n", "", "else", ":", "\n", "            ", "effective_batch_size", "=", "batch_size", "\n", "\n", "", "if", "num_beams", ">", "1", ":", "\n", "            ", "output", "=", "self", ".", "_generate_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "effective_batch_size", ",", "\n", "length_penalty", ",", "\n", "num_beams", ",", "\n", "vocab_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "_generate_no_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "effective_batch_size", ",", "\n", ")", "\n", "\n", "", "if", "num_return_sequences", "!=", "1", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "output", ")", ")", ":", "\n", "                ", "output", "[", "i", "]", "=", "output", "[", "i", "]", ".", "view", "(", "batch_size", ",", "num_return_sequences", ",", "-", "1", ")", "\n", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.CaptionPreTrainedModel._decode_step": [[244, 264], ["modeling_utils.CaptionPreTrainedModel.prepare_inputs_for_generation", "modeling_utils.CaptionPreTrainedModel.", "modeling_utils.CaptionPreTrainedModel._do_output_past", "modeling_utils.CaptionPreTrainedModel._do_output_past"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning.prepare_inputs_for_generation", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning._do_output_past", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning._do_output_past"], ["", "def", "_decode_step", "(", "self", ",", "input_ids", ",", "past", ")", ":", "\n", "        ", "model_inputs", "=", "self", ".", "prepare_inputs_for_generation", "(", "input_ids", ",", "past", "=", "past", ")", "\n", "outputs", "=", "self", "(", "**", "model_inputs", ")", "# (batch_size * num_beams, cur_len, vocab_size)", "\n", "token_len", "=", "outputs", "[", "0", "]", ".", "shape", "[", "1", "]", "\n", "if", "self", ".", "od_labels_len", "==", "0", ":", "\n", "            ", "next_token_idx", "=", "token_len", "-", "1", "\n", "", "else", ":", "\n", "            ", "if", "token_len", "==", "2", ":", "\n", "                ", "assert", "self", ".", "_do_output_past", "(", "outputs", ")", "\n", "next_token_idx", "=", "1", "\n", "", "else", ":", "\n", "                ", "next_token_idx", "=", "token_len", "-", "self", ".", "od_labels_len", "-", "1", "\n", "\n", "", "", "next_token_logits", "=", "outputs", "[", "0", "]", "[", ":", ",", "next_token_idx", ",", ":", "]", "# (batch_size * num_beams, vocab_size)", "\n", "assert", "outputs", "[", "0", "]", ".", "shape", "[", "1", "]", "==", "model_inputs", "[", "'input_ids'", "]", ".", "shape", "[", "1", "]", "\n", "\n", "# if model has past, then set the past variable to speed up decoding", "\n", "if", "self", ".", "_do_output_past", "(", "outputs", ")", ":", "\n", "            ", "past", "=", "outputs", "[", "1", "]", "\n", "", "return", "next_token_logits", ",", "past", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.CaptionPreTrainedModel._generate_no_beam_search": [[265, 375], ["torch.cat.new().fill_", "torch.cat.new().fill_", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.stack().float", "torch.stack().float", "torch.stack().float", "torch.stack().float", "modeling_utils.CaptionPreTrainedModel.prepare_inputs_for_generation", "modeling_utils.CaptionPreTrainedModel.", "modeling_utils.CaptionPreTrainedModel._do_output_past", "torch.log_softmax", "torch.log_softmax", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.cat.append", "torch.cat.append", "torch.stack().float.append", "torch.stack().float.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input_ids[].masked_fill_", "torch.stack().float.sum", "torch.stack().float.sum", "torch.cat.new().fill_", "torch.cat.new().fill_", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.new", "torch.cat.new", "range", "modeling_utils.top_k_top_p_filtering", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax.unsqueeze", "torch.argmax.unsqueeze", "cur_unfinished.mul.mul.mul", "cur_unfinished.mul.mul.max", "cur_unfinished.mul.mul.to", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "modeling_utils.CaptionPreTrainedModel._do_output_past", "set", "tokens_to_add.unsqueeze", "tokens_to_add.ne().long", "torch.cat.new", "torch.cat.new", "input_ids[].tolist", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.softmax", "torch.softmax", "tokens_to_add.ne"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning.prepare_inputs_for_generation", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning._do_output_past", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.top_k_top_p_filtering", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning._do_output_past"], ["", "def", "_generate_no_beam_search", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "batch_size", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Generate sequences for each example without beam search (num_beams == 1).\n            All returned sequence are generated independantly.\n        \"\"\"", "\n", "assert", "self", ".", "num_keep_best", "==", "1", ",", "'cannot generate >1 sentences in greedy search'", "\n", "# current position / max lengths / length of generated sentences / unfinished sentences", "\n", "unfinished_sents", "=", "[", "]", "\n", "cur_unfinished", "=", "input_ids", ".", "new", "(", "batch_size", ")", ".", "fill_", "(", "1", ")", "\n", "\n", "# log of scores for each sentence in the batch", "\n", "logprobs", "=", "[", "]", "\n", "\n", "past", "=", "None", "\n", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "            ", "model_inputs", "=", "self", ".", "prepare_inputs_for_generation", "(", "input_ids", ",", "past", "=", "past", ")", "\n", "outputs", "=", "self", "(", "**", "model_inputs", ")", "\n", "if", "cur_len", "==", "1", ":", "\n", "                ", "token_len", "=", "2", "+", "self", ".", "od_labels_len", "\n", "next_token_idx", "=", "1", "\n", "", "else", ":", "\n", "                ", "assert", "cur_len", ">", "1", "\n", "if", "not", "self", ".", "_do_output_past", "(", "outputs", ")", ":", "\n", "                    ", "token_len", "=", "cur_len", "+", "1", "+", "self", ".", "od_labels_len", "\n", "next_token_idx", "=", "cur_len", "\n", "", "else", ":", "\n", "                    ", "token_len", "=", "2", "\n", "next_token_idx", "=", "1", "\n", "", "", "assert", "outputs", "[", "0", "]", ".", "shape", "[", "1", "]", "==", "token_len", "\n", "\n", "next_token_logits", "=", "outputs", "[", "0", "]", "[", ":", ",", "next_token_idx", ",", ":", "]", "\n", "\n", "# if model has past, then set the past variable to speed up decoding", "\n", "if", "self", ".", "_do_output_past", "(", "outputs", ")", ":", "\n", "                ", "past", "=", "outputs", "[", "1", "]", "\n", "\n", "# repetition penalty from CTRL paper (https://arxiv.org/abs/1909.05858)", "\n", "", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "                ", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "for", "previous_token", "in", "set", "(", "input_ids", "[", "i", "]", ".", "tolist", "(", ")", ")", ":", "\n", "# if score < 0 then repetition penalty has to multiplied to reduce the previous token probability", "\n", "                        ", "if", "next_token_logits", "[", "i", ",", "previous_token", "]", "<", "0", ":", "\n", "                            ", "next_token_logits", "[", "i", ",", "previous_token", "]", "*=", "repetition_penalty", "\n", "", "else", ":", "\n", "                            ", "next_token_logits", "[", "i", ",", "previous_token", "]", "/=", "repetition_penalty", "\n", "\n", "", "", "", "", "if", "do_sample", ":", "\n", "# Temperature (higher temperature => more likely to sample low probability tokens)", "\n", "                ", "if", "temperature", "!=", "1.0", ":", "\n", "                    ", "next_token_logits", "=", "next_token_logits", "/", "temperature", "\n", "# Top-p/top-k filtering", "\n", "", "next_token_logits", "=", "top_k_top_p_filtering", "(", "next_token_logits", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ")", "\n", "# Sample", "\n", "next_token", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", ",", "num_samples", "=", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "# Greedy decoding", "\n", "                ", "next_token", "=", "torch", ".", "argmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Compute scores", "\n", "", "_scores", "=", "F", ".", "log_softmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", "# (batch_size, vocab_size)", "\n", "_scores", "=", "torch", ".", "gather", "(", "_scores", ",", "-", "1", ",", "next_token", ".", "unsqueeze", "(", "-", "1", ")", ")", "# (batch_size, 1)", "\n", "logprobs", ".", "append", "(", "_scores", ")", "# (batch_size, 1)", "\n", "unfinished_sents", ".", "append", "(", "cur_unfinished", ")", "\n", "\n", "# update generations and finished sentences", "\n", "tokens_to_add", "=", "next_token", "*", "cur_unfinished", "+", "pad_token_id", "*", "(", "1", "-", "cur_unfinished", ")", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "input_ids", ",", "tokens_to_add", ".", "unsqueeze", "(", "-", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "#for t in input_ids:", "\n", "#print(self.tokenizer.convert_ids_to_tokens(t.tolist()))", "\n", "\n", "for", "eos_token_id", "in", "eos_token_ids", ":", "\n", "                ", "cur_unfinished", "=", "cur_unfinished", ".", "mul", "(", "tokens_to_add", ".", "ne", "(", "eos_token_id", ")", ".", "long", "(", ")", ")", "\n", "", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "# stop when there is a </s> in each sentence, or if we exceed the maximul length", "\n", "if", "cur_unfinished", ".", "max", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "# add eos_token_ids to unfinished sentences", "\n", "", "", "if", "cur_len", "==", "max_length", ":", "\n", "            ", "input_ids", "[", ":", ",", "-", "1", "]", ".", "masked_fill_", "(", "cur_unfinished", ".", "to", "(", "dtype", "=", "torch", ".", "bool", ")", ",", "eos_token_ids", "[", "0", "]", ")", "\n", "\n", "", "logprobs", "=", "torch", ".", "cat", "(", "logprobs", ",", "dim", "=", "1", ")", "\n", "unfinished_sents", "=", "torch", ".", "stack", "(", "unfinished_sents", ",", "dim", "=", "1", ")", ".", "float", "(", ")", "\n", "sum_logprobs", "=", "(", "logprobs", "*", "unfinished_sents", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "# return logprobs to keep consistent with beam search output", "\n", "logprobs", "=", "sum_logprobs", "/", "unfinished_sents", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n", "# pad to the same length, otherwise DataParallel will give error", "\n", "pad_len", "=", "max_length", "-", "input_ids", ".", "shape", "[", "1", "]", "\n", "if", "pad_len", ">", "0", ":", "\n", "            ", "padding_ids", "=", "input_ids", ".", "new", "(", "batch_size", ",", "pad_len", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "input_ids", ",", "padding_ids", "]", ",", "dim", "=", "1", ")", "\n", "\n", "# (batch_size, n_best, max_len), (batch_size, n_best)", "\n", "", "return", "input_ids", ".", "unsqueeze", "(", "1", ")", ",", "logprobs", ".", "unsqueeze", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.CaptionPreTrainedModel._generate_beam_search": [[376, 598], ["torch.cat.unsqueeze().expand", "torch.cat.unsqueeze().expand", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "beam_scores.new.new.view", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros().fill_().to", "torch.zeros().fill_().to", "torch.zeros().fill_().to", "torch.zeros().fill_().to", "enumerate", "torch.cat.new().fill_", "torch.cat.new().fill_", "enumerate", "modeling_utils.BeamHypotheses", "modeling_utils.CaptionPreTrainedModel.prepare_inputs_for_generation", "modeling_utils.CaptionPreTrainedModel.", "modeling_utils.CaptionPreTrainedModel._do_output_past", "range", "beam_scores.new.new.new", "torch.cat.new", "torch.cat.new", "torch.cat.new", "torch.cat.new", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "all", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "enumerate", "all_best.append", "enumerate", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.contiguous", "torch.cat.contiguous", "range", "range", "range", "modeling_utils.top_k_top_p_filtering", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.log_softmax", "torch.log_softmax", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "beam_indices.repeat().to.repeat().to.repeat().to", "next_words.view.view.view", "next_scores.view.view.view", "torch.log_softmax", "torch.log_softmax", "_scores.view.view.view", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "next_scores.view.view.size", "next_words.view.view.size", "zip", "next_batch_beam.extend", "len", "tuple", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "min", "best.append", "torch.cat.new", "torch.cat.new", "modeling_utils.CaptionPreTrainedModel._do_output_past", "set", "torch.softmax", "torch.softmax", "beam_scores[].expand_as", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.log_softmax.size", "beam_scores[].expand_as", "generated_hyps[].is_done", "next_batch_beam.extend", "len", "len", "torch.cat.new.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "reordered_past.append", "len", "len", "input_ids[].tolist", "beam_indices.repeat().to.repeat().to.repeat", "next_scores[].max().item", "generated_hyps[].add", "next_sent_beam.append", "len", "len", "len", "layer_past[].unsqueeze().clone().detach", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "word_id.item", "input_ids[].clone", "score.item", "next_scores[].max", "layer_past[].unsqueeze().clone", "layer_past[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning.prepare_inputs_for_generation", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning._do_output_past", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.top_k_top_p_filtering", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning._do_output_past", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.BeamHypotheses.is_done", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.BeamHypotheses.add"], ["", "def", "_generate_beam_search", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "batch_size", ",", "\n", "length_penalty", ",", "\n", "num_beams", ",", "\n", "vocab_size", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Generate sequences for each example with beam search.\n        \"\"\"", "\n", "# Expand input to num beams", "\n", "input_ids", "=", "input_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "num_beams", ",", "cur_len", ")", "\n", "input_ids", "=", "input_ids", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", "*", "num_beams", ",", "cur_len", ")", "# (batch_size * num_beams, cur_len)", "\n", "\n", "# generated hypotheses", "\n", "num_keep_best", "=", "self", ".", "num_keep_best", "\n", "generated_hyps", "=", "[", "\n", "BeamHypotheses", "(", "num_keep_best", ",", "max_length", ",", "length_penalty", ",", "early_stopping", "=", "False", ")", "for", "_", "in", "range", "(", "batch_size", ")", "\n", "]", "\n", "# NOTE: Expand >1 words to leave some spare tokens to keep the", "\n", "# beam size, because some sentences may end here and cannot expand", "\n", "# in the next level", "\n", "TOPN_PER_BEAM", "=", "2", "\n", "\n", "# scores for each sentence in the beam", "\n", "beam_scores", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "num_beams", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "beam_scores", "[", ":", ",", "1", ":", "]", "=", "-", "1e9", "\n", "beam_scores", "=", "beam_scores", ".", "view", "(", "-", "1", ")", "# shape (batch_size * num_beams,)", "\n", "\n", "# cache compute states", "\n", "past", "=", "None", "\n", "\n", "# done sentences", "\n", "done", "=", "[", "False", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "            ", "model_inputs", "=", "self", ".", "prepare_inputs_for_generation", "(", "input_ids", ",", "past", "=", "past", ")", "\n", "outputs", "=", "self", "(", "**", "model_inputs", ")", "# (batch_size * num_beams, cur_len, vocab_size)", "\n", "if", "cur_len", "==", "1", ":", "\n", "                ", "token_len", "=", "2", "+", "self", ".", "od_labels_len", "\n", "next_token_idx", "=", "1", "\n", "", "else", ":", "\n", "                ", "assert", "cur_len", ">", "1", "\n", "if", "not", "self", ".", "_do_output_past", "(", "outputs", ")", ":", "\n", "                    ", "token_len", "=", "cur_len", "+", "1", "+", "self", ".", "od_labels_len", "\n", "next_token_idx", "=", "cur_len", "\n", "", "else", ":", "\n", "                    ", "token_len", "=", "2", "\n", "next_token_idx", "=", "1", "\n", "\n", "", "", "assert", "outputs", "[", "0", "]", ".", "shape", "[", "1", "]", "==", "token_len", "\n", "scores", "=", "outputs", "[", "0", "]", "[", ":", ",", "next_token_idx", ",", ":", "]", "# (batch_size * num_beams, vocab_size)", "\n", "assert", "outputs", "[", "0", "]", ".", "shape", "[", "1", "]", "==", "model_inputs", "[", "'input_ids'", "]", ".", "shape", "[", "1", "]", "\n", "\n", "# if model has past, then set the past variable to speed up decoding", "\n", "if", "self", ".", "_do_output_past", "(", "outputs", ")", ":", "\n", "                ", "past", "=", "outputs", "[", "1", "]", "\n", "\n", "# repetition penalty (from CTRL paper https://arxiv.org/abs/1909.05858)", "\n", "", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "                ", "for", "i", "in", "range", "(", "batch_size", "*", "num_beams", ")", ":", "\n", "                    ", "for", "previous_token", "in", "set", "(", "input_ids", "[", "i", "]", ".", "tolist", "(", ")", ")", ":", "\n", "# if score < 0 then repetition penalty has to multiplied to reduce the previous token probability", "\n", "                        ", "if", "scores", "[", "i", ",", "previous_token", "]", "<", "0", ":", "\n", "                            ", "scores", "[", "i", ",", "previous_token", "]", "*=", "repetition_penalty", "\n", "", "else", ":", "\n", "                            ", "scores", "[", "i", ",", "previous_token", "]", "/=", "repetition_penalty", "\n", "\n", "", "", "", "", "if", "do_sample", ":", "\n", "# Temperature (higher temperature => more likely to sample low probability tokens)", "\n", "                ", "if", "temperature", "!=", "1.0", ":", "\n", "                    ", "scores", "=", "scores", "/", "temperature", "\n", "# Top-p/top-k filtering", "\n", "", "scores", "=", "top_k_top_p_filtering", "(", "\n", "scores", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ",", "min_tokens_to_keep", "=", "2", "\n", ")", "# (batch_size * num_beams, vocab_size)", "\n", "# Sample [TOPN_PER_BEAM] next words for each beam (so we have some spare tokens and match output of greedy beam search)", "\n", "next_words", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", ",", "\n", "num_samples", "=", "TOPN_PER_BEAM", ")", "# (batch_size * num_beams, TOPN_PER_BEAM)", "\n", "# Compute next scores", "\n", "_scores", "=", "F", ".", "log_softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "# (batch_size * num_beams, vocab_size)", "\n", "_scores", "=", "torch", ".", "gather", "(", "_scores", ",", "-", "1", ",", "next_words", ")", "# (batch_size * num_beams, TOPN_PER_BEAM)", "\n", "next_scores", "=", "_scores", "+", "beam_scores", "[", ":", ",", "None", "]", ".", "expand_as", "(", "_scores", ")", "# (batch_size * num_beams, TOPN_PER_BEAM)", "\n", "# Match shape of greedy beam search", "\n", "beam_indices", "=", "torch", ".", "arange", "(", "num_beams", ")", "*", "vocab_size", "\n", "beam_indices", "=", "beam_indices", ".", "repeat", "(", "batch_size", ",", "TOPN_PER_BEAM", ")", ".", "to", "(", "next_words", ".", "device", ")", "\n", "next_words", "=", "next_words", ".", "view", "(", "batch_size", ",", "TOPN_PER_BEAM", "*", "num_beams", ")", "# (batch_size, TOPN_PER_BEAM * num_beams)", "\n", "next_words", "=", "next_words", "+", "beam_indices", "\n", "next_scores", "=", "next_scores", ".", "view", "(", "batch_size", ",", "TOPN_PER_BEAM", "*", "num_beams", ")", "# (batch_size, TOPN_PER_BEAM * num_beams)", "\n", "", "else", ":", "\n", "# do greedy beam search", "\n", "                ", "scores", "=", "F", ".", "log_softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "# (batch_size * num_beams, vocab_size)", "\n", "assert", "scores", ".", "size", "(", ")", "==", "(", "batch_size", "*", "num_beams", ",", "vocab_size", ")", "\n", "# Add the log prob of the new beams to the log prob of the beginning of the sequence (sum of logs == log of the product)", "\n", "_scores", "=", "scores", "+", "beam_scores", "[", ":", ",", "None", "]", ".", "expand_as", "(", "scores", ")", "# (batch_size * num_beams, vocab_size)", "\n", "# re-organize to group the beam together (we are keeping top hypothesis accross beams)", "\n", "_scores", "=", "_scores", ".", "view", "(", "batch_size", ",", "num_beams", "*", "vocab_size", ")", "# (batch_size, num_beams * vocab_size)", "\n", "next_scores", ",", "next_words", "=", "torch", ".", "topk", "(", "_scores", ",", "TOPN_PER_BEAM", "*", "num_beams", ",", "dim", "=", "1", ",", "largest", "=", "True", ",", "sorted", "=", "True", ")", "\n", "\n", "", "assert", "next_scores", ".", "size", "(", ")", "==", "next_words", ".", "size", "(", ")", "==", "(", "batch_size", ",", "TOPN_PER_BEAM", "*", "num_beams", ")", "\n", "\n", "# next batch beam content", "\n", "# list of (batch_size * num_beams) tuple(next hypothesis score, next word, current position in the batch)", "\n", "next_batch_beam", "=", "[", "]", "\n", "\n", "# for each sentence", "\n", "for", "batch_ex", "in", "range", "(", "batch_size", ")", ":", "\n", "\n", "# if we are done with this sentence", "\n", "                ", "done", "[", "batch_ex", "]", "=", "done", "[", "batch_ex", "]", "or", "generated_hyps", "[", "batch_ex", "]", ".", "is_done", "(", "next_scores", "[", "batch_ex", "]", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "if", "done", "[", "batch_ex", "]", ":", "\n", "                    ", "next_batch_beam", ".", "extend", "(", "[", "(", "0", ",", "pad_token_id", ",", "0", ")", "]", "*", "num_beams", ")", "# pad the batch", "\n", "continue", "\n", "\n", "# next sentence beam content", "\n", "", "next_sent_beam", "=", "[", "]", "\n", "\n", "# next words for this sentence", "\n", "for", "idx", ",", "score", "in", "zip", "(", "next_words", "[", "batch_ex", "]", ",", "next_scores", "[", "batch_ex", "]", ")", ":", "\n", "\n", "# get beam and word IDs", "\n", "                    ", "beam_id", "=", "idx", "//", "vocab_size", "\n", "word_id", "=", "idx", "%", "vocab_size", "\n", "\n", "# end of sentence, or next word", "\n", "if", "word_id", ".", "item", "(", ")", "in", "eos_token_ids", "or", "cur_len", "+", "1", "==", "max_length", ":", "\n", "                        ", "generated_hyps", "[", "batch_ex", "]", ".", "add", "(", "\n", "input_ids", "[", "batch_ex", "*", "num_beams", "+", "beam_id", ",", ":", "cur_len", "]", ".", "clone", "(", ")", ",", "score", ".", "item", "(", ")", "\n", ")", "\n", "", "else", ":", "\n", "                        ", "next_sent_beam", ".", "append", "(", "(", "score", ",", "word_id", ",", "batch_ex", "*", "num_beams", "+", "beam_id", ")", ")", "\n", "\n", "# the beam for next step is full", "\n", "", "if", "len", "(", "next_sent_beam", ")", "==", "num_beams", ":", "\n", "                        ", "break", "\n", "\n", "# update next beam content", "\n", "", "", "if", "cur_len", "+", "1", "==", "max_length", ":", "\n", "                    ", "assert", "len", "(", "next_sent_beam", ")", "==", "0", "\n", "", "else", ":", "\n", "                    ", "assert", "len", "(", "next_sent_beam", ")", "==", "num_beams", "\n", "\n", "", "if", "len", "(", "next_sent_beam", ")", "==", "0", ":", "\n", "                    ", "next_sent_beam", "=", "[", "(", "0", ",", "pad_token_id", ",", "0", ")", "]", "*", "num_beams", "# pad the batch", "\n", "", "next_batch_beam", ".", "extend", "(", "next_sent_beam", ")", "\n", "assert", "len", "(", "next_batch_beam", ")", "==", "num_beams", "*", "(", "batch_ex", "+", "1", ")", "\n", "\n", "# sanity check / prepare next batch", "\n", "", "assert", "len", "(", "next_batch_beam", ")", "==", "batch_size", "*", "num_beams", "\n", "beam_scores", "=", "beam_scores", ".", "new", "(", "[", "x", "[", "0", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "beam_words", "=", "input_ids", ".", "new", "(", "[", "x", "[", "1", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "beam_idx", "=", "input_ids", ".", "new", "(", "[", "x", "[", "2", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "\n", "# re-order batch", "\n", "input_ids", "=", "input_ids", "[", "beam_idx", ",", ":", "]", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "input_ids", ",", "beam_words", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# re-order internal states", "\n", "if", "past", ":", "\n", "                ", "reordered_past", "=", "[", "]", "\n", "for", "layer_past", "in", "past", ":", "\n", "# get the correct batch idx from layer past batch dim", "\n", "# batch dim of `past` and `mems` is at 1st position", "\n", "                    ", "reordered_layer_past", "=", "[", "layer_past", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "for", "i", "in", "beam_idx", "]", "\n", "reordered_layer_past", "=", "torch", ".", "cat", "(", "reordered_layer_past", ",", "dim", "=", "0", ")", "\n", "# check that shape matches", "\n", "assert", "reordered_layer_past", ".", "shape", "==", "layer_past", ".", "shape", "\n", "reordered_past", ".", "append", "(", "reordered_layer_past", ")", "\n", "", "past", "=", "tuple", "(", "reordered_past", ")", "\n", "\n", "# update current length", "\n", "", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "# stop when we are done with each sentence", "\n", "if", "all", "(", "done", ")", ":", "\n", "                ", "break", "\n", "\n", "# visualize hypotheses", "\n", "# print([len(x) for x in generated_hyps], cur_len)", "\n", "# globals().update( locals() );", "\n", "# !import code; code.interact(local=vars())", "\n", "# for ii in range(batch_size):", "\n", "#     for ss, ww in sorted(generated_hyps[ii].hyp, key=lambda x: x[0], reverse=True):", "\n", "#         print(\"%.3f \" % ss + \" \".join(self.dico[x] for x in ww.tolist()))", "\n", "#     print(\"\")", "\n", "\n", "# select the best hypotheses", "\n", "", "", "tgt_len", "=", "torch", ".", "ones", "(", "batch_size", ",", "num_keep_best", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "logprobs", "=", "torch", ".", "zeros", "(", "batch_size", ",", "num_keep_best", ",", "\n", "dtype", "=", "torch", ".", "float", ")", ".", "fill_", "(", "-", "1e5", ")", ".", "to", "(", "input_ids", ".", "device", ")", "\n", "all_best", "=", "[", "]", "\n", "\n", "for", "i", ",", "hypotheses", "in", "enumerate", "(", "generated_hyps", ")", ":", "\n", "            ", "best", "=", "[", "]", "\n", "hyp_scores", "=", "torch", ".", "tensor", "(", "[", "x", "[", "0", "]", "for", "x", "in", "hypotheses", ".", "hyp", "]", ")", "\n", "_", ",", "best_indices", "=", "torch", ".", "topk", "(", "hyp_scores", ",", "\n", "min", "(", "num_keep_best", ",", "len", "(", "hyp_scores", ")", ")", ",", "largest", "=", "True", ")", "\n", "for", "best_idx", ",", "hyp_idx", "in", "enumerate", "(", "best_indices", ")", ":", "\n", "                ", "conf", ",", "best_hyp", "=", "hypotheses", ".", "hyp", "[", "hyp_idx", "]", "\n", "best", ".", "append", "(", "best_hyp", ")", "\n", "logprobs", "[", "i", ",", "best_idx", "]", "=", "conf", "\n", "tgt_len", "[", "i", ",", "best_idx", "]", "=", "len", "(", "best_hyp", ")", "+", "1", "# +1 for the <EOS> symbol", "\n", "\n", "", "all_best", ".", "append", "(", "best", ")", "\n", "\n", "# generate target batch, pad to the same length", "\n", "", "decoded", "=", "input_ids", ".", "new", "(", "batch_size", ",", "num_keep_best", ",", "max_length", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "for", "batch_idx", ",", "best", "in", "enumerate", "(", "all_best", ")", ":", "\n", "            ", "for", "best_idx", ",", "hypo", "in", "enumerate", "(", "best", ")", ":", "\n", "                ", "decoded", "[", "batch_idx", ",", "best_idx", ",", ":", "tgt_len", "[", "batch_idx", ",", "best_idx", "]", "-", "1", "]", "=", "hypo", "\n", "decoded", "[", "batch_idx", ",", "best_idx", ",", "tgt_len", "[", "batch_idx", ",", "best_idx", "]", "-", "1", "]", "=", "eos_token_ids", "[", "0", "]", "\n", "\n", "", "", "return", "decoded", ",", "logprobs", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.BeamHypotheses.__init__": [[636, 646], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "n_hyp", ",", "max_length", ",", "length_penalty", ",", "early_stopping", ")", ":", "\n", "        ", "\"\"\"\n        Initialize n-best list of hypotheses.\n        \"\"\"", "\n", "self", ".", "max_length", "=", "max_length", "-", "1", "# ignoring bos_token", "\n", "self", ".", "length_penalty", "=", "length_penalty", "\n", "self", ".", "early_stopping", "=", "early_stopping", "\n", "self", ".", "n_hyp", "=", "n_hyp", "\n", "self", ".", "hyp", "=", "[", "]", "\n", "self", ".", "worst_score", "=", "1e9", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.BeamHypotheses.__len__": [[647, 652], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Number of hypotheses in the list.\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "hyp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.BeamHypotheses.add": [[653, 666], ["modeling_utils.BeamHypotheses.hyp.append", "len", "len", "len", "sorted", "min", "enumerate"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "hyp", ",", "sum_logprobs", ")", ":", "\n", "        ", "\"\"\"\n        Add a new hypothesis to the list.\n        \"\"\"", "\n", "score", "=", "sum_logprobs", "/", "len", "(", "hyp", ")", "**", "self", ".", "length_penalty", "\n", "if", "len", "(", "self", ")", "<", "self", ".", "n_hyp", "or", "score", ">", "self", ".", "worst_score", ":", "\n", "            ", "self", ".", "hyp", ".", "append", "(", "(", "score", ",", "hyp", ")", ")", "\n", "if", "len", "(", "self", ")", ">", "self", ".", "n_hyp", ":", "\n", "                ", "sorted_scores", "=", "sorted", "(", "[", "(", "s", ",", "idx", ")", "for", "idx", ",", "(", "s", ",", "_", ")", "in", "enumerate", "(", "self", ".", "hyp", ")", "]", ")", "\n", "del", "self", ".", "hyp", "[", "sorted_scores", "[", "0", "]", "[", "1", "]", "]", "\n", "self", ".", "worst_score", "=", "sorted_scores", "[", "1", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "worst_score", "=", "min", "(", "score", ",", "self", ".", "worst_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.BeamHypotheses.is_done": [[667, 678], ["len"], "methods", ["None"], ["", "", "", "def", "is_done", "(", "self", ",", "best_sum_logprobs", ")", ":", "\n", "        ", "\"\"\"\n        If there are enough hypotheses and that none of the hypotheses being generated\n        can become better than the worst one in the heap, then we are done with this sentence.\n        \"\"\"", "\n", "if", "len", "(", "self", ")", "<", "self", ".", "n_hyp", ":", "\n", "            ", "return", "False", "\n", "", "elif", "self", ".", "early_stopping", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "worst_score", ">=", "best_sum_logprobs", "/", "self", ".", "max_length", "**", "self", ".", "length_penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.__init__": [[685, 687], ["transformers.pytorch_transformers.modeling_utils.PreTrainedModel.__init__"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "ImgPreTrainedModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained": [[688, 876], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "cls", "torch.load.keys", "torch.load.keys", "zip", "getattr", "torch.load.copy", "torch.load.copy", "modeling_utils.ImgPreTrainedModel.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.copy", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.copy"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"Instantiate a pretrained pytorch model from a pre-trained model configuration.\n\n            The model is set in evaluation mode by default using `model.eval()` (Dropout modules are desactivated)\n            To train the model, you should first set it back in training mode with `model.train()`\n\n        Params:\n            **pretrained_model_name_or_path**: either:\n                - a string with the `shortcut name` of a pre-trained model to load from cache\n                    or download and cache if not already stored in cache (e.g. 'bert-base-uncased').\n                - a path to a `directory` containing a configuration file saved\n                    using the `save_pretrained(save_directory)` method.\n                - a path or url to a tensorflow index checkpoint `file` (e.g. `./tf_model/model.ckpt.index`).\n                    In this case, ``from_tf`` should be set to True and a configuration object should be\n                    provided as `config` argument. This loading option is slower than converting the TensorFlow\n                    checkpoint in a PyTorch model using the provided conversion scripts and loading\n                    the PyTorch model afterwards.\n            **model_args**: (`optional`) Sequence:\n                All remaning positional arguments will be passed to the underlying model's __init__ function\n            **config**: an optional configuration for the model to use instead of an automatically loaded configuation.\n                Configuration can be automatically loaded when:\n                - the model is a model provided by the library (loaded with a `shortcut name` of a pre-trained model), or\n                - the model was saved using the `save_pretrained(save_directory)` (loaded by suppling the save directory).\n            **state_dict**: an optional state dictionnary for the model to use instead of a state dictionary loaded\n                from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuraton but load your own weights.\n                In this case though, you should check if using `save_pretrained(dir)` and `from_pretrained(save_directory)` is not\n                a simpler option.\n            **cache_dir**: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n            **output_loading_info**: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n            **kwargs**: (`optional`) dict:\n                Dictionary of key, values to update the configuration object after loading.\n                Can be used to override selected configuration parameters. E.g. ``output_attention=True``.\n\n               - If a configuration is provided with `config`, **kwargs will be directly passed\n                 to the underlying model's __init__ method.\n               - If a configuration is not provided, **kwargs will be first passed to the pretrained\n                 model configuration class loading function (`PretrainedConfig.from_pretrained`).\n                 Each key of **kwargs that corresponds to a configuration attribute\n                 will be used to override said attribute with the supplied **kwargs value.\n                 Remaining keys that do not correspond to any configuration attribute will\n                 be passed to the underlying model's __init__ function.\n\n        Examples::\n\n            >>> model = BertModel.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            >>> model = BertModel.from_pretrained('./test/saved_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            >>> model = BertModel.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            >>> assert model.config.output_attention == True\n            >>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            >>> config = BertConfig.from_json_file('./tf_model/my_tf_model_config.json')\n            >>> model = BertModel.from_pretrained('./tf_model/my_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "config", "=", "kwargs", ".", "pop", "(", "'config'", ",", "None", ")", "\n", "state_dict", "=", "kwargs", ".", "pop", "(", "'state_dict'", ",", "None", ")", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "'cache_dir'", ",", "None", ")", "\n", "from_tf", "=", "kwargs", ".", "pop", "(", "'from_tf'", ",", "False", ")", "\n", "output_loading_info", "=", "kwargs", ".", "pop", "(", "'output_loading_info'", ",", "False", ")", "\n", "\n", "# Load config", "\n", "if", "config", "is", "None", ":", "\n", "            ", "config", ",", "model_kwargs", "=", "cls", ".", "config_class", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "\n", "cache_dir", "=", "cache_dir", ",", "return_unused_kwargs", "=", "True", ",", "\n", "**", "kwargs", "\n", ")", "\n", "", "else", ":", "\n", "            ", "model_kwargs", "=", "kwargs", "\n", "\n", "# Load model", "\n", "", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "            ", "archive_file", "=", "cls", ".", "pretrained_model_archive_map", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint", "\n", "                ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", ")", "\n", "", "else", ":", "\n", "                ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint", "\n", "                ", "archive_file", "=", "pretrained_model_name_or_path", "+", "\".index\"", "\n", "", "else", ":", "\n", "                ", "archive_file", "=", "pretrained_model_name_or_path", "\n", "# redirect to the cache, if necessary", "\n", "", "", "try", ":", "\n", "            ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Couldn't reach server at '{}' to download pretrained weights.\"", ".", "format", "(", "\n", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "cls", ".", "pretrained_model_archive_map", ".", "keys", "(", ")", ")", ",", "\n", "archive_file", ")", ")", "\n", "", "return", "None", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading weights file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading weights file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "\n", "# Instantiate model.", "\n", "", "model", "=", "cls", "(", "config", ",", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "\n", "if", "state_dict", "is", "None", "and", "not", "from_tf", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "resolved_archive_file", ",", "map_location", "=", "'cpu'", ")", "\n", "\n", "", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint", "\n", "            ", "return", "cls", ".", "load_tf_weights", "(", "model", ",", "config", ",", "resolved_archive_file", "[", ":", "-", "6", "]", ")", "# Remove the '.index'", "\n", "\n", "# Convert old format to new format if needed from a PyTorch state_dict", "\n", "", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "new_key", "=", "None", "\n", "if", "'gamma'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "new_key", ":", "\n", "                ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "            ", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "# Load from a PyTorch state_dict", "\n", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "metadata", "=", "getattr", "(", "state_dict", ",", "'_metadata'", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "''", ")", ":", "\n", "            ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                ", "if", "child", "is", "not", "None", ":", "\n", "                    ", "load", "(", "child", ",", "prefix", "+", "name", "+", "'.'", ")", "\n", "\n", "# Make sure we are able to load base models as well as derived models (with heads)", "\n", "", "", "", "start_prefix", "=", "''", "\n", "model_to_load", "=", "model", "\n", "if", "not", "hasattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "and", "any", "(", "s", ".", "startswith", "(", "cls", ".", "base_model_prefix", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "start_prefix", "=", "cls", ".", "base_model_prefix", "+", "'.'", "\n", "", "if", "hasattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "and", "not", "any", "(", "s", ".", "startswith", "(", "cls", ".", "base_model_prefix", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "model_to_load", "=", "getattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "\n", "\n", "", "load", "(", "model_to_load", ",", "prefix", "=", "start_prefix", ")", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", ")", "\n", "", "if", "len", "(", "error_msgs", ")", "==", "2", "and", "\"size mismatch for cls.seq_relationship.weight\"", "in", "error_msgs", "[", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "'Error(s) in loading state_dict for {}:\\n\\t{}'", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", ")", ")", "\n", "", "elif", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Error(s) in loading state_dict for {}:\\n\\t{}'", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", ")", ")", "\n", "\n", "", "if", "hasattr", "(", "model", ",", "'tie_weights'", ")", ":", "\n", "            ", "model", ".", "tie_weights", "(", ")", "# make sure word embedding weights are still tied", "\n", "\n", "# Set model in evaluation mode to desactivate DropOut modules by default", "\n", "", "model", ".", "eval", "(", ")", "\n", "\n", "if", "output_loading_info", ":", "\n", "            ", "loading_info", "=", "{", "\"missing_keys\"", ":", "missing_keys", ",", "\"unexpected_keys\"", ":", "unexpected_keys", ",", "\"error_msgs\"", ":", "error_msgs", "}", "\n", "return", "model", ",", "loading_info", "\n", "\n", "", "return", "model", "", "", "", ""]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.top_k_top_p_filtering": [[600, 633], ["float", "min", "torch.sort", "torch.sort", "torch.cumsum", "torch.cumsum", "sorted_indices_to_remove[].clone", "sorted_indices_to_remove.scatter", "max", "logits.size", "torch.softmax", "torch.topk", "torch.topk"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "", "def", "top_k_top_p_filtering", "(", "logits", ",", "top_k", "=", "0", ",", "top_p", "=", "1.0", ",", "filter_value", "=", "-", "float", "(", "\"Inf\"", ")", ",", "min_tokens_to_keep", "=", "1", ")", ":", "\n", "    ", "\"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n        Args:\n            logits: logits distribution shape (batch size, vocabulary size)\n            if top_k > 0: keep only top k tokens with highest probability (top-k filtering).\n            if top_p < 1.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n            Make sure we keep at least min_tokens_to_keep per batch example in the output\n        From: https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317\n    \"\"\"", "\n", "if", "top_k", ">", "0", ":", "\n", "        ", "top_k", "=", "min", "(", "max", "(", "top_k", ",", "min_tokens_to_keep", ")", ",", "logits", ".", "size", "(", "-", "1", ")", ")", "# Safety check", "\n", "# Remove all tokens with a probability less than the last token of the top-k", "\n", "indices_to_remove", "=", "logits", "<", "torch", ".", "topk", "(", "logits", ",", "top_k", ")", "[", "0", "]", "[", "...", ",", "-", "1", ",", "None", "]", "\n", "logits", "[", "indices_to_remove", "]", "=", "filter_value", "\n", "\n", "", "if", "top_p", "<", "1.0", ":", "\n", "        ", "sorted_logits", ",", "sorted_indices", "=", "torch", ".", "sort", "(", "logits", ",", "descending", "=", "True", ")", "\n", "cumulative_probs", "=", "torch", ".", "cumsum", "(", "F", ".", "softmax", "(", "sorted_logits", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Remove tokens with cumulative probability above the threshold (token with 0 are kept)", "\n", "sorted_indices_to_remove", "=", "cumulative_probs", ">", "top_p", "\n", "if", "min_tokens_to_keep", ">", "1", ":", "\n", "# Keep at least min_tokens_to_keep (set to min_tokens_to_keep-1 because we add the first one below)", "\n", "            ", "sorted_indices_to_remove", "[", "...", ",", ":", "min_tokens_to_keep", "]", "=", "0", "\n", "# Shift the indices to the right to keep also the first token above the threshold", "\n", "", "sorted_indices_to_remove", "[", "...", ",", "1", ":", "]", "=", "sorted_indices_to_remove", "[", "...", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "sorted_indices_to_remove", "[", "...", ",", "0", "]", "=", "0", "\n", "\n", "# scatter sorted tensors to original indexing", "\n", "indices_to_remove", "=", "sorted_indices_to_remove", ".", "scatter", "(", "1", ",", "sorted_indices", ",", "sorted_indices_to_remove", ")", "\n", "logits", "[", "indices_to_remove", "]", "=", "filter_value", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.CaptionBertSelfAttention.__init__": [[27, 29], ["transformers.pytorch_transformers.modeling_bert.BertSelfAttention.__init__"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "CaptionBertSelfAttention", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.CaptionBertSelfAttention.forward": [[30, 71], ["modeling_bert.CaptionBertSelfAttention.transpose_for_scores", "modeling_bert.CaptionBertSelfAttention.transpose_for_scores", "modeling_bert.CaptionBertSelfAttention.transpose_for_scores", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "modeling_bert.CaptionBertSelfAttention.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_bert.CaptionBertSelfAttention.query", "modeling_bert.CaptionBertSelfAttention.key", "modeling_bert.CaptionBertSelfAttention.value", "modeling_bert.CaptionBertSelfAttention.query", "modeling_bert.CaptionBertSelfAttention.key", "modeling_bert.CaptionBertSelfAttention.value", "modeling_bert.CaptionBertSelfAttention.transpose", "math.sqrt", "torch.nn.Softmax", "torch.nn.Softmax", "context_layer.view.view.permute", "context_layer.view.view.size"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "None", ",", "\n", "history_state", "=", "None", ")", ":", "\n", "        ", "if", "history_state", "is", "not", "None", ":", "\n", "            ", "x_states", "=", "torch", ".", "cat", "(", "[", "history_state", ",", "hidden_states", "]", ",", "dim", "=", "1", ")", "\n", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "x_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "x_states", ")", "\n", "", "else", ":", "\n", "            ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attention_probs", "=", "attention_probs", "*", "head_mask", "\n", "\n", "", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "\n", "outputs", "=", "(", "context_layer", ",", "attention_probs", ")", "if", "self", ".", "output_attentions", "else", "(", "context_layer", ",", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.CaptionBertAttention.__init__": [[77, 81], ["transformers.pytorch_transformers.modeling_bert.BertAttention.__init__", "modeling_bert.CaptionBertSelfAttention", "transformers.pytorch_transformers.modeling_bert.BertSelfOutput"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "CaptionBertAttention", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "self", "=", "CaptionBertSelfAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "BertSelfOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.CaptionBertAttention.forward": [[82, 88], ["modeling_bert.CaptionBertAttention.self", "modeling_bert.CaptionBertAttention.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_tensor", ",", "attention_mask", ",", "head_mask", "=", "None", ",", "\n", "history_state", "=", "None", ")", ":", "\n", "        ", "self_outputs", "=", "self", ".", "self", "(", "input_tensor", ",", "attention_mask", ",", "head_mask", ",", "history_state", ")", "\n", "attention_output", "=", "self", ".", "output", "(", "self_outputs", "[", "0", "]", ",", "input_tensor", ")", "\n", "outputs", "=", "(", "attention_output", ",", ")", "+", "self_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.CaptionBertEncoder.__init__": [[94, 99], ["transformers.pytorch_transformers.modeling_bert.BertEncoder.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "modeling_bert.CaptionBertLayer", "range"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "CaptionBertEncoder", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "CaptionBertLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.CaptionBertEncoder.forward": [[100, 127], ["enumerate", "layer_module"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "None", ",", "\n", "encoder_history_states", "=", "None", ")", ":", "\n", "        ", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "history_state", "=", "None", "if", "encoder_history_states", "is", "None", "else", "encoder_history_states", "[", "i", "]", "\n", "layer_outputs", "=", "layer_module", "(", "\n", "hidden_states", ",", "attention_mask", ",", "head_mask", "[", "i", "]", ",", "\n", "history_state", ")", "\n", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "\n", "# Add last layer", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# outputs, (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.CaptionBertLayer.__init__": [[133, 138], ["transformers.pytorch_transformers.modeling_bert.BertLayer.__init__", "modeling_bert.CaptionBertAttention", "transformers.pytorch_transformers.modeling_bert.BertIntermediate", "transformers.pytorch_transformers.modeling_bert.BertOutput"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "CaptionBertLayer", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "attention", "=", "CaptionBertAttention", "(", "config", ")", "\n", "self", ".", "intermediate", "=", "BertIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "BertOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.CaptionBertLayer.forward": [[139, 148], ["modeling_bert.CaptionBertLayer.attention", "modeling_bert.CaptionBertLayer.intermediate", "modeling_bert.CaptionBertLayer.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "None", ",", "\n", "history_state", "=", "None", ")", ":", "\n", "        ", "attention_outputs", "=", "self", ".", "attention", "(", "hidden_states", ",", "attention_mask", ",", "\n", "head_mask", ",", "history_state", ")", "\n", "attention_output", "=", "attention_outputs", "[", "0", "]", "\n", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "attention_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgModel.__init__": [[153, 184], ["transformers.pytorch_transformers.modeling_bert.BertPreTrainedModel.__init__", "transformers.pytorch_transformers.modeling_bert.BertEmbeddings", "modeling_bert.CaptionBertEncoder", "transformers.pytorch_transformers.modeling_bert.BertPooler", "logger.info", "hasattr", "modeling_bert.BertImgModel.apply", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "transformers.pytorch_transformers.modeling_bert.BertLayerNorm"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertImgModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "embeddings", "=", "BertEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "CaptionBertEncoder", "(", "config", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "\n", "self", ".", "img_dim", "=", "config", ".", "img_feature_dim", "\n", "logger", ".", "info", "(", "'BertImgModel Image Dimension: {}'", ".", "format", "(", "self", ".", "img_dim", ")", ")", "\n", "self", ".", "img_feature_type", "=", "config", ".", "img_feature_type", "\n", "if", "hasattr", "(", "config", ",", "'use_img_layernorm'", ")", ":", "\n", "            ", "self", ".", "use_img_layernorm", "=", "config", ".", "use_img_layernorm", "\n", "", "else", ":", "\n", "            ", "self", ".", "use_img_layernorm", "=", "None", "\n", "\n", "", "if", "config", ".", "img_feature_type", "==", "'dis_code'", ":", "\n", "            ", "self", ".", "code_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "code_voc", ",", "config", ".", "code_dim", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "img_embedding", "=", "nn", ".", "Linear", "(", "config", ".", "code_dim", ",", "self", ".", "config", ".", "hidden_size", ",", "bias", "=", "True", ")", "\n", "", "elif", "config", ".", "img_feature_type", "==", "'dis_code_t'", ":", "# transpose", "\n", "            ", "self", ".", "code_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "code_voc", ",", "config", ".", "code_dim", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "img_embedding", "=", "nn", ".", "Linear", "(", "config", ".", "code_size", ",", "self", ".", "config", ".", "hidden_size", ",", "bias", "=", "True", ")", "\n", "", "elif", "config", ".", "img_feature_type", "==", "'dis_code_scale'", ":", "# scaled", "\n", "            ", "self", ".", "input_embeddings", "=", "nn", ".", "Linear", "(", "config", ".", "code_dim", ",", "config", ".", "code_size", ",", "bias", "=", "True", ")", "\n", "self", ".", "code_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "code_voc", ",", "config", ".", "code_dim", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "img_embedding", "=", "nn", ".", "Linear", "(", "config", ".", "code_dim", ",", "self", ".", "config", ".", "hidden_size", ",", "bias", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "img_embedding", "=", "nn", ".", "Linear", "(", "self", ".", "img_dim", ",", "self", ".", "config", ".", "hidden_size", ",", "bias", "=", "True", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "if", "self", ".", "use_img_layernorm", ":", "\n", "                ", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "img_layer_norm_eps", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgModel._resize_token_embeddings": [[185, 190], ["modeling_bert.BertImgModel._get_resized_embeddings"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "old_embeddings", "=", "self", ".", "embeddings", ".", "word_embeddings", "\n", "new_embeddings", "=", "self", ".", "_get_resized_embeddings", "(", "old_embeddings", ",", "new_num_tokens", ")", "\n", "self", ".", "embeddings", ".", "word_embeddings", "=", "new_embeddings", "\n", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgModel._prune_heads": [[191, 198], ["heads_to_prune.items", "modeling_bert.BertImgModel.encoder.layer[].attention.prune_heads"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n            See base class PreTrainedModel\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgModel.forward": [[199, 280], ["torch.ones_like.unsqueeze.to", "modeling_bert.BertImgModel.embeddings", "modeling_bert.BertImgModel.encoder", "modeling_bert.BertImgModel.pooler", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.ones_like.dim", "torch.ones_like.dim", "torch.ones_like.unsqueeze().unsqueeze", "torch.ones_like.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones_like.dim", "torch.ones_like.dim", "torch.ones_like.unsqueeze", "torch.ones_like.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "modeling_bert.BertImgModel.code_embeddings", "modeling_bert.BertImgModel.img_embedding", "torch.ones_like.unsqueeze", "torch.ones_like.unsqueeze", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "modeling_bert.BertImgModel.code_embeddings", "modeling_bert.BertImgModel.permute", "modeling_bert.BertImgModel.img_embedding", "modeling_bert.BertImgModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "modeling_bert.BertImgModel.code_embeddings", "modeling_bert.BertImgModel.img_embedding", "modeling_bert.BertImgModel.img_embedding", "modeling_bert.BertImgModel.dropout", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_bert.BertImgModel.parameters", "modeling_bert.BertImgModel.LayerNorm", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "img_feats", "=", "None", ",", "\n", "encoder_history_states", "=", "None", ")", ":", "\n", "        ", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones_like", "(", "input_ids", ")", "\n", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "", "if", "attention_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "", "elif", "attention_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "            ", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "num_hidden_layers", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "# We can specify head_mask for each layer", "\n", "# switch to float if needed + fp16 compatibility", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "num_hidden_layers", "\n", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ")", "\n", "if", "encoder_history_states", ":", "\n", "            ", "assert", "img_feats", "is", "None", ",", "\"Cannot take image features while using encoder history states\"", "\n", "\n", "", "if", "img_feats", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "img_feature_type", "==", "'dis_code'", ":", "\n", "                ", "code_emb", "=", "self", ".", "code_embeddings", "(", "img_feats", ")", "\n", "img_embedding_output", "=", "self", ".", "img_embedding", "(", "code_emb", ")", "\n", "", "elif", "self", ".", "img_feature_type", "==", "'dis_code_t'", ":", "# transpose", "\n", "                ", "code_emb", "=", "self", ".", "code_embeddings", "(", "img_feats", ")", "\n", "code_emb", "=", "code_emb", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "img_embedding_output", "=", "self", ".", "img_embedding", "(", "code_emb", ")", "\n", "", "elif", "self", ".", "img_feature_type", "==", "'dis_code_scale'", ":", "# left scaled", "\n", "                ", "code_emb", "=", "self", ".", "code_embeddings", "(", "img_feats", ")", "\n", "img_embedding_output", "=", "self", ".", "img_embedding", "(", "code_emb", ")", "\n", "", "else", ":", "\n", "                ", "img_embedding_output", "=", "self", ".", "img_embedding", "(", "img_feats", ")", "\n", "if", "self", ".", "use_img_layernorm", ":", "\n", "                    ", "img_embedding_output", "=", "self", ".", "LayerNorm", "(", "img_embedding_output", ")", "\n", "\n", "# add dropout on image embedding", "\n", "", "img_embedding_output", "=", "self", ".", "dropout", "(", "img_embedding_output", ")", "\n", "\n", "# concatenate two embeddings", "\n", "", "embedding_output", "=", "torch", ".", "cat", "(", "(", "embedding_output", ",", "img_embedding_output", ")", ",", "1", ")", "\n", "\n", "", "encoder_outputs", "=", "self", ".", "encoder", "(", "embedding_output", ",", "\n", "extended_attention_mask", ",", "head_mask", "=", "head_mask", ",", "\n", "encoder_history_states", "=", "encoder_history_states", ")", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "\n", "# add hidden_states and attentions if they are here", "\n", "outputs", "=", "(", "sequence_output", ",", "pooled_output", ",", ")", "+", "encoder_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.ImageBertForSequenceClassification.__init__": [[294, 321], ["transformers.pytorch_transformers.modeling_bert.BertPreTrainedModel.__init__", "torch.nn.Dropout", "torch.nn.Dropout", "hasattr", "modeling_bert.ImageBertForSequenceClassification.apply", "modeling_bert.BertImgModel", "BertModel", "torch.nn.Linear", "torch.nn.Linear", "hasattr", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "ImageBertForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "self", ".", "loss_type", "=", "config", ".", "loss_type", "\n", "self", ".", "config", "=", "config", "\n", "if", "config", ".", "img_feature_dim", ">", "0", ":", "\n", "            ", "self", ".", "bert", "=", "BertImgModel", "(", "config", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n", "if", "hasattr", "(", "config", ",", "'classifier'", ")", ":", "\n", "            ", "if", "not", "hasattr", "(", "config", ",", "'cls_hidden_scale'", ")", ":", "\n", "                ", "config", ".", "cls_hidden_scale", "=", "2", "\n", "\n", "", "if", "config", ".", "classifier", "==", "'linear'", ":", "\n", "                ", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "\n", "self", ".", "config", ".", "num_labels", ")", "\n", "", "elif", "config", ".", "classifier", "==", "'mlp'", ":", "\n", "                ", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", "*", "config", ".", "cls_hidden_scale", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "config", ".", "cls_hidden_scale", ",", "self", ".", "config", ".", "num_labels", ")", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "config", ".", "num_labels", ")", "# original", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.ImageBertForSequenceClassification.init_code_embedding": [[322, 324], ["em.clone"], "methods", ["None"], ["", "def", "init_code_embedding", "(", "self", ",", "em", ")", ":", "\n", "        ", "self", ".", "bert", ".", "code_embeddings", ".", "weight", ".", "data", "=", "em", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.ImageBertForSequenceClassification.forward": [[325, 355], ["modeling_bert.ImageBertForSequenceClassification.bert", "modeling_bert.ImageBertForSequenceClassification.dropout", "modeling_bert.ImageBertForSequenceClassification.classifier", "torch.nn.MSELoss", "torch.nn.MSELoss", "labels.to.to.to", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_bert.ImageBertForSequenceClassification.view", "labels.to.to.view", "torch.nn.KLDivLoss", "torch.nn.KLDivLoss", "torch.nn.KLDivLoss", "torch.nn.KLDivLoss", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax", "modeling_bert.ImageBertForSequenceClassification.contiguous().view", "torch.nn.LogSoftmax.", "torch.nn.LogSoftmax.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "labels.to.to.contiguous", "modeling_bert.instance_bce_with_logits", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_bert.ImageBertForSequenceClassification.contiguous", "modeling_bert.ImageBertForSequenceClassification.view", "labels.to.to.view"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.instance_bce_with_logits"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "img_feats", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ",", "img_feats", "=", "img_feats", ")", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "#  doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "labels", "=", "labels", ".", "to", "(", "torch", ".", "float", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "loss_type", "==", "'kl'", ":", "\n", "# KL Loss: https://github.com/uclanlp/visualbert/blob/master/pytorch_pretrained_bert/modeling.py", "\n", "                    ", "loss_fct", "=", "torch", ".", "nn", ".", "KLDivLoss", "(", "reduction", "=", "\"batchmean\"", ")", "\n", "log_softmax", "=", "torch", ".", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", "\n", "reshaped_logits", "=", "logits", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "3129", ")", "\n", "reshaped_logits", "=", "log_softmax", "(", "reshaped_logits", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ".", "contiguous", "(", ")", ")", "\n", "", "elif", "self", ".", "loss_type", "==", "'bce'", ":", "# [VQA]", "\n", "                    ", "loss", "=", "instance_bce_with_logits", "(", "logits", ",", "labels", ")", "\n", "", "else", ":", "# cross_entropy [GQA, Retrieval, Captioning]", "\n", "                    ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.ImageBertForMultipleChoice.__init__": [[361, 397], ["transformers.pytorch_transformers.modeling_bert.BertPreTrainedModel.__init__", "hasattr", "torch.nn.Dropout", "torch.nn.Dropout", "hasattr", "modeling_bert.ImageBertForMultipleChoice.apply", "modeling_bert.BertImgModel", "BertModel", "torch.nn.Linear", "torch.nn.Linear", "hasattr", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "transformers.pytorch_transformers.modeling_bert.BertLayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "ImageBertForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "loss_type", "=", "config", ".", "loss_type", "\n", "if", "config", ".", "img_feature_dim", ">", "0", ":", "\n", "            ", "self", ".", "bert", "=", "BertImgModel", "(", "config", ")", "# ImageBERT", "\n", "", "else", ":", "\n", "            ", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "# original BERT", "\n", "\n", "", "if", "hasattr", "(", "config", ",", "'use_img_layernorm'", ")", ":", "\n", "            ", "self", ".", "use_img_layernorm", "=", "config", ".", "use_img_layernorm", "\n", "", "else", ":", "\n", "            ", "self", ".", "use_img_layernorm", "=", "None", "\n", "\n", "", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "if", "hasattr", "(", "config", ",", "'classifier'", ")", ":", "\n", "            ", "if", "not", "hasattr", "(", "config", ",", "'cls_hidden_scale'", ")", ":", "config", ".", "cls_hidden_scale", "=", "2", "\n", "if", "config", ".", "classifier", "==", "'linear'", ":", "\n", "                ", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "num_choice", "*", "config", ".", "hidden_size", ",", "self", ".", "config", ".", "num_labels", ")", "\n", "", "elif", "config", ".", "classifier", "==", "'mlp'", ":", "\n", "                ", "if", "self", ".", "use_img_layernorm", ":", "\n", "                    ", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "config", ".", "num_choice", "*", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", "*", "config", ".", "cls_hidden_scale", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "BertLayerNorm", "(", "config", ".", "hidden_size", "*", "config", ".", "cls_hidden_scale", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "config", ".", "cls_hidden_scale", ",", "self", ".", "config", ".", "num_labels", ")", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "config", ".", "num_choice", "*", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", "*", "config", ".", "cls_hidden_scale", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "config", ".", "cls_hidden_scale", ",", "self", ".", "config", ".", "num_labels", ")", "\n", ")", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "num_choice", "*", "config", ".", "hidden_size", ",", "self", ".", "config", ".", "num_labels", ")", "# original", "\n", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.ImageBertForMultipleChoice.forward": [[398, 433], ["input_ids.view", "isinstance", "modeling_bert.ImageBertForMultipleChoice.dropout", "modeling_bert.ImageBertForMultipleChoice.view", "modeling_bert.ImageBertForMultipleChoice.classifier", "input_ids.size", "position_ids.view", "token_type_ids.view", "attention_mask.view", "img_feats.view", "modeling_bert.ImageBertForMultipleChoice.bert", "modeling_bert.ImageBertForMultipleChoice.bert", "position_ids.size", "token_type_ids.size", "attention_mask.size", "img_feats.size", "img_feats.size", "modeling_bert.instance_bce_with_logits", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "labels.view"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.instance_bce_with_logits"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "img_feats", "=", "None", ")", ":", "\n", "        ", "num_choices", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "\n", "flat_input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "position_ids", ".", "size", "(", "-", "1", ")", ")", "if", "position_ids", "is", "not", "None", "else", "None", "\n", "flat_token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "flat_attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "\n", "flat_img_feats", "=", "img_feats", ".", "view", "(", "-", "1", ",", "img_feats", ".", "size", "(", "-", "2", ")", ",", "img_feats", ".", "size", "(", "-", "1", ")", ")", "if", "img_feats", "is", "not", "None", "else", "None", "\n", "\n", "if", "isinstance", "(", "self", ".", "bert", ",", "BertImgModel", ")", ":", "\n", "            ", "outputs", "=", "self", ".", "bert", "(", "flat_input_ids", ",", "position_ids", "=", "flat_position_ids", ",", "token_type_ids", "=", "flat_token_type_ids", ",", "\n", "attention_mask", "=", "flat_attention_mask", ",", "head_mask", "=", "head_mask", ",", "img_feats", "=", "flat_img_feats", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "self", ".", "bert", "(", "flat_input_ids", ",", "position_ids", "=", "flat_position_ids", ",", "token_type_ids", "=", "flat_token_type_ids", ",", "\n", "attention_mask", "=", "flat_attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "\n", "# reshaped_pool_output", "\n", "reshaped_pool_output", "=", "pooled_output", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "num_choice", "*", "(", "pooled_output", ".", "shape", "[", "1", "]", ")", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "reshaped_pool_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "loss_type", "==", "'bce'", ":", "\n", "                ", "loss", "=", "instance_bce_with_logits", "(", "logits", ",", "labels", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "num_labels", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ",", "labels", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.OscarForMultipleChoice.__init__": [[506, 531], ["transformers.pytorch_transformers.modeling_bert.BertPreTrainedModel.__init__", "torch.nn.Dropout", "torch.nn.Dropout", "hasattr", "modeling_bert.OscarForMultipleChoice.apply", "modeling_bert.BertImgModel", "BertModel", "torch.nn.Linear", "torch.nn.Linear", "hasattr", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "OscarForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "loss_type", "=", "config", ".", "loss_type", "\n", "\n", "if", "config", ".", "img_feature_dim", ">", "0", ":", "\n", "            ", "self", ".", "bert", "=", "BertImgModel", "(", "config", ")", "# ImageBERT", "\n", "", "else", ":", "\n", "            ", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "# original BERT", "\n", "\n", "", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n", "if", "hasattr", "(", "config", ",", "'classifier'", ")", ":", "\n", "            ", "if", "not", "hasattr", "(", "config", ",", "'cls_hidden_scale'", ")", ":", "config", ".", "cls_hidden_scale", "=", "2", "\n", "\n", "if", "config", ".", "classifier", "==", "'linear'", ":", "\n", "                ", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "# original", "\n", "#self.classifier = weight_norm(nn.Linear(config.hidden_size, self.config.num_labels), dim=None)", "\n", "", "elif", "config", ".", "classifier", "==", "'mlp'", ":", "\n", "                ", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", "*", "config", ".", "cls_hidden_scale", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "config", ".", "cls_hidden_scale", ",", "2", ")", ")", "# bce loss", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "# original", "\n", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.OscarForMultipleChoice.forward": [[532, 573], ["input_ids.view", "isinstance", "modeling_bert.OscarForMultipleChoice.dropout", "modeling_bert.OscarForMultipleChoice.classifier", "input_ids.size", "position_ids.view", "token_type_ids.view", "attention_mask.view", "img_feats.view", "modeling_bert.OscarForMultipleChoice.bert", "modeling_bert.OscarForMultipleChoice.bert", "position_ids.size", "token_type_ids.size", "attention_mask.size", "img_feats.size", "img_feats.size", "modeling_bert.instance_bce_with_logits", "labels.view", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "labels.view"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.instance_bce_with_logits"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "img_feats", "=", "None", ")", ":", "\n", "        ", "num_choices", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "\n", "flat_input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "position_ids", ".", "size", "(", "-", "1", ")", ")", "if", "position_ids", "is", "not", "None", "else", "None", "\n", "flat_token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "flat_attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "\n", "flat_img_feats", "=", "img_feats", ".", "view", "(", "-", "1", ",", "img_feats", ".", "size", "(", "-", "2", ")", ",", "img_feats", ".", "size", "(", "-", "1", ")", ")", "if", "img_feats", "is", "not", "None", "else", "None", "\n", "\n", "if", "isinstance", "(", "self", ".", "bert", ",", "BertImgModel", ")", ":", "\n", "            ", "outputs", "=", "self", ".", "bert", "(", "flat_input_ids", ",", "position_ids", "=", "flat_position_ids", ",", "token_type_ids", "=", "flat_token_type_ids", ",", "\n", "attention_mask", "=", "flat_attention_mask", ",", "head_mask", "=", "head_mask", ",", "img_feats", "=", "flat_img_feats", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "self", ".", "bert", "(", "flat_input_ids", ",", "position_ids", "=", "flat_position_ids", ",", "token_type_ids", "=", "flat_token_type_ids", ",", "\n", "attention_mask", "=", "flat_attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "#logger.info('pooled_output: {}, reshaped_pool_output: {}, logits: {}'.format(pooled_output.shape, reshaped_pool_output.shape, logits.shape))", "\n", "#logger.info('logits: {}, reshaped_logits: {}'.format(logits.shape, reshaped_logits.shape))", "\n", "#logger.info('labels: {}, labels.veiw: {}, labels.view(-1, num_labels): {}'.format(labels.shape, labels.view(-1).shape, labels.view(-1, self.config.num_labels).shape))", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "loss_type", "==", "'bce'", ":", "#[batch_size, 2] v1", "\n", "#loss = instance_bce_with_logits(reshaped_logits, labels)", "\n", "                ", "loss", "=", "instance_bce_with_logits", "(", "logits", ",", "labels", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "num_labels", ")", ")", "\n", "", "elif", "self", ".", "loss_type", "==", "'bxe'", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "#loss = loss_fct(reshaped_logits, labels)", "\n", "loss", "=", "loss_fct", "(", "logits", ",", "labels", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), reshaped_logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertCaptioningLoss.__init__": [[576, 584], ["torch.nn.Module.__init__", "getattr", "getattr", "getattr", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax", "torch.nn.KLDivLoss", "torch.nn.KLDivLoss"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "label_smoothing", "=", "getattr", "(", "config", ",", "'label_smoothing'", ",", "0", ")", "\n", "self", ".", "drop_worst_ratio", "=", "getattr", "(", "config", ",", "'drop_worst_ratio'", ",", "0", ")", "\n", "self", ".", "drop_worst_after", "=", "getattr", "(", "config", ",", "'drop_worst_after'", ",", "0", ")", "\n", "self", ".", "log_soft", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "1", ")", "\n", "self", ".", "kl", "=", "nn", ".", "KLDivLoss", "(", "reduction", "=", "'none'", ")", "\n", "self", ".", "iter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertCaptioningLoss.forward": [[585, 602], ["logits.size", "torch.zeros_like().scatter", "torch.zeros_like().scatter", "torch.zeros_like().scatter", "torch.zeros_like().scatter", "modeling_bert.BertCaptioningLoss.log_soft", "modeling_bert.BertCaptioningLoss.kl().sum", "loss.mean.mean.mean", "target.view", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "modeling_bert.BertCaptioningLoss.kl", "int"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "def", "forward", "(", "self", ",", "logits", ",", "target", ")", ":", "\n", "        ", "self", ".", "iter", "+=", "1", "\n", "eps", "=", "self", ".", "label_smoothing", "\n", "n_class", "=", "logits", ".", "size", "(", "1", ")", "\n", "one_hot", "=", "torch", ".", "zeros_like", "(", "logits", ")", ".", "scatter", "(", "1", ",", "target", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", "\n", "one_hot", "=", "one_hot", "*", "(", "1", "-", "eps", ")", "+", "(", "1", "-", "one_hot", ")", "*", "eps", "/", "(", "n_class", "-", "1", ")", "\n", "log_prb", "=", "self", ".", "log_soft", "(", "logits", ")", "\n", "loss", "=", "self", ".", "kl", "(", "log_prb", ",", "one_hot", ")", ".", "sum", "(", "1", ")", "\n", "\n", "if", "self", ".", "drop_worst_ratio", ">", "0", "and", "self", ".", "iter", ">", "self", ".", "drop_worst_after", ":", "\n", "            ", "loss", ",", "_", "=", "torch", ".", "topk", "(", "loss", ",", "\n", "k", "=", "int", "(", "loss", ".", "shape", "[", "0", "]", "*", "(", "1", "-", "self", ".", "drop_worst_ratio", ")", ")", ",", "\n", "largest", "=", "False", ")", "\n", "\n", "", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning.__init__": [[608, 617], ["modeling_utils.CaptionPreTrainedModel.__init__", "modeling_bert.BertImgModel", "transformers.pytorch_transformers.modeling_bert.BertOnlyMLMHead", "modeling_bert.BertCaptioningLoss", "modeling_bert.BertForImageCaptioning.apply", "modeling_bert.BertForImageCaptioning.tie_weights"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForImageCaptioning", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "bert", "=", "BertImgModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyMLMHead", "(", "config", ")", "\n", "self", ".", "loss", "=", "BertCaptioningLoss", "(", "config", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning.tie_weights": [[618, 626], ["hasattr", "hasattr", "modeling_bert.BertForImageCaptioning._tie_or_clone_weights"], "methods", ["None"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "config", ",", "'tie_weights'", ")", "and", "self", ".", "config", ".", "tie_weights", ":", "\n", "            ", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "cls", ".", "predictions", ".", "decoder", ",", "\n", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ")", "\n", "", "freeze", "=", "False", "\n", "if", "hasattr", "(", "self", ".", "config", ",", "'freeze_embedding'", ")", ":", "\n", "            ", "freeze", "=", "self", ".", "config", ".", "freeze_embedding", "\n", "", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ".", "requires_grad", "=", "not", "freeze", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning.forward": [[627, 633], ["kwargs.get", "modeling_bert.BertForImageCaptioning.generate", "modeling_bert.BertForImageCaptioning.encode_forward"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning.generate", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning.encode_forward"], ["", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "is_decode", "=", "kwargs", ".", "get", "(", "'is_decode'", ",", "False", ")", "\n", "if", "is_decode", ":", "\n", "            ", "return", "self", ".", "generate", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "encode_forward", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning.encode_forward": [[634, 656], ["modeling_bert.BertForImageCaptioning.bert", "modeling_bert.BertForImageCaptioning.cls", "modeling_bert.BertForImageCaptioning.loss", "modeling_bert.BertForImageCaptioning.cls", "modeling_bert.BertForImageCaptioning.float"], "methods", ["None"], ["", "", "def", "encode_forward", "(", "self", ",", "input_ids", ",", "img_feats", ",", "attention_mask", ",", "masked_pos", ",", "masked_ids", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "\n", "is_training", "=", "True", ",", "encoder_history_states", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "img_feats", "=", "img_feats", ",", "attention_mask", "=", "attention_mask", ",", "\n", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "encoder_history_states", "=", "encoder_history_states", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "[", ":", ",", ":", "masked_pos", ".", "shape", "[", "-", "1", "]", ",", ":", "]", "\n", "\n", "if", "is_training", ":", "\n", "            ", "sequence_output", "=", "outputs", "[", "0", "]", "[", ":", ",", ":", "masked_pos", ".", "shape", "[", "-", "1", "]", ",", ":", "]", "\n", "# num_masks_in_batch * hidden_size", "\n", "sequence_output_masked", "=", "sequence_output", "[", "masked_pos", "==", "1", ",", ":", "]", "\n", "class_logits", "=", "self", ".", "cls", "(", "sequence_output_masked", ")", "\n", "masked_ids", "=", "masked_ids", "[", "masked_ids", "!=", "0", "]", "# remove padding masks", "\n", "masked_loss", "=", "self", ".", "loss", "(", "class_logits", ".", "float", "(", ")", ",", "masked_ids", ")", "\n", "outputs", "=", "(", "masked_loss", ",", "class_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "", "else", ":", "\n", "            ", "sequence_output", "=", "outputs", "[", "0", "]", "[", ":", ",", ":", "input_ids", ".", "shape", "[", "-", "1", "]", ",", ":", "]", "\n", "class_logits", "=", "self", ".", "cls", "(", "sequence_output", ")", "\n", "outputs", "=", "(", "class_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning.prepare_inputs_for_generation": [[658, 757], ["torch.full", "torch.full", "torch.full", "torch.full", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_bert.BertForImageCaptioning.prepare_inputs_for_generation._remove_rows_cols"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "curr_ids", ",", "past", "=", "None", ")", ":", "\n", "# NOTE: if attention is on, it should be the token used to mask words in training", "\n", "        ", "mask_token_id", "=", "self", ".", "mask_token_id", "\n", "batch_size", "=", "curr_ids", ".", "shape", "[", "0", "]", "\n", "mask_ids", "=", "torch", ".", "full", "(", "\n", "(", "batch_size", ",", "1", ")", ",", "mask_token_id", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "curr_ids", ".", "device", "\n", ")", "\n", "\n", "def", "_slice", "(", "t", ",", "start", ",", "end", ")", ":", "\n", "            ", "if", "t", "is", "None", ":", "\n", "                ", "return", "t", "\n", "", "assert", "t", ".", "shape", "==", "(", "batch_size", ",", "self", ".", "max_seq_len", "+", "self", ".", "od_labels_len", ")", "\n", "return", "t", "[", ":", ",", "start", ":", "end", "]", "\n", "\n", "", "def", "_remove_elements", "(", "t", ",", "start", ",", "end", ")", ":", "\n", "            ", "if", "t", "is", "None", ":", "\n", "                ", "return", "t", "\n", "", "assert", "t", ".", "shape", "==", "(", "batch_size", ",", "self", ".", "max_seq_len", "+", "self", ".", "od_labels_len", ")", "\n", "return", "torch", ".", "cat", "(", "[", "t", "[", ":", ",", ":", "start", "]", ",", "t", "[", ":", ",", "end", ":", "]", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "if", "past", "is", "None", ":", "\n", "            ", "input_ids", "=", "torch", ".", "cat", "(", "[", "curr_ids", ",", "mask_ids", "]", ",", "dim", "=", "1", ")", "\n", "\n", "curr_len", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "full_len", "=", "self", ".", "max_seq_len", "+", "self", ".", "od_labels_len", "+", "self", ".", "img_seq_len", "\n", "assert", "self", ".", "full_attention_mask", ".", "shape", "==", "(", "batch_size", ",", "\n", "full_len", ",", "full_len", ")", "\n", "\n", "def", "_remove_rows_cols", "(", "t", ",", "row_start", ",", "row_end", ",", "col_start", ",", "col_end", ")", ":", "\n", "                ", "t00", "=", "t", "[", ":", ",", ":", "row_start", ",", ":", "col_start", "]", "\n", "t01", "=", "t", "[", ":", ",", ":", "row_start", ",", "col_end", ":", "]", "\n", "t10", "=", "t", "[", ":", ",", "row_end", ":", ",", ":", "col_start", "]", "\n", "t11", "=", "t", "[", ":", ",", "row_end", ":", ",", "col_end", ":", "]", "\n", "res", "=", "torch", ".", "cat", "(", "[", "torch", ".", "cat", "(", "[", "t00", ",", "t01", "]", ",", "dim", "=", "2", ")", ",", "torch", ".", "cat", "(", "[", "t10", ",", "t11", "]", ",", "\n", "dim", "=", "2", ")", "]", ",", "dim", "=", "1", ")", "\n", "assert", "res", ".", "shape", "==", "(", "t", ".", "shape", "[", "0", "]", ",", "t", ".", "shape", "[", "1", "]", "-", "row_end", "+", "row_start", ",", "\n", "t", ".", "shape", "[", "2", "]", "-", "col_end", "+", "col_start", ")", "\n", "return", "res", "\n", "\n", "", "seq_start", "=", "curr_len", "\n", "seq_end", "=", "self", ".", "max_seq_len", "\n", "attention_mask", "=", "_remove_rows_cols", "(", "self", ".", "full_attention_mask", ",", "seq_start", ",", "\n", "seq_end", ",", "seq_start", ",", "seq_end", ")", "\n", "\n", "masked_pos", "=", "_remove_elements", "(", "self", ".", "full_masked_pos", ",", "seq_start", ",", "seq_end", ")", "\n", "token_type_ids", "=", "_remove_elements", "(", "self", ".", "full_token_type_ids", ",", "seq_start", ",", "seq_end", ")", "\n", "position_ids", "=", "_remove_elements", "(", "self", ".", "full_position_ids", ",", "seq_start", ",", "seq_end", ")", "\n", "img_feats", "=", "self", ".", "img_feats", "\n", "\n", "if", "self", ".", "add_od_labels", ":", "\n", "                ", "assert", "self", ".", "od_label_ids", ".", "shape", "[", "1", "]", "==", "self", ".", "od_labels_len", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "input_ids", ",", "self", ".", "od_label_ids", "]", ",", "dim", "=", "1", ")", "\n", "", "", "else", ":", "\n", "            ", "last_token", "=", "curr_ids", "[", ":", ",", "-", "1", ":", "]", "\n", "# The representation of last token should be re-computed, because", "\n", "# it depends on both self-attention context and input tensor", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "last_token", ",", "mask_ids", "]", ",", "dim", "=", "1", ")", "\n", "start_pos", "=", "curr_ids", ".", "shape", "[", "1", "]", "-", "1", "\n", "end_pos", "=", "start_pos", "+", "input_ids", ".", "shape", "[", "1", "]", "\n", "masked_pos", "=", "_slice", "(", "self", ".", "full_masked_pos", ",", "start_pos", ",", "end_pos", ")", "\n", "token_type_ids", "=", "_slice", "(", "self", ".", "full_token_type_ids", ",", "start_pos", ",", "end_pos", ")", "\n", "position_ids", "=", "_slice", "(", "self", ".", "full_position_ids", ",", "start_pos", ",", "end_pos", ")", "\n", "\n", "img_feats", "=", "None", "\n", "assert", "past", "[", "0", "]", ".", "shape", "[", "0", "]", "==", "batch_size", "\n", "if", "self", ".", "prev_encoded_layers", "is", "None", ":", "\n", "                ", "assert", "start_pos", "==", "1", "# the first token after BOS", "\n", "assert", "past", "[", "0", "]", ".", "shape", "[", "1", "]", "==", "2", "+", "self", ".", "od_labels_len", "+", "self", ".", "img_seq_len", "\n", "# reorder to [od_labels, img_feats, sentence]", "\n", "self", ".", "prev_encoded_layers", "=", "[", "\n", "torch", ".", "cat", "(", "[", "x", "[", ":", ",", "2", ":", ",", ":", "]", ",", "x", "[", ":", ",", ":", "start_pos", ",", ":", "]", "]", ",", "dim", "=", "1", ")", "\n", "for", "x", "in", "past", "]", "\n", "s2s", "=", "self", ".", "full_attention_mask", "[", ":", ",", ":", "self", ".", "max_seq_len", ",", "\n", ":", "self", ".", "max_seq_len", "]", "\n", "s2i", "=", "self", ".", "full_attention_mask", "[", ":", ",", ":", "self", ".", "max_seq_len", ",", "\n", "self", ".", "max_seq_len", ":", "]", "\n", "i2s", "=", "self", ".", "full_attention_mask", "[", ":", ",", "self", ".", "max_seq_len", ":", ",", "\n", ":", "self", ".", "max_seq_len", "]", "\n", "i2i", "=", "self", ".", "full_attention_mask", "[", ":", ",", "self", ".", "max_seq_len", ":", ",", "\n", "self", ".", "max_seq_len", ":", "]", "\n", "self", ".", "full_attention_mask", "=", "torch", ".", "cat", "(", "\n", "[", "torch", ".", "cat", "(", "[", "i2i", ",", "i2s", "]", ",", "dim", "=", "2", ")", ",", "\n", "torch", ".", "cat", "(", "[", "s2i", ",", "s2s", "]", ",", "dim", "=", "2", ")", "]", ",", "\n", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "assert", "start_pos", ">", "1", "\n", "assert", "past", "[", "0", "]", ".", "shape", "[", "1", "]", "==", "2", "\n", "self", ".", "prev_encoded_layers", "=", "[", "torch", ".", "cat", "(", "[", "x", ",", "p", "[", ":", ",", ":", "-", "1", ",", ":", "]", "]", ",", "dim", "=", "1", ")", "\n", "for", "x", ",", "p", "in", "zip", "(", "self", ".", "prev_encoded_layers", ",", "past", ")", "]", "\n", "\n", "", "attention_mask", "=", "self", ".", "full_attention_mask", "[", ":", ",", "\n", "self", ".", "od_labels_len", "+", "self", ".", "img_seq_len", "+", "start_pos", ":", "self", ".", "od_labels_len", "+", "self", ".", "img_seq_len", "+", "end_pos", ",", "\n", ":", "self", ".", "od_labels_len", "+", "self", ".", "img_seq_len", "+", "end_pos", "]", "\n", "\n", "", "return", "{", "'input_ids'", ":", "input_ids", ",", "'img_feats'", ":", "img_feats", ",", "\n", "'masked_pos'", ":", "masked_pos", ",", "'attention_mask'", ":", "attention_mask", ",", "\n", "'token_type_ids'", ":", "token_type_ids", ",", "'position_ids'", ":", "position_ids", ",", "\n", "'is_training'", ":", "False", ",", "\n", "'encoder_history_states'", ":", "self", ".", "prev_encoded_layers", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning.get_output_embeddings": [[758, 760], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning.generate": [[761, 898], ["max", "modeling_bert.BertForImageCaptioning._expand_for_beams", "modeling_bert.BertForImageCaptioning._expand_for_beams", "modeling_bert.BertForImageCaptioning._expand_for_beams", "modeling_bert.BertForImageCaptioning._expand_for_beams", "modeling_bert.BertForImageCaptioning._expand_for_beams", "modeling_bert.BertForImageCaptioning._expand_for_beams", "modeling_bert.BertForImageCaptioning._expand_for_beams", "torch.full", "torch.full", "torch.full", "torch.full", "modeling_bert.BertForImageCaptioning._expand_for_beams", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cat.unsqueeze().expand", "torch.cat.unsqueeze().expand", "utils.cbs.ConstrainedBeamSearch", "utils.cbs.ConstrainedBeamSearch.search", "utils.cbs.select_best_beam_with_constraints", "modeling_bert.BertForImageCaptioning.dim", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_bert.BertForImageCaptioning._generate_beam_search", "modeling_bert.BertForImageCaptioning._generate_no_beam_search", "curr_ids.unsqueeze", "logprobs.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning._expand_for_beams", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning._expand_for_beams", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning._expand_for_beams", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning._expand_for_beams", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning._expand_for_beams", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning._expand_for_beams", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning._expand_for_beams", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning._expand_for_beams", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.ConstrainedBeamSearch.search", "home.repos.pwc.inspect_result.cciiplab_dpt.utils.cbs.select_best_beam_with_constraints", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.CaptionPreTrainedModel._generate_beam_search", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.CaptionPreTrainedModel._generate_no_beam_search"], ["", "def", "generate", "(", "self", ",", "img_feats", ",", "attention_mask", ",", "masked_pos", ",", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "input_ids", "=", "None", ",", "max_length", "=", "None", ",", "\n", "do_sample", "=", "None", ",", "num_beams", "=", "None", ",", "temperature", "=", "None", ",", "top_k", "=", "None", ",", "top_p", "=", "None", ",", "\n", "repetition_penalty", "=", "None", ",", "bos_token_id", "=", "None", ",", "pad_token_id", "=", "None", ",", "\n", "eos_token_ids", "=", "None", ",", "mask_token_id", "=", "None", ",", "length_penalty", "=", "None", ",", "\n", "num_return_sequences", "=", "None", ",", "\n", "num_keep_best", "=", "1", ",", "is_decode", "=", "None", ",", "\n", "add_od_labels", "=", "False", ",", "od_labels_start_posid", "=", "None", ",", "\n", "use_cbs", "=", "False", ",", "fsm", "=", "None", ",", "num_constraints", "=", "None", ",", "\n", "min_constraints_to_satisfy", "=", "None", ",", "use_hypo", "=", "False", ",", "\n", "decoding_constraint_flag", "=", "None", ",", "bad_ending_ids", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Generates captions given image features\n        \"\"\"", "\n", "assert", "is_decode", "\n", "batch_size", "=", "img_feats", ".", "shape", "[", "0", "]", "\n", "self", ".", "img_seq_len", "=", "img_feats", ".", "shape", "[", "1", "]", "\n", "self", ".", "max_seq_len", "=", "max_length", "\n", "self", ".", "mask_token_id", "=", "mask_token_id", "\n", "self", ".", "prev_encoded_layers", "=", "None", "\n", "# NOTE: num_keep_best is not equavilant to num_return_sequences", "\n", "# num_keep_best is the number of hypotheses to keep in beam search", "\n", "# num_return_sequences is the repeating times of input, coupled with", "\n", "# do_sample=True can generate more than one samples per image", "\n", "self", ".", "num_keep_best", "=", "num_keep_best", "\n", "\n", "vocab_size", "=", "self", ".", "config", ".", "vocab_size", "\n", "if", "not", "use_cbs", ":", "\n", "            ", "num_fsm_states", "=", "1", "\n", "", "else", ":", "\n", "            ", "b", ",", "num_fsm_states", ",", "f1", ",", "v", "=", "fsm", ".", "shape", "\n", "assert", "b", "==", "batch_size", "and", "v", "==", "vocab_size", "and", "f1", "==", "num_fsm_states", "\n", "\n", "", "self", ".", "add_od_labels", "=", "add_od_labels", "\n", "# avoid position_ids collision of caption and od labels", "\n", "self", ".", "od_labels_start_posid", "=", "max", "(", "od_labels_start_posid", ",", "self", ".", "max_seq_len", ")", "\n", "if", "self", ".", "add_od_labels", ":", "\n", "# get od labels part from input_ids", "\n", "            ", "assert", "input_ids", ".", "shape", "[", "0", "]", "==", "batch_size", "\n", "od_label_ids", "=", "input_ids", "[", ":", ",", "self", ".", "max_seq_len", ":", "]", "\n", "self", ".", "od_labels_len", "=", "input_ids", ".", "shape", "[", "1", "]", "-", "self", ".", "max_seq_len", "\n", "input_ids", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "od_labels_len", "=", "0", "\n", "od_label_ids", "=", "None", "\n", "assert", "input_ids", ".", "shape", "==", "(", "batch_size", ",", "self", ".", "max_seq_len", ")", "\n", "input_ids", "=", "None", "\n", "\n", "", "if", "input_ids", "is", "None", ":", "\n", "            ", "input_ids", "=", "torch", ".", "full", "(", "\n", "(", "batch_size", ",", "1", ")", ",", "bos_token_id", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "img_feats", ".", "device", "\n", ")", "\n", "", "else", ":", "\n", "            ", "assert", "input_ids", ".", "dim", "(", ")", "==", "2", ",", "\"Input prompt should be of shape (batch_size, sequence length).\"", "\n", "assert", "input_ids", ".", "shape", "[", "0", "]", "==", "batch_size", ",", "\"Input batch size must match image features\"", "\n", "\n", "", "cur_len", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "if", "num_return_sequences", "!=", "1", ":", "\n", "# Expand input to num return sequences", "\n", "            ", "input_ids", "=", "self", ".", "_expand_for_beams", "(", "input_ids", ",", "num_return_sequences", ")", "\n", "effective_batch_size", "=", "batch_size", "*", "num_return_sequences", "\n", "", "else", ":", "\n", "            ", "effective_batch_size", "=", "batch_size", "\n", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "self", ".", "max_seq_len", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "posids_len", "=", "self", ".", "max_seq_len", "\n", "if", "self", ".", "add_od_labels", ":", "\n", "                ", "od_labels_posids", "=", "torch", ".", "arange", "(", "\n", "self", ".", "od_labels_start_posid", ",", "\n", "self", ".", "od_labels_start_posid", "+", "self", ".", "od_labels_len", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "torch", ".", "cat", "(", "[", "position_ids", ",", "od_labels_posids", "]", ")", "\n", "posids_len", "+=", "self", ".", "od_labels_len", "\n", "", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "[", "batch_size", ",", "posids_len", "]", ")", "\n", "\n", "", "num_expand", "=", "num_beams", "*", "num_fsm_states", "*", "num_return_sequences", "\n", "self", ".", "od_label_ids", "=", "self", ".", "_expand_for_beams", "(", "od_label_ids", ",", "num_expand", ")", "\n", "self", ".", "img_feats", "=", "self", ".", "_expand_for_beams", "(", "img_feats", ",", "num_expand", ")", "\n", "self", ".", "full_attention_mask", "=", "self", ".", "_expand_for_beams", "(", "attention_mask", ",", "num_expand", ")", "\n", "self", ".", "full_masked_pos", "=", "self", ".", "_expand_for_beams", "(", "masked_pos", ",", "num_expand", ")", "\n", "self", ".", "full_token_type_ids", "=", "self", ".", "_expand_for_beams", "(", "token_type_ids", ",", "num_expand", ")", "\n", "self", ".", "full_position_ids", "=", "self", ".", "_expand_for_beams", "(", "position_ids", ",", "num_expand", ")", "\n", "self", ".", "full_head_mask", "=", "self", ".", "_expand_for_beams", "(", "head_mask", ",", "num_expand", ")", "\n", "\n", "if", "not", "use_cbs", ":", "\n", "            ", "if", "num_beams", ">", "1", ":", "\n", "                ", "output", "=", "self", ".", "_generate_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "effective_batch_size", ",", "\n", "length_penalty", ",", "\n", "num_beams", ",", "\n", "vocab_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "output", "=", "self", ".", "_generate_no_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "effective_batch_size", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "assert", "self", ".", "num_keep_best", "==", "1", ",", "'not supported n_best > 1 for CBS'", "\n", "searcher", "=", "ConstrainedBeamSearch", "(", "eos_token_ids", ",", "max_length", ",", "\n", "num_beams", ")", "\n", "curr_ids", ",", "sum_logprobs", "=", "searcher", ".", "search", "(", "\n", "input_ids", ",", "\n", "None", ",", "\n", "self", ".", "_decode_step", ",", "\n", "fsm", ",", "\n", ")", "\n", "curr_ids", ",", "logprobs", "=", "select_best_beam_with_constraints", "(", "\n", "curr_ids", ",", "\n", "sum_logprobs", ",", "\n", "num_constraints", ",", "\n", "min_constraints_to_satisfy", ",", "\n", "eos_token_ids", ",", "\n", ")", "\n", "# (batch_size, n_best, max_len), (batch_size, n_best)", "\n", "output", "=", "(", "curr_ids", ".", "unsqueeze", "(", "1", ")", ",", "logprobs", ".", "unsqueeze", "(", "1", ")", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning._expand_for_beams": [[899, 909], ["list", "x.contiguous().view.contiguous().view.unsqueeze().expand", "x.contiguous().view.contiguous().view.contiguous().view", "x.contiguous().view.contiguous().view.unsqueeze", "x.contiguous().view.contiguous().view.contiguous"], "methods", ["None"], ["", "def", "_expand_for_beams", "(", "self", ",", "x", ",", "num_expand", ")", ":", "\n", "        ", "if", "x", "is", "None", "or", "num_expand", "==", "1", ":", "\n", "            ", "return", "x", "\n", "\n", "", "input_shape", "=", "list", "(", "x", ".", "shape", ")", "\n", "expanded_shape", "=", "input_shape", "[", ":", "1", "]", "+", "[", "num_expand", "]", "+", "input_shape", "[", "1", ":", "]", "\n", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "expanded_shape", ")", "\n", "# (batch_size * num_expand, ...)", "\n", "x", "=", "x", ".", "contiguous", "(", ")", ".", "view", "(", "[", "input_shape", "[", "0", "]", "*", "num_expand", "]", "+", "input_shape", "[", "1", ":", "]", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertForImageCaptioning._do_output_past": [[910, 912], ["len"], "methods", ["None"], ["", "def", "_do_output_past", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "return", "len", "(", "outputs", ")", ">", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertPreTrainingHeads.__init__": [[915, 920], ["torch.nn.Module.__init__", "transformers.pytorch_transformers.modeling_bert.BertLMPredictionHead", "torch.nn.Linear", "torch.nn.Linear", "hasattr"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPreTrainingHeads", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ")", "\n", "num_seq_relations", "=", "config", ".", "num_contrast_classes", "if", "hasattr", "(", "config", ",", "\"num_contrast_classes\"", ")", "else", "2", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_seq_relations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertPreTrainingHeads.forward": [[921, 925], ["modeling_bert.BertPreTrainingHeads.predictions", "modeling_bert.BertPreTrainingHeads.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ",", "pooled_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "prediction_scores", ",", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__": [[971, 981], ["modeling_utils.ImgPreTrainedModel.__init__", "modeling_bert.BertImgModel", "modeling_bert.BertPreTrainingHeads", "modeling_bert.BertImgForPreTraining.apply", "modeling_bert.BertImgForPreTraining.tie_weights", "hasattr"], "methods", ["home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.__init__", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertImgForPreTraining", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "#self.bert = BertModel(config) # original BERT", "\n", "self", ".", "bert", "=", "BertImgModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertPreTrainingHeads", "(", "config", ")", "\n", "self", ".", "num_seq_relations", "=", "config", ".", "num_contrast_classes", "if", "hasattr", "(", "config", ",", "\"num_contrast_classes\"", ")", "else", "2", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.init_weights": [[982, 995], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "\n", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "BertLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.tie_weights": [[996, 1002], ["modeling_bert.BertImgForPreTraining._tie_or_clone_weights"], "methods", ["None"], ["", "", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "cls", ".", "predictions", ".", "decoder", ",", "\n", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.BertImgForPreTraining.forward": [[1003, 1021], ["modeling_bert.BertImgForPreTraining.bert", "modeling_bert.BertImgForPreTraining.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "prediction_scores.view", "masked_lm_labels.view", "seq_relationship_score.view", "next_sentence_label.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ",", "\n", "next_sentence_label", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "img_feats", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ",", "img_feats", "=", "img_feats", ")", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "outputs", "[", ":", "2", "]", "\n", "prediction_scores", ",", "seq_relationship_score", "=", "self", ".", "cls", "(", "sequence_output", ",", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", "seq_relationship_score", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", "and", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "self", ".", "num_seq_relations", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "total_loss", "=", "masked_lm_loss", "+", "next_sentence_loss", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "+", "(", "masked_lm_loss", ",", ")", "\n", "\n", "", "return", "outputs", "# (loss), prediction_scores, seq_relationship_score, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_bert.instance_bce_with_logits": [[282, 288], ["torch.binary_cross_entropy_with_logits", "logits.dim", "labels.size"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.ciderD.ciderD_scorer.CiderScorer.size"], ["", "", "def", "instance_bce_with_logits", "(", "logits", ",", "labels", ",", "reduction", "=", "'mean'", ")", ":", "\n", "    ", "assert", "logits", ".", "dim", "(", ")", "==", "2", "\n", "loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "logits", ",", "labels", ",", "reduction", "=", "reduction", ")", "\n", "if", "reduction", "==", "'mean'", ":", "\n", "        ", "loss", "*=", "labels", ".", "size", "(", "1", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.DeclarationGeneration.finetuning_T5.DataTrainingArguments.__post_init__": [[217, 231], ["ValueError", "ValueError", "finetuning_T5.DataTrainingArguments.train_file.split", "finetuning_T5.DataTrainingArguments.validation_file.split"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dataset_name", "is", "None", "and", "self", ".", "train_file", "is", "None", "and", "self", ".", "validation_file", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Need either a dataset name or a training/validation file.\"", ")", "\n", "", "elif", "self", ".", "source_lang", "is", "None", "or", "self", ".", "target_lang", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Need to specify the source language and the target language.\"", ")", "\n", "\n", "", "if", "self", ".", "train_file", "is", "not", "None", ":", "\n", "            ", "extension", "=", "self", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "extension", "==", "\"json\"", ",", "\"`train_file` should be a json file.\"", "\n", "", "if", "self", ".", "validation_file", "is", "not", "None", ":", "\n", "            ", "extension", "=", "self", ".", "validation_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "extension", "==", "\"json\"", ",", "\"`validation_file` should be a json file.\"", "\n", "", "if", "self", ".", "val_max_target_length", "is", "None", ":", "\n", "            ", "self", ".", "val_max_target_length", "=", "self", ".", "max_target_length", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.DeclarationGeneration.finetuning_T5.main": [[233, 627], ["transformers.HfArgumentParser", "logging.basicConfig", "training_args.get_process_log_level", "logger.setLevel", "datasets.utils.logging.set_verbosity", "transformers.utils.logging.set_verbosity", "transformers.utils.logging.enable_default_handler", "transformers.utils.logging.enable_explicit_format", "logger.warning", "logger.info", "transformers.set_seed", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSeq2SeqLM.from_pretrained", "AutoModelForSeq2SeqLM.from_pretrained.resize_token_embeddings", "isinstance", "datasets.load_metric", "transformers.Seq2SeqTrainer", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "logger.warning", "os.path.isdir", "transformers.trainer_utils.get_last_checkpoint", "datasets.load_dataset", "datasets.load_dataset", "len", "isinstance", "isinstance", "ValueError", "tuple", "data_args.source_lang.split", "data_args.target_lang.split", "logger.warning", "AutoTokenizer.from_pretrained.", "transformers.DataCollatorForSeq2Seq", "isinstance", "AutoTokenizer.from_pretrained.batch_decode", "AutoTokenizer.from_pretrained.batch_decode", "finetuning_T5.main.postprocess_text"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.utils.misc.set_seed", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.cciiplab_dpt.modeling.modeling_utils.ImgPreTrainedModel.from_pretrained"], ["", "", "", "def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "# or by passing the --help flag to this script.", "\n", "# We now keep distinct sets of args, for a cleaner separation of concerns.", "\n", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "Seq2SeqTrainingArguments", ")", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "# \u89e3\u6790\u53c2\u6570\u6210\u6570\u636e\u53c2\u6570\u7c7b", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "# Setup logging", "\n", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "]", ",", "\n", ")", "\n", "\n", "# \u8bbe\u7f6elogging\u7684\u7ea7\u522b", "\n", "log_level", "=", "training_args", ".", "get_process_log_level", "(", ")", "\n", "logger", ".", "setLevel", "(", "log_level", ")", "\n", "datasets", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_explicit_format", "(", ")", "\n", "\n", "# Log on each process the small summary:", "\n", "logger", ".", "warning", "(", "\n", "f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"", "\n", "+", "f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"", "\n", ")", "\n", "logger", ".", "info", "(", "f\"Training/evaluation parameters {training_args}\"", ")", "\n", "\n", "if", "data_args", ".", "source_prefix", "is", "None", "and", "model_args", ".", "model_name_or_path", "in", "[", "\n", "\"t5-small\"", ",", "\n", "\"t5-base\"", ",", "\n", "\"t5-large\"", ",", "\n", "\"t5-3b\"", ",", "\n", "\"t5-11b\"", ",", "\n", "]", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "\"You're running a t5 model but didn't provide a source prefix, which is expected, e.g. with \"", "\n", "\"`--source_prefix 'translate English to German: ' `\"", "\n", ")", "\n", "\n", "# \u68c0\u6d4b\u662f\u5426\u5df2\u7ecf\u5b58\u5728checkpoint", "\n", "# Detecting last checkpoint.", "\n", "", "last_checkpoint", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "training_args", ".", "output_dir", ")", "and", "training_args", ".", "do_train", "and", "not", "training_args", ".", "overwrite_output_dir", ":", "\n", "        ", "last_checkpoint", "=", "get_last_checkpoint", "(", "training_args", ".", "output_dir", ")", "\n", "if", "last_checkpoint", "is", "None", "and", "len", "(", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"", "\n", "\"Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "", "elif", "last_checkpoint", "is", "not", "None", "and", "training_args", ".", "resume_from_checkpoint", "is", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"", "\n", "\"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"", "\n", ")", "\n", "\n", "# \u8bbe\u7f6e\u968f\u673a\u79cd\u5b50", "\n", "# Set seed before initializing model.", "\n", "", "", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Get the datasets: you can either provide your own JSON training and evaluation files (see below)", "\n", "# or just provide the name of one of the public datasets available on the hub at https://huggingface.co/datasets/", "\n", "# (the dataset will be downloaded automatically from the datasets Hub).", "\n", "#", "\n", "# For translation, only JSON files are supported, with one field named \"translation\" containing two keys for the", "\n", "# source and target languages (unless you adapt what follows).", "\n", "#", "\n", "# In distributed training, the load_dataset function guarantee that only one local process can concurrently", "\n", "# download the dataset.", "\n", "if", "data_args", ".", "dataset_name", "is", "not", "None", ":", "\n", "# Downloading and loading a dataset from the hub.", "\n", "        ", "raw_datasets", "=", "load_dataset", "(", "\n", "data_args", ".", "dataset_name", ",", "data_args", ".", "dataset_config_name", ",", "cache_dir", "=", "model_args", ".", "cache_dir", "\n", ")", "\n", "", "else", ":", "\n", "# \u8fd9\u91cc\u662f\u8f7d\u5165\u4eba\u5de5\u6570\u636e\u96c6", "\n", "        ", "data_files", "=", "{", "}", "\n", "if", "data_args", ".", "train_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"train\"", "]", "=", "data_args", ".", "train_file", "\n", "extension", "=", "data_args", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "", "if", "data_args", ".", "validation_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"validation\"", "]", "=", "data_args", ".", "validation_file", "\n", "extension", "=", "data_args", ".", "validation_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "", "if", "data_args", ".", "test_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"test\"", "]", "=", "data_args", ".", "test_file", "\n", "extension", "=", "data_args", ".", "test_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "", "raw_datasets", "=", "load_dataset", "(", "extension", ",", "data_files", "=", "data_files", ",", "cache_dir", "=", "model_args", ".", "cache_dir", ")", "\n", "# See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at", "\n", "# https://huggingface.co/docs/datasets/loading_datasets.html.", "\n", "\n", "# \u8f7d\u5165checkpoint", "\n", "# Load pretrained model and tokenizer", "\n", "#", "\n", "# Distributed training:", "\n", "# The .from_pretrained methods guarantee that only one local process can concurrently", "\n", "# download model & vocab.", "\n", "", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "model_args", ".", "config_name", "if", "model_args", ".", "config_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "model_args", ".", "tokenizer_name", "if", "model_args", ".", "tokenizer_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "use_fast", "=", "model_args", ".", "use_fast_tokenizer", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "model", "=", "AutoModelForSeq2SeqLM", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "\n", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "\n", "# Set decoder_start_token_id", "\n", "if", "model", ".", "config", ".", "decoder_start_token_id", "is", "None", "and", "isinstance", "(", "tokenizer", ",", "(", "MBartTokenizer", ",", "MBartTokenizerFast", ")", ")", ":", "\n", "        ", "if", "isinstance", "(", "tokenizer", ",", "MBartTokenizer", ")", ":", "\n", "            ", "model", ".", "config", ".", "decoder_start_token_id", "=", "tokenizer", ".", "lang_code_to_id", "[", "data_args", ".", "target_lang", "]", "\n", "", "else", ":", "\n", "            ", "model", ".", "config", ".", "decoder_start_token_id", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "data_args", ".", "target_lang", ")", "\n", "\n", "", "", "if", "model", ".", "config", ".", "decoder_start_token_id", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"Make sure that `config.decoder_start_token_id` is correctly defined\"", ")", "\n", "\n", "", "prefix", "=", "data_args", ".", "source_prefix", "if", "data_args", ".", "source_prefix", "is", "not", "None", "else", "\"\"", "\n", "\n", "# \u9884\u5904\u7406\u6570\u636e\u96c6\uff0c\u5bf9inputs\u548ctargets\u8fdb\u884c\u5206\u8bcd", "\n", "# Preprocessing the datasets.", "\n", "# We need to tokenize inputs and targets.", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "column_names", "=", "raw_datasets", "[", "\"train\"", "]", ".", "column_names", "\n", "", "elif", "training_args", ".", "do_eval", ":", "\n", "        ", "column_names", "=", "raw_datasets", "[", "\"validation\"", "]", ".", "column_names", "\n", "", "elif", "training_args", ".", "do_predict", ":", "\n", "        ", "column_names", "=", "raw_datasets", "[", "\"test\"", "]", ".", "column_names", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"There is nothing to do. Please pass `do_train`, `do_eval` and/or `do_predict`.\"", ")", "\n", "return", "\n", "\n", "# For translation we set the codes of our source and target languages (only useful for mBART, the others will", "\n", "# ignore those attributes).", "\n", "", "if", "isinstance", "(", "tokenizer", ",", "tuple", "(", "MULTILINGUAL_TOKENIZERS", ")", ")", ":", "\n", "        ", "assert", "data_args", ".", "target_lang", "is", "not", "None", "and", "data_args", ".", "source_lang", "is", "not", "None", ",", "(", "\n", "f\"{tokenizer.__class__.__name__} is a multilingual tokenizer which requires --source_lang and \"", "\n", "\"--target_lang arguments.\"", "\n", ")", "\n", "\n", "tokenizer", ".", "src_lang", "=", "data_args", ".", "source_lang", "\n", "tokenizer", ".", "tgt_lang", "=", "data_args", ".", "target_lang", "\n", "\n", "# For multilingual translation models like mBART-50 and M2M100 we need to force the target language token", "\n", "# as the first generated token. We ask the user to explicitly provide this as --forced_bos_token argument.", "\n", "forced_bos_token_id", "=", "(", "\n", "tokenizer", ".", "lang_code_to_id", "[", "data_args", ".", "forced_bos_token", "]", "if", "data_args", ".", "forced_bos_token", "is", "not", "None", "else", "None", "\n", ")", "\n", "model", ".", "config", ".", "forced_bos_token_id", "=", "forced_bos_token_id", "\n", "\n", "# Get the language codes for input/target.", "\n", "", "source_lang", "=", "data_args", ".", "source_lang", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "\n", "target_lang", "=", "data_args", ".", "target_lang", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "\n", "\n", "# Temporarily set max_target_length for training.", "\n", "max_target_length", "=", "data_args", ".", "max_target_length", "\n", "padding", "=", "\"max_length\"", "if", "data_args", ".", "pad_to_max_length", "else", "False", "\n", "\n", "if", "training_args", ".", "label_smoothing_factor", ">", "0", "and", "not", "hasattr", "(", "model", ",", "\"prepare_decoder_input_ids_from_labels\"", ")", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "\"label_smoothing is enabled but the `prepare_decoder_input_ids_from_labels` method is not defined for\"", "\n", "f\"`{model.__class__.__name__}`. This will lead to loss being calculated twice and will take up more memory\"", "\n", ")", "\n", "\n", "", "def", "preprocess_function", "(", "examples", ")", ":", "\n", "        ", "inputs", "=", "[", "ex", "[", "source_lang", "+", "\"_q\"", "]", "for", "ex", "in", "examples", "[", "\"translation\"", "]", "]", "\n", "targets", "=", "[", "ex", "[", "target_lang", "+", "\"_a\"", "]", "for", "ex", "in", "examples", "[", "\"translation\"", "]", "]", "\n", "inputs", "=", "[", "prefix", "+", "inp", "for", "inp", "in", "inputs", "]", "\n", "model_inputs", "=", "tokenizer", "(", "inputs", ",", "max_length", "=", "data_args", ".", "max_source_length", ",", "padding", "=", "padding", ",", "truncation", "=", "True", ")", "\n", "\n", "# Setup the tokenizer for targets", "\n", "with", "tokenizer", ".", "as_target_tokenizer", "(", ")", ":", "\n", "            ", "labels", "=", "tokenizer", "(", "targets", ",", "max_length", "=", "max_target_length", ",", "padding", "=", "padding", ",", "truncation", "=", "True", ")", "\n", "\n", "# If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore", "\n", "# padding in the loss.", "\n", "", "if", "padding", "==", "\"max_length\"", "and", "data_args", ".", "ignore_pad_token_for_loss", ":", "\n", "            ", "labels", "[", "\"input_ids\"", "]", "=", "[", "\n", "[", "(", "l", "if", "l", "!=", "tokenizer", ".", "pad_token_id", "else", "-", "100", ")", "for", "l", "in", "label", "]", "for", "label", "in", "labels", "[", "\"input_ids\"", "]", "\n", "]", "\n", "\n", "", "model_inputs", "[", "\"labels\"", "]", "=", "labels", "[", "\"input_ids\"", "]", "\n", "return", "model_inputs", "\n", "\n", "# \u5904\u7406\u8bad\u7ec3\u96c6", "\n", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "if", "\"train\"", "not", "in", "raw_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"--do_train requires a train dataset\"", ")", "\n", "", "train_dataset", "=", "raw_datasets", "[", "\"train\"", "]", "\n", "if", "data_args", ".", "max_train_samples", "is", "not", "None", ":", "\n", "            ", "train_dataset", "=", "train_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_train_samples", ")", ")", "\n", "", "with", "training_args", ".", "main_process_first", "(", "desc", "=", "\"train dataset map pre-processing\"", ")", ":", "\n", "            ", "train_dataset", "=", "train_dataset", ".", "map", "(", "\n", "preprocess_function", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "remove_columns", "=", "column_names", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", "desc", "=", "\"Running tokenizer on train dataset\"", ",", "\n", ")", "\n", "\n", "# \u5904\u7406\u9a8c\u8bc1\u96c6", "\n", "", "", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "max_target_length", "=", "data_args", ".", "val_max_target_length", "\n", "if", "\"validation\"", "not", "in", "raw_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"--do_eval requires a validation dataset\"", ")", "\n", "", "eval_dataset", "=", "raw_datasets", "[", "\"validation\"", "]", "\n", "if", "data_args", ".", "max_eval_samples", "is", "not", "None", ":", "\n", "            ", "eval_dataset", "=", "eval_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_eval_samples", ")", ")", "\n", "", "with", "training_args", ".", "main_process_first", "(", "desc", "=", "\"validation dataset map pre-processing\"", ")", ":", "\n", "            ", "eval_dataset", "=", "eval_dataset", ".", "map", "(", "\n", "preprocess_function", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "remove_columns", "=", "column_names", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", "desc", "=", "\"Running tokenizer on validation dataset\"", ",", "\n", ")", "\n", "\n", "# \u5904\u7406\u6d4b\u8bd5\u96c6", "\n", "", "", "if", "training_args", ".", "do_predict", ":", "\n", "        ", "max_target_length", "=", "data_args", ".", "val_max_target_length", "\n", "if", "\"test\"", "not", "in", "raw_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"--do_predict requires a test dataset\"", ")", "\n", "", "predict_dataset", "=", "raw_datasets", "[", "\"test\"", "]", "\n", "if", "data_args", ".", "max_predict_samples", "is", "not", "None", ":", "\n", "            ", "predict_dataset", "=", "predict_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_predict_samples", ")", ")", "\n", "", "with", "training_args", ".", "main_process_first", "(", "desc", "=", "\"prediction dataset map pre-processing\"", ")", ":", "\n", "            ", "predict_dataset", "=", "predict_dataset", ".", "map", "(", "\n", "preprocess_function", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "remove_columns", "=", "column_names", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", "desc", "=", "\"Running tokenizer on prediction dataset\"", ",", "\n", ")", "\n", "\n", "# Data collator", "\n", "", "", "label_pad_token_id", "=", "-", "100", "if", "data_args", ".", "ignore_pad_token_for_loss", "else", "tokenizer", ".", "pad_token_id", "\n", "if", "data_args", ".", "pad_to_max_length", ":", "\n", "        ", "data_collator", "=", "default_data_collator", "\n", "", "else", ":", "\n", "        ", "data_collator", "=", "DataCollatorForSeq2Seq", "(", "\n", "tokenizer", ",", "\n", "model", "=", "model", ",", "\n", "label_pad_token_id", "=", "label_pad_token_id", ",", "\n", "pad_to_multiple_of", "=", "8", "if", "training_args", ".", "fp16", "else", "None", ",", "\n", ")", "\n", "\n", "# Metric", "\n", "# metric = load_metric(\"sacrebleu\")", "\n", "", "metric", "=", "load_metric", "(", "\"/home/yuhang/SceneGraph/gqa_process/transformers-master/sacrebleu.py\"", ")", "\n", "\n", "def", "postprocess_text", "(", "preds", ",", "labels", ")", ":", "\n", "        ", "preds", "=", "[", "pred", ".", "strip", "(", ")", "for", "pred", "in", "preds", "]", "\n", "labels", "=", "[", "[", "label", ".", "strip", "(", ")", "]", "for", "label", "in", "labels", "]", "\n", "\n", "return", "preds", ",", "labels", "\n", "\n", "", "def", "compute_metrics", "(", "eval_preds", ")", ":", "\n", "        ", "preds", ",", "labels", "=", "eval_preds", "\n", "if", "isinstance", "(", "preds", ",", "tuple", ")", ":", "\n", "            ", "preds", "=", "preds", "[", "0", "]", "\n", "", "decoded_preds", "=", "tokenizer", ".", "batch_decode", "(", "preds", ",", "skip_special_tokens", "=", "True", ")", "\n", "if", "data_args", ".", "ignore_pad_token_for_loss", ":", "\n", "# Replace -100 in the labels as we can't decode them.", "\n", "            ", "labels", "=", "np", ".", "where", "(", "labels", "!=", "-", "100", ",", "labels", ",", "tokenizer", ".", "pad_token_id", ")", "\n", "", "decoded_labels", "=", "tokenizer", ".", "batch_decode", "(", "labels", ",", "skip_special_tokens", "=", "True", ")", "\n", "\n", "# Some simple post-processing", "\n", "decoded_preds", ",", "decoded_labels", "=", "postprocess_text", "(", "decoded_preds", ",", "decoded_labels", ")", "\n", "\n", "result", "=", "metric", ".", "compute", "(", "predictions", "=", "decoded_preds", ",", "references", "=", "decoded_labels", ")", "\n", "result", "=", "{", "\"bleu\"", ":", "result", "[", "\"score\"", "]", "}", "\n", "\n", "prediction_lens", "=", "[", "np", ".", "count_nonzero", "(", "pred", "!=", "tokenizer", ".", "pad_token_id", ")", "for", "pred", "in", "preds", "]", "\n", "result", "[", "\"gen_len\"", "]", "=", "np", ".", "mean", "(", "prediction_lens", ")", "\n", "result", "=", "{", "k", ":", "round", "(", "v", ",", "4", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", "}", "\n", "return", "result", "\n", "\n", "# Initialize our Trainer", "\n", "", "trainer", "=", "Seq2SeqTrainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "train_dataset", "if", "training_args", ".", "do_train", "else", "None", ",", "\n", "eval_dataset", "=", "eval_dataset", "if", "training_args", ".", "do_eval", "else", "None", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "data_collator", "=", "data_collator", ",", "\n", "compute_metrics", "=", "compute_metrics", "if", "training_args", ".", "predict_with_generate", "else", "None", ",", "\n", ")", "\n", "\n", "# Training", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "if", "training_args", ".", "resume_from_checkpoint", "is", "not", "None", ":", "\n", "            ", "checkpoint", "=", "training_args", ".", "resume_from_checkpoint", "\n", "", "elif", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "checkpoint", "=", "last_checkpoint", "\n", "", "train_result", "=", "trainer", ".", "train", "(", "resume_from_checkpoint", "=", "checkpoint", ")", "\n", "trainer", ".", "save_model", "(", ")", "# Saves the tokenizer too for easy upload", "\n", "\n", "metrics", "=", "train_result", ".", "metrics", "\n", "max_train_samples", "=", "(", "\n", "data_args", ".", "max_train_samples", "if", "data_args", ".", "max_train_samples", "is", "not", "None", "else", "len", "(", "train_dataset", ")", "\n", ")", "\n", "metrics", "[", "\"train_samples\"", "]", "=", "min", "(", "max_train_samples", ",", "len", "(", "train_dataset", ")", ")", "\n", "\n", "trainer", ".", "log_metrics", "(", "\"train\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"train\"", ",", "metrics", ")", "\n", "trainer", ".", "save_state", "(", ")", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "max_length", "=", "(", "\n", "training_args", ".", "generation_max_length", "\n", "if", "training_args", ".", "generation_max_length", "is", "not", "None", "\n", "else", "data_args", ".", "val_max_target_length", "\n", ")", "\n", "num_beams", "=", "data_args", ".", "num_beams", "if", "data_args", ".", "num_beams", "is", "not", "None", "else", "training_args", ".", "generation_num_beams", "\n", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Evaluate ***\"", ")", "\n", "\n", "metrics", "=", "trainer", ".", "evaluate", "(", "max_length", "=", "max_length", ",", "num_beams", "=", "num_beams", ",", "metric_key_prefix", "=", "\"eval\"", ")", "\n", "max_eval_samples", "=", "data_args", ".", "max_eval_samples", "if", "data_args", ".", "max_eval_samples", "is", "not", "None", "else", "len", "(", "eval_dataset", ")", "\n", "metrics", "[", "\"eval_samples\"", "]", "=", "min", "(", "max_eval_samples", ",", "len", "(", "eval_dataset", ")", ")", "\n", "\n", "trainer", ".", "log_metrics", "(", "\"eval\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"eval\"", ",", "metrics", ")", "\n", "\n", "", "if", "training_args", ".", "do_predict", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Predict ***\"", ")", "\n", "\n", "predict_results", "=", "trainer", ".", "predict", "(", "\n", "predict_dataset", ",", "metric_key_prefix", "=", "\"predict\"", ",", "max_length", "=", "max_length", ",", "num_beams", "=", "num_beams", "\n", ")", "\n", "metrics", "=", "predict_results", ".", "metrics", "\n", "max_predict_samples", "=", "(", "\n", "data_args", ".", "max_predict_samples", "if", "data_args", ".", "max_predict_samples", "is", "not", "None", "else", "len", "(", "predict_dataset", ")", "\n", ")", "\n", "metrics", "[", "\"predict_samples\"", "]", "=", "min", "(", "max_predict_samples", ",", "len", "(", "predict_dataset", ")", ")", "\n", "\n", "trainer", ".", "log_metrics", "(", "\"predict\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"predict\"", ",", "metrics", ")", "\n", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "if", "training_args", ".", "predict_with_generate", ":", "\n", "                ", "predictions", "=", "tokenizer", ".", "batch_decode", "(", "\n", "predict_results", ".", "predictions", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "True", "\n", ")", "\n", "predictions", "=", "[", "pred", ".", "strip", "(", ")", "for", "pred", "in", "predictions", "]", "\n", "output_prediction_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"generated_predictions.txt\"", ")", "\n", "with", "open", "(", "output_prediction_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "                    ", "writer", ".", "write", "(", "\"\\n\"", ".", "join", "(", "predictions", ")", ")", "\n", "\n", "", "", "", "", "kwargs", "=", "{", "\"finetuned_from\"", ":", "model_args", ".", "model_name_or_path", ",", "\"tasks\"", ":", "\"translation\"", "}", "\n", "if", "data_args", ".", "dataset_name", "is", "not", "None", ":", "\n", "        ", "kwargs", "[", "\"dataset_tags\"", "]", "=", "data_args", ".", "dataset_name", "\n", "if", "data_args", ".", "dataset_config_name", "is", "not", "None", ":", "\n", "            ", "kwargs", "[", "\"dataset_args\"", "]", "=", "data_args", ".", "dataset_config_name", "\n", "kwargs", "[", "\"dataset\"", "]", "=", "f\"{data_args.dataset_name} {data_args.dataset_config_name}\"", "\n", "", "else", ":", "\n", "            ", "kwargs", "[", "\"dataset\"", "]", "=", "data_args", ".", "dataset_name", "\n", "\n", "", "", "languages", "=", "[", "l", "for", "l", "in", "[", "data_args", ".", "source_lang", ",", "data_args", ".", "target_lang", "]", "if", "l", "is", "not", "None", "]", "\n", "if", "len", "(", "languages", ")", ">", "0", ":", "\n", "        ", "kwargs", "[", "\"language\"", "]", "=", "languages", "\n", "\n", "", "if", "training_args", ".", "push_to_hub", ":", "\n", "        ", "trainer", ".", "push_to_hub", "(", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "trainer", ".", "create_model_card", "(", "**", "kwargs", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.cciiplab_dpt.DeclarationGeneration.finetuning_T5._mp_fn": [[629, 632], ["finetuning_T5.main"], "function", ["home.repos.pwc.inspect_result.cciiplab_dpt.DeclarationGeneration.finetuning_T5.main"], ["", "def", "_mp_fn", "(", "index", ")", ":", "\n", "# For xla_spawn (TPUs)", "\n", "    ", "main", "(", ")", "\n", "\n"]]}